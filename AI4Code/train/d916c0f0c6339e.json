{"cell_type":{"a95a42a0":"code","5fcc79f4":"code","cde8ee25":"code","8ace0ffa":"code","f447febf":"code","e541a21e":"code","787d2ad2":"code","c07a9066":"code","0e71f391":"code","723e424c":"code","763c9d15":"code","e99dcae1":"code","c979dbe8":"code","565c16e1":"code","8b225a28":"code","c274aaf7":"code","44710c6d":"code","11141540":"code","2e20a3c4":"code","ba50aeea":"code","afd70a1e":"code","ca6eefe9":"code","8493245e":"markdown","012ed0f8":"markdown","99559ee2":"markdown","a8c6d08d":"markdown","16825170":"markdown","2c03fdc7":"markdown","f4feaf60":"markdown","280bc031":"markdown","5ccee47d":"markdown","016b34bc":"markdown","613ac5b9":"markdown","07510f62":"markdown","20688d61":"markdown","f749e402":"markdown","181f0d08":"markdown","e25c91d7":"markdown","f9c9518a":"markdown","d62cd7f3":"markdown"},"source":{"a95a42a0":"import os\nfrom IPython.display import Image\nImage(filename=\"..\/input\/sign-language-mnist\/amer_sign2.png\", width= 800, height=500)","5fcc79f4":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","cde8ee25":"import csv\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","8ace0ffa":"def get_data(filename):\n    with open(filename) as training_file:\n        training_reader = csv.reader(training_file, delimiter=',')\n        image = []\n        labels = []\n        line_count = 0\n        for row in training_reader:\n            if line_count == 0:\n                line_count +=1\n            else:\n                labels.append(row[0])\n                temp_image = row[1:785]\n                image_data_as_array = np.array_split(temp_image, 28)\n                image.append(image_data_as_array)\n                line_count += 1\n        images = np.array(image).astype('float')\n        labels = np.array(labels).astype('float')\n        print(f'Processed {line_count} lines.')\n\n    return images, labels\n\n\ntraining_images, training_labels = get_data(\"..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv\")\ntesting_images, testing_labels = get_data(\"..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv\")\n\nprint(\"Total Training images\", training_images.shape)\nprint(\"Total Training labels\",training_labels.shape)\nprint(\"Total Testing images\",testing_images.shape)\nprint(\"Total Testing labels\",testing_labels.shape)","f447febf":"alphabets = 'abcdefghijklmnopqrstuvwxyz'\nmapping_letter = {}\n\nfor i,l in enumerate(alphabets):\n    mapping_letter[l] = i\nmapping_letter = {v:k for k,v in mapping_letter.items()}","e541a21e":"# Display some pictures of the dataset\nfig, axes = plt.subplots(nrows=4, ncols=6, figsize=(8, 8),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    img = training_images[i].reshape(28,28)\n    ax.imshow(img, cmap = 'gray')\n    title = mapping_letter[training_labels[i]]\n    ax.set_title(title, fontsize = 15)\nplt.tight_layout(pad=0.5)\nplt.show()","787d2ad2":"# Display the distribution of each letter\n\nvc = pd.Series(training_labels).value_counts()\nplt.figure(figsize=(20,5))\nsns.barplot(x = sorted(vc.index), y = vc, palette = \"rocket\")\nplt.title(\"Number of pictures of each category\", fontsize = 15)\nplt.xticks(fontsize = 15)\nplt.show()","c07a9066":"training_images = np.expand_dims(training_images, axis = 3)\ntesting_images = np.expand_dims(testing_images, axis = 3)\n\nprint(training_images.shape)\nprint(testing_images.shape)","0e71f391":"# Create an ImageDataGenerator and do Image Augmentation\n\ntrain_datagen = ImageDataGenerator(rescale = 1.0\/255.0,\n                                   height_shift_range=0.1,\n                                   width_shift_range=0.1,\n                                   zoom_range=0.1,\n                                   shear_range=0.1,\n                                   rotation_range=10,\n                                   fill_mode='nearest',\n                                   horizontal_flip=True)\n\n#Image Augmentation is not done on the testing data\n\nvalidation_datagen = ImageDataGenerator(rescale=1.0\/255)\n\ntrain_datagenerator = train_datagen.flow(training_images,\n                                         training_labels,\n                                         batch_size = 32)\n\nvalidation_datagenerator = validation_datagen.flow(testing_images,\n                                                   testing_labels, \n                                                   batch_size=32)\n","723e424c":"# Define a Callback class that stops training once accuracy reaches 99.8%\n\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.998):\n      print(\"\\nReached 99.8% accuracy so cancelling training!\")\n      self.model.stop_training = True","763c9d15":"# Define the model\n\nmodel = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape = (28,28,1)),\n                                    tf.keras.layers.MaxPool2D(2,2),\n                                    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n                                    tf.keras.layers.MaxPool2D(2,2),\n                                    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n                                    tf.keras.layers.MaxPool2D(2,2),\n                                    tf.keras.layers.Flatten(),\n                                    tf.keras.layers.Dense(1024, activation = 'relu'),\n                                    tf.keras.layers.Dropout(0.2),\n                                    tf.keras.layers.Dense(512, activation = 'relu'),\n                                    tf.keras.layers.Dropout(0.2),\n                                    tf.keras.layers.Dense(25, activation = 'softmax')])","e99dcae1":"model.summary()","c979dbe8":"# Compiling the Model. \nmodel.compile(loss = 'sparse_categorical_crossentropy',\n             optimizer = tf.keras.optimizers.Adam(),\n              metrics = ['accuracy'])","565c16e1":"learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience = 2, \n                                            verbose=1,factor=0.25, \n                                            min_lr=0.0001)","8b225a28":"# Train the Model\ncallbacks = myCallback()\nhistory = model.fit(train_datagenerator,\n                    validation_data = validation_datagenerator,\n                    steps_per_epoch = len(training_labels)\/\/32,\n                    epochs = 100,\n                    validation_steps = len(testing_labels)\/\/32,\n                    callbacks = [callbacks, learning_rate_reduction])","c274aaf7":"# Plot the chart for accuracy and loss on both training and validation\n\nimport matplotlib.pyplot as plt\nfig.set_size_inches(16,9)\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","44710c6d":"model.evaluate(testing_images, testing_labels, verbose=0)\n\n# model.save('sign_language.h5')","11141540":"tf.keras.utils.plot_model(model,\n                          to_file=\"model.png\",\n                          show_shapes=True,\n                          show_dtype=False,\n                          show_layer_names=True,\n                          rankdir=\"TB\",                          \n                          expand_nested=True,\n                          dpi=96)","2e20a3c4":"from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n# Predict the label of the test_images\npred = model.predict(testing_images)\npred = np.argmax(pred,axis=1)\n\n# Get the accuracy score\nacc = accuracy_score(testing_labels,pred)\n\n# Display the results\nprint(f'## {acc*100:.2f}% accuracy on the test set')","ba50aeea":"# Map the numbers into letters\ny_test_letters = [mapping_letter[x] for x in testing_labels]\npred_letters = [mapping_letter[x] for x in pred]\n\nprint(classification_report(y_test_letters, pred_letters))","afd70a1e":"# Display a confusion matrix\ncf_matrix = confusion_matrix(y_test_letters, pred_letters, normalize='true')\nplt.figure(figsize = (20,15))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test_letters)), yticklabels = sorted(set(y_test_letters)),cbar=False)\nplt.title('Normalized Confusion Matrix\\n', fontsize = 23)\nplt.xlabel(\"Predicted Classes\",fontsize=15)\nplt.ylabel(\"True Classes\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15,rotation=0)\nplt.show()","ca6eefe9":"correct = np.nonzero(pred == testing_labels)[0]\nplt.figure(figsize=(6, 6))\ni = 0\nfor c in correct[:9]:\n    plt.subplot(3,3,i+1)\n    plt.imshow(testing_images[c].reshape(28,28), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted:{}, Actual:{}\".format(pred_letters[c], y_test_letters[c]))\n    plt.tight_layout()\n    i += 1","8493245e":"Now lets define a callback for avoiding the excess training and stopping the training based on the predefined condition, in our case, we want training to stop once the **accuracy** is reached above **99%**.","012ed0f8":"<h1> 1. Importing important Libraries <\/h1>","99559ee2":"As you can see that there are 25 categories present in the labels, On careful observation we find that **Z** is not present in the dataset.\n\nNow we need to add another dimension in our images so that we can process it for the **ImageDataGenerator** and do the **Image Augmentation**\nRead more [here](https:\/\/keras.io\/api\/preprocessing\/image\/)","a8c6d08d":"<h1> 9. Plotiing the losses <\/h1>","16825170":"# Sign Language Classification Problem\n\nThe dataset format is patterned to match closely with the classic MNIST. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z. The training data (27,455 cases) and test data (7172 cases) are approximately half the size of the standard MNIST but otherwise similar with a header row of label, \n\npixel1,pixel2\u2026.pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255.\n","2c03fdc7":"<h1>3. EDA and Data Visualization <\/h1>","f4feaf60":"<h1> 6. Defining the model <\/h1>","280bc031":"We need to read the csv train and test inputs. Since we are training these as images, so we need to convert them to images and extract labels from it.\n\nThe 1st column of the csv has the label information and the rest are the image pixels.\nWe'll return the images and labels as numpy array.","5ccee47d":"<h1>11. Evaluating Model <\/h1>","016b34bc":"<h1> 4. Data Augmentation <\/h1> ","613ac5b9":"I have used 3 Conv2D and 3 MaxPooling2D and the dropout of 0.2","07510f62":"<h1> 8. Training Model <\/h1>","20688d61":"<h1> 0. List the Directory <\/h1>","f749e402":"<h1> 10. Visualise the model <\/h1>","181f0d08":"<h1>5.  Define a Callback <\/h1>","e25c91d7":"<h1> 2. Reading the dataset <\/h1>","f9c9518a":"<h1>7. Learning Rate modification <\/h1>","d62cd7f3":"<h1>12. Outputs sample<\/h1>"}}