{"cell_type":{"2d18a1c6":"code","b069777c":"code","c83c999d":"code","251a34b0":"code","8806613e":"code","d10258ef":"code","eebc8eee":"code","b2d72b66":"code","7a70b5c5":"code","a17db8b8":"code","08bd356d":"code","a09e6d9a":"code","c3f37ba2":"code","7330d605":"code","6a52791f":"code","c2f9d858":"markdown","08e7d599":"markdown","ce51c656":"markdown","c6f8088a":"markdown","cc7046a0":"markdown","1952c95a":"markdown","00313c30":"markdown","e6883ec1":"markdown","0cd6159d":"markdown","21d22a9d":"markdown","17f44ef3":"markdown","4a0ffba1":"markdown","f1af22c6":"markdown"},"source":{"2d18a1c6":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport random\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nfrom sklearn.metrics import confusion_matrix","b069777c":"my_transform = transforms.Compose([transforms.ToTensor()])\n\nmnist_train = torchvision.datasets.MNIST('data', train=True, download=True, transform = my_transform)\nmnist_test = torchvision.datasets.MNIST('data', train=False, download=True, transform = my_transform)","c83c999d":"sample = torchvision.datasets.MNIST('data', train=True, download=True)\n\nplt.figure(figsize = (16, 3))\nfor i,(image, label) in enumerate(sample):\n    if i>=16:\n        break\n    plt.subplot(2,8,i+1)\n    plt.imshow(image)","251a34b0":"class VanillaRNN(nn.Module):\n    def __init__(self, batch_size, input_size, hidden_size, output_size):\n        super(VanillaRNN, self).__init__()\n        self.batch_size  = batch_size\n        self.input_size  = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        \n        #rnn layer\n        self.rnn = nn.RNN(input_size, hidden_size)\n        \n        #fully connected layer\n        self.layer = nn.Linear(hidden_size, self.output_size)\n        \n    def forward(self, images, prints=False):\n        if prints: print(\"Original Shape of Image:\", images.shape)\n        \n        images = images.permute(1,0,2)\n        if prints: print(\"Permuted Image Shape:\", images.shape)\n        \n        # initialize hidden state with zeros\n        hidden_state = torch.zeros(1, self.batch_size, self.hidden_size)\n        if prints: print(\"Hidden Layer shape:\", hidden_state.shape)\n            \n        hidden_outputs, hidden_state = self.rnn(images, hidden_state)\n        \n        out = self.layer(hidden_state)\n        \n        if prints:\n            print(\"\\n\"+ '----hidden_outputs shape:', hidden_outputs.shape, '\\n' +\n                  '----final hidden state:', hidden_state.shape, '\\n' +\n                  '----out shape:', out.shape)\n        \n        # Reshaped out\n        out = out.view(-1, self.output_size)\n        if prints: print('Out Final Shape:', out.shape)\n        \n        return out","8806613e":"# ==== STATICS ====\nbatch_size = 64        # how many images to be trained in one iteration\ninput_size = 28        # image 28 by 28\nhidden_size = 150      # can be changed to any number: neurons\noutput_size = 10       # 10 different digits\n# =================","d10258ef":"train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64)\n\nimage_example , label_example = next(iter(train_loader))\n\nprint(\"Original Image shape:\",image_example.shape)\nimage_example = image_example.view(-1,28,28)\n\nprint(\"Changed image shape:\", image_example.shape)\nprint(\"Label shape:\", label_example.shape)\n\nmodel_example = VanillaRNN(batch_size, input_size, hidden_size, output_size)\nprint(\"VanillaRNN Model:\\n\",model_example,\"\\n\")\n\nout = model_example(image_example, prints=True)","eebc8eee":"def accuracy(out, actual_labels, batchSize):\n    predictions = out.max(dim=1)[1]\n    \n    correct = (predictions==actual_labels).sum().item()\n    accuracy = correct\/batch_size\n    \n    return accuracy","b2d72b66":"def train_network(model, train_data, test_data, batch_size=64,num_epochs=1, learning_rate=0.001):\n    print('Get data ready...')\n    # Create dataloader for training dataset - so we can train on multiple batches\n    # Shuffle after every epoch\n    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True, drop_last=True)\n    \n    # Create criterion and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    \n    \n    print('Training started...')\n    # Train the data multiple times\n    for epoch in range(num_epochs):\n        \n        # Save Train and Test Loss\n        train_loss = 0\n        train_acc = 0\n        \n        # Set model in training mode:\n        model.train()\n        \n        for k, (images, labels) in enumerate(train_loader):\n            \n            # Get rid of the channel\n            images = images.view(-1, 28, 28)\n            \n            # Create log probabilities\n            out = model(images)\n            # Clears the gradients from previous iteration\n            optimizer.zero_grad()\n            # Computes loss: how far is the prediction from the actual?\n            loss = criterion(out, labels)\n            # Computes gradients for neurons\n            loss.backward()\n            # Updates the weights\n            optimizer.step()\n            \n            # Save Loss & Accuracy after each iteration\n            train_loss += loss.item()\n            train_acc += accuracy(out, labels, batch_size)\n            \n        \n        # Print Average Train Loss & Accuracy after each epoch\n        print('TRAIN | Epoch: {}\/{} | Loss: {:.2f} | Accuracy: {:.2f}'.format(epoch+1, num_epochs, train_loss\/k, train_acc\/k))\n            \n            \n    print('Testing Started...')\n    # Save Test Accuracy\n    test_acc = 0\n    # Evaluation mode\n    model.eval()\n    \n    for k, (images, labels) in enumerate(test_loader):\n        # Get rid of the channel\n        images = images.view(-1, 28, 28)\n        \n        # Create logit predictions\n        out = model(images)\n        # Add Accuracy of this batch\n        test_acc += accuracy(out, labels, batch_size)\n        \n    # Print Final Test Accuracy\n    print('TEST | Average Accuracy per {} Loaders: {:.5f}'.format(k, test_acc\/k) )","7a70b5c5":"batch_size=64\ninput_size=28\nhidden_state=150\noutput_size=10\n\nmodel_rnn = VanillaRNN(batch_size, input_size, hidden_size, output_size)\n\ntrain_network(model_rnn, mnist_train, mnist_test, num_epochs=10)","a17db8b8":"class LSTM_Model(nn.Module):\n    def __init__(self, input_size,hidden_size, layer_size, output_size, bidirectional=True):\n        super(LSTM_Model,self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.layer_size = layer_size\n        self.output_size = output_size\n        self.bidirectional = bidirectional\n        \n        #Initialize LSTM model\n        self.lstm = nn.LSTM(input_size, hidden_size, layer_size, batch_first=True, bidirectional=bidirectional)\n        \n        # bidirectional\n        if bidirectional:\n            self.layer = nn.Linear(hidden_size*2,output_size)\n        else:\n            self.layer = nn.Linear(hidden_size, output_size)\n        \n        # FNN\n    def forward(self, images, prints=False):\n        if prints: print('images shape:', images.shape)\n        \n        # Set initial states\n        if self.bidirectional:\n            # Hidden state:\n            hidden_state = torch.zeros(self.layer_size*2, images.size(0), self.hidden_size)\n            # Cell state:\n            cell_state = torch.zeros(self.layer_size*2, images.size(0), self.hidden_size)\n        else:\n            # Hidden state:\n            hidden_state = torch.zeros(self.layer_size, images.size(0), self.hidden_size)\n            # Cell state:\n            cell_state = torch.zeros(self.layer_size, images.size(0), self.hidden_size)\n        if prints: print('hidden_state t0 shape:', hidden_state.shape, '\\n' +\n                         'cell_state t0 shape:', cell_state.shape)\n        \n        # LSTM:\n        output, (last_hidden_state, last_cell_state) = self.lstm(images, (hidden_state, cell_state))\n        if prints: print('LSTM: output shape:', output.shape, '\\n' +\n                         'LSTM: last_hidden_state shape:', last_hidden_state.shape, '\\n' +\n                         'LSTM: last_cell_state shape:', last_cell_state.shape)\n        # Reshape\n        output = output[:, -1, :]\n        if prints: print('output reshape:', output.shape)\n        \n        # FNN:\n        output = self.layer(output)\n        if prints: print('FNN: Final output shape:', output.shape)\n        \n        return output","08bd356d":"# parameters\nbatch_size  = 64\ninput_size  = 28\nhidden_size = 100\nlayer_size  = 2\noutput_size = 10","a09e6d9a":"images, labels = next(iter(train_loader))\n\nprint(\"Original Shape of image:\", images.shape)\n\n# Remove channel from shape\nimages = images.view(-1,28,28)\nprint(\"Reshaped images shape:\", images.shape)\n\nlstm_model = LSTM_Model(input_size, hidden_size, layer_size, output_size)\nprint(\"LSTM Model:\\n\")\nprint(lstm_model,\"\\n\")\n\nout = lstm_model(images, prints=True)","c3f37ba2":"batch_size = 64\ninput_size = 28\nhidden_size = 100  \nlayer_size = 2         \noutput_size = 10\n\n# Instantiate the model\n# We'll use TANH as our activation function\nlstm_model = LSTM_Model(input_size, hidden_size, layer_size, output_size)\n\n# ==== TRAIN ====\ntrain_network(lstm_model, mnist_train, mnist_test, num_epochs=10)","7330d605":"def show_confusion_matrix(model, test_data):\n    torch.no_grad()    # disable gradient computing\n    \n    model.eval()\n    pred, real = [],[]\n    \n    for image, label in test_data:\n        image = image.view(-1,28,28)\n        out = model(image)\n        \n        prediction = torch.max(out,dim=1)[1].item()\n        pred.append(prediction)\n        \n        real.append(label)\n        \n    return confusion_matrix(pred, real)","6a52791f":"plt.figure(figsize=(16,8))\nsns.heatmap(show_confusion_matrix(lstm_model,mnist_test),annot=True, cmap=\"icefire\", fmt = ',')\nplt.title(\"Confusion Matrix\")","c2f9d858":"# Confusion Matrix","08e7d599":"## **LSTMs** (Long Short Term Memory RNNs)","ce51c656":"# ***Digit Recognizer*** - Image Classification using Deep Learning","c6f8088a":"* Note- Checkout [This blog](https:\/\/towardsdatascience.com\/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21) which contains detailed explanation for better understanding of intiution behind long short term memory RNNs and GRUs.\n","cc7046a0":"<div class=\"alert alert_box alert-warning\">\nUPVOTE the notebook if you find it insightful!\n    \nSee you later:)\n<\/div>","1952c95a":"## Training Model..","00313c30":"I took help from [this notebook](https:\/\/www.kaggle.com\/andradaolteanu\/pytorch-rnns-and-lstms-explained-acc-0-99) in which concepts are explained flawlessly and efficiently!!","e6883ec1":"![Screenshot 2021-06-02 at 1.20.59 PM.png](attachment:f604c69f-dd77-4599-8f1f-7c3b55e935bd.png)","0cd6159d":"## Importing Modules","21d22a9d":"## Training Function...\ud83d\udeb4","17f44ef3":"## Creating Class for RNN Implementation","4a0ffba1":"# Visualize data","f1af22c6":"## Accuracy Function...\ud83c\udfaf"}}