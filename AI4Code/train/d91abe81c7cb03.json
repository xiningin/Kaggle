{"cell_type":{"2391095a":"code","717ad712":"code","3d4a758c":"code","222bd0f8":"code","cd43429d":"code","3a5b07c3":"code","9d6b822a":"code","8befbb84":"code","65d1bd74":"code","9d275d5d":"code","89327a96":"code","2b9bad99":"code","d7d5c46c":"code","8c33213c":"code","5580ae93":"code","dacfb9eb":"code","8a69d5b3":"code","0ce4ec36":"code","65517bbb":"code","8983d05d":"code","d348349e":"code","192d05c7":"code","706ee692":"code","8a1757dd":"code","47c55f23":"code","932c0693":"code","56050cf1":"code","1795ca5c":"code","9286c688":"code","936d5aef":"markdown","ccfded41":"markdown","81555902":"markdown","b59df263":"markdown","4e644cd0":"markdown","59135a56":"markdown","157c119c":"markdown","a75b5788":"markdown","b8999ab1":"markdown","182600e0":"markdown","0a4fd063":"markdown"},"source":{"2391095a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport sklearn\nfrom itertools import cycle\n\nplt.style.use(\"ggplot\")\ncolor_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\ncolor_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])","717ad712":"train = pd.read_parquet('..\/input\/medallion-monthly-test\/train.parquet')\ntest = pd.read_parquet('..\/input\/medallion-monthly-test\/test.parquet')\nss = pd.read_csv('..\/input\/medallion-monthly-test\/sample_submission.csv')","3d4a758c":"train.shape, test.shape, ss.shape","222bd0f8":"ss.head()","cd43429d":"# Some videos have zero views?\ntrain['hasZeroViews'] = train['view_count'] == 0\ntrain['hasZeroViews'].value_counts()\n\ntrain = train.query('not hasZeroViews').reset_index(drop=True).copy()","3a5b07c3":"# Category Mapping Names\ncategory_id_map = {\n    1: \"Film & Animation\",\n    2: \"Autos & Vehicles\",\n    10: \"Music\",\n    15: \"Pets & Animals\",\n    17: \"Sports\",\n    19: \"Travel & Events\",\n    20: \"Gaming\",\n    22: \"People & Blogs\",\n    23: \"Comedy\",\n    24: \"Entertainment\",\n    25: \"News & Politics\",\n    26: \"Howto & Style\",\n    27: \"Education\",\n    28: \"Science & Technology\",\n    29: \"Nonprofits & Activism\",\n}\n\ntrain['category_name'] = train['categoryId'].map(category_id_map)","9d6b822a":"# Log transform of view count by category\nfig, axs = plt.subplots(5, 3, figsize=(15, 15), sharex=True)\naxs = axs.flatten()\nplt_idx = 0\nfor cat_id, d in train.groupby('categoryId'):\n    title = f'{cat_id}: {category_id_map[cat_id]} - view count'\n    d['view_count'].apply(np.log1p) \\\n        .plot(kind='hist',\n              bins=100,\n              title=title,\n              ax=axs[plt_idx]\n             )\n    plt_idx += 1\nplt.tight_layout()\nplt.show()","8befbb84":"fig, axs = plt.subplots(5, 3, figsize=(15, 15), sharex=True)\naxs = axs.flatten()\nplt_idx = 0\nfor cat_id, d in train.groupby('categoryId'):\n    title = f'{cat_id}: {category_id_map[cat_id]} - Like count'\n    d['likes'].apply(np.log1p) \\\n        .plot(kind='hist',\n              bins=100,\n              title=title,\n              ax=axs[plt_idx],\n              color=color_pal[1]\n             )\n    plt_idx += 1\nplt.tight_layout()\nplt.show()","65d1bd74":"train['like_to_view_ratio'] = train['likes'] \/ (train['view_count'] + 1)","9d275d5d":"train['like_to_view_ratio'].max()","89327a96":"fig, axs = plt.subplots(5, 3, figsize=(15, 15), sharex=True)\naxs = axs.flatten()\nplt_idx = 0\nfor cat_id, d in train.groupby('categoryId'):\n    title = f'{cat_id}: {category_id_map[cat_id]} - Like to view ratio'\n    d['like_to_view_ratio'] \\\n        .plot(kind='hist',\n              bins=10,\n              title=title,\n              ax=axs[plt_idx],\n              color=color_pal[2]\n             )\n    plt_idx += 1\nplt.tight_layout()\nplt.show()","2b9bad99":"plt.style.use('ggplot')\ntrain.query('video_id == \"3C66w5Z0ixs\"') \\\n    .set_index('trending_date')['view_count'].plot()","d7d5c46c":"# Take average of categoryId in train\ncat_to_view = train.groupby(['categoryId'])['view_count'].mean() \\\n    .round().astype('int').to_dict()\n\n# Predicted View Count\ntest['view_count'] = test['categoryId'].map(cat_to_view)\n# Save Our Submission\ntest[ss.columns].to_csv('submission.csv', index=False)","8c33213c":"top_video = train['video_id'].value_counts().index[0]\ntop_video_title = train.query('video_id == @top_video')['title'].values[0]","5580ae93":"train['trending_date'] = pd.to_datetime(train['trending_date'])\nax = train.query('video_id == @top_video').set_index('trending_date')['view_count'] \\\n    .plot(figsize=(12, 5), title=top_video_title, style='.-')\nax.set_ylabel('Video View Count')\nplt.show()","dacfb9eb":"train['isTrain'] = True\ntest['isTrain'] = False\ntt = pd.concat([train, test])\n\ntrain_occurance = tt.query('isTrain').groupby('video_id').size().to_dict()\ntest_occurance = tt.query('isTrain == False').groupby('video_id').size().to_dict()\n\ntt['train_occurance'] = tt['video_id'].map(train_occurance).fillna(0).astype('int')\ntt['test_occurance'] = tt['video_id'].map(test_occurance).fillna(0).astype('int')\ntt['isOverlap'] = (tt['train_occurance'] > 0) & (tt['test_occurance'] > 0)","8a69d5b3":"tt.query('isTrain == False')['isOverlap'].value_counts()","0ce4ec36":"# JfVOs4VSpmA <--- Example Video that is in train and test\ntt.query('video_id == \"JfVOs4VSpmA\"').set_index('trending_date') \\\n    .groupby('isTrain')['view_count'] \\\n    .plot(title='Video in Train and test', figsize=(12, 5), style='.-')\nplt.legend()\nplt.show()","65517bbb":"train_max_view = tt.query('isOverlap and isTrain').groupby('video_id')['view_count'].max().to_dict()","8983d05d":"test['last_known_view_count'] = test['video_id'].map(train_max_view)","d348349e":"test.dropna(subset=['last_known_view_count']) \\\n    .plot(x='view_count', y='last_known_view_count', kind='scatter')","192d05c7":"# Post Process by imputing last known view count value\ntest['pp_view_count'] = test['last_known_view_count'] \\\n        .fillna(test['view_count']) \\\n    .astype('int')\n\ntest[['id','pp_view_count']] \\\n    .rename(columns={'pp_view_count':'view_count'}) \\\n    .to_csv('submission_pp_last_known.csv', index=False)","706ee692":"train['isTrain'] = True\ntest['isTrain'] = False\ntt = pd.concat([train, test])\n\ntrain_occurance = tt.query('isTrain').groupby('video_id').size().to_dict()\ntest_occurance = tt.query('isTrain == False').groupby('video_id').size().to_dict()\n\ntt['train_occurance'] = tt['video_id'].map(train_occurance).fillna(0).astype('int')\ntt['test_occurance'] = tt['video_id'].map(test_occurance).fillna(0).astype('int')\ntt['isOverlap'] = (tt['train_occurance'] > 0) & (tt['test_occurance'] > 0)","8a1757dd":"# JfVOs4VSpmA <--- Example Video that is in train and test\nax = tt.query('video_id == \"JfVOs4VSpmA\"').set_index('trending_date') \\\n    .groupby('isTrain')['view_count'] \\\n    .plot(title='Video in Train and test', figsize=(12, 5), style='.-')\n\ntt.query('video_id == \"JfVOs4VSpmA\"').set_index('trending_date') \\\n    ['pp_view_count'].plot(ax=ax[0], style='.-')\n\n\nplt.legend()\nplt.show()","47c55f23":"video_first_trend_date = tt.groupby('video_id')['trending_date'].min().to_dict()\ntt['first_trend_date'] = tt['video_id'].map(video_first_trend_date)","932c0693":"tt.query('isOverlap and isTrain == False').shape","56050cf1":"tt.query('isOverlap and isTrain == False and train_occurance >= 2') \\\n    ['train_occurance'].value_counts()","1795ca5c":"tt.query('isOverlap and isTrain == False and train_occurance >= 2')['video_id'].nunique()","9286c688":"overlap_videos_for_reg = tt.query('isOverlap and isTrain == False and train_occurance >= 2')['video_id'].unique()","936d5aef":"## Create Regression Model","ccfded41":"# Linear Model to Predict Overlapping videos","81555902":"# Visualize our Post Processed Predictions","b59df263":"# Look for Videos in both Training and Test!","4e644cd0":"# Sample Submission","59135a56":"# Baseline Submission\n\n- This submission basically takes the average view count for each category from the training set, and predicts that as the test set value.\n- Scores **2,495,658** on the Public Leaderboard","157c119c":"## Example Video Trending over Different Trending Dates","a75b5788":"# Welcome to the Competition!\nThis is a test of kaggle's new platform. This baseline should help you get started.\n\nIn this competition you are tasked with predicting the view count of youtube videos based on information about them.","b8999ab1":"# Training Data\n- `id` - Unique Identifier for the row (combindation of video id and trending date)                      \n- `video_id` - Unique Identifier for the video\n- `title` - Title of the Video\n- `publishedAt` - Datetime the video was published\n- `channelId` - Id of the channel hosting the video\n- `channelTitle` - Title of the channel hosting the video\n- `categoryId` - Video category\n- `trending_date ` - Date on which we are predicting the view count\n- `tags` - Video Tags\n- `view_count` - **TARGET COLUMN** Number of views as of the trending date\n- `likes` - Number of likes as of the trending date **Not provided in the test set**\n- `dislikes` - Number of dislikes **Not provided in the test set**\n- `comment_count` Comment Count **Not provided in the test set**\n- `thumbnail_link` Link to the thumbnail of the video.\n- `comments_disabled` True\/False if comments are disabled.\n- `ratings_disabled` True\/False if ratings are disabled.\n- `description` Video description\n","182600e0":"# EDA of Training Data and Target","0a4fd063":"# Training and Test Video Overlap"}}