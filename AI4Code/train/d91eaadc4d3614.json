{"cell_type":{"6482410b":"code","03daeacf":"code","63439226":"code","0486ea49":"code","6a84a23b":"code","a2c51f24":"code","5099b1b2":"code","13aa0240":"code","bebf31a1":"code","e9fe2ec7":"code","7a50b337":"code","b909cc1f":"code","3dc2836e":"code","76caee14":"code","c422077c":"code","43707cfd":"code","f6146927":"code","2b001919":"code","f664e68c":"code","8f85be5e":"code","4ae0373b":"code","bec63d5f":"code","a729ac41":"code","762df1c5":"code","3ead5625":"code","b45fb436":"code","555c5d05":"code","eca71901":"code","8f4ef361":"code","e4dd673b":"code","cdd5b0c0":"code","0f3c611c":"code","192b63de":"code","bc13d8b8":"code","ffb6bcd7":"code","13e0217c":"code","3380dd83":"code","10ae213a":"code","8f2d7d82":"markdown"},"source":{"6482410b":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\n!cp -r ..\/input\/nfl-health-and-safety-helmet-assignment .\/\n\n\n!pip install adamp\n!pip install timm\n!pip install -q imutils","03daeacf":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\nCFG = {\n    'fold_num': 5,\n    'seed': 125,\n    'img_size': 224, \n    'train_bs': 128,\n    'valid_bs': 128,\n    'weight_decay':1e-6,\n    'model_arch': 'gluon_seresnext50_32x4d', \n    'epochs': 12,\n    'lr': 0.0003,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'accelerator': 'TPU', \n    'num_classes': 275,\n    'grad_clip': 0.001\n}","63439226":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\nif CFG['accelerator']=='TPU':\n    !curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n    !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n    import torch\n    import torch_xla\n    import torch_xla.core.xla_model as xm\n    import torch_xla.debug.metrics as met\n    import torch_xla.distributed.parallel_loader as pl\n    import torch_xla.distributed.xla_multiprocessing as xmp\n    import torch_xla.utils.utils as xu\n    import os\n    os.environ[\"XLA_USE_BF16\"] = \"1\"\n    os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\"\n    device = xm.xla_device()\n    \nif CFG['accelerator']=='GPU':\n    import torch\n    device = torch.device('cuda:0')\n    torch.backends.cudnn.benchmark = True\n    print(torch.cuda.is_available())","0486ea49":"from glob import glob\nimport joblib\nimport sklearn\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom skimage import io\n\nfrom datetime import datetime\n#import torchvision\n#from torchvision import transforms\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n#from torchvision.utils import make_grid \nfrom torch import nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport os\nfrom os.path import join\nfrom os import listdir, rmdir\nfrom shutil import move\nimport random\nfrom operator import itemgetter\nimport copy\nimport time\nimport timm\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport pydicom\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.cluster.vq import kmeans,whiten\nfrom scipy.stats import zscore\nfrom operator import itemgetter\n\nimport optuna\nfrom optuna.trial import TrialState\nimport shutil\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nimport imutils\nimport gc","6a84a23b":"from fastai.vision.all import *\nimport albumentations\n\n#Code by ilovescience https:\/\/www.kaggle.com\/tanlikesmath\/cassava-classification-eda-fastai-starter\/notebook\n\nset_seed(999,reproducible=True)","a2c51f24":"dataset_path = Path('..\/input\/nfl-health-and-safety-helmet-assignment')\nos.listdir(dataset_path)","5099b1b2":"train = pd.read_csv(dataset_path\/'image_labels.csv')\ntrain.head()","13aa0240":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\n#le = LabelEncoder()\n\n#all_data = pd.read_csv('.\/nfl-health-and-safety-helmet-assignment\/image_labels.csv')\n#all_data = all_data.rename(columns={'filepaths':'image', 'labels':'label'})\n\n#train = all_data[all_data['data set'] != 'test'].loc[:, ['image', 'label']]#, 'labels']]\n#train['image'] = train.image_id.apply(lambda x: '\/'.join(x.split('\\\\')[-3:]))\n#train = train.reset_index(drop=True)\n\n#test = all_data[all_data['data set'] == 'test'].loc[:, ['image', 'label']]#, 'labels']]\n#test['image'] = test.image_id.apply(lambda x: '\/'.join(x.split('\\\\')[-3:]))\n#test = test.reset_index(drop=True)\n\n#display(train)\n#display(test)\n\n#I don't know what is all data \"data set\", Hence I commented it.","bebf31a1":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\nfig = go.Figure(\n    data=[ go.Bar(x=train['label'].value_counts().index, \n            y=train['label'].value_counts().values,\n            text=train['label'].value_counts().values,\n            textposition='auto',name='Count',\n           marker_color='indianred')],\n    layout_title_text=\"Class distribution\"\n)\nfig.show()","e9fe2ec7":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\nfor idx in tqdm(train.index):\n    img_name = train.loc[idx,'image']\n    #reading the image and converting BGR color space to RGB\n    img = cv2.cvtColor(cv2.imread('.\/nfl-health-and-safety-helmet-assignment\/images\/'+img_name), cv2.COLOR_BGR2RGB)\n    \n    #normalize the image in the range [0,1]\n    norm_image = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    \n    width,height,depth = img.shape\n    \n    #adding new column to the tabel with width height and aspect ratio for every image\n    train.loc[idx,'width'] = width\n    train.loc[idx,'height'] = height\n    train.loc[idx,'Aspect Ratio'] = width\/height\n    \n    #calculate mean and standart deviation for each image\n    train.loc[idx,'Mean'] = img.mean()\n    train.loc[idx,'SD'] = img.std()\n    \n    #calculate mean and standart deviation for each normalized image\n    train.loc[idx,'Normalized_Mean'] = norm_image.mean()\n    train.loc[idx,'Normalized_SD'] = norm_image.std()\ntrain","7a50b337":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\nfig =  make_subplots(rows=2,cols=1,subplot_titles=['Original Image', 'Normalized Image'])\ncolors = ['rgb({}, {}, {})'.format(random.randint(0,255), random.randint(0,255), random.randint(0,255)) for iter in range(len(train['label'].unique()))]\nfor idx,class_name in enumerate(train['label'].unique()):\n    #scatter plot between mean and variance of the images for every disease\n    fig.add_trace(go.Scatter(x=train[train['label'] == class_name]['Mean'],\n                             y=train[train['label'] == class_name]['SD'],\n                            mode = 'markers',name=class_name, marker_color=colors[idx]),1,1)\n    \n    #scatter plot between mean and variance of the normalized images for every disease\n    fig.add_trace(go.Scatter(x=train[train['label'] == class_name]['Normalized_Mean'],\n                             y=train[train['label'] == class_name]['Normalized_SD'],\n                            mode = 'markers',name=class_name, marker_color=colors[idx], showlegend=False),2,1)\n#x-axis and y axis title\nfig.update_xaxes(title_text=\"Mean\", row=1, col=1)\nfig.update_yaxes(title_text=\"Standard Deviation\", row=1, col=1)\n\nfig.update_xaxes(title_text=\"Mean\", row=2, col=1)\nfig.update_yaxes(title_text=\"Standard Deviation\", row=2, col=1)\nfig.show()","b909cc1f":"input_path = '.\/nfl-health-and-safety-helmet-assignment\/images\/'\nfrom scipy.cluster.vq import kmeans,whiten\nfrom scipy.stats import zscore","3dc2836e":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\nfig = make_subplots(rows=2,cols=1,\n                    subplot_titles=['Normalized Mean','Normalized Standard Deviation'],\n                    shared_xaxes=True)\ncolors = ['rgb({}, {}, {})'.format(random.randint(0,255), random.randint(0,255), random.randint(0,255)) for iter in range(len(train['label'].unique()))]\nfor idx,class_name in enumerate(train['label'].unique()):\n    fig.add_trace(go.Box(y=train[train['label'] == class_name]['Normalized_Mean'],\n                        name=class_name,showlegend=False,\n                        marker_color=colors[idx]),1,1)\n    fig.add_trace(go.Box(y=train[train['label'] == class_name]['Normalized_SD'],\n                        name=class_name,showlegend=False,\n                        marker_color=colors[idx]),2,1)\nfig.update_layout(title='Outlier Detection - Box Plot')\nfig.show()","76caee14":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\ndef calculate_fences_new(array):\n    upper_fence = array.describe()['75%']+1.5*(array.describe()['75%']-array.describe()['25%'])\n    lower_fence = array.describe()['25%']-1.5*(array.describe()['75%']-array.describe()['25%'])\n    return lower_fence, upper_fence","c422077c":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\noutliers = set()\n\nfor species in train['label'].unique():\n    images  = train[train['label'] ==  label]\n    \n    data_for_fences_mean = train[train['label']==label].loc[:, 'Normalized_Mean']\n    data_for_fences_sd = train[train['label']==label].loc[:, 'Normalized_SD']\n    \n    outliers_mean = images[images['Normalized_Mean'].between(calculate_fences_new(data_for_fences_mean)[0],calculate_fences_new(data_for_fences_mean)[1],inclusive=True)]\n    outliers_mean = images[~images['image'].isin(outliers_mean['image'])]\n    \n    outliers_st = images[images['Normalized_SD'].between(calculate_fences_new(data_for_fences_sd)[0],calculate_fences_new(data_for_fences_sd)[1],inclusive=True)]\n    outliers_st = images[~images['image'].isin(outliers_st['image'])]\n    \n    delete_mean = set(input_path+outliers_mean['image'].astype(str).values)\n    delete_st= input_path+outliers_st['image'].astype(str).values\n    outliers = outliers.union(delete_mean)\n    outliers = outliers.union(delete_st)\n    \nprint(len(outliers))","43707cfd":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\nimgs = list(outliers)\n\ngridimg = []        \nfor idx,img_name in enumerate(np.random.choice(imgs,25,replace=False)):\n    np_image = mpimg.imread(img_name)\n    gridimg.append(np_image)\n\nfig = plt.figure(figsize=(25, 25))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(5, 5),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 label_mode=\"1\")\n\nfor ax, im in zip(grid, gridimg):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n    ax.axis('off')\n\nplt.show()","f6146927":"for images in outliers:\n    os.remove(images)\n    train = train.drop(train[train['image']=='\/'.join(images.split('\/')[-3:])].index)","2b001919":"train","f664e68c":"#Code by  Georgii Sirotenko  https:\/\/www.kaggle.com\/georgiisirotenko\/pytorch-fish-outliers-handling-test-100\n\ndef init_logger(log_file='.\/'+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()","8f85be5e":"def get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb","4ae0373b":"def rand_bbox(size, lam):\n    W = size[0]\n    H = size[1]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.int(W * cut_rat)\n    cut_h = np.int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w \/\/ 2, 0, W)\n    bby1 = np.clip(cy - cut_h \/\/ 2, 0, H)\n    bbx2 = np.clip(cx + cut_w \/\/ 2, 0, W)\n    bby2 = np.clip(cy + cut_h \/\/ 2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, df, data_root, \n                 transforms=None, \n                 output_label=True, \n                 one_hot_label=False,\n                 do_fmix=False, \n                 fmix_params={\n                     'alpha': 1., \n                     'decay_power': 3., \n                     'shape': (CFG['img_size'], CFG['img_size']),\n                     'max_soft': True, \n                     'reformulate': False\n                 },\n                 do_cutmix=False,\n                 cutmix_params={\n                     'alpha': 1,\n                 }\n                ):\n        \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.do_fmix = do_fmix\n        self.fmix_params = fmix_params\n        self.do_cutmix = do_cutmix\n        self.cutmix_params = cutmix_params\n        \n        self.output_label = output_label\n        self.one_hot_label = one_hot_label\n        \n        if output_label == True:\n            self.species = self.df['label'].values\n            \n            if one_hot_label is True:\n                self.species = np.eye(self.df['label'].max()+1)[self.label]\n            \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.species[index]\n          \n        img  = get_img(\"{}\/{}\".format(self.data_root, self.df.loc[index]['image']))\n\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        if self.do_fmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n            with torch.no_grad():\n                \n                lam = np.clip(np.random.beta(self.fmix_params['alpha'], self.fmix_params['alpha']),0.6,0.7)\n                \n                # Make mask, get mean \/ std\n                mask = make_low_freq_image(self.fmix_params['decay_power'], self.fmix_params['shape'])\n                mask = binarise_mask(mask, lam, self.fmix_params['shape'], self.fmix_params['max_soft'])\n    \n                fmix_ix = np.random.choice(self.df.index, size=1)[0]\n                fmix_img  = get_img(\"{}\/{}\".format(self.data_root, self.df.iloc[fmix_ix]['image']))\n\n                if self.transforms:\n                    fmix_img = self.transforms(image=fmix_img)['image']\n\n                mask_torch = torch.from_numpy(mask)\n                \n                # mix image\n                img = mask_torch*img+(1.-mask_torch)*fmix_img\n\n                # mix target\n                rate = mask.sum()\/CFG['img_size']\/CFG['img_size']\n                target = rate*target + (1.-rate)*self.labels[fmix_ix]\n        \n        if self.do_cutmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n            with torch.no_grad():\n                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n                cmix_img  = get_img(\"{}\/{}\".format(self.data_root, self.df.iloc[cmix_ix]['image']))\n                if self.transforms:\n                    cmix_img = self.transforms(image=cmix_img)['image']\n                    \n                lam = np.clip(np.random.beta(self.cutmix_params['alpha'], self.cutmix_params['alpha']),0.3,0.4)\n                bbx1, bby1, bbx2, bby2 = rand_bbox((CFG['img_size'], CFG['img_size']), lam)\n\n                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2, bby1:bby2]\n\n                rate = 1 - ((bbx2 - bbx1) * (bby2 - bby1) \/ (CFG['img_size'] * CFG['img_size']))\n                target = rate*target + (1.-rate)*self.labels[cmix_ix]\n        if self.output_label == True:\n            return img, target\n        else:\n            return img","bec63d5f":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,ImageCompression,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, \n    CenterCrop, Resize, RandomGamma, Posterize, GaussianBlur\n)\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_transforms(data):\n    \n    if data == 'train':\n        return Compose([\n            #RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            CLAHE(p=0.5),\n#             Posterize(p=0.5),\n#             GaussianBlur(p=0.5),\n#             ImageCompression(p=0.5),\n            #HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\n    elif data == 'val':\n        return Compose([\n            #CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            #Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","a729ac41":"#Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(15,12))\n    i = 0\n    for row in range(5):\n         for col in range(5):\n                img = mpimg.imread(input_path+samples[i][0][0])\n                ax[row][col].imshow(img)\n                ax[row][col].axis('off')\n                ax[row][col].set_title(samples[i][1], fontsize=15)\n                i+=1\n  \nexample = train\n\nrand_samples = [] \nfor _ in range(25): \n    sample = random.sample(list(train['image']), 1)\n    rand_samples.append([sample, train[train['image']==sample[0]]['label'].values[0]])\nrand_samples[0]\nplot_samples(rand_samples)\nplt.suptitle('Samples', fontsize=30)\nplt.tight_layout()\nplt.show()","762df1c5":"#le = LabelEncoder()\n#sets = {'train':train, 'test':test}\n#for x in ['train', 'test']:\n    #sets[x]['label'] = le.fit_transform(sets[x].label.values)","3ead5625":"def prepare_dataloader(df, trn_idx, val_idx, data_root='.\/nfl-health-and-safety-helmet-assignment\/images'):\n    \n    \n\n    train_ = df.reset_index().loc[trn_idx,:].reset_index(drop=True)\n    valid_ = df.reset_index().loc[val_idx,:].reset_index(drop=True)\n        \n    train_ds = CustomDataset(train_, data_root, transforms=get_transforms(data='train'), output_label=True, one_hot_label=False, do_fmix=False, do_cutmix=False)\n    valid_ds = CustomDataset(valid_, data_root, transforms=get_transforms(data='val'), output_label=True)\n    \n    if CFG['accelerator']=='TPU':\n        \n        train_sampler = torch.utils.data.distributed.DistributedSampler(\n            train_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n\n        valid_sampler = torch.utils.data.distributed.DistributedSampler(\n            valid_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n    \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            shuffle=False,\n            sampler=train_sampler,\n            num_workers=CFG['num_workers'],\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            sampler=valid_sampler,\n            pin_memory=True,\n    )\n        \n    if CFG['accelerator']=='GPU':\n        \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            shuffle=True,        \n            num_workers=CFG['num_workers']\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=True\n    )\n    \n    \n    return train_loader, val_loader, len(train_ds), len(valid_ds)","b45fb436":"from torch import autograd\n\ndef train_one_epoch(loader, epoch, model, optimizer, criterion, device, gradient_clipping=False):\n   \n   LOGGER.info('--------------------------------------------------------------')\n   LOGGER.info('Epoch: {}\/{}'.format(epoch+1, CFG['epochs']))\n   model.train()\n  \n   running_loss = 0.\n   running_corrects = 0.\n\n   pbar = tqdm(enumerate(loader), total=len(loader))\n   for step, (imgs, targets) in pbar:\n      imgs, targets = imgs.to(device).float(), targets.to(device).long()\n      if CFG['accelerator']=='GPU':\n        with autocast():\n            output = model(imgs)\n            loss = criterion(output, targets)\n            loss = loss \/ CFG['accum_iter']\n        scaler.scale(loss).backward()\n            \n            \n      if CFG['accelerator']=='TPU':   \n        \n        output = model(imgs)\n        gc.collect()\n        loss = criterion(output, targets)\n        loss = loss \/ CFG['accum_iter']\n        loss.backward()\n      \n      if gradient_clipping:\n        timm.utils.agc.adaptive_clip_grad(model.parameters(), clip_factor=CFG['grad_clip'], eps=1e-3, norm_type=2.0)\n        \n      _, pred = output.max(dim=1)\n      running_corrects += torch.sum(pred == targets.data)\n      running_loss += loss.item()*imgs.size(0)\n            \n      pbar.set_description(f'train | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}')\n      if ((step + 1) % CFG['accum_iter'] == 0) or ((step + 1) == len(loader)):\n            \n            if CFG['accelerator']=='GPU':\n                scaler.step(optimizer)\n                scaler.update()\n                \n            if CFG['accelerator']=='TPU':\n                xm.optimizer_step(optimizer)\n                \n            optimizer.zero_grad()\n   return running_corrects, running_loss","555c5d05":"def valid_one_epoch(loader,epoch, model, device, criterion):\n    model.eval()\n    \n    running_loss = 0.\n    running_corrects = 0.\n    \n    pbar = tqdm(enumerate(loader), total=len(loader))\n    for step, (imgs, targets) in pbar:\n       imgs, targets = imgs.to(device).float(), targets.to(device).long()\n       with torch.no_grad():\n             output = model(imgs)\n             gc.collect()\n             _, pred = output.max(dim=1)\n             loss = criterion(output, targets)\n       running_corrects += torch.sum(pred == targets.data)\n       running_loss += loss.item()*imgs.size(0)\n       gc.collect()\n    \n       pbar.set_description(f'val | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}')\n                \n    return running_corrects, running_loss","eca71901":"class CustomDataset(Dataset):\n    def __init__(self, df, data_root, \n                 transforms=None, \n                 output_label=True, \n                 one_hot_label=False):\n        \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        \n        self.output_label = output_label\n        self.one_hot_label = one_hot_label\n        \n        if output_label == True:\n            self.labels = self.df['label'].values\n            #print(self.labels)\n            \n            if one_hot_label is True:\n                self.labels = np.eye(self.df['label'].max()+1)[self.labels]\n                #print(self.labels)\n            \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.labels[index]\n          \n        img  = get_img(\"{}\".format(self.df.loc[index]['image']))\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        if self.output_label == True:\n            return img, target\n        else:\n            return img","8f4ef361":"def get_transforms(data):\n    \n    if data == 'train':\n        return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\n    elif data == 'val':\n        return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","e4dd673b":"# Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(15,12))\n    i = 0\n    for row in range(5):\n         for col in range(5):\n                img = mpimg.imread(samples[i][0][0])\n                ax[row][col].imshow(img)\n                ax[row][col].axis('off')\n                ax[row][col].set_title(samples[i][1], fontsize=15)\n                i+=1\n  \nexample = all_data\n\nrand_samples = [] \nfor _ in range(25): \n#     rand_samples.append([random.sample([os.path.join(input_path+'\/'+str(classes), str(filename)) for filename in os.listdir(input_path)], 1), classes]) \n    sample = random.sample(list(train['image']), 1)\n    rand_samples.append([sample, train[train['image']==sample[0]]['label'].values[0]])\nrand_samples[0]\nplot_samples(rand_samples)\nplt.suptitle('Samples', fontsize=30)\nplt.show()","cdd5b0c0":"le = LabelEncoder()\nsets = {'train':train, 'test':test}\nfor x in ['train', 'test']:\n    sets[x]['label'] = le.fit_transform(sets[x].label.values)","0f3c611c":"def prepare_dataloader(df, trn_idx, val_idx, data_root='.\/nfl-health-and-safety-helmet-assignment'):\n\n    train_ = df.reset_index().loc[trn_idx,:].reset_index(drop=True)\n    valid_ = df.reset_index().loc[val_idx,:].reset_index(drop=True)\n        \n    train_ds = CustomDataset(train_, data_root, transforms=get_transforms(data='train'), output_label=True, one_hot_label=False)\n    valid_ds = CustomDataset(valid_, data_root, transforms=get_transforms(data='val'), output_label=True)\n    \n    if CFG['accelerator']=='TPU':\n        \n        train_sampler = torch.utils.data.distributed.DistributedSampler(\n            train_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n\n        valid_sampler = torch.utils.data.distributed.DistributedSampler(\n            valid_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n    \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            sampler=train_sampler,\n            num_workers=CFG['num_workers'],\n        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            sampler=valid_sampler,\n            pin_memory=True,\n    )\n        \n    if CFG['accelerator']=='GPU':\n        \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            shuffle=True,        \n            num_workers=CFG['num_workers']\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=True\n    )\n    \n    \n    return train_loader, val_loader, len(train_ds), len(valid_ds)","192b63de":"from torch import autograd\n\ndef train_one_epoch(loader, epoch, model, optimizer, criterion, gradient_clipping=False):\n   \n   LOGGER.info('--------------------------------------------------------------')\n   LOGGER.info('Epoch: {}\/{}'.format(epoch+1, CFG['epochs']))\n    \n   model.train()\n\n   running_loss = 0.\n   running_corrects = 0.\n    \n   pbar = tqdm(enumerate(loader), total=len(loader))\n   for step, (imgs, targets) in pbar:\n        \n      imgs, targets = imgs.to(device).float(), targets.to(device).long()\n      if CFG['accelerator']=='GPU':\n        with autocast():\n            output = model(imgs)\n            loss = criterion(output, targets)\n            loss = loss \/ CFG['accum_iter']\n        scaler.scale(loss).backward()\n            \n            \n      if CFG['accelerator']=='TPU':\n        output = model(imgs)\n        gc.collect()\n        loss = criterion(output, targets)\n        loss = loss \/ CFG['accum_iter']\n        loss.backward()\n      \n      if gradient_clipping:\n        timm.utils.agc.adaptive_clip_grad(model.parameters(), clip_factor=CFG['grad_clip'], eps=1e-3, norm_type=2.0)\n        \n      _, pred = output.max(dim=1)\n      running_corrects += torch.sum(pred == targets.data)\n      running_loss += loss.item()*imgs.size(0)\n    \n      if loss.item()==float(\"NaN\"):\n            xm.master_print('0'*50)\n            break\n            \n      description = f'train | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}'\n      pbar.set_description(description)\n    \n      if ((step + 1) % CFG['accum_iter'] == 0) or ((step + 1) == len(loader)):\n            \n            if CFG['accelerator']=='GPU':\n                scaler.step(optimizer)\n                scaler.update()\n                \n            if CFG['accelerator']=='TPU':\n                xm.optimizer_step(optimizer)\n                \n            optimizer.zero_grad()\n   return running_corrects, running_loss","bc13d8b8":"def valid_one_epoch(loader,epoch, model, device, criterion):\n    model.eval()\n    \n    running_loss = 0.\n    running_corrects = 0.\n    \n    pbar = tqdm(enumerate(loader), total=len(loader))\n    for step, (imgs, targets) in pbar:\n       imgs, targets = imgs.to(device).float(), targets.to(device).long()\n       with torch.no_grad():\n             output = model(imgs)\n             gc.collect()\n             _, pred = output.max(dim=1)\n             loss = criterion(output, targets)\n       running_corrects += torch.sum(pred == targets.data)\n       running_loss += loss.item()*imgs.size(0)\n       gc.collect()\n    \n       description = f'val | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}'\n       pbar.set_description(description)\n                \n    return running_corrects, running_loss","ffb6bcd7":"def fit(seed, epochs, model, freeze, device, fold, train_loader, val_loader, criterion, gradient_clipping=False):\n  \n  if CFG['accelerator']=='TPU':\n          LOGGER.info('Creating a model {}...'.format(seed))\n          #device = xm.xla_device()\n          WRAPPED_MODEL = xmp.MpModelWrapper(model)\n          model = WRAPPED_MODEL.to(device)\n          #model.to(device)\n          if freeze==True:\n            if seed==1:\n              optimizer = torch.optim.Adam(model.head.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n            if seed==2 or seed==3:\n              optimizer = torch.optim.Adam(model.fc.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n            if seed==4 or seed==0:\n              optimizer = torch.optim.Adam(model.classifier.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n          if freeze==False:\n            optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        \n  if CFG['accelerator'] == 'GPU':\n    LOGGER.info('Creating a model...')\n    model.to(device)\n    if freeze==True:\n        if seed==1:\n            optimizer = torch.optim.Adam(model.head.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        if seed==2 or seed==3:\n            optimizer = torch.optim.Adam(model.fc.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        if seed==4 or seed==0:\n            optimizer = torch.optim.Adam(model.classifier.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])           \n    if freeze==False:\n       optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n    \n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  \n  if CFG['accelerator']=='TPU':\n     if freeze==True:\n                                         \n        for fase in ['CLASSIFIER TRAINING', 'ALL NET TRAINING']:\n                                         \n            if fase=='ALL NET TRAINING':             \n               model.load_state_dict(best_model)\n               for param in model.parameters():\n                   param.requires_grad=True\n               optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']* xm.xrt_world_size()\/10, betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])  \n               scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)     \n                                         \n            for epoch in range(epochs):\n                                         \n                #train\n                para_loader = pl.ParallelLoader(train_loader, [device])\n                running_corrects, running_loss = train_one_epoch(para_loader.per_device_loader(device), epoch, model, optimizer, criterion, gradient_clipping)\n                epoch_loss = running_loss \/ train_len\n                epoch_acc = running_corrects\/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                \n                #val\n                para_loader = pl.ParallelLoader(val_loader, [device])\n                running_corrects, running_loss = valid_one_epoch(para_loader.per_device_loader(device), epoch, model, device, criterion)\n                epoch_loss = running_loss \/ val_len\n                epoch_acc = running_corrects\/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss)\n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                   \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n            time_elapsed = time.time() - since\n            LOGGER.info('{} TIME {}m {}s'.format(fase, time_elapsed\/\/60, time_elapsed%60))\n            LOGGER.info('=='*31)\n                                         \n     if freeze==False:\n        for epoch in range(epochs):\n                                         \n                #train\n                para_loader = pl.ParallelLoader(train_loader, [device])\n                running_corrects, running_loss = train_one_epoch(para_loader.per_device_loader(device), epoch, model, optimizer, criterion, gradient_clipping)\n                epoch_loss = running_loss \/ train_len\n                epoch_acc = running_corrects\/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                \n                \n                #val\n                para_loader = pl.ParallelLoader(val_loader, [device])\n                running_corrects, running_loss = valid_one_epoch(para_loader.per_device_loader(device), epoch, model, device, criterion)\n                epoch_loss = running_loss \/ val_len\n                epoch_acc = running_corrects\/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n    \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n        time_elapsed = time.time() - since\n        LOGGER.info('FOLD_{} TRAINING TIME {}m {}s'.format(fold+1, time_elapsed\/\/60, time_elapsed%60))\n        LOGGER.info('=='*31) \n                                         \n                                         \n  if CFG['accelerator']=='GPU':\n     if freeze==True:\n                                         \n        for fase in ['CLASSIFIER TRAINING', 'ALL NET TRAINING']:\n                                         \n            if fase=='ALL NET TRAINING':             \n               model.load_state_dict(best_model)\n               for param in model.parameters():\n                   param.requires_grad=True\n               optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']\/10, betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])  \n               scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)     \n                                         \n            for epoch in range(CFG['epochs']):\n                                         \n                #train                           \n                running_corrects, running_loss = train_one_epoch(train_loader, epoch, model, optimizer, criterion, gradient_clipping)\n                epoch_loss = running_loss \/ train_len\n                epoch_acc = running_corrects\/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                \n                #val\n                running_corrects, running_loss = valid_one_epoch(val_loader, epoch, model, device, criterion)\n                epoch_loss = running_loss \/ val_len\n                epoch_acc = running_corrects\/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n            time_elapsed = time.time() - since\n            LOGGER.info('{} TIME {}m {}s'.format(fase, time_elapsed\/\/60, time_elapsed%60))\n            LOGGER.info('=='*31)\n                                         \n     if freeze == False :\n        for epoch in range(epochs):\n                \n                #train                           \n                running_corrects, running_loss = train_one_epoch(train_loader, epoch, model, optimizer, criterion, gradient_clipping)\n                epoch_loss = running_loss \/ train_len\n                epoch_acc = running_corrects\/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                \n                #val                             \n                running_corrects, running_loss = valid_one_epoch(val_loader, epoch, model, device, criterion)\n                epoch_loss = running_loss \/ val_len\n                epoch_acc = running_corrects\/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n        time_elapsed = time.time() - since\n        LOGGER.info('FOLD_{} TRAINING TIME {}m {}s'.format(fold+1, time_elapsed\/\/60, time_elapsed%60))\n        LOGGER.info('=='*31) \n                                         \n  if CFG['accelerator']=='TPU':\n     xm.save(best_model,'{}_fold_{}.pth'.format(CFG['model_arch'], fold+1))\n  if CFG['accelerator']=='GPU':\n     torch.save(best_model,'{}_fold_{}.pth'.format(CFG['model_arch'], fold+1))\n  \n  LOGGER.info('Prediction Saved! \\n')","13e0217c":"if __name__ == '__main__':\n    \n    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n    \n    fold_best_acc = []\n    \n    all_losses = {f'fold_{x+1}':[[],[]] for x in range(CFG['fold_num'])}\n    all_accuracies = {f'fold_{x+1}':[[],[]] for x in range(CFG['fold_num'])}\n    \n    for fold, (trn_idx, val_idx) in enumerate(folds):\n        \n        #we'll train fold 0 first\n        if fold > 0:\n            break \n            \n        LOGGER.info('\\n\\n')\n        LOGGER.info(f'========== fold: {fold+1} training ==========')\n        LOGGER.info('Accelerator: {}'.format(CFG['accelerator']))\n        LOGGER.info(f'Device: {device}')\n            \n        train_loader, val_loader, train_len, val_len = prepare_dataloader(train, trn_idx, val_idx, data_root='.\/nfl-health-and-safety-helmet-assignment')\n        model = timm.create_model(CFG['model_arch'], pretrained=True, num_classes=CFG['num_classes'])\n        if CFG['accelerator']=='GPU':\n            model = nn.DataParallel(model).to(device)\n        scaler = GradScaler()\n        criterion = nn.CrossEntropyLoss().to(device)\n        #criterion = TaylorCrossEntropyLossV1().to(device)\n        fit(seed=1, epochs = CFG['epochs'], model=model, freeze=False, device=device, fold=fold, train_loader=train_loader, val_loader=val_loader, criterion=criterion, gradient_clipping=False)\n\n        LOGGER.info(f'========== fold: {fold+1} result ==========')\n        LOGGER.info('Score: {}'.format(max(all_accuracies['fold_{}'.format(fold+1)][1])))\n        fold_best_acc.append(max(all_accuracies['fold_{}'.format(fold+1)][1]))   \n        \n        del model, train_loader, val_loader#, scaler\n        torch.cuda.empty_cache()\n    # CV result\n    LOGGER.info(f\"========== CV ==========\")\n    LOGGER.info(f'Score: {max(fold_best_acc)}')","3380dd83":"model = timm.create_model('gluon_resnet50_v1b', pretrained=False, num_classes=CFG['num_classes'])\nif CFG['accelerator']=='GPU':\n    model = nn.DataParallel(model).to(device)\nstate = torch.load('.\/gluon_resnet50_v1b_fold_1.pth')\nmodel.load_state_dict(state);\nmodel.to(device);","10ae213a":"test","8f2d7d82":"#After 3:30 hs, many cells deleted, eyes burning. I gave up my TPU project. "}}