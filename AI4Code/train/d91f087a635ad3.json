{"cell_type":{"f19ae02e":"code","56092083":"code","1d1be55d":"code","51439f47":"code","aea3f1bb":"code","0550523f":"code","ea4b30c9":"code","a799d39a":"code","c3789250":"code","5fbe3e4f":"code","011b79ae":"code","047131cd":"code","49a1853f":"code","1ccc8691":"code","068e9dd9":"code","68d6c8d9":"code","3375b901":"code","ff73dfd3":"code","8365be5d":"code","deb11929":"code","bf986003":"code","41d41ef8":"code","ed2b3534":"code","c2d60f07":"code","7968c5be":"code","46a534c3":"code","3e821432":"code","435bb6fe":"code","be3fb808":"code","6af751ce":"code","55106496":"code","ad7180f5":"code","fb9cf6d8":"code","eab4edca":"code","1b172a1d":"code","94d7ab59":"code","be239612":"code","109eb8fe":"code","8d2e93a3":"code","a6fc15f2":"code","3fbfea86":"code","062e584a":"code","51795257":"code","c2c74c1e":"code","d7764a84":"code","d3673f2a":"code","6ea3d7f3":"code","bd0552a7":"code","f47e9243":"code","309565d6":"code","9a13f266":"code","7913cbf3":"code","4d9314eb":"code","47a9aa91":"code","15418234":"code","c1281706":"code","64e8e2d9":"code","1d635147":"code","55011a75":"code","51216a00":"code","df90edd4":"code","b9b2b3b2":"code","61ece9a0":"code","a7efa3df":"code","135967ff":"code","3ebed309":"code","542fb135":"code","a4cc2cfc":"code","dbfd8e31":"code","c80ad3c0":"code","299db0cd":"code","521526f7":"code","57dd642d":"code","69c9bba8":"code","dcc68d01":"code","84881270":"code","a30b15f0":"code","28a9d562":"code","23cccf31":"code","97ea9dbe":"code","b44ac723":"code","64e641e4":"code","9c44867d":"code","e867ead0":"markdown","8d4705dd":"markdown","195cc686":"markdown","46fbae3a":"markdown","15adcb98":"markdown","edb68c04":"markdown","42d83214":"markdown","c73e258d":"markdown","d5edcff5":"markdown","6ac37067":"markdown","f786fb33":"markdown","c7a04faf":"markdown","3a178f32":"markdown","3b1d4e5b":"markdown","04f97946":"markdown","69ed86cc":"markdown","29f09be1":"markdown","15751951":"markdown","77e0bd61":"markdown","4e364316":"markdown","3a3fb9dc":"markdown","8ea6ae81":"markdown","dc06d9ea":"markdown","206e6b75":"markdown","65b4ea4f":"markdown","5526eed6":"markdown","3d7e5cbb":"markdown"},"source":{"f19ae02e":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import TimeSeriesSplit\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nfrom hyperopt import fmin, tpe, hp, rand, Trials\n\nimport gc","56092083":"pd.set_option(\"display.max_columns\", None)","1d1be55d":"#\u30cf\u30f3\u30ba\u30aa\u30f3\u306e\u30b9\u30e0\u30fc\u30ba\u306a\u9032\u884c\u306e\u305f\u3081\u306b\u5168\u4f53\u306e20\u5206\u306e1\u3060\u3051\u8aad\u307f\u8fbc\u3080\u3053\u3068\u306b\u3057\u307e\u3059\u3002\n#\u5b9f\u969b\u306b\u8ab2\u984c\u3067\u30e2\u30c7\u30ea\u30f3\u30b0\u3059\u308b\u969b\u306b\u306f\"skiprows=lambda x: x%20!=0\"\u3092\u524a\u9664\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n#df_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0)\ndf_train = pd.read_csv('..\/input\/homework-for-students2\/train.csv', index_col=0, parse_dates=['issue_d', 'earliest_cr_line'])\ndf_test = pd.read_csv('..\/input\/homework-for-students2\/test.csv', index_col=0, parse_dates=['issue_d', 'earliest_cr_line'])","51439f47":"#\u3042\u3068\u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u5206\u5272\u7528\u306b\u30bd\u30fc\u30c8\ndf_train.sort_values('issue_d', inplace=True)","aea3f1bb":"# DataFrame\u306eshape\u3067\u884c\u6570\u3068\u5217\u6570\u3092\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\ndf_train.shape, df_test.shape","0550523f":"# \u5148\u982d5\u884c\u3092\u307f\u3066\u307f\u307e\u3059\u3002\ndf_train.head()","ea4b30c9":"df_test.head()","a799d39a":"df_train[df_train.loan_condition==1].loan_amnt.mean() # \u8cb8\u3057\u5012\u308c\u305f\u30ed\u30fc\u30f3\u306e\u5e73\u5747\u984d","c3789250":"# \u4e0a\u306e\u8cb8\u3057\u5012\u308c\u305f\u30ed\u30fc\u30f3\u306b\u5bfe\u3059\u308b\u3082\u306e\u3092\u53c2\u8003\u306b\u3001\u8cb8\u3057\u5012\u308c\u3066\u3044\u306a\u3044\u30ed\u30fc\u30f3\u306e\u5e73\u5747\u984d\u3092\u7b97\u51fa\u307f\u3066\u304f\u3060\u3055\u3044\u3002\ndf_train[df_train.loan_condition==0].loan_amnt.mean()","5fbe3e4f":"df_train.describe()","011b79ae":"df_test.describe()","047131cd":"f = 'loan_amnt'\n\nplt.figure(figsize=[7,7])\ndf_train[f].hist(density=True, alpha=0.5, bins=20)\n# test\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u53ef\u8996\u5316\u3092\u8a18\u5165\u3057\u3066\u307f\u307e\u3057\u3087\u3046\ndf_test[f].hist(density=True, alpha=0.5, bins=20)\nplt.xlabel(f)\nplt.ylabel('density')\nplt.show()","49a1853f":"f = 'purpose'\n\n# value_counts\u3092\u7528\u3044\u3066train\u306epurpose\u306b\u5bfe\u3057\u3066\u96c6\u8a08\u7d50\u679c\u3092\u307f\u3066\u307f\u307e\u3057\u3087\u3046\u3002\ndf_train[f].value_counts() \/ len(df_train)","1ccc8691":"# \u540c\u69d8\u306btest\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\ndf_test[f].value_counts() \/ len(df_test)","068e9dd9":"# \u5916\u90e8\u30c7\u30fc\u30bf(statelatlong)\u3092\u8ffd\u52a0\ndf_statelatlong = pd.read_csv('..\/input\/homework-for-students2\/statelatlong.csv')\ndf_statelatlong","68d6c8d9":"df_train = pd.merge(df_train, df_statelatlong, left_on='addr_state', right_on='State', how='left')\ndf_test = pd.merge(df_test, df_statelatlong, left_on='addr_state', right_on='State', how='left')\ndf_train.drop(['State', 'City'], axis=1, inplace=True)\ndf_test.drop(['State', 'City'], axis=1, inplace=True)","3375b901":"df_train","ff73dfd3":"# \u5916\u90e8\u30c7\u30fc\u30bf(SPI)\u8ffd\u52a0\ndf_spi = pd.read_csv('..\/input\/homework-for-students2\/spi.csv', parse_dates=['date'])\ndf_spi","8365be5d":"df_spi['issue_d_year'] = df_spi.date.dt.year\ndf_spi['issue_d_month'] = df_spi.date.dt.month","deb11929":"df_temp = df_spi.groupby(['issue_d_year', 'issue_d_month'], as_index=False)['close'].mean()\ndf_temp.head()","bf986003":"# \u300cissue_d\u300d\u304b\u3089\u5e74\u30fb\u6708\u30c7\u30fc\u30bf\u3092\u751f\u6210\n\ndf_train['issue_d_year'] = df_train.issue_d.dt.year\ndf_test['issue_d_year'] = df_test.issue_d.dt.year\n\ndf_train['issue_d_month'] = df_train.issue_d.dt.month\ndf_test['issue_d_month'] = df_test.issue_d.dt.month","41d41ef8":"df_train = df_train.merge(df_temp, on=['issue_d_year', 'issue_d_month'], how='left')\ndf_test = df_test.merge(df_temp, on=['issue_d_year', 'issue_d_month'], how='left')","ed2b3534":"df_train","c2d60f07":"df_test","7968c5be":"# \u5916\u90e8\u30c7\u30fc\u30bf(US_GDP_by_State)\u8ffd\u52a0\ndf_US_GDP_by_State = pd.read_csv('..\/input\/homework-for-students2\/US_GDP_by_State.csv')\ndf_US_GDP_by_State","46a534c3":"#df_train = pd.merge(df_train, df_US_GDP_by_State, left_on=['City', 'issue_d_year'], right_on=['State', 'year'], how='left')\n#df_test = pd.merge(df_test, df_US_GDP_by_State, left_on=['City', 'issue_d_year'], right_on=['State', 'year'], how='left')\n#df_train","3e821432":"#plt.figure(figsize=[7,7])\n#plt.hist(df_train['State & Local Spending'], density=True, bins=20)\n#plt.figure(figsize=[7,7])\n#plt.hist(df_train['Gross State Product'], density=True, bins=20)\n#plt.figure(figsize=[7,7])\n#plt.hist(df_train['Real State Growth %'], density=True, bins=20)\n#plt.figure(figsize=[7,7])\n#plt.hist(df_train['Population (million)'], density=True, bins=20)","435bb6fe":"## earliest_cr_line\u306f\u3001\u6708\u90e8\u5206\u3092\u8ffd\u52a0\u3059\u308b\n\n#df_train['earliest_cr_line_year'] = df_train.earliest_cr_line.dt.year\n#df_test['earliest_cr_line_year'] = df_test.earliest_cr_line.dt.year\ndf_train['earliest_cr_line_month'] = df_train.earliest_cr_line.dt.month\ndf_test['earliest_cr_line_month'] = df_test.earliest_cr_line.dt.month","be3fb808":"df_train.columns","6af751ce":"# \u300cearliest_cr_line\u300d\u3068\u300cissue_d\u300d\u306e\u6708\u6570\u5dee\u3092\u53d6\u308b\u3002\ndf_train['issue_d_earliest_cr_line_diff'] = (df_train.issue_d.dt.year * 12 + df_train.issue_d.dt.month) - (df_train.earliest_cr_line.dt.year * 12 + df_train.earliest_cr_line.dt.month)\ndf_test['issue_d_earliest_cr_line_diff'] = (df_test.issue_d.dt.year * 12 + df_test.issue_d.dt.month) - (df_test.earliest_cr_line.dt.year * 12 + df_test.earliest_cr_line.dt.month)\n\n\n## \u904e\u53bb\u306e\u5168\u30a2\u30ab\u30a6\u30f3\u30c8\u6570\u306e\u3046\u3061\u73fe\u884c\u6ede\u7d0d\u30a2\u30ab\u30a6\u30f3\u30c8\u6570\u306e\u6bd4\u7387\n#df_train['acc_now_delinq_total_acc_retio'] = df_train.acc_now_delinq \/ df_train.total_acc * 100\n#df_test['acc_now_delinq_total_acc_retio'] = df_test.acc_now_delinq \/ df_test.total_acc * 100\n\n## \u958b\u3044\u3066\u3044\u308b\u30a2\u30ab\u30a6\u30f3\u30c8\u6570\u306e\u3046\u3061\u73fe\u884c\u6ede\u7d0d\u30a2\u30ab\u30a6\u30f3\u30c8\u6570\u306e\u6bd4\u7387\n#df_train['acc_now_delinq_open_acc_retio'] = df_train.acc_now_delinq \/ df_train.open_acc * 100\n#df_test['acc_now_delinq_open_acc_retio'] = df_test.acc_now_delinq \/ df_test.open_acc * 100\n\n# \u5168\u53e3\u5ea7\u6b8b\u9ad8\u306e\u3046\u3061\u306e\u30ed\u30fc\u30f3\u984d\u306e\u6bd4\u7387\n#df_train['loan_amnt_tot_cur_bal_ratio'] = df_train.loan_amnt \/ df_train.tot_cur_bal * 100\n#df_test['loan_amnt_tot_cur_bal_ratio'] = df_test.loan_amnt \/ df_test.tot_cur_bal * 100\n\n## \u5168\u53e3\u5ea7\u6b8b\u9ad8\u306e\u3046\u3061\u306e\u672a\u6255\u3044\u306e\u7dcf\u56de\u53ce\u984d\u306e\u6bd4\u7387\n#df_train['tot_coll_amt_tot_cur_bal_ratio'] = df_train.tot_coll_amt \/ df_train.tot_cur_bal * 100\n#df_test['tot_coll_amt_tot_cur_bal_ratio'] = df_test.tot_coll_amt \/ df_test.tot_cur_bal * 100\n\n\n\n# 1%\u70b9\u4ee5\u4e0b\u306e\u5024\u306f1%\u70b9\u306b\u300199%\u70b9\u4ee5\u4e0a\u306e\u5024\u306f99%\u70b9\u306bclippinng\u3057\u3066\u5bfe\u6570\u5909\u63db\n\n#num_cols_target_cl_lg = ['acc_now_delinq_total_acc_retio', 'acc_now_delinq_open_acc_retio', 'loan_amnt_tot_cur_bal_ratio', 'tot_coll_amt_tot_cur_bal_ratio']\n#num_cols_target_cl_lg = ['loan_amnt_tot_cur_bal_ratio']\n#num_cols_target_cl_lg = ['loan_amnt_tot_cur_bal_ratio', 'tot_coll_amt_tot_cur_bal_ratio']\n\n#p01_cl_lg = df_train[num_cols_target_cl_lg].quantile(0.01)\n#p99_cl_lg = df_train[num_cols_target_cl_lg].quantile(0.99)\n\n#plt.figure(figsize=[7,7])\n#df_train[num_cols_target_cl_lg].clip(p01_cl_lg, p99_cl_lg, axis=1).apply(np.log1p).hist(bins=20)\n#df_test[num_cols_target_cl_lg].clip(p01_cl_lg, p99_cl_lg, axis=1).apply(np.log1p).hist(bins=20)\n#df_train[num_cols_target_cl_lg].apply(np.log1p).hist(bins=20)\n#df_test[num_cols_target_cl_lg].apply(np.log1p).hist(bins=20)","55106496":"# NULL\u30d5\u30e9\u30b0\u3092\u751f\u6210\n\n#df_train['emp_title_null'] = df_train['emp_title'].apply(lambda x : 1 if not x else 0)\n#df_train['emp_length_null'] = df_train['emp_length'].apply(lambda x : 1 if x == 'n\/a' else 0)\n#df_train['annual_inc_null'] = df_train['annual_inc'].apply(lambda x : 1 if not x else 0)\n#df_train['title_null'] = df_train['title'].apply(lambda x : 1 if not x else 0)\n#df_train['dti_null'] = df_train['dti'].apply(lambda x : 1 if not x else 0)\n#df_train['delinq_2yrs_null'] = df_train['delinq_2yrs'].apply(lambda x : 1 if not x else 0)\n#df_train['earliest_cr_line_null'] = df_train['earliest_cr_line'].apply(lambda x : 1 if not x else 0)\n#df_train['inq_last_6mths_null'] = df_train['inq_last_6mths'].apply(lambda x : 1 if not x else 0)\n#df_train['mths_since_last_delinq_null'] = df_train['mths_since_last_delinq'].apply(lambda x : 1 if not x else 0)\n#df_train['mths_since_last_record_null'] = df_train['mths_since_last_record'].apply(lambda x : 1 if not x else 0)\n#df_train['open_acc_null'] = df_train['open_acc'].apply(lambda x : 1 if not x else 0)\n#df_train['pub_rec_null'] = df_train['pub_rec'].apply(lambda x : 1 if not x else 0)\n#df_train['revol_util_null'] = df_train['revol_util'].apply(lambda x : 1 if not x else 0)\n#df_train['total_acc_null'] = df_train['total_acc'].apply(lambda x : 1 if not x else 0)\n#df_train['collections_12_mths_ex_med_null'] = df_train['collections_12_mths_ex_med'].apply(lambda x : 1 if not x else 0)\n#df_train['mths_since_last_major_derog_null'] = df_train['mths_since_last_major_derog'].apply(lambda x : 1 if not x else 0)\n#df_train['acc_now_delinq_null'] = df_train['acc_now_delinq'].apply(lambda x : 1 if not x else 0)\n#df_train['tot_coll_amt_null'] = df_train['tot_coll_amt'].apply(lambda x : 1 if not x else 0)\n#df_train['tot_cur_bal_null'] = df_train['tot_cur_bal'].apply(lambda x : 1 if not x else 0)\n\n#df_test['emp_title_null'] = df_test['emp_title'].apply(lambda x : 1 if not x else 0)\n#df_test['emp_length_null'] = df_test['emp_length'].apply(lambda x : 1 if x == 'n\/a' else 0)\n#df_test['annual_inc_null'] = df_test['annual_inc'].apply(lambda x : 1 if not x else 0)\n#df_test['title_null'] = df_test['title'].apply(lambda x : 1 if not x else 0)\n#df_test['dti_null'] = df_test['dti'].apply(lambda x : 1 if not x else 0)\n#df_test['delinq_2yrs_null'] = df_test['delinq_2yrs'].apply(lambda x : 1 if not x else 0)\n#df_test['earliest_cr_line_null'] = df_test['earliest_cr_line'].apply(lambda x : 1 if not x else 0)\n#df_test['inq_last_6mths_null'] = df_test['inq_last_6mths'].apply(lambda x : 1 if not x else 0)\n#df_test['mths_since_last_delinq_null'] = df_test['mths_since_last_delinq'].apply(lambda x : 1 if not x else 0)\n#df_test['mths_since_last_record_null'] = df_test['mths_since_last_record'].apply(lambda x : 1 if not x else 0)\n#df_test['open_acc_null'] = df_test['open_acc'].apply(lambda x : 1 if not x else 0)\n#df_test['pub_rec_null'] = df_test['pub_rec'].apply(lambda x : 1 if not x else 0)\n#df_test['revol_util_null'] = df_test['revol_util'].apply(lambda x : 1 if not x else 0)\n#df_test['total_acc_null'] = df_test['total_acc'].apply(lambda x : 1 if not x else 0)\n#df_test['collections_12_mths_ex_med_null'] = df_test['collections_12_mths_ex_med'].apply(lambda x : 1 if not x else 0)\n#df_test['mths_since_last_major_derog_null'] = df_test['mths_since_last_major_derog'].apply(lambda x : 1 if not x else 0)\n#df_test['acc_now_delinq_null'] = df_test['acc_now_delinq'].apply(lambda x : 1 if not x else 0)\n#df_test['tot_coll_amt_null'] = df_test['tot_coll_amt'].apply(lambda x : 1 if not x else 0)\n#df_test['tot_cur_bal_null'] = df_test['tot_cur_bal'].apply(lambda x : 1 if not x else 0)","ad7180f5":"df_train.columns","fb9cf6d8":"# \u4e0d\u8981\u306a\u7279\u5fb4\u91cf\u3092\u524a\u9664\n#df_train = df_train.drop(['earliest_cr_line', 'issue_d', 'State_x', 'City', 'issue_d_year', 'State_y', 'year'], axis=1)\n#df_test = df_test.drop(['earliest_cr_line', 'issue_d', 'State_x', 'City', 'issue_d_year', 'State_y', 'year'], axis=1)\n#df_train = df_train.drop(['earliest_cr_line', 'issue_d', 'State', 'City'], axis=1)\n#df_test = df_test.drop(['earliest_cr_line', 'issue_d', 'State', 'City'], axis=1)\ndf_train = df_train.drop(['earliest_cr_line', 'issue_d'], axis=1)\ndf_test = df_test.drop(['earliest_cr_line', 'issue_d'], axis=1)","eab4edca":"#X\u3068y\u306b\u5206\u5272\n\ny_train = df_train['loan_condition']\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = df_test","1b172a1d":"# clipping\u3057\u3066\u307f\u308b\n# \u5217\u3054\u3068\u306b\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e1%\u70b9\u300199%\u70b9\u3092\u8a08\u7b97\nnum_cols = ['annual_inc', 'dti', 'revol_bal', 'tot_coll_amt', 'tot_cur_bal']\n\np01 = X_train[num_cols].quantile(0.01)\np99 = X_train[num_cols].quantile(0.99)\n\n# 1%\u70b9\u4ee5\u4e0b\u306e\u5024\u306f1%\u70b9\u306b\u300199%\u70b9\u4ee5\u4e0a\u306e\u5024\u306f99%\u70b9\u306bclippinng\u3059\u308b\nplt.figure(figsize=[7,7])\nX_train[num_cols].hist(bins=20)\nX_test[num_cols].hist(bins=20)\nX_train[num_cols].clip(p01, p99, axis=1).hist(bins=20)\nX_test[num_cols].clip(p01, p99, axis=1).hist(bins=20)\nX_train[num_cols].clip(p01, p99, axis=1).apply(np.log1p).hist(bins=20)\nX_test[num_cols].clip(p01, p99, axis=1).apply(np.log1p).hist(bins=20)","94d7ab59":"num_cols_target_cl = ['dti']\nnum_cols_target_cl_lg = ['annual_inc', 'revol_bal', 'tot_cur_bal']\n\np01_cl = X_train[num_cols_target_cl].quantile(0.01)\np99_cl = X_train[num_cols_target_cl].quantile(0.99)\np01_cl_lg = X_train[num_cols_target_cl_lg].quantile(0.01)\np99_cl_lg = X_train[num_cols_target_cl_lg].quantile(0.99)\n\n# 1%\u70b9\u4ee5\u4e0b\u306e\u5024\u306f1%\u70b9\u306b\u300199%\u70b9\u4ee5\u4e0a\u306e\u5024\u306f99%\u70b9\u306bclippinng\u3059\u308b\nplt.figure(figsize=[7,7])\nX_train[num_cols_target_cl].clip(p01_cl, p99_cl, axis=1).hist(bins=20)\nX_test[num_cols_target_cl].clip(p01_cl, p99_cl, axis=1).hist(bins=20)\nX_train[num_cols_target_cl_lg].clip(p01_cl_lg, p99_cl_lg, axis=1).apply(np.log1p).hist(bins=20)\nX_test[num_cols_target_cl_lg].clip(p01_cl_lg, p99_cl_lg, axis=1).apply(np.log1p).hist(bins=20)\n\n#X_train[num_cols] = X_train[num_cols].clip(p01, p99, axis=1)\n#X_test[num_cols] = X_test[num_cols].clip(p01, p99, axis=1)","be239612":"# tot_coll_amt\u306fYeo-Johnson\u5909\u63db\n\n#from sklearn.preprocessing import PowerTransformer\n\n#col = ['tot_coll_amt']\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u57fa\u3065\u3044\u3066\u8907\u6570\u30ab\u30e9\u30e0\u306eYeo-Johnson\u5909\u63db\u3092\u5b9a\u7fa9\n#pt = PowerTransformer(method='yeo-johnson')\n#pt.fit(X_train[col])\n\n# \u5909\u63db\u5f8c\u306e\u30c7\u30fc\u30bf\u3067\u5404\u5217\u3092\u7f6e\u63db\n#X_train_yj_temp= pt.transform(X_train[col])\n#X_test_yj_temp = pt.transform(X_test[col])\n#X_train_yj_temp","109eb8fe":"#X_train['tot_coll_amt'] = X_train_yj_temp\n#X_test['tot_coll_amt'] = X_test_yj_temp\n#plt.figure(figsize=[7,7])\n#X_train['tot_coll_amt'].hist(bins=20)","8d2e93a3":"# dtype\u304cobject\u306e\u30ab\u30e9\u30e0\u540d\u3068\u30e6\u30cb\u30fc\u30af\u6570\u3092\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\ncats = []\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \n        print(col, X_train[col].nunique())","a6fc15f2":"X_train['emp_title'].head(10) # \u30ab\u30c6\u30b4\u30ea\u3088\u308a\u30c6\u30ad\u30b9\u30c8\u3068\u3057\u3066\u6271\u3063\u305f\u307b\u3046\u304c\u826f\u3044\u304b\u3082\u3057\u308c\u306a\u3044","3fbfea86":"# title\u306f\u30c6\u30ad\u30b9\u30c8\u3068\u3057\u3066\u6271\u3046\u304b\uff1f\nX_train.groupby(['purpose', 'title'], as_index=False).size()\n","062e584a":"#sub_grade_values = X_train['sub_grade'].drop_duplicates().sort_values()\n#sub_grade_label = list(range(1, len(sub_grade_values) + 1))\n\n#sub_grade_dict = {}\n#sub_grade_dict.update(zip(sub_grade_values, sub_grade_label))\n#sub_grade_dict","51795257":"target = 'loan_condition'\nt_encoding_col = ['grade', 'sub_grade', 'emp_length', 'home_ownership', 'purpose', 'addr_state', 'initial_list_status', 'application_type', 'earliest_cr_line_month', 'issue_d_month']\n#t_encoding_col = ['emp_length', 'home_ownership', 'purpose', 'addr_state', 'initial_list_status', 'application_type', 'earliest_cr_line_month', 'issue_d_month']\n\nfor i, t_col in enumerate(t_encoding_col):\n\n    X_temp = pd.concat([X_train, y_train], axis=1)\n\n    # X_test\u306fX_train\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    summary = X_temp.groupby([t_col])[target].mean()\n    enc_test = X_test[t_col].map(summary) \n\n\n    # X_train\u306e\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092oof\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n\n    enc_train = Series(np.zeros(len(X_train)), index=X_train.index)\n\n    for i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n        X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix]\n        X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n\n        summary = X_train_.groupby([t_col])[target].mean()\n        enc_train.iloc[val_ix] = X_val[t_col].map(summary)\n        \n    X_train[t_col] = enc_train\n    X_test[t_col] = enc_test","c2c74c1e":"X_train['zip_code']","d7764a84":"enc_test","d3673f2a":"cats","6ea3d7f3":"TXT_train = X_train.emp_title.copy()\nTXT_test = X_test.emp_title.copy()\n\ncats.remove('emp_title')","bd0552a7":"TXT_train","f47e9243":"X_train.head()","309565d6":"X_test.head()","9a13f266":"#Ordinal\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u5bfe\u8c61\u5916\u306e\u7279\u5fb4\u91cf\u3092\u9664\u5916\u3059\u308b\n# \u203b\u6700\u7d42\u7684\u306btitle\u3001zip_code\u306e\u307f\n\ncats.remove('grade')\ncats.remove('sub_grade')\ncats.remove('emp_length')\ncats.remove('home_ownership')\ncats.remove('purpose')\ncats.remove('addr_state')\ncats.remove('initial_list_status')\ncats.remove('application_type')\n#cats.remove('zip_code')\ncats","7913cbf3":"encoder = OrdinalEncoder(cols=cats)\nencoder","4d9314eb":"X_train[cats] = encoder.fit_transform(X_train[cats])\nX_test[cats] = encoder.transform(X_test[cats])","47a9aa91":"X_train.head()","15418234":"X_test.head()","c1281706":"## emp_length\u3092\u9806\u5e8f\u5c3a\u5ea6\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\n#emp_length_mapping = {'< 1 year': 0, '1 year': 1, '2 years': 2, '3 years': 3, '4 years': 4, '5 years': 5, '6 years': 6, '7 years': 7, '8 years': 8, '9 years': 9, '10+ years': 10, 'n\/a': np.nan}\n#X_train['emp_length'] = X_train['emp_length'].map(emp_length_mapping)\n#X_test['emp_length'] = X_test['emp_length'].map(emp_length_mapping)\n#X_train['emp_length']","64e8e2d9":"## grade\u3092\u9806\u5e8f\u5c3a\u5ea6\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\n#grade_mapping = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\n#X_train['grade'] = X_train['grade'].map(grade_mapping)\n#X_test['grade'] = X_test['grade'].map(grade_mapping)\n#X_train['grade']","1d635147":"## sub_grade\u3092\u9806\u5e8f\u5c3a\u5ea6\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\n\n##sub_grade_mapping = {'A': '1', 'B': '2', 'C': '3', 'D': '4', 'E': '5', 'F': '6', 'G':'7'}\n\n#sub_grade_values = X_train['sub_grade'].drop_duplicates().sort_values()\n#sub_grade_label = list(range(1, len(sub_grade_values) + 1))\n\n#sub_grade_mapping = {}\n#sub_grade_mapping.update(zip(sub_grade_values, sub_grade_label))\n\n#X_train['sub_grade'] = X_train['sub_grade'].map(sub_grade_mapping)\n#X_test['sub_grade'] = X_test['sub_grade'].map(sub_grade_mapping)","55011a75":"# \u4ee5\u4e0b\u3092\u53c2\u8003\u306b\u81ea\u5206\u3067\u66f8\u3044\u3066\u307f\u307e\u3057\u3087\u3046 \nX_train.drop(['emp_title'], axis=1, inplace=True)\nX_test.drop(['emp_title'], axis=1, inplace=True)\n\n#X_train.fillna(X_train.median(), inplace=True)\n#X_test.fillna(X_train.median(), inplace=True)\n\n# https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.drop.html\n# https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.fillna.html","51216a00":"# NLTK\u304b\u3089\u82f1\u8a9e\u306estop words\u3092\u8aad\u307f\u8fbc\u3093\u3067\u30ea\u30b9\u30c8\u304b\u3089\u9664\u5916\u3059\u308b\n#import nltk\nfrom nltk.corpus import stopwords\nstops = stopwords.words(\"english\")","df90edd4":"TXT_train = TXT_train.fillna('NULL')\nTXT_test = TXT_test.fillna('NULL')","b9b2b3b2":"TXT_train_array = []\nfor col in TXT_train.values:\n    TXT_train_array.append(col)\n\nTXT_test_array = []\nfor col in TXT_test.values:\n    TXT_test_array.append(col)","61ece9a0":"from nltk.stem.porter import PorterStemmer as PS\nps = PS()\nwords_stem_train = [' '.join([ps.stem(w) for w in s.split(' ')]) for s in TXT_train_array]\nwords_stem_test = [' '.join([ps.stem(w) for w in s.split(' ')]) for s in TXT_test_array]","a7efa3df":"col_name =['emp_title']\nTXT_train = pd.DataFrame(words_stem_train, columns=col_name)\nTXT_test = pd.DataFrame(words_stem_test, columns=col_name)","135967ff":"#tfidf = TfidfVectorizer(max_features=1000, use_idf=True)\ntfidf = TfidfVectorizer(max_features=100, stop_words=stops)\nTXT_train_2 = tfidf.fit_transform(TXT_train.emp_title)\nTXT_test_2 = tfidf.transform(TXT_test.emp_title)","3ebed309":"del TXT_train, TXT_test\ngc.collect()","542fb135":"TXT_train_2","a4cc2cfc":"TXT_train_3 = pd.DataFrame(TXT_train_2.toarray(), columns=tfidf.get_feature_names())\nTXT_test_3 = pd.DataFrame(TXT_test_2.toarray(), columns=tfidf.get_feature_names())","dbfd8e31":"del TXT_train_2, TXT_test_2\ngc.collect()","c80ad3c0":"TXT_train_3","299db0cd":"TXT_train_3['key'] = list(range(len(TXT_train_3.index)))\nTXT_test_3['key'] = list(range(len(TXT_test_3.index)))\nX_train['key'] = list(range(len(X_train.index)))\nX_test['key'] = list(range(len(X_test.index)))","521526f7":"TXT_train_3","57dd642d":"X_train = pd.merge(X_train, TXT_train_3, how='left', on='key')\nX_test = pd.merge(X_test, TXT_test_3, how='left', on='key')\ndel TXT_train_3, TXT_test_3\ngc.collect()\n\nX_train.drop(['key'], axis=1, inplace=True)\nX_test.drop(['key'], axis=1, inplace=True)","69c9bba8":"#X_train.drop(['title'], axis=1, inplace=True)\n#X_test.drop(['title'], axis=1, inplace=True)\nX_train.drop(['title', 'zip_code'], axis=1, inplace=True)\nX_test.drop(['title', 'zip_code'], axis=1, inplace=True)","dcc68d01":"scores = []\n\ntss = TimeSeriesSplit(n_splits=3)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(tss.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    #clf = GradientBoostingClassifier()\n    clf = LGBMClassifier()\n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))\n    \nprint(np.mean(scores))\nprint(scores)","84881270":"X_train_sp = sp.sparse.csr_matrix(X_train.values)\nX_test_sp = sp.sparse.csr_matrix(X_test.values)\nX_train.drop(['issue_d_year'], axis=1, inplace=True)\nX_test.drop(['issue_d_year'], axis=1, inplace=True)","a30b15f0":"# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\u3002\u5c64\u5316\u62bd\u51fa\u3067\u826f\u3044\u304b\u306f\u5225\u9014\u3088\u304f\u8003\u3048\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    #clf = GradientBoostingClassifier()\n    clf = LGBMClassifier()\n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","28a9d562":"print(np.mean(scores))\nprint(scores)","23cccf31":"# \u5168\u30c7\u30fc\u30bf\u3067\u518d\u5b66\u7fd2\u3057\u3001test\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u3059\u308b\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict_proba(X_test)[:,1]","97ea9dbe":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\n# \u3053\u3061\u3089\u3082\u30b9\u30e0\u30fc\u30ba\u306a\u9032\u884c\u306e\u305f\u3081\u306b20\u5206\u306e\uff11\u306b\u9593\u5f15\u3044\u3066\u3044\u307e\u3059\u304c\u3001\u672c\u756a\u3067\u306f\"skiprows=lambda x: x%20!=0\"\u3092\u524a\u9664\u3057\u3066\u7528\u3044\u3066\u304f\u3060\u3055\u3044\u3002\nsubmission = pd.read_csv('..\/input\/homework-for-students2\/sample_submission.csv', index_col=0)\n\nsubmission.loan_condition = y_pred\nsubmission.to_csv('submission.csv')","b44ac723":"submission.head()","64e641e4":"# Feature Importance\nfti = clf.feature_importances_   \n\nprint('Feature Importances:')\nfor i, feat in enumerate(X_train):\n    print('\\t{0:20s} : {1:>.6f}'.format(feat, fti[i]))\n","9c44867d":"fig, ax = plt.subplots(figsize=(5, 8))\nlgb.plot_importance(clf, max_num_features=30, ax=ax, importance_type='gain')","e867ead0":"## \u30c6\u30ad\u30b9\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","8d4705dd":"## \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","195cc686":"### \u7279\u5fb4\u91cf\u9078\u629e","46fbae3a":"## dtype\u304cobject\u306e\u30ab\u30e9\u30e0\u3092\u5168\u3066Ordinal\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3057\u3066\u304a\u304d\u307e\u3059\u3002","15adcb98":"# \u76ee\u7684\u95a2\u6570\uff08\u6642\u7cfb\u5217\u5206\u5272\uff09\n\ndef objective_tss(space):\n    scores = []\n    \n    tss = TimeSeriesSplit(n_splits=3)\n    \n    for i, (train_ix, test_ix) in enumerate(tqdm(tss.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n        \n        clf = LGBMClassifier(n_estimators=9999, **space)\n        \n        clf.fit(X_train_, y_train_, early_stopping_rounds=20,\n                eval_metric='auc', eval_set=[(X_val, y_val)])\n        \n        y_pred = clf.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n        \n        del X_train_, y_train_, X_val, y_val, y_pred, score, clf\n        gc.collect()\n        \n    scores = np.array(scores)\n    print(scores.mean())\n    \n    return -scores.mean() # \u3053\u306e\u623b\u308a\u5024\u304c\u6700\u5c0f\u5316\u3055\u308c\u308b","edb68c04":"## \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\u3068\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f","42d83214":"# \u76ee\u7684\u95a2\u6570\uff08\u6642\u7cfb\u5217\u5206\u5272\uff09\ndef objective_ts(space):\n    scores = []\n    period_list = [2011, 2012, 2013, 2014, 2015]\n    y_train_tmp = df_train[['loan_condition', 'issue_d_year']]\n\n    for period in period_list:\n        X_train_tv = X_train[X_train.issue_d_year < period]\n        X_test_tv = X_train[X_train.issue_d_year == period]\n        y_train_tv = y_train_tmp[y_train_tmp.issue_d_year < period].loan_condition\n        y_test_tv = y_train_tmp[y_train_tmp.issue_d_year == period].loan_condition\n\n        X_train_, y_train_ = X_train_tv.values, y_train_tv.values\n        X_val, y_val = X_test_tv.values, y_test_tv.values\n        \n        clf = LGBMClassifier(n_estimators=9999, **space)\n        \n        clf.fit(X_train_, y_train_, early_stopping_rounds=20,\n                eval_metric='auc', eval_set=[(X_val, y_val)])\n        \n        y_pred = clf.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n        \n        del X_train_, y_train_, X_val, y_val, y_pred, score, clf\n        gc.collect()\n        \n    scores = np.array(scores)\n    print(scores.mean())\n    \n    return -scores.mean() # \u3053\u306e\u623b\u308a\u5024\u304c\u6700\u5c0f\u5316\u3055\u308c\u308b","c73e258d":"## X\u3068y\u306b\u5206\u5272","d5edcff5":"period_list = [2011, 2012, 2013, 2014, 2015]\ny_train_tmp = df_train[['loan_condition', 'issue_d_year']]\nscores = []\n\nfor period in period_list:\n    X_train_tv = X_train[X_train.issue_d_year < period]\n    X_test_tv = X_train[X_train.issue_d_year == period]\n    y_train_tv = y_train_tmp[y_train_tmp.issue_d_year < period].loan_condition\n    y_test_tv = y_train_tmp[y_train_tmp.issue_d_year == period].loan_condition\n\n    X_train_, y_train_ = X_train_tv.values, y_train_tv.values\n    X_val, y_val = X_test_tv.values, y_test_tv.values\n    clf = LGBMClassifier()\n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    print('CV Score of Fold_%d is %f' % (period, score))\n    \nprint(np.mean(scores))\nprint(scores)","6ac37067":"## \u30ed\u30fc\u30f3\u76ee\u7684\u306b\u3064\u3044\u3066\u3001value_counts\u3068\u898b\u3066\u307f\u308b","f786fb33":"# \u63a2\u7d22\u7d50\u679c\u306e\u683c\u7d0d\u5148\ntrials_skf = Trials()\n\n# \u6700\u9069\u5316\u5b9f\u884c\nprint('best_skf:start')\nbest_skf = fmin(fn=objective_skf,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=20,\n            trials=trials_skf,\n            rstate=np.random.RandomState(71)\n           )\n\n# \u7d50\u679c\u306e\u51fa\u529b\nclf_skf = LGBMClassifier(**best_skf)\nprint(clf_skf)","c7a04faf":"\u8b1b\u7fa9\u4e2d\u306b\u7528\u3044\u308b\u30b5\u30f3\u30d7\u30eb\u3067\u3059\u3002\u5185\u5bb9\u3068\u3057\u3066\u306f\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u30ec\u30d9\u30eb\u3067\u3042\u308a\u3001\u3053\u3053\u304b\u3089\u6539\u5584\u3057\u3066\u3044\u304f\u306e\u304c\u8b1b\u7fa9\u5f8c\u306e\u8ab2\u984c\u306b\u306a\u308a\u307e\u3059\u3002Discussion\u3067\u6d3b\u767a\u306a\u8b70\u8ad6\u3092\u901a\u3058\u3066\u30ec\u30d9\u30eb\u30a2\u30c3\u30d7\u3057\u3066\u3044\u304d\u307e\u3057\u3087\u3046\u3002","3a178f32":"## emp_title\u306f\u30c6\u30ad\u30b9\u30c8\u306b\u898b\u3048\u308b\u306e\u3067\u4e00\u65e6\u5206\u96e2","3b1d4e5b":"# \u63a2\u7d22\u7d50\u679c\u306e\u683c\u7d0d\u5148\ntrials_tss = Trials()\n\n# \u6700\u9069\u5316\u5b9f\u884c\nprint('best_ts:start')\nbest_tss = fmin(fn=objective_tss,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=100,\n            trials=trials_tss,\n            rstate=np.random.RandomState(71)\n           )\n\n# \u7d50\u679c\u306e\u51fa\u529b\nclf_tss = LGBMClassifier(**best_tss)\nprint(clf_tss)","04f97946":"## \u57fa\u672c\u7d71\u8a08\u91cf\u3092train\/test\u3067\u6bd4\u8f03","69ed86cc":"# AI Academy FE&Modeling\u30b5\u30f3\u30d7\u30ebNotebook","29f09be1":"## \u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u6700\u9069\u5316","15751951":"#clf = clf_ts\n#clf = clf_skf\nclf = clf_tss","77e0bd61":"# \u63a2\u7d22\u7d50\u679c\u306e\u683c\u7d0d\u5148\ntrials_ts = Trials()\n\n# \u6700\u9069\u5316\u5b9f\u884c\nprint('best_ts:start')\nbest_ts = fmin(fn=objective_ts,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=20,\n            trials=trials_ts,\n            rstate=np.random.RandomState(71)\n           )\n\n# \u7d50\u679c\u306e\u51fa\u529b\nclf_ts = LGBMClassifier(**best_ts)\nprint(clf_ts)","4e364316":"## \u30ed\u30fc\u30f3\u984d\u306b\u3064\u3044\u3066\u3001\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u898b\u3066\u307f\u308b\u3002","3a3fb9dc":"## \u30e2\u30c7\u30ea\u30f3\u30b0","8ea6ae81":"## Target\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","dc06d9ea":"## \u30c6\u30ad\u30b9\u30c8\u7279\u5fb4\u91cf\u3092\u9664\u3044\u3066\u3001\u6b20\u640d\u5024\uff08\u7a7a\u6b04\uff09\u3092\u4e2d\u592e\u5024\u3067\u57cb\u3081\u308b","206e6b75":"# \u63a2\u7d22\u7a7a\u9593\u3092\u6307\u5b9a\u3059\u308b\u3002\nspace ={\n    'max_depth': hp.choice('max_depth', np.arange(10, 30, dtype=int)),\n    'subsample': hp.uniform ('subsample', 0.8, 1),\n    'learning_rate' : hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n    'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05)\n}","65b4ea4f":"# \u76ee\u7684\u95a2\u6570\uff08\u5c64\u5316\u62bd\u51fa\uff09\ndef objective_skf(space):\n    scores = []\n    \n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n    \n    for i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n        \n        clf = LGBMClassifier(n_estimators=9999, **space)\n        \n        clf.fit(X_train_, y_train_, early_stopping_rounds=20,\n                eval_metric='auc', eval_set=[(X_val, y_val)])\n        \n        y_pred = clf.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n        \n        del X_train_, y_train_, X_val, y_val, y_pred, score, clf\n        gc.collect()\n        \n    scores = np.array(scores)\n    print(scores.mean())\n    \n    return -scores.mean() # \u3053\u306e\u623b\u308a\u5024\u304c\u6700\u5c0f\u5316\u3055\u308c\u308b","5526eed6":"## Clipping & \u5bfe\u6570\u5909\u63db","3d7e5cbb":"## \u30c7\u30fc\u30bf\u8ffd\u52a0"}}