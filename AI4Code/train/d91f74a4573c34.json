{"cell_type":{"3839b2fe":"code","0ab9cd43":"code","b5a2658a":"code","0493b119":"code","1d8038c9":"code","6bfeb951":"code","4057de91":"code","236af378":"code","b1ebe740":"code","99310f5c":"code","4a482bc0":"code","3dc370ba":"code","e73d3a6a":"code","864abfd4":"code","1798bb8c":"code","65b08ddb":"code","a00729a4":"code","da46d7de":"code","73617983":"markdown","76b71589":"markdown","33396a3c":"markdown","43fb61dc":"markdown","02599951":"markdown","260c420c":"markdown","eb2db2d5":"markdown","a18617c6":"markdown"},"source":{"3839b2fe":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport random\nimport matplotlib.pylab as plt\nimport seaborn as sns\npd.set_option('display.max_colwidth', None)","0ab9cd43":"img_paths=[]\nimg_labels=[]\nfor i in glob('..\/input\/satellite-images-of-hurricane-damage\/**',recursive=True):\n    if i.endswith('.jpeg'):\n        a=i.split('\/')\n        img_paths.append(i)\n        img_labels.append(a[-2])","b5a2658a":"len(img_paths),len(img_labels)","0493b119":"print('We got total '+str(len(img_paths))+' images')","1d8038c9":"img_path = pd.Series(img_paths).astype(str)\nlabels=pd.Series(img_labels)\ndata = pd.concat([img_path,labels],axis=1)\ndata.sample(5)","6bfeb951":"plt.figure(figsize=(15,5))\nsns.countplot(x=data[1])","4057de91":"from sklearn.model_selection import train_test_split\ntrain_set , test_set = train_test_split(data,test_size=0.25,random_state=0)\ntrain_set.shape,test_set.shape","236af378":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras","b1ebe740":"train_gen = ImageDataGenerator(validation_split=0.1,rotation_range=10, # rotation\n        width_shift_range=0.2, # horizontal shift\n        height_shift_range=0.2, # vertical shift\n        zoom_range=0.2, # zoom\n        horizontal_flip=True, # horizontal flip\n        brightness_range=[0.2,1.2]) # brightness)\ntest_gen = ImageDataGenerator(rotation_range=10, # rotation\n        width_shift_range=0.2, # horizontal shift\n        height_shift_range=0.2, # vertical shift\n        zoom_range=0.2, # zoom\n        horizontal_flip=True, # horizontal flip\n        brightness_range=[0.2,1.2]) # brightness)\n\ntrain_data = train_gen.flow_from_dataframe(\n    dataframe = train_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (227,227),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = True,\n    subset = 'training',\n    batch_size=100,\n    seed=2020\n)\n\nval_data = train_gen.flow_from_dataframe(\n    dataframe = train_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (227,227),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = False,\n    subset = 'validation',\n    batch_size=100,\n    seed=2020\n)\n\ntest_data = test_gen.flow_from_dataframe(\n    dataframe = test_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (227,227),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = False,\n    batch_size=100,\n    seed=2020\n)","99310f5c":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Flatten(),\n    keras.layers.Dense(4096, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(4096, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(2, activation='sigmoid')\n])\nmodel.compile(\n    optimizer=tf.optimizers.Adam(lr=0.000001),\n    loss='binary_crossentropy',\n    metrics=['accuracy','Recall']\n)\n","4a482bc0":"model.summary()","3dc370ba":"history = model.fit(train_data,epochs=15,validation_data=val_data)","e73d3a6a":"import matplotlib.pyplot as plt\n#plotting the Accuracy of test and training sets\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","864abfd4":"#plotting the loss of test and training sets\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","1798bb8c":"y_pred = model.predict(test_data)\ny_pred = np.argmax(y_pred,axis=1)","65b08ddb":"from sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(test_data.labels,y_pred))","a00729a4":"classes=['Damage','No Damage']\ncon_mat_df = pd.DataFrame(confusion_matrix(test_data.labels,y_pred),\n                     index = classes, \n                     columns = classes)","da46d7de":"import seaborn as sns\nfigure = plt.figure(figsize=(12, 6))\nsns.heatmap(con_mat_df, annot=True,cmap=plt.cm.cool,fmt='d')\nplt.tight_layout()\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","73617983":"> Model creation & compilation","76b71589":"> It seems the number of no damage is half than actual damage image.","33396a3c":"**Saving the image paths and their labels into dataframe**","43fb61dc":"**Lets get all the images from the dataset and store the paths as well as their labels**","02599951":"# Welcome here!!!","260c420c":"> Model Training","eb2db2d5":"> Splitted the dataset into training and testing sets","a18617c6":"> Getting the Traininig, Validation & Testing images"}}