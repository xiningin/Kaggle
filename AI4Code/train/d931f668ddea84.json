{"cell_type":{"20d155e5":"code","da81933e":"code","2400ee67":"code","c16e8158":"code","e78428e1":"code","ea58437e":"code","0efe9b0e":"code","dcd38f8c":"code","f3441367":"code","b622d83b":"code","132d8827":"code","818f11a1":"code","efec4a91":"code","95ea695a":"code","259c163c":"code","bf921b65":"code","03dd3e59":"code","7fdbad3c":"markdown","216b258d":"markdown","5f79b16a":"markdown"},"source":{"20d155e5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.metrics\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","da81933e":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","2400ee67":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","c16e8158":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","e78428e1":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","ea58437e":"from sklearn.preprocessing import OneHotEncoder","0efe9b0e":"enc = OneHotEncoder(handle_unknown='ignore', sparse = False)","dcd38f8c":"y = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])","f3441367":"y = y.to_numpy()\ny = y.reshape(-1,1)","b622d83b":"y = enc.fit_transform(y)","132d8827":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100,max_depth=5,random_state=0)\nmodel.fit(X, y)\npredictions = model.predict(X_test)","818f11a1":"import tensorflow as tf","efec4a91":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(100, input_shape = (5, )))\nmodel.add(tf.keras.layers.PReLU(alpha_initializer='zeros'))\nmodel.add(tf.keras.layers.Dense(50, activation = 'relu'))\nmodel.add(tf.keras.layers.PReLU(alpha_initializer='zeros'))\nmodel.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))","95ea695a":"model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nmodel.summary()","259c163c":"history = model.fit(X, y, epochs = 20, verbose = 1)","bf921b65":"print(output)","03dd3e59":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)","7fdbad3c":"# Using random forest classifier","216b258d":"# Importing dataset","5f79b16a":"# Creating submission"}}