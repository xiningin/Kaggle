{"cell_type":{"44638fcc":"code","86e5dffa":"code","36f468cd":"code","f2d0b4d8":"code","c3f1f238":"code","c1ec0137":"code","8761a189":"code","d304f5f3":"code","a61b840b":"code","034d77dd":"code","40de4e22":"code","41db5d54":"code","38652155":"code","4785140f":"code","9d09681a":"code","cfd9cc43":"code","4ed7ee0f":"code","2a645d5f":"code","8deff3b0":"code","1ff8d785":"code","50b2257c":"code","f69edadf":"code","daa60bba":"code","d4d438b1":"code","ccfb7bb0":"code","691ea1d6":"code","e482de4a":"code","76ff7092":"markdown","507a4298":"markdown","2b0ee62c":"markdown","9040301a":"markdown","2dcd44d3":"markdown","5989d7a4":"markdown","1e1d6420":"markdown","00cef92e":"markdown","67950a35":"markdown","af6b3768":"markdown","5432d8e9":"markdown","8e45efcb":"markdown","3f84c0cb":"markdown"},"source":{"44638fcc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86e5dffa":"img_dir = '..\/input\/image-classification\/images\/images'\nval_dir = '..\/input\/image-classification\/validation\/validation'","36f468cd":" pip install --upgrade pip","f2d0b4d8":"! pip install -q tf-nightly","c3f1f238":"import tensorflow as tf\nfrom tensorflow import keras\ntf.__version__","c1ec0137":"pip install -q pyyaml h5py  # Required to save models in HDF5 format","8761a189":"# change as you want\nimage_size = (180, 180)\nbatch_size = 32","d304f5f3":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=img_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1007,\n    image_size=image_size,\n    batch_size=batch_size,\n)","a61b840b":"class_names=train_ds.class_names\nclass_names","034d77dd":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=img_dir,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1007,\n    image_size=image_size,\n    batch_size=batch_size,\n)","40de4e22":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    directory=val_dir,\n    validation_split=0.9999,\n    subset=\"validation\",\n    seed=1007,\n    image_size=image_size,\n    batch_size=batch_size,\n)","41db5d54":"# put your code here \nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(16, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(12):\n        ax = plt.subplot(3, 4, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[int(labels[i])])\n        plt.axis(\"off\")","38652155":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","4785140f":"# put your code here \nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","9d09681a":"num_classes =4\nimg_height=180\nimg_width=180\n\n\nmodel = keras.Sequential([\n      tf.keras.layers.experimental.preprocessing.Resizing(\n        img_height, img_width, interpolation='bilinear', name=None\n    ),\n      layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(img_height, img_width, 3)),\n      layers.Conv2D(32, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n\n         layers.Conv2D(32, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n\n      layers.Conv2D(128, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n\n        layers.Conv2D(128, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n\n      layers.Conv2D(256, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n\n         layers.Conv2D(256, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n\n        layers.Dropout(.2),\n\n      layers.Flatten(),\n      layers.Dense(128, activation='relu'),\n      layers.Dense(num_classes)\n    ])","cfd9cc43":"callbacks = [\n    tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=5,\n    restore_best_weights=True\n)]\n    ","4ed7ee0f":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","2a645d5f":"epochs=2\n\n\n    \nhistory = model.fit(\n  train_ds,\n  callbacks=callbacks  , \n  validation_data=val_ds,\n  epochs=epochs\n)","8deff3b0":"# put your code here \nfrom matplotlib import pyplot\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n\n\npyplot.figure(figsize=(8, 8))\npyplot.subplot(1, 2, 1)\npyplot.plot( acc, label='Training Accuracy')\npyplot.plot( val_acc, label='Validation Accuracy')\npyplot.legend(loc='lower right')\npyplot.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\npyplot.plot(loss, label='Training Loss')\npyplot.plot(val_loss, label='Validation Loss')\npyplot.legend(loc='upper right')\npyplot.title('Training and Validation Loss')\npyplot.show()","1ff8d785":"!mkdir -p saved_model\nmodel.save('saved_model\/my_model') ","50b2257c":"# put your code here \npredictions = model.predict(test_ds)\nscore = tf.nn.softmax(predictions)","f69edadf":"test_dir = '..\/input\/image-classification\/test\/test\/classify'\n\nos.listdir(test_dir)","daa60bba":"l","d4d438b1":"for i in range(1,11):\n    test_path = '..\/input\/image-classification\/test\/test\/classify\/{}.JPG'.format(i)\n\n    \n    img = keras.preprocessing.image.load_img(\n       test_path, target_size=(img_height, img_width)\n    )\n    img_array = keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0) # Create a batch\n\n    predictions = model.predict(img_array)\n    score = tf.nn.softmax(predictions[0])\n\n    print(\n        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n        .format(class_names[np.argmax(score)], 100 * np.max(score))\n    )","ccfb7bb0":"# put your code here \nsunflower_url = \"https:\/\/www.englishwsheets.com\/images\/food-and-drinks-vocabulary-esl-picture-dictionary-worksheets-for-kids-icon.png\"\nsunflower_path = tf.keras.utils.get_file('food-and-drinks-vocabulary', origin=sunflower_url)\n\nimg = keras.preprocessing.image.load_img(\n    sunflower_path, target_size=(img_height, img_width)\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\n)\n","691ea1d6":"sunflower_url = \"https:\/\/cdn-a.william-reed.com\/var\/wrbm_gb_food_pharma\/storage\/images\/publications\/food-beverage-nutrition\/foodnavigator.com\/article\/2018\/05\/22\/uk-food-and-drink-manufacturers-feeling-brexit-uncertainty\/8217042-1-eng-GB\/UK-food-and-drink-manufacturers-feeling-Brexit-uncertainty_wrbm_large.jpg\"\nsunflower_path = tf.keras.utils.get_file('UK-food-and-drink-manufacturers-feeling-Brexit-uncertainty_wrbm_large', origin=sunflower_url)\n\nimg = keras.preprocessing.image.load_img(\n    sunflower_path, target_size=(img_height, img_width)\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score)))","e482de4a":"sunflower_url = \"https:\/\/www.ceu.edu\/sites\/default\/files\/styles\/panopoly_image_full\/public\/academic_areas\/field_ra_image\/art-culture.jpg\"\nsunflower_path = tf.keras.utils.get_file('art-culture', origin=sunflower_url)\n\nimg = keras.preprocessing.image.load_img(\n    sunflower_path, target_size=(img_height, img_width)\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score)))","76ff7092":"# Data Directories ","507a4298":"# test on some images from \n\n```..\/input\/image-classification\/test\/test\/classify```","2b0ee62c":"# image size and batch size \nchange the image size and the batch size as you want","9040301a":"# Install TF nighlty ","2dcd44d3":"# Your model ","5989d7a4":"# validation data ","1e1d6420":"# test on 3 external images ","00cef92e":"# Save model ","67950a35":"# plot error and accuracy (train and validation) ","af6b3768":"# test data ","5432d8e9":"# import TF & check the version ","8e45efcb":"# visualize (plot) some images from training data with their labels ","3f84c0cb":"# training data "}}