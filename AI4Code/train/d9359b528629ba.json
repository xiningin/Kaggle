{"cell_type":{"e44c7c7c":"code","4a4af53e":"code","7634d237":"code","e6e083a7":"code","39145ac0":"code","8df67c40":"code","d9ce186a":"code","838e94aa":"code","4949b939":"code","c3b8e8b3":"code","6ac48c12":"code","a2c770e4":"code","d8b328e3":"code","0e1aaebc":"code","da4722b6":"code","cb2d72d9":"code","0fe759fc":"code","a0fbe43c":"code","65be98f8":"code","57742cf5":"code","d85d784b":"code","cb378cb0":"code","dc27290e":"code","ab878f29":"markdown","a620351d":"markdown","90a2ba9b":"markdown","c38ca327":"markdown","e85b8bba":"markdown","658825c0":"markdown","06136973":"markdown","b5df576b":"markdown","ae87df48":"markdown","253ece85":"markdown","32bec4e5":"markdown","9b83a975":"markdown","d9016591":"markdown","8f3a0f60":"markdown","c0e25024":"markdown","e38c5bc1":"markdown","f5a53974":"markdown","fbdad051":"markdown","6a7f2617":"markdown","16e3e5b3":"markdown"},"source":{"e44c7c7c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4a4af53e":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings('ignore')","7634d237":"# load the data\ndf=pd.read_csv('\/kaggle\/input\/pump-sensor-data\/sensor.csv',index_col='timestamp',parse_dates=True)\ndf.drop('Unnamed: 0', axis=1, inplace=True)\ndf.drop(['sensor_15','sensor_50'],axis=1,inplace=True)\ndf.replace({'BROKEN': 1, 'NORMAL': 0,'RECOVERING':0.5}, inplace=True)\n\n# fill na, a linear interpolation from left\ndf=df.interpolate(method='linear',limit_direction='backward',axis=0)\nDf=df.copy() # for later use","e6e083a7":"def add_alarm_column(df, Failure_times,timewindow_for_prediction):\n\n  \"\"\"\n  Add one 'alarm' column to label the 'alarm windows'.\n  value=2, 10h-5min ahead of the machine failure; \n  \"\"\"\n  df['alarm']=df['machine_status']\n  for i,failure_time in enumerate(Failure_times):\n    start_predic_time=failure_time-pd.Timedelta(seconds=60*timewindow_for_prediction[0]) #  mins before the failure time\n    stop_predic_time=failure_time-pd.Timedelta(seconds=60*timewindow_for_prediction[1]) #  mins before the failure time\n    df.loc[start_predic_time:stop_predic_time,'alarm']=2 # can not use 1, because 1 indicate the machine failure time\n  return df","39145ac0":"Failure_times=df[df['machine_status']==1].index\ndf=add_alarm_column(df, Failure_times,(12*60,1)) # 12h-1min ahead of failure is the alarm windows","8df67c40":"def generate_train_validation_test_datasets(df,Failure_times):\n  '''\n  - the data before the first failure is used as test dataset\n  - the data before the second failure is used as validation dataset\n  - the data after the second failure is used as training dataset\n  '''\n\n  df_val=df.loc[:(Failure_times[0]+pd.Timedelta(seconds=60*120)),:]\n  df_test=df.loc[(Failure_times[0]+pd.Timedelta(seconds=60*120)):(Failure_times[1]+pd.Timedelta(seconds=60*120)),:]\n  df_train=df.loc[Failure_times[1]+pd.Timedelta(seconds=60*120):,:]\n\n  return df_train, df_val,df_test","d9ce186a":"Failure_times=df[df['machine_status']==1].index\ndf_train, df_val,df_test=generate_train_validation_test_datasets(df,Failure_times)\nDf_train=df_train.copy()\nDf_val=df_val.copy()\nDf_test=df_test.copy()","838e94aa":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\n\nsensor_names=Df_train.columns[:-2]\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler = scaler.fit(Df_train[sensor_names]) # use this scaler for test and validation data set\n\ntrain_scaled=scaler.transform(Df_train[sensor_names])\npca=PCA(n_components=8).fit(train_scaled) # use this pca for test and validation data set\ndf_train_pca=pd.DataFrame(pca.transform(train_scaled))\n\npcs = ['pc'+str(i+1) for i in range(8)]\ndf_train_pca.columns = pcs\ndf_train_pca['machine_status']=Df_train['machine_status'].values\ndf_train_pca['alarm']=Df_train['alarm'].values\ndf_train_pca.index=Df_train.index\ndf_train=df_train_pca[['pc1','pc2','pc3','pc4','machine_status','alarm']]","4949b939":"sensor_names=Df_test.columns[:-2]\ntest_scaled=scaler.transform(Df_test[sensor_names])\ndf_test_pca=pd.DataFrame(pca.transform(test_scaled))\n\npcs = ['pc'+str(i+1) for i in range(8)]\ndf_test_pca.columns = pcs\ndf_test_pca['machine_status']=Df_test['machine_status'].values\ndf_test_pca['alarm']=Df_test['alarm'].values\ndf_test_pca.index=Df_test.index\ndf_test=df_test_pca[['pc1','pc2','pc3','pc4','machine_status','alarm']]","c3b8e8b3":"sensor_names=Df_val.columns[:-2]\nval_scaled=scaler.transform(Df_val[sensor_names])\ndf_val_pca=pd.DataFrame(pca.transform(val_scaled))\n\npcs = ['pc'+str(i+1) for i in range(8)]\ndf_val_pca.columns = pcs\ndf_val_pca['machine_status']=Df_val['machine_status'].values\ndf_val_pca['alarm']=Df_val['alarm'].values\ndf_val_pca.index=Df_val.index\ndf_val=df_val_pca[['pc1','pc2','pc3','pc4','machine_status','alarm']]","6ac48c12":"def generate_seq_preFailure2(df,Failure_times,features_columns,timewindow_for_use, window_len, stride):\n  '''\n  Generate data samples using the time windows ahead of each machine failure time;\n  window_len: how many data points from each feature will be used to make one sample for the model. \n  stride: sliding window size\n  '''\n  X = np.empty((1,1,window_len*len(features_columns)), float)\n  Y=np.empty((1), float)\n\n  for i,failure_time in enumerate(Failure_times):\n    windows_start=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[0]) #  mins before the failure time\n    windows_end=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[1]) #  mins before the failure time\n\n    df_prefailure_single_window_feature=df.loc[windows_start:windows_end,features_columns]\n    df_prefailure_single_window_target=df.loc[windows_start:windows_end,'alarm']\n    \n    data=df_prefailure_single_window_feature.to_numpy().tolist()\n    targets=df_prefailure_single_window_target.tolist()\n\n    data_gen=tf.keras.preprocessing.sequence.TimeseriesGenerator(data, targets, window_len,stride=stride,sampling_rate=1,batch_size=1,shuffle=True)\n\n    for i in range(len(data_gen)):\n      x, y = data_gen[i]\n      x=np.transpose(x).flatten()\n      x=x.reshape((1,1,len(x)))\n      X=np.append(X,x,axis=0)\n      Y=np.append(Y,y\/2,axis=0) # alarm windows are marked as 2, however, for the model, I will use 1 becasue of the sigmoid function. \n\n    # for alarm windown, no stride=1\n    windows_start=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[2]) #  mins before the failure time\n    windows_end=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[3]) #  mins before the failure time\n\n    df_prefailure_single_window_feature=df.loc[windows_start:windows_end,features_columns]\n    df_prefailure_single_window_target=df.loc[windows_start:windows_end,'alarm']\n    \n    data=df_prefailure_single_window_feature.to_numpy().tolist()\n    targets=df_prefailure_single_window_target.tolist()\n\n    data_gen=tf.keras.preprocessing.sequence.TimeseriesGenerator(data, targets, window_len,stride=1,sampling_rate=1,batch_size=1,shuffle=True)\n\n    for i in range(len(data_gen)):\n      x, y = data_gen[i]\n      x=np.transpose(x).flatten()\n      x=x.reshape((1,1,len(x)))\n      X=np.append(X,x,axis=0)\n      Y=np.append(Y,y\/2,axis=0) # alarm windows are marked as 2, however, for the model, I will use 1 becasue of the sigmoid function. \n\n\n  return X,Y","a2c770e4":"Failure_times=df_train[df_train['machine_status']==1].index \nfeatures_columns=df_train.columns.tolist()[:-2]\ntimewindow_for_use=(96*60,12*60,12*60, 5) \nwindow_len=20 \nstride=5 \nX,y=generate_seq_preFailure2(df_train,Failure_times,features_columns,timewindow_for_use,window_len, stride)\nX,y=generate_seq_preFailure2(df_train,Failure_times,features_columns,timewindow_for_use,window_len, stride)\n\n# remove the sample with Y=nan\nid_keep= np.where((y == 0) | (y ==1))\ny_train=y[id_keep]\nX_train=X[id_keep][:,:]\n\nprint(X_train.shape, y_train.shape)\n\n# positive cases\nprint('Training datasets, Alarm samples:',np.sum(y_train==1)\/(np.sum(y_train==0)+np.sum(y_train==1)))","d8b328e3":"# Generate test dataset\ndef generate_seq_single_preFailure(df,failure_time,features_columns,timewindow_for_use,window_len,stride):\n  '''\n  Generate the test data set using one machine failure time.\n  '''\n  \n  X = np.empty((1,1,window_len*len(features_columns)), float)\n  Y=np.empty((1), float)\n  \n  windows_start=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[0]) #  mins before the failure time\n  windows_end=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[1]) #  mins before the failure time\n  df_prefailure_single_window_feature=df.loc[windows_start:windows_end,features_columns]\n  df_prefailure_single_window_target=df.loc[windows_start:windows_end,'alarm']\n    \n  data=df_prefailure_single_window_feature.to_numpy().tolist()\n  targets=df_prefailure_single_window_target.tolist()\n\n  data_gen=tf.keras.preprocessing.sequence.TimeseriesGenerator(data, targets, window_len,stride=stride,sampling_rate=1,batch_size=1,shuffle=False) # for ploting, do not shuffle the data\n  \n  for i in range(len(data_gen)):\n    x, y = data_gen[i]\n    x=np.transpose(x).flatten()\n    x=x.reshape((1,1,len(x)))\n    X=np.append(X,x,axis=0)\n    Y=np.append(Y,y\/2,axis=0)\n\n  return X,Y","0e1aaebc":"failure_time=df_test[df_test['machine_status']==1].index[0]\nprint('Test failure time:',failure_time)\nfeatures_columns=df_test.columns.tolist()[:-2]\ntimewindow_for_use=(60*60,5) # 6h-5min\nwindow_len=20\nstride=1\nX_test,y_test=generate_seq_single_preFailure(df_test,failure_time,features_columns,timewindow_for_use,window_len,stride)\n\n# select\nid_keep= np.where((y_test == 0) | (y_test ==1))\ny_test=y_test[id_keep]\nX_test=X_test[id_keep][:,:]\nprint('Test, number of positive samples', np.sum(y_test==1))\nX_test.shape, y_test.shape","da4722b6":"failure_time=df_val[df_val['machine_status']==1].index[0]\nprint('Validation failure time:',failure_time)\nfeatures_columns=df_val.columns.tolist()[:-2]\ntimewindow_for_use=(60*60,5) # 6h-5min\nwindow_len=20\nstride=1\nX_val,y_val=generate_seq_single_preFailure(df_val,failure_time,features_columns,timewindow_for_use,window_len,stride)\n\n# select\nid_keep= np.where((y_val == 0) | (y_val ==1))\ny_val=y_val[id_keep]\nX_val=X_val[id_keep][:,:]\nprint('Validation, number of positive samples', np.sum(y_val==1))\nX_val.shape, y_val.shape","cb2d72d9":"# 4 LSTM layers, with 128, 128, 64,64 units in each layer\nfrom numpy.random import seed\nseed(1)\n\ntf.random.set_seed(2)\n\nmodel_1 = tf.keras.Sequential()\nmodel_1.add(tf.keras.layers.LSTM(128,input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))\nmodel_1.add(tf.keras.layers.LeakyReLU(alpha=0.2)) # \n\nmodel_1.add(tf.keras.layers.LSTM(128,return_sequences=True))\nmodel_1.add(tf.keras.layers.LeakyReLU(alpha=0.2))\nmodel_1.add(tf.keras.layers.Dropout(0.5))\n\nmodel_1.add(tf.keras.layers.LSTM(64,return_sequences=True))\nmodel_1.add(tf.keras.layers.LeakyReLU(alpha=0.2))\nmodel_1.add(tf.keras.layers.Dropout(0.5)) # to prevent overfiting\n\nmodel_1.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n\nmodel_1.compile(loss='binary_crossentropy',\n       optimizer=tf.keras.optimizers.Adam(lr=0.01), # tried 0.1, 0.01, 0.001, 0.01 gives the best results\n       metrics=['binary_accuracy']\n       )\n\n# create a learning rate callback, reduce the lr during the training\ndef scheduler(epoch, lr):\n  if epoch < 25:\n    return lr\n  else:\n    return 0.001\n\nlr_scheduler= tf.keras.callbacks.LearningRateScheduler(scheduler)\n\n#model.summary()\n\nhistory_1=model_1.fit(X_train, y_train, epochs=50, callbacks=[lr_scheduler],batch_size=64, verbose=1, shuffle=True) # real-time prediction, batchsize=1? Here for faster training, I use 64\n\n# plot the loss (or training) curves\npd.DataFrame(history_1.history).iloc[:,:2].plot(figsize=(16,4));\nplt.title('Model_1, loss curves');","0fe759fc":"def plot_confusion_matrix(y_test,y_test_preds,flag_model):\n  # creat confusion matrics\n  cm=confusion_matrix(y_test,tf.round(y_test_preds))\n  cm_norm=cm.astype('float')\/cm.sum(axis=1)[:,np.newaxis] # normalize the confusion matrics\n  n_classes=cm.shape[0]\n\n  fig,ax=plt.subplots(figsize=(5,5))\n  cax=ax.matshow(cm, cmap=plt.cm.Blues)\n  fig.colorbar(cax)\n\n  # create classes\n  classes=False\n  if classes:\n    labels=classes\n  else:\n    labels=np.arange(cm.shape[0])\n\n  # label the axes\n  ax.set(title=flag_model,\n      xlabel='Predicted label',\n      ylabel='True label',\n      xticks=np.arange(n_classes),\n      yticks=np.arange(n_classes),\n      xticklabels=labels,\n      yticklabels=labels)\n\n  # set x-axis labels to bottom\n  ax.xaxis.set_label_position('bottom')\n  ax.xaxis.tick_bottom()\n\n  # adjust label size\n  ax.yaxis.label.set_size(20)\n  ax.title.set_size(20)\n  ax.xaxis.label.set_size(20)\n\n  # set threshold for different colors\n  threshold=(cm.max()+cm.min())\/2.\n\n  # plot the text on each cell\n  for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n    plt.text(j,i,f\"{cm[i,j]}({cm_norm[i,j]*100:.1f}%)\",\n        horizontalalignment='center',\n        color='white' if cm[i,j]>threshold else 'black',\n        size=15)\n    \nfrom sklearn.metrics import confusion_matrix\nimport itertools","a0fbe43c":"# evaluation1: loss and accuracy\nloss,accuracy=model_1.evaluate(X_val,y_val)\nprint(f'Model loss on the validation set: {loss:.4f}')\nprint(f'Model accuracy on the validation set: {(accuracy*100):.2f}%')\n\n# evaluation2: recall\ny_val_preds_1=model_1.predict(X_val).flatten()\ny_val_preds_1=tf.round(y_val_preds_1)\ncm=confusion_matrix(y_val,tf.round(y_val_preds_1))\nrecall=(cm[1,1])\/(cm[1,1]+cm[1,0])\nprecision=(cm[0,0])\/(cm[0,1]+cm[0,0])\nprint(f'Model recall on the validation set: {recall:.4f}') \nprint(f'Model precison on the validation set: {precision:.4f}') \n\n# evaluation3: confusion matrix\nplot_confusion_matrix(y_val,y_val_preds_1,'model_1')","65be98f8":"failure_time=df_val[df_val['machine_status']==1].index[0]\nprint('failure time:',failure_time)\nwindows_start=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[0])\nwindows_end=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[1])\ndf_preFailure=df_val.loc[windows_start:windows_end,:]\n\ny_val_preds_1=model_1.predict(X_val).flatten()\ny_val_preds_1=tf.round(y_val_preds_1)\ndf_preFailure['alarm']=np.append(np.zeros(window_len),(y_val_preds_1))\n\ndf_preFailure[['pc1','pc2','pc3','pc4']].plot(c=\"grey\",figsize=(18,2),legend=None)\ndf_preFailure[df_preFailure['alarm']==1].index.to_list()\n\n# vertical lines\nfor xc in df_preFailure[df_preFailure['alarm']==1].index.to_list():\n  plt.axvline(x=xc,c='red')\n\ndf_val['machine_status'].plot()\nplt.xlim([windows_start,windows_end+pd.Timedelta(seconds=60*200)])\n\nplt.title(\"60h ahead of the failure\")\nplt.show()","57742cf5":"# evaluation1: loss and accuracy\nloss,accuracy=model_1.evaluate(X_test,y_test)\nprint(f'Model loss on the test set: {loss:.4f}')\nprint(f'Model accuracy on the test set: {(accuracy*100):.2f}%')\n\n# evaluation2: recall\ny_test_preds_1=model_1.predict(X_test).flatten()\ny_test_preds_1=y_test_preds_1.flatten()\ny_test_preds_1=tf.round(y_test_preds_1)\ncm=confusion_matrix(y_test,tf.round(y_test_preds_1))\nrecall=(cm[1,1])\/(cm[1,1]+cm[1,0])\nprecision=(cm[0,0])\/(cm[0,1]+cm[0,0])\nprint(f'Model recall on the test set: {recall:.4f}') \nprint(f'Model precison on the test set: {precision:.4f}') \n\n# evaluation3: confusion matrix\n\nplot_confusion_matrix(y_test,y_test_preds_1,'model_1')","d85d784b":"failure_time=df_test[df_test['machine_status']==1].index[0]\nprint('failure time:',failure_time)\nwindows_start=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[0])\nwindows_end=failure_time-pd.Timedelta(seconds=60*timewindow_for_use[1])\ndf_preFailure=df_test.loc[windows_start:windows_end,:]\n\ny_test_preds_1=model_1.predict(X_test).flatten()\ny_test_preds_1=tf.round(y_test_preds_1)\ndf_preFailure['alarm']=np.append(np.zeros(window_len),(y_test_preds_1))\n\ndf_preFailure[['pc1','pc2','pc3','pc4']].plot(c=\"grey\",figsize=(18,2),legend=None)\ndf_preFailure[df_preFailure['alarm']==1].index.to_list()\n\n# vertical lines\nfor xc in df_preFailure[df_preFailure['alarm']==1].index.to_list():\n  plt.axvline(x=xc,c='red')\n\ndf_test['machine_status'].plot()\nplt.xlim([windows_start,windows_end+pd.Timedelta(seconds=60*200)])\n\nplt.title(\"60h ahead of the failure\")\nplt.show()","cb378cb0":"from matplotlib.animation import FuncAnimation\nfrom matplotlib import rc \nrc('animation', html='html5') # equivalent to rcParams['animation.html'] = 'html5'","dc27290e":"def animate(i):\n  x=df_preFailure.index[:i*100]\n  y1=df_preFailure[\"pc1\"][:i*100]\n  y2=df_preFailure[\"pc2\"][:i*100]\n  y3=df_preFailure[\"pc3\"][:i*100]\n  y4=df_preFailure[\"pc4\"][:i*100]\n  machine_status=df_preFailure['machine_status'][:i*100]\n  alarm=df_preFailure['alarm'][:i*100]\n  \n  plt.cla()\n  plt.plot(x,y1,c=\"grey\")\n  plt.plot(x,y2,c=\"grey\")\n  plt.plot(x,y3,c=\"grey\")\n  plt.plot(x,y4,c=\"grey\")\n  #plt.plot(x,machine_status,label='machine state')\n  plt.plot(x,alarm,label='alarm',c=\"red\")\n  plt.tight_layout()\n\nplt.figure(figsize=(18,2))\nani=FuncAnimation(plt.gcf(),animate,interval=1000,frames=40, repeat=True)\nani","ab878f29":"# 1. Import the libraries and get the Data","a620351d":"## 6.3 Evaluation on the test samples\n### 6.3.1 Confusion matrix","90a2ba9b":"## 6.3.3 Make animation to mimic the prediction in real","c38ca327":"<h1>Table of contents<\/h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a>Import the libraries and get the Data<\/a><\/li>\n        <li><a>Label alarm states<\/a><\/li>\n        <li><a>Seperate test, train, validaiton dataset<\/a><\/li>\n        <li><a>Preprocessing data<\/a><\/li>\n        <li><a>Segmentation<\/a><\/li>\n        <li><a>LSTM model<\/a><\/li>\n        <li><a>Conclusions<\/a><\/li>\n        <li><a>References<\/a><\/li>\n<\/div>","e85b8bba":"# 2. Label alarm states","658825c0":"# 8. References\n* Jason Brownlee, [How to Get Started with Deep Learning for Time Series Forecasting (7-Day Mini-Course)](https:\/\/machinelearningmastery.com\/how-to-get-started-with-deep-learning-for-time-series-forecasting-7-day-mini-course\/). \n* Jason Brownlee, [How to Develop LSTM Models for Time Series Forecasting](https:\/\/machinelearningmastery.com\/how-to-develop-lstm-models-for-time-series-forecasting\/). \n* Alexandra Amidon, [A Brief Survey of Time Series Classification Algorithms](https:\/\/towardsdatascience.com\/a-brief-introduction-to-time-series-classification-algorithms-7b4284d31b97).\n* Pedro Lara-Ben\u00edtez, [An Experimental Review on Deep Learning Architectures for Time Series Forecasting](https:\/\/arxiv.org\/abs\/2103.12057).\n* Tarang Shah, [About Train, Validation and Test Sets in Machine Learning](https:\/\/towardsdatascience.com\/train-validation-and-test-sets-72cb40cba9e7).\n* Jason Brownlee, [How to Get Reproducible Results with Keras](https:\/\/machinelearningmastery.com\/reproducible-results-neural-networks-keras\/).","06136973":"# 7. Conclusions\n\nThe results confirm that the LSTM model is suitable for early detection of machine failures (12h-5min before failure). Based on the performance of the model on the test data, I suggest that in real production, if the model issues an alarm, then the engineer can wait to see if more alarms will come. If no more alarms appear, then the engineers do not need to do anything. But if more alarms come, then the engineers need to check whether there is a problem.\n\nHowever, considering that I first used PCA to reduce the dimension of all sensor input, even if one of the sensors failed, the model would not work. Given that many sensors are highly correlated, one of the possibilities for optimizing the model may be\n* group sensors into several groups based on the correlation between each other and the domain knowledge of the sensor data. \n* select one sensor from each group to train the model. \n\nBy doing so, in real production, if one sensor used in the model breaks down, we can choose a second one from its group to do the prediction. \n","b5df576b":"### 6.3.2 Visualize the results","ae87df48":"From the results, we can see that:\n* The false positive rate (1.5%) is quite low, which means our model will not give too many false alarms;\n* In the time time window of 12h before the failure, our model will give 284 alarms, which is enough to notify the engineers to check if there is a problem.","253ece85":"## 4.2 Standardization and PCA for test dataset","32bec4e5":"## 4.3 Standardization and PCA for validation dataset","9b83a975":"### 6.2.2 Visualize the results","d9016591":"# 4. Preprocessing data\n## 4.1 Standardization and PCA for traing dataset","8f3a0f60":"# Thank you very much for checking the code, and suggestions are welcome!","c0e25024":"## 5.2 Test samples","e38c5bc1":"## 5.3 Validation samples","f5a53974":"# 6. LSTM model\n## 6.1 Build model\n\nHyperparameters:\n* 3 layers of LSTM.\n* 128, 128, 64 units in each LSTM layer.\n* Slope for Leaky ReLU is set at 0.2. Leaky ReLU is a type of activation function based on a ReLU, but it has a small slope for negative values instead of a flat slope. It allows a small gradient when the unit is not active.\n* A dropout rate = 0.5 is set to avoid overfiting.\n\n* Activation funciton of the output layer is set to 'sigmoid' becasue of the binary classification problem.","fbdad051":"## 6.2 Evaluate the model on validation samples\n### 6.2.1 Confusion matrix","6a7f2617":"# 3. Seperate test, train,validaiton dataset","16e3e5b3":"# 5. Segmentation\n## 5.1 Training samples"}}