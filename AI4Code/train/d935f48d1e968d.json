{"cell_type":{"d3c24382":"code","c5ae5bd4":"code","e3245f44":"code","dea1b69e":"code","40026daf":"code","7b0f441d":"code","1c70f1fa":"code","a9a9c67d":"code","34050881":"code","5f64a98d":"code","5c9d7847":"code","c484db45":"code","908dffdf":"code","e57e207d":"code","c4f08ae9":"code","9706dbc6":"code","ac6fecb7":"code","f9abdbfc":"code","c3f012d2":"code","6dba2182":"code","7b0fa134":"code","3f222939":"code","64af35f1":"code","7a773e11":"code","f7b17ac7":"code","c6753e2a":"code","5aaaa08e":"code","ed7d2ca8":"code","2a0ab400":"code","75fe3311":"code","df0b5101":"code","0fba3020":"markdown","8826cb5d":"markdown","51101e9b":"markdown","eb128b30":"markdown","8bac142e":"markdown","83205eed":"markdown","efb5119b":"markdown","ca2ab42e":"markdown","668cc5d3":"markdown","76a0a37a":"markdown","b70e0f45":"markdown","cac2b219":"markdown","507eaca0":"markdown","1e4fab02":"markdown"},"source":{"d3c24382":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c5ae5bd4":"import math\nimport tensorflow as tf\nprint(tf.__version__)\n\nnp.random.seed(2019)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","e3245f44":"data_train_file = \"..\/input\/digit-recognizer\/train.csv\"\ndata_test_file = \"..\/input\/digit-recognizer\/test.csv\"\n\ndf_train = pd.read_csv(data_train_file)\ndf_test = pd.read_csv(data_test_file)","dea1b69e":"df_train.head()","40026daf":"# Notice data is shifted to the left by one column, since the label is missing\ndf_test.head()","7b0f441d":"df_test.describe()","1c70f1fa":"# Note this returns numpy arrays\ndef get_features_labels(df):\n    # The first column is the label.\n    labels = df['label'].values\n    \n    # Select all columns except the first\n    features = df.values[:, 1:]\/255\n    \n    return features, labels","a9a9c67d":"train_features, train_labels = get_features_labels(df_train)\ntest_features = df_test.values\/255","34050881":"print(train_features.shape)\nprint(test_features.shape)\nprint(train_labels.shape)","5f64a98d":"# Defaults to showing data from the training set, \n# but we can provide the test data as well, and leave labels as None, to visualize test set\ndef display_by_index(index, features=train_features, labels=train_labels):\n    plt.figure()\n    \n    if labels is not None:\n        plt.title(f'Label: {labels[index]}')\n        \n    _ = plt.imshow(np.reshape(features[index, :], (28,28)), 'gray')","5c9d7847":"# Visualize a training sample\ndisplay_by_index(221)","c484db45":"# Visualize a test sample\ndisplay_by_index(221, features=test_features, labels=None)","908dffdf":"df_train['label'].value_counts()","e57e207d":"print(df_test.shape)","c4f08ae9":"train_labels_1hot = tf.keras.utils.to_categorical(train_labels)","9706dbc6":"print(train_labels_1hot.shape)","ac6fecb7":"train_labels_1hot","f9abdbfc":"model_arch = {}","c3f012d2":"model_arch['single_layer'] = [\n      tf.keras.layers.Input(shape=(28*28,)),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","6dba2182":"model_arch['dnn'] = [\n      tf.keras.layers.Input(shape=(28*28,)),\n      tf.keras.layers.Dense(200, activation='sigmoid'),\n      tf.keras.layers.Dense(60, activation='sigmoid'),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","7b0fa134":"model_arch['dnn_relu'] = [\n      tf.keras.layers.Input(shape=(28*28,)),\n      tf.keras.layers.Dense(200, activation='relu'),\n      tf.keras.layers.Dense(60, activation='relu'),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","3f222939":"# lr decay function\ndef lr_decay(epoch):\n    return 0.01 * math.pow(0.6, epoch)\n\n# lr schedule callback\nlr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)\n\n# Plot the decay rate\nx = []\ny = []\nfor i in range(1,10):\n    y.append(lr_decay(i))\n    x.append(i)\nplt.plot(x, y)","64af35f1":"# Add dropout\nmodel_arch['dnn_relu_dropout'] = [\n      tf.keras.layers.Input(shape=(28*28,)),\n      tf.keras.layers.Dense(200, activation='relu'),\n      tf.keras.layers.Dropout(0.25),\n      tf.keras.layers.Dense(60, activation='relu'),\n      tf.keras.layers.Dropout(0.25),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","7a773e11":"# CNN\nmodel_arch['cnn'] = [\n      tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n      tf.keras.layers.Conv2D(kernel_size=3, filters=12, activation='relu', padding='same'),\n      tf.keras.layers.Conv2D(kernel_size=6, filters=24, activation='relu', padding='same', strides=2),\n      tf.keras.layers.Conv2D(kernel_size=6, filters=32, activation='relu', padding='same', strides=2),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(200, activation='relu'),\n      tf.keras.layers.Dropout(0.25),\n      tf.keras.layers.Dense(10, activation='softmax')\n  ]","f7b17ac7":"model_arch.keys()","c6753e2a":"model = tf.keras.Sequential(model_arch['cnn'])\n\n# optimizer = 'sgd'\noptimizer = 'adam'\n# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n\n# We will now compile and print out a summary of our model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n\nmodel.summary()","5aaaa08e":"BATCH_SIZE=128\nEPOCHS=5","ed7d2ca8":"history = model.fit(train_features, train_labels_1hot, \n          epochs=EPOCHS, \n          batch_size=BATCH_SIZE, \n          validation_split=0.2)\n#           ,callbacks=[lr_decay_callback])","2a0ab400":"plt.plot(history.history['acc'], color='b', label=\"Training accuracy\")\nplt.plot(history.history['val_acc'], color='r', label=\"Validation accuracy\")\nplt.legend(loc='lower right', shadow=True)","75fe3311":"predictions = model.predict_classes(test_features)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","df0b5101":"for i in range(200,210):\n    display_by_index(i, features=test_features, labels=submissions[\"Label\"].values)\n","0fba3020":"## Training the model\nAdjust the hyper params as needed.","8826cb5d":"## Preprocess data into numpy","51101e9b":"## Creating the model \nFor this one we use a deep neural net, expecting \"okay\" results, but nothing spectacular.\n","eb128b30":"## Imports","8bac142e":"## Load and explore data","83205eed":"Dataset looks fairly balanced. No need to do additional work here.","efb5119b":"## Spot-checking some values","ca2ab42e":"## Visualize the numbers\nA helper function for visualizing a specific row","668cc5d3":"### Choose model architecture and compile","76a0a37a":"Confirm that the shape is what we expect: 42k in train, 28k in test, with 784 pixels per row","b70e0f45":"I've created a helper function to take care of processing the features into numpy arrays, but there are many options here.","cac2b219":"## Submission","507eaca0":"### Learning rate decay","1e4fab02":"Turning labels into 1-hot encoding transforms the shape from 1 column to 10 columns"}}