{"cell_type":{"da4a930a":"code","f9ee9e23":"code","8a281b2f":"code","06e93cd9":"code","20a9d31e":"code","9ac3f846":"code","a2266a21":"code","c98802ac":"code","dae6083c":"code","10079838":"code","4a8a48b2":"code","e1f7cb60":"code","e8455c5e":"code","82885a0e":"code","760916ad":"code","b9a91678":"code","0bcfa290":"code","d51cb6c9":"code","f7cb56ec":"code","9a8690f6":"code","6bdee1d3":"code","c96c6189":"code","3d33e3fa":"code","fd1c0595":"code","97c3cb4b":"code","61b187a1":"code","5477a3e4":"code","c28d3b6a":"code","180dfd14":"code","e551b266":"code","c0ea156d":"code","826e233d":"code","f2ff51c9":"code","92f9aca2":"code","0e10d59e":"code","7e7acd2a":"code","bdfd6478":"markdown","78d3bed6":"markdown","966a9312":"markdown","b2516150":"markdown","ea851646":"markdown","746801b4":"markdown"},"source":{"da4a930a":"\n\n# To support both python 2 and python 3\nfrom __future__ import division, print_function, unicode_literals\n\n# Common imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom fbprophet import Prophet\nfrom fbprophet.diagnostics import cross_validation\n\n# plotting\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\n%matplotlib inline\n    \nfrom statsmodels.tsa.seasonal import seasonal_decompose #decompose seasonality\nfrom statsmodels.tsa.stattools import adfuller #test if series is stationary (then can perform ARIMA)\n\n    \n# set random seeds \nfrom numpy.random import seed\nfrom tensorflow import set_random_seed\n\nRANDOM_SEED = 2018\nseed(RANDOM_SEED)\nset_random_seed(RANDOM_SEED)","f9ee9e23":"plt.rcParams[\"figure.figsize\"] = [16,9]","8a281b2f":"def SMAPE (forecast, actual):\n    \"\"\"Returns the Symmetric Mean Absolute Percentage Error between two Series\"\"\"\n    masked_arr = ~((forecast==0)&(actual==0))\n    diff = abs(forecast[masked_arr] - actual[masked_arr])\n    avg = (abs(forecast[masked_arr]) + abs(actual[masked_arr]))\/2\n    \n    print('SMAPE Error Score: ' + str(round(sum(diff\/avg)\/len(forecast) * 100, 2)) + ' %')","06e93cd9":"def Fuller(TimeSeries):\n    \"\"\"Provides Fuller test results for TimeSeries\"\"\"\n    stationary_test = adfuller(TimeSeries)\n    print('ADF Statistic: %f' % stationary_test[0])\n    print('p-value: %f' % stationary_test[1])\n    print('Critical Values:')\n    for key, value in stationary_test[4].items():\n        print('\\t%s: %.3f' % (key, value))","20a9d31e":"#Bring in the Data\n\ntrain = pd.read_csv('..\/input\/train.csv', parse_dates=['date'], index_col=['date'])\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['date'], index_col=['date'])\ntrain.index = pd.to_datetime(train.index)\ntrain.shape, test.shape\n","9ac3f846":"train.shape, test.shape","a2266a21":"train.head()","c98802ac":"test.head()","dae6083c":"stores = pd.DataFrame(train.groupby(['date','store']).sum()['sales']).unstack()\nstores = stores.resample('7D',label='left').sum()\nstores.sort_index(inplace = True)","10079838":"stores.plot(figsize=(16,9), title='Weekly Store Sales', legend=True)\nplt.show()","4a8a48b2":"stores.head(10)","e1f7cb60":"store_qtr = pd.DataFrame(stores.quantile([0.0,0.25,0.5,0.75,1.0],axis=1)).transpose()\nstore_qtr.sort_index(inplace = True)\nstore_qtr.columns = ['Min','25%','50%','75%','Max']\nstore_qtr.plot(figsize=(16,9), title='Weekly Quartile Sales')\nplt.show()","e8455c5e":"seasonal = seasonal_decompose(pd.DataFrame(store_qtr['50%']).diff(1).iloc[1:,0],model='additive')\nseasonal.plot()\nplt.suptitle = 'Additive Seasonal Decomposition of Average Store Week-to-Week Sales'\nplt.show()","82885a0e":"Fuller(pd.DataFrame(store_qtr['50%']).diff(1).iloc[1:,0])","760916ad":"items = pd.DataFrame(train.groupby(['date','item']).sum()['sales']).unstack()\nitems = items.resample('7D',label='left').sum()\nitems.sort_index(inplace = True)\n\nitems.tail(13)","b9a91678":"items.plot(figsize=(16,9), title='Weekly Item Sales', legend=None)\nplt.show()","0bcfa290":"item_WK_qtr = pd.DataFrame(items.quantile([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0],axis=1)).transpose()\nitem_WK_qtr.sort_index(inplace = True)\nitem_WK_qtr.columns = ['Min','10%','20%','30%','40%','50%','60%','70%','80%','90%','Max']\nitem_WK_qtr.plot(figsize=(16,9), title='Weekly Quartile Sales')\nplt.show()","d51cb6c9":"seasonal = seasonal_decompose(pd.DataFrame(item_WK_qtr['50%']).diff(1).iloc[1:,0],model='additive')\nseasonal.plot()\nplt.title = 'Additive Seasonal Decomposition of Average Item Week-to-Week Sales'\nplt.show()","f7cb56ec":"Fuller(pd.DataFrame(item_WK_qtr['50%']).diff(1).iloc[1:,0])","9a8690f6":"store_item = train.groupby(by=['item','store']).sum()['sales'].groupby(level=0).apply(\n    lambda x: 100* x\/ x.sum()).unstack()\nsns.heatmap(store_item, cmap='Blues', linewidths=0.01, linecolor='gray').set_title(\n    'Store % of Total Sales by Item')\nplt.show()","6bdee1d3":"item_store = train.groupby(by=['store','item']).sum()['sales'].groupby(level=0).apply(\n    lambda x: 100* x\/ x.sum()).unstack()\nsns.heatmap(item_store , cmap='Blues', linewidths=0.01, linecolor='gray').set_title(\n    'Item % of Total Sales by Store')\nplt.show()","c96c6189":"train['Day'] = train.index.weekday_name\ntrain.head()","3d33e3fa":"dow_store = train.groupby(['store','Day']).sum()['sales'].groupby(level=0).apply(\n    lambda x: 100* x\/ x.sum()).unstack().loc[:,['Monday',\n                                                'Tuesday',\n                                                'Wednesday',\n                                                'Thursday',\n                                                'Friday',\n                                                'Saturday',\n                                                'Sunday']]\nsns.heatmap(dow_store, cmap='Blues', linewidths=0.01, linecolor='gray').set_title(\n    'Day % of Total Sales by Store')\nplt.show()","fd1c0595":"dow_store","97c3cb4b":"dow_item = train.groupby(['item','Day']).sum()['sales'].groupby(level=0).apply(\n    lambda x: 100* x\/ x.sum()).unstack().loc[:,['Monday',\n                                                'Tuesday',\n                                                'Wednesday',\n                                                'Thursday',\n                                                'Friday',\n                                                'Saturday',\n                                                'Sunday']]\nsns.heatmap(dow_item, cmap='Blues', linewidths=0.01, linecolor='gray').set_title(\n    'Day % of Total Sales by Item')\nplt.show()","61b187a1":"dow = pd.DataFrame(train.groupby(['date','Day']).sum()['sales']).unstack()['sales'].loc[:,\n                                                                                ['Monday',\n                                                                               'Tuesday',\n                                                                               'Wednesday',\n                                                                               'Thursday',\n                                                                               'Friday',\n                                                                               'Saturday',\n                                                                               'Sunday']]\ndow = dow.resample('7D',label='left').sum()\ndow.sort_index(inplace = True)","5477a3e4":"dow.plot(figsize=(16,9), title='Sales by Day of Week')\nplt.show()","c28d3b6a":"#Transforming the sales figures to limit the impact of outliers during modeling\n\ntrain['sales'] = np.log1p(train['sales'])","180dfd14":"proph_results = test.reset_index()\nproph_results['sales'] = 0\nproph_results.head()","e551b266":"#Setting Prophet Holiday Parameters\n\nnfl_playoffs = ['2013-01-11','2013-01-12', '2013-01-19','2013-01-26','2013-02-02','2014-01-10', '2014-01-11',\n            '2014-01-18', '2014-01-25','2014-02-01','2015-01-16','2015-01-17','2015-01-24','2015-01-31','2015-02-07', '2016-01-14',\n            '2016-01-15', '2016-01-22','2016-01-29', '2016-02-05']\nmajor_holidays = ['2013-01-01', '2013-12-25', '2014-01-01', '2014-12-25','2015-01-01', '2015-12-25','2016-01-01', '2016-12-25',\n            '2017-01-01', '2017-12-25']\n\nnfl_playoffs = pd.DataFrame({\n    'holiday': 'nfl_playoffs',\n    'ds': pd.to_datetime(nfl_playoffs),\n    'lower_window': 0,\n    'upper_window': 1,\n})\nmajor_holidays = pd.DataFrame({\n    'holiday': 'major_holidays',\n    'ds': pd.to_datetime(major_holidays),\n    'lower_window': 0,\n    'upper_window': 1,\n})\n\nholidays = pd.concat((nfl_playoffs, major_holidays))","c0ea156d":"#holidays","826e233d":"for s in proph_results['store'].unique():\n    for i in proph_results['item'].unique():\n        proph_train = train.loc[(train['store'] == s) & (train['item'] == i)].reset_index()\n        proph_train.rename(columns={'date': 'ds', 'sales': 'y'}, inplace=True)\n        \n        m = Prophet(holidays=holidays, holidays_prior_scale=0.5,\n            yearly_seasonality=4,  interval_width=0.95,\n            changepoint_prior_scale=0.006, daily_seasonality=True)\n        m.fit(proph_train[['ds', 'y']])\n        future = m.make_future_dataframe(periods=len(test.index.unique()), include_history=False)\n        fcst = m.predict(future)\n        \n        proph_results.loc[(proph_results['store'] == s) & (proph_results['item'] == i), 'sales'] = np.expm1(fcst['yhat']).values","f2ff51c9":"proph_results.head(20)","92f9aca2":"proph_results.shape","0e10d59e":"proph_results.drop(['date', 'store', 'item'], axis=1, inplace=True)\nproph_results.head()","7e7acd2a":"proph_results.to_csv('proph_results.csv', index=False)","bdfd6478":"### Day of Week Variability","78d3bed6":"### Modeling The Data","966a9312":"### Store & Item Trends","b2516150":"### Store Trends","ea851646":"## Exploratory Analysis","746801b4":"### Item Trends"}}