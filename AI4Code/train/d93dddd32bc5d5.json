{"cell_type":{"25347cb9":"code","35f58d47":"code","e65f8f69":"code","db740ea1":"code","73aced77":"code","1bd30f71":"code","23cd0529":"markdown","2f68f90e":"markdown","0ba363d7":"markdown","2ec31ce0":"markdown"},"source":{"25347cb9":"import numpy as np \nimport pandas as pd \nimport os\nfrom os import path\nimport itertools","35f58d47":"InputPath = \"..\/input\/siim-covid19-detection\"\nTrainPath = f\"{InputPath}\/train\"\nTestPath = f\"{InputPath}\/test\"\n\ntrain_image_level = pd.read_csv(f\"{InputPath}\/train_image_level.csv\")\ntrain_image_level.head(\n)\n","e65f8f69":"#let's change the id to ImageID, and remove the '-image' from the end of each element\ntrain_image_level.rename({\"id\" : \"ImageID\"}, axis = 1, inplace = True)\ntrain_image_level[\"ImageID\"] = train_image_level[\"ImageID\"].apply(lambda x:f'{x[:-6]}')\n\ntrain_image_level.head()","db740ea1":"sample_df = train_image_level.head(5).reset_index(drop = True)\nprint(sample_df)","73aced77":"for i, rows in sample_df.iterrows():\n    dir = os.listdir(TrainPath + \"\/\" + rows[\"StudyInstanceUID\"])\n    for k in dir:\n        ImagePath_1 = TrainPath + \"\/\" + rows[\"StudyInstanceUID\"] + \"\/\"+ k + \"\/\" + rows[\"ImageID\"] + \".dcm\"\n        if path.exists(ImagePath_1):\n            print(ImagePath_1)\n            break","1bd30f71":"AllTrainFiles=os.walk(TrainPath)\nfor root, dirs, files in itertools.islice(AllTrainFiles,15):\n    for name in files:\n        if name[-4:]=='.dcm':\n            ImagePath_2 = os.path.join(root, name)\n            print(ImagePath_2)","23cd0529":"In most real-world projects, the data files are not orderly placed in a single folder. Instead, to be more organized they are often clustered under diffrent sub-folders. This is the case for the data provided for [siim-covid19-detection](https:\/\/www.kaggle.com\/c\/siim-covid19-detection) competition.\n\nIn order to handle this project the very first step is to load the images efficiently. In this notebook, two methods are provided for this step.\n\nThis is particulatly important to automate loading large datasets with a few lines of code.\n\nFirst let's import some libraries","2f68f90e":"**Method1: Using the files information sheet**:\nIn the [siim-covid19-detection](https:\/\/www.kaggle.com\/c\/siim-covid19-detection) data, the folder and file names are given in the train_image_level.csv file. We can use this information to load all files.\n \nFirst, let's define the paths and load the .csv file.","0ba363d7":"In order to save time, let's pick a sample of 5 images to read for now. You can later apply the same method to read all files.","2ec31ce0":"**Method2: Using Pythom method walk()**:\nThe [walk()](https:\/\/www.tutorialspoint.com\/python\/os_walk.htm) method generates the file names in a directory tree.\n\nMore information can be found [here](https:\/\/docs.python.org\/3\/library\/os.html)."}}