{"cell_type":{"689caef4":"code","6bbbb47d":"code","ba252ba1":"code","6a4de9a6":"code","cfbe9d2f":"code","bf690d57":"code","4456ba70":"code","d6b2f27b":"code","464f4d9f":"code","67d8b57d":"code","c752c5ff":"code","3b2d5e85":"code","9b349a8f":"code","639882ea":"code","3ca332e9":"code","309875e0":"code","78fb3167":"code","74f0f578":"code","10d03613":"code","efa3a8db":"code","93d6e034":"code","ebbba69a":"code","db135c40":"code","aeff04d6":"code","70e356fe":"code","592baf6d":"code","4062c2c7":"code","3ad62c66":"code","43f8afff":"code","1d049183":"code","624f9081":"code","24623b17":"code","9a915b1b":"code","0bcbeccd":"code","d681d179":"code","f6cf2d01":"code","a2f120fa":"code","16b3e2d7":"code","892aa172":"code","598450b7":"code","a3441113":"code","a623e2c4":"code","3d1d66d4":"code","354ad8b9":"code","95136d48":"code","9f3f188e":"code","2cee1bc0":"code","00af303e":"code","0b6e9dea":"code","cdf145d1":"code","86837562":"code","1cf9a069":"code","64c8b476":"code","b537b381":"code","0099b071":"code","73966c5b":"code","3a4d9fd6":"code","f0682949":"code","1de2432f":"code","cdf93893":"code","a49526dd":"code","5717454c":"code","02f87396":"markdown","ec931799":"markdown","66d8a79a":"markdown","9d98de49":"markdown","ed1ae0a0":"markdown","ee5b1447":"markdown","725c8f0e":"markdown","a9a0b8ea":"markdown","7625b618":"markdown","54a41466":"markdown","9a2de247":"markdown","203a4771":"markdown","5d4ca0d3":"markdown","8fb6ea6e":"markdown","73de77f0":"markdown","7d5dd7a3":"markdown","6c1d723b":"markdown","c198dcdb":"markdown","b1fc3e6a":"markdown","a09d1954":"markdown","1b7e09fa":"markdown","094c72f8":"markdown","b3c916aa":"markdown","e8c7e85a":"markdown","6d087a57":"markdown","aec5d2fb":"markdown","857de37b":"markdown","347ccc96":"markdown","52c12a7f":"markdown","c28acf75":"markdown","baa497d6":"markdown","1fc082d2":"markdown","e465c02c":"markdown","aca8ff9e":"markdown","6ac91902":"markdown","98e8509b":"markdown","686b75f2":"markdown","669e5e9d":"markdown","d778c10e":"markdown","10d5a684":"markdown","4814a314":"markdown","c9683526":"markdown","e54dcaaf":"markdown","a59be093":"markdown","3fa6aab0":"markdown","287f7f29":"markdown","759ebc28":"markdown","16142136":"markdown","b62d9477":"markdown","3d73ef55":"markdown","79a058d4":"markdown","d8ab0ac0":"markdown","aff5081f":"markdown","179882b3":"markdown","b32646da":"markdown","d684c2cc":"markdown","0adf6b87":"markdown","b3a1afd1":"markdown","72fb5ae6":"markdown","717d0ed3":"markdown","d558585d":"markdown","96749c98":"markdown","85a43603":"markdown","81f89deb":"markdown","30a34181":"markdown","7eeb9249":"markdown","bedc5a22":"markdown","53dc0fab":"markdown","669c61a8":"markdown","00908813":"markdown","64d1011f":"markdown","e9a6ba35":"markdown","d14702c8":"markdown","1126b730":"markdown","d0baaf73":"markdown","6ecff5ef":"markdown"},"source":{"689caef4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","6bbbb47d":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","ba252ba1":"train.head()","6a4de9a6":"test.head()","cfbe9d2f":"print('train shape : {}'.format(train.shape))\nprint('-'*40)\nprint('train shape : {}'.format(test.shape))","bf690d57":"print(train.info())\nprint('-'*40)\nprint(test.info())","4456ba70":"train.describe()","d6b2f27b":"train.describe(include=['O'])","464f4d9f":"cor = train.corr()\nplt.figure(figsize=(8,6))\nsns.heatmap(cor, vmax=1, annot=True)\nplt.show()","67d8b57d":"print(train.isnull().sum())\nprint('-'*40)\nprint(test.isnull().sum())","c752c5ff":"gender_survived = train.groupby('Sex').Survived.mean().reset_index()\ngender_survived","3b2d5e85":"class_survived = train.groupby('Pclass').Survived.mean().reset_index()\nclass_survived","9b349a8f":"gender_class_survived = train.groupby(['Sex','Pclass']).Survived.mean().reset_index()\ngender_class_survived","639882ea":"embarked_survived = train.groupby('Embarked').Survived.mean().reset_index()\nembarked_survived ","3ca332e9":"parch_survived = train.groupby('Parch').Survived.mean().reset_index()\nparch_survived ","309875e0":"table = pd.pivot_table(train, values='Survived', index=['SibSp', 'Parch'], aggfunc= 'mean').head()\ntable ","78fb3167":"#set background and style of graph\nsns.set_style('darkgrid')\nsns.set_palette('pastel')\n\n#figure size\nplt.figure(figsize=(12,8))\n\n#create 1st graph: Train data\ncolors = ['gold','yellowgreen','lightcoral']\nplt.subplot(1,2,1)\nplt.pie(train['Embarked'].value_counts(), labels = ['Southampton','Cherbourg','Queenstown'], \n        colors=colors, autopct = '%1.1f%%',startangle = 10)\nplt.title('Proportion of Embarked in Train data')\n\n#create 2nd graph: Test data\ncolors = ['silver','turquoise','wheat']\nplt.subplot(1,2,2)\nplt.pie(test['Embarked'].value_counts(), labels = ['Southampton','Cherbourg','Queenstown'], \n        colors=colors, autopct = '%1.1f%%',startangle = 10)\nplt.title('Proportion of Embarked in Test data')\n\n#show the data\nplt.show()","74f0f578":"#figure size\nplt.figure(figsize=(12,8))\n\n#create 1st graph: Train data\ncolor = ['lightskyblue','orange']\nplt.subplot(1,2,1)\nplt.pie(train['Sex'].value_counts(),labels=['Male','Female'],colors=color, autopct = '%1.1f%%',startangle = 10)\nplt.title('Gender Proportion in Titanic in Train Data')\n\n#create 2nd graph: Test data\ncolor2 = ['lime','yellow']\nplt.subplot(1,2,2)\nplt.pie(test['Sex'].value_counts(),labels=['Male','Female'],colors=color2, autopct = '%1.1f%%',startangle = 10)\nplt.title('Gender Proportion in Titanic in Test Data')\n\n#adjust the distance between plot\nplt.subplots_adjust(wspace=0.5)\n\n#show the data\nplt.show()","10d03613":"#create histogram in the graph\nplt.hist(train['SibSp'], color= 'red',alpha = 0.5)\nplt.hist(test['SibSp'], color= 'blue', alpha = 0.5)\n\n#Title\nplt.title('Distribution of Siblings (SibSp) in Train (Red) and Test (Blue) Set')\n#Legend\nplt.legend(['Train','Test'])\n\n#show the data\nplt.show()","efa3a8db":"#create histogram in the graph\nplt.hist(train['Parch'], color= 'red',alpha = 0.5)\nplt.hist(test['Parch'], color= 'blue', alpha = 0.3)\n\n#title\nplt.title('Distribution of Parent (Parch) Passenger in Train (Red) and Test (Blue) Set')\n\n#legend\nplt.legend(['Train','Test'])\n\n#show the data\nplt.show()","93d6e034":"#figure size\nplt.figure(figsize=(12,8))\n\n#Create 1st graph\nplt.subplot(1,2,1)\nax = sns.boxplot(x=\"Fare\",data=train)\nplt.title('Fare Price in Train')\n\n#Create 2nd graph\nplt.subplot(1,2,2)\nax = sns.boxplot(x=\"Fare\",data=test, color='red')\nplt.title('Fare Price in Test')\n\n#show the data\nplt.show()","ebbba69a":"g = sns.FacetGrid(train,col='Survived')\ng.map(plt.hist,'Age',bins=15)\nplt.show()","db135c40":"g1 = sns.FacetGrid(train,col='Survived',row='Sex')\ng1.map(plt.hist,'Age',bins=15)\nplt.show()","aeff04d6":"g2 = sns.FacetGrid(train,col='Survived',row='Pclass')\ng2.map(plt.hist,'Age',bins=20)\nplt.show()","70e356fe":"g3 = sns.FacetGrid(train,col='Embarked')\ng3.map(sns.pointplot,'Pclass','Survived','Sex',c='red')\ng3.add_legend()\nplt.show()","592baf6d":"g4 = sns.FacetGrid(train,col='Survived',row='Embarked')\ng4.map(sns.barplot, 'Sex','Fare')\ng4.add_legend()\nplt.show()","4062c2c7":"train['Sex'] = train['Sex'].replace('female',0)\ntrain['Sex'] = train['Sex'].replace('male',1)\ntest['Sex'] = test['Sex'].replace('female',0)\ntest['Sex'] = test['Sex'].replace('male',1)","3ad62c66":"print(train.Age.median())\nprint(test.Age.median())","43f8afff":"train['Age'] = train['Age'].fillna(28)\ntest['Age'] = test['Age'].fillna(27)","1d049183":"train['Embarked'] = train['Embarked'].fillna('S')","624f9081":"train['Embarked'] = train['Embarked'].replace('S',int(0))\ntrain['Embarked'] = train['Embarked'].replace('Q',int(1))\ntrain['Embarked'] = train['Embarked'].replace('C',int(2))\n\ntest['Embarked'] = test['Embarked'].replace('S',int(0))\ntest['Embarked'] = test['Embarked'].replace('Q',int(1))\ntest['Embarked'] = test['Embarked'].replace('C',int(2))","24623b17":"print(train.SibSp.unique())\nprint(test.SibSp.unique())","9a915b1b":"train['SibSp'] = train['SibSp'].replace([1,2,3,4,5,8],1)\ntest['SibSp'] = train['SibSp'].replace([1,2,3,4,5,8],1)","0bcbeccd":"print('train unique:{}'.format(train.SibSp.unique()))\nprint('test unique:{}'.format(test.SibSp.unique()))","d681d179":"print(train.Parch.unique())\nprint(test.Parch.unique())","f6cf2d01":"train['Parch'] = train['Parch'].replace([1,2,3,4,5,6,9],1)\ntest['Parch'] = test['Parch'].replace([1,2,3,4,5,6,9],1)","a2f120fa":"print('train unique:{}'.format(train.Parch.unique()))\nprint('test unique:{}'.format(test.Parch.unique()))","16b3e2d7":"train['AgeRange'] = pd.cut(train['Age'], 5)\ntrain[['AgeRange', 'Survived']].groupby(['AgeRange'], as_index=False).mean().sort_values(by='AgeRange', ascending=True)","892aa172":"train['AgeCategory'] = train['AgeRange'].cat.codes\ntrain.head()","598450b7":"#Make a new label based on Age Category\nbins = [-0.01,16.336,32.252,48.168,64.084,80.0]\nlabels = [0,1,2,3,4]\ntest['AgeCategory'] = pd.cut(test['Age'],bins,labels=labels)\ntest.head()","a3441113":"print(test.Fare.mode())\ntest['Fare'] = test['Fare'].fillna(7.75)","a623e2c4":"print(train.Fare.describe())\nprint('-'*40)\nprint(test.Fare.describe())","3d1d66d4":"bins = [-0.01,7.9104,14.4542,31.00,512.3292]\nlabels = [0,1,2,3]\ntrain['FareCategory'] = pd.cut(train['Fare'],bins,labels=labels)\ntest['FareCategory'] = pd.cut(test['Fare'],bins,labels=labels)","354ad8b9":"test.head(3)","95136d48":"train2 = train.drop(['Ticket','Fare','Cabin','AgeRange','Age','Name','PassengerId'],axis=1)\ntrain2.head()","9f3f188e":"test2 = test.drop(['Ticket','Fare','Cabin','Age','Name','PassengerId'],axis=1)\ntest2.head(100)","2cee1bc0":"X_train = train2.drop('Survived',axis=1)\nY_train = train2['Survived']\nX_test = test2\nfeatures = ['Pclass', 'Sex','SibSp','Parch','Embarked','AgeCategory','FareCategory']\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)","00af303e":"#import logistic regression\nfrom sklearn.linear_model import LogisticRegression\n\n#correlates logistic regression with a variables\nlogreg = LogisticRegression()\n\n#fit the logistic regression with X and Y train\nlogreg.fit(X_train, Y_train)\n\n#Find accuracy and prediction\nY1_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n\nprint('Accuracy : {}'.format(acc_log))","0b6e9dea":"coeff = pd.DataFrame(X_train.columns)\ncoeff.columns = ['Feature']\ncoeff[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff.sort_values(by='Correlation', ascending=True)","cdf145d1":"# Support Vector Machines\nfrom sklearn.svm import SVC, LinearSVC\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY2_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n\nprint('Accuracy : {}'.format(acc_svc))","86837562":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 4)\nknn.fit(X_train, Y_train)\nY3_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n\nprint('Accuracy : {}'.format(acc_knn))","1cf9a069":"# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY4_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n\nprint('Accuracy : {}'.format(acc_gaussian))","64c8b476":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY5_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n\nprint('Accuracy : {}'.format(acc_random_forest))","b537b381":"feature_imp = pd.Series(random_forest.feature_importances_,index=features).sort_values(ascending=False)\nfeature_imp","0099b071":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY6_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree\n\nprint('Accuracy : {}'.format(acc_decision_tree))","73966c5b":"feature_imp = pd.Series(decision_tree.feature_importances_,index=features).sort_values(ascending=False)\nfeature_imp","3a4d9fd6":"test3 = test.copy()\ntest3.head()","f0682949":"test3['Survived'] = Y5_pred","1de2432f":"test3.head()","cdf93893":"test4 = test3.drop(['Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked','AgeCategory','FareCategory'],axis=1)","a49526dd":"test4.head()","5717454c":"#Make the file into CSV\ntest4.to_csv('submission.csv',index = False)","02f87396":"Relationship between **Parch (Parent)** and **Survived Rate** :","ec931799":"Try to print the head of each columns in the variables.","66d8a79a":"After we clean the data, we will use several machine learning to predict the best machine learning that we can use to predict Titanic Model.","9d98de49":"**Siblings Distribution**","ed1ae0a0":"To know the best n categories, we can use pd.cut then use groupby to know the rate of survival based on mean.","ee5b1447":"Based on shape and info( ), we could know that there is 12 column in data that consists of 5 column interger, 3 column object and 2 column float.","725c8f0e":"After that, using **cat.codes**, we can make the age based on categories","a9a0b8ea":"Sex = because gender plays important role on Titanic Survival. We will change gender male and female into numeric number (female = 0, male = 1)","7625b618":"## Modelling","54a41466":"Relationship between gender and survived rate:","9a2de247":"## Submission","203a4771":"#### Univariate Distribution","5d4ca0d3":"Based correlation, we can know that:\n1. Parch (Bring parents) has strong correlation (0.41) with Sibsp (Having siblings)\n2. Pclass has strong correlation (-0.34) with Survived (Means Gender plays important role)\n3. Age has strong correlation (-0.37) with Pclass.","8fb6ea6e":"Based on findings in every part, for our machine learning, we will use features:\n\n<br> a. Sex = because gender plays important role on Titanic Survival <\/br>\n<br> b. Pclass = class also plays important role <\/br>\n<br> c. embarked <\/br>\n<br> d. SibSp = By dividing it, into **have or have not** <\/br>\n<br> e. Parch = By dividing it, into **have or have not** <\/br>\n<br> f. Age = Will be divided based on categories <\/br>\n<br> g. Fare = Will be divided based on categories <\/br>\n\n<br> To achieve that, we will clean both **train and test data**<\/br>","73de77f0":"### Decision Tree","7d5dd7a3":"**CONCLUSIONS**:\n\n<br> Based on machine learning, we can know that <\/br>:\n\n<table>\n<thead>\n<tr><th>Machine Learning<\/th><th>Accuracy Score<\/th><th>Top Three Features<\/th><\/tr>\n<\/thead>\n<tbody>\n    <tr><td>Random Forest<\/td><td>87.32<\/td><td>Sex, Class, and Age Category<\/td><\/tr>\n    <tr><td>Decision Tree<\/td><td>87.32<\/td><td>Sex,Class, and Age Category<\/td><\/tr>\n    <tr><td>KNN Classifier<\/td><td>85.63<\/td><td>*<\/td><\/tr>\n    <tr><td>Support Vector Machine (SVM)<\/td><td>82.15<\/td><td>*<\/td><\/tr>\n    <tr><td>Logistic Regression<\/td><td>78.56<\/td><td>Sex,Class, and Age Category<\/td><\/tr>\n    <tr><td>Naive Bayes Statistic<\/td><td>75.87<\/td><td>*<\/td><\/tr>\n<\/tbody>\n<\/table>\n\n\n<br> * = *means that that I cannot predict the feature importance. (Will be updated, if I find it!)* <\/br>\n\n<br> We also can know that **sex, class, and age** are the most three feature that have huge importance on machine learning that we made <\/br>","6c1d723b":"People who stayed on class 1, have higher chance to survived (62.9%) than people from class 2 (47.28%) and class 3 (24.23%).","c198dcdb":"#### Age (Fill the null)","b1fc3e6a":"Based on this data, we could know that:\n<br> 1. In Southampton & Cherbourg, people with higher fare have higher tendency to survive. <\/br>\n<br> 2. In Queenstown, fare are not correlate with survive rate.","a09d1954":"We will drop **Ticket, Fare, Cabin, AgeRange, Age, Name, and PassengerId** column because we don't need it on analysis.","1b7e09fa":"Relationship between **gender**, **class**, and **survived rate**:","094c72f8":"Same as Sibsp, **Parch** distribution are heavily distributed on 0. To make the data more equal, we will change the data into categorical **(0 = Not Have, 1 = Have)**","b3c916aa":"Use (include = ['0']) to analyze categorical data.","e8c7e85a":"Based on data understanding and visualization, we can know that there are several facts that we can know such as:\n<br> a. **Female** have chance more likely to survive than **men** (**Sex** column) <\/br>\n<br> b. column **Pclass** play important role on predicting survival rate <\/br>\n<br> c. People who pay higher fare (especially in **Southampton and Cherbourg**) have higher rate to survive than people who pay lower rate.<\/br>\n<br> d. Having **siblings (SibSp) and Parent\/Spouse(Parch)** have higher tendency to survived.<\/br>\n<br> e. People who most likely unsurvived are **men in age 20-40** <\/br>","6d087a57":"#### Drop Column (Ticket, Fare, Cabin,AgeRange)","aec5d2fb":"#### Gender (Make into 0 = Female, 1 = Male)","857de37b":"Divide the data into train and test data.","347ccc96":"### Support Vector Machine (SVM)","52c12a7f":"### Random Forest ","c28acf75":"### Data Cleaning","baa497d6":"Relationship between class and survived:","1fc082d2":"Based on data above, we can know that age 20 - 40 are the highest rate where most of the people are not survived. Also, if you see critically, you will realize that people below 10 years old have higher rate and opportunities to survive.","e465c02c":"Based on our distribution, **Sibsp** data is heavily distributed on 0 and low distribution on 1-8. Because of that, to make the data more equal **(between distributed and not distributed)**, we will change the data into categorical **(0 = Not have, 1 = Have)**.","aca8ff9e":"From this data, we can know:\n<br> 1. Most people who didn't survived in Titanic are Male on 20 until around 40. <\/br>\n<br> 2. Most people who survived in Titanic are Female around 20 until 40 years. <\/br>","6ac91902":"**Fare Distribution**","98e8509b":"Based on this data, we can know that gender play more important role than class.","686b75f2":"Based on this data, we can know that the highest rate of survival is for people who having 2 **Parch** and 1 **SibSp** and continued by 0 **Parch** and 2 **SibSp**.","669e5e9d":"The goal of using pivoting table is to understand more about relationship between variables that we used.\n\n<br> Several variables that we try to correlate are : <\/br>\n1. gender and Survived rate\n2. Pclass and Survived rate\n3. Gender, Pclass, and Survived Rate\n4. Embarked and Survived Rate\n5. Parch (Parent) and Survived Rate\n6. Parch (Parent), SibSp (Sibling, Spouse) and Survived Rate\n\n<br> In pivoting table, we will only use **train data** because we want to correlate it with survival rate. <\/br>","d778c10e":"### Logistic Regression","10d5a684":"## IMPORT ALL DICTIONARIES THAT WE NEED","4814a314":"Based on this data, we can know that:\n<br> 1. People in **Pclass 1** have higher tendency to survived than die <\/br>\n<br> 2. People in **Pclass 2** have 50\/50% probabilities to survived and die <\/br>\n<br> 3. People in **Pclass 3** have higher tendency to unsurvived than survived <\/br>","c9683526":"#### Embarked (Make into 0 = S, 1 = Q, 2 = C)","e54dcaaf":"Male who embarked from Cherbourg have a higher rate of survived.","a59be093":"###  Pivoting Table Understanding","3fa6aab0":"### Basic Data Understanding","287f7f29":"Based on Gender, 74% female survived and only 18% men survived.","759ebc28":"Relationship between **Embarked** and **Survived Rate**:","16142136":"Let's known about the relationship between class and survived based on Embarked place.","b62d9477":"**Age Distribution**","3d73ef55":"Age and Survived Rate","79a058d4":"Age based on Survived and Pclass","d8ab0ac0":"####  Parch (Divide into 0 = have not or 1 = have)","aff5081f":"Based on the null data, we could know that:\n1. In train data, we have null data in **age, cabin, and embarked**.\n2. In test data, we have null data in **age, cabin, and fare**.","179882b3":"Since ages have some null inside them, we will fill the null with median scores.","b32646da":"We will make the fare divided into 4 categories based on Percentile data:\n<br> a. 0 - 25% (very low) <\/br>\n<br> b. 25 - 50% (low) <\/br>\n<br> c. 50 - 75% (high) <\/br>\n<br> d. 75 - 100% (very high) <\/br>","d684c2cc":"Find the percentile of each data:","0adf6b87":"#### Sibsp (Divide it into 0 = Not Have or 1 = Have)","b3a1afd1":"In order to understand more about the data, we will do:\n1. Basic Data Understanding --> To understand more about what data that we analyze.\n2. Pivoting Data Understanding --> Create a correlation table that correlates between two variables.\n3. Visual Distributions --> Give us more understanding about the data consists of univariate and multivariate graph.\n4. Data Cleaning --> Clean data that we don't need and make clean data for modelling.","72fb5ae6":"Based on explanation, we can know that there is passengerID, Name, Sex, Age, Sibsp (Number of Siblings or Spouse), Parch (Number of Parents\/Children Abroad), Ticket, Fare, Cabin ane Embarked.","717d0ed3":"### Visual Distributions","d558585d":"People who embarked from C(Cherbourg) has the higher opportunity to survive than people who come from Q(Queenstown) and S(Southampton).","96749c98":"#### Age divided (Based on Categories)","85a43603":"# TITANIC MACHINE LEARNING LEARN","81f89deb":"To improve understanding about data, we can divide the data based on sex and gender.","30a34181":"**Parch Distribution**","7eeb9249":"**Conclusion :**\n<br> Based on distribution, we can know that: <\/br>\n1. Train and test distribution data are really simmilar\n2. Most people embarked on Southampton\n3. Male are more dominant than woman on taking the titanic based on gender.\n4. Distribution of **SibSp (Siblings) ,Parch (Parent), and Fare** are extreme positive skew, which means most of passenger didn't bring siblings, parent, and pay a low fare.","bedc5a22":"On April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).","53dc0fab":"#### Correlational Distribution","669c61a8":"#### Fare divided (Based on Categories)","00908813":"Relationship between **Sibsp (Siblings)**, **Parch (Parent)** and **Survived Rate** :","64d1011f":"Since there is 2 null in data embarked and most of the embarked comes from Southampton **(S)**. We will fill the null with the southampton.","e9a6ba35":"### Gaussian Naive Bayes Statistic","d14702c8":"## DATA UNDERSTANDING & PREPARATION","1126b730":"**Gender Distribution**","d0baaf73":"### K Neighbors Classifier","6ecff5ef":"Take train and test data to export it into Jupyter Notebook."}}