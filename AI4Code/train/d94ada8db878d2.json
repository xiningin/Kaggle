{"cell_type":{"181ae71d":"code","97ae6029":"code","6114ab00":"code","cc0ec636":"code","d1adcd9a":"code","9cc30dc6":"code","3adcca21":"code","c791749f":"code","f63c5264":"code","b18c6d32":"markdown","6975fba2":"markdown","ae3f9739":"markdown","12a55b83":"markdown","cbdbfe34":"markdown","a615b14a":"markdown","fa6a5fa8":"markdown","88598328":"markdown","b89d97df":"markdown","706ed9f2":"markdown","656c8af3":"markdown","040bcc70":"markdown","342437ae":"markdown","4c7e78e8":"markdown"},"source":{"181ae71d":"!pip install bs4 -q","97ae6029":"import requests\nfrom bs4 import BeautifulSoup","6114ab00":"def awesome_data(data):\n  name_selec = []\n  link_selec = []\n\n  link = 'https:\/\/github.com\/awesomedata\/awesome-public-datasets'\n  req = requests.get(link)\n  soup = BeautifulSoup(req.content, 'html.parser')\n  html = soup.find_all('a', rel=\"nofollow\")\n  print('\\n\\n-------------------- DATASETS FOUND IN AWESOME PUBLIC DATASETS\\n\\n')\n\n  for i in range(len(html))[8:]:\n    name = (str(html[i]).strip('<\/a>').split('w\">')[1]).lower()\n    link = str(html[i]).split('f=\"')[1].split('\" r')[0]\n    if (data in name):\n      name_selec.append(name)\n      link_selec.append(link)\n    else:\n      name_selec += ''\n      link_selec += ''\n  for j in range(len(name_selec)):\n    if len(name_selec) < 1:\n      print('Datasets not found')\n    else:\n      print(f'\\n{name_selec[j]}\\n{link_selec[j]}\\n')\n","cc0ec636":"def uci_dados(data):\n  dataset = data\n  dataset_clean = dataset.replace(' ', '+').lower()\n\n  link = f'https:\/\/archive.ics.uci.edu\/ml\/datasets\/{dataset_clean}'\n  req = requests.get(link)\n  soup = BeautifulSoup(req.content, 'html.parser')\n\n  dataset_html = soup.find_all('span', class_='heading')\n  table = soup.find_all('td')\n  warning = soup.find_all('p')\n  print('\\n\\n-------------------- DATASETS FOUND IN UCI\\n\\n')\n  try:\n    name = str(dataset_html).split('b>')[1].split('<\/')[0]\n    charac = str(table).split('\"normal\">')[46].split('<\/p>')[0]\n  except IndexError:\n    name = ''\n    charac = ''\n    link = ''\n    print('')\n\n  print(f'\\n{name} ({link})\\n{charac}')\n\n","d1adcd9a":"def data_google(data):\n  dataset = data\n  dataset_clean = dataset.replace(' ', '+').lower()\n  link = f'https:\/\/datasetsearch.research.google.com\/search?query={dataset_clean}'\n\n  req = requests.get(link)\n  soup = BeautifulSoup(req.content, 'html.parser')\n\n  name = soup.find_all('h1',  class_=\"iKH1Bc\")\n  site = soup.find_all('li', class_=\"iW1HZe\")\n  print('\\n\\n--------------------DATASETS FOUND IN GOOGLE DATA SEARCH\\n\\n')\n  print(f'Link to acess this and others datasets:{link}')\n  for i in range(5):\n    name_clean = str(name[i]).split('\">')[1].split('<\/')[0]\n    site_clean = str(site[i]).split('\">')[1].split('<')[0]\n    print(f'\\n{name_clean}\\n Dataset source: {site_clean}\\n')\n","9cc30dc6":"def search_data(dataset):\n  awesome_data(dataset)\n  uci_dados(dataset)\n  data_google(dataset)","3adcca21":"search_data('iris')","c791749f":"search_data('football')","f63c5264":"search_data('earthquake')","b18c6d32":"# Build our function","6975fba2":"* Iris\n\n* Football\n\n* Earthquake","ae3f9739":"## Dataset Research Google\n\n![image.png](attachment:image.png)","12a55b83":"## UCI - Machine Learning\n\n![image.png](attachment:image.png)","cbdbfe34":"# Datasites\n\nWe will to search the datasets in 3 differents sites:\n* Awesome Public Datasets\n* UCI Machine Learning\n* Google Data Search","a615b14a":"# About Libraries","fa6a5fa8":"![Search%20datasets.png](attachment:Search%20datasets.png)","88598328":"# Don't forget to upvote","b89d97df":"## BeautifulSoup\n\n![bs.png](attachment:bs.png)\n\nBeautifulSoup is a library used for make web scraping in websites using a easy and short syntax. With it we can get phrases, words, numbers, images, and tables","706ed9f2":"## Requests\n\n![70-702215_building-with-python-requests-python-requests-logo.png](attachment:70-702215_building-with-python-requests-python-requests-logo.png)\n\nIt is a library used to requisition websites, and download a web page","656c8af3":"Searching for datasets on different sites can be a tiring job, thinking about it, I developed an algorithm that searches for a dataset on 3 different sites. For this, we will use the \"requests\" and \"BeautifulSoup\"\n\n**In this tutorial, I will build a script to search datasets.**","040bcc70":"# Testing","342437ae":"# Step-by-step\n\n* Libraries\n* Datasites\n* Building our function\n* Testing","4c7e78e8":"## Awesome public datasets\n\n![image.png](attachment:image.png)"}}