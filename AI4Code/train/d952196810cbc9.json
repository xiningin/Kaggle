{"cell_type":{"5216b1ff":"code","4655a401":"code","43dcdf8c":"code","3778cb8c":"code","5e3c65a1":"code","5a804a51":"code","826d1dab":"code","c771a614":"code","cd618113":"code","56ae8263":"code","53939b3a":"code","2bc58cd3":"code","e0334b5c":"code","31265c74":"code","f882af75":"code","868b7e33":"markdown","75b75d1f":"markdown","fb4476b1":"markdown","134879c3":"markdown","cb876b19":"markdown","0b661e3f":"markdown","56913a1a":"markdown","0657db5b":"markdown","61b1f71f":"markdown","7796a3c7":"markdown","d627b9b0":"markdown","7bc57926":"markdown","6a686034":"markdown","c7d34d30":"markdown","5d183ae4":"markdown"},"source":{"5216b1ff":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4655a401":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","43dcdf8c":"data=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ndata_test=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ndata.head()  ","3778cb8c":"sns.countplot(data.label)\nprint(data.label.value_counts())","5e3c65a1":"X=data.copy()\nX.drop(labels=\"label\",axis=1,inplace=True)\ndef prep(x):\n    X=np.array(x).reshape(x.shape[0],28,28,1).astype('float32')\n    return X\nX=prep(X)    ","5a804a51":"plt.figure(figsize=(20,5))\nfor r in range(0,20):\n    plt.subplot(2,10,r+1)\n    f= plt.imshow(X[r].reshape(28,28))\n    plt.title(data.label[r])\n    f.axes.get_xaxis().set_visible(False)\n    f.axes.get_yaxis().set_visible(False)\nplt.show()    ","826d1dab":"Y=pd.get_dummies(data.label)\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)","c771a614":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers","cd618113":"model=keras.Sequential([\n    layers.Conv2D(input_shape=[28,28,1],filters=64,kernel_size=3,strides=1,padding='same',activation='relu'),\n    layers.Conv2D(filters=64,kernel_size=3,strides=1,activation='relu'),\n    layers.MaxPool2D(pool_size=2),\n    layers.Conv2D(filters=56,kernel_size=3,strides=1,padding='same',activation='relu'),\n    layers.MaxPool2D(pool_size=2),\n    layers.Flatten(),\n    layers.Dense(50,activation='relu'),\n    layers.Dropout(0.20),\n    layers.Dense(30,activation='relu'),\n    layers.Dense(10,activation='sigmoid'),\n])\nmodel.summary()","56ae8263":"model.compile(\n   loss='CategoricalCrossentropy',\n    optimizer='adam',\n    metrics=['categorical_accuracy'],\n   )","53939b3a":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=10,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\nhistory = model.fit(\n    X_train, Y_train,\n    validation_data=(X_test, Y_test),\n    batch_size=64,\n    epochs=1000,\n    callbacks=[early_stopping],\n     # hide the output because we have so many epochs\n)","2bc58cd3":"history_df = pd.DataFrame(history.history)\n# Start the plot at epoch 5\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nhistory_df.loc[:, ['categorical_accuracy', 'val_categorical_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['val_loss'].min(), \n              history_df['val_categorical_accuracy'].max()))","e0334b5c":"data_test=prep(data_test)\npred=model.predict_classes(data_test)","31265c74":"plt.figure(figsize=(20,5))\nfor r in range(0,20):\n    plt.subplot(2,10,r+1)\n    f= plt.imshow(data_test[r].reshape(28,28))\n    plt.title(pred[r])\n    f.axes.get_xaxis().set_visible(False)\n    f.axes.get_yaxis().set_visible(False)\nplt.show()    \n    ","f882af75":"final_sub=pd.DataFrame()\nfinal_sub['ImageId']=range(1,len(pred)+1)\nfinal_sub['Label']=pred\nfinal_sub.to_csv(\"DigitRecognizer_CNN.csv\",index=False)","868b7e33":"## Difining our model<br>\n### Model consists of:-\n* 1st Convolutional layer\n* 2nd Convolutional layer\n* Pooling layer\n* 3rd Convolutional layer\n* Pooling layer\n* Flatten layer\n* Dense layer of 50 neurons\n* Dropout layer\n* Dense layer of 30 neurons\n* output layer of 10 neurons","75b75d1f":"## Difining optimizer and loss for our model","fb4476b1":"## Importing Keras","134879c3":"## Hold out validation ","cb876b19":"## Viewing first 20 images","0b661e3f":"###  **reading csv file**","56913a1a":"## Let's first visualize before submitting","0657db5b":"# Digit Recognizer using CNN\n\n**This is a novice's notebook**<br>\nperhaps my first submission using cnn.\nAll the contributers, Experts, masters, grandmasters out their please review this notebook and provide valuable feedback for further improvement. ","61b1f71f":"## Training the model and using early stopping to stop our model from overfitting. ","7796a3c7":"## Pridction for submission","d627b9b0":"## Importing Libraries for data exploration","7bc57926":"## The result seems satisfactory<br>\n## Let's make final submission\n","6a686034":"## Visualising the distribution of data","c7d34d30":"## Defining a pipeline for data preprocessing. ","5d183ae4":"## Plotting the loss and accuracy"}}