{"cell_type":{"589d2b36":"code","ed65110b":"code","bd51087b":"code","711afac3":"code","0b6fb694":"code","861c9eb1":"code","c2bacae2":"code","5285f773":"code","92b243d1":"code","6f5676c6":"code","c6957a03":"code","b61f718c":"code","e1d54cb5":"code","7804c21d":"code","8ab0e231":"code","41214128":"code","d7751265":"code","94cc0ee0":"code","9dd6d133":"code","32f6042d":"code","b40c59cd":"code","f2198001":"code","bb45e561":"code","82bb5044":"code","5efb6288":"code","049f4c74":"code","68c8657b":"code","f29dac8e":"code","67f9c630":"code","a63b162c":"code","40fec82b":"code","fffde271":"code","eba52474":"code","e40e546a":"code","a5ff9687":"code","31dbac77":"code","63e946c4":"code","025ecf75":"code","5f4f558b":"code","d6473ecc":"code","caeeff58":"code","d538c17e":"code","f0ef7668":"code","e14912e4":"code","f06bd06e":"code","6e1ea34d":"code","95e4ecbb":"code","cc0680aa":"code","a98de1c6":"code","a9b754a4":"code","0075f1bb":"code","09b7d7bb":"code","d346f4ca":"code","da139aad":"code","37025175":"code","263bd39f":"code","f3bea4c2":"code","93013bfa":"code","76c25376":"code","e589c226":"code","4eb4e1c4":"code","959d2a5f":"code","7e476e6c":"code","5bc3f502":"code","10340063":"code","3e337be7":"code","1cf6a6ca":"code","b5c2919c":"code","3c62e725":"code","88432ce0":"code","31ba7e89":"code","7fe8d825":"code","5f4d2d54":"code","adca02e7":"code","2fad0f67":"code","91b07ba0":"code","6acbc0b2":"code","408be3f2":"code","1d75912e":"code","a4b63205":"code","ef7cf6d2":"code","4d9d895d":"code","3a0715f0":"code","d4ef6d50":"code","93242afe":"code","37f673db":"code","30ddb522":"code","f9b70f45":"code","bae36daf":"code","54d6f573":"code","9913fe11":"code","4b927bff":"code","4c02dc2d":"code","c443cb80":"code","7c8f1717":"code","83bdfc40":"code","bd94821f":"code","86a92117":"code","6e7b9396":"code","a9be9ff1":"code","56d4dea0":"code","0c603f44":"code","d7a3af40":"code","27362950":"code","ed690264":"code","0473bdd7":"code","ba1df1ac":"code","d67ebba9":"code","fd51c2b2":"markdown","88cff009":"markdown","184c31cb":"markdown","cdbf2066":"markdown","cf720fa3":"markdown","4d5ed442":"markdown","6b279f53":"markdown","8c175ef1":"markdown","92753dd5":"markdown","c6270488":"markdown","5353b889":"markdown","a03f0281":"markdown","bc3cd7e3":"markdown","b6f6e0ae":"markdown","2c33d66c":"markdown","d3fd38de":"markdown","ba6759f7":"markdown"},"source":{"589d2b36":"#!pip install xgboost","ed65110b":"# In this mini-project im trying to use machine learning algorithms to train an optimum model for prediction\n# (This is my answer for an exercise in ML course at Maktabkhooneh.org)\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport pylab as pl\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split","bd51087b":"titanic_train = pd.read_csv('..\/input\/data-science-day1-titanic\/DSB_Day1_Titanic_train.csv')","711afac3":"titanic_test = pd.read_csv('..\/input\/titaniccsv\/test.csv')","0b6fb694":"titanic_train.info()","861c9eb1":"titanic_train.describe()","c2bacae2":"titanic_train.head()","5285f773":"titanic_train['Embarked'].value_counts(normalize = True)*100","92b243d1":"titanic_train['Cabin'].value_counts(normalize = True)*100","6f5676c6":"titanic_train['Embarked'].value_counts(normalize = True)*100","c6957a03":"titanic_train.isnull().sum()","b61f718c":"titanic_test.isnull().sum()","e1d54cb5":"# Label Encoding for train Data\ntitanic_train['Sex']=titanic_train['Sex'].map({'male':1,'female':0})\ntitanic_train['Embarked']=titanic_train['Embarked'].map({'S':1,'C':2,'Q':3})\n\n# Label Encoding for test Data\ntitanic_test['Sex']=titanic_test['Sex'].map({'male':1,'female':0})\ntitanic_test['Embarked']=titanic_test['Embarked'].map({'S':1,'C':2,'Q':3})","7804c21d":"titanic_train.head()","8ab0e231":"titanic_test.head()","41214128":"titanic_train['Age']=titanic_train['Age'].replace({np.nan:titanic_train['Age'].mean()})","d7751265":"titanic_train = titanic_train.drop(['Cabin'], axis = 1)","94cc0ee0":"titanic_test['Age']=titanic_test['Age'].replace({np.nan:titanic_test['Age'].mean()})\ntitanic_test = titanic_test.drop(['Cabin'], axis = 1)","9dd6d133":"titanic_train.isnull().sum()","32f6042d":"# summarize the shape of the raw data\nprint(\"Before:\",titanic_train.shape)\n\n# drop rows with missing values\ntitanic_train.dropna(inplace=True)\n\n# summarize the shape of the data with missing rows removed\nprint(\"After:\",titanic_train.shape)","b40c59cd":"titanic_test.isnull().sum()","f2198001":"# summarize the shape of the raw data\nprint(\"Before:\",titanic_test.shape)\n\n# drop rows with missing values\ntitanic_test.dropna(inplace=True)\n\n# summarize the shape of the data with missing rows removed\nprint(\"After:\",titanic_test.shape)","bb45e561":"sns.catplot(x=\"Sex\", kind=\"count\", data=titanic_train)\n# 1 = Male \n# 0 = Female","82bb5044":"sns.catplot(x=\"Survived\", kind=\"count\", data=titanic_train)","5efb6288":"sns.displot(titanic_train, x=\"Fare\", kind=\"kde\" , hue = 'Sex')\n# 1 = Male \n# 0 = Female","049f4c74":"sns.catplot(x=\"Survived\", y=\"Fare\", hue=\"Sex\", kind=\"swarm\", data=titanic_train)\n# 1 = Male \n# 0 = Female","68c8657b":"sns.catplot(x=\"Age\", y=\"Fare\", hue=\"Sex\" , kind=\"point\", data=titanic_train , height = 7 , aspect = 4)","f29dac8e":"sns.relplot(x=\"SibSp\", y=\"Age\", hue=\"Survived\", data=titanic_train)\n","67f9c630":"X = titanic_train[['Fare']]\nY = titanic_train[['Survived']]","a63b162c":"X_train, X_test , Y_train , Y_test = train_test_split(X,Y,test_size=0.3,random_state=4)","40fec82b":"t_corr = titanic_train.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(t_corr, annot=True, annot_kws={'size':8}, cmap='Reds' )","fffde271":"X.head()","eba52474":"Y.tail()","e40e546a":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","a5ff9687":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, Y_train)","31dbac77":"Y_pred = log_reg.predict(X_test)","63e946c4":"X_test","025ecf75":"print('The accuracy of Logistic Regression is: ', (metrics.accuracy_score(Y_test, Y_pred)))","5f4f558b":"Y_test.to_numpy()","d6473ecc":"Y_pred.shape # just to stop some error","caeeff58":"Y_pred = Y_pred.reshape(267,1)\nerror = (Y_pred) - (Y_test)","d538c17e":"sns.histplot(error)","f0ef7668":"knn = KNeighborsClassifier(n_neighbors = 13) \nknn.fit(X_train, Y_train)","e14912e4":"Y_pred = knn.predict(X_test)","f06bd06e":"knn.score(X_train,Y_train)","6e1ea34d":"knn.score(X_test, Y_test)","95e4ecbb":"error_rate = []\nfor i in range(1,50):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,Y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != Y_test.values))","cc0680aa":"plt.figure(figsize=(18,6))\nplt.plot(range(1,50),error_rate,color='red', marker='o',\n         markerfacecolor='black', markersize=10)\nplt.xlabel('K Value')\nplt.ylabel('Error Rate')\n# it seems to be 13 !","a98de1c6":"print(classification_report(Y_test, Y_pred))","a9b754a4":"conf_m =confusion_matrix(Y_test, Y_pred)\nsns.heatmap(conf_m, square=True , annot=True)","0075f1bb":"# At this point we are going back to run the load data lines , again :","09b7d7bb":"titanic_train","d346f4ca":"X = titanic_train.drop(['Survived','Ticket','Name','PassengerId'] , axis = 1)\nY = titanic_train['Survived']","da139aad":"X","37025175":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)","263bd39f":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","f3bea4c2":"X_train","93013bfa":"classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, Y_train)","76c25376":"Y_pred = classifier.predict(X_test)","e589c226":"cm = confusion_matrix(Y_test, Y_pred)\nsns.heatmap(cm , square=True , annot=True)\naccuracy_score(Y_test, Y_pred)","4eb4e1c4":"regressor = DecisionTreeRegressor(random_state = 0)\nregressor.fit(X, Y)","959d2a5f":"X = sc.fit_transform(X)","7e476e6c":"Y_pred.shape","5bc3f502":"Error = (Y_pred - Y_test)","10340063":"sns.displot(Error)","3e337be7":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","1cf6a6ca":"rand_fc = RandomForestClassifier(criterion = 'entropy', random_state = 42)\nrand_fc.fit(X_train, Y_train)","b5c2919c":"# Evaluating on Training set\nrand_fc_pred_train = rand_fc.predict(X_train)\nprint('Training Set Evaluation F1-Score=>',f1_score(Y_train,rand_fc_pred_train))","3c62e725":"rand_fc.feature_importances_\nfeature_importance=pd.DataFrame({'rand_fc':rand_fc.feature_importances_},index=titanic_train.drop(columns=['Survived','Ticket','Name','PassengerId']).columns)\nfeature_importance.sort_values(by='rand_fc',ascending=True,inplace=True)\n\nindex = np.arange(len(feature_importance))\nfig, ax = plt.subplots(figsize=(18,8))\nrand_fc_feature=ax.barh(index,feature_importance['rand_fc'],0.4,color='Green',label='Random Forest')\nax.set(yticks=index+0.4,yticklabels=feature_importance.index)\n\nax.legend()\nplt.show()","88432ce0":"X_new = titanic_train[['Age']]\nY_new = titanic_train['Survived']","31ba7e89":"X_new","7fe8d825":"X_new.shape","5f4d2d54":"X_new = X_new.values.reshape(889,1)","adca02e7":"Y_new = Y_new.values.reshape(889,1)","2fad0f67":"Y_new.shape","91b07ba0":"ranf_regressor = RandomForestRegressor(n_estimators = 100000, random_state = 0)\nranf_regressor.fit(X_new,Y_new)","6acbc0b2":"# testing\nY_new_pred=ranf_regressor.predict([[15]])\nY_new_pred","408be3f2":"#higher resolution graph\nX_new_grid = np.arange(min(X_new),max(X_new),1)\nX_new_grid = X_new_grid.reshape(len(X_new_grid),1) \n  \nplt.scatter(X_new,Y_new, color='red') #plotting real points\nplt.plot(X_new_grid, ranf_regressor.predict(X_new_grid),color='blue') #plotting for predict points\n  \nplt.title(\"Random Forest\")\nplt.xlabel('Age')\nplt.ylabel('Survive')\nplt.show()","1d75912e":"X = titanic_train['Fare']\nY = titanic_train['Survived']","a4b63205":"X = X.values.reshape(889,1)","ef7cf6d2":"X","4d9d895d":"Y=Y.values.reshape(889,1)","3a0715f0":"Y.shape","d4ef6d50":"X.shape","93242afe":"sc = StandardScaler()\nX = sc.fit_transform(X)\nY = sc.fit_transform(Y)","37f673db":"svr_rbf = SVR(kernel='rbf', C=1e4, gamma=0.1)\nsvr_lin = SVR(kernel='linear', C=1e4)\nsvr_poly = SVR(kernel='poly', C=1e4, degree=2)\ny_rbf = svr_rbf.fit(X, Y).predict(X)\ny_lin = svr_lin.fit(X, Y).predict(X)\ny_poly = svr_poly.fit(X, Y).predict(X)","30ddb522":"pl.scatter(X, Y, c='k', label='data')\npl.plot(X, y_rbf, c='g', label='RBF model')\npl.plot(X, y_lin, c='r', label='Linear model')\npl.plot(X, y_poly, c='b', label='Polynomial model')\npl.xlabel('Fare')\npl.ylabel('Survived')\npl.title('Support Vector Regression')\npl.legend()\npl.show()","f9b70f45":"X = titanic_train.drop(['Survived','Ticket','Name','PassengerId'] , axis = 1)\nY = titanic_train['Survived']","bae36daf":"X","54d6f573":"sc = StandardScaler()\nX = sc.fit_transform(X)\nX","9913fe11":"Y = Y.values.reshape(889,1)\nY.shape","4b927bff":"Y = sc.fit_transform(Y)","4c02dc2d":"# spliting the dataset for training and testing \nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25)","c443cb80":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\nprint(X_train.shape)\nprint(X_test.shape)","7c8f1717":"model = XGBClassifier()\nmodel.fit(X_train, Y_train)","83bdfc40":"Y_pred = model.predict(X_test)","bd94821f":"error = Y_pred - Y_test","86a92117":"sns.displot(error)","6e7b9396":"X","a9be9ff1":"reg_mod = xgb.XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    subsample=0.85,\n    colsample_bytree=1, \n    max_depth=13,\n    gamma=0,\n)\nreg_mod.fit(X_train, Y_train)","56d4dea0":"scores = cross_val_score(reg_mod, X_train, Y_train,cv=10)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())","0c603f44":"reg_mod.fit(X_train,Y_train)\n\npredictions = reg_mod.predict(X_test)","d7a3af40":"rmse = np.sqrt(mean_squared_error(Y_test, predictions))\nprint(\"RMSE: %f\" % (rmse))","27362950":"r2 = np.sqrt(r2_score(Y_test, predictions))\nprint(\"R_Squared Score : %f\" % (r2))","ed690264":"plt.figure(figsize=(40, 7), dpi=320)\nx_ax = range(len(Y_test))\nplt.plot(x_ax, Y_test, label=\"test\")\nplt.plot(x_ax, predictions, label=\"predict\")\nplt.title(\"Titanic_Data(predicting passengers survival)\")\nplt.legend()\nplt.show()\n# orange = predicted value\n# blue = actual_value","0473bdd7":"# parameters = [{'n_estimators': [100 ,200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000], 'learning_rate': [0.1 , 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] , ' subsample': [0.1 , 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] , 'colsample_bytree':[0.1 , 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] , 'max_depth':[1 , 2 , 3, 4, 5, 6, 7, 8, 9, 10 , 11 ,12 ,13, 14, 15, 16, 17, 18, 19, 20]}]\n# ","ba1df1ac":"# we could use (GridSearch) the upper line to find the best hyper parameters ! but for now ...","d67ebba9":"# M.Hossein Hashemi","fd51c2b2":"# KNN","88cff009":"## Importing the libraries","184c31cb":"## EDA","cdbf2066":"# Decision Tree Regression","cf720fa3":"# Random forest Regression","4d5ed442":"# Logistic Regression","6b279f53":"## Strorytelling - Visualization","8c175ef1":"# Decision Tree","92753dd5":"<img src = \"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/3136\/logos\/front_page.png\" width=50%>","c6270488":"## Data Preprocessing","5353b889":"# Random forest","a03f0281":"# XG Boost","bc3cd7e3":"# SVR","b6f6e0ae":"<div class=\"alert alert-block alert-success\">\n    <h1 align=\"center\">Machine Learning in Python<\/h1>\n    <h3 align=\"center\">Mini Project 3 - Titanic<\/h3>\n<\/div>","2c33d66c":"## Load and Prepare Data","d3fd38de":"## Train your model (Classification)","ba6759f7":"# XGBoost regressor"}}