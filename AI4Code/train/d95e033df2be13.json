{"cell_type":{"15835751":"code","1d135111":"code","a50357f4":"code","d5642bd9":"code","13b5a9bf":"code","75ad456e":"code","d25b3768":"code","9a34ad28":"code","205290ba":"code","69f560b8":"code","0c22613c":"code","75fcd4c9":"code","9412b82c":"code","64f27d4b":"code","2df8b6a6":"code","a69320df":"code","14de7c98":"code","a1d0ac95":"code","805fe8f3":"code","d32e9e05":"code","c7fdf5a8":"code","64da37fc":"code","2a90300c":"code","5ddfea97":"code","1ecb8766":"code","dc08aa39":"code","de37c901":"code","4f8d40e4":"code","0287d1a3":"code","22ef1634":"code","3dc14993":"code","fffadcfc":"code","6e6c8f6e":"code","68ddecde":"code","598450a2":"code","3fbfe890":"code","0e2dfbbd":"code","74f96c65":"markdown","847b3a04":"markdown","1d776fb2":"markdown","b85867ef":"markdown","427a8122":"markdown","68f98d6d":"markdown","2abb8a93":"markdown","10555807":"markdown","d68d819b":"markdown","26072e08":"markdown","19786d22":"markdown","f2daa02c":"markdown","0c336cae":"markdown","9698f61b":"markdown","b7404ab1":"markdown","af528826":"markdown","da7ef1ce":"markdown","734fa98b":"markdown","58aebbc8":"markdown","dff76d40":"markdown","71e7a7f4":"markdown","c3c49e7e":"markdown","6fcf30fd":"markdown","85cca21a":"markdown","ae68205d":"markdown","6d5b9b68":"markdown","5a12dd32":"markdown","b8d691c7":"markdown","5fbbc52d":"markdown","e76e5113":"markdown","b9f35679":"markdown","982be880":"markdown","6542e00b":"markdown","a7676145":"markdown","b72faf8d":"markdown","7b38a9ee":"markdown","1dee23be":"markdown"},"source":{"15835751":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline","1d135111":"!wget -O loan_train.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/loan_train.csv","a50357f4":"df = pd.read_csv('loan_train.csv')\ndf.head()","d5642bd9":"df.shape","13b5a9bf":"df['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf.head()","75ad456e":"df['loan_status'].value_counts()","d25b3768":"# notice: installing seaborn might takes a few minutes\n!conda install -c anaconda seaborn -y","9a34ad28":"import seaborn as sns\n\nbins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","205290ba":"bins = np.linspace(df.age.min(), df.age.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'age', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","69f560b8":"df['dayofweek'] = df['effective_date'].dt.dayofweek\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n","0c22613c":"df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ndf.head()","75fcd4c9":"df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)","9412b82c":"df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf.head()","64f27d4b":"df.groupby(['education'])['loan_status'].value_counts(normalize=True)","2df8b6a6":"df[['Principal','terms','age','Gender','education']].head()","a69320df":"Feature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head()\n","14de7c98":"X = Feature\nX[0:5]","a1d0ac95":"y = df['loan_status'].values\ny[0:5]","805fe8f3":"X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]","d32e9e05":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","c7fdf5a8":"from sklearn.neighbors import KNeighborsClassifier\nk = 6\n\nneighK6 = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneighK6\n \nyhat = neighK6.predict(X_test)\nyhat[0:5]\n\nfrom sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neighK6.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))","64da37fc":"Ks = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\n\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)\/np.sqrt(yhat.shape[0])\n\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+\/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()\nprint( \"Best accuracy:\", mean_acc.max(), \"k=\", mean_acc.argmax()+1)","2a90300c":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nX_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)\n#Modelling\nTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6)\nTree","5ddfea97":"Tree.fit(X_trainset,y_trainset)","1ecb8766":"predTree = Tree.predict(X_testset)\nprint (predTree [0:5])\nprint (y_testset [0:5])\n\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n\nprint(\"Accuracy: \", metrics.accuracy_score(y_testset, predTree))\n\n\n!conda install -c conda-forge pydotplus -y\n!conda install -c conda-forge python-graphviz -y\nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\nfrom sklearn.externals.six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline \ndot_data = StringIO()\nfilename = \"loan.png\"\nfeatureNames = df.columns[0:8]\ntargetNames = df['loan_status'].unique().tolist()\nout=tree.export_graphviz(Tree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_trainset), filled=True,  special_characters=True,rotate=False)  \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')","dc08aa39":"df.dtypes\ndf = df[pd.to_numeric(df['education'], errors='coerce').notnull()]\ndf['education'] = df['education'].astype('int')\ndf.dtypes\n\nfrom sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train)","de37c901":"yhat = clf.predict(X_test)\nyhat [0:5]\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools","4f8d40e4":"!pip install scikit-learn==0.22","0287d1a3":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\ncnf_matrix = confusion_matrix(y_test, yhat, labels=['PAIDOFF','COLLECTION'])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat))\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['PAIDOFF','COLLECTION'],normalize= False,  title='Confusion matrix')\n\nfrom sklearn.metrics import f1_score\nf1_score(y_test, yhat, average='weighted',pos_label=\"PAIDOFF\")\n\nfrom sklearn.metrics import jaccard_score\njaccard_score(y_test, yhat)","22ef1634":"df = df[['loan_status', 'Principal', 'terms', 'effective_date', 'due_date', 'age', 'education', 'Gender']]\ndf['loan_status'] = df['loan_status'].astype('int')\n\nfrom sklearn import preprocessing\nX = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLogR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nLogR","3dc14993":"yhat = LogR.predict(X_test)\nyhat\nyhat_prob = LogR.predict_proba(X_test)\nyhat_prob","fffadcfc":"from sklearn.metrics import jaccard_score\njaccard_score(y_test, yhat)\nfrom sklearn.metrics import log_loss\nlog_loss(y_test, yhat_prob)","6e6c8f6e":"from sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss","68ddecde":"!wget -O loan_test.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/loan_test.csv","598450a2":"test_df = pd.read_csv('loan_test.csv')\ntest_df.head()","3fbfe890":"X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]\nY = test_df['loan_status'].values\nY[0:5]","0e2dfbbd":"#test the KNN algorithm already trained with K=6\nyhatKNN=neigh.predict(X)\nKNNJaccard = jaccard_score(y, yhatKNN)\nKNNF1 = f1_score(y, yhatKNN, average='weighted')\nprint(\"Avg F1-score: %.2f\" % KNNF1 )\nprint(\"KNN Jaccard Score: %.2f\" % KNNJaccard)\n\n\nyhatDEC = Tree.predict(X)\nDTJaccard = jaccard_score(y, yhatDEC)\nDTF1 = f1_score(y, yhatDEC, average='weighted')\nprint(\"Avg F1-score: %.2f\" % DTF1 )\nprint(\"Decision Tree Jaccard Score: %.2f\" % DTJaccard)\n\nyhatSVM=clf.predict(X)\nSVMJaccard = jaccard_score(y, yhatSVM)\nSVMF1 = f1_score(y, yhatSVM, average='weighted')\nprint(\"Avg F1-score: %.2f\" % SVMF1)\nprint(\"SVM Jaccard score: %.2f\" % SVMJaccard)\n\nyhatLOG = LogR.predict(X)\nyhatLOGproba = LogR.predict_proba(X)\nLogRJaccard = jaccard_score(y, yhatLOG)\nLogRF1 = f1_score(y, yhatLOG, average='weighted')\nLogloss = log_loss(y, yhatLOGproba)\nprint(\"LogLoss: : %.2f\" % Logloss)\nprint(\"Avg F1-score: %.4f\" % LogRF1)\nprint(\"LOG Jaccard score: %.4f\" % LogRJaccard)","74f96c65":"We load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n\nLets first load required libraries:","847b3a04":"### Lets look at the day of the week people get the loan ","1d776fb2":"Lets download the dataset","b85867ef":"Data Standardization give data zero mean and unit variance (technically should be done after train test split )","427a8122":"## Normalize Data ","68f98d6d":"# K Nearest Neighbor(KNN)\nNotice: You should find the best k to build the model with the best accuracy.  \n**warning:** You should not use the __loan_test.csv__ for finding the best k, however, you can split your train_loan.csv into train and test to find the best __k__.","2abb8a93":"Let\u2019s see how many of each class is in our data set ","10555807":"First, download and load the test set:","d68d819b":"## Convert Categorical features to numerical values","26072e08":"Lets defind feature sets, X:","19786d22":"# Classification ","f2daa02c":"### About dataset","0c336cae":"What are our lables?","9698f61b":"# Decision Tree","b7404ab1":"# Data visualization and pre-processing\n\n","af528826":"### Convert to date time object ","da7ef1ce":"| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | 0.79    | 0.78     | NA      |\n| Decision Tree      | 0.79    | 0.78     | NA      |\n| SVM                | 0.77    | 0.76     | NA      |\n| LogisticRegression | 0.7428  | 0.7199   | 0.56    |","734fa98b":"# Pre-processing:  Feature selection\/extraction","58aebbc8":"# Support Vector Machine","dff76d40":"Lets look at gender:","71e7a7f4":"Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\nYou should use the following algorithm:\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n\n\n__ Notice:__ \n- You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n- You should include the code of the algorithm in the following cells.","c3c49e7e":"86 % of female pay there loans while only 73 % of males pay there loan\n","6fcf30fd":"We see that people who get the loan at the end of the week dont pay it off, so lets use Feature binarization to set a threshold values less then day 4 ","85cca21a":"### Load Test set for evaluation ","ae68205d":"# Report\nYou should be able to report the accuracy of the built model using different evaluation metrics:","6d5b9b68":"Lets convert male to 0 and female to 1:\n","5a12dd32":"<h1 align=\"center\"><font size=\"5\">Classification with Python<\/font><\/h1>","b8d691c7":"Lets plot some columns to underestand data better:","5fbbc52d":"260 people have paid off the loan on time while 86 have gone into collection \n","e76e5113":"## One Hot Encoding  \n#### How about education?","b9f35679":"This dataset is about past loans. The __Loan_train.csv__ data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n\n| Field          | Description                                                                           |\n|----------------|---------------------------------------------------------------------------------------|\n| Loan_status    | Whether a loan is paid off on in collection                                           |\n| Principal      | Basic principal loan amount at the                                                    |\n| Terms          | Origination terms which can be weekly (7 days), biweekly, and monthly payoff schedule |\n| Effective_date | When the loan got originated and took effects                                         |\n| Due_date       | Since it\u2019s one-time payoff schedule, each loan has one single due date                |\n| Age            | Age of applicant                                                                      |\n| Education      | Education of applicant                                                                |\n| Gender         | The gender of applicant                                                               |","982be880":"#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame ","6542e00b":"### Load Data From CSV File  ","a7676145":"# Logistic Regression","b72faf8d":"# Model Evaluation using Test set","7b38a9ee":"### Feature selection","1dee23be":"#### Feature befor One Hot Encoding"}}