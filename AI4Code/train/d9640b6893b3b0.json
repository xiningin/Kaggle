{"cell_type":{"d40f1fd0":"code","adf2aa9c":"code","df09d348":"code","f380ca74":"code","f71d27c1":"code","ad5d2af5":"code","16ec811d":"code","48786901":"code","2420afd8":"code","2d59c81d":"code","9d7dfac8":"code","0068ee85":"code","738988dc":"code","0a002fdd":"code","6c93e803":"code","31d52d7e":"code","95ee74d0":"code","7a36696a":"code","588e1901":"code","bf675d95":"code","d569517d":"markdown","c7692b1c":"markdown","1ca70c79":"markdown","5078ea0f":"markdown","56001196":"markdown","60e43c4c":"markdown","e29bc6d0":"markdown","9c6597e7":"markdown"},"source":{"d40f1fd0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","adf2aa9c":"import matplotlib.pyplot as plt\ndata=pd.read_csv('\/kaggle\/input\/churn-modellingcsv\/Churn_Modelling.csv')","df09d348":"X=data.iloc[:,3:13]\ny=data.iloc[:,13]","f380ca74":"geography=pd.get_dummies(X['Geography'],drop_first=True)\ngender=pd.get_dummies(X['Gender'],drop_first=True)","f71d27c1":"X=pd.concat([X,geography,gender],axis=1)","ad5d2af5":"X=X.drop(['Geography','Gender'],axis=1)","16ec811d":"X.head()","48786901":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","2420afd8":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n","2d59c81d":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom keras.layers import Dropout","9d7dfac8":"classifier=Sequential()\n#adding first input hidden layer of neurons\nclassifier.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu',input_dim=11))\n#adding 2nd layer\nclassifier.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu'))\n#adding 3rd layer\nclassifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n\n","0068ee85":"classifier.summary()","738988dc":"# Compiling the ANN\nclassifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","0a002fdd":"model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 20, nb_epoch = 100)\n","6c93e803":"print(model_history.history.keys())","31d52d7e":"plt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","95ee74d0":"plt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","7a36696a":"y_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Calculate the Accuracy\nfrom sklearn.metrics import accuracy_score\nscore=accuracy_score(y_pred,y_test)","588e1901":"cm","bf675d95":"score","d569517d":"part 3 of our model in this we will be making predictions","c7692b1c":"**let make an ANN for our data **","1ca70c79":"**this is what our neural net look like**","5078ea0f":"**using standard scaler to scaler down the data as in neural network distance is involved that is why we have to scale our values**","56001196":"wrangling the data. getting geography and gender in numerical varibale","60e43c4c":"importing required libaries","e29bc6d0":"*splitting the data*","9c6597e7":"# **if you like the kernel plaese upvote it**"}}