{"cell_type":{"2b8e0aae":"code","0da079cb":"code","f94a51e0":"code","7244586e":"code","ec40c4e4":"code","9c8bc286":"code","68bfa16f":"code","ba408914":"code","06ca59fb":"code","8ee91fe1":"code","3e8e4c6e":"code","51249bcc":"code","043c34ad":"code","bc59863d":"code","1167cf92":"code","bd252fb3":"code","43cb0484":"code","c51129fb":"code","09df68f9":"code","c389f41e":"code","f8e21804":"code","014ba10b":"code","6c5c41c4":"code","8f5ed7f7":"code","bf489284":"code","fee72228":"code","c730e969":"code","107c3f03":"code","36eb7c68":"code","45475e68":"code","10bd8da0":"code","fe5c4726":"code","b3919ff9":"code","6efd3bfb":"code","86b1ee00":"code","ca147d16":"code","1a43420b":"code","330098b0":"code","8109a5e5":"code","bcd98be6":"code","23d782b4":"code","aa5e0de5":"code","ab9923c6":"code","27d5901c":"markdown","2a2b6fdf":"markdown","6c34fca6":"markdown","f1018123":"markdown","1175979b":"markdown","54a3a5dd":"markdown","8d2ab93e":"markdown","7b64dcaa":"markdown","293fd1bf":"markdown","a86a956e":"markdown","fa8f94f6":"markdown","ffe2a026":"markdown","7c98a816":"markdown","c3769b5b":"markdown","cb91a758":"markdown","3e67401e":"markdown","522d8e06":"markdown","c9349b99":"markdown","edec7754":"markdown","21919948":"markdown","282fb612":"markdown","5afdc99b":"markdown","d832e6ee":"markdown","904a815a":"markdown","f2cc6c2e":"markdown","cdd4bcba":"markdown","66f12bfa":"markdown","51a9a9fb":"markdown","133d10a4":"markdown"},"source":{"2b8e0aae":"from sklearn.datasets import fetch_openml\nmnist = fetch_openml('mnist_784', version = 1, cache = True)\nX, y =mnist['data'], mnist['target']","0da079cb":"X = X.values\n","f94a51e0":"X.shape","7244586e":"import numpy as np\ny = np.array(list(y))\ny.shape","ec40c4e4":"y[36000]","9c8bc286":"import pandas as pd \nimport numpy as np","68bfa16f":"print(set(list(mnist['target'])))","ba408914":"%matplotlib inline\nimport matplotlib \nimport matplotlib.pyplot as plt\nsome_digit = X[36000]\nsome_digit_image = some_digit.reshape(28,28)\nplt.imshow(some_digit_image, cmap = matplotlib.cm.copper, interpolation = 'nearest')\nplt.axis('off')\nplt.show()","06ca59fb":"X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\nimport numpy as np\nnp.random.seed(42)\nshuffle_index = np.random.permutation(60000)\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]","8ee91fe1":"#we are going to use Stochastic Gradient Descent(SGD) classifier\n\nfrom sklearn.linear_model import SGDClassifier\nX1 = {\"xcoor\": pd.Series([0,1]), \"ycoord\": pd.Series([0,1])}\nX3 = pd.DataFrame(X1)\ny = [0,1]\nclf = SGDClassifier(loss = 'hinge', penalty = \"l2\")\nclf.fit(X3, y)\n","3e8e4c6e":"y_train_9  = (y_train == '9') \ny_test_9 = (y_test == '9')","51249bcc":"type(y_train_9)\nnp.unique(y_train_9)","043c34ad":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state = 42, max_iter = 10)\nsgd_clf.fit(X_train, y_train_9)","bc59863d":"#testing SGD Classifier in Sklearn\n\nsome_digit = X[36000]\nsgd_clf.predict([some_digit])","1167cf92":"some_digit = X[36000]\nsome_digit_image = some_digit.reshape(28,28)\nplt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = 'nearest')\nplt.axis('off')\nplt.show()","bd252fb3":"from sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, X_train, y_train_9, cv = 3, scoring = 'accuracy')\n","43cb0484":"from sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_9, cv = 3)\n\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train_9, y_train_pred)\n","c51129fb":"from sklearn.metrics import precision_score, recall_score\nprint(precision_score(y_train_9, y_train_pred),\nrecall_score(y_train_9, y_train_pred))","09df68f9":"y_scores = sgd_clf.decision_function([some_digit])\ny_scores","c389f41e":"threshold = 0\ny_some_digit_pred = (y_scores > threshold)\ny_some_digit_pred","f8e21804":"#Calculating precision\/ recall curve using Scikit-Learn\n\ny_scores = cross_val_predict(sgd_clf, X_train, y_train_9, cv=3, \n                             method=\"decision_function\")\n","014ba10b":"from sklearn.metrics import precision_recall_curve\n\nprecisions, recalls, thresholds = precision_recall_curve(y_train_9, y_scores)\n\nprint(len(precisions), len(recalls), len(y_scores))","6c5c41c4":"def plot_precision_recall_vs_threshold(precision, recalls, thresholds):\n    plt.figure(figsize = (30,10))\n    plt.plot(thresholds, precisions[:-1], \"b--\", label = \"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label = \"recall\")\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc = \"upper left\")\n    plt.ylim([0, 1])\n\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.show()","8f5ed7f7":"def plot_precision_vs_recall(precisions, recalls):\n    plt.figure(figsize = (18,7))\n    plt.plot(recalls[:-1], precisions[:-1], 'b-', label = \"precision\")\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.legend(loc = \"upper left\")\n    plt.ylim([0,1])\n    \nplot_precision_vs_recall(precisions, recalls)\nplt.show()","bf489284":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_train_9, y_scores)\n\ndef plot_roc_curve(frp, tpr, label = None):\n    plt.figure(figsize = (18,7))\n    plt.plot(fpr, tpr, linewidth = 2, label = label)\n    plt.plot([0,1], [0,1], 'k--')\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positve Rate')\n    plt.ylabel('True Positive Rate')\n    \nplot_roc_curve(fpr, tpr)\nplt.show()","fee72228":"from sklearn.ensemble import RandomForestClassifier\nforest_clf = RandomForestClassifier(random_state = 42)\n\ny_probas_forest = cross_val_predict(forest_clf, X_train,\ny_train_9, cv=3, method=\"predict_proba\")\n\ny_scores_forest = y_probas_forest[:,1]\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_9,y_scores_forest)\n\nfig, ax = plt.subplots()\nax.plot(fpr, tpr, \"b:\", label = \"SGD\")\nax.plot(fpr_forest, tpr_forest, linewidth = 2, label=\"Random Forest\")\nax.plot([0,1], [0, 1], 'k--')\nax.legend(loc = 4)\nax.set_title('ROC curves')\n","c730e969":"#By default scikit learn SGDClassifier assumes OvA \nsgd_clf.fit(X_train, y_train)\n#Under the hood it trained 10 classifiers \n\nsgd_clf.predict([some_digit])","107c3f03":"some_digit_scores = sgd_clf.decision_function([some_digit])\n\nsome_digit_scores","36eb7c68":"from sklearn.multiclass import OneVsOneClassifier\novo_clf = OneVsOneClassifier(SGDClassifier(random_state =42, max_iter = 20))\n\novo_clf.fit(X_train, y_train)\novo_clf.predict([some_digit])\n","45475e68":"len(ovo_clf.estimators_)","10bd8da0":"#calculating confusion matrix for multicalss using Scikit-Learn\n\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv = 3)\nconf_mx = confusion_matrix(y_train, y_train_pred)\n\nconf_mx","fe5c4726":"#plotting confusion matrix for multiclass using sklearn\n\nplt.matshow(conf_mx, cmap = plt.cm.gray)\nplt.show()","b3919ff9":"#Highlight the errors by normalizing\nrow_sums = conf_mx.sum(axis = 1, keepdims = True)\nnorm_conf_mx = conf_mx \/ row_sums\n\n#Remove the correct predictions\n\nnp.fill_diagonal(norm_conf_mx, 0)\nplt.matshow(norm_conf_mx, cmap=plt.cm.gray)\nplt.show()","6efd3bfb":"\ny_train = y_train.astype(int)\n\ny_train_large = (y_train >=7)\ny_train_odd = (y_train % 2 == 1)\ny_multilabel = np.c_[y_train_large, y_train_odd]\n","86b1ee00":"#Train the classifier\n\n#KNeighbours Classifier supports multi-label classification\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_clf = KNeighborsClassifier()\nknn_clf.fit(X_train, y_multilabel)","ca147d16":"knn_clf.predict([some_digit])","1a43420b":"#Demonstrating multi-output classifier: digit image noise removal\n\n#Adding noise to the training set\n\nimport numpy.random as rnd\nnoise_train = rnd.randint(0,100, (len(X_train), 784))\nX_train_mod = X_train + noise_train\n\n#adding noise to the test set\n\nnoise_test = rnd.randint(0, 100, (len(X_test), 784))\nX_test_mod = X_test + noise_test\n\n","330098b0":"#setting clean image as the label (y_train and y_test)\n\ny_train_mod = X_train\ny_test_mod = X_test\n","8109a5e5":"#let us view the noisy image \n\ndef plot_digit(array):\n  array_image = array.reshape(28,28)\n  plt.imshow(array_image, cmap = matplotlib.cm.copper, interpolation = \"nearest\")\n  plt.axis('off')\n  plt.show()\n\nplot_digit(X_test_mod[4000])","bcd98be6":"plot_digit(X_test_mod[4001])","23d782b4":"#let us clean the image using the Classifier\n\nknn_clf.fit(X_train_mod, y_train_mod)\n","aa5e0de5":"clean_digit = knn_clf.predict([X_test_mod[4001]])\nplot_digit(clean_digit)\n","ab9923c6":"clean_digit1 = knn_clf.predict([X_test_mod[3999]])\nplot_digit(clean_digit1)\nplot_digit(X_test_mod[3999])","27d5901c":"**Observations**:\n* Looks fairly good since most images are on the diagonal\n* 5s look darker than other digits \n    * it could be because , Fewer 5s in the dataset\n    * Classifier does not perform well on 5s\n\n","2a2b6fdf":"# Multi-Output Classification \n\n* It is simply a generalization of multilabel classification where\neach label can be multiclass (i.e., it can have more than two\npossible values).\n\n* Multi-output classification example:\n  * Removing noise from images\n\n* We'll build a system that removes noise from images. It will take\nas input a noisy digit image, and it will output a clean digit image,\nrepresented as an array of pixel intensities, just like the MNIST\nimages.\n","6c34fca6":"\u25cf Notice that the classifier\u2019s output is\n\n - **Multilabel (one label per pixel) - so 784 labels**\n\n -  **Multiclass:** And each label can have **multiple values** (pixel\nintensity ranges from 0 to 255) - 256 classes.\n\nIt is thus an example of a **Multioutput classification system.**","f1018123":"## Confusion Matrix","1175979b":"#","54a3a5dd":"# TrainClassifier Using training ","8d2ab93e":"Is the accuracy of 95% for SGD Classifier good enough?\nProbably Not!\nNever5Classifier - a dumb classifier gave an accuracy of 90%\nWe need a better measure of performance for the classifier","7b64dcaa":"**Observations**:\n  * 8 and 9 columns are bright: many digits misclassified as 8 and 9\n  * 8 and 9 rows are bright: many 8 and 9 misclassified as other digits.\n  * (3,5) and (5,3) are little brighter :\n  confusion between 3 and 5\n  * 4 and 5 are confused with 8 \n\n**possible solutions**\n  * gather more training data for 8s and 9s\n  * Engineer new features that would help the classifier , like number of loops , curves , and bends\n  * preprocess images\n      * using skelarn, Pillow or OpenCV to make certain features stand out more\n\n  * we need to analyse individual errors","293fd1bf":"# Performance Metrics","a86a956e":"**A Binary Classifier can be used for Multiclass Classification. There\nare basically two strategies for doing this.**","fa8f94f6":"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \n**Source**: [MNIST Website](http:\/\/yann.lecun.com\/exdb\/mnist\/) - Date unknown  \n**Please cite**:  \n\nThe MNIST database of handwritten digits with 784 features, raw data available at: http:\/\/yann.lecun.com\/exdb\/mnist\/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \n\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \n\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \n\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\n\nDownloaded from openml.org.","ffe2a026":"**Classification of image into whether [large, odd], how do we do it ?** ","7c98a816":"# Dividing the dataset in training and test datast","c3769b5b":"How to decide the best threshold?\n\n    \u25cf Get the scores of all the training dataset using cross_val_predict with\ndecision_function as function\n\n    \u25cf Compute the precision and recall for all possible thresholds using\nprecision_recall_curve()\n\n    \u25cf Plot both precision and recall for the thresholds using matplotlib\n    \n    \u25cf Select the threshold value that gives the best precision\/ recall tradeoff to the task at hand.","cb91a758":"- What is confusion matrix?\n    - The general idea is to count the number of times instances of class  A are classified as class B. \n    - Can be better than simple accuracy","3e67401e":"## Cross Validation - Accuracy","522d8e06":"By selecting an appropriate threshold, the user can obtain the\ndesired precision. However, the best precision may not have the best\nrecall.","c9349b99":"- The resulting accuracy of 95% is good enough?\n\n    \u25cf Accuracy may not be a good performance measure when dealing with   skewed datasets\n    \n    \u25cf Ours is a skewed dataset with only 10% of the data as\n    digit 5.","edec7754":"# Multilabel classification","21919948":"- Doing multi-class classification using OvA Classifier\n\n    - 10 classifier scores is obtained\n    - Index of the maximum score is 9","282fb612":"# Classification of MNIST handwritten data","5afdc99b":"1) One-versus-all (OvA) strategy also called one-versus-the-rest \n - for example,\n\n    a) For eg. to classify the digit images into 10 classes (from 0 to 9)  one way is to train 10 binary classifiers, one for each digit (a 0-detector, a 1-detector, a 2-detector, and so on).\n\n    b) Then when you want to classify an image, select the class\n    whose classifier outputs the highest score.","d832e6ee":"- Cross Validation - Accuracy\n- Confusion Matrix\n    - Precision\n    - Recall\n    - F1 score\n- ROC Curve","904a815a":"**2. One-versus-one (OvO) strategy** \n\n\n  a. This is another strategy in which we train a binary classifier\nfor every pair of digits: one to distinguish 0s and 1s, another\nto distinguish 0s and 2s, another for 1s and 2s, and so on.\n\nb. If there are N classes, you need to train N \u00d7 (N \u2013 1) \/ 2\nclassifiers.","f2cc6c2e":"- Binary classifiers distinguish between two classes\n- While multi-class classifiers (also called multinomial classifiers)\n  can distinguish\n     - Between more than two classes\n     - Can distinguish between multiple classes\n     - Eg. Random Forest classifiers , naive Bayes classifiers etc","cdd4bcba":"# Multi-Class Classification","66f12bfa":"the scores of 10 classifiers is obtained , and 17111.656 is the highest score ","51a9a9fb":"**Error Analysis**\n* Once the model (classifier) is identified, it can be improved by analyzing the types of errors it makes\n* For the previous multiclass classification example of classifying images of digits into digit labels, it can be done by observing the confusion matrix and plotting it on the graph","133d10a4":"**Doing multi-class classification using OvO Classifier**\n\n* SGD uses OVA by default\n* Need to specifically mention OvO to do OvO classification\n* Number of estimators trained for MNIST dataset = 45"}}