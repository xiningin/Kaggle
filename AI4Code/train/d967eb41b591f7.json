{"cell_type":{"937ccee2":"code","7507ac15":"code","e4b4728f":"code","cd8d4d6f":"code","243bdf91":"code","1b4741ea":"code","efc36790":"code","df026d53":"code","d6d82a30":"code","dbe12c68":"code","dc66554e":"code","9a1087a5":"code","0b83e3b4":"code","29163fc7":"code","5e7895cd":"code","0e5ad7f6":"code","47f9a2d7":"code","f3bfd600":"code","6969664a":"code","b47d21d0":"code","5e7cc18c":"code","9875f520":"code","c3a39f45":"code","567cf8e5":"code","7e8bb656":"code","19f8c993":"code","04a94c81":"code","66e3aaf5":"code","2e33f848":"code","194e3b4f":"code","8ea0b289":"code","72bd7475":"code","1e4163c7":"code","42e38ff9":"code","3e4a3439":"code","dbfa2d5f":"code","56320cf5":"code","1729d4c0":"code","3555c348":"code","f750023a":"code","5a1b4e64":"code","db705f7a":"code","90fc9271":"markdown","0da090e6":"markdown","38ab5a42":"markdown","66bb704b":"markdown","422601b7":"markdown","98cc6d4b":"markdown","212f9dd1":"markdown","d64f1275":"markdown","65867bd5":"markdown","9aed6e9c":"markdown","781eaca0":"markdown","51570cf1":"markdown","d23ae777":"markdown","d17a90ef":"markdown","13d7223b":"markdown","094e026a":"markdown","7410bf49":"markdown","b79e587d":"markdown","de54a1db":"markdown"},"source":{"937ccee2":"!pip install eli5\n!pip install pdpbox\n!pip install shap","7507ac15":"from collections import defaultdict\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom scipy.stats import spearmanr\nfrom scipy.cluster import hierarchy\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, roc_curve, auc\nfrom xgboost import XGBClassifier, plot_importance\nimport warnings\nimport eli5\nimport shap\nfrom eli5.sklearn import PermutationImportance\nfrom pdpbox import pdp, get_dataset, info_plots\nfrom sklearn.tree import DecisionTreeClassifier\nwarnings.filterwarnings('ignore')\nplt.style.use('fivethirtyeight')\n%matplotlib inline","e4b4728f":"data = pd.read_csv('..\/input\/heart-disease-cleveland-uci\/heart_cleveland_upload.csv')\n# To display the top 5 rows\ndata.head(5)","cd8d4d6f":"data.describe()","243bdf91":"data.shape","1b4741ea":"heart = data.copy()","efc36790":"target = 'condition'\nfeatures_list = list(heart.columns)\nfeatures_list.remove(target)","df026d53":"y = heart.pop('condition')","d6d82a30":"X_train, X_test, y_train, y_test = train_test_split(heart, y, test_size=0.2, random_state=33)\nX_train.shape, X_test.shape","dbe12c68":"%%time\n\n# ML in two lines ;)\nxgb = XGBClassifier(objective='binary:logistic', random_state=33, n_jobs=-1)\nxgb.fit(X_train, y_train)","dc66554e":"# make predictions for test data\nxgb_predictions = xgb.predict(X_test)","9a1087a5":"import eli5\nfrom eli5.sklearn import PermutationImportance","0b83e3b4":"eli5.show_weights(xgb.get_booster(), top=15)","29163fc7":"tgt = 6\nprint('Reference:', y_test.iloc[tgt])\nprint('Predicted:', xgb_predictions[tgt])\neli5.show_prediction(xgb.get_booster(), X_test.iloc[tgt], \n                     feature_names=list(heart.columns), show_feature_values=True)","5e7895cd":"%%time\n\n# we need to retrain a new model with arrays\n# as eli5 has a bug with Dataframes and XGBoost\n# cf. https:\/\/github.com\/TeamHG-Memex\/eli5\/pull\/261\nxgb_array = XGBClassifier(objective='binary:logistic', random_state=33, n_jobs=-1)\nxgb_array.fit(X_train.values, y_train)","0e5ad7f6":"model = DecisionTreeClassifier(random_state=1)\nmodel = model.fit(X_train, y_train)","47f9a2d7":"permutation = PermutationImportance(model, random_state=33).fit(X_train, y_train)","f3bfd600":"eli5.show_weights(permutation, feature_names = features_list, top=30)","6969664a":"def plot_pdp(model, df, feature, cluster_flag=False, nb_clusters=None, lines_flag=False):\n    pdp_goals = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns.tolist(), feature=feature)\n    pdp.pdp_plot(pdp_goals, feature, cluster=cluster_flag, n_cluster_centers=nb_clusters, plot_lines=lines_flag)\n    plt.show()","b47d21d0":"plot_pdp(xgb, X_train, 'thalach')","5e7cc18c":"plot_pdp(xgb, X_train, 'ca')","9875f520":"features_to_plot = ['thalach', 'ca']\ninter1  =  pdp.pdp_interact(model=xgb, dataset=X_train, model_features=features_list, features=features_to_plot)\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='grid')\nplt.show()","c3a39f45":"plot_pdp(xgb, X_train, 'thalach', cluster_flag=True, nb_clusters=24, lines_flag=True)","567cf8e5":"!conda install -c conda-forge Skater -y","7e8bb656":"from skater.core.explanations import Interpretation\nfrom skater.model import InMemoryModel","19f8c993":"interpreter = Interpretation(training_data=X_test, feature_names=features_list)\nim_model = InMemoryModel(xgb.predict_proba, examples=X_train, target_names=['Disease', 'No Disease'])","04a94c81":"predictions = xgb_array.predict_proba(X_test.values)\n","66e3aaf5":"from skater.core.local_interpretation.lime.lime_tabular import LimeTabularExplainer\n\nexp = LimeTabularExplainer(X_test.values, feature_names=features_list, discretize_continuous=True, class_names=['No disease', 'Disease'])","2e33f848":"tgt = 1\nprint('Reference:', y_test.iloc[tgt])\nprint('Predicted:', predictions[tgt])\nexp.explain_instance(X_test.iloc[tgt].values, xgb_array.predict_proba).show_in_notebook()","194e3b4f":"tgt = 6\nprint('Reference:', y_test.iloc[tgt])\nprint('Predicted:', predictions[tgt])\nexp.explain_instance(X_test.iloc[tgt].values, xgb_array.predict_proba).show_in_notebook()","8ea0b289":"tgt = 15\nprint('Reference:', y_test.iloc[tgt])\nprint('Predicted:', predictions[tgt])\nexp.explain_instance(X_test.iloc[tgt].values, xgb_array.predict_proba).show_in_notebook()","72bd7475":"# pip install shap\nimport shap\n\n# load JS visualization code to notebook\nshap.initjs()","1e4163c7":"# explain the model's predictions using SHAP values\n# (same syntax works for LightGBM, CatBoost, and scikit-learn models)\nexplainer = shap.TreeExplainer(xgb)\nshap_values = explainer.shap_values(X_test)","42e38ff9":"X_shap = pd.DataFrame(shap_values)\nX_shap.head()","3e4a3439":"print('Expected Value: ', explainer.expected_value)","dbfa2d5f":"shap.summary_plot(shap_values, X_test, plot_type=\"bar\", color='red')\n","56320cf5":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[1,:], X_test.iloc[1,:])","1729d4c0":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[6,:], X_test.iloc[6,:])","3555c348":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[15,:], X_test.iloc[15,:])","f750023a":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[:1000,:], X_test.iloc[:1000,:])","5a1b4e64":"shap.initjs()\nshap.summary_plot(shap_values, X_test)","db705f7a":"shap.initjs()\nshap.dependence_plot(ind='thalach', interaction_index='ca',\n                     shap_values=shap_values, \n                     features=X_test,  \n                     display_features=X_test)","90fc9271":"We have explained the local instances using SHAP, similar to the LIME explanations, just visualised in a different way.","0da090e6":"## Permutation Importance","38ab5a42":"Getting feature importance values using SHAP, we see similar results. ca, thal, cp and oldpeak are few of the most important features. ","66bb704b":"Installing the required dependencies","422601b7":"Looking at another, opposite example here. The prediction made by the model is that the patient is suffering from heart disease. Looking at and understanding the top 3 feature values contributing to this prediction:\n1. ca = 2. This shows that 2 vessels out of the 3 heart vessels are blocked. This is poor, and leads to an extreme lack of blood flow in and out of the heart. The chances of disease are high due to this.\n2. thal = 2. It signifies that there were defects initially in the test and that the blood flow isn't at an optimum level. This is coungruent with the earlier factor of there being 2 vessels that are blocked. \n3. oldpeak = 2.80. The level of ST Depression in the electrocardiograph results is high. The more the depression in the ECG Graph, the more are the chances of the patient being diagnosed with a disease. ","98cc6d4b":"We have taken a local example here. We can see that the top 4 features contributing to the prediction of the feature are oldpeak, ca, cp and thal. \n\nOldpeak, which is the most important feature in this prediction is related to the electrocardiograph results of the patient. If the electrocardiograph shows a ST Depression (indicating that the patient is suffering from myocardial ischaemia), the value of oldpeak shows us the level of the ST Depression. The more the depression, the likelier it is that the patient is suffering from heart disease. ","212f9dd1":"We have looked at two extreme cases. Now, let's look at a case where the model predicted that the patient is suffering from angina but the result is not as obvious. Looking at the top 3 features. \n1. ca = 0. This shows us that no vessels are blocked. This is a good sign, and leads the model to think that the patient does not have a heart disease. \n2. thal = 0. Acting against ca, thallium test shows us that there are some defects in the blood supply and heart cells of the patient. This is a great example that shows us that in real life, results are mixed more often than not. \n3. cp = 3. The patient is suffering from chest pain type 3 (asymptomatic pain). This sounds counter intuitive, but asymptomatic pain is actually the most severe out of all 4 possible chest pain types. So, this leads the model to making a prediction that the patient has a heart disease. \n\nUsing SHAP, we have seen two extreme cases in the same fashion as LIME. Now, we look at a local explanation that isn't as extreme. We see a good mix of Red and Blue feature values from the figure shown above. Looking at both cases individually:\n\n1. The most important feature values influencing the model to make the decision that the patient has a heart disease are thal=2 (Showing that there are some defects in the blood supply and the quality of heart cells of the patient), cp=3 (Showing that the type of chest pain is asymptomatic. This may seem counterintuitive, but asymptomatic chest pain is actually the most severe out of the four types, which leads the model to believe that the patient has a heart disease.)  and chol=307 (High cholestrol leads to blockage of blood vessels of the heart and decreases the overall blood flow in and around the heart). \n\n2. The most important feature value influencing the model to make the decision that the patient does not have a heart disease are ca = 0. This is perhaps the most important feature, and from this we realise that none of the vessels of the patient are blocked.  ","d64f1275":"eXplainable AI or XAI in short, is basically a way to remove the ambiguity in machine learning methods and to enable transparency so that the outcomes of black-box models can be easily understood by humans.\n\nWhy XAI -\nWith AI forming the future of all complex decision-making, it is crucial to know how and why these decisions were made. Artificial Intelligence clearly enhances the speed, precision, and effectiveness of human efforts. For example, AI techniques can be used to identify which transactions are likely to be fraudulent, as well as automate manually intense data management tasks in financial institutions, or it can be useful for face recognition in cameras.\n\nHowever, consider an AI-powered medical diagnosis system that predicts cancer or heart disease in a patient previously diagnosed as healthy by medical experts. Human life cannot be put to risk unless the predictions of the models are transparent and provide a legitimate reason for the result. If an AI system provides counterintuitive advice when picking stocks or an AI autonomous vehicle drives unpredictably and causes a fatal collision despite normal road conditions, then in such cases, it\u2019s essential to know why the model took the decisions and behaved in the way it did. This is where XAI comes into the picture. It has the potential to explain the underlying black-box processes and to provide trust in AI.","65867bd5":"We explain a local instance using LIME. The final prediction of the model is 0 (The patient is not suffering from heart disease). We can see the feature values that are contributing to this prediction of the model.\n\nLooking at the top 3 features and explaining:\n1. ca = 0. This shows that upon performing an angiography, no vessel of the heart was found to be blocked. This, of course, is wonderful as blocked vessels lead to a lack of blood flow and eventually problems (such as angina). The fact that no vessels are blocked is a great indicator of good health of the heart. \n2. thal = 0. Upon performing a Thallium test to check the blood flow in the heart, it is found that there are no defects and the results are normal.\n3. cp = 2. This indicates that the patient is suffering from Non-Anginal pain, which is not as bad as asymptomatic pain. ","9aed6e9c":"## LIME","781eaca0":"This scatter plot shows us the relation between two features, as well as the SHAP Values. The X-axis shows us thalach (maximum heart rate), the Y-axis shows us the SHAP Values and the color of each dot shows us the value of ca. More often than not, the shap values are low when the value of ca is low. There is also a slight trend of the shap values decreasing as the value of thalach increases. ","51570cf1":"This diagram shows us the most important features of the dataset of Heart Disease. The three most important features are as follows:\n\n\n1.   cp (Chest Pain Type) - There are four types of angina, depending on the number of symptoms the patient experiences.\n  i. 0 - Typical Angina - Having all 3 major symptoms of Angina\n  ii. 1 - Atypical Angina - Having 2 out of the 3 major symptoms of Angina\n  iii. 2 - Non-Anginal Pain - Having one symptom\n  iv. 3 - Asymptomatic \n  \n  The severity of Angina is as follows:\n  \n  Typical Angina < Atypical Angina < Non-Anginal Pain < Asymptomatic\n2.   thal (Thallium Test) - A thallium test is a test used to check how much blood is reaching different parts of the heart by using a radioactive tracer. They help the doctors to check the blood supply. \n  i. 0 - Normal results (no complications)\n  ii. 1 - Fixed Defect - Blood supply is blocked at one or more parts of the heart\n  iii. 2 - Reversible Defect - Blood supply is blocked at some parts, but it restributes after some time, hence, it's not permanent. \n3.   ca (Number of blocked vessels) - The heart has three main vessels for blood supply. By applying angiography, the doctor can see the results of how many vessels are blocked. \n  i. 0 - No vessels are blocked\n  ii. 1 - 1 vessels are blocked\n  iii. 2 - 2 vessels are blocked\n  iv. 3 - 3 vessels are blocked\n","d23ae777":"# Feature Importance on Heart Disease Dataset","d17a90ef":"This is a global explanation of the predictions of the model. -0.3918 is the base value as obtained using the SHAP Values. This means that if the total value is more than -0.3918, it signifies that the patient has the disease and if it is less than -0.3918, it signifies that the patient does not have the disease. The blue part of the graph pushes the prediction lower, and the red part is responsible for increasing it. This means that the instances in which there are a lot more red colored features will usually be 1 (having a disease) and vice versa.","13d7223b":"By this beautiful scatter plot graph, we have visualised the effects of the features on the prediction at different values. The color represents the value of the feature. (Blue meaning low, purple meaning the median value and red meaning high). For example, in ca, we see that when the dots are blue, the shap value is negative and when the dots are red and purple, the shap values are mostly positive. This signifies that when no vessels are blocked, chances of disease are low but as the number of vessels blocked increases, so does the chances of having a disease. ","094e026a":"Reading the data","7410bf49":"## PDP","b79e587d":"## SHAP","de54a1db":"We have looked at two extreme cases. Now, let's look at a case where the model predicted that the patient is suffering from angina but the result is not as obvious. Looking at the top 3 features. \n1. ca = 0. This shows us that no vessels are blocked. This is a good sign, and leads the model to think that the patient does not have a heart disease. \n2. thal = 2. Acting against ca, thallium test shows us that there are some defects in the blood supply and heart cells of the patient. This is a great example that shows us that in real life, results are mixed more often than not. \n3. cp = 3. The patient is suffering from chest pain type 3 (asymptomatic pain). This sounds counter intuitive, but asymptomatic pain is actually the most severe out of all 4 possible chest pain types. So, this leads the model to making a prediction that the patient has a heart disease. "}}