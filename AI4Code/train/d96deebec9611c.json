{"cell_type":{"17b79e89":"code","2c21e86b":"code","0564fa90":"code","76e13aa1":"code","05c95655":"code","0908f965":"code","91cc9c12":"code","066b8f83":"code","7153d99d":"code","dd0165f6":"code","ceddaa30":"code","36c1f20e":"code","d75a4b0e":"code","e1abd972":"code","55f40e3d":"code","e819996e":"code","942af58d":"code","e1543d72":"code","cd52c87e":"code","5400c69c":"code","4a424ce7":"code","dab39b0d":"code","343319b0":"code","dd66ba5c":"code","1663adac":"code","1da5c723":"code","d0b5de04":"code","88aa1824":"markdown","45e94ed8":"markdown","d4205c43":"markdown","4b06b002":"markdown","843dfbfa":"markdown","5fb34103":"markdown","03f5a2c6":"markdown","33feece7":"markdown","e4110719":"markdown","cb18437c":"markdown","48522bd7":"markdown","1df18eaa":"markdown","77062e60":"markdown","2abae167":"markdown","8f2ce73d":"markdown","af59b9fb":"markdown","7cc435b9":"markdown","59f180a1":"markdown","6a31d139":"markdown"},"source":{"17b79e89":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\nfrom plotly.subplots import make_subplots\npyo.init_notebook_mode()\nsns.set_style('darkgrid')\n","2c21e86b":"e_data = pd.read_csv('\/kaggle\/input\/earthquake-database\/database.csv')\ne_data.head()","0564fa90":"missing = e_data.isna().sum()\nmissing = missing[missing>0]\nmissing = missing.reset_index()\ntr = go.Bar(x=missing['index'],y=missing[0],name='Missing')\ntr2 = go.Bar(x=missing['index'],y=[e_data.shape[0]]*len(missing['index']),name='Total')\n\ndata = [tr2,tr]\nfig = go.Figure(data=data,layout={'title':'Proportion Of Missing Values In Our Dataset','barmode':'overlay'})\nfig.show()","76e13aa1":"#Tackle Missing Values\ne_data['Magnitude Type'] = e_data['Magnitude Type'].fillna(e_data['Magnitude Type'].mode()[0])\n\nmissing = e_data.isna().sum()\nmissing = missing[missing>0]\nmissing = missing.reset_index()\nnot_missing = [col for col in e_data.columns if col not in missing['index'].values]","05c95655":"def get_day_of_week(sir):\n    return sir.weekday()\ndef get_month(sir):\n    return sir.month\ndef get_year(sir):\n    return sir.year\n\n\ne_data =e_data[not_missing]\ne_data.Date = pd.to_datetime(e_data.Date)\n\ne_data['Day_of_Week'] = e_data.Date.apply(get_day_of_week)\ne_data['Month'] = e_data.Date.apply(get_month)\ne_data['Year'] = e_data.Date.apply(get_year)\n","0908f965":"Info = e_data.describe()\nInfo.loc['kurt'] = e_data.kurt()\nInfo.loc['skew'] = e_data.skew()\nInfo","91cc9c12":"f_data = e_data.copy().rename(columns={'Date':'date'})\npartitions = []\npartitions.append(f_data.loc[44:int(len(f_data)\/3)-1,:])\npartitions.append(f_data.loc[int(len(f_data)\/3):2*int(len(f_data)\/3)-1,:])\npartitions.append(f_data.loc[2*int(len(f_data)\/3):3*int(len(f_data)\/3),:])\n\n\nneg_part_means =[]\nneg_part_std   =[]\npos_part_means =[]\npos_part_std   =[]\nfor part in partitions:\n    neg_part_means.append(part['Magnitude'].mean())\n    neg_part_std.append(part['Magnitude'].std())\n    pos_part_means.append(part['Depth'].mean())\n    pos_part_std.append(part['Depth'].std())\n    \nres_df = pd.DataFrame({'Depth Mean':pos_part_means,'Magnitude Mean':neg_part_means,'Depth SD':pos_part_std,'Magnitude SD':neg_part_std},\n                     index = [f'Partition_{i}' for i in range(1,4)])\n\n\n\nres_df","066b8f83":"fig = make_subplots(rows=3, cols=2)\n\nfor idx,prt in enumerate(partitions):\n    fig.add_trace(\n    go.Scatter(x=prt['date'], y=prt['Depth'],name=f'Depth Part {idx+1}'),\n    row=idx+1, col=1)\n    fig.add_trace(\n    go.Scatter(x=prt['date'], y=prt['Magnitude'],name=f'Magnitude Part {idx+1}'),\n    row=idx+1, col=2)\n\nfig.update_layout(height=600, width=900, title_text=\"Distibution Of Yearly Magnitude\/Deapth Over Our Time Line For Each Partition\")\nfig.show()","7153d99d":"fig = make_subplots(rows=4, cols=2, subplot_titles=('Observed Depth', 'Observed Magnitude', 'Trend Depth','Trend Magnitude','Seasonal Depth','Seasonal Magnitude','Residual Depth','Residual Magnitude'))\n\nlbl = ['Depth','Magnitude']\n\nfor idx,column in enumerate(['Depth','Magnitude']):\n    res = seasonal_decompose(f_data[column], period=100, model='additive', extrapolate_trend='freq')\n    \n    fig.add_trace(\n    go.Scatter(x=np.arange(0,len(res.observed)), y=res.observed,name='{} Observed'.format(lbl[idx])),\n    row=1, col=idx+1)\n    \n    fig.add_trace(\n    go.Scatter(x=np.arange(0,len(res.trend)), y=res.trend,name='{} Trend'.format(lbl[idx])),\n    row=2, col=idx+1)\n    \n    fig.add_trace(\n    go.Scatter(x=np.arange(0,len(res.seasonal)), y=res.seasonal,name='{} Seasonal'.format(lbl[idx])),\n    row=3, col=idx+1)\n    \n    fig.add_trace(\n    go.Scatter(x=np.arange(0,len(res.resid)), y=res.resid,name='{} Residual'.format(lbl[idx])),\n    row=4, col=idx+1)\n            \nfig.update_layout(height=600, width=900, title_text=\"Decomposition Of Our Magnitude\/Depth into Trend,Level,Seasonality and Residuals\")\nfig.show()","dd0165f6":"f, ax = plt.subplots(nrows=2, ncols=1, figsize=(16, 10))\n\nax[0].set_title('Depth Autocorrelation Analysis ',fontsize=18,fontweight='bold')\nautocorrelation_plot(e_data['Depth'],ax=ax[0])\nax[1].set_title('Magnitude Autocorrelation Analysis ',fontsize=18,fontweight='bold')\nautocorrelation_plot(e_data['Magnitude'],ax=ax[1],color='tab:red')\nplt.show()","ceddaa30":"f, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 10))\nax[0,0].set_ylim(-0.1,0.1)\nax[1,0].set_ylim(-0.1,0.1)\nax[0,1].set_ylim(-0.1,0.1)\nax[1,1].set_ylim(-0.1,0.1)\nplot_acf(e_data['Magnitude'],lags=50, ax=ax[0,0],title='Autocorrelation Magnitude')\nplot_pacf(e_data['Magnitude'],lags=50, ax=ax[1,0],title='Partial Autocorrelation Magnitude')\nplot_acf(e_data['Depth'],lags=50, ax=ax[0,1],color='tab:red',title='Autocorrelation Depth')\nplot_pacf(e_data['Depth'],lags=50, ax=ax[1,1],color='tab:red',title='Partial Autocorrelation Depth')\nplt.show()","36c1f20e":"tmp = e_data.groupby(by='Year').count()\ntmp = tmp.reset_index()[['Year','Date']]\ntmp\nfig = ex.line(tmp,x='Year',y='Date')\nfig.update_layout(\n    title= 'Number Of Earthquakes Over The Years 1965-1966',\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0.0,\n        dtick = 1\n    )\n)\nfig.add_shape(type=\"line\",\n    x0=tmp['Year'].values[0], y0=tmp['Date'].mean(), x1=tmp['Year'].values[-1], y1=tmp['Date'].mean(),\n    line=dict(\n        color=\"Red\",\n        width=2,\n        dash=\"dashdot\",\n    ),\n        name='Mean'\n)\nfig.show()","d75a4b0e":"tmp = e_data.groupby(by='Year').mean()\ntmp = tmp.reset_index()[['Year','Magnitude']]\ntmp\nfig = ex.line(tmp,x='Year',y='Magnitude')\nfig.update_layout(\n    title= 'Mean Earthquakes Magnitude Over The Years 1965-1966',\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0.0,\n        dtick = 1\n    )\n)\nfig.show()","e1abd972":"tmp = e_data.groupby(by='Year').std()\ntmp = tmp.reset_index()[['Year','Magnitude']]\ntmp\nfig = ex.line(tmp,x='Year',y='Magnitude')\nfig.update_layout(\n    title= 'Earthquake Standard Deviation From The Mean Over The Years 1965-1966, Mean SD Shown With Red Line',\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0.0,\n        dtick = 1\n    )\n)\nfig.add_shape(\n        # Line Horizontal\n            type=\"line\",\n            x0=1965,\n            y0=tmp['Magnitude'].mean(),\n            x1=2016,\n            y1=tmp['Magnitude'].mean(),\n            line=dict(\n                color=\"red\",\n                width=2.5,\n                dash=\"dashdot\",\n            ),\n    )\nfig.show()","55f40e3d":"fig = make_subplots(\n    rows=2, cols=2,\n    column_widths=[0.6, 0.4],subplot_titles=('Location Of Recorded Earthquakes','Distriubtion Of Magnitudes',  'Distriubtion Of Depths'),\n    row_heights=[0.4, 0.6],\n    specs=[[{\"type\": \"scattergeo\", \"rowspan\": 2}, {\"type\": \"histogram\"}],\n           [            None                    , {\"type\": \"bar\"}]])\n\nfig.add_trace(\n    go.Scattergeo(lat=e_data[\"Latitude\"],\n                  lon=e_data[\"Longitude\"],\n                  mode=\"markers\",\n                  hoverinfo=\"text\",\n                  text=e_data.Magnitude,\n                  showlegend=False,\n                  marker=dict(color=\"crimson\", size=4, opacity=0.8)),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Histogram(x=e_data.Magnitude,name='Magnitude'),\n    row=1, col=2\n)\nfig.add_trace(\n    go.Histogram(x=e_data.Depth,name='Depth'),\n    row=2, col=2\n)\n\n\nfig.update_geos(\n    projection_type=\"orthographic\",\n    landcolor=\"white\",\n    oceancolor=\"MidnightBlue\",\n    showocean=True,\n    lakecolor=\"LightBlue\"\n)\n\nfig.update_xaxes(tickangle=45)\n\nfig.update_layout(\n    template=\"plotly_dark\",\n    margin=dict(r=10, t=25, b=40, l=60),\n    \n)\n\nfig.show()","e819996e":"tmp = e_data[['Year','Day_of_Week']]\ntmp=tmp.groupby(by='Year').agg(lambda x:x.value_counts().index[0])\ntmp = tmp.reset_index()\ndays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday',\n            'Sunday']\ndays = {k:days[k] for k in range(0,7)}\ntmp['Day_of_Week'] = tmp['Day_of_Week'].replace(days)\nfig = ex.pie(tmp,names='Day_of_Week',title='Propotion Of Earthquakes On A Certian Day Of Week Over The Years ')\nfig.show()","942af58d":"ex.pie(e_data,names='Status',title='Proportion Of Different Earthquake Statuses',hole=.3)","e1543d72":"ex.pie(e_data,names='Source',title='Proportion Of Different Earthquake Sources',hole=.3)","cd52c87e":"pivot_table = e_data.pivot_table(index='Year',columns='Month',values='Magnitude')\nsns.clustermap(pivot_table,annot=True,cmap='coolwarm',col_cluster=False,figsize=(20,13))","5400c69c":"plt.figure(figsize=(20,11))\nax = sns.distplot(e_data['Latitude'],label='Latitude')\nax.set_title('Distribution Of Earthquake Latitudes',fontsize=19)\nax.set_ylabel('Density',fontsize=16)\nax.set_xlabel('Latitude',fontsize=16)\n\nplt.show()","4a424ce7":"plt.figure(figsize=(20,11))\nax = sns.distplot(e_data['Longitude'],label='Longitude',color='teal')\nax.set_title('Distribution Of Earthquake Longitudes',fontsize=19)\nax.set_ylabel('Density',fontsize=16)\nax.set_xlabel('Longitude',fontsize=16)\n\nplt.show()","dab39b0d":"ex.pie(e_data,names='Type',title='Proportion Of Different Eqrthquake Types In Our Dataset')","343319b0":"plt.figure(figsize=(20,11))\nax = sns.distplot(e_data['Depth'],label='Depth',color='red')\nax.set_title('Distribution Of Earthquake Depths',fontsize=19)\nax.set_ylabel('Density',fontsize=16)\nax.set_xlabel('Depth',fontsize=16)\n\nplt.show()","dd66ba5c":"plt.figure(figsize=(20,11))\nax = sns.distplot(e_data['Magnitude'],label='Magnitude',color='teal')\nax.set_title('Distribution Of Earthquake Magnitudes',fontsize=19)\nax.set_ylabel('Density',fontsize=16)\nax.set_xlabel('Magnitude',fontsize=16)\n\nplt.show()","1663adac":"#Outlier Removal\ne_data = e_data[e_data['Depth'] <300]","1da5c723":"tmp = e_data.copy()\ntmp = tmp[tmp['Magnitude']<=6.1]\ntmp = tmp[tmp['Depth']<60]\n\nsns.jointplot(data=tmp,x='Depth',y='Magnitude',kind='kde',cmap='coolwarm',height=12,levels=30)","d0b5de04":"#Clustring\nfrom sklearn.cluster import KMeans,DBSCAN\nDB = DBSCAN(eps=0.5,algorithm='ball_tree',min_samples=15)\nc_data = e_data.copy()\nDB.fit(e_data[['Magnitude','Depth']])\nc_data['Cluster'] = DB.labels_\n\nfig = ex.scatter_3d(c_data,x='Longitude',y='Depth',z='Magnitude',color='Cluster',height=900)\nfig.show()","88aa1824":"### As shown in the bar chart above, half of our features have missing values where all those features except the magnitude type are missing more than 70% of the data. Another important point is that the data we are missing explains different behaviors in other features. for example, the 'Depth Error' features explain the degree of error in the depth measurement that is being estimated. We shell use the mode of the magnitude type feature to replace the small number of missing values, as for the other features which can some of them can be imputed using regression and nearest neighbor approach. We will leave them because it may be mathematically correct due to high correlation but remember! Correlation does not intend caucasian, and when looking at a natural disaster like an earthquake, I am interested in an element that can highlight caucasian rather than correlation.\n\n","45e94ed8":"<a id=\"3\"><\/a>\n<h1 style=\"background-color:gray;font-family:newtimeroman;font-size:250%;color:whitesmoke;text-align:center;border-radius: 15px 50px;\">Exploratory Data Analysis (EDA)<\/h1>\n","d4205c43":"### The altitude follows a trimodal distribution similar to the latitude. We will perform clustering on those features in a later stage of this kernel, hopefully giving some insight into different groups of earthquake sites.","4b06b002":"### As we can see via the skewness value, even before plotting our features' distributions, the magnitude and depth features are positively skewed and a fair amount at that. It can be already assumed that the cause of the skewness in the data is the phenomena of 'black swans,' we do not know when those swans or outliers will occur as with any natural disaster. Still, there are some earthquakes with significantly higher magnitudes and with higher depths than the average earthquakes, which take on fairly low values of the same features.","843dfbfa":"### We see that in the 60's we had a very high mean magnitude of earthquakes in compression to later years where the mean magnitude stays around the same value for all years.","5fb34103":"### So we can confirm that an earthquake is most likely to be at depth 10 or 30 with a magnitude of 5.5. looking at the distributions of each of the parameters, we can see that, as concluded earlier, the depth follows a bimodal distribution. Still, our magnitude feature follows a multimodal distribution of higher-order, which suggests that our magnitude scale is rounded and is not continuous rather than a 'discrete' feature, which possibly should be interested as an ordinal scale than a value of the measurement.","03f5a2c6":"<h1 style=\"background-color:gray;font-family:newtimeroman;font-size:250%;color:whitesmoke;text-align:center;border-radius: 15px 50px;\">Table of Contents<\/h1>\n\n\n* [1. Introduction](#1)\n* [2. Data Preprocessing](#2)\n* [3. Exploratory Data Analysis (EDA)](#3)\n* [4. Clustering](#4)\n","33feece7":"### We see that our dataset's latitudes follow a multimodal distribution of a trimodal distribution to be precise; I assume we can use clustering to cluster the 3 different groups of latitudes and try and understand why those clusters have similar latitudes and what unites those clusters.","e4110719":"### A higher percentage of earthquakes were recorded on Saturdays and Mondays ","cb18437c":"<a id=\"4\"><\/a>\n<h1 style=\"background-color:gray;font-family:newtimeroman;font-size:250%;color:whitesmoke;text-align:center;border-radius: 15px 50px;\">Clustering<\/h1>\n","48522bd7":"### When we look at the distribution of earthquake depths, we see that most earthquakes follow a bimodal distribution around depth 60. Still, we have some records of earthquakes occurring at depth 600-700, rare and defined as black swans. We will ignore those values in the next steps to see the true distribution without an extremely long tail.","1df18eaa":"### From the 60 till the last few years, there is an average climbing trend in the total earthquake events per year. We see that in the last 3 years in our dataset, there is a sudden drop in our trend ","77062e60":"### The standard deviation of earthquake magnitude over the years gives us the following insight. As explained in the beginning observing a year where the variance of earthquake magnitudes is large can imply that something was wrong. It's worth investigating, in other words, why did the magnitude vary so much during that year in comparison to an average year where there is a certain amount of small earthquake with little to non peculiar behavior.","2abae167":"### 88 percent of our sources are from the US","8f2ce73d":"<a id=\"1\"><\/a>\n<h1 style=\"background-color:gray;font-family:newtimeroman;font-size:250%;color:whitesmoke;text-align:center;border-radius: 15px 50px;\">Introduction<\/h1>\n\n\n![](https:\/\/cdn.britannica.com\/34\/127134-050-49EC55CD\/Building-foundation-earthquake-Japan-Kobe-January-1995.jpg)\n\n**In the following kernel, we will be exploring earthquake records. We will try to visualize the data in a way that will grant us some insight as to what affects earthquakes. Is there any connection between periods and earthquakes? , is there a connection between The magnitude of the earthquake and the depth? We will try to visualize these key points, along with the mean magnitudes and depth across the years and the standard deviation. Why the standard deviation, you may ask? Well, the answer maybe not as intuitive. We can think of a year being 'special' or worth looking into if that year had high-value earthquake magnitudes and low standard deviation, which basically means that there was a certain amount of earthquakes and all those earthquakes throughout the year had high magnitudes. The opposite is also interesting, meaning we have low magnitudes but with high standard deviation..**","af59b9fb":"### The intuition behind the heatmap above was to find out there are any years that stand out in the average magnitude value in a certain month. In other words, I wanted to find out are stronger earthquakes more common in February of each fifth year or some pattern that may uncover the cycle behavior of earthquakes. I found out that all the years have a similar behavior except 1966,1971, and 1968  which had significantly higher average earthquake magnitude.","7cc435b9":"<a id=\"2\"><\/a>\n<h1 style=\"background-color:gray;font-family:newtimeroman;font-size:250%;color:whitesmoke;text-align:center;border-radius: 15px 50px;\">Data Preprocessing<\/h1>\n","59f180a1":"### A quick look at what our data looks like and the features we will work on","6a31d139":"### We see that there are other measurements source in our data like exposition, etc... They are still less than 1 percent of our data, meaning we will treat them as extreme outliers or 'black swans' as we already referred to extreme, unpredictable outliers."}}