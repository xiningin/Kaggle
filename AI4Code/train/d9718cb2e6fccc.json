{"cell_type":{"7d05ed47":"code","2f848162":"code","3dae4ef8":"code","13aa0e55":"code","f1769bf5":"code","606237c5":"code","cf46dc6a":"code","36068510":"code","646f35ac":"code","06f18e66":"markdown","f637a9dc":"markdown","87cd9a87":"markdown","9c3db4fa":"markdown","a11a323b":"markdown","ec660fb8":"markdown","07527998":"markdown"},"source":{"7d05ed47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2f848162":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ny = train['SalePrice']\n","3dae4ef8":"train.info()","13aa0e55":"train.describe()","f1769bf5":"num_vars = train._get_numeric_data().columns\ncat_vars = train.select_dtypes(include = 'object').columns\n\ndf_num = train[num_vars]\ndf_cat = train[cat_vars]\n#len(num_vars)","606237c5":"for var in num_vars:\n    plt.hist(df_num[var])\n    plt.title(var)\n    plt.show()","cf46dc6a":"mean_sale = np.mean(train['SalePrice'])\ngrt_mean_array = []\nfor i in range(0,len(train['Id'])):\n    if train['SalePrice'][i] > mean_sale:\n        grt_mean_array.append(1)\n    else:\n        grt_mean_array.append(0)\n        \ntrain['GrtMean'] = grt_mean_array","36068510":"pd.pivot_table(train, index = \"GrtMean\")","646f35ac":"sns.heatmap(df_num.corr())\nsns.set(rc = {'figure.figsize':(20,12)})","06f18e66":"Get info on the training data","f637a9dc":"Data Visualisation for house predictions based on that done by Ken Jee for the titanic project","87cd9a87":"Plot a pivot table for the data, the pivot table has been tabulated based on house prices that sold above average in order to get an idea for which features house price is more dependent on.","9c3db4fa":"Break down into numerical data and catagorical data","a11a323b":"Plot histograms of numerical variables to see distributions of them","ec660fb8":"Plot a heat map to see which variables might be correlated, for example we would expect garage cars and garage area to be strongly correlated as the bigger the area the more cars you can fit in.\nI have plotted this to identify features which are correlated together. I might not want to include two variables that are correlated (only the one that is a better indicator) as this might weight the model to what is in reality one factor of house price","07527998":"This is only a very basic set of data visualisations however i am still going to use it to guide feature engineering and model selection"}}