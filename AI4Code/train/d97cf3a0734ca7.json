{"cell_type":{"f845f832":"code","99f368ff":"code","9f789ade":"code","7c10b74a":"code","13559f9e":"code","45d0bff2":"code","6e9efa3d":"code","bd32332e":"code","f10d9847":"code","5ec63b4d":"code","9db4600c":"code","b1569229":"code","abefce53":"code","63749a66":"code","6e669d86":"code","b62b0b9b":"code","0705be68":"code","57162c43":"code","15168bea":"code","ca97721c":"code","04c5e252":"code","0d3ec8bb":"code","ebe86d7d":"code","4031c5da":"code","6fb99725":"code","3f59c063":"code","98cd3650":"code","049b6e75":"code","734989b4":"code","0faeb86a":"code","2ca79c8e":"markdown","e97f5312":"markdown","7b009b43":"markdown","3bef1e05":"markdown","b145939d":"markdown","240575c6":"markdown","e21df90a":"markdown","343db2db":"markdown","3dd0bdbe":"markdown"},"source":{"f845f832":"import os\nprint(os.listdir('..\/input\/ctcfloop-data\/Data'))","99f368ff":"from Bio import SeqIO\nimport numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, matthews_corrcoef\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nnp.random.seed(12345)","9f789ade":"def get_num(fasta_name, fasta_name2):\n    num = 0\n    for seq_record in SeqIO.parse(fasta_name,\"fasta\"):\n        if(not(re.search('N',str(seq_record.seq.upper())))):\n            num+=1\n    for seq_record2 in SeqIO.parse(fasta_name2,\"fasta\"):\n        if(not(re.search('N',str(seq_record2.seq.upper())))):\n            num+=1\n    return num","7c10b74a":"'''Convert the input sequences into binary matrixs'''\ndef get_seq_matrix(fasta_name,seqmatrix,rank): \n    labellist = []\n    for seq_record in SeqIO.parse(fasta_name,\"fasta\"):\n        label = seq_record.id\n        sequence = seq_record.seq.upper()\n        if(re.search('N',str(sequence))):\n            continue\n        Acode = np.array(get_code(sequence,'A'),dtype=int)\n        Tcode = np.array(get_code(sequence,'T'),dtype=int)\n        Gcode = np.array(get_code(sequence,'G'),dtype=int)\n        Ccode = np.array(get_code(sequence,'C'),dtype=int)\n        seqcode = np.vstack((Acode,Tcode,Gcode,Ccode))\n        labellist.append(label)\n        seqmatrix[rank] = seqcode\n        rank +=1\n    return seqmatrix,labellist,rank","13559f9e":"def get_code(seq,nt):\n    nts = ['A','T','G','C']\n    nts.remove(nt)\n    codes = str(seq).replace(nt,str(1))\n    for i in range(0,len(nts)):\n        codes = codes.replace(nts[i],str(0))\n    coding = list(codes)\n    for i in range(0,len(coding)):\n        coding[i] = float(coding[i])\n    return coding","45d0bff2":"'''Get the train, validation and test set from the input'''\ndef get_data(infile,infile2):\n    rank = 0\n    num = get_num(infile,infile2)\n    seqmatrix = np.zeros((num,4,1038))\n    (seqmatrix, poslab, rank) = get_seq_matrix(infile,seqmatrix,rank)\n    (seqmatrix, neglab, rank) = get_seq_matrix(infile2,seqmatrix,rank)\n    X = seqmatrix\n    Y = np.array(poslab + neglab,dtype = int)\n    validation_size = 0.10\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=validation_size)\n    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=validation_size)\n    return np.transpose(X_train,axes=(0,2,1)), np.transpose(X_val,axes=(0,2,1)), np.transpose(X_test,axes=(0,2,1)), Y_train, Y_val, Y_test","6e9efa3d":"'''Calculate ROC AUC during model training, obtained from <https:\/\/github.com\/nathanshartmann\/NILC-at-CWI-2018>'''\ndef binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    N = K.sum(1 - y_true)\n    FP = K.sum(y_pred - y_pred * y_true)\n    return FP\/N\n\ndef binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    P = K.sum(y_true)\n    TP = K.sum(y_pred * y_true)\n    return TP\/P\n\ndef roc_auc(y_true, y_pred):\n    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n    binSizes = -(pfas[1:]-pfas[:-1])\n    s = ptas*binSizes\n    return K.sum(s, axis=0)","bd32332e":"def one_hot_to_seq(matrix):\n    nts = ['A','T','G','C']\n    seqs = []\n    index = [np.where(r==1)[0][0] for r in matrix]\n    for i in index:\n        seqs.append(nts[i])\n    seq = ''.join(seqs)\n    return seq","f10d9847":"infile   = '..\/input\/ctcfloop-data\/Data\/GM12878_pos_seq.fasta'\nsecondin = '..\/input\/ctcfloop-data\/Data\/GM12878_neg_seq.fasta'","5ec63b4d":"X_train,X_val,X_test,Y_train,Y_val,Y_test = get_data(infile,secondin)","9db4600c":"print(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","b1569229":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dropout, Dense, Permute, Lambda\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D\nfrom tensorflow.keras.layers import Bidirectional, LSTM\nfrom tensorflow.keras.layers import multiply\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.constraints import MaxNorm\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","abefce53":"labels = ['negative', 'positive']\nlabel=0","63749a66":"dense_unit = 112\ndroprate_cnn  = 0.4279770967884926\ndroprate_lstm = 0.05028428952624636\nfilter_unit = 208\nl2_reg = 5.2164660610264974e-05\n#learning_rate = 0.00010199140620075788\nlstm_unit = 64\npool_size = 4\nwindow_size = 13","6e669d86":"## Build Model\ninputs = Input(shape = (1038, 4))\n\n# 1st Conv1D\ncnn_out = Conv1D(filter_unit, window_size,\n                 kernel_regularizer=l2(l2_reg),\n                 activation=\"relu\")(inputs)\npooling_out = MaxPooling1D(pool_size=pool_size, strides=pool_size)(cnn_out)\ndropout1 = Dropout(droprate_cnn)(pooling_out)\n\n# 2nd Conv1D\ncnn_out2 = Conv1D(filter_unit, window_size,\n                  kernel_regularizer=l2(l2_reg),\n                  activation=\"relu\")(dropout1)\npooling_out2 = MaxPooling1D(pool_size=pool_size, strides=pool_size)(cnn_out2)\ndropout2 = Dropout(droprate_cnn)(pooling_out2)\n\n# LSTM\nlstm_out = Bidirectional(LSTM(lstm_unit, return_sequences=True, \n                              kernel_regularizer=l2(l2_reg)\n                             ),merge_mode = 'concat')(dropout2)\n\n# Attention\na = Permute((2, 1))(lstm_out)\na = Dense(61, activation='softmax')(a)\na_probs = Permute((2, 1), name='attention_vec')(a)\n\nattention_out = multiply([lstm_out, a_probs])\nattention_out = Lambda(lambda x: K.sum(x, axis=1))(attention_out)\ndropout3 = Dropout(droprate_lstm)(attention_out)\n\n# FC\ndense_out = Dense(dense_unit, \n                  kernel_regularizer=l2(l2_reg),\n                  activation='relu')(dropout3)\n\noutput = Dense(1, activation='sigmoid')(dense_out)\n\nmodel = Model(inputs=[inputs], outputs=output)\n\nmodel.summary()","b62b0b9b":"model.load_weights('..\/input\/ctcfloop-data\/Data\/GM12878.bestmodel.hdf5')","0705be68":"y_pred = model.predict(X_test)\nrounded = [round(y[0]) for y in y_pred]","57162c43":"cm = confusion_matrix(Y_test, rounded)\nprint(cm)","15168bea":"print(classification_report(Y_test, rounded, target_names=labels))","ca97721c":"TP = cm[1, 1]\nTN = cm[0, 0]\nFP = cm[0, 1]\nFN = cm[1, 0]\nspecificity = TN \/ float( TN + FP)\nsensitivity = TP \/ float(FN + TP)\nprint('Specificity:',specificity)\nprint('Sensitivity:',sensitivity)","04c5e252":"layer_names = [l.name for l in model.layers]\nprint(layer_names)","0d3ec8bb":"conv_layer_index = layer_names.index('conv1d_1')\nconv_layer = model.layers[conv_layer_index]\nnum_motifs = conv_layer.filters\nwindow     = conv_layer.kernel_size[0]\nconv_output= conv_layer.get_output_at(0)\n\nprint(num_motifs)\nprint(window)","ebe86d7d":"X = X_test\nY = Y_test","4031c5da":"f = K.function([model.input], [K.max(K.max(conv_output, axis=1), axis=0)])\nf_seq = K.function([model.input], [K.argmax(conv_output, axis=1), K.max(conv_output, axis=1)])\nf_act = K.function([model.input],[conv_output])","6fb99725":"motifs = np.zeros((num_motifs, window, 4))\nnsites = np.zeros(num_motifs)\nnseqs = np.zeros(num_motifs)\nY_pos = [i for i,e in enumerate(Y) if e ==label]\nX_pos = X[Y_pos]\n\nnsamples = len(X_pos)\nmean_acts = np.zeros((num_motifs, nsamples))\nprint(mean_acts.shape)","3f59c063":"z = f([X_pos])\nmax_motif = z[0]\nthr_per = 0.5\nz_seq = f_seq([X_pos])\nmax_inds = z_seq[0]\nmax_acts = z_seq[1]\nz_act = f_act([X_pos])\nacts = z_act[0]\n\nfor m in range(num_motifs):\n    for n in range(len(X_pos)):\n        if max_acts[n, m] > thr_per*max_motif[m]:\n            nseqs[m] +=1","98cd3650":"output_dir = '.\/'\noutput_dir2= '.\/'\n##get the filter activity and locations on the input sequence\nact_file = open(output_dir+'motifs'+str(label)+'_act', 'w')\nloc_file = open(output_dir+'motifs'+str(label)+'_loc', 'w')\nfor m in range(num_motifs):\n    for n in range(len(X_pos)):\n        for j in range(acts.shape[1]):\n            weight = (519-abs(j-519))\/519\n            mean_acts[m,n] += acts[n,j,m]*weight\n            if acts[n, j, m] > thr_per * max_motif[m]:\n                nsites[m] += 1\n                motifs[m] += X_pos[n, j:j+window, :]\n                loc_file.write(\"M%i %i %i\\n\" % (m, j, j+window))","049b6e75":"for m in range(num_motifs):\n    act_file.write(\"M%i\" % (m))\n    for n in range(len(X_pos)):\n        act_file.write(\"\\t%0.4f\" % (mean_acts[m,n]))\n    act_file.write(\"\\n\")","734989b4":"for m in range(num_motifs):\n    seqfile = open(output_dir2+'motif'+str(m)+'_seq.fasta', 'w')\n    for n in range(len(X_pos)):\n        for j in range(acts.shape[1]): \n            if acts[n, j, m] > thr_per * max_motif[m]:\n                nsites[m] += 1\n                motifs[m] += X_pos[n, j:j+window, :]\n                kmer = one_hot_to_seq(X_pos[n, j:j+window, :])         \n                seqfile.write('>%d_%d' % (n,j))\n                seqfile.write('\\n')\n                seqfile.write(kmer)\n                seqfile.write('\\n')","0faeb86a":"print('Making motifs')\nmotifs = motifs[:, :, [0, 3, 2, 1]]\nmotifs_file = open(output_dir+'motifs'+str(label)+'.txt', 'w')\nmotifs_file.write('MEME version 4.9.0\\n\\n'\n              'ALPHABET= ACGT\\n\\n'\n              'strands: + -\\n\\n'\n              'Background letter frequencies (from uniform background):\\n'\n              'A 0.25000 C 0.25000 G 0.25000 T 0.25000\\n\\n')\nfor m in range(num_motifs):\n    if nsites[m] == 0:\n        continue\n    motifs_file.write('MOTIF M%i O%i\\n' % (m, m))\n    motifs_file.write(\"letter-probability matrix: alength= 4 w= %i nsites= %i nseqs= %i E= 1337.0e-6\\n\" % (window, nsites[m], nseqs[m]))\n    for j in range(window):\n        motifs_file.write(\"%f %f %f %f\\n\" % tuple(1.0 * motifs[m, j, 0:4] \/ np.sum(motifs[m, j, 0:4])))\n    motifs_file.write('\\n')","2ca79c8e":"## Build Model","e97f5312":"## Prepare Dataset","7b009b43":"## Dataset : common cell types GM12878, K562, HeLa","3bef1e05":"## Visualize Motifs","b145939d":"# DeepCTCFLoop getMotifs","240575c6":"## Evaluate Model","e21df90a":"based on https:\/\/github.com\/BioDataLearning\/DeepCTCFLoop\/","343db2db":"## Load Model weight","3dd0bdbe":"## utils"}}