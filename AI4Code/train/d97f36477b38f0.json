{"cell_type":{"ccaae822":"code","c52037b8":"code","9c1aeb49":"code","70da02a6":"code","5c12889a":"code","8f3fb18c":"code","a142f1e7":"code","553549f1":"code","9e492d8f":"code","e666c007":"code","f5df68e0":"code","c6c58c75":"markdown","ea2d731b":"markdown","3df502a3":"markdown","413f3810":"markdown","d0259008":"markdown"},"source":{"ccaae822":"import tensorflow as tf\ntf.__version__","c52037b8":"!pip install keras-tuner\nimport kerastuner","9c1aeb49":"# Imports for Deep Learning\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten, BatchNormalization, MaxPooling2D\nfrom keras.models import Sequential, Model\nfrom keras.callbacks import Callback\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import VGG16\nfrom keras import optimizers\n\n# Imports to view data\nimport cv2\nimport numpy as np\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom IPython.display import clear_output\nfrom numpy import floor\nimport random\n\ndef plot_samples(letter):\n    print(\"Samples images for letter \" + letter)\n    base_path = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test\/'\n    img = base_path + letter + \"_test.jpg\"\n    \n    plt.figure(figsize=(16,16))\n    plt.imshow(plt.imread(img))\n    print(img)\n    return cv2.imread(img)\n\nplot_samples('A')","70da02a6":"class PlotLearning(Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n        self.acc = []\n        self.val_acc = []\n        self.fig = plt.figure()\n        \n        self.logs = []\n        \n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n        self.i += 1\n        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n        \n        clear_output(wait=True)\n        \n        ax1.set_yscale('Log')\n        ax1.plot(self.x, self.losses, label=\"loss\")\n        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n        ax1.legend()\n        \n        ax2.plot(self.x, self.acc, label=\"acc\")\n        ax2.plot(self.x, self.val_acc, label=\"val_acc\")\n        ax2.legend()\n        \n        plt.show()\n        \n        \nplot = PlotLearning()","5c12889a":"data_dir = \"..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\"\ntarget_size = (128, 128)\ntarget_dims = (128, 128, 3) # add channel for RGB\nn_classes = 29\nval_frac = 0.2\nbatch_size = 100\n\ndata_augmentor = ImageDataGenerator(\n    samplewise_center=False, \n    samplewise_std_normalization=False, \n    validation_split=val_frac,\n    featurewise_center=False, \n    featurewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0.2,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    brightness_range=None,\n    shear_range=0.0,\n    zoom_range=0.0,\n    channel_shift_range=0.2,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=False,\n    vertical_flip=False, \n    rescale=1.\/255,\n    preprocessing_function=None, \n    data_format='channels_last', \n)\n\ntrain_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, shuffle=True, subset=\"training\")\nval_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, subset=\"validation\")","8f3fb18c":"model = Sequential([\n    BatchNormalization(input_shape=target_dims),\n    Conv2D(32, (3,3), kernel_regularizer=\"l2\", activation='relu', padding='same'),\n    MaxPooling2D((3, 3)),\n    \n    BatchNormalization(),\n    Conv2D(64, (3,3), kernel_regularizer=\"l2\", activation='relu', padding='same'),\n    MaxPooling2D((3, 3)),\n        \n    BatchNormalization(),\n    Conv2D(128, (3,3), kernel_regularizer=\"l2\", activation='relu', padding='same'),\n    MaxPooling2D((3, 3)),\n    \n    Flatten(),\n    \n    BatchNormalization(),\n    Dense(256, kernel_regularizer=\"l2\", activation='relu'),\n    BatchNormalization(),\n    Dense(128, kernel_regularizer=\"l2\", activation='relu'),\n    BatchNormalization(),\n    Dense(64, kernel_regularizer=\"l2\", activation='relu'),\n    BatchNormalization(),\n    Dense(n_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"acc\"])\nmodel.summary()","a142f1e7":"model = VGG16(weights=\"imagenet\", include_top=False, input_shape=target_dims)\nfor layer in model.layers[:-5]:\n    layer.trainable = False\n\ntop_layers = model.output\ntop_layers = Flatten(input_shape=model.output_shape[1:])(top_layers)\ntop_layers = Dense(4096, activation='relu', kernel_initializer='random_normal')(top_layers)\ntop_layers = Dense(n_classes, activation='softmax')(top_layers)\n\nmodel_final = Model(input=model.input, output=top_layers)\n\nsgd = optimizers.SGD(lr=0.01, clipvalue=0.5)\nmodel_final.compile(\n    loss='categorical_crossentropy',\n    optimizer=sgd, metrics=['acc'])\nmodel_final.summary()","553549f1":"#model.fit_generator(train_generator, epochs=40, validation_data=val_generator, validation_steps=200, callbacks=[plot], workers=8, steps_per_epoch=2000)\nmodel_final.fit_generator(train_generator, epochs=10, validation_data=val_generator, validation_steps=200, callbacks=[plot], workers=8, steps_per_epoch=2000)","9e492d8f":"img = cv2.resize(plot_samples('B'), (128, 128))[::-1]\/255\nprint(np.argmax(model_final.predict(np.array([img]))))\n\nimg = cv2.resize(plot_samples('space'), (128, 128))[::-1]\/255\nprint(np.argmax(model_final.predict(np.array([img]))))","e666c007":"model_final.save(\"ASL-model.h5\")\nprint(\"Loss: {}\\nValidation Accuracy: {}\".format(*model.evaluate_generator(generator=val_generator, workers=8, steps=500)))","f5df68e0":"train_generator.class_indices.keys()","c6c58c75":"## Creating Accuracy - Loss Graph callback.","ea2d731b":"# Model Specification","3df502a3":"# The data\n\nThe dataset contains images with 29 different signs in American Sign Language. These are the 26 letters (A through Z) plus the signs for *space*, *delete* and *nothing*. Our model will view these images and learn to classify what sign is made in each image.\n\nSample images below\n","413f3810":"# Model Fitting","d0259008":"# Data Processing Set-Up"}}