{"cell_type":{"5e9a7044":"code","7b235938":"code","5d3e15e4":"code","c66c9ec6":"code","e4687f23":"code","573fdbbf":"code","3b4b663a":"code","b9d184f1":"code","4e01b594":"code","10e3d4bb":"code","8469a277":"code","98d53f53":"code","c1203543":"code","47401a60":"code","cfd9e2df":"code","f2f050e5":"code","32a63ff7":"code","21ebc486":"code","1a78b2f3":"code","5f69ad43":"code","605090e5":"code","d9c81c11":"code","c4c05714":"code","32cb1e26":"code","18da5a64":"code","1b365aec":"code","0e530230":"code","0cb7fd58":"code","7f082cb8":"code","5fa4e4ea":"code","285378ad":"code","c75901a1":"code","b32a809f":"code","7e18936f":"code","dcee7ddc":"code","a80110af":"code","fd9739bd":"code","492f7e6e":"code","aee865dc":"code","8865e761":"code","aa3c2818":"code","be8f9d3a":"code","7952e5c1":"code","36d36718":"code","b8743146":"code","ccee220a":"code","8b79456f":"code","6f244dc0":"code","711d5ee0":"code","8865f1a0":"code","f78795a1":"markdown","79f0a1dc":"markdown","a66d8efd":"markdown","460da357":"markdown","9e645a8a":"markdown","2db6676c":"markdown","745e7fb8":"markdown","6d0568e8":"markdown","738e0a20":"markdown","82964a98":"markdown","25052cb8":"markdown","4ae833b9":"markdown","703c02a8":"markdown","60930342":"markdown","7a561627":"markdown","9bc84bbb":"markdown","fe2e34c6":"markdown","7bc688ea":"markdown","2fcae627":"markdown","9c77ae3c":"markdown","6c43acea":"markdown","e27fdf35":"markdown","ac3f223c":"markdown","b71b6687":"markdown","d7592c89":"markdown","7e330a83":"markdown","ab69e29c":"markdown","593da7ce":"markdown","ffd29115":"markdown","d726be30":"markdown","1daa9606":"markdown","67092f94":"markdown","b59fd3ee":"markdown","99f7e217":"markdown","d26d7e68":"markdown","4092e3db":"markdown","775d0c40":"markdown","ecca8379":"markdown","d6c3dae0":"markdown","67895178":"markdown","a3d34486":"markdown","975c7f62":"markdown","41e78bf8":"markdown","b5bacd62":"markdown","e03b6e0a":"markdown","b1ef53b7":"markdown","448c2cca":"markdown","ae53a4f9":"markdown","35e5a3c8":"markdown","4188cad0":"markdown","ff17901d":"markdown","ba263c2d":"markdown","88ea4682":"markdown","25aec92e":"markdown","ba527723":"markdown","34f1881c":"markdown"},"source":{"5e9a7044":"import numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","7b235938":"import os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5d3e15e4":"%matplotlib inline\n\nplt.style.use('seaborn')\nsns.set(style=\"darkgrid\")\nplt.rcParams['figure.figsize'] = (10.0, 8.0)\nplt.rcParams['xtick.labelsize'] = 14 \nplt.rcParams['ytick.labelsize'] = 14 \nplt.rcParams['axes.labelsize'] = 18\n\nsns.set(font_scale=1.8)\nsns.set(style=\"darkgrid\")\n\npd.options.display.max_columns = 100\npd.options.display.max_rows = 100\npd.options.mode.chained_assignment = None\npd.set_option('display.float_format', lambda x: '%.4f' % x)\nnp.set_printoptions(formatter={'float_kind':'{:f}'.format})","c66c9ec6":"raw_df = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\n\nraw_df.shape","e4687f23":"raw_df.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']","573fdbbf":"raw_df.sample(10)","3b4b663a":"raw_df.info()","b9d184f1":"raw_df.describe()","4e01b594":"fig, ax = plt.subplots(figsize=(14,8))\nsns.set(font_scale=1.5)\nsns.barplot(x=\"rest_ecg\", y=\"target\", data=raw_df, ci=None)\nax.set_xlabel('rest_ecg')\nax.set_ylabel('target')\nplt.title(\"target distribution for each rest ECG value\".title(), fontsize=20)\nplt.show()","10e3d4bb":"from sklearn.preprocessing import OneHotEncoder\n\n\ndf = pd.get_dummies(raw_df, drop_first=True, columns=[\"chest_pain_type\", \"rest_ecg\", \"thalassemia\", \"st_slope\"])\n\ndf.describe()","8469a277":"cols_to_box_plot = [\"cholesterol\", \"max_heart_rate_achieved\"]\n\nfig, ax = plt.subplots(len(cols_to_box_plot), 1, figsize=(12, 10*len(cols_to_box_plot)))\nfor i, col in enumerate(cols_to_box_plot):\n    sns.boxplot(y=col, data=df, ax=ax[i])\n    ax[i].set_title(f\"Box Plot for {col} column\".title())\n    print()\n","98d53f53":"def remove_outliers(df, col_names, how=\"IQR\", what_to_do=\"drop\"):\n    for col_name in col_names:\n        Q1 = df[col_name].quantile(0.25)\n        Q3 = df[col_name].quantile(0.75)\n        IQR = Q3 - Q1  # IQR is interquartile range. \n\n        filter1 = (df[col_name] >= Q1 - 1.5 * IQR) & (df[col_name] <= Q3 + 1.5 *IQR)\n\n        if what_to_do == \"drop\":\n            df = df[filter1]\n\n        if what_to_do == \"median\":\n            df.loc[filter1, col_name] = df.col_name.median()\n\n        if what_to_do == \"mean\":\n            df.loc[filter1, col_name] = df.col_name.mean()\n        break\n        \n    return df","c1203543":"df_with_outliers = df.copy()  # to keep track of whether or not the ouliers removal improved models. And if so, which.\ndf = remove_outliers(df, [\"cholesterol\", \"max_heart_rate_achieved\"])\ndf","47401a60":"df.isna().any()","cfd9e2df":"df.target.value_counts()","f2f050e5":"temp_df = pd.get_dummies(raw_df, drop_first=False, columns=[\"chest_pain_type\", \"rest_ecg\", \"thalassemia\", \"st_slope\"])\n","32a63ff7":"plt.figure(figsize=(22, 16))\nsns.heatmap(temp_df.corr(), annot=True, fmt='.1f', cmap='BrBG', vmax=1, vmin=-1)\nplt.title(\"DataFrame Correlation Matrix\\n\", fontsize=16)\nplt.show()","21ebc486":"plt.figure(figsize=(8, 12))\nheatmap = sns.heatmap(temp_df.corr()[['target']].sort_values(by='target', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\nheatmap.set_title('Features Correlating with the Target feature'.title(), fontdict={'fontsize': 18}, pad=16);","1a78b2f3":"df[\"age_sq\"] = df.age ** 2\ndf[\"age_sex\"] = df.age * df.sex","5f69ad43":"from sklearn.preprocessing import StandardScaler \n\ndesc_df = df.describe()\ncols = [col for col in df.columns if desc_df[col][\"max\"] != 1.0]  # if the max is 1, then it's a dummy var (I checked)\n\nscaler = StandardScaler()\n\nstndrd_df = df.copy()\nstndrd_df[cols] = scaler.fit_transform(df[cols])\n\nstndrd_df.describe()","605090e5":"from sklearn.preprocessing import MinMaxScaler\n\n\ncols = df.columns\nscaler = MinMaxScaler()\nnorm_df = df.copy()\nnorm_df[cols] = scaler.fit_transform(df[cols])\n\nnorm_df.describe()","d9c81c11":"from sklearn.preprocessing import OrdinalEncoder\n\n\ncontinues_cols = [\"age\", \"age_sex\", \"age_sq\", \"resting_blood_pressure\", \"cholesterol\", \"max_heart_rate_achieved\", \"st_depression\"]\ncategory_cols = [\"num_major_vessels\"]\ndummy_cols = [col for col in df.columns if col not in continues_cols + category_cols + [\"target\"]]\n\ndummy_df = df.copy()\n\ndummy_df = pd.get_dummies(dummy_df, drop_first=True, columns=category_cols)\n\nfor col in continues_cols:\n    try:\n        dummy_df[col] = pd.qcut(dummy_df[col], 3, labels=[1, 2, 3], duplicates='drop')\n    except ValueError as e:\n        print(col, e, sep=\"\\n\")\n        dummy_df[col] = pd.qcut(dummy_df[col], q=[0.1, 0.5, 0.8], labels=[1, 2], duplicates='drop')\n\nenc = OrdinalEncoder()\ndummy_df_ = enc.fit_transform(dummy_df)\n\ndummy_df = pd.DataFrame(dummy_df_, columns=dummy_df.columns)\ndummy_df = pd.get_dummies(dummy_df, drop_first=True, columns=continues_cols)\n\n\n[col for col in dummy_df.columns if max(dummy_df[col]) != 1.0]  # make sure all cols are binary","c4c05714":"counts = df.target.value_counts(dropna=False)\ncounts","32cb1e26":"from sklearn.metrics import f1_score \n\n\nacc = len(df[df.target==counts.sort_values(ascending=False).index[0]])\/len(df)\npred = np.ones(len(df))\nf1 = f1_score(df.target, pred)\n\nprint('Beanchmark Accuracy:', acc)\nprint('Beanchmark F1:', f1) # it'll be 0..","18da5a64":"dfs = {\"Normalized_df\": norm_df, \"Standadized_df\": stndrd_df, \"not_scaled_df\": df, \"not_scaled_with_outliers_df\": df_with_outliers}\ndfs_w_dummy = {\"Normalized_df\": norm_df, \"Standadized_df\": stndrd_df, \"not_scaled_df\": df, \"not_scaled_with_outliers_df\": df_with_outliers, \"dummy_df\": dummy_df}  \n# perhaps I won't want to try all models with dummy as well. It's mainly for NB\n\ntarget_var = \"target\"\n\nevaluations = [\"avg_test_accuracy\", \"avg_test_f1\"]\n\nindex = [\n    np.repeat(list(dfs_w_dummy.keys()), len(evaluations)),\n    evaluations * len(dfs_w_dummy)\n        ]\n\nbeanchmark_vals = np.array([acc, f1])\nbeanchmark_vals = np.tile(beanchmark_vals, len(dfs_w_dummy))\n\nevaluation_df = pd.DataFrame(index=index)\nevaluation_df[\"beanchmark\"] = beanchmark_vals\n\nevaluation_df","1b365aec":"from numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_validate\n\n\n\ndef evaluate(classifier, dfs=dfs, k=4):\n    \"\"\"\n    Description: Given a classifier, list of dataframes and k, computes the accuracy and f1 scores with KFOLD, and stores it in evaluation_df for further analysis and comparison.\n    params:\n    classifier: classifier object\n    dfs: list of dataframes. The rational for more than 1 df, is in case you'll want to compare different preprocessed datasets, such as: different features, saclling, etc.\n    k: number of k in KFOLD\n    returns: a DataFrame object\n    \"\"\"\n    clf_name = classifier.__class__.__name__\n    print(f\"For model: {clf_name}\")\n    \n    for i, df_item in enumerate(dfs.items()):\n        df_name = df_item[0]\n        df_ = df_item[1]\n        \n        X = df_.loc[:, df_.columns != target_var]\n\n        y = df_[target_var]\n        \n        scores = cross_validate(classifier, X, y, cv=k, scoring=('accuracy', 'f1'), return_train_score=True)\n        avg_test_accuracy = scores['test_accuracy'].mean()\n        avg_test_f1 = scores['test_f1'].mean()\n        \n        print(f\"\\nfor dataframe {df_name}:\")\n        print(f\"{avg_test_accuracy:.3f} accuracy with a standard deviation of {scores['test_accuracy'].std():.3f}\")\n        print(f\"{avg_test_f1:.3f} f1 with a standard deviation of {scores['test_f1'].std():.3f}\")\n        print(\"Train accuracy:\", scores[\"train_accuracy\"])\n        print((df_name, evaluations), clf_name)\n        evaluation_df.loc[(df_name, evaluations), clf_name] =  [avg_test_accuracy, avg_test_f1]\n\n    \n    print(\"\\n\")\n    \n    return evaluation_df\n\n","0e530230":"from sklearn.model_selection import GridSearchCV\n\n\ndef grid_search(model, grid: dict, dfs=dfs, k=4, to_print=True):\n    \"\"\"\n    Description: Performing a GridSearch given model, dfs and paramters\n    params:\n    model: model object that is working with GridSearchCV\n    grid: a dict object(we can iterate over it: list, tuple, numpy array) grid which has param name and param values\n    dfs: list of dataframes. The rational for more than 1 df, is in case you'll want to compare different preprocessed datasets, such as: different features, saclling, etc.\n    k: number of k in KFOLD\n    returns: a dict object, best_params ***on one of the given datasets (if its performed way better than others, we'll see it in evaluation_df)***\n    \"\"\"\n    max_acc = -1\n    for df_name, df_ in dfs.items():\n        X = df_.loc[:, df_.columns != target_var]\n        y = df_[target_var]\n\n        grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=k, scoring='accuracy',error_score=0)\n        grid_result = grid_search.fit(X, y)\n    \n        print(f\"\\nFor {df_name}:\")\n        print(\"Best: %.3f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n        \n        if grid_result.best_score_ > max_acc: # if this accuracy is higher than the last one, then change the best_params to this one and the max_acc var\n            best_params = grid_result.best_params_ \n            max_acc = grid_result.best_score_\n            \n        means = grid_result.cv_results_['mean_test_score']\n        stds = grid_result.cv_results_['std_test_score']\n        params = grid_result.cv_results_['params']\n        \n        if to_print == True:\n            for mean, stdev, param in zip(means, stds, params):\n                print(\"%.3f (%.3f) with: %r\" % (mean, stdev, param))\n        \n    return best_params # NOTE: That's returning the best performed params, that performed best on a given dataset","0cb7fd58":"stndrd_df.describe()","7f082cb8":"%%time\n\nfrom sklearn.naive_bayes import BernoulliNB\n\n\nbinarize = [-0.5, 0, 0.5]\nstandard_dfs = {\"Standadized_df\": stndrd_df}\ngrid = dict(binarize=binarize)\nmodel = BernoulliNB()\nbest_params = grid_search(model, grid, to_print=False, dfs=dfs_w_dummy)\n\n\n##########################################################################################\n\n\nmodel = BernoulliNB(**best_params)\n\nevaluate(model, k=4, dfs=dfs_w_dummy)","5fa4e4ea":"from sklearn.naive_bayes import GaussianNB\n\n\nmodel = GaussianNB()\n\nevaluate(model, k=4, dfs=dfs_w_dummy)","285378ad":"%%time\n\nfrom sklearn.linear_model import LogisticRegression\n\n\nmodel = LogisticRegression()\n\nsolvers = ['newton-cg', 'liblinear']\npenalty = ['l1', 'l2']\nc_values = (0.1, 1, 2, 5, 10, 20, 30, 40, 50)\nn_jobs = [-1]\n\ngrid = dict(solver=solvers, penalty=penalty, C=c_values)\n\nbest_params = grid_search(model, grid, to_print=False)","c75901a1":"%%time\n\n\nmodel = LogisticRegression(**best_params)\n\nevaluate(model, k=4, dfs=dfs_w_dummy)","b32a809f":"%%time\n\nfrom sklearn.svm import SVC\n\n\nmodel = SVC()\n\nkernel = ['poly', 'rbf', 'sigmoid']\nC = np.linspace(0.1, 20, 4)\ndegree = [2, 3]\ncoef0 = [1, 5]\n\ngrid = dict(kernel=kernel, C=C, degree=degree, coef0=coef0)\n\nbest_params = grid_search(model, grid, to_print=False)","7e18936f":"%%time\n\n\nmodel = SVC(**best_params)\n\nevaluate(model, k=4)","dcee7ddc":"%%time\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\nmodel = KNeighborsClassifier()\n\nn_neighbors = range(3, 24, 3)\nweights = ['uniform', 'distance']\nmetric = ['minkowski']  # remember that minkowski can be manhattan or euclidean (p=1, p=2, respectively)\np = [1, 2, 3, 4]  # for minkowski\n\n\ngrid = dict(n_neighbors=n_neighbors, weights=weights, metric=metric, p=p, n_jobs=n_jobs)\n\nbest_params = grid_search(model, grid)","a80110af":"%%time\n\n\nmodel = KNeighborsClassifier(**best_params)\n\nevaluate(model, k=4)","fd9739bd":"%%time\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nmodel = DecisionTreeClassifier()\n\nmin_samples_leaf = np.linspace(5, 20, 4).astype(int)\nmax_depth = [3, 7, 9]\n\n\ngrid = dict(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n\n\nbest_params = grid_search(model, grid)","492f7e6e":"%%time\n\n\nmodel = DecisionTreeClassifier(**best_params)\n\nevaluate(model, k=4, dfs=dfs_w_dummy)","aee865dc":"%%time\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nmodel = RandomForestClassifier()\n\n\nn_estimators = [10, 100, 500, 1000]\nmin_samples_leaf = np.linspace(5, 20, 4).astype(int)\nmax_depth = [3, 7, 9]\n\n\ngrid = dict(n_estimators=n_estimators, max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n\n\nbest_params = grid_search(model, grid, to_print=False)","8865e761":"%%time\n\n\nmodel = RandomForestClassifier(**best_params)\n\nevaluate(model, k=4)","aa3c2818":"%%time\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\nmodel = AdaBoostClassifier()\n\n\nn_estimators = [10, 100, 500, 700, 1000]\nlearning_rate = [0.001, 0.01, 0.1]\n\n\ngrid = dict(learning_rate=learning_rate, n_estimators=n_estimators)\n\n\nbest_params = grid_search(model, grid)","be8f9d3a":"%%time\n\n\nmodel = AdaBoostClassifier(**best_params)\n\nevaluate(model, k=4)","7952e5c1":"%%time\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\nmodel = GradientBoostingClassifier()\n\nn_estimators = [10, 100, 1000]\nlearning_rate = [0.001, 0.01, 0.1]\nsubsample = [0.5, 0.7, 1.0]\nmax_depth = [3, 7, 9]\n\n\ngrid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n\nbest_params = grid_search(model, grid, to_print=False)","36d36718":"%%time\n\n\nmodel = GradientBoostingClassifier(**best_params)\n\nevaluate(model, k=4)","b8743146":"from sklearn.neural_network import MLPClassifier\n\nmodel = MLPClassifier()\n\n\nbatch_size = [16, 32, 64, 'auto']\nhidden_layer_sizes = [(10, 10), (20, 5), (5, 5), (10), (5, 5, 5)]\nsolver = ['adam']\nalpha = [0.001, 0.01]\nlearning_rate = [\"invscaling\", \"constant\"]\nlearning_rate_init = [0.001, 0.01]\nmomentum = [0.0, 0.9]\nactivation = ['relu', 'tanh']\n\n\ngrid = dict(batch_size=batch_size, hidden_layer_sizes=hidden_layer_sizes)#, solver=solver, alpha=alpha, learning_rate=learning_rate, learning_rate_init=learning_rate_init, momentum=momentum, activation=activation)\n\nbest_params = grid_search(model, grid, to_print=False)","ccee220a":"%%time\n\n\nmodel = MLPClassifier(**best_params)\n\nevaluate(model, k=4)","8b79456f":"evaluation_df","6f244dc0":"evaluation_df1 = evaluation_df.groupby(level=[1]).max() * 100 \nevaluation_df1 = evaluation_df1.T.reset_index(col_fill=\"model\")\nevaluation_df1.rename(columns={'index': 'model'}, inplace=True)\nevaluation_df1","711d5ee0":"y = evaluation_df1.avg_test_accuracy\n\n\n\nfig, ax = plt.subplots(figsize=(20, 10))\nplt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\nplot = sns.barplot(x=evaluation_df1.model, y=y)\nplt.title(\"Test set\/s Mean accuracy %\".title())\n\n# annotate the accuracy\nfor bar in plot.patches:\n    plot.annotate(format(bar.get_height(), '.2f'),\n                   (bar.get_x() + bar.get_width() \/ 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 5),\n                   textcoords='offset points')\n    \nfor bar in ax.patches:\n    bar.set_facecolor('#888888')\n\nhighlight = evaluation_df1.iloc[y.idxmax()].model\n\npos = y.idxmax()\n\nax.patches[pos].set_facecolor('#aa3333')","8865f1a0":"y = evaluation_df1.avg_test_f1\n\n\nfig, ax = plt.subplots(figsize=(20, 10))\nplt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\nplot = sns.barplot(x=evaluation_df1.model, y=y)\nplt.title(\"Test set\/s Mean f1 score %\".title())\n\n# annotate the accuracy\nfor bar in plot.patches:\n    plot.annotate(format(bar.get_height(), '.2f'),\n                   (bar.get_x() + bar.get_width() \/ 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 5),\n                   textcoords='offset points')\n    \nfor bar in ax.patches:\n    bar.set_facecolor('#888888')\n\nhighlight = evaluation_df1.iloc[y.idxmax()].model\n\npos = y.idxmax()\n\nax.patches[pos].set_facecolor('#aa3333')","f78795a1":"# Neural Networks","79f0a1dc":"# KNN","a66d8efd":"Standardization: Will scale the input to have mean of 0 and variance of 1. $$X_{stand} = \\frac{X - \\mu}{\\sigma}$$\n","460da357":"Now, let's try with the dummy df (binarize paramter in BernoulliNB makes it 2 categories features). <\/br>\nNote: BernoulliNB on standadized df is only 2 categories while the dummy df has 3 categories for the continues values. it shouldn't behave too different.<\/br>\nLet's see if it's better that way. <\/br>","9e645a8a":"# Exploring the data + Preprocessing","2db6676c":"Since 54% of the dataset had a heart disease, we can't infer anything by the target feature frequency in other features(such as age), becuase it has a strong bias. <\/br>\nThat is, we can't say that (for example) for ages 25-35 has higher probability of having a heart disease than 35-45.","745e7fb8":"# Support Vector Machines","6d0568e8":"The dataset is balanced, so it'll probably be easy to get better accuracy than the beanchmark.","738e0a20":"## First, Benchmark","82964a98":"### Helper function, to perform a grid search","25052cb8":"## Standardization","4ae833b9":"Let's change the column names to be a bit clearer\n","703c02a8":"# Feature Scalling","60930342":"Reminder: the box is 25th-75th percentiles (aka IQR). The bottom and top lines are defined by: \n<\/br>\ntop: 75th percentile + 1.5 * IQR\n<\/br>\nbottom:25th percentile - 1.5 * IQR\n","7a561627":"# ML models","9bc84bbb":"## Normalization","fe2e34c6":"It doesn't seem there's a strong Multicollinearity in the data. <\/br>\nPerhaps st_slope and st_depression (0.6) are strognly correlated and hence, worth considiration in terms of whether or not to remove one of them.","7bc688ea":"For the Bernoully naive bayes, we need to binarize values, so we will only use the standardized df(has both negative and positive values, approx in the 50 percentile) with different binarize values (ex: binarize=0 is to cut it to approx half 0 and half 1). ","2fcae627":"Let's create a temp df with one-hot-encoding, without throwing the first categorical value, <\/br>\nto better understand the corrleation matrix\n","9c77ae3c":"Let's remove the outliers","6c43acea":"Min Max Scaling: Will scale the input to have minimum of 0 and maximum of 1. <\/br> That is, it scales the data in the range of [0, 1] This is useful when the parameters have to be on same positive scale. But in this case, the outliers are lost. $$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$","e27fdf35":"Note that this accuracies are a result of the best-performed hyperparamters & data type.","ac3f223c":"### There are deifferent kinds of naive bayes classifiers. <\/br>\nall bayes classifiers obey to this equation: p(y | x1; x2...; xn) = p (x1; x2...; xn | y) * p(y) \/ p(x).  <\/br>\n* Multinomial - the most common one, assumes discrete features. simple conditional probability with the probability being simply the frequency of each feature in each class.  <\/br>\n* Gaussian - assumes the likelihood probabilities follow Gaussian distribution.  <\/br>\n* Bernoully - assumes bernoully distribution of the features(binary).\n* Categorical - assumes features are categorical","b71b6687":"### Outliers","d7592c89":"Note to self: no need for categorical NB because bernoully NB takes its place.\n<\/br>\nAlso, multinominal is not relavent beacuse it's not suited for both continues and binary data. It needs discrite values.","7e330a83":"From looking at the features description, I don't understand some of the features nature. <br\/>\nThose features are: \n<br\/>resting electrocardiographic results (values 0,1,2)\n\n<br\/> Is this ordinal? <br\/> I need to know this in order to decide whether or not I should perform one-hot-encoding on it (if it's ordinal, it's better to leave it as-is).","ab69e29c":"The benchmark would be the most common label in the train set","593da7ce":"Doesnt seem ordinal to me.\nLet's one-hot-encode!","ffd29115":"check for NAs","d726be30":"Great! no NAs at all                     ","1daa9606":"It's well known that older people tend to have higher possibilty for heart disease, I wonder in what age does this start to reflect, and by how much. Let's check","67092f94":"# Logistic Regression!","b59fd3ee":"## And the winner is ... (Drumroll...) ...","99f7e217":"### Correlations","d26d7e68":"Let's explore some more","4092e3db":"#### Let's create some variables and dfs that will help with the help functions","775d0c40":"Data contains;\n\n* age - age in years\n* sex - (1 = male; 0 = female)\n* cp - chest pain type\n* trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n* chol - serum cholestoral in mg\/dl\n* fbs - (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n* restecg - resting electrocardiographic results\n* thalach - maximum heart rate achieved\n* exang - exercise induced angina (1 = yes; 0 = no)\n* oldpeak - ST depression induced by exercise relative to rest\n* slope - the slope of the peak exercise ST segment\n* ca - number of major vessels (0-3) colored by flourosopy\n* thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n* target - have disease or not (1=yes, 0=no)","ecca8379":"We'll try both Normalization & standadization, and see which one performes better.","d6c3dae0":"Since the dataset is not big, outliers will have a significant impact. Let's boxlot some outlier suspected columns","67895178":"# Logistic regression","a3d34486":"# Diagnosing Heart Disease","975c7f62":"# Naive Bayes","41e78bf8":"Makes sense that BernoulliNB will work best on the standardized df(with binary=0 or close to it). <\/br> However, it doesn't seem siginificant, which probably means that the already-binary(those the model didn't binarize) features has the most impact on the model.","b5bacd62":"# Evaluation","e03b6e0a":"# XGBoost","b1ef53b7":"### One-Hot-Encoding","448c2cca":"## Dummy df (for Bernoulli Naive bayes)","ae53a4f9":"# Random Forest","35e5a3c8":"# Import the Data","4188cad0":"# Decision Tree","ff17901d":"# AdaBoost","ba263c2d":"### Understanding resting electrocardiographic results","88ea4682":"## Feature Engineering","25aec92e":"So, let's try to make sense of the not-understood features","ba527723":"### Helper function, to evaluate a model","34f1881c":"### Get some basic feel for the data"}}