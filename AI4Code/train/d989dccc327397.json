{"cell_type":{"694dc866":"code","d83565fa":"code","5f7a18d5":"code","ebee7b03":"code","a76ad92b":"code","8586c983":"code","99491a52":"code","b7255c50":"code","b0231776":"code","fa697fc5":"code","0211d38d":"code","7f65039f":"code","e9e29208":"code","a9904aa1":"code","05a672ca":"code","9289c4fa":"code","ab99a6b2":"code","08646812":"code","f8e16a29":"code","f18161ff":"code","4e8d3414":"code","ad431935":"code","7957cd02":"code","f8296fd3":"code","129c8460":"code","124044c3":"code","0f59557a":"code","e3717a45":"code","db7cf5aa":"code","2cde194d":"code","6f53c1ca":"code","c156d5ce":"code","6df35d8d":"code","64d95f76":"code","6fafe9c6":"code","db53131a":"code","84e9572c":"code","f5e130c6":"code","c233400a":"code","0353cf8c":"code","2c907fbe":"code","1df51179":"code","63b8b27e":"code","275daa48":"code","d7ed1b58":"code","6a509261":"code","93ad2b44":"code","21a35123":"code","ba37f799":"code","13bbe808":"code","77a567de":"code","edb3c75c":"code","da5cc910":"code","70fc7d03":"code","be3fad8f":"code","fa1c9b3d":"code","4f743494":"code","235ebc3d":"code","e049b604":"markdown","8355ab84":"markdown","27b64020":"markdown","941a1630":"markdown","df85e1b0":"markdown","a931b50f":"markdown","4907c544":"markdown","1c759032":"markdown","5f75e91b":"markdown","7af6bd68":"markdown","595e33ff":"markdown","b5a5fc4c":"markdown","e5bbe68c":"markdown","abebf82a":"markdown"},"source":{"694dc866":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","d83565fa":"data_train = pd.read_csv('..\/input\/train.csv')\ndata_test = pd.read_csv('..\/input\/test.csv')","5f7a18d5":"data_train.info()","ebee7b03":"data_train.head()","a76ad92b":"def detect_outliers(df,n,features):\n    outlier_indices = []\n    for col in features:\n        Q1 = np.percentile(df[col],25)\n        Q3 = np.percentile(df[col],75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step)].index\n        outlier_indices.extend(outlier_list_col)\n\n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(k for k, v in outlier_indices.items() if v>n)\n    return multiple_outliers","8586c983":"data1 = data_train.copy()","99491a52":"Outliers_to_drop = detect_outliers(data1,2,['Age','Parch','Fare','SibSp'])\ndata1.iloc[Outliers_to_drop]","b7255c50":"data2 = data1.drop(Outliers_to_drop).reset_index(drop=True)\ndata3 = data2.copy()","b0231776":"data2.info()","fa697fc5":"data2.head(3)","0211d38d":"def categorical_plot(df, feature):\n    sns.countplot(data=df, x=feature)\n    sns.factorplot(data=df, x=feature,y ='Survived', kind='bar')","7f65039f":"categorical_plot(data2, 'Pclass')","e9e29208":"categorical_plot(data2, 'Sex')","a9904aa1":"sns.factorplot(data=data2, x='Pclass',y ='Survived', hue='Sex',kind='bar')","05a672ca":"data2['Sex'] = data2['Sex'].apply(lambda x: 1 if x=='male' else 0)","9289c4fa":"categorical_plot(data2, 'Embarked')","ab99a6b2":"data2['Embarked'] = data2.Embarked.fillna('S')","08646812":"sns.factorplot(data=data2, x='Embarked', y ='Survived', hue='Sex',kind='bar')","f8e16a29":"data2['Cabin_Initial'] = data2['Cabin'].apply(lambda x: 'NA' if pd.isna(x) else str(x)[0])\ndata2.Cabin_Initial.value_counts()","f18161ff":"categorical_plot(data2, 'Cabin_Initial')","4e8d3414":"sns.factorplot(data=data2, x='Cabin_Initial', y ='Survived', hue='Sex',kind='bar')","ad431935":"sns.distplot(data2[-(data2['Age'].isna())].Age)","7957cd02":"data2.head(3)","f8296fd3":"na_index = list(data2[data2['Age'].isna()].index)\nage_median = data2[-(data2['Age'].isna())].Age.median()\nfor i in na_index:\n    age_median2 = data2[((data2['Sex']==data2.iloc[i]['Sex'])&(data2['SibSp']==data2.iloc[i]['SibSp'])&(data2['Parch']==data2.iloc[i]['Parch']))]['Age'].median()\n    if not np.isnan(age_median2):\n        data2['Age'].iloc[i] = age_median2\n    else:\n        data2['Age'].iloc[i] = age_median","129c8460":"sns.distplot(data2.Age)","124044c3":"data2['Age_bucket'] = pd.cut(data2['Age'], 6, labels=['A','B','C','D','E','F'])","0f59557a":"data2.head()","e3717a45":"sns.factorplot(data=data2, x='Age_bucket', y='Survived',kind='bar')","db7cf5aa":"def age_gap(x):\n    if x < 8:\n        return 'A'\n    elif x < 12:\n        return 'B'\n    elif x < 18:\n        return 'C'\n    elif x < 50:\n        return 'D'\n    elif x < 60:\n        return 'E'\n    else:\n        return 'F'","2cde194d":"data2['Age_bucket2'] = data2['Age'].apply(age_gap)\nsns.factorplot(data=data2, x='Age_bucket2', y='Survived',kind='bar')","6f53c1ca":"sns.factorplot(data=data2, x='SibSp', y='Survived',kind='bar')","c156d5ce":"sns.factorplot(data=data2, x='Parch', y='Survived',kind='bar')","6df35d8d":"data2['Family'] = data2['Parch']+data2['SibSp']+1\nsns.factorplot(data=data2, x='Family', y='Survived',kind='bar')","64d95f76":"data2['Title'] = data2['Name'].map(lambda i: i.split(',')[1].split('.')[0].strip())\ndata2['Title'].value_counts()","6fafe9c6":"data2['Title'] = data2['Title'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndata2['Title'] = data2['Title'].map({'Master':0, 'Miss':1, 'Ms' : 1 , 'Mme':1, 'Mlle':1, 'Mrs':1, 'Mr':2, 'Rare':3})\ndata2['Title'] = data2['Title'].astype(int)\n\nsns.factorplot(data=data2, x='Title', y='Survived',kind='bar')","db53131a":"data2.head(3)","84e9572c":"data2['Ticket_Initial'] = data2['Ticket'].apply(lambda x: 'NA' if x.isdigit() else \n                                               x.replace('.','').replace('\/','').strip().split(' ')[0])\ndata2[['Ticket_Initial','Survived']].groupby(by='Ticket_Initial', as_index=True).mean().sort_values(by='Survived', ascending=False)","f5e130c6":"sns.distplot(data2.Fare)","c233400a":"data2['Fare_log'] = data2['Fare'].apply(lambda x: np.log(x) if x !=0 else 0)\nsns.distplot(data2.Fare_log)","0353cf8c":"data2['Fare_bucket'] = pd.cut(data2['Fare_log'], bins=4, labels=['A','B','C','D'])\nsns.factorplot(data=data2, x='Fare_bucket', y='Survived',kind='bar')","2c907fbe":"data_test.head()","1df51179":"data_all = pd.concat([data3, data_test], axis=0).reset_index(drop=True)\ntrain_len = len(data3)","63b8b27e":"data_all['Embarked'] = data_all.Embarked.fillna('S')\ndata_all['Cabin_Initial'] = data_all['Cabin'].apply(lambda x: 'NA' if pd.isna(x) else str(x)[0])\n\nna_index = list(data_all[data_all['Age'].isna()].index)\nage_median = data_all[-(data_all['Age'].isna())].Age.median()\nfor i in na_index:\n    age_median2 = data_all[((data_all['Sex']==data_all.iloc[i]['Sex'])&(data_all['SibSp']==data_all.iloc[i]['SibSp'])&(data_all['Parch']==data_all.iloc[i]['Parch']))]['Age'].median()\n    if not np.isnan(age_median2):\n        data_all['Age'].iloc[i] = age_median2\n    else:\n        data_all['Age'].iloc[i] = age_median\n        \ndata_all['Age_bucket2'] = data_all['Age'].apply(age_gap)\n\ndata_all['Family'] = data_all['Parch']+data_all['SibSp']+1\ndata_all['Title'] = data_all['Name'].map(lambda i: i.split(',')[1].split('.')[0].strip())\ndata_all['Title'] = data_all['Title'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndata_all['Title'] = data_all['Title'].map({'Master':0, 'Miss':1, 'Ms' : 1 , 'Mme':1, 'Mlle':1, 'Mrs':1, 'Mr':2, 'Rare':3})\ndata_all['Title'] = data_all['Title'].astype(int)\n\ndata_all['Ticket_Initial'] = data_all['Ticket'].apply(lambda x: 'NA' if x.isdigit() else \n                                               x.replace('.','').replace('\/','').strip().split(' ')[0])\ndata_all['Fare_log'] = data_all['Fare'].apply(lambda x: np.log(x) if x !=0 else 0)\ndata_all['Fare_bucket'] = pd.cut(data_all['Fare_log'], bins=4, labels=['A','B','C','D'])","275daa48":"data_all.tail()","d7ed1b58":"dummies_Age = pd.get_dummies(data_all['Age_bucket2'], prefix='Age_bucket2')\ndummies_Cabin = pd.get_dummies(data_all['Cabin_Initial'], prefix='Cabin_Initial')\ndummies_Embarked = pd.get_dummies(data_all['Embarked'], prefix='Embarked')\ndummies_Fare = pd.get_dummies(data_all['Fare_bucket'], prefix='Fare_bucket')\ndummies_Ticket = pd.get_dummies(data_all['Ticket_Initial'], prefix='Ticket_Initial')\ndummies_Pclass = pd.get_dummies(data_all['Pclass'], prefix='Pclass')\ndummies_Sex = pd.get_dummies(data_all['Sex'], prefix='Sex')\ndummies_Family = pd.get_dummies(data_all['Family'], prefix='Family')\ndummies_Name = pd.get_dummies(data_all['Title'], prefix='Title')\n\ndata_all = pd.concat([data_all, dummies_Age, dummies_Cabin, dummies_Embarked, dummies_Fare,\n                     dummies_Ticket,dummies_Pclass,dummies_Sex,dummies_Family,dummies_Name], axis=1)","6a509261":"data_all.head(3)","93ad2b44":"train_df = data_all[:train_len].filter(regex='Age_bucket2_.*|Fare_bucket_.*|Cabin_Initial_.*|Embarked_.*|Sex_.*|Pclass_.*|Family_.*|Ticket_Initial_.*|Title_.*')\ntest_df = data_all[train_len:].filter(regex='Age_bucket2_.*|Fare_bucket_.*|Cabin_Initial_.*|Embarked_.*|Sex_.*|Pclass_.*|Family_.*|Ticket_Initial_.*|Title_.*')\n\ntrain = train_df.as_matrix()\ntest = test_df.as_matrix()\n\nX = train\ny = data_all[:train_len]['Survived'].as_matrix()","21a35123":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)","ba37f799":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score","13bbe808":"from sklearn.linear_model import LogisticRegression\n\nlgr = LogisticRegression()","77a567de":"C = [0.001,0.01,0.1,1,10,100]\npenalty = ['l1','l2']\n\nparam_grid = dict(C=C, penalty=penalty)\n\ngrid_search = GridSearchCV(lgr, param_grid, scoring='accuracy', cv=5)\ngrid_result = grid_search.fit(X_train, y_train)\n\nresult_lgr = pd.DataFrame(grid_result.cv_results_)\nresult_lgr.sort_values(by='mean_test_score', ascending=False)","edb3c75c":"best_lgr = grid_search.best_estimator_\ny_pred = best_lgr.predict(X_test)\nprint(accuracy_score(y_test,y_pred))","da5cc910":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()","70fc7d03":"n_estimators = [i for i in range(50,350,10)]\nmax_depth = [i for i in range(7,13,1)]\n\nparam_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n\ngrid_search = GridSearchCV(rfc, param_grid, scoring='accuracy', cv=5)\ngrid_result = grid_search.fit(X_train, y_train)\n\nresult_rfc = pd.DataFrame(grid_result.cv_results_)\nresult_rfc.sort_values(by='mean_test_score', ascending=False)","be3fad8f":"best_rfc = grid_search.best_estimator_\ny_pred = best_rfc.predict(X_test)\nprint(accuracy_score(y_test,y_pred))","fa1c9b3d":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier()","4f743494":"n_estimators = [i for i in range(50,350,10)]\nmax_depth = [i for i in range(7,13,1)]\n\nparam_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n\ngrid_search = GridSearchCV(gbc, param_grid, scoring='accuracy', cv=5)\ngrid_result = grid_search.fit(X_train, y_train)\n\nresult_gbc = pd.DataFrame(grid_result.cv_results_)\nresult_gbc.sort_values(by='mean_test_score', ascending=False)","235ebc3d":"best_gbc = grid_search.best_estimator_\ny_pred = best_gbc.predict(X_test)\nprint(accuracy_score(y_test,y_pred))","e049b604":"### GradientBoosting","8355ab84":"### Sex","27b64020":"### EDA&Feature Engineering","941a1630":"### Pclass","df85e1b0":"### Concat","a931b50f":"### Cabin","4907c544":"> ### RandomForest","1c759032":"### Ticket","5f75e91b":"### Name","7af6bd68":"### Age","595e33ff":"### Embark","b5a5fc4c":"### SibSp","e5bbe68c":"### Logistic Regression","abebf82a":"### Fare"}}