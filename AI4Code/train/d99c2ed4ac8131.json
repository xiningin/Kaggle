{"cell_type":{"3076b09b":"code","cf2d58ad":"code","7cf103d5":"code","5fa0d7e2":"code","5da7166d":"code","c9c49852":"code","3112fcb2":"code","3d142651":"code","e26c08a1":"code","941a99c6":"code","c33bd3fa":"code","a4380262":"code","6b5b07b5":"code","7aa12a24":"code","7ff68b20":"code","b49e1daf":"code","038ac4bd":"code","68ac33d1":"code","748e9dfd":"code","98c6d6e1":"code","f1860415":"code","2d51eed6":"code","1fb85dd2":"code","a1916736":"code","6320b5e8":"markdown","ef187708":"markdown","2e2983c2":"markdown","6e697143":"markdown","84e16a4e":"markdown","7e9ae13e":"markdown","cb6575b6":"markdown","5be58c7b":"markdown","d5bfc610":"markdown","d7d7a515":"markdown","ea219912":"markdown","3b493d2b":"markdown","bfb55e07":"markdown","09f953ef":"markdown","0c70330b":"markdown","33c90e80":"markdown","acacce3e":"markdown","d1ad3f79":"markdown","7ad0db4e":"markdown","d65fd4c3":"markdown","afcb3cf9":"markdown","d8f1316a":"markdown","3e95142a":"markdown","0ca40c3c":"markdown","78564c2a":"markdown","e15bc0fe":"markdown","abe3cf17":"markdown"},"source":{"3076b09b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport ast\nimport plotly.express as px\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf2d58ad":"df = pd.read_csv(\"..\/input\/huggingface-modelhub\/huggingface_models.csv\")","7cf103d5":"df.sample(3)","5fa0d7e2":"df[\"tags\"] = df[\"tags\"].apply(ast.literal_eval)\ndf[\"files\"] = df[\"files\"].apply(ast.literal_eval)","5da7166d":"px.bar(df[\"pipeline_tag\"].value_counts().reset_index(), x=\"index\", y=\"pipeline_tag\", labels={\"index\": \"pipeline-tag\", \"pipeline_tag\": \"Count\"})","c9c49852":" px.bar(df.sort_values(\"downloads_last_month\", ascending=False)[:20], x=\"modelId\", y=\"downloads_last_month\")","3112fcb2":" px.bar(df[df[\"publishedBy\"]!=\"huggingface\"].sort_values(\"downloads_last_month\", ascending=False)[:20], x=\"modelId\", y=\"downloads_last_month\")","3d142651":" px.bar(df[\"publishedBy\"].value_counts()[:20].reset_index(), x=\"index\", y=\"publishedBy\", labels={\"index\": \"Top 20 publishers\", \"publishedBy\": \"Count\"})","e26c08a1":"px.bar(df[[\"publishedBy\", \"downloads_last_month\"]]\n       .groupby(\"publishedBy\").sum().reset_index().sort_values(\"downloads_last_month\", ascending=False)[:20],\n       x=\"publishedBy\", y=\"downloads_last_month\", labels={\"y\": \"Total downloads last month\"})","941a99c6":"df[\"hf_or_not\"] = df[\"publishedBy\"].apply(lambda x: \"huggingface\" if x==\"huggingface\" else \"others\")\npx.pie(df, values=\"downloads_last_month\", names=\"hf_or_not\", title=\"Share of Downloads (HuggingFace models vs Others)\")","c33bd3fa":"def is_tf_torch_present(x):\n    if \"tf\" in x and \"pytorch\" in x:\n        return \"Both\"\n    elif \"pytorch\" in x:\n        return \"PyTorch\"\n    elif \"tf\" in x:\n        return \"Tensorflow\"\n    return None\ndf[\"tf_torch\"] = df[\"tags\"].apply(lambda x: is_tf_torch_present(x))","a4380262":"df_temp = df[\"tf_torch\"].value_counts().reset_index()\npx.pie(df_temp, values=\"tf_torch\", names=\"index\", title=\"Model availability Pytorch vs Tensorflow (based on Tags)\")","6b5b07b5":"def is_tf_torch_present_by_files(x):\n    is_tf, is_torch = False, False\n    for y in x:\n        if '.h5' in y:\n            is_tf = True\n        if '.bin' in y:\n            is_torch = True\n    if is_tf and is_torch:\n        return \"Both\"\n    elif is_tf:\n        return \"Tensorflow\"\n    elif is_torch:\n        return \"PyTorch\"","7aa12a24":"df[\"tf_torch_by_files\"] = df[\"files\"].apply(is_tf_torch_present_by_files)\ndf_temp = df[\"tf_torch_by_files\"].value_counts().reset_index()\npx.pie(df_temp, values=\"tf_torch_by_files\", names=\"index\", title=\"Model availability Pytorch vs Tensorflow (based on Files)\")","7ff68b20":"df_temp = df[[\"tf_torch\", \"downloads_last_month\"]].groupby(\"tf_torch\").sum().reset_index()\npx.pie(df_temp, values=\"downloads_last_month\", names=\"tf_torch\", title=\"Share of Downloads between Tf vs Torch models\")","b49e1daf":"# First we need to convert it into datetime format\ndf[\"lastModified\"] = pd.to_datetime(df[\"lastModified\"])","038ac4bd":"# Let's create a new column year-month, eg: 2020-01 denoting Jan20\ndef get_year_month(x):\n    return str(x.year) + \"-\" + str(x.month)\ndf[\"year\"] = df[\"lastModified\"].dt.year\ndf[\"month\"] = df[\"lastModified\"].dt.month\ndf[\"year-month\"] = df[\"lastModified\"].apply(lambda x: get_year_month(x))","68ac33d1":"df_temp = df[[\"year-month\", \"year\", \"month\"]].value_counts().reset_index().sort_values([\"year\", \"month\"])\npx.line(df_temp, x=\"year-month\", y=0, title=\"Freshness of models\", labels={\"0\": \"Count of models\"})","748e9dfd":"# We need to derive two new columns from datetime `lastModified` for our heatmap\ndf[\"dayofweek\"] = df[\"lastModified\"].dt.day_name()\ndf[\"dayofweekint\"] = df[\"lastModified\"].dt.dayofweek\ndf[\"hour\"] = df[\"lastModified\"].dt.hour","98c6d6e1":"df_temp = df[[\"dayofweek\", \"hour\", \"modelId\", \"dayofweekint\"]].groupby([\"dayofweek\",\"dayofweekint\", \"hour\"]).count().reset_index()","f1860415":"df_temp = df_temp.reset_index().sort_values([\"dayofweekint\",\"hour\"])\ndef df_to_plotly(df, countCol):\n    return {'z': df[countCol].tolist(),\n            'x': df[\"dayofweek\"].tolist(),\n            'y': df[\"hour\"].tolist()}\nimport plotly.graph_objects as go\nfig = go.Figure(data=go.Heatmap(df_to_plotly(df_temp, countCol=\"modelId\")))\nfig.show()","2d51eed6":"df_temp = df[df[\"publishedBy\"] == \"huggingface\"][[\"dayofweek\", \"hour\", \"modelId\", \"dayofweekint\"]].groupby([\"dayofweek\",\"dayofweekint\", \"hour\"]).count().reset_index()\ndf_temp = df_temp.reset_index().sort_values([\"dayofweekint\",\"hour\"])\ndef df_to_plotly(df, countCol):\n    return {'z': df[countCol].tolist(),\n            'x': df[\"dayofweek\"].tolist(),\n            'y': df[\"hour\"].tolist()}\nimport plotly.graph_objects as go\nfig = go.Figure(data=go.Heatmap(df_to_plotly(df_temp, countCol=\"modelId\")))\nfig.show()","1fb85dd2":"df_temp = df[df[\"publishedBy\"] == \"huggingtweets\"][[\"dayofweek\", \"hour\", \"modelId\", \"dayofweekint\"]].groupby([\"dayofweek\",\"dayofweekint\", \"hour\"]).count().reset_index()\ndf_temp = df_temp.reset_index().sort_values([\"dayofweekint\",\"hour\"])\ndef df_to_plotly(df, countCol):\n    return {'z': df[countCol].tolist(),\n            'x': df[\"dayofweek\"].tolist(),\n            'y': df[\"hour\"].tolist()}\nimport plotly.graph_objects as go\nfig = go.Figure(data=go.Heatmap(df_to_plotly(df_temp, countCol=\"modelId\")))\nfig.show()","a1916736":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nwordcloud = WordCloud().generate(\" \".join(sum(df[\"tags\"].dropna().to_list(),[])))\nplt.figure(figsize=(14,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","6320b5e8":"Observations:\n- Tensorflow-only models account for only **0.11% of downloads**.\n- Even if models containing both tf and torch were **10% in number**, they account for **64% of the downloads**.","ef187708":"#### Huggingtweets update heatmap","2e2983c2":"Observations:\n- Both the approaches of using tag vs filenames lead to similar ratios present.\n- PyTorch seems to be a dominating presence in modelhub as of now.","6e697143":"### Who has published most number of models?","84e16a4e":"#### Top20 most downloaded models provided by community\nExcluding Huggingface's provided models, which are the most downloaded models","7e9ae13e":"#### Identify using 'file extensions'\nNow, as a sanity check(maybe), let's try and generate the same data from list of files available.\n\n![image.png](attachment:7424f7e2-1406-406e-9933-bf80876d50a7.png)\n\nIn the given image, `.bin` could denote existence of a pytorch model, while `.h5` could denote existence of a tensorflow model. Lets try plotting with this logic and see.","cb6575b6":"Observations:\n- **8 out of 20** most downloaded models are community provided(including companies like google). Rest are uploaded by Huggingface.","5be58c7b":"### Most used tags","d5bfc610":"### Number of times model is downloaded Pytorch,Tf or both","d7d7a515":"Column **tags** and **files** are arrays, so we need to process them a bit differently like this:","ea219912":"### Pytorch or Tensorflow?","3b493d2b":"### Which publishers models are most downloaded overall?\nPublisher vs Total Download count of all models. Top-20","bfb55e07":"Observations:\n- **Helsinki-NLP** stands out in top charts having more number of models available and downloads as well.\n- **sentence-transformers** ranked 12 in number of models available but leads in downloads, following huggingface.\n- **huggingtweets** contains generative models, each finetuned to a specific persona, and hence leads in number of available models\n","09f953ef":"In this notebook, I'll attempt visualizing data of models available in [Huggingface Modelhub].(https:\/\/huggingface.co\/models)\n\nThere are two files available under the dataset:\n- huggingface_models.csv : Primary file which contains metadata information like model name, tags, last modified and filenames\n- huggingfacemodelcardreadme.csv : Detailed file containing README.md contents if available for a particular model\n\nWe'll start with loading the csv `huggingface_models.csv` file as a pandas dataframe. Let's start with looking at some sample of rows in the dataset.","0c70330b":"#### When are Huggingface published models uploaded\/updated?","33c90e80":"These are the column descriptions of the dataset:\n- **modelId**: ID of the model as present on HF website\n- **lastModified**: Time when this model was last modified\n- **tags**: Tags associated with the model (provided by mantainer)\n- **pipeline_tag**: If exists, denotes which pipeline this model could be used with\n- **files**: List of available files in the model repo\n- **publishedBy**: Custom column derived from modelID, specifying who published this model\n- **downloads_last_month**: Number of times the model has been downloaded in last month.\n- **library**: Name of library the model belongs to eg: transformers, spacy, timm etc.","acacce3e":"### Are the models updated recently?\nWe don't have `createdAt` in the dataset. Although `lastModified` is available. Using that as proxy, we can try visualizing when were the models last updated.","d1ad3f79":"### How many models are available for different pipelines?","7ad0db4e":"Observations:\n1. [herbert-base-cased](https:\/\/huggingface.co\/allegro\/herbert-base-cased) is a model trained on Polish language. It's graph looks like this:\n![image.png](attachment:dba8a55e-4dea-4e50-aca9-132d737ec0dd.png)\n2. [sentence-transformer model](https:\/\/huggingface.co\/sentence-transformers\/paraphrase-xlm-r-multilingual-v1) is a paraphrasing model. It's graph looks like this:\n![image.png](attachment:4aaaaf5c-9eeb-4343-b5bb-bab1d1b7cb51.png)\n\nIt's likely and possible that herbert downloads could be a part of an automated pipeline which leads to such high peak of downloads like [Apple was accidentlly doing to Huggingface](https:\/\/twitter.com\/julien_c\/status\/1173669642629537795) 2 years back. Note that in the live downloads graphs above, data has changed since it's a current screenshot, whereas the dataset was created earlier.\n\n![image.png](attachment:53b69c74-e34a-46bc-88fb-d074df877617.png)","d65fd4c3":"End notes:\n- Further analysis to be done in coming versions on tags and files\n- README content is unexplored and parsing it will be a challenging problem\n\nPlease upvote if you liked the notebook and share any errors in comments. :)","afcb3cf9":"Observations:\n- Most of the models are updated very recently\n- Number's a lot higher in May, but that could be due to a lot of new models added. Since we only have `lastModified` info, it's not possible to investigage further as it'd need a field like `createdAt`.\n- Oldest available model is from Dec2019\n- Three peaks are observed when more models are updated `August-2020`, `Jan-2021` and `May-2021`. ","d8f1316a":"### What percentage of total model downloads are from huggingface?","3e95142a":"#### Identifying using available 'tags'","0ca40c3c":"Observations:\n- Some of the publishers are companies whereas some are individual contributors. It's difficult to identify the difference just by this dataset itself.\n- Some of the individual publishers *work* at Huggingface","78564c2a":"### Which are the Top-20 Most Downloaded models?\n\"most downloaded\" refers to the past-1month download count available when the dataset was created.","e15bc0fe":"### Heatmap: When are most models uploaded\/updated?","abe3cf17":"Observations:\n- Someone else needs to cross-check this as I can't believe my eyes. Even though the timezone is UTC and folks are spread across globe, but it looks like **out of 75 models uploaded by HF, *zero* of them are uploaded(lastUploaded) on a weekend** "}}