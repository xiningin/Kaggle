{"cell_type":{"a8fb3722":"code","5663dc5f":"code","85f34051":"code","980b5812":"code","f56b8ceb":"code","bc3cf105":"code","19bab828":"code","636935cf":"code","454400bb":"code","c801be57":"markdown","a4d2de75":"markdown","81967eeb":"markdown","4e15882c":"markdown","b5d5a363":"markdown","a88d48fd":"markdown","d0ce74b4":"markdown","e9f4a184":"markdown","80b1f50a":"markdown","53d84af2":"markdown","ca42101d":"markdown","53fb4e86":"markdown","ffe33915":"markdown"},"source":{"a8fb3722":"# Data manipulation\nimport pandas as pd\nimport numpy as np\n# NN architecture\nfrom keras.layers import Input, Dense, Activation, Flatten, Conv2D, MaxPool2D, Dropout\n# Model\nfrom keras.models import Model\n# Optimizer\nfrom keras.optimizers import Adam\n# Visualisation\nimport matplotlib.pyplot as plt\n# Utils\nfrom keras.utils.np_utils import to_categorical","5663dc5f":"train_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\nprint('Training')\nprint('train_df shape :', train_df.shape)\nprint('test_df shape :', test_df.shape)","85f34051":"label_counts = train_df['label'].value_counts()\n\nplt.figure()\nplt.bar(label_counts.index, label_counts.values)\nplt.xticks(label_counts.index)\nplt.title('Count of each label in our training data')\nplt.show()","980b5812":"# Seperating features from labels into different numy arrays\nX_train = train_df.iloc[:, 1:].values\ny_train = train_df.iloc[:, 0].values\nX_test = test_df.values\n\n# One hot encoding the output vector\ny_train = to_categorical(y_train, len(set(y_train)))\n\n# Reshaping data to fit a CNN model\nX_train = X_train.reshape(-1, 28, 28)\nX_test = X_test.reshape(-1, 28, 28)\n\nprint('X_train shape :', X_train.shape)\nprint('y_train shape :', y_train.shape)\nprint('X_test shape :', X_test.shape)","f56b8ceb":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n\ni = 0\nfor ax in [ax1, ax2, ax3, ax4]:\n    ax.imshow(X_train[i])\n    ax.set_title('This is ' + str(np.argmax(y_train[i])))\n    ax.tick_params(bottom = False, top = False, right = False, left = False, \n                   labelbottom = False, labeltop = False, labelright = False, labelleft = False)\n    i += 1\n    \nfig.show()","bc3cf105":"X_input = Input(shape = (28, 28, 1))\n# (28, 28)\nX = Conv2D(4, kernel_size = (3, 3), strides = (1, 1), name = 'Conv1')(X_input)\n# (26, 26)\nX = Conv2D(4, kernel_size = (3, 3), strides = (1, 1), name = 'Conv2')(X)\n# (24, 24)\nX = MaxPool2D(pool_size = (2, 2), strides = (1, 1), name = 'MaxPool1')(X)\n# (23, 23)\nX = Conv2D(2, kernel_size = (3, 3), strides = (1, 1), name = 'Conv3')(X)\n# (21, 21)\nX = Conv2D(1, kernel_size = (3, 3), strides = (1, 1), name = 'Conv4')(X)\n# (19, 19)\nX = MaxPool2D(pool_size = (2, 2), strides = (1, 1), name = 'MaxPool2')(X)\n# (18, 18)\nX = Flatten(name = 'Flatten')(X)\n# (324)\nX = Dense(200, activation = 'relu', name = 'Dense1')(X)\nX = Dropout(rate = .2, name = 'Dropout')(X)\nX = Dense(100, activation = 'relu', name = 'Dense2')(X)\nX = Dense(10, activation = 'softmax', name = 'Dense3')(X)\n\nmodel = Model(inputs = X_input, outputs = X, name = 'MNIST_Classifier')\n\nprint(model.summary())","19bab828":"# Defining the optimizing algorithm and learning rate\noptimizer = Adam(learning_rate = 0.001)\n#Compiling model\nmodel.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n# Fitting model\n_ = model.fit(X_train, y_train, epochs = 35, batch_size = 32)","636935cf":"# Prediction\ny_test = model.predict(X_test)\n# Taking the highest probability output by the softmax activation function and labelling acoordingly\ny_test = [np.argmax(y_test[i]) for i in range(y_test.shape[0])]\n\nprint('Sample of y_test :', y_test[:5])","454400bb":"results = pd.DataFrame(data = y_test, index = range(len(y_test)), columns = ['label'])\nresults = results.reset_index()\nresults.rename(columns = {'index': 'ImageId'}, inplace = True)\nresults['ImageId'] = results['ImageId'] + 1\nresults.to_csv('results.csv', index = False)","c801be57":"## Predicting test data","a4d2de75":"## Libraries","81967eeb":"Images are represented with 784 pixels.\n\nWe have 42 000 instances of training data and 28 000 instances of test data.","4e15882c":"## Checking for imbalanced labels","b5d5a363":"## Creating CNN architecture","a88d48fd":"## Compiling and fitting model","d0ce74b4":"Labels seem to be equally distributed across our training data.\n\nNote : Unequally distributed labels might lead to a biased model.","e9f4a184":"## Data preparation for modeling","80b1f50a":"<div align = 'center'><h1>Digit Recognizer<\/h1><\/div>","53d84af2":"## Creating output file for submission","ca42101d":"## Data preview","53fb4e86":"We have reached 99% accuracy on training data which is perfect.","ffe33915":"## Loading data"}}