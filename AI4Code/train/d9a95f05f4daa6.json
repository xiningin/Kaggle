{"cell_type":{"4077342b":"code","e8553fab":"code","1f5b7ab5":"code","e9e1fe45":"code","bf3230a7":"code","5be23de5":"code","ad15ce01":"code","959d608c":"code","cc198351":"code","1bbaa365":"code","29b513f1":"code","24da94e1":"code","80e63332":"code","ea5dbee6":"code","e1c5622c":"code","41347f31":"code","21d6da94":"code","fa5887c2":"code","fd02daa8":"code","71b6a0ef":"code","0b2663ec":"code","967b6f1c":"code","9b5f7ca0":"code","ffdea54f":"code","a7d8ec10":"code","3a51ebce":"code","6ed014f9":"code","2a694814":"code","18ec4245":"markdown","fd59f56f":"markdown","a0839354":"markdown","a957ffd5":"markdown","4d3475dc":"markdown","adcb67d5":"markdown","37343daa":"markdown","67def246":"markdown","4c58cb1b":"markdown","778fdbab":"markdown","dd9a1501":"markdown","17d43a93":"markdown","c884ff12":"markdown","2b6d269a":"markdown","a9f2d157":"markdown","4b22d825":"markdown","e641e987":"markdown","a3c59b1d":"markdown","1bdbc2b2":"markdown","68f67ec9":"markdown","8352d720":"markdown","93b01d3b":"markdown","c3956fbf":"markdown","f924c290":"markdown","c4516498":"markdown","c30f1cdb":"markdown","25f7e295":"markdown"},"source":{"4077342b":"!pip install pandas_flavor","e8553fab":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer\nfrom sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\nfrom sklearn.linear_model import LogisticRegression, ridge_regression, Lasso, ElasticNet, RidgeClassifierCV, ElasticNetCV\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n","1f5b7ab5":"from pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef missing(df):        \n    tmp =  sorted(\n                [(col , str(df[col].dtypes) ,df[col].isna().sum(), np.round( df[col].isna().sum() \/ len(df) * 100,2) ) for col in df.columns if df[col].isna().sum() !=0 ],\n                key = lambda x: x[2], reverse=True)\n    \n    return pd.DataFrame(tmp).rename({0:\"Feature\", 1:\"dtype\", 2:\"count\", 3:\"percent\"},axis=1)  \n\n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_cols(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef discrete_features_cols(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef discrete_features_df(df,thresold):\n#     thresold in number of unique values\n    return df[ discrete_features_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef continuous_features_cols(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef continuous_features_df(df,thresold):\n    #     thresold in number of unique values\n    return df[ continuous_features_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n@register_dataframe_method\ndef describe_discrete_cols(df,thresold, ascending=True):\n    \n    values = pd.DataFrame()\n    \n    for col in df.discrete_features_cols(thresold=thresold):\n        values[col] = [df[col].unique(), df[col].nunique()]\n        \n    return values.transpose().sort_values(by = 1,ascending=ascending).rename({0:\"Values\",1:\"cardinality\"},axis=1)\n    \n    \n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_dataframe_method\ndef compare_cols(df,l_feat,r_feat, percent=False, percent_of_total=False):\n    \n#     [L_feat] {R_feat1: agg1, R_feat2: agg2}\n\n    \n    if percent or percent_of_total:\n        \n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})\n            \n            if percent: tmp[key +\" %\"] = tmp.groupby(level=0).apply(lambda x: np.round(100 * x \/ float(x.sum()),2))\n\n            if percent_of_total: tmp[key+\" % of total\"] = np.round(tmp[key + \" \" + val] \/ tmp[key + \" \" + val].sum() * 100 , 2)\n            \n            comp.append(tmp)\n            \n        return comp\n    \n    else:\n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})           \n            comp.append(tmp)\n            \n        return comp  \n    \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n\n            length = len(df[i])\n            tmp = np.round((length - df[i].between(lower_range,upper_range).sum())\/length * 100, 2)\n            if tmp != 0:\n                features[i] = tmp\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Outlier percent'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_dataframe_method\ndef drop_row_outlier(df, cols, inplace=False):\n#     init empty index\n    indices = pd.Series(np.zeros(len(df), dtype=bool), index=df.index)\n\n    for col in cols:\n        low, top = df[col].IQR_range()\n        indices |= (df[col] > top) | (df[col] < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n\n@register_series_method\ndef drop_row_outlier(df, inplace=False):\n#     init empty index\n\n    low, top = df.IQR_range()\n        \n    \n    return df.drop(df[ (df > top) | (df < low) ].index, inplace=inplace)\n\n@register_dataframe_method\ndef count_dtypes(df, ascending=False):\n    return pd.DataFrame(df.dtypes.value_counts(ascending=ascending)).rename({0:\"Count\"},axis=1)\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    print(df.dtypes.value_counts(ascending=False))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = missing(df)\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())","e9e1fe45":"def display_multiple_tables(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","bf3230a7":"sns.set(style=\"darkgrid\",font_scale=1.3)\nplt.rcParams['figure.dpi']=100\n\n\nfrom matplotlib.ticker import MaxNLocator\n\ndef srt_reg(y, df,x_size=20,y_size=20,*args,**kwargs):\n    \n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, figsize=(x_size,y_size))\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sns.regplot(x=i,\n                    y=y,\n                    data=df,\n                    ax=j,\n                    order=3,\n                    ci=None,\n                    color='#e74c3c',\n                    line_kws={'color': 'black'},\n                    scatter_kws={'alpha':0.4},\n                   *args,**kwargs)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n        plt.tight_layout()\n\ndef srt_box(y, df,*args,**kwargs):\n    fig, axes = plt.subplots(19, 3, figsize=(30,30))\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sortd = df.groupby([i])[y].median().sort_values(ascending=False)\n        sns.boxplot(x=i,\n                    y=y,\n                    data=df,\n                    palette='plasma',\n                    order=sortd.index,\n                    ax=j,\n                    *args,**kwargs)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n\n\n        \ndef histplt(df,ncols = 3, x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        sns.histplot(x=df,ax=ax,*args,**kwargs)\n        [ ax.bar_label(tmp) for tmp in ax.containers]\n        \n        ax.tick_params(labelrotation=45)\n#         plt.tight_layout()\n        \n    else:\n    \n#         ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, \n                                 figsize=(x_size,y_size)\n                                )\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            sns.histplot(data=df, x=i,ax=j,*args,**kwargs)\n            j.tick_params(labelrotation=45)\n            [ j.bar_label(tmp) for tmp in j.containers]\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n\ndef countplt(df,ncols = 3, x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        sns.countplot(x=df,ax=ax,*args,**kwargs)\n        [ ax.bar_label(tmp) for tmp in ax.containers]\n        \n        ax.tick_params(labelrotation=45)\n#         plt.tight_layout()\n        \n    else:\n    \n#         ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, \n                                 figsize=(x_size,y_size)\n                                )\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            sns.countplot(data=df, x=i,ax=j,*args,**kwargs)\n            j.tick_params(labelrotation=45)\n            [ j.bar_label(tmp) for tmp in j.containers]\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n\n\n    \n    \ndef barplt(df,y,x_size=30,y_size=30,*args,**kwargs):\n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n        \n        if i == y:\n            continue\n\n        sns.barplot(data=df,\n                    x=i,\n                    y=y,\n                    ax=j,*args,**kwargs)\n\n        j.tick_params(labelrotation=45)\n        [ j.bar_label(tmp) for tmp in j.containers]\n#         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n    \n    \ndef violinplt(df,y,ncols=3,x_size=30,y_size=30,x_scale = \"linear\", y_scale = \"linear\", *args,**kwargs):\n    \n    \n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n    \n    if df[y].dtype == 'O':\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.violinplot(data=df,\n                        x=y,\n                        y=i,\n                        ax=j,*args,**kwargs)\n            \n            lower_range, upper_range = df[i].IQR_range()\n            outliers = df[(df[i] > upper_range) | (df[i] < lower_range)][i]\n            sns.scatterplot(y=outliers, x=0, marker='D', color='crimson', ax=j)\n            j.tick_params(labelrotation=45)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n        \n    else:\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            g = sns.violinplot(data=df,\n                        x=i,\n                        y=y,\n                        ax=j,*args,**kwargs)\n            g.set_xscale(x_scale)\n            g.set_yscale(y_scale)\n            j.tick_params(labelrotation=45)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \ndef boxplt(df,y,x_size=30,y_size=30,*args,**kwargs):\n\n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n    \n    if df[y].dtype == 'O':\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.boxplot(data=df,\n                        x=y,\n                        y=i,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n        \n    else:\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.boxplot(data=df,\n                        x=i,\n                        y=y,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n\n\nimport scipy.stats as stats\n\ndef qqplt(df,x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        stats.probplot(df,plot=ax, *args,**kwargs)\n        \n#         ax.set_title(label=df.columns)\n        ax.tick_params(labelrotation=45)\n        ax.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n#         plt.tight_layout()\n        \n    \n    else:\n        ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, figsize=(x_size,y_size))\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            stats.probplot(df[i],plot=j, *args,**kwargs)\n            j.set_title(label=i)\n            j.tick_params(labelrotation=45)\n            j.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n            plt.tight_layout()","5be23de5":"df = pd.read_csv(\"..\/input\/heart-failure-prediction\/heart.csv\")\ndf.about()","ad15ce01":"\nfrom pandas_profiling import ProfileReport\nprofile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n\nprofile.to_widgets()","959d608c":"df.describe_discrete_cols(thresold=10)","cc198351":"countplt(df.discrete_features_df(thresold=10),x_size=40,y_size=20)","1bbaa365":"countplt(df.discrete_features_df(thresold=10),x_size=40,y_size=20, hue=\"HeartDisease\")","29b513f1":"features = df.discrete_features_cols(thresold=10)\nfeatures.remove(\"HeartDisease\")\n\ntables = [compare_cols(df=df, l_feat= [col,\"HeartDisease\"], r_feat={\"HeartDisease\":\"count\"}, percent_of_total=True, percent=True)[0] for col in features]\ndisplay_multiple_tables(tables)","24da94e1":"# display(*df.compare_cols( [\"Sex\",\"ChestPainType\",\"HeartDisease\"], {\"HeartDisease\" :\"count\"}, percent=True, percent_of_total=True) )\n\n\ndisplay(*compare_cols( df[ (df[\"Sex\"]==\"F\") & (df[\"HeartDisease\"]==0) ] , [\"Sex\",\"HeartDisease\",\"ChestPainType\",], { \"ChestPainType\":\"count\"}, percent=True,) )\n\ndisplay(*compare_cols( df[ (df[\"Sex\"]==\"F\") & (df[\"HeartDisease\"]==1) ] , [\"Sex\",\"HeartDisease\",\"ChestPainType\",], { \"ChestPainType\":\"count\"}, percent=True, ) )","80e63332":"display(*compare_cols( df[ (df[\"Sex\"]==\"M\") & (df[\"HeartDisease\"]==0) ] , [\"Sex\",\"HeartDisease\",\"ChestPainType\",], { \"ChestPainType\":\"count\"}, percent=True,) )\ndisplay(*compare_cols( df[ (df[\"Sex\"]==\"M\") & (df[\"HeartDisease\"]==1) ] , [\"Sex\",\"HeartDisease\",\"ChestPainType\",], { \"ChestPainType\":\"count\"}, percent=True, ) )","ea5dbee6":"df.continuous_features_cols(thresold=10)","e1c5622c":"histplt(df.continuous_features_df(thresold=10), x_size=50, y_size=20)","41347f31":"df.drop_row_outlier(cols = ['RestingBP', 'Oldpeak'], inplace=True)\n\nhistplt(df.continuous_features_df(thresold=10), x_size=50, y_size=20)","21d6da94":"cont_feat = df.continuous_features_cols(thresold=10)\ncont_feat.append(\"HeartDisease\")\n\nhistplt(df = df[cont_feat], x_size=50, y_size=25, hue=\"HeartDisease\", multiple='stack')","fa5887c2":"from sklearn.preprocessing import LabelEncoder","fd02daa8":"df.describe_discrete_cols(thresold=10)","71b6a0ef":"obj_cols = list(df.select_dtypes(include=\"object\").columns)\nobj_cols","0b2663ec":"df[obj_cols] = df[obj_cols].apply(LabelEncoder().fit_transform)","967b6f1c":"df.describe_discrete_cols(thresold=10)","9b5f7ca0":"df.continuous_features_df(thresold=10).skew()","ffdea54f":"histplt(df[\"Oldpeak\"],y_size=5,x_size=20)\ndf[\"Oldpeak\"].skew()","a7d8ec10":"pt = PowerTransformer(standardize=False)\n\ndf[\"Oldpeak\"] = pt.fit_transform(df[[\"Oldpeak\"]])\n\nhistplt(df[\"Oldpeak\"],y_size=5,x_size=20)\ndf[\"Oldpeak\"].skew()","3a51ebce":"x = df.drop(\"HeartDisease\", axis=1)\ny = df[\"HeartDisease\"]\n\nsc = StandardScaler()\n# with standardscaler\nx_sc = sc.fit_transform(X=x)\n\nlr = LogisticRegression(max_iter=1000)\nsvc= SVC()\nknn = KNeighborsClassifier()\nridge = RidgeClassifierCV()\nrf = RandomForestClassifier()\n\nmodels = {\n    'lr':lr,\n    'svc':svc,\n    'knn':knn,\n    'rf':rf\n}\n","6ed014f9":"scores = {}\nfor name, model in zip(models, models.values()):\n    scores[name] = np.round(cross_val_score(model,X=x,y=y, scoring=\"recall\", cv = 10), 3)\n\nfor key in scores.keys():\n    print(f'{key : <5} {np.round(sum(scores[key])\/len(scores[key]) * 100, 2)} %', np.round(np.std(scores[key]) * 100, 2))\n","2a694814":"scores = {}\nfor name, model in zip(models, models.values()):\n    scores[name] = np.round(cross_val_score(model,X=x_sc,y=y, scoring=\"recall\", cv = 10), 3)\n\nfor key in scores.keys():\n    print(f'{key : <5} {np.round(sum(scores[key])\/len(scores[key]) * 100, 2)} %', np.round(np.std(scores[key]) * 100, 2))","18ec4245":"# Building models","fd59f56f":"# Importing data and initial impressions","a0839354":"**Chest pain type**\n[source](https:\/\/www.heart.org\/en\/health-topics\/heart-attack\/angina-chest-pain)\n\n`Angina` is chest pain or discomfort caused when your heart muscle doesn't get enough oxygen-rich blood.\nIt may feel like pressure or squeezing in your chest. The discomfort also can occur in your shoulders, arms, neck, jaw, upper abdomen or back. Angina pain may even feel like indigestion.\n\n[Angina and atypical Angina](https:\/\/www.harringtonhospital.org\/typical-and-atypical-angina-what-to-look-for\/)\n\n*\\\"Men commonly have the usual kind of angina...\"*\n\n*\\\"Women may have more of a subtle presentation called atypical angina...\"*\n\n[Asymptomatic](https:\/\/elitecarehouston.com\/silent-heart-attacks-what-do-asymptomatic-signs-of-a-heart-attack-mean\/)\n\n*\\\"Nearly half of all heart attacks have no symptoms at all \u2014 but that doesn\u2019t mean they\u2019re any less deadly than heart attacks with symptoms....\"*\n\n*\\\"A lot of studies say that silent heart attacks are more common in women than in men....\"*\n\n**Fasting Blood sugar**\n\n[source](https:\/\/www.medicalnewstoday.com\/articles\/317536#blood-sugar-charts)\n\n|                      | Target blood sugar levels for people without diabetes | Target blood sugar levels for people with diabetes |\n|----------------------|-------------------------------------------------------|----------------------------------------------------|\n| Before meals         | 72\u201399 mg\/dl                                           | 80\u2013130 mg\/dl                                       |\n| 2 hours after a meal | less than 140 mg\/dl                                   | less than 180 mg\/dl                                |\n\n\nfrom data description we know `[1: if FastingBS > 120 mg\/dl, 0: otherwise]`\n\n\n**Resting ECG levels**\n[source](https:\/\/elentra.healthsci.queensu.ca\/assets\/modules\/ECG\/normal_ecg.html)\n\n`[Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]`\n\n**ExerciseAngina**\n\nas explained earlier, it is Angina caused due to exercise `exercise-induced angina [Y: Yes, N: No]`","a957ffd5":"### Observations\n**HD=Heart Disease**\n\n- ~75% and ~37% of women and men respectively don't have HD\n- ~50% of data comprises of men with HD \n\n**chest pain type**\n\n- if person has ASY, ~80% of times its HD\n- if person has ATA, ~83% of times its NOT HD\n\n**Fasting blood sugar**\n- if FastingBS = 1(> 120 mg\/dl),  ~80% of times its HD\n\n**RestingECG**\n- if ST =1, ~66% of times its HD\n\n**Exercise induced Angina**\n- if Y, ~85% of times its HD\n- if N, ~65% of times its NOT HD\n\n**ST_Slope**\n- if Down, ~78% of times its HD\n- if Flat, ~83% of times its HD\n- if Up, ~80% of times its NOT HD\n\n\n>*\\\"Men commonly have the usual kind of angina...\"*\n\n>*\\\"Women may have more of a subtle presentation called atypical angina...\"*\n\n>*\\\"A lot of studies say that silent heart attacks are more common in women than in men....\"(Asymptomatic)*\n\n**from the above aggregation, all the above quoted statement from the website does not agree with our data. The distribution between male and female is quite similar.**","4d3475dc":"**SVC turns out to be the best model with Average Recall value of 89% with 10 fold CV**","adcb67d5":"### from the above explanation lets try to use group by and plots with respect to HeartDisease","37343daa":"### Lets look at the distribution","67def246":"a feature is discrete if it has a relatively lower cardinality compared to size of data. It is irrespective of the datatype.\n\nAs seen below `Sex` is discrete because it has `[\"M\",\"F\"]` (dtype=object) and cardinality of 2, same applies to `HeartDisease` even if it has `[0,1]` (dtype = int)","4c58cb1b":"**lets remove outliers for `RestingBP` `Oldpeak`**","778fdbab":"# Custom methods for plotting","dd9a1501":"## Lets look at discrete data","17d43a93":"**clearly standard scaling helps in increasing accuracy**\n\n**svc and rf have the best accuracy**","c884ff12":"## all models with standard scaler","2b6d269a":"## This notebook contains End to End process for classification of HeartDisease\n### Please feel free to provide your suggestions. Upvote if you found it helpful\n\n## Describing Dataset\n1. Age: age of the patient [years]\n2. Sex: sex of the patient [M: Male, F: Female]\n3. ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n4. RestingBP: resting blood pressure [mm Hg]\n5. Cholesterol: serum cholesterol [mm\/dl]\n6. FastingBS: fasting blood sugar [1: if FastingBS > 120 mg\/dl, 0: otherwise]\n7. RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]\n8. MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]\n9. ExerciseAngina: exercise-induced angina [Y: Yes, N: No]\n10. Oldpeak: oldpeak = ST [Numeric value measured in depression]\n11. ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n12. HeartDisease: output class [1: heart disease, 0: Normal]\n","a9f2d157":"## Lets get a heads up with pandas profiling","4b22d825":"## all models without standard scaler","e641e987":"### Understanding what the data is about\n","a3c59b1d":"**There are 7 discrete features as seen above, with respective cardinality**\n\n**lets look at the distribution of each of those**","1bdbc2b2":"# Encoding features","68f67ec9":"### Handle outliers ","8352d720":"# Exploring data","93b01d3b":"# Imports","c3956fbf":"# Best model","f924c290":"# Introduction","c4516498":"# Custom methods for pandas","c30f1cdb":"## Lets look at continuous features","25f7e295":"# Handling Skew"}}