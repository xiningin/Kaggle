{"cell_type":{"3857487f":"code","e7d0fa78":"code","eb98116e":"code","b4640d8b":"code","8fa21739":"code","e068c102":"code","07ced59f":"code","f4e769da":"code","02eed893":"code","27f482fb":"code","61ae483d":"code","483e5679":"code","2ebd3886":"code","7ba75582":"code","55500de7":"code","9d121533":"code","c449d6b0":"code","288e8d4b":"code","330f7de3":"code","4f3cc128":"code","50301f70":"code","4fad3e86":"code","826924ac":"code","8b4d1bab":"code","06807ddd":"code","97203465":"code","3937511a":"code","f4c9c47a":"markdown","7b28b725":"markdown","75d76a2a":"markdown","3fdb93ef":"markdown","398aea47":"markdown","448dbb6c":"markdown","6c3cbf46":"markdown","8eff16e8":"markdown","4e1e4aae":"markdown","b87b985a":"markdown","35dc6156":"markdown","3c083af9":"markdown","d2d82e5b":"markdown","390ea31d":"markdown","071a6ba1":"markdown","4b6c87c5":"markdown","78f66fcc":"markdown","db0a3582":"markdown","b8162349":"markdown","6f46717c":"markdown","a60c4401":"markdown","3fe5d32c":"markdown","a4428870":"markdown","0e0c238f":"markdown"},"source":{"3857487f":"\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom datetime import timedelta\nplt.style.use(\"ggplot\")","e7d0fa78":"# archives\ncaract=pd.read_csv(\"..\/input\/caracteristics.csv\", encoding=\"latin1\")\nholiday=pd.read_csv(\"..\/input\/holidays.csv\", encoding=\"latin1\")\nplaces=pd.read_csv(\"..\/input\/places.csv\", encoding=\"latin1\")\nusers=pd.read_csv(\"..\/input\/users.csv\", encoding=\"latin1\")\nvehicles=pd.read_csv(\"..\/input\/vehicles.csv\", encoding=\"latin1\")\n","eb98116e":"# Date of the accidents\ndia=[]\nfor i in tqdm(range(0,len(caract))):\n    dia.append(pd.datetime((caract.iloc[i,1]+2000),caract.iloc[i,2],caract.iloc[i,3]))\ncaract[\"Data\"]=dia","b4640d8b":"# Period of the accident\ndef periodo(x):\n    if x< 600:\n        return \"Dawn\"\n    elif x<1600:\n        return \"Day Time\"\n    elif x<1900:\n        return \"Twilight\"\n    else:\n        return \"Night\"\ncaract[\"period\"]=caract[\"hrmn\"].apply(lambda x: periodo(x))","8fa21739":"# Selecting just a few columns\ncaract=caract.loc[:,[\"Num_Acc\", \"lum\",\"agg\", \"int\", \"atm\", \"col\", \"Data\", \"period\"]]","e068c102":"# Finding weekday\nweekend=[]\nfor i in tqdm(range(0,len(caract))):\n    dia=caract.iloc[i,6]\n    if int(dia.weekday()) in [5,6]:\n        weekend.append(\"weekend\")\n    else:\n        weekend.append(\"work day\")\ncaract[\"weekend\"]=weekend","07ced59f":"# Puting holidays proximity into the DF Characteristics\n# Here we want to identify accidents that happened at the limits of 1 day (after or before) a holiday\nholiday.ds=holiday.ds.apply(lambda x: pd.to_datetime(x))\nlistadias=[]\nfor i in tqdm(range(0, len(holiday))):\n    listadias.append(holiday.iloc[i,0]-timedelta(days=1))\n    listadias.append(holiday.iloc[i,0])\n    listadias.append(holiday.iloc[i,0]+timedelta(days=1))\n\ncaract[\"feriado\"]=caract[\"Data\"].apply(lambda x: \"holiday\" if x in listadias else \"non holiday\")\n    ","f4e769da":"# Places: choosing arbitrary some variables\nplaces=places.loc[:,[\"Num_Acc\",\"catr\", \"circ\", \"plan\", \"surf\"]]\n\n# Merging in \"caract DataFrame\"\ncaract=pd.merge(caract, places,on=\"Num_Acc\")","02eed893":"# Let\u00b4s identify accidents with severe victims\nusers=users[users[\"grav\"].isin([2,3])]\nacidentes_graves=users.Num_Acc.unique()\ncaract[\"grave\"]=caract.Num_Acc.apply(lambda x: \"Serious Victims\" if x in acidentes_graves else \"No Victims\")","27f482fb":"# Let\u00b4s put out the \"NaN\" rows\ncaract=caract.dropna()","61ae483d":"# Putting names in \"lum\"\nkey={1:\"Full day\", 2: \"Twilight or dawn\", 3:\"Night without public lighting\",\n        4:\"Night with public lighting\", 5:\"Night with public lighting on\"}\ncaract.lum=caract.lum.apply(lambda x: key[x])","483e5679":"# Putting names in \"agg\"\nkey={1:\"Out of agglomeration\",2:\"Building areas\"}\ncaract[\"agg\"]=caract[\"agg\"].apply(lambda x: key[x])","2ebd3886":"# Putting names in \"int\"\ncaract[\"int\"]=caract[\"int\"].apply(lambda x: 9 if x==0 else x)\nkey={9:'Other intersection', 8:'Level crossing', 7:'Place', 6:'Giratory', \n     5:'Intersection with more than 4 branches', 4:'Intersection in Y', \n     3:'Intersection in T', 2:'Intersection in X', 1:'Out of intersection'}\ncaract[\"int\"]=caract[\"int\"].apply(lambda x: key[x])","7ba75582":"# Putting names in \"atm\"\nkey={9:'Other', 8:'Cloudy weather', 7:'Dazzling weather', 6:'Strong wind - storm', \n     5:'Fog - smoke', 4:'Snow - hail', 3:'Heavy rain', \n     2:'Light rain', 1:'Normal'}\ncaract[\"atm\"]=caract[\"atm\"].apply(lambda x: key[x])","55500de7":"# Putting names in \"col\"\nkey={7:'Without collision', 6:'Other collision', 5:'Three or more vehicles - multiple collisions', \n     4:'Three vehicles and more - in chain', 3:'Two vehicles - by the side', \n     2:'Two vehicles - from the rear', 1:'Two vehicles - frontal'}\ncaract[\"col\"]=caract[\"col\"].apply(lambda x: key[x])","9d121533":"# Putting names in \"catr\"\nkey={9:'other', 6:'Parking lot open to public traffic', 5:'Off public network', \n     4:'Communal Way', 3:'Departmental Road', 2:'National Road', 1:'Highway'}\ncaract[\"catr\"]=caract[\"catr\"].apply(lambda x: key[x])","c449d6b0":"# Putting names in \"circ\"\nkey={4:'With variable assignment channels', 3:'Separated carriageways', 2:'Bidirectional', 1:'One way', 0:\"Other\"}\ncaract[\"circ\"]=caract[\"circ\"].apply(lambda x: key[x])","288e8d4b":"# Putting names in \"plan\"\nkey={4:'In \"S\"', 3:'Curved right', 2:'Curved on the left', 1:'Straight part', 0:\"ignored\"}\ncaract[\"plan\"]=caract[\"plan\"].apply(lambda x: key[x])","330f7de3":"# Putting names in \"surf\"\nkey={9:'other', 8:'fat - oil', 7:'icy', 6:'mud', 5:'snow', 4:'flooded', 3:'puddles', 2:'wet', 1:'normal', 0:\"Ignored\"}\ncaract[\"surf\"]=caract[\"surf\"].apply(lambda x: key[x])","4f3cc128":"# Let\u00b4s change columns names for more comprehensible ones\nnew_names={\"lum\":\"luminousity\", \"agg\":\"agglomeration\", \"int\":\"type Intersection\", \"atm\":\"atmosphere\",\n          \"feriado\":\"holiday\", \"catr\":\"type of road\", \"circ\":\"circulation\", \"plan\":\"shape\", \"surf\":\"surface\", \"grave\":\"severity\"}\ncaract=caract.rename(columns=new_names)","50301f70":"# We\u00b4ll use just a sample for clustering... For practical computational issues.\nsample=caract.sample(n=30000)\n\n# Let\u00b4s drop the columns \"Num_Acc\", \"Data\", \"severity\", calling the new DF by \"X\"\nX=sample.drop(columns=[\"Num_Acc\", \"Data\", \"severity\"])","4fad3e86":"# We\u00b4ll use the \"cost\" statistics to choose the best number of clusters\nfrom kmodes.kmodes import KModes\n\nclusters=[]\ncosts=[]\n\nfor i in tqdm(range(1,31)):\n    km=KModes(n_clusters=i)\n    km=km.fit(X)\n    \n    clusters.append(i)\n    costs.append(km.cost_)\n\n# Plotting graph\nplt.figure()\nplt.plot(clusters, costs)\nplt.title(\"Costs (Inertia) of Clustering\")\nplt.ylabel(\"Costs\")\nplt.xlabel(\"Number of Clusters\")\nplt.xticks(np.arange(1,30,2))\nplt.show()","826924ac":"# Modeling the clusters with the sample (n=30.000)\nkm=KModes(n_clusters=12)\nclusters=km.fit_predict(X)\nsample[\"Cluster\"]=clusters","8b4d1bab":"freq=sample.Cluster.value_counts(normalize=True, ascending=True)\nfreq.plot(kind=\"barh\", color=\"Blue\")\nplt.title(\"Relative Frequencies of the Clusters\")\nplt.xlabel(\"Relative Frequencies\")\nplt.ylabel(\"Cluster Label\")\nplt.show()","06807ddd":"# Selecting just the accidents with severe victims\nsevere_accidents=sample[sample[\"severity\"]==\"Serious Victims\"]\nfreq=severe_accidents.Cluster.value_counts(ascending=True)\nfreq.plot(kind=\"barh\", color=\"Red\")\nplt.title(\"Absolute Number of Accidents With Severe Victims\")\nplt.xlabel(\"Total Accidents\")\nplt.ylabel(\"Cluster Label\")\nplt.show()","97203465":"clusters=np.arange(0,12,1)\ntotal=[]\ntotal_injured=[]\nrisk=[]\n\n\nfor i in clusters:\n    parcial=sample[sample[\"Cluster\"]==i]\n    total.append(len(parcial))\n    total_injured.append(len(parcial[parcial[\"severity\"]==\"Serious Victims\"]))\n    risk.append(len(parcial[parcial[\"severity\"]==\"Serious Victims\"])\/len(parcial))\n\ndf_risk=pd.DataFrame({\"Cluster\":clusters, \"Total Accidents\":total, \"Total w\/ Serious Victims\":total_injured,\n                     \"Risk (%)\":risk})\ndf_risk=df_risk.set_index(\"Cluster\")\ndf_risk=df_risk.sort_values(\"Total w\/ Serious Victims\", ascending=False)\ndf_risk","3937511a":"# Selecting the variables of interest\ncluster_selected=2\ninterest=[\"luminousity\", \"agglomeration\",\"type Intersection\", \"atmosphere\", \"col\", \n          \"period\", \"weekend\", \"holiday\", \"type of road\", \"circulation\", \"shape\"]\n\n# Spliting two databases: cluster and non-cluster\ndb_cluster=sample[sample[\"Cluster\"]==cluster_selected]\ndb_noncluster=sample[sample[\"Cluster\"]!=cluster_selected]\n\n# Creating a DataFrame to compare cluster and non-cluster in each variable\nfor i in interest:\n    categories=sample[i].unique()\n    perc_cluster=[]\n    perc_noncluster=[]\n    \n    for x in categories:\n        perc_cluster.append(len(db_cluster[db_cluster[i]==x])\/len(db_cluster))\n        perc_noncluster.append(len(db_noncluster[db_noncluster[i]==x])\/len(db_noncluster))\n    \n    # Creating a DataFrame for chart ploting:\n    df_graphic=pd.DataFrame({\"Categories\":categories, \"Cluster {}\".format(cluster_selected):perc_cluster, \n                             \"Others\":perc_noncluster})\n    df_graphic=df_graphic.set_index(\"Categories\")\n    \n    #Chart\n    plt.figure()\n    df_graphic.plot(kind=\"barh\")\n    plt.title(\"Variable {}, in Cluster {}\".format(i,cluster_selected))\n    plt.xlabel(\"Relative Frequency\")\n    plt.show()    \n        ","f4c9c47a":"### In which clusters can we find accidents with severe victims?","7b28b725":"### Preparing data for clustering","75d76a2a":"### CLUSTER ANALYSIS \"MACHINE\"","3fdb93ef":"### Understanding the total Clusters that we must find","398aea47":"# Introduction","448dbb6c":"# Importing libraries and archives","6c3cbf46":"#### The next lines of code allows us to compare each cluster to all the others aggrouped.\n#### We are not going to print all the Clusters, but we\u00b4ll give a \"summary dataframe\" just after.\n#### If anyone is interested in seeing the respective graphs, one can just set the object \"cluster_selected\" to the selected cluster","8eff16e8":"# Treating Data","4e1e4aae":"In this section, we will compare the characteristics of each Cluster with the rest of the sample, aiming to discover the particular behavior and aggregation paterns associated with the Clusters","b87b985a":"### What are the probabilities of each Cluster of having severe injured users?","35dc6156":"![image.png](attachment:image.png)","3c083af9":"# A final short summary of all clusters","d2d82e5b":"### Frequency of Clusters","390ea31d":"# Finding the Clusters","071a6ba1":"Just to aid the comprehension of the analysis, let\u00b4s keep the original names (not the codes) of each variable\u00b4s categories.","4b6c87c5":"This dataset gives us a false impression of simplicity when we see it at a first glance. But we must take a lot of care with this impression.\nWhen we examine the variables of the 5 archives, we realize that any analysis of it faces a huge challenge of dealing with the multiple combinations of possibilities, and the impossibility to the human tought to intuitively achieve a meaninful \"enlightenment\".","78f66fcc":"### Understanding the characteristics of each Cluster","db0a3582":"### It\u00b4s very important to realize that Cluster\u00b4s numbers may not be the same each time you run K-Modes, because the \"K\" algorithms have a random start that may change the results.\nIn this exercise I did not use a \"random seed\", so the dataframe bellow has it\u00b4s validity restricted to the original notebook run outside Kaggle\u00b4s Python. But it will be probabilisticaly very simmilar, leading to the same conclusions.","b8162349":"For computational economy, we are going to use a sample of 30.000 accidents into the next steps. It\u00b4s, surely, a significative number to reach the insights we are pursuing.","6f46717c":"Based on the \"elbow curve\", we suggest 12 as the number of meaningful clusters to be analysed","a60c4401":"At least to me, it seems that this kind of Clustering can make analysis easier, with insights not immediately evidents at an initial sight.","3fe5d32c":"#### The KModes algorithm","a4428870":"One possible approach in these situations is to make a \"cluster analysis\", putting togheter similar cases and understanding the pattern achieved. But, altought the typical analysis of clustering uses the \"K-means\" algorithm, K-means is not a good choice when you have categorical data.\n\nEven if you switch your categorical data into dummies variables, the concept of \"distance\" used in K-Means is not acceptable to categorical variables. Is it acceptable to measure the distance of a \"male\"\/\"female\" individual into a 0\/1 basis? It does not have empirical validity to go on...\n\nZHEXUE HUANG (1998) proposed an extension of K-means algorithm to categorical variables (http:\/\/arbor.ee.ntu.edu.tw\/~chyun\/dmpaper\/huanet98.pdf). \nIn this analysis I used the version of \"nicodv\" available in github (https:\/\/github.com\/nicodv\/kmodes), friendly designed using a interface very known by users of scikit-learn. Thank\u00b4s @nicodv!","0e0c238f":"### We\u00b4ll choose 12 Clusters as the ideal number"}}