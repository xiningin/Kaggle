{"cell_type":{"57d68532":"code","ef6899cc":"code","b8d53504":"code","e9f7c998":"code","c8ac3c2d":"code","a4781fd7":"code","cd04ecd1":"code","f8da39a4":"code","9aee89b1":"code","16028b5b":"code","c16a3e1a":"code","e4face66":"code","81dae9a5":"code","c86dc2bd":"code","28196302":"code","c5a15bfc":"code","564ecdd0":"code","de524b1b":"markdown","29cf06d6":"markdown","86a1e8ab":"markdown","31e8771c":"markdown","4ed75858":"markdown","6cbd9f17":"markdown","e43e88a9":"markdown","c1e212e2":"markdown","a9965bb9":"markdown","85596735":"markdown","56ac9dd6":"markdown"},"source":{"57d68532":"# keras imports\nfrom keras.datasets import imdb\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM\nfrom keras.layers import Bidirectional\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.utils import np_utils\nfrom keras.layers.embeddings import Embedding\nfrom keras.optimizers import Adam, Adadelta\nfrom keras.models import load_model\nfrom keras.regularizers import l2\n\n# Generic imports\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np, string, pickle, warnings, random\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings(\"ignore\")","ef6899cc":"topWords = 50000\nMAX_LENGTH = 200\nnb_classes = 2\n\n# Downloading data\nimdbData = imdb.load_data(path='imdb.npz', num_words=topWords)\n\n(x_train, y_train), (x_test, y_test) = imdbData","b8d53504":"stopWords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \\\n             \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", \\\n             'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', \\\n             'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', \\\n             'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n             'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n             'at', 'by', 'for', 'with', 'about', 'between', 'into', 'through', 'during', 'before', 'after', \\\n             'above', 'below', 'to', 'from', 'off', 'over', 'then', 'here', 'there', 'when', 'where', 'why', \\\n             'how', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'own', 'same', 'so', \\\n             'than', 'too', 's', 't', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n             've', 'y', 'ma']\nword2Index = imdb.get_word_index()\nindex2Word = {v: k for k, v in word2Index.items()}\nindex2Word[0] = \"\"\nsentimentDict = {0: 'Negative', 1: 'Positive'}\n\ndef getWordsFromIndexList(indexList):\n    wordList = []\n    for index in indexList:\n      if index in index2Word:\n        wordList.append(index2Word[index])\n\n    return \" \".join(wordList)\n\ndef getSentiment(predictArray):\n    pred = int(predictArray[0])\n    return sentimentDict[pred]\n\ndef getIndexFromWordList(wordList):\n    indexList = []\n    for word in wordList:\n      if word in word2Index:\n        indexList.append(str(word2Index[word]))\n        \n    return indexList","e9f7c998":"print (len(word2Index))","c8ac3c2d":"print(getWordsFromIndexList(x_train[0]))","a4781fd7":"print(len(x_train[0]), x_train[0])","cd04ecd1":"stopIndexList = []\n\nfor stopWord in stopWords:\n    stopIndexList.append(word2Index[stopWord])\n\ntrainData = []\n\nfor indexList in x_train:\n    processedList = [index for index in indexList if index not in stopIndexList]\n    trainData.append(processedList)\n    \nx_train = trainData","f8da39a4":"'''\nPadding data to keep vectors of same size\nIf size < 200 then it will be padded, else it will be cropped\n'''\ntrainX = pad_sequences(x_train, maxlen = MAX_LENGTH, padding='post', value = 0.)\ntestX = pad_sequences(x_test, maxlen = MAX_LENGTH, padding='post', value = 0.)\n\n'''\nOne-hot encoding for the classes\n'''\ntrainY = np_utils.to_categorical(y_train, num_classes = nb_classes)\ntestY = np_utils.to_categorical(y_test, num_classes = nb_classes)","9aee89b1":"print(len(trainX[0]), trainX[0])","16028b5b":"sgdOptimizer = 'adam'\nlossFun='categorical_crossentropy'\nbatchSize=1024\nnumEpochs = 50\nnumHiddenNodes = 128\nEMBEDDING_SIZE = 300\ndenseLayer1Size = 256\ndenseLayer2Size = 128","c16a3e1a":"model = Sequential()\n\n# Train Embedding layer with Embedding Size = 300\nmodel.add(Embedding(topWords, EMBEDDING_SIZE, input_length=MAX_LENGTH, mask_zero=True, name='embedding_layer'))\n\n# Define Deep Learning layer\nmodel.add(Bidirectional(LSTM(numHiddenNodes), merge_mode='concat',name='bidi_lstm_layer'))\n\n# Define Dense layers\nmodel.add(Dense(denseLayer1Size, activation='relu', name='dense_1'))\nmodel.add(Dropout(0.25, name = 'dropout'))\nmodel.add(Dense(denseLayer2Size, activation='relu', name='dense_2'))\n\n# Define Output Layer\nmodel.add(Dense(nb_classes, activation='softmax', name='output'))\n\nmodel.compile(loss=lossFun, optimizer=sgdOptimizer, metrics=[\"accuracy\"])\nprint(model.summary())","e4face66":"model.fit(trainX, trainY, batch_size=batchSize, epochs=numEpochs, verbose=1, validation_data=(testX, testY))","81dae9a5":"score = model.evaluate(testX, testY, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))","c86dc2bd":"predY = model.predict_classes(testX)\nyPred = np_utils.to_categorical(predY, num_classes = nb_classes)\nprint(\"Classification Report:\\n\")\nprint(classification_report(testY, yPred))","28196302":"model.save('imdb_bi_lstm_tensorflow_model.hdf5')","c5a15bfc":"loaded_model = load_model('imdb_bi_lstm_tensorflow_model.hdf5')\nprint(loaded_model.summary())","564ecdd0":"num = 121\nnum_next = num + 1\nprint(\"Testing for test case...\" + str(num))\ngroundTruth = testY[num]\n\nsampleX = testX[num:num_next]\npredictionClass = loaded_model.predict_classes(sampleX, verbose=0)\nprediction = np_utils.to_categorical(predictionClass, num_classes = nb_classes)[0]\n\nprint(\"Text: \" + str(getWordsFromIndexList(x_test[num-1])))\nprint(\"\\nPrediction: \" + str(getSentiment(predictionClass)))\nif np.array_equal(groundTruth,prediction):\n    print(\"\\nPrediction is Correct\")\nelse:\n    print(\"\\nPrediction is Incorrect\")","de524b1b":"## Download data","29cf06d6":"## Load the Tensorflow Model","86a1e8ab":"# Model accuracy","31e8771c":"## Import libraries","4ed75858":"## Network Parameters","6cbd9f17":"## Network Architecture","e43e88a9":"## Save the Tensorflow Model","c1e212e2":"## Training the model","a9965bb9":"## Data Padding","85596735":"## Testing the model","56ac9dd6":"## Preprocess data"}}