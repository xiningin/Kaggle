{"cell_type":{"c6c7426c":"code","ad040518":"code","926d60f2":"code","79f87528":"code","64a98ba9":"code","1ff11b59":"code","35ff4563":"code","13a7727e":"code","119a1507":"code","8efa55f5":"code","6d94e252":"code","0dab9c6c":"code","d91cb7fb":"code","a93cae29":"code","76ddf3b9":"code","dda2fe89":"code","eeb7f86b":"code","2c13b233":"code","2bbc0306":"code","bc21460b":"code","3440e86d":"code","082535e2":"code","02df1b46":"code","e946f3c1":"code","4edf9dec":"code","4d6deb18":"code","34b33eca":"code","3d492318":"code","ea1814cd":"code","a677c3a9":"code","6ca41ebc":"code","67c08a1d":"code","b8d0a187":"code","c2b20965":"code","bb29a02c":"code","5f8ab9ed":"code","cd2616d9":"code","8a1dc60b":"code","7fdd2d75":"code","b4b3c90a":"code","fd3737a5":"code","caf28bf1":"code","60e22830":"code","f89320eb":"code","71e81834":"code","7834831a":"code","15fdcb43":"code","39179aed":"code","0edb850d":"code","5370adcd":"code","4474df96":"code","d4ee12af":"code","4c10134d":"code","63f78e4e":"code","c59de39f":"code","84d5b063":"code","8722ecf4":"markdown","6e774060":"markdown","45524087":"markdown","a71a068b":"markdown","e81ee115":"markdown","f81a9e14":"markdown","e92a4364":"markdown","8da82ef3":"markdown","2a0b4b6f":"markdown","a78455d6":"markdown","e8aa2b2e":"markdown","37e8694a":"markdown","1a7e8962":"markdown","3f39deff":"markdown","d144fc40":"markdown","75510f1c":"markdown","46b8cafd":"markdown","8308d7ac":"markdown","77482bf3":"markdown","e98af247":"markdown","cc241a89":"markdown","b5adcc6a":"markdown","063577e0":"markdown","f01ca0b0":"markdown","ba5ec753":"markdown","9f466090":"markdown","446ff82d":"markdown","86d99b80":"markdown","67e898b1":"markdown","cae96d44":"markdown","751a2ebe":"markdown","bccdff59":"markdown","a84c1590":"markdown"},"source":{"c6c7426c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad040518":"train=pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntrain.head()","926d60f2":"test=pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv')\ntest.head()","79f87528":"train.shape,test.shape","64a98ba9":"train.info()","1ff11b59":"test.info()","35ff4563":"train.describe()","13a7727e":"test.describe()","119a1507":"train.isnull().sum()","8efa55f5":"test.isnull().sum()","6d94e252":"px.pie(train,'Gender')","0dab9c6c":"px.pie(train,'Driving_License')","d91cb7fb":"px.pie(train,'Previously_Insured')","a93cae29":"#correcting vehicle_age values\ntrain['Vehicle_Age'].replace({'< 1 Year':'less_than_one_year','> 2 Years':'more_than_two_years'},inplace=True)\ntest['Vehicle_Age'].replace({'< 1 Year':'less_than_one_year','> 2 Years':'more_than_two_years'},inplace=True)","76ddf3b9":"px.pie(train,'Vehicle_Age')","dda2fe89":"px.pie(train,'Vehicle_Damage')","eeb7f86b":"px.pie(train,'Response')","2c13b233":"c_columns=['Gender','Vehicle_Age','Vehicle_Damage']\nfor i in c_columns:\n    train[i]=train[i].astype('category')\n    test[i]=test[i].astype('category')","2bbc0306":"train.info()","bc21460b":"test.info()","3440e86d":"plt.figure(figsize=(10,10))\nsns.distplot(train['Age'])\nplt.axvline(x=train['Age'].mean(),linestyle='--',c='r',label='Mean Age')\nplt.xticks(range(0,100,10))\nplt.legend()","082535e2":"sns.boxplot(train['Age'])","02df1b46":"sns.boxplot(train['Vintage'])","e946f3c1":"sns.boxplot(train['Policy_Sales_Channel'])","4edf9dec":"plt.figure(figsize=(10,10))\nsns.distplot(train['Annual_Premium'])\nplt.axvline(x=train['Annual_Premium'].mean(),linestyle='--',c='r',label='Avg annual premium')\nplt.xticks(range(0,600000,30000),rotation=90)\nplt.legend()","4d6deb18":"sns.boxplot(train['Region_Code'])","34b33eca":"plt.figure(figsize=(20,5))\nsns.boxplot(train['Annual_Premium'])","3d492318":"sns.stripplot(data=train,y='Gender',x='Age',jitter=True)","ea1814cd":"sns.countplot('Response',hue='Gender',data=train)","a677c3a9":"plt.figure(figsize=(10,5))\nsns.countplot('Driving_License',hue='Gender',data=train)","6ca41ebc":"sns.stripplot(data=train,x='Annual_Premium',y='Vehicle_Age',jitter=True)","67c08a1d":"sns.countplot('Vehicle_Age',hue='Vehicle_Damage',data=train)","b8d0a187":"sns.countplot('Vehicle_Age',hue='Previously_Insured',data=train)","c2b20965":"sns.countplot('Vehicle_Age',hue='Gender',data=train)","bb29a02c":"sns.lmplot(y='Vintage',x='Annual_Premium',col='Response',row='Gender',fit_reg=True,data=train)","5f8ab9ed":"from sklearn.preprocessing import OrdinalEncoder\no=OrdinalEncoder()\nfor i in c_columns:\n    train[i]=o.fit_transform(train[[i]])\n    test[i]=o.transform(test[[i]])","cd2616d9":"train.head()","8a1dc60b":"test.head()","7fdd2d75":"#printing correlation matrix\ncorr=train.iloc[:,:-1].corr()\ntop_features=corr.index\nplt.figure(figsize=(20,20))\nsns.heatmap(train[top_features].corr(),annot=True)","b4b3c90a":"# function to remove those independent features which are correlated\ndef correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr","fd3737a5":"correlation(train.iloc[:,:-1],0.5)","caf28bf1":"c=train.drop(columns={'id','Policy_Sales_Channel', 'Vehicle_Age','Vehicle_Damage'})\nc.head()","60e22830":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV,train_test_split","f89320eb":"X=c.drop(columns='Response',axis=1)\ny=c['Response']","71e81834":"#splitting the data\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.4,stratify=y,random_state=0)","7834831a":"#scaling the data\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.transform(x_test)","15fdcb43":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_auc_score","39179aed":"#function defined to fit the model\ndef model(model):\n    model.fit(x_train,y_train)\n    y_t=model.predict(x_train)\n    y_pred=model.predict(x_test)\n    tr=str('Training score:') + str(roc_auc_score(y_train,y_t))\n    te=str('Test score:') + str(roc_auc_score(y_test,y_pred))\n    return tr,te","0edb850d":"model(RandomForestClassifier(random_state=0))","5370adcd":"model(DecisionTreeClassifier(random_state=0))","4474df96":"model(XGBClassifier(random_state=0))","d4ee12af":"model(LGBMClassifier(random_state=0))","4c10134d":"model(KNeighborsClassifier())","63f78e4e":"r_params={\n    'n_neighbors': np.arange(1,15),\n    'leaf_size':np.arange(20,100,10)\n}","c59de39f":"from tpot import TPOTClassifier\n\n\ntpot_classifier = TPOTClassifier(generations= 3, population_size= 12, offspring_size= 6,\n                                 verbosity= 2, early_stop= 12,\n                                 config_dict={'sklearn.neighbors.KNeighborsClassifier': r_params}, \n                                 cv = 4, scoring = 'roc_auc')\ntpot_classifier.fit(x_train,y_train)","84d5b063":"roc_auc = tpot_classifier.score(x_test, y_test)\nprint(roc_auc)","8722ecf4":"## FEATURE SCALING AND SPLITTING","6e774060":"* No outliers in Region_Code features.\n* On an average,the customers come from the region_code around 30.","45524087":"Above figures show that when annual_premium is low then both gender's interest in buying the vehicle insurance will increase irrespective of the vintage.","a71a068b":"## FEATURE SELECTION","e81ee115":"Approx 50% of the customers  didn't have their vehicle damaged in the past.","f81a9e14":"Outliers are having premium\/year of more than 60000.","e92a4364":"## UNIVARIATE ANALYSIS","8da82ef3":"## HYPERPARAMETER TUNING","2a0b4b6f":"Vehicles aged less than one year are more previously insured than other categories.\n","a78455d6":"* Annual_Premium column has high number of outliers starting near 1,00,000.\n* It shows right skewed distribution.\n* Mean premium\/year is around 31000.","e8aa2b2e":"Both male and female have same age distributions.","37e8694a":"Males with DL are more in proportion than females in DL.","1a7e8962":"* Cars aged 1-2 Year has probably been more damaged and car aged less than one year is less damaged among the other categories.\n* Customers having cars aged more than two years are surely damaged.","3f39deff":"Most of the customers who whether want to take vehicle insurance or not are males.","d144fc40":"Customer using their cars for 1-2 years generally pay more premium for vehicle insurance per year.","75510f1c":"## MODEL FITTING","46b8cafd":"Let's examine the categorical features one by one in the training dataset.","8308d7ac":"* Female have more vehicles aged less than one year than males.\n* Males have more vehicles aged around 1-2 Year or more than two years than females.","77482bf3":"* Mean channel code is between around 130.\n* No outliers in the policy_sales_channel feature.","e98af247":"Around 87.7% of the customers having an health insurance aren't interested in buying vehicle insurance.","cc241a89":"The categorical features(**'Gender','Vehicle_Age','Vehicle_Damage'**) in both train and test sets should be converted from object type to categorical type.","b5adcc6a":" ## BIVARIATE\/MULTIVARIATE ANALYSIS","063577e0":"Approx 54% of the people who have claimed health insurance are males.","f01ca0b0":"* Most of the customers having health insurance are associated with the company on an average of 150 days.\n* No outliers in the vintage feature.","ba5ec753":"99.8 % of the people who have claimed health insurance have a driving license.","9f466090":"53% of the people have vehicles aged 1-2 years followed by 43% having vehicle age less than 1 year and the remaining people have vehcle age of more than 2 years.","446ff82d":"## VARIABLE ENCODING","86d99b80":"* No missing values in both train and test datasets.\n* Presence of outliers in id and Annual_Premium features due to large difference between 75% quartile and maximum value.","67e898b1":"We can see that previously test set ROC was 0.50 which was increased to 0.58 using effective hyperparameters.","cae96d44":"54.2 % of the people who already had health insurance doesn't have vehicle insurance.","751a2ebe":"No outliers in the age feature.","bccdff59":"* Most of the customers having health insurance are between 20 to 30 years of age.\n* The curve shows right skewed distribution.\n* Mean age is around 40.","a84c1590":"Random Forest and Decision Tree are overfitting the training set whereas XGB and LGBM have benchmark roc of around 0.5 respectively on the training set and 0.50 and 0.49 in the test set respectively.\n\nThe KNN Classifier has the best benchmark score of 0.56 in training set and 0.50 in the test set.\nWe will use KNN Classifier for model prediction and tune the model using tpot."}}