{"cell_type":{"4dc9caa4":"code","aca80393":"code","a804544a":"code","db7046db":"code","6a539680":"code","3c164914":"code","96ae0882":"code","c27a6aa4":"code","c3685205":"code","1de1a958":"code","29e71e3f":"code","cba0a19d":"code","e7809827":"code","73bca758":"code","20f3e2ac":"code","1be5f6dd":"code","72ad51ce":"markdown","97e516c0":"markdown","523d6861":"markdown","9be44635":"markdown","28b10e68":"markdown","7d2fab3f":"markdown","84371c8b":"markdown","7282dfc1":"markdown","35b9e334":"markdown","92d8ab8b":"markdown","09103a00":"markdown","66a99a52":"markdown","d0c4e440":"markdown"},"source":{"4dc9caa4":"import numpy as np\nimport os\nfrom tqdm import tqdm\nimport wave\nfrom scipy.io import wavfile\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","aca80393":"train = pd.read_csv(\"..\/input\/train_curated.csv\")\ntest = pd.read_csv(\"..\/input\/train_noisy.csv\")","a804544a":"plt.figure(figsize=(15,8))\naudio_type = train['labels'].value_counts().head(30)\nsns.barplot(audio_type.values, audio_type.index)\nfor i, v in enumerate(audio_type.values):\n    plt.text(0.8,i,v,color='k',fontsize=12)\nplt.xticks(rotation='vertical')\nplt.xlabel('Frequency')\nplt.ylabel('Label Name')\nplt.title(\"Top 30 labels with their frequencies in training data\")\nplt.show()","db7046db":"train_new = train.sort_values('labels').reset_index()\ntrain_new['nframes'] = train_new['fname'].apply(lambda f: wave.open('..\/input\/train_curated\/' + f).getnframes())\n\ntrain_fname = train_new.head(1000)","6a539680":"_, ax = plt.subplots(figsize=(16, 4))\nsns.violinplot(ax=ax, x=\"labels\", y=\"nframes\", data=train_fname)\nplt.xticks(rotation=90)\nplt.title('Distribution of audio frames, per label', fontsize=16)\nplt.show()","3c164914":"path = \"..\/input\/train_curated\/\"\nfig, axes = plt.subplots(figsize=(16,5))\ntrain_new.nframes.hist(bins=100)\nplt.suptitle('Frame Length Distribution in Train Curated', ha='center', fontsize='large');","96ae0882":"show_df = train.sort_values('labels')\nlabels = show_df['labels'].unique()\n\nfor label in labels[:5]:\n    \n    train_files_inds = show_df['labels'] == label\n\n    rand_inds = np.random.randint(0,show_df['fname'][train_files_inds].count(),5)\n    fnames = show_df['fname'].iloc[rand_inds]\n\n    _, axs = plt.subplots(figsize=(17,4),nrows=1,ncols=5)\n\n    for i,fname in enumerate(fnames):\n        rate, data = wavfile.read(path + fname)\n        axs[i].plot(data, '-', label=fname)\n        axs[i].legend()\n    plt.suptitle(label,x=0.04,y=0.5,horizontalalignment='center', fontsize=15)\n    del rate\n    del data\ndel axs","c27a6aa4":"from wordcloud import WordCloud\nwordcloud = WordCloud(max_font_size=50, width=600, height=300).generate(' '.join(train.labels))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud for Labels\", fontsize=35)\nplt.axis(\"off\")\nplt.show() ","c3685205":"##https:\/\/www.kaggle.com\/ilyamich\/remove-uninformative-parts-from-the-audio-files\nimport os\n\nTRAIN_PATH = '..\/input\/train_curated\/'\ntrain_ids = next(os.walk(TRAIN_PATH))[2]\ntrain_ids[0]","1de1a958":"import IPython.display as ipd\nipd.Audio(TRAIN_PATH + \"8a8110c2.wav\")","29e71e3f":"sample_rate, audio = wavfile.read(TRAIN_PATH + \"8a8110c2.wav\")\nplt.plot(audio);","cba0a19d":"def normalize_audio(audio):\n    audio = audio \/ max(np.abs(audio))\n    return audio","e7809827":"def divide_audio(audio, resolution=100, window_duration=0.1, minimum_power=0.001, sample_rate=44100):    \n    duration = len(audio) \/ sample_rate #in seconds\n    itterations = int(duration * resolution)\n    step = int(sample_rate \/ resolution)\n    window_length = np.floor(sample_rate*window_duration)\n    audio_power = np.square(normalize_audio(audio)) \/ window_length #Normalized power to window duration\n    \n    start = np.array([])\n    stop = np.array([])\n    is_started = False\n    \n    for n in range(itterations):\n        power = np.sum(audio_power[n*step : int(n*step+window_length)])\n        if not is_started and power > minimum_power:\n            start = np.append(start, n*step+window_length\/2)\n            is_started = True\n        elif is_started and (power <= minimum_power or n == itterations-1):\n            stop = np.append(stop, n*step+window_length\/2)\n            is_started = False\n    \n    if start.size == 0:\n        start = np.append(start, 0)\n        stop = np.append(stop, len(audio))\n        \n    start = start.astype(int)\n    stop = stop.astype(int)\n    return start, stop","73bca758":"start, stop =  divide_audio(audio)\nprint(start)\nprint(stop)\nplt.plot(audio[start[0]:stop[0]]);","20f3e2ac":"columns = ['File Name', 'Audio Duration', 'Segment Number']\naudio_segments = pd.DataFrame(columns=columns)\n\nfig, ax = plt.subplots(10, 4, figsize = (12, 16))\nfor i in tqdm(range(40), total=40):\n    random_audio_idxs = np.random.randint(len(train_ids)+1, size=1)[0]\n    _, tmp = wavfile.read(TRAIN_PATH + train_ids[random_audio_idxs])\n    start, stop = divide_audio(tmp)\n    \n    audio_segments = audio_segments.append({'File Name': train_ids[random_audio_idxs],\n                                            'Audio Duration': len(tmp)\/sample_rate,\n                                            'Segment Number': len(start)}, ignore_index=True)\n    \n    ax[i\/\/4, i%4].plot(tmp)\n    ax[i\/\/4, i%4].set_title(train_ids[random_audio_idxs])\n    ax[i\/\/4, i%4].get_xaxis().set_ticks([])","1be5f6dd":"audio_segments.sample(5)","72ad51ce":"## Exploratory Data Analysis","97e516c0":"### Now look at some labels waveform ","523d6861":"After some manual tunning it seems that the it works<br>\nNow lets briefly look on more examples:","9be44635":"We will look on one example","28b10e68":"## Remove uninformative Part","7d2fab3f":"### Audio Length\nWe shall now analyze the lengths of the audio files in our dataset of some categories","84371c8b":"# More To Come. Stayed Tuned !!","7282dfc1":"### Frame lenght distribution","35b9e334":"**If there are any suggestions\/changes you would like to see in the Kernel please let me know :). Appreciate every ounce of help!**<br>\n\n<p>Please leave any comments about further improvements to the notebook! Any feedback or constructive criticism is greatly appreciated!. If you like it or it helps you , you can upvote and\/or leave a comment :).|","92d8ab8b":"### Distribution of Categories","09103a00":"It measures the power in each segment and based on that decides if this part is a noise.<br>\nAnd returns the start and stop of each segment in the audio","66a99a52":"### Wordcloud for Labels","d0c4e440":"So the idea is to crop and segment the audio files and leave only the part that contain information.<br>\nFirst wi will normalize the data to be between -1 and 1:"}}