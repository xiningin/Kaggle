{"cell_type":{"88b52446":"code","fb02a4d6":"code","438b2a5c":"code","14643170":"code","3629b9ee":"code","a656cefb":"code","0cee70af":"code","35875da8":"code","ed6c6f00":"code","8c812dd9":"code","8a71c466":"code","d3697039":"code","6aeb9952":"code","32be5510":"code","96aa7d20":"code","d1b85ef5":"code","9cd42083":"code","1b49f86f":"code","90f37ad3":"markdown","aedc211b":"markdown","b538b13f":"markdown","00f817f1":"markdown","ced56d95":"markdown"},"source":{"88b52446":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fb02a4d6":"data_train = pd.read_csv(\"..\/input\/google-stock-price\/Google_Stock_Price_Train.csv\")\ndata_train.head()","438b2a5c":"train= data_train.loc[:,[\"Open\"]].values\ntrain","14643170":"# Scale\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0,1))\ntrain_scaled = scaler.fit_transform(train)\ntrain_scaled","3629b9ee":"plt.plot(train_scaled)\nplt.show","a656cefb":"# Creating a data structure with 50 timesteps and 1 output\nX_train = []\ny_train = []\ntimesteps = 50\nfor i in range(timesteps,1258):\n    X_train.append(train_scaled[i-timesteps:i,0])\n    y_train.append(train_scaled[i,0])\nX_train ,y_train = np.array(X_train), np.array(y_train)","0cee70af":"#reshaping\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_train","35875da8":"y_train","ed6c6f00":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import SimpleRNN\n\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first layer and some dropout regularisation\n\nregressor.add(SimpleRNN(units = 50 ,activation=\"tanh\",return_sequences=True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second layer and some dropout regularisation\n\nregressor.add(SimpleRNN(units = 50 ,activation=\"tanh\",return_sequences=True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1)) \n\n# Compiling the RNN\nregressor.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 100, batch_size = 32)","8c812dd9":"input_shape = (X_train.shape[1], 1)\ninput_shape","8a71c466":"data_test = pd.read_csv(\"..\/input\/google-stock-price\/Google_Stock_Price_Test.csv\")\ndata_test.head() ","d3697039":"real_stock_price = data_test.loc[:,[\"Open\"]].values\nreal_stock_price","6aeb9952":"# Getting the predicted stock price of 2017\ndataset_total = pd.concat((data_train[\"Open\"],data_test[\"Open\"]), axis=0)\ninputs = dataset_total[len(dataset_total) - len(data_test) - timesteps:].values.reshape(-1,1)\ninputs = scaler.transform(inputs)  # min max scaler\ninputs","32be5510":"X_test = []\nfor i in range(timesteps, 70):\n    X_test.append(inputs[i-timesteps:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n\n# Visualising the results\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()\n# epoch = 250 daha g\u00fczel sonu\u00e7 veriyor.","96aa7d20":"import math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n","d1b85ef5":"model = Sequential()\nmodel.add(LSTM(60, input_shape = (X_train.shape[1], 1)))# 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\nmodel.fit(X_train, y_train, epochs=15, batch_size=1)","9cd42083":"trainPredict = model.predict(X_train)\ntestPredict = model.predict(X_test)\n# invert predictions\ntrainPredict= scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([y_train])\ntestPredict = scaler.inverse_transform(testPredict)\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\n","1b49f86f":"# Visualising the results\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(testPredict, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","90f37ad3":"<a id=\"2\"><\/a>\n## Creating RNN Model[](http:\/\/)","aedc211b":"<a id=\"1\"><\/a>\n## Loading and Preprocessing Data","b538b13f":"# Recurrent Neural Network (RNN) \n\ncontent\n* [Loading and Preprocessing Data](#1)\n* [Creating RNN Model](#2)\n* [Predictions and Visualising RNN Model](#3)\n* [Creating LSTM Model](#4)","00f817f1":"<a id=\"4\"><\/a>\n## Creating LSTM Model","ced56d95":"<a id=\"3\"><\/a>\n## Predictions and Visualising RNN Model"}}