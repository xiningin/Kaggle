{"cell_type":{"66081c57":"code","e9c51e74":"code","9e5cf011":"code","54989248":"code","bab0a6d1":"code","233d288e":"code","afa50dae":"code","86c8ccb5":"code","be44eb06":"code","c1525a1e":"code","89e59aba":"code","6def0d1d":"code","980274f0":"code","d7cfa369":"code","96653892":"code","5bd96dca":"code","aea7317e":"code","68526b83":"code","fd90c4d9":"code","5a18249c":"code","c6f04e26":"code","14af04e3":"markdown","d7da80ae":"markdown","94741e5d":"markdown","73c5b73b":"markdown"},"source":{"66081c57":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport keras\nimport tensorflow as tf\nfrom keras import layers\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nimport matplotlib.gridspec as gridspec\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns\n\nimport glob\nimport os\nimport random\nimport cv2","e9c51e74":"## Declare Directory\ntrain_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\"\nval_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\"\ntest_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\"\n\nclasses = [\"With Mask\", \"Without Mask\"]","9e5cf011":"n = 5\n## Check Image\nplt.figure(figsize=(15, n))\nfor i in range(n):\n    # read image\n    sample = random.choice(os.listdir(train_dir + \"\/WithMask\"))\n    # print(\"filename:\", sample)\n    img_dir = train_dir + \"\/WithMask\/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # plot image\n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"With Mask\")\nplt.show()   \n\nplt.figure(figsize=(15, n))\nfor i in range(n):\n    # read image\n    sample = random.choice(os.listdir(train_dir + \"\/WithoutMask\"))\n    # print(\"filename:\", sample)\n    img_dir = train_dir + \"\/WithoutMask\/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # plot image\n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"Without Mask\")\nplt.show()   ","54989248":"# Dataset loader\ntrain_datagen = ImageDataGenerator(\n                                rescale=1.\/255,\n                                rotation_range=0.2,\n                                #width_shift_range=0.1,\n                                #height_shift_range=0.1,\n                                shear_range=0.2,\n                                #zoom_range=0.09,\n                                horizontal_flip=True,\n                                vertical_flip=False,\n                                #validation_split=0.1\n                                )\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)","bab0a6d1":"# Image Generator Config\ntarget_size = (150, 150)\nbatch_size = 16\n\n# Load Dataset\ntrain_dataset = train_datagen.flow_from_directory(train_dir,\n                                                  target_size=target_size,\n                                                  batch_size=batch_size,\n                                                  class_mode=\"categorical\",\n                                                  shuffle=True)\n\nval_dataset = val_datagen.flow_from_directory(val_dir,\n                                              target_size=target_size,\n                                              batch_size=batch_size,\n                                              class_mode=\"categorical\",\n                                              shuffle=False)","233d288e":"base_model = tf.keras.applications.MobileNet(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))","afa50dae":"# Freezing Layer\nfor layer in base_model.layers:\n    layer.trainable = False","86c8ccb5":"model = keras.Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2, activation=\"softmax\"))","be44eb06":"model.summary()","c1525a1e":"## Setting backprop of model (how this model learning)\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics =\"accuracy\")","89e59aba":"# Training\nEPOCHS = 10\nhistory = model.fit_generator(train_dataset,\n                               steps_per_epoch=len(train_dataset)\/\/train_dataset.batch_size,\n                               validation_data=val_dataset, \n                               validation_steps=len(val_dataset)\/\/val_dataset.batch_size,\n                               epochs=EPOCHS)","6def0d1d":"## Review Our Model\nimport matplotlib.gridspec as gridspec\n\nfig = plt.figure(figsize=(14,5))\ngrid = gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\nfig.add_subplot(grid[0])\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nfig.add_subplot(grid[1])\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()","980274f0":"# Load Test Dataset\ntest_dataset = val_datagen.flow_from_directory(test_dir,\n                                            target_size=target_size,\n                                            batch_size=1,\n                                            class_mode=None,\n                                            shuffle=False)","d7cfa369":"probabilities = model.predict_generator(test_dataset)","96653892":"y_pred = probabilities.argmax(axis=-1)\ny_test = test_dataset.classes","5bd96dca":"print(\"Accuracy Score of Model:\", accuracy_score(y_pred,y_test))","aea7317e":"print(classification_report(y_test, y_pred, target_names=classes))","68526b83":"def preprocessing_img(img):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (150, 150))\n    img = np.array(img)\n    img = np.expand_dims(img, axis=0)\n    img = img\/255\n    return img","fd90c4d9":"random_test_img = random.choice(glob.glob(test_dir+\"\/*\/*\"))\nprint(random_test_img)\nimg_test = cv2.imread(random_test_img)\nimg_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\nplt.imshow(img_test)\nplt.show()","5a18249c":"img_test = preprocessing_img(img_test)\nresult = model.predict(img_test)\nscore = np.max(result)\npredicted_class = classes[np.argmax(result)]\nprint(predicted_class)\nprint(\"Confident: \", score)","c6f04e26":"model.save(\"face-masked-detection.h5\")","14af04e3":"# Review Model","d7da80ae":"# Testing model","94741e5d":"# Preparation","73c5b73b":"# Modelling "}}