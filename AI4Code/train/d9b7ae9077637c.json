{"cell_type":{"67626b94":"code","df41db34":"code","b249ad34":"code","8ed1df65":"code","08236646":"code","450f80d3":"code","221516d5":"code","d6a74454":"code","a9b54821":"code","5b8ad3f4":"code","d84ed33f":"code","88ca13aa":"code","98b79c62":"code","ab6f933e":"code","c4e9542a":"code","74e2584f":"markdown","91a5316f":"markdown"},"source":{"67626b94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","df41db34":"df = pd.read_csv('\/kaggle\/input\/full_dataset.csv',sep=';')\ndf.head()","b249ad34":"df.info()","8ed1df65":"## importing everything that we're going to need!\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM, SimpleRNN\nfrom keras.layers.wrappers import Bidirectional\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\n\nfrom gensim import corpora\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport re","08236646":"def replace_tags(list_of_tokens: list) -> list:\n    \n    treated_tokens = []\n    for token in list_of_tokens:\n        if token == '?':\n            treated_tokens.append('<QST_MARK>')\n        elif token == '!':\n            treated_tokens.append('<EXC_MARK>')\n        else:\n            treated_tokens.append(token)\n            \n    return treated_tokens \n\ndef pad_sequence(list_of_treated_tokens: list, max_len: int) -> list:\n    \n    actual_len = len(list_of_treated_tokens)\n    if actual_len < max_len:\n        padded_list = ['<PAD>' for _ in range(max_len-actual_len)] + list_of_treated_tokens\n    elif actual_len > max_len:\n        padded_list = list_of_treated_tokens[:max_len]\n    else:\n        padded_list = list_of_treated_tokens\n        \n    return padded_list\n    \ndef pre_processing(text: str) -> str:\n    text = re.sub('([!?])',r' \\1 ',text)\n    text = text.lower().split()\n    \n    ## adding tokens\n    list_with_tokens = replace_tags(text)\n    \n    ## padding the sentence\n    padded_list = pad_sequence(list_with_tokens,max_len=30)\n       \n    return padded_list","450f80d3":"## applying pre_processing\n\ndf['text_tratado'] = df.title.apply(pre_processing)","221516d5":"## encoding using a simple bow model\n\nencoder = corpora.Dictionary(df.text_tratado)\n\nx = np.array([encoder.doc2idx(s) for s in df.text_tratado])","d6a74454":"## defining y\ny = df.label\ny_ann = to_categorical(y.map({'python':0,'java':1,'R':2,'javascript':3,'php':4}),5)","a9b54821":"## train test\n\nx_train,x_valid,y_train,y_valid = train_test_split(x,y_ann,test_size=0.2)","5b8ad3f4":"cross_val_score(SVC(),x,y,cv=10)","d84ed33f":"cross_val_score(RandomForestClassifier(500),x,y,cv=10)","88ca13aa":"## defining the model\n\nmodel = Sequential()\nmodel.add(Embedding(x.shape[1],64))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(Bidirectional(LSTM(256, dropout=0.2)))\nmodel.add(Dense(32,activation= 'relu'))\nmodel.add(Dense(16,activation= 'relu'))\nmodel.add(Dense(8,activation= 'relu'))\nmodel.add(Dense(5, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","98b79c62":"model.fit(x_train,y_train,batch_size = 32, epochs = 10, validation_data = (x_valid,y_valid))","ab6f933e":"model2 = Sequential()\nmodel2.add(Embedding(x.shape[1],64))\nmodel2.add(SpatialDropout1D(0.2))\nmodel2.add(SimpleRNN(256, dropout=0.2))\nmodel2.add(Dense(32,activation= 'relu'))\nmodel2.add(Dense(16,activation= 'relu'))\nmodel2.add(Dense(8,activation= 'relu'))\nmodel2.add(Dense(5, activation='softmax'))\n\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel2.summary()","c4e9542a":"model2.fit(x_train,y_train,batch_size = 32, epochs = 10, validation_data = (x_valid,y_valid))","74e2584f":"## Bidirectional LSTM and RNN","91a5316f":"## SVC and RandomForestClassifier"}}