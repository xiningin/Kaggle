{"cell_type":{"cc8bd1c2":"code","1f78e016":"code","8e35cd08":"code","a36856c2":"code","1f66fb94":"code","d6e6a271":"code","c150c6b8":"code","6253f62a":"code","a73ade68":"code","a9902357":"code","0a51d301":"code","9bb4a232":"code","d46ed856":"code","dd9a7975":"code","e237973e":"code","5eb0d50a":"code","f249b54f":"code","6cafae97":"code","a8b637c4":"code","19769d2b":"code","e0ec8b3a":"markdown","5061495b":"markdown","1ea592d4":"markdown","6fb6825d":"markdown","594cd8a8":"markdown","03997026":"markdown","e8eeaef4":"markdown","90a4a22c":"markdown","f36c65c9":"markdown","66a82b1c":"markdown","d6153042":"markdown","037c315b":"markdown","d68f1bae":"markdown","7a8160e7":"markdown","69a1557a":"markdown","ace70216":"markdown","3b0cd81a":"markdown","d1bf7c82":"markdown","dfb25cab":"markdown","9a2e119a":"markdown","a92c43f9":"markdown"},"source":{"cc8bd1c2":"import torch\nimport torchvision\nfrom torchvision import transforms, models\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets\nimport numpy as np\n\nimport os\nimport copy\nimport time\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\n\n\nimport matplotlib.pyplot as plt","1f78e016":"cache_dir = expanduser(join('~', '.torch'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","8e35cd08":"!cp ..\/input\/resnet34\/* ~\/.torch\/models\/","a36856c2":"!ls ~\/.torch\/models","1f66fb94":"data_transforms = {\n    'seg_train': transforms.Compose([\n         transforms.RandomResizedCrop(224),\n         transforms.RandomHorizontalFlip(),\n         transforms.ToTensor(),\n         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'seg_test': transforms.Compose([\n         transforms.Resize(256),\n         transforms.CenterCrop(224),\n         transforms.ToTensor(),\n         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}","d6e6a271":"image_train = {x: torchvision.datasets.ImageFolder('..\/input\/intel-image-classification\/seg_train\/seg_train', data_transforms[x]) for x in ['seg_train']}\ndata_train = {x: torch.utils.data.DataLoader(image_train[x], batch_size=16,\n                                              shuffle=True, num_workers=4) for x in ['seg_train']}\n\ndataset_train = {x: len(image_train[x]) for x in ['seg_train']}\nclass_names = image_train['seg_train'].classes\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","c150c6b8":"image_val = {x: torchvision.datasets.ImageFolder('..\/input\/intel-image-classification\/seg_test\/seg_test', data_transforms[x]) for x in ['seg_test']}\ndata_val = {x: torch.utils.data.DataLoader(image_val[x], batch_size=16,\n                                              shuffle=True, num_workers=4) for x in ['seg_test']}\n\ndataset_val = {x: len(image_val[x]) for x in ['seg_test']}","6253f62a":"class Img_clf(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 512, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(128*28*28, 64)\n        self.fc2 = nn.Linear(64, 6)\n        \n    def forward(self, x):\n        out = F.relu(F.max_pool2d(self.conv1(x),2))\n        out = F.relu(F.max_pool2d(self.conv2(out),2))\n        out = F.relu(F.max_pool2d(self.conv3(out),2))\n        out = out.view(-1, 128*28*28)\n        out = F.relu(self.fc1(out))\n        out = self.fc2(out)\n        \n        return out","a73ade68":"model = Img_clf()\nmodel.to(device) #Moving to Cuda if available","a9902357":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())","0a51d301":"def train_model(model, criterion, optimizer, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for data in [data_train, data_val]:\n            phase = list(data.keys())[0]\n            if phase == 'seg_train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in data[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'seg_train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'seg_train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            if phase == 'seg_train':\n                epoch_loss = running_loss \/ dataset_train[phase]\n                epoch_acc = running_corrects.double() \/ dataset_train[phase]\n            else:\n                epoch_loss = running_loss \/ dataset_val[phase]\n                epoch_acc = running_corrects.double() \/ dataset_val[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'seg_test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","9bb4a232":"trained_model = train_model(model, criterion, optimizer, num_epochs=5)","d46ed856":"transfer_model = models.resnet34(pretrained=True)\nfor name, param in transfer_model.named_parameters():\n    if ('bn' not in name):\n        param.requires_grad = False","dd9a7975":"transfer_model.fc = nn.Sequential(nn.Linear(transfer_model.fc.in_features, 500), nn.ReLU(), nn.Dropout(), nn.Linear(500, 6))","e237973e":"### Pretrained Model\noptimizer = torch.optim.Adam(transfer_model.parameters(), lr=0.01)\ntransfer_model.to(device)\ntrained_tl_model = train_model(transfer_model, criterion, optimizer,\n                       num_epochs=5)","5eb0d50a":"data_test_transform = {\n    'seg_pred': transforms.Compose([\n         transforms.Resize(256),\n         transforms.CenterCrop(224),\n         transforms.ToTensor(),\n         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}","f249b54f":"image_test = {x: torchvision.datasets.ImageFolder(\"..\/input\/intel-image-classification\/seg_pred\", data_test_transform[x]) for x in ['seg_pred']}\ndata_test = {x: torch.utils.data.DataLoader(image_test[x], batch_size=8,\n                                              shuffle=True, num_workers=4) for x in ['seg_pred']}\n\ndataset_sizes = {x: len(image_test[x]) for x in ['seg_pred']}","6cafae97":"model.eval()   # Set model to evaluate mode\nfor inputs, labels in data_test[\"seg_pred\"]:\n    inputs = inputs.to(device)\n    outputs = trained_tl_model(inputs)\n    _, preds = torch.max(outputs, 1)\n    print(preds)\n    break","a8b637c4":"trained_model.to('cpu')\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.detach().numpy()\n    inp = inp.transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(data_test['seg_pred']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n#inputs = inputs#.to(device)\noutputs = trained_model(inputs)\n_, preds = torch.max(outputs, 1)\n\nplt.figure(figsize=(16,16))\nimshow(out, title=[class_names[x] for x in preds])","19769d2b":"trained_tl_model.to('cpu')\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.detach().numpy()\n    inp = inp.transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(data_test['seg_pred']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n#inputs = inputs#.to(device)\noutputs = trained_tl_model(inputs)\n_, preds = torch.max(outputs, 1)\n\nplt.figure(figsize=(16,16))\nimshow(out, title=[class_names[x] for x in preds])","e0ec8b3a":"### **Things happening in Below cell**\n\n* **Creating Data Loaders for both seg_train and seg_test.**\n* **Applying Transforms while the dataloaders are created.**\n* **Using GPU if available.**\n* **Using Batch size of 16.**\n* **Shuffling the deck of samples to avoid having continous deck of same sample with same class.**","5061495b":"### **Adding FC layers to Resnet along with dropout**","1ea592d4":"**Importing Libraries**","6fb6825d":"### **Prediction Using Classifier Model**","594cd8a8":"**Note: Above Models are trained on 5 Epochs, hence the results are not great !**","03997026":"### **Prediction from Transfer Learning**","e8eeaef4":"* **Declaring the Loss Function**\n* **Declaring the optimizer and passing the model parameters on which the optimization or weight updates needs to happen.**","90a4a22c":"### **Results for 25 Epochs**\n\n### **Training complete in 63m 49s**\n\n### **Best val Acc: 0.854000**","f36c65c9":"* **Defining the Function train()**\n* **Iterating through the Epochs**\n* **Iterating through the Train and Validation Iterators.**\n* **During each iteration, a batch of 16 sample is taken from both train and validation iterator. And each sample is a tuple of image and label.**\n* **In *model.train()* phase, it enables the parameters to learn.**\n* **In *model.eval()* the parameters are disabled and the model is used only for making inferences.**\n* **We are retaining the parameters, where the loss is minimum and accuracy is maximum.**","66a82b1c":"**Few Simple Augmentations like Horizontal Flip, Cropping are composed in Transformation Module of Torchvision**","d6153042":"### **Updating BatchNorm layer of Resnet**\n### **Keeping requires_grad=False for all layers, except BatchNorm Layer.**","037c315b":"### **Building CNN**\n\n* **3 Conv Layers**\n* **4 Activation Unit - RELU**\n* **3 MaxPooling - Stride 2**\n* **2 FC Layers**","d68f1bae":"### **About Notebook**\n\n* **Building Image Classifier Model from scratch.**\n* **Verifying the Performance of the Model.**\n* **Building Image Classifier Model Using Resnet by Transfer Learning.**\n* **Tweak the Resnet by adding new layer and retrain only the BatchNorm layer of resnet**\n* **Check the performance parameters of resnet based model.**\n* **Compare the time taken by both the models.**","7a8160e7":"### Applying Transformation to pred images","69a1557a":"### **Creating DataLoader for Pred Images**","ace70216":"### **Pros and Cons of Building from Scratch**\n\n* **Building a Image Classifier without Transfer learning with Validation Accuracy of 85%, descent!.**\n* **Drawback is the time taken to train 25 epoch.**\n* **Transfer Learning is handy, reduced time for training from 63min to 20min.**\n* **Since Resnet is trained on ImageNet, the parameters learned earlier came handy.**\n* **Validation Accuracy of 91% compared to 85%, Much better!**","3b0cd81a":"### **Transfer Learning**\n\n* **Pretrained Model - Resnet34**\n* **Keeping all the trained parameters intact without retraining, keeping parameters = False except BatchNormalization's Parameters as True**\n* **Adding New Full connection Layer using nn.Sequential**\n* **Learning only the parameters of the new added FC layer**\n\n### **Why Transfer Learning**\n\n* **Less Computation**\n* **Trained Parameters**","d1bf7c82":"### **Keeping model in Eval phase, while predicting. Since parameters are not updated,while performing inferences.**","dfb25cab":"* **Initializing the model.**\n* **Moving to GPU if available.**","9a2e119a":"### **Training Model**","a92c43f9":"### **Result for Twenty Epoch**\n\n### **Training complete in 20m 17s**\n\n### **Best val Acc: 0.910000**\n\n"}}