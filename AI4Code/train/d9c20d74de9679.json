{"cell_type":{"6fce966f":"code","d2ca374a":"code","6f0bd568":"code","bb5393eb":"code","f580f2fe":"code","4d7ab3bc":"code","6883a122":"code","992fe0d4":"code","d5d96277":"code","7b8190b1":"code","05e67dd8":"code","87f09387":"code","c4319479":"code","f6ae8327":"code","0b4ae2ef":"code","ea6c65a3":"code","40cea773":"code","c2a9c0a6":"code","b81c2dec":"code","9f28b16e":"code","8a0de3bf":"code","1ba7e39d":"code","0883273a":"code","60b525d1":"code","47fc0559":"code","a78b0c99":"code","a6cd82c0":"code","afbc1114":"code","05fc3c90":"code","83900a0e":"code","50b66ac4":"code","91504ad7":"code","5c399e70":"code","40d0124f":"code","d20a6304":"code","23f010c0":"code","b28592ba":"code","4b6009df":"code","be2e0154":"code","5f33844c":"code","67ca48f8":"code","eec1e6db":"code","f750285a":"code","c4ab84ee":"code","bb2b7dea":"code","71068f8e":"code","1023d522":"code","e0980c4e":"code","a64e5e49":"code","40c54726":"code","7bd81d8d":"code","d5ecc94f":"code","e76fbe38":"code","8cb7285d":"code","f633c128":"code","61211668":"code","bfd98ae9":"code","1f0c12bf":"code","b600047e":"code","92d941b4":"code","017e7b45":"code","1d58c0e6":"code","a94e0c40":"code","1fa995a5":"code","e0f3c22e":"code","b2885163":"code","1104ae14":"code","04369450":"code","d0b0ad59":"code","51004554":"code","7589fa23":"code","d3c457ee":"code","336340b2":"code","d292e2f3":"code","31bda66e":"code","b40ab5dc":"code","86901e73":"code","de6fd1fd":"code","fbc6308a":"code","a065c9f5":"code","a9e61657":"code","0f20bf8e":"code","b648ec79":"code","ceac77d6":"code","a13c07c8":"code","66fd206d":"markdown","3594a270":"markdown","42facdff":"markdown","3256e1d0":"markdown","024d177f":"markdown","5d6aafc5":"markdown","078190ce":"markdown","155633a3":"markdown","45cdcddf":"markdown","5a710f04":"markdown","07bb6e5b":"markdown","f8bc0c7a":"markdown","4d8024c0":"markdown","0886377f":"markdown","599babf6":"markdown","6f60ced9":"markdown","488510e1":"markdown","c9e7390d":"markdown","deb691f5":"markdown","8c5c96da":"markdown","d67832fa":"markdown","a8863b55":"markdown","56a8da8e":"markdown","8d981f1c":"markdown","bf25f17b":"markdown","ec85943b":"markdown","03480106":"markdown","afc6bf7b":"markdown","4b004327":"markdown","de56e1db":"markdown","5568f93e":"markdown","8c245b82":"markdown","594a1e4b":"markdown","c4085c88":"markdown","17507d6a":"markdown","14db3e40":"markdown","f6ad82e8":"markdown","281f9d8a":"markdown","91d87cc7":"markdown","8bf2f3cf":"markdown","bacbc2c0":"markdown","00f6272e":"markdown","6ba01cba":"markdown","a8e7e3d4":"markdown","69c97a9f":"markdown","43f928c4":"markdown"},"source":{"6fce966f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings \n\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d2ca374a":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","6f0bd568":"train_df.columns","bb5393eb":"train_df.head()","f580f2fe":"train_df.describe()","4d7ab3bc":"train_df.info()","6883a122":"def bar_plot(variable):\n    \"\"\"\n    input variable ex: \"sex\"\n    output bar plot & value count\n    \n    \"\"\"\n    \n    # get feature\n    \n    var = train_df[variable]\n    \n    #count number of categorical variable\n    varValue= var.value_counts()\n    \n    #visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks (varValue.index, varValue.index.values)\n    plt.ylabel( \"Frequance\")\n    plt.title(variable)\n    plt.show()\n    print(\"{} : \\n{}\".format(variable,varValue))\n    ","992fe0d4":"category1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\",\"Parch\"]\n\nfor c in category1:\n bar_plot(c)","d5d96277":"category2 = [\"Cabin\", \"Name\", \"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","7b8190b1":"def plot_hist(variable):\n    plt.figure(figsize=(9,3))\n    plt.hist(train_df[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\" {}: discrubion with hist\".format(variable))\n    plt.show()","05e67dd8":"numericVar = [\"Fare\",\"Age\",\"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)\n    ","87f09387":"### Pclass vs Survived\n\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = True)","c4319479":"### Sex vs Survived\n\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = True)","f6ae8327":"### Sibling and Spouse vs Survived\n\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","0b4ae2ef":"### Parch vs Survived\n\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","ea6c65a3":"#1st Q \/ 3th Q = 2sd Q = median\n\n# IQR = Q3-Q1 \n\ndef detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","40cea773":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","c2a9c0a6":"\n# drop outliers\ntrain_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)","b81c2dec":"train_df_len= len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis=0).reset_index(drop = True)","9f28b16e":"train_df.head()","8a0de3bf":"train_df.columns[train_df.isnull().any()]","1ba7e39d":"train_df.isnull().sum()","0883273a":"\ntrain_df[train_df[\"Embarked\"].isnull()]","60b525d1":"train_df.boxplot(column=\"Fare\", by = \"Embarked\")\nplt.show()","47fc0559":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","a78b0c99":"train_df[train_df[\"Fare\"].isnull()]","a6cd82c0":"\ntrain_df[\"Fare\"]=train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"]==3][\"Fare\"]))","afbc1114":"train_df[train_df[\"Fare\"].isnull()]","05fc3c90":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\nplt.show()","83900a0e":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","50b66ac4":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", kind = \"bar\", data = train_df, size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","91504ad7":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","5c399e70":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 50)\nplt.show()","40d0124f":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 4)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","d20a6304":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 3)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","23f010c0":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","b28592ba":"train_df[train_df[\"Age\"].isnull()]","4b6009df":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","be2e0154":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\",data = train_df, kind = \"box\")\nplt.show()","5f33844c":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","67ca48f8":"#train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","eec1e6db":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","f750285a":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","c4ab84ee":"train_df[train_df[\"Age\"].isnull()]","bb2b7dea":"train_df[\"Name\"].head(10)","71068f8e":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","1023d522":"train_df[\"Title\"].head(10)","e0980c4e":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 40)\nplt.show()","a64e5e49":"# convert to categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)","40c54726":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","7bd81d8d":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","d5ecc94f":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","e76fbe38":"train_df.head()","8cb7285d":"train_df = pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","f633c128":"train_df.head(10)","61211668":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","bfd98ae9":"train_df.head()","1f0c12bf":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","b600047e":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","92d941b4":"train_df.head(10)","017e7b45":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","1d58c0e6":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","a94e0c40":"train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\ntrain_df.head()","1fa995a5":"train_df[\"Embarked\"].head()","e0f3c22e":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","b2885163":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","1104ae14":"train_df[\"Ticket\"].head(30)","04369450":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","d0b0ad59":"train_df[\"Ticket\"].head(20)","51004554":"train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\")\ntrain_df.head(10)","7589fa23":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","d3c457ee":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns= [\"Pclass\"])\ntrain_df.head()","336340b2":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns=[\"Sex\"])\ntrain_df.head()","d292e2f3":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)\ntrain_df.columns","31bda66e":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","b40ab5dc":"train_df_len","86901e73":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)","de6fd1fd":"test.head()","fbc6308a":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","a065c9f5":"logreg= LogisticRegression(solver='liblinear')\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2)\nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","a9e61657":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","0f20bf8e":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","b648ec79":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","ceac77d6":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","a13c07c8":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","66fd206d":"### Simple Logistic Regression","3594a270":"### Ensemble MOdelling","42facdff":"#### Embarked -- Sex -- Pclass -- Survived","3256e1d0":"* Female passengers have much better survival rate than males.\n* males have better survival rate in pclass 3 in C.\n* embarked and sex will be used in training","024d177f":"### Ticket","5d6aafc5":"#### Parch - Survived Analysis","078190ce":"* pclass is important feature for model training.","155633a3":"* Passsengers who pay higher fare have better survival. Fare can be used as categorical for training.","45cdcddf":"### Fill missing values\n\n- Embarked has 2\n- Fare has 1 missing value","5a710f04":"### Hyperparameter Tuning -- Grid Search -- Cross Validation","07bb6e5b":"<a id = \"1\"><\/a>\n## Load and Check the Data","f8bc0c7a":"### Prediction and Submission","4d8024c0":"### Feature Engineering","0886377f":"### Train - Test Split","599babf6":"\n#### Pclass -- Survived","6f60ced9":"* age <= 10 has a high survival rate,\n* oldest passengers (80) survived,\n* large number of 20 years old did not survive,\n* most passengers are in 15-35 age range,\n* use age feature in training\n* use age distribution for missing value of age","488510e1":"<a id = \"9\" > <\/a><br>\n## Visualization\n\n### Correalation","c9e7390d":"* Age is not correlated with sex but it is correlated with parch, sibsp and pclass.","deb691f5":"<a id = \"10\"><\/a>\n## Modelling","8c5c96da":"<a id = \"7\" > <\/a><br>\n## Outlier Detection","d67832fa":"#### Family Size","a8863b55":"<a id = \"8\" > <\/a><br>\n## Missing Value\n### Find Missing Value\n\n### Fill Missing Value\n\n","56a8da8e":"* Small familes have more chance to survive than large families.","8d981f1c":"* We will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n- Decision Tree\n- SVM\n- Random Forest\n- KNN\n- Logistic Regression","bf25f17b":"<a id = \"6\" > <\/a><br>\n\n## Basic Data Analysis\n\n* Pclass - Survived\n* Sex - Survived\n* SibSp Survived\n* Parch - Survived","ec85943b":"### Categorical Variable","03480106":"#### Pclass -- Survived -- Age","afc6bf7b":"Having a lot of SibSp have less chance to survive.\nif sibsp == 0 or 1 or 2, passenger has more chance to survive\nwe can consider a new feature describing these categories.","4b004327":"<a id = \"3\" > <\/a><br>\n## Univariate Variable Analysis\n\n        1. [Categorical Variable Analysis]\n        2. [Numerical Variable Analysis]","de56e1db":"### Embarked","5568f93e":"#### SibSp - Survived AnalysiSibSp - Survived Analysis","8c245b82":"Fare feature seems to have correlation with survived feature. ( 0.26)","594a1e4b":"#### Age -- Survived","c4085c88":"Name -- Title","17507d6a":"#### Fill Missing: Age Feature","14db3e40":"Sibsp and parch can be used for new feature extraction with th = 3\nsmall familes have more chance to survive.\nthere is a std in survival of passenger with parch = 3","f6ad82e8":"#### Embarked -- Sex -- Fare -- Survived","281f9d8a":"### Sex\n","91d87cc7":"<a id = \"2\" > <\/a><br>\n## Variable Description \n\n1.PassengerId: unique id number\n\n2.Survived: binary dead or alive\n\n3.Pclass: passenger class\n\n4.Name: name\n\n5.Sex: gender of passenger\n\n6.Age : age of passenger\n\n7.SibSp: number of sibling\/spouses\n\n8.Parch: number of parents\/children\n\n9.Ticket: ticret number\n\n10.Fare: amount of money spent on ticket\n\n11.Cabin: cabin catogory\n\n12.Embarked : port where passenger embarked","8bf2f3cf":"* 1st class passengers are older than 2nd, and 2nd is older than 3rd class.","bacbc2c0":"### Numerical Variable","00f6272e":"### Pclass","6ba01cba":"### Drop Passenger ID and Cabin","a8e7e3d4":"# Introduction\n\nThe sinking titanik is one of the notorious shipwreck in the history. She sang after hitting with an iceberg. \n\n<font color = 'blue' >\n\nContent:\n\n1.[Load and check the data](#1)\n    \n2.[Variable Description](#2)\n        \n3.[Univariate Variable Analysis](#3)\n    \n        1. [Categorical Variable Analysis](#4)\n    \n        2. [Numerical Variable Analysis] ,(#5)\n6.[Basic Data Analysis](#6)\n    \n7.[Outlier Detection](#7)\n\n8.[Missing Value](#8)\n    \n9.[Visualization](#9)\n\n10.[Modelling](#10)","69c97a9f":"*float64(2) : Fare and Age\n\n*int64(5) : Pclass, sibsp, parch, passengerId, Survived\n\n*object(5) : Name, sex, ticket,cabin, embarked","43f928c4":"* Sex is not informative for age prediction, age distribution seems to be same."}}