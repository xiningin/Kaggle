{"cell_type":{"2c4eb41f":"code","5851de19":"code","a79a0d06":"code","6f6f4f20":"code","8f255300":"code","560b4a44":"code","7ee5d3b8":"code","4b1af328":"code","eaff1d96":"code","66c7fbc8":"code","29d3da5e":"code","31ed11d5":"code","fc88b0f1":"code","7d9a1238":"code","e9047b60":"code","be8068f8":"code","23f447a0":"code","ee500a9d":"code","5855dd28":"code","2d1ae476":"code","00302eda":"code","122f73d9":"code","c04874b7":"code","97367c39":"code","b1090d9f":"code","e72133b5":"code","5c89de64":"code","6f76e16d":"code","954f37b1":"code","fd137ee0":"code","921b85e9":"code","08e33329":"code","5f35ac10":"code","0cc1540f":"code","d77f2fef":"code","23683d05":"code","5abc88e4":"code","b67a376c":"code","a1ac7d45":"code","d4fd5d53":"code","c940a737":"code","3977059c":"code","7f3e0d3d":"code","d7fefef5":"code","85b9b223":"code","e8a3ad33":"code","38d57898":"code","57b797ae":"code","0e4193fd":"code","800786d3":"code","408087a6":"code","ae873990":"code","bb8f148f":"code","2d2562aa":"code","88eb2976":"code","5b0d3a8b":"code","3ae3a41f":"code","2b48b53a":"code","8ec498f9":"code","59b18cac":"code","c1abeb06":"code","8d4ca9cc":"code","77ac7a09":"code","12083f0d":"code","c05bce4c":"code","1f6b00f0":"code","6d4780f7":"code","f329db1b":"code","900acd79":"code","53e3c87d":"code","c5abdff5":"code","b084d53e":"code","4b281ddc":"code","d8b8119e":"code","d500c987":"code","a6d97547":"code","0497418d":"code","c1ec9cdb":"code","fcef3c22":"code","d0c6f101":"code","c6d60432":"code","2e59b5aa":"code","3902cc07":"code","1fdc4776":"code","f8139c34":"code","201dd343":"code","edfffd78":"code","71af0e0c":"code","eed52515":"code","d53bb608":"code","90332f0b":"code","769c5e42":"code","047c837b":"code","3aad0242":"code","f90cbd8f":"code","5229bf8d":"code","97c7523e":"code","b3fd4fd9":"code","b306c058":"code","90a81327":"code","f4786359":"code","ccbc9c6a":"code","79d06951":"code","912d4a59":"code","3b62fd72":"code","78192703":"code","c832b060":"code","bca1bf31":"code","e2182f68":"code","0d660e59":"code","e6ba685c":"code","da7ef712":"code","cab0a5ac":"code","078895d7":"code","31dcaf1c":"code","31021fda":"code","91e176af":"code","eeac4428":"code","c13a28a8":"code","20c064da":"code","f8530cc6":"code","49b34e53":"code","b105fcca":"code","a5216e24":"code","69b2cb7e":"code","8eeac7b0":"code","cd17d818":"code","cc83f823":"code","fd6c2ac2":"code","a7f71016":"code","af567e19":"code","1a585665":"code","1feab3c2":"code","6d63f538":"code","2326a542":"code","1654b331":"code","de44e6e5":"code","f4e794d3":"code","4846a34b":"code","fdbedb6e":"code","3180ee7a":"code","b4a9dc61":"code","24c242c1":"code","3ce914b1":"code","1bac70c6":"code","a5fb4cde":"code","f82174df":"code","2a08ce63":"code","af05aabd":"code","e4350a5c":"code","efe8b6c3":"code","532c43e4":"code","e698dc5d":"code","e6d1c06a":"code","f9e82ba1":"code","c8cb5fbd":"code","fb3ac82f":"code","71c40604":"code","0ce354d9":"code","e5ae279e":"code","bd1e63c2":"code","428169fd":"code","0330069c":"code","7c736970":"code","126b3503":"code","1c4a88bb":"code","cd41cbe7":"code","3983d055":"code","118db891":"code","fa730e4f":"code","0ce145af":"code","bac262a4":"code","1ef7c020":"code","ddaf83c2":"code","1b7f7a81":"code","def1403f":"code","e41d9ecd":"code","1ef81217":"code","63db7484":"code","d771a343":"code","f06b7664":"code","9c2b9528":"code","b9f9235f":"code","cd3fe273":"code","860a9603":"code","339fe6f1":"code","1903a65a":"code","9ad884a0":"code","cfd7f63a":"code","a15c675a":"code","388c2c9e":"code","a7815582":"code","44322c0f":"code","a59509db":"code","c1ab1761":"code","b28c4f5b":"code","5400868a":"code","16ccea0e":"code","fa792097":"code","b5fa4145":"code","12314a84":"code","67ba8bb5":"code","71b13f73":"code","3a558079":"code","00e66d70":"code","5f8b780a":"code","d1c41bca":"code","b098b887":"code","08c7e4dc":"code","3d7d77c3":"code","34b0ff9f":"code","97de5445":"code","b40d7ef7":"code","d1383d35":"code","02abd4cc":"code","9d5a0203":"code","1051b058":"code","7645c5cd":"code","5089939b":"code","45f8720d":"code","36709eb3":"code","0fab18d5":"code","ad83f383":"code","11072ae8":"code","1240f0c3":"code","07d27e0d":"code","d082b2b9":"code","5b918a87":"code","100e2053":"code","28a71b13":"code","ff42d020":"code","55466474":"code","8bb83449":"code","bfe79117":"code","c1a0f61b":"code","95c9c2b0":"code","a627574b":"code","118008ce":"code","982c532f":"code","1b8b8e31":"code","36cb29a1":"code","9c709bbb":"code","c8fd3421":"code","54e4061f":"code","cae825e3":"code","8d8828d4":"code","ac56baf4":"code","823a5acb":"code","b6670243":"code","7e2ffd30":"code","cecce849":"code","ea2dfbe5":"code","cfe9107f":"code","9d0765c8":"code","853791a6":"code","21af5686":"code","d533874a":"code","66533a03":"code","3dc918e4":"code","4d2c339c":"code","0391b56a":"code","9fddeea6":"code","44c5e418":"code","803dc2ce":"code","02a0b018":"code","567d14a2":"code","8e740db9":"code","e9b4b2af":"code","849f54d0":"code","ead5c20b":"code","d4cd57cf":"code","6e8b702f":"code","d22d3971":"code","2e67a518":"code","78661109":"code","d41be6b5":"code","38852b8e":"code","90cf9eb8":"code","763c2dbe":"code","c5cd44db":"code","6ed26f2e":"code","6dd829a7":"code","12e77ad8":"code","76ebc660":"code","7977335e":"code","2d971054":"code","ddae9d33":"code","1920a789":"code","d0279c16":"code","e81a8860":"code","185a1fc8":"code","3040a5ab":"code","b37ee8fd":"code","1c25c0ac":"code","ffddecd3":"code","1bdbff17":"code","37e4f986":"code","85c6b6c8":"code","0d46c246":"code","4fc36572":"code","4713a4c7":"code","4f469f24":"code","a24f028e":"code","159fbb1b":"code","64b13a99":"code","08ae82ba":"code","3c7b72ce":"code","e14e61c0":"code","d3c21ba6":"code","4f23bc23":"code","79c8024e":"code","8eeb62bc":"code","fa6bcb13":"code","c51d300f":"code","28e9d2d3":"code","6ce0d57e":"code","0ac55bd7":"code","6915c77d":"code","6113e608":"code","db3755e0":"code","8a5a5a56":"code","a0c249a9":"code","f3307567":"code","fc681fa2":"code","27aba7f6":"code","b3eb0015":"code","a6b1ab24":"code","1524e467":"code","1a3f30f1":"code","c35aa84f":"code","50e4ca1b":"code","279e93ed":"code","b836873f":"code","e69c2e73":"code","9c96e5e0":"code","6508760e":"code","117e1c5d":"code","82e19f87":"code","2f3709d1":"code","dce066ce":"code","6c032b0e":"code","100650bb":"code","ee5df327":"code","ab9f8834":"code","01befa08":"code","2dead0e6":"code","cd4e04a8":"code","d183c4a8":"code","37b4088c":"code","eae5c075":"code","ad776805":"code","111d2af9":"code","4d5eb4e9":"code","8e8ce3a4":"code","920c27ee":"code","e56223e2":"code","85b6f882":"code","e8ce11fe":"code","e063ef94":"code","da149b75":"code","c9d210b1":"code","09aef9bc":"code","e3e42b86":"code","e8868bba":"code","9537c4a6":"code","68f87de1":"code","08bce374":"code","bcc7d074":"code","5c332f82":"code","3dbbc4dc":"code","27f6afc4":"code","2c20a0f5":"code","4f54b639":"code","be2e6297":"code","79fd466f":"code","68ae3d54":"code","b0eae472":"code","f06f1379":"code","8606cbf2":"code","2f692cb5":"code","955615b9":"code","4ba33a44":"code","3408f77f":"code","70cbf63e":"code","1ee6b4c4":"code","ce4d6478":"code","7d6e3a32":"code","ac870284":"code","b8432893":"code","4634eeac":"code","2907358d":"code","59c8fe64":"code","060a6c0b":"code","3e184bd6":"code","b2acfc56":"code","a1b3d477":"code","bc92acee":"code","604fb1db":"code","9b5fafe9":"code","c207fe93":"code","eb7e4349":"code","87c496ea":"code","29fc0a5c":"code","f32d8faa":"code","5803f657":"code","6349b177":"code","6b3047a2":"code","c9451c4c":"code","e85e81de":"code","9b03637b":"code","9d56d0d5":"code","c8452108":"code","b24944ab":"code","4cc106d3":"code","b0337cb3":"code","e5b2f283":"code","a156305d":"code","2a8194a1":"code","25e2128f":"code","3ae9f88b":"code","7af1a67d":"code","a00af005":"code","5514d7ad":"code","445b5d81":"code","b3f2f37b":"code","03cb06fa":"code","33b441ac":"code","54182443":"code","594a0b5e":"code","b20a2f11":"code","bb73a16c":"code","fa2ce960":"code","744b9ae5":"code","107497dd":"code","ba095265":"code","85e86fa9":"code","989aff77":"code","acb8eaf4":"code","b10d2350":"code","ea3d763e":"code","5668d72a":"code","ce8ef4fe":"code","e63ad13b":"code","12179801":"code","15fc52d3":"code","28a4b4a4":"code","981c0650":"code","b5a705b5":"code","8a0376ed":"code","93645b14":"code","2c56728c":"code","a6d837a8":"code","ad2ff296":"code","81110e5f":"code","9498d521":"code","a85980a4":"code","677768a7":"code","e049f6a7":"code","9861e3bb":"code","c04b5090":"code","afe68a6b":"code","a2f5df7e":"code","2287dc1f":"code","937f33f2":"code","82dec9bd":"code","a3ecf540":"code","060689ce":"code","f2059925":"code","01c7149a":"code","b36a321b":"code","2682faf5":"code","3460aeaf":"code","ba600ee1":"code","a5468917":"code","e7bf1aab":"code","aea111c5":"code","4faa299d":"code","592fc1f0":"code","484c6626":"code","b741b284":"code","950116d9":"code","cea3318b":"code","7de8383e":"code","defacd40":"code","a7f68dd9":"code","da231e87":"code","83ea9c77":"code","94b67f70":"code","5f34bf3b":"code","e7f681f9":"code","42768673":"code","33a667f0":"code","01bd1a3f":"code","2c871ea1":"code","33d90e4f":"code","53b74c9d":"code","f64d7359":"code","da85fba0":"code","dd3f71bc":"code","fc0fff60":"code","fe97a2e6":"code","94d80af4":"code","864b9b77":"code","6956226f":"code","89f420d9":"code","802e1468":"code","a8a18f20":"code","aca31888":"code","cea8c11d":"code","323f54c9":"code","81e44af3":"code","e99f6cd2":"code","9edb06b3":"code","d5d42818":"code","1bfda7d4":"code","8d87473b":"code","5d3106df":"code","ebd03db0":"code","b09727fe":"code","4112e483":"code","3bd4c57e":"code","fb494f3c":"code","d2e457b4":"code","563a06e4":"code","db27f775":"code","79ca755e":"code","5c2c475f":"code","48ccafeb":"code","1295ad7c":"code","639736de":"code","9fddcdbd":"code","8dcd754f":"code","8ec3f59a":"code","1a8ac8f6":"code","b92566d2":"code","438d782b":"code","43c69d6c":"code","6a5b7bb3":"code","cf919cdb":"code","8866eed8":"code","28bfd751":"code","d6aca414":"code","6732738e":"code","55f5dace":"code","93b54f4d":"code","35788461":"code","72357f79":"code","dc4390ea":"code","17eecbb5":"code","7144f5ad":"markdown","b8238846":"markdown","0461ab20":"markdown","9e41d4ed":"markdown","48947efa":"markdown","33d43997":"markdown","c3477cc3":"markdown","34b9d118":"markdown","3a94b33d":"markdown","74e7e27c":"markdown","3bc14913":"markdown","4ec9c6fd":"markdown","bfe657ab":"markdown","f9cd295a":"markdown","0f06d6ce":"markdown","1fcb6e8b":"markdown","c3453341":"markdown","3999f43f":"markdown","01cbe32c":"markdown","ac250ae1":"markdown","95c6ad27":"markdown","75db6044":"markdown","c37b6170":"markdown","e7b7057f":"markdown","de7973a1":"markdown","125f6889":"markdown","e52739e9":"markdown","8a952c61":"markdown","c33c8d97":"markdown","72479e23":"markdown","0d7dffd2":"markdown","755584b4":"markdown","778efefb":"markdown","f54f10c1":"markdown","b2f0a7d0":"markdown","2b7dfe29":"markdown","9ae6f71d":"markdown","0bd57b35":"markdown","6b2caf8d":"markdown","8c36b550":"markdown","f157c599":"markdown","dd7c3095":"markdown","0fc1e19d":"markdown","3038519a":"markdown","f3fcf3db":"markdown","4b34a55a":"markdown","17b1cf55":"markdown","5d0d56c1":"markdown","c8e22990":"markdown","9757b118":"markdown","2170d995":"markdown","e499c7b1":"markdown","57370264":"markdown","d38edeb1":"markdown","8c36f114":"markdown","2dd25d93":"markdown","f2acb618":"markdown","cfa3b6ff":"markdown","5f447141":"markdown","1e0d5524":"markdown","66eb5801":"markdown","19b19362":"markdown","64e677bd":"markdown","a9edb104":"markdown","83a02d2b":"markdown","2257bb99":"markdown","cc19ea64":"markdown","f4cab558":"markdown","d0be3852":"markdown","79c6f750":"markdown","cdbfd57e":"markdown","6d8b764b":"markdown","2e2d0044":"markdown","faa60a5d":"markdown","e0ea19e4":"markdown","5e71dccd":"markdown","9ffe23ab":"markdown","74492b5c":"markdown","7121f999":"markdown","07b2aa28":"markdown","4e6806f0":"markdown","4dfe4473":"markdown","c1703100":"markdown","ff562268":"markdown","4da0c01b":"markdown","85c9df1a":"markdown","847544d0":"markdown","ea414b40":"markdown","f63e450d":"markdown","393a8f30":"markdown","e4298921":"markdown","cf866065":"markdown","44ede233":"markdown","6f7d49c1":"markdown","9e0739de":"markdown","807e32de":"markdown","f6d799da":"markdown","8542c2b3":"markdown","f02c9267":"markdown","b7a1e8ae":"markdown","61d31cdd":"markdown","01a0a820":"markdown","9ec0ef8b":"markdown","82309fd3":"markdown","c50ab11f":"markdown","bd8463f8":"markdown","40c015f1":"markdown","7ad33434":"markdown","d081090c":"markdown","f661aa14":"markdown","8222ad47":"markdown","167eb85d":"markdown","2d701865":"markdown","539b0a20":"markdown","0d16c3a3":"markdown","5e7a1618":"markdown","32eadb96":"markdown","5e666483":"markdown","069703fa":"markdown","a0300736":"markdown","7f662c5a":"markdown","cecddefa":"markdown","b2c6b58c":"markdown","d7191022":"markdown","3778f887":"markdown","438d1d12":"markdown","e441b891":"markdown","dc4fe52b":"markdown","a27c4c8c":"markdown","a98b54d3":"markdown","1c386de7":"markdown","436822f5":"markdown","fc39062e":"markdown","6ed460e7":"markdown","b7e7e8de":"markdown","5bde2b83":"markdown","b3946573":"markdown","4e68f444":"markdown","fe8d5461":"markdown","7793a626":"markdown","4c6a42c2":"markdown","81356496":"markdown","9b67b914":"markdown","efec0950":"markdown","afb63bc5":"markdown","7ec16a00":"markdown","33badd0b":"markdown","49c6dfd6":"markdown","394b5d46":"markdown","925ca136":"markdown","3751ed8f":"markdown","6abb6614":"markdown","d75c56a3":"markdown","fd3828b2":"markdown","c64b5df5":"markdown","e1c2497d":"markdown","216092a1":"markdown","baf37450":"markdown","7ca12564":"markdown","e0f8ab0e":"markdown","0ab353a9":"markdown","00862e09":"markdown","5120b5bc":"markdown","ddeb9ccf":"markdown","4ad48ea0":"markdown","50cf6a54":"markdown","e49dc05b":"markdown","af69ca22":"markdown","124bfeb6":"markdown","cfe0de77":"markdown","b86bd563":"markdown","ad9a8352":"markdown","f784adce":"markdown","6ce4450f":"markdown","a07db895":"markdown","245761bb":"markdown","ba9d0bec":"markdown","50fd6f20":"markdown","abfa8fac":"markdown","4bfdefcf":"markdown","a56eb3dd":"markdown","e2f05747":"markdown","bd37ed17":"markdown","13cbc19e":"markdown","d521fdb0":"markdown","900cb81e":"markdown","9441b51e":"markdown","b9a21f12":"markdown","5498d641":"markdown","8e4ec805":"markdown","a1098673":"markdown","490e905b":"markdown","a4acad64":"markdown","3bd869c5":"markdown","a1443eb2":"markdown","b8242e97":"markdown","28f5f3b8":"markdown","11c730de":"markdown","a161bc2d":"markdown","198912b6":"markdown","f4aebb13":"markdown","efdc46a6":"markdown","90aa7b56":"markdown","cf265fcf":"markdown","7bbd5629":"markdown","135feebc":"markdown","824cbc37":"markdown","39d17bde":"markdown","72b89e1e":"markdown","2df60f2b":"markdown","c11c6b86":"markdown","c1d24d44":"markdown","8db220fd":"markdown","9c509c60":"markdown","e6a1b666":"markdown","2bfe1d7e":"markdown","ab3b0c46":"markdown","6970b771":"markdown","a0b41157":"markdown","629f4446":"markdown","2cec22db":"markdown","7cab79ae":"markdown"},"source":{"2c4eb41f":"%%html\n<!-- Style properties for markdown cells throughout the project -->\n\n<style>\n.text\n{    \n    font-family:Verdana;\n    font-size: 13px;\n}\n.text11\n{\n    font-family:Verdana;\n    font-size:11px;\n}\n.text12\n{    \n    font-family:Verdana;\n    font-size: 12px;\n}\n.text14\n{    \n    font-family:Verdana;\n    font-size: 14px;\n}\n.text16\n{\n    font-family:Verdana;\n    font-size: 16px;\n}\n.jump\n{\n    font-size: 12px;\n}\n.expand\n{\n    display:list-item\n}\n<\/style>","5851de19":"#30 August 2021 16:30 IST\n\nSTATIC = True","a79a0d06":"import datetime\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\nimport warnings\nfrom plotly.subplots import make_subplots\nfrom collections import Counter\nfrom geopy.geocoders import Nominatim\nfrom plotly.colors import n_colors\nfrom scipy.stats import chisquare\nfrom tabulate import tabulate\n\n# pio.renderers.default='notebook'\nwarnings.filterwarnings('ignore')\n\nmapbox_personal_token = 'pk.eyJ1IjoidnlhZHV2YW5zaGkiLCJhIjoiY2txYWxteGprMG52NDJvam8wcTZmYTc4cyJ9.cvg0lKU2zkXKCLq1mWjflg'","6f6f4f20":"#Reading the data\n\nif STATIC:\n    df = pd.read_csv('https:\/\/media.githubusercontent.com\/media\/vyaduvanshi\/ds-projects\/master\/\\\ncoronavirus-future-prediction\/static_raw_df.csv')\nelse:\n    df = pd.read_csv('https:\/\/raw.githubusercontent.com\/owid\/covid-19-data\/master\/public\/data\/owid-covid-data.csv')\n\ndf.head()","8f255300":"# #Saving to local\n\n# df.to_csv('static_raw_df.csv', index=False)\n\n# os.remove('static_raw_df.csv')","560b4a44":"df.info()","7ee5d3b8":"#Getting list of ISO codes which are unusual\n\nfor r in df.iso_code.unique():\n    if 'OWID' in r:\n        print(r)","4b1af328":"#Checking rows associated with the ISO code 'OWID_CYN'\n\ndf[df['iso_code'] == 'OWID_CYN']","eaff1d96":"#Dropping unrequired columns, changing format to datetime, renaming column, renaming ISO code for Kosovo, dropping\n#Northern Cyprus as it's all missing data (and not a recognized nation)\n\ncols_to_drop = [21,22,23,24,33]\ndf.drop(df.columns[cols_to_drop], inplace=True, axis=1)\ndf['date'] = pd.to_datetime(df['date'], format=('%Y-%m-%d'))\ndf.rename(columns = {'location':'country'},inplace=True)\ndf.replace('OWID_KOS','XKX', inplace=True)\ndf.drop(df[df['iso_code']=='OWID_CYN'].index, inplace=True)","66c7fbc8":"df.shape","29d3da5e":"#Importing the data with recovery stats\n\nif STATIC:\n    recovered_df = pd.read_csv('https:\/\/media.githubusercontent.com\/media\/vyaduvanshi\/ds-projects\/master\/\\\ncoronavirus-future-prediction\/static_raw_recovered_df.csv')\nelse:\n    recovered_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/\\\ncsse_covid_19_time_series\/time_series_covid19_recovered_global.csv')\n    \nrecovered_df.head()","31ed11d5":"# #Saving to local\n\n# recovered_df.to_csv('static_raw_recovered_df.csv', index=False)","fc88b0f1":"#Dropping all the columns from 5th August onwards\n\nrecovered_df = recovered_df.loc[:,:'8\/4\/21']","7d9a1238":"#Getting list of countries with multiple occurences (due to Province\/State) to add them up into a single row\n\nrecovered_countries =  list(recovered_df['Country\/Region'])\ncounter_a = Counter(recovered_countries)\n\ncountry_with_multiple_instances = []\n\nfor country_name in counter_a:\n    if counter_a[country_name] > 1:\n        print(country_name)\n        country_with_multiple_instances.append(country_name)","e9047b60":"#Appending country-wise dataframes to a list to concat into a single dataframe later\n\ndate_cols = recovered_df.columns[4:]\nfull_recovered_df = []\n\nfor country in set(recovered_countries):\n    rec_df = recovered_df[recovered_df['Country\/Region'] == country][date_cols].T\n    if country in country_with_multiple_instances:\n        rec_df['temp'] = rec_df.sum(axis=1)\n        rec_df.drop(rec_df.iloc[:,:-1], axis=1, inplace=True)\n    lat = recovered_df[recovered_df['Country\/Region'] == country]['Lat'].values[0]\n    long = recovered_df[recovered_df['Country\/Region'] == country]['Long'].values[0]\n    rec_df.columns = ['Recovered']\n    rec_df['Country'] = country\n    rec_df['Latitude'] = lat\n    rec_df['Longitude'] = long\n    full_recovered_df.append(rec_df)","be8068f8":"#Transforming list of dataframes into a single dataframe and cleaning it up\n\nrecovered_df = pd.concat(full_recovered_df)\nrecovered_df.reset_index(inplace=True)\nrecovered_df.rename(columns = {'index':'Date'},inplace=True)\nrecovered_df['Date'] = recovered_df['Date'].apply(lambda x:x[:-2] + '20' + x[-2:])\nrecovered_df['Date'] = pd.to_datetime(recovered_df['Date'],format=('%m\/%d\/%Y'))\nrecovered_df.sort_values(['Country','Date'],inplace=True)\nrecovered_df.head()","23f447a0":"#Setting coordinates for a few countries to np.nan due to multiple regions for them in dataframe\n\nfor country in country_with_multiple_instances:\n    recovered_df.loc[recovered_df['Country'] == country, 'Latitude'] = np.nan\n    recovered_df.loc[recovered_df['Country'] == country, 'Longitude'] = np.nan","ee500a9d":"#Getting list of countries exclusive to each dataframe by using XOR\n\nset(recovered_countries) ^ set(df['country'].unique())","5855dd28":"#Renaming country names to the same standard\n\nrecovered_df.replace({'Burma':'Myanmar', 'Cabo Verde':'Cape Verde', 'Congo (Brazzaville)':'Congo',\n                            'Congo (Kinshasa)':'Democratic Republic of Congo',\n                            'Korea, South':'South Korea', 'Taiwan*':'Taiwan',\n                            'Timor-Leste':'Timor', 'US':'United States'}, inplace=True)","2d1ae476":"#Renaming columns and setting indexes to prepare for merge\n\nrecovered_df.rename(columns={'Date':'date','Country':'country','Recovered':'total_recovered',\n                            'Latitude':'latitude', 'Longitude':'longitude'}, inplace=True)\nrecovered_df.set_index(['date','country'], inplace=True)\ndf.set_index(['date','country'], inplace=True)","00302eda":"#Merging (df) and (recovered_df)\n\ndf = df.join(recovered_df)","122f73d9":"df.shape","c04874b7":"#Importing government response data\n\nif STATIC:\n    df_gov = pd.read_csv('https:\/\/media.githubusercontent.com\/media\/vyaduvanshi\/ds-projects\/master\/\\\ncoronavirus-future-prediction\/static_raw_df_gov.csv')\nelse:\n    df_gov = pd.read_csv('https:\/\/raw.githubusercontent.com\/OxCGRT\/covid-policy-tracker\/master\/data\/OxCGRT_latest.csv')\n    \ndf_gov.head()","97367c39":"# #Saving to local\n\n# df_gov.to_csv('static_raw_df_gov.csv', index=False)","b1090d9f":"df_gov.info()","e72133b5":"#Dropping columns and rows not needed, renaming other columns, changing date format\n\ncols_to_drop2 = [0,2,3,4,7,9,11,13,15,17,19,22,27,33,35,37,38,39,40,41,42,43,44,46,48,50]\ndf_gov.drop(df_gov[df_gov['Jurisdiction'] == 'STATE_TOTAL'].index, inplace=True)\ndf_gov.drop(df_gov.columns[cols_to_drop2],inplace=True, axis=1)\nmodifying_col_names = df_gov.columns.str.split('_')\nnew_col_names = [col_name[0] if len(col_name) is 1 else col_name[1] for col_name in modifying_col_names]\ndf_gov.columns = new_col_names\ndf_gov['Date'] = pd.to_datetime(df_gov['Date'],format=('%Y%m%d'))","5c89de64":"df_gov.head()","6f76e16d":"#Renaming columns and setting index to prepare for merge\n\ndf_gov.rename(columns={'Date':'date','CountryCode':'iso_code'},inplace=True)\ndf_gov.set_index(['date','iso_code'],inplace=True)\ndf.reset_index(inplace=True)\ndf.set_index(['date','iso_code'],inplace=True)","954f37b1":"#Merging (df) and (df_gov)\n\ndf = df.join(df_gov)\ndf.reset_index(inplace=True)","fd137ee0":"df.shape","921b85e9":"#Importing google mobility trends data (700+ MB data)\n\nif STATIC:\n    google_df = pd.read_csv('https:\/\/media.githubusercontent.com\/media\/vyaduvanshi\/ds-projects\/master\/\\\ncoronavirus-future-prediction\/static_raw_google_df.csv')\nelse:\n    google_df = pd.read_csv('https:\/\/www.gstatic.com\/covid19\/mobility\/Global_Mobility_Report.csv')\n    \ngoogle_df.head()","08e33329":"# #Saving to local\n\n# google_df.to_csv('static_raw_google_df.csv', index=False)","5f35ac10":"#Dropping data for sub-regions inside the countries, keeping only the whole country data\n\ngoogle_df = google_df[pd.isnull(google_df['sub_region_1'])]\ngoogle_df = google_df[pd.isnull(google_df['metro_area'])]","0cc1540f":"google_df.info()","d77f2fef":"#Dropping columns not needed, renaming other columns\n\ncols_to_drop3 = [0,2,3,4,5,6,7]\ngoogle_df.drop(google_df.columns[cols_to_drop3], axis=1, inplace=True)\ngoogle_df.rename(columns = {'country_region':'country'})\ngoogle_df.columns = ['country','date'] + [(\"gm_\"+col_name[:-29]) for col_name in google_df.columns[2:]]","23683d05":"#Getting country names in google_df but not in original df\n\nfor country in google_df['country'].unique():\n    if country not in df['country'].unique():\n        print(country)","5abc88e4":"#Renaming some countries, dropping others (overseas regions) as they don't exist in the main dataframe\n\ngoogle_df.replace({'The Bahamas':'Bahamas', \"C\u00f4te d'Ivoire\":\"Cote d'Ivoire\",\n                  'Myanmar (Burma)':'Myanmar'},inplace=True)","b67a376c":"#Formatting google_df and merging it with original df\n\ngoogle_df['date'] = pd.to_datetime(google_df['date'], format=('%Y-%m-%d'))\ngoogle_df.set_index(['date','country'],inplace=True)\n\ndf.set_index(['date','country'], inplace=True)\ndf = df.join(google_df)\ndf.reset_index(inplace=True)","a1ac7d45":"df.shape","d4fd5d53":"#Dropping rows 'International', 'European Union' and 'Macao' (all NaN values) in countries. And renaming Micronesia\n#to proper name\n\ndf.drop(df[(df['iso_code'] == 'OWID_INT') | (df['iso_code'] == 'OWID_EUN')].index, inplace=True)\ndf.drop(df[df['country'] == 'Macao'].index, inplace=True)\ndf.replace({'Micronesia (country)':'Micronesia'}, inplace=True)","c940a737":"#Checking for missing coordinate values\n\ndf['latitude'].isna().value_counts()","3977059c":"#Adding all coordinates to dictionary, np.nan for missing coordinates\n\nlat_longs = {}\narbitrary_mid_date = '2020-05-01'\n\nfor country in df['country'].unique():\n    try:\n        lat = df[(df['country'] == country) & (df['date'] == arbitrary_mid_date)].latitude.values[0]\n        long = df[(df['country'] == country) & (df['date'] == arbitrary_mid_date)].longitude.values[0]\n    except IndexError:\n        lat_longs[country] = {'lat':np.nan, 'long':np.nan}\n        continue\n    lat_longs[country] = {'lat':lat, 'long':long}\n    \nfor i,j in lat_longs.items():\n    if np.isnan(j['lat']):\n        print(i,j)","7f3e0d3d":"#Getting coordinates for countries with np.nan values\n\ngeolocator = Nominatim(user_agent='abc')\nfor country,coords in lat_longs.items():\n    if not np.isnan(coords['lat']):\n        continue\n    try:\n        location = geolocator.geocode(country)\n        lat = location.latitude\n        long = location.longitude\n        lat_longs[country] = {'lat':lat, 'long':long}\n    except:\n        print(country)","d7fefef5":"#Deleting 'World' and continents from coordinate dict\n\nkeys_to_remove = ['World','Europe','North America','Asia','South America','Oceania','Africa']\n\nfor key in keys_to_remove:\n    lat_longs.pop(key)","85b9b223":"#Filling latitudes and longitudes for all the countries\n\nfor country in df['country'].unique():\n    if country in keys_to_remove:\n        continue\n    lat = lat_longs[country]['lat']\n    long = lat_longs[country]['long']\n    df.loc[df['country']==country, ['latitude','longitude']] = (lat, long)","e8a3ad33":"df.shape","38d57898":"#Importing a dataset which contains literacy rates for all countries\n\ndf_literacy = pd.read_csv('https:\/\/raw.githubusercontent.com\/vyaduvanshi\/helper-files\/master\/\\\nliteracy-rates-most-recent.csv')\n\ndf_literacy.head()","57b797ae":"#Changing ISO code of Kosovo to project norm, and dropping some unrequired rows\n\ndf_literacy.replace({'OWID_KOS':'XKX'}, inplace=True)\ndf_literacy.drop(df_literacy[df_literacy['Code']=='OWID_WRL'].index, inplace=True)\ndf_literacy.dropna(axis=0, subset=['Code'], inplace=True)","0e4193fd":"#Cleaning literacy_df and merging it to the main dataframe\n\ndf_literacy.rename(columns={'Code':'iso_code',\n                            'Literacy rates (World Bank, CIA World Factbook, and other sources)':'literacy_rate'},\n                   inplace=True)\ndf_literacy = pd.pivot_table(df_literacy, index='iso_code', aggfunc='last')\ndf_literacy.drop(['Entity','Year'], axis=1, inplace=True)\n\ndf.set_index('iso_code',inplace=True)\ndf = df.join(df_literacy)\ndf.reset_index(inplace=True)","800786d3":"df.shape","408087a6":"#Importing democracy index (di) country-wise\n\ndi_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/vyaduvanshi\/helper-files\/master\/democracy_index.csv')\ndi_df.head()","ae873990":"#Renaming, formatting and dropping a column from di_df\n\ndi_df.dropna(inplace=True)\ndi_df.rename(columns={'iso':'iso_code'}, inplace=True)\ndi_df.iso_code = di_df.iso_code.str.upper()\ndi_df.drop(['country'], axis=1, inplace=True)","bb8f148f":"#Dropping rows and columns not needed and merging di_df with main dataframe\n\n# di_df.drop(di_df[(di_df['iso_code']=='PRK') | (di_df['iso_code']=='TKM')].index, inplace=True)\ndi_df = di_df.pivot_table(di_df, index='iso_code', aggfunc='last')\ndel di_df['year']\n\ndf.set_index('iso_code', inplace=True)\ndf = df.join(di_df)\ndf.reset_index(inplace=True)","2d2562aa":"df.shape","88eb2976":"df.head()","5b0d3a8b":"#Setting recovered values for US to NaN because of null records after 13th Dec\n\nus_recovered_df = df[df['country'] == 'United States']\ndf.loc[us_recovered_df.index, 'total_recovered'] = np.nan","3ae3a41f":"#Creating two separate dataframes, one for continents and one for world\n\ncontinent_list = ['Africa','Asia','Europe','Oceania','North America','South America']\ncontinent_df = []\n\nfor continent in continent_list:\n    temp_df = df[df['country'] == continent]\n    continent_df.append(temp_df)\n\ncontinent_df = pd.concat(continent_df)\nworld_df = df[df['country'] == 'World']","2b48b53a":"#Dropping 'World' and continents in 'country' column as they are already separated into their own dataframes\n\nfor key in keys_to_remove:\n    df.drop(df[df['country'] == key].index, inplace=True)","8ec498f9":"#Setting the date values in `world_df` and `continent_df` same as main `df`\n\nworld_df = world_df.set_index('date').reindex(np.sort(df.date.unique())).reset_index()\ncontinent_df = continent_df.set_index('date').groupby('country').apply(lambda x: x.reindex(pd.date_range(min(df.date),\n                                                                                                         max(df.date),\n                                                                                                         freq = 'D')))\\\n.drop('country', axis=1).reset_index()\ncontinent_df.rename(columns = {continent_df.columns[1]:'date'}, inplace=True)","59b18cac":"#Function to calculate moving average for a grouped dataframe\ndef calc_MA_on_group(x):\n    fill_val = x.rolling(window=7).mean()\n    return pd.Series(fill_val, index=x.index)\n\n\n#Function to create new features in a dataframe\ndef create_features(df, group=None):\n    df['percent_pop_affected'] = df['total_cases']\/df['population'] * 100\n    df['percent_pop_tested'] = df['total_tests']\/df['population'] * 100\n    df['percent_pop_vaccinated'] = df['total_vaccinations']\/df['population'] * 100\n    df['herd_immunity_threshold'] = 0.67 * df['population']\n    df['death_percent'] = df['total_deaths']\/df['total_cases'] * 100\n    df['recovered_percent'] = df['total_recovered']\/df['total_cases'] * 100\n    df['total_cases_per_hundred'] = (df['total_cases'] * 100)\/df['population']\n    df['total_deaths_per_hundred'] = (df['total_deaths'] * 100)\/df['population']\n    df['total_recovered_per_hundred'] = (df['total_recovered'] * 100)\/df['population']\n    df['total_tests_per_hundred'] = (df['total_tests'] * 100)\/df['population']\n    \n    if group == 'world':\n        df['population'] = df['population'].bfill()\n        df['herd_immunity_threshold'] = 0.67 * df['population']\n        df['positive_rate'] = (df['new_cases']\/df['new_tests']).rolling(window=7).mean()\n        df['tests_per_case'] =  (df['new_tests']\/df['new_cases']).rolling(window=7).mean()\n        df['new_tests_smoothed'] = df['new_tests'].rolling(window=7).mean()\n        df['new_recovered_smoothed'] = df['new_recovered'].rolling(window=7).mean()\n        df['percent_increase_cases'] = df['new_cases'].pct_change() * 100\n        \n    if group == 'all':\n        df['active_cases'] = df['total_cases'] - df['total_recovered'] - df['total_deaths']\n        df['new_recovered'] = df.groupby('country')['total_recovered'].diff(1)\n        df['total_tests'] = df.groupby('country')['total_tests'].ffill()\n        df['total_recovered'] = df.groupby('country')['total_recovered'].ffill()\n        df['total_cases'] = df.groupby('country')['total_cases'].ffill()\n        df['total_vaccinations'] = df.groupby('country')['total_vaccinations'].ffill()\n        df['total_deaths'] = df.groupby('country')['total_deaths'].ffill()\n        \n    if group == 'continent' or group == 'all':\n        df['new_recovered_smoothed'] = df.groupby('country')['new_recovered'].apply(calc_MA_on_group)\n        df['percent_increase_cases'] = df.groupby('country')['new_cases'].pct_change() * 100\n        \n    if group == 'continent':\n        df['new_tests_smoothed'] = df.groupby('country')['new_tests'].apply(calc_MA_on_group)\n        df['positive_rate_smoothed'] = df['new_cases']\/df['new_tests']\n        df['positive_rate_smoothed'] = df.groupby('country')['positive_rate_smoothed'].apply(calc_MA_on_group)\n        df['tests_per_case_smoothed'] = df['new_tests']\/df['new_cases']\n        df['tests_per_case_smoothed'] = df.groupby('country')['tests_per_case_smoothed'].apply(calc_MA_on_group)","c1abeb06":"#Creating new features in main dataframe\n\ncreate_features(df, 'all')","8d4ca9cc":"#Creating temporary dataframes for World and continents to calculate new features for main 'world_df' & 'continent_df'\n\ntemp_world_df = pd.pivot_table(df, index='date', aggfunc=np.sum).reset_index()\ntemp_continent_df = pd.pivot_table(df, index=['continent','date'], aggfunc=np.sum).reset_index()\n\ntemp_world_df = temp_world_df[['date','new_tests','icu_patients','hosp_patients','total_tests','total_recovered',\n                               'new_recovered','active_cases']]\ntemp_continent_df = temp_continent_df[['date','continent','total_recovered','new_recovered','total_tests',\n                                      'new_tests','active_cases']]","77ac7a09":"#Dropping all empty or unrequired columns from 'world_df' and 'continent_df'\n\nworld_df = world_df.dropna(axis=1, how='all').drop(columns = ['iso_code','country'])\ncontinent_df = continent_df.dropna(axis=1, how='all').drop(columns = ['iso_code'])","12083f0d":"#Joining `world_df` and `continent_df` with `temp_world_df` and `temp_continent_df`\n\nworld_df = world_df.set_index('date').join(temp_world_df.set_index('date'))\ncontinent_df = continent_df.join(temp_continent_df.set_index(['date','continent']), on=['date','country'])","c05bce4c":"#Creating new features from function for both dataframes and renaming a column in `continent_df`\n\nworld_df.reset_index(inplace=True)\ncreate_features(world_df, 'world')\ncreate_features(continent_df, 'continent')\n\ncontinent_df.rename(columns={'country':'continent'}, inplace=True)","1f6b00f0":"#Creating two dataframes grouped into intervals of 25 days each for plotting\n\ncontinent_df_25d = continent_df.groupby(['continent', pd.Grouper(key='date', freq='25d')]).last().reset_index()\ndf_25d = df.groupby(['continent','country', pd.Grouper(key='date', freq='25d')]).last().reset_index()","6d4780f7":"# #Saving three stable and static final dataframes (df, world_df, continent_df) to disk. Needed if you want to jump\n# #directly to EDA or ML\n\n# df.to_csv('final_df.csv', index=False)\n# world_df.to_csv('final_world_df.csv',index=False)\n# continent_df.to_csv('final_continent_df.csv', index=False)","f329db1b":"#Importing from github. Necessary if you jumped directly to EDA\n\ndf = pd.read_csv('https:\/\/media.githubusercontent.com\/media\/vyaduvanshi\/ds-projects\/master\/\\\ncoronavirus-future-prediction\/final_df.csv')\nworld_df = pd.read_csv('https:\/\/media.githubusercontent.com\/media\/vyaduvanshi\/ds-projects\/master\/\\\ncoronavirus-future-prediction\/final_world_df.csv')\ncontinent_df = pd.read_csv('https:\/\/media.githubusercontent.com\/media\/vyaduvanshi\/ds-projects\/master\/\\\ncoronavirus-future-prediction\/final_continent_df.csv')\n\ndf['date'] = pd.to_datetime(df['date'], format=('%Y-%m-%d'))\nworld_df['date'] = pd.to_datetime(world_df['date'], format=('%Y-%m-%d'))\ncontinent_df['date'] = pd.to_datetime(continent_df['date'], format=('%Y-%m-%d'))","900acd79":"df.info(verbose=True)","53e3c87d":"#Custom theme for plotly graphs\n\nmy_theme = go.layout.Template({\n    'data': {'bar': [{'error_x': {'color': '#2a3f5f'},\n                      'error_y': {'color': '#2a3f5f'},\n                      'marker': {'line': {'color': '#E5ECF6', 'width': 0.5}},\n                      'type': 'bar'}],\n             'barpolar': [{'marker': {'line': {'color': '#E5ECF6', 'width': 0.5}}, 'type': 'barpolar'}],\n             'carpet': [{'aaxis': {'endlinecolor': '#2a3f5f',\n                                   'gridcolor': 'white',\n                                   'linecolor': 'white',\n                                   'minorgridcolor': 'white',\n                                   'startlinecolor': '#2a3f5f'},\n                         'baxis': {'endlinecolor': '#2a3f5f',\n                                   'gridcolor': 'white',\n                                   'linecolor': 'white',\n                                   'minorgridcolor': 'white',\n                                   'startlinecolor': '#2a3f5f'},\n                         'type': 'carpet'}],\n             'choropleth': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'type': 'choropleth'}],\n             'contour': [{'colorbar': {'outlinewidth': 0, 'ticks': ''},\n                          'colorscale': [[0.0, '#0d0887'], [0.1111111111111111,\n                                         '#46039f'], [0.2222222222222222,\n                                         '#7201a8'], [0.3333333333333333,\n                                         '#9c179e'], [0.4444444444444444,\n                                         '#bd3786'], [0.5555555555555556,\n                                         '#d8576b'], [0.6666666666666666,\n                                         '#ed7953'], [0.7777777777777778,\n                                         '#fb9f3a'], [0.8888888888888888,\n                                         '#fdca26'], [1.0, '#f0f921']],\n                          'type': 'contour'}],\n             'contourcarpet': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'type': 'contourcarpet'}],\n             'heatmap': [{'colorbar': {'outlinewidth': 0, 'ticks': ''},\n                          'colorscale': [[0.0, '#0d0887'], [0.1111111111111111,\n                                         '#46039f'], [0.2222222222222222,\n                                         '#7201a8'], [0.3333333333333333,\n                                         '#9c179e'], [0.4444444444444444,\n                                         '#bd3786'], [0.5555555555555556,\n                                         '#d8576b'], [0.6666666666666666,\n                                         '#ed7953'], [0.7777777777777778,\n                                         '#fb9f3a'], [0.8888888888888888,\n                                         '#fdca26'], [1.0, '#f0f921']],\n                          'type': 'heatmap'}],\n             'heatmapgl': [{'colorbar': {'outlinewidth': 0, 'ticks': ''},\n                            'colorscale': [[0.0, '#0d0887'], [0.1111111111111111,\n                                           '#46039f'], [0.2222222222222222,\n                                           '#7201a8'], [0.3333333333333333,\n                                           '#9c179e'], [0.4444444444444444,\n                                           '#bd3786'], [0.5555555555555556,\n                                           '#d8576b'], [0.6666666666666666,\n                                           '#ed7953'], [0.7777777777777778,\n                                           '#fb9f3a'], [0.8888888888888888,\n                                           '#fdca26'], [1.0, '#f0f921']],\n                            'type': 'heatmapgl'}],\n             'histogram': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'histogram'}],\n             'histogram2d': [{'colorbar': {'outlinewidth': 0, 'ticks': ''},\n                              'colorscale': [[0.0, '#0d0887'],\n                                             [0.1111111111111111, '#46039f'],\n                                             [0.2222222222222222, '#7201a8'],\n                                             [0.3333333333333333, '#9c179e'],\n                                             [0.4444444444444444, '#bd3786'],\n                                             [0.5555555555555556, '#d8576b'],\n                                             [0.6666666666666666, '#ed7953'],\n                                             [0.7777777777777778, '#fb9f3a'],\n                                             [0.8888888888888888, '#fdca26'], [1.0,\n                                             '#f0f921']],\n                              'type': 'histogram2d'}],\n             'histogram2dcontour': [{'colorbar': {'outlinewidth': 0, 'ticks': ''},\n                                     'colorscale': [[0.0, '#0d0887'],\n                                                    [0.1111111111111111,\n                                                    '#46039f'],\n                                                    [0.2222222222222222,\n                                                    '#7201a8'],\n                                                    [0.3333333333333333,\n                                                    '#9c179e'],\n                                                    [0.4444444444444444,\n                                                    '#bd3786'],\n                                                    [0.5555555555555556,\n                                                    '#d8576b'],\n                                                    [0.6666666666666666,\n                                                    '#ed7953'],\n                                                    [0.7777777777777778,\n                                                    '#fb9f3a'],\n                                                    [0.8888888888888888,\n                                                    '#fdca26'], [1.0, '#f0f921']],\n                                     'type': 'histogram2dcontour'}],\n             'mesh3d': [{'colorbar': {'outlinewidth': 0, 'ticks': ''}, 'type': 'mesh3d'}],\n             'parcoords': [{'line': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'parcoords'}],\n             'pie': [{'automargin': True, 'type': 'pie'}],\n             'scatter': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatter',\n                         'line':{'width':2.5}}],\n             'scatter3d': [{'line': {'colorbar': {'outlinewidth': 0, 'ticks': ''}},\n                            'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}},\n                            'type': 'scatter3d'}],\n             'scattercarpet': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scattercarpet'}],\n             'scattergeo': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scattergeo'}],\n             'scattergl': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scattergl'}],\n             'scattermapbox': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scattermapbox'}],\n             'scatterpolar': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatterpolar'}],\n             'scatterpolargl': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatterpolargl'}],\n             'scatterternary': [{'marker': {'colorbar': {'outlinewidth': 0, 'ticks': ''}}, 'type': 'scatterternary'}],\n             'surface': [{'colorbar': {'outlinewidth': 0, 'ticks': ''},\n                          'colorscale': [[0.0, '#0d0887'], [0.1111111111111111,\n                                         '#46039f'], [0.2222222222222222,\n                                         '#7201a8'], [0.3333333333333333,\n                                         '#9c179e'], [0.4444444444444444,\n                                         '#bd3786'], [0.5555555555555556,\n                                         '#d8576b'], [0.6666666666666666,\n                                         '#ed7953'], [0.7777777777777778,\n                                         '#fb9f3a'], [0.8888888888888888,\n                                         '#fdca26'], [1.0, '#f0f921']],\n                          'type': 'surface'}],\n             'table': [{'cells': {'fill': {'color': '#EBF0F8'}, 'line': {'color': 'white'}},\n                        'header': {'fill': {'color': '#C8D4E3'}, 'line': {'color': 'white'}},\n                        'type': 'table'}]},\n    'layout': {'annotationdefaults': {'arrowcolor': '#2a3f5f', 'arrowhead': 0, 'arrowwidth': 1},\n               'autotypenumbers': 'strict',\n               'coloraxis': {'colorbar': {'outlinewidth': 0, 'ticks': ''}},\n               'colorscale': {'diverging': [[0, '#8e0152'], [0.1, '#c51b7d'],\n                                            [0.2, '#de77ae'], [0.3, '#f1b6da'],\n                                            [0.4, '#fde0ef'], [0.5, '#f7f7f7'],\n                                            [0.6, '#e6f5d0'], [0.7, '#b8e186'],\n                                            [0.8, '#7fbc41'], [0.9, '#4d9221'], [1,\n                                            '#276419']],\n                              'sequential': [[0.0, '#0d0887'],\n                                             [0.1111111111111111, '#46039f'],\n                                             [0.2222222222222222, '#7201a8'],\n                                             [0.3333333333333333, '#9c179e'],\n                                             [0.4444444444444444, '#bd3786'],\n                                             [0.5555555555555556, '#d8576b'],\n                                             [0.6666666666666666, '#ed7953'],\n                                             [0.7777777777777778, '#fb9f3a'],\n                                             [0.8888888888888888, '#fdca26'], [1.0,\n                                             '#f0f921']],\n                              'sequentialminus': [[0.0, '#0d0887'],\n                                                  [0.1111111111111111, '#46039f'],\n                                                  [0.2222222222222222, '#7201a8'],\n                                                  [0.3333333333333333, '#9c179e'],\n                                                  [0.4444444444444444, '#bd3786'],\n                                                  [0.5555555555555556, '#d8576b'],\n                                                  [0.6666666666666666, '#ed7953'],\n                                                  [0.7777777777777778, '#fb9f3a'],\n                                                  [0.8888888888888888, '#fdca26'],\n                                                  [1.0, '#f0f921']]},\n               'colorway': [\"#db2b39\",\"#3d405b\",\"#2fbf71\",\"#faa613\",\"#00a6fb\"],\n               'font': {'color': '#2a3f5f'},\n               'geo': {'bgcolor': 'white',\n                       'lakecolor': 'white',\n                       'landcolor': '#E5ECF6',\n                       'showlakes': True,\n                       'showland': True,\n                       'subunitcolor': 'white'},\n               'hoverlabel': {'align': 'left',\n                             'namelength': 0},\n               'hovermode': 'closest',\n               'legend': {'orientation': 'v',\n                          'bordercolor': '#3D3D3D',\n                          'borderwidth': 0.7,\n                          'itemwidth': 30,\n                          'x': 0.01,\n                          'y': 1.075,\n                          'title': None,\n                          'bgcolor':'rgba(255,255,255,0.70)'},\n               'mapbox': {'style': 'light'},\n               'paper_bgcolor': 'white',\n               'plot_bgcolor': 'white',\n               'polar': {'angularaxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''},\n                         'bgcolor': '#E5ECF6',\n                         'radialaxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''}},\n               'scene': {'xaxis': {'backgroundcolor': '#E5ECF6',\n                                   'gridcolor': 'white',\n                                   'gridwidth': 2,\n                                   'linecolor': 'white',\n                                   'showbackground': True,\n                                   'ticks': '',\n                                   'zerolinecolor': 'white'},\n                         'yaxis': {'backgroundcolor': '#E5ECF6',\n                                   'gridcolor': 'white',\n                                   'gridwidth': 2,\n                                   'linecolor': 'white',\n                                   'showbackground': True,\n                                   'ticks': '',\n                                   'zerolinecolor': 'white'},\n                         'zaxis': {'backgroundcolor': '#E5ECF6',\n                                   'gridcolor': 'white',\n                                   'gridwidth': 2,\n                                   'linecolor': 'white',\n                                   'showbackground': True,\n                                   'ticks': '',\n                                   'zerolinecolor': 'white'}},\n               'shapedefaults': {'line': {'color': '#2a3f5f'}},\n               'ternary': {'aaxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''},\n                           'baxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''},\n                           'bgcolor': '#E5ECF6',\n                           'caxis': {'gridcolor': 'white', 'linecolor': 'white', 'ticks': ''}},\n               'title': {'x': 0.5,\n                        'font_size':30},\n               'xaxis': {'automargin': True,\n                         'gridcolor': '#eeeeee',\n                         'linecolor': 'white',\n                         'tickformat': '%b\\n%Y',\n                         'ticks': '',\n                         'title': {'text':None, 'standoff': 0, 'font': {'color':'white'}},\n                         'zerolinecolor': 'white',\n                         'zerolinewidth': 2,\n                         'hoverformat': '%d %b %Y'},\n               'yaxis': {'automargin': True,\n                         'gridcolor': '#eeeeee',\n                         'linecolor': 'white',\n                         'ticks': '',\n                         'title': {'text':None, 'standoff': 0, 'font': {'color':'white'}},\n                         'zerolinecolor': 'white',\n                         'zerolinewidth': 2}}\n})","c5abdff5":"#Setting custom plotting theme as default\n\ndef set_theme():\n    pio.templates['my_theme'] = my_theme\n    pio.templates.default = 'my_theme'\n\nset_theme()\nconfig = {'displayModeBar':False}","b084d53e":"fig = go.Figure()\nfig.add_scatter(x=[6,6,8,8,6], y=[2,3,3,2,2], fill='toself', fillcolor='rgba(0,166,251,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[4,5,5,4,4], fill='toself', fillcolor='rgba(250,166,19,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[6,7,7,6,6], fill='toself', fillcolor='rgba(47,191,113,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[8,9,9,8,8], fill='toself', fillcolor='rgba(61,64,91,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[10,11,11,10,10], fill='toself', fillcolor='rgba(219,43,57,1)')\nfig.add_scatter(x=[10],y=[5])\nfig.add_scatter(x=[0],y=[0])\nfig.add_annotation(x=3.5, y=2.5, text='Vaccinations    -', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=4.5, text='Tests              -', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=6.5, text='Recoveries      -', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=8.5, text='Deaths           -', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=10.5, text='Cases             -', font_size=35,showarrow=False)\nfig.update_layout(xaxis_tickformat='', showlegend=False, xaxis_gridcolor='#ffffff', yaxis_gridcolor='#ffffff',\n                 hoverlabel=None, margin=dict(t=90, b=0), xaxis_fixedrange=True, yaxis_fixedrange=True)\nfig.update_xaxes(visible=False)\nfig.update_yaxes(visible=False)\nfig.update_traces(mode='text', hoverinfo='skip')\nfig.add_annotation(x=0,y=1.15,showarrow=False,xref='paper', yref='paper', text='There are 5 main features in this \\\nproject (listed below). Each feature is represented by its unique colour. And the',\n                  font=dict(size=(15)))\nfig.add_annotation(x=0,y=1.1, showarrow=False, xref='paper', yref='paper', text=\"plotting of the features will \\\nalways follow the same order as below.<span style='font-size:0.65em'> (The legend order though is governed by ease of \\\nviewability)<\/span>\",\n                  font=dict(size=15))\nfig.show(config=config)","4b281ddc":"#Function to get last valid value or last change in value\n\ndef last_valid_value(var, last_changed=False):\n    val = var.iloc[var.last_valid_index()]\n    count = 1\n    while val == 0:\n        val = var.iloc[var.last_valid_index() - count]\n        count += 1\n    if last_changed == True:\n        while val == var.iloc[var.last_valid_index() - count]:\n            count += 1\n        else:\n            return var.iloc[var.last_valid_index() - count]\n    return val","d8b8119e":"fig = go.Figure()\nfig.add_annotation(xref='paper',yref='paper',x=0.5,y=1.28, text='Today\\'s Stats With Last Change', showarrow=False,\n                  font=dict(size=30))\nfig.add_indicator(mode = \"number+delta\", title='Total Cases',\n    value = last_valid_value(world_df.total_cases),\n    domain = {'x': [0, 0.25], 'y': [0.75, 1]},\n    delta = {'reference': last_valid_value(world_df.total_cases,True), 'relative': False, 'position':'top'})\nfig.add_indicator(mode = \"number+delta\", title='Total Deaths',\n    value = last_valid_value(world_df.total_deaths),\n    domain = {'x': [0.75, 1], 'y': [0.75, 1]},\n    delta = {'reference': last_valid_value(world_df.total_deaths,True), 'relative': False, 'position' : \"top\"})\nfig.add_indicator(mode = \"number+delta\", title='Total Recoveries',\n    value = last_valid_value(world_df.total_recovered),\n    domain = {'x': [0.375, 0.625], 'y': [0.375, 0.625]},\n    delta = {'reference': last_valid_value(world_df.total_recovered,True), 'relative': False, 'position' : \"top\"})\nfig.add_indicator(mode = \"number+delta\", title='Total Tests',\n    value = last_valid_value(world_df.total_tests),\n    domain = {'x': [0, 0.25], 'y': [0, 0.25]},\n    delta = {'reference': last_valid_value(world_df.total_tests,True), 'relative': False, 'position' : \"top\"})\nfig.add_indicator(mode = \"number+delta\", title='Total Vaccinations',\n    value = last_valid_value(world_df.total_vaccinations),\n    domain = {'x': [0.75, 1], 'y': [0, 0.25]},\n    delta = {'reference': last_valid_value(world_df.total_vaccinations,True), 'relative': False, 'position' : \"top\"})","d500c987":"fig = go.Figure()\nfig.add_annotation(xref='paper',yref='paper',x=0.5,y=1.28, text='Today\\'s Stats With Last Change', showarrow=False,\n                  font=dict(size=30))\nfig.add_indicator(mode = \"number+delta\", title='New Cases',\n    value = last_valid_value(world_df.new_cases),\n    domain = {'x': [0, 0.25], 'y': [0.75, 1]},\n    delta = {'reference': last_valid_value(world_df.new_cases,True), 'relative': False, 'position':'top'})\nfig.add_indicator(mode = \"number+delta\", title='New Deaths',\n    value = last_valid_value(world_df.new_deaths),\n    domain = {'x': [0.75, 1], 'y': [0.75, 1]},\n    delta = {'reference': last_valid_value(world_df.new_deaths,True), 'relative': False, 'position' : \"top\"})\nfig.add_indicator(mode = \"number+delta\", title='New Recoveries',\n    value = last_valid_value(world_df.new_recovered),\n    domain = {'x': [0.375, 0.625], 'y': [0.375, 0.625]},\n    delta = {'reference': last_valid_value(world_df.new_recovered,True), 'relative': False, 'position' : \"top\"})\nfig.add_indicator(mode = \"number+delta\", title='New Tests',\n    value = last_valid_value(world_df.new_tests),\n    domain = {'x': [0, 0.25], 'y': [0, 0.25]},\n    delta = {'reference': last_valid_value(world_df.new_tests,True), 'relative': False, 'position' : \"top\"})\nfig.add_indicator(mode = \"number+delta\", title='New Vaccinations',\n    value = last_valid_value(world_df.new_vaccinations),\n    domain = {'x': [0.75, 1], 'y': [0, 0.25]},\n    delta = {'reference': last_valid_value(world_df.new_vaccinations,True), 'relative': False, 'position' : \"top\"})","a6d97547":"fig = make_subplots(rows=1, cols=2, subplot_titles=['Normal Scale','Logarithmic Scale'])\n[fig.add_scatter(x=world_df.date, y=world_df.total_cases, row=1, col=column+1, line=dict(color='#DB2B39'),\n                 fill='tozeroy',hovertemplate='%{x}<br><b>%{y:.5s}<\/b><extra><\/extra>') for column in range(2)]\nfig.update_yaxes(type=\"log\", row=1, col=2)#, nticks=7)\nfig.update_layout(title_text='Total Cases', showlegend=False)\nfig.show(config=config)","0497418d":"fig = make_subplots(rows=1, cols=2, subplot_titles=['Normal Scale','Logarithmic Scale'])\n[fig.add_scatter(x=world_df.date, y=world_df.total_deaths, row=1, col=column+1, line=dict(color='#3D405B'),\n                fill='tozeroy', hovertemplate='%{x}<br><b>%{y:.4s}<\/b><extra><\/extra>') for column in range(2)]\nfig.update_yaxes(type=\"log\", row=1, col=2)\nfig.update_layout(title_text='Total Deaths', showlegend=False)\nfig.show(config=config)","c1ec9cdb":"world_df_rec = world_df.query('date < \"08-05-2021\"')\n\nfig = make_subplots(rows=1, cols=2, subplot_titles=['Normal Scale','Logarithmic Scale'])\n[fig.add_scatter(x=world_df_rec.date, y=world_df_rec.total_recovered, row=1, col=column+1, line=dict(color='#2FBF71'),\n                 fill='tozeroy',hovertemplate='%{x}<br><b>%{y:.5s}<\/b><extra><\/extra>') for column in range(2)]\nfig.update_yaxes(type=\"log\", row=1, col=2)\nfig.update_layout(title_text='Total Recoveries', showlegend=False)\nfig.show(config=config)","fcef3c22":"fig = make_subplots(rows=1, cols=2, subplot_titles=['Normal Scale','Logarithmic Scale'])\n[fig.add_scatter(x=world_df.date, y=world_df.total_tests, row=1, col=column+1, line=dict(color='#FAA613'),\n                fill='tozeroy', hovertemplate='%{x}<br><b>%{y}<\/b><extra><\/extra>') for column in range(2)]\nfig.update_yaxes(type=\"log\", row=1, col=2)\nfig.update_layout(title_text='Total Tests', showlegend=False)\nfig.show(config=config)","d0c6f101":"world_df_vax = world_df.query(\"date > '2020-10-31'\")\n\nfig = make_subplots(rows=1, cols=2, subplot_titles=['Normal Scale','Logarithmic Scale'])\n[fig.add_scatter(x=world_df_vax.date, y=world_df_vax.total_vaccinations, row=1, col=column+1,\n                line=dict(color='#00A6FB'),fill='tozeroy', hovertemplate='%{x}<br><b>%{y}<\/b><extra><\/extra>')\\\n                                                                                 for column in range(2)]\nfig.update_yaxes(type=\"log\", row=1, col=2)\nfig.update_layout(title_text='Total Vaccinations', showlegend=False)\nfig.show(config=config)","c6d60432":"#Function to pass custom legend names\n\ndef custom_legend_name(new_names, fig_in_func=None):\n    if fig_in_func != None: #condition added for ML plotting\n        for i, new_name in enumerate(new_names):\n            fig_in_func.data[i].name = new_name\n        return fig_in_func\n    for i, new_name in enumerate(new_names):\n        fig.data[i].name = new_name","2e59b5aa":"fig = go.Figure()\n[fig.add_scatter(x=world_df.date, y=world_df[c],) for c in ['new_cases','new_cases_smoothed']]\nfig.update_layout(hoverlabel=dict(bgcolor='rgba(0,0,0,0.70)',font=dict(color='white')),title='New Cases',\n                  hovermode='x unified',colorway=['#DB2B39','#0D0628'], height=640,\n                  xaxis=dict(rangeslider=dict(visible=True),type=\"date\"))\n\ncustom_legend_name(['New Cases','New Cases Smoothed'])\nfig.show(config=config)","3902cc07":"fig = go.Figure()\n[fig.add_scatter(x=world_df.date, y=world_df[c],) for c in ['new_deaths','new_deaths_smoothed']]\nfig.update_layout(hovermode='x unified', hoverlabel=dict(bgcolor='rgba(255,255,255,0.80)',font=dict(color='black')),\n                 title='New Deaths',colorway=['#3D405B','#DC0073'],height=640,\n                  xaxis=dict(rangeslider=dict(visible=True),type=\"date\"))\ncustom_legend_name(['New Deaths','New Deaths Smoothed'])\nfig.show(config=config)","1fdc4776":"fig = go.Figure()\n[fig.add_scatter(x=world_df_rec.date, y=world_df_rec[c],) for c in ['new_recovered','new_recovered_smoothed']]\nfig.update_layout(hovermode='x unified', hoverlabel=dict(bgcolor='rgba(255,255,255,0.75)',font=dict(color='black')),\n                 title='New Recoveries',colorway=['#2FBF71','#0D0628'],height=640,\n                  xaxis=dict(rangeslider=dict(visible=True),type=\"date\"))\ncustom_legend_name(['New Recovered','New Recovered Smoothed'])\nfig.add_annotation(xref='paper',yref='paper',x=-0.05,y=-0.43,showarrow=False,\n                  text=\"(The spike on 12th Dec is due to Turkey's govt providing a data dump on that very date. As \\\nthe figures are official, I will make no changes to the graph.)\")\nfig.show(config=config)","f8139c34":"world_df_tests = world_df[world_df['date'] < df.date.iloc[-2]]\n\nfig = go.Figure()\n[fig.add_scatter(x=world_df_tests.date, y=world_df_tests[c],) for c in ['new_tests','new_tests_smoothed']]\nfig.update_layout(hovermode='x unified', hoverlabel=dict(bgcolor='rgba(255,255,255,0.75)',font=dict(color='black')),\n                 title='New Tests',colorway=['#FAA613','#28502E'],height=640,\n                  xaxis=dict(rangeslider=dict(visible=True),type=\"date\"))\ncustom_legend_name(['New Tests','New Tests Smoothed'])\nfig.show(config=config)","201dd343":"fig = go.Figure()\n[fig.add_scatter(x=world_df_vax.date, y=world_df_vax[c],) for c in ['new_vaccinations','new_vaccinations_smoothed']]\nfig.update_layout(hovermode='x unified', hoverlabel=dict(bgcolor='rgba(0,0,0,0.75)',font=dict(color='white')),\n                 title='New Vaccinations',colorway=['#00A6FB','#0D0628'],height=640,\n                  xaxis=dict(rangeslider=dict(visible=True),type=\"date\"))\ncustom_legend_name(['New Vaccinations','New Vaccinations Smoothed'])\nfig.show(config=config)","edfffd78":"fig = go.Figure()\nfig.add_scatter(x=world_df.date, y=world_df.population, name='pop', line_color='#740667')\nfig.add_scatter(x=world_df.date, y=world_df.total_cases, fill='tozeroy', mode='lines', line_color='#DB2B39')\nfig.add_scatter(x=world_df.date, y=world_df.total_vaccinations, fill='tonexty', name='total_vax', line_color='#00A6FB')\nfig.add_scatter(x=world_df.date, y=world_df.herd_immunity_threshold, name='HiT', line_color='#F65BE3')\nfig.add_annotation(x=0.5, xref='paper',y = world_df.herd_immunity_threshold[0], text = 'Herd Immunity Threshold',\n                  arrowhead=2, font=dict(color='#F65BE3'), arrowcolor='#F65BE3', arrowsize=1.2)\nfig.add_annotation(x=0.25, xref='paper', y=world_df.population[0], text='Population', arrowhead=2,\n                  font=dict(color='#740667'), arrowsize=1.2)\nfig.add_annotation(x=0.15, xref='paper', y=round(len(world_df) * 0.15), text = 'Total Cases',\n                  arrowhead=2, font=dict(color='#DB2B39'), arrowsize=1.2)\nfig.add_annotation(x=0.92, xref='paper', y=world_df.total_vaccinations[round(len(world_df) * 0.92)],\n                   text='Total Vaccinations', arrowhead=2, font=dict(color='#00A6FB'), arrowsize=1.2)\nfig.update_layout(title_text='Herd Immunity Threshold', showlegend=False)\nfig.update_traces(hovertemplate='%{x}<br><b>%{y}<\/b><extra><\/extra>')\nfig.show(config=config)","71af0e0c":"fig = px.line(world_df_tests, x='date', y=['total_cases','total_deaths','total_recovered','total_tests',\n                              'total_vaccinations'], log_y=True)\nfig.update_traces(hovertemplate='%{y}')\nfig.update_layout(legend=dict(title=None), title='Totals Comparison Line Chart', hovermode='x unified',\n                 hoverlabel=dict(bgcolor='rgba(255,255,255,0.5)',font=dict(color='black')))\ncustom_legend_name(['Total Cases','Total Deaths','Total Recovered','Total Tests','Total Vaccinations'])\nfig.add_annotation(xref='paper',yref='paper',x=0,y=-0.16,showarrow=False,\n                  text=\"(Testing had started in other countries before China started releasing official figures for\\\n Cases. Hence, in the graph, Tests start before Cases)\")\nfig.show(config=config)","eed52515":"fig = px.area(world_df, x='date', y=['total_cases','total_deaths','total_recovered','total_tests',\n                                     'total_vaccinations'])\nfig.update_traces(hovertemplate='%{y}')\nfig.update_layout(legend=dict(title=None, traceorder='reversed'), title='Totals Comparison Area Chart',\n                  hovermode='x unified',hoverlabel=dict(bgcolor='rgba(0,0,0,0.75)',font=dict(color='white')))\ncustom_legend_name(['Total Cases','Total Deaths','Total Recovered','Total Tests','Total Vaccinations'])\nfig.show(config=config)","d53bb608":"fig = px.line(world_df, x='date', y=['new_cases','new_deaths','new_recovered','new_tests',\n                                     'new_vaccinations'], log_y=True)\nfig.update_traces(hovertemplate=None)\nfig.update_layout(legend=dict(title=None), title='Daily Figures', hovermode='x unified',\n                 hoverlabel=dict(bgcolor='rgba(255,255,255,0.75)',font=dict(color='black')))\ncustom_legend_name(['New Cases','New Deaths','New Recovered','New Tests','New Vaccinations'])\nfig.show(config=config)","90332f0b":"fig = px.area(world_df_tests, x='date',y=['percent_pop_affected','percent_pop_tested','percent_pop_vaccinated'],\n              title='Percent Population Area Chart', color_discrete_sequence=['#db2b39','#faa613','#00a6fb'])\nfig.update_traces(hovertemplate=None, legendgroup=None)\nfig.update_layout(legend=dict(title=None), hovermode='x unified',hoverlabel=dict(bgcolor='rgba(0,0,0,0.75)',\n                                                                                  font=dict(color='white')))\ncustom_legend_name(['Percent Population Affected','Percent Population Tested','Percent Population Vaccinated'])\nfig.show(config=config)","769c5e42":"fig = px.line(world_df, x='date',y=['new_cases','hosp_patients','icu_patients'],title='Cases & Patients',\n             color_discrete_sequence=['#db2b39','#390099','#00A676'])\nfig.update_traces(hovertemplate=None, legendgroup=None)\nfig.update_layout(legend=dict(title=None), hovermode='x unified',\n                 hoverlabel=dict(bgcolor='rgba(255,255,255,0.75)',font=dict(color='black')))\ncustom_legend_name(['New Cases','Hospital Patients','ICU Patients'])\nfig.show(config=config)","047c837b":"fig = go.Figure()\nfig.add_scatter(x=world_df.date, y=world_df.death_percent, fill='tozeroy', name='Case Fatality Percent',\n               line=dict(color='#3d405b'))\nfig.add_scatter(x=world_df.date, y=world_df.recovered_percent, fill='tonexty', name='Recovered Percent',\n               line=dict(color='#2fbf71'))\nfig.update_traces(hovertemplate=None, legendgroup=None)\nfig.update_layout(legend=dict(title=None), hovermode='x unified', title='Recovered Percent & Case Fatality Percent',\n                 hoverlabel=dict(bgcolor='rgba(255,255,255,0.75)',font=dict(color='black')))\ncustom_legend_name(['Case Fatality Percent','Recovered Percent'])\nfig.show(config=config)","3aad0242":"fig= go.Figure()\nfig.add_scatter(x=world_df.date, y=world_df.positive_rate, name='Positive Rate')\nfig.add_scatter(x=world_df.date, y=world_df.tests_per_case, name='Tests Per Case', line=dict(color='#faa613'))\nfig.update_layout(hovermode='x unified', hoverlabel=dict(bgcolor='rgba(0,0,0,0.75)',font=dict(color='white')),\n                 title='Positive Rate & Tests Per Case')\nfig.show(config=config)","f90cbd8f":"fig = px.line(world_df, x='date', y='percent_increase_cases', color_discrete_sequence=['#F71735'],\n        title='Growth Rate<br><sup><sup>(Percent change per day)<\/sup><\/sup>')\nfig.update_traces(hovertemplate='%{x}<br>Percent change: %{y}')\nfig.show(config=config)","5229bf8d":"#Calculating plot ratio of vaccination start day to total days\n\ntotal_days = max(world_df.date) - min(world_df.date)\nvax_start_day = pd.Timestamp('2020-12-13') - min(world_df.date)\nvax_start_ratio = vax_start_day\/total_days","97c7523e":"fig = px.line(world_df, x='date', y='reproduction_rate', title='Coronavirus Reproduction Rate (R<sub>0<\/sub>)',\n             color_discrete_sequence=['#F71735'])\nfig.update_traces(hovertemplate='%{x}<br>R<sub>0<\/sub>: %{y}')\nfig.add_shape(type='line', xref='paper',x0=vax_start_ratio ,x1=vax_start_ratio, y1=3.7)\nfig.add_annotation(x=vax_start_ratio+0.01, xref='paper', y=0.75, yref='paper',axref='x domain',ayref='y domain',\n                   ax=60, ay=-70,\n                   text='Start of Vaccination<br>(13th Dec 2020)', arrowhead=2, arrowsize=1.2)\nfig.show(config=config)","b3fd4fd9":"#Importing data for a graph\nepidemic_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/vyaduvanshi\/helper-files\/master\/epidemic_stats.csv')\nepidemic_df.dropna(inplace=True)\nepidemic_df.drop([2,3,7,12,13,15,17],inplace=True)\n\n#Creating array for plotting line\nx_array = []\nfor x,y in zip(epidemic_df.rnaught_lower,epidemic_df.rnaught_upper):\n    x_array.append(x)\n    x_array.append(y)   \ny_array = []\nfor x,y in zip(epidemic_df.hit_lower,epidemic_df.hit_upper):\n    y_array.append(x)\n    y_array.append(y)\n\n#Plotting graph\na = ['#23001E','#20A39E','#D00000','#29282A','#FF0A0A','#C6F91F','#FF3333','#AAF683','#FFBA49','#058C42']\nfig = go.Figure()\nfor r0_low, r0_high, hit_low, hit_high in zip(epidemic_df.rnaught_lower, epidemic_df.rnaught_upper,\n                                           epidemic_df.hit_lower, epidemic_df.hit_upper):\n    fig.add_scatter(x=[r0_low,r0_low,0,0,r0_high,r0_high],y=[0,hit_low,hit_low,hit_high,hit_high,0], fill='toself',\n                   mode='text')\nfig.add_scatter(x=sorted(x_array), y=sorted(y_array), line_color='black', showlegend=False)\nfig.update_xaxes(tickformat='', hoverformat='', title=dict(text='R<sub>0<\/sub>', standoff=15,\n                                                           font=dict(color='#2A3F5F')))\nfig.update_yaxes(title=dict(text='Herd Immunity Threshold', standoff=15, font=dict(color='#2A3F5F')))\nfig.update_layout(showlegend=True, height=800, margin=dict(l=0,r=0), colorway = a,\n                  title_text='R<sub>0<\/sub> vs Herd Immunity Threshold', legend_orientation='h', legend_borderwidth=0)\nfig.update_traces(hovertemplate='<b>R<sub>0<\/sub>: <\/b>%{x}<br><b>HIT: <\/b>%{y}<extra><\/extra>')\ncustom_legend_name(list(epidemic_df.Disease), fig_in_func=fig)\nfig.show()","b306c058":"fig = px.line(world_df, x='total_vaccinations_per_hundred', y='reproduction_rate', range_y=[0,1.4],\n       title='Vaccination vs Reproduction (R<sub>0<\/sub>) Rates', color_discrete_sequence=['#F71735'])\nfig.update_traces(hovertemplate='Total Vaccinations Per Hundred: %{x}<br>R<sub>0<\/sub>: %{y}')\nfig.update_xaxes(title=dict(text='Total Vaccinations Per Hundred', standoff=15, font_color='#2a3f5f'),\n                 hoverformat = '', tickformat = '')\nfig.update_yaxes(title=dict(text='Reproduction Rate', standoff= 15, font_color='#2a3f5f'))\nfig.show(config=config)","90a81327":"#Function to calculate rate of feature\n\ndef calc_rate(var, x, population):\n    return round((var * x)\/population,2)\n\npop = world_df.population[0]","f4786359":"#Data for table\n\nheader_vals = ['Feature','Per Capita','Per 100','Per 1000','Per Million']\n\nvalues_world = [['Total Cases','Total Deaths','Total Recovered','Total Tests','Total Vaccinations',\n                'People Vaccinated','People Fully Vaccinated'],\n                \n                [calc_rate(last_valid_value(world_df.total_cases),1,pop),\n                 round(last_valid_value(world_df.total_deaths)\/pop,4),\n                 calc_rate(last_valid_value(world_df.total_recovered),1,pop),\n                 calc_rate(last_valid_value(world_df.total_tests),1,pop),\n                 calc_rate(last_valid_value(world_df.total_vaccinations),1,pop),\n                 calc_rate(last_valid_value(world_df.people_vaccinated),1,pop),\n                 calc_rate(last_valid_value(world_df.people_fully_vaccinated),1,pop)],\n                \n                [round(last_valid_value(world_df.total_cases_per_hundred),2),\n                 round(last_valid_value(world_df.total_deaths_per_hundred),2),\n                 round(last_valid_value(world_df.total_recovered_per_hundred),2),\n                 round(last_valid_value(world_df.total_tests_per_hundred),2),\n                 last_valid_value(world_df.total_vaccinations_per_hundred),\n                 last_valid_value(world_df.people_vaccinated_per_hundred),\n                 last_valid_value(world_df.people_fully_vaccinated_per_hundred)],\n                \n                [calc_rate(last_valid_value(world_df.total_cases),1000,pop),\n                 calc_rate(last_valid_value(world_df.total_deaths),1000,pop),\n                 calc_rate(last_valid_value(world_df.total_recovered),1000,pop),\n                 calc_rate(last_valid_value(world_df.total_tests),1000,pop),\n                 calc_rate(last_valid_value(world_df.total_vaccinations),1000,pop),\n                 calc_rate(last_valid_value(world_df.people_vaccinated),1000,pop),\n                 calc_rate(last_valid_value(world_df.people_fully_vaccinated),1000,pop)],\n                \n                [last_valid_value(world_df.total_cases_per_million),\n                 last_valid_value(world_df.total_deaths_per_million),\n                 calc_rate(last_valid_value(world_df.total_recovered),1000000,pop),\n                 calc_rate(last_valid_value(world_df.total_tests),1000000,pop),\n                 calc_rate(last_valid_value(world_df.total_vaccinations),1000000,pop),\n                 calc_rate(last_valid_value(world_df.people_vaccinated),1000000,pop),\n                 calc_rate(last_valid_value(world_df.people_fully_vaccinated),1000000,pop)]]","ccbc9c6a":"fig = go.Figure(data=[go.Table(\n    header=dict(values=header_vals,\n                fill_color='paleturquoise',\n                align='center',\n               height=35,\n               font=dict(size=15)),\n    cells=dict(values=values_world,\n               fill_color='lavender',\n               align='left',\n              height=30,\n              font=dict(size=13)))\n])\n\nfig.update_layout(title_text='Features in Various Rates',margin=dict(b=0))\nfig.show(config=config)","79d06951":"cont_total_df = pd.pivot_table(continent_df, index='continent', aggfunc='last').reset_index()\n\nfor log_y in False,True:\n    fig = go.Figure()\n    fig = px.histogram(cont_total_df, x='continent', y=['total_cases','total_deaths','total_recovered','total_tests',\n                                                        'total_vaccinations'], barmode='group', log_y=log_y,\n                      title = '<sup>Logarithmic Scale<sup>' if log_y else \n                       'Continent Wise Comparison<br><sup>Normal Scale<\/sup>')\n    fig.update_layout(legend=dict(orientation='h', title=None, borderwidth=0),title_font_size=30, title_y=0.94)\n    fig.update_traces(hovertemplate='%{y}<extra><\/extra>')\n    fig.update_xaxes(tickfont=dict(size=15))\n    custom_legend_name(['Total Cases','Total Deaths','Total Recovered','Total Tests','Total Vaccinations'])\n    fig.show(config=config)","912d4a59":"fig = go.Figure()\nfig.add_scatter(x=[6,6,8,8,6], y=[2,3,3,2,2], fill='toself', fillcolor='rgba(255,149,10,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[4,5,5,4,4], fill='toself', fillcolor='rgba(41,191,18,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[6,7,7,6,6], fill='toself', fillcolor='rgba(57,0,153,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[8,9,9,8,8], fill='toself', fillcolor='rgba(52,228,234,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[10,11,11,10,10], fill='toself', fillcolor='rgba(255,44,85,1)')\nfig.add_scatter(x=[6,6,8,8,6], y=[12,13,13,12,12], fill='toself', fillcolor='rgba(83,134,228,1)')\nfig.add_scatter(x=[10],y=[5])\nfig.add_scatter(x=[0],y=[0])\nfig.add_annotation(x=3.5, y=2.5, text='South America   -    ', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=4.5, text='Oceania             -    ', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=6.5, text='North America   -    ', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=8.5, text='Europe             -    ', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=10.5, text='Asia                 -    ', font_size=35,showarrow=False)\nfig.add_annotation(x=3.5, y=12.5, text='Africa               -    ', font_size=35,showarrow=False)\nfig.update_layout(xaxis_tickformat='', showlegend=False, xaxis_gridcolor='#ffffff', yaxis_gridcolor='#ffffff',\n                 hoverlabel=None, margin=dict(t=90, b=0), xaxis_fixedrange=True, yaxis_fixedrange=True)\nfig.update_xaxes(visible=False)\nfig.update_yaxes(visible=False)\nfig.update_traces(mode='text', hoverinfo='skip')\nfig.add_annotation(x=0,y=1.15,showarrow=False,xref='paper', yref='paper', text='The continents are represented by \\\nthe following colours. Their order of plotting will always be alphabetical.',\n                  font=dict(size=(15)))\nfig.show(config=config)","3b62fd72":"#Passing colours for each continent\n\npio.templates['my_theme'].layout.colorway= [\"#5386E4\",\"#ff2c55\",\"#34e4ea\",\"#390099\",\"#29bf12\",\"#ff950a\"]","78192703":"fig = px.area(continent_df, x='date', y='new_cases_smoothed', color='continent',\n             title='New Cases', groupnorm='percent', hover_data=['new_cases'], height=550)\nfig.update_traces(hovertemplate='%{customdata:,}', legendgroup=None, mode='none')\nfig.update_layout(hovermode='x unified', legend=dict(title=None, orientation='h', borderwidth=0),\n                 hoverlabel=dict(bgcolor='rgba(0,0,0,0.4)',font=dict(color='white')))\nfig.show(config=config)","c832b060":"fig = px.area(continent_df, x='date', y='new_deaths_smoothed', color='continent',\n             title='New Deaths', groupnorm='percent', hover_data=['new_deaths'], height=550)\nfig.update_traces(hovertemplate='%{customdata:,}', mode='none', legendgroup=None)\nfig.update_layout(hovermode='x unified', legend=dict(title=None, orientation='h', borderwidth=0),\n                 hoverlabel=dict(bgcolor='rgba(0,0,0,0.4)',font=dict(color='white')))\nfig.show(config=config)","bca1bf31":"continent_df_rec = continent_df.query('date < \"08-05-2021\"')\n\nfig = px.area(continent_df_rec, x='date', y='new_recovered_smoothed', color='continent',\n             title='New Recoveries', groupnorm='percent', hover_data=['new_recovered'], height=550)\nfig.update_traces(hovertemplate='%{customdata:,}', mode='none', legendgroup=None)\nfig.update_layout(hovermode='x unified', legend=dict(title=None, orientation='h', borderwidth=0),\n                 hoverlabel=dict(bgcolor='rgba(0,0,0,0.4)',font=dict(color='white')))\nfig.show(config=config)","e2182f68":"fig = px.area(continent_df, x='date', y='new_tests_smoothed', color='continent',\n             title='New Tests', groupnorm='percent', hover_data=['new_tests'], height=550)\nfig.update_traces(hovertemplate='%{customdata:,}', mode='none', legendgroup=None)\nfig.update_layout(hovermode='x unified', legend=dict(title=None, orientation='h', borderwidth=0),\n                 hoverlabel=dict(bgcolor='rgba(0,0,0,0.4)',font=dict(color='white')))\nfig.show(config=config)","0d660e59":"continent_df_vax = continent_df.query(\"date>'2020-11-20'\")\ncontinent_df_vax = continent_df_vax[continent_df_vax['date'] < df.date.iloc[-1]]\n\nfig = px.area(continent_df_vax, x='date', y='new_vaccinations_smoothed', color='continent',\n             title='New Vaccinations', groupnorm='percent', hover_data=['new_vaccinations'], height=550)\nfig.update_traces(hovertemplate='%{customdata:,}', mode='none', legendgroup=None)\nfig.update_layout(hovermode='x unified', legend=dict(title=None, orientation='h', borderwidth=0),\n                 hoverlabel=dict(bgcolor='rgba(0,0,0,0.4)',font=dict(color='white')))\nfig.show(config=config)","e6ba685c":"domains = [\n    {'x': [0.0, 0.38], 'y': [0.0, 0.38]}, #bot left\n    {'x': [0.31, 0.69], 'y': [0.31, 0.69]}, # mid\n    {'x': [0.0, 0.38], 'y': [0.62, 1.0]}, # top left\n    {'x': [0.62, 1], 'y': [0.0, 0.38]}, #bot right\n    {'x': [0.62, 1], 'y': [0.62, 1.00]}, #top right\n]\n\nfig = go.Figure()\nfig.add_pie(labels=continent_df.continent, values=continent_df.new_tests, domain=domains[0], title_text='Tests')\nfig.add_pie(labels=continent_df.continent, values=continent_df.new_recovered, domain=domains[1],\n            title_text='Recoveries')\nfig.add_pie(labels=continent_df.continent, values=continent_df.new_cases, domain=domains[2], title_text='Cases')\nfig.add_pie(labels=continent_df.continent, values=continent_df.new_vaccinations, domain=domains[3],\n            title_text='Vaccinations')\nfig.add_pie(labels=continent_df.continent, values=continent_df.new_deaths, domain=domains[4], title_text='Deaths')\n\nfig.update_layout(width=950, height=800, legend={'x':-0.09,'y':0.52}, title='Continent Comparison Across Features \\\n(Totals)')\nfig.update_traces(hoverinfo=\"label+value\", textinfo='percent', opacity=0.8, sort=False, direction='clockwise',\n                  insidetextorientation='horizontal', title_position='bottom center', title_font_size=21,\n                  marker=dict(line=dict(color='#000000',width=0.6)))\nfig.show(config=config)","da7ef712":"temp_df = continent_df.copy()\n\nfor var in ['new_cases_smoothed','new_deaths_smoothed','new_recovered_smoothed','new_tests_smoothed',\n         'new_vaccinations_smoothed']:\n    if var == 'new_vaccinations_smoothed':\n        temp_df = continent_df_vax\n    if var == 'new_recovered_smoothed':\n        temp_df = continent_df_rec\n    fig = px.line(temp_df, x='date', y=var, color='continent', title=var.replace('_',' ').title().\n                  replace('Smoothed','Line Chart').replace('New','Daily'))\n    fig.update_traces(hovertemplate=None, legendgroup=None)\n    fig.update_layout(legend=dict(title=None,orientation='v'), hovermode='x unified',\n                     hoverlabel=dict(bgcolor='rgba(0,0,0,0.75)',font=dict(color='white')))\n    fig.show(config=config)","cab0a5ac":"for continent in continent_list:\n    temp_df = continent_df_vax[continent_df_vax['continent']==continent]\n    fig = go.Figure()\n    fig.add_scatter(x=continent_df_vax.date,\n                    y=temp_df.people_fully_vaccinated,fill='tozeroy', fillcolor='rgba(0,166,251,0.8)',\n                    line_color='rgba(0,166,251,0.8)', name='Fully vaccinated',\n                    hovertemplate='%{y:,.4s}<br>% of population : '+'%{text:.2f}',\n                   text=(temp_df.people_fully_vaccinated\/temp_df.population *100))\n    fig.add_scatter(x=continent_df_vax.date,\n                    y=temp_df.people_vaccinated,fill='tonexty', fillcolor='rgba(0,166,251,0.3)',\n                    line_color='rgba(0,166,251,0.9)',name='At least 1 dose',\n                   hovertemplate='%{y:,.4s}<br>% of population : '+'%{text:.2f}',\n                   text=(temp_df.people_vaccinated\/temp_df.population *100))\n    fig.update_layout(title_text='Vaccinations<br><sub>'+continent+'<\/sub>', legend=dict(orientation='h',\n                                                                                        borderwidth=0),\n                     hovermode='x unified', hoverlabel=dict(bgcolor='rgba(255,255,255,0.5)',font=dict(color='black')))\n    if continent == 'Asia':\n        fig.add_annotation(xref='paper',yref='paper',x=0,y=-0.2, showarrow=False,\n                           text=\"<span style='font-size:1em;color:dark-gray'>(The spike on 10th June is \\\ndue to China\\'s sudden reporting on that date. As the numbers are official, \\\nI will make no changes to the graph.)<\/span>\")\n    if continent == 'Oceania':\n        fig.add_annotation(xref='paper',yref='paper',x=-0.1,y=-0.2, showarrow=False,\n                           text=\"<span style='font-size:1em;color:dark-gray'>(The spike on 24th May is \\\ndue to Australia\\'s commencement of reporting for second doses. As the numbers are official, \\\nI will make no changes to the graph.)<\/span>\")\n    fig.show(config=config)","078895d7":"fig = px.area(continent_df, x='date', y='death_percent', color='continent',title='Case Fatality Percent')\nfig.update_layout(legend=dict(orientation='h',borderwidth=0, title=None), hovermode='x unified',\n                 hoverlabel=dict(bgcolor='rgba(255,255,255,0.7)',font=dict(color='black')))\nfig.update_traces(mode='none',hovertemplate='%{y:.2f}', legendgroup=None)\nfig.show(config=config)","31dcaf1c":"fig = px.area(continent_df_rec, x='date', y='recovered_percent', color='continent',title='Recovered Percent')\nfig.update_layout(legend=dict(orientation='h',borderwidth=0, title=None), hovermode='x unified',\n                 hoverlabel=dict(bgcolor='rgba(255,255,255,0.7)',font=dict(color='black')))\nfig.update_traces(mode='none',hovertemplate='%{y:.2f}', legendgroup=None)\nfig.show(config=config)","31021fda":"for feature in ('percent_pop_affected','percent_pop_tested','percent_pop_vaccinated'):\n    fig = px.area(continent_df_vax if feature == 'percent_pop_vaccinated' else continent_df,\n                  x='date', y=feature, color='continent',\n                  title=feature.replace('pop','Population').replace('_',' ').title())\n    fig.update_layout(legend=dict(orientation='h',borderwidth=0, title=None), hovermode='x unified',\n                     hoverlabel=dict(bgcolor='rgba(255,255,255,0.7)',font=dict(color='black')))\n    fig.update_traces(mode='none',hovertemplate='%{y:.2f}', legendgroup=None)\n    fig.show(config=config)","91e176af":"fig = px.line(continent_df, x='date', y='tests_per_case_smoothed', color='continent',title='Tests Per Case',\n             log_y=True)\nfig.update_layout(legend_title=None, hovermode='x unified',\n                 hoverlabel=dict(bgcolor='rgba(0,0,0,0.75)',font=dict(color='white')))\nfig.update_traces(hovertemplate='%{y:.2f}', legendgroup=None)\nfig.show(config=config)","eeac4428":"def max_range_aniframe(feature):\n    return continent_df_25d[feature].max() + (continent_df_25d[feature].max()\/10)","c13a28a8":"fig = px.bar(continent_df_25d, x='continent', y='total_cases',animation_frame=continent_df_25d.date.astype(str),\n             log_y=False, range_y=[1,max_range_aniframe('total_cases')], color_discrete_sequence=['#db2b39'],\n             title='Total Cases', text='total_cases')\n\nannotation_date = list(continent_df_25d.date.sort_values().dt.strftime('%d %b %Y'))\nfig.update_layout(showlegend=False, xaxis_tickfont_size=15)\nfig.update_traces(customdata= annotation_date[0:6], texttemplate='%{y:,}', textposition='outside',\n                  hovertemplate='%{customdata}<br>%{y}')\nfig.add_annotation(x=0.5,y=1.15,text=annotation_date[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(customdata=annotation_date[0+(6*idx):6+(6*idx)],\n                         hovertemplate='%{customdata}<br>%{y}', textposition='outside')\n    frame.layout.update(annotations=[dict(x=0.5,y=1.15,text=annotation_date[idx*6],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","20c064da":"fig = px.bar(continent_df_25d, x='continent', y='total_deaths',animation_frame=continent_df_25d.date.astype(str),\n             log_y=False, range_y=[1,max_range_aniframe('total_deaths')], color_discrete_sequence=['#3d405b'],\n             title='Total Deaths', text='date')\n\nfig.update_layout(showlegend=False, xaxis_tickfont_size=15)\nfig.update_traces(customdata= annotation_date[0:6], texttemplate='%{y:,}', textposition='outside',\n                  hovertemplate='%{customdata}<br>%{y}')\nfig.add_annotation(x=0.5,y=1.15,text=annotation_date[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(customdata=annotation_date[0+(6*idx):6+(6*idx)],\n                         hovertemplate='%{customdata}<br>%{y}', textposition='outside')\n    frame.layout.update(annotations=[dict(x=0.5,y=1.15,text=annotation_date[idx*6],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","f8530cc6":"continent_df_25d_rec = continent_df_25d.query('date < \"08-05-2021\"')\n\nfig = px.bar(continent_df_25d_rec, x='continent', y='total_recovered',\n             animation_frame=continent_df_25d_rec.date.astype(str), log_y=False,\n             range_y=[1,max_range_aniframe('total_recovered')], color_discrete_sequence=['#2fbf71'],\n             title='Total Recovered', text='date')\n\nannotation_date_rec = list(continent_df_25d_rec.date.sort_values().dt.strftime('%d %b %Y'))\nfig.update_layout(showlegend=False, xaxis_tickfont_size=15)\nfig.update_traces(customdata= annotation_date_rec[0:6], texttemplate='%{y:,}', textposition='outside',\n                  hovertemplate='%{customdata}<br>%{y}')\nfig.add_annotation(x=0.5,y=1.15,text=annotation_date_rec[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(customdata=annotation_date_rec[0+(6*idx):6+(6*idx)],\n                         hovertemplate='%{customdata}<br>%{y}', textposition='outside')\n    frame.layout.update(annotations=[dict(x=0.5,y=1.15,text=annotation_date_rec[idx*6],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","49b34e53":"fig = px.bar(continent_df_25d, x='continent', y='total_tests',animation_frame=continent_df_25d.date.astype(str),\n             log_y=False, range_y=[1,max_range_aniframe('total_tests')], color_discrete_sequence=['#faa613'],\n             title='Total Tests', text='date')\n\nfig.update_layout(showlegend=False, xaxis_tickfont_size=15)\nfig.update_traces(customdata= annotation_date[0:6], texttemplate='%{y:,}', textposition='outside',\n                  hovertemplate='%{customdata}<br>%{y}')\nfig.add_annotation(x=0.5,y=1.15,text=annotation_date[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(customdata=annotation_date[0+(6*idx):6+(6*idx)],\n                         hovertemplate='%{customdata}<br>%{y}', textposition='outside')\n    frame.layout.update(annotations=[dict(x=0.5,y=1.15,text=annotation_date[idx*6],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","b105fcca":"continent_df_25d_vax = continent_df_25d.query('date > \"27-10-2020\"')\n\nfig = px.bar(continent_df_25d_vax, x='continent', y='total_vaccinations',\n             animation_frame=continent_df_25d_vax.date.astype(str), log_y=False,\n             range_y=[1,max_range_aniframe('total_vaccinations')], color_discrete_sequence=['#00a6fb'],\n             title='Total Vaccinations', hover_name='date', text='date')\n\nannotation_date_vax = list(continent_df_25d_vax.date.sort_values().dt.strftime('%d %b %Y'))\nfig.update_layout(showlegend=False, xaxis_tickfont_size=15)\nfig.update_traces(customdata= annotation_date_vax[0:6], texttemplate='%{y:,}', textposition='outside',\n                  hovertemplate='%{customdata}<br>%{y}')\nfig.add_annotation(x=0.5,y=1.15,text=annotation_date_vax[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(customdata=annotation_date_vax[0+(6*idx):6+(6*idx)],\n                         hovertemplate='%{customdata}<br>%{y}', textposition='outside')\n    frame.layout.update(annotations=[dict(x=0.5,y=1.15,text=annotation_date_vax[idx*6],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","a5216e24":"#Function to change SI-prefix units from machine to human\n\ndef human_format(num):\n    num = float('{:.3g}'.format(num))\n    magnitude = 0\n    while abs(num) >= 1000:\n        magnitude += 1\n        num \/= 1000.0\n    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'), \n                         ['', 'K', 'M', 'B', 'T'][magnitude])","69b2cb7e":"#Creating two variables for 3d plots\n\ncolorlist = list(np.arange(0,continent_df_25d.shape[0]\/6)) * 6\ndatelist = [str(x) if idx%4==0 else '' for idx,x in enumerate(continent_df_25d.date.dt.strftime('%d %b %Y').unique())]","8eeac7b0":"continent_df_25d[\"hover_data\"] = continent_df_25d.apply(lambda r: \n    f\"Tests: {human_format(r['total_tests'])}<br>Vaccinations: {human_format(r['total_vaccinations'])}\",axis=1)\n\nannotation_dates_3d = list(continent_df_25d.date.dt.strftime('%d %b %Y'))\n\nfig = px.scatter_3d(continent_df_25d, x='total_cases', y='total_deaths', z='total_tests',\n             color=colorlist, symbol='continent', text=annotation_dates_3d,\n                    symbol_sequence=['square','diamond','circle','x','cross','square-open'],\n                   custom_data=['hover_data'], title='Cases, Deaths, Tests', opacity=0.85,\n                   color_continuous_scale='Turbo', labels={'total_tests':'Total Tests',\n                                                          'total_deaths':'Total Deaths',\n                                                          'total_cases':'Total Cases'})\n\ncamera = dict(eye=dict(x=1.75, y=-1.25, z=0.65))\n                                                        \nfig.update_layout(margin=dict(l=0, r=0, b=0, t=100), scene_camera=camera, legend=dict(orientation='h',borderwidth=0,\n                                                                                   title_text=None),\n                 coloraxis_colorbar=dict(title=None, thickness=20, len=1, tickvals=np.arange(0,len(datelist)),\n                                    ticktext=datelist))\nfig.update_traces( mode='markers', hovertemplate='<b>%{text}<\/b><br>Cases: %{x}<br>Deaths: %{y}<br>%{customdata}')\nfig.show(config=config)","cd17d818":"fig = px.scatter_3d(continent_df_25d, x='total_cases_per_hundred', y='total_deaths_per_hundred',\n                    z='total_tests_per_hundred', color = colorlist, symbol='continent', text=annotation_dates_3d,\n                   symbol_sequence=['square','diamond','circle','x','cross','square-open'],\n                   custom_data=['total_vaccinations_per_hundred'], title='(Cases, Deaths, Tests) Per Hundred \\\nPopulation',\n                    opacity=0.85, color_continuous_scale='Turbo', labels={'total_tests_per_hundred':'Total Tests',\n                                                          'total_deaths_per_hundred':'Total Deaths',\n                                                          'total_cases_per_hundred':'Total Cases'})\n\ncamera = dict(eye=dict(x=1.75, y=-1.25, z=0.65))\n\nfig.update_layout(margin=dict(l=0, r=0, b=0, t=100), scene_camera=camera, legend=dict(orientation='h',borderwidth=0,\n                                                                                   title_text=None),\n                 coloraxis_colorbar=dict(title=None, thickness=20, len=1, tickvals=np.arange(0,len(datelist)),\n                                    ticktext=datelist))\nfig.update_traces( mode='markers', hovertemplate='<b>%{text}<\/b><br>Cases: %{x}<br>Deaths: %{y}<br>\\\nTests: %{z}<br>Vaccinations: %{customdata}')\nfig.show(config=config)","cc83f823":"#Creating temporary dataframes for plotting of all five features\n\ntemp_df = pd.pivot_table(df, index=['continent','country'], aggfunc='last').reset_index()\ntemp_df['world'] = 'World'\ntemp_df_cases = temp_df[temp_df['total_cases'].notna()]\ntemp_df_deaths = temp_df[temp_df['total_deaths'].notna()]\ntemp_df_recovered = temp_df[temp_df['total_recovered'].notna()]\ntemp_df_recovered = temp_df_recovered[(temp_df_recovered['total_recovered'] != 0)]\ntemp_df_tests = temp_df[temp_df['total_tests'].notna()]\ntemp_df_vax = temp_df[temp_df['total_vaccinations'].notna()]\n# temp_df_vax = temp_df_vax[(temp_df_vax['total_vaccinations'])]\n\ntemp_df_cases['total_cases_per_hundred'] = round(temp_df_cases['total_cases_per_hundred'],4)\ntemp_df_deaths['total_deaths_per_hundred'] = round(temp_df_deaths['total_deaths_per_hundred'],5)\ntemp_df_tests['total_tests_per_hundred'] = round(temp_df_tests['total_tests_per_hundred'],3)\ntemp_df_vax['total_vaccinations_per_hundred'] = round(temp_df_vax['total_vaccinations_per_hundred'],3)","fd6c2ac2":"fig = px.treemap(temp_df_cases, path=['world','continent','country'], values='total_cases', color='total_cases',\n                 color_continuous_scale=[\"#FCEEEF\", \"#db2b39\"], title='Total Cases', hover_name='country')\n\nfig.update_traces(hovertemplate=None, hoverinfo='label+value+percent root+percent parent')\nfig.update_layout( margin = dict(t=80, l=0, r=0, b=10), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.show(config=config)","a7f71016":"fig = px.treemap(temp_df_cases, path=['world','continent','country'], values='total_cases_per_hundred',\n                 color='total_cases_per_hundred', title='Total Cases Per 100 Population',\n                 color_continuous_scale=[\"#FCEEEF\", \"#db2b39\"], custom_data=['total_cases_per_hundred'])\n\nfig.update_traces(hovertemplate='<b>%{label}<\/b><br>%{customdata}')\nfig.update_layout( margin = dict(t=80, l=0, r=0, b=10), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.data[0].customdata[-1] = round(last_valid_value(world_df['total_cases_per_hundred']),3)\nfig.data[0].customdata[-7:-1] = np.round(cont_total_df[['total_cases_per_hundred']].values,3)\n    \nfig.show(config=config)","af567e19":"fig = px.treemap(temp_df_deaths, path=['world','continent','country'], values='total_deaths',\n          color='total_deaths', color_continuous_scale=[\"#ffffff\", \"#3d405b\"], title='Total Deaths')\n\nfig.update_traces(hovertemplate=None, hoverinfo='label+value+percent root+percent parent')\nfig.update_layout( margin = dict(t=80, l=0, r=0, b=10), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.show(config=config)","1a585665":"fig = px.treemap(temp_df_deaths, path=['world','continent','country'], values='total_deaths_per_hundred',\n                 color='total_deaths_per_hundred', title='Total Deaths Per 100 Population',\n                 color_continuous_scale=[\"#ffffff\", \"#3d405b\"], custom_data=['total_deaths_per_hundred'])\n\nfig.update_traces(hovertemplate='<b>%{label}<\/b><br>%{customdata}')\nfig.update_layout( margin = dict(t=80, l=0, r=0, b=10), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.data[0].customdata[-1] = round(last_valid_value(world_df['total_deaths_per_hundred']),3)\nfig.data[0].customdata[-7:-1] = np.round(cont_total_df[['total_deaths_per_hundred']].values,3)\n    \nfig.show(config=config)","1feab3c2":"fig = px.treemap(temp_df_recovered, path=['world','continent','country'], values='total_recovered',\n          color='total_recovered', color_continuous_scale=[\"#ffffff\", \"#2fbf71\"], title='Total Recovered')\n\nfig.update_traces(hovertemplate=None, hoverinfo='label+value+percent root+percent parent')\nfig.update_layout( margin = dict(t=80, l=0, r=0, b=10), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.show(config=config)","6d63f538":"fig = px.treemap(temp_df_recovered, path=['world','continent','country'], values='total_recovered_per_hundred',\n                 color='total_recovered_per_hundred', title='Total Recovered Per 100 Population',\n                 color_continuous_scale=[\"#ffffff\", \"#2fbf71\"], custom_data=['total_recovered_per_hundred'])\n\nfig.update_traces(hovertemplate='<b>%{label}<\/b><br>%{customdata}')\nfig.update_layout( margin = dict(t=80, l=0, r=0, b=10), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.data[0].customdata[-1] = round(last_valid_value(world_df['total_recovered_per_hundred']),3)\nfig.data[0].customdata[-7:-1] = np.round(cont_total_df[['total_recovered_per_hundred']].values,3)\n    \nfig.show(config=config)","2326a542":"fig = px.sunburst(temp_df_tests, path=['world','continent','country'], values='total_tests',\n          color='total_tests', color_continuous_scale=[\"#ffffff\", \"#faa613\"], title='Total Tests')\n\nfig.update_traces(hovertemplate=None, hoverinfo='label+value+percent root+percent parent')\nfig.update_layout( margin = dict(t=50, l=0, r=0, b=0), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.show(config=config)","1654b331":"fig = px.sunburst(temp_df_tests, path=['world','continent','country'], values='total_tests_per_hundred',\n                 color='total_tests_per_hundred', title='Total Tests Per 100 Population',\n                 color_continuous_scale=[\"#ffffff\", \"#faa613\"], custom_data=['total_tests_per_hundred'])\n\nfig.update_traces(hovertemplate='<b>%{label}<\/b><br>%{customdata}')\nfig.update_layout( margin = dict(t=50, l=0, r=0, b=0), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.data[0].customdata[-1] = round(last_valid_value(world_df['total_tests_per_hundred']),3)\nfig.data[0].customdata[-7:-1] = np.round(cont_total_df[['total_tests_per_hundred']].values,3)\n    \nfig.show(config=config)","de44e6e5":"#Creating and filling values into variables to pass to vaccination sunburst plot\n\ntemp_list = [['People Vaccinated ' + country, 'People Fully Vaccinated ' + country] for country in temp_df_vax.country]\ntemp_list = [x for y in temp_list for x in y]\nids = ['World'] + list(temp_df_vax['continent'].unique()) + list(temp_df_vax['country']) + temp_list\ncountry_end = next(x for x in ids if 'Vaccinated' in x)\ncountry_end_index = ids.index(country_end)\nlabels = ids[0:country_end_index] + ['People Vaccinated', 'People Fully Vaccinated'] * len(ids[7:country_end_index])\nparents = []\nvalues = []\nvalues_per_100 = []\nvalues_percent_world = []\nfor x in ids:\n    if x == 'World':\n        parents.append('')\n        values.append(0)\n        values_per_100.append(last_valid_value(world_df.total_vaccinations_per_hundred))\n    elif x in list(temp_df_vax.continent):\n        parents.append('World')\n        values.append(0)\n        values_per_100.append(cont_total_df[cont_total_df.continent == x].total_vaccinations_per_hundred.values[0])\n    elif x in list(temp_df_vax.country):\n        parents.append(temp_df_vax[temp_df_vax.country == x].continent.values[0])\n        values.append(temp_df_vax[temp_df_vax.country == x].total_vaccinations.values[0])\n        values_per_100.append(temp_df_vax[temp_df_vax.country == x].total_vaccinations_per_hundred.values[0])\n    elif 'Fully' in x:\n        x = x[24:]\n        parents.append(x)\n        values.append(temp_df_vax[temp_df_vax.country == x].people_fully_vaccinated.values[0])\n        values_per_100.append(temp_df_vax[temp_df_vax.country == x].people_fully_vaccinated_per_hundred.values[0])\n    elif 'People Vaccinated' in x:\n        x = x[18:]\n        parents.append(x)\n        values.append(temp_df_vax[temp_df_vax.country == x].people_vaccinated.values[0])\n        values_per_100.append(temp_df_vax[temp_df_vax.country == x].people_vaccinated_per_hundred.values[0])","f4e794d3":"#Creating custom colorscale for vaccination sunburst graphs\n\na = n_colors('rgb(255, 255, 255)','rgb(0,166,251)', 256, colortype='rgb')\nb = []\nfor x in a:\n    b.append(x)\n    b.append(x)\nb.insert(0, 'rgb(128,210,253)')","4846a34b":"#Creating a variable to show values in hoverlabel\n\nvalues2 = values.copy()\nvalues2[0] = last_valid_value(world_df.total_vaccinations)\nvalues2[1:7] = cont_total_df['total_vaccinations'].values","fdbedb6e":"#Calculating relative values from parent nodes to show in hoverlabels\n\npercent_from_world = []\npercent_from_parent = []\n\nfor x in range(len(ids)):\n    if x < 217:\n        percent_from_world.append(round(values2[x]\/values2[0]*100,3))\n    else:\n        percent_from_world.append(np.nan)\n\nfor x in range(len(ids)):\n    if parents[x] == 'Africa':\n        percent_from_parent.append(round(values2[x]\/values2[1]*100,3))\n    elif parents[x] == 'Asia':\n        percent_from_parent.append(round(values2[x]\/values2[2]*100,3))\n    elif parents[x] == 'Europe':\n        percent_from_parent.append(round(values2[x]\/values2[3]*100,3))\n    elif parents[x] == 'North America':\n        percent_from_parent.append(round(values2[x]\/values2[4]*100,3))\n    elif parents[x] == 'Oceania':\n        percent_from_parent.append(round(values2[x]\/values2[5]*100,3))\n    elif parents[x] == 'South America':\n        percent_from_parent.append(round(values2[x]\/values2[6]*100,3))\n    else:\n        percent_from_parent.append(np.nan)","3180ee7a":"#Creating a column in dataframe where each row consists of a string to be displayed as hoverlabel\n\ntemp_df_values2 = pd.DataFrame(values2)\ntemp_df_values2['percent_from_world'] = percent_from_world\ntemp_df_values2['percent_from_parent'] = percent_from_parent\ntemp_df_values2['parent'] = parents\ntemp_df_values2[\"hover_data\"] = temp_df_values2.apply(lambda r: \n    f\"Vaccinations: {human_format(r[0])}<br>% of {r['parent']}: {r['percent_from_parent']}<br>\\\n% of World: {r['percent_from_world']}\",axis=1)\ntemp_df_values2.hover_data.iloc[217:] = temp_df_values2.iloc[217:].hover_data.str.split('<br>').str[0]\ntemp_df_values2.hover_data.iloc[0] = temp_df_values2.hover_data.iloc[0].replace('% of : nan<br>','')\ntemp_df_values2.hover_data.iloc[1:7] = temp_df_values2.hover_data.iloc[1:7].str.replace('% of World: nan<br>','')","b4a9dc61":"fig = px.sunburst(names=labels, parents=parents, values=values, ids=ids, color=values,\n                 color_continuous_scale=b, title='Total Vaccinations')\n\nfig.update_layout(margin = dict(t=50, l=0, r=0, b=0), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))\nfig.update_traces(customdata=temp_df_values2['hover_data'],\n                  hovertemplate='<b>%{label}<\/b><br>%{customdata}')\nfig.show(config=config)","24c242c1":"fig = px.sunburst(names=labels, parents=parents, values=values_per_100, ids=ids, color=values_per_100,\n                 color_continuous_scale=b, title='Total Vaccinations Per 100 Population')\n\nfig.update_traces(customdata=temp_df_vax.total_vaccinations_per_hundred,\n                  hovertemplate='<b>%{label}<\/b><br>%{customdata}')\nfig.update_layout( margin = dict(t=50, l=0, r=0, b=0), coloraxis_colorbar=dict(title=None,thickness=20,\n                                                                               len=1))    \nfig.show(config=config)","3ce914b1":"#Modifying default plotting options for all further graphs\n\npio.templates['my_theme'].layout.xaxis.title = {'standoff': 15}\npio.templates['my_theme'].layout.yaxis.title = {'standoff': 15}\npio.templates['my_theme'].layout.plot_bgcolor = '#f8f9fa'\npio.templates['my_theme'].layout.xaxis.tickformat = ''\npio.templates['my_theme'].layout.xaxis.hoverformat = ''","1bac70c6":"#Creating a dataframe with mean values of each column for each country\n\ndf_avg_value = pd.pivot_table(df, index=['country','continent'], aggfunc='mean').reset_index()","a5fb4cde":"#Function to plot two variables with their linear trendline\n\ndef plot_with_trendline(x, y, trendline=False, log_x=False, log_y=False):\n    if trendline:\n        fig = px.scatter(df_avg_value, x=x, y=y, trendline='ols', log_x=(True if log_x else False),\n                        log_y=(True if log_y else False))\n        fig.data[1]['line']['color'] = '#212529'\n        trendline = fig.data[1]\n        trendline_split = trendline.hovertemplate.split('<br>')\n        trendline.hovertemplate = (trendline_split[0] +\n#         '<br>' + trendline_split[1].replace('_',' ').title() +         #Comment out to add y = mx+c in hoverlabel\n        '<br>' + trendline_split[2])\n    \n    fig = px.scatter(df_avg_value, x=x, y=y, color='continent', custom_data=['country'],\n                     log_x=(True if log_x else False),log_y=(True if log_y else False),\n                     category_orders={'continent':['Africa','Asia','Europe','North America','Oceania',\n                                                   'South America']})\n    x = x.replace('_',' ').title()\n    y = y.replace('_',' ').title()\n    fig.update_xaxes(title=x)\n    fig.update_yaxes(title=y)\n    fig.update_traces(hovertemplate='%{customdata}<br>'+x+': %{x}<br>'+y+': %{y}', marker_size=8)\n    if trendline:\n        fig.add_trace(trendline)\n    fig.update_layout(legend=dict(orientation='h', title=None, borderwidth=0))\n    return fig","f82174df":"#Function to plot more than two variables with linear trendlines for each relation\n\ndef plot_multiple_trendlines(x, y, xy_reverse=False):\n    x_legend = []\n    if xy_reverse:\n        fig = px.scatter(df_avg_value, x=y, y=x, trendline='ols', custom_data=['continent','country'])\n    else:\n        fig = px.scatter(df_avg_value, x=x, y=y, trendline='ols', custom_data=['continent','country'])\n    y = y.replace('_',' ').title()\n    \n    for var in range(len(x)):\n        trendline = fig.data[var*2+1]\n        trendline_split = trendline.hovertemplate.split('<br>')\n        trendline.hovertemplate = (trendline_split[0] +\n#         '<br>' + x[1].replace('_',' ').title() +            #Comment out to add y = mx+c in hoverlabel\n        '<br>' + trendline_split[2])\n        if x[var][:3] == 'gm_':\n            x_element = x[var][3:].replace('_',' ').title()\n        elif x[var][-5:] == 'Index':\n            x_element = \"\".join([(\" \"+i if i.isupper() else i) for i in x[var]]).strip()\n        else:\n            x_element = x[var].replace('_',' ').title()\n        \n        x_legend = x_legend + [x_element] + ['']\n        fig.data[var*2].hovertemplate = ('%{customdata[1]}<br>'+x_element+': %{x}<br>'+y+': %{y}\\\n<extra>%{customdata[0]}<\/extra>') if not xy_reverse else ('%{customdata[1]}<br>'+x_element+': %{y}<br>'+y+': %{x}\\\n<extra>%{customdata[0]}<\/extra>')\n        \n    fig.update_xaxes(title=y) if xy_reverse else fig.update_xaxes(title='Value')\n    fig.update_yaxes(title='Value') if xy_reverse else fig.update_yaxes(title=y)  \n    fig.update_traces(marker_size=8)\n    fig.update_layout(legend=dict(orientation='h', title=None, borderwidth=0))\n    for i, new_name in enumerate(x_legend):\n        fig.data[i].name = new_name\n    return fig","2a08ce63":"fig = plot_with_trendline('median_age', 'total_deaths_per_hundred', True)\nfig.show(config=config)","af05aabd":"fig = plot_multiple_trendlines(['aged_70_older','aged_65_older'], 'total_deaths_per_hundred')\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(Percentages of population)')\nfig.show(config=config)","e4350a5c":"fig = plot_with_trendline('diabetes_prevalence','total_deaths_per_hundred',True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(% of population aged 20 to 79 in 2017)')\nfig.show(config=config)","efe8b6c3":"fig = plot_with_trendline('cardiovasc_death_rate','total_deaths_per_hundred', True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(Annual deaths per 100k people, 2017)')\nfig.show(config=config)","532c43e4":"fig = plot_multiple_trendlines(['male_smokers','female_smokers'], 'total_deaths_per_hundred')\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(Percentages of population)')\nfig.show(config=config)","e698dc5d":"fig = plot_with_trendline('aged_65_older','Protection of elderly people',True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(Percentage of population)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(Protection of Elderly People- 0=No measures, 3=Extensive restrictions for isolation and\\\n hygeine)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","e6d1c06a":"fig = plot_with_trendline('hospital_beds_per_thousand','death_percent', True)\nfig.update_yaxes(title='Case Fatality Percent')\nfig.show(config=config)","f9e82ba1":"fig = plot_with_trendline('hospital_beds_per_thousand','total_recovered_per_hundred', True)\nfig.show(config=config)","c8cb5fbd":"fig = plot_with_trendline('handwashing_facilities','reproduction_rate', True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(Percentage of population with basic handwashing facilities)')\nfig.show(config=config)","fb3ac82f":"#Function to create a correlation table\n\ndef create_corr_table(features1, features2):\n    round_limit = 4\n    features_total = features1 + features2\n    header_vals = ['Feature','Feature2','r','r<sup>2<\/sup>','r (Avg df)','r<sup>2<\/sup> (Avg df)']\n    r = [round(df[x].corr(df[y]),round_limit) for (x,y) in zip(features1,features2)]\n    r2 = [round(x**2,round_limit) for x in r]\n    r_avg = [round(df_avg_value[x].corr(df_avg_value[y]),round_limit) for (x,y) in zip(features1,features2)]\n    r2_avg = [round(x**2,round_limit) for x in r_avg]\n    \n    def fix_name(name):\n        name = \"\".join([(\" \"+i if i.isupper() else i) for i in name]).strip()\n        name = name.replace('_',' ').title().replace('Hundred','100').replace('Thousand','1000')\n        name = name.replace('Cardiovasc','Cardiovascular').replace('Gdp','GDP').replace('Gm ','')\n        return name.replace('Death Percent','Case Fatality Percent').replace('Government','Govt.')\n    \n    def get_color_array(array):\n        return [0 if abs(x)<=0.15 else 1 if abs(x)<=0.3 else 2 if abs(x)<=0.45 else 3 if abs(x)<=0.6 else 4 if \n                abs(x)<=0.75 else 5 for x in array]\n    \n    gen_colors = n_colors('rgb(247, 178, 178)','rgb(244, 40, 40)', 6, colortype='rgb')\n    colors = [['lavender'] * len(features1)] + [['lavender'] * len(features2)]\n    values_world = [[fix_name(x) for x in features1],\n                    [fix_name(x) for x in features2],\n                    r,\n                    r2,\n                    r_avg,\n                    r2_avg]\n    \n    fig = go.Figure(data=[go.Table(columnwidth=[2,2,1,1,1,1],\n    header=dict(values=header_vals,\n                fill_color='paleturquoise',\n                align='center',\n                height=35,\n                font=dict(size=15)),\n    cells=dict(values=values_world,\n               align='left',\n               height=30,\n               font=dict(size=13),\n               fill_color=colors + [list(np.array(gen_colors)[get_color_array(x)]) for x in (r,r2,r_avg,r2_avg)]))\n    ])\n    height_padding = 140\n    for (x,y) in zip(values_world[0],values_world[1]):\n        if len(x) > 28:\n            height_padding += 16.5\n        if len(y) > 25:\n            height_padding += 16.5\n    \n    fig.update_layout(title_text='Correlation Of Features',margin=dict(b=0), height=height_padding+len(features1)*33)\n    fig.show(config=config)","71c40604":"features1 = ['total_deaths_per_hundred']*7 + ['Protection of elderly people','death_percent',\n                                             'total_recovered_per_hundred','reproduction_rate']\n\nfeatures2 = ['median_age','aged_65_older','aged_70_older','diabetes_prevalence','cardiovasc_death_rate','male_smokers',\n            'female_smokers','aged_65_older'] + ['hospital_beds_per_thousand']*2 + ['handwashing_facilities']\n\ncreate_corr_table(features1, features2)","0ce354d9":"fig = plot_with_trendline('stringency_index','reproduction_rate',True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(Value from 0 to 100; 100 = strictest response)')\nfig.show(config=config)","e5ae279e":"fig = plot_with_trendline('stringency_index','percent_pop_affected', True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(Value from 0 to 100; 100 = strictest response)')\nfig.show(config=config)","bd1e63c2":"fig = plot_with_trendline('Public information campaigns','total_vaccinations_per_hundred', True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(0=No campaign, 2=Coordinated campaign across media)')\nfig.show(config=config)","428169fd":"fig = plot_with_trendline('Emergency investment in healthcare','total_tests_per_hundred',True, log_x=True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(in USD)')\nfig.show(config=config)","0330069c":"fig = plot_with_trendline('Investment in vaccines','total_vaccinations_per_hundred', True, log_x=True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(In USD)')\nfig.show(config=config)","7c736970":"fig = plot_with_trendline('Vaccination policy','total_vaccinations_per_hundred', True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(0=No availability, 5=Availability to all groups of population)')\nfig.show(config=config)","126b3503":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[4,18,23]].columns, 'total_tests_per_hundred')\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.255, showarrow=False,\n                   text='(CT- 0=No tracing, 2=Done for all cases<br>\\\nPIC- 0=No campaign, 2=Coordinated campaign across media<br>\\\nTP- 0=No policy, 3=Open public testing to asymptomatic people too)')\nfig.update_layout(margin=dict(b=100))\nfig.show(config=config)","1c4a88bb":"fig = plot_with_trendline('Public information campaigns','reproduction_rate', True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(0=No campaign, 2=Coordinated campaign across media)')\nfig.show(config=config)","cd41cbe7":"fig = plot_with_trendline('Facial Coverings', 'reproduction_rate', True)\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.17, showarrow=False,\n                   text='(0=No policy, 4=Required outside home at all times)')\nfig.show(config=config)","3983d055":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[3,21,22,25]].columns, 'reproduction_rate')\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.30, showarrow=False,\n                   text='(CPT- 0=No measures, 2=Required Closing<br>\\\nSC- 0=No measures, 3=Required closing all levels<br>\\\nSAHR- 0=No measures, 3=Required not leaving house with minimal exceptions<br>\\\nWC- 0=No measures, 3=Required closing all but essential workplaces)')\nfig.update_layout(margin=dict(b=120, t=20))\nfig.show(config=config)","118db891":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[2,19,20]].columns, 'reproduction_rate')\nfig.add_annotation(xref='paper', yref='paper', x=0.5,y=-0.25, showarrow=False,\n                   text='(CPE- 0=No measures, 2=Required Canceling<br>\\\nROG- 0=No restrictions, 4=Restrictions on gatherings of 10 people or less<br>\\\nROIM- 0=No measures, 2=Movement restricted)')\nfig.update_layout(margin=dict(b=100, t=20))\nfig.show(config=config)","fa730e4f":"features1 = ['stringency_index']*2 + ['Public information campaigns','Emergency investment in healthcare',\n                                     'Investment in vaccines','Vaccination policy','Contact tracing',\n                                      'Public information campaigns','Testing policy','Public information campaigns',\n                                     'Facial Coverings','Close public transport','School closing',\n                                      'Stay at home requirements','Workplace closing','Cancel public events',\n                                      'Restrictions on gatherings','Restrictions on internal movement']\n\nfeatures2 = ['reproduction_rate','percent_pop_affected','total_vaccinations_per_hundred','total_tests_per_hundred'] +\\\n             ['total_vaccinations_per_hundred']*2 + ['total_tests_per_hundred']*3 + ['reproduction_rate']*9\n\ncreate_corr_table(features1, features2)","0ce145af":"fig = plot_with_trendline('life_expectancy','death_percent', True)\nfig.update_yaxes(title='Case Fatality Percent')\nfig.show(config=config)","bac262a4":"fig = plot_with_trendline('life_expectancy','recovered_percent', True)\nfig.show(config=config)","1ef7c020":"fig = plot_with_trendline('life_expectancy','handwashing_facilities', True)\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.18, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.22, showarrow=False,\n                  text='(Handwashing facilities- Percentage of population with basic handwashing facilities)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","ddaf83c2":"features1 = ['life_expectancy']*3\n\nfeatures2 = ['death_percent','recovered_percent','handwashing_facilities']\n\ncreate_corr_table(features1, features2)","1b7f7a81":"fig = plot_with_trendline('population_density', 'reproduction_rate', True, log_x=True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(sq. km)')\nfig.show(config=config)","def1403f":"fig = plot_with_trendline('population_density', 'percent_pop_affected', True, log_x=True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(sq. km)')\nfig.show(config=config)","e41d9ecd":"fig = plot_with_trendline('population_density','stringency_index', True, log_x=True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(sq. km)')\nfig.show(config=config)","1ef81217":"features1 = ['population_density']*3\n\nfeatures2 = ['reproduction_rate','percent_pop_affected','stringency_index']\n\ncreate_corr_table(features1, features2)","63db7484":"fig = plot_with_trendline('gdp_per_capita','hospital_beds_per_thousand', True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.show(config=config)","d771a343":"fig = plot_with_trendline('gdp_per_capita','positive_rate', True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.show(config=config)","f06b7664":"fig = plot_with_trendline('gdp_per_capita','Contact tracing', True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.25, showarrow=False,\n                  text='(CT- 0=No contact tracing, 2=Done for all cases)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","9c2b9528":"fig = plot_with_trendline('gdp_per_capita','tests_per_case', True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.show(config=config)","b9f9235f":"fig = plot_with_trendline('gdp_per_capita','total_tests_per_hundred', True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.show(config=config)","cd3fe273":"fig = plot_with_trendline('gdp_per_capita','total_vaccinations_per_hundred', True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.show(config=config)","860a9603":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[5,8,12]].columns, 'gdp_per_capita', True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.show(config=config)","339fe6f1":"fig = plot_with_trendline('gdp_per_capita','Emergency investment in healthcare',True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.update_yaxes(title_text='Emergency Investment In Healthcare (USD)')\nfig.show(config=config)","1903a65a":"fig = plot_with_trendline('gdp_per_capita','Investment in vaccines',True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.update_yaxes(title_text='Investment In Vaccines (USD)')\nfig.show(config=config)","9ad884a0":"fig = plot_with_trendline('gdp_per_capita','Fiscal measures',True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.update_yaxes(title_text='Fiscal Measures (USD)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(Announced economic stimulus spending)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","cfd7f63a":"fig = plot_with_trendline('gdp_per_capita','Income support',True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(Income Support (for households)- 0=No income support, 2=Replacing 50% lost salary)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","a15c675a":"fig = plot_with_trendline('gdp_per_capita','Debt\/contract relief',True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(D\/C Relief (for households)- 0=No relief, 2=Broad debt\/contract relief)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","388c2c9e":"fig = plot_with_trendline('gdp_per_capita','International support',True, log_y=True)\nfig.add_annotation(xref='paper', yref='paper',x=0.5, y=-0.17, showarrow=False,\n                  text='(2011 International$)')\nfig.update_yaxes(title_text='International Support (USD)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(International Support means COVID-19 related aid to other countries)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","a7815582":"features1 = ['gdp_per_capita']*15\n\nfeatures2 = ['hospital_beds_per_thousand','positive_rate','Contact tracing','tests_per_case','total_tests_per_hundred',\n            'total_vaccinations_per_hundred','ContainmentHealthIndex','EconomicSupportIndex','GovernmentResponseIndex',\n             'Emergency investment in healthcare','Investment in vaccines','Fiscal measures','Income support',\n             'Debt\/contract relief','International support']\n\ncreate_corr_table(features1, features2)","44322c0f":"fig = plot_with_trendline('literacy_rate','reproduction_rate', True)\nfig.show(config=config)","a59509db":"fig = plot_with_trendline('literacy_rate','total_cases_per_hundred', True)\nfig.show(config=config)","c1ab1761":"fig = plot_with_trendline('literacy_rate','death_percent', True)\nfig.update_yaxes(title='Case Fatality Percent')\nfig.show(config=config)","b28c4f5b":"fig = plot_with_trendline('literacy_rate','total_tests_per_hundred', True)\nfig.show(config=config)","5400868a":"fig = plot_with_trendline('literacy_rate','total_vaccinations_per_hundred', True)\nfig.show(config=config)","16ccea0e":"fig = plot_with_trendline('literacy_rate','handwashing_facilities', True)\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(Handwashing facilities- Percentage of population with basic handwashing facilities)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","fa792097":"fig = plot_with_trendline('literacy_rate','hospital_beds_per_thousand', True)\nfig.show(config=config)","b5fa4145":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[5,8,12]].columns, 'literacy_rate', True)\nfig.show(config=config)","12314a84":"fig = plot_with_trendline('literacy_rate','stringency_index', True)\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(Stringency Index- Value from 0 to 100; 100 = strictest response)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","67ba8bb5":"features1 = ['literacy_rate']*11\n\nfeatures2 = ['reproduction_rate','total_cases_per_hundred','death_percent','total_tests_per_hundred',\n             'total_vaccinations_per_hundred','handwashing_facilities','hospital_beds_per_thousand',\n             'ContainmentHealthIndex','EconomicSupportIndex','GovernmentResponseIndex','stringency_index']\n\ncreate_corr_table(features1, features2)","71b13f73":"fig = plot_with_trendline('Democracy index','reproduction_rate', True)\nfig.show(config=config)","3a558079":"fig = plot_with_trendline('Democracy index','total_cases_per_hundred', True)\nfig.show(config=config)","00e66d70":"fig = plot_with_trendline('Democracy index','death_percent', True)\nfig.show(config=config)","5f8b780a":"fig = plot_with_trendline('Democracy index','recovered_percent', True)\nfig.show(config=config)","d1c41bca":"fig = plot_with_trendline('Democracy index','total_tests_per_hundred', True)\nfig.show(config=config)","b098b887":"fig = plot_with_trendline('Democracy index','total_vaccinations_per_hundred', True)\nfig.show(config=config)","08c7e4dc":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[2,3,20]].columns, 'Democracy index', True)\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(CPE- 0=No measures, 2=Require cancelling)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.31, showarrow=False,\n                  text='(CPT- 0=No measures, 2=Require closing for most citizens)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.36, showarrow=False,\n                  text='(ROIM- 0= No measures, 2= Restrictions in place)')\nfig.update_layout(margin=dict(t=20,b=140))\nfig.show(config=config)","3d7d77c3":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[21,22,25]].columns, 'Democracy index', True)\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='SC- 0=No measures, 3=Require closing all levels)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.31, showarrow=False,\n                  text='(SAHR- 0=No measures, 3=Require not leaving house with minimal exceptions)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.36, showarrow=False,\n                  text='(WC- 0=No measures, 3=Require closing except essential services)')\nfig.update_layout(margin=dict(t=20,b=140))\nfig.show(config=config)","34b0ff9f":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[10,15,19]].columns, 'Democracy index', True)\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(FC- 0=No policy, 4=Required at all times)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.31, showarrow=False,\n                  text='(ITC- 0= No resctrictions, 4= Total border closure)')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.36, showarrow=False,\n                  text='(ROG- 0= No restrictions, 4= Restrictions on gatherings of 10 people or less)')\nfig.update_layout(margin=dict(t=20,b=140))\nfig.show(config=config)","97de5445":"fig = plot_with_trendline('Democracy index','stringency_index', True)\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(Stringency Index- Value from 0 to 100; 100 = strictest response)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","b40d7ef7":"features1 = ['Democracy index']*16\n\nfeatures2 = ['reproduction_rate','total_cases_per_hundred','death_percent','recovered_percent',\n             'total_tests_per_hundred','total_vaccinations_per_hundred','Cancel public events',\n             'Close public transport','Restrictions on internal movement','School closing',\n             'Stay at home requirements','Workplace closing','Facial Coverings','International travel controls',\n             'Restrictions on gatherings','stringency_index']\n\ncreate_corr_table(features1, features2)","d1383d35":"fig = plot_with_trendline('human_development_index','total_tests_per_hundred', True)\nfig.show(config=config)","02abd4cc":"fig = plot_with_trendline('human_development_index','total_vaccinations_per_hundred', True)\nfig.show(config=config)","9d5a0203":"fig = plot_multiple_trendlines(df_avg_value.iloc[:,[5,8,12]].columns, 'human_development_index', True)\nfig.show(config=config)","1051b058":"fig = plot_with_trendline('human_development_index','stringency_index', True)\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.21, showarrow=False,\n                  text='For y-axis:')\nfig.add_annotation(xref='paper', yref='paper',x=0, y=-0.26, showarrow=False,\n                  text='(Stringency Index- Value from 0 to 100; 100 = strictest response)')\nfig.update_layout(margin=dict(t=20,b=100))\nfig.show(config=config)","7645c5cd":"features1 = ['human_development_index']*6\n\nfeatures2 = ['total_tests_per_hundred','total_vaccinations_per_hundred','ContainmentHealthIndex',\n             'EconomicSupportIndex','GovernmentResponseIndex','stringency_index']\n\ncreate_corr_table(features1, features2)","5089939b":"fig = plot_multiple_trendlines(df_avg_value.columns[36:42], 'total_deaths_per_hundred')\nfig.show(config=config)","45f8720d":"fig = plot_multiple_trendlines(df_avg_value.columns[36:42], 'Democracy index')\nfig.show(config=config)","36709eb3":"fig = plot_multiple_trendlines(df_avg_value.columns[36:42], 'stringency_index')\nfig.show(config=config)","0fab18d5":"fig = plot_multiple_trendlines(df_avg_value.columns[36:42], 'literacy_rate')\nfig.show(config=config)","ad83f383":"fig = plot_multiple_trendlines(df_avg_value.columns[36:42], 'GovernmentResponseIndex')\nfig.update_yaxes(title='Government Response Index')\nfig.show(config=config)","11072ae8":"fig = plot_multiple_trendlines(df_avg_value.columns[36:42], 'human_development_index')\nfig.show(config=config)","1240f0c3":"features1 = ['gm_grocery_and_pharmacy','gm_parks', 'gm_residential','gm_retail_and_recreation','gm_transit_stations',\n             'gm_workplaces']*6\n\nfeatures2 = ['total_deaths_per_hundred']*6 + ['Democracy index']*6 + ['stringency_index']*6 + ['literacy_rate']*6 +\\\n['GovernmentResponseIndex']*6 + ['human_development_index']*6\n\ncreate_corr_table(features1, features2)","07d27e0d":"fig = px.scatter(df.groupby('country').max('reproduction_rate'), y='reproduction_rate',\n           title='Highest Point of R<sub>0<\/sub> Per Country')\n\nfig.update_traces(hovertemplate='<b>%{x}<\/b><br>R<sub>0<\/sub>: %{y}', marker_color='#db2b39')\nfig.update_xaxes(title_text='')\nfig.update_yaxes(title_text='')\nfig.update_layout(margin=dict(l=30,r=10,t=70,b=0))\nfig.show(config=config)","d082b2b9":"#Reordering dataframe to obtain correct order of date indices for animation frames\n\nidx = df_25d[df_25d['country']=='United States'].index\ntemp_df = df_25d[df_25d['country']=='United States']\ndf_25d.drop(idx, inplace=True)\ndf_25d = pd.concat([temp_df, df_25d])\n\nmap_dates = list(temp_df.date.sort_values().dt.strftime('%d %b %Y')) * 22","5b918a87":"fig = px.choropleth(df_25d, locations='iso_code', color='total_cases', animation_frame=df_25d.date.astype(str),\n                        projection ='equirectangular', title='Total Cases',\n                    color_continuous_scale=['#FCEEEF','#db2b39',\"#7A151D\"],\n                   range_color=(0,np.max(df_25d.total_cases)), custom_data=[df_25d['country'],df_25d['total_cases']])\n\nfig.update_layout(geo_showframe=False, margin=dict(r=0,l=0,t=50,b=0),height=700,\n                  coloraxis_colorbar=dict(title=None,thickness=20,len=0.6))\nfig.update_traces(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]}')\nfig.add_annotation(x=0.5,y=1,text=map_dates[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]:,.4s}')\n    frame.layout.update(annotations=[dict(x=0.5,y=1,text=map_dates[idx],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","100e2053":"fig = px.choropleth(df_25d, locations='iso_code', color='total_deaths', animation_frame=df_25d.date.astype(str),\n                        projection ='equirectangular', title='Total Deaths',\n                    color_continuous_scale=['#DADAE7',\"#3d405b\",'#202031'],\n                   range_color=(0,np.max(df_25d.total_deaths)), custom_data=[df_25d['country'],df_25d['total_deaths']])\n\nfig.update_layout(geo_showframe=False, margin=dict(r=0,l=0,t=50,b=0),height=700,\n                  coloraxis_colorbar=dict(title=None,thickness=20,len=0.6))\nfig.update_traces(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]}')\nfig.add_annotation(x=0.5,y=1,text=map_dates[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]:,.4s}')\n    frame.layout.update(annotations=[dict(x=0.5,y=1,text=map_dates[idx],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","28a71b13":"#Filtering data to get desired dates to plot recoveries\n\ndf_25d_rec = df_25d.query('date < \"08-05-2021\"')\nmap_dates_rec = list(temp_df.query('date < \"08-05-2021\"').date.sort_values().dt.strftime('%d %b %Y')) * 9","ff42d020":"fig = px.choropleth(df_25d_rec, locations='iso_code', color='total_recovered',\n                    animation_frame=df_25d_rec.date.astype(str), projection ='equirectangular',title='Total Recovered',\n                    color_continuous_scale=['#BDEFD3',\"#2fbf71\",'#186338'],\n                   range_color=(0,np.max(df_25d_rec.total_recovered)),\n                    custom_data=[df_25d_rec['country'],df_25d_rec['total_recovered']])\n\nfig.update_layout(geo_showframe=False, margin=dict(r=0,l=0,t=50,b=0),height=700,\n                  coloraxis_colorbar=dict(title=None,thickness=20,len=0.6))\nfig.update_traces(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]}')\nfig.add_annotation(x=0.5,y=1,text=map_dates_rec[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]:,.4s}')\n    frame.layout.update(annotations=[dict(x=0.5,y=1,text=map_dates_rec[idx],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","55466474":"fig = px.choropleth(df_25d, locations='iso_code', color='total_tests', animation_frame=df_25d.date.astype(str),\n                        projection ='equirectangular', title='Total Tests',\n                    color_continuous_scale=['#FCD99C',\"#faa613\",'#9D6607'],\n                   range_color=(0,np.max(df_25d.total_tests)), custom_data=[df_25d['country'],df_25d['total_tests']])\n\nfig.update_layout(geo_showframe=False, margin=dict(r=0,l=0,t=50,b=0),height=700,\n                  coloraxis_colorbar=dict(title=None,thickness=20,len=0.6))\nfig.update_traces(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]}')\nfig.add_annotation(x=0.5,y=1,text=map_dates[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]:,.4s}')\n    frame.layout.update(annotations=[dict(x=0.5,y=1,text=map_dates[idx],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","8bb83449":"#Filtering data to get desired dates to plot vaccinations\n\ndf_25d_vax = df_25d.query('date > \"27-10-2020\"')\nmap_dates_vax = list(temp_df.query('date > \"27-10-2020\"').date.sort_values().dt.strftime('%d %b %Y')) * 9","bfe79117":"fig = px.choropleth(df_25d_vax, locations='iso_code', color='total_vaccinations',\n                    animation_frame=df_25d_vax.date.astype(str),\n                    projection ='equirectangular', title='Total Vaccinations',\n                    color_continuous_scale=['#D6F1FF',\"#00a6fb\",'#00527A'],\n                    range_color=(0,np.max(df_25d.total_vaccinations)),\n                    custom_data=[df_25d_vax['country'],df_25d_vax['total_vaccinations']])\n\nfig.update_layout(geo_showframe=False, margin=dict(r=0,l=0,t=50,b=0),height=700,\n                  coloraxis_colorbar=dict(title=None,thickness=20,len=0.6))\nfig.update_traces(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]}')\nfig.add_annotation(x=0.5,y=1,text=map_dates_vax[0],showarrow=False, xref='paper',yref='paper',\n                  font=dict(size=16))\nfor idx,frame in enumerate(fig.frames):\n    frame.data[0].update(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]:,.4s}')\n    frame.layout.update(annotations=[dict(x=0.5,y=1,text=map_dates_vax[idx],\n                                           showarrow=False, xref='paper',yref='paper',font=dict(size=16))])\nfig.show(config=config)","c1a0f61b":"#Create dummy categories to group and plot as discrete colours\n\ndef create_dummy_feature(df, col):\n    if col == 'total_deaths_per_hundred':\n        max_value = round(max(df[col]),1)\n        df['dummy'] = pd.cut(df[col], np.linspace(0,max_value,6))\n    else:\n        max_value = np.ceil(max(df[col]))\n        df['dummy'] = pd.cut(df[col], np.linspace(0,max_value,6, dtype=int))\n    df['dummy'] = df.dummy.astype(str).replace(({',':' to'}), regex=True)","95c9c2b0":"#Checking for token\nif mapbox_personal_token:\n    px.set_mapbox_access_token(mapbox_personal_token)\n    \n    \n#Function to create map with specifications\ndef create_mapbox(df, col):\n    create_dummy_feature(df, col)\n    fig = px.scatter_mapbox(df, lat='latitude', lon='longitude', size=col, size_max=20, zoom=1,\n                            mapbox_style=('dark' if mapbox_personal_token else 'carto-darkmatter'),\n                            title=col.replace('_',' ').title()+' Population', opacity=0.5,color='dummy',\n                            custom_data=[df['country'],df[col]],\n                            color_discrete_sequence=[\"#ff2c55\",\"#34e4ea\",\"#29bf12\",\"#e3ff47\",\"#c96bdb\"])\n#                   animation_frame=df.date.astype(str))\n    fig.update_layout(margin=dict(l=0,r=0,t=80,b=0), legend=dict(title=None, orientation='h',\n                                                                borderwidth=0))\n    fig.update_traces(hovertemplate='<b>%{customdata[0]}<\/b><br>%{customdata[1]:,}<extra><\/extra>')\n    fig.show(config=config)","a627574b":"create_mapbox(temp_df_cases, 'total_cases_per_hundred')","118008ce":"create_mapbox(temp_df_deaths, 'total_deaths_per_hundred')","982c532f":"create_mapbox(temp_df_recovered, 'total_recovered_per_hundred')","1b8b8e31":"create_mapbox(temp_df_tests, 'total_tests_per_hundred')","36cb29a1":"create_mapbox(temp_df_vax, 'total_vaccinations_per_hundred')","9c709bbb":"#Reverting current theme to previous state\n\nset_theme()","c8fd3421":"#Function to plot Top 10 countries of any feature\n\ndef plot_top10(df, feature):\n    top10_countries = df.groupby('country').last()[feature].sort_values(ascending=False)[:10].index\n    df = df.groupby(['country','date']).last().loc[top10_countries].reset_index()\n    fig = px.line(df, x='date', y=feature, color='country', title='Top 10 '+feature.replace('_',' ').title(),\n                 color_discrete_sequence= [\"#db2b39\",\"#3d405b\",\"#2fbf71\",\"#faa613\",\"#00a6fb\",\"#c04cfd\",\"#f3de2c\",\n                                           \"#735f3d\",\"#6a788a\",\"#054a29\"])\n    fig.update_layout(legend=dict(title=None))\n    fig.update_traces(hovertemplate='%{x}<br><b>%{y}<\/b>')\n    fig.show(config=config)","54e4061f":"plot_top10(df, 'total_cases')","cae825e3":"plot_top10(df, 'total_deaths')","8d8828d4":"plot_top10(df.query('date < \"08-05-2021\"'), 'total_recovered')","ac56baf4":"plot_top10(df, 'total_tests')","823a5acb":"plot_top10(df.query('date > \"12-1-2020\"'), 'total_vaccinations')","b6670243":"#Picking 6 countries to plot with\n\ncountries_to_plot = ['Brazil','India','United States','Mauritius','New Zealand','Taiwan']\ndf_countries6 = pd.concat(df[df['country'] == country] for country in countries_to_plot)","7e2ffd30":"#Preparing dataframe for parallel categories plot\n\ndf_oxbsg= df_countries6[['country','School closing','Workplace closing','Cancel public events',\n                         'Restrictions on gatherings','Close public transport','Stay at home requirements',\n                         'Restrictions on internal movement','International travel controls',\n                         'Public information campaigns']]\n\ndf_oxbsg['country2'] = df_oxbsg['country']\ndf_oxbsg.replace({'country2':{'Brazil':1,'India':2,'United States':3,'Mauritius':4,'New Zealand':5,'Taiwan':6}},\n                 inplace=True)","cecce849":"#Creating dimensions for parallel categories plot\n\ndim = []\ncountries6_colorscale = [\"#ff595e\",\"#ffca3a\",\"#8ac926\",\"#1982c4\",\"#6a4c93\",\"#615055\"]\n\nfor idx,var in enumerate(['country','Stay at home requirements','School closing','Workplace closing',\n                          'Close public transport','Cancel public events','Restrictions on gatherings',\n                          'Restrictions on internal movement','International travel controls',\n                          'Public information campaigns']):\n    dim.append(go.parcats.Dimension(values=df_oxbsg[var], label=var.title(), categoryorder='category descending'))","ea2dfbe5":"dim[0].categoryorder = 'array'\ndim[0].categoryarray = ['Brazil','India','United States','Mauritius','New Zealand','Taiwan']\n\nfig = go.Figure(data = [go.Parcats(dimensions=[x for x in dim],\n        line={'color': df_oxbsg.country2,\n              'colorscale':countries6_colorscale})])\n\nfig.update_traces(hovertemplate='%{category}', labelfont_size=8,)\nfig.update_layout(margin=dict(t=80,b=10,r=30,l=40), title='Government Measures')\nfig.show(config=config)","cfe9107f":"#Preparing dimensions for parallel coordinates plot\n\ndf_countries6 = pd.concat(df[df['country'] == country] for country in countries_to_plot)\ntemp_df = pd.DataFrame({'country':df_countries6['country'].unique()})\ntemp_df['dummy'] = temp_df.index\ndf_countries6 = pd.merge(df_countries6, temp_df, on = 'country', how='left')\n\ndimensions = list([dict(range=[0,df_countries6['dummy'].max()],\n                       tickvals = temp_df['dummy'], ticktext = temp_df['country'],\n                       label='Country', values=df_countries6['dummy']),\n                  dict(range=[df_countries6['gm_retail_and_recreation'].min(),df_countries6['gm_retail_and_recreation'].max()],\n                        label='Retail & Recreation', values=df_countries6['gm_retail_and_recreation']),\n                  dict(range=[df_countries6['gm_grocery_and_pharmacy'].min(),df_countries6['gm_grocery_and_pharmacy'].max()],\n                       label='Grocery & Pharmacy', values=df_countries6['gm_grocery_and_pharmacy']),\n                  dict(range=[df_countries6['gm_parks'].min(),df_countries6['gm_parks'].max()],\n                       label='Parks', values=df_countries6['gm_parks']),\n                  dict(range=[df_countries6['gm_transit_stations'].min(),df_countries6['gm_transit_stations'].max()],\n                       label='Transit Stations', values=df_countries6['gm_transit_stations']),\n                  dict(range=[df_countries6['gm_workplaces'].min(),df_countries6['gm_workplaces'].max()],\n                       label='Workplaces', values=df_countries6['gm_workplaces']),\n                  dict(range=[df_countries6['gm_residential'].min(),df_countries6['gm_residential'].max()],\n                       label='Residential', values=df_countries6['gm_residential']),\n                  dict(range=[df_countries6['reproduction_rate'].min(),df_countries6['reproduction_rate'].max()],\n                       label='Reproduction Rate', values=df_countries6['reproduction_rate'])\n                  ])","9d0765c8":"countries6_colorscale = [\"#ff595e\",\"#ffca3a\",\"#8ac926\",\"#1982c4\",\"#6a4c93\",\"#003844\"]\nfig = go.Figure(data=go.Parcoords(line = dict(color = df_countries6['dummy'],\n                                              colorscale = countries6_colorscale), dimensions=dimensions))\n\nfig.update_layout(title='Mobility Trends')\nfig.show(config=config)","853791a6":"#Modifying default plotting options for further graphs\n\npio.templates['my_theme'].layout.xaxis.title = {'standoff': 15}\npio.templates['my_theme'].layout.yaxis.title = {'standoff': 15}\npio.templates['my_theme'].layout.xaxis.tickformat = ''\npio.templates['my_theme'].layout.xaxis.hoverformat = ''","21af5686":"#Creating and displaying Benford's 1st digit's distribution\n\nbenford_dist1 = [np.log10(1+1\/x)*100 for x in np.arange(1,10)]\nfig = px.bar(x=np.arange(1,10), y=benford_dist1, title='Benford\\'s 1st Digit Distribution')\nfig.update_layout(xaxis_title='Digits', yaxis_title='Frequency')\nfig.update_traces(hovertemplate='Digit:<b>%{x}<\/b><br>Frequency:<b>%{y}<\/b>')\nfig.show(config=config)","d533874a":"#Creating and displaying Benford's 2nd digit's distribution\n\nbenford_dist2 = [sum([np.log10(1+1\/x)*100 for x in range(int('1'+str(y)),100,10)]) for y in np.arange(0,10)]\nfig = px.bar(x=np.arange(0,10), y=benford_dist2, title='Benford\\'s 2nd Digit Distribution')\nfig.update_layout(xaxis_title='Digits', yaxis_title='Frequency', xaxis_nticks=20)\nfig.update_traces(hovertemplate='Digit:<b>%{x}<\/b><br>Frequency:<b>%{y}<\/b>')\nfig.show(config=config)","66533a03":"#Creating and displaying Benford's 3rd digit's distribution\n\nbenford_dist3 = [sum([np.log10(1+1\/x)*100 for x in range(int('10'+str(y)),1000,10)]) for y in np.arange(0,10)]\nfig = px.bar(x=np.arange(0,10), y=benford_dist3, title='Benford\\'s 3rd Digit Distribution')\nfig.update_layout(xaxis_title='Digits', yaxis_title='Frequency', xaxis_nticks=20)\nfig.update_traces(hovertemplate='Digit:<b>%{x}<\/b><br>Frequency:<b>%{y}<\/b>')\nfig.show(config=config)","3dc918e4":"#Creating and displaying Benford's 4th digit's distribution\n\nbenford_dist4 = [sum([np.log10(1+1\/x)*100 for x in range(int('100'+str(y)),10000,10)]) for y in np.arange(0,10)]\nfig = px.bar(x=np.arange(0,10), y=benford_dist4, title='Benford\\'s 4th Digit Distribution')\nfig.update_layout(xaxis_title='Digits', yaxis_title='Frequency', xaxis_nticks=20)\nfig.update_traces(hovertemplate='Digit:<b>%{x}<\/b><br>Frequency:<b>%{y}<\/b>')\nfig.show(config=config)","4d2c339c":"#Creating and displaying Benford's 5th digit's distribution\n\nbenford_dist5 = [sum([np.log10(1+1\/x)*100 for x in range(int('1000'+str(y)),100000,10)]) for y in np.arange(0,10)]\nfig = px.bar(x=np.arange(0,10), y=benford_dist5, title='Benford\\'s 5th Digit Distribution')\nfig.update_layout(xaxis_title='Digits', yaxis_title='Frequency', xaxis_nticks=20)\nfig.update_traces(hovertemplate='Digit:<b>%{x}<\/b><br>Frequency:<b>%{y}<\/b>')\nfig.show(config=config)","0391b56a":"#Creating and displaying Benford's First 2 digits distribution\n\nbenford_dist_first_two = [np.log10(1+1\/x)*100 for x in np.arange(10,100)]\nfig = px.bar(x=np.arange(10,100), y=benford_dist_first_two, title='Benford\\'s First 2 Digits Distribution')\nfig.update_layout(xaxis_title='Digits', yaxis_title='Frequency', xaxis_nticks=25)\nfig.update_traces(hovertemplate='Digit:<b>%{x}<\/b><br>Frequency:<b>%{y}<\/b>')\nfig.show(config=config)","9fddeea6":"#Creating and displaying Benford's First 3 digits distribution\n\nbenford_dist_first_three = [np.log10(1+1\/x)*100 for x in np.arange(100,1000)]\nfig = px.bar(x=np.arange(100,1000), y=benford_dist_first_three, title='Benford\\'s First 3 Digits Distribution')\nfig.update_layout(xaxis_title='Digits', yaxis_title='Frequency', xaxis_nticks=25)\nfig.update_traces(hovertemplate='Digit:<b>%{x}<\/b><br>Frequency:<b>%{y}<\/b>')\nfig.show(config=config)","44c5e418":"#Creating and displaying Benford's Last 2 digits distribution\n\nbenford_dist_last_two = [1.0] * 100\nfig = px.bar(x=np.arange(0,100), y=benford_dist_last_two, title='Benford\\'s Last 2 Digits Distribution')\nfig.update_layout(xaxis_title='Digits', yaxis_title='Frequency', xaxis_nticks=25)\nfig.update_traces(hovertemplate='Digit:<b>%{x}<\/b><br>Frequency:<b>%{y}<\/b>')\nfig.show(config=config)","803dc2ce":"#Custom class to compute various digit frequencies of any series, along with its goodness of fit chi-square statistic \n#and p-value\n\nclass BenfordCompute(object):\n    def __init__(self, series):\n        self.series = series\n    \n    #Method to calculate frequency of single digits, 1st to 5th place\n    def freq_single(self, order='first'):\n        observed_freq = [0,0,0,0,0,0,0,0,0,0]\n        for x in self.series.dropna().astype(int).values:\n            x = abs(x)\n            if order == 'first':\n                digit = int(str(x)[0])\n            try:\n                check_variable = True\n                if order == 'second':\n                    digit = int(str(x)[1])\n                elif order == 'third':\n                    digit = int(str(x)[2])\n                elif order == 'fourth':\n                    digit = int(str(x)[3])\n                elif order == 'fifth':\n                    digit = int(str(x)[4])\n            except IndexError:\n                check_variable = False\n                pass\n            if check_variable:\n                observed_freq[digit] += 1\n        if order == 'first':\n            del observed_freq[0]\n        observed_freq = np.array(observed_freq)\n        return observed_freq\/observed_freq.sum()*100\n    \n    #Method to calculate frequency of first two digits\n    def freq_first_two(self):\n        observed_freq = [0]*90\n        for x in self.series.dropna().astype(int).values:\n            x = abs(x)\n            if x < 10:\n                continue\n            firsttwo_digits = int(str(x)[:2])\n            observed_freq[firsttwo_digits-10] += 1\n        observed_freq = np.array(observed_freq)\n        return observed_freq\/observed_freq.sum()*100\n    \n    #Method to calculate frequency of last two digits\n    def freq_last_two(self):\n        observed_freq = [0]*100\n        for x in self.series.dropna().astype(int).values:\n            x = abs(x)\n            if x < 10:\n                continue\n            lasttwo_digits = int(str(x)[-2:])\n            observed_freq[lasttwo_digits] += 1\n        observed_freq = np.array(observed_freq)\n        return observed_freq\/observed_freq.sum()*100\n    \n    #Method to calculate frequency of first three digits\n    def freq_first_three(self):\n        observed_freq = [0]*900\n        for x in self.series.dropna().astype(int).values:\n            x = abs(x)\n            if x < 100:\n                continue\n            firstthree_digits = int(str(x)[:3])\n            observed_freq[firstthree_digits-100] += 1\n        observed_freq = np.array(observed_freq)\n        return observed_freq\/observed_freq.sum()*100\n    \n    #Method to calculate chi-square statistic and p-value for any digit frequencies\n    def chi_square(self, order='first'):\n        if '_' not in order:\n            if order == 'first':\n                expected_dist = benford_dist1\n            elif order == 'second':\n                expected_dist = benford_dist2\n            elif order == 'third':\n                expected_dist = benford_dist3\n            elif order == 'fourth':\n                expected_dist = benford_dist4\n            elif order == 'fifth':\n                expected_dist = benford_dist5\n            return chisquare(self.freq_single(order=order), expected_dist)\n        elif order == 'first_two':\n            expected_dist = benford_dist_first_two\n            return chisquare(self.freq_first_two(), expected_dist)\n        elif order == 'last_two':\n            expected_dist = benford_dist_last_two\n            return chisquare(self.freq_last_two(), expected_dist)\n        elif order == 'first_three':\n            expected_dist = benford_dist_first_three\n            return chisquare(self.freq_first_three(), expected_dist)\n        \n    def chi_square_pretty(self, order='first'):\n        chi_pretty = self.chi_square(order=order)\n        print('For '+order.title()+ ' Digit(s):\\n')\n        print('Chi-Square Statistic: ',chi_pretty[0])\n        print('P-value: ',chi_pretty[1])\n        \n    #Method to calculate chi-square statistic and p-value for all digits together, presented in a table\n    def chi_square_all(self, non_table=None):\n        a = []\n        to_tabulate = []\n        a.append(self.chi_square(order='first'))\n        a.append(self.chi_square(order='second'))\n        a.append(self.chi_square(order='third'))\n        a.append(self.chi_square(order='fourth'))\n        a.append(self.chi_square(order='fifth'))\n        a.append(self.chi_square(order='first_two'))\n        a.append(self.chi_square(order='last_two'))\n        a.append(self.chi_square(order='first_three'))\n        for x,y,z in zip(['First Digit','Second Digit','Third Digit','Fourth Digit','Fifth Digit','First Two Digits',\n                         'Last Two Digits','First Three Digits'],[x[0] for x in a],[x[1] for x in a]):\n            to_tabulate.append([x,y,z])\n        if non_table:\n            return to_tabulate\n        print(tabulate(to_tabulate,headers=['Digits','Chi-Square Statistic','p-value'], tablefmt='github'))","02a0b018":"#Custom child class to plot figures for comparison of frequencies with Benford's distribution\n\nclass BenfordCheck(BenfordCompute):\n    \n    #Plot graph for frequency of single digits, 1st to 5th\n    def fig_single(self, order='first'):\n        start = 0\n        fig = go.Figure()\n        if order == 'first':\n            start = 1\n            expected_dist = benford_dist1\n        elif order == 'second':\n            expected_dist = benford_dist2\n        elif order == 'third':\n            expected_dist = benford_dist3\n        elif order == 'fourth':\n            expected_dist = benford_dist4\n        elif order == 'fifth':\n            expected_dist = benford_dist5\n        pvalue = self.chi_square(order=order)[1]\n        fig.add_bar(x=np.arange(start,10), y=self.freq_single(order=order), legendgroup='one',\n                   hovertemplate='<b>Digit:<\/b> %{x}<br><b>Frequency:<\/b> %{y}<extra><\/extra>')\n        fig.add_scatter(x=np.arange(start,10), y=expected_dist, legendgroup='two',\n                       hovertemplate='<b>Digit:<\/b> %{x}<br><b>Frequency:<\/b> %{y}<extra><\/extra>')\n        fig.update_layout(title_text='<b>'+order.title()+' Digit <\/b>(Observed vs Benford\\'s) Frequencies\\\n<br><sup><span style=\"font-size:14px\">p-value: '+str(pvalue)+'<\/span><\/sup>', legend_orientation='h',\n                          legend_borderwidth=0)\n        custom_legend_name(['Observed','Benford\\'s'], fig_in_func=fig)\n        return fig\n    \n    #Plot graph for frequency of first two digits\n    def fig_first_two(self):\n        fig = go.Figure()\n        pvalue = self.chi_square(order='first_two')[1]\n        fig.add_bar(x=np.arange(10,100), y=self.freq_first_two(), legendgroup='one',\n                   hovertemplate='<b>Digit:<\/b> %{x}<br><b>Frequency:<\/b> %{y}<extra><\/extra>')\n        fig.add_scatter(x=np.arange(10,100), y=benford_dist_first_two, legendgroup='two',\n                       hovertemplate='<b>Digit:<\/b> %{x}<br><b>Frequency:<\/b> %{y}<extra><\/extra>')\n        fig.update_layout(title_text='<b>First Two Digits <\/b>(Observed vs Benford\\'s) Frequencies\\\n<br><sup><span style=\"font-size:14px\">p-value: '+str(pvalue)+'<\/span><\/sup>', legend_orientation='h',\n                          legend_borderwidth=0)\n        custom_legend_name(['Observed','Benford\\'s'], fig_in_func=fig)\n        return fig\n    \n    #Plot graph for frequency of last two digits\n    def fig_last_two(self):\n        fig = go.Figure()\n        pvalue = self.chi_square(order='last_two')[1]\n        fig.add_bar(x=np.arange(0,100), y=self.freq_last_two(), legendgroup='one',\n                   hovertemplate='<b>Digit:<\/b> %{x}<br><b>Frequency:<\/b> %{y}<extra><\/extra>')\n        fig.add_scatter(x=np.arange(0,100), y=benford_dist_last_two, legendgroup='two',\n                       hovertemplate='<b>Digit:<\/b> %{x}<br><b>Frequency:<\/b> %{y}<extra><\/extra>')\n        fig.update_layout(title_text='<b>Last Two Digits <\/b>(Observed vs Benford\\'s) Frequencies\\\n<br><sup><span style=\"font-size:14px\">p-value: '+str(pvalue)+'<\/span><\/sup>', legend_orientation='h',\n                         legend_borderwidth=0)\n        custom_legend_name(['Observed','Benford\\'s'], fig_in_func=fig)\n        return fig\n    \n    #Plot graph for frequency of first three digits\n    def fig_first_three(self):\n        fig = go.Figure()\n        pvalue = self.chi_square(order='first_three')[1]\n        fig.add_bar(x=np.arange(100,1000), y=self.freq_first_three(), legendgroup='one',\n                   hovertemplate='<b>Digit:<\/b> %{x}<br><b>Frequency:<\/b> %{y}<extra><\/extra>')\n        fig.add_scatter(x=np.arange(100,1000), y=benford_dist_first_three, legendgroup='two',\n                       hovertemplate='<b>Digit:<\/b> %{x}<br><b>Frequency:<\/b> %{y}<extra><\/extra>')\n        fig.update_layout(title_text='<b>First Three Digits <\/b>(Observed vs Benford\\'s) Frequencies\\\n<br><sup><span style=\"font-size:14px\">p-value: '+str(pvalue)+'<\/span><\/sup>', legend_orientation='h',\n                          legend_borderwidth=0)\n        custom_legend_name(['Observed','Benford\\'s'], fig_in_func=fig)\n        return fig\n    \n    #Plot a single graph containing all the other plots as subplots\n    def fig_all(self):\n        pfirst = self.chi_square(order='first')[1]\n        psecond = self.chi_square(order='second')[1]\n        pthird = self.chi_square(order='third')[1]\n        pfourth = self.chi_square(order='fourth')[1]\n        pfifth = self.chi_square(order='fifth')[1]\n        pfirsttwo = self.chi_square(order='first_two')[1]\n        plasttwo = self.chi_square(order='last_two')[1]\n        pfirstthree = self.chi_square(order='first_three')[1]\n        fig = make_subplots(rows=2, cols=4, subplot_titles=['First Digit'+'<br><sup>p='+str(pfirst)+'<\/sup>',\n                                                            'Second Digit'+'<br><sup>p='+str(psecond)+'<\/sup>',\n                                                            'Third Digit'+'<br><sup>p='+str(pthird)+'<\/sup>',\n                                                            'Fourth Digit'+'<br><sup>p='+str(pfourth)+'<\/sup>',\n                                                            'Fifth Digit'+'<br><sup>p='+str(pfifth)+'<\/sup>',\n                                                            'First Two Digits'+'<br><sup>p='+str(pfirsttwo)+'<\/sup>',\n                                                            'Last Two Digits'+'<br><sup>p='+str(plasttwo)+'<\/sup>',\n                                                        'First Three Digits'+'<br><sup>p='+str(pfirstthree)+'<\/sup>'])\n        fig_11 = self.fig_single(order='first')\n        fig_12 = self.fig_single(order='second')\n        fig_13 = self.fig_single(order='third')\n        fig_14 = self.fig_single(order='fourth')\n        fig_21 = self.fig_single(order='fifth')\n        fig_22 = self.fig_first_two()\n        fig_23 = self.fig_last_two()\n        fig_24 = self.fig_first_three()\n        fig.append_trace(fig_11.data[0], row=1, col=1)\n        fig.append_trace(fig_11.data[1], row=1, col=1)\n        fig.append_trace(fig_12.data[0], row=1, col=2)\n        fig.append_trace(fig_12.data[1], row=1, col=2)\n        fig.append_trace(fig_13.data[0], row=1, col=3)\n        fig.append_trace(fig_13.data[1], row=1, col=3)\n        fig.append_trace(fig_14.data[0], row=1, col=4)\n        fig.append_trace(fig_14.data[1], row=1, col=4)\n        fig.append_trace(fig_21.data[0], row=2, col=1)\n        fig.append_trace(fig_21.data[1], row=2, col=1)\n        fig.append_trace(fig_22.data[0], row=2, col=2)\n        fig.append_trace(fig_22.data[1], row=2, col=2)\n        fig.append_trace(fig_23.data[0], row=2, col=3)\n        fig.append_trace(fig_23.data[1], row=2, col=3)\n        fig.append_trace(fig_24.data[0], row=2, col=4)\n        fig.append_trace(fig_24.data[1], row=2, col=4)\n        for trace in range(2,16):\n            fig['data'][trace]['showlegend'] = False\n        fig.update_layout(title_text='Benford\\'s Law vs Observed Distribution', height=700, margin=dict(l=0,r=0),\n                         colorway=['#DB2B39','#3D405B'], legend_x=0.9, legend_y=1.25, legend_borderwidth=1)\n        return fig.show(config=config)","567d14a2":"benford_all = BenfordCheck(df.new_cases)","8e740db9":"benford_all.fig_single(order='first')","e9b4b2af":"benford_all.chi_square_pretty(order='first')","849f54d0":"benford_all.fig_single(order='second')","ead5c20b":"benford_all.chi_square_pretty(order='second')","d4cd57cf":"benford_all.fig_single(order='third')","6e8b702f":"benford_all.chi_square_pretty(order='third')","d22d3971":"benford_all.fig_single(order='fourth')","2e67a518":"benford_all.chi_square_pretty(order='fourth')","78661109":"benford_all.fig_single(order='fifth')","d41be6b5":"benford_all.chi_square_pretty(order='fifth')","38852b8e":"benford_all.fig_first_two()","90cf9eb8":"benford_all.chi_square_pretty(order='first_two')","763c2dbe":"benford_all.fig_first_three()","c5cd44db":"benford_all.chi_square_pretty(order='first_three')","6ed26f2e":"benford_all.fig_last_two()","6dd829a7":"benford_all.chi_square_pretty(order='last_two')","12e77ad8":"benford_saudi = BenfordCheck(df.query(\"country == 'Saudi Arabia'\").new_cases)\nbenford_saudi.fig_all()","76ebc660":"benford_saudi.chi_square_all()","7977335e":"benford_iran = BenfordCheck(df.query(\"country == 'Iran'\").new_cases)\nbenford_iran.fig_all()","2d971054":"benford_iran.chi_square_all()","ddae9d33":"benford_usa = BenfordCheck(df.query(\"country == 'United States'\").new_cases)\nbenford_usa.fig_all()","1920a789":"benford_usa.chi_square_all()","d0279c16":"benford_india = BenfordCheck(df.query(\"country == 'India'\").new_cases)\nbenford_india.fig_all()","e81a8860":"benford_india.chi_square_all()","185a1fc8":"benford_china = BenfordCheck(df.query(\"country == 'China'\").new_cases)\nbenford_china.fig_all()","3040a5ab":"benford_china.chi_square_all()","b37ee8fd":"benford_qatar = BenfordCheck(df.query(\"country == 'Qatar'\").new_cases)\nbenford_qatar.fig_all()","1c25c0ac":"benford_qatar.chi_square_all()","ffddecd3":"benford_singapore = BenfordCheck(df.query(\"country == 'Singapore'\").new_cases)\nbenford_singapore.fig_all()","1bdbff17":"benford_singapore.chi_square_all()","37e4f986":"#Creatng dataframe for plotting of p-values of all countries\n\np_value_all = {}\nfor x in df.country.unique():\n    benford_x = BenfordCheck(df[df['country'] == x].new_cases)\n    chi_data = benford_x.chi_square_all(non_table=True)\n    p_data = [x[2] for x in chi_data]\n    if np.isnan(np.array(p_data)).all():\n        continue\n    p_value_all[x] = p_data\np_value_df = pd.DataFrame(p_value_all).T","85c6b6c8":"#Function that helps in filling colours in table\n\ndef p_value_color(array):\n    return [0 if np.isnan(x) else 1 if x>=0.05 else 2 if x<0.05 else None for x in array]","0d46c246":"fig = go.Figure(data=[go.Table(#columnwidth=[200,100,100,100,100,100,100,100,100],\n    header=dict(values=['Countries','First Digit','Second Digit','Third Digit','Fourth Digit','Fifth Digit',\n                        'First Two Digits','Last Two Digits','First Three Digits'],\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[p_value_df.index, round(p_value_df[0],5),round(p_value_df[1],5),round(p_value_df[2],5),\n                       round(p_value_df[3],5),round(p_value_df[4],5),round(p_value_df[5],5),round(p_value_df[6],5),\n                       round(p_value_df[7],5)],align='left',\n              fill_color=[['lavender']*p_value_df.shape[0]] + [list(np.array(['white','#a2f562',\n                                                                              '#f56262'])[p_value_color(x)]) for x \n                                    in (p_value_df[0], p_value_df[1], p_value_df[2], p_value_df[3], p_value_df[4],\n                                        p_value_df[5], p_value_df[6], p_value_df[7])]))\n])\nfig.update_layout(title_text='P-Values Of All Countries',margin=dict(b=0,l=0,r=0), height=700)\nfig.show(config=config)","4fc36572":"pip install pmdarima","4713a4c7":"pip install prophet","4f469f24":"import itertools\nfrom pmdarima.arima import auto_arima\nfrom prophet.diagnostics import cross_validation\nfrom prophet.diagnostics import performance_metrics\nfrom prophet import Prophet\nfrom scipy.special import inv_boxcox\nfrom scipy.stats import boxcox\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import kpss\nfrom statsmodels.tsa.stattools import pacf\nfrom tqdm import tqdm","a24f028e":"# from helper_functions import config\n# from helper_functions import set_theme\n# from helper_functions import custom_legend_name\nworld_df = pd.read_csv('https:\/\/media.githubusercontent.com\/media\/vyaduvanshi\/ds-projects\/master\/\\\ncoronavirus-future-prediction\/final_world_df.csv')\nworld_df['date'] = pd.to_datetime(world_df['date'], format=('%Y-%m-%d'))","159fbb1b":"#Setting theme for further plots\n\nset_theme()","64b13a99":"#Making a dataframe with `new_cases` as the target variable\n\ndf = world_df\ndf = df[['date','new_cases']]\ndf['new_cases'] = df['new_cases'].fillna(df['new_cases'].bfill())\ndf = df.set_index('date')\ndf.index = pd.to_datetime(df.index)","08ae82ba":"fig = px.line(df.new_cases, title='New Cases')\nfig.update_traces(showlegend=False, hovertemplate='%{x}<br><b>%{y:.5s}<\/b><extra><\/extra>')\nfig.show(config=config)","3c7b72ce":"#Function to plot moving average and standard deviation to visually inspect stationarity\n\ndef test_stationarity(df, feature, series_type='val'):\n    rol_mean = df[feature].rolling(window=7).mean()\n    rol_std = df[feature].rolling(window=7).std()\n    fig = go.Figure()\n    fig.add_scatter(y=df[feature], x=df.index)\n    fig.add_scatter(y=rol_mean, x=df.index)\n    fig.add_scatter(y=rol_std, x=df.index)\n    fig.update_layout(legend=dict(title=None),\n                  hovermode='x unified',hoverlabel=dict(bgcolor='rgba(255,255,255,0.75)',font=dict(color='black')))\n    custom_legend_name(['New Cases','Rolling 7-Day Mean','Rolling 7-Day Standard Deviation'],fig_in_func=fig)\n    if series_type == 'full':\n        fig.update_layout(title_text='Full Non-Split Series')\n    elif series_type == 'val':\n        fig.update_layout(title_text='Training Set')\n    elif series_type == 'val2':\n        fig.update_layout(title_text='(Training + 1st Validation) Set')\n    elif series_type == 'test':\n        fig.update_layout(title_text='(Training + Val1 + Val2) Set')\n    fig.show(config=config)","e14e61c0":"test_stationarity(df, 'new_cases', 'full')","d3c21ba6":"#Function to output results of ADF test\n\ndef adf_test(timeseries):\n    print(\"Results of Dickey-Fuller Test:\")\n    dftest = adfuller(timeseries)\n    dfoutput = pd.Series(\n        dftest[0:4],\n        index=[\n            \"Test Statistic\",\n            \"p-value\",\n            \"#Lags Used\",\n            \"Number of Observations Used\",\n        ],\n    )\n    for key, value in dftest[4].items():\n        dfoutput[\"Critical Value (%s)\" % key] = value\n    print(dfoutput)","4f23bc23":"adf_test(df.new_cases)","79c8024e":"#Function to output result of KPSS test\n\ndef kpss_test(timeseries):\n    print(\"Results of KPSS Test:\")\n    kpsstest = kpss(timeseries, nlags=\"auto\")\n    kpss_output = pd.Series(\n        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n    )\n    for key, value in kpsstest[3].items():\n        kpss_output[\"Critical Value (%s)\" % key] = value\n    print(kpss_output)","8eeb62bc":"kpss_test(df.new_cases)","fa6bcb13":"#Separating data into sets of weeks\n\nweeks = [g for n, g in df.groupby(pd.Grouper(freq='W'))]\nfig = go.Figure()\nfor idx,x in enumerate(weeks):\n    if idx >55:\n        fig.add_scatter(x=x.index, y=x.new_cases)\nfig.update_layout(title_text='Part Of Series Showing Weekly Seasonality', showlegend=False, yaxis_title='New Cases',\n                 yaxis_title_font_color='#2A3F5F')\nfig.update_traces(hovertemplate='%{x}<br><b>%{y:.5s}<\/b><extra><\/extra>')\nfig.show(config=config)\nfor week in weeks:\n    week.index = week.index.day_name()\n(weeks[0],weeks[9]) = (weeks[9],weeks[0])","c51d300f":"fig = go.Figure()\nfig.update_layout(showlegend=False, title_text='Plots Showing Weekly Seasonality For Each Week<br>\\\nSince the Start of the Pandemic')\nfor idx,x in enumerate(weeks):\n    if idx%10 == 0 and idx>0:\n        fig.show(config=config)\n        fig = go.Figure()\n        fig.update_layout(showlegend=False)\n    fig.add_scatter(x=x.index, y=x.new_cases)\nfig.show(config=config)","28e9d2d3":"#Function to split dataframe into train, test, validation 1 and validation 2\n\ndef split_train_test_val(df):\n    test_size = 30\n    train_df = df[:-test_size*3]\n    val_df = df[-test_size*3:-test_size*2]\n    val2_df = df[-test_size*2:-test_size]\n    test_df = df[-test_size:]\n    return train_df, test_df, val_df, val2_df","6ce0d57e":"#Spliting data\n\ntrain_df, test_df, val_df, val2_df = split_train_test_val(df)","0ac55bd7":"test_stationarity(train_df, 'new_cases')","6915c77d":"#Function to create ACF or PACF plots\n\ndef create_corr_plot(series, plot_pacf=False):\n    corr_array = pacf(series.dropna(), alpha=0.05) if plot_pacf else acf(series.dropna(), alpha=0.05)\n    lower_y = corr_array[1][:,0] - corr_array[0]\n    upper_y = corr_array[1][:,1] - corr_array[0]\n\n    fig = go.Figure()\n    [fig.add_scatter(x=(x,x), y=(0,corr_array[0][x]), mode='lines',line_color='#3f3f3f') \n     for x in range(len(corr_array[0]))]\n    fig.add_scatter(x=np.arange(len(corr_array[0])), y=corr_array[0], mode='markers', marker_color='#1f77b4',\n                   marker_size=12)\n    fig.add_scatter(x=np.arange(len(corr_array[0])), y=upper_y, mode='lines', line_color='rgba(255,255,255,0)')\n    fig.add_scatter(x=np.arange(len(corr_array[0])), y=lower_y, mode='lines',fillcolor='rgba(32, 146, 230,0.3)',\n            fill='tonexty', line_color='rgba(255,255,255,0)')\n    fig.update_traces(showlegend=False)\n    fig.update_xaxes(range=[-1,42], tickformat='', hoverformat='')\n    fig.update_yaxes(zerolinecolor='#000000')\n    fig.update_traces(hovertemplate='%{x}<br>%{y}<extra><\/extra>')\n    \n    title='Partial Autocorrelation (PACF)' if plot_pacf else 'Autocorrelation (ACF)'\n    fig.update_layout(title=title)\n    fig.show(config=config)","6113e608":"create_corr_plot(train_df.new_cases)","db3755e0":"create_corr_plot(train_df.new_cases, True)","8a5a5a56":"#Function to set inferred index for df to prevent statsmodels throwing warnings\n\ndef set_inferred_index(df):\n    try:\n        df.index = pd.DatetimeIndex(df.index.values, freq=df.index.inferred_freq)\n    except AttributeError:\n        pass\n    \nset_inferred_index(train_df)","a0c249a9":"#Function to get actual values, predicted values and model in a tuple\n\ndef get_model_pred(model_arg, aic_bic=True, split_type='val', series_type='normal', algo_type='sarima'):\n    predicted = []\n    if split_type == 'test':\n        model_df = train_df.append(val_df).append(val2_df)[['new_cases']].copy()\n        future_df = test_df.copy()            \n    elif split_type == 'val2':\n        model_df = train_df.append(val_df)[['new_cases']].copy()\n        future_df = val2_df.copy()\n    else:\n        model_df = train_df[['new_cases']].copy()\n        future_df = val_df.copy()\n    if algo_type == 'hw':\n        if model_arg[0] == 'mul' or model_arg[1] == 'mul':\n            model_df = model_df.drop(model_df[(model_df.new_cases == 0)].index)\n    if series_type == 'lr':\n        X = [i for i in range(len(model_df.new_cases))]\n        X = np.reshape(X, (len(X), 1))\n        lr = LinearRegression().fit(X,model_df.new_cases)\n        lr_trend = lr.predict(X)\n        model_df = model_df.new_cases - lr_trend\n    elif series_type == 'boxcox':\n        model_df,lmbda = boxcox(model_df.drop(model_df[(model_df.new_cases == 0)].index).new_cases, lmbda=None)\n    pred_index = len(model_df)\n    for x in range(len(future_df)):\n        set_inferred_index(model_df)\n        if algo_type == 'sarima':\n            order = model_arg[0]\n            seasonal_order = model_arg[1]\n            model = SARIMAX(model_df, order=order, seasonal_order=seasonal_order)\n            model = model.fit(maxiter=200, disp=0)\n            if aic_bic:\n                return (order, seasonal_order),model.aic, model.bic\n        elif algo_type == 'hw':\n            model = ExponentialSmoothing(model_df, seasonal_periods=model_arg[7], seasonal=model_arg[1],\n                                         trend=model_arg[0], damped=model_arg[2])\n            model = model.fit(smoothing_level=model_arg[4], smoothing_trend=model_arg[5],\n                              smoothing_seasonal=model_arg[6], damping_trend=model_arg[3])\n            if aic_bic:\n                return (model_arg),model.aic, model.bic\n        if series_type == 'lr':\n            inversed_forecast = model.forecast() + lr.predict([[pred_index]])\n            predicted.append(inversed_forecast)\n            detrended_future_obs = future_df[['new_cases']].iloc[x] - lr.predict([[pred_index]])\n            model_df = model_df.append(detrended_future_obs)\n            pred_index += 1\n        elif series_type == 'boxcox':\n            inversed_forecast = inv_boxcox(model.forecast(),lmbda)\n            predicted.append(inversed_forecast)\n            detrended_future_obs = ((future_df[['new_cases']].iloc[x])**lmbda - 1) \/ lmbda\n            model_df = np.append(model_df, detrended_future_obs)\n        else:\n            predicted.append(model.forecast())\n            model_df = model_df.append(future_df[['new_cases']].iloc[x])\n    if series_type == 'lr':\n        return future_df.new_cases, np.array([x.values[0] for x in predicted]), model\n    return future_df.new_cases, np.array([x[0] for x in predicted]), model","f3307567":"#Function to plot actual and predicted values\n\ndef plot_pred(actual, predicted, plot_model_attribs):\n    fig = go.Figure()\n    fig.add_scatter(y=actual, x=actual.index)\n    fig.add_scatter(y=predicted, x=actual.index)\n    fig.update_xaxes(tickformat='', hoverformat='')\n    custom_legend_name(['Actual','Predicted'], fig_in_func=fig)\n    fig.update_layout(title_text=('Actual vs Predicted<br><span style=\"font-size:0.65em\">'+\n                                  str(plot_model_attribs)+'<\/span>'), legend_orientation='h',\n                     legend_borderwidth=0)\n    fig.update_traces(hovertemplate='%{x}<br><b>%{y:.5s}<\/b><extra><\/extra>')\n    fig.show(config=config)","fc681fa2":"#Function to plot residuals\n\ndef plot_resid(actual, predicted, plot_model_attribs):\n    \"\"\"\n    resid:              The y-axis points to be plotted. x-axis is assumed to be linearly increasing.\n    tickvalues:         The values you want to be displayed as ticklabels on x-axis. Works for hoverlabels too. Has \n                        to be same length as `resid`. (This is necessary to ignore 'gaps' in graph where two polygons \n                        meet.)\n    plot_model_attribs: The parameters passed to the SARIMA model.\n    \"\"\"\n    #Adjusting array with paddings to connect polygons at zero line on x-axis\n    resid = actual - predicted\n    index_array = []\n    start_digit = 0\n    split_array = np.split(resid,np.where(np.abs(np.diff(np.sign(resid)))==2)[0]+1)\n    split_array = [np.append(x,0) for x in split_array]\n    split_array = [np.insert(x,0,0) for x in split_array]\n    split_array[0] = np.delete(split_array[0],0)\n    split_array[-1] = np.delete(split_array[-1],-1)\n    for x in split_array:\n        index_array.append(np.arange(start_digit,start_digit+len(x)))\n        start_digit += len(x)-1\n\n    #Formatting dates to be displayed neatly as autoformatting won't work for this figure\n    datelist = []\n    cur_month = ''\n    prev_month = ''\n    cur_year = ''\n    for x in actual.index:\n        ts = pd.to_datetime(x)\n        ts = ts.strftime('%Y %b %d')\n        if cur_month == ts[5:-3]:\n            datelist.append(pd.to_datetime(x).strftime('%d'))\n        elif cur_year == ts[:4]:\n            datelist.append(pd.to_datetime(x).strftime('%b %d'))\n            prev_month = cur_month\n        else:\n            datelist.append(ts)\n        cur_month = ts[5:-3]\n        cur_year = ts[:4]\n\n    #Making an array for ticklabels\n    flat = []\n    for x in index_array:\n        for y in x:\n            flat.append(y)\n    flat_counter = Counter(flat)\n    none_indices = np.where([(flat_counter[x]>1) for x in flat_counter])[0]\n    custom_tickdata = []\n    neg_padding = 0\n    start_pos = 0\n    for y in range(len(flat)):\n        for x in range(start_pos,flat[-1]+1):\n            if x in none_indices:\n                custom_tickdata.append('')\n                break\n            custom_tickdata.append(datelist[x-neg_padding])\n        neg_padding +=1\n        start_pos = 1+x\n\n    #Making an array for hoverlabels\n    custom_hoverdata=[]\n    sublist = []\n    len_track = 2\n    value_idx = 0\n    for idx,x in enumerate(custom_tickdata):\n        if x == '':\n            custom_hoverdata.append(sublist)\n            sublist = []\n            sublist.append(x)\n            continue\n        if idx==0:\n            sublist.append(str(x)+'<br><b>'+str(resid[value_idx])+'<\/b>')\n            value_idx += 1\n        else:\n            if len(x) > len_track:\n                prev_month = cur_month\n            if prev_month == '':\n                sublist.append(str(x)+' '+cur_month+'<br><b>'+str(resid[value_idx])+'<\/b>')\n                value_idx += 1\n            else:\n                sublist.append(str(x)+' '+prev_month+'<br><b>'+str(resid[value_idx])+'<\/b>')\n                value_idx += 1\n        sublist2 = sublist.copy()\n    custom_hoverdata.append(sublist2)\n\n    #Creating figure\n    fig = go.Figure()\n    idx = 0\n    for x,y in zip(split_array,index_array):\n        color = 'rgba(219,43,57,0.8)' if x[1]<0 else 'rgba(47,191,113,0.8)'\n        if (idx==0 and x[0] < 0):\n            color= 'rgba(219,43,57,0.8)'\n        fig.add_scatter(y=x, x=y, fill='tozeroy', fillcolor=color, line_color=color, customdata=custom_hoverdata[idx],\n                        hovertemplate='%{customdata}<extra><\/extra>')\n        idx += 1\n    fig.update_layout(margin=dict(l=0), title_text='Residuals<br><span style=\"font-size:0.65em\">'+\n                                  str(plot_model_attribs)+'<\/span>')\n    fig.update_xaxes(hoverformat='',tickmode = 'array', tickangle=90,\n                tickvals = np.arange(index_array[-1][-1]+1),\n                ticktext = custom_tickdata)\n    fig.update_traces(mode='lines', showlegend=False)\n    fig.show(config=config)","27aba7f6":"#Class containing the model, figure and metrics of the predictions\n\nclass Metrics(object):\n    def __init__(self, actual, predicted, model):\n        self.actual = actual\n        self.predicted = predicted\n        self.model = model\n    def mse(self):\n        return np.sum(np.square(self.actual-self.predicted))\/len(self.predicted)\n    def rmse(self):\n        return np.sqrt(self.mse())\n    def mae(self):\n        return np.sum(np.abs(self.actual-self.predicted))\/len(self.predicted)\n    def mape(self):\n        try:\n            return np.mean(np.abs((self.actual-self.predicted)\/self.actual))*100\n        except ZeroDivisionError:\n            return np.nan\n    def mase(self, algo_type='sarima'):\n        try:\n            if algo_type == 'hw':\n                s = 7\n            else:\n                s = self.diff_order()[0] if not self.diff_order()[1] else self.diff_order()[1]\n                if s == 0:\n                    s = 1\n            y_train = np.asarray(self.model.model.endog[:-29])\n            mae_naive = np.mean(np.abs(y_train[s:] - y_train[:-s]))\n            if mae_naive == 0:\n                return np.nan\n            else:\n                return np.mean(np.abs(self.actual-self.predicted))\/mae_naive\n        except TypeError:\n            return None\n    def fig(self):\n        return plot_pred(self.actual, self.predicted, self.model_attribs)\n    def resid_fig(self):\n        return plot_resid(self.actual, self.predicted, self.model_attribs)\n    def model_name(self, model_attribs, seasonal_model_attribs):\n        if seasonal_model_attribs == 0:\n            self.model_attribs = (model_attribs)\n        else:\n            self.model_attribs = (model_attribs,seasonal_model_attribs)\n    def aic(self):\n        return self.model.aic\n    def bic(self):\n        return self.model.bic\n    def diff_order(self):\n        try:\n            return (self.model.model.k_diff, self.model.model.k_seasonal_diff)\n        except:\n            pass\n    def get_all(self, algo_type='sarima'):\n        print('For model ' + str(self.model_attribs) + ':\\n\\nMean Squared Error (MSE): ',self.mse(),\n             '\\nRoot Mean Squared Error (RMSE): ', self.rmse(),\n             '\\nMean Absolute Error (MAE): ', self.mae(),\n             '\\nMean Absolute Percentage Error (MAPE): ', self.mape(),\n             '\\nMean Absolute Scaled Error (MASE): ', self.mase(algo_type))","b3eb0015":"#Standard deviation after single order of non-seasonal differencing\n\ntrain_df['diff1'] = train_df['new_cases'] - train_df['new_cases'].shift(1)\ntrain_df['diff1'].std()","a6b1ab24":"#Standard deviation after another order of non-seasonal differencing\n\ntrain_df['diff2'] = train_df['diff1'] - train_df['diff1'].shift(1)\ntrain_df['diff2'].std()","1524e467":"test_stationarity(train_df, 'diff1')","1a3f30f1":"adf_test(train_df.diff1.dropna())","c35aa84f":"kpss_test(train_df.diff1.dropna())","50e4ca1b":"create_corr_plot(train_df.diff1)","279e93ed":"create_corr_plot(train_df.diff1, True)","b836873f":"#Training ARIMA with I=1 and MA=2\n\nsarima_diff1 = ((0,1,2),(0,0,0,0))\nactual_diff1, predicted_diff1, model_diff1 = get_model_pred(sarima_diff1, aic_bic=False)\ndiff1 = Metrics(actual_diff1, predicted_diff1, model_diff1)\ndiff1.model_name(sarima_diff1[0], sarima_diff1[1])","e69c2e73":"diff1.fig()","9c96e5e0":"diff1.resid_fig()","6508760e":"diff1.get_all()","117e1c5d":"#Standard deviation after single order of seasonal differencing\n\ntrain_df['sdiff'] = train_df['new_cases'] - train_df['new_cases'].shift(7)\ntrain_df['sdiff'].std()","82e19f87":"#Standard deviation after another order of seasonal differencing\n\ntrain_df['sdiff2'] = train_df['sdiff'] - train_df['sdiff'].shift(7)\ntrain_df['sdiff2'].std()","2f3709d1":"test_stationarity(train_df, 'sdiff')","dce066ce":"adf_test(train_df.sdiff.dropna())","6c032b0e":"kpss_test(train_df.sdiff.dropna())","100650bb":"create_corr_plot(train_df.sdiff)","ee5df327":"create_corr_plot(train_df.sdiff, True)","ab9f8834":"#Training SARIMA with S=7, S(AR)=1 and S(I)=1\n\nsarima_sdiff = ((0,0,0),(1,1,0,7))\nactual_sdiff, predicted_sdiff, model_sdiff = get_model_pred(sarima_sdiff, aic_bic=False)\nsdiff = Metrics(actual_sdiff, predicted_sdiff, model_sdiff)\nsdiff.model_name(sarima_sdiff[0], sarima_sdiff[1])","01befa08":"sdiff.fig()","2dead0e6":"sdiff.resid_fig()","cd4e04a8":"sdiff.get_all()","d183c4a8":"#Standard deviation after single order seasonal and non-seasonal difference\n\ntrain_df['sdiff_plus_diff'] = train_df['sdiff'] - train_df['sdiff'].shift(1)\ntrain_df['sdiff_plus_diff'].std()","37b4088c":"test_stationarity(train_df,'sdiff_plus_diff')","eae5c075":"adf_test(train_df.sdiff_plus_diff.dropna())","ad776805":"kpss_test(train_df.sdiff_plus_diff.dropna())","111d2af9":"create_corr_plot(train_df.sdiff_plus_diff)","4d5eb4e9":"create_corr_plot(train_df.sdiff_plus_diff, True)","8e8ce3a4":"#Training SARIMA with AR=2, I=1, S=7, S(AR)=3 and S(I)=1\n\nsarima_sdiff_plus_diff = ((2,1,0),(3,1,0,7))\nactual_sdiff_plus_diff, predicted_sdiff_plus_diff, model_sdiff_plus_diff = get_model_pred(sarima_sdiff_plus_diff,\n                                                                                          aic_bic=False)\nsdiff_plus_diff = Metrics(actual_sdiff_plus_diff, predicted_sdiff_plus_diff, model_sdiff_plus_diff)\nsdiff_plus_diff.model_name(sarima_sdiff_plus_diff[0],sarima_sdiff_plus_diff[1])","920c27ee":"sdiff_plus_diff.fig()","e56223e2":"sdiff_plus_diff.resid_fig()","85b6f882":"sdiff_plus_diff.get_all()","e8ce11fe":"#Transforming dataframe by boxcox to train a model on it\n\nboxcox_df = train_df.drop(train_df[(train_df.new_cases == 0)].index)\nseries,lmbda = boxcox(boxcox_df.new_cases, lmbda=None)\nboxcox_df['new_cases'] = series","e063ef94":"fig = px.histogram(train_df.new_cases)\nfig.layout.xaxis.tickformat = ''\nfig.layout.xaxis.hoverformat = ''\nfig.update_layout(legend_borderwidth=1, legend_title=None, title_text='Before Transformation')\nfig.update_traces(hovertemplate='%{x}<br>%{y}<extra><\/extra>')\nfig.show(config=config)","da149b75":"fig = px.histogram(boxcox_df.new_cases)\nfig.layout.xaxis.tickformat = ''\nfig.layout.xaxis.hoverformat = ''\nfig.update_layout(legend_borderwidth=1, legend_title=None, title_text='After Transformation')\nfig.update_traces(hovertemplate='%{x}<br>%{y}<extra><\/extra>')\nfig.show(config=config)","c9d210b1":"test_stationarity(boxcox_df, 'new_cases')","09aef9bc":"lmbda","e3e42b86":"adf_test(series)","e8868bba":"kpss_test(series)","9537c4a6":"#Finding standard deviation for four types of differencing on boxcox transformed series\n\nboxcox_df['diff1'] = boxcox_df['new_cases'] - boxcox_df['new_cases'].shift(1)\nboxcox_df['diff2'] = boxcox_df['diff1'] - boxcox_df['diff1'].shift(1)\nboxcox_df['sdiff'] = boxcox_df['new_cases'] - boxcox_df['new_cases'].shift(7)\nboxcox_df['sdiff_plus_diff'] = boxcox_df['diff1'] - boxcox_df['diff1'].shift(7)","68f87de1":"boxcox_df['new_cases'].std()","08bce374":"boxcox_df['diff1'].std()","bcc7d074":"boxcox_df['diff2'].std()","5c332f82":"boxcox_df['sdiff'].std()","3dbbc4dc":"boxcox_df['sdiff_plus_diff'].std()","27f6afc4":"create_corr_plot(boxcox_df.sdiff_plus_diff)","2c20a0f5":"create_corr_plot(boxcox_df.sdiff_plus_diff, plot_pacf=True)","4f54b639":"#Training SARIMA with AR=2, I=1, S=7, S(AR)=3 and S(I)=1 on boxcox transformed series\n\nsarima_boxcox = ((2,1,0),(3,1,0,7))\nactual_boxcox, predicted_boxcox, model_boxcox = get_model_pred(sarima_boxcox, aic_bic=False, series_type='boxcox')\nboxcox_trained = Metrics(actual_boxcox, predicted_boxcox, model_boxcox)\nboxcox_trained.model_name(sarima_boxcox[0],sarima_boxcox[1])","be2e6297":"boxcox_trained.fig()","79fd466f":"boxcox_trained.resid_fig()","68ae3d54":"boxcox_trained.get_all()","b0eae472":"#Preparing data into the right format to pass to scikitlearn's LinearRegression\n\nX = [i for i in range(0, len(train_df.new_cases))]\nX = np.reshape(X, (len(X), 1))","f06f1379":"#Training a linear regression model on the series and differencing the model line from the original series\n\nlr = LinearRegression()\nlr.fit(X,train_df.new_cases)\n\nlr_trend = lr.predict(X)\nlr_series = train_df.new_cases - lr_trend\ntrain_df['lr'] = lr_series","8606cbf2":"test_stationarity(train_df, 'lr')","2f692cb5":"adf_test(lr_series)","955615b9":"kpss_test(lr_series)","4ba33a44":"#Standard deviation of LR differenced series\n\ntrain_df['lr'].std()","3408f77f":"#Standard deviation of single order differenced LR differenced series\n\ntrain_df['lrdiff1'] = train_df['lr'] - train_df['lr'].shift(1)\ntrain_df['lrdiff1'].std()","70cbf63e":"#Standard deviation of double order differenced LR differenced series\n\ntrain_df['lrdiff2'] = train_df['lrdiff1'] - train_df['lrdiff1'].shift(1)\ntrain_df['lrdiff2'].std()","1ee6b4c4":"#Standard deviation of single order seasonally differenced LR differenced series\n\ntrain_df['lrsdiff'] = train_df['lr'] - train_df['lr'].shift(7)\ntrain_df['lrsdiff'].std()","ce4d6478":"#Standard deviation of single order seasonal and non-seasonal LR differenced series\n\ntrain_df['lrsdiff_plus_diff'] = train_df['lrsdiff'] - train_df['lrsdiff'].shift(1)\ntrain_df['lrsdiff_plus_diff'].std()","7d6e3a32":"create_corr_plot(train_df['lrsdiff_plus_diff'])","ac870284":"create_corr_plot(train_df['lrsdiff_plus_diff'], plot_pacf=True)","b8432893":"#Training SARIMA with AR=2, I=1, S=7, S(AR)=3, S(I)=1 on LR differenced series\n\nsarima_lr = ((2,1,0),(3,1,0,7))\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n    actual_lr, predicted_lr, model_lr = get_model_pred(sarima_lr, aic_bic=False, series_type='lr')\nlr_trained = Metrics(actual_lr, predicted_lr, model_lr)\nlr_trained.model_name(sarima_lr[0],sarima_lr[1])","4634eeac":"lr_trained.fig()","2907358d":"lr_trained.resid_fig()","59c8fe64":"lr_trained.get_all()","060a6c0b":"#Function to create grid of parameters for SARIMA grid search\n\np_params = list(range(6))\nd_params = [0,1,2]\nq_params = list(range(6))\nP_params = list(range(6))\nD_params = [0,1]\nQ_params = list(range(6))\nS_params = [0,7]\n\ndef create_param_list(p_params, d_params, q_params, P_params, D_params, Q_params, S_params, series_type='normal'):\n    param_list = []\n    for p in p_params:\n        for d in d_params:\n            for q in q_params:\n                for P in P_params:\n                    for D in D_params:\n                        for Q in Q_params:\n                            for S in S_params:\n                                if D==1 and d==2:\n                                    continue\n                                if S==0 and (P>0 or D>0 or Q>0):\n                                    continue\n                                if d==0 and D==0:\n                                    continue\n                                param_list.append(((p,d,q),(P,D,Q,S)))\n    return param_list","3e184bd6":"#Function to grid search SARIMA models across various parameters\n\ndef train_and_pred(params, aic_bic=True, split_type='val', series_type='normal'):\n    p,d,q = params[0]\n    P,D,Q,S = params[1]\n    try:\n        sarima_grid = ((p,d,q),(P,D,Q,S))\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\"ignore\")\n            actual_grid, predicted_grid, model_grid = get_model_pred(sarima_grid, aic_bic=aic_bic,\n                                                                     split_type=split_type, series_type=series_type)\n        if aic_bic:\n            return actual_grid, predicted_grid, model_grid\n        metrics_grid = Metrics(actual_grid, predicted_grid, model_grid)\n        metrics_grid.model_name((p,d,q),(P,D,Q,S))\n        return metrics_grid\n    except: #some models are not computable and throw errors\n        return","b2acfc56":"#Function to execute the grid-search with or without parallel processing\n\ndef grid_search_sarimax(parallel=False, aic_bic=True, split_type='val', series_type='normal'):\n    \"\"\"\n    parallel:    True uses all CPU cores.\n                 False runs it normally.\n    aic_bic:     True computes and returns the AIC and BIC scores for all models in param_list as class Metrics.\n                 False runs a rolling forecast of 30 days on each parameter, thus training each model 30 times. It \n                 then returns a list of instances of class Metrics.\n    split_type:  'val' to use train as train and first validation set as test.\n                 'val2' to use (train+val) as train and second validation set as test.\n                 'test' to use (train+val+val2) as train and test set as test.\n    series_type: 'normal' to use the default series in SARIMA models.\n                 'reg' to use series detrended by linear regression.\n                 'boxcox' to use series transformed by boxcox.\n    \"\"\"\n    param_list = create_param_list(p_params, d_params, q_params, P_params, D_params, Q_params, S_params,\n                                   series_type=series_type)\n    if not parallel:\n        models = [train_and_pred(param, aic_bic=aic_bic, split_type=split_type, series_type=series_type) \n                  for param in tqdm(param_list)]\n    else:\n        from multiprocess import Pool\n        import parallel #custom .py file required (in current directory) only for parallel processing\n        import os\n        max_pool = os.cpu_count()\n        with Pool(max_pool) as p, tqdm(total=len(param_list)) as pbar:\n            models = [(p.apply_async(parallel.train_and_pred, (param,),\n                                     dict(aic_bic=aic_bic, split_type=split_type, series_type=series_type),\n                                     callback=lambda _: pbar.update(1))) for param in param_list]\n            models = [x.get() for x in models]\n    return models","a1b3d477":"# %%time\n# #Grid search on the normal series to return AIC and BIC scores\n\n# normal_aic_bic = grid_search_sarimax()","bc92acee":"# %%time\n# #Grid search on the boxcox series to return AIC and BIC scores\n\n# boxcox_aic_bic = grid_search_sarimax(series_type='boxcox')","604fb1db":"# %%time\n# #Grid search on the LR detrended series to return AIC and BIC scores\n\n# lr_aic_bic = grid_search_sarimax(series_type='lr')","9b5fafe9":"# #Function to get the best models based on IC scores in each order of differencing\n\n# def get_top_models(model_list):\n#     diffs_01 = []\n#     diffs_10 = []\n#     diffs_11 = []\n#     diffs_20 = []\n#     model_list = [x for x in normal_aic_bic if x!=None]\n#     top_model_list = []\n\n#     for model in model_list:\n#         if model[0][0][1] == 0:\n#             diffs_01.append(model)\n#         elif model[0][0][1] == 2:\n#             diffs_20.append(model)\n#         else:\n#             if model[0][1][1] == 0:\n#                 diffs_10.append(model)\n#             elif model [0][1][1] == 1:\n#                 diffs_11.append(model)\n\n#     for x in (diffs_01, diffs_10, diffs_11, diffs_20):\n#         temp_df = pd.DataFrame(x)\n#         top_model_list.extend(temp_df.sort_values(1).head(5)[0].values)\n#         top_model_list.extend(temp_df.sort_values(2).head(5)[0].values)\n        \n#     return top_model_list","c207fe93":"# %%time\n# #The top 40 models from each series being trained to find their 30-day rolling forecast RMSE scores on 1st Validation\n\n# normal_top = []\n# boxcox_top = []\n# lr_top = []\n\n# for x in tqdm(get_top_models(normal_aic_bic)):\n#     normal_top.append(train_and_pred(x, aic_bic=False))\n\n# for x in tqdm(get_top_models(boxcox_aic_bic)):\n#     boxcox_top.append(train_and_pred(x, series_type='boxcox', aic_bic=False))\n    \n# for x in tqdm(get_top_models(lr_aic_bic)):\n#     lr_top.append(train_and_pred(x, series_type='lr', aic_bic=False))","eb7e4349":"# #Concatenating the best scores to a single dataframe\n\n# top_models_grid = pd.concat([pd.DataFrame([(x.model_attribs, x.rmse(),'normal') for x in normal_top if x!=None]),\n#                              pd.DataFrame([(x.model_attribs, x.rmse(),'boxcox') for x in boxcox_top if x!=None]),\n#                              pd.DataFrame([(x.model_attribs, x.rmse(),'lr') for x in lr_top if x!=None])])","87c496ea":"#Manually passing the best results a variable so it can be used even if the time-taking computation is skipped\n\ntop_models_grid = pd.DataFrame([[((3, 2, 2), (2, 0, 1, 7)), 19634.74428968301, 'boxcox'],\n [((5, 1, 3), (3, 0, 2, 7)), 19745.971512098506, 'boxcox'],\n [((5, 1, 3), (2, 0, 2, 7)), 19871.168770235356, 'boxcox'],\n [((5, 1, 3), (3, 0, 1, 7)), 19895.86596117377, 'boxcox'],\n [((5, 1, 3), (1, 0, 2, 7)), 19966.745046262848, 'boxcox'],\n [((5, 1, 3), (2, 0, 1, 7)), 19993.681918591043, 'boxcox'],\n [((5, 1, 3), (2, 0, 1, 7)), 19993.681918591043, 'boxcox'],\n [((5, 1, 3), (0, 1, 3, 7)), 20164.362481277407, 'boxcox'],\n [((3, 0, 3), (2, 1, 5, 7)), 20242.323707311414, 'boxcox'],\n [((1, 0, 1), (1, 1, 1, 7)), 20270.54552704959, 'boxcox'],\n [((0, 1, 1), (1, 1, 1, 7)), 20272.70613794951, 'boxcox'],\n [((5, 1, 3), (0, 1, 2, 7)), 20292.36329395848, 'boxcox'],\n [((5, 1, 3), (3, 0, 2, 7)), 20304.77908584254, 'lr'],\n [((5, 1, 3), (1, 0, 2, 7)), 20320.4173948662, 'lr'],\n [((1, 0, 1), (0, 1, 2, 7)), 20341.326477819264, 'boxcox'],\n [((3, 0, 3), (1, 1, 1, 7)), 20345.958576452045, 'boxcox'],\n [((3, 0, 3), (1, 1, 1, 7)), 20345.958576452045, 'boxcox'],\n [((5, 1, 3), (2, 0, 1, 7)), 20357.02064064762, 'lr'],\n [((5, 1, 3), (2, 0, 1, 7)), 20357.02064064762, 'lr'],\n [((5, 1, 3), (3, 0, 2, 7)), 20366.350883787552, 'normal'],\n [((0, 1, 1), (0, 1, 2, 7)), 20395.00699393534, 'boxcox'],\n [((5, 1, 3), (2, 0, 1, 7)), 20478.591594869296, 'normal'],\n [((5, 1, 3), (2, 0, 1, 7)), 20478.591594869296, 'normal'],\n [((5, 1, 3), (2, 0, 2, 7)), 20479.8400468167, 'lr'],\n [((5, 1, 3), (1, 0, 1, 7)), 20496.169103386972, 'boxcox'],\n [((2, 1, 3), (1, 1, 1, 7)), 20498.779215374947, 'boxcox'],\n [((5, 1, 3), (1, 1, 1, 7)), 20549.802454227894, 'boxcox'],\n [((5, 1, 3), (2, 1, 1, 7)), 20551.639587278907, 'boxcox'],\n [((5, 1, 3), (1, 0, 0, 7)), 20560.296084296373, 'boxcox'],\n [((2, 0, 2), (1, 1, 1, 7)), 20574.780884399224, 'boxcox'],\n [((5, 1, 3), (2, 0, 2, 7)), 20602.21424911169, 'normal'],\n [((1, 1, 3), (1, 1, 1, 7)), 20604.58299009131, 'boxcox'],\n [((2, 0, 3), (1, 1, 1, 7)), 20608.790108674315, 'boxcox'],\n [((5, 1, 3), (1, 0, 2, 7)), 20631.662368602985, 'normal'],\n [((5, 1, 3), (3, 0, 0, 7)), 20674.344538756068, 'lr'],\n [((5, 1, 3), (3, 0, 0, 7)), 20674.344538756068, 'lr'],\n [((5, 1, 3), (1, 1, 2, 7)), 20678.90013139158, 'boxcox'],\n [((1, 1, 3), (0, 1, 2, 7)), 20688.361648607995, 'boxcox'],\n [((5, 1, 3), (1, 0, 0, 7)), 20694.940490399345, 'normal'],\n [((5, 1, 3), (3, 0, 1, 7)), 20727.08312501934, 'lr'],\n [((5, 1, 3), (1, 0, 0, 7)), 20735.185465402927, 'lr'],\n [((5, 2, 5), (1, 0, 2, 7)), 20828.976646340067, 'lr'],\n [((5, 1, 3), (3, 0, 0, 7)), 20863.152905109797, 'normal'],\n [((5, 1, 3), (3, 0, 0, 7)), 20863.152905109797, 'normal'],\n [((5, 0, 3), (1, 1, 1, 7)), 20878.732980754117, 'boxcox'],\n [((5, 2, 5), (2, 0, 1, 7)), 20902.231767221616, 'lr'],\n [((5, 1, 3), (3, 0, 1, 7)), 20951.34408129412, 'normal'],\n [((1, 2, 2), (3, 0, 1, 7)), 20962.941244034806, 'lr'],\n [((1, 2, 2), (3, 0, 1, 7)), 20962.941244034806, 'lr'],\n [((5, 1, 3), (1, 0, 1, 7)), 20978.60436714676, 'lr']])","29fc0a5c":"auto_arima(train_df.new_cases, start_p=0, d=0, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=0, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           information_criterion='aic', with_intercept=False)","f32d8faa":"auto_arima(train_df.new_cases, start_p=0, d=1, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=0, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           information_criterion='aic', with_intercept=False)","5803f657":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((0,1,0),(2,0,1,7)), aic_bic=False).rmse()","6349b177":"auto_arima(train_df.new_cases, start_p=0, d=2, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=0, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           information_criterion='aic', with_intercept=False)","6b3047a2":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((5,2,0),(1,0,2,7)), aic_bic=False).rmse()","c9451c4c":"auto_arima(train_df.new_cases, start_p=0, d=1, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=1, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           information_criterion='aic', with_intercept=False)","e85e81de":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((0,1,1),(1,1,1,7)), aic_bic=False).rmse()","9b03637b":"auto_arima(train_df.new_cases, start_p=0, d=0, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=1, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           information_criterion='aic', with_intercept=False)","9d56d0d5":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((3,0,3),(1,1,1,7)), aic_bic=False).rmse()","c8452108":"auto_arima(train_df.new_cases.append(val_df.new_cases), start_p=0, d=0, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=0, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           out_of_sample_size=30, information_criterion='oob', with_intercept=False)","b24944ab":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((1,0,0),(4,0,0,7)), aic_bic=False).rmse()","4cc106d3":"auto_arima(train_df.new_cases.append(val_df.new_cases), start_p=0, d=1, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=0, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           out_of_sample_size=30, information_criterion='oob', with_intercept=False)","b0337cb3":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((0,1,0),(1,0,5,7)), aic_bic=False).rmse()","e5b2f283":"auto_arima(train_df.new_cases.append(val_df.new_cases), start_p=0, d=2, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=0, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           out_of_sample_size=30, information_criterion='oob', with_intercept=False)","a156305d":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((1,2,0),(3,0,0,7)), aic_bic=False).rmse()","2a8194a1":"auto_arima(train_df.new_cases.append(val_df.new_cases), start_p=0, d=1, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=1, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           out_of_sample_size=30, information_criterion='oob', with_intercept=False)","25e2128f":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((1,1,0),(1,1,2,7)), aic_bic=False).rmse()","3ae9f88b":"auto_arima(train_df.new_cases.append(val_df.new_cases), start_p=0, d=0, start_q=0, max_p=5, max_d=2, max_q=5,\n           start_P=0, D=1, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n           out_of_sample_size=30, information_criterion='oob', with_intercept=False)","7af1a67d":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((5,0,1),(1,1,0,7)), aic_bic=False).rmse()","a00af005":"# #Might take some time to finish\n\n# auto_arima(train_df.new_cases.append(val_df.new_cases), start_p=0, d=0, start_q=0, max_p=5, max_d=2, max_q=5,\n#            start_P=0, D=0, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n#            out_of_sample_size=30, information_criterion='oob', with_intercept=False, stepwise=False, max_order=8)","5514d7ad":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((0,0,0),(5,0,1,7)), aic_bic=False).rmse()","445b5d81":"# #Might take some time to finish\n\n# auto_arima(train_df.new_cases.append(val_df.new_cases), start_p=0, d=1, start_q=0, max_p=5, max_d=2, max_q=5,\n#            start_P=0, D=0, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n#            out_of_sample_size=30, information_criterion='oob', with_intercept=False, stepwise=False, max_order=8)","b3f2f37b":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((3,1,3),(1,0,0,7)), aic_bic=False).rmse()","03cb06fa":"# #Might take some time to finish\n\n# auto_arima(train_df.new_cases.append(val_df.new_cases), start_p=0, d=1, start_q=0, max_p=5, max_d=2, max_q=5,\n#            start_P=0, D=1, start_Q=0, max_P=5, max_D=1, max_Q=5, seasonal=True, m=7, maxiter=200, trace=True,\n#            out_of_sample_size=30, information_criterion='oob', with_intercept=False, stepwise=False, max_order=8)","33b441ac":"#Calculating RMSE after 1 month daily rolling forecast on the best selected model above by auto_arima\n\ntrain_and_pred(((5,1,1),(1,1,1,7)), aic_bic=False).rmse()","54182443":"#Top performing models from auto_arima and some manually selected neighbouring models balancing AR and MA\n\nsarimax_top_models = [((5,0,1),(1,0,0,7)),\n                      ((1,1,0),(1,0,0,7)),\n                      ((5,0,0),(1,0,0,7)),\n                      ((1,0,0),(1,0,0,7)),\n                      ((0,1,0),(2,0,1,7)),\n                      ((1,1,0),(0,1,0,7)),\n                      ((1,1,0),(1,1,0,7)),\n                      ((1,0,0),(4,0,0,7)),\n                      ((0,1,0),(1,0,5,7)),\n                      ((5,0,1),(1,1,0,7)),\n                      ((3,1,3),(1,0,0,7)),\n                      ((5,0,1),(1,0,1,7)),\n                      ((5,1,4),(0,1,0,7)),\n                      ((0,1,0),(2,0,1,7)),\n                      ((2,1,0),(3,1,0,7)),\n                      ((2,0,2),(1,0,0,7))]","594a0b5e":"# %%time\n# #Training top models on (Train+Validation) set and predicting with rolling forecast on 2nd Validation set\n# sarimax_top_val2 = {'normal':[],\n#                     'boxcox':[],\n#                     'lr':[]}\n\n# #Top selected models from auto_arima\n# for x in tqdm(sarimax_top_models):\n#     a = train_and_pred(x, aic_bic=False, split_type='val2')\n#     sarimax_top_val2['normal'].append(a)\n#     b = train_and_pred(x, aic_bic=False, split_type='val2', series_type='boxcox')\n#     sarimax_top_val2['boxcox'].append(b)\n#     c = train_and_pred(x, aic_bic=False, split_type='val2', series_type='lr')\n#     sarimax_top_val2['lr'].append(c)\n\n# #Top models from grid search\n# for x in tqdm(top_models_grid[top_models_grid[2] == 'normal'][0].values):\n#     a = train_and_pred(x, aic_bic=False, split_type='val2')\n#     sarimax_top_val2['normal'].append(a)\n# for x in tqdm(top_models_grid[top_models_grid[2] == 'boxcox'][0].values):\n#     a = train_and_pred(x, aic_bic=False, split_type='val2', series_type='boxcox')\n#     sarimax_top_val2['boxcox'].append(a)\n# for x in tqdm(top_models_grid[top_models_grid[2] == 'lr'][0].values):\n#     a = train_and_pred(x, aic_bic=False, split_type='val2', series_type='lr')\n#     sarimax_top_val2['lr'].append(a)","b20a2f11":"# %%time\n# #Calculating rolling forecast RMSE scores of top models on 1st Validation set, for comparison. (20~ MINS TO RUN)\n\n# sarimax_top_val = {'normal':[],\n#                     'boxcox':[],\n#                     'lr':[]}\n\n# for x in tqdm(sarimax_top_models):\n#     a = train_and_pred(x, aic_bic=False, split_type='val')\n#     sarimax_top_val['normal'].append(a)\n#     b = train_and_pred(x, aic_bic=False, split_type='val', series_type='boxcox')\n#     sarimax_top_val['boxcox'].append(b)\n#     c = train_and_pred(x, aic_bic=False, split_type='val', series_type='lr')\n#     sarimax_top_val['lr'].append(c)","bb73a16c":"# #Removing None from results, results with extreme outliers, results with missing predicted values\n\n# sarimax_top_val2['normal'] = [x for x in sarimax_top_val2['normal'] if x!=None]\n# sarimax_top_val2['boxcox'] = [x for x in sarimax_top_val2['boxcox'] if x!=None]\n# sarimax_top_val2['lr'] = [x for x in sarimax_top_val2['lr'] if x!=None]","fa2ce960":"# #Rolling forecast RMSE scores of top models on normal, boxcox and LR series\n\n# sarima_top_list = [(x.model_attribs, x.rmse(),'normal') for x in sarimax_top_val2['normal'] if x!=None]\n# sarima_top_list += [(x.model_attribs, x.rmse(),'boxcox') for x in sarimax_top_val2['boxcox'] if x!=None]\n# sarima_top_list += [(x.model_attribs, x.rmse(),'lr') for x in sarimax_top_val2['lr'] if x!= None]","744b9ae5":"# #Results sorted from best to worst by RMSE scores\n\n# pd.DataFrame(sarima_top_list).sort_values(1)","107497dd":"# #Making dataframes of top models on each series type along with model scores and appending them to a list\n\n# a = []\n# a.append(pd.DataFrame([(x.model_attribs, x.rmse(), 'normal','val2') for x in sarimax_top_val2['normal'] if x!=None]))\n# a.append(pd.DataFrame([(x.model_attribs, x.rmse(), 'boxcox','val2') for x in sarimax_top_val2['boxcox'] if x!=None]))\n# a.append(pd.DataFrame([(x.model_attribs, x.rmse(), 'lr','val2') for x in sarimax_top_val2['lr'] if x!=None]))\n# a.append(pd.DataFrame([(x.model_attribs, x.rmse(), 'normal','val') for x in sarimax_top_val['normal'] if x!=None]))\n# a.append(pd.DataFrame([(x.model_attribs, x.rmse(), 'boxcox','val') for x in sarimax_top_val['boxcox'] if x!=None]))\n# a.append(pd.DataFrame([(x.model_attribs, x.rmse(), 'lr','val') for x in sarimax_top_val['lr'] if x!=None]))\n# top_models_grid[3] = 'val'\n# a.append(top_models_grid)","ba095265":"top_trained_val2 = train_and_pred(((5, 0, 1), (1, 1, 0, 7)), aic_bic=False, split_type='val2', series_type='boxcox')\ntop_trained_val2.fig()","85e86fa9":"top_trained_val2.resid_fig()","989aff77":"top_trained_val2.get_all()","acb8eaf4":"# #Formatting scores and calculating average to select best generalising model\n\n# scores_df = pd.concat(a, ignore_index=True)\n# scores_df['val1'] = scores_df[scores_df[3] == 'val'][1]\n# scores_df['val2'] = scores_df[scores_df[3] == 'val2'][1]\n# scores_df.drop([1,3], axis=1, inplace=True)\n# scores_df = scores_df.groupby([0,2]).last().reset_index()\n# scores_df.columns = ['Model','Series Type','Validation 1','Validation 2']\n# scores_df['Avg'] = (scores_df['Validation 1'] + scores_df['Validation 2'])\/2\n# scores_df['Diff'] = np.abs(scores_df['Validation 1'] - scores_df['Validation 2'])\n# scores_df = scores_df.sort_values('Avg')\n# scores_df = scores_df.round(2)","b10d2350":"# fig = go.Figure(data=[go.Table(\n#     header=dict(values=list(scores_df.columns),\n#                 fill_color='paleturquoise',\n#                 align='left'),\n#     cells=dict(values=[scores_df.Model, scores_df['Series Type'],scores_df['Validation 1'],scores_df['Validation 2'],\n#                       scores_df['Avg'], scores_df['Diff']],\n#                fill_color='lavender',\n#                align='left'))\n# ])\n# fig.update_layout(title_text='RMSE Scores SARIMA',margin=dict(b=0), height=700)\n# fig.show(config=config)","ea3d763e":"#Training best generalising model till now to predict on the test set\n\ntest_final = train_and_pred(((1, 1, 0), (1, 1, 0, 7)), aic_bic=False, series_type='boxcox', split_type='test')","5668d72a":"test_final.fig()","ce8ef4fe":"test_final.resid_fig()","e63ad13b":"test_final.get_all()","12179801":"# #Creating an ensemble of the best models in a list\n\n# scores_df.reset_index(drop=True, inplace=True)\n# test_ensemble = [(scores_df.head(50).groupby(['Series Type','Model']).last()).loc['normal'].index.values,\n#                  (scores_df.head(50).groupby(['Series Type','Model']).last()).loc['boxcox'].index.values,\n#                  (scores_df.head(50).groupby(['Series Type','Model']).last()).loc['lr'].index.values]","15fc52d3":"# %%time\n# #Training the models in the ensemble list to predict on Test set\n\n# sarimax_top_test = {'normal':[],\n#                     'boxcox':[],\n#                     'lr':[]}\n# for x in test_ensemble[0]:\n#     a = train_and_pred(x, aic_bic=False, split_type='test')\n#     sarimax_top_test['normal'].append(a)\n# for x in test_ensemble[1]:\n#     b = train_and_pred(x, aic_bic=False, split_type='test', series_type='boxcox')\n#     sarimax_top_test['boxcox'].append(b)\n# for x in test_ensemble[2]:\n#     c = train_and_pred(x, aic_bic=False, split_type='test', series_type='lr')\n#     sarimax_top_test['lr'].append(c)","28a4b4a4":"# #Models with their RMSE scores on Test set on normal series\n\n# [(x.model_attribs, x.rmse()) for x in sarimax_top_test['normal'] if x!=None]","981c0650":"# #Models with their RMSE scores on Test set on boxcox transformed series\n\n# [(x.model_attribs, x.rmse()) for x in sarimax_top_test['boxcox'] if (x!=None and ~np.isnan(x.predicted).any())]","b5a705b5":"# #Models with their RMSE scores on Test set on LR detrended series\n\n# [(x.model_attribs, x.rmse()) for x in sarimax_top_test['lr'] if x!=None]","8a0376ed":"# #Taking predictions of all the models in a list\n\n# all_pred = []\n# for key,value in sarimax_top_test.items():\n#     for x in value:\n#         if x == None:\n#             continue\n#         if np.isnan(x.predicted).any():\n#             continue\n#         all_pred.append(x.predicted)","93645b14":"#Saving manually in case the time-taking computation was SKIPPED\n\nall_pred = [[538169.296339039,  472647.37845408206,  576275.302895467,  649669.8245450011,  678715.184368176,  679636.3622903939,  769004.9061356927,  571931.2269493527,  520746.886297117,  588627.3728623524,  669731.1369143045,  700168.0598836961,  704609.925047442,  835811.9285784822,  568144.1576755593,  448143.228845646,  664014.272347302,  649699.6102897462,  724834.065246637,  696429.116936515,  873345.6794873938,  530716.0100915818,  463655.9049312095,  664956.18606667,  666141.6915140856,  723494.1497843121,  700118.4645595823,  873237.5589850979,  520021.1000243697,  425127.499532109]\n, [553067.4487768516,  480630.20064410876,  564240.0599785547,  634691.1117343208,  672476.4662604374,  678919.0273557549,  780812.3800457495,  582554.5315090489,  521731.72586360545,  582763.0785912204,  676304.9435025617,  699520.9180088551,  703564.409614038,  818460.8002988051,  578379.2426597459,  470832.9908973022,  643761.9805416813,  660485.4401467816,  722675.8676362758,  701800.5361184613,  864278.0823532302,  542905.6253892162,  459977.7448273293,  662781.2060944121,  664907.1642697613,  727982.3777073738,  699614.7304072687,  876620.961957828,  516321.709027753,  432728.2639609]\n, [572328.9030389525,  490593.93031862593,  565106.2572133985,  638657.542698048,  668684.2643453919,  683596.9116216521,  760574.3146353568,  599882.4308863136,  526186.5023143083,  588016.8502845285,  673603.5032407119,  683109.8100053291,  715228.1009897675,  808796.8454219179,  594373.6344964767,  478163.179498207,  645383.7296268827,  656899.1631252733,  718027.8906676488,  704632.1634951205,  854058.1098891377,  554920.8755706808,  477842.5258215334,  651038.6047745846,  672817.5291232929,  720267.5677829974,  709367.6125909211,  866548.31554998,  529015.6035736826,  444519.2478471105]\n, [555344.2533522644,  484668.43186292675,  571750.0956801557,  635315.3658417129,  667912.0077526044,  669743.336630828,  753255.9707510415,  588951.3433416081,  526201.865829121,  574863.3507935182,  674941.2826105213,  679821.290819602,  699074.189864433,  816719.0108830844,  586860.8742009194,  475927.5316139096,  643369.9180431777,  654259.5763267188,  702886.1718881702,  698600.2146670307,  843249.2316596024,  564882.8058952163,  480645.0071296823,  654849.6733610227,  659503.5352564532,  715028.3104682665,  689547.9589708735,  858381.9683456195,  541517.4127327997,  462672.21993711486]\n, [548011.6000685965,  476264.2588428237,  571600.1915780472,  633276.7868491831,  664736.0423954478,  672973.2733202995,  774680.3493922228,  569308.3480072769,  510558.4103204227,  590505.4066852013,  684588.4313415203,  684253.6337099023,  704151.97391196,  825285.1470153244,  565177.2531828578,  468999.7499754024,  645194.1256031852,  666729.4214096487,  707293.6520569711,  707408.439506766,  862309.1478191038,  544705.8482495412,  457280.1998310754,  667542.6816943667,  663080.345246777,  721769.7751529386,  697083.7043262498,  880731.0781565773,  516618.0253822908,  441723.24329857324]\n, [579343.1676272725,  490663.4884913212,  552342.5970229667,  643408.2925819827,  670720.2159503549,  685427.8101524634,  749290.4280183378,  601937.1041650767,  526407.0085477679,  576614.9677864567,  677710.0640695007,  676033.3057162433,  712428.7425259514,  816804.0607791118,  592577.089580348,  492430.64279525675,  630815.3663267234,  672285.9064413926,  702303.6379776709,  712945.6525607477,  838427.7238613942,  569741.4279500949,  484504.7163713506,  648136.2231568391,  671303.8479460153,  713786.9794291969,  702937.0007814813,  864914.251866395,  537395.3235094364,  458610.0076716066]\n, [568603.828657702,  475538.03018878226,  577203.3464017743,  661663.8413339149,  639688.928443648,  704269.9219012808,  750800.8965480884,  593216.5351881152,  515647.10177572543,  584184.3019450072,  698430.6348498722,  649118.6574944463,  740049.8666754216,  818196.9671618718,  567703.7013227757,  469755.3121365148,  632261.0835958666,  694784.6605306823,  689933.4175401204,  732499.266986551,  857237.2253457073,  545897.946868791,  466903.62884108553,  647367.5626892883,  685085.0397207112,  701258.6182182076,  714587.0278234476,  868877.9568697064,  517105.9001007572,  445996.69733946974]\n, [574716.484604419,  484118.17358334176,  549242.1569658557,  642278.157973054,  672963.9764382057,  684299.9836598729,  744346.2554021153,  603459.9833009696,  518495.17176841764,  573314.0627263102,  679425.1950268486,  687753.6245454281,  712542.5981449465,  797255.2787455319,  601279.5045636916,  481349.32839022507,  633083.2025501813,  668601.8085334775,  717123.3351183822,  707977.418113916,  841553.0234550047,  568308.0308938557,  482409.0538709022,  642047.492829866,  676711.3067969031,  719230.3023934137,  708904.7736548628,  861865.3938589186,  543180.0385382569,  457642.4201525504]\n, [573164.356577939,  483227.9439955523,  543990.6011201655,  640622.233728076,  674270.3409216161,  683164.9968729316,  740297.0377607701,  604613.1125757959,  517881.98346948344,  566863.6153360506,  678474.754275942,  688493.502925486,  712307.6533332838,  790716.682824359,  604696.7287453864,  481500.0575105747,  629873.6702593559,  667452.6943716325,  716955.8317960734,  707674.0083589269,  838281.9637266619,  570983.9469427705,  483273.4936432859,  640299.8672526713,  676517.8373970756,  719074.698913267,  708872.740674624,  859987.9589242836,  545273.8472562485,  459126.48458318796]\n, [570618.6840034818,  480916.65276923537,  547478.8688370764,  639154.1881419921,  669452.9491201915,  680869.3721939855,  742165.2598012908,  598422.8039925412,  514630.3602162568,  571480.0505751675,  676207.6110391137,  684438.7580083266,  709193.5863419559,  795496.0229270303,  596294.5587641447,  477667.2676679947,  631905.7395733473,  665691.1954264102,  714579.9194499253,  705198.49463121,  840674.721994564,  564335.3169874743,  479411.46326961607,  641832.560934428,  674517.9441280672,  717566.5246377861,  706875.5324762978,  861326.1546107476,  540618.4818508491,  455868.36754136905]\n, [532567.7334912753,  468316.4917985418,  579005.3633711151,  652757.2265418682,  680936.4685952791,  680112.6350804174,  770544.9488093997,  562265.1512331621,  514177.81064056663,  589637.3834801143,  665546.5775324184,  703735.9641878214,  703417.412678218,  838143.900200967,  563086.484774579,  445156.4103366907,  664316.541708005,  651774.9699151297,  725194.3109703477,  697373.9866591818,  873736.0258333558,  530712.8140057231,  463382.71897327784,  664477.6840057333,  663427.500380098,  724400.038000822,  700306.3771286121,  873708.0633364252,  524574.5418505494,  429063.47986773954]\n, [547578.6479268052,  477009.62975176907,  564690.457960815,  634430.4524260338,  673817.2352162666,  679651.5648802433,  786956.8289900919,  572087.4417154322,  514891.31463111506,  584326.1299878577,  673542.531491097,  704460.7235649123,  701946.2655963015,  818421.4053863684,  570997.8764596685,  470134.93553247047,  639977.6634097705,  663235.8711950345,  723722.4189555929,  703528.0758667336,  863634.4406612206,  543377.879435224,  457972.4340280298,  662148.9673908169,  662320.0848834498,  730070.6839871153,  700090.9248489446,  877785.6684183173,  521073.8324557497,  437111.1538077942]\n, [575691.4951800206,  482276.3899298861,  548782.1809205026,  644257.9280827078,  675928.760857903,  683218.6084921743,  743664.7103714866,  601017.5762148818,  522342.5092677441,  566979.321198046,  679015.5732510551,  690969.4406265292,  707554.6433762222,  804692.4353246742,  594053.6264575233,  487975.4696557953,  624144.9845826662,  674226.9228182755,  712397.7625710145,  711589.1116445939,  837503.9055491864,  569572.1310468068,  482086.2549887048,  642648.8375738295,  673076.4365898536,  723774.5637587033,  704354.4879254665,  864923.3573298517,  541620.5674094752,  457697.7795325288]\n, [573496.8361492082,  481022.0225527562,  543545.2329563807,  642580.382995658,  676734.6818146758,  681546.1884334298,  741748.3756871971,  601634.3197827344,  520726.7713749276,  559502.218968291,  679661.8440965173,  692311.1727546953,  707270.9066596315,  797365.1481444427,  597358.484535656,  488542.7665026905,  618769.5035418957,  673321.7066182874,  711993.1817416493,  711362.8111904514,  833755.9599819372,  572783.7088653288,  482555.22476927354,  640424.6554258862,  672654.0849390747,  723605.1974846898,  704207.12199477,  862448.2338065748,  544086.4740622574,  459832.5786386382]\n, [553766.0858266263,  488267.47286240937,  575921.8207877512,  633489.6023630861,  667943.0268979538,  669628.878467528,  754068.2208313864,  575845.7777814585,  526720.648476044,  583668.9472338989,  670101.8621801501,  680671.9985543337,  707230.6953270952,  815402.9681462235,  596592.8698279691,  471077.09310387156,  660075.8443038393,  639934.0860598702,  711921.6567042964,  689435.9913374059,  848795.9452784993,  561852.2257849622,  493850.9951483097,  649954.4353789653,  661284.3538546858,  703928.5760613811,  697418.6633721062,  846065.3667033773,  555330.3319567319,  466202.44735394657]\n, [570238.1059005266,  480251.9467210428,  542818.2707648152,  637563.0836463921,  673982.8260583836,  678937.4038971828,  740393.7537779863,  596160.3775587984,  519228.2634192721,  561709.9337977897,  673345.5062724814,  689488.0988597731,  704117.1625665117,  796061.6886067166,  591988.1850989689,  485229.4394821169,  619092.8191145683,  669103.5412247763,  709698.6406744207,  708412.6471843112,  833528.9661326164,  567859.6756609291,  479338.225943821,  640856.1128532601,  669628.6122651584,  721923.3123241884,  702209.4436465406,  862060.3007876388,  541009.1063759491,  457295.6231772516]\n, [570281.7681864804,  478930.53777886624,  542575.8336606601,  639641.2316747975,  673867.9106431169,  678805.0752639514,  740111.2579175534,  597277.1711556538,  517941.4957201646,  559160.6444452048,  675602.6776811603,  689319.6520390469,  703992.0615151384,  796228.0772525702,  592134.834555057,  485056.68411912833,  618519.5490447857,  669794.5813889041,  709504.9610080222,  708457.8818822281,  833446.8078735424,  567968.0322320405,  479301.1510859951,  640758.9848637958,  669769.2135767932,  721910.8886603123,  702167.152771926,  862083.6030922596,  541002.7834203709,  457300.6650711169]\n, [567357.5601132794,  485725.611290193,  564946.0162382013,  640794.2487079463,  671446.4784675548,  686325.981018359,  763924.457072111,  590546.8024130457,  519966.0928756448,  588209.1387314446,  671480.3272221461,  686511.2021239717,  716702.86420751,  807765.565137006,  587395.2982619593,  479319.5147418485,  639616.8829335679,  658740.5924953739,  718080.0955191501,  708103.9107362351,  852968.3152120685,  555051.7658382991,  476814.75684637984,  648167.5236289899,  671544.237270898,  721830.2407623769,  711812.8797071897,  865482.0163330929,  533545.9127568357,  448570.5606178581]\n, [578670.2830122077,  487980.0962177963,  546959.3796634275,  640395.5191828146,  677194.5548620749,  683531.5984431553,  743156.3528733915,  602464.5894974534,  520619.3943001179,  567102.4122905304,  675608.8696680001,  692126.6893263212,  707985.6478318723,  794769.9720895052,  597971.4499445597,  491129.11906952853,  619898.6022036008,  670234.773066819,  711286.353163863,  710364.5106078325,  831899.5600022619,  572567.495381521,  483253.83521605044,  639448.5575229507,  670229.3379316955,  721473.5887075807,  704231.554547169,  859634.4951650188,  544876.8736412914,  460092.8209378612]\n, [565314.9184040272,  484063.1739906845,  541206.918773543,  656816.0357683583,  650842.6336700626,  695601.3902810122,  737955.4447021919,  594810.1656694057,  517206.02567918494,  563419.3588121952,  683953.0753782239,  683038.3133945204,  706864.2395619467,  797636.6169016038,  589628.7693886878,  485444.9411504024,  614846.8734284686,  677386.376244084,  702194.2343263414,  712340.7688014895,  832876.799985817,  565744.9027211132,  481498.4288371758,  636646.3659162885,  677470.1895050532,  714961.2849906416,  706084.802882003,  860453.6743999989,  540946.0810647514,  456451.9327695804]\n, [565411.3019276479,  483866.19919640524,  536479.0519603562,  656949.3262902519,  650344.7818416471,  686821.1623727435,  740084.5033616337,  599743.8678022705,  514581.50839072186,  558629.200759403,  694642.6828527086,  665295.6608346096,  711558.8309868182,  789875.0151541368,  586657.0502725489,  485976.1258008578,  611909.5610626327,  680730.5710058274,  704348.9382908705,  714123.6929688874,  828525.4028622337,  563055.8605458251,  480012.7694988834,  624367.9605258186,  672431.0186954141,  714238.3802807002,  702975.5509468982,  849030.230162213,  543470.2566104517,  454797.65372214385]\n, [551485.7582168678,  484797.7576037137,  574279.6326426578,  636026.6915228424,  669080.3520246419,  670146.5935092,  753815.5206690746,  581111.2766403493,  524312.6201947408,  577017.8577185513,  670795.8297997364,  681583.8622992719,  696955.064531606,  816769.5647246627,  583235.1274678777,  475237.9974250959,  642717.7935984237,  653800.2329758258,  701407.0247490399,  699153.9757672467,  839320.325593707,  564851.2401035347,  482258.54675381124,  653478.9928000426,  656485.5020526106,  714638.8642739374,  688711.9219616082,  856946.2413155764,  545353.5590061658,  464704.42965656164]\n, [543800.740959087,  475509.54615985276,  571579.3117824348,  633217.7312172557,  664444.8802815268,  674066.9296602804,  780511.3852067337,  560947.6054458689,  506062.1224394514,  593401.5607335186,  682542.325615062,  689372.9410209395,  701827.9502885883,  827663.5243257191,  558964.284785285,  469079.1648883046,  642775.4465747839,  668239.0718218744,  708337.8858222204,  708652.4655090517,  863925.5445906341,  544190.0068348584,  457180.4640837844,  666269.1199614621,  661622.2433100648,  721791.1823163619,  698290.4867025592,  882430.4663235209,  522160.241440528,  443972.08369073545]\n, [566643.8103123811,  485043.8327747854,  542724.7502254263,  654241.9432998487,  648920.2254429667,  695746.2324564134,  736728.2483183579,  593795.1049699516,  515499.6623619259,  560071.6395777275,  694169.6527447123,  672063.5814263468,  714843.0834584027,  797478.7005929205,  584986.2080567868,  489663.7786695153,  614436.1617584829,  676487.5862319788,  697156.2537271893,  715113.6515861596,  833824.5521163502,  563023.2985367649,  484177.803424303,  636067.5360069614,  676148.1950365033,  711334.3989383805,  707491.9402559362,  861810.921085008,  539355.5320114607,  459057.0091023812]\n, [579926.7620858608,  485123.71068965504,  547845.3990345667,  645201.1957319914,  668719.6303454236,  689414.0864762455,  739946.1638577302,  604140.9070397662,  520770.71616674814,  567718.2555875673,  681492.3494992291,  675109.7462489237,  710749.1410546459,  804073.2134998529,  591231.4148364601,  492169.635283215,  618101.1756872075,  676413.7461650525,  699127.8196366736,  714848.9318778883,  833429.7206643636,  568602.1709246014,  485462.9587432937,  634981.5071613655,  676246.1314451551,  712015.5112834938,  707087.5002000371,  862721.7246362765,  541063.2136098866,  460312.08428024367]\n, [578973.6346115347,  484975.5525807626,  546216.5597252399,  644339.2574880259,  668593.657594039,  688508.6862763803,  740917.9754246764,  603973.1842099727,  520311.2582451109,  566364.9241810918,  682720.2306732484,  676071.4636036623,  711111.9497615979,  801643.2731256271,  591982.3400177617,  492228.19008447736,  617257.563622328,  676207.0642220067,  698964.0150426937,  714820.1799888111,  833253.9184579268,  569051.7588425167,  485442.96783428796,  634863.5257458093,  676240.4122842271,  711995.4166026994,  707071.9619328587,  862756.2933688996,  541345.5529287225,  460630.2050736169]\n, [581324.0488280631,  495888.06723259157,  560549.556262464,  644235.1290228784,  665320.8057303254,  683230.1348256322,  754093.4921877148,  600561.5746570326,  522733.43758622144,  574275.7464309147,  679971.920769406,  679865.9589265705,  704801.5817819312,  805698.4232081188,  592343.7036889682,  499090.1121744162,  623339.9464236603,  676674.9025439459,  701770.4555962154,  709999.6365668622,  838665.1229271136,  569117.7960723898,  483981.28918792435,  641632.2292082543,  671516.006673379,  713466.5594272364,  703489.3022181412,  864929.0285843465,  543030.3500290142,  464069.3270612596]\n, [583433.558173317,  491598.9642039728,  547019.9012276541,  641992.5698422418,  670155.0439486479,  693823.6436655385,  722638.9076738971,  608730.9480723124,  525321.863651913,  567441.4752985431,  679060.4565813935,  671322.3894653143,  708763.5733918662,  801145.2826792842,  596549.5232118987,  497245.0004445325,  617640.5847624935,  674330.7156009518,  695149.0934446133,  713611.9398679234,  829171.175378786,  574664.8972062131,  490660.65898529324,  634245.963822113,  673824.2915142181,  711328.9481698611,  701531.2995757124,  861241.9649214356,  546628.7083690463,  466332.89798645565]\n, [577578.6242873674,  484500.5652380709,  545087.416002337,  643073.4688859037,  668629.3710074436,  687674.3904827064,  742829.4956762823,  603015.0463514948,  519709.83361716435,  564690.2705786456,  682955.6683841384,  677343.8685743293,  711100.2282758421,  800090.104827746,  592760.0228897054,  492233.1140079197,  614817.7555381042,  675769.3544911833,  699052.2130007566,  714800.985111807,  832137.3966514589,  570910.4267208637,  484977.7048240875,  633661.7445938227,  675535.1912153092,  711985.0694742565,  706769.026145722,  860830.8658553592,  543119.2847041088,  462189.0132749044]\n, [575071.7915208398,  484883.52403141634,  544020.1562624733,  638283.4963481687,  672877.1086360579,  687777.8408919995,  744322.9200518052,  599023.061332728,  516200.1303188472,  562049.5341016804,  681685.8717225143,  681954.2746122506,  709910.677328053,  800697.595843038,  592175.1003344437,  490681.5884119326,  615583.9330945202,  677383.0690673703,  704607.8710605282,  714014.5085164482,  833320.264095432,  570490.5824417091,  481371.58014649554,  634624.2833166486,  676243.9554091765,  712002.4512578138,  707068.3740552858,  862653.8013397385,  546037.339384777,  462668.50468258193]\n, [579812.2286959301,  490235.4874551235,  538201.3396592907,  640829.0375265306,  671055.0601366473,  690726.3782148446,  715385.2433616836,  607325.6197281255,  523948.40946368413,  562720.190170704,  680756.9380602295,  675855.100249203,  709142.0337748306,  797270.2393490114,  597951.4281944978,  497094.1099779984,  618789.4605063605,  673868.5820237012,  695109.1761740226,  713591.0927534794,  828183.7075600231,  576741.9492414464,  491560.9783063103,  635052.5336876241,  672779.8597717688,  710730.8019576953,  704104.1246875662,  862434.475993629,  550744.2363999332,  469279.5646864849]\n, [581603.7489517694,  488144.00120139896,  546389.1754266389,  640648.6524901695,  665195.0060465302,  685420.1494426006,  740075.7448129453,  607462.3768867557,  523667.85180987936,  563977.4264117652,  680925.8975561111,  673912.6537172738,  708968.3523279227,  797000.822025904,  597685.6547694138,  496971.5094103282,  613343.5104429664,  674049.7049426624,  694906.8855007796,  713513.4499362749,  829847.9039894457,  575297.029659812,  490690.0558636297,  633981.1752782167,  671152.571596536,  711598.1732227812,  703419.1386593349,  864554.3604934132,  547698.3202774422,  466189.65646136313]\n, [577819.2257207022,  484513.31187654583,  545153.9261121536,  643255.050307633,  668700.5486549989,  687788.4797075705,  742470.0521959774,  602837.0431331261,  519579.6030607115,  564509.7572452627,  683088.4324184946,  677584.300825449,  710969.3275390636,  799767.7658822065,  592746.8233751081,  492231.6196545063,  614565.9283009318,  677812.4440225107,  702952.350155761,  715606.5583817669,  832279.6746707099,  571706.0232465733,  482475.4804495116,  634124.0141523157,  675953.6383566436,  711984.2151183158,  706900.3989184169,  861691.3707785181,  545710.4651454893,  461697.14402737987]\n, [577213.7251457034,  488146.6397672072,  546336.0134041935,  640428.5754529781,  665055.2981832423,  685238.3139817254,  740504.4000027983,  606694.1496356124,  523691.49405685195,  564170.3961027024,  683361.1219473283,  678821.9615775306,  708172.6931817618,  794922.5189718473,  597818.3054260339,  497060.4276357671,  614145.0475264875,  673891.4593616679,  695064.717279599,  713503.4489603179,  829158.535895252,  576166.8095125463,  490373.5168173711,  633664.7064092037,  673637.8872990742,  711602.8965921238,  702217.9605810955,  861593.3422818093,  546924.9999356976,  463259.43714283855]\n, [579530.3596113469,  489067.78995132266,  538897.332058291,  637938.7553067873,  670798.0199771113,  692108.7407607867,  720606.3226789783,  607905.9804067693,  524818.3200591769,  563561.528113705,  679256.2868438106,  672974.271913701,  708401.2257133863,  799672.2602089257,  597403.3942431206,  496461.74703917105,  616634.6693201695,  675421.9412863003,  694998.5832983888,  715717.772719095,  825130.5901846393,  575998.3621082613,  491397.9438015807,  632483.3680362821,  672771.1788603979,  711675.6644052013,  701144.0675127842,  863138.0308455635,  541784.4578436265,  1.0]\n, [567440.0262471181,  471946.5542686427,  582492.3878524891,  664889.4515243642,  632546.9996696521,  712414.4106064951,  741825.3607327823,  580769.8745169822,  511945.914978075,  585487.3175840032,  700955.470144795,  641098.6089066763,  735378.6597771306,  822770.7830884503,  563676.870573938,  472252.64247805317,  628215.1135769851,  689962.9352515909,  669797.5775856473,  734410.7768633884,  858797.9557015456,  543069.5937226714,  472662.3117737677,  640367.2823704836,  681410.4820339688,  692483.4879978287,  719629.3483132265,  881477.7924973662,  522008.9022788477,  449101.11605213897]\n, [538168.1704864606,  472646.9887525539,  576275.1857957073,  649670.2049029294,  678714.7487539336,  679636.3268831688,  769005.1723535382,  571932.6855799779,  520745.42201751313,  588625.5241870236,  669734.0812561769,  700165.703601941,  704611.1780985363,  835810.7850795253,  568145.5785770423,  448141.3717125892,  664015.4571051507,  649699.2374926533,  724834.4982983236,  696428.4159407737,  873346.0076267376,  530715.5891441605,  463656.2474834712,  664955.4394294146,  666142.9749923421,  723493.5249249882,  700118.320646305,  873237.9911067003,  520019.39049228095,  425128.8179100345]\n, [553064.1764756889,  480626.9963108024,  564242.1592786352,  634694.8214731759,  672477.3432596087,  678919.1466825063,  780810.7053758916,  582554.4534247976,  521729.0881383793,  582761.1943928953,  676308.5623349968,  699517.1306382145,  703566.5565347731,  818462.1608498392,  578380.3084792005,  470825.4783310699,  643766.5650022823,  660484.2149107696,  722675.962937031,  701799.0296658353,  864279.6598635208,  542903.4928393827,  459978.145141107,  662780.8652949936,  664909.2693808326,  727980.8094497889,  699614.2964264418,  876621.2257087363,  516319.4080246008,  432729.2550187169]\n, [559027.1065883308,  489409.6402299615,  572836.2509938416,  633790.2951807512,  668922.4421290933,  671938.4237803125,  755505.6678358983,  588333.5004286602,  532596.268299452,  581446.1394065669,  669144.2912573852,  682818.4330142963,  701470.2312724052,  817855.7824250062,  590067.3732911109,  480993.73702115275,  646925.3265966119,  652410.042284705,  706635.0570999895,  700718.9003122271,  846287.7820570146,  568234.8115097436,  486955.68501234846,  657464.4677759341,  659666.6336394006,  717477.5958003501,  694240.3730349002,  859256.2612678689,  548363.5998529604,  467334.1548388279]\n, [572324.5203441425,  490587.1390474264,  565103.1155281207,  638662.24921876,  668687.0821443801,  683596.3100228315,  760575.5706204849,  599883.7601197322,  526182.5666025524,  588006.2861675649,  673607.9492899124,  683112.0952389971,  715225.0660223159,  808800.8553045791,  594373.6374872765,  478155.6252632977,  645381.1827591271,  656901.8732633574,  718030.2266073634,  704628.9164476243,  854059.9268951017,  554918.4571082188,  477839.9220542359,  651035.8946375907,  672820.6616944415,  720269.0654181744,  709363.7654270617,  866549.9673882358,  529010.9091059866,  444516.10061127297]\n, [558001.9084776294,  487658.3887651104,  574572.5214551644,  638007.6495350252,  670546.1699050539,  672460.160192567,  755610.7830277783,  591373.0136937721,  528866.4664106998,  577865.3671740423,  677231.3513712374,  682469.3886397934,  701608.5618061007,  818948.0841658235,  589893.4493385302,  479306.4172266703,  645989.0045455595,  656980.4024117545,  705426.6554151771,  701247.4087002737,  845398.4217955123,  568150.7043635616,  483980.9928444961,  657502.3707351685,  662239.7109544377,  717529.1888461557,  692288.257712961,  860425.4317929761,  545072.9676867636,  466181.2696713412]\n, [556114.7280141719,  494643.7859229374,  571173.3932149088,  639764.2727976231,  665573.4900872408,  671296.2830132394,  752307.8845951124,  592220.1421783429,  528572.1837973911,  582466.0020626088,  679309.931833698,  670174.050078447,  704712.918361871,  708882.4221744386,  587272.2123069837,  481348.78002889745,  645726.9170825023,  658523.6679174477,  697716.1843168872,  705624.2663529918,  844426.7805595109,  718621.4986763108,  483778.827275694,  658691.630417613,  722273.6523645127,  712397.6230694922,  694745.7189126968,  862830.8297811728,  544629.0286158954,  469971.8457561093]\n, [575254.8968630387,  491948.82348348515,  563285.785655195,  631260.936387493,  656469.2463437628,  672123.29822464,  757162.408705644,  600226.1521341384,  526619.1061724639,  579674.2442716629,  680945.3364528813,  673242.6766282432,  700638.8821091969,  808600.8885338567,  592658.4326549014,  492238.6770506074,  632690.2025534734,  668564.765544406,  698537.4960581613,  705630.1637342622,  842546.4344996186,  571387.0790521892,  482854.7872691767,  652315.4098976646,  667448.2222273595,  713074.6336324137,  697989.704600813,  864220.9843678614,  542379.7641369879,  465775.63242193655]\n, [548787.1997090465,  477115.6914376789,  572532.8763056928,  634204.6581510813,  665686.6216248086,  673917.059309984,  775562.541288632,  570102.4015895824,  511407.61968577304,  591486.6156581596,  685460.1953875009,  685252.944910525,  705200.3221257998,  826317.5983135549,  566123.766703254,  470033.33253797644,  646255.4405299406,  667746.5007829082,  708339.9826084881,  708501.9610694818,  863357.2349816053,  545769.1068226804,  458370.04771436704,  668664.6711446887,  664171.8847102735,  722860.0773890135,  698192.1954605761,  881797.7602042174,  517743.06508087256,  442871.28644658823]\n, [582747.8667609834,  498020.15470546973,  563060.9629622428,  642453.7210321665,  666680.7264249253,  682262.3482908648,  756836.9451520232,  605610.0445819027,  525201.9408300878,  575554.5114342963,  681552.6734279589,  677560.9266230594,  708851.3316747462,  808407.8239356804,  598780.1055169562,  496024.90198630525,  627191.614063607,  673598.5229663379,  701553.2204131129,  708729.515338305,  841278.4286597916,  568900.1601758841,  481098.3001805217,  648859.2542829416,  670526.752255039,  714794.9226359685,  702070.687134127,  865570.9717035136,  538207.2007794501,  461751.7817433475]\n, [579486.4676286895,  491034.5350502419,  553117.6100208282,  643760.8392417299,  671057.5603930107,  685848.5054154415,  749193.0683024882,  602257.0439402743,  526666.243006327,  576814.7809261967,  677942.7162253951,  676258.2557221162,  712686.2359355068,  816970.3426822531,  592831.1725486983,  492654.7436022635,  630975.6071655164,  672440.733190268,  702485.7516939704,  713157.2878059143,  838571.4844459251,  570014.4486822523,  484738.46362259483,  648276.7051000546,  671458.3705296246,  713929.3596498892,  703106.3586814974,  865024.605336451,  537646.3044020436,  458819.6755846968]\n, [569732.672352952,  475593.42281481763,  581456.471613381,  661672.2859485411,  639688.5455850294,  704272.4565820026,  750833.137570908,  593219.2249175528,  515649.8600288895,  584180.6889362595,  698356.144046869,  649111.8059645691,  739946.3991867042,  818203.6122356841,  567746.3646503162,  469777.79024572397,  632277.0612945087,  688114.2976693076,  677295.5491189533,  732548.7744607403,  857234.9834734831,  545918.8453779279,  466908.0010139599,  647344.7155370079,  683788.1661368004,  704114.7557662869,  705253.643600616,  868933.8044136879,  513078.35514523997,  446517.2242739651]]\n\nall_pred = [np.array(x) for x in all_pred]","2c56728c":"#Creating a Metrics instance of SARIMA ensemble\n\nsarima_ensemble = Metrics(test_df.new_cases, sum(all_pred)\/len(all_pred),_)\nsarima_ensemble.model_name('SARIMAX','Ensemble')","a6d837a8":"sarima_ensemble.fig()","ad2ff296":"sarima_ensemble.resid_fig()","81110e5f":"sarima_ensemble.get_all()","9498d521":"#Training SARIMA model to predict the future, AR=1, I=1, S=7, S(AR)=1, S(I)=1\n\nset_inferred_index(df)\nmodel = SARIMAX(df.new_cases, order=(1, 1, 0), seasonal_order=(1, 1, 0, 7))\nmodel = model.fit(maxiter=200, disp=0)","a85980a4":"#Getting predictions plus upper and lower intervals for them\n\nsf_sarima = model.get_forecast(100).summary_frame()","677768a7":"fig = go.Figure()\nfig.add_scatter(x=df.index[-150:], y=df.new_cases[-150:])\nfig.add_scatter(x=(list(sf_sarima.index) + list(sf_sarima.index[::-1])),\n                y=(list(sf_sarima.mean_ci_lower) + list(sf_sarima.mean_ci_upper[::-1])),\n                fill='toself',mode='none', fillcolor='rgba(61, 64, 91, 0.5)')\nfig.add_scatter(x=sf_sarima.index, y=sf_sarima['mean'], line_color='#390099')\ncustom_legend_name(['Historical New Cases','Confidence Interval','Forecast'], fig_in_func=fig)\nfig.update_layout(title_text='SARIMA 100-day Forecast with 95% Confidence Intervals')\nfig.update_traces(hovertemplate='<b>%{x}<\/b><br>%{y}<extra><\/extra>')\nfig.show(config=config)","e049f6a7":"#Training a Holt Winters model with \"averaged\" value parameters\n\nhw_params = ('add', 'add', True, 0.5, 0.5, 0.5, 0.5, 7)\nactual_hw, predicted_hw, model_hw = get_model_pred(hw_params, aic_bic=False, algo_type='hw')\nhw_trained = Metrics(actual_hw, predicted_hw, model_hw)\nhw_trained.model_name(hw_params,0)","9861e3bb":"hw_trained.fig()","c04b5090":"hw_trained.resid_fig()","afe68a6b":"hw_trained.get_all(algo_type='hw')","a2f5df7e":"#Creating a grid of parameters for Holt Winters\n\ntrend = ['add','mul',None]\nseasonal = ['add','mul',None]\ndamped = [True, False]\nphi = [0.25,0.5,0.75,0.99]\nalpha = [0.25,0.5,0.75,1]\nbeta = [0.25,0.5,0.75,1]\ngamma = [0.25,0.5,0.75,1]\nseasonal_periods = [0,7]\n\nhw_grid_params = []\nfor t in trend:\n    for s in seasonal:\n        temp_s = s\n        for d in damped:\n            temp_d = d\n            for p in phi:\n                temp_p = p\n                for a in alpha:\n                    for b in beta:\n                        temp_b = b\n                        for g in gamma:\n                            temp_g = g\n                            for sp in seasonal_periods:\n                                b = temp_b\n                                p = temp_p\n                                g = temp_g\n                                s = temp_s\n                                d = temp_d\n                                if not d:\n                                    p = 0\n                                if not t:\n                                    b = 0\n                                    d = False\n                                    p = 0\n                                if (not s or sp == 0):\n                                    g = 0\n                                    sp = 0\n                                    s = None    \n                                hw_grid_params.append((t,s,d,p,a,b,g,sp))","2287dc1f":"#Removing duplicate parameters\n\nhw_grid_params = list(set(hw_grid_params))","937f33f2":"#Function to grid search Holt Winters algorithm\n\ndef grid_search_hw(param_list, series_type='normal', split_type='val'):\n    grid_hw = []\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\")\n        for x in tqdm(param_list):\n            try:\n                actual_hw, predicted_hw, model_hw = get_model_pred(x, aic_bic=False, algo_type='hw',\n                                                                   series_type=series_type, split_type=split_type)\n                hw_trained = Metrics(actual_hw, predicted_hw, model_hw)\n                hw_trained.model_name(x,0)\n                if True in np.isnan(hw_trained.predicted):\n                    continue\n                grid_hw.append(hw_trained)\n            except ValueError: #Negative values in series (lr) do not work with multiplicative trend or seasonality\n                pass\n    return grid_hw","82dec9bd":"# %%time\n# #Grid searching Holt Winters with 30-day rolling forecast on all three series\n\n# hw_trained_grid_normal = grid_search_hw(hw_grid_params)\n# hw_trained_grid_boxcox = grid_search_hw(hw_grid_params, series_type='boxcox')\n# hw_trained_grid_lr = grid_search_hw(hw_grid_params, series_type='lr')","a3ecf540":"# #Concatenating all the results into a single dataframe\n\n# hw_df1 = pd.DataFrame([(x.model_attribs,x.rmse()) for x in hw_trained_grid_normal if x.rmse()!=0]\n#                     ).sort_values(1).head(100)\n# hw_df1['series'] = 'normal'\n# hw_df2 = pd.DataFrame([(x.model_attribs,x.rmse()) for x in hw_trained_grid_boxcox if x.rmse()!=0]\n#                      ).sort_values(1).head(100)\n# hw_df2['series'] = 'boxcox'\n# hw_df3 = pd.DataFrame([(x.model_attribs,x.rmse()) for x in hw_trained_grid_lr if x.rmse()!=0]).sort_values(1).head(100)\n# hw_df3['series'] = 'lr'\n\n# hw_df = pd.concat([hw_df1, hw_df2, hw_df3])","060689ce":"# hw_df","f2059925":"#Assigning dataframe of top models to variable manually so the time-taking computation can be SKIPPED\n\nhw_df = pd.DataFrame([[('mul', 'add', True, 0.99, 0.25, 0.25, 0.25, 7),20712.180332165215, 'boxcox'],\n       [('add', 'add', True, 0.99, 0.25, 0.25, 0.25, 7),20894.851577673555, 'boxcox'],\n       [('mul', 'add', False, 0, 0.25, 0.25, 0.25, 7),21026.228299640316, 'boxcox'],\n       [('add', 'add', True, 0.75, 0.25, 0.5, 0.25, 7), 21086.6947875702,'boxcox'],\n       [('mul', 'add', True, 0.75, 0.25, 0.5, 0.25, 7),21115.427827668307, 'boxcox'],\n       [('add', 'add', True, 0.75, 0.25, 0.75, 0.25, 7),21198.430465465248, 'boxcox'],\n       [('add', 'add', False, 0, 0.25, 0.25, 0.25, 7),21218.279105715104, 'boxcox'],\n       [('mul', 'add', True, 0.75, 0.25, 1, 0.25, 7), 21485.77810059913,'boxcox'],\n       [('add', 'add', True, 0.75, 0.25, 1, 0.25, 7), 21507.32040751619,'boxcox'],\n       [('add', 'add', True, 0.75, 0.5, 0.25, 0.25, 7),21749.72376906739, 'boxcox'],\n       [('mul', 'add', True, 0.75, 0.5, 0.25, 0.25, 7),21757.825030366934, 'boxcox'],\n       [('add', 'add', True, 0.5, 0.25, 1, 0.25, 7), 21781.887911918544,'boxcox'],\n       [('mul', 'add', True, 0.5, 0.25, 1, 0.25, 7), 21800.801562062374,'boxcox'],\n       [('mul', 'add', True, 0.99, 0.5, 0.25, 0.25, 7),21831.146405051615, 'boxcox'],\n       [('mul', 'mul', True, 0.75, 0.25, 0.5, 0.25, 7),21848.928970832647, 'normal'],\n       [('mul', 'mul', True, 0.75, 0.25, 0.5, 0.25, 7),21854.872397017916, 'boxcox'],\n       [('add', 'mul', True, 0.75, 0.25, 0.5, 0.25, 7),21855.144393002494, 'normal'],\n       [('add', 'mul', True, 0.75, 0.25, 0.5, 0.25, 7),21857.69734678629, 'boxcox'],\n       [('add', 'add', True, 0.75, 0.25, 0.25, 0.25, 7),21859.87279676428, 'boxcox'],\n       [('add', 'mul', True, 0.75, 0.25, 0.25, 0.25, 7),21868.852940747343, 'normal'],\n       [('add', 'add', True, 0.99, 0.5, 0.25, 0.25, 7),21876.565488350803, 'boxcox'],\n       [('mul', 'add', False, 0, 0.5, 0.25, 0.25, 7), 21888.033915979,'boxcox'],\n       [('add', 'mul', True, 0.75, 0.25, 0.25, 0.25, 7),21901.17790621034, 'boxcox'],\n       [('mul', 'add', True, 0.75, 0.25, 0.25, 0.25, 7),21915.888995123492, 'boxcox'],\n       [('add', 'add', False, 0, 0.5, 0.25, 0.25, 7), 21959.961101636818,'boxcox'],\n       [('mul', 'mul', True, 0.75, 0.25, 0.25, 0.25, 7),21969.946942274095, 'boxcox'],\n       [('mul', 'add', True, 0.99, 0.25, 0.5, 0.25, 7),21972.038168795618, 'boxcox'],\n       [('mul', 'mul', True, 0.75, 0.25, 0.25, 0.25, 7),22010.562546185924, 'normal'],\n       [('add', 'add', True, 0.99, 0.25, 0.5, 0.25, 7),22070.34668039192, 'boxcox'],\n       [('add', 'add', True, 0.5, 0.5, 0.25, 0.25, 7), 22082.33072523937,'boxcox'],\n       [('mul', 'add', True, 0.5, 0.5, 0.25, 0.25, 7),22087.648712996648, 'boxcox'],\n       [('mul', 'add', False, 0, 0.25, 0.5, 0.25, 7), 22146.982771968145,'boxcox'],\n       [('add', 'add', True, 0.5, 0.25, 0.75, 0.25, 7),22198.745396344057, 'boxcox'],\n       [('add', 'add', True, 0.5, 0.5, 0.5, 0.25, 7), 22240.578969418544,'boxcox'],\n       [('add', 'add', False, 0, 0.25, 0.5, 0.25, 7), 22251.715603515644,'boxcox'],\n       [('add', 'add', True, 0.25, 0.5, 0.25, 0.25, 7),22260.874550086533, 'boxcox'],\n       [('add', 'add', True, 0.25, 0.5, 0.5, 0.25, 7),22267.027395884914, 'boxcox'],\n       [('mul', 'mul', True, 0.99, 0.25, 0.25, 0.25, 7),22271.401658998955, 'boxcox'],\n       [('add', 'mul', True, 0.5, 0.25, 1, 0.25, 7), 22286.645527798642,'boxcox'],\n       [('add', 'mul', True, 0.5, 0.25, 1, 0.25, 7), 22291.861739448887,'normal'],\n       [('mul', 'mul', True, 0.5, 0.25, 1, 0.25, 7), 22298.36786153884,'boxcox'],\n       [('mul', 'mul', True, 0.5, 0.25, 1, 0.25, 7), 22316.22940227011,'normal'],\n       [('add', 'add', True, 0.75, 0.5, 0.5, 0.25, 7), 22325.18745149854,'boxcox'],\n       [('mul', 'mul', True, 0.99, 0.25, 0.25, 0.25, 7),22335.050437416838, 'normal'],\n       [(None, 'add', False, 0, 0.5, 0, 0.25, 7), 22336.90704182524,'boxcox'],\n       [('add', 'add', True, 0.25, 0.5, 0.75, 0.25, 7),22340.187621136578, 'boxcox'],\n       [('add', 'mul', True, 0.5, 0.25, 0.75, 0.25, 7),22351.993759732097, 'boxcox'],\n       [('add', 'mul', True, 0.5, 0.25, 0.75, 0.25, 7),22366.221821733594, 'normal'],\n       [('mul', 'mul', True, 0.5, 0.25, 0.75, 0.25, 7),22375.719811004143, 'boxcox'],\n       [('mul', 'mul', True, 0.5, 0.25, 0.75, 0.25, 7),22415.16532094281, 'normal'],\n       [('mul', 'add', True, 0.25, 0.5, 1, 0.25, 7), 22470.74257099917,'boxcox'],\n       [('add', 'add', True, 0.25, 0.5, 1, 0.25, 7), 22470.9246036948,'boxcox'],\n       [('mul', 'mul', False, 0, 0.25, 0.25, 0.25, 7), 22497.81588643475,'normal'],\n       [('mul', 'mul', True, 0.75, 0.25, 0.75, 0.25, 7),22513.4803454825, 'normal'],\n       [('mul', 'mul', True, 0.75, 0.25, 0.75, 0.25, 7),22522.323767144033, 'boxcox'],\n       [(None, 'mul', False, 0, 0.5, 0, 0.25, 7), 22549.849723870833,'normal'],\n       [(None, 'mul', False, 0, 0.5, 0, 0.25, 7), 22553.83159072885,'boxcox'],\n       [('add', 'mul', True, 0.75, 0.25, 0.75, 0.25, 7),22578.00314882439, 'boxcox'],\n       [('mul', 'add', True, 0.5, 0.5, 0.75, 0.25, 7), 22605.17687762891,'boxcox'],\n       [('add', 'add', True, 0.5, 0.5, 0.75, 0.25, 7),22611.479010298655, 'boxcox'],\n       [('mul', 'mul', False, 0, 0.25, 0.25, 0.25, 7), 22616.31897540984,'boxcox'],\n       [('add', 'mul', True, 0.75, 0.25, 0.75, 0.25, 7),22628.59582758851, 'normal'],\n       [('add', 'mul', True, 0.99, 0.25, 0.25, 0.25, 7),22678.872820747092, 'boxcox'],\n       [('add', 'mul', True, 0.25, 0.5, 0.25, 0.25, 7),22684.56113894306, 'normal'],\n       [('mul', 'mul', True, 0.25, 0.5, 0.25, 0.25, 7),22690.74526891189, 'normal'],\n       [('add', 'mul', True, 0.25, 0.5, 0.25, 0.25, 7),22701.376417213047, 'boxcox'],\n       [('mul', 'mul', True, 0.25, 0.5, 0.25, 0.25, 7),22704.374929159265, 'boxcox'],\n       [('add', 'mul', True, 0.5, 0.25, 0.5, 0.25, 7),22771.593345491412, 'boxcox'],\n       [('mul', 'mul', True, 0.5, 0.25, 0.5, 0.25, 7),22806.332457612687, 'boxcox'],\n       [('add', 'mul', True, 0.5, 0.25, 0.5, 0.25, 7),22812.201176934097, 'normal'],\n       [('add', 'add', True, 0.75, 0.25, 0.25, 0.5, 7), 22812.236004888,'boxcox'],\n       [('mul', 'add', True, 0.99, 0.25, 0.25, 0.5, 7),22819.614255215787, 'boxcox'],\n       [('mul', 'add', True, 0.75, 0.25, 0.5, 0.5, 7),22833.996968416628, 'boxcox'],\n       [('mul', 'add', True, 0.75, 0.25, 0.25, 0.5, 7),22838.390316054752, 'boxcox'],\n       [('add', 'add', True, 0.75, 0.25, 0.5, 0.5, 7),22839.294043828057, 'boxcox'],\n       [('mul', 'mul', True, 0.5, 0.25, 0.5, 0.25, 7), 22883.74636489252,'normal'],\n       [('add', 'mul', True, 0.25, 0.5, 0.5, 0.25, 7),22919.455075977105, 'normal'],\n       [('mul', 'mul', True, 0.25, 0.5, 0.5, 0.25, 7),22926.846083076256, 'normal'],\n       [('add', 'mul', True, 0.25, 0.5, 0.5, 0.25, 7),22947.984164245587, 'boxcox'],\n       [('mul', 'mul', True, 0.25, 0.5, 0.5, 0.25, 7),22951.522764376943, 'boxcox'],\n       [('add', 'add', True, 0.99, 0.25, 0.25, 0.5, 7),22961.838268069292, 'boxcox'],\n       [('add', 'add', True, 0.5, 0.25, 0.5, 0.25, 7),22963.287571532648, 'boxcox'],\n       [('add', 'mul', True, 0.75, 0.25, 0.25, 0.5, 7),22974.21881902943, 'normal'],\n       [('add', 'mul', True, 0.75, 0.25, 0.25, 0.5, 7),22977.726384124595, 'boxcox'],\n       [('mul', 'add', True, 0.5, 0.25, 0.5, 0.25, 7), 22996.94864516798,'boxcox'],\n       [('add', 'add', True, 0.75, 0.5, 0.75, 0.25, 7),23007.75265635506, 'boxcox'],\n       [('mul', 'mul', True, 0.75, 0.25, 0.25, 0.5, 7),23010.484581076187, 'boxcox'],\n       [('add', 'mul', True, 0.5, 0.5, 0.25, 0.25, 7), 23013.57922637515,'normal'],\n       [('add', 'add', True, 0.5, 0.25, 1, 0.5, 7), 23017.86743686907,'boxcox'],\n       [('mul', 'mul', True, 0.5, 0.5, 0.25, 0.25, 7), 23018.15633717269,'normal'],\n       [('mul', 'add', True, 0.5, 0.25, 1, 0.5, 7), 23022.601434996974,'boxcox'],\n       [('mul', 'add', True, 0.99, 0.25, 0.25, 0.5, 7),23028.001425374503, 'normal'],\n       [('mul', 'mul', True, 0.75, 0.25, 0.25, 0.5, 7),23042.20657757218, 'normal'],\n       [('add', 'mul', True, 0.5, 0.5, 0.25, 0.25, 7), 23044.09126119537,'boxcox'],\n       [('mul', 'mul', True, 0.5, 0.5, 0.25, 0.25, 7), 23046.07329097096,'boxcox'],\n       [('mul', 'add', False, 0, 0.25, 0.25, 0.5, 7), 23088.734622922697,'boxcox'],\n       [('add', 'add', True, 0.5, 0.25, 0.75, 0.5, 7),23108.610331120308, 'boxcox'],\n       [('add', 'mul', False, 0, 0.25, 0.25, 0.25, 7),23117.803302414028, 'boxcox'],\n       [('mul', 'add', True, 0.5, 0.25, 0.75, 0.5, 7),23118.020468040006, 'boxcox'],\n       [('mul', 'add', True, 0.5, 0.5, 1, 0.25, 7), 23177.406984926987,'boxcox']])\nhw_df.columns = [0,1,'series']","01c7149a":"#Checking series type of top performing 100 models\n\nhw_df.series.value_counts()","b36a321b":"%%time\n#Training the top 100 models to predict on the 2nd Validation set\n\nhw_val2_normal = grid_search_hw(hw_df[hw_df['series'] == 'normal'][0].values, split_type='val2', series_type='normal')\nhw_val2_boxcox = grid_search_hw(hw_df[hw_df['series'] == 'boxcox'][0].values, split_type='val2', series_type='boxcox')","2682faf5":"#Concatenating results to a single dataframe, and adding new features to help select best generalising model\n\nhw_top_100 = pd.concat([pd.DataFrame([(x.model_attribs,x.rmse(),'normal') for x in hw_val2_normal]),\n                        pd.DataFrame([(x.model_attribs,x.rmse(),'boxcox') for x in hw_val2_boxcox])])\nhw_top_100 = hw_top_100.set_index([2,0]).sort_values([2,0])\nhw_top_100['Validation 1'] = hw_df.set_index(['series',0]).sort_values(['series',0])[1]\nhw_top_100['Avg'] = (hw_top_100[1]+hw_top_100['Validation 1'])\/2\nhw_top_100 = hw_top_100.sort_values('Avg')\nhw_top_100['Diff'] = abs(hw_top_100[1] - hw_top_100['Validation 1'])\nhw_top_100 = hw_top_100.rename(columns={1:'Validation 2'})","3460aeaf":"pd.set_option('display.float_format', '{:.2f}'.format)\nhw_top_diff = hw_top_100.sort_values('Diff').head(10).sort_values('Avg')\nhw_top_diff","ba600ee1":"#Training the best generalising model to see its resulting graphs and metrics\n\nhw_params = ('mul', 'add', True, 0.99, 0.25, 0.25, 0.5, 7)\nactual_hw, predicted_hw, model_hw = get_model_pred(hw_params,aic_bic=False,\n                                                   algo_type='hw', series_type='boxcox', split_type='val2')\nhw_trained = Metrics(actual_hw, predicted_hw, model_hw)\nhw_trained.model_name(hw_params,0)","a5468917":"hw_trained.fig()","e7bf1aab":"hw_trained.resid_fig()","aea111c5":"hw_trained.get_all()","4faa299d":"#Training the best generalising model on the test set. (The selected model did not converge so a neighbouring model\n#is picked)\n\nhw_params = ('mul', 'add', True, 0.99, 0.25, 0.25, 0.5, 7)\nactual_hw, predicted_hw, model_hw = get_model_pred(hw_params,aic_bic=False,\n                                                   algo_type='hw', series_type='boxcox', split_type='test')\nhw_trained = Metrics(actual_hw, predicted_hw, model_hw)\nhw_trained.model_name(hw_params,0)","592fc1f0":"hw_trained.fig()","484c6626":"hw_trained.resid_fig()","b741b284":"hw_trained.get_all()","950116d9":"#Training the best models\n\nhw_top_diff = hw_top_diff.reset_index()\nhw_test_normal = grid_search_hw(hw_top_diff[hw_top_diff[2] == 'normal'][0].values, split_type='test', series_type='normal')\nhw_test_boxcox = grid_search_hw(hw_top_diff[hw_top_diff[2] == 'boxcox'][0].values, split_type='test', series_type='boxcox')","cea3318b":"#Adding predictions of best models to a list and creating a Metrics instance for graphs and scores\n\nhw_all_pred = [x.predicted for x in hw_test_normal] + [x.predicted for x in hw_test_boxcox]\nhw_ensemble = Metrics(hw_test_normal[0].actual, sum(hw_all_pred)\/len(hw_all_pred),_)\nhw_ensemble.model_name('Holt Winters','Ensemble')","7de8383e":"hw_ensemble.fig()","defacd40":"hw_ensemble.resid_fig()","a7f68dd9":"hw_ensemble.get_all()","da231e87":"#Training the best generalising model to predict the future\n\nmodel_arg = ('mul', 'add', True, 0.99, 0.25, 0.25, 0.5, 7)\nmodel = ExponentialSmoothing(df.drop(df[df.new_cases == 0].index).new_cases, seasonal_periods=model_arg[7], seasonal=model_arg[1],\n                             trend=model_arg[0], damped=model_arg[2])\nmodel = model.fit(smoothing_level=model_arg[4], smoothing_trend=model_arg[5],\n                  smoothing_seasonal=model_arg[6], damping_trend=model_arg[3])","83ea9c77":"sf_hw = model.forecast(100)","94b67f70":"fig = go.Figure()\nfig.add_scatter(x=df.index[0:], y=df.new_cases[0:])\nfig.add_scatter(x=sf_hw.index, y=sf_hw)\ncustom_legend_name(['Historical New Cases','Forecast'], fig_in_func=fig)\nfig.update_layout(title_text='Holt Winters 100-day Forecast')\nfig.update_traces(hovertemplate='<b>%{x}<\/b><br>%{y}<extra><\/extra>')\nfig.show(config=config)","5f34bf3b":"#Splitting main dataframe into train, val1, val2 and test to reset the change in Holt Winters\n\ntrain_df, test_df, val_df, val2_df = split_train_test_val(df)","e7f681f9":"#Changing format of dataframe to suit Prophet's standards\n\ntrain_df = train_df.reset_index()\ntrain_df.columns = ['ds','y']","42768673":"#Training a basic Prophet model\n\nm = Prophet(yearly_seasonality=False, daily_seasonality=False).fit(train_df)\nfuture = m.make_future_dataframe(30)\nbasic_proph = Metrics(val_df.new_cases, np.array(m.predict(future).iloc[-30:]['yhat']), _)\nbasic_proph.model_name('Prophet',0)","33a667f0":"basic_proph.fig()","01bd1a3f":"basic_proph.resid_fig()","2c871ea1":"basic_proph.get_all()","33d90e4f":"#Training Prophet with manually tuned hyperparameters\n\nm = Prophet(seasonality_mode='multiplicative', yearly_seasonality=False, daily_seasonality=False, growth='linear',\n           changepoint_prior_scale=0.1, seasonality_prior_scale=5, changepoint_range=0.95).fit(train_df)\nfuture = m.make_future_dataframe(30)\nmanual_proph = Metrics(val_df.new_cases, np.array(m.predict(future).iloc[-30:]['yhat']), _)\nmanual_proph.model_name('Prophet',0)","53b74c9d":"manual_proph.fig()","f64d7359":"manual_proph.resid_fig()","da85fba0":"manual_proph.get_all()","dd3f71bc":"#Creating copy of dataframes for rolling forecast so as to not modify the original dataframes\nrolling_train = train_df.copy()\nrolling_val = val_df.copy().reset_index()\nrolling_val.columns = ['ds','y']\n\n#30-day rolling prophet forecast, changepoint_scale=0.1\npredicted = []\nfor x in tqdm(range(1,len(rolling_val)+1)):\n    m = Prophet(seasonality_mode='multiplicative', yearly_seasonality=False, daily_seasonality=False, growth='linear',\n           changepoint_prior_scale=0.1, seasonality_prior_scale=5, changepoint_range=0.95).fit(rolling_train)\n    future = m.make_future_dataframe(1)\n    pred = m.predict(future.iloc[-1:])['yhat'].values[0]\n    predicted.append(pred)\n    rolling_train = rolling_train.append(rolling_val.iloc[x-1])\n\nrolling_proph = Metrics(val_df.new_cases, np.array(predicted),_)\nrolling_proph.model_name('Prophet',0)","fc0fff60":"rolling_proph.fig()","fe97a2e6":"rolling_proph.resid_fig()","94d80af4":"rolling_proph.get_all()","864b9b77":"#Creating copy of dataframes for rolling forecast so as to not modify the original dataframes\nrolling_train = train_df.copy()\nrolling_val = val_df.copy().reset_index()\nrolling_val.columns = ['ds','y']\n\n#30-day rolling prophet forecast, changepoint_scale=0.5\npredicted = []\nfor x in tqdm(range(1,len(rolling_val)+1)):\n    m = Prophet(seasonality_mode='multiplicative', yearly_seasonality=False, daily_seasonality=False, growth='linear',\n           changepoint_prior_scale=0.5, seasonality_prior_scale=5, changepoint_range=0.95).fit(rolling_train);\n    future = m.make_future_dataframe(1)\n    pred = m.predict(future.iloc[-1:])['yhat'].values[0]\n    predicted.append(pred)\n    rolling_train = rolling_train.append(rolling_val.iloc[x-1])\n\nrolling_proph = Metrics(val_df.new_cases, np.array(predicted),_)\nrolling_proph.model_name('Prophet',0)","6956226f":"rolling_proph.fig()","89f420d9":"rolling_proph.resid_fig()","802e1468":"rolling_proph.get_all()","a8a18f20":"#Preparing copies of dataframes (for some ease in plotting) for grid search\n\ngrid_val = val_df.copy()\ngrid_val.reset_index(inplace=True)\ngrid_val.columns=['ds','y']\ngrid_train = pd.concat([train_df, grid_val])","aca31888":"#Creating the parameter grid for grid search\n\nparam_grid = {  \n    'changepoint_prior_scale': [0.001, 0.002, 0.01, 0.1, 0.25, 0.5],\n    'seasonality_prior_scale': [0.01, 0.1, 1.0, 5.0, 10.0],\n    'seasonality_mode': ['additive','multiplicative'],\n    'growth': ['linear'],\n    'changepoint_range': [0.1, 0.5, 0.8, 0.95]\n}\nall_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]","cea8c11d":"# %%time\n# #Grid search over all 240 parameters with cross-validation\n\n# rmses = []\n# for params in tqdm(all_params):\n#     m = Prophet(**params, yearly_seasonality=False, daily_seasonality=False)\n#     m = m.fit(grid_train)\n#     df_cv = cross_validation(m, initial=str(grid_train.shape[0]-31) + ' days', horizon='1 day', period='1 day')\n#     df_p = performance_metrics(df_cv, rolling_window=1)\n#     rmses.append(df_p['rmse'].values[0])","323f54c9":"# #Creating dataframe of all the model parameters along with their RMSE scores\n\n# tuning_results = pd.DataFrame(all_params)\n# tuning_results['rmse'] = rmses\n# tuning_results = tuning_results.sort_values('rmse')\n# tuning_results","81e44af3":"# #Selecting the top 40 models\n\n# top_prophet_models = [list(tuning_results.iloc[:40].iloc[x].values) for x in range(40)]","e99f6cd2":"#Training top performing model from grid-search\n\nm = Prophet(changepoint_prior_scale=0.5, seasonality_prior_scale=1.0, seasonality_mode='multiplicative',\n            changepoint_range=0.95, yearly_seasonality=False, daily_seasonality=False).fit(train_df)\nfuture = m.make_future_dataframe(30)\ngrid_proph = Metrics(val_df.new_cases, np.array(m.predict(future).iloc[-30:]['yhat']), _)\ngrid_proph.model_name('Prophet',0)","9edb06b3":"grid_proph.fig()","d5d42818":"grid_proph.resid_fig()","1bfda7d4":"grid_proph.get_all()","8d87473b":"#Manually passing top 40 models so above time-taking computation can be SKIPPED\n\ntop_prophet_models = [[0.5, 5.0, 'multiplicative', 'linear', 0.95, 68496.51956237167],\n [0.5, 1.0, 'multiplicative', 'linear', 0.95, 68536.11617835006],\n [0.5, 0.1, 'multiplicative', 'linear', 0.95, 68628.25718529584],\n [0.5, 10.0, 'multiplicative', 'linear', 0.95, 68942.84671194918],\n [0.5, 0.01, 'multiplicative', 'linear', 0.95, 69628.06674852669],\n [0.25, 1.0, 'multiplicative', 'linear', 0.95, 78758.12814339087],\n [0.25, 10.0, 'multiplicative', 'linear', 0.95, 78759.54733564568],\n [0.25, 0.1, 'multiplicative', 'linear', 0.95, 78924.09412838506],\n [0.25, 5.0, 'multiplicative', 'linear', 0.95, 79151.50283379994],\n [0.25, 0.01, 'multiplicative', 'linear', 0.95, 80213.47033026148],\n [0.5, 5.0, 'additive', 'linear', 0.95, 85405.79814091229],\n [0.5, 10.0, 'additive', 'linear', 0.95, 85422.6856861233],\n [0.5, 0.1, 'additive', 'linear', 0.95, 85459.28342252369],\n [0.5, 1.0, 'additive', 'linear', 0.95, 85463.78934329028],\n [0.5, 0.01, 'additive', 'linear', 0.95, 86569.83984379865],\n [0.25, 5.0, 'additive', 'linear', 0.95, 96911.21875227928],\n [0.25, 1.0, 'additive', 'linear', 0.95, 97216.09695754146],\n [0.25, 0.1, 'additive', 'linear', 0.95, 97405.95622789257],\n [0.25, 10.0, 'additive', 'linear', 0.95, 98005.19271723731],\n [0.25, 0.01, 'additive', 'linear', 0.95, 98697.63093980013],\n [0.1, 5.0, 'multiplicative', 'linear', 0.95, 109049.90195165592],\n [0.1, 0.1, 'multiplicative', 'linear', 0.95, 109274.81993574959],\n [0.1, 1.0, 'multiplicative', 'linear', 0.95, 109998.05918405706],\n [0.1, 10.0, 'multiplicative', 'linear', 0.95, 110067.23623292665],\n [0.1, 0.01, 'multiplicative', 'linear', 0.95, 120940.54246312709],\n [0.001, 5.0, 'multiplicative', 'linear', 0.95, 134317.58224694864],\n [0.001, 1.0, 'multiplicative', 'linear', 0.95, 134429.61859325954],\n [0.001, 10.0, 'multiplicative', 'linear', 0.95, 135015.32116229937],\n [0.5, 0.1, 'multiplicative', 'linear', 0.5, 135445.16340580367],\n [0.5, 1.0, 'multiplicative', 'linear', 0.5, 135474.37422890184],\n [0.5, 10.0, 'multiplicative', 'linear', 0.5, 135482.70052235207],\n [0.5, 5.0, 'multiplicative', 'linear', 0.5, 135545.00735833478],\n [0.25, 0.1, 'multiplicative', 'linear', 0.5, 137338.0141640413],\n [0.001, 0.1, 'multiplicative', 'linear', 0.95, 137342.49488270315],\n [0.25, 1.0, 'multiplicative', 'linear', 0.5, 137377.5775584008],\n [0.25, 5.0, 'multiplicative', 'linear', 0.5, 137383.00742894819],\n [0.25, 10.0, 'multiplicative', 'linear', 0.5, 137388.8692865301],\n [0.5, 1.0, 'additive', 'linear', 0.5, 138373.30412958527],\n [0.5, 10.0, 'additive', 'linear', 0.5, 138424.10538792968],\n [0.5, 5.0, 'additive', 'linear', 0.5, 138440.86432930426]]","5d3106df":"# %%time\n# #Finding RMSEs of top models with cross validation, includes 2nd Validation set\n\ngrid_val2 = val2_df.copy()\ngrid_val2.reset_index(inplace=True)\ngrid_val2.columns=['ds','y']\ngrid2_train = pd.concat([train_df, grid_val, grid_val2])\n\n# rmses2 = []\n# for x in tqdm(top_prophet_models):\n#     param_grid = {'changepoint_prior_scale': x[0],\n#                   'seasonality_prior_scale': x[1],\n#                   'seasonality_mode': x[2],\n#                   'growth': x[3],\n#                   'changepoint_range': x[4]}\n#     m = Prophet(**param_grid, yearly_seasonality=False, daily_seasonality=False)\n#     m = m.fit(grid2_train)\n#     df_cv = cross_validation(m, initial=str(grid2_train.shape[0]-31) + ' days', horizon='1 day', period='1 day')\n#     df_p = performance_metrics(df_cv, rolling_window=1)\n#     rmses2.append(df_p['rmse'].values[0])","ebd03db0":"rmses2 = [49379.81149042711, 49468.19180461303, 49542.06937470975, 49356.75162882476, 50961.68146601285,\n          54408.77247706884, 54522.53334574541, 54170.295340920675, 54642.48673508921, 56155.482973485865,\n          57632.711162021194, 57592.37418301971, 57443.61971524401, 57775.42374426384, 58843.47959652853,\n          68296.25306466538, 68061.10029511034, 68273.48335750909, 67511.87185612555, 69506.19201838046,\n          87664.34053715246, 87542.98816953565, 88989.14346179654, 88198.10355742653, 121636.72874178934,\n          195005.0039692153, 196573.72459879064, 194608.13077828434, 107505.68359457407, 107882.57339696081,\n          107568.7740900801, 107568.27354584601, 112699.90101143483, 195438.89750312644, 112177.88753643607,\n          112299.9525291053, 112508.85148867678, 108691.73639965984, 108733.77022216775, 108597.22876546648]","b09727fe":"#Finding RMSEs of top models manually, includes 1st Validation set\n\nrmses_manual = []\nfor x in tqdm(top_prophet_models):\n    param_grid = {'changepoint_prior_scale': x[0],\n                  'seasonality_prior_scale': x[1],\n                  'seasonality_mode': x[2],\n                  'growth': x[3],\n                  'changepoint_range': x[4]}\n    m = Prophet(**param_grid, yearly_seasonality=False, daily_seasonality=False).fit(grid_train)\n    future = m.make_future_dataframe(30)\n    rmse_manual = Metrics(val_df.new_cases, np.array(m.predict(future).iloc[-30:]['yhat']), _)\n    rmse_manual.model_name('Prophet',0)\n    rmses_manual.append(rmse_manual)","4112e483":"#Finding RMSEs of top models manually, includes 2nd Validation set\n\nrmses2_manual = []\nfor x in tqdm(top_prophet_models):\n    param_grid = {'changepoint_prior_scale': x[0],\n                  'seasonality_prior_scale': x[1],\n                  'seasonality_mode': x[2],\n                  'growth': x[3],\n                  'changepoint_range': x[4]}\n    m = Prophet(**param_grid, yearly_seasonality=False, daily_seasonality=False).fit(grid2_train)\n    future = m.make_future_dataframe(30)\n    rmse2_manual = Metrics(val2_df.new_cases, np.array(m.predict(future).iloc[-30:]['yhat']), _)\n    rmse2_manual.model_name('Prophet',0)\n    rmses2_manual.append(rmse2_manual)","3bd4c57e":"#Concatenating all scores into a dataframe, creating new features to judge and find the best model\n\ntop_prophet_df = pd.DataFrame(top_prophet_models)\ntop_prophet_df.rename(columns={5:'rmse_crossval'}, inplace=True)\ntop_prophet_df['rmse2_crossval'] = rmses2\ntop_prophet_df['rmse_manual'] = [x.rmse() for x in rmses_manual]\ntop_prophet_df['rmse2_manual'] = [x.rmse() for x in rmses2_manual]\ntop_prophet_df['crossval_avg'] = (top_prophet_df['rmse_crossval'] + top_prophet_df['rmse2_crossval'])\/2\ntop_prophet_df['crossval_diff'] = np.abs(top_prophet_df['rmse_crossval'] - top_prophet_df['rmse2_crossval'])\ntop_prophet_df['manual_avg'] = (top_prophet_df['rmse_manual'] + top_prophet_df['rmse2_manual'])\/2\ntop_prophet_df['manual_diff'] = np.abs(top_prophet_df['rmse_manual']-top_prophet_df['rmse2_manual'])\ntop_prophet_df['diff-diff'] = np.abs(top_prophet_df['crossval_diff'] + top_prophet_df['manual_diff'])","fb494f3c":"top_prophet_df.sort_values('diff-diff')","d2e457b4":"#Training the best model till now to predict on Test set\n\nm = Prophet(changepoint_prior_scale=0.5, seasonality_prior_scale=5, seasonality_mode='multiplicative',\n            changepoint_range=0.5, yearly_seasonality=False, daily_seasonality=False).fit(grid_val2)\nfuture = m.make_future_dataframe(30)\ntest_proph = Metrics(test_df.new_cases, np.array(m.predict(future).iloc[-30:]['yhat']), _)\ntest_proph.model_name('Prophet',0)","563a06e4":"test_proph.fig()","db27f775":"test_proph.resid_fig()","79ca755e":"test_proph.get_all()","5c2c475f":"#Creating an ensemble list of models\n\nprophet_ensemble = (list(top_prophet_df.sort_values('crossval_diff')[[0,1,2,3,4]].head(10).values) +\n                    list(top_prophet_df.sort_values('manual_diff')[[0,1,2,3,4]].head(10).values) +\n                    list(top_prophet_df.sort_values('diff-diff')[[0,1,2,3,4]].head(10).values))\nprophet_ensemble = [tuple(x) for x in prophet_ensemble]\nprophet_ensemble= set(prophet_ensemble)","48ccafeb":"%%time\n#Training the models in ensemble list and predicting on the Test set\n\nensembles_test = []\nfor x in tqdm(prophet_ensemble):\n    param_grid = {'changepoint_prior_scale': x[0],\n                  'seasonality_prior_scale': x[1],\n                  'seasonality_mode': x[2],\n                  'growth': x[3],\n                  'changepoint_range': x[4]}\n    m = Prophet(**param_grid, yearly_seasonality=False, daily_seasonality=False).fit(grid_val2)\n    future = m.make_future_dataframe(30)\n    ensemble_test = Metrics(test_df.new_cases, np.array(m.predict(future).iloc[-30:]['yhat']), _)\n    ensemble_test.model_name('Prophet',0)\n    ensembles_test.append(ensemble_test)","1295ad7c":"#Creating Metrics instance of predictions from the ensemble of models\n\nensemble_model = Metrics(test_df.new_cases, sum([x.predicted for x in ensembles_test])\/len(ensembles_test),_)\nensemble_model.model_name('Prophet',0)","639736de":"ensemble_model.fig()","9fddcdbd":"ensemble_model.resid_fig()","8dcd754f":"ensemble_model.get_all()","8ec3f59a":"#Creating copy of main dataframe to format it according to Prophet's standards\n\nproph_df = df.reset_index()\nproph_df.columns=['ds','y']","1a8ac8f6":"#Training the model and predicting the future\n\nm = Prophet(changepoint_prior_scale=0.5, seasonality_prior_scale=5, seasonality_mode='multiplicative',\n            changepoint_range=0.5, yearly_seasonality=False, daily_seasonality=False).fit(proph_df)\nfuture = m.make_future_dataframe(100)\nsf_prophet = m.predict(future)\nsf_prophet = sf_prophet.iloc[-100:]","b92566d2":"fig = go.Figure()\nfig.add_scatter(x=proph_df.ds[-150:], y=proph_df.y[-150:])\nfig.add_scatter(x=(list(sf_prophet.ds) + list(sf_prophet.ds[::-1])),\n                y=(list(sf_prophet.yhat_lower) + list(sf_prophet.yhat_upper[::-1])),\n                fill='toself',mode='none', fillcolor='rgba(61, 64, 91, 0.5)')\nfig.add_scatter(x=sf_prophet.ds, y=sf_prophet.yhat, line_color='#390099')\ncustom_legend_name(['Historical New Cases','Confidence Interval','Forecast'], fig_in_func=fig)\nfig.update_layout(title_text='Prophet 100-day Forecast with 80% Confidence Intervals')\nfig.update_traces(hovertemplate='<b>%{x}<\/b><br>%{y}<extra><\/extra>')\nfig.show(config=config)","438d782b":"#Resetting dataframe into original splits\n\ntrain_df, test_df, val_df, val2_df = split_train_test_val(df)","43c69d6c":"#Function to plot future predictions of all models\n\ndef plot_all_models_future(start, future_days, ensemble=False, prophet=True):\n    #SARIMA\n    set_inferred_index(df)\n    model = SARIMAX(df.new_cases, order=(1, 1, 0), seasonal_order=(1, 1, 0, 7))\n    model = model.fit(maxiter=200)\n    sf_sarima = model.get_forecast(future_days).summary_frame()\n\n    #Holt Winters Exponential Smoothing\n    model_arg = ('mul', 'add', True, 0.99, 0.25, 0.25, 0.5, 7)\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\")\n        model = ExponentialSmoothing(df.drop(df[df.new_cases == 0].index).new_cases, seasonal_periods=model_arg[7],\n                                     seasonal=model_arg[1], trend=model_arg[0], damped=model_arg[2])\n        model = model.fit(smoothing_level=model_arg[4], smoothing_trend=model_arg[5],\n                          smoothing_seasonal=model_arg[6], damping_trend=model_arg[3])\n        sf_hw = model.forecast(future_days)\n\n    #Prophet\n    m = Prophet(changepoint_prior_scale=0.5, seasonality_prior_scale=5, seasonality_mode='multiplicative',\n            changepoint_range=0.5, yearly_seasonality=False, daily_seasonality=False).fit(proph_df)\n    future = m.make_future_dataframe(future_days)\n    sf_prophet = m.predict(future)\n    sf_prophet = sf_prophet.iloc[-future_days:]\n    \n    #Figure\n    fig = go.Figure()\n    fig.add_scatter(x=df.index[start:], y=df.new_cases[start:])\n    if ensemble:\n        fig.add_scatter(x=sf_prophet.ds, y=(sf_hw + sf_sarima['mean'])\/2)\n        custom_legend_name(['Historical New Cases','SARIMA + Holt Winters Forecast'], fig_in_func=fig)\n        fig.update_layout(title_text=str(future_days)+' Days Ensemble Forecast')\n    else:\n        fig.add_scatter(x=sf_prophet.ds, y=sf_sarima['mean'])\n        fig.add_scatter(x=sf_prophet.ds, y=sf_hw)\n        if prophet:\n            fig.add_scatter(x=sf_prophet.ds, y=sf_prophet.yhat)\n            custom_legend_name(['Historical New Cases','SARIMA Forecast','Holt Winters Forecast','Prophet Forecast'],\n                           fig_in_func=fig)\n            fig.update_layout(title_text=str(future_days)+' Days Forecast')\n        else:\n            custom_legend_name(['Historical New Cases','SARIMA Forecast','Holt Winters Forecast'], fig_in_func=fig)\n            fig.update_layout(title_text=str(future_days)+' Days Forecast Without Prophet')\n    fig.update_traces(hovertemplate='<b>%{y}<\/b><br>%{x}<extra><\/extra>')\n    fig.show(config=config)","6a5b7bb3":"plot_all_models_future(0,1000)","cf919cdb":"plot_all_models_future(0,1000,prophet=False)","8866eed8":"#Adding Metrics instance of each model to a list\n\nensemble_all = []\n\n#SARIMA\ntest_final = train_and_pred(((1, 1, 0), (1, 1, 0, 7)), aic_bic=False, series_type='boxcox', split_type='test')\nensemble_all.append(test_final)\n\n#Holt Winters\nhw_params = ('mul', 'add', True, 0.99, 0.25, 0.25, 0.5, 7)\nactual_hw, predicted_hw, model_hw = get_model_pred(hw_params,aic_bic=False,\n                                                   algo_type='hw', series_type='boxcox', split_type='test')\nhw_trained = Metrics(actual_hw, predicted_hw, model_hw)\nhw_trained.model_name(hw_params,0)\nensemble_all.append(hw_trained)\n\n#Prophet\nm = Prophet(changepoint_prior_scale=0.5, seasonality_prior_scale=5, seasonality_mode='multiplicative',\n            changepoint_range=0.5, yearly_seasonality=False, daily_seasonality=False).fit(grid_val2)\nfuture = m.make_future_dataframe(30)\ntest_proph = Metrics(test_df.new_cases, np.array(m.predict(future).iloc[-30:]['yhat']), _)\ntest_proph.model_name('Prophet',0)\nensemble_all.append(test_proph)","28bfd751":"#Creating Metrics instance of ensemble for graphs and score\n\nallmet = Metrics(test_df.new_cases, sum([x.predicted for x in ensemble_all])\/3,_)\nallmet.model_name('Ensemble of SARIMA, HW & Prophet',0)","d6aca414":"allmet.fig()","6732738e":"allmet.resid_fig()","55f5dace":"allmet.get_all()","93b54f4d":"#Creating Metrics instance of ensemble of SARIMA and HW\n\nallmet_without_proph = Metrics(test_df.new_cases, sum([x.predicted for x in ensemble_all[:2]])\/2,_)\nallmet_without_proph.model_name('Ensemble of SARIMA and HW',0)","35788461":"allmet_without_proph.fig()","72357f79":"allmet_without_proph.resid_fig()","dc4390ea":"allmet_without_proph.get_all()","17eecbb5":"plot_all_models_future(0,365,ensemble=True)","7144f5ad":"<span class=text>Commenting out for run on Kaggle<\/span>","b8238846":"<span class=text>Very clearly, the trend still exists. This means to train any model on this box-cox transformed dataset, it would still require differencing.<\/span>","0461ab20":"<a id='eda_cnc_bv'><\/a>\n\n## 4. COUNTRIES IN CONTINENTS (BI-VARIATE ANALYSIS)\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#eda>Jump to EDA Start<\/a><\/span>","9e41d4ed":"### Test","48947efa":"<a id='eda_intro'><\/a>\n\n## 0. INTRODUCTION\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#eda>Jump to EDA Start<\/a><\/span>","33d43997":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class=text11>(In this plot, the colours for the root node (world) and the continents are to be ignored. They only exist as filler.)<\/span>","c3477cc3":"<span class=text>The RMSE score in better in the rolling forecast with <code>changepoint_scale=0.5<\/code> but that might purely be out of overfitting. To find an even better model, a grid search along with Prophet's inbuilt cross-validation will be run.<\/span>","34b9d118":"<a id='skip_sarima_ensemble'><\/a>","3a94b33d":"<span class=text>From the above plots, it is very clear that the data has weekly seasonality. Therefore, a seasonal ARIMA model should be used.<\/span>\n\n<a id='ml_sarima'><\/a>","74e7e27c":"Click [here](#mobility_trends) for a detailed description of the mobility trends data.","3bc14913":"<div class=\"alert alert-warning\">\n<b>NOTE:<\/b> The computation below can take a long time (7.33 hours~) to finish depending on your machine. You can skip it with this jump point below.\n<\/div>\n\n### <b><a href=#skip_prophet_grid>JUMP<\/a><\/b>","4ec9c6fd":"### Box-Cox Transformation","bfe657ab":"<b>First Two Digits<\/b>","f9cd295a":"<span class=text>Of course no forecasting model is a good enough model to predict accurately for a 1000 days lest even a month. The 1000-days graphs here are just a comparison of model extrapolations and the figures of <code>Cases<\/code> going into negative is weird but expected.<\/span>","0f06d6ce":"<a id='#model'><\/a>\n\n# Machine Learning\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#top>Jump to Beginning<\/a><\/span>","1fcb6e8b":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graph below, you can-<br>\n\u2003\u20031. Drag the column headers to switch the column positioning.\n<\/details>","c3453341":"#### <span style=\"font-family:Verdana\"> Augmented Dickey-Fuller (ADF) test<\/span>\n    Null Hypothesis: The series has a unit root.\n    Alternate Hypothesis: The series has no unit root.","3999f43f":"<div class=\"alert alert-danger\">\n<b>NOTE:<\/b> Tracking of recovery data was discontinued from 5th August 2021 onwards.\n<\/div>\n\n<sup><a href=#cite_4>[4]<\/a><\/sup> <a id='up_4'><\/a>","01cbe32c":"<b>Last Two Digits<\/b>\n\n<span class=text>As the digits increase, their frequency of occurrence evens out. This is evident from the plots of <code>First<\/code> to <code>Fifth<\/code> digits. And so, the frequency of <code>Last Two<\/code> digits is considered to be perfectly even.<\/span>","ac250ae1":"Jump to section of Machine Learning -\n\n[0. Introduction](#ml_intro)<br>\n[1. SARIMA](#ml_sarima)<br>\n[2. Holt Winters Exponential Smoothing](#ml_hw)<br>\n[3. Prophet](#ml_prophet)<br>\n[4. Ensemble](#ml_ensemble)","95c6ad27":"#### Population Density","75db6044":"<a href=\"https:\/\/github.com\/vyaduvanshi\/ds-projects\/tree\/master\/coronavirus-future-prediction\">Github Link<\/a>\n\n<span class=text>Coronavirus disease 2019 (COVID-19) is a contagious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The first known case was identified in Wuhan, China, in December 2019. The disease has since spread worldwide, leading to an ongoing pandemic.<br>\n<br>This project takes a detailed look on the global, continental and individual country level data of COVID-19. Some of the various parameters are <code>Cases<\/code>,<code>Deaths<\/code>,<code>Recoveries<\/code>,<code>Tests<\/code>,<code>Vaccinations<\/code> and many more. The project is divided into 4 distinct sections-\n<br><br>1. Preprocessing, as the name suggests is where the preprocessing takes place.\n<br>2. EDA consists of visualisations and their inferences on global data, continental comparison, comparison between countries, a bi-variate analysis of several features of different countries and then checking how well the data for countries fit Benford's distribution.\n<br>3. ML consists of three algorithms, SARIMA, Holt Winter's Triple Exponential Smoothing and Facebook's Prophet. And then an ensemble of all three.\n<br>4. Lastly Citations consists of, you guessed it, citations.<\/span>","c37b6170":"<span class=text><u>Observations:<\/u>\n<br>1. Countries with higher Literacy Rate relatively saw a higher case rate per population. ($r=0.316$)\n<br>2. Countries with higher Literacy Rate relatively have better access to handwashing facilities for their populace.($r=0.676$)\n<br>3. Countries with higher Literacy Rate relatively have more hospital beds per thousand. ($r=0.503$)\n<br>4. Countries with higher Literacy Rate relatively provided better economic support to its populace. ($r=0.34$)\n<br>5. Countries with higher Literacy Rate relatively responded better to the pandemic. ($r=0.287$)\n<\/span>","e7b7057f":"<span class=text>Qatar's first and fourth digit do not follow Benford's distribution, the p-value is small enough for null hypothesis to be rejected.<\/span>","de7973a1":"### Zero differencing","125f6889":"<div class=\"alert alert-warning\">\n<b>NOTE:<\/b> The computation below can take a long time (1.6~ hours) to finish depending on your machine. You can skip it with this jump point below.\n<\/div>\n\n### <b><a href=#skip_sarima_ensemble>JUMP<\/a><\/b>","e52739e9":"<span class=text>Judging by the results of both the ADF and the KPSS test, the series has unit roots and is not stationary. The series might also have a seasonal component which I will look for now.<\/span>","8a952c61":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graphs below, you can-<br>\n\u2003\u20031. Click on the <b>Play<\/b> or <b>Stop<\/b> buttons to control the animation.<br>\n\u2003\u20032. Drag the slider manually to control animation.\n<\/details>","c33c8d97":"<span class=text11>The root (world) and parent nodes (continents) do not represent colour according to the scale but rather an average of their children nodes(countries). This design decision was taken to bring the focus to countries, as totals will always be dominated by parent nodes.<\/span>","72479e23":"<span class=text11>All three variables on y-axis are on a scale of 0-100. For more info, <a href=\"https:\/\/github.com\/OxCGRT\/covid-policy-tracker\/blob\/master\/documentation\/index_methodology.md\">here<\/a>.<\/span>","0d7dffd2":"<span class=text>The best model returned by <code>auto_arima<\/code> above has already been tried.<\/span>","755584b4":"### Ensemble","778efefb":"<div class=\"alert alert-warning\">\n<b>NOTE:<\/b> The computation below can take a long time (4.75~hours) to finish depending on your machine. You can skip it with this jump point below.\n<\/div>\n\n### <b><a href=#skip_sarima_val1and2>JUMP<\/a><\/b>","f54f10c1":"<span class=text>The series has become stationary after a seasonal difference and a trend difference.<\/span>","b2f0a7d0":"### Ensemble","2b7dfe29":"<span class=text>From the table above which is sorted by average score of both validation sets, it is evident that the best performing model is indeed ((5, 0, 1), (1, 1, 0, 7)) on the boxcox series, the model ((1, 1, 0), (1, 1, 0, 7)) lagging only very slightly behind. But the second model will be chosen due to the difference between the two being small and the first one being a more complex model. And so this model will be used to predict on the test set. Judging by the stability of scores (diff) on both Validation sets too, this model fares well. However, both the models should perform well on the test set as both result in a good and stable score.<\/span>","9ae6f71d":"<span class=text>Commenting out for run on Kaggle<\/span>","0bd57b35":"<span class=text>This is the series I will be forecasting on. Visually inspecting the above plot, there seems to be a slight upward trend which means the mean is not constant. And the variance also seems to be a function of time. Therefore, the data does not seem stationary. A more robust inspection can be done by the ADF and KPSS tests.<\/span>","6b2caf8d":"<span class=text>This is the best performing model till now, and by no surprise, as it is an ensemble of the two best performing models till now which are also diverse in comparison to each other. I'll now use this model to predict the future.<\/span>","8c36b550":"<a id='ml_hw'><\/a>\n\n## 2. Triple Exponential Smoothing (Holt Winters)\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#ml>Jump to ML start<\/a><\/span>","f157c599":"<span class=text>Commenting out for run on Kaggle<\/span>","dd7c3095":"<span class=text>China's fourth digit and first three digits does not follow Benford's distribution, the p-value is small enough for null hypothesis to be rejected.<\/span>","0fc1e19d":"<span class=text>This performs even better than the last model!<\/span>","3038519a":"### Identifying Stationarity","f3fcf3db":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graphs below, you can-<br>\n\u2003\u20031. <b>Click<\/b> on any block\/section to zoom-in or zoom-out.\n<\/details>","4b34a55a":"<sup><a href=#cite_13>[13]<\/a><\/sup> <a id='up_13'><\/a>","17b1cf55":"<div class=\"alert alert-warning\">\n<b>NOTE:<\/b> The computation below can take a long time (16+21+18+9 = 64~hours) to finish depending on your machine. You can skip it with this jump point below.\n<\/div>\n\n### <b><a href=#skip_sarima_grid>JUMP<\/a><\/b>","5d0d56c1":"<b>Now that the desired dataframe is prepared, it's time for some<\/b>\n    \n# <span>Exploratory Data Analysis<\/span>\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#top>Jump to Beginning<\/a><\/span>","c8e22990":"### Test","9757b118":"<span class=text>Again as p-value > $\\alpha$, we fail to reject the null hypothesis.<\/span>","2170d995":"<b>1st Digit<\/b>","e499c7b1":"<a id='top'><\/a>\n # <center>CORONAVIRUS FUTURE PREDICTION<\/center>","57370264":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graphs below, you can-<br>\n\u2003\u20031. <b>Drag<\/b> the 3D space around.\n<\/details>","d38edeb1":"### <span style=\"font-family:Verdana\">4.1. Populace and Country Infrastructure<\/span>","8c36f114":"<span class=text>Due to the series not being stationary, it does not make sense to train a model with zero order of differencing.<\/span>","2dd25d93":"\\begin{equation}\n{\\normalsize Herd\\:Immunity\\:Threshold = 1 - \\frac{1}{R_0}}\n\\end{equation}\n\n<br><span class=text>Herd Immunity Threshold is always an evolving figure depending on how the infection is spreading. To add even more, the different variants and difference in reproduction rate in countries and even sub-countries make it difficult to estimate a true herd immunity threshold. Most of the estimates lie between 60-95%. For plotting purposes, a liberal threshold of 67% has been chosen.<sup><a href=#cite_11>[11]<\/a><\/sup> <a id='up_11'><\/a>. More about $R_0$ below.<\/span>","f2acb618":"<span class=text14>Here, I am picking six countries, 3 of which had one of the worst <b>covid responses<\/b> and 3 which had one of the best. And then those countries will be compared in parallel category and parallel coordinate plots in terms of the government responses and mobility trends. The countries are-<br><br>\n<b><u>Worst<\/u><\/b><br>\nBrazil<br>\nIndia<br>\nUnited States<br><br>\n<b><u>Best<\/u><\/b><br>\nMauritius<br>\nNew Zealand<br>\nTaiwan\n<\/span>","cfa3b6ff":"<span class=text><u>Observations:<\/u>\n<br>1. Countries with a higher Human Development Index score relatively saw a higher test rate per population. ($r=0.297$)\n<br>2. Countries with a higher Human Development Index score relatively saw a higher vaccination rate per population.($r=0.365$)\n<br>3. Countries with higher Human Development Index score received relatively more economic support from the government. ($r=0.480$)\n<br>4. Countries with higher Human Development Index score responded relatively better to the pandemic. ($r=0.330$)\n<\/span>","5f447141":"<span class=text><b><u>Procedure:<\/u><\/b><br><br>1. Grid search will train and fit models across a range of parameters and will calculate the AIC and BIC scores for each model.<br>2. These information criterion scores will then be compared for each model within the same orders of differencing and the the top models in each order of differencing will be selected.<br>3. These models will then be trained on the Training set and their prediction errors on 30-day rolling forecasts on the 1st Validation set will be compared.<br>4. The best 10 models in each series type will then be used to predict on the 2nd Validation set.<br>5. The best model amongst them will be chosen to predict on the test set, along with other non-ARIMA models.<\/span>","1e0d5524":"<span class=text>The long tail of the distribution is eradicated but the distribution is not even close to being Gaussian. There is still trend remaining in the series.<\/span>","66eb5801":"<span class=text12>Testing began way before China started releasing official numbers.<\/span>","19b19362":"### Future","64e677bd":"### Future","a9edb104":"<span class=text>And again as p-value > $\\alpha$, we fail to reject the null hypothesis.<\/span>","83a02d2b":"<span class=text>This is by far the series with the lowest standard deviation.<\/span>","2257bb99":"<span class=text>The series is trend stationary but not difference stationary. Therefore, the series is not strict stationary and will have to be differenced to be trained on.<\/span>","cc19ea64":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class=text11>(Drag and select a smaller area on the graph to view more countries.)<\/span>","f4cab558":"<span class=text>$R_0$ is the expected number of cases directly generated by one case in a population where all individuals are susceptible to the infection.<sup><a href=#cite_12>[12]<\/a><\/sup> <a id='up_12'><\/a><br><br>\nWhen $R_0 > 1$, the infection will be able to start spreading in a population, but not if $R_0 < 1$. Generally, the larger the value of $R_0$, the harder it is to control the epidemic.<\/span>","d0be3852":"<a id='skip_hw_grid'><\/a>","79c6f750":"<span class=text>p-value > $\\alpha$. Null hypothesis will be failed to be rejected.<\/span>","cdbfd57e":"<a id='ml_prophet'><\/a>\n\n## 3. PROPHET\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#ml>Jump to ML start<\/a><\/span>","6d8b764b":"<b>China<\/b>","2e2d0044":"<span class=text>Benford's Law is a law about the observation of distribution of digits in a dataset. The law states that in many naturally occurring collections of numbers, the leading digit is likely to be small. In sets that obey the law, the number 1 appears as the leading significant digit about 30\u2009% of the time, while 9 appears as the leading significant digit less than 5\u2009% of the time. If the digits were distributed uniformly, they would each occur about 11.1\u2009% of the time but that is not the case. <sup><a href=#cite_15>[15]<\/a><\/sup> <a id='up_15'><\/a>\n<br><br>\nThe law extends to the second digit, the third digit and various combinations of digits. The combinations were not noted by Frank Benford and would be better attributed to Mark Nigrini. <sup><a href=#cite_16>[16]<\/a><\/sup> <a id='up_16'><\/a>\n<br><br>\nAccording to Benford's law, the probability of a number starting from the digit $n$ is-\n<br><br><\/span>\n\\begin{equation}\n{\\normalsize  log_{10} \\left(1+\\frac{1}{n}\\right)}\n\\end{equation}\n\n<span class=text>The reason why I think the Coronavirus dataset should follow Benford's law is because of the exponential growth of Covid. For eg-\n<br><br>\nIf the number of cases are 100 and rising, it would take longer for the cases to rise from 100 to 200 than, say, from 900 to 1000. This is because as the virus spreads to more people, the same absolute number of cases becomes smaller relatively. A rise from 100 to 200 is 2 times, but a rise from 900 to 1000 is only 1.11 times.<\/span>","faa60a5d":"<b>Jump to-<\/b>\n## [0. Preprocessing](#preprocess)\n## [1. EDA](#eda)\n## [2. Machine Learning](#ml)\n## [3. Citations](#citations)\n\n<span class=text>(All the sections linked to above use the imports below, so execute them first.)<\/span>","e0ea19e4":"<span class=text11>All three variables on y-axis are on a scale of 0-100. For more info, <a href=\"https:\/\/github.com\/OxCGRT\/covid-policy-tracker\/blob\/master\/documentation\/index_methodology.md\">here<\/a>.<\/span>","5e71dccd":"<span class=text><u>Observations:<\/u>\n<br>1. Countries with a higher Democracy Index score relatively saw a higher case rate per population. ($r=0.261$)\n<br>2. There is no linear correlation between the Democracy Index score of a country and the containment and impositions laid down by the government. ($r=0.01\\sim$)\n<\/span>","9ffe23ab":"### Combining SARIMA and Holt Winters (excluded Prophet)","74492b5c":"<span class=text>For the fourth digit as well, p-value > $\\alpha$. So, we fail to reject the null hypothesis.<\/span>","7121f999":"<span class=text>The standard deviation has increased when another order of seasonal difference is added. Therefore, a single order difference should be sufficient lest the series gets overdifferenced.<\/span>","07b2aa28":"<b>4th Digit<\/b>","4e6806f0":"<span class=text>The best performing model on the 2nd Validation set is ((5, 0, 1), (1, 1, 0, 7)) on the boxcox transformed series.<\/span>","4dfe4473":"<b>India<\/b>","c1703100":"#### <span style=\"font-family:Verdana\"> Kwiatkowski\u2013Phillips\u2013Schmidt\u2013Shin (KPSS) test<\/span>\n    Null Hypothesis: The process is trend stationary.\n    Alternate Hypothesis: The series has a unit root (series is not stationary).","ff562268":"<span class=text>Saudi Arabia's first digit does not follow Benford's distribution, the p-value is small enough for null hypothesis to be rejected.<\/span>","4da0c01b":"Note to self: Add manual value of scores_df","85c9df1a":"<b>Saudi Arabia<\/b>","847544d0":"<span class=text>To find a model that would have the best odds of predicting close to the actual figures, a model should be found which has the least average score along with a low difference between <code>Validation 1<\/code> and <code>Validation 2<\/code>. A low difference would mean the model performance is more stable and it wasn't overfit on any one validation set to get a good average score. So, the model third from the top (<code>(mul, add, True, 0.99, 0.25, 0.25, 0.5, 7)<\/code>) in the dataframe is being chosen for the lowest <code>Diff<\/code> and only slightly more <code>Avg<\/code> than the model in the first row.<\/span>","ea414b40":"<span class=text>ACF plot shows a seasonal cut-off at 2nd iteration and a trend cut-off at lag 2. PACF plot shows a seasonal cut-off at 5th iteration (35) and a trend cut-off at lag 4.<\/span>","f63e450d":"<sup><a href=#cite_14>[14]<\/a><\/sup> <a id='up_14'><\/a>","393a8f30":"<a id='skip_prophet_grid'><\/a>\n\n#### Top performing model from grid-search","e4298921":"<span class=text><b>Note:<\/b> Several of the statistics in the graphs below were not constant and varied on each date. So, to simply be able to represent one country by one dot, the average of the statistics across the entire time frame of data is taken.<\/span>","cf866065":"<span class=text>Adding another order of differencing increases the standard deviation of the series. Therefore, second order differencing would likely be overdifferencing.","44ede233":"<span class=text>For an even more detailed view on Benford's Law on coronavirus data, check out my other project. (Work in progress, not yet complete.)<\/span>","6f7d49c1":"<div class=\"alert alert-info\">\n<b>NOTE:<\/b> If you jumped directly to the EDA part, execute the following cell. It'll import the files <code>final_df.csv<\/code>, <code>final_world_df.csv<\/code> and <code>final_continent_df.csv<\/code> from my github repository.\n<br><br>If you did not directly jump to this part however, you can skip the next cell.\n<\/div>","9e0739de":"<b>Google Mobility Trends Data<\/b> <sup><a href=#cite_6>[6]<\/a><\/sup> <a id='up_6'><\/a>","807e32de":"<span class=text>The best performing model scored 23189 on 1st Validation set, 29675 on the 2nd Validation set and 31198 on the test set. This could mean that the model was overfit on the 1st Validation set. It could also mean the test and the 2nd Validation data took an unexpected turn that the model could not predict well.<\/span>","f6d799da":"#### Rolling Forecast","8542c2b3":"### Single-order Seasonal difference (Weekly)","f02c9267":"<a id='ml_intro'><\/a>\n\n## 0. INTRODUCTION\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#ml>Jump to ML start<\/a><\/span>","b7a1e8ae":"<span class=text>The grid search for Holt Winters is complete on all the three series (normal, boxcox, linear regression detrended) and now the best performing models will be selected to be trained on the (Training + 1st Validation) set to predict on 2nd Validation set.<\/span>","61d31cdd":"<span class=text>The series of `New Cases` is going to be divided into four parts. The sets are of size 30 each except training set which is (Total Size - 120)\n<br>1. Training Set\n<br>2. 1st Validation Set\n<br>3. 2nd Validation Set\n<br>4. Test Set\n<br><br>The models will first be trained on the Training set and the best performing ones on the 1st Validation set will then be trained on (Training+Validation) set and then evaluated on the 2nd Validation set, and so on.","01a0a820":"<span class=text>In the ACF plot, the convergence\/cut-off to zero starts at lag 12 and in the PACF plot, it starts at lag 10. This means AR could be 10 and MA could be 12 but that would be too complex and redundant. So, the first model that I'll try is MA(2), which is the difference of the two.<\/span><sup><a href=#cite_17>[17]<\/a><\/sup> <a id='up_17'><\/a>","9ec0ef8b":"$(trend,\\: seasonal,\\: damped,\\: phi,\\: alpha,\\: beta,\\: gamma,\\: seasonal\\_period)$","82309fd3":"<sup><a href=#cite_10>[10]<\/a><\/sup> <a id='up_10'><\/a>","c50ab11f":"#### Observations:\n<br><span class=text>\nThe series passes all the goodness-of-fit tests of the various digit placements. This comes as no surprise as the series in question consisted of all the datapoints from each country (not a sum) so even if individual countries fabricated their figures, the combined dataset would make the stats more neutral. A visual inspection of the datasets in the above figures does bring to light some inconsistencies with Benford's distributon but they still fit the chi-square goodness-of-fit test. Anyhow, the more interesting tests would be of individual countries.<\/span>","bd8463f8":"#### Human Development Index","40c015f1":"<span class=text>P-value > $\\alpha$, so we fail to reject the null hypothesis.<\/span>","7ad33434":"<span class=text>Iran's first digit does not follow Benford's distribution, the p-value is small enough for null hypothesis to be rejected.<\/span>","d081090c":"<a id='eda_sel_countries'><\/a>\n\n## 6. SELECTED COUNTRIES\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#eda>Jump to EDA Start<\/a><\/span>\n","f661aa14":"#### Basic out-of-the-box Prophet model with default parameters","8222ad47":"<b>2nd Digit<\/b>","167eb85d":"<span class=text>According to the ADF and KPSS tests, the series is now difference non-stationary but trend stationary after a single order seasonal differencing of 7 days.<\/span>","2d701865":"### Test","539b0a20":"<a id='eda_continents'><\/a>\n\n## 2. CONTINENTS\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#eda>Jump to EDA Start<\/a><\/span>","0d16c3a3":"<a id='citations'><\/a>\n\n# Citations\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#top>Jump to Beginning<\/a><\/span>","5e7a1618":"### Grid Search","32eadb96":"<span class=text>The box-cox transformed series is not stationary.<\/span>","5e666483":"<b>United States of America<\/b>","069703fa":"<a id=\"mobility_trends\"><\/a>\n\n### 4.4. Mobility Trends","a0300736":"### Detrend by Model Fitting (Linear Regression)","7f662c5a":"<span class=text>The ACF plot cuts off at the second iteration of 7 which is the seasonality. This points to seasonal MA being 2 and the PACF plot cuts off on the third iteration, which means seasonal AR could be 3. To simplify the model, AR will be passed as 1 and MA as 0.<\/span>","cecddefa":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graphs below, you can-<br>\n\u2003\u20031. Hover over the trendline to see its R<sup>2<\/sup> value.\n<\/details>","b2c6b58c":"<span class=text>Null Hypothesis cannot be rejected. $($p-value = $0.367)$. Therefore, the series is difference non-stationary.<\/span>","d7191022":"### Grid Search","3778f887":"<span class=text><u>Observations:<\/u>\n<br>1. Countries with higher GDP Per Capita relatively have more hospital beds per population. ($r=0.296$)\n<br>2. There is a mild negative linear correlation between GDP Per Capita and positive rate. ($r=-0.241$)\n<br>3. There is a mild linear correlation between GDP Per Capita and how strict were the contact tracing policies. ($r=0.231$)\n<br>4. Countries with higher GDP Per Capita relatively have a higher test rate per population. ($r=0.332$)\n<br>5. Countries with higher GDP Per Capita relatively have a higher vaccination rate per population. ($r=0.372$)\n<br>6. Countries with higher GDP Per Capita relatively score better on Economic Support Index. ($r=0.366$)\n<br>7. Countries with higher GDP Per Capita provided relatively better Income Support to its residents. ($r=0.481$)\n<br>8. There is no linear correlation between GDP Per Capita and the amount countries gave to other countries in aid of the pandemic. ($r=0.003$)\n<\/span>","438d1d12":"<span class=text>The model performs poorly on predicting for validation set despite being the best performing model in cross validation. The reason could be overfitting, especially due to <code>changepoint_prior_value<\/code> being high. The top performing 40 models will be trained on both the 1st Validation set and the 2nd Validation set, and the model with <b>consistent<\/b> + <b>good<\/b> performance on both will be selected to predict on the Test set.<\/span>","e441b891":"<span class=text>Commenting out some <code>auto_arima<\/code> calls below as it leads to kaggle kernel memory overload.<\/span>","dc4fe52b":"<span class=text>Now, I will apply the test on the figure of `New Cases` for the complete dataframe, the summed up figures for `World` and individual countries.\n<br><br>\n### <b>Benford on Complete Dataframe<\/b><\/span>","a27c4c8c":"<span class=text markdown=\"1\">\n\n1. <a id='cite_1'><\/a>[^](#up_1) Mathieu, E., Ritchie, H., Ortiz-Ospina, E. et al. A global database of COVID-19 vaccinations. Nat Hum Behav (2021). https:\/\/doi.org\/10.1038\/s41562-021-01122-8<br>\n2. <a id='cite_2'><\/a>[^](#up_2) Hasell, J., Mathieu, E., Beltekian, D. et al. A cross-country database of COVID-19 testing. Sci Data 7, 345 (2020). https:\/\/doi.org\/10.1038\/s41597-020-00688-8<br>\n3. <a id='cite_3'><\/a>[^](#up_3) Attribute the data as the \"COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University\" or \"JHU CSSE COVID-19 Data\" for short, and the url: https:\/\/github.com\/CSSEGISandData\/COVID-19.<br>\n4. <a id='cite_4'><\/a>[^](#up_4) <a id='cite_4'><\/a>[^](#up_4_2) https:\/\/github.com\/CSSEGISandData\/COVID-19\/issues\/4465<br>\n5. <a id='cite_5'><\/a>[^](#up_5) Thomas Hale, Noam Angrist, Rafael Goldszmidt, Beatriz Kira, Anna Petherick, Toby Phillips, Samuel Webster, Emily Cameron-Blake, Laura Hallas, Saptarshi Majumdar, and Helen Tatlow. (2021). \u201cA global panel database of pandemic policies (Oxford COVID-19 Government Response Tracker).\u201d Nature Human Behaviour. https:\/\/doi.org\/10.1038\/s41562-021-01079-8<br>\n6. <a id='cite_6'><\/a>[^](#up_6) Google LLC \"Google COVID-19 Community Mobility Reports\".\nhttps:\/\/www.google.com\/covid19\/mobility\/ Accessed: <date>30-08-2021 16:30<\/date><br>\n7. <a id='cite_7'><\/a>[^](#up_7) https:\/\/commons.wikimedia.org\/wiki\/Data:Cross-country_literacy_rates_-_World_Bank,_CIA_World_Factbook,_and_other_sources_(OWID_2762).tab<br>\n8. <a id='cite_8'><\/a>[^](#up_8) https:\/\/www.gapminder.org\/data\/documentation\/democracy-index\/<br>\n9. <a id='cite_9'><\/a>[^](#up_9) https:\/\/github.com\/CSSEGISandData\/COVID-19\/issues\/3464<br>\n10. <a id='cite_10'><\/a>[^](#up_10) https:\/\/github.com\/CSSEGISandData\/COVID-19\/issues\/3484<br>\n11. <a id='cite_11'><\/a>[^](#up_11) McDermott A. Core Concept: Herd immunity is an important-and often misunderstood-public health phenomenon. Proc Natl Acad Sci U S A. 2021 May 25;118(21):e2107692118. doi: 10.1073\/pnas.2107692118. PMID: 34011611; PMCID: PMC8166024.<br>\n12. <a id='cite_12'><\/a>[^](#up_12) https:\/\/en.wikipedia.org\/wiki\/Basic_reproduction_number<br>\n13. <a id='cite_13'><\/a>[^](#up_13) https:\/\/en.wikipedia.org\/wiki\/Herd_immunity<br>\n14. <a id='cite_14'><\/a>[^](#up_14) https:\/\/github.com\/owid\/covid-19-data\/issues\/1551<br>\n15. <a id='cite_15'><\/a>[^](#up_15) https:\/\/en.wikipedia.org\/wiki\/Benford%27s_law<br>\n16. <a id='cite_16'><\/a>[^](#up_16) Mark J. Nigrini, Benford's Law: Applications for Forensic Accounting, Auditing, and Fraud Detection (Hoboken, NJ: Wiley, 2020).<br>\n17. <a id='cite_17'><\/a>[^](#up_17) https:\/\/people.duke.edu\/~rnau\/411arim3.htm<br>\n18. <a id='cite_18'><\/a>[^](#up_18) Hyndman, R., & Khandakar, Y. (2008). Automatic Time Series Forecasting: The forecast Package for R. Journal of Statistical Software, 27(3), 1 - 22. doi:http:\/\/dx.doi.org\/10.18637\/jss.v027.i03","a98b54d3":"<span class=text>With a single order of non-seasonal differencing, the series has now become stationary.<\/span>","1c386de7":"### Future","436822f5":"<span class=text>The statements below should strictly be taken as <b>observations<\/b> from the data, not conclusions. (The statements are drawn from the scores of the full data, not from the data of averages) There can be plenty of reasons for these correlations that the data might not have captured. One major reason could be under-reporting and false reporting, with or without intention. None of the relationships below should be interpreted as a cause and effect one. These are mere associations\/correlations and some of them might even be flukes. There can even be a third variable which is the caused to rise by one variable and then in turn causes another variable to also rise. Even if there is a causation between the two variables, the correlation coefficient does not reveal which is the cause and which is the effect variable. Heck, even when the correlation coefficient is zero, it still does not imply no association. It only means there is no linear relationship between the two. And so, the statements below should not be taken conclusively.\n<br><br>1. Countries with a higher median age relatively saw a higher death rate per population according to the reported figures. ($r=0.348$)\n<br>2. Countries with higher proportion of older population relatively saw a higher death rate per population. ($r=0.361$)\n<br>3. Countries with a higher percentage of female smokers relatively saw a higher death rate per population. ($r=0.374$)\n<br>4. Countries with higher percentage of elderly population relatively spent more resources for their protection. ($r=0.375$)\n<br>5. Case Fatality Percent has no linear correlation with availability of hospital beds. ($r=-0.086$)\n<\/span>","fc39062e":"<span class=text>p-value > $\\alpha$, so Null hypothesis is failed to be rejected.<\/span>","6ed460e7":"#### Literacy Rate","b7e7e8de":"### Seasonal difference + Trend difference","5bde2b83":"<b>P-values for All Countries<\/b>","b3946573":"### Benford on Individual Countries","4e68f444":"<span class=text>This model performs worse than the model trained on the series that underwent box-cox transformation, but performs only slightly better than the model with both a seasonal and a trend difference. If a choice was to be made between these two models, the one with the slightly less performance will be chosen as the little benefit it gives is not worth the complexity it adds.<\/span>","fe8d5461":"<span class=text><u>Observations:<\/u>\n<br><br>1. It comes with no surprise with the rise in Stringency Index for the pandemic, there was a relative fall in movement to Groceries and Pharmacies ($r=-0.387$), Parks($r=-0.310$), Retail and Recreational places ($r=-0.595$), Transit Stations ($r=-0.541$), Workplaces ($r=-0.449$) and a relative rise of time spent in residential areas ($r=0.562$).\n<br>2. It's interesting to note that with a rise in Literacy Rate, there was a relative drop in movement to Groceries and Pharmacies ($r=-0.234$), Retail and Recreational places ($r=-0.281$), Transit Stations ($r=-0.309$) and Workplaces ($r=-0.224$).\n<br>3. Again no surprise that with the rise in Government Response Index, there was a relative fall in movement to Groceries and Pharmacies ($r=-0.285$), Retail and Recreational places ($r=-0.508$), Transit Stations ($r=-0.468$), Workplaces ($r=-0.401$) and a relative rise in time spent in residential areas ($r=0.455$).\n<\/span>","7793a626":"---\n<a id='ml'><\/a>","4c6a42c2":"<b>Qatar<\/b>","81356496":"<span class=text>To test how well the observed frequencies of the digits match the respective Benford's distribution, the chi-square goodness-of-fit test will be used. The following are the null and the alternative hypotheses for it-\n<br><br>\n$H_0$ : The series follows Benford's distribution.\n<br>\n$H_1$ : The series does not follow Benford's distribution.\n<br><br>\nIf the p-value is greater than or equal to the significance level (p-value $\\geq$ $\\alpha$), which is 0.05, then the null hypothesis will fail to be rejected. However, if p-value $<$ $\\alpha$, then the null hypothesis will be rejected and the alternate hypothesis will be accepted.<\/span>","9b67b914":"<span class=text>Running an ensemble of 10 models slightly reduces the score.<\/span>","efec0950":"<span class=text>We fail to reject the null hypothesis because p-value > $\\alpha$.<\/span>","afb63bc5":"<span class=text>Now that the 5256 models each on the three series (normal, boxcox-transformed, linear regression detrended) have been trained via grid search, their AIC and BIC scores will now be compared. The top 40 models with the best scores will be trained on the Training set and predicted on 1st Validation set with a 30-days rolling forecast, the other models will be discarded.<\/span>","7ec16a00":"### Sources of Data\n\n<span class=text markdown=\"1\">\n\nMain Coronavirus Global Data from OWID [[1]](#citations) [[2]](#citations)<br>\nRecovery Data from JHU [[3]](#citations)<br>\nGovernment Response Tracker Data from Oxford [[4]](#citations)<br>\nGoogle Mobility Trends Data [[5]](#citations)<br>\nLiteracy Rate [[6]](#citations)<br>\nDemocracy Index [[7]](#citations)","33badd0b":"<span class=text>Commenting out for run on Kaggle<\/span>","49c6dfd6":"#### Life Expectancy","394b5d46":"### Combining the three models (Ensemble)","925ca136":"### Identifying Seasonality","3751ed8f":"<span class=text>The best generalising model manually selected from the above dataframe is (0.50, 5, multiplicative, linear, 0.5). This was found by finding a good balance between differences between scores on (1st Cross-Validation and 2nd Cross-Validation) set and manual (1st Validation and 2nd Validation) set, and the averages for the same. And then another difference between the two found differences was done just for comparison but it's not a great measure of comparison. It's possible some other models might perform even better than the one selected by this method.<span>","6abb6614":"<a id='eda_countries'><\/a>\n\n## 5. COUNTRIES\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#eda>Jump to EDA Start<\/a><\/span>","d75c56a3":"<span class=text>Taking an ensemble of the top and varied models did not return a better score. One reason could be that the selected model could already be one of the top performing models on the Test set and an ensemble of averages would only bring its score down. Had an even greater number of models with more variation in their parameters been included in the ensemble, the score could have been better. Perhaps a better scoring ensemble can be created by removing those models in the ensemble which perform poorly on the Test set, but that would be just deliberate overfitting then.<\/span>","fd3828b2":"<span class=text>The ensemble gives poorer results than the best performing Prophet model till now. This is probably because the models were parameterically close to each other. The result could be better if a more diverse set of models were chosen.<\/span>","c64b5df5":"<b>First Three Digits<\/b>","e1c2497d":"<span class=text>The model ((5, 0, 1), (1, 1, 0, 7)) gives the best score on the 2nd Validation set, but it's possible it was just a fluke and the model doesn't generalise well, in which case it will not be used to predict on the test set. To find a model that generalises well, it's performance on both the validation sets should provide low scores. Such a model will be looked for now.<\/span>","216092a1":"<a id='ml_ensemble'><\/a>\n\n## 4. All Models (+ Ensemble)\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#ml>Jump to ML start<\/a><\/span>","baf37450":"<span class=text11>All three variables on y-axis are on a scale of 0-100. For more info, <a href=\"https:\/\/github.com\/OxCGRT\/covid-policy-tracker\/blob\/master\/documentation\/index_methodology.md\">here<\/a>.<\/span>","7ca12564":"<a id='eda_cnc'><\/a>\n\n## 3. COUNTRIES IN CONTINENTS\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#eda>Jump to EDA Start<\/a><\/span>","e0f8ab0e":"<a id='eda_benford'><\/a>\n\n## 6. BENFORD'S LAW\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#eda>Jump to EDA Start<\/a><\/span>\n","0ab353a9":"### Grid Search","00862e09":"<div class=\"alert alert-info\">\n<b>NOTE:<\/b> If you jumped directly to the machine learning part, execute the following cell. For that, you'll need to have the script file <code>helper_functions.py<\/code> in the same folder as this notebook. It'll also import <code>final_world_df.csv<\/code> from my github repository.\n<br><br>If you did not directly jump to this part however, you can skip the next cell.\n<\/div>","5120b5bc":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graph below, you can-<br>\n\u2003\u20031. On each vertical line, drag and select an area highlighting all combinations with it.<br>\n\u2003\u20032. Have multiple drag selections at once.\n<\/details>","ddeb9ccf":"### auto_arima","4ad48ea0":"<b>(Literacy Rate & Democracy Index) Data<\/b> <sup><a href=#cite_7>[7]<\/a><a href=#cite_8>[8]<\/a><\/sup> <a id='up_7'><\/a><a id='up_8'><\/a>","50cf6a54":"### 4.2. Government Measures for Pandemic","e49dc05b":"### 4.3. Country Indicators\/Metrics","af69ca22":"<b>5th Digit<\/b>","124bfeb6":"<span class=text>Commenting out for run on Kaggle<\/span>","cfe0de77":"<span class=text>So far, the model with a trend difference and a seasonal difference far outperform the models with just a single trend difference or a single seasonal difference.<\/span>","b86bd563":"<span class=text>The histogram shows a long tail to the right of the distribution suggesting an exponential distribution.<\/span>","ad9a8352":"## 1. Seasonal Auto-Regressive Integrated Moving Average (SARIMA)\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#ml>Jump to ML start<\/a><\/span>","f784adce":"<span class=text>Despite being already differenced\/detrended by the linear regression model, the standard deviation still is the lowest when a single order non seasonal and seasonal differences are done. Increasing the order of non seasonal difference to two increases the standard deviation. Hence, the differencing with the lowest standard deviation will be used.","6ce4450f":"<b>Iran<\/b>","a07db895":"### <u><span class=text16>Important Note:<\/span><\/u>\n\n<span class=text15>The <code>recovery<\/code> statistic does not include United States throughout the entire project. As the data for the same was unavailable after <code>13th Dec 2020<\/code><sup><a href=#cite_9>[9]<\/a><\/sup> <a id='up_9'><\/a>, the decision was taken to null the entire column (for US) to prevent the sudden fluctuation in data. The other 4 features do include US.<\/span>","245761bb":"<span class=text12>These values change multiple times a day (given that you import the data again) as the data is updated in multiple instances, country by country, and sometimes multiple times a day for a single country. (Recoveries figure is for the last updated date i.e. 4th Aug 2021)<\/span>","ba9d0bec":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graphs below (and all x-y plane graphs), you can-<br>\n\u2003\u20031. <b>Hover<\/b> with your mouse to see more info. (Applicable for non x-y plane graphs too)<br>\n\u2003\u20032. <b>Drag<\/b> on the x-y plane horizontally, vertically or make a box by dragging to zoom in on that area.<br>\n\u2003\u20033. Move the axes up and down by dragging from the middle of the axes.<br>\n\u2003\u20034. Scale the axes by dragging from the dragging from the end of the axes.<br>\n\u2003\u20035. <b>Double click<\/b> anywhere on the graph <b>to restore<\/b> the default view.\n<\/details>","50fd6f20":"<span class=text>The top performing models can be combined together and their predictions averaged. This might give an even better prediction. This is due to the law of large numbers which states the average of multiple experiments will perform better than any single experiment, and give results closer to the expected value.<\/span>","abfa8fac":"#### Picking top 40 models","4bfdefcf":"<span class=text>Commenting out for run on Kaggle<\/span>","a56eb3dd":"#### Democracy Index","e2f05747":"<b>Recovery Data<\/b> <sup><a href=#cite_3>[3]<\/a><\/sup> <a id='up_3'><\/a>","bd37ed17":"<span class=text>As the best results are from models with no differencing, single non-seasonal difference and a seasonal + non-seasonal difference, <code>auto_arima<\/code> can be run again on these specific differencing parameters for a more extensive search, by relaxing the constraints on the parameters.<\/span>","13cbc19e":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graphs below, you can-<br>\n\u2003\u20031. Drag the map around.\n<\/details>","d521fdb0":"Jump to section of EDA -\n\n[0. Introduction](#eda_intro)<br>\n[1. World](#eda_world)<br>\n[2. Continents](#eda_continents)<br>\n[3. Countries in Continents](#eda_cnc)<br>\n[4. Countries in Continents (Bi-variate Analysis)](#eda_cnc_bv)<br>\n[5. Countries](#eda_countries)<br>\n[6. Selected Countries](#eda_sel_countries)<br>\n[7. Benford's Law](#eda_benford)","900cb81e":"### Single Order Difference (Non-seasonal)","9441b51e":"<span class=text>A few variations of differencing and transformations on the series will be computed to get more varied results out of which the ones with best performance will be selected. These will be-\n<br>1. Non-seasonal difference\n<br>2. Seasonal difference\n<br>3. Non-seasonal + seasonal difference\n<br>4. Detrending by model fitting\n<br>5. Box-Cox transformed series","b9a21f12":"<b>Government Response Data<b> <sup><a href=#cite_5>[5]<\/a><\/sup> <a id='up_5'><\/a>","5498d641":"<div class=\"alert alert-warning\">\n<b>NOTE:<\/b> The computation below can take a long time (50mins~) to finish depending on your machine. You can skip it with this jump point below.\n<\/div>\n\n### <b><a href=#skip_prophet_rmses2>JUMP<\/a><\/b>","8e4ec805":"<a id='skip_sarima_val1and2'><\/a>","a1098673":"#### GDP Per Capita","490e905b":"<span class=text>The computation of 1 month rolling forecast on the above chosen model fails, so it wil be skipped.<\/span>","a4acad64":"<span class=text>Null hypothesis can be rejected $($p-value < $0.01)$. Therefore, the series is not trend stationary.<\/span>","3bd869c5":"<span class=text><b>Chi-Square Goodness of Fit Test<\/b><\/span>","a1443eb2":"<details class=text>\n    <summary class=expand>Plotly Tutorial <b>(Click Me!)<\/b><\/summary>\n<br>If you are new to Plotly, I have added these <b>Plotly Tutorial<\/b> buttons for you. There will be one before each new type of graph to explain the various ways in which you can manipulate it. If you are however used to Plotly, then you can ignore these buttons.\n<\/details>","b8242e97":"<a id='skip_sarima_grid'><\/a>","28f5f3b8":"<span class=text>The six features below represent the percentage change in mobility of people as compared to the baseline for that day.<br>\nThe baseline (y-axis `0`) is the median value, for the corresponding day of the week, during the 5-week period Jan 3\u2013Feb 6, 2020.<br>Baseline day represents a <i>normal<\/i> value for that day of the week. Measuring it relative to a normal value for that day of the week is useful because people have different schedules on different days (eg- weekdays and weekends). Measuring it relative to this baseline also means that seasonal variation is not taken into account. And so, a short period of the year can't represent normal for every region on our planet and hence, the comparisons between countries should not be taken stringently. Also, the points below are a single point average of mobility trends of each country from 15th Feb 2020 till today.<br><br>The <code>Residential<\/code> category shows a change in duration of time spent at home whereas the other categories measure a change in total visitors. For more information on each feature, click <a href=\"https:\/\/www.google.com\/covid19\/mobility\/data_documentation.html?hl=en\">here<\/a> and <a href=\"https:\/\/support.google.com\/covid19-mobility\/answer\/9824897?hl=en&ref_topic=9822927\">here<\/a>. <\/span>","11c730de":"<span class=text>The future has been predicted using the same best selected model but not on a boxcox transformed series as boxcox cannot inverse transform negative observations. The difference is negligible.<\/span>","a161bc2d":"---\n<a id='eda'><\/a>","198912b6":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graph below, you can-<br>\n\u2003\u20031. Drag vertical categories and change their order.<br>\n\u2003\u20032. Drag labels on top horizontally and change their order.\n<\/details>","f4aebb13":"<span class=text>As plotting graphs for all countries can get a bit too much, I will be plotting the graphs for a select few countries for a closer look. These countries will be selected based on these measures (along with max <code>new_cases<\/code> having at least 4 digits)-\n<br>1. Least Democracy Index (Saudia Arabia, Iran)\n<br>2. Most Total Cases (USA, India)\n<br>3. Highest Recovered Percent (China)\n<br>4. Lowest Death Percent (Qatar, Singpore)\n<br><br>\n<b>Note:<\/b> Not following Benford's distribution does not equate the data being falsified. There can be many reasons for such discrepancies which this project does not cover.<\/span>","efdc46a6":"<span class=text>The rolling forecast RMSE scores obtained from the top performing models are better than the scores on the models tried manually earlier. But to be even more comprehensive, <code>auto_arima<\/code> will now be deployed to perhaps find some even better models. It is a lot like grid-search but is better optimized and also implements the stepwise algorithm by Hyndman and Khandakar (2008) <sup><a href=#cite_18>[18]<\/a><\/sup> <a id='up_18'><\/a>.It can also use the 1st Validation set to predict on using it as an out-of-bag set.<\/span>","90aa7b56":"<b>3rd Digit<\/b>","cf265fcf":"<div class=\"alert alert-danger\">\n<b>NOTE:<\/b> Tracking of global recovery data was discontinued from 5th August 2021 onwards.\n<\/div>\n\n<sup><a href=#cite_4>[4]<\/a><\/sup> <a id='up_4_2'><\/a>","7bbd5629":"<span class=text><u>Observations:<\/u>\n<br>1. Countries with higher life expectancy relatively also have better access to handwashing facilities for their populace. ($r=0.821$)<\/span>","135feebc":"<span class=text><u>Observations:<\/u>\n<br>1. Countries with a more diverse vaccination policy relatively saw a higher vaccination rate per population. No surprise there. ($r=0.615$)\n<br>2. Unsurprisingly again, countries with a more diverse testing policy relatively saw a higher test rate per population. ($r=0.289$)\n<br>3. The linear correlation between reproduction rate and containment response from government is negligible. ($r=0.1\\sim$)\n<\/span>","824cbc37":"<span class=text>Picking the best models till now and some models with adjacent tweaked parameters, which will now be used to predict on the 2nd Validation set.<\/span>","39d17bde":"### Ensemble","72b89e1e":"<span class=text>If some of the code breaks, it could be due to the datasets having major alterations (apart from the daily updating of figures). In that case, make the variable `STATIC` `True` which imports static files of last updated date from my github repository. The static data is dated `30 August 2021 16:30 IST`. I will update this every 15 days.<\/span>","2df60f2b":"<details class=text>\n    <summary class=expand>Plotly Tutorial<\/summary>\n<br>In the graphs below, you can-<br>\n\u2003\u20031. Select a range by dragging the ends of the slider below the graph.<br>\n\u2003\u20032. Dragging that selected range itself to change the sectional view.<br>\n\u2003\u20033. <b>Click<\/b> on legend to toggle.<br>\n\u2003\u20034. <b>Double<\/b> click on legend to single out.<br>\n\u2003\u20035. Double click on legend again to restore to default.<br><br>\n(3 to 5 are applicable for all graphs with legends)\n<\/details>","c11c6b86":"<span class=text><u>Observations:<\/u>\n<br>1. There is no linear correlation between population density and reproduction rate. ($r=0.003$)\n<br>2. There is no linear correlation between population density and percentage of population affected. ($r=0.025$)<\/span>","c1d24d44":"<b>Singapore<\/b>","8db220fd":"<div class=\"alert alert-warning\">\n<b>NOTE:<\/b> The computation below can take a long time (60mins~) to finish depending on your machine. You can skip it with this jump point below.\n<\/div>\n\n### <b><a href=#skip_hw_grid>JUMP<\/a><\/b>","9c509c60":"<span class=text>The parameters selected are the same as the best performing model until now.","e6a1b666":"<a id='eda_world'><\/a>\n\n## 1. WORLD\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003<span class=jump><a href=#eda>Jump to EDA Start<\/a><\/span>","2bfe1d7e":"<span class=text>When put through two orders of trend differencing, the standard deviation increases but when put through a single order trend difference and a single order weekly seasonal difference, the standard deviation decreases. So, this will be the series that will be modeled on.<\/span>","ab3b0c46":"#### Prophet model with manual parameters","6970b771":"<span class=text>The future has been predicted using the same best selected model but not on a boxcox transformed series as boxcox cannot inverse transform negative observations. The difference is negligible.<\/span>","a0b41157":"<a id='skip_prophet_rmses2'><\/a>","629f4446":"<span class=text>The value of lambda being so close to 0.5 indicates that the boxcox transformation in this case is close to a square root transform.<\/span>","2cec22db":"<a id='preprocess'><\/a><b>Main Data<\/b> <sup><a href=#cite_1>[1]<\/a><\/sup><sup><a href=#cite_2>[2]<\/a><\/sup> <a id='up_1'><\/a><a id='up_2'><\/a>","7cab79ae":"<span class=text>Because p-value > $\\alpha$, we fail to reject the null hypothesis. This means we do not have sufficient evidence to say that the observed distribution of digits is different from Benford's distribution.<\/span>"}}