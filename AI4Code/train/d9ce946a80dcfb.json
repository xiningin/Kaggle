{"cell_type":{"8224124f":"code","95dc81eb":"code","55c3eb58":"code","2dde40fa":"code","0fbc9393":"code","f7146356":"code","40918f5c":"code","bf532587":"code","c974af18":"code","9cacc993":"code","2c8b995e":"code","88d611e0":"code","3d37b740":"code","9c499b74":"code","7c50933c":"code","4a61f119":"code","f948bd57":"markdown","03825c1e":"markdown","6e70741c":"markdown","e702166b":"markdown","cef9fd5e":"markdown","9c9a05ea":"markdown","0363be7e":"markdown","a74f18a1":"markdown","938fd407":"markdown","3d939a97":"markdown"},"source":{"8224124f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","95dc81eb":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntrain_data = train\ntest_data = test","55c3eb58":"train_data.head()","2dde40fa":"test_data.head()","0fbc9393":"train_data = train_data.drop(['Name'], axis=1)\ntest_data = test_data.drop(['Name'], axis=1)\n\ntrain_data = train_data.drop(['SibSp'], axis=1)\ntest_data = test_data.drop(['SibSp'], axis=1)\n\ntrain_data = train_data.drop(['Parch'], axis=1)\ntest_data = test_data.drop(['Parch'], axis=1)\n\ntrain_data = train_data.drop(['Ticket'], axis=1)\ntest_data = test_data.drop(['Ticket'], axis=1)\n\ntrain_data = train_data.drop(['Cabin'], axis=1)\ntest_data = test_data.drop(['Cabin'], axis=1)\n","f7146356":"train_data.head()","40918f5c":"test_data.head()","bf532587":"data = pd.concat((train_data.loc[:,'Sex':'Fare'],\n                      test_data.loc[:,'Sex':'Fare']))\n\ndata.head()","c974af18":"data.isna().sum()","9cacc993":"data = pd.get_dummies(data)\ndata = data.fillna(data.mean())\ndata.isna().sum()","2c8b995e":"X_train = data[:train_data.shape[0]]\nX_test = data[train_data.shape[0]:]","88d611e0":"print(X_train.shape)\nprint(X_test.shape)","3d37b740":"data","9c499b74":"from sklearn.ensemble import RandomForestClassifier\ny = train[\"Survived\"]\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)","7c50933c":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.head()","4a61f119":"output.to_csv('titanic_random_forest.csv', index=False)\nprint(\"Your submission was successfully saved!\")","f948bd57":"split the dataset","03825c1e":"load the dataset provided","6e70741c":"selecting the important feature for training data","e702166b":"saving output","cef9fd5e":"filling the null values","9c9a05ea":"show the test data","0363be7e":"creating feature dataframe","a74f18a1":"checking null values","938fd407":"show the train data","3d939a97":"implementing the Random Forest Classifier "}}