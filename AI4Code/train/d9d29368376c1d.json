{"cell_type":{"36dd7261":"code","53bf6dd3":"code","19ae1a35":"code","81d5e58e":"code","7d3c9adb":"code","ae00521d":"code","6bd2ee16":"code","1fc78058":"code","1bff5fcc":"code","9e0fd713":"code","387721ea":"code","5b85324f":"code","0c1a057c":"code","a92af4f6":"code","47373cf2":"code","b972f979":"code","b21d45f6":"code","2dc56783":"code","1b4c68fa":"code","137906b5":"markdown","5233d56e":"markdown","33e6af92":"markdown","6ec13fd2":"markdown","aeeb1452":"markdown","76be29bb":"markdown","89f96323":"markdown","7075534a":"markdown","d9dcf618":"markdown","617089b0":"markdown","7253520a":"markdown","37cc1097":"markdown","606c32cf":"markdown","5f20219f":"markdown","2346cc94":"markdown","8bf56416":"markdown"},"source":{"36dd7261":"import PIL.Image, PIL.ImageFont, PIL.ImageDraw\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport tensorflow_datasets as tfds\nimport tensorflow.keras as ks","53bf6dd3":"gpus = tf.config.experimental.list_logical_devices('GPU')\n\nstrategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\nprint(\"running on gpu\", [gpu.name for gpu in gpus])","19ae1a35":"batch_size = 64 * strategy.num_replicas_in_sync\n\n\ndef get_training_dataset():\n    with strategy.scope():\n        dataset = tfds.load('mnist', split='train', as_supervised=True, try_gcs=True)\n        dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n        dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n        dataset = dataset.repeat()\n        dataset = dataset.batch(batch_size, drop_remainder=True)\n        dataset = dataset.prefetch(-1)\n\n    return dataset\n\ndef get_validation_dataset():\n    dataset = tfds.load(\"mnist\", split=\"test\", as_supervised=True, try_gcs=True)\n    dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n\n    #dataset = dataset.cache() # this small dataset can be entirely cached in RAM\n    dataset = dataset.batch(10000, drop_remainder=True) # 10000 items in eval dataset, all in one batch\n    dataset = dataset.repeat() # Mandatory for Keras for now\n    return dataset\n\n    \n    return dataset","81d5e58e":"def read_image_tfds(image, label):\n    \n    xmin = tf.random.uniform((), 0, 48, dtype=tf.int32)\n    ymin = tf.random.uniform((), 0, 48, dtype=tf.int32)\n    image = tf.reshape(image, (28, 28, 1,))\n    image = tf.image.pad_to_bounding_box(image, ymin, xmin, 75, 75)\n    image = tf.cast(image, tf.float32)\/255.0\n    xmin = tf.cast(xmin, tf.float32)\n    ymin = tf.cast(ymin, tf.float32)\n    xmax = (xmin+28)\/75\n    ymax = (ymin+28)\/75\n    xmin = xmin\/75\n    ymin = ymin\/75\n    \n    return image, (tf.one_hot(label, 10), [xmin, ymin, xmax, ymax])   \n    ","7d3c9adb":"def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n    \n    batch_train_ds = training_dataset.unbatch().batch(N)\n    \n    if tf.executing_eagerly():\n\n        for validation_digits, (validation_labels, validation_bboxes) in validation_dataset:\n\n            validation_digits = validation_digits.numpy()\n            validation_labels = validation_labels.numpy()\n            validation_bboxes = validation_bboxes.numpy()\n            break\n\n        for training_digits, (training_labels, training_bboxes) in batch_train_ds:\n            training_digits = training_digits.numpy()\n            training_labels = training_labels.numpy()\n            training_bboxes = training_bboxes.numpy()\n            break\n    \n    validation_labels = np.argmax(validation_labels, axis=1)\n    training_labels = np.argmax(training_labels, axis=1)\n\n    return (training_digits, training_labels, training_bboxes, \n           validation_digits, validation_labels, validation_bboxes)","ae00521d":"\n\nwith strategy.scope():\n    training_dataset = get_training_dataset()\n    validation_dataset = get_validation_dataset()\n\n\n(training_digits, training_labels, training_bboxes, \nvalidation_digits, validation_labels, validation_bboxes) = dataset_to_numpy_util(training_dataset,\n                                                                                 validation_dataset, 10)\n","6bd2ee16":"def display_digits_with_boxes(digits, predictions, labels, pred_bboxes, bboxes, iou, title):\n\n    n = 10\n\n    indexes = np.random.choice(len(predictions), size=n)\n    n_digits = digits[indexes]\n    n_predictions = predictions[indexes]\n    n_labels = labels[indexes]\n\n    n_iou = []\n    if len(iou) > 0:\n        n_iou = iou[indexes]\n\n    if (len(pred_bboxes) > 0):\n        n_pred_bboxes = pred_bboxes[indexes,:]\n\n    if (len(bboxes) > 0):\n        n_bboxes = bboxes[indexes,:]\n\n\n    n_digits = n_digits * 255.0\n    n_digits = n_digits.reshape(n, 75, 75)\n    fig = plt.figure(figsize=(20, 4))\n    plt.title(title)\n    plt.yticks([])\n    plt.xticks([])\n\n    for i in range(10):\n        ax = fig.add_subplot(1, 10, i+1)\n        bboxes_to_plot = []\n        if (len(pred_bboxes) > i):\n            bboxes_to_plot.append(n_pred_bboxes[i])\n\n        if (len(bboxes) > i):\n            bboxes_to_plot.append(n_bboxes[i])\n\n        img_to_draw = draw_bounding_boxes_on_image_array(image=n_digits[i], boxes=np.asarray(bboxes_to_plot), color=['red', 'green'], display_str_list=[\"true\", \"pred\"])\n        plt.xlabel(n_predictions[i])\n        plt.xticks([])\n        plt.yticks([])\n\n        if n_predictions[i] != n_labels[i]:\n            ax.xaxis.label.set_color('red')\n\n\n\n        plt.imshow(img_to_draw)\n\n        if len(iou) > i :\n            color = \"black\"\n            if (n_iou[i][0] < iou_threshold):\n                color = \"red\"\n            ax.text(0.2, -0.3, \"iou: %s\" %(n_iou[i][0]), color=color, transform=ax.transAxes)\n\n","1fc78058":"def draw_bounding_boxes_on_image_array(image, boxes, color=[], thickness=1, display_str_list=()):\n    \n    image_pil = PIL.Image.fromarray(image)\n    rgbimg = PIL.Image.new('RGBA', image_pil.size)\n    rgbimg.paste(image_pil)\n    \n    draw_bounding_boxes_on_image(rgbimg, boxes, color, thickness, display_str_list)\n    \n    return np.array(rgbimg)\n    \n\ndef draw_bounding_boxes_on_image(image, boxes, color=[], thickness=1, display_str_list=()):\n    \n    boxes_shape = boxes.shape\n    \n    if not boxes_shape:\n        return\n    \n    if len(boxes_shape)!=2 or boxes_shape[1]!=4:\n        raise ValueError('Input must be of size [N, 4]')\n    \n    for i in range(boxes_shape[0]):\n        draw_bounding_box_on_image(image, boxes[i, 1], boxes[i, 0], boxes[i, 3], boxes[i, 2], color[i], thickness, \n                                  display_str_list[i])\n        \ndef draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax, color='red', thickness=1, \n                              display_str_list=None, use_normalized_coordinates=True):\n    \n    draw = PIL.ImageDraw.Draw(image)\n    \n    im_width, im_height = image.size\n    \n    if use_normalized_coordinates:\n        \n        (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n    \n    else:\n        (left, right, top, bottom) = (xmin, ymin, xmax, ymax)\n    \n    draw.line([(left, top), (left, bottom),(right, bottom), (right, top), (left, top)], width=thickness, fill=color)\n    ","1bff5fcc":"display_digits_with_boxes(training_digits, training_labels, training_labels, np.array([]), \n                         training_bboxes, np.array([]), 'training_digits and their labels')\n\ndisplay_digits_with_boxes(validation_digits, validation_labels, validation_labels, np.array([]), \n                          validation_bboxes, np.array([]), 'validation_digits and their labels' )","9e0fd713":"def feature_extractor(inputs):\n    \n    x = ks.layers.Conv2D(16, activation='relu', kernel_size=3, input_shape=(75, 75, 1))(inputs)\n    x = ks.layers.AveragePooling2D((2, 2))(x)\n    x = ks.layers.Conv2D(32, activation='relu', kernel_size=3)(x)\n    x = ks.layers.AveragePooling2D((2, 2))(x)\n    x = ks.layers.Conv2D(64, activation='relu', kernel_size=3)(x)\n    x = ks.layers.AveragePooling2D((2, 2))(x)\n    return x\n\ndef dense_layer(inputs):\n    x = ks.layers.Flatten()(inputs)\n    x = ks.layers.Dense(128, activation='relu')(x)\n    return x\n\ndef classifier(inputs):\n    classifier_output = ks.layers.Dense(10, activation='softmax',name='classifier')(inputs)\n    return classifier_output\n\ndef bounding_box_regression(inputs):\n    bounding_box_regression_output = ks.layers.Dense(units='4', name='bounding_box')(inputs)\n    \n    return bounding_box_regression_output\n\ndef final_model(inputs):\n    feature_cnn = feature_extractor(inputs)\n    dense_output = dense_layer(feature_cnn)\n    classification_output = classifier(dense_output)\n    bounding_box = bounding_box_regression(dense_output)\n    \n    model = ks.Model(inputs=inputs, outputs=[classification_output, bounding_box])\n    \n    return model\n\ndef define_and_compile_model(inpust):\n    \n    model = final_model(inputs)\n    model.compile(optimizer='adam', loss={\n        'classifier': 'categorical_crossentropy', \n        'bounding_box': 'mse'\n    }, \n                  metrics={\n                     'classifier':'acc',\n                     'bounding_box': 'mse'   \n                         })\n    return model","387721ea":"with strategy.scope():\n    inputs = tf.keras.layers.Input(shape=(75, 75, 1,))\n    model = define_and_compile_model(inputs)\nmodel.summary()","5b85324f":"steps_per_epoch = 60000\/(batch_size*5)\nvalidation_steps = 1\n\nhistory = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, validation_data=validation_dataset, \n                   validation_steps=1, epochs=40, verbose=0)","0c1a057c":"loss, classification_loss, bounding_box_loss, classification_accuracy, bounding_box_mse = model.evaluate(validation_dataset, steps=1)","a92af4f6":"def intersection_over_union(pred_box, true_box):\n    xmin_pred, ymin_pred, xmax_pred, ymax_pred =  np.split(pred_box, 4, axis = 1)\n    xmin_true, ymin_true, xmax_true, ymax_true = np.split(true_box, 4, axis = 1)\n\n    smoothing_factor = 1e-10\n\n    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n    ymin_overlap = np.maximum(ymin_pred, ymin_true)\n    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n\n    pred_box_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n    true_box_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)\n\n    overlap_area = np.maximum((xmax_overlap - xmin_overlap), 0)  * np.maximum((ymax_overlap - ymin_overlap), 0)\n    union_area = (pred_box_area + true_box_area) - overlap_area\n    \n    iou = (overlap_area + smoothing_factor) \/ (union_area + smoothing_factor)\n\n    return iou","47373cf2":"def check_iou(iou, iou_threshold=0.6):\n    \n    good = 0\n    bad = 0\n    \n    for i in iou:\n        if i >= iou_threshold:\n            good +=1\n            continue\n        bad += 1\n    return good, bad\n            ","b972f979":"predictions = model.predict(validation_digits, steps=1)\nprediction_labels = np.argmax(predictions[0], axis=1)\n\npredicted_bboxes = predictions[1]\n\niou = intersection_over_union(predicted_bboxes, validation_bboxes)\n\ngood, bad = check_iou(iou)\n\nprint('the number of good bounding box prediction: ', good)\nprint('the number of bad bounding box prediction: ', bad)\n\niou_threshold=0.6","b21d45f6":"display_digits_with_boxes(validation_digits, prediction_labels, validation_labels, \n                         predicted_bboxes, validation_bboxes, iou, 'True and Predicted values')","2dc56783":"def plot_metrics(metric_name, title, ylim=5):\n    plt.style.use('ggplot')\n    plt.figure(figsize=(5, 5))\n    plt.title(title)\n    plt.ylim(0,ylim)\n    plt.plot(history.history[metric_name],color='blue',label=metric_name)\n    plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)\n    plt.legend([metric_name, f'val_{metric_name}'])\n  ","1b4c68fa":"plot_metrics(\"classifier_loss\", \"Classification Loss\", ylim=2)\nplot_metrics(\"bounding_box_loss\", \"Bounding Box Loss\", ylim=0.025)","137906b5":"## *creating our own bounding box by placing the images randomly on a 75x75 image*","5233d56e":"## *Training the model*","33e6af92":"# *Object Localization using mnist dataset using Tensorflow*","6ec13fd2":"## *Visualizing the models metrics -->to see how it learned*","aeeb1452":"## *For knowing how well the bounding box are predicted with respect to the true boxes, the intersection over union formulated function is used*","76be29bb":"## *Let's create the model and compile it*","89f96323":"## *We'll create a multiple output model which would be able to classify the image as well predict the bounding box*","7075534a":"## *Lets Visualize a number of images in random with the bounding box*","d9dcf618":"## *we'll make use of GPU for training our model*","617089b0":"## *Load the dataset and from the tensorflow datasets*","7253520a":"## *Lets check how the model predicts using the validation data*","37cc1097":"## *checking how many boxes are predicted successfully*","606c32cf":"## *Evaluating the model*","5f20219f":"![image.png](attachment:6209d59c-be0f-49c9-bf14-d9e0bc26601c.png)","2346cc94":"## *Visualizing the prediction*","8bf56416":"### *Lets Load the necessary libraries for this notebook*"}}