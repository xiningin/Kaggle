{"cell_type":{"091f3373":"code","3e60271c":"code","e03d1678":"code","f807a586":"code","68580009":"code","42a5d5ff":"code","348d282c":"code","c68251ae":"code","05e0bb0d":"code","810ec83f":"code","f9a94382":"markdown"},"source":{"091f3373":"##################\n# I Initialization\n##################\n\n#+++++++++++++++\n# Load libraries\n#+++++++++++++++\n\nimport os\nfrom pathlib import Path # for path in Windows and Unix\nimport zipfile\nimport numpy as np\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.model_selection import GridSearchCV\nfrom imblearn.over_sampling import SMOTE\n\n#+++++++++++++++++++\n# Define Environment\n#++++++++++++++++++\n\nenvironemnt = 'kaggle'\n\n#+++++++++++++++++++++++++++\n# Define the working folders\n#+++++++++++++++++++++++++++\n\n# see https:\/\/careerkarma.com\/blog\/python-list-files-in-directory\/\n# See https:\/\/medium.com\/@ageitgey\/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f\n\nif environemnt == 'kaggle':\n    project_data_folder = Path('\/kaggle\/input\/beta-lactamase-001-data-wrangling-and-eda\/')\nif environemnt == 'local':\n    project_data_folder = Path('\/home\/will\/Documents\/\/Python\/Beta_lactamase\/Data\/')\nif environemnt == 'colab':\n    project_data_folder = Path('\/content\/drive\/MyDrive\/Bioinformatics\/Beta-lactamase\/Data\/')\n    \n#++++++++++++++++++++++++\n# Load the processed data\n#++++++++++++++++++++++++\n\nfile_path = project_data_folder \/ 'beta-lactamase_filtered_dataset.csv'\ndf = pd.read_csv(file_path)\ndf.head()","3e60271c":"#####################\n# II Data preparation\n#####################\n\n#+++++++++++++++++++\n# Feature enginering\n#+++++++++++++++++++\n\n# Drop content no useful for prediction\n# canonical_smiles, standard_relation, standard_value, standard_units, \n# standard_type, target_pref_name, bao_label\n\ncolumns_to_drop = ['canonical_smiles', 'standard_relation', 'standard_value', 'standard_units', \n                   'standard_type', 'target_pref_name', 'bao_label', 'Name', 'molecule_chembl_id']\ndf1 = df.drop(columns_to_drop, axis = 1)\n\n# Recode pchembl_value\t\n# pChEMBL values <5 == 'Inactive' pChEMBL values > 6 == 'Active' pChEMBL values 5-6 == 'Intermediate'\n# Inactive = 0\n# Intermediate = 1\n# Active = 2\n\ndef pchembl_value_encoding(pchembl_value):\n    if pchembl_value < 5:\n        return 'Inactive'\n    elif pchembl_value > 5 and pchembl_value < 6:\n        return 'Intermediate'\n    else:\n        return 'Active'\n\ndf1['pchembl_value_code'] = df1.apply(lambda row : pchembl_value_encoding(row['pchembl_value']), axis = 1)\n\ndf1 = df1.drop(['pchembl_value'], axis = 1)\ndf1.head()","e03d1678":"#++++++++++++++++++++++++++++++++++++++++++++\n# Exclude molecule with intermediate activity\n#++++++++++++++++++++++++++++++++++++++++++++\n\n# see https:\/\/www.kaggle.com\/sayalaruano\/eda-fingerprint-calc-binary-classifiers\/comments\n\ndf1 = df1[df1['pchembl_value_code'] != 'Intermediate']","f807a586":"#+++++++++++++++++++++++\n# activities repartition\n#+++++++++++++++++++++++\n\npchembl_value_code = df1.pchembl_value_code.value_counts()\npchembl_value_code.plot.bar(figsize=(8,4), color = ['#F8766D', '#00BFC4'], ec='black')\n\nplt.title('Biomolecule activities repartition', fontsize=14, fontweight='black', pad=15)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","68580009":"#+++++++++++++++++++++++++++++++++++++++++\n# Split data into input and output objects\n#+++++++++++++++++++++++++++++++++++++++++\n\nfrom sklearn.utils import shuffle\n\nX = df1.drop(['pchembl_value_code'], axis = 1)\ny = df1['pchembl_value_code']\nX, y = shuffle(X, y)","42a5d5ff":"#++++++++++++++++++++++++++++++\n# Remove low variance features\n#++++++++++++++++++++++++++++++\n\n# See https:\/\/dataprofessor.github.io\/ds\/bioinformatics\/cheminformatics\/padelpy\/scikit-learn\/2021\/07\/06\/_07_06_padelpy.html#Load-HCV-dataset\n\nfrom sklearn.feature_selection import VarianceThreshold\n\ndef remove_low_variance(input_data, threshold=0.1):\n    selection = VarianceThreshold(threshold)\n    selection.fit(input_data)\n    return input_data[input_data.columns[selection.get_support(indices=True)]]\n\nX = remove_low_variance(X, threshold=0.1)\nX","348d282c":"#########################\n# III Random Forest model\n#########################\n\n# see Basic Code Stencil (PRACTICAL) Data Science infinity\n# see https:\/\/towardsdatascience.com\/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n# see https:\/\/medium.com\/@benfenison\/gridsearching-a-random-forest-classifier-fc225609699c\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)\n\n# Instanciate the grid search object\nrf_grid = {\"n_estimators\" : [100, 150, 200, 250, 400, 500, 750, 100],\n           \"max_depth\" : [None , 3 , 5 , 10],\n           \"min_samples_split\" : np.arange(2 , 20 ,4),\n           \"min_samples_leaf\" : np.arange(1 , 20 ,4)}\n\ngscv = GridSearchCV(\n    estimator = RandomForestClassifier(random_state=42),\n    param_grid = rf_grid,\n    cv = 5,\n    scoring = 'accuracy',\n    n_jobs = -1\n)\n\n# Fit to data\ngscv.fit(X_train, y_train)\n\n# Get the best CV score\ngscv.best_score_","c68251ae":"# Optimal parameters\ngscv.best_params_","05e0bb0d":"# Create optimal model object\nclf = gscv.best_estimator_\n\n# Train the optimal model\n# Train our model\nclf.fit(X_train, y_train)\n\n# Assess the model accuracy\n# see https:\/\/stackoverflow.com\/questions\/31421413\/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case\n\ny_pred = clf.predict(X_test)\n\n# Accuracy\nprint('accuracy score:', accuracy_score(y_test, y_pred))\n\n# Precision\nprint('precision score:', precision_score(y_test, y_pred, average=\"macro\"))\n\n# Recall score\nprint('recall score:', recall_score(y_test, y_pred, average=\"macro\"))\n\n# F1 score\nprint('F1 score:',f1_score(y_test, y_pred, average=\"macro\"))","810ec83f":"# Feature importance\nresult = permutation_importance(clf, X_test, y_test, n_repeats = 10, random_state = 42)\n\npermutation_importance= pd.DataFrame(result[\"importances_mean\"])\nfeature_names = pd.DataFrame(X.columns)\npermutation_importance_summary = pd.concat([feature_names, permutation_importance], axis = 1)\npermutation_importance_summary.columns = [\"input_variable\", \"feature_importance\"]\npermutation_importance_summary.sort_values(by = \"feature_importance\", inplace=True)\n\n# List the 20 top features\npermutation_importance_summary.head(20)","f9a94382":"# Introduction\n\nThis project proposed by [Data Professor](https:\/\/www.youtube.com\/channel\/UCV8e2g4IWQqK71bbzGDEI4Q) aims to build models predicting molecules binding to the Beta-Lactamase protein. For the complete project description, see this [video](https:\/\/www.youtube.com\/watch?v=_GtEgiWWyK4) on the [Data Professor](https:\/\/www.youtube.com\/channel\/UCV8e2g4IWQqK71bbzGDEI4Q) channel.  \n\n* The EDA and data pre-processing were performed in the notebook [Beta-Lactamase_001_Data_Wrangling_and_EDA](https:\/\/www.kaggle.com\/wguesdon\/beta-lactamase-001-data-wrangling-and-eda\/edit\/run\/83400192).\n* Model baseline was performed in the notebook [Beta-Lactamase_002_classification_model](https:\/\/www.kaggle.com\/wguesdon\/beta-lactamase-002-classification-model)\n* Models comparision were performed in the notebook [Beta-Lactamase_003_Classification_Pipeline](https:\/\/www.kaggle.com\/wguesdon\/beta-lactamase-003-classification-pipeline)\n* This notebook contains the tunning of the selected model with the best performance."}}