{"cell_type":{"9e82d9cd":"code","5c2a2fb7":"code","7ed1c8ca":"code","52a74d0c":"code","1297a6e4":"code","d63ad18a":"code","c34113ad":"code","bf16d309":"code","c39bd104":"code","12179c24":"code","f90e99f7":"code","ac61f21e":"code","49a53426":"code","901ce823":"code","977f3dd7":"code","e7ebc8ad":"code","e41b4d63":"code","09e053fd":"code","53a68cfe":"code","54538668":"code","113d15b5":"code","b0ff4627":"code","878d144b":"code","4da63ca3":"code","781c9a29":"code","7cb4da2d":"code","f900c47c":"code","89644ee7":"code","f60886bc":"code","babb55fd":"code","db0ee31b":"code","aea8d92a":"code","e29d7390":"code","1e3cb733":"code","4c79d7d0":"code","32f0a632":"code","8b21ebab":"code","89227976":"code","1f6ea5ae":"code","db34df03":"code","cf0c24db":"code","bc2aa977":"code","de3a870b":"code","734703e6":"code","acc76954":"code","d33ef8a0":"code","57ae85e4":"code","3c47bb36":"code","381dd6b8":"code","3ef9cfcd":"code","67d53a58":"code","6ce19e0c":"code","ea25ecc5":"code","da3ffee1":"code","4d8fe395":"code","4d57804f":"code","e98223f9":"code","63ac2298":"code","187450e9":"code","0ab6c8dd":"code","39e28ee4":"code","3652aaa1":"code","c04f8ce8":"code","4d31ae10":"markdown","dca0ff2f":"markdown","d3b01eaa":"markdown","fde997a9":"markdown","b0b9565d":"markdown","551bfcda":"markdown","3a05662d":"markdown","57fb2ac5":"markdown","7fa907fb":"markdown"},"source":{"9e82d9cd":"!pip install \/kaggle\/input\/iterative-stratification\/iterative-stratification-master\/","5c2a2fb7":"import pandas as pd\nimport numpy as np\nfrom fastai.vision.all import *\nimport pickle\nimport os","7ed1c8ca":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet50-19c8e357.pth'\n# !cp '..\/input\/resnet34\/resnet34.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet34-333f7ec4.pth'","52a74d0c":"path = Path('..\/input\/hpa-cell-tiles-sample-balanced-dataset')","1297a6e4":"df = pd.read_csv(path\/'cell_df.csv')","d63ad18a":"df.head()","c34113ad":"len(df)","bf16d309":"labels = [str(i) for i in range(19)]\nfor x in labels: df[x] = df['image_labels'].apply(lambda r: int(x in r.split('|')))","c39bd104":"dfs = df.sample(frac=0.1, random_state=42)\ndfs = dfs.reset_index(drop=True)\nlen(dfs)","12179c24":"unique_counts = {}\nfor lbl in labels:\n    unique_counts[lbl] = len(dfs[dfs.image_labels == lbl])\n\nfull_counts = {}\nfor lbl in labels:\n    count = 0\n    for row_label in dfs['image_labels']:\n        if lbl in row_label.split('|'): count += 1\n    full_counts[lbl] = count\n    \ncounts = list(zip(full_counts.keys(), full_counts.values(), unique_counts.values()))\ncounts = np.array(sorted(counts, key=lambda x:-x[1]))\ncounts = pd.DataFrame(counts, columns=['label', 'full_count', 'unique_count'])\ncounts.set_index('label').T\n","f90e99f7":"len(dfs)","ac61f21e":"nfold = 5\nseed = 42\n\ny = dfs[labels].values\nX = dfs[['image_id', 'cell_id']].values\n\ndfs['fold'] = np.nan\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nmskf = MultilabelStratifiedKFold(n_splits=nfold, random_state=seed)\nfor i, (_, test_index) in enumerate(mskf.split(X, y)):\n    dfs.iloc[test_index, -1] = i\n    \ndfs['fold'] = dfs['fold'].astype('int')","49a53426":"dfs['is_valid'] = False\ndfs['is_valid'][dfs['fold'] == 0] = True","901ce823":"dfs.is_valid.value_counts()","977f3dd7":"def get_x(r): return path\/'cells'\/(r['image_id']+'_'+str(r['cell_id'])+'.jpg')\nimg = get_x(dfs.loc[12])\nimg = PILImage.create(img)\nimg.show();","e7ebc8ad":"def get_y(r): return r['image_labels'].split('|')\nget_y(dfs.loc[12])","e41b4d63":"sample_stats = ([0.07237246, 0.04476176, 0.07661699], [0.17179589, 0.10284516, 0.14199627])","09e053fd":"item_tfms = RandomResizedCrop(224, min_scale=0.75, ratio=(1.,1.))\nbatch_tfms = [*aug_transforms(flip_vert=True, size=128, max_warp=0), Normalize.from_stats(*sample_stats)]\nbs=256","53a68cfe":"dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock(vocab=labels)),\n                splitter=ColSplitter(col='is_valid'),\n                get_x=get_x,\n                get_y=get_y,\n                item_tfms=item_tfms,\n                batch_tfms=batch_tfms\n                )\ndls = dblock.dataloaders(dfs, bs=bs)","54538668":"# dblock.summary(dfs)","113d15b5":"dls.show_batch(nrows=3, ncols=3)","b0ff4627":"learn = cnn_learner(dls, resnet50, metrics=[accuracy_multi, PrecisionMulti()]).to_fp16()","878d144b":"# learn.lr_find()\n# SuggestedLRs(lr_min=0.03630780577659607, lr_steep=0.02754228748381138)","4da63ca3":"lr=3e-2","781c9a29":"learn.fine_tune(2,base_lr=lr)","7cb4da2d":"learn.recorder.plot_loss()","f900c47c":"from sklearn.metrics import multilabel_confusion_matrix as cm","89644ee7":"# val_targ = torch.stack([x[1] for x in learn.dls.valid_ds], dim=0).numpy()\n# val_targ.shape","f60886bc":"val_targ = dfs[labels][dfs.is_valid == True].values","babb55fd":"val_targ.shape","db0ee31b":"val_preds_all = learn.get_preds(dl=learn.dls.valid)","aea8d92a":"val_preds = val_preds_all[0].numpy()","e29d7390":"val_preds = val_preds > 0.5","1e3cb733":"full_preds = val_preds_all[0].numpy()","4c79d7d0":"vis_arr = cm(val_targ, val_preds)","32f0a632":"# i = 60\n# print(learn.dls.valid.dataset[i][1])\n# print(val_preds[i])\n# print(full_preds[i])\n# learn.dls.valid.dataset[i][0]","8b21ebab":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ndef print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=14):\n\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names,\n    )\n\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    axes.set_ylabel('True label')\n    axes.set_xlabel('Predicted label')\n    axes.set_title(\"Confusion Matrix for the class - \" + class_label)","89227976":"fig, ax = plt.subplots(5, 4, figsize=(12, 16))\n    \nfor axes, cfs_matrix, label in zip(ax.flatten(), vis_arr, labels):\n    print_confusion_matrix(cfs_matrix, axes, label, [\"0\", \"1\"])\n\nfig.tight_layout()\nplt.show()","1f6ea5ae":"val = dfs[dfs.is_valid==True]\nlen(val[val['16'] == 1])","db34df03":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(val_targ, val_preds)\naverage_precision","cf0c24db":"from sklearn.metrics import precision_recall_curve\n\nprecision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(19):\n    precision[i], recall[i], _ = precision_recall_curve(val_targ[:, i], val_preds[:, i])\n    average_precision[i] = average_precision_score(val_targ[:, i], val_preds[:, i])\n\n# A \"micro-average\": quantifying score on all classes jointly\nprecision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(val_targ.ravel(), val_preds.ravel())\naverage_precision[\"micro\"] = average_precision_score(val_targ, val_preds, average=\"micro\")\nprint('Average precision score, micro-averaged over all classes: {0:0.2f}'.format(average_precision[\"micro\"]))","bc2aa977":"average_precision","de3a870b":"path = Path('..\/input\/hpa-cell-tiles-test-with-enc-dataset')","734703e6":"df = pd.read_csv(path\/'cell_df.csv')","acc76954":"df.to_csv('cell_df.csv', index=False)","d33ef8a0":"test_dl = learn.dls.test_dl(df)","57ae85e4":"test_dl.show_batch()","3c47bb36":"preds, _ = learn.get_preds(dl=test_dl)","381dd6b8":"preds.shape","3ef9cfcd":"with open('preds.pickle', 'wb') as handle:\n    pickle.dump(preds, handle)","67d53a58":"tta, _ = learn.tta(dl=test_dl)","6ce19e0c":"tta.shape","ea25ecc5":"with open('tta.pickle', 'wb') as handle:\n    pickle.dump(tta, handle)","da3ffee1":"cls_prds = torch.argmax(preds, dim=-1)\nlen(cls_prds), cls_prds","4d8fe395":"sample_submission = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/sample_submission.csv')\nsample_submission.head()","4d57804f":"df['cls'] = cls_prds\ndf['pred'] = df[['cls', 'enc']].apply(lambda r: str(r[0]) + ' 1 ' + r[1], axis=1)\ndf.head()","e98223f9":"subm = df.groupby(['image_id'])['pred'].apply(lambda x: ' '.join(x)).reset_index()\n# subm = subm.loc[3:]\nsubm.head()","63ac2298":"sub = pd.merge(\n    sample_submission,\n    subm,\n    how=\"left\",\n    left_on='ID',\n    right_on='image_id',\n)","187450e9":"sub.head()","0ab6c8dd":"def isNaN(num):\n    return num != num","39e28ee4":"for i, row in sub.iterrows():\n    if isNaN(row['pred']): continue\n    sub.PredictionString.loc[i] = row['pred']","3652aaa1":"sub = sub[sample_submission.columns]\nsub.head()","c04f8ce8":"sub.to_csv('submission.csv', index=False)","4d31ae10":"## Change below to `frac=1` to run on the whole training sample","dca0ff2f":"I trained for 10 epochs in the 0.342 leaderboard submission. ","d3b01eaa":"## Using multilabel stratification for the train-validation split.\n\nThere is some leakage in the code below (cells belonging to the same image should be in the same split). However, when I fixed that, I got a lower score... coincidence? ","fde997a9":"## Where are the mistakes? ","b0b9565d":"## Let's train!","551bfcda":"# fastai training with the data-block API\nfastai is a great tool to create a strong baseline quickly. I use pretty much out of the box approach for multilabel classification, with resnet50 backbone, one cycle training, lr finder etc. The data block API is a great way to prepare the data, and comes with a default set of augmentations that I use as well.\n\nSolution overview: https:\/\/www.kaggle.com\/c\/hpa-single-cell-image-classification\/discussion\/221550\n\n### I will smile for every upvote :) ","3a05662d":"## Using fastai data block API with item and batch transforms\n\nRead more: https:\/\/docs.fast.ai\/tutorial.datablock.html","57fb2ac5":"# Inference\nThis is running on the public test data preprocessed in the same way as train. We will save both regular preds and preds with TTA so that we can use them later in a separate submission notebook. ","7fa907fb":"Thank you for your attention! Looking forward to questions and comments!"}}