{"cell_type":{"ff7b7d7e":"code","5966fbfa":"code","254f5066":"code","168b66cf":"code","42f5445a":"code","aeac4aa9":"code","3ce0936e":"code","32250d9f":"code","f9b25ae3":"code","b38d592d":"code","1ff34518":"code","7addf492":"code","da576804":"code","90223a7f":"code","1e1f5d06":"code","530b8033":"code","c60564a5":"code","bc4e4f9d":"code","6bf6cd24":"code","2563275b":"code","fb42a199":"code","d992884c":"code","fb406be4":"code","602f7833":"code","3d8d723c":"code","51d9a701":"code","b904ec1d":"code","88e80391":"code","0ee82017":"code","395b5681":"code","b62e1bac":"code","48a82bc7":"code","d3774018":"code","640e4da7":"code","e65a6e7e":"code","855665ef":"code","30e94a05":"code","0d2ddf20":"code","fcc8351b":"code","9eb04404":"code","394eedef":"code","2bbf6253":"code","44939e0b":"code","865718b7":"code","7dc6461f":"code","53ffd420":"code","bc761a4a":"code","41979df6":"code","a1f34634":"code","59838e7e":"code","0ffeb500":"code","249f90da":"code","349cf583":"code","5e4c66c5":"code","3c0984fd":"code","ee5d9600":"markdown","fb71e367":"markdown","f31c2609":"markdown","ed9f76f1":"markdown","f4a0b46c":"markdown","4aa53c9c":"markdown","7813565f":"markdown","46cfd2f5":"markdown","b5414e3f":"markdown","956f9a1e":"markdown","2b03fa72":"markdown","e3ff9c72":"markdown","74577cda":"markdown","0b9bf937":"markdown","4c55979b":"markdown","be2b89f0":"markdown","3f49eb7a":"markdown","4568c2b8":"markdown","9ce33bac":"markdown","15c0d6be":"markdown","40a8fa7f":"markdown","6f9eddfe":"markdown","0734c8e4":"markdown","44750190":"markdown","7ca61e2e":"markdown","29702d8a":"markdown","0746b0e1":"markdown"},"source":{"ff7b7d7e":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report, confusion_matrix","5966fbfa":"import pandas as pd\n\ndf = pd.read_csv('..\/input\/arabic-natural-audio-dataset\/ANAD_Normalized.csv')\ndf.head()\n","254f5066":"# We haven't null values\ndf.isnull().sum()","168b66cf":"df.columns","42f5445a":"df['Emotion '].unique()","aeac4aa9":"#Unbalanced classes but it is okay\n\ndf[\"Emotion \"].value_counts()","3ce0936e":"sns.countplot(df['Emotion ']);","32250d9f":"# Exploring the Correlation with the target column (Emotion or Type because Type is the numerical column of Emotion)\ndf.corr()['Type'][df.corr()['Type']>= 0.5].sort_values()","f9b25ae3":"cols = df.corr()['Type'][df.corr()['Type']>= 0.5].index\ncols = cols.tolist()+['Type']\ncols","b38d592d":"plt.figure(figsize=(10,6))\nsns.heatmap(df.corr()[cols].loc[cols]);","1ff34518":"df.corr()['Type'][df.corr()['Type']<= -0.5].sort_values()","7addf492":"cols_two= df.corr()['Type'][df.corr()['Type']<= -0.5].index\ncols_two= cols_two.tolist()+['Type']\ncols_two","da576804":"plt.figure(figsize=(10,6))\nsns.heatmap(df.corr()[cols_two].loc[cols_two]);","90223a7f":"df['Type'].unique()","1e1f5d06":"\ndf_happy= df[df['Emotion ']=='happy']\nclass_happy= df_happy['Type'].iloc[0]\n\ndf_angry= df[df['Emotion ']=='angry']\nclass_angry = df_angry['Type'].iloc[0]\n\ndf_surprised = df[df['Emotion ']== \"surprised\"]\nclass_surprised =df_surprised['Type'].iloc[0]","530b8033":"dict_classes= {class_happy: \"happy\" ,class_angry: \"angry\",class_surprised: \"surprised\"}\ndict_classes","c60564a5":"X= df.drop(['name','Type','Emotion '],axis=1).values\ny= df['Type'].values","bc4e4f9d":"model_pca= PCA(n_components= 50)\nmodel_pca.fit(X)","6bf6cd24":"X2= model_pca.transform(X)","2563275b":"print(X.shape, X2.shape)","fb42a199":"#traing sets: X_train, y_train & test_sets: X_test, y_test\nX_train, X_test, y_train, y_test = train_test_split(X2,y, test_size=0.2)","d992884c":"X_train.shape","fb406be4":"X_test.shape","602f7833":"y_train.shape","3d8d723c":"y_test.shape","51d9a701":"X_train.shape","b904ec1d":"y_train_nn = to_categorical(y_train)[:,1:]\ny_test_nn = to_categorical(y_test)[:,1:]","88e80391":"y_train_nn[0:5]","0ee82017":"#Little Verification: perfect!\ny_train[0:5]","395b5681":"y_test_nn[0:5]","b62e1bac":"#Little Verification: perfect!\ny_test[0:5]","48a82bc7":"clf1 = LogisticRegression()\nclf1.fit(X_train, y_train)","d3774018":"y_pred= clf1.predict(X_test)\nprint(classification_report(y_test,y_pred))","640e4da7":"dict_classes","e65a6e7e":"labels=[\"happy\",\"surprised\",\"angry\"]\ncm_one= pd.DataFrame(confusion_matrix(y_test,y_pred), index=labels, columns= labels)\nsns.heatmap(cm_one, annot = True, fmt = 'g');","855665ef":"grid = {'n_estimators': [10, 50, 100, 200,300]}\nclf_two= GridSearchCV(RandomForestClassifier(),grid)\nclf_two.fit(X_train,y_train)","30e94a05":"clf_two.best_params_","0d2ddf20":"y_pred_two= clf_two.predict(X_test)\nprint(classification_report(y_test,y_pred_two))","fcc8351b":"labels=[\"happy\",\"surprised\",\"angry\"]\ncm_two= pd.DataFrame(confusion_matrix(y_test,y_pred_two), index=labels, columns= labels)\nsns.heatmap(cm_two, annot = True, fmt = 'g');","9eb04404":"grid = {'C': [1, 5, 50], 'gamma': [0.05, 0.1, 0.5, 1, 5]}\nclf_three= GridSearchCV(SVC(),grid)\nclf_three.fit(X_train, y_train)","394eedef":"print(clf_three.best_params_)","2bbf6253":"y_pred_three = clf_three.predict(X_test)\nprint(classification_report(y_test,y_pred_three))","44939e0b":"labels=[\"happy\",\"surprised\",\"angry\"]\ncm_three= pd.DataFrame(confusion_matrix(y_test,y_pred_three), index=labels, columns= labels)\nsns.heatmap(cm_three, annot = True, fmt = 'g');","865718b7":"model = Sequential()\nmodel.add(Dense(units=64,activation='relu'))\nmodel.add(Dense(units=32, activation='relu'))\nmodel.add(Dense(units=16, activation='relu'))\nmodel.add(Dense(units=3,activation='softmax'))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])","7dc6461f":"model.fit(x=X_train, \n          y=y_train_nn, \n          epochs=25,\n          batch_size=64,\n          validation_data=(X_test, y_test_nn), verbose=1\n          )","53ffd420":"model_loss = pd.DataFrame(model.history.history)","bc761a4a":"model_loss[['loss','val_loss']].plot();","41979df6":"model_loss[['accuracy','val_accuracy']].plot();","a1f34634":"model_two = Sequential()\nmodel_two.add(Dense(units=64,activation='relu'))\nmodel_two.add(Dense(units=32,activation='relu'))\nmodel_two.add(Dropout(0.2))\nmodel.add(Dense(units=16, activation='relu'))\nmodel_two.add(Dense(units=3,activation='softmax'))\nmodel_two.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])","59838e7e":"model_two.fit(x=X_train, \n          y=y_train_nn, \n          epochs=30,\n          batch_size=64,\n          validation_data=(X_test, y_test_nn), verbose=1\n          )","0ffeb500":"model_two_loss = pd.DataFrame(model.history.history)","249f90da":"model_two_loss[['loss','val_loss']].plot();","349cf583":"model_two_loss[['accuracy','val_accuracy']].plot();","5e4c66c5":"model.evaluate(X_test,y_test_nn)","3c0984fd":"model_two.evaluate(X_test,y_test_nn)","ee5d9600":"# Arabic Audio Emotion Classifier\n\n## Step1: Introduction\n\n### 1- Use case\n\nEmotion expression is an essential part of human interaction. The same text can hold different meanings when expressed with different emotions. Thus understanding the text alone is not enough for getting the meaning of an utterance. Acted and natural corpora have been used to detect emotions from speech. Many speech databases for different languages including English, German, Chinese, Japanese, Russian, Italian, Swedish and Spanish exist for modeling emotion recognition.\n\nArabic does not have an established natural audio emotion detector, so this is still a novel problem yet to be solved.\n\nEmotion detectors for natural audio can be used in other applications like voice assistants, which can use the information derived from them to better serve the user depending on his\/her mood. They can also be used in automated answering systems, which can help automatically determine the satisfaction of a customer calling a support line.\n\n### 2- Justification of the use case choice\n\nI am Tunisian (a country in the Maghreb region of North Africa): Arabic is my mother tongue(with French), I remain fascinated by the Arabic language and wanted to apply my knowledge in Machine Learning, Deep Learning, and Arabic to build an emotion classifier.\n\n    \n### 3- Dataset\nThe data set used in this project was obtained here https:\/\/www.kaggle.com\/suso172\/arabic-natural-audio-dataset (the normalized csv file was used) and consisted of acoustic features, much like other researchers used before. The features center around 25 wave properties and are as follows:\n\n08 videos of live calls between an anchor and a human outside the studio were downloaded from online Arabic talk shows. Each video was then divided into turns: callers and receivers. To label each video, 18 listeners were asked to listen to each video and select whether they perceive a **\"happy\"**, **\"angry\"** or **\"surprised\"** emotion. Silence, laughs and noisy chunks were removed. Every chunk was then automatically divided into 1 sec speech units forming our final corpus composed of **1384** records.\n\n25 **acoustic features**, also known as low-level descriptors, were extracted. These features are: intensity, zero crossing rates, MFCC 1-12 (Mel-frequency cepstral coefficients), F0 (Fundamental frequency) and F0 envelope, probability of voicing and, LSP frequency 0-7. On every feature 19 statistical functions were applied. The functions are: maximum, minimum, range, absolute position of maximum, absolute position of minimum, arithmetic of mean, Linear Regression1, Linear Regression2, Linear RegressionA, Linear RegressionQ, standard Deviation, kurtosis, skewness, quartiles 1, 2, 3 and, inter-quartile ranges 1-2, 2-3, 1-3. The delta coefficient for every LLD is also computed as an estimate of the first derivative hence leading to a total of nearly 900 features.\n\n### 4- Data Quality Assessment\n\nAlthough each of the 8 original audio samples were split into 1 second segments, every segment from the same original audio sample was classified to the **same emotion** by the listeners. I found this a bit odd, considering that it's rare when an individual, let along group of individuals, collectively have the same emotion through a series of spoken lines. After listening to the audio samples myself (**with my knowledge of Arabic**), I found that my suspicions were correct.\n\nAdditionally, the emotions happy, angry, and surprised were quite limited to describe the emotional spectrum of the lines spoken in the audio samples. I found more emotions like neutral among others in many of the spoken lines, yet they were still classified under 1 of the 3 emotions that the makers of the data set came up with.\n\nOverall, I believe that the data could be imporved, but it is great, we do with it!\n\n### 5- Proposed Approach: Models used\n\nGiven the very high success rate we usually get, using neural networks to build classifier, I decided to use Neural Network and oppose this model to traditional Machine Learning Algorithms: Logistic regression, Support Vector Machine and Random Forest classifiers.\n","fb71e367":"##### Creating and Training the model","f31c2609":"#### Exploring the columns ","ed9f76f1":"##### Predictions & Evaluation (on the test set)","f4a0b46c":"# Step6: Classification with Deep Neural Network & Evaluation","4aa53c9c":"##### Predictions & Evaluation (on the test set)","7813565f":"### 2. Machine Learning Model_2: Random Forest with GridSearch","46cfd2f5":"### 6-  Importing the libraries and modules for the project","b5414e3f":"The best accuracy is obtained with the neural networks (see results above)\n\nTraditional machine learning algorithms provide acceptable accuracy on many use cases. But, a lot of times the accuracy we are building might not be satisfactory. Therefore, we are always looking for better ways to improve the performance of our models Deep Learning Neural Networks. There are many techniques available wwith Neural Networks that could help us achieve that (to avoid overfitting using Dropout strategy for example an so on...).In our exemple of audio arabic emotion classifier, we succeeded in achieving high performance and metrics we used prove this high performance (f1 score, precision, recall, accuracy)","956f9a1e":"# Step8: Conclusion","2b03fa72":"# Step2: Data Exploration & Visualizations","e3ff9c72":"#### Exploring Highest correlations between features & Visualization","74577cda":"#### 1. Create the dictionary of correspondent classes","0b9bf937":"#### Trying this strategy: adding Dropout layers","4c55979b":"# Step3: Feature engineering","be2b89f0":"####  Unique values of emotions (classes) & Visualization ","3f49eb7a":"#### 2. Labels Transformation (only for the Neural Network Algorithm) not for Traditional ML Algorithms","4568c2b8":"##### Creating and Training the model","9ce33bac":"### Predictions & Evaluation of Neural Network models (on the test set)","15c0d6be":"#### 2. Applying Principal component Analysis PCA to get the most informative artificial features","40a8fa7f":"##### Creating and Training the model","6f9eddfe":"#### Exploring Null values ","0734c8e4":"##### Predictions & Evaluation (on the test set)","44750190":"### 3. Machine Learning Model_3: Support Vector Machine","7ca61e2e":"### 1. Machine Learning Model_1: Logistic Regression","29702d8a":"# Step5: Classification with Traditional Machine Learning Algorithms & Evaluation","0746b0e1":"# Step4. Splitting the data"}}