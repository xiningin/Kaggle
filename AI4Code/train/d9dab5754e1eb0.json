{"cell_type":{"863232a2":"code","6820c96b":"code","c7c9f37b":"code","8f4277ac":"code","1a577e1a":"code","f12dd1c3":"code","f41b5d53":"code","e03e96ad":"code","6af99230":"code","fd548c33":"code","434dffc8":"code","abf1e759":"code","2293b99d":"code","6edfc9ed":"code","61bddc94":"code","0c80db4b":"code","c33eb608":"code","28d05b74":"code","b0709362":"code","dfdee3f8":"code","ee22dc51":"code","a931beed":"code","59bc4930":"code","1550dd01":"code","c7151c20":"code","10f65129":"code","18632862":"code","e1734220":"code","b2adb735":"code","66c645f4":"code","9e2eacbb":"code","d8f9df31":"code","93d6d176":"code","f400afaf":"markdown","f99f7e15":"markdown","e2c93886":"markdown","58eef745":"markdown","307208e4":"markdown","fa694e77":"markdown","86106776":"markdown","eea75b19":"markdown","af2f3c09":"markdown","23b1d34f":"markdown","7bd5403f":"markdown","d3fae86d":"markdown","b5188459":"markdown","54012001":"markdown","2647daf7":"markdown","6e772f7a":"markdown","ba27ab98":"markdown","cc844026":"markdown","215173e1":"markdown","a6bd78ae":"markdown","aa0d129a":"markdown"},"source":{"863232a2":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\n%matplotlib inline","6820c96b":"warnings.filterwarnings('ignore')\ndata=pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')","c7c9f37b":"#Auxiliary data which helps to show visualisation.\n#Type [question position(offset) in DF,amount of columns cointained in the question in DF]\nk=1\nkk=0\nsss=[]\nfor i in range(1,len(data.columns)):\n    try:\n        if (data.columns[i][:3]==data.columns[i+1][:3]):          \n            k+=1           \n        else:\n            sss.append([kk+1,k])\n            kk+=k\n            k=1\n    except IndexError:\n        sss.append([kk+1,k])\n        kk+=k\n        k=1","8f4277ac":"# This function takes question's number and data as input and generate data for visualisation\ndef vis_func(x,xdata,sort=False):\n    temp_data=xdata.iloc[1:,sss[x-1][0]:sum(sss[x-1])]\n    if sss[x-1][1]!=1: \n        data_count=temp_data.count()\n        col_ar=[]\n        for i in temp_data:\n            col_ar.append(temp_data[i].value_counts().keys()[0])\n        \n        return [col_ar, data_count.values]\n    \n    else:\n        col2_ar=[]\n        for i in temp_data.value_counts(sort=sort).keys():\n            col2_ar.append(i[0])\n        \n        return [col2_ar,temp_data.value_counts(sort=sort)]\n    \n\n#First version    \n\ndef vis_func_1st(x,xdata,sort=False):\n    temp_data=xdata.iloc[1:,sss[x-1][0]:sum(sss[x-1])]\n    \n    if sss[x-1][1]!=1: \n        data_count=temp_data.count()\n        col_ar=[]\n        for i in temp_data:\n            col_ar.append(temp_data[i].value_counts().keys()[0])\n        \n        fig=plt.figure(figsize=(16,8))\n        plt1=fig.add_subplot()\n        plt1.set_xticklabels(col_ar, rotation=45)\n        plt1.bar(col_ar, height=data_count.values,label=xdata.iloc[0,sss[x-1][0]])\n        plt1.legend()\n        \n    else:\n        col2_ar=[]\n        for i in temp_data.value_counts(sort=sort).keys():\n            col2_ar.append(i[0])\n        \n        fig=plt.figure(figsize=(16,8))\n        plt1=fig.add_subplot()\n        plt1.set_xticklabels(col2_ar, rotation=45)\n        plt1.bar(col2_ar, height=temp_data.value_counts(sort=sort),label=xdata.iloc[0,sss[x-1][0]])\n        plt1.legend()","1a577e1a":"fig=plt.figure(figsize=(16,8))\nplt1=fig.add_subplot()\nplt1.set_xticklabels(vis_func(7,data)[0], rotation=45)\n\nplt1.bar(vis_func(7,data)[0], height=vis_func(7,data)[1],label='Using')\nplt1.bar(vis_func(8,data)[0], height=vis_func(8,data)[1],label='Recommended')\nplt1.legend()\nplt.show()","f12dd1c3":"print('% of people using Python and recommended it:', \\\nround((len(data[data['Q7_Part_1']==data['Q8']].index)\/data['Q7_Part_1'].count())*100,2))","f41b5d53":"print('% of people using other languages,but recommending Python',\\\nround(len(data[(data['Q7_Part_1'].isnull()==True)&(data['Q8']=='Python')].index)\\\n\/len(data[(data['Q7_Part_1'].isnull()==True)].index)*100,2))","e03e96ad":"data22=data[(data['Q7_Part_1'].isnull()==False)] #sorted by Python\ndata23=data[(data['Q7_Part_1'].isnull()==True)]  #other data \nfig=plt.figure(figsize=(16,8))\nplt1=fig.add_subplot()\n\nplt1.set_xticklabels(vis_func(1,data)[0], rotation=45)\nplt1.text(3, 3500,'Programming lagnuage users by age',  fontsize=15, fontweight='bold')\nplt1.bar(vis_func(1,data22)[0], height=vis_func(1,data22)[1],label='Python users')\nplt1.bar(vis_func(1,data23)[0], height=vis_func(1,data23)[1],label='Other')\nplt1.legend()\nplt.show()","6af99230":"Columns=data.columns\ncolumns_s=[] # list of answers with only one possible answer\n\nfor i in Columns:\n    if (('Part' not in i) and ('OTHER' not in i)):\n        columns_s.append(i)\n        \ncolumns_s=columns_s[1:] # drop Time from Start to Finish\n#print(columns_s)\ndata_s=data[columns_s] # data with only one possible answer\ndata_m=data.drop(columns_s+['Time from Start to Finish (seconds)'],axis=1) # data with multiple possibility to answer\n#data_s\n#data_m","fd548c33":"data_m_1=data_m.notna().drop(index=0)\ndata_m_1[data_m_1==True]=1 # data where value=1 if option choosen, esle 0.\n#data_m_1","434dffc8":"data_m_1['ZEROS']=0\nd=data_m_1['ZEROS'] # temporary columns with zero value\ncolumns_m_1=data_m_1.columns\ndata_for_corr_m_1=pd.DataFrame() #merged data,which contain amounts of chosen options in question \n\nfor i in range(len(columns_m_1)):\n    try:\n        if (('Part' in columns_m_1[i]) or ('OTHER' in columns_m_1[i])) and (columns_m_1[i][:3]==columns_m_1[i+1][:3]):\n            d+=data_m_1.iloc[:,i]          \n        else:\n            d+=data_m_1.iloc[:,i]\n            data_for_corr_m_1[columns_m_1[i][:5]]=d\n            d=0\n    except IndexError:\n        d+=data_m_1.iloc[:,i]\n        data_for_corr_m_1[columns_m_1[i][:5]]=d\n        d=0\n    \ndata_for_corr_m_1=data_for_corr_m_1.drop('ZEROS',axis=1)","abf1e759":"data_for_corr_m_1.iloc[:,:10].describe()","2293b99d":"data_for_corr_m_1.iloc[:,10:20].describe()","6edfc9ed":"data_for_corr_m_1.iloc[:,20:].describe()","61bddc94":"\nindex2=[]\nfor i in data_for_corr_m_1:\n    index2.append(data_for_corr_m_1[data_for_corr_m_1[i]>=data_for_corr_m_1[i].max()].index)\n\nindex2_t=[]\nindex2_2t=[]\nindex2_n=[]\nfor i in index2:\n    index2_2t.append(len(i))\n    for j in i:\n        index2_n.append(j)\n        if j not in index2_t:\n            index2_t.append(j)\n\nrow_to_del=[] #list of index's number, with a lot of max options per respondent\nfor i in Counter(index2_n):\n    if Counter(index2_n)[i]>5:\n        row_to_del.append(i)\nprint('Number of respondents,which one chose maximum options in more than 5 question')\nprint(len(row_to_del))","0c80db4b":"print('Mean amount of chosen options value in all questions ')\nprint(np.mean(data_for_corr_m_1.mean()))\nprint('Median amount of chosen options value in all questions ')\nprint(np.mean(data_for_corr_m_1.median()))","c33eb608":"columns_m_1_pop=[] # list of popular questions \ndict_pop=(data_for_corr_m_1.describe().loc[['50%']]>0).any()\nfor i in dict_pop.keys():\n    if dict_pop[i]==True:\n        columns_m_1_pop.append(i)\n        \nprint('Mean amount of chosen options value in most popular questions')\nprint(np.mean(data_for_corr_m_1[columns_m_1_pop].mean()))\nprint('Median amount of chosen options value in most popular questions')\nprint(np.mean(data_for_corr_m_1[columns_m_1_pop].median()))","28d05b74":"sns.heatmap(data_for_corr_m_1.corr())\nplt.show()","b0709362":"data_for_corr_m_1_cut=data_for_corr_m_1[columns_m_1_pop]\ndata_for_corr_m_1_cut.columns=(['Programming languages',\"IDE's\",'Notebook host','Hardware','Vizualization Lib',\n                                'ML Frameworks','ML Algorithm','Work activities','Courses','Media'])\ndata_for_corr_m_1_cut.corr()                             ","dfdee3f8":"sns.heatmap(data_for_corr_m_1_cut.corr())\nplt.show()","ee22dc51":"#auxiliary dict for data replacement\ndict_conv={'35-39':37.0, '30-34': 32.0, '22-24': 23.0, '25-29':27.0, '18-21':19.0,\n '55-59':57.0, '50-54':52.0, '40-44':42.0, '60-69':65.0, '45-49':47.0, '70+':70.0,'Doctoral degree':5.0,\n 'Master\u2019s degree':4.0, 'Bachelor\u2019s degree':3.0, 'No formal education past high school':1.0,\n 'Some college\/university study without earning a bachelor\u2019s degree':2.0,\n 'Professional degree':6.0, 'I prefer not to answer':0.0,'5-10 years':8.0,'10-20 years':15.0, '3-5 years':4.0,'< 1 years':0.5,\n '1-2 years':1.5, '20+ years':20.0, 'I have never written code':0.0, 'I do not use machine learning methods':0.0,\n '3-4 years':3.5, 'Under 1 year':0.5, '2-3 years':2.5, '4-5 years':4.5, '20 or more years':20.0, '100,000-124,999':112500.0, \n '15,000-19,999':17500.0, '125,000-149,999':137500.0, '70,000-79,999':75000.0, '30,000-39,999':35000.0, '90,000-99,999':95000.0,\n '1,000-1,999':1500.0, '$0-999':500.0, '10,000-14,999':12500.0, '150,000-199,999':175000.0, '60,000-69,999':65000.0, \n '4,000-4,999':4500.0, '> $500,000':500000.0, '300,000-500,000':400000.0, '40,000-49,999':45000.0, '25,000-29,999':27500.0, \n '80,000-89,999':85000.0, '7,500-9,999':8750.0, '50,000-59,999':55000.0, '250,000-299,999':275000.0, '5,000-7,499':6250.0, \n '2,000-2,999':2500.0, '20,000-24,999':22500.0, '200,000-249,999':225000.0, '3,000-3,999':3500.0, 'Man':2.0, 'Woman':1.0,\n 'Prefer to self-describe':0.0, 'Prefer not to say':0.0, 'Nonbinary':0.0}","a931beed":"#replacing data\nColumns_s_tr=['Q1','Q4','Q6','Q15','Q24','Q2']\ndata_s_c=data[Columns_s_tr].fillna(0)\n\nfor i in dict_conv:\n    data_s_c[data_s_c==i]=dict_conv[i]\n\ndata_s_c.columns=['Age','Education','Programming Exp','ML exp','Compensation','Gender']\ndata_s_c_2= data_s_c.drop(np.where((data_s_c['Compensation']==0)|(data_s_c['Compensation']==500))[0])\n\n#data_s_c_2","59bc4930":"data_s_c.iloc[1:].astype(float).corr()","1550dd01":"sns.heatmap(data_s_c.iloc[1:].astype(float).corr())\nplt.show()","c7151c20":"data_merg=data_s_c.merge(data_for_corr_m_1_cut,how='outer',left_index=True,right_index=True)\nsns.heatmap(data_merg.iloc[1:].astype(float).corr())\nplt.show()","10f65129":"data_t_1=data.iloc[1:].drop(np.where(data['Q24']=='$0-999')[0]).sort_values(by=['Q24'])\ndata_t_1_1=pd.crosstab(data_t_1['Q1'],data_t_1['Q24'])\nplt.figure(figsize=(16,8))\nax=sns.heatmap(data_t_1_1,linewidth=0.01)\nax.set(xlabel='Compensation', ylabel='Age')\nax.text(7, -0.5,'Compensation by age without $0-900',  fontsize=15, fontweight='bold')\nplt.show()","18632862":"data_t_2=pd.crosstab(data['Q2'].iloc[1:],data['Q6'].iloc[1:])\nplt.figure(figsize=(16,8))\nax=sns.heatmap(data_t_2,linewidth=0.01)\nax.set(xlabel='Programming Exp', ylabel='Gender')\nax.text(2,-0.5,'Gender by Programming expirience',  fontsize=15, fontweight='bold')\nplt.show()","e1734220":"data_t_3=pd.crosstab(data['Q2'].iloc[1:],data['Q1'].iloc[1:])\nplt.figure(figsize=(16,8))\nax=sns.heatmap(data_t_3,linewidth=0.01)\nax.set(xlabel='Age', ylabel='Gender')\nax.text(4,-0.5,'Gender by Age',  fontsize=15, fontweight='bold')\nplt.show()","b2adb735":"data_t_4=data.iloc[1:].drop(np.where(data['Q24']=='$0-999')[0])\ndata_t_4_1=pd.crosstab(data_t_4['Q2'],data_t_4['Q24'])\nplt.figure(figsize=(16,8))\nax=sns.heatmap(data_t_4_1,linewidth=0.01)\nax.set(xlabel='Compensation', ylabel='Gender')\nax.text(6,-.5,'Compensation without $0-900 by gender',  fontsize=15, fontweight='bold')\nplt.show()","66c645f4":"data_t_4=data[data['Q24']=='> $500,000'].iloc[1:]\ndata_t_4_1=pd.crosstab(data_t_4['Q2'],data_t_4['Q24'])\nplt.figure(figsize=(12,8))\nax=sns.heatmap(data_t_4_1)\nax.set(xlabel='Compensation', ylabel='Gender')\nax.text(0,-.5,'Compensation > $500,000 by gender',  fontsize=15, fontweight='bold')\nplt.show()","9e2eacbb":"vis_func_1st(2,data)","d8f9df31":"fig=plt.figure(figsize=(16,8))\nplt1=fig.add_subplot()\nplt1.set_xticklabels(vis_func(3,data,1)[0], rotation=45)\n\nplt1.bar(vis_func(3,data,1)[0][:20], height=vis_func(3,data,1)[1][:20],label=\"Respondent's countries, Top 20\")\nplt1.legend()\nplt.show()","93d6d176":"for i in range(1,len(sss)+1):\n    if i in [1,2,3,7,8]:\n        continue\n    else:\n        vis_func_1st(i,data)","f400afaf":"<b>Intro<\/b>\n\nBefore starting analizing and plotting, I've decided to make some functions and other auxiliary things<br>\nto make easier this process. To make shorter code.<br>\nThe first version of function was fuction which needed only question's number.<br>\n<b>Give question's number to func and it made for you bar plot<br><\/b>\nBut later, I've changed my mind,and made func which returned data for bar plot and have more input params,<br>\nit makes more variations of usage.<br>\nI though about making this func more complicated,variable but had not time because of personal issue.<br>\nSorry for that and lack of beauty.<br>\nJust take a look! :)","f99f7e15":"We can see,that more wealthiest group is in range 30-50 y.o.","e2c93886":"As we saw, we had no correlation between gender and compensation.<br>\nAnd here we can see it too. We have womans in the same categories of compensation,<br>\nas mans.But no a lot of them. If we look to 2nd plot, we will see about 10 womans and 40 mans,<br>\nwith compensation >500.000$. If we scale it by 3rd plot(respondents gender distribution),<br>\nwe will see,that's same value of percent.<br>\nIt's explained by respondent's gender distribution.","58eef745":"Just short describe of merged data,which contain amounts of chosen options in question below.","307208e4":"At the beginning,I decided to look at the distribution of programming languages and the distribution of recommended languages.<br>\nWe can see,that Python is most popular language and most recommended.\nPercent of recommended to using other languages by users,which using it, quite low.","fa694e77":"After it,I decided to split data for data where we can chose only one option and data with many options at once.<br>\nThe reason of this decision was, that I wanted to see, how many options people choose. What's mean and median value. How often people chose a maximum of option's possible number.<br>\nIs there any correlation in how many options respondents chose from question to question?<br>","86106776":"As we can see, we have non-popular question, which more than half respondents skip<br>\nAlso we have maximum of option's number chosen in each question.<br>\nBelow, I've checked it and saw, that not a lot of anomaly rows.<br>\nSo, I've decided to dont del it from frame.<\/br>","eea75b19":"Now we can take a look closer to this part<br>\nWe have good correlation between amount of chosen programming languages and IDE's, that's clear.<br>\nSo, respondents, who use a lot of visualization libraries, also use a lot of<br>\nML Frame works and many different ML algorithms, and vice versa. That's also clear :)<br>\nAlso interesting thing,that people,who using a lot of online education platforms, also<br>\nare active consumers of online sources,that report on data science topics.And vice versa.<br>","af2f3c09":"Let's look to languages distribution scaled by respondent's age.<br>\nAs we can see on the plot, in respondet's age groups older 35y.o. percent python's usage fluctuate between 35-50,<br>\nwhereas in respondents younger age, python's usage fluctuate between 75-80 percent.<br>\nSo, Python going more and more popular.\n","23b1d34f":"So. What we can see?\nWe see,that <b>Age<\/b> has strong correlation with <b>Programming expirience<\/b>.<br>\nGood correlation with <b>Compensation and ML expirience<\/b>, and not bad<br>\nwith <b>Education<\/b>.<br>\nAlso we can see,that here <b>NO correlation<\/b> between <b>gender<\/b> and all other data.<br>\n<b>Compensation<\/b> has good correlation with <b>programming and ML expirience<\/b>.<br>\nWe have dependancy between <b>ML expirience and Programming expirience.<\/b>","7bd5403f":"Further,we will look to more plots! :)","d3fae86d":"One things, which I interested, after I saw this python's domination,was ,<b> how many people recommend an aspiring data scientist Python, dependence of<\/b> are they using Python or if they aren't using Python.","b5188459":"Interesting thing,that almost no woman with programming expirience more,than 10 years.<br>\nAnd almost no woman older 50 y.o.","54012001":"Sorry,if it's not so interesting, but i had have interest to confirm some things by data.<br>\nBy the next step, we will check of what compensation depend or not depend.","2647daf7":"<b>Short list of content.<\/b>\n1. Look on data.\n    1. Data with multiple possibility to answer at once.\n        1. Describe data. Look at data,transform it.\n        2. Trying to find correlations. Visualization.\n    2. Data with only one possible answer.\n        1. Transform. Correlate. Gender conspiracy theory xD.\n        2. Visualization.\n2. A little bit more visualization.","6e772f7a":"Top 20 countries","ba27ab98":"Further, I've decided to find more dependencies. And add more data for it.<br>\nAnd found good correlation between <b>Compensation<\/b> and <br>\nhow many activities that make up an important part of your role at work,<br>\nrespondents are chose.<br>\nAlso we have good dependency between <b>ML expirience<\/b> and how many options was<br>\nchosen in question about <b>ML Frameworks,Algorithm and Vizualisation lib<\/b><br>","cc844026":"As we see, not all Python's users recommending Python,those people about 1\/6.<br>\nBut more that 1\/4 of people using other languages recommending Python.<br>","215173e1":"<b>Let's do just quick look through all data.","a6bd78ae":"In this part, I've try to check dependencies between respondent's age,Education,<br>\nprogramming and ML expirience,compensation and gender.<br>\nFor this I've created dictionary. Keys are values of original data, and new values:<br>\nFor all exept education and gender it is mean of category value.<br>\nEducation its categorial data, but it can be scaled. All known,that <br>\nhigh school degree<<Doctoral degree and etc.<br>\nAnd I've replace in gender data man->2,woman->1.<br>\n<b>Note! I'm don't think,that womans<man and etc. its just for corr!<\/b><br>\nIt was deliberate. I've try to check out next thing, is there any dependencies,<br>\nbetween gender and salary(compensation). If yes and mans earn more money,<br>\nthen we will have good positive correlation(for example. 2(man)>1(woman)<br>\n100k dollars > 70k dollars),else we'll have negative or no correlation.\n","aa0d129a":"So. As we can see, we haven't correlation between questions block 'A' and block 'B' it's ok,<br>\nbecause of survey methodic.<br>\nBut we have strong correlation inside this blocks, it's could mean, that people chose a proportional<br>\nnumber of answers options inside questions block. They generally chose a lot or not so.<br>\nAlso we can see, that we have more correlation between questions,which close to each other.<br>\nRespondents more often chose the same percent of options amount in neighbor questions.<br>\nAnd we have not bad correlations in first part of questions. Let's look on it too.<br>\nFor this we should remove Block A,B and 'non popular' questions."}}