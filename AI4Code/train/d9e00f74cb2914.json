{"cell_type":{"431777dd":"code","22b6c932":"code","77afd289":"code","7b2cd99c":"code","7661c326":"code","2238a196":"code","c4b4aba7":"code","4afac036":"code","16236756":"code","99dec340":"code","9c8e9c07":"code","6785f83a":"code","0ef5d7fa":"code","d8216d2a":"code","1b992b11":"code","75fd8054":"code","ae996f54":"code","ce026131":"code","2a24c29e":"code","84421f3a":"code","86d07d6e":"code","07be6898":"code","022fc096":"code","7dccfdc1":"code","8655acf5":"code","652786d5":"code","3f68d67a":"code","f917d06e":"code","aa1c88f0":"markdown","0ed419f3":"markdown","22d29bed":"markdown","93a4af3c":"markdown","101246af":"markdown","3d93ccb3":"markdown","40389176":"markdown","636409eb":"markdown","62163e36":"markdown","a9e9b05f":"markdown"},"source":{"431777dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","22b6c932":"dataset = pd.read_csv('..\/input\/train.csv')\ntestset = pd.read_csv('..\/input\/test.csv')","77afd289":"dataset.columns","7b2cd99c":"dataset_title = [i.split(',')[1].split('.')[0].strip() for i in dataset['Name']]\ndataset['Title'] = pd.Series(dataset_title)\ndataset['Title'].value_counts()\ndataset['Title'] = dataset['Title'].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Ms', 'Mme', 'Mlle'], 'Others')","7661c326":"dataset_title = [i.split(',')[1].split('.')[0].strip() for i in testset['Name']]\ntestset['Title'] = pd.Series(dataset_title)\ntestset['Title'].value_counts()\ntestset['Title'] = testset['Title'].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Ms', 'Mme', 'Mlle'], 'Others')","2238a196":"dataset['FN'] = dataset['SibSp'] + dataset['Parch'] + 1\ntestset['FN'] = testset['SibSp'] + testset['Parch'] + 1","c4b4aba7":"def family(x):\n    if x < 2:\n        return 'S'\n    elif x == 2:\n        return 'C'\n    elif x <= 4:\n        return 'M'\n    else:\n        return 'L'\n    \ndataset['FN'] = dataset['FN'].apply(family)\ntestset['FN'] = testset['FN'].apply(family)","4afac036":"dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\ntestset['Embarked'].fillna(testset['Embarked'].mode()[0], inplace=True)\ndataset['Age'].fillna(dataset['Age'].median(), inplace=True)\ntestset['Age'].fillna(testset['Age'].median(), inplace=True)\ntestset['Fare'].fillna(testset['Fare'].median(), inplace=True)","16236756":"dataset = dataset.drop(['PassengerId', 'Cabin', 'Name', 'SibSp', 'Parch', 'Ticket'], axis=1)\ntestset_passengers = testset['PassengerId']\ntestset = testset.drop(['PassengerId', 'Cabin', 'Name', 'SibSp', 'Parch', 'Ticket'], axis=1)","99dec340":"dataset.iloc[:10]","9c8e9c07":"X_train = dataset.iloc[:, 1:9].values\nY_train = dataset.iloc[:, 0].values\nX_test = testset.values","6785f83a":"#print(Y_train.shape)\nprint(X_train.shape)","0ef5d7fa":"# Converting the remaining labels to numbers\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder_X_1 = LabelEncoder()\nX_train[:, 1] = labelencoder_X_1.fit_transform(X_train[:, 1])\nX_train[:, 4] = labelencoder_X_1.fit_transform(X_train[:, 4])\nX_train[:, 5] = labelencoder_X_1.fit_transform(X_train[:, 5])\nX_train[:, 6] = labelencoder_X_1.fit_transform(X_train[:, 6])","d8216d2a":"labelencoder_X_2 = LabelEncoder()\nX_test[:, 1] = labelencoder_X_2.fit_transform(X_test[:, 1])\nX_test[:, 4] = labelencoder_X_2.fit_transform(X_test[:, 4])\nX_test[:, 5] = labelencoder_X_2.fit_transform(X_test[:, 5])\nX_test[:, 6] = labelencoder_X_2.fit_transform(X_test[:, 6])","1b992b11":"print(X_test.shape)\nprint(X_train.shape)","75fd8054":"X_test[:10, 3]","ae996f54":"# Converting categorical values to one-hot representation\n#0, 1, 4, 5, 6\none_hot_encoder = OneHotEncoder(categorical_features = [0, 1, 4, 5, 6])\nX_train = one_hot_encoder.fit_transform(X_train).toarray()\nX_test = one_hot_encoder.fit_transform(X_test).toarray()\n\nprint(X_test.shape)\nprint(X_train.shape)","ce026131":"print(X_test.shape)\nprint(X_train.shape)","2a24c29e":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.1)","84421f3a":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(19, 128)\n        self.fc2 = nn.Linear(128, 256)\n        self.fc3 = nn.Linear(256, 2)\n        \n    def forward(self, x):\n        x = x.view(x.shape[0], -1)\n        \n        x = self.fc1(x)\n        x = F.dropout(x, p=0.4)\n        x = F.leaky_relu(x)\n        \n        x = self.fc2(x)\n        x = F.dropout(x, p=0.4)\n        x = F.leaky_relu(x)\n        \n        x = self.fc3(x)\n        x = F.softmax(x, dim=1)\n        \n        return x\n    \nnet = Net()","86d07d6e":"batch_size = 50\nnum_epochs = 181\nlearning_rate = 0.001\nbatch_no = len(x_train) \/\/ batch_size","07be6898":"criterion = nn.NLLLoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)","022fc096":"from sklearn.utils import shuffle\nfrom torch.autograd import Variable\n\nmin_loss = np.Inf\n\nfor epoch in range(num_epochs):\n    x_train, y_train = shuffle(x_train, y_train)\n    \n    train_loss = 0\n    valid_loss = 0\n    \n    for i in range(batch_no):\n        x_var = Variable(torch.FloatTensor(x_train))\n        y_var = Variable(torch.LongTensor(y_train))\n        # Forward + Backward + Optimize\n        optimizer.zero_grad()\n        ypred_var = net(x_var)\n        loss =criterion(ypred_var, y_var)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    \n    if epoch % 20 == 0:\n        test_var = Variable(torch.FloatTensor(x_val), requires_grad=True)\n        test_y_var = Variable(torch.LongTensor(y_val))\n        with torch.no_grad():\n            result = net(test_var)\n            #loss\n            loss = criterion(result, test_y_var)\n            #calculate loss\n            valid_loss += loss.item()\n            \n            values, labels = torch.max(result, 1)\n            num_right = np.sum(labels.data.numpy() == y_val)\n            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n                epoch+1, train_loss,valid_loss),\n                'Accuracy {:.2f}%'.format((num_right \/ len(y_val))* 100),)\n            \n        # save model if validation loss has decreased\n        if valid_loss <= min_loss:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n                min_loss,\n                valid_loss))\n            torch.save(net.state_dict(), 'model.pt')\n            min_loss = valid_loss","7dccfdc1":"net.load_state_dict(torch.load('model.pt'))","8655acf5":"# Evaluate the model\ntest_var = Variable(torch.FloatTensor(x_val), requires_grad=True)\nwith torch.no_grad():\n    result = net(test_var)\n    values, labels = torch.max(result, 1)\n    num_right = np.sum(labels.data.numpy() == y_val)\n    print('Accuracy {:.2f}'.format(num_right \/ len(y_val)))","652786d5":"X_test_var = Variable(torch.FloatTensor(X_test), requires_grad=True)\nprint(X_test_var.shape)\nwith torch.no_grad():\n    test_result = net(X_test_var)\nvalues, labels = torch.max(test_result, 1)\nsurvived = labels.data.numpy()","3f68d67a":"len(testset_passengers)\nlen(survived)","f917d06e":"import csv\n\ndata = [['PassengerId', 'Survived']]\nfor i in range(len(survived)):\n    data.append([testset_passengers[i], survived[i]])\n    \nwith open('submission.csv', 'w') as file:\n    writer = csv.writer(file)\n    writer.writerows(data)\n    \nprint(\"Complete\")","aa1c88f0":"# Find Survied","0ed419f3":"# Drop Columns","22d29bed":"# Chnage Name into 3 categories","93a4af3c":"# Test","101246af":"## Define Model","3d93ccb3":"# Load Data","40389176":"## Encode string to number","636409eb":"# Fill NUll Value","62163e36":"# Count Family Size","a9e9b05f":"# Train"}}