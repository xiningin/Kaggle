{"cell_type":{"bd0b98e0":"code","a4fc1c72":"code","609afc79":"code","b7ccad7e":"code","7310644a":"code","eb0def96":"code","0e82fe1b":"code","4060fcbc":"code","9fe9abdf":"code","e4d4bf15":"code","436c9232":"code","55c90ea6":"code","3192e34c":"code","d16da825":"code","52ef1f57":"code","9cd6f35f":"code","57078073":"code","cc19adb6":"code","b3304361":"code","ab07e714":"code","9b0cc201":"code","bbf27ae5":"code","e9f75e23":"code","5dc35696":"code","c07369db":"code","cdef1a3d":"code","f92cecef":"code","b742a4a8":"code","99dcc6ff":"code","0f8f339b":"code","64687485":"code","3a9b5614":"code","657fa667":"code","db2cc14e":"code","d12cc4d9":"code","5c10a6c7":"code","5fe75f7f":"code","74373d14":"code","7bfdaa17":"code","007762ba":"code","4de603f7":"code","ccd6b0e3":"code","81d533c8":"code","eb46c901":"code","cf99187a":"code","8585b047":"code","980db21c":"code","f254d683":"code","79b794c8":"code","708ca84a":"code","16c4a8e9":"code","0d0e8b41":"code","ac51585e":"code","8e6d1e0c":"code","5d28b66c":"code","54cca6a7":"code","0eca9492":"code","5d2a94e6":"code","72f19b2e":"code","554e8b96":"code","b7b54195":"code","0b413ee0":"code","82005cfb":"code","3e124e35":"code","ad78b275":"code","e1267c98":"markdown","77fbb298":"markdown","47112b31":"markdown","e5749cf2":"markdown","8e2d0328":"markdown","27f0d498":"markdown","aa39815a":"markdown","69cc4608":"markdown","f4658406":"markdown","9acf4757":"markdown","f444777a":"markdown","4f4b11af":"markdown","b5ee0ac3":"markdown","f6652c85":"markdown","bdefdbc9":"markdown","6dc631f7":"markdown","ff5593ce":"markdown","bb584593":"markdown","e94d6919":"markdown","51922235":"markdown","19a6e311":"markdown","e192b0df":"markdown","21b1c7ee":"markdown","e29d6c84":"markdown","e65e491f":"markdown","76dfd740":"markdown","2656dddd":"markdown","1a8224b9":"markdown","b2092ece":"markdown","e183f749":"markdown","5fd36ee1":"markdown","441821c9":"markdown","880f5308":"markdown","2f304131":"markdown","07812e5d":"markdown","3cb56bbf":"markdown","78b7f5aa":"markdown","46caca90":"markdown","5becfffd":"markdown","b7376ee3":"markdown","85d7bd4f":"markdown","3ebab619":"markdown","2df152ef":"markdown","89b52c50":"markdown","415ad79a":"markdown","89004bcd":"markdown","521d6302":"markdown","f4d43d7e":"markdown","a1139754":"markdown","a398b5aa":"markdown"},"source":{"bd0b98e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a4fc1c72":"df=pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\",skiprows=1,low_memory=False)\n","609afc79":"import seaborn as sns\ndef plot_bar(col, title, palette):\n    \n    plt.figure(figsize=(10,10))\n    plt.xticks(fontsize=16)\n    sns.countplot(y=col,data=df.iloc[1:],order=df.iloc[1:][col].value_counts().index,palette=palette,linewidth=3,)\n    plt.title(title)\n    plt.show()","b7ccad7e":"df.head()","7310644a":"\ndf_country_count = pd.DataFrame({'Country':df[df.columns[3]].value_counts().index, \n                             'Count':df[df.columns[3]].value_counts().values})\n\n\ndata = [ dict(\n        type = 'choropleth',\n        locations = df_country_count['Country'],\n        locationmode = 'country names',\n        z = df_country_count['Count'],\n        colorscale=\n            [[0.0, \"rgb(251, 237, 235)\"],\n            [0.09, \"rgb(245, 211, 206)\"],\n            [0.12, \"rgb(239, 179, 171)\"],\n            [0.15, \"rgb(236, 148, 136)\"],\n            [0.22, \"rgb(239, 117, 100)\"],\n            [0.35, \"rgb(235, 90, 70)\"],\n            [0.45, \"rgb(207, 81, 61)\"],\n            [0.65, \"rgb(176, 70, 50)\"],\n            [0.85, \"rgb(147, 59, 39)\"],\n            [1.00, \"rgb(110, 47, 26)\"]],\n        autocolorscale = False,\n        reversescale = False,\n        marker = dict(\n            line = dict (\n                color = 'rgb(180,180,180)',\n                width = 0.5\n            ) \n        ),\n        colorbar = dict(\n            autotick = False,\n            tickprefix = '',\n            title = 'Participant'),\n      ) ]\n\nlayout = dict(\n    title = \"Country Distribution of All Respondents\",\n    geo = dict(\n        showframe = False,\n        showcoastlines = True,\n        projection = dict(type = 'Mercator'),\n        width=500,height=400)\n)\n\nw_map = dict( data=data, layout=layout)\niplot( w_map, validate=False)\n","eb0def96":"country = \"India\"\nif country not in df[df.columns[3]].unique():\n  raise ValueError(f\"{country} not found\")\ndf[\"country\"]=np.where(df[df.columns[3]]==country,country,'Others')","0e82fe1b":"\nfig=px.pie(df,df.columns[3],title=f\"{len(df[df[df.columns[3]]==country])*100\/len(df):.2f}% of all survey respondents are from {country}\", hole=0.3)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","4060fcbc":"\nfig=px.pie(df,df.columns[1],title=\"56% of all survey respondents are less than 30 yrs old\", hole=0.6)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\nage_pct = len(df[(df[df.columns[3]]==country) & (df[df.columns[1]].isin(['18-21','22-24','25-29']))])*100\/len(df[df[df.columns[3]]==country])\nif age_pct < 56:\n    title = f\"{country} is older, with {age_pct:.0f}% of Kagglers being under under 30\"\nelif age_pct > 56:\n    title = f\"{country} is younger, with {age_pct:.0f}% of Kagglers being under under 30\"\nelse:\n    title = f\"{age_pct:.0f}% of Kagglers from {country} are also under 30\"\nfig = px.pie(df[df[df.columns[3]]==country], df.columns[1], title=title, hole=0.6)\nfig.update_traces(textinfo='percent+label')\n\nfig.show()\ndf['age1'] = df.iloc[:,1].str.split('-').str[0]\ndf['age1'].replace('70+','70', inplace=True)\ndf['age2'] = df.iloc[:,1].str.split('-').str[1]\ndf['age1'] = df.age1.astype('int')\ndf.age2.fillna(70, inplace=True)\ndf['age2'] = df.age2.astype('int')\ndf['age'] = (df.age1+df.age2)\/2\nglobal_median = df.age.mean()\ncountry_median = df[df.country==country].age.mean()\n\nif country_median <= global_median:\n    title = f\"With an average age of {country_median:.0f},<br>Kagglers from {country} are generally {global_median - country_median:.0f} years younger than the average Kaggler\"\nelse:\n    title = f\"With an average age of {country_median:.0f},<br>Kagglers from {country} are generally {country_median - global_median:.0f} years younger than the average Kaggler\"\n\nloc = df.groupby(df.columns[3]).age.mean().sort_values(ascending=False).index.to_list().index(country)\ncolor = ['#636EFA']*len(df.groupby(df.columns[3]).age.mean().sort_values(ascending=False).index)\ncolor[loc] = 'orange'\n\nfig = go.Figure(data=[go.Bar(x=df.groupby(df.columns[3]).age.mean().sort_values(ascending=False).index\n       , y=df.groupby(df.columns[3]).age.mean().sort_values(ascending=False)\n            , marker_color=color)])\nfig.update_layout(\n    shapes=[\n    dict(\n      type= 'line',\n      yref= 'y', y0= global_median, y1= global_median,\n      xref= 'x', x0= -0.5, x1= len(df.groupby(df.columns[3]).age)-0.5\n    )],\n    title=title,\n    xaxis_title=None,\n    yaxis_title='Age')\n\nfig.add_annotation(x=len(df.groupby(df.columns[3]).age)*0.95, y=global_median, xshift=-20, yshift=10,\n            text=\"Global Average\",\n            showarrow=False)\nfig.show()\nfig = go.Figure(data=[\n    go.Bar(name=country, y=df[df.country==country][df.columns[1]].value_counts(normalize=True).sort_index()*100),\n    go.Bar(name='Others', y=df[df.country=='Others'][df.columns[1]].value_counts(normalize=True).sort_index()*100)\n])\n\n# Change the bar mode\nfig.update_layout(\n    barmode='group',\n    title=f'Age distribution of Kagglers from {country} compared to others',\n    xaxis_title='Age',\n    yaxis_title='Percentage of respondents',\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = [x for x in range(12)],\n        ticktext = df[df.columns[1]].sort_values().unique()\n    )\n)\n\nfig.show()\n","9fe9abdf":"gender=\"Man\"\nfig=px.pie(df,df.columns[2],title=\"79.3% kagglers are men\", hole=0.6)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\ngnd_pct=len(df[(df[df.columns[3]]==country) & (df[df.columns[2]].isin(['Man']))])*100\/len(df[df[df.columns[3]]==country])\ndf_all = df.groupby(df.columns[3])[df.columns[2]].value_counts().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum()))[:,gender].sort_values(ascending=False)\nif country in df_all.index:\n    country_avg = df_all[country]\n    global_avg = len(df[df[df.columns[2]]==gender])*100\/len(df)\n\n    if country_avg > global_avg:\n        title=f\"In {country}, this percentage increases to {country_avg:.2f}%\"\n    else:\n        title=f\"In {country}, this percentage decreases to {country_avg:.2f}%\"\n\n    loc = df_all.index.to_list().index(country)\n    color = ['#123AAA']*len(df_all.index)\n    color[loc] = 'yellow'\n\n    fig = go.Figure(data=[go.Bar(x=df_all.index, y=df_all.values, marker_color=color)])\n    fig.update_layout(\n        shapes=[\n            dict(\n              type= 'line',\n              yref= 'y', y0= global_avg, y1= global_avg,\n              xref= 'x', x0= -0.5, x1= len(df_all.index)-0.5\n            )],\n        title=title,\n        xaxis_title=\"Country\",\n        yaxis_title='Percentage')\n    fig.add_annotation(x=len(df_all.index)*0.95, y=global_avg, xshift=-20, yshift=10,\n                text=\"Global Average\",\n                showarrow=False)\n    fig.show()\n    fig = go.Figure(data=[\n    go.Bar(name=country, y=df[df.country==country][df.columns[2]].value_counts(normalize=True).sort_index()*100),\n    go.Bar(name='Others', y=df[df.country=='Others'][df.columns[2]].value_counts(normalize=True).sort_index()*100)\n])\n\n# Change the bar mode\nfig.update_layout(\n    barmode='group',\n    title=f'Gender distribution of Kagglers from {country} compared to others',\n    xaxis_title='Gender',\n    yaxis_title='Percentage of respondents',\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = [x for x in range(12)],\n        ticktext = df[df.columns[2]].sort_values().unique()\n    )\n)\n\nfig.show()\n","e4d4bf15":"degree=\"Master\u2019s degree\"\ndf_academia=df[(df[df.columns[4]]!=\"I prefer not to answer\") & (~df[df.columns[4]].isna())]\nfig=px.pie(df_academia,df_academia.columns[4],title=\"Most of the kagglers are Holders of either Master's Degree or Bachelor's degree\", hole=0.6)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\nmost_common_degree=df_academia[df_academia.iloc[:,3]==country].iloc[:,4].value_counts(normalize=True)[[0]]\nif most_common_degree.index[0] == \"Master's degree\":\n    title = f\"The same trend is observed in {country},<br>with {most_common_degree[0]*100:.0f}% respondents reporting having a Master's degree\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported having a {most_common_degree.index[0]} at {most_common_degree[0]*100:.0f}%\"\n    \nfig=px.pie(df_academia[df_academia.iloc[:,3]==country],df_academia.columns[4],title=title, hole=0.6)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\ndf_academia = df.groupby(df.columns[3])[df.columns[4]].value_counts().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum()))[:,degree].sort_values(ascending=False)","436c9232":"df_job=df[(~df[df.columns[5]].isna())]\nfig=px.pie(df_job,df_job.columns[5],title=\"26.2 % kagglers are student\", hole=0.6)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\nmost_common_job=df_job[df_job.iloc[:,3]==country].iloc[:,5].value_counts(normalize=True)[[0]]\nif most_common_job.index[0] == \"Student\":\n    title = f\"The same trend is observed in {country},<br>with {most_common_job[0]*100:.2f}% respondents reporting are students\"\nelse:\n    title = f\"However, in the case of {country},<br>more respondents reported are {most_common_job.index[0]} at {most_common_job[0]*100:.2f}%\"\n    \nfig=px.pie(df_job[df_job.iloc[:,3]==country],df_job.columns[5],title=title, hole=0.6)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\ndf_job = df.groupby(df.columns[3])[df.columns[4]].value_counts().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum()))[:,degree].sort_values(ascending=False)\n","55c90ea6":"df_exp=df[(~df[df.columns[6]].isna())]\nfig=px.pie(df,df.columns[6],title=\"Most of the kagglers are freshers who has an experience of below 3 years\", hole=0.6)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\nmost_common_exp=df_exp[df_exp.iloc[:,3]==country].iloc[:,6].value_counts(normalize=True)[[0]]\nif most_common_exp.index[0] == \"1-3 years\":\n    title = f\"The same trend is observed in {country},<br>with {most_common_exp[0]*100:.2f}% respondents reporting are freshers\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_exp.index[0]} experienced employees at {most_common_job[0]*100:.2f}%\"\n    \nfig=px.pie(df_exp[df_exp.iloc[:,3]==country],df_exp.columns[6],title=title, hole=0.6)\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\nplot_bar(df.columns[6], title=\"Years of experitse in writing code of kagglers\", palette=\"Reds\")\n","3192e34c":"programming_col= [col for col in df.columns if \"What programming languages do you use on a regular basis?\" in col]\ndf_pro=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in programming_col]\nmapping_dict=dict(zip(programming_col,mapping))\ndf_pro=df_pro[programming_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_pro.drop(columns=[\"None\"],inplace=True)\n","d16da825":"fig = px.bar(df_pro[df_pro.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=f'87% of all respondents use Python on a regular basis',\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nmost_common_lang=df_pro[df_pro.iloc[:,-1]==country][df_pro.columns[:-2]].count().sort_values(ascending=False)\nif most_common_lang.index[0] == \"Python\":\n    title = f\"The same trend is observed in {country},<br>with {most_common_lang[0]} respondents reporting are {most_common_lang.index[0]} users\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are \"\n\nfig = px.bar(df_pro[df_pro.iloc[:,-1]==country][df_pro.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","52ef1f57":"ide_col= [col for col in df.columns if \"Which of the following integrated development environments (IDE's) do you use on a regular basis?\" in col]\ndf_ide=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in ide_col]\nmapping_dict=dict(zip(ide_col,mapping))\ndf_ide=df_ide[ide_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_ide.drop(columns=[\"None\"],inplace=True)\ndf_ide.head()","9cd6f35f":"fig = px.bar(df_ide[df_ide.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nmost_common_ide=df_ide[df_ide.iloc[:,-1]==country][df_ide.columns[:-2]].count().sort_values(ascending=False)\nif most_common_ide.index[0] == \"Jupyter Notebook\":\n    title = f\"The same trend is observed in {country},<br>with {most_common_ide[0]} respondents reporting are {most_common_ide.index[0]} users\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_ide.index[0]} users at {most_common_ide[0]*100:.2f}%\"\n\nfig = px.bar(df_ide[df_ide.iloc[:,-1]==country][df_ide.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","57078073":"host_col= [col for col in df.columns if \"Which of the following hosted notebook products do you use on a regular basis?\" in col]\ndf_host=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in host_col]\nmapping_dict=dict(zip(host_col,mapping))\ndf_host=df_host[host_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_host.drop(columns=[\"None\"],inplace=True)\ndf_host.head()\n\nfig = px.bar(df_host[df_host.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"Hosted Notebook products used on daily basis\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nmost_common_host=df_host[df_host.iloc[:,-1]==country][df_host.columns[:-2]].count().sort_values(ascending=False)\nif most_common_host.index[0] == \"Colab Notebooks\":\n    title = f\"The same trend is observed in {country}, with {most_common_host[0]} respondents reporting are using {most_common_host.index[0]} as hosted notebook followed by {most_common_host.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_host.index[0]} users at {most_common_ide[0]*100:.2f}%\"\n\nfig = px.bar(df_host[df_host.iloc[:,-1]==country][df_host.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","cc19adb6":"device_col= [col for col in df.columns if \"What type of computing platform do you use most often for your data science projects?\" in col]\ndf_device=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in device_col]\nmapping_dict=dict(zip(device_col,mapping))\ndf_device=df_device[device_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","b3304361":"fig = px.bar(df_device[\"Selected Choice\"].value_counts())\nfig.update_layout(\n    title=\"Computational Devices used for data science projects\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()\n","ab07e714":"hardware_col= [col for col in df.columns if \"Which types of specialized hardware do you use on a regular basis?\" in col]\ndf_hardware=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in hardware_col]\nmapping_dict=dict(zip(hardware_col,mapping))\ndf_hardware=df_hardware[hardware_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_hardware.drop(columns=[\"None\"],inplace=True)\n","9b0cc201":"fig = px.bar(df_hardware[df_hardware.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"Specialized hardware used on daily basis\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nmost_common_hardware=df_hardware[df_hardware.iloc[:,-1]==country][df_hardware.columns[:-2]].count().sort_values(ascending=False)\nif most_common_hardware.index[0] == \"NVIDIA GPUs \":\n    title = f\"The same trend is observed in {country}, with {most_common_hardware[0]} respondents reporting are using {most_common_hardware.index[0]} as Specialized hardware followed by {most_common_hardware.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_hardware.index[0]} users at {most_common_hardware[0]}\"\n\nfig = px.bar(df_hardware[df_hardware.iloc[:,-1]==country][df_hardware.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","bbf27ae5":"tpu_col= [col for col in df.columns if \"Approximately how many times have you used a TPU (tensor processing unit)?\" in col]\ndf_tpu=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in tpu_col]\nmapping_dict=dict(zip(tpu_col,mapping))\ndf_tpu=df_tpu[tpu_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\n","e9f75e23":"fig = px.bar(df_tpu[\"Approximately how many times have you used a TPU (tensor processing unit)?\"].value_counts())\nfig.update_layout(\n    title=\"TPU usage science projects\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()","5dc35696":"viz_col= [col for col in df.columns if \"What data visualization libraries or tools do you use on a regular basis? \" in col]\ndf_viz=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in viz_col]\nmapping_dict=dict(zip(viz_col,mapping))\ndf_viz=df_viz[viz_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_viz.drop(columns=[\"None\"],inplace=True)\n","c07369db":"fig = px.bar(df_viz[df_viz.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"Data Visualization tools used on daily basis\",\n    xaxis_title=\"Data Visualization tools used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_viz=df_viz[df_viz.iloc[:,-1]==country][df_viz.columns[:-2]].count().sort_values(ascending=False)\nif most_common_viz.index[0] == \"Matplotlib \":\n    title = f\"The same trend is observed in {country}, with {most_common_viz[0]} respondents reporting are using {most_common_viz.index[0]} as data visualisation tool followed by {most_common_viz.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_viz.index[0]} users at {most_common_viz[0]}\"\n\nfig = px.bar(df_viz[df_viz.iloc[:,-1]==country][df_viz.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Data Visualization tools used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","cdef1a3d":"ml_col= [col for col in df.columns if \"For how many years have you used machine learning methods?\" in col]\ndf_ml=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in ml_col]\nmapping_dict=dict(zip(ml_col,mapping))\ndf_ml=df_ml[ml_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\n","f92cecef":"fig = px.bar(df_ml[\"For how many years have you used machine learning methods?\"].value_counts())\nfig.update_layout(\n    title=\"years of experience using machine learning methods?\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()","b742a4a8":"ml_fw_col= [col for col in df.columns if \"Which of the following machine learning frameworks do you use on a regular basis?\" in col]\ndf_ml_fw=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in ml_fw_col]\nmapping_dict=dict(zip(ml_fw_col,mapping))\ndf_ml_fw=df_ml_fw[ml_fw_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_ml_fw.drop(columns=[\"None\"],inplace = True)","99dcc6ff":"fig = px.bar(df_ml_fw[df_ml_fw.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\" Machine learning framework used on daily basis\",\n    xaxis_title=\"Machine learning framework used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_ml_fw=df_ml_fw[df_ml_fw.iloc[:,-1]==country][df_ml_fw.columns[:-2]].count().sort_values(ascending=False)\nif most_common_ml_fw.index[0] == 'learn ':\n    title = f\"The same trend is observed in {country}, with {most_common_ml_fw[0]} respondents reporting are using {most_common_ml_fw.index[0]} as ML framework followed by {most_common_ml_fw.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_ml_fw.index[0]} users at {most_common_ml_fw[0]}\"\n\nfig = px.bar(df_ml_fw[df_ml_fw.iloc[:,-1]==country][df_ml_fw.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Machine learning framework used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","0f8f339b":"ml_algo_col= [col for col in df.columns if \"Which of the following ML algorithms do you use on a regular basis?\" in col]\ndf_ml_algo=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in ml_algo_col]\nmapping_dict=dict(zip(ml_algo_col,mapping))\ndf_ml_algo=df_ml_algo[ml_algo_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_ml_algo.drop(columns=[\"None\"],inplace = True)","64687485":"fig = px.bar(df_ml_algo[df_ml_algo.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\" Machine learning Algorithms used on daily basis\",\n    xaxis_title=\"Machine learning Algorithms used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_ml_algo=df_ml_algo[df_ml_algo.iloc[:,-1]==country][df_ml_algo.columns[:-2]].count().sort_values(ascending=False)\nif most_common_ml_algo.index[0] == 'Linear or Logistic Regression':\n    title = f\"The same trend is observed in {country}, with {most_common_ml_algo[0]} respondents reporting are using {most_common_ml_algo.index[0]} as Machine learning models followed by {most_common_ml_algo.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_ml_algo.index[0]} users at {most_common_ml_algo[0]}\"\n\nfig = px.bar(df_ml_algo[df_ml_algo.iloc[:,-1]==country][df_ml_algo.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Machine learning Algorithms used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","3a9b5614":"cv_col= [col for col in df.columns if \"Which categories of computer vision methods do you use on a regular basis?\" in col]\ndf_cv=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in cv_col]\nmapping_dict=dict(zip(cv_col,mapping))\ndf_cv=df_cv[cv_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_cv.drop(columns=[\"None\"],inplace = True)\n","657fa667":"fig = px.bar(df_cv[df_cv.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\" Computer Vision methods used on daily basis\",\n    xaxis_title=\"Computer Vision methods used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_cv=df_cv[df_cv.iloc[:,-1]==country][df_cv.columns[:-2]].count().sort_values(ascending=False)\nif most_common_cv.index[0] == 'Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)':\n    title = f\"The same trend is observed in {country}, with {most_common_cv[0]} respondents reporting are using {most_common_cv.index[0]} as Computer Vision methods followed by {most_common_cv.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_cv.index[0]} users at {most_common_cv[0]}\"\n\nfig = px.bar(df_cv[df_cv.iloc[:,-1]==country][df_cv.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Computer Vision methods used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","db2cc14e":"nlp_col= [col for col in df.columns if \"Which of the following natural language processing (NLP) methods do you use on a regular basis?\" in col]\ndf_nlp=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in nlp_col]\nmapping_dict=dict(zip(nlp_col,mapping))\ndf_nlp=df_nlp[nlp_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_nlp.drop(columns=[\"None\"],inplace = True)\n","d12cc4d9":"fig = px.bar(df_nlp[df_nlp.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\" NLP methods used on daily basis\",\n    xaxis_title=\"NLP methods used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_nlp=df_nlp[df_nlp.iloc[:,-1]==country][df_nlp.columns[:-2]].count().sort_values(ascending=False)\nif most_common_nlp.index[0] == 'Word embeddings\/vectors (GLoVe, fastText, word2vec)':\n    title = f\"The same trend is observed in {country}, with {most_common_nlp[0]} respondents reporting are using {most_common_nlp.index[0]} as NLP methods followed by {most_common_nlp.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_nlp.index[0]} users at {most_common_nlp[0]}\"\n\nfig = px.bar(df_nlp[df_nlp.iloc[:,-1]==country][df_nlp.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"NLP methods used\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","5c10a6c7":"industry_col= [col for col in df.columns if \"In what industry is your current employer\/contract (or your most recent employer if retired)?\" in col]\ndf_industry=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in industry_col]\nmapping_dict=dict(zip(industry_col,mapping))\ndf_industry=df_industry[industry_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\n","5fe75f7f":"fig = px.bar(df_industry[\"Selected Choice\"].value_counts())\nfig.update_layout(\n    title=\"current employer\/contract industry\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()","74373d14":"size_col= [col for col in df.columns if \"What is the size of the company where you are employed?\" in col]\ndf_size=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in size_col]\nmapping_dict=dict(zip(size_col,mapping))\ndf_size=df_size[size_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\n","7bfdaa17":"fig = px.bar(df_size[\"What is the size of the company where you are employed?\"].value_counts())\nfig.update_layout(\n    title=\"Size of the company\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()","007762ba":"ds_workload_col= [col for col in df.columns if \"Approximately how many individuals are responsible for data science workloads at your place of business?\" in col]\ndf_ds_workload=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in ds_workload_col]\nmapping_dict=dict(zip(ds_workload_col,mapping))\ndf_ds_workload=df_ds_workload[ds_workload_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","4de603f7":"fig = px.bar(df_ds_workload[\"Approximately how many individuals are responsible for data science workloads at your place of business?\"].value_counts())\nfig.update_layout(\n    title=\"Responsible Data Science workload Individuals\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()","ccd6b0e3":"ml_app_col= [col for col in df.columns if \"Does your current employer incorporate machine learning methods into their business?\" in col]\ndf_ml_app=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in ml_app_col]\nmapping_dict=dict(zip(ml_app_col,mapping))\ndf_ml_app=df_ml_app[ ml_app_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","81d533c8":"fig = px.bar(df_ml_app[\"Does your current employer incorporate machine learning methods into their business?\"].value_counts())\nfig.update_layout(\n    title=\"Machine learning incorporation into business\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()","eb46c901":"role_col= [col for col in df.columns if \"Select any activities that make up an important part of your role at work:\" in col]\ndf_role=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in role_col]\nmapping_dict=dict(zip(role_col,mapping))\ndf_role=df_role[ role_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","cf99187a":"fig = px.bar(df_role[df_role.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\" Role at work\",\n    xaxis_title=\"Role at work\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_role=df_role[df_role.iloc[:,-1]==country][df_role.columns[:-2]].count().sort_values(ascending=False)\nif most_common_role.index[0] == 'Analyze and understand data to influence product or business decisions':\n    title = f\"The same trend is observed in {country}, with {most_common_role[0]} respondents reporting are of {most_common_role.index[0]} role followed by {most_common_role.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_role.index[0]} users at {most_common_role[0]}\"\n\nfig = px.bar(df_role[df_role.iloc[:,-1]==country][df_role.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Role at work\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","8585b047":"salary_col= [col for col in df.columns if \"What is your current yearly compensation (approximate $USD)?\" in col]\ndf_salary=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in salary_col]\nmapping_dict=dict(zip(salary_col,mapping))\ndf_salary=df_salary[ salary_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\n\n","980db21c":"fig = px.bar(df_salary[\"What is your current yearly compensation (approximate $USD)?\"].value_counts())\nfig.update_layout(\n    title=\"Current yearly compensation\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()","f254d683":"cloud_comp_col= [col for col in df.columns if \"Which of the following cloud computing platforms do you use on a regular basis?\" in col]\ndf_cloud_comp=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in cloud_comp_col]\nmapping_dict=dict(zip(cloud_comp_col,mapping))\ndf_cloud_comp=df_cloud_comp[ cloud_comp_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\n\n","79b794c8":"fig = px.bar(df_cloud_comp[df_cloud_comp.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"Cloud Computing platforms\",\n    xaxis_title=\"cloud computing platforms\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_cloud_comp=df_cloud_comp[df_cloud_comp.iloc[:,-1]==country][df_cloud_comp.columns[:-2]].count().sort_values(ascending=False)\nif most_common_cloud_comp.index[0] == 'Amazon Web Services (AWS) ':\n    title = f\"The same trend is observed in {country}, with {most_common_cloud_comp[0]} respondents reporting are using {most_common_cloud_comp.index[0]} as Cloud Computing platforms followed by {most_common_cloud_comp.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_cloud_comp.index[0]} users at {most_common_cloud_comp[0]}\"\n\nfig = px.bar(df_cloud_comp[df_cloud_comp.iloc[:,-1]==country][df_cloud_comp.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Cloud Computing platforms\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","708ca84a":"fav_cloud_col= [col for col in df.columns if \"Of the cloud platforms that you are familiar with, which has the best developer experience (most enjoyable to use)?\" in col]\ndf_fav_cloud=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in fav_cloud_col]\nmapping_dict=dict(zip(fav_cloud_col,mapping))\ndf_fav_cloud=df_fav_cloud[ fav_cloud_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","16c4a8e9":"fig = px.bar(df_fav_cloud[\"Selected Choice\"].value_counts())\nfig.update_layout(\n    title=\"Familiar Cloud Platforms\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","0d0e8b41":"cloud_comp_prod_col= [col for col in df.columns if \"Which of the following cloud computing platforms do you use on a regular basis?\" in col]\ndf_cloud_comp_prod=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in cloud_comp_prod_col]\nmapping_dict=dict(zip(cloud_comp_prod_col,mapping))\ndf_cloud_comp_prod=df_cloud_comp_prod[ cloud_comp_prod_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","ac51585e":"fig = px.bar(df_cloud_comp_prod[df_cloud_comp_prod.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"Cloud Computing products\",\n    xaxis_title=\"cloud computing products\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_cloud_comp_prod=df_cloud_comp_prod[df_cloud_comp_prod.iloc[:,-1]==country][df_cloud_comp_prod.columns[:-2]].count().sort_values(ascending=False)\nif most_common_cloud_comp_prod.index[0] == 'Amazon Web Services (AWS) ':\n    title = f\"The same trend is observed in {country}, with {most_common_cloud_comp_prod[0]} respondents reporting are using {most_common_cloud_comp_prod.index[0]} as Cloud Computing products followed by {most_common_cloud_comp_prod.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_cloud_comp_prod.index[0]} users at {most_common_cloud_comp_prod[0]}\"\n\nfig = px.bar(df_cloud_comp_prod[df_cloud_comp_prod.iloc[:,-1]==country][df_cloud_comp_prod.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Cloud Computing products\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","8e6d1e0c":"data_storage_prod_col= [col for col in df.columns if \"Do you use any of the following data storage products on a regular basis?\" in col]\ndf_data_storage_prod=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in data_storage_prod_col]\nmapping_dict=dict(zip(data_storage_prod_col,mapping))\ndf_data_storage_prod=df_data_storage_prod[ data_storage_prod_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","5d28b66c":"fig = px.bar(df_data_storage_prod[df_data_storage_prod.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"Data Storage products\",\n    xaxis_title=\"Data Storage products\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_data_storage_prod=df_data_storage_prod[df_data_storage_prod.iloc[:,-1]==country][df_data_storage_prod.columns[:-2]].count().sort_values(ascending=False)\nif most_common_data_storage_prod.index[0] == 'Amazon Simple Storage Service (S3)  ':\n    title = f\"The same trend is observed in {country}, with {most_common_data_storage_prod[0]} respondents reporting are using {most_common_data_storage_prod.index[0]} as Data Storage products followed by {most_common_data_storage_prod.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_data_storage_prod.index[0]} users at {most_common_data_storage_prod[0]}\"\n\nfig = px.bar(df_data_storage_prod[df_data_storage_prod.iloc[:,-1]==country][df_data_storage_prod.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Data Storage products\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","54cca6a7":"ml_prod_col= [col for col in df.columns if \"Do you use any of the following managed machine learning products on a regular basis?\" in col]\ndf_ml_prod=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in ml_prod_col]\nmapping_dict=dict(zip(ml_prod_col,mapping))\ndf_ml_prod=df_ml_prod[ ml_prod_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\ndf_ml_prod.drop(columns=[\"No \/ None\"],inplace=True)","0eca9492":"fig = px.bar(df_ml_prod[df_ml_prod.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"Managed ML products\",\n    xaxis_title=\"Managed ML products\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_ml_prod=df_ml_prod[df_ml_prod.iloc[:,-1]==country][df_ml_prod.columns[:-2]].count().sort_values(ascending=False)\nif most_common_ml_prod.index[0] == 'Amazon SageMaker ':\n    title = f\"The same trend is observed in {country}, with {most_common_ml_prod[0]} respondents reporting are using {most_common_ml_prod.index[0]} as Managed ML product followed by {most_common_ml_prod.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_ml_prod.index[0]} users at {most_common_ml_prod[0]}\"\n\nfig = px.bar(df_ml_prod[df_ml_prod.iloc[:,-1]==country][df_ml_prod.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"Managed ML products\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","5d2a94e6":"big_data_col= [col for col in df.columns if \"Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?\" in col]\ndf_big_data=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in big_data_col]\nmapping_dict=dict(zip(big_data_col,mapping))\ndf_big_data=df_big_data[ big_data_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","72f19b2e":"fig = px.bar(df_big_data[df_big_data.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"big_data products\",\n    xaxis_title=\"big_data products\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_big_data=df_big_data[df_big_data.iloc[:,-1]==country][df_big_data.columns[:-2]].count().sort_values(ascending=False)\nif most_common_big_data.index[0] == 'MySQL ':\n    title = f\"The same trend is observed in {country}, with {most_common_big_data[0]} respondents reporting are using {most_common_big_data.index[0]} as BIG DATA product followed by {most_common_big_data.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_big_data.index[0]} users at {most_common_big_data[0]}\"\n\nfig = px.bar(df_big_data[df_big_data.iloc[:,-1]==country][df_big_data.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"big_data products\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","554e8b96":"big_data_prod_col= [col for col in df.columns if \"Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?\" in col]\ndf_big_data_prod=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in big_data_prod_col]\nmapping_dict=dict(zip(big_data_prod_col,mapping))\ndf_big_data_prod=df_big_data_prod[ big_data_prod_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)\n","b7b54195":"fig = px.bar(df_big_data_prod[\"Selected Choice\"].value_counts())\nfig.update_layout(\n    title=\"Big Data Products\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside',)\nfig.show()","0b413ee0":"bi_tools_col= [col for col in df.columns if \"Which of the following business intelligence tools do you use on a regular basis? (Select all that apply)\" in col]\ndf_bi_tools=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in bi_tools_col]\nmapping_dict=dict(zip(bi_tools_col,mapping))\ndf_bi_tools=df_bi_tools[ bi_tools_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","82005cfb":"fig = px.bar(df_bi_tools[df_bi_tools.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=\"BI tools\",\n    xaxis_title=\"BI tools\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()\nprint(\"=\"*199)\nmost_common_bi_tools=df_bi_tools[df_bi_tools.iloc[:,-1]==country][df_bi_tools.columns[:-2]].count().sort_values(ascending=False)\nif most_common_bi_tools.index[0] == 'MySQL ':\n    title = f\"The same trend is observed in {country}, with {most_common_bi_tools[0]} respondents reporting are using {most_common_bi_tools.index[0]} as bi tools followed by {most_common_bi_tools.index[1]}\"\nelse:\n    title = f\"In the case of {country},<br>more respondents reported are {most_common_bi_tools.index[0]} users at {most_common_bi_tools[0]}\"\n\nfig = px.bar(df_bi_tools[df_bi_tools.iloc[:,-1]==country][df_bi_tools.columns[:-2]].count().sort_values(ascending=False))\nfig.update_layout(\n    title=title,\n    xaxis_title=\"bi_tools\",\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","3e124e35":"bi_tools_often_col= [col for col in df.columns if \"Which of the following business intelligence tools do you use most often?\" in col]\ndf_bi_tools_often=df.copy()\nmapping=[col.split('-')[-1].lstrip() for col in bi_tools_often_col]\nmapping_dict=dict(zip(bi_tools_often_col,mapping))\ndf_bi_tools_often=df_bi_tools_often[ bi_tools_often_col + [df.columns[3]] + [\"country\"]].rename(columns=mapping_dict)","ad78b275":"fig = px.bar(df_bi_tools_often[\"Selected Choice\"].value_counts())\nfig.update_layout(\n    title=\"BI tools used often\",\n    xaxis_title=None,\n    yaxis_title='Number of respondents',\n    showlegend=False\n)\nfig.update_traces(textposition='inside')\nfig.show()","e1267c98":"# Machine Learning Algorithms","77fbb298":"# Gender Distribution","47112b31":"# Coding Experience","e5749cf2":"# Computational Platform used","8e2d0328":"### Kaggle respondents are mostly students and it is acceptable that the professionals might not be able to concnetrate on kaggle due to the workload they have.","27f0d498":"# What is the Important task of using Machine Learning in the Industry??","aa39815a":"# Educational Qualification","69cc4608":"### Yayyy!  Students in india have started using kaggle like a hobby and we can see the diference how indians between age group (18-24) distanced out other countries. But the experienced ones are less in india as compared to other countries and Most of the Indians who responded to this survey are Youngsters.","f4658406":"![survey analysis.png](attachment:fe44d81c-ffae-4af9-aefc-23179bbecc09.png)","9acf4757":"# Cloud Computing Platforms Used","f444777a":"# How far the companies have reached in implementing Machine Learning into their business?","4f4b11af":"### \"NVIDIA GPUs\" are the most used hardwares ","b5ee0ac3":"### Nothing surprising, Most of the budding machine learning enthusiasts are fond of using jupyter notebook as using it is pretty much easier than anything else","f6652c85":"# Salary Breakdown","bdefdbc9":"### Woohooo! Indians are crazy about kaggle now-a-days and this pandemic has helped many of the indians to come out of the regular studies and try out something that could make them feel knowledgable. And we can See most of the survey responders are Indians followed by USA","6dc631f7":"# Data Visualization tools usage","ff5593ce":"# Managed Machine Learing Products used on regular basis","bb584593":"# Job Titles","e94d6919":"# Specialized Hardware usage","51922235":"### Hands Up!! I myself using Colab notebooks and kaggle notebooks from the past 1 year. This isn't a Surprise for me","19a6e311":"# Experience in using machine learning models","e192b0df":"# Workload Management in the Industry","21b1c7ee":"> Woooo......! Percentage Distribution of men is way higher than women but Indian Women's Distribution is somewhat higher than the average of others, which is a good sign for India.","e29d6c84":"### Lets start exploring the data","e65e491f":"# TPU usage","76dfd740":"### Matplotlib is the mostly used but I use Plotly to make the visualizations more Interactive","2656dddd":"### From the past 5 years kaggle has been conducting the survey that presents the most comprehensional view of the data science and machine learning. So now let us explore the data given to understand the impact, priorities or concerns of a specific group of data science and machine learning practitioners.","1a8224b9":"### Let's find out how the people of different genders are distributed ","b2092ece":"# Data Storage Products","e183f749":"### Lets explore distribution of Kagglers country wise","5fd36ee1":"# Programming Languages","441821c9":"### I will be mostly concentrating on India","880f5308":"# Natural language processing methods","2f304131":"# Big Data Products","07812e5d":"### Lets dive deep into the data to find out age group of kagglers who are more into kaggling","3cb56bbf":"# Hosting Notebook Products","78b7f5aa":"# Computer Vision Methods","46caca90":"* So, we have nearly 42 questions related to Data Science. Let's deal with each question one after the other and educate ourselves how machine learning community performs machine learning tasks. ","5becfffd":"# Most used Cloud Computing Platforms","b7376ee3":"# Mostly used BI tools","85d7bd4f":"# Size of the Company","3ebab619":"### From this Can we confirm that \"Python is the most used programming language by the Kagglers\" ? (Its the most used though)","2df152ef":"# Current employer industry","89b52c50":"# Machine learning Frameworks usage","415ad79a":"# BI tools used","89004bcd":"### What shocked me from this donut chart is that 1% of the kagglers who responded have not gone past the high school. Don't you think that was too early to start????","521d6302":"# IDE used","f4d43d7e":"# Age Distribution","a1139754":"# Importing Required Libraries","a398b5aa":"### May be I also belong to the  category of majority of the kagglers in this particular phase as I have never used a TPU yet. But looking forward to use them when required."}}