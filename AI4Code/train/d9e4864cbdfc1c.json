{"cell_type":{"51a3c032":"code","f5616acd":"code","58dc8b0c":"code","1ee8ab83":"code","605280b5":"code","92cd44d8":"code","a8e91e99":"code","1f9c1342":"code","be40bfed":"code","fcc2be94":"code","d77367a3":"code","8e1b881b":"code","aa7f5457":"code","3425b64a":"code","87513812":"code","894c80e3":"code","5d2605cf":"code","d194474c":"code","9d8901f9":"code","c9ce3fb7":"code","f17b638d":"code","ebe62758":"code","373b4f1d":"code","36e15ed7":"code","4f6d6048":"code","8fb9f7f3":"code","9afb1436":"code","d5a6c862":"code","ffd61286":"code","99f8854d":"code","fabc32d8":"code","c045a325":"code","0e58da47":"code","5e6b0973":"code","4ead511b":"code","33ab2a70":"code","32c95a32":"code","b296d3c8":"code","7083f2f0":"code","16b196ab":"code","b9383903":"code","0d8eaee3":"code","783c7559":"code","33725054":"code","cbf4dab1":"code","8714f920":"code","15a7bc69":"code","675d128c":"code","179af557":"code","58ce1933":"code","ff85048e":"code","f63c0d1f":"code","730d2451":"code","9da64031":"code","1c40cd33":"code","df729e0d":"code","7fa88b78":"code","7dbd47fe":"code","b0b95aa2":"code","b0a492f3":"code","411257f8":"code","6e229cea":"code","e7a7dba4":"code","8bd4f626":"code","7b2d6e68":"code","9bd9894d":"code","4caacd95":"code","dc064438":"code","e7e6d8bc":"code","41ad53c6":"code","337dfe4c":"code","2dcb6dd0":"code","19791b18":"code","4ef606b4":"code","2d9acefc":"code","90b75003":"code","406980f6":"code","a91773be":"code","5386d317":"code","21a06af7":"code","e0ca13d6":"code","2a829297":"code","cb571569":"code","22ffcf32":"code","d6c635d9":"code","a48f664b":"code","d3598c00":"code","b19cddaa":"code","b8680b90":"code","e34c5de4":"code","c62de921":"code","72fe72af":"code","02463a1a":"markdown","c831a2e3":"markdown","c7081c9b":"markdown","3f64a044":"markdown","6f45b19f":"markdown","1ad019b3":"markdown","899e9152":"markdown","0977617d":"markdown","96b041cc":"markdown","e08c2105":"markdown","749ea422":"markdown","45effe48":"markdown","accf0f5d":"markdown","bb641dc0":"markdown","5ab975f7":"markdown","f9f3cf41":"markdown","d228ce58":"markdown","b48bb32c":"markdown","ed3630f7":"markdown","171b0998":"markdown","202311f3":"markdown","ba3e7008":"markdown","105ca90c":"markdown","b9b5e7e1":"markdown","076b51ae":"markdown","11b142c8":"markdown","dbf14cd1":"markdown","450ccae0":"markdown","2e601ac9":"markdown","fc4cc57e":"markdown","e9270126":"markdown","94b3c21f":"markdown","a1183140":"markdown","8f8e6786":"markdown","e3f91f7f":"markdown","59e30799":"markdown","5d49dd22":"markdown","b5be9283":"markdown","26ad7c04":"markdown","77b8f2cc":"markdown","257d03b9":"markdown","bcddda73":"markdown","9d53d9ce":"markdown","abf7048b":"markdown","4c647d08":"markdown","e69eb916":"markdown","e53672ae":"markdown","198610cc":"markdown","3372a165":"markdown","78584ba2":"markdown","6457f016":"markdown"},"source":{"51a3c032":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5616acd":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","58dc8b0c":"train.shape","1ee8ab83":"train.head()","605280b5":"train.info()","92cd44d8":"train.describe()","a8e91e99":"train.isnull().sum()","1f9c1342":"train[\"Embarked\"].value_counts()","be40bfed":"train['Embarked'].fillna('S',inplace = True)\ntrain['Embarked'].value_counts()","fcc2be94":"train['Age'].fillna(train['Age'].median(),inplace = True)","d77367a3":"train.isnull().sum()","8e1b881b":"train['Cabin'].fillna(\"U\",inplace = True)","aa7f5457":"import matplotlib.pyplot as plt\nimport seaborn as sns","3425b64a":"train['Age'].hist(bins=15)","87513812":"plt.boxplot(train['Age'])","894c80e3":"train['Fare'].hist()","5d2605cf":"plt.boxplot(train['Fare'])","d194474c":"print(train['Pclass'].value_counts())\ntrain['Pclass'].hist()","9d8901f9":"train['SibSp'].value_counts()","c9ce3fb7":"train['SibSp'].hist()","f17b638d":"plt.boxplot(train['SibSp'])","ebe62758":"train['Parch'].value_counts()","373b4f1d":"train['Parch'].hist()","36e15ed7":"plt.boxplot(train['Parch'])","4f6d6048":"train['Age']","8fb9f7f3":"train['NewAge'] = np.sin(train['Age'])\nplt.boxplot(train['NewAge'])","9afb1436":"train['NewAge'].describe()","d5a6c862":"train['NewFare'] = np.cos(train['Fare'])\nplt.boxplot(train['NewFare'])","ffd61286":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","99f8854d":"train['Cab'] = train['Cabin'].astype(str).str[0]\ntrain.head()","fabc32d8":"train['Cab'].value_counts()","c045a325":"train.head()","0e58da47":"train['fam'] = train['SibSp']+train['Parch']\ntrain.head()","5e6b0973":"train[['fam', 'Survived']].groupby(['fam'], as_index=False).mean().sort_values(by='Survived', ascending=False)","4ead511b":"train['fam'].value_counts()","33ab2a70":"train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","32c95a32":"g = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","b296d3c8":"grid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","7083f2f0":"grid = sns.FacetGrid(train, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","16b196ab":"grid = sns.FacetGrid(train, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","b9383903":"import re\ndef findTitle(name):\n    match = re.search(\"(Dr|Mrs?|Ms|Miss|Master|Rev|Capt|Mlle|Col|Major|Sir|Jonkheer|Lady|the Countess|Mme|Don)\\\\.\",name)\n    if match:\n        title = match.group(0)\n        if (title == 'Don.' or title == 'Major.' or title == 'Capt.'):\n            title = 'Sir.'\n        if (title == 'Mlle.' or title == 'Mme.'):\n            title = 'Miss.'\n        return title\n    else:\n        return \"Other\"\ntrain[\"Title\"] = train[\"Name\"].apply(findTitle)\n\ntrain.head()","0d8eaee3":"train.info()","783c7559":"pd.crosstab(train['Title'], train['Sex'])","33725054":"train[\"T\"] = train[\"Ticket\"].apply(lambda x: str(x)[0])\ntrain.head()","cbf4dab1":"train['T'].value_counts()","8714f920":"train['T'].replace({'S':10,'P':11,'C':12,'A':13,'W':14,'F':15,'L':16},inplace = True)\ntrain['T'].value_counts()","15a7bc69":"train.head()","675d128c":"train['Cab'].value_counts()","179af557":"enc_cab = {'U':0,'C':1,'B':2,'D':3,'E':4,'A':5,'F':6,'G':7,'T':8}\ntrain['Cab'] = train['Cab'].replace(enc_cab)\ntrain['Cab'].value_counts()","58ce1933":"Uncommon = {'Lady.':0, 'the Countess.':0,'Capt.':0, 'Col.':0,'Don.':0, 'Dr.':0, 'Major.':0, 'Rev.':0, 'Sir.':0, 'Jonkheer.':0, 'Dona.':0}\n\ntrain['Title'] = train['Title'].replace(Uncommon)\ntrain['Title'].value_counts()","ff85048e":"t = {5 : 'u'}\ntrain['Title'] = train['Title'].replace(t)\ntrain['Title'].value_counts()","f63c0d1f":"title_encode = {\"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4,'u':0,'Ms.':0}\ntrain['Title'] = train['Title'].replace(title_encode)\ntrain['Title'].value_counts()","730d2451":"train = train.drop(['Name', 'PassengerId'], axis=1)\ntrain.head()","9da64031":"sex_encode = {\"male\":1,\"female\":2}\ntrain['Sex'] = train['Sex'].replace(sex_encode)\ntrain.head()","1c40cd33":"train['Embarked'].value_counts()\n","df729e0d":"embarked_encode = {'S':1,'C':2,'Q':3}\ntrain['Embarked'] = train['Embarked'].replace(embarked_encode)\ntrain.head()","7fa88b78":"grid = sns.FacetGrid(train, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","7dbd47fe":"plt.figure(figsize= (16,10))\nsns.heatmap(train.corr(),cmap = 'Dark2',annot = True,linewidths=1.0,linecolor='black')","b0b95aa2":"plt.figure(figsize= (16,10))\nsns.heatmap(np.abs(train.corr()),cmap = 'Dark2',annot = True,linewidths=1.0,linecolor='black')","b0a492f3":"test.shape","411257f8":"test.head()","6e229cea":"test.info()","e7a7dba4":"test.isnull().sum()","8bd4f626":"test['Age'].fillna(test['Age'].median(),inplace = True)","7b2d6e68":"test.isnull().sum()","9bd9894d":"test['Fare'].fillna(test['Fare'].median(),inplace = True)","4caacd95":"test.isnull().sum()","dc064438":"test['Cabin'].fillna('U',inplace = True)\ntest.head()","e7e6d8bc":"test['NewAge'] = np.sin(test['Age'])\nplt.boxplot(train['NewAge'])","41ad53c6":"test['NewFare'] = np.cos(test['Fare'])\nplt.boxplot(test['NewFare'])","337dfe4c":"test['Cab'] = test['Cabin'].astype(str).str[0]\ntest.head()","2dcb6dd0":"test['Cab'].value_counts()","19791b18":"test['fam'] = test['SibSp']+test['Parch']\ntest.head()","4ef606b4":"test[\"T\"] = test[\"Ticket\"].apply(lambda x: str(x)[0])","2d9acefc":"print(test['T'].value_counts())\ntest.head()","90b75003":"test['T'].replace({'S':10,'P':11,'C':12,'A':13,'W':14,'F':15,'L':16},inplace = True)\ntest['T'].value_counts()","406980f6":"test[\"Title\"] = test[\"Name\"].apply(findTitle)\n\ntest.head()","a91773be":"enc_cab = {'U':0,'C':1,'B':2,'D':3,'E':4,'A':5,'F':6,'G':7,'T':8}\ntest['Cab'] = test['Cab'].replace(enc_cab)\ntest['Cab'].value_counts()","5386d317":"Uncommon = {'Lady.':'u', 'the Countess.':'u','Capt.':'u', 'Col.':'u','Don.':'u', 'Dr.':'u', 'Major.':'u', 'Rev.':'u', 'Sir.':'u', 'Jonkheer.':'u', 'Dona.':'u', 'Other':'u','Ms.':'u'}\n\ntest['Title'] = test['Title'].replace(Uncommon)\ntest['Title'].value_counts()\ntitle_encode = {\"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4,'u':0,'Ms.':0}\ntest['Title'] = test['Title'].replace(title_encode)\ntest['Title'].value_counts()\n","21a06af7":"sex_encode = {\"male\":1,\"female\":2}\ntest['Sex'] = test['Sex'].replace(sex_encode)\ntest.head()","e0ca13d6":"embarked_encode = {'S':1,'C':2,'Q':3}\ntest['Embarked'] = test['Embarked'].replace(embarked_encode)\ntest.head()","2a829297":"train.head()","cb571569":"from sklearn.linear_model import LogisticRegression   \nfrom sklearn.model_selection import KFold \nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn import metrics","22ffcf32":"def classification_model(model, data, predictors, outcome):  \n    #Fit the model:  \n    model.fit(data[predictors],data[outcome])    \n    #Make predictions on training set:  \n    predictions = model.predict(data[predictors])    \n    #Print accuracy  \n    accuracy = metrics.accuracy_score(predictions,data[outcome])  \n    print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n    #Perform k-fold cross-validation with 5 folds  \n    kf = KFold(5,shuffle=True)  \n    error = []  \n    for train, test in kf.split(data):\n        # Filter training data    \n        train_predictors = (data[predictors].iloc[train,:])        \n        # The target we're using to train the algorithm.    \n        train_target = data[outcome].iloc[train]        \n        # Training the algorithm using the predictors and target.    \n        model.fit(train_predictors, train_target)\n        #Record error from each cross-validation run    \n        error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n     \n    print(\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error))) \n    # %s is placeholder for data from format, next % is used to conert it into percentage\n    #.3% is no. of decimals\n    return model","d6c635d9":"output = 'Survived'\nmodel = RandomForestClassifier()\npredict = ['Sex','Title','Pclass','T']\nclassification_model(model,train,predict,output)\nm = classification_model(model,train,predict,output)\na = m.predict(test[predict])\na","a48f664b":"output = 'Survived'\nmodel = RandomForestClassifier()\npredict = ['Sex','Title','Pclass','Cab','Embarked']\nmod = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nclassification_model(mod,train,predict,output)\nmod.best_params_","d3598c00":"output = 'Survived'\nmodel = RandomForestClassifier(n_estimators = 800, min_samples_split= 2, min_samples_leaf= 1, max_features= 'auto', max_depth= 100, bootstrap= True)\npredict = ['Sex','Title','Pclass','Cab','Age']\nclassification_model(model,train,predict,output)\nm = classification_model(model,train,predict,output)\na = m.predict(test[predict])\na","b19cddaa":"my_submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': a})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","b8680b90":"output = 'Survived'\nmodel = RandomForestClassifier()\npredict = ['Sex','Title','Pclass','Cab','Embarked','T']\nclassification_model(model,train,predict,output)\nm = classification_model(model,train,predict,output)\na = m.predict(test[predict])\na","e34c5de4":"from sklearn import svm","c62de921":"output = 'Survived'\nmodel = svm.SVC()\npredict = ['Sex','Title','Pclass','Cab','Embarked']\nclassification_model(model,train,predict,output)\nm = classification_model(model,train,predict,output)\na = m.predict(test[predict])\na","72fe72af":"from sklearn.neighbors import KNeighborsClassifier\n\noutput = 'Survived'\nmodel = KNeighborsClassifier(n_neighbors = 3)\npredict = ['Sex','Title','Pclass']\nclassification_model(model,train,predict,output)\nm = classification_model(model,train,predict,output)\na = m.predict(test[predict])\na","02463a1a":"Now, moving on to the **Age** column.  From the 5-Number Summary of the Age column, we got to know that Age has a normal distribution because the mean = 29.699 is very close to the median = 28.0. We have 177 missing values in Age. Age can play a vital role in determining whether a person survived or not. We have two options to replace the missing values. One, we can replace them with the mean of the column or two, we can replace them with the median of the column. As it seems, we can replace them with either mean or median and it won't make a huge difference. I decided to replace the null values with the median, as median is much more robust to outliers than mean.","c831a2e3":"There are a lot of outliers in Age, which have to be dealt with.","c7081c9b":"The Embarked column has 2 missing values. From its analysis, we can see that 'S' has the highest frequency. We also find that if we make the missing values equal to either of 'S','C' or 'Q', it won't make a huge difference to our analysis and model. So,I decided to replace the null values with the mode, which is 'S'.","3f64a044":"Checking the probability of people surviving on the basis of Sex","6f45b19f":"from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","1ad019b3":"# Model Creation for Predictions","899e9152":"SibSp is again a numerical column with a lot of outliers. These outliers have to be dealt with.","0977617d":"Now, we will look at the statistical overview(five number summary) of the numerical columns of the dataset.","96b041cc":"Encoding the 'Sex' column","e08c2105":"Looking at the Parch column","749ea422":"Encoding the embarked column","45effe48":"Here is a generic function to extract the title from the name","accf0f5d":"Now, we will have a look at the SibSp column","bb641dc0":"Plotting Survived on the basis of Embarked Sex and Fare","5ab975f7":"We will Start with the Age column. We have to find a function which removes the outliers.","f9f3cf41":"Fare has a huge number of outliers which, again, have to be dealt with before modelling. ","d228ce58":"# Creating New Features\n","b48bb32c":"So, what I did here is create a new feature called fam. This fam feature holds the number of people in the family, which by the logic of the problem is the summation of SibSp and Parch. We have found that with 3 family members, almost 72% people are surviving.","ed3630f7":"Plotting Survived vs Age","171b0998":"Checking the probability of people surviving on the basis of Pclass","202311f3":"Next jobs:\n1. Extracting the title from name\n2. Creating more meaningful features","ba3e7008":"Now, let us move to the **Fare** column.","105ca90c":"Now, we will look at the data and make some insights from it.","b9b5e7e1":"# Data at a glance","076b51ae":"Now, let's look at the Embarked Column. It has 2 missing values. Let us look at its categories.","11b142c8":"# Outlier Handling","dbf14cd1":"From this data we have found out a very important result - \n1. If a person is in Pclass 3, then the person has least chance of surviving.\n2. If the person is in Pclass 1, then the person has a very high chance of surviving. \nSo, Pclass and Survived have some correlation.","450ccae0":"We can infer the following about the numerical columns:\n1. PassengerId - This column is just like a Serial Number from 1 to 891. Hence, it is not of much use.\n2. Survived - This is the target column. From the mean and median, we can conclusively say that there were more casualties than survivors.\n3. PClass -  Although it is a numerical column, it seems that it holds categorical data. We will go into this later.\n4. Age - As mentioned earlier, Age has some missing values. By looking at the five number summary, we can say that Age has a fairly normal distribution. This will be proven as correct or wrong later when we visualize the data. \n5. SibSp - This column is not a normal distribution, as the mean and median are far apart.\n6. Parch - This column is not a normal distribution, as the mean and median are far apart. \n7. Fare - This column is not a normal distribution, as the mean and median are far apart. We have to normalise it. \n","2e601ac9":"# Titanic Dataset Problem","fc4cc57e":"At a glance, we can say the following about the training set-\n1. Columns **Age** , **Cabin** and **Embarked** have missing values\n2. The columns **Sex**, **Ticket**, **Cabin** and **Embarked** contain values of **object** type. These columns have to be encoded before any modelling is done.","e9270126":"This is a very important piece of information. Females have much higher chances of survivng than males. Hence, the Sex column will be one of the most important columns for this data set.","94b3c21f":"# Filling in Missing Values","a1183140":"Plotting Survived based on Pclass and Age","8f8e6786":"We will start by importing two packages - Matplotlib and Seaborn","e3f91f7f":"We will look at the data types involved and the number of values each column contains.","59e30799":"So, we have 891 data points in the training set. The data is contained under 12 headings(columns). The target variable is **Survived** which has a value of 0 or 1 based on whether a certain person died or survived the crash. So, it is essentially a **classification** problem. ","5d49dd22":"This project is based on the ship RMS Titanic which started from Southampton,England and was supposed to go to New York,USA. It was hyped up as the \"unsinkable\" ship. It was one of the most anti-climatic events in the history of mankind as the RMS Titanic collided with an iceberg in the Atlantic ocean and sunk. It's wreck now lies near Newfoundland beneath the waves, in the sea bed. Only a fraction of the people onboard it survived.","b5be9283":"First, we will take a look at the training set. We will have a look at a couple of things :\n1. The amount of data we have in the training set.\n2. The first few data points(rows) of the dataset.","26ad7c04":"Parch also seems to have a lot of outliers. We have to deal with them.","77b8f2cc":"Now, let us check the PClass column","257d03b9":"This seems to be a normal distribution. Let us check if it has any outliers.","bcddda73":"# Performing the same operations on the test set","9d53d9ce":"# Exploratory Data Analysis","abf7048b":"So, we will start by importing the training and testing dataset into train and test respectively. ","4c647d08":"We had inferred that Age has a fairly normal distribution. Let us check if it was correct.","e69eb916":"# Encoding the categories into numeric values","e53672ae":"So, Pclass is a column containing categorical data in the form 1,2,3.","198610cc":"From the above heatmap, we can conclude that the Survived column is correlated to(high ones)-\n1. Title\n2. Sex\n3. PClass\n4. Fare\n5. Embarked\n6. Cab","3372a165":"As we have extracted the title, name isn't of much use now. Even Passenger ID can be dropped.","78584ba2":"Checking for missing values in each column.","6457f016":"Checking the probability of people surviving on the basis of fam"}}