{"cell_type":{"b13630d6":"code","e3a0b590":"code","1c67af4c":"code","ea6ae2d1":"code","18950b89":"code","b4193e12":"code","c84cdc27":"code","51df979f":"code","0dd2bffd":"code","0000a47d":"code","216ba7f7":"code","e8ecc3dd":"code","4adb723b":"code","dc8db749":"code","ddce0baf":"code","fb88761d":"code","ed5a1a70":"code","ff46fb72":"code","ba42d48d":"code","2466a311":"code","eac05d03":"code","b3aa5003":"code","f245db5b":"code","928ce762":"code","34644f9d":"code","459e1401":"markdown","ce37f4f7":"markdown","f91ee9fc":"markdown","96c9b7d9":"markdown","25984204":"markdown","6f39ed77":"markdown","4eeb4f77":"markdown"},"source":{"b13630d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e3a0b590":"! unzip \/kaggle\/input\/platesv2\/plates.zip\n","1c67af4c":"!ls","ea6ae2d1":"! pip install tf_nightly","18950b89":"import tensorflow as tf \ntf.__version__ ","b4193e12":"!ls plates","c84cdc27":"image_size = (200, 200)\nbatch_size = 10\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"plates\/train\",\n    validation_split=0.3,\n    subset=\"training\",\n    seed=15,\n    image_size=image_size,\n    batch_size=batch_size,\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"plates\/train\",\n    validation_split=0.3,\n    subset=\"validation\",\n    seed=15,\n    image_size=image_size,\n    batch_size=batch_size,\n)\n","51df979f":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","0dd2bffd":"from tensorflow import keras\nfrom tensorflow.keras import layers\ndata_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.45),\n        layers.experimental.preprocessing.RandomZoom(0.1),\n        layers.experimental.preprocessing.RandomContrast(0.1),\n       \n        \n    ]\n)","0000a47d":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","216ba7f7":"train_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)","e8ecc3dd":"def make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    for size in [128, 256, 512, 728]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        #x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(units, activation=activation)(x)\n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=2)\nkeras.utils.plot_model(model, show_shapes=True)","4adb723b":"epochs = 200\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n]\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nhistory = model.fit(train_ds, epochs=epochs, callbacks=[callbacks], validation_data=val_ds)\n\n","dc8db749":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\n#epochs_range = range(22)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(1, 2, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","ddce0baf":"from keras.preprocessing.image import ImageDataGenerator\ntest_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow_from_directory(  \n        'plates',\n        classes=['test'],\n        target_size = (200, 200),\n        batch_size = 10,\n        shuffle = False,        \n        class_mode = None)","fb88761d":"#test_generator.reset()\npredict = model.predict_generator(test_generator, steps = len(test_generator.filenames))\nlen(predict)","ed5a1a70":"predict","ff46fb72":"sub_df = pd.read_csv('..\/input\/platesv2\/sample_submission.csv')\nsub_df.head()","ba42d48d":"sub_df['label'] = predict","2466a311":"sub_df.head(10)","eac05d03":"sub_df['label'] = sub_df['label'].apply(lambda x: 'dirty' if x > 0.5 else 'cleaned')","b3aa5003":"sub_df.head(10)","f245db5b":"sub_df.to_csv('sub.csv', index=False)","928ce762":"dd= pd.read_csv(\".\/sub.csv\")\ndd.head(10)","34644f9d":"dd.label.value_counts()","459e1401":"# Install TF nightly","ce37f4f7":"# Using image data augmentation","f91ee9fc":"# Visualize the data","96c9b7d9":"# Build a model","25984204":"# Test Data","6f39ed77":"# Train the model","4eeb4f77":"# Generate a Dataset"}}