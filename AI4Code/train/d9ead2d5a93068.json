{"cell_type":{"9713b1ac":"code","24f90bef":"code","45277083":"code","73985a3f":"code","93befbd5":"code","923de6e1":"code","8782d59c":"code","c44afb91":"code","4b117ba1":"code","fcacab44":"code","2c92e5fd":"code","450ecb29":"code","b965d07f":"code","3e849452":"code","93f4b9e7":"code","19f58886":"code","1b6e6a57":"code","c0212bde":"code","c2364a5e":"code","04868df8":"code","c1e76661":"code","14fa7190":"code","0f2f3352":"code","a3241053":"code","04e5871d":"code","3c1be1bb":"code","68d28c4d":"code","afa93a3c":"code","d78b7ef2":"code","e24c314d":"code","4ee51a87":"code","76168ae7":"code","8411634f":"code","081a6d0c":"code","f91a62cc":"code","f8212e90":"code","1360ce4c":"code","5e4829f4":"code","be361a87":"code","14b5dd3a":"code","1d8c5d03":"code","0e23c1f4":"code","938849dd":"code","5b069978":"code","da3e9ca4":"code","a1131e03":"code","28ac08a2":"code","81d93004":"code","cef43931":"code","7d738166":"code","1cd25874":"code","87f1e3b6":"code","25f8637b":"code","4dfea519":"code","ea29e88e":"code","5242716c":"code","45199a59":"code","d50f3703":"code","518e86b9":"code","fbece159":"code","284cba0f":"markdown","210616c7":"markdown","b96203ed":"markdown","aa7de13e":"markdown","2557da0d":"markdown","fc531f47":"markdown","da740e79":"markdown","105d212c":"markdown","ed525eb4":"markdown","9193440b":"markdown","1554715a":"markdown","b984f135":"markdown","5a42700c":"markdown","ac3f96cf":"markdown","dd3dee59":"markdown","d2e0523a":"markdown","f9908414":"markdown","5366567d":"markdown","5e488de1":"markdown","59bfdd2b":"markdown","707ff7e1":"markdown","a248d863":"markdown","fdfaa2fc":"markdown","a36cc3eb":"markdown","e6f8289e":"markdown"},"source":{"9713b1ac":"import pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\nimport numpy as np\nimport os \nimport networkx as nx\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns \nfrom matplotlib import colors\nplt.figure(figsize=(10,10))\n\nfrom tqdm import tqdm_notebook as tqdm\n#from tqdm import tqdm\n%matplotlib inline","24f90bef":"print(os.listdir(\"\/kaggle\/\"))\ndata=pd.read_csv(\"..\/input\/ufcdata\/data.csv\")\ndata.head()","45277083":"for index,fight in data[::-1].iterrows():\n    if fight.Winner == \"Blue\":\n        break\nprint(\"The first\",len(data)-index,\"fights have been recorded as red wins\")        \nDataToDisplay=data[::-1]\ndisplay(DataToDisplay.head(10))\nprint(\"........................................................................\")\ndisplay(DataToDisplay[int(len(data)-index-10):int(len(data)-index)])","73985a3f":"data.describe()","93befbd5":"PrepropData=pd.read_csv(\"\/kaggle\/input\/ufcdata\/preprocessed_data.csv\")\nPrepropData.head()","923de6e1":"RawFighterDetails=pd.read_csv(\"\/kaggle\/input\/ufcdata\/raw_fighter_details.csv\")\nRawFighterDetails.head()","8782d59c":"print(\"The number of non nan Reach entries is\",len(list(RawFighterDetails[RawFighterDetails[\"Reach\"]!= float(\"nan\")])))\nprint(\"The number of non nan Stance entries is\",len(list(RawFighterDetails[RawFighterDetails[\"Stance\"]!= float(\"nan\")])))\nprint(\"The number of non nan DOB entries is\",len(list(RawFighterDetails[RawFighterDetails[\"DOB\"]!= float(\"nan\")])))\nprint(\"The total number of entries is \",len(RawFighterDetails[\"fighter_name\"]))","c44afb91":"RawTotalFightData=pd.read_csv(\"\/kaggle\/input\/ufcdata\/raw_total_fight_data.csv\",delimiter =\";\")\nRawTotalFightData.head()","4b117ba1":"data.dropna()\ndata.head()\n","fcacab44":"Data=data.join(RawTotalFightData,lsuffix=\"\",rsuffix=\"_raw\").copy()\nfor key in Data.keys():\n    if key[-4:] == \"_raw\":\n        print(key)\n        Data=Data.drop([str(key)],axis=1)\nprint(\"These are all duplicates or will give no indication of who is going to win the fight.\")\n        \nData[\"date_time\"]=pd.to_datetime(Data[\"date\"])\nData=Data.drop([\"date\"],axis=1)\nData=Data.sort_values([\"date_time\"],ascending=True)\n\n#there is some error in the way to data is recorded the first fight winners are all red\nData=Data.reset_index(drop=True)\nfor index,fight in Data.iterrows():\n    if fight.Winner == \"Blue\":\n        StartPoint=index\n        break\nData=Data[StartPoint:]\nData=Data.reset_index(drop=True)\ndisplay(Data)\nAllData=Data","2c92e5fd":"display(AllData.head(0))","450ecb29":"CorneredThingsToKeep=[\"fighter\",\"current_lose_streak\",\"current_win_streak\",\"wins\",\n                      \"losses\",\"draw\",\"age\",\"SIG_STR.\",\"TOTAL_STR.\",\"TD\",\"total_title_bouts\",\n                     \"win_by_KO\/TKO\",\"KD\",\"total_time_fought(seconds)\"]\n\nThingsToKeep=[\"Winner\",\"win_by\",\"last_round\",\"last_round_time\",\"date_time\"]\nfor thing in CorneredThingsToKeep:\n    ThingsToKeep.append(\"R_\"+thing)\n    ThingsToKeep.append(\"B_\"+thing)\nData=AllData[ThingsToKeep]\ndisplay(Data.head(1))","b965d07f":"def ConvertToLandedAttempted(DF,Feature):\n    for corner in [\"R_\",\"B_\"]:\n        try:\n            DF[[corner+Feature+\"_landed\",corner+Feature+\"_attempted\"]] = DF[corner+Feature].str.split(\" of \",expand=True)\n            for label in [corner+Feature+\"_landed\",corner+Feature+\"_attempted\"]:\n                DF[label]=pd.to_numeric(DF[label])\n            DF=DF.drop([corner+Feature],axis=1)\n        except:\n            pass\n    return DF\n\nFeaturesToSplit=[\"SIG_STR.\",\"TOTAL_STR.\",\"TD\"]\n    \nfor feat in FeaturesToSplit:\n    Data=ConvertToLandedAttempted(Data,feat)\n\nfor corner in [\"R_\",\"B_\"]:\n    try:\n        Data[corner+\"total_no._fights\"]=pd.to_numeric(Data[corner+\"draw\"]+Data[corner+\"wins\"]+Data[corner+\"losses\"])\n        Data=Data.drop([corner+\"draw\",corner+\"losses\"],axis=1)\n    except:\n        pass\n    \n    \nData.head().T","3e849452":"Data[(Data.R_fighter == \"Jon Jones\") | (Data.B_fighter == \"Jon Jones\")][[\"R_fighter\",\"B_fighter\",\"R_total_time_fought(seconds)\",\"B_total_time_fought(seconds)\",\"date_time\"]]","93f4b9e7":"Data=Data.drop([corner+\"_total_time_fought(seconds)\" for corner in [\"R\",\"B\"]],axis=1)","19f58886":"Data.head(2)","1b6e6a57":"# now lets create totals for all the revelevent factors\n\nCorneredThingsToKeep=[\"fighter\",\"current_lose_streak\",\"current_win_streak\",\"wins\",\n                      \"losses\",\"draw\",\"age\",\"SIG_STR.\",\"TOTAL_STR.\",\"TD\",\"total_title_bouts\",\n                     \"win_by_KO\/TKO\",\"KD\",\"total_time_fought(seconds)\"]\n\nThingsToKeep=[\"Winner\",\"win_by\",\"last_round\",\"last_round_time\",\"date_time\"]\n\nThingstoTotal=[\"SIG_STR.\",\"TOTAL_STR.\",\"TD\"]\n\nfor corner in [\"R_\",\"B_\"]:\n    for feature in ThingstoTotal:\n        for Type in [\"_attempted\",\"_landed\"]:\n            stat=corner+feature+Type\n            Data[stat+\"_total\"]=np.zeros(len(Data))\n            \n            \nfor index,fight in tqdm(Data.iterrows(),total=len(Data)):\n    for corner in [\"R_\",\"B_\"]:\n        for feature in ThingstoTotal:\n            for Type in [\"_attempted\",\"_landed\"]:\n                stat=corner+feature+Type\n                fighter=str(fight[corner+\"fighter\"])\n                \n                #find the index of the previou fight involving the fighter \n                PreviousFighterFights=Data[(Data.R_fighter == fighter) | (Data.B_fighter == fighter)]\n                PreviousFightsIndex=PreviousFighterFights[PreviousFighterFights.index < index].index\n                if len(PreviousFightsIndex)> 0:\n                    PrevIndex=PreviousFightsIndex[-1]\n                else:\n                    continue \n                PrevCorner=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                PrevStatLabel=PrevCorner+feature+Type\n                PrevTotal=Data[PrevStatLabel+\"_total\"][PrevIndex] \n                PrevStat=Data[PrevStatLabel][PrevIndex]\n                Data[stat+\"_total\"][index]=PrevTotal+PrevStat\n                \ndef TestIfWorking(Data,Features):\n    display(Data[(Data.R_fighter == \"Jon Jones\") | (Data.B_fighter == \"Jon Jones\")][[\"R_fighter\",\"B_fighter\",*Features]])\n                ","c0212bde":"def TestIfWorking(Data,Features):\n    display(Data[(Data.R_fighter == \"Jon Jones\") | (Data.B_fighter == \"Jon Jones\")][[\"R_fighter\",\"B_fighter\"]+Features])\n            \nTestIfWorking(Data,[corner+\"SIG_STR._attempted_total\" for corner in [\"R_\",\"B_\"]]+[corner+\"SIG_STR._attempted\" for corner in [\"R_\",\"B_\"]])            ","c2364a5e":"Data[\"last_round_time\"]=[int(minutes)*60 + int(seconds) for minutes,seconds in Data.last_round_time.str.split(\":\")]\nData.last_round=pd.to_numeric(Data.last_round)\nData[\"fight_time\"]=(Data.last_round-1)*60*5+Data.last_round_time\n\n\n#totalling the time\ndef TotalStat(Stats,Data,CornerDependence=True,Descriptor=\"\"):\n    if type(Stats)==str:\n        Stats=[Stats]\n    for stat in Stats:\n        for corner in [\"R_\",\"B_\"]:\n            try:\n                Data[corner+stat+Descriptor+\"_total\"]\n            except:\n                Data[corner+stat+Descriptor+\"_total\"]=np.zeros(len(Data))\n        for index,fight in tqdm(Data.iterrows(),total=len(Data),desc=\"Totaling \"+stat):\n            for corner in [\"R_\",\"B_\"]:\n                fighter=str(fight[corner+\"fighter\"])\n                PreviousFighterFights=Data[(Data.R_fighter == fighter) | (Data.B_fighter == fighter)]\n                PreviousFightsIndex=PreviousFighterFights[PreviousFighterFights.index < index].index\n                if len(PreviousFightsIndex)> 0:\n                    PrevIndex=PreviousFightsIndex[-1]\n                else:\n                    continue\n                if CornerDependence==True:\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    PrevCorner=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                elif CornerDependence==False:\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    PrevCorner=\"\"\n                elif CornerDependece == \"Reverse\":\n                    PrevCorner=\"B_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"R_\"\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                Data[corner+stat+Descriptor+\"_total\"][index]=Data[PrevCornerTotal+stat+Descriptor+\"_total\"][PrevIndex]+Data[PrevCorner+stat][PrevIndex]\n    return Data\n\n\n            \nData=TotalStat(\"fight_time\",Data,CornerDependence=False)\n\n\n\nTestIfWorking(Data,[corner+\"fight_time\"+\"_total\" for corner in [\"R_\",\"B_\"] ]+[\"fight_time\"])\n","04868df8":"#totaling the defensive stats\n\ndef TotalDefenceStat(Stats,Data,CornerDependence=\"Reverse\"):\n    if type(Stats)==str:\n        Stats=[Stats]\n    for stat in Stats:\n        for ending,Descriptor in [[\"_attempted\",\"_faced\"],[\"_landed\",\"_defended\"]]:\n            StatEnd=stat+ending\n            for corner in [\"R_\",\"B_\"]:\n                try:\n                    Data[corner+stat+Descriptor+\"_total\"]\n                except:\n                    Data[corner+stat+Descriptor+\"_total\"]=np.zeros(len(Data))\n            for index,fight in tqdm(Data.iterrows(),total=len(Data),desc=\"Totaling \"+stat):\n                for corner in [\"R_\",\"B_\"]:\n                    fighter=str(fight[corner+\"fighter\"])\n                    PreviousFighterFights=Data[(Data.R_fighter == fighter) | (Data.B_fighter == fighter)]\n                    PreviousFightsIndex=PreviousFighterFights[PreviousFighterFights.index < index].index\n                    if len(PreviousFightsIndex)> 0:\n                        PrevIndex=PreviousFightsIndex[-1]\n                    else:\n                        continue\n                    if CornerDependence==True:\n                        PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                        PrevCorner=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    elif CornerDependence==False:\n                        PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                        PrevCorner=\"\"\n                    elif CornerDependence == \"Reverse\":\n                        PrevCorner=\"B_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"R_\"\n                        PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    if Descriptor == \"_faced\":\n                        Data[corner+stat+Descriptor+\"_total\"][index]=Data[PrevCornerTotal+stat+Descriptor+\"_total\"][PrevIndex]+Data[PrevCorner+StatEnd][PrevIndex]\n                    else:\n                        Data[corner+stat+Descriptor+\"_total\"][index]=Data[PrevCornerTotal+stat+Descriptor+\"_total\"][PrevIndex]+(Data[PrevCorner+stat+\"_attempted\"][PrevIndex]-Data[PrevCorner+StatEnd][PrevIndex])\n    return Data\n\nFeatures=[stat for stat in [\"SIG_STR.\",\"TOTAL_STR.\",\"TD\"]]\n\n\n\n\n    \nData=TotalDefenceStat(Features,Data)\nTestIfWorking(Data,[key for key in Data.keys() if \"SIG_STR.\" in key])","c1e76661":"def TotalStat(Stats,Data,CornerDependence=True,Descriptor=\"\"):\n    if type(Stats)==str:\n        Stats=[Stats]\n    for stat in Stats:\n        for corner in [\"R_\",\"B_\"]:\n            try:\n                Data[corner+stat+Descriptor+\"_total\"]\n            except:\n                Data[corner+stat+Descriptor+\"_total\"]=np.zeros(len(Data))\n        for index,fight in tqdm(Data.iterrows(),total=len(Data),desc=\"Totaling \"+stat):\n            for corner in [\"R_\",\"B_\"]:\n                fighter=str(fight[corner+\"fighter\"])\n                PreviousFighterFights=Data[(Data.R_fighter == fighter) | (Data.B_fighter == fighter)]\n                PreviousFightsIndex=PreviousFighterFights[PreviousFighterFights.index < index].index\n                if len(PreviousFightsIndex)> 0:\n                    PrevIndex=PreviousFightsIndex[-1]\n                else:\n                    continue\n                if CornerDependence==True:\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    PrevCorner=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                elif CornerDependence==False:\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    PrevCorner=\"\"\n                elif CornerDependece == \"Reverse\":\n                    PrevCorner=\"B_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"R_\"\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                Data[corner+stat+Descriptor+\"_total\"][index]=Data[PrevCornerTotal+stat+Descriptor+\"_total\"][PrevIndex]+Data[PrevCorner+stat][PrevIndex]\n    return Data\n\n\nData=TotalStat(\"KD\",Data)\nTestIfWorking(Data,[key for key in Data.keys() if \"KD\" in key])","14fa7190":"#calculting the finnish probability for each fighter \n# we will do this by totaling number of finnishes and then dividing by total fight time\ndisplay(\"The different win_by options \",Data.win_by.unique())\n\ndef IsFinnish(DF,corner=\"Undefined\"):\n    CornerPrefix=\"R_\" if corner==\"Red\" else \"B_\"\n    if DF[\"Winner\"]==corner and DF[\"win_by\"] in ['KO\/TKO', 'Submission']:\n        return 1\n    return 0\n\nfor corner in [\"Red\",\"Blue\"]:        \n    Data[corner[0]+\"_finish\"]=Data.apply(IsFinnish,**{\"corner\":corner},axis=1)\n\nData=TotalStat(\"finish\",Data)\nTestIfWorking(Data,[key for key in Data.keys() if \"finish\" in key ])","0f2f3352":"Features=[]\nfor corner in [\"R_\",\"B_\"]:\n    for AttackForm in [\"SIG_STR.\",\"TOTAL_STR.\",\"TD\"]:\n        Data[corner+AttackForm+\"_probability\"]=Data[corner+AttackForm+\"_landed_total\"]\/Data[corner+AttackForm+\"_attempted_total\"]\n        Features.append(AttackForm+\"_probability\")\n        Data[corner+AttackForm+\"_defence_probability\"]=Data[corner+AttackForm+\"_defended_total\"]\/Data[corner+AttackForm+\"_faced_total\"]\n        Features.append(AttackForm+\"_defence_probability\")\n        Data[corner+AttackForm+\"_rate\"]=Data[corner+AttackForm+\"_attempted_total\"]\/Data[corner+\"fight_time\"+\"_total\"]\n        Features.append(AttackForm+\"_rate\")\n        \n    Data[corner+\"KD_rate\"]=Data[corner+\"KD\"+\"_total\"]\/Data[corner+\"fight_time\"+\"_total\"]\n    Features.append(\"KD_rate\")\n    \n    Data[corner+\"win_probability\"]=Data[corner+\"wins\"]\/Data[corner+\"total_no._fights\"]\n    Features.append(\"win_probability\")\n    \n    Data[corner+\"finish_rate\"]=Data[corner+\"finish_total\"]\/Data[corner+\"fight_time\"+\"_total\"]\n    Features.append(\"finish_rate\")\n    \n    Features+=[corner+factor for factor in [\"age\",\"total_no._fights\",\"total_title_bouts\",\"current_win_streak\",\"current_lose_streak\"]]\n","a3241053":"display(Data[-10:])","04e5871d":"Data=Data[~Data.win_by.isin([\"DQ\",\"TKO - Doctor's Stoppage\",\"Overturned\"])]\n\ndef BinaryWinner(DF):\n    if DF[\"Winner\"]==\"Red\":\n        return 1\n    elif DF[\"Winner\"]==\"Blue\":\n        return 0 \n    else:\n        return np.nan\nData[\"Winner\"]=Data.apply(BinaryWinner,axis=1)\nData.head()","3c1be1bb":"print(len(Data.dropna())*100.0\/len(Data),\"% of the fights don't have NaN in them\")\nprint(Data.Winner.mean()*100,\"% of the fights were won \")","68d28c4d":"FightNetwork=nx.MultiDiGraph()\nfor index,fight in tqdm(Data.iterrows(),total=len(Data)):\n    if fight.Winner == 1:\n        FightNetwork.add_edge(fight.B_fighter,fight.R_fighter,key=fight.date_time)\n    elif fight.Winner == 0:\n        FightNetwork.add_edge(fight.R_fighter,fight.B_fighter,key=fight.date_time)\nfig=plt.figure(figsize=(12,12),dpi=100)\nnx.draw(FightNetwork,pos=nx.spring_layout(FightNetwork,k=0.4),arrowsize=0.1,font_size=1,width=0.02,node_size=0,with_labels=True)\nfig.show()","afa93a3c":"Centralities=nx.katz_centrality(nx.DiGraph(FightNetwork),tol=0.001)","d78b7ef2":"%%time\nCentralities=nx.katz_centrality(nx.DiGraph(FightNetwork),tol=0.001)","e24c314d":"%%time\nCentralities=nx.katz_centrality(nx.DiGraph(FightNetwork),tol=0.001,alpha=0.1,beta=1)","4ee51a87":"def PrintScores(Scores,number):\n    for i in  sorted(Scores,key=Scores.get,reverse=True)[:number]:\n        print(i,Scores[i])\n\nPrintScores(Centralities,30)","76168ae7":"RedScores,BlueScores=[],[]\nRedFighters,BlueFighters=[],[]\nTotalCentralities=[]\nCententralities={}\n\nFightNetwork=nx.MultiDiGraph()\nSumCentralities=np.nan\nIndexes=list(Data.index)\nfor (index,fight),NextIndex in tqdm(zip(Data.iterrows(),Indexes[1:]),total=len(Data)-1):\n    try:\n        RedScores.append(Cententralities[fight.R_fighter])\n    except:\n        RedScores+=[np.median(RedScores) if len(RedScores)>0 else np.nan]\n    try:\n        BlueScores.append(Cententralities[fight.B_fighter])\n    except:\n        BlueScores+=[np.median(BlueScores) if len(BlueScores)>0 else np.nan]\n    \n    if fight.Winner == 1:\n        FightNetwork.add_edge(fight.B_fighter,fight.R_fighter,key=fight.date_time)\n    elif fight.Winner == 0:\n        FightNetwork.add_edge(fight.R_fighter,fight.B_fighter,key=fight.date_time)\n    \n    TotalCentralities.append(SumCentralities)    \n    if fight.date_time!=Data.date_time[NextIndex]:\n        Cententralities=nx.katz_centrality(nx.DiGraph(FightNetwork),tol=0.001,alpha=0.1,beta=1)\n        SumCentralities=np.sum(list(Cententralities.values()))\n\n\ntry:\n    RedScores.append(Cententralities[list(Data.R_fighter)[-1]])\nexcept:\n    RedScores+=[np.median(RedScores)]\ntry:\n    BlueScores.append(Cententralities[list(Data.B_fighter)[-1]])\nexcept:\n    BlueScores+=[np.median(BlueScores)]\n\nTotalCentralities.append(TotalCentralities[-1])\n    \nData[\"R_centrality\"]=RedScores\nData[\"B_centrality\"]=BlueScores\nData[\"total_centrality\"]=TotalCentralities\n  \n    ","8411634f":"Data[\"total_centrality\"].describe()","081a6d0c":"print(\"The first 10 non NaN maximum centrality scores are:\")\ncount=0\nfor index,fight in Data.iterrows():\n    if fight.R_centrality >0 or fight.B_centrality > 0:\n        print(np.nanmax([fight.R_centrality,fight.B_centrality]))\n        count+=1\n        if count == 10:\n            break\n            \nprint(\"\\nThe last 10 maximum centrality scores are:\")\ncount=0\nfor index,fight in Data[::-1].iterrows():\n    if fight.R_centrality >0 or fight.B_centrality > 0:\n        print(np.nanmax([fight.R_centrality,fight.B_centrality]))\n        count+=1\n        if count == 10:\n            break\n            \nprint(\"\\nThe maximum centrality is\",np.nanmax(list(Data.R_centrality)+list(Data.B_centrality)))","f91a62cc":"import random\nCententralities=nx.katz_centrality(nx.DiGraph(FightNetwork),tol=0.001,alpha=0.1,beta=1)\n\n# R_SIG_STR._attempted is just a random thing to plot against \nCentralititesData=Data[[\"R_fighter\",\"B_fighter\",\"Winner\",\"R_SIG_STR._attempted\"]]\n\nCentralititesData[\"R_centrality\"]=[Cententralities[fighter] if fighter in Cententralities.keys() else np.median(list(Cententralities.values())) for fighter in list(CentralititesData[\"R_fighter\"])]\nCentralititesData[\"B_centrality\"]=[Cententralities[fighter] if fighter in Cententralities.keys() else np.median(list(Cententralities.values())) for fighter in list(CentralititesData[\"B_fighter\"])]\nCentralititesData[\"centrality_difference\"]=(CentralititesData[\"R_centrality\"]-CentralititesData[\"B_centrality\"])\/(CentralititesData[\"R_centrality\"]+CentralititesData[\"B_centrality\"])\n\nWinners=list(CentralititesData[\"Winner\"])\ncols=[\"b\",\"r\"]\nwinner=[0.0,1.0]\nColors=[cols[winner.index(x)] if x in [0.0,1.0] else random.choice(cols) for x in Winners]\nplt.scatter(CentralititesData[\"centrality_difference\"],CentralititesData[\"R_SIG_STR._attempted\"],color=Colors,alpha=0.1)\nplt.xlabel(\"Centrality Difference\")\nplt.ylabel(\"Red Fighter's Number of Attempted Strikes\")\n\nplt.show()","f8212e90":"Data[\"centrality_difference\/total\"] = (Data[\"R_centrality\"] - Data[\"B_centrality\"])\/Data[\"total_centrality\"]\nData[\"centrality_difference\/product\"] = (Data[\"R_centrality\"] - Data[\"B_centrality\"])\/(Data[\"R_centrality\"]*Data[\"B_centrality\"])\n\nFeatures=[]\nfor AttackForm in [\"SIG_STR.\",\"TOTAL_STR.\",\"TD\"]:\n    Features.append(AttackForm+\"_probability\")\n    Features.append(AttackForm+\"_defence_probability\")\n    Features.append(AttackForm+\"_rate\")\nFeatures.append(\"KD_rate\")\nFeatures.append(\"win_probability\")\nFeatures.append(\"finish_rate\")\nFeatures+=[factor for factor in [\"age\",\"total_no._fights\",\"total_title_bouts\",\"current_win_streak\",\"current_lose_streak\"]]\nFeatures=[corner+feat for corner in [\"R_\",\"B_\"] for feat in Features]\nFeatures+=[\"R_centrality\",\"B_centrality\",\"centrality_difference\/total\",\"centrality_difference\/product\"]\nprint(Features)","1360ce4c":"import seaborn as sns \nStuffToPlot=Data[Features+[\"Winner\"]].fillna(Data[Features+[\"Winner\"]].median())\nPairPlot=sns.pairplot(Data[Features+[\"Winner\"]],hue=\"Winner\",palette={1:\"r\",0:\"b\"},plot_kws={\"alpha\":0.03})\n","5e4829f4":"#ELR = estimated landing rate\nELRFeatures=[\"TD\",\"SIG_STR.\",\"TOTAL_STR.\"]\n\nNewFeatures=[]\nCorners=[\"R_\",\"B_\"]\nfor feature in ELRFeatures:\n    for corner in Corners:\n        OtherCorner=Corners[Corners.index(corner)-1]\n        NewFeature=corner+feature+\"_ELR\"  \n        Start=corner+feature #  prob of landing     prob of not defending                                rate of attempts\n        Data[NewFeature]=Data[Start+\"_probability\"]*(1-Data[OtherCorner+feature+\"_defence_probability\"])*Data[Start+\"_rate\"]\n        NewFeatures.append(NewFeature)\n        \nELRFeatures=NewFeatures \n","be361a87":"import seaborn as sns \n\nDataToPlot=Data[Data[\"R_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[DataToPlot[\"B_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[NewFeatures+[\"Winner\"]]\nDataToPlot=DataToPlot.dropna()\nprint(len(DataToPlot))\n\nStuffToPlot=DataToPlot\nPairPlot=sns.pairplot(DataToPlot,hue=\"Winner\",palette={1:\"r\",0:\"b\"},plot_kws={\"alpha\":0.01})","14b5dd3a":"ELRDifferenceFeatures=[]\nfor feature in [\"TD\",\"SIG_STR.\",\"TOTAL_STR.\"]: \n    NewFeature=feature+\"_ELR_difference\"\n    Data[NewFeature]=(Data[\"R_\"+feature+\"_ELR\"]-Data[\"B_\"+feature+\"_ELR\"])\/(Data[\"R_\"+feature+\"_ELR\"]+Data[\"B_\"+feature+\"_ELR\"])\n    ELRDifferenceFeatures.append(NewFeature)\n    ","1d8c5d03":"DataToPlot=Data[Data[\"R_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[DataToPlot[\"B_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[ELRDifferenceFeatures+[\"Winner\"]]\nDataToPlot=DataToPlot.dropna()\n\nDataToPlot=DataToPlot[ELRDifferenceFeatures+[\"Winner\"]]\nprint(len(DataToPlot))\n\n\nPairPlot=sns.pairplot(DataToPlot,hue=\"Winner\",palette={1:\"r\",0:\"b\"},plot_kws={\"alpha\":0.05})\n","0e23c1f4":"DataToPlot=Data[ELRDifferenceFeatures+[\"Winner\"]]\nDataToPlot=DataToPlot.dropna()\nprint(len(DataToPlot))\n\nPairPlot=sns.pairplot(DataToPlot,hue=\"Winner\",palette={1:\"r\",0:\"b\"},plot_kws={\"alpha\":0.05})","938849dd":"def TotalStat(Stats,Data,CornerDependence=True,Descriptor=\"\"):\n    if type(Stats)==str:\n        Stats=[Stats]\n    for stat in Stats:\n        for corner in [\"R_\",\"B_\"]:\n            try:\n                Data[corner+stat+Descriptor+\"_total\"]\n            except:\n                Data[corner+stat+Descriptor+\"_total\"]=np.zeros(len(Data))\n        for index,fight in tqdm(Data.iterrows(),total=len(Data),desc=\"Totaling \"+stat):\n            for corner in [\"R_\",\"B_\"]:\n                fighter=str(fight[corner+\"fighter\"])\n                PreviousFighterFights=Data[(Data.R_fighter == fighter) | (Data.B_fighter == fighter)]\n                PreviousFightsIndex=PreviousFighterFights[PreviousFighterFights.index < index].index\n                if len(PreviousFightsIndex)> 0:\n                    PrevIndex=PreviousFightsIndex[-1]\n                else:\n                    continue\n                if CornerDependence==True:\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    PrevCorner=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                elif CornerDependence==False:\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    PrevCorner=\"\"\n                elif CornerDependece == \"Reverse\":\n                    PrevCorner=\"B_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"R_\"\n                    PrevCornerTotal=\"R_\" if Data[\"R_fighter\"][PrevIndex] == fighter else \"B_\"\n                    \n                PrevStat=Data[PrevCorner+stat][PrevIndex] if not np.isnan(Data[PrevCorner+stat][PrevIndex]) else 0\n                PrevTotal=Data[PrevCornerTotal+stat+Descriptor+\"_total\"][PrevIndex] if not np.isnan(Data[PrevCornerTotal+stat+Descriptor+\"_total\"][PrevIndex]) else 0\n            \n                Data[corner+stat+Descriptor+\"_total\"][index]=PrevTotal+PrevStat\n    return Data\n\n\nAttackForms=[\"SIG_STR.\",\"TOTAL_STR.\",\"TD\"]\n\nfor index,corner in enumerate([\"R_\",\"B_\"]):\n    OtherCorner=[\"R_\",\"B_\"][index-1]\n    for attack in AttackForms:\n        Data[corner+attack+\"_weighted_landed\"]=Data[OtherCorner+attack+\"_defence_probability\"]*Data[corner+attack+\"_landed\"]\n\nWeightedLanded=[attack+\"_weighted_landed\" for attack in AttackForms]\n\nData=TotalStat(WeightedLanded,Data)\n\nWeightedProbs=[]\nfor corner in [\"R_\",\"B_\"]:\n    for attack in AttackForms:\n        Data[corner+attack+\"_weighted_probability\"]=Data[corner+attack+\"_weighted_landed_total\"]\/(Data[corner+attack+\"_attempted_total\"]+0.0000000001)\n        WeightedProbs.append(corner+attack+\"_weighted_probability\")\n\nData.replace({feature:0.0 for feature in WeightedProbs},np.nan)\n    \ndef TestIfWorking(Data,Features):\n    display(Data[(Data.R_fighter == \"Jon Jones\") | (Data.B_fighter == \"Jon Jones\")][[\"R_fighter\",\"B_fighter\",*Features]])\n\n    \nTestIfWorking(Data,[key for key in list(Data.keys()) if \"SIG_STR.\" in str(key)])","5b069978":"DataToPlot=Data\nDataToPlot=DataToPlot[DataToPlot[\"R_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[DataToPlot[\"B_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[[corner + x + \"_weighted_probability\" for x in AttackForms for corner in [\"R_\",\"B_\"]]+[\"Winner\"]]\n\nfor feature in [corner + x + \"_weighted_probability\" for x in AttackForms for corner in [\"R_\",\"B_\"]]:\n    DataToPlot[DataToPlot[feature] != 0]\nDataToPlot=DataToPlot.dropna()\n\nprint(\"plot for\",len(DataToPlot),\"fights\")\n\n\nPairPlot=sns.pairplot(DataToPlot,hue=\"Winner\",palette={1:\"r\",0:\"b\"},plot_kws={\"alpha\":0.05})\n","da3e9ca4":"for attack in AttackForms:\n    Data[attack+\"_weighted_probability_difference\"]=(Data[\"R_\"+attack+\"_weighted_probability\"]-Data[\"B_\"+attack+\"_weighted_probability\"])\/(Data[\"R_\"+attack+\"_weighted_probability\"]+Data[\"B_\"+attack+\"_weighted_probability\"])","a1131e03":"DataToPlot=Data\nDataToPlot=DataToPlot[DataToPlot[\"R_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[DataToPlot[\"B_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[[attack+\"_weighted_probability_difference\" for attack in AttackForms]+[\"Winner\"]]\n\nfor feature in [attack+\"_weighted_probability_difference\" for attack in AttackForms]:\n    DataToPlot=DataToPlot[DataToPlot[feature] != 0]\n\nDataToPlot=DataToPlot.dropna()\nprint(\"plot for\",len(DataToPlot),\"fights\")\n\n\nPairPlot=sns.pairplot(DataToPlot,hue=\"Winner\",palette={1:\"r\",0:\"b\"},plot_kws={\"alpha\":0.05})\n","28ac08a2":"Corners=[\"R_\",\"B_\"]\nfor feature in [\"TD\",\"SIG_STR.\",\"TOTAL_STR.\"]:\n    for corner in Corners:\n        OtherCorner=Corners[Corners.index(corner)-1]\n        Data[corner+feature+\"_weighted_ELR\"]=Data[corner+feature+\"_weighted_probability\"]*(1-Data[OtherCorner+feature+\"_defence_probability\"])*Data[corner+feature+\"_rate\"]\n\nFeaturesToPlot=[]\nfor feature in [\"TD\",\"SIG_STR.\",\"TOTAL_STR.\"]:\n    Data[feature+\"_weighted_ELR_difference\"]=(Data[\"R_\"+feature+\"_weighted_ELR\"]-Data[\"B_\"+feature+\"_weighted_ELR\"])\/(Data[\"R_\"+feature+\"_weighted_ELR\"]+Data[\"B_\"+feature+\"_weighted_ELR\"])\n    FeaturesToPlot.append(feature+\"_weighted_ELR_difference\")\n\nData[\"centrality_difference\/total\"] = (Data[\"R_centrality\"] - Data[\"B_centrality\"])\/(Data[\"R_centrality\"] + Data[\"B_centrality\"])\nData[\"centrality_difference\/product\"] = (Data[\"R_centrality\"] - Data[\"B_centrality\"])\/(Data[\"R_centrality\"]*Data[\"B_centrality\"])\n","81d93004":"import seaborn as sns\n\nDataToPlot=Data\nDataToPlot=DataToPlot[DataToPlot[\"R_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[DataToPlot[\"B_total_no._fights\"] > 3]\nDataToPlot=DataToPlot[FeaturesToPlot+[\"Winner\"]]\n\n\nDataToPlot=DataToPlot.dropna()\nprint(\"plot for\",len(DataToPlot),\"fights\")\n\nPairPlot=sns.pairplot(DataToPlot,hue=\"Winner\",palette={1:\"r\",0:\"b\"},plot_kws={\"alpha\":0.05})","cef43931":"import pandas as pd\nimport numpy as np \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\n\nFeatures=[]\nfor AttackForm in [\"SIG_STR.\",\"TOTAL_STR.\",\"TD\"]:\n    Features.append(AttackForm+\"_probability\")\n    Features.append(AttackForm+\"_defence_probability\")\n    Features.append(AttackForm+\"_rate\")\nFeatures.append(\"KD_rate\")\nFeatures.append(\"win_probability\")\nFeatures.append(\"finish_rate\")\nFeatures+=[factor for factor in [\"age\",\"total_no._fights\",\"total_title_bouts\",\"current_win_streak\",\"current_lose_streak\",\"centrality\"]]\nFeatures=[corner+feat for corner in [\"R_\",\"B_\"] for feat in Features]\nfor AttackForm in [\"SIG_STR.\",\"TOTAL_STR.\",\"TD\"]:\n    Features.append(AttackForm+\"_ELR_difference\")\nFeatures.append(\"centrality_difference\/total\")\nFeatures.append(\"centrality_difference\/product\")\n\nDataToUse=Data\nDataToUse=DataToUse[DataToUse[\"R_total_no._fights\"] > 3 ]\nDataToUse=DataToUse[DataToUse[\"B_total_no._fights\"] > 3 ]\nDataToUse=DataToUse[Features+[\"Winner\"]]\nDataToUse=DataToUse.dropna()\nprint(\"We have data for\",len(DataToUse),\"fights\")\nTransformData=StandardScaler()\n\nContinue=True\nwhile Continue:\n    TrainX,TestX,TrainY,TestY=train_test_split(DataToUse[Features].copy(),DataToUse[\"Winner\"].copy(),test_size=0.25)\n    if 0.99<np.mean(TrainY)\/np.mean(TestY)<1.01:\n        Continue=False\n\nprint(\"Red wins\",np.mean(TrainY)*100,\"% of the training fights\")\nprint(\"Red wins\",np.mean(TestY)*100,\"% of the test fights\")\nTransformData.fit_transform(TrainX)\nTransformData.transform(TestX)\n\n","7d738166":"parameters = {'kernel':['rbf'], 'C':[0.2,0.3,0.4,0.5]}\nprint(\"For a rbf SVC\")\nModel=SVC(gamma=\"auto\")\nModelTuner = GridSearchCV(Model,parameters,n_jobs=-1,cv=5,scoring=\"accuracy\")\nModelTuner.fit(TrainX,TrainY)\nprint(\"We get an accuracy of\",ModelTuner.score(TrainX,TrainY),\"on the training set\")\nprint(\"We get an accuracy of \",ModelTuner.score(TestX,TestY),\"on the test set\\n\")\nprint(\"With hyper paremetres of\",ModelTuner.best_estimator_.get_params())","1cd25874":"print(\"For a polynomial SVC of degree 2\")\nModel=SVC(gamma=\"auto\")\nparameters = {'kernel':[\"poly\"],\"degree\":[2], 'C':[0.1,0.3,0.7,0.9,0.5,1]}\nModelTuner = GridSearchCV(Model,parameters,n_jobs=-1,cv=5,scoring=\"accuracy\")\nModelTuner.fit(TrainX,TrainY)\nprint(\"We get an accuracy of\",ModelTuner.score(TrainX,TrainY),\"on the training set\")\nprint(\"We get an accuracy of \",ModelTuner.score(TestX,TestY),\"on the test set\\n\")\nprint(\"With hyper paremetres of\",ModelTuner.best_estimator_.get_params())","87f1e3b6":"print(\"For a linear SVC\")\nModel=SVC(gamma=\"auto\")\nparameters = {'kernel':[\"linear\"], 'C':[1,3,5,7,10]}\nModelTuner = GridSearchCV(Model,parameters,n_jobs=-1,cv=5,scoring=\"accuracy\")\nModelTuner.fit(TrainX,TrainY)\nprint(\"We get an accuracy of\",ModelTuner.score(TrainX,TrainY),\"on the training set\")\nprint(\"We get an accuracy of \",ModelTuner.score(TestX,TestY),\"on the test set\\n\")\nprint(\"With hyper paremetres of\",ModelTuner.best_estimator_.get_params())","25f8637b":"print(\"For a Random Forrest\")\nModel=RandomForestClassifier(n_jobs=-1)\nparameters = {'n_estimators':[100,200,300,1000],\"max_depth\":[None,200,120,100,80,10],\"bootstrap\":[False]}\nModelTuner = GridSearchCV(Model,parameters,n_jobs=-1,cv=5,scoring=\"accuracy\")\nModelTuner.fit(TrainX,TrainY)\nprint(\"We get an accuracy of\",ModelTuner.score(TrainX,TrainY),\"on the training set\")\nprint(\"We get an accuracy of \",ModelTuner.score(TestX,TestY),\"on the test set\\n\")\nprint(\"With hyper paremetres of\",ModelTuner.best_estimator_.get_params())","4dfea519":"print(\"For KNN\")\nModel=KNeighborsClassifier()\nparameters = {'n_neighbors':[4,5,7,8],\"weights\":[\"uniform\",\"distance\"]}\nModelTuner = GridSearchCV(Model,parameters,n_jobs=-1,cv=5,scoring=\"accuracy\")\nModelTuner.fit(TrainX,TrainY)\nprint(\"We get an accuracy of\",ModelTuner.score(TrainX,TrainY),\"on the training set\")\nprint(\"We get an accuracy of \",ModelTuner.score(TestX,TestY),\"on the test set\\n\")\nprint(\"With hyper paremetres of\",ModelTuner.best_estimator_.get_params())","ea29e88e":"print(\"For Logistic Regression\")\nModel=LogisticRegression(max_iter=1000000000,tol=0.00001)\nparameters = {'penalty':[\"l1\",\"l2\"],\"C\":[0.01,0.1,0.2,0.33,1.0]}\nModelTuner = GridSearchCV(Model,parameters,n_jobs=-1,cv=5,scoring=\"accuracy\")\nModelTuner.fit(TrainX,TrainY)\nprint(\"We get an accuracy of\",ModelTuner.score(TrainX,TrainY),\"on the training set\")\nprint(\"We get an accuracy of \",ModelTuner.score(TestX,TestY),\"on the test set\\n\")\nprint(\"With hyper paremetres of\",ModelTuner.best_estimator_.get_params())","5242716c":"import tensorflow as tf\n#from tensorflow.keras import backend.tensorflow_backend.set_session \nfrom tensorflow import keras\n           \nTrainX = np.array(TrainX.astype(\"float64\"))\nTestX = np.array(TestX.astype(\"float64\"))\n\nTrainY = np.array(TrainY.astype(\"float64\"))\nTestY = np.array(TestY.astype(\"float64\"))\n","45199a59":"  \nOptimiser=keras.optimizers.SGD(learning_rate=0.00006,momentum=0.7)\n\nModel=keras.Sequential()\nModel.add(keras.layers.Dense(32,input_dim=int(np.shape(TrainX)[1]),activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n\nModel.compile(loss=\"binary_crossentropy\",optimizer=Optimiser,metrics=[\"accuracy\"])\nHistory=Model.fit(TrainX,TrainY,batch_size=60,epochs=4000,validation_data=(TestX,TestY),verbose=0)","d50f3703":"def MovingAverage(a, n=10) :\n    ret = np.cumsum(a, dtype=float)\n    ret[n:] = ret[n:] - ret[:-n]\n    MovAv=list(a[:n-1])+list(ret[n - 1:] \/ n)\n    return MovAv\n\nXaxis=range(0,len(History.history[\"accuracy\"]),10)\nYAcc=MovingAverage(History.history[\"accuracy\"][::10])\nYValAcc=MovingAverage(History.history[\"val_accuracy\"][::10])\nplt.plot(Xaxis,YAcc,label=\"Train set\")\nplt.plot(Xaxis,YValAcc,label= \"Test set\")\nplt.grid(linestyle=\"-.\")\n\nplt.legend()\nplt.show()    \n\nprint(\"Red wins\",np.mean(TrainY),\"% and\",np.mean(TestY),\"% of the training and test fights respectivly\")\nprint(\"The max accurcy on the test set is\",np.max(History.history[\"val_accuracy\"]))","518e86b9":"Optimiser=keras.optimizers.SGD(learning_rate=0.00004,momentum=0.7)\n\nModel=keras.Sequential()\nModel.add(keras.layers.Dense(32,input_dim=np.shape(TrainX)[1],activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(32,activation='elu'))\nModel.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n\nModel.compile(loss=\"binary_crossentropy\",optimizer=Optimiser,metrics=[\"accuracy\"])\n\n\nBigNetHistory=Model.fit(TrainX,TrainY,batch_size=60,epochs=4000,validation_data=(TestX,TestY),verbose=0)","fbece159":"Xaxis=range(0,len(BigNetHistory.history[\"accuracy\"]),10)\n\nYAcc=MovingAverage(BigNetHistory.history[\"accuracy\"][::10])\nYValAcc=MovingAverage(BigNetHistory.history[\"val_accuracy\"][::10])\n\nplt.plot(Xaxis,YAcc,label=\"Train Set\")\nplt.plot(Xaxis,YValAcc,label=\"Test Set\")\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.grid(linestyle=\"-.\")\nplt.show()    \n\nprint(\"Red wins\",np.mean(TrainY),\"% and\",np.mean(TestY),\"% of the training and test fights respectivly\")\nprint(\"The max accurcy on the test set is\",np.max(BigNetHistory.history[\"val_accuracy\"]))","284cba0f":"Lets see if the centralities have any validity for predicting the outcome fights. I will use the full fight network too see how well the centralities predict the result of historical fights. This is representitive how the scores could be used to in reality as we cannot use the future to predict the past.  ","210616c7":"One method to find the best parameters for Katz centrality is to use gradient descent to maximize the accuracy of a linear SVM trained only on the Katz centrality features. This may be attempted at a later date. A computaitionaly less intensive approach would be to maximise the difference between the mean centrality scores for red wins and blue wins. ","b96203ed":"These weighted takedown ELRs don't appear to be as predictive as the standard ELRs so for now we will just train the models on those. ","aa7de13e":"Unfortunately the data does not appear to be very separable. We could reduce the dimensionality of the data by changing all the features to differences between the red corner and blue corner over the sum of both. The data still doesn't appear very separable lets try and make some more predictive features such as: \n\n**Reach Difference** The difference in reach between the two fighters against divided by the sum of the reaches. To be made later. ","2557da0d":"Reach,Stance and DOB will not be used from this data","fc531f47":"**Expected Landing Rate for each Attack Form** for a given attack form $a$ given by\n$$ a_p(1-a^{opp}_{dp})a_r .$$ Where $a_p$ is the previously discussed probability of fighter landing a strike based their historical fights. $a^{opp}_{dp}$ is the probability of the opposition fighter defending the attack form. Finally $a_r$ is the rate the fighter attempts this attack form. The theoretical motivation for this feature is it is equal rate the fighter lands the attack form multiplied by the probability of the opposition fighter not defending the attack form. This is not actually the expected landing rate for a given attack form but can be considered related to it. This will be calculated for the three attack forms strikes, significant strikes and takedowns. \n\nAn alternative approach would be to create two features:\n$$ a_r\\frac{a_p}{a_p + a^{opp}_{dp}} \\,\\,\\,\\,\\,\\, \\& \\,\\,\\,\\,\\,\\, \\frac{a^{opp}_{dp}}{a_p + a^{opp}_{dp}} .$$ Here the fractions (probabilities?) total one like they would in reality.","da740e79":"First lets adjust our columns to give total numbers of strikes,takedowns etc.","105d212c":"The centralities separate the fights well if we use the most the up to date fight network now lets see if they area as predictive if we only use historical data. ","ed525eb4":"## Feature Engineering and Exploratory Data Analysis\nLets join the raw data processed data together first so we decide what features to use and construct. ","9193440b":"Lets also look at the difference between the ELRs.","1554715a":"The graphs appear to cross around 64% so after that I would expect the test score to decrease due to overtraining. This appears to be around the best accuracy we can get for traditional supervised learning models, $\\approx$64%. \n\nFurther algorithms that could be attempted are gradient boosting methods. ","b984f135":"It will be best to fill the NaNs in with medians. We will also remove fights that where won by (win_by in the Data Frame)  disqualification (DQ), doctors stoppage (TKO - Doctor's Stoppage), and if the decision is overturned (Overturned). These fights can be considered anomalous. Then we will set (Winner) to 1 if red wins and 0 if blue wins. The can train some algorithms before calculating centrality scores for the fighters.  ","5a42700c":"Now we will crate total fight time so we can calculate the rates. ","ac3f96cf":"Total fight time isn't working so lets drop it.","dd3dee59":"\n# Predicting the winner of UFC fights \n<span style=\"color:red\">Rough copy, I am currently working on this offline and will upload when I have finnished it.<\/span>\n\nThe goal of this project is to create a machine learing model that predicts the winner of ufc fights. UFC fights are incredibly hard to predict, fighters only tend to fight eachother if they are seen ass being about as good as each other, fighters rarely if ever fight someone they are confident they can beat unlike in boxing. This makes predicting the out come of UFC fights very difficult to predict. The UFC places the favoured fighter or the champion of the weight division in the red corner, they are right about the victor only 57% of time. Below is a description of the data that came with the data, which cam be found at https:\/\/www.kaggle.com\/rajeevw\/ufcdata. Unfortunately a lot of the data has been recorded\/scraped incorrectly, the first one thousand fights all have the red corner winning. Most people who have used this data set on kaggle did not notice this as result there models could achieve an accuracy of 67% by just guessing Red wins every time.\n\nBelow is some information that cam with the data.\n\n### Context\nThis is a list of every UFC fight in the history of the organisation. Every row contains information about both fighters, fight details and the winner. The data was scraped from ufcstats website. After fightmetric ceased to exist, this came into picture. I saw that there was a lot of information on the website about every fight and every event and there were no existing ways of capturing all this. I used beautifulsoup to scrape the data and pandas to process it. It was a long and arduous process, please forgive any mistakes. I have provided the raw files in case anybody wants to process it differently. This is my first time creating a dataset, any suggestions and corrections are welcome! In case anyone wants to check out the work, I have all uploaded all the code files, including the scraping module here\n\nHave fun!\n\n### Content\nEach row is a compilation of both fighter stats. Fighters are represented by 'red' and 'blue' (for red and blue corner). So for instance, red fighter has the complied average stats of all the fights except the current one. The stats include damage done by the red fighter on the opponent and the damage done by the opponent on the fighter (represented by 'opp' in the columns) in all the fights this particular red fighter has had, except this one as it has not occured yet (in the data). Same information exists for blue fighter. The target variable is 'Winner' which is the only column that tells you what happened. Here are some column definitions:\n\n### Column definitions:\n\n|Column name  |Description |\n|-----|-------------|\n|R_ and B_ |prefix signifies red and blue corner fighter stats respectively|\n|_opp_ | containing columns is the average of damage done by the opponent on the fighter|\n|KD |is number of knockdowns|\n|SIG_STR |is no. of significant strikes 'landed of attempted'|\n|SIG_STR_pct |is significant strikes percentage|\n|TOTAL_STR |is total strikes 'landed of attempted'|\n|TD |is no. of takedowns|\n|TD_pct |is takedown percentages|\n|SUB_ATT |is no. of submission attempts|\n|PASS |is no. times the guard was passed?|\n|REV |*Probably reversels*|\n|HEAD |is no. of significant strinks to the head 'landed of attempted'|\n|BODY |is no. of significant strikes to the body 'landed of attempted'|\n|CLINCH |is no. of significant strikes in the clinch 'landed of attempted'|\n|GROUND |is no. of significant strikes on the ground 'landed of attempted'|\n|win_by |is method of win|\n|last_round |is last round of the fight (ex. if it was a KO in 1st, then this will be 1)|\n|last_round_time |is when the fight ended in the last round|\n|Format |is the format of the fight (3 rounds, 5 rounds etc.)|\n|Referee |is the name of the Ref|\n|date |is the date of the fight|\n|location |is the location in which the event took place|\n|Fight_type |is which weight class and whether it's a title bout or not|\n|Winner |is the winner of the fight|\n|Stance |is the stance of the fighter (orthodox, southpaw, etc.)|\n|Height_cms |is the height in centimeter|\n|Reach_cms |is the reach of the fighter (arm span) in centimeter|\n|Weight_lbs |is the weight of the fighter in pounds (lbs)|\n|age |is the age of the fighter|\n|title_bout |Boolean value of whether it is title fight or not|\n|weight_class |is which weight class the fight is in (Bantamweight, heavyweight, Women's flyweight, etc.)|\n|no_of_rounds |is the number of rounds the fight was scheduled for|\n|current_lose_streak |is the count of current concurrent losses of the fighter|\n|current_win_streak |is the count of current concurrent wins of the fighter|\n|draw |is the number of draws in the fighter's ufc career|\n|wins |is the number of wins in the fighter's ufc career|\n|losses |is the number of losses in the fighter's ufc career|\n|total_rounds_fought |is the average of total rounds fought by the fighter|\n|total_time_fought(seconds) |is the count of total time spent fighting in seconds|\n|total_title_bouts |is the total number of title bouts taken part in by the fighter|\n|win_by_Decision_Majority |is the number of wins by majority judges decision in the fighter's ufc career|\n|win_by_Decision_Split |is the number of wins by split judges decision in the fighter's ufc career|\n|win_by_Decision_Unanimous |is the number of wins by unanimous judges decision in the fighter's ufc career|\n|win_by_KO\/TKO |is the number of wins by knockout in the fighter's ufc career|\n|win_by_Submission |is the number of wins by submission in the fighter's ufc career|\n|win_by_TKO_Doctor_Stoppage |is the number of wins by doctor stoppage in the fighter's ufc career|\n|avg         | average over number of rounds in the fight |\n\n","d2e0523a":"Clearly the centrality for early fights is large compared to later fights. To try and account for this I will consider the difference between centralities (Red-Blue) over the sum of them and another feature with the difference over the product.","f9908414":"It takes a long time to calculate the centrality scores so instead of recalculating after every fight we will train for all fights on the same day. ","5366567d":"It makes sens to split randomly to reduce the bias. The UFC puts the favoured fighter in the Red corner and it seems they may have changed how they decide who is the favoured fighter. We appear to get better results when we replace NaNs with median as well. Most of the NaNs occur for a fighters first fight as they we have we don't have any data for them in previous fights. All models all less accurate or only marginally more accurate than guessing red for every fight. Now I will construct networks of all the fights and calculate the centralities of the networks. ","5e488de1":"The first thing I will show is that for around the first thousand or so fights (chronologically) all the victors have been recorded scraped as fighting in the Red corner. Other kaggle users who have used this data set failed to notice this. ","59bfdd2b":"Now we can construct all our features.","707ff7e1":"We will use the data frame above to calculate the features for all the fights. We will calculate historical features about each fighter. Such as:\n\n* **Probability of landing a significant strike**. This will be the number of significant strikes a fighter has landed over the number they have thrown.\n* **Significant strike rate.** The rate at which a fighter attempts to land significant strikes. Preferably per second but could be given per round if necessary.\n* **Probability of landing a strike**\n* **Strike Rate**\n* **Probability of landing a takedown.** A takedown is where one fighter wrestles the other fighter to the ground.\n* **Takedown attempt rate.**\n* **Takedown,Significant Strike and Strike defence probability**. The probability of defending the attack method based on historical fights.  \n* **Knock down rate**. A knock down is when one fighter knocks anther one down with a strike. \n* **Win probability**\n* **total number of fights**\n* **Age**\n* **How many title bouts the fighter has been in**\n* **Network Centrality.** A network will be constructed using networkx and the an eigenvector centrality score score will be calculated for every fighter, we will start with katz centrality but may use some others later like PageRank. We will begin with creating a network for all the fighters and one for each weight class. For a fight we will consider each fighters score for the network of all fighters and their score in the weight class of the fights. \n* **Finnish rate**. In MMA finishing an opponent is when one fighter knocks out or taps out an opponent. Clearly a fighter has knocked out every opponent they have faced in the first round they are good fighter. This feature will be number of finishes over total fight time.\n* **Current loss streak**\n* **Current win streak** \n\n\nFor training and testing it makes sense to split the fights chronologically rather than randomly. Training the algorithms on the oldest fights and testing them on more recent ones. \n\nSome other features we may include later are:\n* **Reach difference**  A fighters reach is the distance between their fingertips when they hold the arms apart and parallel to the ground. Reach can approximate the distance a fighter can punch at.  \n* **Height difference** Will give and indication who is punching with and who is punching against gravity. \n\nLets work throw away any data we do not need to calculate the above features. ","a248d863":"The ELR of takedowns appears to very predictive if we only consider fights where both fighter have had more than 4 fights. Lets see if we can make a more predictive statistic. We can create a new statistic we will call *Weighted attack Probability*,\n$$  = \\frac{1}{\\textit{Red Total Attacks Attempted}} \\sum_{fights} (\\textit{Blue Attack Defense})(\\textit{Red Attacks landed})$$.\n\nWe well weight the attack forms significant strikes, strikes and takedowns in this way then calculate *ELR*s and *ELR* differences using the new probabilities.","fdfaa2fc":"Lets inspect for fighters with at least 4 fights.","a36cc3eb":"*TD_ELR_difference* looks very predictive, now lets look at for any number of fights. ","e6f8289e":"## Model Training and evaluation\nLets only train models on fights where both fighters have had at least 4 fights in UFC so we have data against a range of oppenants. "}}