{"cell_type":{"954daaa4":"code","132fe813":"code","cf385830":"code","00703441":"code","9690fc06":"code","c164d8dc":"code","f77875e3":"code","ecbfc4e3":"code","e3bcae61":"code","21642acd":"code","6109cfcc":"code","24f74f2f":"code","a78cf1fd":"code","81effcfe":"code","35dc4a09":"code","327aa412":"code","421ba287":"markdown","7f3d11df":"markdown"},"source":{"954daaa4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn')\n\nimport warnings\nwarnings.simplefilter(action='ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve","132fe813":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\nprint(df.shape)\ndf.head()","cf385830":"df.info()","00703441":"df.describe()","9690fc06":"non_zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\ndf[non_zero_features] = df[non_zero_features].replace(0, np.nan)","c164d8dc":"df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)","f77875e3":"df_train.info()","ecbfc4e3":"sns.heatmap(df_train.corr(), annot=True)","e3bcae61":"df_train.describe()","21642acd":"features = df_train.drop('Outcome', axis=1).columns\nfor c in features:\n    f, axis = plt.subplots(1,2, figsize=(20, 5))\n    sns.distplot(df_train[c], ax=axis[0], kde=True)\n    sns.boxplot(df_train['Outcome'], df_train[c], ax=axis[1])\n    plt.show()","6109cfcc":"df_train['Outcome'].value_counts().plot.bar()","24f74f2f":"for c in non_zero_features:\n    df_train[df_train[c].isnull()]['Outcome'].value_counts().plot.bar()\n    plt.title(c)\n    plt.show()\n","a78cf1fd":"X_train = df_train.drop('Outcome', axis=1)\ny_train = df_train['Outcome']\nX_test = df_test.drop('Outcome', axis=1)\ny_test = df_test['Outcome']\n\nimputer = SimpleImputer(strategy='median')\nX_train = imputer.fit_transform(X_train)\nX_test = imputer.transform(X_test)\n\nscale = StandardScaler()\nX_train = scale.fit_transform(X_train)\nX_test = scale.transform(X_test)\n\nfor c in ['BloodPressure', 'Insulin']:\n    X_train = np.c_[X_train, np.where(df_train[c].isnull(), 1, 0)]\n    X_test = np.c_[X_test, np.where(df_test[c].isnull(), 1, 0)]\n\nmodels = [('LogisticRegression', LogisticRegression()), ('Knn', KNeighborsClassifier()), ('SVC', SVC())]\n\nfor name, model in models:\n    y_pred = cross_val_predict(model, X_train, y_train)\n    print(name + '\\n')\n    print('accuracy_score : ', accuracy_score(y_train, y_pred))\n    print('recall_score : ', recall_score(y_train, y_pred))\n    print('precision : ', precision_score(y_train, y_pred))\n    print('f1_score : ', f1_score(y_train, y_pred))\n    print('roc_auc_score : ', roc_auc_score(y_train, y_pred))\n    print('\\n')","81effcfe":"lr = LogisticRegression(random_state=0)\n\nparam_grid = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n    'max_iter': list(range(100,800,100)),\n    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n}\nlr_search = GridSearchCV(lr, param_grid=param_grid, cv=5, scoring='roc_auc')\n\nlr_search.fit(X_train , y_train)\n\nprint('Config: %s' % lr_search.best_params_)\nprint('Best Score: %s' % lr_search.best_score_)","35dc4a09":"y_train_pred = lr_search.predict(X_train)\ny_test_pred = lr_search.predict(X_test)\ny_train_prob= lr_search.predict_proba(X_train)[:,1]\ny_test_prob= lr_search.predict_proba(X_test)[:,1]\n\nprint('Train accuracy_score : ', accuracy_score(y_train, y_train_pred))\nprint('Test accuracy_score : ', accuracy_score(y_test, y_test_pred))\nprint('\\n')\nprint('Train recall_score : ', recall_score(y_train, y_train_pred))\nprint('Test recall_score : ', recall_score(y_test, y_test_pred))\nprint('\\n')\nprint('Train precision : ', precision_score(y_train, y_train_pred))\nprint('Test precision : ', precision_score(y_test, y_test_pred))\nprint('\\n')\nprint('Train f1_score : ', f1_score(y_train, y_train_pred))\nprint('Test f1_score : ', f1_score(y_test, y_test_pred))\nprint('\\n')\nprint('Train roc_auc_score : ', roc_auc_score(y_train, y_train_prob))\nprint('Test roc_auc_score : ', roc_auc_score(y_test, y_test_prob))","327aa412":"def plot_roc_curve(false_positive_rate, true_positive_rate):\n    plt.plot(false_positive_rate, true_positive_rate, linewidth=2)\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n    plt.plot([0, 1], [0, 1], 'r--')\n\nfalse_positive_rate, true_positive_rate, _ = roc_curve(y_test, y_test_prob)\n  \nplot_roc_curve(false_positive_rate, true_positive_rate)","421ba287":"## EDA","7f3d11df":"# Model Building"}}