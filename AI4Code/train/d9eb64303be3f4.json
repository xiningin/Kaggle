{"cell_type":{"7c27a308":"code","edc70854":"code","7ad867cb":"code","bf76f2ec":"code","29af7aad":"code","9d73705c":"code","381a4a83":"code","ffd35e17":"code","a6131101":"code","de83b875":"code","9f2c62bd":"code","d26eaa6d":"code","54d91ad9":"code","fda5fa5b":"code","3b0381a8":"code","eb1ccc71":"code","2e748589":"code","2c23302d":"code","37b15799":"code","37935bdb":"code","8ff5c4bc":"code","5a894f01":"code","b080b841":"code","b4d65169":"code","5fa161fd":"code","e9ec967d":"code","cc324471":"code","51a1e9da":"code","35771f86":"code","f60b54c2":"code","679a17f3":"code","58fee059":"code","b4937b0b":"code","c41a895b":"code","6a1f0043":"code","5e8390b7":"code","a267e5a3":"code","60fb450e":"code","56fb11e8":"code","8cab1dc0":"code","b72530ab":"markdown","d8f4688f":"markdown","3e2449db":"markdown","9f094a5f":"markdown","e43e4afb":"markdown","4f7c538f":"markdown","7b7dcb11":"markdown","435a8b87":"markdown","ea2c57a4":"markdown","e51f9288":"markdown","b9d8774d":"markdown","c0ab6aa2":"markdown"},"source":{"7c27a308":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","edc70854":"\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n","7ad867cb":"df=pd.read_csv(\"\/kaggle\/input\/TheUnsinkable.csv\")","bf76f2ec":"df.info()\ndf.describe()","29af7aad":"df.head(5) #sibsp-->sibling spouse, parch---->no of parents,children, embarked--->port of embarkment","9d73705c":"df.isnull() #since we can't view whole data so we use visualisation using seaborn","381a4a83":"df.corr('pearson')","ffd35e17":"\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","a6131101":"#map\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","de83b875":"#sns.set_style('whitegrid')\nsns.countplot(x='survived',data=df)","9f2c62bd":"sns.countplot(x='survived',hue='sex',data=df) #In seaborn, the hue parameter determines which column in the data frame should be used for colour encoding. ","d26eaa6d":"sns.countplot(x='survived',hue='pclass',data=df)","54d91ad9":"sns.distplot(df['age'].dropna(),kde=False,color='darkred',bins=40) #kde=Kernel Density Estimates, bins are class intervals the total range of dataset is divides into","fda5fa5b":"sns.countplot(x='sibsp',data=df)","3b0381a8":"sns.distplot(df['fare'])","eb1ccc71":"sns.boxplot(x='pclass',y='age', data=df) #we find mean age based on different classes, for class1- 37, for class2- 30, for class3-25","2e748589":"def impute_age(cols):\n    age=cols[0]           #1st column is age\n    pclass=cols[1]        #2nd column is pclass\n    \n    if pd.isnull(age):\n        if pclass==1:\n            return 37\n        if pclass==2:\n            return 29\n        if pclass==3:\n            return 24\n    else:                  #when age is not null\n        return age\n        ","2c23302d":"df['age']=df[['age','pclass']].apply(impute_age, axis=1)","37b15799":"sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","37935bdb":"df.drop('deck',axis=1, inplace=True)","8ff5c4bc":"df.head(5)","5a894f01":"embark=pd.get_dummies(df['embarked'],drop_first=True)","b080b841":"sex=pd.get_dummies(df['sex'],drop_first=True)","b4d65169":"ad_male=pd.get_dummies(df['adult_male'],drop_first=True)","5fa161fd":"df.drop(['sex','embarked','who','embark_town','alive','alone','adult_male','class'],axis=1,inplace=True)","e9ec967d":"df.head()","cc324471":"df=pd.concat([df,sex,embark,ad_male],axis=1)","51a1e9da":"df.head()","35771f86":"df.drop(['survived'],axis=1).head()","f60b54c2":"df['survived'].head()","679a17f3":"from sklearn.model_selection import train_test_split","58fee059":"X_train,X_test,y_train, y_test=train_test_split(df.drop('survived',axis=1),df['survived'],test_size=0.3,random_state=101)","b4937b0b":"logmodel=LogisticRegression()","c41a895b":"logmodel.fit(X_train,y_train)","6a1f0043":"pred=logmodel.predict(X_test)","5e8390b7":"accuracy=confusion_matrix(y_test,pred)","a267e5a3":"accuracy","60fb450e":"accuracy=accuracy_score(y_test,pred)","56fb11e8":"accuracy","8cab1dc0":"pred","b72530ab":"# DATA VISUALISATION","d8f4688f":"This Model will predict chances of survival on RMS Titanic for a person, given his age, gender, boarding port, ticket fare, passenger class.","3e2449db":"the hue value above can be changed depending upon what column we pick","9f094a5f":"Handling NAN values","e43e4afb":"# Importing Libraries","4f7c538f":"now we can see deck has max null values and also has no impact on classification and hence can be removed\n\nyticklables=False means no value on y axis, x axis contains all the columns","7b7dcb11":"The correlation matrix gives the relation of one column with another. It ranges between -1 to +1","435a8b87":"now check the mapping again","ea2c57a4":"Data Visualisation\nData Cleaning\n\nWe want to fill the missing values. so we use the mean value to fill up missing places--->IMPUTATION\n\nNow only cabin is left to be dealt with.\n\nthe problem is too many missing values.\n\ndrop column\n","e51f9288":"# Regression Model","b9d8774d":"We want to fill the missing values. so we use the mean value to fill up missing places--->IMPUTATION","c0ab6aa2":"#  Data Cleaning"}}