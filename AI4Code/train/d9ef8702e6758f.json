{"cell_type":{"1673bf37":"code","819e1082":"code","72aad31c":"code","f06da8c0":"code","5b4136a2":"code","6d65cfe0":"code","014aa96a":"code","80716d35":"code","d96033e7":"code","44607a2b":"code","dcc6a85a":"code","3087496f":"code","91fdbd8c":"code","f1d5a482":"code","cfc344eb":"code","fa82f97a":"code","75cc0387":"code","548b5225":"code","53878cfe":"code","541fa6cb":"code","00aa12ed":"code","1a3b6b8e":"code","0387221a":"code","ffda0b29":"code","b06c9d99":"code","d74c3d77":"code","4bb9b892":"code","1fee5bdd":"code","194d62b1":"code","b2d11139":"code","c78e656c":"markdown","53006f11":"markdown","056b8681":"markdown","ff488b81":"markdown","bd0cd8d1":"markdown","ddac8b38":"markdown","13ca4b02":"markdown"},"source":{"1673bf37":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom keras.utils import np_utils\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","819e1082":"train = pd.read_csv(\"..\/input\/train.csv\")\ntrain.head()","72aad31c":"# Check for null values\ntrain.isnull().sum().sum()","f06da8c0":"train.drop(\"id\", axis=1, inplace=True)\ntrain.columns","5b4136a2":"f = plt.figure()\nsns.countplot(train['target'])\nplt.title(\"Count plot\",fontsize=20)\nplt.show()\n","6d65cfe0":"y = train['target']\ntrain.drop(\"target\", axis=1, inplace=True)\nX = train","014aa96a":"feature_model = ExtraTreesClassifier(n_estimators=100,verbose=1,n_jobs=-1)\nfeature_model.fit(X,y)","80716d35":"#feature importance\nprint(feature_model.feature_importances_)","d96033e7":"feature_select = SelectFromModel(feature_model, prefit=True)\nX_new = feature_select.transform(X)","44607a2b":"feature_select = SelectFromModel(feature_model, prefit=True)\nX_new = feature_select.transform(X)","dcc6a85a":"feature_idx = feature_select.get_support()\nfeature_name = X.columns[feature_idx]","3087496f":"feature_name","91fdbd8c":"f,ax = plt.subplots(figsize=(20,15))\nsns.heatmap(train[feature_name].corr(), ax=ax,cmap=\"YlGnBu\")\nplt.title(\"Correlation Matrix\",fontsize=20)\nplt.show()","f1d5a482":"plt.figure(figsize=(15,15))\nplt.bar(range(len(feature_model.feature_importances_)), feature_model.feature_importances_)\nplt.title(\"Feature Importance\")\nplt.xticks(np.arange(len(train.columns)),train.columns, rotation=90)\nplt.show()","cfc344eb":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,auc,roc_curve\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.neighbors import KNeighborsClassifier","fa82f97a":"x_train, x_test, y_train, y_test = train_test_split(X_new, y, random_state=42)","75cc0387":"model_KNN = KNeighborsClassifier(n_neighbors=5, algorithm='auto', n_jobs=-1,p=2)\nmodel_KNN.fit(x_train, y_train)","548b5225":"y_pred = model_KNN.predict(x_test)","53878cfe":"print(\"Accuracy(KNN_Classifier)\\t:\"+str(accuracy_score(y_test,y_pred)))\nprint(\"Precision(KNN_Classifier)\\t:\"+str(precision_score(y_test,y_pred)))\nprint(\"Recall(KNN_Classifier)\\t:\"+str(recall_score(y_test,y_pred)))","541fa6cb":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","00aa12ed":"from matplotlib.colors import ListedColormap\n\n# we only take the first two features. We could avoid this ugly\n# slicing by using a two-dim dataset\nX_ = X_new[:, :2][:600]\ny_ = y[:600]\n# Create color maps\ncmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\ncmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\nh = .02  # step size in the mesh\n\nclf = KNeighborsClassifier(n_neighbors=5, algorithm='auto', n_jobs=-1,p=2)\nclf.fit(X_, y_)\n\n# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, x_max]x[y_min, y_max].\nx_min, x_max = X_[:, 0].min() - 1, X_[:, 0].max() + 1\ny_min, y_max = X_[:, 1].min() - 1, X_[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(15,15))\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n# Plot also the training points\nplt.scatter(X_[:, 0], X_[:, 1], c=y_, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"2-Class classification (k = %i)\"\n              % (5))\nplt.show()","1a3b6b8e":"prob=model_KNN.predict_proba(x_test)\nprob = prob[:,1]","0387221a":"fpr,tpr,_ = roc_curve(y_test, prob)\nroc_auc = auc(fpr, tpr)\nplt.figure(figsize=(14,12))\nplt.title('Receiver Operating Characteristic',fontsize=20)\nsns.lineplot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","ffda0b29":"test = pd.read_csv(\"..\/input\/test.csv\")\ntest.head()","b06c9d99":"test.shape","d74c3d77":"id_test = test['id']","4bb9b892":"test.drop(\"id\", axis=1, inplace=True)","1fee5bdd":"test = test[feature_name]","194d62b1":"y_pred_test = model_KNN.predict_proba(test)[:,1]","b2d11139":"my_submission = pd.DataFrame({'id': id_test, 'target': y_pred_test})\nmy_submission.to_csv('SubmissionVictor2.csv', index=False)","c78e656c":"## Conclusion\n* **Still a Long way to gooo......**\n* **A Lot of improvement needed to be done to achieve the Silver medal....**\n![](https:\/\/banner2.kisspng.com\/20180402\/yje\/kisspng-emoji-emoticon-anger-computer-icons-smiley-angry-emoji-5ac1ababcd4bf6.5569267415226418358409.jpg)\n","53006f11":"#### Therefore the target classes are balanced and doesnot need to be sampled","056b8681":"## Submission","ff488b81":"## Feature extraction and feature selection","bd0cd8d1":"## Model creation\n### Model Performance in case of KNN","ddac8b38":"## Plotting of Decision boundaries for KNN","13ca4b02":"## I hope this kernel was helpful to you. Please upvote it if you like it..."}}