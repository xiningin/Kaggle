{"cell_type":{"7247947e":"code","a8993e09":"code","18b76246":"code","f81fc17c":"code","d1526a6f":"code","611b05f4":"code","e6253334":"code","cb143856":"code","f46ada11":"code","9b1fc4e9":"code","20b1f435":"code","a68db588":"code","b8c4f037":"code","b1ef2a1c":"code","b5c8545d":"code","65dafde8":"code","a79535ce":"code","f10fa3a1":"code","d8e0f3b5":"code","ee9bad56":"code","71ffae38":"code","0a3fc5f9":"code","cd394a29":"code","fb6c5504":"code","3da1a169":"code","c859744a":"code","770cda05":"code","887fe86b":"code","a6673141":"code","d5a46d49":"code","7cc43907":"code","65ebcc4e":"code","3caf05dd":"markdown","0193c14a":"markdown","8dc1f663":"markdown","d96e809f":"markdown","54e820b9":"markdown","1fcbeada":"markdown","31c8715c":"markdown","32563f08":"markdown","4e1fb428":"markdown","875dc04e":"markdown","9ae466fe":"markdown","bf2b2438":"markdown","7da5cba3":"markdown","94f72569":"markdown","88633d8d":"markdown","bea0507c":"markdown","c99f7fe4":"markdown","6c45331a":"markdown","4e3a9f97":"markdown","39d888fc":"markdown","c5473eca":"markdown","43c6045a":"markdown","d6a35670":"markdown","6c16cede":"markdown","05811a46":"markdown","11cbeb82":"markdown","c98d032a":"markdown","afa83b31":"markdown","f1a43ab0":"markdown","5b7ffcb5":"markdown","8467b5df":"markdown","4e958b74":"markdown","c3454f8e":"markdown","dc2e1a68":"markdown","d0848d13":"markdown","7724982a":"markdown","9b37405f":"markdown","27fd7b9c":"markdown","7fe1d3a6":"markdown","ba3b5a77":"markdown","08eaecec":"markdown","1ac0ead8":"markdown","a9276722":"markdown","204b90f4":"markdown","d5b5d31d":"markdown","311cdadb":"markdown","80373da2":"markdown","f39e6e4b":"markdown","d6953446":"markdown","34e3cc69":"markdown","fea5f6dc":"markdown","2fb596d9":"markdown","9ce768d3":"markdown","872461cb":"markdown","e3debdc2":"markdown","637eac9e":"markdown","c20334ea":"markdown"},"source":{"7247947e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nimport networkx as nx\nimport warnings\nwarnings.filterwarnings('ignore')\nimport folium \nfrom folium import plugins\nfrom highcharts import Highchart\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a8993e09":"df_2017=pd.read_csv('..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv',encoding='ISO-8859-1')\ndf_2018=pd.read_csv('..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv')\ndf_2018.columns=df_2018.iloc[0]\ndf_2018=df_2018.drop([0])","18b76246":"print('Total respondents in 2018:',df_2018.shape[0],'with a growth of:',(df_2018.shape[0]-df_2017.shape[0])\/df_2017.shape[0]*100,'%')","f81fc17c":"print('Maximum Response Time: ',(df_2018['Duration (in seconds)'].astype('int')\/60).max(),'mins')\nprint('Minimum Response Time: ',(df_2018['Duration (in seconds)'].astype('int')\/60).min(),'mins')\nprint('Mean Response Time: ',(df_2018['Duration (in seconds)'].astype('int')\/60).mean(),'mins')","d1526a6f":"df_2018['mins']=df_2018['Duration (in seconds)'].astype('int')\/60\nplt.hist(df_2018[df_2018['mins']<100].mins,bins=30,edgecolor='black', linewidth=1.2)\nplt.title('Response Time in Minutes')\nplt.gcf().set_size_inches(10,5)","611b05f4":"ax=df_2018['What is your gender? - Selected Choice'].value_counts().plot.barh(width=0.9,color='#ffd700')\nfor i, v in enumerate(df_2018['What is your gender? - Selected Choice'].value_counts().values): \n    ax.text(200, i, v,fontsize=12,color='red',weight='bold')\nplt.title('Gender Distribution')\nplt.gcf().set_size_inches(8,5)\nplt.show()","e6253334":"gen_2018=df_2018['What is your gender? - Selected Choice'].value_counts().to_frame()\ngen_2017=df_2017['GenderSelect'].value_counts().to_frame()\ngen_2017=gen_2017.merge(gen_2018,left_index=True,right_index=True,how='left').dropna()\ngen_2017.columns=['2017','2018']\nH = Highchart(width=800, height=400)\n\noptions = {\n    'title': {\n        'text': 'Male vs Female Respondents (2017-2018)'\n    },\n    'xAxis': {\n        'categories': ['Male', 'Female',],\n        'title': {\n            'text': None\n        }\n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': 'Respondents'\n        },\n        'labels': {\n            'overflow': 'justify'\n        }\n    },\n    'legend': {\n        'layout': 'vertical',\n        'align': 'right',\n        'verticalAlign': 'top',\n        'x': -40,\n        'y': 80,\n        'floating': True,\n        'borderWidth': 1,\n        'shadow': True\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(gen_2017['2017'])\ndata2 = list(gen_2017['2018'])\nH.add_data_set(data1, 'bar', '2017')\nH.add_data_set(data2, 'bar', '2018')\n\nH","cb143856":"names=['Afghanistan','Albania','Algeria','American Samoa','Andorra','Angola','Anguilla','Antarctica','Antigua & Barbuda','Argentina','Armenia','Aruba','Australia','Austria','Azerbaijan','Bahamas','Bahrain','Bangladesh','Barbados','Belarus','Belgium','Belize','Benin','Bermuda','Bhutan','Bolivia','Bosnia','Botswana','Bouvet Island','Brazil','British Indian Ocean Territory','British Virgin Islands','Brunei','Bulgaria','Burkina Faso','Burundi','Cambodia','Cameroon','Canada','Cape Verde','Caribbean Netherlands','Cayman Islands','Central African Republic','Chad','Chile',\"People 's Republic of China\",'Christmas Island','Cocos (Keeling) Islands','Colombia','Comoros','Congo - Brazzaville','Congo - Kinshasa','Cook Islands','Costa Rica','Croatia','Cuba','Cura\u00e7ao','Cyprus',\n 'Czech Republic','C\u00f4te d\u2019Ivoire','Denmark','Djibouti','Dominica','Dominican Republic','Ecuador','Egypt','El Salvador','Equatorial Guinea','Eritrea','Estonia','Ethiopia','Falkland Islands','Faroe Islands','Fiji','Finland','France','French Guiana','French Polynesia','French Southern Territories','Gabon','Gambia','Georgia','Germany','Ghana','Gibraltar','Greece','Greenland','Grenada','Guadeloupe','Guam','Guatemala','Guernsey','Guinea','Guinea-Bissau','Guyana','Haiti','Heard & McDonald Islands','Honduras','Hong Kong','Hungary','Iceland','India','Indonesia','Iran','Iraq','Ireland','Isle of Man','Israel','Italy','Jamaica','Japan','Jersey','Jordan',\n 'Kazakhstan','Kenya','Kiribati','Kuwait','Kyrgyzstan','Laos','Latvia','Lebanon','Lesotho','Liberia','Libya','Liechtenstein','Lithuania','Luxembourg','Macau','Macedonia','Madagascar','Malawi','Malaysia','Maldives','Mali','Malta','Marshall Islands','Martinique','Mauritania','Mauritius','Mayotte','Mexico','Micronesia','Moldova','Monaco','Mongolia','Montenegro','Montserrat','Morocco','Mozambique','Myanmar','Namibia','Nauru','Nepal','Netherlands','New Caledonia','New Zealand','Nicaragua','Niger','Nigeria','Niue','Norfolk Island','North Korea','Northern Mariana Islands','Norway','Oman','Pakistan','Palau','Palestine','Panama','Papua New Guinea','Paraguay','Peru','Philippines','Pitcairn Islands','Poland','Portugal','Puerto Rico','Qatar','Romania','Russia','Rwanda','R\u00e9union','Samoa','San Marino','Saudi Arabia','Senegal','Serbia','Seychelles','Sierra Leone','Singapore','Sint Maarten','Slovakia','Slovenia','Solomon Islands','Somalia','South Africa','South Georgia & South Sandwich Islands','South Korea','South Sudan','Spain','Sri Lanka','St. Barth\u00e9lemy','St. Helena','St. Kitts & Nevis','St. Lucia','St. Martin','St. Pierre & Miquelon','St. Vincent & Grenadines','Sudan','Suriname','Svalbard & Jan Mayen','Swaziland','Sweden','Switzerland','Syria','S\u00e3o Tom\u00e9 & Pr\u00edncipe','Taiwan','Tajikistan','Tanzania','Thailand','Timor-Leste','Togo','Tokelau','Tonga','Trinidad & Tobago','Tunisia','Turkey','Turkmenistan','Turks & Caicos Islands','Tuvalu','U.S. Outlying Islands','U.S. Virgin Islands','United Kingdom','United States','Uganda','Ukraine','United Arab Emirates','Uruguay','Uzbekistan','Vanuatu','Vatican City','Venezuela','Vietnam','Wallis & Futuna','Western Sahara','Yemen','Zambia','Zimbabwe','\u00c5land Islands']\nlong=[33.93911,41.153332,28.033886,-14.270972,42.506285,-11.202692,18.220554,-82.862752,17.060816,-38.416097,40.069099,12.52111,-25.274398,47.516231,40.143105,25.03428,26.0667,23.684994,13.193887,53.709807,50.503887,17.189877,9.30769,32.3078,27.514162,-16.290154,43.915886,-22.328474,-54.4207915,-14.235004,-6.343194,18.420695,4.535277,42.733883,12.238333,-3.373056,12.565679,7.369722,56.130366,16.5388,12.1783611,19.3133,6.611111,15.454166,-35.675147,35.86166,-10.447525,-12.164165,4.570868,-11.6455,-0.228021,-4.038333,-21.236736,9.748917,45.1,21.521757,12.16957,35.126413,49.817492,7.539989,56.26392,11.825138,15.414999,18.735693,-1.831239,26.820553,13.794185,1.650801,15.179384,58.595272,9.145,-51.796253,61.892635,-17.713371,61.92411,46.227638,3.933889,-17.679742,-49.280366,-0.803689,13.443182,32.1656221,51.165691,7.946527,36.140751,39.074208,71.706936,12.1165,16.265,13.444304,15.783471,49.465691,9.945587,11.803749,4.860416,18.971187,-53.08181,15.199999,22.396428,47.162494,64.963051,20.593684,-0.789275,32.427908,33.223191,53.1423672,\n54.236107,31.046051,41.87194,18.109581,36.204824,49.214439,30.585164,48.019573,-0.023559,-3.370417,29.31166,41.20438,19.85627,56.879635,33.854721,-29.609988,6.428055,26.3351,47.166,55.169438,49.815273,22.198745,41.608635,-18.766947,-13.254308,4.210484,3.202778,17.570692,35.937496,7.131474,14.641528,\n21.00789,-20.348404,-12.8275,23.634501,7.425554,47.411631,43.7384176,46.862496,42.708678,16.742498,31.791702,-18.665695,21.916221,-22.95764,-0.522778,28.394857,52.132633,-20.904305,-40.900557,12.865416,17.607789,9.081999,-19.054445,-29.040835,40.339852,15.0979,60.472024,21.4735329,30.375321,7.51498,31.952162,8.537981,-6.314993,-23.442503,-9.189967,12.879721,-24.3767537,51.919438,39.399872,18.220833,25.354826,45.943161,61.52401,-1.940278,-21.115141,-13.759029,43.94236,23.885942,14.497401,44.016521,-4.679574,8.460555,1.352083,18.04248,48.669026,46.151241,-9.64571,5.152149,-30.559482,-54.429579,35.907757,6.8769919,40.463667,7.873054,17.9,-15.9650104,17.357822,13.909444,18.0708298,46.8852,12.984305,12.862807,3.919305,77.553604,-26.522503,60.128161,46.818188,34.802075,0.18636,23.69781,38.861034,-6.369028,15.870032,-8.874217,8.619543,-9.2002,-21.178986,10.691803,33.886917,38.963745,38.969719,21.694025,-7.109535,19.2823192,18.335765,55.378051,40.7605367,1.373333,48.379433,23.424076,-32.522779,41.377491,-15.376706,41.902916,6.42375,14.058324,-14.2938,24.215527,15.552727,-13.133897,-19.015438,60.1785247,]\nlat= [67.709953 ,   20.168331 ,1.659626 , -170.132217 ,    1.521801 ,   17.873887 ,-63.068615 ,  135. ,  -61.796428 ,  -63.616672 ,45.038189 ,  -69.968338 ,  133.775136 ,   14.550072 ,47.576927 ,  -77.39628  ,   50.5577   ,   90.356331 ,\n-59.543198 ,   27.953389 ,    4.469936 ,  -88.49765  ,2.315834 ,  -64.7505   ,   90.433601 ,  -63.588653 ,17.679076 ,   24.684866 ,    3.3464497,  -51.92528  ,71.876519 ,  -64.639968 ,  114.727669 ,   25.48583  ,-1.561593 ,   29.918886 ,  104.990963 ,   12.354722 ,-106.346771 ,  -23.0418   ,  -68.2385339,  -81.2546   ,20.939444 ,   18.732207 ,  -71.542969 ,  104.195397 ,105.690449 ,   96.870956 ,  -74.297333 ,   43.3333   ,15.827659 ,   21.758664 , -159.777671 ,  -83.753428 ,15.2000001,  -77.781167 ,  -68.99002  ,   33.429859 ,15.472962 ,   -5.54708  ,    9.501785 ,   42.590275 ,-61.370976 ,  -70.162651 ,  -78.183406 ,   30.802498 ,-88.89653  ,   10.267895 ,   39.782334 ,   25.0136071,40.489673 ,  -59.523613 ,   -6.9118061,  178.065032 ,\n25.7481511,    2.213749 ,  -53.125782 , -149.406843 ,69.3485571,   11.609444 ,  -15.310139 ,  -82.9000751,10.451526 ,   -1.023194 ,   -5.353585 ,   21.824312 ,-42.604303 ,  -61.679    ,  -61.551    ,  144.793731 ,-90.230759 ,   -2.585278 ,   -9.696645 ,  -15.180413 ,-58.93018  ,  -72.285215 ,   73.504158 ,  -86.241905 ,114.109497 ,   19.5033041,  -19.020835 ,   78.96288  ,113.921327 ,   53.688046 ,   43.679291 ,   -7.6920536,-4.548056 ,   34.851612 ,   12.56738  ,  -77.297508 ,138.252924 ,   -2.13125  ,   36.238414 ,   66.923684 ,37.906193 , -168.734039 ,   47.481766 ,   74.766098 ,102.495496 ,   24.603189 ,   35.862285 ,   28.233608 ,-9.429499 ,   17.228331 ,    9.555373 ,   23.881275 ,6.129583 ,  113.543873 ,   21.745275 ,   46.869107 ,34.301525 ,  101.975766 ,   73.22068  ,   -3.996166 ,14.375416 ,  171.184478 ,  -61.024174 ,  -10.940835 ,57.552152 ,   45.166244 , -102.552784 ,  150.550812 ,28.369885 ,    7.4246158,  103.846656 ,   19.37439  ,-62.187366 ,   -7.09262  ,   35.529562 ,   95.955974 ,18.49041  ,  166.931503 ,   84.124008 ,    5.291266 ,165.618042 ,  174.885971 ,  -85.207229 ,    8.081666 ,8.675277 , -169.867233 ,  167.954712 ,  127.510093 ,145.6739   ,    8.468946 ,   55.975413 ,   69.345116 ,134.58252  ,   35.233154 ,  -80.782127 ,  143.95555  ,-58.443832 ,  -75.015152 ,  121.774017 , -128.3242376,19.145136 ,   -8.224454 ,  -66.590149 ,   51.183884 ,24.96676  ,  105.318756 ,   29.873888 ,   55.536384 ,-172.104629 ,   12.457777 ,   45.079162 ,  -14.452362 ,21.005859 ,   55.491977 ,  -11.779889 ,  103.819836 ,-63.05483  ,   19.699024 ,   14.995463 ,  160.156194 ,46.199616 ,   22.937506 ,  -36.587909 ,  127.766922 ,31.3069788,   -3.74922  ,   80.771797 ,  -62.833333 ,-5.7089241,  -62.782998 ,  -60.978893 ,  -63.0500809,-56.3159   ,  -61.287228 ,   30.217636 ,  -56.027783 ,23.6702719,   31.465866 ,   18.643501 ,    8.227512 ,38.996815 ,    6.613081 ,  120.960515 ,   71.276093 ,34.888822 ,  100.992541 ,  125.727539 ,    0.824782 ,-171.8484   , -175.198242 ,  -61.222503 ,    9.537499 ,35.243322 ,   59.556278 ,  -71.797928 ,  177.64933  ,166.647047 ,  -64.896335 ,   -3.435973 ,  -73.9788903,32.290275 ,   31.1655799,   53.847818 ,  -55.765835 ,64.585262 ,  166.959158 ,   12.453389 ,  -66.58973  ,108.277199 , -178.1165   ,  -12.885834 ,   48.516388 ,27.849332 ,   29.154857 ,   19.9156105]\n\ncoun_dat=pd.DataFrame({'name':names,'longitude':long,'latitude':lat})\ndd1=df_2017['Country'].value_counts().to_frame()\ndf_2018['In which country do you currently reside?'].replace({'United States of America':'United States','Viet Nam':'Vietnam','China':\"People 's Republic of China\",\"United Kingdom of Great Britain and Northern Ireland\":'United Kingdom',\"Hong Kong (S.A.R.)\":\"Hong Kong\"},inplace=True)\ndd2=df_2018['In which country do you currently reside?'].value_counts().to_frame()\n#dd2=dd2.rename(index={'United States of America':'United States','Viet Nam':'Vietnam','China':\"People 's Republic of China\",\"United Kingdom of Great Britain and Northern Ireland\":'United Kingdom',\"Hong Kong (S.A.R.)\":\"Hong Kong\"})\ndd1=dd1.merge(dd2,left_index=True,right_index=True,how='left')\ndd1.columns=['2017','2018']\ndd1['Growth']=(dd1['2018']-dd1['2017'])\/dd1['2017']*100\ndecimals = 2   \ndd1['Growth']=dd1['Growth'].apply(lambda x: round(x, decimals))\ndd1.dropna(inplace=True)\ncoun_fin=coun_dat.merge(dd1,left_on='name',right_index=True,how='left').dropna()\ndef growth_col(value):\n    if value < 0:\n        return 'red'\n    elif value > 0 and value < 50:\n        return 'yellow'\n    else:\n        return 'green'\nlocate=coun_fin[['longitude','latitude']]\ncoun=coun_fin['name']\nresp_2017=coun_fin['2017']\nresp_2018=coun_fin['2018']\ngrowth=coun_fin['Growth']\nmap1 = folium.Map(location=[48.85, 2.35], tiles=\"Mapbox Control Room\", zoom_start=2)\nfor point in coun_fin.index:\n    info='<font color=\"red\" >Country: <\/font>'+str(coun.loc[point])+'<br><font color=\"red\"> Total Respondents 2017: <\/font>'+str(resp_2017.loc[point])+'<br><font color=\"red\"> Total Respondents 2018: <\/font>'+str(resp_2018.loc[point])+'<br><font color=\"red\"> Growth: <\/font>'+str(growth.loc[point])+' %'\n    iframe = folium.IFrame(html=info, width=250, height=250)\n    folium.CircleMarker(list(locate.loc[point]),popup=folium.Popup(iframe),radius=resp_2018.loc[point]*0.01,color=growth_col(growth.loc[point]),fill_color=growth_col(growth.loc[point]),fill=True).add_to(map1)\nmap1","f46ada11":"H = Highchart(width=800, height=400)\n\noptions = {\n    'title': {\n        'text': 'Age Ranges'\n    },\n    'xAxis': {\n        'categories': list(df_2018['What is your age (# years)?'].value_counts().index),\n        'title': {\n            'text': None\n        }\n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': 'Respondents'\n        },\n        'labels': {\n            'overflow': 'justify'\n        }\n    },\n    'legend': {\n        'layout': 'vertical',\n        'align': 'right',\n        'verticalAlign': 'top',\n        'x': -40,\n        'y': 80,\n        'floating': True,\n        'borderWidth': 1,\n        'shadow': True\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True\n            }\n        },\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(df_2018['What is your age (# years)?'].value_counts())\nH.add_data_set(data1, 'bar')\n\nH","9b1fc4e9":"df_2018['Age Grp']=np.where(df_2018['What is your age (# years)?'].isin(['25-29','22-24','30-34','18-21']),'Young','')\ndf_2018['Age Grp']=np.where(df_2018['What is your age (# years)?'].isin(['35-39', '40-44', '45-49', '50-54']),'Middle',df_2018['Age Grp'])\ndf_2018['Age Grp']=np.where(df_2018['What is your age (# years)?'].isin(['55-59', '60-69', '70-79', '80+']),'Old',df_2018['Age Grp'])\ncoun_age=df_2018.groupby(['In which country do you currently reside?','Age Grp'])['What is your age (# years)?'].count().reset_index()\ncoun_age.columns=['Country','Age Grp','Count']\ncoun_age=coun_age[coun_age['Country'].isin(df_2018['In which country do you currently reside?'].value_counts()[:6].index)]\ncoun_age=coun_age[coun_age['Country']!='Other']\ncoun_age.pivot('Country','Age Grp','Count').plot.bar(stacked=True,width=0.8)\nplt.gcf().set_size_inches(16,8)\nplt.show()","20b1f435":"H = Highchart(width=800, height=500)\n\noptions = {\n    'title': {\n        'text': 'UnderGraduate Major'\n    },\n    'xAxis': {\n        'categories': list(df_2018['Which best describes your undergraduate major? - Selected Choice'].value_counts().index),\n        'title': {\n            'text': None\n        }\n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': 'Count'\n        },\n        'labels': {\n            'overflow': 'justify'\n        }\n    },\n    'legend': {\n        'layout': 'vertical',\n        'align': 'right',\n        'verticalAlign': 'top',\n        'x': -40,\n        'y': 80,\n        'floating': True,\n        'borderWidth': 1,\n        'shadow': True\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(df_2018['Which best describes your undergraduate major? - Selected Choice'].value_counts())\nH.add_data_set(data1, 'bar')\n\nH","a68db588":"plt.figure(figsize=(8,8))\nax=df_2018['Select the title most similar to your current role (or most recent title if retired): - Selected Choice'].value_counts()[:10].plot.barh(width=0.9,color=sns.color_palette('inferno_r',25))\nfor i, v in enumerate(df_2018['Select the title most similar to your current role (or most recent title if retired): - Selected Choice'].value_counts()[:10].values): \n    ax.text(200, i, v,fontsize=12,color='blue',weight='bold')\nplt.gca().invert_yaxis()\nplt.title('Current Roles')\nplt.show()","b8c4f037":"lol1=df_2017[(df_2017['CurrentJobTitleSelect']=='Data Scientist')&(df_2017['StudentStatus']!='Yes')].Country.value_counts()[:10].to_frame()\nlol2=df_2018[(df_2018['Select the title most similar to your current role (or most recent title if retired): - Selected Choice']=='Data Scientist')&(df_2018['In what industry is your current employer\/contract (or your most recent employer if retired)? - Selected Choice']!='I am a student')]['In which country do you currently reside?'].value_counts()[:10].to_frame()\ncoun_10=lol1.merge(lol2,left_index=True,right_index=True,how='outer')\ncoun_10.columns=['2017','2018']\nH = Highchart(width=800, height=500)\n\noptions = {\n    'title': {\n        'text': 'No of Data Scientists Respondents By Top-10 Countries (2017-2018)'\n    },\n    'xAxis': {\n        'categories': list(coun_10.index),\n        'title': {\n            'text': None\n        }\n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': 'Respondents'\n        },\n        'labels': {\n            'overflow': 'justify'\n        }\n    },\n    'legend': {\n        'layout': 'vertical',\n        'align': 'right',\n        'verticalAlign': 'top',\n        'x': -80,\n        'y': 20,\n        'floating': True,\n        'borderWidth': 1,\n        'shadow': True\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(coun_10['2017'])\ndata2 = list(coun_10['2018'])\nH.add_data_set(data1, 'bar', '2017')\nH.add_data_set(data2, 'bar', '2018')\n\nH","b1ef2a1c":"l1=[col for col in df_2018 if col.startswith(\"Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years?\")]\ncol1=[]\ncol2=[]\nl2=df_2018[l1[:-1]]\nfor i in l2.columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\nide=pd.DataFrame({'IDE':col1,'Count':col2})\nH = Highchart(width=800, height=500)\n\noptions = {\n    'title': {\n        'text': \"Most Used IDE's\"\n    },\n    'xAxis': {\n        'categories': list(ide.sort_values('Count',ascending=False)['IDE']),\n        'title': {\n            'text': None\n        }\n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': 'Count'\n        },\n        'labels': {\n            'overflow': 'justify'\n        }\n    },\n    'legend': {\n        'layout': 'vertical',\n        'align': 'right',\n        'verticalAlign': 'top',\n        'x': -40,\n        'y': 80,\n        'floating': True,\n        'borderWidth': 1,\n        'shadow': True\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(ide.sort_values('Count',ascending=False)['Count'])\nH.add_data_set(data1, 'bar')\n\nH","b5c8545d":"plt.figure(figsize=(8,10))\nax=df_2018['What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice'].value_counts()[:10].plot.barh(width=0.9,color=sns.color_palette('viridis_r',25))\nfor i, v in enumerate(df_2018['What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice'].value_counts()[:10]): \n    ax.text(200, i, v,fontsize=12,color='blue',weight='bold')\nplt.gca().invert_yaxis()\nplt.title('First Language Recommended')\nplt.show()                                                                                                                                                      ","65dafde8":"lang_2017=df_2018['What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice'].value_counts().to_frame()\nlang_2018=df_2017['LanguageRecommendationSelect'].value_counts().to_frame()\nlang_2017=lang_2017.merge(lang_2018,left_index=True,right_index=True,how='left')\nlang_2017.columns=['2018','2017']\nH = Highchart(width=900, height=400)\n\noptions = {\n    'title': {\n        'text': 'Top Recommended First Language (2017-2018)'\n    },\n    'xAxis': {\n        'categories': list(lang_2017.index),\n        'title': {\n            'text': None\n        }\n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': 'Count'\n        },\n        'labels': {\n            'overflow': 'justify'\n        }\n    },\n    'legend': {\n        'layout': 'vertical',\n        'align': 'right',\n        'verticalAlign': 'top',\n        'x': -80,\n        'y': 20,\n        'floating': True,\n        'borderWidth': 1,\n        'shadow': True\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(lang_2017['2017'])\ndata2 = list(lang_2017['2018'])\nH.add_data_set(data1, 'bar', '2017')\nH.add_data_set(data2, 'bar', '2018')\n\nH","a79535ce":"l1=[col for col in df_2018 if col.startswith(\"Where do you find public datasets? (Select all that apply) - Selected Choice - \")]\ncol1=[]\ncol2=[]\nl2=df_2018[l1[:-2]]\nfor i in l2.columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\nsource=pd.DataFrame({'Source':col1,'Count':col2})\nH = Highchart(width=650, height=500)\n\noptions = {\n    'chart': {\n        'type': 'pie',\n        'options3d': {\n            'enabled': True,\n            'alpha': 45\n        }\n    },\n    'title': {\n        'text': \"Finding Public DataSets From?\"\n    },\n    'plotOptions': {\n        'pie': {\n            'innerSize': 100,\n            'depth': 45\n        }\n    },\n}\n\ndata = source.values.tolist()\n\nH.set_dict_options(options)\nH.add_data_set(data, 'pie', 'Count')\n\nH","f10fa3a1":"time_spent=[col for col in df_2018 if col.startswith(\"During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? \")]\ntime_spent=time_spent[:-1]\nimport itertools\nplt.figure(figsize=(20,20))\nlength=len(time_spent)\nfor i,j in itertools.zip_longest(time_spent,range(length)):\n    plt.subplot((length\/2),2,j+1)\n    plt.subplots_adjust(wspace=0.2,hspace=0.5)\n    df_2018[i].astype('float').hist(bins=10,edgecolor='black')\n    plt.axvline(df_2018[i].astype('float').mean(),linestyle='dashed',color='r')\n    plt.title(i[161:],size=20)\n    plt.xlabel('% Time')\nplt.show()","d8e0f3b5":"projects=df_2018['Which better demonstrates expertise in data science: academic achievements or independent projects? - Your views:'].value_counts().to_frame()\nprojects.columns=['Count']\nH = Highchart(width=1000, height=500)\n\noptions = {\n    'title': {\n        'text': \"Independent Projects Good or Not?\",\n        'style':{\n            'color': 'white',\n        }\n    },\n    'xAxis': {\n        'categories': list(projects.index),\n        'title': {\n            'text': None\n        },'labels': {\n            'overflow': 'justify',\n            'style': {\n            'color': 'white',\n         }\n        },\n        \n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': None\n        },\n        'labels': {\n            'overflow': 'justify',\n            'style': {\n            'color': 'white',\n         }\n        }\n    },\n    'credits': {\n        'enabled': False\n    },\n    'chart': {\n            'backgroundColor':'black',\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True,\n                'style': {\n            'color': 'white',\n         }\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(projects['Count'])\nH.add_data_set(data1, 'bar')\n\nH","ee9bad56":"cloud=[col for col in df_2018 if col.startswith(\"Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice -\")][:-4]\ncol1,col2=[],[]\nfor i in df_2018[cloud].columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\ncloud1=pd.DataFrame({'Cloud Provider':col1,'Count':col2})\n\ncloud_ml=df_2018[df_2018['Select the title most similar to your current role (or most recent title if retired): - Selected Choice']=='Data Scientist']\ncloud=[col for col in cloud_ml if col.startswith(\"Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice -\")][:-4]\ncol1,col2=[],[]\nfor i in cloud_ml[cloud].columns:\n    col1.append(cloud_ml[i].value_counts().index.values[0])\n    col2.append(cloud_ml[i].value_counts().values[0])\ncloud2=pd.DataFrame({'Cloud Provider':col1,'Count':col2})\n\ncloud=cloud1.merge(cloud2,left_on='Cloud Provider',right_on='Cloud Provider',how='left')\ncloud.columns=['Cloud Provider','Cloud N','Cloud ML']\n\nH = Highchart(width=800, height=400)\n\noptions = {\n    'title': {\n        'text': 'Top Cloud Providers'\n    },\n    'xAxis': {\n        'categories': list(cloud['Cloud Provider']),\n        'title': {\n            'text': None\n        }\n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': 'Count'\n        },\n        'labels': {\n            'overflow': 'justify'\n        }\n    },\n    'legend': {\n        'layout': 'vertical',\n        'align': 'right',\n        'verticalAlign': 'top',\n        'x': -80,\n        'y': 20,\n        'floating': True,\n        'borderWidth': 1,\n        'shadow': True\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(cloud['Cloud N'])\ndata2 = list(cloud['Cloud ML'])\nH.add_data_set(data1, 'bar', 'All Uses')\nH.add_data_set(data2, 'bar', 'ML')\n\nH","71ffae38":"aws=[col for col in df_2018 if col.startswith('Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - AWS') or col.startswith('Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon ')]\ngoogle=[col for col in df_2018 if col.startswith('Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Google') or col.startswith('Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google ')]\ncol1=[]\ncol2=[]\nfor i in df_2018[aws].columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\naws=pd.DataFrame({'Service':col1,'Count':col2})\n\ncol1=[]\ncol2=[]\nfor i in df_2018[google].columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\ngoogle=pd.DataFrame({'Service':col1,'Count':col2})\nf,ax=plt.subplots(1,2,figsize=(25,15))\ngoogle.set_index('Service').plot.barh(width=0.8,ax=ax[0])\naws.set_index('Service').plot.barh(width=0.8,ax=ax[1])\nplt.subplots_adjust(wspace=0.5)\nax[0].set_title('GCP Services')\nax[1].set_title('AWS Services')\nax[0].set_xlim(0,4000,500)\nplt.show()","0a3fc5f9":"frame=[col for col in df_2018 if col.startswith('What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - ')]\nframe=frame[:-2]\ncol1=[]\ncol2=[]\nfor i in df_2018[frame].columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\nframe=pd.DataFrame({'FrameWork':col1,'Count':col2})\nframe=frame.sort_values('Count',ascending=False)\nH = Highchart(width=850, height=500)\n\noptions = {\n    'title': {\n        'text': \"Most commonly used ML FrameWorks\",\n    },\n    'xAxis': {\n        'categories': list(frame['FrameWork']),\n        'title': {\n            'text': None\n        },'labels': {\n            'overflow': 'justify',\n        },\n        \n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': None\n        },\n        'labels': {\n            'overflow': 'justify',\n        }\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True,\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\ndata1 = list(frame['Count'])\nH.add_data_set(data1, 'bar')\n\nH","cd394a29":"viz=[col for col in df_2018 if col.startswith('What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - ')]\nviz=viz[:-2]\ncol1=[]\ncol2=[]\nfor i in df_2018[viz].columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\nviz=pd.DataFrame({'Viz Lib':col1,'Count':col2})\nviz=viz.sort_values('Count',ascending=False)\n\nH = Highchart(width=850, height=500)\n\noptions = {\n    'title': {\n        'text': \"Most commonly used Visualization FrameWorks\",\n    },\n    'xAxis': {\n        'categories': list(viz['Viz Lib']),\n        'title': {\n            'text': None\n        },'labels': {\n            'overflow': 'justify',\n        },\n        \n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': None\n        },\n        'labels': {\n            'overflow': 'justify',\n        }\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True,\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\ndata1 = list(viz['Count'])\nH.add_data_set(data1, 'bar')\n\nH","fb6c5504":"lang=[col for col in df_2018 if col.startswith('What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice -')]\nlang=lang[:-2]\ndf_lang=df_2018[lang]\ndf_lang.columns=[i[102:] for i in lang]\ncol1=[]\ncol2=[]\nfor i in df_2018[lang].columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\nlanguages=pd.DataFrame({'Lang':col1,'Count':col2})\nlanguages=languages.sort_values('Count',ascending=False)\n\nH = Highchart(width=850, height=500)\n\noptions = {\n    'title': {\n        'text': \"Most commonly used Languages\",\n    },\n    'xAxis': {\n        'categories': list(languages['Lang']),\n        'title': {\n            'text': None\n        },'labels': {\n            'overflow': 'justify',\n        },\n        \n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': None\n        },\n        'labels': {\n            'overflow': 'justify',\n        }\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True,\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\ndata1 = list(languages['Count'])\nH.add_data_set(data1, 'bar')\n\nH","3da1a169":"import networkx as nx\nc = df_lang.stack().groupby(level=0).apply(tuple).value_counts()\nout = [i + (j,) for i, j in c.items()]\nout=[word for word in out if len(word)==3]\nlang_net=pd.DataFrame(out)\nlang_net.columns=['Lang 1','Lang 2','Count']\ng = nx.from_pandas_edgelist(lang_net,source='Lang 1',target='Lang 2')\ncmap = plt.cm.RdYlGn\ncolors = [n for n in range(len(g.nodes()))]\nk = 0.35\npos=nx.spring_layout(g, k=k)\nnx.draw_networkx(g,node_size=languages['Count'].values, cmap = cmap, node_color=colors, edge_color='grey', font_size=22, width=lang_net['Count'].values*0.01)\nplt.title('Languages Network',size=50)\nplt.gcf().set_size_inches(25,20)","c859744a":"ind=[col for col in df_2018 if col.startswith('Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - ') or col.startswith('In what industry is your current employer\/contract (or your most recent employer if retired)? - Selected Choice') or col.startswith('Duration (in seconds)')]\nind=ind[:-2]\nlulz=df_2018[ind]\ndataframe=pd.DataFrame()\nfor i in lulz.columns[2:]:\n    abc=lulz.groupby(['In what industry is your current employer\/contract (or your most recent employer if retired)? - Selected Choice',i])['Duration (in seconds)'].count().reset_index()\n    abc.columns=['Industry','Data','Count']\n    dataframe=dataframe.append(abc)\n\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle=le.fit(dataframe['Industry'])\ndataframe['Industry_enc']=le.transform(dataframe['Industry'])\nle=le.fit(dataframe['Data'])\ndataframe['Data_enc']=le.transform(dataframe['Data'])\ndataframe.sort_values(['Industry_enc','Data_enc'],inplace=True)\n\nH = Highchart(width=800, height=800)\ndata= dataframe[['Data_enc','Industry_enc','Count']].values.tolist()\nH.add_data_set(data, series_type='heatmap', borderWidth=1, dataLabels={\n    'enabled': True,\n})\n\nH.set_options('chart', {\n    'style': {\n            'fontFamily': '\\'Unica One\\', sans-serif'\n        },\n    'type': 'heatmap',\n    'plotBorderWidth': 1\n})\nH.set_options('xAxis', {\n    'categories': list(dataframe['Data'].unique())\n})\nH.set_options('yAxis', {\n    'categories': list(dataframe['Industry'].unique())\n})\nH.set_options('title', {\n    'text': \"Industry vs Type of Data Faced\"\n})\nH.set_options('colorAxis', {\n    'min': 0,\n    'minColor': '#FFFFFF',\n    'maxColor': '#00ff00'\n})\nH.set_options('legend', {\n    'align': 'right',\n    'layout': 'vertical',\n    'margin': 0,\n    'verticalAlign': 'top',\n    'y': 25,\n    'symbolHeight': 280\n})\nH.set_options('tooltip', {\n    'formatter': \"function () {\" + \n                \"return 'Industry: '+'<b>' + this.series.yAxis.categories[this.point.x] + '<\/b><br>Frequency: <b>' +\" +\n                    \"this.point.value + '<\/b><br> Data: <b>' + this.series.xAxis.categories[this.point.x] + '<\/b>';\" +\n            \"}\"\n})\nH","770cda05":"train=[col for col in df_2018 if col.startswith('What percentage of your current machine learning\/data science training falls under each category? ')]\ntrain=train[:-2]\nimport math\nplt.figure(figsize=(20,20))\nlength=len(train)\nfor i,j in itertools.zip_longest(train,range(length)):\n    plt.subplot(math.ceil((length\/2)),2,j+1)\n    plt.subplots_adjust(wspace=0.2,hspace=0.5)\n    df_2018[i].astype('float').hist(bins=10,edgecolor='black')\n    plt.axvline(df_2018[i].astype('float').mean(),linestyle='dashed',color='r')\n    plt.title(i[130:],size=20)\n    plt.xlabel('% Time')\nplt.show()","887fe86b":"train=[col for col in df_2018 if col.startswith('What percentage of your current machine learning\/data science training falls under each category? ')]\ntrain=train[:-2]\ndf_ind=df_2018[df_2018['In which country do you currently reside?']=='India']\ndf_usa=df_2018[df_2018['In which country do you currently reside?']=='United States']\nplt.figure(figsize=(20,20))\nlength=len(train)\nfor i,j in itertools.zip_longest(train,range(length)):\n    plt.subplot(math.ceil((length\/2)),2,j+1)\n    plt.subplots_adjust(wspace=0.2,hspace=0.5)\n    df_ind[i].astype('float').hist(bins=10,color='tomato',alpha=0.7,label='India')\n    df_usa[i].astype('float').hist(bins=10,color='lightgreen',alpha=0.7,label='United States')\n    plt.axvline(df_ind[i].astype('float').mean(),linestyle='dashed',color='r')\n    plt.axvline(df_usa[i].astype('float').mean(),linestyle='dashed',color='g')\n    plt.title(i[130:],size=20)\n    plt.xlabel('% Time')\n    plt.legend()\nplt.show()\n","a6673141":"online=[col for col in df_2018 if col.startswith('On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - ')]\nonline=online[:-2]\ncol1=[]\ncol2=[]\nl2=df_2018[online]\nfor i in l2.columns:\n    col1.append(df_2018[i].value_counts().index.values[0])\n    col2.append(df_2018[i].value_counts().values[0])\nonline=pd.DataFrame({'Platform':col1,'Count':col2})\nH = Highchart(width=650, height=500)\noptions = {\n    'chart': {\n        'style': {\n            'fontFamily': '\\'Unica One\\', sans-serif'\n        },\n        'type': 'pie',\n        'options3d': {\n            'enabled': True,\n            'alpha': 45\n        }\n    },\n    'title': {\n        'text': \"Online Platforms\"\n    },\n    'plotOptions': {\n        'pie': {\n            'innerSize': 100,\n            'depth': 45\n        }\n    },\n}\n\ndata = online.values.tolist()\n\nH.set_dict_options(options)\nH.add_data_set(data, 'pie', 'Count')\n\nH","d5a46d49":"ind_ml=df_2018[df_2018['In what industry is your current employer\/contract (or your most recent employer if retired)? - Selected Choice']!='I am a student']\nind_ml['Does your current employer incorporate machine learning methods into their business?'].value_counts().plot.barh(width=0.8,color=sns.color_palette('inferno_r',10))\nplt.gcf().set_size_inches(6,8)\nplt.gca().invert_yaxis()\nplt.title('ML Maturity')","7cc43907":"ind_ml=ind_ml.groupby(['In what industry is your current employer\/contract (or your most recent employer if retired)? - Selected Choice','Does your current employer incorporate machine learning methods into their business?'])['Duration (in seconds)'].count().reset_index()\nind_ml.columns=['Industry','ML','Count']\nle=le.fit(ind_ml['Industry'])\nind_ml['Industry_enc']=le.transform(ind_ml['Industry'])\nle=le.fit(ind_ml['ML'])\nind_ml['ML_enc']=le.transform(ind_ml['ML'])\nind_ml.sort_values(['Industry_enc','ML_enc'],inplace=True)\n\nH = Highchart(width=800, height=800)\ndata= ind_ml[['ML_enc','Industry_enc','Count']].values.tolist()\nH.add_data_set(data, series_type='heatmap', borderWidth=1, dataLabels={\n    'enabled': True,\n})\n\nH.set_options('chart', {\n    'style': {\n            'fontFamily': '\\'Unica One\\', sans-serif'\n        },\n    'type': 'heatmap',\n    'plotBorderWidth': 1\n})\nH.set_options('xAxis', {\n    'categories': list(ind_ml['ML'].unique())\n})\nH.set_options('yAxis', {\n    'categories': list(ind_ml['Industry'].unique())\n})\nH.set_options('title', {\n    'text': \"Industry vs ML Maturity\"\n})\nH.set_options('colorAxis', {\n    'min': 0,\n    'minColor': '#FFFFFF',\n    'maxColor': '#00ff00'\n})\nH.set_options('legend', {\n    'align': 'right',\n    'layout': 'vertical',\n    'margin': 0,\n    'verticalAlign': 'top',\n    'y': 25,\n    'symbolHeight': 280\n})\nH.set_options('tooltip', {\n    'formatter': \"function () {\" + \n                \"return 'Industry: '+'<b>' + this.series.yAxis.categories[this.point.x] + '<\/b><br>Frequency: <b>' +\" +\n                    \"this.point.value + '<\/b><br> Maturity: <b>' + this.series.xAxis.categories[this.point.x] + '<\/b>';\" +\n            \"}\"\n})\nH","65ebcc4e":"ind=df_ind['Does your current employer incorporate machine learning methods into their business?'].value_counts().to_frame()\nusa=df_usa['Does your current employer incorporate machine learning methods into their business?'].value_counts().to_frame()\ndf_c=ind.merge(usa,left_index=True,right_index=True,how='left')\ndf_c.columns=['India','United States']\nH = Highchart(width=800, height=400)\n\noptions = {\n    'title': {\n        'text': 'ML in Business (India vs USA)'\n    },\n    'xAxis': {\n        'categories': list(df_c.index),\n        'title': {\n            'text': None\n        }\n    },\n    'yAxis': {\n        'min': 0,\n        'title': {\n            'text': 'Count'\n        },\n        'labels': {\n            'overflow': 'justify'\n        }\n    },\n    'legend': {\n        'layout': 'vertical',\n        'align': 'right',\n        'verticalAlign': 'top',\n        'x': -30,\n        'y': 20,\n        'floating': True,\n        'borderWidth': 1,\n        'shadow': True\n    },\n    'credits': {\n        'enabled': False\n    },\n    'plotOptions': {\n        'bar': {\n            'dataLabels': {\n                'enabled': True\n            }\n        }\n    }\n}\n\nH.set_dict_options(options)\n\n\n\n\ndata1 = list(df_c['India'])\ndata2 = list(df_c['United States'])\nH.add_data_set(data1, 'bar', 'India')\nH.add_data_set(data2, 'bar', 'United States')\n\nH","3caf05dd":"## ML Maturity (India vs Usa)","0193c14a":"## Data Scientists By Countries","8dc1f663":"## Gender Split","d96e809f":"The above graph shows the number of Data Science Respodents by Country in 2017 and 2018 respectively. Again we can see that **India** has shown a great growth in the number of Data Scientists, as the demand for Data Science professionals have soared in India. **[Read through this article](https:\/\/economictimes.indiatimes.com\/jobs\/indias-demand-for-data-scientists-grows-over-400-report\/articleshow\/64930355.cms)** to get a real Idea about the demand for Data Scientists in India.","54e820b9":"And the clear winner is Pythonnnnnn!!. The obvious reason for this is the ease and flexibility of Python. It is so easy to learn and can be used in any technology domain. However lets compare it with the last year results to get a better idea of how the community thinks","1fcbeada":"## Most Commonly Used Machine Learning Libraries","31c8715c":"## ML Maturity in Business","32563f08":"I was indeed expecting something like this :p. Just look at the University histogram!! It clearly shows how eduaction system in United States is so better as compared to that of India's. \n\nMOOC's are so very famous in India, I have seen so many students go through these extensive online courses. One major reason what I think is the **Education System** in India. Students easily learn stuff that is not taught in the univerities.","4e1fb428":"The recommendation for Python as the first language has shot up sharply. More than 100% rise as compared to 2017. On the contrary, the recommendation for R has gone down. The reason maybe the steep learning curve of R.","875dc04e":"## DataSet Source","9ae466fe":"## Respondents By Country","bf2b2438":"## First Recommended Language","7da5cba3":"As expected, Kaggle has a huge number of student community. I too joined Kaggle as a student and now I am a working professional, but still I love going through Kaggle. ","94f72569":"## How did you learn Data Science??","88633d8d":"## Response Time","bea0507c":"## Age","c99f7fe4":"We did see earlier that the number of Python users are way more than R users according to the survey data. Thus Sklearn being on the most commonly used ML framework was somewhat implicit.","6c45331a":"## Learn Data Science (USA vs India)","4e3a9f97":"We can clearly see that Python is pretty much used with every other language. This shows the versatility of Python. However the major chunk of network is with R and SQL, because of the obvious fact that these data munging and analysis tools are the most frequently tool-set.","39d888fc":"The results are similar to that of last year. Majority of the respondents are from the CS background. However Data Science being a diverse field, people from Non-CS background have a great proportion too.","c5473eca":"Looks like people in the United States are getting old early :p!","43c6045a":"# Kaggle Journey 2017-2018\n\n![](https:\/\/cdn-images-1.medium.com\/max\/920\/1*T5oDltDFi8FQJ8kZdFUMoQ.png)\n\nExactly 2 years ago I joined Kaggle while searching for some small datasets for learning Excel and Pandas. Being a novice and completely new to Data Science, Kaggle Kernels were pretty overwhelming for me in the start. However with the help of the Kaggle Community, everyday is a great learning experience. Kaggle not only helped me in refining my Data Science skills, but also helped me connect with some great people. Cheers to such a great and ever growing community.\n\nNow coming to the dataset, it is the result of the second worldwide survey conducted by Kaggle, which will provide meaningful insights about the people working in the field of Data Science. Kaggle had released it's survey data last year for the first time. Following is my notebook using the dataset: **[Novice To Grandmaster](https:\/\/www.kaggle.com\/ash316\/novice-to-grandmaster)**. With the help of this dataset, we will see how the Kaggle Community has grown and changed in the past year and try to find some interesting patterns and insights that are hidden in this trove of data.\n\nI hope you like this notebook.If you find like this notebook and find it useful, **DO UPVOTE**.","d6a35670":"## Data Science And Cloud\n\nMachine learning was once out of the reach of most enterprise budgets, but today, public cloud providers\u2019 ability to offer machine-learning services makes this technology affordable. ML\/DL requires GPU powered machines which are too costly, but with the advent of powerful virtual instances, the costs have potentially gone down. Being a Cloud Engineer I know how easily we can run and scale ML models\/applications on virtual instances. Lets us now see how the Top 3 Cloud Providers viz AWS, GCP and Azure compete against each other.","6c16cede":"## Online Platforms","05811a46":"## Time Spent in Various Data Science Tasks","11cbeb82":"I have tried to put a lot of information into the map :p. Click on any bubble to get more information about it. Lets look into it in detail.\n\nSo the circle size is proportional to the number of respondents. However the color is represents the growth % in the number of respondents. Looking into the map we can clearly say that USA and India have the highest number of respondents. However India has a 52% growth in respondents, whereas USA has just 12% growth. This growth is evident, as we Indians are the highest producer of Engineers...:p!!\n\nIts not just India but other asian countries like **China,Russia and Vietnam** have also shown good growth. The European continent also has an average growth somewhere between **30-50%**. The only 3 countries that have shown a negative growth in the number of respondents are **Australia, Phillipines and South Korea!**","c98d032a":"It looks like only the Computers\/Technology industries have very well adopted the ML\/DS in their business. The next industry which looks promising is Education. Now a days solutions made by reputed Universities like Stanford, MIT,etc give equal competition to those built by some Top CS companies. ","afa83b31":"As usual, Python leads with a huge margin. A noteable difference as compared to 2017 is that SQL surpasses R by a pretty decent margin. The reason is pretty obvious, SQL is the bread and butter for databases and with the increase in data and databases, the use of SQL will indeed increase.\n\nLets try to make a simple network that will show which all languages are used together.","f1a43ab0":"## UnderGraduate Major","5b7ffcb5":"Jupyter Notebook leads the list with a huge difference. The reason might be because of the wide range of language supported by Jupyter.","8467b5df":"The number of female respondents are still very less as compared to males.There is a huge gender bias as almost **80%** of the respondents are males.However lets check the rise in the numbers compared to 2017 to get a better idea.","4e958b74":"### Age Groups By Country","c3454f8e":"The Maximum Response Time is just crazy...lmao!! Similarly the minimum response time is also funny. The mean response time is on a very higher side due to some outliers like the maximum response time. As far as I remember, I took somewhere between 12-15 mins to complete the survey, and believe that majority of the respondents did take that much time only. Lets check it and make the data speak itself!!","dc2e1a68":"Similar to the last year results, majority of the respondents are young with their age ranges lying between 18-29 years. It will be interesting to see which age-group do the respondents belong to by their countries. For this, lets split the age-groups into 3 distinct parts\n\n - Young (18-34 years)\n - Middle (35-54 years)\n - Old (55-80+ years)","d0848d13":"Matplotlib wins with a huge margin. This was expected because it is the first visualization library any Python user starts with while starting with Data Science Journey!!","7724982a":"Kaggle is still the major source for finding datasets. ","9b37405f":"## Most Used Machine Learning Libraries","27fd7b9c":"## ML Maturity By Industry","7fe1d3a6":"A majority of the respondents(about 55-60 %) said that they either don't use ML or are still exploring or still don't know about it in their business. Since the ML\/DS is boom is a recent thing, I was expecting similar results. Many industries are still researching for ML techniques to implement and integrate them in their existing systems. Lets dig in and check how is it distributed by industries. ","ba3b5a77":"Lets check how many people did respond to the survey!!","08eaecec":"After removing time > 100 minutes, we can see that majority of the respondents finished the survey in less than 20-15 minutes.","1ac0ead8":"We can clearly see that GCP's offers far more ML services as compared to AWS, and these services are also more used as compared to the AWS's ML services!!","a9276722":"## What Type of Data do Industries Deal With?\n\nNot every industry needs to deal with time series data and similarly not every industry deals with audio or video data. Lets check what different types of data the various industries deal with..!","204b90f4":"**Formal education will make you a living; self-education will make you a fortune -Jim Rohn**\n\n - It is evident that many respondents do learn Data Science on their own. I personally haven't taken up any courses till now and have learnt everything on the fly with the help of Kaggle Kernels.\n - With the increased number of Online Courses on various MOOC's, people starting new get a good start to Data Science using these online platforms, and thus Online courses also have a good share.\n - However the low percentages for **Work and Kaggle Competitions** were a bit surprising. I have read many a time that how people learn a lot many new things by competing in a Kaggle Competition. Similarly, I think we get to work on real DS stuff in the industry. However the lower percentages don't reflect this?\n \nLets just break this down and check if we get similar results for the Top 2 Countries viz United States and India.","d5b5d31d":"## AWS vs GCP (Fight For ML)","311cdadb":"## Favorite IDE's","80373da2":"# Stay Tuned... More To Come!!\n### Just short of time...too many things on the plate..:p","f39e6e4b":"## Current Role","d6953446":"Lets go through the Data Science Pipeline stepwise and understand why each phase takes lesser time or more time:\n\n - **Gathering Data**: Undoubtedly the one of the most time consuming part in the entire pipeline. Getting the data can be painstaking and it really depends from where do we fetch our data. If it comes from a publicly hosted site like Kaggle, it is very easy and no time is required. However its not the case in real world. In real world cases, we need to select the right data in the right format and build a secure way of transferring the data flow to our ML models or application.\n - **Cleaning Data**: The most time consuming part, and I am sure no one will disagree on this!! Transforming the data into correct format for the application, detecting and correcting corrupt or inaccurate data, etc all come under data cleaning. The main challenge in this is correction of values to remove duplicates and invalid entries, as deletion of data can lead to information loss. Hence critical decisions and thinking is required, which makes it a time consuming process.\n - **Visualizing Data**: It is probably the least time consuming process(and probably the most enjoyable one..:p), and it reduces even further if we use Enterprise Tools like Tableau,Qlik,Tibco,etc, which helps in building graphs and dashboards with simple drag and drop features.\n - **Model Building**: It is where the data scientists build decide a suitable algorithm ,build predictive models, tune these models,etc. It is the 2nd most time consuming process after Data Gathering.\n - **Putting Model into Production**: Simply it means encapsulating the ML model into an application or hosting it somewhere so that others can use the model with their own data. Now a days it has become very easy to build API's that directly query the ML model and return results based on the user input data. The process has become easier due to the great integration of ML models and cloud deployment, which has infact reduced the time required for production deployment.\n - **Finding Insights and Communicating with Stakeholders**: Finding insights is retrieving all the important patterns and facts in the trove in data and effectively communicating it to the clients with minimum cognitive load. Effective communication and simple but effective visualizations play a very important role in this phase.","34e3cc69":"## Most Used Programming Languages","fea5f6dc":"Due to my wrong calculations, I had previouslt mentioned that the growth is low for the female coders. However thanks to [Heads and Tails](https:\/\/www.kaggle.com\/headsortails) for correcting me on that point. The growth for both the sexes is almost the same i.e around 44%. But still the number of females are still pretty low as compared to the males.","2fb596d9":"People often ask me \"How do I show case my knowledge in a certain domain?\". My simple answer is build projects and upload to your Github profile. The above results also show that Individual projects are indeed a great asset as compared to Acandemic Achievements.","9ce768d3":"## A Simple Language Network","872461cb":"The 5th bar-pair shows how United States does have a great opportunity for ML engineers and Data Scientists. This is one of the main reasons that so many Asian's flock to the United States for better work opportunities or even better and relevant work experience.\n\nHowever the 1st bar-pair does show that India also has great potential for becoming a ML\/AI\/DS hotspot, and with the increase in demand for Data Scientists in the past few years in India, I am sure it will catch up soon with the United States. Have a look at **[this article](https:\/\/www.analyticsindiamag.com\/top-countries-hiring-most-number-of-artificial-intelligence-machine-learning-experts\/)**, which mentions the Top countries which have a great potential for ML\/DS.","e3debdc2":"AWS is a clear winner among the Cloud Providers. The reason is simply due to the variety of services available on AWS. However being a Cloud Engineer, I think I can add a point here. As far as I have seen, GCP beats AWS in the Machine Learning capability part. Also after my own small research, I did find that many small ML\/AI ventures do go for GCP rather than AWS. \n\nLets dig a bit further and check which all services are mostly used in AWS and GCP!!","637eac9e":"So about **24k** people did respond to the survey, which is almost **43%** more than the number of respondents in 2017. This shows how actively the Data Science Community is growing.","c20334ea":"## Individual Projects or Academic Achievements"}}