{"cell_type":{"30085373":"code","d9405dfa":"code","d3890e76":"code","e70f24dd":"code","f0e7931b":"code","1e57a2a2":"code","c40d67d9":"code","19300325":"code","75ad4ab3":"code","d61dcf90":"code","691426f4":"code","501bb6ab":"code","7d932284":"code","6f1fc6e8":"code","cc9db599":"markdown","c7929bac":"markdown","1edebea4":"markdown","94220ee1":"markdown","7701b67f":"markdown","fade2587":"markdown","0250abf9":"markdown","8c2db5a1":"markdown","02072735":"markdown","84231fc7":"markdown","613fef6c":"markdown","8df5e315":"markdown","bf1e07c6":"markdown"},"source":{"30085373":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.base import BaseEstimator\nfrom sklearn.metrics import mean_squared_error, log_loss, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler","d9405dfa":"class SGDRegressor(BaseEstimator):\n    # you code here\n    def __init__(self):\n        pass\n        \n    def fit(self, X, y):\n        pass\n                  \n    def predict(self, X):\n        pass                ","d3890e76":"data_demo = pd.read_csv('..\/input\/weights_heights.csv')","e70f24dd":"plt.scatter(data_demo['Weight'], data_demo['Height']);\nplt.xlabel('Weight (lbs)')\nplt.ylabel('Height (Inch)')\nplt.grid();","f0e7931b":"X, y = data_demo['Weight'].values, data_demo['Height'].values","1e57a2a2":"X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                     test_size=0.3,\n                                                     random_state=17)","c40d67d9":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.reshape([-1, 1]))\nX_valid_scaled = scaler.transform(X_valid.reshape([-1, 1]))","19300325":"# you code here","75ad4ab3":"# you code here","d61dcf90":"# you code here","691426f4":"# you code here","501bb6ab":"# you code here\nsgd_holdout_mse = 10","7d932284":"# you code here\nlinreg_holdout_mse = 9","6f1fc6e8":"try:\n    assert (sgd_holdout_mse - linreg_holdout_mse) < 1e-4\n    print('Correct!')\nexcept AssertionError:\n    print(\"Something's not good.\\n Linreg's holdout MSE: {}\"\n          \"\\n SGD's holdout MSE: {}\".format(linreg_holdout_mse, \n                                            sgd_holdout_mse))","cc9db599":"Draw chart of model weights ($w_0$ and $w_1$) behavior during training.","c7929bac":"Train created `SGDRegressor` with `(X_train_scaled, y_train)` data. Leave default parameter values for now.","1edebea4":"# <center> Assignment #8 (demo)\n\n## <center> Implementation of online regressor","94220ee1":"Do the same thing for `LinearRegression` class from `sklearn.linear_model`. Evaluate MSE for hold-out set.","7701b67f":"Make a prediction for hold-out  set `(X_valid_scaled, y_valid)` and check MSE value.","fade2587":"Here we'll implement a regressor trained with stochastic gradient descent (SGD). Fill in the missing code. If you do evething right, you'll pass a simple embedded test.","0250abf9":"Perform train\/test split and scale data.","8c2db5a1":"Draw a chart with training process  \u2013 dependency of mean squared error from the i-th SGD iteration number.","02072735":"Print the minimal value of mean squared error and the best weights vector.","84231fc7":"Implement class `SGDRegressor`. Specification:\n- class is inherited from `sklearn.base.BaseEstimator`\n- constructor takes parameters `eta` \u2013 gradient step ($10^{-3}$ by default) and `n_epochs` \u2013 dataset pass count (3 by default)\n- constructor also creates `mse_` and `weights_` lists in order to track mean squared error and weight vector during gradient descent iterations\n- Class has `fit` and `predict` methods\n- The `fit` method takes matrix `X` and vector `y` (`numpy.array` objects) as parameters, appends column of ones to  `X` on the left side, initializes weight vector `w` with **zeros** and then makes `n_epochs` iterations of weight updates (you may refer to this [article](https:\/\/medium.com\/open-machine-learning-course\/open-machine-learning-course-topic-8-vowpal-wabbit-fast-learning-with-gigabytes-of-data-60f750086237) for details), and for every iteration logs mean squared error and weight vector `w` in corresponding lists we created in the constructor. \n- Additionally the `fit` method will create `w_` variable to store weights which produce minimal mean squared error\n- The `fit` method returns current instance of the `SGDRegressor` class, i.e. `self`\n- The `predict` method takes `X` matrix, adds column of ones to the left side and returns prediction vector, using weight vector `w_`, created by the `fit` method.","613fef6c":"Let's test out the algorithm on height\/weight data. We will predict heights (in inches) based on weights (in lbs).","8df5e315":"## <center>Linear regression and Stochastic Gradient Descent","bf1e07c6":"<center>\n<img src=\"https:\/\/habrastorage.org\/files\/fd4\/502\/43d\/fd450243dd604b81b9713213a247aa20.jpg\" \/>\n    \n## [mlcourse.ai](https:\/\/mlcourse.ai) \u2013 Open Machine Learning Course \n\nAuthor: [Yury Kashnitskiy](https:\/\/yorko.github.io). Translated by [Sergey Oreshkov](https:\/\/www.linkedin.com\/in\/sergeoreshkov\/). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/) license. Free use is permitted for any non-commercial purpose."}}