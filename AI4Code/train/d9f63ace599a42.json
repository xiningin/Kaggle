{"cell_type":{"10edc43c":"code","8b7a5f10":"code","a4d9b22a":"code","2529e21d":"code","4bcb92c5":"code","a0b1ace5":"code","1d8615c1":"code","af3c93d7":"code","053346af":"code","3365bce6":"code","7530262d":"code","e02c8f54":"code","2dcb57bf":"code","4b144d36":"markdown","cecb3152":"markdown","d75de0ea":"markdown","9a94c6ee":"markdown","dde2ca95":"markdown","e45a66aa":"markdown","e3c7b90c":"markdown","2abb761b":"markdown","ee59a0a6":"markdown"},"source":{"10edc43c":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfrom pandas.io.json import json_normalize\nimport json\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport seaborn as sns\n%matplotlib inline\n\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nimport torch\nimport torch.nn as nn\nT = torch.Tensor\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\n\nfrom keras.utils import to_categorical","8b7a5f10":"# PATHS\n\nPATH = '..\/input\/abstraction-and-reasoning-challenge\/'\nTRAIN_PATH = PATH + 'training\/'\nTEST_PATH = PATH + 'test\/'\n\ntrain_input, train_output, train_ids = [], [], []\ntest_input,  test_output, test_ids = [], [], []\nfile_names = []","a4d9b22a":"# Function to Read file data\n\ndef read_json():\n    \n    idx = 0\n    \n    for file_name in os.listdir(TRAIN_PATH):\n        full_file_path = TRAIN_PATH + file_name\n        with open (TRAIN_PATH+file_name) as f:\n            file = json.load(f)\n            #Each train data has more than one ip\/op pairs, so looping over each pair \n            for i in range(len(file['train'])):\n                in_data, out_data = file['train'][i]['input'],file['train'][i]['output']\n                # Tagging all the train data under one comming id for segregation of different sets\n                train_ids.append(idx)\n                train_input.append(in_data)\n                train_output.append(out_data)\n                file_names.append(file_name)\n\n            # There is one set of test data in each file sample, hence no need to loop     \n            in_data, out_data = file['test'][0]['input'],file['test'][0]['output']\n            test_ids.append(idx)\n            test_input.append(in_data)\n            test_output.append(out_data)\n\n        idx +=1\n    \nread_json()                          \ntrain_df = pd.DataFrame(zip(train_ids, train_input, train_output, file_names), columns = ['id','input','output','filename'])\ntest_df = pd.DataFrame(zip(test_ids, test_input, test_output), columns = ['id','input','output'])          ","2529e21d":"display(train_df.head(10))\ndisplay(test_df.head(4))","4bcb92c5":"cmap = colors.ListedColormap(\n            ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n             '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nfig, ax = plt.subplots(1,4, figsize=(15,5))\nnorm = colors.Normalize(vmin=0, vmax=9)\n\nax[0].imshow(train_df[train_df['id'] == 85]['input'].iloc[0], cmap=cmap, norm=norm)\nax[1].imshow(train_df[train_df['id'] == 85]['output'].iloc[0], cmap=cmap, norm=norm)\nax[2].imshow(test_df[test_df['id'] == 85]['input'].iloc[0], cmap=cmap, norm=norm)\nax[3].imshow(test_df[test_df['id'] == 85]['output'].iloc[0], cmap=cmap, norm=norm)\n\nax[0].set_xticklabels([])\nax[1].set_xticklabels([])\nax[2].set_xticklabels([])\nax[3].set_xticklabels([])\n\nax[0].set_yticklabels([])\nax[1].set_yticklabels([])\nax[2].set_yticklabels([])\nax[3].set_yticklabels([])\n\n\nax[0].grid(True)\nax[1].grid(True)\nax[2].grid(True)\nax[3].grid(True)\n\n_ = ax[0].set_title('Train Input')\n_ = ax[1].set_title('Train Output')\n_ = ax[2].set_title('Test Input')\n_ = ax[3].set_title('Test Input')","a0b1ace5":"'''\nPass the id of a particular train\/test sample, the function will \nplot 3 train inputs and thier corresponding outputs.\nThe 4th pair ip\/op plot would be of Test sample belonging to the respective train samples\n'''\ndef plot_abstracts(idx):\n    cmap = colors.ListedColormap(\n            ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n             '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    fig, ax = plt.subplots(2,4, figsize=(15,10))\n    norm = colors.Normalize(vmin=0, vmax=9)\n    ax[0][0].imshow(train_df[train_df['id'] == idx]['input'].iloc[0], cmap=cmap, norm=norm)\n    ax[0][1].imshow(train_df[train_df['id'] == idx]['output'].iloc[0], cmap=cmap, norm=norm)\n    ax[0][2].imshow(train_df[train_df['id'] == idx]['input'].iloc[1], cmap=cmap, norm=norm)\n    ax[0][3].imshow(train_df[train_df['id'] == idx]['output'].iloc[1], cmap=cmap, norm=norm)\n\n    ax[1][0].imshow(train_df[train_df['id'] == idx]['input'].iloc[2], cmap=cmap, norm=norm)\n    ax[1][1].imshow(train_df[train_df['id'] == idx]['output'].iloc[2], cmap=cmap, norm=norm)\n    ax[1][2].imshow(test_df[test_df['id'] == idx]['input'].iloc[0], cmap=cmap, norm=norm)\n    ax[1][3].imshow(test_df[test_df['id'] == idx]['output'].iloc[0], cmap=cmap, norm=norm)\n\n    ax[0][0].set_xticklabels([])\n    ax[0][1].set_xticklabels([])\n    ax[0][2].set_xticklabels([])\n    ax[0][3].set_xticklabels([])\n\n    ax[1][0].set_xticklabels([])\n    ax[1][1].set_xticklabels([])\n    ax[1][2].set_xticklabels([])\n    ax[1][3].set_xticklabels([])\n\n    ax[0][0].set_yticklabels([])\n    ax[0][1].set_yticklabels([])\n    ax[0][2].set_yticklabels([])\n    ax[0][3].set_yticklabels([])\n\n    ax[1][0].set_yticklabels([])\n    ax[1][1].set_yticklabels([])\n    ax[1][2].set_yticklabels([])\n    ax[1][3].set_yticklabels([])\n\n    ax[0][0].grid(True)\n    ax[0][1].grid(True)\n    ax[0][2].grid(True)\n    ax[0][3].grid(True)\n\n    ax[1][0].grid(True)\n    ax[1][1].grid(True)\n    ax[1][2].grid(True)\n    ax[1][3].grid(True)\n\n    _ = ax[0][0].set_title('Train Input')\n    _ = ax[0][1].set_title('Train Output')\n    _ = ax[0][2].set_title('Train Input')\n    _ = ax[0][3].set_title('Train Input')\n\n    _ = ax[1][0].set_title('Train Input')\n    _ = ax[1][1].set_title('Train Output')\n    _ = ax[1][2].set_title('Test Input')\n    _ = ax[1][3].set_title('Test Input')\n    \n    plt.show()\n\nplot_abstracts(110)","1d8615c1":"plot_abstracts(180)","af3c93d7":"plot_abstracts(150)","053346af":"# Creating 1000 samples from a set of training sample for Training\ndef repeat_matrix(a):\n    return np.concatenate([a]*((1000 \/\/ len(a)) + 1))[:1000]\n\n\ndef get_outp(outp):\n    outp_matrix_dims = np.shape(outp)\n    outp_probs_len = np.shape(outp)[0]*np.shape(outp)[1]*10\n    outp = to_categorical(np.array(outp).flatten(),\n                          num_classes=10).flatten()\n\n    return outp, outp_probs_len, outp_matrix_dims","3365bce6":"class CreateDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = repeat_matrix(X)\n        self.y = repeat_matrix(y)\n        \n    def __len__(self):\n        return SIZE\n    \n    def __getitem__(self, idx):\n        inp = self.X[idx]\n        outp = self.y[idx]\n        outp, outp_probs_len, outp_matrix_dims = get_outp(outp)\n        \n        return inp, outp, outp_probs_len, outp_matrix_dims, self.y","7530262d":"class Net(nn.Module):\n    def __init__(self, inp_dim=(10, 10), outp_dim=(10, 10)):\n        super(Net, self).__init__()\n        \n        KERNEL_SIZE = 3\n        if inp_dim[0] < 5 or inp_dim[1] < 5:\n            KERNEL_SIZE = 1\n\n        self.conv2d_1 = nn.Conv2d(3, 50, kernel_size=KERNEL_SIZE)\n        self.conv2d_2 = nn.Conv2d(50, 100, kernel_size=KERNEL_SIZE)\n        self.dense_1 = nn.Linear(100, outp_dim[0]*outp_dim[1]*10)\n        \n        self.relu = nn.ReLU()\n        self.softmax = nn.Softmax(dim=1)\n        \n\n    def forward(self, x, outp_dim):\n        \"\"\"\n        1.  x.shape = (128,width,height)  - 128 is the batch size set by DataLoader\n            unsqueeze will add a new dimension (1) to the dataset\n            x.shape = (1, 128, height, width)\n        2.  [x.unsqueeze(0)*3] will create three tensors having new dimension (3 channels for RGB )\n            we now concatenate the three tensors creating a new tensor\n            x.shape = (3, 128, width, height)\n        3.  Format of Tensor for Training-\n            # 4d: [batch_size, channels, height, width]\n            # used for nn.Conv2d() input.\n            \n            for this we just have to change the places of batch_size(128) and channels(3) in x\n            hence we use permute to reshape x\n            \n        \"\"\"\n        x = torch.cat([x.unsqueeze(0)]*3)\n        x = x.permute((1, 0, 2, 3)).float()\n        self.conv2d_1.in_features = x.shape[1]\n        conv_1_out = self.relu(self.conv2d_1(x))\n        self.conv2d_2.in_features = conv_1_out.shape[1]\n        conv_2_out = self.relu(self.conv2d_2(conv_1_out))\n        \n        self.dense_1.out_features = outp_dim\n        feature_vector, _ = torch.max(conv_2_out, 2)\n        feature_vector, _ = torch.max(feature_vector, 2)\n        logit_outputs = self.dense_1(feature_vector)\n        \n        out = []\n        for idx in range(logit_outputs.shape[1]\/\/10):\n            out.append(self.softmax(logit_outputs[:, idx*10: (idx+1)*10]))\n        return torch.cat(out, axis=1)","e02c8f54":"def transform_dim(inp_dim, outp_dim, test_dim):\n    return (test_dim[0]*outp_dim[0]\/inp_dim[0],\n            test_dim[1]*outp_dim[1]\/inp_dim[1])\n\ndef resize(x, test_dim, inp_dim):\n    if inp_dim == test_dim:\n        return x\n    else:\n        return cv2.resize(flt(x), inp_dim,\n                          interpolation=cv2.INTER_AREA)\n\ndef flt(x): return np.float32(x)\ndef npy(x): return x.cpu().detach().numpy()\ndef itg(x): return np.int32(np.round(x))","2dcb57bf":"EPOCHS = 50\nBATCH_SIZE = 128\nSIZE=1000\n\nidx = 0\nstart = time.time()\npred_y = []\ntest_y = []\n\nfor id_val in list(set(train_df['id'])):\n    X_train = train_df[train_df['id'] == id_val]['input'].values\n    X_train = [cv2.resize(np.float32(x), np.shape(X_train[0])) for x in X_train]\n    \n    y_train = train_df[train_df['id'] == id_val]['output'].values\n    y_train = [cv2.resize(np.float32(y), np.shape(y_train[0])) for y in y_train]\n    \n    y_test = test_df[test_df['id'] == id_val]['output'].values\n    y_test = [cv2.resize(np.float32(y), np.shape(y_train[0])) for y in y_test]\n    \n    X_test = test_df[test_df['id'] == id_val]['input'].values\n    X_test = np.array([cv2.resize(np.float32(x), np.shape(X_train[0])) for x in X_test])\n    X_test = X_test.reshape(np.shape(X_train[0]))\n    \n    \n    train_set = CreateDataset(X_train, y_train)\n    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n\n    inp_dim = np.array(X_train[0]).shape\n    outp_dim = np.array(y_train[0]).shape\n    network = Net(inp_dim, outp_dim).cuda()\n    optimizer = Adam(network.parameters(), lr=0.01)\n    \n    for epoch in range(EPOCHS):\n        for train_batch in train_loader:\n            train_X, train_y, out_d, d, out = train_batch\n            train_preds = network.forward(train_X.cuda(), out_d.cuda())\n            train_loss = nn.MSELoss()(train_preds, train_y.cuda())\n            \n            optimizer.zero_grad()\n            train_loss.backward()\n            optimizer.step()\n\n    end = time.time() \n    print(f\"Train sample id {idx}\")\n    print(\"Train loss: \" + str(np.round(train_loss.item(), 3)) + \"   \" +\\\n          \"Total time: \" + str(np.round(end - start, 1)) + \" s\" + \"\\n\")\n    \n    \n    test_dim = X_test.shape\n    test_preds = npy(network.forward(T(X_test).unsqueeze(0).cuda(), out_d.cuda()))\n    test_preds = np.argmax(test_preds.reshape((10, *outp_dim)), axis=0)\n    pred_y.append(itg(resize(test_preds, np.shape(test_preds),\n                                           tuple(itg(transform_dim(inp_dim,\n                                                                   outp_dim,\n                                                                   test_dim))))))\n    test_y.append(y_test)\n    \n    # Limiting Training to 50 samples\n    if (idx==50):\n        break\n   \n    idx += 1\n","4b144d36":"<center><h2>Plotting 3 Train samples and corresponding Test Input & Output<\/h2><\/center>","cecb3152":"<center>Plot function<\/center>","d75de0ea":"<center><h3>Training Model<\/center>","9a94c6ee":"<h1 style=\"font-family:verdana;\"> <center>\ud83d\udcda Introduction \ud83d\udcda<\/center> <\/h1>\n\n***\n\n![image.png](attachment:image.png)\n\n\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.4em;\">\n    <center>\n        \ud83d\udccc <span style=\"color:crimson;\">Abstraction and Reasoning Challenge (ARC).<\/span> \n<\/center> \n    <center>\n    In this kernel we will build an algorithm that solve abstract reasoning tasks. <br>\n<br>\n        Classic machine learning problems generally involve one specific task which can be solved by training on millions of data samples. But in this challenge, we need to build an algorithm that can learn patterns from a minimal number of examples.\n    <\/center>\n    \n    \n<\/div>","dde2ca95":"<center><h2>Plot Train\/Test Input\/Output<\/h2><\/center>","e45a66aa":"<center><h2>Importing Libraries<\/h2><\/center>","e3c7b90c":"<center><h3>Creating Network of Conv & Dense Layers<\/center>","2abb761b":"<center><h2>Creating Dataset for PyTorch<\/h2><\/center>","ee59a0a6":"<h2><center>Loading Data<\/center>"}}