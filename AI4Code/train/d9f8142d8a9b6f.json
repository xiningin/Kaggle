{"cell_type":{"5346bb3b":"code","09b65ffc":"code","5ae4ad4c":"code","3698149c":"code","7771cc0d":"code","d96a2641":"code","58c3c96a":"code","c853228b":"code","82ea9a84":"code","d621cccc":"code","ea3e7540":"code","13e6fa2a":"code","700cb116":"code","4213d253":"code","d711c5db":"code","951dd959":"code","f574a8fe":"code","3565446a":"code","8704ba22":"code","fbfc2aef":"code","9ff148e9":"code","518db1e2":"code","57ff4743":"code","64003ecc":"code","f05691ef":"code","c6a556ab":"code","478eff3c":"markdown","131aee7e":"markdown","36f4733a":"markdown","ed7e39b9":"markdown","7b2d2366":"markdown","e2c558be":"markdown","940f33aa":"markdown","8506de04":"markdown","8bcffbf6":"markdown","1c954058":"markdown"},"source":{"5346bb3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","09b65ffc":"import numpy as np\nimport pandas as pd\nimport pylab as py\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz ,DecisionTreeRegressor\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB, ComplementNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neural_network import MLPClassifier,MLPRegressor\nfrom sklearn.base import clone","5ae4ad4c":"#url ='https:\/\/raw.githubusercontent.com\/birdtbird\/for_superAI_file\/main\/train%20(1).csv'\nTitanic = pd.read_csv('..\/input\/titanic\/train.csv')#training data\nTitanic.head()","3698149c":"DropList = ['Name','Ticket','Fare','Embarked','Fare']\ntrainingD =Titanic.drop(columns=DropList)\ntrainingD.head()","7771cc0d":"trainingD.isnull().values.any()","d96a2641":"trainingD = trainingD.dropna()","58c3c96a":"trainingD.isnull().values.any()","c853228b":"sort=\"Survived\"\ntrainingD_Id = trainingD[[sort,\"PassengerId\"]].groupby(sort).count()\nprint(trainingD_Id)\ntrainingD.Survived.isnull().values.any()","82ea9a84":"sort=\"Pclass\"\ntrainingD_Id = trainingD[[sort,\"PassengerId\"]].groupby(sort).count()\nprint(trainingD_Id)\ntrainingD.Pclass.isnull().values.any()","d621cccc":"sort=\"Age\"\ntrainingD_Id = trainingD[[sort,\"PassengerId\"]].groupby(sort).count()\nprint(trainingD_Id)\ntrainingD.Age.isnull().values.any()","ea3e7540":"plot = pd.Series(Titanic.Age)\nplot.plot(kind='bar')","13e6fa2a":"sort=\"SibSp\"\ntrainingD_Id = trainingD[[sort,\"PassengerId\"]].groupby(sort).count()\nprint(trainingD_Id)\ntrainingD.SibSp.isnull().values.any()","700cb116":"sort=\"Parch\"\ntrainingD_Id = trainingD[[sort,\"PassengerId\"]].groupby(sort).count()\nprint(trainingD_Id)\ntrainingD.Parch.isnull().values.any()","4213d253":"sort=\"Cabin\"\ntrainingD_Id = trainingD[[sort,\"PassengerId\"]].groupby(sort).count()\nprint(trainingD_Id)\ntrainingD.Cabin.isnull().values.any()","d711c5db":"#url ='https:\/\/raw.githubusercontent.com\/birdtbird\/for_superAI_file\/main\/test.csv'\nTestD = pd.read_csv('..\/input\/titanic\/test.csv')#Test data\nTestD.head()","951dd959":"DTC = DecisionTreeClassifier()\nDTR = DecisionTreeRegressor()\n\nNB=GaussianNB()\nMNB = MultinomialNB()\nBNB = BernoulliNB()\nCat_NB = CategoricalNB()\nComNB = ComplementNB()\n\nMLPC = MLPClassifier()\nMLPR = MLPRegressor()\n\nModelList = [DTC, DTR, NB, MNB, BNB, Cat_NB, ComNB, MLPC, MLPR]\nModelName = ['DecisionTreeClassifier', 'DecisionTreeRegressor', 'GaussianNB',\n             'MultinomialNB', 'BernoulliNB', 'CategoricalNB', 'ComplementNB',\n             'MLPClassifier','MLPRegressor']","f574a8fe":"def TestModel(model,Y_Output,Y_Test,Name):\n  Y_Output=model.predict(X_T)\n  print(Name,\" Accuracy:\",metrics.accuracy_score(Y_Test, Y_Output.astype(int)))\n  #print(Name,\" Accuracy:\",metrics.accuracy_score(Y_Test, Y_Output))\n  #print(Y_Output)\n  #print(Y_Test.to_numpy())","3565446a":"EXcepFeature = ['Sex','Cabin','Survived']\n\nX = trainingD.drop(EXcepFeature,axis =1 )\nY = trainingD.Survived\n\n# No 5-fold cross validation\nX,X_T,Y,Y_T =train_test_split(X, Y, test_size=0.2, random_state=1)\n#  pass()\n\nfor i in range(len(ModelList)):\n  model = clone(ModelList[i])\n  Name  = ModelName[i]\n  model.fit(X,Y)\n  Y_Output = model.predict(X_T)\n  TestModel(model,Y_Output,Y_T,Name)","8704ba22":"DTC = DecisionTreeClassifier()\nDTR = DecisionTreeRegressor()\n\nNB=GaussianNB()\nMNB = MultinomialNB()\nBNB = BernoulliNB()\nComNB = ComplementNB()\n\nMLPC = MLPClassifier()\nMLPR = MLPRegressor()\n\nModelList = [DTC, DTR, NB, MNB, BNB, ComNB, MLPC, MLPR]\nModelName = ['DecisionTreeClassifier', 'DecisionTreeRegressor', 'GaussianNB',\n             'MultinomialNB', 'BernoulliNB','ComplementNB',\n             'MLPClassifier','MLPRegressor']","fbfc2aef":"def TestModelWithFiveFold(model,i,Name):\n  test = listFold[i]\n  X_test=test.drop( EXcepFeature,axis =1 )\n  Y_Test=test.Survived\n  Y_Output=model.predict(X_test)\n  #Y_Output = np.where(Y_Output.astype(int) <0.8,Y_Output,0)\n  precisionLO, recallLO, thresholdsLO = cal_precision_recall_f1(Y_Output,Y_Test)\n  acc = metrics.accuracy_score(Y_Test, Y_Output.astype(int))\n\n  precision.append(precisionLO)\n  recall.append(recallLO)\n  thresholds.append(thresholdsLO)\n  Accuracy.append(acc)\n\n  print(Name,\" Accuracy : \",acc)\n  #print('precision : ',precisionLO,)\n  #print('recall : ',recallLO)\n  #print('thresholds : ',thresholdsLO)\n\n  #print(Name,\" Accuracy:\",metrics.accuracy_score(Y_Test, Y_Output))\n  #print(Y_Output)\n  #print(Y_Test.to_numpy())","9ff148e9":"def cal_precision_recall_f1(lab,prob):\n  slab = lab[np.argsort(-prob)]\n  rlist = []\n  prlist = []\n  relist = []\n  f1list = []\n  tplist = []\n  fplist = []\n  tnlist = []\n  fnlist = []\n  for i in range(len(slab)):\n    s = slab[i]\n    rlist.append(s)\n    pr = sum(rlist)\/len(rlist)\n    prlist.append(pr)\n    re = sum(rlist)\/sum(slab)\n    relist.append(re)\n    f1 = 2*((pr*re)\/(pr+re))\n    f1list.append(f1)\n  return prlist,relist,f1list\n","518db1e2":"def cal_roc(lab,prob):\n  slab = lab[np.argsort(-prob)]\n  tpr_list = []\n  fpr_list = []\n  pre_list = []\n  rec_list = []\n  f1_list = []\n  preres = np.zeros(len(lab))\n  for i in range(len(slab)):\n    s = slab[i]\n    preres[i] = 1\n    tp = sum((slab == preres) & (slab==1))\n    tn = sum((slab == preres) & (slab==0))\n    fp = sum((slab != preres) & (slab==0))\n    fn = sum((slab != preres) & (slab==1))\n    tprate = tp\/(tp+fn)\n    fprate = fp\/(fp+tn)\n\n    pre = tp\/(tp+fp)\n    rec = tp\/(tp+fn)\n\n    tpr_list.append(tprate)\n    fpr_list.append(fprate)\n    pre_list.append(pre)\n    rec_list.append(rec)\n\n    f1 = 2*((pre*rec)\/(pre+rec))\n    f1_list.append(f1)\n  \n\n  ap = np.mean(pre_list)\n  auc = np.mean(tpr_list)\n\n  return tpr_list,fpr_list,pre_list,rec_list,f1_list,ap,auc","57ff4743":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nEXcepFeature = ['Sex','Cabin','Survived']\n\nglobal precision, recall, thresholds, Accuracy\nprecision = []\nrecall = []\nthresholds = []\nAccuracy = []\n\n#with 5-fold cross validation\n\na,_ =trainingD.shape\nXFold_1=trainingD.loc[np. array([i for i in range(1,a+1)])%5==0,:]\nXFold_2=trainingD.loc[np. array([i for i in range(1,a+1)])%5==1,:]\nXFold_3=trainingD.loc[np. array([i for i in range(1,a+1)])%5==2,:]\nXFold_4=trainingD.loc[np. array([i for i in range(1,a+1)])%5==3,:]\nXFold_5=trainingD.loc[np. array([i for i in range(1,a+1)])%5==4,:]\nlistFold=[XFold_1,XFold_2,XFold_3,XFold_4,XFold_5]\n##############################################################\n\nfor i in range(0,5):\n  print('XFold_%s' % (i+1))\n  for model,Name in zip(ModelList,ModelName):\n    for j in range(0,5):\n      if j==i:\n        continue\n      train = listFold[j]\n      X = train.drop(EXcepFeature,axis =1 )\n      Y = train.Survived\n      model=model.fit(X,Y)\n    TestModelWithFiveFold(model,i,Name)\n    print('------------------------------------------------------------------------------------------------------------')\n  print('oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo')","64003ecc":"P=[]\nG=[]\nlistA=[]\nc=0\nA=0\nfor c in range(8):\n  print(ModelName[c])\n  plt.plot(recall[c],precision[c])\n  plt.plot(recall[c+1*8],precision[c+1*8])\n  plt.plot(recall[c+2*8],precision[c+2*8])\n  plt.plot(recall[c+3*8],precision[c+3*8])\n  plt.plot(recall[c+4*8],precision[c+4*8])\n  plt.show()\n  \n","f05691ef":"P=[]\nG=[]\nlistA=[]\nc=0\nA=0\nfor c in range(8):\n  print(ModelName[c])\n  plt.plot(thresholds[c])\n  plt.plot(thresholds[c+1*8])\n  plt.plot(thresholds[c+2*8])\n  plt.plot(thresholds[c+3*8])\n  plt.plot(thresholds[c+4*8])\n  plt.show()","c6a556ab":"C=0\nA=0\nfor i,j in zip(recall,precision):\n  plt.plot(i,j)\n  plt.show()","478eff3c":"check the data that we will use to train ","131aee7e":"import test case (not use in code)","36f4733a":"plot F1","ed7e39b9":"strat cleaning data","7b2d2366":"22p22c0265_\u0e17\u0e31\u0e0a\u0e0a\u0e1e\u0e07\u0e29\u0e4c_W2HW2_27092020","e2c558be":"Plot all recall,precision graph","940f33aa":"plot all recall precision in every model.","8506de04":"start training model .I had use \n* DecisionTreeClassifier \n* DecisionTreeRegressor \n* GaussianNB MultinomialNB \n* BernoulliNB \n* CategoricalNB \n* ComplementNB \n* MLPClassifier \n* MLPRegressor ","8bcffbf6":"import data from kaggle","1c954058":"get rip all null values in the table"}}