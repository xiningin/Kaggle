{"cell_type":{"01caf148":"code","3d3d9b6b":"code","e8feb364":"code","a0dcdbe9":"code","19eed28b":"code","d73ed6a4":"code","7291042c":"code","3c9268d2":"code","a7f3f52d":"code","98197a2e":"code","7f085e32":"code","ff3cf353":"code","8e59857d":"code","6cb8db1e":"code","70f51410":"code","44417a51":"code","6bf55eab":"code","ec2e31ae":"code","100dc1bf":"code","ac3835c2":"code","51e08b1c":"code","e8cad2a4":"code","e19bf433":"code","b48be739":"code","a67b22c2":"code","e2f2a8b5":"code","92ef6aec":"code","f2fe1946":"code","a93cbff7":"code","81600711":"code","1dc6c853":"code","962159a8":"markdown","9435099f":"markdown","6065d303":"markdown","20bad194":"markdown","57fd0424":"markdown","4c48d91c":"markdown","a1f6a1d9":"markdown","5bf47419":"markdown","88824220":"markdown","8937a67e":"markdown","9184ce6b":"markdown","c3542b3c":"markdown","7d047f48":"markdown","e8284764":"markdown","dc347587":"markdown","b6eb5d3d":"markdown","59f6cccd":"markdown"},"source":{"01caf148":"!pip install opendatasets --upgrade --quiet","3d3d9b6b":"import os\nimport torch\nimport torchvision\nimport tarfile\nimport torch.nn as nn\nimport numpy as np\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport opendatasets as od\n%matplotlib inline\n\nmatplotlib.rcParams['figure.facecolor'] = '#ffffff'","e8feb364":"data_dir = '..\/input\/covid19-image-dataset\/Covid19-dataset'\n\nprint(os.listdir(data_dir))\nprint(os.listdir(data_dir+'\/train'))","a0dcdbe9":"# stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\ntrain_tfms = tt.Compose([tt.Resize((256,256)),\n                         tt.RandomCrop(256, padding=4, padding_mode='reflect'),\n                         tt.RandomHorizontalFlip(),\n                         tt.ToTensor(),\n                         # tt.Normalize(*stats, inplace=True)\n                         ])\n\nvalid_tfms = tt.Compose([tt.Resize((256,256)),\n                         tt.ToTensor(),\n                         # tt.Normalize(*stats)\n                         ])","19eed28b":"train_ds = ImageFolder(data_dir+'\/train', train_tfms)\nvalid_ds = ImageFolder(data_dir+'\/test', valid_tfms)","d73ed6a4":"batch_size = 16","7291042c":"train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nvalid_dl = DataLoader(valid_ds, batch_size, num_workers=3, pin_memory=True)","3c9268d2":"def denormalize(images, means, stds):\n    means = torch.tensor(means).reshape(1,3,1,1)\n    stds = torch.tensor(stds).reshape(1,3,1,1)\n    return images*stds+means\n\ndef show_batch(dl):\n    for images,labels in dl:\n        fig, ax = plt.subplots(figsize=(12,12))\n        ax.set_xticks([]);ax.set_yticks([])\n        # denorm_images = denormalize(images,*stats)\n        ax.imshow(make_grid(images[:16], nrow=4).permute(1,2,0).clamp(0,1))\n        # ax.imshow(make_grid(denorm_images[:16], nrow=4).permute(1,2,0).clamp(0,1))\n        break","a7f3f52d":"show_batch(train_dl)","98197a2e":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n","7f085e32":"device = get_default_device()\ndevice","ff3cf353":"train_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","8e59857d":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","6cb8db1e":"def conv_block(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n              nn.BatchNorm2d(out_channels), \n              nn.ReLU(inplace=True)]\n    if pool: \n        layers.append(nn.MaxPool2d(4))\n    return nn.Sequential(*layers)\n\nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        # input: 3 X 256 X 256\n        self.conv1 = conv_block(in_channels, 64) # out: 64 X 256 X 256\n        self.conv2 = conv_block(64, 128, pool=True) # out: 128 X 64 X 64\n        self.res1 = nn.Sequential(conv_block(128, 128), \n                                  conv_block(128, 128))\n        \n        self.conv3 = conv_block(128, 256, pool=True) # out: 256 X 16 X 16\n        self.conv4 = conv_block(256, 512, pool=True) # out: 512 X 4 X 4\n        self.res2 = nn.Sequential(conv_block(512, 512), \n                                  conv_block(512, 512))\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4), # out: 512 X 1 X 1\n                                        nn.Flatten(),  # out: 512\n                                        nn.Dropout(0.2),\n                                        nn.Linear(512, num_classes))  # out: 3\n        \n    def forward(self, xb):\n        out = self.conv1(xb)\n        out = self.conv2(out)\n        out = self.res1(out) + out\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out\n        out = self.classifier(out)\n        return out","70f51410":"model = to_device(ResNet9(3, 3), device)\nmodel","44417a51":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","6bf55eab":"history = [evaluate(model, valid_dl)]\nhistory","ec2e31ae":"epochs = 50\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","100dc1bf":"%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","ac3835c2":"train_time='11:22'","51e08b1c":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\nplot_accuracies(history)","e8cad2a4":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","e19bf433":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');\n\n\nplot_lrs(history)","b48be739":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return train_ds.classes[preds[0].item()]","a67b22c2":"img, label = valid_ds[0]\nplt.imshow(img.permute(1, 2, 0).clamp(0, 1))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","e2f2a8b5":"img, label = valid_ds[10]\nplt.imshow(img.permute(1, 2, 0).clamp(0, 1))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","92ef6aec":"img, label = valid_ds[20]\nplt.imshow(img.permute(1, 2, 0).clamp(0, 1))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","f2fe1946":"img, label = valid_ds[30]\nplt.imshow(img.permute(1, 2, 0).clamp(0, 1))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","a93cbff7":"img, label = valid_ds[40]\nplt.imshow(img.permute(1, 2, 0).clamp(0, 1))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","81600711":"img, label = valid_ds[50]\nplt.imshow(img.permute(1, 2, 0).clamp(0, 1))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","1dc6c853":"img, label = valid_ds[60]\nplt.imshow(img.permute(1, 2, 0).clamp(0, 1))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","962159a8":"# Defining model and other required classes","9435099f":"# DataLoader and Batch initialization","6065d303":"# Training and Optimization","20bad194":"# Data","57fd0424":"# Conclusion","4c48d91c":"# Helper functions for GPU","a1f6a1d9":"### The validatioin accuracy being quite stable in the last five epochs (starting from 25th upto 30th) we can conclude that the model has reached the optimum model.\n### Although 98% accuracy is something really huge to claim and we can't do that exactly here. One of the reasons is that the dataset is not enough large to be trained on for a industry level deep neural network architecture.\n### So there is a scope of future improvement by training on more data","5bf47419":"# Required installation and imports","88824220":"# Plotting accuracy, cost, learning rate","8937a67e":"### Batch size is something that needs some trial and error to check if it exceeds device memory and slowing down the training process or not.\n### Although it's a good practise to use batch_size as some power of two.\n### In this model, intially I started with 32 batch_size but that slowed down training extensively. But reducing batch size to 16 increased the training speed a lot.","9184ce6b":"### All information regarding each layer of the ResNet9 network has been printed below in details.","c3542b3c":"### The data being a real life images needs some modificaion before putting into the deep neural network.\n### * Image size is not same throughout the whole dataset. Therefore all the images has been resized to 256 X 256 size using the Resize() function.\n### * Dataset being not enough large and also to maintain variation in training data, RandomHorizontalFlip is applied to use horizontal mirror image of given images.","7d047f48":"### This ResNet model has 9 layers in total. Takes batch of 3 channel input images of 256X256 image size.\n### The conv1, conv2, res1, conv3, conv4, res2 - all these convolution and residual layers converts the 3 channel 256X256 sized image to a 512 channel 4X4 feature map.\n### Finally another final maxpooling converts 4X4 feature map to 1X1.\n### At the end a last linear layer convertes 512 dimensional flattened data to 3 dimensional data which is considered as prediction.\n### * output dimensions of each layer has been written along with the code explicitely.\n","e8284764":"### In case, we are using some normalization on the data before training, this denormalize function is used to get back the image with real pizel values without any normalization.\n### show_batch function basically takes a batch of data to show but as we have given a break statement, it shows the first image of the batch only.","dc347587":"### ImageClassificationBase class is moreover a general class that can be used generally for any image data model. training_step and validation_step functions apply the deep learning model, calculate and return the cost on training and validation batch respectively.","b6eb5d3d":"# Predicting on individual images","59f6cccd":"### Dataset that has been used here is downloaded from Kaggle. You can get it here.\n### The dataset consists of Chest X-ray images of Covid-19 patients, Viral Pneumonia patients and normal persons.\n### Our moto is to develop a three class clssification deep learning model to predict if the person with the chest X-ray images have Covid-19, Viral Pneumonia or (s)he is fit and fine."}}