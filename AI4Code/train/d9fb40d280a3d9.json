{"cell_type":{"da7950d7":"code","f0db61f4":"code","15db2997":"code","2b6a6a52":"code","c211ea45":"code","d8a6c104":"code","99c8684a":"code","95deb946":"code","88b1dddb":"code","f54fb057":"code","da8a1581":"code","d19779be":"code","762a9b7d":"code","42f2c2c2":"code","1e4f4cec":"code","8b18ad8a":"code","86d63784":"code","7bd25a70":"code","835d9c62":"code","4ba84d5c":"code","f362d0fd":"code","8edc7e07":"markdown","6482a71a":"markdown"},"source":{"da7950d7":"import itertools\nimport warnings\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.tsa.api as smt\nfrom sklearn.metrics import mean_absolute_error\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nwarnings.filterwarnings('ignore')","f0db61f4":"# Dataset\n# Atmospheric CO2 from Continuous Air Samples at Mauna Loa Observatory, Hawaii, U.S.A.\n# Period of Record: March 1958 - Decemver 2001\n\ndata = sm.datasets.co2.load_pandas()\ny = data.data\ny.index.sort_values()","15db2997":"y = y['co2'].resample('MS').mean()","2b6a6a52":"y.head()","c211ea45":"y.shape","d8a6c104":"y.isnull().sum()","99c8684a":"y = y.fillna(y.bfill())\ny.head()","95deb946":"y.plot(figsize=(15, 6))\nplt.show()","88b1dddb":"df = pd.read_csv(\"..\/input\/air-passengers\/AirPassengers.csv\", index_col='Month', parse_dates=True)","f54fb057":"df.shape\ndf.columns","da8a1581":"df.head()","d19779be":"df[['#Passengers']].plot(title='Passengers Data')","762a9b7d":"df.index.freq = \"MS\"\ntrain = df[:120]\ntest = df[120:]","42f2c2c2":"# Stability Test (Dickey-Fuller Test)\ndef is_stationary(y):\n\n    # \"HO: Non-stationary\"\n    # \"H1: Stationary\"\n\n    p_value = sm.tsa.stattools.adfuller(y)[1]\n    if p_value < 0.05:\n        print(F\"Result: Stationary (H0: non-stationary, p-value: {round(p_value, 3)})\")\n    else:\n        print(F\"Result: Non-Stationary (H0: non-stationary, p-value: {round(p_value, 3)})\")","1e4f4cec":"# Time Series Components and Stationarity Test\ndef ts_decompose(y, model=\"additive\", stationary=False):\n    result = seasonal_decompose(y, model=model)\n    fig, axes = plt.subplots(4, 1, sharex=True, sharey=False)\n    fig.set_figheight(10)\n    fig.set_figwidth(15)\n\n    axes[0].set_title(\"Decomposition for \" + model + \" model\")\n    axes[0].plot(y, 'k', label='Original ' + model)\n    axes[0].legend(loc='upper left')\n\n    axes[1].plot(result.trend, label='Trend')\n    axes[1].legend(loc='upper left')\n\n    axes[2].plot(result.seasonal, 'g', label='Seasonality & Mean: ' + str(round(result.seasonal.mean(), 4)))\n    axes[2].legend(loc='upper left')\n\n    axes[3].plot(result.resid, 'r', label='Residuals & Mean: ' + str(round(result.resid.mean(), 4)))\n    axes[3].legend(loc='upper left')\n    plt.show(block=True)\n\n    if stationary:\n        is_stationary(y)","8b18ad8a":"# Analysis for additive and multiplicative models\nfor model in [\"additive\", \"multiplicative\"]:\n    ts_decompose(df, model)","86d63784":"# Single Exponential Smoothing \n\ndef ses_optimizer(train, alphas, step=48):\n    best_alpha, best_mae = None, float(\"inf\")\n    for alpha in alphas:\n        ses_model = SimpleExpSmoothing(train).fit(smoothing_level=alpha)\n        y_pred = ses_model.forecast(step)\n        mae = mean_absolute_error(test, y_pred)\n        if mae < best_mae:\n            best_alpha, best_mae = alpha, mae\n        print(\"alpha:\", round(alpha, 2), \"mae:\", round(mae, 4))\n    print(\"best_alpha:\", round(best_alpha, 2), \"best_mae:\", round(best_mae, 4))\n    return best_alpha, best_mae\n\nalphas = np.arange(0.01, 1, 0.10)\nbest_alpha, best_mae = ses_optimizer(train, alphas, step=24)\n# alpha: 0.11 mae: 82.528\n\nses_model = SimpleExpSmoothing(train).fit(smoothing_level=best_alpha)\ny_pred = ses_model.forecast(24)\n\ndef plot_prediction(y_pred, label):\n    train[\"#Passengers\"].plot(legend=True, label=\"TRAIN\")\n    test[\"#Passengers\"].plot(legend=True, label=\"TEST\")\n    y_pred.plot(legend=True, label=\"PREDICTION\")\n    plt.title(\"Train, Test and Predicted Test Using \"+label)\n    plt.show()\n\nplot_prediction(y_pred, \"Single Exponential Smoothing\")\n","7bd25a70":"# Double Exponential Smoothing\n\ndef des_optimizer(train, alphas, betas, step=48):\n    best_alpha, best_beta, best_mae = None, None, float(\"inf\")\n    for alpha in alphas:\n        for beta in betas:\n            des_model = ExponentialSmoothing(train, trend=\"add\").fit(smoothing_level=alpha, smoothing_slope=beta)\n            y_pred = des_model.forecast(step)\n            mae = mean_absolute_error(test, y_pred)\n            if mae < best_mae:\n                best_alpha, best_beta, best_mae = alpha, beta, mae\n            print(\"alpha:\", round(alpha, 2), \"beta:\", round(beta, 2), \"mae:\", round(mae, 4))\n    print(\"best_alpha:\", round(best_alpha, 2), \"best_beta:\", round(best_beta, 2), \"best_mae:\", round(best_mae, 4))\n    return best_alpha, best_beta, best_mae\n\n\nalphas = np.arange(0.01, 1, 0.10)\nbetas = np.arange(0.01, 1, 0.10)\n\nbest_alpha, best_beta, best_mae = des_optimizer(train, alphas, betas, step=24)\n#54.10\n\ndes_model = ExponentialSmoothing(train, trend=\"add\").fit(smoothing_level=best_alpha,\n                                                         smoothing_slope=best_beta)\ny_pred = des_model.forecast(24)\n\nplot_prediction(y_pred, \"Double Exponential Smoothing\")","835d9c62":"# Triple Exponential Smoothing (Holt-Winters)\n\ndef tes_optimizer(train, abg, step=48):\n    best_alpha, best_beta, best_gamma, best_mae = None, None, None, float(\"inf\")\n    for comb in abg:\n        tes_model = ExponentialSmoothing(train, trend=\"add\", seasonal=\"add\", seasonal_periods=12).\\\n            fit(smoothing_level=comb[0], smoothing_slope=comb[1], smoothing_seasonal=comb[2])\n        y_pred = tes_model.forecast(step)\n        mae = mean_absolute_error(test, y_pred)\n        if mae < best_mae:\n            best_alpha, best_beta, best_gamma, best_mae = comb[0], comb[1], comb[2], mae\n        print([round(comb[0], 2), round(comb[1], 2), round(comb[2], 2), round(mae, 2)])\n\n    print(\"best_alpha:\", round(best_alpha, 2), \"best_beta:\", round(best_beta, 2), \"best_gamma:\", round(best_gamma, 2),\n          \"best_mae:\", round(best_mae, 4))\n\n    return best_alpha, best_beta, best_gamma, best_mae\n\nalphas = betas = gammas = np.arange(0.10, 1, 0.20)\nabg = list(itertools.product(alphas, betas, gammas))\n\nbest_alpha, best_beta, best_gamma, best_mae = tes_optimizer(train, abg, step=24)\n# 11.99\n# carp\u0131msal hata: 15.12\n\ntes_model = ExponentialSmoothing(train, trend=\"add\", seasonal=\"add\", seasonal_periods=12).\\\n            fit(smoothing_level=best_alpha, smoothing_slope=best_beta, smoothing_seasonal=best_gamma)\n\ny_pred = tes_model.forecast(24)\n\nplot_prediction(y_pred, \"Triple Exponential Smoothing ADD\")\n","4ba84d5c":"# ARIMA(p, d, q): (Autoregressive Integrated Moving Average)\n\n# p ve q kombinasyonlar\u0131n\u0131n \u00fcretilmesi\np = d = q = range(0, 4)\npdq = list(itertools.product(p, d, q))\n\ndef arima_optimizer_aic(train, orders):\n    best_aic, best_params = float(\"inf\"), None\n    for order in orders:\n        try:\n            arma_model_result = ARIMA(train, order).fit(disp=0)\n            aic = arma_model_result.aic\n            if aic < best_aic:\n                best_aic, best_params = aic, order\n            print('ARIMA%s AIC=%.2f' % (order, aic))\n        except:\n            continue\n    print('Best ARIMA%s AIC=%.2f' % (best_params, best_aic))\n    return best_params\n\nbest_params_aic = arima_optimizer_aic(train, pdq)\n\n\n# Tuned Model\narima_model = ARIMA(train, best_params_aic).fit(disp=0)\ny_pred = arima_model.forecast(24)[0]\nmean_absolute_error(test, y_pred)\n# 51.18\n\nplot_prediction(pd.Series(y_pred, index=test.index), \"ARIMA\")","f362d0fd":"# SARIMA\n\np = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n\n\ndef sarima_optimizer_aic(train, pdq, seasonal_pdq):\n    best_aic, best_order, best_seasonal_order = float(\"inf\"), float(\"inf\"), None\n    for param in pdq:\n        for param_seasonal in seasonal_pdq:\n            try:\n                sarimax_model = SARIMAX(train, order=param, seasonal_order=param_seasonal)\n                results = sarimax_model.fit(disp=0)\n                aic = results.aic\n                if aic < best_aic:\n                    best_aic, best_order, best_seasonal_order = aic, param, param_seasonal\n                print('SARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, aic))\n            except:\n                continue\n    print('SARIMA{}x{}12 - AIC:{}'.format(best_order, best_seasonal_order, best_aic))\n    return best_order, best_seasonal_order\n\n\nbest_order, best_seasonal_order = sarima_optimizer_aic(train, pdq, seasonal_pdq)\n\n# Tuned Model\nmodel = SARIMAX(train, order=best_order, seasonal_order=best_seasonal_order)\nsarima_final_model = model.fit(disp=0)\ny_pred_test = sarima_final_model.get_forecast(steps=24)\n# pred_ci = y_pred_test.conf_int()\ny_pred = y_pred_test.predicted_mean\nmean_absolute_error(test, y_pred)\n# 63.8447\n\nplot_prediction(pd.Series(y_pred, index=test.index), \"SARIMA\")\n\n\n\np = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n\ndef sarima_optimizer_mae(train, pdq, seasonal_pdq):\n    best_mae, best_order, best_seasonal_order = float(\"inf\"), float(\"inf\"), None\n\n    for param in pdq:\n        for param_seasonal in seasonal_pdq:\n            try:\n                model = SARIMAX(train, order=param, seasonal_order=param_seasonal)\n                sarima_model = model.fit(disp=0)\n                y_pred_test = sarima_model.get_forecast(steps=24)\n                y_pred = y_pred_test.predicted_mean\n                mae = mean_absolute_error(test, y_pred)\n\n                # mae = fit_model_sarima(train, val, param, param_seasonal)\n\n                if mae < best_mae:\n                    best_mae, best_order, best_seasonal_order = mae, param, param_seasonal\n                print('SARIMA{}x{}12 - MAE:{}'.format(param, param_seasonal, mae))\n            except:\n                continue\n    print('SARIMA{}x{}12 - MAE:{}'.format(best_order, best_seasonal_order, best_mae))\n    return best_order, best_seasonal_order, best_mae\n\nbest_order, best_seasonal_order, best_mae = sarima_optimizer_mae(train, pdq, seasonal_pdq)\n\nmodel = SARIMAX(train, order=best_order, seasonal_order=best_seasonal_order)\nsarima_final_model = model.fit(disp=0)\ny_pred_test = sarima_final_model.get_forecast(steps=24)\ny_pred = y_pred_test.predicted_mean\nmean_absolute_error(test, y_pred)\n\nplot_prediction(pd.Series(y_pred, index=test.index), \"SARIMA\")","8edc7e07":"<h2 style='background:#11489c; border:0; color:white'><center>Time Series Forecasting<\/center><\/h2>\n\nTime series forecasting occurs when you make scientific predictions based on historical time stamped data. It involves building models through historical analysis and using them to make observations and drive future strategic decision-making. An important distinction in forecasting is that at the time of the work, the future outcome is completely unavailable and can only be estimated through careful analysis and evidence-based priors\n\n<h2 style='background:#11489c; border:0; color:white'><center>What is time series forecasting?<\/center><\/h2>\n\nTime series forecasting is the process of analyzing time series data using statistics and modeling to make predictions and inform strategic decision-making. It\u2019s not always an exact prediction, and likelihood of forecasts can vary wildly\u2014especially when dealing with the commonly fluctuating variables in time series data as well as factors outside our control. However, forecasting insight about which outcomes are more likely\u2014or less likely\u2014to occur than other potential outcomes. Often, the more comprehensive the data we have, the more accurate the forecasts can be. While forecasting and \u201cprediction\u201d generally mean the same thing, there is a notable distinction. In some industries, forecasting might refer to data at a specific future point in time, while prediction refers to future data in general. Series forecasting is often used in conjunction with time series analysis. Time series analysis involves developing models to gain an understanding of the data to understand the underlying causes. Analysis can provide the \u201cwhy\u201d behind the outcomes you are seeing. Forecasting then takes the next step of what to do with that knowledge and the predictable extrapolations of what might happen in the future\n\n<a href=\"https:\/\/ibb.co\/6NKsCsQ\"><img src=\"https:\/\/i.ibb.co\/Yb5jsjg\/1-gl-Ykmq-Klw-Jgbwy-w-RCJr-A.png\" alt=\"1-gl-Ykmq-Klw-Jgbwy-w-RCJr-A\" border=\"0\"><\/a>\n    \n<h2 style='background:#11489c; border:0; color:white'><center>Sections<\/center><\/h2>\n\n* Smoothing Methods\n    \n* Single Exponential Smoothing\n     \n* Double Exponential Smoothing(a, b) \n    \n* Triple Exponential Smoothing a.k.a Holt-Winters(a, b, g)\n    \n* Statistical Methods\n      \n* AR(p), MA(q), ARMA(p,q)\n    \n* ARIMA(p, d, q)\n    \n* SARIMA(p, d, q)(P,D,Q)m\n    \n* Machine Learning for Time Series Forecasting\n\n<h2 style='background:#11489c; border:0; color:white'><center>Stationary<\/center><\/h2>\n\n<a href=\"https:\/\/ibb.co\/f0cN3bp\"><img src=\"https:\/\/i.ibb.co\/Bs16hmZ\/1-xdblk-Zyg6-Ymm-Re-Ak-ZHUksw.png\" alt=\"1-xdblk-Zyg6-Ymm-Re-Ak-ZHUksw\" border=\"0\"><\/a>\n\n* The statistical properties of the series do not change over time\n* A time series is said to be stationary if its mean, variance, and covariance remain constant over time\n\n<h2 style='background:#11489c; border:0; color:white'><center>Trend<\/center><\/h2>\n\n<a href=\"https:\/\/ibb.co\/cXgQKgn\"><img src=\"https:\/\/i.ibb.co\/tPmDwmr\/Multiplicative-Decomposition-of-Airline-Passenger-Dataset.png\" alt=\"Multiplicative-Decomposition-of-Airline-Passenger-Dataset\" border=\"0\"><\/a>\n\n* The structure in which a time series increases or decreases in the long run is called a trend\n* The condition that a time series repeats a certain behavior at certain periods is called seasonality\n\n<h2 style='background:#11489c; border:0; color:white'><center>Cycle<\/center><\/h2>\n\n<a href=\"https:\/\/ibb.co\/Sdxd8R1\"><img src=\"https:\/\/i.ibb.co\/xfsf0Jc\/maxresdefault.jpg\" alt=\"maxresdefault\" border=\"0\"><\/a>\n\n* It is a kind of seasonality, of a longer-term, uncertain nature\n\n<h2 style='background:#11489c; border:0; color:white'><center>Moving Average<\/center><\/h2>\n\n<a href=\"https:\/\/ibb.co\/DGdfBNy\"><img src=\"https:\/\/i.ibb.co\/rb92BgS\/Screenshot-2021-12-06-193508.png\" alt=\"Screenshot-2021-12-06-193508\" border=\"0\"><\/a>\n\n* The future value of a time series is the average of its k previous values\n\n* t-1 -----> t\n\n* Used for trending, not forecasting\n\n<a href=\"https:\/\/ibb.co\/7njvMqw\"><img src=\"https:\/\/i.ibb.co\/St5NYzh\/Screenshot-2021-12-06-194616.png\" alt=\"Screenshot-2021-12-06-194616\" border=\"0\"><\/a>\n\n<h2 style='background:#11489c; border:0; color:white'><center>Weighted Average<\/center><\/h2>\n\n* The weighted average is similar to the moving average\n* It carries the idea of giving more weight to later observations\n\n* Single Exponential Smoothing (Only in stationary series. No trend and seasonality)\n* Double Exponential Smoothing (Level + Trend. No seasonality)\n* Triple Exponential Smoothing a.k.a Holt-Winters (Level + Trend + Seasonality)\n\n<h2 style='background:#11489c; border:0; color:white'><center>Importing Libraries<\/center><\/h2>","6482a71a":"- **SARIMA(0, 0, 0)x(1, 1, 1, 12)12 - MAE:30.626157879495242**"}}