{"cell_type":{"cc67700c":"code","5243126d":"code","1a31e84c":"code","4707f6cc":"code","8e431799":"code","83d4fbf9":"code","e7d7c121":"code","932d9c2a":"code","066c5496":"code","424c8d37":"code","2c5bf5e6":"code","35502274":"code","3bc94780":"code","3ecb67e0":"code","9d157f22":"code","dd904eb6":"code","035c9ae4":"code","bdfd02d2":"code","8f77179b":"code","cc378a01":"code","0f4c2a49":"code","8ae0754d":"markdown","f67d859b":"markdown","07ebc664":"markdown","5e184eb3":"markdown"},"source":{"cc67700c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5243126d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","1a31e84c":"data = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv',encoding='latin1')\ndata= data.iloc[:,[0,1]]\ndata.columns = [\"label\", \"message\"]","4707f6cc":"data.head()","8e431799":"data.shape","83d4fbf9":"data.describe(include='all')","e7d7c121":"data['label'].value_counts()","932d9c2a":"data.isnull().sum()","066c5496":"pd.set_option('display.max_colwidth',150)\ndata.head()","424c8d37":"import string\ns=string.punctuation","2c5bf5e6":"# def Remove_pun(txt):\n#     text_rem= \"\".join([c for c in txt if c not in s])\n#     return text_rem\n# data['msg_clean']= data['message'].apply(lambda x: Remove_pun(x))","35502274":"data.head()","3bc94780":"# import re\n\n# def token(txt):\n#     token = re.split('\\W+',txt)\n#     return token\n# data['Msg_clean_token'] = data['msg_clean'].apply(lambda x: token(x.lower()))\n# data.head()   ","3ecb67e0":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus= []\nfor i in range(len(data)):\n    MSG=re.sub('[^a-zA-Z]',' ',data['message'][i]) \n    MSG=MSG.lower()\n    MSG=MSG.split() #not a-z and A-Z only non letter will be replace by space\n    ps= PorterStemmer()\n    all_stopwords= stopwords.words('english')\n    MSG= [ps.stem(word) for word in MSG if not word in set(all_stopwords)]\n    MSG= ' '.join(MSG)\n    corpus.append(MSG)","9d157f22":"corpus","dd904eb6":"from sklearn.feature_extraction.text import CountVectorizer\ncv= CountVectorizer()\n\nX= cv.fit_transform(corpus).toarray()\nY=data.iloc[:,0].values","035c9ae4":"from sklearn.preprocessing import LabelEncoder\nLE= LabelEncoder()\nY=LE.fit_transform(Y)","bdfd02d2":"#split the data\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.22, random_state = 0)","8f77179b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(\"Accuracy score {}\".format(acc_logreg))\ncm=confusion_matrix(y_test,y_pred)\nprint(\"Confusion metrics  {}\".format(cm))","cc378a01":"# # Gaussian Naive Bayes\n# from sklearn.naive_bayes import GaussianNB\n# gaussian = GaussianNB()\n# gaussian.fit(x_train, y_train)\n# y_pred = gaussian.predict(x_test)\n# cm=confusion_matrix(y_test,y_pred)\n# print(\"Confusion metrics  {}\".format(cm))\n# print(accuracy_score(y_test,y_pred))","0f4c2a49":"new_msg = 'Hey Vick, Lets go for dinner tonight'\nnew_msg = re.sub('[^a-zA-Z]', ' ', new_msg)\nnew_msg = new_msg.lower()\nnew_msg = new_msg.split()\nps = PorterStemmer()\nall_stopwords = stopwords.words('english')\nall_stopwords.remove('not')\nnew_msg = [ps.stem(word) for word in new_msg if not word in set(all_stopwords)]\nnew_msg = ' '.join(new_msg)\nnew_corpus = [new_msg]\nnew_X_test = cv.transform(new_corpus).toarray()\nnew_y_pred = logreg.predict(new_X_test)\nprint(new_y_pred)","8ae0754d":"Removing stop words","f67d859b":"# So, Model predict it right its not a spam msg.","07ebc664":"Use our model to predict if the following Message:\n\n\"Hey vick, Lets got for dinner\"\n\nis spam or ham\n\nlets use logistic because its gives us high Accuracy score","5e184eb3":"Text Preprocessing\n1-Remove punctuation\n2-tokeize\n3-remove stop words\n4-steamming"}}