{"cell_type":{"3bc3722d":"code","178cbbf7":"code","9d748ab5":"code","5268befc":"code","4362ed59":"code","05d6dce1":"code","d01cc66e":"code","dd87cbeb":"code","3a8beb78":"code","a5b9158a":"code","116696d4":"code","09a102c0":"code","7cf41478":"code","08dbc861":"code","3b1c077c":"code","e0022030":"code","1732cd59":"code","450eecec":"code","3d0a2b1b":"code","9df412af":"code","3e3761d0":"code","05848575":"markdown","cbbab144":"markdown","6d444c6d":"markdown","ff3d43f6":"markdown","d77706ec":"markdown","a471bc98":"markdown","4efc8e8b":"markdown","718f2fe5":"markdown","ba6a0dda":"markdown"},"source":{"3bc3722d":"import pandas as pd\nimport numpy as np\nimport sys\nfrom itertools import combinations, groupby\nfrom collections import Counter\nfrom IPython.display import display","178cbbf7":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9d748ab5":"import zipfile\n\ndataset_orders = \"order_products__train.csv\"\ndataset_products = 'products.csv'\ndataset_departments = 'departments.csv'\ndataset_aisles = 'aisles.csv'\n\narchive_orders = zipfile.ZipFile(\"..\/input\/\"+dataset_orders+\".zip\",\"r\")\narchive_products = zipfile.ZipFile(\"..\/input\/\"+dataset_products+\".zip\",\"r\")\narchive_departments = zipfile.ZipFile(\"..\/input\/\"+dataset_departments+\".zip\",\"r\")\narchive_aisles = zipfile.ZipFile(\"..\/input\/\"+dataset_aisles+\".zip\",\"r\")\n\ndf_order = pd.read_csv(archive_orders.open('order_products__train.csv'))\ndf_product = pd.read_csv(archive_products.open('products.csv'))\ndf_departments = pd.read_csv(archive_departments.open('departments.csv'))\ndf_aisles = pd.read_csv(archive_aisles.open('aisles.csv'))","5268befc":"name_orders = \"order_products__prior.csv\"\narchive_orders = zipfile.ZipFile(\"..\/input\/\"+name_orders+\".zip\",\"r\")\norders = pd.read_csv(archive_orders.open('order_products__prior.csv'))","4362ed59":"df_orders = pd.merge(df_order, df_product, on='product_id')\ndf_orders.head()","05d6dce1":"from sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import CountVectorizer","d01cc66e":"orders.head(2)","dd87cbeb":"df_product.head(2)","3a8beb78":"df_departments.head(2)","a5b9158a":"df_aisles.head(2)","116696d4":"df = pd.merge(pd.merge(pd.merge(df_order, \n                                          df_product, \n                                          on=\"product_id\", how = 'inner'), \n                                   df_aisles, \n                                   on=\"aisle_id\", how='inner'),\n                      df_departments, \n                      on=\"department_id\", how = 'inner')","09a102c0":"df.head()","7cf41478":"df_meta = df.groupby('product_id', as_index=False).agg(set)","08dbc861":"df_meta.head(2)","3b1c077c":"df_meta['aisle'] = df_meta['aisle'].apply(lambda x: [i.replace(' ','') for i in x])\ndf_meta['department'] = df_meta['department'].apply(lambda x: [i.replace(' ','') for i in x])","e0022030":"df_meta.columns","1732cd59":"df_meta['metadata'] = df_meta.apply(lambda x : ' ' + ' '.join(x['aisle']) + ' ' + ' '.join(x['department']), axis = 1)\ndf_meta","450eecec":"df_vec = df_meta.head(10000) #Reduzindo para salvar mem\u00f3ria\ndf_produtos_previstos = pd.merge(df_vec[['product_id']], df_product[['product_id','product_name']], on='product_id', how='inner')\n\ncount_vec = CountVectorizer(stop_words='english')\ncount_vec_matrix = count_vec.fit_transform(df_vec['metadata'])\ncosine_sim_matrix = cosine_similarity(count_vec_matrix, count_vec_matrix)\nmapping = pd.Series(df_produtos_previstos.index, index = df_produtos_previstos['product_name'])","3d0a2b1b":"def recommend_products_based_on_metadata(product_input):\n    \n    product_index = mapping[product_input]\n    \n    similarity_score = list(enumerate(cosine_sim_matrix[product_index]))\n    similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n    \n    similarity_score = similarity_score[1:10]\n    product_indices = [i[0] for i in similarity_score]\n    \n    return (df_vec['product_name'].iloc[product_indices])","9df412af":"df_produtos_previstos.sample(5)","3e3761d0":"recommend_products_based_on_metadata('Over Tired and Cranky Bubble Bath')","05848575":"## Visualizando datasets","cbbab144":"## Carregando zip","6d444c6d":"# Cria tabela compras","ff3d43f6":"# Metadata-based Recommender System","d77706ec":"# Importando Bibliotecas","a471bc98":"# Inserindo os metadados","4efc8e8b":"* Metadata-based Recommendation System as described in this [Medium tutorial](https:\/\/medium.com\/analytics-vidhya\/metadata-based-recommender-systems-in-python-c6aae213b25c). All Credits to the authors!","718f2fe5":"## Importando bibliotecas necess\u00e1rias","ba6a0dda":"**work in progress!**"}}