{"cell_type":{"225222e1":"code","c7a3e2c0":"code","2a0c15fc":"code","7e23d710":"code","24c6c81e":"code","c9749a16":"code","c710ae21":"code","1934d715":"code","ec0ab15b":"code","8240a9d5":"markdown","154d6588":"markdown","94f28eb6":"markdown","cc30760e":"markdown"},"source":{"225222e1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n\n# For DEEP learning\nimport tensorflow as tf\nfrom keras.layers import Conv2D, Dense, Flatten, Dropout\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\n\n# ensure consistency across runs\nfrom numpy.random import seed\nseed(1)\n\nimport os\nfrom glob import glob\nimport random\nbase_dir = '\/kaggle\/input\/asl-alphabet\/'\n\nimg = cv2.imread(os.path.join(base_dir+'asl_alphabet_train\/asl_alphabet_train\/W','W2547.jpg'))\nplt.imshow(img)\n\n\n# Any results you write to the current directory are saved as output.","c7a3e2c0":"# print(os.listdir(\"..\/input\"))\n# print(\"===============================================\")\n# print(os.listdir(\"..\/input\/asl-alphabet\"))\n# print(\"===============================================\")\n# print(os.listdir(\"..\/input\/asl-alphabet\/asl_alphabet_train\"))\n# print(\"===============================================\")\n# print(os.listdir(\"..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\"))\n# print(\"===============================================\")\n# print(os.listdir(\"..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/A\"))\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n# #     # print(dirname,_,filename)\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","2a0c15fc":"def sample_random(letter):\n    base_dir = os.path.join(\"..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\",letter)\n    files = [os.path.join(base_dir,x) for x in os.listdir(base_dir)]\n    imgs = random.sample(files,4)\n    # print(imgs)\n    \n    plt.figure(figsize=(16,16))\n    plt.subplot(241) # https:\/\/stackoverflow.com\/questions\/3584805\/in-matplotlib-what-does-the-argument-mean-in-fig-add-subplot111\n    plt.imshow(cv2.imread(imgs[0]))\n    plt.subplot(242)\n    plt.imshow(cv2.imread(imgs[1]))\n    plt.subplot(243)\n    plt.imshow(cv2.imread(imgs[2]))\n    plt.subplot(244)\n    plt.imshow(cv2.imread(imgs[3]))\n\nsample_random('W')","7e23d710":"from tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport skimage\nfrom skimage.transform import resize\n\nimg_size = 64\ntrain_dir = \"..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/\"\ntest_dir = \"..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test\/\"\ndef input_data(folder):\n    \"\"\"\n    Load the data and labels from the given folder.\n    \"\"\"\n    X = []\n    y = []\n    for d in os.listdir(folder):\n        if not d.startswith('.'):\n            if d in ['A']:\n                label = 0\n            elif d in ['B']:\n                label = 1\n            elif d in ['C']:\n                label = 2\n            elif d in ['D']:\n                label = 3\n            elif d in ['E']:\n                label = 4\n            elif d in ['F']:\n                label = 5\n            elif d in ['G']:\n                label = 6\n            elif d in ['H']:\n                label = 7\n            elif d in ['I']:\n                label = 8\n            elif d in ['J']:\n                label = 9\n            elif d in ['K']:\n                label = 10\n            elif d in ['L']:\n                label = 11\n            elif d in ['M']:\n                label = 12\n            elif d in ['N']:\n                label = 13\n            elif d in ['O']:\n                label = 14\n            elif d in ['P']:\n                label = 15\n            elif d in ['Q']:\n                label = 16\n            elif d in ['R']:\n                label = 17\n            elif d in ['S']:\n                label = 18\n            elif d in ['T']:\n                label = 19\n            elif d in ['U']:\n                label = 20\n            elif d in ['V']:\n                label = 21\n            elif d in ['W']:\n                label = 22\n            elif d in ['X']:\n                label = 23\n            elif d in ['Y']:\n                label = 24\n            elif d in ['Z']:\n                label = 25\n            elif d in ['del']:\n                label = 26\n            elif d in ['nothing']:\n                label = 27\n            elif d in ['space']:\n                label = 28           \n            else:\n                label = 29\n            for file in tqdm(os.listdir(folder + d)):\n                img_file = cv2.imread(folder + d + '\/' + file)\n                if img_file is None:\n                    continue\n#                 print(img_file)\n#                 print(\"================================\")\n                img_file = skimage.transform.resize(img_file, (img_size, img_size))\n                img = np.asarray(img_file)\n                X.append(img)\n                y.append(label)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y\n\n\n# x_train, y_train = input_data(train_dir)\n# #x_test, y_test= get_data(test_dir) # Too few images\n\n# from sklearn.model_selection import train_test_split\n# x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2) \n\n# # Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n# from keras.utils.np_utils import to_categorical\n# y_trainHot = to_categorical(y_train, num_classes = 30)\n# y_testHot = to_categorical(y_test, num_classes = 30)\n","24c6c81e":"data_dir = \"..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\"\ntarget_size = (64, 64)\ntarget_dims = (64, 64, 3) # add channel for RGB\nn_classes = 29\nval_frac = 0.1\nbatch_size = 64\ndata_augmentor = ImageDataGenerator(samplewise_center=True, \n                                    samplewise_std_normalization=True, \n                                    validation_split=val_frac)\n\ntrain_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, shuffle=True, subset=\"training\")\nval_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, subset=\"validation\")","c9749a16":"ImageDataGenerator?","c710ae21":"model = Sequential()\nmodel.add(Conv2D(filters = 16, kernel_size = 3, strides=1, activation = 'relu', input_shape = target_dims) )\nmodel.add(Conv2D(filters = 16, kernel_size = 3, strides=2, activation = 'relu'))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters = 32, kernel_size = 3, strides=1, activation = 'relu'))\nmodel.add(Conv2D(filters = 32, kernel_size = 3, strides=2, activation = 'relu'))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(filters = 64, kernel_size = 3, strides=1, activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = 3, strides=2, activation = 'relu'))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation= 'relu'))\nmodel.add(Dense(n_classes, activation='softmax'))\n\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","1934d715":"model.fit_generator(train_generator, epochs=5, validation_data=val_generator)","ec0ab15b":"model.fit(x_train, y_train, epochs = 4, validation_data=(xtest,ytest), verbose=1)","8240a9d5":"#### MODEL SETUP","154d6588":"#### MODEL FITTING","94f28eb6":"#### INPUT DATA ( WITHOUT USING ImageDataGenerator )","cc30760e":"#### INPUT DATA ( USING ImageDataGenerator )"}}