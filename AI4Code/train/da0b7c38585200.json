{"cell_type":{"ae171846":"code","16856a30":"code","ed765b80":"code","39295e39":"code","1d28dc14":"code","5263e065":"code","424d3f8c":"code","66f7ed8a":"code","8b247ec8":"code","6da48721":"code","aa3577d9":"code","48db9ae6":"code","c123b4ec":"code","d0517835":"code","742db2d0":"code","853b58f2":"code","43fbdbec":"code","db03e1d0":"code","781f2cdc":"code","64945e6f":"code","188a800c":"code","074a3444":"code","f211ac69":"code","1fb6522f":"code","19f57e4d":"code","7d7860f4":"code","a57b0496":"code","3ea5d6bf":"markdown","f3786980":"markdown","efa644d8":"markdown","4b9aeeca":"markdown","442d012b":"markdown","5ab8c310":"markdown","9c5a86d3":"markdown","b9325d31":"markdown","94c829de":"markdown","c7cd36be":"markdown","d0c3a953":"markdown","10a20136":"markdown","0599ef2c":"markdown","952174e3":"markdown","8846be91":"markdown","e4c275ae":"markdown","6c146a2d":"markdown","584b685d":"markdown","edc0502d":"markdown","afa50a62":"markdown","00f83394":"markdown","fce06d8d":"markdown","d15389cc":"markdown"},"source":{"ae171846":"!pip install yfinance","16856a30":"import numpy as np\nimport pandas as pd\n\nimport yfinance as yf\n\nimport datetime\nimport time\nimport requests\nimport io\n\nimport plotly.express as px","ed765b80":"# Start and End date (5 Years data)\nend = datetime.datetime(2022,1,20)\nstart = datetime.datetime(2017,4,1)","39295e39":"nifty_50 = ['ADANIPORTS', 'ASIANPAINT', 'AXISBANK', 'BAJAJ-AUTO', 'BAJFINANCE', 'BAJAJFINSV',\n       'BPCL', 'BHARTIARTL', 'BRITANNIA', 'CIPLA', 'COALINDIA',\n       'DIVISLAB', 'DRREDDY', 'EICHERMOT', 'GRASIM', 'HCLTECH',\n       'HDFCBANK', 'HDFCLIFE', 'HEROMOTOCO', 'HINDALCO', 'HINDUNILVR',\n       'HDFC', 'ICICIBANK', 'ITC', 'IOC', 'INDUSINDBK', 'INFY',\n       'JSWSTEEL', 'KOTAKBANK', 'LT', 'M&M', 'MARUTI', 'NTPC',\n       'NESTLEIND', 'ONGC', 'POWERGRID', 'RELIANCE', 'SBILIFE',\n       'SHREECEM', 'SBIN', 'SUNPHARMA', 'TCS', 'TATACONSUM', 'TATAMOTORS',\n       'TATASTEEL', 'TECHM', 'TITAN', 'UPL', 'ULTRACEMCO', 'WIPRO']","1d28dc14":"df = pd.DataFrame()\n\nfor company in nifty_50:\n    temp = yf.download(f'{company}.NS',start=start, end=end, progress=False)\n    temp['Company'] = company\n    temp.reset_index(inplace=True)\n    df = df.append(temp, ignore_index=True)","5263e065":"sectors = ['Infrastructure', 'Consumer Goods', 'Banking', 'Automobile', 'Financial Services', 'Financial Services',\n           'Energy - Oil & Gas', 'Telecommunication', 'Consumer Goods', 'Pharmaceuticals', 'Mining',          \n           'Pharmaceuticals', 'Pharmaceuticals', 'Automobile', 'Cement', 'Information Technology',           \n           'Financial Services', 'Insurance', 'Automobile', 'Metals', 'Consumer Goods',           \n           'Banking', 'Banking', 'Consumer Goods',  'Energy - Oil & Gas', 'Banking', 'Information Technology',           \n           'Metals', 'Banking', 'Construction', 'Automobile', 'Automobile', 'Energy - Power',           \n           'Consumer Goods', 'Energy - Power', 'Energy - Oil & Gas', 'Energy - Power', 'Insurance',           \n           'Cement', 'Banking', 'Pharmaceuticals', 'Information Technology',  'Consumer Goods', 'Automobile',           \n           'Metals', 'Information Technology', 'Consumer Goods', 'Chemicals',  'Cement', 'Information Technology']\n\nsector_dict = dict(zip(nifty_50, sectors))","424d3f8c":"# Adding sectors\ndf['Sector'] = df['Company'].apply(lambda x: sector_dict[x])","66f7ed8a":"# Combining similar sectors\ndf['Sector'] = df['Sector'].replace({'Energy - Oil & Gas':'aEnergy', 'Energy - Power':'Energy',\n                     'Banking':'Banking & Financial Services', 'Financial Services':'Banking & Financial Services', 'Insurance':'Banking & Financial Services',\n                     'Mining':'Construction', 'Infrastructure':'Construction', 'Cement':'Construction',\n                     'Chemicals':'Pharmaceuticals'})","8b247ec8":"df.head()","6da48721":"df.to_csv('Indian Stock Market Data.csv', index=False)","aa3577d9":"# Transforming the data for easy analysis\ndf1 = pd.pivot(df, index='Date', columns='Company', values='Adj Close')\ndisplay(df1.shape)","48db9ae6":"# Removing the last row\ndf1 = df1.iloc[:-1,:]","c123b4ec":"# Imputing missing values with previous values\ndf1 = df1.fillna(method='bfill')","d0517835":"# Plotting sample data\nsample = df1.iloc[:,:3]\n\nfig = px.line(sample, facet_col=\"Company\", facet_col_wrap=1, width=1000, height=900)\nfig.update_yaxes(matches=None)\nfig.show()","742db2d0":"energy_company = ['RELIANCE', 'IOC', 'ONGC', 'NTPC', 'BPCL', 'POWERGRID']\n\ndf_energy = df1[energy_company]","853b58f2":"# ADT Test for random stocks\nn_obs = 900\ndf_train, df_test = df_energy[0:-n_obs], df_energy[-n_obs:]\n\nfrom statsmodels.tsa.stattools import adfuller\n\ndef adf_test(df):\n    result = adfuller(df.values)\n    print('ADF Statistics: %f' % result[0])\n    print('p-value: %f' % result[1])\n    # print('Critical values:')\n    # for key, value in result[4].items():\n    #     print('\\t%s: %.3f' % (key, value))\n        \nfor company in energy_company:\n    print(f'ADF Test: {company}')\n    adf_test(df_train[company])\n    print('*'*50)","43fbdbec":"# KPSS Test for random stocks\nfrom statsmodels.tsa.stattools import kpss\n\ndef kpss_test(df):    \n    statistic, p_value, n_lags, critical_values = kpss(df.values)\n    \n    print(f'KPSS Statistic: {statistic}')\n    print(f'p-value: {p_value}')\n    print(f'num lags: {n_lags}')\n    # print('Critial Values:')\n    # for key, value in critical_values.items():\n    #     print(f'   {key} : {value}')\n        \nfor company in energy_company:\n    print(f'ADF Test: {company}')\n    kpss_test(df_train[company])\n    print('*'*50)","db03e1d0":"df_train_transformed = df_train.diff().dropna()\n\nfig = px.line(df_train_transformed, facet_col=\"Company\", facet_col_wrap=1, height=1000)\nfig.update_yaxes(matches=None)\nfig.show()","781f2cdc":"for company in energy_company:\n    print(f'ADF Test: {company}')\n    adf_test(df_train_transformed[company])\n    print('*'*50)","64945e6f":"for company in energy_company:\n    print(f'ADF Test: {company}')\n    kpss_test(df_train_transformed[company])\n    print('*'*50)","188a800c":"from statsmodels.tsa.api import VAR\n\nmodel = VAR(df_train_transformed)\nfor i in list(range(12)):\n    result = model.fit(i)\n    print('Lag Order =', i)\n    print('AIC : ', result.aic)\n    print('*'*50)","074a3444":"results = model.fit(maxlags=0, ic='aic')\nresults.summary()","f211ac69":"from statsmodels.stats.stattools import durbin_watson\n\nout = durbin_watson(results.resid)\n\nfor col, val in zip(df_train_transformed.columns, out):\n    print(col, ':', round(val, 2))","1fb6522f":"from statsmodels.tsa.stattools import grangercausalitytests\n\nmaxlag=4\ntest = 'ssr_chi2test'\n\ndef grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n   \n    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [var + '_x' for var in variables]\n    df.index = [var + '_y' for var in variables]\n    return df\n\ngrangers_causation_matrix(df_train_transformed, variables = df_train_transformed.columns)","19f57e4d":"# Let's check maxlag between RELIANCE and NTPC stock prices\nmaxlag=7\nresults = grangercausalitytests(df_train_transformed[['NTPC', 'RELIANCE']], maxlag, verbose=False)","7d7860f4":"p_values = [results[i+1][0]['ssr_ftest'][1] for i in range(maxlag)]\np_values","a57b0496":"# Plotting sample data\nsample = df_train_transformed[['NTPC', 'RELIANCE']]\n\nfig = px.line(sample, facet_col=\"Company\", facet_col_wrap=1, width=1000, height=600)\nfig.update_yaxes(matches=None)\nfig.show()","3ea5d6bf":"# Time Series Analysis\n\nAs the data is huge, it will be computetionaly difficult to perform the time series analysis, so I will focus on a sector e.g. Energy","f3786980":"It means that effect of RELIANCE stock on NTPC stock is highest after 1 day delay","efa644d8":"A value of 2.0 means that there is no autocorrelation detected in the residuals.","4b9aeeca":"After transforming the data, the p-values are all below the 0.05 alpha level, therefore, we reject the null hypothesis. So the current data is stationary.","442d012b":"### ADF Test Again","5ab8c310":"After transforming the data, the p-values are all well below the 0.05 alpha level, therefore, we can't reject the null hypothesis. So the current data is stationary.","9c5a86d3":"# Getting the data","b9325d31":"# Data Cleaning","94c829de":"### KPSS Test Again","c7cd36be":"There is no hard-and-fast-rule on the choice of lag order. It is basically an empirical issue. However, it is often advised to use the AIC in selecting the lag order with the smallest value. Therefore, we will select `lag order=0`.","d0c3a953":"The correlation between the stocks is very less, except BPCL and IOC. It means when IOC stock price increases, the stock price of BPCL also increases.","10a20136":"### ADF Test for Stationarity\n\nThe ADF test is one of the most popular statistical tests. It can be used to help us understand whether the time series is stationary or not.\n\n> Null hypothesis: If failed to be rejected, it suggests the time series is not stationarity.\n\n> Alternative hypothesis: The null hypothesis is rejected, it suggests the time series is stationary.","0599ef2c":"Except for `POWERGRID`, the p-value are all less than 0.05 alpha level, therefore, we can reject the null hypothesis and derive that the three time series are not stationary.\n\nAfter cross-check ADF test and KPSS test. We can conclude that the three time series data we have here are not stationary. We will transform the time series to be stationary by difference method.","952174e3":"### Durbin-Watson Statistic","8846be91":"### KPSS Test for Stationary\nThe KPSS test figures out if a time series is stationary around a mean or linear trend, or is non-stationary due to a unit root.\n\n> Null hypothesis: The time series is stationary\n\n> Alternative hypothesis: The time series is not stationary\n","e4c275ae":"## Creating Model ","6c146a2d":"### Difference Method","584b685d":"The p value for RELIANCE and NTPC is much below 0.05, so RELIANCE stock price granger causes NTPC stock price","edc0502d":"The p-values are all well above the 0.05 alpha level, we cannot reject the null hypothesis. So the three time series are not stationary.","afa50a62":"# Data Visualization","00f83394":"## Making the data stationary","fce06d8d":"## Test for Stationarity","d15389cc":"### Granger Causality Test\nThe Granger causality test is a statistical hypothesis test for determining whether one time series is useful in forecasting another.\n\n> H0 : X does not granger cause Y (p value >= 0.05)\n\n> H1 : X granger causes Y (p value < 0.05)"}}