{"cell_type":{"ae443681":"code","db57d6be":"code","d944f011":"code","268943c4":"code","92226a95":"code","fa7a0d04":"code","97c7af7c":"code","c8de39cd":"code","eddb4b96":"code","2b176eaf":"code","94d2ea1a":"code","be02f9fe":"code","a71ee858":"code","2b14b175":"code","c99f021e":"code","4fac76b1":"code","d669d383":"code","e77c12a1":"code","7fd75d71":"code","1cb52efa":"code","d84f4044":"code","c74089cd":"code","3d952205":"code","7dc8585a":"code","aeec0cd1":"code","85888399":"code","4a7398f1":"code","af834d49":"code","0f641c88":"code","50eb620a":"code","ed5c018b":"code","d2795dbd":"markdown","9d091204":"markdown","1183fdcb":"markdown","8eb359e7":"markdown","c5a75734":"markdown","375c0754":"markdown","4ef80144":"markdown"},"source":{"ae443681":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#Importing packages\nimport tensorflow as tf\nimport os\nimport cv2\nimport imageio\nimport numpy as np\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.patches as mpatches\nfrom scipy.signal import find_peaks\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\nfrom tensorflow.keras.models import Model\nimport random as rn\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications import VGG16\nimport datetime\nimport glob\nimport warnings\nfrom tensorflow.keras import models, layers\nfrom sklearn.metrics import cohen_kappa_score\nimport math\nfrom keras.regularizers import l1 ,l2\nimport keras\nfrom tensorflow.keras.layers import BatchNormalization, Activation, Flatten\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nimport argparse\nimport os\nimport warnings\n\nfrom keras.callbacks import Callback\nfrom keras import backend as K\nwarnings.filterwarnings('ignore')\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","db57d6be":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nimg_path = list()\nimg_fullname = list()\nimg_name = list()\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/aptos2019-blindness-detection\/train_images\/'):\n    for filename in filenames:\n        img_path.append(os.path.join(dirname, filename))\n        temp = os.path.join(dirname, filename)\n        temp = temp.split(\"\/\")[-1]\n        img_fullname.append(temp)\n        temp = temp.split(\".\")[0]\n        img_name.append(str(temp))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d944f011":"pre_df = pd.DataFrame()\npre_df['path'] = img_path\npre_df['fullname'] = img_fullname\npre_df['id_code'] = img_name","268943c4":"# Reading DR grades files of 2019, Messidor & IDRiD\ntrain2019 = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\ntrain2019 = train2019[['id_code', 'diagnosis']]","92226a95":"# Fetching DR grades of the respective images of 2019\nlabels = list()\nid_code = list()\nfor i, j in train2019.iterrows():\n    id_code.append(j['id_code'])\n    labels.append(j['diagnosis'])","fa7a0d04":"train_labels = pd.DataFrame() # Storing the image file name & DR grades into the dataframe\ntrain_labels['id_code'] = id_code\ntrain_labels['diagnosis'] = labels","97c7af7c":"# Merging the image path & DR grades \npre_df = pd.merge(pre_df, train_labels, on='id_code', how='left')","c8de39cd":"pre_df = pre_df[pre_df['diagnosis'].notna()] # removing row if the DR grade is NaN","eddb4b96":"print(pre_df[pre_df['diagnosis'].isnull()]) # Verify if there is any NaN present in the DR grades field","2b176eaf":"convert_dict = {'diagnosis': str}\n  \npre_df = pre_df.astype(convert_dict)","94d2ea1a":"# train test split\nfrom sklearn.model_selection import train_test_split\ny = pre_df['diagnosis'].values\nX_train, X_test, y_train, y_test = train_test_split(pre_df, y, test_size=0.20, stratify=y)","be02f9fe":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","a71ee858":"# Hyperparameters\nbatch_size = 8\nnum_classes = 5\nl = 14\nnum_filter = 32\ncompression = 0.5\ndropout_rate = 0","2b14b175":"img_height = 32\nimg_width = 32\nchannel = 3","c99f021e":"tf.keras.backend.clear_session()\n# Dense Block\ndef denseblock(input, num_filter, dropout_rate):\n    global compression\n    temp = input\n    for _ in range(l): \n        BatchNorm = layers.BatchNormalization()(temp)\n        relu = layers.Activation('relu')(BatchNorm)\n        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n        if dropout_rate>0:\n            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n        \n        temp = concat\n        \n    return temp\n\n## transition Blosck\ndef transition(input, num_filter, dropout_rate):\n    global compression\n    BatchNorm = layers.BatchNormalization()(input)\n    relu = layers.Activation('relu')(BatchNorm)\n    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n    if dropout_rate>0:\n         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n    return avg\n\n#output layer\ndef output_layer(input):\n    global compression\n    BatchNorm = layers.BatchNormalization()(input)\n    relu = layers.Activation('relu')(BatchNorm)\n    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n    flat = layers.Flatten()(AvgPooling)\n    output = layers.Dense(num_classes, activation='softmax')(flat)\n    return output","4fac76b1":"num_filter = 32\ndropout_rate = 0\nl = 14\n\ntf.keras.backend.clear_session()\ninput = layers.Input(shape=(img_height, img_width, channel,))\nFirst_Conv2D = layers.Conv2D(24, (2,2), use_bias=False ,padding='same', kernel_initializer='he_uniform', bias_initializer='zeros',kernel_regularizer=l2(0.0001))(input)\n\nFirst_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\nFirst_Transition = transition(First_Block, num_filter, dropout_rate)\n\nSecond_Block = denseblock(First_Transition, num_filter, dropout_rate)\nSecond_Transition = transition(Second_Block, num_filter, dropout_rate)\n\nThird_Block = denseblock(Second_Transition, num_filter, dropout_rate)\nThird_Transition = transition(Third_Block, num_filter, dropout_rate)\n\nLast_Block = denseblock(Third_Transition, num_filter, dropout_rate)\noutput = output_layer(Last_Block)","d669d383":"model = Model(inputs=[input], outputs=[output])\nmodel.summary()","e77c12a1":"#optimizer = SGD(learning_rate=0.1, momentum=0.9, decay= 1e-6, nesterov=True)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])","7fd75d71":"# reference URL - https:\/\/vijayabhaskar96.medium.com\/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\nfrom keras_preprocessing.image import ImageDataGenerator\n\ndatagen=ImageDataGenerator(rescale=1.\/255., validation_split=0.20, horizontal_flip=True)\n\ntrain_generator=datagen.flow_from_dataframe(dataframe=X_train, directory=None, x_col=\"path\", y_col=\"diagnosis\", subset=\"training\", \n                batch_size=8, shuffle=True, class_mode=\"categorical\", drop_duplicates = False, target_size=(32,32))\n\nvalid_generator=datagen.flow_from_dataframe(dataframe=X_train, directory=None, x_col=\"path\", y_col=\"diagnosis\", subset=\"validation\", \n                        batch_size=8, shuffle=True, class_mode=\"categorical\", drop_duplicates = False, target_size=(32,32))\n\ntest_datagen=ImageDataGenerator(rescale=1.\/255.)\n\ntest_generator=test_datagen.flow_from_dataframe(dataframe=X_test, directory=None, x_col=\"path\", \n                y_col=None, batch_size=1, shuffle=False, class_mode=None, target_size=(32,32))","1cb52efa":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size\nmodel.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID, epochs=50)","d84f4044":"y_pred = model.predict(test_generator)\ny_pred_class = np.argmax(y_pred, axis=1)","c74089cd":"cohen = cohen_kappa_score(y_pred_class, y_test.astype('int'), weights='quadratic')\nprint(\"Quadratic Cohen kappa score of VGG model on test data is - %.3f\" %cohen)","3d952205":"print ('Classification Report : \\n', classification_report(y_test.astype('int'), y_pred_class))\nsns.heatmap(confusion_matrix(y_test.astype('int'), y_pred_class), annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('Actual class')\nplt.xlabel('Predicted class')\nplt.show()","7dc8585a":"img_path = list()\nimg_fullname = list()\nimg_name = list()\nfor dirname, _, filenames in os.walk('..\/input\/aptos2019-blindness-detection\/test_images\/'):\n    for filename in filenames:\n        img_path.append(os.path.join(dirname, filename))\n        temp = os.path.join(dirname, filename)\n        temp = temp.split(\"\/\")[-1]\n        img_fullname.append(temp)\n        temp = temp.split(\".\")[0]\n        img_name.append(str(temp))\n","aeec0cd1":"pre_df = pd.DataFrame()\npre_df['path'] = img_path\npre_df['fullname'] = img_fullname\npre_df['id_code'] = img_name","85888399":"test_datagen=ImageDataGenerator(rescale=1.\/255.)\n\ntest_generator_2019=test_datagen.flow_from_dataframe(dataframe=pre_df, directory=None, x_col=\"path\", \n                y_col=None, batch_size=1, shuffle=False, class_mode=None, target_size=(32,32))","4a7398f1":"y_pred_2019 = model.predict(test_generator_2019)\ny_pred_class_2019 = np.argmax(y_pred_2019, axis=1)","af834d49":"filenames = list()\nfor i in test_generator_2019.filenames:\n    temp = i.split('.')[-2]\n    temp = temp.split('\/')[-1]\n    filenames.append(temp)","0f641c88":"submission_dense = pd.DataFrame()\nsubmission_dense['id_code'] = filenames\nsubmission_dense['diagnosis'] = y_pred_class_2019","50eb620a":"submission_dense","ed5c018b":"submission_dense.to_csv('.\/submission.csv', index=False)","d2795dbd":"**Prediction on test data**","9d091204":"**Train and test data split up**","1183fdcb":"**Calcualting KAPPA and Macro F1 score on test data**","8eb359e7":"**Training the model**","c5a75734":"**Reading Test data and predicting DR grades using trained model**","375c0754":"**1.1 Reading data**","4ef80144":"**Building DensetNet Model**"}}