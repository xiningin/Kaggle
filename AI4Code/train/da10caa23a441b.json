{"cell_type":{"10560193":"code","a035a020":"code","30a845fa":"code","b9c8b787":"code","2db9904d":"code","42731c4f":"code","b957ee30":"code","b22e4b79":"code","d31dc4df":"code","312393a8":"code","3a5c9cef":"code","eaa49a1e":"code","6d0e765b":"code","24badd74":"code","6cb53478":"code","d90307d8":"code","d7dd86d5":"code","0e654e89":"code","f0c0d59d":"code","6f4bae3e":"code","7027a2b1":"code","ef5d71f9":"code","61dd14a2":"markdown","9685d8f9":"markdown","d734cc6e":"markdown","d16725e5":"markdown","bad16ccc":"markdown"},"source":{"10560193":"# import data\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a035a020":"# import basic library\nfrom sklearn.impute import SimpleImputer\nfrom IPython.display import display\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostRegressor\nfrom catboost import CatBoostClassifier","30a845fa":"# import train & test data\ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")\nsample = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")","b9c8b787":"# information about test and train data\ndisplay(train.info())\ndisplay(test.info())","2db9904d":"# basic structure of train data\ntrain.head()","42731c4f":"# basic structure of train data 2\ntrain.describe().T","b957ee30":"# number of misssing values by feature\nprint(\"number of misssing values by feature\")\ntrain.isnull().sum().sort_values(ascending = False)","b22e4b79":"# train_data missing values\nnull_values_train = []\nfor col in train.columns:\n    c = train[col].isna().sum()\n    pc = np.round((100 * (c)\/len(train)), 2)            \n    dict1 ={\n        'Features' : col,\n        'null_train (count)': c,\n        'null_trian (%)': '{}%'.format(pc)\n    }\n    null_values_train.append(dict1)\nDF1 = pd.DataFrame(null_values_train, index=None).sort_values(by='null_train (count)',ascending=False)\n\n\n# test_data missing values\nnull_values_test = []\nfor col in test.columns:\n    c = test[col].isna().sum()\n    pc = np.round((100 * (c)\/len(test)), 2)            \n    dict2 ={\n        'Features' : col,\n        'null_test (count)': c,\n        'null_test (%)': '{}%'.format(pc)\n    }\n    null_values_test.append(dict2)\nDF2 = pd.DataFrame(null_values_test, index=None).sort_values(by='null_test (count)',ascending=False)\n\n\ndf = pd.concat([DF1, DF2], axis=1)\ndf#.head()","d31dc4df":"df = pd.DataFrame()\ndf[\"n_missing\"] = train.drop([\"id\", \"claim\"], axis=1).isna().sum(axis=1)\ndf[\"claim\"] = train[\"claim\"].copy()\n\nfig, ax = plt.subplots(figsize=(12,5))\nax.hist(df[df[\"claim\"]==0][\"n_missing\"],\n        bins=40, edgecolor=\"black\",\n        color=\"darkseagreen\", alpha=0.7, label=\"claim is 0\")\nax.hist(df[df[\"claim\"]==1][\"n_missing\"],\n        bins=40, edgecolor=\"black\",\n        color=\"darkorange\", alpha=0.7, label=\"claim is 1\")\nax.set_title(\"Missing values distributionin in each target class\", fontsize=20, pad=15)\nax.set_xlabel(\"Missing values per row\", fontsize=14, labelpad=10)\nax.set_ylabel(\"Amount of rows\", fontsize=14, labelpad=10)\nax.legend(fontsize=14)\nplt.show();","312393a8":"print(\" train data\")\nprint(f' Number of rows: {train.shape[0]}\\n Number of columns: {train.shape[1]}\\n No of missing values: {sum(train.isna().sum())}')","3a5c9cef":"print(\" test data\")\nprint(f' Number of rows: {test.shape[0]}\\n Number of columns: {test.shape[1]}\\n No of missing values: {sum(test.isna().sum())}')","eaa49a1e":"# looking at Claim column\nfig, ax = plt.subplots(figsize=(6, 6))\n\nbars = ax.bar(train[\"claim\"].value_counts().index,\n              train[\"claim\"].value_counts().values,              \n              edgecolor=\"black\",\n              width=0.4)\nax.set_title(\"Claim (target) values distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Amount of values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Claim (target) value\", fontsize=14, labelpad=10)\nax.set_xticks(train[\"claim\"].value_counts().index)\nax.tick_params(axis=\"both\", labelsize=14)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in train[\"claim\"].value_counts().values\/(len(train)\/100)],\n                 padding=5, fontsize=15)\nax.bar_label(bars, [f\"{x:2d}\" for x in train[\"claim\"].value_counts().values],\n                 padding=-30, fontsize=15)\nax.margins(0.2, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","6d0e765b":"# proportion of no null in each row\ntrain1 = train[train.isna().sum(axis=1)==0]\nprint(\"proportion of no null data : %.2f\" %(len(train1)\/len(train)*100))\nprint(\"number of claim 1 in no null data : %d\" %(len(train1[train1['claim']==0])))\nprint(\"number of claim 0 in no null data : %d\" %(len(train1[train1['claim']==1])))","24badd74":"fig, ax = plt.subplots(figsize=(6, 6))\n\nbars = ax.bar(train1[\"claim\"].value_counts().index,\n              train1[\"claim\"].value_counts().values,              \n              edgecolor=\"black\",\n              width=0.4)\nax.set_title(\"Claim (target) values distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Amount of values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Claim (target) value\", fontsize=14, labelpad=10)\nax.set_xticks(train1[\"claim\"].value_counts().index)\nax.tick_params(axis=\"both\", labelsize=14)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in train1[\"claim\"].value_counts().values\/(len(train1)\/100)],\n                 padding=5, fontsize=15)\nax.bar_label(bars, [f\"{x:2d}\" for x in train1[\"claim\"].value_counts().values],\n                 padding=-30, fontsize=15)\nax.margins(0.2, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","6cb53478":"target = train.pop('claim')","d90307d8":"train_ = train[0:9579]\ntest_ = test[0:4934]","d7dd86d5":"# distribution of Features f1 to f60\nL = len(train.columns[0:60])\nnrow= int(np.ceil(L\/6))\nncol= 6\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\n#ax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\ni = 1\nfor feature in train.columns[0:60]:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, color='cyan',  alpha=0.5, label='train')\n    ax = sns.kdeplot(test_[feature], shade=True, color='darkblue',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\nplt.suptitle('DistPlot: train & test data', fontsize=20)\nplt.show()","0e654e89":"# distribution of Features f61 to f118\nL = len(train.columns[60:])\nnrow= int(np.ceil(L\/6))\nncol= 6\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\n#ax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\ni = 1\nfor feature in train.columns[60:]:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, color='cyan',  alpha=0.5, label='train')\n    ax = sns.kdeplot(test_[feature], shade=True, color='darkblue',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\nplt.suptitle('DistPlot: train & test data', fontsize=20)\nplt.show()","f0c0d59d":"# outlier of train data\ndf_plot = ((train - train.min())\/(train.max() - train.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\nsns.boxplot(data = df_plot.iloc[:, 1:30], ax = ax[0])\nsns.boxplot(data = df_plot.iloc[:, 30:60], ax = ax[1])\nsns.boxplot(data = df_plot.iloc[:, 60:90], ax = ax[2])\nsns.boxplot(data = df_plot.iloc[:, 90:120], ax = ax[3])","6f4bae3e":"# outlier of test data\ndf_plot = ((test - test.min())\/(test.max() - test.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\nsns.boxplot(data = df_plot.iloc[:, 1:30], ax = ax[0])\nsns.boxplot(data = df_plot.iloc[:, 30:60], ax = ax[1])\nsns.boxplot(data = df_plot.iloc[:, 60:90], ax = ax[2])\nsns.boxplot(data = df_plot.iloc[:, 90:119], ax = ax[3])","7027a2b1":"# correlation of train\ncorr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nplt.figure(figsize = (15, 15))\nplt.title('Corelation matrix')\nsns.heatmap(corr, mask = mask, cmap = 'Spectral_r', linewidths = .5)\n\nplt.show()","ef5d71f9":"# correlation of train\ncorr = test.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nplt.figure(figsize = (15, 15))\nplt.title('Corelation matrix')\nsns.heatmap(corr, mask = mask, cmap = 'Spectral_r', linewidths = .5)\n\nplt.show()","61dd14a2":"- there are 1820782 missing values\n- proportion of missising value between test and train are very similar\n- There is a small percentage of null values based on each column, but overall, the percentage of null values is huge.\n- It is an amount that cannot be ignored.","9685d8f9":"- The distribution of test and train data is very similar.\n- The distribution of outliers shows different shapes in several columns but most have a similar distribution.\n- The correlation between the two data is also similar.\n- Overall test data and train data seem similar.","d734cc6e":"- The claim rate in train data is half and half.\n- Only 37% of the data without null values is intact.\n- Interestingly, the claim rate of the intact data is completely different from the previous train data.\n- In other words, it means that there are a lot of null values in the data with claim 1.\n- With this in mind, you will have to deal with null values.","d16725e5":"- 120 columns in train data ","bad16ccc":"- The train data is twice as large as the test data.\n- Both data have identical columns, except that the train data has a claim column.\n- I'll have to check the structure of the data more deeply."}}