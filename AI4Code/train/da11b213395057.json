{"cell_type":{"3ac2167a":"code","2f7715aa":"code","83a9fe43":"code","0eeb29b2":"code","fd6f7692":"code","149de86e":"code","a2028bbe":"code","f5628ce4":"code","b90626a8":"code","f6adce36":"code","3c240eb9":"code","66ef37a2":"code","c84a5ddb":"code","3d4c18f9":"code","664abf3c":"code","fdc58794":"code","51a3ee51":"code","ab2c958d":"code","495d8b88":"code","dc45e034":"markdown"},"source":{"3ac2167a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport keras\nimport random\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout, Input,InputLayer, Activation, BatchNormalization\nfrom keras.layers import AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D, ZeroPadding2D, SpatialDropout2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.optimizers import RMSprop\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport tensorflow as tf\nimport random\nimport cv2\nimport os\nimport numpy as np\n# from keras.applications.resnet50 import ResNet50\nfrom keras.models import Model\nimport keras\nfrom keras.callbacks import EarlyStopping\nimg_size = 224","2f7715aa":"def rotateImage(image, angle):\n    row,col = image.shape\n    center=tuple(np.array([row,col])\/2)\n    rot_mat = cv2.getRotationMatrix2D(center,angle,1.0)\n    new_image = cv2.warpAffine(image, rot_mat, (col,row))\n    return new_image\n\ndef randomZoom(image):\n    x=random.randint(30,140)\n    y=random.randint(0,20)\n    crop_img = image[x:x+224, y:y+224]\n    crop_img = cv2.resize(crop_img, (224, 224))\n    return crop_img","83a9fe43":"labels = ['NORMAL', 'PNEUMONIA']\ndef get_data(data_dir):\n    data = []\n    for label in labels:\n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img = cv2.imread(os.path.join(path, img))\n                gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n                resized_arr = cv2.resize(gray, (img_size, img_size))\n                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n                equalized = clahe.apply(resized_arr)\n                if class_num==0:\n                    data.append([equalized, class_num])\n                else:\n                    aug_img=rotateImage(equalized,random.randint(0,60) )\n                    if random.randint(0,1)==1:\n                        aug_img=randomZoom(aug_img)\n                    data.append([aug_img, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)\n\ntrain=get_data(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\")\ntest=get_data(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test\")\nval=get_data(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val\")","0eeb29b2":"def get_data(data_dir,start,end):\n    data = []\n    for label in labels:\n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n    for img in os.listdir(data_dir):\n        try:\n            img = cv2.imread(os.path.join(data_dir, img))\n            gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            resized_arr = cv2.resize(gray, (img_size, img_size))\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            equalized = clahe.apply(resized_arr)\n            aug_img=randomZoom(equalized)\n            aug_img=rotateImage(aug_img,random.randint(start,end)) \n            aug_img=cv2.flip( aug_img, random.randint(0,1) )\n            data.append([aug_img, 0])\n        except Exception as e:\n            print(e)\n    return np.array(data)","fd6f7692":"normal_data_1=get_data(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/NORMAL\/\",5,30)\nnormal_data_2=get_data(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/NORMAL\/\",31,40)","149de86e":"x_train_normal = []\ny_train_normal = []\nfor feature, label in normal_data_1:\n  x_train_normal.append(feature)\n  y_train_normal.append(label)\nfor feature, label in normal_data_2:\n  x_train_normal.append(feature)\n  y_train_normal.append(label)","a2028bbe":"# Normalize the data\nx_train_normal = np.array(x_train_normal,dtype=np.float16) \/ 255","f5628ce4":"x_train = []\ny_train = []\nx_val=[]\ny_val=[]\nx_test = []\ny_test = []\n\nfor feature, label in train:\n  x_train.append(feature)\n  y_train.append(label)\n\nfor feature, label in test:\n  x_test.append(feature)\n  y_test.append(label)\n\nfor feature, label in val:\n  x_val.append(feature)\n  y_val.append(label)","b90626a8":"# Normalize the data\nx_train = np.array(x_train,dtype=np.float16) \/ 255\nx_test = np.array(x_test,dtype=np.float16) \/ 255\nx_val = np.array(x_val,dtype=np.float16) \/ 255","f6adce36":"x_train=np.concatenate((x_train, x_train_normal), axis=0)\ny_train=np.concatenate((y_train, y_train_normal), axis=0)","3c240eb9":"x_train=x_train.reshape(-1, img_size, img_size, 1)\ny_train = np.array(y_train)\n\nx_test=x_test.reshape(-1, img_size, img_size, 1)\ny_test = np.array(y_test)\n\nx_val=x_val.reshape(-1, img_size, img_size, 1)\ny_val = np.array(y_val)\n","66ef37a2":"print(x_train.shape)\nprint(type(x_train))\nprint(y_train.shape)\nprint(type(y_train))","c84a5ddb":"model = Sequential()\nmodel.add(InputLayer(input_shape=(img_size, img_size, 1)))\n\nmodel.add(ZeroPadding2D((3, 3)))\nmodel.add(Conv2D(112, activation='relu', kernel_size=(3, 3)))\nmodel.add(MaxPooling2D((2, 2), strides=(3, 3)))\nmodel.add(Conv2D(72, activation='relu', kernel_size=(2, 2)))\nmodel.add(MaxPooling2D((2, 2), strides=(3, 3)))\nmodel.add(Conv2D(64, activation='relu', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\nmodel.add(Conv2D(32, activation='sigmoid', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2, 2), strides=(3, 3)))\nmodel.add(Conv2D(16, activation='sigmoid', kernel_size=(2, 2)))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(968, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dense(2, activation=\"softmax\"))\nmodel.summary()\n","3d4c18f9":"rms= RMSprop(lr=0.00001)\nmodel.compile(optimizer =rms , loss =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics = ['accuracy'])","664abf3c":"checkpoint_filepath = '.\/checkpoint\/model_{val_loss:.4f}-{epoch:02d}-{val_accuracy:.4f}\/'\nms = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_filepath,\n        save_weights_only=False,\n        monitor='val_loss',\n        mode='min',\n        save_best_only=True)","fdc58794":"history = model.fit(x_train,y_train,epochs = 30,validation_data = (x_val,y_val),callbacks=[ms])","51a3ee51":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(30)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n","ab2c958d":"predictions = model.predict_classes(x_test)\npredictions = predictions.reshape(1,-1)[0]\nprint(classification_report(y_test, predictions, target_names = ['NORMAL (Class 0)','PNEUMONIA (Class 1)']))","495d8b88":"import sklearn.metrics as metrics\ncm = metrics.confusion_matrix(y_test, predictions)\nprint(cm)","dc45e034":"Manually augment dataset "}}