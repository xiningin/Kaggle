{"cell_type":{"83f35720":"code","9fb815ac":"code","373d69bf":"code","1373c30e":"code","981ad059":"code","9d7dfdeb":"code","702bab46":"code","0133b2fa":"code","5f99d712":"code","1c19dff1":"code","6efdbccd":"code","5586ba8f":"code","e3197be1":"code","ca5b916d":"code","dc5b2e7b":"code","07828177":"code","a15bac67":"code","76ff25e8":"code","58bdff77":"code","07881b97":"code","a71cb0de":"code","b21d63e0":"markdown","301c7663":"markdown","d84be758":"markdown","ce21d615":"markdown","09b7c286":"markdown"},"source":{"83f35720":"import gc\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\n\nplt.rcParams['figure.figsize'] = [8, 8]\nplt.style.use('ggplot')\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 8)","9fb815ac":"!ls ..\/input\/qualityeducation","373d69bf":"notas = {\n    'nu_nota_cn': 'Ci\u00eancias da Natureza',\n    'nu_nota_ch': 'Ci\u00eancias Humanas',\n    'nu_nota_lc': 'Linguagens e C\u00f3digos',\n    'nu_nota_mt': 'Matem\u00e1tica',\n    'nu_nota_redacao': 'Reda\u00e7\u00e3o'\n}","1373c30e":"# from https:\/\/www.kaggle.com\/valleyzw\/ubiquant-lgbm-baseline\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in tqdm([x for x in df.columns if 'NU_NOTA_' not in x]):\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","981ad059":"%%time\n\n# https:\/\/docs.google.com\/spreadsheets\/d\/14C4lbQFEmUnIJN17gr01L8ikXsT27eHZ\/edit#gid=673716161\ntrain = reduce_mem_usage(pd.read_csv('..\/input\/qualityeducation\/train.csv'))\ntrain.columns = [x.lower() for x in train.columns.tolist()]\n\ntrain","9d7dfdeb":"gc.collect()","702bab46":"train.info()","0133b2fa":"%%time\n\ntest = reduce_mem_usage(pd.read_csv('..\/input\/qualityeducation\/test.csv'))\ntest.columns = [x.lower() for x in test.columns.tolist()]\ntest","5f99d712":"gc.collect()","1c19dff1":"test.info()","6efdbccd":"train[notas.keys()].isnull().sum() \/ len(train)","5586ba8f":"train = train.dropna(subset=notas.keys()).reset_index()\ntrain","e3197be1":"(train.isnull().sum()[train.isnull().sum() > 0] \/ len(train)).plot.barh();","ca5b916d":"train['co_municipio_residencia'].value_counts()","dc5b2e7b":"train['no_municipio_residencia'].value_counts()","07828177":"train['co_uf_residencia'].value_counts()","a15bac67":"nota_media_por_uf = train.groupby('co_uf_residencia')[list(notas.keys())].agg(['mean']).droplevel(1, axis=1)\nnota_media_por_uf.plot.bar(figsize=(15, 8))\nplt.xticks(rotation=0);","76ff25e8":"features = [\n    'co_uf_residencia'\n]\n\ntargets = list(notas.keys())\n\nn_splits = 5\n\nscores = []\n\npreds_test_cn = []\npreds_test_ch = []\npreds_test_lc = []\npreds_test_mt = []\npreds_test_redacao = []\n\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\nfor fold, (tr, val) in enumerate(kf.split(train[features], train[targets])):\n    print('FOLD:', fold)\n    \n    # split\n    X_train = train.loc[tr, features + targets]\n    X_val = train.loc[val, features + targets]\n    X_test = test[features]\n    \n    # features\n    nota_media_por_uf_ = X_train.groupby('co_uf_residencia')[targets].agg(['mean']).droplevel(1, axis=1)\n    nota_media_por_uf_.columns = [f'pred_{x}' for x in nota_media_por_uf_.columns]\n    X_val = X_val.merge(nota_media_por_uf_, on='co_uf_residencia', how='left').drop(features, axis=1)\n    X_test = X_test.merge(nota_media_por_uf_, on='co_uf_residencia', how='left').drop(features, axis=1)\n    \n    # metricas\n    rmses = []\n    for i, nota in enumerate(targets):\n        # print('Nota:', notas[nota])\n        y_true = X_val.iloc[:, i].values\n        y_pred = X_val.iloc[:, i + 5].values\n        rmse = metrics.mean_squared_error(y_true, y_pred, squared=False)\n        rmses.append(rmse)\n        # print('RMSE:', rmse)\n        # print()\n\n    mcrmse = np.mean(rmses)\n    scores.append(mcrmse)\n    print('MCRMSE:', mcrmse)\n    print()\n    \n    # predicao dados de teste\n    preds_test_cn.append(X_test['pred_nu_nota_cn'].values.tolist())\n    preds_test_ch.append(X_test['pred_nu_nota_ch'].values.tolist())\n    preds_test_lc.append(X_test['pred_nu_nota_lc'].values.tolist())\n    preds_test_mt.append(X_test['pred_nu_nota_mt'].values.tolist())\n    preds_test_redacao.append(X_test['pred_nu_nota_redacao'].values.tolist())\n    \nprint('-' * 30)\nprint('Mean:', np.mean(scores))\nprint('Std:', np.std(scores))","58bdff77":"df_sub = pd.DataFrame({\n    'NU_INSCRICAO': test['nu_inscricao'],\n    'NU_NOTA_CN': np.mean(preds_test_cn, axis=0),\n    'NU_NOTA_CH': np.mean(preds_test_ch, axis=0),\n    'NU_NOTA_LC': np.mean(preds_test_lc, axis=0),\n    'NU_NOTA_MT': np.mean(preds_test_mt, axis=0),\n    'NU_NOTA_REDACAO': np.mean(preds_test_redacao, axis=0)\n})\n\ndf_sub","07881b97":"%%time\n\ndf_sub.to_csv('submission.csv', index=False)","a71cb0de":"!head submission.csv","b21d63e0":"As targets possuem valores NA.   \nPor enquanto vamos remover essas linhas.   ","301c7663":"## Checando submiss\u00e3o","d84be758":"## EDA","ce21d615":"Algumas features possuem mais de 70% de valores NA.   ","09b7c286":"## Treinamento\n\nQue tal usar somente a nota m\u00e9dia por UF como baseline?   "}}