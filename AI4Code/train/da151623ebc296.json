{"cell_type":{"95978e09":"code","58c9291e":"code","ddd7a799":"code","fce5312a":"code","08104d75":"code","a0499773":"markdown","3c2e1d6c":"markdown","5a85cb49":"markdown","87cf8ddf":"markdown","920d9658":"markdown"},"source":{"95978e09":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.models import Model\nfrom keras.layers import Input,Flatten,Dense,Conv2D,ReLU,BatchNormalization,MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2","58c9291e":"pd.set_option('display.expand_frame_repr', False)\npd.set_option('display.max_columns', None)  \npd.set_option('max_rows', None)\ndata = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nY = data['label'].to_numpy()\ndata = data.drop(columns=['label'])\nX = data.to_numpy()\ntest = test.to_numpy()\nX = X.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)\nX = X\/255.0\ntest = test\/255.0\nindices = np.random.randint(low=0, high=42000, size=10)\nfor i in indices:\n    plt.figure()\n    plt.imshow(X[i,:,:,0], cmap='gray')\nY = to_categorical(Y, 10)","ddd7a799":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.05)\ni = Input(shape=(28,28,1))\nm = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), padding='valid')(i)\nm = BatchNormalization()(m)\nm = ReLU()(m)\nm = MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid')(m)\n\nm = Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), padding='valid')(m)\nm = BatchNormalization()(m)\nm = ReLU()(m)\nm = MaxPool2D(pool_size=(2,2), strides=(2,2), padding='valid')(m)\n\nm = Flatten()(m)\nm = Dense(128, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(m)\nm = Dense(64, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(m)\nm = Dense(10, activation='softmax', kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(m)\n\nmodel = Model(inputs=i, outputs=m)\nmodel.summary()","fce5312a":"opt = Adam(0.01)\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\nmodel.fit(X_train, Y_train, batch_size=64, epochs=100, verbose=2, validation_data=(X_test, Y_test))","08104d75":"preds = model.predict(test)\npreds = preds.argmax(axis=1)\nimageid = np.arange(1,28001)\noutput = pd.DataFrame({\"ImageId\": imageid,\"Label\": preds})\noutput.to_csv('submissions.csv', index=False)","a0499773":"# Building the Model\n\nLet's get to building the model. We split data into training and cross-validation sets, define the input for the keras model and then start implementing it. I have used the Functional API though Sequential will work just as fine for this. The architecture is as follows -\n\n1. Conv2D Layer, followed by a Batch Normalization and Relu Activation\n2. MaxPool2D Layer\n3. Conv2D Layer, followed by a Batch Normalization and Relu Activation\n4. MaxPool2D Layer\n5. Flatten, followed by 3 Fully Connected Layers.","3c2e1d6c":"# Data Preparation and Preprocessing\n\nLoad training and test data into numpy arrays, then separate out the label from the training data. Reshape the arrays into the form (m,28,28,1) where m denotes number of examples and normalize the data by dividing by 255.0, that is, the range of the possible pixel values (sorta like MinMaxScaling). We then visualize 10 randomly chosen images from the training set and one-hot encode the labels.","5a85cb49":"# Making Predictions\n\nNote that Keras Functional API doesn't support predict_classes hence we have to use argmax along 2nd axis to make the prediction for the digit the model thinks the example is.","87cf8ddf":"# Getting Started\n\nLet's first load all the libraries required for the problem.","920d9658":"# Training the Model\n\nIt's time to train the model. We use Adam optimizer, alongwith categorical cross-entropy as loss function and accuracy as metric."}}