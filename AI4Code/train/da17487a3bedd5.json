{"cell_type":{"79fa3534":"code","b5ecd4b5":"code","6f3e09e4":"code","cf38dec5":"code","cc9d2ec6":"code","efc1b706":"code","7c1b85ee":"code","25ec68a8":"code","0e8bbaff":"code","46529c34":"code","2a2931e7":"code","73e33765":"code","02d26a7a":"code","8e54507e":"code","7f9b3ebe":"code","51a2d4b2":"code","4b7fb087":"code","b5900c59":"code","1e7f255d":"code","86811bf9":"code","108bf22c":"code","3a9c4466":"code","12b91c3e":"code","9316c8b2":"code","d6cce534":"code","755c6fdc":"code","80e60415":"code","5036bbae":"code","ced14828":"code","b899912b":"code","1492d540":"code","a731857d":"code","3d0c6b4a":"code","2e682e1b":"code","b6e450dc":"code","19fcc144":"code","30f9c343":"code","8905cd6a":"code","8d293cc2":"code","3ff9878c":"markdown","1958e1e9":"markdown","a53f7ec0":"markdown","4336f573":"markdown","32f21fd1":"markdown","cbe23416":"markdown","e950d620":"markdown","94f22e18":"markdown","05236711":"markdown","b54cce73":"markdown","2281332f":"markdown","2c41bf17":"markdown","2197fb93":"markdown","e2bba85c":"markdown","aae8d05e":"markdown","bbe8aaaf":"markdown","cec32444":"markdown","dc569dd9":"markdown","8426ecdf":"markdown","31a47d69":"markdown","a3423638":"markdown","9942af55":"markdown","a5f6392e":"markdown","845cf601":"markdown","410782b0":"markdown","ec3f2b5e":"markdown","8baf1545":"markdown","ee9e7128":"markdown","bb8944ef":"markdown","caeaf8fa":"markdown"},"source":{"79fa3534":"from __future__ import annotations\n\n!pip install nlplot","b5ecd4b5":"import os\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\n\nimport nltk\nfrom nltk.corpus import stopwords\nimport nlplot\nfrom spacy import displacy","6f3e09e4":"def read_text(data_dir: str, doc_id: str) -> str:\n    path = os.path.join(data_dir, f'train\/{doc_id}.txt')\n    with open(path, 'r') as f:\n        text = f.read()\n    return text\n\n\ndef make_train_all_text(data_dir: str) -> pd.core.frame.DataFrame:\n    dic = {'id': [], 'text': []}\n    train_discourse = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    doc_ids = train_discourse['id'].unique().tolist()\n    \n    for doc_id in tqdm(doc_ids):\n        dic['id'].append(doc_id)\n        dic['text'].append(read_text(data_dir, doc_id))\n        \n    return pd.DataFrame(dic)","cf38dec5":"DATA_DIR = '..\/input\/feedback-prize-2021'\n\ntrain_all_text = make_train_all_text(DATA_DIR)\ntrain_discourse = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n\ntrain_discourse['number'] = 1\ntrain_discourse['number'] = train_discourse.groupby('id').cumsum()['number']\n\ntrain_discourse_lea = train_discourse.query(' discourse_type==\"Lead\" ')\ntrain_discourse_pos = train_discourse.query(' discourse_type==\"Position\" ')\ntrain_discourse_evi = train_discourse.query(' discourse_type==\"Evidence\" ')\ntrain_discourse_con = train_discourse.query(' discourse_type==\"Concluding Statement\" ')\ntrain_discourse_cou = train_discourse.query(' discourse_type==\"Counterclaim\" ')\ntrain_discourse_reb = train_discourse.query(' discourse_type==\"Rebuttal\" ')","cc9d2ec6":"display(train_all_text.head(2))","efc1b706":"display(train_discourse.query(' id == \"423A1CA112E2\" '))","7c1b85ee":"def visualize_label(\n    df: pd.core.frame.DataFrame,\n    doc_id: str,\n    data_dir: str) -> None:\n    df_filtered = df.query(f' id == \"{doc_id}\" ')\n    \n    ents = []\n    for _, row in df_filtered.iterrows():\n        ents.append({\n            'start': int(row['discourse_start']),\n            'end': int(row['discourse_end']),\n            'label': row['discourse_type']\n        })\n        \n    text = read_text(data_dir, doc_id)\n    doc = {\n        'text': text,\n        'ents': ents\n    }\n    \n    colors = {\n        'Lead': '#dad1f6',\n        'Position': '#f9d5de',\n        'Claim': '#adcfad',\n        'Evidence': '#fbbf9a',\n        'Counterclaim': '#bdf2fa',\n        'Concluding Statement': '#eea69e',\n        'Rebuttal': '#d1f8f4',\n    }\n    options = {\n        'ents': df['discourse_type'].unique().tolist(),\n        'colors': colors\n    }\n    displacy.render(doc, style='ent', options=options, manual=True, jupyter=True)","25ec68a8":"visualize_label(train_discourse, '423A1CA112E2', DATA_DIR)","0e8bbaff":"def get_specified_discourse_flow(\n    df: pd.core.frame.DataFrame,\n    discourse_flow: List[str] = []) -> pd.core.frame.DataFrame:\n    \n    for i, dis in enumerate(discourse_flow):\n        _df = df.query(f' number=={i+1} ')\n        _df = _df.query(f' discourse_type==\"{dis}\" ')\n        ids = set(_df['id'].unique())\n        df = df[df['id'].isin(ids)]\n    return df\n\n\ndef plot_pie_chart(\n    df: pd.core.frame.DataFrame,\n    number: int,\n    discourse_flow: List[str] = []\n) -> None:\n    fig, ax = plt.subplots(figsize=(6, 6))\n    df_flow = get_specified_discourse_flow(df, discourse_flow)\n    \n    print(f'Number of ids: {df_flow.shape[0]}')\n    \n    num_end = df_flow.groupby('id').last()['number'].reset_index().query(f'number == {number-1}').shape[0]\n    \n    df_plot = df_flow.query(f' number=={number} ')\n    cnt = df_plot['discourse_type'].value_counts()\n    x, y = cnt.keys().tolist(), cnt.values.tolist()\n    x += ['End']\n    y += [num_end]\n    ax.pie(y, labels=x, counterclock=False, startangle=90,\n                    autopct=lambda p: '{:.1f}'.format(p) if p >= 8 else '')\n    ax.axis('equal')\n    plt.show()","46529c34":"plot_pie_chart(train_discourse, 1, [])","2a2931e7":"plot_pie_chart(train_discourse, 2, ['Lead'])","73e33765":"plot_pie_chart(train_discourse, 3, ['Lead', 'Position'])","02d26a7a":"plot_pie_chart(train_discourse, 4, ['Lead', 'Position', 'Claim'])","8e54507e":"plot_pie_chart(train_discourse, 5, ['Lead', 'Position', 'Claim', 'Claim'])","7f9b3ebe":"plot_pie_chart(train_discourse, 6, ['Lead', 'Position', 'Claim', 'Claim', 'Claim'])","51a2d4b2":"plot_pie_chart(train_discourse, 7, ['Lead', 'Position', 'Claim', 'Claim', 'Claim', 'Evidence'])","4b7fb087":"plot_pie_chart(train_discourse, 8, ['Lead', 'Position', 'Claim', 'Claim', 'Claim', 'Evidence', 'Evidence'])","b5900c59":"plot_pie_chart(\n    train_discourse,\n    9,\n    ['Lead', 'Position', 'Claim', 'Claim', 'Claim', 'Evidence', 'Evidence', 'Evidence']\n)","1e7f255d":"plot_pie_chart(\n    train_discourse,\n    10,\n    ['Lead', 'Position', 'Claim', 'Claim', 'Claim', 'Evidence', 'Evidence', 'Evidence', 'Concluding Statement']\n)","86811bf9":"npt_all_text = nlplot.NLPlot(train_all_text, target_col='text')\nnpt_lea = nlplot.NLPlot(train_discourse_lea, target_col='discourse_text')\nnpt_pos = nlplot.NLPlot(train_discourse_pos, target_col='discourse_text')\nnpt_evi = nlplot.NLPlot(train_discourse_evi, target_col='discourse_text')\nnpt_con = nlplot.NLPlot(train_discourse_con, target_col='discourse_text')\nnpt_cou = nlplot.NLPlot(train_discourse_cou, target_col='discourse_text')\nnpt_reb = nlplot.NLPlot(train_discourse_reb, target_col='discourse_text')","108bf22c":"stop_words = stopwords.words('english') + ['school', 'students', 'student', 'people']","3a9c4466":"n1 = npt_all_text.bar_ngram(\n    title='N1 gram',\n    xaxis_label='word count',\n    yaxis_label='word',\n    ngram=1,\n    top_n=50,\n    stopwords=stop_words\n)\nn2 = npt_all_text.bar_ngram(\n    title='N2 gram',\n    xaxis_label='word count',\n    yaxis_label='word',\n    ngram=2,\n    top_n=50,\n    stopwords=stop_words\n)\nn3 = npt_all_text.bar_ngram(\n    title='N3 gram',\n    xaxis_label='word count',\n    yaxis_label='word',\n    ngram=3,\n    top_n=50,\n    stopwords=stop_words\n)\ntrace1 = n1['data'][0]\ntrace2 = n2['data'][0]\ntrace3 = n3['data'][0]\n\nfig = make_subplots(rows=1, cols=3, subplot_titles=('N1', 'N2', 'N3'), shared_xaxes=False)\nfig.update_xaxes(title_text='word count', row=1, col=1)\nfig.update_xaxes(title_text='word count', row=1, col=2)\nfig.update_xaxes(title_text='word count', row=1, col=3)\n\nfig.update_layout(height=1800, width=1400, title_text='Nxx gram')\nfig.add_trace(trace1, row=1, col=1)\nfig.add_trace(trace2, row=1, col=2)\nfig.add_trace(trace3, row=1, col=3)\nfig.show()","12b91c3e":"npt_all_text.build_graph(stopwords=stop_words, min_edge_frequency=2000)","9316c8b2":"npt_all_text.co_network(\n    title='Co-occurrence network',\n)","d6cce534":"npt_all_text.sunburst(\n    title='Sunburst chart',\n)","755c6fdc":"npt_all_text.wordcloud(\n    max_words=100,\n    max_font_size=100,\n    colormap='Greys',\n    stopwords=stop_words\n)","80e60415":"npt_lea.wordcloud(\n    max_words=100,\n    max_font_size=100,\n    colormap='Greys',\n    stopwords=stop_words\n)","5036bbae":"npt_pos.wordcloud(\n    max_words=100,\n    max_font_size=100,\n    colormap='Greys',\n    stopwords=stop_words\n)","ced14828":"npt_evi.wordcloud(\n    max_words=100,\n    max_font_size=100,\n    colormap='Greys',\n    stopwords=stop_words\n)","b899912b":"npt_con.wordcloud(\n    max_words=100,\n    max_font_size=100,\n    colormap='Greys',\n    stopwords=stop_words\n)","1492d540":"npt_cou.wordcloud(\n    max_words=100,\n    max_font_size=100,\n    colormap='Greys',\n    stopwords=stop_words\n)","a731857d":"npt_reb.wordcloud(\n    max_words=100,\n    max_font_size=100,\n    colormap='Greys',\n    stopwords=stop_words\n)","3d0c6b4a":"npt_all_text.word_distribution(title='All text')","2e682e1b":"npt_lea.word_distribution(title='Lead')","b6e450dc":"npt_pos.word_distribution(title='Position')","19fcc144":"npt_evi.word_distribution(title='Evidence')","30f9c343":"npt_con.word_distribution(title='Concluding Statement')","8905cd6a":"npt_cou.word_distribution(title='Counterclaim')","8d293cc2":"npt_reb.word_distribution(title='Rebuttal')","3ff9878c":"# N-gram","1958e1e9":"# Co-occurrence network & Sunburst chart","a53f7ec0":"## Counterclaim","4336f573":"## Lead -> Position -> Claim -> Claim -> ?","32f21fd1":"# Label Visualization\n\nFor this part, I took inspiration from: https:\/\/www.kaggle.com\/odins0n\/feedback-prize-eda, upvote for this notebook too! :)","cbe23416":"## Concluding Statement","e950d620":"## Rebuttal","94f22e18":"## First?","05236711":"## Counterclaim","b54cce73":"## Rebuttal","2281332f":"## Lead -> Position -> ?","2c41bf17":"## Lead","2197fb93":"## Lead -> Position -> Claim -> Claim -> Claim -> Evidence -> Evidence -> Evidence -> Concluding Statement -> ?","e2bba85c":"## Lead -> ?","aae8d05e":"## Lead -> Position -> Claim -> Claim -> Claim -> Evidence -> ?","bbe8aaaf":"## Position","cec32444":"## Lead -> Position -> Claim -> Claim -> Claim -> ?","dc569dd9":"## Lead","8426ecdf":"# Preparation\n## Library imports","31a47d69":"## Concluding Statement","a3423638":"# Flow of discourse type","9942af55":"## Evidence","a5f6392e":"## Position","845cf601":"# Dstribution of word count\n## all text","410782b0":"## Lead -> Position -> Claim -> Claim -> Claim -> Evidence -> Evidence -> ?","ec3f2b5e":"## General Functions","8baf1545":"## Lead -> Position -> Claim -> ?","ee9e7128":"# Word cloud\n## all discourse","bb8944ef":"## Evidence","caeaf8fa":"## Lead -> Position -> Claim -> Claim -> Claim -> Evidence -> Evidence -> Evidence -> ?"}}