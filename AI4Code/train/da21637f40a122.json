{"cell_type":{"26966f14":"code","1cdea656":"code","1378cc67":"code","9a66a27f":"code","da02a06f":"code","1ba0a487":"code","7f3e3d73":"code","0c85611a":"code","044c1c2c":"code","1957437e":"code","acc023e4":"code","4a70468e":"code","b4bdf585":"code","2a0282cc":"code","4c10e049":"markdown","f091ddbe":"markdown","af374ee5":"markdown","71a33ac6":"markdown","ddd8a898":"markdown","0d604ed5":"markdown","8c948285":"markdown","210e9871":"markdown","3dd3ca3c":"markdown","2ea68a9d":"markdown","5833fa21":"markdown","13dc5bed":"markdown","e864c029":"markdown"},"source":{"26966f14":"import time\nimport warnings\nimport multiprocessing\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis","1cdea656":"%%time\n\npath=Path('..\/input')\n\ndef load_data(data):\n    return pd.read_csv(data)\n\nwith multiprocessing.Pool() as pool:\n    train, test, sub = pool.map(load_data, [path\/'train.csv', \n                                            path\/'test.csv', \n                                            path\/'sample_submission.csv'])","1378cc67":"NFOLDS=5\nNTRIALS=100\nRS=42\ndebug=0\n\nlowest=0.01\nhighest=0.99","9a66a27f":"if debug:\n    magic_max=2\n    magic_min=0\n    NFOLDS=2\n    NTRIALS=2\nelse:\n    magic_max=train['wheezy-copper-turtle-magic'].max()\n    magic_min=train['wheezy-copper-turtle-magic'].min()","da02a06f":"def preprocess(clfs=['QDA'], train=train, test=test, magic_min=magic_min, magic_max=magic_max):\n    \n    prepr = {}\n    \n    #PREPROCESS 512 SEPARATE MODELS\n    for i in range(magic_min, magic_max+1):\n\n        # EXTRACT SUBSET OF DATASET WHERE WHEEZY-MAGIC EQUALS i     \n        X = train[train['wheezy-copper-turtle-magic']==i].copy()\n        Y = X.pop('target').values\n        X_test = test[test['wheezy-copper-turtle-magic']==i].copy()\n        idx_train = X.index \n        idx_test = X_test.index\n        X.reset_index(drop=True,inplace=True)\n\n        cols = [c for c in X.columns if c not in ['id', 'wheezy-copper-turtle-magic']]\n\n        l=len(X)\n        X_all = pd.concat([X[cols], X_test[cols]], ignore_index=True)\n\n        X_vt = VarianceThreshold(threshold=1.5).fit_transform(X_all)              # np.ndarray\n        \n        prepr['vt_' + str(i)] = X_vt        \n        prepr['train_size_' + str(i)] = l\n        prepr['idx_train_' + str(i)] = idx_train\n        prepr['idx_test_' + str(i)] = idx_test\n        prepr['target_' + str(i)] = Y\n        \n    return prepr","1ba0a487":"%%time\n\ndata = preprocess()","7f3e3d73":"def get_data(i, data):\n    \n    l = data['train_size_' + str(i)]    \n\n    X_all = data['vt_' + str(i)]                \n\n    X = X_all[:l, :]\n    X_test = X_all[l:, :]\n\n    Y = data['target_' + str(i)]\n\n    idx_train = data['idx_train_' + str(i)]\n    idx_test = data['idx_test_' + str(i)]\n    \n    return X, X_test, Y, idx_train, idx_test","0c85611a":"def pseudolabeling(X_train, X_test, Y_train, Y_pseudo, \n                   idx_test, lowest=lowest, highest=highest, test=test):\n    \n    assert len(test) == len(Y_pseudo), \"The length of test does not match that of Y_pseudo!\"\n    \n    #SELECT ONLY THE PSEUDOLABLES CORRESPONDING TO THE CURRENT VALUES OF 'wheezy-copper-turtle-magic'\n    Y_aug = Y_pseudo[idx_test]\n    \n    assert len(Y_aug) == len(X_test), \"The length of Y_aug does not match that of X_test!\"\n\n    Y_aug[Y_aug > highest] = 1\n    Y_aug[Y_aug < lowest] = 0\n    \n    mask = (Y_aug == 1) | (Y_aug == 0)\n    \n    Y_useful = Y_aug[mask]\n    X_test_useful = X_test[mask]\n    \n    X_train_aug = np.vstack((X_train, X_test_useful))\n    Y_train_aug = np.vstack((Y_train.reshape(-1, 1), Y_useful.reshape(-1, 1)))\n    \n    return X_train_aug, Y_train_aug","044c1c2c":"def train_classifier(clf_name, clfs, data=data, train=train, test=test, \n                     debug=debug, NFOLDS=NFOLDS, RS=RS, Y_pseudo=None,\n                     magic_min=magic_min, magic_max=magic_max,\n                     lowest=lowest, highest=highest, verbose=1):\n    \n    auc_all = np.array([])\n    oof = np.zeros(len(train))\n    preds = np.zeros(len(test))    \n    \n    #TRAIN 512 SEPARATE MODELS\n    for i in range(magic_min, magic_max+1):\n        \n        X, X_test, Y, idx_train, idx_test = get_data(i=i, data=data)      \n   \n        # STRATIFIED K FOLD    \n        folds = StratifiedKFold(n_splits=NFOLDS, random_state=RS)\n        \n        auc_folds = np.array([])\n        \n        for train_index, val_index in folds.split(X, Y):     \n\n            X_train, Y_train = X[train_index, :], Y[train_index]\n            X_val, Y_val = X[val_index, :], Y[val_index]\n            \n            if Y_pseudo is not None:\n                X_train_aug, Y_train_aug = pseudolabeling(X_train, X_test, \n                                                          Y_train, Y_pseudo, idx_test, \n                                                          lowest=lowest, highest=highest, \n                                                          test=test)\n                clfs[clf_name].fit(X_train_aug, Y_train_aug)                \n            else:\n                clfs[clf_name].fit(X_train, Y_train)\n\n            oof[idx_train[val_index]] = clfs[clf_name].predict_proba(X_val)[:,1]\n            preds[idx_test] += clfs[clf_name].predict_proba(X_test)[:,1]\/NFOLDS\n\n            auc = roc_auc_score(Y_val, oof[idx_train[val_index]])\n            auc_folds = np.append(auc_folds, auc)\n                 \n        auc_all = np.append(auc_all, np.mean(auc_folds))\n        \n    auc_combo = roc_auc_score(train['target'].values, oof)\n    auc_av = np.mean(auc_all)\n    std = np.std(auc_all)\/(np.sqrt(NFOLDS)*np.sqrt(magic_max+1))\n    \n    if verbose:    \n        # PRINT VALIDATION CV AUC FOR THE CLASSFIER\n        print(f'The result summary for the {clf_name} classifier:')\n        print(f'The combined CV score is {round(auc_combo, 5)}.')    \n        print(f'The folds average CV score is {round(auc_av, 5)}.')\n        print(f'The standard deviation is {round(std, 5)}.\\n')\n    \n    return preds, auc_combo","1957437e":"%%time\n\nresults = {}\nresults['rp']=np.array([])\nresults['auc']=np.array([])\n        \nnp.random.seed(RS)\n\nfor j in range(NTRIALS):\n\n    rp=10**(-2*np.random.rand()) # sampling values between 0.01 and 1\n       \n    # KEY: NAME, VALUE: [CLASSIFIER, DO_RANKING]\n    clfs_init={'QDA': QuadraticDiscriminantAnalysis(reg_param=rp)}\n\n    clfs={'QDA': QuadraticDiscriminantAnalysis(reg_param=rp)}\n\n    Y_pseudo, _ = train_classifier('QDA', clfs=clfs_init, verbose=0)\n\n    _, auc = train_classifier('QDA', clfs=clfs, Y_pseudo=Y_pseudo, verbose=0)\n        \n    results['rp']=np.append(results['rp'], rp)\n    results['auc']=np.append(results['auc'], auc)\n        \n    print(f\"Trial number {j}: AUC = {round(auc, 5)}, rp={round(rp, 5)}.\\n\")   ","acc023e4":"auc_max = np.max(results['auc'])\ni_max = np.argmax(results['auc'])\nrp_best = results['rp'][i_max]\n\nprint(f\"The highest AUC achived is {round(auc_max, 5)} for rp={round(rp_best, 5)}.\")\n\nauc_min = np.min(results['auc'])\ni_min = np.argmin(results['auc'])\n\nprint(f\"The lowest AUC achived is {round(auc_min, 5)} for rp={round(results['rp'][i_min], 5)}.\")\n\n#CHECK IF THE BEST VALUE IS ON THE BOUNDARY\nprint(f\"The smallest value of `reg_param` that was explored during the search is {round(np.min(results['rp']), 5)}.\")\nprint(f\"The larges value of `reg_param` that was explored during the search is {round(np.max(results['rp']), 5)}.\")","4a70468e":"import matplotlib.pyplot as plt\n\nplt.scatter(results['rp'], results['auc'], s=4)\nplt.xlabel('reg_param')\nplt.ylabel('ROC AUC')","b4bdf585":"clfs_best = {'QDA': QuadraticDiscriminantAnalysis(reg_param=rp_best)}\n\npreds_best, auc_best = train_classifier('QDA', clfs=clfs_best, Y_pseudo=Y_pseudo, verbose=0)\n\nprint(f\"AUC: {auc_best}\")","2a0282cc":"sub['target'] = preds_best\nsub.to_csv('submission.csv',index=False)","4c10e049":"### Loading Data","f091ddbe":"## Submission\n\n### Training the Classifier with the Best Parameters","af374ee5":"### Visualizing the Results of the Search","71a33ac6":"### Loading Libraries","ddd8a898":"### Preparing Things for Cross-Validation","0d604ed5":"## Parameter Search\n\n### Trying Different Values of the Parameters","8c948285":"Define the preprocessing function applying variance threshold to data grouped by the values of the `wheezy-copper-turtle-magic` variable.","210e9871":"Checking and handling the debuging mode (low values of `magic_max` and `NFOLDS` save a lot of time; the latter breaks cross-validation):","3dd3ca3c":"Defining the optional parameters.","2ea68a9d":"UPDATED!!!\n\n## The Purpose of This Notebook\n\nIn earlier versions of the notebook we were investigating the question of parameter tuning for the QDA model. Now, after the power of pseudolabeling was finally revealed the question becomes: What would be the best values of the QDA parameters with pseudolabeling? This notebook does not answer this question completely but it gives you the right tool to do this investigation on your own. \n\n## Short Description of the Method\n\nOur method is very simple: we generate 100 random values for the QDA parameter `reg_param` and then train 100 different models: one model for each value of `reg_param`. Then the value that maximizes ROC AUC score is identified and the results are visualized in the form of the AUC vs `reg_parm` scatter plot.\n\nHere is the list of our assumptions:\n\n* If you remember how pseudolableing with QDA works (which was very well explained in [Roman's](https:\/\/www.kaggle.com\/nroman\/i-m-overfitting-and-i-know-it) and [Chris's](https:\/\/www.kaggle.com\/cdeotte\/psuedo-labeling-qda-0-969) kernels) then you remember that we need to train QDA twice: one time without pseudolableing and the other with pseudolabeling. In what follows we will assume for simplicity that for both of these trainings the same value of `reg_param` is used. It is not difficult to modify the code below if you want to explore non-equal values of the parameters. \n\n* We also use `lowest=0.01`, `highest=0.99`, the same values as in Chris's notebook. Those can be easily adjusted as well. \n\n* In this notebook, we will do 100 trials with 5-fold cross-validation each. This can be easily adjusted by modifying the values of the parameter `NTRIALS` and `NFODS` below.\n\nEnjoy!","5833fa21":"## Preparatory Work","13dc5bed":"### Summary of the Results","e864c029":"### Creating the Submission File"}}