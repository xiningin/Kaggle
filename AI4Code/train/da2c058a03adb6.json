{"cell_type":{"d36e7ebf":"code","a0a47303":"code","05b75223":"code","0d111742":"code","0bd0e41a":"code","1ae73dd7":"code","a9bdeace":"code","48b788c0":"code","41859ad3":"code","c972c806":"code","638d5fcd":"code","3eeb10e7":"code","99e93231":"code","07e582aa":"code","5508f3e9":"code","5744d6ff":"code","cede8401":"code","259173a1":"code","11e3796a":"code","108490b0":"code","6c707445":"code","da8eac00":"code","e15ebded":"code","5a767ca9":"code","a49b7bc4":"code","8bcde798":"code","0473f43b":"code","343f8cd6":"code","2e083d08":"code","7478274d":"code","714e27c5":"code","b31f6bdb":"code","6358b8c6":"code","d4ae9eed":"code","e4db8922":"code","104a8cdd":"code","da5ad762":"code","6d90a261":"code","8699d775":"code","51cddb5b":"code","a476fdab":"code","91a0259f":"code","f97669e7":"code","c7f72741":"code","f40a5783":"code","c2ae41ab":"code","19e1237b":"code","aed6cab9":"code","7436d88c":"code","7638ada2":"code","29292493":"code","6f9409dd":"code","905d0f63":"code","3b0c091a":"code","1896dfd4":"code","f0559851":"code","a71b98df":"code","cf82fb5a":"code","f72faf6c":"code","702a55e8":"code","084f3af8":"code","481213dc":"code","0fb6d3cd":"code","ffcb08d1":"code","da8f5223":"code","d24c4930":"code","26288ab5":"code","0d0dd432":"code","fcfd4941":"code","ebc882f0":"code","4de62c26":"code","b4f51f82":"code","d21ad41f":"code","7245bc2b":"code","0390a5a3":"code","817919bf":"code","99601957":"code","0e06a9c2":"code","ba56c7be":"code","c2af5941":"code","086acab5":"code","7f29dc1a":"code","d62b47b9":"code","055a6f75":"code","a6b1cc49":"code","b61b2281":"code","6da49f11":"code","7827555f":"code","f6b835b2":"markdown","7c87b4a4":"markdown","714d023b":"markdown","9359b7ae":"markdown","a33f3da4":"markdown","00156df2":"markdown","89c867bf":"markdown","efaf0255":"markdown","ec1a8648":"markdown","ac3780b5":"markdown","6c91b8db":"markdown","857fd3dc":"markdown","b5675627":"markdown","47128e56":"markdown","c8909930":"markdown","e1b5f306":"markdown","0233c5ec":"markdown","4d92fb97":"markdown","1106cc9f":"markdown","ab6da951":"markdown","d6442eca":"markdown","36b4a2d1":"markdown","c04b706f":"markdown","b3770ba0":"markdown","9b3be2c1":"markdown","36abb48f":"markdown","f83dba1d":"markdown","d9c67262":"markdown"},"source":{"d36e7ebf":"from IPython.display import Image\nImage(\"..\/input\/ctgimage\/aparelho-ctg.png\")","a0a47303":"# Carregando os pacotes\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc, precision_score, recall_score, roc_auc_score \nimport warnings\nwarnings.filterwarnings(\"ignore\")","05b75223":"pd.__version__","0d111742":"np.__version__","0bd0e41a":"fetal_health = pd.read_csv('..\/input\/fetal-health-classification\/fetal_health.csv')","1ae73dd7":"fetal_health.head(20)","a9bdeace":"fetal_health.info()","48b788c0":"# Verificando valores nulos\nfetal_health.isnull().sum()","41859ad3":"fetal_health['fetal_health'] = fetal_health['fetal_health'].astype('int64')","c972c806":"# Formato dos dados\nfetal_health.shape","638d5fcd":"# Verificando valores \u00fanicos\nfor col in list(fetal_health.columns):\n    \n    # Obt\u00e9m uma lista de valores \u00fanicos\n    list_of_unique_values = fetal_health[col].unique()\n    \n    # Se o n\u00famero de valores exclusivos for menor que 15, imprima os valores. \n    # Caso contr\u00e1rio, imprima o n\u00famero de valores exclusivos\n    if len(list_of_unique_values) < 15:\n        print(\"\\n\")\n        print(col + ': ' + str(len(list_of_unique_values)) + ' valores \u00fanicos')\n        print(list_of_unique_values)\n    else:\n        print(\"\\n\")\n        print(col + ': ' + str(len(list_of_unique_values)) + ' valores \u00fanicos')","3eeb10e7":"# Checando as colunas que tem valor = '?'\nfetal_health.isin(['?']).any()","99e93231":"fetal_health['fetal_health'].value_counts()","07e582aa":"sns.set(style=\"whitegrid\")\n\n#Usando um gr\u00e1fico de barras para mostrar a distribui\u00e7\u00e3o das classes: Morrer e Sobreviver\nbp = sns.countplot(x=fetal_health['fetal_health'])\nplt.title(\"Distribui\u00e7\u00e3o de classe do conjunto de dados\")\nbp.set_xticklabels([\"Normal\",\"Suspeito\",\"Patol\u00f3gico\"])\nplt.show()","5508f3e9":"# Verifica a propor\u00e7\u00e3o de cada classe\nround(fetal_health['fetal_health'].value_counts() \/ len(fetal_health.index) * 100, 0)","5744d6ff":"# Vamos visualizar de forma gr\u00e1fica\n\n# Percentual de cada valor da vari\u00e1vel alvo\npercentual = round(fetal_health['fetal_health'].value_counts() \/ len(fetal_health.index) * 100, 0)\n\n# Labels\nlabels = [\"Normal\",\"Suspeito\",\"Patol\u00f3gico\"]\n\n# Plot\nplt.axis(\"equal\")\nplt.pie(percentual , \n        labels = labels,\n        radius = 1.6,\n        autopct = '%1.2f%%',\n        explode = [0.05,0.05,0.05],\n        startangle = 90,\n        shadow = True,\n        counterclock = False,\n        pctdistance = 0.6)\nplt.show()","cede8401":"# Coletando estat\u00edsticas das colunas\nfetal_health.describe()","259173a1":"# Fun\u00e7\u00e3o para visualizar a distribui\u00e7\u00e3o de cada vari\u00e1vel\ndef cria_histograma(df, features, rows, cols):\n    fig = plt.figure(figsize = (20,20))\n    \n    for i, feature in enumerate(features):\n        ax = fig.add_subplot(rows, cols, i+1)\n        df[feature].hist(bins = 20, ax = ax, facecolor = 'midnightblue')\n        ax.set_title(feature + \" Distribui\u00e7\u00e3o\", color = 'DarkRed')\n        \n    fig.tight_layout()  \n    plt.show()","11e3796a":"# Executa a fun\u00e7\u00e3o\ncria_histograma(fetal_health, fetal_health.columns, 8, 3)","108490b0":"# Avaliando a correla\u00e7\u00e3o das vari\u00e1veis independentes com a vari\u00e1vel alvo\ncorr = fetal_health.corr()\ncorr[['fetal_health']].sort_values(by = 'fetal_health',ascending = False).style.background_gradient()","6c707445":"fetal_health_clean = fetal_health.drop('fetal_health', axis = 1)\ny = fetal_health['fetal_health']","da8eac00":"fetal_health_clean","e15ebded":"# Avaliando a Correla\u00e7\u00e3o das vari\u00e1veis\ncorr = fetal_health_clean.corr()","5a767ca9":"# Cria o mapa de calor com a matriz de correla\u00e7\u00e3o\nf, ax = plt.subplots(figsize = (15, 9))\nsns.heatmap(corr, cbar = True, annot = True, fmt = '.2f', annot_kws = {'size': 10}, vmax = 1, square = True, cmap = 'rainbow')\nplt.show()","a49b7bc4":"# Import library for VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)","8bcde798":"calc_vif(fetal_health_clean)","0473f43b":"fetal_health_clean.shape[1]","343f8cd6":"# Renomeando a vari\u00e1vel baseline value para baseline_value\nfetal_health_clean['baseline_value'] = fetal_health_clean['baseline value']\ndel fetal_health_clean['baseline value']","2e083d08":"!pip install factor_analyzer","7478274d":"from sklearn.decomposition import FactorAnalysis\nfrom factor_analyzer import FactorAnalyzer\nfrom factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\nfrom factor_analyzer.factor_analyzer import calculate_kmo","714e27c5":"# \nscaler = StandardScaler()\n\nscaled_fetal_health_clean=fetal_health_clean.copy()\nscaled_fetal_health_clean=pd.DataFrame(scaler.fit_transform(scaled_fetal_health_clean), columns=scaled_fetal_health_clean.columns)\nscaled_fetal_health_clean.info()","b31f6bdb":"#Teste de adequa\u00e7\u00e3o\n\n#Bartlett\n#p-value should be 0 (statistically sig.)\nchi_square_value,p_value=calculate_bartlett_sphericity(scaled_fetal_health_clean)\nprint(chi_square_value, p_value)","6358b8c6":"#KMO\n#Value should be 0.6<\nkmo_all,kmo_model=calculate_kmo(scaled_fetal_health_clean)\nprint(kmo_model)","d4ae9eed":"scaled_fetal_health_clean","e4db8922":"#EXPLORATORY FACTOR ANALYSIS\nfa = FactorAnalyzer(rotation=None)\nfa.fit(scaled_fetal_health_clean)","104a8cdd":"#GET EIGENVALUES\nev, v = fa.get_eigenvalues()","da5ad762":"# SCREEPLOT (need pyplot)\nplt.scatter(range(1,scaled_fetal_health_clean.shape[1]+1),ev)\nplt.plot(range(1,scaled_fetal_health_clean.shape[1]+1),ev)\nplt.title('Scree Plot')\nplt.xlabel('Factors')\nplt.ylabel('Eigenvalue')\nplt.grid(True)\nplt.show()","6d90a261":"fa = FactorAnalysis(n_components=3, random_state=0, svd_method='lapack')","8699d775":"fa.fit(scaled_fetal_health_clean)","51cddb5b":"# Create factor analysis object and perform factor analysis\nfa = FactorAnalyzer(3, rotation=\"varimax\", method='minres', use_smc=True)\nfa.fit(scaled_fetal_health_clean)","a476fdab":"fa.loadings_","91a0259f":"fa.get_communalities()","f97669e7":"# Get variance of each factors\nfa.get_factor_variance()","c7f72741":"loadings = pd.DataFrame(fa.loadings_, columns=['Factor 1', 'Factor 2', 'Factor 3'], index=scaled_fetal_health_clean.columns)\nfator1 = loadings['Factor 1'].copy()\nfator2 = loadings['Factor 2'].copy()\nfator3 = loadings['Factor 3'].copy()\nprint('Factor 1 \\n%s' %fator1.sort_values(ascending=False))\nprint('')\nprint('Factor 2 \\n%s' %fator2.sort_values(ascending=False))\nprint('')\nprint('Factor 3 \\n%s' %fator3.sort_values(ascending=False))","f40a5783":"!pip install pingouin","c2ae41ab":"import pingouin as pg","19e1237b":"#Create the factors\nfactor1 = scaled_fetal_health_clean[['histogram_width', 'histogram_variance', 'histogram_number_of_peaks', 'mean_value_of_short_term_variability', 'histogram_max', 'light_decelerations']]\nfactor2 = scaled_fetal_health_clean[['histogram_mode', 'histogram_mean', 'histogram_median', 'baseline_value']]\nfactor3 = scaled_fetal_health_clean[['abnormal_short_term_variability', 'percentage_of_time_with_abnormal_long_term_variability']]\n#Get cronbach alpha\nfactor1_alpha = pg.cronbach_alpha(factor1)\nfactor2_alpha = pg.cronbach_alpha(factor2)\nfactor3_alpha = pg.cronbach_alpha(factor3)\nprint(factor1_alpha, factor2_alpha, factor3_alpha)","aed6cab9":"# Criando um Dataframe com apenas com as colunas que possuem maior relev\u00eancia para os fatores \nscaled_fetal_health_fact = pd.concat([factor1, factor2, factor3], axis=1, join='inner')","7436d88c":"scaled_fetal_health_fact","7638ada2":"# Aplicando os fatores ao Dataframe\nscaled_fetal_health_new = fa.fit_transform(scaled_fetal_health_fact)","29292493":"coluns_fact = ['factor1', 'factor2', 'factor3']","6f9409dd":"scaled_fetal_health_new_fact=pd.DataFrame(scaled_fetal_health_new, columns=coluns_fact)","905d0f63":"fetal_health_clean_new = fetal_health_clean.copy()","3b0c091a":"# Eliminando a colunas com colinearidade que foram substituidas por fatores\nfor col in factor1:\n    del fetal_health_clean_new[col]\nfor col in factor2:\n    del fetal_health_clean_new[col]\nfor col in factor3:\n    del fetal_health_clean_new[col]","1896dfd4":"# Criando a vers\u00e3o final do Dataframe \nfetal_health_clean_finish = pd.concat([fetal_health_clean_new, scaled_fetal_health_new_fact], axis=1, join='inner')","f0559851":"fetal_health_clean_finish","a71b98df":"fetal_health_clean_finish.shape","cf82fb5a":"fetal_health_clean_finish.columns","f72faf6c":"X = fetal_health_clean_finish","702a55e8":"# Aplica a divis\u00e3o com propor\u00e7\u00e3o 70\/30\nX_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size = 0.30, random_state = 101)","084f3af8":"# Treina o padronizador com o m\u00e9todo fit() e aplica com o m\u00e9todo transform() nos dados de treino e teste.\n\nX_scaled_treino = X_treino.copy()\nX_scaled_teste = X_teste.copy()\n\n# features\nnum_cols = fetal_health_clean_finish.columns\n\n# Padronizando as vari\u00e1veis de entrada\nfor i in num_cols:\n    \n    # fit on training data column\n    scale = StandardScaler().fit(X_scaled_treino[[i]])\n    \n    # transform the training data column\n    X_scaled_treino[i] = scale.transform(X_scaled_treino[[i]])\n    X_scaled_teste[i] = scale.transform(X_scaled_teste[[i]])","481213dc":"# Cria o seletor de vari\u00e1veis\n\n# Cria o estimador\nestimador_rfc = RandomForestClassifier(random_state = 101)\n\n# Cria o seletor\nseletor_f1 = RFECV(estimator = estimador_rfc, step = 1, cv = StratifiedKFold(10), scoring='f1_macro')\n\n# Treinamos o seletor\nseletor_f1 = seletor_f1.fit(X_scaled_treino, y_treino)","0fb6d3cd":"print('N\u00famero Ideal de Atributos: {}'.format(seletor_f1.n_features_))","ffcb08d1":"# Vamos avaliar a acur\u00e1cia do modelo com F1 Score\nprevisoes_seletor_f1 = seletor_f1.predict(X_scaled_teste)\nfrom sklearn.metrics import accuracy_score\nacc_seletor_f1 = accuracy_score(y_teste, previsoes_seletor_f1)\nacc_seletor_f1","da8f5223":"# Visualiza os scores das vari\u00e1veis mais importantes\nseletor_f1.estimator_.feature_importances_","d24c4930":"X_scaled_treino.columns","26288ab5":"seletor_f1.support_","0d0dd432":"X_scaled_treino# Cria um dataframe com os resultados\nresultado_seletor_f1 = pd.DataFrame()\nresultado_seletor_f1['Atributo'] = X_scaled_treino.columns[np.where(seletor_f1.support_ == True)]\nresultado_seletor_f1['Score'] = seletor_f1.estimator_.feature_importances_\nresultado_seletor_f1.sort_values('Score', inplace = True, ascending = True)","fcfd4941":"# Plot \n#plt.figure(figsize = (10, 10))\nplt.barh(y = resultado_seletor_f1['Atributo'], width = resultado_seletor_f1['Score'], color = 'Blue')\nplt.title('Import\u00e2ncia de Vari\u00e1veis - RFECV', fontsize = 18, fontweight = 'bold', pad = 10)\nplt.xlabel('Import\u00e2ncia', fontsize = 14, labelpad = 15)\nplt.show()","ebc882f0":"# Extrai as vari\u00e1veis e quais s\u00e3o importante ou n\u00e3o para o modelo\nvariaveis_rfecv = pd.Series(seletor_f1.support_, index = X_scaled_treino.columns)\nvariaveis_rfecv","4de62c26":"del X_scaled_treino['severe_decelerations']\ndel X_scaled_treino['histogram_number_of_zeroes']\ndel X_scaled_treino['histogram_tendency']\n#del X_scaled_treino['fetal_movement']","b4f51f82":"del X_scaled_teste['severe_decelerations']\ndel X_scaled_teste['histogram_number_of_zeroes']\ndel X_scaled_teste['histogram_tendency']\n#del X_scaled_teste['fetal_movement']","d21ad41f":"# Fit model using each importance as a threshold\nthresholds = np.sort(seletor_f1.estimator_.feature_importances_)\nfor thresh in thresholds:\n    # select features using threshold\n    selection = SelectFromModel(seletor_f1.estimator_, threshold=thresh, prefit=True)\n    select_X_treino = selection.transform(X_scaled_treino)\n    # train model\n    selection_model = ExtraTreesClassifier()\n    selection_model.fit(select_X_treino, y_treino)\n    # eval model\n    select_X_teste = selection.transform(X_scaled_teste)\n    y_pred = selection_model.predict(select_X_teste)\n    predictions = [round(value) for value in y_pred]\n    accuracy = accuracy_score(y_teste, predictions)\n    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_treino.shape[1], accuracy*100.0))","7245bc2b":"# Regress\u00e3o Log\u00edstica\n\n# Cria o modelo\nmodelo_lr = LogisticRegression(tol = 1e-7, penalty = 'l2', C = 0.1, solver = 'liblinear', multi_class='ovr')\n\n# Treina o modelo\nmodelo_lr.fit(X_scaled_treino, y_treino)\n\n# Faz as previs\u00f5es\ny_pred = modelo_lr.predict(X_scaled_teste)\npredict_proba = modelo_lr.predict_proba(X_scaled_teste)\n\nprint(confusion_matrix(y_teste, y_pred))\n\n# M\u00e9tricas Globais\ncohen_kappa_lr = cohen_kappa_score(y_teste, y_pred)\nacc_lr = modelo_lr.score(X_scaled_teste, y_teste)\nprint(\"\\nCoeficiente Cohen kappa = {}\".format(cohen_kappa_lr))\nprint(\"Acur\u00e1cia = {}\".format(acc_lr))\nprint(\"\")\n\n# Relat\u00f3rio de Classifica\u00e7\u00e3o\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patol\u00f3gico']))","0390a5a3":"# XGBoost\n\nimport xgboost as xgb\n\n# Cria o modelo\nxgb_model = xgb.XGBClassifier (eta=0.1,\n                               max_depth=3,\n                               min_child_weight=8,\n                               learning_rate=0.1, \n                               colsample_bytree = 0.8,\n                               subsample = 0.80,\n                               objective='multi: softprob',\n                               n_estimators=65,\n                               reg_alpha = 0.01,\n                               num_class=3,\n                               gamma=0.01,\n                               random_state=42)\n# Treina o modelo\nxgb_model.fit(X_scaled_treino, y_treino)\n\n# Faz as previs\u00f5es\ny_pred = xgb_model.predict(X_scaled_teste)\npredict_proba = xgb_model.predict_proba(X_scaled_teste)\n\nprint(confusion_matrix(y_teste, y_pred))\n\n# M\u00e9tricas Globais\ncohen_kappa_xgb = cohen_kappa_score(y_teste, y_pred)\nacc_xgb = xgb_model.score(X_scaled_teste, y_teste)\nprint(\"\\nCoeficiente Cohen kappa = {}\".format(cohen_kappa_xgb))\nprint(\"Acur\u00e1cia = {}\".format(acc_xgb))\nprint(\"\")\n\n# Relat\u00f3rio de Classifica\u00e7\u00e3o\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patol\u00f3gico']))","817919bf":"# RandomForestClassifier\n\n# Cria o modelo\nRFclf=RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Treina o modelo\nRFclf.fit(X_scaled_treino, y_treino)\n\n# Faz as previs\u00f5es\ny_pred=RFclf.predict(X_scaled_teste)\npredict_proba = RFclf.predict_proba(X_scaled_teste)\n\nprint(confusion_matrix(y_teste, y_pred))\n\n# M\u00e9tricas Globais\ncohen_kappa_RF = cohen_kappa_score(y_teste, y_pred)\nacc_RF = RFclf.score(X_scaled_teste, y_teste)\nprint(\"\\nCoeficiente Cohen kappa = {}\".format(cohen_kappa_RF))\nprint(\"Acur\u00e1cia = {}\".format(acc_RF))\nprint(\"\")\n\n# Relat\u00f3rio de Classifica\u00e7\u00e3o\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patol\u00f3gico']))","99601957":"# Criando o classificador ExtraTreesClassifier\nETclf=ExtraTreesClassifier(n_estimators=100,random_state=42)\n\n#Train the model \nETclf.fit(X_scaled_treino, y_treino)\n\n# prediction on test set\ny_pred=ETclf.predict(X_scaled_teste)\npredict_proba = ETclf.predict_proba(X_scaled_teste)\n\nprint(confusion_matrix(y_teste, y_pred))\n\n# M\u00e9tricas Globais\ncohen_kappa_ET = cohen_kappa_score(y_teste, y_pred)\nacc_ET = ETclf.score(X_scaled_teste, y_teste)\nprint(\"\\nCoeficiente Cohen kappa = {}\".format(cohen_kappa_ET))\nprint(\"Acur\u00e1cia = {}\".format(acc_ET))\nprint(\"\")\n\n# Relat\u00f3rio de Classifica\u00e7\u00e3o\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patol\u00f3gico']))","0e06a9c2":"\ny_pred=RFclf.predict(X_scaled_teste)\npredict_proba = RFclf.predict_proba(X_scaled_teste)\nconf_matriz = confusion_matrix(y_teste, y_pred)","ba56c7be":"TP = conf_matriz[0,0] + conf_matriz[1,1] + conf_matriz[2,2]\nTN = conf_matriz[0,1] + conf_matriz[0,2] + conf_matriz[1,0] + conf_matriz[1,2] + conf_matriz[2,0] + conf_matriz[2,2]\nFP = conf_matriz[0,1] + conf_matriz[0,2] + conf_matriz[1,0] + conf_matriz[1,2] + conf_matriz[2,0] + conf_matriz[2,2]\nFN = conf_matriz[1,0] + conf_matriz[2,0] + conf_matriz[0,1] + conf_matriz[2,1] + conf_matriz[0,2] + conf_matriz[1,2]","c2af5941":"# classe Normal\nTP = conf_matriz[0,0]\nTN = conf_matriz[1,1] + conf_matriz[1,2] + conf_matriz[2,1] + conf_matriz[2,2] \nFN = conf_matriz[0,1] + conf_matriz[0,2]\nFP = conf_matriz[1,0] + conf_matriz[2,0]\nAcc = (TP + TN) \/ (TP + TN + FP + FN) \nprecisao = TP \/ (TP + FP) \nsensibilidade = TP \/ (TP + FN)\nespecificidade = TN \/ (TN + FP)\nPontua\u00e7\u00e3o_F = 2 * TP \/ (2 * TP + FP + FN)\n#\n# Print\nprint('\\nClasse Normal')\nprint('Precis\u00e3o :', precisao)\nprint('sensibilidade :', sensibilidade)\nprint('Especificidade :', especificidade)\nprint('Pontua\u00e7\u00e3o_F :', Pontua\u00e7\u00e3o_F)","086acab5":"# classe Suspeito\nTP = conf_matriz[1,1]\nTN = conf_matriz[0,0] + conf_matriz[1,2] + conf_matriz[2,1] + conf_matriz[2,2] \nFN = conf_matriz[1,0] + conf_matriz[1,2]\nFP = conf_matriz[0,1] + conf_matriz[2,1]\nAcc = (TP + TN) \/ (TP + TN + FP + FN) \nprecisao = TP \/ (TP + FP) \nsensibilidade = TP \/ (TP + FN)\nespecificidade = TN \/ (TN + FP)\nPontua\u00e7\u00e3o_F = 2 * TP \/ (2 * TP + FP + FN)\n#\n# Print\nprint('\\nClasse Suspeito')\nprint('Precis\u00e3o :', precisao)\nprint('sensibilidade :', sensibilidade)\nprint('Especificidade :', especificidade)\nprint('Pontua\u00e7\u00e3o_F :', Pontua\u00e7\u00e3o_F)","7f29dc1a":"# classe Patol\u00f3gico\nTP = conf_matriz[2,2]\nTN = conf_matriz[0,0] + conf_matriz[0,1] + conf_matriz[1,0] + conf_matriz[1,1] \nFP = conf_matriz[2,0] + conf_matriz[2,1]\nFN = conf_matriz[0,2] + conf_matriz[1,2]\nprecisao = TP \/ (TP + FP) \nsensibilidade = TP \/ (TP + FN)\nespecificidade = TN \/ (TN + FP)\nPontua\u00e7\u00e3o_F = 2 * TP \/ (2 * TP + FP + FN)\n#\n# Print\nprint('\\nClasse Patol\u00f3gico')\nprint('Precis\u00e3o :', precisao)\nprint('sensibilidade :', sensibilidade)\nprint('Especificidade :', especificidade)\nprint('Pontua\u00e7\u00e3o_F :', Pontua\u00e7\u00e3o_F)","d62b47b9":"# Relat\u00f3rio de Classifica\u00e7\u00e3o\nprint(classification_report(y_teste, y_pred, target_names = ['Normal', 'Suspeito','Patol\u00f3gico']))","055a6f75":"import scikitplot as skplt\nskplt.metrics.plot_roc(y_teste, predict_proba, figsize=(10, 8))","a6b1cc49":"import lime\nimport lime.lime_tabular","b61b2281":"# LIME tem um explainer para todos os tipos de modelos\nexplainer_v1 = lime.lime_tabular.LimeTabularExplainer(X_scaled_treino.values,  \n                              feature_names = X_scaled_treino.columns.values.tolist(), \n                              class_names = ['Normal', 'Suspeito','Patol\u00f3gico'],  \n                              verbose = True, \n                              mode = 'classification')","6da49f11":"import cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)","7827555f":"from lime import submodular_pick\nsp_obj = submodular_pick.SubmodularPick(explainer_v1, X_scaled_treino.values, RFclf.predict_proba, sample_size=190, num_features=9, num_exps_desired=5)\n#Plot the 5 explanations\n[exp.as_pyplot_figure(label=exp.available_labels()[0]) for exp in sp_obj.sp_explanations];\n# Make it into a dataframe\nW_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n \nW_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n \n#Making a dataframe of all the explanations of sampled points\nW=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\nW['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\nW['prediction']  = W.apply(lambda row: 'Normal' if (row['prediction'] == 0) else row['prediction'], axis=1)\nW['prediction']  = W.apply(lambda row: 'Suspeito' if (row['prediction'] == 1) else row['prediction'], axis=1)\nW['prediction']  = W.apply(lambda row: 'Patol\u00f3gico' if (row['prediction'] == 2) else row['prediction'], axis=1)\n#Plotting the aggregate importances\nnp.abs(W.drop(\"prediction\", axis=1)).mean(axis=0).sort_values(ascending=False).head(25).sort_values(ascending=True).iplot(kind=\"barh\")\n \n#Aggregate importances split by classes\ngrped_coeff = W.groupby(\"prediction\").mean()\n \ngrped_coeff = grped_coeff.T\ngrped_coeff[\"abs\"] = np.abs(grped_coeff.iloc[:, 0])\ngrped_coeff.sort_values(\"abs\", inplace=True, ascending=False)\ngrped_coeff.head(25).sort_values(\"abs\", ascending=True).drop(\"abs\", axis=1).iplot(kind=\"barh\", bargap=0.05) \n","f6b835b2":"Ap\u00f3s comparar o desempenho entre os modelos, o que obteve a melhor performance foi o RandomForestClassifier, agora vamos avaliar a sua performance.","7c87b4a4":"VIF superior a 5 ou 10 indica alta multicolinearidade entre esta vari\u00e1vel independente e as outras, neste caso podemos perceber uma alta colinearidade entre as vari\u00e1veis histogram_mode, histogram_mean, histogram_median, baseline value, tamb\u00e9m entre as vari\u00e1veis histogram_width, histogram_mean e histogram_median.\n\nResolverei o problema de multicolinearidade empregando a an\u00e1lise fatorial para agrupar em fatores as vari\u00e1vies com alta colinearidade, depois eliminarei as vari\u00e1veis colineares, mantendo as demais vari\u00e1veis juntamente com os fatores.","714d023b":"## Prevendo resultado de exame CTG\n\n### por Antonildo Santos","9359b7ae":"Em nosso conjunto de dados n\u00e3o existem dados faltantes, isto \u00e9 muito bom, pois n\u00e3o precisaremos utilizar nenhum tipo de m\u00e9todo de inputa\u00e7\u00e3o de dados.","a33f3da4":"## Criando o Classificador","00156df2":"### Interpretando o resultado do\u00a0Modelo\nPara realizar este trabalho utilizei o pacote LIME, que serve para gerar explica\u00e7\u00f5es locais para o modelo. A ideia central por tr\u00e1s da t\u00e9cnica \u00e9 bastante intuitiva. Suponha que temos um classificador complexo, com um limite de decis\u00e3o altamente n\u00e3o linear, seu objetivo \u00e9 entender por que o modelo de aprendizado de m\u00e1quina fez uma determinada previs\u00e3o. O LIME testa o que acontece com as previs\u00f5es quando voc\u00ea d\u00e1 varia\u00e7\u00f5es de seus dados ao modelo de aprendizado de m\u00e1quina.","89c867bf":"O objetivo deste trabalho \u00e9 analisar um conjunto de dados contendo medi\u00e7\u00f5es extra\u00eddas de cardiotocogramas fetais (CTGs) e criar um modelo para classificar o resultado do exame de Cardiotocograma (CTG) (que representa o bem-estar do feto).\n\n## Introdu\u00e7\u00e3o\n\nA aus\u00eancia de acompanhamento m\u00e9dico \u00e9 considerada uma das principais causas de mortalidade infantil, conforme dados do Fundo de Popula\u00e7\u00e3o das Na\u00e7\u00f5es Unidas (Fnuap), a taxa de mortalidade infantil mundial \u00e9 de 45 \u00f3bitos a cada mil crian\u00e7as nascidas vivas. Apesar de comprovadamente este n\u00famero est\u00e1 em constante decl\u00ednio \u00e9 importante destacar que essa redu\u00e7\u00e3o n\u00e3o ocorre na mesma propor\u00e7\u00e3o em todos os pa\u00edses. A ONU espera que, at\u00e9 2030, os pa\u00edses acabem com as mortes evit\u00e1veis \u200b\u200bde rec\u00e9m-nascidos e crian\u00e7as menores de 5 anos de idade, e espera que todos os pa\u00edses reduzam a mortalidade de menores de 5 anos para pelo menos 25 por 1.000 nascidos vivos.\n\nA morbimortalidade materna e perinatal continuam ainda muito elevadas no Brasil, incompat\u00edveis com o atual n\u00edvel de desenvolvimento econ\u00f4mico e social do Pa\u00eds. Sabe-se que a maioria das mortes e complica\u00e7\u00f5es que surgem durante a gravidez,\nparto e puerp\u00e9rio s\u00e3o preven\u00edveis, mas para isso \u00e9 necess\u00e1ria a participa\u00e7\u00e3o ativa do sistema de sa\u00fade. \n\nDiante do exposto, os Cardiotocogramas (CTGs) s\u00e3o uma op\u00e7\u00e3o simples e de baixo custo para avalia\u00e7\u00e3o da sa\u00fade fetal, permitindo aos profissionais de sa\u00fade atuarem na preven\u00e7\u00e3o da mortalidade infantil e materna. O pr\u00f3prio equipamento funciona enviando pulsos de ultrassom e lendo sua resposta, lan\u00e7ando luz sobre a frequ\u00eancia card\u00edaca fetal (FCF), movimentos fetais, contra\u00e7\u00f5es uterinas e muito mais. \nHospitais, maternidades e cl\u00ednicas obst\u00e9tricas que buscam oferecer um atendimento integral \u00e0 gestante devem estar preparados para a realiza\u00e7\u00e3o da cardiotocografia (CTG). O exame avalia a vitalidade do beb\u00ea e indica o sofrimento fetal, trazendo alertas como a necessidade da antecipa\u00e7\u00e3o do parto, por exemplo.\n\n### Sobre o conjunto de dados\n\nEste conjunto de dados possui 2126 medi\u00e7\u00f5es extra\u00eddas de cardiotocogramas fetais (CTGs) que foram processados \u200b\u200bautomaticamente e os respectivos recursos diagn\u00f3sticos medidos. Os CTGs tamb\u00e9m foram classificados por tr\u00eas obstetras especialistas e uma etiqueta de classifica\u00e7\u00e3o de consenso atribu\u00edda a cada um deles, conforme descrito em:\n\nAyres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5: 311-318","efaf0255":"### Sele\u00e7\u00e3o de Atributos (Feature Selection)","ec1a8648":"O m\u00e9todo do scree plot desenha uma linha reta para cada fator e seus autovalores. Numere os valores pr\u00f3prios maiores que um considerado como o n\u00famero de fatores.\n\nAqui, voc\u00ea pode ver apenas que os valores pr\u00f3prios de 5 fatores s\u00e3o maiores que um. Isso significa que precisamos escolher apenas 5 fatores (ou vari\u00e1veis \u200b\u200bn\u00e3o observadas). Por\u00e9m ap\u00f3s avaliar as possibilidades cheguei ao n\u00famero de 3 fatores.","ac3780b5":"A vari\u00e1vel alvo desse conjunto de dados nos indicam tr\u00eas classes que representam a etiqueta de classifica\u00e7\u00e3o de consenso atribu\u00edda por tr\u00eas obstetras especialistas.","6c91b8db":"# Fim","857fd3dc":"O teste de Bartlett retornou o valor p igual zero, isso quer dizer que o teste foi estatisticamente significativo, indicando que a matriz de correla\u00e7\u00e3o observada n\u00e3o \u00e9 uma matriz identidade.\n\nO KMO geral para nossos dados \u00e9 de 0.74, o que \u00e9 excelente. Este valor indica que posso prosseguir com a an\u00e1lise fatorial planejada.","b5675627":"### Refer\u00eancias\n\nForma\u00e7\u00e3o Intelig\u00eancia Artificial Aplicada \u00e0 Medicina\nhttps:\/\/www.datascienceacademy.com.br\/\n\nMinist\u00e9rio da Sa\u00fade http:\/\/bvsms.saude.gov.br\/bvs\/publicacoes\/manual_tecnico_gestacao_alto_risco.pdf\n\nIntroduction to Factor Analysis in Python https:\/\/www.datacamp.com\/community\/tutorials\/introduction-factor-analysis\n\nRFECV https:\/\/www.scikit-yb.org\/en\/latest\/api\/model_selection\/rfecv.html\n\nInterpretability part 3: opening the black box with LIME and SHAP https:\/\/www.kdnuggets.com\/2019\/12\/interpretability-part-3-lime-shap.html\n","47128e56":"## Avaliando a performance do modelo","c8909930":"## Carregando os Dados","e1b5f306":"### Teste de Adequa\u00e7\u00e3o para An\u00e1lise Fatorial\nAntes de realizar a an\u00e1lise fatorial, precisamos avaliar a \u201cfatorabilidade\u201d de nosso conjunto de dados. Fatorabilidade significa \"podemos encontrar os fatores no conjunto de dados?\". Existem dois m\u00e9todos para verificar a fatorabilidade ou adequa\u00e7\u00e3o da amostragem:\n\n* Teste de Bartlett\n* Teste Kaiser-Meyer-Olkin\n\nO teste de esfericidade de Bartlett verifica se as vari\u00e1veis \u200b\u200bobservadas est\u00e3o correlacionadas entre si ou n\u00e3o, usando a matriz de correla\u00e7\u00e3o observada contra a matriz de identidade. Se o teste n\u00e3o for estatisticamente significante, n\u00e3o devemos empregar uma an\u00e1lise fatorial.\n\nO teste Kaiser-Meyer-Olkin (KMO) mede a adequa\u00e7\u00e3o dos dados para a an\u00e1lise fatorial. Ele determina a adequa\u00e7\u00e3o para cada vari\u00e1vel observada e para o modelo completo. KMO estima a propor\u00e7\u00e3o da vari\u00e2ncia entre todas as vari\u00e1veis \u200b\u200bobservadas. Menor propor\u00e7\u00e3o \u00e9 mais adequado para an\u00e1lise fatorial. Os valores de KMO variam entre 0 e 1. O valor de KMO menor que 0,6 \u00e9 considerado inadequado.","0233c5ec":"O Cronbach Alfa pode ser usado para medir se as vari\u00e1veis de um fator formam ou n\u00e3o um fator \u201ccoerente\u201d e confi\u00e1vel. Um valor acima de 0.6 para o alfa \u00e9, na pr\u00e1tica, considerado aceit\u00e1vel.","4d92fb97":"Fonte dos dados: https:\/\/archive.ics.uci.edu\/ml\/datasets\/cardiotocography","1106cc9f":"Atrav\u00e9s do gr\u00e1fico de correla\u00e7\u00e3o podemos perceber que existe colinearidade entre algumas vari\u00e1veis, como por exemplo histogram_median, histogram_mean, histogram_mode. Vamos constatar isso atrav\u00e9s do metodo VIF (Variance Inflation Factor).","ab6da951":"### Escolhendo o n\u00famero de fatores\n\nPara escolher o n\u00famero de fatores, voc\u00ea pode usar o crit\u00e9rio de Kaiser e o gr\u00e1fico de scree. Ambos s\u00e3o baseados em valores pr\u00f3prios.","d6442eca":"O primeiro gr\u00e1fico d\u00e1 uma ideia de quais recursos s\u00e3o importantes para o modelo num sentido mais amplo. Bem no topo do gr\u00e1fico, podemos encontrar o n\u00famero de desacelera\u00e7\u00f5es prolongadas por segundo como um indicador muito forte para diagnosticar o estado fetal, seguido do \"fator 3\" que representa o valor m\u00e9dio de variabilidade de curto prazo e porcentagem de tempo com variabilidade anormal de longo prazo.\n\nO segundo gr\u00e1fico divide a infer\u00eancia entre os tr\u00eas r\u00f3tulos e os examina separadamente. Este gr\u00e1fico nos permite entender qual recurso foi mais importante na previs\u00e3o de uma classe espec\u00edfica. Numa vis\u00e3o geral podemos perceber que basicamente os mesmos recursos s\u00e3o importantes para todas as classes, por\u00e9m para classe \"Normal\" o n\u00famero de desacelera\u00e7\u00f5es prolongadas por segundo como o indicador mais forte, j\u00e1 para as classes \"Suspeito\" e \"Patol\u00f3gico\" destaca-se o \"fator 3\" que representa o valor m\u00e9dio de variabilidade de curto prazo e porcentagem de tempo com variabilidade anormal de longo prazo.","36b4a2d1":"### Informa\u00e7\u00f5es sobre os atributos:\n\n    baseline value                                         - linha de base FHR (batimentos por minuto)\n    accelerations                                          - n\u00famero de acelera\u00e7\u00f5es por segundo\n    fetal_movement                                         - n\u00famero de contra\u00e7\u00f5es uterinas por segundo\n    light_decelerations                                    - n\u00famero de desacelera\u00e7\u00f5es leves por segundo\n    severe_decelerations                                   - n\u00famero de desacelera\u00e7\u00f5es graves por segundo\n    prolongued_decelerations                               - n\u00famero de desacelera\u00e7\u00f5es prolongadas por segundo\n    abnormal_short_term_variability                        - porcentagem de tempo com variabilidade anormal de curto prazo\n    mean_value_of_short_term_variability                   - valor m\u00e9dio de variabilidade de curto prazo\n    percentage_of_time_with_abnormal_long_term_variability - porcentagem de tempo com variabilidade anormal de longo prazo\n    mean_value_of_long_term_variability                    - valor m\u00e9dio de variabilidade de longo prazo\n    histogram_width                                        - largura do histograma FHR\n    histogram_min                                          - m\u00ednimo do histograma FHR\n    histogram_max                                          - M\u00e1ximo do histograma FHR\n    histogram_number_of_peaks                              - N\u00ba de picos do histograma\n    histogram_number_of_zeroes                             - N\u00ba de zeros do histograma\n    histogram_mode                                         - modo histograma\n    histogram_mean                                         - m\u00e9dia do histograma\n    histogram_median                                       - mediana do histograma\n    histogram_variance                                     - vari\u00e2ncia do histograma\n    histogram_tendency                                     - tend\u00eancia do histograma\n    fetal_health                                           - c\u00f3digo de classe do estado fetal \n                                                            (1 = normal; 2 = suspeito; 3 = patol\u00f3gico)","c04b706f":"O fator 1 tem altas cargas fatoriais para:\n* histogram_width\n* histogram_variance\n* histogram_number_of_peaks\n* mean_value_of_short_term_variability\n* histogram_max\n* light_decelerations\n\nO fator 2 tem altas cargas fatoriais para:\n* histogram_mode\n* histogram_mean\n* histogram_median\n* baseline_value\n\nO fator 3 tem altas cargas fatoriais para:\n* abnormal_short_term_variability\n* percentage_of_time_with_abnormal_long_term_variability\n","b3770ba0":"#### Submodular Pick And Global Explanations\nServe para encontrar um grupo de interpreta\u00e7\u00f5es que tentam explicar a maioria dos casos. Utilizei uma amostra de 190 registros, o que representa 30% dos dados de teste.","9b3be2c1":"## An\u00e1lise Explorat\u00f3ria","36abb48f":"# Data Science Aplicada \u00e0 \u00c1rea de Sa\u00fade","f83dba1d":"### Aplicando transforma\u00e7\u00e3o nos dados","d9c67262":"Os alfas s\u00e3o avaliados em 0.87, 0.95 e 0.69, o que indica que eles s\u00e3o \u00fateis e coerentes."}}