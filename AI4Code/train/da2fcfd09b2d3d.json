{"cell_type":{"c797d3ed":"code","0b3fdf8f":"code","92efbcee":"code","36afbc6d":"code","fef2bc50":"code","e2135f38":"code","7482a54f":"code","42cff9d2":"code","33c2dc1c":"code","502f74af":"code","fb19ee2e":"code","72088c65":"code","ba39b046":"markdown"},"source":{"c797d3ed":"#!ls ..\/input\/plant-seedlings\/\nimport os\nos.listdir('..\/input\/input\/input\/plant-seedlings-classification\/')","0b3fdf8f":"!ls ..\/input\/input\/input\/vgg16\/","92efbcee":"import os\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)","36afbc6d":"!cp ..\/input\/input\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5 ~\/.keras\/models\/","fef2bc50":"print(os.listdir('..\/input\/input\/input\/plant-seedlings-classification\/train\/'))","e2135f38":"import fnmatch\nimport os\nimport numpy as np\nimport pandas as pd\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nnp.random.seed(21)\n\npath = '..\/input\/input\/input\/plant-seedlings-classification\/train\/'\ntrain_label = []\ntrain_img = []\nlabel2num = {'Loose Silky-bent':0, 'Charlock':1, 'Sugar beet':2, 'Small-flowered Cranesbill':3,\n             'Common Chickweed':4, 'Common wheat':5, 'Maize':6, 'Cleavers':7, 'Scentless Mayweed':8,\n             'Fat Hen':9, 'Black-grass':10, 'Shepherds Purse':11}\nfor i in os.listdir(path):\n    label_number = label2num[i]\n    new_path = path+i+'\/'\n    for j in fnmatch.filter(os.listdir(new_path), '*.png'):\n        temp_img = image.load_img(new_path+j, target_size=(200,200))\n        train_label.append(label_number)\n        temp_img = image.img_to_array(temp_img)\n        train_img.append(temp_img)\n\ntrain_img = np.array(train_img)\n\ntrain_y=pd.get_dummies(train_label)\ntrain_y = np.array(train_y)\ntrain_img=preprocess_input(train_img)\n\nprint('Training data shape: ', train_img.shape)\nprint('Training labels shape: ', train_y.shape)","7482a54f":"import keras\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndef vgg16_model(num_classes=None):\n\n    model = VGG16(weights='imagenet', include_top=False,input_shape=(200,200,3))\n    model.layers.pop()\n    model.layers.pop()\n    model.layers.pop()\n\n    model.outputs = [model.layers[-1].output]\n\n    model.layers[-2].outbound_nodes= []\n    x=Conv2D(256, kernel_size=(2,2),strides=2)(model.output)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)    \n    x=Conv2D(128, kernel_size=(2,2),strides=1)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x=Flatten()(x)\n    x=Dense(num_classes, activation='softmax')(x)\n\n    model=Model(model.input,x)\n\n    for layer in model.layers[:14]:\n\n        layer.trainable = False\n\n\n    return model","42cff9d2":"def precision(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\n\ndef recall(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\n\ndef fscore(y_true, y_pred):\n    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n        return 0\n\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    f_score = 2 * (p * r) \/ (p + r + K.epsilon())\n    return f_score","33c2dc1c":"from keras import backend as K\nnum_classes=12\nmodel = vgg16_model(num_classes)\nmodel.compile(optimizer=\"nadam\", loss='categorical_crossentropy', metrics=['accuracy',fscore])\nmodel.summary()","502f74af":"#Split training data into rain set and validation set\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, Y_train, Y_valid=train_test_split(train_img,train_y,test_size=0.1, random_state=42)\n\n#Data augmentation\n'''from keras.preprocessing.image import ImageDataGenerator\ngen_train = ImageDataGenerator( \n    rotation_range=30,\n    width_shift_range=0.2,\n   height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True\n\n)\ngen_train.fit(X_train)\n\n#Train model\nfrom keras.callbacks import ModelCheckpoint\nepochs = 10\nbatch_size = 32\nmodel_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n\nmodel.fit_generator(gen_train.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), \n                    steps_per_epoch=(X_train.shape[0]\/\/(4*batch_size)), \n                    epochs=epochs, \n                    validation_data=(X_valid,Y_valid),\n                    callbacks=[model_checkpoint],verbose=1)\n'''\nfrom keras.callbacks import ModelCheckpoint\nepochs = 10\nbatch_size = 32\n# model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n\nmodel_checkpoint = ModelCheckpoint('.\/model61.{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}.h5',\n                           monitor='val_loss',\n                             verbose=1,\n                            save_best_only=True,\n                            mode='min',\n                             save_weights_only=False)\n\n\nmodel.fit(X_train,Y_train,\n          batch_size=128,\n          epochs=20,\n          verbose=1, shuffle=True, validation_data=(X_valid,Y_valid), callbacks=[model_checkpoint])","fb19ee2e":"import matplotlib.pyplot as plt\ndef plot_model(model):\n    plots = [i for i in model.history.history.keys() if i.find('val_') == -1]\n    plt.figure(figsize=(10,10))\n\n    for i, p in enumerate(plots):\n        plt.subplot(len(plots), 2, i + 1)\n        plt.title(p)\n        plt.plot(model.history.history[p], label=p)\n        plt.plot(model.history.history['val_'+p], label='val_'+p)\n        plt.legend()\n\n    plt.show()\n    \nplot_model(model)","72088c65":"\nfrom sklearn.metrics import classification_report, confusion_matrix\nlabelNames=['Loose Silky-bent', 'Charlock', 'Sugar beet', 'Small-flowered Cranesbill',\n             'Common Chickweed', 'Common wheat', 'Maize', 'Cleavers', 'Scentless Mayweed',\n             'Fat Hen', 'Black-grass', 'Shepherds Purse']\npreds = model.predict(X_valid)\nprint(\"[INFO] evaluating network...\")\nprint(classification_report(Y_valid.argmax(axis=1), preds.argmax(axis=1),\n\ttarget_names=labelNames))\nprint(\"The confusion matrix:\")\nprint(confusion_matrix(Y_valid.argmax(axis=1), preds.argmax(axis=1)))\n#print(classification_report(predictions, labels))\n\n#X_valid,Y_valid","ba39b046":"Transfer learning with pre-trained VGG16 model with imagenet weights.\nThe plant-seedlings-classification dataset of kaggle is used.\nThe last three layers of the network is popped, and 2 new conv layers and 1 new fully-connected\/dense layer is added.Hence only these three layers are learnt.\nThe first 13 layers are set as untrainable. Hence the 13th layer acts as the \"bottleneck\" layer. \n\nCross validation accuracy of 92% and a cross validation loss of 0.25092 was achieved.\n\n"}}