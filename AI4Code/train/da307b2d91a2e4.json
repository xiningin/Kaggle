{"cell_type":{"1e9bfb0c":"code","bc1d1c1e":"code","2236b9bb":"code","abe5ca7e":"code","90d3e1dd":"code","bc1bd0f9":"code","60bdba5f":"code","62b7b322":"code","1caf3f72":"code","2d355712":"code","d6a57407":"code","7076a9fd":"code","faa9d181":"code","2dee59a2":"code","a1a0f94d":"code","8ae39cf1":"code","64c44b8e":"code","e4160368":"code","6b48fe94":"code","255698b9":"code","004955d8":"code","c095762b":"code","09b4763e":"markdown"},"source":{"1e9bfb0c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc1d1c1e":"data_master = pd.read_csv(\"\/kaggle\/input\/parkinsons-data-set\/parkinsons.data\")\ndata_master.head(5)","2236b9bb":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","abe5ca7e":"data_master.info()","90d3e1dd":"fig,axes=plt.subplots(5,5,figsize=(15,15))\naxes=axes.flatten()\n\nfor i in range(1,len(data_master.columns)-1):\n    sns.boxplot(x='status',y=data_master.iloc[:,i],data=data_master,orient='v',ax=axes[i])\nplt.tight_layout()\nplt.show()","bc1bd0f9":"data_master.status.value_counts()","60bdba5f":"'''for dataset in data_master: \n    dataset['status'] = dataset['status'].astype(float) \n\ndata_master['status'].value_counts()'''","62b7b322":"X = data_master.drop(['status', 'name'], axis = 1)\ny = data_master.status","1caf3f72":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","2d355712":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n\ndef clf_scores(clf, y_predicted):\n    # Accuracy\n    acc_train = clf.score(X_train, y_train)*100\n    acc_test = clf.score(X_test, y_test)*100\n    \n    roc = roc_auc_score(y_test, y_predicted)*100 \n    tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n    cm = confusion_matrix(y_test, y_predicted)\n    correct = tp + tn\n    incorrect = fp + fn\n    \n    return acc_train, acc_test, roc, correct, incorrect, cm","d6a57407":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression()\nclf_lr.fit(X_train, y_train)\n\nY_pred_lr = clf_lr.predict(X_test)\nprint(clf_scores(clf_lr, Y_pred_lr))","7076a9fd":"#2. KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=3)\nclf_knn.fit(X_train, y_train)\n\nY_pred_knn = clf_knn.predict(X_test)\nprint(clf_scores(clf_knn, Y_pred_knn))","faa9d181":"#3. Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\nclf_gnb = GaussianNB()\nclf_gnb.fit(X_train, y_train)\n\nY_pred_gnb = clf_gnb.predict(X_test)\nprint(clf_scores(clf_gnb, Y_pred_gnb))","2dee59a2":"data_master.columns","a1a0f94d":"#Scaling\nfrom sklearn.preprocessing import StandardScaler\n\n# copy of datasets\nX_train_scaled = X_train.copy()\nX_test_scaled = X_test.copy()\n\n# numerical features\nnum_cols = ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA',\n       'spread1', 'spread2', 'D2', 'PPE']\n\n# apply standardization on numerical features\nfor i in num_cols:\n    \n    # fit on training data column\n    scale = StandardScaler().fit(X_train_scaled[[i]])\n    \n    # transform the training data column\n    X_train_scaled[i] = scale.transform(X_train_scaled[[i]])\n    \n    # transform the testing data column\n    X_test_scaled[i] = scale.transform(X_test_scaled[[i]])\n","8ae39cf1":"X_train.describe()","64c44b8e":"X_train_scaled.describe()","e4160368":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression()\nclf_lr.fit(X_train_scaled, y_train)\n\nY_pred_lr = clf_lr.predict(X_test_scaled)\nprint(clf_scores(clf_lr, Y_pred_lr))","6b48fe94":"#2. KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=3)\nclf_knn.fit(X_train_scaled, y_train)\n\nY_pred_knn = clf_knn.predict(X_test_scaled)\nprint(clf_scores(clf_knn, Y_pred_knn))","255698b9":"#3. Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\nclf_gnb = GaussianNB()\nclf_gnb.fit(X_train_scaled, y_train)\n\nY_pred_gnb = clf_gnb.predict(X_test_scaled)\nprint(clf_scores(clf_gnb, Y_pred_gnb))","004955d8":"#4. SVM\n\nfrom sklearn.svm import SVC\n\nclf_svm = SVC()\nclf_svm.fit(X_train_scaled, y_train)\n\nY_pred_svm = clf_svm.predict(X_test_scaled)\nprint(clf_scores(clf_svm, Y_pred_svm))","c095762b":"#Meta-classifier\nfrom mlxtend.classifier import StackingClassifier\nfrom sklearn import model_selection\n\nlr = LogisticRegression()\nsclf = StackingClassifier(classifiers=[clf_knn, clf_svm, clf_gnb], \n                          meta_classifier=lr)\nsclf.fit(X_train_scaled, y_train)\nfor clf, label in zip([clf_knn, clf_svm, clf_gnb, sclf], \n                      ['KNN', \n                       'SVM', \n                       'Naive Bayes',\n                       'StackingClassifier']):\n\n    Y_pred = clf.predict(X_test_scaled)\n    scores = clf_scores(clf, Y_pred)\n    #scores = model_selection.cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring='accuracy')\n    \n    print(scores, label)","09b4763e":"If you have reached till here, then please \n## Upvote for the notebook :-)"}}