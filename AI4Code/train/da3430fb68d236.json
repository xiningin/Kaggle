{"cell_type":{"264eeef9":"code","0abc1ab7":"code","79983118":"code","013a2b4f":"code","018017b8":"code","f3800a6d":"code","6575d31c":"code","130be7ff":"code","7c75b3c7":"code","d8bd0550":"code","8abe3c5e":"code","920e834c":"code","6f6f13c9":"code","a25d9a48":"code","3484db64":"code","e1bbde31":"code","b78483d8":"code","7a604970":"code","9455665a":"code","c46464d8":"code","091bdde8":"code","6cfe2fb1":"code","19b94664":"code","0fb03cfb":"code","65bebaef":"code","76e83a2f":"code","ff9027a3":"code","cc8578f0":"code","df2df539":"markdown","e58bf7a6":"markdown","61adfcf4":"markdown","cc84e0be":"markdown","ccff48cb":"markdown","248a6265":"markdown","2f184f64":"markdown","5f33665c":"markdown","1dc4b31e":"markdown","a454b950":"markdown","ef07c961":"markdown","0ffd19b8":"markdown","0c18d90b":"markdown","c0d4b8d6":"markdown","f44dfe1f":"markdown","0bb66b88":"markdown","4ce6d22e":"markdown","8d4f4e1c":"markdown","889b73e0":"markdown"},"source":{"264eeef9":"%matplotlib inline\nimport copy\nimport matplotlib.pyplot as plt\nimport imgaug.augmenters as iaa\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport skimage\nfrom skimage import io, transform\nfrom sklearn.metrics import confusion_matrix\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport cv2\nfrom torch.nn import Conv2d\nimport datetime","0abc1ab7":"EPOCHS = 30\ntrain_data_dir = \"..\/input\/augmentedchestxrayval\/train\/train\"\nval_data_dir = \"..\/input\/augmentedchestxrayval\/val\/val\"\ntest_data_dir = \"..\/input\/augmentedchestxrayval\/test\/test\"\nTEST = 'test'\nTRAIN = 'train'\nVAL ='val'","79983118":"def data_transforms():\n     return transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","013a2b4f":"image_datasets = {TRAIN: datasets.ImageFolder(train_data_dir, data_transforms()), \n                  VAL: datasets.ImageFolder(val_data_dir, data_transforms()), \n                  TEST: datasets.ImageFolder(test_data_dir, data_transforms()) }\n\ndataloaders = {TRAIN: torch.utils.data.DataLoader(image_datasets[TRAIN], batch_size = 4, shuffle=True), \n               VAL: torch.utils.data.DataLoader(image_datasets[VAL], batch_size = 1, shuffle=True), \n               TEST: torch.utils.data.DataLoader(image_datasets[TEST], batch_size = 1, shuffle=True)}","018017b8":"print(len(image_datasets[TRAIN]))\nprint(len(image_datasets[VAL]))\nprint(len(image_datasets[TEST]))","f3800a6d":"dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL]}\n\nprint(dataset_sizes)\n\nclasses = image_datasets[TRAIN].classes\nclass_names = image_datasets[TRAIN].classes","6575d31c":"def imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  \n\n\ninputs, classes = next(iter(dataloaders[TRAIN]))\nout = torchvision.utils.make_grid(inputs)\nimshow(out, title=[class_names[x] for x in classes])","130be7ff":"def number_of_labels(dataset):\n    all_labels = {}\n    # Imgs cause this is ImageFolder class      \n    for _, local_label in dataset.imgs:\n        if not local_label in all_labels:\n            all_labels[local_label] = 1\n        else:\n            all_labels[local_label] += 1\n    return all_labels\n\ndef plot_labels_number(labels, idx_to_label):\n    print(idx_to_label)\n    normal_index = idx_to_label['NORMAL']\n    pneunomia_index = idx_to_label['PNEUMONIA']\n    x = ['NORMAL', 'PNEUMONIA']\n    y = [labels[normal_index], labels[pneunomia_index]]\n    print(y)\n    plt.figure(figsize=(10,8))\n    sns.barplot(x, y)\n    plt.title('Number of cases', fontsize=14)\n    plt.xlabel('Case type', fontsize=12)\n    plt.ylabel('Count', fontsize=12)\n    plt.show()\n\nval_labels = number_of_labels(image_datasets[VAL])\ntrain_labels = number_of_labels(image_datasets[TRAIN])\ntest_labels = number_of_labels(image_datasets[TEST])\nidx = image_datasets[VAL].class_to_idx\n\nplot_labels_number(val_labels, idx)\nplot_labels_number(train_labels, idx)\nplot_labels_number(test_labels, idx)","7c75b3c7":"# Augmentation sequence \nseq = iaa.OneOf([\n    iaa.Fliplr(), # horizontal flips\n    iaa.Affine(rotate=20), # roatation\n    iaa.Multiply((1.2, 1.5))]) #random brightness\n","d8bd0550":"# Augmentation sequence \nseq = iaa.OneOf([\n    iaa.Fliplr(), # horizontal flips\n    iaa.Affine(rotate=20), # roatation\n    iaa.Multiply((1.2, 1.5))]) #random brightness","8abe3c5e":"# We have to generate 2690 images\n# But in the whole set there are only 1583 cases! (so we have to oversamaple the 1107 images)","920e834c":"# !rm \/kaggle\/working\/*.jpg","6f6f13c9":"def generate_normal_images(dataset, seq, name_index, stop_index):\n    normal_class_label = image_datasets[TRAIN].class_to_idx['NORMAL']\n    \n    # The dataset is ImageFolder cause imgs suffix here     \n    for image_path, label in dataset.imgs: \n        if name_index == stop_index:\n            break\n        \n        if label == normal_class_label:\n                img = cv2.imread(str(image_path))\n                img = cv2.resize(img, (224,224))\n\n                # check if it's grayscale\n                if img.shape[2]==1:\n                    img = np.dstack([img, img, img])\n\n                # cv2 reads in BGR mode by default\n                orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                # normalize the image pixels\n                orig_img = img.astype(np.float32)\/255.\n\n                aug_img1 = seq.augment_image(img)\n                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n                aug_img1 = aug_img1.astype(np.float32)\/255.\n\n                name_index += 1   \n                img = cv2.convertScaleAbs(aug_img1, alpha=(255.0))\n                cv2.imwrite(f'{name_index}.jpg', img)\n    return name_index\n\n# Generating the lacking images\n# images = 1\n# to_generate = 2690\n\n# images = generate_normal_images(image_datasets[TRAIN], seq, images, to_generate)\n# print(images)\n# images = generate_normal_images(image_datasets[TEST], seq, images, to_generate)\n# print(images)\n# images = generate_normal_images(image_datasets[VAL], seq, images, to_generate)\n# print(images)\n\n# We have to call this twice, cause the iniitali normal set has size only of 1583!!!\n# New seq, chaning how we augment the stuff slightly\n# seq = iaa.OneOf([\n#     iaa.Fliplr(), # horizontal flips\n#     iaa.Affine(rotate=15), # roatation\n#     iaa.Multiply((1.1, 1.3))]) #random brightness\n\n# images = generate_normal_images(image_datasets[TRAIN], seq, images, to_generate)\n# images","a25d9a48":"# Zip all the images, so that it is easy to download them with single click on the dev machine!!\n# !cd \/kaggle\/working\/\n# !zip -m generated_images *.jpg\n\n# Clear the output files, just not to confuse between variuos experiments\n# !rm \/kaggle\/working\/learned_net.pth\n# !rm \/kaggle\/working\/checkpoint.pt","3484db64":"# Stolen from https:\/\/github.com\/Bjarten\/early-stopping-pytorch\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), 'checkpoint.pt')\n        self.val_loss_min = val_loss","e1bbde31":"def train_model(model, criterion, optimizer, scheduler, num_epochs, early_stopping):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch: {}\/{}\".format(epoch+1, num_epochs))\n        print(\"=\"*10)\n        \n        for phase in [TRAIN, VAL]:\n            if phase == TRAIN:\n                scheduler.step()\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n            for data in dataloaders[phase]:\n                inputs, labels = data\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase==TRAIN):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n            if phase == 'val':\n                early_stopping(epoch_loss, model)\n        \n            if early_stopping.early_stop:\n                print(\"Early stopping\")\n                print('Best val Acc: {:4f}'.format(best_acc))\n                model.load_state_dict(torch.load('checkpoint.pt'))\n                return model\n        \n    # seems the 'break' key word does not work in kaggle --.--    \n    print('Best val Acc: {:4f}'.format(best_acc))\n    # returning the BEST model     \n    model.load_state_dict(torch.load('checkpoint.pt'))\n    return model","b78483d8":"model_pre = models.squeezenet1_0()\nmodel_pre.load_state_dict(torch.load('..\/input\/pytorch-pretrained-models\/squeezenet1_0-a815701f.pth'))","7a604970":"for param in model_pre.features.parameters():\n    param.requires_grad = False\n\nnum_classes = 2\nmodel_pre.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))    \n\n#  just to see if we do not have any bug\nfor param in model_pre.features.parameters():\n    param.requires_grad = False\n\nprint(model_pre)","9455665a":"fire = model_pre.features[12]\n# Assign the new layers to make the requireds_grad True\nfire.squeeze = Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\nfire.expand1x1 = Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\nfire.expand3x3 = Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\n# I want to ensure that we will learn the desired layers\nprint('Layers to learn!')\nfor name,param in model_pre.named_parameters():\n    if param.requires_grad:\n        print(name)","c46464d8":"from torch import nn\n\nclass CustomNet(nn.Module):   \n    def __init__(self):\n        super(CustomNet, self).__init__()\n        \n        self.layers = nn.Sequential(\n            nn.Conv2d(in_channels=3 , out_channels=1, kernel_size=(7,7)),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(7,7)),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(5,5), stride=2),\n            nn.Dropout(),\n            nn.Flatten(),\n            nn.Linear(in_features = 10816, out_features = 2),\n            nn.Softmax()\n        )\n    \n#         self.cnn_layers = Sequential(\n#             # Defining a 2D convolution layer\n#             Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n#             BatchNorm2d(4),\n#             ReLU(inplace=True),\n#             MaxPool2d(kernel_size=2, stride=2),\n#             # Defining another 2D convolution layer\n#             Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n#             BatchNorm2d(4),\n#             ReLU(inplace=True),\n#             MaxPool2d(kernel_size=2, stride=2),\n#         )\n\n#         self.linear_layers = Sequential(\n#             Linear(4 * 7 * 7, 10)\n#         )\n\n    # Defining the forward pass    \n    def forward(self, x):\n        return self.layers(x)","091bdde8":"# Changing to the custom net!\nmodel_pre = CustomNet()\n\nmodel_pre = model_pre.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_pre.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n# Decay LR by a factor of 0.1 every 10 epochs\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\nearly_stopping = EarlyStopping(3, True)","6cfe2fb1":"print(datetime.datetime.now())\nmodel_pre = train_model(model_pre, criterion, optimizer, exp_lr_scheduler, EPOCHS, early_stopping)\nprint(datetime.datetime.now())","19b94664":"def test_model():\n    running_correct = 0.0\n    running_total = 0.0\n    true_labels = []\n    pred_labels = []\n    with torch.no_grad():\n        for data in dataloaders[TEST]:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            true_labels.append(labels.item())\n            outputs = model_pre(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            pred_labels.append(preds.item())\n            running_total += labels.size(0)\n            running_correct += (preds == labels).sum().item()\n        acc = running_correct\/running_total\n    return (true_labels, pred_labels, running_correct, running_total, acc)","0fb03cfb":"true_labels, pred_labels, running_correct, running_total, acc = test_model()","65bebaef":"print(\"Total Correct: {}, Total Test Images: {}\".format(running_correct, running_total))\nprint(\"Test Accuracy: \", acc)","76e83a2f":"cm = confusion_matrix(true_labels, pred_labels)\ntn, fp, fn, tp = cm.ravel()\nax = sns.heatmap(cm, annot=True, fmt=\"d\")","ff9027a3":"torch.save(model_pre.state_dict(), '.\/learned_net.pth')","cc8578f0":"print(datetime.datetime.now())","df2df539":"# Early stop implementation","e58bf7a6":"# Define the Hyperparameters","61adfcf4":"Look that there is not enough normal patiets. The disporportrio is quite huge (1583 vs 4273). We have to generate through the augmentation missing 2690 values. Furthermore, we need to change the order of sets, because validation set is way to small (8 patients! xD). Going to rearrange the set (collect all the files) and split them into the percentage 30% test, 70% train (20% validation from the 70%).","cc84e0be":"# Define Function for Testing","ccff48cb":"# Defining custom net!","248a6265":"# Check how balanced data is","2f184f64":"# Train Phase","5f33665c":"# Load the pretrained model from Pytorch","1dc4b31e":"# Balance the data","a454b950":"# Specyfing data","ef07c961":"# Data Preprocessing and Augmentation\n","0ffd19b8":"# Results","0c18d90b":"**Confusion Matrix, Presision and Recall**","c0d4b8d6":"# Generate missing NORMAL cases","f44dfe1f":"# Unlock more layers in the SqueezNet","0bb66b88":"# Import Libraries","4ce6d22e":"# Testing Phase","8d4f4e1c":"# Visualize the Chest X-rays","889b73e0":"# Define Function for Training"}}