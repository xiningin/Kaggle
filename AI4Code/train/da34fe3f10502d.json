{"cell_type":{"fa3b548c":"code","b133e9d8":"code","01570a6c":"code","e7896db9":"code","0a2f0243":"code","ac9d73d5":"code","02f6c747":"code","ac4dc298":"code","33f27996":"code","3c773af8":"code","8045f69b":"code","be0eecce":"code","e470738d":"code","78902ef3":"code","2de0be86":"code","3d200337":"code","099deb81":"code","4c8aae28":"code","4de53762":"code","44b0a0ed":"code","6c76430d":"code","9d85a0c3":"code","12442471":"code","5e79e955":"code","f754f241":"code","30b3342e":"code","3af31605":"code","d373d6e3":"code","b0e13f68":"code","55f9e619":"code","2c350525":"code","983a58cb":"code","0fea4766":"markdown","87c661fd":"markdown","14c3c163":"markdown","148260d9":"markdown","d13235a6":"markdown","195b097a":"markdown","48733b6a":"markdown","14b2be6f":"markdown","70089512":"markdown","baca6f48":"markdown","1394e59d":"markdown","298b120d":"markdown","8a40017c":"markdown","08e7568a":"markdown","27979d24":"markdown","e0991981":"markdown","2e747e25":"markdown","e1d33cd7":"markdown","0cd232d2":"markdown","b347040c":"markdown","1fe546cc":"markdown","8b40240e":"markdown","c908a927":"markdown","9dfc85b3":"markdown","aa284d19":"markdown","f5720f7d":"markdown","acba71a9":"markdown","d2a04fd4":"markdown","24b2b334":"markdown","8fafba42":"markdown","fd547f1e":"markdown","a1d597eb":"markdown","f2feadc6":"markdown","9a431e4c":"markdown"},"source":{"fa3b548c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #importing seaborn module \nimport warnings\nfrom collections import Counter\nwarnings.filterwarnings('ignore')  #this will ignore the warnings.it wont display warnings in notebook\n#plt.style.use('fivethirtyeight')\nplt.style.use('ggplot')\nplt.rcParams['figure.figsize']=[6,3]\nplt.rcParams['figure.dpi']=80","b133e9d8":"data = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")","01570a6c":"#Missing Values\ndata.isnull().sum()","e7896db9":"data.info()","0a2f0243":"data.describe()","ac9d73d5":"cat_col = ['sex', 'cp', 'restecg', 'exang', 'slope', 'ca','thal','fbs','target']\nnum_col = ['age', 'trestbps', 'chol','thalach','oldpeak']\n","02f6c747":"plt.figure(figsize=(12, 28))\ncount = 1\nfor cols in cat_col:\n    plt.subplot(9, 2, count)\n    data[cols].value_counts().plot.pie(shadow=True,autopct='%1.1f%%')\n    count +=1\n    plt.subplot(9, 2, count)\n    sns.countplot(cols, data=data)\n    count+=1","ac4dc298":"features = num_col\n\ndef outlier_hunt(df):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than 2 outliers. \n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in df.columns.tolist():\n        print(\"col\", col)\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        print(\"Q1\", Q1)\n        \n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        print(\"Q3\", Q3)\n        \n        # Interquartile rrange (IQR)\n        IQR = Q3 - Q1\n        print(\"IQR\", IQR)\n        # outlier step\n        outlier_step = 1.5 * IQR\n        print(\"outlier_step\", outlier_step)\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2 )\n    \n    print(\"outlier_indices\",outlier_indices)\n    return multiple_outliers   \n\nprint('The dataset contains %d observations with more than 2 outliers' %(len(outlier_hunt(data[features]))))\n","33f27996":"plt.figure(figsize=(12, 24))\ncount = 1\nfor cols in num_col:\n    plt.subplot(6, 2, count)\n    sns.boxplot(x='target', y= cols, data= data)\n    count +=1\n    plt.subplot(6, 2, count)\n    \n    g = sns.kdeplot(data[cols][(data[\"target\"] == 0) & (data[cols].notnull())], color=\"Red\", shade = True)\n    g = sns.kdeplot(data[cols][(data[\"target\"] == 1) & (data[cols].notnull())], ax =g, color=\"Blue\", shade= True)\n    g.set_xlabel(cols)\n    g.set_ylabel(\"Frequency\")\n    g = g.legend([\"No Diesese\",\"Diesese\"])\n    count+=1","3c773af8":"#Categorical Variables : Catplot\nfor cols in cat_col:\n    if cols!='target':\n        sns.catplot(x=cols,y='target',kind='bar',data=data)\n","8045f69b":"#Catplot cp+target+restecg+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='restecg',hue='sex')\n","be0eecce":"#Catplot cp+target+exang+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='exang',hue='sex')\n","e470738d":"#Catplot cp+target+slope+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='slope',hue='sex')\n","78902ef3":"#Catplot cp+target+ca+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='ca',hue='sex')\n\n","2de0be86":"#Catplot cp+target+thal+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='thal',hue='sex')","3d200337":"#Catplot restecg+target+exang+sex\nsns.catplot(x='exang',y='target',kind='point',data=data,col='restecg',hue='sex')\n","099deb81":"#Explore Numerical Variables\nsns.catplot(x='target',y='age',data=data,kind='box',hue='sex', col='cp')\n","4c8aae28":"sns.catplot(x='target',y='chol',data=data,kind='box',hue='sex', col='exang')","4de53762":"sns.catplot(x='target',y='chol',data=data,kind='box',hue='sex', col='slope')","44b0a0ed":"sns.catplot(x='target',y='age',data=data,kind='box',hue='sex', col='ca')","6c76430d":"sns.catplot(x='target',y='oldpeak',data=data,kind='box',hue='sex', col='thal')","9d85a0c3":"#Catplot cp+target+fbs+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='fbs',hue='sex')\n","12442471":"#Variable = age Vs restecg\nf,ax=plt.subplots(1,3,figsize=(12,8))\nsns.distplot(data[data['restecg']==0].age,ax=ax[0])\nax[0].set_title('age in restecg 0')\nsns.distplot(data[data['restecg']==1].age,ax=ax[1])\nax[1].set_title('age in restecg 1')\nsns.distplot(data[data['restecg']==2].age,ax=ax[2])\nax[2].set_title('age in restecg 2')\nplt.show()","5e79e955":"#Variable = age Vs fbs\nf,ax=plt.subplots(1,2,figsize=(18,8))\nsns.distplot(data[data['fbs']==0].age,ax=ax[0])\nax[0].set_title('age in fbs 0')\nsns.distplot(data[data['fbs']==1].age,ax=ax[1])\nax[1].set_title('age in fbs 1')","f754f241":"#Final Pair plot\nsns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':12})\nfig=plt.gcf()\nfig.set_size_inches(18,10)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","30b3342e":"train = data.drop([\"target\"],axis=1)\ntrain_ = data[\"target\"]\n\nX_train = train.values\ny_train = train_.values","3af31605":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)","d373d6e3":"from sklearn.model_selection import train_test_split, cross_val_predict,cross_validate\ntrain_x, test_x,train_y,test_y = train_test_split(X_train,y_train,test_size  = 0.2, random_state=0)\nprint(\"Train dataset shape: {0}, \\nTest dataset shape: {1}\".format(train_x.shape, test_x.shape))\n","b0e13f68":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n#storing  the K nearest neighbors classifier\nMisclassified_sample = []\nfor i in range(1, 30):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(train_x,train_y)\n    pred_i = knn.predict(test_x)\n    Misclassified_sample.append((test_y != pred_i).sum())\nprint(\"Misclassified_sample = \", Misclassified_sample)","55f9e619":"# Lowest number of samples for K=8\n\nKNN_classifier = KNeighborsClassifier(n_neighbors=8)\n\n# Fitting the values fo X and Y\nKNN_classifier.fit(train_x, train_y)\n\n#Predicting the test values with Model\nprediction =  KNN_classifier.predict(test_x)\n\n###### confusion matrix  starts ######\nfrom sklearn.metrics import accuracy_score, confusion_matrix\ncm_knn = confusion_matrix(test_y,prediction) \nnames = np.unique(prediction)\nsns.heatmap(cm_knn, square=True, annot=True, cbar=False,xticklabels=names, yticklabels=names, cmap=\"YlGnBu\" ,fmt='g')\nplt.xlabel('Truth')\nplt.ylabel('Predicted')\n###### Confusion matrix ends ########\n\n#calculating the accuracy\naccuracy_score = accuracy_score(test_y,prediction)\nprint(\"accuracy_score KNN=8 :\",accuracy_score)","2c350525":"# Generic function for model building\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\ndef fit_and_test(classifier, X_train, y_train, X_test, y_test, only_return_accuracy=False):\n  classifier.fit(X_train, y_train)\n  y_hat = classifier.predict(X_test)\n  print('accuracy:', accuracy_score(y_test, y_hat))\n  if not only_return_accuracy:\n    print('f1_score:', f1_score(y_test, y_hat))\n","983a58cb":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n#grid search over regularisation hyperparameter 'c'\nfor c in [0.001,.01, 0.02, 0.05, 0.25, 0.5, 0.75, 1,1.05,1.1,1.5,1.6,2,7]:\n  lr = LogisticRegression(C=c, max_iter=1000) \n  print (f'At C = {c}:-', end=' ')\n  fit_and_test(lr, train_x, train_y, test_x, test_y, True)","0fea4766":"Freq distribution of chol is higher for female than male  ","87c661fd":"# Conclusion : We recommend KNN (88.52% accuracy with only 7 misclassified samples) to build the model","14c3c163":"Explore Categorical Variables","148260d9":"* male (68.3%), female (31.7%) \n* cp - maximum value is 0 (47.2%) i.e.  0 -> 2-> 1 -> 3\n* restecg - max occurance is 0(50.2%) & 1 (48.5%), 2 (1.3%) is minimal\n* exang - 67.3% have no and 32.7% are yes\n* slope - max occurance of 1&2 (46%), 0 is minimal (6.9%)\n* ca- values from 0 to 4, 0 -> 1 -> 2 -> 3 -> 4 \n* thal - 0,1,2,3 ; 2&3 are max, o is min\n* fbs - 85.1% = 0 n 14.9%=1\n* target - 54.5% have heart diesese, 45.5% have none","d13235a6":"* for restecg=2, only female have diesese for exang=0\n* For restecg=0, female have higher diesese chance than male\n","195b097a":"Data Processing ","48733b6a":"Machine Learning Algorithm begins","14b2be6f":"female have higher chances of having heart diesese than male for cp = 0to3 & restecg from 0-2","70089512":"older people (age= 60 & 80) have restecg=2","baca6f48":"Numerical Data - Outlier detection and removal","1394e59d":"#No missing values","298b120d":"Train Test Split","8a40017c":"people (age< 42) have no fbs","08e7568a":"For thal=3 & diesese=1, age of male&female are lower than diesese=0","27979d24":"For slope=0 & diesese = 1, chol value for male are higher than female","e0991981":"Logistic Regresion ","2e747e25":"* male - for thal=0 & cp=2, only male have diesese\n* for thal=1 & cp=0-3 only male have diesese\n* for thal=2 & cp=0,2,3 , female have higher chance than male of heart diesese\n* except for cp=1 where both have equal chance for heart diesese\n* For thal=3, female have higher chance for cp=2, for other cp values only male have heart diesese\n","e1d33cd7":"For cp=0&3 age of female is slightly higher than male ","0cd232d2":"Simple KNN (K Nearest Neighbours)","b347040c":"For ca=2, and diesese=1, male have very low age than female","1fe546cc":"female have higher chances of having heart diesese than male for cp = 0to3 & exang from 0-3\nexcept for cp=3 & exang=3 for which female does not have heart diesese\n","8b40240e":"No outliers > 2, hence no need to drop","c908a927":"* female have no heart diesese for slope =0 & cp = 0to3\n* for slope = 1 & 2, female have higher chance of heart diesese than male\n* for cp=0to3, except slope=1 & cp=3, for which female have no heart diesese\n","9dfc85b3":"Generate categorical and numerical columns","aa284d19":"KNN accuracy : 88.52% with only 7 misclassified samples","f5720f7d":"* age - young people (25-30) have higher chance than older people\n* For People having heart diesese - max distribution lies between (45-59) \n  Vs not having heart diesese (51-62)\n* trestbps - people with value 190-220 & (80-85) have no heart diesese\n* chol - people with very high chol (530-600) have heart diesese\n* fbs - Doesn't not have any variance\n* thalach - people with value (52-85) do not have diesese\n* max freq of having diesese is between (150-172)\n* oldpeak - people with value (5-7)& (-1.5 to -1.2) : No diesese\n","acba71a9":"First Look at categorical data ","d2a04fd4":"Logistic Regression Accuracy : 85.42% ","24b2b334":"303 rows & 14 columns","8fafba42":"* Female - \n* For ca=0, higher chance for female than male for diesese\n* For ca=1, & cp=0to2,higher chance for female than male for diesese\n* For ca=2& cp=0,1, only female have diesese\n* For ca=3 & 4 female do not have diesese\n\n* male - \n* For (ca=1 & cp=3) and (ca=2 & cp=2to3) and ca=3 and 4, only male have diesese\n","fd547f1e":"female have higher chances of having heart diesese than male for fbs = 0","a1d597eb":"# **Please UpVote, if you have liked my Kernel :)**","f2feadc6":"Numerical Data Analysis","9a431e4c":"* sex - Female have more chance of heart diesese than male\n* cp - Value 1,2&3 indicate higher chance of heart diesese than 0\n* restecg - Value 0 & 1 indicate higher chance of diesese than 2.\n* Value 2 seems to be a outlier\n* exang - value 0 indicates higher chance of diesese than 1\n* slope - 2 indiactes higher chances of diesese than 0&1\n* ca - Value 4&0 have higher chance of diesese than 1,2,3\n* thal - Value 2 have highest chance and 3 have minimum chance of heart diesese\n* fbs - fbs=0 have slightly higher chance of heart diesese than fbs=1\n"}}