{"cell_type":{"dacd17d2":"code","da242c78":"code","dafe1c0f":"code","34ea38d6":"code","3b55e623":"code","406213a5":"code","6abdd4f4":"code","d0452900":"code","ece20760":"code","7a46bc9f":"code","0c746c81":"code","57c9f3bd":"code","0fec7c8a":"code","981e5d7c":"code","0ce40459":"code","b419ef80":"code","87769d1c":"code","ee7eb5f8":"code","25dbd1f3":"code","dd7a1ac7":"markdown"},"source":{"dacd17d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da242c78":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport random","dafe1c0f":"train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv',sep=',')\ntest= pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv', sep = ',')","34ea38d6":"train.shape","3b55e623":"# we have 60000 training data ","406213a5":"test.shape","6abdd4f4":"# we have 10000 test data ","d0452900":"train.head()","ece20760":"train = np.array(train, dtype = 'float32')\ntest = np.array(test, dtype='float32')","7a46bc9f":"i = random.randint(1,60000) \nplt.imshow( train[i,1:].reshape((28,28)) ) \n\nplt.imshow( train[i,1:].reshape((28,28)) , cmap = 'gray') \n\n\n# Remember the 10 classes decoding is as follows:\n# 0 => T-shirt\/top\n# 1 => Trouser\n# 2 => Pullover\n# 3 => Dress\n# 4 => Coat\n# 5 => Sandal\n# 6 => Shirt\n# 7 => Sneaker\n# 8 => Bag\n# 9 => Ankle boot","0c746c81":"# Let's view more images in a grid format\n# Define the dimensions of the plot grid \nW_grid = 15\nL_grid = 15\n\n# fig, axes = plt.subplots(L_grid, W_grid)\n# subplot return the figure object and axes object\n# we can use the axes object to plot specific figures at various locations\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n\naxes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n\nn_training = len(train) # get the length of the training dataset\n\n# Select a random number from 0 to n_training\nfor i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n\n    # Select a random number\n    index = np.random.randint(0, n_training)\n    # read and display an image with the selected index    \n    axes[i].imshow( train[index,1:].reshape((28,28)) )\n    axes[i].set_title(train[index,0], fontsize = 8)\n    axes[i].axis('off')\n\nplt.subplots_adjust(hspace=0.4)\n\n# Remember the 10 classes decoding is as follows:\n# 0 => T-shirt\/top\n# 1 => Trouser\n# 2 => Pullover\n# 3 => Dress\n# 4 => Coat\n# 5 => Sandal\n# 6 => Shirt\n# 7 => Sneaker\n# 8 => Bag\n# 9 => Ankle boot","57c9f3bd":"X_train = train[:,1:]\/255\ny_train = train[:,0]\n\nX_test = test[:,1:]\/255\ny_test = test[:,0]","0fec7c8a":"from sklearn.model_selection import train_test_split\n\nX_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = 0.2, random_state = 12345)","981e5d7c":"# * unpack the tuple\nX_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\nX_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))\nX_validate = X_validate.reshape(X_validate.shape[0], *(28, 28, 1))","0ce40459":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard","b419ef80":"model = Sequential([Conv2D(32, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n                                 MaxPooling2D(2,2),\n                                 Conv2D(32, (3,3), activation=\"relu\"),\n                                 MaxPooling2D(2,2),\n                                 Dropout(0.2),\n                                 Flatten(),\n                                 Dense(128, activation=\"relu\"),\n                                Dense(10, activation=\"softmax\")])\n\n","87769d1c":"model.summary()","ee7eb5f8":"model.compile(optimizer='adam',\n              loss='SparseCategoricalCrossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train,\n                        y_train,\n                        batch_size = 512,\n                        epochs = 50,\n                        verbose = 1,\n                        validation_data = (X_validate, y_validate))","25dbd1f3":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)","dd7a1ac7":"# **CASE STUDY: FASHION CLASS **\n\nFashion training set consists of 70,000 images divided into 60,000 training and 10,000 testing samples. Dataset sample consists of 28x28 grayscale image, associated with a label from 10 classes.\n\nThe 10 classes are as follows:\n0 => T-shirt\/top 1 => Trouser 2 => Pullover 3 => Dress 4 => Coat 5 => Sandal 6 => Shirt 7 => Sneaker 8 => Bag 9 => Ankle boot\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.\n"}}