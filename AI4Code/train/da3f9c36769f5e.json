{"cell_type":{"6c76241f":"code","495c207e":"code","6db43cbd":"code","8312d256":"code","a475ae3b":"code","d770f004":"code","d48b8997":"code","9ab725fa":"code","ef25f797":"code","b518335c":"code","00fc6b56":"code","8afeb070":"code","481eef31":"code","02371808":"code","95b58fcd":"code","c22c8c6a":"code","1ceb8df3":"code","166c2bc5":"code","62dae6ae":"code","a58e9bc6":"code","8bad75c4":"code","2def6189":"code","d7bd068e":"code","091787fc":"code","1cb32ead":"code","fd6370af":"code","d9ff0e8e":"code","703d7227":"code","93fbcd03":"code","37625113":"code","5297e124":"code","98fa6111":"code","59128694":"code","986c4f1b":"code","9a45991a":"code","42eb1e4c":"markdown","050b2645":"markdown","84f365a5":"markdown","bba8d3a5":"markdown","88d19ed4":"markdown","63aa8b21":"markdown"},"source":{"6c76241f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.probability import FreqDist\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn import metrics\n\nimport string\nimport re\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","495c207e":"train_df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest_df = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","6db43cbd":"train_df.head()","8312d256":"train_df.info()","a475ae3b":"train_df.isnull().sum()","d770f004":"test_df.head()","d48b8997":"test_df.info()","9ab725fa":"test_df.isnull().sum()","ef25f797":"print(round(train_df.target.value_counts(normalize=True)*100, 2))","b518335c":"sns.countplot(train_df.target)","00fc6b56":"# Analyzing the frequency\nFreqDist([w.lower() for w in (sum(train_df['text'].apply(lambda x: word_tokenize(x)), []))])","8afeb070":"# Creating a copy for clean and keep the original\ntrain_df['text_cleaned'] = train_df.text.copy()","481eef31":"# Functions for clean\n\n# Remove punctuation\ndef remove_punct(text):\n    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n    return no_punct\n\n# Lemmatization\ndef word_lemmat(text):\n    lemmatizer = WordNetLemmatizer()\n    lemmat_text = [lemmatizer.lemmatize(i) for i in text]\n    return lemmat_text\n\n# Stemming\ndef word_stemmer(text):\n    stemmer = PorterStemmer()\n    stem_text = [stemmer.stem(i) for i in text]\n    return stem_text\n    \n# Remove stop words\ndef remove_stopw(text):\n    stop_w = set(stopwords.words(\"english\"))\n    words = \" \".join([w for w in text if w not in stop_w])\n    return words","02371808":"# Apply the functions\n\n# Remove special caracteres\ntrain_df['text_cleaned'] = train_df['text_cleaned'].str.replace('[^A-Za-z0-9+]', ' ')\n\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(lambda x: remove_punct(x.lower().strip()))\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(word_tokenize)\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(lambda x: word_lemmat(x))\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(lambda x: word_stemmer(x))\ntrain_df['text_cleaned'] = train_df['text_cleaned'].apply(lambda x: remove_stopw(x))","95b58fcd":"# Apply the functions\n\n# Remove special caracteres\ntest_df['text'] = test_df['text'].str.replace('[^A-Za-z0-9+]', ' ')\n\ntest_df['text'] = test_df['text'].apply(lambda x: remove_punct(x.lower().strip()))\ntest_df['text'] = test_df['text'].apply(word_tokenize)\ntest_df['text'] = test_df['text'].apply(lambda x: word_lemmat(x))\ntest_df['text'] = test_df['text'].apply(lambda x: word_stemmer(x))\ntest_df['text'] = test_df['text'].apply(lambda x: remove_stopw(x))","c22c8c6a":"# Define X and y\ntrain_df[['target','text_cleaned']].head()","1ceb8df3":"X = train_df['text_cleaned']\ny = train_df['target']","166c2bc5":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)","62dae6ae":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","a58e9bc6":"nb = MultinomialNB()","8bad75c4":"vector = CountVectorizer()\nvector.fit(X_train)","2def6189":"# Transform training data\nX_train_doc = vector.transform(X_train)","d7bd068e":"# X_train_doc = vect.fit_transform(X_train)","091787fc":"X_test_doc = vector.transform(X_test)","1cb32ead":"nb.fit(X_train_doc, y_train)","fd6370af":"y_pred_text = nb.predict(X_test_doc)","d9ff0e8e":"print(\"Accuracy:\")\nprint(metrics.accuracy_score(y_test, y_pred_text))\nprint()\nprint(\"Confusion Matrix\")\nprint(metrics.confusion_matrix(y_test, y_pred_text))","703d7227":"logreg = LogisticRegression()","93fbcd03":"logreg.fit(X_train_doc, y_train)","37625113":"y_pred_text = logreg.predict(X_test_doc)","5297e124":"print(\"Accuracy:\")\nprint(metrics.accuracy_score(y_test, y_pred_text))\nprint()\nprint(\"Confusion Matrix\")\nprint(metrics.confusion_matrix(y_test, y_pred_text))","98fa6111":"file_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","59128694":"Vector_test = vector.transform(test_df['text'])","986c4f1b":"y_predict_test = logreg.predict(Vector_test)\nfile_submission.target = y_predict_test\nfile_submission.to_csv(\"submission.csv\", index=False)","9a45991a":"file_submission.head(10)","42eb1e4c":"# Train and test models","050b2645":"## Using Naive Bayes Classifiers","84f365a5":"# Submission","bba8d3a5":"## Using Logistic Regression","88d19ed4":"The target is balanced.","63aa8b21":"# clearing the data"}}