{"cell_type":{"5bd19a31":"code","b7d1d92e":"code","0fde6df2":"code","75cfb7ff":"code","2be73848":"code","e8c37041":"code","1bc241fb":"code","120e5909":"code","b783f4b6":"code","c691b2aa":"code","545daebe":"code","7dc526bc":"code","3bee8a37":"code","7d467469":"code","65372a4f":"code","347505db":"code","5641099b":"code","85280338":"code","e81d3808":"code","0f24d712":"code","adf035fd":"code","ec791af7":"code","cdd202f4":"code","01186145":"code","bafdae17":"code","1556fe8f":"code","0cf2ec7c":"code","9ec1b00f":"code","86864163":"code","0c16eeee":"code","7168f0a6":"code","3c02120a":"code","31d22650":"code","53369771":"code","d8937cc8":"code","11d765bb":"code","2fb6813b":"code","e1f7ea37":"code","f95e37b2":"code","052d4826":"code","7295f92b":"code","320cf917":"code","a9d7c09a":"code","2bebcebd":"code","972c3ebf":"code","16bb46fe":"code","8c4b965a":"code","6dd96bde":"code","a16f7c6f":"code","ac56dd94":"code","29cdb1b4":"code","a9b6174d":"code","65f28d7e":"code","5d5a0c66":"code","40be0434":"code","868d3365":"code","591254d1":"code","7403bf53":"code","7dd1a04d":"code","a16d5fad":"markdown","d012b07c":"markdown","2c4ff57c":"markdown","feddc2c6":"markdown","aad0b28d":"markdown","98e8ee33":"markdown","93e4776c":"markdown","7be64b2f":"markdown","374ac720":"markdown","d871c1be":"markdown"},"source":{"5bd19a31":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport numpy as np # linear algebra\nimport cv2 as cv\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.manifold import TSNE\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7d1d92e":"train_path = '\/kaggle\/input\/omniglot\/images_background'\ntest_path = '\/kaggle\/input\/omniglot\/images_evaluation'","0fde6df2":"def load_data(path):\n    X = []\n    Y = []\n    Alphabets = []\n    a = 0\n    c = 0\n    for d_a in os.listdir(path):\n        for d_c in os.listdir(os.path.join(path, d_a)):\n            for d_f in os.listdir(os.path.join(path, d_a, d_c)):\n                Y.append([a, c])\n                X.append(os.path.join(path, d_a, d_c, d_f))\n                Alphabets.append(d_a)\n            c += 1\n        a += 1\n    return np.array(X), np.array(Y), np.array(Alphabets)\n\ndef split(data, labels, *largs):\n    m = np.max(labels[:, 0])\n    dev_size = int(np.ceil(m \/ 10))\n    mask = np.isin(labels[:, 0], np.random.randint(m, size=dev_size))\n    return data[~mask], labels[~mask], data[mask], labels[mask]\n\nX_train, Y_train, X_dev, Y_dev = split(*load_data(train_path))\n\nX_test, Y_test, Alphabets = load_data(test_path)","75cfb7ff":"print(f'Train data loaded shape: {X_train.shape}, train labels shape: {Y_train.shape}')\nprint(f'Train data loaded shape: {X_dev.shape}, train labels shape: {Y_dev.shape}')\nprint(f'Test data loaded shape: {X_test.shape}, test labels shape: {Y_test.shape}')","2be73848":"def print_cl_batch(images, labels):\n    x1, x2 = images\n    length = labels.shape[0]\n    fig = plt.figure(figsize=(8, 15))\n    for i in range(5):\n        ax = fig.add_subplot(5, 2, i*2 + 1)\n        ax.set_title('Element 1')\n        ax.imshow(x1[i])\n        ax = fig.add_subplot(5, 2, i*2 + 2)\n        ax.set_title('Element 2')\n        ax.imshow(x2[i])\n    plt.show()\n\ndef print_tl_batch(images, labels):\n    a, p, n = images\n    length = labels.shape[0]\n    fig = plt.figure(figsize=(8, 15))\n    for i in range(5):\n        ax = fig.add_subplot(5, 3, i*3 + 1)\n        ax.set_title(f'Anchor, id: {labels[i]}')\n        ax.imshow(a[i])\n        ax = fig.add_subplot(5, 3, i*3 + 2)\n        ax.set_title('Positive')\n        ax.imshow(p[i])\n        ax = fig.add_subplot(5, 3, i*3 + 3)\n        ax.set_title('Negative')\n        ax.imshow(n[i])\n    plt.show()\n\ndef print_bh_batch(images, labels):\n    cpb = np.unique(labels).shape[0]\n    ipb = int(images.shape[0] \/ cpb)\n    rows = min(5, cpb)\n    cols = min(5, ipb)\n    fig = plt.figure(figsize=(15, 8))\n    for i in range(rows):\n        for j in range(cols):\n            ax = fig.add_subplot(rows, cols, i*cols + j + 1)\n            ax.imshow(images[i * ipb + j])\n\ndef print_sbh_batch(images, labels):\n    cpb = np.unique(labels[:, 1]).shape[0]\n    ipb = int(images.shape[0] \/ cpb)\n    rows = min(5, cpb)\n    cols = min(5, ipb)\n    fig = plt.figure(figsize=(15, 8))\n    for i in range(rows):\n        for j in range(cols):\n            ax = fig.add_subplot(rows, cols, i*cols + j + 1)\n            ax.imshow(images[i * ipb + j])\n\ndef shuffle(arr):\n    np.random.shuffle(arr)\n    return arr\n\ndef load_image(file):\n    image = tf.keras.preprocessing.image.load_img(file)\n    return tf.keras.preprocessing.image.img_to_array(image)\n\n","e8c37041":"def evaluate(x, y, alphabets, batch, min_margin):\n    def normalize_labels(l):\n        for i in range(l.shape[1]):\n            unique = np.unique(l[:, i])\n            length = unique.shape[0]\n            unique_map = {v: k for v, k in zip(unique.tolist(), range(length))}\n            l[:, i] = np.array([unique_map[v] for v in l[:, i]])\n        return l\n    \n    def plot(embeddings, ax, l, title):\n        length = np.unique(l).shape[0]\n        unique_palette = np.array(sns.color_palette(\"husl\", length))\n        ax.set_title(title)\n        sc = ax.scatter(embeddings[:,0], embeddings[:,1], lw=0, s=40,\n                        c=unique_palette[l.astype(np.int)])\n        ax.axis('off')\n        ax.axis('tight')\n        \n    def plot_false_predictions(mask, ls, pred, prefix):\n        def sample(size, m_pred):\n            s = []\n            for p_l in m_pred:\n                m = ls == p_l\n                length = np.sum(m)\n                if length == 0:\n                    print(f'Label: {p_l} from available labels: {ls}')\n                else:\n                    idxs = np.random.randint(length, size=size)\n                    s.append([data[m][idxs], p_l])\n            return s\n        def prepare_data(m_data, m_labels, m_pred):\n            length = m_labels.shape[0]\n            idx = np.random.randint(length, size=5)\n            s = sample(4, m_pred[idx])\n            if len(s) < 4:\n                idx = np.random.randint(length, size=5)\n                s = sample(4, m_pred[idx])\n            return m_data[idx], m_labels[idx], s\n        def plot_data(p_d, a_l, s_d):\n            fig = plt.figure(figsize=(15, 16))\n            for i in range(5):\n                ax = fig.add_subplot(5, 5, i*5 + 1)\n                ax.set_title(f'{prefix}, id: {a_l[i]}')\n                ax.imshow(p_d[i])\n                s_imgs, s_label = s_d[i]\n                for j in range(4):\n                    ax = fig.add_subplot(5, 5, i*5 + j + 2)\n                    ax.set_title(f'{prefix} sample {j + 1} of {s_label}')\n                    ax.imshow(s_imgs[j])\n            plt.show()\n        mask2 = np.isin(pred[mask], np.unique(ls[mask]))\n        p_d, p_l, p_s = prepare_data(data[mask][mask2], ls[mask][mask2], pred[mask][mask2])\n        plot_data(p_d, p_l, p_s)\n        \n    def scatter(embeddings):\n        tsne = TSNE()\n        data = tsne.fit_transform(embeddings)\n        f = plt.figure(figsize=(20, 10))\n        plot(data, f.add_subplot(1, 2, 1), labels[:, 1], 'Characters')\n        plot(data, f.add_subplot(1, 2, 2), labels[:, 0], 'Alphabets')\n        plt.show()\n    \n    def calculate_centroids(unique, embeddings, l):\n        equal = np.equal(np.expand_dims(unique, axis=1), np.expand_dims(l, axis=0))\n        positive_mask = equal.astype(dtype=np.float32)\n        matmul = np.matmul(positive_mask, embeddings)\n        reduce_sum = np.sum(positive_mask, axis=-1)\n        return np.divide(matmul, np.expand_dims(reduce_sum, axis=1))\n    \n    def predict(embeddings, l, multiplier):\n        centroids = calculate_centroids(np.unique(l), embeddings, l)\n        pairwise_dist = np.linalg.norm(np.expand_dims(centroids, 0) - np.expand_dims(embeddings, 1), axis=-1)\n        margin = np.ones_like(l, dtype=np.float32) * min_margin * multiplier\n        dist = np.concatenate([pairwise_dist, np.reshape(margin, (-1, 1))], axis=1)\n        return np.argmin(dist, axis=1)\n    \n    def print_report(report, title):\n        print(title)\n        print(\"Accuracy: {:.2f}\".format(report['accuracy']))\n        print(\"Precision: {:.2f}\".format(report['macro avg']['precision']))\n        print(\"Recall: {:.2f}\".format(report['macro avg']['recall']))\n        print(\"F1-score: {:.2f}\".format(report['macro avg']['f1-score']))\n        \n    def evaluate(model):\n        def scatter_func():\n            scatter(embeddings)\n        def false_pred_sample_func():\n            plot_false_predictions(chars_mask, labels[:, 1], y_chars, 'Chars')\n            plot_false_predictions(alphs_mask, labels[:, 0], y_alphs, 'Alphabets')\n        def report_func():\n            print_report(classification_report(labels[:, 1], y_chars, output_dict=True, zero_division=0), 'Characters')\n            print()\n            print_report(classification_report(labels[:, 0], y_alphs, output_dict=True, zero_division=0), 'Alphabets')\n        embeddings = model.predict(data)\n        y_chars = predict(embeddings, labels[:, 1], 1)\n        y_alphs = predict(embeddings, labels[:, 0], 2)\n        chars_mask = y_chars != labels[:, 1]\n        alphs_mask = y_alphs != labels[:, 0]\n        return scatter_func, false_pred_sample_func, report_func\n        \n    \n    np.random.seed(31)\n    idxs = shuffle(np.unique(y[: , 0]))\n    mask = np.isin(y[: , 0], idxs[:batch])\n    data = np.array([load_image(file) for file in x[mask]])\n    labels = normalize_labels(y[mask])\n    return evaluate\n\nevaluator = evaluate(X_test, Y_test, Alphabets, 5, 0.6)","1bc241fb":"def build_network():\n    branch = tf.keras.Sequential()\n    branch.add(tf.keras.layers.Lambda(lambda x: x \/ 255.0))\n    branch.add(tf.keras.layers.Conv2D(64, (5, 5), padding='valid', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))\n    branch.add(tf.keras.layers.ZeroPadding2D(padding=(1, 1)))\n    branch.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n    \n    branch.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))    \n    branch.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))\n    branch.add(tf.keras.layers.Conv2D(256, (5, 5), padding='valid', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))\n    branch.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n    \n    branch.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))    \n    branch.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))\n    branch.add(tf.keras.layers.Conv2D(256, (3, 3), padding='valid', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))\n    branch.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n    \n    branch.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))\n    branch.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))\n    branch.add(tf.keras.layers.Conv2D(512, (3, 3), padding='valid', kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Activation('relu'))\n    branch.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n    \n    branch.add(tf.keras.layers.GlobalAveragePooling2D())\n    \n    branch.add(tf.keras.layers.Dense(32, kernel_initializer='he_normal'))\n    branch.add(tf.keras.layers.BatchNormalization())\n    branch.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n    return branch","120e5909":"class PairDataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, data, labels, batch_size, steps_per_epoch):\n        self.data = data\n        self.labels = labels\n        self.batch_size = batch_size\n        self.steps_per_epoch = steps_per_epoch\n\n    def __len__(self):\n        return self.steps_per_epoch\n\n    def __get_geneuine_pairs__(self, char_ids):\n        def mask(char_id):\n            m = self.labels == self.labels[char_id]\n            m[char_id] = False\n            return m\n        def rand_file(files):\n            return shuffle(files)[0]\n        return [load_image(file) for file in self.data[char_ids]], [load_image(rand_file(self.data[mask(idx)])) for idx in char_ids], [True for _ in range(len(char_ids))]\n\n    def __get_imposter_pairs__(self, char_ids):\n        mask = np.isin(self.labels, self.labels[char_ids])\n        imposters = shuffle(self.data[~mask])[:len(char_ids)]\n        return [load_image(file) for file in self.data[char_ids]], [load_image(file) for file in imposters], [False for _ in range(len(char_ids))]\n\n    def __getitem__(self, index):\n        char_ids = np.random.randint(len(self.labels), size=self.batch_size)\n        half = int(self.batch_size \/ 2)\n        x_1, x_2, y = self.__get_geneuine_pairs__(char_ids[:half])\n        a, b, c = self.__get_imposter_pairs__(char_ids[half:])\n        x_1.extend(a)\n        x_2.extend(b)\n        y.extend(c)\n        return [np.array(x_1), np.array(x_2)], np.array(y)\n\n\ndef euclidean_distance(vects):\n    x, y = vects\n    sum_square = tf.reduce_sum(tf.math.square(x - y), axis=1)\n    return tf.sqrt(tf.maximum(sum_square, 1e-16))\n\n\ndef eucl_dist_output_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0], 1)\n\ndef contrastive_loss(margin):\n    def loss(y_true, y_pred):\n        y_true = tf.cast(y_true, dtype=tf.float32)\n        square_pred = tf.math.square(y_pred)\n        margin_square = tf.math.square(tf.maximum(margin - y_pred, 0.0))\n        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n    return loss\n\ndef contrastive_accuracy(margin):\n    def acc(y_true, y_pred):\n        y_true = tf.cast(y_true, dtype=tf.float32)\n        return tf.reduce_mean(tf.cast(tf.equal(y_true, tf.cast(y_pred < margin, dtype=tf.float32)), dtype=tf.float32))\n    return acc","b783f4b6":"cl_train_gen = PairDataGenerator(X_train, Y_train[:, 1], 33, 50)\ncl_dev_gen = PairDataGenerator(X_dev, Y_dev[:, 1], 33, 4)\n[x1, x2], y = cl_train_gen.__getitem__(0)\nprint_cl_batch(*cl_train_gen.__getitem__(0))","c691b2aa":"x_in_1 = tf.keras.Input((105, 105, 3))\nx_in_2 = tf.keras.Input((105, 105, 3))\n\nbranch = build_network()\n\nbranch_1 = branch(x_in_1)\nbranch_2 = branch(x_in_2)\nx_out = tf.keras.layers.Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([branch_1, branch_2])\n\nsiamese_model_1 = tf.keras.Model([x_in_1, x_in_2], x_out)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nsiamese_model_1.compile(optimizer=optimizer, loss=contrastive_loss(1.0), metrics=[contrastive_accuracy(0.5)])","545daebe":"s_func, p_func, r_func = evaluator(branch)\ns_func()","7dc526bc":"p_func()","3bee8a37":"r_func()","7d467469":"siamese_history_1 = siamese_model_1.fit_generator(\n                    generator=cl_train_gen,\n                    validation_data=cl_dev_gen,\n                    epochs=50,\n                    verbose=0 # set to 1 to see learning progress\n                )","65372a4f":"s_func, p_func, r_func = evaluator(branch)\ns_func()","347505db":"p_func()","5641099b":"r_func()","85280338":"class TripletDataGenerator(tf.keras.utils.Sequence):\n    \n    def __init__(self, data, labels, batch_size, steps_per_epoch):\n        self.data = data\n        self.labels = labels\n        self.batch_size = batch_size\n        self.steps_per_epoch = steps_per_epoch\n        \n    def __len__(self):\n        return self.steps_per_epoch\n    \n    def __gettriplet__(self, char_id):\n        mask = self.labels[:, 1] == char_id\n        ap = shuffle(self.data[mask])[:2]\n        n = shuffle(self.data[~mask])[0]\n        return load_image(ap[0]), load_image(ap[1]), load_image(n)\n    \n    def __getitem__(self, index):\n        char_ids = np.unique(self.labels[:, 1])\n        anchor_ids = shuffle(char_ids)[:self.batch_size]\n        x_a = []\n        x_p = []\n        x_n = []\n        for char_id in anchor_ids:\n            a, p, n = self.__gettriplet__(char_id)\n            x_a.append(a)\n            x_p.append(p)\n            x_n.append(n)\n        x_a = np.array(x_a)\n        x_p = np.array(x_p)\n        x_n = np.array(x_n)\n        return [x_a, x_p, x_n], anchor_ids\n\ndef euclidian_distance(v1, v2):\n    return tf.sqrt(tf.reduce_sum(tf.square(v1 - v2), axis=-1) + 1e-16)\n\ndef triplet_loss(margin):\n    def loss(y_true, y_pred):\n        total_lenght = y_pred.shape.as_list()[-1]\n        anchors = y_pred[:,0:int(total_lenght*1\/3)]\n        positives = y_pred[:,int(total_lenght*1\/3):int(total_lenght*2\/3)]\n        negatives = y_pred[:,int(total_lenght*2\/3):]\n        pos_dist = euclidian_distance(anchors, positives)\n        neg_dist = euclidian_distance(anchors, negatives)\n        return tf.reduce_mean(tf.maximum((pos_dist - neg_dist) + margin, 0.0))\n    return loss\n\ndef tl_acc(margin):\n    def acc(y_true, y_pred):\n        total_lenght = y_pred.shape.as_list()[-1]\n        anchors = y_pred[:,0:int(total_lenght*1\/3)]\n        positives = y_pred[:,int(total_lenght*1\/3):int(total_lenght*2\/3)]\n        negatives = y_pred[:,int(total_lenght*2\/3):]\n        pos_dist = euclidian_distance(anchors, positives)\n        neg_dist = euclidian_distance(anchors, negatives)\n        return tf.reduce_mean(tf.cast(tf.math.logical_and(tf.math.less_equal(pos_dist, neg_dist), tf.math.less_equal(pos_dist, 2*margin)), dtype=tf.float32))\n    return acc","e81d3808":"tl_train_gen = TripletDataGenerator(X_train, Y_train, 22, 50)\ntl_dev_gen = TripletDataGenerator(X_dev, Y_dev, 22, 4)\nprint_tl_batch(*tl_train_gen.__getitem__(0))","0f24d712":"x_in_a = tf.keras.Input((105, 105, 3))\nx_in_p = tf.keras.Input((105, 105, 3))\nx_in_n = tf.keras.Input((105, 105, 3))\n\nbranch = build_network()\n\nbranch_a = branch(x_in_a)\nbranch_p = branch(x_in_p)\nbranch_n = branch(x_in_n)\nx_out = tf.keras.layers.Concatenate()([branch_a, branch_p, branch_n])\n\nsiamese_model_1 = tf.keras.Model([x_in_a, x_in_p, x_in_n], x_out)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nsiamese_model_1.compile(optimizer=optimizer, loss=triplet_loss(0.3), metrics=[tl_acc(0.3)])","adf035fd":"siamese_history_1 = siamese_model_1.fit_generator(\n                    generator=tl_train_gen,\n                    validation_data=tl_dev_gen,\n                    epochs=50,\n                    verbose=0 # set to 1 to see learning progress\n                )","ec791af7":"s_func, p_func, r_func = evaluator(branch)\ns_func()","cdd202f4":"p_func()","01186145":"r_func()","bafdae17":"def scheduler(epoch, lr):\n    return lr * 0.8 if epoch % 2 == 0 else lr","1556fe8f":"branch = build_network()\n\nbranch_a = branch(x_in_a)\nbranch_p = branch(x_in_p)\nbranch_n = branch(x_in_n)\nx_out = tf.keras.layers.Concatenate()([branch_a, branch_p, branch_n])\n\nsiamese_model_2 = tf.keras.Model([x_in_a, x_in_p, x_in_n], x_out)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nsiamese_model_2.compile(optimizer=optimizer, loss=triplet_loss(0.3), metrics=[tl_acc(0.3)])\n\nsiamese_history_2 = siamese_model_2.fit_generator(\n                    generator=tl_train_gen,\n                    validation_data=tl_dev_gen,\n                    epochs=50,\n                    verbose=0, # set to 1 to see learning progress\n                    callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)]\n                )","0cf2ec7c":"s_func, p_func, r_func = evaluator(branch)\ns_func()","9ec1b00f":"p_func()","86864163":"r_func()","0c16eeee":"class BatchHardDataGenerator(tf.keras.utils.Sequence):\n    \n    def __init__(self, data, labels, images_per_class, classes_per_batch, steps_per_epoch):\n        self.data = data\n        self.labels = labels\n        self.images_per_class = images_per_class\n        self.steps_per_epoch = steps_per_epoch\n        self.classes_per_batch = classes_per_batch\n        \n    def __len__(self):\n        return self.steps_per_epoch\n    \n    def __getclass__(self, char_id):\n        mask = self.labels[:, 1] == char_id\n        return [load_image(file) for file in shuffle(self.data[mask])[:self.images_per_class]], [char_id for _ in range(self.images_per_class)]\n    \n    def __getitem__(self, index):\n        char_ids = np.unique(self.labels[:, 1])\n        classes = shuffle(char_ids)[:self.classes_per_batch]\n        x = []\n        y = []\n        for cls in classes:\n            data, labels = self.__getclass__(cls)\n            x.extend(data)\n            y.extend(labels)\n        x = np.array(x)\n        y = np.array(y)\n        return x, y","7168f0a6":"bh_train_gen = BatchHardDataGenerator(X_train, Y_train, 4, 16, 50)\nbh_dev_gen = BatchHardDataGenerator(X_dev, Y_dev, 4, 16, 4)\nprint_bh_batch(*bh_train_gen.__getitem__(0))","3c02120a":"def pairwise_distances(embeddings):\n    dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n    square_norm = tf.linalg.diag_part(dot_product)\n    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n    distances = tf.maximum(distances, 0.0)\n    mask = tf.cast(tf.equal(distances, 0.0), dtype=tf.float32)\n    distances = distances + mask * 1e-16\n    distances = tf.sqrt(distances)\n    distances = distances * (1.0 - mask)\n    return distances\n\ndef get_anchor_positive_triplet_mask(labels):\n    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n    indices_not_equal = tf.logical_not(indices_equal)\n    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n    mask = tf.logical_and(indices_not_equal, labels_equal)\n    return mask\n\n\ndef get_anchor_negative_triplet_mask(labels):\n    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n    mask = tf.logical_not(labels_equal)\n    return mask\n\ndef masked_maximum(data, mask, dim=1):\n    axis_minimums = tf.math.reduce_min(data, dim, keepdims=True)\n    masked_maximums = (\n        tf.math.reduce_max(tf.math.multiply(data - axis_minimums, mask), dim, keepdims=True) + axis_minimums\n    )\n    return masked_maximums\n\n\ndef masked_minimum(data, mask, dim=1):\n    axis_maximums = tf.math.reduce_max(data, dim, keepdims=True)\n    masked_minimums = (\n        tf.math.reduce_min(tf.math.multiply(data - axis_maximums, mask), dim, keepdims=True) + axis_maximums\n    )\n    return masked_minimums\n\ndef calculate_centroids(unique, embeddings, labels):\n    equal = tf.equal(tf.expand_dims(unique, axis=1), tf.expand_dims(labels, axis=0))\n    positive_mask = tf.cast(equal, dtype=tf.float32)\n    matmul = tf.matmul(positive_mask, embeddings)\n    reduce_sum = tf.reduce_sum(positive_mask, axis=-1)\n    return tf.divide(matmul, tf.expand_dims(reduce_sum, axis=1))\n\ndef get_triplet_mask(labels):\n    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n    indices_not_equal = tf.logical_not(indices_equal)\n    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n    i_equal_j = tf.expand_dims(label_equal, 2)\n    i_equal_k = tf.expand_dims(label_equal, 1)\n    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n    mask = tf.logical_and(distinct_indices, valid_labels)\n    return mask\n\ndef bh_loss(margin):\n    def loss(labels, embeddings):\n        convert_to_float32 = (embeddings.dtype == tf.dtypes.float16 or embeddings.dtype == tf.dtypes.bfloat16)\n        precise_embeddings = (tf.cast(embeddings, tf.dtypes.float32) if convert_to_float32 else embeddings)\n        lshape = tf.shape(labels)\n        labels = tf.reshape(labels, [lshape[0], 1])\n        pdist_matrix = pairwise_distances(precise_embeddings)\n        adjacency = tf.math.equal(labels, tf.transpose(labels))\n        adjacency_not = tf.math.logical_not(adjacency)\n        adjacency_not = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n        hard_negatives = masked_minimum(pdist_matrix, adjacency_not)\n        batch_size = tf.size(labels)\n        adjacency = tf.cast(adjacency, dtype=tf.dtypes.float32)\n        mask_positives = tf.cast(adjacency, dtype=tf.dtypes.float32) - tf.linalg.diag(tf.ones([batch_size]))\n        hard_positives = masked_maximum(pdist_matrix, mask_positives)\n        triplet_loss = tf.maximum(hard_positives - hard_negatives + margin, 1e-16)\n        return tf.reduce_mean(triplet_loss)\n    return loss\n\ndef bh_acc(min_margin):\n    def acc(labels, embeddings):\n        ls = tf.reshape(labels, [-1])\n        unique, idx = tf.unique(ls)\n        centroids = calculate_centroids(unique, embeddings, ls)\n        pairwise_dist = tf.norm(tf.expand_dims(centroids, 0) - tf.expand_dims(embeddings, 1), ord='euclidean', axis=-1)\n        margin = tf.reshape(tf.multiply(tf.ones_like(labels, dtype=tf.float32), tf.constant(min_margin, dtype=tf.float32)), [-1, 1])\n        dist = tf.concat([pairwise_dist, margin], axis=1)\n        min_idx = tf.argmin(dist, axis=1, output_type=tf.dtypes.int32)\n        reduce_sum = tf.reduce_sum(tf.cast(tf.equal(min_idx, idx), dtype=tf.float32))\n        size = tf.cast(tf.size(ls, out_type=tf.dtypes.int32), dtype=tf.float32)\n        accuracy = reduce_sum \/ size\n        return accuracy\n    return acc\n","31d22650":"x_in = tf.keras.Input((105, 105, 3))\n\nbranch = build_network()\n\nx_out = branch(x_in)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nbh_model_1 = tf.keras.Model(x_in, x_out)\n\nbh_model_1.compile(optimizer=optimizer, loss=bh_loss(0.3), metrics=[bh_acc(0.3)])\n\n","53369771":"bh_history_1 = bh_model_1.fit_generator(\n                    generator=bh_train_gen,\n                    validation_data=bh_dev_gen,\n                    epochs=50,\n                    verbose=0 # set to 1 to see learning progress\n                )","d8937cc8":"s_func, p_func, r_func = evaluator(branch)\ns_func()","11d765bb":"p_func()","2fb6813b":"r_func()","e1f7ea37":"def scheduler(epoch, lr):\n    return lr * 0.8 if epoch % 2 == 0 else lr","f95e37b2":"x_in = tf.keras.Input((105, 105, 3))\n\nbranch = build_network()\n\nx_out = branch(x_in)\n\nbh_model_2 = tf.keras.Model(x_in, x_out)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nbh_model_2.compile(optimizer=optimizer, loss=bh_loss(0.3), metrics=[bh_acc(0.3)])\n\nbh_history_2 = bh_model_2.fit_generator(\n                    generator=bh_train_gen,\n                    validation_data=bh_dev_gen,\n                    epochs=50,\n                    verbose=0, # set to 1 to see learning progress\n                    callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)]\n                )","052d4826":"s_func, p_func, r_func = evaluator(branch)\ns_func()","7295f92b":"p_func()","320cf917":"r_func()","a9d7c09a":"x_in = tf.keras.Input((105, 105, 3))\n\nbranch = build_network()\n\nx_out = branch(x_in)\n\nbh_model_3 = tf.keras.Model(x_in, x_out)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\nbh_model_3.compile(optimizer=optimizer, loss=bh_loss(0.3), metrics=[bh_acc(0.3)])\n\nbh_train_gen = BatchHardDataGenerator(X_train, Y_train, 6, 11, 50)\nbh_dev_gen = BatchHardDataGenerator(X_dev, Y_dev, 6, 11, 4)\n\nbh_history_3 = bh_model_3.fit_generator(\n                    generator=bh_train_gen,\n                    validation_data=bh_dev_gen,\n                    epochs=50,\n                    verbose=0, # set to 1 to see learning progress\n                    callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)]\n                )","2bebcebd":"s_func, p_func, r_func = evaluator(branch)\ns_func()","972c3ebf":"p_func()","16bb46fe":"r_func()","8c4b965a":"class StructuredBatchHardDataGenerator(tf.keras.utils.Sequence):\n    \n    def __init__(self, data, labels, top_level_classes, images_per_class, classes_per_batch, steps_per_epoch):\n        self.data = data\n        self.labels = labels\n        self.top_level_classes = top_level_classes\n        self.images_per_class = images_per_class\n        self.steps_per_epoch = steps_per_epoch\n        self.classes_per_batch = classes_per_batch\n        \n    def __len__(self):\n        return self.steps_per_epoch\n    \n    def __getclass__(self, char_id):\n        mask = self.labels[:, 1] == char_id\n        return [load_image(file) for file in shuffle(self.data[mask])[:self.images_per_class]], self.labels[mask][:self.images_per_class].tolist()\n    \n    def __top_level_mask__(self):\n        classes = np.unique(self.labels[:, 0])\n        return np.isin(self.labels[:, 0], shuffle(classes)[:self.top_level_classes])\n    \n    def __getitem__(self, index):\n        char_ids = np.unique(self.labels[self.__top_level_mask__()][:, 1])\n        classes = shuffle(char_ids)[:self.classes_per_batch]\n        x = []\n        y = []\n        for cls in classes:\n            data, labels = self.__getclass__(cls)\n            x.extend(data)\n            y.extend(labels)\n        x = np.array(x)\n        y = np.array(y)\n        return x, y","6dd96bde":"sbh_train_gen = StructuredBatchHardDataGenerator(X_train, Y_train, 4, 4, 16, 50)\nsbh_dev_gen = StructuredBatchHardDataGenerator(X_dev, Y_dev, 4, 4, 16, 4)\nprint_sbh_batch(*sbh_train_gen.__getitem__(0))","a16f7c6f":"def sbh_loss(margin):\n    def loss(labels, embeddings):\n        m = tf.constant(margin)\n        convert_to_float32 = (embeddings.dtype == tf.dtypes.float16 or embeddings.dtype == tf.dtypes.bfloat16)\n        precise_embeddings = (tf.cast(embeddings, tf.dtypes.float32) if convert_to_float32 else embeddings)\n        labels = tf.transpose(labels)\n        lshape = tf.shape(labels)\n        no_axis = tf.size(lshape)\n        exp_labels = tf.expand_dims(labels, axis=0)\n        pdist_matrix = tf.expand_dims(pairwise_distances(precise_embeddings), axis=0)\n        adjacency = tf.math.equal(tf.transpose(exp_labels), exp_labels)\n        adjacency = tf.transpose(adjacency, perm=[1,2,0])\n        adjacency_not = tf.math.logical_not(adjacency)\n        adjacency_not = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n        hard_negatives = masked_minimum(pdist_matrix, adjacency_not, no_axis)\n        adjacency = tf.cast(adjacency, dtype=tf.dtypes.float32)\n        mask_positives = tf.cast(adjacency, dtype=tf.dtypes.float32) - tf.linalg.diag(tf.ones(lshape))\n        hard_positives = masked_maximum(pdist_matrix, mask_positives, no_axis)\n        triplet_loss = tf.maximum(hard_positives - hard_negatives + m, 1e-16)\n        return tf.reduce_mean(tf.reduce_sum(triplet_loss, axis=0))\n\n    return loss\n\ndef sbh_acc(min_margin):\n    def acc(labels, embeddings):\n        labels = tf.gather(labels, 1, axis=1)\n        ls = tf.reshape(labels, [-1])\n        unique, idx = tf.unique(ls)\n        centroids = calculate_centroids(unique, embeddings, ls)\n        pairwise_dist = tf.norm(tf.expand_dims(centroids, 0) - tf.expand_dims(embeddings, 1), ord='euclidean', axis=-1)\n        margin = tf.reshape(tf.multiply(tf.ones_like(labels, dtype=tf.float32), tf.constant(min_margin, dtype=tf.float32)), [-1, 1])\n        dist = tf.concat([pairwise_dist, margin], axis=1)\n        min_idx = tf.argmin(dist, axis=1, output_type=tf.dtypes.int32)\n        reduce_sum = tf.reduce_sum(tf.cast(tf.equal(min_idx, idx), dtype=tf.float32))\n        size = tf.cast(tf.size(ls, out_type=tf.dtypes.int32), dtype=tf.float32)\n        accuracy = reduce_sum \/ size\n        return accuracy\n    return acc","ac56dd94":"x_in = tf.keras.Input((105, 105, 3))\n\nbranch = build_network()\n\nx_out = branch(x_in)\n\nsbh_model_1 = tf.keras.Model(x_in, x_out)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nsbh_model_1.compile(optimizer=optimizer, loss=sbh_loss([0.3, 0.6]), metrics=[sbh_acc(0.3)])\n\nsbh_history_1 = sbh_model_1.fit_generator(\n                    generator=sbh_train_gen,\n                    validation_data=sbh_dev_gen,\n                    epochs=50,\n                    verbose=0, # set to 1 to see learning progress\n                    callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)]\n                )","29cdb1b4":"s_func, p_func, r_func = evaluator(branch)\ns_func()","a9b6174d":"p_func()","65f28d7e":"r_func()","5d5a0c66":"def sbh_loss2(margin):\n    def loss(labels, embeddings):\n        m = tf.constant(margin, dtype=tf.float32)\n        convert_to_float32 = (embeddings.dtype == tf.dtypes.float16 or embeddings.dtype == tf.dtypes.bfloat16)\n        precise_embeddings = (tf.cast(embeddings, tf.dtypes.float32) if convert_to_float32 else embeddings)\n        labels = tf.transpose(labels)\n        lshape = tf.shape(labels)\n        no_axis = tf.size(lshape)\n        exp_labels = tf.expand_dims(labels, axis=0)\n        pdist_matrix = tf.expand_dims(pairwise_distances(precise_embeddings), axis=0)\n        adjacency = tf.math.equal(tf.transpose(exp_labels), exp_labels)\n        adjacency = tf.transpose(adjacency, perm=[1,2,0])\n        adjacency_not = tf.math.logical_not(adjacency)\n        adjacency_not = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n        penalized_margins = tf.reduce_sum(adjacency_not * margin, axis=0)\n        penalized_pdist_matrix = tf.maximum(pdist_matrix - penalized_margins, 1e-16)\n        hard_negatives = masked_minimum(penalized_pdist_matrix, adjacency_not[1], no_axis)\n        adjacency = tf.cast(adjacency, dtype=tf.dtypes.float32)\n        mask_positives = tf.cast(adjacency[1], dtype=tf.dtypes.float32) - tf.linalg.diag(tf.ones(lshape[1]))\n        hard_positives = masked_maximum(pdist_matrix, mask_positives, no_axis)\n        triplet_loss = tf.math.log1p(tf.math.exp(hard_positives - hard_negatives))\n        return tf.reduce_mean(tf.reduce_sum(triplet_loss, axis=0))\n\n    return loss","40be0434":"sbh_train_gen = StructuredBatchHardDataGenerator(X_train, Y_train, 4, 3, 22, 50)\nsbh_dev_gen = StructuredBatchHardDataGenerator(X_dev, Y_dev, 4, 3, 22, 4)\nprint_sbh_batch(*sbh_train_gen.__getitem__(0))","868d3365":"x_in = tf.keras.Input((105, 105, 3))\n\nbranch = build_network()\n\nx_out = branch(x_in)\n\nsbh_model_2 = tf.keras.Model(x_in, x_out)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nsbh_model_2.compile(optimizer=optimizer, loss=sbh_loss2(0.3), metrics=[sbh_acc(0.3)])\n\nsbh_history_2 = sbh_model_2.fit_generator(\n                    generator=sbh_train_gen,\n                    validation_data=sbh_dev_gen,\n                    epochs=50,\n                    verbose=0, # set to 1 to see learning progress\n                    callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)]\n                )","591254d1":"s_func, p_func, r_func = evaluator(branch)\ns_func()","7403bf53":"p_func()","7dd1a04d":"r_func()","a16d5fad":"## Triplet loss\n\nIn early 2015, 3 guys from Google Inc. published a paper [FaceNet: A Unified Embedding for Face Recognition and Clustering F. Schroff et al](https:\/\/arxiv.org\/pdf\/1503.03832.pdf). In this paper they presented a model they trained using their loss function called Triplet Loss. \n\n<img src=\"https:\/\/omoindrot.github.io\/assets\/triplet_loss\/triplet_loss.png\"><\/img>\n\nThis loss function ensures that an image $x_i^a$ (anchor) of specific person is closer to all other images $x_i^p$ (positive) of the same person than it is o any image $x_i^n$ (negative) of any other person. \n\nFormally written:\n<center>$$ \\mathcal{L}_{T} = \\sum_i^N[||f(x_i^a) - f(x_i^p)||_2^2 - ||f(x_i^a) - f(x_i^n)||_2^2 + \\alpha]$$, where:<\/center>\n\n* $f(x)$ is an embedding of an image x in d-dimensional Euclidian space\n* $\\alpha$ is margin that is enforced between positive and negative pairs\n\nTo ensure fast convergence, they propsed to possible ways to select triplets:\n\n* Generate triplets offline every n steps, using most recent network checkpoint and compute argmin for negative pair distances and argmax for positive pair distances on a subset of the data\n* Generate triplets online. This can be done by selecting the hard positive\/negative examples from within a mini-batch\n\nThey focused on second approach having mini batches of the order of few thousand examples ","d012b07c":"## Batch Hard Triplet Loss\n\nTwo years later A. Hermans et al published a paper: [In Defense of the Triplet Loss for Person Re-Identification](https:\/\/arxiv.org\/pdf\/1703.07737.pdf), in which they proposed small modifications to triplet loss function that made it easier to train.\n\nIn opose to classical implementation they proposed to form a batch by randomly sample $P$ classes, and then randomly sample $K$ images of each class. Now for each sample $a$ in a batch we can select hardest positive and hardest negative samples. \n<center>$$ \\mathcal{L}_{BH} = \\sum_{i=1}^{P} \\sum_{a=1}^K [m + \\max_{p=1...K}D(x_a^i, x_p^i) - \\min_{j=1...P, n=1...K, j \\neq i}D(x_a^i, x_n^j)]$$<\/center>\n<br><\/br>\nThey also proposed an alternative to hard margin \\\\(m\\\\) (used to push out more negative examples), called soft margin and calculated as follows:\n<center>$$ln(1 + \\exp(hardest\\_positive - hardest\\_negative))$$<\/center>","2c4ff57c":"<img style=\"float: left; padding-right: 20px;\" src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/2\/26\/Precisionrecall.svg\/450px-Precisionrecall.svg.png\"\/>\n\n## Evaluation metrics\n\nThere are several evaluation metrics, that are usefull to measure model predictions. There are 4 possible outcomes of model prediction:\n* $TP$ - True Positives - is when model predicts that object is in a class it is tested agains, and object actually belongs to this class, \n* $TN$ - True Negatives - is when model predicts that object is not in a class it is tested agains, and object actually doesn't belong to this class,\n* $FP$ - False Positives - is when model predicts that object is in a class it is tested agains, but object actually belongs to different class,\n* $FN$ - False Negatives - is when model predicts that object is not in a class it is tested agains, but object actually belongs to this calss\n\nAccuracy - is most basic metric that measures ratio between all predictions that match actual state and all predictions\n\n$Acc = \\dfrac{TP + TN}{(TP + TN + FP + FN)}$,\n\nPrecision - measures ratio between True Positives and all positives predictions (True Positives and False Positives)\n\n$Prec = \\dfrac{TP}{TP + FP}$,\n\nRecall - measures ratio between True Positives and all actual positives (True Positives and False Negatives)\n\n$Rec = \\dfrac{TP}{TP + FN}$,\n\nF1 - is a mixture of Precision and Recall metrics, which treats both metrics evenly and penalize big differences between Precision and Recall\n\n$F_1 = 2 * \\dfrac{Prec * Rec}{Prec + Rec}$","feddc2c6":"### Utility methods\n\nBelow you can find some utility methods for printing batches of data, shuffling array and loading an image.","aad0b28d":"## Contrastive loss\n\nOne of first mention of Siamese Network was in [Learning a similarity metric discriminatively, with application to face verification S. Chopra et al](http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/chopra-05.pdf) paper. Contrastive loss function was used for training in it:\n\n<center>$$ \\mathcal{L}_{C} = \\sum_{i=1}^{P}(1-y^i)L_G(D(x_1^i, x_2^i)) + y^iL_I(D(x_1^i, x_2^i)) $$<\/center>\n<br><\/br>\nwhere:\n\n* $x_1^i, x_2^i$ is the i-th sample, \n* $L_G$ is partial loss function for a genuine pair, \n* $L_I$ is partial loss function for an imposter pair\n* $P$ is the numner of samples \n* $y^i$ is a binary label of i-th sample, which is equal 1 when $x_1^i$ and $x_2^i$ represents the same class, 0 otherwise\n","98e8ee33":"## Batch Hard Triplet Loss with Structured Classes (Labels)\n\nX. Zhang et al published in 2016 a paper called [Embedding Label Structures for Fine-Grained Feature Representation](https:\/\/webpages.uncc.edu\/~szhang16\/paper\/CVPR16_structured_labels.pdf), in which they presented approach to embed structured classes into triplet loss function. They distinguish two possibilities:\n* labels that are naturally grouped in a tree-like hierachy \n* labels that share common attributes\n\nIn first approach they proposed to organize images in quadruplet to model 2 level hierarchy. Each sample consits of four images:\n* $r_i$ - reference image in i-th sample\n* $p_i^+$ - positive image in i-th sample, representing the same leaf class as the reference image\n* $p_i^-$ - negative image in i-th sample, representing the same root class as the reference image\n* $n_i$ - negative image in i-th sample \n\nThe loss function looks as follows:\n\n<center>$$ \\mathcal{L}_{LH} = \\dfrac{1}{2N}\\sum_{i=1}^{N} max\\{0, D(r_i, p_i^+) - D(r_i, p_i^-) + m_1 - m_2\\} + \\dfrac{1}{2N}\\sum_{i=1}^{N} max\\{0, D(r_i, p_i^-) - D(r_i, n_i) + m_2\\}$$<\/center>\n<br><\/br>\n\nIn the second approach they proposed a way to manipulate margin using IoU (Intersection over Union) equation:\n<center>$$m = m_b(1 - \\dfrac{{A_p}\\cap{A_n}}{{A_p}\\cup{A_n}})$$<\/center>\nwhere:\n\n* $A_p$ is a positive example set of attributes\n* $A_n$ is a negative example set of attributes","93e4776c":"### Data Loading\n\nWe will load both data sets. Training dataset will be additionaly divided into 2 sets:\n* training (around 9\/10 of original training dataset)\n* development (around 1\/10 of original training dataset)\n\nSplit is made based on alphabets. So ****DEV**** dataset will contains 3 out of 30 available alphabets.","7be64b2f":"## Summary\n\nBoth siamese network architecture and triplet loss are also subject of research in other areas:\n\n* Object tracking:\n    * [Triplet Loss in Siamese Network for Object Tracking](https:\/\/openaccess.thecvf.com\/content_ECCV_2018\/papers\/Xingping_Dong_Triplet_Loss_with_ECCV_2018_paper.pdf)\n    * [Learning Dynamic Siamese Network for Visual Object Tracking](https:\/\/openaccess.thecvf.com\/content_ICCV_2017\/papers\/Guo_Learning_Dynamic_Siamese_ICCV_2017_paper.pdf)\n    * [A Twofold Siamese Network for Real-Time Object Tracking](https:\/\/openaccess.thecvf.com\/content_cvpr_2018\/papers\/He_A_Twofold_Siamese_CVPR_2018_paper.pdf)\n* Speach recognition:\n    * [Spoken Language Identification using LSTM-based Angular Proximity](ftp:\/\/tlp.limsi.fr\/public\/lid-is2017.pdf)\n    * [End-to-End Text-Independent Speaker Verification with Triplet Loss on Short Utterances](https:\/\/www.isca-speech.org\/archive\/Interspeech_2017\/pdfs\/1608.PDF)\n    * [Speech Emotion Recognition from Variable-Length Inputs with Triplet Loss Function](https:\/\/www.isca-speech.org\/archive\/Interspeech_2018\/pdfs\/1432.pdf)\n* Medical:\n    * [A TRIPLET-LOSS EMBEDDED DEEP REGRESSOR NETWORK FOR ESTIMATING BLOOD\nPRESSURE CHANGES USING PROSODIC FEATURES](https:\/\/www.researchgate.net\/profile\/Hao_Chun_Yang2\/publication\/327812834_A_Triplet-Loss_Embedded_Deep_Regressor_Network_for_Estimating_Blood_Pressure_Changes_Using_Prosodic_Features\/links\/5e5874164585152ce8f4b31b\/A-Triplet-Loss-Embedded-Deep-Regressor-Network-for-Estimating-Blood-Pressure-Changes-Using-Prosodic-Features.pdf)\n    ","374ac720":"## Siamese network\n\n<img src=\"https:\/\/camo.githubusercontent.com\/b27757e11d8687dc846b016e0fac80a544e7b645\/68747470733a2f2f736f72656e626f756d612e6769746875622e696f2f696d616765732f5369616d6573655f6469616772616d5f322e706e67\"><\/img>\n\nIdea of siamese network is to have 2 identical branches of convolutional network that have the same weights set on each filter respectively, this way both branches would produce the same output given the same example, plus during backpropagation, filters in both branches will be adjusted the same way.\n\nAs an output of each branch you will get two points in a space: $f(x_1)$, $f(x_2)$, then in last layer network will measure compatibility between $x_1$ and $x_2$, defined as:\n\n<center>$$D(x_1, x_2) = ||f(x_1) - f(x_2)||$$<\/center>\n<br><\/br>\n\nSiamese network behave properly, when following condition is met:\n\n<center>$\\exists~m > 0$, such that $D(x_1, x_2) + m < D(x_1, x_2')$, where:<\/center>\n\n* $x_1, x_2$ is a same class (\"genuine pair\")\n* $x_1, x_2'$ is not a same class (\"imposter pair\")","d871c1be":"## Omniglot Dataset\n\n<img src='https:\/\/github.com\/brendenlake\/omniglot\/blob\/master\/omniglot_grid.jpg?raw=true'><\/img>\n\nOmniglot data set consists of 50 different alphabets, that is splitted into 2 smaller sets:\n* Training data set consists of 30 alphabets 964 characters (19280 images)\n* Evaluation data set consists of 20 alphabets 659 characters (13180 images)\n\nImages have 105 pixels x 105 pixels x 3 channels shape\n\n### Citations\n1. Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332-1338.\n2. Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2019). The Omniglot Challenge: A 3-Year Progress Report. Preprint available on arXiv:1902.03477"}}