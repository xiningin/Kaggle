{"cell_type":{"d412e84e":"code","e9bdffb6":"code","fdf8dce1":"code","dc482f52":"code","b1611706":"code","49dd253f":"code","2099ccc5":"code","3c2cec2f":"code","23de6653":"code","0e671ab5":"code","05503a79":"code","8fda447c":"code","f6fa3420":"code","18f5cd91":"code","744a66ab":"code","3f579f5e":"code","35ebb45b":"code","6c8ccbf5":"code","038a4b0e":"code","24eebb00":"code","efe75688":"code","b23dc267":"code","c269bafa":"code","321f7c97":"code","6580bf01":"code","afc0327e":"code","0d3fa973":"code","eda5c3f5":"code","6089567e":"code","31ee54c2":"code","a5605ba2":"code","b8952e95":"code","aab24bb2":"code","d1da5865":"code","7522b3c4":"code","9cc1abba":"code","d3f449d5":"markdown","dfb33885":"markdown","a628fd5a":"markdown","09c181e1":"markdown","a6dd5167":"markdown","e678bee7":"markdown","8324a99d":"markdown","307ab704":"markdown","960783d8":"markdown","33f74dc5":"markdown","33ab8b0e":"markdown","ba35fd64":"markdown","c3955fa1":"markdown","55af2948":"markdown","62d67937":"markdown","233324df":"markdown","a8bba219":"markdown","7ebc6c65":"markdown","6faaf0a6":"markdown","2f4cf491":"markdown","484f481a":"markdown","dd5230ee":"markdown","1d97555c":"markdown","110d189c":"markdown","f59c1c00":"markdown","a115850d":"markdown","88818a1e":"markdown","bb6857b6":"markdown","ccec91ec":"markdown","37d8a298":"markdown","3c492254":"markdown"},"source":{"d412e84e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e9bdffb6":"import pandas as pd \nimport cv2                 \nimport numpy as np         \nimport os                  \nfrom random import shuffle\nfrom tqdm import tqdm  \nimport scipy\nimport skimage\nfrom skimage.transform import resize\nfrom PIL import Image\nimport sklearn","fdf8dce1":"print(os.listdir(\"\/kaggle\/input\/papsmeardatasets\/\"))\nHerlev = \"\/kaggle\/input\/papsmeardatasets\/herlev_pap_smear\/\"\nSipak = \"\/kaggle\/input\/papsmeardatasets\/sipakmed_fci_pap_smear\/\"","dc482f52":"Lista_H = os.listdir(Herlev)","b1611706":"def get_data(Dir):\n    X = []\n    y = []\n    \n    for dir_name in Dir:\n        for nextDir in os.listdir(dir_name):\n            if not nextDir.startswith('.'):\n                if nextDir.startswith('normal'):\n                    label = 0\n                elif nextDir.startswith('abnormal') or nextDir.startswith('benign'):\n                    label = 1\n                \n\n\n                temp = dir_name + nextDir\n\n                for file in tqdm(os.listdir(temp)):\n                    if not file.endswith('d.bmp') and not file.endswith('dat'):\n                        img = cv2.imread(temp + '\/' + file)\n                        if img is not None:\n                            img = skimage.transform.resize(img, (64,64,3))\n                            #img_file = scipy.misc.imresize(arr=img_file, size=(150, 150, 3))\n                            img = np.asarray(img)\n                            X.append(img)\n                            y.append(label)\n                    \n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y","49dd253f":"Lista = [Herlev, Sipak]","2099ccc5":"X_train, y_train = get_data(Lista)","3c2cec2f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt","23de6653":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15)","0e671ab5":"\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt","05503a79":"plt.plot(classifier.history.history['accuracy'])\nplt.plot(classifier.history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n#history1.history['val_loss']\n# Plot training & validation loss values\nplt.plot(classifier.history.history['loss'])\nplt.plot(classifier.history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","8fda447c":"#classifier.save('..\/input\/trenirana\/Cell_predict (1).h5')","f6fa3420":"new_model = tf.keras.models.load_model('..\/input\/trenirana\/Cell_predict (1).h5')","18f5cd91":"predictions = new_model.predict([X_test])","744a66ab":"niz = np.arange(0.0, 1.01, 0.01)","3f579f5e":"def zaok(a, x):\n    if a >= x:\n        return 1\n    else:\n        return 0","35ebb45b":"y_test[0] == np.rint(predictions[0])","6c8ccbf5":"TP = 0\nFP = 0\nTN = 0\nFN = 0\nfor (i, j) in zip (y_test, predictions):\n    if i == 0:\n        if i == np.rint(j):\n            TN += 1\n        else:\n            FP += 1\n    elif i == 1:\n        if i == np.rint(j):\n            TP += 1\n        else:\n            FN += 1\n     \n            ","038a4b0e":"print(TP, FP, TN, FN)","24eebb00":"def prec(TP,FP):\n    return TP\/(TP+FP)\ndef rec(TP, FN):\n    return TP\/(TP+FN)","efe75688":"precision = []\nrecall = []\npom_pred = []\n\nfor k in niz:\n    TP_1 = 0\n    FP_1 = 0\n    TN_1 = 0\n    FN_1 = 0\n    for (i, j) in zip (y_test, predictions):\n        if i == 0:\n            if i == zaok(j, k):\n                TN_1 += 1\n            else:\n                FP_1 += 1\n        elif i == 1:\n            if i == zaok(j, k):\n                TP_1 += 1\n            else:\n                FN_1 += 1\n    precision.append(prec(TP_1,FP_1))\n    recall.append(rec(TP_1,FN_1))\n    \n    \n    ","b23dc267":"brojac = 0\n\nfor (i, j) in zip (y_test, predictions):\n    if i != np.rint(j):\n        brojac += 1\n    ","c269bafa":"accu = 1 - brojac\/len(y_test)","321f7c97":"print('Accuracy je:', accu)","6580bf01":"Rec_ = TP\/(FN+TP)","afc0327e":"print(Rec_)","0d3fa973":"Pre_ = TP\/(FP+TP)","eda5c3f5":"print(Pre_)","6089567e":"plt.plot(recall, precision)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.annotate('Najbolji Recall i precision', xy=(Rec_, Pre_), xytext=(1, 1.1),\n            arrowprops=dict(facecolor='black', shrink=0.002),\n            )","31ee54c2":"arr = np.rint(predictions)","a5605ba2":"cm = sklearn.metrics.confusion_matrix(y_test,arr)","b8952e95":"from sklearn.metrics import plot_confusion_matrix","aab24bb2":"cm","d1da5865":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncn = sns.light_palette(\"blue\", as_cmap=True)\nx=pd.DataFrame(cm)\nx=x.style.background_gradient(cmap=cn)\ndisplay(x)","7522b3c4":"%matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n","9cc1abba":"plt.imshow(cm, interpolation='nearest', cmap=cn)\nplt.title(\"Matrica konfuzije\")\nplt.colorbar()\ntick_marks = np.arange(2)\nplt.xticks(tick_marks, ['Negative', 'Positive'], rotation=45)\nplt.yticks(tick_marks, ['P', 'N'])\n\n#if normalize:\n#    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n#    print(\"Normalized confusion matrix\")\n#else:\n#    print('Confusion matrix, without normalization')\n\n#print(cm)\n\nthresh = cm.max() \/ 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n        horizontalalignment=\"center\",\n        color=\"white\" if cm[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","d3f449d5":"Na slici dolje se mo\u017ee vidjeti kako mre\u017ea izgleda po slojevima. ","dfb33885":"Import-anje svega \u0161to \u0107e nam trebati za izradu modela, te matplot.pyplot za crtanje grafova.\n\n","a628fd5a":"Precision","09c181e1":"Ispod je CNN za binarnu klasifikaciju (napravljen originalno za klasifikaciju ma\u010daka i pasa, malo prilago\u0111en) ","a6dd5167":"Na trening setu od 3798 slika i validacijskom setu od 423 uvje\u017eban je CNN. ","e678bee7":"# Prou\u010davanje predikcije za test set od 745 slika","8324a99d":"classifier = Sequential()\n\n# Step 1 - Convolution\nclassifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Conv2D(64, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a third convolutional layer\nclassifier.add(Conv2D(128, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a fourth convolutional layer\nclassifier.add(Conv2D(128, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dropout(0.4))\nclassifier.add(Dense(units = 64, activation = 'relu'))\nclassifier.add(Dense(units = 1, activation = 'sigmoid'))\n\n# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics =[\"accuracy\",tf.keras.metrics.Recall(\n    thresholds=None, top_k=None, class_id=None, name=None, dtype=None\n)])\n#metrics =[ tf.keras.metrics.Recall()]\nplot_model(classifier, to_file='cnn_model.png', show_shapes=True, show_layer_names=True)\ndisplay(Image.open('cnn_model.png'))\n","307ab704":"## Grafovi ","960783d8":"# Pristup datasetu","33f74dc5":"## Prebrojavanje TP, TN, FP, FN","33ab8b0e":"Resizeanje slika na 64 x 64 za CNN.\nDavanje labela ( abnormalna = 1, normalna = 0).\nVra\u0107a listu slika i labela.","ba35fd64":"\n\nclassifier.fit(X_train, y_train,validation_split = 0.1,  epochs=20)","c3955fa1":"Mijenjamo \"odlu\u010duju\u0107u\" vrijednost za odre\u0111ivanje klase stanice.","55af2948":"Za metriku se koristi Accuracy (osnovna metrika)  i Recall jer nas zanima koliko imamo FN rezultata, koje \u017eelimo izbje\u0107i. ","62d67937":"Recall","233324df":"### Accuracy\n","a8bba219":"print(classifier.history.history.keys())","7ebc6c65":"Na prvom grafu je prikazana usporedba accuracya na trening i validacijskom setu kroz epohe. \nNa drugom grafu je prikazana vrijednost loss funkcije kroz epohe na trening i validacijskom setu.","6faaf0a6":"Pomo\u0107ni niz za precision i recall graf","2f4cf491":"Funkcije za ra\u010dunanje precisiona i recalla.","484f481a":"Graf: Precision i recall, u ovisnosti o \"decision\" funkciji.","dd5230ee":"arr je niz predvi\u0111anja za testni set (niz nula i jedinica) ","1d97555c":"Dijelimo dataset na trening i test. 85% dataseta koristimo za model, 15% za testiranje.","110d189c":"## Matrica konfuzije ve\u0107a\n","f59c1c00":"# Matrica konfuzije","a115850d":"Treniranje mre\u017ee, 20 epoha, 10% se koristi za validaciju.","88818a1e":"Predvi\u0111anje na testnom setu.","bb6857b6":"pomo\u0107na funkcija za precision i recall graf","ccec91ec":"Postavljamo X_train na sve slike, y_train sve labele.","37d8a298":"## nizovi precision i recall za graf ","3c492254":"### Broj pogre\u0161nih predikcija"}}