{"cell_type":{"b36b4adc":"code","664cb275":"code","ad36ae0a":"code","5dfb4e5b":"code","f0f9a7c2":"markdown","6815ec43":"markdown","746dc149":"markdown","c8dcdcc5":"markdown","6028dbcc":"markdown","cf702c0a":"markdown"},"source":{"b36b4adc":"import numpy as np\nfrom skimage.measure import label, regionprops\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    \"\"\"\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    \"\"\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape((shape[1], shape[0])).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list, all_masks=None, shape=(256, 1600)):\n    \n    # Take the individual masks and create a single mask array\n    if all_masks is None:\n        all_masks = np.zeros(shape, dtype = np.int16)\n    #if isinstance(in_mask_list, list):\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask, shape)\n    return np.expand_dims(all_masks, -1)\n\ndef get_bboxes_from_rle(encoded_pixels, return_mask=False):\n    \"\"\"get all bboxes from a whole mask label\"\"\"\n    \n    mask = masks_as_image([encoded_pixels])\n    lbl = label(mask) \n    \n    props = regionprops(lbl)\n\n    #get bboxes by a for loop\n    bboxes = []\n    for prop in props:\n        bboxes.append([prop.bbox[1], prop.bbox[0], prop.bbox[4], prop.bbox[3]])\n\n    if return_mask:\n        return bboxes, mask \n    return bboxes","664cb275":"import cv2\nimport pandas as pd\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\nann_file_path = '..\/input\/severstal-steel-defect-detection\/train.csv'\ntrain_image_dir = '..\/input\/severstal-steel-defect-detection\/train_images\/'\nimages = ['0002cc93b.jpg', '0007a71bf.jpg', '000789191.jpg'] # some images for test\n\nann_csv = pd.read_csv(ann_file_path)\n\nfor image in images:\n\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5))\n    img_0 = cv2.imread(train_image_dir+'\/' + image)\n    img_1 = img_0.copy()\n    print ('Image', image)\n    \n    # a loop of 4 classes\n    for i in range(4):\n        rle_0 = ann_csv.query('ImageId_ClassId==\"'+image+'_'+str(i+1)+'\"')['EncodedPixels'].values[0]\n        if isinstance(rle_0, str)!=True and i!=0:\n            continue\n        bboxes, mask_0 = get_bboxes_from_rle(rle_0, True)\n    \n        if i == 0:\n            color = (255, 0, 0)                \n        elif i == 1:\n            color = (0, 255, 0)\n        elif i == 2:\n            color = (0, 0, 255)\n        else:\n            color = (0, 0, 0)\n\n        for bbox in bboxes:\n            print('Found bbox', bbox)\n            cv2.rectangle(img_1, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color,5)\n             \n    ax1.imshow(img_0)\n    ax1.set_title('Image')\n    ax2.set_title('Mask')\n    ax3.set_title('Image with derived bounding box')\n    ax2.imshow(mask_0[...,0], cmap='gray')\n    ax3.imshow(img_1)\n    plt.show()","ad36ae0a":"import pandas as pd\nimport pickle\nfrom tqdm import tqdm\n\nIds = ann_csv.loc[:, 'ImageId_ClassId'].values\nlabel_category = 4\n\noutput = []\nfor i in tqdm(range(len(Ids)\/\/label_category)):\n    # generate anns of all samples into a json file\n    \n    masks = []\n    bboxes = []\n    labels = []\n    \n    for j in range(label_category):\n        encoded_pixels = ann_csv.loc[i+j:i+j+1, 'EncodedPixels'].values[0]\n        current_bboxes = get_bboxes_from_rle(encoded_pixels)\n        current_labels = list(np.ones([len(current_bboxes)]) * (j+1))\n        \n        bboxes.extend(current_bboxes)\n        labels.extend(current_labels)\n        masks.append({\n            u'counts':encoded_pixels,\n            u'size':[256, 1600]\n        })\n        \n    bboxes = np.array(bboxes)\n    labels = np.array(labels, dtype=int)\n    masks = np.array(masks)\n    \n    dict0 = {\n        'filename': Ids[i][:-2],\n        'width': 1600,\n        'height': 256,\n        'ann': \n        {\n            'bboxes': bboxes, # shape is (sample_num, bbox_num)\n            'labels': labels, # shape is (sample_num, bbox_num)\n            'masks': masks  # shape is (sample_num, 4)\n        }\n        }\n    output.append(dict0)\n\n# save output as a pickle file\nwith open('train_anns.pkl', 'wb') as f:\n    pickle.dump(output, f)","5dfb4e5b":"# load the file\nwith open(\"train_anns.pkl\", \"rb\") as f:\n    anns = pickle.load(f)\n\n# print some labels    \nprint('frist label:')\nprint(anns[0])\nprint('')\nprint('second label:')\nprint(anns[1])\nprint('')\nprint('third label:')\nprint(anns[2])","f0f9a7c2":"Frist, write some useful functions according to https:\/\/www.kaggle.com\/voglinio\/from-masks-to-bounding-boxes.","6815ec43":"Let check the output file.","746dc149":"Let's see the effect!","c8dcdcc5":"Now generate a json file of all samples. Note that the format of the json file is based on mmdetection's coco dataset (https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/mmdet\/datasets\/coco.py) but has different 'masks' fields, because in mmdetection a 'masks' field corresponds to masks of objects, but here is a sematic task. \nNote that output is a list of dictionaries with the following format:\n{\n    'filename'.\n    'width',\n    'height', \n    'ann': \n    {\n        'bboxes',\n        'labels',\n        'masks'\n    }\n}","6028dbcc":"Hello every one! At the beginning, I planned to try mmdetection's Hybrid Task Cascade (https:\/\/github.com\/open-mmlab\/mmdetection\/tree\/master\/configs\/htc) for this task. Though it's probably not a good idea, but I hope bboxes can help. I implemented code from Costas Voglis'nice kernel https:\/\/www.kaggle.com\/voglinio\/from-masks-to-bounding-boxes on this dataset to get bbox labels. ","cf702c0a":"Please feel free to give suggestions, I hope this can help, thank you! :)"}}