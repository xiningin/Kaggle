{"cell_type":{"4cb64dc5":"code","5640bce7":"code","e2ca9ad9":"code","215b6654":"code","4dfafb0b":"code","a29d234f":"code","fe3e30a2":"code","8be87030":"code","2610332b":"markdown","df30f433":"markdown","85bc580d":"markdown","96134a39":"markdown","1d83c7e2":"markdown","ca4e5353":"markdown","7898aa66":"markdown","27194c24":"markdown","3c4e8366":"markdown"},"source":{"4cb64dc5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5640bce7":"log4shell_tweets_df = pd.read_csv('\/kaggle\/input\/log4shell-tweets\/log4shell_tweets.csv',\n                                  parse_dates=['status_date', 'user_created_date'])\nlog4shell_tweets_df.head()","e2ca9ad9":"tweets_per_hour = log4shell_tweets_df.resample('H', on='status_date')['status_id'].count()\n\nax = tweets_per_hour.plot(figsize=(16,8), rot=45, x_compat=True,\n                          title='Log4J + Log4Shell Tweets per Hour')\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Tweets per hour\")","215b6654":"# Filter sources that were used more than 250 times\nsources = log4shell_tweets_df['source'].value_counts().loc[lambda x : x>250].sort_values()\nsources.plot.barh(figsize=(12,6), title=\"Most Common Sources for Log4Shell Tweets\")","4dfafb0b":"most_retweeted = log4shell_tweets_df.nlargest(5, 'retweet_count')[['user_name', 'text', 'retweet_count']]\nfor index, data in most_retweeted.iterrows():\n    print('User name:', data.user_name)\n    print('Retweet count:', data.retweet_count)\n    print(data.text)\n    print()","a29d234f":"most_favorited = log4shell_tweets_df.nlargest(5, 'favourite_count')[['user_name', 'text', 'favourite_count']]\nfor index, data in most_favorited.iterrows():\n    print('User name:', data.user_name)\n    print('Favorite count:', data.favourite_count)\n    print(data.text)\n    print()","fe3e30a2":"log4shell_tweets_df.plot.scatter(x='retweet_count', y='favourite_count',\n                                figsize=(12,6), title='Favorite count vs. Retweet count')","8be87030":"log4shell_tweets_df['retweet_count'].corr(log4shell_tweets_df['favourite_count'])","2610332b":"### Plot retweet count vs. favorite count\n\nThe results from the previous two sections look like the same tweets in a different order. Let's see how strong the correlation is overall between retweets and favorites. (I expect it to be pretty strong.)","df30f433":"### Load Data","85bc580d":"### What were the most-favorited Log4Shell statuses?","96134a39":"### What are the most common sources of Log4Shell tweets?","1d83c7e2":"That looks like a positive correlation, but let's put a number on it.","ca4e5353":"### What were the most-retweeted Log4Shell statuses?","7898aa66":"### Plot the number of Log4Shell tweets per hour\n\nUse the `resample` method to get a count of the tweets in each hour of the data set.","27194c24":"As expected, the more exposure a tweet receives through retweets, the more favorites (likes) it will also receive. This probably generalizes beyond this data set.","3c4e8366":"The first mentions of Log4Shell came just before midnight on Thursday, December 9th. Interest ramped up quickly that Friday, and only subsided somewhat over the weekend. It picked up again on Monday, December 13, and reached a peak of around 700 tweets per hour. This level of activity was sustained for the next two days, but has declined steadily since."}}