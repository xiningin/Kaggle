{"cell_type":{"b2b79fa2":"code","f34dc6b8":"code","c4c4d40a":"markdown"},"source":{"b2b79fa2":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport json\nimport sys\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom glob import glob \n\n\nimport matplotlib.pyplot as plt\n\n\ndef run (fold):\n\n    train_data = f\"{INPUT_PATH}\/{fold}\/data\/train\" \n    valid_data = f\"{INPUT_PATH}\/{fold}\/data\/val\"\n    test_data = f\"{INPUT_PATH}\/{fold}\/data\/test\" \n\n\n\n    train_files = glob(train_data +\"\/**\/*.png\", recursive=True)\n    valid_files = glob(valid_data +\"\/**\/*.png\", recursive=True)\n    test_files = glob(test_data +\"\/**\/*.png\", recursive=True)\n\n\n    print(f\"train_files:{len(train_files)}, valid_files:{len(valid_files)}, test_files:{len(test_files)}\")\n\n    tf.random.set_seed(123)\n    batch_size = 8\n\n    train = tf.keras.preprocessing.image_dataset_from_directory(\n        train_data ,\n        labels=\"inferred\",\n        label_mode=\"categorical\",\n        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n        shuffle=True,\n        seed=123,\n        batch_size=batch_size,\n        image_size=(32, 32),\n    )\n\n    valid = tf.keras.preprocessing.image_dataset_from_directory(\n        valid_data ,\n        labels=\"inferred\",\n        label_mode=\"categorical\",\n        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n        shuffle=True,\n        seed=123,\n        batch_size=batch_size,\n        image_size=(32, 32),\n    )\n\n    print (\"cardinaly:\", (train.cardinality()* batch_size).numpy(), (valid.cardinality()* batch_size).numpy() )\n\n    total_length = ((train.cardinality() + valid.cardinality()) * batch_size).numpy()\n    if total_length > 10_000:\n        print(f\"Dataset size larger than 10,000. Got {total_length} examples\")\n        sys.exit()\n\n    test = tf.keras.preprocessing.image_dataset_from_directory(\n        test_data,\n        labels=\"inferred\",\n        label_mode=\"categorical\",\n        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n        shuffle=False,\n        seed=123,\n        batch_size=batch_size,\n        image_size=(32, 32),\n    )\n\n    base_model = tf.keras.applications.ResNet50(\n        input_shape=(32, 32, 3),\n        include_top=False,\n        weights=None,\n    )\n    base_model = tf.keras.Model(\n        base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\n    )\n\n    inputs = tf.keras.Input(shape=(32, 32, 3))\n    x = tf.keras.applications.resnet.preprocess_input(inputs)\n    x = base_model(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(10)(x)\n    model = tf.keras.Model(inputs, x)\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n        metrics=[\"accuracy\"],\n    )\n    model.summary()\n    loss_0, acc_0 = model.evaluate(valid)\n    print(f\"loss {loss_0}, acc {acc_0}\")\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        \"best_model\",\n        monitor=\"val_accuracy\",\n        mode=\"max\",\n        save_best_only=True,\n        save_weights_only=True,\n    )\n\n    history = model.fit(\n        train,\n        validation_data=valid,\n        epochs=EPOCHS,\n        callbacks=[checkpoint],\n    )\n\n    model.load_weights(\"best_model\")\n\n    loss, acc = model.evaluate(valid)\n    best_epoch = np.argmax(history.history['val_accuracy'])\n    print(f\"FOLD:{fold} final loss:{loss:.5f}, final acc:{acc:.5f}, epoch:{best_epoch}\")\n\n\n    plt.figure(figsize=(15,5))\n    plt.plot(np.arange(EPOCHS),history.history['loss'],'.',label='Train loss',color='orange')\n    plt.plot(np.arange(EPOCHS),history.history['val_loss'],'.',label='Val loss',color='blue')\n    plt.legend(loc=2)\n    plt2 = plt.gca().twinx()\n    plt2.plot(np.arange(EPOCHS),history.history['accuracy'],'-o',label='Train acc',color='gray')\n    plt2.plot(np.arange(EPOCHS),history.history['val_accuracy'],'-o',label='Val acc',color='black')\n    plt.legend(loc=3)\n    plt.show()          \n\n\n    test_loss, test_acc = model.evaluate(test)\n    print(f\"FOLD:{fold} test loss:{test_loss:.5f}, test acc:{test_acc:.5f}\")\n\n    predictions = model.predict(test)\n    names = [x.split(\"\/\")[-1] for x in test.file_paths]\n    labels= [x.split(\"\/\")[-2] for x in test.file_paths]\n    pred = np.argmax(predictions, axis=1)\n\n    class_names = test.class_names\n    df = pd.DataFrame ({\n     \"name\":names,\n     \"label\":labels,\n     \"pred\":pred   \n    })\n    for i in range(10):\n        df[f\"prob_{i}\"]=predictions[:,i]\n\n    df[\"pred\"] = df[\"pred\"].map(lambda x: class_names [x])     \n    df.to_csv(f\"test_{fold}.csv\", index=False)\n\n    accuracy = accuracy_score(df[\"label\"],df[\"pred\"])\n    print(f\"fold:{fold} test accuracy: {accuracy:.5f}\")\n\nEPOCHS = 100\nINPUT_PATH = \"..\/input\/dcai-data-denoised-s2-train-5mlc-ext2-aug4\"\n\n\n\nfor fold in [0]:\n    run(fold)\n\n","f34dc6b8":"!ls -lart","c4c4d40a":"https:\/\/worksheets.codalab.org\/worksheets\/0x7a8721f11e61436e93ac8f76da83f0e6"}}