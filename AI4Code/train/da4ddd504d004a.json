{"cell_type":{"1583e747":"code","6d2f4411":"code","65c38380":"code","13eeb2f0":"code","85ba993f":"code","e6bd0474":"code","9ee6bc6e":"code","9a2a975b":"code","3db6f1c9":"code","912b656c":"code","03a69193":"code","50a438d7":"code","53bce3c7":"code","13850ca7":"code","bfef4e7a":"code","aa311b57":"code","7086cbb2":"code","bf7060a3":"code","dc828522":"code","e68596bb":"code","f7d44149":"code","ff51fcd3":"code","dafa2d0f":"code","2c7b23e1":"markdown","fb711f4b":"markdown","c4bf7536":"markdown","586efb17":"markdown","5d159f52":"markdown","f683bbe3":"markdown","02d41610":"markdown","d8cb580b":"markdown","8c8a1d9b":"markdown","2ed4f449":"markdown","5910e599":"markdown","37035db7":"markdown","06340800":"markdown","99bb5165":"markdown","682b8d79":"markdown","e378f366":"markdown","e27d281d":"markdown","2e401c10":"markdown","e1dc87b2":"markdown","9ac54fda":"markdown","e8ca06cc":"markdown","524a0c36":"markdown","affb52b8":"markdown"},"source":{"1583e747":"!pip install dfply\n!pip install plotly\n\nimport pprint\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport pandas as pd\nimport numpy as np\nfrom dfply import *\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nfrom sklearn.model_selection import *\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import *\nfrom sklearn.ensemble import *\nfrom sklearn.neural_network import *\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.preprocessing import *\nfrom sklearn.inspection import PartialDependenceDisplay, plot_partial_dependence\n\nfrom eli5.sklearn import  PermutationImportance\nfrom eli5 import show_weights\n\nplt.style.use('fivethirtyeight')\nplot_templ = \"seaborn\"\nplot_width_small = 600\nplpt_width_normal = 800\nclr_conti = px.colors.diverging.RdYlGn\nclr_conti_r = px.colors.diverging.RdYlGn_r\nclr_discrete = px.colors.qualitative.Set1\nclr_discrete_r = px.colors.qualitative.Set1_r\n\npp = pprint.PrettyPrinter(indent=4)","6d2f4411":"shoppers_data = pd.read_csv('..\/input\/online-shoppers-intention\/online_shoppers_intention.csv')\nshoppers_data.sample(10)","65c38380":"shoppers_data.info()","13eeb2f0":"shoppers_data.isnull().sum()","85ba993f":"print(\"Total number of duplicate rows: \", shoppers_data.duplicated().sum())","e6bd0474":"shoppers_data.drop_duplicates(inplace=True)","9ee6bc6e":"print(\"Total number of duplicate rows: \", shoppers_data.duplicated().sum())","9a2a975b":"shoppers_data.describe()","3db6f1c9":"shoppers_data.OperatingSystems = shoppers_data.OperatingSystems.astype(str)\nshoppers_data.Browser = shoppers_data.Browser.astype(str)\nshoppers_data.Region = shoppers_data.Region.astype(str)\nshoppers_data.TrafficType = shoppers_data.TrafficType.astype(str)\nprint(\"Columns converted to string\")","912b656c":"vis_data = (\n    shoppers_data >>\n    group_by(X.Revenue) >>\n    summarise(Count = n(X.Revenue))\n)\nvis_data[\"Proportion %\"] = (vis_data.Count \/ vis_data.Count.sum()) * 100\n\nfig = px.bar(\n    vis_data,\n    x='Revenue', \n    y='Proportion %',\n    color='Revenue',\n    template=plot_templ,\n)\nfig.update_layout(\n    title_text = \"Proportion of Revenue Result  - Online Shoppers\",   \n    showlegend=False,\n    width=600,\n    height=500)\nfig.show()","03a69193":"corr_data = shoppers_data.corr()\ncorr_data = corr_data.round(2)\n\ndata = corr_data.fillna(0).to_numpy().tolist()\nxvals = corr_data.index.values.tolist()\nyvals = corr_data.columns.to_list()\n\nfig = ff.create_annotated_heatmap(\n    data, \n    x=xvals, \n    y=yvals, \n    annotation_text=data,\n    colorscale=\"RdBU\")\nfig.update_xaxes(side=\"bottom\")    \nfig.update_layout(\n    title_text = \"Correlation Matrix - Online Shoppers\",\n    template=plot_templ,\n    width=1000,\n    height=600)\nfig.show()","50a438d7":"fig = make_subplots(rows=1, cols=3)\nfig.append_trace(\n    go.Box(\n        x=shoppers_data.Revenue,\n        y=shoppers_data.PageValues        \n    ), row=1, col=1\n)\nfig.append_trace(\n    go.Box(\n        x=shoppers_data.Revenue,\n        y=shoppers_data.ExitRates                \n    ), row=1, col=2\n)\nfig.append_trace(\n    go.Box(\n        x=shoppers_data.Revenue,\n        y=shoppers_data.BounceRates                \n    ), row=1, col=3\n)\nfig.update_xaxes(title_text=\"Revenue\")\nfig.update_yaxes(title_text=\"PageValues\", row=1, col=1)\nfig.update_yaxes(title_text=\"ExitRates\", row=1, col=2)\nfig.update_yaxes(title_text=\"BounceRates\", row=1, col=3)\nfig.update_layout(\n    title_text = \"Web analytics - Online Shoppers\",\n    template=plot_templ,\n    showlegend=False,\n    width=1200,\n    height=500)\nfig.show()","53bce3c7":"rev_values = shoppers_data.Revenue.unique()\ncol_map = {\n    \"1\": \"steelblue\",\n    \"2\": \"darkorange\"\n}\nfig = make_subplots(rows=1, cols=2)\n\nfor rev in rev_values:\n    col = \"1\" if rev == True else \"2\"\n    vis_data = shoppers_data[shoppers_data[\"Revenue\"] == rev]\n    fig.add_trace(\n        go.Scatter(\n            x=vis_data.ProductRelated,\n            y=vis_data.ProductRelated_Duration,\n            mode=\"markers\",\n            marker_color=col_map[col], \n            legendgroup=f\"group{col}\",\n            name=f\"Revenue - {rev}\",\n            showlegend=True\n        ), row=1, col=1\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=vis_data.Administrative,\n            y=vis_data.Administrative_Duration,\n            mode=\"markers\",\n            marker_color=col_map[col],\n            legendgroup=f\"group{col}\",\n            name=f\"Revenue - {rev}\",  \n            showlegend=False                                         \n        ), row=1, col=2\n    )\nfig.update_xaxes(title_text=\"ProductRelated\", row=1, col=1)\nfig.update_xaxes(title_text=\"Administrative\", row=1, col=2)\nfig.update_yaxes(title_text=\"ProductRelated_Duration\", row=1, col=1)\nfig.update_yaxes(title_text=\"Administrative_Duration\", row=1, col=2)\nfig.update_layout(\n    legend_traceorder=\"reversed\",\n    title_text = \"Types of Pages - Online Shoppers\",\n    template = plot_templ,\n    width=1200,\n    height=500)\nfig.show()","13850ca7":"# Encoding revenue and weekend\nshoppers_data.Revenue = shoppers_data.Revenue.apply(lambda x: 1 if x == True else 0)\nshoppers_data.Weekend = shoppers_data.Weekend.apply(lambda x: 1 if x == True else 0)\nprint(\"Encoding revenue and weekend complete\")\n\n# Encoding categorical attributes\ncat_attributes = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType']\nencoder = OneHotEncoder(handle_unknown='ignore')\ntrans = encoder.fit_transform(shoppers_data.loc[:, cat_attributes].values)\nenc_data = pd.DataFrame(\n    trans.toarray(), \n    index=shoppers_data.index.values,\n    columns=encoder.get_feature_names(cat_attributes))\nprep_data = pd.merge(shoppers_data, enc_data, left_index=True, right_index=True)\nprep_data.drop(columns=cat_attributes, inplace=True)\nprint(\"Encoding categorical attributes complete\")\n\n# Normalize numeric attributes\nfeatures = (prep_data >> select(~X.Revenue))\nmm_scaler = MinMaxScaler()\nfeatures = mm_scaler.fit_transform(features)\nprint(\"Normalize numeric attributes complete\")\n\n\n# Train and test split\ntarget = prep_data['Revenue']\ntest_size=0.2\nx_train, x_test, y_train, y_test = train_test_split(\n    features, target, test_size=test_size, shuffle=True, random_state=1, stratify=target) \nprint(f\"Train and test data with dim: {x_train.shape} and {x_test.shape} complete\")    ","bfef4e7a":"def frame_report(actual, predicted, labels=[1,0], names=[\"True\", \"False\"]):\n    report = classification_report(\n        actual, \n        predicted, \n        labels=labels, \n        target_names=names, \n        output_dict=True)\n    df_report = pd.DataFrame.from_dict(report).transpose()\n    style = df_report.style.set_caption('<b>Classification Report<\/b>').background_gradient(\n        cmap='viridis', subset=pd.IndexSlice['True':'False', :'f1-score']) \n    return style    \n\ndef frame_matrix(actual, predicted, cols=[\"False\", \"True\"]):\n    cm = confusion_matrix(actual, predicted)\n    frame = pd.DataFrame(cm, index=cols, columns=cols)    \n    style = frame.style.set_caption('<b>Confusion Matrix<b\/>').background_gradient(cmap='viridis') \n    return style","aa311b57":"# Logistic Regression Model\nmodel = LogisticRegression(solver=\"liblinear\")\nmodel.fit(x_train, y_train)\npredicted = model.predict(x_test)\nframe_report(y_test, predicted)\n","7086cbb2":"print(\"Basline model ROC AUC score: \", roc_auc_score(y_test, predicted))","bf7060a3":"params_space = {   \n    'criterion': 'entropy',\n    'max_depth': 16,\n    'max_features': 'auto',\n    'min_samples_leaf': 10,\n    'min_samples_split': 5,\n    'n_estimators': 35\n}\nselect_clf = RandomForestClassifier(random_state=5)\nselect_clf.set_params(**params_space)\nfeat_selector = SelectFromModel(select_clf)\nfeat_selector.fit(x_train, y_train)\nfeats = feat_selector.transform(x_train)","dc828522":"params_space = {\n    'activation': 'relu',\n    'alpha': 0.0001,\n    'early_stopping': True,\n    'hidden_layer_sizes': (16, 128, 16),\n    'learning_rate_init': 0.001,\n    'max_iter': 1000,\n    'random_state': 2,\n    'solver': 'adam' \n}\nmodel = MLPClassifier(random_state=5)\nmodel.set_params(**params_space)\nmodel.fit(feats, y_train)\npredicted = model.predict(feat_selector.transform(x_test))\nframe_report(y_test, predicted)\n","e68596bb":"print(\"Multilayer Perceptron model ROC AUC score: \", roc_auc_score(y_test, predicted))","f7d44149":"frame_matrix(y_test, predicted)","ff51fcd3":"idx = feat_selector.get_support()\ncols = (prep_data >> select(~X.Revenue)).columns[idx]\nperm = PermutationImportance(model, random_state=1).fit(feat_selector.transform(x_test), y_test)\nshow_weights(perm, feature_names = cols.tolist())","dafa2d0f":"fig = figure()\ntest_feats = feat_selector.transform(x_test)\ndisp = plot_partial_dependence(model, test_feats, [6])\nplt.xlabel('PageValues', fontsize=18)\nplt.ylabel('Prediction', fontsize=16)","2c7b23e1":"The table output above is the list of attributes (in order of importance) that were used to train the Multilayer Perceptron classifier. Feature selection determined that they would be the most useful attributes for the Multilayer Perceptron classifier.\n\n**What feature values impact the classifier?**","fb711f4b":"## 2.1 Load and inspect","c4bf7536":"## 2.4 Summary of numeric columns","586efb17":"Some basic explorations will be performed on the online shoppers data to determine the quality of the data:\n\n- the first few rows\n- the number of rows and columns\n- the column information\n- a summary of the numeric columns\n- duplicates and missing values\n- checking for outliers","5d159f52":"# 1. Introduction\n\nE-commerce is a very large business sector which gives shoppers access to a large variety of goods and services with a few clicks. Many popular shopping platforms such as Amazon or Alibaba process millions of transactions every year. The online shopping market is very competitive and it is important for online shopping platforms to be robust and innovative. A possible way to increase online shopping transactions is understanding and responding to the behavior of online shoppers. Given enough online shopping data and machine learning techniques, it is possible to determine the shopping intent of website visitors.\n\n# 2. Data Understanding\n\n> **Citation**: The data used in this notebook was downloaded:\n>\n> Sakar, C. & Kastro, Yomi. (2018). Online Shoppers Purchasing Intention Dataset. UCI Machine Learning Repository.\n>\n> It can be downloaded from the UCI dataset repository (Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository]([http:\/\/archive.ics.uci.edu\/ml). Irvine, CA: University of California, School of Information and Computer Science). \n\nThe dataset consists of 10 numerical and 8 categorical attributes.\n\n- **Administrative** - count of pages visited by the visitor (e.g. user details and account)\n- **Administrative_Duration**\t- total time spent (seconds) in on Administrative type of page\n- **Informational** - count of pages visited by the visitor (e.g. about and contact of the website)\t\n- **Informational_Duration** - total time spent (seconds) in on Informational type of page\n- **ProductRelated** - count of pages visited by the visitor (e.g. product details)\n- **ProductRelated_Duration**\t- total time spent (seconds) in on ProductRelated type of page\n- **BounceRates**\t- percentage of visitors who enter the site from that page and then leave (\"bounce\") without triggering any other requests to the analytics server\n- **ExitRates** -\tthe percentage of visitors to a page on the website from which they exit the website to a different website\n- **PageValues** - the average value for a page that a user visited before landing on the goal page\n- **SpecialDay** - indicates the closeness of the site visiting time to a specific special day (e.g. Mother\u2019s Day, Valentine's Day)\n- **Month** - the month of the visit to the website\t\n- **OperatingSystems** - the type of operation system used by the visitor\t\n- **Browser**\t- the type of browser used by the visitor\n- **Region** - the geographic region from which the session started\n- **TrafficType**\t- describes how traffic arrived on the website (Direct, Organic, Referral, Social, Email, Display and Paid)\n- **VisitorType**\t- returning or new visitor or other\n- **Weekend**\t- indicating whether the date of the visit is weekend\n- **Revenue** - indicates whether the visitor made a purchase or not","f683bbe3":"The correlation plot shows ~ 6 attributes have decent correlation (relative to the data) with the target Revenue:\n\n- PageValues\n- ExitRates\n- ProductRelated\n- ProductRelated_Duration\n- BounceRates\n- Administrative","02d41610":"## 2.3 Missing and duplicate data","d8cb580b":"Notes:\n- Some have suspicously large values e.g. ProductRelated_Duration\n- Large values could be because of web crawlers or browser was not closed by user\n\n**Modifications:**\n- Some of the categorical columns are currently stored as int and need to be converted to string","8c8a1d9b":"Notes:\n- Columns match description of the data set\n- Some numeric columns and categorical columns (as per data set description)\n- Preliminary check reveals no obvious missing or duplicate rows","2ed4f449":"## 2.2 Column and row level details","5910e599":"# 5. Conclusion\n\nThe aim of this notebook was to develop classifier that could predict the purchasing intentions of website visitors. A baseline Logistic Regression classifier was implemented making use of all the available attributes in the data. Feature selection was employed to reduce the attributes to the most important. After feature selection a Multilayer Perceptron classifier was trained and it significantly out performed the baseline classifier. Even though a decent classifier was develop, a few unanswered questions remain:\n\n**What are the most important features?**","37035db7":"Notes:\n- Duplicate data is removed because it is determined that the sample size is sufficient\n- Duplicate data should ideally be investigated but brevity sake the data is removed ","06340800":"# 4. Modelling\n\nA baseline logistic regression classifier is trained on the online shoppers intention data set to predict whether a website visitor will make a purchase or not. The steps taken in this section are prepare data set for modelling, split the processed data, train the baseline classifier and report the results. After the baseline classifier is built, we experiment with feature selection and Multilayer Perceptron based classifier.\n\n**Data preparation:**\n\n- The 'Revenue' attribute is encoded to values 0 (False) and 1 (True)\n- The 'Weekend' attribute is encoded to values 0 (False) and 1 (True)\n- The 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType' and 'VisitorType'\tattributes are one-hot encoded\n- The numeric attributes are normalized\n- The data is split into a training (80%) and test (20%) set","99bb5165":"Looking at the Confusion Matrix above we observe that out of 2059 negative samples 1930 were classified correctly and out of 382 positive samples 231 were classified correctly. The Multilayer Perceptron classifier performance in terms of the **macro average f1 score is ~0.77** and the **roc auc score is ~0.77**. The Multilayer Perceptron classifier is definetly an improvement on the baseline classifier.\n","682b8d79":"PageValues, ExitRates and BounceRates shows some difference between website visitors that purchased and those that did not.","e378f366":"## 4.1 Baseline classifier","e27d281d":"# 3. Data Exploration\n\nUnderstanding the intentions of visitors to a website can provide immense value to a business. Specifically, businesses can develop and introduce interventions to encourage visitors to purchase. A viable tool for businesses could be machine learning models which can be used to predict the intention of visitors to a website. \n\nThe aim of this notebook is to build a classifier which can predict whether a visitor will make a purchase or not. The target label for the classification task is the Revenue attribute. In this section we explore some of the attributes which could possibly make good predictors for the classification task.","2e401c10":"**The weighted average f1 score of 0.84** seems great but it's not applicable as the target label is unbalanced with significantly more examples of website visits that did not result in revenue. More reasonable metrics would be the **macro average f1 score (~0.65)** and **roc auc score (0.62)**. Given the scores of the aforementioned metrics, the baseline classifier (Logistic Regression) performance is mediocre.  ","e1dc87b2":"The target label of the classification task is unbalanced. Approximately 85% of website visitors did not make a purchase (negative samples) and 15% made a purchase (positive samples).","9ac54fda":"ProductRelated and Administrative page type attributes shows some seperation between website visitors that purchased and those that did not.","e8ca06cc":"## 4.2 Feature selection \n\nThe number of attributes used for training the baseline classifier was 74. In this section we limit the attributes and reduce the feature space. Feature selection is performed via a Random Forest classifier which determines the most signifcant attributes. The most important features resulting from feature selection is used to train a Multilayer Perceptron based classifier.","524a0c36":"The plot above is a useful tool for determining how different PageValues will change the prediction of the Multilayer Perceptron classifier. The threshold for the target label (Revenue) is at 0.50 on the y-axis. The PageValues attribute has a positive relationship with the prediction i.e. as the PageValue increases, the prediction increases toward 1 (website visitor is more likely to purchase).\n\n**Last Words**\n\nThe Multilayer Perceptron classifier is a good starting point for modelling the shopping intentions of website visitors. The classifier is really good at identifying negative examples (recall of ~0.93) and not that great at identifying positive examples (recall of ~0.60). Possible improvements to the model could involve experimenting with different sampling techniques, feature engineering and different algorithms.","affb52b8":"Notes:\n- Columns match description of the data set\n- Some numeric (int, float) columns, string columns and boolean columns\n- Preliminary check reveals no obvious missing data (column value counts match row counts)\n- A few categorical columns need to be converted to str"}}