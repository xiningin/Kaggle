{"cell_type":{"35adf60b":"code","e079f18f":"code","1f6ea8e4":"code","5a292d57":"code","d385e1ab":"code","2f5631e0":"code","2b2a9d0b":"code","524a1de3":"code","5bd94a26":"code","115eff8b":"code","481d42f4":"code","c462e252":"code","332bb0b3":"code","4052bbb6":"code","f810d049":"code","c422230d":"code","6a7d6296":"code","58fbe324":"code","b56eff15":"code","f4a27955":"code","1eda27f6":"code","ad380df8":"code","de610399":"code","5a1dd5c7":"code","5616ff0f":"code","f1684c39":"code","41a46cab":"code","5c3f3d56":"code","1d244198":"code","206a15ff":"code","6ce9edc7":"code","f1325ec0":"code","1367a2a4":"code","f8a122e5":"code","54bdb5b9":"code","57260112":"code","b0428efa":"code","437bf76d":"code","58fa06ad":"code","73d20959":"code","004171f7":"code","9a1c0771":"code","d54e8670":"code","45659f46":"code","c72625d8":"code","92d087c2":"code","85d1f52b":"code","dab2fbed":"code","97d3f22e":"code","9d3650d9":"code","c0982c11":"code","d445eccb":"code","e80dd5bb":"code","71889fc0":"code","4412f989":"code","dccdf954":"code","c2b8e53d":"code","c3d73ff4":"code","cb526d0a":"code","c2ac6de4":"code","613dc73e":"code","a235bd55":"code","3649ca66":"code","70932050":"code","4921b867":"code","a4dc5732":"code","0a5e00c9":"code","a7a8d482":"code","27af34df":"code","1c164f75":"markdown","1922def2":"markdown","e8b3a6f7":"markdown","0cbb60f4":"markdown","7fc0f575":"markdown","c463a0d2":"markdown","3a310f39":"markdown","a83ed3b0":"markdown","0c795790":"markdown","29f2d501":"markdown","864bcec2":"markdown","413c9d48":"markdown","3cd80bf2":"markdown","b8efa6de":"markdown","338cd143":"markdown","dcf3b6e7":"markdown","a506277d":"markdown","54824eb9":"markdown","fa250efe":"markdown","a8eedb45":"markdown","858df33d":"markdown","b34767a5":"markdown","a7d6497f":"markdown","416fbef8":"markdown","f9a3bb1b":"markdown"},"source":{"35adf60b":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e079f18f":"pip install Pillow","1f6ea8e4":"import PIL\nprint('Pillow Version:', PIL.__version__)","5a292d57":"import PIL\n# load and show an image with Pillow\nfrom PIL import Image\n# load the image\nimage = Image.open('\/kaggle\/input\/picture-skimage\/download (3).jfif')\n# summarize some details about the image\nprint(image.format)\nprint(image.mode)\nprint(image.size)\n# show the image\nimage.show()\n# IMAGE SOURCE = https:\/\/www.brides.com\/the-a-z-of-wedding-terminology-4707024","d385e1ab":"from matplotlib import pyplot\n# display the array of pixels as an image\npyplot.imshow(image)\npyplot.show()","2f5631e0":"import matplotlib.pyplot as plt\n\nfrom skimage import data\nfrom skimage.color import rgb2gray\n\noriginal = data.astronaut()\ngrayscale = rgb2gray(original)\n\nfig, axes = plt.subplots(1, 2, figsize=(8, 4))\nax = axes.ravel()\n\nax[0].imshow(original)\nax[0].set_title(\"Original\")\nax[1].imshow(grayscale, cmap=plt.cm.gray)\nax[1].set_title(\"Grayscale\")\n\nfig.tight_layout()\nplt.show()","2b2a9d0b":"# create a Show_image FUnction\ndef show_img(image, title='Image', cmap_type='gray'):\n    plt.imshow(image, cmap=cmap_type)\n    plt.title('Show your image')\n    plt.axis('off')\n    plt.show()","524a1de3":"# Import the modules from skimage\nfrom skimage import data, color\n\n# Load the rocket image\nrocket = data.rocket()\n\n# Convert the image to grayscale\ngray_scaled_rocket = color.rgb2gray(rocket) \n\n# Show the original image\nshow_img(rocket, 'Original RGB image')\n\n# Show the grayscale image\nshow_img(gray_scaled_rocket, 'Grayscale image')","5bd94a26":"# images as nd arrays\nimag = plt.imread(r'\/kaggle\/input\/picture-skimage\/download (3).jfif')\ntype(imag)","115eff8b":"# obtaining with the \n# obtaining red values of an image\nimport numpy as np\n# Obtain the red channel\n#red_channel = image[:, :, 0]\n\n# Plot the red histogram with bins in a range of 256\n#plt.hist(red_channel.ravel(), bins=256)\n\n# Set title and show\n#plt.title('Red Histogram')\n#plt.show()","481d42f4":"# flip the image vertically\ngr = Image.open(r'\/kaggle\/input\/picture-skimage\/download (3).jfif')\nv_f =np.flipud(gr)\nshow_img(v_f, 'Vertically Flipped Image')","c462e252":"# Flip the image vertically\nseville_vertical_flip = np.flipud(gr)\n\n# Flip the previous image horizontally\nseville_horizontal_flip = np.fliplr(gr)","332bb0b3":"show_img(seville_horizontal_flip, 'Seville')","4052bbb6":"show_img(seville_vertical_flip, 'none')","f810d049":"# obtain the optimal threholding value\nthresh = 127\nimage = Image.open(r'\/kaggle\/input\/picture-skimage\/download (3).jfif')\nimage = np.array(image)\n# apply to image\nbinary = image > thresh","c422230d":"# Import the otsu threshold function\nfrom skimage.color import rgb2gray\nfrom skimage.filters import threshold_otsu\n\n# Make the image grayscale using rgb2gray\nimage_gray = color.rgb2gray(image)\n\n# Obtain the optimal threshold value with otsu\nthresh = threshold_otsu(image_gray)\n\n# Apply thresholding to the image\nbinary = image_gray > thresh\n\n# Show the image\nshow_img(binary, 'Binary image')","6a7d6296":"# Import the local threshold function\nfrom skimage.filters import threshold_local\n\n# Set the block size to 35\n##block_size = 35\n\n# Obtain the optimal local thresholding\n##local_thresh = threshold_local(page_image, block_size, offset=10)\n\n# Obtain the binary image by applying local thresholding\n##binary_local = page_image > local_thresh\n\n# Show the binary image\n##show_img(binary_local, 'Local thresholding')","58fbe324":"# Import the try all function\nfrom skimage.filters import try_all_threshold\nimage = Image.open(r'\/kaggle\/input\/picture-skimage\/download (3).jfif')\nimage = np.array(image)\n# Import the rgb to gray convertor function \nfrom skimage.color import rgb2gray\n\n# Turn the fruits_image to grayscale\ngrayscale = rgb2gray(image)\n\n# Use the try all method on the resulting grayscale image\nfig, ax = try_all_threshold(grayscale, verbose=False)\n\n# Show the resulting plots\nplt.show()","b56eff15":"# Import the try all function\nfrom skimage.filters import try_all_threshold\n\n# Import the rgb to gray convertor function \nfrom skimage.color import rgb2gray\n\n# Turn the fruits_image to grayscale\ngrayscale = rgb2gray(image)\n\n# Use the try all method on the resulting grayscale image\nfig, ax = try_all_threshold(grayscale, verbose=False)\n\n# Show the resulting plots\nplt.show()","f4a27955":"def plot_comparison(original, filtered, title_filtered):\n  fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 6), sharex=True, sharey=True)\n  ax1.imshow(original, cmap=plt.cm.gray) \n  ax1.set_title('original') \n  ax1.axis('off')\n  ax2.imshow(filtered, cmap=plt.cm.gray) \n  ax2.set_title(title_filtered) \n  ax2.axis('off')","1eda27f6":"# Edge detection- Sobel\nfrom skimage.filters import sobel\n# Apply edge detection algos\nedge_sobel = sobel(image)\n# Show Image comparison\nplot_comparison(image, edge_sobel, 'Edge with Sobel')","ad380df8":"# Import the color module\nfrom skimage import color\n\n# Import the filters module and sobel function\nfrom skimage.filters import sobel\n\n# Make the image grayscale\nsoaps_image_gray = color.rgb2gray(image)\n\n# Apply edge detection filter\nedge_sobel = sobel(image)\n\n# Show original and resulting image to compare\nshow_img(soaps_image_gray, \"Original\")\nshow_img(edge_sobel, \"Edges with Sobel\")","de610399":"# Import Gaussian filter \nfrom skimage.filters import gaussian\nimage = Image.open(r'\/kaggle\/input\/picture-skimage\/download (3).jfif')\nimage = np.array(image)\n# Apply filter\ngaussian_image = gaussian(image, multichannel=True)\n\n# Show original and resulting image to compare\nshow_img(image, \"Original\")\nshow_img(gaussian_image, \"Reduced sharpness Gaussian\")","5a1dd5c7":"from skimage import exposure as ex\n# obtain the equalized image\nimg_eq = ex.equalize_hist(image)\n# show Original and result\nshow_img(image, 'Original')\nshow_img(img_eq, 'Histogram equalized')","5616ff0f":"# Import the required module\nfrom skimage import exposure\nchest_xray_image = Image.open(r'\/kaggle\/input\/picture-skimage\/download (3).jfif')\nchest_xray_image = np.array(chest_xray_image)\n# Show original x-ray image and its histogram\nshow_img(chest_xray_image, 'Original x-ray')\n\nplt.title('Histogram of image')\nplt.hist(chest_xray_image.ravel(), bins=256)\nplt.show()","f1684c39":"# Import the required module\nfrom skimage import exposure\n\n# Show original x-ray image and its histogram\nshow_img(chest_xray_image, 'Original x-ray')\n\nplt.title('Histogram of image')\nplt.hist(chest_xray_image.ravel(), bins=256)\nplt.show()\n\n# Use histogram equalization to improve the contrast\nxray_image_eq =  exposure.equalize_hist(chest_xray_image)\n\n# Show the resulting image and its stats\nshow_img(xray_image_eq, 'Resulted image')\nplt.title('Histogram of resulting image')\nplt.hist(xray_image_eq.ravel(), bins=256)\nplt.show()","41a46cab":"# Import the required module\n# IMAGE AUTHOR = Marco Leiter \nfrom skimage import exposure\nimage_aerial = Image.open(r'\/kaggle\/input\/aerial-image\/download (4).jfif')\nimage_aerial = np.array(image_aerial)\n# Use histogram equalization to improve the contrast\nimage_eq1 =  exposure.equalize_hist(image_aerial)\n\n# Show the original and resulting image\nshow_img(image_aerial, 'Original')\nshow_img(image_eq1, 'Resulting image')","5c3f3d56":"# Import the necessary modules\nfrom skimage import data, exposure\n\n# Load the image\noriginal_image = data.coffee()\n\n# Apply the adaptive equalization on the original image\nadapthist_eq_image = exposure.equalize_adapthist(original_image, clip_limit=0.03)\n\n# Compare the original image to the equalized\nshow_img(original_image)\nshow_img(adapthist_eq_image, '#ImageProcessingDatacamp')","1d244198":"# rotating image clockwise\n#90 degrees\nfrom skimage.transform import rotate as rt\nimge_rotate = rt(original_image, -90)\nshow_img(imge_rotate, 'Rotated image')","206a15ff":"from skimage.transform import rescale\nimg_rs = rescale(image_aerial, 1\/4, anti_aliasing=True, multichannel=True)\nshow_img(img_rs,'Rescaled')","6ce9edc7":"# Import the data module\nfrom skimage import data\n\n# Load the image from data\nrocket_image = data.rocket()\n\n# Enlarge the image so it is 3 times bigger\nenlarged_rocket_image = rescale(rocket_image, 0.5, anti_aliasing=True, multichannel=True)\n\n# Show original and resulting image\nshow_img(rocket_image)\nshow_img(enlarged_rocket_image, \"0.5 times enlarged image\")","f1325ec0":"# Import the module and function\nfrom skimage.transform import resize\n\n# Set proportional height and width so it is half its size\nheight = int(rocket_image.shape[0] \/ 2.0)\nwidth = int(rocket_image.shape[1] \/ 2.0)\n# Resize using the calculated proportional height and width\nimage_resized = resize(rocket_image, (height, width),\n                       anti_aliasing=True)\n\n# Show the original and rotated image\nshow_img(rocket_image, 'Original')\nshow_img(image_resized, 'Resized image')","1367a2a4":"original_image.shape","f8a122e5":"from skimage import morphology\nsquare = morphology.square(4)\nrectangle = morphology.rectangle(4,2)\nselem = morphology.rectangle(417, 626) # KNOWN AS EROSION START\n# OBTAIN EROSED IMAGE WITH BINARY EROSION\n#ERODED_IMAGE = morphology.binary_erosion(original_image, selem=selem)\n#plot_comparison(original_image, ERODED_IMAGE,'Erosion')","54bdb5b9":"# Obtain dilated image\ndil_img = morphology.binary_dilation(rocket_image)","57260112":"#ERODED_IMAGE = morphology.binary_erosion(dil_img, selem=selem)","b0428efa":"# See results\n#show_img(upper_r_image, 'Original')\n#show_image(eroded_image_shape, 'Eroded image')","437bf76d":"def get_mask(image):\n    ''' Creates mask with three defect regions '''\n    mask = np.zeros(image.shape[:-1])\n    mask[101:106, 0:240] = 1\n    mask[152:154, 0:60] = 1\n    mask[153:155, 60:100] = 1\n    mask[154:156, 100:120] = 1\n    mask[155:156, 120:140] = 1\n    mask[212:217, 0:150] = 1\n    mask[217:222, 150:256] = 1\n    return mask","58fa06ad":"from skimage.restoration import inpaint\n# obtain the image\nmask = get_mask(original_image)\n# Apply inpainting to the damaged image using the mask\nrestored_image = inpaint.inpaint_biharmonic(original_image,mask,multichannel=True)\n# Show the resulting image\nshow_img(original_image)\nshow_img(restored_image)","73d20959":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","004171f7":"image_with_logo = Image.open(r'\/kaggle\/input\/google-logo\/google2.0.0.jpg')\nimage_with_logo = np.array(image_with_logo)","9a1c0771":"# Initialize the mask\n#mask = np.zeros(image_with_logo.shape[:-1])\n\n# Set the pixels where the logo is to 1\n# mask[210:290, 360:425] = 1\n\n# Apply inpainting to remove the logo\n#image_logo_removed = inpaint.inpaint_biharmonic(image_with_logo, \n                                                #mask[210:290, 360:425], \n                                                #multichannel=True)\n\n# Show the original and logo removed images\n#show_img(image_with_logo, 'Image with logo')\n#show_img(image_logo_removed, 'Image with logo removed')","d54e8670":"from skimage.util import random_noise\n# add noise to the image\nn_image = random_noise(image_with_logo)\n# original vs noise image\nshow_img(image_with_logo)\nshow_img(n_image)","45659f46":"from skimage.restoration import denoise_tv_chambolle\n# apply total variation filter denoising\ndenoised_image = denoise_tv_chambolle(n_image, weight=0.1, multichannel=True)\nshow_img(n_image)\nshow_img(denoised_image)","c72625d8":"from skimage.restoration import denoise_bilateral\ndenoised_img_b = denoise_bilateral(n_image,multichannel=True)\nshow_img(denoised_image)\nshow_img(denoised_img_b)","92d087c2":"# import the modules\nfrom skimage.segmentation import slic \nfrom skimage.color import label2rgb\n# obtain the segments\nsegments = slic(rocket_image, start_label = 1)\n# compare segments of the orignal image \nseg_image = label2rgb(segments, rocket_image, kind='avg', bg_label=0)\n\nshow_img(rocket_image)\nshow_img(seg_image)","85d1f52b":"# Import the modules\nfrom skimage import measure, data, filters\n\n# Obtain the horse image\nhorse_image = data.horse()\n\n# Find the contours with a constant level value of 0.8\ncontours = measure.find_contours(horse_image, 0.8)\n\n# Shows the image with contours found\nshow_img(horse_image, contours)","dab2fbed":"# function to find image corners\ndef show_img_corners(image, coords, title=\"Corners detected\"): \n  plt.imshow(image, interpolation='nearest', cmap='gray') \n  plt.title(title)\n  plt.plot(coords[:, 1], coords[:, 0], '+r', markersize=15) \n  plt.axis('off')\n  plt.show()","97d3f22e":"# A function to show the contour of the image \ndef show_image_contour(image, contours):\n    plt.figure()\n    for n, contour in enumerate(contours):\n        plt.plot(contour[:, 1], contour[:, 0], linewidth=3)\n    plt.imshow(image, interpolation='nearest', cmap='gray_r')\n    plt.title('Contours')\n    plt.axis('off')\n    plt.show()","9d3650d9":"# Make the image grayscale\nimage = color.rgb2gray(image)\n\n# Obtain the optimal thresh value\nthresh = filters.threshold_otsu(image)\n# Apply thresholding\nbinary = image > thresh","c0982c11":"# Find contours at a constant value of 0.8\ncontours = measure.find_contours(binary, 0.8)\n\n# Show the image\nshow_image_contour(image, contours)","d445eccb":"# Create list with the shape of each contour \nshape_contours = [cnt.shape[0] for cnt in contours]\n\n# Set 50 as the maximum size of the dots shape\nmax_dots_shape = 50\n\n# Count dots in contours excluding bigger than dots size\ndots_contours = [cnt for cnt in contours if np.shape(cnt)[0] < max_dots_shape]\n\n# Shows all contours found \nshow_image_contour(binary, contours)\n\n# Print the dice's number\nprint(\"Dice's dots number: {}. \".format(len(dots_contours)))","e80dd5bb":"from skimage.feature import canny \n# convert image to grayscale\ncoins = data.coins()\ncoins = rgb2gray(coins)\n# check edges\nedges = canny(coins)\nshow_img(coins)\nshow_img(edges)","71889fc0":"# less edges\nedges = canny(coins, sigma=1.8)\nshow_img(edges)","4412f989":"from skimage.feature import corner_harris, corner_peaks\nimage = rgb2gray(image)\nmeasure_image = corner_harris(image)\ncoords = corner_peaks(measure_image, min_distance=5, threshold_rel=0)","dccdf954":"print('total of', '', len(coords), 'were detected')","c2b8e53d":"show_img_corners(image, coords, title='Corners detected')","c3d73ff4":"# Import the corner detector related functions and module\nfrom skimage.feature import corner_harris, corner_peaks\nrocket_image = data.rocket()\n# Convert image from RGB-3 to grayscale\nrocket_image_gray = color.rgb2gray(rocket_image)\n\n# Apply the detector  to measure the possible corners\nmeasure_image = corner_harris(rocket_image_gray)\n\n# Find the peaks of the corners\ncoords = corner_peaks(measure_image, min_distance=2)\n\n# Show original and resulting image with corners detected\nshow_img(rocket_image, \"Original\")\nshow_img_corners(rocket_image, coords)","cb526d0a":"# Find the peaks with a min distance of 2 pixels\ncoords_w_min_2 = corner_peaks(measure_image, min_distance=2, threshold_rel=0)\nprint(\"With a min_distance set to 2, we detect a total\", len(coords_w_min_2), \"corners in the image.\")","c2ac6de4":"# All nessecary functions for face detections\nimport matplotlib.patches as patches\n\ndef crop_face(result, detected, title=\"Face detected\"):\n    for d in detected:\n        print(d)\n        rostro= result[d['r']:d['r']+d['width'], d['c']:d['c']+d['height']]\n    \n        plt.figure(figsize=(8, 6))\n        plt.imshow(rostro)    \n        plt.title(title)\n        plt.axis('off')\n        plt.show()","613dc73e":"def show_detect_face(result, detected, title=\"Face image\"):\n    plt.imshow(result)\n    img_desc = plt.gca()\n    plt.set_cmap('gray')\n    plt.title(title)\n    plt.axis('off')\n\n    for patch in detected:\n        \n        img_desc.add_patch(\n            patches.Rectangle(\n                (patch['c'], patch['r']),\n                patch['width'],\n                patch['height'],\n                fill=False, color='r',linewidth=2))\nplt.show()","a235bd55":"from skimage import data\nfrom skimage.feature import Cascade\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\n\n# Load the trained file from the module root.\ntrained_file = data.lbp_frontal_face_cascade_filename()\n\n# Initialize the detector cascade.\ndetector = Cascade(trained_file)\n\nimg = data.astronaut()\n\ndetected = detector.detect_multi_scale(img=img,\n                                       scale_factor=1.2,\n                                       step_ratio=1,\n                                       min_size=(60, 60),\n                                       max_size=(90, 500))\n\nplt.imshow(img)\nimg_desc = plt.gca()\nplt.set_cmap('gray')\n\nfor patch in detected:\n\n    img_desc.add_patch(\n        patches.Rectangle(\n            (patch['c'], patch['r']),\n            patch['width'],\n            patch['height'],\n            fill=False,\n            color='r',\n            linewidth=2\n        )\n    )\n\nplt.show()","3649ca66":"# Obtain the segmentation with default 100 regions\nsegments = slic(img)\n\n# Obtain segmented image using label2rgb\nsegmented_image = label2rgb(segments, img, kind='avg')\n\n# Detect the faces with multi scale method\ndetected = detector.detect_multi_scale(img=segmented_image, \n                                       scale_factor=1.2, \n                                       step_ratio=1, \n                                       min_size=(10, 10), max_size=(1000, 1000))\n\n# Show the detected faces\nshow_detect_face(segmented_image, detected)","70932050":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4921b867":"# Load the trained file from data\ntrained_file = data.lbp_frontal_face_cascade_filename()\nfriends_image = Image.open(r'\/kaggle\/input\/friends-image\/download (6).jfif')\nfriends_image = np.array(friends_image)\n# Initialize the detector cascade\ndetector = Cascade(trained_file)\n# Detect faces with scale factor to 1.2 and step ratio to 1\ndetected = detector.detect_multi_scale(img=friends_image,\n                                       scale_factor=1.2,\n                                       step_ratio=1,\n                                       min_size=(10, 10),\n                                       max_size=(300, 300))\n# Show the detected faces\nshow_detect_face(friends_image, detected)","a4dc5732":"# functions to merge blurry Faces\ndef merge_blurry_face(original, gaussain_image):\n    # starting points of a face rectangle\n    x, y =d['r'], d['c']\n    # the width and heigh of a face rectangle\n    width, height = d['r'] + d['width'], d['c'] + d['height']\n    \n    original[x:width, y:height] = gaussain_image\n    return original","0a5e00c9":"def getFaceRectangle(image, d):\n    ''' Extracts the face from the image using the coordinates of the detected image '''\n    # X and Y starting points of the face rectangle\n    x, y  = d['r'], d['c']\n    \n    # The width and height of the face rectangle\n    width, height = d['r'] + d['width'],  d['c'] + d['height']\n    \n    # Extract the detected face\n    face= image[ x:width, y:height]\n    return face","a7a8d482":"#Privacy protection\n# Detect the faces\nfrom skimage.filters import gaussian\ndetected = detector.detect_multi_scale(img=friends_image, \n                                       scale_factor=1.2, step_ratio=1, \n                                       min_size=(10, 10), max_size=(100, 100))\n# For each detected face\nfor d in detected:  \n    # Obtain the face rectangle from detected coordinates\n    face = getFaceRectangle(friends_image,d)\n    \n    # Apply gaussian filter to extracted face\n    blurred_face = gaussian(face, multichannel=True, sigma = 8)\n    \n    # Merge this blurry face to our final image and show it\n    resulting_image = merge_blurry_face(friends_image, blurred_face) \nshow_img(resulting_image, \"Blurred faces\")","27af34df":"# Import the necessary modules\nfrom skimage.restoration import denoise_tv_chambolle, inpaint\nfrom skimage.transform import rotate\n\n# Transform the image so it's not rotated\nupright_img = rotate(friends_image, 20)\n\n# Remove noise from the image, using the chambolle method\nupright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)\n\n# Reconstruct the image missing parts\nmask = get_mask(upright_img)\nresult = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)\n\nshow_img(result)","1c164f75":"# Biltaeral filter","1922def2":"# Rescaling","e8b3a6f7":"# Make images come alive with scikit-image","0cbb60f4":"# Segmentation and face detection","7fc0f575":"# Find contours of an image that is not binary","c463a0d2":"# Removing logos","3a310f39":"# Jump into filtering","a83ed3b0":"# Noise","0c795790":"# Getting started with thresholding","29f2d501":"# Colors with Numpy","864bcec2":"# Enlarging Images","413c9d48":"# Superpixels & segmentation - Supervised & Unsupervised","3cd80bf2":"# GreyScale Image","b8efa6de":"# Apply detector on images","338cd143":"# Morphology: Filtering, operations\n# Shapes and erosion in Sckit images ","dcf3b6e7":"# Numpy for images ","a506277d":"# Contrast enhancement","54824eb9":"# Image restoration","fa250efe":"# Right around the corner - Harrsi corner detector","a8eedb45":"# Finding the edges with Canny","858df33d":"# Rotating","b34767a5":"# Real-world applications - all shown above","a7d6497f":"# Face detection","416fbef8":"# Denoising","f9a3bb1b":"# There  are   a   few   errors   in   terms   of the   parameters   of detections and incorrect data use i applied due to finishing this in a hurry but i look forward to your corrections and contributions and reviews on this \n\n# and please do upvote it if you can :D"}}