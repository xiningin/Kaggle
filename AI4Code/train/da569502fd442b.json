{"cell_type":{"fb62b372":"code","a83f8309":"code","223ccd18":"code","8d1f4f96":"code","d498fc32":"code","d895f3ec":"code","cd45e816":"code","224a0c36":"code","58637708":"code","41d078ce":"code","eaa52892":"code","a69a47a8":"code","56b66804":"code","f9dd3836":"code","91bfd30e":"code","57fa1314":"code","b4b100c5":"code","9ca645e1":"code","d191f32f":"code","7ffd1ecd":"code","e0337bc9":"code","4309263f":"code","4442e5e3":"code","03721564":"code","7d9a4de2":"code","cf7d8df3":"code","f71a8233":"code","455ab706":"code","52e45d0b":"code","cc1a10ad":"code","824e5383":"code","434839ab":"code","b616cad8":"code","d808fa7f":"code","544c104f":"code","3839505c":"code","cb36d99b":"code","56578467":"code","7eb1756a":"code","215623b3":"code","8ad03eed":"code","10590f45":"code","63e5fd7e":"code","37cba7ae":"code","8100c57f":"code","f01cbe79":"markdown"},"source":{"fb62b372":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a83f8309":"import tensorflow as tf\n\nimport os\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    print(\"Not connected to a TPU runtime. Using CPU\/GPU strategy\")\n    strategy = tf.distribute.MirroredStrategy()","223ccd18":"strategy.scope()","8d1f4f96":"# !conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n# !conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n# !conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n# !conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n# !conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n# !conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","d498fc32":"# !pip install efficientnet","d895f3ec":"# import efficientnet.keras as efn\nimport os\nimport shutil\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense , Conv2D , Dropout , MaxPooling2D , Flatten, Activation , BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","cd45e816":"random.seed(7)","224a0c36":"preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n","58637708":"# base_model = EfficientNetB7(weights='imagenet',include_top=False,input_shape=(600,600,3))\n# base_model.trainable = False\n# base_model.summary()","41d078ce":"%cd ..\n%mkdir tmp\n%cd tmp\n%ls\n","eaa52892":"a = os.listdir('..\/input\/efficientnetb7-dataset-augmented\/augmented\/train')\na","a69a47a8":"# for i in a:\n#     os.mkdir('NewPreprocessed\/{}'.format(i))","56b66804":"shutil.copytree(\"..\/input\/efficientnetb7-dataset-augmented\/augmented\/train\",\"\/kaggle\/tmp\/NewPreprocessed\")","f9dd3836":"# from PIL import Image\n# import os, sys\n\n\n# def resize(path,savepath):\n#     for item in os.listdir(path):\n#         item_path = path+\"\/\"+item\n#         im = Image.open(item_path)\n#         imResize = im.resize((600,600), Image.ANTIALIAS)\n#         imResize.save(savepath +\"\/\"+item.split('.')[0]+ '_resized.jpg', 'JPEG')\n\n# for i in a:\n#     path = \"..\/input\/rsna-balenced-dataset\/Processed\/\"+i\n#     savepath = \"NewPreprocessed\/\"+i\n#     resize(path,savepath)\n    ","91bfd30e":"%ls","57fa1314":"for i in a:\n    savepath = \"NewPreprocessed\/\"\n    print(len(os.listdir(savepath+i)))","b4b100c5":"split_size = .85\ndef split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):  \n    all_images = os.listdir(SOURCE)\n    print(type(all_images))\n    random.shuffle(all_images)\n    splitting_index = round(SPLIT_SIZE*len(all_images))\n\n    #print(splitting_index)\n    #print(splitting_index+portion)\n\n    train_images = all_images[:splitting_index]\n    valid_images = all_images[splitting_index:]\n    for img in train_images:\n        shutil.copy(os.path.join(SOURCE,img),TRAINING)\n    for img in valid_images:\n        shutil.copy(os.path.join(SOURCE,img),VALIDATION)\n","9ca645e1":"os.mkdir('train')\nos.mkdir('val')","d191f32f":"for i in a:\n    source = \"NewPreprocessed\/\"+i\n    train = \"train\/\"+i\n    val = \"val\/\"+i\n    os.mkdir(train)\n    os.mkdir(val)\n    split_data(source, train, val, split_size)","7ffd1ecd":"for i in a:\n    train = \"train\/\"+i\n    val = \"val\/\"+i\n    print(len(os.listdir(train)),len(os.listdir(val)))","e0337bc9":"batch_size = 16","4309263f":"# TRAINING_DIR = 'train'\n# train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n# train_generator =  train_datagen.flow_from_directory(TRAINING_DIR,\n#                                                       target_size=(600,600),\n#                                                       batch_size=16,\n#                                                      class_mode='categorical',\n#                                                      shuffle = True)\n# VALIDATION_DIR = 'val'\n# validation_datagen = ImageDataGenerator()\n# validation_generator =  validation_datagen.flow_from_directory(VALIDATION_DIR,\n#                                                       target_size=(600,600),\n#                                                       batch_size=16,\n#                                                       class_mode='categorical',\n#                                                       shuffle = True)","4442e5e3":"TRAINING_DIR = 'train'\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n                                                      TRAINING_DIR,\n                                                        shuffle = True,\n                                                      image_size=(600,600),\n                                                      batch_size=batch_size,\n                                                        label_mode='categorical')\nVALIDATION_DIR = 'val'\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n                                                      VALIDATION_DIR,\n                                                    shuffle = True,\n                                                      image_size=(600,600),\n                                                    label_mode='categorical',\n                                                      batch_size=batch_size)","03721564":"class_names = train_ds.class_names\nclass_names","7d9a4de2":"# plt.figure(figsize=(10, 10))\n# for images, labels in train_ds.take(1):\n#     for i in range(9):\n#         ax = plt.subplot(3, 3, i + 1)\n#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n#         plt.title(class_names[labels[i]])\n#         plt.axis(\"off\")","cf7d8df3":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)","f71a8233":"# base_model = EfficientNetB7(weights='imagenet',include_top=False,input_shape=(600,600,3))","455ab706":"# base_model.trainable = False\n# for i in base_model.layers[-10:]:\n#     i.trainable = True\n#     print(i.trainable)\n# for i in base_model.layers[-20:]:\n#     print(i.trainable)","52e45d0b":"def create_model():\n    inputs = tf.keras.Input(shape=(600, 600, 3))\n    preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n    data_augmentation = tf.keras.Sequential([\n                                              tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n                                              tf.keras.layers.experimental.preprocessing.RandomRotation(0.3),\n                                            ])\n    \n    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n#     prediction_layer0 = tf.keras.layers.Dense(2048,activation=\"relu\")\n#     prediction_layer1 = tf.keras.layers.Dense(1024,activation=\"relu\")\n    prediction_layer2 = tf.keras.layers.Dense(512,activation=\"relu\")\n    prediction_layer3 = tf.keras.layers.Dense(128,activation=\"relu\")\n    prediction_layer4 = tf.keras.layers.Dense(4,activation=\"softmax\")\n    \n    x = data_augmentation(inputs)\n    x = preprocess_input(x)\n    base_model = EfficientNetB7(weights='imagenet',include_top=False,input_tensor=x)\n    base_model.trainable = False\n    for layer in base_model.layers[-20:]:\n        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n            layer.trainable = True\n    x = global_average_layer(base_model.output)\n#     x = BatchNormalization()(x)\n#     x = Dropout(0.2)(x)\n#     x = prediction_layer0(x)\n#     x = Dropout(0.2)(x)\n#     x = prediction_layer1(x)\n    x = Dropout(0.2)(x)\n    x = prediction_layer2(x)\n    x = Dropout(0.2)(x)\n    x = prediction_layer3(x)\n    x = Dropout(0.15)(x)   \n    outputs = prediction_layer4(x)\n    model = tf.keras.Model(inputs, outputs)\n    return(model)","cc1a10ad":"with strategy.scope():\n    Model = create_model()\n    optimizer = Adam(learning_rate=0.001)\n    Model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])","824e5383":"print(Model.input_shape,Model.output_shape)\nModel.summary()","434839ab":"\n# history = Model.fit(train_generator,epochs=40,batch_size=16,validation_data=validation_generator)","b616cad8":"# with strategy.scope():\nhistory = Model.fit(train_ds,epochs=25,batch_size=16,validation_data=val_ds) ","d808fa7f":"# os.mkdir(\"..\/working\/weights\")\n# Model.save_weights(\"..\/working\/weights\/weights.pt\")","544c104f":"# os.rmdir(\"..\/working\/weights\")\nModel.save('..\/working\/weights\/my_model.h5')","3839505c":"Model = tf.keras.models.load_model(\"..\/input\/efficientnetb7\/weights\/my_model.h5\")","cb36d99b":"history = Model.fit(train_ds,epochs=25,batch_size=16,validation_data=val_ds) ","56578467":"Model =  tf.keras.models.load_model(\"\/kaggle\/input\/efficientnetweights\/weights\/my_model.h5\")","7eb1756a":"Model = tf.keras.models.load_model(\"\/kaggle\/input\/efnetb7-layers-increased-more-trainable-layers\/weights\/my_model.h5\")","215623b3":"# Model = create_model()\nModel.load_weights(\"..\/input\/efficientnetweights\/weights\/\")","8ad03eed":"Model.evaluate(val_ds)","10590f45":"# train more with this config only\n","63e5fd7e":"def unfreeze_model(Model):\n    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n    for layer in Model.layers[-40:]:\n        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n            layer.trainable = True\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=8e-5)\n    Model.compile(\n        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n    )\n\n\nunfreeze_model(Model)\n\nepochs = 10  # @param {type: \"slider\", min:8, max:50}\nhist = Model.fit(train_ds, epochs=epochs,batch_size=batch_size, validation_data=val_ds)\nplot_hist(hist)","37cba7ae":"Model.summary()","8100c57f":"Model.layers","f01cbe79":"Loading and saving"}}