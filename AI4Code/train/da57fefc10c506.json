{"cell_type":{"cb940278":"code","006aff69":"code","84162053":"code","483c6861":"code","d3118cca":"code","d67354ba":"code","072de82b":"code","61dbdbf9":"code","3c47b38d":"code","07e916bc":"code","820ee7e0":"code","5aa5c17e":"code","0c15864e":"code","01828aca":"code","72e7f72e":"code","c0c3b59f":"code","5725cfd7":"code","65597dda":"code","9bb44c36":"code","339c838a":"code","b03a0db5":"code","a55cb190":"code","e0507fcc":"code","7f72f800":"code","d71c8e1b":"code","6932e8a4":"code","9b9afb90":"markdown","43c62268":"markdown","b52173e1":"markdown"},"source":{"cb940278":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd \nfrom skimage import io, color\nimport skimage\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\n\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","006aff69":"def display(img):\n    plt.figure()\n    plt.set_cmap('gray')\n    plt.imshow(img)\n    plt.show()\n\n\ndef combineLAB(l, a, b):\n    shape = (l.shape[0], l.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = l\n    zeros[:, :, 1] = a\n    zeros[:, :, 2] = b\n    return zeros\n\n\ndef combineAB(a, b):\n    shape = (a.shape[0], b.shape[1], 2)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = a\n    zeros[:, :, 1] = b\n    return zeros\n\n\ndef combineL_AB(l, ab):\n    shape = (l.shape[0], l.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = l\n    zeros[:, :, 1] = ab[:, :, 0]\n    zeros[:, :, 2] = ab[:, :, 1]\n    return zeros\n\n\ndef make3channels(gray):\n    shape = (gray.shape[0], gray.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = gray\n    zeros[:, :, 1] = gray\n    zeros[:, :, 2] = gray\n    return zeros\n\n\ndef get_l_from_gray(img_path):\n    img = io.imread(img_path)\n    img = skimage.transform.resize(img,(64,64))\n    gray = color.rgb2gray(img)\n    gray = make3channels(gray)\n    lgray = color.rgb2lab(gray, illuminant='D50')[:, :, 0]\n    return lgray\n\n\ndef get_ab_from_file(file):\n    img = io.imread(file)\n    ab = np.zeros((64, 64, 2))\n    ab[:, :, 0] = img[:, :, 1]\n    ab[:, :, 1] = img[:, :, 2]\n    return ab\n\n\ndef lab_normal_image(path):\n    l, ab = load_img_for_training(path)\n    l, ab = (l-127.5)\/127.5, (ab-127.5)\/127.5\n    return l, ab\n\n\ndef rgb_image(l, ab):\n    shape = (l.shape[0],l.shape[1],3)\n    img = np.zeros(shape)\n    img[:,:,0] = l[:,:,0]\n    img[:,:,1:]= ab\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    return img\n\n\ndef load_img_for_training(img_path):\n    img = io.imread(img_path)\n    img = skimage.transform.resize(img,(64,64))\n    lab = color.rgb2lab(img, illuminant='D50')\n    l, a, b = lab[:, :, 0], lab[:, :, 1], lab[:, :, 2]\n    ab = combineAB(a, b)\n    lgray = get_l_from_gray(img_path)\n    return lgray, ab\n\n\ndef save_ab_file(image, filepath):\n    # add in 0zeros to its first component\n    shape = (image.shape[0], image.shape[1], 3)\n    new_ab_image = np.zeros(shape)\n    new_ab_image[:, :, 1] = image[:, :, 0]\n    new_ab_image[:, :, 2] = image[:, :, 1]\n    save_file(new_ab_image, filepath)\n\n\ndef save_file(image, filepath):\n    io.imsave(filepath, image)\n\n\ndef load_ab_image(path):\n    img = io.imread(path)\n    shape = (img.shape[0], img.shape[1], 2)\n    ab = np.zeros(shape)\n    ab[:, :, 0] = img[:, :, 1]\n    ab[:, :, 1] = img[:, :, 2]\n    return ab\n","84162053":"# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","483c6861":"def normalize(image):\n    # convert image from range 0-256 to \n    #image = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n    image = image\/255\n    return image\n\ndef unnormalize(image):\n    image = (image*255)\n    return image.astype('uint8')","d3118cca":"gray_scale = np.load('\/kaggle\/input\/image-colorization\/l\/gray_scale.npy')[:6000]\nab_scale = np.load('\/kaggle\/input\/image-colorization\/ab\/ab\/ab1.npy')[:6000]\nprint(gray_scale.shape)\nprint(ab_scale.shape)","d67354ba":"index = 4579\nl_sample,ab_sample = gray_scale[index].reshape((224,224,1)),ab_scale[index]\nrgb_sample = rgb_image(l_sample,ab_sample)\ndisplay(rgb_sample)\ndisplay(l_sample[:,:,0])","072de82b":"x = np.zeros((6000,224,224,3), dtype='uint8')\n\nfor i in range(6000):\n    l_sample = (gray_scale[i]).reshape((224,224,1))\n    ab_sample = (ab_scale[i])\n    x[i] = rgb_image(l_sample, ab_sample)\n    \ndisplay(x[0])","61dbdbf9":"print(x[0])","3c47b38d":"x = x\/256.0","07e916bc":"from keras import *\nfrom keras.layers import *\nfrom keras.activations import *\nfrom keras.optimizers import *\nfrom matplotlib import pyplot as plt\nfrom utils import *\nfrom keras.initializers import RandomNormal, Zeros","820ee7e0":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, concatenate\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.applications.vgg16 import VGG16","5aa5c17e":"base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\ninclude_top = False, # Leave out the last fully connected layer\nweights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nbase_model.summary()\nencoder = base_model","0c15864e":"from keras.layers import *\n\ndec_input = Input((7,7,512))\n\ndec_x = ReLU()(dec_input)\n\nlayer_dim = [512, 256, 128, 64, 32]\n\nfor i in layer_dim:\n    dec_x = Conv2DTranspose(i, (2, 2), strides=(2, 2), padding='same', activation='relu')(dec_x)\n    dec_x = Conv2D(i, 2, padding='same', activation='relu')(dec_x)\n\n    \ndec_x = Conv2D(3,2,padding='same',activation='sigmoid')(dec_x)\n\ndecoder = Model(inputs=[dec_input], outputs=[dec_x])\ndecoder.compile(optimizer='adam', loss='mse', metrics=['acc'])\ndecoder.summary()","01828aca":"model_out = decoder(encoder.output)\nencoder.trainable=False\nmodel = Model(encoder.input, model_out)\nmodel.compile(optimizer='adam', loss='mae', metrics=['acc'])\nmodel.summary()","72e7f72e":"samples = x.shape[0]\nepochs = 100\nhistory = model.fit(x,x,validation_split=0.1,epochs=epochs,batch_size=64,)\nmodel.save('model.h5')","c0c3b59f":"h = history\nplt.plot(h.history['acc'])\nplt.plot(h.history['val_acc'])\nplt.title('Model accuracy')\nplt.show()\n\nplt.plot(h.history['loss'])\nplt.plot(h.history['val_loss'])\nplt.title('Model Loss')\nplt.show()\n\nplt.plot(h.history['acc'])\nplt.title('Model accuracy')\nplt.show()\n\nplt.plot(h.history['loss'])\nplt.title('Model Loss')\nplt.show()","5725cfd7":"def save_images(generator, samples):\n    ab_values = generator.predict(samples)\n    plt.figure()\n    plt.set_cmap('gray')\n    for i in range(ab_values.shape[0]):\n        rgb = unnormalize(ab_values[i])\n        display(rgb)\n        display(samples[i])\n        ax = plt.subplot(64, 64, i+1)\n        im = ax.imshow(rgb)\n        plt.tight_layout()\n        plt.title(i)\n    plt.show()\n    plt.savefig('gan_generated_image.png')\n\nsamples = x[0:10]\nsave_images(model,samples)","65597dda":"enc_x = encoder.predict(samples)\nprint(enc_x.shape)","9bb44c36":"dec_x = decoder.predict(enc_x)\nprint(dec_x.shape)","339c838a":"display(samples[2])","b03a0db5":"display(dec_x[2])","a55cb190":"encoder.save('enc.h5')","e0507fcc":"decoder.save('dec.h5')","7f72f800":"encoder.layers[-1].output.shape.as_list()","d71c8e1b":"decoder.layers[0].input.shape.as_list()","6932e8a4":"decoder.layers[0].input.shape.as_list() == encoder.layers[-1].output.shape.as_list()","9b9afb90":"**Data Loading**","43c62268":"**Architecture**","b52173e1":"**UTILS**"}}