{"cell_type":{"48a9bd6a":"code","ec822ca0":"code","6aebcf61":"code","37a407f2":"code","1adf89d8":"code","09f52677":"code","665fabb8":"code","467dee58":"code","6b0a92a9":"markdown","d8a067ff":"markdown","ebb7ee21":"markdown","2aecc864":"markdown","0426582c":"markdown","07a07b0f":"markdown","91da5d81":"markdown","67304f0e":"markdown"},"source":{"48a9bd6a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ec822ca0":"data=pd.read_csv('..\/input\/voice.csv')\ndata.head(5)","6aebcf61":"data.describe()","37a407f2":"sns.set()\nfig=plt.gcf()\nfig.set_size_inches(10,10)\nsns.countplot(data['label'])\nplt.show()","1adf89d8":"data=data.replace('male',1)\ndata=data.replace('female',0)\ndata.label.sample(5)","09f52677":"corr = data.corr()\nfig=plt.gcf()\nfig.set_size_inches(18,10)\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=90,\n    horizontalalignment='right'\n);","665fabb8":"x_train,x_test,y_train,y_test=train_test_split(data.drop('label',axis=1),data['label'],test_size=0.25)\nx_train.shape,y_train.shape","467dee58":"lr=LogisticRegression()\nnb=GaussianNB()\nknn=KNeighborsClassifier(n_neighbors=2)\nsgd=SGDClassifier(loss='modified_huber',shuffle=True)\ndtree=DecisionTreeClassifier(max_depth=10,min_samples_leaf=15)\nrfm=RandomForestClassifier(n_estimators=70)\nsvc=SVC(kernel='linear')\nlr.fit(x_train,y_train)\nnb.fit(x_train,y_train)\nknn.fit(x_train,y_train)\nsgd.fit(x_train,y_train)\ndtree.fit(x_train,y_train)\nrfm.fit(x_train,y_train)\nsvc.fit(x_train,y_train)\nprint('Accuracy of various algorithms on test data:-')\nprint('Logsitc Regression: '+str(lr.score(x_test,y_test)))\nprint('Na\u00efve Bayes: '+str(nb.score(x_test,y_test)))\nprint('Stochastic Gradient Descent: '+str(sgd.score(x_test,y_test)))\nprint('K-Nearest Neighbours: '+str(knn.score(x_test,y_test)))\nprint('Decision Tree: '+str(dtree.score(x_test,y_test)))\nprint('Random Forest: '+str(rfm.score(x_test,y_test)))\nprint('Support Vector Machine: '+str(svc.score(x_test,y_test)))\n","6b0a92a9":"<center><font size=4><b>Read data<\/b><\/font><\/center>","d8a067ff":"<center><font size=4><b>Train-Test split<\/b><\/font><\/center>\n* 75% -> train data\n* 25% -> test data","ebb7ee21":"<center><font size=4><b>Import necessary modules<\/b><\/font><\/center>\n* Basic modules\n* Modules for plotting\n* 7 types of classifiers ","2aecc864":"<center><font size=4><b>Checking data for discrepancies<\/b><\/font><\/center>\n* No discrepancies found","0426582c":"<center><font size=4><b>Checking for skewdness of data<\/b><\/font><\/center>\n* Data is not skewed\n* There are identical no. of entries for both labels","07a07b0f":"<center><font size=4><b>Applying models<\/b><\/font><\/center>","91da5d81":"<center><font size=4><b>Co-relation of all features<\/b><\/font><\/center>","67304f0e":"<center><font size=4><b>Encoding data<\/b><\/font><\/center>\n* Male -> 1\n* Female -> 0"}}