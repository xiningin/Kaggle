{"cell_type":{"9c20d6c6":"code","29ea5587":"code","7ba76af1":"code","3d568c02":"code","291574e1":"code","ca009b04":"code","d53a6afd":"code","660b28b4":"code","1d2ee731":"code","952540a6":"code","1208e96c":"code","bd7e9b46":"code","7f5c70d7":"markdown","20f99d68":"markdown","9c325943":"markdown","144e6f5b":"markdown","5a1b379c":"markdown","7c7daeff":"markdown","50ca208c":"markdown","7314b87d":"markdown","9bfa425a":"markdown","832202b4":"markdown"},"source":{"9c20d6c6":"# hardware info & setting\nimport torch, os\nprint('GPU available : ',torch.cuda.is_available())\nprint('GPU line-up   : ',torch.cuda.get_device_name())\nprint('GPU count     : ',torch.cuda.device_count())\nos.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\nprint('GPU current   : ',torch.cuda.current_device())\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu' ","29ea5587":"!pip install torchsummary\n\n# system \nimport os\nfrom glob import glob\nfrom datetime import datetime\n\n# util\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\n\n# torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torchsummary import summary\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport numpy as np\nfrom PIL import Image","7ba76af1":"# parameters \nrandom_seed = 42 #\ub09c\uc218 \ubc1c\uc0dd\uc744 \uc704\ud574\uc11c\ub294 \uc801\uc808\ud55c \uc2dc\ub4dc(seed)\ub97c \ub09c\uc218\ubc1c\uc0dd\uae30\uc5d0 \uc8fc\uc5b4\uc57c \ud55c\ub2e4. \ub9cc\uc57d \uc2dc\ub4dc\uac00 \uac19\ub2e4\uba74 \ub3d9\uc77c\ud55c \ub09c\uc218\ub97c \ubc1c\uc0dd\uc2dc\ud0a4\uac8c \ub41c\ub2e4. random.seed(a=None)\uc744 \ud1b5\ud574 \uc2dc\ub4dc\ub97c \uc124\uc815\ud560 \uc218 \uc788\ub2e4. \nlearning_rate = 0.001 \nbatch_size = 32 \nepochs = 15 \nimg_size = 32 #LeNet-5\uc758 input image\ub294 32x32\nn_classes = 10 # 0~9\uc758 \uc22b\uc790\ub97c \uc778\uc2dd\ud558\ub294 \uac83\uc774\ub77c Class\ub294 10\uac1c","3d568c02":"transform = transforms.Compose([transforms.Resize((32,32)), #transforms.Normalize((0,0,0),(1,1,1)) \/ transforms.Resize((256,256))\n                                transforms.ToTensor()])\n\n# [ CIFAR10 ]\ntrain_set = datasets.CIFAR10(root='.\/data', train=True,\n                                        download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntest_set = datasets.CIFAR10(root='.\/data', train=False,\n                                       download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\nprint('Num of classes : ',len(set(train_set.targets)))\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# print(train_set.data[5].max())\n# print(train_set.data[5].min())\nsample_img1 = cv2.resize(train_set.data[5],(32,32))\nsample_img2 = cv2.resize(train_set.data[6],(256, 256))\n\nprint('img shape : ',train_set.data[5].shape)\nprint('class : ',train_set.targets[5])\n\nfig, ax = plt.subplots(1,2,figsize=(10,5))\nax[0].imshow(sample_img1)\nax[0].set_title('%s %s-%s' % (sample_img1.shape,classes[train_set.targets[5]] ,train_set.targets[5]))\nax[1].imshow(sample_img2)\nax[1].set_title('%s %s-%s' % (sample_img2.shape, classes[train_set.targets[6]] ,train_set.targets[6]))\nplt.show()","291574e1":"img.size()","ca009b04":"# torch tensor type imshow\ndef show(img):\n    npimg = img.numpy()\n    npimg_tf = np.transpose(npimg,(1,2,0))\n    plt.imshow(npimg_tf,interpolation='nearest')\n\ndata_iter = iter(train_loader)\nimg,lbl = data_iter.next()\nshow(img[0])","d53a6afd":"# LeNet-5 : Input(32x32)\n\nclass LeNet5(torch.nn.Module):\n    def __init__(self,n_classes):\n        super(LeNet5,self).__init__()\n        self.feature_extractor = torch.nn.Sequential(\n            # 1. Convolution \n            torch.nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5,stride=1,padding=0),\n            torch.nn.Tanh(), # activation\n            \n            # 2. Subsampling\n            torch.nn.AvgPool2d(kernel_size=2,stride=2),\n            \n            # 3. Convolution\n            torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,stride=1,padding=0),\n            torch.nn.Tanh(),\n            \n            # 4. Subsampling\n            torch.nn.AvgPool2d(kernel_size=2,stride=2),\n            \n            # 5. Convolution\n            torch.nn.Conv2d(in_channels=16,out_channels=120,kernel_size=5,stride=1,padding=0),\n            torch.nn.Tanh(),    \n        )\n        self.classifier = torch.nn.Sequential(\n            # 6. Fully Connected\n            nn.Linear(in_features=120, out_features=84),\n            nn.Tanh(),\n            # 7. Fully Connected\n            nn.Linear(in_features=84, out_features=n_classes)\n        )\n    def forward(self,x):\n        \n        x = self.feature_extractor(x)\n        x = torch.flatten(x,1)\n        logits = self.classifier(x)\n        probs = F.softmax(logits,dim=1)\n        \n        return logits, probs\n\ntorch.manual_seed(random_seed)\nmodel = LeNet5(n_classes).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()\n\nsummary(model, (3, 32, 32))","660b28b4":"def get_accuracy(model, data_loader, device):\n    '''\n    Function for computing the accuracy of the predictions over the entire data_loader\n    '''\n    \n    correct_pred = 0 \n    n = 0\n    \n    with torch.no_grad():\n        model.eval()\n        for X, y_true in data_loader:\n\n            X = X.to(device)\n            y_true = y_true.to(device)\n\n            _, y_prob = model(X)\n            _, predicted_labels = torch.max(y_prob, 1)\n\n            n += y_true.size(0)\n            correct_pred += (predicted_labels == y_true).sum()\n\n    return correct_pred.float() \/ n\n\ndef plot_losses(train_losses, valid_losses):\n    '''\n    Function for plotting training and validation losses\n    '''\n    \n    # temporarily change the style of the plots to seaborn \n    plt.style.use('seaborn')\n\n    train_losses = np.array(train_losses) \n    valid_losses = np.array(valid_losses)\n\n    fig, ax = plt.subplots(figsize = (8, 4.5))\n\n    ax.plot(train_losses, color='blue', label='Training loss') \n    ax.plot(valid_losses, color='red', label='Validation loss')\n    ax.set(title=\"Loss over epochs\", \n            xlabel='Epoch',\n            ylabel='Loss') \n    ax.legend()\n    fig.show()\n    \n    # change the plot style to default\n    plt.style.use('default')\n\ndef train(train_loader, model, criterion, optimizer, device):\n    '''\n    Function for the training step of the training loop\n    '''\n\n    model.train()\n    running_loss = 0\n    \n    for X, y_true in train_loader:\n\n        optimizer.zero_grad()\n        \n        X = X.to(device)\n        y_true = y_true.to(device)\n    \n        # Forward pass\n        y_hat, _ = model(X) \n        loss = criterion(y_hat, y_true) \n        running_loss += loss.item() * X.size(0)\n\n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n    epoch_loss = running_loss \/ len(train_loader.dataset)\n    return model, optimizer, epoch_loss\n\ndef training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n    '''\n    Function defining the entire training loop\n    '''\n    \n    # set objects for storing metrics\n    best_loss = 1e10\n    train_losses = []\n    valid_losses = []\n \n    # Train model\n    for epoch in range(0, epochs):\n\n        # training\n        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n        train_losses.append(train_loss)\n\n        # validation\n        with torch.no_grad():\n            model, valid_loss = validate(valid_loader, model, criterion, device)\n            valid_losses.append(valid_loss)\n\n        if epoch % print_every == (print_every - 1):\n            \n            train_acc = get_accuracy(model, train_loader, device=device)\n            valid_acc = get_accuracy(model, valid_loader, device=device)\n                \n            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n                  f'Epoch: {epoch}\\t'\n                  f'Train loss: {train_loss:.4f}\\t'\n                  f'Valid loss: {valid_loss:.4f}\\t'\n                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n                  f'Valid accuracy: {100 * valid_acc:.2f}')\n\n    plot_losses(train_losses, valid_losses)\n    \n    return model, optimizer, (train_losses, valid_losses)\n\n\ndef validate(valid_loader, model, criterion, device):\n    '''\n    Function for the validation step of the training loop\n    '''\n   \n    model.eval()\n    running_loss = 0\n    \n    for X, y_true in valid_loader:\n    \n        X = X.to(device)\n        y_true = y_true.to(device)\n\n        # Forward pass and record loss\n        y_hat, _ = model(X) \n        loss = criterion(y_hat, y_true) \n        running_loss += loss.item() * X.size(0)\n\n    epoch_loss = running_loss \/ len(valid_loader.dataset)\n        \n    return model, epoch_loss","1d2ee731":"model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, test_loader, epochs, device)","952540a6":"ROW_IMG = 10\nN_ROWS = 5\n\nfig = plt.figure(figsize=(10,7))\nfor index in range(1, ROW_IMG * N_ROWS + 1):\n    plt.subplot(N_ROWS, ROW_IMG, index)\n    plt.axis('off')\n    plt.imshow(test_set.data[index], cmap='gray_r')\n    \n    with torch.no_grad():\n        model.eval()\n        _, probs = model(test_set[index][0].to(device).unsqueeze(0))\n        \n    title = f'{classes[torch.argmax(probs)]} ({torch.max(probs * 100):.0f}%)'\n    \n    plt.title(title, fontsize=7)\nfig.suptitle('LeNet-5 - predictions');","1208e96c":"torch.save(model,'.\/model.pt')","bd7e9b46":"#!rm -r data","7f5c70d7":"---\n# 8. Save Model","20f99d68":"# 0. Check Hardware Info","9c325943":"# Contents\n 0. [Check Hardware info](#0.-Check-Hardware-Info)\n 1. [Load Packages](#1.-Load-Packages)\n 2. [Hyperparameter](#2.-Hyperparameter)\n 3. [Check Datasets](#3.-Check-Datasets)\n 4. [Data Preprocessing](#4.-Data-Preprocessing) \n 5. [Model](#5.-Model)\n 6. [Train](#6.-Train)\n 7. [Evaluate](#7.-Evaluate)\n 8. [Save Model](#8.-Save-Model)\n ---","144e6f5b":"---\n# 7. Evaluate","5a1b379c":"---\n# 2. Hyperparameter","7c7daeff":"---\n# 5. Model Structure : LeNet 5","50ca208c":"---\n# 3. Check Datasets","7314b87d":"![image.png](attachment:c713dd93-0df4-43f3-8d82-a97a94614c10.png)","9bfa425a":"---\n# 1. Load Packages","832202b4":"---\n# 6. Train\n- additional functions\n    - get_accuracy : Extract accuracy\n    - plot_losses : Plot loss values\n    - train : Caculate Trainset Loss optimize\n    - train_loop : Calculate Epoch times\n    - valid : Caculate Testset Loss value\n- Train model with optimizer"}}