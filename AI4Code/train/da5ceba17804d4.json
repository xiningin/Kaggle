{"cell_type":{"1506d00f":"code","4f6eadf8":"code","164f3114":"code","742803f4":"code","b0661415":"code","427d4af8":"code","cf58e009":"code","1381d76f":"code","7a8e858e":"code","dbdc3f1e":"code","b1e80324":"code","6d05fc16":"code","c8600da2":"code","ad51b3db":"code","30ecfa46":"code","da8105e8":"code","02973b69":"code","13c899bf":"code","024e98a2":"code","1b1a3a27":"code","3fd68880":"code","74035781":"code","97309b59":"code","524fbb5a":"code","cd0085b6":"code","e7482cb6":"code","85736000":"code","321365a5":"code","cb0eb097":"code","8f1b91e7":"code","67e1546a":"code","fde63333":"code","ff2bca74":"code","d21dacc8":"code","4aba688b":"code","bf801ef0":"markdown","1a9c6098":"markdown","67f335ed":"markdown","bab5eda7":"markdown","c921ab60":"markdown","d8e16e4e":"markdown","80612a63":"markdown","d13bc659":"markdown"},"source":{"1506d00f":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport matplotlib\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold,KFold\nimport warnings\nimport os\nfrom six.moves import urllib\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nplt.style.use('seaborn')\nfrom scipy.stats import norm, skew\nimport plotly\nfrom plotly.plotly import iplot\nimport plotly.graph_objs as go","4f6eadf8":"os.listdir('..\/input\/')","164f3114":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","742803f4":"train = reduce_mem_usage(pd.read_csv('..\/input\/train.csv'))\ntest = reduce_mem_usage(pd.read_csv('..\/input\/test.csv'))\nmulliken = reduce_mem_usage(pd.read_csv('..\/input\/mulliken_charges.csv'))\ndipole = reduce_mem_usage(pd.read_csv('..\/input\/dipole_moments.csv'))\nstructure = reduce_mem_usage(pd.read_csv('..\/input\/structures.csv'))\npotential = reduce_mem_usage(pd.read_csv('..\/input\/potential_energy.csv'))\nmagnetic = reduce_mem_usage(pd.read_csv('..\/input\/magnetic_shielding_tensors.csv'))\nscaler = reduce_mem_usage(pd.read_csv('..\/input\/scalar_coupling_contributions.csv'))\nsub = reduce_mem_usage(pd.read_csv('..\/input\/sample_submission.csv'))","b0661415":"train.info()","427d4af8":"train.describe()","cf58e009":"train.head(10)","1381d76f":"print(mulliken.shape)\nprint(mulliken.head(10))","7a8e858e":"print(dipole.shape)\nprint(dipole.head(10))","dbdc3f1e":"print(structure.shape)\nprint(structure.head(10))","b1e80324":"print(magnetic.shape)\nprint(magnetic.head(5))","6d05fc16":"print(potential.shape)\nprint(potential.head(10))","c8600da2":"print(scaler.shape)\nprint(scaler.head(10))","ad51b3db":"#Check for Missing Values\n\nobs = train.isnull().sum().sort_values(ascending = False)\npercent = round(train.isnull().sum().sort_values(ascending = False)\/len(train)*100, 2)\npd.concat([obs, percent], axis = 1,keys= ['Number of Observations', 'Percent'])","30ecfa46":"def one_hot_encoder(data):\n    original_columns = data.columns.tolist()\n    categorical_columns = list(filter(lambda c: c in ['object'], data.dtypes))\n    new_data = pd.get_dummies(data, columns=categorical_columns)\n\n    new_columns = list(filter(lambda c: c not in original_columns, new_data.columns))\n    return new_data, new_columns","da8105e8":"#Distribution for Target Variable\nplotly.tools.set_credentials_file('roy.gupta','LIKu6GnqVhkB1BaoUuHP') # Please change the credentials in your version\n\ntrace1 = go.Histogram(\n    x= train['scalar_coupling_constant'],\n    opacity=0.75,\n    name = \"scalar_coupling_constant\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ndata = [trace1]\nlayout = go.Layout(barmode='overlay',\n                   title='Distribution of scalar coupling constant'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","02973b69":"import gc\ngc.collect()","13c899bf":"plotly.tools.set_credentials_file('roy.gupta','LIKu6GnqVhkB1BaoUuHP')\nexample = structure.loc[structure['molecule_name'] == 'dsgdb9nsd_000001']\ntrace1 = go.Scatter3d(\n    x=example['x'],\n    y=example['y'],\n    z=example['z'],\n    mode='markers',\n    marker=dict(\n        size=12,\n        line=dict(\n            color='rgba(217, 217, 217, 0.14)',\n            width=0.5\n        ),\n        opacity=0.8\n    )\n)\n\ndata = [trace1]\nlayout = go.Layout(\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0\n    )\n)\nfig = dict(data = data, layout = layout)\niplot(fig)","024e98a2":"gc.collect()","1b1a3a27":"# Plot the distribution of mulliken_charges\n#Distribution for Target Variable\nplotly.tools.set_credentials_file('roy.gupta','LIKu6GnqVhkB1BaoUuHP') # Please change the credentials in your version\n\ntrace1 = go.Histogram(\n    x= mulliken['mulliken_charge'],\n    opacity=0.75,\n    name = \"scalar_coupling_constant\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ndata = [trace1]\nlayout = go.Layout(barmode='overlay',\n                   title='Distribution of Mulliken Charges'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n","3fd68880":"gc.collect()","74035781":"# Plot the distribution of Potential Energy\n#Distribution for Target Variable\nplotly.tools.set_credentials_file('roy.gupta','LIKu6GnqVhkB1BaoUuHP') # Please change the credentials in your version\n\ntrace1 = go.Histogram(\n    x= potential['potential_energy'],\n    opacity=0.75,\n    name = \"scalar_coupling_constant\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ndata = [trace1]\nlayout = go.Layout(barmode='overlay',\n                   title='Potential Energy'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n","97309b59":"gc.collect()","524fbb5a":"scaler.groupby('type').count()['molecule_name'].sort_values().plot(kind='barh',\n                                                                color='grey',\n                                                               figsize=(15, 5),\n                                                               title='Count of Coupling Type in Train Set')\nplt.show()","cd0085b6":"def Eval_matrix(data, preds):\n    data[\"prediction\"] = preds\n    maes = []\n    for t in data.type.unique():\n        y_true = data[data.type==t].scalar_coupling_constant.values\n        y_pred = data[data.type==t].prediction.values\n        mae = np.log(metrics.mean_absolute_error(y_true, y_pred))\n        maes.append(mae)\n    return np.mean(maes)","e7482cb6":"smul = mulliken.merge(train)\nsns.pairplot(data=smul.sample(500), hue='type', vars=['mulliken_charge','scalar_coupling_constant'])\nplt.show()","85736000":"smg = magnetic.merge(train)\nsns.pairplot(data=smg.sample(500), hue='type', vars=['XX','YX','ZX','XY','YY','ZY','XZ','YZ','ZZ','scalar_coupling_constant'])\nplt.show()","321365a5":"scc = scaler.merge(train)\nsns.pairplot(data=scc.sample(500), hue='type', vars=['fc','sd','pso','dso','scalar_coupling_constant'])\nplt.show()","cb0eb097":"gc.collect()","8f1b91e7":"def map_atom_info(data, atom_idx):\n    data = pd.merge(data, structure, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    data = data.drop('atom_index', axis=1)\n    data = data.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return data\n\ntrain = map_atom_info(train, 0)\ntrain = map_atom_info(train, 1)\n\ntest = map_atom_info(test, 0)\ntest = map_atom_info(test, 1)","67e1546a":"# https:\/\/www.kaggle.com\/seriousran\/just-speed-up-calculate-distance-from-benchmark\ntrain_p_0 = train[['x_0', 'y_0', 'z_0']].values\ntrain_p_1 = train[['x_1', 'y_1', 'z_1']].values\ntest_p_0 = test[['x_0', 'y_0', 'z_0']].values\ntest_p_1 = test[['x_1', 'y_1', 'z_1']].values\n\ntrain['dist'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)\ntest['dist'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)","fde63333":"# make categorical variables\natom_map = {'H': 0,\n            'C': 1,\n            'N': 2}\ntrain['atom_0_cat'] = train['atom_0'].map(atom_map).astype('int')\ntrain['atom_1_cat'] = train['atom_1'].map(atom_map).astype('int')\ntest['atom_0_cat'] = test['atom_0'].map(atom_map).astype('int')\ntest['atom_1_cat'] = test['atom_1'].map(atom_map).astype('int')","ff2bca74":"# One Hot Encode the Type\ntrain_df = pd.concat([train, pd.get_dummies(train['type'])], axis=1)\ntest_df = pd.concat([test, pd.get_dummies(test['type'])], axis=1)","d21dacc8":"train['dist_to_type_mean'] = train['dist'] \/ train.groupby('type')['dist'].transform('mean')\ntest['dist_to_type_mean'] = test['dist'] \/ test.groupby('type')['dist'].transform('mean')","4aba688b":"train.head(10)","bf801ef0":"<pre><b>Evaluation Matrix<\/b>\n\nEvaluation metric is important to understand as it determines how your model will be scored. Ideally we will set the loss function of our machine learning algorithm to use this metric so we can minimize the specific type of error.\n\nCheck out this kernel by @abhishek with code for the evaluation metric: https:\/\/www.kaggle.com\/abhishek\/competition-metric\n<\/pre>","1a9c6098":"<pre>Relationship between Target and Magnetic Features<\/pre>","67f335ed":"<pre><b>Feature Creation<b>\nThis feature was found from @inversion 's kernel here: https:\/\/www.kaggle.com\/inversion\/atomic-distance-benchmark\/output \nThe code was then made faster by @seriousran here: https:\/\/www.kaggle.com\/seriousran\/just-speed-up-calculate-distance-from-benchmark<\/pre>","bab5eda7":"<pre>Relationship between Target and Scalar Coupling Features<\/pre>","c921ab60":"<pre> <b> Define Train and Test Set<\/b><\/pre>","d8e16e4e":"<pre>Prepare One Hot Encoder for Object Datatypes<\/pre>","80612a63":"<pre> Exploratory Analytics <\/pre>","d13bc659":"<pre> Relationship between Target and Mulliken Features"}}