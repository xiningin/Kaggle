{"cell_type":{"07382898":"code","b8942145":"code","0b8f6d80":"code","8434e0b9":"code","41d1939a":"code","606efb55":"code","08c05946":"code","03b24c03":"code","88af38e8":"code","942edb8a":"code","85442e6d":"code","7adb9d98":"code","6e9a3532":"code","ee233cb4":"code","e78d7b82":"code","43744c54":"code","76c91348":"code","8a9ba548":"markdown","417da70c":"markdown","ae2667c3":"markdown","fc65f07c":"markdown","e08fb4b2":"markdown","52285e48":"markdown","1a0bef21":"markdown"},"source":{"07382898":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy\nfrom sklearn import metrics, model_selection\nfrom sklearn.impute import SimpleImputer\n\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')","b8942145":"train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nsample_sub = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","0b8f6d80":"print(f'Train shape: {train.shape}, \\nTest shape: {test.shape}, \\nSubmission shape: {sample_sub.shape}')","8434e0b9":"train.describe()","41d1939a":"train.info()","606efb55":"train.isna().sum()","08c05946":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","03b24c03":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","88af38e8":"plt.rcParams[\"figure.figsize\"] = (12, 5)\nax = train['claim'].value_counts().sort_values().plot(kind=\"barh\")\ntotals= []\nfor i in ax.patches:\n    totals.append(i.get_width())\ntotal = sum(totals)\nfor i in ax.patches:\n     ax.text(i.get_width()+.3, i.get_y()+.20, \n     str(round((i.get_width()\/total)*100, 2))+'%', \n     fontsize=10, color='black')\nax.grid(axis=\"x\")\nplt.suptitle('Claim', fontsize=20)\nplt.show()","942edb8a":"'''\n>>> from sklearn.impute import SimpleImputer\n>>> imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n>>> imp.fit([[1, 2], [np.nan, 3], [7, 6]])\nSimpleImputer()\n>>> X = [[np.nan, 2], [6, np.nan], [7, 6]]\n>>> print(imp.transform(X))\n[[4.          2.        ]\n [6.          3.666...]\n [7.          6.        ]]\n'''","85442e6d":"y = train.claim.astype(int)","7adb9d98":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\ntrain = imputer.fit_transform(train.drop(['id', 'claim'], axis=1))\ntest = imputer.transform(test.drop('id', axis=1))","6e9a3532":"kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","ee233cb4":"test_preds = []\noof_auc = []\ntprs, aucs = [], []\nmean_fpr = np.linspace(0,1,100)\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(train, y)):\n    X_train, y_train = train[train_idx, :], y[train_idx]\n    X_val, y_val = train[val_idx, :], y[val_idx]\n\n    model = XGBClassifier(n_estimators=500, random_state=fold,predictor='gpu_predictor',\n                          tree_method='gpu_hist',eval_metric = 'auc')\n    model.fit(X_train, y_train)\n    \n    preds = model.predict_proba(X_val)[:, 1]\n    fpr, tpr, thresholds = metrics.roc_curve(y_val, preds)\n    tprs.append(scipy.interp(mean_fpr, fpr, tpr))\n    roc_auc = metrics.auc(fpr, tpr)\n    oof_auc.append(roc_auc)\n    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (fold, roc_auc))\n\n    test_preds.append(model.predict(test))\n    \nplt.plot([0,1], [0,1], linestyle='--', lw=2, color='black')\nmean_tpr = np.mean(tprs, axis=0)\nmean_auc = metrics.auc(mean_fpr, mean_tpr)\nplt.plot(mean_fpr, mean_tpr, color='blue', label=r'Mean ROC (AUC=%0.2f )'%(mean_auc), lw=2, alpha=1)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('K-Fold Validation')\nplt.legend(loc=\"lower right\")\nplt.show()","e78d7b82":"mode = scipy.stats.mode(test_preds)","43744c54":"sample_sub.claim = np.array(mode[0]).reshape(-1, 1)\nsample_sub.head()","76c91348":"sample_sub.to_csv('submission.csv', index=None)","8a9ba548":"# Reducing memory usage","417da70c":"# Submission","ae2667c3":"# Missing value imputation","fc65f07c":"> We have large number of missing values.","e08fb4b2":"# KFold ","52285e48":"# Let's plot `claim`","1a0bef21":"# Importing libraries\ud83d\udcda"}}