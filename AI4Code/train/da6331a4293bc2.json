{"cell_type":{"87e8d552":"code","4c5f930a":"code","95cb3cff":"code","30e598b6":"code","015bb030":"code","8dab1a39":"code","4e53f72d":"code","3c07a6ab":"code","a75292fe":"code","9567ba45":"code","eddcd988":"code","4f8d92f4":"code","f9fa2dcc":"code","6fc493cc":"code","15acdde9":"code","516048eb":"code","b93b4537":"code","0dd048b5":"code","f10de77f":"code","8f175776":"code","a51c6101":"code","390d8eb1":"code","23d76c72":"code","66b5b59c":"code","93d7ee65":"code","a141f04d":"code","b7912c37":"code","69cf33d9":"code","b0911ad1":"code","fe7468ff":"code","1ea0906b":"code","3662105c":"code","ba2e3790":"code","c42bf195":"code","9c6ee525":"code","17575e3f":"code","f861b2d3":"code","c5f89fdf":"code","c6e024bf":"code","a520ac26":"code","1c069412":"code","d9478865":"code","a6633068":"code","d68592f9":"code","6a32a58f":"code","ffd66bbf":"code","bb09afeb":"code","d9a4b19a":"code","177c26f0":"code","d6c8b6eb":"code","87630e0d":"code","40fda77d":"code","f5d9c264":"code","9e7549c8":"code","ea0e734b":"code","94da3ab4":"code","0a265af6":"markdown","e441b38b":"markdown","43794da7":"markdown","4895dc8d":"markdown","4c8e94d3":"markdown","d5414767":"markdown","34eb86e3":"markdown","63450b78":"markdown","5b130cfd":"markdown","85ccae09":"markdown","589faa69":"markdown","8ebe489b":"markdown"},"source":{"87e8d552":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns # visualization\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom eli5 import show_weights\nfrom sklearn import preprocessing\nfrom sklearn.pipeline import Pipeline\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\nimport string\nfrom wordcloud import WordCloud, STOPWORDS\nimport re\n\nfrom nltk.tokenize import RegexpTokenizer\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4c5f930a":"wine_file_path = '..\/input\/wine-reviews\/winemag-data-130k-v2.csv'\nwine_data = pd.read_csv(wine_file_path)\nwine_data","95cb3cff":"#MATTHEW CADENA\nprint(\"Columns with Number of Missing Entries:\")\nprint(wine_data.isnull().sum())","30e598b6":"#LJS\n\n#find outliers\ndef findOutliers(data_frame):\n    #mean, standard deviation and three standard deviations\n    data_mean = np.mean(data_frame)\n    data_std = np.std(data_frame)\n    three_stds = data_std *3\n\n    #looking for outlier data that is 3 std above or below the mean\n    lower_three_stds = data_mean - three_stds\n    upper_three_stds = data_mean + three_stds\n    \n    lower_outliers = [x for x in data_frame if x < lower_three_stds]\n    upper_outliers = [x for x in data_frame if x > upper_three_stds]\n    \n    without_outliers = [x for x in data_frame if x > lower_three_stds and x < upper_three_stds]\n    \n    num_lower = len(lower_outliers)\n    num_higher = len(upper_outliers)\n    num_total_outliers = num_lower + num_higher\n    num_non_outliers = len(without_outliers)\n    total = num_total_outliers + num_non_outliers\n    \n    print('Lower outliers: %d' % num_lower)\n    print('Upper outliers: %d' % num_higher)\n    print('Without outliers: %d' % num_non_outliers)\n    print(\"*********************\")\n    print('num total outliers: %d'% num_total_outliers )\n    print('total: %d' % total)\n    print('**********************')\n    print(\"Total PERCENT that are outliers: \", round(num_total_outliers\/total, 9)* 100)\n    ","015bb030":"#LJS\n\n#find the outlier data for points for all data\nfindOutliers(wine_data[\"price\"])","8dab1a39":"#MATTHEW CADENA\nwine_data.price.describe()\n#USED TO SEE THE INFO BEFORE MANIP","4e53f72d":"#MATTHEW CADENA\nq = wine_data[\"price\"].quantile(0.999)\nprint(q)\nwine_data_Outliers = wine_data[wine_data[\"price\"]<q]\nwine_data.price.describe()\n#USED TO SEE THE INFO AFTER MANIP","3c07a6ab":"#MATTHEW CADENA\n#THIS FILLS ANY MISSING ENTRIES WITH THE AVERAGE\nprice_avg = wine_data[\"price\"].mean()\n\nwine_data['price'].fillna(price_avg, inplace = True)","a75292fe":"#Cell removed #3\nwine_data = wine_data.dropna(subset=['country'])\n\n#replacing NaN with unknown for whole database\nwine_data = wine_data.replace('Unknown', np.NaN)\n\nwine_data.taster_name.fillna(\"Unknown\")\nwine_data.region_1.fillna(\"Unknown\")\n\nwine_data = wine_data[['country', 'province', 'region_1', 'winery', 'price', 'points', 'variety', 'title', 'taster_name', 'description']]\nwine_data.rename(columns={'region_1':'region'}, inplace = True)\nwine_data.head()\n\n","9567ba45":"#TIFFANY TRAN\nwine_data = wine_data.dropna(axis=0)","eddcd988":"wine_data[\"country\"] = wine_data[\"country\"].astype('category')\nwine_data[\"description\"] = wine_data[\"description\"].astype('category')\nwine_data[\"province\"] = wine_data[\"province\"].astype('category')\nwine_data[\"region\"] = wine_data[\"region\"].astype('category')\nwine_data[\"taster_name\"] = wine_data[\"taster_name\"].astype('category')\nwine_data[\"title\"] = wine_data[\"title\"].astype('category')\nwine_data[\"variety\"] = wine_data[\"variety\"].astype('category')\nwine_data[\"winery\"] = wine_data[\"winery\"].astype('category')","4f8d92f4":"wine_data[\"country codes\"] = wine_data[\"country\"].cat.codes\nwine_data[\"description codes\"] = wine_data[\"description\"].cat.codes\nwine_data[\"province codes\"] = wine_data[\"province\"].cat.codes\nwine_data[\"region codes\"] = wine_data[\"region\"].cat.codes\nwine_data[\"taster codes\"] = wine_data[\"taster_name\"].cat.codes\nwine_data[\"title codes\"] = wine_data[\"title\"].cat.codes\nwine_data[\"variety codes\"] = wine_data[\"variety\"].cat.codes\nwine_data[\"winery codes\"] = wine_data[\"winery\"].cat.codes\n\nwine_data.head()\n","f9fa2dcc":"wine_data.describe()","6fc493cc":"#LJS\n\n#information about price per country- how many, min, max for all data\n\nfrom learntools.pandas.grouping_and_sorting import *\nwine_data.groupby(['country']).price.agg([len,min,max])","15acdde9":"cData = wine_data.copy()","516048eb":"cData['description']= cData['description'].str.lower()\ncData['description']= cData['description'].apply(lambda elem: re.sub('[^a-zA-Z]',' ', elem))  \ncData['description']","b93b4537":"tokenizer = RegexpTokenizer(r'\\w+')\nwords_descriptions = cData['description'].apply(tokenizer.tokenize)\nwords_descriptions.head()","0dd048b5":"from collections import Counter\nall_words = [word for tokens in words_descriptions for word in tokens]\n\ncount_all_words = Counter(all_words)\ncount_all_words.most_common(100)","f10de77f":"stopword_list = stopwords.words('english')\nps = PorterStemmer()\nwords_descriptions = words_descriptions.apply(lambda elem: [word for word in elem if not word in stopword_list])\nwords_descriptions = words_descriptions.apply(lambda elem: [ps.stem(word) for word in elem])\ncData['description_cleaned'] = words_descriptions.apply(lambda elem: ' '.join(elem))","8f175776":"all_words = [word for tokens in words_descriptions for word in tokens]\nVOCAB = sorted(list(set(all_words)))\nprint(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))\ncount_all_words = Counter(all_words)\nlist_of_words = count_all_words.most_common(15)\nlist_of_words","a51c6101":"first_ele =  [x[0] for x in list_of_words]\nfirst_ele","390d8eb1":"index = 0\ndata1=pd.DataFrame()\ndata2=pd.DataFrame()\ndata3=pd.DataFrame()\ndata4=pd.DataFrame()\ndata5=pd.DataFrame()\ndata6=pd.DataFrame()\ndata7=pd.DataFrame()\ndata8=pd.DataFrame()\ndata9=pd.DataFrame()\ndata10=pd.DataFrame()\ndata11=pd.DataFrame()\ndata12=pd.DataFrame()\ndata13=pd.DataFrame()\ndata14=pd.DataFrame()\ndata15=pd.DataFrame()\ndfs = [data1,data2, data3, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13, data14, data15]\n#x = [pd.DataFrame() for x in dfs]\nwhile index < len(dfs):\n    dfs[index] = cData[cData['description'].str.contains(first_ele[index])]\n    index = index + 1","23d76c72":"sns.set_style(\"dark\")\nfig, axes = plt.subplots(nrows=5, ncols=3, figsize=(30,30))\n\nindex = 0\nrow = 0\ncol = 0\nwhile( index<len(dfs)):\n    y = dfs[index]['points'].value_counts()\n    x = y.index\n    axes[row,col].bar(x,y)\n    axes[row,col].set_title('Points Influenced by the keyword ' + first_ele[index])\n    index = index + 1\n    \n    if col == 2:\n        col = 0\n        row = row + 1\n        \n    elif col != 2:\n        col = col + 1","66b5b59c":"#LJS\n\n#distplot price distribution up to $500 by frequency for all data\nsns.set_style(\"dark\")\nplt.figure(figsize=(30,10))\n\n#graph = sns.distplot(wine_data['price'])\ngraph = sns.distplot(wine_data[wine_data['price'] < 500]['price'])\ngraph.set_title(\"Price Distribution up to $500\", fontsize=18)\ngraph.set_xlabel(\"Price\", fontsize=14)\ngraph.set_ylabel(\"Frequency Distribution\", fontsize=14)","93d7ee65":"#LJS\n\n#distplot price distribution up to $500 by frequency for non outlier data\n\nplt.figure(figsize=(12,5))\n\n#graph = sns.distplot(wine_data['price'])\ngraph = sns.distplot(wine_data_Outliers[wine_data_Outliers['price'] < 500]['price'])\ngraph.set_title(\"Price Distribution up to $500 without Outliers\", fontsize=18)\ngraph.set_xlabel(\"Price\", fontsize=14)\ngraph.set_ylabel(\"Frequency Distribution\", fontsize=14)","a141f04d":"#LJS\n\n#regplot of Points vs distribution of Price for all data\n\nplt.figure(figsize=(20,10))\n\ngraph = sns.regplot(x='points',y='price', data=wine_data, fit_reg = True)\ngraph.set_title(\"Points vs Distribution of Price\", fontsize=18)\ngraph.set_xlabel(\"Points\", fontsize=14)\ngraph.set_ylabel(\"Price Distribution\", fontsize=14)","b7912c37":"#MATTHEW CADENA\nsns.set_style(\"dark\")\nplt.title('Wine Price vs Wine Points', fontsize=40)\nplt.xlabel('Price Point', fontsize=20)\nplt.ylabel('Points', fontsize=20)\n#plt.show()\nplt.xlim([0,200])   \nplt.ylim([75,105])\ng = sns.regplot(x = wine_data['price'], y = wine_data['points'],scatter=False, ci = 99.99)\ng.figure.set_size_inches(20,10)","69cf33d9":"#TIFFANY TRAN\ngraph = wine_data[wine_data.price < 100].dropna().sample(5000)\nsns.kdeplot(graph.price, graph.points, shade=True, cmap=\"bone_r\")\nplt.xlabel(\"Price\", fontsize=15)\nplt.ylabel(\"Points\", fontsize=15)\nplt.yticks(fontsize=10)\nplt.xticks(fontsize=10)\nplt.title(\"Price and Points Correlation\", fontsize= 15)\nplt.suptitle('Sample Size 5000', fontsize= 10)","b0911ad1":"#TIFFANY TRAN\ngraph = wine_data_Outliers[wine_data_Outliers.price < 100].dropna().sample(5000)\nsns.kdeplot(graph.price, graph.points, shade=True, cmap=\"bone_r\")\nplt.xlabel(\"Price\", fontsize=15)\nplt.ylabel(\"Points\", fontsize=15)\nplt.yticks(fontsize=10)\nplt.xticks(fontsize=10)\nplt.title(\"Price and Points Correlation without Outliers\", fontsize= 15)\nplt.suptitle('Sample Size 5000', fontsize= 10)\nplt.figure(figsize=(10,10))","fe7468ff":"#MATTHEW CADENA\n#TOP 15 COUNTRIES BY WINE REVIEWS\nsns.set(font_scale = 1.5)\ng=sns.catplot(x=\"country\",kind=\"count\", palette=\"Spectral\",data = wine_data,order=pd.value_counts(wine_data['country']).iloc[:15].index)\ng.set_xticklabels(rotation=60)\n\ng.fig.set_size_inches(30,10)\ng.fig.suptitle('Top 15 Countries by Wine Reviews', fontsize=40)\nplt.ylabel(\"Wine Reviews\", fontsize = 25)\nplt.xlabel(\"Country\", fontsize = 25)","1ea0906b":"#TIFFANY TRAN\npoints_counts = wine_data['points'].value_counts()\nplt.figure(figsize=(25,10))\nsns.barplot(x = points_counts.index, y = points_counts)\nplt.title(\"Number of Wines in each Point Value\", fontsize = 40)\nplt.ylabel(\"Number of Wines\", fontsize = 25)\nplt.xlabel(\"Point Value\", fontsize = 25)","3662105c":"#LILLIAN\n#MATTHEW CADENA: ADDED THE ORDER PARAMETER TO CLEAN UP THE PLOT\n#TOP 15 VARIETY OF WINES\nsns.set(font_scale = 1.5)\ng=sns.catplot(x=\"variety\",kind=\"count\", palette=\"inferno_r\",data = wine_data,order=pd.value_counts(wine_data['variety']).iloc[:15].index)\ng.set_xticklabels(rotation=60)\ng.fig.set_size_inches(30,10)\nplt.title(\"Most Reviewed Wine Varieties\", fontsize = 40)\nplt.ylabel(\"Reviews\", fontsize = 25)\nplt.xlabel(\"Wine Variety\", fontsize = 25)","ba2e3790":"#BOXPLOT FOR THE TOP 20 VARIETIES OF WINE BASED ON POINTS\n#LILLIAN\n#MATTHEW CADENA: ADDED THE ORDER PARAMETER TO CLEAN UP GRAPH\nfig = plt.figure(figsize=(35,10))\ng = sns.boxplot(x=\"variety\", y=\"points\", data=wine_data,order=pd.value_counts(wine_data['variety']).iloc[:150].index)\ng.set_xticklabels(wine_data.variety, rotation = 270)\nplt.ylim([75,100])\n","c42bf195":"#MATTHEW CADENA\nfig = plt.figure(figsize=(35,10))\ng = sns.boxplot(x=\"winery\", y=\"points\", data=wine_data,order=pd.value_counts(wine_data['winery']).iloc[:100].index)\ng.set_xticklabels(wine_data.winery, rotation = 270)\nplt.ylim([75,100])\ng.set_title(\"Top 100 Wineries by Points\", fontsize = 40)\ng.set_xlabel(\"Winery\", fontsize=20)\ng.set_ylabel(\"Points\", fontsize =20)","9c6ee525":"#MATTHEW CADENA\nfig = plt.figure(figsize=(35,10))\ng = sns.boxplot(x=\"province\", y=\"points\", data=wine_data,order=pd.value_counts(wine_data['province']).iloc[:64].index)\ng.set_xticklabels(wine_data.winery, rotation = 270)\nplt.ylim([75,100])\ng.set_title(\"Top Wine Producing Provinces by Points\", fontsize = 40)\ng.set_xlabel(\"Province\", fontsize=20)\ng.set_ylabel(\"Points\", fontsize =20)","17575e3f":"sns.set_palette(sns.color_palette(\"colorblind\"))\n\nplt.figure(figsize=(10,10))\n\ncountry = wine_data.country.value_counts()[:5]\n\ngraph = sns.boxplot(x='country', y = \"points\", data=wine_data[(wine_data.country.isin(country.index.values))],order=pd.value_counts(wine_data['country']).iloc[:5].index)\ngraph.set_title(\"Top 5 Counries Based on Points\", fontsize=20)\ngraph.set_xlabel(\"Country\", fontsize=15)\ngraph.set_ylabel(\"Points\", fontsize=15)\ngraph.set_xticklabels(graph.get_xticklabels(), rotation = 45)\nplt.ylim([79,101])","f861b2d3":"#THIS NEEDS FIXING#\n#KINDA FIXED....*\n\n#Wine prices by country \ncountries =['Argentina','Italy', 'France', 'Spain', 'US', 'Chile', 'Portugal', 'New Zealand', 'Germany', 'South Africa']\nsub_data = wine_data[wine_data['country'].isin(countries)]\nplt.figure(figsize=(15,10))\nsns.set_context(\"paper\", font_scale=2.5)\n#sns.violinplot(x=\"country\", y=\"price\", data=sub_data,inner=None)\nsns.violinplot(x=\"country\", y=\"price\", data=wine_data,order=pd.value_counts(wine_data['country']).iloc[:15].index ,inner=None)\nplt.ylabel(\"Price\", fontsize=25)\nplt.xlabel(\"Country\", fontsize=25)\nplt.title(\"Top Ten Wine Producing Countrie and Their Wine Price Spread\", fontsize=40)\n#MATTHEW CADENA: I ADDED THE ORDER PARAMETER TO ONLY DISPLAY THE COUNTRIES IN THE 'COUNTRIES' LIST INSTEAD ALL THE COUNTRIES\n#Cris L\nplt.ylim(0,450)\nplt.xticks(rotation =90)\n","c5f89fdf":"#CRISTIAN LYNCH\n\n#Wines in the US\nwine_data_US = wine_data[wine_data['country'] == 'US']\nwine_data_US.head()","c6e024bf":"#CRISTIAN LYNCH\n\n#Top 5 wine variety in the US\nvalue_counts = wine_data_US[\"variety\"].value_counts()\nvalue_counts.head()","a520ac26":"#Plot of reviews by US provinces\nsns.set_style(\"dark\")\nplt.figure(figsize=(20, 10))\nplt.rc('xtick', labelsize=15)\nplt.rc('ytick', labelsize=15)\nsns.countplot(x=\"province\", data=wine_data_US,order=pd.value_counts(wine_data_US['province']).iloc[:5].index)\nplt.ylabel(\"Number of Reviews\", fontsize=25)\nplt.xlabel(\"Province\", fontsize=25)\nplt.title(\"Count of Reviews by province in US\", fontsize=40)\nplt.xticks(rotation=0)\nplt.show()\n#MATTHEW CADENA: I ADDED THE ORDER PARAMETER TO ONLY DISPLAY THE TOP 5 RATHER THAN EVERY PROVINCE\n#Cris L","1c069412":"y = wine_data.points\nfeatures = ['price', 'country codes', 'province codes', 'variety codes', 'winery codes', 'region codes']\nx = wine_data[features]\ntrain_x, val_x, train_y, val_y = train_test_split(x, y, random_state = 0)\nbasic_model = DecisionTreeRegressor()\nbasic_model.fit(train_x, train_y)\nval_predictions = basic_model.predict(val_x)\nprint(\"Printing MAE for Basic Decision Tree Regressor:\", mean_absolute_error(val_y, val_predictions))\n#Chris and Tiffany worked ","d9478865":"def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    leaf_model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    leaf_model.fit(train_x, train_y)\n    preds_val = leaf_model.predict(val_x)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_x, val_x, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %f\" %(max_leaf_nodes, my_mae))\n#Chris worked on this","a6633068":"forest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(train_x, train_y)\nforest_preds = forest_model.predict(val_x)\nprint(\"Printing MAE for RandomForest Model:\",mean_absolute_error(val_y, forest_preds)) #TIFFANY ADDED THIS LINE\n#Chris worked on this","d68592f9":"perm = PermutationImportance(basic_model, random_state=1).fit(val_x, val_y)\neli5.show_weights(perm, feature_names = val_x.columns.tolist())\n#Chris worked on this","6a32a58f":"#TIFFANY\n#choosing the prediction target\ny = wine_data.points\n\n#choosing features\nwine_features = ['price', 'country codes', 'province codes', 'variety codes', 'winery codes', 'region codes']\nX = wine_data[wine_features]\n\n#testing\n#X.describe()\nX.head()","ffd66bbf":"from sklearn.tree import DecisionTreeRegressor\nwine_model = DecisionTreeRegressor(random_state=1)\n\nwine_model.fit(X,y)","bb09afeb":"print(\"Making point predictions for the following 5 Wines:\")\nprint(X.head())\nprint(\"The points predictions are\")\nprint(wine_model.predict(X.head()))","d9a4b19a":"from sklearn.metrics import mean_absolute_error\n\npredicted_wine_points = wine_model.predict(X)\nprint(\"Printing the mean absolute error\", mean_absolute_error(y, predicted_wine_points))","177c26f0":"Currently we will be splitting the data to have better results","d6c8b6eb":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(X,y, random_state = 0)\n\nwine_model = DecisionTreeRegressor()\n\nwine_model.fit(train_X,train_y)\n\n#getting predicted points\nval_predictions = wine_model.predict(val_X)\nprint(\"Using the DecisionTreeRegressor.. Now\\nPrinting the mean absolute value \",mean_absolute_error(val_y, val_predictions))","87630e0d":"#CHRISTOPHER MUCHKENFUSS\n\n\npipe_data = pd.read_csv(wine_file_path)\n\npipe_data.dropna(axis=0, inplace=True)\ny = pipe_data.points\n#pipe_data.drop(['price'], axis=1, inplace=True)\n\n \n\n\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(pipe_data, y, \n                                                                train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n# Select categorical columns\ncategorical_cols = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].nunique() < 10000 and \n                    X_train_full[cname].dtype == \"object\"]\n\n \n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train_full.columns if \n                X_train_full[cname].dtype in ['int64', 'float64']]\n\n \n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\n#X_test = X_test_full[my_cols].copy()\n\n \n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n \n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n \n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n \n\n# Define model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\n\n \n\n# Bundle preprocessing and modeling code in a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)\n                     ])\n\n \n\n# Preprocessing of training data, fit model \nclf.fit(X_train, y_train)\n\n \n\n# Preprocessing of validation data, get predictions\npreds = clf.predict(X_valid)\n\nprint('MAE Using Pipeline:', mean_absolute_error(y_valid, preds))","40fda77d":"#TIFFANY\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nmy_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n                              ('model',\n                               RandomForestRegressor(n_estimators=50,random_state=0))])","f5d9c264":"#TIFFANY\nfrom sklearn.model_selection import cross_val_score\n\npoints_CV = -1 * cross_val_score(my_pipeline, X, y, cv=5, \n                              scoring = 'neg_mean_absolute_error')\nprint(\"Using Cross Validation..\\nNow Printing Mean Absolute Error points:\\n\",\n      points_CV)","9e7549c8":"#TIFFANY TRAN\nprint(\"Using Cross Validation..\\nNow Printing Average Mean Absolute Error points across all experiments: \\n\", points_CV.mean())","ea0e734b":"#TIFFANY TRAN\nfrom xgboost import XGBRegressor\n\nxgbr_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\nxgbr_model.fit(train_X, train_y, \n             early_stopping_rounds=5, \n             eval_set=[(val_X, val_y)], \n             verbose=False)","94da3ab4":"#TIFFANY TRAN\nfrom sklearn.metrics import mean_absolute_error\n\npredictionsXBGR = xgbr_model.predict(val_X)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictionsXBGR, val_y)))","0a265af6":"# Model Visualization\nWe have just looked at all the graphs and data visualization for this dataset. We will now work with the data to build models and predict certain things. Frst we will create a basic model look at the Mean Absolute Error.","e441b38b":"# US Data\nWe will take a quick look at wine data pertaining to the US, seeing as it contains the most reviews","43794da7":"## Data Explanation\/Exploration\nFirst we look at the raw data that we imported to wee what we are working with.","4895dc8d":"Now we will look at the Random Forest Regressor model","4c8e94d3":"Now we will be using the basic Decision Tree and adding Leaf Nodes to try and focus the data","d5414767":"# Dealing with Outliers and Missing Data\nWe nod trim the data to remove some extreme outliers for the price columns as well as fill empty entries with the mean value","34eb86e3":"Lets take a look at information regarding missing entries","63450b78":"# Description Clean Up\nWe will now begin our visuals by looking at the 15 most frequent relevant words and looking at how wine reviews containing those words affect their point spread","5b130cfd":"Prediciting The Error, How far I am off from the actual. [error = actual - predicted]","85ccae09":"# Wine Data Group Notebook\nWe will be exploring a wine dataset to create visuals tha will allow us to visualize the relationship between different aspects of the data as well as create models to help predict beneficial wine making practices","589faa69":"# Using a Pipeline","8ebe489b":"# Data Visualization\nWe will now look at various relationships between different aspects of the wine data set"}}