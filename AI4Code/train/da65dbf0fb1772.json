{"cell_type":{"906c9294":"code","67c3d5e1":"code","2cd6ced2":"code","0243d6e4":"code","0bbaf654":"code","ccaa9769":"code","996a4be9":"code","ab851ff4":"code","2d615d91":"code","93dfe2dd":"code","f6d94a53":"code","5e5511fe":"code","07a8d47b":"code","58c9c5d6":"code","0c3522e2":"code","25b9ca5f":"code","2535b3f5":"code","656c479d":"code","3af72725":"code","22e06d0f":"code","2e673364":"code","45d3fba4":"code","d42e4589":"code","6172098e":"code","8f2006d4":"code","ab41535a":"code","bf28f3f2":"code","87cb9337":"code","488526f7":"code","62a22869":"code","6533ff9b":"code","245567bc":"code","31475a49":"code","fdbb594b":"code","f529d2da":"markdown","c93f0aad":"markdown","06fa593f":"markdown","92c57051":"markdown","494d45b8":"markdown","bd8b1d84":"markdown","cb707b81":"markdown","482b4a2a":"markdown","2af9b213":"markdown","79c96a50":"markdown","487f319f":"markdown","5dd3faaf":"markdown","6e2c067b":"markdown","6ee69535":"markdown","120c19b6":"markdown","20440e43":"markdown","6270e2d4":"markdown","dfc01c9a":"markdown"},"source":{"906c9294":"import spacy\nfrom spacy import displacy\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom spacy.tokens import Span","67c3d5e1":"#loading the language library\nnlp = spacy.load('en_core_web_sm') \n## larger language library can be load via `en_core_web_lg` ","2cd6ced2":"# create your first text document\ndoc = nlp(u'Google acquired Kaggle for the $500 million a few years ago.')","0243d6e4":"## token operations\nfor token in doc:\n    print(f'Word: {token.text} \\nPart of Speech: {token.pos_} \\nSyntactic Dependancy: {token.dep_} \\n ****----***')","0bbaf654":"##directly accessing tokens via indices\nprint(doc[2].text,doc[3].pos_)","ccaa9769":"## SPaCy NLP pipeline available operations\nnlp.pipe_names","996a4be9":"## Parsing sentences in SPaCy\ndoc2 = nlp(u'This is the first sentence. This is the second sentence. This is the third sentence. This is the fourth sentence. ')\n\nfor sentence in doc2.sents:\n    print(f'{sentence}')","ab851ff4":"myString = '\"We\\'re moving to L.A.!\"'\ndoc3 = nlp(myString)\nfor token in doc3:\n    print(token.text)","2d615d91":"##Prefixes, Suffixes, Infixes\ndoc4 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http:\/\/www.oursite.com!\")\n\nfor t in doc4:\n    print(t)","93dfe2dd":"## extracting named entities\nmyString2 = 'Google is going to start a new research lab in Europe by investing $6 million'\ndoc5 = nlp(myString2)\nfor entity in doc5.ents:\n    print(entity)\n    print(entity.label_)\n    print(str(spacy.explain(entity.label_)))\n    print('****----***')","f6d94a53":"## visualizing syntatic dependencies \ndisplacy.render(doc5, style='dep', jupyter=True, options={'distance': 50})","5e5511fe":"## visualizing entities \ndisplacy.render(doc5, style='ent', jupyter=True, options={'distance': 50})","07a8d47b":"p_stemmer  = PorterStemmer()\nsnowball_stemmer = SnowballStemmer(language='english')\nwords = ['run','runner','runs','easily','fairly']\n","58c9c5d6":"for word in words:\n    print(f'{word} \\n snowball: {snowball_stemmer.stem(word)} porter: {p_stemmer.stem(word)}')\n    print('****----***')","0c3522e2":"doc5 = nlp(u'he ran with 50 other runners and fairly won the race easily while running continously')\nfor token in doc5:\n    print(f'{token} --> {token.lemma_}')\n    print('****----***')","25b9ca5f":"list(nlp.Defaults.stop_words)[:10]","2535b3f5":"doc6 = nlp(u'btw he is not generous to everyone.')\nfor word in doc6:\n    print(f'{word.text} --> is stopword: {word.is_stop}')","656c479d":"## add your custom stop word\nnlp.Defaults.stop_words.add('btw')","3af72725":"for word in doc6:\n    print(f'{word.text} --> is stopword: {word.is_stop}')","22e06d0f":"doc7 = nlp(u'The quick brown fox jumped over the lazy dog\\'s back.')","2e673364":"for token in doc7:\n    print(f'{token.text:{10}}{token.pos_:{10}}{token.tag_:{10}}{spacy.explain(token.tag_)}')","45d3fba4":"pos_counts = doc7.count_by(spacy.attrs.POS)\nfor key,value in sorted(pos_counts.items()):\n    print(f'{doc7.vocab[key].text} {value}')","d42e4589":"## visualizing POS tags\ndisplacy.render(doc7, style='dep', jupyter=True, options={'distance': 50})","6172098e":"options = {'distance': 80, 'compact': 'True', 'color': 'yellow', 'bg': '#09a3d5', 'font': 'Times'}\ndisplacy.render(doc7, style='dep', options=options)","8f2006d4":"def show_ners(doc):\n    if doc.ents:\n        for ent in doc.ents:\n            print(f'{ent.text:{10}} {str(spacy.explain(ent.label_)):{10}}')\n    else:\n        print('now entities found...')","ab41535a":"show_ners(nlp(u'hi! how are you?'))","bf28f3f2":"show_ners(nlp(u'In London I read the Harry Potter last week that was pretty interesting and fascinating, \\\nI loved Hogwarts school.'))","87cb9337":"## add custom entities to your vocabulary\n## I'll be adding OpenAI as a company\n\ndoc10 = nlp(u'In America, OpenAI is doing state-of-the-art research in reinforcement learning and Computer Science')\nORG = doc10.vocab.strings[u'ORG']\nnew_ent = Span(doc10,0,1,label=ORG)\ndoc10.ents = list(doc10.ents) + [new_ent]","488526f7":"show_ners(doc10)","62a22869":"## visualizing NERs\ndoc11 = nlp(u'Google is going to start a new research lab in Europe by investing $6 million')\noptions = {'ents': ['ORG', 'PRODUCT']}","6533ff9b":"displacy.render(doc11, style='ent', jupyter=True, options=options)","245567bc":"def set_custom_boundaries(doc):\n    for token in doc[:-1]: #so that we can't get index out of range\n        if token.text == ';':\n            doc[token.i+1].is_sent_start = True\n    return doc\n","31475a49":"nlp.add_pipe(set_custom_boundaries, before='parser') #runs before parser in the pipeline","fdbb594b":"doc12 = nlp(u'Management is doing things right; leadership is doing the right things. -PeterDrucker')\n\nfor sent in doc12.sents:\n    print(sent)","f529d2da":"## Tokenization in detail\n![Screenshot-min.png](attachment:Screenshot-min.png)","c93f0aad":"as you can see lemmatization is more effective like looking at the words like ``won -> win, running -> run``","06fa593f":"you can see ``btw`` is now a stop word","92c57051":"# 2. Parts of Speech\n___\n## Fine-grained Part-of-speech Tags\nTokens are subsequently given a fine-grained tag as determined by morphology:\n<table>\n<tr><th>POS<\/th><th>Description<\/th><th>Fine-grained Tag<\/th><th>Description<\/th><th>Morphology<\/th><\/tr>\n<tr><td>ADJ<\/td><td>adjective<\/td><td>AFX<\/td><td>affix<\/td><td>Hyph=yes<\/td><\/tr>\n<tr><td>ADJ<\/td><td><\/td><td>JJ<\/td><td>adjective<\/td><td>Degree=pos<\/td><\/tr>\n<tr><td>ADJ<\/td><td><\/td><td>JJR<\/td><td>adjective, comparative<\/td><td>Degree=comp<\/td><\/tr>\n<tr><td>ADJ<\/td><td><\/td><td>JJS<\/td><td>adjective, superlative<\/td><td>Degree=sup<\/td><\/tr>\n<tr><td>ADJ<\/td><td><\/td><td>PDT<\/td><td>predeterminer<\/td><td>AdjType=pdt PronType=prn<\/td><\/tr>\n<tr><td>ADJ<\/td><td><\/td><td>PRP\\$<\/td><td>pronoun, possessive<\/td><td>PronType=prs Poss=yes<\/td><\/tr>\n<tr><td>ADJ<\/td><td><\/td><td>WDT<\/td><td>wh-determiner<\/td><td>PronType=int rel<\/td><\/tr>\n<tr><td>ADJ<\/td><td><\/td><td>WP\\$<\/td><td>wh-pronoun, possessive<\/td><td>Poss=yes PronType=int rel<\/td><\/tr>\n<tr><td>ADP<\/td><td>adposition<\/td><td>IN<\/td><td>conjunction, subordinating or preposition<\/td><td><\/td><\/tr>\n<tr><td>ADV<\/td><td>adverb<\/td><td>EX<\/td><td>existential there<\/td><td>AdvType=ex<\/td><\/tr>\n<tr><td>ADV<\/td><td><\/td><td>RB<\/td><td>adverb<\/td><td>Degree=pos<\/td><\/tr>\n<tr><td>ADV<\/td><td><\/td><td>RBR<\/td><td>adverb, comparative<\/td><td>Degree=comp<\/td><\/tr>\n<tr><td>ADV<\/td><td><\/td><td>RBS<\/td><td>adverb, superlative<\/td><td>Degree=sup<\/td><\/tr>\n<tr><td>ADV<\/td><td><\/td><td>WRB<\/td><td>wh-adverb<\/td><td>PronType=int rel<\/td><\/tr>\n<tr><td>CONJ<\/td><td>conjunction<\/td><td>CC<\/td><td>conjunction, coordinating<\/td><td>ConjType=coor<\/td><\/tr>\n<tr><td>DET<\/td><td>determiner<\/td><td>DT<\/td><td>determiner<\/td><td><\/td><\/tr>\n<tr><td>INTJ<\/td><td>interjection<\/td><td>UH<\/td><td>interjection<\/td><td><\/td><\/tr>\n<tr><td>NOUN<\/td><td>noun<\/td><td>NN<\/td><td>noun, singular or mass<\/td><td>Number=sing<\/td><\/tr>\n<tr><td>NOUN<\/td><td><\/td><td>NNS<\/td><td>noun, plural<\/td><td>Number=plur<\/td><\/tr>\n<tr><td>NOUN<\/td><td><\/td><td>WP<\/td><td>wh-pronoun, personal<\/td><td>PronType=int rel<\/td><\/tr>\n<tr><td>NUM<\/td><td>numeral<\/td><td>CD<\/td><td>cardinal number<\/td><td>NumType=card<\/td><\/tr>\n<tr><td>PART<\/td><td>particle<\/td><td>POS<\/td><td>possessive ending<\/td><td>Poss=yes<\/td><\/tr>\n<tr><td>PART<\/td><td><\/td><td>RP<\/td><td>adverb, particle<\/td><td><\/td><\/tr>\n<tr><td>PART<\/td><td><\/td><td>TO<\/td><td>infinitival to<\/td><td>PartType=inf VerbForm=inf<\/td><\/tr>\n<tr><td>PRON<\/td><td>pronoun<\/td><td>PRP<\/td><td>pronoun, personal<\/td><td>PronType=prs<\/td><\/tr>\n<tr><td>PROPN<\/td><td>proper noun<\/td><td>NNP<\/td><td>noun, proper singular<\/td><td>NounType=prop Number=sign<\/td><\/tr>\n<tr><td>PROPN<\/td><td><\/td><td>NNPS<\/td><td>noun, proper plural<\/td><td>NounType=prop Number=plur<\/td><\/tr>\n<tr><td>PUNCT<\/td><td>punctuation<\/td><td>-LRB-<\/td><td>left round bracket<\/td><td>PunctType=brck PunctSide=ini<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>-RRB-<\/td><td>right round bracket<\/td><td>PunctType=brck PunctSide=fin<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>,<\/td><td>punctuation mark, comma<\/td><td>PunctType=comm<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>:<\/td><td>punctuation mark, colon or ellipsis<\/td><td><\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>.<\/td><td>punctuation mark, sentence closer<\/td><td>PunctType=peri<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>''<\/td><td>closing quotation mark<\/td><td>PunctType=quot PunctSide=fin<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>\"\"<\/td><td>closing quotation mark<\/td><td>PunctType=quot PunctSide=fin<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>``<\/td><td>opening quotation mark<\/td><td>PunctType=quot PunctSide=ini<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>HYPH<\/td><td>punctuation mark, hyphen<\/td><td>PunctType=dash<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>LS<\/td><td>list item marker<\/td><td>NumType=ord<\/td><\/tr>\n<tr><td>PUNCT<\/td><td><\/td><td>NFP<\/td><td>superfluous punctuation<\/td><td><\/td><\/tr>\n<tr><td>SYM<\/td><td>symbol<\/td><td>#<\/td><td>symbol, number sign<\/td><td>SymType=numbersign<\/td><\/tr>\n<tr><td>SYM<\/td><td><\/td><td>\\$<\/td><td>symbol, currency<\/td><td>SymType=currency<\/td><\/tr>\n<tr><td>SYM<\/td><td><\/td><td>SYM<\/td><td>symbol<\/td><td><\/td><\/tr>\n<tr><td>VERB<\/td><td>verb<\/td><td>BES<\/td><td>auxiliary \"be\"<\/td><td><\/td><\/tr>\n<tr><td>VERB<\/td><td><\/td><td>HVS<\/td><td>forms of \"have\"<\/td><td><\/td><\/tr>\n<tr><td>VERB<\/td><td><\/td><td>MD<\/td><td>verb, modal auxiliary<\/td><td>VerbType=mod<\/td><\/tr>\n<tr><td>VERB<\/td><td><\/td><td>VB<\/td><td>verb, base form<\/td><td>VerbForm=inf<\/td><\/tr>\n<tr><td>VERB<\/td><td><\/td><td>VBD<\/td><td>verb, past tense<\/td><td>VerbForm=fin Tense=past<\/td><\/tr>\n<tr><td>VERB<\/td><td><\/td><td>VBG<\/td><td>verb, gerund or present participle<\/td><td>VerbForm=part Tense=pres Aspect=prog<\/td><\/tr>\n<tr><td>VERB<\/td><td><\/td><td>VBN<\/td><td>verb, past participle<\/td><td>VerbForm=part Tense=past Aspect=perf<\/td><\/tr>\n<tr><td>VERB<\/td><td><\/td><td>VBP<\/td><td>verb, non-3rd person singular present<\/td><td>VerbForm=fin Tense=pres<\/td><\/tr>\n<tr><td>VERB<\/td><td><\/td><td>VBZ<\/td><td>verb, 3rd person singular present<\/td><td>VerbForm=fin Tense=pres Number=sing Person=3<\/td><\/tr>\n<tr><td>X<\/td><td>other<\/td><td>ADD<\/td><td>email<\/td><td><\/td><\/tr>\n<tr><td>X<\/td><td><\/td><td>FW<\/td><td>foreign word<\/td><td>Foreign=yes<\/td><\/tr>\n<tr><td>X<\/td><td><\/td><td>GW<\/td><td>additional word in multi-word expression<\/td><td><\/td><\/tr>\n<tr><td>X<\/td><td><\/td><td>XX<\/td><td>unknown<\/td><td><\/td><\/tr>\n<tr><td>SPACE<\/td><td>space<\/td><td>_SP<\/td><td>space<\/td><td><\/td><\/tr>\n<tr><td><\/td><td><\/td><td>NIL<\/td><td>missing tag<\/td><td><\/td><\/tr>\n<\/table>","494d45b8":"## Lemmatization","bd8b1d84":"Purpose of this notebook is give a **brief idea on NLP.** As we all know that there are various different approaches to solve any NLP problem. For eg: Frequency based model like Tfidf and various Prediction based model like Word2Vec. <br>  \n\nThis tutorial assumes that you've absolutely no prior knowledge of NLP and SPaCy which is a really handy library for performing niche NLP tasks efficiently and gives you alot of flexibility while performing them. <br>\n\nTherefore i decided to make a kernel on **GETTING STARTED IN NLP** <br>\n\n## Give your Upvotes and comment down your suggestion so that we together improve this kernel :)\n","cb707b81":"## Stemming\n** there's no stemmer in SPaCy so we're using NLTK**","482b4a2a":"___\n## Additional Token Attributes\nWe'll see these again in upcoming lectures. For now we just want to illustrate some of the other information that spaCy assigns to tokens:\n\n|Tag|Description|doc2[0].tag|\n|:------|:------:|:------|\n|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Google`|\n|`.lemma_`|The base form of the word|`google`|\n|`.pos_`|The simple part-of-speech tag|`PROPN`\/`proper noun`|\n|`.tag_`|The detailed part-of-speech tag|`NNP`\/`noun, proper singular`|\n|`.shape_`|The word shape \u2013 capitalization, punctuation, digits|`Xxxxx`|\n|`.is_alpha`|Is the token an alpha character?|`True`|\n|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|","2af9b213":"## Stop words in SPaCy","79c96a50":"That's all for the first part of this tutorial coming up in the second part of tutorial is:\n\n* **Text Classification**\n* **Semantics & Sentiment Analysis**\n* **Topic Modelling**\n\n# PLEASE UPVOTE IF THIS KERNEL HELPED YOU. STAY TUNED!!","487f319f":"![](https:\/\/miro.medium.com\/max\/770\/1*yfr3m-JjwQLucxIsThIJGQ.jpeg)\n","5dd3faaf":"___\n## Pipeline\nWhen we run `nlp`, our text enters a *processing pipeline* that first breaks down the text and then performs a series of operations to tag, parse and describe the data.   Image source: https:\/\/spacy.io\/usage\/spacy-101#pipelines\n\n![pipeline1.png](attachment:pipeline1.png)","6e2c067b":"# NLP Bootcamp: Part 1 of 3\n\n <a>1. NLP & SPaCy Basics <\/a> <br>\n <a>2. Parts of Speech<\/a><br>\n <a>3. Named Entity Recognition<\/a><br>\n <a>4. Sentence Segmentation<\/a><br>\n","6ee69535":"# 3. Named Entity Recognition\n\nEntities refer to name of a person, place, time etc, which can be really the decision making piece of information in the paradigm of NLP.\n## NER Tags\nTags are accessible through the `.label_` property of an entity.\n<table>\n<tr><th>TYPE<\/th><th>DESCRIPTION<\/th><th>EXAMPLE<\/th><\/tr>\n<tr><td>`PERSON`<\/td><td>People, including fictional.<\/td><td>*Fred Flintstone*<\/td><\/tr>\n<tr><td>`NORP`<\/td><td>Nationalities or religious or political groups.<\/td><td>*The Republican Party*<\/td><\/tr>\n<tr><td>`FAC`<\/td><td>Buildings, airports, highways, bridges, etc.<\/td><td>*Logan International Airport, The Golden Gate*<\/td><\/tr>\n<tr><td>`ORG`<\/td><td>Companies, agencies, institutions, etc.<\/td><td>*Microsoft, FBI, MIT*<\/td><\/tr>\n<tr><td>`GPE`<\/td><td>Countries, cities, states.<\/td><td>*France, UAR, Chicago, Idaho*<\/td><\/tr>\n<tr><td>`LOC`<\/td><td>Non-GPE locations, mountain ranges, bodies of water.<\/td><td>*Europe, Nile River, Midwest*<\/td><\/tr>\n<tr><td>`PRODUCT`<\/td><td>Objects, vehicles, foods, etc. (Not services.)<\/td><td>*Formula 1*<\/td><\/tr>\n<tr><td>`EVENT`<\/td><td>Named hurricanes, battles, wars, sports events, etc.<\/td><td>*Olympic Games*<\/td><\/tr>\n<tr><td>`WORK_OF_ART`<\/td><td>Titles of books, songs, etc.<\/td><td>*The Mona Lisa*<\/td><\/tr>\n<tr><td>`LAW`<\/td><td>Named documents made into laws.<\/td><td>*Roe v. Wade*<\/td><\/tr>\n<tr><td>`LANGUAGE`<\/td><td>Any named language.<\/td><td>*English*<\/td><\/tr>\n<tr><td>`DATE`<\/td><td>Absolute or relative dates or periods.<\/td><td>*20 July 1969*<\/td><\/tr>\n<tr><td>`TIME`<\/td><td>Times smaller than a day.<\/td><td>*Four hours*<\/td><\/tr>\n<tr><td>`PERCENT`<\/td><td>Percentage, including \"%\".<\/td><td>*Eighty percent*<\/td><\/tr>\n<tr><td>`MONEY`<\/td><td>Monetary values, including unit.<\/td><td>*Twenty Cents*<\/td><\/tr>\n<tr><td>`QUANTITY`<\/td><td>Measurements, as of weight or distance.<\/td><td>*Several kilometers, 55kg*<\/td><\/tr>\n<tr><td>`ORDINAL`<\/td><td>\"first\", \"second\", etc.<\/td><td>*9th, Ninth*<\/td><\/tr>\n<tr><td>`CARDINAL`<\/td><td>Numerals that do not fall under another type.<\/td><td>*2, Two, Fifty-two*<\/td><\/tr>\n<\/table>","120c19b6":"# 4. Sentence Segmentation\n\nstarting sentences of custom rules","20440e43":"## SpaCy Visualization","6270e2d4":"___\n## Customizing the Appearance\nBesides setting the distance between tokens, you can pass other arguments to the `options` parameter:\n\n<table>\n<tr><th>NAME<\/th><th>TYPE<\/th><th>DESCRIPTION<\/th><th>DEFAULT<\/th><\/tr>\n<tr><td>`compact`<\/td><td>bool<\/td><td>\"Compact mode\" with square arrows that takes up less space.<\/td><td>`False`<\/td><\/tr>\n<tr><td>`color`<\/td><td>unicode<\/td><td>Text color (HEX, RGB or color names).<\/td><td>`#000000`<\/td><\/tr>\n<tr><td>`bg`<\/td><td>unicode<\/td><td>Background color (HEX, RGB or color names).<\/td><td>`#ffffff`<\/td><\/tr>\n<tr><td>`font`<\/td><td>unicode<\/td><td>Font name or font family for all text.<\/td><td>`Arial`<\/td><\/tr>\n<\/table>\n\nFor a full list of options visit https:\/\/spacy.io\/api\/top-level#displacy_options\n","dfc01c9a":"# 1. NLP & SPaCy Basics "}}