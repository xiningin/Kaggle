{"cell_type":{"499cb18e":"code","8ec45133":"code","dd9283ac":"code","5f98b8cb":"code","f1d60ffc":"code","c49a7c5a":"code","c99d7f6d":"code","8395b472":"code","1b7b5a0b":"code","5575d730":"code","be28f9ac":"code","16eb6525":"code","7504ff28":"code","6704f7b8":"code","17e10498":"code","618eeecc":"markdown","92d1262e":"markdown","bd986b17":"markdown","48b5c6c9":"markdown","47e5c6e0":"markdown","3df8c34c":"markdown","09cb52a9":"markdown"},"source":{"499cb18e":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom numpy import mean \nfrom numpy import std\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers, regularizers\nfrom tensorflow.keras.layers import Dropout, Flatten \nfrom tensorflow import keras\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom keras.utils import to_categorical","8ec45133":"train_data=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_data.shape, test_data.shape","dd9283ac":"train_data.columns","5f98b8cb":"Y_train=train_data['label'].values.astype('float32')\nY_train=to_categorical(Y_train)\n\nX_train=train_data.drop('label', axis=1).values.astype('float32')\nX_test=test_data.values.astype('float32')\nprint(\"shape of the train and test data\", X_train.shape, Y_train.shape, X_test.shape)","f1d60ffc":"X_train=X_train\/255.0\nX_train=X_train.reshape(X_train.shape[0], 28 , 28, 1)\nX_test=X_test\/255.0\nX_test=X_test.reshape(X_test.shape[0], 28 , 28, 1)\nprint('Shape of the training and test data ,' ,X_train.shape, X_test.shape)","c49a7c5a":"plt.figure(figsize=(20,10))\ncolumns=5\nfor i in range(columns):\n    plt.subplot(5\/columns +1, 5,i+1)\n    plt.imshow(X_train[i])","c99d7f6d":"from sklearn.model_selection import train_test_split\nx_train ,x_test, y_train ,y_test=train_test_split(X_train,Y_train , test_size=0.2, random_state=12)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","8395b472":"def my_model():\n    \n    \n    inputs=keras.Input(shape=(28,28,1))\n\n    x=layers.Conv2D(32, kernel_size=5, strides=1 ,activation='relu', kernel_regularizer=regularizers.l2(0.005))(inputs)\n    x=layers.Conv2D(32, kernel_size=5, strides=1 ,use_bias=False, kernel_regularizer=regularizers.l2(0.005))(x)\n    x=layers.BatchNormalization()(x)\n    x=keras.activations.relu(x)\n    x=layers.MaxPooling2D(pool_size=2, strides=2)(x)\n    \n    x=layers.Dropout(0.25)(x)\n    \n    x=layers.Conv2D(64, kernel_size=3, padding='same', activation='relu',kernel_regularizer=regularizers.l2(0.005))(x)\n    x=layers.Conv2D(32, kernel_size=3, strides=1 ,use_bias=False)(x)\n\n    x=layers.BatchNormalization()(x)\n    x=keras.activations.relu(x)\n    x=layers.MaxPooling2D(pool_size=2, strides=2)(x)\n    x=layers.Dropout(0.25)(x)\n    x=layers.Flatten()(x)\n    x=layers.Dense(256, use_bias=False)(x)\n    x=layers.BatchNormalization()(x)\n    x=keras.activations.relu(x)\n    x=layers.Dense(128,use_bias=False)(x)\n    x=layers.BatchNormalization()(x)\n    x=keras.activations.relu(x)\n    x=layers.Dense(128,use_bias=False)(x)\n    x=layers.BatchNormalization()(x)\n    x=keras.activations.relu(x)\n    x=layers.Dense(64, use_bias=False)(x)\n    x=layers.BatchNormalization()(x)\n    \n    x=layers.Dropout(0.25)(x)\n    outputs=layers.Dense(10, activation='softmax')(x)\n    \n    model=keras.Model(inputs=inputs, outputs=outputs)\n    return model\n\nmodel=my_model()\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","1b7b5a0b":"model_history=model.fit(x_train ,y_train, batch_size=128, verbose=2, epochs=10, validation_data=(x_test, y_test))","5575d730":"score=model.evaluate(x_test, y_test)\nprint(\"Validation loss:\", score[0])\nprint('validation accuracy :', score[1])","be28f9ac":"acc=model_history.history['accuracy']\nval_acc=model_history.history['val_accuracy']\nloss=model_history.history['loss']\nval_loss=model_history.history['val_loss']\nepochs=range(10)\nplt.subplot(1,2,1)\nplt.plot(epochs, acc, label='Accuracy')\nplt.plot(epochs, val_acc, label='Validation accuracy')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epochs, loss, label='loss')\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.legend()\nplt.show()\n","16eb6525":"predict=model.predict(X_test)","7504ff28":"predict_Score=np.argmax(predict, axis=1)\n","6704f7b8":"sample=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nprint(sample.shape)\nprint(sample.columns)","17e10498":"sample['Label']=predict_Score\nsample.to_csv('sample_submission012.csv', index=False)","618eeecc":"## apply the CNN algorithm","92d1262e":"## split the data train data in dependent and independent feature","bd986b17":"## load train and test dataset","48b5c6c9":"## split the data","47e5c6e0":"## convert the value of the feature between 0 and 1","3df8c34c":"## read the sample data","09cb52a9":"## Load the Library"}}