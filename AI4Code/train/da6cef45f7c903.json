{"cell_type":{"0efa7b2e":"code","383b08e2":"code","7c5e2f87":"code","c3b6a163":"code","afed39f3":"code","f565f973":"code","c9622ec2":"code","13f936ec":"code","f7ccbb1d":"code","64a58db3":"code","ba0f8215":"code","ac2ec881":"code","0b953ef3":"code","18c2aee7":"code","ecb1d7ef":"code","ff17126e":"code","e528042a":"code","36834aea":"code","03d2d506":"code","43c311fd":"code","f2b2a5a4":"code","a6da40d9":"code","3ab80e50":"code","0f3fb46d":"code","b7227326":"code","acc3d5ab":"markdown","ba5d84a8":"markdown","7bc5b39c":"markdown","4620728f":"markdown","dab36b2a":"markdown","6ae0f0bb":"markdown","dfcb30a7":"markdown","ab6844ef":"markdown","43dc4017":"markdown","6d5673e7":"markdown","7bab7d36":"markdown","ec3fdae0":"markdown","3039a11d":"markdown","c70434c4":"markdown","12bbad61":"markdown","75dfe1b1":"markdown","f22b5cb9":"markdown","54e514a5":"markdown","6115cfb8":"markdown","9ee7ea46":"markdown","47df95f3":"markdown","237184df":"markdown","1c923368":"markdown","4c497b64":"markdown","3c5d474c":"markdown","cacdb5bb":"markdown","e5dadf6e":"markdown","9c04818c":"markdown","e19f1700":"markdown","cb1b2992":"markdown","eee35866":"markdown","3d3c970e":"markdown","85b5e6d1":"markdown","d4769d27":"markdown","1621f352":"markdown","f22f66fa":"markdown","395cb58c":"markdown","9a881448":"markdown","a660291e":"markdown","e3f79090":"markdown","a3c3293f":"markdown","4ba7b279":"markdown","e54043a1":"markdown","7eca10c8":"markdown","c1ee449f":"markdown","e22a27b5":"markdown","806ab70a":"markdown","1dedb8d4":"markdown","09313cd1":"markdown","6a6eab26":"markdown","30db6068":"markdown","70416c03":"markdown","fffe3bc0":"markdown","ea314b04":"markdown","4c044340":"markdown","9d7facdb":"markdown","6d8549b1":"markdown","6d687e86":"markdown","f263dd9e":"markdown","7bd3e10a":"markdown","935a831f":"markdown","5cfcbfb3":"markdown","a6d87473":"markdown","db267a16":"markdown","8702e89c":"markdown","efbd3f76":"markdown","2caa2b07":"markdown","cb71d3fd":"markdown","e9be6e47":"markdown","7011eb11":"markdown","55de52d8":"markdown"},"source":{"0efa7b2e":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","383b08e2":"!ls ..\/input\/titanic","7c5e2f87":"data=pd.read_csv('..\/input\/titanic\/train.csv')\n","c3b6a163":"data.head()","afed39f3":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndata['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived',data=data,ax=ax[1])\nax[1].set_title('Survived')\nplt.show()","f565f973":"plt.figure(figsize=(12,8))\nsns.countplot('Sex',hue='Survived',data=data)\nplt.show()","c9622ec2":"plt.figure(figsize=(12,8))\nsns.countplot('Pclass',hue='Survived',data=data)\nplt.show()","13f936ec":"f,ax=plt.subplots(1,2,figsize=(18,8))\nsns.boxplot(\"Pclass\",\"Age\", hue=\"Survived\", data=data,ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0,110,10))\nsns.boxplot(\"Sex\",\"Age\", hue=\"Survived\", data=data,ax=ax[1])\nax[1].set_title('Sex and Age vs Survived')\nax[1].set_yticks(range(0,110,10))\nplt.show()","f7ccbb1d":"#importing all the required ML packages\nfrom sklearn.linear_model import LogisticRegression #logistic regression\nfrom sklearn import svm #support vector Machine\nfrom sklearn.ensemble import RandomForestClassifier #Random Forest\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\nfrom sklearn.naive_bayes import GaussianNB #Naive bayes\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree\nfrom sklearn.model_selection import train_test_split #training and testing data split\nfrom sklearn import metrics #accuracy measure\nfrom sklearn.metrics import confusion_matrix #for confusion matrix","64a58db3":"\ndata['Embarked'].fillna('S',inplace=True)\ndata['Age'].fillna(int(data['Age'].mean()), inplace=True)\n\ndata.info()\n","ba0f8215":"data['Sex'].replace(['male','female'],[0,1],inplace=True)\ndata['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n#data['Initial'].replace(['Mr','Mrs','Miss','Master','Other'],[0,1,2,3,4],inplace=True)","ac2ec881":"data.drop(['Name','Age','Ticket','Fare','Cabin','PassengerId'],axis=1,inplace=True)\nsns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})\nfig=plt.gcf()\nfig.set_size_inches(18,15)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","0b953ef3":"train,test=train_test_split(data,test_size=0.3,random_state=0,stratify=data['Survived'])\ntrain_X=train[train.columns[1:]]\ntrain_Y=train[train.columns[:1]]\ntest_X=test[test.columns[1:]]\ntest_Y=test[test.columns[:1]]\nX=data[data.columns[1:]]\nY=data['Survived']","18c2aee7":"model=svm.SVC(kernel='rbf',C=1,gamma=0.1)\nmodel.fit(train_X,train_Y)\nprediction1=model.predict(test_X)\nprint('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction1,test_Y))","ecb1d7ef":"model=svm.SVC(kernel='linear',C=0.1,gamma=0.1)\nmodel.fit(train_X,train_Y)\nprediction2=model.predict(test_X)\nprint('Accuracy for linear SVM is',metrics.accuracy_score(prediction2,test_Y))","ff17126e":"model = LogisticRegression()\nmodel.fit(train_X,train_Y)\nprediction3=model.predict(test_X)\nprint('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction3,test_Y))","e528042a":"model=DecisionTreeClassifier()\nmodel.fit(train_X,train_Y)\nprediction4=model.predict(test_X)\nprint('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction4,test_Y))","36834aea":"model=KNeighborsClassifier() \nmodel.fit(train_X,train_Y)\nprediction5=model.predict(test_X)\nprint('The accuracy of the KNN is',metrics.accuracy_score(prediction5,test_Y))","03d2d506":"model=GaussianNB()\nmodel.fit(train_X,train_Y)\nprediction6=model.predict(test_X)\nprint('The accuracy of the NaiveBayes is',metrics.accuracy_score(prediction6,test_Y))","43c311fd":"model=RandomForestClassifier(n_estimators=100)\nmodel.fit(train_X,train_Y)\nprediction7=model.predict(test_X)\nprint('The accuracy of the Random Forests is',metrics.accuracy_score(prediction7,test_Y))","f2b2a5a4":"from sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nxyz=[]\naccuracy=[]\nstd=[]\nclassifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\nmodels=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(n_estimators=100)]\nfor i in models:\n    model = i\n    cv_result = cross_val_score(model,X,Y, cv = kfold,scoring = \"accuracy\")\n    cv_result=cv_result\n    xyz.append(cv_result.mean())\n    std.append(cv_result.std())\n    accuracy.append(cv_result)\nnew_models_dataframe2=pd.DataFrame({'CV Mean':xyz,'Std':std},index=classifiers)       \nnew_models_dataframe2","a6da40d9":"new_models_dataframe2['CV Mean'].plot.barh(width=0.8)\nplt.title('Average CV Mean Accuracy')\nfig=plt.gcf()\nfig.set_size_inches(8,5)\nplt.show()","3ab80e50":"f,ax=plt.subplots(3,3,figsize=(12,10))\ny_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,0],annot=True,fmt='2.0f')\nax[0,0].set_title('Matrix for rbf-SVM')\ny_pred = cross_val_predict(svm.SVC(kernel='linear'),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,1],annot=True,fmt='2.0f')\nax[0,1].set_title('Matrix for Linear-SVM')\ny_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,2],annot=True,fmt='2.0f')\nax[0,2].set_title('Matrix for KNN')\ny_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,0],annot=True,fmt='2.0f')\nax[1,0].set_title('Matrix for Random-Forests')\ny_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,1],annot=True,fmt='2.0f')\nax[1,1].set_title('Matrix for Logistic Regression')\ny_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,2],annot=True,fmt='2.0f')\nax[1,2].set_title('Matrix for Decision Tree')\ny_pred = cross_val_predict(GaussianNB(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[2,0],annot=True,fmt='2.0f')\nax[2,0].set_title('Matrix for Naive Bayes')\nplt.subplots_adjust(hspace=0.2,wspace=0.2)\nplt.show()","0f3fb46d":"from sklearn.model_selection import GridSearchCV\nC=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\ngamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\nkernel=['rbf','linear']\nhyper={'kernel':kernel,'C':C,'gamma':gamma}\ngd=GridSearchCV(estimator=svm.SVC(),param_grid=hyper,verbose=True)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","b7227326":"n_estimators=range(100,1000,100)\nhyper={'n_estimators':n_estimators}\ngd=GridSearchCV(estimator=RandomForestClassifier(random_state=0),param_grid=hyper,verbose=True)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","acc3d5ab":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/16_16_automl_training_successful-1.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","ba5d84a8":"Immediately we see, 5 tabs are generated\n\n1. **Feature Importance**: To see the global level importance of features\n2. **Model Summary**: To explore various model metrics and performance\n3. **Individual Prediction Analysis**: To deep dive into individual row level and see what factors impacted the outcome\n4. **What If Analysis**: To change certain parameters and check how the outcome would have changed\n5. **Dependence**: To see Shap summary and Shap dependence plot.\n\nLet's go through them one by one","7bc5b39c":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/19_model_performance_1.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","4620728f":"## With CyberDeck\n\n#### We drag and drop Pclass into the columns section and done","dab36b2a":"Let's change the passenger class to 1 and the age to 11 and see how the survival probability changes.","6ae0f0bb":"In this plot, we see how (at the global level) different features impacted the chances of someone's survival. We see that **Sex, PClass and Age** are the most important ones.","dfcb30a7":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/0_0_titanic_read_data.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>\n","ab6844ef":"### Logistic Regression","43dc4017":"## 5. Dependence\n\nIn this last tab, you will see two plots. The one on the left is again a global feature importance, but this time, it also shows how that variable is affecting survival (in a positive or negative way). The one on the right is a Shap dependence plot which shows us the relation between feature values and SHAP values. This allows you to investigate general relationship between feature value and impact on prediction.","6d5673e7":"### Decision Tree","7bab7d36":"## 4. What-If Analysis\n\nIn this section, we can change different feature values for any row and see how the outcome (probability of survival) would have changed. Let's take a male passenger, age 34, from 3rd class. We see that his chances of survival is very low (2.9%).","ec3fdae0":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/4_4_survived_bar_chart.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","3039a11d":"#### Now this pie chart shows us absolute numbers. If we want to convert it to percentage, we click the cropdown where it currently says \"Count\" and select \"Count as fraction of total\" and the numbers get converted to percentage","c70434c4":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/25_what_if_2.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","12bbad61":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/17_explain_model_choose.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","75dfe1b1":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/24_what_if_1.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","f22b5cb9":"#### All it takes is one drag and drop. We drag the \"Sex\" column to the columns section and done!","54e514a5":"# D) Conclusion\n\nThis marks the end of the first demo of the CyberDeck platform that we are actively building right now. We plan to make this a community product for Data Scientists, by Data Scientists. We would be making the first pre-release around January 2022. So if you think that this product can make your life a little bit easier, then don't forget to sign up at https:\/\/www.cyberdeck.in\/ and we will get right back as soon as we can!\n\nThat's it for now! Stay tuned till we bring a next demo for CyberDeck!","6115cfb8":"## With CyberDeck\n\nTo see this exact thing in CyberDeck, we go to the EDA section of the CyberDeck, upload the data and go to the **Pivot-Chart** section.","9ee7ea46":"## Cross validation","47df95f3":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/15_15_automl_manual_hyperparameter.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","237184df":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/3_3_pie_chart_survived_percentage.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","1c923368":"# C) Explainable AI\n\nExplainable AI is becoming a major part of any organization\/data science workflow very fast. The Shapley values which is based on a game-theoretic approach gives us tremendous insights about the **WHY**. This in turn helps data scientists to directly generate insights or change their workflow. In this section, we will implement that in CyberDeck. But now that you have got the point of this platform, we will not do any coding and directly show you how easy it is inside CyberDeck. \n\nInside CyberDeck, we go to the **ML Model Explainer** Section, choose the model we want the explanation for and hit **Show Model Explanation**\n","4c497b64":"## Note\n\nPlease note that you can recreate all these plots from the dashboard section also where you will have full customization over the plots (almost 20 plots). The below charts show some full fledged dashboards and EDAs.","3c5d474c":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/6_6_bar_chart_survived_by_pclass.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","cacdb5bb":"# A) Exploratory Data Analysis\n\n# 1. How many survived\n\n## With Coding","e5dadf6e":"We see that immediately the probability of survival jumps to 21.3%. This makes sense as we know that passengers from 1st class have a higher chance of survival and also **Children First!**\n\nYou can play around with the variables here and see how changing each variable affects the final outcome.","9c04818c":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/26_dependence_plot.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","e19f1700":"#### CyberDeck trains a plethora of ML algorithms and presents the user with a leaderboard. Here we can see that Catboost worked the best in terms of Accuracy, AUC, Precision, Recall, Kappa and MCC. But the time taken is the largest. So if any user wants to train a slightly inferior but fast model, he\/she will have the ability to do that and the user will understand everything just by looking at this leaderboard! Let's go with the Gradient Boosting Classifier for now as it is much faster and also performed very well.\n\n#### During the leaderboard generation, the model took a subset of the dataset, trained the ML models and did K-Fold cross validation. Now once the user finalizes a model and hits the \"Train model\" button, it will take the full dataset and train the model on top of that. It will also tune the hyperparameters to find the best version of the selected model. But the user will also have the ability to provide the hyperparameters manually with the second button i.e. \"Tune Hyperparameters\". Let's take a look at that.","cb1b2992":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/21_model_performance_3.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","eee35866":"#### And this one has Pclass in the X-Axis","3d3c970e":"## With coding","85b5e6d1":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/13_13_automl_parameters.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","d4769d27":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/20_model_performance_2.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","1621f352":"# 2. Number of survivors by gender","f22f66fa":"#### Whew! That was a lot of code wasn't it! Do note, I only did tuning for a couple of algorithms. If I would have done it for all, then you can imagine how much more code writing would have been there! Now let's try this with CyberDeck.\n\n## 2. With CyberDeck\n\n#### First we go to the AutoML section and choose the dataset. Then we can either train a new model or use an existing one for inference. Let's train a new one.","395cb58c":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/9_full_eda.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","9a881448":"#### Now to convert this to a pie chart, we click the drop-down menu (where it currently says **Table**) and select a pie chart or a bar chart","a660291e":"# 4. Distribution of Age with different factors\n\nNow that we have got some basic idea about how this platform works. Let's look at some different facets of this platform\n\n## With coding","e3f79090":"### SVM","a3c3293f":"## Hyperparameter Tuning\n\n### SVM","4ba7b279":"#### Now we only have to select the target variable. \n\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/12_12_automl_select_target_variable.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>\n\n\n#### At this point, we have two options:\n\n1. We can customize the AutoML parameters and then train the model\n2. We can keep everything at default and train the model. \n\nFor both of these options, CyberDeck will recognize what type of problem it is (classification\/regression) and then train a variety of models and then present the user with a leaderboard about which models performed the best and which ones are the worst.\n\nIf you choose to select the AutoML paramters, you will get a pop up box like this.","e54043a1":"\n\n\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/10_full_dashboard.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","7eca10c8":"## 3. Individual Prediction analysis\n\nIn this tab, we can go to any row number and see what factors affected the most the passenger's survival or death. \n\na) In the **Select Index** section, we can select any row number for which we want the analysis. We can also filter out these rows by prediction probability or observed label.\n\nb) In the **Prediction** section, we get the observed label and also the model's prediction probability for the same. We see this particular passenger has a survival chance of 88% (in reality too she survived).\n\nc) In the **Contributions Plot** section, we see what factors impacted positively (in green) and negatively (in red) for the survival probability.\n\nd) In the **Partial Dependence** plot, we can see how a particular feature's contribution towards survival varies with its different value.","c1ee449f":"### Random Forests","e22a27b5":"### KNN","806ab70a":"#### Let's create the Bar chart now, we simply change \"Multiple Pie Chart\" to \"Grouped Column Chart\" and \"Count as Fraction of Total\" to \"Count\" and voila, we recreate the second chart!","1dedb8d4":"#### Within a few minutes and without any coding like we did before, we have now generated this leaderboard. As we can see, the user will have a plethora of choice about how he wants the data to be prepared for Machine Learning. For now, let's keep everything at default and hit that \"Generate Leaderboard\" button.","09313cd1":"### Gaussian Naive Bayes","6a6eab26":"#### Here we just drag and drop the **Survived** column in the \"Rows\" section and BOOM! We see in a tabular format the number of Survivors and Non-Survivors in a second. ","30db6068":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/18_explain_feature_importance.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","70416c03":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/5_5_bar_chart_survived_by_sex.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","fffe3bc0":"# B)AutoML to predict Survivors\n\nNow that we have seen how powerful the CyberDeck platform can be in terms of a thorough Exploratory Data Analysis, let's dive in the point and click Machine Learning part of it. Machine learning at its core involves creating a model, cross validation and then hyperparameter tuning. We will first code this part with a number of well known ML algorithm and then we would simply show how easy it can be with the CyberDeck platform. \n\n## 1. With Coding","ea314b04":"# Introducing CyberDeck - A free one click platform to perform end to end Data Science Pipeline\n\nData Science is one of the most beautiful things out there. The sheer ability to extract meaningful information out of nothing is a wonder by itself. But being a data scientist comes with its own kinks. One of the major challenges of data science is code writing. One often writes hundreds of lines of codes to achive the feat of extracting valuable information from data. But then also, this is not scalable. As the data changes, the code changes. As a result, we have to write hundreds of lines of codes again even though the processes\/pipelines remain the same. But what if we could make a one stop platform for doing our regular data science work at the click of a mouse - Starting from data processing, EDA all the way to modelling?\n\nTo answer this ever growing problem, we are developing a **FREE** one stop community platform for Data Scientists named **\"CyberDeck\"**. Every similar platform we have seen costs a lot of money. But not this. This is not out for release yet. But if we get a positive feedback from this gold mine of a community, we will make that a reality soon tentatively by the end of this year!\n\nTo demonstrate the capability of CyberDeck, we are choosing the Titanic dataset. We will do a side by side comparison of coding vs using CyberDeck for a variety of processes. We will perform a thorough Exploratory Data Analysis and then do machine learning to predict who will survive. After that, we will demonstrate our Explainable AI section to understand what features impact the survivality the most and do a \"WHAT-IF\" analysis to see some interesting turn of events that would have happened if some feature values were changed. Keep in mind, we will just be scratching the surface of CyberDeck in this demo.\n\nAs we plan to give this product for free, we really need to understand if there will be a need for this among the data scientists. So we couldn't think of a better place than Kaggle. So do let us know if you need this product!\n\nAs a final note, if you like this demo and want to be a contributor, contact me at sagarnil.das@cyberdeck.in\n\nYou can sign up for the Pre-release here: https:\/\/cyberdeck.in\/\n\nYou need it? You got it!\n\nYou can see the medium article here: https:\/\/medium.com\/analytics-vidhya\/convert-your-data-science-hours-to-minutes-with-this-one-method-7089ff2664ff\n\nLet's dive right in!\n\n","4c044340":"## Confusion matrix","9d7facdb":"### Code Reference: https:\/\/www.kaggle.com\/ash316\/eda-to-prediction-dietanic","6d8549b1":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/14_14_automl_leaderboard.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","6d687e86":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/22_model_performance_4.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","f263dd9e":"#### For now, we will let CyberDeck tune the model hyperparameters. So we will select the \"Gradient Boosting Classifier\" and hit the \"Train Model\" button. When the training is complete, this model will be saved as a pickle file which can be later used for inference purpose. When the training is done, We will see a \"Training Successful\" notification below the leaderboard","7bd3e10a":"### Random Forest","935a831f":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/1_1_how_many_survived_table.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","5cfcbfb3":"## 1. Feature importance","a6d87473":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/2_2_pie_chart_survived_total.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","db267a16":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/11_11_ml_train_or_test.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","8702e89c":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/7_7_box_plot_sex_age_survived.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","efbd3f76":"# 3. Number of survivors by Pclass\n\n","2caa2b07":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/23_individual_preds.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","cb71d3fd":"## With CyberDeck","e9be6e47":"## 2. Model Performance\n\nThe next set of screenshots show all the customizable performance metrics monitoring you have at your disposal at the click of a mouse e.g confusion metrics, ROC-AUC, PR-AUC curve, Lift Curve,Precision plot etc.\n\n","7011eb11":"\n<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/cyberdeck.in\/wp-content\/uploads\/2021\/09\/8_8_box_plot_pclass_age_survived.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> <\/div>","55de52d8":"## With CyberDeck\n\n#### To recreate this in CyberDeck, we go to the \"Interactions\" subsection of the \"EDA\" section in CyberDeck and give the necessary axes in the lower right plot area. The below plot has \"Sex\" in X-axis"}}