{"cell_type":{"f1dba8da":"code","ad37235a":"code","b73e64a0":"code","c571b401":"code","c32aa634":"code","0df9d72e":"code","915f1192":"code","abd4abd8":"code","abb51eae":"code","676ab522":"code","dbcaa147":"code","ee839c1f":"code","3e1e2e06":"code","44357bfc":"code","73604a3a":"code","c9322adc":"code","c8ab8b3d":"markdown","bed15108":"markdown"},"source":{"f1dba8da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n#Set numpy and Tensorflow random seed to mask sure experiment reproducible(only works in CPU mode).\nfrom numpy.random import seed\nseed(123)\nfrom tensorflow import set_random_seed\nset_random_seed(123)\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport imageio\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ad37235a":"image_path = '..\/input\/dataa\/dataA\/CameraRGB\/'\nmask_path = '..\/input\/dataa\/dataA\/CameraSeg\/'\nimage_list = os.listdir(image_path)\nmask_list = os.listdir(mask_path)\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]","b73e64a0":"N = 1\nimg = imageio.imread(image_list[N])\nmask = imageio.imread(mask_list[N])\nmask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n\nfig, arr = plt.subplots(1, 2, figsize=(14, 10))\narr[0].imshow(img)\narr[0].set_title('Image')\narr[1].imshow(mask, cmap='Paired')\narr[1].set_title('Segmentation')","c571b401":"road = np.zeros((600, 800))\nroad[np.where(mask==7)[0], np.where(mask==7)[1]]=1\nplt.imshow(road)","c32aa634":"from tqdm import tqdm","0df9d72e":"height, width = 600, 800\nimages = np.zeros((len(image_list), height, width, 3), dtype=np.int16)\nmasks = np.zeros((len(image_list), height, width, 1), dtype=np.int8)\n\nfor n in tqdm(range(len(image_list))):\n    img = imageio.imread(image_list[n])\n    \n    mask = imageio.imread(mask_list[n])\n    mask_road = np.zeros((600, 800, 1), dtype=np.int8)\n    mask_road[np.where(mask==7)[0], np.where(mask==7)[1]]=1\n    \n    images[n] = img\n    masks[n] = mask_road","915f1192":"plt.imshow(images[1].reshape(600, 800, 3))","abd4abd8":"np.random.seed(123)\nshuffle_ids = np.array([i for i in range(len(masks))])\nnp.random.shuffle(shuffle_ids)\ntrain_ids = shuffle_ids[:int(len(masks)*0.8)]\nval_ids = shuffle_ids[int(len(masks)*0.8):int(len(masks)*0.8+100)]\ntest_ids = shuffle_ids[int(len(masks)*0.8+100):]","abb51eae":"train_images, train_masks = images[train_ids], masks[train_ids]\nval_images, val_masks = images[val_ids], masks[val_ids]\ntest_images, test_masks = images[test_ids], masks[test_ids]","676ab522":"train_images.shape, val_images.shape, test_images.shape","dbcaa147":"from keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K","ee839c1f":"# Build U-Net model\ninput_img = Input((height, width, 3), name='img')\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (input_img)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n\nu5 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c4)\nu5 = concatenate([u5, c3])\nc6 = Conv2D(32, (3, 3), activation='relu', padding='same') (u5)\nc6 = Conv2D(32, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c2])\nc7 = Conv2D(16, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(16, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c1])\nc8 = Conv2D(8, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(8, (3, 3), activation='relu', padding='same') (c8)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c8)\n\nmodel = Model(inputs=[input_img], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy') #, metrics=[mean_iou]) # The mean_iou metrics seens to leak train and test values...\nmodel.summary()","3e1e2e06":"callbacks = [\n    EarlyStopping(patience=12, verbose=1),\n    ReduceLROnPlateau(patience=3, verbose=1),\n    ModelCheckpoint('model-sdc-seg-v2.h5', verbose=1, save_best_only=True)\n]\n\nresults = model.fit(train_images, train_masks, batch_size=16, epochs=100, callbacks=callbacks,\n                    validation_data=(val_images, val_masks))","44357bfc":"model.save('final-road-seg-model-v2.h5')","73604a3a":"NUMBER = 0\nmy_preds = model.predict(np.expand_dims(test_images[NUMBER], 0))\nmy_preds = my_preds.flatten()\nmy_preds = np.array([1 if i >= 0.5 else 0 for i in my_preds])\nfig, ax = plt.subplots(nrows=1, ncols=2)\nax[0].imshow(my_preds.reshape(600, 800))\nax[0].set_title('Prediction')\nax[1].imshow(test_masks[NUMBER].reshape(600, 800))\nax[1].set_title('Ground truth')","c9322adc":"NUMBER += 1\nmy_preds = model.predict(np.expand_dims(test_images[NUMBER], 0))\nmy_preds = my_preds.flatten()\nmy_preds = np.array([1 if i >= 0.5 else 0 for i in my_preds])\nfig, ax = plt.subplots(nrows=1, ncols=2)\nax[0].imshow(my_preds.reshape(600, 800))\nax[0].set_title('Prediction')\nax[1].imshow(test_masks[NUMBER].reshape(600, 800))\nax[1].set_title('Ground truth')","c8ab8b3d":"## Limited by RAM, just do <font color=red>road<\/font> segmentation(mask == 7).","bed15108":"## Build U-Net with subtle changes"}}