{"cell_type":{"690c61fb":"code","664d56a5":"code","2d3fea68":"code","704a4e27":"code","4d41059c":"code","619214d3":"code","7b05f26d":"code","e3f44c2e":"code","89d9a189":"code","55030d0f":"code","0cf6c89f":"code","c5b96a1b":"markdown","864554fc":"markdown","6e6d3d6d":"markdown","d6d200a7":"markdown","76bf088b":"markdown","25e88389":"markdown","9305db4a":"markdown","96bd6a8d":"markdown","34e30b0e":"markdown","968f84ca":"markdown","40647df1":"markdown","4dd72355":"markdown","4a7d2123":"markdown","facefb6c":"markdown"},"source":{"690c61fb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder","664d56a5":"df = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndf.head()","2d3fea68":"# gender\ngender_label_encoder = LabelEncoder()\ngender_label_encoder.fit(df['gender'])\ndf['gender'] =  gender_label_encoder.transform(df['gender'])\n\n# smoking_status\nsmoking_label_encoder = LabelEncoder()\nsmoking_label_encoder.fit(df['smoking_status'])\ndf['smoking_status'] =  smoking_label_encoder.transform(df['smoking_status'])","704a4e27":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nnormalized_array = scaler.fit_transform(df[['age','bmi','avg_glucose_level']])\nnormalized_df = pd.DataFrame(normalized_array, columns=['age','bmi','avg_glucose_level'])\ndf[['age', 'bmi', 'avg_glucose_level']] = normalized_df","4d41059c":"df = df.dropna()\ndf = df.reset_index()","619214d3":"df","7b05f26d":"# Defining X and y\nX = df[['gender', 'age', 'hypertension', 'avg_glucose_level', 'bmi', 'smoking_status']]\ny = df['stroke']\n\n# Train test split\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=1) # random_state=1 for same results every time.\n\ninput_shape = [X_train.shape[1]]","e3f44c2e":"model = keras.Sequential([\n    # input layer\n    layers.BatchNormalization(input_shape=input_shape),\n    # hidden layer 1\n    layers.Dense(units=256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=0.4),\n    # hidden layer 2\n    layers.Dense(units=128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=0.4),\n    # hidden layer 3\n    layers.Dense(units=64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=0.4),\n    # hidden layer 4\n    layers.Dense(units=32, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=0.4),\n    layers.Dense(units=3, activation='softmax')\n])\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","89d9a189":"history = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    batch_size=512,\n    epochs=700,\n)","55030d0f":"### Loss Graph\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Learning Curve: Loss over Epochs\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend(['Training Loss', 'Validation Loss'])\n\n### Accuracy Graph\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot(title=\"Learning Curve: Accuracy over Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend(['Training Accuracy', 'Validation Accuracy'])","0cf6c89f":"label_names = [\"Had no stroke\", \"Had stroke\"] # 0 patient had no stroke, 1 patient had stroke\ny_actual = y_train.to_numpy()\ny_pred = model.predict(X_train, verbose=0)\ny_pred = np.argmax(y_pred, axis=-1)\n\nprint(\"On {} samples of untrained(test) dataset:\".format(len(y_pred)))\nprint(\"Prediction:\")\nprint(y_pred)\nprint(\"Actual:\")\nprint(y_actual)\n\n### Classification Report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_actual,y_pred, target_names=label_names))\n\n### Confusion Matrix Graph\ncm = confusion_matrix(y_true=y_actual, y_pred=y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\ndisp.plot()\nplt.title('Confusion Matrix')","c5b96a1b":"### 2. Training the model\n\n##### Results of Training\nLearning Curve showing Loss and Accuracy during training.","864554fc":"I decided to use the features: `gender`, `age`, `hypertension`, `heart_disease`, `avg_glucose_level`, `bmi`, `smoking_status`\nto predict the label: `stroke`","6e6d3d6d":"## Importing the dataset","d6d200a7":"### 1. Creating and compiling the model","76bf088b":"## \ud83e\udd14 My Evaluation\n### Tasks I did to preprocess the **dataset** to increase model performance:\n    - FeatureScaling with MinMax scaler for all values \n    - Dropped NaN values\n    - Limited the features to only: `gender`, `age`, `hypertension`, `heart_disease`, `avg_glucose_level`, `bmi`, `smoking_status`.\n    \n### Improvements I did on the neural network to increase model performance:\n    - BatchNormalization\n    - Layer Dropout\n    - These improvements reduced overfitting\n    \n- With these improvements, the model would steadily perform above **95% accuracy**.\n- At one point it also reached **100% accuracy**.","25e88389":"## \ud83d\udcc8 Evaluation of the Model's Performance","9305db4a":"## \u2702 Defining X and y and train test split","96bd6a8d":"## \ud83e\udd16 The Model","34e30b0e":"Carlo Antonio T. Taleon BSCS-3A | 2021-2022 | Written December 2021\n\n# Stroke Prediction (TF with Keras)\nThis is my final project for the 1st semester of Artificial Neural Networks at WVSU-CICT.","968f84ca":"### 2. Normalizing values\nI want to normalize `age`, `bmi`, and `avg_glucose_level`","40647df1":"## \ud83d\ude82 Data preprocessing","4dd72355":"### 3. Removing NaN values and resetting index","4a7d2123":"### Final Normalized Dataset:","facefb6c":"### 1. Encoding ordinal features: (using LabelEncoder)"}}