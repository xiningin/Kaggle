{"cell_type":{"795ec8f5":"code","fb3869b5":"code","8250c7fd":"code","beff6520":"code","053464c3":"code","a2ed6d5c":"code","5305270f":"code","2582ed26":"code","a6b44306":"code","4a76bfed":"code","c9b0d547":"code","4df6c3d5":"code","348bd501":"code","c4e2c733":"code","d7ff440a":"code","1664fc1c":"code","acf3172f":"code","58f0ef3a":"code","6a187659":"code","d2aac8fb":"code","febbb4fc":"code","3dfea501":"code","5291da6b":"code","53e0b4f2":"code","12603671":"code","b54c2b88":"code","4acda56f":"code","fa2d03cf":"markdown","4053e110":"markdown","2dacb386":"markdown","e26bccaf":"markdown","e263cf11":"markdown","58f27676":"markdown","b3f6e751":"markdown"},"source":{"795ec8f5":"#import packages\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport math\nimport os\nfrom shutil import copyfile","fb3869b5":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.models import load_model\n\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\n\nfrom keras.layers import Flatten","8250c7fd":"#get the dataset for ocr\n!wget http:\/\/www.ee.surrey.ac.uk\/CVSSP\/demos\/chars74k\/EnglishFnt.tgz","beff6520":"#unzip the dataset\n!tar -xvzf EnglishFnt.tgz","053464c3":"#view an image sample\nimgsample = Image.open('\/kaggle\/working\/English\/Fnt\/Sample037\/img037-00008.png')\nnpsample = np.array(imgsample)\nplt.imshow(npsample)","a2ed6d5c":"#create train, valid and test directories\nif not os.path.isdir('dataset'):\n  os.mkdir('dataset')\n\nif not os.path.isdir('dataset\/train'):\n  os.mkdir('dataset\/train')\nif not os.path.isdir('dataset\/valid'):\n  os.mkdir('dataset\/valid')\nif not os.path.isdir('dataset\/test'):\n  os.mkdir('dataset\/test')","5305270f":"#make class directories inside them\nfor i in sorted(os.listdir('English\/Fnt')):\n  if not os.path.isdir('dataset\/train\/'+i):\n    os.mkdir('dataset\/train\/'+i)\n  if not os.path.isdir('dataset\/valid\/'+i):\n    os.mkdir('dataset\/valid\/'+i)\n  if not os.path.isdir('dataset\/test\/'+i):\n    os.mkdir('dataset\/test\/'+i)","2582ed26":"#split main folder to train, valid, test and copy images to the new folders\nbase = 'English\/Fnt\/Sample'\n\nfor char  in range(1, 63):\n  classLen = len(os.listdir(base + str(char).zfill(3)))\n\n  trainLen = math.floor(classLen*0.80)\n  validLen = math.ceil(classLen*0.15)\n\n  randFnt = np.random.randint(low = 1, high = classLen, size = classLen)\n  randTrain = randFnt[:trainLen]\n  randValid = randFnt[trainLen : trainLen+validLen]\n  randTest = randFnt[trainLen+validLen :]\n\n  for imgNo in randTrain:\n    src = base+str(char).zfill(3)+'\/img'+str(char).zfill(3)+'-'+str(imgNo).zfill(5)+'.png'\n    des = 'dataset\/train\/Sample'+str(char).zfill(3)+'\/img'+str(char).zfill(3)+'-'+str(imgNo).zfill(5)+'.png'\n    copyfile(src, des)\n\n  for imgNo in randValid:\n    src = base+str(char).zfill(3)+'\/img'+str(char).zfill(3)+'-'+str(imgNo).zfill(5)+'.png'\n    des = 'dataset\/valid\/Sample'+str(char).zfill(3)+'\/img'+str(char).zfill(3)+'-'+str(imgNo).zfill(5)+'.png'\n    copyfile(src, des)\n\n  for imgNo in randTest:\n    src = base+str(char).zfill(3)+'\/img'+str(char).zfill(3)+'-'+str(imgNo).zfill(5)+'.png'\n    des = 'dataset\/test\/Sample'+str(char).zfill(3)+'\/img'+str(char).zfill(3)+'-'+str(imgNo).zfill(5)+'.png'\n    copyfile(src, des)\n","a6b44306":"#define constants\nnum_classes = 62\nimage_resize = 128\nbatch_size_training = 128\nbatch_size_validation = 64","4a76bfed":"#create data generator\ndata_generator = ImageDataGenerator(rescale=1.0\/255.0)","c9b0d547":"#create train and valid generators\ntrain_generator = data_generator.flow_from_directory(\n    'dataset\/train',\n    target_size = (image_resize, image_resize),\n    batch_size = batch_size_training,\n    color_mode = 'grayscale',\n    class_mode = 'categorical'\n)\n\nvalidation_generator = data_generator.flow_from_directory(\n    'dataset\/valid',\n    target_size = (image_resize, image_resize),\n    batch_size = batch_size_training,\n    color_mode = 'grayscale',\n    class_mode = 'categorical'\n)","4df6c3d5":"#view batch specifications\nbatchX, batchy = train_generator.next()\nprint('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))","348bd501":"#This is the best model i could create.\n#Because for other cases, the improvement was minimal compared to the additional computational cost.","c4e2c733":"#create the model\ndef ocrModel():\n  model = Sequential()\n  model.add(Conv2D(32, (4,4), strides = (1,1), activation = 'relu', input_shape = (128, 128, 1)))\n  model.add(MaxPooling2D(pool_size = (4,4), strides = (2,2)))\n  model.add(Conv2D(64, (4,4), strides = (1,1), activation = 'relu', input_shape = (128, 128, 1)))\n  model.add(MaxPooling2D(pool_size = (4,4),strides = (2,2)))\n\n  model.add(Flatten())\n\n  model.add(Dense(310, activation='relu'))\n  model.add(Dense(num_classes, activation = 'softmax'))\n\n  model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n\n  return model","d7ff440a":"#parameters for fitting\nsteps_per_epoch_training = len(train_generator)\nsteps_per_epoch_validation = len(train_generator)\nnum_epochs = 10","1664fc1c":"model = ocrModel()\n\n#view model summary\nmodel.summary()","acf3172f":"#fit model\nfit_history = model.fit_generator(\n    train_generator,\n    steps_per_epoch = steps_per_epoch_training,\n    epochs = num_epochs,\n    validation_data = validation_generator,\n    validation_steps = steps_per_epoch_validation,\n    verbose = 1\n)","58f0ef3a":"#plot the fitting history\nplt.plot(range(1,11), fit_history.history['val_accuracy'], label='valid')\nplt.plot(range(1,11), fit_history.history['accuracy'], label='train')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","6a187659":"#define test generator\ntest_generator = data_generator.flow_from_directory(\n    'dataset\/test',\n    target_size = (image_resize, image_resize),\n    shuffle = False,\n    color_mode='grayscale'\n)","d2aac8fb":"#evaluate the model\neval = model.evaluate_generator(test_generator, verbose=1)\nprint('Model performance:')\nprint('loss for test dataset is : {}'.format(eval[0]))\nprint('accuracy for test dataset is : {}'.format(eval[1]))","febbb4fc":"#connect to your google drive\n#from google.colab import drive \n#drive.mount('\/content\/gdrive')","3dfea501":"#save model to google drive\n#model.save('\/content\/gdrive\/My Drive\/keras_models\/OCRmodel.h5')","5291da6b":"#to copy from drive\n#!cp \/content\/gdrive\/My\\ Drive\/keras_models\/classifier_resnet_model.h5 .\/classifier_resnet_model.h5","53e0b4f2":"#upload files from local storage\n#from google.colab import files\n#uploaded = files.upload()","12603671":"#create a label map\nclassArr = [str(i) for i in range(10)]\nclassArr.extend([chr(i) for i in range(ord('A'), ord('Z')+1)])\nclassArr.extend([chr(i) for i in range(ord('a'), ord('z')+1)])","b54c2b88":"#view the text images to be detected\nfig, axs = plt.subplots(1,8, figsize = (16,5))\n\nfor i in range(8): \n    image_data = Image.open('\/kaggle\/input\/'+str(i+1)+'.png')\n    axs[i].imshow(image_data)","4acda56f":"#detect text using model\nres = ''\nfor i in range(1,9):\n  img = Image.open('\/kaggle\/input\/'+str(i)+'.png')\n  imgnp = np.array(img)\n  imgnp = np.reshape(imgnp, (1,imgnp.shape[0],imgnp.shape[1], 1))\n  predict = model.predict_classes(imgnp)\n  res += classArr[predict[0]]\n\nprint(res)","fa2d03cf":"<h1>PREPROCESSING<\/h1>","4053e110":"<h1> TEST MODEL ON OWN FILES<\/h1>","2dacb386":"<h3>The only error produced was for character 'g'. <br>Thus we can say the model can produce fairly accurate results, as seen by evaluating the test dataset<\/h4>","e26bccaf":"<h1>TEST MODEL<\/h1>","e263cf11":"<h1> Optical character recognition using keras<\/h1>\n<h3> Dataset used : Chars74k<\/h3>\n<h3> link: <a>http:\/\/www.ee.surrey.ac.uk\/CVSSP\/demos\/chars74k\/<\/a><\/h3>\n<h3>Dataset contained 0-9, A-Z, a-z<\/h3>\n<h3>Dataset comprised of 4 computer fonts in normal, bold, italic <\/h3>\n<p>I used 80% data for training, 15% for validation and 5% for testing. The accuracy achieved is as follows:<br>\n<br>\nTraining : 98.11%<br>\nValidation: 94.66%<br>\nTest: 94.77%<br><\/p>","58f27676":"<h1>MODEL CREATION<\/h1>","b3f6e751":"<h1>FIT MODEL<\/H1>"}}