{"cell_type":{"d57703e1":"code","bcd3c622":"code","1e5d0928":"code","26f414cc":"code","2c919bac":"code","b5438084":"code","3781d0fb":"code","5216896b":"code","035e5de4":"code","463a9343":"code","34b543d6":"code","ba068b47":"code","ce206327":"code","29ae2f34":"code","3d1029d5":"code","c3b9bf9a":"code","5755a32d":"code","60caf351":"code","708d88b9":"code","d0f4efcc":"code","1470d301":"code","c49dd170":"code","248385e8":"code","12acde33":"code","a8b15fe2":"code","ac649865":"code","902d009d":"code","60dabe07":"code","73e2fd59":"code","bdd9eab3":"code","d9c04888":"code","08c8c428":"code","7344c9f4":"code","2053b833":"code","8a3c345a":"code","930e269b":"code","e9f6486e":"code","54b4f478":"code","40a52a48":"code","e1bfb678":"code","48b54a15":"code","4f793347":"code","e99bd562":"code","28402958":"code","5cf028d8":"code","20b7a11a":"code","e72e0f3f":"code","6ba19c7b":"code","b6f51ce9":"code","434897ef":"markdown","93ddd749":"markdown","60b7315e":"markdown","bd659b0c":"markdown","8800909a":"markdown","57c417de":"markdown","26524940":"markdown","baac1cf3":"markdown","a9fa56d2":"markdown","d4412f7e":"markdown","81146313":"markdown","06362dec":"markdown","08afc373":"markdown","c4c007f2":"markdown","dde8c694":"markdown","f1a1e7b5":"markdown","7b90b4f3":"markdown","a17262b5":"markdown","9225f42f":"markdown","d921b2e5":"markdown","74cf002e":"markdown","d1b4f2f3":"markdown","0cd7c24c":"markdown","5804ba58":"markdown","7b1017c9":"markdown","aef34509":"markdown","81473a15":"markdown","5fe2f631":"markdown","62f3882b":"markdown","fa2061c4":"markdown","7a624ce0":"markdown","ce1d405e":"markdown","c6e22f19":"markdown","ab8c08c2":"markdown","6182792c":"markdown","8f71661b":"markdown","4221a362":"markdown","a90d9552":"markdown","605e72ae":"markdown","89160f3c":"markdown","605a3b6a":"markdown","bac91fa2":"markdown","5893ede0":"markdown","1d8f1648":"markdown","4051fd5f":"markdown","41b665eb":"markdown","b82f7541":"markdown","ecd9ac26":"markdown","8b30378e":"markdown","e708a93b":"markdown","e4162ad8":"markdown","42cb83cb":"markdown","f3da18cb":"markdown","698eed64":"markdown","9259c28f":"markdown","691da6cb":"markdown","c57c6e9a":"markdown","3df24a54":"markdown","ef19ba5a":"markdown","be078310":"markdown","d3785713":"markdown","aecfb152":"markdown","8b3be758":"markdown","03381a89":"markdown","9fd7633f":"markdown","a7a62b3e":"markdown","6d73f923":"markdown","523eb80a":"markdown","025752e0":"markdown","5b453df6":"markdown","d152ccbc":"markdown","f050b5f5":"markdown","2c49a2c6":"markdown","c60dd7d5":"markdown","06467c2e":"markdown","39388b3b":"markdown","7cfcf1f7":"markdown","456a3df4":"markdown","24bc64f2":"markdown","bf991628":"markdown","933602f5":"markdown","c52d2237":"markdown"},"source":{"d57703e1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import ConnectionPatch\nimport seaborn as sns\nimport sys\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bcd3c622":"dataframe = pd.read_csv('\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\ndataframe.head()","1e5d0928":"df = dataframe.copy()\ndf = df[1:]\ndf = df.reset_index(drop=True) #Reset index\ndf.head()","26f414cc":"def ds_explore(column):\n    plt.figure(figsize=(12,6))\n    count = sns.countplot(data=df, y=column, order=column.value_counts().iloc[:16].index)\n    for i in count.patches:\n        count.annotate(format(i.get_width()),((i.get_x() + i.get_width()), i.get_y()), \n                                xytext=(30,-8),fontsize=9, color='#000000', \n                                textcoords='offset points', \n                                horizontalalignment='right')","2c919bac":"ds_explore(df['Q1'])\nplt.title('Age Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Age', fontsize=16)","b5438084":"ds_explore(df['Q2'])\nplt.title('Gender Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Gender', fontsize=16)","3781d0fb":"df['Q3'] = df['Q3'].replace({\n    'United States of America':'USA',\n    'United Kingdom of Great Britain and Northern Ireland':'UK'\n})\nds_explore(df['Q3'])\nplt.title('Country Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Country', fontsize=16)","5216896b":"df['Q4'] = df['Q4'].replace({\n    'Some college\/university study without earning a bachelor\u2019s degree':'Without bachelor\u2019s degree',\n    'No formal education past high school':'High school'\n})\nds_explore(df['Q4'])\nplt.title('Formal Education Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Education', fontsize=16)","035e5de4":"ds_explore(df['Q5'])\nplt.title('Job Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Job', fontsize=16)","463a9343":"df['Q6'] = df['Q6'].replace({\n    'I have never written code':'0',\n    '20+ years':'> 20'\n})\ndf['Q6'] = df['Q6'].str.replace('years,?','', regex=True)\nds_explore(df['Q6'])\nplt.title('Programming Experience', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Years', fontsize=16)","34b543d6":"df['Q15'] = df['Q15'].replace({\n    'Under 1 year':'< 1',\n    'I do not use machine learning methods':'0',\n    '20 or more years':'> 20'\n})\ndf['Q15'] = df['Q15'].str.replace('years,?','', regex=True)\nds_explore(df['Q15'])\nplt.title('Machine Learning Experience', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Years', fontsize=16)","ba068b47":"plt.figure(figsize=(12,6))\ncount = sns.countplot(data=df, y='Q25', order=df['Q25'].value_counts().index)\nfor i in count.patches:\n    count.annotate(format(i.get_width()),((i.get_x() + i.get_width()), i.get_y()),\n                   xytext=(30,-8),fontsize=9, color='#000000', textcoords='offset points',\n                   horizontalalignment='right')\nplt.title('Yearly Compensation', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Compensation (USD)', fontsize=16)","ce206327":"df['Q26'] = df['Q26'].replace({\n    '$0 ($USD)':'0',\n    '$100,000 or more ($USD)':'> 100,000'\n})\nplt.figure(figsize=(12,6))\ncount = sns.countplot(data=df, y='Q26', order=df['Q26'].value_counts().index)\nfor i in count.patches:\n    count.annotate(format(i.get_width()),((i.get_x() + i.get_width()), i.get_y()),\n                   xytext=(30,-8),fontsize=9, color='#000000', textcoords='offset points',\n                   horizontalalignment='right')\nplt.title('Money Spend on Cloud Services', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('(USD)', fontsize=16)","29ae2f34":"def to_float(column):\n    for i in range(len(column)):\n        if pd.isnull(column[i]) == False:\n            if column[i].find('-') != -1:\n                number0 = float(column[i].split('-')[0])\n                number1 = float(column[i].split('-')[1])\n                column[i] = np.random.uniform(number0, number1)\n            elif column[i] == 0:\n                column[i] = 0\n            else:\n                number2 = float(column[i].split()[0])\n                number3 = number2+2.0\n                column[i] = np.random.uniform(number2, number3)\n    return column\n\ndef to_int(column):\n    for i in range(len(column)):\n        if pd.isnull(column[i]) == False:\n            if column[i].find('-') != -1:\n                number0 = int(column[i].split('-')[0])\n                number1 = int(column[i].split('-')[1])\n                column[i] = np.random.randint(number0, number1)\n            elif column[i] == 0:\n                column[i] = 0\n            else:\n                number2 = int(column[i].split()[0])\n                number3 = number2+2\n                column[i] = np.random.randint(number2, number3)\n    return column","3d1029d5":"# 1. Change salary column from string into float, we fill the value using random value with range\ndf['yearly_comp'] = df['Q25']\ndf['yearly_comp'] = df['yearly_comp'].str.replace('\\$|,|<|>','', regex=True)\ndf['yearly_comp'] = to_float(df['yearly_comp'])\n\n# 2. Change salary column from string into float, we fill the value using random value with range\ndf['money_spend'] = df['Q26']\ndf['money_spend'] = df['money_spend'].str.replace('\\$|,|<|>','', regex=True)\ndf['money_spend'] = to_float(df['money_spend'])\n\n# 3. Change experience column from string into int, we fill the value using random value with range\ndf['prog_exp'] = df['Q6']\ndf['prog_exp'] = df['prog_exp'].str.replace(' |,|<|>','', regex=True)\ndf['prog_exp'] = to_int(df['prog_exp'])\n\n# 4. Change experience column from string into int, we fill the value using random value with range\ndf['ml_exp'] = df['Q15']\ndf['ml_exp'] = df['ml_exp'].str.replace(' |,|<|>','', regex=True)\ndf['ml_exp'] = to_int(df['ml_exp'])\n\n# 5. Change age column from string into int, we fill the value using random value with range\ndf['age_y'] = df['Q1']\ndf['age_y'] = df['age_y'].str.replace('+','', regex=True)\ndf['age_y'] = to_int(df['age_y'])","c3b9bf9a":"newdf = df[['ml_exp', 'prog_exp', 'age_y', 'money_spend', 'yearly_comp']].copy()","5755a32d":"# We don't remove the nan value, but we will fill the missing value\n# Sort the dataframe by age\nnewdf = newdf.sort_values(by='age_y')\n# Fill the missing value using  ffill method\n# ffill method : propagates the last observed non-null value forward until another non-null value is encountered\n# That's why we sort the dataframe by age\nnewdf = newdf.fillna(axis=0, method='ffill')\n\n# Fill with mean value\nnewdf['prog_exp'] = newdf['prog_exp'].fillna(newdf['prog_exp'].mean())\nnewdf['age_y'] = newdf['age_y'].fillna(newdf['age_y'].mean())\nnewdf['ml_exp'] = newdf['ml_exp'].fillna(newdf['ml_exp'].mean())\nnewdf['money_spend'] = newdf['money_spend'].fillna(newdf['money_spend'].mean())\nnewdf['yearly_comp'] = newdf['yearly_comp'].fillna(newdf['yearly_comp'].mean())\nnewdf = newdf.sort_index()","60caf351":"# CLustering library\nfrom sklearn.cluster import KMeans","708d88b9":"dataset = newdf[['ml_exp', 'prog_exp', 'age_y', 'money_spend', 'yearly_comp']].copy()\n\n# Using elbow method to find the best K value\nsse = []\nk_rng = range(1, 10)\nfor k in k_rng:\n    km = KMeans(n_clusters=k)\n    km.fit(dataset)\n    sse.append(km.inertia_)\n\nplt.plot(k_rng, sse)\nplt.xlabel('K')\nplt.ylabel('Sum of Squared Error', fontsize=16)\nplt.title('Elbow Method', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","d0f4efcc":"# Modeling\nmodel = KMeans(n_clusters=3)\ny_pred = model.fit_predict(dataset)\n\n# add cluster to new column\nnewdf['cluster'] = y_pred\nnewdf.corr()","1470d301":"df1 = newdf[newdf.cluster==0]\ndf2 = newdf[newdf.cluster==1]\ndf3 = newdf[newdf.cluster==2]\nplt.figure(figsize=(8, 6))\nplt.scatter(df1.age_y, df1['yearly_comp'], color='green')\nplt.scatter(df2.age_y, df2['yearly_comp'], color='red')\nplt.scatter(df3.age_y, df3['yearly_comp'], color='blue')\nplt.xlabel('Age')\nplt.ylabel('Yearly Compensation')","c49dd170":"newdf['exp_level'] = newdf['cluster']\nnewdf['exp_level'] = newdf['exp_level'].replace({\n    0:'Entry',\n    1:'Expert',\n    2:'Mid'\n})\n\n# concatinating df with newdf\ndf = pd.concat([df, newdf['exp_level']], axis=1)\ndf['exp_level'].value_counts()","248385e8":"def profile_level(col, level, explode, explode_n):\n    # Entry\n    # make figure and assign axis objects\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n    fig.subplots_adjust(wspace=0)\n\n    # pie chart parameters\n    ratios = df['exp_level'].value_counts()\n    labels = df['exp_level'].unique()\n    explode = explode\n\n    # rotate so that first wedge is split by the x-axis\n    angle = 0 * ratios[0]\n    ax1.pie(ratios, autopct='%1.1f%%', startangle=angle, labels=labels, explode=explode)\n\n    # bar chart parameters\n    xpos = 0\n    bottom = 0\n    ratios = df.loc[df['exp_level'] == level, col].value_counts()\n    width = .2\n\n    for j in range(len(ratios)):\n        height = ratios[j]\n        ax2.bar(xpos, height, width, bottom=bottom)\n        ypos = bottom + ax2.patches[j].get_height() \/ 2\n        bottom += height\n        ax2.text(xpos, ypos, (ax2.patches[j].get_height()), ha='center')\n\n    ax2.set_title('Count')\n    ax2.legend(df.loc[df['exp_level'] == level, col].unique(), loc='upper right')\n    ax2.axis('off')\n    ax2.set_xlim(- 2.5 * width, 2.5 * width)\n\n    # use ConnectionPatch to draw lines between the two plots\n    # get the wedge data\n    theta1, theta2 = ax1.patches[explode_n].theta1, ax1.patches[explode_n].theta2\n    center, r = ax1.patches[explode_n].center, ax1.patches[explode_n].r\n    bar_height = sum([item.get_height() for item in ax2.patches])\n\n    # draw top connecting line\n    x = r * np.cos(np.pi \/ 180 * theta2) + center[0]\n    y = r * np.sin(np.pi \/ 180 * theta2) + center[1]\n    con = ConnectionPatch(xyA=(-width \/ 2, bar_height), coordsA=ax2.transData, xyB=(x, y), coordsB=ax1.transData)\n    con.set_color([0, 0, 0])\n    con.set_linewidth(4)\n    ax2.add_artist(con)\n\n    # draw bottom connecting line\n    x = r * np.cos(np.pi \/ 180 * theta1) + center[0]\n    y = r * np.sin(np.pi \/ 180 * theta1) + center[1]\n    con = ConnectionPatch(xyA=(-width \/ 2, 0), coordsA=ax2.transData, xyB=(x, y), coordsB=ax1.transData)\n    con.set_color([0, 0, 0])\n    ax2.add_artist(con)\n    con.set_linewidth(4)\n    plt.show()","12acde33":"sns.set_palette('CMRmap_r')\n# col, level, explode, explode_n\nprofile_level('Q1', 'Entry', [0.1, 0.0, 0.0], 0)","a8b15fe2":"# col, level, explode, explode_n\nprofile_level('Q1', 'Mid', [0.0, 0.1, 0.0], 1)","ac649865":"# col, level, explode, explode_n\nprofile_level('Q1', 'Expert', [0.0, 0.0, 0.1], 2)","902d009d":"# col, level, explode, explode_n\nprofile_level('Q4', 'Entry', [0.1, 0.0, 0.0], 0)","60dabe07":"# col, level, explode, explode_n\nprofile_level('Q4', 'Mid', [0.0, 0.1, 0.0], 1)","73e2fd59":"# col, level, explode, explode_n\nprofile_level('Q4', 'Expert', [0.0, 0.0, 0.1], 2)","bdd9eab3":"def behavior_ds(cols):\n    list_Q = [col for col in df.columns if cols in col]\n    Q = df[list_Q].copy()\n    exp = pd.concat([Q, df['exp_level']], axis=1)\n    new_exp = (exp.melt(\n        id_vars='exp_level', \n        value_vars = list_Q, \n        value_name=cols).drop('variable', axis=1))\n    plt.figure(figsize=(12,10))\n    count = sns.countplot(data=new_exp, y=cols, hue='exp_level', order=new_exp[cols].value_counts().iloc[:10].index)\n    for i in count.patches:\n        count.annotate(int(i.get_width()),((i.get_x() + i.get_width()), i.get_y()), \n                       xytext=(26,-9),fontsize=9, color='#000000', textcoords='offset points', horizontalalignment='right')\n        \ndef behavior_ds_one(col):\n    plt.figure(figsize=(12,10))\n    count = sns.countplot(data=df, y=col, hue='exp_level', order=df[col].value_counts().iloc[:10].index)\n    for i in count.patches:\n        count.annotate(format(i.get_width()),((i.get_x() + i.get_width()), i.get_y()), \n                       xytext=(30,-8),fontsize=9, color='#000000', textcoords='offset points', horizontalalignment='right')","d9c04888":"behavior_ds('Q7')\nplt.ylabel('Programming Language', fontsize=16)\nplt.title('Most used programming language on reguler basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","08c8c428":"behavior_ds_one('Q8')\nplt.ylabel('Programming Language', fontsize=16)\nplt.title('Programming language to learn data science recommend by data scientist', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","7344c9f4":"behavior_ds('Q9')\nplt.ylabel('IDE', fontsize=16)\nplt.title('Most used IDE on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","2053b833":"behavior_ds('Q10')\nplt.ylabel('Hosted Notebook', fontsize=16)\nplt.title('Most used hosted notebook products on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","8a3c345a":"behavior_ds('Q12')\nplt.ylabel('Hardware', fontsize=16)\nplt.title('Most used specialized hardware on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","930e269b":"behavior_ds('Q14')\nplt.ylabel('Data Visualization Libraries', fontsize=16)\nplt.title('Most used data visualization libraries on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","e9f6486e":"behavior_ds('Q16')\nplt.ylabel('Machine Learning Framework', fontsize=16)\nplt.title('Most used machine learning framework on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","54b4f478":"behavior_ds('Q17')\nplt.ylabel('Machine Learning Algorithms', fontsize=16)\nplt.title('Most used machine learning algorithms on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","40a52a48":"behavior_ds('Q31_A')\nplt.ylabel('Machine Learning Products', fontsize=16)\nplt.title('Most used managed machine learning products', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","e1bfb678":"behavior_ds('Q37_A')\nplt.ylabel('Automated Machine Learning Tools', fontsize=16)\nplt.title('Most used automated machine learning tools on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","48b54a15":"behavior_ds('Q18')\nplt.ylabel('Computer Vision Methods', fontsize=16)\nplt.title('Most used computer vision methods on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","4f793347":"behavior_ds('Q27_A')\nplt.ylabel('Cloud Computing Platforms', fontsize=16)\nplt.title('Most used cloud computing platforms on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","e99bd562":"behavior_ds('Q30_A')\nplt.ylabel('Data Storage Products', fontsize=16)\nplt.title('Most used data storage products on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","28402958":"behavior_ds('Q32_A')\nplt.ylabel('Big Data Products', fontsize=16)\nplt.title('Most used big data products one regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","5cf028d8":"behavior_ds_one('Q35')\nplt.ylabel('Business Intelligence Tools', fontsize=16)\nplt.title('Most used business intelligence tools for data science', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","20b7a11a":"behavior_ds('Q40')\nplt.ylabel('Learning Platform', fontsize=16)\nplt.title('A platform to learn data science', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","e72e0f3f":"behavior_ds('Q42')\nplt.ylabel('Media Sources', fontsize=16)\nplt.title('Favorite media sources that report on data science topics', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","6ba19c7b":"behavior_ds('Q39')\nplt.ylabel('Publicy Platform', fontsize=16)\nplt.title('A platform for publish data analysis or machine learning applications', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","b6f51ce9":"from datetime import date\n\ndates = [date(2022, 1, 1), date(2022, 1, 15), date(2022, 2, 15), date(2022, 3, 15), \n         date(2022, 4, 15), date(2022, 6, 15), date(2022, 7, 1)]\n \nlabels = [\n    'Statistics and Mathematics\\nStd, Mean, Median, Mode, etc',\n    'Programming\\nPython, R, SQL', \n    'Data Extraction\\nPython Libraries (e.g. Pandas, Numpy)', \n    'Exploratory Data Analysis\\nSeaborn, Matplotlib, Plotly, etc',\n    'Machine Learning\\nMachine Learning Frameworks and Algorithms',\n    'Data Engineering\\nCloud Services, Deploying Machine Learning Model, ETL, etc',\n    'Keep Practicing ~'\n]\n\n# Add label to dates\nlabels = ['{0:%d %b %Y}\\n{1}'.format(d, l) for l, d in zip (labels, dates)]\n\nfig, ax = plt.subplots(figsize=(16, 4), constrained_layout=True)\nax.set_ylim(-1, 1)\n\nax.scatter(dates, np.zeros(len(dates)), s=120, zorder=2)\nax.scatter(dates, np.zeros(len(dates)), s=30, zorder=3)\n\nlabel_offsets = np.zeros(len(dates))\nlabel_offsets[::2] = 0.4 # top label\nlabel_offsets[1::2] = -0.7 # bottom label\nfor i, (l, d) in enumerate(zip(labels, dates)):\n    ax.text(d, label_offsets[i], l, ha='center', fontsize=12)\n\nstems = np.zeros(len(dates))\nstems[::2] = 0.35 # top marker\nstems[1::2] = -0.35 # bottom marker\nmarkerline, stemline, baseline = ax.stem(dates, stems, use_line_collection=True)\nplt.setp(markerline, color='black')\nplt.setp(stemline, color='black')\n\n# hide chart border\nfor spine in [\"left\", \"top\", \"right\", \"bottom\"]:\n    ax.spines[spine].set_visible(False)\n\nax.set_xticks([])\nax.set_yticks([])    \nax.set_title('Data Science Roadmap', fontweight=\"bold\", fontsize=16)","434897ef":"**2. Integrated Development Environments (IDE)**","93ddd749":"# **<div style=\"text-align: center\">Thank You!<\/div>**","60b7315e":"**2. Money Spent on Machine Learning\/Cloud Computing Services**","bd659b0c":"# **D. Identifying The Data Scientist**","8800909a":"**Although Data Science is a high-demand job, there are still few experts in the field. You can become a Data Science regardless of your background. After reading some of the data presented above and reading the Data Science Roadmap, I hope you have a better understanding of how to begin as a Data Science until you become an expert. This is only a small portion of what data science has to provide, you may learn more from experts by visiting data science forums or platforms like Kaggle and others.**","57c417de":"**4. Data Visualization Libraries**","26524940":"**Entry Level by Education**","baac1cf3":"**Keep up-to-date with data science topics**","a9fa56d2":"**What is their favorite visualization library?**","d4412f7e":"**1. Programming Experience**","81146313":"# **F. Conclusion**","06362dec":"# **<div style=\"text-align: center\">What We Observe?<\/div>**","08afc373":"**They also give you a recommendation about what programming language you should learn to work in the data field**","c4c007f2":"**3. Country**","dde8c694":"**At this step, we'll try to understand and find out who is our subject of observation.**","f1a1e7b5":"**6. Who are they?**","7b90b4f3":"**Expert Level by Education**","a17262b5":"# **<div style=\"text-align: center\">The Challenge Objective<\/div>**","9225f42f":"**8. Data Storage Products**","d921b2e5":"**What is their favorite big data product?**","74cf002e":"**Favorite platform to learn data science**","d1b4f2f3":"**It is not easy to visualize all features of data in clustering, we will use one feature with the highest correlation value.**","0cd7c24c":"**6. Computer Vision**","5804ba58":"**Tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration. The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners.**","7b1017c9":"**What is their favorite business intelligence tool?**","aef34509":"**By Respondent's Education**","81473a15":"**When using data science tools, the majority of our respondents behaved in a similar way, whether they were beginners, intermediates, or experts.** \n1. Python is the most popular programming language among our respondents, and they advise learning it if you want to work as a data scientist.\n2. Their favorite IDEs are Jupyter Notebook and VSCode. Their favorite hosted notebooks are Colab, and Kaggle.\n3. Although the majority of our respondents do not employ specialized hardware, NVIDIA GPU and Google Cloud TPU are the most popular.\n4. Their favorite data visualization libraries are Matplotlib and Seaborn.\n5. The most popular machine learning frameworks are Scikit-Learn and TensorFlow, and the most popular machine learning algorithms are Linear Regression and Decision Trees or Random Forest. However, most of them do not use machine learning products or automated machine learning tools.\n6. Their primary computer vision method is image classification.\n7. Amazon's cloud computing and data storage capabilities remain at the top\n8. MySQL as their big data solution.\n9. The most popular business intelligence tool is Microsoft Power BI, however other experts prefer Tableau.\n10. Our respondents' preferred learning sites are Coursera,Kaggle Learn and Udemy, they used Kaggle to gain information about data science topics. They use GitHub to share their machine learning apps.","5fe2f631":"**What is their favorite cloud computing platforms?**","62f3882b":"# **C. Work as Data Scientist**","fa2061c4":"# **<div style=\"text-align: center\">Read The Dataset<\/div>**","7a624ce0":"**3. Handle the missing value**","ce1d405e":"# **<div style=\"text-align: center\">Main Dataframe<\/div>**","c6e22f19":"**9. Business Intelligence Tools**","ab8c08c2":"**We will explore the data of Data Scientist practitioners, get information about their job role, experience, their favorite tools and other information related to being an expert in Data Science.**","6182792c":"****Middle Level by Age****","8f71661b":"**Data Science Roadmap**","4221a362":"**What is their favorite machine learning product?**","a90d9552":"**Expert Level by Age**","605e72ae":"**1. Convert from string to numeric variable**","89160f3c":"# **<div style=\"text-align: center\">Exploratory Data Analysis<\/div>**","605a3b6a":"**1. Age**","bac91fa2":"**Middle Level by Education**","5893ede0":"**5. Give a name to the cluster**","1d8f1648":"**What is their favorite computer vision method?**","4051fd5f":"**What is their favorite IDE?**","41b665eb":"**5. Job Title**","b82f7541":"**By Respondent's Age**","ecd9ac26":"**We'll learn about data scientists' behaviors when working in the field, such as \"What programming language do they use?\" \"What cloud computing services do they use?\" \"What are their preferred tools?\" and so on. We'll use their actions as a blueprint for becoming data scientists.**","8b30378e":"**What is their favorite data storage product?**","e708a93b":"**Entry Level by Age**","e4162ad8":"**What is their favorite programming language?**","42cb83cb":"**We might assume that the respondent's lowest level of education is high school. I believe we all studied basic statistics and mathematics in high school, and with only those fundamentals, we can begin our journey to become data scientists. Basic statistics lectures are mostly given by some Data Science learning platforms as a refresher.**","f3da18cb":"**2. Gender**","698eed64":"**We can draw some conclusions based on the information we've gathered.**","9259c28f":"**Now, We know the profile, experience, and salary of our respondents. Next, we will identify our respondents into some categories. We can use the data of profile, experience, salary and etc. The categories will split our respondents by their capabilities or level.**","691da6cb":"**5. Machine Learning**","c57c6e9a":"**What is their favorite automated machine learning tool?**","3df24a54":"**4. Education**","ef19ba5a":"**According to the information provided, the majority of poll respondents are men aged 18 to 29. India has the most data science responders, followed by the United States in second place. In their education, the majority of our responders have a master's degree. Some of them don't refer to themselves as data scientists-practitioners, but they have used data science in various capacities.**","be078310":"# **A. Respondent's Profile**","d3785713":"**1. Yearly Compensation**","aecfb152":"# **B. Data Science Experience**","8b3be758":"**Analyze the respondent's experience data, this information is significant since it will be used as one of the clustering technique's features, along with other data that supports the method.**","03381a89":"**We can use the experience level data to see their profile broken down by experience level.**","9fd7633f":"**We read the data given by Kaggle, the Kaggle Survey 2021 data. The warning occurs because the data frame has a different data type on the first index or in index 0. Now we will remove the 0 index and use the rest as our main data frame.**","a7a62b3e":"**Some of our respondents have worked in the data field and they are paid for it, they also spend money on computing services. This information can be used as a data feature.**","6d73f923":"# **E. The Behavior of Data Scientist**","523eb80a":"**3. Specialized Hardware**","025752e0":"**7. Cloud Computing Platforms**","5b453df6":"**What is their favorite specialized hardware?**","d152ccbc":"**We can give name labels to the highest yearly compensation as Expert, and the middle as Mid, and the least yearly compensation as Entry.**","f050b5f5":"**What is their favorite Hosted Notebook?**","2c49a2c6":"**2. Create a new dataframe for clustering**","c60dd7d5":"**The use of 3 clusters makes acceptable. The level of a data scientist is commonly divided into an entry-level data scientist, a mid-level data scientist, and an expert data scientist, depending on the data science job opening.**","06467c2e":"**1. Programming Language**","39388b3b":"**4. Clustering with KMeans method**","7cfcf1f7":"**I hope that everyone who reads this data visualization finds it to be useful. Since I'm also an entry-level person, you can give me advice if you see any inaccurate or misleading information.**","456a3df4":"**10. Data Science Platform**","24bc64f2":"**2. Machine Learning Experience**","bf991628":"**What is their favorite machine learning algorithm?**","933602f5":"**What is their favorite machine learning framewok?**","c52d2237":"**What is their favorite platform to share their machine learning application?**"}}