{"cell_type":{"5b15f55c":"code","eb0c87dd":"code","41a76ccb":"code","b52ed146":"code","07afcf98":"code","df13b8b3":"code","c8a43051":"code","422da3ad":"code","25c65d61":"code","1afbe213":"code","655f63b5":"code","585a9e2e":"code","11328678":"code","baae22ac":"code","7e33d236":"code","530a9f74":"code","46a85e0b":"code","0d4d35e8":"code","1e394f98":"code","115b29a8":"code","ab0a613d":"code","62907cdf":"code","601c1897":"code","33643f66":"code","30c53b03":"code","cd2a9224":"code","3cee2776":"code","74282622":"code","3a3151ba":"code","1ba54166":"code","cec7936f":"code","88cac2b0":"code","ed110caf":"code","4e971e00":"code","6df85209":"code","248cd20c":"code","d36502c1":"code","e22ddaf0":"code","e9fb22fa":"code","c3850c43":"code","4d5174db":"code","406c4149":"code","7359fd3a":"code","4e371ee6":"code","1e4c87b3":"code","b83e6659":"code","e6c60673":"code","577c3d51":"code","ca7a804e":"code","f5a07486":"code","a00a5a25":"code","732e74d7":"code","bd0f8041":"code","512da14f":"code","13afb273":"code","82f3b196":"code","8a37d7d0":"code","89a4a4c3":"code","47eff227":"code","5b58055b":"code","f5d028d3":"code","2fcd9f1a":"code","e4f34a68":"code","c8b5c2e8":"code","4117cef5":"code","35a0118b":"code","6e92f4c0":"code","21949cc9":"code","79736f0e":"code","be89c202":"code","cd92a2e6":"code","96095e2b":"code","ee331469":"code","a03f88a4":"code","4ad241b4":"code","217faef4":"code","f08b2fd4":"code","be6bd82d":"code","4e147cd3":"code","9d2ca658":"code","f548e1c9":"code","1d9d4e4f":"code","e5baf405":"code","656ca75a":"code","a83a054a":"code","53c1b7e7":"code","4c890078":"code","f1bd866b":"code","6a3ba4c4":"code","7b555fec":"code","b1da70aa":"code","d7389add":"code","de82aefd":"code","dc2201e2":"code","57304e13":"code","0f9f21ee":"code","d7eeec61":"code","dd78a7e0":"code","963cf6e5":"code","15b44f86":"code","929d6366":"code","71902fe9":"code","6db9d0f0":"code","ac334458":"code","d934987f":"code","3ad1ae01":"code","a21f4136":"code","27271107":"code","0f138785":"code","a697d523":"code","bc7b835f":"code","85567bad":"code","b28d8e39":"code","a3f90745":"code","00e4da77":"code","218a7bed":"code","2003083b":"code","e062a2c9":"code","d362b941":"code","e3722edb":"code","604206c2":"code","41fe64e2":"code","5a101958":"code","5a0ab52d":"code","3f4f669c":"code","b3082df5":"code","2452ac9c":"code","f66debcf":"code","18fffb8f":"code","52a727dc":"code","f0259024":"code","0b8276f8":"code","90d25afc":"code","2716b583":"code","9d259c09":"code","7f8d195f":"markdown","a10a55ee":"markdown","9fc452ac":"markdown","cdb7c6e6":"markdown","7d565cc3":"markdown","3ae33a79":"markdown","113b2679":"markdown","23e75f6f":"markdown","89ecb34d":"markdown","627424d0":"markdown","ffe0ede4":"markdown","0ebea949":"markdown","ff567eb3":"markdown","e43fe387":"markdown","6f0b22c0":"markdown","1343d329":"markdown","c3a2e614":"markdown","3f4e2953":"markdown","d157d9f9":"markdown","562dc661":"markdown","5402218c":"markdown","c44d023c":"markdown","570bd632":"markdown","eacf442f":"markdown","f05ae63d":"markdown","1efb3d21":"markdown","4be64059":"markdown","10f5d924":"markdown","3529ab8a":"markdown","8ecfce83":"markdown","986fbcf0":"markdown","26a6ce1e":"markdown","d16d9271":"markdown","a95a9e52":"markdown","10e94087":"markdown","702002c1":"markdown","95fdc49e":"markdown","24e69640":"markdown","31b6ae7e":"markdown","a92d27a6":"markdown","70d7c553":"markdown","742d1e34":"markdown","ec0b89fb":"markdown","e8b8bf7d":"markdown","d20bb08b":"markdown","fe0f8713":"markdown","e5650dd9":"markdown","96301f25":"markdown","0035df58":"markdown","8638b4ad":"markdown","5c422776":"markdown","ae8ed6c2":"markdown","907a27b1":"markdown","e48878cd":"markdown","1a278fbb":"markdown","b53fdaab":"markdown","3326d1af":"markdown","83accb6b":"markdown","d78473a7":"markdown","34b11957":"markdown","f5a2d4e9":"markdown","9ae86f68":"markdown","227403ac":"markdown","166fdb89":"markdown"},"source":{"5b15f55c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eb0c87dd":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom geopy.geocoders import Nominatim\nimport folium\nfrom folium.plugins import HeatMap\nfrom folium.plugins import FastMarkerCluster\nfrom plotly import tools\nimport re\nfrom plotly.offline import init_notebook_mode, plot, iplot\nfrom wordcloud import WordCloud, STOPWORDS \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nimport missingno as msno\nimport glob\n\nsns.set_theme(style=\"whitegrid\")\nsns.color_palette(\"cubehelix\")","41a76ccb":"path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nall_files = glob.glob(path + \"\/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\n    \nengagement_df = pd.concat(li)\nengagement_df = engagement_df.reset_index(drop=True)\nengagement_df.head()","b52ed146":"engagement_df.shape","07afcf98":"engagement_df.isna().sum() * 100.0 \/ engagement_df.shape[0]","df13b8b3":"engagement_df.nunique()","c8a43051":"engagement_df.dtypes","422da3ad":"engagement_df_refined = engagement_df.copy()\nengagement_df_refined.head()","25c65d61":"engagement_df_refined[\"district_id\"] = engagement_df_refined[\"district_id\"].astype(\"category\")\nengagement_df_refined[\"district_id\"].head()","1afbe213":"engagement_df_refined[\"time\"] = pd.to_datetime(engagement_df_refined[\"time\"])\n## The day of the week with Monday=0, Sunday=6.\nengagement_df_refined[\"month\"] = engagement_df_refined[\"time\"].dt.month\nengagement_df_refined[\"dayofweek\"] = engagement_df_refined[\"time\"].dt.dayofweek\nengagement_df_refined[\"weekofyear\"] = engagement_df_refined[\"time\"].dt.weekofyear\nengagement_df_refined.head()","655f63b5":"engagement_df_refined.describe()","585a9e2e":"sns.scatterplot(data=engagement_df_refined\n               ,x=\"pct_access\"\n               ,y=\"engagement_index\")","11328678":"((engagement_df_refined[\"pct_access\"] == 0.0) & \n (engagement_df_refined[\"engagement_index\"] > 0.0)).sum()","baae22ac":"((engagement_df_refined[\"pct_access\"] > 0.0) & \n (engagement_df_refined[\"engagement_index\"] == 0.0)).sum()","7e33d236":"engagement_df_refined[  (engagement_df_refined[\"lp_id\"].isna()) \n                      | (engagement_df_refined[\"pct_access\"].isna())\n                      | (engagement_df_refined[\"engagement_index\"].isna())\n                     ].head(10)","530a9f74":"((engagement_df_refined[\"pct_access\"] == 0.0) & \n (engagement_df_refined[\"engagement_index\"].isna())).sum()","46a85e0b":"engagement_df_refined[\"engagement_index\"].fillna(value=engagement_df_refined[\"pct_access\"] * 10.\n                                                ,inplace=True)","0d4d35e8":"engagement_df_refined[\"pct_access\"].fillna(value=engagement_df_refined[\"engagement_index\"] \/ 10.\n                                          ,inplace=True)","1e394f98":"engagement_df_refined.isna().sum()","115b29a8":"((engagement_df_refined[\"pct_access\"].isna()) & \n (engagement_df_refined[\"engagement_index\"].isna())).sum()","ab0a613d":"engagement_df_refined[\"pct_access\"].fillna(value=0.0 ,inplace=True)","62907cdf":"engagement_df_refined[\"engagement_index\"].fillna(value=0.0, inplace=True)","601c1897":"engagement_df_refined.isna().sum() ","33643f66":"engagement_df_refined[engagement_df_refined[\"lp_id\"].isna()].head(10)","30c53b03":"engagement_df_refined[\"engagement_index_lower_bound\"] = (engagement_df_refined[\"pct_access\"] \/ 100.0) * 1000.0\nengagement_df_refined.head(10)","cd2a9224":"((engagement_df_refined[\"engagement_index\"] >= engagement_df_refined[\"engagement_index_lower_bound\"])).sum()","3cee2776":"engagement_df_refined[((engagement_df_refined[\"engagement_index\"] < engagement_df_refined[\"engagement_index_lower_bound\"]))].index","74282622":"engagement_df_refined.drop( engagement_df_refined[((engagement_df_refined[\"engagement_index\"] < engagement_df_refined[\"engagement_index_lower_bound\"]))].index\n                          , inplace=True)\n\nengagement_df_refined.shape","3a3151ba":"print(\"Percentage of dropped rows (engagement_index_lower_bound check): \", 1171702 * 100. \/ (1171702 + 21152488))","1ba54166":"# sns.scatterplot( x=\"pct_access\"\n#                , y=\"engagement_index\"\n#                , data=engagement_df_refined)","cec7936f":"engagement_df_refined[\"pct_access_upper_bound\"] = (engagement_df_refined[\"engagement_index\"] \/ 1000.0) * 100.0\nengagement_df_refined.head(10)","88cac2b0":"print(\"pct_access_upper_bound check passed rows: \", (engagement_df_refined[\"pct_access\"] <= engagement_df_refined[\"pct_access_upper_bound\"]).sum())","ed110caf":"print(\"pct_access_upper_bound check falied rows: \", (engagement_df_refined[\"pct_access\"] > engagement_df_refined[\"pct_access_upper_bound\"]).sum())","4e971e00":"engagement_df_refined.drop( engagement_df_refined[((engagement_df_refined[\"pct_access\"] > engagement_df_refined[\"pct_access_upper_bound\"]))].index\n                          , inplace = True)\n\nengagement_df_refined.shape","6df85209":"print(\"Percentage of pct_access_upper_bound check failed entries: \", 442 * 100. \/ (1171702 + 442 + 21152488))","248cd20c":"engagement_df_refined.describe()","d36502c1":"engagement_df_refined.drop([\"engagement_index_lower_bound\", \n                            \"pct_access_upper_bound\"]\n                           ,axis=1\n                           ,inplace=True\n                          )","e22ddaf0":"sns.scatterplot( data=engagement_df_refined\n                ,x=\"pct_access\"\n                ,y=\"engagement_index\")","e9fb22fa":"engagement_df_refined[engagement_df_refined[\"lp_id\"].isna()].head(10)","c3850c43":"engagement_df_refined[\"lp_id\"].fillna(value=0.0, inplace=True)\n# engagement_df_refined[\"pct_access\"].fillna(value=0.0, inplace=True)\n# engagement_df_refined.dropna(subset=[\"engagement_index\"], inplace=True)","4d5174db":"engagement_df_refined[\"lp_id\"] = engagement_df_refined[\"lp_id\"].astype(\"category\")\nengagement_df_refined[\"month\"] = engagement_df_refined[\"month\"].astype(\"category\")\nengagement_df_refined[\"dayofweek\"] = engagement_df_refined[\"dayofweek\"].astype(\"category\")\nengagement_df_refined[\"weekofyear\"] = engagement_df_refined[\"weekofyear\"].astype(\"category\")","406c4149":"print(\"before imputation and cleaning: \\n\\n\", engagement_df.nunique())","7359fd3a":"print(\"after imputation and cleaning: \\n\\n\", engagement_df_refined.nunique())","4e371ee6":"print(\"Learning Platforms with wrong relationships = {0} - {1} = {2}\".format(\n        engagement_df[\"lp_id\"].nunique()\n      , engagement_df_refined[\"lp_id\"].nunique()\n      , engagement_df[\"lp_id\"].nunique() - engagement_df_refined[\"lp_id\"].nunique())\n     )","1e4c87b3":"engagement_df_refined.describe()","b83e6659":"basedate = pd.to_datetime('2020-01-01')\nengagement_df_refined[\"days_since\"] = (engagement_df_refined[\"time\"] - basedate).dt.days\nengagement_df_refined.describe()","e6c60673":"sns.distplot( engagement_df_refined[\"pct_access\"]\n            , kde=False)\n\nplt.show()\n\nprint(\"pct_access skew: \", engagement_df_refined[\"pct_access\"].skew())","577c3d51":"sns.distplot( engagement_df_refined[\"engagement_index\"]\n            , kde=False)\n\nplt.show()\n\nprint(\"engagement_index skew: \", engagement_df_refined[\"engagement_index\"].skew())","ca7a804e":"engagement_df_refined[\"district_id\"] = engagement_df_refined[\"district_id\"].astype(\"category\")\nengagement_df_refined[\"days_since\"] = engagement_df_refined[\"days_since\"].astype(\"category\")","f5a07486":"grouped = engagement_df_refined.groupby(by=[\"month\"])[\"lp_id\"].unique().reset_index(name=\"lp_id\")\ngrouped","a00a5a25":"## https:\/\/stackoverflow.com\/questions\/23333786\/reference-values-in-the-previous-row-with-map-or-apply\nnew_col = 'result'\n\ndef apply_func_decorator(func):\n    prev_row = {}\n    def wrapper(curr_row, **kwargs):\n        val = func(curr_row, prev_row)\n        prev_row.update(curr_row)\n        prev_row[new_col] = val\n        return val\n    return wrapper\n\n@apply_func_decorator\ndef running_total(curr_row, prev_row):\n\n      return np.unique(list(curr_row['lp_id'])  + list(prev_row.get(\"result\", [])))","732e74d7":"grouped[\"result\"] = np.nan\ngrouped[\"result\"] = grouped.apply( running_total\n                                 , axis=1)\n\ngrouped[\"result\"]","bd0f8041":"grouped[\"count\"] = grouped[\"result\"].apply(lambda x: len(x))","512da14f":"grouped[\"count\"]","13afb273":"plt.figure(figsize=(8, 6))\n\nsns.barplot(data=grouped\n            ,x=\"month\"\n            ,y=\"count\"\n            ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"unique learning platforms\")\nplt.show()","82f3b196":"grouped[\"lp_id\"] = grouped[\"lp_id\"].apply(np.sort)\ngrouped","8a37d7d0":"grouped[\"new_count\"] = grouped[\"count\"] - grouped[\"count\"].shift(1)\ngrouped[\"new_count\"].fillna(value=0, inplace=True)","89a4a4c3":"grouped","47eff227":"plt.figure(figsize=(8, 6))\n\nsns.barplot(data=grouped\n            ,x=\"month\"\n            ,y=\"new_count\"\n            ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"Newly-launched Learning Platforms\")\nplt.show()","5b58055b":"grouped[\"prev_result\"] = grouped[\"result\"].shift(1)\ngrouped[\"prev_result\"] = grouped[\"prev_result\"].fillna(\"\").apply(list)","f5d028d3":"grouped[\"discontinued\"] = (grouped[\"prev_result\"].map(set) - grouped[\"lp_id\"].map(set)).apply(list)\ngrouped","2fcd9f1a":"grouped[\"closed_count\"] = grouped[\"discontinued\"].apply(lambda x: len(x))\ngrouped","e4f34a68":"plt.figure(figsize=(8, 6))\n\nsns.barplot( x=\"month\"\n            ,y=\"closed_count\"\n            ,data=grouped\n            ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"discontinued learning platforms\")\nplt.show()","c8b5c2e8":"def intersection(a, b):\n    return list(set(a) & set(b))","4117cef5":"grouped[\"common\"] = grouped.apply( lambda x: intersection(x[\"lp_id\"], x[\"prev_result\"])\n                                 , axis=1)\n\ngrouped","35a0118b":"grouped[\"common_count\"] = grouped[\"common\"].apply(len)\ngrouped","6e92f4c0":"plt.figure(figsize=(8,6))\n\nsns.barplot(x=\"month\"\n           ,y=\"common_count\"\n           ,data=grouped\n           ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"sustained learning platforms\")\nplt.show()","21949cc9":"engagement_df_refined[\"district_id\"] = engagement_df_refined[\"district_id\"].astype(int)","79736f0e":"grouped = engagement_df_refined.groupby(by = [\"month\"])[\"district_id\"].unique().reset_index(name=\"district_id\")\ngrouped","be89c202":"@apply_func_decorator\ndef get_cumulative(curr_row, prev_row):\n\n    return np.unique(list(curr_row['district_id'])  + list(prev_row.get(\"result\", [])))","cd92a2e6":"grouped[\"result\"] = np.nan\ngrouped[\"result\"] = grouped.apply( get_cumulative\n                                  ,axis=1)","96095e2b":"grouped","ee331469":"grouped[\"cum_districts_count\"] = grouped[\"result\"].apply(lambda x: len(x))\ngrouped","a03f88a4":"plt.figure(figsize=(8,6))\n\nsns.barplot( data=grouped\n            ,x=\"month\"\n            ,y=\"cum_districts_count\"\n            ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"cumulative districts count\")\nplt.show()","4ad241b4":"engagement_df_refined[\"weekofyear\"] = engagement_df_refined[\"weekofyear\"].astype(int)\nengagement_df_refined[\"month\"] = engagement_df_refined[\"month\"].astype(int)\nengagement_df_refined[\"days_since\"] = engagement_df_refined[\"days_since\"].astype(int)\nengagement_df_refined[\"dayofweek\"] = engagement_df_refined[\"dayofweek\"].astype(int)","217faef4":"grouped = engagement_df_refined.groupby(by=[\"lp_id\", \"district_id\"])[\"weekofyear\"].agg([\"min\", \"max\", \"size\", \"nunique\"]).reset_index()\n\ngrouped = grouped.dropna()\n\ngrouped.rename( columns={ \"min\": \"min_week\"\n                        , \"max\": \"max_week\"\n                        , \"size\": \"total_days_used\"\n                        , \"nunique\": \"total_active_weeks\"\n                        }\n               ,inplace=True\n              )\n\ngrouped[\"total_span_in_weeks\"] = grouped[\"max_week\"] - grouped[\"min_week\"] + 1\n\ngrouped[\"lp_id\"] = grouped[\"lp_id\"].astype(int)\ngrouped[\"max_week\"] = grouped[\"max_week\"].astype(int)\ngrouped[\"min_week\"] = grouped[\"min_week\"].astype(int)\n\ngrouped.head(10)","f08b2fd4":"grouped.describe()","be6bd82d":"plt.figure(figsize=(8, 6))\n\nsns.histplot( x=\"total_span_in_weeks\"\n             ,data=grouped\n             )\n\nplt.xlabel(\"total span (in weeks)\")\nplt.xticks(rotation=30)\nplt.show()","4e147cd3":"dict_ = {\"freemium\": (grouped[\"total_span_in_weeks\"] == 1).sum()\n        ,\"paid\": (grouped[\"total_span_in_weeks\"] > 1).sum()\n        }\n\ngrouped_free_or_paid = pd.DataFrame.from_dict(dict_, orient=\"index\").reset_index()\ngrouped_free_or_paid.columns = [\"subscription\", \"count\"]\ngrouped_free_or_paid","9d2ca658":"((grouped[\"total_span_in_weeks\"] > 1) &\n (grouped[\"total_days_used\"] > 1)).sum() * 100. \/ (grouped[\"total_span_in_weeks\"] > 1).sum()","f548e1c9":"((grouped[\"total_span_in_weeks\"] == 1) &\n (grouped[\"total_days_used\"] > 1)).sum() * 100. \/ (grouped[\"total_span_in_weeks\"] == 1).sum()","1d9d4e4f":"fig = px.pie(\n    grouped_free_or_paid, \n    names='subscription', \n    values='count',\n    color_discrete_sequence=px.colors.sequential.Mint,\n    title='Percentage of Subscription Types', \n    width=700,\n    height=500,\n    hole=0.5\n)\n\nfig.show()","e5baf405":"grouped[grouped[\"total_days_used\"] == 1][\"lp_id\"].nunique() * 100. \/ grouped[\"lp_id\"].nunique()","656ca75a":"plt.figure(figsize=(12, 6))\n\nsns.countplot(x=\"max_week\"\n             ,data=grouped[ grouped[\"total_span_in_weeks\"] == 1 ]\n             )\n\nplt.title(\"Freemium offers vs. week\")\nplt.xlabel(\"week\")\nplt.ylabel(\"freemium count\")\nplt.xticks(rotation=60)\nplt.show()","a83a054a":"g = grouped[grouped[\"total_span_in_weeks\"] == 1]\n\ni = g['total_days_used'].quantile([0.05, 0.25, 0.5, 0.9, 0.95, 0.99, 0.999])\n# j = g['total_days_used'].agg(['min', 'max'])\n\n# pd.concat([i, j], axis=0)\n\n# g.describe()\n\ndf_percentiles = pd.DataFrame(i).reset_index()\ndf_percentiles.rename(columns={\"index\": \"percentile\"}, inplace=True)\n\nplt.figure(figsize=(8, 6))\n\nsns.lineplot(x=\"percentile\"\n            ,y=\"total_days_used\"\n            ,data=df_percentiles)\n\nplt.title(\"Freemium consumer-bases\")\nplt.ylabel(\"days used\")\nplt.show()","53c1b7e7":"plt.figure(figsize=(12, 6))\n\nsns.countplot(x=\"min_week\"\n             ,data=grouped[ grouped[\"total_span_in_weeks\"] > 1 ]\n             )\n\nplt.title(\"Paid registration vs. week\")\nplt.xlabel(\"week\")\nplt.ylabel(\"paid registration count\")\nplt.xticks(rotation=60)\nplt.show()","4c890078":"g = grouped[ grouped[\"total_span_in_weeks\"] > 1 ]\ni = g['total_days_used'].quantile([0.01, 0.05, 0.25, 0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.825, 0.8375, 0.85, 0.9, 0.95, 0.99, 0.995, 0.999])\n# j = g['total_days_used'].agg(['min', 'max'])\n\n# pd.concat([i, j], axis=0)\n\ndf_percentiles = pd.DataFrame(i).reset_index()\ndf_percentiles.rename(columns={\"index\": \"percentile\"}, inplace=True)\n\nplt.figure(figsize=(8, 6))\n\nsns.lineplot(x=\"percentile\"\n            ,y=\"total_days_used\"\n            ,data=df_percentiles)\n\nplt.title(\"Paid consumer-bases\")\nplt.ylabel(\"days used\")\nplt.show()","f1bd866b":"g = grouped[ grouped[\"total_span_in_weeks\"] == 1 ]\n\ng_details = pd.merge(g[[\"lp_id\", \"district_id\", \"min_week\", \"total_days_used\"]]\n                    ,engagement_df_refined[[\"lp_id\", \"district_id\", \"weekofyear\", \"pct_access\", \"engagement_index\"]]\n                    ,how=\"inner\"\n                    ,left_on=[\"lp_id\", \"district_id\", \"min_week\"]\n                    ,right_on=[\"lp_id\", \"district_id\", \"weekofyear\"]\n                    )\n\ng_details[\"lp_id\"] = g_details[\"lp_id\"].astype(int)\n\ng_details.head(10)","6a3ba4c4":"g_details.describe()","7b555fec":"g_details_agg = g_details.groupby(by=[\"lp_id\", \"district_id\"]).mean().reset_index()\ng_details_agg.head()","b1da70aa":"g_details_agg.describe()","d7389add":"dict_ = {\"inactive\": (g_details_agg[\"pct_access\"] == 0.).sum()\n        ,\"active\": (g_details_agg[\"pct_access\"] > 0.).sum()\n        }\n\ngrouped_freemium = pd.DataFrame.from_dict(dict_, orient=\"index\").reset_index()\ngrouped_freemium.columns = [\"activity type\", \"count\"]\ngrouped_freemium","de82aefd":"fig = px.pie(\n    grouped_freemium, \n    names='activity type', \n    values='count',\n    color_discrete_sequence=px.colors.sequential.Mint,\n    title='Percentage of Responsive Consumer Bases in Freemium', \n    width=700,\n    height=500,\n    hole=0.5\n)\nfig.show()","dc2201e2":"freemium_inactive = g_details_agg[ g_details_agg[\"pct_access\"] == 0. ]\n\nfreemium_inactive.describe()","57304e13":"(freemium_inactive[\"total_days_used\"] == 1).sum() * 100. \/ freemium_inactive.shape[0]","0f9f21ee":"(freemium_inactive[\"total_days_used\"] > 1).sum() * 100. \/ freemium_inactive.shape[0]","d7eeec61":"freemium_active = g_details_agg[ g_details_agg[\"pct_access\"] > 0. ]\n\nfreemium_active.describe()","dd78a7e0":"freemium_active.shape[0] * 100. \/ g_details_agg.shape[0]","963cf6e5":"# features = g_details_agg[(g_details_agg[\"pct_access\"] > 0) & \n#                          (g_details_agg[\"engagement_index\"] > 0)][[\"pct_access\", \"engagement_index\"]].reset_index(drop=True)\n\nfeatures = freemium_active[[  \"total_days_used\"\n                            , \"pct_access\"\n                            , \"engagement_index\"]].reset_index(drop=True)","15b44f86":"features.isna().sum()","929d6366":"(freemium_active[\"total_days_used\"] == 1).sum() * 100. \/ freemium_active.shape[0]","71902fe9":"(freemium_active[\"total_days_used\"] > 1).sum() * 100. \/ freemium_active.shape[0]","6db9d0f0":"features = freemium_active[[  \"lp_id\"\n                            , \"district_id\"\n                            , \"total_days_used\"\n                            , \"pct_access\"\n                            , \"engagement_index\"]].reset_index(drop=True)\nfeatures.shape","ac334458":"features.head()","d934987f":"scaler = preprocessing.MinMaxScaler()\nfeatures_normal = scaler.fit_transform(features[[\"pct_access\", \"engagement_index\"]])","3ad1ae01":"pd.DataFrame(features_normal).describe()","a21f4136":"inertia = []\nK = range(1,10)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k).fit(features_normal)\n    kmeanModel.fit(features_normal)\n    inertia.append(kmeanModel.inertia_)","27271107":"# Plot the elbow\nplt.plot(K, inertia, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Inertia')\nplt.show()","0f138785":"kmeans = KMeans(n_clusters=3, random_state=0).fit(features_normal)","a697d523":"labels = pd.DataFrame(kmeans.labels_) #This is where the label output of the KMeans we just ran lives. Make it a dataframe so we can concatenate back to the original data\nlabeledCombs = pd.concat((features,labels),axis=1)\nlabeledCombs = labeledCombs.rename({0:'labels'},axis=1)","bc7b835f":"features.shape","85567bad":"labeledCombs.shape","b28d8e39":"labeledCombs.isna().sum()","a3f90745":"labeledCombs = labeledCombs[ ~(labeledCombs[\"pct_access\"].isna() & \n                               labeledCombs[\"engagement_index\"].isna()\n                              ) \n                           ]\nlabeledCombs.shape","00e4da77":"labeledCombs.head()","218a7bed":"sns.lmplot( x='pct_access'\n           ,y='engagement_index'\n           ,data=labeledCombs\n           ,hue='labels'\n           ,fit_reg=False)","2003083b":"sns.pairplot(labeledCombs, hue='labels')","e062a2c9":"labeledCombs['Constant'] = \"Data\" #This is just to add something constant for the strip\/swarm plots' X axis. Can be anything you want it to be.","d362b941":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\nfig.suptitle(\"pct_access and engagement_index distribution\")\n\nsns.stripplot( x=labeledCombs['Constant']\n              ,y=labeledCombs['pct_access']\n              ,hue=labeledCombs['labels']\n              ,jitter=True\n              ,ax=axes[0]\n             )\n\nsns.stripplot( x=labeledCombs['Constant']\n              ,y=labeledCombs['engagement_index']\n              ,hue=labeledCombs['labels']\n              ,jitter=True\n              ,ax=axes[1]\n            )\n\nfig.tight_layout()\nfig.show()","e3722edb":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\nfig.suptitle(\"pct_access and engagement_index distribution\")\n\nsns.boxplot( x=\"labels\"\n            ,y=\"pct_access\"\n            ,data=labeledCombs\n            ,ax=axes[0]\n           )\n\nsns.boxplot( x=\"labels\"\n            ,y=\"engagement_index\"\n            ,data=labeledCombs\n            ,ax=axes[1]\n           )\n\nfig.tight_layout()\nfig.show()","604206c2":"labeledCombs.columns","41fe64e2":"freemium_inactive.columns","5a101958":"grouped_1wk = pd.concat((labeledCombs.drop([\"Constant\"], axis=1)\n                        ,freemium_inactive.drop([\"min_week\", \"weekofyear\"], axis=1))\n                        ,axis=0)\n\ngrouped_1wk.shape","5a0ab52d":"grouped_1wk.isna().sum()","3f4f669c":"labeledCombs[\"labels\"].unique()","b3082df5":"## Returning customer in Group 3 for the inactive bases.\ngrouped_1wk[\"labels\"].fillna( grouped_1wk[\"total_days_used\"].apply( lambda x: 3 if x > 1 else 0)\n                             ,inplace = True\n                            )\n\ngrouped_1wk.describe()","2452ac9c":"grouped_1wk[\"labels\"].unique()","f66debcf":"grouped_1wk[((grouped_1wk[\"labels\"].isin([0, 1, 2]) & (grouped_1wk[\"total_days_used\"] > 1)))].describe()","18fffb8f":"grouped_1wk.loc[((grouped_1wk[\"labels\"].isin([0, 1, 2]) & (grouped_1wk[\"total_days_used\"] > 1))), \"labels\"] = 4","52a727dc":"grouped_1wk.describe()","f0259024":"grouped = grouped_1wk.groupby([\"labels\"])[\"lp_id\"]\\\n                     .count()\\\n                     .reset_index(name=\"count\")\n\ngrouped[\"groups\"] = grouped[\"labels\"].map({ 0: \"Group 0 (Low Usage, Non-returning Consumers)\"\n                                          ,1: \"Group 1 (Moderate Usage, Non-returning Consumers)\"\n                                          ,2: \"Group 2 (High Usage, Non-returning Consumers)\"\n                                          ,3: \"Group 3 (Inactive yet Returning Consumers)\"\n                                          ,4: \"Group 4 (Active & Returning Consumers)\"\n                                         })\n\ngrouped","0b8276f8":"fig = px.pie(\n    grouped, \n    names='groups', \n    values='count',\n    color_discrete_sequence=px.colors.sequential.Mint,\n    title='Percentage of Groups in the Engagement Information Data', \n    width=700,\n    height=500,\n    hole=0.5\n)\nfig.show()","90d25afc":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\nfig.suptitle('Compare Groups: pct_access and engagement_index')\n\naxes[0].set_title(\"pct_access distribution\")\n\nsns.boxplot( x=\"labels\"\n           , y=\"pct_access\"\n           , data=grouped_1wk\n           , palette=\"cubehelix\"\n           , ax=axes[0]\n           )\n\naxes[0].set_xlabel(\"group\")\n# axes[0].set_xticklabels(grouped_1wk[\"labels\"].unique(), rotation=70)\n\naxes[1].set_title(\"engagement_index distribution\")\n\nsns.boxplot( x=\"labels\"\n           , y=\"engagement_index\"\n           , data=grouped_1wk\n           , palette=\"cubehelix\"\n           , ax=axes[1]\n           )\naxes[1].set_xlabel(\"group\")\n# axes[1].set_xticklabels(grouped_1wk[\"labels\"].unique(), rotation=70)\n\nfig.tight_layout()\nfig.show()","2716b583":"grouped_1wk.groupby([\"labels\"])[[\"pct_access\", \"engagement_index\"]].median()","9d259c09":"grouped_1wk[ grouped_1wk[\"labels\"] == 2 ].describe(percentiles=[0.25, 0.5, 0.60, 0.70, 0.80, 0.85, 0.90, 0.95])","7f8d195f":"- how many of the engagement_index satisfies the lower_bound?","a10a55ee":"## Opportunity Analysis (Freemium)\n\nThe next part of this notebook will provide a glimpse into the Freemium subscription only for brevity.\n\n- **Key Concepts.** Identify prospective consumer-bases or (lp, district) combinations by the following aspects:\n\n    - Returning consumers. Those who viewed the course for multiple days. If a user gets back to the freemium version for several days, there is a strong chance that he\/she found it useful.\n    \n    - Engaged consumers. Those with high access and engagement to the offered course. Sometimes it may happen that a user explored the freemium version in a single day for a significant amount of time (maybe on a weekend or a holiday).","9fc452ac":"- **Remark:** The offered-week shows a periodic trend for the 1-week long freemium subscription. It reached the first peak at about March for a small time span only (3 weeks) and the second peak at about September (3 weeks).","cdb7c6e6":"- **Inactive platform.** A platform is inactive if \n    \n    -  (pct_access, engagement_index) is (0.0, 0.0): No online students; hence no page load events.\n    \n    -  (pct_access, engagement_index) is (0.0, NaN): In case when the pct_access is 0.0 for no online students, the total page load events may be unknown causing the engagement_index to be NaN. Such combination may appear because of some mismanagement in data collection.\n    \n    -  (pct_access, engagement_index) is (NaN, 0.0): This combination should not occur in practice because the total page load events is a multiple of the online students available; therefore, if the latter is NaN, the former must also be NaN. Such combination may still appear because of some mismanagement in data collection.\n    \n    -  (pct_access, engagement_index) is (NaN, NaN).","7d565cc3":"442 rows fail to satisfy the upper bound of pct_access. Let's drop such entries.","3ae33a79":"- All returning consumer bases with pct_access > 0.","113b2679":"**Remarks:**\n\n- 70.4% Paid subscriptions. All of those have returning users.\n\n- 29.6% Freemium subscriptions, lasted for 1 week only. ~6.12% of the freemium consumer bases showed returning habit by coming back to the Learning Platform after the first day .","23e75f6f":"- **Which groups can be targeted for a Paid subscription ?**\n\n- Prospective target (exclusive of Low Usage): 100 - 92.4 = 7.6%\n\n    - Returning target: 3.07 (Inactive) + 3.05 (Active) = 6.12%\n\n    - Non-returning yet engaged = 1.47 (Moderate) + 0.0245 (High) = 1.4945%","89ecb34d":"- **Remark:** Sustained Learning Platforms are those which carry forward the previously seen learning platforms.\n\n    - Example: In February, 3781 Learning Platforms from January were retained. This growth continued up till September (thus, reaching the peak 6689 LPs) and then gradually followed a declining trend in the final 3 months of the year. Note that, September is the end of financial year in the U.S. \n\n    - The most common number of Sustained Learning Platforms stayed close to 5500 over the months in 2020. The number of sustained platforms remained almost stable throughout the year.\n    \n    - We haven't seen any data in December 2019, that is, the month before January 2020. Therefore, it can be regarded as N\/A. But for the sake of simplicity, we filled it with 0.","627424d0":"- **Remark:** The paid registration count remained very high at the initial 2 weeks and then gradually showed a diminishing trend with the approach of the middle of the year.","ffe0ede4":"### 3. Discontinued Learning Platforms\n\nLet's see how the number of Learning Platforms gets discontinued over various months of 2020.","0ebea949":"### 1.1 Inactive (lp, district) combinations\n\nLet's group the inactive consumer-bases based on the returning habit.","ff567eb3":"## Summary\n\nThis notebook has carried out a step-by-step analysis on the Digital Learning state in the U.S. in 2020. The main essence of our findings are summed up as follows.\n\n### Evolution with Time.\n\n- Year 2020 can be regarded a **gold rush phase** in the Digital Learning era with a proliferation of Unique Learning Platforms and their rapid coverage over the districts with time. \n\n- The continuous growth in the Unique Learning Platforms over the months indicates a great enthusiasm in the providers in making their learning materials available via online. However, the high value of the discontinued platforms at the end of the year conveys a deplorable view too and signals an increased competition. While it is fairly easy to deliver a course through the web, it is very dificult to understand the psychology of the students, and tailor the course material as well as pacing to attract and guide them through completion.\n\n### Opportunity Analysis: Freemium to Paid conversion.\n\nOur analysis has revealed 29.6% Freemium offers, lasting for one week only. Out of those, ~6.12% are (lp_id, district_id) consumer-bases with multiple day-visits. The opportunity analysis on the Freemium offers were performed based on **(1) usage pattern and (2) returning tendency of the users**. More insights are discussed below.\n\n- About 4.5% of the Freemium consumer-bases turned out to be prospective. The Sales Representatives can reach out to them for a conversion to a Paid subscription. The target consumer-bases exhibit the following traits.\n\n    - **Group with High Usage (Single visit).** This group clearly stands out with an engaged user-base (median pct_access 1.975 and enagement_index 44.95). The high engagement_index here refers to an increased amount of pageloads (or exploration); this means, they found the course relevant and interesting. Note that, although this group is very small in size (44 consumer-bases only), it could attract and retain a significant portion of the respective district's enrolled students (pct_access range [0.43, 7.5] and engagement_index range [15.39, 1451.36]).\n    \n    - **Group with Moderate Usage (Single visit).** This group comes next with a relatively less  engaged user-base (median pct_access 0.33 and enagement_index 5.79). This group is bigger in size (2639 consumer-bases), but it failed to attract a notable fraction of the respective district's online students. Nevertheless, the top 20% of this group has a pct_access range [0.44, 1.44] and an engagement_index range [14.59, 460.96].\n\n    - **Group with Active & Returning Usage (Multiple visits).** This group is the last one in the list  with engaged & returning consumers, however, median pct_access 0.02 and enagement_index 0.715 (pretty low usage). This group is the biggest active consumer groups (5493 consumer-bases), but it attracted only an infinitesimal fraction of the respective district's online students. At the outset, the very low engagement_index does not give us much hope for further expansion to a Paid version; seems the students simply visited the courses again and again but failed to keep up the pace (hence low engagement or pageloads). Despite this fact, the top 5% of this group seems promising because of the high pct_access and engagement_index values (pct_access range [0.26, 4.66] and engagement_index range [18.84, 1111.11] ).\n\n    ","e43fe387":"## Freemium vs. Paid subscriptions\n\nThis section categorizes the (lp_id, district_id) consumer bases by the duration of the offered weeks. Then it explores the trend of the subscription types in terms of the registration count, usage (in days) and responsiveness (active or inactive).","6f0b22c0":"- Still some rows available for LP_ID None (even after imputing those inactive platforms). These will be imputed after cleaning the data by checking the upper and lower bounds.","1343d329":"## Engagement data\n\nThis section performs the loading, cleaning and imputation of the engagement data. ","c3a2e614":"- **Freemium Active.** Returning habit of active consumer bases:\n\n    - 93.47% didn't return after the first day of usage.\n    \n    - 6.52% used the freemium version for multiple days, therefore there is a strong possibility that they found it useful.","3f4e2953":"### 2. Premium (or Paid) subscription\n\n- How did the registration of consumer bases evolve over time?\n\n- How did the percentiles of days used evolve for the Paid subscription?","d157d9f9":"- We have found some valid yet counter-intuitive combinations above.","562dc661":"- **Groups.** pct_access looks like the key differentiating factor. A total of 3 groups found.\n\n    - Group 0: Low pct_access. \n    \n    - Group 1: Medium pct_access. \n    \n    - Group 2: High pct_access. \n    \n- Group 0 performed very poorly with respect to the usage pattern. Therefore, some opportunity for expansion may lie in the consumer-bases belonging to Group 1 and Group 2. Later on, we'll strip out the returning users from all these groups and form a new Group for **Active & Returning** consumer-bases.","5402218c":"- **Remarks:**\n\n    - When total_span_in_weeks > 1, the consumer bases exhibit a returning habit by coming back to the learning platform after the first day.\n\n    - The number of days used follows an exponential pattern. It starts off with a minimum of 2 days, grows to a median of 12 days, crosses 100 days at about 83rd percentile and eventually touches 366 days at about 99.9th percentile. ","c44d023c":"### 2. Newly-launched Learning Platforms\n\nLet's now observe the number of new Learning Platforms appearing online over the months in 2020.","570bd632":"### Imputation\n\n- **Basic Intuition.** Note that, if the pct_access > 0.0 then the engagement_index > 0.0 too. Because we cannot expect too see a pageload when there are no online students.\n\n- **Inactive Learning Platforms.** Let's impute all those entries with 0.0\n\n- **engagement_index = NaN and pct_access != NaN.** Such entries can be filled with pct_access * 10.0, if pct_access is not NaN and greater than 0.0, as each student online is supposed to load a page at least. A more complex approach to determine this is regression.\n\n- **pct_access = NaN and engagement_index != NaN.** Such entries can be filled with engagement_index \/ 10.0, if engagement_index is not NaN and greater than 0.0. Bound the calculated value by 100.0, if exceeded.\n\n- **lp_id NaN and (pct_access, engagement_index) not NaN.** Fill with 0 (Assume, Misc. LP).","eacf442f":"- **Remark:** The district-wise coverage remained almost same over various months of the year. It started off with 216 districts in January and then continued to grow by a few districts at each month, thus ended up with 233 districts in November through December.","f05ae63d":"- **Freemium consumer-base Statistics.**\n\n    - pct_access: ranges between 0.0% and 7.5%. More than 50% of the consumer-bases appear to be inactive or non-responsive.\n    \n    - engagement_index: ranges between 0.0 and 1451.36. More than 75% of the consumer-bases show extremely low engagement (< 1.0)\n    \n- Let's split the freemium consumer bases into 2 groups:\n\n    - Inactive bases. (lp_id, district_id) with pct_access = 0.\n    \n    - Active bases. (lp_id, district_id) with pct_access > 0.","1efb3d21":"### Findings on Groups\n\n**Group performance analysis (ref. following code cell).**\n\n- Group 2 clearly stands out with an engaged user-base (median pct_access 1.975 and enagement_index 44.95). The high engagement_index here relates to an increased amount of pageloads (or exploration); this means, the group found the course relevant and interesting. Note that, although this group is very small in size (44 consumer-bases only), it could attract and retain a significant portion of the respective district's enrolled students (pct_access range [0.43, 7.5] and engagement_index range [15.39, 1451.36]).\n\n- Group 1 comes next with a relatively less engaged user-base (median pct_access 0.33 and enagement_index 5.79). This group is bigger in size (2639 consumer-bases), but it failed to attract a notable fraction of the respective district's online students. Nevertheless, the top 20% of this group has a pct_access range [0.44, 1.44] and an engagement_index range [14.59, 460.96].\n\n- Group 4 stays third in the list with engaged & returning consumers, however, median pct_access 0.02 and enagement_index 0.715 (pretty low usage). This group is the biggest of the active consumer groups (5493 consumer-bases), but it attracted only an infinitesimal fraction of the respective district's online students. At the outset, the very low engagement_index does not give us much hope for further expansion to a Paid version; seems the students simply visited the courses again and again but failed to keep up the pace (hence low engagement or pageloads). Despite this fact, the top 5% of this group seems promising because of the high pct_access and engagement_index values (pct_access range [0.26, 4.66] and engagement_index range [18.84, 1111.11] ). \n\n- Group 3 is a special one with returning consumers but zero engagement.\n\nSince we don't have much information about Group 3, we'll exclude it from our future analysis. Therefore, the prospective consumer-bases boils down to Group 1, Group 2 and Group 4 (1.4945 + 3.05 = 4.5445%).","4be64059":"### Definition\n\nLet's drill down on the definition and implication of values in the engagement data.\n\n- $$ pct\\_access = \\frac {total\\_online\\_students} {total\\_enrolled\\_students} $$\n\n- $$ engagement\\_index = \\frac {total\\_pageload\\_events} {total\\_enrolled\\_students\\_in\\_thousands} $$","10f5d924":"### 4. Sustained Platforms\n\nLet's have a look at the trend of the sustained platforms as the months roll forward.","3529ab8a":"### 1. Unique Learning Platforms\n\nNow that the engagement data has been imputed and cleaned, let's explore the evolution of the Learning Platforms over the months in 2020. Let's look through the number of cumulative Unique Learning Platforms by month.","8ecfce83":"- **Remark:** The percentiles curve shows a sharp step-wise increase at the very end; at the ~94th percentile it rose to 2 days and finally (after the 99th) it took an abrupt increase to 3 or more days.","986fbcf0":"- Lets impute these combinations (pct_access, engagement_index): (value, NaN) and (NaN, value) by inferring from the known one.","26a6ce1e":"- No platform active for this combination (pct_access == 0.0 & engagement_index == NaN)","d16d9271":"### Findings on Evolution\n\nThis section has depicted the evolutionary trend of the Digital Education in 2020. Here goes a brief summary of our findings.\n\n- Year 2020 can be regarded a **gold rush phase** in the Digital Learning era with a proliferation of Unique Learning Platforms and their rapid coverage over the districts with time. \n\n- The rapid growth of the cumulative Unique Learning Platforms over the months indicates a great enthusiasm in the providers in making their learning materials available via online. However, the high value of the discontinued platforms at the end of the year conveys a deplorable view too and signals an increased competition. While it is fairly easy to deliver a course through the web, it is very dificult to understand the psychology of the students, and tailor the course material as well as pacing to attract and guide them through completion.","a95a9e52":"## Evolution with Time\n\nThis section provides several graphs depicting the change (i.e., growth or decay) of the Learning Platforms over time. It also explores how the districtwise coverage of online education grows with time in 2020. ","10e94087":"- pct_access is defined when any of the following holds true\n\n    - both the $ total\\_online\\_students $ and $ total\\_enrolled\\_students $ are known.\n    \n    - both the $ total\\_online\\_students $ and $ total\\_enrolled\\_students $ are unknown. Mathematically this value is NaN; however, for this specific context, we can define it as 0.0. This is expected for a newly launched platform.\n    \n    - $ total\\_enrolled\\_students $ is known. The value of $ total\\_online\\_students $ can be inferred from the $ total\\_pageload\\_events $. If the latter is 0.0 or NaN, the former will assume the same value; otherwise, we can apply regression to determine this value.\n    \nSimilar notions apply for engagement_index.","702002c1":"- **Remark:** Unique Learning Platforms (ULP) are those which don't have any twin star.\n\n    - January got started with 3857 learning platforms. The number of unique platforms  gradually increased linearly till August; then entered the saturation region where the growth is extremely low or not too obvious compared to the first half of the year. \n    \n    - 8583 is the final count of Unique Learning Platforms at Dec, 2020.\n    \n    - The rapidly-growing trend of cumulative Unique Platforms signifies the enthusiasm of the providers in making their learning materials available via online. This year, therefore, can be regarded a **gold rush phase** in the evolution of the Digital Learning era.","95fdc49e":"- Lets see whether the opposite holds true. That is, pct_access satisfies its upper bound.","24e69640":"## Future Work\n\nFuture analysis can be carried out to explore the following questions.\n\n- Which Learning Platforms turned out to be most effective? \n\n- Which districts turned out to be most responsive to the Digital Education? What are the characteristics of those and what actions can be taken to take it to the next level?","31b6ae7e":"### Cleaning\n\nGet rid of all entries which fail to satify the following:\n\n- **engagement_index lower bound.** Note that, every student must load at least a page to contribute to the engagement_index. Therefore, we need to check whether the engagement_index satisfies its lower bound for a specific entry.\n\n- **pct_access upper bound.** Similar logic suggests us to verify whether pct_access satisfies its upper bound or not in a specific entry.","a92d27a6":"- Note that every student must load at least a page to contribute to the engagement_index. Therefore, we need to check whether the engagement_index given satisfies this lower bound.","70d7c553":"- In the following scatterplot, we can observe a good number of points with pct_access = 0.0 and engagement_index > 0.0. This is counterintuitive because how can a pageload event occur when there are no students online (note that auto pageload events can be scheduled too but those are not our targeted rows)? But it may also happen that the values are too infinitesimal to be captured within 2 decimal places. Therefore, we will focus on the relationships.\n\n    - (pct_access, engagement_index): (0.0, > 0.0) is a valid combination.\n    - (pct_access, engagement_index): (> 0.0, 0.0) is an invalid combination.","742d1e34":"- ~98% learning platforms offered 1-week long freemium subscriptions across all 233 districts. ","ec0b89fb":"- 1171702 rows fail to satisfy the lower bound of the engagement_index. Let's get rid of those failed ones.","e8b8bf7d":"Drop upper_bound and lower_bound columns...","d20bb08b":"**engagement_df_refined cleaning done.**","fe0f8713":"- Offline or inactive platform for this combination (pct_access, engagement_index) = (NaN, NaN). Let's impute such entries with 0.0","e5650dd9":"- **Remark:** Newly-launched Learning Platforms (NLP) are those which got a fresh start in providing the digital learning service.\n\n    - In Februrary, 1832 learning platforms got registered; this is the peak of newly-launched ones. However, no specific growth or declining tendency had been manifested later on. Other than a few bounces (~500 platforms), the newly-launched got bounded by ~250 platforms over various months of the year.","96301f25":"### 1. Freemium subscription\n\n- What percentage of Learning Platforms offered Freemium subscriptions?\n\n- Did the offered weeks of Freemium exhibit any trend?\n\n- How did the percentiles of days used evolve for the Freemium version?","0035df58":"- How many rows fail to satisfy the lower_bound of the engagement_index? We should remove those.","8638b4ad":"- **Remark:** This plot suggests us two subscription categories: Freemium and Paid. The Freemium subscription is represented by the mode of the graph: those lasting for 1-week only.","5c422776":"- **Freemium Inactive Returning habit.**\n\n    - ~94.24% didn't return after using the freemium version for 1 day.\n    \n    - ~5.76% used the freemium version for multiple days; seems they found it useful.","ae8ed6c2":"Let's see the percentage of NaN values in the data. We'll carry out the cleaning and imputation on these in the subsequent lines of code.","907a27b1":"### 1. Freemium: Clustering by Usage Pattern","e48878cd":"## Overview \n\nThis notebook provides a high-level view of the digital learning state in 2020. Specifically, the following areas are being explored:\n\n- **Evolutionary Trend.** \n\n  The evolution of various types of Learning Platforms (e.g., newly-launched, discontinued etc.) and their coverage over the districts with time.\n  \n- **Opportunity Analysis.** \n\n  After delving into the data, the Learning Platforms are classified into Freemium and Paid types. Later on, the Freemium subscription is categorized into several groups and their opportunities for expansion are unveiled.","1a278fbb":"Let's get ready for the next part of our analysis.","b53fdaab":"### Helpful Links\n\n- charting: https:\/\/www.kaggle.com\/niteshyadav3103\/eda-e-commerce-shipping-data\n- multiplot: https:\/\/dev.to\/thalesbruno\/subplotting-with-matplotlib-and-seaborn-5ei8\n- parsing: https:\/\/www.kaggle.com\/girishkumarsahu\/learnplatform-covid-19-impact\n- Percentiles plot: https:\/\/stackoverflow.com\/questions\/47503718\/plot-percentiles-using-matplotlib\n- closest value: https:\/\/stackoverflow.com\/questions\/30112202\/how-do-i-find-the-closest-values-in-a-pandas-series-to-an-input-number\n- fillna with groupby: https:\/\/stackoverflow.com\/questions\/46391128\/pandas-fillna-using-groupby\n- most frequent value: https:\/\/stackoverflow.com\/questions\/15138973\/how-to-get-the-number-of-the-most-frequent-value-in-a-column\n- ref previous row: https:\/\/stackoverflow.com\/questions\/23333786\/reference-values-in-the-previous-row-with-map-or-apply\n- kmeans random state: https:\/\/stats.stackexchange.com\/questions\/224759\/how-to-avoid-k-means-assigning-different-labels-on-different-run\n- dataframe from dict: https:\/\/stackoverflow.com\/questions\/18837262\/convert-python-dict-into-a-dataframe\n- others: https:\/\/online.stat.psu.edu\/stat200\/lesson\/6\/6.4","3326d1af":"### 1.2 Active (lp, district) combinations\n\n- ~46.79% of the Freemium consumer-bases showed an active usage habit.\n\n- Let's group those first based on the usage pattern, i.e., pct_access and engagement_index.","83accb6b":"- **Remark.** ~53.2% Freemium consumer-bases appeared to be inactive or non-responsive.","d78473a7":"- Let's impute those undefined or NaN learning platforms.","34b11957":"### 5. District Coverage\n\nLet's explore the districtwise coverage of Digital Learning in 2020.","f5a2d4e9":"- Let's see the unique values retained before and after the imputation and cleaning.","9ae86f68":"Label the sequence of days and explore the skew of pct_access and engagement_index.","227403ac":"- **Remark:** Discontinued Learning Platforms are those which stopped providing their service any further.\n\n    - In February, 76 learning platforms from January stopped providing their service. The increasing trend in the discontinuation goes on till the end of year. Note that the number of discontinued platforms tends to get very high after September (the end of financial year); approximately 2X - 2.5X jump in October through December. The maximum number of Discontinued Platforms is observed in December with a value of 2982.","166fdb89":"- Invalid combinations are not found (see the above line of code)."}}