{"cell_type":{"f7f82563":"code","24caaa3e":"code","db9664a2":"code","7bfee870":"code","829dfbdd":"code","6389f243":"code","62989b5c":"code","e4e20cef":"code","e7e1fb95":"code","54fba7e6":"code","5a265bac":"code","6a49aa51":"code","f0c7b9b3":"markdown","b0b99c9a":"markdown","4fc43e33":"markdown","97ecc9c1":"markdown","58dc0b03":"markdown","1701cbe4":"markdown","0c071e52":"markdown","b285145c":"markdown"},"source":{"f7f82563":"import os\nimport matplotlib.pyplot as plt\nimport glob\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.metrics import cohen_kappa_score,f1_score\nfrom sklearn.model_selection import KFold, train_test_split\nfrom keras.callbacks import Callback\ndevice = torch.device(\"cuda\")","24caaa3e":"df_train = pd.read_csv(\"..\/input\/liverpool-ion-switching\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/liverpool-ion-switching\/test.csv\")\n\n# I don't use \"time\" feature\ntrain_input = df_train[\"signal\"].values.reshape(-1,4000,1)#number_of_data:1250 x time_step:4000\ntrain_input_mean = train_input.mean()\ntrain_input_sigma = train_input.std()\ntrain_input = (train_input-train_input_mean)\/train_input_sigma\ntest_input = df_test[\"signal\"].values.reshape(-1,10000,1)\ntest_input = (test_input-train_input_mean)\/train_input_sigma\n\ntrain_target = pd.get_dummies(df_train[\"open_channels\"]).values.reshape(-1,4000,11)#classification\n\nidx = np.arange(train_input.shape[0])\ntrain_idx, val_idx = train_test_split(idx, random_state = 111,test_size = 0.2)\n\nval_input = train_input[val_idx]\ntrain_input = train_input[train_idx] \nval_target = train_target[val_idx]\ntrain_target = train_target[train_idx] \n\nprint(\"train_input:{}, val_input:{}, train_target:{}, val_target:{}\".format(train_input.shape, val_input.shape, train_target.shape, val_target.shape))","db9664a2":"class conbr_block(nn.Module):\n    def __init__(self, in_layer, out_layer, kernel_size, stride, dilation):\n        super(conbr_block, self).__init__()\n\n        self.conv1 = nn.Conv1d(in_layer, out_layer, kernel_size=kernel_size, stride=stride, dilation = dilation, padding = 3, bias=True)\n        self.bn = nn.BatchNorm1d(out_layer)\n        self.relu = nn.ReLU()\n    \n    def forward(self,x):\n        x = self.conv1(x)\n        x = self.bn(x)\n        out = self.relu(x)\n        \n        return out       \n\nclass se_block(nn.Module):\n    def __init__(self,in_layer, out_layer):\n        super(se_block, self).__init__()\n        \n        self.conv1 = nn.Conv1d(in_layer, out_layer\/\/8, kernel_size=1, padding=0)\n        self.conv2 = nn.Conv1d(out_layer\/\/8, in_layer, kernel_size=1, padding=0)\n        self.fc = nn.Linear(1,out_layer\/\/8)\n        self.fc2 = nn.Linear(out_layer\/\/8,out_layer)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self,x):\n\n        x_se = nn.functional.adaptive_avg_pool1d(x,1)\n        x_se = self.conv1(x_se)\n        x_se = self.relu(x_se)\n        x_se = self.conv2(x_se)\n        x_se = self.sigmoid(x_se)\n        \n        x_out = torch.add(x, x_se)\n        return x_out\n\nclass re_block(nn.Module):\n    def __init__(self, in_layer, out_layer, kernel_size, dilation):\n        super(re_block, self).__init__()\n        \n        self.cbr1 = conbr_block(in_layer,out_layer, kernel_size, 1, dilation)\n        self.cbr2 = conbr_block(out_layer,out_layer, kernel_size, 1, dilation)\n        self.seblock = se_block(out_layer, out_layer)\n    \n    def forward(self,x):\n\n        x_re = self.cbr1(x)\n        x_re = self.cbr2(x_re)\n        x_re = self.seblock(x_re)\n        x_out = torch.add(x, x_re)\n        return x_out          \n\nclass UNET_1D(nn.Module):\n    def __init__(self ,input_dim,layer_n,kernel_size,depth):\n        super(UNET_1D, self).__init__()\n        self.input_dim = input_dim\n        self.layer_n = layer_n\n        self.kernel_size = kernel_size\n        self.depth = depth\n        \n        self.AvgPool1D1 = nn.AvgPool1d(input_dim, stride=5)\n        self.AvgPool1D2 = nn.AvgPool1d(input_dim, stride=25)\n        self.AvgPool1D3 = nn.AvgPool1d(input_dim, stride=125)\n        \n        self.layer1 = self.down_layer(self.input_dim, self.layer_n, self.kernel_size,1, 2)\n        self.layer2 = self.down_layer(self.layer_n, int(self.layer_n*2), self.kernel_size,5, 2)\n        self.layer3 = self.down_layer(int(self.layer_n*2)+int(self.input_dim), int(self.layer_n*3), self.kernel_size,5, 2)\n        self.layer4 = self.down_layer(int(self.layer_n*3)+int(self.input_dim), int(self.layer_n*4), self.kernel_size,5, 2)\n        self.layer5 = self.down_layer(int(self.layer_n*4)+int(self.input_dim), int(self.layer_n*5), self.kernel_size,4, 2)\n\n        self.cbr_up1 = conbr_block(int(self.layer_n*7), int(self.layer_n*3), self.kernel_size, 1, 1)\n        self.cbr_up2 = conbr_block(int(self.layer_n*5), int(self.layer_n*2), self.kernel_size, 1, 1)\n        self.cbr_up3 = conbr_block(int(self.layer_n*3), self.layer_n, self.kernel_size, 1, 1)\n        self.upsample = nn.Upsample(scale_factor=5, mode='nearest')\n        self.upsample1 = nn.Upsample(scale_factor=5, mode='nearest')\n        \n        self.outcov = nn.Conv1d(self.layer_n, 11, kernel_size=self.kernel_size, stride=1,padding = 3)\n    \n        \n    def down_layer(self, input_layer, out_layer, kernel, stride, depth):\n        block = []\n        block.append(conbr_block(input_layer, out_layer, kernel, stride, 1))\n        for i in range(depth):\n            block.append(re_block(out_layer,out_layer,kernel,1))\n        return nn.Sequential(*block)\n            \n    def forward(self, x):\n        \n        pool_x1 = self.AvgPool1D1(x)\n        pool_x2 = self.AvgPool1D2(x)\n        pool_x3 = self.AvgPool1D3(x)\n        \n        #############Encoder#####################\n        \n        out_0 = self.layer1(x)\n        out_1 = self.layer2(out_0)\n        \n        x = torch.cat([out_1,pool_x1],1)\n        out_2 = self.layer3(x)\n        \n        x = torch.cat([out_2,pool_x2],1)\n        x = self.layer4(x)\n        \n        #############Decoder####################\n        \n        up = self.upsample1(x)\n        up = torch.cat([up,out_2],1)\n        up = self.cbr_up1(up)\n        \n        up = self.upsample(up)\n        up = torch.cat([up,out_1],1)\n        up = self.cbr_up2(up)\n        \n        up = self.upsample(up)\n        up = torch.cat([up,out_0],1)\n        up = self.cbr_up3(up)\n        \n        out = self.outcov(up)\n        \n        #out = nn.functional.softmax(out,dim=2)\n        \n        return out","7bfee870":"class ION_Dataset(Dataset):\n    def __init__(self, train_input, train_output,mode='train'):\n        self.train_input = train_input\n        self.train_output = train_output\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.train_input)\n    \n    def _augmentations(self,input_data, target_data):\n        #flip\n        if np.random.rand()<0.5:    \n            input_data = input_data[::-1]\n            target_data = target_data[::-1]\n        return input_data, target_data\n    \n    def __getitem__(self, idx):\n        x = self.train_input[idx]\n        y = self.train_output[idx]\n        if self.mode =='train':\n            x,y = self._augmentations(x,y)\n        out_x = torch.tensor(np.transpose(x.copy(),(1,0)), dtype=torch.float)\n        out_y = torch.tensor(np.transpose(y.copy(),(1,0)), dtype=torch.float)\n        return out_x, out_y","829dfbdd":"batch_size = 8\ntrain = ION_Dataset(train_input, train_target,mode='train')\nvalid = ION_Dataset(val_input, val_target,mode='valid')\n\nx_test = torch.tensor(np.transpose(test_input,(0,2,1)), dtype=torch.float).cuda()\ntest = torch.utils.data.TensorDataset(x_test)\n\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)","6389f243":"x_train, y = next(iter(train_loader))\nx_train.shape, y.shape","62989b5c":"from torch.optim.optimizer import Optimizer\nfrom torch.optim.lr_scheduler import CosineAnnealingLR,StepLR,ReduceLROnPlateau\nimport time\nfrom tqdm import tqdm\n## Hyperparameter\nn_epochs = 100\nlr = 0.001\n\n## Build tensor data for torch\ntrain_preds = np.zeros((int(train_input.shape[0]*train_input.shape[1])))\nval_preds = np.zeros((int(val_input.shape[0]*val_input.shape[1])))\n\ntrain_targets = np.zeros((int(train_input.shape[0]*train_input.shape[1])))\n\navg_losses_f = []\navg_val_losses_f = []\n\n##Loss function\nloss_fn = torch.nn.BCEWithLogitsLoss()\n\n#Build model, initial weight and optimizer\nmodel = UNET_1D(1,128,7,3) #(input_dim, hidden_layer, kernel_size, depth)\nmodel = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr = lr,weight_decay=1e-5) # Using Adam optimizer\nscheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.8, min_lr=1e-8) # Using ReduceLROnPlateau schedule\ntemp_val_loss = 9999999999\n\n\nfor epoch in range(n_epochs):\n    \n    start_time = time.time()\n    model.train()\n    avg_loss = 0.\n    for i, (x_batch, y_batch) in enumerate(train_loader):\n        y_pred = model(x_batch.cuda())\n        \n        loss = loss_fn(y_pred.cpu(), y_batch)\n        \n        optimizer.zero_grad()\n        loss.backward()\n\n        optimizer.step()\n        avg_loss += loss.item()\/len(train_loader)\n\n        pred = F.softmax(y_pred, 1).detach().cpu().numpy().argmax(axis=1)\n        train_preds[i * batch_size*train_input.shape[1]:(i+1) * batch_size*train_input.shape[1]] = pred.reshape((-1))\n        train_targets[i * batch_size*train_input.shape[1]:(i+1) * batch_size*train_input.shape[1]] = y_batch.detach().cpu().argmax(axis=1).reshape((-1))\n        del y_pred, loss, x_batch, y_batch, pred\n        \n        \n    model.eval()\n\n    avg_val_loss = 0.\n    for i, (x_batch, y_batch) in enumerate(valid_loader):\n        y_pred = model(x_batch.cuda()).detach()\n\n        avg_val_loss += loss_fn(y_pred.cpu(), y_batch).item() \/ len(valid_loader)\n        pred = F.softmax(y_pred, 1).detach().cpu().numpy().argmax(axis=1)\n        val_preds[i * batch_size*val_input.shape[1]:(i+1) * batch_size*val_input.shape[1]] = pred.reshape((-1))\n        del y_pred, x_batch, y_batch, pred\n        \n    if avg_val_loss<temp_val_loss:\n        #print ('checkpoint_save')\n        temp_val_loss = avg_val_loss\n        torch.save(model.state_dict(), 'ION_train_checkpoint.pt')\n        \n    train_score = f1_score(train_targets,train_preds,average = 'macro')\n    val_score = f1_score(val_target.argmax(axis=2).reshape((-1)),val_preds,average = 'macro')\n    \n    elapsed_time = time.time() - start_time \n    scheduler.step(avg_val_loss)\n    \n    print('Epoch {}\/{} \\t loss={:.4f} \\t train_f1={:.4f} \\t val_loss={:.4f} \\t val_f1={:.4f} \\t time={:.2f}s'.format(\n        epoch + 1, n_epochs, avg_loss,train_score, avg_val_loss,val_score, elapsed_time))\n","e4e20cef":"print(\"VALIDATION_SCORE (QWK): \", cohen_kappa_score(val_target.argmax(axis=2).reshape((-1)),val_preds, weights=\"quadratic\"))","e7e1fb95":"print(\"VALIDATION_SCORE (F1): \", f1_score(val_target.argmax(axis=2).reshape((-1)),val_preds ,average = 'macro'))","54fba7e6":"model.load_state_dict(torch.load('ION_train_checkpoint.pt'))\nmodel.eval()\ntest_preds = np.zeros((int(test_input.shape[0]*test_input.shape[1])))\nfor i, x_batch in enumerate(test_loader):\n    y_pred = model(x_batch[0]).detach()\n\n    pred = F.softmax(y_pred, 1).detach().cpu().numpy().argmax(axis=1)\n    test_preds[i * batch_size*test_input.shape[1]:(i+1) * batch_size*test_input.shape[1]] = pred.reshape((-1))\n    del y_pred, x_batch, pred\n","5a265bac":"df_sub = pd.read_csv(\"..\/input\/liverpool-ion-switching\/sample_submission.csv\", dtype={'time':str})\ndf_sub.open_channels = np.array(test_preds,np.int)\ndf_sub.to_csv(\"submission.csv\",index=False)","6a49aa51":"df_sub.head()","f0c7b9b3":"## Define Dataset with augmentation","b0b99c9a":"## Import Library","4fc43e33":"## Next plan\n* K-fold split training\n* Change loss function\n* Try RNN or LSTM model","97ecc9c1":"## Training","58dc0b03":"## Introduction\n* Ref Kernel https:\/\/www.kaggle.com\/kmat2019\/u-net-1d-cnn-with-keras, many thanks @K_mat shared 1DCNN keras version\n* Write the simple pytorch version for U-Net (1D CNN)","1701cbe4":"## Load and Split Dataset\nSimply split the input data into certain length.","0c071e52":"## Predict and Submit\nThis is not the main topic of this kernel, so I just round predicted values.","b285145c":"## Define Model\nThis section defines U-Net(se-resnet base).\nInput and output of the U-Net are follows:\n* Input: 4000 time steps of \"signal\"\n* Output: (4000,11) time steps of \"open_channels\""}}