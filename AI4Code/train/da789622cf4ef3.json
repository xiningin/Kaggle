{"cell_type":{"efb9d3da":"code","538a55ac":"code","15717924":"code","ba053a10":"code","fb4c3efb":"code","9a0b0e6c":"code","7650169b":"code","0617ee1d":"code","500e239e":"code","0294f3c8":"code","ac7c8ca7":"code","26942850":"code","f41a8d68":"code","f10bb2e9":"code","fdac81ce":"code","ed83de82":"code","8d2c9887":"code","212d664a":"code","55b9dceb":"code","25d1a140":"code","cc2595a0":"code","d2016b4b":"code","0839da95":"code","063f3f69":"code","9ad16b8e":"code","88516066":"code","1d5296d3":"code","9934c745":"code","860eee2d":"code","e31d4731":"code","0c3b3136":"code","ba7fcb1f":"markdown","0cafffbb":"markdown","47ab58b6":"markdown","736efbb1":"markdown","1348d9f8":"markdown","542a8387":"markdown","59593051":"markdown","3475ee61":"markdown","ad4499f0":"markdown","a1cea883":"markdown","ff4737fa":"markdown","fe4b3a64":"markdown","7555bb85":"markdown","b1da9158":"markdown","74ca4df2":"markdown","c4a6e806":"markdown","f28129ac":"markdown","58766903":"markdown","dc872a41":"markdown"},"source":{"efb9d3da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom PIL import Image\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom scipy.special import boxcox\nimport os\nfrom os import path\nprint(os.listdir(\"..\/input\"))\n\n%matplotlib inline\nimport plotly\nimport plotly.plotly as py\nimport plotly.offline as offline\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nfrom plotly.graph_objs import Scatter, Figure, Layout\nfrom plotly import tools\n# Any results you write to the current directory are saved as output.","538a55ac":"df = pd.read_csv(\"..\/input\/olist_classified_public_dataset.csv\")\ndf2 = pd.read_csv(\"..\/input\/geolocation_olist_public_dataset.csv\")","15717924":"df.head(10)","ba053a10":"translate_df = pd.read_csv(\"..\/input\/product_category_name_translation.csv\")\ntranslate_df.head()","fb4c3efb":"### all of product categories names are translated into english\nfor i in range(0,len(translate_df)):\n    df.product_category_name[df.product_category_name==translate_df.iloc[i,0]] = translate_df.iloc[i,1]","9a0b0e6c":"plt.figure(figsize=(50,60))\nsns.countplot(y=df.product_category_name,orient=\"v\")\nplt.yticks(fontsize=35)\nplt.xticks(fontsize=30)\nplt.ylabel(\"Product Category Name\", fontsize=40)\nplt.xlabel(\"Product Count\",fontsize=40)\nplt.title(\"Product Category Count\",fontsize=80)\nplt.show()","7650169b":"soup = ' '.join(df.product_category_name)\n#wordcloud = WordCloud().generate()\n\nwordcloud = WordCloud(width=5000, height=2500,max_words=300)\nwordcloud.generate(soup)\nplt.figure(figsize=(20,10),facecolor='k')\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","0617ee1d":"soup = ' '.join(df.review_comment_message)\n#wordcloud = WordCloud().generate()\n\nwordcloud = WordCloud(width=5000, height=2500,max_words=300)\nwordcloud.generate(soup)\nplt.figure(figsize=(20,10),facecolor='k')\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","500e239e":"df.head()","0294f3c8":"### convert data types of date columns into pd.datetime\ntime_columns = ['order_purchase_timestamp','order_aproved_at','order_estimated_delivery_date','order_delivered_customer_date']\nfor x in time_columns:\n    df[x] = pd.to_datetime(df[x])","ac7c8ca7":"### calculate time delay between approving purchase\n### calculate time gap between estimated delivery date and actual ordered date\n\ndf['approved_delay'] = df['order_aproved_at']-df['order_purchase_timestamp']\ndf['delivery_gap_btw_est_act'] = df['order_delivered_customer_date']-df['order_estimated_delivery_date']","26942850":"### convert time delay between approving purchase into minutes data\n\napproved_time = pd.DatetimeIndex(df['approved_delay'])\napproved_minutes = approved_time.hour*60 + approved_time.minute","f41a8d68":"### Approved minutes into histogram\n\nplt.figure(figsize=(15,8))\nax = plt.subplot(1,1,1)\nsns.distplot(list(approved_minutes),bins=50,color='c')\nax.set_xticks(range(0,1800,60))\nplt.title(\"Approval Time Delay Histogram\",fontsize=20)\nplt.xlabel(\"Approval Delay in minutes\", fontsize=10)\nplt.show()","f10bb2e9":"### convert time delay between approving purchase into minutes data\nDeliver_gap = pd.DatetimeIndex(df['delivery_gap_btw_est_act'])\nDeliver_gap = Deliver_gap.day-1\nCleanedList = [x for x in Deliver_gap if str(x) != 'nan']","fdac81ce":"### Approved minutes into histogram\n\nplt.figure(figsize=(15,8))\nax = plt.subplot(1,1,1)\nsns.distplot(CleanedList,bins=50,color='orange')\n#ax.set_xticks(range(0,1800,60))\nplt.title(\"Time gap between Estimated Delivery Date and Actual Date\"+\"\\n (Days Faster than estimated)\",fontsize=20)\nplt.xlabel(\"Dates\", fontsize=12)\nplt.show()","ed83de82":"df2 = pd.read_csv(\"..\/input\/geolocation_olist_public_dataset.csv\").sample(n=50000)\n\nmapbox_access_token = 'pk.eyJ1IjoibGVlZG9oeXVuIiwiYSI6ImNqbjl1Y2hmcTB6dTQzcnBiNDZ2cXcwbGEifQ.hcPVtUhnyzXDXZbQQH0nMw'\ndata = [go.Scattermapbox(\n    lon = df2['lng'],\n    lat = df2['lat'],\n    marker = dict(\n        size = 3,\n        \n    ))]\n\nlayout = dict(\n        title = 'Geo Locations based on Zip code',\n        mapbox = dict(\n            accesstoken = mapbox_access_token,\n            center= dict(lat=-20,lon=-60),\n            bearing=5,\n            pitch=5,\n            zoom=2.3,\n        )\n    )\nfig = dict( data=data, layout=layout )\niplot( fig, validate=False)","8d2c9887":"### longitude and latitude are recored into new columns in df\n\ndf['customer_latitude'] = pd.Series([df2.loc[df2.zip_code_prefix==df.customer_zip_code_prefix[x],:].lat.mean() for x in range(0,len(df)-1)])\ndf['customer_longitude'] = pd.Series([df2.loc[df2.zip_code_prefix==df.customer_zip_code_prefix[x],:].lng.mean() for x in range(0,len(df)-1)])","212d664a":"\nmapbox_access_token = 'pk.eyJ1IjoibGVlZG9oeXVuIiwiYSI6ImNqbjl1Y2hmcTB6dTQzcnBiNDZ2cXcwbGEifQ.hcPVtUhnyzXDXZbQQH0nMw'\ndata = [go.Scattermapbox(\n    lon = df['customer_longitude'],\n    lat = df['customer_latitude'],\n    marker = dict(\n        size = 5,\n        color = 'red'\n    ))]\n\nlayout = dict(\n        title = 'Customer Locations',\n        mapbox = dict(\n            accesstoken = mapbox_access_token,\n            center= dict(lat=-20,lon=-60),\n            bearing=5,\n            pitch=5,\n            zoom=2.3,\n        )\n    )\nfig = dict( data=data, layout=layout )\niplot( fig, validate=False)","55b9dceb":"plt.figure(figsize=(10,10))\ncorr = df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","25d1a140":"heavy_freights = df[df.order_freight_value > df.order_freight_value.quantile(q=0.9)]","cc2595a0":"\nmapbox_access_token = 'pk.eyJ1IjoibGVlZG9oeXVuIiwiYSI6ImNqbjl1Y2hmcTB6dTQzcnBiNDZ2cXcwbGEifQ.hcPVtUhnyzXDXZbQQH0nMw'\ndata = [go.Scattermapbox(\n    lon = heavy_freights['customer_longitude'],\n    lat = heavy_freights['customer_latitude'],\n    marker = dict(\n        size = heavy_freights['order_items_qty']*3,\n        color = 'blue'\n    ))]\n\nlayout = dict(\n        title = 'High Freight order Customer Locations',\n        mapbox = dict(\n            accesstoken = mapbox_access_token,\n            center= dict(lat=-20,lon=-60),\n            bearing=5,\n            pitch=5,\n            zoom=2.3,\n        )\n    )\nfig = dict( data=data, layout=layout )\niplot( fig, validate=False)","d2016b4b":"### import olist public dataset which is including the data for customer_id\n\ndf3 = pd.read_csv(\"..\/input\/olist_public_dataset_v2.csv\")","0839da95":"df3.head()","063f3f69":"### making DataFrame based on df3.customer_id.value_counts()\n### first, making index list\n### second, making counts value list\n### zipping into dictionary and make new df 'purchase_df'\n\nvalue = df3.customer_id.value_counts().index.tolist()\ncounts= df3.customer_id.value_counts().tolist()\npurchase_df = pd.DataFrame({'customer_id':value,'purchase_counts':counts})","9ad16b8e":"### purchase counts number df is concated into df3 as new column\n### pd.merge is very effective\n\ndf3 = pd.merge(df3,purchase_df)\ndf3.head()","88516066":"def normalize(x):\n    return(x-x.mean())\/(x.max()-x.min())","1d5296d3":"df3['normalized_opv']=normalize(df3.order_products_value)\ndf3['normalized_ofv']=normalize(df3.order_freight_value)","9934c745":"from sklearn.cluster import KMeans","860eee2d":"feature = df3[['normalized_opv','normalized_ofv']]\nmodel = KMeans(n_clusters=3,algorithm='auto')\nmodel.fit(feature)\npredict = pd.DataFrame(model.predict(feature))\npredict.columns=['predict']\nr = pd.concat([feature,predict],axis=1)","e31d4731":"ks = range(1,10)\ninertias = []\n\n\nfor k in ks:\n    model = KMeans(n_clusters=k)\n    model.fit(feature)\n    inertias.append(model.inertia_)\n    \n# Plot ks vs inertias\nplt.plot(ks, inertias, '-o')\nplt.xlabel('number of clusters, k')\nplt.ylabel('inertia')\nplt.title(\"Intertias Tilting Graph\")\nplt.xticks(ks)\nplt.show()","0c3b3136":"model = KMeans(n_clusters=3,algorithm='auto')\nmodel.fit(feature)\npredict = pd.DataFrame(model.predict(feature))\npredict.columns=['predict']\n\nplt.figure(figsize=(8,7))\nplt.scatter(r['normalized_opv'],r['normalized_ofv'],c=r['predict'],alpha=0.5)\nplt.xlim(xmax=0.4)\nplt.ylim(ymax=0.4)\nplt.xlabel(\"Order Product Values\",fontsize=15)\nplt.ylabel(\"Order Freight Values\",fontsize=15)\nplt.title(\"Clustering from Product Value & Freight Value\",fontsize=20)\ncenters = pd.DataFrame(model.cluster_centers_,columns=['normalized_opv','normalized_ofv'])\ncenter_x = centers['normalized_opv']\ncenter_y = centers['normalized_ofv']\nplt.scatter(center_x,center_y,s=50,marker='D',c='r')\nplt.show()","ba7fcb1f":"# KMeans Clustering ","0cafffbb":"### Actual delivery occurs on average 15 days earlier than the estimated delivery date\n#### This result implies that Company's estimation for delivery date is too loose that their estimation is needed to be improved","47ab58b6":"# Product Category WordCloud","736efbb1":"# Olist Data Analysis : Geospatial and Correlations\n### Olist E-commerce Data is used to trace customer location based on zip code using latitude and longitude\n#### (1) [What kinds of products are sold frequently? and which words are appeared mainly in review comments](#1)\n#### (2) [Showing Delivery Dates Time Histogram: Estimated Dates vs Actual Dates](#2)\n#### (3) [Geospatial scatterplot using latitudes and longitudes data, linking Zip code for customers](#3)\n#### (4) [Interesting Correlation between features & Freight payments by locations](#4)\n#### (5) [Clustering can seperate customers?](#5)\n#### (6) [ To be improved ](#6)","1348d9f8":"# <a id='4'><\/a><br> Let's look at Intersting Correlations\n### (1) Votes_parital_delivery & order_sellers_qty are stronly correlated : Obvious\n### (2) Votes_satisfied & review_score are stronly correlated : Obvious \n### (3) Votes_before_estimate & review_score stronly correlated : Obvious\n### (4) product_description_length & order_products_value : Interesting ..Right?\n### (5) Customer Latitude and Longitude(Location of Customer) is correlated with order_freight_value ","542a8387":"# In every case of delivery, actual delivery dates never exceed the estimated Delivery Dates","59593051":"# Convert 4 columns into pd.Datetime data types","3475ee61":"# Normalize is needed before conducting Clustering","ad4499f0":"# WordCloud using Review Comment data & Products Categories","a1cea883":"# <a id='6'><\/a><br> To be improved...\n#### only a few customers are recorded as using this e-commerce platform more than once.\n#### in order to get insight or motivate more customers use this platform, further data will be helpful","ff4737fa":"# Let's look at who is paying for higher freight payment\n## This is related to the number of order items quantity and addresses","fe4b3a64":"# <a id='5'><\/a><br> Data merge from value_counts()","7555bb85":"# <a id='3'><\/a><br> Showing Geo Locations based on Zip code","b1da9158":"## KMeans Clustering using only 2 dimensions\n### Clustering method is not seem to efficient","74ca4df2":"# <a id='2'><\/a><br> Showing Histogram for approval time delay data","c4a6e806":"# <a id=\"1\"><\/a><br> Product Category Count Plot","f28129ac":"# Estimate Customer address' Longitude and Latitude based on their zip code","58766903":"# In above graph, size of circle means the number of orders.\n### Therefore, we need to focus on the smaller circles' location, these locations are needed to pay further fees.","dc872a41":"## Checking optimal number of Clusters"}}