{"cell_type":{"ec36fa9d":"code","03a1e7b7":"code","daa72f97":"code","40496af6":"code","d9aee57b":"code","2eff1deb":"code","a4dccb1b":"code","2ad9310c":"code","2d634f69":"code","b5e4817c":"code","054386d3":"code","f8ea6b3a":"code","af3c8063":"code","3cee8f07":"code","2d69e42b":"code","8dcae123":"code","c0cdba0d":"code","3f579198":"code","04a63241":"code","05919053":"code","06151bbf":"code","8a4b2154":"code","c4729b3b":"code","36aae0ca":"code","f351a4fb":"code","e7247135":"code","8782eb2b":"code","44bd1e68":"code","c001a4d9":"code","e064bf64":"code","d6ca48cb":"code","c20a0735":"code","69a28a56":"markdown","b14ccd9b":"markdown"},"source":{"ec36fa9d":"pip install google.colab","03a1e7b7":"import cv2\nimport numpy as np\nimport time\nimport os\nimport matplotlib.pyplot as plt\nfrom google.colab.patches import cv2_imshow\n","daa72f97":"path = '..\/input\/modelo-yolo\/cfg\/yolov4.cfg' ","40496af6":"labels_path = os.path.sep.join(['..\/input\/modelo-yolo\/cfg', 'coco.names'])   \nlabels_path","d9aee57b":"LABELS = open(labels_path).read().strip().split('\\n')\nprint(LABELS)","2eff1deb":"len(LABELS)","a4dccb1b":"weights_path = os.path.sep.join(['..\/input\/modelo-yolo', 'yolov4.weights'])\nconfig_path = os.path.sep.join(['..\/input\/modelo-yolo\/cfg', 'yolov4.cfg'])\nweights_path, config_path","2ad9310c":"net = cv2.dnn.readNet(config_path, weights_path)","2d634f69":"net","b5e4817c":"np.random.seed(42)\nCOLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype='uint8')","054386d3":"ln = net.getLayerNames()\nprint(\"Todas as camadas (layers):\")\nprint(ln)\nprint(\"Total: \"+ str(len(ln)))\nprint(\"Camadas de sa\u00edda: \")\nprint(net.getUnconnectedOutLayers())\nln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\nprint(ln)","f8ea6b3a":"def mostrar(img):\n  fig = plt.gcf()\n  fig.set_size_inches(16, 10)\n  plt.axis(\"off\")\n  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n  plt.show()","af3c8063":"imagem = cv2.imread(\"..\/input\/yolo-opencv-images\/pictures\/2014_697258392-2014031382906.jpg_20140410.jpg\") \nmostrar(imagem)\nimagem_cp = imagem.copy() \n(H, W) = imagem.shape[:2] \nprint(\"Altura: \" + str(H) + \"\\nLargura: \" + str(W))","3cee8f07":"proporcao = imagem.shape[1] \/ imagem.shape[0]\nproporcao","2d69e42b":"def redimensionar(imagem, largura_maxima = 600):\n  if imagem.shape[1] > largura_maxima:\n    proporcao = imagem.shape[1] \/ imagem.shape[0]\n    imagem_largura = largura_maxima\n    imagem_altura = int(imagem_largura \/ proporcao)\n  else:\n    imagem_largura = imagem.shape[1]\n    imagem_altura = imagem.shape[0]\n\n  imagem = cv2.resize(imagem, (imagem_largura, imagem_altura))\n  return imagem","8dcae123":"imagem = redimensionar(imagem)","c0cdba0d":"mostrar(imagem)\n(H, W) = imagem.shape[:2]\nimagem_cp = imagem.copy()\nprint('Altura: ' + str(H) + '\\nLargura: ' + str(W))","3f579198":"def blob_imagem(net, imagem, mostrar_texto=True):\n  inicio = time.time() \n\n  blob = cv2.dnn.blobFromImage(imagem, 1 \/ 255.0, (416, 416), swapRB=True, crop=False)\n  net.setInput(blob)\n  layerOutputs = net.forward(ln)\n\n  termino = time.time()\n\n  if mostrar_texto:\n    print(\"YOLO levou {:.2f} segundos\".format(termino - inicio))\n\n  return net, imagem, layerOutputs","04a63241":"net, imagem, layerOutputs = blob_imagem(net, imagem)","05919053":"_threshold = 0.5\n_threshold_NMS = 0.3\ncaixas = []   \nconfiancas = []   \nIDclasses = []","06151bbf":"def deteccoes(detection, _threshold, caixas, confiancas, IDclasses):\n  scores = detection[5:]      \n  classeID = np.argmax(scores)\n  confianca = scores[classeID]\n\n  if confianca > _threshold:\n      caixa = detection[0:4] * np.array([W, H, W, H])\n      (centerX, centerY, width, height) = caixa.astype(\"int\")\n      x = int(centerX - (width \/ 2))\n      y = int(centerY - (height \/ 2))\n\n      caixas.append([x, y, int(width), int(height)])\n      confiancas.append(float(confianca))\n      IDclasses.append(classeID)\n      \n  return caixas, confiancas, IDclasses","8a4b2154":"for output in layerOutputs:\n    for detection in output:\n        caixas, confiancas, IDclasses = deteccoes(detection, _threshold, caixas, confiancas, IDclasses)","c4729b3b":"objs = cv2.dnn.NMSBoxes(caixas, confiancas, _threshold, _threshold_NMS)","36aae0ca":"print(\"Objetos detectados: \" + str(len(objs)))","f351a4fb":"def check_negativo(n):\n  if (n < 0):\n    return 0\n  else:\n    return n\n\ndef funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=True):\n  (x, y) = (caixas[i][0], caixas[i][1])\n  (w, h) = (caixas[i][2], caixas[i][3])\n  cor = [int(c) for c in COLORS[IDclasses[i]]]\n  cv2.rectangle(imagem, (x, y), (x + w, y + h), cor, 2) \n  texto = \"{}: {:.4f}\".format(LABELS[IDclasses[i]], confiancas[i])\n  if mostrar_texto:\n    print(\"> \" + texto)\n    print(x,y,w,h)\n  cv2.putText(imagem, texto, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, cor, 2)\n\n  return imagem,x,y,w,h","e7247135":"if len(objs) > 0:\n  for i in objs.flatten():\n    imagem, x, y, w, h = funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS)\n    objeto = imagem_cp[y:y + h, x:x + w]\n    cv2_imshow(objeto)","8782eb2b":"mostrar(imagem)","44bd1e68":"path = '..\/input\/yolo-opencv-images'","c001a4d9":"diretorio_fotos = '..\/input\/yolo-opencv-images\/pictures'\ncaminhos = [os.path.join(diretorio_fotos, f) for f in os.listdir(diretorio_fotos)]\nprint(caminhos)","e064bf64":"for caminho_imagem in caminhos:\n  try:\n    imagem = cv2.imread(caminho_imagem) \n    (H, W) = imagem.shape[:2]\n  except:\n    print('Erro ao carregar a imagem -> ' + caminho_imagem)\n    continue\n\n  imagem_cp = imagem.copy()\n  net, imagem, layer_outputs = blob_imagem(net, imagem)\n\n  caixas = []\n  confiancas = []\n  IDclasses = []\n\n  for output in layer_outputs:\n    for detection in output:\n      caixas, confiancas, IDclasses = deteccoes(detection, _threshold, caixas, confiancas, IDclasses)\n\n  objs = cv2.dnn.NMSBoxes(caixas, confiancas, _threshold, _threshold_NMS)\n\n  if len(objs) > 0:\n    for i in objs.flatten():\n      imagem, x, y, w, h = funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=False)\n      objeto = imagem_cp[y:y + h, x:x + w]\n  \n  mostrar(imagem)","d6ca48cb":"diretorio_fotos = \"..\/input\/yolo-opencv-images\/pictures\"\ncaminhos = [os.path.join(diretorio_fotos, f) for f in os.listdir(diretorio_fotos)]\nprint(caminhos)\nthreshold = 0.5\nthreshold_NMS = 0.3","c20a0735":"classes = ['dog']\nfor caminho_imagem in caminhos:\n  try:\n    imagem = cv2.imread(caminho_imagem) \n    (H, W) = imagem.shape[:2]\n  except:\n    print('Erro ao carregar a imagem -> ' + caminho_imagem)\n    continue\n\n  imagem_cp = imagem.copy()\n  net, imagem, layer_outputs = blob_imagem(net, imagem)\n\n  caixas = []\n  confiancas = []\n  IDclasses = []\n\n  for output in layer_outputs:\n    for detection in output:\n      caixas, confiancas, IDclasses = deteccoes(detection, _threshold, caixas, confiancas, IDclasses)\n\n  objs = cv2.dnn.NMSBoxes(caixas, confiancas, _threshold, _threshold_NMS)\n\n  if len(objs) > 0:\n    for i in objs.flatten():\n      if LABELS[IDclasses[i]] in classes:\n        imagem, x, y, w, h = funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=False)\n        objeto = imagem_cp[y:y + h, x:x + w]\n  \n  mostrar(imagem)","69a28a56":"# **Fazendo a detec\u00e7\u00e3o apenas de objetos espec\u00edficos do modelo**","b14ccd9b":"# **If you find this notebook useful, support with an upvote** \ud83d\udc4d"}}