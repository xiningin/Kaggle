{"cell_type":{"ef7a827b":"code","1ad98f9c":"code","1f07037a":"code","757ac65a":"code","677ccfdc":"code","9d09c6a4":"code","c8ff2f3c":"code","5e4eafc4":"code","135d818d":"code","a7d3b01b":"code","bd8ebbe2":"code","cf3a76c7":"code","307ecdd2":"code","a826bf50":"code","f1abb7df":"code","a85ebb64":"code","55d2e9ee":"code","3162fdeb":"code","4cb2ccb8":"code","9e4afd0b":"code","2db2386c":"code","394d764a":"code","8e484145":"code","4533a0d9":"code","cd389ad7":"code","9da63655":"code","949b70cb":"code","def0e6ed":"code","93c27f28":"code","ffe9b36a":"code","3ea80eb4":"code","65841a77":"code","9ea4cdcf":"code","e0bb7003":"code","de2c9066":"code","87519be6":"code","e1231e86":"code","93fd6714":"code","d52212b7":"code","ba394ab6":"code","94a4852a":"code","a153b950":"code","2664de2c":"code","7d917e53":"code","211e1149":"code","9a5df776":"code","cf538ee9":"code","cd4a4062":"code","270ce7ae":"code","5c019515":"code","e82cfd73":"code","a5ae680c":"code","a9a0d16f":"code","4d0375d0":"code","5dfb89f5":"code","dec86551":"code","fbacf356":"code","acf609c4":"code","be0174c1":"code","8d06b295":"code","5b42f3b2":"code","918da32b":"code","526b3bbe":"code","3b6d6729":"code","54ce7e58":"code","2292f11e":"code","e188e04c":"code","4afb669e":"code","0c487e5a":"code","596be000":"code","ec09d45b":"code","7ae873b6":"code","27f1e73d":"code","0f390c4c":"code","c91a13b1":"code","af461328":"code","a278e277":"code","da0e7601":"code","15049e6c":"code","f81113a3":"code","13b6cdd0":"code","5567392a":"code","4b11c966":"code","0f90bba6":"code","f5ce0af0":"code","d7eb9eea":"code","25ddc92f":"code","b8d8717c":"code","2b1e6895":"code","f53d1aa6":"code","2a4cabbf":"code","024bc91d":"code","1b011a57":"code","dc26b569":"code","33b8d2dc":"code","f64f9801":"code","2c29c357":"code","39371f07":"code","fec5bb02":"code","829c390e":"code","8b201d6d":"code","51286336":"markdown","6a022f7e":"markdown","b98ece6f":"markdown","34fd065b":"markdown","2b77f22f":"markdown"},"source":{"ef7a827b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1ad98f9c":"import gc\ngc.collect()","1f07037a":"# !pip install pretrainedmodels\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n!pip install fastai==1.0.52\nimport fastai\n\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.tabular import *\n\n# from torchvision.models import *\n# import pretrainedmodels\n\nfrom utils import *\nimport sys\n\nfrom fastai.callbacks.hooks import *\n\nfrom fastai.callbacks.tracker import EarlyStoppingCallback\nfrom fastai.callbacks.tracker import SaveModelCallback","757ac65a":"from sklearn.metrics import roc_auc_score\n\ndef auroc_score(input, target):\n    input, target = input.cpu().numpy()[:,1], target.cpu().numpy()\n    return roc_auc_score(target, input)\n\nclass AUROC(Callback):\n    _order = -20 #Needs to run before the recorder\n\n    def __init__(self, learn, **kwargs): self.learn = learn\n    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])\n    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n    \n    def on_batch_end(self, last_target, last_output, train, **kwargs):\n        if not train:\n            self.output.append(last_output)\n            self.target.append(last_target)\n                \n    def on_epoch_end(self, last_metrics, **kwargs):\n        if len(self.output) > 0:\n            output = torch.cat(self.output)\n            target = torch.cat(self.target)\n            preds = F.softmax(output, dim=1)\n            metric = auroc_score(preds, target)\n            return add_metrics(last_metrics, [metric])","677ccfdc":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","9d09c6a4":"df_train.shape, df_test.shape","c8ff2f3c":"df_train.columns","5e4eafc4":"df_test.columns","135d818d":"df_train['target'].value_counts()","a7d3b01b":"df_train.head()","bd8ebbe2":"df_train.drop(['ID_code'], axis=1, inplace=True)","cf3a76c7":"df_train.head()","307ecdd2":"df_test.drop(['ID_code'], axis=1, inplace=True)","a826bf50":"df_test.head()","f1abb7df":"df_train_new = df_train.drop(['target'], axis=1)\ncont_names = df_train_new.columns\ndep_var = 'target'\nprocs = [FillMissing, Categorify, Normalize]\ncat_names = []","a85ebb64":"data = (TabularList.from_df(df_train, procs = procs, cont_names=cont_names, cat_names=cat_names)\n        .split_by_rand_pct(0.2, seed=42)\n        .label_from_df(cols=dep_var)\n        .databunch(bs=64*4))","55d2e9ee":"# data.add_test(TabularList.from_df(df_test, cont_names=cont_names))","3162fdeb":"data.show_batch()","4cb2ccb8":"learn = tabular_learner(data, layers=[1000,500], metrics=accuracy, callback_fns=AUROC, ps=[0.001,0.01], emb_drop=0.04)","9e4afd0b":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","2db2386c":"lr = 5e-2\nlearn.fit_one_cycle(5, max_lr=lr,  pct_start=0.3, wd = 1e-2)","394d764a":"learn.fit_one_cycle(5, max_lr=lr,  pct_start=0.3, wd = 1e-2)","8e484145":"learn.recorder.plot_losses()","4533a0d9":"learn.fit_one_cycle(5, max_lr=1e-2, wd=1e-2)","cd389ad7":"learn.recorder.plot_losses()","9da63655":"learn.save('1st-round')\nlearn.load('1st-round')","949b70cb":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","def0e6ed":"interp.plot_confusion_matrix(figsize=(8,8), dpi=60)","93c27f28":"class SaveFeatures():\n    features=None\n    def __init__(self, m): \n        self.hook = m.register_forward_hook(self.hook_fn)\n        self.features = None\n    def hook_fn(self, module, input, output): \n        out = output.detach().cpu().numpy()\n        if isinstance(self.features, type(None)):\n            self.features = out\n        else:\n            self.features = np.row_stack((self.features, out))\n    def remove(self): \n        self.hook.remove()","ffe9b36a":"learn.model","3ea80eb4":"sf = SaveFeatures(learn.model.layers[4])","65841a77":"_= learn.get_preds(data.train_ds)","9ea4cdcf":"label = [data.classes[x] for x in (list(data.train_ds.y.items))]","e0bb7003":"len(label)","de2c9066":"df_new = pd.DataFrame({'label': label})","87519be6":"df_new['label'].value_counts()","e1231e86":"array = np.array(sf.features)","93fd6714":"x=array.tolist()","d52212b7":"df_new['img_repr'] = x","ba394ab6":"df_new.head()","94a4852a":"d2 = pd.DataFrame(df_new.img_repr.values.tolist(), index = df_new.index).rename(columns = lambda x: 'img_repr{}'.format(x+1))","a153b950":"df_new_2 = df_new.join(d2)","2664de2c":"df_new_2.head(10)","7d917e53":"df_new_2.shape","211e1149":"sf = SaveFeatures(learn.model.layers[4])","9a5df776":"_=learn.get_preds(DatasetType.Valid)","cf538ee9":"data.valid_ds.y.items","cd4a4062":"label = [data.classes[x] for x in (list(data.valid_ds.y.items))]\n","270ce7ae":"df_new_valid = pd.DataFrame({'label': label})","5c019515":"df_new_valid['label'].value_counts()","e82cfd73":"array = np.array(sf.features)","a5ae680c":"x=array.tolist()","a9a0d16f":"df_new_valid['img_repr'] = x","4d0375d0":"df_new_valid.head()","5dfb89f5":"d2 = pd.DataFrame(df_new_valid.img_repr.values.tolist(), index = df_new_valid.index).rename(columns = lambda x: 'img_repr{}'.format(x+1))","dec86551":"df_new_valid_2 = df_new_valid.join(d2)","fbacf356":"df_new_valid_2.head(10)","acf609c4":"df_new_valid_2.shape","be0174c1":"df_new_valid_2.drop(['img_repr'], axis=1, inplace=True)","8d06b295":"df_new_valid_2.head()","5b42f3b2":"df_new_2.drop(['img_repr'], axis=1, inplace=True)","918da32b":"df_new_2.shape","526b3bbe":"df_new_2.describe()","3b6d6729":"corr_matrix = df_new_2.corr()\n\ncorr_matrix[\"label\"].sort_values(ascending = False)","54ce7e58":"X = df_new_2\ny = df_new_2.label.copy()\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state=42)","2292f11e":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","e188e04c":"X_train = X_train.drop(\"label\", axis =1)\ny_train = y_train\n\nX_test = X_test.drop(\"label\", axis =1)\ny_test = y_test","4afb669e":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","0c487e5a":"X_train.columns","596be000":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, attributes_names):\n        self.attributes_names = attributes_names\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return X[self.attributes_names].values","ec09d45b":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# numerical pipeline\n\nnum_pipeline = Pipeline([\n    \n    ('select_data', DataFrameSelector(X_train.columns)),\n    ('Std_Scaler', StandardScaler())\n])\n\nX_train_transformed = num_pipeline.fit_transform(X_train)\nX_test_transformed = num_pipeline.fit_transform(X_test)","7ae873b6":"X_train_transformed.shape, X_test_transformed.shape","27f1e73d":"from sklearn.ensemble import RandomForestClassifier\nimport time\n\nstart = time.time()\n\nrf_clf = RandomForestClassifier(bootstrap=True, class_weight = {0:1, 1:5},\n            criterion='gini', max_depth=21, max_features='auto',\n            max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=3,\n            min_samples_split=19, min_weight_fraction_leaf=0.0,\n            n_estimators=277, n_jobs=1, oob_score=False, random_state=42,\n            verbose=5, warm_start=False)\n\nrf_clf.fit(X_train_transformed, y_train)\n\nend = time.time()\n\nprint(\"run_time:\", (end-start)\/(60*60))","0f390c4c":"from sklearn.model_selection import cross_val_predict\n\nimport time\n\nstart = time.time()\n\ny_train_pred_rf = cross_val_predict(rf_clf, X_train_transformed, y_train, cv=3, verbose=5)\n\nend = time.time()\n\nprint(\"run_time:\", (end-start)\/(60*60))","c91a13b1":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_train, y_train_pred_rf)","af461328":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_train, y_train_pred_rf))\nprint(recall_score(y_train, y_train_pred_rf))\nprint(f1_score(y_train, y_train_pred_rf))\nprint(cohen_kappa_score(y_train, y_train_pred_rf))\n\nprint(classification_report(y_train, y_train_pred_rf))","a278e277":"# import scipy.stats as st\n# from sklearn.model_selection import RandomizedSearchCV\n\n# one_to_left = st.beta(10, 1)  \n# from_zero_positive = st.expon(0, 50)\n\n# params = {  \n#     \"n_estimators\": st.randint(50, 300),\n#     \"max_depth\": st.randint(3, 40),\n#    \"min_samples_leaf\": st.randint(3, 40),\n#     \"min_samples_split\": st.randint(3, 20)\n# }\n\n# gs = RandomizedSearchCV(rf_clf, params)","da0e7601":"# gs.fit(X_train_transformed, y_train)  ","15049e6c":"# gs.best_params_","f81113a3":"from sklearn.model_selection import cross_val_predict\n\ny_probas_rf = cross_val_predict(rf_clf, X_train_transformed, y_train, cv=3, method=\"predict_proba\", verbose=0)\ny_scores_rf = y_probas_rf[:,1]","13b6cdd0":"roc_score_rf = roc_auc_score(y_train, y_scores_rf)\nroc_score_rf","5567392a":"from sklearn.metrics import precision_recall_curve\n\nprecisions, recalls, thresholds = precision_recall_curve(y_train, y_scores_rf)\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label = \"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"r-\", label = \"Recall\")\n    plt.xlabel(\"Thresholds\")\n    plt.legend(loc=\"upper left\")\n    \nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.show()","4b11c966":"from sklearn.metrics import roc_curve\n\nfpr_rf, tpr_rf, threshold_rf = roc_curve(y_train, y_scores_rf)\n\ndef plot_roc_curve(fpr_rf, tpr_rf, figsize=(15,12), label = None):\n    plt.plot(fpr_rf, tpr_rf, linewidth = 2, label = label)\n    plt.plot([0,1], [0,1], \"k--\")\n    plt.axis([0,1,0,1])\n    plt.xlabel(\"False Pos Rate\")\n    plt.ylabel('True Neg Rate')\n    \n    \nplot_roc_curve(fpr_rf, tpr_rf)","0f90bba6":"plt.plot(thresholds, recalls[1:], 'b', label='Threshold-Recall curve')\nplt.title('Recall for different threshold values')\nplt.xlabel('Thresholds')\nplt.ylabel('Recall')\nplt.show()","f5ce0af0":"y_pred_test_rf = rf_clf.predict(X_test_transformed)","d7eb9eea":"confusion_matrix(y_test, y_pred_test_rf)","25ddc92f":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_test, y_pred_test_rf))\nprint(recall_score(y_test, y_pred_test_rf))\nprint(f1_score(y_test, y_pred_test_rf))\nprint(cohen_kappa_score(y_test, y_pred_test_rf))\n\nprint(classification_report(y_test, y_pred_test_rf))","b8d8717c":"y_probas_rf = rf_clf.predict_proba(X_test_transformed)\ny_scores_rf = y_probas_rf[:,1]\nroc_score_rf = roc_auc_score(y_test, y_scores_rf)\nroc_score_rf","2b1e6895":"from sklearn.metrics import precision_recall_curve\n\nprecisions, recalls, thresholds = precision_recall_curve(y_test, y_scores_rf)\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label = \"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"r-\", label = \"Recall\")\n    plt.xlabel(\"Thresholds\")\n    plt.legend(loc=\"upper left\")\n    \nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.show()","f53d1aa6":"from sklearn.metrics import roc_curve\n\nfpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_scores_rf)\n\ndef plot_roc_curve(fpr_rf, tpr_rf, figsize=(15,12), label = None):\n    plt.plot(fpr_rf, tpr_rf, linewidth = 2, label = label)\n    plt.plot([0,1], [0,1], \"k--\")\n    plt.axis([0,1,0,1])\n    plt.xlabel(\"False Pos Rate\")\n    plt.ylabel('True Neg Rate')\n      \nplot_roc_curve(fpr_rf, tpr_rf)","2a4cabbf":"df_test.head()","024bc91d":"df_test.shape","1b011a57":"X = df_new_valid_2\ny = df_new_valid_2.label.copy()","dc26b569":"X_val = X.drop(\"label\", axis =1)\ny_val = y","33b8d2dc":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# numerical pipeline\n\nnum_pipeline = Pipeline([\n    \n    ('select_data', DataFrameSelector(X_val.columns)),\n    ('Std_Scaler', StandardScaler())\n])\n\n\nX_val_transformed = num_pipeline.fit_transform(X_val)","f64f9801":"y_pred_test_rf_val = rf_clf.predict(X_val_transformed)","2c29c357":"confusion_matrix(y_val, y_pred_test_rf_val)","39371f07":"from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, cohen_kappa_score\n\nprint(precision_score(y_val, y_pred_test_rf_val))\nprint(recall_score(y_val, y_pred_test_rf_val))\nprint(f1_score(y_val, y_pred_test_rf_val))\nprint(cohen_kappa_score(y_val, y_pred_test_rf_val))\n\nprint(classification_report(y_val, y_pred_test_rf_val))","fec5bb02":"y_probas_rf = rf_clf.predict_proba(X_val_transformed)\ny_scores_rf = y_probas_rf[:,1]\nroc_score_rf = roc_auc_score(y_val, y_scores_rf)\nroc_score_rf","829c390e":"from sklearn.metrics import precision_recall_curve\n\nprecisions, recalls, thresholds = precision_recall_curve(y_val, y_scores_rf)\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label = \"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"r-\", label = \"Recall\")\n    plt.xlabel(\"Thresholds\")\n    plt.legend(loc=\"upper left\")\n    \nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.show()","8b201d6d":"from sklearn.metrics import roc_curve\n\nfpr_rf, tpr_rf, threshold_rf = roc_curve(y_val, y_scores_rf)\n\ndef plot_roc_curve(fpr_rf, tpr_rf, figsize=(15,12), label = None):\n    plt.plot(fpr_rf, tpr_rf, linewidth = 2, label = label)\n    plt.plot([0,1], [0,1], \"k--\")\n    plt.axis([0,1,0,1])\n    plt.xlabel(\"False Pos Rate\")\n    plt.ylabel('True Neg Rate')\n      \nplot_roc_curve(fpr_rf, tpr_rf)","51286336":"# Fastai Hooks & Embeddings for Train data","6a022f7e":"# Performance on Unseen Test","b98ece6f":"# Random Forest","34fd065b":"# Embeddings for Valid Data","2b77f22f":"# Performance on Valid Data"}}