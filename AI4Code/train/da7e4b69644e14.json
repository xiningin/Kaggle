{"cell_type":{"aa76d7fe":"code","8a551e51":"code","6b07c785":"code","775ee77f":"code","65b2792a":"code","d7eff30c":"code","1c9af35f":"code","e7fbac04":"code","fe912f50":"code","6d002158":"code","4b1f8e54":"code","22ebe5b4":"code","733074e0":"code","7b44ec64":"code","f4930e75":"code","4dd848e9":"code","2aa89e31":"code","2f268487":"code","4158c33b":"code","009c76b1":"code","301a9e0a":"code","bd35e31e":"code","73e3400a":"code","bedaf0c2":"code","78ac2e4d":"code","3fe6261d":"code","c7ba1344":"markdown","85b4a0a5":"markdown","4d9686e1":"markdown","87f1dbcb":"markdown","33ad1b33":"markdown","44a8480d":"markdown","e0832ed9":"markdown","603188bd":"markdown","620b2895":"markdown"},"source":{"aa76d7fe":"import numpy as np\nimport pandas as pd\nimport warnings\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport missingno as msno\nimport seaborn as sns\nimport gc\n%matplotlib inline\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')","8a551e51":"train = pd.read_csv('..\/input\/song-popularity-prediction\/train.csv').drop('id', axis=1)\ntest  = pd.read_csv('..\/input\/song-popularity-prediction\/test.csv').drop('id', axis=1)\nss    = pd.read_csv('..\/input\/song-popularity-prediction\/sample_submission.csv')","6b07c785":"train.head()","775ee77f":"test.head()","65b2792a":"train.shape, test.shape","d7eff30c":"msno.matrix(train)","1c9af35f":"train.isnull().mean() * 100","e7fbac04":"msno.matrix(test)","fe912f50":"test.isnull().mean() * 100","6d002158":"train.loc[:, 'song_duration_ms':'audio_valence'].describe().T.style.bar(subset=['mean'], color='#206ff2')\\\n                            .background_gradient(subset=['std'], cmap='Reds')\\\n                            .background_gradient(subset=['50%'], cmap='coolwarm')","4b1f8e54":"sns.countplot(train['song_popularity'], palette='Set3')","22ebe5b4":"features = train.columns.values[0:10]\ni = 0\nsns.set_style('whitegrid')\nplt.figure()\nfig, ax = plt.subplots(10,10,figsize=(18,22))\n\nfor feature in features:\n    i += 1\n    plt.subplot(5,2,i)\n    sns.distplot(train[feature], hist=False,label='train')\n    sns.distplot(test[feature], hist=False,label='test')\n    plt.xlabel(feature, fontsize=9)\n    locs, labels = plt.xticks()\n    plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n    plt.tick_params(axis='y', which='major', labelsize=6)\nplt.show();","733074e0":"features = train.columns.values[9:13]\ni = 0\nsns.set_style('whitegrid')\nplt.figure()\nfig, ax = plt.subplots(10,10,figsize=(12,16))\n\nfor feature in features:\n    i += 1\n    plt.subplot(2,2,i)\n    sns.distplot(train[feature], hist=False,label='train')\n    sns.distplot(test[feature], hist=False,label='test')\n    plt.xlabel(feature, fontsize=9)\n    locs, labels = plt.xticks()\n    plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n    plt.tick_params(axis='y', which='major', labelsize=6)\nplt.show();","7b44ec64":"plt.figure(figsize=(16,6))\nfeatures = train.columns.values[0:13]\nplt.title(\"Distribution of mean values per row in the train and test set\")\nsns.distplot(train[features].mean(axis=1),color=\"green\", kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","f4930e75":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per row in the train and test set\")\nsns.distplot(train[features].std(axis=1),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(test[features].std(axis=1),color=\"red\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","4dd848e9":"columns = train.columns[0:14].to_list()\ncolumns.append('song_popularity')\n\ncorr = train[columns].corr()\nf, ax = plt.subplots(figsize=(20,10))\nmask = np.triu(np.ones_like(corr, dtype=bool))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(corr, annot=True, mask = mask, cmap=cmap)","2aa89e31":"X = train.drop('song_popularity', axis=1).copy()\ny = train['song_popularity'].copy()\nX_test = test.copy()\n\ndel train\ngc.collect()\ndel test\ngc.collect()","2f268487":"def feature_engineering(df):\n    df['NaN_row'] = df.isna().sum(axis=1)\n    df['std'] = df.std(axis=1)\n    return df\n\nX = feature_engineering(X)\nX_test = feature_engineering(X_test)","4158c33b":"X.head()","009c76b1":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\npipeline = Pipeline([\n    ('impute', SimpleImputer(strategy='mean')),\n    ('scale', StandardScaler())\n])\n\nX = pd.DataFrame(columns=X.columns, data=pipeline.fit_transform(X))\nX_test = pd.DataFrame(columns=X_test.columns, data=pipeline.fit_transform(X_test))","301a9e0a":"X.head()","bd35e31e":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc","73e3400a":"params = {  'objective': 'binary', \n            'n_estimators': 20000,\n            'max_depth': 7,\n            'learning_rate':  0.01, \n            'min_child_weight': 256,\n            'min_child_samples': 15, \n            'reg_alpha': 10, \n            'reg_lambda': 0.1, \n            'subsample': 0.6, \n            'subsample_freq': 1, \n            'colsample_bytree': 0.4,}","bedaf0c2":"%%time\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=786)\n\npreds = []\nscores = []\nfeature_importance_df = pd.DataFrame()\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X, y)):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n    \n    model = LGBMClassifier(**params)\n    \n    model.fit(X_train, y_train,\n              eval_set = [(X_valid, y_valid)],\n              verbose = False,\n              early_stopping_rounds = 300)\n    \n    pred_valid = model.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = X.columns\n    fold_importance_df[\"importance\"] = model.feature_importances_\n    fold_importance_df[\"fold\"] = fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\" \"\\n\")\n    print('||'*40, \"\\n\")\n    \n    test_preds = model.predict_proba(X_test)[:,1]\n    preds.append(test_preds)\n    \nprint(f\"Overall Validation Score: {np.mean(scores)}\")","78ac2e4d":"cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n        .groupby(\"Feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:107].index)\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\nplt.figure(figsize=(14,28))\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('Features importance (averaged\/folds)')\nplt.tight_layout()\nplt.savefig('FI.png')","3fe6261d":"predictions = np.mean(np.column_stack(preds),axis=1)\n\nss['song_popularity'] = predictions\nss.to_csv('.\/lgbm.csv', index=False)\nss.head()","c7ba1344":"# Model training & prediction","85b4a0a5":"# Distribution of mean and std\nThis is the distribution of the mean values per row in the train and test set.","4d9686e1":"# Feature Engineering","87f1dbcb":"# Heatmap of correlation matrix","33ad1b33":"Distribution of standard deviation of values per row for train and test datasets.","44a8480d":"Let's check the distribution on target in training data","e0832ed9":"Let's check for missing values","603188bd":"# Density plots of features","620b2895":"Here I am capturing NaN per row and making new feature"}}