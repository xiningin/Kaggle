{"cell_type":{"e132aff5":"code","1ed51c11":"code","8d98e706":"code","829a1e79":"code","25ef488c":"code","fc336668":"code","4966b390":"code","a7bc942f":"code","c917db3e":"code","cdb0e96e":"code","e1074511":"code","e3d45a84":"code","507ca609":"code","f9c152ef":"code","bbf23e7d":"code","f2f82597":"code","3e909a9c":"code","cfe4226f":"code","75451e0d":"code","d9143136":"code","65b188c2":"code","4d5ea26a":"code","d78a32d2":"code","e0869f9a":"code","c67778a4":"code","76ca14b4":"code","10221d2f":"code","b4b8b45f":"code","849e1f8d":"code","5e21f7d1":"code","c95a08dd":"code","0f666459":"code","c8ed75ca":"code","d7b2e624":"code","f7757542":"code","aefec966":"code","356b9d10":"code","03b593c8":"code","7455bd73":"code","90de483d":"code","f745d72b":"code","f7a8d964":"markdown","5cf112e5":"markdown","bf85c596":"markdown","5035c52e":"markdown","d4718700":"markdown","d5a76ad0":"markdown","679baf62":"markdown","e44a0888":"markdown","e641e25c":"markdown","9a0e631c":"markdown","df079900":"markdown","1926d8e9":"markdown","a87f78d1":"markdown"},"source":{"e132aff5":"import pandas as pd\nimport numpy as np\n\nimport random, os\n\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications import imagenet_utils\n\nfrom keras.callbacks import EarlyStopping","1ed51c11":"base_dir = '..\/input\/hackerearth-deep-learning-identify-the-snake-breed\/dataset'\ntrain_dir = os.path.join(base_dir, 'train')\nfiles = os.listdir(train_dir)","8d98e706":"train_df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\ntrain_df.head()","829a1e79":"# train_file_df = pd.DataFrame({'image_id':list(map(lambda x:x.replace('.jpg', ''), files))})\n# train_file_df.head()","25ef488c":"# label_info = pd.merge(left = train_file_df, right = train_df)\n# label_info.head()","fc336668":"num_classes = len(train_df.breed.unique())\nnum_classes","4966b390":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils","a7bc942f":"le = LabelEncoder()\nbreed = le.fit_transform(train_df.breed)\ny = np_utils.to_categorical(breed, num_classes = num_classes)","c917db3e":"y.shape","cdb0e96e":"input_dim = (224, 224)\n\nX = np.zeros((y.shape[0], *input_dim, 3))","e1074511":"for i, img in enumerate(files):\n    image = load_img(os.path.join(train_dir, img), target_size = input_dim)\n    image = img_to_array(image)\n    image = image.reshape((1, *image.shape))\n    image = preprocess_input(image)\n    X[i] = image","e3d45a84":"X.shape","507ca609":"earlystop = EarlyStopping(\n    monitor = 'val_loss',\n    min_delta = 0,\n    patience = 2,\n    verbose = 0,\n    mode = 'auto'\n)","f9c152ef":"from keras.applications.vgg19 import VGG19\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout","bbf23e7d":"vgg_model = VGG19(\n    weights = 'imagenet',\n    include_top = False\n)","f2f82597":"vgg_x = vgg_model.output\nvgg_x = GlobalAveragePooling2D()(vgg_x)\nvgg_x = Dropout(0.2)(vgg_x)\nout = Dense(num_classes, activation = 'softmax')(vgg_x)","3e909a9c":"model = Model(inputs = vgg_model.input, outputs = out)\n","cfe4226f":"for layer in vgg_model.layers:\n    layer.trainable = False","75451e0d":"from keras.optimizers import Adam\nopt = Adam()","d9143136":"model.compile(\n    optimizer=opt,\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\nmodel.summary()","65b188c2":"hist = model.fit(\n    X,\n    y,\n    batch_size = 256,\n    epochs = 20,\n    validation_split = 0.2, \n    verbose = 2,\n    callbacks = [earlystop]\n)\n# model.save('snake_vgg_model1.h5')","4d5ea26a":"hist.history.keys()","d78a32d2":"val_acc = hist.history.get('val_accuracy')\nacc = hist.history.get('accuracy')","e0869f9a":"overfit_info = pd.DataFrame({'acc':acc, 'val_acc':val_acc})","c67778a4":"overfit_info.plot.line()","76ca14b4":"image_path = os.path.join(train_dir,'8b492b973d'+'.jpg')\nimage_path","10221d2f":"img = plt.imread(image_path)\nplt.imshow(img)\nplt.title('Original Bree --> pantherophis-vulpinus')\nplt.show()","b4b8b45f":"img_for_prediction = load_img(image_path, target_size = input_dim)\nimg_for_prediction = img_to_array(img_for_prediction)\nimg_for_prediction = img_for_prediction.reshape((1, *img_for_prediction.shape))\nimg_for_prediction = preprocess_input(img_for_prediction)","849e1f8d":"predictions = model.predict(img_for_prediction)\npred = np.argsort(predictions)[0][-5:]\npred \n# the Order is from 0 to 5 and 5th Position breed is highest.","5e21f7d1":"le.inverse_transform(pred)","c95a08dd":"vgg_x = vgg_model.output\nvgg_x = GlobalAveragePooling2D()(vgg_x)\nvgg_x = Dropout(0.3)(vgg_x)  # Change 1 : Increase the drop out\nout = Dense(num_classes, activation = 'softmax')(vgg_x)\n\nmodel2 = Model(inputs = vgg_model.input, outputs = out)\n\nfor layer in vgg_model.layers[:-2]:  # Change 2 : Skip training for last 2 layers\n    layer.trainable = False\n\nfor layer in vgg_model.layers[-2:]:  # Change 3 : training last 2 layers\n    layer.trainable = True\n\nmodel2.compile(\n    optimizer=opt,\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\nmodel2.summary()\n\nhist2 = model2.fit(\n    X,\n    y,\n    batch_size = 256,\n    epochs = 20,\n    validation_split = 0.2, \n    verbose = 2,\n    callbacks = [earlystop]\n)\n\n# model2.save('snake_vgg_model2.h5')","0f666459":"predictions = model2.predict(img_for_prediction)\npred = np.argsort(predictions)[0][-5:]\n\nle.inverse_transform(pred)","c8ed75ca":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model","d7b2e624":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n)\n\ndatagen.fit(X)","f7757542":"# using the reference to the model created at very first.\nhist_aug = model.fit_generator(\n    datagen.flow(X, y, batch_size = 256),\n    steps_per_epocs = len(X)\/32,\n    epochs = 20,\n    verbose = 2\n)","aefec966":"hist_aug.history.keys()","356b9d10":"hist_aug.save('model_img_augement.h5')","03b593c8":"model3 = load_model('model_img_augement.h5')","7455bd73":"predictions = model3.predict(img_for_prediction)\npred = np.argsort(predictions)[0][-5:]\n\nle.inverse_transform(pred)","90de483d":"# using the reference to the model created at very first.\nhist2_aug = model2.fit_generator(\n    datagen.flow(X, y, batch_size = 256),\n    steps_per_epocs = len(X)\/32,\n    epochs = 20,\n    verbose = 2\n)","f745d72b":"hist2_aug.save('model2_img_augement.h5')\n\nmodel4 = load_model('model2_img_augement.h5')\n\npredictions = model3.predict(img_for_prediction)\npred = np.argsort(predictions)[0][-5:]\n\nle.inverse_transform(pred)","f7a8d964":"# Import Library","5cf112e5":"# Create Callbacks","bf85c596":"# Mapping File with Breed.","5035c52e":"# Data Augement with more layers.","d4718700":"# With Image Augmentation","d5a76ad0":"# Predict \nImage ID : 8b492b973d\t\n\nBreed : pantherophis-vulpinus\n   ","679baf62":"Identify the snake breed\nhttps:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-deep-learning-challenge-snake-breed-detection\/machine-learning\/identify-the-snake-breed-5-66d9a9f5\/\n\nThis is a challenge from HackerEarth.com, and one of the participant from HE has uploaded the dataset on Kaggle. Refer below details on the challenge.\n\n# Problem statement\nThe government has been facing a long-standing issue of wild animals entering residential areas due to various reasons. It's of critical importance that if any such dangerous animal is encountered, the concerned authority should be notified immediately. Reptiles, especially snakes, are among the most dangerous animals and they often enter residential areas.\n\nRecently due to an incident of a youngster getting bitten by a snake, the government decided to install cameras at every corner of the road to detect snakes and other animals.\n\nYou have been hired as a Deep Learning engineer to create a sophisticated model that can detect the breed of a snake from its image.","e44a0888":"# Train Images","e641e25c":"# Convert Target to One-Hot Encoding.","9a0e631c":"Model has predicted \"thamnophis-sirtalis\" with highest probability.","df079900":"# More layers to train","1926d8e9":"# Convert Images to numpy array","a87f78d1":"# Target Information from csv file"}}