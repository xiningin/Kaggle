{"cell_type":{"ebcc6b77":"code","26beef7a":"code","1c424849":"code","25331680":"code","0ee5403e":"code","2ebce85b":"code","1614e481":"code","889644bf":"code","b079f161":"code","c52b2f00":"code","54315503":"code","f72142ce":"code","8b505c65":"code","3c9ef2da":"code","f382d821":"code","c0cb5652":"code","25ff40bf":"code","1c46d890":"code","fa1db514":"code","450d0624":"code","63c12e75":"code","81ea548e":"code","06a15feb":"code","f6face91":"code","3ab11680":"code","eed3d2f1":"code","8ba24773":"code","56e95de9":"code","02e203b9":"code","620090e7":"code","b8e0aaee":"code","ec450524":"code","4d5b856b":"code","89834e09":"code","7dbd226d":"code","b0a689a6":"code","b9f6c0b2":"code","2a62f33e":"code","184fac82":"code","a4af5b07":"code","c7d8666c":"code","f8078ee5":"code","8ff5c41a":"code","a50a3fc6":"code","763b2b88":"code","26b55085":"code","d6a04e56":"code","1510cce1":"code","c4e46dd4":"code","0942ab92":"code","4ec5b78d":"code","b32ed40c":"code","8c84a392":"code","d06bc95b":"code","6722c283":"code","26c79153":"code","6828ec1d":"code","ca2d2292":"code","54142f32":"code","816d37a1":"code","846079d0":"code","1e8e3346":"markdown","edda413d":"markdown","fe81f731":"markdown","420c54e9":"markdown","29947850":"markdown","a4476d8e":"markdown","c0f19c7b":"markdown","fdb83842":"markdown","290fc311":"markdown","f9d36c21":"markdown","08ea64f5":"markdown","12574c99":"markdown","3acfeaab":"markdown","6555bdb1":"markdown","4650cb8c":"markdown","7819d6d6":"markdown","3875b8ee":"markdown","810e424c":"markdown","15489a18":"markdown","ccbf3ec0":"markdown","ce23c891":"markdown","6e8981fe":"markdown"},"source":{"ebcc6b77":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport os.path as path\nimport os\n\ncwd = os.getcwd() # get the current working directory\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt # graphs plotting\n%matplotlib inline\nfrom Bio import SeqIO # some BioPython that might come in handy","26beef7a":"# Read the fasta-file and create a dictionary of its protein sequences\n\n# path for the input file on Kiril's laptop\ninput_file_name = 'E:\\!2020 SPRING\\8630 Advanced Bioinformatics\\Project\\!DATA\\Aligned Spike Proteins (StrainName-AccessionNumber-HostSpecies-VirusSpecies).fasta'\n\n# However, if we are on kaggle, we use kaggle directory\nif cwd == '\/kaggle\/working': \n    input_file_name = '..\/input\/spike-proteins-in-conona-viruses\/Aligned Spike Proteins (StrainName-AccessionNumber-HostSpecies-VirusSpecies).fasta'\n#     input_file_name = '..\/input\/spike-proteins-in-conona-viruses\/upd1300.fasta'\n\n    \n# The fasta defline (name of a sequence) has the following format:\n# Strain Name | Accession Number | Host Species | Virus Species) \nsequences_dictionary = {sequence.id : sequence.seq for sequence in SeqIO.parse(input_file_name,'fasta')}\n","1c424849":"# From the newly formed sequences_dictionary, we create 3 lists:\n# a list of deflines,\n# a list of sequences,\n# and a list of target values\n\n# We want to mark all sequences that belong to the viruses that can infect humans as 1 (i.e., target = 1), \n# all other sequences as 0 (i.e., target = 0)\n\ndeflines = [entry for entry in sequences_dictionary.keys()]             # create a list of deflines\nprotein_sequences = [entry for entry in sequences_dictionary.values()]  # create a list of protein sequences \ntargets = [1 if 'Human' in entry else 0 for entry in deflines]          # create a list of target values","25331680":"# Then we create a class fasta_sequence so that we would be able to use the sequence data easily \n\nclass fasta_sequence:\n    def __init__(self, defline, sequence, target, type_of_encoding = \"onehot\"):\n        \n        # we read the input data\n        \n        self.defline = defline\n        self.sequence = sequence\n        self.target = target\n        \n        # and create more descriptions of the input data\n        \n        # report the strain name (the 1st fiel of the defline)\n        self.strain_name = defline.split(\"|\")[0]\n        # report the accession number (the 2nd fiel of the defline)\n        self.accession_number = defline.split(\"|\")[1]        \n        # report the host species (the 3rd fiel of the defline)\n        self.host_species = defline.split(\"|\")[2]    \n        # report the virus species (the 4th fiel of the defline)\n        self.virus_species = defline.split(\"|\")[3]\n        \n        \n# We convert a string with the alphabet = 'ABCDEFGHIKLMNPQRSTUVWXYZ-' \n# !!!(B,X,Z are ``extra'' letters; we have to address this in the future) \n# into either a list mapping chars to integers (called integer encoding),\n# or a sparce list. In the latter, each amino acid is represented as an one-hot vector of length 20, \n# where each position, except one, is set to 0.  E.g., alanine is encoded as 10000000000000000000, cystine is encoded as 01000000000000000000\n# See the full table above.\n# Symbol '-' is encoded as a zero-vector.\n\n        def encoding(sequence, type_of_encoding):\n\n            # define universe of possible input values\n            alphabet = 'ABCDEFGHIJKLMNPQRSTUVWXYZ-'\n            # define a mapping of chars to integers\n            char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n\n\n            # integer encoding\n            integer_encoded = [char_to_int[char] for char in sequence]\n\n            # one-hot encoding\n            onehot_encoded = list()\n            for value in integer_encoded:\n                letter = [0 for _ in range(len(alphabet)-1)]\n                if value != len(alphabet)-1:\n                    letter[value] = 1\n                onehot_encoded.append(letter)\n            flat_list = [item for sublist in onehot_encoded for item in sublist]\n\n            if type_of_encoding == \"onehot\":\n                return flat_list\n            else:\n                return integer_encoded\n            \n        #  we use the encoding function to create a new attribute for the sequence -- its encoding        \n        self.encoded = encoding(sequence, type_of_encoding)","0ee5403e":"# we create a list of sequences as objects of the class fasta_sequence\n# all sequences are encoded with one-hot encoding (it is the default option of the constructor of the class)\nsequences = []\nfor i in range(0, len(deflines)):\n    current_sequence = fasta_sequence(deflines[i],protein_sequences[i],targets[i])\n    sequences.append(current_sequence)","2ebce85b":"# Let's get the first look at out data\n\nprint(\"There are\", len(sequences), \"sequences in the fasta file\")\nprint(\"Each of the sequences has\", len(sequences[0].sequence), \"cites\")\n\nimport random\nrandom_id = random.randrange(0,len(sequences),1) # generates a random number within the range of sequence numbers\nprint(\"\\n\\nBelow you can see an example of a random sequence number\",random_id,\"\\n\")\nprint(\"The Defline:\\n\",sequences[random_id].defline)\nprint(\"\\nThe details of the Defline:\\nThe strain name: \", sequences[random_id].strain_name), \nprint(\"The accession number: \",sequences[random_id].accession_number)\nprint(\"The host species: \",sequences[random_id].host_species)\nprint(\"The virus species: \",sequences[random_id].virus_species)\nprint(\"\\nThe Sequence:\\n\",sequences[random_id].sequence)\nprint(\"\\nThe Target Value:\\n\",sequences[random_id].target)\n# print(\"\\nEncoding:\\n\",sequences[random_id].encoded)","1614e481":"# Here we print the names of the sequences infective to humans among the first 100 sequence \nfor i in range(0,100):\n    if sequences[i].target == 1:\n        print(sequences[i].defline)","889644bf":"# create a list of strain names (the 4th fiel of the defline)\nvirus_species = [entry.virus_species for entry in sequences]    \n# convert the list of strain names into a set \nvirus_species_set = set(virus_species)\n\nprint(\"There are\", len(virus_species_set)-1, \"unique virus species in our dataset\") # we don't count the NA entry\nprint(\"The list of all unique virus species in our dataset:\\n\", virus_species_set)\n","b079f161":"# create a list of strain names of the viruses that can affect humans\nhuman_virus_species = [entry.virus_species for entry in sequences if 'Human' in entry.defline]\n# turn this list into a set\nhuman_virus_species_set = set(human_virus_species)\n\nprint(\"There are\",len(human_virus_species_set)-1, \"unique virus human-infective species in our dataset\") # we don't count the NA entry\nprint(\"The list of all unique human-infective virus species in our dataset:\\n\", human_virus_species_set)","c52b2f00":"idx = pd.Index(virus_species) # creates an index which allows counting the entries easily\nprint('Here are all of the viral species in the dataset: \\n', len(idx),\"entries in total\")\nidx.value_counts()","54315503":"# here we prepare the data to be plootted as a bar graph\ny_labels = idx.value_counts().index.values # virus species names\ncounts = idx.value_counts().values    # numbers of occuriencies\ncounts_as_series = pd.Series(counts)","f72142ce":"# plot the bar graph\n\nplt.figure(figsize=(12, 9))\nax = counts_as_series.plot(kind ='barh')\nax.set_title('Distribution of viral species')\nax.set_xlabel('Number of entries')\n#ax.set_ylabel('Species of virus')\nax.set_yticklabels(y_labels)\nax.set_xlim(-10, 295) # we change the x limits in order to make labels more readable\n\nrectangles = ax.patches\n\n# we place a label for each bar\nfor rectangle in rectangles:\n    \n    # we obtain x and y positions for the current label\n    x_value = rectangle.get_width()\n    y_value = rectangle.get_y() + rectangle.get_height()\/2\n    \n    # we annotate a current bar in the bar graph\n    plt.annotate(\n        x_value,                    # we use x_value as a label\n        (x_value, y_value),         # we place labels at end of the bars\n        xytext=(5, 0),              # we shift the label horizontally by 5\n        textcoords=\"offset points\", # we interpret xytext as an offset in points\n        va='center',                # we center the labels vertically \n        ha='left')                  # we specify the alignment for the labels                                   ","8b505c65":"#determining unique viral hosts\nhost_species = [entry.host_species for entry in sequences]    \nhost_species_set = set(host_species)\n\nprint(\"There are\",len(host_species_set)-1, \"unique viral hosts in our dataset\") # we don't count the NA entry\nprint(\"The list of unique viral hosts in our dataset is: \\n\", host_species_set)","3c9ef2da":"print('Here are all of the host species in the dataset:')\n#display host species \nidx2 = pd.Index(host_species)\nprint(idx2.value_counts())\n\n# here we prepare the data to be plootted as a bar graph\ny_labels = idx2.value_counts().index.values # viral host species names\ncounts = idx2.value_counts().values    # numbers of occuriencies\ncounts_as_series = pd.Series(counts)\n\n\nplt.figure(figsize=(12, 9))\nax = counts_as_series.plot(kind ='barh')\nax.set_title('The data distribution of viral hosts')\nax.set_xlabel('Number of entries')\n#ax.set_ylabel('Species of viral host')\nax.set_yticklabels(y_labels)\nax.set_xlim(-10, 295) # we change the x limits in order to make labels more readable\n\nrectangles = ax.patches\n\n# we place a label for each bar\nfor rectangle in rectangles:\n    \n    # we obtain x and y positions for the current label\n    x_value = rectangle.get_width()\n    y_value = rectangle.get_y() + rectangle.get_height()\/2\n    \n    # we annotate a current bar in the bar graph\n    plt.annotate(\n        x_value,                    # we use x_value as a label\n        (x_value, y_value),         # we place labels at end of the bars\n        xytext=(5, 0),              # we shift the label horizontally by 5\n        textcoords=\"offset points\", # we interpret xytext as an offset in points\n        va='center',                # we center the labels vertically \n        ha='left')                  # we specify the alignment for the labels       ","f382d821":"# How many viral sequences are marked as infective to humans?\n# To answer it, we can simply count 1's in the target list:\n\nprint(\"We have got\", targets.count(1), \"entries that can infect humans\") \n","c0cb5652":"human_related_sequences = [entry for entry in sequences if 'Human' in entry.defline]  # create a list of human related sequences","25ff40bf":"# NA's in human sequences\ncountNAs = 0\nhuman_NAs = []\nfor entry in human_related_sequences:\n    if entry.virus_species == \"NA\":\n        human_NAs.append(entry.accession_number)\n        countNAs += 1 \n\nprint(\"In total there are\",countNAs,\"NA's in human related sequences.\")\nprint(\"Assension numbers of NA's in human related sequences:\")\nprint(human_NAs)","1c46d890":"# create a list of strain names (the 4th fiel of the defline)\nvirus_species_human = [entry.virus_species for entry in  human_related_sequences]  \nidx_human = pd.Index(virus_species_human) # creates an index which allows counting the entries easily\nidx_human.value_counts()","fa1db514":"multi_targets = []\n\nfor i in range(len(deflines)):\n    vtl = deflines[i].lower()\n    if 'human' in vtl:\n        multi_targets.append('Human')\n    elif 'bat' in vtl:\n        multi_targets.append('Bat')\n    elif 'avian' in vtl:\n        multi_targets.append('Bird')\n    elif 'camel' in vtl:\n        multi_targets.append('Camel')\n    elif 'porcine' in vtl or 'swine' in vtl or 'sus_scrofa_domesticus' in vtl:\n        multi_targets.append(\"Pig\")\n    else:\n        multi_targets.append('Other')","450d0624":"coro_types = []\nfor i in range(len(deflines)):\n    vtl = deflines[i].lower()\n    if 'alpha' in vtl:\n        coro_types.append(\"Alpha\")\n    elif 'hku10' in vtl:\n        coro_types.append(\"Alpha\")\n    # do these before hku1 and hku2 so it counts it right\n    elif 'hku12' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'hku13' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'hku14' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'hku15' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'hku16' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'hku17' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'hku18' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'hku19' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'hku20' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'hku21' in vtl:\n        coro_types.append(\"Delta\")\n\n    elif 'fcov' in vtl:\n        coro_types.append(\"Alpha\")\n    elif 'nl63' in vtl:\n        coro_types.append(\"Alpha\")\n    elif 'hku2' in vtl:\n        coro_types.append(\"Alpha\")\n    elif 'hku11' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'beta' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'cattle' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'mouse' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'hku1' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'hku4' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'hku5' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'hku9' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'severe_acute_respiratory_syndrome' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'SARS' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'middle_east_respiratory_syndrome' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'camel' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'murine' in vtl:\n        coro_types.append(\"Beta\")\n    elif 'chicken' in vtl:\n        coro_types.append(\"Gamma\")\n    elif 'pheasant' in vtl:\n        coro_types.append(\"Gamma\")\n    elif 'pigeon' in vtl:\n        coro_types.append(\"Gamma\")\n    elif 'beluga' in vtl:\n        coro_types.append(\"Gamma\")\n    elif 'tcov' in vtl:\n        coro_types.append(\"Gamma\")\n    elif 'duck' in vtl:\n        coro_types.append(\"Gamma\")\n    elif 'porcine' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'swine' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'sus_scrofa_domesticus' in vtl:\n        coro_types.append(\"Delta\")\n    elif 'sparrow' in vtl:\n        coro_types.append('Delta')\n    elif 'human' in vtl:\n        coro_types.append(\"Human Uncategorized\")\n    else:\n        coro_types.append(\"N\/A\")","63c12e75":"labels = ['Human', 'Bat','Camel', 'Other', 'Bird', 'Pig']\noverall_size = len(multi_targets)\nsizes = [multi_targets.count('Human') \/ overall_size, \\\n         multi_targets.count('Bat') \/ overall_size, \\\n         multi_targets.count('Camel') \/ overall_size, \\\n         multi_targets.count('Other') \/ overall_size, \\\n         multi_targets.count('Bird') \/ overall_size, \\\n         multi_targets.count('Pig') \/ overall_size]\n\nexplode = (0.1, 0, 0, 0, 0, 0)\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal')  \nplt.tight_layout()\nplt.show()","81ea548e":"ct_labels = ['Alpha', 'Beta', 'Gamma', 'Delta', 'N\/A', 'Human Uncategorized']\nct_overall_size = len(coro_types)\nct_sizes = [coro_types.count('Alpha') \/ ct_overall_size, \\\n            coro_types.count('Beta') \/ ct_overall_size, \\\n            coro_types.count('Gamma') \/ct_overall_size, \\\n            coro_types.count('Delta') \/ ct_overall_size, \\\n            coro_types.count('N\/A') \/ ct_overall_size, \\\n            coro_types.count('Human Uncategorized') \/ ct_overall_size]\n\nct_explode = (0, 0, 0, 0, 0, 0)\n\nct_fig1, ct_ax1 = plt.subplots()\nct_ax1.pie(ct_sizes, explode = ct_explode, labels = ct_labels, autopct = '%1.1f%%',\n        shadow=True, startangle=90)\n\n# Equal aspect ratio ensures that pie is drawn as a circle\n\nct_ax1.axis('equal')  \nplt.tight_layout()\nplt.show()","06a15feb":"# for a list of sequences, returns a list of encoded sequences and a list of targets\ndef EncodeAndTarget(list_of_sequences):\n    # encoding the sequences\n    list_of_encoded_sequences = [entry.encoded for entry in list_of_sequences]\n    # creating lists of targets\n    list_of_targets = [entry.target for entry in list_of_sequences]\n    return list_of_encoded_sequences, list_of_targets   ","f6face91":"# encoding ALL the sequences\nencoded_sequences = [entry.encoded for entry in sequences]","3ab11680":"number_of_seq = int(len(sequences)*0.20)\nrandom20 = random.sample(sequences, number_of_seq)\n\n# obtaining encoded sequences and lists of targets\nencoded_random20, targets_random20 = EncodeAndTarget(random20)","eed3d2f1":"# obtaining encoded sequences and lists of targets\nencoded_human_sequences, human_targets = EncodeAndTarget(human_related_sequences)","8ba24773":"# creating two lists of sequenses: with and without Human_coronavirus_HKU1\nsequences_without_HKU1 = [entry for entry in sequences if 'Human_coronavirus_HKU1' not in entry.defline] \nsequences_HKU1 = [entry for entry in sequences if 'Human_coronavirus_HKU1' in entry.defline] \n\n# obtaining encoded sequences and lists of targets\nencoded_without_HKU1, targets_without_HKU1 = EncodeAndTarget(sequences_without_HKU1)\nencoded_HKU1, targets_HKU1 = EncodeAndTarget(sequences_HKU1)","56e95de9":"# creating two lists of sequenses: with and without Severe_acute_respiratory_syndrome_related_coronavirus\nsequences_without_SARS1 = [entry for entry in sequences if 'Severe_acute_respiratory_syndrome_related_coronavirus' not in entry.defline] \nsequences_SARS1 = [entry for entry in sequences if 'Severe_acute_respiratory_syndrome_related_coronavirus' in entry.defline] \n\n# obtaining encoded sequences and lists of targets\nencoded_without_SARS1, targets_without_SARS1 = EncodeAndTarget(sequences_without_SARS1)\nencoded_SARS1, targets_SARS1 = EncodeAndTarget(sequences_SARS1)","02e203b9":"# we create a list were as many avian related sequences as many human relared are in human_related_sequences\nAvian_dataset = [entry for entry in sequences if 'Avian' in entry.defline]\nHuman_Avian_dataset = human_related_sequences + random.sample(Avian_dataset, k = targets.count(1))\n\n# obtaining encoded sequences and lists of targets\nbalanced_encoded_sequences, balancedtargets = EncodeAndTarget(Human_Avian_dataset)","620090e7":"# Manual observation of viral hosts species show 25 hosts with following names which are mammals: \n# Chimpanzee, Anteater, Rat, Mink, Hedgehog, \n# Alpaca, Human, Dolphin, Pig, Buffalo, \n# Sus_scrofa_domesticus\n# Mus_Musculus__Severe_Combined_Immunedeficiency__Scid___Female__6_8_Weeks_Old__Liver__Sample_Id:_E4m31, \n# Dog, Mouse, bat_BF_506I, \n# Rabbit, Camel, Goat, Cattle, Horse, \n# Cat, Bat, bat_BF_258I, Swine, Ferret        \n\nlist_of_mammals_but_human = ['Alpaca', 'Anteater', 'Bat', 'Buffalo', 'Camel',\n                   'Cat', 'Cattle', 'Chimpanzee', 'Dog', 'Dolphin',\n                   'Ferret', 'Goat', 'Hedgehog', 'Horse', 'Mink', 'Mouse',\n                   'Mus_Musculus__Severe_Combined_Immunedeficiency__Scid___Female__6_8_Weeks_Old__Liver__Sample_Id:_E4m31,'\n                   'Pig', 'Rabbit', 'Rat', 'Rhinolophus_blasii', 'Sus_scrofa_domesticus',\n                   'Swine', 'bat_BF_258I', 'bat_BF_506I']\n\nmammal_dataset_but_human = []\nmammal_human = []\nfor sequence in sequences:\n    if sequence.host_species == \"Human\":\n        mammal_human.append(sequence)\n        continue\n    for entry in list_of_mammals_but_human:\n        if sequence.host_species == entry:\n            mammal_dataset_but_human.append(sequence)\n            continue\n            \nmammal_dataset = mammal_dataset_but_human + mammal_human\n\n# obtaining encoded sequences and lists of targets\nmammal_encoded_sequences, mammaltargets = EncodeAndTarget(mammal_dataset)","b8e0aaee":"#adding alpha and betacoronaviruses to separate lists based on criteria outlined in \"vizualization\" section\n\n\nlist_of_alpha_1 = [entry for entry in sequences if 'alpha' in entry.defline.lower()]\nlist_of_alpha_2 = [entry for entry in sequences if 'hku10' in entry.defline.lower()]\nlist_of_alpha_3 = [entry for entry in sequences if 'fcov' in entry.defline.lower()]\nlist_of_alpha_4 = [entry for entry in sequences if 'nl63' in entry.defline.lower()]\nlist_of_alpha_5 = [entry for entry in sequences if 'hku2' in entry.defline.lower()]\n\n\nlist_of_beta_1 = [entry for entry in sequences if 'beta' in entry.defline.lower()]\nlist_of_beta_2 = [entry for entry in sequences if 'hku14' in entry.defline.lower()]\nlist_of_beta_3 = [entry for entry in sequences if 'cattle' in entry.defline.lower()]\nlist_of_beta_4 = [entry for entry in sequences if 'mouse' in entry.defline.lower()]\nlist_of_beta_5 = [entry for entry in sequences if 'hku1' in entry.defline.lower()]\nlist_of_beta_6 = [entry for entry in sequences if 'hku4' in entry.defline.lower()]\nlist_of_beta_7 = [entry for entry in sequences if 'hku5' in entry.defline.lower()]\nlist_of_beta_8 = [entry for entry in sequences if 'hku9' in entry.defline.lower()]\nlist_of_beta_9 = [entry for entry in sequences if 'severe_acute_respiratory_syndrome' in entry.defline.lower()]\nlist_of_beta_10 = [entry for entry in sequences if 'SARS' in entry.defline.lower()]\nlist_of_beta_11 = [entry for entry in sequences if 'middle_east_respiratory_syndrome' in entry.defline.lower()]\nlist_of_beta_12 = [entry for entry in sequences if 'camel' in entry.defline.lower()]\nlist_of_beta_13 = [entry for entry in sequences if 'murine' in entry.defline.lower()]\n\n#combining datasets and removing duplicate sequences\n\nalpha_coronavirus = list_of_alpha_1 + list_of_alpha_2 + list_of_alpha_3 + list_of_alpha_4 + list_of_alpha_5  \nbeta_coronavirus = list_of_beta_1 + list_of_beta_2 + list_of_beta_3 + list_of_beta_4 + list_of_beta_5 + list_of_beta_6 + list_of_beta_7 + list_of_beta_8 + list_of_beta_9 + list_of_beta_10 + list_of_beta_11 + list_of_beta_12 + list_of_beta_13\n\nalpha_and_beta_coronavirus = alpha_coronavirus + beta_coronavirus\nalpha_and_beta_coronavirus = list(dict.fromkeys(alpha_and_beta_coronavirus))\n\nprint('Our data set has', len(alpha_and_beta_coronavirus), 'alphacoronavirus + betacoronavirus sequences')\n\n\n# Creating lists of all non-alphacoronavirus and non-betacoronavirus sequences based on \"vizualization\" section \n\nnon_alpha_beta = []\n    \nfor entry in sequences:\n    if entry  not in alpha_and_beta_coronavirus:\n        non_alpha_beta.append(entry)\n\n\nprint(len(non_alpha_beta), 'are not alphacoronavirus or betacoronavirus')\n\n#combining into one list, this is the entire data set. Previous lists allow for individual access to alphacoroanvirus\/betacoronavirus \n#or their specific titles indicated in the defline (which is represented within our visualization)\n\nalpha_beta_targeted_list = alpha_and_beta_coronavirus + non_alpha_beta\n\n#creating a list of custom targets: 1's refer to alpha and betacoronavirus sequences, 0's refer to non-alpha and betacoronavirus sequences\n\nalpha_beta_targets = []\n\nfor entry in alpha_and_beta_coronavirus:\n    alpha_beta_targets.append(1)\n    \nfor entry in non_alpha_beta:\n    alpha_beta_targets.append(0)\n    \n\n\n# encoding\n# we will only make use of the encoded (encoded_alpha_beta) dataset\n# targets will be represented in alpha_beta_targets\n\nencoded_alpha_beta, alpha_beta_targets2 = EncodeAndTarget(alpha_beta_targeted_list)\n\n\n","ec450524":"from sklearn.manifold import TSNE\nimport seaborn as sns\n\n# We embed all our sequences into 2D vectors with help of TSNE\nX_embedded = TSNE(n_components=2).fit_transform(encoded_sequences)","4d5b856b":"# We visualize the embeddings of ALL sequences\n# Type: 0 is not infective\n#       1 is infective\n\ndata_frame = pd.DataFrame({'1st coordinate of the embedded vector': X_embedded[:,0], \n                           '2nd coordinate of the embedded vector': X_embedded[:,1], \n                           'Type': targets})\nsns.relplot(x = '1st coordinate of the embedded vector', \n            y = '2nd coordinate of the embedded vector', \n            hue = 'Type', \n            data = data_frame, \n            legend = \"full\",\n            style = 'Type')\nplt.show()","89834e09":"# We visualize the embeddings of ALL sequences\n# Type is a type of host\n\ndata_frame = pd.DataFrame({'1st coordinate of the embedded vector': X_embedded[:,0], \n                           '2nd coordinate of the embedded vector': X_embedded[:,1], \n                           'Types of host': multi_targets})\nsns.relplot(x = '1st coordinate of the embedded vector', \n            y = '2nd coordinate of the embedded vector', \n            hue = 'Types of host', \n            data = data_frame, \n            legend = \"full\",\n            style = 'Types of host')\nplt.show()","7dbd226d":"# We visualize the embeddings of ALL sequences\n# Type is a type of virus species\n\ndata_frame_coro_types = pd.DataFrame({'1st coordinate of the embedded vector': X_embedded[:,0], \n                           '2nd coordinate of the embedded vector': X_embedded[:,1], \n                           'Types of virus': coro_types})\nsns.relplot(x = '1st coordinate of the embedded vector', \n            y = '2nd coordinate of the embedded vector', \n            hue = 'Types of virus', \n            data = data_frame_coro_types, \n            legend = \"full\",\n            style = 'Types of virus')\nplt.show()","b0a689a6":"# We embed human related sequences into 2D vectors with help of TSNE\n\nX_embedded_human = TSNE(n_components=2).fit_transform(encoded_human_sequences)","b9f6c0b2":"# We visualize the embeddings of human related sequences\n# Type is a type of virus species\n\nhuman_related_viral_species = [entry.virus_species for entry in human_related_sequences]\n\ndata_frame = pd.DataFrame({'1st coordinate of the embedded vector': X_embedded_human[:,0], \n                           '2nd coordinate of the embedded vector': X_embedded_human[:,1], \n                           'Types of virus': human_related_viral_species})\nsns.relplot(x = '1st coordinate of the embedded vector', \n            y = '2nd coordinate of the embedded vector', \n            hue = 'Types of virus', \n            data = data_frame, \n            legend = \"full\",\n            style = 'Types of virus')\nplt.show()","2a62f33e":"from sklearn import cluster\n\nnumber_of_clusters = 7\n\nour_dictionary_of_clustering = {\"kMeans\": cluster.KMeans(n_clusters = number_of_clusters, random_state = 0, \n                                                         init = \"k-means++\", max_iter = 300, n_init = 10), \n                                 \"Birch\": cluster.Birch(n_clusters = number_of_clusters)\n                                }","184fac82":"# Search for elbow for k-means clustering\n\ndef ElbowSearch_kMeans(X, min_number_of_clusters = 2, \n                        max_number_of_clusters = 7, plotting = True):\n\n    wcss = [] # wcss = Within Cluster Sum of Squares \n    for i in range(min_number_of_clusters, max_number_of_clusters + 1):\n        our_clustering_method = cluster.KMeans(n_clusters = i, random_state = 0, \n                                               init = \"k-means++\", max_iter = 300, n_init = 10)\n        our_clustering_method.fit(X)\n       \n        # inertia_ calculates sum of squared distances of samples to their closest cluster center\n        wcss.append(our_clustering_method.inertia_) \n   \n    if plotting == True:\n        plt.plot(range(min_number_of_clusters, max_number_of_clusters + 1), wcss)\n        plt.title(\"Elbow method for kMeans\")\n        plt.xlabel(\"Number of clusters\")\n        plt.ylabel(\"Within Cluster Sum of Squares (WCSS)\")\n        plt.show()\n        \n    return wcss","a4af5b07":"from sklearn.decomposition import TruncatedSVD\n\ndef Clustering(X, n_clusters = number_of_clusters,\n               list_of_chosen = [\"kMeans\"], plotting = True,\n               dictionary_of_clustering = our_dictionary_of_clustering):\n    dict_labeling = {}\n    for name, clustering_method in dictionary_of_clustering.items():\n        if name in list_of_chosen:\n            labels = clustering_method.fit_predict(X)    \n            dict_labeling[name] = labels\n            \n            if plotting == True:\n                svd = TruncatedSVD(n_components = 2, n_iter = 7, random_state = 42)\n                X_embedded_SVD = svd.fit_transform(X)\n                data_frame_clustering = pd.DataFrame({'1st SVD coordinate': X_embedded_SVD[:,0],\n                                                      '2nd SVD coordinate': X_embedded_SVD[:,1], \n                                                      'Cluster labels':  labels})\n                sns.relplot(x = '1st SVD coordinate', \n                            y = '2nd SVD coordinate', \n                            hue = 'Cluster labels', \n                            data = data_frame_clustering, \n                            legend = \"full\",\n                            style = 'Cluster labels') \n                plt.title(\"The results of \" + str(name) + \" clustering:\")\n                plt.show()\n    return dict_labeling","c7d8666c":"# we apply elbow method to human related sequences\n\nElbowSearch_kMeans(encoded_human_sequences, \n                   min_number_of_clusters = 2, \n                   max_number_of_clusters = 7)","f8078ee5":"# we demonstrate the results of clustering for the kMeans and Birch methods\n\ndict_labeling = Clustering(encoded_human_sequences, number_of_clusters, ['kMeans','Birch'])","8ff5c41a":"# Statictical parameters for the performance of a classifier\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n\ndef scores(y_test, y_predicted):  \n    precision = precision_score(y_test, y_predicted, pos_label = None,\n                                    average = 'weighted')             \n    recall = recall_score(y_test, y_predicted, pos_label = None, average = 'weighted')\n    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n    accuracy = accuracy_score(y_test, y_predicted)\n    print(\"accuracy = %.4f, f1 = %.4f, precision = %.4f, recall = %.4f\" % (accuracy, f1, precision, recall))\n    return accuracy, f1, precision, recall","a50a3fc6":"# Confusion matrix\n\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize = False,\n                          title = 'Confusion Matrix',\n                          cmap = plt.cm.spring):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title, fontsize = 26)\n    #plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize = 20)\n    plt.yticks(tick_marks, classes, fontsize = 20)\n    \n    \n    fmt = '.2f' if normalize else 'd'\n    \n    \n    thresh = cm.max() \/ 2.\n\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment = \"center\", \n                 color = \"white\" if cm[i, j] < thresh else \"black\", fontsize = 40)\n    \n\n    plt.ylabel('True labels', fontsize = 24)\n    plt.xlabel('Predicted labels', fontsize = 24)\n    \n    \n    # this is just a fix for the mpl bug that cuts off top\/bottom of the heatmap matrix\n    # this fix is not needed for kaggle\n    if cwd != '\/kaggle\/working':\n        bottom, top = plt.ylim() # current values for bottom and top\n        bottom += 0.5 # change the bottom\n        top -= 0.5 # change the top\n        plt.ylim(bottom, top) # update the values\n\n    return plt","763b2b88":"# this is our dicrionary of classifiers\n\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nour_dictionary_of_classifiers = {\"SVM\": SVC(probability = True, gamma = 'scale'), \n                                 \"Logistic Regression\": LogisticRegression(C=30.0, class_weight = 'balanced', \n                                                                           solver = 'newton-cg', multi_class = 'multinomial', \n                                                                           n_jobs = -1, random_state = 42),\n                                 \"Decision Tree\": DecisionTreeClassifier(random_state = 42),\n                                 \"Random Forest\": RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 15, \n                                                                         n_jobs= -1, random_state = 42)\n                            }","26b55085":"# Receiver operating characteristic (ROC) curve\n\nfrom sklearn.metrics import roc_curve\n\ndef ROC_curve(xTrain, xTest, yTrain, yTest,\n              list_of_chosen = [\"SVM\"],\n              dictionary_of_classifiers = our_dictionary_of_classifiers):\n    \n    # preparing the figure for plotting the ROC Curves\n    \n    sns.set_style('whitegrid')\n    plt.figure(figsize = (10, 8))\n    plt.plot([0, 1], [0, 1], color = 'blue', linestyle = '--', label = 'Flip a coin')\n   \n    # calculating the ROC Curves\n\n    for name, classifier in dictionary_of_classifiers.items():\n        if name in list_of_chosen:\n            classifier.fit(xTrain, yTrain)\n            # predict_proba gives the probabilities for the target \n            # (0 and 1 in our case) as a list (array). \n            # The number of probabilities for each row is equal \n            # to the number of categories in target variable (2 in our case).\n            probabilities = classifier.predict_proba(xTest)\n            probability_of_ones = probabilities[:,1] \n            # roc_curve returns:\n            # - false positive rates (FP_rates), i.e., \n            # the false positive rate of predictions with score >= thresholds[i]\n            \n            # - true positive rates (TP_rates), i.e., \n            # the true positive rate of predictions with score >= thresholds[i]\n            \n            # - thresholds \n            FP_rates, TP_rates, thresholds = roc_curve(yTest, probability_of_ones)\n            # plotting the ROC Curve to visualize all the methods\n            plt.plot(FP_rates, TP_rates, label = name)\n            \n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize = 14)\n    plt.ylabel('True Positive Rate', fontsize = 14)\n    plt.title('ROC Curve', fontsize = 14)\n    plt.legend(loc = \"lower right\")\n    plt.show()","d6a04e56":"# Box plot after CV-fold crossvalidation\nfrom sklearn.model_selection import cross_validate\n\n# this function returns a dataframe with  'accuracy', 'f1', 'sensitivity', 'specificity' \n# calculated within k-fold cross validation of a list of classifiers\n\n# models = list of classifiers\n# X = list of feature vectors\n# y = list of labels\n# models_names = custom names of the classifiers for the dataframe\n# CV = number of folds in validation\n# number_of_processors = number of processors used for peerforming the cross validation\n\n# if number_of_processors = -1, all processors are used \n# (DISCLAIMER: it may cause a warning ``timeout or by a memory leak'') \n\ndef Crossvalidating(X, y, CV = 5, list_of_chosen = [\"SVM\"], plotting = True,\n                          dictionary_of_classifiers = our_dictionary_of_classifiers,\n                          number_of_processors = 1):\n    \n                  \n    table = pd.DataFrame(index = range(CV*len(list_of_chosen)))\n    table_entries = []\n    y_series = pd.Series(y)\n    \n    for name, classifier in dictionary_of_classifiers.items():\n        if name in list_of_chosen:\n            scoring = {'accuracy','f1','recall','balanced_accuracy'}\n            scores = cross_validate(classifier, X, y_series, cv = CV, n_jobs = number_of_processors,\n                                    scoring = scoring, return_train_score = False)\n            accuracy = scores['test_accuracy']\n            f1 = scores['test_f1']\n            sensitivity = scores['test_recall']\n            balanced_accuracy = scores['test_balanced_accuracy'] \n            # specificity = 2 * balanced_accuracy - sensitivity\n            specificity = []\n            for j in range(0,len(balanced_accuracy)):\n                specificity.append(2*balanced_accuracy[j]-sensitivity[j])\n            for j in range(0,len(balanced_accuracy)):\n                table_entries.append((name, accuracy[j], f1[j], sensitivity[j], specificity[j]))\n                \n    table = pd.DataFrame(table_entries, columns = ['classifier', 'accuracy', 'F1', 'sensitivity', 'specificity'])\n    \n    if plotting == True:\n        df_melted = pd.melt(table,id_vars = ['classifier'], \n                            value_vars = ['accuracy', 'F1', 'sensitivity', 'specificity'], \n                            var_name = 'scores')\n        sns.boxplot(x = 'scores', y = 'value', data = df_melted, hue = 'classifier', palette = \"Set3\")\n        # Put the legend out of the figure\n        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    \n    return table","1510cce1":"def Classifying(xTrain, xTest, yTrain, yTest,\n                list_of_chosen = [\"SVM\"],\n                dictionary_of_classifiers = our_dictionary_of_classifiers, \n                conf_matr = True):\n    for name, classifier in dictionary_of_classifiers.items():\n        if name in list_of_chosen:\n            classifier.fit(xTrain, yTrain)\n            y_predicted = classifier.predict(xTest)  \n\n            print(\"Results for \" + str(name))\n            # report accuracy, f1, precision, recall for the classifier\n            accuracy, f1, precision, recall = scores(yTest, y_predicted)\n            \n            if conf_matr == True:\n                # The confusion matrix for the test data for SVM\n                cm = confusion_matrix(yTest, y_predicted)\n                fig = plt.figure(figsize=(7, 7))\n                plot = plot_confusion_matrix(cm, classes=['Not Infective','Infective'], normalize=False, title='Confusion matrix\\n for ' + str(name))\n                plt.show()","c4e46dd4":"# On random 20% of ALL sequences\n\n# Split the dataset into a training set (80%) and a test set (20%)\nxTrain20, xTest20, yTrain20, yTest20 = train_test_split(encoded_random20, targets_random20, test_size = 0.2, random_state = 42)\n\nclassifiers_we_use = [\"SVM\", \"Decision Tree\"]\nClassifying(xTrain20, xTest20, yTrain20, yTest20, list_of_chosen = classifiers_we_use)","0942ab92":"# On ALL sequences\n\n# Split the dataset into a training set (80%) and a test set (20%)\nxTrain, xTest, yTrain, yTest = train_test_split(encoded_sequences, targets, test_size = 0.2, random_state = 42)\n\nClassifying(xTrain, xTest, yTrain, yTest,[\"SVM\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\"])","4ec5b78d":"# SVM-classifier for muted HKU_1\n\nxTrain_without_HKU1, xTest_without_HKU1, yTrain_without_HKU1, yTest_without_HKU1 = train_test_split(encoded_without_HKU1, \n                                                                                                    targets_without_HKU1, \n                                                                                                    test_size = 0.2, \n                                                                                                    random_state = 42)\nx_Test_HKU1 = xTest_without_HKU1 + encoded_HKU1\ny_Test_HKU1 = yTest_without_HKU1 + targets_HKU1\n\nClassifying(xTrain_without_HKU1, x_Test_HKU1, yTrain_without_HKU1, y_Test_HKU1)","b32ed40c":"# SVM-classifier for TOTALLY muted HKU_1\nxTrain_without_HKU1_total = encoded_without_HKU1\nyTrain_without_HKU1_total = targets_without_HKU1\nx_Test_HKU1_total = encoded_HKU1\ny_Test_HKU1_total = targets_HKU1\n\nClassifying(xTrain_without_HKU1_total, x_Test_HKU1_total, yTrain_without_HKU1_total, y_Test_HKU1_total)","8c84a392":"# SVM-classifier for muted SARS1\n\nxTrain_without_SARS1, xTest_without_SARS1, yTrain_without_SARS1, yTest_without_SARS1 = train_test_split(encoded_without_SARS1, \n                                                                                                        targets_without_SARS1, \n                                                                                                        test_size = 0.2,\n                                                                                                        random_state = 42)\nx_Test_SARS1 = xTest_without_SARS1 + encoded_SARS1\ny_Test_SARS1 = yTest_without_SARS1 + targets_SARS1  \n\nClassifying(xTrain_without_SARS1, x_Test_SARS1, yTrain_without_SARS1, y_Test_SARS1)","d06bc95b":"# SVM-classifier for TOTALLY muted SARS1\nxTrain_without_SARS1_total = encoded_without_SARS1\nyTrain_without_SARS1_total = targets_without_SARS1\nx_Test_SARS1_total = encoded_SARS1\ny_Test_SARS1_total = targets_SARS1\n\nClassifying(xTrain_without_SARS1_total, x_Test_SARS1_total, yTrain_without_SARS1_total, y_Test_SARS1_total)","6722c283":"# SVM-classifier for Balanced Data set\n\nxTrain_Balanced, xTest_Balanced, yTrain_Balanced, yTest_Balanced = train_test_split(balanced_encoded_sequences, \n                                                                                                    balancedtargets, \n                                                                                                    test_size = 0.2, \n                                                                                                    random_state = 42)\n\nClassifying(xTrain_Balanced, xTest_Balanced, yTrain_Balanced, yTest_Balanced)","26c79153":"# SVM-classifier for the mammalian dataset\nxTrain_mammal, xTest_mammal, yTrain_mammal, yTest_mammal = train_test_split(mammal_encoded_sequences, \n                                                                            mammaltargets, \n                                                                            test_size = 0.2, \n                                                                            random_state = 42)\n\nClassifying(xTrain_mammal, xTest_mammal, yTrain_mammal, yTest_mammal)","6828ec1d":"#Classifier for alpha + betacoroanviruses vs others\n\nxTrainAB, xTestAB, yTrainAB, yTestAB = train_test_split(encoded_alpha_beta, alpha_beta_targets, test_size = 0.2, random_state = 42)\n\nclassifiers_we_use = [\"SVM\", \"Logistic Regression\"]\nClassifying(xTrainAB, xTestAB, yTrainAB, yTestAB, list_of_chosen = classifiers_we_use)","ca2d2292":"ROC_curve(xTrain, xTest, yTrain, yTest, list_of_chosen = [\"SVM\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\"])","54142f32":"table = Crossvalidating(xTrain, yTrain, CV = 5, list_of_chosen = [\"SVM\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\"])","816d37a1":"box_plots = sns.boxplot(x = 'classifier', y ='accuracy', data = table, width = 0.8)\nplt.setp(box_plots.get_xticklabels(), rotation = 90)\nbox_plots.set(xlabel = None)","846079d0":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (12,6))  \nf1 = sns.boxplot(x = 'classifier', y = 'accuracy', data = table, ax = ax1, width=0.6, linewidth = 1)\nf1.set(xticklabels=[])\nf1.set(xlabel=None)\nf2 = sns.boxplot(x = 'classifier', y = 'F1', data = table, ax = ax2, width = 0.6, linewidth = 1)\nf2.set(xticklabels=[])\nf2.set(xlabel=None)\nf3 = sns.boxplot(x = 'classifier', y = 'sensitivity', data = table, ax = ax3, width = 0.6, linewidth = 1)\nplt.setp(ax3.get_xticklabels(), rotation = 90)\nf4 = sns.boxplot(x = 'classifier', y = 'specificity', data = table, ax = ax4, width = 0.6, linewidth = 1)\nplt.setp(ax4.get_xticklabels(), rotation = 90)","1e8e3346":"# CLASSIFIERS","edda413d":"> # **Visualization**","fe81f731":"### Muting Human_coronavirus_HKU1","420c54e9":"# alpha + betacoronavirus data sets","29947850":"# Receiver operating characteristic (ROC) curve","a4476d8e":"# Encoding","c0f19c7b":" ### Muting SARS1","fdb83842":"# Box plots","290fc311":" ### Balanced Avian vs Human","f9d36c21":"**Oh, dear!**","08ea64f5":"taken from [Zhang Lab](https:\/\/zhanglab.ccmb.med.umich.edu\/FASTA\/)\n\nFASTA format is a text-based format for representing either nucleotide sequences or peptide sequences, in which base pairs or amino acids are represented using single-letter codes. A sequence in FASTA format begins with a single-line description, followed by lines of sequence data. The description line is distinguished from the sequence data by a greater-than (\">\") symbol in the first column. It is recommended that all lines of text be shorter than 80 characters in length.\nAn example sequence in FASTA format is:\n\n>S|spike_protein|MG996765|AWV66922.1|A0A3G1RFS9|P138\/72|NA|1972|Horse|Switzerland|NA|Equine_torovirus\nMFLCFCAATVLCFWINSGGADVVPNGTLIFSEPVPYPFSLDVLRSFSQHVVLRNKRAVTTISWSYSYQIT\nTSSLSVNSWYVTFTAPLGWNYYTGQSFGTVLNQNAMMRASQSTFTYDVISYVGQRPNLDCQVNSLVNGGL\nDGWYSTVRVDNCFNAPCHVGGRPGCSIGIPYMSNGVCTRVLSTTQSPGLQYEIYSGQQFAVYQITPYTQY\n\n\nSequences are expected to be represented in the standard IUB\/IUPAC amino acid and nucleic acid codes, with these exceptions:\nlower-case letters are accepted and are mapped into upper-case;\na single hyphen or dash can be used to represent a gap of indeterminate length;\nin amino acid sequences, U and * are acceptable letters (see below).\nany numerical digits in the query sequence should either be removed or replaced by appropriate letter codes (e.g., N for unknown nucleic acid residue or X for unknown amino acid residue).\nThe nucleic acid codes are:\n\n        A --> adenosine           M --> A C (amino)\n        C --> cytidine            S --> G C (strong)\n        G --> guanine             W --> A T (weak)\n        T --> thymidine           B --> G T C\n        U --> uridine             D --> G A T\n        R --> G A (purine)        H --> A C T\n        Y --> T C (pyrimidine)    V --> G C A\n        K --> G T (keto)          N --> A G C T (any)\n                                  -  gap of indeterminate length\nThe accepted amino acid codes are:\n\n    A ALA alanine                         P PRO proline\n    B ASX aspartate or asparagine         Q GLN glutamine\n    C CYS cystine                         R ARG arginine\n    D ASP aspartate                       S SER serine\n    E GLU glutamate                       T THR threonine\n    F PHE phenylalanine                   U     selenocysteine\n    G GLY glycine                         V VAL valine\n    H HIS histidine                       W TRP tryptophan\n    I ILE isoleucine                      Y TYR tyrosine\n    K LYS lysine                          Z GLX glutamate or glutamine\n    L LEU leucine                         X     any\n    M MET methionine                      *     translation stop\n    N ASN asparagine                      -     gap of indeterminate length","12574c99":"There are only 7 known to be able to infect humans. \n\nThe virus classification is gives as Genus -> Subgenus -> Species -> Subspecies -> Strain.\nThe names that are in our database are hilighted **in bold**.\n\n\n* 229E (a.k.a. HCoV-229E, Human coronavirus 229E) belongs to  Alphacoronavirus -> Duvinacovirus -> **Human coronavirus 229E** -> NA -> NA\n* NL63 (a.k.a. HCoV-NL63, Human coronavirus NL63) belongs to  Alphacoronavirus -> Setracovirus -> **Human coronavirus NL63** -> NA -> NA\n* OC43 (a.k.a. HCoV-OC43, Human coronavirus OC43) belongs to  Betacoronavirus -> NA -> **Betacoronavirus 1** -> Human coronavirus OC43 -> NA\n* HKU1 (a.k.a. HCoV-HKU1, **Human coronavirus HKU1**) belongs to  Betacoronavirus -> Embecovirus -> **Human coronavirus HKU1** -> NA -> NA\n* MERS-CoV (a.k.a. EMC\/2012, HCoV-EMC\/2012, Middle East respiratory syndrome-related coronavirus)\n   belongs to  Betacoronavirus -> Merbecovirus -> **Middle East respiratory syndrome-related coronavirus** -> NA -> NA\n* SARS-CoV (a.k.a. SARS-CoV, SARS-CoV-1, Severe acute respiratory syndrome coronavirus)\n   belongs to  Betacoronavirus -> NA-> **Severe acute respiratory syndrome-related coronavirus** -> NA -> Severe acute respiratory syndrome coronavirus\n* **SARS-CoV-2** (a.k.a. 2019-nCoV, Severe acute respiratory syndrome coronavirus 2)\n   belongs to  Betacoronavirus -> Sarbecovirus -> Severe acute respiratory syndrome-related coronavirus -> NA -> Severe acute respiratory syndrome coronavirus 2\n                  \n                  \n\n","3acfeaab":"### Random 20% of all sequences","6555bdb1":"#### Dictionary of classifiers","4650cb8c":"Looks like all NAs are the Middle_east beast :-)","7819d6d6":"# **Getting familiar with the data**","3875b8ee":" ### Mammals","810e424c":"# CLUSTERING","15489a18":"# How we assess the performance","ccbf3ec0":"Everything (accuracy, f1, precision, recall) is close to 1 here, meaning: we are experiencing overfitting","ce23c891":"### Human related","6e8981fe":"# **Reading the data**"}}