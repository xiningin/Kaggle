{"cell_type":{"77236ec6":"code","8c97172a":"code","1de5c0ce":"code","7b0b409b":"code","32a365dd":"code","f5f4682d":"code","77de2450":"code","f04efc3f":"code","d82ebb35":"code","a568937c":"code","25d73663":"code","b5c306fd":"code","601b64aa":"code","eccbca54":"code","b15217d8":"code","e2ec825f":"code","fa101333":"code","136746e0":"code","3b2ff099":"code","96d01607":"code","67655d8e":"code","a5826e6b":"code","9e3a58f0":"code","61b48043":"code","5947832e":"code","f4625ab8":"code","c07927ae":"code","46d62a98":"code","33e9e319":"code","62f44fd6":"code","16482420":"code","1c759138":"code","abf128fa":"code","c49b7222":"code","34e0a738":"code","6464c988":"code","06597d8c":"code","325efedc":"code","3b8777f2":"code","be5e67b2":"code","e3f88c4d":"code","add28bf2":"code","71ab3f8a":"code","51f7ac51":"code","933346c5":"code","13835aa7":"code","b1bfdf1a":"code","c602679e":"code","292a98c4":"code","7cfb8800":"markdown","b08eefec":"markdown","bbe5d5e0":"markdown","88a8a0f7":"markdown","8191b89f":"markdown","44679cbb":"markdown","6b419a8e":"markdown"},"source":{"77236ec6":"# import python standard library\nimport time\n\n# import data manipulation library\nimport numpy as np\nimport pandas as pd\n\n# import data visualization library\nimport matplotlib.pyplot as plt\n\n# import tensorflow model class\nimport tensorflow as tf\n\n# import sklearn model selection\nfrom sklearn.model_selection import train_test_split","8c97172a":"# acquiring training and testing data\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","1de5c0ce":"# visualize head of the training data\ndf_train.head(n=5)","7b0b409b":"# visualize tail of the testing data\ndf_test.tail(n=5)","32a365dd":"# combine training and testing dataframe\ndf_train['datatype'], df_test['datatype'] = 'training', 'testing'\ndf_train['imageid'] = df_train.index + 1\ndf_test.insert(0, 'label', np.nan)\ndf_test['imageid'] = df_test.index + 1\ndf_data = pd.concat([df_train, df_test], ignore_index=True)","f5f4682d":"# data dimensions\nimg_size = 28\nnum_channels = 1\nnum_classes = 10\n\n# flat dimensions\nimg_size_flat = img_size * img_size * num_channels","77de2450":"def imageplot(image: list, label: list, size: tuple, figsize: tuple = (4, 3), ncols: int = 5, nrows: int = None) -> plt.figure:\n    \"\"\" Return an image plot applied for an image data in grayscale picture (m, n) format, RGB picture (m, n, 3) format and RGBA picture (m, n, 4) format.\n    \n    Args:\n        image (list): The image data.\n        label (list): The label of an image data.\n        size (tuple): The tuple of an image size.\n        figsize (tuple): The matplotlib figure size width and height in inches. Default to (4, 3).\n        ncols (int): The number of columns for axis in the figure. Default to 5.\n        nrows (int): The number of rows for axis in the figure. Default to None.\n    \n    Returns:\n        plt.figure: The plot figure.\n    \"\"\"\n    \n    if nrows is None: nrows = (len(label) - 1) \/\/ ncols + 1\n    \n    fig, axes = plt.subplots(figsize=(figsize[0]*ncols , figsize[1]*nrows), ncols=ncols, nrows=nrows)\n    axes = axes.flatten()\n    _ = [axes[i].imshow(image[i].reshape(size), interpolation='spline16') for i in range(len(label))]\n    return fig","f04efc3f":"# describe training and testing data\ndf_data.describe(include='all')","d82ebb35":"# feature exploration: number 1\nnumber = 1\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","a568937c":"# feature exploration: number 2\nnumber = 2\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","25d73663":"# feature exploration: number 3\nnumber = 3\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","b5c306fd":"# feature exploration: number 4\nnumber = 4\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","601b64aa":"# feature exploration: number 5\nnumber = 5\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","eccbca54":"# feature exploration: number 6\nnumber = 6\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","b15217d8":"# feature exploration: number 7\nnumber = 7\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","e2ec825f":"# feature exploration: number 8\nnumber = 8\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","fa101333":"# feature exploration: number 9\nnumber = 9\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","136746e0":"# feature exploration: number 0\nnumber = 0\npixel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), df_data.columns[1:-2]].values\nlabel = df_data.loc[(df_data['datatype'] == 'training') & (df_data['label'] == number), 'label'].values\n_ = imageplot(pixel[:15], label[:15], (img_size, img_size))","3b2ff099":"# feature extraction: normalize pixel between 0 to 1\ncol_pixels = df_data.columns[1:-2]\ndf_data[col_pixels] = df_data[col_pixels] \/ 255.0","96d01607":"# feature extraction: label\ndf_data['label'] = df_data['label'].fillna(-1).astype(int)","67655d8e":"# convert category codes for data dataframe\ndf_data = pd.get_dummies(df_data, columns=['datatype', 'label'], drop_first=True)","a5826e6b":"# describe data dataframe\ndf_data.describe(include='all')","9e3a58f0":"# verify dtypes object\ndf_data.info()","61b48043":"# select all features\nx = df_data[df_data['datatype_training'] == 1].drop(['imageid', 'datatype_training', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_5', 'label_6', 'label_7', 'label_8', 'label_9'], axis=1)\ny = df_data.loc[df_data['datatype_training'] == 1, ['label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_5', 'label_6', 'label_7', 'label_8', 'label_9']]","5947832e":"# perform train-test (validate) split\nx_train, x_validate, y_train, y_validate = train_test_split(x, y, test_size=0.25, random_state=58)","f4625ab8":"# weight variable\ndef weight_variable(shape, name = None, stddev = 0.1):\n    return tf.Variable(tf.truncated_normal(shape, stddev=stddev, seed=58), name=name)","c07927ae":"# bias variable\ndef bias_variable(shape, name = None, value = 0.1):\n    return tf.Variable(tf.constant(value, shape=shape), name=name)","46d62a98":"# conv2d layer\ndef conv2d_layer(x, weight, bias, padding = 'SAME', strides = [1, 1, 1, 1]):\n    return tf.nn.conv2d(x, weight, strides, padding) + bias","33e9e319":"# fully connected layer\ndef fc_layer(x, weight, bias):\n    return tf.matmul(x, weight) + bias","62f44fd6":"# flatten layer\ndef flatten_layer(x):\n    num_features = x.get_shape()[1:4].num_elements()\n    return tf.reshape(x, [-1, num_features]), num_features","16482420":"# max pool layer\ndef max_pool_layer(x, ksize = [1, 2, 2, 1], padding = 'SAME', strides = [1, 2, 2, 1]):\n    return tf.nn.max_pool(x, ksize, strides, padding)","1c759138":"# relu layer\ndef relu_layer(x):\n    return tf.nn.relu(x)","abf128fa":"# reset default graph\ntf.reset_default_graph()","c49b7222":"# placeholder variables used for inputting data to the graph\nx_flat = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x_flat')\nx_image = tf.reshape(x_flat, [-1, img_size, img_size, num_channels])\ny_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\ny_true_class = tf.argmax(y_true, axis=1)","34e0a738":"# convolution + relu + max pool layer 1\nweight_conv1 = weight_variable([5, 5, num_channels, 16], name='weight_conv1')\nbias_conv1 = bias_variable([16], name='bias_conv1')\nlayer_conv1 = max_pool_layer(relu_layer(conv2d_layer(x_image, weight_conv1, bias_conv1)))","6464c988":"# convolution + relu + max pool layer 2\nweight_conv2 = weight_variable([5, 5, 16, 64], name='weight_conv2')\nbias_conv2 = bias_variable([64], name='bias_conv2')\nlayer_conv2 = max_pool_layer(relu_layer(conv2d_layer(layer_conv1, weight_conv2, bias_conv2)))","06597d8c":"# flatten layer\nlayer_flat, num_features = flatten_layer(layer_conv2)","325efedc":"# fully connected + relu layer 1\nweight_fc1 = weight_variable([num_features, 128], name='weight_fc1')\nbias_fc1 = bias_variable([128], name='bias_fc1')\nlayer_fc1 = relu_layer(fc_layer(layer_flat, weight_fc1, bias_fc1))","3b8777f2":"# fully connected + relu layer 2\nweight_fc2 = weight_variable([128, num_classes], name='weight_fc2')\nbias_fc2 = bias_variable([num_classes], name='bias_fc2')\nlayer_fc2 = relu_layer(fc_layer(layer_fc1, weight_fc2, bias_fc2))","be5e67b2":"# predicted class label\ny_pred_proba = tf.nn.softmax(layer_fc2)\ny_pred_class = tf.argmax(y_pred_proba, axis=1)","e3f88c4d":"# cost function\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=layer_fc2))","add28bf2":"# optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)","71ab3f8a":"# performance metrics\naccuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_class, y_true_class), tf.float32))","51f7ac51":"# counter for total number of iterations performed so far\ntotal_epoch = 0\nrndobj = np.random.RandomState(seed=58)\n\ndef optimize(num_epoch, printcost = True, printfrequency = 1000, train_batch_size = 256, validate_batch_size = 256):\n    global total_epoch\n    \n    # record start time\n    timestart = time.time()\n    \n    for i in range(total_epoch, total_epoch + num_epoch):\n        # specify batch size\n        train_index = rndobj.choice(x_train.index, replace=True, size=train_batch_size)\n        validate_index = rndobj.choice(x_validate.index, replace=True, size=validate_batch_size)\n        \n        # tensorflow model fit\n        feed_dict_train = {x_flat: x_train.loc[train_index], y_true: y_train.loc[train_index]}\n        feed_dict_validate = {x_flat: x_validate.loc[validate_index], y_true: y_validate.loc[validate_index]}\n        session.run(optimizer, feed_dict=feed_dict_train)\n        \n        # print status every 1000 iterations\n        if printcost and i % printfrequency == 0: print('epoch: %d, training accuracy: %f, testing accuracy: %f' %(i + 1, session.run(accuracy, feed_dict=feed_dict_train), session.run(accuracy, feed_dict=feed_dict_validate)))\n    \n    # update the total epoch\n    total_epoch += num_epoch\n    \n    # record end time\n    timeend = time.time()\n    \n    # time elapsed\n    timeelapsed = timeend - timestart\n    \n    # print the time elapsed\n    print(\"elapsed time: %f\" %timeelapsed)","933346c5":"# create tensorflow session\nsession = tf.Session()\nsession.run(tf.global_variables_initializer())","13835aa7":"# tensorflow model fit 1 epoch\noptimize(1)","b1bfdf1a":"# tensorflow model fit 10000 epoch\noptimize(10000, printfrequency=1000)","c602679e":"# prepare testing data and compute the observed value\nx_test = df_data[df_data['datatype_training'] == 0].drop(['imageid', 'datatype_training', 'label_0', 'label_1', 'label_2', 'label_3', 'label_4', 'label_5', 'label_6', 'label_7', 'label_8', 'label_9'], axis=1)\ny_test = pd.DataFrame(y_pred_class.eval(session=session, feed_dict={x_flat: x_test}), columns=['Label'], index=df_data.loc[df_data['datatype_training'] == 0, 'imageid'])","292a98c4":"# submit the results\nout = pd.DataFrame({'ImageId': y_test.index, 'Label': y_test['Label']})\nout.to_csv('submission.csv', index=False)","7cfb8800":"After extracting all features, it is required to convert category features to numerics features, a format suitable to feed into our Machine Learning models.","b08eefec":"> **Acquiring training and testing data**\n\nWe start by acquiring the training and testing datasets into Pandas DataFrames.","bbe5d5e0":"> **Supply or submit the results**\n\nOur submission to the competition site Kaggle is ready. Any suggestions to improve our score are welcome.","88a8a0f7":"> **Feature exploration, engineering and cleansing**\n\nHere we generate descriptive statistics that summarize the central tendency, dispersion and shape of a dataset\u2019s distribution together with exploring some data.\n","8191b89f":"> **Problem overview**\n\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\nIn this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We\u2019ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.","44679cbb":"> **Model, predict and solve the problem**\n\nNow, it is time to feed the features to Machine Learning models.","6b419a8e":"A TensorFlow graph consists of the following parts which will be detailed below:\n* Placeholder variables used for inputting data to the graph.\n* Variables that are going to be optimized so as to make the convolutional network perform better.\n* The mathematical formulas for the convolutional network.\n* A loss measure that can be used to guide the optimization of the variables.\n* An optimization method which updates the variables."}}