{"cell_type":{"3e92ea1b":"code","83524c65":"code","e6d6920b":"code","70817d90":"code","3ce2acbc":"code","95f448a2":"code","cd118e78":"code","4fd70c63":"code","a1dd2b0d":"code","4de9c3e7":"code","f325375b":"code","e86208fe":"code","e39c9553":"code","ace08fc4":"code","287ffd39":"code","1c8e4cf9":"code","8862b735":"code","57ffe4d3":"code","791013c1":"code","77691b37":"code","3e397189":"code","d4629282":"code","abf5828d":"code","8b8186fc":"code","e6934d4a":"code","f3963a57":"code","c89641e1":"code","cfd26264":"code","5aa700df":"code","4d624725":"code","c7ecb0db":"code","532db4d2":"code","4862558e":"code","5690f96f":"code","ee5ae178":"code","47543bb2":"code","d612a6d3":"code","100dc3a7":"code","9f56c42f":"code","4dd903b5":"markdown","e8a8ebf3":"markdown","a1f3d412":"markdown","a6a87daa":"markdown","a827e1af":"markdown","68d8e13c":"markdown","5997c72a":"markdown","89c26430":"markdown","24c0e435":"markdown","915fc2e6":"markdown","3e81933e":"markdown"},"source":{"3e92ea1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","83524c65":"# Read csv files\ndf=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf.head()","e6d6920b":"# Read csv files\ndf_test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_test.head()","70817d90":"sns.countplot(data=df,x='Pclass',hue='Survived',palette=['red','green']);","3ce2acbc":"# Probability of survival given Pclass value\np_c1=df.query('Survived==1 & Pclass==1').shape[0]\/df.query('Pclass==1').shape[0]\np_c2=df.query('Survived==1 & Pclass==2').shape[0]\/df.query('Pclass==2').shape[0]\np_c3=df.query('Survived==1 & Pclass==3').shape[0]\/df.query('Pclass==3').shape[0]\np_c1,p_c2,p_c3","95f448a2":"sns.countplot(data=df,x='Sex',hue='Survived',palette=['red','green']);","cd118e78":"# Probability of survival given Sex value\np_m=df.query('Survived==1 & Sex==\"male\"').shape[0]\/df.query('Sex==\"male\"').shape[0]\np_f=df.query('Survived==1 & Sex==\"female\"').shape[0]\/df.query('Sex==\"female\"').shape[0]\np_m,p_f","4fd70c63":"sns.boxplot(data=df,y='Age',x='Survived',palette=['red','green']); \nplt.grid()\n# Age distribution seams normal for survival propability","a1dd2b0d":"# Number of Siblings\/Spouses Aboard\n# each of two or more children or offspring having one or both parents in common; a brother or sister.\nsns.boxplot(data=df,y='SibSp',x='Survived',palette=['red','green']);\nplt.grid()\n# SibSp distribution seams normal for survival propability\n# However NO survivals for SibSp above 4","4de9c3e7":"# Number of Parents\/Children Aboard\nsns.countplot(data=df,x='Parch',hue='Survived',palette=['red','green']);","f325375b":"sns.boxplot(data=df,y='Fare',x='Survived',palette=['red','green']);\nplt.grid()","e86208fe":"# the money paid for a journey on public transport.\n\nplt.hist(df.query('Survived==1').Fare,bins=50,color='green',alpha=.5,label='Survived');\nplt.hist(df.query('Survived==0').Fare,bins=50,color='red',alpha=.5,label='Not Survived');\nplt.xlabel('fare');\nplt.ylabel('count');\n\nplt.legend();\nplt.xlim(0,200);","e39c9553":"# Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\nsns.countplot(data=df,x='Embarked',hue='Survived',palette=['red','green']);","ace08fc4":"Data=pd.DataFrame({},)\nData['Sex']=['male','female']\nData['survived']=[df.query('Survived==1 & Sex==\"male\"').shape[0]\/df.shape[0],\n                 df.query('Survived==1 & Sex==\"female\"').shape[0]\/df.shape[0]]\nData['not_survived']=[df.query('Survived==0 & Sex==\"male\"').shape[0]\/df.shape[0],\n                 df.query('Survived==0 & Sex==\"female\"').shape[0]\/df.shape[0]]\n\nData","287ffd39":"# probalibity of survival given it is male. Same as calculated above.\n# Calculated by Conidtional probability from above table\np_male_and_survived=Data.query('Sex==\"male\"')['survived'].sum()\np_male=Data.query('Sex==\"male\"')['survived'].sum()+Data.query('Sex==\"male\"')['not_survived'].sum()\np_male_and_survived\/p_male     # P(B survival \/ A Male) = P (A and B Male and suvival) \/ P(A Male)","1c8e4cf9":"# probalibity of survival given it is male. Same as calculated above.\n# Calculated by Conidtional probability from df\np_male_and_survived=df.query('Survived==1 & Sex==\"male\"').shape[0]\/df.shape[0]\np_male=df.query('Sex==\"male\"').shape[0]\/df.shape[0]\np_male_and_survived\/p_male     # P(B survival \/ A Male) = P (A and B Male and suvival) \/ P(A Male)","8862b735":"# probalibity of survival given it is male. Same as calculated above.\n# Calculated direct from the df\ndf.query('Survived==1 & Sex==\"male\"').shape[0]\/df.query('Sex==\"male\"').shape[0]","57ffe4d3":"# AS configured Pclass==1 inhanced the suvival of male in this Pclass\ndf.query('Survived==1 & Sex==\"male\" & Pclass==1').shape[0]\/df.query('Sex==\"male\" & Pclass==1').shape[0]","791013c1":"# Clean data to be ready for make comb case columns for conditional probability\ndf_clean=df.dropna(subset=['Embarked'])\ndf_clean.info()","77691b37":"#Make combination cases\ndf_clean=pd.read_csv('\/kaggle\/input\/titanic\/train.csv').dropna(subset=['Embarked'])\ndf_clean['comb']=df_clean['Pclass'].astype(str)+df_clean['Sex']+df_clean['SibSp'].astype(str\n          )+df_clean['Parch'].astype(str)+df_clean['Embarked']\ndf_clean.head()","3e397189":"# Make combination cases for input data and check probability to survive in each case.\nprobability=pd.DataFrame({},)\nsurv_prob=[]\nfor i in df_clean.comb.unique():\n    surv_prob.append(df_clean.query('Survived==1 & comb==@i').shape[0]\/df_clean.query('comb==@i').shape[0])\n    \nprobability['comb']=df_clean.comb.unique()\nprobability['surv_prob']=surv_prob\nprobability.head(2)","d4629282":"print('We have {} pairs of [ Pclass -Sex - SibSp - Parch - Embarked ] comb and surv_prob that will be used for below calcuations'.format(probability.shape[0]))","abf5828d":"# Create new_df with surv_prob\nnew=pd.DataFrame({},)\ndf_copy=df_clean.copy()\n\ndf_copy['surv_prob']=np.ones(df_copy.shape[0])   # ADD new column surv_prob\n\nfor i in range(probability.shape[0]):\n    text=probability.comb[i]\n    value=probability.surv_prob[i]\n    data=df_copy.query('comb==@text')\n    data.loc[:]['surv_prob']=value\n    new=new.append(data)\n    \nnew_df=new.sort_values(by='PassengerId')","8b8186fc":"# Check train df_clean at given value to select threshold value for Type_1 error < 0.05\n\nvalue=0.4    # change this value at required to start with\nperc2 = 0.9  # expected survival but it is actually NOT ,, Type_1 error\n\n# READ train.csv \ndf_check=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_check=df_check.dropna(subset=['Embarked'])\n\n# MAKE combination cases\ndf_check['comb']=df_check['Pclass'].astype(str)+df_check['Sex']+df_check['SibSp'].astype(str\n          )+df_check['Parch'].astype(str)+df_check['Embarked']\n\n# REFERENCE comb and surv_prob columns\nprob=new_df[['comb','surv_prob']]    \n\n# MERGE df_check with REFERENCE prob\ndf_check=df_check.merge(prob,how='left',on='comb').drop_duplicates(subset=['PassengerId'])\ndf_check['Survived_expect']=np.ones(df_check.shape[0])\n\n# WHILE loop for best match value\n\nwhile perc2 > 0.05:         # Type_1 error threshold\n\n    # Survived_expect column based on probability value\n  \n    ind_ex=df_check.query('surv_prob < @value').index\n    df_check.loc[ind_ex,'Survived_expect']=0               # Set Survived_expect for surv_prob < value = 0\n    #df_check=df_check.reset_index()\n    perc2=df_check.query('Survived==0 & Survived_expect==1').shape[0]\/df_check.query('Survived==0').shape[0]\n    value+=0.05\n\nerror=pd.DataFrame(df_check.groupby('Survived')['Survived_expect'].value_counts()).rename(columns={'Survived_expect':'count'})\nperc1=df_check.query('Survived==0 & Survived_expect==0').shape[0]\/df_check.query('Survived==0').shape[0]\nperc2=df_check.query('Survived==0 & Survived_expect==1').shape[0]\/df_check.query('Survived==0').shape[0]\nperc3=df_check.query('Survived==1 & Survived_expect==1').shape[0]\/df_check.query('Survived==1').shape[0]\nperc4=df_check.query('Survived==1 & Survived_expect==0').shape[0]\/df_check.query('Survived==1').shape[0]\n\nerror['ratio']=[perc1,perc2,perc3,perc4]\n\n#This function colours values.\ndef adding_colour(val):\n    if val < 0.05:\n        color = 'green'\n    else:\n        color = 'black'      \n    return 'color: %s' % color\n\nerror.style.applymap(adding_colour)","e6934d4a":"print('Survived_expect column is based on probability value above {:0.2} from Calculation above that makes Type_1 error < 5 %.'.format(value))\nprint()\nprint('Type_1 error = {:0.2%} with Type_2 error = {:0.2%}.'.format(perc2,perc4))","f3963a57":"# READ train.csv \nnew_df_test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nnew_df_test=new_df_test.dropna(subset=['Embarked'])\n\n# MAKE combination cases\nnew_df_test['comb']=new_df_test['Pclass'].astype(str)+new_df_test['Sex']+new_df_test['SibSp'].astype(str\n          )+new_df_test['Parch'].astype(str)+new_df_test['Embarked']\n\n# REFERENCE comb and surv_prob columns\nprob=new_df[['comb','surv_prob']]    \n\n# MERGE df_check with REFERENCE prob\nnew_df_test=new_df_test.merge(prob,how='left',on='comb').drop_duplicates(subset=['PassengerId'])\nnew_df_test['Survived_expect']=np.ones(new_df_test.shape[0])\n\n# USE value from above cell that makes Type_1 error < 0.05\n# ... Survived_expect column based on probability value\nnew_df_test['Survived_expect']=np.ones(new_df_test.shape[0])\nind_ex=new_df_test.query('surv_prob < @value').index\nnew_df_test.loc[ind_ex,'Survived_expect']=0               # Set Survived_expect for surv_prob < value = 0\nnew_df_test=new_df_test.reset_index().drop(columns=['index','comb'])\nnew_df_test   # df_test with Survived_expect Coulmn","c89641e1":"# This output df is sorted depending on Critical Cases Comes first to arrange Rescue plan.\nnew_df_test.query('Survived_expect==0').sort_values(by='surv_prob')","cfd26264":"My_submission=new_df_test[['PassengerId','Survived_expect']].rename(columns={'Survived_expect':'Survived'})\nMy_submission.to_csv('submission.csv', index=False)","5aa700df":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain.dropna(subset=['Embarked'],inplace=True)\ntrain.info()","4d624725":"print(train.Embarked.value_counts())\nprint(train.Sex.value_counts())","c7ecb0db":"# Convert Categorical data to Numerical for Model \n## ... This trial was manulally, so it will be replaced by automatic one.\ntrain[\"Embarked\"].replace({\"S\":1, \"C\":2, 'Q':3}, inplace=True)\ntrain[\"Sex\"].replace({\"male\":1, \"female\":2}, inplace=True)\n\n# Zero is defined for missing values.\nprint(train.Embarked.value_counts())\nprint(train.Sex.value_counts())","532db4d2":"# Import sklearn\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Target data\ny=train.Survived\nfeatures=['Pclass','Sex','SibSp','Parch','Embarked','Fare']\nX=train[features]\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Specify Model using DecisionTreeRegressor\ntrain_model = DecisionTreeRegressor(random_state=1)\n    ## Fit Model\ntrain_model.fit(train_X, train_y)\n    ## Make validation predictions and calculate mean absolute error\nval_predictions = train_model.predict(val_X)\nrounded_val_predictions = [int(np.round(x)) for x in val_predictions]\nval_mae = mean_absolute_error(rounded_val_predictions, val_y)\nprint(\"Validation MAE for Decision Tree Regressor Model: {:,.0f}\".format(val_mae))\n\n# Specify Model using RandomForestRegressor\nrf_model = RandomForestRegressor(random_state=1)\n    ## Fit Model\nrf_model.fit(train_X, train_y)\n    ## Make validation predictions and calculate mean absolute error\nrf_val_predictions = rf_model.predict(val_X)\nrounded_rf_val_predictions = [int(np.round(x)) for x in rf_val_predictions]\nrf_val_mae = mean_absolute_error(rounded_rf_val_predictions, val_y)\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))","4862558e":"test.info()","5690f96f":"# Choose any of both models as they give the same results\nnew_test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nnew_test.Fare.fillna(value=new_test.Fare.mean(),inplace=True)\n# Convert Categorical data to Numerical for Model\nnew_test[\"Embarked\"].replace({\"S\":1, \"C\":2, 'Q':3}, inplace=True)\nnew_test[\"Sex\"].replace({\"male\":1, \"female\":2}, inplace=True)\n\nX=new_test[features]\n\nrf_test_predictions=rf_model.predict(X)\nSurvived= [int(np.round(x)) for x in rf_test_predictions]\nnew_test['Survived']=Survived\n\nnew_test.head(2)","ee5ae178":"My_submission=new_test[['PassengerId','Survived']]\nMy_submission.to_csv('submission.csv', index=False)","47543bb2":"print('As MAE for [0,1] data, it is always 0. So I used not_equal% for output and val_y to get validation criteria')\nnot_equal=(rounded_val_predictions != val_y).sum()\/val_y.size\nprint(\"not_equal%  for Decision Tree Regressor Model: {:,.0%} of y_val data\".format(not_equal))\nrf_not_equal=(rounded_rf_val_predictions != val_y).sum()\/val_y.size\nprint(\"not_equal%  for  Random Forest Model: {:,.0%} of y_val data\".format(rf_not_equal))","d612a6d3":"# Import sklearn\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Target data\ny=train.Survived\nfeatures=['Pclass','Sex','SibSp','Parch','Embarked','Fare','Age']\nX=train[features]\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Missing values\nfrom sklearn.impute import SimpleImputer\n# Imputation\nimputer = SimpleImputer(strategy='most_frequent')  \nall_X_train = pd.DataFrame(imputer.fit_transform(train_X))\nall_X_valid = pd.DataFrame(imputer.transform(val_X))\n\n# Imputation removed column names; put them back\nall_X_train.columns = train_X.columns\nall_X_valid.columns = val_X.columns\n\n# Specify Model using RandomForestRegressor\nrf_model = RandomForestRegressor(random_state=1)\n    ## Fit Model\nrf_model.fit(all_X_train, train_y)\n    ## Make validation predictions and calculate mean absolute error\nrf_val_predictions = rf_model.predict(all_X_valid)\nrounded_rf_val_predictions = [int(np.round(x)) for x in rf_val_predictions]\nrf_not_equal=(rounded_rf_val_predictions != val_y).sum()\/val_y.size\nprint(\"not_equal%  for  Random Forest Model After adding Age column: {:,.0%} of y_val data\".format(rf_not_equal))","100dc3a7":"# Choose any of both models as they give the same results\nnew_test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nnew_test.Fare.fillna(value=new_test.Fare.mean(),inplace=True)\n# Convert Categorical data to Numerical for Model\nnew_test[\"Embarked\"].replace({\"S\":1, \"C\":2, 'Q':3}, inplace=True)\nnew_test[\"Sex\"].replace({\"male\":1, \"female\":2}, inplace=True)\n\nX=new_test[features]\n# Missing values\n\n# Imputation\nall_X = pd.DataFrame(imputer.transform(X))\n\n# Imputation removed column names; put them back\nall_X.columns = X.columns\n\nrf_test_predictions=rf_model.predict(all_X)\nSurvived= [int(np.round(x)) for x in rf_test_predictions]\nnew_test['Survived']=Survived\n\nnew_test.head(2)","9f56c42f":"My_submission=new_test[['PassengerId','Survived']]\nMy_submission.to_csv('submission.csv', index=False)","4dd903b5":"> **The follwing expectation will use Random Forest Model and use not_equal% as validation criteria.**","e8a8ebf3":"### Both Models are working fine with Mean Absolute Error of zero, which is perfect.","a1f3d412":"## Use of Machine Learning for Expecting Survived status\n\n> **Above calculation depends manily on the Survived probility based on availiable properities. Now, will get more step in machine learning by using a Model.**\n\n> ### Step 1:\n1. **Build up the Model using Available Data.**\n2. **Evaluate the Model**\n\n> ### Step 2:  *Pridect for test data*","a6a87daa":">> ### **YOU can Change the criteria to expect Survived**","a827e1af":"### From data Above:\n* we dropped the two missing values of Embarked and we will work with the rest of data.\n* Cabin column is full of missing values, so all column will be dropped.\n* Name and Ticket columns will not be used, so they will be dropped too.\n* Age column still has missing vlaues, so we will work without it as a trial, and with it imputated data. ","68d8e13c":"> ### Step 2:  *Pridect for test data*","5997c72a":"> ### **GET Exploraty visualization and Claculated Survived probabilty a given properity.**\n","89c26430":"## Update Machine Learning Model for Better Expectation Survived status\n\n-- ***deeper look for using MAE as validation criteria***","24c0e435":"> ### **Conditional probability check**\n* P(B survival \/ A Male) = P (A and B Male and suvival) \/ P(A Male)\n* it is propbability of survival given it is male\n* Repeat for calcuating propbability of survival given it is male and class==1, GENERALIZE the solution.","915fc2e6":"> ## **WE can still use surv_prob as reference to apply RESCUE periority for cases of low surv_prob.**","3e81933e":"## Expecting Survived status\n\n> **As configured from above calculation of conditional probability, the Survived probility based on availiable properities will biased to survived or not survived based on probability of survived based at  a given properity.**\n\n> ### Step 1:\n1. After drawing of properities found [ Pclass - Sex - SibSp - Parch - Embarked ] has biased effect of survived probaility.\n* Make pairs of [ Pclass - Sex - SibSp - Parch - Embarked ] comb and calculate surv_prob vs each unique comb.\n\n> ### Step 2:\n* Check train df_clean at given value to select threshold value of surv_prob to get Type_1 error < 0.05\n\n> ### Step 3:\n* Use omb and calculate surv_prob pairs with threshold value of surv_prob calcualted from above step to Expect Survived status.\n\n> * **Above Steps uses  Type_1 error as [ it is Expected survived while it is not ].**\n> * *AS rescue plan, it is better to assume the worst case scenario.*"}}