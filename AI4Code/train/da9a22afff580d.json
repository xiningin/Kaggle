{"cell_type":{"1b3501f6":"code","c974fbca":"code","b5959223":"code","652ae819":"code","9dae99b8":"code","960e7165":"code","6669e8e7":"code","ddc846f1":"code","884da7ed":"code","4fb12076":"code","df4f1d99":"code","4a5545f5":"code","2176e235":"code","c20cd018":"code","d9f6a469":"code","d9dd6ce8":"code","e38c4f01":"code","caa743c1":"code","1e3da70e":"code","e418a811":"code","38f2a7b5":"code","0cf5a90d":"code","b11b2ae8":"code","540a1323":"code","f7e9a389":"code","71ef971e":"code","7737e420":"code","c3bd2048":"code","3108c9f8":"code","a655607f":"code","e89b65b8":"code","c7e70a2c":"code","f6fc85d1":"code","19200611":"code","912ab08a":"code","c6ee382a":"code","0bbbc89e":"code","19863958":"code","091d5f59":"code","09940307":"code","a7806c83":"code","94d95a2d":"code","e8ff273d":"code","93d0f80f":"code","b3de8c39":"code","3ea6654c":"code","1bca03dd":"code","5c2a3a46":"code","f598c27d":"code","d20eddb6":"code","f312ce4d":"code","bb271c72":"code","5f2e80fc":"code","9c30d102":"code","b4f0a4e9":"code","4f0153d7":"code","8ae0b1c8":"code","d6059476":"code","3f6b2aed":"code","619baf67":"code","4ea84dfd":"code","d1536d3f":"code","161815f3":"code","867b726d":"code","f39e7fb8":"code","529edf21":"code","2315a63e":"code","6e82a5b6":"code","5bb886c6":"code","283c7447":"code","37092d8d":"code","f1e938ff":"markdown","2e828f01":"markdown","63afede0":"markdown","e789a2ac":"markdown","c5f725b4":"markdown"},"source":{"1b3501f6":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","c974fbca":"Architecure_Data = Path(\"..\/input\/image-classification\/images\/images\/architecure\")","b5959223":"Cezanne_Data = Path(\"..\/input\/impressionist-classifier-data\/training\/training\/Cezanne\")","652ae819":"Main_JPG_Path = list(Architecure_Data.glob(r\"*.jpg\"))","9dae99b8":"Cezanne_JPG_Path = list(Cezanne_Data.glob(r\"*.jpg\"))","960e7165":"for Cezanne_IMG in Cezanne_JPG_Path:\n    Main_JPG_Path.append(Cezanne_IMG)","6669e8e7":"Main_JPG_Series = pd.Series(Main_JPG_Path,name=\"JPG\").astype(str)","ddc846f1":"print(Main_JPG_Series.head(-1))","884da7ed":"Main_JPG_Series = Main_JPG_Series.sample(frac=1).reset_index(drop=True)","4fb12076":"print(Main_JPG_Series.head(-1))","df4f1d99":"Cezanne_IMG_Data = pd.Series(list(Cezanne_Data.glob(r\"*.jpg\")),name=\"JPG\").astype(str)","4a5545f5":"Architecure_IMG_Data = pd.Series(list(Architecure_Data.glob(r\"*.jpg\")),name=\"JPG\").astype(str)","2176e235":"Example_Arc_IMG = Architecure_IMG_Data[440]\nExample_Cezanne_IMG = Cezanne_IMG_Data[2]","c20cd018":"Reading_Arc = cv2.imread(Example_Arc_IMG)\nReading_Arc = cv2.resize(Reading_Arc,(180,180))\nReading_Cezanne = cv2.imread(Example_Cezanne_IMG)\nReading_Cezanne = cv2.resize(Reading_Cezanne,(180,180))","d9f6a469":"figure,axis = plt.subplots(1,3,figsize=(12,12))\n\nBlend_IMG = cv2.addWeighted(Reading_Arc,0.8,Reading_Cezanne,0.4,0.5)\n\naxis[0].imshow(Reading_Arc)\naxis[1].imshow(Reading_Cezanne)\naxis[2].imshow(Blend_IMG)","d9dd6ce8":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(Blend_IMG)","e38c4f01":"figure,axis = plt.subplots(1,3,figsize=(12,12))\n\nDiff_IMG = cv2.absdiff(Reading_Arc,Reading_Cezanne,np.zeros((5,5)))\n\naxis[0].imshow(Reading_Arc)\naxis[1].imshow(Reading_Cezanne)\naxis[2].imshow(Diff_IMG)","caa743c1":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(Diff_IMG)","1e3da70e":"figure,axis = plt.subplots(1,3,figsize=(12,12))\n\nDiff_Concat = cv2.absdiff(Diff_IMG,Blend_IMG,np.zeros((5,5)))\n\naxis[0].imshow(Blend_IMG)\naxis[1].imshow(Diff_IMG)\naxis[2].imshow(Diff_Concat)","e418a811":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(Diff_Concat)","38f2a7b5":"figure,axis = plt.subplots(8,8,figsize=(12,12))\n\nlist_diff_img = []\n\nfor i,ax in enumerate(axis.flat):\n    IM_1 = Example_Arc_IMG = Architecure_IMG_Data[i]\n    IM_2 = Example_Cezanne_IMG = Cezanne_IMG_Data[i]\n    Reading_Arc = cv2.imread(IM_1)\n    Reading_Arc = cv2.cvtColor(Reading_Arc,cv2.COLOR_BGR2RGB)\n    Reading_Arc = cv2.resize(Reading_Arc,(180,180))\n    Reading_Cezanne = cv2.imread(IM_2)\n    Reading_Cezanne = cv2.cvtColor(Reading_Cezanne,cv2.COLOR_BGR2RGB)\n    Reading_Cezanne = cv2.resize(Reading_Cezanne,(180,180))\n    Blend_IMG = cv2.addWeighted(Reading_Arc,0.8,Reading_Cezanne,0.3,0.5)\n    Diff_IMG = cv2.absdiff(Reading_Arc,Reading_Cezanne,np.zeros((5,5)))\n    Diff_Concat = cv2.absdiff(Diff_IMG,Blend_IMG,np.zeros((5,5)))\n    \n    list_diff_img.append(Diff_Concat)\n    \n    ax.set_xlabel(Diff_Concat.shape)\n    ax.set_title(\"CONCAT DIFF\")\n    ax.imshow(Diff_Concat)\n    \nplt.tight_layout()\nplt.show()","0cf5a90d":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[4])","b11b2ae8":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[2])","540a1323":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[6])","f7e9a389":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[11])","71ef971e":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[61])","7737e420":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[51])","c3bd2048":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[32])","3108c9f8":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[3])","a655607f":"figure = plt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.imshow(list_diff_img[5])","e89b65b8":"Splitting_Data = Main_JPG_Series[2000:4000]","c7e70a2c":"X_Train = []\n\nfor IMG_main in Splitting_Data:\n    X_IMG = cv2.imread(IMG_main)\n    X_IMG = cv2.cvtColor(X_IMG,cv2.COLOR_BGR2RGB)\n    X_IMG = cv2.resize(X_IMG,(180,180))\n    X_IMG = X_IMG \/ 255.\n    X_Train.append(X_IMG)\n    \nprint(\"IT'S TRANSFORMED\")","f6fc85d1":"print(X_Train[3].shape)","19200611":"figure = plt.figure(figsize=(10,10))\nplt.imshow(X_Train[3])","912ab08a":"figure = plt.figure(figsize=(10,10))\nplt.imshow(X_Train[100])","c6ee382a":"figure = plt.figure(figsize=(10,10))\nplt.imshow(X_Train[1000])","0bbbc89e":"X_Train = np.asarray(X_Train)\nX_Train = X_Train.reshape(-1,180,180,3)","19863958":"print(X_Train.shape)","091d5f59":"Generator_Input = keras.Input(shape=(180,))\n\nx = layers.Dense(128*90*90)(Generator_Input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((90,90,128))(x)\n\nx = layers.Conv2D(256,4,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2DTranspose(256,4,padding=\"same\",strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(256,4,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256,3,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256,3,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\n\nx = layers.Conv2D(3,7,padding=\"same\",activation=\"tanh\")(x)","09940307":"Generator = keras.models.Model(Generator_Input,x)","a7806c83":"print(Generator.summary())","94d95a2d":"Discriminator_Input = layers.Input(shape=(180,180,3))\n\nx = layers.Conv2D(128,3)(Discriminator_Input)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128,3,strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Flatten()(x)\nx = layers.Dense(1,activation=\"sigmoid\")(x)\n\nDiscriminator = keras.models.Model(Discriminator_Input,x)","e8ff273d":"print(Discriminator.summary())","93d0f80f":"Discriminator.compile(optimizer=RMSprop(lr=0.0008,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","b3de8c39":"Discriminator.trainable = False","3ea6654c":"DCGAN_Input = keras.Input(shape=(180,))\nDCGAN_Output = Discriminator(Generator(DCGAN_Input))","1bca03dd":"DCGAN_Model = keras.models.Model(DCGAN_Input,DCGAN_Output)","5c2a3a46":"DCGAN_Model.compile(optimizer=RMSprop(lr=0.0001,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","f598c27d":"print(DCGAN_Model.summary())","d20eddb6":"os.mkdir(\"new_creation\")\nos.mkdir(\"old_\u0131mg\")","f312ce4d":"start_period = 0\nbatch_size = 12\ndim_size = 180\niterations = 1000\n\nCombinated_IMG_List = []","bb271c72":"for step in range(iterations):\n    random_noising = np.random.normal(size=(batch_size,dim_size))\n    Generator_Images = Generator.predict(random_noising)\n    \n    stop = start_period + batch_size\n    \n    Real_IMG = X_Train[start_period:stop]\n    \n    Combinated_IMG = np.concatenate([Generator_Images,Real_IMG])\n    \n    labels = np.concatenate([np.ones((batch_size,1)),np.zeros((batch_size,1))])\n    labels = labels + 0.05 * np.random.random(labels.shape)\n    \n    Discriminator_LS = Discriminator.train_on_batch(Combinated_IMG,labels)\n    \n    random_noising = np.random.normal(size=(batch_size,dim_size))\n    \n    Misleading_IMG = np.zeros((batch_size,1))\n    \n    Adversarial_LS = DCGAN_Model.train_on_batch(random_noising,Misleading_IMG)\n    \n    start_period = start_period + batch_size\n    \n    if start_period > len(X_Train) - batch_size:\n        start_period = 0\n        \n    if step % 10 == 0:\n        \n        DCGAN_Model.save_weights(\"DCGAN_Model_Weights.h5\")\n        \n        print(\"DISCRIMINATOR LOSS: \", Discriminator_LS)\n        print(\"ADVERSARIAL LOSS: \", Adversarial_LS)\n        \n        Combinated_IMG_List.append(Combinated_IMG)\n        \n        Img_X_X = image.array_to_img(Generator_Images[0] * 255., scale=False)\n        Img_X_X.save(os.path.join(\".\/new_creation\",\"FAKE\" + str(step)+\".png\"))\n        \n        Img_X_X = image.array_to_img(Real_IMG[0] * 255.,scale=False)\n        Img_X_X.save(os.path.join(\".\/old_\u0131mg\",\"REAL\"+str(step)+\".png\"))","5f2e80fc":"Export_Out = Path(\".\/new_creation\")\nList_Output = list(Export_Out.glob(r\"*.png\"))\nList_Output_Series = pd.Series(List_Output,name=\"PNG\").astype(str)","9c30d102":"Predict_Noise = tf.random.normal(shape=[30,dim_size])","b4f0a4e9":"plt.imshow(Predict_Noise,cmap=\"binary\")","4f0153d7":"Gen_Predict_N = Generator(Predict_Noise)","8ae0b1c8":"figure, axes = plt.subplots(nrows=5,ncols=6,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMG_Random = Gen_Predict_N[i]\n    ax.imshow(IMG_Random)\n    ax.set_xlabel(Gen_Predict_N[i].shape)\nplt.tight_layout()\nplt.show()","d6059476":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Gen_Predict_N[7])\nplt.show()","3f6b2aed":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Gen_Predict_N[1])\nplt.show()","619baf67":"figure = plt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.imshow(Gen_Predict_N[22])\nplt.show()","4ea84dfd":"figure, axes = plt.subplots(nrows=5,ncols=5,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    List_Gen_Image = cv2.imread(List_Output_Series[i])\n    ax.imshow(List_Gen_Image)\n    ax.set_xlabel(List_Gen_Image.shape)\n    ax.set_ylabel(List_Gen_Image.size)\nplt.tight_layout()\nplt.show()","d1536d3f":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[22])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","161815f3":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[3])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","867b726d":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[4])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","f39e7fb8":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[44])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","529edf21":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[55])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","2315a63e":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[1])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","6e82a5b6":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[28])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","5bb886c6":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[80])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","283c7447":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[90])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","37092d8d":"figure = plt.figure(figsize=(10,10))\nList_Gen_Image = cv2.imread(List_Output_Series[99])\nplt.axis(\"off\")\nplt.imshow(List_Gen_Image)\nplt.show()","f1e938ff":"# PACKAGES AND LIBRARIES","2e828f01":"# PATH & LABEL & TRANSFORMATION","63afede0":"# DATA PROCESS","e789a2ac":"# DC-GAN","c5f725b4":"# VISUALIZATION"}}