{"cell_type":{"8579fee4":"code","dba48d7b":"code","0015c8cc":"code","6ff9a996":"code","ea5dfdc5":"code","c1fa66b6":"code","910ac294":"code","01c04a9d":"code","4d59e746":"code","aa6dde29":"code","ebe3667b":"code","3d8e7e80":"code","c807af2f":"code","71cdd651":"code","3e5a6743":"code","ea42a04f":"code","c0146a09":"code","804b7ca4":"code","180ab860":"code","8b0f8571":"code","641f7141":"code","8496a5c8":"code","79b8373b":"code","adaf5316":"code","4c59c265":"code","f2ccc852":"code","6c8d1c21":"code","f09780ec":"code","99aeead1":"code","3a548185":"code","80555324":"markdown","7e526a12":"markdown","4f0ffc00":"markdown","9f1b2021":"markdown","198c49e7":"markdown","12d0fb6f":"markdown","a86c8e2d":"markdown","d828229c":"markdown","a83c4845":"markdown","562117c6":"markdown","070e7c34":"markdown","a3cc3b8f":"markdown","6baf5632":"markdown","4a101780":"markdown","9d7ecd9f":"markdown","eaf8e83b":"markdown","3165dda4":"markdown","f4f17a9a":"markdown","a6f5cd4b":"markdown","20b1a1e6":"markdown","6b2fea88":"markdown","d6f4b2bc":"markdown","05272c08":"markdown","51d60ca1":"markdown","a311ff89":"markdown"},"source":{"8579fee4":"import pandas as pd\nimport numpy as np\nimport os\n\nfrom IPython.display import Markdown as md\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.graph_objects as go\n\nfrom sklearn import model_selection","dba48d7b":"DATA_DIR = r\"..\/input\/av-healthcare-analytics-ii\/healthcare\/\"\n\ntrain_df = pd.read_csv(os.path.join(DATA_DIR, \"train_data.csv\"))\ntest_df = pd.read_csv(os.path.join(DATA_DIR, \"test_data.csv\"))\n\nfeatures_desc_df = pd.read_csv(os.path.join(DATA_DIR, \"train_data_dictionary.csv\"))\n\n## add new column\ntrain_df.loc[:,'dataset'] = 'train'\ntest_df.loc[:,'dataset'] = 'test'\n\nfeatures_desc_df.loc[features_desc_df.shape[0]] = [\"dataset\", \"Indicates the data belongs to train set or test set\"]\ndf = pd.concat([train_df, test_df]) ","0015c8cc":"md(\"<h4>Dataset basic summary:<\/h4><br>The dataset contains <strong>{}<\/strong> features and <strong>{}<\/strong> samples. <br><font size='-1' color='red'> Note: It includes both train and test set<\/font>\".format(df.shape[1], df.shape[0]))","6ff9a996":"features_format_str = \"<h3>Features:<\/h3><br>\"\n\n## iterate each rows in dataframe\nfor row in features_desc_df.values.tolist():\n    features_format_str+= f\"- <strong>{row[0]}:<\/strong>     {row[1]}<br>\"\n\n## display the formated string in markdown\nmd(features_format_str)","ea5dfdc5":"print(f\"No of Target variable: {df['Stay'].nunique()}\")\ntarget_distribution = df[df[\"dataset\"] == \"train\"][\"Stay\"].value_counts().sort_values(ascending=True)\nfig = go.Figure(data=go.Bar(x=target_distribution.index, y=target_distribution), layout_title_text=\"Distribution of Stay\")\nfig.show()","c1fa66b6":"sns.set_style(\"whitegrid\")\n\n#Create combination chart\nfig, ax1 = plt.subplots(figsize=(18,8))\ncolor = 'tab:green'\n#bar plot creation\nax1.set_title('Distribution of Stay', fontsize=16)\nax1.set_xlabel('Length of patient stay in hospital', fontsize=12)\nax1.set_ylabel('No of Samples', fontsize=12)\nax1 = sns.barplot(x=target_distribution.index, y=target_distribution)\nax1.tick_params(axis='y')\n\n#specify we want to share the same x-axis\nax2 = ax1.twinx()\ncolor = 'black'\n\nax2 = sns.lineplot(x=target_distribution.index, y=target_distribution.cumsum(), sort=False, color=color, markers=True, dashes=False)\nax2.tick_params(axis='y', color=color)\n#line plot creation\nax2.set_ylabel('Total no of samples', fontsize=12)\n\n## set label for lineplot\nfor x in target_distribution.cumsum().index:\n    cum_percentage_of_target = round((target_distribution.cumsum()[x] \/ target_distribution.sum()) * 100, 2)\n    ax2.text(x,target_distribution.cumsum()[x]-10000,f'{cum_percentage_of_target} %',color=color, fontsize=11)\n\n#show plot\nplt.show()","910ac294":"df[df[\"dataset\"] == \"train\"][\"Visitors with Patient\"].unique()","01c04a9d":"from sklearn import preprocessing\nfrom tqdm import tqdm\nfrom sklearn.utils import class_weight\n\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score","4d59e746":"df[\"is_patient_admitted_in_same_city_hospital\"] = np.where(df[\"City_Code_Patient\"] == df[\"City_Code_Hospital\"], 1, 0)","aa6dde29":"df[\"is_patient_admitted_in_same_city_hospital\"].value_counts()","ebe3667b":"## impute missing value\ndf.fillna(df[df[\"dataset\"] == \"train\"][\"Bed Grade\"].mode()[0], inplace=True)","3d8e7e80":"label_encoding_cols = [\"Hospital_type_code\", \"Hospital_region_code\", \"Department\", \"Ward_Type\", \"Type of Admission\", \"Severity of Illness\"]\n\n## store label encoder object\nlabel_encoder_dict = {}\nfor cols in tqdm(label_encoding_cols):\n    le = preprocessing.LabelEncoder()\n    le.fit(df[df[\"dataset\"] == \"train\"][cols])\n    df[cols] = le.transform(df[cols])\n    label_encoder_dict[cols] = le","c807af2f":"train_df_encoded = df[df[\"dataset\"] == \"train\"]\ntest_df_encoded = df[df[\"dataset\"] == \"test\"]\n\n## target variable encoding\nle = preprocessing.LabelEncoder()\nle.fit(train_df_encoded[\"Stay\"])\ntrain_df_encoded[\"Stay\"] = le.transform(train_df_encoded[\"Stay\"])\nlabel_encoder_dict[\"Stay\"] = le","71cdd651":"## age encode\nage_encode = {'51-60':6, '71-80':8, '31-40':4, '41-50':5, '81-90':9, '61-70':7, '21-30':3,\n       '11-20':2, '0-10':1, '91-100':10}\n\ntrain_df_encoded[\"Age\"] = train_df_encoded[\"Age\"].map(age_encode)\ntest_df_encoded[\"Age\"] = test_df_encoded[\"Age\"].map(age_encode)","3e5a6743":"train_df_encoded.head()","ea42a04f":"## StratifiedKFold\nNUM_FOLDS = 5\nkfold = model_selection.StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(X=train_df_encoded, y=train_df_encoded[\"Stay\"])):\n    train_df_encoded.loc[val_idx, \"fold\"] = fold","c0146a09":"def get_class_weights(y):    \n    class_weights = class_weight.compute_class_weight('balanced',\n                                                     np.unique(y),\n                                                     y)\n    class_weights = {label:weight for label, weight in enumerate(class_weights)}\n    return class_weights","804b7ca4":"from sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier","180ab860":"selected_features = [\"Hospital_code\", \"Hospital_type_code\", \"City_Code_Hospital\", \"Hospital_region_code\", \"Available Extra Rooms in Hospital\", \n                         \"Department\", \"Ward_Type\", \"Bed Grade\", \"City_Code_Patient\",  \"Type of Admission\", \"Severity of Illness\", 'Age', \"Admission_Deposit\",\n                        \"is_patient_admitted_in_same_city_hospital\"]\n\nclass_weights = get_class_weights(train_df_encoded[train_df_encoded[\"fold\"] != 4][\"Stay\"])\n## used cost sensitive funtion for RandomForest\nmodel = RandomForestClassifier(random_state=666, class_weight=class_weights)\ntrn_df = train_df_encoded[train_df_encoded[\"fold\"] != 4]\ntst_df = train_df_encoded[train_df_encoded[\"fold\"] == 4]\nclass_weights = get_class_weights(trn_df[\"Stay\"])\nmodel.fit(trn_df[selected_features], trn_df[\"Stay\"])\npreds = model.predict(tst_df[selected_features])\nprint(f'Accuracy: {accuracy_score(tst_df[\"Stay\"], preds)*100}%')","8b0f8571":"eval_fold = 4\nselected_features = [\"Hospital_code\", \"Hospital_type_code\", \"City_Code_Hospital\", \"Hospital_region_code\", \"Available Extra Rooms in Hospital\", \n                         \"Department\", \"Ward_Type\", \"Bed Grade\", \"City_Code_Patient\",  \"Type of Admission\", \"Severity of Illness\", 'Age', \"Admission_Deposit\",\n                        \"is_patient_admitted_in_same_city_hospital\"]","641f7141":"eval_fold = 4\nselected_features = [\"Hospital_code\", \"Hospital_type_code\", \"City_Code_Hospital\", \"Hospital_region_code\", \"Available Extra Rooms in Hospital\", \n                         \"Department\", \"Ward_Type\", \"Bed Grade\", \"City_Code_Patient\",  \"Type of Admission\", \"Severity of Illness\", 'Age', \"Admission_Deposit\",\n                        \"is_patient_admitted_in_same_city_hospital\"]\nmodels = []\n\npredicted_probs = np.array([])\n\n## Build KFold model\nfor fold in tqdm(range(0, 4)):\n    train_df_features = train_df_encoded[(train_df_encoded[\"fold\"] != fold) & (train_df_encoded[\"fold\"] != eval_fold)]\n    test_df_features = train_df_encoded[(train_df_encoded[\"fold\"] == fold) & (train_df_encoded[\"fold\"] != eval_fold)]\n    \n    clf = LGBMClassifier(n_estimators= 300, random_state=666)\n        \n    ## fit the model\n    clf.fit(train_df_features[selected_features], train_df_features[\"Stay\"], categorical_feature=label_encoding_cols + ['Age', 'is_patient_admitted_in_same_city_hospital'])\n    ## add model to list\n    models.append(clf)\n    ## predict for validation set\n    pred = clf.predict(test_df_features[selected_features])\n    \n    ## predict on unseen kfold set\n    unseen_pred_probs = clf.predict_proba(train_df_encoded[train_df_encoded[\"fold\"] == eval_fold][selected_features])\n    if predicted_probs.size == 0:\n        predicted_probs = unseen_pred_probs\n    else:\n        predicted_probs = np.sum([predicted_probs, unseen_pred_probs], axis=0)\n        \n    print(f\"Fold {fold} accuracy: {accuracy_score(test_df_features['Stay'], pred):.2f}\")","8496a5c8":"predicted_probs_avg = predicted_probs \/ 4\npredicted_probs_avg = np.argmax(predicted_probs_avg,axis=1)\n\nprint(f'Unseen Fold accuracy: {accuracy_score(train_df_encoded[train_df_encoded[\"fold\"] == eval_fold][\"Stay\"], predicted_probs_avg)}')","79b8373b":"test_predicted_probs = np.array([])\n\n## Build KFold model\nfor model in tqdm(models):\n    ## predict on unseen kfold set\n    test_pred_probs = model.predict_proba(test_df_encoded[selected_features])\n    if test_predicted_probs.size == 0:\n        test_predicted_probs = test_pred_probs\n    else:\n        test_predicted_probs = np.sum([test_predicted_probs, test_pred_probs], axis=0)\n\n## calculate average prob \ntest_predicted_probs_avg = test_predicted_probs \/ 4\ntest_predicted_probs_avg = np.argmax(test_predicted_probs_avg,axis=1)","adaf5316":"submission_df = pd.DataFrame(test_df_encoded[\"case_id\"])\nsubmission_df[\"Stay\"] = label_encoder_dict[\"Stay\"].inverse_transform(test_predicted_probs_avg)","4c59c265":"## write into submission file\nsubmission_df.to_excel(\"submission.xlsx\", index=False)","f2ccc852":"submission_df[\"Stay\"].unique()","6c8d1c21":"!pip install pycaret","f09780ec":"from pycaret.classification import *","99aeead1":"cols = selected_features+['Stay']\nexp = setup(train_df_encoded[train_df_encoded[\"fold\"] != eval_fold][cols] , target = 'Stay')","3a548185":"models = compare_models()","80555324":"<h2> KFOLD model <\/h2>","7e526a12":"<h2> Distribution of Target variable<\/h2>","4f0ffc00":"<h2>Problem Statement<\/h2>\nRecent Covid-19 Pandemic has raised alarms over one of the most overlooked area to focus: Healthcare Management. While healthcare management has various use cases for using data science, <strong>patient length of stay is one critical parameter to observe and predict<\/strong> if one wants to improve the efficiency of the healthcare management in a hospital.\nThis parameter helps hospitals to identify patients of high LOS risk (patients who will stay longer) at the time of admission. Once identified, patients with high LOS risk can have their treatment plan optimized to miminize LOS and lower the chance of staff\/visitor infection. Also, prior knowledge of LOS can aid in logistics such as room and bed allocation planning.\nSuppose you have been hired as Data Scientist of HealthMan \u2013 a not for profit organization dedicated to manage the functioning of Hospitals in a professional and optimal manner.\n\n<\/br><br><center><img align=\"center\" titile=\"AV Hackathon\" src=\"https:\/\/datahack-prod.s3.ap-south-1.amazonaws.com\/__sized__\/contest_cover\/cover_4-thumbnail-1200x1200.png\"><\/center>\n\n<h2> Task: <\/h2>\nThe task is to accurately <font size=\"3\"><strong>predict the Length of Stay for each patient<\/strong><\/font> on case by case basis so that the Hospitals can use this information for optimal resource allocation and better functioning. <br>\n\n* The length of stay is divided into 11 different classes ranging from 0-10 days to more than 100 days.\n* Our focus should be predicting the 11 categories as correct as possible.","9f1b2021":"<h2> Build ML model <\/h2>","198c49e7":"Write submission file","12d0fb6f":"Let's build model using **Pycarat**","a86c8e2d":"<h2> Inference for Test set <\/h2>","d828229c":"* The problem is **Multilable classification**.\n* Next, will see cumulative percentage of sample available for each target variables.","a83c4845":"Lets create the new feature called: `is_patient_admitted_in_same_city_hospital` means whether the patient is admitted in the same city where he is from or he got admitted to different city hospital.","562117c6":"<h4> Crazy Feature:<\/h4>","070e7c34":"Let's see what kind of different features we have:","a3cc3b8f":"<h2> Encoding Features <\/h2>","6baf5632":"RandomForest Model","4a101780":"`Bed Grade` feature has missing value. hence, mode of the value has been imputed directly.","9d7ecd9f":"Very nice EDA has been done in this kernel. https:\/\/www.kaggle.com\/isaienkov\/healthcare-analysis-and-modeling-42-7\n\nI will be straightaway going for modeling.","eaf8e83b":"Calculate cost sensitive class weights","3165dda4":"Target variable encode","f4f17a9a":"<font size=\"4\">Stay tuned!<\/font><br>\nMore will be updated soon. Thanks for reading my kernel.","a6f5cd4b":"Interpretation of the Graph:\n\n* Two graphs are combined in above. \n* The bar chart is representing distribution of the target variables. \n* The lineplot is representing the cumulative percentage of samples for each target. ","20b1a1e6":"Observation:\n\n- 11 target labels available (This is grouped by no of days stayed in the hospital like categories 0-10, 10-20, etc ).\n- The distribution of taget variable is skewed right side.\n- Very less percentage of samples we have on from left side.","6b2fea88":"<h2> Feature Engineering <\/h2>","d6f4b2bc":"<h2> Cumulative percentage of Target variable <\/h2>","05272c08":"This is crazy when you look at the data.\n\nThe feature ` Visitors with Patient` column has values ranging from <strong>1 to 32<\/strong>. If you see the description of the column has `Number of Visitors with the patient`. \n\nIs really possible that the patient has more number of visitors with him?","51d60ca1":"Got accuracy of 30%.","a311ff89":"Observation:\n\n* Less than <font size=\"3\" color=\"red\">**47.99%**<\/font> of the data contains almost 9 target classes.\n* Only 2 labels having <font size=\"3\" color=\"blue\">**52%**<\/font> of the data samples.\n* It is very unbalanced when it comes to label distribution of the data.\n* This is how the real-world data looks like. Very difficult to get balanced data samples in each class when the data comes from real-world."}}