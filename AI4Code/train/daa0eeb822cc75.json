{"cell_type":{"8c5db852":"code","655f19fd":"code","4c85066b":"code","b70afec6":"code","aec11747":"code","fe9157f9":"code","7da28ae8":"code","c0d8be31":"code","011b8b69":"code","45dca823":"code","dd3d9525":"code","1a35f789":"code","76e493fc":"code","ed0c854e":"code","16cb81f9":"code","f7d4cfb7":"code","ca02029c":"markdown","ffec9edf":"markdown","666e81e9":"markdown","2b06ae43":"markdown","8a55806d":"markdown","adf07b0c":"markdown","b67eabd7":"markdown","37c089fd":"markdown","99c1b923":"markdown","aa627711":"markdown","23f93056":"markdown"},"source":{"8c5db852":"# import libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nfrom wordcloud import WordCloud,STOPWORDS\nimport spacy as sp\nimport string\nimport nltk\nimport re\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\nfrom plotly.subplots import make_subplots\npyo.init_notebook_mode()\nnltk.download(\"vader_lexicon\")\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nnlps = sp.load('en')\nfrom nltk.util import ngrams\n\nplt.rc(\"figure\",figsize=(18,11))","655f19fd":"rih = pd.read_csv(\"..\/input\/rihanna-lyrics\/Rihanna Lyrics.csv\", delimiter=\";\", encoding=\"Windows-1252\")\nrih","4c85066b":"preprocessed = rih.copy()\nfor col in preprocessed.columns[:-2]:\n    preprocessed[col] = preprocessed[col].str.lower()\n\ndef extract_feat(s):\n    artist = s[s.find(\"(\")+1:s.find(\")\")]\n    if artist.find(\"ft.\") != -1:\n        return artist.replace(\"ft. \",\"\")\n    else:\n        return \"solo\"\n    \ndef remove_artist(s):\n    artist = s[s.find(\"(\")+1:s.find(\")\")]\n    if artist.find(\"ft.\") != -1:\n        return s[:s.find(\"(\")]\n    else:\n        return s\n    \npreprocessed[\"featuring\"] = preprocessed.song.apply(extract_feat)\npreprocessed.song = preprocessed.song.apply(remove_artist)\npreprocessed.song = preprocessed.song.apply(lambda x:re.sub(r\"[^\\w\\s]\", \"\", x) )\n\n\npreprocessed = preprocessed.loc[preprocessed.lyrics.dropna().index,:]\n\npreprocessed[\"number_of_verses\"]=0\npreprocessed[\"number_of_chorus\"]=0\npreprocessed.loc[preprocessed.lyrics.notna().index,\"number_of_verses\"] = preprocessed.lyrics[preprocessed.lyrics.notna()].apply(lambda x:len( re.findall(r\"verse\",x)))\npreprocessed.loc[preprocessed.lyrics.notna().index,\"number_of_chorus\"] = preprocessed.lyrics[preprocessed.lyrics.notna()].apply(lambda x:len( re.findall(r\"chorus\",x)))\n\npreprocessed.loc[preprocessed.lyrics.notna().index,\"lyrics\"] = preprocessed.lyrics[preprocessed.lyrics.notna()].apply(lambda x: re.sub(r\"\\[([^]]*)]\",\"\",x))\npreprocessed.loc[preprocessed.lyrics.notna().index,\"lyrics\"] = preprocessed.lyrics[preprocessed.lyrics.notna()].apply(lambda x: x.replace(\"\\n\",\" \"))\npreprocessed.loc[preprocessed.lyrics.notna().index,\"lyrics\"] = preprocessed.lyrics[preprocessed.lyrics.notna()].apply(lambda x:re.sub(r\"[^\\w\\s]\",\"\", x))\n\n\nsid = SIA()\npreprocessed[\"sentiments\"]           = preprocessed[\"lyrics\"].apply(lambda x: sid.polarity_scores(x))\npreprocessed[\"Positive Sentiment\"]   = preprocessed[\"sentiments\"].apply(lambda x: x[\"pos\"]) \npreprocessed[\"Neutral Sentiment\"]    = preprocessed[\"sentiments\"].apply(lambda x: x[\"neu\"])\npreprocessed[\"Negative Sentiment\"]   = preprocessed[\"sentiments\"].apply(lambda x: x[\"neg\"])\n\npreprocessed.drop(columns=['sentiments'],inplace=True)\n\npreprocessed[\"# Of Words\"]                 = preprocessed[\"lyrics\"].apply(lambda x: len(x.split(\" \")))\npreprocessed[\"# Of StopWords\"]             = preprocessed[\"lyrics\"].apply(lambda x: len([word for word in x.split(\" \") if word in list(STOPWORDS)]))\npreprocessed[\"Average Word Length\"]        = preprocessed[\"lyrics\"].apply(lambda x: np.mean(np.array([len(va) for va in x.split(\" \") if va not in list(STOPWORDS)])))\npreprocessed[\"Average Sentence Length\"]    = preprocessed[\"lyrics\"].apply(lambda x: np.mean(np.array([len(va) for va in x.split(\".\")])))\n\n#Album Mean Statistics DF\nalbum_rih = preprocessed.groupby(by='album').mean()\n\npreprocessed","b70afec6":"# get the number of missing data points per column\nmissing_values_count = rih.isnull().sum()\n\n# look at the number of missing points in the column\nmissing_values_count[:]","aec11747":"plt.title(\"Number Of Songs Associated With Each Album\",fontsize=19,fontweight=\"bold\")\nax = sns.barplot(y=preprocessed.album.value_counts().index,x=preprocessed.album.value_counts().values,palette=\"nipy_spectral\")\nax.set_yticklabels(ax.get_yticklabels(),fontsize=15,fontweight=\"bold\")\nplt.show()","fe9157f9":"plt.title('Top 10 Most Featured Artist In Rihanna Songs',fontsize=19,fontweight='bold')\nax = sns.barplot(y=preprocessed.featuring.value_counts()[1:11].index,x=preprocessed.featuring.value_counts()[1:11].values,palette='nipy_spectral')\nax.set_yticklabels(ax.get_yticklabels(),fontsize=15,fontweight='bold')\nplt.show()","7da28ae8":"fig = make_subplots(rows=2, cols=1,shared_xaxes=True,subplot_titles=('Perason Correaltion',  'Spearman Correaltion'))\n\ns_val =preprocessed.corr('pearson')\ns_idx = s_val.index\ns_col = s_val.columns\ns_val = s_val.values\nfig.add_trace(\n    go.Heatmap(x=s_col,y=s_idx,z=s_val,name='pearson',showscale=False,xgap=1,ygap=1),\n    row=1, col=1)\n\ns_val =preprocessed.corr('spearman')\ns_idx = s_val.index\ns_col = s_val.columns\ns_val = s_val.values\nfig.add_trace(\n    go.Heatmap(x=s_col,y=s_idx,z=s_val,xgap=1,ygap=1),\n    row=2, col=1)\n\nfig.update_layout(\n    hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=16,\n        font_family=\"Rockwell\"))\n\nfig.update_layout(height=700, width=900, title_text=\"Correlations Between Our Different Numeric Features\")\nfig.show()","c0d8be31":"fig = go.Figure()\nalbum_rih = album_rih.sort_values(by='year')\nalbum_rihanna = album_rih.groupby(by='year').mean().reset_index()\n\nfor column in album_rihanna.columns[:-1]:\n    fig.add_trace(\n        go.Scatter(\n            x = album_rihanna.year,\n            y = album_rihanna[column],\n            name = column,))\n\n\nbtns = []\nfor x,col in enumerate(album_rihanna.columns[:-1]):\n    bol = [False]*12\n    bol[x]=True\n    d = dict(label = col,\n                  method = 'update',\n                  args = [{'visible':bol},\n                          {'title': 'Distribution of [' +col+'] Over The Years',\n                           'showlegend':True}])\n    btns.append(d)\n    \n    \nfig.update_layout(title='Features Distribution Over The Years',\n    updatemenus=[go.layout.Updatemenu(\n        active=0,\n        showactive=True,\n        buttons=btns)])\n\n\nfig.show()","011b8b69":"album_mean = album_rih.sort_values(by=\"year\")\n\nalbum_year_index =[album + \"  \"+ str(year) for album,year in zip(album_mean.index,album_mean.year)]\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=album_year_index, y=album_mean['Positive Sentiment'],\n                    mode='lines+markers',\n                    name='Mean Positive Sentiment Value',hovertext=album_mean['year']))\nfig.add_trace(go.Scatter(x=album_year_index, y=album_mean['Negative Sentiment'],\n                    mode='lines+markers',\n                    name='Mean Negative Sentiment Value',hovertext=album_mean['year']))\n\nfig.update_layout(title='Album Sentiment Change Over The Years')\nfig.show()\n#album_mean","45dca823":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=album_year_index, y=album_mean['number_of_verses'],\n                    mode='lines+markers',\n                    name='Mean Verse Amount',hovertext=album_mean['year']))\nfig.add_trace(go.Scatter(x=album_year_index, y=album_mean['number_of_chorus'],\n                    mode='lines+markers',\n                    name='Mean Chorus Amount',hovertext=album_mean['year']))\n\nfig.update_layout(title='Album Chorus and Verse Count Change Over The Years')\nfig.show()","dd3d9525":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=album_year_index, y=album_mean['views'],\n                    mode='lines+markers',\n                    name='Mean Verse Amount',hovertext=album_mean['year']))\n\nfig.update_layout(title='Album Views Over The Years')\nfig.show()","1a35f789":"l_t = ' '.join(preprocessed.song).strip().replace('rihanna','')\nl_t = l_t.replace('ft','')\nw_c = WordCloud(width=600,height=400,collocations = False,stopwords=STOPWORDS,colormap='nipy_spectral',background_color='white').generate(l_t)\n\nplt.title('Most Used Words In Rihanna Song Titles',fontsize=19,fontweight='bold')\nplt.imshow(w_c)\nplt.axis('off')\nplt.show()","76e493fc":"l_t = ' '.join(preprocessed.lyrics[preprocessed.lyrics.notna()]).strip()\nw_c = WordCloud(width=600,height=400,collocations = False,stopwords=STOPWORDS,colormap='nipy_spectral',background_color='white').generate(l_t)\n\nplt.title('Most Used Words In Rihanna Lyrics',fontsize=19,fontweight='bold')\nplt.imshow(w_c)\nplt.axis('off')\nplt.show()","ed0c854e":"#preprocessed.lyrics\nw1_dict = dict()\nfor word in l_t.split():\n    w= word.strip()\n    if w in STOPWORDS:\n        continue\n    else:\n        w1_dict[w] = w1_dict.get(w,0)+1\nw1_dict = {k: v for k, v in sorted(w1_dict.items(), key=lambda item: item[1],reverse=True)}\n\nw2_dict = dict()\n\ntop_10_w1 = list(w1_dict.keys())[:10]\ntoken=nltk.word_tokenize(l_t)\ntrigram =ngrams(token,3)\ntrigram = [k for k in trigram if k[0] in top_10_w1]","16cb81f9":"w_c = WordCloud(width=600,height=400,collocations = False,colormap='nipy_spectral',background_color='white').generate(' '.join(top_10_w1))\nplt.title('Top 10 Words In Rihanna Lyrics',fontsize=19,fontweight='bold')\nplt.imshow(w_c)\nplt.axis('off')\nplt.show()","f7d4cfb7":"NUMBER_OF_COMPONENTS=100\n\nCV = CountVectorizer()\nsvd = TruncatedSVD(NUMBER_OF_COMPONENTS)\n\nc_matrix = CV.fit_transform(preprocessed.lyrics)\n\ndec_matrix = svd.fit_transform(c_matrix)\ndec_df=pd.DataFrame(dec_matrix,columns=['PC_{}'.format(i) for i in range(1,NUMBER_OF_COMPONENTS+1)])\n\nex_var = svd.explained_variance_ratio_\nvariance_cum = np.cumsum(ex_var)\ndata = [go.Scatter(x=np.arange(0,len(variance_cum)),y=variance_cum,name='Cumulative Explained Variance',mode='lines+markers'),\n        go.Scatter(x=np.arange(0,len(variance_cum)),y=ex_var,name='Explained Variance',mode='lines+markers')]\nlayout = dict(title='Explained Variance Ratio Using {} Words'.format(NUMBER_OF_COMPONENTS),\n             xaxis_title='# Componenets',yaxis_title='Explained Variance',height=650,width=900)\nfig = go.Figure(data=data,layout=layout)\nfig.update_layout(template='seaborn')\nfig.show()","ca02029c":"## 3.1. Label Based Analysis\n","ffec9edf":"# 3. Exploratory Data Analysis\nFirst, check for missing values and handle them if there is any.<br>\nThen, visualize the data.","666e81e9":"## 3.4. Text Based Analysis\n","2b06ae43":"Apparently, more than 90% of the variance in Rihanna's lyrics can be explained using only 100 words.","8a55806d":"# 1. Introduction\nI was reminiscing Rihanna's old songs, and then decided to do an EDA on [Rihanna Lyrics dataset](https:\/\/www.kaggle.com\/vivovinco\/rihanna-lyrics).<br>\nHope you enjoy this one.\n\n![image.png](attachment:41fc7c3f-a3a0-4934-824e-0808fd7eef73.png)","adf07b0c":"# 2. Data Preprocessing and Feature Engineering\n","b67eabd7":"## 3.3. Album Based Analysis\n","37c089fd":"The most viewed two albums of Rih's ([Unapologetic](https:\/\/en.wikipedia.org\/wiki\/Unapologetic) and [ANTI](https:\/\/en.wikipedia.org\/wiki\/Anti_(album))) has the lowest mean values of choruses.<br>\nBesides, I haven't noticed that she released an album almost every year until ANTI. \ud83d\ude10","99c1b923":"Rihanna has an average of 14 songs per album which is great!","aa627711":"# 4. Vectorization And Decomposition\n","23f93056":"## 3.2. Correlation Analysis\n"}}