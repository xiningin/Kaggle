{"cell_type":{"98eeacc3":"code","64955b98":"code","e1bdfe95":"code","56ac98dd":"code","4d05e433":"code","ee7f2130":"code","16f5f47a":"code","5e71ef9f":"code","f1576530":"code","67124f55":"code","9c962c7f":"code","b71645f1":"code","a5ff3115":"code","8f471dec":"code","05039be6":"code","124b3f47":"code","e94066f4":"code","03d7711f":"code","ca1ff90e":"code","650c48a2":"code","7467b8eb":"code","88d1ea77":"code","dec0d766":"code","491fa8ca":"code","96206be4":"markdown","59d85ae1":"markdown","af63d585":"markdown"},"source":{"98eeacc3":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom functools import partial\nimport os","64955b98":"# Cr\u00e9ation listes d'image (X) et de cat\u00e9gorie (Y)\nimages=[]\ncategories=[]\n\n# Chargement des donn\u00e9es\ndata = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\n\n(listeIMG,listeCat) = data[\"image_id\"],data[\"label\"]\n\nPATH = '..\/input\/cassava-leaf-disease-classification\/train_images'\n\n#Limit\u00e9 \u00e0 1300 image parcequ'au-dela nous avions une erreur\nlisteIMG= listeIMG[:1000]\nlisteCat= listeCat[:1000]\n\n\n# Parcoure le DataSet d'images et remplis les listes X et Y\nfor x in listeIMG:\n    img = Image.open(f'{PATH}\/{x}').convert(\"L\")\n    images.append(np.array(img))\n\n\n#print(X)\n#print(len(listeIMG))\n\n# Normalisation\nimages = np.array(images, dtype=np.float) \/ 255.0\n\n# Transforme nos cat\u00e9gories en vecteurs de 0 et 1, l'index du 1 correspondant \u00e0 la cat\u00e9gorie de notre image\ncategories = keras.utils.to_categorical(listeCat, 5)\n","e1bdfe95":"#Test de r\u00e9cup\u00e9ration et affichage d'image\nimgFILE = '..\/input\/cassava-leaf-disease-classification\/train_images\/' + listeIMG[0]\nimgSRC = Image.open(imgFILE)\nimgSRC","56ac98dd":"# Cr\u00e9ation du mod\u00e8le \ndef build_and_train_model1(x_train, y_train, x_test, y_test,batch_nb,epok):\n    model = keras.models.Sequential()\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(1800, activation=keras.activations.relu))\n    model.add(keras.layers.Dense(1800, activation=keras.activations.relu))\n    model.add(keras.layers.Dense(1400, activation=keras.activations.relu))\n    model.add(keras.layers.Dense(1200, activation=keras.activations.relu))\n    model.add(keras.layers.Dense(5, activation=\"sigmoid\"))\n    #model.add(keras.layers.Dense(5, activation=\"softmax\"))\n\n    # Compilation du mod\u00e8le\n    model.compile(\n        loss=keras.losses.mse,  # Calcul le loss\n        optimizer=keras.optimizers.SGD(learning_rate),  # Minimise le loss\n        # optimizer=keras.optimizers.Adam()\n        metrics=keras.metrics.categorical_accuracy\n    )\n    \n    # Entra\u00eenement du mod\u00e8le\n    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epok, batch_size = batch_nb)\n    model.summary()\n    \n    score = model.evaluate(x_test, y_test, verbose=0)\n\n\n","4d05e433":"epok = 100\nnbBatch=300\nlearning_rate = 0.95\n\n# Split des donn\u00e9es d'entrainement et de test\nIMG_train, IMG_test, Categories_train, Categories_test = train_test_split(images, categories, test_size=0.33, random_state=42)\n\n# Lancement du programme de notre mod\u00e8le\nbuild_and_train_model1( IMG_train , Categories_train,IMG_test,Categories_test, nbBatch,epok)","ee7f2130":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(\"Device:\", tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nPATH = \"..\/input\/cassava-leaf-disease-classification\"\nBATCH_SIZE = 300\nIMAGE_SIZE = [512, 512,3]\nHEIGHT = 100\nWIDTH = 100\nCHANNELS = 3\nEPOCH = 100\nlearning_rate = 0.001","16f5f47a":"FILENAMES = tf.io.gfile.glob(PATH + \"\/train_tfrecords\/*.tfrec\")\nsplit_ind = int(0.8 * len(FILENAMES))\nTRAINING_FILENAMES, VALID_FILENAMES = FILENAMES[:split_ind], FILENAMES[split_ind:]\n\nTEST_FILENAMES = tf.io.gfile.glob(PATH + \"\/test_tfrecords\/*.tfrec\")\nprint(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\nprint(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\nprint(\"Test TFRecord Files:\", len(TEST_FILENAMES))","5e71ef9f":"def resize(x):\n    x = tf.image.resize(x, (HEIGHT,WIDTH))\n    return x\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32)\n    return resize(image)#Modifie la taille de l'image en [HEIGHT,WIDTH,3], ce qi nous permettra de travailler avec de plus petites images\n","f1576530":"def read_tfrecord(example, labeled):\n    tfrecord_format = (\n        {\n            \"image\": tf.io.FixedLenFeature([], tf.string),\n            \"target\": tf.io.FixedLenFeature([], tf.int64),\n        }\n        if labeled\n        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n    )\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example[\"image\"])\n\n    if labeled:\n        label = tf.cast(example[\"target\"], tf.int32)\n        return image, label\n    return image\n","67124f55":"def load_dataset(filenames, labeled=True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False  # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames )  # automatically interleaves reads from multiple files\n    dataset = dataset.with_options( ignore_order)  # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map( partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE )\n    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n    return dataset","9c962c7f":"def get_dataset(filenames, labeled=True):\n    dataset = load_dataset(filenames, labeled=labeled)\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset","b71645f1":"train_dataset = get_dataset(TRAINING_FILENAMES)\nvalid_dataset = get_dataset(VALID_FILENAMES)\ntest_dataset = get_dataset(TEST_FILENAMES, labeled=False)\n\n","a5ff3115":"for images in test_dataset.take(1):\n    plt.imshow(images[0]\n               .numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","8f471dec":"#AFFICHES des images et leurs cat\u00e9gories\n\ndef show_batch(data):\n    plt.figure(figsize=(10, 10))\n\n    for images, labels in data.take(1):\n        for i in range(25):\n            ax = plt.subplot(5, 5, i + 1)\n            plt.imshow(images.numpy()[i].astype(\"uint8\"))\n            plt.axis(\"off\")\n            \n        \nshow_batch(train_dataset)\n","05039be6":"def build_and_train_model(addlayers,train_dataset, valid_dataset):\n    model = keras.models.Sequential()\n    addlayers(model)\n    \n    model.add(keras.layers.Flatten())\n\n    model.add(keras.layers.Dense(5, activation=\"sigmoid\"))\n    model.add(keras.layers.Dense(5, activation=\"softmax\"))\n\n\n    model.compile(\n        loss=keras.losses.binary_crossentropy,  # calcul l'erreur\n        optimizer=keras.optimizers.SGD(learning_rate),  # minimise l'erreur\n        #optimizer=keras.optimizers.Adam(),\n        metrics=['accuracy']\n    )\n    \n    logs = history = model.fit(\n        train_dataset,\n        epochs= EPOCH,\n        batch_size = BATCH_SIZE,\n        validation_data = valid_dataset,\n    )\n    model.summary()\n    \n    score = model.evaluate(train_dataset, verbose=0)\n    model.reset_states()\n\n\n    return logs\n\n\n","124b3f47":"def pmc(model):\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(800, activation='relu'))\n    model.add(keras.layers.Dense(800, activation='relu'))\n    model.add(keras.layers.Dense(400, activation='relu'))\n    model.add(keras.layers.Dense(200, activation='relu'))\n    ","e94066f4":"def convnet(model):\n    model.add(keras.layers.Conv2D(64, (4, 4), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.MaxPool2D())\n    model.add(keras.layers.Conv2D(32, (4, 4), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.MaxPool2D())\n    model.add(keras.layers.Conv2D(16, (4, 4), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.MaxPool2D())\n    model.add(keras.layers.Dropout(0.5))\n    model.add(keras.layers.Dropout(0.5))\n    \n    model.add(keras.layers.Flatten())\n    \n#le loss et l'accuracy gardent la m\u00eame valeur \u00e0 chaque epoch\n\n    ","03d7711f":"def resNet(model):\n    model.add(keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.BatchNormalization())\n\n    model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.BatchNormalization())\n\n\n    model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.BatchNormalization())\n\n","ca1ff90e":"#import torchvision.models as models\n#vgg16 = models.vgg16(pretrained=True)","650c48a2":"#def vgg16_pytorch(model):\n    #model = vgg16","7467b8eb":"#On a divis\u00e9 le nombre initial de couche \u00e0 cause d'un probl\u00e8me de m\u00e9moire\n\ndef vgg16(model):\n    model.add(keras.layers.Conv2D(64,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.Conv2D(64,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.MaxPool2D())\n    model.add(keras.layers.Dropout(0.5))\n\n    \n    model.add(keras.layers.Conv2D(128,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.Conv2D(128,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.MaxPool2D())\n    model.add(keras.layers.Dropout(0.5))\n\n    \n    model.add(keras.layers.Conv2D(256,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.Conv2D(256,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.Conv2D(256,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.MaxPool2D())\n    model.add(keras.layers.Dropout(0.5))\n\n    \n    model.add(keras.layers.Conv2D(512,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.Conv2D(512,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.Conv2D(512,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.MaxPool2D())\n    model.add(keras.layers.Dropout(0.5))\n\n    \n    model.add(keras.layers.Conv2D(512,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.Conv2D(512,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.Conv2D(512,(3, 3), padding=\"same\", activation=keras.activations.relu))\n    model.add(keras.layers.MaxPool2D())\n    model.add(keras.layers.Dropout(0.5))\n\n    \n    model.add(keras.layers.Flatten())\n\n    # Ajout des couches fully-connected, suivie de couche ReLU\n    model.add(keras.layers.Dense(4096, activation='relu'))\n    model.add(keras.layers.Dense(4096, activation='relu'))\n    model.add(keras.layers.Dense(1000, activation='relu'))\n\n    ","88d1ea77":"\nall_logs = [(build_and_train_model(pmc,train_dataset , valid_dataset),\"mod\u00e8le pmc\"),\n           (build_and_train_model(convnet,train_dataset , valid_dataset),\"mod\u00e8le convnet\"),\n            (build_and_train_model(vgg16,train_dataset , valid_dataset),\"mod\u00e8le vgg-16\")\n\n           ]\n","dec0d766":"#Pour l'affichage\ndef plot_all_logs(all_logs):\n    # Loss\n    for logs in all_logs:\n        y_coords = logs[0].history[\"loss\"]\n        x_coords = list(range(len(y_coords)))\n        plt.plot(x_coords, y_coords,label=logs[1])\n        plt.legend()\n        plt.title(\"Loss\")\n\n    plt.show()\n    \n        # accuracy\n    for logs in all_logs:\n        y_coords = logs[0].history[\"categorical_accuracy\"]\n        x_coords = list(range(len(y_coords)))\n        plt.plot(x_coords, y_coords,label=logs[1])\n        plt.legend()\n        plt.title(\"Accuracy\")\n        \n    plt.show()\n","491fa8ca":"plot_all_logs(all_logs)","96206be4":"Nous avons abandonn\u00e9 cette m\u00e9thodes pour essayer de d\u00e9chiffrer les TFrecords.","59d85ae1":"Nous avons tent\u00e9 de transformer les images directement en matrice de valeurs repr\u00e9sentant les pixels.","af63d585":"Norayda N'SIEMO\nMounir AMIA\nAlpha SOW\nIsma\u00eel MANE\n\nNous disposons d'un ensemble de donn\u00e9es de 21 367 images \u00e9tiquet\u00e9es, nous allons cr\u00e9er et optimiser un mod\u00e8le pour avoir le maximum de prediction des maladies qui touchent les feuilles de manioc. "}}