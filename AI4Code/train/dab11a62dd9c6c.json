{"cell_type":{"9dc0bf3d":"code","af3de1b5":"code","9e540006":"code","f168113a":"code","62f5878b":"code","4f7a45a5":"code","c4b67574":"code","3d2ccbfe":"code","0f9306b2":"code","31a09b6c":"code","2807814a":"code","ff8b03e4":"code","efa7387b":"code","dc25e57e":"code","512b26e5":"code","774fe6e8":"code","ade7215f":"code","72cee230":"code","5f3991f7":"markdown","d6f16b6d":"markdown","6a1369a4":"markdown","927f0c0a":"markdown","b4a7d64e":"markdown","b12cd6a5":"markdown"},"source":{"9dc0bf3d":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\nfrom contextlib import contextmanager # timer\nfrom functools import partial\n\nimport seaborn as sns\nimport SimpleITK as sitk\nimport matplotlib.pylab as plt\n\nfrom skimage.transform import rescale, resize\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader, Dataset\nprint(os.listdir(\"..\/input\/\"))","af3de1b5":"# Stolen from a Kaggle Kernel\n# https:\/\/www.kaggle.com\/lopuhin\/mercari-golf-0-3875-cv-in-75-loc-1900-s\/comments\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(f'[{name}] done in {time.time() - t0:.0f} s')","9e540006":"'''\nDoc: Take out image one by one and apply transformations upon __getitem__\n'''\n\nclass CamusIterator(Dataset):\n    def __init__( \n        self, \n        data_type='train', \n        global_transforms=[], \n        augment_transforms=[]\n    ):\n        super(CamusIterator, self).__init__()\n        \n        train_file='..\/input\/camus-data\/training\/training'\n        test_file='..\/input\/camus-data\/testing\/testing'\n        \n        if data_type == 'train':\n            data_file = train_file\n        elif data_type == 'test':\n            data_file = test_file\n        else:\n            raise Exception('Wrong data_type for CamusIterator')\n            \n        self.data_type = data_type\n        self.data_file = data_file\n        self.global_transforms = global_transforms\n        self.augment_transforms = augment_transforms\n    \n    def _read_image( self, patient_file, suffix ):\n        image_file = '{}\/{}\/{}'.format( self.data_file, patient_file, patient_file+suffix )\n        # Stolen from a StackOverflow answer\n        # https:\/\/stackoverflow.com\/questions\/37290631\/reading-mhd-raw-format-in-python\n        image = sitk.GetArrayFromImage( sitk.ReadImage(image_file, sitk.sitkFloat32) )\n        return image\n\n    def _read_info( self, data_file ):\n        info = {}\n        with open( data_file, 'r' ) as f:\n            for line in f.readlines():\n                info_type, info_details = line.strip( '\\n' ).split( ': ' )\n                info[ info_type ] = info_details\n        return info\n\n    def __len__( self ):\n        return len( os.listdir(self.data_file) )\n    \n    def __getitem__( self, index ):\n        patient_file = 'patient{}'.format( f'{index+1:04}' ) # patient{0001}, patient{0002}, etc\n        \n        image_2CH_ED = self._read_image( patient_file, '_2CH_ED.mhd' )\n        image_2CH_ES = self._read_image( patient_file, '_2CH_ES.mhd' )\n        image_4CH_ED = self._read_image( patient_file, '_4CH_ED.mhd' )\n        image_4CH_ES = self._read_image( patient_file, '_4CH_ES.mhd' )\n        image_2CH_sequence = self._read_image( patient_file, '_2CH_sequence.mhd' )\n        image_4CH_sequence = self._read_image( patient_file, '_4CH_sequence.mhd' )\n        \n        if self.data_type == 'train':\n            image_2CH_ED_gt = self._read_image( patient_file, '_2CH_ED_gt.mhd' )\n            image_2CH_ES_gt = self._read_image( patient_file, '_2CH_ES_gt.mhd' )\n            image_4CH_ED_gt = self._read_image( patient_file, '_4CH_ED_gt.mhd' )\n            image_4CH_ES_gt = self._ead_image( patient_file, '_4CH_ES_gt.mhd' )\n\n        info_2CH = self._read_info( '{}\/{}\/{}'.format(self.data_file, patient_file, 'Info_2CH.cfg') )\n        info_4CH = self._read_info( '{}\/{}\/{}'.format(self.data_file, patient_file, 'Info_4CH.cfg') )\n        \n        if self.data_type == 'train':\n            data = {\n                'patient': patient_file,\n                '2CH_ED': image_2CH_ED,\n                '2CH_ES': image_2CH_ES,\n                '4CH_ED': image_4CH_ED,\n                '4CH_ES': image_4CH_ES,\n                '2CH_sequence': image_2CH_sequence,\n                '4CH_sequence': image_4CH_sequence,\n                '2CH_ED_gt': image_2CH_ED_gt,\n                '2CH_ES_gt': image_2CH_ES_gt,\n                '4CH_ED_gt': image_4CH_ED_gt,\n                '4CH_ES_gt': image_4CH_ES_gt,\n                'info_2CH': info_2CH,    # Dictionary of infos\n                'info_4CH': info_4CH}    # Dictionary of infos\n        elif self.data_type == 'test':\n            data = {\n                'patient': patient_file,\n                '2CH_ED': image_2CH_ED,\n                '2CH_ES': image_2CH_ES,\n                '4CH_ED': image_4CH_ED,\n                '4CH_ES': image_4CH_ES,\n                '2CH_sequence': image_2CH_sequence,\n                '4CH_sequence': image_4CH_sequence,\n                'info_2CH': info_2CH,   # Dictionary of infos\n                'info_4CH': info_4CH}   # Dictionary of infos\n        \n        # Transforms\n        for transform in self.global_transforms:\n            data = transform(data)\n        for transform in self.augment_transforms:\n            data = transform(data)\n            \n        return data\n\n    def __iter__( self ):\n        for i in range( len(self) ):\n            yield self[ i ]","f168113a":"class AddSaltPepper(object):\n    '''\n    Ripped out of Prof. Stough's code\n    \n    \"Class to augment the inputs with salt and pepper noise with some frequency.\n    Assume already normalized image.\"\n    '''\n    def __init__( self, freq = 0.0, fields=['2CH_ED', '2CH_ES', '4CH_ED', '4CH_ES'] ):\n        assert freq >= 0.0 and freq <= 1.0,\\\n            'AddSaltPepper: freq must be in [0,1] ({})'.format( freq )\n        \n        self.freq = freq\n        self.fields = fields\n        \n    def __call__(self, data):        \n        for field in self.fields:\n            noise = np.random.randint( 0, 2, size=data[field].shape ).astype( np.float32 )\n            data[field] = np.where( np.random.random_sample( data[field].shape )<=self.freq, \n                             noise, data[field] )\n        \n        return data","62f5878b":"class ResizeImagesAndLabels(object):\n    ''' \n    Ripped out of Prof. Stough's code \n    '''\n    \n    def __init__(self, size, fields=['2CH_ED', '2CH_ES', '4CH_ED', '4CH_ES',\n                                     '2CH_ED_gt', '2CH_ES_gt', '4CH_ED_gt', '4CH_ES_gt']):\n        self.size = size\n        self.fields = fields\n        \n    def __call__(self, data):\n        for field in self.fields:            \n            # transpose to go from chan x h x w to h x w x chan and back.\n            data[field] = resize(data[field].transpose([1,2,0]), \n                                 self.size, mode='constant', \n                                 anti_aliasing=True)\n            data[field] = data[field].transpose( [2,0,1] )      \n\n        return data","4f7a45a5":"# Batch size need to be 1 to avoid RuntimeError: Sizes of tensors must match except in dimension 0.\n# https:\/\/medium.com\/@yvanscher\/pytorch-tip-yielding-image-sizes-6a776eb4115b\n# Prolly also need the \"collate_fn\" variable to have batch_size other than 1\nparam_Loader = {'batch_size': 1,\n                'shuffle': True,\n                'num_workers': 8}\n\nglobal_transforms = [\n    ResizeImagesAndLabels(size=[256, 256])\n]\naugment_transforms = [\n    #AddSaltPepper(freq = .1)\n]","c4b67574":"train_iter = CamusIterator(\n    data_type='train',\n    global_transforms=global_transforms,\n    augment_transforms=augment_transforms,\n)\n\ntest_iter = CamusIterator(\n    data_type='test',\n    global_transforms=global_transforms,\n    augment_transforms=augment_transforms,\n)\n\nprint('Number of Train Samples: ', len(train_iter))\nprint('Number of Test Samples: ', len(test_iter))\n\ndata = DataLoader(train_iter, **param_Loader)","3d2ccbfe":"with timer('DataLoader loading'):\n    count = 0\n    for d in data:\n        for key in d:\n            print(key)\n            \n        break\n        count += 1\n        if count % 50 == 0:\n            print(count)","0f9306b2":"patient_info = train_iter[0]['info_2CH']\npatient_info","31a09b6c":"count = 0\ninfo_2CH_list = []\nwith timer('Read Train Camus'):\n    for patient_data in train_iter:\n        info_2CH_list.append(patient_data['info_2CH'])\n        info_2CH_list[-1]['patient'] = patient_data['patient']\n        count += 1\n        #if count == 5:\n        #    break\n        if count % 50 == 0:\n            print(count)","2807814a":"info_2CH_df = pd.DataFrame(info_2CH_list)\ninfo_2CH_df.set_index('patient', inplace=True)\ninfo_2CH_df.info()","ff8b03e4":"info_2CH_df","efa7387b":"fig, axs = plt.subplots(ncols=3, figsize=(20,8))\nsns.countplot(info_2CH_df['ED'], ax=axs[0])\nsns.countplot(info_2CH_df['ES'], ax=axs[1])\nsns.countplot(info_2CH_df['NbFrame'], ax=axs[2])","dc25e57e":"fig, axs = plt.subplots(ncols=3, figsize=(20,8))\nsns.countplot(info_2CH_df['ImageQuality'], ax=axs[0])\nsns.countplot(info_2CH_df['Sex'], ax=axs[1])\nsns.distplot(info_2CH_df['Age'].apply(lambda x: int(x)), ax=axs[2])","512b26e5":"fig, axs = plt.subplots(ncols=3, figsize=(20,8))\nsns.distplot(info_2CH_df['LVedv'].apply(lambda x: float(x)), ax=axs[0])\nsns.distplot(info_2CH_df['LVesv'].apply(lambda x: float(x)), ax=axs[1])\nsns.distplot(info_2CH_df['LVef'].apply(lambda x: float(x)), ax=axs[2])","774fe6e8":"def display_image(image):\n    # Stolen from a StackOverflow answer\n    # https:\/\/stackoverflow.com\/questions\/37290631\/reading-mhd-raw-format-in-python\n    \n    plt.figure(figsize=(20,16))\n    plt.gray()\n    plt.subplots_adjust(0,0,1,1,0.01,0.01)\n    for i in range(image.shape[0]):\n        plt.subplot(5,6,i+1), plt.imshow(image[i]), plt.axis('off')\n        # use plt.savefig(...) here if you want to save the images as .jpg, e.g.,\n    plt.show()","ade7215f":"patient = train_iter[0]\ndisplay_image(patient['2CH_ED'])\ndisplay_image(patient['2CH_ED_gt'])\npatient['info_2CH']['ImageQuality']","72cee230":"patient['4CH_ED'].shape","5f3991f7":"def run_training(network,\n                 data_iterator,\n                 effective_batchsize,\n                 criterion,\n                 optimizer=nn.MSELoss(),\n                 cur_learning_rate=1e-3,\n                 cur_weight_decay=1e-5,\n                 keys = ['2CH_ED', '2CH_ED_gt']):\n    '''\n    Most of this code is ripped out of Prof. Stough's code\n    Loop over data_iterator once\n    '''\n    \n    in_key, out_key = keys\n    \n    # Instantiate an optimizer and criterion\n    network.train()\n    \n    # reinit seed for augmentation\n    # https:\/\/github.com\/pytorch\/pytorch\/issues\/5059#issuecomment-404232359\n    np.random.seed()\n    \n    # Borrowing from: https:\/\/github.com\/L1aoXingyu\/pytorch-beginner\/blob\/master\/08-AutoEncoder\/conv_autoencoder.py\n    # criterion = nn.MSELoss()\n    # optimizer = torch.optim.Adam(net_ae.parameters(), \n    #                             lr=cur_learning_rate,\n    #                             weight_decay=cur_weight_decay)\n    if not optimizer:\n        optimizer = torch.optim.Adam(network.parameters(),\n                                     lr=cur_learning_rate,\n                                     weight_decay=cur_weight_decay)\n        \n    # Loss of model\n    running_loss = 0.0\n        \n    for i, data in enumerate(data_iterator):\n        \n        # get inputs\n        inputs, correct_outputs = torch.from_numpy(data[in_key]), torch.from_numpy(data[out_key])\n        \n        if torch.cuda.is_available:\n            inputs, correct_outputs = inputs.cuda(), correct_outputs.cuda()\n            \n        # wrap them in Variable?\n        #inputs, correct_outputs = Variable(inputs), Variable(correct_outputs)\n        \n        # get network output\n        net_outputs = network(inputs)\n        \n        # get loss\n        net_loss = criterion(net_outputs, correct_outputs)\n        \n        # https:\/\/discuss.pytorch.org\/t\/freezing-the-updates-without-freezing-the-gradients\/7358\n        # This discussion on a more complicated topic talks about how it's the loss object that \n        # updates the network gradients when you call backward. But how does the loss (criterion)\n        # even know what the network parameters are? It must be hidden in net_outputs...\n        # Basically this does the accumulation of gradients\n        net_loss.backward()\n        \n        if (i % effective_batchsize) == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        running_loss += net_loss.detach().cpu().item()\n        net_outputs = net_outputs.detach().cpu().numpy()\n        \n    avg_loss = running_loss \/ len(data_iterator)\n    one_output = net_outputs\n    one_input = inputs.detach().cpu().numpy()\n    one_correct_output = correct_outputs.detach().cpu().numpy()\n    \n    return avg_loss, one_output, one_input, one_correct_output","d6f16b6d":"**BASELINE MODEL**","6a1369a4":"**CATEGORICAL DATA EDA**","927f0c0a":"**IMAGE DATA**","b4a7d64e":"#Io[0,...].shape\nX = skimage.transform.resize(Io[0,...], [256,256])\nplt.imshow(X)","b12cd6a5":"In this notebook, I use *CAMUS Dataset*, the largest publicly-available and fully-annotated dataset for 2D echocardiographic assessment (to our knowledge). The CAMUS dataset contains 2D apical four-chamber and two-chamber view sequences acquired from 500 patients.\n\nhttps:\/\/www.creatis.insa-lyon.fr\/Challenge\/camus\/\n\n**Credits:**\nS. Leclerc, E. Smistad, J. Pedrosa, A. Ostvik, et al.\n\"Deep Learning for Segmentation using an Open Large-Scale Dataset in 2D Echocardiography\" in IEEE Transactions on Medical Imaging,\nearly acces, 2019\n\ndoi: 10.1109\/TMI.2019.2900516"}}