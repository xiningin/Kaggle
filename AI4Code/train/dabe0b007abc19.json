{"cell_type":{"7a0f414d":"code","ab3878a2":"code","b1a4f4b8":"code","94bcefe2":"code","9f196af8":"code","8daa1414":"code","d7394ece":"code","4a255d5f":"code","5ac2bd9b":"code","7d1689ca":"code","5947b695":"code","66adbfb5":"code","206f5d28":"markdown","e3058895":"markdown","a4ef36dc":"markdown","5ee8d3e1":"markdown","9a203dfe":"markdown","831db350":"markdown","860d5b7b":"markdown","fea9b0af":"markdown","e23129c2":"markdown","5483b12f":"markdown","319118a3":"markdown","4dd78b7d":"markdown","a6258945":"markdown","1ab44391":"markdown","e2969b51":"markdown","de37eb5b":"markdown","7813ff72":"markdown","f7a018a7":"markdown","9ee34347":"markdown","a8f7feb6":"markdown","7df83e6b":"markdown","bc503600":"markdown"},"source":{"7a0f414d":"from IPython.display import Image\nImage(\"..\/input\/neuralnetwork\/Screenshot from 2020-06-21 16-18-13.png\", width = '800px')","ab3878a2":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom PIL import Image\nfrom torch import optim\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms, models","b1a4f4b8":"# we are loading the dataset\ndata_dir = '..\/input\/leafdataset\/test'\n\n\ndef load_split_train_test(datadir, valid_size = .2):\n    train_transforms = transforms.Compose([#transforms.RandomRotation(30),  # data augmentations are great\n                                       #transforms.RandomResizedCrop(224),  # but not in this case of map tiles\n                                       #transforms.RandomHorizontalFlip(),\n                                       transforms.Resize(224),\n                                       transforms.ToTensor(),\n                                       #transforms.Normalize([0.485, 0.456, 0.406], # PyTorch recommends these but in this\n                                       #                     [0.229, 0.224, 0.225]) # case I didn't get good results\n                                       ])\n\n    test_transforms = transforms.Compose([transforms.Resize(224),\n                                      transforms.ToTensor(),\n                                      #transforms.Normalize([0.485, 0.456, 0.406],\n                                      #                     [0.229, 0.224, 0.225])\n                                      ])\n\n    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n    test_data = datasets.ImageFolder(datadir, transform=test_transforms)\n\n    num_train = len(train_data)\n    indices = list(range(num_train))\n    split = int(np.floor(valid_size * num_train))\n    np.random.shuffle(indices)\n    from torch.utils.data.sampler import SubsetRandomSampler\n    train_idx, test_idx = indices[split:], indices[:split]\n    train_sampler = SubsetRandomSampler(train_idx)\n    test_sampler = SubsetRandomSampler(test_idx)\n    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=64)\n    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=64)\n    return trainloader, testloader\n\ntrainloader, testloader = load_split_train_test(data_dir, .2)\nprint(trainloader.dataset.classes)","94bcefe2":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnet50(pretrained=True)","9f196af8":"# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.fc = nn.Sequential(nn.Linear(2048, 512),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(512, 10),\n                                 nn.LogSoftmax(dim=1))\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n# model.to(device)","8daa1414":"epochs = 20\nsteps = 0\nrunning_loss = 0\nprint_every = 10\ntrain_losses, test_losses = [], []\nfor epoch in range(epochs):\n    for inputs, labels in trainloader:\n\n        steps += 1\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        \n        if steps % print_every == 0:\n            test_loss = 0\n            accuracy = 0\n            model.eval()\n            with torch.no_grad():\n                for inputs, labels in testloader:\n\n                    inputs, labels = inputs.to(device),  labels.to(device)\n                    logps = model.forward(inputs)\n                    batch_loss = criterion(logps, labels)\n                    test_loss += batch_loss.item()\n                    \n                    ps = torch.exp(logps)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals =  top_class == labels.view(*top_class.shape)\n                    accuracy +=   torch.mean(equals.type(torch.FloatTensor)).item()\n            train_losses.append(running_loss\/len(trainloader))\n            test_losses.append(test_loss\/len(testloader))                    \n            print(f\"Epoch {epoch+1}\/{epochs}.. \"\n                  f\"Train loss: {running_loss\/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss\/len(testloader):.3f}.. \"\n                  f\"Test accuracy: {accuracy\/len(testloader):.3f}\")\n            running_loss = 0\n            model.train()\ntorch.save(model, 'leaf.pth')","d7394ece":"plt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)\nplt.show()","4a255d5f":"data_dir = '..\/input\/leafdataset\/test'\n\ntest_transforms = transforms.Compose([transforms.Resize(224),\n                                      transforms.ToTensor(),\n                                     ])","5ac2bd9b":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel=torch.load('leaf.pth')\n# model.eval()","7d1689ca":"def predict_image(image):\n    image_tensor = test_transforms(image).float()\n    image_tensor = image_tensor.unsqueeze_(0)\n    input = Variable(image_tensor)\n    input = input.to(device)\n    output = model(input)\n    index = output.data.cpu().numpy().argmax()\n    return index  ","5947b695":"def get_random_images(num):\n    data_dir = '..\/input\/leafdataset\/test'\n    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n    classes = data.classes\n    indices = list(range(len(data)))\n    np.random.shuffle(indices)\n    idx = indices[:num]\n    from torch.utils.data.sampler import SubsetRandomSampler\n    sampler = SubsetRandomSampler(idx)\n    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n    dataiter = iter(loader)\n    images, labels = dataiter.next()\n    return images, labels","66adbfb5":"classes = ['Tomato__Target_Spot','Tomato__Target_Spot','Tomato__Tomato_YellowLeaf__Curl_Virus','Tomato_Late_blight','Tomato_Leaf_Mold','Tomato_Septoria_leaf_spot','Tomato_Spider_mites_Two_spotted_spider_mite','Tomato__Target_Spot','Tomato__Tomato_mosaic_virus','Tomato__Tomato_YellowLeaf__Curl_Virus']\nto_pil = transforms.ToPILImage()\nimages, labels = get_random_images(3)\nfig=plt.figure(figsize=(10,10))\nfor ii in range(len(images)):\n    image = to_pil(images[ii])\n    index = predict_image(image)\n    sub = fig.add_subplot(1, len(images), ii+1)\n    res = int(labels[ii]) == index\n    sub.set_title(str(classes[index]) + \":\" + str(res))\n    plt.axis('off')\n    plt.imshow(image)\nplt.show()","206f5d28":"# CNN Architecture ","e3058895":"## The Input Layer, Hiden Layer, Output Layer can be customizable. \n## The Hidden layer can be a multilayer. When the layer is more then two Layer is called Deep Neural Network","a4ef36dc":"## Finally, to demo the prediction function, I get the random image sample, predict them and display the results:","5ee8d3e1":"## Checking, If the Cuda is Available or Not","9a203dfe":"## Next we\u2019ll determine whether we have GPU or not. I assume that if you\u2019re doing this you have a GPU-powered machine, otherwise the code will be at least 10 times slower. But it\u2019s a good idea to generalize and check for the GPU availability.","831db350":"# What is Deep Learning?\n## [Deep learning](https:\/\/en.wikipedia.org\/wiki\/Deep_learning) is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data. ... Deep learning allows machines to solve complex problems even when using a data set that is very diverse, unstructured and inter-connected.\n\n","860d5b7b":"## Now we\u2019re getting into the interesting part of the deep neural network. First, we have to freeze the pre-trained layers, so we don\u2019t backprop through them during training. Then, we re-define the final fully-connected the layer, the one that we\u2019ll train with our images. We also create the criterion (the loss function) and pick an optimizer (Adam in this case) and learning rate.","fea9b0af":"# Spliting the Dataset","e23129c2":"![](https:\/\/pytorch.org\/tutorials\/_images\/mnist.png)","5483b12f":"# What is Neural Network?\n## [Artificial neural networks](https:\/\/en.wikipedia.org\/wiki\/Neural_network) or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with task-specific rules. \n","319118a3":"## And now finally, let\u2019s train our model! There\u2019s just one epoch in this example but in most cases you\u2019ll need more. The basic process is quite intuitive from the code: You load the batches of images and do the feed forward loop. Then calculate the loss function, and use the optimizer to apply gradient descent in back-propagation.\n\n## It\u2019s that simple with PyTorch. Most of the code below deals with displaying the losses and calculate accuracy every 10 batches, so you get an update while training is running. During validation, don\u2019t forget to set the model to eval() mode, and then back to train() once you\u2019re finished.","4dd78b7d":"# Problem Statement\n## In this problem statement, We are going to classify 10 classes of Leaf disease using Pytorch","a6258945":"![](data:image\/png;base64,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)","1ab44391":"# Training the Model","e2969b51":"# Required Library","de37eb5b":"# ![Pytorch](data:image\/png;base64,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)","7813ff72":"## And\u2026 after you wait a few minutes (or more, depending on the size of your dataset and the number of epochs), training is done and the model is saved for later predictions!\n\n## There is one more thing you can do now, which is to plot the training and validation losses:","f7a018a7":"# Testing the model","9ee34347":"## The function that predicts the class of a specific image is very simple. Note that it requires a Pillow image, not a file path.","a8f7feb6":"# Available frame works \n\n## 1) [Tensorflow](https:\/\/www.tensorflow.org\/guide) \n## 2) [Pytorch](https:\/\/pytorch.org\/docs\/stable\/index.html)\n## 3) [Keras](https:\/\/keras.io\/)\n## 4) [Theano](http:\/\/deeplearning.net\/software\/theano\/)","7df83e6b":"## Now for easier testing, I also created a function that will pick a number of random images from the dataset folders:","bc503600":"# Neural Network From Scratch"}}