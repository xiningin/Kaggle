{"cell_type":{"d5404e73":"code","d4fb6318":"code","2bc16a3f":"code","e3521836":"code","118227d0":"code","8087348b":"code","1d877d22":"code","d5349a5c":"code","e351f44a":"code","f48e935e":"code","428e1789":"code","6ef93948":"code","169a899b":"code","943184c1":"code","74c74e88":"code","b499a4f3":"code","12565a1e":"code","597d82f0":"code","b184c421":"code","f8cab854":"code","22e2d2d0":"code","19dab498":"code","a4ffc6b9":"code","33f415f1":"code","66fc701a":"code","7264e53d":"code","5856041a":"code","2a490e5a":"code","dd756f6b":"markdown","da155040":"markdown","20fc7085":"markdown","e4fa7fda":"markdown","c86ef4ec":"markdown","91543f4a":"markdown","44b56bf0":"markdown"},"source":{"d5404e73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4fb6318":"from PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport json\nimport cv2\nimport matplotlib.pyplot as plt\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nimport torch.optim as optim\n%matplotlib inline","2bc16a3f":"path = '\/kaggle\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask'\nos.listdir(path)","e3521836":"categories = ['background']\nwith open(path + '\/meta.json') as f:\n    data = json.load(f)\n    for i in data['classes']:\n        categories.append(i['title'])","118227d0":"categories","8087348b":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","1d877d22":"dataset_path = path + '\/Medical Mask'\nos.listdir(dataset_path)","d5349a5c":"import random\n\nfrom torchvision.transforms import functional as F\n\n\nclass Compose(object):\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, image, target):\n        for t in self.transforms:\n            image, target = t(image, target)\n        return image, target\n\n\nclass RandomHorizontalFlip(object):\n    def __init__(self, prob):\n        self.prob = prob\n\n    def __call__(self, image, target):\n        if random.random() < self.prob:\n            height, width = image.shape[-2:]\n            image = image.flip(-1)\n            bbox = target[\"boxes\"]\n            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n            target[\"boxes\"] = bbox\n        return image, target\n\n\nclass ToTensor(object):\n    def __call__(self, image, target):\n        image = F.to_tensor(image)\n        return image, target","e351f44a":"class MaskDataset(Dataset):\n    \n    def __init__(self, path, categories, transform = None):\n        self.root = path\n        self.images = list(sorted(os.listdir(path + '\/images')))\n        self.annotations = list(sorted(os.listdir(path + '\/annotations')))\n        self.transforms = transform\n        self.categories = categories\n        \n    def __len__(self):\n        return len(self.annotations)\n    \n    def __getitem__(self, idx):\n\n        name_of_annnotation = self.annotations[idx]\n        \n        with open(self.root + '\/annotations\/'+name_of_annnotation) as f:\n            data = json.load(f)\n            \n            \n        bounding_boxes = []\n        labels = []\n        areas = []\n        image_name = data['FileName']\n        img = Image.open(self.root + '\/images\/' + image_name).convert(\"RGB\")\n        number_of_annotation = data['NumOfAnno']\n        anno = data['Annotations']\n        for i in anno:\n            #print(i['BoundingBox'])\n            x1,y1,x2,y2 = i['BoundingBox']\n            bounding_boxes.append([x1,y1,x2,y2])\n            labels.append(self.categories.index(i['classname']))\n            area = (x2 - x1) * (y2 - y1)\n            areas.append(area)\n            \n        target = {}\n        target['boxes'] = torch.as_tensor(bounding_boxes, dtype = torch.float32)\n        target['labels'] = torch.as_tensor(labels, dtype = torch.int64)\n        target['image_id'] = torch.as_tensor(int(image_name[:image_name.find('.')]), dtype = torch.int64)\n        target['area'] = torch.as_tensor(areas)\n        target['iscrowd'] = torch.zeros((number_of_annotation,), dtype = torch.int64)\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n            \n        return img, target","f48e935e":"def collate_fn(batch):\n    return tuple(zip(*batch))","428e1789":"def get_transform(train):\n    transforms = []\n    transforms.append(ToTensor())\n    if train:\n        transforms.append(RandomHorizontalFlip(0.5))\n    return Compose(transforms)","6ef93948":"batch_size = 2\nshuffle = True\nvalidation_split = 0.2\nrandom_seed = 42","169a899b":"dataset = MaskDataset(dataset_path,categories, get_transform(True))\nlength = len(dataset)\nindices = list(range(length))\nsplit_idx = int(np.floor(length * validation_split))\nif shuffle:\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n    \ntrain_idx, valid_idx = indices[split_idx:], indices[:split_idx]","943184c1":"train_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_data = DataLoader(dataset, batch_size = batch_size, sampler = train_sampler, collate_fn = collate_fn)\nvalid_data = DataLoader(dataset, batch_size = batch_size, sampler = valid_sampler, collate_fn = collate_fn)","74c74e88":"imgs, targets = next(iter(train_data))","b499a4f3":"def show_image(img, target):\n    img = img.clone().numpy()\n    img = img.transpose((1,2,0))\n    img = np.ascontiguousarray(img)\n    box_coords = target['boxes']\n    label = target['labels']\n    font = cv2.FONT_HERSHEY_SIMPLEX \n    fontscale = 0.6\n    for idx, i in enumerate(box_coords):\n\n        x1,y1,x2,y2 = map(int, i)\n        cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 1)\n        cv2.putText(img, categories[int(label[idx])],(max(0, x1 - 5), max(0, y1 - 5)), \n                    font, fontscale, (0,0,0), 1)\n    plt.figure(figsize = (15,15))\n    plt.imshow(img)","12565a1e":"show_image(imgs[0], targets[0])","597d82f0":"model = fasterrcnn_resnet50_fpn(pretrained = True)","b184c421":"num_classes = len(categories)\nin_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)","f8cab854":"epoch = 5\nlr = 0.0001\nmodel.to(device)\nparams = [param for param in model.parameters() if param.requires_grad]\noptimizer = optim.Adam(params, lr = lr)","22e2d2d0":"# Uncomment following code to train the model\n\n\"\"\"for i in range(epoch):\n    running_loss = 0\n    idx = 1\n    print(\"*\"*50)\n    print(\"Epoch : {}\/{}\".format(i + 1, epoch))\n    for images,targets in train_data:\n      if idx % 200 == 0:\n        print(f\"Iteration {idx}\/1731\")\n      optimizer.zero_grad()\n      images = [image.to(device) for image in images]\n      targets = [{key: value.to(device) for key,value in target.items()} for target in targets]\n      \n      output = model(images, targets)\n      \n      losses = sum(loss for loss in output.values())\n      running_loss += losses.item()\n      \n      losses.backward()\n      optimizer.step()\n      idx += 1\n\n    print(\"Loss after epoch {} is {:.4f}\".format(i + 1, running_loss\/len(train_data))) \"\"\"   ","19dab498":"path_to_model = '\/kaggle\/input\/model-weights-trained-on-colab'\nos.listdir(path_to_model)","a4ffc6b9":"# For CPU\n#model = torch.load(path_to_model+'\/complete-model.pth', map_location=torch.device('cpu'))\n# For GPU\nmodel = torch.load(path_to_model+'\/complete-model.pth')","33f415f1":"model","66fc701a":"test_csv = pd.read_csv('\/kaggle\/input\/face-mask-detection-dataset\/submission.csv')\ntest_csv.head()","7264e53d":"length = len(test_csv['name'])\ni = 0\nmodel.eval()\nwhile i < length:\n    name_of_file = test_csv['name'][i]\n    img = Image.open(dataset_path+'\/images\/'+name_of_file).convert(\"RGB\")\n    img = F.to_tensor(img)\n    count = len(test_csv[test_csv['name'] == name_of_file])\n    print(f\"Doing inference on image {name_of_file}\")\n    with torch.no_grad():\n        predictions = model([img.to(device)])\n        for j in range(count):\n            print(f\"Getting {j} inference on {name_of_file} \")\n            try:\n                preds = list(map(int, predictions[0]['boxes'][j].to('cpu').numpy()))\n                label = categories[predictions[0]['labels'][j].item()]\n                test_csv.loc[i + j, 'x1'], test_csv.loc[i + j, 'x2'], test_csv.loc[i + j,'y1'], test_csv.loc[i + j,'y2'] = preds \n                test_csv.loc[i + j, 'classname'] = label\n            except:\n                continue\n    i += count","5856041a":"test_csv.tail()","2a490e5a":"test_csv.to_csv('submission.csv', index = False)","dd756f6b":"## Visualizing the dataset","da155040":"# Some Helper Functions (Used from Pytorch official documentation)","20fc7085":"## Loading, Preprocessing and splitting the data","e4fa7fda":"## Importing Libraries","c86ef4ec":"## Defining and training the model","91543f4a":"## Inference","44b56bf0":"## Defining path for directory and categories for object detection"}}