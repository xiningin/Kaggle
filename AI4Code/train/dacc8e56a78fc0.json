{"cell_type":{"caaf5bc0":"code","98e483bf":"code","5b950cf5":"code","3d6f693c":"code","dc548f31":"code","e7943c78":"code","62187bc1":"code","f474efa6":"code","f36694ff":"code","d285c7cf":"code","86111745":"code","62814117":"code","f08aa2f4":"code","86df4008":"code","b5e92f9c":"code","38a7ab49":"code","f2f33796":"code","913bdb1f":"code","f03a7944":"code","e23f7640":"code","e5d4697b":"code","230ed3e0":"code","9b879fe3":"code","991c928f":"code","6e60b33c":"code","afedb79d":"code","85aebaad":"code","4419c00e":"code","6f7c2774":"code","57b13965":"code","df4d5f1f":"code","66d4a6eb":"code","a47f2cbd":"markdown","b74d684d":"markdown","ef8723d0":"markdown","56a146b8":"markdown","eee9e941":"markdown","dc7c8a64":"markdown","5000a0fe":"markdown","be1f8bc1":"markdown","c8f100fc":"markdown","734827c3":"markdown","ff2e1e71":"markdown"},"source":{"caaf5bc0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\nfrom sklearn.metrics import confusion_matrix, classification_report","98e483bf":"test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","5b950cf5":"train.head(10)","3d6f693c":"test.head(10)","dc548f31":"propSurv_0 = np.mean(train.Survived == 0)\npropSurv_1 = np.mean(train.Survived == 1)\n\nprint('Proportion in Class 0:', round(propSurv_0, 4))\nprint('Proportion in Class 1:', round(propSurv_1, 4))","e7943c78":"train.isna().sum(axis=0)","62187bc1":"test.isna().sum(axis=0)","f474efa6":"# Add FamSize Column\ntrain.loc[:,'FamSize'] = train.loc[:,'SibSp'] + train.loc[:,'Parch']\ntest.loc[:,'FamSize'] = train.loc[:,'SibSp'] + train.loc[:,'Parch']\n\n# Add Deck Column\ndef set_deck(cabin):\n    if str(cabin) == 'nan':\n        return 'Missing'\n    return cabin[0]\n\ntrain.loc[:, 'Deck'] = train.Cabin.map(set_deck)\ntest.loc[:, 'Deck'] = test.Cabin.map(set_deck)\n\ntrain.head(10)","f36694ff":"num_features = ['Age', 'FamSize']\ncat_features = ['Sex', 'Pclass', 'Deck']\nfeatures = num_features + cat_features\n\nnum_transformer = Pipeline(\n    steps = [\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', MinMaxScaler())  \n    ]\n)\n\ncat_transformer = Pipeline(\n    steps = [\n        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ]\n)\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('num', num_transformer, num_features),\n        ('cat', cat_transformer, cat_features)\n    ]\n)","d285c7cf":"preprocessor.fit(train[features])\nX_train = preprocessor.transform(train[features])\nX_test = preprocessor.transform(test[features])\n\ny_train = train.Survived.values\n\nprint('X_train shape:', X_train.shape)\nprint('y_train shape:', y_train.shape)\nprint('X_test shape: ', X_test.shape)","86111745":"np.set_printoptions(linewidth=200)\nprint(X_train[:10])","62814117":"pd.set_option('display.max_columns', None)\ntemp1 = train[features]\ntemp2 = pd.DataFrame(\n    X_train,\n    columns = ['Age_sc', 'FamSize_sc', 'F', 'M', 'PC1', 'PC2', 'PC3', \n               'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'missing']\n)\n\ncombined_df = pd.concat([temp1, temp2], axis=1) \ncombined_df.sample(10)","f08aa2f4":"lr_mod = LogisticRegression(solver='liblinear')\nlr_mod.fit(X_train, y_train)\nprint(lr_mod.score(X_train, y_train))","86df4008":"# 1  2  3  4  5\n# V  T  T  T  T  --> Val_Score_1\n# T  V  T  T  T  --> Val_Score_2\n# T  T  V  T  T  --> Val_Score_3\n# T  T  T  V  T  --> Val_Score_4\n# T  T  T  T  V  --> Val_Score_5\n\n# cv_score = average","b5e92f9c":"# Scoring with Cross-Validation\nlr_cv_results = cross_val_score(lr_mod, X_train, y_train, cv=10, scoring='accuracy')\n\nprint('Validation Accuracy by fold: ', lr_cv_results)\nprint('Average Validation Accuracy: ', np.mean(lr_cv_results))","38a7ab49":"lr_param_grid = {\n    #'penalty': ['l1', 'l2'],\n    'C': [0.001, 0.1, 1, 10]\n}\n\nlr_grid_search = GridSearchCV(lr_mod, lr_param_grid, cv=10, refit='True')\nlr_grid_search.fit(X_train, y_train)\n\nlr_gs_res = lr_grid_search.cv_results_\n\nprint(lr_gs_res.keys())","f2f33796":"for k, v in lr_gs_res.items():\n    print(f'{k:<20}{v}')","913bdb1f":"print(lr_gs_res['mean_test_score'])","f03a7944":"for params, score in zip(lr_gs_res['params'], lr_gs_res['mean_test_score']):\n    print(params, '\\t', score)","e23f7640":"print(lr_grid_search.best_score_)\nprint(lr_grid_search.best_params_)","e5d4697b":"best_lr_model = lr_grid_search.best_estimator_\nprint(best_lr_model.score(X_train, y_train))","230ed3e0":"dtree = DecisionTreeClassifier(random_state=1)\n\ndt_param_grid = {\n    'max_depth': [2, 4, 6, 8, 10, 12],\n    'min_samples_leaf': [2, 4, 8, 16]\n}\n\ndt_grid_search = GridSearchCV(dtree, dt_param_grid, cv=10, refit='True')\ndt_grid_search.fit(X_train, y_train)\n\ndt_gs_res = dt_grid_search.cv_results_","9b879fe3":"for params, score in zip(dt_gs_res['params'], dt_gs_res['mean_test_score']):\n    print(params, '\\t', score)","991c928f":"print(dt_grid_search.best_score_)\nprint(dt_grid_search.best_params_)","6e60b33c":"%%time\nforest = RandomForestClassifier(random_state=1, n_estimators=100)\n\nrf_param_grid = {\n    #'n_estimators' : [100, 200, 300, 400, 500],\n    'max_depth': [6, 8, 10, 12],\n    'min_samples_leaf': [2, 4, 8]\n}\n\nrf_grid_search = GridSearchCV(forest, rf_param_grid, cv=10, refit='True')\nrf_grid_search.fit(X_train, y_train)\n\nrf_gs_res = rf_grid_search.cv_results_","afedb79d":"for params, score in zip(rf_gs_res['params'], rf_gs_res['mean_test_score']):\n    print(params, '\\t', score)","85aebaad":"print(rf_grid_search.best_score_)\nprint(rf_grid_search.best_params_)","4419c00e":"best_forest_mod = rf_grid_search.best_estimator_\nprint(best_forest_mod.score(X_train, y_train))","6f7c2774":"gender_submission = test = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ngender_submission.head()","57b13965":"test_pred = best_forest_mod.predict(X_test)\nprint(test_pred[:50])","df4d5f1f":"submission = pd.DataFrame({\n    'PassengerID' : test.PassengerId,\n    'Survived' : test_pred\n})\nsubmission.head()","66d4a6eb":"submission.to_csv('my_submission.csv', index=False)","a47f2cbd":"## Preprocessing","b74d684d":"## Random Forests: Hyper-Parameter Tuning","ef8723d0":"## Create New Features\n","56a146b8":"## Check for Missing Values","eee9e941":"# Logistic Regression","dc7c8a64":"## Import Packages","5000a0fe":"## Decision Trees: Hyper-Parameter Tuning","be1f8bc1":"# Titanic Dataset","c8f100fc":"## Load Data","734827c3":"## Generate Test Predictions","ff2e1e71":"# Logistic Regression: Hyper-Parameter Tuning"}}