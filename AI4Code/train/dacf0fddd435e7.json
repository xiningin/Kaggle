{"cell_type":{"f5537f5c":"code","95a4bfbd":"code","4c11f1c0":"code","674462ac":"code","d587ba27":"code","bf7ddedf":"code","2a7e9b88":"code","0f3c96f6":"code","3e12fbd2":"code","fe1baa27":"code","51d341dc":"code","23ab5d64":"code","28c6d1cf":"code","e8264071":"markdown","41399b49":"markdown","7ec518d5":"markdown","19313bee":"markdown","22f5f972":"markdown","157085aa":"markdown","4e12247f":"markdown","3e0d1d32":"markdown","3781893d":"markdown","d9ed4c71":"markdown","3c5ecdca":"markdown","848558cd":"markdown","b97cb65c":"markdown","81dee25c":"markdown"},"source":{"f5537f5c":"# Importing all the important Libraries\nimport numpy as np\nimport pandas as pd\nimport math\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n%matplotlib inline","95a4bfbd":"# Loading Dataset\ndf = pd.read_csv('..\/input\/student-scores\/dataset.csv')\nprint('Shape:', df.shape)\ndf.head()","4c11f1c0":"# Vizualizing Data\ndf.plot(x='Hours', y='Scores', style='o')\nplt.title('Hours vs Percentage')\nplt.xlabel('Hours Studied')\nplt.ylabel('Percentage Score')\nplt.show()\nplt.savefig('datasetVizualization.png')","674462ac":"# Dividing the dataset columns. \n# Hours in X and Scores in y\nX = df.iloc[:, :-1].values    \ny = df.iloc[:, 1].values","d587ba27":"# Split Data into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","bf7ddedf":"# Linear Regression Model\nlr = LinearRegression()    \nlr.fit(X_train, y_train)\nprint('Linear Regression Model Trained Successfully!')","2a7e9b88":"# Getting B0 and B1\nprint('coef_ :', lr.coef_)\nprint('intercept_ :', lr.intercept_)","0f3c96f6":"# Plotting a Regression Line\nregression_line = lr.coef_* X + lr.intercept_\nplt.scatter(X, y)\nplt.title('Hours vs Percentage')\nplt.xlabel('Hours Studied')\nplt.ylabel('Percentage Score')\nplt.plot(X, regression_line, color='orange')\nplt.show()\nplt.savefig('regressionLine.png')","3e12fbd2":"# Prediction\ny_pred = lr.predict(X_test)","fe1baa27":"# Actual Score vs Predicted Score\nnew_df = pd.DataFrame({'Actual Score': y_test, \n                       'Predicted Score': y_pred})\nnew_df","51d341dc":"fig, ax = plt.subplots()\nindex = np.arange(len(X_test))\nbar_width = 0.35\nactual = plt.bar(index, new_df['Actual Score'], bar_width, label='Actual Score')\n\npredicted = plt.bar(index + bar_width, new_df['Predicted Score'], bar_width, label='Predicted Score')\n\nplt.xlabel('Hours')\nplt.ylabel('Scores')\nplt.title('Actual vs Predicted Scores')\nplt.xticks(index + bar_width, X_test)\nplt.legend()\nplt.show()\nplt.savefig('actualvspredicted.png')","23ab5d64":"# Model Evaluation\nprint('Mean Absolute Error MAE:', mean_absolute_error(y_test, y_pred))\nprint('\\nMean Squared Error MSE:', mean_squared_error(y_test, y_pred))\nprint('\\nRoot Mean Squared Error RMSE:', math.sqrt(mean_squared_error(y_test, y_pred)))\nprint('\\nR2 Score:', r2_score(y_test, y_pred))","28c6d1cf":"# Predicted score if a student studies for 9.25 hrs\/day\n# input_hours = input('Enter number of hours for predicting the score: ')\ninput_hours = 9.25\ninput_hours = float(input_hours)\nhours = np.array([input_hours])\nhours = hours.reshape(-1, 1)\npred_score = lr.predict(hours)\nprint(\"Number of Hours =\", input_hours, 'hours\/day')\nprint(\"Predicted Score = {:.4}\".format(pred_score[0]))","e8264071":"## Prediction\nUsing the trained Linear Regression Model to predict scores for test data and compare the results.","41399b49":"## Linear Regression\nLinear regression is probably one of the most important and widely used regression techniques. It\u2019s among the simplest regression methods. One of its main advantages is the ease of interpreting results.\n\nLinear regression is a statistical approach for modelling relationship between a dependent variable with a given set of independent variables.\n\nIt is assumed that the two variables are linearly related. Hence, we try to find a linear function that predicts the response value(y) as accurately as possible as a function of the feature or independent variable(x).\n\nLet's define,<br>\nx as feature vector, i.e x = [x<sub>1<\/sub>, x<sub>2<\/sub>, ..., x<sub>n<\/sub>],<br>\ny as response vector, i.e y = [y<sub>1<\/sub>, y<sub>2<\/sub>, ..., y<sub>n<\/sub>]<br>\n\nNow, the task is to find a line which fits best in above scatter plot so that we can predict the response for any new feature values. (i.e a value of x not present in dataset). This line is called regression line.\n\nThe equation of regression line is represented as:\n\n **h(x<sub>i<\/sub>) = \u03b2<sub>0<\/sub> + \u03b2<sub>1<\/sub>x<sub>i<\/sub>** \n\nThe linear equation assigns one scale factor to each input value or column, called a coefficient and represented by the capital Greek letter Beta (\u03b2). One additional coefficient is also added, giving the line an additional degree of freedom (e.g. moving up and down on a two-dimensional plot) and is often called the intercept or the bias coefficient.","7ec518d5":"# Prediction using Supervised ML\n## (Level - Beginner)\n\n\n---\n\n\n**Aim :** Predict the percentage of a student based on the no. of study hours. <br>\n**Dataset :** Data can be found at http:\/\/bit.ly\/w-data <br>\n\nWhat will be predicted score if a student studies for 9.25 hrs\/day? <br>\n\n\n---\n\n","19313bee":"## Comaprison of various test sizes\n<table>\n  <tr>\n    <th>Test No.<\/th>\n    <th>Test Size<\/th>\n    <th>MAE<\/th>\n    <th>MSE<\/th>\n    <th>RMSE<\/th>\n    <th>R2 Score<\/th>\n    <th>Predicted Score<\/th>\n  <\/tr>\n  <tr>\n    <td>1<\/td>\n    <td>0.2<\/td>\n    <td>4.183859899002982<\/td>\n    <td>21.598769307217456<\/td>\n    <td>4.647447612100373<\/td>\n    <td>0.9454906892105354<\/td>\n    <td>93.69<\/td>\n  <\/tr>\n  <tr>\n    <td>2<\/td>\n    <td>0.25<\/td>\n    <td>4.130879918502482<\/td>\n    <td>20.33292367497996<\/td>\n    <td>4.509204328368805<\/td>\n    <td>0.9367661043365056<\/td>\n    <td>93.89<\/td>\n  <\/tr>\n  <tr>\n    <td>3<\/td>\n    <td>0.3<\/td>\n    <td>4.419727808027651<\/td>\n    <td>22.965097212700428<\/td>\n    <td>4.7921912746363144<\/td>\n    <td>0.9568211104435257<\/td>\n    <td>92.92<\/td>\n  <\/tr>\n  <tr>\n    <td>4<\/td>\n    <td>0.35<\/td>\n    <td>4.691397441397446<\/td>\n    <td>25.463280738222593<\/td>\n    <td>5.046115410711748<\/td>\n    <td>0.9555700801388128<\/td>\n    <td>92.15<\/td>\n  <\/tr>\n  <tr>\n    <td>5<\/td>\n    <td>0.4<\/td>\n    <td>4.8945108634106065<\/td>\n    <td>26.034569687682232<\/td>\n    <td>5.102408224327237<\/td>\n    <td>0.956640847232559<\/td>\n    <td>92.66<\/td>\n  <\/tr>\n<\/table>","22f5f972":"## References\n1. https:\/\/numpy.org\/\n2. https:\/\/pandas.pydata.org\/\n3. https:\/\/matplotlib.org\/\n4. https:\/\/seaborn.pydata.org\/\n5. https:\/\/scikit-learn.org\/","157085aa":"## Linear Regression Model\nLinearRegression fits a linear model with coefficients w = (w1, \u2026, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.\n\nWith Scikit-Learn it is extremely straight forward to implement linear regression models, as all you really need to do is import the LinearRegression class, instantiate it, and call the fit() method along with our training data. ","4e12247f":"## Preparing the data\nHere, we store the values of attribute 'Hours' in X and label 'Scores' in y.","3e0d1d32":"## Plotting a Regression Line\nUsing line equation, **h(x<sub>i<\/sub>) = \u03b2<sub>0<\/sub> + \u03b2<sub>1<\/sub>x<sub>i<\/sub>** <br>\nregression_line = LinearRegression().coef_*X + LinearRegression().intercept_\n\n**coef_ : array of shape (n_features, ) or (n_targets, n_features)**<br>\nIt is used to estimate the coefficients for the linear regression problem. It would be a 2D array of shape (n_targets, n_features) if multiple targets are passed during fit. Ex. (y 2D). On the other hand, it would be a 1D array of length (n_features) if only one target is passed during fit.\n\n**intercept_ : float or array of shape (n_targets,)**<br>\nIndependent term in the linear model. Set to 0.0 if fit_intercept = False.\n\nThe value \u03b2<sub>1<\/sub> = 9.9106 (approximately) means that the predicted response rises by 9.9106 when \ud835\udc65 is increased by one.<br>\nThe value \u03b2<sub>0<\/sub> = 2.0181 (approximately) illustrates that the model predicts the response 2.0181 when \ud835\udc65 is zero.","3781893d":"## Splitting Datset\nThe split of data into the training and test sets is very important. We use Scikit Learn's built-in method of train_test_split() from model_selection.\n\nThe test size is kept 0.3 which indicates that 70% of data is used for training and remaining 30% of data is used for testing purpose.","d9ed4c71":"## Model Evaluation\nThe final step is to evaluate the performance of algorithm.\n\n**Mean Absolute Error (MAE)** is the mean of the absolute value of the errors. It is calculated as:<br>\n![mae.png](data:image\/png;base64,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)\n\n**Mean Squared Error (MSE)** is the mean of the squared errors and is calculated as:<br>\n![mse.png](data:image\/png;base64,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)\n\n**Root Mean Squared Error (RMSE)** is the square root of the mean of the squared errors:<br>![rmse.png](data:image\/png;base64,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)\n\n**R2 Score** is a statistical method that determines the goodness of fit.<br>\nThe high value of R-square determines the less difference between the predicted values and actual values and hence represents a good model.\n","3c5ecdca":"## Loading Dataset\nThe dataset is available at http:\/\/bit.ly\/w-data. \n\nThe dataset consists of 25 records with 2 columns as 'Hours' representing the number of hours studied per day and 'Scores' representing the scores obtained by student.","848558cd":"## Libraries\nNumPy to perform the multi-dimensional operation.\n\nPandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool.\n\nSeaborn and Matplotlib used for plotting and vizualization of data.\n\nScikit is used for splitting dataset into training and testing, predicting a continuous-valued attribute associated with an object and also evaluation of trained model.","b97cb65c":"## Predicted score if a student studies for 9.25 hrs\/day","81dee25c":"## Supervised Machine Learning\nSupervised learning deals with or learns with \"labeled\" data. In simple terms, it learns from presentable examples.\nSupervised learning classified into two categories of algorithms: \n1. **Classification :** A classification problem is when the output variable is a category, such as \"positive\" and \"negative\" or \"mask\" and \"no mask\". It is discrete in nature.\n2. **Regression :** A regression problem is when the output variable is a real value, such as \"rupees\",\"weight\" or \"scores\". It is continuous in nature."}}