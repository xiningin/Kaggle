{"cell_type":{"89b78acf":"code","6ccc83af":"code","07e91a90":"code","8c064725":"code","82b645c7":"code","a821e1e4":"code","ed4ccaec":"code","8d8e2502":"code","d7e45d1e":"code","3e7952a4":"code","69df8294":"code","4123c855":"code","ecb7e58f":"code","a3545762":"code","52f0a316":"code","2cd74cbd":"code","5f9c68d6":"code","47d86b1a":"code","c278e56c":"code","a3b57037":"code","c8a2d091":"markdown","2f4c50df":"markdown","2432bfbb":"markdown"},"source":{"89b78acf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6ccc83af":"#importing the dataset\ndataset = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/audi.csv')\ndataset.head(10)","07e91a90":"dataset.describe()","8c064725":"dataset.info()","82b645c7":"dataset.isnull().sum()","a821e1e4":"# X and y variables\n\ny = dataset['price'].values\nX = dataset.drop('price',axis=1).values","ed4ccaec":"print(X)","8d8e2502":"print(y)","d7e45d1e":"#1. model\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX[:, 0] = le.fit_transform(X[:, 0])# model","3e7952a4":"#2. transmission\nX[:, 2] = le.fit_transform(X[:, 2]) #transmission","69df8294":"#OneHotEncoder for the fuelType\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [4])], remainder = 'passthrough')\n\nX = np.array(ct.fit_transform(X)) ","4123c855":"print(X)\nprint('------->')\nprint(y)","ecb7e58f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","a3545762":"#multiple linear regression\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\nreg = LinearRegression()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\n\nr2_score(y_test, y_pred)","52f0a316":"#decision tree\nfrom sklearn.tree import DecisionTreeRegressor\nreg = DecisionTreeRegressor(random_state = 1)\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\n\nr2_score(y_test, y_pred)","2cd74cbd":"#random forest\nfrom sklearn.ensemble import RandomForestRegressor\nreg = RandomForestRegressor(n_estimators = 10, random_state = 1)\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\n\nr2_score(y_test, y_pred)","5f9c68d6":"#random forest tuning\nfrom sklearn.ensemble import RandomForestRegressor\nreg = RandomForestRegressor(n_estimators = 20, random_state = 1,criterion='mae')\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\n\nr2_score(y_test, y_pred)","47d86b1a":"\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","c278e56c":"from xgboost import XGBRegressor\nreg = XGBRegressor()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\n\nr2_score(y_test, y_pred)","a3b57037":"\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","c8a2d091":"### Splitting into train and test sets","2f4c50df":"### Training models on the dataset","2432bfbb":"### Encoding Categorical Data"}}