{"cell_type":{"00fc6135":"code","bc17f90c":"code","b6cf3acd":"code","2323253c":"code","c9eb34d8":"code","fdeb4dfe":"code","96974225":"code","da4ce5c3":"code","d1ac4ae2":"code","bd74035e":"code","fef3c90a":"code","7aee349b":"code","c7a6abc3":"code","69ef3b13":"code","4fb4a81c":"code","5c7f1809":"code","a44016ef":"code","6e8c20c5":"code","08958ae8":"code","e1c91dd2":"code","bb91f13d":"code","873200a3":"code","3288ae21":"code","b16720a7":"code","9fcecca8":"code","6b3769ad":"code","3bdeab7d":"code","93e66d73":"code","c2c22e3a":"code","5c5e9910":"markdown"},"source":{"00fc6135":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc17f90c":"os.chdir(\"..\/input\")\nos.listdir()","b6cf3acd":"df=pd.read_csv(\"..\/input\/qsarbiodegradation\/qsar-biodeg.csv\")","2323253c":"from warnings import filterwarnings\nfilterwarnings('ignore')","c9eb34d8":"df.head()","fdeb4dfe":"df.info()","96974225":"df.isnull().sum()","da4ce5c3":"df[\"Class\"].value_counts() \n# eady biodegradable (RB) and not ready biodegradable (NRB)\n# RB:2 NRB:1","d1ac4ae2":"df.Class=[1 if each ==2 else 0 for each in df.Class]","bd74035e":"df[\"Class\"].value_counts() \n# eady biodegradable (RB) and not ready biodegradable (NRB)\n# RB:1 NRB:0","fef3c90a":"y = df[\"Class\"].values\nX = df.drop(['Class'], axis=1)","7aee349b":"# Data Standardization\nfrom sklearn.preprocessing import StandardScaler\nScaler=StandardScaler()\nX=Scaler.fit_transform(X)\n\nX[0:3]","c7a6abc3":"from sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.layers import LeakyReLU\n\n\n# Train-Test \nfrom sklearn.model_selection import train_test_split\n# shuffle and split training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n                                                    random_state=42)","69ef3b13":"def create_model(optimizer=\"adam\"):\n    # create model\n    model = Sequential()\n    model.add(Dense(32, input_dim=41, activation=LeakyReLU()))\n    model.add(Dropout(0.4))\n    model.add(Dense(27, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(7, activation='sigmoid'))\n    model.add(Dropout(0.2))\n    model.add(Dense(27, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(1, activation='sigmoid')) # Since it has 2 outputs, 'sigmoid' as activation in the output layer\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n    return model\nmodel = create_model() ","4fb4a81c":"train=model.fit(X_train, y_train, epochs=100, batch_size=100, verbose=0,validation_data=(X_test,y_test))","5c7f1809":"# plot loss during training\nimport matplotlib.pyplot as plt\nplt.plot(train.history['loss'], label='train')\nplt.plot(train.history['val_loss'], label='test')\nplt.title('Model Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss values')\nplt.legend(loc='upper right')\nplt.show()","a44016ef":"# Untunned Scores of the Model\nimport sklearn.metrics as metrics\ny_pred=model.predict_classes(X_test)","6e8c20c5":"# %%Accuracy\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n\n# %%f1 score\n\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))","08958ae8":"# Grid Search Cross Validation\n# GridSearch Cross Validation Parameters\nparam_grid = {\n   \n    'epochs': [100,150,200],\n    'batch_size':[32,100,128],\n    'optimizer':['RMSprop', 'Adam','SGD'],\n    \n}\n\n# create model\n\n# Creating Model Object with KerasClassifier\nmodel_cv = KerasClassifier(build_fn=create_model, verbose=0)\n\n\ngrid = GridSearchCV(estimator=model_cv,  \n                    n_jobs=-1, \n                    verbose=1,\n                    cv=5,\n                    param_grid=param_grid)\n\ngrid_cv_model = grid.fit(X_train, y_train,) # Fitting the GridSearch Object on the Train Set\n\n\nmeans = grid_cv_model.cv_results_['mean_test_score'] # Mean of test scores\nstds = grid_cv_model.cv_results_['std_test_score'] # standard deviations of test scores\nparams = grid_cv_model.cv_results_['params'] # parameters used\n# to print all scores, standard deviations and parameters used\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n\n# Printing the Best Parameters as a Result of Grid Search Cross Validation on the Screen\nprint(\"Best: %f using %s\" % (grid_cv_model.best_score_, grid_cv_model.best_params_))","e1c91dd2":"# %% Model Tuning- Building a Tuned Model with Best Parameters\n# Creating Tuned Model Object with KerasClassifier\ncv_model = grid_cv_model.best_estimator_","bb91f13d":"#%% K-FOLD\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n# K-fold accuracy scores\n\nkfold = KFold(n_splits=5, shuffle=True)\nresults = cross_val_score(cv_model, X_test, y_test, cv=kfold,scoring= 'accuracy')","873200a3":"print('K-fold Cross Validation Accuracy Results: ', results)\nprint('K-fold Cross Validation Accuracy Results Mean: ', results.mean())","3288ae21":"# K-fold f1 scores\nfrom sklearn.model_selection import KFold\n\n\nkfold = KFold(n_splits=5, shuffle=True)\nresults = cross_val_score(cv_model, X_test,y_test, cv=kfold,scoring=\"f1_weighted\")","b16720a7":"print('K-fold Cross Validation f1_weighted Results: ', results)\nprint('K-fold Cross Validation f1_weighted Results Mean: ', results.mean())","9fcecca8":"# Tuned Model Prediction\n\ny_pred = cv_model.predict(X_test)","6b3769ad":"# %% f1 score\nimport sklearn.metrics as metrics\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))\n\n\n# %% Accuracy\n\nprint(\"accuracy:\",metrics.accuracy_score(y_test, y_pred))","3bdeab7d":"#%% Confusion Matrix and Classification Report\nfrom sklearn.metrics import confusion_matrix, classification_report \n\n# Classification Report\nmodel_report = classification_report(y_test, y_pred)\nprint(model_report)","93e66d73":"# Confusion Matrix\n# multilabel-indicator is not supported so np.argmax should be used!\nmodel_conf = confusion_matrix(y_test,y_pred)\nprint(model_conf)","c2c22e3a":"#%% ROC-AUC Curve\nimport matplotlib.pyplot as plt\n\n\n\nprobs=cv_model.predict_proba(X_test)\nfpr,tpr,threshold=metrics.roc_curve(y_test,y_pred)\nroc_auc=metrics.auc(fpr,tpr)\n\n\n\n\nplt.title(\"ROC\")\nplt.plot(fpr,tpr,label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy',  linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","5c5e9910":"## Modeling"}}