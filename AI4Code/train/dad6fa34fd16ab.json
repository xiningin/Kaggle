{"cell_type":{"aa47f269":"code","5eed255c":"code","c6a34e69":"code","51df2f2d":"code","c671822f":"code","2338447d":"code","b54184f3":"code","89a08b1b":"code","aaf7bff4":"code","299d069d":"code","c77bd6ea":"code","09808b43":"code","21a1dba5":"code","76256d3e":"code","291d7e05":"code","5357fb90":"code","2874b1d1":"code","6d383e86":"code","4cc92b25":"code","a8ee75c1":"code","6937a97c":"code","b5a859dc":"code","46169b09":"code","aabd25d1":"code","46283b73":"markdown","4b391913":"markdown","40e208dc":"markdown","ea5910e9":"markdown","39492a07":"markdown","36d1f7f3":"markdown","01c62ef4":"markdown","f5733235":"markdown","d1336678":"markdown","59b78366":"markdown","5c6b2352":"markdown","dd0b80c8":"markdown","bef654b7":"markdown","13b376a4":"markdown","011f81da":"markdown","3b3e56f2":"markdown"},"source":{"aa47f269":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5eed255c":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport json\nimport cv2","c6a34e69":"train_data_dir = \"..\/input\/flower_data\/flower_data\/train\/\"\ntest_data_dir = \"..\/input\/flower_data\/flower_data\/valid\/\"\nfile_path = \"..\/input\/cat_to_name.json\"","51df2f2d":"df = pd.read_json(file_path, typ='series')\ndf = df.to_frame('category')\ndf.head()","c671822f":"df.count()","2338447d":"img_dir = os.path.join(train_data_dir, str(np.random.randint(1, 103)))\n\nfor img_name in os.listdir(img_dir)[1:2]:\n    img_array = cv2.imread(os.path.join(img_dir, img_name))\n    img_array = cv2.resize(img_array, (225,225), interpolation=cv2.INTER_AREA)\n    plt.imshow(img_array)\n    plt.show()\n    print(img_array.shape)","b54184f3":"train_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([transforms.Resize(225),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])","89a08b1b":"train_data = datasets.ImageFolder(train_data_dir, transform=train_transforms)\ntest_data = datasets.ImageFolder(test_data_dir, transform=test_transforms)","aaf7bff4":"print(\"Number of Training images: \", len(train_data))\nprint(\"Number of Test images: \", len(test_data))","299d069d":"trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)","c77bd6ea":"model1 = models.densenet121(pretrained=True)","09808b43":"for params in model1.features.parameters():\n    params.requires_grad = False","21a1dba5":"model1.classifier = nn.Sequential(nn.Linear(1024, 256),\n                                  nn.ReLU(),\n                                  nn.Dropout(0.2),\n                                  nn.Linear(256, 102),\n                                  nn.LogSoftmax(dim=1))","76256d3e":"criterion = nn.NLLLoss()\n\noptimizer = optim.Adam(model1.classifier.parameters(), lr=0.003)","291d7e05":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel1.to(device)\ndevice","5357fb90":"epochs = 25\nsteps = 0\nrunning_loss = 0\nprint_every = 50\ntraining_loss = []\nTest_loss = []\nfor e in range(epochs):\n    for images, labels in trainloader:\n        steps += 1\n        \n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        y_pred = model1.forward(images)\n        loss = criterion(y_pred, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        accuracy = 0\n        if steps % print_every == 0:\n            test_loss = 0\n            \n            model1.eval()\n            \n            with torch.no_grad():\n                for images, labels in testloader:\n                    images, labels = images.to(device), labels.to(device)\n                    y_pred = model1.forward(images)\n                    batch_loss = criterion(y_pred, labels)\n                    \n                    test_loss += batch_loss.item()\n                    \n                    ps = torch.exp(y_pred)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n                \n                \n                  \n                print(f\"Epoch {e+1}\/{epochs}.. \"\n                  f\"Train loss: {running_loss\/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss\/len(testloader):.3f}.. \"\n                  f\"Test accuracy: {accuracy\/len(testloader):.3f}\")\n                \n                training_loss.append(running_loss)\n                running_loss = 0\n                model1.train()\n            Test_loss.append(test_loss)","2874b1d1":"torch.save(model1.state_dict(), 'model1.pth')","6d383e86":"data_dir = \"..\/input\/test set\/\"\n\ndata = datasets.ImageFolder(data_dir, transform=test_transforms)\ndataloader = torch.utils.data.DataLoader(data)","4cc92b25":"data_labels = []\nmodel1.to(device)\nmodel1.eval()\nwith torch.no_grad():\n    for images, labels in dataloader:\n        images = images.to(device)\n        ps = model1.forward(images)\n        \n        if type(ps) == tuple:\n            ps, _ = ps\n        \n        _, preds_tensor = torch.max(ps, 1)\n        preds = np.squeeze(preds_tensor.numpy())if not device else np.squeeze(preds_tensor.cpu().numpy())\n        data_labels.append(int(preds))","a8ee75c1":"files =[]\ncategories = []\nfor file in os.listdir(os.path.join(data_dir, \"test set\")):\n    files.append(file)\n\nfor i in data_labels:\n    categories.append(df.loc[i+1, 'category'])    ","6937a97c":"d = {'Image_Name': files, 'Class_Label': data_labels, 'Flower_Category': categories}\nresult = pd.DataFrame(d)","b5a859dc":"result = result.sort_values(by=\"Image_Name\")","46169b09":"result","aabd25d1":"result.to_csv(\"..\/working\/result.csv\")","46283b73":"## Saving the dataframe as CSV file","4b391913":" ## Specifing Train and Validation directory","40e208dc":"## Using GPU if available","ea5910e9":"## Prediction on Test Set","39492a07":"## Training the model","36d1f7f3":"## Loading Pre-trained model (DenseNet121)","01c62ef4":"## Saving the trained model","f5733235":"## Data Preprocessing","d1336678":"## Loading and transforming Training and Validation Data","59b78366":"## Importing Libraries","5c6b2352":"## Changing classifier layer to predict 102 species of flowers","dd0b80c8":"## Converting Test Predictions to dataframe","bef654b7":"## Visualizing random training image from one of the classes","13b376a4":"## Freezing training for all \"features layers\", Training only classifier layer","011f81da":"## Loading JSON file","3b3e56f2":"## Defining Loss function and Optimizer"}}