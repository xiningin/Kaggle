{"cell_type":{"e52e97da":"code","bc750714":"code","be682036":"code","5ff1b513":"code","7763f651":"code","b1560c6f":"code","6eec5544":"code","7880caef":"code","229a5ffa":"code","a72546c1":"code","4e6cb90a":"code","c08aacd4":"code","379f8d50":"code","338e58cf":"code","6a58dca3":"code","8f2c6129":"markdown","98db0c49":"markdown","26bfb083":"markdown"},"source":{"e52e97da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","bc750714":"from tqdm import tqdm_notebook as tqdm\nfrom PIL import Image as pil_image\nfrom PIL.ImageDraw import Draw\nimport pandas as pd\nfrom os.path import isfile\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL.ImageDraw import Draw\n\nTRAIN_DF = '..\/input\/humpback-whale-identification\/train.csv'\nSUB_Df = '..\/input\/humpback-whale-identification\/sample_submission.csv'\nTRAIN = '..\/input\/humpback-whale-identification\/train\/'\nTEST = '..\/input\/humpback-whale-identification\/test\/'\nBB_DF = \"..\/input\/metadata\/bounding_boxes.csv\"","be682036":"tagged = dict([(p, w) for _, p, w in pd.read_csv(TRAIN_DF).to_records()])\nsubmit = [p for _, p, _ in pd.read_csv(SUB_Df).to_records()]\njoin = list(tagged.keys()) + submit","5ff1b513":"def expand_path(p):\n    if isfile(TRAIN + p):\n        return TRAIN + p\n    if isfile(TEST + p):\n        return TEST + p\n    return p","7763f651":"# Raw data image read, if data in rotate list, 180 deg rotate\ndef read_raw_image(p):\n    img = pil_image.open(expand_path(p))\n    #if p in rotate: img = img.rotate(180)  # if rotation is required,\n    return img","b1560c6f":"def show_whale(imgs, per_row=2):\n    n         = len(imgs)\n    rows      = (n + per_row - 1)\/\/per_row\n    cols      = min(per_row, n)\n    fig, axes = plt.subplots(rows,cols, figsize=(24\/\/per_row*cols,24\/\/per_row*rows))\n    for ax in axes.flatten(): ax.axis('off')\n    for i,(img,ax) in enumerate(zip(imgs, axes.flatten())): ax.imshow(img.convert('RGB'))","6eec5544":"# image size data generation\n\np2size = {}\nfor p in tqdm(join):\n    size = pil_image.open(expand_path(p)).size\n    p2size[p] = size","7880caef":"# anisotropy; The horizontal compression ratio, ~ 2\n\ntotal_width = 0\ntotal_height = 0\n\nfor val in p2size.values():\n    total_width  += val[0]\n    total_height += val[1]\n    \navg_width = total_width\/len(p2size)\navg_height = total_height\/len(p2size)\nratio = avg_width\/avg_height\nratio","229a5ffa":"# Bounding box data load\n\np2bb = pd.read_csv(BB_DF).set_index(\"Image\")\np2bb.head()","a72546c1":"# example\nfilename = list(tagged.keys())[100]\nfilename","4e6cb90a":"def draw_dot(draw, x, y):\n    draw.ellipse(((x-5,y-5),(x+5,y+5)), fill='red', outline='red')\n\ndef draw_dots(draw, coordinates):\n    for x,y in coordinates: draw_dot(draw, x, y)\n\nsize_x,size_y = p2size[filename]\nx0, y0, x1, y1 = p2bb.loc[filename]\n\n#if rotation is required,\n#if filename in rotate:\n#    x0, y0, x1, y1 = size_x - x1, size_y - y1, size_x - x0, size_y - y0\n\ncoordinates = [(x0, y0), (x1, y1)]\nimg = read_raw_image(filename)\ndraw = Draw(img)\ndraw_dots(draw, coordinates)\nimg","c08aacd4":"def bounding_rectangle(list):\n    x0, y0 = list[0]\n    x1, y1 = x0, y0\n    for x,y in list[1:]:\n        x0 = min(x0, x)\n        y0 = min(y0, y)\n        x1 = max(x1, x)\n        y1 = max(y1, y)\n    return x0,y0,x1,y1\n\nbox = bounding_rectangle(coordinates)\nbox","379f8d50":"draw.rectangle(box, outline='red')\nimg","338e58cf":"import sys\nimport platform\nold_stderr = sys.stderr\nsys.stderr = open('\/dev\/null' if platform.system() != 'Windows' else 'nul', 'w')\nsys.stderr = old_stderr\n\nimport random\nfrom keras import backend as K\nfrom keras.preprocessing.image import img_to_array,array_to_img\nfrom scipy.ndimage import affine_transform\n\nimg_shape    = (384,384,3) # The image shape used by the model\nanisotropy   = 2.0 # The horizontal compression ratio\n#crop_margin  = 0.05 # The margin added around the bounding box to compensate for bounding box inaccuracy\n\ndef build_transform(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    \"\"\"\n    Build a transformation matrix with the specified characteristics.\n    \"\"\"\n    rotation        = np.deg2rad(rotation)\n    shear           = np.deg2rad(shear)\n    rotation_matrix = np.array([[np.cos(rotation), np.sin(rotation), 0], [-np.sin(rotation), np.cos(rotation), 0], [0, 0, 1]])\n    shift_matrix    = np.array([[1, 0, height_shift], [0, 1, width_shift], [0, 0, 1]])\n    shear_matrix    = np.array([[1, np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])\n    zoom_matrix     = np.array([[1.0\/height_zoom, 0, 0], [0, 1.0\/width_zoom, 0], [0, 0, 1]])\n    shift_matrix    = np.array([[1, 0, -height_shift], [0, 1, -width_shift], [0, 0, 1]])\n    return np.dot(np.dot(rotation_matrix, shear_matrix), np.dot(zoom_matrix, shift_matrix))\n\ndef read_cropped_image(p, augment, crop_margin=0.05):\n    \"\"\"\n    @param p : the name of the picture to read\n    @param augment: True\/False if data augmentation should be performed\n    @return a numpy array with the transformed image\n    \"\"\"\n    size_x,size_y = p2size[p]\n    \n    # Determine the region of the original image we want to capture based on the bounding box.\n    x0,y0,x1,y1   = p2bb.loc[p]\n    # if rotation is required,\n    #if p in rotate: x0, y0, x1, y1 = size_x - x1, size_y - y1, size_x - x0, size_y - y0\n\n    dx            = x1 - x0\n    dy            = y1 - y0\n    x0           -= dx*crop_margin\n    x1           += dx*crop_margin + 1\n    y0           -= dy*crop_margin\n    y1           += dy*crop_margin + 1\n    if (x0 < 0     ): x0 = 0\n    if (x1 > size_x): x1 = size_x\n    if (y0 < 0     ): y0 = 0\n    if (y1 > size_y): y1 = size_y\n    dx            = x1 - x0\n    dy            = y1 - y0\n    if dx > dy*anisotropy:\n        dy  = 0.5*(dx\/anisotropy - dy)\n        y0 -= dy\n        y1 += dy\n    else:\n        dx  = 0.5*(dy*anisotropy - dx)\n        x0 -= dx\n        x1 += dx\n    \n    # Generate the transformation matrix\n    trans = np.array([[1, 0, -0.5*img_shape[0]], [0, 1, -0.5*img_shape[1]], [0, 0, 1]])\n    trans = np.dot(np.array([[(y1 - y0)\/img_shape[0], 0, 0], [0, (x1 - x0)\/img_shape[1], 0], [0, 0, 1]]), trans)\n    \n    if augment:\n        trans = np.dot(build_transform(\n            random.uniform(-5, 5),\n            random.uniform(-5, 5),\n            random.uniform(0.8, 1.0),\n            random.uniform(0.8, 1.0),\n            random.uniform(-0.05*(y1 - y0), 0.05*(y1 - y0)),\n            random.uniform(-0.05*(x1 - x0), 0.05*(x1 - x0))\n            ), trans) \n    trans = np.dot(np.array([[1, 0, 0.5*(y1 + y0)], [0, 1, 0.5*(x1 + x0)], [0, 0, 1]]), trans)\n\n    # Read the image, Comvert to numpy array\n    img   = read_raw_image(p)\n    img   = img_to_array(img)\n    \n    # Apply affine transformation\n    matrix = trans[:2,:2]\n    offset = trans[:2,2]\n    x = np.moveaxis(img, -1, 0) # Change to channel first\n    \n    img    = [affine_transform(img, matrix, offset, order=1, output_shape=img_shape[:-1], mode='constant', cval=np.average(img)) for img in x]\n    img    = np.moveaxis(np.stack(img, axis=0), 0, -1)\n\n    # Normalize to zero mean and unit variance\n    img  -= np.mean(img, keepdims=True)\n    img  \/= np.std(img, keepdims=True) + K.epsilon()\n    \n    return img\n\ndef read_for_training(p, crop_margin=0.05):\n    \"\"\"\n    Read and preprocess an image with data augmentation (random transform).\n    \"\"\"\n    print(\"Training crop_margin: \", crop_margin)\n    return read_cropped_image(p, True, crop_margin)\n\ndef read_for_validation(p, crop_margin=0.05):\n    \"\"\"\n    Read and preprocess an image without data augmentation (use for testing).\n    \"\"\"\n    print(\"Validation crop_margin: \", crop_margin)\n    return read_cropped_image(p, False, crop_margin)\n\nimgs = [\n    read_raw_image(filename),                                      # raw image plot\n    array_to_img(read_for_validation(filename)),                   # Affine transform (resize with bbox) without augmentation\n    array_to_img(read_for_validation(filename, crop_margin=0)),    # Affine transform (resize with bbox) without augmentation, margin = 0\n    array_to_img(read_for_training(filename)),                     # Affine transform (resize with bbox) with augmentation\n    array_to_img(read_for_training(filename, crop_margin=0))       # Affine transform (resize with bbox) with augmentation, margin = 0\n]\nshow_whale(imgs, per_row=5)","6a58dca3":"img_shape    = (384,384,1)\n\ndef read_cropped_image(p, augment, crop_margin=0.05):\n    \"\"\"\n    @param p : the name of the picture to read\n    @param augment: True\/False if data augmentation should be performed\n    @return a numpy array with the transformed image\n    \"\"\"\n    size_x,size_y = p2size[p]\n    \n    # Determine the region of the original image we want to capture based on the bounding box.\n    x0,y0,x1,y1   = p2bb.loc[p]\n    dx            = x1 - x0\n    dy            = y1 - y0\n    x0           -= dx*crop_margin\n    x1           += dx*crop_margin + 1\n    y0           -= dy*crop_margin\n    y1           += dy*crop_margin + 1\n    if (x0 < 0     ): x0 = 0\n    if (x1 > size_x): x1 = size_x\n    if (y0 < 0     ): y0 = 0\n    if (y1 > size_y): y1 = size_y\n    dx            = x1 - x0\n    dy            = y1 - y0\n    if dx > dy*anisotropy:\n        dy  = 0.5*(dx\/anisotropy - dy)\n        y0 -= dy\n        y1 += dy\n    else:\n        dx  = 0.5*(dy*anisotropy - dx)\n        x0 -= dx\n        x1 += dx\n\n    # Generate the transformation matrix\n    trans = np.array([[1, 0, -0.5*img_shape[0]], [0, 1, -0.5*img_shape[1]], [0, 0, 1]])\n    trans = np.dot(np.array([[(y1 - y0)\/img_shape[0], 0, 0], [0, (x1 - x0)\/img_shape[1], 0], [0, 0, 1]]), trans)\n    if augment:\n        trans = np.dot(build_transform(\n            random.uniform(-5, 5),\n            random.uniform(-5, 5),\n            random.uniform(0.8, 1.0),\n            random.uniform(0.8, 1.0),\n            random.uniform(-0.05*(y1 - y0), 0.05*(y1 - y0)),\n            random.uniform(-0.05*(x1 - x0), 0.05*(x1 - x0))\n            ), trans)\n    trans = np.dot(np.array([[1, 0, 0.5*(y1 + y0)], [0, 1, 0.5*(x1 + x0)], [0, 0, 1]]), trans)\n\n    # Read the image, transform to black and white and comvert to numpy array\n    img   = read_raw_image(p).convert('L')\n    img   = img_to_array(img)\n    \n    # Apply affine transformation\n    matrix = trans[:2,:2]\n    offset = trans[:2,2]\n    img    = img.reshape(img.shape[:-1])\n    img    = affine_transform(img, matrix, offset, output_shape=img_shape[:-1], order=1, mode='constant', cval=np.average(img))\n    img    = img.reshape(img_shape)\n    \n    # Normalize to zero mean and unit variance\n    img  -= np.mean(img, keepdims=True)\n    img  \/= np.std(img, keepdims=True) + K.epsilon()\n    return img\n\ndef read_for_training(p):\n    \"\"\"\n    Read and preprocess an image with data augmentation (random transform).\n    \"\"\"\n    return read_cropped_image(p, True)\n\ndef read_for_validation(p):\n    \"\"\"\n    Read and preprocess an image without data augmentation (use for testing).\n    \"\"\"\n    return read_cropped_image(p, False)\n\nimgs = [\n    read_raw_image(filename),                      # raw image plot\n    array_to_img(read_for_validation(filename)),   # Affine transform (resize with bbox) without augmentation\n    array_to_img(read_for_training(filename))      # Affine transform (resize with bbox) with augmentation\n]\nshow_whale(imgs, per_row=3)","8f2c6129":"# Affine transform_Grey level","98db0c49":"I tried to use [@martinpiotte's](https:\/\/www.kaggle.com\/martinpiotte)  kernel referenced from, <br>\n        \n[bounding_box affine transform_1](https:\/\/www.kaggle.com\/martinpiotte\/bounding-box-data-for-the-whale-flukes) <br>\n[bounding_box affine transform_2](http:\/\/www.kaggle.com\/martinpiotte\/whale-recognition-model-with-score-0-78563) <br>\n\n- affine transform RGB, Grey level preprocessing","26bfb083":"# Affine transform_RGB\n- You can use this code for traning siamese network (martinpiotte's ver.)\n- margin added to this kernel, as mentioned from previous kernel\n- Margin cripping is prefered because edge information could be damaged during data augmentation at exact clipping"}}