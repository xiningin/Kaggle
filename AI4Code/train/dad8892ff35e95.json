{"cell_type":{"d96da82b":"code","da38f147":"code","0cfb545c":"code","58c0b5d7":"code","60550df9":"code","4cc4f791":"code","cf5b0956":"code","b625aa4b":"code","95378c9e":"code","4a149f67":"code","a3a90dcc":"code","87f5c6d1":"code","69da0619":"code","1602dfd6":"code","efa1dcc0":"code","61151269":"code","ebd2315c":"code","0ae88f7f":"code","d8dfacac":"code","db0890c6":"code","5a44d57b":"code","32238267":"code","16ac7211":"code","4b08b82d":"code","a71b2a74":"code","3c6bd975":"code","637c1af3":"code","08162a01":"code","2565e626":"code","47283719":"code","42ed3c2d":"code","8694e939":"code","805a2d3a":"code","f7503511":"code","0413dda1":"code","3e536cd2":"code","6a5c90f7":"code","0806452d":"code","c85f3523":"code","f47c4e7e":"code","41a38ae5":"code","f06d891d":"code","b3be1ed4":"code","bfabbcfd":"code","cbc5a8bd":"code","21c1e32c":"code","d0c2dc58":"code","36e159b0":"code","c0ee85f1":"code","64ac46a6":"code","52cb8937":"code","3a999a86":"code","287b78e0":"code","f0842612":"code","27fc3802":"code","cec249ba":"code","a97c0d5d":"code","eb944e73":"code","1ff5913b":"code","24897455":"code","3101b511":"code","35811ec1":"code","726a049d":"code","37278257":"code","c1418d17":"code","e4f3e1a1":"code","33afeafe":"code","83f9e830":"code","e06e81fc":"code","cbaa907f":"code","c4be3928":"code","294aa746":"code","2affb0b7":"code","d7e9e33e":"code","e0c60bf5":"code","63fbc463":"code","46e539ee":"code","d0fab42c":"code","f33b22cc":"code","f7595665":"code","727eda38":"code","50870cde":"code","e90bb6aa":"code","bb2c9817":"code","6d2ccb69":"code","714741e2":"code","3821b07e":"code","d5eb441d":"code","3f6e1087":"code","f56a9e4e":"code","4d64995f":"code","504247e4":"code","a7355ec8":"code","cb005217":"markdown","482e7490":"markdown","02527094":"markdown","4fbcd8b3":"markdown","aff6aecf":"markdown","f64c2342":"markdown","868ee4da":"markdown","0e878c57":"markdown","97ca090c":"markdown","03abb944":"markdown","94d82b04":"markdown","14eb065d":"markdown","650e9178":"markdown","b8c3b848":"markdown","1e533f41":"markdown","7cf0ea1d":"markdown","d118e6d6":"markdown","a849ffb1":"markdown","db4baf35":"markdown","e71c66c4":"markdown","0b3bf120":"markdown","b7a3de1b":"markdown","20a17a6c":"markdown","d63a2434":"markdown","607f5595":"markdown","b293e95b":"markdown","95e9fd77":"markdown","8b8ef498":"markdown","a8ce2a77":"markdown","0ff0a13e":"markdown","eda7f36b":"markdown","8c0e5270":"markdown","9d131d86":"markdown","d8b18bc1":"markdown","fc14952d":"markdown","786cf19f":"markdown","1b4d8b71":"markdown","b64fffef":"markdown","53d612b0":"markdown","bf02c748":"markdown","8e8cb820":"markdown","4fa43287":"markdown","94c3193b":"markdown","1724d8e5":"markdown","07a3d1d3":"markdown","ec37dbdb":"markdown","2223726e":"markdown","0277888d":"markdown","2a9d78f8":"markdown","75365b5f":"markdown","41092851":"markdown","92a81aeb":"markdown","1ef73fad":"markdown","1810bab9":"markdown","817ddaeb":"markdown","969e9073":"markdown","41c61e7d":"markdown","8914f701":"markdown","87f93583":"markdown","81c1337a":"markdown","ffe39710":"markdown","4a7be67a":"markdown","d473d503":"markdown","d033c16d":"markdown","e9ddf71c":"markdown","185e1791":"markdown","85c49c1f":"markdown","108da488":"markdown","cda99d21":"markdown","f0266442":"markdown","25ed95f9":"markdown","59557ea3":"markdown","b07011ca":"markdown","86c6e39a":"markdown","e0fd762b":"markdown"},"source":{"d96da82b":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nprint(tf.__version__)","da38f147":"fashion_mnist = keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()","0cfb545c":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","58c0b5d7":"train_images.shape","60550df9":"train_labels","4cc4f791":"test_images.shape","cf5b0956":"#If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255\nplt.figure()\nplt.imshow(train_images[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()","b625aa4b":"train_images = train_images \/ 255.0\n\ntest_images = test_images \/ 255.0","95378c9e":"#let's display the first 25 images from the training set and display the class name below each image\nplt.figure(figsize=(12,12))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i]])\nplt.show()","4a149f67":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28, 28)),\n    keras.layers.Dense(128, activation='relu'),\n    keras.layers.Dense(10)\n])","a3a90dcc":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","87f5c6d1":"model.fit(train_images, train_labels, epochs=10)","69da0619":"test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","1602dfd6":"\nfrom keras.datasets import imdb\n\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)","efa1dcc0":"train_data[0]","61151269":"train_labels[0]","ebd2315c":"#Since we restricted ourselves to the top 10,000 most frequent words, no word index will exceed 10,000\nmax([max(sequence) for sequence in train_data])","0ae88f7f":"\nimport numpy as np\n\ndef vectorize_sequences(sequences, dimension=10000):\n    # Create an all-zero matrix of shape (len(sequences), dimension)\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1  #set specific indices of results[i] to 1s\n    return results\n\n# Our vectorized training data\nx_train = vectorize_sequences(train_data)\n# Our vectorized test data\nx_test = vectorize_sequences(test_data)","d8dfacac":"x_train[0]","db0890c6":"# Our vectorized labels\ny_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')","5a44d57b":"from keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","32238267":"model.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","16ac7211":"from keras import optimizers\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","4b08b82d":"from keras import losses\nfrom keras import metrics\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss=losses.binary_crossentropy,\n              metrics=[metrics.binary_accuracy])","a71b2a74":"x_val = x_train[:10000]\npartial_x_train = x_train[10000:]\n\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]","3c6bd975":"history = model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs=20,\n                    batch_size=512,\n                    validation_data=(x_val, y_val))","637c1af3":"history_dict = history.history\nhistory_dict.keys()","08162a01":"import matplotlib.pyplot as plt\n\nacc = history.history['loss']\nval_acc = history.history['binary_accuracy']\nloss = history.history['val_loss']\nval_loss = history.history['val_binary_accuracy']\n\nepochs = range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'bo', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","2565e626":"plt.clf()   # clear figure\nacc_values = history_dict['binary_accuracy']\nval_acc_values = history_dict['val_binary_accuracy']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","47283719":"model = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=4, batch_size=512)\nresults = model.evaluate(x_test, y_test)","42ed3c2d":"results","8694e939":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt","805a2d3a":"_URL = 'https:\/\/storage.googleapis.com\/mledu-datasets\/cats_and_dogs_filtered.zip'\n\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')","f7503511":"#After extracting its contents, assign variables with the proper file path for the training and validation set\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')","0413dda1":"train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures","3e536cd2":"num_cats_tr = len(os.listdir(train_cats_dir))\nnum_dogs_tr = len(os.listdir(train_dogs_dir))\n\nnum_cats_val = len(os.listdir(validation_cats_dir))\nnum_dogs_val = len(os.listdir(validation_dogs_dir))\n\ntotal_train = num_cats_tr + num_dogs_tr\ntotal_val = num_cats_val + num_dogs_val","6a5c90f7":"print('total training cat images:', num_cats_tr)\nprint('total training dog images:', num_dogs_tr)\n\nprint('total validation cat images:', num_cats_val)\nprint('total validation dog images:', num_dogs_val)\nprint(\"--\")\nprint(\"Total training images:\", total_train)\nprint(\"Total validation images:\", total_val)","0806452d":"#Setting up variables to use while pre-processing the dataset and training the network\nbatch_size = 128\nepochs = 15\nIMG_HEIGHT = 150\nIMG_WIDTH = 150","c85f3523":"train_image_generator = ImageDataGenerator(rescale=1.\/255) # Generator for our training data\nvalidation_image_generator = ImageDataGenerator(rescale=1.\/255) # Generator for our validation data","f47c4e7e":"train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n                                                           directory=train_dir,\n                                                           shuffle=True,\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                           class_mode='binary')","41a38ae5":"val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n                                                              directory=validation_dir,\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                              class_mode='binary')","f06d891d":"model = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n    MaxPooling2D(),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1)\n])","b3be1ed4":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","bfabbcfd":"model.summary()","cbc5a8bd":"history = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=total_train \/\/ batch_size,\n    epochs=epochs,\n    validation_data=val_data_gen,\n    validation_steps=total_val \/\/ batch_size\n)","21c1e32c":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","d0c2dc58":"image_gen = ImageDataGenerator(rescale=1.\/255, horizontal_flip=True)","36e159b0":"train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size=(IMG_HEIGHT, IMG_WIDTH))","c0ee85f1":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]","64ac46a6":"image_gen = ImageDataGenerator(rescale=1.\/255, rotation_range=45)","52cb8937":"train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n\naugmented_images = [train_data_gen[0][0][0] for i in range(5)]","3a999a86":"# zoom_range from 0 - 1 where 1 = 100%.\nimage_gen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.5) ","287b78e0":"train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n\naugmented_images = [train_data_gen[0][0][0] for i in range(5)]","f0842612":"image_gen_train = ImageDataGenerator(\n                    rescale=1.\/255,\n                    rotation_range=45,\n                    width_shift_range=.15,\n                    height_shift_range=.15,\n                    horizontal_flip=True,\n                    zoom_range=0.5\n                    )","27fc3802":"train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n                                                     directory=train_dir,\n                                                     shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                     class_mode='binary')","cec249ba":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]","a97c0d5d":"image_gen_val = ImageDataGenerator(rescale=1.\/255)","eb944e73":"val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n                                                 directory=validation_dir,\n                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                 class_mode='binary')","1ff5913b":"model_new = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', \n           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n    MaxPooling2D(),\n    Dropout(0.2),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Dropout(0.2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1)\n])","24897455":"model_new.compile(optimizer='adam',\n                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                  metrics=['accuracy'])\n\nmodel_new.summary()","3101b511":"history = model_new.fit_generator(\n    train_data_gen,\n    steps_per_epoch=total_train \/\/ batch_size,\n    epochs=epochs,\n    validation_data=val_data_gen,\n    validation_steps=total_val \/\/ batch_size\n)","35811ec1":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","726a049d":"import tensorflow as tf\n\nimport numpy as np\nimport os\nimport time","37278257":"path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https:\/\/storage.googleapis.com\/download.tensorflow.org\/data\/shakespeare.txt')","c1418d17":"# Read, then decode for py2 compat.\ntext = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n# length of text is the number of characters in it\nprint ('Length of text: {} characters'.format(len(text)))","e4f3e1a1":"# Take a look at the first 250 characters in text\nprint(text[:250])","33afeafe":"# The unique characters in the file\nvocab = sorted(set(text))\nprint ('{} unique characters'.format(len(vocab)))","83f9e830":"# Creating a mapping from unique characters to indices\nchar2idx = {u:i for i, u in enumerate(vocab)}\nidx2char = np.array(vocab)\n\ntext_as_int = np.array([char2idx[c] for c in text])","e06e81fc":"print('{')\nfor char,_ in zip(char2idx, range(20)):\n    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\nprint('  ...\\n}')","cbaa907f":"# Show how the first 13 characters from the text are mapped to integers\nprint ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))","c4be3928":"# The maximum length sentence we want for a single input in characters\nseq_length = 100\nexamples_per_epoch = len(text)\/\/(seq_length+1)\n\n# Create training examples \/ targets\nchar_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n\nfor i in char_dataset.take(5):\n  print(idx2char[i.numpy()])","294aa746":"sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n\nfor item in sequences.take(5):\n  print(repr(''.join(idx2char[item.numpy()])))","2affb0b7":"def split_input_target(chunk):\n    input_text = chunk[:-1]\n    target_text = chunk[1:]\n    return input_text, target_text\n\ndataset = sequences.map(split_input_target)","d7e9e33e":"for input_example, target_example in  dataset.take(1):\n  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))","e0c60bf5":"for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n    print(\"Step {:4d}\".format(i))\n    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))","63fbc463":"# Batch size\nBATCH_SIZE = 64\n\n# Buffer size to shuffle the dataset\n# (TF data is designed to work with possibly infinite sequences,\n# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n# it maintains a buffer in which it shuffles elements).\nBUFFER_SIZE = 10000\n\ndataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n\ndataset","46e539ee":"# Length of the vocabulary in chars\nvocab_size = len(vocab)\n\n# The embedding dimension\nembedding_dim = 256\n\n# Number of RNN units\nrnn_units = 1024","d0fab42c":"def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n  model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n                              batch_input_shape=[batch_size, None]),\n    tf.keras.layers.GRU(rnn_units,\n                        return_sequences=True,\n                        stateful=True,\n                        recurrent_initializer='glorot_uniform'),\n    tf.keras.layers.Dense(vocab_size)\n  ])\n  return model","f33b22cc":"model = build_model(\n  vocab_size = len(vocab),\n  embedding_dim=embedding_dim,\n  rnn_units=rnn_units,\n  batch_size=BATCH_SIZE)","f7595665":"for input_example_batch, target_example_batch in dataset.take(1):\n  example_batch_predictions = model(input_example_batch)\n  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")","727eda38":"model.summary()","50870cde":"sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\nsampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()","e90bb6aa":"sampled_indices","bb2c9817":"print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\nprint()\nprint(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))","6d2ccb69":"def loss(labels, logits):\n  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n\nexample_batch_loss  = loss(target_example_batch, example_batch_predictions)\nprint(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\nprint(\"scalar_loss:      \", example_batch_loss.numpy().mean())","714741e2":"model.compile(optimizer='adam', loss=loss)","3821b07e":"# Directory where the checkpoints will be saved\ncheckpoint_dir = '.\/training_checkpoints'\n# Name of the checkpoint files\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n\ncheckpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_prefix,\n    save_weights_only=True)","d5eb441d":"EPOCHS=10\n\nhistory = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])","3f6e1087":"tf.train.latest_checkpoint(checkpoint_dir)","f56a9e4e":"model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n\nmodel.build(tf.TensorShape([1, None]))","4d64995f":"model.summary()","504247e4":"def generate_text(model, start_string):\n  # Evaluation step (generating text using the learned model)\n\n  # Number of characters to generate\n  num_generate = 1000\n\n  # Converting our start string to numbers (vectorizing)\n  input_eval = [char2idx[s] for s in start_string]\n  input_eval = tf.expand_dims(input_eval, 0)\n\n  # Empty string to store our results\n  text_generated = []\n\n  # Low temperatures results in more predictable text.\n  # Higher temperatures results in more surprising text.\n  # Experiment to find the best setting.\n  temperature = 1.0\n\n  # Here batch size == 1\n  model.reset_states()\n  for i in range(num_generate):\n      predictions = model(input_eval)\n      # remove the batch dimension\n      predictions = tf.squeeze(predictions, 0)\n\n      # using a categorical distribution to predict the character returned by the model\n      predictions = predictions \/ temperature\n      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n\n      # We pass the predicted character as the next input to the model\n      # along with the previous hidden state\n      input_eval = tf.expand_dims([predicted_id], 0)\n\n      text_generated.append(idx2char[predicted_id])\n\n  return (start_string + ''.join(text_generated))","a7355ec8":"print(generate_text(model, start_string=u\"ROMEO: \"))","cb005217":"- Preprocess the data","482e7490":"**Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better.**","02527094":"**The term \u201cdeep\u201d usually refers to the number of hidden layers in the neural network. Traditional neural networks only contain 2-3 hidden layers, while deep networks can have much higher hidden layers.Deep learning models are trained by using large sets of labeled data and neural network architectures that learn features directly from the data without the need for manual feature extraction.**","4fbcd8b3":"![](https:\/\/articles.adxy.in\/wp-content\/uploads\/2019\/08\/similarities-between-biologicalneuron-artificialneuron.gif)","aff6aecf":"![](https:\/\/static.wixstatic.com\/media\/bd3071_7dfa208b4f3c4283acda8703cf76bcdf~mv2.gif)","f64c2342":"![](https:\/\/peltarion.com\/static\/fashion-mnist_long.png)","868ee4da":"- Download the Shakespeare dataset","0e878c57":"## Recurrent Neural Network","97ca090c":"![](https:\/\/lh3.googleusercontent.com\/proxy\/qIQXDsuZv8v07mLanR7K0fiIwur-OWZHV64T0EXt8dZ5PXi88bsGKcQxit5coR3eONbbi5hSF3cA9wJy1bzbjVNxpJSjIMuZpRLuRZt8KzbKRkJ8e2OHSZJRphJGxUlI)","03abb944":"**It turns out that the accuracy on the test dataset is a little less than the accuracy on the training dataset. This gap between training accuracy and test accuracy represents overfitting. Overfitting happens when a machine learning model performs worse on new, previously unseen inputs than it does on the training data. An overfitted model \"memorizes\" the noise and details in the training dataset to a point where it negatively impacts the performance of the model on the new data.**","94d82b04":"**It contains 4 entries: one per metric that was being monitored, during training and during validation. Let's use Matplotlib to plot the training and validation loss side by side, as well as the training and validation accuracy**","14eb065d":"- Compile the model","650e9178":"The following code block generates the text\n\n- It Starts by choosing a start string, initializing the RNN state and setting the number of characters to generate\n- Get the prediction distribution of the next character using the start string and the RNN state\n- Then, use a categorical distribution to calculate the index of the predicted character. Use this predicted character as our next input to the model\n- The RNN state returned by the model is fed back into the model so that it now has more context, instead than only one character. After predicting the next character, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted characters","b8c3b848":"- Building our network","1e533f41":"- Apply zoom augmentation","7cf0ea1d":"### --------------------------If You Found this helpful, Do Upvote Please----------------------------------------","d118e6d6":"- Build the model","a849ffb1":"-  Try it for the first example in the batch","db4baf35":"- Create training examples and targets","e71c66c4":"# 4) Predict Next Character in the Sequence with Shakespeare","0b3bf120":"- Execute the training","b7a3de1b":"- Evaluate accuracy","20a17a6c":"![](https:\/\/media2.giphy.com\/media\/l3q2FnW3yZRJVZH2g\/giphy.gif)","d63a2434":"- Create the model","607f5595":"- Create training batches","b293e95b":"![](https:\/\/miro.medium.com\/max\/3288\/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)","95e9fd77":"- Train the model","8b8ef498":"![](https:\/\/miro.medium.com\/max\/2560\/1*ciDgQEjViWLnCbmX-EeSrA.gif)","a8ce2a77":"### The prediction task","0ff0a13e":"- Generate text","eda7f36b":"![](https:\/\/machinelearningknowledge.ai\/wp-content\/uploads\/2019\/10\/Backpropagation.gif)","8c0e5270":"- Put it all together","9d131d86":"- Compile the model","d8b18bc1":"![](https:\/\/miro.medium.com\/max\/3534\/0*yK_SN7M6SG-ovDwi.jpg)","fc14952d":"- Configure checkpoints","786cf19f":"- Train the model","1b4d8b71":"- Randomly rotate the image","b64fffef":"- Understand the data","53d612b0":"-  Read the data","bf02c748":"**Another technique to reduce overfitting is to introduce dropout to the network. It is a form of regularization that forces the weights in the network to take only small values, which makes the distribution of weight values more regular and the network can reduce overfitting on small training examples.When we apply dropout to a layer it randomly drops out (set to zero) number of output units from the applied layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer**","8e8cb820":"- Apply horizontal flip","4fa43287":"![](https:\/\/i.stack.imgur.com\/ptDPZ.gif)","94c3193b":"# 1) Basic Image Classification with Fashion MNIST","1724d8e5":"## Neural Networks","07a3d1d3":"![](https:\/\/miro.medium.com\/max\/1928\/1*xn5kA92_J5KLaKcP7BMRLA.gif)","ec37dbdb":"**Our input data is simply vectors, and our labels are scalars (1s and 0s): this is the easiest setup you will ever encounter. A type of network that performs well on such a problem would be a simple stack of fully-connected (Dense) layers with relu activations.we need to pick a loss function and an optimizer. Since we are facing a binary classification problem and the output of our network is a probability (we end our network with a single-unit layer with a sigmoid activation), is it best to use the binary_crossentropy loss**","2223726e":"- Build The Model","0277888d":"### Data augmentation","2a9d78f8":"# 2) Binary Text classification with IMDB ","75365b5f":"**We cannot feed lists of integers into a neural network. We have to turn our lists into tensors.We could one-hot-encode our lists to turn them into vectors of 0s and 1s. Concretely, this would mean for instance turning the sequence. [3,5] into a 10,000-dimensional vector that would be all-zeros except for indices 3 and 5, which would be ones. Then we could use as first layer in our network a Dense layer, capable of handling floating point vector data**","41092851":"# 3) Image classification with Augmentation (Cats vs Dogs)","92a81aeb":"![](https:\/\/i1.wp.com\/gereshes.com\/wp-content\/uploads\/2019\/09\/trajNoFlashLowFid.gif?resize=1089%2C548&ssl=1)\n### -------------- Neural Network Optimal Control in Astrodynamics (Sounds Cool) ------------------\n                              ","1ef73fad":"- Preparing the data","1810bab9":"![](https:\/\/static.wixstatic.com\/media\/bd3071_7dfa208b4f3c4283acda8703cf76bcdf~mv2.gif)","817ddaeb":"**Take one sample image from the training examples and repeat it five times so that the augmentation is applied to the same image five times**","969e9073":"- Data preparation","41c61e7d":"- Train the model","8914f701":"**Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.It utilizes a hierarchical level of artificial neural networks to carry out the process of machine learning. The artificial neural networks are built like the human brain, with neuron nodes connected together like a web.**","87f93583":"- Explore the data","81c1337a":"- Dropout","ffe39710":"## Convolutional neural network","4a7be67a":"**In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 70% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable a sign of overfitting.**","d473d503":"- Validating our approach","d033c16d":"**Our fairly naive approach achieves an accuracy of 88%**","e9ddf71c":"- Train the model","185e1791":"![](https:\/\/corochann.com\/wp-content\/uploads\/2017\/05\/rnn1_graph-800x460.png)","85c49c1f":"- The prediction loop","108da488":"![](https:\/\/hackernoon.com\/hn-images\/1*_mM83sFLjzKt8cRB439Y3Q.gif)","cda99d21":"- Try the model","f0266442":"![](https:\/\/i.redd.it\/1jofyu3ugsiz.jpg)","25ed95f9":"![](https:\/\/miro.medium.com\/max\/2560\/1*NgPy8YAskOp51S9gfsY0Ug.jpeg)","59557ea3":"![](https:\/\/static.wixstatic.com\/media\/bd3071_7dfa208b4f3c4283acda8703cf76bcdf~mv2.gif)","b07011ca":"## ------------------------ Let's get started -----------------------------------","86c6e39a":"- Process the text","e0fd762b":"- Create validation data generator"}}