{"cell_type":{"7f68523b":"code","0c506b0c":"code","bef70392":"code","417534d4":"code","e35d38ea":"code","d2adbc49":"code","38177c5b":"code","92e8877b":"code","669f12d6":"code","bda9f5ac":"code","cfe6941a":"code","4b613f0e":"code","55cb99e2":"code","73508120":"code","d4db3767":"code","2dad1397":"markdown","45ba22fb":"markdown","2b3f7f25":"markdown","568ee875":"markdown","056250d7":"markdown","56360d0a":"markdown","743ddd43":"markdown","0638cc92":"markdown"},"source":{"7f68523b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json         #json file reading\nimport multiprocessing as mp\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport re\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","0c506b0c":"#ensure that the internet option is on (Kaggle) to install textract package\n!pip install textract --upgrade\n!pip install wordcloud\n!pip install PIL\nimport textract\nfrom wordcloud import WordCloud, STOPWORDS\n","bef70392":"def checkForDuplicates(List):\n    ''' Check for any duplicates in a list'''\n    if len(List) == len(set(List)):\n        return False\n    else:\n        return True\n    \n    \ndef read_pdf(file):\n    '''Reads \"\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/COVID.DATA.LIC.AGMT.pdf\" and makes it a bit more readable '''\n    import textract\n    text = str(textract.process(file))\n    text = text.lstrip('b')\n    text = text.strip(\"'\")\n    text = text.split('\\\\n')\n\n    pdf_str = ''\n    for t in text:\n        if t != '':\n            if t[0].isupper():\n                pdf_str = pdf_str + t + '\\n'\n            else:\n                pdf_str = pdf_str + t    \n            \n    return pdf_str\n\n\ndef load_json_files(directory_name):\n    '''Loads json files into list'''\n    articles = []\n    \n    articlenames = os.listdir(directory_name)\n\n    for articlename in tqdm(articlenames):\n        articlename = directory_name + articlename\n        article = json.load(open(articlename, 'rb'))\n        articles.append(article)\n    \n    return articles\n\n\n\ndef article_title_list(article,source):\n    '''Create a list of a paper's ID, title and source''' \n\n    row = [article[\"paper_id\"],article[\"metadata\"][\"title\"],source]\n    return  row\n\n\n\n\ndef article_author_list(article):\n    '''Create a list of a paper's ID, authors and source'''\n    authors = []\n\n    for idx in range(len(article[\"metadata\"][\"authors\"])):\n        author = [article[\"paper_id\"],article[\"metadata\"][\"authors\"][idx][\"first\"], article[\"metadata\"][\"authors\"][idx][\"last\"]]\n        authors.append(author)\n    \n    return authors\n\n\n\n\n\ndef article_body_list(article):\n    '''Create a list of a paper's ID and body'''\n    body = []\n    for idx in range(len(article[\"body_text\"])):\n        bod = [article[\"paper_id\"],article[\"body_text\"][idx][\"section\"],article[\"body_text\"][idx][\"text\"]]\n        body.append(bod)\n    \n    return body\n\n\n\n\n\ndef article_abstract_list(article):\n    '''Create a list of a paper's ID, and abstracts'''\n    abstracts = []\n    for idx in range(len(article[\"abstract\"])):\n        abstract = [article[\"paper_id\"], article[\"abstract\"][idx][\"text\"]]\n        abstracts.append(abstract)\n    \n    return abstracts\n\n\ndef article_text(article):\n    '''Create a list of a paper's ID, and abstracts'''\n    text = ''\n    for idx in range(len(article[\"abstract\"])):\n        text = text + '\\n\\n' + article[\"abstract\"][idx][\"text\"]\n        \n    for idx in range(len(article[\"body_text\"])):\n        text = text + '\\n\\n' + article[\"body_text\"][idx][\"section\"] + '\\n\\n' + article[\"body_text\"][idx][\"text\"]\n    \n    text = [article[\"paper_id\"],text]\n    \n    \n    return text\n\n\n\n\ndef create_df(articles,source):\n    '''Creates dataframes for Kaggle Covid-19'''\n    \n    titles_list = []\n    authors_list = []\n    text = []\n     \n\n    \n    for article in tqdm(articles):\n        \n        '''Create a list of lists containing a paper's ID, title and source'''\n        titles_list.append(article_title_list(article,source))\n\n        '''Create a list of lists containing a paper's ID, authors and source'''    \n        authors_list.extend([*[item for item in article_author_list(article)]])           \n \n\n        '''Create a list of lists containing a paper's abstracts and body'''    \n        text.append(article_text(article)) \n        \n    text = pd.DataFrame(text,columns = [\"Paper_Id\",'Text'])   \n    title_df = pd.DataFrame(titles_list,columns = [\"Paper_Id\",\"Title\",'Source'])\n    author_df = pd.DataFrame(authors_list,columns = [\"Paper_Id\",\"First_Name\",\"Last_Name\"])\n\n        \n    return title_df,author_df,text\n    ","417534d4":"noncomm_use_subset_Dir = '\/kaggle\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\/pdf_json\/'\nbiorxiv_medrxiv_Dir = '\/kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\/pdf_json\/'\ncomm_use_subset_Dir = '\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/pdf_json\/'\ncustom_license_Dir = '\/kaggle\/input\/CORD-19-research-challenge\/custom_license\/custom_license\/pdf_json\/'\n\nnoncomm_pmc_Dir = '\/kaggle\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\/pmc_json\/'\nbiorxiv_pmc_Dir = '\/kaggle\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\/pmc_json\/'\ncomm_pmc_Dir = '\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/pmc_json\/'\ncustom_pmc_Dir = '\/kaggle\/input\/CORD-19-research-challenge\/custom_license\/custom_license\/pmc_json\/'","e35d38ea":"listOfFileNames = []\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        listOfFileNames.append(os.path.join(dirname, filename))\n\ncheckForDuplicates(listOfFileNames)\n\ndel listOfFileNames","d2adbc49":"with open(\"\/kaggle\/input\/CORD-19-research-challenge\/metadata.readme\",'r') as f:\n    file = f.read()\n    print(file)","38177c5b":"print(read_pdf(\"\/kaggle\/input\/CORD-19-research-challenge\/COVID.DATA.LIC.AGMT.pdf\"))","92e8877b":"meta_data = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv')\nmeta_data.head()","669f12d6":"with open(\"\/kaggle\/input\/CORD-19-research-challenge\/json_schema.txt\",'r') as f:\n    file = f.read()\n    print(file)","bda9f5ac":"# Create stopword list:\n\nstopwords = set(STOPWORDS)\nstopwords.update([\"et al\",'et', 'al',\"addition\", \"respectively\", \"found\", \"although\",'present',\n                  'identified','Thu','Finally','either','suggesting','include',\"well\", \n                  \"including\", \"associated\", \"method\", \"result\",'used','doi','display',\n                  'https','copyright', 'holder','org','author','available','made','peer',\n                  'reviewed','without','permission','license','rights','reserverd','Furthermore'\n                  'using','preprint','allowed','following','may','thus','funder','International',\n                 'granted','compared','will','one','two','use','different','likely','Discussion',\n                 'medRexiv','Introduction','Moreover','known','funder','granted'])","cfe6941a":"articles = load_json_files(comm_use_subset_Dir)\ncomm_subset_title,comm_subset_author,comm_subset_text = create_df(articles,'comm_use_subset')\n\ncomm_subset_title.to_csv('comm_subset_title.csv',index = False)\ncomm_subset_author.to_csv('comm_subset_author.csv',index = False)\ncomm_subset_text.to_csv('comm_subset_text.csv',index = False)\n\n\nbody_text = \" \".join(text for text in comm_subset_text.Text)\n\n\n#del comm_subset_title\n#del comm_subset_author\n#del comm_subset_text\n\n\nprint (\"There are {} words in the bodies of the articles.\".format(len(body_text)))\n\n\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=stopwords,max_words=200, background_color=\"white\").generate(body_text)\n\n# Display the generated image:\n# the matplotlib way:\nprint('World Cloud for Bodies of articles')\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n","4b613f0e":"#Generate Wordclouds\n'''\narticles = load_json_files(biorxiv_medrxiv_Dir)\nbio_title,bio_author,bio_text = create_df(articles,'biorxiv_medrxiv')\n\nbio_title.to_csv('biorxiv_medrxiv_title.csv',index = False)\nbio_author.to_csv('biorxiv_medrxiv_author.csv',index = False)\nbio_text.to_csv('biorxiv_medrxiv_text.csv',index = False)\n\n\nbody_text = \" \".join(review for review in bio_text.Text)\n\n\ndel bio_title\ndel bio_author\ndel bio_text\n\n\nprint (\"There are {} words in the abstracts of articles.\".format(len(body_text)))\n\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=stopwords,max_words=200, background_color=\"white\").generate(body_text)\n\n# Display the generated image:\n# the matplotlib way:\nprint('World Cloud for Bodies of articles')\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n# Save the image:\n#wordcloud.to_file(\"wordcloud_biorxiv.png\")\n###############################################################\n\narticles = load_json_files(noncomm_use_subset_Dir)\nnoncomm_subset_title,noncomm_subset_author,noncomm_subset_text= create_df(articles,'noncomm_use_subset')\n  \n\nnoncomm_subset_title.to_csv('noncomm_subset_title.csv',index = False)\nnoncomm_subset_author.to_csv('noncomm_subset_author.csv',index = False)\nnoncomm_subset_text.to_csv('noncomm_subset_text.csv',index = False)\n\n\nbody_text = \" \".join(review for review in noncomm_subset_text.Text)\n\n\ndel noncomm_subset_title\ndel noncomm_subset_author\ndel noncomm_subset_text\n\n\nprint (\"There are {} words in the combination of all review.\".format(len(body_text)))\n\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=stopwords,max_words=200, background_color=\"white\").generate(body_text)\n\n# Display the generated image:\nprint('World Cloud for Bodies of articles')\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n# Save the image:\n#wordcloud.to_file(\"wordcloud_noncom.png\")\n\n##########################################################################\n\narticles = load_json_files(custom_license_Dir)\ncustom_license_title,custom_license_author,custom_license_text= create_df(articles,'custom_license')\n    \n\ncustom_license_title.to_csv('custom_license_title.csv',index = False)\ncustom_license_author.to_csv('custom_license_author.csv',index = False)\ncustom_license_text.to_csv('custom_license_text.csv',index = False)\n\n\nbody_text = \" \".join(review for review in custom_license_text.Text)\n\n\ndel custom_license_title\ndel custom_license_author\ndel custom_license_text\n\nprint (\"There are {} words in the combination of all review.\".format(len(body_text)))\n\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=stopwords,max_words=200, background_color=\"white\").generate(body_text)\n\n# Display the generated image:\nprint('World Cloud for Bodies of articles')\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n# Save the image:\n#wordcloud.to_file(\"wordcloud_custom.png\")\n'''","55cb99e2":"comm_subset_text.head()","73508120":"def search(word,df_text):\n    from nltk.tokenize import word_tokenize\n    papers = []\n    \n    for idx in tqdm(range(len(df_text))):\n        if word in word_tokenize(df_text.loc[idx,'Text']):\n            papers.append(df_text.loc[idx,'Paper_Id'])\n            \n    return papers\n        \n","d4db3767":"looking_for = 'pregnancy'\n\nsearch(looking_for,comm_subset_text)","2dad1397":"Word clouds while interesting are not particularly usefull. So let's look at searching for a word or phrase","45ba22fb":"**Creating DataFrames**","2b3f7f25":"**Previewing Files**","568ee875":"**Defining Functions**","056250d7":"**Installing packages**","56360d0a":"**Checking for any duplicates**","743ddd43":"**Difining directory names**","0638cc92":"These look at the \/pdf_json\/ files"}}