{"cell_type":{"e538c5f1":"code","d82d104a":"code","03cc63d3":"code","2ce05a92":"code","0131a85d":"code","be99ae1f":"code","5cb63ad4":"code","be3b61c8":"code","87f2a293":"code","2de58060":"code","a01e1ba8":"code","6d8ec62a":"code","27e199b4":"markdown","fa6f8bf3":"markdown","30d00232":"markdown","40241fc1":"markdown","1130702a":"markdown","d440858f":"markdown","0f795fdd":"markdown","c50d929e":"markdown","e5240c84":"markdown","f93db493":"markdown","cba75c45":"markdown","d1ee5d0d":"markdown","45287880":"markdown","ac473ed9":"markdown","5c3a6ff4":"markdown","7e933f08":"markdown","15bb2bdd":"markdown","6d1d3cf5":"markdown","46c831a6":"markdown","cbd48c99":"markdown","3278f0ee":"markdown","186c84f6":"markdown","4d663328":"markdown"},"source":{"e538c5f1":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image ","d82d104a":"\ntrain_gen = ImageDataGenerator(rescale=1\/255,\n                shear_range =0.2,\n                zoom_range=0.2,\n                horizontal_flip=True)","03cc63d3":"train_data = train_gen.flow_from_directory('..\/input\/dogcat-classificationcnn\/dataset\/training_set',\n                                          target_size=(64,64),\n                                          batch_size=8,\n                                          class_mode='binary')","2ce05a92":"test_gen = ImageDataGenerator(rescale=1\/255)\n","0131a85d":"test_data = test_gen.flow_from_directory('..\/input\/dogcat-classificationcnn\/dataset\/test_set',\n                                        target_size=(64,64),\n                                        batch_size = 8,\n                                        class_mode ='binary')","be99ae1f":"\n\n\nmy_model = tf.keras.models.Sequential()\n\n#creating convolution layer \nmy_model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[64,64,3]))\n#apply pooling\nmy_model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))  \n\n\nmy_model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'))\nmy_model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n\n#Flattening the image\nmy_model.add(tf.keras.layers.Flatten())\n\n# nueral network \nmy_model.add(tf.keras.layers.Dense(units=128,activation='relu'))\nmy_model.add(tf.keras.layers.Dense(units=128,activation='relu')) \nmy_model.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n             ","5cb63ad4":"\n#creating a model summary\nmy_model.summary()","be3b61c8":"#compiling the model\n\nmy_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","87f2a293":"\n#training the model with different parameters\n# can do tunning with the parameters to get a better accuracy \nmy_model.fit(x=train_data,validation_data=test_data,epochs=10)","2de58060":"# saving the model\n\nmy_model.save('cat_dog.h5')","a01e1ba8":"#Predicting a single image \n\ntest_image = image.load_img('..\/input\/dogcat-classificationcnn\/dataset\/test_set\/cats\/cat.4005.jpg',target_size=(64,64))\ntest_image = image.img_to_array(test_image)\ntest_image = test_image\/255\ntest_image = np.expand_dims(test_image,axis=0)\nresult = my_model.predict(test_image)","6d8ec62a":"if result[0] <=0.5 :\n    print('Cat')\nelse :\n    print('Dog')","27e199b4":"Computer Vision is an interdisciplinary field of science that aims to make computers process, analyze images and videos and extract details in the same way a human mind does. Earlier Computer Vision was meant only to mimic human visual systems until we realized how AI can augment its applications and vice versa","fa6f8bf3":"![](https:\/\/media.medicalbag.com\/images\/2018\/05\/31\/artificialintelligenceg8701_1436103.jpg)","30d00232":"**3 Pooling**\n\n\nPooling layers section would reduce the number of parameters when the images are too large. Spatial pooling also called subsampling or downsampling which reduces the dimensionality of each map but retains important information. Spatial pooling can be of different types:\n \nMax Pooling\n\nAverage Pooling\n\nSum Pooling","40241fc1":"**ImageDataGenerator**\n\nFeature scaling","1130702a":"# **BASIC STEPS INVOLVED IN THE CREATION OF CNN**","d440858f":"**TRAINING**","0f795fdd":"# **SUMMARY**","c50d929e":"**Referance**\n\nhttps:\/\/medium.com\/@RaghavPrabhu\/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\n\nhttps:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network\n","e5240c84":"**DOG CAT CLASSIFICATION**\n\n\n![](http:\/\/)![](https:\/\/woogle.dev\/wp-content\/uploads\/2020\/04\/1MBSM_G12XN105sEHsJ6C3A.png)","f93db493":"# **Lets get started by coding a simple example**","cba75c45":"# **INTRODUCTION TO COMPUTER VISION (CNN)**","d1ee5d0d":"Work by Hubel and Wiesel in the 1950s and 1960s showed that cat and monkey visual cortexes contain neurons that individually respond to small regions of the visual field. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field.[23] Neighboring cells have similar and overlapping receptive fields.[citation needed] Receptive field size and location varies systematically across the cortex to form a complete map of visual space.[citation needed] The cortex in each hemisphere represents the contralateral visual field.[citation needed]\n\nTheir 1968 paper identified two basic visual cell types in the brain:[9]\n\nsimple cells, whose output is maximized by straight edges having particular orientations within their receptive field\ncomplex cells, which have larger receptive fields, whose output is insensitive to the exact position of the edges in the field.\nHubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks","45287880":"# **CNN**","ac473ed9":"![](https:\/\/miro.medium.com\/max\/3600\/1*dOv2a1ctNrHDo8Zks30Bbw.png)","5c3a6ff4":"**4 Fully connected layer**\n\nThe layer we call as FC layer, we flattened our matrix into vector and feed it into a fully connected layer like a neural network.\n\n\n\n![](https:\/\/burniegroup.com\/wp-content\/uploads\/2018\/10\/noun_Artificial-Neural-Network_1551919_a30c33.png)","7e933f08":"> Applying convolution to the selected image \n\n> Adding activation (commonly relu)\n\n> Feature extraction through pooling\n\n> Flattening the image and feeding to nueral network\n","15bb2bdd":"**2 Activation function**\n\n\nReLU stands for Rectified Linear Unit for a non-linear operation. The output is \u0192(x) = max(0,x).\n![](http:\/\/)Why ReLU is important : ReLU\u2019s purpose is to introduce non-linearity in our ConvNet. Since, the real world data would want our ConvNet to learn would be non-negative linear values.\n","6d1d3cf5":"**Steps involved in coding**\n\n1 Importing libraries\n\n2 Feature scaling\n\n3 Creating the model\n\n4 Training\n\n5 Prediction","46c831a6":"**Importing the relavant libraries**","cbd48c99":"Introduction. A Convolutional Neural Network (ConvNet\/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects\/objects in the image and be able to differentiate one from the other.","3278f0ee":"\n**1 Convolution layer**\n\n\nConvolution is the first layer to extract features from an input image. Convolution preserves the relationship between pixels by learning image features using small squares of input data. It is a mathematical operation that takes two inputs such as image matrix and a filter or kernel.\n\n\n![](https:\/\/miro.medium.com\/max\/576\/1*kYSsNpy0b3fIonQya66VSQ.png)\n\n\n![](https:\/\/miro.medium.com\/max\/335\/1*MrGSULUtkXc0Ou07QouV8A.gif)","186c84f6":"**MODEL**\n\n","4d663328":"**Prediction**"}}