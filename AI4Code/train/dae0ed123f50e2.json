{"cell_type":{"854c87b9":"code","62b87c1d":"code","fd29cf9a":"code","ea3be224":"code","59f1ebab":"code","1edab59c":"code","6425158c":"code","387cf6e7":"code","47337465":"code","25aa0dd7":"code","11cce775":"code","241cc38a":"code","5080353a":"code","68f0570a":"code","e766996c":"code","a752148a":"code","996eb54c":"code","baaadbab":"code","d616db80":"markdown","9cf2638e":"markdown","d28caebc":"markdown","c1990443":"markdown","ebca76e6":"markdown","d35f2639":"markdown","586aaa9b":"markdown","ff052466":"markdown"},"source":{"854c87b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","62b87c1d":"import pandas as pd\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\npd.set_option('display.max_columns', None)\n","fd29cf9a":"def load_retail_df(path):\n    \"\"\"\n         Returns the  dataset with the path \n         \n         parameters\n         ----------\n         path: str\n            Keeps the index information of the Excel file\n\n         Returns\n         -------\n            dataframe\n\n    \"\"\"\n    return pd.read_csv(path)\n","ea3be224":"def check_df(dataframe, head=5):\n    \"\"\"\n         Written to be able to quickly learn about the dataset\n\n         parameters\n         ----------\n         dataframe: dataframe\n               the dataset you want to look at\n         head: int, float, optional\n               We write how many observations we want to examine from the beginning and the end.\n         Returns\n         -------\n          None\n    \"\"\"\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n","59f1ebab":"def outlier_thresholds(dataframe, variable):\n    \"\"\"\n         Sets lower and upper limits to suppress outliers in the first and last quartiles in the dataset\n\n         Parameters\n         ----------\n         dataframe: dataframe\n             The data set for which you want to set the lower and upper limits\n         variable: str\n             Variable name that contains the outlier in the dataset\n         Returns\n         -------\n             Returns the value of the lower and upper limit\n    \"\"\"\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","1edab59c":"def replace_with_thresholds(dataframe, variable):\n    \"\"\"\n         It is used to suppress the dataset according to the determined lower and upper limit.\n\n         Parameters\n         ----------\n         dataframe: dataframe\n             The dataset to be printed\n         variable: str\n             The variable to be suppressed in the dataset\n\n         Returns\n         -------\n            None\n    \"\"\"\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","6425158c":"def retail_data_prep(dataframe):\n    \"\"\"\n         The data is preprocessed, albeit partially, in the dataset.\n            Invoices that start with the letter C, expressing the return in invoices,\n            are removed from the dataset.\n         Accordingly, negative values are also removed and finally outliers are suppressed.\n         \n         parameters\n         ----------\n         dataframe: dataframe\n             The dataset to be preprocessed\n\n         Returns\n         -------\n         The preprocessed dataset is returned\n    \"\"\"\n    dataframe.dropna(inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe.drop(dataframe[dataframe[\"StockCode\"] == \"POST\"].index, inplace=True)\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe = dataframe[dataframe[\"Price\"] > 0]\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    return dataframe","387cf6e7":"def create_invoice_product_df(dataframe, id=False):\n    \"\"\"\n         We bring our dataset to the shape desired by the apriori algorithm for Association Rule Learning.\n\n         Parameters\n         ----------\n         dataframe: dataframe\n             The dataset required to be suitable for basket analysis (Invoice*Product)\n         id: bool, optional\n            If the id value is not entered, the names of the products will be displayed\n            as the variable names in the dataset, if the id value is entered True\n            Variable names will be used in StockCode with uniqueids representing products\n\n         Returns\n         -------\n             The dataset will be set and returned with Invoice in the rows and Product in the columns\n    \"\"\"\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)","47337465":"# Let's install mlxtend library\n!pip install mlxtend","25aa0dd7":"def create_rules(dataframe, id=True, country=\"France\"):\n    \"\"\"\n     Shows us the association rules\n     \n     Parameters\n     ----------\n     dataframe: dataframe\n         Dataframe converted to Invoice * Product\n         \n     id: bool, optional\n         In the create_invoice_product_df function,\n         it allows to display StockCode or Description\n         as the name of the variables in the columns\n         \n     country: str, optional\n        Assuming that there is more than one country\n        in the dataset and the habits of each country are different,\n        country breakdown is applied.\n\n     Returns\n     -------\n         Association analyzes are returned\n     \"\"\"\n    dataframe = dataframe[dataframe['Country'] == country]\n    dataframe = create_invoice_product_df(dataframe, id)\n    frequent_itemsets = apriori(dataframe, min_support=0.01, use_colnames=True)\n    rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\n    return rules","11cce775":"\ndef arl_recommender(rules_df, product_id, rec_count=1):\n    \"\"\"\n         It helps us recommend the best selling products with the data added to the cart\n\n         Parameters\n         ----------\n         rules_df: dataframe\n             Dataset containing association rules\n\n         product_id: str\n             The code of the product added to the cart is according to the example here StockCode\n\n         rec_count: int\n             How many suggestions should be made?\n\n         Returns\n         -------\n             List of recommended products\n    \"\"\"\n    sorted_rules = rules_df.sort_values(\"lift\", ascending=False)\n\n    recommendation_list = []\n\n    for i, product in sorted_rules[\"antecedents\"].items():\n        for j in list(product):\n            if j == product_id:\n                recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"]))\n\n    recommendation_list = list({item for item_list in recommendation_list for item in item_list})\n\n    return recommendation_list[:rec_count]\n","241cc38a":"def get_desc_by_id(dataframe, stock_code):\n    \"\"\"\n         Returns the names of the entered id or ids\n         \n         Parameters\n         ----------\n         dataframe: dataframe\n             Dataset containing the names of the variables\n             \n         stock_code: str, list\n             If a single value, i.e. str, is entered, it belongs to a single product and returns a single name. If the type is a list, it is used to return the names of all StockCodes.\n        \n         Returns\n         -------\n             Product names are returned\n         \"\"\"\n    if type(stock_code) == list:\n        return ([dataframe[dataframe[\"StockCode\"] == code][[\"Description\"]].values[0].tolist() for code in stock_code])\n    else:\n        product_name = dataframe[dataframe[\"StockCode\"] == stock_code, \"Description\"].values[0]\n        return product_name","5080353a":"df_ = load_retail_df(\"..\/input\/online-retail-ii-uci\/online_retail_II.csv\")\ndf = df_.copy()\ndf['InvoiceDate']=pd.to_datetime(df['InvoiceDate'])\n\ncheck_df(df)","68f0570a":"df = retail_data_prep(df)","e766996c":"rules = create_rules(df, country='Germany')\nrules.head(10)","a752148a":"basket_list = ['21987', '20719', '22747']\nget_desc_by_id(df, stock_code=basket_list)\n","996eb54c":"recommends = {basket_id: arl_recommender(rules_df=rules, product_id=basket_id, rec_count=3) for basket_id in basket_list}\nrecommends\n","baaadbab":"recommend_desc = {key: get_desc_by_id(df, stock_code=recommends.get(key)) for key in recommends}\nrecommend_desc","d616db80":"## Let's Explore and Practice \ud83d\ude80\n\nWe will use Online Retail dataset and suggest products to users at the basket stage.\n\n\n- InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'C', it indicates a cancellation.\n\n- StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product.\n\n- Description: Product (item) name. Nominal.\n\n- Quantity: The quantities of each product (item) per transaction. Numeric.\n\n- InvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated.\n\n- UnitPrice: Unit price. Numeric. Product price per unit in sterling (\u00a3).\n\n- Customer ID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer.\n\n- Country: Country name. Nominal. The name of the country where a customer resides.","9cf2638e":"## Data Preprocessing\n* We observe that there are 4382 NA values in the description and 243007 in the CustomerID. We also see outliers in these variables. Let's edit them with a partial preprocessing \ud83d\ude80","d28caebc":"## Determination of association rules\n* In this application, the association analysis will be made according to Germany. Let's learn the rules of association now \ud83d\ude80","c1990443":"## Interpretation of association rules\n* antecendents = item in cart\n* consequents = product to recommend\n* antecendents support = probability that the item in the cart will appear in the cart\n* consequents support = probability that the proposed product will appear in the cart\n* support = probability that the product in the basket and the product to be recommended will appear in the basket together\n* confidence = probability of buying the recommended product when the product in the cart is purchased\n* lift = shows how many times the probability of buying the product to be recommended increases when the product in the basket is purchased.\n\nLet's examine the first observation together\ud83d\ude80\n\nLet the product number 20719 be bread. Let the product number 15036 be milk. So let's accept it like this to understand\n\n* Probability of only bread appearing in the whole basket = 0.171242\n* Probability of showing only milk in the whole basket = 0.019608\n* Probability of bread and milk appearing in the whole basket = 0.011765\n* Probability of getting milk when bread is bought = 0.068702\n* We observe that when bread is bought, the probability of getting milk increases 3.503817 times.\n\nbasket_list = [21987, 23235, 22747]\n\nLet's have these three products in our basket. Let's check their names \ud83d\ude80","ebca76e6":"## ASSOCIATION RULE LEARNING\n\nPeople who liked this product also liked this one,\nor those who bought this bought this too.\nSounds familiar doesn't it? \nLet's explore how this is done with association rule learning\n\n![Basket Analysis](https:\/\/media-exp1.licdn.com\/dms\/image\/C4E22AQFtakw2Esiz4A\/feedshare-shrink_800\/0\/1632247827174?e=1635379200&v=beta&t=wh6Cjmpr1Ba4DH_R1cfBJRRRjzpLRQRxpnqqy0pmwMc)","d35f2639":"## Product recommendations\n* Now let's make 3 suggestions for each product in the basket.","586aaa9b":"## Thus, we have successfully implemented our recommendation system for this example with basket analysis and association rule learning.\n\n## Let data be your best friend :) \ud83d\ude80","ff052466":"## Names of product recommendations\n* Let's also examine the names of the recommended products for each product in the basket."}}