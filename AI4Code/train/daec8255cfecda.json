{"cell_type":{"40e575c1":"code","01161254":"code","5168e1dc":"code","b07e13c6":"code","257bfcb9":"code","f7d01212":"code","1c4df92c":"code","0e1ef9cd":"code","55fca2e3":"code","439f3fa8":"code","4be3e7ca":"code","6bde9f85":"code","82168f37":"code","8ab1582a":"code","afecae43":"code","628d39b5":"code","00c47fe3":"code","de5357c0":"code","800c8350":"code","55b08b49":"code","82ce7087":"code","dfebaedd":"code","937c64c7":"code","c5e75c2a":"markdown","55a53303":"markdown","721b420c":"markdown","f450b230":"markdown","cc678742":"markdown","388fc306":"markdown","20c15604":"markdown","31ffe48a":"markdown","2a349d50":"markdown","f595c883":"markdown"},"source":{"40e575c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","01161254":"import bz2","5168e1dc":"def labels_text(x):\n  label=[]\n  text=[]\n  for line in bz2.BZ2File(x):\n    decode = line.decode(\"utf-8\")\n    label.append(int(decode[9]) - 1)\n    text.append(decode[10:].strip())\n  return np.array(label),text\n\ntrain_label, train_text = labels_text('\/kaggle\/input\/amazonreviews\/train.ft.txt.bz2')\ntest_label, test_text = labels_text('\/kaggle\/input\/amazonreviews\/test.ft.txt.bz2')","b07e13c6":"from sklearn.utils import shuffle\ntrain_text, train_label = shuffle(train_text, train_label)\ntest_text, test_label = shuffle(test_text, test_label)","257bfcb9":"train_text[0]","f7d01212":"train_label[0]","1c4df92c":"len(train_text)","0e1ef9cd":"len(test_text)","55fca2e3":"train_text=train_text[0:10000]\ntrain_label=train_label[0:10000]","439f3fa8":"test_text=test_text[0:2500]\ntest_label=test_label[0:2500]","4be3e7ca":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus_train=[]\n\nfor i in range(10000):\n    review = re.sub('\".*?\"', '', train_text[i]) #removing any word within quotation marks\n    review = re.sub('[^a-zA-Z]', ' ', review) #keeping only letters and removing anything else\n    review = review.lower() #converting everything to lowercase\n    review = review.split() #splitting each word in string and placing it into a list\n    ps = PorterStemmer() #stemming\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not') \n    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n    review = ' '.join(review) #forming a string form a splitted list of words\n    corpus_train.append(review)","6bde9f85":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus_train).toarray()\ny = train_label[0:10000]","82168f37":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state = 0)","8ab1582a":"from sklearn.svm import SVC\nclassifier = SVC(C=3,kernel = 'rbf', random_state = 0)#2.0=84.52(-),1.75=84.72(83.16),1.5=84.84(83.13),3.25=84.6(-)\nclassifier.fit(X_train, y_train)","afecae43":"y_pred = classifier.predict(X_val)","628d39b5":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_val, y_pred)\nprint(cm)\nacc = accuracy_score(y_val, y_pred)\nprint(acc)","00c47fe3":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","de5357c0":"corpus_test=[]\nfor i in range(2500):\n    review = re.sub('\".*?\"', '', test_text[i]) #removing any word within quotation marks\n    review = re.sub('[^a-zA-Z]', ' ', review) #keeping only letters and removing anything else\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    all_stopwords = stopwords.words('english')\n    all_stopwords.remove('not')\n    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n    review = ' '.join(review)\n    corpus_test.append(review)","800c8350":"X_test = cv.transform(corpus_test).toarray()\ny_test = test_label[0:2500]","55b08b49":"y_pred_new = classifier.predict(X_test)","82ce7087":"cm_final = confusion_matrix(y_test, y_pred_new)\nprint(cm_final)\nacc_final = accuracy_score(y_test, y_pred_new)\nprint(acc_final)","dfebaedd":"new_review = \"I took four photo prints on glossy A4 sheets and \\\n            two photo prints on normal A4 sheets: that means total six copies. \\\n            And there you go, it says the cartridge is exhausted! What a nonsense! \\\n            Rs. 685 for six photos, that too excluding the photo paper costs! \\\n            They are telling lies about the number of prints possible. Maybe \\\n            it may be possible to take 150 colour prints with this with a lot \\\n            of white space, like an MS word document with a few heading lines \\\n            in colours. I have HP Deskjet Ink Advantage 2135 which I bought a \\\n            couple of weeks ago. Neither the printer nor this cartridge is meant \\\n            for photo printing.\"\nnew_review = re.sub('\".*?\"', '', new_review)\nnew_review = re.sub('[^a-zA-Z]', ' ', new_review)\nnew_review = new_review.lower()\nnew_review = new_review.split()\nps = PorterStemmer()\nall_stopwords = stopwords.words('english')\nall_stopwords.remove('not')\nnew_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\nnew_review = ' '.join(new_review)\nnew_corpus = [new_review]\nnew_X_test = cv.transform(new_corpus).toarray()\nnew_y_pred = classifier.predict(new_X_test)\nprint(new_y_pred)","937c64c7":"\"\"\"from sklearn.model_selection import GridSearchCV\nparameters = [{'C': [0.25, 0.5, 0.75, 2, 3], 'kernel': ['rbf'], 'gamma': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}]\ngrid_search = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 5)\ngrid_search.fit(X_train, y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(\"Best Accuracy: {:.2f} %\".format(best_accuracy.mean()*100))\nprint(\"Best Parameters:\", best_parameters)\"\"\"","c5e75c2a":"**Shuffling Dataset (because we will only be using a part of the dataset)**","55a53303":"**FINAL ACCURACY**","721b420c":"**TESTING MODEL ON TEST SET**","f450b230":"**AVERAGE VALIDATION ACCURACY**","cc678742":"**Bag Of Words Model**","388fc306":"**Converting Dataset to Required Format**","20c15604":"**VALIDATION ACCURACY**","31ffe48a":"**Taking 10000 reviews for training and 2500 for testing**","2a349d50":"**Create A Validation Set**","f595c883":"**Any Classification Algorithm that gives best accuracy**"}}