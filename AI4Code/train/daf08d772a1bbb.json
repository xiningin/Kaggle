{"cell_type":{"c900fcd6":"code","5c5fa142":"code","d2fc7c11":"code","ac643232":"code","2fb8da26":"code","799866fb":"code","3a63cd5e":"code","30e6937e":"code","2c2257a8":"code","4711feae":"markdown","4c2059da":"markdown","8f228c04":"markdown","646002d5":"markdown"},"source":{"c900fcd6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torchvision.models as models\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom pathlib import Path\nimport glob\nfrom PIL import Image\nimport torch\nfrom sklearn.manifold import TSNE\nimport random\nimport matplotlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pytorch_lightning as pl\nfrom torch.utils.data import DataLoader, Dataset\nfrom pytorch_lightning.metrics import Accuracy\nimport wandb\n\nimport zipfile\nwith zipfile.ZipFile('..\/input\/platesv2\/plates.zip', 'r') as zip_obj:\n   zip_obj.extractall('\/kaggle\/working\/')\n    \ndataset_dir = Path('\/kaggle\/working\/plates')\nassert(dataset_dir.exists())","5c5fa142":"seed = 42\n\npl.seed_everything(seed)","d2fc7c11":"train_transform = transforms.Compose([\n        transforms.RandomPerspective(distortion_scale=0.2, p=0.1, interpolation=3, fill=255),\n        transforms.RandomChoice([transforms.CenterCrop(180),\n                                 transforms.CenterCrop(160),\n                                 transforms.CenterCrop(140),\n                                 transforms.CenterCrop(120),\n                                 transforms.Compose([transforms.CenterCrop(280),\n                                                     transforms.Grayscale(3),\n                                                     ]),\n                                 transforms.Compose([transforms.CenterCrop(200),\n                                                     transforms.Grayscale(3),\n                                                     ]),\n                                 ]),\n        transforms.RandomApply([\n            transforms.RandomAffine((0,180), translate=(0.2, 0.2), scale=(0.3, 3), fillcolor=0)\n            ],\n            p=0.7\n        ),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.Resize((224, 224)),\n        transforms.ColorJitter(hue=(0.1, 0.2), brightness=(0.5, 1.5)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])","ac643232":"class TestImageDataset(Dataset):\n\n    def __init__(self, root_dir, transform=None):\n\n        self.root_dir = root_dir\n        self.transform = transform\n        self.pictures = []\n        \n        for filename in sorted(glob.glob(f'{root_dir}\/*')):\n            im=Image.open(filename)\n            np_im = im\n            if self.transform:\n                np_im = self.transform(np_im)\n            self.pictures.append(np_im)\n\n        self.pictures = torch.stack(self.pictures)\n            \n\n    def __len__(self):\n        return len(self.pictures)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        sample = self.pictures[idx]\n\n        return sample\n\nclass MyResNet152(pl.LightningModule):\n    \n    def __init__(self, dataset_dir, batch_size=4):\n        super(MyResNet152, self).__init__()\n        self.net = models.resnet152(pretrained=True)\n        \n        # Disable grad for all conv layers\n        for param in self.net.parameters():\n            param.requires_grad = False                \n        \n        # Create some additional layers for ResNet model\n        fc_inputs = self.net.fc.in_features\n        self.net.fc = torch.nn.Sequential(\n            torch.nn.Linear(fc_inputs, 256),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256, 2),\n            torch.nn.Softmax(dim=1)\n        ) \n        self.loss = torch.nn.BCELoss(reduction='mean')\n    \n        self.dataset_dir = dataset_dir\n        # self.batch_size = batch_size\n        self.example_input_array = torch.rand(batch_size, 3, 224, 224)\n        self.metric = Accuracy()\n        \n    def forward(self, x):\n        x = self.net(x)\n        return x\n    \n    def training_step(self, batch, batch_idx):\n        x, y_true = batch\n        y_pred = self(x)[:,1]\n        loss = self.loss(y_pred, y_true.float())\n        pred_labels = (y_pred > 0.5).float()\n        accuracy = self.metric(pred_labels, y_true)\n        return {'loss': loss, 'accuracy': accuracy}\n    \n    \n    def setup(self, stage=None):\n        \n        if stage == 'test':\n            self.test_labels = []\n            self.test_preds = []\n    \n    def test_step(self, batch, batch_idx):\n        \n        y_pred = self(batch)[:,1]\n        pred_labels = (y_pred > 0.5).int()\n        \n        self.test_preds += y_pred.squeeze().tolist()\n        self.test_labels += pred_labels.squeeze().tolist()\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n        \n    def prepare_data(self):\n        self.train_dataset = ImageFolder(root=dataset_dir\/'train', transform=train_transform)\n        self.test_dataset = TestImageDataset(dataset_dir\/'test', transform=test_transform)\n\n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=40, shuffle=True, num_workers=4)\n    \n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, batch_size=64, shuffle=False, num_workers=4)\n    \n    def training_epoch_end(self, outputs):\n  \n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        avg_acc = torch.stack([x['accuracy'].float() for x in outputs]).mean()\n        print(f'{self.current_epoch}.  Loss:  {avg_loss:.6f}   Accuracy: {avg_acc:.6f}')\n\n        logs = {'train_loss': avg_loss, 'train_accuracy': avg_acc}\n        \n        self.prepare_data()\n        return {'avg_train_loss': avg_loss, 'log': logs, 'progress_bar': logs}","2fb8da26":"def show_input(input_tensor, title=''):\n    \n    mean =[0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    \n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nif False:\n    model = MyResNet152(dataset_dir)\n    model.prepare_data()\n    for i in range(10):\n        show_input(model.train_dataset[i][0])","799866fb":"pl.seed_everything(seed)\n\nSUBMIT = True\nif not SUBMIT:\n    from pytorch_lightning.loggers import WandbLogger\n\n    wandb_logger = WandbLogger(project='dirty-dishes')\n    wandb_logger.watch(model, log='all', log_freq=1)\nelse:\n    wandb_logger = None\n\nmodel = MyResNet152(dataset_dir)\n\nEPOCHS_NUM = 100\ntrainer = pl.Trainer(max_epochs=EPOCHS_NUM, progress_bar_refresh_rate=0, logger=wandb_logger, gpus=1)    \ntrainer.fit(model) \n\ncheckpoint_name = 'final.pth'\n\ntrainer.save_checkpoint(checkpoint_name)\n\nif not SUBMIT:\n    wandb.save(checkpoint_name)","3a63cd5e":"trainer.test(model)","30e6937e":"(np.array(model.test_preds) > 0.5).mean()","2c2257a8":"THRESHOLD = 0.5\n\nsub_df = pd.read_csv('..\/input\/platesv2\/sample_submission.csv')\nsub_df['label'] = model.test_preds\nsub_df['label'] = sub_df['label'].apply(lambda x: 'dirty' if x > THRESHOLD else 'cleaned')\nsub_df.to_csv(f'submission.csv', index=False)","4711feae":"## Getting Predictions","4c2059da":"## Preparation","8f228c04":"# Pytorch Lightning\n\nCredit to [this kernel](https:\/\/www.kaggle.com\/sergeiboltovskii\/baseline-in-pytorch)","646002d5":"## Training"}}