{"cell_type":{"6c8c8c9d":"code","06c5d4b7":"code","ba8981a6":"code","25c8ae4d":"code","f4cf6b1d":"code","99ed5b24":"code","35b4c5b1":"code","1564d6f3":"code","0272f71c":"code","afacc2fa":"code","a204346a":"code","ca0e5878":"code","56047d2e":"code","65fca024":"code","a3146bb1":"code","7e0c9c26":"code","26341881":"code","ee05c489":"code","36f4c487":"code","b9ef7e58":"code","90aff0fd":"code","0ee6d265":"code","b09fcf69":"code","053014d0":"code","84744b9b":"code","a485e715":"code","163ad617":"code","76d01fdb":"code","4d4ce451":"code","0cfdca83":"code","1a9710cd":"code","e50db026":"code","2fc3d5d7":"code","0f2bc614":"code","8bdb14b4":"markdown","b8dab87f":"markdown","4948a9e5":"markdown","cbc987fb":"markdown","1f144d40":"markdown","f04a9698":"markdown","aaeb6c23":"markdown","cc31a935":"markdown","3437e3ad":"markdown","39b6cd65":"markdown","076658f8":"markdown","eb7c16c1":"markdown","5e515408":"markdown","e25f73cc":"markdown","fafa5a1d":"markdown","fc76f65b":"markdown","fe49b310":"markdown","e1069a46":"markdown","74583618":"markdown","d1f62445":"markdown","d3590ab8":"markdown","454dc96a":"markdown","91fd6da5":"markdown","d76406fa":"markdown","cc9c498f":"markdown","2e494f8b":"markdown","856e4491":"markdown","9adb3d6a":"markdown","dba2244d":"markdown","96b9e1df":"markdown","6c07867f":"markdown","bac8fc31":"markdown","cc3e3040":"markdown","4e65d8c5":"markdown","d35a2c4f":"markdown","5c567547":"markdown","9bd25f0d":"markdown","aed5b4d1":"markdown","99feb8d9":"markdown","6c543245":"markdown"},"source":{"6c8c8c9d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n","06c5d4b7":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","ba8981a6":"df_train.columns","25c8ae4d":"df_train.head(10)","f4cf6b1d":"df_train['SalePrice'].describe()","99ed5b24":"#histogram\nsns.distplot(df_train['SalePrice']);","35b4c5b1":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","1564d6f3":"#scatter plot grlivarea\/saleprice\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","0272f71c":"#scatter plot totalbsmtsf\/saleprice\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","afacc2fa":"#box plot overallqual\/saleprice\nvar = 'OverallQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","a204346a":"var = 'YearBuilt'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);","ca0e5878":"#correlation matrix\ncorrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","56047d2e":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","65fca024":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df_train[cols], size = 2.5)\nplt.show();","a3146bb1":"#missing data\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)\n","7e0c9c26":"#dealing with missing data\ndf_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\ndf_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\ndf_train.isnull().sum().max() #just checking that there's no missing data missing...","26341881":"#standardizing data\nsaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","ee05c489":"#bivariate analysis saleprice\/grlivarea\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","36f4c487":"#identifying the indices of the outliers\ndf_train.sort_values(by = 'GrLivArea', ascending = False)[:2]\n","b9ef7e58":"#deleting outliers\ndf_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\ndf_train = df_train.drop(df_train[df_train['Id'] == 524].index)","90aff0fd":"#bivariate analysis saleprice\/grlivarea\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","0ee6d265":"#histogram and normal probability plot\nsns.distplot(df_train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","b09fcf69":"#applying log transformation\ndf_train['SalePrice'] = np.log(df_train['SalePrice'])","053014d0":"#transformed histogram and normal probability plot\nsns.distplot(df_train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","84744b9b":"#histogram and normal probability plot\nsns.distplot(df_train['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt)\n","a485e715":"#data transformation\ndf_train['GrLivArea'] = np.log(df_train['GrLivArea'])","163ad617":"#transformed histogram and normal probability plot\nsns.distplot(df_train['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt)","76d01fdb":"#histogram and normal probability plot\nsns.distplot(df_train['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['TotalBsmtSF'], plot=plt)","4d4ce451":"#create column for new variable (one is enough because it's a binary categorical feature)\n#if area>0 it gets 1, for area==0 it gets 0\ndf_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\ndf_train['HasBsmt'] = 0 \ndf_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1","0cfdca83":"#transform data\ndf_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])","1a9710cd":"#histogram and normal probability plot\nsns.distplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","e50db026":"#scatter plot\nplt.scatter(df_train['GrLivArea'], df_train['SalePrice']);","2fc3d5d7":"#scatter plot\nplt.scatter(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], df_train[df_train['TotalBsmtSF']>0]['SalePrice']);","0f2bc614":"#converting categorical variables into dummy variables\ndf_train = pd.get_dummies(df_train)","8bdb14b4":"#  Selection of significant variables based on an numerical\/correlations\/visual analysis","b8dab87f":"In the above plot (which was already previously plotted):\nThe two far RHS observations are likely to be outliers, we'll thus delete them.  \nThe two highest observations seem to be aligned with the trend (and in fact, correspond to the two outliers near 7 discused in the previous paragraph) so we'll keep them.","4948a9e5":"# References used  \n\n[Comprehensive data exploration with Python](https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python) by Pedro Marcelino  \n\n[Data analysis and feature extraction with Python](https:\/\/www.kaggle.com\/pmarcelino\/data-analysis-and-feature-extraction-with-python) by Pedro Marcelino ","cbc987fb":"# Abstract  \nWe analyse 'SalePrice' by itself and with the most correlated variables.  \nWe deal with missing data and outliers.  \nWe test some of the fundamental statistical assumptions.   \nFinally, we transform categorial variables into dummy variables.  \n\nThis work is based on the references and will be further extended in the future. In particular, more exploratory data analysis and feature engineering will be performed.  Also, various regression models will be applied to this data for evaluation purposes. ","1f144d40":"Outliers is a complex subjet because it may or may not contain important information.  \n### Univariate analysis  \nThe primary concern here is to establish a threshold that defines an observation as an outlier. To do so, we'll standardize the data, that is, we'll convert data values to have a mean of 0 and a standard deviation of 1.","f04a9698":"Similarly, post transformation, in the above plot, 'SalePrice' exhibit equal levels of variance across the range of 'TotalBsmtSF', thus showing homoscedasticity.","aaeb6c23":"For this data,we'll consider that when more than 15% of the data is missing, we should delete the corresponding variable and pretend it never existed (e.g. 'PoolQC', 'MiscFeature', 'Alley', etc.), specially since none of these variables seem to be \"statistically\" significant (according to the analysis in the previous section), and are strong candidates for outliers.  \n\n'GarageX' variables have the same number of missing data, and thus probably refer to the same set of observations. Since the most important information regarding garages is already expressed by 'GarageCars' and considering that we are just talking about 5% of missing data, we'll delete the mentioned 'GarageX' variables. The same logic applies to 'BsmtX' variables.  \n\nRegarding 'MasVnrArea' and 'MasVnrType', we can consider that these variables are not essential. Furthermore, they have a strong correlation with 'YearBuilt' and 'OverallQual' which are already considered. Thus, we will not lose information if we delete 'MasVnrArea' and 'MasVnrType'.  \n\nFinally, we have one missing observation in 'Electrical'. Since it is just one observation, we'll delete this observation and keep the variable.  \n\nIn summary, to handle missing data, we'll delete all the variables with missing data, except the variable 'Electrical'. In 'Electrical' we'll just delete the observation with missing data.  ","cc31a935":"###  Relationship with categorical features","3437e3ad":"The above post log transformation plot exhibits homoscedasticity. By contrast, prior to the log transformation, in the bivariate scatter plots in the previous sections above these variables had a conic shape.  \n**Notice the power of normality! By just ensuring normality in some variables, we solved the homoscedasticity problem.**","39b6cd65":"Skewness is seen so the same type of transformation as above should work.  \n### GrLivArea plots after a transformation  \n","076658f8":"### 'SalePrice' correlation matrix (zoomed heatmap style)","eb7c16c1":"The above graph shows that buyers are more prone to spend more money in new houses than in old relics (however, this is not a strong trend).","5e515408":"# Dependent variable analysis ","e25f73cc":"(above we're practically dividing the total number of nulls in a column per the total number of rows in that column)","fafa5a1d":"'SalePrice' is not normal. It shows positive kurtosis (i.e. peakedness), positive skewness and does not follow the diagonal line.  \n\n### SalePrice plots after a transformation  \nTransformation to get a normal distribution:  in case of positive skewness, log transformations usually works well.  ","fc76f65b":"### SalePrice original plots","fe49b310":"# Converting categorical variables into dummy variables","e1069a46":"We can feel tempted to eliminate some observations (e.g. TotalBsmtSF > 3000) but for now let us just not delete any of them.","74583618":"In the above histogram we have skewness but in the probability plot we have a significant number of observations with zero value (houses without basement), which do not allow us to do log transformations.  \n### TotalBsmtSF plots after a transformation  \nIn order to do a log transformation here, we'll create a variable that can give the effect of having or not having a basement (binary variable). Then, we'll do a log transformation of all the non-zero observations, thus ignoring those with zero values. This should enable us to transform the data, without losing the effect of having or not having a basement (there is a chance that this is not the right treatment but as shown in the plots below the results look good). ","d1f62445":"# Outliers","d3590ab8":"As shown above, the transformation results in normalization.  \n### TotalBsmtSF original plots","454dc96a":"### Scatter plots of the most correlated variables with'SalePrice'","91fd6da5":"The above correlations matrix shows:  \n* Very Strong correlations (yellow colored squares) between  'TotalBsmtSF' and '1stFlrSF' variables; and the'GarageX' variables (in each case variables give almost the same information implying multicollinearity).  \n* Notable 'SalePrice' correlations with 'GrLivArea', 'TotalBsmtSF', 'OverallQual' (confirming our previous subjective analysis above) and others that we examine below.  ","d76406fa":"The above graph shows that for houses with a basement there is a linear(almost exponential) relationship, and also another branch for the no basement case.","cc9c498f":"### Correlation matrix (heatmap style)","2e494f8b":"### GrLivArea original plots","856e4491":"According to the above standarization, we have a long tail only on the positive axis, thus with possibly 2 outliers near 7 (which for now we won't consider them to be outliers).  \n### Bivariate analysis  \n","9adb3d6a":"# Missing Data","dba2244d":"### In the search for normality\nThe point here is to test 'SalePrice' in a very lean way. We'll do this paying attention to:\n\n**Histogram** - Kurtosis and skewness.  \n**Normal Probability Plot** - Data distribution should closely follow the diagonal line that represents the normal distribution.","96b9e1df":"###  Relationship with numerical variables","6c07867f":"### Homoscedasticity Test  \nThe best approach to test homoscedasticity for two metric variables is graphically. Departures from an equal dispersion are shown by such shapes as cones (small dispersion at one side of the graph, large dispersion at the opposite side) or diamonds (a large number of points at the center of the distribution).  ","bac8fc31":"The above matrix of the 10 (=k) variables most correlated with 'SalePrice'shows that:  \n\n* 'OverallQual', 'GrLivArea' and 'TotalBsmtSF' are strongly correlated with 'SalePrice'.   \n* 'GarageCars' and 'GarageArea' are also some of the most strongly correlated variables. However, since the number of cars that fit into the garage is limited by the garage area, 'GarageCars' is highly correlated with 'GarageArea' and thus only one of these variables needs to remain in the analysis (we can keep 'GarageCars' since its correlation with 'SalePrice' is higher).  \n* 'TotalBsmtSF' and '1stFloor' are also correlated with 'SalePrice', and with each other for obvious reasons. We can keep 'TotalBsmtSF'.\n* 'FullBath'is correlated with 'SalePrice'.  \n* 'TotRmsAbvGrd' is highly correlated with 'GrLivArea'.  \n* 'YearBuilt' is slightly correlated with 'SalePrice'.  ","cc3e3040":"# Selection of significant variables based on qualitative\/subjective analysis  \nThe **bold face variables below** were selected based on qualitative thinking and visual inspections of SalePrice plots versus the variables (ironically, Neighborhood (location) was not found to be significant; but this is perhaps due to using scatter plots instead of boxplots (which are more suitable for categorical variable visualization) in the visual inspections). This selection will be confirmed numerically through a correlation analysis in the next section.   \n  \n**SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.**  \n* MSSubClass: The building class\n* MSZoning: The general zoning classification\n* LotFrontage: Linear feet of street connected to property\n* LotArea: Lot size in square feet\n* Street: Type of road access\n* Alley: Type of alley access\n* LotShape: General shape of property\n* LandContour: Flatness of the property\n* Utilities: Type of utilities available\n* LotConfig: Lot configuration\n* LandSlope: Slope of property\n* Neighborhood: Physical locations within Ames city limits\n* Condition1: Proximity to main road or railroad\n* Condition2: Proximity to main road or railroad (if a second is present)\n* BldgType: Type of dwelling\n* HouseStyle: Style of dwelling  \n**OverallQual: Overall material and finish quality**  \n* OverallCond: Overall condition rating  \n**YearBuilt: Original construction date**  \n* YearRemodAdd: Remodel date\n* RoofStyle: Type of roof\n* RoofMatl: Roof material\n* Exterior1st: Exterior covering on house\n* Exterior2nd: Exterior covering on house (if more than one material)\n* MasVnrType: Masonry veneer type\n* MasVnrArea: Masonry veneer area in square feet\n* ExterQual: Exterior material quality\n* ExterCond: Present condition of the material on the exterior\n* Foundation: Type of foundation\n* BsmtQual: Height of the basement\n* BsmtCond: General condition of the basement\n* BsmtExposure: Walkout or garden level basement walls\n* BsmtFinType1: Quality of basement finished area\n* BsmtFinSF1: Type 1 finished square feet\n* BsmtFinType2: Quality of second finished area (if present)\n* BsmtFinSF2: Type 2 finished square feet\n* BsmtUnfSF: Unfinished square feet of basement area  \n**TotalBsmtSF: Total square feet of basement area**  \n* Heating: Type of heating\n* HeatingQC: Heating quality and condition\n* CentralAir: Central air conditioning\n* Electrical: Electrical system\n* 1stFlrSF: First Floor square feet\n* 2ndFlrSF: Second floor square feet\n* LowQualFinSF: Low quality finished square feet (all floors)  \n**GrLivArea: Above grade (ground) living area square feet**  \n* BsmtFullBath: Basement full bathrooms\n* BsmtHalfBath: Basement half bathrooms\n* FullBath: Full bathrooms above grade\n* HalfBath: Half baths above grade\n* Bedroom: Number of bedrooms above basement level\n* Kitchen: Number of kitchens\n* KitchenQual: Kitchen quality\n* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n* Functional: Home functionality rating\n* Fireplaces: Number of fireplaces\n* FireplaceQu: Fireplace quality\n* GarageType: Garage location\n* GarageYrBlt: Year garage was built\n* GarageFinish: Interior finish of the garage\n* GarageCars: Size of garage in car capacity\n* GarageArea: Size of garage in square feet\n* GarageQual: Garage quality\n* GarageCond: Garage condition\n* PavedDrive: Paved driveway\n* WoodDeckSF: Wood deck area in square feet\n* OpenPorchSF: Open porch area in square feet\n* EnclosedPorch: Enclosed porch area in square feet\n* 3SsnPorch: Three season porch area in square feet\n* ScreenPorch: Screen porch area in square feet\n* PoolArea: Pool area in square feet\n* PoolQC: Pool quality\n* Fence: Fence quality\n* MiscFeature: Miscellaneous feature not covered in other categories\n* MiscVal: $Value of miscellaneous feature\n* MoSold: Month Sold\n* YrSold: Year Sold\n* SaleType: Type of sale\n* SaleCondition: Condition of sale","4e65d8c5":"Based on the correlation matrix above, we select the variables that are the most correlated with SalePrice to examine them further:","d35a2c4f":"Important questions about missing data:  \n\nHow prevalent is the missing data? Missing data can imply a reduction of the sample size. This can prevent us from proceeding with the analysis.  \nIs missing data random or does it have a pattern? We need to ensure that the missing data process is not biased and hidding an inconvenient truth.   \n","5c567547":"The above plot has a lot of information about the relationships between variables. For instance, notice:  \n\n'TotalBsmtSF' and 'GrLiveArea' - basement areas are usually less than the above ground living area  \n\n'SalePrice' and 'YearBuilt' - the 'dots cloud' appears to be have a somewhat exponential function, prices have been increasing faster more recently","9bd25f0d":"The above graph shows a rough linear (somewhat exponential) relationship.","aed5b4d1":"# *Explanatory Data Analysis | House Prices*  \n**David Rivas, Ph.D.**  ","99feb8d9":"# Variables tested against the multivariate analysis assumptions  \nThe four statistical assumptions that must be tested in order for a multivariate analysis to be valid are [Multivariate Data Analysis](https:\/\/www.amazon.com\/Multivariate-Data-Analysis-Joseph-Hair\/dp\/9332536503\/ref=as_sl_pc_tf_til?tag=pmarcelino-20&linkCode=w00&linkId=5e9109fa2213fef911dae80731a07a17&creativeASIN=9332536503):  \n\n**Normality** - The data should look like a normal distribution. This is important because several statistic tests rely on this (e.g. t-statistics). In this exercise we'll just check univariate normality for 'SalePrice' (which is a limited approach). Remember that univariate normality doesn't ensure multivariate normality (which is what we would like to have), but it helps. Another detail to take into account is that with big samples (>200 observations) normality is not such an issue. However, if we solve normality, we avoid a lot of other problems (e.g. heteroscedasticity - opposite to homoscedasticity) which is the main reason why we are doing this analysis.  \n\n**Homoscedasticity** - It refers to the 'assumption that dependent variable(s) exhibit equal levels of variance across the range of predictor variable(s). Homoscedasticity is desirable because we want the error term to be the same across all values of the independent variables.  \n\n**Linearity**- The most common way to assess linearity is to examine scatter plots and search for linear patterns. If patterns are not linear, it would be worthwhile to explore data transformations. However, we'll not get into this because most of the scatter plots we've seen appear to have linear relationships.  \n\n**Absence of correlated errors** - Correlated errors occur when one error is correlated to another. For instance, if one positive error makes a negative error systematically, it means that there's a relationship between these variables. This occurs often in time series, where some patterns are time related. We'll also not get into this. However, if you detect something, try to add a variable that can explain the effect you're getting. That's the most common solution for correlated errors.  ","6c543245":"The above graph shows a linear relationship."}}