{"cell_type":{"992c4a79":"code","de596b21":"code","1dc0a375":"code","5fc96328":"code","de6cc31b":"code","1d3165ec":"code","8e2c9720":"code","23a0e628":"code","c0397f02":"code","2cf604d0":"code","dad5ec7e":"code","bd58ae18":"code","85d7f1fa":"code","81578fce":"code","749e214a":"code","f0e253e4":"code","facc7e64":"code","23dff43a":"code","9164fdce":"markdown","70dee147":"markdown","16971391":"markdown","a0e72a87":"markdown","486a0d70":"markdown","ac3f759a":"markdown","0df4b119":"markdown","09ceeb56":"markdown"},"source":{"992c4a79":"# Libraries \nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport os\n","de596b21":"#importing training dataset\ntrain=pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Train.csv')\nX_train=train['Path']\ny_train=train.ClassId\ntrain","1dc0a375":"data_dir = \"..\/input\/gtsrb-german-traffic-sign\"\ntrain_imgpath= list((data_dir + '\/' + str(train.Path[i])) for i in range(len(train.Path)))","5fc96328":"for i in range(0,9):\n    plt.subplot(331+i)\n    seed=np.random.randint(0,39210)\n    im = Image.open(train_imgpath[seed])  \n    plt.imshow(im)\n    \nplt.show()","de6cc31b":"train_data=[]\ntrain_labels=[]\n\n\npath = \"..\/input\/gtsrb-german-traffic-sign\/\"\nfor i in range(len(train.Path)):\n    image=cv2.imread(train_imgpath[i])\n    image_from_array = Image.fromarray(image, 'RGB')\n    size_image = image_from_array.resize((28,28))\n    train_data.append(np.array(size_image))\n    train_labels.append(train.ClassId[i])\n\n\nX=np.array(train_data)\ny=np.array(train_labels)","1d3165ec":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split( X, y, test_size=0.20, random_state=7777)  ","8e2c9720":"#Spliting the images into train and validation sets\n\nX_train = X_train.astype('float32')\/255 \nX_val = X_val.astype('float32')\/255\n\n#Using one hote encoding for the train and validation labels\nfrom keras.utils import to_categorical\ny_train = to_categorical(y_train, 43)\ny_val = to_categorical(y_val, 43)","23a0e628":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam\nfrom keras.layers import Dropout","c0397f02":"def create_model(layers):\n    cnn = tf.keras.models.Sequential()\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 3]))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Flatten())\n    \n    for i, nodes in enumerate(layers):\n        cnn.add(tf.keras.layers.Dense(units=nodes, activation='relu'))\n            \n    cnn.add(tf.keras.layers.Dense(units=43, activation='softmax'))\n    \n    cnn.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn\n\nmodel = KerasClassifier(build_fn=create_model, verbose=1)\nlayers = [[128],(256, 128),(200, 150, 120)]\nparam_grid = dict(layers=layers)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_val, y_val))\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","2cf604d0":"def create_model1():\n    # create model\n    cnn = tf.keras.models.Sequential()\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 3]))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Flatten())\n    cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\n    cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n    cnn.add(tf.keras.layers.Dense(units=43, activation='softmax'))\n    \n    # compile the model\n    cnn.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model1, verbose = 1)\n\n# define the grid search parameters\nbatch_size = [20,40]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(batch_size=batch_size)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_val, y_val))\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","dad5ec7e":"def create_model2(dropout):\n    # create model\n    cnn = tf.keras.models.Sequential()\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 3]))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Flatten())\n    cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\n    cnn.add(Dropout(dropout))\n    cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n    cnn.add(Dropout(dropout))\n    cnn.add(tf.keras.layers.Dense(units=43, activation='softmax'))\n    \n    # compile the model\n    cnn.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model2, verbose = 1,epochs=10, batch_size=20)\n\n# define the grid search parameters\ndropout = [0.0, 0.1, 0.2]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(dropout=dropout)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_val, y_val))\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","bd58ae18":"#Definition of the DNN model\n\ncnn = tf.keras.models.Sequential()\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 3]))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\ncnn.add(tf.keras.layers.Flatten())\ncnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\ncnn.add(Dropout(0.2))\ncnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\ncnn.add(Dropout(0.2))\ncnn.add(tf.keras.layers.Dense(units=43, activation='softmax'))\n\n# compile the model\ncnn.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nhistory = cnn.fit(X_train, y_train, batch_size=20, epochs=20,validation_data=(X_val, y_val))\n","85d7f1fa":"import matplotlib.pyplot as plt\n\nplt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()","81578fce":"test=pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Test.csv')\nX_test=train['Path']\ny_test=train.ClassId","749e214a":"data_dir = \"..\/input\/gtsrb-german-traffic-sign\"\ntest_imgpath= list((data_dir + '\/' + str(test.Path[i])) for i in range(len(test.Path)))\n","f0e253e4":"test_data=[]\ntest_labels=[]\n\n\npath = \"..\/input\/gtsrb-german-traffic-sign\/\"\nfor i in range(len(test.Path)):\n    image=cv2.imread(test_imgpath[i])\n    image_from_array = Image.fromarray(image, 'RGB')\n    size_image = image_from_array.resize((28,28))\n    test_data.append(np.array(size_image))\n    test_labels.append(test.ClassId[i])\n\n\nX_test=np.array(test_data)\ny_test=np.array(test_labels)\n\nX_test = X_test.astype('float32')\/255 ","facc7e64":"#predictions-\npred = cnn.predict_classes(X_test)","23dff43a":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, pred)","9164fdce":"inputing the parameters in the final model \n(for better accuracy, you can run grid search multiple times zooming into each range used before)","70dee147":"# preparing test data","16971391":"# **Preprocessing image-**\nconverting images into arrays of the form (28,28,3)","a0e72a87":"Grid Search to determine the layers and neurons in each layer in the sequential model.\n","486a0d70":"Grid Search to determine the batch size","ac3f759a":"# CNN Model-\n","0df4b119":"Plotting the values of accuracy and loss vs epoch to visually determine the suitable number of epochs required","09ceeb56":"Grid Search to determine the dropout rate\n"}}