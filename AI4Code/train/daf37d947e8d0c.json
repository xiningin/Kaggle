{"cell_type":{"4ecf4123":"code","38f41dc8":"code","8db32036":"code","96c7f700":"code","08b33349":"code","69492906":"code","03d3b06c":"code","8532bc83":"code","1e6d79d6":"code","c5e6a5b0":"code","9c7bb8a1":"code","f6f0baf1":"code","bb4c03d9":"code","cbc0a8e3":"code","30b256da":"code","cf90c6dd":"code","de0cfcc7":"code","d5adfbb2":"markdown","405f1410":"markdown","f322720b":"markdown","0396c9e5":"markdown","88176f1b":"markdown","f2c1bcaa":"markdown","e81de789":"markdown","e4810d7e":"markdown","c9de343c":"markdown","5ae814c3":"markdown","151316a7":"markdown","1a85b1b1":"markdown","06336dbc":"markdown","b6e878d0":"markdown"},"source":{"4ecf4123":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","38f41dc8":"train = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\n\ndef get_train_file_path(image_id):\n    return \"..\/input\/petfinder-pawpularity-score\/train\/{}.jpg\".format(image_id)\n\ndef get_test_file_path(image_id):\n    return \"..\/input\/petfinder-pawpularity-score\/test\/{}.jpg\".format(image_id)\n\ntrain['file_path'] = train['Id'].apply(get_train_file_path)\ntest['file_path'] = test['Id'].apply(get_test_file_path)\n\ndisplay(train.head())\ndisplay(test.head())","8db32036":"train['Pawpularity'].hist()","96c7f700":"plt.figure(figsize=(20, 20))\nrow, col = 5, 5\nfor i in range(row * col):\n    plt.subplot(col, row, i+1)\n    image = cv2.imread(train.loc[i, 'file_path'])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    target = train.loc[i, 'Pawpularity']\n    plt.imshow(image)\n    plt.title(f\"target: {target}\")\nplt.show()","08b33349":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nMODEL_DIR = '..\/input\/petfinder-efficientnet-b0-starter-training\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","69492906":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    size=512\n    batch_size=32\n    model_name='tf_efficientnet_b0_ns'\n    seed=42\n    target_size=1\n    target_col='Pawpularity'\n    n_fold=5","03d3b06c":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport sys\nimport math\nimport time\nimport pickle\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nimport timm\n\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","8532bc83":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n    return score\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","1e6d79d6":"train = pd.read_pickle('..\/input\/petfinder-efficientnet-b0-starter-training\/train.pkl')\ndisplay(train.groupby(['fold', \"bins\"]).size())","c5e6a5b0":"# ====================================================\n# Dataset\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image = self.transform(image=image)['image']\n        return image","9c7bb8a1":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            A.RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","f6f0baf1":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.fc = nn.Linear(self.n_features, self.cfg.target_size)\n\n    def feature(self, image):\n        feature = self.model(image)\n        return feature\n        \n    def forward(self, image):\n        feature = self.feature(image)\n        output = self.fc(feature)\n        return output","bb4c03d9":"# ====================================================\n# Helper functions\n# ====================================================\ndef get_features(test_loader, model, device):\n    model.eval()\n    features = []\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    for step, (images) in tk0:\n        images = images.to(device)\n        batch_size = images.size(0)\n        with torch.no_grad():\n            feature = model.feature(images)\n        features.append(feature.to('cpu').numpy())\n    features = np.concatenate(features)\n    return features","cbc0a8e3":"IMG_FEATURES = []\ntest_dataset = TestDataset(train, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, \n                         batch_size=CFG.batch_size * 2, \n                         shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\nfor fold in range(CFG.n_fold):\n    model = CustomModel(CFG, pretrained=False)\n    state = torch.load(MODEL_DIR+f'{CFG.model_name}_fold{fold}_best.pth', \n                       map_location=torch.device('cpu'))['model']\n    model.load_state_dict(state)\n    model.to(device)\n    features = get_features(test_loader, model, device)\n    IMG_FEATURES.append(features)\n    del state; gc.collect()\n    torch.cuda.empty_cache()","30b256da":"# ====================================================\n# Model\n# ====================================================\ndef run_single_lightgbm(param, train, features, target, fold=0, categorical=[]):\n    \n    train[[f\"img_{i}\" for i in np.arange(1280)]] = IMG_FEATURES[fold]\n    \n    trn_idx = train[train.fold != fold].index\n    val_idx = train[train.fold == fold].index\n    LOGGER.info(f'train size : {len(trn_idx)}  valid size : {len(val_idx)}')\n    \n    if categorical == []:\n        trn_data = lgb.Dataset(train.iloc[trn_idx][features].values, label=target.iloc[trn_idx].values)\n        val_data = lgb.Dataset(train.iloc[val_idx][features].values, label=target.iloc[val_idx].values)\n    else:\n        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx].values, categorical_feature=categorical)\n        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx].values, categorical_feature=categorical)\n        \n    num_round = 10000\n    clf = lgb.train(param, \n                    trn_data,\n                    num_round,\n                    valid_sets=[trn_data, val_data],\n                    verbose_eval=10,\n                    early_stopping_rounds=10)\n    LOGGER.info(f'Dumping model with pickle... lightgbm_fold{fold}.pkl')\n    with open(OUTPUT_DIR+f'lightgbm_fold{fold}.pkl', 'wb') as fout:\n        pickle.dump(clf, fout)\n    \n    oof = np.zeros(len(train))\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    score = get_score(target.iloc[val_idx].values, oof[val_idx])\n    LOGGER.info(f\"fold{fold} score: {score:<.5f}\")\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold\n\n    return oof, fold_importance_df, val_idx\n\n\ndef run_kfold_lightgbm(param, train, features, target, n_fold=5, categorical=[]):\n    \n    oof = np.zeros(len(train))\n    feature_importance_df = pd.DataFrame()\n    val_idxes = []\n    \n    for fold in range(n_fold):\n        LOGGER.info(f\"===== Fold {fold} =====\")\n        _oof, fold_importance_df, val_idx = run_single_lightgbm(param, \n                                                                train, features, target, \n                                                                fold=fold, categorical=categorical)\n        oof += _oof\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        val_idxes.append(val_idx)\n    \n    val_idxes = np.concatenate(val_idxes)\n    score = get_score(target.iloc[val_idxes].values, oof[val_idxes])\n    LOGGER.info(f\"CV score: {score:<.5f}\")\n    \n    return oof, feature_importance_df, val_idxes\n\n\ndef show_feature_importance(feature_importance_df):\n    cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n                .groupby(\"Feature\").mean().sort_values(by=\"importance\", ascending=False)[:50].index)\n    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n    plt.figure(figsize=(8, 16))\n    sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n    plt.title('Features importance (averaged\/folds)')\n    plt.tight_layout()\n    plt.savefig(OUTPUT_DIR+'feature_importance_df_lightgbm.png')","cf90c6dd":"target = train['Pawpularity']\nfeatures = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n            'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'] + [f\"img_{i}\" for i in np.arange(1280)]\n\nlgb_param = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.01,\n    'seed': 42,\n    'max_depth': -1,\n    'min_data_in_leaf': 10,\n    'verbosity': -1,\n}\n\noof, feature_importance_df, _ = run_kfold_lightgbm(lgb_param, \n                                                   train, features, target, \n                                                   n_fold=5, categorical=[])\n\nshow_feature_importance(feature_importance_df)\nfeature_importance_df.to_csv(OUTPUT_DIR+f'feature_importance_df.csv', index=False)","de0cfcc7":"train['pred'] = oof\nscore = get_score(train['Pawpularity'].values, train['pred'].values)\nLOGGER.info(f\"CV: {score:<.5f}\")\ntrain[['Id', 'Pawpularity', 'pred']].to_pickle(OUTPUT_DIR+'oof.pkl')","d5adfbb2":"# Directory settings","405f1410":"# Data Loading","f322720b":"# About this notebook\n- PyTorch efficientnet_b0 + LGB starter code\n- efficientnet_b0 if from https:\/\/www.kaggle.com\/yasufuminakama\/petfinder-efficientnet-b0-starter-training\n\nIf this notebook is helpful, feel free to upvote :)","0396c9e5":"# Helper functions","88176f1b":"# LGB","f2c1bcaa":"# Library","e81de789":"# Dataset","e4810d7e":"# Transforms","c9de343c":"# CFG","5ae814c3":"# Utils","151316a7":"# MODEL","1a85b1b1":"![](https:\/\/www.petfinder.my\/images\/cuteness_meter.jpg)","06336dbc":"# Quick EDA","b6e878d0":"# CV split"}}