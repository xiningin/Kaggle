{"cell_type":{"201806ba":"code","4ff679a7":"code","4c654ff1":"code","911d66ff":"code","cc9c8444":"code","0451c0c5":"code","b4f6c046":"code","8722db8e":"code","e1e59fae":"code","f248d02d":"code","a2d5cf44":"code","37d047c9":"code","354ba2ff":"code","ed7e00c2":"code","ddde0b5a":"code","7e7ec43d":"code","5f7d4d2d":"code","abe43768":"code","e5ff37e5":"code","baba4518":"code","cdf97275":"code","98a4b294":"code","fdc45440":"code","d9025660":"code","838fd776":"code","295801ce":"code","a52e2ace":"code","586addf9":"code","f98d8f8e":"code","6915d649":"code","fe8c1bff":"code","75ab275d":"code","b4691218":"code","301c353c":"code","79803e35":"code","aaa6b04d":"markdown","50e070b2":"markdown","e6d672e0":"markdown","a1c17520":"markdown","00efb841":"markdown","29b9ec0f":"markdown","78b8713a":"markdown","70e4b64a":"markdown","7b4e8718":"markdown","de118fce":"markdown","384ea609":"markdown","64efee5a":"markdown","fb8eec92":"markdown","e5595fc9":"markdown","84406fe8":"markdown","e27ad019":"markdown","49e3d624":"markdown","c7ffd90d":"markdown","4acfc255":"markdown","104bbb65":"markdown","7fc2dad7":"markdown","fa6c86e3":"markdown","b4dbde18":"markdown","0d9458bb":"markdown","7da640d6":"markdown","6a5995de":"markdown","e2ca0b90":"markdown","2c899010":"markdown","6071a01d":"markdown","bca55921":"markdown","213a6bf3":"markdown","c60e580c":"markdown"},"source":{"201806ba":"## Data and Visualization\nimport pandas as pd \nimport numpy as np\npd.options.mode.chained_assignment = None  # default='warn'\n%config InlineBackend.figure_format='retina'\nimport matplotlib.pyplot as plt\n\n%load_ext autoreload\n%autoreload 2\nfrom wordcloud import WordCloud, STOPWORDS\nfrom utils_vis import explore_label, TSNE_Visualization, Imbalance_Interactive\nfrom utils_data import prepare_data, CustomStop ,review_to_words, downsample_2\nimport random\n","4ff679a7":"data_all = pd.read_csv('..\/input\/consumer-reviews-of-amazon-products\/1429_1.csv', dtype = {'name': object, 'reviews.didPurchase': np.float})\ndata_all.head(2)","4c654ff1":"data_all.info()","911d66ff":"data_all.isna().sum()","cc9c8444":"data_all.isna().sum()[['reviews.text', 'reviews.rating']]","0451c0c5":"data_all.duplicated(subset = ['reviews.text']).sum()","b4f6c046":"data_all.dropna(subset = ['reviews.text', 'reviews.rating'],inplace = True)\ndata_all.isna().sum()","8722db8e":"data = data_all[['reviews.text', 'reviews.rating', 'reviews.doRecommend', 'reviews.didPurchase']]\ndata.rename(columns = {'reviews.text': 'Reviews', 'reviews.rating': 'Rating', \n                       'reviews.doRecommend': 'Recommend', 'reviews.didPurchase': 'Purchase'}, inplace = True)\ndata","e1e59fae":"data.info()","f248d02d":"fig1, (ax11, ax12, ax13) = plt.subplots(1,3, figsize = (15,5))\nfig1.suptitle('Figure 1: Selected Columns Distribution', fontsize = 16)\n\nax11.hist(data['Rating']);\nax11.set_title('Rating [1:5]');\n\nax12.hist(data['Purchase']);\nax12.set_title('Did the customer make a purchase? [0: no, 1:yes]');\n\nax13.hist(data['Recommend'].astype(float));\nax13.set_title('Did the customer recommend the product? [0: no, 1:yes]');","a2d5cf44":"explore_label(data, Rating = 5, Num_Samples = 3)","37d047c9":"explore_label(data, Rating = 4, Num_Samples = 5)","354ba2ff":"explore_label(data, Rating = 3, Num_Samples = 15)","ed7e00c2":"explore_label(data, Rating = 2, Num_Samples = 5)","ddde0b5a":"explore_label(data, Rating = 1, Num_Samples = 5)","7e7ec43d":"Custom_StopWords = CustomStop(data_all)\nprint('Total number of custom stop words = {}'.format(len(Custom_StopWords)))","5f7d4d2d":"\", \".join(Custom_StopWords)","abe43768":"explore_label(data, Rating = 5, CustomStop = Custom_StopWords)","e5ff37e5":"explore_label(data, Rating = 4, CustomStop = Custom_StopWords)","baba4518":"explore_label(data, Rating = 3, CustomStop = Custom_StopWords)","cdf97275":"explore_label(data, Rating = 2, CustomStop = Custom_StopWords)","98a4b294":"explore_label(data, Rating = 1, CustomStop = Custom_StopWords)","fdc45440":"map1 = {1: 'Neg', 2: 'Neg', 3: 'Neu', 4:'Pos', 5:'Pos'}\nmap2 = {1: 'Neg', 2: 'Neg', 3: 'Pos', 4:'Pos', 5:'Pos'}\nmap3 = {1: 'Neg', 2: 'Neg', 3: 'Neg', 4:'Pos', 5:'Pos'}\n\ndata1 = prepare_data(filename = '..\/input\/consumer-reviews-of-amazon-products\/1429_1.csv', label_map = map1)\ndata2 = prepare_data(filename = '..\/input\/consumer-reviews-of-amazon-products\/1429_1.csv', label_map = map2)\ndata3 = prepare_data(filename = '..\/input\/consumer-reviews-of-amazon-products\/1429_1.csv', label_map = map3)","d9025660":"imbalance1 = data1.query('Label == \"Pos\"').shape[0]\/ data1.query('Label == \"Neg\"').shape[0]\nimbalance2 = data2.query('Label == \"Pos\"').shape[0]\/ data2.query('Label == \"Neg\"').shape[0]\nimbalance3 = data3.query('Label == \"Pos\"').shape[0]\/ data3.query('Label == \"Neg\"').shape[0]","838fd776":"fig2, (ax21, ax22, ax23) = plt.subplots(1,3, figsize = (15,5))\nfig2.suptitle('Figure 2: Label distribution for different mappings', fontsize = 16)\n\nax21.hist(data1['Label']);\nax21.set_title('Label 3 as neutral');\n\nax22.hist(data2['Label']);\nax22.set_title('Label 3 as positive');\n\nax23.hist(data3['Label']);\nax23.set_title('Label 3 as negative');\n\nfig3, ax3 = plt.subplots(1,1, figsize = (15, 5))\nfig3.suptitle('Figure 3: Imbalance ratio for different mappings', fontsize = 16)\nax3.bar(['data1', 'data2', 'data3'],[imbalance1, imbalance2, imbalance3], width = .3);","295801ce":"Imbalance_Interactive(data2, target = 'Label')","a52e2ace":"Imbalance_Interactive(data3, target = 'Label')","586addf9":"data2_ds = downsample_2(data2)\ndata3_ds = downsample_2(data3)","f98d8f8e":"fig4, (ax41, ax42) = plt.subplots(1,2, figsize = (10,5))\nfig4.suptitle('Figure 4: Label distribution for the down sampled dataset', fontsize = 16)\n\nax41.hist(data2_ds['Label']);\nax41.set_title('Label 3 as positive');\n\nax42.hist(data3_ds['Label']);\nax42.set_title('Label 3 as negative');","6915d649":"tsne, X, y = TSNE_Visualization(data, n_documents = 500 )","fe8c1bff":"tsne1, X1, y1 = TSNE_Visualization(data, n_documents = 500,  CustomStop =  Custom_StopWords)","75ab275d":"tsne_under, X_under, y_under = TSNE_Visualization(data3, targetname = 'Label', n_documents = 500)","b4691218":"tsne_under1, X_under1, y_under1 = TSNE_Visualization(data3, targetname = 'Label', n_documents = 500, CustomStop =  Custom_StopWords)","301c353c":"tsne_under, X_under, y_under = TSNE_Visualization(data3_ds, targetname = 'Label', n_documents = 500 )","79803e35":"tsne_under1, X_under1, y_under1 = TSNE_Visualization(data3_ds, targetname = 'Label', n_documents = 500, CustomStop =  Custom_StopWords)","aaa6b04d":"### Dropping missing values","50e070b2":"<a id = 'Basic'><\/a>\n\n---\n# <center> Basic Properties <\/center>\n---","e6d672e0":"<a id = 'deep_dive'><\/a>\n\n---\n# <center> Deep Dive <\/center> \n---","a1c17520":"## Loading main data file","00efb841":"## Importing necessary libraries","29b9ec0f":"<a id ='Custom_Stop'><\/a>\n## Custom Stop Words","78b8713a":"This is the first part of the project [Sentiment Analysis With Consumer Reviews of Amazon Products](https:\/\/www.kaggle.com\/omarayman67\/basic-machine-learning-pipeline) which covers the process of exploring the data and preparing the necessary data as well as helpful methods for later stages.\n\nThe next stage is to perform [Model Training](https:\/\/www.kaggle.com\/omarayman67\/model-training)","70e4b64a":"<a id='label_down'><\/a>\n## Label mapping and down sampling","7b4e8718":"<a id='label_map'><\/a>\n## Label mapping and imblance ratio","de118fce":"<a id='label_down_stop'><\/a>\n## Label mapping, down sampling, custom stop words and data separability ","384ea609":"<a id ='columns_dis'><\/a>\n## Columns distribution","64efee5a":"- Data is highly imbalanced more toward _positive_ attitudes than _negative_ ones. Thus, it is important to handle this imbalance before expecting any good results from the model. \n- A lot of common words ,that cannot distinguish the true semantic, is dominant in all rating levels. For example, words like `Amazon`, `Kindle` and `tablet` manifest themselves in all word clouds above.\n- Theses words are problem specific and are not added to most common libraries. This reveals the importance of deriving custom stop words in order to pre-process the data more effectively. \n- Most reviews come from verified purchases which make the text more authentic. \n- Some reviews express positive attitude while the person does not recommend the product. On the other hand, some reviews are clearly for unsatisfied customers, yet they recommend the product. This might be a problem for the model if they are of a great values.  \n- It is super cumbersome to trace every single comment along with other columns to verify the comment. _Luckily_, the `Rating` value is expressive in most cases. Thus, **it will be used from now on**. ","fb8eec92":"- Rating column is the most suitable target for the problem on hand not only because of lower missing values but also it more expressive, less prone to human errors.\n- Remapping the ratings into binary class might reduce the noise introduced by the hesistant users. Thus, it will be used from later on.  \n- Removing additional custom stop words (i.e., derived from the data itself) make the word cloud more clearer giving the model more expressive words per category. \n- Adding the rating = 3 to negative category helps reduce the endemic imbalance of this dataset. ","e5595fc9":"---\n# <center> Table of Contents <\/center>\n---\n<ul>\n<li><a href=\"#intro\">Introduction<\/a><\/li>\n    - <a href=\"#about\">About The Data <\/a><br>\n\n<li><a href=\"#Basic\">Basic Properties<\/a><\/li>\n    - <a href=\"#columns\">Exploring the data columns <\/a><br>\n    - <a href=\"#missing\">Missing and duplicate values <\/a><br>\n    - <a href=\"#basic_obs\">Basic key observations <\/a><br>\n    \n<li><a href=\"#deep_dive\">Deep Dive<\/a><\/li>\n    - <a href=\"#columns_dis\">Columns distribution <\/a><br>\n    - <a href=\"#Explore_rev\">Explore the reviews <\/a><br>\n    - <a href=\"#deep_obs\">Deep dive key Observations <\/a><br>\n\n<li><a href=\"#prepare_data\">Prepare the data <\/a><\/li>\n    - <a href=\"#Custom_Stop\">Custom Stop Words <\/a><br>\n    - <a href=\"#explore_stop\">Exploring the reviews after removing custom stop words<\/a><br>\n    - <a href=\"#label_map\">Label mapping and imblance ratio<\/a><br>\n    - <a href=\"#prep_obs\">Deep dive key Observations <\/a><br>\n    \n<li><a href=\"#imbalance\">Imbalance Handling <\/a><\/li>    \n    - <a href=\"#label_down\">Label mapping and down sampling <\/a><br>\n    - <a href=\"#label_down_stop\">Label mapping, down sampling, custom stop words and data separability<\/a><br>\n    - <a href=\"#label_map\">Label mapping and imblance ratio<\/a><br>\n    - <a href=\"#imb_obs\">Imbalance handling key observations <\/a><br>\n<\/ul>","84406fe8":"<a id = 'columns'><\/a>\n## Exploring the data Columns ","e27ad019":"# <center> Sentiment Analysis With Consumer Reviews of Amazon Products<\/center>\n## <center> 1- Data Pre-processing<\/center>\n\n<img src = \"https:\/\/i.ibb.co\/SXyBchg\/preprocessing.jpg\" width = \"100%\">\n\n# <u>Made by<\/u> :  <center> Omar Khater <\/center>","49e3d624":"- The imbalanced data set with multi-level target is not easy to be seperated. \n- The imbalanced data set with binary target is not highly seperable. Thus, the model acting on this data set is not expected to perform so well.\n- Combining down sampling technique with additional stop words helps seperate the data signficantly. Thus,the model acting on this data set is expected to better than the whole dataset with the cost of reducing total number of training examples. ","c7ffd90d":"<a id ='about'><\/a>\n## About The Data","4acfc255":"<a id ='basic_obs'><\/a>\n## Basic key observations ","104bbb65":"<a id = 'Explore_rev'><\/a>\n## Explore the reviews","7fc2dad7":"<a id='explore_stop'><\/a>\n## Exploring the reviews after removing custom stop words","fa6c86e3":"<a id= 'imbalance'><\/a>\n\n---\n# <center> Imbalance Handling <\/center>\n---","b4dbde18":"<a id='deep_obs'><\/a>\n## Deep dive key Observations","0d9458bb":"## Extract relevent data","7da640d6":"- The data has more than 34k row of the data which is sufficient for producing a good semantic model.\n\n- Few of the existed columns are related to the `Semantic Analysis` problem. For example, `reviews.text` describes the customer feeling in words. In addition, `reviews.rating` qunatify the customer satisfication. Moreover, `reviews.doRecommend` might serve as a binary level quantizer for the customer satisfication as well although it has a significant number of the missing values. Furthermore, the `reviews.didPurchase` might make the review more authentic. Finally, other columns might produce beneficial stop words that help preprocess the data more effectively such as `name`, `categories`, `manufacturer`.  ","6a5995de":"<a id='missing'><\/a>\n## Missing and duplicate values","e2ca0b90":"<a id ='intro'><\/a>\n\n---\n# <center> Introduction <\/center>\n---","2c899010":"<a id = 'prepare_data'><\/a>\n\n---\n# <center> Prepare Data <\/center>\n---","6071a01d":"<a id='imb_obs'><\/a>\n## Imbalance handling key observations","bca55921":"To make the word cloud more cleaner, some custom words (i.e., from the data itself) is derived. ","213a6bf3":"This is a list of over 34,000 consumer reviews for **<u>Amazon products<\/u>** like the Kindle, Fire TV Stick, and more provided by [Datafiniti's Product Database](https:\/\/datafiniti.co\/products\/product-data\/). The dataset includes basic product information, rating, review text, and more for each product.\n\nNote that this is a sample of a large dataset. The full dataset is available through `Datafiniti`.","c60e580c":"<a id ='prep_obs'><\/a>\n## Preparing data key observations"}}