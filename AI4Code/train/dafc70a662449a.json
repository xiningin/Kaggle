{"cell_type":{"35bdd313":"code","6c8dc9f4":"code","6fb45c54":"code","e8f803c4":"code","96c99e53":"code","8a59d990":"code","b27c06c6":"code","abe5f8be":"code","b5443f57":"code","34ce1110":"code","cf887f28":"code","a12a09dd":"code","0754c583":"code","d7e436a1":"code","28d86fa0":"code","a48ea400":"code","0114f8a8":"code","25e84b2e":"code","d05b2d60":"code","622235bb":"markdown"},"source":{"35bdd313":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# Any results you write to the current directory are saved as output.","6c8dc9f4":"import numpy as np\nimport pandas as pd\nimport os\nimport json\nimport glob\nimport sys\n\nsys.path.insert(0, \"..\/\")\n\nroot_path = '\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13'\n\ncorona_features = {\"doc_id\": [None], \"source\": [None], \"title\": [None],\n                  \"abstract\": [None], \"text_body\": [None]}\ncorona_df = pd.DataFrame.from_dict(corona_features)\n\njson_filenames = glob.glob(f'{root_path}\/**\/*.json', recursive=True)","6fb45c54":"def return_corona_df(json_filenames, df, source):\n\n    for file_name in json_filenames:\n\n        row = {\"doc_id\": None, \"source\": None, \"title\": None,\n              \"abstract\": None, \"text_body\": None}\n\n        with open(file_name) as json_data:\n            data = json.load(json_data)\n\n            doc_id = data['paper_id']\n            row['doc_id'] = doc_id\n            row['title'] = data['metadata']['title']\n\n            # Now need all of abstract. Put it all in \n            # a list then use str.join() to split it\n            # into paragraphs. \n\n            abstract_list = [abst['text'] for abst in data['abstract']]\n            abstract = \"\\n \".join(abstract_list)\n\n            row['abstract'] = abstract\n\n            # And lastly the body of the text. \n            body_list = [bt['text'] for bt in data['body_text']]\n            body = \"\\n \".join(body_list)\n            \n            row['text_body'] = body\n            \n            # Now just add to the dataframe. \n            \n            if source == 'b':\n                row['source'] = \"BIORXIV\"\n            elif source == \"c\":\n                row['source'] = \"COMMON_USE_SUB\"\n            elif source == \"n\":\n                row['source'] = \"NON_COMMON_USE\"\n            elif source == \"p\":\n                row['source'] = \"PMC_CUSTOM_LICENSE\"\n            \n            df = df.append(row, ignore_index=True)\n    \n    return df\n    \ncorona_df = return_corona_df(json_filenames, corona_df, 'b')\n","e8f803c4":"corona_out = corona_df.to_csv('kaggle_covid-19_open_csv_format.csv')","96c99e53":"corona_df = corona_df.dropna()","8a59d990":"from IPython.display import FileLink\nFileLink(r'kaggle_covid-19_open_csv_format.csv')","b27c06c6":"!pip install ktrain","abe5f8be":"import ktrain\nktrain.text.preprocessor.detect_lang = ktrain.text.textutils.detect_lang\ndf = corona_df\ntexts = df[\"text_body\"]\ntm = ktrain.text.get_topic_model(texts, n_topics=None, n_features=10000)","b5443f57":"tm.print_topics()\ntm.build(texts, threshold=0.25)","34ce1110":"texts = tm.filter(texts)\ndf = tm.filter(df)","cf887f28":"tm.visualize_documents(doc_topics=tm.get_doctopics())","a12a09dd":"transmission_results = tm.search('transmission', case_sensitive=False)\nincubation_results = tm.search('incubation', case_sensitive=False)\nenvironmental_results = tm.search('environmental stability', case_sensitive=False)","0754c583":"threshold = .80\n\ntransmission_topic_ids = {doc[3] for doc in transmission_results if doc[2]>threshold}\nincubation_topic_ids = {doc[3] for doc in incubation_results if doc[2]>threshold}\nenvironmental_topic_ids = {doc[3] for doc in environmental_results if doc[2]>threshold}\n\nt_topics = transmission_topic_ids.copy()\nt_topics.update(incubation_topic_ids)\nt_topics.update(environmental_topic_ids)\n","d7e436a1":"\ntm.visualize_documents(doc_topics=tm.get_doctopics(t_topics))\n","28d86fa0":"docs = tm.get_docs(topic_ids=t_topics, rank=True)\nprint(\"TOTAL_NUM_OF_DOCS: %s\" % len(docs))\n\nprint(\"##################################\")\n\nfor t in t_topics:\n    docs = tm.get_docs(topic_ids=[t], rank=True)\n    print(\"NUM_OF_DOCS: %s\" % len(docs))\n    if(len(docs)==0): continue\n    doc = docs[1]\n    print('TOPIC_ID: %s' % (doc[3]))\n    print('TOPIC: %s' % (tm.topics[t]))\n    print('DOC_ID: %s'  % (doc[1]))\n    print('TOPIC SCORE: %s '% (doc[2]))\n    print('TEXT: %s' % (doc[0][0:400]))\n    \n    \n    print(\"##################################\")\n","a48ea400":"tm.train_recommender()\n","0114f8a8":"text = \"What is known about covid-19 transmission?\"\nfor i, doc in enumerate(tm.recommend(text=text, n=5)):\n    print('RESULT #%s'% (i+1))\n    print('TEXT:\\n\\t%s' % (\" \".join(doc[0].split()[:500])))\n    print()","25e84b2e":"text = \"What is known about covid-19 incubation period?\"\nfor i, doc in enumerate(tm.recommend(text=text, n=5)):\n    print('RESULT #%s'% (i+1))\n    print('TEXT:\\n\\t%s' % (doc[0]))\n    print()","d05b2d60":"text = \"What is known about covid-19 environmental stability?\"\nfor i, doc in enumerate(tm.recommend(text=text, n=5)):\n    print('RESULT #%s'% (i+1))\n    print('TEXT:\\n\\t%s' % (doc[0]))\n    print()","622235bb":"> What is known about transmission, incubation, and environmental stability?\n* "}}