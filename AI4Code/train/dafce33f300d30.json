{"cell_type":{"d83656f7":"code","8f305229":"code","3d6a88d8":"code","dec9b7af":"code","c83591b3":"code","92acc29a":"code","b3874c9a":"code","2decb393":"code","3158cbb5":"code","449a6d3a":"code","8fe892cd":"code","9d5ecde4":"code","3a4f4e6f":"code","997dff18":"code","759bfd47":"code","bc576474":"markdown","a8baae86":"markdown","d86cb2bc":"markdown","38f39e3a":"markdown","d364fbf4":"markdown","4ffed81c":"markdown","da1e442c":"markdown","4e89220b":"markdown","8506a248":"markdown","8c8d8399":"markdown","8a47e7ef":"markdown","35569e03":"markdown","0c720e3c":"markdown","d352c40e":"markdown","e6dd8e39":"markdown","1adab10b":"markdown"},"source":{"d83656f7":"!pip install foolbox","8f305229":"import os\nimport shutil \nfrom tqdm import tqdm\n\ndata_root = '..\/input\/architectural-heritage-elements-image64-dataset'\ntrain_dir = 'train'\nval_dir = 'val'\ntest_dir = 'test'\n\nclass_names = sorted(os.listdir(\"..\/input\/architectural-heritage-elements-image64-dataset\/train\"))\n\nfor dir_name in [train_dir, val_dir, test_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n\nfor class_name in class_names:\n    train_source_dir = os.path.join(data_root, 'train', class_name)\n    for i, file_name in enumerate(tqdm([fn for fn in os.listdir(train_source_dir) if '.jpg' in fn])):\n        if i % 10 != 0:\n            dest_dir = os.path.join(train_dir, class_name) \n        else:\n            dest_dir = os.path.join(val_dir, class_name)\n        shutil.copy(os.path.join(train_source_dir, file_name), os.path.join(dest_dir, file_name))\n\n    test_source_dir = os.path.join(data_root, 'test', class_name)\n    for i, file_name in enumerate(tqdm([fn for fn in os.listdir(test_source_dir) if '.jpg' in fn])):\n        dest_dir = os.path.join(test_dir, class_name)\n        shutil.copy(os.path.join(test_source_dir, file_name), os.path.join(dest_dir, file_name))","3d6a88d8":"!find train -type f | wc -l\n!find val -type f | wc -l\n!find test -type f | wc -l","dec9b7af":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport foolbox as fb\n\nimport torch\nimport random\nimport torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\n\nfrom torchvision import transforms, models\n\nrandom.seed(123)\ntorch.manual_seed(123)\ntorch.cuda.manual_seed(123)\n\nmean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\nstd = np.array([0.229, 0.224, 0.225], dtype=np.float32)\npreprocessing = dict(mean=mean, std=std, axis=-3)\nbounds = (0, 1)\neps = 128.0\/255.0","c83591b3":"BATCH_SIZE = 64\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.ToTensor()\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\ntrain_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\nval_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2)\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)","92acc29a":"import itertools\n\ndef show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nX_batch, y_batch = next(iter(train_dataloader))\n\nfor x_item, y_item in itertools.islice(zip(X_batch, y_batch), 0, 5):\n    show_input(x_item, title=class_names[y_item])","b3874c9a":"def train_model(model, loss, optimizer, scheduler, num_epochs):\n    losses, accs = [], []\n    norm_losses, norm_accs = [], []\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}:'.format(epoch, num_epochs - 1), flush=True)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                model.train()\n            else:\n                dataloader = val_dataloader\n                model.eval()\n\n            running_loss = 0.\n            running_acc = 0.\n\n            running_norm_loss = 0.\n            running_norm_acc = 0.\n\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                attack = {\n                    'train': fb.attacks.LinfPGD(),\n                    'val': fb.attacks.L2PGD()\n                }\n                \n                epsilons = {\n                    'train': 1e-4,\n                    'val': eps\n                }\n                \n                model.eval()\n                if phase == 'train':\n                    fmodel = fb.PyTorchModel(model, bounds=bounds)\n                    adv = attack[phase](fmodel, inputs, labels, epsilons=epsilons[phase])[1]\n                    model.train()\n                else:\n                    fmodel = fb.PyTorchModel(model, bounds=bounds)\n                    adv = attack[phase](fmodel, inputs, labels, epsilons=epsilons[phase])[1]\n                    preprocessed_inputs = attack[phase](fmodel, inputs, labels, epsilons=0)[1]\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(adv)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                    if phase == 'val':\n                        norm_preds = model(preprocessed_inputs)\n                        norm_loss_value = loss(norm_preds, labels)\n                        norm_preds_class = norm_preds.argmax(dim=1)\n\n                # statistics\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n                \n                if phase == 'val':\n                    running_norm_loss += norm_loss_value.item()\n                    running_norm_acc += (norm_preds_class == labels.data).float().mean()\n\n            epoch_loss = running_loss \/ len(dataloader)\n            epoch_acc = running_acc \/ len(dataloader)\n            \n            if phase == 'val':\n                epoch_norm_loss = running_norm_loss \/ len(dataloader)\n                epoch_norm_acc = running_norm_acc \/ len(dataloader)\n            \n            if phase == 'train':\n                scheduler.step(epoch_loss)\n\n            if phase == 'val':\n                losses.append(epoch_loss)\n                accs.append(epoch_acc)\n\n                norm_losses.append(epoch_norm_loss)\n                norm_accs.append(epoch_norm_acc)\n\n                print('{} Norm Loss: {:.4f}\\t Norm Acc: {:.4f}'.format(phase, epoch_norm_loss, epoch_norm_acc), flush=True)\n            print('{} Loss: {:.4f}\\t Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n\n    return model, losses, accs, norm_losses, norm_accs","2decb393":"model = models.resnet34(pretrained=False)\nmodel.fc = torch.nn.Linear(model.fc.in_features, 10)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","3158cbb5":"EPOCHS = 10\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3.0e-4, amsgrad=True)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n_, curr_losses, curr_accs, curr_norm_losses, curr_norm_accs = train_model(model, loss, optimizer, scheduler, num_epochs=EPOCHS)","449a6d3a":"plt.figure(figsize=(20, 10))\nplt.plot(curr_losses, label='adv loss')\nplt.plot(curr_norm_losses, label='base loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","8fe892cd":"plt.figure(figsize=(20, 10))\nplt.plot(curr_accs, label='adv accuracy')\nplt.plot(curr_norm_accs, label='base accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","9d5ecde4":"test_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\ntest_dataset = torchvision.datasets.ImageFolder(test_dir, test_transforms)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)","3a4f4e6f":"model.eval()\nfmodel = fb.PyTorchModel(model, bounds=bounds)\nattack = fb.attacks.L2PGD()\n\nis_advs, norm_is_advs = [], []\n\nfor inputs, labels in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    \n    _, _, norm_is_adv = attack(fmodel, inputs, labels, epsilons=0)\n    _, _, is_adv = attack(fmodel, inputs, labels, epsilons=eps)\n    is_advs.append(is_adv.cpu().numpy())\n    norm_is_advs.append(norm_is_adv.cpu().numpy())","997dff18":"robust_accuracy = 1 - np.concatenate(is_advs).mean()\naccuracy = 1 - np.concatenate(norm_is_advs).mean()\nprint(accuracy, robust_accuracy)","759bfd47":"!rm -rf train val test","bc576474":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0434\u0432\u0430 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 \u043a\u043b\u0430\u0441\u0441\u0430 DataLoader \u0434\u043b\u044f \u0442\u0440\u0435\u0439\u043d\u0430 \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0431\u0443\u0434\u0443\u0442 \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438\u0437 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0431\u0430\u0442\u0447\u0430\u043c\u0438 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 64 (\u0434\u043b\u044f 128 \u043f\u0430\u043c\u044f\u0442\u0438 \u0443\u0436\u0435 \u043d\u0435 \u0445\u0432\u0430\u0442\u0430\u0435\u0442). \u041f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044f \u0432 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u043c \u043a\u0440\u043e\u043f\u0435, \u0440\u0430\u0441\u0442\u044f\u043d\u0443\u0442\u043e\u043c \u0434\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 224x224 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439, \u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 - \u043f\u0440\u043e\u0441\u0442\u043e \u0432 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0438 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0434\u043e 224x224 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439.\n\n\u0412\u044b\u0432\u0435\u0434\u0435\u043c 5 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438.","a8baae86":"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u043d\u0435\u0430\u0442\u0430\u043a\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0438 \u0430\u0442\u0430\u043a\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445.","d86cb2bc":"\u041f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u0441\u043f\u043e\u0441\u043e\u0431 \u0431\u043e\u0440\u044c\u0431\u044b \u0441 PGD-\u0430\u0442\u0430\u043a\u0430\u043c\u0438 - \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u0430\u0442\u0430\u043a\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u0445, \u043a\u0430\u0436\u0434\u0443\u044e \u044d\u043f\u043e\u0445\u0443 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0431\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u0438 \u0432\u0430\u043b\u0438\u0434\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u043d\u0430 \u0430\u0442\u0430\u043a\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0431\u0430\u0442\u0447\u0430\u0445. \u041a\u0440\u043e\u043c\u0435 \u0442\u043e\u0433\u043e, \u043c\u044b \u0432\u0430\u043b\u0438\u0434\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u0435\u0449\u0451 \u0438 \u043d\u0430 \u0431\u0430\u0442\u0447\u0430\u0445, \u0430\u0442\u0430\u043a\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0441 $\\varepsilon = 0$, \u0447\u0442\u043e \u043d\u0438\u043a\u0430\u043a \u043d\u0435 \u043c\u0435\u043d\u044f\u0435\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u0434\u0430\u0432\u0430\u044f \u043d\u0430\u043c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043d\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435.\n\n\u0410\u0442\u0430\u043a\u043e\u0432\u0430\u0442\u044c \u0431\u0430\u0442\u0447\u0438 \u0431\u0443\u0434\u0435\u043c \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e PGD-\u0430\u0442\u0430\u043a \u0441 \u043d\u043e\u0440\u043c\u043e\u0439 $L_\\infty$ \u0438 \u043c\u0435\u043d\u044c\u0448\u0438\u043c $\\varepsilon$. [\u0412 \u0434\u0430\u043d\u043d\u043e\u0439 \u0441\u0442\u0430\u0442\u044c\u0435](https:\/\/towardsdatascience.com\/know-your-enemy-7f7c5038bdf3) \u043f\u0440\u0438\u0432\u043e\u0434\u044f\u0442\u0441\u044f \u0433\u0440\u0430\u0444\u0438\u043a\u0438, \u0434\u0435\u043c\u043e\u043d\u0441\u0442\u0440\u0438\u0440\u0443\u044e\u0449\u0438\u0435 \u0431\u041e\u043b\u044c\u0448\u0443\u044e \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u044c \u0431\u0435\u0441\u043a\u043e\u043d\u0435\u0447\u043d\u043e\u0439 \u043d\u043e\u0440\u043c\u044b \u043f\u0440\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 \u043f\u0440\u043e\u0442\u0438\u0432 \u0430\u0442\u0430\u043a \u043a\u0430\u043a \u0441 $L_2$, \u0442\u0430\u043a \u0438 \u0441 $L_\\infty$ \u043d\u043e\u0440\u043c\u0430\u043c\u0438, \u0432 \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0438 \u0441 $L_2$-PGD \u0430\u0442\u0430\u043a\u0430\u043c\u0438 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438. \u0413\u0440\u0430\u0444\u0438\u043a\u0438 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u044b \u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u0445 \u043d\u0438\u0436\u0435:\n![](https:\/\/miro.medium.com\/max\/4800\/1*vi_Hor2kxWJYypzbfGoS3Q.png)","38f39e3a":"\u0420\u0430\u0437\u043e\u0431\u044c\u0451\u043c \u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0443\u044e (\u0432 \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0438 9:1) \u0438 \u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0440\u0430\u0431\u043e\u0447\u0438\u0435 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438 \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0442\u0440\u0451\u0445 \u0432\u044b\u0431\u043e\u0440\u043e\u043a.","d364fbf4":"\u041d\u0430\u043f\u043e\u0441\u043b\u0435\u0434\u043e\u043a \u0443\u0431\u0435\u0440\u0451\u043c \u0437\u0430 \u0441\u043e\u0431\u043e\u0439 :)","4ffed81c":"\u041f\u0440\u043e\u0432\u0435\u0434\u0451\u043c \u0442\u0435 \u0436\u0435 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0438 \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u044b\u0435 accuracy.","da1e442c":"\u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0438 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043c \u0441\u0438\u0434\u044b \u0438 \u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u044b \u0434\u043b\u044f \u043f\u0440\u0435\u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0438\u043d\u0433\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439.","4e89220b":"\u041d\u0430\u0440\u0438\u0441\u0443\u0435\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u043e\u0448\u0438\u0431\u043a\u0438 \u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043d\u0430 \u0430\u0442\u0430\u043a\u043e\u0432\u0430\u043d\u043d\u043e\u0439 (adv) \u0438 \u043d\u0435\u0430\u0442\u0430\u043a\u043e\u0432\u0430\u043d\u043d\u043e\u0439 (base) \u0432\u044b\u0431\u043e\u0440\u043a\u0435.","8506a248":"### \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435","8c8d8399":"\u0412\u044b\u0432\u0435\u0434\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u044b \u0432\u044b\u0431\u043e\u0440\u043e\u043a.","8a47e7ef":"\u041e\u0431\u0443\u0447\u0430\u0442\u044c\u0441\u044f \u0431\u0443\u0434\u0435\u043c \u043d\u0430 \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u043e\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435 \u044d\u043f\u043e\u0445, \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043b\u043e\u0441\u0441\u0430 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0432\u043e\u0437\u044c\u043c\u0451\u043c \u043a\u0440\u043e\u0441\u0441-\u044d\u043d\u0442\u0440\u043e\u043f\u0438\u044e, \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u043e\u043c \u0431\u0443\u0434\u0435\u0442 Adam \u0441 $lr = 0.0003$.","35569e03":"### \u0422\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435","0c720e3c":"## \u041a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0439 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u043d\u043e\u0433\u043e \u043d\u0430\u0441\u043b\u0435\u0434\u0438\u044f","d352c40e":"\u0414\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0432\u043e\u0437\u044c\u043c\u0451\u043c \u043c\u043e\u0434\u0435\u043b\u044c ResNet-34 \u0441 \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u043c \u0441\u043b\u043e\u0435\u043c \u0432 \u043a\u043e\u043d\u0446\u0435.","e6dd8e39":"\u0423\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043c foolbox \u0434\u043b\u044f \u043e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u043b\u0435\u043d\u0438\u044f PGD-\u0430\u0442\u0430\u043a.","1adab10b":"\u0417\u0430\u0434\u0430\u0447\u0430 \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044f \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 \u043c\u043e\u0434\u0435\u043b\u0438, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u0430\u043c\u044f\u0442\u043d\u0438\u043a\u043e\u0432 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u043f\u043e 10 \u043a\u043b\u0430\u0441\u0441\u0430\u043c. \u041a\u0440\u043e\u043c\u0435 \u0442\u043e\u0433\u043e, \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u044b\u0442\u044c \u0443\u0441\u0442\u043e\u0439\u0447\u0438\u0432\u0430 \u043a PGD-\u0430\u0442\u0430\u043a\u0430\u043c \u0441 \u043d\u043e\u0440\u043c\u043e\u0439 $L_2$, 50 \u0448\u0430\u0433\u0430\u043c\u0438 \u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c $\\varepsilon = \\frac{128}{255}$.\n\n**\u0414\u0430\u043d\u043d\u044b\u0435**: 10\u043a+ \u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 1404 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f. \n\n\u041c\u0435\u0442\u0440\u0438\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u0432 \u0437\u0430\u0434\u0430\u0447\u0435 - accuracy."}}