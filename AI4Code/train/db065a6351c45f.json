{"cell_type":{"2e203b79":"code","de19e071":"code","6bf331bc":"code","de36b328":"code","25bd748f":"code","45e3477d":"code","e0933846":"code","36e9090e":"code","4f3c9ede":"code","61e648f1":"code","4d4aec47":"code","c6d8df16":"code","3dd3e394":"code","1add4442":"code","4cca6207":"code","264807a8":"code","54eee592":"code","176d2f7f":"code","fe68dfc7":"code","338d91c5":"code","efe05c34":"code","30fa5bf5":"code","c498d9c0":"code","1c2a1fba":"markdown","110274a3":"markdown","9af37ad6":"markdown"},"source":{"2e203b79":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","de19e071":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nfrom torch import nn\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2","6bf331bc":"df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nfast_sub = False\n\nif df.shape[0] == 2477:\n    fast_sub = True\n    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n                       columns=['id', 'PredictionString'])\nelse:\n    fast_sub = False\n","de36b328":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","25bd748f":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","45e3477d":"\nsplit = 'test'\nsave_dir = f'\/kaggle\/tmp\/{split}\/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'\/kaggle\/tmp\/{split}\/study\/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm')\n    im = resize(xray, size=600)  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/000c9c05fd14\/e555410bd2cd\/51759b5579bc.dcm')\n    im = resize(xray, size=600)  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=600)  \n            study = dirname.split('\/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))\n","e0933846":"image_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'\/kaggle\/tmp\/{split}\/image\/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm')\n    im = resize(xray, size=512)  \n    im.save(os.path.join(save_dir,'65761e66de9f_image.png'))\n    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/000c9c05fd14\/e555410bd2cd\/51759b5579bc.dcm')\n    im = resize(xray, size=512)  \n    im.save(os.path.join(save_dir, '51759b5579bc_image.png'))\n    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\nelse:\n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=512)  \n            im.save(os.path.join(save_dir, file.replace('.dcm', '_image.png')))\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            splits.append(split)\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","36e9090e":"import numpy as np \nimport pandas as pd\nif fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","4f3c9ede":"df['id_last_str']","61e648f1":"study_len","4d4aec47":"# IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\nDIM = (512,512,3)\n\n#load_dir = f\"\/kaggle\/input\/{COMPETITION_NAME}\/\"\nif fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df = sub_df[:study_len]\ntest_paths = f'\/kaggle\/tmp\/{split}\/study\/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\n\nlabel_cols = sub_df.columns[2:]\n\nsub_df['test_path'] = test_paths","c6d8df16":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm\n\nclass SiimClfModel(nn.Module):\n    def __init__(self, backbone_name, backbone_pretrained, n_classes=4):\n        super(SiimClfModel, self).__init__()\n        self.backbone = timm.create_model(backbone_name, pretrained=False)\n        if(backbone_pretrained):\n            self.backbone.load_state_dict(torch.load(backbone_pretrained))\n        clf_in_feature = self.backbone.classifier.in_features\n        self.backbone.classifier = nn.Linear(clf_in_feature, n_classes)\n        \n    def forward(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        \n        return x","3dd3e394":"class ClfTestDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, csv, transforms=None):\n        self.csv = csv.reset_index()\n        self.augmentations = transforms\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        image = cv2.imread(row.test_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']\n        \n        if('clf_label_idx' in self.csv.columns):\n            return torch.tensor(image), torch.tensor(row.clf_label_idx)\n        \n        return image\n    \n\ndef get_test_transforms(candidate):\n    dim = candidate.get('dim', DIM)\n    return A.Compose(\n        [\n            A.Resize(dim[0],dim[1],always_apply=True),\n            A.Normalize(),\n            ToTensorV2(p=1.0)\n        ]\n    )","1add4442":"CANDIDATES = [\n    {\n        'backbone_name':'efficientnet_b3',\n        'model_path':'..\/input\/siimstudyclfmodels\/v2\/Fold0_efficientnet_b3_v2_5folds_ValidLoss0.962_ValidAcc0.624_ValidAUC0.708_Ep01.pth'\n    },\n    {\n        'backbone_name':'efficientnet_b3',\n        'model_path':'..\/input\/siimstudyclfmodels\/v2\/Fold1_efficientnet_b3_v2_5folds_ValidLoss0.931_ValidAcc0.644_ValidAUC0.726_Ep01.pth'\n    },\n    {\n        'backbone_name':'efficientnet_b3',\n        'model_path':'..\/input\/siimstudyclfmodels\/v2\/Fold2_efficientnet_b3_v2_5folds_ValidLoss0.921_ValidAcc0.634_ValidAUC0.753_Ep02.pth'\n    },\n    {\n        'backbone_name':'efficientnet_b3',\n        'model_path':'..\/input\/siimstudyclfmodels\/v2\/Fold3_efficientnet_b3_v2_5folds_ValidLoss0.943_ValidAcc0.626_ValidAUC0.724_Ep01.pth'\n    },\n    {\n        'backbone_name':'efficientnet_b3',\n        'model_path':'..\/input\/siimstudyclfmodels\/v2\/Fold4_efficientnet_b3_v2_5folds_ValidLoss0.955_ValidAcc0.635_ValidAUC0.706_Ep01.pth'\n    },\n]\n","4cca6207":"BATCH_SIZE = 16","264807a8":"from tqdm.notebook import tqdm \n\ndef clf_predict_fn(dataloader, model, device):\n    model.eval()\n    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n    batch_preds=[]\n    \n    for i, inps in tk0:\n        inps = inps.to(device)\n        outputs = model(inps)\n        probs = nn.functional.softmax(outputs, dim=-1)\n        batch_preds.append(probs.detach().cpu().numpy())\n        \n        del inps, outputs, probs\n        torch.cuda.empty_cache()\n        \n    return np.concatenate(batch_preds)","54eee592":"for candidate in CANDIDATES:\n    model = SiimClfModel(backbone_name=candidate['backbone_name'], backbone_pretrained=None)\n    model.load_state_dict(torch.load(candidate['model_path'], map_location='cpu'))\n    model.to('cuda:0')\n    print()\n    \n    test_dataset = ClfTestDataset(sub_df, get_test_transforms(candidate))\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE)\n    \n    sub_df[label_cols] += clf_predict_fn(test_dataloader, model, torch.device('cuda:0'))\n    \n    del model\n    torch.cuda.empty_cache()\n    \nsub_df[label_cols] \/= len(CANDIDATES)","176d2f7f":"sub_df.columns = ['id', 'PredictionString1', 'negative', 'typical', 'indeterminate', 'atypical', 'test_path']\ndf = pd.merge(df, sub_df, on = 'id', how = 'left')","fe68dfc7":"for i in range(study_len):\n    negative = df.loc[i,'negative']\n    typical = df.loc[i,'typical']\n    indeterminate = df.loc[i,'indeterminate']\n    atypical = df.loc[i,'atypical']\n    df.loc[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'","338d91c5":"df_study = df[['id', 'PredictionString']]\n\n# df.to_csv('submission.csv',index=False)\n# df","efe05c34":"sub_df = df_study.fillna('')\ndef remove_prediction_on_image_level(row):\n    if(row['id'].endswith('_image')):\n        row['PredictionString'] = ''\n    return row\nsub_df = sub_df.apply(remove_prediction_on_image_level, axis=1)","30fa5bf5":"sub_df.iloc[0].PredictionString","c498d9c0":"sub_df.to_csv('submission.csv',index=False)","1c2a1fba":"# study predict","110274a3":"# .dcm to .png","9af37ad6":"# study string"}}