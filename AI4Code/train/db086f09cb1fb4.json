{"cell_type":{"f7e961f0":"code","d65e2b31":"code","ad677502":"code","0f001006":"code","9d0db88e":"code","591a034d":"code","d8ea4c47":"code","861ac38e":"code","d336d3f3":"code","898bccd0":"code","331e3976":"code","4905b8f6":"code","943ef668":"code","088851d8":"code","8bfed4e2":"code","55381d0f":"code","7a703158":"code","a87bc0f2":"code","40572f63":"code","d699780d":"code","bd87e106":"code","c15c7805":"code","f4291017":"code","dc55fc4e":"code","665c08fe":"code","2d0555fa":"code","336706c5":"code","d5e7a28b":"code","19a48a5a":"code","b6364770":"code","3d72042d":"code","6191f918":"markdown","ab790fb3":"markdown","90de1aca":"markdown","6cab4621":"markdown","4fc09cd4":"markdown","0097cb7c":"markdown","db5df5f5":"markdown","1c53bc94":"markdown","841937ab":"markdown","c70f8638":"markdown","d924b6f3":"markdown","4d85d7a9":"markdown","e1e86202":"markdown","4011158a":"markdown","ab7dca6a":"markdown","dfc57916":"markdown","37e3afe7":"markdown","b22a4b89":"markdown","3505b624":"markdown"},"source":{"f7e961f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport geopandas as gpd\nimport missingno\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d65e2b31":"data = pd.read_csv(\"\/kaggle\/input\/covid19-in-india\/covid_19_india.csv\",index_col=0)","ad677502":"data = data.iloc[:8835]","0f001006":"data.head()","9d0db88e":"missingno.matrix(data)","591a034d":"data.duplicated().sum()","d8ea4c47":"data.info()","861ac38e":"data['Time'].unique()","d336d3f3":"data.rename(columns={\"Date\" : \"Datetime\"},inplace=True)","898bccd0":"def timeconv(df):\n    alltime = []\n    for i in df[\"Time\"]:\n        mer = i[-2:]\n        \n        time = i[:-3]\n        if len(time) ==4:\n            time = \"0\"+time\n        if mer == \"PM\":\n            time = str(12+int(time[:2]))+time[-3:]\n        alltime.append(time)\n    assert df.shape[0] == len(alltime)\n    df['Datetime'] = df['Datetime'] +\" \"+ pd.Series(alltime)\n            \n       \n        \n        \ntimeconv(data)","331e3976":"data.drop([\"Time\"],axis=1,inplace = True)","4905b8f6":"data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])","943ef668":"timest = data.iloc[-2][\"Datetime\"]\ndata.iloc[-1,0] = timest","088851d8":"data","8bfed4e2":"l = data.groupby('State\/UnionTerritory')","55381d0f":"data = data.replace(\"-\",np.nan)","7a703158":"missingno.matrix(data)","a87bc0f2":"data.drop(list(data.columns)[2:4],axis=1,inplace = True)","40572f63":"data['State\/UnionTerritory'].unique()","d699780d":"def drop_star(df):\n    for i in df['State\/UnionTerritory'].iteritems():\n        if i[1][-3:] == \"***\":\n            df.drop(i[0],inplace=True)\n        \ndrop_star(data)\ndata['State\/UnionTerritory'].unique()","bd87e106":"data.drop(data[(data['State\/UnionTerritory']=='Telangana')|(data['State\/UnionTerritory']=='Daman & Diu')|(data['State\/UnionTerritory']=='Dadar Nagar Haveli')].index,inplace=True)\ndata['State\/UnionTerritory'].unique()","c15c7805":"data.info()","f4291017":"data[data['State\/UnionTerritory']=='Tripura']","dc55fc4e":"l = data.groupby('State\/UnionTerritory')\ncurrent = l.last()","665c08fe":"current","2d0555fa":"fig ,ax = plt.subplots(figsize= (12,8))\nfig.set_facecolor(\"white\")\ncurrent = current.sort_values(\"Confirmed\",ascending=False)\np = sns.barplot(ax=ax,x= current.index,y=current['Confirmed'])\np.set_xticklabels(labels = current.index,rotation=90)\n\np.set_yticklabels(labels=(p.get_yticks()*1).astype(int))\n","336706c5":"fig, axs = plt.subplots(12,3, figsize=(16,30))\nfig.delaxes(axs[11,2])\nfig.set_facecolor(\"white\")\ndef plotpie(ax,cplot,data,state):\n    labels = ['Cured', 'Deaths','Ambiguous']\n    colors = ['green', 'red','gray']\n    amb = data.loc[state]['Confirmed'] - data.loc[state]['Cured']+data.loc[state]['Deaths']\n    size = [data.loc[state]['Cured'],data.loc[state]['Deaths'],amb]\n    x = cplot\/\/3\n    y = cplot%3\n    ax[x,y].pie(size,labels=labels, colors=colors, startangle=0, autopct='%1.1f%%')\n    ax[x,y].set_title(state+'\\n'+\"Total cases : {}\".format(data.loc[state]['Confirmed']))\n    ax[x,y].axis('equal')\n\ncplot = 0\nfor i in sorted(list(current.index)):\n    if i in ['Cases being reassigned to states', 'Unassigned'] :\n        continue\n    plotpie(axs,cplot,current,i)\n    cplot+=1\nfig.tight_layout()\nplt.plot()","d5e7a28b":"import datetime\nimport matplotlib.dates as mdates\nfig, axs = plt.subplots(18,2, figsize=(16,100))\nfig.set_facecolor(\"white\")\nfig.delaxes(axs[17,1])\n\ndef statewise_timeplot(ax,cplot,data,state):\n    toplot = data[data[\"State\/UnionTerritory\"] == state]\n    x = cplot\/\/2\n    y = cplot%2\n    sd = pd.to_datetime('2020-3-25') \n    td = datetime.timedelta(days=21)\n    ed = sd+td\n    #print(sd,ed)\n    \n    #toplot = toplot.set_index(\"Datetime\")\n    toplot = toplot.loc[(toplot[\"Datetime\"] > sd) & (toplot['Datetime']< ed)]\n    #print(toplot)\n    toplot = toplot.set_index(\"Datetime\")\n    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Confirmed\"],ax= ax[x,y],label='Confirmed')\n    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Cured\"],ax= ax[x,y],label=\"Cured\")\n    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Deaths\"],ax= ax[x,y],label=\"Deaths\")\n    ax[x,y].set_title(state)\n    ax[x,y].set_xlim(pd.Timestamp('2020-3-25'),pd.Timestamp(\"2020-04-11\"))\n    ax[x,y].set_ylim(0,1000000)\n    ax[x,y].xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n    ax[x,y].xaxis.set_minor_formatter(mdates.DateFormatter(\"%m-%d\"))\n    ax[x,y].tick_params(axis='x', rotation=45)\n    ax[x,y].legend()\n\n\n\ncplot = 0\nfor i in sorted(list(current.index)):\n    if i in ['Cases being reassigned to states', 'Unassigned'] :\n        continue\n    statewise_timeplot(axs,cplot,data,i)\n    cplot+=1\n    \nfig.tight_layout()\nplt.plot()\n","19a48a5a":"fp = \"\/kaggle\/input\/india-states\/Igismap\/Indian_States.shp\"\nmap_df = gpd.read_file(fp)\ndisplay(map_df)\ncurrent\ncurrent.rename(index={\"Andaman and Nicobar Islands\":\"Andaman & Nicobar Island\",\"Delhi\":\"NCT of Delhi\",\"Arunachal Pradesh\":\"Arunanchal Pradesh\",\"Dadra and Nagar Haveli and Daman and Diu\":\"Dadara & Nagar Havelli\",\"Jammu and Kashmir\":\"Jammu & Kashmir\",\"Telengana\":\"Telangana\"},inplace=True)","b6364770":"current.drop(['Cases being reassigned to states', 'Unassigned'], axis = 0).reset_index()\nmerged = map_df.merge(current, left_on = 'st_nm', right_on = 'State\/UnionTerritory', how = 'left')\nmerged = merged[~merged['Datetime'].isna()]\nmerged.reset_index().drop('index', axis = 1)\nmerged\n","3d72042d":"fig, ax = plt.subplots(1, figsize=(10, 10))\nax.axis('off')\nax.set_title('Covid-19 data', fontdict={'fontsize': '25', 'fontweight' : '10'})\n\nmerged.plot(column='Confirmed',cmap='YlOrRd', linewidth=0.8, ax=ax, edgecolor='0', legend=True,markersize=[39.739192, -104.990337])","6191f918":"### Moving forward, let's take a look at distinct state names for further analysis.","ab790fb3":"### Checking duplicated values in the dataset.","90de1aca":"### Whoa! most of the values are missing in 3rd and 4th column, we better drop those columns for now.","6cab4621":"### Extracting the latest insights from the data, we will later visualize the trends.","4fc09cd4":"### Zooming to the span of 21 days lockdown from 25-March-2020. \n","0097cb7c":"# Data Cleaning and Data Analysis on Covid-19 dataset (India).\n\n![corona](https:\/\/c.files.bbci.co.uk\/14A35\/production\/_115033548_gettyimages-1226314512.jpg)\n\n","db5df5f5":"### Now we are looking for unique timestamps given in the dataset, further we will merge the ***date*** and the ***time*** columns.","1c53bc94":"## Loading the dataset.","841937ab":"# Visualization","c70f8638":"### There are still several typos in state names, we will deal with this manually.","d924b6f3":"### Finally, here is the geoplot showing the Covid-19 spread across the Indian states with severity.","4d85d7a9":"### Convert the Datetime column to dtype of datetime64[ns]","e1e86202":"### **We will be analyzing the data of Covid-19 spread over the Indian states. The data ranges from 01-January-2020 to 26-November-2020.**","4011158a":"### Keeping it simple, we will drop the rows with state name ending with \"***\" as it is seems to be rows with incomplete values.","ab7dca6a":"### Exploring the missing values in the dataset using missingno package and info of the dataset.","dfc57916":"### Plotting a bar plot to show the spread of Covid-19 across the states in decreasing order.","37e3afe7":"### Now let's look at the Cured\/Death ratio of these states using pie plot.","b22a4b89":"### Prepariing data for geoplot using geopandas. ","3505b624":"### We discovered that there are several missing values marked as \"-\", let's take a look."}}