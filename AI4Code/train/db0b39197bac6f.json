{"cell_type":{"2c518d29":"code","1a605e45":"code","0aa1dfb6":"code","ca5cbff5":"code","e0257f7d":"code","0916b49f":"code","db01d9f9":"code","5d0142ae":"code","a2688b7e":"code","3acf2f49":"code","af634152":"code","936742c8":"code","97a9a1de":"code","dc68d80b":"code","c63a03ad":"code","f4e2c190":"code","a6c8167d":"code","346bbe8c":"code","f1bae158":"code","16e5a62d":"code","76be6f73":"code","a58de520":"code","1b26f85d":"code","685aed01":"markdown","1986597d":"markdown","4b013f19":"markdown","49615a61":"markdown","b187c7bb":"markdown"},"source":{"2c518d29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a605e45":"trainPath='..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train'\nvalidPath='..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid'","0aa1dfb6":"import os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.layers import Input, Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom sklearn.metrics import confusion_matrix,accuracy_score","ca5cbff5":"train_datagen=ImageDataGenerator(rescale=1.\/255,\n                                 shear_range=0.2,\n                                 zoom_range=0.2,\n                                 rotation_range=25,\n                                 horizontal_flip=True,\n                                fill_mode='nearest')\n\nvalid_datagen=ImageDataGenerator(rescale=1.\/255)","e0257f7d":"trainData=train_datagen.flow_from_directory(trainPath,\n                                            target_size=(224, 224),\n                                            color_mode=\"rgb\",\n                                            shuffle=True,\n                                            batch_size=16,\n                                            seed=123,\n                                            class_mode='categorical')","0916b49f":"validData=valid_datagen.flow_from_directory(validPath,\n                                            target_size=(224, 224),\n                                            color_mode=\"rgb\",\n                                            shuffle=True,\n                                            batch_size=16,\n                                            seed=123,\n                                            class_mode='categorical')","db01d9f9":"feature_number=len(os.listdir(trainPath))\nfeature_number","5d0142ae":"model =Sequential()\nmodel.add(Conv2D(32, kernel_size = (3,3), activation='relu', padding ='valid', input_shape=[224,224,3]))\nmodel.add(MaxPooling2D((2, 2),padding ='valid'))\n\nmodel.add(Conv2D(64, kernel_size = (3,3), padding ='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2),padding ='valid'))\n\nmodel.add(Conv2D(64, kernel_size = (3,3),padding ='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2),padding ='valid'))\n\nmodel.add(Conv2D(128, kernel_size=(3, 3),padding ='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2),padding ='valid'))\n\nmodel.add(Conv2D(128, kernel_size=(3, 3),padding ='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(256, kernel_size=(3, 3),padding ='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2),padding ='valid'))\n\nmodel.add(Conv2D(256, kernel_size=(3, 3),padding ='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n# model.add(Dropout(0.1))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dense(feature_number, activation='softmax'))","a2688b7e":"model.summary()","3acf2f49":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","af634152":"checkpoint=ModelCheckpoint(r'.\/tomato_leaf_diseases-3.h5',\n                          monitor='val_loss',\n                          mode='min',\n                          save_best_only=True,\n                          verbose=1)\nearlystop=EarlyStopping(monitor='val_loss',\n                       min_delta=0,\n                       patience=10,\n                       verbose=1,\n                       restore_best_weights=True)\n\ncallbacks=[checkpoint,earlystop]","936742c8":"model_history=model.fit_generator(trainData,validation_data=validData,\n                                 epochs=50,\n                                 steps_per_epoch=trainData.samples\/\/16,\n                                 validation_steps=validData.samples\/\/16,\n                                shuffle=True,\n                                 )","97a9a1de":"model.save('.\/tomato_leaf_disease-3.h5')","dc68d80b":"model.save_weights('tomato_leaf_disease-model-weight-3.h5')","c63a03ad":"# https:\/\/www.kaggle.com\/koksal1994\/conf14","f4e2c190":"# sns.set()\n\nacc = model_history.history['accuracy']\nval_acc = model_history.history['val_accuracy']\nloss = model_history.history['loss']\nval_loss = model_history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nprint(\"Maximum Accuracy : {:.2f} %\".format(max(acc)*100))\nprint(\"Maximum Validation Accuracy : {:.2f} %\".format(max(val_acc)*100))\n\n\nprint(\"Maximum Accuracy Loss : {:.2f} %\".format(min(loss)*100))\nprint(\"Maximum Validation Loss : {:.2f} %\".format(min(val_loss)*100))","a6c8167d":"plt.figure(figsize=(15,10))\nplt.plot(epochs,acc, label='Accuracy')\nplt.plot(epochs,val_acc, label='val_accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.grid()\nplt.savefig('Accuracy-Score-cnn2d-3')\nplt.show()","346bbe8c":"plt.figure(figsize=(15,10))\nplt.plot(epochs,loss, label='Training Loss')\nplt.plot(epochs,val_loss, label='Val Loss')\nplt.title('Training and Validation Loss')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.grid()\nplt.savefig('Loss-Score-cnn2d-3')\nplt.show()","f1bae158":"model_file=load_model('..\/input\/outputfile\/tomato_leaf_disease.h5')","16e5a62d":"pred=np.argmax(model_file.predict(validData),axis=1)\npred","76be6f73":"list(validData.class_indices)","a58de520":"import cv2\ndef prepare(filepath):\n    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n    img_array = img_array \/ 255\n    new_array = cv2.resize(img_array, (224, 224))\n    return new_array.reshape(-1, 224, 224, 3)\n\ndef prediction(img):\n    pred_result=np.argmax(model_file.predict(img))\n    disease_category=list(validData.class_indices)\n    return disease_category[pred_result]\n","1b26f85d":"img=prepare('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/Tomato___Leaf_Mold\/0160c3b5-d89e-40e5-a313-49ae1524040a___Crnl_L.Mold 6823.JPG')\nprediction(img)\n","685aed01":"## Data Augmentation ","1986597d":"## Build Model with CNN","4b013f19":"## Load Model","49615a61":"## Image Path","b187c7bb":"## Import Library"}}