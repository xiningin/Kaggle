{"cell_type":{"48d8cfaf":"code","4fa5183a":"code","876befad":"code","55310934":"code","84392747":"code","9fb10ef9":"code","803b18b6":"code","cb52b062":"markdown","bf1202be":"markdown","35ee4d94":"markdown","06b58e4b":"markdown","7d45c12d":"markdown","339d3cc6":"markdown"},"source":{"48d8cfaf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4fa5183a":"import numpy as np\nimport os\nimport sys\nimport tensorflow as tf\nimport time\n\n# \u5bfc\u5165\u7528\u4e8e\u63d0\u4ea4\u9884\u6d4b\u7ed3\u679c\u7684\u5305\nINPUT_DIR = '..\/input\/tensorflow-great-barrier-reef'\nsys.path.insert(0, INPUT_DIR)\nimport greatbarrierreef","876befad":"MODEL_DIR = '..\/input\/cots-detection-w-tensorflow-object-detection-api\/cots_efficientdet_d0'\nstart_time = time.time()\ntf.keras.backend.clear_session()\ndetect_fn_tf_odt = tf.saved_model.load(os.path.join(os.path.join(MODEL_DIR, 'output'), 'saved_model'))\nend_time = time.time()\nelapsed_time = end_time - start_time\nprint('Elapsed time: ' + str(elapsed_time) + 's')","55310934":"def load_image_into_numpy_array(path):\n    \n    img_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(io.BytesIO(img_data))\n    (im_width, im_height) = image.size\n    \n    return np.array(image.getdata()).reshape(\n      (im_height, im_width, 3)).astype(np.uint8)","84392747":"def detect(image_np):\n\n    input_tensor = np.expand_dims(image_np, 0)\n    start_time = time.time()\n    detections = detect_fn_tf_odt(input_tensor)\n    return detections\n    ","9fb10ef9":"env = greatbarrierreef.make_env()   # \u521d\u59cb\u5316\u73af\u5883\niter_test = env.iter_test()    # \u5faa\u73af\u6d4b\u8bd5\u96c6\u548c\u6837\u672c\u63d0\u4ea4\u7684\u8fed\u4ee3\u5668","803b18b6":"DETECTION_THRESHOLD = 0.19\n\nsubmission_dict = {\n    'id': [],\n    'prediction_string': [],\n}\n\nfor (image_np, sample_prediction_df) in iter_test:\n    height, width, _ = image_np.shape\n    \n    # Run object detection using the TensorFlow model.\n    detections = detect(image_np)\n    \n    # Parse the detection result and generate a prediction string.\n    num_detections = detections['num_detections'][0].numpy().astype(np.int32)\n    predictions = []\n    for index in range(num_detections):\n        score = detections['detection_scores'][0][index].numpy()\n        if score < DETECTION_THRESHOLD:\n            continue\n\n        bbox = detections['detection_boxes'][0][index].numpy()\n        y_min = int(bbox[0] * height)\n        x_min = int(bbox[1] * width)\n        y_max = int(bbox[2] * height)\n        x_max = int(bbox[3] * width)\n        \n        bbox_width = x_max - x_min\n        bbox_height = y_max - y_min\n        \n        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n    # Generate the submission data.\n    prediction_str = ' '.join(predictions)\n    sample_prediction_df['annotations'] = prediction_str\n    env.predict(sample_prediction_df)\n\n    print('Prediction:', prediction_str)   ","cb52b062":"##### *\u4ecenumpy\u56fe\u50cf\u8bc6\u522bCOTS*","bf1202be":"> #### wanglijie-19\u5927\u6570\u636e-\u671f\u672b","35ee4d94":"### 2\u3001\u5c06TensorFlow COTS\u68c0\u6d4b\u6a21\u578b\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\uff0c\u5e76\u5b9a\u4e49\u4e00\u4e9b\u7528\u4e8e\u8fd0\u884c\u7684util\u51fd\u6570\u63a8\u8bba\u3002\n\n","06b58e4b":"### 3\u3001\u8fd0\u884c\u7ed3\u679c\u5e76\u6784\u5efa\u63d0\u4ea4\u6570\u636e","7d45c12d":"##### ***\u52a0\u8f7d\u56fe\u7247\u5230numpy_array***\n\n*\u5c06\u56fe\u50cf\u653e\u5165Numpy\u6570\u7ec4\u4ee5\u8f93\u5165TensorFlow\u56fe\u3002*\n*\u6ce8\u610f\uff0c\u6309\u7167\u60ef\u4f8b\uff0c\u6211\u4eec\u5c06\u5176\u653e\u5165\u6709\u5f62\u7684numpy\u6570\u7ec4\u4e2d\uff0c(\u9ad8\u5ea6\uff0c\u5bbd\u5ea6\uff0c\u901a\u9053)\uff0c\u5176\u4e2d\u901a\u9053=3\u8868\u793aRGB\u3002*  \n\n*\u8def\u5f84\uff1a\u6587\u4ef6\u8def\u5f84(\u53ef\u4ee5\u662f\u672c\u5730\u7684\uff0c\u4e5f\u53ef\u4ee5\u662fcolossus\u67b6\u6784\u4e2d\u7684)\u3002*\n\n*\u8fd4\u56de\u503c\uff1auint8 numpy\u6570\u7ec4\u5f62\u72b6\uff08\u9ad8\u5ea6\uff0c\u5bbd\u5ea6\uff0c3\uff09\u3002*\n","339d3cc6":"### 1\u3001\u5bfc\u5165\u76f8\u5e94\u5305\u53ca\u6570\u636e"}}