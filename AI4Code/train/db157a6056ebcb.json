{"cell_type":{"54fb6837":"code","306cd229":"code","91a52e6d":"code","2dedd125":"code","19caa209":"code","a1da6741":"code","756cad9e":"code","099cc629":"code","897bd12a":"code","99118ddb":"code","d663aaee":"code","ac770e53":"code","a1e5bbe2":"code","feac3461":"code","90bc3ad6":"code","bde29c5c":"markdown","afbc134b":"markdown","384bf774":"markdown","3c75d560":"markdown","e5af62e1":"markdown"},"source":{"54fb6837":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torchvision\nimport torch\nimport torch.nn\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","306cd229":"\"\"\"\u8bfb\u53d6png\u56fe\u7247\"\"\"\nimport matplotlib.pyplot as plt\nimage=plt.imread(\"..\/input\/ljy-hwdb1\/train\/00000\/100234.png\")\nplt.imshow(image)\nplt.show()","91a52e6d":"# #\u5faa\u73af\u8f93\u51fa\u56fe\u7247\n# label={0:\"\u4e00\",1:\"\u4e01\",2:\"\u4e03\",3:\"\u4e07\",4:\"\u4e08\",5:\"\u4e09\",6:\"\u4e0a\",7:\"\u4e0b\",8:\"\u4e0d\",9:\"\u4e0e\"}\n# #print(list(os.walk(\"..\/input\/\"))) #\u8f93\u51fa\u6570\u636e\u96c6\u7684\u6587\u4ef6\u5185\u5bb9\n# for root,dir,files in os.walk(\"..\/input\/\"): #\u904d\u5386\u6570\u636e\u96c6\u6240\u5728\u7684\u6587\u4ef6\u5939\n#     #root\uff1a\u8868\u793a\u5f53\u524d\u6240\u5728\u7684\u6587\u4ef6\u5939\uff08\u9996\u5148\u5728jy-hwbd1\u4e0b\u904d\u5386\uff0c\u7136\u540e\u8fdb\u5165test\u904d\u5386\uff09\n#     #dir\u8868\u793a\u5f53\u524d\u76ee\u5f55\u4e0b\u6709\u51e0\u4e2a\u6587\u4ef6\u5939\n#     #\u5230\u4e86\\train\u6216\u8005\\test\u4e0b\u9762files\u624d\u6709\u503c\n#     for file in files:#\u62fc\u63a5\u5b57\u7b26\u4e32\u4e3a\uff1a\u201dA\\B\u201c\n#         image_path=os.path.join(root,file)\n#         image=plt.imread(image_path)\n#         plt.imshow(image)\n#         plt.show()","2dedd125":"#\u8bfb\u53d6\u8bad\u7ec3\u96c6\n#\u5faa\u73af\u8f93\u51fa\u56fe\u7247\nlabel={0:\"\u4e00\",1:\"\u4e01\",2:\"\u4e03\",3:\"\u4e07\",4:\"\u4e08\",5:\"\u4e09\",6:\"\u4e0a\",7:\"\u4e0b\",8:\"\u4e0d\",9:\"\u4e0e\"}\n#print(list(os.walk(\"..\/input\/\"))) #\u8f93\u51fa\u6570\u636e\u96c6\u7684\u6587\u4ef6\u5185\u5bb9\ntrain_dataset=[]#\u4e00\u4e2a\u5143\u7ec4(\u56fe\u7247\u77e9\u9635\uff0c\u5b57\u7684\u7c7b\u522b)\nfor root,dir,files in os.walk(\"..\/input\/ljy-hwdb1\/train\"): #\u904d\u5386\u6570\u636e\u96c6\u6240\u5728\u7684\u6587\u4ef6\u5939\n    #root\uff1a\u8868\u793a\u5f53\u524d\u6240\u5728\u7684\u6587\u4ef6\u5939\uff08\u9996\u5148\u5728jy-hwbd1\u4e0b\u904d\u5386\uff0c\u7136\u540e\u8fdb\u5165test\u904d\u5386\uff09\n    #dir\u8868\u793a\u5f53\u524d\u76ee\u5f55\u4e0b\u6709\u51e0\u4e2a\u6587\u4ef6\u5939\n    #\u5230\u4e86\\train\u6216\u8005\\test\u4e0b\u9762files\u624d\u6709\u503c\n    for file in files:#\u8bfb\u5165\u6570\u636e\u96c6\u4e3a\u5217\u8868\n        label=root.split()[-1]# split() \u901a\u8fc7\u6307\u5b9a\u5206\u9694\u7b26\u5bf9\u5b57\u7b26\u4e32\u8fdb\u884c\u5207\u7247\u6210\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u9ed8\u8ba4\u4e3a\u6240\u6709\u7684\u7a7a\u5b57\u7b26\uff0c\u5305\u62ec\u7a7a\u683c\u3001\u6362\u884c(\\n)\u3001\u5236\u8868\u7b26(\\t)\u7b49\u3002\n        image_path=os.path.join(root,file)\n        image=plt.imread(image_path)\n        train_dataset.append((image,label))\n\n#\u8bfb\u53d6\u6d4b\u8bd5\u96c6\n\n\ntest_dataset=[]#\u4e00\u4e2a\u5143\u7ec4(\u56fe\u7247\u77e9\u9635\uff0c\u5b57\u7684\u7c7b\u522b)\nfor root,dir,files in os.walk(\"..\/input\/ljy-hwdb1\/test\"): #\u904d\u5386\u6570\u636e\u96c6\u6240\u5728\u7684\u6587\u4ef6\u5939\n    #root\uff1a\u8868\u793a\u5f53\u524d\u6240\u5728\u7684\u6587\u4ef6\u5939\uff08\u9996\u5148\u5728jy-hwbd1\u4e0b\u904d\u5386\uff0c\u7136\u540e\u8fdb\u5165test\u904d\u5386\uff09\n    #dir\u8868\u793a\u5f53\u524d\u76ee\u5f55\u4e0b\u6709\u51e0\u4e2a\u6587\u4ef6\u5939\n    #\u5230\u4e86\\train\u6216\u8005\\test\u4e0b\u9762files\u624d\u6709\u503c\n    for file in files:#\u8bfb\u5165\u6570\u636e\u96c6\u4e3a\u5217\u8868\n        label=root.split()[-1]# split() \u901a\u8fc7\u6307\u5b9a\u5206\u9694\u7b26\u5bf9\u5b57\u7b26\u4e32\u8fdb\u884c\u5207\u7247\u6210\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u9ed8\u8ba4\u4e3a\u6240\u6709\u7684\u7a7a\u5b57\u7b26\uff0c\u5305\u62ec\u7a7a\u683c\u3001\u6362\u884c(\\n)\u3001\u5236\u8868\u7b26(\\t)\u7b49\u3002\n        image_path=os.path.join(root,file)\n        image=plt.imread(image_path)\n        test_dataset.append((image,label))\n    ","19caa209":"print(train_dataset[0])","a1da6741":"# \"\"\"\u642d\u5efa\u795e\u7ecf\u7f51\u7edc\"\"\"\n# #\u5b9a\u4e49\u5377\u79ef\u5c42\n# image=torch.tensor([[0,1,0,0,0,0,0,0],\n#                      [0,1,0,0,0,0,0,0],\n#                      [0,1,0,0,0,0,0,0],\n#                      [0,1,0,0,0,0,0,0],\n#                      [0,1,0,0,0,0,0,0],\n#                      [0,1,0,0,0,0,0,0],\n#                      [0,1,0,0,0,0,0,0],\n#                      [0,1,0,0,0,0,0,0]],dtype=torch.float32).reshape(1,1,8,8)\n# kernel=torch.tensor([[1,0,0],\n#                     [0,1,0],\n#                     [0,0,1]],dtype=torch.float32).reshape(1,1,3,3)\n# kernel=torch.nn.Parameter(kernel)#\u7f51\u7edc\u91cc\u9762\u5377\u79ef\u6838\u5fc5\u987b\u4e3aParameter\n# conv_layer.weight=kernel#\u8bbe\u7f6e\u5377\u79ef\u7f51\u7edc\u7684kernel\n# conv_layer.bias=torch.nn.Parameter(torch.zeros_like(conv_layer.bias))#\u504f\u7f6e\u7f6e0\n# conv_layer=torch.nn.Conv2d(1,1,3,1,0)#t\u901a\u9053\u6570\uff0c\u91c7\u6837\u5668\uff0ckernel_size\uff0cstride\uff0cpadding\n# y1=conv_layer(image)\n# print(y1)","756cad9e":"# #\u6c60\u5316\u5c42\n# max_pooling_layer=torch.nn.MaxPool2d(kernel_size=2,stride=2)\n# y2=max_pooling_layer(y1)\n# print(y2)","099cc629":"# #relu\n# relu_layer=torch.nn.ReLU()\n# y3=relu_layer(y2)\n# print(y3)","897bd12a":"# \"\"\"Sequential\u6a21\u5757\u5b9e\u73b0\u51e0\u4e2a\u5c0f\u5c42\u7684\u5c01\u88c5\"\"\"\n# conv_layer_combine=torch.nn.Sequential(conv_layer,max_pooling_layer,relu_layer)\n# conv_layer_combine(image)","99118ddb":"import cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torchvision\nimport torch\nimport torch.nn\nimport os \nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader #\u4f5c\u7528\uff1a\u4e00\u6b21\u4f2050\u5f20\u56fe\u7247\uff0c\u62fc\u6210\u5f20\u91cf\uff1b\u6253\u4e71\u56fe\u7247\u987a\u5e8f\nimport torchvision.transforms as transforms","d663aaee":"\n\n#\u8bfb\u53d6\u8bad\u7ec3\u96c6\n#\u5faa\u73af\u8f93\u51fa\u56fe\u7247\n\n#print(list(os.walk(\"..\/input\/\"))) #\u8f93\u51fa\u6570\u636e\u96c6\u7684\u6587\u4ef6\u5185\u5bb9\ntrain_dataset=[]#\u4e00\u4e2a\u5143\u7ec4(\u56fe\u7247\u77e9\u9635\uff0c\u5b57\u7684\u7c7b\u522b)\nfor root,dir,files in os.walk(\"..\/input\/ljy-hwdb1\/train\"): #\u904d\u5386\u6570\u636e\u96c6\u6240\u5728\u7684\u6587\u4ef6\u5939\n    #root\uff1a\u8868\u793a\u5f53\u524d\u6240\u5728\u7684\u6587\u4ef6\u5939\uff08\u9996\u5148\u5728jy-hwbd1\u4e0b\u904d\u5386\uff0c\u7136\u540e\u8fdb\u5165test\u904d\u5386\uff09\n    #dir\u8868\u793a\u5f53\u524d\u76ee\u5f55\u4e0b\u6709\u51e0\u4e2a\u6587\u4ef6\u5939\n    #\u5230\u4e86\\train\u6216\u8005\\test\u4e0b\u9762files\u624d\u6709\u503c\n    for file in files:#\u8bfb\u5165\u6570\u636e\u96c6\u4e3a\u5217\u8868\n        label=int(root.split(\"\/\")[-1])# split() \u901a\u8fc7\u6307\u5b9a\u5206\u9694\u7b26\u5bf9\u5b57\u7b26\u4e32\u8fdb\u884c\u5207\u7247\u6210\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u9ed8\u8ba4\u4e3a\u6240\u6709\u7684\u7a7a\u5b57\u7b26\uff0c\u5305\u62ec\u7a7a\u683c\u3001\u6362\u884c(\\n)\u3001\u5236\u8868\u7b26(\\t)\u7b49\u3002\n        image_path=os.path.join(root,file) #\u5408\u5e76\u4e3a\u7edd\u5bf9\u8def\u5f84\n        image=plt.imread(image_path) #\u8bfb\u5165\u56fe\u7247\u4e3a\u77e9\u9635\u5217\u8868\n        image=cv2.resize(image,(28,28))#\u5c06\u56fe\u7247\u538b\u7f29\u4e3a28\u00d728\u77e9\u9635\n        image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  #\u8f6c\u4e3a\u7070\u5ea6\u56fe\n        image=image.reshape(28,28,1)\n        image=transforms.ToTensor()(image)\n        train_dataset.append((image,label))\n        \n\n#\u8bfb\u53d6\u6d4b\u8bd5\u96c6\n\n\ntest_dataset=[]#\u4e00\u4e2a\u5143\u7ec4(\u56fe\u7247\u77e9\u9635\uff0c\u5b57\u7684\u7c7b\u522b)\nfor root,dir,files in os.walk(\"..\/input\/ljy-hwdb1\/test\"): #\u904d\u5386\u6570\u636e\u96c6\u6240\u5728\u7684\u6587\u4ef6\u5939\n    #root\uff1a\u8868\u793a\u5f53\u524d\u6240\u5728\u7684\u6587\u4ef6\u5939\uff08\u9996\u5148\u5728jy-hwbd1\u4e0b\u904d\u5386\uff0c\u7136\u540e\u8fdb\u5165test\u904d\u5386\uff09\n    #dir\u8868\u793a\u5f53\u524d\u76ee\u5f55\u4e0b\u6709\u51e0\u4e2a\u6587\u4ef6\u5939\n    #\u5230\u4e86\\train\u6216\u8005\\test\u4e0b\u9762files\u624d\u6709\u503c\n    for file in files:#\u8bfb\u5165\u6570\u636e\u96c6\u4e3a\u5217\u8868\n        label=int(root.split(\"\/\")[-1])# split() \u901a\u8fc7\u6307\u5b9a\u5206\u9694\u7b26\u5bf9\u5b57\u7b26\u4e32\u8fdb\u884c\u5207\u7247\u6210\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u9ed8\u8ba4\u4e3a\u6240\u6709\u7684\u7a7a\u5b57\u7b26\uff0c\u5305\u62ec\u7a7a\u683c\u3001\u6362\u884c(\\n)\u3001\u5236\u8868\u7b26(\\t)\u7b49\u3002\n        image_path=os.path.join(root,file)\n        image=plt.imread(image_path)\n        image=cv2.resize(image,(28,28)) #\u5c06\u56fe\u7247\u538b\u7f29\u4e3a28\u00d728\u77e9\u9635\n        image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  #\u8f6c\u4e3a\u7070\u5ea6\u56fe\n        image=image.reshape(28,28,1)\n        image=transforms.ToTensor()(image)\n        test_dataset.append((image,label))\n# print(test_dataset[0])\n\n\n#\u6253\u4e71\u6570\u636e\u96c6\ntrain_loader=DataLoader(dataset=train_dataset,batch_size=50,shuffle=True) #shuffle\u8bbe\u7f6e\u662f\u5426\u6253\u4e71\ntest_loader=DataLoader(dataset=test_dataset,batch_size=50,shuffle=False) #shuffle\u8bbe\u7f6e\u662f\u5426\u6253\u4e71","ac770e53":"print(type(train_dataset))\nprint(type(train_loader))","a1e5bbe2":"class ConvNet(torch.nn.Module):\n\n    def __init__(self): #\u5b9a\u4e49\u521d\u59cb\u5316\u53c2\u6570\n        #\u8c03\u7528\u7236\u7c7b\u65b9\u6cd5\n        super(ConvNet,self).__init__()\n        self.layer1=torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,stride=1,padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2,stride=2))\n        self.layer2=torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2,stride=2))\n        self.fc1=torch.nn.Linear(7*7*32,120)\n        self.fc2=torch.nn.Linear(120,84)        #\n        self.fc3=torch.nn.Linear(84,10)              \n    def forward(self,x):\n        x=self.layer1(x)\n        x=self.layer2(x)\n        x=x.reshape(x.size(0),-1) #\u628a\u8f93\u51fa\u77e9\u9635\u62c9\u76f4\n        x=self.fc1(x)\n        x=self.fc2(x)\n        x=self.fc3(x)\n        return x\nmodel=ConvNet()\n","feac3461":"#\u5b9a\u4e49\u635f\u5931\u51fd\u6570\ncriterion=torch.nn.CrossEntropyLoss()\n#\u8bbe\u7f6e\u4f18\u5316\u7684\u65b9\u6cd5\u4e3aAdam\uff0c\u4f20\u5165\u5f85\u4f18\u5316\u53c2\u6570\u548c\u5b66\u4e60\u7387\noptimizer=torch.optim.Adam(model.parameters(),lr=0.001) \n\nlost_list=[]\nfor epoch in range(50):#\u904d\u5386\u6574\u4e2a\u8bad\u7ec3\u96c610\u6b21\n    n = 0\n    N = 0\n    #\u8bad\u7ec3\u7f51\u7edc\n    for images,labels in train_loader:\n        y_predict=model(images)\n\n        loss=criterion(y_predict,labels) #cross_entropy\n        optimizer.zero_grad() #\u5373\u5c06\u68af\u5ea6\u521d\u59cb\u5316\u4e3a\u96f6\uff08\u56e0\u4e3a\u4e00\u4e2abatch\u7684loss\u5173\u4e8eweight\u7684\u5bfc\u6570\u662f\u6240\u6709sample\u7684loss\u5173\u4e8eweight\u7684\u5bfc\u6570\u7684\u7d2f\u52a0\u548c\uff09\n        loss.backward()\n        optimizer.step()\n        lost_list.append(loss.item())\n    #\u8ba1\u7b97\u51c6\u786e\u7387   \n    for images,labels in test_loader:\n        y_predict = model(images)\n#         loss = criterion(y_predict,labels)\n#         loss_list.append(loss.item())\n#         optimizer.step()\n        \n        labels1 = np.array(labels)\n        index = y_predict.argmax(axis=1)\n        #print(len(index))\n        for i in range(len(index)):\n            N+=1\n            if index[i] == labels1[i]:\n                n+=1\n    n=n\/N\n\n    print('\u7b2c'+ str(epoch+1) + '\u6b21\u8bad\u7ec3\u7684\u51c6\u786e\u7387\u4e3a\uff1a' + str(n))\nplt.plot(lost_list)\nplt.show()","90bc3ad6":"label={0:\"\u4e00\",1:\"\u4e01\",2:\"\u4e03\",3:\"\u4e07\",4:\"\u4e08\",5:\"\u4e09\",6:\"\u4e0a\",7:\"\u4e0b\",8:\"\u4e0d\",9:\"\u4e0e\"}\ndataset=[]\nimage1_path=\"..\/input\/ljy-hwdb1\/test\/00007\/203283.png\" \nimage=plt.imread(image1_path) #\u8bfb\u5165\u56fe\u7247\u4e3a\u77e9\u9635\u5217\u8868\nimage=cv2.resize(image,(28,28))#\u5c06\u56fe\u7247\u538b\u7f29\u4e3a28\u00d728\u77e9\u9635\nimage=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  #\u8f6c\u4e3a\u7070\u5ea6\u56fe\nimage=image.reshape(28,28,1)\nimage=transforms.ToTensor()(image)\ndataset.append((image,label))\nloader=DataLoader(dataset=dataset,batch_size=1,shuffle=False)\nfor images,labels in loader:\n    y_predict=model(images)\nout_label=int(y_predict.argmax(axis=1)[0])\nprint(\"\u624b\u5199\u8f93\u5165\u7684\u5b57\u4e3a\uff1a\"+str(label[out_label]))","bde29c5c":"## ----------------------------------------------\u642d\u5efa\u7f51\u7edc(\u6b63\u5f0f\u4ee3\u7801)----------------------------------------------","afbc134b":"\u6a21\u578b\u8bad\u7ec3","384bf774":"1.\u9884\u5904\u7406\uff0c\u628a\u56fe\u7247\u90fdresize\u4e3a28\u00d728","3c75d560":"### \u6d4b\u8bd5\u81ea\u5df1\u7684\u5b57","e5af62e1":"2.\u5377\u79ef\u5c421\n+ \u8f93\u5165\uff1a(1\uff0c28\uff0c28)\n+ \u8f93\u51fa\uff1a(16,14,14)\n+ kernel:16\u4e2a3\u00d73\n\n3.\u5377\u79ef\u5c422\n+ \u8f93\u5165\uff1a(16\uff0c14\uff0c14)\n+ \u8f93\u51fa\uff1a(32\uff0c7\uff0c7)\n+ kernel:32\u4e2a3\u00d73\n\n4.\u5168\u8fde\u63a5\u5c42\n+ \u8f93\u5165\uff1a(32\uff0c7\uff0c7)\n+ \u8f93\u51fa1\uff1a(1\uff0c7\u00d77\u00d732)\n+ \u8f93\u51fa2\uff1aone-hot \uff081\u00d710\uff09\u7684\u5217\u5411\u91cf"}}