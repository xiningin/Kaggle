{"cell_type":{"ab8461c5":"code","1d7deb48":"code","cce103be":"code","c321696a":"code","a0d7383c":"code","ab8bd87d":"code","adf37b18":"code","c00790de":"code","829a0adf":"code","083a9d78":"code","b8994a21":"code","0f69e373":"code","3b2e2d2d":"code","c93583ec":"code","ae407888":"code","adeb0975":"markdown"},"source":{"ab8461c5":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel\n\n# Utils\nfrom tqdm import tqdm\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","1d7deb48":"CONFIG = dict(\n    seed = 42,\n    model_name = '..\/input\/roberta-base',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])","cce103be":"MODEL_PATHS = [\n    '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-0.bin',\n    '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-1.bin',\n    '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-2.bin',\n    '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-3.bin',\n    '..\/input\/pytorch-w-b-jigsaw-starter\/Loss-Fold-4.bin'\n]","c321696a":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","a0d7383c":"df = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\ndf.head()","ab8bd87d":"class JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }","adf37b18":"test_dataset = JigsawDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)","c00790de":"class JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs","829a0adf":"@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS","083a9d78":"def inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds","b8994a21":"preds = inference(MODEL_PATHS, test_loader, CONFIG['device'])","0f69e373":"print(f\"Total Predictiions: {preds.shape[0]}\")\nprint(f\"Total Unique Predictions: {np.unique(preds).shape[0]}\")","3b2e2d2d":"df['score'] = preds\ndf.head()","c93583ec":"df['score'] = df['score'].rank(method='first')\ndf.head()","ae407888":"df.drop('text', axis=1, inplace=True)\ndf.to_csv(\"submission.csv\", index=False)","adeb0975":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">\ud83c\udfaf Training Kernel: <strong><a href=\"https:\/\/www.kaggle.com\/debarshichanda\/pytorch-w-b-jigsaw-starter\">[Pytorch + W&B] Jigsaw Starter<\/a><\/strong>.<\/span>"}}