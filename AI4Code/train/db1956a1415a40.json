{"cell_type":{"41a52dd7":"code","4c2734b6":"code","3919a6cc":"code","94be8d3a":"code","3048ded3":"code","6297e9f4":"code","1c12f1aa":"code","05b1d1f8":"code","edf85268":"code","fdd11e36":"code","45ea0ab3":"code","961d9330":"code","294ee2e1":"code","16e18611":"code","c843345f":"code","8ceb331b":"code","d508455d":"code","bda3b321":"code","c0b7ce4c":"code","7bc9e446":"code","207df4aa":"code","6cf9f6ec":"code","0b7dc859":"markdown","41d82e95":"markdown","62bc7bf8":"markdown","d631170c":"markdown","d07ee8c1":"markdown","55d6a948":"markdown","8aae0d72":"markdown","5096eae6":"markdown","b5181baf":"markdown","093d13ec":"markdown","7e3bffa7":"markdown","989bed02":"markdown","8012f1c7":"markdown","c724465b":"markdown","b48f8e3d":"markdown","8220851a":"markdown","377becfe":"markdown","17711fb1":"markdown","f47a3d4e":"markdown","e3d90b5c":"markdown","8cbb81c6":"markdown","c292dd5a":"markdown","e82221c1":"markdown","4493f19e":"markdown","afcb7ef4":"markdown","8ac44212":"markdown","5891b777":"markdown","ad03e072":"markdown","cb2eb1d3":"markdown"},"source":{"41a52dd7":"# Basic math libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Import library\nimport os\nprint(os.listdir(\"..\/input\"))\n# Take note that the .7z directory name is automatically converted to lowercase. \n\nimport os.path\n# Ensure we're reading the directory correctly.\nos.path.exists('..\/input\/chest_xray\/chest_xray')","4c2734b6":"directory = os.listdir('..\/input\/chest_xray\/chest_xray')\nprint(\"Parent directory includes these folders:\", directory)","3919a6cc":"train_folder = '..\/input\/chest_xray\/chest_xray\/train\/'\nval_folder   = '..\/input\/chest_xray\/chest_xray\/val\/'\ntest_folder  = '..\/input\/chest_xray\/chest_xray\/test\/'","94be8d3a":"# train \nos.listdir(train_folder)\ntrain_n = train_folder + 'NORMAL\/'\ntrain_p = train_folder + 'PNEUMONIA\/'","3048ded3":"# Normal pic \nprint(\"Total images this directory are:\", len(os.listdir(train_n)))\n\nrand_norm = np.random.randint(0, len(os.listdir(train_n)))\nnorm_pic = os.listdir(train_n)[rand_norm]\nnorm_pic_address = train_n + norm_pic\n\nprint('normal picture title: ', norm_pic)","6297e9f4":"# Pneumonia\nprint(\"Total images this directory are:\", len(os.listdir(train_p)))\n\nrand_p = np.random.randint(0, len(os.listdir(train_p)))\nsic_pic =  os.listdir(train_p)[rand_p]\nsic_pic_address = train_p + sic_pic\n\nprint('pneumonia picture title:', sic_pic)","1c12f1aa":"# Load the images\n# Image.open is from Import\nfrom PIL import Image\n\nnorm_load = Image.open(norm_pic_address)\nsic_load  = Image.open(sic_pic_address)","05b1d1f8":"# plot images\nf = plt.figure(figsize = (10, 10))\n\n# add_subplot(nrows, ncols, index, **kwargs)\na1 = f.add_subplot(1, 2, 1)\nimg_plot = plt.imshow(norm_load)\na1.set_title('Normal')\n\na2 = f.add_subplot(1, 2, 2)\nimg_plot = plt.imshow(sic_load)\na2.set_title('Patient-Zero')","edf85268":"# validation \nos.listdir(val_folder)\nval_n = val_folder + 'NORMAL\/'\nval_p = val_folder + 'PNEUMONIA\/'","fdd11e36":"# Normal pic \nprint(\"Total images this directory are:\", len(os.listdir(val_n)))\n\nrand_norm = np.random.randint(0, len(os.listdir(val_n)))\nnorm_pic = os.listdir(val_n)[rand_norm]\nnorm_pic_address = val_n + norm_pic\n\nprint('normal picture title: ', norm_pic)","45ea0ab3":"# Pneumonia\nprint(\"Total images this directory are:\", len(os.listdir(val_p)))\n\nrand_p = np.random.randint(0, len(os.listdir(val_p)))\nsic_pic =  os.listdir(val_p)[rand_p]\nsic_pic_address = val_p + sic_pic\n\nprint('pneumonia picture title:', sic_pic)","961d9330":"# test\nos.listdir(test_folder)\ntest_n = test_folder + 'NORMAL\/'\ntest_p = test_folder + 'PNEUMONIA\/'","294ee2e1":"# Normal pic \nprint(\"Total images this directory are:\", len(os.listdir(test_n)))\n\nrand_norm = np.random.randint(0, len(os.listdir(test_n)))\nnorm_pic = os.listdir(test_n)[rand_norm]\nnorm_pic_address = test_n + norm_pic\n\nprint('normal picture title: ', norm_pic)","16e18611":"# Pneumonia\nprint(\"Total images this directory are:\", len(os.listdir(test_p)))\n\nrand_p = np.random.randint(0, len(os.listdir(test_p)))\nsic_pic =  os.listdir(test_p)[rand_p]\nsic_pic_address = test_p + sic_pic\n\nprint('pneumonia picture title:', sic_pic)","c843345f":"print(\"Total train normal images:\", len(os.listdir(train_n)))\nprint(\"Total validation normal images:\", len(os.listdir(val_n)))\nprint(\"Total test normal images:\", len(os.listdir(test_n)))","8ceb331b":"print(\"Total train pneumonia images:\", len(os.listdir(train_p)))\nprint(\"Total validation pneumonia images:\", len(os.listdir(val_p)))\nprint(\"Total test pneumonia images:\", len(os.listdir(test_p)))","d508455d":"train_n_count = len(os.listdir(train_n))\nval_n_count   = len(os.listdir(val_n))\ntest_n_count  = len(os.listdir(test_n))\n\ntrain_p_count = len(os.listdir(train_p))\nval_p_count   = len(os.listdir(val_p))\ntest_p_count  = len(os.listdir(test_p))\n\nnormal_count = [train_n_count, val_n_count, test_n_count]\nsic_count = [train_p_count, val_p_count, test_p_count]\n\nprint(normal_count)\nprint(sic_count)","bda3b321":"normal_count_total = train_n_count + val_n_count + test_n_count\nsic_count_total    = train_p_count + val_p_count + test_p_count\n\nprint(normal_count_total)\nprint(sic_count_total)","c0b7ce4c":"# data to plot\nn_groups = 1\n\n# create plot\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.35\nopacity = 0.8\n \nrects1 = plt.bar(index, normal_count_total, bar_width,\n                 alpha = opacity,\n                 color = 'b',\n                 label = 'normal')\n \nrects2 = plt.bar(index + bar_width, sic_count_total, bar_width,\n                 alpha = opacity,\n                 color = 'r',\n                 label = 'pneumonia')\n \nplt.xlabel('Dataset')\nplt.ylabel('Image Count')\nplt.title('Total Normal-Pneumonia Imbalance')\nplt.xticks(index + bar_width, ('', ''))\nplt.legend()\n \nplt.tight_layout()\nplt.show()","7bc9e446":"total_images = normal_count_total + sic_count_total\n\nnormal_count_pct = normal_count_total \/ total_images\nsic_count_pct = sic_count_total \/ total_images\n\nprint(\"Percentage normal: {0} %\\n\".format(normal_count_pct))\nprint(\"Percentage pneumonia: {0} %\\n\".format(sic_count_pct))","207df4aa":"# data to plot\nn_groups = 3\n    \n# create plot\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.35\nopacity = 0.8\n \nrects1 = plt.bar(index, normal_count, bar_width,\n                 alpha = opacity,\n                 color = 'b',\n                 label = 'normal')\n \nrects2 = plt.bar(index + bar_width, sic_count, bar_width,\n                 alpha = opacity,\n                 color = 'r',\n                 label = 'pneumonia')\n \nplt.xlabel('Dataset')\nplt.ylabel('Image Count')\nplt.title('Train-Validation-Test Imbalance')\nplt.xticks(index + bar_width, ('Train', 'Validation', 'Test'))\nplt.legend()\n \nplt.tight_layout()\nplt.show()","6cf9f6ec":"# from sklearn.model_selection import train_test_split\n\n#Splitting \n# X_train, X_test, y_train, y_test = train_test_split(x_files, y_train, test_size = 0.3, random_state = 42)","0b7dc859":"Validation is exceptionally small in count, whereas overall, training pneumonia takes the majority of all subsets.","41d82e95":"### Consider Imbalanced Dataset\n**This dataset is highly imbalanced, which is problematic because:** Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Sollicitudin tempor id eu nisl nunc mi ipsum. Pellentesque eu tincidunt tortor aliquam nulla facilisi cras fermentum odio. Interdum consectetur libero id faucibus nisl tincidunt eget. Mattis aliquam faucibus purus in. Dignissim cras tincidunt lobortis feugiat vivamus at augue eget. Purus faucibus ornare suspendisse sed nisi lacus sed viverra tellus. Enim tortor at auctor urna nunc id cursus metus aliquam.","62bc7bf8":"And we randomly select one image from the pneumonia hat.","d631170c":"Add them up to compare simply the total normal vs pneumonia counts.","d07ee8c1":"There is a severe imbalance between the labels. We can drill down and visualize these distribution measures using a [bar chart](https:\/\/pythonspot.com\/matplotlib-bar-chart\/).","55d6a948":"Plot the results for interpretation.","8aae0d72":"#### Define Test Data","5096eae6":"## Data Split\nThe data should be split to validate the efficacy of the models. We might use either cross validation, or a 70-30 split.\n\n**Before splitting the data,  we will need to obtain the y-labels to go along with X.**","b5181baf":"#### Define Validation Data","093d13ec":"## Project Proposal End","7e3bffa7":"Group all these counts together for their totals.","989bed02":"This concludes our initial examination of our data. Our next step is to build a CNN, tweak its architecture, and explore other available models for import. The best classification accuracy will be chosen from the models.\n\nAfter completing the first half of this project, we will then turn to interpretting and visualizing the model, using various methods.\n\n### Thank you","8012f1c7":"# Artificial Intelligence\n## X-ray Pneumonia Classification\n10\/22\/2018  \n* Bethelhem Tesfaw\n* John Wolsky\n* Liu Huimin\n* Naomi Sprague\n* Garth Mortensen","c724465b":"First, locate the main directory and display its content.","b48f8e3d":"And plot them.","8220851a":"## Initial Data Review","377becfe":"### Load Data\n#### Define Training Data","17711fb1":"And select a Pneumonia image.","f47a3d4e":"Using Python Image Library (PIL), we can open the images.","e3d90b5c":"We randomly select one image from the healthy hat.","8cbb81c6":"Select one validation data normal image.","c292dd5a":"### Problem\n#### Part 1: Classify Images\nUsing Convolutional Neural Networks (CNN) and other machine learning methods, classify chest x-ray images as:\n\n1. Healthy \n2. Pneumonia viral \n3. Pneumonia bacterial\n\n#### Part 2: Visualize what CNNs Learn\nAfter classifying these images, visualize and interpret the learned classified representations. Much research has been done to determine why a neural network produces certain results, given predictors. That is, explore how the CNN classified the images. Three ways to accomplish this are:\n\n1. Visualize intermediate convnet outputs (intermediate activations) - *Show how succesive layers tranform output, and see the first idea of individual convnet filters.*\n2. Visualize convnets filters - *See precisely what visual pattern or concept each filter is receptive to.*\n3. Visualize heatmaps of class activation in an image - *Identify which parts of an image were identified as belonging to a certain class.*\n\n**Deep Learning in Python (Ch. 5, pg 160)**, can serve as a guide for the second half of this project. On Monday, October 8, 2018 at 5:48:26 PM plus 1h17m, Professor Lai also discussed how to identify driving factors in prediction. Simplified, we can take the output of a hidden layer, and build a machine learning model to predict. The weights of this model indicates the relative importance of each factor.\n\nThrough this work, we will not have only classified the x-ray images, but also opened the black box to understand its operatations and determination of important predictors.\n  \n### Scope\nInitially, we will build a CNN to classify the x-ray images into the three classes. Various architectures will be used before settling on a CNN, perhaps including AlexNet, VGG-16 and others. The CNN's performance will then be measured using accuracy and other metrics, such as ROC.\n \nThe CNN's x-hat hidden layer outputs may then be used as inputs to build several machine learning models. To determine the effecacy these models, their performance would be evaluated. As a possible final step, we may combine them into an ensemble model, with the same end goal of producing a three-way classification.\n \n### Data\n#### Data Source\nThe data archive is housed on kaggle, here:\nhttps:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia\n\n\n#### Data Structure\nThe dataset is a .zip archive containing the three pre-split folders of training, validation and test. Housed within them are a total of 5,863 images. The data is pre-split into those folders, with subfolders for normal and pneumonia. \n \nThe archive is 1.21Gb zipped, and 1.17Gb uncompressed. The directory structure is shown below.\n\n* \/chest_xray\/  \n  * test\/\n    * NORMAL\/\n    * PNEUMONIA\/\n  * train\/\n    * NORMAL\/\n    * PNEUMONIA\/\n  * val\/\n    * NORMAL\/\n    * PNEUMONIA\/\n\nThese folders will provide class labels.\n\nThis folder structure does not follow a 70-30 split, but rather a 89-1-10. It is an odd split, which we may later erase by merging all folders and splitting according to our desires. \n\nOur dataset is significantly imbalanced. there are nearly *3x the amount of pneumonia labels than normal labels*. However, in training data, we do have two classes of pneumonia, so the imbalance may be less severe than it appears at first glance. This ratio doesn't hold equal for test data. Some time should be reserved to read further into working with unbalanced data.\n\n\n|**Dir**    |                               | **Files**     | **% Total**|\n|-------|-----------|-------:|---------:|\n| test  |                                |               | 10.6  |\n|         | NORMAL              | 234        | 4.0   |\n|         | PNEUMONIA       | 390       | 6.7    |\n| train |                              |                | 89.0 |\n|         | NORMAL             | 1,342      | 22.9 |\n|         | PNEUMONIA      | 3,876     | 66.1  |\n| val   |                               |                | 0.3   |\n|         | NORMAL             | 9            | 0.2   |\n|         | PNEUMONIA      | 9            | 0.2   |\n| **Total** |                             | **5,860**    | **100**       |\n.\n\nThe data is comprised entirely of images whose properties are:\n* Of varying pixel height x width. **POTENTIAL TROUBLE** \/ [*POTENTIAL SOLUTION*](https:\/\/www.kaggle.com\/dansbecker\/programming-in-tensorflow-and-keras)\n* 8-bit depth\n* grayscale  \n\n#### Potential Challenges\n\nTo load this data, we might use this [kernel](https:\/\/www.kaggle.com\/jgrandinetti\/classification-using-convnet-keras) as a guide. ImageDataGenerator uses flow_from_directory, which could be a perfect solution for this folder structure.\n\nIt remains to be seen whether these large format images will pose processing (CPU\/GPU) and memory (RAM) challenges, but downsampling might be helpful. Pooling early on could decrease processing time substantially.\n\n### Tools\nWe will use the following tools:\n1. Kaggle\n2. MATLAB\n3. Python  \n    I. Tensorflow  \n    II. Keras  \n4. Google Drive\n5. Onedrive","e82221c1":"Is there anything evident to you in the images above? I see nothing at all.","4493f19e":"Define the two training class folders of Normal and Pneumonia.","afcb7ef4":"Display percentages of total.","8ac44212":"Select one test data image.","5891b777":"And select a pneumonia image.","ad03e072":"The folders are split to include train, testing, as well as validation. Create variables pointing to these subfolders","cb2eb1d3":"### Obtain Y-labels"}}