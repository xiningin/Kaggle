{"cell_type":{"273ae277":"code","05e0fb90":"code","0f22c5b9":"code","199167aa":"code","7925c6d5":"code","a011155a":"code","37e37ea1":"code","a34edeab":"code","cfa70544":"code","6e9a684f":"code","076a9224":"code","eda61616":"code","5f7e6c75":"code","182d0d81":"code","086a0f4e":"code","05d54f6a":"code","0b948658":"code","6386c90c":"code","d0d76a90":"code","ff508275":"code","31c69599":"code","0751f7fa":"code","e9847178":"code","d2c80c86":"code","13d81328":"code","3d049566":"code","ec33b54a":"code","7bc1db80":"code","b82803d2":"code","617e6683":"code","f113eff5":"code","0b95b619":"code","4c3360b4":"code","e0741702":"code","61ef0295":"code","cbbcb354":"code","89cd7242":"code","88a9ac78":"code","2153cb1e":"code","af34a790":"code","84cd7413":"code","4ee98b34":"code","f35c0b41":"code","23423f82":"code","6882f22e":"code","d166e319":"code","82f199a5":"code","26a04c56":"code","9ac6cb21":"code","8ac77bae":"code","673ddcd8":"code","207fb0c5":"code","ab51823d":"code","27dcfbf9":"code","206f8684":"code","f232037f":"markdown","d53f5f66":"markdown","52857f48":"markdown","09c55fc5":"markdown","484b44da":"markdown","aa3f2f5d":"markdown","cdcd3b7e":"markdown","bab12788":"markdown","9134930f":"markdown","ba023f99":"markdown","d21a1bc2":"markdown","ba26e730":"markdown","0c35620e":"markdown","6d9e989e":"markdown","b3a92c50":"markdown","fda94f3f":"markdown","668846ba":"markdown"},"source":{"273ae277":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05e0fb90":"df= pd.read_csv(\"\/kaggle\/input\/mushroom-classification\/mushrooms.csv\")","0f22c5b9":"df","199167aa":"df.describe()","7925c6d5":"df.isnull().sum()","a011155a":"df.nunique()","37e37ea1":"s= (df.dtypes == 'object')\nobj_cols = list(s[s].index) ","a34edeab":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nlabel_df = df.copy()\nfor i in obj_cols:\n    label_df[i] = encoder.fit_transform(df[i])","cfa70544":"label_df.head()","6e9a684f":"# let's import the data set again incase any issue arrises\ndf= pd.read_csv(\"\/kaggle\/input\/mushroom-classification\/mushrooms.csv\")","076a9224":"from sklearn.preprocessing import OneHotEncoder\noh_encoder = OneHotEncoder(handle_unknown='ignore', sparse =False)","eda61616":"one_hot_cols = pd.DataFrame(oh_encoder.fit_transform(df[obj_cols]))\n# adding the index\none_hot_cols.index= df.index","5f7e6c75":"#removing categorical columns\nnum_df = df.drop(obj_cols,axis=1)","182d0d81":"oh_df = pd.concat([num_df,one_hot_cols],axis =1)","086a0f4e":"oh_df","05d54f6a":"oh_df[0]","0b948658":"df= pd.read_csv(\"\/kaggle\/input\/mushroom-classification\/mushrooms.csv\")\n","6386c90c":"dummy_df = pd.get_dummies(df)","d0d76a90":"dummy_df","ff508275":"from sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt","31c69599":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters = 2 ,init= 'k-means++',random_state=1)","0751f7fa":"label_pred_k = kmeans.fit_transform(label_df)\nplt.figure(figsize = (10,7))\nplt.scatter(label_pred_k[:,0],label_pred_k[:,1],label ='cluster1')\nplt.title('Cluster for label encoded values of mushroom')","e9847178":"oh_pred_k = kmeans.fit_transform(oh_df)","d2c80c86":"plt.figure(figsize =(10,7))\nplt.scatter(oh_pred_k[:,0],oh_pred_k[:,1],label ='cluster')\nplt.title(\"cluster for One HotEncoed values\")","13d81328":"d_pred_k = kmeans.fit_transform(dummy_df)\nplt.figure(figsize=(10,7))\nplt.scatter(d_pred_k[:,0],d_pred_k[:,1], label = 'cluster')\nplt.title(\"cluster for dummy encoded values\")","3d049566":"label_x=label_df.iloc[:,1:]\nlabel_y=label_df.iloc[:,0]","ec33b54a":"L_X_train,L_X_valid,L_Y_train,L_Y_valid = train_test_split(label_x,label_y,train_size=.77,random_state=10)\n","7bc1db80":"oh_x=oh_df.iloc[:,1:]\noh_y=oh_df.iloc[:,0]","b82803d2":"OH_X_train,OH_X_valid,OH_Y_train,OH_Y_valid= train_test_split(oh_x,oh_y,train_size=.50,random_state=10)","617e6683":"dummy_x =dummy_df.iloc[:,1:]\ndummy_y=dummy_df.iloc[:,0]","f113eff5":"D_X_train,D_X_valid,D_Y_train,D_Y_valid=train_test_split(dummy_x,dummy_y,train_size=.77,random_state=10)","0b95b619":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()","4c3360b4":"#label encoded data\nlr.fit(L_X_train,L_Y_train)\nlr_L_pred= lr.predict(L_X_valid)\nlr_L_accuracy=lr.score(L_X_valid,L_Y_valid)\nlr_L_accuracy","e0741702":"lr_L_pred","61ef0295":"#OneHotEncoded data\nlr.fit(OH_X_train,OH_Y_train)\nlr_OH_pred= lr.predict(OH_X_valid)\nlr_OH_accuracy=lr.score(OH_X_valid,OH_Y_valid)\nlr_OH_accuracy","cbbcb354":"#dummy data\nlr.fit(D_X_train,D_Y_train)\nlr_D_pred= lr.predict(D_X_valid)\nlr_D_accuracy=lr.score(D_X_valid,D_Y_valid)\nlr_D_accuracy","89cd7242":"from sklearn.linear_model import LogisticRegression\nLR =LogisticRegression()","88a9ac78":"# LABEL ENCODING\nLR.fit(L_X_train,L_Y_train)# LABEL ENCODING\nLR.fit(L_X_train,L_Y_train)\nLR_L_pred= LR.predict(L_X_valid)\nLR_L_accuracy=LR.score(L_X_valid,L_Y_valid)\nLR_L_accuracy","2153cb1e":"#OneHotEncoded data\nLR.fit(OH_X_train,OH_Y_train)\nLR_OH_pred= LR.predict(OH_X_valid)\nLR_OH_accuracy=LR.score(OH_X_valid,OH_Y_valid)\nLR_OH_accuracy","af34a790":"#dummy data\nLR.fit(D_X_train,D_Y_train)\nLR_D_pred= LR.predict(D_X_valid)\nLR_D_accuracy=LR.score(D_X_valid,D_Y_valid)\nLR_D_accuracy","84cd7413":"from sklearn.tree import DecisionTreeRegressor\nDF=DecisionTreeRegressor(random_state=0)","4ee98b34":"# LABEL ENCODING\nDF.fit(L_X_train,L_Y_train)\nDF_L_pred= DF.predict(L_X_valid)\nDF_L_accuracy=DF.score(L_X_valid,L_Y_valid)\nDF_L_accuracy","f35c0b41":"#OneHotEncoded data\nDF.fit(OH_X_train,OH_Y_train)\nDF_OH_pred= DF.predict(OH_X_valid)\nDF_OH_accuracy=DF.score(OH_X_valid,OH_Y_valid)\nDF_OH_accuracy","23423f82":"#dummy data\nDF.fit(D_X_train,D_Y_train)\nDF_D_pred= DF.predict(D_X_valid)\nDF_D_accuracy=DF.score(D_X_valid,D_Y_valid)\nDF_D_accuracy","6882f22e":" from sklearn.ensemble import RandomForestRegressor\nRF = RandomForestRegressor()","d166e319":"# LABEL ENCODING\nRF.fit(L_X_train,L_Y_train)\nRF_L_pred= RF.predict(L_X_valid)\nRF_L_accuracy=RF.score(L_X_valid,L_Y_valid)\nRF_L_accuracy","82f199a5":"#OneHotEncoded data\nRF.fit(OH_X_train,OH_Y_train)\nRF_OH_pred= RF.predict(OH_X_valid)\nRF_OH_accuracy=RF.score(OH_X_valid,OH_Y_valid)\nRF_OH_accuracy","26a04c56":"#dummy data\nRF.fit(D_X_train,D_Y_train)\nRF_D_pred= RF.predict(D_X_valid)\nRF_D_accuracy=RF.score(D_X_valid,D_Y_valid)\nRF_D_accuracy","9ac6cb21":"from xgboost import XGBRegressor\nXG = XGBRegressor(n_estimators=500)","8ac77bae":"# LABEL ENCODING\nXG.fit(L_X_train,L_Y_train)\nXG_L_pred= XG.predict(L_X_valid)\nXG_L_accuracy=XG.score(L_X_valid,L_Y_valid)\nXG_L_accuracy","673ddcd8":"#OneHotEncoded data\nXG.fit(OH_X_train,OH_Y_train)\nXG_OH_pred= XG.predict(OH_X_valid)\nXG_OH_accuracy=XG.score(OH_X_valid,OH_Y_valid)\nXG_OH_accuracy","207fb0c5":"#dummy data\nXG.fit(D_X_train,D_Y_train)\nXG_D_pred= XG.predict(D_X_valid)\nXG_D_accuracy=XG.score(D_X_valid,D_Y_valid)\nXG_D_accuracy","ab51823d":"models=['Linear Model','Logistic Regression','Decision Tree Regressor','Random Forest Regressor','XGBregressor']\nlabel_encoding=[lr_L_accuracy,LR_L_accuracy,DF_L_accuracy,RF_L_accuracy,XG_L_accuracy]\nOnehot_encoding =[lr_OH_accuracy,LR_OH_accuracy,DF_OH_accuracy,RF_OH_accuracy,XG_OH_accuracy]\ndummy_encoding = [lr_D_accuracy,LR_D_accuracy,DF_D_accuracy,RF_D_accuracy,XG_D_accuracy]","27dcfbf9":"table = pd.DataFrame({'Model':models,'Label Encoding':label_encoding,'One Hot Encoding':Onehot_encoding,'Dummy Encoding':dummy_encoding})","206f8684":"table","f232037f":"For OneHotEncoded Data","d53f5f66":"Our data is clean hence do not require any kind if replacement in its value","52857f48":"Starting with K-means","09c55fc5":"# Let's  split our data set","484b44da":"1. Linear Regression","aa3f2f5d":"Encoding data using Dummies","cdcd3b7e":"# Let's encode our data with help of diffrent techniques","bab12788":"# Our data is now encoded \n# now we will be fitting our data in diffrent modeling techniques","9134930f":"4. XGBRegressor","ba023f99":"For data encoded by dummies","d21a1bc2":"3. Decision Tree Regressor","ba26e730":"2. Logistic  Regression","0c35620e":"For label encoded data","6d9e989e":"Staring with Label Encoding of data","b3a92c50":"# Fitting the data in diffrent models","fda94f3f":"4. Random Forest Regressor","668846ba":"Applying OneHotEncoding to the data set"}}