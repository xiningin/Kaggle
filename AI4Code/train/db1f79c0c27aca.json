{"cell_type":{"c8371e94":"code","c15bae73":"code","64efaf46":"code","495ec4aa":"code","60f4c545":"code","7f8745eb":"code","76a4ec26":"code","5eec1d65":"code","18cdf60e":"code","50d50cda":"code","d321ba88":"code","259e4b14":"code","253e1055":"code","2e99e469":"code","73cb8bd6":"code","4cc2eb40":"code","08dd0a11":"code","f2244649":"code","5175b739":"code","2fe710bf":"code","a5219019":"code","22570fcb":"code","b2bb40ba":"code","4ebef5d4":"markdown","995f9b7a":"markdown","c514f737":"markdown","46ea65d3":"markdown","0884cc2a":"markdown","bea62ba5":"markdown","e860240a":"markdown","328d031c":"markdown","bd9cdfec":"markdown","aa840df0":"markdown","0f132695":"markdown","2d98fb50":"markdown"},"source":{"c8371e94":"# I like to put all includes at the start of the script so we can make sure we have all the neccessary packages installed already \nimport os\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D","c15bae73":"dataset_path = Path(r'..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset')\n\nfile_path = list(dataset_path.glob(r'**\/*.png'))\n\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_path))","64efaf46":"file_path = pd.Series(file_path).astype(str)\nlabels = pd.Series(labels)\n\ndf = pd.concat([file_path, labels], axis=1)\n\ndf.columns = ['image', 'label']\n\ndf.head()","495ec4aa":"fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15,10))\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df.image[i]))\n    ax.set_title(df.label[i])\n    \nplt.show()","60f4c545":"df = df[df['label'].apply(lambda x: x[-2:] != 'GT')].reset_index(drop=True)\ndf.label.value_counts()","7f8745eb":"x_train, x_test = train_test_split(df, test_size=0.3,random_state=30)\nx_train, x_val = train_test_split(x_train, test_size=0.2, random_state=30)","76a4ec26":"print(\"Training Data Shape\", x_train.shape)\nprint(\"Test Data Shape\", x_test.shape)\nprint(\"Validation Data Shape\", x_val.shape)","5eec1d65":"image_data_generator = ImageDataGenerator(rescale = 1.\/255,\n    rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntrain = image_data_generator.flow_from_dataframe(dataframe=x_train, x_col='image', y_col='label', target_size=(200,200), color_mode='rgb', class_mode='categorical', shuffle=False)\ntest = image_data_generator.flow_from_dataframe(dataframe=x_test, x_col='image', y_col='label', target_size=(200,200), color_mode='rgb', class_mode='categorical', shuffle=False)\nval = image_data_generator.flow_from_dataframe(dataframe=x_val, x_col='image', y_col='label', target_size=(200,200), color_mode='rgb', class_mode='categorical',shuffle=False)","18cdf60e":"input_shape = (200, 200, 3)\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape ),\n    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(9, activation='softmax')\n])\n\nmodel.summary()","50d50cda":"model.compile(optimizer=\"adam\", \n              loss='categorical_crossentropy', \n              metrics=[\"accuracy\"]\n             )\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=4)\n\nhistory = model.fit(train, \n                    validation_data=val, \n                    epochs=20, \n                    callbacks=callback)","d321ba88":"model.save('model-1.h5')","259e4b14":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']","253e1055":"plt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training_Accuracy\")\nplt.plot(val_accuracy, label=\"Validation_Accuracy\")\nplt.legend()\nplt.title(\"Training Accuracy VS. Validation Accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training_Loss\")\nplt.plot(val_loss, label=\"Validation_Loss\")\nplt.legend()\nplt.title(\"Training Loss VS. Validation Loss\")\n\nplt.show()","2e99e469":"pred = model.predict(test)","73cb8bd6":"pred = np.argmax(pred, axis=1)","4cc2eb40":"labels = train.class_indices","08dd0a11":"labels","f2244649":"labels = dict((v,k) for k, v in labels.items())","5175b739":"labels","2fe710bf":"y_pred = [labels[k] for k in pred]","a5219019":"print(classification_report(x_test.label, y_pred))","22570fcb":"print(confusion_matrix(x_test.label, y_pred))","b2bb40ba":"test_accuracy = model.evaluate(test)[1]","4ebef5d4":"### Import Data","995f9b7a":"### Save Model","c514f737":"### Start Training","46ea65d3":"## Define the model","0884cc2a":"## Display Images","bea62ba5":"Extract the class with highest probability for all the test files","e860240a":"### List Each Directory (Fish) With The Number Of Images For That Category (Fish)","328d031c":"### Check The Accuracy","bd9cdfec":"### Plot The Accuracy","aa840df0":"## My results from running the model for 20 Epochs is below\n#### Training_Accuracy = 0.878\n#### Validation_Accuracy= 0.8722\n\n## No bad but definitly room for improvment","0f132695":"### Includes","2d98fb50":"### Create train, test and validation dataset"}}