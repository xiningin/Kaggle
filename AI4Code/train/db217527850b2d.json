{"cell_type":{"de922f0d":"code","43f6e4c0":"code","18f50ad2":"code","7633b400":"code","0a37563a":"code","a6afa42c":"code","7c262414":"code","e91afc53":"code","20cb5837":"code","d58c3565":"code","47a4d236":"code","e288b078":"code","8f8e5715":"code","d15a8de5":"code","4ae40b3a":"code","7e34738f":"code","23dcc926":"code","e5201907":"code","3227d662":"code","1fd6b1dc":"code","d5675535":"code","77a8e534":"code","e431490c":"code","577fc61e":"code","26226c9a":"code","d2c276cf":"code","f325527e":"code","f737074e":"code","25598cc1":"code","1c6d310c":"code","9d049e2b":"code","58daf92a":"code","1622550a":"code","de8f8675":"code","685d68d4":"code","c7057550":"code","7246756d":"markdown","47a7ac10":"markdown","74b6f0e9":"markdown","089bf613":"markdown","30877877":"markdown","37525209":"markdown","14f03b9f":"markdown","33447dc9":"markdown","be822a00":"markdown","d6dc0845":"markdown","ded1b819":"markdown","1574536a":"markdown","ca68e108":"markdown","8aaf6ddf":"markdown","07d1da8b":"markdown","7d094f1d":"markdown","6373d6cd":"markdown","4aad5578":"markdown","75624dfa":"markdown","16891d62":"markdown","5a2b8bca":"markdown","8df9522c":"markdown","8105ad87":"markdown","a76fc476":"markdown","0e600fab":"markdown","65475165":"markdown","940a70a7":"markdown","2912dced":"markdown","c80bc480":"markdown","f5c4fdb2":"markdown","42a7ce05":"markdown","56baf773":"markdown","f84e8c79":"markdown","996d3dbd":"markdown","f702cf03":"markdown","c06dcd05":"markdown","c14b7a83":"markdown","3a0f54e7":"markdown","0b931dec":"markdown","0892c260":"markdown","4c7394cb":"markdown","f5f00db6":"markdown","0631d7e0":"markdown","5c812afa":"markdown","6493ec0f":"markdown","cd781646":"markdown","76fed182":"markdown","f0f06ba0":"markdown","f884b41a":"markdown","25dcdd99":"markdown","04600ed3":"markdown","c36a2f1d":"markdown","ed4702c5":"markdown","31b71c3e":"markdown"},"source":{"de922f0d":"# Install this to upgrade the statsmodels package. It will be required to use AR, MA, & ARMA models\n!pip install statsmodels --upgrade\n!pip install openpyxl","43f6e4c0":"#If the above command doesn't work, please run the below command in the anaconda prompt otherwise ignore\n#conda install statsmodels","18f50ad2":"# Importing libraries for data manipulation\nimport pandas as pd\nimport numpy as np\n\n#Importing libraries for visualization\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\n#Importing library for date manipulation\nfrom datetime import datetime\n\n#To calculate the MSE or RMSE\nfrom sklearn.metrics import mean_squared_error\n\n#Importing acf and pacf functions\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n#Importing models from statsmodels library\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\n\n#To ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')","7633b400":"#If you are having issue while running the excel file in pandas, please run the below command in anaoconda prompt otherwise ignore.\n#conda install -c anaconda xlrd","0a37563a":"df = pd.read_excel('..\/input\/amazon-stock-prices\/amazon_stocks_prices.xlsx', engine=\"openpyxl\")\ndf.head()","a6afa42c":"#Write your code here\ndf.info()","7c262414":"# Setting date as the index\ndf = df.set_index(['date'])\ndf.head()","e91afc53":"# Visualizing the time series\nplt.figure(figsize=(16,8))\nplt.xlabel(\"Month\")\nplt.ylabel(\"Closing Prices\")\nplt.title('Amazon Stock Prices')\nplt.plot(df.index, df.close, color = 'c', marker='.')","20cb5837":"# Splitting the data into train and test\ndf_train = df.loc['2006-01-01':'2015-12-01']\ndf_test = df.loc['2016-01-01' : '2017-12-01']\nprint(df_train)\nprint(df_test)","d58c3565":"# Calculating the rolling mean and standard deviation for a window of 12 observations\nrolmean=df_train.rolling(window=12).mean()\nrolstd=df_train.rolling(window=12).std()\n\n#Visualizing the rolling mean and standard deviation\n\nplt.figure(figsize=(16,8))\nactual = plt.plot(df_train, color='c', label='Actual Series')\nrollingmean = plt.plot(rolmean, color='red', label='Rolling Mean') \n#rollingstd = plt.plot(rolstd, color='green', label='Rolling Std. Dev.')\nplt.title('Rolling Mean & Standard Deviation of the Series')\nplt.legend()\nplt.show()","47a4d236":"#Define a function to use adfuller test\ndef adfuller(df_train):\n  #Importing adfuller using statsmodels\n  from statsmodels.tsa.stattools import adfuller\n  print('Dickey-Fuller Test: ')\n  adftest = adfuller(df_train['close'])\n  adfoutput = pd.Series(adftest[0:4], index=['Test Statistic','p-value','Lags Used','No. of Observations'])\n  for key,value in adftest[4].items():\n    adfoutput['Critical Value (%s)'%key] = value\n  print(adfoutput)\nadfuller(df_train)","e288b078":"# Visualize the rolling mean and standard deviation after using log transformation\nplt.figure(figsize=(16,8))\ndf_log = np.log(df_train)\nMAvg = df_log.rolling(window=12).mean()\nMStd = df_log.rolling(window=12).std()\nplt.plot(df_log)\nplt.plot(MAvg, color='r', label = 'Moving Average')\nplt.plot(MStd, color='g', label = 'Standard Deviation')\nplt.legend()\nplt.show()","8f8e5715":"plt.figure(figsize=(16,8))\ndf_shift = df_log - df_log.shift(periods = 1)\nMAvg_shift = df_shift.rolling(window=12).mean()\nMStd_shift = df_shift.rolling(window=12).std()\nplt.plot(df_shift, color='c')\nplt.plot(MAvg_shift, color='red', label = 'Moving Average')\nplt.plot(MStd_shift, color='green', label = 'Standard Deviation')\nplt.legend()\nplt.show()\n\n#Dropping the null values that we get after applying differencing method\ndf_shift = df_shift.dropna()","d15a8de5":"#____________________ # call the adfuller function for df_shift series\nadfuller(df_shift)","4ae40b3a":"#Importing the seasonal_decompose to decompose the time series\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndecomp = seasonal_decompose(df_train)\n\ntrend = decomp.trend\nseasonal = decomp.seasonal\nresidual = decomp.resid\n\nplt.figure(figsize=(15,10))\nplt.subplot(411)\nplt.plot(df_train, label='Actual', marker='.')\nplt.legend(loc='upper left')\nplt.subplot(412)\nplt.plot(trend, label='Trend', marker='.')\nplt.legend(loc='upper left')\nplt.subplot(413)\nplt.plot(seasonal, label='Seasonality', marker='.')\nplt.legend(loc='upper left')\nplt.subplot(414)\nplt.plot(residual, label='Residuals', marker='.')\nplt.legend(loc='upper left')\nplt.tight_layout()","7e34738f":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n\nplt.figure(figsize = (16,8))\nplot_acf(df_shift, lags = 12) \nplt.show() \nplot_pacf(df_shift, lags = 12) \nplt.show()","23dcc926":"#Importing AutoReg function to apply AR model\nfrom statsmodels.tsa.ar_model import AutoReg\n\nplt.figure(figsize=(16,8))\nmodel_AR = AutoReg(df_shift, lags=1) #Use number of lags as 1 and apply AutoReg function on df_shift series\nresults_AR = model_AR.fit() #fit the model\nplt.plot(df_shift)\npredict = results_AR.predict(start=0,end=len(df_shift)-1) #predict the series \npredict = predict.fillna(0) #Converting NaN values to 0\nplt.plot(predict, color='red')\nplt.title('AR Model - RMSE: %.4f'% mean_squared_error(predict,df_shift['close'], squared=False))  #Calculating rmse\nplt.show()","e5201907":"results_AR.aic","3227d662":"from statsmodels.tsa.arima_model import ARIMA\nplt.figure(figsize=(16,8))\nmodel_MA = ARIMA(df_shift, order=(0, 0, 1)) #Using p=0, d=0, q=1 and apply arima function on df_shift series\nresults_MA = model_MA.fit()\nplt.plot(df_shift)\nplt.plot(results_MA.fittedvalues, color='red')\nplt.title('MA Model - RMSE: %.4f'% mean_squared_error(results_MA.fittedvalues,df_shift['close'], squared=False))\nplt.show()","1fd6b1dc":"results_MA.aic","d5675535":"plt.figure(figsize=(16,8))\nmodel_ARMA = ARIMA(df_shift, order=(1, 0, 1)) #Using p=1, d=0, q=1 and apply ARIMA function on df_shift series\nresults_ARMA = model_ARMA.fit()\nplt.plot(df_shift)\nplt.plot(results_ARMA.fittedvalues, color='red')\nplt.title('ARMA Model - RMSE: %.4f'% mean_squared_error(results_ARMA.fittedvalues,df_shift['close'], squared=False))\nplt.show()","77a8e534":"results_ARMA.aic","e431490c":"from statsmodels.tsa.arima_model import ARIMA\n\nplt.figure(figsize=(16,8))\nmodel_ARIMA = ARIMA(df_log, order=(1,1,1))  #Using p=1, d=1, q=1 and apply ARIMA function on df_log series\nresults_ARIMA = model_ARIMA.fit()\nplt.plot(df_shift)\nplt.plot(results_ARIMA.fittedvalues, color='red')\nplt.title('ARIMA Model - RMSE: %.4f'% mean_squared_error(results_ARIMA.fittedvalues,df_shift['close'], squared=False))\nplt.show()","577fc61e":"results_ARIMA.aic","26226c9a":"# Printing the fitted values\npredictions=pd.Series(results_ARIMA.fittedvalues)\npredictions","d2c276cf":"#First step - doing cumulative sum\npredictions_cumsum = predictions.cumsum() # use .cumsum fuction on the predictions\npredictions_cumsum","f325527e":"#Second step - Adding the first value of the log series to the cumulative sum values\npredictions_log = pd.Series(df_log['close'].iloc[0], index=df_log.index)\npredictions_log = predictions_log.add(predictions_cumsum, fill_value=0)\npredictions_log","f737074e":"#Third step - applying exponential transformation\npredictions_ARIMA = np.exp(predictions_log) #use exponential function\npredictions_ARIMA","25598cc1":"#Plotting the original vs predicted series\nplt.figure(figsize=(16,8))\nplt.plot(df_train, color = 'c', label = 'Original Series')  #plot the original train series\nplt.plot(predictions_ARIMA, color = 'r', label = 'Predicted Series')  #plot the predictions ARIMA\nplt.title('Actual vs Predicted')\nplt.legend()\nplt.show()","1c6d310c":"#Forecasting the values for next 24 months\nforecasted_ARIMA = results_ARIMA.forecast(steps=24)  #forecast using the results_ARIMA for next 24 months. Keep steps=24\nforecasted_ARIMA[0]","9d049e2b":"# Creating a list containing all the forecasted values\nlist1 = forecasted_ARIMA[0].tolist()\nseries1 = pd.Series(list1)\nseries1","58daf92a":"#Making a new dataframe to get the additional dates from 2016-2018\nindex = pd.date_range('2016-01-1','2018-1-1' , freq='1M')- pd.offsets.MonthBegin(1)\ndf1 = pd.DataFrame()\ndf1['forecasted'] = series1\ndf1.index = index\ndf1","1622550a":"#Applying exponential transformation to the forecasted log values\nforecasted_ARIMA = np.exp(df1['forecasted']) #use exponential function on forecasted data\nforecasted_ARIMA","de8f8675":"#Plotting the original vs predicted series\nplt.figure(figsize=(16,8))\nplt.plot(df, color = 'c', label = 'Original Series')\nplt.plot(predictions_ARIMA, color = 'r', label = 'Prediction on Train data') #plot the predictions ARIMA series\nplt.plot(forecasted_ARIMA, label = 'Prediction on Test data', color='b')  #plot the forecasted ARIMA series\nplt.title('Actual vs Predicted')\nplt.legend()\nplt.show()","685d68d4":"from sklearn.metrics import mean_squared_error\nerror = mean_squared_error(predictions_ARIMA, df_train, squared = False) #calculate RMSE using the predictions_ARIMA and df_train \nerror","c7057550":"from sklearn.metrics import mean_squared_error\nerror = mean_squared_error(forecasted_ARIMA, df_test, squared = False)  #calculate RMSE using the forecasted_ARIMA and df_test\nerror","7246756d":"### Decomposing the time series components into Trend, Seasonality and Residual","47a7ac10":"### Making the series stationary","74b6f0e9":"### Plotting the auto-correlation function and partial auto-correlation function to get p and q values for AR, MA, ARMA, and ARIMA models","089bf613":"### Reading the dataset","30877877":"**Let's shift the series by order 1 (or by 1 month) & apply differencing (using lagged series)** \n\nand then check the rolling mean and standard deviation.","37525209":"### Forecasting the values for next 24 months and compare it with test data","14f03b9f":"###**Question 1: Check the info of the dataset and write your observations. (2 Marks)**","33447dc9":"### ARIMA Model","be822a00":"**Observations:**\n- From the above PACF plot we can see that **the highest lag** at which the plot extends beyond the statistically significant boundary is **lag 1.** \n- This indicates that an **AR Model of lag 1 (p=1)** should be sufficient to fit the data.\n- Similarly, from the ACF plot, we can infer that **q=1.**","d6dc0845":"### ARMA Model","ded1b819":"We will be using an **ARIMA model with p=1 and q=1** (as observed from the ACF and PACF plots) **and d=0 so that it will work as an ARMA model.**","1574536a":"Now, let's try to visualize the original data with the predicted values on the training data and the forecasted values.","ca68e108":"**Observations:**\n- We can see there is a upward trend in the series.\n- We can confirm that **the series is not stationary.**","8aaf6ddf":"We can use some of the following methods to convert a non-stationary series into a stationary one:\n1. **Log Transformation**\n2. **By differencing the series (lagged series)**\n\nLet's first use a log transformation over this series to remove exponential variance and check the stationarity of the series again.","07d1da8b":"### Checking info ","7d094f1d":"**Observations:_____________**\n- There are **two columns and 144 observations** in the data\n- The Timestamp column is of DateTime data type and closing price is of float data type. \n- There are **no missing values** in the dataset.","6373d6cd":"**To forecast the values for the next 24 months using the ARIMA model, we need to follow the steps below:**\n1. Forecast the log-transformed fitted values for the next 24 months\n2. Make a list of these 24 month (2016-2017) forecasted values\n3. Convert that list into a series so that we can work with pandas functions \n4. Make a dataframe where we have the dates starting from 2016-01-01 to 2017-12-01 as the index and the respective forecasted values\n5. Apply the inverse transformation and get the real forecasted values","4aad5578":"**Observations:**\n- We can see that there are significant **trend, seasonality and residuals components** in the series\n- The plot for seasonality shows that **Amazon's stock prices spike in August, September, and December.**\n\n**Now let's move on to the model building section. First, we will plot the `ACF` and `PACF` plots to get the values of p and q i.e. order of AR and MA models to be used.**","75624dfa":"**Observations:**\n1. From the above test, we can see that the **p-value = 1 i.e. > 0.05** (For 95% confidence intervals) therefore, **we fail to reject the null hypothesis.**\n2. Hence, **we can confirm that the series is non-stationary.**","16891d62":"- **As observed earlier, most of the predicted values on the training data are very close to the actual values** except for the dip in stock prices in the year 2015.\n- **On the test data, the model is able to correctly predict the trend of the stock prices**, as we can see that the blue line appears to be close to the actual values (cyan blue) and they both have an upward trend. **However the test predictions are not able to identify the volatile variations in the stock prices over the last 2 years.**\n\nLet's test the RMSE of the transformed predictions and the original value on the training and testing data to check whether the model is giving a generalized performance or not.","5a2b8bca":"**Observations:**\n- Since **we can still see the upward trend in the series**, we can conclude that **the series is still non-stationary.** \n- However, the standard deviation is almost constant which implies that **now the series has constant variance.**","8df9522c":"### MA Model","8105ad87":"We can also use the **Augmented Dickey-Fuller (ADF) Test** to verify if the series is stationary or not.\nThe null and alternate hypotheses for the ADF Test are defined as: \n- **Null hypothesis:** The Time Series is non-stationary\n- **Alternative hypothesis:** The Time Series is stationary","a76fc476":"### Importing libraries","0e600fab":"**Observations:**\n- We can see that **the p-value is now far lesser than 0.05** (for 95% confidence interval), **therefore we can reject the null hypothesis that the series is non-stationary.**\n- We can conclude that **the series is now stationary.**\n\nLet's decompose the time series to check its different components.","65475165":"*Fitting and predict the shifted series with the AR Model and calculate the RMSE. *","940a70a7":"- **The AIC value of the ARMA model is more or less similar** to that of MA model \n\n**Let us try using the ARIMA Model.**","2912dced":"- **The MA model is giving a much lower AIC** when compared to the AR model, implying that **the MA model fits the training data better.** ","c80bc480":"**Observations**\n- **The ARIMA model is giving the RMSE same as ARMA and MA models. So far AR model has the lowest RMSE.**\n\n**Let's check the AIC value** of the model","f5c4fdb2":"### Splitting the dataset","42a7ce05":"### Conclusion","56baf773":"We will be using an **ARIMA Model with p=1, d=1, & q=1**.","f84e8c79":"###**Question 5: Fit and predict the shifted series with the ARMA Model and calculate the RMSE. Also, visualize the time series and write your observations. (2 Marks)**","996d3dbd":"Now that we have fitted values using the ARIMA model, **we will use the inverse transformation to get back the original values.**","f702cf03":"### AR Model","c06dcd05":"**Observations:**\n- **The mean and the standard deviation seem to be constant over time.**\n\nLet us use the adfuller test to check the stationarity.","c14b7a83":"# **Project: Time Series - Forecasting Stock Prices**\n\n**Stocks are one of the most popular financial instruments invented for building wealth** and are the **centerpiece of any investment portfolio.** Recent advances in trading technology have opened up stock markets in such a way that nowadays, **nearly anybody can own stock.** \n\nIn the last few decades, there's been an **explosive increase in the average person's interest for the stock market.** This makes stock value prediction an interesting and popular problem to explore.\n\n\n------------------\n## **Objective:**\n------------------\n\nAmazon.com, Inc. engages in the retail sale of consumer products and subscriptions in North America as well as internationally. This dataset consists of monthly average stock closing prices of Amazon over a period of 12 years from 2006 to 2017. We have to **build a time series model** using the AR, MA, ARMA and ARIMA models in order to **predict the stock closing price of Amazon.**\n\n--------------------------\n## **Data Dictionary:**\n--------------------------\n- **date:** Date when the price was collected\n- **close:** Closing price of the stock","3a0f54e7":"**Observations:**\n- We can see that **the predicted series is very similar to the original series** i.e. The model is good at predicting values on the training data except for the dip in stock prices in 2015 which may have been due to some external factors that are not included in this model. \n- Let us **forecast the closing prices for the next 24 months.**","0b931dec":"Now let us check the **rolling mean and standard deviation** of the series to **visualize if the series has any trend or seasonality.**","0892c260":"### Fitting and predict the shifted series with the ARIMA Model and calculate the RMSE. ","4c7394cb":"Now, let's build MA, ARMA, and ARIMA models as well and see if we can get a better model ","f5f00db6":"**Observations:**\n- We can see that the series has an **upward trend with some seasonality.** This implies that the **average stock price of Amazon has been increasing almost every year.**\n- Before building different models, it is important to **check whether the series is stationary or not.**\n\nLet us first split the dataset into train and test data","0631d7e0":"### Fitting and predict the shifted series with the MA Model and calculate the RMSE.","5c812afa":"**We will be using an ARIMA model with p=0 and d=0 so that it will work as an MA model**","6493ec0f":"- **The AIC value of the ARIMA model is the same** as the ARMA model. \n\nWe can see that **all the models return almost the same RMSE.** There is not much difference in AIC value as well across all the models except for the AR model.\n\n**We can choose to predict the values using ARIMA as it takes into account more factors than AR, MA, ARMA models.**","cd781646":"Now, let's **visualize the time series** to get an idea how about the trend and\/or seasonality within the data.","76fed182":"### Visualizing the rolling mean and rolling standard deviation of the shifted series (df_shift) and checking the stationarity by calling the adfuller() function.","f0f06ba0":"**Observations:**\n- **The ARMA model is giving the RMSE as MA model. So far AR model has the lowest RMSE.**\n\n**Let's check the AIC value** of the model","f884b41a":"### Inverse Transformation","25dcdd99":"###**Question 8: Forecast the stocks prices for the next 24 months and perform the inverse transformation. (5 Marks)**","04600ed3":"-We have choosen ARIMA model to predict the values mainly considering it's lower AIC value and also due to the fact that ARIMA takes into account more factors than AR, MA, ARMA models.**\n- **The RMSE is higher on the testing data** in comparison to the training data which makes sense according to our pbservations.\n- **The model is able to correctly predict the trend of the stock prices in test data** but the test predictions are not able to identify the volatile variations in the stock prices over the last 2 years. This might be because there have been many fluctuations in the Bitcoin prices over the last 24 months.\n- Overall the model prdictions are good but it still **might not be complex enough to capture the fluctuations - Dips.** We can further try to build more complex time series models like SARIMA, SARIMAX, etc. while considering more factors like trend, seasonality, etc. and check if we can get a more generalized model.","c36a2f1d":"**Observations:**\n- **The MA model is giving a slightly higher(by 0.0002) RMSE** when compared to the AR model.\n\nLet's check the AIC value of the model","ed4702c5":"**Observations:**\n- We can see that **by using the AR model, we get root mean squared error (RMSE) = 0.0900**\n\n**Let's check the AIC value** of the model","31b71c3e":"### Testing the stationarity of the series"}}