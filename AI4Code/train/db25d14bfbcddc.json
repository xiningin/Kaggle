{"cell_type":{"7571fcaa":"code","b534b287":"code","a250049d":"code","e209732e":"code","061ad327":"code","566cf68e":"code","1ef9802f":"code","f0507553":"code","0ec0741e":"code","af7bd8f8":"code","5b777ea5":"code","b3f09fd8":"code","c2f0b91d":"code","70477c5f":"markdown"},"source":{"7571fcaa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b534b287":"#Importing the datasets\ndf_train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/test.csv')\ndf_sub = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/test.csv')","a250049d":"df_train.info()","e209732e":"df_test.info()","061ad327":"df_sub.info()","566cf68e":"df_train.shape, df_test.shape, df_sub.shape","1ef9802f":"df_train.head()","f0507553":"import datetime\ndf_train['Date'] = pd.to_datetime(df_train['Date'], infer_datetime_format=True)\ndf_test['Date'] = pd.to_datetime(df_test['Date'], infer_datetime_format=True)\ndf_train.loc[:, 'Date'] = df_train.Date.dt.strftime(\"%m%d\")\ndf_train[\"Date\"]  = df_train[\"Date\"].astype(int)\ndf_test.loc[:, 'Date'] = df_test.Date.dt.strftime(\"%m%d\")\ndf_test[\"Date\"]  = df_test[\"Date\"].astype(int)","0ec0741e":"df_train['ConfirmedCases'] = df_train['ConfirmedCases'].apply(int)\ndf_train['Fatalities'] = df_train['Fatalities'].apply(int)","af7bd8f8":"df_train['Province_State'] = df_train['Province_State'].fillna('unknown')\ndf_test['Province_State'] = df_test['Province_State'].fillna('unknown')","5b777ea5":"import xgboost as xgb\nfrom xgboost import XGBRegressor","b3f09fd8":"features = ['Date']\nsubmission = pd.DataFrame(columns=['ForecastId', 'ConfirmedCases', 'Fatalities'])\n\nfrom tqdm import tqdm\nfor i in tqdm(df_train.Country_Region.unique()):\n    c_train = df_train[df_train['Country_Region'] == i]\n    c_test = df_test[df_test['Country_Region'] == i]\n    for j in c_train.Province_State.unique():\n        p_train = c_train[c_train['Province_State'] == j]\n        p_test = c_test[c_test['Province_State'] == j]\n        x_train = p_train[features]\n        y_train_cc = p_train['ConfirmedCases']\n        y_train_ft = p_train['Fatalities']\n        model = xgb.XGBRegressor(n_estimators=1000)\n        model.fit(x_train, y_train_cc)\n        #Confirmed Cases Prediction\n        y_pred_cc = model.predict(p_test[features])\n        model.fit(x_train, y_train_ft)\n        #Fatalities Prediction\n        y_pred_ft = model.predict(p_test[features])\n        \n        p_test['ConfirmedCases'] = y_pred_cc\n        p_test['Fatalities'] = y_pred_ft\n        submission = pd.concat([submission, p_test[['ForecastId', 'ConfirmedCases', 'Fatalities']]], axis=0)","c2f0b91d":"submission.to_csv('submission.csv', index=False)","70477c5f":"Now lets preprosses the data"}}