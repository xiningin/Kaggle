{"cell_type":{"03e73879":"code","f4cef5ff":"code","e6d1b214":"code","6ac9664a":"code","00f092d5":"code","e42cc0bc":"code","6bac593f":"code","42b765b5":"code","34ebc58b":"code","698edb5b":"code","481967c9":"code","f0da8c98":"code","202adaac":"code","d9098ac5":"code","0912f3c4":"code","1beee376":"code","4296e3f3":"code","b5eb64fc":"code","5a2b0f65":"code","2ee62956":"code","9ed59d35":"code","663dc17d":"code","f12451b6":"code","f0528303":"code","45f18217":"code","3a96d219":"code","2e3799d4":"code","bcbcf1ab":"code","82711aba":"code","b3b7ee25":"code","09943282":"code","82a1094f":"code","7480fd6c":"code","7d92f583":"code","dfd40f8e":"code","2e478be7":"code","51d1c925":"code","24243145":"code","7eb4d2fe":"code","3003b838":"code","b96a4238":"code","ca4b9473":"code","e5d6ebe9":"code","a543d76f":"code","4775c04a":"code","da8db275":"code","d24bd181":"code","fee448f3":"markdown","b837d0d9":"markdown","5ac1260b":"markdown","ef1c903c":"markdown","8f08654b":"markdown","664c381a":"markdown","b36b3961":"markdown","275c1280":"markdown","fb4d51ec":"markdown","987468fa":"markdown","89a4acd7":"markdown","c4853b56":"markdown","2faf5aed":"markdown","09f273a5":"markdown","902f6714":"markdown","abb0ccce":"markdown","736a3fee":"markdown","ec67d014":"markdown","2c3d6a5b":"markdown","8defd79a":"markdown","1d3fe144":"markdown","aca8fd86":"markdown","7ea736ba":"markdown","c44635fa":"markdown","fb43e4c6":"markdown","dda1a2a6":"markdown"},"source":{"03e73879":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4cef5ff":"import glob\nimport sys\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom tqdm.notebook import tqdm_notebook as tq\nimport warnings\nimport plotly as py\nimport statistics as stat\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport geopandas","e6d1b214":"eng = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'\neng_files = glob.glob(eng + \"\/*.csv\")\n\nfiles = []\n\nfor f in eng_files:\n    df = pd.read_csv(f, index_col = None, header = 0)\n    district_id = f.split('\/')[4].split('.')[0]\n    df['district_id'] = district_id\n    files.append(df)\n    \nengagement = pd.concat(files)\nengagement = engagement.reset_index(drop = True)\nengagement['time'] = pd.to_datetime(engagement['time'])","6ac9664a":"district = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\nproduct = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')","00f092d5":"#percentage of null or missing values in the dataset\ndef pcrt_null_values(data):\n    sum_of_null = data.isnull().sum()\n    percentage = (sum_of_null\/len(data))*100\n    val_data = pd.DataFrame(data = [sum_of_null, percentage])\n    val_data = val_data.T\n    val_data.columns = [\"Total Missing\", \"Percentage Missing\"]\n    return val_data","e42cc0bc":"#counting duplicates in the dataset\ndef dup_count(data):\n    dc = data.duplicated().sum()\n    return dc","6bac593f":"#delete rows in the district data that are all null values\n#and maintain a new data without nullvalues rows\ndef drop_district_null_rows(data):\n    m = district.drop(columns = 'district_id')\n    n = m.dropna(axis = 0, how = 'all')\n    n['district_id'] = district['district_id']\n    new = n.reindex(columns = ['district_id', 'state', 'locale', 'pct_black\/hispanic',\n                               'pct_free\/reduced', 'county_connections_ratio', 'pp_total_raw'])\n    return new","42b765b5":"new_district = drop_district_null_rows(district)\nnew_district.head(0)","34ebc58b":"#imputing missing values\nfrom sklearn.impute import SimpleImputer\nimpute = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\nnew_district1 = impute.fit_transform(new_district)\nnew_district_1 = pd.DataFrame(new_district1, columns=['district_id', 'state', 'locale', 'pct_black\/hispanic',\n                                         'pct_free\/reduced', 'county_connections_ratio', 'pp_total_raw'])\n","698edb5b":"#Information about pct_black\/hispanic, pct_free\/reduced, county_connections_ratio and pp_total_raw is \n#presented in the form of intervals, where \"[a, b[\" means that a \u2264 x < b. \nnew_district_1['pp_total_raw'] = new_district_1['pp_total_raw'].apply(lambda x: int(x.split(',')[0][1:]) + 1000)\nfor i in ['pct_black\/hispanic', 'pct_free\/reduced']:\n    new_district_1[i] = new_district_1[i].apply(lambda x: float(x.split(',')[0][1:]) + 0.1)\nnew_district_1.drop('county_connections_ratio', axis = 1, inplace = True)","481967c9":"\n#######\n##State Abbreviation in Usa\nstates = {'Alabama' : 'AL','Alaska' : 'AK','Arizona' : 'AZ','Arkansas' : 'AR','California' : 'CA','Colorado': 'CO',\n         'Connecticut' : 'CT', 'District of Columbia' : 'DC', 'Delaware' : 'DE','Florida' : 'FL','Georgia' : 'GA',\n         'Hawaii' : 'HI','Idaho' : 'ID', 'Illinois' : 'IL','Indiana' : 'IN','Iowa' : 'IA','Kansas' : 'KS',\n         'Kentucky' : 'KY','Louisiana' : 'LA','Maine' : 'ME','Maryland' : 'MD','Massachusetts' : 'MA',\n         'Michigan' : 'MI','Minnesota' : 'MN','Mississipi' : 'MS','Missouri' : 'MO','Montana' : 'MT','Nebraska' : 'NE',\n         'Nevada' : 'NV','New Hampshire' : 'NH','New Jersey' : 'NJ','New Mexico' : 'NM','New York' : 'NY',\n         'North Carolina' : 'NC','North Dakota' : 'ND','Ohio' : 'OH','Oklahoma' : 'OK','Oregon' : 'OR','Pennsylvania' : 'PA',\n         'Rhode Island' : 'RI','South Carolina' : 'SC','South Dakota' : 'SD','Tennessee' : 'TN','Texas' : 'TX' ,'Utah' : 'UT',\n         'Vermont' : 'VT','Virginia' : 'VA','Washington' : 'WA','West Virginia' : 'WV', 'Wisconsin' : 'WI', 'Wyoming' : 'WY',}\n###Geo-Map\ndef district_geomap(title):\n    new_district_1['states'] = new_district_1['state'].map(states)\n    fig = go.Figure()\n    layout = dict(title_text = title,\n                  title_font = dict(family = \"monospace\", size = 25, color = \"black\"), geo_scope = 'usa')\n    fig.add_trace(go.Choropleth(locations = new_district_1['states'].value_counts().to_frame().reset_index()['index'],\n                                zmax = 1, z = new_district_1['states'].value_counts().to_frame().reset_index()['states'],\n                                locationmode = 'USA-states', marker_line_color = 'white', geo = 'geo', colorscale = \"RdYlBu\"))          \n    fig.update_layout(layout)   \n    fig.show()\n    \n    \n    plt.figure(figsize = (15, 8))\n    sns.set_style(\"white\")\n    a = sns.barplot(data = new_district_1['state'].value_counts().reset_index(), x = 'state', y = 'index', color = '#90afc5')\n    plt.xticks([])\n    plt.yticks(fontname = 'monospace', fontsize = 14, color = '#283655')\n    plt.ylabel('')\n    plt.xlabel('')\n\n    a.spines['left'].set_linewidth(1.5)\n    for w in ['right', 'top', 'bottom']:\n        a.spines[w].set_visible(False)\n    \n    for p in a.patches:\n        width = p.get_width()\n        plt.text(0.5 + width, p.get_y() + 0.55 * p.get_height(), f'{int(width)}',\n             ha = 'center', va = 'center', fontname = 'monospace', fontsize = 15, color = '#283655')\n\n    plt.show()","f0da8c98":"district_geomap('Number of School Districts in each State')","202adaac":"#this gives the number of counts of locale in each state\ndef district_count_plot(y, palette, title, hue = None, data = None):\n    sns.set_theme(style = 'darkgrid')\n    plt.figure(figsize = (15, 22))\n    plt.xticks(rotation = 90)\n    plt.title(title)\n    b = sns.countplot(y = y, hue = hue, palette = palette, data = data)\n    b.spines['left'].set_linewidth(2)\n    for c in ['right', 'top', 'bottom']:\n        b.spines[c].set_visible(True)\n    for p in b.patches:\n        width = p.get_width()\n        plt.text(0.5 + width, p.get_y() + 0.55 * p.get_height(), f'{str(width)}',\n                 ha = 'center', va = 'center', fontname = 'monospace', fontsize = 10, color = '#283655')","d9098ac5":"district_count_plot('state', 'CMRmap', 'Counts of locale in each State Presented', 'locale', new_district_1)","0912f3c4":"###Pie Graph\nfor i in ['state', 'locale', 'Basic_category','Provider\/Company Name', 'Primary Essential Function', 'Sector(s)']:\n    def pie_graph(data, i, title):\n        fig = px.pie(data[i].value_counts().reset_index().rename(columns = {'i': 'count'}), values = i, names = 'index',\n                     width = 800, height = 800)\n        fig.update_traces(textposition = 'inside', textinfo = 'percent + label', hole = 0.65, \n                           marker = dict(colors = ['#90afc5','#336b87','#2a3132','#763626'], \n                                         line = dict(color = 'white', width = 2)))\n        fig.update_layout(annotations = [dict(text = title, x = 0.5, y = 0.5, font_size = 25, \n                                              showarrow = False, font_family = 'monospace',\n                                              font_color = '#283655')],showlegend = False)\n                  \n        fig.show()","1beee376":"pie_graph(new_district_1, 'state', 'Percentage of School<br> District in Each State')","4296e3f3":"pie_graph(new_district_1, 'locale', 'Percentage of School <br> District in Each Locale')","b5eb64fc":"colors = [\"#90afc5\", \"#336b87\", \"#763626\"]\n\nfig = plt.figure(figsize = (15, 11))\nsns.set_style(\"white\")\nplt.title('Percentage of Black\/Hispanic', size = 20, fontname = \"monospace\", color = \"#763626\")\na = sns.kdeplot(new_district_1['pct_black\/hispanic'], color = \"#763626\",\n                shade = True, alpha = 0.9, linewidth = 1.5, edgecolor = \"black\")\nplt.ylabel(\"\")\nplt.xlabel(\"\")\nplt.xticks(fontname = \"monospace\")\nplt.yticks([])\nfor j in [\"right\", \"left\", \"top\"]:\n    a.spines[j].set_visible(True)\n    a.spines[\"bottom\"].set_linewidth(1.5)\nfig.tight_layout(h_pad = 3)\nplt.figtext(0.07, 1.05, \"Distribution of Charateristics of School Districts\",\n            fontsize = 30, fontname = \"monospace\", color = \"#283655\") \nplt.figtext(0.70, 0.47, \"Conclusion\", fontsize = 30, fontname = \"monospace\",\n               color = \"#283655\")\nplt.figtext(0.54, 0.40, \"\"\"The average number of students who identified themselves\nas black or Hispanic is 24%. The most common value is 10%.\"\"\", fontsize = 13)\n   \nplt.show()","5a2b0f65":"colors = [\"#90afc5\", \"#336b87\", \"#763626\"]\n\nfig = plt.figure(figsize = (11, 11))\nsns.set_style(\"white\")\nplt.title('Percentage of Students Eligible for Free or Reduced', size = 20, fontname = \"monospace\", color = \"#90afc5\")\na = sns.kdeplot(new_district_1['pct_free\/reduced'], color = \"red\",\n                shade = True, alpha = 0.9, linewidth = 2, edgecolor = \"blue\")\nplt.ylabel(\"\")\nplt.xlabel(\"\")\nplt.xticks(fontname = \"monospace\")\nplt.yticks([])\nfor j in [\"right\", \"left\", \"top\"]:\n    a.spines[j].set_visible(True)\n    a.spines[\"bottom\"].set_linewidth(1.5)\nfig.tight_layout(h_pad = 1)\nplt.figtext(0.07, 1.05, \"Distribution of Charateristics of School Districts\",\n            fontsize = 30, fontname = \"monospace\", color = \"#283655\") \nplt.figtext(0.70, 0.47, \"Conclusion\", fontsize = 30, fontname = \"monospace\",\n               color = \"#283655\")\nplt.figtext(0.64, 0.40, \"\"\"The average number of students eligible\nfor free or reduced - price lunch is 33.3%. \nThe most value is 30%.\"\"\", fontsize = 13)\n\nplt.show()","2ee62956":"colors = [\"#90afc5\", \"#336b87\", \"#763626\"]\n\nfig = plt.figure(figsize = (11, 11))\nsns.set_style(\"white\")\nplt.title('Local and Federal Expenditure', size = 20, fontname = \"monospace\", color = \"#336b87\")\na = sns.kdeplot(new_district_1['pp_total_raw'], color = \"blue\",\n                shade = True, alpha = 0.9, linewidth = 2, edgecolor = \"red\")\nplt.ylabel(\"\")\nplt.xlabel(\"\")\nplt.xticks(fontname = \"monospace\")\nplt.yticks([])\nfor j in [\"right\", \"left\", \"top\"]:\n    a.spines[j].set_visible(True)\n    a.spines[\"bottom\"].set_linewidth(1.5)\nfig.tight_layout(h_pad = 1)\nplt.figtext(0.07, 1.05, \"Distribution of Charateristics of School Districts\",\n            fontsize = 30, fontname = \"monospace\", color = \"#283655\") \nplt.figtext(0.70, 0.47, \"Conclusion\", fontsize = 30, fontname = \"monospace\",\n               color = \"#283655\")\nplt.figtext(0.92, 0.40, \"\"\"Per-pupil total expenditure\n (sum of local and federal expenditure) is $11,329.55 \n and the most common value is $9,000.\"\"\", fontsize = 13, fontname = \"monospace\", color = \"#283655\", ha = \"right\") \n\n\nplt.show()","9ed59d35":"dist_area_group = new_district_1.groupby(\"locale\").agg({\"pct_black\/hispanic\":\"mean\",\"pct_free\/reduced\":\"mean\", \"pp_total_raw\":\"mean\"}).reset_index()\n\ncolors = [\"#90afc5\", \"#336b87\", \"#763626\"]\n\nfig = plt.figure(figsize = (13, 12))\nfor i in range(len(dist_area_group.columns.tolist()[1:])):\n    plt.subplot(2, 2, i+1)\n    sns.set_style(\"white\")\n    plt.title(dist_area_group.columns.tolist()[1:][i], size = 20, fontname = \"monospace\",\n             y = 1.09, color = colors[i])\n    plt.grid(color = \"gray\", linestyle = \":\", axis = \"y\", zorder = 0, dashes = (1, 7))\n    a = sns.barplot(data = dist_area_group, x = \"locale\", y = dist_area_group.columns.tolist()[1:][i],\n                   color = colors[i])\n    plt.xlabel(\"\")\n    plt.ylabel(\"\")\n    plt.xticks(fontname = \"monospace\", size = 14)\n    plt.yticks([])\n    \n    for j in [\"right\", \"top\", \"left\"]:\n        a.spines[j].set_visible(False)\n    for j in [\"bottom\"]:\n        a.spines[j].set_linewidth(1.4)\n    \n    if i < 3:\n        for p in a.patches:\n            height = p.get_height()\n            a.annotate(f'{int(height*100)}%', (p.get_x() + p.get_width()\/2, p.get_height()- 0.03),\n                      ha = \"center\", va = \"center\", size = 18, xytext = (2, 5),\n                      textcoords = \"offset points\", color = \"white\", fontname = \"monospace\")\n        else:\n            for p in a.patches:\n                height = p.get_height()\n                a.annotate(f'{int(height)}$', (p.get_x() + p.get_width()\/2, p.get_height() - 1000),\n                          ha = \"center\", va = \"center\", size = 18, xytext = (0, 5), textcoords = \"offset points\",\n                          color = \"white\", fontname = \"monospace\")\n\nplt.figtext(0.07, 1.05, \"Characteristics of School Districts by locale\", fontsize = 22, fontname = \"monospace\", color = \"#283655\")\nplt.figtext(0.83, 0.34, \"Conclusion\", fontsize = 22, fontname = \"monospace\", color = \"#283655\")\nplt.figtext(0.99, 0.15, \"\"\"The largest count of students who identified themselves as\nBlack or Hispanic are in large cities. \nThe smallest count is in the suburbs and the rural areas.\n\nIn cities and towns half of the students are eligible\nfor free or reduced-priced lunch.\n\nThe Highest total expenses per student is in the rural area.\"\"\", fontsize = 11, fontname = \"monospace\", color = \"#283655\", ha = \"right\")\n\nfig.tight_layout(pad = 2)\n\nplt.show()","663dc17d":"product['Basic_category'] = 'x'\nfor i in range(len(product)):\n    if pd.isna(product['Primary Essential Function'][i]) == False:\n        product['Basic_category'][i] = product['Primary Essential Function'][i].split('-')[0][:-1]","f12451b6":"#delete rows in the product data that has any null values\ndef drop_product_null_rows():\n    s = product.dropna(axis = 0, how = 'any')\n    return s ","f0528303":"new_product = drop_product_null_rows()","45f18217":"#presenting the top 10  on a bar chart and pie chart\n\nplt.figure(figsize = (15, 8))\nsns.set_style(\"white\")\n\nplt.title(\"TOP - 10 learning providers\", size = 35, x = 0.4, y = 1.06, fontname = 'monospace', color = '#283655')\nr = sns.barplot(data = new_product['Provider\/Company Name'].value_counts().reset_index().head(10), \n                x = 'Provider\/Company Name', y = 'index', color = '#90afc5')\nplt.xticks([])\nplt.yticks(fontname = 'monospace', fontsize = 14, color = '#283655')\nplt.xlabel(\"\")\nplt.ylabel(\"\")\n\nr.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'bottom', 'top']:\n    r.spines[w].set_visible(False)\n\nfor p in r.patches:\n    width = p.get_width()\n    plt.text(0.5 + width, p.get_y() + 0.55 * p.get_height(), f'{int(width)}',\n            ha = \"center\", va = \"center\", fontname = 'monospace', fontsize = 15,\n            color = \"#283655\")\n    \nfig = px.pie(product['Sector(s)'].value_counts().reset_index().rename(columns = {'Sectors(s)': 'count'}).head(15),\n             values = 'Sector(s)', names = 'index', width = 700, height = 700)\n\nfig.update_traces(textposition = 'inside', textinfo = 'percent + value + label', hole = 0.7, marker = dict(colors = ['#90afc5', '#336b87', '#2a3132','#763626', 'a43820'],\n                                                                                                  line = dict(color = 'white', width = 2)))\nfig.update_layout(annotations = [dict(text = 'Sector of education <br> where the product is used', x = 0.5, y = 0.5, font_size = 26, showarrow = False,\n                                     font_family = 'monospace', font_color = '#283655')], showlegend = False)\n\nfig.show()\n","3a96d219":"fig = px.pie(new_product['Basic_category'].value_counts().reset_index().rename(columns = {'Basic_category' : 'count'}),\n             values = 'count', names = 'index', width = 600, height = 600)\n\nfig.update_traces(textposition = 'inside', textinfo = 'value + percent + label', hole = 0.7, marker = dict(colors = ['#90afc5', '#336b87', '#2a3132','#763626', 'a43820'],\n                                                                                                  line = dict(color = 'white', width = 2)))\nfig.update_layout(annotations = [dict(text = 'Count of Products <br> by category', x = 0.5, y = 0.5, font_size = 26, showarrow = False,\n                                     font_family = 'monospace', font_color = '#283655')], showlegend = False)\n\nfig.show()","2e3799d4":"plt.figure(figsize = (12, 20))\nsns.set_style(\"white\")\nplt.title('Count of products by subcategory', size = 35, x = 0.2, y = 1.06, fontname = 'monosapce', color = \"#283655\")\na = sns.barplot(data = new_product[\"Primary Essential Function\"].value_counts().reset_index(), x = 'Primary Essential Function',\n               y = 'index', color = \"#90afc5\")\nplt.xticks([])\nplt.yticks(fontname = 'monospace', fontsize = 10, color = '#283655')\nplt.xlabel(\"\")\nplt.ylabel(\"\")\n\na.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'top', 'bottom']:\n    a.spines[w].set_visible(False)\n\nfor p in a.patches:\n    width = p.get_width()\n    plt.text(1 + width, p.get_y() + 0.55 * p.get_height(), f'{int(width)}', ha = 'center', va = 'center', fontname = 'monospace',\n            fontsize = 11, color = '#283655')\nplt.show()\n\n###########################","bcbcf1ab":"#check if there are rows with complete null values\ndef drop_eng_null_rows():   \n    p = engagement.drop(columns = ['district_id', 'time'])\n    q = p.dropna(axis = 0, how = 'all')\n    if len(q) == len(p):\n        q['district_id'] = engagement['district_id']\n        q['time'] = engagement['time']\n        new = q.reindex(columns = ['time', 'district_id','lp_id', 'pct_access', 'engagement_index'])\n        print(\"There is no Null Values in rows \\n\" 'count of null values in each column \\n')\n    print(engagement.isnull().sum())","82711aba":"#dropping all null values in the dataset\n#delete rows in the product data that has any null values\ndef drop_eng_null_rows():\n    x = engagement.dropna(axis = 0, how = 'any')\n    return x ","b3b7ee25":"new_eng = drop_eng_null_rows()","09943282":"#merging new_product and engagement data\nmerged_data_1 = pd.merge(new_product, new_eng, left_on = 'LP ID', right_on = 'lp_id')\nmerged_data_1['district_id'] = merged_data_1['district_id'].astype('int64')\nmerged_data = merged_data_1.drop('lp_id', axis = 1)","82a1094f":"#merging merged_data and new_district_1 data\nmerged_data_1 = pd.merge(merged_data, new_district_1, on = 'district_id')\nmerged_data_1.drop(['URL', 'states'], axis = 1, inplace = True)","7480fd6c":"state_access = merged_data_1.groupby(['state', 'time']).agg({'pct_access': 'mean'}).reset_index()\nstate_eng = merged_data_1.groupby(['state', 'time']).agg({'engagement_index': 'mean'}).reset_index()\nlocale_access = merged_data_1.groupby(['locale', 'time']).agg({'pct_access': 'mean'}).reset_index()\nlocale_eng = merged_data_1.groupby(['locale', 'time']).agg({'engagement_index': 'mean'}).reset_index()\ncat_access = merged_data_1.groupby(['Basic_category', 'time']).agg({'pct_access': 'mean'}).reset_index()\ncat_eng = merged_data_1.groupby(['Basic_category', 'time']).agg({'engagement_index': 'mean'}).reset_index()\n\nfor i in [state_access, state_eng, locale_access, locale_eng, cat_access, cat_eng]:\n    i['day_of_week'] = i['time'].dt.dayofweek","7d92f583":"#state_access.query(\"time >= '2020-04-27' & time<= '2020-06-01' & state == 'Minnesota'\").mean()","dfd40f8e":"fig = px.line(state_eng, x = 'time', y = 'engagement_index', color = 'state', line_group = 'state')\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of engagement_index of all products by states',\n                 title_font_family = 'monospace', title_font_color = '#221f1f', title_font_size = 12)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12)\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                linewidth = 1.5, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12)\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color = 'red')\nfig.add_annotation(x = '2020-03-11', y = 2500, text = 'WHO has declared Covid-19 a pandemic', showarrow = True,\n                  font = dict(family = 'monospace', size = 11, color = 'black'), arrowhead = 2, arrowsize = 1,\n                  arrowwidth = 2, arrowcolor = '#636363', ax = 130, ay = 1)\nfig.add_vrect(x0 = \"2020-06-01\", x1 = \"2020-08-31\", fillcolor = \"yellow\", opacity = 0.25, line_width = 0)\nfig.add_annotation(x = \"2020-07-15\", y = 2000, text = \"Summer holidays\", showarrow = False,\n                   font = dict(family ='monospace', size = 11, color = 'black'))\nfig.update_traces(line_width = 2)\nfig.show()","2e478be7":"fig = px.line(state_access, x = 'time', y = 'pct_access', color = 'state', line_group = 'state')\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of pct_access of all products by states',\n                 title_font_family = 'monospace', title_font_color = '#221f1f', title_font_size = 12)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12)\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12)\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color = 'red')\nfig.add_annotation(x = '2020-03-11', y = 7.5, text = 'WHO has declared Covid-19 a pandemic', showarrow = True,\n                  font = dict(family = 'monospace', size = 11, color = 'black'), arrowhead = 2, arrowsize = 1,\n                  arrowwidth = 2, arrowcolor = '#636363', ax = 130, ay = 1)\nfig.add_vrect(x0 = \"2020-06-01\", x1 = \"2020-08-31\", fillcolor = \"yellow\", opacity = 0.25, line_width = 0)\nfig.add_annotation(x = \"2020-07-15\", y = 6, text = \"Summer holidays\", showarrow = False,\n                   font = dict(family ='monospace', size = 11, color = 'black'))\nfig.update_traces(line_width = 1)\nfig.show()","51d1c925":"months_map = {1:\"January\", 2:\"February\", 3:\"March\", 4:\"April\",\n             5:\"May\", 6:\"June\", 7:\"July\", 8:\"August\",\n             9:\"September\", 10:\"October\", 11:\"November\", 12:\"December\"}\nfor i in [state_access, state_eng]:\n    i[\"states\"] = i[\"state\"].map(states)\n    i[\"month\"] = i.time.dt.month.map(months_map)\n    \n    fig = px.choropleth(data_frame = i.groupby(['state', 'states', 'month']).agg({i.columns[2]:'mean'}).reset_index(),\n                       locations = \"states\", locationmode = 'USA-states',\n                       color = i.groupby(['state','states', 'month']).agg({i.columns[2]:'mean'}).reset_index()[i.groupby(['state', 'states', 'month']).agg({i.columns[2]:'mean'}).reset_index().columns[3]],\n                       scope = 'usa', color_continuous_scale = \"cividis\", animation_frame = 'month', hover_name = \"state\")\n    fig.update_layout(title_text = f'Monthly Dynamics of {i.columns[2]}', title_font = dict(family = \"monospace\", size = 25, color = 'black'))\n    fig.show()\n    # Changes in the average student activity indicators on school days 1 and 2 weeks after the announcement of the pandemic in every state.\n    #there are no information about Texas during the start of the pandemic, hence, the state does not participate in the analysis","24243145":"cov_imp = pd.DataFrame(state_access[\"state\"].unique().tolist()).rename(columns = {0:'state'})\n# There is no information about North Dakota during the start of the pandemic\n# There is no information about Texas during the start and in most period of the pandemic\ncov_imp = cov_imp.query(\"state != 'North Dakota' & state != 'Texas'\").reset_index()\ncov_imp.drop('index', axis = 1, inplace = True)\n\nfor i in [\"mean_access\", 'w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access',\n          'w10_access','w11_access','w12_access','mean_eng', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng', 'w6_eng', 'w7_eng', 'w8_eng',\n          'w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']:\n    cov_imp[i] = 0.0\nstatesss = cov_imp['state'].unique().tolist()\nfor i in statesss:\n    cov_imp[\"mean_access\"][statesss.index(i)] = round(state_access.query(\"time >= '2020-03-09' & time <= '2020-03-13' & state == @i\")['pct_access'].mean(), 2)\n    cov_imp[\"w1_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-03-16' & time <= '2020-03-20' & state == @i\")['pct_access'].mean()\n                                                            \/cov_imp['mean_access'][statesss.index(i)] - 1)*100, 1)\n    cov_imp[\"w2_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-03-23' & time <= '2020-03-27' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-03-16' & time<= '2020-03-20' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w3_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-03-30' & time <= '2020-04-03' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-03-23' & time<= '2020-03-27' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w4_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-04-06' & time <= '2020-04-10' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-03-30' & time<= '2020-04-03' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w5_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-04-13' & time <= '2020-04-17' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-04-06' & time<= '2020-04-10' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w6_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-04-20' & time <= '2020-04-24' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-04-13' & time<= '2020-04-17' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w7_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-04-27' & time <= '2020-05-01' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-04-20' & time<= '2020-04-24' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w8_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-05-04' & time <= '2020-05-08' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-04-27' & time<= '2020-05-01' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w9_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-05-11' & time <= '2020-05-15' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-05-04' & time<= '2020-05-08' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w10_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-05-18' & time <= '2020-05-22' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-05-11' & time<= '2020-05-15' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w11_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-05-25' & time <= '2020-05-29' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-05-18' & time<= '2020-05-22' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp[\"w12_access\"][statesss.index(i)] = round((state_access.query(\"time >= '2020-06-01' & time <= '2020-06-05' & state == @i\")['pct_access'].mean()\n                                                             \/state_access.query(\"time>= '2020-05-25' & time<= '2020-05-29' & state == @i\")['pct_access'].mean() - 1)*100, 1)\n    \n    cov_imp[\"mean_eng\"][statesss.index(i)] = round(state_eng.query(\"time >= '2020-03-09' & time <= '2020-03-13' & state == @i\")['engagement_index'].mean(), 1)\n    cov_imp[\"w1_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-03-16' & time <= '2020-03-20' & state == @i\")['engagement_index'].mean()\n                                                            \/cov_imp['mean_eng'][statesss.index(i)] - 1)*100, 1)\n    cov_imp[\"w1_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-03-23' & time <= '2020-03-27' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-03-16' & time<= '2020-03-20' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w3_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-03-30' & time <= '2020-04-03' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-03-23' & time<= '2020-03-27' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w4_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-04-06' & time <= '2020-04-10' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-03-30' & time<= '2020-04-03' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w5_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-04-13' & time <= '2020-04-17' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-04-06' & time<= '2020-04-10' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w6_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-04-20' & time <= '2020-04-24' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-04-13' & time<= '2020-04-17' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w7_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-04-27' & time <= '2020-05-01' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-04-20' & time<= '2020-04-24' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w8_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-05-04' & time <= '2020-05-08' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-04-27' & time<= '2020-05-01' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w9_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-05-11' & time <= '2020-05-15' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-05-04' & time<= '2020-05-08' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w10_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-05-18' & time <= '2020-05-22' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-05-11' & time<= '2020-05-15' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w11_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-05-25' & time <= '2020-05-29' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-05-18' & time<= '2020-05-22' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp[\"w12_eng\"][statesss.index(i)] = round((state_eng.query(\"time >= '2020-06-01' & time <= '2020-06-05' & state == @i\")['engagement_index'].mean()\n                                                             \/state_eng.query(\"time>= '2020-05-25' & time<= '2020-05-29' & state == @i\")['engagement_index'].mean() - 1)*100, 1)\n\n    \n    def color_values(val):\n        color = 'red' if val < 0 else 'green'\n        return 'color: %s' % color\n    \n    slice_ = ['w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access','w10_access','w11_access','w12_access', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng','w6_eng', 'w7_eng', 'w8_eng','w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']\n    slice_2 = [\"mean_access\", 'w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access','w10_access','w11_access','w12_access']\n    slice_3 = ['mean_eng', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng','w6_eng', 'w7_eng', 'w8_eng','w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']\n    asz = cov_imp.style.applymap(color_values, subset = slice_).set_precision(1).set_properties(**{'background-color': '#fafafa'}, subset = slice_2).set_properties(**{'background-color': '#f7f7f7'}, subset = slice_3)","7eb4d2fe":"asz","3003b838":"fig = px.line(locale_access, x = 'time', y = 'pct_access', color = 'locale', line_group = 'locale')\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of pct_access of all products by locale',\n                 title_font_family = 'monospace', title_font_color = '#221f1f', title_font_size = 20,\n                 title_x = 0.5)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2', \n                 linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12 )\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2', \n                 linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12 )\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color = 'red')\nfig.add_annotation()\nfig.add_annotation(x = '2020-03-11', y = 2.5, text = 'WHO has declared Covid-19 a pandemic', showarrow = True,\n                  font = dict(family = 'monospace', size = 11, color = 'black'), arrowhead = 2, arrowsize = 1,\n                  arrowwidth = 2, arrowcolor = '#636363', ax = 130, ay = 1)\nfig.add_vrect(x0 = \"2020-06-01\", x1 = \"2020-08-31\", fillcolor = \"yellow\", opacity = 0.25, line_width = 0)\nfig.add_annotation(x = \"2020-07-15\", y = 1.95, text = \"Summer holidays\", showarrow = False,\n                   font = dict(family ='monospace', size = 11, color = 'black'))\nfig.update_traces(line_width = 1)\nfig.show()","b96a4238":"fig = px.line(locale_eng, x = 'time', y = 'engagement_index', color = 'locale', line_group = 'locale')\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of engagement_index of all products by locale',\n                 title_font_family = 'monospace', title_font_color = '#221f1f', title_font_size = 20,\n                 title_x = 0.5)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2', \n                 linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12 )\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2', \n                 linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12 )\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color = 'red')\nfig.add_annotation()\nfig.add_annotation(x = '2020-03-11', y = 700, text = 'WHO has declared Covid-19 a pandemic', showarrow = True,\n                  font = dict(family = 'monospace', size = 11, color = 'black'), arrowhead = 2, arrowsize = 1,\n                  arrowwidth = 2, arrowcolor = '#636363', ax = 130, ay = 1)\nfig.add_vrect(x0 = \"2020-06-01\", x1 = \"2020-08-31\", fillcolor = \"yellow\", opacity = 0.25, line_width = 0)\nfig.add_annotation(x = \"2020-07-15\", y = 610, text = \"Summer holidays\", showarrow = False,\n                   font = dict(family ='monospace', size = 11, color = 'black'))\nfig.update_traces(line_width = 1)\nfig.show()","ca4b9473":"cov_imp1 = pd.DataFrame(locale_access[\"locale\"].unique().tolist()).rename(columns = {0:'locale'})\n\n\nfor i in [\"mean_access\", 'w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access',\n          'w10_access','w11_access','w12_access','mean_eng', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng', 'w6_eng', 'w7_eng', 'w8_eng',\n          'w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']:\n\n    cov_imp1[i] = 0.0\nlocales = cov_imp1['locale'].unique().tolist()\nfor i in locales:\n    cov_imp1[\"mean_access\"][locales.index(i)] = round(locale_access.query(\"time >= '2020-03-09' & time <= '2020-03-13' & locale == @i\")['pct_access'].mean(), 2)\n    cov_imp1[\"w1_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-03-16' & time <= '2020-03-20' & locale == @i\")['pct_access'].mean()\n                                                            \/cov_imp1['mean_access'][locales.index(i)] - 1)*100, 1)\n    cov_imp1[\"w2_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-03-23' & time <= '2020-03-27' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-03-16' & time<= '2020-03-20' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w3_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-03-30' & time <= '2020-04-03' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-03-23' & time<= '2020-03-27' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w4_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-04-06' & time <= '2020-04-10' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-03-30' & time<= '2020-04-03' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w5_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-04-13' & time <= '2020-04-17' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-04-06' & time<= '2020-04-10' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w6_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-04-20' & time <= '2020-04-24' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-04-13' & time<= '2020-04-17' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w7_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-04-27' & time <= '2020-05-01' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-04-20' & time<= '2020-04-24' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w8_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-05-04' & time <= '2020-05-08' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-04-27' & time<= '2020-05-01' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w9_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-05-11' & time <= '2020-05-15' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-05-04' & time<= '2020-05-08' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w10_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-05-18' & time <= '2020-05-22' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-05-11' & time<= '2020-05-15' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w11_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-05-25' & time <= '2020-05-29' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-05-18' & time<= '2020-05-22' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp1[\"w12_access\"][locales.index(i)] = round((locale_access.query(\"time >= '2020-06-01' & time <= '2020-06-05' & locale == @i\")['pct_access'].mean()\n                                                             \/locale_access.query(\"time>= '2020-05-25' & time<= '2020-05-29' & locale == @i\")['pct_access'].mean() - 1)*100, 1)\n    \n    cov_imp1[\"mean_eng\"][locales.index(i)] = round(locale_eng.query(\"time >= '2020-03-09' & time <= '2020-03-13' & locale == @i\")['engagement_index'].mean(), 1)\n    cov_imp1[\"w1_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-03-16' & time <= '2020-03-20' & locale == @i\")['engagement_index'].mean()\n                                                            \/cov_imp1['mean_eng'][locales.index(i)] - 1)*100, 1)\n    cov_imp1[\"w1_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-03-23' & time <= '2020-03-27' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-03-16' & time<= '2020-03-20' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w3_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-03-30' & time <= '2020-04-03' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-03-23' & time<= '2020-03-27' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w4_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-04-06' & time <= '2020-04-10' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-03-30' & time<= '2020-04-03' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w5_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-04-13' & time <= '2020-04-17' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-04-06' & time<= '2020-04-10' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w6_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-04-20' & time <= '2020-04-24' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-04-13' & time<= '2020-04-17' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w7_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-04-27' & time <= '2020-05-01' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-04-20' & time<= '2020-04-24' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w8_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-05-04' & time <= '2020-05-08' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-04-27' & time<= '2020-05-01' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w9_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-05-11' & time <= '2020-05-15' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-05-04' & time<= '2020-05-08' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w10_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-05-18' & time <= '2020-05-22' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-05-11' & time<= '2020-05-15' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w11_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-05-25' & time <= '2020-05-29' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-05-18' & time<= '2020-05-22' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp1[\"w12_eng\"][locales.index(i)] = round((locale_eng.query(\"time >= '2020-06-01' & time <= '2020-06-05' & locale == @i\")['engagement_index'].mean()\n                                                             \/locale_eng.query(\"time>= '2020-05-25' & time<= '2020-05-29' & locale == @i\")['engagement_index'].mean() - 1)*100, 1)\n\n    \n    def color_values(val):\n        color = 'red' if val < 0 else 'green'\n        return 'color: %s' % color\n    \n    slice_ = ['w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access','w10_access','w11_access','w12_access', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng','w6_eng', 'w7_eng', 'w8_eng','w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']\n    slice_2 = [\"mean_access\", 'w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access','w10_access','w11_access','w12_access']\n    slice_3 = ['mean_eng', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng','w6_eng', 'w7_eng', 'w8_eng','w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']\n    adp = cov_imp1.style.applymap(color_values, subset = slice_).set_precision(1).set_properties(**{'background-color': '#fafafa'}, subset = slice_2).set_properties(**{'background-color': '#f7f7f7'}, subset = slice_3)","e5d6ebe9":"   adp","a543d76f":"fig = px.line(cat_access.query(\"Basic_category != 'x' \"), x = 'time', y = 'pct_access', color = 'Basic_category', line_group = 'Basic_category')\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of pct_access of all products by product category',\n                 title_font_family = 'monospace', title_font_color = '#221f1f', title_font_size = 20,\n                 title_x = 0.5)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2', \n                 linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12 )\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2', \n                 linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12 )\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color = 'red')\nfig.add_annotation(x = '2020-03-11', y = 4.5, text = 'WHO has declared Covid-19 a pandemic', showarrow = True,\n                  font = dict(family = 'monospace', size = 11, color = 'black'), arrowhead = 2, arrowsize = 1,\n                  arrowwidth = 2, arrowcolor = '#636363', ax = 130, ay = 1)\nfig.add_vrect(x0 = \"2020-06-01\", x1 = \"2020-08-31\", fillcolor = \"yellow\", opacity = 0.25, line_width = 0)\nfig.add_annotation(x = \"2020-07-15\", y = 3.8, text = \"Summer holidays\", showarrow = False,\n                   font = dict(family ='monospace', size = 11, color = 'black'))\nfig.update_traces(line_width = 1)\nfig.show()","4775c04a":"fig = px.line(cat_eng.query(\"Basic_category != 'x' \"), x = 'time', y = 'engagement_index', color = 'Basic_category', line_group = 'Basic_category')\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of engagement_index of all products by product category',\n                 title_font_family = 'monospace', title_font_color = '#221f1f', title_font_size = 20,\n                 title_x = 0.5)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2', \n                 linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12 )\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2', \n                 linewidth = 2, tickfont_family = 'monospace', tickfont_color = '#221f1f', tickfont_size = 12 )\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color = 'red')\nfig.add_annotation(x = '2020-03-11', y = 1900, text = 'WHO has declared Covid-19 a pandemic', showarrow = True,\n                  font = dict(family = 'monospace', size = 11, color = 'black'), arrowhead = 2, arrowsize = 1,\n                  arrowwidth = 2, arrowcolor = '#636363', ax = 130, ay = 1)\nfig.add_vrect(x0 = \"2020-06-01\", x1 = \"2020-08-31\", fillcolor = \"yellow\", opacity = 0.25, line_width = 0)\nfig.add_annotation(x = \"2020-07-15\", y = 1600, text = \"Summer holidays\", showarrow = False,\n                   font = dict(family ='monospace', size = 11, color = 'black'))\nfig.update_traces(line_width = 1)\nfig.show()","da8db275":"cov_imp2 = pd.DataFrame(cat_eng.query(\"Basic_category != 'x'\")[\"Basic_category\"].unique().tolist()).rename(columns = {0:'Basic_category'})\n\n\nfor i in [\"mean_access\", 'w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access',\n          'w10_access','w11_access','w12_access','mean_eng', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng', 'w6_eng', 'w7_eng', 'w8_eng',\n          'w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']:\n    cov_imp2[i] = 0.0\n    \ncategories = cov_imp2['Basic_category'].unique().tolist()\nfor i in categories:\n    cov_imp2[\"mean_access\"][categories.index(i)] = round(cat_access.query(\"time >= '2020-03-09' & time <= '2020-03-13' & Basic_category == @i\")['pct_access'].mean(), 2)\n    cov_imp2[\"w1_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-03-16' & time <= '2020-03-20' & Basic_category == @i\")['pct_access'].mean()\n                                                            \/cov_imp2['mean_access'][categories.index(i)] - 1)*100, 1)\n    cov_imp2[\"w2_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-03-23' & time <= '2020-03-27' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-03-16' & time<= '2020-03-20' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w3_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-03-30' & time <= '2020-04-03' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-03-23' & time<= '2020-03-27' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w4_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-04-06' & time <= '2020-04-10' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-03-30' & time<= '2020-04-03' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w5_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-04-13' & time <= '2020-04-17' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-04-06' & time<= '2020-04-10' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w6_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-04-20' & time <= '2020-04-24' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-04-13' & time<= '2020-04-17' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w7_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-04-27' & time <= '2020-05-01' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-04-20' & time<= '2020-04-24' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w8_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-05-04' & time <= '2020-05-08' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-04-27' & time<= '2020-05-01' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w9_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-05-11' & time <= '2020-05-15' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-05-04' & time<= '2020-05-08' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w10_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-05-18' & time <= '2020-05-22' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-05-11' & time<= '2020-05-15' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w11_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-05-25' & time <= '2020-05-29' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-05-18' & time<= '2020-05-22' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    cov_imp2[\"w12_access\"][categories.index(i)] = round((cat_access.query(\"time >= '2020-06-01' & time <= '2020-06-05' & Basic_category == @i\")['pct_access'].mean()\n                                                             \/cat_access.query(\"time>= '2020-05-25' & time<= '2020-05-29' & Basic_category == @i\")['pct_access'].mean() - 1)*100, 1)\n    \n    cov_imp2[\"mean_eng\"][categories.index(i)] = round(cat_eng.query(\"time >= '2020-03-09' & time <= '2020-03-13' & Basic_category == @i\")['engagement_index'].mean(), 1)\n    cov_imp2[\"w1_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-03-16' & time <= '2020-03-20' & Basic_category == @i\")['engagement_index'].mean()\n                                                            \/cov_imp2['mean_eng'][categories.index(i)] - 1)*100, 1)\n    cov_imp2[\"w1_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-03-23' & time <= '2020-03-27' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-03-16' & time<= '2020-03-20' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w3_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-03-30' & time <= '2020-04-03' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-03-23' & time<= '2020-03-27' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w4_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-04-06' & time <= '2020-04-10' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-03-30' & time<= '2020-04-03' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w5_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-04-13' & time <= '2020-04-17' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-04-06' & time<= '2020-04-10' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w6_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-04-20' & time <= '2020-04-24' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-04-13' & time<= '2020-04-17' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w7_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-04-27' & time <= '2020-05-01' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-04-20' & time<= '2020-04-24' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w8_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-05-04' & time <= '2020-05-08' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-04-27' & time<= '2020-05-01' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w9_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-05-11' & time <= '2020-05-15' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-05-04' & time<= '2020-05-08' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w10_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-05-18' & time <= '2020-05-22' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-05-11' & time<= '2020-05-15' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w11_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-05-25' & time <= '2020-05-29' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-05-18' & time<= '2020-05-22' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n    cov_imp2[\"w12_eng\"][categories.index(i)] = round((cat_eng.query(\"time >= '2020-06-01' & time <= '2020-06-05' & Basic_category == @i\")['engagement_index'].mean()\n                                                             \/cat_eng.query(\"time>= '2020-05-25' & time<= '2020-05-29' & Basic_category == @i\")['engagement_index'].mean() - 1)*100, 1)\n\n    \n    def color_values(val):\n        color = 'red' if val < 0 else 'green'\n        return 'color: %s' % color\n    \n    slice_ = ['w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access','w10_access','w11_access','w12_access', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng','w6_eng', 'w7_eng', 'w8_eng','w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']\n    slice_2 = [\"mean_access\", 'w1_access', 'w2_access', 'w3_access', 'w4_access','w5_access','w6_access','w7_access','w8_access','w9_access','w10_access','w11_access','w12_access']\n    slice_3 = ['mean_eng', 'w1_eng', 'w2_eng', 'w3_eng', 'w4_eng', 'w5_eng','w6_eng', 'w7_eng', 'w8_eng','w9_eng', 'w10_eng', 'w11_eng', 'w12_eng']\n    aaa = cov_imp2.style.applymap(color_values, subset = slice_).set_precision(1).set_properties(**{'background-color': '#fafafa'}, subset = slice_2).set_properties(**{'background-color': '#f7f7f7'}, subset = slice_3)                                        ","d24bd181":"aaa","fee448f3":"#### Figure 11","b837d0d9":"#### Table 3","5ac1260b":"#### Figure 4","ef1c903c":"#### Figure 6","8f08654b":"#### Figure 3","664c381a":"#### Figure 12","b36b3961":"#### Figure 9","275c1280":"#### Product Data:\nThe product data comes with information based on 372 entries out of which company name had 1 missing entry and Sector(s) and Primary Essential Function had 20 missing entries respectively. These missing entries were deleted or dropped. There are five unique Sector(s) and four major categories. The PreK-12 sector of education had the most usage of product constituting about 48% of the dataset and the top learning provider was Google LLC.\n\nMost products can be found in the LC category and this constitute about 77% of the products as shown in the figure 8, chart 2 and chart 3 below.\n\n\n#### Engagement Data:\nThe engagement data consist of data based on 22324189 entries of which about 24% are missing. These missing entries were dropped or deleted. The data was merged with the product data and district data for further analysis.\n\n","fb4d51ec":"#### Figure 8","987468fa":"#### Figure 7","89a4acd7":"#### Chart 3","c4853b56":"#### Figure 5","2faf5aed":"It\u2019s observed that the percentage of students in the districts who identified themselves as Black or Hispanic has a distribution which is right skewed with less than 24% having the largest counts of school districts in the city. Moreover, percentage of students in districts eligible for free or reduced-price lunch and the local and federal expenditure observed almost a symmetrical distribution but a right skewed with less than 34% and having the largest counts of districts in the city for the former. On average total expenditure on each student is $11329.55 and this mostly occurred in the rural area. As illustrated in figure 5 to figure 7 and chart 1 below.  ","09f273a5":"#### Figure 2","902f6714":"# PREPROCESSING\n\n### District Data:\nThe district data consist of information based on 233 entries of which state, locale and percentage of students who identified themselves as Black or Hispanic (pct_black\/Hispanic) had 24.5% missing entries. Percentage of free or reduced meals (pct_free\/reduced), ratio base on the county level data (county_connections_ratio) and per-pupil total expenditure (pp_total_raw) had 36.5%, 30.47% and 49.36% of missing entries respectively. State and locale missing entries were dropped or deleted and the remaining missing entries were imputed using the most frequent value or item in each column.\n\nIn all, there are 23 states presented in the data. The entries for pct_black\/Hispanic, pct_free\/reduced, county_connections_ratio and pp_total_raw were originally entered as intervals. The intervals for pct_black\/Hispanic, pct_free\/reduced and pp_total_raw are very close and with a range of 0.2 , 0.02 and 2000 respectively. Therefore, prudent to represent each interval entry by its average and median in case of pp_total_raw. However, intervals for county_connections_ratio are wide and hence inappropriate to represent each entry with its mean or median value.\n\nThe top six states with more than ten school districts and the highest number of suburbs are Connecticut, Utah, Massachusetts, Illinois, California and Ohio. As shown in figure 1 and figure 2 below.\n","abb0ccce":"#### Figure 10","736a3fee":"#### Figure 1","ec67d014":"#### Chart 2","2c3d6a5b":"# Conclusion\nUpon declaring covid-19 pandemic, most students, teachers and users of educational facilities and materials didn\u2019t immediately engage in digital learning, but after a week. Right after the third week users went offline on digital learning and this mostly occurred in the month of May 2020 probably due to conspiracy theorists claim of covid-19 not being real and most schools were on summer holidays.\n \nAfter summer holidays users of educational facilities and materials were actively engaged in digital learning as can be evident from figures 12 to 15 above from middle of August 2020 onwards. There is an increase in pct_access and engagement_index of products by most states, locale and ofprimary function of the products\n\nCovid -19 has urged and encouraged us to make good use of technology in education and from this point onwards digital learning will become a major and an integral part of the educational system across states and locale.\n","8defd79a":"#### Chart 1","1d3fe144":"#### Figure 13","aca8fd86":"#### Table 2","7ea736ba":"#### Figure 15","c44635fa":"#### Table 1","fb43e4c6":"#### Figure 14","dda1a2a6":"# ANALYSIS\nThe Covid-19 pandemic also known as the coronavirus pandemic is an ongoing global pandemic caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-Cov-2). The pandemic has disrupted in person learning for more than 56 million students in the USA. Covid-19 was declared a pandemic on the 11th March 2020 across countries by World Health Organization (WHO). Most states and locale governments temporarily shut or closed down educational institutions in order to avoid the rapid spread of the virus.\n\n>\n#### Before 11th March\nFrom figure 9 and figure 10, prior to the declaration of Covid-19 a pandemic, the percentage of students in districts that have at least one page-load event of a given product on a given day (pct_access) in most states is fairly less than 500% with the least access being from Texas, California and Tennesse and the highest access being from Arizona and Connecticut. During this same period the total page-load events per one thousand students on a given day (engagement_index)  is less than 1300 with the least being from Tennesse, Texas and California and the highest engagement_index being from Arizona and Connecticut. \n\nMoreover, in general, the rural had the highest rate of pct_access and the highest engagement_index followed by the suburbs while the cities and towns had the least pct_access and engagement_index.\n\n#### After 11th to Start of Summer Holidays\nAfter WHO had declared Covid-19 a pandemic, pct_access of all products by states fairly declined and engagement_index fairly rose in states. This is due to some school districts  temporarily shut down. \n\nHowever, in general, the rural had the highest rate of pct_access and the highest engagement_index followed by the suburbs and towns.\n\n#### During Summer Holidays\nSummer holidays are defined by school districts, there is no exact date or day throughout the states. However, in general, late May to early September can be assumed. From the graph in figure 9 and figure 10,  school districts that begun their holidays in early June had pct_access of all products and engagement_index declined till July 31st were it starts to peak and throughout the month of August. This rise is due to school districts in some states such as Arizona and Indiana resuming early.\n\nAlthough, the rural area had the highest rate of pct_access and the highest engagement_index followed by the suburbs and cities but in the month of August the pct_access and engagement_index for towns peaked.\n\n\n#### After Summer Holidays\nAfter the summer holidays there had been on average a consistent rise in pct_access of all products by states and on average a consistent rise in engagement_index by states.\n\nNonetheless, on average, the rural had the highest rate of pct_access and the highest engagement_index followed by the suburbs and cities. This is attributed to school district involving in digital learning.\n\n#### The Imediate Impact of Covid-19\nFrom tables 1 and 2, the immediate impact of covid-19 after 11th March saw a decline in pct_access and an rise in engagement_index. Nevetheless, from the third week in March 2020 to the fourth week in April 2020 on average had an increase in pct_access and engagement_index of all products by both states and locale but throughout May 2020 there was a decline in pct_access and engagement_index by both states and locale.\n\nIn addition, pct_acces of primary functions of products fell immediately after 11th March 2020 yet increase from the third week in March 2020 to first week in April 2020. But engagement_index rose right after 11th March 2020 to the first week in April 2020. Throughout the month of May 2020, on average pct_access and engagement_index of primary functions of products fell, this is evident in table 3."}}