{"cell_type":{"a14461cd":"code","919f230e":"code","28c189fc":"code","cbe3c29b":"code","c134e4ec":"code","6109958a":"code","12201d6d":"code","a10c3c68":"code","dc0b323c":"code","301928e0":"code","cc54b659":"code","3abd3d06":"code","4d3676a0":"markdown","98c5c734":"markdown","186ab448":"markdown","87e18bc7":"markdown","72d7ef86":"markdown","2c57da87":"markdown","3d25fa7a":"markdown","643786bb":"markdown","16597ff8":"markdown","05afd293":"markdown"},"source":{"a14461cd":"import numpy as np \nimport pandas as pd \nimport os\nfrom tqdm import notebook \nfrom tqdm.notebook import tqdm as tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nsns.set_style('darkgrid')\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.metrics import Recall,AUC\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","919f230e":"for sets in ['training_set', 'test_set']:\n\n    foldernames = os.listdir(f'..\/input\/cat-and-dogs\/dataset\/{sets}\/')\n    path = f'..\/input\/cat-and-dogs\/dataset\/{sets}\/'\n    categories = []\n    files = []\n    i = 0\n    for k, folder in enumerate(foldernames):\n        filenames = os.listdir(path + folder);\n        for file in filenames:\n            files.append(path + folder + \"\/\" + file)\n            categories.append(k)\n\n    df = pd.DataFrame({\n        'filename': files,\n        'category': categories\n    })\n    if sets == 'training_set':\n        train_df = pd.DataFrame(columns=['filename', 'category'])\n        for i in range(2):\n            train_df = train_df.append(df[df.category == i].iloc[:500,:])\n\n        train_df = train_df.reset_index(drop=True)\n    else:\n        test_df = pd.DataFrame(columns=['filename', 'category'])\n        for i in range(2):\n            test_df = test_df.append(df[df.category == i].iloc[:500,:])\n\n        test_df = test_df.reset_index(drop=True)\ndf = test_df.append(train_df)\ndf['category'][df['category']==0] = 'dog'\ndf['category'][df['category']==1] = 'cat'\ndf.head()","28c189fc":"fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"xy\"}, {\"type\": \"pie\"}]])\n\n\nfig.add_trace(go.Bar(x =df['category'].value_counts().index,y=df['category'].value_counts().to_numpy(),marker_color=['navajowhite','palegreen'],showlegend=False),row=1,col=1)\n\nfig.add_trace(go.Pie(\n     values=df['category'].value_counts().to_numpy(),\n     labels=df['category'].value_counts().index,\n    marker=dict(colors=['navajowhite','palegreen'])),\n    row=1, col=2)","cbe3c29b":"label = 'cat' #label for cats images\ndata = df[df['category'] == label]\nsns.set_style('dark')\n\n\npics = 4 #set the number of pics\nfig,ax = plt.subplots(int(pics\/\/2),2,figsize=(20,20))\nplt.suptitle('Images of cats')\nax = ax.ravel()\nfor i in range((pics\/\/2)*2):\n    path = data.sample(1).loc[:,'filename'].to_numpy()[0]\n    img = image.load_img(path)\n    img = image.img_to_array(img)\/255\n    ax[i].imshow(img)\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","c134e4ec":"label = 'dog' #label for dogs images\ndata = df[df['category'] == label]\nsns.set_style('dark')\n\n\npics = 4 #set the number of pics\nfig,ax = plt.subplots(int(pics\/\/2),2,figsize=(20,20))\nplt.suptitle('Images of dogs')\nax = ax.ravel()\nfor i in range((pics\/\/2)*2):\n    path = data.sample(1).loc[:,'filename'].to_numpy()[0]\n    img = image.load_img(path)\n    img = image.img_to_array(img)\/255\n    ax[i].imshow(img)\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","6109958a":"def shaper(row):\n    shape = image.load_img(row['filename']).size\n    row['height'] = shape[1]\n    row['width'] = shape[0]\n    return row\ndf = df.apply(shaper,axis=1)\ndf.head(5)","12201d6d":"sns.set_style('darkgrid')\nfig,(ax1,ax2,ax3) = plt.subplots(1,3,gridspec_kw={'width_ratios': [3,0.5,0.5]},figsize=(15,10))\nsns.kdeplot(data=df.drop(columns=['filename','category']),ax=ax1,legend=True)\nsns.boxplot(data=df,y='height',ax=ax2,color='skyblue')\nsns.boxplot(data=df,y='width',ax=ax3,color='orange')\nplt.suptitle('Distribution of image shapes')\nax3.set_ylim(0,7000)\nax2.set_ylim(0,7000)\nplt.tight_layout()","a10c3c68":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\ntraining_set = train_datagen.flow_from_directory(\n        '..\/input\/cat-and-dogs\/dataset\/training_set',\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='binary')\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_set = test_datagen.flow_from_directory(\n    '..\/input\/cat-and-dogs\/dataset\/test_set',\n    target_size = (64, 64),\n    batch_size = 32,\n    class_mode = 'binary')","dc0b323c":"cnn = tf.keras.models.Sequential()\n\ncnn.add(tf.keras.layers.Conv2D(\n    filters= 32,\n    kernel_size = 3,\n    activation = 'relu',\n    input_shape = [64,64,3]\n))\n\ncnn.add(tf.keras.layers.MaxPool2D(\n    pool_size = 2,\n    strides = 2\n))\n\ncnn.add(tf.keras.layers.Conv2D(\n    filters= 32,\n    kernel_size = 3,\n    activation = 'relu',\n))\ncnn.add(tf.keras.layers.MaxPool2D(\n    pool_size = 2,\n    strides = 2\n))\n\ncnn.add(tf.keras.layers.Flatten())\n\ncnn.add(tf.keras.layers.Dense(\n    units=128, \n    activation='relu'\n))\n\ncnn.add(tf.keras.layers.Dense(\n    units=1, \n    activation='sigmoid'\n))\n\ncnn.compile(\n    optimizer = 'adam', \n    loss = 'binary_crossentropy', \n    metrics = ['accuracy']\n    )\n\ncnn.summary()","301928e0":"cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy',Recall(),AUC()])","cc54b659":"history = cnn.fit(\n    x = training_set, \n    validation_data = test_set, \n    epochs = 15,\n    batch_size = 32\n)","3abd3d06":"epochs = 15\n\nprint(\"CNN: Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(epochs,history.history['accuracy'][epochs-1],history.history['val_accuracy'][epochs-1]))\ndef show_plots(history):\n    \"\"\" Useful function to view plot of loss values & accuracies across the various epochs \"\"\"\n    loss_vals = history['loss']\n    val_loss_vals = history['val_loss']\n    epochs = range(1, len(history['accuracy'])+1)\n    \n    f, ax = plt.subplots(nrows=1,ncols=2,figsize=(16,4))\n    \n    # plot losses on ax[0]\n    ax[0].plot(epochs, loss_vals, color='navy',marker='o', linestyle=' ', label='Training Loss')\n    ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n    ax[0].set_title('Training & Validation Loss')\n    ax[0].set_xlabel('Epochs')\n    ax[0].set_ylabel('Loss')\n    ax[0].legend(loc='best')\n    ax[0].grid(True)\n    \n    # plot accuracies\n    acc_vals = history['accuracy']\n    val_acc_vals = history['val_accuracy']\n\n    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n    ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n    ax[1].set_title('Training & Validation Accuracy')\n    ax[1].set_xlabel('Epochs')\n    ax[1].set_ylabel('Accuracy')\n    ax[1].legend(loc='best')\n    ax[1].grid(True)\n    \n    plt.show()\n    plt.close()\n    \n    # delete locals from heap before exiting\n    del loss_vals, val_loss_vals, epochs, acc_vals, val_acc_vals\nshow_plots(history.history)","4d3676a0":"The height and width of images vary a lot. We will need to reshape them to a fixed shape before training.","98c5c734":"As you can see, the sizes of the images are different. Let's visualize the distribution of their shapes","186ab448":"The dataset is perfectly balanced.\n\nLet's go on and take a look to some sample images.","87e18bc7":"# Image Classification of Dogs and Cats using CNN\n  \n## Dataset\nThe dataset is already splitted into *test_set* and *training_set*. \nWe have 2000 images to test (1k cats and 1k dogs) and 8000 images to train (4k cats and 4k dogs). \n  \nIn this notebook we will follow the simplest *pipeline* for **image classification** using **tensorflow** and **CNN**.  \n  \n**Objective: To create a classification model that can detect fire in images**\n  \n**Models used: Sequential CNN from scratch**","72d7ef86":"Model fitting","2c57da87":"## Creating the model\nLet's finally create the model.","3d25fa7a":"### Exploratory analysis\n\n#### Loading Training and Test set","643786bb":"### Import libraries","16597ff8":"The following step is to compile the model","05afd293":"Let's begin with looking at the numerosity of each category"}}