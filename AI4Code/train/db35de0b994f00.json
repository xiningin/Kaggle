{"cell_type":{"6f63e0c8":"code","42afd612":"code","49e4a334":"code","aefff204":"code","dec94d4c":"code","610c39e1":"code","29dd0055":"code","4b6114b8":"code","76727ee1":"code","90000533":"code","56db43b4":"code","654728dc":"code","9c6b5b41":"code","89268faa":"markdown","e4e282d9":"markdown","89086363":"markdown","4145af86":"markdown","918bbf56":"markdown","74d24d53":"markdown","67fb96e4":"markdown","16bb857e":"markdown"},"source":{"6f63e0c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42afd612":"import gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","49e4a334":"train = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\n\ntrain","aefff204":"print(train.isna().sum(), test.isna().sum())","dec94d4c":"train['std'] = train.std(axis=1)\ntrain['min'] = train.min(axis=1)\ntrain['max'] = train.max(axis=1)\n\ntest['std'] = test.std(axis=1)\ntest['min'] = test.min(axis=1)\ntest['max'] = test.max(axis=1)","610c39e1":"y = train['target']\ntrain.drop(columns = ['id', 'target'], inplace = True)\ntest.drop(columns = 'id', inplace = True)","29dd0055":"def Stacking_Data_Loader(model, model_name, train, y, test, fold):\n    '''\n    Put your train, test datasets and fold value!\n    This function returns train, test datasets for stacking ensemble :)\n    '''\n\n    stk = StratifiedKFold(n_splits = fold, random_state = 42, shuffle = True)\n    \n    # Declaration Pred Datasets\n    train_fold_pred = np.zeros((train.shape[0], 1))\n    test_pred = np.zeros((test.shape[0], fold))\n    \n    for counter, (train_index, valid_index) in enumerate(stk.split(train, y)):\n        x_train, y_train = train.iloc[train_index], y[train_index]\n        x_valid, y_valid = train.iloc[valid_index], y[valid_index]\n\n        print('------------ Fold', counter+1, 'Start! ------------')\n        if model_name == 'cat':\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n        elif model_name == 'xgb':\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric = 'auc', verbose = 500, early_stopping_rounds = 200)\n        else:\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric = 'auc', verbose = 500, early_stopping_rounds = 200)\n            \n        print('------------ Fold', counter+1, 'Done! ------------')\n        \n        train_fold_pred[valid_index, :] = model.predict_proba(x_valid)[:, 1].reshape(-1, 1)\n        test_pred[:, counter] = model.predict_proba(test)[:, 1]\n        \n        del x_train, y_train, x_valid, y_valid\n        gc.collect()\n        \n    test_pred_mean = np.mean(test_pred, axis = 1).reshape(-1, 1)\n    \n    del test_pred\n    gc.collect()\n    \n    print('Done!')\n    \n    return train_fold_pred, test_pred_mean","4b6114b8":"lgb_params = {\n    'objective': 'binary',\n    'n_estimators': 20000,\n    'random_state': 42,\n    'learning_rate': 8e-3,\n    'subsample': 0.6,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.4,\n    'reg_alpha': 10.0,\n    'reg_lambda': 1e-1,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n    'device': 'gpu',\n}\n\n\nxgb_params = {'n_estimators': 10000,\n               'learning_rate': 0.03689407512484644,\n               'max_depth': 8,\n               'colsample_bytree': 0.3723914688159835,\n               'subsample': 0.780714581166012,\n               'eval_metric': 'auc',\n               'use_label_encoder': False,\n               'gamma': 0,\n               'reg_lambda': 50.0,\n               'tree_method': 'gpu_hist',\n               'gpu_id': 0,\n               'predictor': 'gpu_predictor',\n               'random_state': 42}\n\ncat_params = {'iterations': 17298,\n               'learning_rate': 0.03429054860458741,\n               'reg_lambda': 0.3242286463210283,\n               'subsample': 0.9433911589913944,\n               'random_strength': 22.4849972385133,\n               'depth': 8,\n               'min_data_in_leaf': 4,\n               'leaf_estimation_iterations': 8,\n               'task_type':\"GPU\",\n               'bootstrap_type':'Poisson',\n               'verbose' : 500,\n               'early_stopping_rounds' : 200,\n               'eval_metric' : 'AUC'}","76727ee1":"lgbm = LGBMClassifier(**lgb_params)\n\nxgb = XGBClassifier(**xgb_params)\n\ncat = CatBoostClassifier(**cat_params)","90000533":"cat_train, cat_test = Stacking_Data_Loader(cat, 'cat', train, y, test, 3)\ndel cat\ngc.collect()\n\nlgbm_train, lgbm_test = Stacking_Data_Loader(lgbm, 'lgbm', train, y, test, 3)\ndel lgbm\ngc.collect()\n\nxgb_train, xgb_test = Stacking_Data_Loader(xgb, 'xgb', train, y, test, 3)\ndel xgb\ngc.collect()","56db43b4":"stack_x_train = np.concatenate((cat_train, lgbm_train, xgb_train), axis = 1)\nstack_x_test = np.concatenate((cat_test, lgbm_test, xgb_test), axis = 1)\n\ndel cat_train, lgbm_train, xgb_train, cat_test, lgbm_test, xgb_test\ngc.collect()\n\nstack_x_train","654728dc":"stk = StratifiedKFold(n_splits = 5)\n\ntest_pred_lo = 0\nfold = 1\ntotal_auc = 0\n\nfor train_index, valid_index in stk.split(stack_x_train, y):\n    x_train, y_train = stack_x_train[train_index], y[train_index]\n    x_valid, y_valid = stack_x_train[valid_index], y[valid_index]\n    \n    lr = LogisticRegression(n_jobs = -1, random_state = 42, C = 5, max_iter = 2000)\n    lr.fit(x_train, y_train)\n    \n    valid_pred_lo = lr.predict_proba(x_valid)[:, 1]\n    test_pred_lo += lr.predict_proba(stack_x_test)[:, 1]\n    auc = roc_auc_score(y_valid, valid_pred_lo)\n    total_auc += auc \/ 5\n    print('Fold', fold, 'AUC :', auc)\n    fold += 1\n    \nprint('Total AUC score :', total_auc)","9c6b5b41":"sub = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv')\nsub['target'] = test_pred_lo\nsub.to_csv('sub.csv', index = 0)\nsub","89268faa":"**Second level training**","e4e282d9":"**Import Libraries**","89086363":"**Final Stacking Datasets**","4145af86":"**Modeling**\n\n*Stacking data loader*","918bbf56":"**Stacking**\n* Making train, test prediction array!\n* Concat 3 arrays in 1 dataset","74d24d53":"**Feature Generation**","67fb96e4":"Model's HyperParameters\n\n* LGBM Param : https:\/\/www.kaggle.com\/hiro5299834\/tps-oct-2021-single-lightgbm\n* Cat Param : https:\/\/www.kaggle.com\/ranjeetshrivastav\/tps-oct-21-catboost\n* xgb Param : https:\/\/www.kaggle.com\/rahulchauhan3j\/tps-oct-2021-xgboost-pipeline-with-optuna#Model-Fit-and-Submission\nThanks for Sharing!","16bb857e":"**Submission**\n\nLevel 2 Results **Blending**"}}