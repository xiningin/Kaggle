{"cell_type":{"f5aa0667":"code","a738674c":"code","3ff25961":"code","751749fc":"code","81dd5caf":"code","cf99d98b":"code","edc86c68":"code","ba047cb8":"code","96f55c41":"code","d70b37fa":"code","33a03eb9":"code","29f27adf":"code","1b11a95a":"code","1c4cdafb":"code","306a72ed":"code","d9719548":"code","065e478b":"code","240af3f2":"code","60c3eb17":"code","e4634db7":"code","b3eeeb34":"code","86b9f710":"code","0c9bc07b":"code","6bb8e51a":"code","c6e71a34":"code","29641fdc":"code","f3d0509a":"code","588efc55":"code","2c812951":"code","f0fb49e6":"code","46b93ab7":"code","7471e366":"code","d5efe292":"code","f7c375d1":"code","47ac5a52":"code","2e972533":"code","339d5048":"code","76c6dfa6":"code","f8463dfd":"code","4ab227d9":"code","e2540233":"code","2474ece0":"code","ff8c102f":"code","182e1e47":"code","1c381770":"markdown","627b3287":"markdown","3ce35be6":"markdown","59c746c1":"markdown","5b9156a6":"markdown","fd058435":"markdown","e3ed6892":"markdown","e61208f8":"markdown","651c90d1":"markdown","28b80e4d":"markdown","c7f671da":"markdown","b61a282c":"markdown","5e31d6a2":"markdown","1f21e1f0":"markdown","a6bd9180":"markdown","0c15b8c5":"markdown","5a76fb52":"markdown","fa8eeb9a":"markdown","278c2f76":"markdown","65297311":"markdown","32c292b1":"markdown","12cf4268":"markdown","ba8dba1a":"markdown","4cf47d1c":"markdown","c98d450b":"markdown","641d7926":"markdown","7a2046ef":"markdown","98c043c1":"markdown","a564f043":"markdown","be868182":"markdown","3ec7070d":"markdown","83414bd2":"markdown","7aa35622":"markdown","f22e45eb":"markdown","ef65b8ee":"markdown","703d6447":"markdown","e844ad5d":"markdown","40705ab8":"markdown","7b01892a":"markdown","8889e47e":"markdown","ab5c5db0":"markdown","ffe8f585":"markdown","39688e23":"markdown","c797854b":"markdown","58cd520d":"markdown","33a8c054":"markdown","3d88fde3":"markdown","6c58ad5f":"markdown","9aa97446":"markdown","c85f0985":"markdown","4d80d1e7":"markdown","8921d903":"markdown"},"source":{"f5aa0667":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a738674c":"DfIdTrain = pd.read_csv('..\/input\/train_identity.csv')\nDfTransTrain = pd.read_csv('..\/input\/train_transaction.csv')","3ff25961":"DfIdTrain.head()","751749fc":"DfTransTrain.head()","81dd5caf":"\nDfTrain = pd.merge(DfIdTrain, DfTransTrain, how='inner', on ='TransactionID')","cf99d98b":"DfTrain.head()","edc86c68":"from matplotlib import pyplot as plt\ncolors = ['peru']\nplt.hist(DfTrain['isFraud'],density=True, histtype='bar', color=colors, label=colors)\n#plt.xlabel('Value')\n#plt.legend(legend)\nplt.ylabel('Number of Transactions')\nplt.title('Histogram of fraud and normal transactions')\nplt.show()","ba047cb8":"\nfrom matplotlib import pyplot as plt\nfig, axs = plt.subplots(1,2,  figsize=(9, 3), sharey=True)\naxs[0].scatter(DfTrain['isFraud'].head(100), DfTrain['card4'].head(100))\n#fig, ax = plt.subplots()\n#plt.scatter(DfTrain['isFraud'],DfTrain['card3'])\n#plt.xlabel('Value')\n#plt.ylabel('Number of Transactions')\n#plt.title('Histogram of fraud and normal transactions')\nplt.show()","96f55c41":"HalfCountTrain = len(DfTrain)\/2","d70b37fa":"DfTrainClen = DfTrain.dropna(thresh = HalfCountTrain, axis = 1)","33a03eb9":"DfTrainClen = DfTrainClen.drop('TransactionID', axis = 1)","29f27adf":"DfTrainClen.head()","1b11a95a":"DfTrainClenNum = DfTrainClen.select_dtypes(['int64','float64'])","1c4cdafb":"DfTrainClenCat = DfTrainClen.select_dtypes(['object'])","306a72ed":"NumColsTrain = list(DfTrainClenNum.columns)\nCatColsTrain = list(DfTrainClenCat.columns)","d9719548":"ImputerTrain = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\nImputerTrain = ImputerTrain.fit(DfTrainClenNum)\nDfTrainClen[NumColsTrain]=ImputerTrain.transform(DfTrainClenNum)","065e478b":"LabelencoderTrain = LabelEncoder()","240af3f2":"DfTrainClenCat = DfTrainClenCat.fillna('NA')","60c3eb17":"for i in range(len(CatColsTrain)):\n  DfTrainClenCat.iloc[:, i] = LabelencoderTrain.fit_transform(DfTrainClenCat.iloc[:, i])\n#Assign encoded data to dataframe \nDfTrainClen[CatColsTrain] = DfTrainClenCat","e4634db7":"#isFraud is 28th column in dataframe\ny = DfTrainClen.iloc[:,28]","b3eeeb34":"X = DfTrainClen.iloc[:,:]\nX = X.drop(columns='isFraud')","86b9f710":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","0c9bc07b":"sc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train) \nX_test  = sc_x.fit_transform(X_test)","6bb8e51a":"pca = PCA()\nX_train_pca = X_train\nX_test_pca = X_test\nX_train_pca = pca.fit_transform(X_train_pca)  \nX_test_pca = pca.transform(X_test_pca) \n\nexplained_variance = pca.explained_variance_ratio_\nprint(explained_variance)","c6e71a34":"model = XGBClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","29641fdc":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","f3d0509a":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","588efc55":"DfIdTest = pd.read_csv('..\/input\/test_identity.csv')","2c812951":"DfIdTest.head()\n","f0fb49e6":"DfTransTest = pd.read_csv('..\/input\/test_transaction.csv')","46b93ab7":"DfTransTest.head()\n","7471e366":"DfTest = pd.merge(DfIdTest, DfTransTest, how='outer', on ='TransactionID')","d5efe292":"DfTest.head()","f7c375d1":"NumColsTrain.remove('isFraud')","47ac5a52":"DfTestClenNum = DfTest[NumColsTrain]","2e972533":"DfTestClenCat = DfTest[CatColsTrain]","339d5048":"DfTestClen = pd.concat([DfTestClenNum, DfTestClenCat],axis=1)\n","76c6dfa6":"ImputerTest = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\nImputerTest = ImputerTest.fit(DfTestClen[NumColsTrain])\nDfTestClen[NumColsTrain]=ImputerTest.transform(DfTestClen[NumColsTrain])","f8463dfd":"LabelencoderTest = LabelEncoder()","4ab227d9":"DfTestClenCat = DfTestClenCat.fillna('NA')","e2540233":"for i in range(len(CatColsTrain)):\n  DfTestClenCat.iloc[:, i] = LabelencoderTest.fit_transform(DfTestClenCat.iloc[:, i])","2474ece0":"DfTestClen[CatColsTrain] = DfTestClenCat","ff8c102f":"X_testToPredict = DfTestClen.iloc[:,:]","182e1e47":"sc_x = StandardScaler()\nX_testToPredict  = sc_x.fit_transform(X_testToPredict)","1c381770":"**Feature scaling of test data**","627b3287":"**View sample data**","3ce35be6":"**Query the sample test data**","59c746c1":"**TransactionID is not required for evaluatin model. Lets drop it**\n","5b9156a6":"Finally write predicted values to submission file","fd058435":"**Assign numeric test data**","e3ed6892":"![image.png](attachment:image.png)","e61208f8":"**Merge idenity and transaction data for training**","651c90d1":"**Split train and test data**\n\n\n","28b80e4d":"**Load transaction data for test**\n","c7f671da":"**Sample cleansed train data**","b61a282c":"**Query the sample test transaction data**","5e31d6a2":"**Get categorical data for training\n**","1f21e1f0":"**Fill missing values with NA**\n\n","a6bd9180":"**From the above we can conclude that around 7 percent of transactions are fraud**","0c15b8c5":"**Load all coulmns as X_train and then drop isFraud**\n","5a76fb52":"**Fit Random forest**","fa8eeb9a":"**Do PCA on data**","278c2f76":"**Loop through categorical data and encode label**","65297311":"**Provided test data don't have dependent variable but we need to find better model which can give better accuracy.\nLets divide given data to test and train**","32c292b1":"**Standar scale the independent variables**","12cf4268":"**Assign categorical test data**","ba8dba1a":"**Get length of 50% of data**","4cf47d1c":"**From PCA result, we can conclude that no domination from select variables. Let include all variables for training.**","c98d450b":"**Since Random forest gave better accuracy score, predict isFraud using it**","641d7926":"![image.png](attachment:image.png)","7a2046ef":"**Since we have to predict isFraud, remove it from test data**","98c043c1":"**Sample Training data**","a564f043":"**Load identity data for test**\n","be868182":"**Encode categorical variables for test data**","3ec7070d":"**Impute missing values for Numeric test data using mean stratgey**","83414bd2":"**Load training data provided**","7aa35622":"**Loop through categorical data and encode label**\n","f22e45eb":"**Visualize fraud and normal transactions using histogram**","ef65b8ee":"**From the accuracy score with 96.11%, Random forest is the best model.\nNow predict isFraud for the test data provided in competition.\nPerform data cleansing for test data provided**","703d6447":"**Drop Columns for which more than 50% values are missing in training data**\n\n ","e844ad5d":"**Split data for X, y independent and dependent variables for training data**\n\n","40705ab8":"**Encode categorical variables for training data**\n\n","7b01892a":"**Fill missing values with NA**","8889e47e":"**Get numeric data for training**\n\n","ab5c5db0":"**Fit Logistic regression**","ffe8f585":"**Fit XGB model**","39688e23":"**Finally combine numeric and categorical test data**","c797854b":"**Set 50%threshold and drop columns with more than 50% missing values**\n","58cd520d":"**Get numeric and categorical columns for training**\n","33a8c054":"**Assign encoded data to dataframe **","3d88fde3":"**Impute missing values for Numeric train data using mean stratgey**\n","6c58ad5f":"**Query the sample test identity data**","9aa97446":"**Cardwise fraud and normal transactions**","c85f0985":"**Merge idenity and transaction data for test**\n\n","4d80d1e7":"**Load all coulmns as X_test **\n","8921d903":"**Fraud is one of the major ethical issues in the credit card industry. \nThe main aims is to build reliable model which can accurately predict if a transaction is fraud or not? **"}}