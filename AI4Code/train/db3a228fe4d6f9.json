{"cell_type":{"01915ac6":"code","044da640":"code","3a0ec0e0":"code","ab910fc1":"code","ec016bf8":"code","ef03d910":"code","f81590e8":"code","12552ae3":"code","29b3ffa6":"code","939466ad":"code","4c899cfb":"code","7e183efd":"code","8f9dc87d":"code","b57b03d1":"code","412e9e07":"code","0d492912":"code","bfe1d9ae":"code","39e3dbfa":"code","b65de12b":"code","a2446b4e":"code","181518a3":"code","d097558f":"code","505c4e03":"code","c769d15e":"markdown","211624da":"markdown","84566c4f":"markdown","4d9dc31f":"markdown","d3ede1b7":"markdown","611112e4":"markdown","db956d6a":"markdown","5b31fb4e":"markdown","6eb9dbd9":"markdown","4b791e71":"markdown","06648eb2":"markdown","3389efa2":"markdown","7a997ace":"markdown","f1cf6062":"markdown"},"source":{"01915ac6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","044da640":"import xgboost as xgb # extreme gradient boosting\nimport pandas as pd # data structures\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra, arrays\nimport seaborn as sns # statistical data visualization","3a0ec0e0":"df = pd.read_csv('..\/input\/auto-mpg.csv')\ndf.head(5)","ab910fc1":"df.shape","ec016bf8":"df.sort_values('mpg',ascending=True).head(5)","ef03d910":"df.sort_values('mpg',ascending=False).head(10)","f81590e8":"df.dtypes","12552ae3":"df['horsepower'].unique()","29b3ffa6":"df = df[df['horsepower'] != '?']","939466ad":"df['horsepower'] = df['horsepower'].astype('float')\ndf.dtypes","4c899cfb":"df['diesel'] = (df['car name'].str.contains('diesel')).astype(int)","7e183efd":"df.loc[df['diesel']==1]","8f9dc87d":"df.shape","b57b03d1":"df.describe()","412e9e07":"labels = np.array(df['mpg'])\nfeatures = df.drop('mpg', axis=1)","0d492912":"from sklearn.model_selection import train_test_split\n\n(train_features_f,test_features_f,train_labels,test_labels) = train_test_split(features, \n                                                                               labels, \n                                                                               test_size=0.25, \n                                                                               random_state=4)","bfe1d9ae":"train_features_cont = train_features_f.drop(['car name','diesel'], axis=1)\ntest_features_cont = test_features_f.drop(['car name','diesel'], axis=1)","39e3dbfa":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler().fit(train_features_cont)\n\ntrain_features = np.append(scaler.transform(train_features_cont), \n                           train_features_f['diesel'][:,None], \n                           axis=1)\ntest_features = np.append(scaler.transform(test_features_cont), \n                          test_features_f['diesel'][:,None], \n                          axis=1)","b65de12b":"print('Shapes')\nprint('Train features: {0} \\nTrain labels: {1}'.format(train_features.shape,\n                                                       train_labels.shape))\nprint('Test features: {0} \\nTest labels: {1}'.format(test_features.shape,\n                                                     test_labels.shape))","a2446b4e":"from sklearn.model_selection import KFold\nK = 4 # num splits\nkf = KFold(n_splits=K)","181518a3":"from sklearn import metrics\n\nxgb_predictions = []\n\nfor j, (train_index, val_index) in enumerate(kf.split(train_features)):\n    partial_train_data,val_data = train_features[train_index],train_features[val_index]\n    partial_train_targets,val_targets = train_labels[train_index],train_labels[val_index]\n\n    feature_names=['cylinders','displacement','horsepower','weight',\n                   'acceleration','model year','origin','diesel']\n    \n    d_train = xgb.DMatrix(partial_train_data, partial_train_targets, \n                          feature_names=feature_names)\n    d_val = xgb.DMatrix(val_data, val_targets, feature_names=feature_names)\n    d_test = xgb.DMatrix(test_features, feature_names=feature_names)\n    \n    watchlist = [(d_train, 'train'), (d_val, 'val')]\n    \n    xgb_params = {'min_child_weight': 1, 'eta': 0.3, 'colsample_bytree': 0.9, \n                  'max_depth': 3, 'subsample': 0.9, 'lambda': 1., \n                  'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n                  'eval_metric': 'rmse', 'objective': 'reg:linear'}\n    \n    model = xgb.train(xgb_params, d_train, 100, watchlist, early_stopping_rounds=2,\n                      maximize=False, verbose_eval=0)\n    \n    xgb_prediction = model.predict(d_test)\n    \n    xgb_predictions.append(list(xgb_prediction))\n    \n    print('Fold {0} rmse: {1}'.format(j+1,np.sqrt(metrics.mean_squared_error(xgb_prediction, \n                                                                             test_labels))))\n    \n    xgb.plot_importance(model, height=0.7) ","d097558f":"preds = [np.mean([x[i] for x in xgb_predictions]) for i in range(len(xgb_predictions[0]))]\n\nresults = pd.DataFrame({'car name': test_features_f['car name'], \n                        'label mpg': test_labels, \n                        'prediction': preds})","505c4e03":"results.head(10)","c769d15e":"oldsmobile cutlass ciera (diesel) has a mpg of 38, quite far from predicted 23. Research on internet shows combined mpg is 26 for this car, not 38","211624da":"Create train (75%) and test (25%) sets","84566c4f":"**K-fold cross-validation**","4d9dc31f":"Standarize continuous features and then add binary diesel column","d3ede1b7":"Remove incomplete rows","611112e4":"Remove car name and diesel columns to have only continuous features","db956d6a":"Create new column for diesel type as it affects fuel consumption","5b31fb4e":"K-fold and XGBoost models. feature importance graphs are plot","6eb9dbd9":"Fuel economy is measured in mpg miles per gallon in automobile industry. Fuel consumption is a relevant information that impacts areas such as economy or air pollution.\n\nThe purpose of this notebook is to predict mpg with K-fold, XGBoost and the mpg dataset.","4b791e71":"**mpg predicitons**","06648eb2":"Split data into labels and features","3389efa2":"There are missing values in horsepower (renault lecar deluxe) and car name provides more information (diesel type)","7a997ace":"**Data evaluation**","f1cf6062":"**Data preparation**"}}