{"cell_type":{"692229d0":"code","21abcc36":"code","17cf3cb5":"code","48b399d3":"code","1acfee1a":"code","595ec5c0":"code","5416684d":"code","91156fd3":"code","5d40ebbb":"code","1f707eab":"code","1edb94b1":"markdown","18dae560":"markdown","97dbdb68":"markdown","bdbd9264":"markdown","05bb3fbf":"markdown","9f65fa68":"markdown","d59ff98a":"markdown"},"source":{"692229d0":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np","21abcc36":"from sklearn.model_selection import train_test_split\n\nTEST_PATH = \"..\/input\/digit-recognizer\/test.csv\"\nTRAIN_PATH = \"..\/input\/digit-recognizer\/train.csv\"\nSUB_PATH = \"..\/input\/digit-recognizer\/sample_submission.csv\"\n\ntrain_df = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntrain_row = train_df.loc[:,\"pixel0\":].values\ntrain_labels = train_df.label\ntest_row = test_df.loc[:,\"pixel0\":].values\n\ntrain_row, valid_row, train_labels, valid_labels =\\\ntrain_test_split(train_row, train_labels, test_size=0.15, random_state=2020)\n\nprint(\"training size   : \", len(train_labels))\nprint(\"validation size : \", len(valid_labels))","17cf3cb5":"def decode_image(rowImage, label=None, image_size=(512, 512)):\n    image = tf.reshape(rowImage,(28, 28, 1))\n    image = tf.cast(image, tf.float32) \/ 255.0\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.5)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","48b399d3":"AUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64\n\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_row, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_row, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_row)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","1acfee1a":"model = keras.Sequential([\n    keras.layers.Conv2D(4, 5, 1, padding=\"same\", use_bias=True, activation=tf.nn.relu, input_shape=(28, 28, 1)),\n    keras.layers.Conv2D(4, 5, 1, padding=\"same\", use_bias=True, activation=tf.nn.relu),\n    keras.layers.AveragePooling2D(),\n    keras.layers.Conv2D(12, 5, 1, padding=\"same\", use_bias=True, activation=tf.nn.relu),\n    keras.layers.Conv2D(12, 5, 1, padding=\"same\", use_bias=True, activation=tf.nn.relu),\n    keras.layers.AveragePooling2D(),\n    keras.layers.Conv2D(32, 5, 1, padding=\"same\", use_bias=True, activation=tf.nn.relu),\n    keras.layers.Conv2D(64, 5, 1, padding=\"same\", use_bias=True, activation=tf.nn.relu),\n    keras.layers.Flatten(),\n    keras.layers.Dense(200, use_bias=True, activation=tf.nn.relu),\n    keras.layers.Dense(200, use_bias=True, activation=tf.nn.relu),\n    keras.layers.Dense(10, use_bias=True, activation=tf.nn.softmax)\n])\n\nmodel.compile(loss=keras.losses.sparse_categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['sparse_categorical_accuracy'])\n    \nmodel.summary()","595ec5c0":"EPOCHS = 50\nSTEPS_PER_EPOCH = train_labels.shape[0] \/\/ BATCH_SIZE\n\nhistory = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","5416684d":"history_dict = history.history\n\nacc = history_dict['sparse_categorical_accuracy']\nval_acc = history_dict['val_sparse_categorical_accuracy']\n\nepochs = range(1, len(acc) + 1)\n\nplt.figure(figsize=(9, 6))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'bo-', label='Validation acc', color=\"orange\")\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid()\n\nplt.show()","91156fd3":"def plot_image(i, predictions_array, true_label, img):\n    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.imshow(img)\n\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        color = 'green'\n    else:\n        color = 'red'\n\n    plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label, 100 * np.max(predictions_array), true_label), color=color)","5d40ebbb":"num_rows = 5\nnum_cols = 4\nnum_images = num_rows * num_cols\n\nsample_images = [np.reshape(rowImage,(28, 28))\/255. for rowImage in valid_row[:num_images]]\nsample_labels = valid_labels[:num_images].values\npreds = model.predict(np.reshape(sample_images, (num_images, 28, 28, 1)), verbose=1)\n\nplt.figure(figsize=(2 * num_cols, 2 * num_rows))\n\nfor i in range(num_images):\n    plt.subplot(num_rows, num_cols, i + 1)\n    plot_image(i, preds, sample_labels, sample_images)\nplt.show()","1f707eab":"import numpy as np\nsub = pd.read_csv(SUB_PATH)\n\nprobs = [np.argmax(prob) for prob in model.predict(test_dataset, verbose=1)]\nsub.Label = probs\nsub.to_csv('submission_ld.csv', index=False)\nsub.head()","1edb94b1":"5. **Predictions on a small sample of validation data**","18dae560":"5. **Generate Submission**","97dbdb68":"# Digit recognition : A simple digit recognizer with costumized CNN structure","bdbd9264":"4. **Training**","05bb3fbf":"2. **Lest's build datasets**\n\n    Currently we have 1D non-normalized images. So we need to convert them into **2D** grayscale (one channel) images and make **normalization**. \n\n    After that we will also use **data augmentation**[](http:\/\/) to improve our training set and avoid **overfitting**","9f65fa68":"1. **Lest's get the data**\n    \n    For the training and the visualisation of generalisation performance, we need to split our data into training and validation set","d59ff98a":"3. **Creating the CNN model**"}}