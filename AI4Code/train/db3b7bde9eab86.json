{"cell_type":{"fd1556bf":"code","0c697049":"code","edda9bd5":"code","83d6ea24":"code","650a15c0":"code","54092328":"code","c96752c1":"code","0d969ce6":"code","29441ebd":"code","3f71b7bd":"code","1a7be3f7":"code","a858f760":"code","97a29de1":"code","e14e92d2":"code","decd01a9":"code","dfa896ba":"code","26bf0eeb":"code","6255ffc0":"code","9db08fb0":"code","21e3009d":"code","3f8a3220":"code","982e4678":"code","881ed80a":"code","b43d3c6d":"code","bc83f328":"code","aa73aa38":"code","468784cb":"code","bd9158cf":"code","df58e22d":"code","f92cdc60":"code","6394901b":"code","cc0d75a4":"code","a42bf6fd":"code","d7bec253":"code","944956a3":"code","71990886":"code","7b594b9c":"code","9dd68039":"code","13b5527b":"code","ad5357ea":"markdown","5365d416":"markdown","a34fd3af":"markdown","b049a955":"markdown","76b30f2a":"markdown","fee19d92":"markdown","8ca6ceff":"markdown","dc2528cd":"markdown"},"source":{"fd1556bf":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport math\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\n#MUSIC PROCESS\nimport pydub\nfrom scipy.io.wavfile import read, write\nimport librosa\nimport librosa.display\nimport IPython\nfrom IPython.display import Audio\nimport scipy\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape,\\\nConv2DTranspose, LeakyReLU, Conv1D, AveragePooling1D, MaxPooling1D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","0c697049":"Main_Video_Path = Path(\"..\/input\/real-life-violence-situations-dataset\/Real Life Violence Dataset\")\nVideo_Path = list(Main_Video_Path.glob(r\"*\/*.mp4\"))\nVideo_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Video_Path))\nVideo_Path_Series = pd.Series(Video_Path,name=\"MP4\").astype(str)\nVideo_Labels_Series = pd.Series(Video_Labels,name=\"CATEGORY\")\nMain_MP4_Data = pd.concat([Video_Path_Series,Video_Labels_Series],axis=1)","edda9bd5":"Violence_Data = Main_MP4_Data[Main_MP4_Data[\"CATEGORY\"] == \"Violence\"]\nNonViolence_Data = Main_MP4_Data[Main_MP4_Data[\"CATEGORY\"] == \"NonViolence\"]\n\nViolence_Data = Violence_Data.reset_index()\nNonViolence_Data = NonViolence_Data.reset_index()","83d6ea24":"FPS = 30\nDELAY = int(100\/FPS)\n# when it is necessary","650a15c0":"violence_frame_list = []\n\nfor file_video in Violence_Data.MP4:\n    Video_File_Path = file_video\n    \n    Video_Caption = cv2.VideoCapture(Video_File_Path)\n    Frame_Rate = Video_Caption.get(5)\n    \n    while Video_Caption.isOpened():\n        \n        Current_Frame_ID = Video_Caption.get(1)\n        \n        ret,frame = Video_Caption.read()\n        \n        if ret != True:\n            break\n            \n        if Current_Frame_ID % math.floor(Frame_Rate) == 0:\n            Frame_Resize = cv2.resize(frame,(64,64))\n            violence_frame_list.append(Frame_Resize)\n            \n            \n    Video_Caption.release()","54092328":"figure,axis = plt.subplots(5,5,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    \n    Img_Pick = violence_frame_list[i]\n    \n    ax.set_xlabel(Img_Pick.shape)\n    ax.imshow(Img_Pick)\n\nplt.tight_layout()\nplt.show()","c96752c1":"X_4D_Violence = np.asarray(violence_frame_list)","0d969ce6":"print(np.shape(X_4D_Violence))","29441ebd":"X_4D_Violence_Labels = np.ones((5832,1))","3f71b7bd":"print(np.shape(X_4D_Violence_Labels))","1a7be3f7":"X_4D_Violence_Labels = X_4D_Violence_Labels.flatten()","a858f760":"X_4D_Violence_Labels = X_4D_Violence_Labels.astype(int)","97a29de1":"print(X_4D_Violence_Labels)","e14e92d2":"nonviolence_frame_list = []\n\nfor file_video in NonViolence_Data.MP4:\n    Video_File_Path = file_video\n    \n    Video_Caption = cv2.VideoCapture(Video_File_Path)\n    Frame_Rate = Video_Caption.get(5)\n    \n    while Video_Caption.isOpened():\n        \n        Current_Frame_ID = Video_Caption.get(1)\n        \n        ret,frame = Video_Caption.read()\n        \n        if ret != True:\n            break\n            \n        if Current_Frame_ID % math.floor(Frame_Rate) == 0:\n            Frame_Resize = cv2.resize(frame,(64,64))\n            nonviolence_frame_list.append(Frame_Resize)\n            \n            \n    Video_Caption.release()","decd01a9":"figure,axis = plt.subplots(5,5,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    \n    Img_Pick = nonviolence_frame_list[i]\n    \n    ax.set_xlabel(Img_Pick.shape)\n    ax.imshow(Img_Pick)\n\nplt.tight_layout()\nplt.show()","dfa896ba":"X_4D_NonViolence = np.asarray(nonviolence_frame_list)","26bf0eeb":"print(np.shape(X_4D_NonViolence))","6255ffc0":"X_4D_NonViolence_Labels = np.ones((4985,1))","9db08fb0":"print(np.shape(X_4D_NonViolence_Labels))","21e3009d":"X_4D_NonViolence_Labels = X_4D_NonViolence_Labels.flatten()","3f8a3220":"X_4D_NonViolence_Labels = X_4D_NonViolence_Labels.astype(int)","982e4678":"print(np.shape(X_4D_NonViolence_Labels))","881ed80a":"print(X_4D_NonViolence_Labels)","b43d3c6d":"X_Train = np.concatenate((X_4D_Violence,X_4D_NonViolence),axis=0)","bc83f328":"print(np.shape(X_Train))","aa73aa38":"Y_Train = np.concatenate((X_4D_Violence_Labels,X_4D_NonViolence_Labels),axis=0)","468784cb":"print(np.shape(Y_Train))","bd9158cf":"Target_X = X_Train\nLabel_X = Y_Train","df58e22d":"xTrain,xTest,yTrain,yTest = train_test_split(Target_X,Label_X,train_size=0.9,random_state=42,shuffle=True)","f92cdc60":"print(xTrain.shape)\nprint(yTrain.shape)\nprint(xTest.shape)\nprint(yTest.shape)","6394901b":"Model = Sequential()\n\nModel.add(SeparableConv2D(12,(3,3),activation=\"relu\",\n                 input_shape=(64,64,3)))\nModel.add(BatchNormalization())\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(SeparableConv2D(24,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.2))\nModel.add(MaxPooling2D((2,2)))\n\n\n#\nModel.add(TimeDistributed(Flatten()))\nModel.add(Bidirectional(LSTM(64,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\nModel.add(Bidirectional(LSTM(64,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\n\n#\nModel.add(Flatten())\nModel.add(Dense(128,activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(Dense(1,activation=\"sigmoid\"))","cc0d75a4":"print(Model.summary())","a42bf6fd":"Callback_Stop_Early = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3)","d7bec253":"Model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","944956a3":"CNN_Model = Model.fit(xTrain,yTrain,\n                      validation_data=(xTest,yTest),\n                      callbacks=Callback_Stop_Early,\n                      epochs=50)","71990886":"Model_Test_Prediction = Model.predict(xTest)","7b594b9c":"Model_Test_Prediction = Model_Test_Prediction.argmax(axis=-1)\nprint(Model_Test_Prediction)","9dd68039":"Model_Test_Prediction_Class = Model.predict_classes(xTest)","13b5527b":"print(Model_Test_Prediction_Class.flatten())","ad5357ea":"#### CONCAT VIOLENCE AND NON-VIOLENCE","5365d416":"#### VIOLENCE TRANSFORMATION","a34fd3af":"# PACKAGES AND LIBRARIES","b049a955":"# MODEL","76b30f2a":"#### NON-VIOLENCE TRANSFORMATION","fee19d92":"# SPLITTING TRAIN AND TEST","8ca6ceff":"# PATH, LABEL, TRANSFORMATION","dc2528cd":"# DATA PROCESS"}}