{"cell_type":{"97118d7b":"code","0202c56d":"code","1a2f6db0":"code","6889381f":"code","6ee1e9df":"code","9aa96640":"code","16993db0":"code","bd1ebd8e":"code","bb1da438":"code","c4848a5f":"code","c8caa3d4":"code","a8931b83":"code","e4abf0e4":"markdown"},"source":{"97118d7b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Data preprocessing\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0202c56d":"# Read the raw data\nauthor_papers_all_with_year = pd.read_csv('..\/input\/ee226-2021spring-problem2\/author_paper_all_with_year.csv')\npaper_reference = pd.read_csv('..\/input\/ee226-2021spring-problem2\/paper_reference.csv')\nprint(author_papers_all_with_year)\nprint(paper_reference)","1a2f6db0":"slice = author_papers_all_with_year['author_id'][(author_papers_all_with_year.paper_id < 3) & (author_papers_all_with_year.paper_id > 1)]\nprint(slice)\ntest = author_papers_all_with_year['paper_id'][(author_papers_all_with_year.author_id < 3) & (author_papers_all_with_year.author_id > 1)]\nprint(test)\n# print(type(slice))\n# print(len(slice))\n# print(slice.iloc[1])","6889381f":"# construct the pragh with nodes representing author, edge representing relation\n# node has attributes year and conference\nimport scipy.io as scio\n# construct the network by author_papers_all_with_year\nnetwork = {}\ntmp = [author_papers_all_with_year.at[0, 'author_id']]\npaper = author_papers_all_with_year.at[0, 'paper_id']\nfor i in range(1, 93230):\n    author_id = author_papers_all_with_year.at[i, 'author_id']\n    paper_id = author_papers_all_with_year.at[i, 'paper_id']\n    if paper_id == paper:\n        tmp.append(author_id)\n        continue\n    else:\n        counts = len(tmp)\n        if counts > 1:\n            for j in range(counts):\n                if tmp[j] in network:\n                    for k in tmp:\n                        if k != tmp[j] and k not in network[tmp[j]]:\n                            network[tmp[j]].append(k)\n                        else:\n                            continue\n                else:\n                    network[tmp[j]] = []\n                    for k in tmp:\n                        if k != tmp[j]:\n                            network[tmp[j]].append(k)\n                        else:\n                            continue\n            tmp = [author_id]\n            paper = paper_id\n        else:\n            tmp = [author_id]\n            paper = paper_id\ncounts = len(tmp)\nif counts > 1:\n    for j in range(counts):\n        if tmp[j] in network:\n            for k in tmp:\n                if k != tmp[j] and k not in network[tmp[j]]:\n                    network[tmp[j]].append(k)\n                else:\n                    continue\n        else:\n            network[tmp[j]] = []\n            for k in tmp:\n                if k != tmp[j]:\n                    network[tmp[j]].append(k)\n                else:\n                    continue\n# constuct the network by paper_reference\nfor i in range(24525):\n    paper_id = paper_reference.at[i, 'paper_id']\n    reference_id = paper_reference.at[i, 'reference_id']\n    authors_pre = author_papers_all_with_year['author_id'][(author_papers_all_with_year.paper_id < (paper_id + 1)) & (author_papers_all_with_year.paper_id > (paper_id - 1))]\n    length1 = len(authors_pre)\n    authors_aft = author_papers_all_with_year['author_id'][(author_papers_all_with_year.paper_id < (reference_id + 1)) & (author_papers_all_with_year.paper_id > (reference_id - 1))]\n    length2 = len(authors_aft)\n    for j in range(length1):\n        for k in range(length2):\n            author_pre = authors_pre.iloc[j]\n            author_aft = authors_aft.iloc[k]\n            if author_pre in network:\n                if author_aft in network[author_pre]:\n                    continue\n                else:\n                    network[author_pre].append(author_aft)\n            else:\n                network[author_pre] = []\n                network[author_pre].append(author_aft)\n#graph['network'] = network\n#print(network)\n# path = '.\/network.mat'\n# scio.savemat(path, network)","6ee1e9df":"import networkx as nx\n# dod = scio.loadmat('.\/graph2')\n# print(dod)\n#G=nx.from_dict_of_lists(network)\n# print(network)\nG = nx.DiGraph(network)\nnx.draw(G, node_size = 0.1)\nG1 = nx.DiGraph({1: [2], 2: [1], 3: [4, 5], 4: [3, 5]})\nprint(G1.edges())\n#nx.draw(G1)\nT = nx.DiGraph({1:[2],1:[1],4:[3,5]})\nprint(T.edges())\nsub = max(nx.weakly_connected_components(T), key=len)\nprint(max(nx.weakly_connected_components(T), key=len))\n# print(T.nodes())\nsub = (list(c for c in sub))\nprint(sub)\ntemp = nx.DiGraph()\n\nlst = list(nx.selfloop_edges(T))\nT.remove_edges_from(lst)\nprint(T.edges())\nfor i in T.edges():\n    if i[0] in sub:\n        temp.add_edge(i[0],i[1])\n\nprint(temp.nodes())","9aa96640":"from collections import defaultdict\n\ngraph = [[0, 1], [0, 2], [2, 3]]\ngra = defaultdict(set)\nfor cur in graph:\n    gra[cur[0]].add(cur[1])\nprint(gra)","16993db0":"import copy\nimport random\nimport networkx as nx\nimport numpy as np\nimport os\nimport sys\nimport scipy as sp\nimport scipy.io\nimport scipy.sparse\nfrom argparse import ArgumentParser\n\nnp.random.seed(10)\n\n#input part has changed\n# parser = ArgumentParser()\n# parser.add_argument('--train_percent', type=float,help='Split ratio. Between 0 and 1' ,default=0.8)\n# parser.add_argument('--num_folds', type=int,help='How many folds to create', default=5)\n# parser.add_argument('--file_name', type=str,help='Name of the file will be appended with the fold_id',default=\"fold\") \n\n# args = parser.parse_args()","bd1ebd8e":"def SampleNegativeEdges(graph, num_edges):\n#   \"\"\"Samples edges from compliment of graph.\"\"\"\n    random_negatives = set()\n    nodes = list(graph.nodes())\n    while len(random_negatives) < num_edges:\n        i1 = random.randint(0, len(nodes) - 1)\n        i2 = random.randint(0, len(nodes) - 1)\n        if i1 == i2:\n            continue\n        if i1 > i2:\n            i1, i2 = i2, i1\n        n1 = nodes[i1]\n        n2 = nodes[i2]\n        if graph.has_edge(n1, n2):\n            continue\n        random_negatives.add((n1, n2))\n    \n    return random_negatives","bb1da438":"def MakeDirectedNegatives(positive_edges):\n#   \"\"\" Reverse the positive set and create negative edges\"\"\"\n    positive_set = set([(u, v) for (u, v) in list(positive_edges)])\n    directed_negatives = []\n    for (u, v) in positive_set:\n        if (v, u) not in positive_set:\n            directed_negatives.append((v, u))\n    return np.array(directed_negatives, dtype='int32')","c4848a5f":"def splitDiGraphToTrainTest(di_graph, train_ratio, is_undirected=True):\n    # Split the graph to train and test graphs\n    train_digraph = di_graph.copy()\n    test_digraph = di_graph.copy()\n    node_num = di_graph.number_of_nodes()\n    edges = [e for e in di_graph.edges()]\n    \n    for (st, ed) in edges:\n        if(is_undirected and st >= ed):\n            continue\n        if(np.random.uniform() <= train_ratio):\n            test_digraph.remove_edge(st, ed)\n            if(is_undirected):\n                test_digraph.remove_edge(ed, st)\n        else:\n            train_digraph.remove_edge(st, ed)\n            if(is_undirected):\n                train_digraph.remove_edge(ed, st)\n    # If trai graph not connected, then take the largest weakly connected component            \n    if not nx.is_connected(train_digraph.to_undirected()):\n\n        sub = max(\n            nx.weakly_connected_components(train_digraph),\n            key=len\n        )\n        subgraph = nx.DiGraph()\n        temp = list(c for c in train_digraph)\n        for i in train_digraph.edges():\n            if i[0] in temp:\n                subgraph.add_edge(i[0],i[1])\n                \n        tdl_nodes = subgraph.nodes()\n        tdl_test_nodes = test_digraph.nodes()\n        # Remove nodes not present in train graph, from the test graph\n        tdl_nodes = list(set(tdl_nodes) & set(tdl_test_nodes))\n        \n        nodeListMap = dict(zip(tdl_nodes, range(len(tdl_nodes))))\n        \n        nx.relabel_nodes(subgraph, nodeListMap, copy=False)\n        test_digraph = test_digraph.subgraph(tdl_nodes)\n        test_digraph_1 =  nx.DiGraph(test_digraph)\n        nx.relabel_nodes(test_digraph_1, nodeListMap, copy=False)\n        return (train_digraph, test_digraph_1)\n\n    return (train_digraph, test_digraph)","c8caa3d4":"\ndef main():\n  \n  for fold_id in range(5):\n    print(\"Fold_{}\".format(fold_id))\n    file_name = \"fold\"+'_'+str(fold_id)+'.mat'\n\n    \n    G = nx.DiGraph(network)\n    graph = G\n    lst = list(nx.selfloop_edges(G))\n    graph.remove_edges_from(lst)\n    train_graph, test_graph = splitDiGraphToTrainTest(graph,train_ratio=0.8,is_undirected=False)\n    # Split graph into test and train\n    \n\n\n    data_dict={}\n    data_dict['train_network'] = nx.to_scipy_sparse_matrix(train_graph).astype(np.float64)  \n    data_dict['test_network'] = nx.to_scipy_sparse_matrix(test_graph).astype(np.float64)\n    data_dict['network'] = ((data_dict['train_network']+data_dict['test_network'])!=0).astype(np.float64)\n    graph = nx.from_scipy_sparse_matrix(data_dict['network'])\n\n#     if(not args.directed):\n      \n#       train_graph_undirected = train_graph.to_undirected()\n#       test_graph_undirected = test_graph.to_undirected()\n      \n#       test_edges = test_graph_undirected.edges()\n#       train_edges = train_graph_undirected.edges() \n#     else:\n    test_edges = test_graph.edges()\n    train_edges = train_graph.edges()\n\n    data_dict['positive_train_edges'] = np.array(train_edges,dtype=np.int32)\n    data_dict['positive_test_edges'] = np.array(test_edges,dtype=np.int32)\n\n\n\n    random_negatives = list(\n        SampleNegativeEdges(graph, len(test_edges) + len(train_edges)))\n    random.shuffle(random_negatives)\n\n    test_negatives = random_negatives[:len(test_edges)]\n  \n    train_eval_negatives = random_negatives[len(test_edges):]\n\n    test_negatives = np.array(test_negatives, dtype='int32')\n    test_edges = np.array(test_edges, dtype='int32')\n    train_edges = np.array(train_edges, dtype='int32')\n    train_eval_negatives = np.array(train_eval_negatives, dtype='int32')\n\n    data_dict['negative_train_edges'] = train_eval_negatives\n    \n    \n\n#     if args.directed:\n#       # If graph is directed, then add 10% - reversed edges to negative set\n    test_edges_size = len(test_negatives)\n    print(test_edges_size)\n    normal_negatives_size = int(0.9*test_edges_size)\n    reversed_negatives_size = int(0.1*test_edges_size)\n    np.random.shuffle(test_negatives)\n    normal_negatives = test_negatives[:normal_negatives_size]\n    np.random.shuffle(train_edges) \n    reversed_negatives = MakeDirectedNegatives(train_edges[:reversed_negatives_size])\n    print(reversed_negatives)\n    print(normal_negatives)\n    all_negatives = np.concatenate([reversed_negatives, normal_negatives], axis=0)\n    data_dict['negative_test_edges'] = all_negatives\n    data_dict['directed'] = True\n          \n#     else:\n#       data_dict['negative_test_edges'] = test_negatives\n#       data_dict['directed'] = False\n    out_dir = \"..\/output\/test\/\"\n    sp.io.savemat(os.path.join(output_dir, file_name),data_dict)","a8931b83":"if __name__ == '__main__':\n      main()","e4abf0e4":"Create link-prediction splits.(8-2)."}}