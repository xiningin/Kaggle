{"cell_type":{"1ec1e725":"code","144e5594":"code","de145def":"code","a14c238d":"code","e5c63721":"code","b3fc98ca":"code","2f57d8ce":"code","eec7c792":"code","259821d6":"code","a92b6544":"code","ca6596da":"code","72199f43":"code","f6fc0266":"code","08b93b6d":"code","b7704856":"code","a3ece1b6":"markdown","5245fc24":"markdown","9b5000f4":"markdown","200fc21b":"markdown","1e14ea55":"markdown","30bf1dff":"markdown","7ce54e04":"markdown"},"source":{"1ec1e725":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport tensorflow.keras\nfrom tensorflow.keras.layers import Conv2D, Dropout, MaxPool2D, AvgPool2D, Add, Dense \nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nimport warnings\nwarnings.warn(\"ignore\")\nimport os\nos.chdir('..\/')\nos.listdir('input')","144e5594":"from keras.preprocessing.image import load_img, img_to_array\nimport os\n\ndef convert(path,y):\n    array=[]\n    img_cat = []\n    for img_path in os.listdir(path):\n        img = load_img(path + img_path, target_size=(150,150))\n        img = img_to_array(img)\n        img = img\/255.\n        array.append(img)\n        img_cat.append(y)\n    return np.array(array), np.array(img_cat)","de145def":"trainX_building, trainY_building  = convert(\"input\/intel-image-classification\/seg_train\/seg_train\/buildings\/\",0)\ntrainX_forest,trainY_forest  = convert(\"input\/intel-image-classification\/seg_train\/seg_train\/forest\/\",1)\ntrainX_glacier,trainY_glacier  = convert(\"input\/intel-image-classification\/seg_train\/seg_train\/glacier\/\",2)\ntrainX_mount,trainY_mount  = convert(\"input\/intel-image-classification\/seg_train\/seg_train\/mountain\/\",3)\ntrainX_sea,trainY_sea  = convert(\"input\/intel-image-classification\/seg_train\/seg_train\/sea\/\",4)\ntrainX_street,trainY_street  = convert(\"input\/intel-image-classification\/seg_train\/seg_train\/street\/\",5)\n\nprint('train building shape ', trainX_building.shape, trainY_building.shape) \nprint('train forest', trainX_forest.shape ,trainY_forest.shape)\nprint('train glacier', trainX_glacier.shape,trainY_glacier.shape)\nprint('train mountain', trainX_mount.shape, trainY_mount.shape)\nprint('train sea',     trainX_sea.shape, trainY_sea.shape)\nprint('train street', trainX_street.shape ,trainY_street.shape)","a14c238d":"X_train= np.concatenate((trainX_building,trainX_forest, trainX_glacier,trainX_mount, trainX_sea,trainX_street),axis=0)\ny_train= np.concatenate((trainY_building,trainY_forest, trainY_glacier,trainY_mount, trainY_sea,trainY_street),axis=0)","e5c63721":"testX_building, testY_building  = convert(\"input\/intel-image-classification\/seg_test\/seg_test\/buildings\/\",0)\ntestX_forest,testY_forest  = convert(\"input\/intel-image-classification\/seg_test\/seg_test\/forest\/\",1)\ntestX_glacier,testY_glacier  = convert(\"input\/intel-image-classification\/seg_test\/seg_test\/glacier\/\",2)\ntestX_mount,testY_mount  = convert(\"input\/intel-image-classification\/seg_test\/seg_test\/mountain\/\",3)\ntestX_sea,testY_sea  = convert(\"input\/intel-image-classification\/seg_test\/seg_test\/sea\/\",4)\ntestX_street,testY_street  = convert(\"input\/intel-image-classification\/seg_test\/seg_test\/street\/\",5)\n\nprint('test building shape ', testX_building.shape, testY_building.shape) \nprint('test forest', testX_forest.shape ,testY_forest.shape)\nprint('test glacier', testX_glacier.shape,testY_glacier.shape)\nprint('test mountain', testX_mount.shape, testY_mount.shape)\nprint('test sea',     testX_sea.shape, testY_sea.shape)\nprint('test street', testX_street.shape ,testY_street.shape)","b3fc98ca":"X_test= np.concatenate((testX_building,testX_forest, testX_glacier,testX_mount, testX_sea,testX_street),axis=0)\ny_test= np.concatenate((testY_building,testY_forest, testY_glacier,testY_mount, testY_sea,testY_street),axis=0)","2f57d8ce":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","eec7c792":"from tensorflow.keras.utils import to_categorical\n\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\ny_train.shape,y_test.shape\ny_test[1]","259821d6":"from tensorflow.keras.layers import Input,Dropout, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\nfrom tensorflow.keras.models import Model, load_model,Sequential\nfrom tensorflow.keras.initializers import glorot_uniform","a92b6544":"def identity_block(X, f, filters, stage, block):\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    # Retrieve Filters\n    F1, F2, F3 = filters\n\n    # Save the input value. We'll need this later to add back to the main path. \n    X_shortcut = X\n\n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X","ca6596da":"def convolutional_block(X, f, filters, stage, block, s = 2):\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    \n    ##### SHORTCUT PATH ####\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","72199f43":"\ndef ResNet50(input_shape = (150, 150, 3), classes = 6):   \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n    # Stage 3\n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4\n    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5\n    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    # AVGPOOL.\n    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n\n    # output layer\n    X = Flatten()(X)\n    X = Dropout(0.3)(X)\n    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model","f6fc0266":"model = ResNet50(input_shape = (150, 150, 3), classes = 6)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","08b93b6d":"model.fit(X_train, y_train, epochs = 50, batch_size = 64,validation_data=(X_test, y_test), shuffle=True)","b7704856":"model.save('\/my_model.h5')\nmodel.evaluate(X_test, y_test)","a3ece1b6":"# 2) modeling ResNet","5245fc24":"# ResNet","9b5000f4":"# 3) Training","200fc21b":"upvote if find anything helpful","1e14ea55":"## 1.1) train set","30bf1dff":"## 1.2) test set","7ce54e04":"# 1) convert image to array"}}