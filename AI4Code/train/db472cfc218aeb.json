{"cell_type":{"c36e3384":"code","5eac63e1":"code","49dc9107":"code","0da168e2":"code","e050a19b":"code","b619814f":"code","9d29b645":"code","2a50b3bf":"code","b9ccae9e":"code","7a6a65fa":"code","d86e0697":"code","a200a8ac":"code","55b2200b":"code","fbbec927":"code","b0fd08fb":"code","5cda2c9d":"code","7dde558a":"code","5557ad71":"code","79134eab":"code","8cbdd229":"markdown","3e0eed99":"markdown","54e35a17":"markdown","c6528e65":"markdown","f375dca2":"markdown","8e8c7db1":"markdown","6516fa1f":"markdown","b2a3c3d6":"markdown","82b880db":"markdown","c4971614":"markdown"},"source":{"c36e3384":"import numpy as np\nimport tensorflow as tf\nimport os\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5eac63e1":"# Model \/ data parameters\nnum_classes = 10\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n\n# Scale images to the [0, 1] range\nx_train = x_train.astype(\"float32\")\nx_test = x_test.astype(\"float32\") \nprint(\"x_train shape:\", x_train.shape)\nprint(x_train.shape[0], \"train samples\")\nprint(x_test.shape[0], \"test samples\")\n\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","49dc9107":"x_train[0].shape","0da168e2":"plt.imshow(x_train[0], cmap='gray')\nplt.show()","e050a19b":"def create_mlp():\n    input_ = layers.Input(shape=(28,28))\n    flatten = layers.Flatten()(input_)\n    hidden1 = keras.layers.Dense(256, activation=\"relu\")(flatten)\n    hidden2 = keras.layers.Dense(128, activation=\"relu\")(hidden1)\n    hidden3 = keras.layers.Dense(64, activation=\"relu\")(hidden2)\n    output = keras.layers.Dense(10, activation=\"softmax\")(hidden3)\n    model = keras.Model(inputs=input_, outputs=output)\n    return model\nmodel = create_mlp()","b619814f":"model.summary()","9d29b645":"keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)","2a50b3bf":"batch_size = 128\nepochs = 15\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)","b9ccae9e":"score = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])","7a6a65fa":"# adding a channel for cnn's\nx_train = np.expand_dims(x_train, -1)\nx_test = np.expand_dims(x_test, -1)","d86e0697":"def create_cnn():\n    input_ = layers.Input(shape=(28,28,1))\n    conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(input_)\n    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(pool1)\n    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n    flatten = layers.Flatten()(pool2)\n    output = layers.Dense(10, activation=\"softmax\")(flatten)\n    model = keras.Model(inputs=input_, outputs=output)\n    return model\nmodel2 = create_cnn()","a200a8ac":"model2.summary()","55b2200b":"keras.utils.plot_model(model2, \"my_first_model_with_shape_info.png\", show_shapes=True)","fbbec927":"batch_size = 128\nepochs = 15\n\nmodel2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\nmodel2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)","b0fd08fb":"score = model2.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])","5cda2c9d":"layers = model2.layers \nfilters, biases = layers[1].get_weights()","7dde558a":"fig1=plt.figure(figsize=(8, 12))\ncolumns = 4\nrows = 8\nn_filters = columns * rows\nfor i in range(1, n_filters +1):\n    f = filters[:, :, :, i-1]\n    fig1 =plt.subplot(rows, columns, i)\n    fig1.set_xticks([])  \n    fig1.set_yticks([])\n    plt.imshow(f[:, :, 0])\nplt.show()  ","5557ad71":"def convolution2d(image, kernel, bias):\n    m, n = kernel.shape\n    if (m == n):\n        y, x = image.shape[:-1]\n        y = y - m + 1\n        x = x - m + 1\n        new_image = np.zeros((y,x))\n        for i in range(y):\n            for j in range(x):\n                new_image[i][j] = np.sum(image[i:i+m, j:j+m]*kernel)\n    return new_image\n\nkernel = filters[:, :, 0, 7]\nconv_1_img = convolution2d(x_train[0], kernel, biases)\nplt.imshow(conv_1_img)\nplt.show()","79134eab":"layers = model2.layers \nfilters, biases = layers[3].get_weights()\n\nimport matplotlib.pyplot as plt\nfig1=plt.figure(figsize=(8, 12))\ncolumns = 8\nrows = 8\nn_filters = columns * rows\nfor i in range(1, n_filters +1):\n    f = filters[:, :, :, i-1]\n    fig1 =plt.subplot(rows, columns, i)\n    fig1.set_xticks([])  \n    fig1.set_yticks([])\n    plt.imshow(f[:, :, 0])\nplt.show()  ","8cbdd229":"# MLP Evaluation","3e0eed99":"# Importing Packages","54e35a17":"# Loading the Dataset and Preprocessing","c6528e65":"CNN Evaluation","f375dca2":"# MLP Training","8e8c7db1":"# CNN Model","6516fa1f":"# MLP Model","b2a3c3d6":"# CNN Training","82b880db":"# CNN Summary","c4971614":"# MLP Model Summary"}}