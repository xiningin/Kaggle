{"cell_type":{"7721b1a7":"code","08b7fe20":"code","611a3830":"code","de606efc":"code","3a1b729f":"code","74144521":"code","4498babc":"code","0279e0d5":"code","dc32680c":"code","344a3239":"code","d83297e7":"code","950dc68b":"code","fd59be65":"code","0426778f":"code","c752808a":"code","1c4ca8c8":"code","0c3f4029":"code","48e68086":"code","f79da95e":"code","a5f14b32":"code","d2107b2b":"code","e6cfb14b":"markdown","564d5351":"markdown","901c1197":"markdown","7b5f45f9":"markdown","a9046bd4":"markdown","c1122483":"markdown","d558b4a7":"markdown","8a64793b":"markdown","896ad124":"markdown","33ea134c":"markdown","209078c4":"markdown","2b1e2d36":"markdown","6df518aa":"markdown","1beaa086":"markdown","fcd6087b":"markdown","a148156e":"markdown","5a9c85cf":"markdown","b78f19dc":"markdown","5d9aee8f":"markdown","7c873e62":"markdown"},"source":{"7721b1a7":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler\n\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Input, Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport os","08b7fe20":"FilePath = \"..\/input\/skin-cancer-mnist-ham10000\/hmnist_28_28_RGB.csv\"\ndf = pd.read_csv(FilePath)","611a3830":"df","de606efc":"label = df[\"label\"]\ndf = df.drop(columns=[\"label\"]) ","3a1b729f":"plt.figure(figsize = (8,6))\nsns.countplot(label)","74144521":"X_train , X_test , y_train , y_test = train_test_split(df , label , test_size = 0.2)","4498babc":"sampler = RandomOverSampler()\nX_train, y_train = sampler.fit_resample(X_train, y_train)\n\nplt.figure(figsize = (8,6))\nsns.countplot(y_train)","0279e0d5":"\nX_train = np.array(X_train).reshape(-1,28,28,3)\nX_test = np.array(X_test).reshape(-1,28,28,3)","dc32680c":"fig, axes = plt.subplots(2, 2)\nfig.set_size_inches(6, 6)\nk = 0 \nfor i in range(2):\n    for j in range(2):\n        axes[i, j].imshow(X_train[k])\n        k += 1\nplt.tight_layout()","344a3239":"y_train = tf.keras.utils.to_categorical(y_train)\ny_test = tf.keras.utils.to_categorical(y_test)","d83297e7":"from keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))\n","950dc68b":"model = Sequential([\n            Input(shape = [28,28,3]),\n            Conv2D(64 , (3,3) , activation='relu',padding='same'),\n            MaxPooling2D(),\n            BatchNormalization(),\n            Conv2D(128 , (3,3) , activation='relu',padding='same'),\n            Conv2D(128 , (3,3) , activation='relu',padding='same'),\n            MaxPooling2D(),\n            BatchNormalization(), \n            Conv2D(256 , (3,3) , activation='relu',padding='same'),\n            Conv2D(256 , (3,3) , activation='relu',padding='same'),\n            MaxPooling2D(),\n            BatchNormalization(),\n            Conv2D(512 , (3,3) , activation='relu',padding='same'),\n            Conv2D(512 , (3,3) , activation='relu',padding='same'),\n            MaxPooling2D(),\n#             BatchNormalization(),\n#             Conv2D(512 , (3,3) , activation='relu',padding='same'),\n#             Conv2D(512 , (3,3) , activation='relu',padding='same'),\n#             MaxPooling2D(),\n            Flatten(),\n            Dropout(.5),\n            Dense(256, activation = 'relu'),\n            BatchNormalization(),\n            Dropout(.5),\n            Dense(128, activation = 'relu'),\n            BatchNormalization(),\n            Dropout(.5),\n            Dense(64, activation = 'relu'),\n            BatchNormalization(),\n            Dense(32, activation = 'relu'),\n            BatchNormalization(),\n            Dense(7, activation = 'softmax'),\n])\n\nmodel.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=[f1_m, 'accuracy'])","fd59be65":"#make model folder model\nmodel._name = 'skincancer_CNN'\nmodel_save_path = \".\"\nif not os.path.exists(model_save_path):\n    os.mkdir(model_save_path)","0426778f":"early_stop = EarlyStopping(patience=10, verbose=1, monitor='val_f1_m', mode='max')\nreduce_lr =  ReduceLROnPlateau(monitor='val_f1_m', factor=0.1, patience=7, min_delta=1e-4, mode='max')\ncheckpoint = ModelCheckpoint(os.path.join(model_save_path, model.name+\".h5\"), save_weights_only=True,\n                             verbose=1, save_best_only=True, monitor='val_f1_m', mode='max')","c752808a":"model.summary()","1c4ca8c8":"history = model.fit(X_train,\n                    y_train,\n                    epochs=50,\n                    batch_size=128,\n                    steps_per_epoch=len(X_train)\/\/128,\n                    validation_data= (X_test, y_test),\n                    callbacks=[early_stop, checkpoint, reduce_lr])","0c3f4029":"f1 = history.history[\"f1_m\"]\nval_f1 = history.history[\"val_f1_m\"]\nepochs = range(1, len(val_f1) + 1)\n\nplt.plot(epochs, f1, color=\"blue\", label=\"training acc\")\nplt.plot(epochs, val_f1, color=\"red\", label=\"training val_acc\")\nplt.legend()\nplt.xlabel(\"epoch\")\nplt.ylabel(\"accuracy\")\nplt.title(\"Training and Validation F1-Score\")\n# plt.savefig(f\".\/balanced\/models\/{model._name}_f1_training_plot.jpg\")\nplt.show()","48e68086":"acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nepochs = range(1, len(val_acc) + 1)\n\nplt.plot(epochs, acc, color=\"blue\", label=\"training acc\")\nplt.plot(epochs, val_acc, color=\"red\", label=\"training val_acc\")\nplt.legend()\nplt.xlabel(\"epoch\")\nplt.ylabel(\"accuracy\")\nplt.title(\"Training and Validation Accuracy\")\n# plt.savefig(f\".\/balanced\/models\/{model._name}_f1_training_plot.jpg\")\nplt.show()","f79da95e":"loss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\nepochs = range(1, len(val_acc) + 1)\n\nplt.plot(epochs, loss, color=\"blue\", label=\"training loss\")\nplt.plot(epochs, val_loss, color=\"red\", label=\"training val_loss\")\n\nplt.legend()\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.title(\"Training and Validation Loss\")\n\nplt.show()","a5f14b32":"# Konversi model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()","d2107b2b":"with tf.io.gfile.GFile('model.tflite', 'wb') as f:\n  f.write(tflite_model)","e6cfb14b":"Plot label distribution","564d5351":"Splitting dataset into train and test set","901c1197":"Encode the labels, so we can use them for training\n\nThey will look like this: [0, 1, 0, 0, 0, 0, 0] to represent label 1 (0-based indexing)","7b5f45f9":"Custom metrics, F1-Score","a9046bd4":"Image examples after we converted the dataframe into 28x28x3 matrices","c1122483":"**THAT'S IT!!**, Please give me some suggestions or tips to improve this models, thanks :)","d558b4a7":"let's look at the dataframe, each column represents a pixel value, we have to convert them into 28x28x3 before throw them into models","8a64793b":"Importing libraries","896ad124":"Load dataset","33ea134c":"# Data Preparation","209078c4":"# Plot Training","2b1e2d36":" Reshape the data so it can be thrown into the model","6df518aa":"Let's make a skincancer classifier!!\n\nYou can see the dataset [**here**](https:\/\/www.kaggle.com\/kmader\/skin-cancer-mnist-ham10000), this notebook is final assignment of [**Belajar Pengembangan Machine Learning**](https:\/\/www.dicoding.com\/academies\/185) Course on Dicoding, created by [**Satria Kemal**](https:\/\/www.dicoding.com\/users\/codesigma)","1beaa086":"# Convert to TFLite","fcd6087b":"Imbalanced dataset might hurt the performance of our models, so we have to make them balanced. \n\nOne of the methods can we use is oversamping.\n","a148156e":"Callbacks","5a9c85cf":"For this problem, this architecture works best so far","b78f19dc":"# Training","5d9aee8f":"# Modelling","7c873e62":"Create model save path for checkpoint callback and saving models"}}