{"cell_type":{"92dc120d":"code","abcb9b12":"code","8017d591":"code","9c1563a6":"code","f3eef4ee":"code","68d83b8b":"code","7d649169":"code","35228d21":"code","b37a9978":"code","75a8bdc8":"code","060ea0d6":"code","e09c5363":"code","84564b23":"code","6bf13f05":"code","cfbd9115":"code","fe338773":"code","0a4e390d":"code","f366de2f":"code","4f3ecca0":"code","53ef5e93":"code","9beea347":"code","cee99b69":"code","339b3b73":"code","b372d968":"code","faa1d38a":"code","474c1111":"code","5e9f1158":"code","0b723576":"code","0cbe60d1":"code","988ea276":"code","95689fac":"code","36e76174":"code","3da8de7a":"code","f4e516bf":"code","d42219f3":"code","3d0b8c25":"code","ab5f6091":"code","8f318e34":"markdown","b7affdc1":"markdown","83c7b1f3":"markdown","fb1c69f0":"markdown","389acaf3":"markdown","dc88cc99":"markdown","687ef11e":"markdown","115bc23b":"markdown","5a4ca5d2":"markdown","49fd0f18":"markdown","9b51bd9c":"markdown","5be4aee4":"markdown","5629c38f":"markdown","c6e48029":"markdown"},"source":{"92dc120d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n","abcb9b12":"train_data=pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/train.csv\")\ntest_data=pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/test.csv\")","8017d591":"print(\"training data shape:\",train_data.shape)","9c1563a6":"print(\"testing data shape:\",test_data.shape)","f3eef4ee":"print(\"training data head:\\n\",train_data.head())","68d83b8b":"print(\"testing data head:\\n\",test_data.head())","7d649169":"train_data.columns.to_list()","35228d21":"test_data.columns.to_list()","b37a9978":"train_data['COVID-19 Deaths'].value_counts()","75a8bdc8":"train_data.describe()","060ea0d6":"test_data.describe()","e09c5363":"train_data.dtypes","84564b23":"test_data.dtypes","6bf13f05":"import matplotlib.pyplot as plt","cfbd9115":"fig, ax = plt.subplots(figsize=(12,6))\ntrain_data.plot('Start Date','COVID-19 Deaths', ax=ax)\n","fe338773":"import missingno\nmissingno.matrix(train_data,figsize=(25,10))","0a4e390d":"# drop rows with null values for covid 19 deaths and total deaths\ntrain_data = train_data.dropna(subset=[\"COVID-19 Deaths\"])\ntrain_data = train_data.dropna(subset=[\"Total Deaths\"])","f366de2f":"#check that values got removed\nmissingno.matrix(train_data,figsize=(25,10))","4f3ecca0":"import seaborn as sns\nsns.boxplot(x=train_data[\"Start Date\"],y=train_data[\"COVID-19 Deaths\"])","53ef5e93":"# Find the 95th quantile\nquantile = train_data['COVID-19 Deaths'].quantile(0.995)\n\n# Trim the outliers\ntrain_data = train_data[train_data['COVID-19 Deaths'] < quantile]","9beea347":"# get rid of values from before march 2020. there is no valuable covid data from before then. \n# but first, convert start date to datetime objects\ntrain_data[\"Start Date\"]=pd.to_datetime(train_data[\"Start Date\"]).dt.strftime(\"%Y%m%d\")\ntest_data[\"Start Date\"]=pd.to_datetime(test_data[\"Start Date\"]).dt.strftime(\"%Y%m%d\")\n\n#get rid of first few months of 2020 when covid data doesnt matter\ntrain_data=train_data[train_data[\"Start Date\"]>=\"20200301\"]\n\nimport seaborn as sns\nplt.figure(figsize = (15,8))\nsns.barplot(x='Start Date', y = 'COVID-19 Deaths',data = train_data)\n","cee99b69":"#now, turn the start date column to ints\ntrain_data[\"Start Date\"]=train_data[\"Start Date\"].astype(int)\ntest_data[\"Start Date\"]=test_data[\"Start Date\"].astype(int)\n\n#create start date squared column to make it curvilinear\ntrain_data[\"Start Date Squared\"]=train_data[\"Start Date\"]**2\ntest_data[\"Start Date Squared\"]=test_data[\"Start Date\"]**2\n","339b3b73":"import seaborn as sns\nsns.FacetGrid(train_data, col='Race and Hispanic Origin Group', row='Age Group').map(sns.regplot, 'Start Date', 'COVID-19 Deaths')","b372d968":"# we need to get rid of columns\/features that will not be beneficial to building our model\n# to predict covid-19 deaths. we also need to get rid of redundant data and highly correlated\n# columns that will do more bad than good for training our model.\n\n#include only 'HHS Region'=='United States' and 'Group'='By Week' in the training data\n#so as to not include redundant data\ntrain_data = train_data[train_data['HHS Region']==\"United States\"]\ntrain_data = train_data[train_data['Group']==\"By Week\"]\ntest_data = test_data[test_data['HHS Region']==\"United States\"]\ntest_data = test_data[test_data['Group']==\"By Week\"]\n\n#keep only start date, start date squared, and total deaths as features for training our model\ny = train_data[\"COVID-19 Deaths\"]\nfeatures = ['Start Date','Start Date Squared','Total Deaths']\n\n#one-hot encoding pandas method get dummies\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n","faa1d38a":"from math import sqrt\nimport numpy as np\nimport statsmodels.api as sm \nfrom sklearn.metrics import accuracy_score, mean_squared_error, roc_auc_score, f1_score\nfrom sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit, GridSearchCV\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n#create time series split object\ntscv = TimeSeriesSplit(n_splits = 10)\n\n#params for grid search\nn_components = list(range(1,X.shape[1]+1,1))\nnormalize = [True, False]\nselection = [\"cyclic\", \"random\"]","474c1111":"#make OLS model\n#make ordinary least squares linear regression pipeline and conduct gridsearchcv\npipe = Pipeline(steps=[('std_scl', StandardScaler()),\n                           ('pca', PCA()),\n                           ('linear', LinearRegression())])\nparameters = dict(pca__n_components=n_components,\n                      linear__normalize=normalize)\nols_reg = GridSearchCV(pipe, parameters)\nols_reg.fit(X, y)","5e9f1158":"#make ridge model\n#make ridge regression pipeline and conduct gridsearchcv\npipe = Pipeline(steps=[(\"std_slc\",  StandardScaler()),\n                           (\"pca\", PCA()),\n                           (\"ridge\", Ridge())])\nsolver = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n    \nparameters = dict(pca__n_components=n_components,\n                      ridge__normalize=normalize,\n                      ridge__solver=solver)\n\nridge_reg = GridSearchCV(pipe, parameters)\nridge_reg.fit(X, y)","0b723576":"# lasso regression\n# build and train a Lasso Regression model\npipe = Pipeline(steps=[(\"std_slc\", StandardScaler()),\n                           (\"pca\", PCA()),\n                           (\"lasso\", Lasso())])\n\nparameters = dict(pca__n_components=n_components,\n                      lasso__normalize=normalize,\n                      lasso__selection=selection)\nlasso_reg = GridSearchCV(pipe, parameters)\nlasso_reg.fit(X, y)","0cbe60d1":"# elastic regression\n# build and train an Elastic Regression model\npipe = Pipeline(steps=[('stc_slc', StandardScaler()),\n                           ('pca', PCA()),\n                           ('elasticnet', ElasticNet())])\nparameters = dict(pca__n_components=n_components,\n                    elasticnet__normalize=normalize,\n                    elasticnet__selection=selection)\nelastic_reg = GridSearchCV(pipe, parameters)\nelastic_reg.fit(X, y)","988ea276":"# split validation data\nols_rmse = []\nrr_rmse = []\nlr_rmse = []\nen_rmse = []\n\n#local cross validation\nfor train_index, test_index in tscv.split(X):\n    X_cv_train, y_cv_train = X.iloc[train_index], y.iloc[train_index]\n    X_cv_test, y_cv_test = X.iloc[test_index], y.iloc[test_index]\n    \n    ols=ols_reg.fit(X_cv_train, y_cv_train)\n    rr=ridge_reg.fit(X_cv_train, y_cv_train)\n    lr=lasso_reg.fit(X_cv_train, y_cv_train)\n    en=elastic_reg.fit(X_cv_train, y_cv_train)\n    \n    ols_pred = ols.predict(X_cv_test)\n    rr_pred = rr.predict(X_cv_test)\n    lr_pred = lr.predict(X_cv_test)\n    en_pred = en.predict(X_cv_test)\n    \n    #get rmse scores for predictions and append them to the arrays\n    ols_rmse.append(np.sqrt(mean_squared_error(y_cv_test, ols_pred)))\n    rr_rmse.append(np.sqrt(mean_squared_error(y_cv_test, rr_pred)))\n    lr_rmse.append(np.sqrt(mean_squared_error(y_cv_test, lr_pred)))\n    en_rmse.append(np.sqrt(mean_squared_error(y_cv_test, en_pred)))\n\nprint(\"ols rmse: \", np.mean(ols_rmse))\nprint(\"rr rmse: \", np.mean(rr_rmse))\nprint(\"lr rmse: \", np.mean(lr_rmse))\nprint(\"en rmse: \", np.mean(en_rmse))\n\npd_ols=pd.DataFrame(ols_rmse)\npd_rr=pd.DataFrame(rr_rmse)\npd_lr=pd.DataFrame(lr_rmse)\npd_en=pd.DataFrame(en_rmse)\n\nprint(\"\\nDescribe of ordinary least squares model predictions:\")\nprint(pd_ols.describe())\nprint(\"\\nDescribe of ridge regression model predictions:\")\nprint(pd_rr.describe())\nprint(\"\\nDescribe of lasso regression model predictions:\")\nprint(pd_lr.describe())\nprint(\"\\nDescribe of elastic regression model predictions:\")\nprint(pd_en.describe())\n","95689fac":"import matplotlib as plt\nimport seaborn as sns\n\n#plotting the distributions\n#ols\nsns.set_theme(style=\"whitegrid\")\nsns.displot(pd_ols)","36e76174":"#ridge\nsns.displot(pd_rr)","3da8de7a":"#lasso\nsns.displot(pd_lr)\n","f4e516bf":"#elastic\nsns.displot(pd_en)","d42219f3":"#best_model = best model out of all the models i trained = ridge regression model\n#although the mean makes it seem that lasso would yield better predictions, ridge ended up\n#predicting better on the test data\nrr_pred = ridge_reg.predict(X_test)\nrr_pred=np.where(rr_pred< 0, 0,rr_pred).astype(int)\noutput = pd.DataFrame({'id': test_data.id, 'COVID-19 Deaths':rr_pred})\n\n#output target vector to file for submission\noutput.to_csv('submission.csv', index=False)","3d0b8c25":"output","ab5f6091":"#output target vector\nprint(output.to_string())","8f318e34":"## Elastic","b7affdc1":"# Exploratory Data Analysis","83c7b1f3":"## Check for outliers","fb1c69f0":"## Lasso","389acaf3":"We are predicting the covid-19 deaths column.","dc88cc99":"# Building Models","687ef11e":"# Loading data from the provided CSV files","115bc23b":"# Data Transformations\/Feature Engineering","5a4ca5d2":"As you can see, there are many missing values in covid-19 deaths and total deaths. There are also missing values in month, mmwr week, week-ending date and footnote but I will not be using those in my training, so there is no need to get rid of them.","49fd0f18":"## OLS","9b51bd9c":"## Check for missing data","5be4aee4":"# Select best model and output to submission.csv","5629c38f":"## Ridge","c6e48029":"## Dealing with missing data"}}