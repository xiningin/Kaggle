{"cell_type":{"8a459a2a":"code","c20f562e":"code","528be037":"code","fde6588a":"code","14f3c167":"code","d89e1c13":"code","9b82dcc1":"code","d1c0906b":"code","66f6b865":"code","9acf9ed9":"code","1c0566c1":"code","28e74162":"code","2424f186":"code","0342a4e0":"code","1fa3ac44":"code","a9d2a8bc":"markdown","7d752fd5":"markdown","af0f152d":"markdown","df2a5deb":"markdown","ec263238":"markdown","d4ca3966":"markdown","098f6a88":"markdown","fcfce44f":"markdown"},"source":{"8a459a2a":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.base import clone\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline","c20f562e":"df = pd.read_csv('https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/covtype\/covtype.data.gz', sep=',', header=None)[:50000]","528be037":"df.head(3)","fde6588a":"df.shape","14f3c167":"features = list(range(0, 54))\ntarget = 54\n\ndf = df[(df[target] == 1) | (df[target] == 2)]","d89e1c13":"cover_train, cover_test = train_test_split(df, test_size=0.5)\n\ncover_X_train, cover_y_train = cover_train[features], cover_train[target]\ncover_X_test, cover_y_test = cover_test[features], cover_test[target]","9b82dcc1":"scaler = StandardScaler()\ncover_X_train = scaler.fit_transform(cover_X_train)\ncover_X_test = scaler.transform(cover_X_test)","d1c0906b":"def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n    \"\"\"\n    Computes meta-features using the classifier.\n    \n    :arg clf: scikit-learn classifier\n    :args X_train, y_train: training set\n    :arg X_test: testing set\n    :arg cv: cross-validation folding\n    \"\"\"\n    X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n    for train_fold_index, predict_fold_index in cv.split(X_train):\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n        y_fold_train = y_train[train_fold_index]\n        \n        folded_clf = clone(clf)\n        folded_clf.fit(X_fold_train, y_fold_train)\n        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)[:, 1]\n    \n    meta_clf = clone(clf)\n    meta_clf.fit(X_train, y_train)\n    \n    X_meta_test = meta_clf.predict_proba(X_test)[:, 1]\n    \n    return X_meta_train, X_meta_test","66f6b865":"def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\n    \"\"\"\n    Generates metafeatures using a list of classifiers.\n    \n    :arg classifiers: list of scikit-learn classifiers\n    :args X_train, y_train: training set\n    :arg X_test: testing set\n    :arg cv: cross-validation folding\n    \"\"\"\n    features = [\n        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n        for clf in tqdm(classifiers)\n    ]\n    \n    stacked_features_train = np.vstack([\n        features_train for features_train, features_test in features\n    ]).T\n\n    stacked_features_test = np.vstack([\n        features_test for features_train, features_test in features\n    ]).T\n    \n    return stacked_features_train, stacked_features_test","9acf9ed9":"np.random.seed(42)","1c0566c1":"clf = GradientBoostingClassifier(n_estimators=300)\nclf.fit(cover_X_train, cover_y_train)\n\naccuracy_score(clf.predict(cover_X_test), cover_y_test)","28e74162":"cv = KFold(n_splits=10, shuffle=True)\n\nstacked_features_train, stacked_features_test = generate_meta_features([\n    LogisticRegression(C=0.001, penalty='l1', solver='liblinear', max_iter=5000),\n    LogisticRegression(C=0.001, penalty='l2', solver='liblinear', max_iter=5000),  \n    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n    GradientBoostingClassifier(n_estimators=300)\n], cover_X_train, cover_X_test, cover_y_train.values, cv)","2424f186":"total_features_train = np.hstack([cover_X_train, stacked_features_train])\ntotal_features_test = np.hstack([cover_X_test, stacked_features_test])","0342a4e0":"np.random.seed(42)\nclf = LogisticRegression(penalty='none', solver='lbfgs')\nclf.fit(stacked_features_train, cover_y_train)\naccuracy_score(clf.predict(stacked_features_test), cover_y_test)","1fa3ac44":"def compute_meta_feature_mean(clf, X_train, X_test, y_train, cv):\n    \"\"\"\n    This function calculates the features for the meta-classifier.\n    They are the probabilities of the classes when solving the multiclass classification problem.\n\n    :arg clf: classifier\n    :args X_train, y_train: training sample\n    :arg X_test: test sample features\n    :arg cv: class, folds (KFold)\n\n    :returns X_meta_train, X_meta_test: new features for training and test samples\n    \"\"\"\n    n_classes = len(np.unique(y_train))\n    X_meta_train = np.zeros((len(X_train), n_classes), dtype=np.float32)\n    X_meta_tests_array = []\n    splits = 0\n    \n    for train_fold_index, predict_fold_index in cv.split(X_train):\n        n_classes = len(np.unique(y_train))\n        X_meta_test = np.zeros((len(X_test), n_classes), dtype=np.float32)\n        splits += 1\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n        y_fold_train = y_train[train_fold_index]\n        \n        folded_clf = clone(clf)\n        folded_clf.fit(X_fold_train, y_fold_train)\n        \n        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n        \n        X_meta_tests_array.append(folded_clf.predict_proba(X_test))\n        print (X_meta_tests_array)\n    \n    meta_clf = clone(clf)\n    meta_clf.fit(X_train, y_train)\n    \n    X_meta_test = sum(X_meta_tests_array) \/ splits\n    \n    return X_meta_train, X_meta_test","a9d2a8bc":"Stacking is another way to combine several algorithms into one, which is often used both in solving real problems from the industrial sphere and in competitions on platforms like Kaggle.\nThe approach uses the concept of _base classifiers_, each of which is independently trained on some (possibly the same) set of features, as well as a meta-classifier_ that uses the predictions of the basic classifiers as features.\n\nTo avoid overfitting, we will split the training sample into folds..  \nFor example, folds when splitting into three parts:  \n``==*``  \n``=*=``  \n``*==``  \n\nThis is required in order to obtain new features (the responses of the algorithms at the first level) over the entire training set, i.e. the responses of the algorithm on those objects that were not used during training. In the example above, we will use the algorithm responses obtained on objects with asterisks. _Important_: on each fold, we train the algorithm again.","7d752fd5":"# Practice\nLet's analyze stacking in practice by analyzing the dataset describing the parameters that were taken from the satellite when photographing the Earth. We have 54 variables. For simplicity, we will consider two types of surfaces, so we reduce our problem to the problem of binary classification. Let's do some basic preprocessing using StandardScaler.","af0f152d":"We will train one gradient boosting in which we will use 300 algorithms. If we aggregate boosting with a random forest and two logistic regressions, we get a better result:","df2a5deb":"# Task \n### Implement a scheme where, instead, aggregation of responses of all trained on fold classifiers on a test sample is performed using averaging.\n## Explanation:\n\n1. Create X_meta_test, fill it with zeros (by analogy with X_meta_train);\n1. Further, at each step, where we train folded_clf.fit (X_fold_train, y_fold_train) and its predictions on X_fold_predict we push into X_meta_train [predict_fold_index], add one more line, where in X_meta_test we will add the predictions of the probabilities X foltest_clf on They can be added to each other at once, or many arrays can be saved, then at the end they will need to be added all together, and then divided by the number of splits (the number of arrays is equal to the number of splits in cross-validation);\n1. After the loop, all that remains is to average all these arrays - this will be our X_meta_test.","ec263238":"Stacking allows you to combine the answers of several first-level algorithms into one big answer using a new learning algorithm. To avoid overfitting, we will split the training sample into folds - splitting the training sample into several parts. On each fold, we train the algorithm again.","d4ca3966":"# Simplify task to binary classification","098f6a88":"# Stacking\n> Stacking is the aggregation of responses from machine learning models using another machine learning model. The approach uses the concept of basic models, each of which is trained independently of the others, and a meta-model, which uses the predictions of the basic models as features. \n\n## Staking rules:\n\n1. You need to train meta-models on new ones for basic data models. This avoids a data leak that appears when evaluating algorithms on a training set.\n1. You can use cross-validation approaches (split by fold, bootstrap) to get different models.\n1. Better to apply regressors to meta-models.\n1. It's better to start with a simple meta-model like linear regression. In the case of classification, to aggregate the probability of classes. This special case is called blending.\n1. Take models of various nature as basic models.\n1. Train the model not only on the true target, but also on the proxy target, for example, on an important feature that was identified during data mining.\n1. Stacking with a large number of levels with enough data, time and effort, which is rare in practice.\n\n","fcfce44f":"### So, we did algorithm when, for the test sample, the algorithm was retrained anew on the entire training sample. \n"}}