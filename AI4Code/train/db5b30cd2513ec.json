{"cell_type":{"174b12f1":"code","95c9381e":"code","0fc31ca4":"code","8a940c8e":"code","5dc2f0ce":"code","b0c1d9b3":"code","63124546":"code","4a35e3fb":"code","33abb04d":"code","8a00d523":"code","4bfa5b62":"code","25994246":"code","fda8567c":"code","877f5b21":"code","8570c22d":"code","5517242e":"code","8905b8aa":"code","25afe619":"code","f731619c":"code","d995918a":"code","d2b3a739":"code","54240729":"code","d88de81c":"code","d7814470":"code","3b0977b4":"code","1c3cab73":"code","cc91906b":"code","b703e6a6":"markdown","874e6d8f":"markdown","ff406a5f":"markdown","d474bf77":"markdown","dd7521a8":"markdown","2e9933b1":"markdown","db89744a":"markdown","7cab8954":"markdown","555ed4e8":"markdown","10a96109":"markdown","33ba3427":"markdown","3d0dd593":"markdown","b4b620d5":"markdown"},"source":{"174b12f1":"import pandas as pd #fornece ferramentas de an\u00e1lise de dados e estruturas de dados de alta performance\nimport numpy as np #usada principalmente para realizar c\u00e1lculos em Arrays Multidimensionais\nimport matplotlib.pyplot as plt #biblioteca com recursos para a gera\u00e7\u00e3o de gr\u00e1ficos 2D a partir de arrays.\nimport seaborn as sns #biblioteca que ajuda a melhorar a exibi\u00e7\u00e3o dos dados junto ao matplotlib\n\n#Parametros extras para seaborn \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set(style=\"white\", color_codes=True)\n\n#Carregando e exibi\u00e7\u00e3o do conjuto de treinamento \n\niris_train = \"iris-train.csv\"\ndf_iris_train = pd.read_csv(\"..\/input\/iris-train.csv\", index_col='Id')\npd.set_option('precision', 2)\ndf_iris_train.head()\n","95c9381e":"#Explorando o conjunto de treinamento\n\nprint(df_iris_train['Species'].value_counts())","0fc31ca4":"#N\u00famero de linhas e colunas\n\ndf_iris_train.shape","8a940c8e":"#Quais as colunas e respectivo dados de teste\n\ndf_iris_train.info()","5dc2f0ce":"#sum\u00e1rio estat\u00edstico das caracter\u00edsticas num\u00e9ricas\n\ndf_iris_train.describe()","b0c1d9b3":"#quais as correla\u00e7\u00f5es entre as caracter\u00edsticas num\u00e9ricas?\n\ndf_iris_train.corr()","63124546":"#Gr\u00e1fico de dispers\u00e3o simples\n\ndf_iris_train.plot(kind=\"scatter\", x=\"SepalLengthCm\", y=\"SepalWidthCm\")","4a35e3fb":"#gr\u00e1fico de dispers\u00e3o usando a esp\u00e9cie na cor\n\nsns.FacetGrid(df_iris_train, hue=\"Species\", size=5) \\\n   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n   .add_legend()","33abb04d":"#importar pacotes usados na sele\u00e7\u00e3o do modelo e na medi\u00e7\u00e3o da precis\u00e3o\n\nfrom sklearn.model_selection import train_test_split\n\n\n#importar os pacotes necess\u00e1rios para os algoritmos de classifica\u00e7\u00e3o\n\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","8a00d523":"#isolando o alvo para os modelos\n\nX = df_iris_train.drop(['Species'], axis=1) #tudo, exceto a coluna alvo\ny = df_iris_train['Species'] #apenas a coluna alvo\n\nprint('Forma dos dados originais:', X.shape, y.shape)","4bfa5b62":"#separando os dados em teste e treino\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('Forma dos dados separados:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)","25994246":"#exibindo os dados de treino\n\nX_train.head()","fda8567c":"y_train.head()","877f5b21":"#execu\u00e7\u00e3o, ajuste e acur\u00e1cia do modelo\n\nmodelo_RL = LogisticRegression(random_state=10, solver='lbfgs', multi_class='ovr')\n\nmodelo_RL.fit(X_train, y_train)\nscore = modelo_RL.score(X_test, y_test) * 100\n\nprint(modelo_RL, '\\nScore:', score, '%')\n","8570c22d":"#comparando os dados reais com as previs\u00f5es (\"iris-train.csv\")\n\nprev_train = pd.DataFrame(X_test)\n\npredict = modelo_RL.predict(X_test)\nprev_train['real'] = y_test\nprev_train['previsto'] = predict\n\nprev_train","5517242e":"#gr\u00e1fico de dispers\u00e3o sobre a previs\u00e3o do modelo com os dados de treino (30%)\n\nsns.FacetGrid(prev_train, hue=\"previsto\", size=5) \\\n   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n   .add_legend()","8905b8aa":"#Matriz de confus\u00e3o gerado pela previs\u00e3o do modelo\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, predict)\ncm","25afe619":"#quais as correla\u00e7\u00f5es entre as caracter\u00edsticas num\u00e9ricas?\n\nprev_train.corr()","f731619c":"#Carregando os dados de testes\n\ndf_iris_test = pd.read_csv(\"..\/input\/iris-test.csv\", index_col='Id')\ndf_iris_test.head()","d995918a":"#tudo, j\u00e1 que n\u00e3o possui a coluna alvo\n\nX_test = df_iris_test \n\nprint('Forma dos dados de teste:', X_test.shape)","d2b3a739":"#previs\u00e3o com os dados de teste (\"iris-test.csv\")\n\nprev_test = pd.DataFrame(X_test)\n\npredict = modelo_RL.predict(X_test)\nprev_test['previsto'] = predict\n\nprev_test","54240729":"#gr\u00e1fico de dispers\u00e3o sobre a previs\u00e3o do modelo com os dados de treino (30%)\n\nsns.FacetGrid(prev_test, hue=\"previsto\", size=5) \\\n   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n   .add_legend()","d88de81c":"#Valida\u00e7\u00e3o cruzada do modelo utilizando Kfold\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nkfold = KFold(n_splits=10, random_state=0)\nmodelo_RL = LogisticRegression(random_state=10, solver='lbfgs', multi_class='ovr')\nresultados = cross_val_score(modelo_RL, X, y, cv=kfold)\n\nprint(\"Precis\u00e3o: m\u00e9dia final = %.3f%%, desvio padr\u00e3o final = (%.3f%%)\" % (resultados.mean()*100.0, resultados.std()*100.0))\nprint('Precis\u00e3o de cada uma das 10 intera\u00e7\u00f5es usando kfold:',resultados)\nprint(\"Varia\u00e7\u00e3o de precis\u00e3o do kfold:\",resultados.var())","d7814470":"#gerar dados de envio (submiss\u00e3o)\n\nsubmission_RL = pd.DataFrame({\n  'Id': X_test.index,\n  'Species': predict\n})\nsubmission_RL.set_index('Id', inplace=True)\n\n# mostrar dados de exemplo\nsubmission_RL.head(10)","3b0977b4":"#gerar arquivo CSV para o envio\n\nsubmission_RL.to_csv('iris-submission_RL.csv')","1c3cab73":"#verificar conte\u00fado do arquivo gerado\n\n!head iris-submission_RL.csv","cc91906b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\ndepth_range = range(1, 10)\nleaf_range = range(1, 15)\n\nparam_grid = dict()\nmodelo_RL = LogisticRegression()\n\ngrid = GridSearchCV(modelo_RL, param_grid, cv=10, scoring='accuracy')\ngrid.fit(X, y)\n\nprint (grid.best_score_)\nprint (grid.best_params_)\nprint (grid.best_estimator_)","b703e6a6":"### 2\u00ba CRIA\u00c7\u00c3O DO MODELO","874e6d8f":"# Conclus\u00e3o","ff406a5f":"O conjunto de dados Iris foi usado no cl\u00e1ssico artigo de 1936 de R. A. Fisher, The Use of Multiple Measurements in Taxonomic Problems, e tamb\u00e9m pode ser encontrado no UCI Machine Learning Repository.\n\nEle inclui tr\u00eas esp\u00e9cies de \u00edris com 50 amostras cada, bem como algumas propriedades sobre cada flor. Uma esp\u00e9cie de flor \u00e9 linearmente separ\u00e1vel das outras duas, mas as outras duas n\u00e3o s\u00e3o linearmente separ\u00e1veis umas das outras.\n\nAs colunas neste conjunto de dados s\u00e3o:\n\n    Id (identifica\u00e7\u00e3o \u00fanica)\n    SepalLengthCm (comprimento da s\u00e9pala - em cent\u00edmetros)\n    SepalWidthCm (largura da s\u00e9pala - em cent\u00edmetros)\n    PetalLengthCm (comprimento da p\u00e9tala - em cent\u00edmetros)\n    PetalWidthCm (largura da p\u00e9tala - em cent\u00edmetros)\n    Species (nome da esp\u00e9cie)\n\n\n\n\n","d474bf77":"## ===> OBS: AO FINAL DESTE ARQUIVO H\u00c1 A CONCLUS\u00c3O <===","dd7521a8":"Todos os modelos que executei irei listar ao final, mas o formato \u00e9 o mesmo da Regress\u00e3o Log\u00edstica guardadas as propor\u00e7\u00f5es... Os hiperpar\u00e2mentros que utilizei s\u00e3o particulares a cada modelo, e percebi que essa \u00e9 uma parte importante, pois abre a possibilidade de ajuste mais finos que elevam a performance.\nNo caso do modelo acima chamo a aten\u00e7\u00e3o para o modo em partes que constru\u00ed, pois considerei para futuras utiliza\u00e7\u00f5es e consultas ser mais did\u00e1tico e f\u00e1cil de buscar a informa\u00e7\u00e3o que gerou o resultado.\nOutro ponto percebido foi a utiliza\u00e7\u00e3o do K-FOLD para o refinamento, devido a sua utiliza\u00e7\u00e3o foi poss\u00edvel ajustar alguns hiperpar\u00e2mentros de forma a conseguir melhoria de at\u00e9 5% ou 6% na acur\u00e1cia, sendo que nem todos os modelos utilizei tais ajustes, os submeti com os hiperpar\u00e2metros padr\u00e3o e obtive acur\u00e1cias acima de 90% em alguns.\nA utiliza\u00e7\u00e3o de gr\u00e1ficos me pareceu algo extremamente \u00fatil para si tra\u00e7ar a estrat\u00e9gia de qual modelo utilizar, o apelo visual permite concluir rapidamente a ou as poss\u00edveis linhas para se alcan\u00e7ar o melhor resultado e perceber incluisve como o modelo se comporta na predi\u00e7\u00e3o. Foi poss\u00edvel perceber com os gr\u00e1ficos que altera\u00e7\u00f5es nos hiperpar\u00e2metros alterava significativamente a sa\u00edda.\nDevido a sugest\u00e3o do Hjort foi poss\u00edvel utilizar a biblioteca GRID SEARCH CV, que tem por objetivo buscar os melhores par\u00e2metros para serem utilizados no modelo, claro que a biblioteca n\u00e3o serve para utilizarmos de forma cabal, mas sim como mais uma fonte s\u00f3lida de ajustes ao modelo produzido.\nEm minha opini\u00e3o quatro vertentes foram importantes na constru\u00e7\u00e3o dos modelos e conseguir obter conhecimento e resultados:\n\n1 - A utiliza\u00e7\u00e3o dos gr\u00e1ficos para an\u00e1lise dos dados\n\n2 - A utiliza\u00e7\u00e3o do K-FOLD\n\n3 - A utiliza\u00e7\u00e3o do GRID SEARCH CV\n\n4 - A tentativa e erro constante, esse para mim \u00e9 o nosso principal meio de trabalho.\n\nSegue a lista dos modelos que submeti e estou a disposi\u00e7\u00e3o para disponibiliz\u00e1-los, \u00e9 s\u00f3 pedir.\n\nA) SVM\nB) Logistic Regression\nC) Decision Tree \nD) KNN\nE) Naive bayes\nF) Random Forest\nG) Perceptron\nH) SGD\nI) Linear SVC\nJ) MLP\nL) Ridge\nM) Gradient Boosting\nN) Ada Boost \nO) Linear Discriminant Analysis","2e9933b1":"#### A.1) UTILIZANDO OS DADOS DE TESTE","db89744a":"## A) REGRESS\u00c3O LOG\u00cdSTICA","7cab8954":"# UTILIZA\u00c7\u00c3O DOS MODELOS","555ed4e8":"#### A.2) ENVIO DOS DADOS ","10a96109":"#### A.3 ENCONTRANDO OS MELHORES PAR\u00c2METROS","33ba3427":"### 1\u00ba CARREGAMENTO DA BASE DA DADOS E EXPLORA\u00c7\u00c3O","3d0dd593":"#### PREPARA\u00c7\u00c3O DOS PACOTES DOS ALGORITMOS DE CLASSIFICA\u00c7\u00c3O E DOS DADOS","b4b620d5":"# 1\u00ba Desafio Modelagem Preditiva - SERPRO - Iris #\n\n## Classifique plantas \u00edris em tr\u00eas esp\u00e9cies distintas neste cl\u00e1ssico conjunto de dados ##"}}