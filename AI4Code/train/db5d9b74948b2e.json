{"cell_type":{"4d809add":"code","00f3925e":"code","47a1fa6e":"code","c17f467f":"code","26387e2b":"code","30c03dcf":"code","e8ec7b5b":"code","694e1dee":"code","8a744324":"code","a10eeb66":"code","7b47fd1e":"code","0e90ed8f":"code","8b21d903":"code","8c2943c7":"code","b14f9931":"code","54e61527":"code","580026ea":"code","1296a32e":"code","76edd577":"code","d9720dd6":"code","885b1b1e":"code","0c8791bc":"code","80188e92":"code","94c8b285":"code","5ca3123b":"code","460ee2ed":"code","266242c9":"code","f0da046d":"code","eb32a217":"code","04fe7bf9":"code","4cdbeee2":"code","68906ab7":"code","134dfad4":"code","63f8b9c7":"code","660e6578":"code","dba0df2d":"code","dcf3ebcc":"code","94d1982c":"code","e2cb32b9":"code","abcb8f97":"code","aa0bfe2d":"code","d1f83693":"code","47776608":"code","13df32ca":"code","6a74ff76":"code","31eeb8c2":"code","f1663b0d":"code","197cbd80":"code","cdaebb8b":"code","2590b930":"code","d45b6e0c":"code","794e9824":"code","7a50174f":"code","772bf5b0":"code","3cdffc2b":"code","878468f5":"code","7fc94be1":"code","9f7a23cd":"code","8f422a42":"code","a9c75fd5":"code","07cd7d8f":"code","bdb801e6":"code","888451bc":"code","48f29f28":"code","f14a3765":"code","1e20460f":"code","b84aea09":"code","4b96e4ed":"code","51493741":"code","cfae54a1":"markdown","a9b99a42":"markdown","bd18ab11":"markdown","18aa179a":"markdown","422ed254":"markdown","95d4c3d4":"markdown","906c3685":"markdown","b6520103":"markdown","efa224da":"markdown","641ca096":"markdown"},"source":{"4d809add":"!pip install fastai2 -q","00f3925e":"import os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nimport missingno as msno\nimport tensorflow.keras.backend as K\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Lambda\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","47a1fa6e":"from fastai2.basics import *\nfrom fastai2.callback.all import *\nfrom fastai2.vision.all import *\nfrom fastai2.medical.imaging import *\n\nimport pydicom","c17f467f":"train_df = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntest_df = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/test.csv')","26387e2b":"train_df.head()","30c03dcf":"plt.subplot(121)\nmsno.bar(train_df)\nplt.title(\"Missing values in Training Data\", fontsize = 20, color = 'Red')\n\nplt.subplot(122)\nmsno.bar(test_df)\nplt.title(\"Missing values in Test Data\", fontsize = 20, color = 'Blue')\n\nplt.show()","e8ec7b5b":"print(f'Total unique patients are {train_df.Patient.nunique()} out of total {len(train_df.Patient)} patients')","694e1dee":"go.Figure(go.Pie(labels = train_df.Sex.value_counts().keys().tolist(), \n                       values = train_df.Sex.value_counts().values.tolist(), \n                       marker = dict(colors=['red']), hoverinfo = \"value\", pull=[0, 0.1]), \n          layout = go.Layout(title = {'text':\"Gender Distribution\", 'x':0.5}, font=dict(family=\"Courier New, monospace\",\n                                                                                                size=18,\n                                                                                                color=\"RebeccaPurple\")))","8a744324":"go.Figure(go.Pie(labels = train_df.SmokingStatus.value_counts().keys().tolist(), \n                       values = train_df.SmokingStatus.value_counts().values.tolist(), \n                       marker = dict(colors=['pink', 'blue', 'purple']), hoverinfo = \"value\", hole = 0.3), \n          layout = go.Layout(title = {'text':\"Smoking Status\", 'x':0.425}, font=dict(family=\"Courier New, monospace\",\n                                                                                                size=18,\n                                                                                                color=\"RebeccaPurple\")))","a10eeb66":"train_df.groupby('Sex')['SmokingStatus'].value_counts()","7b47fd1e":"fig = go.Figure(data=[\n    go.Bar(name='Smoker', x= train_df.Sex.unique(), y = [train_df.groupby('Sex')['SmokingStatus'].value_counts().values[5],\n                                                         train_df.groupby('Sex')['SmokingStatus'].value_counts().values[2]]),\n    go.Bar(name='Non-Smoker', x= train_df.Sex.unique(), y = [train_df.groupby('Sex')['SmokingStatus'].value_counts().values[4],\n                                                             train_df.groupby('Sex')['SmokingStatus'].value_counts().values[0]]),\n    go.Bar(name='Ex-Smoker', x= train_df.Sex.unique(), y = [train_df.groupby('Sex')['SmokingStatus'].value_counts().values[3],\n                                                             train_df.groupby('Sex')['SmokingStatus'].value_counts().values[1]]),\n])\nfig.update_layout(title = {'text':\"Smoking Distribution by Sex\", 'x':0.5}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"),\n                  barmode ='group')\nfig.show()","0e90ed8f":"count_df = pd.DataFrame(train_df['Patient'].value_counts())\ncount_df = count_df.reset_index()\ncount_df.rename(columns = {'index':'Patient ID', 'Patient':'No of Images'}, inplace = True)\n\nfig = px.bar(count_df, x='Patient ID',y ='No of Images',color='No of Images')\nfig.update_xaxes(showticklabels=False)\nfig.update_layout(title = {'text':\"Distribution of Images per Patient\", 'x':0.5}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()","8b21d903":"dicom_ids = os.listdir('..\/input\/osic-pulmonary-fibrosis-progression\/train\/')\npatient_sizes = [len(os.listdir('..\/input\/osic-pulmonary-fibrosis-progression\/train\/' + d)) for d in dicom_ids]\ndicom_df = pd.DataFrame({'Dicom_ID':dicom_ids, 'Dicom Files':patient_sizes})\n\nfig = px.bar(dicom_df, x='Dicom_ID',y ='Dicom Files',color='Dicom Files')\nfig.update_xaxes(showticklabels=False)\nfig.update_layout(title = {'text':\"Distribution of Dicom Files per Dicom ID\", 'x':0.5}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()","8c2943c7":"fig = ff.create_distplot([train_df.Age.values], ['Age'], colors = ['red'])\nfig.update_layout(title = {'text':\"Age Distribution\", 'x':0.5}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()\n\nfig = ff.create_distplot([train_df.Weeks.values], ['Weeks'], colors = ['blue'])\nfig.update_layout(title = {'text':\"Weeks Distribution\", 'x':0.5}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()","b14f9931":"fig = ff.create_distplot([train_df.Percent.values], ['Percent'], colors = ['purple'])\nfig.update_layout(title = {'text':\"Percent Distribution\", 'x':0.5}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()\n\nfig = ff.create_distplot([train_df.FVC.values], ['FVC'], colors = ['green'])\nfig.update_layout(title = {'text':\"FVC Distribution\", 'x':0.5}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()","54e61527":"fig = px.histogram(train_df, x='Age', color='SmokingStatus', marginal=\"box\", \n                   color_discrete_map={'Ex-smoker':'green','Never smoked':'light green','Currently smokes':'orange'})\nfig.update_traces(marker_line_color='cyan',marker_line_width=1, opacity=0.8)\nfig.update_layout(title = {'text':\"Smoking Status by Age\", 'x':0.4}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()","580026ea":"fig = px.histogram(train_df, x='Age', color='Sex',marginal=\"box\", color_discrete_map={'Male':'blue','Female':'light green'})\nfig.update_traces(marker_line_color='cyan',marker_line_width=1, opacity=0.8)\nfig.update_layout(title = {'text':\"Sex Distribution by Age\", 'x':0.45}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()","1296a32e":"fig = px.histogram(train_df, x='FVC', color='Sex', marginal=\"rug\", \n                   color_discrete_map={'Male':'DarkKhaki','Female':'MediumSpringGreen'})\nfig.update_traces(marker_line_color='LightSlateGrey',marker_line_width=1, opacity=0.8)\nfig.update_layout(title = {'text':\"Gender Distribution in FVC\", 'x':0.45}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()","76edd577":"fig = px.histogram(train_df, x='FVC', color='SmokingStatus', marginal=\"box\",\n                   color_discrete_map={'Ex-smoker':'#393E46','Never smoked':'MediumTurquoise','Currently smokes':'Linen'})\nfig.update_traces(marker_line_color = 'black',marker_line_width = 1, opacity = 0.8)\nfig.update_layout(title = {'text':\"SmokingStatus Distribution in FVC\", 'x':0.45}, \n                  font = dict(family=\"Courier New, monospace\", size=18, color=\"RebeccaPurple\"))\nfig.show()","d9720dd6":"source_path = Path('..\/input\/osic-pulmonary-fibrosis-progression')\nsource_files = os.listdir(source_path)\nprint(source_files)","885b1b1e":"train_path = source_path\/'train'\ntrain_files = get_dicom_files(train_path)\ntrain_files","0c8791bc":"dicom_img = dcmread(train_files[0])\ndicom_img","80188e92":"dicom_img.show()","94c8b285":"tensor_dicom = pixels(dicom_img) #convert into tensor\n\nprint(f'RescaleIntercept: {dicom_img.RescaleIntercept:1f}\\nRescaleSlope: {dicom_img.RescaleSlope:1f}\\nMax pixel: '\n      f'{tensor_dicom.max()}\\nMin pixel: {tensor_dicom.min()}\\nShape: {tensor_dicom.shape}')","5ca3123b":"tensor_dicom_scaled = scaled_px(dicom_img)\nplt.hist(tensor_dicom_scaled.flatten(), color='c')","460ee2ed":"# Viewing Cancellous Bone Area\ndicom_img.show(min_px = 300, max_px = 400, figsize=(10, 10))","266242c9":"# Fat Area\ndicom_img.show(min_px = -120, max_px = -90, figsize=(10, 10))","f0da046d":"# Water Based Area\ndicom_img.show(max_px=None, min_px=0, figsize=(10, 10))","eb32a217":"# Air Based Area\ndicom_img.show(max_px=None, min_px=-1000, figsize=(10, 10))","04fe7bf9":"train_df.shape","4cdbeee2":"train_df[train_df.duplicated(subset = ['Patient','Weeks'])]","68906ab7":"train_df.drop_duplicates(keep=False, inplace = True, subset=['Patient','Weeks'])","134dfad4":"submission_df = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/sample_submission.csv')","63f8b9c7":"submission_df","660e6578":"temp_sub_df = submission_df['Patient_Week'].str.split('_', expand = True)\ntemp_sub_df.rename(columns = {0: 'Patient', 1: 'Weeks'}, inplace = True)","dba0df2d":"submission_df = pd.concat([submission_df, temp_sub_df], axis = 1)\nsubmission_df = submission_df[['Patient','Weeks','Confidence','Patient_Week']]","dcf3ebcc":"test_df.head()","94d1982c":"submission_df = submission_df.merge(test_df.drop('Weeks', axis = 1), on = 'Patient')","e2cb32b9":"train_df['data_type'] = 'Train'\ntest_df['data_type'] = 'Val'\nsubmission_df['data_type'] = 'Test'\ncombined_df = train_df.append([test_df, submission_df])","abcb8f97":"data_type = ['Train', 'Val', 'Test']\nfor type in data_type:\n    data = combined_df.query(\"data_type == @type\")\n    print(type, \"shape in combined data is \", data.shape)","aa0bfe2d":"# Minimum Week for each patient\ncombined_df['Min_Weeks'] = combined_df['Weeks']\ncombined_df.loc[combined_df.data_type == 'Test','Min_Weeks'] = np.nan\ncombined_df['Min_Weeks'] = combined_df.groupby('Patient')['Min_Weeks'].transform('min')","d1f83693":"base = combined_df.loc[combined_df.Weeks == combined_df.Min_Weeks]\nbase = base[['Patient','FVC']].rename(columns = {'FVC':'min_FVC'})\nbase.drop_duplicates(keep = 'first', inplace = True, subset = ['Patient'])","47776608":"combined_df.Weeks = combined_df.Weeks.astype(int)\ncombined_df.Min_Weeks = combined_df.Min_Weeks.astype(float)","13df32ca":"combined_df = combined_df.merge(base, on='Patient', how='left')\ncombined_df['Deviation_Weeks'] = combined_df['Weeks'] - combined_df['Min_Weeks']\ndel base","6a74ff76":"combined_df = pd.concat([combined_df, pd.get_dummies(combined_df[['Sex','SmokingStatus']])], axis = 1)","31eeb8c2":"scaler = MinMaxScaler()\nscaled = pd.DataFrame(scaler.fit_transform(combined_df[['Age','Percent','min_FVC','Deviation_Weeks']]), \n                      columns = ['scaled_Age', 'scaled_Percent', 'scaled_FVC', 'scaled_Deviation_Weeks'])\ncombined_df = pd.concat([combined_df, scaled], axis = 1)","f1663b0d":"combined_df","197cbd80":"feature_columns = ['Sex_Male','Sex_Female','SmokingStatus_Ex-smoker','SmokingStatus_Never smoked','SmokingStatus_Currently smokes',\n                   'scaled_Age','scaled_Percent','scaled_Deviation_Weeks','scaled_FVC']","cdaebb8b":"train_df = combined_df.loc[combined_df.data_type == 'Train']\ntest_df = combined_df.loc[combined_df.data_type == 'Val']\nsubmission_df = combined_df.loc[combined_df.data_type == 'Test']\ndel combined_df","2590b930":"train_df.shape, test_df.shape, submission_df.shape","d45b6e0c":"C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n\ndef score(y_true, y_pred):\n    tf.dtypes.cast(y_true, tf.float32)\n    tf.dtypes.cast(y_pred, tf.float32)\n    sigma = y_pred[:, 2] - y_pred[:, 0]\n    fvc_pred = y_pred[:, 1]\n    \n    sigma_clip = tf.maximum(sigma, C1)\n    delta = tf.abs(y_true[:, 0] - fvc_pred)\n    delta = tf.minimum(delta, C2)\n    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n    metric = (delta \/ sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n    return K.mean(metric)\n\ndef qloss(y_true, y_pred):\n    qs = [0.2, 0.50, 0.8]\n    q = tf.constant(np.array([qs]), dtype=tf.float32)\n    e = y_true - y_pred\n    v = tf.maximum(q*e, (q-1)*e)\n    return K.mean(v)\n\ndef mloss(_lambda):\n    def loss(y_true, y_pred):\n        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n    return loss\n\ndef make_model():\n    x1 = Input((9,), name=\"Patient\")\n    x2 = Dense(100, activation=\"relu\", name=\"d1\")(x1)\n    x3 = Dense(100, activation=\"relu\", name=\"d2\")(x2)\n    \n    p1 = Dense(3, activation=\"relu\", name=\"p1\")(x3)\n    p2 = Dense(3, activation=\"relu\", name=\"p2\")(x3)\n    \n    preds = Lambda(lambda x3: x3[0] + tf.cumsum(x3[1], axis=1), \n                     name=\"preds\")([p1, p2])\n    \n    model = Model(x1, preds, name=\"CNN\")\n   \n    model.compile(loss = mloss(0.8), optimizer = tf.keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.005,\n                                                                          amsgrad=False), metrics=[score])\n    return model","794e9824":"model = make_model()\nprint(model.summary())\nprint(model.count_params())","7a50174f":"y = train_df['FVC'].values\nz = train_df[feature_columns].values\nsub = submission_df[feature_columns].values\npe = np.zeros((sub.shape[0], 3))\npred = np.zeros((z.shape[0], 3))","772bf5b0":"NFOLD = 5\nBATCH_SIZE=128\nkf = KFold(n_splits=NFOLD)","3cdffc2b":"%%time\ncnt = 0\nfor tr_idx, val_idx in kf.split(z):\n    cnt += 1\n    print(f\"FOLD {cnt}\")\n    model = make_model()\n    model.fit(z[tr_idx], y[tr_idx], batch_size=BATCH_SIZE, epochs=800, \n            validation_data=(z[val_idx], y[val_idx]), verbose=0) #\n    print(\"train\", model.evaluate(z[tr_idx], y[tr_idx], verbose=0, batch_size=BATCH_SIZE))\n    print(\"val\", model.evaluate(z[val_idx], y[val_idx], verbose=0, batch_size=BATCH_SIZE))\n    print(\"predict val...\")\n    pred[val_idx] = model.predict(z[val_idx], batch_size=BATCH_SIZE, verbose=0)\n    print(\"predict test...\")\n    pe += model.predict(sub, batch_size=BATCH_SIZE, verbose=0) \/ NFOLD","878468f5":"sigma_opt = mean_absolute_error(y, pred[:, 1])\nunc = pred[:,2] - pred[:, 0]\nsigma_mean = np.mean(unc)\nprint(sigma_opt, sigma_mean)","7fc94be1":"idxs = np.random.randint(0, y.shape[0], 100)\nplt.plot(y[idxs], label=\"ground truth\")\nplt.plot(pred[idxs, 0], label=\"q25\")\nplt.plot(pred[idxs, 1], label=\"q50\")\nplt.plot(pred[idxs, 2], label=\"q75\")\nplt.legend(loc=\"best\")\nplt.show()","9f7a23cd":"print(unc.min(), unc.mean(), unc.max(), (unc>=0).mean())","8f422a42":"plt.hist(unc)\nplt.title(\"uncertainty in prediction\")\nplt.show()","a9c75fd5":"submission_df.head()","07cd7d8f":"pe[:, 1]","bdb801e6":"submission_df['FVC1'] = pe[:, 1]\nsubmission_df['Confidence1'] = pe[:, 2] - pe[:, 0]","888451bc":"subm = submission_df[['Patient_Week','FVC','Confidence','FVC1','Confidence1']].copy()","48f29f28":"subm.loc[~subm.FVC1.isnull()].head(10)","f14a3765":"subm.loc[~subm.FVC1.isnull(),'FVC'] = subm.loc[~subm.FVC1.isnull(),'FVC1']\nif sigma_mean<70:\n    subm['Confidence'] = sigma_opt\nelse:\n    subm.loc[~subm.FVC1.isnull(),'Confidence'] = subm.loc[~subm.FVC1.isnull(),'Confidence1']","1e20460f":"subm.head()","b84aea09":"subm.describe().T","4b96e4ed":"otest = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/test.csv')\nfor i in range(len(otest)):\n    subm.loc[subm['Patient_Week']==otest.Patient[i]+'_'+str(otest.Weeks[i]), 'FVC'] = otest.FVC[i]\n    subm.loc[subm['Patient_Week']==otest.Patient[i]+'_'+str(otest.Weeks[i]), 'Confidence'] = 0.1","51493741":"subm[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)","cfae54a1":"**Model**","a9b99a42":"**Inspect DICOM files with FastAI**","bd18ab11":"**Missing values**","18aa179a":"**Check for duplicates patient records**","422ed254":"Let's quickly check DICOM files also","95d4c3d4":"**EDA**","906c3685":"Most of the DICOMs have less than 200 files","b6520103":"**Thus there are no missing values in either Training or Test data**","efa224da":"**Data Inspection**","641ca096":"Largest bin value is -1000 which represent Air on Hounsfield Scale(https:\/\/en.wikipedia.org\/wiki\/Hounsfield_scale)"}}