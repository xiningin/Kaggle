{"cell_type":{"7da799e0":"code","55600c7b":"code","e650ff1a":"code","c34a1954":"code","66ca7d03":"code","325c33f5":"code","000d1fa8":"code","2bb76305":"code","ab72b31c":"code","4347816e":"code","d62b2058":"code","b499ff15":"code","566434bb":"code","3c4b119a":"code","ff851963":"markdown","24a35c8d":"markdown","fbebddd5":"markdown","9082fef7":"markdown","e0acdc42":"markdown","39d06c90":"markdown","b1840ba3":"markdown","052d671d":"markdown","dedb7bac":"markdown","96d614bc":"markdown","efaa039b":"markdown","c3011203":"markdown","d804dfef":"markdown","6cd7a17b":"markdown"},"source":{"7da799e0":"!git clone https:\/\/github.com\/nishkalavallabhi\/OneStopEnglishCorpus.git","55600c7b":"import numpy as np \nimport pandas as pd\nimport os\n\nname = []\nele = []\ninter = []\nadv= []\n\npath_adv = '.\/OneStopEnglishCorpus\/Texts-SeparatedByReadingLevel\/Adv-Txt'\npath_ele = '.\/OneStopEnglishCorpus\/Texts-SeparatedByReadingLevel\/Ele-Txt'\npath_int = '.\/OneStopEnglishCorpus\/Texts-SeparatedByReadingLevel\/Int-Txt'\n\nfor dirname, _, filenames in os.walk(path_adv):\n    for filename in filenames:\n        path =  dirname +\"\/\" +filename\n        if \".txt\" in path:\n            name.append (filename.replace(\"-adv.txt\",\"\"))\n            with open(path) as f:\n                content = \" \".join(f.readlines()) \n                adv.append(content)\n            with open(path_ele + \"\/\" + filename.replace(\"-adv\",\"-ele\")) as f:\n                content = \" \".join(f.readlines()) \n                ele.append(content)\n            with open(path_int + \"\/\" + filename.replace(\"-adv\",\"-int\")) as f:\n                content = \" \".join(f.readlines()[1:]) \n                inter.append(content)\n                \ndf_1 = pd.DataFrame ({\n    \"name\": name,\n    \"excerpt\": ele\n})\ndf_1[\"level\"] = \"ele\"\n\ndf_2 = pd.DataFrame ({\n    \"name\": name,\n    \"excerpt\": inter\n})\ndf_2[\"level\"] = \"inter\"\n\ndf_3 = pd.DataFrame ({\n    \"name\": name,\n    \"excerpt\": adv\n})\ndf_3[\"level\"] = \"adv\"\n\ndf = df_1.append(df_2).append(df_3)\n\ndf.to_csv(\"OneStopEnglishCorpus.csv\", index=False)\n\ndf.head()","e650ff1a":"%%writefile ensemble.py\n\nimport numpy as np \nimport pandas as pd \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n\nimport torch\nimport transformers\n\nimport random\nimport os\nimport sys\n\nfrom tqdm import tqdm\n\nclass CLRPDataset():\n    def __init__(self,df,max_len, tokenizer):\n        self.excerpt = df['excerpt'].values\n        self.max_len = max_len\n        self.tokenizer = tokenizer \n\n\n        if \"target\" in df.columns:\n            self.target = df['target'].values\n        else:\n            self.target = None\n    \n    def __getitem__(self,index):\n        encode = self.tokenizer(self.excerpt[index],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                return_token_type_ids = True,\n                                truncation=True)  \n\n        #token_ids = encode['input_ids'].squeeze(0)\n        #attn_masks = encode['attention_mask'].squeeze(0)\n        #token_type_ids = encode['token_type_ids'].squeeze(0)\n\n        token_ids = encode['input_ids'][0]\n        attn_masks = encode['attention_mask'][0]\n        token_type_ids = encode['token_type_ids'][0]\n        \n        \n        if self.target is None:\n            return token_ids, attn_masks, token_type_ids\n\n\n        target = self.target[index]\n        target = torch.tensor(target).float()    \n\n        return token_ids, attn_masks, token_type_ids, target  \n\n\n    def __len__(self):\n        return len(self.excerpt)\n    \nclass BertRegreesion(torch.nn.Module):\n\n    def __init__(self, dropout, bert_model, model_path,  freeze_bert=False):\n        super(BertRegreesion, self).__init__()\n        \n        self.bert_layer = transformers.AutoModel.from_pretrained(model_path)\n        \n        #  Fix the hidden-state size of the encoder outputs (If you want to add other pre-trained models here, search for the encoder output size)\n        if bert_model == \"roberta-base\":  \n            hidden_size = 768\n        elif bert_model == \"roberta-large\":  \n            hidden_size = 1024\n        elif bert_model == \"microsoft\/deberta-large\":  \n            hidden_size = 1024\n            \n        # Freeze bert layers and only train the regression layer weights\n        if freeze_bert:\n            for p in self.bert_layer.parameters():\n                p.requires_grad = False\n\n        # ReGression layer\n        self.dropout = torch.nn.Dropout(p=dropout)\n        self.head = torch.nn.Linear(hidden_size, 1)\n        self.bert_model = bert_model\n    \n    def forward(self, input_ids, attn_masks, token_type_ids):\n\n        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n        if  self.bert_model == \"microsoft\/deberta-large\":\n            output = self.bert_layer(input_ids, attn_masks, token_type_ids)\n            output = output[0]\n            output = output[:,0,:].squeeze(1)\n        else:  \n            cont_reps, output = self.bert_layer(input_ids, attn_masks, token_type_ids,  return_dict=False)\n\n        output = self.head(self.dropout(output))\n\n        return output\n    \nBATCH_SIZE = 4\nFOLDS = 5\nNUM_WORKERS = 4\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nclass Config:\n    epochs = 20 \n    eval_per_epoch = 8 #4\n    dropout = 0.4\n    max_len = 256\n    bert_model = \"roberta-base\"\n    warm_up_steps = 300\n\ndef get_preds (bert_model, instances_path, max_len, df_test):\n    print(instances_path)\n    model_path = \"\/kaggle\/input\/transformers\/\" + bert_model + \"-hf\"\n    print(f\"model_path:{model_path}\")\n\n    vocab_path = model_path\n    instances_path = \"\/kaggle\/input\/\" + instances_path\n    instance_name = bert_model.replace(\"\/\",\"_\")\n\n    device = DEVICE\n    tokenizer = transformers.AutoTokenizer.from_pretrained(vocab_path)\n\n    test_data = CLRPDataset(df_test,max_len, tokenizer=tokenizer)\n    test_loader = torch.utils.data.DataLoader(test_data,\n                                          batch_size=BATCH_SIZE,\n                                          shuffle=False,\n                                          num_workers=NUM_WORKERS)\n\n    p = np.zeros((len(df_test),))\n    for fold in range(FOLDS): \n        preds = []\n\n        model = BertRegreesion (dropout = Config.dropout, bert_model=bert_model, model_path= model_path, freeze_bert=False)\n        \n        filename = f\"{instances_path}\/{instance_name}_{fold}.pt\"\n        model.load_state_dict(torch.load(filename, map_location=torch.device(device)))\n        model.to(device)\n        model.eval()\n    \n        with torch.no_grad():\n            for token_ids, attn_masks, token_type_ids in tqdm(test_loader):\n                token_ids = token_ids.to(device)\n                attn_masks = attn_masks.to(device)\n                token_type_ids = token_type_ids.to(device)\n\n                output = model.forward(token_ids, attn_masks, token_type_ids)\n                output = output.detach().cpu()[:,0]\n\n                preds.append(output)\n        preds = np.concatenate(preds)\n        p += preds\n        del model\n    \n    return p\/FOLDS\n\ndef main():\n    from numba import cuda \n    device = cuda.get_current_device()\n    device.reset()\n    \n    df_test = pd.read_csv(\"OneStopEnglishCorpus.csv\")\n    args = sys.argv[1:]\n    \n    preds = get_preds (args[0],args[1], max_len = Config.max_len, df_test = df_test)\n    df_test [args[1]] = preds\n    \n    df_test[[args[1]]].to_pickle(args[1]+\".pkl\")\n\nif __name__ == \"__main__\":\n    main()            \n            ","c34a1954":"%%writefile ensemble_atthead.py\n\nimport numpy as np \nimport pandas as pd \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\n\n\nimport torch\nimport transformers\n\nimport random\nimport os\nimport sys\n\nfrom tqdm import tqdm\n\nclass CLRPDataset():\n    def __init__(self,df,max_len, tokenizer):\n        self.excerpt = df['excerpt'].values\n        self.max_len = max_len\n        self.tokenizer = tokenizer \n\n\n        if \"target\" in df.columns:\n            self.target = df['target'].values\n        else:\n            self.target = None\n    \n    def __getitem__(self,index):\n        encode = self.tokenizer(self.excerpt[index],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                return_token_type_ids = True,\n                                truncation=True)  \n\n        #token_ids = encode['input_ids'].squeeze(0)\n        #attn_masks = encode['attention_mask'].squeeze(0)\n        #token_type_ids = encode['token_type_ids'].squeeze(0)\n\n        token_ids = encode['input_ids'][0]\n        attn_masks = encode['attention_mask'][0]\n        token_type_ids = encode['token_type_ids'][0]\n        \n        \n        if self.target is None:\n            return token_ids, attn_masks, token_type_ids\n\n\n        target = self.target[index]\n        target = torch.tensor(target).float()    \n\n        return token_ids, attn_masks, token_type_ids, target  \n\n\n    def __len__(self):\n        return len(self.excerpt)\n    \nclass AttentionHead(torch.nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n        self.W = torch.nn.Linear(in_features, hidden_dim)\n        self.V = torch.nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n\n\nclass BertRegreesion(torch.nn.Module):\n\n    def __init__(self, dropout, bert_model, model_path,  freeze_bert=False):\n        super(BertRegreesion, self).__init__()\n        \n        self.bert_layer = transformers.AutoModel.from_pretrained(model_path, output_hidden_states=True)\n\n        #  Fix the hidden-state size of the encoder outputs (If you want to add other pre-trained models here, search for the encoder output size)\n        if bert_model == \"roberta-base\":  \n            hidden_size = 768\n        elif bert_model == \"roberta-large\":  \n            hidden_size = 1024\n        elif bert_model == \"microsoft\/deberta-large\":  \n            hidden_size = 1024\n\n        # Freeze bert layers and only train the regression layer weights\n        if freeze_bert:\n            for p in self.bert_layer.parameters():\n                p.requires_grad = False\n\n        self.head = AttentionHead(hidden_size,hidden_size,1)\n                \n        # ReGression layer\n        self.dropout = torch.nn.Dropout(p=dropout)\n        self.linear = torch.nn.Linear(hidden_size, 1)\n        self.bert_model = bert_model\n    \n    def forward(self, input_ids, attn_masks, token_type_ids):\n\n        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n        if  self.bert_model == \"microsoft\/deberta-large\":\n            output = self.bert_layer(input_ids, attn_masks, token_type_ids)\n            output = output[0]\n\n        else:  \n            output = self.bert_layer(input_ids, attn_masks, token_type_ids,  return_dict=False)\n            output = output[0]\n        \n        output = self.head(output)\n        output = self.dropout(output)\n        output = self.linear(output)\n\n        return output\n    \nBATCH_SIZE = 4\nFOLDS = 5\nNUM_WORKERS = 4\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nclass Config:\n    epochs = 20 \n    eval_per_epoch = 8 #4\n    dropout = 0.4\n    max_len = 256\n    bert_model = \"roberta-base\"\n    warm_up_steps = 300\n\ndef get_preds (bert_model, instances_path, max_len, df_test):\n    print(instances_path)\n    model_path = \"\/kaggle\/input\/transformers\/\" + bert_model + \"-hf\"\n    print(f\"model_path:{model_path}\")\n\n    vocab_path = model_path\n    instances_path = \"\/kaggle\/input\/\" + instances_path\n    instance_name = bert_model.replace(\"\/\",\"_\")\n\n    \n    device = DEVICE\n    tokenizer = transformers.AutoTokenizer.from_pretrained(vocab_path)\n\n    test_data = CLRPDataset(df_test,max_len, tokenizer=tokenizer)\n    test_loader = torch.utils.data.DataLoader(test_data,\n                                          batch_size=BATCH_SIZE,\n                                          shuffle=False,\n                                          num_workers=NUM_WORKERS)\n\n    p = np.zeros((len(df_test),))\n    for fold in range(FOLDS): \n        preds = []\n\n        model = BertRegreesion (dropout = Config.dropout, bert_model=bert_model, model_path= model_path, freeze_bert=False)\n        \n        filename = f\"{instances_path}\/{instance_name}_{fold}.pt\"\n        model.load_state_dict(torch.load(filename, map_location=torch.device(device)))\n        model.to(device)\n        model.eval()\n    \n        with torch.no_grad():\n            for token_ids, attn_masks, token_type_ids in tqdm(test_loader):\n                token_ids = token_ids.to(device)\n                attn_masks = attn_masks.to(device)\n                token_type_ids = token_type_ids.to(device)\n\n                output = model.forward(token_ids, attn_masks, token_type_ids)\n                output = output.detach().cpu()[:,0]\n\n                preds.append(output)\n        preds = np.concatenate(preds)\n        p += preds\n        del model\n    \n    return p\/FOLDS\n\ndef main():\n    from numba import cuda \n    device = cuda.get_current_device()\n    device.reset()\n    \n    df_test = pd.read_csv(\"OneStopEnglishCorpus.csv\")\n    args = sys.argv[1:]\n    \n    preds = get_preds (args[0],args[1], max_len = Config.max_len, df_test = df_test)\n    df_test [args[1]] = preds\n    \n    df_test[[args[1]]].to_pickle(args[1]+\".pkl\")\n\nif __name__ == \"__main__\":\n    main()            \n            ","66ca7d03":"!python ensemble_atthead.py \"roberta-large\" \"clrp-roberta-large-2h-atthead-se\"\n\n!python ensemble_atthead.py \"microsoft\/deberta-large\" \"clrp-deberta-large-ppln4-atthead\"\n!python ensemble.py \"roberta-large\" \"clrp-roberta-large-2f-se\"\n\n!python ensemble.py \"microsoft\/deberta-large\" \"clrp-deberta-large-2-se\"\n!python ensemble.py \"microsoft\/deberta-large\" \"clrp-deberta-large-4-se\"","325c33f5":"!pip install textstat","000d1fa8":"import numpy as np \nimport pandas as pd \nimport sklearn.linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\n\nimport textstat","2bb76305":"FOLDS = 5\n\ndef read_oof (name, return_all = True):\n    oof = pd.read_csv(f\"\/kaggle\/input\/{name}\/oof.csv\")\n    \n    if \"pred_x\" in oof.columns:\n        oof = oof.rename (columns={\"pred_x\":name})\n    else:\n        oof = oof.rename (columns={\"pred\":name})\n        \n    if return_all:\n        return oof\n    else:\n        return oof[[\"id\",name]]\n\n\nname_1 = \"clrp-roberta-large-2f-se\"\nname_2 = \"clrp-deberta-large-2-se\"\nname_3 = \"clrp-deberta-large-4-se\"\nname_4 = \"clrp-deberta-large-ppln4-atthead\"\nname_5 = \"clrp-roberta-large-2h-atthead-se\"\n\noof = read_oof (name_1, return_all =True)\ntmp = read_oof (name_2, return_all =False)\noof = oof.merge(tmp, on =\"id\")\ntmp = read_oof (name_3, return_all =False)\noof = oof.merge(tmp, on =\"id\")\ntmp = read_oof (name_4, return_all =False)\noof = oof.merge(tmp, on =\"id\")\ntmp = read_oof (name_5, return_all =False)\noof = oof.merge(tmp, on =\"id\")\n\nfor name in [name_1, name_2, name_3, name_4, name_5]:\n    score = mean_squared_error (oof[\"target\"], oof[name], squared=False)\n    print(f\"rmse {name}: {score:.5f}\"  )\n\noof_textstats = pd.read_csv(\"\/kaggle\/input\/clrp-textstats\/textstats.csv\")\noof = oof.merge(oof_textstats, on=\"id\")\n\noof[\"t1\"] = oof[\"syllable_count\"]**2\noof[\"t2\"] = oof[\"coleman_liau_index\"]**2\n\ntextstats_feats = [\n    'syllable_count', \n    'gunning_fog', 'automated_readability_index', 'coleman_liau_index', 'text_standard', \n    \"dale_chall_readability_score\",\n    \"t1\", \n    \"t2\", \n] ","ab72b31c":"df_test = pd.read_csv(\"OneStopEnglishCorpus.csv\")\n\npred = pd.read_pickle(name_1 + \".pkl\")\ndf_test[name_1] = pred.values\n\npred = pd.read_pickle(name_2+ \".pkl\")\ndf_test[name_2] = pred.values\n\npred = pd.read_pickle(name_3+ \".pkl\")\ndf_test[name_3] = pred.values\n\npred = pd.read_pickle(name_4+ \".pkl\")\ndf_test[name_4] = pred.values\n\npred = pd.read_pickle(name_5+ \".pkl\")\ndf_test[name_5] = pred.values\n\ndf_test[\"syllable_count\"] = df_test [\"excerpt\"].map(lambda x: textstat.syllable_count(x))\ndf_test[\"gunning_fog\"] = df_test [\"excerpt\"].map(lambda x: textstat.gunning_fog(x))\ndf_test[\"automated_readability_index\"] = df_test [\"excerpt\"].map(lambda x: textstat.automated_readability_index(x))\ndf_test[\"coleman_liau_index\"] = df_test [\"excerpt\"].map(lambda x: textstat.coleman_liau_index(x))\ndf_test[\"text_standard\"] = df_test [\"excerpt\"].map(lambda x: textstat.text_standard(x, float_output=True))\ndf_test[\"dale_chall_readability_score\"] = df_test [\"excerpt\"].map(lambda x: textstat.dale_chall_readability_score(x))\n\n\ndf_test[\"t1\"] = df_test[\"syllable_count\"]**2\ndf_test[\"t2\"] = df_test[\"coleman_liau_index\"]**2\n\ndf_test[\"target\"] = 0","4347816e":"cols = [name_1, name_2, name_3, name_4, name_5] + textstats_feats","d62b2058":"scaler = StandardScaler().fit(oof[cols])\n\noof[cols] = scaler.transform(oof[cols])\ndf_test[cols] = scaler.transform(df_test[cols])\n\noof_pred = []\noof_target = []\n\nX_test = df_test[cols].values\n\nfor fold in range(FOLDS):\n    df_val = oof.query(\"kfold == @fold\")\n    X_val = df_val[cols].values\n    y_val = df_val[\"target\"].values\n    \n    df_train = oof.query(\"kfold != @fold\")\n    X_train = df_train[cols].values\n    y_train = df_train[\"target\"].values\n    \n    model = sklearn.linear_model.Ridge(alpha=5.0)\n    model.fit (X_train, y_train)\n    p_val = model.predict (X_val)\n    \n    df_test[\"target\"] += model.predict(X_test)\n    \n    oof_pred.append(p_val)\n    oof_target.append (y_val)\n    score = mean_squared_error (y_val, p_val, squared=False)\n\noof_pred = np.concatenate (oof_pred)\noof_target = np.concatenate (oof_target)\nens_score = mean_squared_error (oof_target, oof_pred, squared=False)\nprint(f\"rmse ens: {ens_score:.5f}\"  )","b499ff15":"df_test[\"target\"] \/= FOLDS  ","566434bb":"def eval_onecorpus_accuracy(df_test, model_name):\n    df_ele =  df_test.query(\"level == 'ele'\")[[\"name\",model_name]].copy().rename(columns={model_name:\"ele\"})\n    df_inter =  df_test.query(\"level == 'inter'\")[[\"name\",model_name]].copy().rename(columns={model_name:\"inter\"})\n    df_adv =  df_test.query(\"level == 'adv'\")[[\"name\",model_name]].copy().rename(columns={model_name:\"adv\"})\n\n    df_test = df_ele.merge(df_inter, on=\"name\").merge(df_adv, on=\"name\")\n    ## accuracy\n    df_test[\"flag_1\"] =  (df_test[\"ele\"] > df_test[\"inter\"]).astype(int) \n    df_test[\"flag_2\"] =  (df_test[\"inter\"] > df_test[\"adv\"]).astype(int)\n    accuracy = (df_test[\"flag_1\"].sum() + df_test[\"flag_2\"].sum())\/(2*df_test.shape[0])\n    return accuracy    ","3c4b119a":"for model_name in [name_1, name_2, name_3, name_4, name_5]:\n    accuracy = eval_onecorpus_accuracy(df_test, model_name)\n    print (f\"model:{model_name}, accuracy:{accuracy:.5f}\")\n\naccuracy = eval_onecorpus_accuracy(df_test, \"target\")\nprint (f\"model:ensemble, accuracy:{accuracy:.5f}\")","ff851963":"## OneStopEnglish corpus ","24a35c8d":"### Ensemble","fbebddd5":"## Evaluate OneStopEnglish accuracy on single models and ensemble","9082fef7":"We download the OneStop EnglishCorpus from Github and we assemble it into a dataset.","e0acdc42":"The accuracy on this dataset can be defined in this way\n- if *pred* for elementary text is grater than pred for intermediate text than 1 else 0 (elementary text is predicted to be more readable then intermediate text)\n- if *pred* for itermediate text is grater than pred for adcanced text than 1 else 0 (itermediate text is predicted to be more readable then advanced text)\n","39d06c90":"## Predict readability on OneStopEnglish corpus","b1840ba3":"|Model|OneEnglishCorpus (Accuracy)|CommonLit CV (RMSE)|CommonLit Public LB (RMSE)|CommonLit Private LB (RMSE)|\n|:----|:-------------------------:|:-----------------:|:------------------------:|:-------------------------:|\n|clrp-deberta-large-ppln4-atthead|0.85979|0.48395|0.472|0.469|\n|clrp-deberta-large-2-se|0.88624|0.48962|0.472|0.471|\n|clrp-deberta-large-4-se|0.87831|0.49059|0.468|0.470|\n|clrp-roberta-large-2f-se|0.83598|0.48927|0.472|0.470|\n|clrp-roberta-large-2h-atthead-se|0.84656|0.49703|NA|NA|\n|**ensemble**|**0.98942**|**0.45964**|**0.458**|**0.454**|\n","052d671d":"Here we entrust 4 of our competition models to predict readability on the OneStopEnglish corpus. Notice that we first write on disk a python script for each model prediciton pipeline, then we execute them by calling them separately by a shell command. In such a way we avoid problems with extensive and repetive usage of memory and GPU in the same script.","dedb7bac":"In this notebook we show how some of our models prepared for the CommonLit competition generalize well on this dataset (**83.5%-88.6%** accuracy) as well as how a linear combination of these models with classical readability features outperform accuracy on the dataset as reported in litterature (**98.9%**)","96d614bc":"In this part of the code, we retireve the out of fold predictions (OOF) from the CommonLit dataset, we produce a series of readability measures (Syllable count, Gunning Fog, Readability index, Coleman Liau Index, Text Standard, Dale Chall Readability Score) and we combine all together into a linear combination with L2 regularization (a Ridge regression). Though such is based on the CommonLit dataset, we apply it to the OneStopEnglish corpus in order to obtain an ensemble.","efaa039b":"### Single Models","c3011203":"\nOne of the challenges of this competition is to fine tuning very large models (350\/400M parameters) with a small sample (~2.800 rows).\n\nOne way to avoid overfit train\/validation set is to check how your model generalizes with a completely different dataset.\n\nOneStopEnglish corpus of texts (https:\/\/aclanthology.org\/W18-0535\/) is a dataset written at three reading levels.  \n\nThe corpus consists of 189 texts, each represented in three versions: elementary, intermediate and advanced text:\n\n\n<img src=\"https:\/\/d3i71xaburhd42.cloudfront.net\/f6d485c14786abbab731b0cf5e1f4de6b69dc57b\/5-Table1-1.png\" alt=\"Example sentences for three reading levels\" style=\"width:600px;\"\/>\n\n\nThis dataset is not designed specifically for children's readability, but accuracy on such dataset may show your model's skills on assessing readability.\n","d804dfef":"### Download OneStopEnglish corpus dataset ","6cd7a17b":"At this point we just need to evaluate performances of each model alone and of their ensemble on the OneStopEnglish corpus (a blend by a ridge linear regression on out of fold predictions on the commonlit dataset). Please notice how the ensemble outruns all the single models."}}