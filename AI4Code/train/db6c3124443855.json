{"cell_type":{"01bb8afb":"code","a3ae327e":"code","8f0105ec":"code","de3f3d44":"code","6cf52054":"code","bbff1b8b":"code","9ddd197f":"code","4d119456":"code","07bd2ffd":"code","a555cced":"code","8b5fe058":"code","bfedfb90":"code","12f903be":"code","59abcd37":"code","f1202aab":"code","1d5fea96":"code","3b1e6f7c":"code","63a3f162":"code","e9314789":"code","400a4f5f":"code","f6877991":"code","8e4590ce":"code","1b48eea5":"code","5fccecd5":"code","47f010a8":"code","24601d52":"code","2659b690":"code","a380934a":"code","e55093d8":"code","0d38f669":"code","964da214":"code","5e85d6eb":"code","16f04c5f":"code","f7386424":"code","ff30a7a3":"code","8d0670cc":"code","a5695b11":"code","9dfa75e3":"code","c68543cc":"code","87b5c9df":"code","26f1ca29":"code","cfee1642":"code","f641902b":"code","06f54f27":"code","5333d8f5":"code","70b9d307":"code","9a4a249a":"code","c89d6e20":"code","3fd26283":"markdown","db42e3b7":"markdown","6a93b46b":"markdown","07f15ef1":"markdown","1eaaf3a9":"markdown","e669766d":"markdown","d095c6ff":"markdown","32afcaca":"markdown","94c763ea":"markdown","2a846607":"markdown","115ebbfd":"markdown"},"source":{"01bb8afb":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","a3ae327e":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport cv2\nimport sys\nsys.path.append(\"\/kaggle\/usr\/lib\/siim_infer_helper_func\/\")\nfrom siim_infer_helper_func import *","8f0105ec":"df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\nif df.shape[0] == 2477:\n    tp1 = \"\/kaggle\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm\"\n    tp2 = \"\/kaggle\/input\/siim-covid19-detection\/train\/000c9c05fd14\/e555410bd2cd\/51759b5579bc.dcm\"\n    fast_sub = True\n    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n                       columns=['id', 'PredictionString'])\nelse:\n    fast_sub = False","de3f3d44":"study_size = (768,768)\nimage_size = (640,640)\n\nsplit = 'test'\nsave_dir = f'\/kaggle\/tmp\/{split}\/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'\/kaggle\/tmp\/{split}\/study\/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray(tp1)\n    im = resize(xray, size1=study_size[0],size2=study_size[1])  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    assert(tp1.split(\"\/\")[-3] == '00086460a852')\n    xray = read_xray(tp2)\n    im = resize(xray, size1=study_size[0],size2=study_size[1])  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    assert(tp2.split(\"\/\")[-3] == '000c9c05fd14')\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size1=study_size[0], size2=study_size[1])  \n            study = dirname.split('\/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))","6cf52054":"image_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'\/kaggle\/tmp\/{split}\/image\/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray(tp1)\n    im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n    cv2.imwrite(os.path.join(save_dir,'65761e66de9f_image.png'),im)\n    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\n    xray = read_xray(tp2)\n    im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n    cv2.imwrite(os.path.join(save_dir, '51759b5579bc_image.png'),im)\n    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\nelse:\n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = cv2.resize(xray,image_size,interpolation = cv2.INTER_AREA)\n            cv2.imwrite(os.path.join(save_dir, file.replace('.dcm', '_image.png')),im)\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            splits.append(split)\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","bbff1b8b":"study_tf_mpaths = [\n    \"\/kaggle\/input\/bestmodeldataset\/fold0v2l_0.831.h5\",\n    \"\/kaggle\/input\/bestmodeldataset\/fold0v2l_0.831.h5\",\n    \"\/kaggle\/input\/bestmodeldataset\/fold0_v2l_0.828.h5\",\n    \"\/kaggle\/input\/bestmodeldataset\/fold1_v2l_0.828.h5\"\n]\n\nbinaryclass_tf_mpaths = [\n    \"\/kaggle\/input\/2class-tf\/model0.h5\",\n    \"\/kaggle\/input\/2class-tf\/model1.h5\",\n    \"\/kaggle\/input\/2class-tf\/model2.h5\",\n    \"\/kaggle\/input\/2class-tf\/model3.h5\",\n    \"\/kaggle\/input\/2class-tf\/model4.h5\",\n]\n\nweightpath = [\n              \"..\/input\/covid19-effneteffdet\/blackout_effv2m_image600\/pretrained_model_0_0.848.bin\",\n              \"..\/input\/covid19-effneteffdet\/blackout_effv2m_image600\/pretrained_model_2_0.841.bin\",           \n             ]\n\nmodelpath = [\n             \"tf_efficientnetv2_m\",\n             \"tf_efficientnetv2_m\",\n            ]\n\nnonewpath = [\"..\/input\/covid19-effneteffdet\/none_effv2m_image600\/model_0_0.903.bin\",\n             \"..\/input\/covid19-effneteffdet\/effv2mnone_image640model\/pretrained_model_1_0.925_imagesize640.bin\",\n             \"..\/input\/covid19-effneteffdet\/none_effv2m_image600\/model_2_0.925.bin\",\n             \"..\/input\/covid19-effneteffdet\/effv2mnone_image640model\/pretrained_model_3_0.908_imagesize640.bin\",\n             \"..\/input\/covid19-effneteffdet\/effv2mnone_image640model\/pretrained_model_4_0.901_centralcrop640to600.bin\"]\n\nnonemodelpath = [\"tf_efficientnetv2_m\",\n                 \"tf_efficientnetv2_m\",\n                 \"tf_efficientnetv2_m\",\n                 \"tf_efficientnetv2_m\",\n                 \"tf_efficientnetv2_m\"]","9ddd197f":"import tensorflow as tf\nimport tensorflow_hub as tfhub\n\nMODEL_ARCH = 'efficientnetv2-l-21k-ft1k'\n# Get the TensorFlow Hub model URL\nhub_type = 'feature_vector' # ['classification', 'feature_vector']\nMODEL_ARCH_PATH = f'\/kaggle\/input\/efficientnetv2-tfhub-weight-files\/tfhub_models\/{MODEL_ARCH}\/{hub_type}'\n\n# Custom wrapper class to load the right pretrained weights explicitly from the local directory\nclass KerasLayerWrapper(tfhub.KerasLayer):\n    def __init__(self, handle, **kwargs):\n        handle = tfhub.KerasLayer(tfhub.load(MODEL_ARCH_PATH))\n        super().__init__(handle, **kwargs)","4d119456":"import numpy as np \nimport pandas as pd\nif fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","07bd2ffd":"#prepare tensorflow module\n\n!pip install \/kaggle\/input\/kerasapplications -q\n!pip install \/kaggle\/input\/efficientnet-keras-source-code\/ -q --no-deps\n\nimport os\n\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf","a555cced":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df = sub_df[:study_len]\ntest_paths = f'\/kaggle\/tmp\/{split}\/study\/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\nIMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 768)\n\nlabel_cols = sub_df.columns[2:]\n\ntest_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[8], IMSIZE[8]), ext='png')\ndtest = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\nwith strategy.scope():\n    \n    models = []\n    for mpath in study_tf_mpaths:\n        model = tf.keras.models.load_model(mpath,custom_objects={'KerasLayer': KerasLayerWrapper})\n        models.append(model)\n        del model\n\nsub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) \/ len(models)\nsub_df_tf = sub_df.copy()\ndel models","8b5fe058":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df = sub_df[study_len:]\ntest_paths = f'\/kaggle\/tmp\/{split}\/image\/' + sub_df['id'] +'.png'\nsub_df['none'] = 0\n\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\nIMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\n\nlabel_cols = sub_df.columns[2]\n\ntest_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[8], IMSIZE[8]), ext='png')\ndtest = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\nwith strategy.scope():\n    \n    models = []\n    for mpath in binaryclass_tf_mpaths:\n        model = tf.keras.models.load_model(mpath)\n        models.append(model)\n        del model\n\nsub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) \/ len(models)\ndf_2class_tf = sub_df.copy().reset_index(drop=True)\ndel models","bfedfb90":"from numba import cuda \ndevice = cuda.get_current_device()\ndevice.reset()","12f903be":"from torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport torch\nimport torch.nn as nn\n\nimport sys\nsys.path.insert(0, \"..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\/\")\nimport timm\n\ndevice = 'cuda'","59abcd37":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df = sub_df[:study_len]\ntest_paths = f'\/kaggle\/tmp\/{split}\/study\/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\nlabel_cols = sub_df.columns[2:]\nsub_df","f1202aab":"def get_valid_transforms():\n    return A.Compose(\n        [\n            A.Resize(height=600, width=600, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nDATA_ROOT_PATH = '\/kaggle\/tmp\/test\/study'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, path, transforms=None):\n        super().__init__()\n        self.df = df\n        self.path = path\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        path = self.path[index]\n        image_id = self.df.id[index]\n        image = cv2.imread(path,cv2.IMREAD_COLOR)\n        #print(image.std())\n        if image.std() < 20.0:\n            histimage = A.Equalize(p=1.0)(image=image)['image']\n        else:\n            histimage = image\n        histimage = ToTensorV2(p=1.0)(image=histimage)[\"image\"]\n        image = image.astype(np.float32)\n        image \/= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        \n        assert(image.shape == (3,600,600))\n        return sample['image'], histimage, image_id#, dim0, dim1\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","1d5fea96":"dataset = DatasetRetriever(\n    df=sub_df,\n    path = test_paths,\n    transforms=get_valid_transforms()\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n)","3b1e6f7c":"class EfficientNetModel(nn.Module):\n    \"\"\"\n    Model Class for EfficientNet Model\n    \"\"\"\n    def __init__(self, model_name, num_classes=4, pretrained=True):\n        super(EfficientNetModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nmodels = []\nmmodels = []\n\nfor wpath,mpath in zip(weightpath,modelpath):\n    print(wpath,mpath)\n    model = EfficientNetModel(mpath,pretrained=False).to(device)\n    model.load_state_dict(torch.load(wpath))\n    model.eval()\n    models.append(model)","63a3f162":"image_ids = []\noutputs = np.empty((0,4))\n\nwith torch.no_grad():\n    for image, histimage, image_id, in data_loader:\n        image = image.cuda().float()\n        histimage = histimage.cuda().float()\n        for i,model in enumerate(models):\n            if i==0: \n                output = model(image).softmax(dim=1)\n            else:\n                output += model(image).softmax(dim=1)\n    \n        output = output\/len(models)\n        \n        outputs = np.append(outputs,output.cpu().detach().numpy(),axis=0)\n        image_ids = np.append(image_ids,image_id)\nprint(outputs.shape)\nprint(image_ids.shape)\nsub_df.id = image_ids\nsub_df[label_cols] = outputs\nsub_df_torch = sub_df.copy()","e9314789":"display(sub_df_torch,sub_df_tf)\nsub_df[label_cols] = (sub_df_tf[label_cols] + sub_df_torch[label_cols])\/2\ndisplay(sub_df)\ndf_study = sub_df.copy()","400a4f5f":"for i in range(study_len):\n    negative = df_study.loc[i,'negative']\n    typical = df_study.loc[i,'typical']\n    indeterminate = df_study.loc[i,'indeterminate']\n    atypical = df_study.loc[i,'atypical']\n    df_study.loc[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\ndf_study = df_study[[\"id\",\"PredictionString\"]]\ndisplay(df_study)","f6877991":"del model\ndel models","8e4590ce":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df = sub_df[study_len:].reset_index(drop=True)\ntest_paths = f'\/kaggle\/tmp\/{split}\/image\/' + sub_df['id'] +'.png'\nsub_df['none'] = 0\nlabel_cols = sub_df.columns[2]\nsub_df","1b48eea5":"def get_valid_transforms():\n    return A.Compose(\n        [\n            #A.Resize(height=600, width=600, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nDATA_ROOT_PATH = '\/kaggle\/tmp\/test\/study'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, path, transforms=None):\n        super().__init__()\n        self.df = df\n        self.path = path\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        path = self.path[index]\n        image_id = self.df.id[index]\n        image = cv2.imread(path,cv2.IMREAD_COLOR)\n        image = image.astype(np.float32)\n        image \/= 255.0\n        cimage = A.CenterCrop(height=600,width=600,p=1.0)(image=image)[\"image\"]\n        rimage = cv2.resize(image,(600,600))\n        image = ToTensorV2(p=1.0)(image=image)[\"image\"]\n        cimage = ToTensorV2(p=1.0)(image=cimage)[\"image\"]\n        rimage = ToTensorV2(p=1.0)(image=rimage)[\"image\"]\n        \n        #assert(image.shape == (3,600,600))\n        return image, cimage, rimage, image_id\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","5fccecd5":"nonemodels = []\nfor wpath,mpath in zip(nonewpath,nonemodelpath):\n    model = EfficientNetModel(mpath,pretrained=False,num_classes=1).to(device)\n    model.load_state_dict(torch.load(wpath))\n    model.eval()\n    nonemodels.append(model)","47f010a8":"dataset = DatasetRetriever(\n    df=sub_df,\n    path = test_paths,\n    transforms=get_valid_transforms()\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n)","24601d52":"image_ids = []\nnoneout = []\n\n#outputs = []\nwith torch.no_grad():\n    for image,cimage,rimage, image_id, in data_loader:\n        image = image.cuda().float()\n        cimage = cimage.cuda().float()\n        rimage = rimage.cuda().float()\n        output0 = nonemodels[0](rimage).sigmoid() \n        output1 = nonemodels[1](image).sigmoid() \n        output2 = nonemodels[2](rimage).sigmoid() \n        output3 = nonemodels[3](image).sigmoid()\n        output4 = nonemodels[4](cimage).sigmoid()\n\n        outputn = (output0+output1+output2+output3+output4)\/5\n        noneout = np.append(noneout,outputn.cpu().detach().numpy())\n        image_ids = np.append(image_ids,image_id)\nprint(noneout.shape)\nprint(image_ids.shape)\nsub_df[label_cols] = noneout\ndf_2class_torch = sub_df.reset_index(drop=True).copy()","2659b690":"display(df_2class_tf,df_2class_torch)\nsub_df[label_cols] = (df_2class_tf[label_cols] + df_2class_torch[label_cols])\/2.0\ndisplay(sub_df)\ndf_2class = sub_df.copy()","a380934a":"del model\ndel nonemodels","e55093d8":"weights_dir = ['\/kaggle\/input\/yolo-bestresult\/best_fold0.pt',\n               '\/kaggle\/input\/yolo-bestresult\/best_fold1.pt',\n               '\/kaggle\/input\/yolo-bestresult\/best_fold2.pt',\n              ]\n\npaths = [\n         \n         \"\/kaggle\/input\/covid19-effneteffdet\/d3_image640\/fold4-d3_0.660.bin\",\n         \"\/kaggle\/input\/covid19-effneteffdet\/fold0-cspresdext50pan_0.650.bin\",\n        ]\n\nmodel_names = [\n    \"tf_efficientdet_d3\",\n    \"cspresdext50pan\",\n]\n\ndet_weights = [1,1]\nweight_detyolo = [1,1]","0d38f669":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport torch\n\n\ndim = 640 #1024, 256, 'original'\ntest_dir = f'\/kaggle\/tmp\/{split}\/image'\n\n\nshutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5') # install dependencies\n","964da214":"!python detect.py \\\n--weights {weights_dir[0]} {weights_dir[1]} {weights_dir[2]} \\\n--img 640\\\n--conf 0.001\\\n--iou 0.5\\\n--source $test_dir\\\n--name infer_fold \\\n--save-txt --save-conf --exist-ok\n\nlabelpaths = glob(\"runs\/detect\/infer_fold\/labels\/*\")","5e85d6eb":"meta = meta[meta['split'] == 'test']\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\ntest_df = df[study_len:].reset_index(drop=True) \nmeta['image_id'] = meta['image_id'] + '_image'\nmeta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on = 'id', how = 'left')\n\ntest_df","16f04c5f":"predbox_ens = []\nimage_ids = []\nscore = []\nbox = []\nfor file_path in tqdm(labelpaths):\n    image_id = file_path.split('\/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    data = np.concatenate([data[:, :2], yolo2a(data[:, 2:])],axis=1)\n    \n    if fast_sub:\n        predbox_ens.append(norm2hw(h, w, data[:,2:]))\n    \n    \n    image_ids.append(image_id)\n    score.append(data[:,1])\n    box.append(data[:,2:])\n\npred_df_yolo = pd.DataFrame({'id':image_ids,'score':score,'label':1,'box':box})","f7386424":"pred_df_yolo","ff30a7a3":"if fast_sub:\n    box_plot(tp1,predbox_ens[0])\n    box_plot(tp2,predbox_ens[1])","8d0670cc":"!pip install --no-deps '\/kaggle\/input\/pycocotools\/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl'\n!pip install \"\/kaggle\/input\/effdet-latestvinbigdata-wbf-fused\/omegaconf-2.0.6-py3-none-any.whl\"","a5695b11":"import sys\nsys.path.insert(0, \"\/kaggle\/input\/effdet-latestvinbigdata-wbf-fused\/efficientdet-pytorch\/\")\nsys.path.insert(0, \"\/kaggle\/input\/timm-pytorch-image-models\/pytorch-image-models-master\/\")\nsys.path.insert(0, \"\/kaggle\/input\/weightedboxesfusion\")\n\nimport torch\nimport os\n\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchPredict\nfrom effdet.efficientdet import HeadNet\nfrom glob import glob\nimport gc\nfrom ensemble_boxes import *","9dfa75e3":"#meta = meta[meta['split'] == 'test']\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\ntest_df = df[study_len:].reset_index(drop=True) \n#meta['image_id'] = meta['image_id'] + '_image'\n#meta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on = 'id', how = 'left')\n\ntest_df","c68543cc":"def get_valid_transforms():\n    return A.Compose(\n        [\n            #A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        \n    )\n\nDATA_ROOT_PATH = '\/kaggle\/tmp\/test\/image'\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, transforms=None):\n        super().__init__()\n        self.df = df\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_id = self.df.id.values[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}\/{image_id}.png',cv2.IMREAD_COLOR)\n        dim0 = self.df.dim0.values[index]\n        dim1 = self.df.dim1.values[index]\n        image = image.astype(np.float32)\n        image \/= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        \n        return sample['image'], image_id, dim0, dim1\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","87b5c9df":"dataset = DatasetRetriever(\n    df=test_df,\n    transforms=get_valid_transforms()\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n)","26f1ca29":"def load_net(checkpoint_path,model_name):\n    config = get_efficientdet_config(model_name)\n    config.image_size = [640,640]\n    config.norm_kwargs=dict(eps=.001, momentum=.01)\n    net = EfficientDet(config, pretrained_backbone=False)\n    net.reset_head(num_classes=1)\n    net.class_net = HeadNet(config, num_outputs=config.num_classes)\n\n    checkpoint = torch.load(checkpoint_path)\n    net.load_state_dict(checkpoint['model_state_dict'])\n    del checkpoint\n    gc.collect()\n\n    evalnet = DetBenchPredict(net)\n    evalnet.eval();\n    return evalnet.cuda()\n\n","cfee1642":"nets = []\nfor path, mname in zip(paths,model_names):\n    print(path)\n    model = load_net(path,mname)\n    nets.append(model)","f641902b":"def make_predictions(images, nets, score_threshold=0.001):\n    images = images.cuda().float()\n    predictions = []\n    dets = []\n    with torch.no_grad():\n        for model in nets:\n            dets.append(model(images))\n        for i in range(images.shape[0]):\n            boxes = [det[i].detach().cpu().numpy()[:,[1,0,3,2]]\/640.0 for det in dets]\n            scores = [det[i].detach().cpu().numpy()[:,4] for det in dets]\n            label = [det[i].detach().cpu().numpy()[:,5] for det in dets]            \n            boxes, scores, label  = weighted_boxes_fusion(boxes,\n                                                          scores,\n                                                          label,\n                                                          weights=det_weights,\n                                                          iou_thr=0.6,\n                                                          conf_type='avg',\n                                                          skip_box_thr=0.01)\n            \n            indexes = np.where(scores > score_threshold)[0]\n            boxes = boxes[indexes]\n            scores = scores[indexes]\n            label = label[indexes]\n            predictions.append({\n                'boxes': boxes,\n                'scores': scores,\n                'label': label\n            })\n    return predictions\n\ndef format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"opacity {0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n    return \" \".join(pred_strings)","06f54f27":"results = []\nboxess = []\nfor j,(images, image_ids, dim0, dim1) in enumerate(data_loader):\n    predictions = make_predictions(images, nets)\n    for i,prediction in enumerate(predictions):\n        boxes = prediction['boxes']\n        scores = prediction['scores']\n        label = prediction['label']\n        image_id = image_ids[i]\n        \n        index = pred_df_yolo[pred_df_yolo.id==image_id].index\n        yolorow = pred_df_yolo.iloc[index]\n        boxes_y = yolorow.box.values[0]\n        scores_y = yolorow.score.values[0]\n        labels_y = label\n        ens_box = [boxes,boxes_y]\n        ens_score = [scores,scores_y]\n        ens_label = [label,labels_y]\n        \n        \n        \n        boxes, scores, label  = weighted_boxes_fusion(ens_box,\n                                                      ens_score,\n                                                      ens_label,\n                                                      weights=weight_detyolo,\n                                                      iou_thr=0.6,\n                                                      conf_type='avg',\n                                                      skip_box_thr=0.01)\n        \n        boxes[:,0], boxes[:,2] = boxes[:,0]*dim1[i].item(), boxes[:,2]*dim1[i].item()\n        boxes[:,1], boxes[:,3] = boxes[:,1]*dim0[i].item(), boxes[:,3]*dim0[i].item()  \n        boxes = boxes.astype(np.int32)\n        if fast_sub:\n            boxess.append(boxes)\n        result = {\n            'id': image_id,\n            'PredictionString': format_prediction_string(boxes, scores)\n        }\n        results.append(result)\npred_df = pd.DataFrame(results, columns=['id', 'PredictionString'])\npred_df","5333d8f5":"pred_df['none'] = df_2class['none'] \npred_df","70b9d307":"for i in range(sub_df.shape[0]):\n    if pred_df.loc[i,'none']< 0.95:\n        pred_df.loc[i,'PredictionString'] = pred_df.loc[i,'PredictionString'] + ' none ' + str(pred_df.loc[i,'none']) + ' 0 0 1 1'\n    else:\n        pred_df.loc[i,'PredictionString'] = 'none 1 0 0 1 1'\npred_df = pred_df[['id', 'PredictionString']]   \npred_df","9a4a249a":"if fast_sub:\n    box_plot(tp1,boxess[0])\n    box_plot(tp2,boxess[1])","c89d6e20":"df_study = df_study.append(pred_df).reset_index(drop=True)\ndf_study = df_study[['id','PredictionString']]\ndf_study.to_csv('\/kaggle\/working\/submission.csv',index = False)\ndf_study","3fd26283":"## image level path list","db42e3b7":"# tensorflow","6a93b46b":"# study level and 2-class","07f15ef1":"# effdet","1eaaf3a9":"## model and weight paths","e669766d":"# Pytorch studylevel","d095c6ff":"# yolo","32afcaca":"# Pytorch 2-class","94c763ea":"# image classification end \n\n# image level start","2a846607":"## Pytorch Tensorflow ensemble model\n\n#### studylevel : effnetv2m(torch) + effnetv2l(tf)\n#### 2class: effnetv2m+b3(torch) + effnetb5(tf)\n#### imagelevel : yolov5(3model) + effdet + resdet (wbf ensemble)\n\n### only publish inference notebook \n\n## reference\n\n### thanks to https:\/\/www.kaggle.com\/sreevishnudamodaran\/siim-effnetv2-l-cascadercnn-mmdetection-infer\n### thanks to https:\/\/www.kaggle.com\/micheomaano\/siim-cov19-efnb7-yolov5-infer\n### thanks to https:\/\/www.kaggle.com\/h053473666\/siim-cov19-efnb7-yolov5-infer\n### thanks to https:\/\/www.kaggle.com\/shangweichen\/siim-efnb7-train-pytorch-xla-tpu\n\n\n## my public notebook \n\n### [step1 get_imageinformation](https:\/\/www.kaggle.com\/kunihikofurugori\/siim-step1-get-imginfo).\n\n### [step2 make_dataframe](https:\/\/www.kaggle.com\/kunihikofurugori\/step2-make-dataframe\/edit\/run\/69201903).\n\n### [step3-1 renew-imglev_ds](https:\/\/www.kaggle.com\/kunihikofurugori\/siim-step3-1-renew-imglev-ds)\n\n### [step3-2 renew-studylev_ds](https:\/\/www.kaggle.com\/kunihikofurugori\/siim-step3-1-renew-studylev-ds)\n\n","115ebbfd":"# Pytorch"}}