{"cell_type":{"93a07286":"code","bd91448c":"code","934d7262":"code","1208fe0c":"code","ca6dc7b7":"code","99bc7575":"code","139e892a":"code","3d540cb3":"code","1572cb23":"code","c9a266df":"code","70f9a129":"code","0c65a2f6":"code","c4f4789f":"code","31da158d":"code","4a00ab37":"code","86e4f014":"code","214fbeb9":"code","5456c9a7":"markdown","bb5de4b7":"markdown","2805b553":"markdown","a7b2fc62":"markdown","a2e185d1":"markdown","20faa98c":"markdown","dd10ee5f":"markdown","b5e2aca5":"markdown","10931d30":"markdown","97b32461":"markdown","f32caa9d":"markdown","1ef588a3":"markdown","51539052":"markdown","1f7b3f05":"markdown","9aa51cea":"markdown","04c72bc9":"markdown","f60dc941":"markdown","e1f7d498":"markdown","16b6233c":"markdown","626f8da2":"markdown"},"source":{"93a07286":"import math\nfrom IPython import display\nfrom matplotlib import cm\nfrom matplotlib import gridspec\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\ntf.logging.set_verbosity(tf.logging.ERROR)\npd.options.display.max_rows = 10\npd.options.display.float_format = '{:.1f}'.format","bd91448c":"dataframe = pd.read_csv(\"..\/input\/Mall_Customers_Data.csv\", sep=\",\")\ndataframe = dataframe.reindex(np.random.permutation(dataframe.index))\ndataframe.head()","934d7262":"dataframe.describe()","1208fe0c":"#Get general info about data\nprint (\"data shape :\",dataframe.shape,\"\\n\")\nprint (\"data info  :\",dataframe.info())\nprint (\"\\ncolumns  :\",dataframe.columns)\nprint (\"\\nmissing values :\",dataframe.isnull().sum())","ca6dc7b7":"import seaborn as sns\nimport warnings\nimport itertools\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\ncorrelation = dataframe[[\"Annual Income (k$)\", \"Age\", 'Spending Score (1-100)']].corr()\nplt.figure(figsize=(9,7))\nsns.heatmap(correlation,annot=True,cmap=\"coolwarm\",linewidth=2,edgecolor=\"k\")\nplt.title(\"CORRELATION BETWEEN VARIABLES\")","99bc7575":"import seaborn as sns\nsns.set(style=\"ticks\")\nsns.pairplot(dataframe, vars=[\"Annual Income (k$)\", \"Age\", 'Spending Score (1-100)'],hue=\"Gender\", markers=[\"o\", \"s\"])","139e892a":"plt.scatter(dataframe['Age'],dataframe['Annual Income (k$)'], cmap=\"coolwarm\", c=dataframe['Spending Score (1-100)'])\nplt.ylabel(\"Annual Income (k$)\")\nplt.xlabel(\"Age\")\nplt.title(\"Spending Score (1-100)\")\nplt.show()\n\ndataframe_female = dataframe[dataframe[\"Gender\"]==\"Female\"]\nplt.scatter(dataframe_female['Age'],dataframe_female['Annual Income (k$)'], cmap=\"coolwarm\", c=dataframe_female['Spending Score (1-100)'])\nplt.ylabel(\"Annual Income (k$)\")\nplt.xlabel(\"Age\")\nplt.title(\"Female Spending Score (1-100)\")\nplt.show()\n\ndataframe_male = dataframe[dataframe[\"Gender\"]==\"Male\"]\nplt.scatter(dataframe_male['Age'],dataframe_male['Annual Income (k$)'], cmap=\"coolwarm\", c=dataframe_male['Spending Score (1-100)'])\nplt.ylabel(\"Annual Income (k$)\")\nplt.xlabel(\"Age\")\nplt.title(\"Male Spending Score (1-100)\")\nplt.show()","3d540cb3":"def preprocess_features(dataframe):\n  selected_features = dataframe[\n    [\"Gender\",          \n     \"Age\",           \n     \"Annual Income (k$)\"      \n    ]]\n  processed_features = selected_features\n  return processed_features\n\ndef preprocess_targets(dataframe):\n  output_targets = pd.DataFrame()\n  output_targets[\"Spending Score (1-100)\"] = dataframe[\"Spending Score (1-100)\"]\/100\n  return output_targets\n\ndef linear_scale(series):\n  min_val = series.min()\n  max_val = series.max()\n  scale = (max_val - min_val) \/ 2.0\n  return series.apply(lambda x:((x - min_val) \/ scale) - 1.0)\n\ndef normalize(dataframe):\n  processed_features = pd.DataFrame()\n  processed_features[\"Gender\"] = dataframe[\"Gender\"]\n  processed_features[\"Age\"] = linear_scale(dataframe[\"Age\"])\n  processed_features[\"AnnualIncome\"] = linear_scale(dataframe[\"Annual Income (k$)\"])\n  return processed_features\n\ndef my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):    \n    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    if shuffle:\n      ds = ds.shuffle(10000)\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels","1572cb23":"total_records = dataframe.shape[0]\ntraining_percentage = 0.7\nvalidation_percentage = 1 - training_percentage\n\nnormalized_preprocessed_features = normalize(preprocess_features(dataframe))\npreprocessed_targets = preprocess_targets(dataframe)\n# Choose the first 80% examples for training.\ntraining_examples = normalized_preprocessed_features.head(int(total_records*training_percentage))\ntraining_targets = preprocessed_targets.head(int(total_records*training_percentage))\n# Choose the last 20% examples for validation.\nvalidation_examples = normalized_preprocessed_features.tail(int(total_records*validation_percentage))\nvalidation_targets = preprocessed_targets.tail(int(total_records*validation_percentage))\n","c9a266df":"feature_columns = [tf.feature_column.numeric_column(\"Age\"),\n             tf.feature_column.numeric_column(\"AnnualIncome\"),\n             tf.feature_column.indicator_column(\n                   tf.feature_column.categorical_column_with_vocabulary_list(\"Gender\",[\"Male\",\"Female\"]))\n                  ]","70f9a129":"def train_model(\n    learning_rate,\n    steps,\n    batch_size,\n    training_examples,\n    training_targets,\n    validation_examples,\n    validation_targets):\n\n  periods = 10\n  steps_per_period = steps \/ periods\n\n  # Create a linear regressor object.\n  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n  linear_regressor = tf.estimator.LinearRegressor(\n      feature_columns=feature_columns,\n      optimizer=my_optimizer\n  )\n    \n  # Create input functions\n  training_input_fn = lambda: my_input_fn(training_examples, \n                                          training_targets, \n                                          batch_size=batch_size)\n  predict_training_input_fn = lambda: my_input_fn(training_examples, \n                                                  training_targets, \n                                                  num_epochs=1, \n                                                  shuffle=False)\n  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n                                                    validation_targets, \n                                                    num_epochs=1, \n                                                    shuffle=False)\n\n  # Train the model, but do so inside a loop so that we can periodically assess\n  # loss metrics.\n  print(\"Training model...\")\n  print(\"RMSE (on training data):\")\n  training_rmse = []\n  validation_rmse = []\n  for period in range (0, periods):\n    # Train the model, starting from the prior state.\n    linear_regressor.train(\n        input_fn=training_input_fn,\n        steps=steps_per_period,\n    )\n    # Take a break and compute predictions.\n    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n    \n    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n    \n    # Compute training and validation loss.\n    training_root_mean_squared_error = math.sqrt(\n        metrics.mean_squared_error(training_predictions, training_targets))\n    validation_root_mean_squared_error = math.sqrt(\n        metrics.mean_squared_error(validation_predictions, validation_targets))\n    # Occasionally print the current loss.\n    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n    # Add the loss metrics from this period to our list.\n    training_rmse.append(training_root_mean_squared_error)\n    validation_rmse.append(validation_root_mean_squared_error)\n  print(\"Model training finished.\")\n  \n  # Output a graph of loss metrics over periods.\n  plt.ylabel(\"RMSE\")\n  plt.xlabel(\"Periods\")\n  plt.title(\"Root Mean Squared Error vs. Periods\")\n  plt.tight_layout()\n  plt.plot(training_rmse, label=\"training\")\n  plt.plot(validation_rmse, label=\"validation\")\n  plt.legend()\n\n  return linear_regressor","0c65a2f6":"linear_regressor = train_model(\n    learning_rate=0.001,\n    steps=100,\n    batch_size=100,\n    training_examples=training_examples,\n    training_targets=training_targets,\n    validation_examples=validation_examples,\n    validation_targets=validation_targets)","c4f4789f":"predict_training_input_fn = lambda: my_input_fn(training_examples, \n                                                  training_targets, \n                                                  num_epochs=1, \n                                                  shuffle=False)\ntraining_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\ntraining_predictions = np.array([item['predictions'][0] for item in training_predictions]) \ntraining_predictions = pd.DataFrame(training_predictions)\n\nx2 = np.linspace(0.0, 1.0)\nplt.scatter(training_targets,training_predictions)\nplt.plot(x2, x2)\nplt.show()","31da158d":"Age = tf.feature_column.numeric_column(\"Age\")\nAnnualIncome = tf.feature_column.numeric_column(\"AnnualIncome\")\nGender = tf.feature_column.categorical_column_with_vocabulary_list(\"Gender\",[\"Male\",\"Female\"])\nAge_buckets = tf.feature_column.bucketized_column(Age, np.arange(-1.0,1.0,0.05).tolist())\nAnnualIncome_buckets = tf.feature_column.bucketized_column(AnnualIncome, np.arange(-1.0,1.0,0.05).tolist())\nfeature_columns = [Age_buckets, AnnualIncome_buckets, Gender]","4a00ab37":"linear_regressor = train_model(\n    learning_rate=0.01,\n    steps=100,\n    batch_size=100,\n    training_examples=training_examples,\n    training_targets=training_targets,\n    validation_examples=validation_examples,\n    validation_targets=validation_targets)","86e4f014":"predict_training_input_fn = lambda: my_input_fn(training_examples, \n                                                  training_targets, \n                                                  num_epochs=1, \n                                                  shuffle=False)\ntraining_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\ntraining_predictions = np.array([item['predictions'][0] for item in training_predictions]) \ntraining_predictions = pd.DataFrame(training_predictions)\n\nx2 = np.linspace(0.0, 1.0)\nplt.scatter(training_targets,training_predictions)\nplt.plot(x2, x2)\nplt.show()","214fbeb9":"predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n                                                  validation_targets, \n                                                  num_epochs=1, \n                                                  shuffle=False)\n\nvalidation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\nvalidation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\nvalidation_predictions = pd.DataFrame(validation_predictions)\n\nx1 = np.linspace(0.0, 1.0)\nplt.scatter(validation_targets,validation_predictions)\nplt.plot(x1, x1)\nplt.show()","5456c9a7":"To visualize the the differences between male and female, we do the following plot. We can see that spending score of men is slightly lower than the one for women. Other than this there is no other obvious differences to be noticed.","bb5de4b7":"Now let's train it:","2805b553":"**Create a linear prediction model**","a7b2fc62":"We can see that all the values of spending score predicted are between 30 and 60 in a scale of 0 to 100.","a2e185d1":"let's build a linear regression model to predict the spending score based on the age, the gender and the annual income and the gender","20faa98c":"We preprocess the features and we normalize them so our model converge more easly. We also split our dataset into a trainning subset (70%) and a validation subset (30%).","dd10ee5f":"We define then our model.","b5e2aca5":"The available dataset contains only 200 records. However, the quality of data is good since the dataset doesn't contain NULL values and the values seems to be correct.\nFor example, the gender can be either Male or Female, the age is between 18 and 70 and the annual income is between 15.000 dollars and 137.000 dollars.","10931d30":"**Conclusion**","97b32461":"The small dataset was a real limit in developping a large and more complex model.\nWith a larer dataset, we can train un Deep Neural Network or even a Wide and Deep Neural Network","f32caa9d":"****Linear model with advanced feature preprocessing****","1ef588a3":"The spending score and the age are highly correlated (33%) which is expected since the shopping behavior can be different from one generation to another. The annual income in the other hand is only 1% correlated to to the spending score. this may be counter intuitive since we can think that the more we gain, the more we spend.\nThe correlation matrix bellow does not show the differences between male and female since it is a categorical feature.","51539052":"**Data visualisation**","1f7b3f05":"The loss function seems to converge to a value of 26% wich a little bit high. The limits of this model are related to the few data we possess (only 200 records). If we had more data, we can imagine training the model on a deep neural network or do more feature preprocessing.","9aa51cea":"As expected, the train loss is relatively low at 20% but the validation loss is in the other hand high, wich means that we are overfitting our data.","04c72bc9":"Now let's do a heat map with age, annual income and spending score. We can see that generally that people who have the higher spending scores are the following :\n- very young pepole with less than 25 years old and with relatively low annual income (less than 40k dolars)\n- people betwenn 27 and 40 years old and with relatively high annual income (more than 70k dolars)","f60dc941":"\nShopping Malls assign to each customer a spending score between 0 and 100. We can imagine that the more the customer spends money in the Mall, the more its score increases. The objective of this paper is to predict a spending score of a consumer based on demographic information like age, gender and personal annual income.","e1f7d498":"Let's bucketize our features into small intervalls. This wll lead us to a wide network. this implies that the model will more \"learn\" the data that \"generalize\" it. This means that we may face some overfitting.","16b6233c":"**Introduction**","626f8da2":"let's first import the needed librairies and the data set."}}