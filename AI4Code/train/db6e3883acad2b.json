{"cell_type":{"14393b4e":"code","1e7d0828":"code","3589ed44":"code","80f9353f":"code","36fdacd6":"code","29a5ced2":"code","d605f6aa":"code","fbbddad6":"code","9109ad79":"code","947865dd":"code","9cd72ec5":"code","dbf6d085":"code","d403096f":"code","96eee66a":"code","314c1cb5":"code","89d82362":"code","883a2daf":"code","28157e51":"code","cbc93fe3":"code","7a4c422a":"code","0dbd71e3":"code","3570df08":"code","7ddb3d06":"code","d98d55f0":"code","00a81380":"code","8d75102d":"code","05d1d610":"code","a6c9a3d1":"code","8838e3ef":"code","71f34609":"code","38ecdfce":"code","69463cd8":"code","dc4f4f87":"code","518e625d":"code","b2c8bcd8":"code","5ceae4ea":"code","1a1f0077":"code","26f5e079":"code","efa2c83e":"code","bb6ac155":"code","2cff8e55":"code","3626c4fa":"code","8b1d74f8":"code","07cfa850":"code","1b3a1b2e":"code","8181a501":"code","0d070642":"code","4100f5c8":"code","01e770a9":"code","b0f3f536":"code","2e26e8f5":"code","0354b3c9":"code","0689d966":"code","f02d089a":"markdown","665b141f":"markdown","d73c681a":"markdown","f3349ce0":"markdown","bdd54e65":"markdown","ba202e73":"markdown","406e8dfe":"markdown","fef902a9":"markdown","1ec9886a":"markdown","e5020154":"markdown","1a66ba26":"markdown","6c10394a":"markdown","59e34bb9":"markdown","63ac992b":"markdown","7ed7aabd":"markdown","7bfae810":"markdown","13dd156b":"markdown","28c2aa82":"markdown","54dbb9f5":"markdown","ca9430c1":"markdown","c42b0549":"markdown"},"source":{"14393b4e":"import numpy as np \nimport pandas as pd \nfrom datetime import datetime","1e7d0828":"nba_df = pd.read_csv(\"\/kaggle\/input\/nba-games-stats-from-2014-to-2018\/nba.games.stats.csv\")\nprint(nba_df.shape)\nnba_df.sample(5)","3589ed44":"# Drop irrelevant column:\n\nnba_df=nba_df.drop('Unnamed: 0', axis=1)","80f9353f":"# create defence rebounds field for team and opponent:\n\nnba_df['DefRebounds'] = nba_df['TotalRebounds'] - nba_df['OffRebounds']\nnba_df['Opp.DefRebounds'] = nba_df['Opp.TotalRebounds'] - nba_df['Opp.OffRebounds']\nnba_df.shape","36fdacd6":"# Cleaning texts for easier handling:\n\nnba_df.columns = nba_df.columns.str.replace('Opp.', 'Opp')\nnba_df.columns = nba_df.columns.str.replace('Opp3PointShots', 'OppX3PointShots' )","29a5ced2":"# 2-class columns to Boolean:\n\nnba_df['Home'] = nba_df['Home'].replace(['Home', 'Away'], [1,0]).astype(str).astype(int)","d605f6aa":"# 2-class columns to Boolean - Leave Column as such for ML:\n\nnba_df['WINorLOSS'] = nba_df['WINorLOSS'].replace(['W', 'L'], [1,0]).astype(str).astype(int)","fbbddad6":"PIR = ((nba_df['TeamPoints'] + nba_df['TotalRebounds'] + nba_df['Assists'] \n     + nba_df['Steals'] + nba_df['Blocks'] + nba_df['OppTotalFouls']) \n       \n       # Missed Field Goals:\n    - ((nba_df['FieldGoalsAttempted']- nba_df['FieldGoals'])\n       \n       # Missed Free Throws:\n    +(nba_df['FreeThrowsAttempted'] - nba_df['FreeThrows']) \n    + nba_df['Turnovers'] + nba_df['OppBlocks'] + nba_df['TotalFouls']))\n\n\nOppPIR = ((nba_df['OppnentPoints'] + nba_df['OppTotalRebounds'] + nba_df['OppAssists'] \n     + nba_df['OppSteals'] + nba_df['OppBlocks'] + nba_df['TotalFouls']) \n    - ((nba_df['OppFieldGoalsAttempted']- nba_df['OppFieldGoals'])\n    +(nba_df['OppFreeThrowsAttempted'] - nba_df['OppFreeThrows']) \n    + nba_df['OppTurnovers'] + nba_df['Blocks'] + nba_df['OppTotalFouls']))       \n\nnba_df['PIR'] = pd.Series(PIR)\nnba_df['OppPIR'] = pd.Series(OppPIR)","9109ad79":"nba_df['Month'] = [int(m[5:7]) for m in nba_df['Date']]\nnba_df['Year'] = [int(y[:4]) for y in nba_df['Date']]","947865dd":"def seasons(d):\n  m=d[5:7]\n  y=d[:4] \n  if (y =='2014' and m in ('10','11','12')) or (y=='2015' and m in ('01','02','03','04')):\n    s='one'\n  elif (y=='2015' and m in ('10','11','12')) or (y=='2016' and m in ('01','02','03','04')):\n    s='two'\n  elif (y=='2016' and m in ('10','11','12')) or (y=='2017' and m in ('01','02','03','04')):\n    s='three'\n  else:\n    s='four'\n  return (s)\n\nnba_df['Season']=nba_df['Date'].apply(seasons)\n\n# Question: 1-4 are integers. Should we change to text?","9cd72ec5":"# Categorizing months into halfs (February contains the AllStar break). It will follow by dummies:\n\ndef halfs(x):\n    if x in ('10','11','12','01'):\n        x = 'Pre_AllStar'\n    else:\n        x = 'Post_AllStar'\n    return (x)\n\nnba_df['Season_half']=nba_df['Month'].apply(halfs)","dbf6d085":"# Points Differance at the end of the game:\n\nnba_df['diff_points']=abs(nba_df['TeamPoints']-nba_df['OppnentPoints'])","d403096f":"total_wins_season = pd.DataFrame(nba_df.groupby(['Team', 'Season'])['WINorLOSS'].sum())\ntotal_wins_season.iloc[75:85]","96eee66a":"team_rank = nba_df.merge(total_wins_season, left_on=['Team','Season'], right_index = True)\nnba_df['team_rank'] = team_rank['WINorLOSS_y']","314c1cb5":"nba_df_for_ML = nba_df[['Game', 'Home','WINorLOSS', 'Season', 'Season_half']].copy()","89d82362":"# Team stats coulmns are averaged for the last 5 games. The first 5 games are group_aggregated.\n# In some runs, Opponent Columns were averaged too, but it was not beneficial\n\ndef five_last_games_avg(col):\n  first_games_avg_dict = {}\n\n  for idx in nba_df.index:\n    sum_points=0\n    if nba_df.loc[idx]['Game'] ==1:\n      first_games_avg = (nba_df.iloc[idx:idx+5][col].sum())\/5\n      first_games_avg_dict.update({idx:first_games_avg})\n      for i in range(5):\n        first_games_avg_dict.update({idx+i:first_games_avg})\n    elif nba_df.loc[idx]['Game'] > 5:\n      y = nba_df.loc[idx]['Game'] -5\n      for i in range(y,nba_df.loc[idx]['Game']):\n          sum_points+=nba_df.loc[i][col]\n          first_games_avg_dict.update({idx:(sum_points\/5)})\n\n  nba_df_for_ML[f'avg_{col}'] = pd.Series(first_games_avg_dict)","883a2daf":"# VERY VERY SLOW:\n# %%timeit\n# 1 loop, best of 3: 5min 57s per loop\n\nnba_df_columns_for_avg = ['PIR', 'OppPIR','TeamPoints',\n        'FieldGoalsAttempted', 'FieldGoals.',\n        'X3PointShotsAttempted', 'X3PointShots.', \n       'FreeThrowsAttempted', 'FreeThrows.', 'OffRebounds', \n       'DefRebounds', 'Assists', 'Steals', 'Blocks', 'Turnovers', 'TotalFouls','diff_points']\n\nfor a in nba_df_columns_for_avg:\n  five_last_games_avg(a)","28157e51":"from datetime import timedelta\nnba_df['Game_Date'] = pd.to_datetime(nba_df['Date'])","cbc93fe3":"def scale_rest_days(i):\n  x=nba_df.loc[i]['Game']\n  if x>3:\n    if (nba_df.loc[i]['Game_Date']- nba_df.loc[i-1]['Game_Date']).days==1:\n      if (nba_df.loc[i]['Game_Date']- nba_df.loc[i-2]['Game_Date']).days==2:\n        if (nba_df.loc[i]['Game_Date']- nba_df.loc[i-3]['Game_Date']).days==3:\n          return -3\n        else: \n          return -1\n      elif (nba_df.loc[i]['Game_Date']- nba_df.loc[i-2]['Game_Date']).days==3:\n        return 1\n      else:\n        return 2\n    elif (nba_df.loc[i]['Game_Date']- nba_df.loc[i-1]['Game_Date']).days==2:\n      if (nba_df.loc[i]['Game_Date']- nba_df.loc[i-2]['Game_Date']).days==3:\n        return 3\n      else:\n        return 4\n    elif (nba_df.loc[i]['Game_Date']- nba_df.loc[i-1]['Game_Date']).days==3:\n      return 5\n    else:\n      return 6\n  else:\n    return 0","7a4c422a":"nba_df['ind']=nba_df.index.values\nnba_df_for_ML['rest_days_scale']= nba_df['ind'].apply(scale_rest_days)","0dbd71e3":"def sum_wins():\n    streak_dict = {}\n    sum_wins = 0\n    for idx in nba_df_for_ML.index:\n        if nba_df_for_ML.loc[idx]['Game'] == 1:\n            sum_wins = nba_df_for_ML.loc[idx]['WINorLOSS']\n            streak_dict.update({idx:sum_wins})\n        else: \n            if nba_df_for_ML.loc[idx-1]['WINorLOSS'] == 0:\n                sum_wins=0\n                streak_dict.update({idx:sum_wins})\n            else:\n                sum_wins += nba_df_for_ML.loc[idx-1]['WINorLOSS']\n                streak_dict.update({idx:sum_wins})            \n    nba_df_for_ML['wins_streak'] = pd.Series(streak_dict)\n\nsum_wins()\n    ","3570df08":"print(nba_df_for_ML.shape)\nnba_df_for_ML.sample(5)","7ddb3d06":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import log_loss, confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import train_test_split","d98d55f0":"# !pip install pydot\n# import pydot\n# from IPython.display import Image\n# from sklearn.externals.six import StringIO\n# from sklearn.tree import export_graphviz","00a81380":"# def visualize_tree(model, md=5, width=800):\n#     dot_data = StringIO()  \n#     export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n#     graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]  \n#     return Image(graph.create_png(), width=width)","8d75102d":"# def print_dot_text(model, md=5):\n#     \"\"\"The output of this function can be copied to http:\/\/www.webgraphviz.com\/\"\"\"\n#     dot_data = StringIO()\n#     export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n#     dot_text = dot_data.getvalue()\n#     print(dot_text)","05d1d610":"nba_df_dumm = pd.get_dummies(nba_df_for_ML)\nnba_df_for_ML.shape #(9840, 24)\nnba_df_dumm.shape","a6c9a3d1":"X = nba_df_dumm.drop(['WINorLOSS'], axis=1)\ny = nba_df_dumm.WINorLOSS\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    train_size=0.75, \n                                                    test_size=0.25,\n                                                    shuffle=True, \n                                                    #stratify=nba_df_for_ML.WINorLOSS\n                                                    )","8838e3ef":"dt_model_1 = DecisionTreeClassifier(min_samples_leaf=3, min_weight_fraction_leaf=0.01, max_leaf_nodes=40).fit(X_train, y_train)","71f34609":"# visualize_tree(dt_model_1, md=5, width=1200)","38ecdfce":"pd.Series(dt_model_1.feature_importances_, index=X_train.columns).sort_values().tail(20)\\\n    .plot.barh(title='Features importance');","69463cd8":"features_importance = pd.Series(dt_model_1.feature_importances_, index=X_train.columns).sort_values().tail(20)\nfeatures_importance","dc4f4f87":"# Cross Validation:\n\n(-cross_val_score(dt_model_1, X_train, y_train, cv=9, scoring='neg_log_loss')).mean().round(3)\n\n# f1 was also tested with worse results","518e625d":"y_test_pred = pd.DataFrame(dt_model_1.predict_proba(X_test), \n                        columns=dt_model_1.classes_)\n\nlog_loss(y_test, y_test_pred).mean().round(3)","b2c8bcd8":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV","5ceae4ea":"random_forest = RandomForestClassifier(n_estimators=100,max_leaf_nodes=100, min_weight_fraction_leaf= 0.01)\nmy_param_grid = [{\"n_estimators\": [30, 70 ,100],\"max_leaf_nodes\": [30, 70, 100], \"min_samples_leaf\" : [30, 70, 100]}]\nk = 7\nrandom_forest_gs = GridSearchCV(random_forest, my_param_grid, scoring='neg_log_loss',cv=k)\nrandom_forest_gs.fit(X_train, y_train)","1a1f0077":"random_forest_gs.best_params_","26f5e079":"random_forest_2 = random_forest_gs.best_estimator_","efa2c83e":"y_test_pred = pd.DataFrame(random_forest_2.predict_proba(X_test), \n                           columns=random_forest_2.classes_)","bb6ac155":"log_loss(y_true=y_test, y_pred=y_test_pred).mean().round(3)","2cff8e55":"(-cross_val_score(random_forest_2, X_train, y_train, cv=10, scoring='neg_log_loss')).mean().round(3)","3626c4fa":"y_test_pred = pd.DataFrame(dt_model_1.predict_proba(X_test), \n                        columns=dt_model_1.classes_)\n\nlog_loss(y_test, y_test_pred).mean().round(3)","8b1d74f8":"from sklearn.ensemble import VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier","07cfa850":"clf_bagging = BaggingClassifier(base_estimator=random_forest_2, n_estimators=100, max_features=0.8)\nclf_bagging.fit(X_train, y_train)\n\n# done also with dt_model_1 (Decision Tree Classifier), with similar results","1b3a1b2e":"print(f\"Begging classifier:\\n \\\n    \\ttrain accuracy: {clf_bagging.score(X_train, y_train):.3f}\\n \\\n    \\ttest accuracy: {clf_bagging.score(X_test, y_test):.3f}\")","8181a501":"clf_adaboost = AdaBoostClassifier(base_estimator=random_forest_2,\n                                  n_estimators=200,\n                                  learning_rate=0.01)\nclf_adaboost.fit(X_train, y_train)","0d070642":"print(f\"DT ADA boosting classifier:\\n \\\n    \\ttrain accuracy: {clf_adaboost.score(X_train, y_train):.3f}\\n \\\n    \\ttest accuracy: {clf_adaboost.score(X_test, y_test):.3f}\")","4100f5c8":"from sklearn.linear_model import LogisticRegression","01e770a9":"nba_lr = LogisticRegression(max_iter=1000)","b0f3f536":"X = nba_df_dumm.drop(['WINorLOSS'], axis=1)\ny = nba_df_dumm.WINorLOSS\n\nnba_lr.fit(X, y)","2e26e8f5":"accuracy_score(y_true=y_train,\n               y_pred=nba_lr.predict(X_train)).mean().round(3)","0354b3c9":"(-cross_val_score(nba_lr, X_train, y_train, cv=9, scoring='neg_log_loss')).mean().round(3)","0689d966":"cross_val_score(nba_lr, X_train, y_train, cv=9, scoring='accuracy').mean().round(3)","f02d089a":"### Ensamble Models Using Random Forest Classifier:","665b141f":"#### Team Rank (below) was tested, but caused features leakage, thus ignored","d73c681a":"### Avg last 5_games:","f3349ce0":"\nIn order to improve score, a limited set of features were selected by Features Importance. Since 'Home' and 'wins_streak' were the most important by far, they were removed in order to select for the best of weaker features. Consequently, limited DF was analysed ('wins_streak', 'Home', 'avg_FreeThrowsAttempted', 'avg_FreeThrows.', 'avg_TotalFouls', 'rest_days_scale'). Alas, with no better results...","bdd54e65":"### File read and Data Cleaning:","ba202e73":"This project is based on the approach that one is taking when going to gamble on a team in an upcoming game. Therefore, data is converted to past-data. Team and Opponent names were removed, but their average scoring from past games were taken into consideration\n\nNotebook was created with the help of Zohar Hirsch\n","406e8dfe":"Model is Valid","fef902a9":"### DF for ML:","1ec9886a":"### Bagging:","e5020154":"### Decision Tree:","1a66ba26":"#### Create Wins Streak:","6c10394a":"### Logistic Regression:","59e34bb9":"Model is Valid","63ac992b":"### Calculating Rest Days:","7ed7aabd":"## Running Models:","7bfae810":"https:\/\/www.thesportsgeek.com\/sports-betting\/nba\/  and https:\/\/www.lineups.com\/betting\/nba-strategy\/\n\nGAME DAYS WITH NO REST:\n- 3IN4-B2B: 3rd game in 4 days w\/ playing on last 2 consecutive days (\u2026X+O+[X+X])\n- Soft-B2B: 2nd game in 2 consecutive days. Pattern=\u2026[X+X]\nAT LEAST 1 DAY REST:\n- 3IN4: 3rd game in 4 days and had 1 day rest yesterday. Pattern=\u2026X+X+O+X\n- 1: Had 1 day rest (yesterday) and a playing a game today. Pattern=\u2026O+X\n- 2: Had 2 days rest and a playing a game a game today. Pattern=\u2026O+O+X\n- 3+: 3 or more days rest and playing a game today. Pattern=\u2026O+O+O+X\n\nConsequently, scale is:\n- Consecutive game = -1\n- Rested Yesterday = 3\n- Rested 2 days ago = 2\n- Rested 3 days ago = 1","13dd156b":"### Performance Index Rating calculates as:\nPIR = (Points + Rebounds + Assists + Steals + Blocks + Fouls Drawn) \u2013 (Missed Field Goals + Missed Free Throws + Turnovers + Shots Rejected + Fouls Committed)","28c2aa82":"### AdaBoost:","54dbb9f5":"Ensemble models are presented although they didn't display improved scoring","ca9430c1":"## Features Engineering:","c42b0549":"### Random Forest & Grid Search:"}}