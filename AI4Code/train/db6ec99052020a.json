{"cell_type":{"fcaf9166":"code","1e22b6ab":"code","4ab33f07":"code","5b0f1640":"code","940743a7":"code","65483d2a":"code","1b2ce789":"code","39977180":"code","8cbd9e33":"code","3f811ae9":"code","1977dd79":"code","2ba467a0":"code","9d715efa":"code","84928bbb":"code","e9c28d07":"markdown","c7a17003":"markdown","8d771568":"markdown","384a280a":"markdown","c9d77ff8":"markdown","7caea81f":"markdown"},"source":{"fcaf9166":"import numpy as np \nimport pandas as pd\nimport os\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,UpSampling2D,Concatenate,Input,Softmax\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint","1e22b6ab":"EPOCHS=10\nBATCH_SIZE=10\nHEIGHT=256\nWIDTH=256\nN_CLASSES=13","4ab33f07":"def LoadImage(name, path):\n    img = Image.open(os.path.join(path, name))\n    img = np.array(img)\n    \n    image = img[:,:256]\n    mask = img[:,256:]\n    \n    return image, mask\n\n\ndef bin_image(mask):\n    bins = np.array([20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240])\n    new_mask = np.digitize(mask, bins)\n    return new_mask\n\ndef getSegmentationArr(image, classes, width=WIDTH, height=HEIGHT):\n    seg_labels = np.zeros((height, width, classes))\n    img = image[:, : , 0]\n\n    for c in range(classes):\n        seg_labels[:, :, c] = (img == c ).astype(int)\n    return seg_labels\n\ndef give_color_to_seg_img(seg, n_classes=N_CLASSES):\n    \n    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n    colors = sns.color_palette(\"hls\", n_classes)\n    \n    for c in range(n_classes):\n        segc = (seg == c)\n        seg_img[:,:,0] += (segc*( colors[c][0] ))\n        seg_img[:,:,1] += (segc*( colors[c][1] ))\n        seg_img[:,:,2] += (segc*( colors[c][2] ))\n\n    return(seg_img)\n\nclasses = 13","5b0f1640":"train_folder = \"..\/input\/cityscapes-image-pairs\/cityscapes_data\/train\"\nvalid_folder = \"..\/input\/cityscapes-image-pairs\/cityscapes_data\/val\"\n\nnum_of_training_samples = len(os.listdir(train_folder)) \nnum_of_valid_samples = len(os.listdir(valid_folder))\n\ndef DataGenerator(path, batch_size=BATCH_SIZE, classes=N_CLASSES):\n    files = os.listdir(path)\n    while True:\n        for i in range(0, len(files), batch_size):\n            batch_files = files[i : i+batch_size]\n            imgs=[]\n            segs=[]\n            for file in batch_files:\n                image, mask = LoadImage(file, path)\n                mask_binned = bin_image(mask)\n                labels = getSegmentationArr(mask_binned, classes)\n\n                imgs.append(image)\n                segs.append(labels)\n\n            yield np.array(imgs), np.array(segs)","940743a7":"train_gen = DataGenerator(train_folder, batch_size=BATCH_SIZE)\nval_gen = DataGenerator(valid_folder, batch_size=BATCH_SIZE)","65483d2a":"imgs, segs = next(train_gen)\nimgs.shape, segs.shape","1b2ce789":"image = imgs[0]\nmask = give_color_to_seg_img(np.argmax(segs[0], axis=-1))\nmasked_image = cv2.addWeighted(image\/255, 0.5, mask, 0.5, 0)\n\nfig, axs = plt.subplots(1, 3, figsize=(20,20))\naxs[0].imshow(image)\naxs[0].set_title('Original Image')\naxs[1].imshow(mask)\naxs[1].set_title('Segmentation Mask')\n#predimg = cv2.addWeighted(imgs[i]\/255, 0.6, _p, 0.4, 0)\naxs[2].imshow(masked_image)\naxs[2].set_title('Masked Image')\nplt.show()","39977180":"def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    p = MaxPool2D((2, 2), (2, 2))(c)\n    return c, p\n\ndef up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    us = UpSampling2D((2, 2))(x)\n    concat = Concatenate()([us, skip])\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    return c\n\ndef bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    return c\n\ndef UNet():\n    f = [16, 32, 64, 128, 256]\n    inputs = Input((HEIGHT,WIDTH,3))\n    \n    p0 = inputs\n    c1, p1 = down_block(p0, f[0]) #128 -> 64\n    c2, p2 = down_block(p1, f[1]) #64 -> 32\n    c3, p3 = down_block(p2, f[2]) #32 -> 16\n    c4, p4 = down_block(p3, f[3]) #16->8\n    \n    bn = bottleneck(p4, f[4])\n    \n    u1 = up_block(bn, c4, f[3]) #8 -> 16\n    u2 = up_block(u1, c3, f[2]) #16 -> 32\n    u3 = up_block(u2, c2, f[1]) #32 -> 64\n    u4 = up_block(u3, c1, f[0]) #64 -> 128\n    \n    outputs = Conv2D(13, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n    model = Model(inputs, outputs)\n    return model","8cbd9e33":"checkpoint = ModelCheckpoint('seg_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')","3f811ae9":"model = UNet()\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\nmodel.summary()","1977dd79":"TRAIN_STEPS = num_of_training_samples\/\/BATCH_SIZE+1\nVAL_STEPS = num_of_valid_samples\/\/BATCH_SIZE+1\n\nmodel.fit_generator(train_gen, validation_data=val_gen, steps_per_epoch=TRAIN_STEPS, \n                    validation_steps=VAL_STEPS, epochs=EPOCHS, callbacks = checkpoint)","2ba467a0":"model.load_weights(\".\/seg_model.hdf5\")","9d715efa":"loss = history.history[\"val_loss\"]\nacc = history.history[\"val_acc\"]\n\nplot.figure(figsize=(12, 6))\nplot.subplot(211)\nplot.title(\"Val. Loss\")\nplot.plot(loss)\nplot.xlabel(\"Epoch\")\nplot.ylabel(\"Loss\")\n\nplot.subplot(212)\nplot.title(\"Val. Accuracy\")\nplot.plot(acc)\nplot.xlabel(\"Epoch\")\nplot.ylabel(\"Accuracy\")\n\nplot.tight_layout()\n#plot.savefig(\"learn.png\", dpi=150)\nplot.show()","84928bbb":"max_show = 1\nimgs, segs = next(val_gen)\npred = model.predict(imgs)\n\nfor i in range(max_show):\n    _p = give_color_to_seg_img(np.argmax(pred[i], axis=-1))\n    _s = give_color_to_seg_img(np.argmax(segs[i], axis=-1))\n\n    predimg = cv2.addWeighted(imgs[i]\/255, 0.5, _p, 0.5, 0)\n    trueimg = cv2.addWeighted(imgs[i]\/255, 0.5, _s, 0.5, 0)\n    \n    plt.figure(figsize=(12,6))\n    plt.subplot(121)\n    plt.title(\"Prediction\")\n    plt.imshow(predimg)\n    plt.axis(\"off\")\n    plt.subplot(122)\n    plt.title(\"Original\")\n    plt.imshow(trueimg)\n    plt.axis(\"off\")\n    plt.tight_layout()\n    plt.savefig(\"pred_\"+str(i)+\".png\", dpi=150)\n    plt.show()","e9c28d07":"# Utility Functions","c7a17003":"# Training","8d771568":"# Dataset","384a280a":"# Importing Libraries","c9d77ff8":"# Model","7caea81f":"# Validation"}}