{"cell_type":{"1cf2b3bb":"code","941874dc":"code","e8e7dfd9":"code","e6b97acf":"code","08e44165":"code","928f564b":"code","a58f7e66":"code","4dc246cf":"code","e5db78d3":"code","c5a125c4":"markdown"},"source":{"1cf2b3bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport math\nimport itertools\nfrom wordcloud import WordCloud\nfrom itertools import combinations\n\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nSIA = SentimentIntensityAnalyzer()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nsns.set_style(\"whitegrid\")\nnotebookstart = time.time()\npd.options.display.max_colwidth = 500\npd.options.display.max_rows = 999\npd.options.display.width = 300\npd.options.display.max_columns = 100","941874dc":"def big_bar_cloud(plot_df, plt_set, x_var, columns, figsize, custom_palette = sns.color_palette(\"Paired\")):\n    \"\"\"\n    Iteratively Plot BarPlots\n    \"\"\"\n    palette = itertools.cycle(custom_palette)\n    rows = math.ceil(len(plt_set)\/columns)\n    n_plots = rows*columns\n    f,ax = plt.subplots(rows, columns, figsize = figsize)\n    for i in range(0,n_plots):\n        ax = plt.subplot(rows, columns, i+1)\n        if i < len(plt_set):\n            col = plt_set[i]\n            sns.barplot(data=df, x=x_var, y=col, ax=ax, color=next(palette), alpha=.8)\n            ax.set_title(\"{} by {}\".format(col, x_var))\n        else:\n            ax.axis('off')\n    plt.tight_layout(pad=2)\n    \n    \n    \ndef rank_correlations(df, figsize=(12,20), n_charts = 18, polyorder = 2, custom_palette = sns.color_palette(\"Paired\", 5)):\n    # Rank Correlations\n    palette = itertools.cycle(custom_palette)\n    continuous_rankedcorr = (df\n                             .corr()\n                             .unstack()\n                             .drop_duplicates().reset_index())\n    continuous_rankedcorr.columns = [\"f1\",\"f2\",\"Correlation Coefficient\"]\n    continuous_rankedcorr['abs_cor'] = abs(continuous_rankedcorr[\"Correlation Coefficient\"])\n    continuous_rankedcorr.sort_values(by='abs_cor', ascending=False, inplace=True)\n\n    # Plot Top Correlations\n    top_corr = [(x,y,cor) for x,y,cor in list(continuous_rankedcorr.iloc[:, :3].values) if x != y]\n    f, axes = plt.subplots(int(n_charts\/3),3, figsize=figsize, sharex=False, sharey=False)\n    row = 0\n    col = 0\n    for (x,y, cor) in top_corr[:n_charts]:\n        if col == 3:\n            col = 0\n            row += 1\n        g = sns.regplot(x=x, y=y, data=df, order=polyorder, ax = axes[row,col], color=next(palette))\n        axes[row,col].set_title('{} and {}'.format(x, y))\n        axes[row,col].text(0.18, 0.93,\"Cor Coef: {:.2f}\".format(cor),\n                           ha='center', va='center', transform=axes[row,col].transAxes)\n        col += 1\n    plt.tight_layout(pad=0)\n    plt.show()\n    \n    \n# Data Exploration\ndef custom_describe(df, value_count_n = 5):\n    \"\"\"\n    Custom Describe Function - More Tailored to categorical type variables..\n    \"\"\"\n    unique_count = []\n    for x in df.columns:\n        unique_values_count = df[x].nunique()\n        value_count = df[x].value_counts().iloc[:5]\n\n        value_count_list = []\n        value_count_string = []\n        \n        for vc_i in range(0,value_count_n):\n            value_count_string += [\"ValCount {}\".format(vc_i+1),\n                                   \"Occ\"]\n            if vc_i <= unique_values_count - 1:\n                value_count_list.append(value_count.index[vc_i])\n                value_count_list.append(value_count.iloc[vc_i])\n            else:\n                value_count_list.append(np.nan)\n                value_count_list.append(np.nan)\n        \n        unique_count.append([x,\n                             unique_values_count,\n                             df[x].isnull().sum(),\n                             df[x].dtypes] + value_count_list)\n        \n    print(\"Dataframe Dimension: {} Rows, {} Columns\".format(*df.shape))\n    return pd.DataFrame(unique_count,\n            columns=[\"Column\",\"Unique\",\"Missing\",\"dtype\"\n                    ] + value_count_string\n                       ).set_index(\"Column\")\n\nprint(\"Helper Functions Ready\")","e8e7dfd9":"categorical_cols = [\n    'age'\n]\n\n\ncontinuous_cols = [\n    'alcohol-use',\n    'alcohol-frequency',\n    'marijuana-use',\n    'marijuana-frequency',\n    'cocaine-use',\n    'cocaine-frequency',\n    'crack-use',\n    'crack-frequency',\n    'heroin-use',\n    'heroin-frequency',\n    'hallucinogen-use',\n    'hallucinogen-frequency',\n    'inhalant-use',\n    'inhalant-frequency',\n    'pain-releiver-use',\n    'pain-releiver-frequency',\n    'oxycontin-use',\n    'oxycontin-frequency',\n    'tranquilizer-use',\n    'tranquilizer-frequency',\n    'stimulant-use',\n    'stimulant-frequency',\n    'meth-use',\n    'meth-frequency',\n    'sedative-use',\n    'sedative-frequency',\n    'n'\n]\n\ndf = pd.read_csv(\"\/kaggle\/input\/fivethirtyeight-drug-use-by-age-dataset\/drug-use-by-age.csv\")\nprint(\"DF Shape: {} Rows, {} Columns\".format(*df.shape))\n\n# Data Cleaning\nfor col in continuous_cols:\n    df[col] = pd.to_numeric(df[col], errors='coerce')","e6b97acf":"display(df.head(30))","08e44165":"print(\"Categorical Variables\")\ndisplay(custom_describe(df[categorical_cols]))\nprint(\"Continuous Variables\")\ndisplay(df[continuous_cols].describe().T)","928f564b":"big_bar_cloud(plot_df=df, plt_set=continuous_cols, x_var='age', columns=2, figsize=[20,32])","a58f7e66":"# Plot Correlation Matrix\nf, ax = plt.subplots(figsize=[14,12])\nax = sns.heatmap(df[continuous_cols].corr(), \n                 annot=True, fmt=\".1f\",\n                 vmin=-1, vmax=1,\n                 cbar_kws={'label': 'Correlation Coefficient'})\nax.set_title(\"Continuous Variable Correlation Matrix\")\nplt.show()","4dc246cf":"rank_correlations(df = df.loc[:,continuous_cols])","e5db78d3":"print(\"Script Complete - Runtime: {:.2f} Minutes\".format((time.time() - notebookstart) \/ 60))","c5a125c4":"# Substance Abuse and Mental Health Data Archive (SAMHDA)\n## 2012 Survey on Drug Use by Age Groups\n_By Nick Brooks, November 2020_\n\n**Resources:**\n- https:\/\/fivethirtyeight.com\/features\/how-baby-boomers-get-high\/\n- https:\/\/github.com\/fivethirtyeight\/data"}}