{"cell_type":{"c53def3c":"code","aac7ec18":"code","2d154971":"code","9436c10d":"code","dd1ee06a":"code","c27c4b80":"code","e2b5dde0":"code","012a8742":"code","15c9ac79":"code","7049f32a":"code","83838aa3":"code","8aac9171":"code","c2ad255a":"code","5f92fcbe":"code","96360630":"code","c3fed432":"code","4cb1212c":"markdown","964eb732":"markdown","4d3e69b2":"markdown","6bf43237":"markdown"},"source":{"c53def3c":"#Kutuphanelerin yuklenmesi\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","aac7ec18":"def rfm():\n    #Tum kolonlar\u0131n gosterilmesini saglar\n    pd.set_option('display.max_columns', None) \n    df = pd.read_excel(\"..\/input\/turkish-market-sales-dataset-with-9000items\/MarketSales.xlsx\")\n    df.head()\n\n    #Tarihlerin tekil say\u0131s\u0131n\u0131 verir.\n    df[\"STARTDATE\"].nunique()\n\n    #Eksik gozlemleri verir.\n    df.isnull().sum()\n\n    #veri boyutunun sorgusu\n    df.shape\n\n    # essiz urun sayisi\n    df.CATEGORY_NAME1.nunique()\n    df.CATEGORY_NAME2.nunique()\n    df.CATEGORY_NAME3.nunique()\n\n    #Essiz 354 adet urun bulunmaktad\u0131r.\n    df.BRAND.nunique()\n\n    # urunlerin ka\u00e7 kere gectigini g\u00f6steriyor\n    df.CATEGORY_NAME3.value_counts().head(30)\n\n    # en cok siparis edilen urun hangisidir ? \n    # iptallerden dolay\u0131 eksi deger gozukuyor\n    df.groupby(\"CATEGORY_NAME3\") .agg({\"AMOUNT\":\"sum\"}).head()\n\n    #En cok hangi \u00fcr\u00fcn al\u0131nm\u0131s.\n    df.groupby(\"CATEGORY_NAME3\").agg({\"AMOUNT\":\"sum\"}).sort_values(\"AMOUNT\" ,ascending = False)\n\n    #Toplamda odenen ucret\n    df[\"TotalPrice\"] = df[\"AMOUNT\"] * df[\"PRICE\"]\n    df.head()\n\n    #Faturaya gore en fazla odenen ucret.\n    df.groupby(\"FICHENO\").agg({\"TotalPrice\":\"sum\"}).head()\n\n    # en fazla al\u0131\u015fveri\u015f yapan sehir\n    df.CITY.value_counts()[0:5]\n\n    # En fazla para harcayan sehir\n    df.groupby(\"CITY\").agg({\"TotalPrice\":\"sum\"}).sort_values(\"TotalPrice\" , ascending = False).head()\n\n    # \u00c7eyrekl\u0131klerinin gosterilmesi\n    df.describe([0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99]).T\n\n    # Ayk\u0131r\u0131 olan degerlerin gosterimi.\n    for feature in [\"AMOUNT\",\"PRICE\",\"TotalPrice\"]:\n\n        Q1 = df[feature].quantile(0.01)\n        Q3 = df[feature].quantile(0.99)\n        IQR = Q3-Q1\n        upper = Q3 + 1.5*IQR\n        lower = Q1 - 1.5*IQR\n\n        if df[(df[feature] > upper) | (df[feature] < lower)].any(axis=None):\n            print(feature,\"yes\")\n            print(df[(df[feature] > upper) | (df[feature] < lower)].shape[0])\n        else:\n            print(feature, \"no\")\n\n\n    # Recency\n    #En son al\u0131sveris yap\u0131lan tarih.\n    df[\"STARTDATE\"].max()\n\n    # Bugunun tarihi olarak en son gecen tarihi ekledim.\n    import datetime as dt\n    today_date = dt.datetime(2017 , 11 ,16)\n    today_date\n\n    # Musterilerin en son ne zaman al\u0131sveris yapt\u0131ga bak\u0131yoruz.\n    df.groupby(\"CLIENTCODE\").agg({\"STARTDATE\":\"max\"}).head()\n\n    #Musterilerin en son al\u0131sveris yapt\u0131g\u0131 tarihten bugunu c\u0131kar\u0131yoruz.\n    temp_df = (today_date - df.groupby(\"CLIENTCODE\").agg({\"STARTDATE\":\"max\"}))\n\n    #Degisken ismini degistirdim.\n    temp_df.rename(columns = {\"STARTDATE\":\"Recency\"} , inplace= True)\n\n    #Sadece g\u00fcn say\u0131s\u0131n\u0131 elde ettik.\n    recency_df = temp_df.Recency.apply(lambda x : x.days)\n\n    # Frequency (s\u0131kl\u0131k)\n    freq_df = df.groupby(\"CLIENTCODE\").agg({\"FICHENO\":\"nunique\"})\n\n    #Degisken ismini degistirdim.\n    freq_df.rename(columns = {\"FICHENO\" : \"Frequency\"} , inplace = True)\n\n    # Monetary (musterinin toplam b\u0131rakt\u0131g\u0131 para m\u0131ktar\u0131)\n    monetary_df = df.groupby(\"CLIENTCODE\").agg({\"TotalPrice\":\"sum\"})\n    monetary_df.head()\n\n    #Degisken ismini degistirdim.\n    monetary_df.rename(columns= {\"TotalPrice\":\"Monetary\"} , inplace = True)\n\n    #Degiskenlerin birlestirilmesi\n    rfm = pd.concat([recency_df , freq_df , monetary_df] , axis = 1)\n\n    # Skorlama i\u015flemi\n    rfm[\"RecencyScore\"] = pd.qcut(rfm[\"Recency\"], 5, labels = [5, 4 , 3, 2, 1])\n    rfm.head()\n    rfm[\"Recency\"].min()\n    rfm[\"Frequency\"].min()\n\n    # Skorlama i\u015flemi\n    rfm[\"FrequencyScore\"]= pd.qcut(rfm[\"Frequency\"].rank(method=\"first\"),5, labels=[1,2,3,4,5])\n\n    # Skorlama i\u015flemi\n    rfm[\"MonetaryScore\"] = pd.qcut(rfm[\"Monetary\"] , 5 , labels = [1,2,3,4,5])\n\n    rfm = rfm.dropna()\n\n    # rfm skorlar\u0131 kategorik degere donusturuldu\n    rfm[\"rfm_score\"] = (rfm.RecencyScore.astype(str)+\n                        rfm.FrequencyScore.astype(str) +\n                        rfm.MonetaryScore.astype(str))\n\n    #En cok sipari\u015f veren ve sitede aktif olan ki\u015filerin getirlmesi.\n    rfm.loc[rfm.rfm_score==\"555\"]\n\n    # Regular Expressions (D\u00fczenli \u0130fadeler) kullan\u0131larak RFM haritas\u0131 \u00e7\u0131kar\u0131ld\u0131\n    seg_map = {\n        r'[1-2][1-2]': 'Hibernating',\n        r'[1-2][3-4]': 'At Risk',\n        r'[1-2]5': 'Can\\'t Loose',\n        r'3[1-2]': 'About to Sleep',\n        r'33': 'Need Attention',\n        r'[3-4][4-5]': 'Loyal Customers',\n        r'41': 'Promising',\n        r'51': 'New Customers',\n        r'[4-5][2-3]': 'Potential Loyalists',\n        r'5[4-5]': 'Champions'\n    }\n\n    #Monetary degeri d\u0131sar\u0131da b\u0131rak\u0131larak ,  FrequencyScore ve RecencyScore degerlerinin birlestirilerek segment isminde degisken olusturulmas\u0131.\n    rfm[\"segment\"] =rfm.RecencyScore.astype(str) + rfm.FrequencyScore.astype(str)\n    rfm.head() \n\n    #OLusturdugumuz regex sozlugunun tum segment'e uygulanarak isimlendirdim.\n    rfm.segment = rfm.segment.replace(seg_map , regex = True)\n\n    #df ve rfm'in birlestilmesi\n    result = pd.merge(df, rfm, on='CLIENTCODE')\n    \n    #Segment'e gore gruplar\u0131n toplam harcamas\u0131n\u0131n medyan degeri.\n    #result.groupby(\"segment\").agg({\"TotalPrice\":np.median})\n\n    # Segmentlerin recency , frequency ve monetary degerlerine gore ortalama ve medyan\u0131n incelenmesi.\n    #rfm[[\"segment\",\"Recency\",\"Frequency\",\"Monetary\"]].groupby(\"segment\").agg([\"mean\",\"median\",\"count\"])\n    return result","2d154971":"rfm()","9436c10d":"# B\u0130R SUBEN\u0130N TUM SEPETLER\u0130NE YAPILAN B\u0130RL\u0130KTEL\u0130K ANAL\u0130Z\u0130D\u0130R.\n\ndef normal( support , threshold):\n    \"\"\"\n    support = Birliktelik analizinde kullan\u0131lan \"min_support\" degeri\n    threshold = Birliktelik analizinde kullan\u0131lan \"association_rules\" fonksiyonun degeri.\n    \"\"\"\n    #Kutuphanelerin yuklenmesi\n    import matplotlib.pyplot as plt\n    import pandas as pd\n    import seaborn as sns\n   \n    #Verinin fonksiyona tan\u0131mlanmas\u0131\n    def satislar_load():\n        dff =pd.read_excel(\"..\/input\/turkish-market-sales-dataset-with-9000items\/MarketSales.xlsx\")\n        return dff\n    \n    #Veri setinin atanmas\u0131\n    df = satislar_load()\n    \n    #Veride bulunan sehirlerden birinin secilmesi\n    df = df.loc[df.BRANCH == \"\u0130stanbul Subesi\"]\n\n\n    #Verideki tarih k\u0131sm\u0131n\u0131 g\u00fcn , ay , y\u0131l olarak ay\u0131r\u0131lmas\u0131\n    df[\"STARTDATE\"] = df[\"STARTDATE\"].astype('datetime64[ns]')\n    df[\"year\"] =df[\"STARTDATE\"].dt.year\n    df[\"month\"] =df[\"STARTDATE\"].dt.month\n    df[\"day\"] =df[\"STARTDATE\"].dt.day\n    df[\"day_name\"]= df.STARTDATE.dt.day_name()\n\n    #df'in yedeginin al\u0131nmas\u0131\n    df_yedek = df.copy()\n\n    #Urunlerin tekil isimlerinin al\u0131nmas\u0131\n    df_urunler = df_yedek.CATEGORY_NAME3.unique()\n\n    #tum zamanlara gore urunlerin sat\u0131s\u0131\n    #for a in df_urunler:\n        #for i in [\"day\"  ,\"day_name\"]:\n            #sns.countplot(df_yedek.loc[df_yedek.CATEGORY_NAME3 == a, \"CATEGORY_NAME3\"], hue=df_yedek[i])\n            #plt.show()\n\n\n    ### birliktelik analizi\n    df_genel = df_yedek.copy()\n     \n    #Urunler\u0131n virgul ile ayr\u0131lmas\u0131\n    df_yedek = df_yedek.CATEGORY_NAME3.str.strip(\",\")\n    \n    #Verilerde birlestirme isleminin yap\u0131lmas\u0131\n    dff = pd.concat([df_genel.FICHENO , df_yedek] , axis = 1 )\n    \n    #Eksik degerlerin dusurulmesi\n    dff = dff.dropna()\n\n    #Her kesilen faturada birlikte al\u0131nan urunlerin tek sat\u0131rda virgulle birlestirilmesi\n    dff = dff.groupby('FICHENO')['CATEGORY_NAME3'].agg(','.join).reset_index()\n    \n    #FICHENO degiskeninin dusurulmesi\n    dff = dff.drop(\"FICHENO\" , axis = 1)\n    \n    #Virgule gore urunlerin ayr\u0131lmas\u0131 \u0131slemi\n    data = list(dff['CATEGORY_NAME3'].apply(lambda x:x.split(\",\")))\n    \n\n    #Enkod isleminin yap\u0131lmas\u0131\n    from mlxtend.preprocessing import TransactionEncoder\n    tencoder = TransactionEncoder()\n    te_data = tencoder.fit(data).transform(data)\n    df = pd.DataFrame(te_data, columns=tencoder.columns_)\n   \n\n    #Apriori algoritmas\u0131n\u0131n kullan\u0131lmas\u0131\n    from mlxtend.frequent_patterns import apriori,  association_rules\n    df1 = apriori(df, min_support=support, use_colnames=True)\n   \n    #Birliktelik kurallar\u0131n\u0131n c\u0131kar\u0131lmas\u0131\n    df_association = association_rules(df1, metric = 'confidence', min_threshold =threshold)\n    \n    return df_association.sort_values(by='confidence', ascending=False).reset_index()\n\n","dd1ee06a":"normal( 0.01 , 0.5)","c27c4b80":"# GUN OLARAK DEGERLEND\u0130RME\ndef day( support , threshold , day , plot = False ):\n    \"\"\"\n    support = Birliktelik analizinde kullan\u0131lan \"min_support\" degeri\n    threshold = Birliktelik analizinde kullan\u0131lan \"association_rules\" fonksiyonun degeri.\n    day = Secilecek gun baz\u0131nda birliktelik analizi uygular.\n    plot = \"True\" yap\u0131ld\u0131g\u0131nda urunler\u0131n gun bazl\u0131 grafiklerini verir.\n    \"\"\"\n    #Kutuphanelerin yuklenmesi\n    import matplotlib.pyplot as plt\n    import pandas as pd\n    import seaborn as sns\n    \n    #Verinin fonksiyona tan\u0131mlanmas\u0131\n    def satislar_load():\n        dff =pd.read_excel(\"..\/input\/turkish-market-sales-dataset-with-9000items\/MarketSales.xlsx\")\n        return dff\n    \n    #Veri setinin atanmas\u0131\n    df = satislar_load()\n    \n    #Veride bulunan sehirlerden birinin secilmesi\n    df = df.loc[df.BRANCH == \"\u0130stanbul Subesi\"]\n\n\n    ## ucuncu. ad\u0131m\n\n    #Verideki tarih k\u0131sm\u0131n\u0131 g\u00fcn , ay , y\u0131l olarak ay\u0131r\u0131lmas\u0131\n    df[\"STARTDATE\"] = df[\"STARTDATE\"].astype('datetime64[ns]')\n    df[\"year\"] =df[\"STARTDATE\"].dt.year\n    df[\"month\"] =df[\"STARTDATE\"].dt.month\n    df[\"day\"] =df[\"STARTDATE\"].dt.day\n    df[\"day_name\"]= df.STARTDATE.dt.day_name()\n\n\n    #df'in yedeginin al\u0131nmas\u0131\n    df_yedek = df.copy()\n    \n    #Secilecek gun uzerinden \u0131slemler yap\u0131lacakt\u0131r\n    df_yedek = df_yedek.loc[df_yedek.day_name == day]\n    \n    #Urunlerin tekil isimlerinin al\u0131nmas\u0131\n    df_urunler = df_yedek.CATEGORY_NAME3.unique()\n\n    #tum zamanlara gore urunlerin sat\u0131s\u0131\n    \n    if plot:\n        for a in df_urunler:\n            for i in [\"hour\" ,\"day_name\"]:\n                sns.countplot(df_yedek.loc[df_yedek.CATEGORY_NAME3 == a, \"CATEGORY_NAME3\"], hue=df_yedek[i])\n                plt.show()\n\n    ### birliktelik analizi\n    df_genel = df_yedek.copy()\n    \n    #Urunler\u0131n virgul ile ayr\u0131lmas\u0131\n    df_yedek = df_yedek.CATEGORY_NAME3.str.strip(\",\")\n\n    #Verilerde birlestirme isleminin yap\u0131lmas\u0131\n    dff = pd.concat([df_genel.FICHENO , df_yedek] , axis = 1 )\n    \n    #Eksik degerlerin dusurulmesi\n    dff = dff.dropna()\n\n    #Her kesilen faturada birlikte al\u0131nan urunlerin tek sat\u0131rda virgulle birlestirilmesi\n    dff = dff.groupby('FICHENO')['CATEGORY_NAME3'].agg(','.join).reset_index()\n\n    #FICHENO degiskeninin dusurulmesi\n    dff = dff.drop(\"FICHENO\" , axis = 1)\n    \n    #Virgule gore urunlerin ayr\u0131lmas\u0131 \u0131slemi\n    data = list(dff['CATEGORY_NAME3'].apply(lambda x:x.split(\",\")))\n    \n\n    #Enkod isleminin yap\u0131lmas\u0131\n    from mlxtend.preprocessing import TransactionEncoder\n    tencoder = TransactionEncoder()\n    te_data = tencoder.fit(data).transform(data)\n    df = pd.DataFrame(te_data, columns=tencoder.columns_)\n   \n\n    #Apriori algoritmas\u0131n\u0131n kullan\u0131lmas\u0131\n    from mlxtend.frequent_patterns import apriori,  association_rules\n    df1 = apriori(df, min_support=support, use_colnames=True)\n   \n    #Birliktelik kurallar\u0131n\u0131n c\u0131kar\u0131lmas\u0131\n    df_association = association_rules(df1, metric = 'confidence', min_threshold =threshold)\n    \n    return df_association.sort_values(by='confidence', ascending=False).reset_index()","e2b5dde0":"day( 0.01 , 0.50 , \"Monday\" )","012a8742":"day( 0.01 , 0.50 , \"Tuesday\" )","15c9ac79":"day( 0.01 , 0.50 , \"Wednesday\" )","7049f32a":"day( 0.01 , 0.50 , \"Thursday\" )","83838aa3":"day( 0.01 , 0.50 , \"Friday\" )","8aac9171":"day( 0.01 , 0.50 , \"Saturday\" )","c2ad255a":"day( 0.01 , 0.50 , \"Sunday\" )","5f92fcbe":"#CLTV\n#import modules\nimport pandas as pd # for dataframes\nimport matplotlib.pyplot as plt # for plotting graphs\nimport seaborn as sns # for plotting graphs\nimport datetime as dt\nimport numpy as np","96360630":"def cltv():\n    #Verinin fonksiyona tan\u0131mlanmas\u0131\n    def satislar_load():\n        dff =pd.read_excel(\"..\/input\/turkish-market-sales-dataset-with-9000items\/MarketSales.xlsx\")\n        return dff\n    #Veri setinin atanmas\u0131\n    df = satislar_load()\n    df.head()\n\n    #Calulate total purchase\n    df['TotalPurchase'] = df['AMOUNT'] * df['PRICE']\n\n    df=df.groupby('CLIENTCODE').agg({'STARTDATE': lambda date: (date.max() - date.min()).days,\n                                            'FICHENO': lambda num: len(num),\n                                            'AMOUNT': lambda quant: quant.sum(),\n                                            'TotalPurchase': lambda price: price.sum()})\n\n    # Change the name of columns\n    df.columns=['num_days','num_transactions','num_units','spent_money']\n    df.head()\n\n\n    #1. Calculate Average Order Value\n   \n    # Average Order Value\n    df['avg_order_value']=df['spent_money']\/df['num_transactions']\n\n    #2. Calculate Purchase Frequency\n\n    purchase_frequency=sum(df['num_transactions'])\/df.shape[0]\n\n    #3. Calculate Repeat Rate and Churn Rate\n\n    # Repeat Rate\n    repeat_rate=df[df.num_transactions > 1].shape[0]\/df.shape[0]\n\n    #Churn Rate\n    churn_rate=1-repeat_rate\n\n    # Profit Margin(Kar marj\u0131)\n    df['profit_margin']=df['spent_money']*0.10\n\n    # Customer Value\n    df['CLV']=(df['avg_order_value']*purchase_frequency)\/churn_rate\n\n    #Customer Lifetime Value\n    df['cust_lifetime_value']=df['CLV']*df['profit_margin']\n    return df","c3fed432":"cltv()","4cb1212c":"# CLTV","964eb732":"**GUN OLARAK DEGERLEND\u0130RME**","4d3e69b2":"# Birliktelik Analizi","6bf43237":"# RFM ANAL\u0130Z\u0130"}}