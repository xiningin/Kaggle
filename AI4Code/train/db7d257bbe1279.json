{"cell_type":{"69777fbc":"code","e96da7de":"code","0f73fab7":"code","b79b012b":"code","306f3719":"markdown","6fe30949":"markdown","bd45e727":"markdown","690b52e9":"markdown","6c67972d":"markdown","3fdf9583":"markdown"},"source":{"69777fbc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as DT\nfrom datetime import datetime\n\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n\n","e96da7de":"# Path of the file to read\ntrain_file_path = '..\/input\/train_technidus_clf.csv'\ntest_file_path = '..\/input\/test_technidus_clf.csv'\n\n#Variable to access data\ntrain_data=pd.read_csv(train_file_path)\ntest_data=pd.read_csv(test_file_path)\n\n#Describe the data\n#print(train_data.describe())\ntrain_data.shape\nprint('Test Data')\nprint(test_data.shape)\n\nprint('Train Data')\nprint(train_data.shape)\n#Check and print columns with missing values\nmissing_val_count_by_column = (train_data.isnull().sum())\n#print(missing_val_count_by_column [missing_val_count_by_column > 0])\n \ntrain_data.TotalChildren=train_data.TotalChildren.fillna(train_data.TotalChildren.mode())\ntrain_data.TotalChildren=train_data.TotalChildren.fillna(train_data.HomeOwnerFlag.mode())\n\nmissing_val_count_by_column2 = (train_data.isnull().sum())\n#print(missing_val_count_by_column2 [missing_val_count_by_column2 > 0])\n# Any results you write to the current directory are saved as output.\n\n","0f73fab7":"#Convert Education column to int\ndef Education_to_numeric(bp):\n    if bp == 'Bachelors ':\n        return 4\n    if bp == 'Partial College':\n        return 3\n    if bp == 'High School':\n        return 2\n    if bp == 'Graduate Degree':\n        return 1\n    if bp == 'Partial High School':\n        return 0\nedu=train_data.Education\nedut=test_data.Education\nedupp = edu.apply(Education_to_numeric)\nedud = edut.apply(Education_to_numeric)\ntrain_data.Education=edupp\ntest_data.Education=edud\n\n\n\n#Convert Occupation column to int\ndef occupation_to_numeric(b):\n    if b == 'Clerical':\n        return 1\n    if b == 'Professional':\n        return 1\n    if b == 'Manual':\n        return 0\n    if b == 'Skilled Manual':\n        return 0\n    if b == 'Management':\n        return 1\np=train_data.Occupation\npt=test_data.Occupation\nd = p.apply(occupation_to_numeric)\ndt = pt.apply(occupation_to_numeric)\ntrain_data.Occupation=d\ntest_data.Occupation=dt\n\n\n\n#Convert Occupation column to int\ndef COUNTRY_to_numeric(d):\n    if d == 'Canada':\n        return 3\n    if d == 'France':\n        return 4\n    if d == 'Australia':\n        return 1\n    if d == 'United Kingdom':\n        return 2\n    if d == 'United States':\n        return 5\n    if d == 'Germany':\n        return 6\n\npon=train_data.CountryRegionName\nptu=test_data.CountryRegionName\nqa = pon.apply(COUNTRY_to_numeric)\nqaw= ptu.apply(COUNTRY_to_numeric)\ntrain_data.CountryRegionName=qa\ntest_data.CountryRegionName=qaw\n\n\n#Convert MaritalStatus column to int\ndef marital_to_numeric(ip):\n    if ip == 'M':\n        return 0\n    if ip == 'S':\n        return 1\npl= train_data.MaritalStatus\nplt=test_data.MaritalStatus\nml = pl.apply(marital_to_numeric)\nmlt = plt.apply(marital_to_numeric)\ntrain_data.MaritalStatus=ml\ntest_data.MaritalStatus=mlt\n\n#Convert Gender column to int\n#def car_to_numeric(car):\n #   if car ==0:\n  #      return 2\n   # if car >=1:\n    #    return 1\n#iz=train_data.NumberCarsOwned\n#izt=test_data.NumberCarsOwned\n#ci = iz.apply(car_to_numeric)\n#cti = izt.apply(car_to_numeric)\n#train_data.NumberCarsOwned=ci\n#test_data.NumberCarsOwned=cti\n\n\n#Convert Gender column to int\ndef region_to_numeric(a):\n    if a == 'M':\n        return 2\n    if a == 'F':\n        return 1\nz=train_data.Gender\nzt=test_data.Gender\nc = z.apply(region_to_numeric)\nct = zt.apply(region_to_numeric)\ntrain_data.Gender=c\ntest_data.Gender=ct\n\n\n#Convert train Birthdate column to age(int)\nyy=train_data.BirthDate\nnow=pd.Timestamp(DT.datetime.now())\nnuu = pd.to_datetime(yy)\nnuu=(now-nuu)\/365\nny=nuu.dt.days\ntrain_data.BirthDate=ny\n\n\n#Convert test Birthdate column to age(int)\nyyt=test_data.BirthDate\nnowt=pd.Timestamp(DT.datetime.now())\nnuut = pd.to_datetime(yyt)\nnuut=(nowt-nuut)\/365\nnyt=nuut.dt.days\ntest_data.BirthDate=nyt\n\n#childrennithome\n#df[\"ColC\"] = df[\"ColA\"].subtract(df[\"ColB\"], fill_value=0)\ntrain_data.PostalCode=train_data.TotalChildren.subtract(train_data.NumberChildrenAtHome, fill_value=0)\ntest_data.PostalCode=test_data.TotalChildren.subtract(test_data.NumberChildrenAtHome, fill_value=0)\n\n#income per children\ngh=train_data.YearlyIncome-train_data.TotalChildren\n#train_data.Suffix=gh\n\n\n#train_data.YearlyIncome=np.exp(train_data.YearlyIncome)\n#test_data.YearlyIncome=np.exp(test_data.YearlyIncome)\n\n#Convert Occupation column to string\ndef age_to_numeric(qa):\n    if qa <=37:\n        return 3\n    if 51>qa >=44:\n        return 4\n    if 58>qa >=51:\n        return 1\n    if 65>qa >=58:\n        return 2\n    if qa >=65:\n        return 5\ntrain_data.BirthDate=100\/train_data.BirthDate**3.9\ntest_data.BirthDate=100\/test_data.BirthDate**3.9\n#di = pti.apply(age_to_numeric)\n#dti= ptit.apply(age_to_numeric)\n#train_data.BirthDate=di\n#test_data.BirthDate=dti\n\n\ndef ave_to_numeric(qa):\n    if qa <40:\n        return 1\n    if 50>qa >=40:\n        return 2\n    if 59>qa >=50:\n        return 3\n    if 65>qa >=59:\n        return 4\n    if qa >=65:\n        return 5\n#lo=train_data.AveMonthSpend*100\n#lot=test_data.AveMonthSpend*100\n#dp = lo.apply(ave_to_numeric)\n#dtp= lot.apply(ave_to_numeric)\n#train_data.AveMonthSpend=lo\n#test_data.AveMonthSpend=lot\ntrain_data.AveMonthSpend=(np.log(train_data.AveMonthSpend))*12\ntest_data.AveMonthSpend=(np.log(test_data.AveMonthSpend))*12\n\ntrain_data.Suffix=(train_data.YearlyIncome**3.3)-(train_data.AveMonthSpend**3)\ntest_data.Suffix=(test_data.YearlyIncome**3.3)-(test_data.AveMonthSpend**3)\n\ntrain_data.YearlyIncome=(train_data.YearlyIncome**3.3)\ntest_data.YearlyIncome=(test_data.YearlyIncome**3.3)\n\n#test_data.AveMonthSpend=(1\/test_data.AveMonthSpend**4)\n\n\ntrain_data.TotalChildren=(train_data.TotalChildren*2)\ntest_data.TotalChildren=(test_data.TotalChildren*2)\n\ntrain_data.City=train_data.AveMonthSpend*30\ntest_data.City=test_data.AveMonthSpend*30\n\ntrain_data.PostalCode=train_data.TotalChildren.subtract(train_data.NumberChildrenAtHome, fill_value=0)\ntest_data.PostalCode=test_data.TotalChildren.subtract(test_data.NumberChildrenAtHome, fill_value=0)\n\ntrain_data.PostalCode=1\/train_data.CustomerID**1\/2\ntest_data.PostalCode=1\/test_data.CustomerID**1\/2\n\n#Let's  Create target object and call it y\ny = train_data.BikeBuyer\n#train_data['IncomePerchild']=(train_data.YearlyIncome\/train_data.TotalChildren).astype(int)\n#test_data['IncomePerchild']=(test_data.YearlyIncome\/test_data.TotalChildren).astype(int)\n\n\n# Create X with the required features\nfeatures = ['TotalChildren','YearlyIncome',\n            'HomeOwnerFlag','NumberChildrenAtHome','Gender','MaritalStatus','BirthDate','CountryRegionName',\n            'Occupation','PostalCode','Suffix','Education','PostalCode'\n            ]\nimport matplotlib.pyplot as plt\ntrain_data.AveMonthSpend.plot.hist(color='blue',bins=50)\nplt.show()\nX= train_data[features]\ntextX=test_data[features]\n\nimport seaborn as sns\ncorr= train_data.corr()\n#corr\nf, ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(corr,cmap='coolwarm',linewidths=2.0, annot=True)\n\nfrom sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer()\nX = my_imputer.fit_transform(X)\n\ntextX = my_imputer.fit_transform(textX)\n\n\n","b79b012b":"\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n\nxgb = XGBClassifier(n_estimators=380, learning_rate=0.049, random_state=1,min_child_weight=6)\ntraining_start = time.perf_counter()\nxgb.fit(train_X, train_y)\ntraining_end = time.perf_counter()\nprediction_start = time.perf_counter()\npreds = xgb.predict(val_X)\nprediction_end = time.perf_counter()\nacc_xgb = (preds == val_y).sum().astype(float) \/ len(preds)*100\nxgb_train_time = training_end-training_start\nxgb_prediction_time = prediction_end-prediction_start\nprint(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\nprint(\"Time consumed for training: %4.3f\" % (xgb_train_time))\nprint(\"Time consumed for prediction: %6.5f seconds\" % (xgb_prediction_time))\n\n\n  \npre=xgb.predict(textX)\nfinal=pre.astype(int)\noutput = pd.DataFrame({'CustomerID': test_data.CustomerID,\n                      'BikeBuyer': final})\n\n\noutput.to_csv('Sample Submission file clf .csv', index=False)","306f3719":"**2. Data preprocessing\/cleaning**","6fe30949":"**4. Modelling**\n\nGradient BOOST Algorithm was used because of its speed and accurate implementation of gradient boosting machines and it has proven to push the limits of computing power for boosted trees","bd45e727":"**3. Exploratory data analysis**\nThis is the stage where i performed the critical process of performing initial investigation on the train data set so as to discover patterns, correlations, to spot anomalities, to test various hypothessis and to check assumptions with the help of summary statistics and graphical assumptions.\n I used **Heatmap** to analyse the correlation between the various features and visualized","690b52e9":"**1. General Introduction**\n\nThis model was developed to predict to predict the customers' purchase behaviour. For each customer, I  predicted a value **0** or **1** for the BikeBuyer variable. (1 means the customer will buy a bike, 0 means a customer will not) The goal of this model is to classifywith a high level of accuracy and low level of under-fitting, It was developed with an optimized supervized algorithm, leveraging on the features in the train data and some engineered feature to provide the algorithm used with the right desired input. The classification model should provide decision maker with the needed insights on the type of customers that would likely buy bikes   with respect to the large historical data. Looking forward to you using this model to !!!!!!!!!","6c67972d":"2b.   Data Preprocessing\n\nThis is the stage to store customer data in a dataframe where the CSV file containining the data can be easily manipulated by python using Pandas powerful methods. Also to identify missing data which may have resulted from the customer data collection also outlier values would be identified in this section which would have negative skew the model. As seen from the missing value count below, The missing value exists in the dataframe. But it is also imputed to fill the missing column\n","3fdf9583":"1b. Import Critical libraries\nAll critical libraries needed for the data analyssis and modellling are imported"}}