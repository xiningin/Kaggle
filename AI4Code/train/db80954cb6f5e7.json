{"cell_type":{"acbeaee9":"code","16f3698e":"code","b1cc2fd6":"code","1344bd19":"code","06d45df9":"code","9471203c":"code","17ddc740":"code","4b2a7867":"code","809756ec":"code","95a4bf46":"code","5b9d0682":"code","ff523254":"code","ca0f8736":"code","9c51f867":"code","7b0ecfbb":"code","d304e7e7":"code","8d119733":"code","9820bbbb":"markdown","0f69a973":"markdown","e01966c3":"markdown","322b6890":"markdown","a474f7d8":"markdown","854b3e65":"markdown","57c55e9d":"markdown","e3df7f5d":"markdown","a7cd78c5":"markdown"},"source":{"acbeaee9":"!nvidia-smi","16f3698e":"import sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')","b1cc2fd6":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport glob\nimport random\npd.set_option('display.max_columns', None)\n\n# Image Aug\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# Machine Learning\n# Deep Learning\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","1344bd19":"csv_dir = '..\/input\/seti-breakthrough-listen'\ntest_dir = '..\/input\/seti-breakthrough-listen\/test'\nmodels_dir = '..\/input\/seti-numpy-trained-models\/resnet34d\/resnet34d_Numpy'\n\nsample_sub_file_path = os.path.join(csv_dir, 'sample_submission.csv')\nprint(f'Test file: {sample_sub_file_path}')\nprint(f'Models path: {models_dir}')","06d45df9":"test_df = pd.read_csv(sample_sub_file_path)\n\ntest_df.head()","9471203c":"def return_filpath(name, folder):\n    path = os.path.join(folder, name[0], f'{name}.npy')\n    return path","17ddc740":"test_df['image_path'] = test_df['id'].apply(lambda x: return_filpath(x, folder=test_dir))","4b2a7867":"params = {\n    'model': 'resnet34d',\n    'pretrained': False,\n    'inp_channels': 1,\n    'im_size': 512,\n    'on_target_only': False,\n    'device': device,\n    'batch_size': 64,\n    'num_workers' : 2,\n    'out_features': 1,\n    'debug': False\n}","809756ec":"def get_test_transforms(TTA, DIM = params['im_size']):\n    if TTA > 1:\n        return albumentations.Compose(\n            [\n                albumentations.Resize(DIM, DIM),\n                albumentations.HorizontalFlip(p=0.5),\n                albumentations.VerticalFlip(p=0.5),\n                albumentations.RandomResizedCrop(\n                    height=DIM, width=DIM, scale=(0.5, 1.0), p=0.5\n                ),\n                albumentations.ShiftScaleRotate(\n                    shift_limit=0.3, scale_limit=0.3, rotate_limit=90,\n                    border_mode=0, value=0, mask_value=0, p=0.5\n                ),\n                ToTensorV2(p=1.0)\n            ]\n        )\n    else:\n        return albumentations.Compose(\n            [\n                albumentations.Resize(DIM, DIM),\n                ToTensorV2(p=1.0)\n            ]\n        )","95a4bf46":"class SETIDataSet(Dataset):\n    def __init__(self, images_filepaths, targets, transform=None, params=params):\n        self.images_filepaths = images_filepaths\n        self.targets = targets\n        self.transform = transform\n        self.params = params\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        if self.params['on_target_only']:\n            image = np.load(image_filepath)[[0, 2, 4]]\n        else:\n            image = np.load(image_filepath)\n        image = image.astype(np.float32)\n        image = np.vstack(image).transpose((1, 0))\n            \n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n        \n        label = torch.tensor(self.targets[idx]).float()\n        return image, label","5b9d0682":"class AlienNet(nn.Module):\n    def __init__(self, model_name=params['model'], out_features=params['out_features'],\n                 inp_channels=params['inp_channels'], pretrained=params['pretrained']):\n        super().__init__()\n\n        # Feature Extractor (Backbone)\n        self.model = timm.create_model(model_name, pretrained=pretrained,\n                                       in_chans=inp_channels, num_classes=0)\n        out_tensor_size = self.model.num_features\n\n        if model_name.split('_')[0] == 'efficientnet':\n            out_channels = self.model.conv_stem.out_channels\n            kernel_size = self.model.conv_stem.kernel_size\n            stride = self.model.conv_stem.stride\n            padding = self.model.conv_stem.padding\n            bias = self.model.conv_stem.bias\n            self.model.conv_stem = nn.Conv2d(inp_channels, out_channels,\n                                             kernel_size=kernel_size, stride=stride,\n                                             padding=padding, bias=bias)\n            \n        # Classifier (Head)\n        layers_list = [nn.Linear(out_tensor_size, out_features)]\n        self.clf_head = nn.Sequential(*layers_list)\n    \n    def forward(self, x):\n        x = self.model(x)\n        x = self.clf_head(x)\n        return x","ff523254":"NUM_TTA = 1","ca0f8736":"if params['debug']:\n    test_df = test_df.sample(frac=0.01)","9c51f867":"predicted_labels = None\nfor i in range(NUM_TTA):\n    for model_name in glob.glob(models_dir + '\/*.pth'):\n        model = AlienNet()\n        model.load_state_dict(torch.load(model_name))\n        model = model.to(params['device'])\n        model.eval()\n\n        test_dataset = SETIDataSet(\n            images_filepaths = test_df['image_path'].values,\n            targets = test_df['target'].values,\n            transform = get_test_transforms(NUM_TTA)\n        )\n        test_loader = DataLoader(\n            test_dataset, batch_size=params['batch_size'],\n            shuffle=False, num_workers=params['num_workers'],\n            pin_memory=True\n        )\n        \n        temp_preds = None\n        with torch.no_grad():\n            for (images, target) in tqdm(test_loader, desc=f'TTA: {i+1} Predicting. '):\n                images = images.to(params['device'], non_blocking=True)\n                output = model(images)\n                predictions = torch.sigmoid(output).cpu().numpy()\n                if temp_preds is None:\n                    temp_preds = predictions\n                else:\n                    temp_preds = np.vstack((temp_preds, predictions))\n        \n        if predicted_labels is None:\n            predicted_labels = temp_preds\n        else:\n            predicted_labels += temp_preds\n        \npredicted_labels \/= (NUM_TTA*len(glob.glob(models_dir + '\/*.pth')))","7b0ecfbb":"sub_df = pd.DataFrame()\nsub_df['id'] = test_df['id']\nsub_df['target'] = predicted_labels","d304e7e7":"sub_df.head()","8d119733":"sub_df.to_csv('submission.csv', index=False)","9820bbbb":"# Dataset","0f69a973":"# Import","e01966c3":"# About This Notebook\n\nThis is a implementation of a vanilla resnet34d in Pytorch for the SETI Competition. This scores around 0.97x(0.974-0.976) on LB and 0.9882 CV.\n\nTraining Params: -\n1. **Dataset**: - Spatial arrngement of the channels (512x512)\n2. **Augmentations**: - Resize, HorizontalFlip, VerticalFlip, RandomResizedCrop, ShiftScaleRotate, Cutout, Mixup\n3. **Optimizer**: - Adam\n4. **Scheduler**: - CosineAnnealingWarmRestarts\n5. **Model**: - Resnet34d\n6. **Initial Weights**: - Imagenet\n5. **Max Epochs**: - 30 (~7 min per epoch)\n6. **Saved Weights**: - 5-fold ensemble. Weights having highest OOF score on ROC-AUC metric were saved.\n\nThis notebook only contains the inference for the model as described above. If you are interested in EDA or A baseline model please refer the link below.\n\nEDA and Baseline Model Notebook:- https:\/\/www.kaggle.com\/manabendrarout\/nfnet-pytorch-starter-lb-0-95\n\n**If you find this notebook useful and use parts of it in your work, please don't forget to show your appreciation by upvoting this kernel. That keeps me motivated and inspires me to write and share these public kernels. \ud83d\ude0a**","322b6890":"# Get GPU Info","a474f7d8":"# Prediction","854b3e65":"# Augmentations","57c55e9d":"**If you find this notebook useful and use parts of it in your work, please don't forget to show your appreciation by upvoting this kernel. That keeps me motivated and inspires me to write and share these public kernels. \ud83d\ude0a**","e3df7f5d":"# CNN Model","a7cd78c5":"# CFG"}}