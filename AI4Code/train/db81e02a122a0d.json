{"cell_type":{"5190e9d7":"code","b3684610":"code","81f8251e":"code","98896ea1":"code","00331a4b":"code","3fcb20ba":"code","82ed1258":"code","6fbf9ecd":"code","06ed2522":"code","8fb7986c":"code","1845145a":"code","a334d10a":"code","48197fcb":"code","22126583":"code","038c8f2b":"code","137f223c":"code","ce22b90d":"code","5b51c6c8":"code","77e5b57a":"code","88d594ff":"code","47610835":"code","dc8c5a84":"code","886aa27f":"code","5344eafb":"code","900aa71c":"code","327f9a64":"code","9d0096c9":"code","5e7bac85":"code","0a39acfb":"code","ea5444f9":"code","731ba8dd":"code","ea308690":"code","05a74402":"code","88c4bb14":"code","0260db20":"code","353a3542":"code","86fc759e":"code","8f3b7766":"code","eea5cdbe":"code","289c4d5d":"code","5023376f":"code","ffa1e27b":"code","f712d018":"markdown","353130f9":"markdown","51bada23":"markdown","4d22c769":"markdown","0ddb33cd":"markdown","e33e374e":"markdown","ab12e784":"markdown","0622ee60":"markdown","250a5473":"markdown","7433d537":"markdown","1d46f254":"markdown","906db59c":"markdown","3f3a6f86":"markdown","c17686eb":"markdown","ee3e68ea":"markdown"},"source":{"5190e9d7":"import numpy as np\nimport pandas as pd\nfrom pandas_datareader import data, wb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport math\nimport datetime\nimport plotly\nimport cufflinks as cf\ncf.go_offline()\n%matplotlib inline","b3684610":"start = datetime.datetime(2017, 7, 12)\nend = datetime.datetime(2020, 7, 12)","81f8251e":"df = data.DataReader(\"BTC-USD\",'yahoo',start,end)\ndf.head()","98896ea1":"df.tail()","00331a4b":"df.xs(key='Close',axis=1).max()","3fcb20ba":"df.xs(key='Close',axis=1).iplot()","82ed1258":"plt.figure(figsize=(12,5))\ndf['Close'].loc['2019-07-12':'2020-07-12'].rolling(window=30).mean().plot(label='30 Day Moving Avg.')\ndf['Close'].loc['2019-07-12':'2020-07-12'].plot(label='Close')\nplt.legend()","6fbf9ecd":"df0 = df[['Open','High','Low','Close']].loc['2019-07-12':'2020-07-12']\ndf0.iplot(kind='candle')","06ed2522":"df['Close'].loc['2019-07-10':'2020-07-10'].ta_plot(study='sma',periods=[9,18,27])","8fb7986c":"df1=df.reset_index()['Close']","1845145a":"df1","a334d10a":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler(feature_range=(0,1))\ndf1=scaler.fit_transform(np.array(df1).reshape(-1,1))","48197fcb":"print(df1)","22126583":"training_size=int(len(df1)*0.70)\ntest_size=len(df1)-training_size\ntrain_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]","038c8f2b":"training_size,test_size","137f223c":"train_data","ce22b90d":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, time_step=1):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-time_step-1):\n\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + time_step, 0])\n\treturn np.array(dataX), np.array(dataY)","5b51c6c8":"# reshape into X=t,t+1,t+2,t+3 and Y=t+4\ntime_step = 100\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, y_test = create_dataset(test_data, time_step)","77e5b57a":"print(X_train.shape), print(y_train.shape)","88d594ff":"print(X_test.shape), print(y_test.shape)","47610835":"# reshape input to be [samples, time steps, features] which is required for LSTM\nX_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)","dc8c5a84":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM","886aa27f":"model=Sequential()\nmodel.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')\n","5344eafb":"model.summary()","900aa71c":"model.summary()","327f9a64":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64,verbose=1)","9d0096c9":"train_predict=model.predict(X_train)\ntest_predict=model.predict(X_test)","5e7bac85":"# Transformback to original form\ntrain_predict=scaler.inverse_transform(train_predict)\ntest_predict=scaler.inverse_transform(test_predict)","0a39acfb":"### Calculate RMSE performance metrics\nfrom sklearn.metrics import mean_squared_error\nmath.sqrt(mean_squared_error(y_train,train_predict))","ea5444f9":"### Test Data RMSE\nmath.sqrt(mean_squared_error(y_test,test_predict))","731ba8dd":"# shift train predictions for plotting\nlook_back=100\ntrainPredictPlot = np.empty_like(df1)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(df1)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(df1))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","ea308690":"len(test_data)","05a74402":"x_input=test_data[230:].reshape(1,-1)\nx_input.shape","88c4bb14":"temp_input=list(x_input)\ntemp_input=temp_input[0].tolist()","0260db20":"temp_input","353a3542":"# demonstrate prediction for next 10 days\nfrom numpy import array\n\nlst_output=[]\nn_steps=100\ni=0\nwhile(i<30):\n    \n    if(len(temp_input)>100):\n        #print(temp_input)\n        x_input=np.array(temp_input[1:])\n        print(\"{} day input {}\".format(i,x_input))\n        x_input=x_input.reshape(1,-1)\n        x_input = x_input.reshape((1, n_steps, 1))\n        #print(x_input)\n        yhat = model.predict(x_input, verbose=0)\n        print(\"{} day output {}\".format(i,yhat))\n        temp_input.extend(yhat[0].tolist())\n        temp_input=temp_input[1:]\n        #print(temp_input)\n        lst_output.extend(yhat.tolist())\n        i=i+1\n    else:\n        x_input = x_input.reshape((1, n_steps,1))\n        yhat = model.predict(x_input, verbose=0)\n        print(yhat[0])\n        temp_input.extend(yhat[0].tolist())\n        print(len(temp_input))\n        lst_output.extend(yhat.tolist())\n        i=i+1\n    \n\nprint(lst_output)","86fc759e":"day_new=np.arange(1,101)\nday_pred=np.arange(101,131)","8f3b7766":"len(df1)","eea5cdbe":"plt.plot(day_new,scaler.inverse_transform(df1[997:]))\nplt.plot(day_pred,scaler.inverse_transform(lst_output))","289c4d5d":"df3=df1.tolist()\ndf3.extend(lst_output)","5023376f":"df3=scaler.inverse_transform(df3).tolist()","ffa1e27b":"plt.plot(df3)","f712d018":"### Set Duration","353130f9":"### Import the Libraries","51bada23":"### Stacked LSTM Model","4d22c769":"**CONCLUSION:** Here, these predictions say that ","0ddb33cd":"#### Splitting the Close data into Train and Test sets","e33e374e":"#### Maximum Closing Rate","ab12e784":"### Exploratory Data Analysis","0622ee60":"#### Visualization (Closing Rate)","250a5473":"### Lets Predict","7433d537":"### Let's Visualize the Predictions","1d46f254":"#### 30-day Moving Average for Close Price","906db59c":"#### Using MinMaxScaler","3f3a6f86":"#### Let's Reset the Index to Close","c17686eb":"### Predictions for Next 30 Days","ee3e68ea":"### Import the data using DataReader"}}