{"cell_type":{"c90d7451":"code","d026f3c6":"code","30579de4":"code","75d51818":"markdown","94de32f0":"markdown","470e344e":"markdown"},"source":{"c90d7451":"# imports\nimport numpy as np \nimport pandas as pd \n\nfrom sklearn import ensemble\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\n\nfrom sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\n#variables\nTRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH =\"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSIO_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nNFOLDS = 5 \nTARGET = \"Survived\"\nSEED = 42\n\n# load \ntrain = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\n#preprocess\n#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","d026f3c6":"# split data (input & target)\nntrain = train.shape[0]\nntest = test.shape[0]\n\ny_train = train[TARGET]\ntrain = train.drop([TARGET], axis=1)\nx_train = train.values \nx_test = test\n\n# define model\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 1000,\n    'warm_start': True,\n    'max_depth': 5,\n    'max_features': 'sqrt',\n    'verbose': 1\n}\n\nclass SklearnHelper(object):\n    def __init__(self, clf, seed = 0, params = None):\n        params['random_state'] = seed\n        self.clf = clf(**params) \n        \n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n        \n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self, x, y):\n        return self.clf.fit(x, y)\n    \n    def feature_importances(self, x, y):\n        print(self.clf.fit(x, y).feature_importances_)\n        \nrf_42 = SklearnHelper(clf=RandomForestClassifier, seed=42, params=rf_params)\nrf_2002 = SklearnHelper(clf=RandomForestClassifier, seed=2002, params=rf_params)\nrf_777 = SklearnHelper(clf=RandomForestClassifier, seed=777, params=rf_params)\n\n# oof ensemble\ndef get_oof(clf, x_train, y_train, x_test,ntrain,ntest):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n    \n    kf = KFold(n_splits=NFOLDS, random_state=SEED) \n    \n    for i, (train_index, val_index) in enumerate(kf.split(x_train)):\n        x_train_part = x_train[train_index]\n        y_train_part = y_train[train_index]\n        x_val_part = x_train[val_index]\n       \n        clf.fit(x_train_part, y_train_part)\n        \n        oof_train[val_index] = clf.predict(x_val_part)\n        oof_test_skf[i, :] = clf.predict(x_test)\n        \n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n\nrf_oof_train_42, rf_oof_test_42 = get_oof(rf_42,x_train, y_train, x_test,ntrain,ntest) \nrf_oof_train_2002, rf_oof_test_2002 = get_oof(rf_2002,x_train, y_train, x_test,ntrain,ntest) \nrf_oof_train_777, rf_oof_test_777 = get_oof(rf_777,x_train, y_train, x_test,ntrain,ntest) \n\nx_train = np.concatenate((rf_oof_train_42, rf_oof_train_2002,rf_oof_train_777), axis = 1)\nx_test = np.concatenate((rf_oof_test_42, rf_oof_test_2002,rf_oof_test_777), axis = 1)\n\ngbm = xgb.XGBClassifier(\n    n_estimators = 2000,\n    max_depth = 4,\n    objective = 'binary:logistic'\n).fit(x_train, y_train)\n\n# evaluate model\ny_train_pred = cross_val_predict(gbm, x_train, y_train, cv=3)\nprint( confusion_matrix(y_train, y_train_pred) )\nprint(\"precision_score1:\",precision_score(y_train, y_train_pred) )\nprint(\"recall_score1:\",recall_score(y_train, y_train_pred))\nprint(\"f1_score1:\",f1_score(y_train, y_train_pred))\nprint(\"roc_auc score\",roc_auc_score(y_train, y_train_pred) )","30579de4":"predictions = gbm.predict(x_test)\n\nsub = pd.read_csv(SAMPLE_SUBMISSIO_PATH)\nsub[TARGET] = predictions\nsub.to_csv(SUBMISSION_PATH, index=False)\nsub.head()","75d51818":"# Before building model\n\nimports & variables & load & preprocess","94de32f0":"# Build model","470e344e":"# After building model\n\npredict & make submission csv"}}