{"cell_type":{"49bbd5f7":"code","8d5b046b":"code","d180fe56":"code","cc0fc7df":"code","25a9c97b":"code","d7dc7409":"code","d2ec715c":"code","ba8c96cb":"markdown","27be7353":"markdown","79813196":"markdown","8a0bca36":"markdown","aab98a26":"markdown","b44375d0":"markdown","b4507b83":"markdown","d931e6b6":"markdown"},"source":{"49bbd5f7":"# import useful libraries\nimport numpy as np # linear algebra\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nfrom glob import glob\nimport os\n\n# import pytorch modules\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import models, transforms\nfrom torchvision.datasets import ImageFolder\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# define paths\ntrain_path = '..\/input\/seg_train\/seg_train'\ntest_path = '..\/input\/seg_test\/seg_test'\npred_path = '..\/input\/seg_pred\/seg_pred'","8d5b046b":"transformer = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5],\n                         [0.5, 0.5, 0.5])\n])\n\ntrain_loader = DataLoader(\n    ImageFolder(train_path, transform=transformer),\n    num_workers=8, batch_size=200, shuffle=True\n)\n\ntest_loader = DataLoader(\n    ImageFolder(test_path, transform=transformer),\n    num_workers=8, batch_size=200, shuffle=True\n)","d180fe56":"folders = os.listdir(train_path)\n\n\nimages = []\nlabels = []\nfor cl in folders:\n    path = os.path.join(train_path, cl, '*.jpg')\n    for file in glob(path)[:2]:\n        with Image.open(file) as f:\n            images.append(np.array(f))\n            labels.append(cl)\n            \nfig = plt.figure(figsize=(10, 15))\n\nfor i, image in enumerate(images):\n    ax = fig.add_subplot(6, 2, i+1)\n    ax.imshow(image)\n    ax.set_title(labels[i])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \nplt.show()","cc0fc7df":"resnet_model = models.resnet50(pretrained=True)\n\n# freeze all parameters in ResNet so we won't have to retrain them\nfor param in resnet_model.parameters():\n    param.requires_grad = False\n\n# replace the last layer with another one that will be trainable\nin_shape = resnet_model.fc.in_features\nresnet_model.fc = nn.Linear(in_shape, 6)","25a9c97b":"error = nn.CrossEntropyLoss()\nopt = optim.Adam(resnet_model.parameters())\n\ndef train(model, train_loader, n_epochs=100):\n    model = model.to(device)\n    model.train()\n    \n    for epoch in range(n_epochs):\n        epoch_loss = 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            opt.zero_grad()\n            out = model(x)\n            loss = error(out, y)\n            loss.backward()\n            opt.step()\n            epoch_loss += loss.item()        \n        if epoch % int(0.1*n_epochs) == 0:\n            print(f'epoch: {epoch} \\t Train Loss: {epoch_loss:.4g}')\n            \ntrain(resnet_model, train_loader)","d7dc7409":"def test(model, test_loader):\n    model = model.to(device)\n    model.eval()\n    loss = 0\n    for x, y in test_loader:\n        with torch.no_grad():\n            out = model(x.to(device)).cpu()\n        loss += error(out, y)\n        \n    print(f'Test loss: {loss:.4g}')\n    \ntest(resnet_model, test_loader)","d2ec715c":"classes = train_loader.dataset.class_to_idx\n\ndef predict(model, path, sample_size=5):\n    for file in glob(os.path.join(path, '*.jpg'))[:sample_size]:\n        with Image.open(file) as f:\n            img = transformer(f).unsqueeze(0)\n            with torch.no_grad():\n                out = model(img.to(device)).cpu().numpy()\n            for key, value in classes.items():\n                if value == np.argmax(out):\n                    print(key)\n            plt.imshow(np.array(f))\n            plt.show()\n            \npredict(resnet_model, pred_path)","ba8c96cb":"### Set up transfer learning model\n\nHere I am using ResNet50 but you can use whatever model you want. I chose not to retrain the whole thing because that would be the opposite of what I am doing.\n\nIn essenece, I use ResNet to generate features for the fully connnected layer to learn how to make decisions based on those features.","27be7353":"\n### Beautiful, isn't it?\n\nIn summary, transfer learning is a useful tool to generate very rich features and use them to make a network that does miracles without too much work.","79813196":"Use the model to predict images in the other folder.","8a0bca36":"### Visualize because it looks cool","aab98a26":"## Do not reinvent the wheel\n\nThis module will show you how to use transfer learning which essentially uses some fancy CNN models as feature generators and train fully connected layers on your custom dataset, like this one.","b44375d0":"### Test this model","b4507b83":"Define loss, optimizer, and train the network.","d931e6b6":"### Define pipeline tools that apply transforms and make the dataset."}}