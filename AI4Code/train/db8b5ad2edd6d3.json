{"cell_type":{"fe50f6ae":"code","99483513":"code","d11161fe":"code","e75edcc0":"code","6b633424":"code","5115d779":"code","83d65d14":"code","e82df2da":"code","d2b764c2":"code","1ec8dbe0":"code","fda16c86":"code","da336586":"code","06c6b630":"code","18cd63bf":"code","ba80e1f3":"code","1fb68864":"code","9a487df8":"code","eb878bb5":"code","1298bc3c":"code","bc727119":"code","43457930":"code","ba46ba46":"code","580a0909":"code","8c694770":"code","f1541ba8":"code","d32c9aa4":"code","9400e346":"code","011746eb":"code","875cce85":"code","e14c8cc8":"code","59f251e9":"code","7396f64b":"code","cc4aa472":"code","95d7c8b6":"code","9a254d20":"code","1591bebc":"code","daef08c9":"code","0f42ddf0":"markdown","fb8f7a05":"markdown","015475d5":"markdown","0af4176f":"markdown","4790bc32":"markdown","5951e933":"markdown","4e2f2bff":"markdown","96099d8a":"markdown"},"source":{"fe50f6ae":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\n\n\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa.arima_model import ARMA, ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import adfuller\nfrom fbprophet import Prophet\n\nfrom sklearn.metrics import mean_squared_error","99483513":"file = pd.read_csv(\"..\/input\/bigdataset\/Datasets-master\/daily-max-temperatures.csv\")\nfile.head()","d11161fe":"file[\"Date\"] = pd.to_datetime(file[\"Date\"])","e75edcc0":"file = file.set_index(\"Date\")\nfile.index\n","6b633424":"#plotting the data\nfile.isnull().sum()","5115d779":"file.describe()","83d65d14":"file.plot(figsize = (16, 10))\nplt.show()","e82df2da":"plt.figure(1)\nplt.subplot(211)\nfile[\"Temperature\"].hist()\nplt.subplot(212)\nfile[\"Temperature\"].plot(kind = 'kde')\nplt.show()\n","d2b764c2":"fig, ax = plt.subplots(figsize = (15, 6))\nsns.boxplot(file.index.month, file[\"Temperature\"])","1ec8dbe0":"#decomposing the model\nplt.rcParams['figure.figsize'] = 16, 8\ndecomposition = sm.tsa.seasonal_decompose(file[\"Temperature\"], model='multiplicative', period=365)\nfig = decomposition.plot()\nplt.show()","fda16c86":"plt.plot(file)","da336586":"from statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nplt.figure()\nplt.subplot(211)\nplot_acf(file[\"Temperature\"], ax=plt.gca(), lags = 30)\nplt.subplot(212)\nplot_pacf(file[\"Temperature\"], ax=plt.gca(), lags = 30)\nplt.show()","06c6b630":"rolmean = file[\"Temperature\"].rolling(window = 12).mean()\nrolstd = file[\"Temperature\"].rolling(window = 12).std()\n\n#Plot rolling statistics:\norig = plt.plot(file, color='blue',label='Original')\nmean = plt.plot(rolmean, color='red', label='Rolling Mean')\nstd = plt.plot(rolstd, color='black', label = 'Rolling Std')\nplt.legend(loc='best')\nplt.title('Rolling Mean & Standard Deviation')\nplt.show()","18cd63bf":"\n#Perform Dickey-Fuller test:\nprint ('Results of Dickey-Fuller Test:')\ndftest = adfuller(file[\"Temperature\"], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\nprint (dfoutput)","ba80e1f3":"\ndef test_stationarity(timeseries):\n    \n    #Determing rolling statistics\n    rolmean = timeseries.rolling(window=12).mean()\n    rolstd = timeseries.rolling(window=12).std()\n\n    #Plot rolling statistics:\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","1fb68864":"from statsmodels.tsa.ar_model import AR\nfrom random import random","9a487df8":"\n# fit model\nmodel = AR(file[\"Temperature\"])\nmodel_fit = model.fit()","eb878bb5":"plt.plot(file[\"Temperature\"])\nplt.plot(model_fit.fittedvalues, color='red')\nplt.title('RSS: %.4f'% np.nansum((model_fit.fittedvalues-file[\"Temperature\"])**2))\nplt.show()","1298bc3c":"#Building the ARIMA model\n\n#splitting the dataset\n\ntrain = file[:int(0.75*len(file))]\ntest = file[train.shape[0]:]\n\ntrain.shape, test.shape","bc727119":"train[\"Temperature\"].plot()\ntest[\"Temperature\"].plot()","43457930":"from statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n# fit model\nmodel = ARIMA(train, order=(1, 0, 1))\nmodel_fit = model.fit(disp=1)","ba46ba46":"model_fit.summary()","580a0909":"test","8c694770":"#Predictions\nend_index = len(file)\npredictions = model_fit.predict(start=2737, end = end_index - 1)","f1541ba8":"predictions","d32c9aa4":"mse = mean_squared_error(file[train.shape[0]:], predictions)\nrmse = sqrt(mse)\nprint('RMSE: {}, MSE:{}'.format(rmse,mse))","9400e346":"plt.plot(file[\"Temperature\"])\nplt.plot(predictions)\n#plt.title('RMSE: %.4f'% np.sqrt(np.nansum((predictions-file[\"Temperature\"])**2)\/len(file)))","011746eb":"predictions = pd.Series(predictions)","875cce85":"train.head()","e14c8cc8":"train_prophet = pd.DataFrame()\ntrain_prophet['ds'] = train.index\ntrain_prophet['y'] = train[\"Temperature\"].values","59f251e9":"from fbprophet import Prophet\n\n#instantiate Prophet with only yearly seasonality as our data is monthly \nmodel = Prophet( yearly_seasonality=True, seasonality_mode = 'multiplicative')\nmodel.fit(train_prophet) #fit the model with your dataframe","7396f64b":"future = model.make_future_dataframe(periods = 913, freq = 'D') \nfuture.tail()","cc4aa472":"# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","95d7c8b6":"\nfig = model.plot(forecast)\n#plot the predictions for validation set\n\nplt.plot(test, label='Valid', color = 'red', linewidth = 2)\n\nplt.show()","9a254d20":"model.plot_components(forecast);","1591bebc":"\ny_prophet = pd.DataFrame()\ny_prophet['ds'] = test.index\ny_prophet['y'] = test[\"Temperature\"].values","daef08c9":"y_prophet = y_prophet.set_index('ds')\nforecast_prophet = forecast.set_index('ds')","0f42ddf0":"# We can check stationarity using the following:\n\n- **ACF and PACF plots:** If the time series is stationary, the ACF\/PACF plots will show a quick drop-off in correlation after a small amount of lag between points.\n- **Plotting Rolling Statistics:** We can plot the moving average or moving variance and see if it varies with time. Moving average\/variance is for any instant \u2018t\u2019, the average\/variance of the last year, i.e. last 12 months.\n- **Augmented Dickey-Fuller Test:** This is one of the statistical tests for checking stationarity. Here the null hypothesis is that the TS is non-stationary. The test results comprise of a Test Statistic and some Critical Values for difference confidence levels. If the \u2018Test Statistic\u2019 is less than the \u2018Critical Value\u2019, we can reject the null hypothesis and say that the series is stationary. Refer this article for details.\n\n# **ACF and PACF plots**\n\n- Let's review the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots\n- If the time series is stationary, the ACF\/PACF plots will show a quick drop-off in correlation after a small amount of lag between points.\n- This data is non-stationary as a high number of previous observations are correlated with future values.\n- Confidence intervals are drawn as a cone.\n- By default, this is set to a 95% confidence interval, suggesting that correlation values outside of this code are very likely a correlation and not a statistical fluke.\n- The partial autocorrelation at lag k is the correlation that results after removing the effect of any correlations due to the terms at shorter lags","fb8f7a05":"# Decomposing using statsmodel:\n\n- We can use statsmodels to perform a decomposition of this time series.\n- The decomposition of time series is a statistical task that deconstructs a time series into several components, each representing one of the underlying categories of patterns.\n- With statsmodels we will be able to see the trend, seasonal, and residual components of our data.","015475d5":"# Stationarity\n- A Time Series is said to be stationary if its statistical properties such as mean, variance remain constant over time.\n- Most of the Time Series models work on the assumption that the TS is stationary. Major reason for this is that there are many ways in which a series can be non-stationary, but only one way for stationarity.\n- Intuitively, we can say that if a Time Series has a particular behaviour over time, there is a very high probability that it will follow the same in the future.\n- Also, the theories related to stationary series are more mature and easier to implement as compared to non-stationary series.","0af4176f":"# Augmented Dickey-Fuller \n- The intuition behind the test is that if the series is integrated then the lagged level of the series y(t-1) will provide no relevant information in predicting the change in y(t).\n- Null hypothesis: The time series is not stationary\n- Rejecting the null hypothesis (i.e. a very low p-value) will indicate staionarity","4790bc32":"# Plotting Rolling Statistics\n- We observe that the rolling mean and Standard deviation are not constant with respect to time (increasing trend)\n- The time series is hence not stationary","5951e933":"# Prophet Model ","4e2f2bff":"# Time Series Forecasting\n\n","96099d8a":"Here we can clearly see that the P-values is well below 5%, so we can successfully reject the null hypothesis and call the series to be stationary."}}