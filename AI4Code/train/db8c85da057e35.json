{"cell_type":{"48355d15":"code","aac8278f":"code","67822a10":"code","961cea75":"code","010220bd":"code","6294bfa7":"code","17390d49":"code","f76d6425":"code","8b4d4f9c":"code","c1b06344":"code","c8277e97":"code","27bc1972":"markdown","8adf99dd":"markdown","f0e9b4f0":"markdown","bb072689":"markdown"},"source":{"48355d15":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (6,6)\n\nimport numpy as np\nimport pandas as pd\n\nimport os\nprint(os.listdir(\"..\/input\"))","aac8278f":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\nX = np.array(train.drop([\"label\"], axis=1)) \/ 255.\ny = np.array(train[\"label\"])\n\nfrom tensorflow.keras.utils import to_categorical\ny = to_categorical(y)\n\nX_test = np.array(test) \/ 255.\n\nprint(X.shape, y.shape, X_test.shape)","67822a10":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n\nprint(X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape)","961cea75":"from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.models import Model","010220bd":"# https:\/\/github.com\/keras-team\/keras\/issues\/10306\n# BatchNormalization makes autoencoder working better\n\ninp = Input(shape=(28,28,1))\n\n# Encoder\nconv_1 = Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")(inp)\nconv_1 = BatchNormalization()(conv_1)\npool_1 = MaxPooling2D((2,2), padding=\"same\")(conv_1)\nconv_2 = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(pool_1)\nconv_2 = BatchNormalization()(conv_2)\npool_2 = MaxPooling2D((2,2), padding=\"same\")(conv_2)\nconv_3 = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(pool_2)\nconv_3 = BatchNormalization()(conv_3)\nencoded = MaxPooling2D((2,2), padding=\"same\")(conv_3)\n\n# Decoder\nconv_4 = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(encoded)\nup_1 = UpSampling2D((2,2))(conv_4)\nconv_5 = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(up_1)\nup_2 = UpSampling2D((2,2))(conv_5)\nconv_6 = Conv2D(128, (3,3), activation=\"relu\")(up_2)\nup_3 = UpSampling2D((2,2))(conv_6)\ndecoded = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='autoencoder')(up_3)\n\n# Classification\nflatten = Flatten()(encoded)\nfc = Dense(128, activation=\"relu\")(flatten)\nfc = Dropout(0.5)(fc)\nclassifer = Dense(y_train.shape[1], activation=\"softmax\", name=\"classification\")(fc)\n\nmodel = Model(inp, [decoded, classifer])","6294bfa7":"losses = {\n    \"autoencoder\": \"mse\",\n    \"classification\": \"categorical_crossentropy\"\n}\n\nloss_weights = {\n    \"autoencoder\": 1.0,\n    \"classification\": 5.0\n}\n\nmetrics = {\n    \"autoencoder\": \"mse\",\n    \"classification\": \"acc\"\n}\n\nmodel.compile(loss=losses, loss_weights=loss_weights, optimizer=\"adam\", metrics=metrics)\n\nmodel.summary()","17390d49":"from tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint('model.h5', \n                             monitor='val_classification_acc', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='max', \n                             save_weights_only = True)\n\nhist = model.fit(X_train,\n                 {\"autoencoder\": X_train,  \"classification\": y_train},\n                 verbose=1,\n                 batch_size=512, \n                 epochs=50, \n                 validation_data=(X_val, {\"autoencoder\": X_val, \"classification\": y_val}), \n                 callbacks=[checkpoint])","f76d6425":"y_1, y_2 = model.predict(X_val[:10])\ny_1.shape, y_2.shape","8b4d4f9c":"samples = 5\ny_1, y_2 = model.predict(X_val[:samples])\nfor i in range(samples):\n    plt.subplot(1, 2, 1)\n    plt.imshow(X_val[i].reshape(28,28), cmap=\"gray\")\n    plt.title(\"original\")\n    plt.subplot(1, 2, 2)\n    plt.imshow(y_1[i].reshape(28,28), cmap=\"gray\")\n    plt.title(\"autoencoder and predict {}\".format(y_2[i].argmax()))\n    plt.show()","c1b06344":"sub = pd.read_csv(\"..\/input\/sample_submission.csv\")\nmodel.load_weights(\"model.h5\")\ny_test = model.predict(X_test, batch_size=1024, verbose=0)\nsub.Label = np.argmax(y_test[1], axis=1)\nsub.to_csv(\"submission.csv\", index=False)","c8277e97":"!head submission.csv","27bc1972":"Trying to build a multi-output model","8adf99dd":"# train test split","f0e9b4f0":"# predict and submit","bb072689":"# load dataset"}}