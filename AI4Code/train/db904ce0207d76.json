{"cell_type":{"ce40eb97":"code","74088f57":"code","f21b078a":"code","0dd722dc":"code","986cf9a1":"code","91efa898":"code","f7c68eaf":"code","0f8bfae5":"code","92b71dd3":"code","89124acc":"code","26ac3c74":"code","7e5046fa":"code","15492a19":"code","c97b42f7":"code","1e724c2c":"code","d03dc606":"code","9968643b":"code","dfb0693a":"code","30721b2f":"code","9b6e40ba":"code","17d7217b":"code","512b9596":"code","c81f6d14":"code","1fe43e66":"code","4cf1a3b3":"code","75f36a5c":"code","7504c858":"code","02042906":"code","fdfe2a59":"code","8f2cc9e1":"code","986fdac1":"code","8aee64ea":"code","cd708b57":"code","788c56c0":"code","9eba6cfd":"code","6c643002":"code","eaa816f9":"code","5ee54c71":"code","cfeba35c":"code","b7263e18":"code","2b746e5c":"code","e29994ac":"code","b20eb569":"code","5882a801":"code","dd971971":"code","5b97f5d3":"code","6bedee93":"markdown","22d637b0":"markdown","d404cafd":"markdown","0adc48b9":"markdown","15fa16c4":"markdown","6730891a":"markdown","6c7ee870":"markdown","c0c706ec":"markdown","7979a4f3":"markdown","4d9af920":"markdown","44b1b257":"markdown","b8dabf05":"markdown","3d60e3c2":"markdown","d5fb0b05":"markdown"},"source":{"ce40eb97":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74088f57":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt","f21b078a":"buff = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_train = pd.DataFrame(buff)\nbuff = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndf_test =pd.DataFrame(buff)\ncombine = [df_train, df_test]","0dd722dc":"df_train.head(20)","986cf9a1":"df_train.describe()","91efa898":"df_train.info()\nprint(\"-\" * 40)\ndf_test.info()","f7c68eaf":"df_train.corr()","0f8bfae5":"sns.distplot(df_train[df_train[\"Survived\"] == 1][\"Age\"], bins=50)\nsns.distplot(df_train[df_train[\"Survived\"] == 0][\"Age\"], bins=50)","92b71dd3":"#creating the \"young\" feature\nfor data in combine:\n    arr = []\n    for i in range(len(data)):\n        if data[\"Age\"].iloc[i] < 15:\n            arr.append(1)\n        else:\n            arr.append(0)\n    data[\"Young\"] = arr\ndf_train[df_train[\"Young\"] == 1] #78 children within data","89124acc":"df_train[\"Fare\"].median()","26ac3c74":"for data in combine:\n    for i in range(len(data)):\n        if data[\"Fare\"].isna()[i] == True:\n            data[\"Fare\"].iloc[i] = data[\"Fare\"].median()\n        if data[\"Embarked\"].isna()[i] == True:\n            data[\"Embarked\"].iloc[i] = \"S\"  # S is the median value","7e5046fa":"for data in combine:\n    data.drop(columns=[\"Cabin\"], inplace=True)","15492a19":"df_train","c97b42f7":"#switching the heirarchy of Pclass\nfor data in combine:\n    data[\"Pclass\"] = data[\"Pclass\"].map({1:3, 3:1, 2:2})","1e724c2c":"#switching Sex to binary encoding\nfor data in combine:\n    data[\"Sex\"] = data[\"Sex\"].map({\"male\": 0, \"female\" : 1})","d03dc606":"df_train","9968643b":"#extracting title\nfor data in combine:\n    data[\"Title\"] = data[\"Name\"].apply(lambda name: name.split(\".\")[0].split(\" \")[-1])","dfb0693a":"for data in combine:\n    data[\"Title\"] = data[\"Title\"].map({\n\"Mr\" : 1,\n\"Miss\" : 2,\n\"Mrs\" : 3,\n\"Master\" : 4,\n\"Dr\" : 5,\n\"Rev\" : 5,\n\"Mlle\" : 5,\n\"Col\" : 5,\n\"Major\" : 5,\n\"Ms\" : 5,\n\"Lady\" : 5,\n\"Countess\" : 5,\n\"Sir\" : 5,\n\"Don\"  : 5,\n\"Capt\" : 5,\n\"Jonkheer\" : 5,\n\"Mme\" : 5})","30721b2f":"for data in combine:\n    data[\"Family\"] = data[\"Parch\"] + data[\"SibSp\"]","9b6e40ba":"sns.distplot(df_train[df_train[\"Family\"] == 0][\"Survived\"])\nsns.distplot(df_train[df_train[\"Family\"] != 0][\"Survived\"])","17d7217b":"#create travelling alone feature\nfor data in combine:\n    data[\"Alone\"] = data[\"Family\"].apply(lambda x : 1 if x < 1 else 0)","512b9596":"df_train","c81f6d14":"#people associated with royalty\nroyal_tickets = list(df_train[df_train[\"Title\"] == 5][\"Ticket\"])\nsns.distplot(df_train[df_train[\"Ticket\"].isin(royal_tickets)][\"Survived\"])\nsns.distplot(df_train[~df_train[\"Ticket\"].isin(royal_tickets)][\"Survived\"])","1fe43e66":"sns.distplot(df_train[df_train[\"Title\"] == 5][\"Survived\"])","4cf1a3b3":"for data in combine:\n    data[\"WithRoyalty\"] = data[\"Ticket\"].apply(lambda tick: 1 if tick in royal_tickets else 0)","75f36a5c":"df_train[\"Embarked\"].value_counts()","7504c858":"for data in combine:\n    data[\"Embarked\"] = data[\"Embarked\"].map({\"Q\" : 1, \"C\" : 2, \"S\" : 3})","02042906":"df_train.corr()","fdfe2a59":"#creating model without using age -> might have to come back and fix\nfor data in combine:\n    data.drop(columns=[ \"Family\", \"Parch\", \"SibSp\", \"Age\", \"Name\", \"Ticket\", \"PassengerId\"], inplace=True)","8f2cc9e1":"df_train","986fdac1":"y = np.array(df_train[\"Survived\"].values)\nx = np.array(df_train.drop(columns=\"Survived\").values)\nnp.reshape(x,(891,len(list(df_train.columns)) -1,1))\nprint(\"X shape:\", x.shape)\nnum_classes = x.shape[1]","8aee64ea":"from sklearn.preprocessing import StandardScaler\nx = StandardScaler().fit_transform(x)\nx","cd708b57":"'''from sklearn.decomposition import PCA\npca = PCA(0.92)\nx = pca.fit_transform(x)\nx.shape\n'''","788c56c0":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout","9eba6cfd":"model = Sequential()\nmodel.add(Dense(num_classes * 2, activation=\"relu\", input_shape = (x.shape[1],)))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(num_classes ** 2, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes ** 3, activation=\"relu\"))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"mse\"])\nhistory = model.fit(x,y, epochs=35, batch_size = 1,validation_split=0.05, shuffle=True )","6c643002":"plt.plot(history.history[\"mse\"]) \nplt.plot(history.history[\"val_mse\"])","eaa816f9":"df_test[\"Title\"].iloc[414] = 1","5ee54c71":"x_test = StandardScaler().fit_transform(np.array(df_test.values))\nfinal = model.predict(x_test)","cfeba35c":"final = [int(np.round(x[0])) for x in final]","b7263e18":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0,max_depth=3, random_state=0).fit(x[:800],y[:800])\ngbc.score(x[800:], y[800:])","2b746e5c":"final1 = gbc.predict(x_test)","e29994ac":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\n\n\n\n# Training classifiers\ndtc = DecisionTreeClassifier(max_depth=3).fit(x[:800],y[:800])\nknn = KNeighborsClassifier(n_neighbors=4).fit(x[:800],y[:800])\nsvc = SVC(kernel='rbf', probability=True).fit(x[:800],y[:800])\nprint(dtc.score(x[800:], y[800:]))\nprint(knn.score(x[800:], y[800:]))\nprint(svc.score(x[800:], y[800:]))\n\nfinal2 = dtc.predict(x_test)\nfinal3 = knn.predict(x_test)\nfinal4 = svc.predict(x_test)","b20eb569":"pred_data = [final, final1, final2, final3, final4]\npred = []\nfor i in range(len(final)):\n    sum_d = 0\n    for j in range(len(pred_data)):\n        if j == 0: sum_d += 2 * pred_data[j][i]    #double weigh the initial model\n        else: sum_d += pred_data[j][i]\n    if sum_d > 3:\n        pred.append(1)\n    else:\n        pred.append(0)\n\n    ","5882a801":"ans = pd.DataFrame(pred)\nans[\"Survived\"] = pred\nans[\"PassengerId\"] = list(range(892,892 + len(df_test) ))\nans = ans[[\"PassengerId\", \"Survived\"]]\nans\n'''\nans = pd.DataFrame()\nans[\"Survived\"] = final\nans[\"PassengerId\"] = list(range(892,892 + len(df_test) ))\nans = ans[[\"PassengerId\", \"Survived\"]]\n'''\nans\n\n","dd971971":"ans.to_csv(\"submission.csv\", index=False)","5b97f5d3":"len(ans[ans[\"Survived\"] == 1])","6bedee93":"**drop**\n* WithRoyalty (experiment first)\n* Family\n* Parch\n* SibSp\n* Age\n\nStill have pretty weak correlations for a couple features but still relevent enough to include in model :\/","22d637b0":"5 means a rare title ","d404cafd":"Largest difference here is the 0-10 age grouping","0adc48b9":"Seems much more likley for a person to survive if they are with a person of royalty","15fa16c4":"* **Pclass** is highly relevent -> ordering should be changed because of heirarchy in data is backwards.\n* **Fare** is decently relevent -> (come up with something later)\n* **Age** seems unrelated but intuitivly should be related -> need to do feature engineering\n* **Parch and SibSp** unrelevent alone but should be combined","6730891a":"* Age, Embarked are almost full features that should be completed.\n* Cabin is too incomplete - drop.\n* Fare also needs to be completed in the test set.\n","6c7ee870":"seems to be at the optimal fitting point","c0c706ec":"estimating data with few missing points","7979a4f3":"No real reason for pca on such a small dataset","4d9af920":"people travelling alone are more prone to dying ","44b1b257":"number of survivors","b8dabf05":"assuming a child is 0-14 years of age (the statistical significance within the data)","3d60e3c2":"stand alone neural net got ~78 % acc -> try ensemble","d5fb0b05":"Normalize?"}}