{"cell_type":{"4573083f":"code","15cad6a4":"code","4e02b8b5":"code","7ff94e61":"code","4d8e5daf":"code","16bb4938":"code","8f900ed1":"code","ace5beef":"code","cca4b6df":"code","29cf94ac":"code","62f3a630":"code","ce779541":"code","936232f8":"code","5cbe29ba":"markdown","d83d9698":"markdown","9e1df609":"markdown","98702683":"markdown"},"source":{"4573083f":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.utils import resample\nfrom joblib import dump, load","15cad6a4":"wq = pd.read_csv('..\/input\/water-potability\/water_potability.csv')\nwq.head(n=10)","4e02b8b5":"print(wq.shape)\nprint(\"--------\")\nprint(wq.info())","7ff94e61":"# We have some NAs\nwq.isna().sum()\/wq.shape[0]","4d8e5daf":"# Lets drop NAs\nwq.dropna(inplace=True)","16bb4938":"wq.Potability.value_counts()","8f900ed1":"# Let's look at the correlation \nplt.figure(figsize=(12,10))\nsns.heatmap(wq.corr(), annot=True, cmap='BuGn', fmt='.2f')\nplt.show()","ace5beef":"random_state = 7 \nX = wq.drop(['Potability'], axis=1).to_numpy()\ny = wq['Potability'].to_numpy()","cca4b6df":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state, stratify=y)","29cf94ac":"def upsample_train_data(X, y):\n    ''' upsample the minority class '''\n    df = pd.concat([pd.DataFrame(X),pd.DataFrame(y, columns=['outcome'])], axis=1)\n    \n    val_counts = df.outcome.value_counts()\n    val_counts = dict(val_counts)    \n    \n    high_count = max(val_counts, key= val_counts.get)\n    low_count  = min(val_counts, key= val_counts.get)\n   \n    df_high = df[df.outcome == high_count]\n    df_low = df[df.outcome == low_count]   \n    df_low = resample(df_low, n_samples=val_counts.get(high_count), replace=True, random_state=random_state)\n    \n    df = pd.concat([df_high, df_low], axis=0, ignore_index=True)\n    X = df.drop('outcome', axis=1).to_numpy()\n    y = df['outcome'].to_numpy()\n    \n    return X, y   ","62f3a630":"# Upsample Training Data\nX_train, y_train =  upsample_train_data(X_train, y_train)","ce779541":"models = [(\"model_RF\", RandomForestClassifier()), (\"model_Ada\", AdaBoostClassifier()), (\"model_KNN\", KNeighborsClassifier())]\n\nparam_grids = [\n              {\n               \"model_RF__min_samples_leaf\" : [2,4,6],\n               \"model_RF__criterion\" : ['gini','entropy'],\n               \"model_RF__n_estimators\" : [250,500,1000],\n               \"model_RF__random_state\" : [random_state]  \n              },\n              {\n               \"model_Ada__n_estimators\" :range(50,200,50),\n               \"model_Ada__random_state\" : [random_state]  \n              },\n              {\n                \"model_KNN__n_neighbors\" :range(2, 75, 1)                  \n              }             \n             ]","936232f8":"for i in range(0,3):\n    pipeline = Pipeline(steps=\n                        [\n                         ('StdScaler',StandardScaler()),\n                         models[i]\n                        ]\n                       )\n    gridsearch = GridSearchCV(estimator=pipeline, param_grid = param_grids[i], cv=5, refit='Accuracy', scoring={'AUC':'roc_auc','Accuracy': make_scorer(accuracy_score)}, return_train_score=False)\n    gridsearch.fit(X_train, y_train)\n    print(gridsearch.best_estimator_)\n    print(accuracy_score(y_test, gridsearch.best_estimator_.predict(X_test)))\n    print('**********************************************************')","5cbe29ba":"## 14% of ph, 24% of Sulfate and 5% of Trihalomethanes values are missing","d83d9698":"## Potability of water is very weakly correlated with the features in the dataset. It would be interesting to see if these features can collectively predict potability.","9e1df609":"# We get highest accuracy of 69.30% on test data using RandomForestClassifier. ","98702683":"## Dataset is slightly imbalanced i.e. number of observations with potable water is not equal to the number of observations with nonpotable water. We would upsample the training data to have same number of potable and non-potable observations. Another option could be using a probablity threshold using ROC AUC curve to predict the potability of water. Higher AUC means a better model. I will be using upsampling for this effort."}}