{"cell_type":{"9f9de341":"code","ec9ad990":"code","bda08564":"code","00aa71c1":"code","3d163137":"code","d3d4dada":"code","2fb3f81e":"code","6a9fdc65":"code","9d136a16":"code","602250bb":"code","52c43940":"code","7fa9f63f":"code","d555b4fc":"code","b715aa19":"code","90b3a030":"code","dc5d2ecc":"markdown","c5c1135b":"markdown","e99d7cd7":"markdown","14f768de":"markdown","5c9e48ce":"markdown","ed28e198":"markdown","38775bda":"markdown","1db8c05b":"markdown","67f4b5f7":"markdown","88f09912":"markdown","940255d9":"markdown"},"source":{"9f9de341":"#load modules\nimport os\nimport pandas as pd\nimport numpy as np\nfrom pandas import read_csv\nfrom pandas import datetime\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","ec9ad990":"#Load datasets\ntrain=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")\nsample=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nitems=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nitem_cat=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nshops=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv\")","bda08564":"#convert date to datetime format\ntrain['date'] = pd.to_datetime(train['date'],format = '%d.%m.%Y')\ntrain","00aa71c1":"#create pivot table\ndataset = train.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],fill_value = 0,aggfunc='sum')\ndataset.reset_index(inplace = True)\ndataset","3d163137":"ID = test.ID\nID","d3d4dada":"test = test.drop(['ID'], axis=1)\ntest","2fb3f81e":"#merge pivot table with test set\ndataset = pd.merge(test,dataset,on = ['item_id','shop_id'],how = 'left')\ndataset","6a9fdc65":"#check for any null values\ndataset.isnull().sum().sum()","9d136a16":"#fill all NaN values with 0\ndataset.fillna(0,inplace = True)\ndataset.isnull().sum().sum()","602250bb":"#drop shop_id and item_id\ndataset.drop(['shop_id','item_id'],inplace = True, axis = 1)\ndataset","52c43940":"#split the dataset in two\n# the last column is our label\ny_train = dataset.iloc[:,-1:]\n#drop last column of data\nX_train = dataset.iloc[:, :-1]\n#drop first colum of data\nX_test = dataset.iloc[:,1:]\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)","7fa9f63f":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = AdaBoostRegressor(base_estimator = RandomForestRegressor(max_depth=10), random_state=0, n_estimators=3000).fit(X_train, y_train)\ny_pred = model.predict(X_train)\ny_pred","d555b4fc":"print(model.score(X_train, y_train))","b715aa19":"pred = model.predict(X_test)\npred","90b3a030":"# creating submission file \nsubmission_file = pred\n# we will keep every value between 0 and 20\nsubmission_file = submission_file.clip(0,20)\n# creating dataframe with required columns \nsubmission_trp = pd.DataFrame({'ID':ID,'item_cnt_month':submission_file.ravel()})\n# creating csv file from dataframe\nsubmission_trp.to_csv('submission.csv',index = False)\nsubmission_trp.head(20)","dc5d2ecc":"\nThis challenge serves as final project for the \"How to win a data science competition\" Coursera course.\n\nIn this competition you will work with a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company.\n\nWe are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance your data science skills.","c5c1135b":"Load libraries","e99d7cd7":"Create dataset","14f768de":"Submit file","5c9e48ce":"Make predictions","ed28e198":"Convert date to datetime format","38775bda":"An AdaBoost regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. ","1db8c05b":"Load datasets","67f4b5f7":"Define model","88f09912":"Create X, y and X_test","940255d9":"Preprocess data"}}