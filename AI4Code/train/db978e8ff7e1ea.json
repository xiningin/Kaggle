{"cell_type":{"1dc195ed":"code","5cef73e3":"code","7bc63fe5":"code","b38a0cb7":"code","068094e2":"code","75c2e37e":"code","911678ca":"code","27c50996":"code","4ac6cf9d":"code","fe03f6d3":"code","4d31bfe4":"code","826ef906":"code","008249f2":"code","c73ff7e4":"code","c5b7e6a1":"code","e8652bcd":"code","aecc1388":"code","1f13dbd1":"code","e9769318":"code","994aa22e":"code","f01fcffe":"code","51958e0c":"code","0c34d940":"code","d78a86dc":"code","3fc3f9de":"code","f55ac26e":"code","f379a9c4":"code","e0fca834":"code","c6cbf4f0":"code","073cdc67":"code","59ebfc22":"code","b165df5a":"code","48210c58":"code","e6f7b6a2":"code","8506c44a":"code","f76eefee":"code","749e2561":"code","01274ebf":"markdown","87a6499c":"markdown","68982548":"markdown","4d7dc0e5":"markdown","93640fc7":"markdown","627c34dd":"markdown","49afbba3":"markdown","dab78f72":"markdown","99feaa6f":"markdown","bb4df0b0":"markdown","8aa47ced":"markdown","13e0c7c3":"markdown","6615ffdf":"markdown"},"source":{"1dc195ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5cef73e3":"df= pd.read_csv('\/kaggle\/input\/water-potability\/water_potability.csv')\ndf.head()","7bc63fe5":"df.info()","b38a0cb7":"df.describe()","068094e2":"df.isna().sum()","75c2e37e":"df['ph'].hist()","911678ca":"df['ph']= df['ph'].fillna(df['ph'].mean())","27c50996":"df['Sulfate'].hist()","4ac6cf9d":"df['Sulfate']= df['Sulfate'].fillna(df['Sulfate'].mean())","fe03f6d3":"df['Trihalomethanes'].hist()","4d31bfe4":"df['Trihalomethanes']= df['Trihalomethanes'].fillna(df['Trihalomethanes'].mean())","826ef906":"df.hist(figsize=(15,15))\nplt.show()","008249f2":"sns.pairplot(df, hue='Potability')","c73ff7e4":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(), annot=True)","c5b7e6a1":"from sklearn.utils import shuffle\n\ndf= shuffle(df)\ndf.head()","e8652bcd":"from sklearn.model_selection import train_test_split\n\nX= df.drop('Potability', axis=1)\ny= df['Potability']","aecc1388":"from sklearn.preprocessing import StandardScaler\n\nss=StandardScaler()\nX= ss.fit_transform(X)","1f13dbd1":"X= pd.DataFrame(X, columns= [col for col in df.columns if col!='Potability' ])","e9769318":"X.head()","994aa22e":"X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, stratify=y)","f01fcffe":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC","51958e0c":"key= ['KNeighborsClassifier', 'LogisticRegression', 'RandomForestClassifier', 'GaussianNB', 'DecisionTreeClassifier', 'XGBClassifier', 'SVC']\nvalue= [KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier(), GaussianNB(), DecisionTreeClassifier(), XGBClassifier(), SVC()]\n\nmodels= dict(zip(key,value))","0c34d940":"training_scores= []\ntesting_scores=[]\n\nfor key, value in models.items():\n    value.fit(X_train, y_train)\n    train_score= value.score(X_train,  y_train)\n    test_score= value.score(X_test, y_test)\n    training_scores.append(train_score)\n    testing_scores.append(test_score)\n    \n    print(f\"{key}\\n\")\n    print(f\"Training Score: {train_score}\" )\n    print(f\"Testing Score: {test_score} \\n\")","d78a86dc":"from sklearn.model_selection import cross_val_score\ncv_scores= []\n\nfor key, value in models.items():\n    cvs=cross_val_score(value, X,y, cv=5)\n    \n    cv_scores.append(cvs.mean())\n    print(f\"{key}\\n\")\n    print(f\"CV Score: {cvs.mean()} \\n\" )","3fc3f9de":"random_states=[]\n\nsvc= SVC()\nrfc= RandomForestClassifier()\n\nsvc_acc=[]\nrfc_acc=[]\n\nfor i in range(1,150,1):\n    xtrain, xtest, ytrain,ytest= train_test_split(X,y,random_state=i, test_size=0.2, stratify=y)\n    svc.fit(xtrain,ytrain)\n    rfc.fit(xtrain,ytrain)\n    svc_acc.append(svc.score(xtest,ytest))\n    rfc_acc.append(rfc.score(xtest,ytest))\n    random_states.append(i)\n    \n\n","f55ac26e":"plt.plot(random_states, svc_acc)","f379a9c4":"plt.plot(random_states,rfc_acc)","e0fca834":"svc_acc.index(max(svc_acc))","c6cbf4f0":"m= rfc_acc.index(max(rfc_acc))","073cdc67":"r= random_states[m]","59ebfc22":"X_train, X_test, y_train, y_test= train_test_split(X,y,random_state=r, stratify=y, test_size=0.2)\n\nrfc.fit(X_train, y_train)\nrfc.score(X_test,y_test)","b165df5a":"from sklearn.model_selection import RandomizedSearchCV\n\nrfc= RandomForestClassifier(random_state=r)\n\nparams={'n_estimators':[10,100,200,500],\n       'max_depth':[5,10,20,80],\n       'min_samples_leaf':[1,10,25]}\n\nrandom= RandomizedSearchCV(rfc, param_distributions=params,cv=5, random_state=r)","48210c58":"random.fit(X_train,y_train)","e6f7b6a2":"best= random.best_estimator_","8506c44a":"best.fit(X_train,y_train)\n\ny_pred= best.predict(X_test)\nbest.score(X_test,y_test)","f76eefee":"from sklearn.metrics import classification_report, confusion_matrix, plot_roc_curve\n\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\n","749e2561":"plot_roc_curve(best, X_test,y_test)","01274ebf":"**There aren't highly co-related features**","87a6499c":"# Training our Models","68982548":"**Yes, the data is pretty well distributed and normalized**","4d7dc0e5":"# Result","93640fc7":"# Upvote the notebook if you liked :)","627c34dd":"**The data looks normalized already**","49afbba3":"**Overall, RandomForest seems to be working slightly better than SVC**","dab78f72":"# Hyperparameter Tuning","99feaa6f":"**We still scale the data for better results**","bb4df0b0":"# Exploratory Data Analysis","8aa47ced":"# Load Data","13e0c7c3":"# Null-Values","6615ffdf":"# SVC and RandomForestClassifier are performing best"}}