{"cell_type":{"e0ccfa16":"code","84a7dcbb":"code","a0c131d9":"code","51ae89a7":"code","0cf1e20e":"code","7fbd14c7":"code","486fe527":"code","b5e455af":"code","6038c449":"code","a5e2c7f7":"code","a527c51d":"code","f9a942f8":"markdown"},"source":{"e0ccfa16":"from datetime import datetime\nimport lxml\nfrom lxml import html\nimport requests\nimport numpy as np\nimport pandas as pd","84a7dcbb":"# Enter a stock symbol\nsymbol = 'GOOGL'","a0c131d9":"# URL link\nurl_bs = 'https:\/\/finance.yahoo.com\/quote\/' + symbol + '\/balance-sheet?p=' + symbol\nurl_is = 'https:\/\/finance.yahoo.com\/quote\/' + symbol + '\/financials?p=' + symbol\nurl_cf = 'https:\/\/finance.yahoo.com\/quote\/' + symbol + '\/cash-flow?p='+ symbol","51ae89a7":"# Set up the request headers that we're going to use, to simulate\n# a request by the Chrome browser. Simulating a request from a browser\n# is generally good practice when building a scraper\nheaders = {\n    'Accept': 'text\/html,application\/xhtml+xml,application\/xml;q=0.9,image\/webp,image\/apng,*\/*;q=0.8,application\/signed-exchange;v=b3',\n    'Accept-Encoding': 'gzip, deflate, br',\n    'Accept-Language': 'en-US,en;q=0.9',\n    'Cache-Control': 'max-age=0',\n    'Pragma': 'no-cache',\n    'Referrer': 'https:\/\/google.com',\n    'User-Agent': 'Mozilla\/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/77.0.3865.120 Safari\/537.36'\n}","0cf1e20e":"def get_table(url):\n    # Fetch the page that we're going to parse, using the request headers defined above\n    page = requests.get(url, headers)\n\n    # Parse the page with LXML, so that we can start doing some XPATH queries\n    # to extract the data that we want\n    tree = html.fromstring(page.content)\n\n    # Smoke test that we fetched the page by fetching and displaying the H1 element\n    tree.xpath(\"\/\/h1\/text()\")\n    table_rows = tree.xpath(\"\/\/div[contains(@class, 'D(tbr)')]\")\n\n    # Ensure that some table rows are found; if none are found, then it's possible\n    # that Yahoo Finance has changed their page layout, or have detected\n    # that you're scraping the page.\n    assert len(table_rows) > 0\n\n    parsed_rows = []\n\n    for table_row in table_rows:\n        parsed_row = []\n        el = table_row.xpath(\".\/div\")\n\n        none_count = 0\n\n        for rs in el:\n            try:\n                (text,) = rs.xpath('.\/\/span\/text()[1]')\n                parsed_row.append(text)\n            except ValueError:\n                parsed_row.append(np.NaN)\n                none_count += 1\n\n        if (none_count < 4):\n            parsed_rows.append(parsed_row)\n\n    df = pd.DataFrame(parsed_rows)\n    df1 = df\n    \n    df = pd.DataFrame(parsed_rows)\n    df = df.set_index(0) # Set the index to the first column: 'Period Ending'.\n    df = df.transpose() # Transpose the DataFrame, so that our header contains the account names\n\n    # Rename the \"Breakdown\" column to \"Date\"\n    cols = list(df.columns)\n    cols[0] = 'Date'\n    df = df.set_axis(cols, axis='columns', inplace=False)\n    df2 = df\n    return df1, df2","7fbd14c7":"# get Balance Sheet \nbs1, bs2 = get_table(url_bs)\nbs1","486fe527":"bs2","b5e455af":"# get Income Statement \nis1, is2 = get_table(url_is)\nis1","6038c449":"is2","a5e2c7f7":"# get Cash Flow\ncf1, cf2 = get_table(url_cf)\ncf1","a527c51d":"cf2","f9a942f8":"# Scrape Yahoo Finance\n## Balance Sheet, Income Statement, Cash Flow"}}