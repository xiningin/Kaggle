{"cell_type":{"e2e8f997":"code","0eabe1b6":"code","434a824e":"code","2268ee64":"code","09dfae65":"code","92b0f5cf":"code","335f5117":"code","044fc9ee":"code","56aa2f92":"code","858966d9":"code","9510bb6f":"code","bd536954":"code","dcafe471":"code","11d52cc6":"code","5225426a":"code","a1ebbf97":"markdown","5116e5c1":"markdown","6c3bc9a0":"markdown","e2e1f142":"markdown","2878cdc3":"markdown","fa024841":"markdown","9bd63ca7":"markdown"},"source":{"e2e8f997":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Any results you write to the current directory are saved as output.","0eabe1b6":"data2_weka = pd.read_csv('..\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv')\nprint(plt.style.available) # look at available plot styles\nplt.style.use('ggplot')","434a824e":"data2_weka.head()","2268ee64":"data2_weka.info()","09dfae65":"data2_weka.describe()","92b0f5cf":"color_list = ['red' if i=='Abnormal' else 'green' for i in data2_weka.loc[:,'class']]\npd.plotting.scatter_matrix(data.loc[:, data2_weka.columns != 'class'],\n                                       c=color_list,\n                                       figsize= [15,15],\n                                       diagonal='hist',\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = '*',\n                                       edgecolor= \"black\")\nplt.show()","335f5117":"data1 = data2_weka[data2_weka['class'] =='Abnormal']\ndata1.head()","044fc9ee":"x = np.array(data1.loc[:,'pelvic_incidence']).reshape(-1,1)\ny = np.array(data1.loc[:,'lumbar_lordosis_angle']).reshape(-1,1)\n#Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x,y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('lumbar_lordosis')\nplt.show()","56aa2f92":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(x,y)\n\ny_head = lr.predict(x)\nplt.plot(x,y_head, color=\"black\")\nplt.scatter(x,y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('lumbar_lordosis')\nplt.show()\n","858966d9":"from sklearn.metrics import r2_score\nprint(\"r_square_score\", r2_score(y,y_head))","9510bb6f":"from sklearn.preprocessing import PolynomialFeatures\npr = PolynomialFeatures(degree = 5)\n\nx_polynomial = pr.fit_transform(x)\n\nlr2 = LinearRegression()\nlr2.fit(x_polynomial,y)\n\ny_head2 = lr2.predict(x_polynomial).reshape(-1,1)\nplt.plot(x,y_head2,color = \"yellow\",linewidth =3,label = \"poly_reg\")\nplt.legend()\nplt.scatter(x,y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('lumbar_lordosis')\nplt.show()","bd536954":"from sklearn.metrics import r2_score\nprint(\"r_square_score\", r2_score(y,y_head2))","dcafe471":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=50, random_state=42 )\nrf.fit(x,y)\n\nx_ = np.arange(min(x),max(x),0.05).reshape(-1,1)\ny_head3 = rf.predict(x_)\nplt.figure(figsize=[10,10])\nplt.plot(x_,y_head3,color=\"green\",label=\"randomforest\")\nplt.scatter(x,y,color=\"red\")\nplt.xlabel('pelvic_incidence')\nplt.ylabel('lumbar_lordosis')\nplt.show()","11d52cc6":"from sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(x,y)\n\ny_head4 = tree_reg.predict(x)\nplt.figure(figsize=[10,10])\nplt.scatter(x,y,color=\"red\")\nplt.plot(x,y_head4,color=\"green\",label=\"decisiontree\")\nplt.xlabel('pelvic_incidence')\nplt.ylabel('lumbar_lordosis')\nplt.show()\n","5225426a":"from sklearn.metrics import r2_score\nprint(\"r_square_score\", r2_score(y,y_head4))\n","a1ebbf97":"Decision Tree Regressor\n\n> * Decision Tree is a decision-making tool that uses a flowchart-like tree structure or is a model of decisions and all of their possible results, including outcomes, input costs and utility.\n> * Decision tree regression observes features of an object and trains a model in the structure of a tree to predict data in the future to produce meaningful continuous output.\n\nhttps:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/decision-tree.jpg\n","5116e5c1":"Exploratory Data Analysis\n\n* In order to make something in data, as you know you need to explore data.\n* We always start with *head()* to see features that are *pelvic_incidence,\tpelvic_tilt numeric,lumbar_lordosis_angle,\tsacral_slope,\tpelvic_radius* and \t*degree_spondylolisthesis* and target variable that is *class*\n* head(): default value of it shows first 5 rows(samples). If you want to see for example 20 rows just write head(20)\n","6c3bc9a0":"Linear Regression Method\n\n* **\n\ny = ax + b\nfit() : fits the data1, train the data1\npredict() : predict the data1","e2e1f142":"We state the feature and target variable in new data model.\n\nx : feature \ny : target variable\n\n> feature -- pelvic_incidence\n> target  -- lumbar_lordosis_angle","2878cdc3":"Linear Regression Score\n\nScore: Score uses R^2 method that is ((y_pred - y_mean)^2 )\/(y_actual - y_mean)^2\nScore : predict and give accuracy. \n\nIt should be very close to 1. ","fa024841":"Polynomial Regression\n\ny = a*x + b* x^2 + c*x^3 + d* x^4+ e*x^5\n\ncoefficent = 5\npr : polynomialfeatures","9bd63ca7":"Create the New Data \n\n* We create the new data model that only include Abnormal in class column."}}