{"cell_type":{"fb27856c":"code","af6cb5be":"code","7e21665b":"code","77c9785a":"code","e3bfc9f7":"code","83dc01ce":"code","386cb48d":"code","b0210ace":"code","c0831af4":"code","0aeb3753":"code","6963f2bc":"code","6badba81":"code","b2eca287":"code","d58f88fc":"code","cf5d27cd":"code","c1c907d5":"code","101612f1":"code","bdcdf046":"code","3672dd3f":"code","bc0df8a2":"code","5ef3af4c":"markdown","b157dee0":"markdown","39a96547":"markdown","df0713d5":"markdown","b7054099":"markdown","fd2ec590":"markdown","eae5dd23":"markdown","fc73bf47":"markdown"},"source":{"fb27856c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af6cb5be":"# \u6839\u636e\u6253\u5370\u51fa\u7684\u6587\u4ef6\u8def\u5f84\uff0c\u5c06\u6587\u4ef6\u8bfb\u53d6\u8fdb\u5185\u5b58\nsample_submission = pd.read_csv('\/kaggle\/input\/california-house-prices\/sample_submission.csv')\ntrain_data = pd.read_csv('\/kaggle\/input\/california-house-prices\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/california-house-prices\/test.csv')","7e21665b":"# \u6211\u4eec\u5148\u770b\u4e00\u4e0b\u8fd9\u4e09\u4e2a\u6570\u636e\u957f\u4ec0\u4e48\u6837\nsample_submission.shape, train_data.shape, test_data.shape","77c9785a":"# \u6211\u4eec\u5148\u6765\u7c97\u7565\u770b\u4e00\u4e0b\u6570\u636e\u96c6\u5305\u542b\u54ea\u4e9b\u7279\u5f81\uff0chead\u65b9\u6cd5\u53ef\u4ee5\u67e5\u770b\u524d\u4e94\u884c\u6570\u636e\ntrain_data.head()","e3bfc9f7":"# \u4fdd\u9669\u8d77\u89c1\uff0c\u8fd8\u662f\u770b\u4e00\u4e0b\u6d4b\u8bd5\u96c6\u957f\u4ec0\u4e48\u6837\u5b50\u518d\u8fdb\u884c\u4e0b\u4e00\u6b65\u5904\u7406\ntest_data.head()","83dc01ce":"# train_data.loc[:, train_data.columns != 'Sold Price'] # \u8fd9\u884c\u4ee3\u7801\u7528\u4e8e\u63d0\u53d6\u9664'Sold Price'\u5916\u7684\u5176\u4ed6\u5217\nall_features = pd.concat((train_data.loc[:, train_data.columns != 'Sold Price'], test_data.iloc[:, 1:]))\nall_features.info() # info\u65b9\u6cd5\u53ef\u4ee5\u603b\u89c8\u6570\u636e","386cb48d":"# \u5c06\u6240\u6709\u7f3a\u5931\u7684\u503c\u66ff\u6362\u4e3a\u76f8\u5e94\u7279\u5f81\u7684\u5e73\u5747\u503c\u3002\u901a\u8fc7\u5c06\u7279\u5f81\u91cd\u65b0\u7f29\u653e\u5230\u96f6\u5747\u503c\u548c\u5355\u4f4d\u65b9\u5dee\u6765\u6807\u51c6\u5316\u6570\u636e\nnumeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\nall_features[numeric_features] = all_features[numeric_features].apply(\n    lambda x: (x - x.mean()) \/ (x.std()))\nall_features[numeric_features] = all_features[numeric_features].fillna(0)","b0210ace":"# # \u5904\u7406\u79bb\u6563\u503c\u3002\u6211\u4eec\u7528\u4e00\u6b21\u72ec\u70ed\u7f16\u7801\u66ff\u6362\u5b83\u4eec\n# all_features = pd.get_dummies(all_features, dummy_na=True)\n# all_features.shape","c0831af4":"all_features = all_features[numeric_features[1:]] # \u539f\u672c\u7b2c\u4e00\u5217\u662fId\uff0c\u53bb\u6389\nall_features.info()","0aeb3753":"import torch\n\n# \u4ecepandas\u683c\u5f0f\u4e2d\u63d0\u53d6NumPy\u683c\u5f0f\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u5f20\u91cf\u8868\u793a\nn_train = train_data.shape[0]\ntrain_features = torch.tensor(all_features[:n_train].values,\n                              dtype=torch.float32)\ntest_features = torch.tensor(all_features[n_train:].values,\n                             dtype=torch.float32)\n# \u6ce8\u610f\u8bfe\u4e0a\u6570\u636e\u7684\u6807\u7b7e\u5217\u4e3aSalePrice\uff0c\u4e0e\u6bd4\u8d5b\u7528\u7684\u6807\u7b7e\u5217\u540d\u4e0d\u540c\ntrain_labels = torch.tensor(train_data['Sold Price'].values.reshape(-1, 1),\n                            dtype=torch.float32)","6963f2bc":"from torch import nn\n\n# \u5b9a\u4e49\u6a21\u578b\u4e0e\u635f\u5931\u51fd\u6570\nloss = nn.MSELoss()\nin_features = train_features.shape[1]\n\ndef get_net():\n    net = nn.Sequential(nn.Linear(in_features, 1))\n    return net","6badba81":"# \u6211\u4eec\u66f4\u5173\u5fc3\u76f8\u5bf9\u8bef\u5dee\uff0c\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u7528\u4ef7\u683c\u9884\u6d4b\u7684\u5bf9\u6570\u6765\u8861\u91cf\u5dee\u5f02\ndef log_rmse(net, features, labels):\n    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))\n    return rmse.item()","b2eca287":"from torch.utils import data\n\n# Defined in file: .\/chapter_linear-networks\/linear-regression-concise.md\ndef load_array(data_arrays, batch_size, is_train=True):\n    \"\"\"\u6784\u9020\u4e00\u4e2aPyTorch\u6570\u636e\u8fed\u4ee3\u5668\u3002\"\"\"\n    dataset = data.TensorDataset(*data_arrays)\n    return data.DataLoader(dataset, batch_size, shuffle=is_train)","d58f88fc":"# \u6211\u4eec\u7684\u8bad\u7ec3\u51fd\u6570\u5c06\u501f\u52a9Adam\u4f18\u5316\u5668\ndef train(net, train_features, train_labels, test_features, test_labels,\n          num_epochs, learning_rate, weight_decay, batch_size):\n    train_ls, test_ls = [], []\n    # \u6ce8\u610fkaggle\u73af\u5883\u4e2d\u6ca1\u6709\u5b89\u88c5d2l\uff0c\u6545\u7528\u5230\u7684\u5730\u65b9\u9700\u8981\u624b\u52a8\u5b9a\u4e49\n    train_iter = load_array((train_features, train_labels), batch_size)\n    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate,\n                                 weight_decay=weight_decay)\n    for epoch in range(num_epochs):\n        for X, y in train_iter:\n            optimizer.zero_grad()\n            l = loss(net(X), y)\n            l.backward()\n            optimizer.step()\n        train_ls.append(log_rmse(net, train_features, train_labels))\n        if test_labels is not None:\n            test_ls.append(log_rmse(net, test_features, test_labels))\n    return train_ls, test_ls","cf5d27cd":"# K\u6298\u4ea4\u53c9\u9a8c\u8bc1\ndef get_k_fold_data(k, i, X, y):\n    assert k > 1\n    fold_size = X.shape[0] \/\/ k\n    X_train, y_train = None, None\n    for j in range(k):\n        idx = slice(j * fold_size, (j + 1) * fold_size)\n        X_part, y_part = X[idx, :], y[idx]\n        if j == i:\n            X_valid, y_valid = X_part, y_part\n        elif X_train is None:\n            X_train, y_train = X_part, y_part\n        else:\n            X_train = torch.cat([X_train, X_part], 0)\n            y_train = torch.cat([y_train, y_part], 0)\n    return X_train, y_train, X_valid, y_valid","c1c907d5":"# \u8fd4\u56de\u8bad\u7ec3\u548c\u9a8c\u8bc1\u8bef\u5dee\u7684\u5e73\u5747\u503c\ndef k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,\n           batch_size):\n    train_l_sum, valid_l_sum = 0, 0\n    for i in range(k):\n        data = get_k_fold_data(k, i, X_train, y_train)\n        net = get_net()\n        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n                                   weight_decay, batch_size)\n        train_l_sum += train_ls[-1]\n        valid_l_sum += valid_ls[-1]\n        # \u5220\u53bb\u5229\u7528d2l\u753b\u56fe\u7684\u4ee3\u7801\n        print(f'fold {i + 1}, train log rmse {float(train_ls[-1]):f}, '\n              f'valid log rmse {float(valid_ls[-1]):f}')\n    return train_l_sum \/ k, valid_l_sum \/ k","101612f1":"# \u6a21\u578b\u9009\u62e9\nk, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\ntrain_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\n                          weight_decay, batch_size)\nprint(f'{k}-\u6298\u9a8c\u8bc1: \u5e73\u5747\u8bad\u7ec3log rmse: {float(train_l):f}, '\n      f'\u5e73\u5747\u9a8c\u8bc1log rmse: {float(valid_l):f}')","bdcdf046":"# \u6700\u540e\u63d0\u4ea4\u524d\u9700\u8981\u786e\u8ba4\u6bd4\u8d5b\u6240\u9700\u7684\u683c\u5f0f\u662f\u5426\u548c\u8bfe\u4e0a\u6570\u636e\u96c6\u6709\u51fa\u5165\nsample_submission.head()","3672dd3f":"# \u63d0\u4ea4\u4f60\u7684Kaggle\u9884\u6d4b\ndef train_and_pred(train_features, test_feature, train_labels, test_data,\n                   num_epochs, lr, weight_decay, batch_size):\n    net = get_net()\n    train_ls, _ = train(net, train_features, train_labels, None, None,\n                        num_epochs, lr, weight_decay, batch_size)\n    # \u5220\u53bb\u5229\u7528d2l\u753b\u56fe\u7684\u4ee3\u7801\n    print(f'train log rmse {float(train_ls[-1]):f}')\n    preds = net(test_features).detach().numpy()\n    # \u4e0d\u51fa\u6240\u6599\uff0c\u5217\u540d\u9700\u8981\u505a\u66ff\u6362\n    test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n    submission = pd.concat([test_data['Id'], test_data['Sold Price']], axis=1)\n    submission.to_csv('submission.csv', index=False)\n    # \u6700\u540e\u8fd4\u56de\u4e00\u4e0b\u63d0\u4ea4\u7684\u7ed3\u679c\uff0c\u4ee5\u4fbf\u67e5\u770b\n    return submission\n\nsubmission = train_and_pred(train_features, test_features, train_labels, test_data,\n               num_epochs, lr, weight_decay, batch_size)","bc0df8a2":"# \u67e5\u770b\u4e00\u4e0b\u9884\u6d4b\u7ed3\u679c\uff0c\u4ee5\u786e\u4fdd\u683c\u5f0f\u4e0e\u6837\u4f8b\u4e00\u81f4\nsubmission.head()","5ef3af4c":"\u53ef\u4ee5\u770b\u51fa\uff0c\u73b0\u5728\u7684\u7279\u5f81\u53ea\u5305\u542b18\u5217\u4e86\uff0c\u5e76\u4e14\u90fd\u662f\u6570\u503c\u7279\u5f81","b157dee0":"\u6ce8\u610f\u5230\u6bd4\u8d5b\u7528\u5230\u7684\u8bad\u7ec3\u96c6\u6807\u7b7e(\u5373\u771f\u5b9e\u6210\u4ea4\u4ef7\u683c)\u4e0e\u4e0a\u8bfe\u65f6\u7528\u5230\u7684\u4e0d\u540c\uff0c\u4e0a\u8bfe\u65f6\u7528\u5230\u7684\u6807\u7b7e\u5728\u6700\u540e\u4e00\u5217\uff0c\u800c\u6bd4\u8d5b\u7528\u5230\u7684\u6807\u7b7e\u5728\u7b2c\u4e09\u5217\uff0c\u540d\u79f0\u4e3a`Sold Price`\n\n\u901a\u8fc7\u641c\u7d22\uff0c\u6211\u5728[stackoverflow](https:\/\/stackoverflow.com\/questions\/29763620\/how-to-select-all-columns-except-one-column-in-pandas)\u4e0a\u67e5\u5230\u5982\u4f55\u53bb\u6389\u67d0\u5217\uff0c\u90a3\u73b0\u5728\u6211\u4eec\u7ee7\u7eed\u628a\u6570\u636e\u96c6\u7684\u7279\u5f81\u63d0\u53d6\u51fa\u6765\u5427~","39a96547":"\u8003\u8651\u5230\u8bad\u7ec3\u96c6\u670947439\u6761\u6570\u636e\uff0c\u505a\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65f6\u95f4\u4f1a\u6bd4\u8f83\u957f\uff0c\u5927\u7ea6\u9700\u89815\u5206\u949f\n\n\u6b64\u5904\u8d85\u53c2\u6570\u76f4\u63a5\u7167\u642c\u8bfe\u4ef6\uff0c\u6545\u635f\u5931\u503c\u6bd4\u8f83\u5927","df0713d5":"\u4ece\u6570\u5b57\u4e0a\u6211\u4eec\u53ef\u4ee5\u770b\u51fa\u4ee5\u4e0b\u4e24\u70b9\uff1a\n1. \u6211\u4eec\u8981\u63d0\u4ea4\u7684\u6587\u4ef6\u53ea\u5305\u542b\u4e24\u5217\uff0c\u7b2c\u4e00\u5217\u662f\u5bf9\u5e94\u4e86\u6bcf\u4e00\u4e2a\u6d4b\u8bd5\u96c6\u6837\u672c\u7684`Id`\uff0c\u7b2c\u4e8c\u5217\u662f\u6211\u4eec\u6240\u9884\u6d4b\u7684`SalePrice`(\u5982\u4e0a\u8bfe\u6240\u6f14\u793a\u7684\u90a3\u6837)\n1. \u4e0a\u8bfe\u6f14\u793a\u7684\u8bad\u7ec3\u96c6\u4e0e\u6d4b\u8bd5\u96c6\u7684\u5f62\u72b6\u5206\u522b\u4e3a`(1460, 81)`\u548c`(1459, 80)`\uff0c\u53ef\u4ee5\u770b\u51fa\u6bd4\u8d5b\u7528\u7684\u6570\u636e\u96c6\u6837\u672c\u6570\u91cf\u66f4\u591a\uff0c\u4f46\u662f\u7279\u5f81\u5374\u66f4\u5c11\u4e86","b7054099":"\u4ee5\u4e0a\u4ee3\u7801\u662f\u65b0\u5efa\u7b14\u8bb0\u672c\u65f6\u9ed8\u8ba4\u751f\u6210\u7684\n\n---\n\u4ee5\u4e0b\u4ee3\u7801\u662f\u6211\u81ea\u5df1\u5199\u7684\uff0c\u57fa\u672c\u8109\u7edc\u53c2\u8003\u8001\u5e08\u7684\u8bfe\u4ef6`kaggle-house-price.ipynb`\uff0c\u5e0c\u671b\u7ed9\u5927\u5bb6\u63d0\u4f9b\u4e00\u4e2a\u7b80\u5355\u7684\u8d77\u6b65(getting started)\u7528\u4ee5\u53c2\u8003","fd2ec590":"\u81f3\u6b64\u5c31\u53ef\u4ee5\u5411kaggle\u63d0\u4ea4\u6211\u4eec\u7684\u7ed3\u679c\u4e86~\n\n\u5982\u679c\u8fd9\u7bc7\u7b14\u8bb0\u672c\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u4e0d\u59a8\u70b9\u4e2a\u8d5e\u4ee5\u6ee1\u8db3\u6211\u5c0f\u5c0f\u7684\u865a\u8363\u5fc3\uff0c\u7231\u4f60\u54df~","eae5dd23":"\u5982\u679c\u6211\u4eec\u76f4\u63a5\u7528\u8001\u5e08\u63d0\u4f9b\u7684\u4ee3\u7801(\u5373\u4e0a\u9762\u88ab\u6ce8\u91ca\u6389\u7684\u4ee3\u7801)\uff0c\u90a3kaggle\u5c31\u4f1a\u62a5\u4e00\u4e2a\u9519\u8bef\uff1a\n\n> Your notebook tried to allocate more memory than is available. It has restarted.\n\n\u8fd9\u8bf4\u660e\u7279\u5f81\u5206\u5e03\u592a\u8fc7\u5206\u6563\u4e86\uff0c\u5982\u679c\u7528\u72ec\u70ed\u7f16\u7801\u5c31\u4f1a\u5360\u7528\u5927\u91cf\u5185\u5b58\uff0c\u5bfc\u81f4\u91cd\u542f\n\n\u7b80\u5355\u8d77\u89c1\uff0c\u63a5\u4e0b\u6765\u6211\u5c1d\u8bd5\u8df3\u8fc7\u5bf9\u5b57\u7b26\u4e32\u7684\u5904\u7406\uff0c\u53ea\u5229\u7528\u6570\u503c\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3","fc73bf47":"\u53ef\u4ee5\u53d1\u73b0`Id`\u4e3a4\u7684\u6570\u636e\u7f3a\u5931\u4e86\u8bb8\u591a\u7279\u5f81\uff0c\u50cf\u8fd9\u6837\u7684\u6570\u636e\u5e94\u8be5\u8fd8\u4f1a\u6709\u5f88\u591a\n\n\u4f46\u662f\u4e0d\u7528\u614c\uff0c\u8001\u5e08\u5728\u4e0a\u8bfe\u7684\u65f6\u5019\u5df2\u7ecf\u6559\u4f1a\u6211\u4eec\u8981\u5982\u4f55\u5904\u7406\u8fd9\u4e9b\u7f3a\u5931\u7684\u6570\u636e\n\n\u4e0d\u8bb0\u5f97\u7684\u8bdd\u53ef\u4ee5\u56de\u53bbb\u7ad9\u770b\u56de\u653e\u54e6~"}}