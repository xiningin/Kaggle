{"cell_type":{"a0ca8847":"code","3844e4bb":"code","f8b21059":"code","8cefc700":"code","e8eb9459":"code","1fb17cca":"code","34a6dacf":"code","aa2a5e8c":"code","33e8b4be":"code","14b7bdc9":"code","57277f58":"code","9ff5ede5":"code","8e75d6bb":"markdown","044c60d4":"markdown","cf933935":"markdown","1565c1ef":"markdown","39963bf7":"markdown","52deea2b":"markdown","1823250a":"markdown","3c462418":"markdown","73849351":"markdown","ffb4de2a":"markdown","9ffc71ba":"markdown","3ad339d6":"markdown"},"source":{"a0ca8847":"import math, time, random, datetime\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3844e4bb":"data_file=\"\/kaggle\/input\/titanic\/train.csv\"\ntrain=pd.read_csv(data_file)\ndt=\"\/kaggle\/input\/titanic\/test.csv\"\ntest=pd.read_csv(dt)\n\n","f8b21059":"df_bin =pd.DataFrame()\ndf_con =pd.DataFrame()\ndf_bin['Survived'] = train['Survived']\ndf_con['Survived'] = train['Survived']\ndf_bin['Pclass'] = train['Pclass']\ndf_con['Pclass'] = train['Pclass']\ndf_bin['Sex'] = train['Sex']\ndf_bin['Sex'] = np.where(df_bin['Sex'] == 'female', 1, 0)\ndf_con['Sex'] = train['Sex']\ndf_bin['SibSp'] = train['SibSp']\ndf_con['SibSp'] = train['SibSp']\ndf_bin['Fare'] = pd.cut(train['Fare'], bins=5)#descritised\ndf_con['Fare'] = train['Fare']\ndf_bin['Embarked'] = train['Embarked']\ndf_con['Embarked'] = train['Embarked']\ndf_bin['Embarked']=np.where(df_bin['Embarked'] == 'S' ,1,0)\ndf_con = df_con.dropna(subset=['Embarked'])\ndf_bin = df_bin.dropna(subset=['Embarked'])\n","8cefc700":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\none_hot_cols = df_bin.columns.tolist()\none_hot_cols.remove('Survived')\ndf_bin_enc = pd.get_dummies(df_bin, columns=one_hot_cols)\n","e8eb9459":"df_con_enc  = df_con.apply(LabelEncoder().fit_transform)\nselected_df = df_con_enc\nX_train=selected_df.drop('Survived',axis=1)\ny_train=selected_df.Survived","1fb17cca":"def fit_ml_algo(algo, X_train, y_train, cv):\n    \n    model = algo.fit(X_train, y_train)\n    acc = round(model.score(X_train, y_train) * 100, 2)\n    #Cross validation\n    train_pred= model_selection.cross_val_predict(algo,\n                                                    X_train,\n                                                    y_train,\n                                                    cv=cv,\n                                                    n_jobs=-1)\n    #Cross validation accuracy matric\n    acc_cv = round(metrics.accuracy_score(y_train, train_pred)* 100, 2)\n    \n    return train_pred, acc, acc_cv","34a6dacf":"from numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBClassifier\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\nmodel = XGBClassifier(learning_rate=0.01,\n                      n_estimators=1150,\n                      max_depth=5,\n                      objective= 'binary:logistic',\n                      \n                     )\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv)\nmean(scores)*100","aa2a5e8c":"#Gradient Boost Tree\nstart_time = time.time()\ntrain_pred_log, acc_log, acc_cv_log = fit_ml_algo(XGBClassifier(),\n                                                  X_train,\n                                                  y_train,\n                                                        10)\nlog_time = (time.time()-start_time)\nprint(\"Accuracy : %s\"% acc_log)\nprint(\"Accuracy CV 10-Fold : %s\"% acc_cv_log)\nprint(\"Running Time: %s\" % datetime.timedelta(seconds=log_time))","33e8b4be":"test_embarked_one_hot = pd.get_dummies(test['Embarked'], \n                                       prefix='embarked')\n\ntest_sex_one_hot = pd.get_dummies(test['Sex'], \n                                prefix='sex')\n\ntest_plcass_one_hot = pd.get_dummies(test['Pclass'], \n                                   prefix='pclass')\ntest = pd.concat([test, \n                  test_embarked_one_hot, \n                  test_sex_one_hot, \n                  test_plcass_one_hot], axis=1)\n","14b7bdc9":"wanted_test_columns = X_train.columns","57277f58":"cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\nmodel = XGBClassifier(learning_rate=0.01,\n                      n_estimators=1150,\n                      max_depth=5,\n                      objective= 'binary:logistic',\n                      \n                     )\nmodel.fit(X_train, y_train)\npredictions = model.predict(test[wanted_test_columns]\n                                     .apply(LabelEncoder().fit_transform))\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\nmodel = XGBClassifier(learning_rate=0.01,\n                      n_estimators=1150,\n                      max_depth=5,\n                      objective= 'binary:logistic',\n                      \n                     )\nscores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv)\nmean(scores)*100\nmodel.fit(X_train,y_train)\npredictions = model.predict(test)\npredictions","9ff5ede5":"output = pd.DataFrame({'PassengerId': test['PassengerId'],'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"finish\")","8e75d6bb":"# Use oneHotEncoder to make the Data easy to read","044c60d4":"**we manuoilate the date for more clain and function dataframe**","cf933935":"# 1)Import Library","1565c1ef":"# 2)Import your Data","39963bf7":"# 3) MAnupilate the DataFrame ","52deea2b":"You can use (! pip install\"your library\" to install new package in kaggle","1823250a":"# Please if you like the nootebook give a vote","3c462418":"# Use the XGBoost Classifier","73849351":"# Use the Cross_Validation","ffb4de2a":"# Please Give a Vote","9ffc71ba":"# 4)Fiting ","3ad339d6":"# MAke your Submission"}}