{"cell_type":{"9a830ae5":"code","ac381197":"code","9d153922":"code","ff534c36":"markdown"},"source":{"9a830ae5":"!pip install ..\/input\/cassava-models\/Keras_Applications-1.0.8-py3-none-any.whl\n!pip install ..\/input\/cassava-models\/efficientnet-1.1.0-py3-none-any.whl\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom scipy import spatial\nfrom tqdm.notebook import tqdm","ac381197":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nEPOCHS = 12\nBATCH_SIZE = 8\nIMAGE_SIZE = [384, 384]\n# Seed\nSEED = 42\n# Learning rate\nLR = 0.001\n# Verbosity\nVERBOSE = 1","9d153922":"# Function to read and preprocess our data\ndef preprocess():\n    # Read train and test csv\n    train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n    test = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    # Drop duplicates images to avoid leakage (dont know if this is correct)\n    train.drop_duplicates(subset = ['image'], inplace = True)\n    train.reset_index(drop = True, inplace = True)\n    label_mapper = dict(zip(train['label_group'].unique(), np.arange(len(train['label_group'].unique()))))\n    label_mapper_inv = dict(zip(np.arange(len(train['label_group'].unique())), train['label_group'].unique()))\n    train['label_group'] = train['label_group'].map(label_mapper)\n    # Number of classes\n    N_CLASSES = train['label_group'].nunique()\n    return test, N_CLASSES\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image\n\n# Function to read our test image and return image\ndef read_image_test(image):\n    image = tf.io.read_file(image)\n    image = decode_image(image)\n    return image\n\ndef get_test_dataset(image):\n    dataset = tf.data.Dataset.from_tensor_slices(image)\n    dataset = dataset.map(read_image_test, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# Function to create our EfficientNetB0 model\ndef get_model():\n        \n    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3))\n    x = efn.EfficientNetB0(include_top = False, weights = None)(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n    output = tf.keras.layers.Dense(N_CLASSES, activation = 'softmax')(x)\n\n    model = tf.keras.models.Model(inputs = [inp], outputs = [output])\n\n    opt = tf.keras.optimizers.Adam(learning_rate = LR)\n\n    model.compile(\n        optimizer = opt,\n        loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n    )\n\n    return model\n\ndef inference(test):\n    print('\\n')\n    print('-'*50)\n    model = get_model()\n    model.load_weights('..\/input\/shopee-baseline-model\/EfficientNetB0_384_42.h5')\n    model = tf.keras.models.Model(inputs = model.input, outputs = model.layers[-2].output)\n    \n    test_image = '..\/input\/shopee-product-matching\/test_images\/' + test['image']\n    test_dataset = get_test_dataset(test_image)\n    # Predict the test images and get embeddings\n    embeddings = model.predict(test_dataset)\n\n    # Iterate over each test image and use cosine distance to find similar images\n    predictions = []\n    for test_index in tqdm(range(embeddings.shape[0])):\n        distances = spatial.distance.cdist(\n            embeddings[np.newaxis, test_index, :], embeddings, 'cosine')[0]\n        # Only get small distances\n        TOP = len(distances[distances <= 0.11])\n        top_k = list(np.argsort(distances)[:TOP])\n        predictions.append(' '.join(test['posting_id'].iloc[top_k].values))\n        \n    submission = pd.DataFrame({'posting_id' :test['posting_id'], 'matches': predictions})\n    return submission\n    \ntest, N_CLASSES = preprocess()\nsubmission = inference(test)\n# Save predictions\nsubmission.to_csv('submission.csv', index = False)\nsubmission.head()","ff534c36":"# Comments\n\nThe task of this competition is to identify which products have been posted repeatedly. In other words, for each observation on the test set, we need to find the products that are the same which are also part of the test set. On the previous version I thought that the group labels of the test set were different from the train set, that is not true, they are the same.\n\nSome public scripts just use the test set data to make predictions (for example if two or more observations have the same title, they are the same product). In this script we are going to use the image data to train a classifier to predict the label_group columns, then we are going to use the last embedding layer to predict each test image. With the predicted embedding matrix we are going to calculate the cosine distance between the images.\n\nYou could also include the text data into this model to make it even better.\n\nTraining notebook can be found here: https:\/\/www.kaggle.com\/ragnar123\/shopee-training-baseline"}}