{"cell_type":{"4eb54c21":"code","033bd9a7":"code","a007ed4a":"code","ce641092":"code","33af91da":"code","288ab9be":"code","cbf8c6f6":"code","aaf989de":"markdown","ab310b41":"markdown"},"source":{"4eb54c21":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import KBinsDiscretizer\nimport lightgbm\nimport optuna\n\nRANDOM_STATE = 42  # random state\nN_FOLD = 5       # number of fold for CV\nN_BINS = 10      # number of bins for target discretization\n","033bd9a7":"# Load data\ndf_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-aug-2021\/test.csv\")\n# add fold column\ndf_train[\"fold\"] = -1\ndf_train.drop(columns=\"id\", inplace=True)\ndf_train.head()","a007ed4a":"# Target discretization (try to use different strategies e.g.: quantile, kmeans)\ntarget = df_train.loss.values.reshape(-1,1)\nkbins = KBinsDiscretizer(n_bins=N_BINS, encode=\"ordinal\", strategy=\"uniform\")\ntarget_discrete = kbins.fit_transform(target)","ce641092":"# Create folds\nskf = StratifiedKFold(N_FOLD, shuffle=True, random_state=RANDOM_STATE)\n\nfor k, (train_index, test_index) in enumerate(skf.split(np.zeros(len(target)), target_discrete)):\n    df_train.loc[test_index, \"fold\"] = k\n\n# convert fold to int\ndf_train[\"fold\"] = df_train[\"fold\"].astype(np.int32)\ndf_train.head()","33af91da":"def objective(trial, write_submission=False):\n    rmse_list = []\n\n    if write_submission:\n        classifier_list = []\n\n    train_col = set(df_train.columns).difference([\"id\", \"loss\", \"fold\"])\n\n    params = {\n        \"reg_alpha\" : trial.suggest_loguniform(\"reg_alpha\" , 1e-2 , 1),\n        \"reg_lambda\" : trial.suggest_loguniform(\"reg_lambda\" , 1e-2 , 1),\n        \"num_leaves\" : trial.suggest_int(\"num_leaves\" , 40 , 200),\n        \"learning_rate\" : trial.suggest_float(\"learning_rate\" , 0.1 , 0.2),\n        \"max_depth\" : trial.suggest_int(\"max_depth\" , 3 , 4),\n        \"n_estimators\" : trial.suggest_int(\"n_estimators\" , 200 ,1000),\n        \"min_child_samples\" : trial.suggest_int(\"min_child_samples\" , 10 , 100),\n        \"min_child_weight\" : trial.suggest_loguniform(\"min_child_weight\" , 1e-5 , 1),\n        \"subsample\" : trial.suggest_float(\"subsample\" , 0.05 , 1.0),\n        \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\" , 0.05 , 0.1),\n        \"random_state\": RANDOM_STATE\n    }\n\n    for k in range(N_FOLD):\n        # get train\/val index\n        train_index = df_train[\"fold\"] != k\n        val_index = df_train[\"fold\"] == k\n\n        # Compute train\/val dataset\n        X_train = df_train.loc[train_index, train_col].values\n        y_train = df_train.loc[train_index, \"loss\"].values\n\n        X_val = df_train.loc[val_index, train_col].values\n        y_val = df_train.loc[val_index, \"loss\"].values\n\n        \n        # ===================================\n        lgbm = lightgbm.LGBMRegressor(**params)\n        lgbm.fit(X_train, y_train, eval_set=[(X_val,y_val)], eval_metric=\"rmse\", early_stopping_rounds=100, verbose=False)\n        # ====================================\n\n        best_rmse = lgbm.best_score_[\"valid_0\"][\"rmse\"]\n        rmse_list.append(best_rmse)\n    \n        if write_submission:\n            classifier_list.append(lgbm)\n            print(f\"fold {k}: rmse {rmse_list[-1]}\")\n\n    rmse_cv = np.mean(rmse_list)\n\n    if write_submission:\n        print(f\"Writing submission with rmse cv: {rmse_cv}\")\n        df_sub = pd.DataFrame()\n        df_sub[\"id\"] = df_test[\"id\"]\n\n        y_test = 0\n\n        for k in range(N_FOLD):\n            X_test = df_test.loc[:, train_col]\n            y_test += classifier_list[k].predict(X_test)\n\n        y_test \/= N_FOLD\n\n        df_sub[\"loss\"] = y_test\n\n        df_sub.to_csv(\"submission.csv\", float_format=\"%.12f\", index=False)\n\n    return rmse_cv","288ab9be":"# Optimize objective function with OPTUNA !\nsampler = optuna.samplers.TPESampler(seed=RANDOM_STATE)\nstudy = optuna.create_study(sampler=sampler, direction=\"minimize\")\nstudy.optimize(objective, n_trials=20)\n\n# Print best parameters\nbest_trial = study.best_trial\nprint(\"Best trial:\")\nprint(best_trial.params)","cbf8c6f6":"# Write submission file\nobjective(best_trial, write_submission=True)","aaf989de":"# Train LGBM","ab310b41":"# Split dataset for CV\n\nSplit the dataset using discretized target"}}