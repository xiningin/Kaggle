{"cell_type":{"8597f41e":"code","5887c373":"code","7e8b8f15":"code","f0bb7fec":"code","5bae1ad6":"code","145a0bb9":"code","83d0c37d":"code","bfcf068a":"code","067bfa4a":"code","7dbd6f67":"code","dce3dd3d":"code","727c58d8":"code","eeb46334":"code","6711056b":"code","16684549":"code","825cc361":"code","92abb3e7":"code","bedd3e6a":"code","db48808b":"code","bcbc6e4e":"code","0f38bb84":"code","33d7431a":"code","569d0eb0":"code","5b877b78":"code","e8ebfe13":"code","1581261a":"code","298cd174":"code","557e67d7":"code","bce5c9df":"code","e8fc2ff8":"code","11b9770b":"code","8e993329":"code","1f140eb9":"code","b1c46ce7":"code","2dabf2cf":"code","8be15dee":"code","ead97024":"code","72a7299b":"code","78d33226":"code","c38c700b":"markdown","a763b3bc":"markdown","565a611c":"markdown","39c20023":"markdown","a8453777":"markdown","092e1693":"markdown"},"source":{"8597f41e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5887c373":"train_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')\ntest_data_copy = pd.read_csv('..\/input\/test.csv')\nn_rows_train = train_data.shape[0]\nY_train = train_data.iloc[:,-1]\n#train_data = train_data.iloc[:,:-1]\n\na = train_data.append(test_data, sort=False)\n\n#total_data.drop(total_data[(total_data['OverallQual']<5) & (total_data['SalePrice']>200000)].index, inplace=True)\n#total_data.drop(total_data[(total_data['GrLivArea']>4000) & (total_data['SalePrice']<300000)].index, inplace=True)\n#total_data.reset_index(drop=True, inplace=True)\n\ntotal_data = a.copy(deep=True)\ntotal_data = total_data.drop(['Id','SalePrice'],axis=1)\ntotal_data.head()\nprint(test_data.shape)","7e8b8f15":"train_data.head()","f0bb7fec":"print(\"Size of dataset: \", train_data.shape[0])","5bae1ad6":"#correlation matrix\ncorrmat = train_data.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","145a0bb9":"# NOTE: we can draw scatter plots, it is  just for visualization of relation between different variables\nsns.set()\ncols = ['SalePrice','OverallQual', 'GrLivArea','TotalBsmtSF', 'FullBath','YearBuilt']\nsns.pairplot(train_data[cols], height=2.5)\nplt.show()","83d0c37d":"#Missing data treatment\ntotal_missing_values = total_data.isnull().sum().sort_values(ascending=False)\npercentage_missing_data = (100*(total_data.isnull().sum()\/total_data.isnull().count())).sort_values(ascending=False)\nmissing_data = pd.concat([total_missing_values, percentage_missing_data], axis=1, keys=['total_missing_values','percentage_missing_data'])\nmissing_data.head(20)","bfcf068a":"#missing value treatment\n#we can see some of the features which have high missing values are categorical, \n#so we will replce their missing value by \"None\" which represents NA category as given in variable description\ntotal_data[\"PoolQC\"] = total_data[\"PoolQC\"].fillna(\"None\") \ntotal_data[\"MiscFeature\"] = total_data[\"MiscFeature\"].fillna(\"None\") \ntotal_data[\"Alley\"] = total_data[\"Alley\"].fillna(\"None\") \ntotal_data[\"Fence\"] = total_data[\"Fence\"].fillna(\"None\")\ntotal_data[\"FireplaceQu\"] = total_data[\"FireplaceQu\"].fillna(\"None\") \n\n# LotFrontage is a continuous variable, so we replace missing values from houses of same neighborhood\n# and take their median\ntotal_data[\"LotFrontage\"] = total_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n\ntotal_data[\"GarageCond\"] = total_data[\"GarageCond\"].fillna(\"None\") \ntotal_data[\"GarageQual\"] = total_data[\"GarageQual\"].fillna(\"None\") \ntotal_data[\"GarageFinish\"] = total_data[\"GarageFinish\"].fillna(\"None\") \ntotal_data[\"GarageType\"] = total_data[\"GarageType\"].fillna(\"None\")\n\n# we have replaced garage variables by none i.e. they don't have garage, so we can replace numeric\n# variables of garage =0 \ntotal_data[\"GarageYrBlt\"] = total_data[\"GarageYrBlt\"].fillna(0)\ntotal_data[\"GarageCars\"] = total_data[\"GarageCars\"].fillna(0)\ntotal_data[\"GarageArea\"] = total_data[\"GarageArea\"].fillna(0)\n\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    total_data[col] = total_data[col].fillna(0)\n    \nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    total_data[col] = total_data[col].fillna('None')\n    \ntotal_data[\"MasVnrType\"] = total_data[\"MasVnrType\"].fillna(\"None\")\ntotal_data[\"MasVnrArea\"] = total_data[\"MasVnrArea\"].fillna(0)\n\n# MSZoning is categorical variable but doesn't have any NA category, so we replace missing values \n# by most occured value in that variable\ntotal_data['MSZoning'] = total_data['MSZoning'].fillna(total_data['MSZoning'].mode()[0])\ntotal_data['MSZoning'] = total_data['MSZoning'].fillna(total_data['MSZoning'].mode()[0])\n# NOTE: there are other variables which have 1or 2 missing values, they are very los, we can even drop \n# those obervations\n# this variable has same value for all observations except 3, so we drop it\ntotal_data = total_data.drop(['Utilities'], axis=1)\n\ntotal_data[\"Functional\"] = total_data[\"Functional\"].fillna(\"Typ\")\nfor col in ('KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType'):\n    total_data[col] = total_data[col].fillna(total_data[col].mode()[0])\ntotal_data['MSSubClass'] = total_data['MSSubClass'].fillna(\"None\")\n\ntotal_data['Electrical'] = total_data['Electrical'].fillna(total_data['Electrical'].mode()[0])\ntotal_data['YearsSinceRemodel'] = total_data['YrSold'].astype(int) - total_data['YearRemodAdd'].astype(int)","067bfa4a":"total_data['Total_sqr_footage'] = (total_data['BsmtFinSF1'] + total_data['BsmtFinSF2'] +\n                                 total_data['1stFlrSF'] + total_data['2ndFlrSF'])\n\ntotal_data['Total_Bathrooms'] = (total_data['FullBath'] + (0.5*total_data['HalfBath']) + \n                               total_data['BsmtFullBath'] + (0.5*total_data['BsmtHalfBath']))\n\ntotal_data['Total_porch_sf'] = (total_data['OpenPorchSF'] + total_data['3SsnPorch'] +\n                              total_data['EnclosedPorch'] + total_data['ScreenPorch'] +\n                             total_data['WoodDeckSF'])\n\n\n#simplified features\ntotal_data['haspool'] = total_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ntotal_data['has2ndfloor'] = total_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ntotal_data['hasgarage'] = total_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\ntotal_data['hasbsmt'] = total_data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ntotal_data['hasfireplace'] = total_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","7dbd6f67":"# converting some numericla variiables that really are categories\ntotal_data['MSSubClass'] = total_data['MSSubClass'].apply(str)","dce3dd3d":"sns.distplot(total_data['YrSold'], kde=False)","727c58d8":"total_data['YrSold'] = 2010 - total_data['YrSold']","eeb46334":"sns.boxplot(x = train_data['MoSold'],y= train_data['SalePrice'])","6711056b":"sns.distplot(total_data['MoSold'])","16684549":"# Monthes with the largest number of deals may be significant\ntotal_data['season'] = total_data.MoSold.replace( {1: 0, \n                                   2: 0, \n                                   3: 0, \n                                   4: 1,\n                                   5: 1, \n                                   6: 1,\n                                   7: 1,\n                                   8: 0,\n                                   9: 0,\n                                  10: 0,\n                                  11: 0,\n                                  12: 0})\n","825cc361":"\n# Lable Encoding OverallQual\ntotal_data = total_data.replace({'ExterQual':{'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'ExterCond':{'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'BsmtQual': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'BsmtCond': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'BsmtFinType1':{'NA':0,'None':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6}})\ntotal_data = total_data.replace({'BsmtFinType2':{'NA':0,'None':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6}})\ntotal_data = total_data.replace({'HeatingQC': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data= total_data.replace({'CentralAir':{'N':0, 'None':0,'Y':1}})\ntotal_data = total_data.replace({'KitchenQual': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'FireplaceQu': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'GarageQual': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'GarageCond': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'PoolQC': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'GarageFinish': {'NA':0,'None':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}})\ntotal_data = total_data.replace({'Fence':{'NA':0,\"None\":0, 'MnWv':1, 'GdWo':2, 'MnPrv':3, 'GdPrv':4}})\ntotal_data = total_data.replace({'LandSlope':{'None':0, 'Sev':1, 'Mod':2, 'Gtl':3}})\ntotal_data = total_data.replace({'Functional':{'None':0, 'Sal':1, 'Sev':2, 'Maj2':3, 'Maj1':4, 'Mod':5, 'Min2':6, 'Min1':7, 'Typ':8}})\n","92abb3e7":"total_data = total_data.fillna(0)","bedd3e6a":"print('Shape all_data: {}'.format(total_data.shape))","db48808b":"col = (total_data.dtypes[total_data.dtypes == \"object\"].index).tolist()","bcbc6e4e":"'''\nfor c in col:\n    total_data[c] = total_data[c].astype('category')\n    total_data[c] = total_data[c].cat.codes\n'''","0f38bb84":"train_data.head()","33d7431a":"train_data.loc[1,'Id']","569d0eb0":"n_row = np.shape(train_data)[0]\nmin = train_data.loc[1,'Id']\nfor x in range(n_row):\n        if min > train_data.loc[x,'Id']:\n            min = x","5b877b78":"min","e8ebfe13":"from scipy.stats import skew\n#reducing skewness of all features and target variable\nY_train1 = np.log1p(Y_train)\n\nn_rows_train = train_data.shape[0];\ntrain_data = total_data.iloc[:n_rows_train,:]\ntest_data = total_data.iloc[n_rows_train:,:]\n#finding numerical features\n\nfeatures = total_data.dtypes[total_data.dtypes != \"object\"].index\n\n#finding skewness of all variables\nskewed_feats = total_data[features].apply(lambda x: skew(x.dropna()))\n#adjusting features having skewness >0.5\nskewed_feats = skewed_feats[skewed_feats > 0.5]\nskewed_feats = skewed_feats.index\ntotal_data[skewed_feats] = np.log1p(total_data[skewed_feats])","1581261a":"# although we have applied norm distribution to all numeric variables, but here we will plot graph of\n# target variable only\n# NOTE: y axisis probability density estimates, # to get freq, use kde= False\nchart1, ax1 = plt.subplots()\nsns.distplot(Y_train, norm_hist=False,ax=ax1)\n#after applying logarithm, we get plot relatively simiar to norm distribution\nchart2, ax2 = plt.subplots()\nsns.distplot(Y_train1, norm_hist=False,ax=ax2)","298cd174":"\n# now converting categorical features to one hot encoding vectors\ntotal_data_oh = pd.get_dummies(total_data)\ntotal_data_oh.head()","557e67d7":"#split between X and test data\nX = total_data_oh.iloc[:n_rows_train,:]\ntest_data = total_data_oh.iloc[n_rows_train:,:]\nprint(X.shape)\ncol = X.columns\n#scaling the data\nscaler = RobustScaler()\nscaler = scaler.fit(X)\n\nX = scaler.transform(X)\ntest_data = scaler.transform(test_data)\n","bce5c9df":"X = pd.DataFrame(X, columns = col)\ntest_data = pd.DataFrame(test_data, columns = col)\nX.head()","e8fc2ff8":"'''\n#PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=200)\npca = pca.fit(X)\nprincipalComponents_train = pca.transform(X)\nprincipalComponents_test = pca.transform(test_data)\nX = pd.DataFrame(principalComponents_train)\ntest_data = pd.DataFrame(principalComponents_test)\n'''","11b9770b":"#  split X between training and testing set\nx_train, x_test, y_train, y_test = train_test_split(X,Y_train1, test_size=0.3, shuffle=True) \n\n\n# I have tried PCA code above, but the model is performing bad with it. So, I am not applying PCA.\n","8e993329":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\n'''\nCross-validation is a resampling procedure used to evaluate machine learning models on a limited \ndata sample. It is just used to check how this particular model will perform on different test sets. \nIt is not used to say whether this particuclar model is best or not.\nAt the end final predictions are made by model.fit and model.predict only.\n'''\n#Validation function\nn_folds = 5\n\ndef rmse_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X.values)\n    rmse= np.sqrt(-cross_val_score(model, X, Y_train1, scoring=\"neg_mean_squared_error\", cv = kf)) \n    # this computes rmse of each fold\n    return(rmse)","1f140eb9":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\ndef rmse(y_pred, y_test):\n    rmse = sqrt(mean_squared_error(y_test,y_pred))\n    return rmse","b1c46ce7":"from sklearn.linear_model import Lasso\nlasso = Lasso(alpha=0.0005, max_iter=10000)\nlasso.fit(X, Y_train1)\n#pred_lasso = lasso.predict(x_test)\n#print(rmse(pred_lasso,y_test))\n#print(rmse_cv(lasso).mean())","2dabf2cf":"from sklearn.linear_model import ElasticNet\nelastic_net_model = ElasticNet(alpha=0.0005, l1_ratio=.7, random_state=3)\nelastic_net_model.fit(X, Y_train1)\n#pred_elastic = elastic_net_model.predict(x_test)\n#print(rmse(pred_elastic,y_test))\n#print(rmse_cv(elastic_net_model).mean())","8be15dee":"#making predictions on test set\ny_pred_elastic_net_test_data = np.expm1(elastic_net_model.predict(test_data))\ny_pred_lasso_test_data = np.expm1(lasso.predict(test_data))","ead97024":"pred = 0.3*y_pred_elastic_net_test_data + 0.7*y_pred_lasso_test_data","72a7299b":"solution = pd.DataFrame({\"id\":test_data_copy.Id, \"SalePrice\":pred})\nsolution.to_csv(\"housing_pricefinal.csv\", index = False)","78d33226":"#y_pred_lasso_test_data","c38c700b":"Since YrSold lies between 2006 and 2010, we better include their difference from 2010 which might give us additional information.","a763b3bc":"Currently month solde variable has numeric values corresponding to each month in calendar. Taking this variable as it is will not give us valueable information because Dec-->12 which is largest numeric in that variable but has smallest sales","565a611c":"We can see that more number of deals happend in months number 4,5,6,7. So we now create a new binary variable representing this trend. ","39c20023":"models tried: XGBOOST, MLP","a8453777":"MoSold vs SalePrice is not giving us much insights about MoSold variable,so we now see distribution of MoSold","092e1693":"Categorical ordinal variables which actually have order are:\nOverallQual, OverallCond, ExterQual, ExterCond,BsmtQual, BsmtCond, BsmtFinType1, BsmtFinType2,HeatingQC, CentralAir\nKitchenQual, FireplaceQu, GarageFinish, GarageQual, GarageCond. PoolQC, Fence, Landslope, Functional\n\nTreating these categories with Label encoder instead of one hot encoder makes more sense.\nWe have to manually make a dictionary to assign values to each category, because Lable encoder might not give correct label to each category."}}