{"cell_type":{"ac67251e":"code","2ad3bb28":"code","a1dac0d8":"code","cc21085c":"code","17b88d73":"code","2227feb6":"code","d0040fc4":"code","8a54b529":"code","821d1112":"code","3fb792a5":"code","fe489777":"code","3ae90465":"code","2095cabe":"code","fca717d0":"code","b0c628bd":"code","61a2e9ac":"code","acf32e04":"code","a6e2b987":"code","637d1c6a":"code","8f1a1a66":"code","5633444f":"code","06aebae5":"code","04f8f1eb":"code","c2023805":"code","bfb13394":"code","5e022a71":"code","f090f1ac":"code","3f6ef730":"code","4e891672":"code","ed3e011e":"code","e7583d27":"code","2793d3d9":"code","b6cb9740":"code","626e03f1":"code","938a31d6":"code","a0cd949b":"code","8f42ab19":"code","10967b90":"code","8379fd4b":"code","b5e7e4a5":"code","ea860d05":"code","f119fe9a":"code","bbc8d1b2":"code","9b8126a9":"code","fdcc1ed0":"code","62033318":"code","f3b3ec5a":"code","3716e55f":"code","bf8610e4":"code","65cb373e":"code","11d64d39":"code","2699bc3f":"code","9768859b":"code","209381c7":"code","a0a93651":"code","f05ba794":"code","b9d5817d":"markdown","f56a7b70":"markdown","1c02e293":"markdown","75c67997":"markdown","5c25b9d7":"markdown","8a65b8e7":"markdown","5c58a6b8":"markdown","2ea54510":"markdown","5a5f9a0a":"markdown","f37b9541":"markdown","1d7118ee":"markdown","1dc3a464":"markdown","3631f684":"markdown","dd0ce55e":"markdown"},"source":{"ac67251e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, OneHotEncoder\nfrom sklearn.cluster import KMeans\nimport datetime as dtm\nimport missingno\nimport holidays\nfrom collections import Counter","2ad3bb28":"raw_data1 = pd.read_csv(\"..\/input\/train.csv\")\nraw_data2 = pd.read_csv(\"..\/input\/test.csv\")\nraw_data2[\"revenue\"] = 0\nraw_data1[\"train_test\"] = \"train\"\nraw_data2[\"train_test\"] = \"test\"\nraw_data = pd.concat([raw_data1, raw_data2],ignore_index=True)\ninput_Data = pd.DataFrame(raw_data)\ninput_Data[\"release_date_mod\"] = pd.to_datetime(input_Data[\"release_date\"], format=\"%m\/%d\/%y\")\ninput_Data[\"identifier\"] = input_Data[\"id\"]\ninput_Data = input_Data.drop([\"id\",\"homepage\", \"imdb_id\", \"original_title\", \"overview\", \"poster_path\", \"tagline\", \"title\"],axis = 1)","a1dac0d8":"#### Columns with dictionaries are originally read as string. Converting them in to dictionary\ncolumns_with_dictionaries = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\nfor cols in columns_with_dictionaries:\n    input_Data[cols] = input_Data[cols].apply(lambda x: {} if pd.isna(x) else eval(x))","cc21085c":"missingno.bar(raw_data1,figsize=(15,6))","17b88d73":"missingno.bar(raw_data2,figsize=(15,6))","2227feb6":"#### Indicator if the movie belongs to a certain collection or series\n\ninput_Data[\"collection\"] = input_Data[\"belongs_to_collection\"].apply(lambda x: 0 if len(x) == 0 else 1)\ninput_Data = input_Data.drop(\"belongs_to_collection\", axis = 1)","d0040fc4":"#### Checking if movies belonging to collection have higher average revenue as compared to non collection movies. \n#### The difference is clearly visible\n\nsns.barplot(x = \"collection\", y = \"revenue\",estimator=np.mean, data=input_Data)\nplt.show()","8a54b529":"input_Data[\"genre_extract\"] = input_Data[\"genres\"].apply(lambda x: [\"genre na\"] if len(x) == 0 else [i[\"name\"] for i in x])\ninput_Data[\"genre_count\"] = input_Data[\"genre_extract\"].apply(lambda x: 0 if \"genre na\" in x else len(x))","821d1112":"plt.figure(figsize=(15,4))\nplt.subplot(1,2,1)\nsns.countplot(\"genre_count\",data=input_Data)\nplt.subplot(1,2,2)\nsns.barplot(x = \"genre_count\",y = \"revenue\",data=input_Data)\nplt.show()","3fb792a5":"#### Converting the list of values to columns\nmlb = MultiLabelBinarizer()\ninput_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"genre_extract\"]),columns=mlb.classes_, index=input_Data.index))","fe489777":"#### deleting original variables which are not required\ninput_Data = input_Data.drop([\"genres\",\"genre_extract\"], axis = 1)","3ae90465":"sum(input_Data[\"release_date_mod\"].isnull())","2095cabe":"#### There was 1 movie with no release date. Googled and filled the actual release date.\ndtval = pd.to_datetime('01-05-2005', format= '%d-%m-%Y')\ninput_Data.loc[3828,\"release_date_mod\"] = dtval ","fca717d0":"#### Generating other variables using Date\ninput_Data[\"year\"] = input_Data[\"release_date_mod\"].dt.year\ninput_Data[\"month\"] = input_Data[\"release_date_mod\"].dt.month\ninput_Data[\"day\"] = input_Data[\"release_date_mod\"].dt.day\ninput_Data[\"year\"] = input_Data[\"year\"].apply(lambda x: x-100 if x>2019 else x)\ninput_Data[\"release_date_mod\"] = pd.to_datetime(input_Data[['year','month','day']])\ninput_Data[\"day_of_week\"] = input_Data[\"release_date_mod\"].dt.weekday_name\ninput_Data[\"week_of_year\"] = input_Data[\"release_date_mod\"].dt.weekofyear","b0c628bd":"input_Data = pd.concat([input_Data,pd.get_dummies(input_Data[\"day_of_week\"])],axis = 1)\ninput_Data = input_Data.drop(\"day_of_week\",axis=1)","61a2e9ac":"#### Understanding if the release date was a holiday\ninput_Data[\"holiday1\"] = 0\nCountries = ['AR','AU','AT','BY','BE','BR','BG','CA','CO','HR','CZ','DK','FI','FRA','DE','HU','IND','IE','IT','JP','LT','LU','MX','NL','NZ','NO','PL','PT','PTE','RU','SI','SK','ZA','ES','SE','CH','UA','UK','US']\nfor i in range(len(Countries)):\n    for j in range(len(input_Data)):\n        try:\n            if input_Data.loc[j,\"holiday1\"] == 1:\n                continue\n            elif input_Data.loc[j,\"release_date_mod\"] in holidays.CountryHoliday(Countries[i]):\n                input_Data.loc[j,\"holiday1\"] = 1\n                continue\n            else:\n                continue\n        except:\n            continue","acf32e04":"input_Data = input_Data.drop([\"release_date\", \"release_date_mod\"], axis = 1)","a6e2b987":"budget = pd.DataFrame(input_Data[[\"identifier\",\"year\",\"budget\"]])","637d1c6a":"cluster = budget[\"budget\"].values.reshape(-1,1)","8f1a1a66":"score = []\nfor i in range(1,20):\n    model = KMeans(n_clusters=i)\n    model.fit(cluster)\n    score.append(model.inertia_)","5633444f":"plt.plot(score,marker = \".\")\nplt.xticks(range(0,19,1))\nplt.annotate(\"# of clusters\", xy =(3,1000000000000000000), xytext = (7.5,5000000000000000000), arrowprops = dict(facecolor = \"black\"))\nplt.show()","06aebae5":"check = pd.pivot_table(budget, index=\"year\", values=\"budget\", aggfunc=\"mean\").reset_index()","04f8f1eb":"plt.figure(figsize=(15,6))\nsns.barplot(x = \"year\", y = \"budget\", data=check)\nplt.xticks(rotation = 90)\nplt.show()\ndel check","c2023805":"budget[\"year_category\"] = budget[\"year\"].apply(lambda x: \"Before 1955\" if x<=1955 else (\"1955 to 1990\" if x<= 1990 else \"Post 1990\"))","bfb13394":"avg_bud = pd.pivot_table(budget[budget[\"year\"] != 1927], index=\"year_category\", values=\"budget\", aggfunc=\"mean\").reset_index()","5e022a71":"avg_bud","f090f1ac":"budget = pd.merge(budget, avg_bud, on=\"year_category\", how=\"left\")\nbudget[\"Modified_budget\"] = budget[[\"budget_x\", \"budget_y\"]].apply(lambda x: x[1] if x[0] == 0 else x[0], axis = 1) ","3f6ef730":"input_Data = pd.merge(input_Data, budget[[\"identifier\", \"Modified_budget\"]], on=\"identifier\", how=\"left\")","4e891672":"input_Data = input_Data.drop(\"budget\", axis = 1)\ndel budget\ndel avg_bud\ndel cluster\ndel score\ndel model","ed3e011e":"input_Data[\"language_extract\"] = input_Data[[\"original_language\",\"spoken_languages\"]].apply(lambda x: [x[0]] if len(x[1]) == 0 else [i[\"iso_639_1\"] for i in x[1]], axis = 1)\ninput_Data[\"language_coverage\"] = input_Data[\"language_extract\"].apply(lambda x: len(x))","e7583d27":"sns.countplot(\"language_coverage\", data = input_Data)\nplt.show()","2793d3d9":"mlb = MultiLabelBinarizer()\ninput_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"language_extract\"]), index = input_Data.index, columns = mlb.classes_))","b6cb9740":"input_Data = input_Data.drop([\"language_extract\",\"spoken_languages\"], axis = 1)","626e03f1":"input_Data[\"country_extract\"] = input_Data[\"production_countries\"].apply(lambda x: [\"country na\"] if len(x) == 0 else [i[\"name\"] for i in x])\ninput_Data[\"country_coverage\"] = input_Data[\"country_extract\"].apply(lambda x: 0 if 'country na' in x else len(x))","938a31d6":"sns.countplot(\"country_coverage\", data=input_Data)\nplt.show()","a0cd949b":"#mlb = MultiLabelBinarizer()\n#language_check = input_Data[[\"year\", \"original_language\"]].join(pd.DataFrame(mlb.fit_transform(input_Data[\"Country_extract\"]), columns = mlb.classes_))\n#language_check_inter = language_check.groupby([\"year\", \"original_language\"]).sum().reset_index()\n#language_check_inter = language_check_inter.melt(id_vars=[\"year\", \"original_language\"], var_name=\"Country\")\n#language_check_inter = language_check_inter[language_check_inter[\"value\"] != 0]\n#language_check_inter = language_check_inter.sort_values([\"year\",\"original_language\",\"value\"], ascending = False).drop_duplicates([\"year\", \"original_language\"])","8f42ab19":"#input_Data = pd.merge(input_Data, language_check_inter[[\"year\", \"original_language\", \"Country\"]], on=[\"year\", \"original_language\"], how=\"left\")\n#input_Data[\"Country_extract_mod\"] = input_Data[[\"Country_extract\", \"Country\"]].apply(lambda x:  [x[1]] if \"Not Available\" in x[0] else x[0], axis = 1)\n#input_Data.at[1757,\"Country_extract_mod\"] = [\"Vietnam\"]\n#input_Data.at[2342,\"Country_extract_mod\"] = [\"Turkey\"]\n#input_Data.at[3939,\"Country_extract_mod\"] = [\"Germany\"]\n#input_Data.at[5526,\"Country_extract_mod\"] = [\"UnitedArabEmirates\"]\n#input_Data.at[6153,\"Country_extract_mod\"] = [\"Turkey\"]\n#input_Data[\"Country_coverage\"] = input_Data[\"Country_coverage\"].apply(lambda x: 1 if x == 0 else x)","10967b90":"#sns.countplot(\"Country_coverage\", data=input_Data)\n#plt.show()","8379fd4b":"mlb = MultiLabelBinarizer()\ninput_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"country_extract\"]), index = input_Data.index, columns = mlb.classes_))\ninput_Data = input_Data.drop([\"country_extract\",\"production_countries\"],axis = 1)","b5e7e4a5":"np.isnan(input_Data[\"runtime\"]).sum()","ea860d05":"yearly_runtime = input_Data[np.isnan(input_Data[\"runtime\"]) == False][[\"year\",\"runtime\"]]\nyearly_runtime = pd.pivot_table(yearly_runtime, index=\"year\", values=\"runtime\", aggfunc=\"mean\").reset_index()","f119fe9a":"plt.figure(figsize=(15,6))\nsns.barplot(x=\"year\",y = \"runtime\", data = yearly_runtime)\nplt.xticks(rotation = 90)\nplt.show()\ndel yearly_runtime","bbc8d1b2":"input_Data[\"runtime\"] = input_Data[\"runtime\"].fillna(np.mean(input_Data[\"runtime\"]))","9b8126a9":"input_Data[\"prod_house_extract\"] = input_Data[\"production_companies\"].apply(lambda x: \"prod house na\" if len(x) == 0 else [i[\"name\"] for i in x])\ninput_Data[\"prod_house_coverage\"] = input_Data[\"prod_house_extract\"].apply(lambda x: 0 if 'prod house na' in x else len(x))","fdcc1ed0":"mlb = MultiLabelBinarizer()\ninput_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"prod_house_extract\"]),columns=mlb.classes_, index = input_Data.index))\ninput_Data = input_Data.drop([\"prod_house_extract\",\"production_companies\"], axis = 1)","62033318":"input_Data[\"crew_count\"] = input_Data.crew.apply(len)","f3b3ec5a":"crew_check = pd.pivot_table(input_Data, index=\"year\", values=\"crew_count\", aggfunc=\"mean\").reset_index()\nplt.figure(figsize=(15,6))\nsns.barplot(\"year\", \"crew_count\",data = crew_check)\nplt.xticks(rotation = 90)\nplt.show()","3716e55f":"input_Data[\"crew_count\"] = input_Data[\"crew_count\"].fillna(input_Data[\"crew_count\"].mean())","bf8610e4":"def get_crew(x,crew):\n    crew_ret = []\n    if crew == \"director\":\n        if pd.isnull(x) == True:\n            crew_ret.append(\"director not known\")\n        else:\n            for i,name in enumerate(re.split(\"}\",x)):\n                if len(re.findall(r\"Director'.*,\",str(name))) != 0:\n                    crew_ret.append(re.sub(r\"[',\\s\\\"\\]-]\",\"\",re.split(\":\",str(re.findall(r\"Director'.*,\",name)))[1]))\n                else:\n                    continue\n        if len(crew_ret) == 0:\n            crew_ret.append(\"No Director\")\n    else:\n        if pd.isnull(x) == True:\n            crew_ret.append(\"producer not known\")\n        else:\n            for i,name in enumerate(re.split(\"}\",x)):\n                if len(re.findall(r\"Producer'.*,\",str(name))) != 0:\n                    crew_ret.append(re.sub(r\"[',\\s\\\"\\]-]\",\"\",re.split(\":\",str(re.findall(r\"Producer'.*,\",name)))[1]))\n                else:\n                    continue\n        if len(crew_ret) == 0:\n            crew_ret.append(\"No Producer\")\n    return crew_ret","65cb373e":"#input_Data[\"Directors\"] = input_Data[\"crew\"].apply(get_crew,crew = \"director\")\n#input_Data[\"Producers\"] = input_Data[\"crew\"].apply(get_crew,crew = \"producer\")","11d64d39":"#mlb = MultiLabelBinarizer()\n#input_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"Directors\"]),columns=mlb.classes_+\"_director\", index = input_Data.index))\n#input_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"Producers\"]),columns=mlb.classes_+\"_producer\", index = input_Data.index))\n#input_Data = input_Data.drop([\"Directors\",\"Producers\",\"crew\"],axis = 1)","2699bc3f":"input_Data = input_Data.drop(\"crew\",axis = 1)","9768859b":"input_Data[\"cast_count\"] = input_Data.cast.apply(len)","209381c7":"crew_check = pd.pivot_table(input_Data, index=\"year\", values=\"cast_count\", aggfunc=\"mean\").reset_index()\nplt.figure(figsize=(15,6))\nsns.barplot(\"year\", \"cast_count\",data = crew_check)\nplt.xticks(rotation = 90)\nplt.show()","a0a93651":"input_Data[\"cast_count\"] = input_Data[\"cast_count\"].fillna(input_Data[\"cast_count\"].mean())","f05ba794":"input_Data = input_Data.drop(\"cast\",axis = 1)","b9d5817d":"#### Handling Budget","f56a7b70":"#### Handling Cast","1c02e293":"#### Handling Crew\n- First finding the crew count\n- Second handling crew director\n- Third handling crew producer","75c67997":"# First Dataset for model development\n\n1. All the variables explored in their raw state with the following exceptions made:\n    - Target variable is log transformed\n    - In case of spoken language is blank, original language is used for imputation\n    - For continuous variables like budget, runtime etc, cluster and mean imputations are done\n2. Following needs to be explored\n    - Cast and crew names not explored till now. Information on cast and crew gender is not understood\n    - Different categories can be grouped on the basis of exploratory data analysis\n    - Transformation of Continuous variables depending upon their distributions\n    - hyperparameter tuning to get the best model results\n    - Feature engineering to see if any additional features can help in improving the predictions","5c25b9d7":"#### Understanding Missing Values","8a65b8e7":"# Exploratory data analysis - Univariate Analysis","5c58a6b8":"#### Understanding Belongs_to_collection variable","2ea54510":"#### Understanding Release Date","5a5f9a0a":"#### Handling spoken Languages","f37b9541":"#### Handling Production Houses","1d7118ee":"#### Understanding Genres","1dc3a464":"#### Handling runtime null values","3631f684":"#### Handling Production Countries","dd0ce55e":"#### Importing the raw data and Initial data exploration"}}