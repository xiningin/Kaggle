{"cell_type":{"9d8c1c8c":"code","cc9bbe85":"code","d476b7ea":"code","490d420e":"code","9e6a9c54":"code","35b1e50f":"code","5d4c5bda":"code","e22e5aaf":"code","5a0cd30b":"markdown","9b580ca5":"markdown","1ff8cf4e":"markdown","eb0c4d05":"markdown","47ece09c":"markdown","d4940248":"markdown","0ecc7baf":"markdown"},"source":{"9d8c1c8c":"# !pip install matplotlib\nimport torch\nimport torchvision\nfrom torchvision.datasets import MNIST\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nfrom torch.utils.data import random_split, DataLoader\nimport torch.nn.functional as F\n%matplotlib inline","cc9bbe85":"dataset = MNIST(root='data\/', download=True)\ntest = MNIST(root='data\/', train=False)\n### Checking the dataset\n\nimage, label = dataset[0]\nplt.imshow(image, cmap='gray')\nprint(\"Label\", label)","d476b7ea":"dataset = MNIST(root='data\/', train=True, transform=transforms.ToTensor())\n## Checking Dataset shape\nimage, label = dataset[0]\nprint(image.shape, label,\" ## 1 Channel length, 28*28 pixel image\")\n\n## Splitting the dataset\ntrain, valid = random_split(dataset, [50000, 10000])\n\n## Dataloader for loading train and valid data\nbatch_size = 128\ntrainLoader = DataLoader(train, batch_size, shuffle=True)\nvalidLoader = DataLoader(valid, batch_size)","490d420e":"## Losses with Cross Entropy\nloss_fn = F.cross_entropy\n\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds==labels).item()\/ len(preds))","9e6a9c54":"import torch.nn as nn\n\ninput_size = 28*28\nclasses = 10\n\nclass MnistModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, classes)\n    def forward(self, xb):\n        xb = xb.reshape(-1, 28*28)\n        out = self.linear(xb)\n        return out\n    def training_step(self, batch):\n        images, labels = batch\n        outputs = self(images) \n        loss = loss_fn(outputs, labels)\n        return loss\n    def valid_step(self, batch):\n        images, labels = batch\n        outputs = self(images)\n        loss = loss_fn(outputs, labels)\n        acc = accuracy(outputs, labels)\n        return {\"val_loss\":loss, \"val_acc\":acc}\n    def valid_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n    \nmodel = MnistModel()\n## Some Stats of the model\nprint(model.linear.weight.shape, model.linear.bias.shape)\nprint(list(model.parameters()))\n","35b1e50f":"## Evaluation\ndef evaluate_model(model, valid_loader):\n    result = [model.valid_step(batch) for batch in valid_loader]\n    return model.valid_epoch_end(result)\n\nhistory = []\n### Fitting data\ndef fit(epochs, model,train_loader, valid_loader, lr, opt_func = torch.optim.SGD):\n    historry = []\n    ## Defining optimizer\n    optimizer = opt_func(model.parameters(), lr)\n    for i in range(epochs):\n        ## Training\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        result = evaluate_model(model, valid_loader)\n        model.epoch_end(epochs, result)\n        history.append(result)\n    return history\n        ","5d4c5bda":"## Fitting\nhistory1 = fit(5, model, trainLoader, validLoader, 0.001)","e22e5aaf":"### Plotting Graph\nhistory = history1 #+ history2 + history3 + history4\naccuracies = [result['val_acc'] for result in history]\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs')","5a0cd30b":"## Functions for MNIST model","9b580ca5":"### Function for training and evaluation","1ff8cf4e":"## Logistic Regression for Image Classification","eb0c4d05":"### Preparing MNIST logistic regression model","47ece09c":"### Importing Modules","d4940248":"### Loading Dataset from MNIST","0ecc7baf":"### Taking the dataset as a pytorch tensor for further training"}}