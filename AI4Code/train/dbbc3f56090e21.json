{"cell_type":{"7c46a0d6":"code","0f55be5a":"code","70d1b3a2":"code","a3443a56":"code","b60f9b62":"code","2d35b3b3":"code","39ad897d":"code","dda5dee7":"code","b515d029":"code","3779b544":"code","9a7ddd61":"code","87d1bc4b":"code","1a8e8a20":"code","b6c9ffd9":"code","9b37f9a7":"code","5b04f3aa":"code","808f8426":"code","36e6dad3":"code","f0a3c3b6":"code","7d1b5959":"code","029fc872":"code","38b1dfd2":"code","f3273074":"code","9311c4e6":"code","cefd8da1":"code","bee4c4cd":"code","8014912b":"code","f26f407c":"code","b05402d3":"code","f30f063c":"code","d7dbc431":"code","0f50c15d":"code","c9e0c2a4":"markdown","701abef0":"markdown","2a652bf9":"markdown","1f3da002":"markdown","62804283":"markdown","a0614334":"markdown","c1bdc4ab":"markdown","61394def":"markdown","ac830dce":"markdown","5f2fe00e":"markdown","174d7813":"markdown","3346f0ea":"markdown","71506770":"markdown","9e1dc0bd":"markdown"},"source":{"7c46a0d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0f55be5a":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\n%matplotlib inline\nimport random\nimport re\n\n# Geovisualization library\nimport folium\nfrom folium.plugins import CirclePattern, HeatMap\n","70d1b3a2":"data = pd.read_csv(\"..\/input\/zomato-indore-data\/zomato_indore.csv\")","a3443a56":"data.shape","b60f9b62":"#dropping the unnamed column\ndata = data.drop(['Unnamed: 0'],axis=1)","2d35b3b3":"data.head()","39ad897d":"data.describe()","dda5dee7":"#Checking for null\/missing values\ndata.isna().sum()","b515d029":"#Checking for unique rating text\ndata.groupby('rating_text').size()","3779b544":"#Isolating the aggregate_rating & rating_text column\ndata_rating = pd.DataFrame(data, columns=['aggregate_rating','rating_text'])\n#checking the newly created dataframe\ndata_rating.head()","9a7ddd61":"#function to check the aggregate rating value for every type of rating\ndef rating_check():\n  for x, y in data_rating.itertuples(index=False):\n    std_rating = ['Average','Excellent', 'Good', 'Poor', 'Very Good']   #list of standard rating\n    if any(y in stdr for stdr in std_rating):                           #checking if the value in rating column matches with that in the standard rating list\n      print(y , \">>>\", x)\n    else:\n      print(y, \">>>\", \"unknown rating\") \n\n#calling the function\nrating_check()","87d1bc4b":"#function to update the rating as per the aggregate rating\ndef upd_rating():\n  for x, y in data_rating.itertuples(index=False):\n    std_rating = ['Average','Excellent', 'Good', 'Poor', 'Very Good']\n    if any(y in stdr for stdr in std_rating):\n      continue\n    elif (0 <= x <= 2.4):\n      data_rating['rating_text'] = data_rating['rating_text'].replace(y,std_rating[3])\n    elif (2.5 <= x <= 3.4):\n      data_rating['rating_text'] = data_rating['rating_text'].replace(y,std_rating[0])     \n    elif (3.5 <= x <= 3.9):\n      data_rating['rating_text'] = data_rating['rating_text'].replace(y,std_rating[2])     \n    elif (4.0 <= x <= 4.4):\n      data_rating['rating_text'] = data_rating['rating_text'].replace(y,std_rating[4])\n    else:\n      data_rating['rating_text'] = data_rating['rating_text'].replace(y,std_rating[1]) \n\n#calling the function\nupd_rating()","1a8e8a20":"#checking if the replace function has worked\ndata_rating.groupby('rating_text').size()","b6c9ffd9":"#combining the two dataframes and creating a new  \ndata_clean = data_rating.combine_first(data)","9b37f9a7":"data_clean.head()","5b04f3aa":"#getting the list of columns from original dataset = data\ndata.columns","808f8426":"#rearranging the columns as per the original\ndata_clean = data_clean[['name', 'locality', 'latitude', 'longitude', 'cuisines',\n       'average_cost_for_two', 'aggregate_rating', 'votes', 'rating_text']]","36e6dad3":"data_clean.head()","f0a3c3b6":"#validating the rating_text column for the newly created dataframe\ndata_clean.groupby('rating_text').size()","7d1b5959":"#taking a backup\ndata_clean_backup = data_clean.copy()","029fc872":"#Cost vs Rating\nsns.set(style=\"darkgrid\")\nfig, ax = plt.subplots(figsize=(25,10))\nax = sns.swarmplot (x='average_cost_for_two', y='aggregate_rating', data=data_clean, hue = 'rating_text')\nplt.title('Average Costs for Two v\/s Aggregate Rating')\nplt.ylabel('Aggregate Rating')\nplt.xlabel('Average Costs for Two')","38b1dfd2":"sns.set(style=\"darkgrid\")\nfig = plt.figure()\nfig = sns.relplot(x=\"aggregate_rating\", y=\"votes\", kind=\"line\", hue=\"rating_text\",data=data_clean,height=15,aspect=1,palette=\"cubehelix\")\nfig.fig.set_size_inches(15,10)\nfig.set_titles(\"Votes Distribution Per Rating\")\nfig.set_xlabels(\"Aggregate Rating\")\nfig.set_ylabels(\"Total Votes\")\nplt.show()\n","f3273074":"#Function to generate base map\ndef BaseMap(default_location=[22.719568, 75.857727], default_zoom_start=12):   #the default location co-ordinates are of Indore\n    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start, width='50%', height='50%')\n    return base_map","9311c4e6":"base_map = BaseMap()\nbase_map","cefd8da1":"#creating a dataframe with condition#1\ncond1 = (data_clean['average_cost_for_two'] <= 500) & (data_clean['aggregate_rating'] >= 4.0)\ndf_cond1 = data_clean[cond1]\ndf_cond1['popup_text'] = df_cond1['name'] + \",\" + \"\u20b9\"+df_cond1['average_cost_for_two'].astype(str) + \",\" + df_cond1['rating_text']\ndf_cond1.head()","bee4c4cd":"#creating a dataframe with condition#2\ncond2 = (data_clean['average_cost_for_two'] >= 501) & (data_clean['average_cost_for_two'] <= 1500) & (data_clean['aggregate_rating'] >= 4.0)\ndf_cond2 = data_clean[cond2]\ndf_cond2['popup_text'] = df_cond2['name'] + \",\" + \"\u20b9\"+df_cond2['average_cost_for_two'].astype(str) + \",\" + df_cond2['rating_text']\ndf_cond2.head()","8014912b":"#creating a dataframe with condition#3\ncond3 = (data_clean['average_cost_for_two'] >= 1501) & (data_clean['average_cost_for_two'] <= 3000) & (data_clean['aggregate_rating'] >= 4.0)\ndf_cond3 = data_clean[cond3]\ndf_cond3['popup_text'] = df_cond3['name'] + \",\" + \"\u20b9\"+df_cond3['average_cost_for_two'].astype(str) + \",\" + df_cond3['rating_text']\ndf_cond3.head()","f26f407c":"#creating a dataframe with condition#4\ncond4 = (data_clean['average_cost_for_two'] >= 500) & (data_clean['average_cost_for_two'] <= 1000) & (data_clean['rating_text'].isin(['Average','Poor']))\ndf_cond4 = data_clean[cond4]\ndf_cond4['popup_text'] = df_cond4['name'] + \",\" + \"\u20b9\"+df_cond4['average_cost_for_two'].astype(str) + \",\" + df_cond4['rating_text']\ndf_cond4.head()","b05402d3":"\ndf_cond1.apply(lambda row:folium.CircleMarker(location=[row[\"latitude\"], row[\"longitude\"]], popup=row[\"popup_text\"]).add_to(base_map), axis=1)\nbase_map","f30f063c":"df_cond2.apply(lambda row:folium.CircleMarker(location=[row[\"latitude\"], row[\"longitude\"]], popup=row[\"popup_text\"]).add_to(base_map), axis=1)\nbase_map","d7dbc431":"df_cond3.apply(lambda row:folium.CircleMarker(location=[row[\"latitude\"], row[\"longitude\"]], popup=row[\"popup_text\"]).add_to(base_map), axis=1)\nbase_map","0f50c15d":"df_cond4.apply(lambda row:folium.CircleMarker(location=[row[\"latitude\"], row[\"longitude\"]], popup=row[\"popup_text\"]).add_to(base_map), axis=1)\nbase_map","c9e0c2a4":"**No missing or null values found**","701abef0":"# **Geo Visualisation**","2a652bf9":"# **Loading Dataset**","1f3da002":"**For Geo-Visualisation we'll create different dataframes with specific conditions:**\n\n**Note**: There can be multiple condition that can be thought of but for now I'm most interested in the following.\n\n*   Condition#1 -- cost <= 500 and rating = very good, excellent\n*   Condition#2 -- 501 <= cost <= 1500 and rating = very good & excellent\n*   Condition#3 -- 1501 <= cost <= 3000 and rating = very good & excellent\n*   Condition#4 -- 500 <= cost <= 1000 and rating = poor & average\n\n\n\n","62804283":"**As observed, there are some non standard rating text. Hence cleaning of the dataset is required.**","a0614334":"# **Importing Libraries**","c1bdc4ab":"**Plotting the above created Condition#1 dataframes on map**","61394def":"# **Geo Data Analysis of Zomato Indore Dataset**\n\nThank you @sakshi for uploading this dataset. In this notebook I have tried to analyse the Zomato data about eating places in Indore and their ratings. I have geo-visualized the data on the map of Indore.","ac830dce":"# **Dataset Exploration**","5f2fe00e":"# **Data Cleaning**","174d7813":"**Replacing the non-standard rating text with the standard**\n\nAs it is clear from the above dataset that the value in the 'rating_text' depends on the value in 'aggregate_rating' column\n\n","3346f0ea":"**Updating the rating as per the aggregate rating has worked. Now combining the two dataframes to create a new dataframe**","71506770":"**Eye-balling the above results we can determine that:**\n\n1.   aggregate rating between 0 - 2.4 has rating = poor\n2.   aggregate rating between 2.5 - 3.4 has rating = average\n3.   aggregate rating between 3.5 - 3.9 has rating = good\n4.   aggregate rating between 4 - 4.4 has rating = very good\n5.   aggregate rating >= 4.5 has rating = excellent\n\nCreating a function to update non-standard rating with this new-found relation between aggregate rating and rating","9e1dc0bd":"# **Data Visualisation**"}}