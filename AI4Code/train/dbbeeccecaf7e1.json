{"cell_type":{"0ae937b5":"code","b7a1554d":"code","00ee01cd":"code","4fff0c28":"code","b0d76a44":"code","97101c01":"code","1ebec630":"code","e327fb95":"code","d6992a82":"code","57c41425":"code","f70a061f":"code","684c9c23":"code","8d0ffd5a":"code","d4934704":"code","47a3c37c":"code","bad44cc9":"code","f3c1fe36":"code","e5daad28":"code","597ca74e":"code","35100f0c":"code","0be00936":"code","d959d0ba":"code","894da8cc":"code","6c55e187":"code","4d7f5144":"code","ed361066":"code","4713f9a8":"code","045806b1":"code","804d3336":"code","02f0b5aa":"code","3aa5b6a4":"code","6744bfb8":"markdown","710cf6a7":"markdown","66e7518d":"markdown","ea3564bd":"markdown","772b1c66":"markdown","bd24444b":"markdown","05ad72ae":"markdown","76ca94d2":"markdown","a518b0d7":"markdown","2497325f":"markdown","9d61459f":"markdown","d4d5ac38":"markdown","6225b7b4":"markdown"},"source":{"0ae937b5":"# Work with Data - the main Python libraries\nimport numpy as np\nimport pandas as pd\nfrom scipy.interpolate import Rbf, interp2d\nimport datetime\n\n# For import data\nimport os\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Modeling and Prediction\nfrom fbprophet import Prophet\nfrom sklearn.metrics import r2_score, mean_absolute_error\n\nimport warnings\nwarnings.simplefilter('ignore')","b7a1554d":"# Set parameters\nN = 15*24\nforecasting_period = 2  # hours\ntime_interval='H' # hour\nQ = 12  # Seasonality is less than a day, hours\nindicator_names = ['PM2.5', 'PM10']\nindicator_name = indicator_names[0]\ntype_agg='mean' # 'mean' or 'max'","00ee01cd":"#datetime_analysis = '2021-11-16 10:00:00'\ndatetime_analysis = '2021-11-27 09:00:00'  # maximum value after 2021-11-16\n#datetime_analysis = '2021-11-12 18:00:00'\n#datetime_analysis = '2021-01-23 18:00:00'  # maximum value","4fff0c28":"# Import files with data from Kaggle dataset\ndataset_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        dataset_files.append(os.path.join(dirname, filename))\ndataset_files","b0d76a44":"len(dataset_files)","97101c01":"# Data from SaveEcoBot\nstations_about = pd.read_csv('..\/input\/air-quality-monitoring\/saveecobot_city_about_stations.csv', header=0, sep=';')\nstations_about = stations_about[stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\nstations_about","1ebec630":"def get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    # Transform indicator to SaveEcoBot variants\n    if indicator_name=='PM2.5':\n        indicator_name = 'pm25'\n    elif indicator_name=='PM10':\n        indicator_name = 'pm10'\n    \n    # Get codes station\n    id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = stations_about.loc[num,'id_ecocity']\n    if not np.isnan(id_station_ecocity):\n        id_station_ecocity = int(id_station_ecocity)\n        id_station = \"EcoCity_\" + str(id_station_ecocity)\n    else: id_station = \"SaveEcoBot_\" + str(id_station_saveecobot)\n    #print(num, id_station_saveecobot, id_station_ecocity, id_station)\n        \n    df = pd.read_csv(f\"..\/input\/air-quality-monitoring\/data_saveecobot_{id_station_saveecobot}.csv\")\n    #display(df.head())\n    df = df[df['indicator_code']==indicator_name]\n    #display(df.head())\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    #df = df.dropna().reset_index(drop=True)\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    #display(df.head())\n    # Data processing - converting data to average or maximum values per given time_interval\n    #df = df.resample('H').mean()\n    if type_agg == 'mean':\n        df = df.resample(time_interval).mean()\n    else:\n        # type_agg == 'max'\n        df = df.resample(time_interval).max()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n\n    if df.shape[1] > 1:\n        # Resample is successfull\n        #display(df.head())\n        df['network'] = str(stations_about.loc[num,'network'])\n        df['id_station'] = id_station\n        df['lat'] = float(stations_about.loc[num,'lat'])\n        df['lng'] = float(stations_about.loc[num,'lng'])\n        print(f\"Number of data for {num}th station #{id_station} is {len(df)}\")\n        #display(df)\n        #print(df.info())   \n    else:\n        print(f\"Data for {num}th station #{id_station} is bad\")\n        df = pd.DataFrame()\n    return df","e327fb95":"%%time\ndf = pd.DataFrame()\nln = 0\nfor i in range(len(stations_about)):\n    df_i = get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, i)\n    #df_i.info()\n    if len(df) > 0:\n        #ln += len(df_i)\n        #print('\\n',ln)\n        df = pd.concat([df, df_i], ignore_index=True)\n    else: df = df_i\ndf = df.dropna().reset_index(drop=True)\ndf","d6992a82":"df.info()","57c41425":"# Data from SaveEcoBot\necocity_stations_about = pd.read_csv('..\/input\/air-quality-monitoring-from-ecocity\/ecocity_about_stations_2021.csv', header=0, sep=';')\necocity_stations_about","f70a061f":"ecocity_stations_about_region = ecocity_stations_about[ecocity_stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\necocity_stations_about_region['id_ecocity'] = ecocity_stations_about_region['id_ecocity'].astype('int')\necocity_stations_about_region","684c9c23":"def get_data_for_indicator_of_station_from_ecocity(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    #id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = int(stations_about.loc[num,'id_ecocity'])\n    \n    # Find file name\n    for i in range(len(dataset_files)):\n        if dataset_files[i].find(str(id_station_ecocity))>0:\n            file_name = dataset_files[i]\n    \n    df = pd.read_csv(file_name)\n    #display(df)\n    df = df[df['indicator_name']==indicator_name]\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    df = df.resample('H').mean()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n    df['network'] = str(stations_about.loc[num,'network'])\n    #df['id_station_ecocity'] = id_station_ecocity\n    df['id_station'] = \"EcoCity_\" + str(id_station_ecocity)\n    df['lat'] = float(stations_about.loc[num,'lat'])\n    df['lng'] = float(stations_about.loc[num,'lng'])\n    #print(f\"Number of data for {num}th station #{id_station_saveecobot} in SaveEcoBot and #{id_station_ecocity} in EcoCity is {len(df)}\")\n    #display(df)\n    return df","8d0ffd5a":"%%time\ndf2 = pd.DataFrame()\nfor i in range(len(ecocity_stations_about_region)):\n    df_i = get_data_for_indicator_of_station_from_ecocity(ecocity_stations_about_region, indicator_name, i)\n    if len(df2) > 0:\n        df2 = pd.concat([df2, df_i], ignore_index=True)\n    else: df2 = df_i\ndf2","d4934704":"df2.info()","47a3c37c":"# Drop data on stations of the EcoCity network from SaveEcoBot \n# with datetime which equal datetime of data from EcoCity\nif len(df)>0:\n    len_before = len(df)\n    for id_station in df2['id_station'].unique().tolist():\n        print(id_station)\n        ds_list = df2[df2['id_station']==id_station]['ds'].tolist()\n        df = df.drop(df[(df.id_station == id_station) & (df.ds.isin(ds_list))].index)\n    len_after = len(df)\n    print(f\"Number of data before the dropping duplicates - {len_before}, after - {len_after}\")","bad44cc9":"if len(df)>0:\n    df = pd.concat([df, df2], ignore_index=True)\nelse: df = df2\ndf","f3c1fe36":"df.info()","e5daad28":"df.describe()","597ca74e":"# Selection data for interpolation\nif type_agg == 'mean':\n    data = df[df['ds']==datetime.datetime.fromisoformat(datetime_analysis)].reset_index(drop=True)\nelse:\n    #type_agg == 'max':\n    datetime_analysis = 'all time'\n    data = df.copy()\n    \nx = data.lng.values\ny = data.lat.values\nz = data.value.values\nfig = plt.figure()\nplt.scatter(x, y)\nplt.title(f'Stations in Vinnytsia region with data for {indicator_name} in {datetime_analysis}')\ndisplay(data)\nplt.show()","35100f0c":"number_steps_in_day = 24 if time_interval=='H' else 1","0be00936":"def get_data_for_prediction(df, id_station_name, num_last_data=30):\n    # Get data for given id_station_name with the last num_last_data data\n    #id_station_name = 'EcoCity_848'\n    df_i = df[df['id_station']==id_station_name]\n    df_i = df_i[(len(df_i)-num_last_data):].reset_index(drop=True)\n    display(df_i['value'].describe())\n    print(len(df_i))\n    return df_i","d959d0ba":"def plot_with_anomalies(df, cols_y_list, cols_y_list_name, dates_x, anomalous_dates, log_y=False):\n    # Thanks to https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality\n    # Draws a plot with title - the features cols_y_list (y) and dates_x (x) from the dataframe df\n    # and with vertical lines in the dates from the list anomalous_dates\n    # with the length between the minimum and maximum of feature cols_y_list[0]\n    # with log_y = False or True\n    # cols_y_list - dictionary of the names of cols from cols_y_list (keys - name of feature, value - it's name for the plot legend), \n    # name of cols_y_list[0] is the title of the all plot\n    \n    fig = px.line(df, x=dates_x, y=cols_y_list[0], title=cols_y_list_name[cols_y_list[0]], log_y=log_y, template='gridon',width=800, height=600)\n    y_max = df[cols_y_list[0]].max()\n    for i in range(len(cols_y_list)-1):\n        fig.add_trace(go.Scatter(x=df[dates_x], y=df[cols_y_list[i+1]], mode='lines', name=cols_y_list_name[cols_y_list[i+1]]))\n        max_i = df[cols_y_list[i+1]].max()\n        y_max = max_i if max_i > y_max else y_max\n    \n    y_min = min(df[cols_y_list[0]].min(),0)\n    for i in range(len(anomalous_dates)):\n        anomal_date = anomalous_dates[i]\n        #print(anomal_date, y_min, y_max)\n        fig.add_shape(dict(type=\"line\", x0=anomal_date, y0=y_min, x1=anomal_date, y1=y_max, line=dict(color=\"red\", width=1)))\n    fig.show()","894da8cc":"def get_model_err(df, res, model, id_station_name, forecasting_period,\n                 Q_order, daily_order, weekly_order, quarterly_order):\n    # Data prediction and score calculation\n    \n    # Make a forecast\n    future = model.make_future_dataframe(periods = forecasting_period, freq=time_interval)\n    forecast = model.predict(future)\n        \n    # Ouput the prediction for the next time\n    forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(2)\n    y_pred = forecast['yhat'][:-forecasting_period]\n    \n    # Calculation r2_score (accuracy of prediction for training data)\n    r2 = round(r2_score(df['y'], y_pred),2)\n    mae_err = round(mean_absolute_error(df['y'], y_pred),2)\n    \n    # Save results\n    if res.empty:\n        num = 0\n    else: num = len(res)\n    res.loc[num, 'id_station'] = id_station_name\n    res.loc[num, 'Q_order'] = Q_order\n    res.loc[num, 'daily_order'] = daily_order\n    res.loc[num, 'weekly_order'] = weekly_order\n    res.loc[num, 'quarterly_order'] = quarterly_order\n    res.loc[num, 'r2_score'] = r2\n    res.loc[num, 'mae'] = mae_err\n    print(id_station_name, Q_order, daily_order, weekly_order, quarterly_order, r2, mae_err)\n    #display(res)\n    \n    # Draw plot of the values with forecasting data\n    #label_str = \" - \".join([id_station_name, indicator_name, str(Q_order), str(daily_order), str(weekly_order), str(quarterly_order), str(r2), str(mae_err)])\n    #figure = model.plot(forecast, xlabel = 'Date', ylabel = label_str)\n    \n    # Draw plot with the components (trend and seasonalities) of the forecasts\n    #figure_component = model.plot_components(forecast)    \n\n    return res","6c55e187":"def Prophet_tuning(df, anomalous, number_steps_in_day, Q_order, daily_order, weekly_order, quarterly_order):\n    # Prophet tuning\n\n    model = Prophet(daily_seasonality=False, weekly_seasonality=False, yearly_seasonality=False, \n                    changepoint_range=1, changepoint_prior_scale = 0.5, \n                    holidays=anomalous, seasonality_mode = 'multiplicative')\n\n    if (Q_order > 0):\n        model.add_seasonality(name='Q_hours', period=Q, \n                              fourier_order=Q_order, mode = 'multiplicative')\n\n    if (daily_order > 0):\n        model.add_seasonality(name='daily', period=1*number_steps_in_day, \n                              fourier_order=daily_order, mode = 'multiplicative')\n    if (weekly_order > 0):\n        model.add_seasonality(name='weekly', period=7*number_steps_in_day, \n                              fourier_order=weekly_order, mode = 'multiplicative')\n    if (quarterly_order > 0):\n        model.add_seasonality(name='quarterly', period=365.25\/12*4*number_steps_in_day, \n                              fourier_order=quarterly_order, mode = 'multiplicative')\n    model.fit(df)\n\n    return model","4d7f5144":"def model_tuning(res, df, anomalous, id_station_name, number_steps_in_day, forecasting_period):\n    # Prophet model with parameters and structure tuning\n    \n    Q_order_from = -1\n    daily_order_from = -1\n    weekly_order_from = -1\n    quarterly_order_from = -1\n    \n    Q_order_to = 0\n    daily_order_to = 0\n    weekly_order_to = 0\n    quarterly_order_to = 0\n    \n    order_min = 3\n    order_max = 6\n    \n    if len(df) > 31*4*24*2:\n        # All data more 2 quarters\n        quarterly_order_from = order_min\n        quarterly_order_to = order_max\n\n    if len(df) > 7*2*24:\n        # All data more 2 weeks\n        weekly_order_from = order_min\n        weekly_order_to = order_max\n\n    if len(df) > 24*2:\n        # All data more 2 \n        daily_order_from = order_min\n        daily_order_to = order_max        \n\n    if len(df) > 2*Q:\n        # All data more Q hours\n        Q_order_from = order_min\n        Q_order_to = order_max        \n\n    print(Q_order_from, daily_order_from, weekly_order_from, quarterly_order_from)\n    print(Q_order_to, daily_order_to, weekly_order_to, quarterly_order_to)\n    \n    for i0 in range(Q_order_to-Q_order_from):\n        Q_order = Q_order_from + i0\n\n        for i1 in range(daily_order_to-daily_order_from):\n            daily_order = daily_order_from + i1\n\n            for i2 in range(weekly_order_to-weekly_order_from):\n                weekly_order = weekly_order_from + i2\n\n                for i3 in range(quarterly_order_to-quarterly_order_from):\n                    quarterly_order = quarterly_order_from + i3\n\n                    print(Q_order, daily_order, weekly_order, quarterly_order, Q_order)\n                    model = Prophet_tuning(df, anomalous, number_steps_in_day, Q_order, daily_order, \n                                           weekly_order, quarterly_order)\n\n                    # Training err for prediction by the model                \n                    res = get_model_err(df, res, model, id_station_name, forecasting_period,\n                             Q_order, daily_order, weekly_order, quarterly_order)\n    #print('model_tuning')\n    #display(res)\n    return res","ed361066":"def prophet_pred(res, df, id_station_name, number_steps_in_day, threshold_min, forecasting_period):\n    \n    # Data preparation \n    df = df[['ds', 'value']].reset_index(drop=True)\n    df.columns = ['ds', 'y']\n    \n    # Get anomalous\n    df_abnorm = df[(df['y'] >= np.quantile(df['y'], threshold_min))]\n    anomalous_dates = df_abnorm['ds'].astype('str').tolist()\n    anomalous = pd.DataFrame({\n                              'holiday': 'anomalous',\n                              'ds': pd.to_datetime(anomalous_dates),\n                              'lower_window': 0,\n                              'upper_window': 0,\n                              'prior_scale': 20,\n                            })\n                            \n    plot_with_anomalies(df, [\"y\"], {\"y\" : f\"Anomalous dates with data of {indicator_name}\"}, 'ds', anomalous_dates, False)\n    \n    # Modeling and Visualization\n    # Model tuning\n    res = model_tuning(res, df, anomalous, id_station_name, number_steps_in_day, forecasting_period)\n    \n    # Resiults display \n    res_i = res[res['id_station']==id_station_name].sort_values(by=['mae'], ascending=True)\n    display(res_i)\n    \n    # Prediction with OPTIMAL parameters\n    model = Prophet_tuning(df, anomalous, number_steps_in_day, \n                           int(res_i.head(1)['Q_order']), \n                           int(res_i.head(1)['daily_order']), \n                           int(res_i.head(1)['weekly_order']), \n                           int(res_i.head(1)['quarterly_order']))\n    # Make a forecast\n    future = model.make_future_dataframe(periods = forecasting_period, freq=time_interval)\n    forecast = model.predict(future)\n\n    # Ouput the prediction for the next time\n    forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(2)\n    y_pred = forecast['yhat'][:-forecasting_period]\n\n    # Draw plot of the values with forecasting data\n    label_str = \" - \".join([id_station_name, indicator_name])\n    figure = model.plot(forecast, xlabel = 'Date', ylabel = label_str)\n\n    # Draw plot with the components (trend and seasonalities) of the forecasts\n    figure_component = model.plot_components(forecast)\n    \n    return res","4713f9a8":"id_station_list = df['id_station'].unique().tolist()\nid_station_list","045806b1":"for id_st in id_station_list:\n    df_i = df[df['id_station']==id_st]\n    df_i = df_i[(len(df_i)-10*24):]\n    print(id_st, int(len(df_i)\/number_steps_in_day))\n    df_i['value'].plot()\n    plt.show()\n    display(df_i.head(1))\n    display(df_i.tail(1))","804d3336":"# Staions with good series in November 2021\nid_station_best_list = ['EcoCity_337', 'EcoCity_848', 'EcoCity_1315']\n#id_station_best_list = ['EcoCity_337']\nid_station_best_list","02f0b5aa":"%%time\nres = pd.DataFrame(columns = ['id_station', 'Q_order', 'daily_order', 'weekly_order', 'quarterly_order', \n                              'r2_score', 'mae'])\nfor id_station_name in id_station_best_list:\n    print(id_station_name)\n    df1 = get_data_for_prediction(df, id_station_name, num_last_data=N)    \n    res = prophet_pred(res, df1, id_station_name, number_steps_in_day, threshold_min=0.95, forecasting_period=forecasting_period)","3aa5b6a4":"# Results display\npd.set_option('max_rows', 200)\nprint(f'Q_order = {Q}_hours_order')\ndisplay(res)","6744bfb8":"### 2.1 Download data from SaveEcoBot<a class=\"anchor\" id=\"2.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","710cf6a7":"## 2. Download data<a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","66e7518d":"### 2.3 Selection data for interpolation<a class=\"anchor\" id=\"2.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","ea3564bd":"### 3.1. Prediction functions <a class=\"anchor\" id=\"3.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","772b1c66":"<a class=\"anchor\" id=\"0\"><\/a>\n# Air Quality in Vinnytsia city - Hourly data forecasting:\n* Download of public (from SaveEcoBot and EcoCity) monitoring data\n* 2 indicators: PM2.5, PM10\n* prediction data in each monitoring station with tuning parameters\n* definition of average or maximum values in hourly data","bd24444b":"## Acknowledgements\n\n### Notebooks:\n* [Air Quality Station - Daily Forecasting - Prophet](https:\/\/www.kaggle.com\/vbmokin\/air-quality-station-daily-forecasting-prophet)\n* [Air Quality City - Stations data prediction](https:\/\/www.kaggle.com\/vbmokin\/air-quality-city-stations-data-prediction)\n* [Air Quality in Region - 2D Analysis](https:\/\/www.kaggle.com\/vbmokin\/air-quality-in-region-2d-analysis)\n* [Data Science for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/eda-for-tabular-data-advanced-techniques)\n* [COVID in UA: Prophet with 4, Nd seasonality](https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality)\n\n### Kaggle Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)\n\n### Other open data:\n* [Open data of the Vinnytsia City Council](https:\/\/opendata.gov.ua\/dataset\/pibehb-3a6pydhehocti-test)\n* [API of the Center for Hydrometeorology in Vinnytsia region](http:\/\/meteo.vn.ua\/api\/api.php)","05ad72ae":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download data](#2)\n   - [Download data from SaveEcoBot](#2.1)\n   - [Download data from EcoCity](#2.2)\n   - [Selection data for interpolation](#2.3)\n1. [Data prediction](#3)\n   - [Prediction functions](#3.1)\n   - [Selection parameters](#3.2)\n   - [Prediction results](#3.3)","76ca94d2":"## 3. Data prediction<a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","a518b0d7":"### 3.2. Selection parameters <a class=\"anchor\" id=\"3.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","2497325f":"### 3.3. Prediction results <a class=\"anchor\" id=\"3.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","9d61459f":"### 2.2 Download data from EcoCity<a class=\"anchor\" id=\"2.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","d4d5ac38":"## 1. Import libraries<a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","6225b7b4":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)"}}