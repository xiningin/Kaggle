{"cell_type":{"94d65d3b":"code","fc9b4682":"code","6b4de348":"code","b3dd056b":"code","9177498f":"code","3d5de1bf":"code","04eb2521":"code","8adb9ddd":"code","aad612c8":"code","c368233b":"code","042b24ad":"code","1068cebc":"code","1dfb90ba":"code","d900a8ee":"code","cb484a01":"code","4f8114e2":"code","fcc6fac0":"code","20e46b7d":"code","c81a94ec":"code","61e13901":"code","7d8e70ee":"code","f73dee7a":"code","36b95e0a":"code","51ecdf08":"code","56466c25":"code","0d8763a2":"code","5b31279e":"code","657a2e8c":"code","db2f475e":"code","cee40bd5":"code","8835f362":"code","0d0fd96d":"code","2870bacc":"code","06a4c107":"code","1a29c57d":"code","8b323f41":"code","27274c83":"code","a2c7969c":"code","1b75bb89":"code","560e57e5":"code","7f8c55a3":"code","9e382d20":"code","84a1227f":"code","f7683964":"code","e110b9af":"code","42fe9328":"code","b13f2fde":"code","d93c1437":"code","de400954":"code","218ec83b":"code","643c5e43":"code","f66494e9":"code","8ab34ad3":"code","77b625e5":"code","51884fe5":"code","da75f38b":"code","5b2af7b3":"code","7b325b07":"code","3ee51f82":"code","414a8859":"code","0c90b3e9":"code","2eca4741":"code","2982f552":"code","e317eafb":"code","46ff8f85":"code","db42264d":"code","32983e11":"code","a3ef8652":"code","5a7d9ecb":"code","ac01461b":"code","37f108f4":"code","6d03337a":"code","58c13bb6":"code","d6d152ef":"code","f2cca89c":"code","f20df4f8":"code","e5185d10":"code","cd1e5305":"code","341f6c52":"code","0609b8a3":"code","ca53a267":"code","13d28d95":"code","2acb173a":"code","b49d461f":"code","5a8b7135":"code","89858c71":"code","2f6251fe":"code","1cf199d2":"code","f48b1a57":"code","ebd786a0":"code","2191ebcc":"code","08c58ba1":"code","87534e27":"code","9a8ba24f":"code","869a9346":"code","a7a506bf":"code","7278ef1b":"code","c28d304b":"code","d5aeb698":"code","04c3b8dd":"code","813a1f0d":"code","e65d6b07":"code","5974eacb":"code","12fc0798":"code","f13372d3":"code","db2a5901":"code","bb7ad1de":"code","c578612a":"code","d4945c8d":"code","6ac6b0b8":"code","7463b002":"code","7780e2b8":"code","012f438e":"code","eef947ea":"code","3f7a32bc":"code","c45bdbf2":"code","56b18cfe":"code","7871a36a":"code","7b18df56":"code","ee904f27":"code","569f6dc3":"code","bd910f89":"code","7a4d04da":"code","67bf131b":"code","5c106528":"code","b0d02f40":"code","fdf06e92":"code","bbf093aa":"code","9dc872ad":"code","5de2bc15":"code","ba553d84":"code","188755a9":"code","9cea9d78":"code","26a1456c":"code","85a804f9":"code","9230a3ec":"code","722aca5b":"code","edef695e":"markdown","1a30c49b":"markdown","990135e3":"markdown","29ac5622":"markdown","385a152d":"markdown","5a641853":"markdown","d00b546b":"markdown","9d089e80":"markdown","09cd4112":"markdown","d63b8b4d":"markdown","1aa9365c":"markdown","42004b7f":"markdown","1ceb40da":"markdown","5886d665":"markdown","7d181a70":"markdown","99c2b1a8":"markdown","256b7b3a":"markdown","f9a668e2":"markdown","c36d7791":"markdown","58faf1ea":"markdown","d0ab8211":"markdown","9b146f6c":"markdown","3c970578":"markdown","02509f1d":"markdown","ea2ebe0c":"markdown","9780ca1f":"markdown","524cd30b":"markdown","a1f256bc":"markdown","39492aad":"markdown","c146e898":"markdown","ff064749":"markdown","d2340559":"markdown","71783b58":"markdown","a24f860e":"markdown","fd7ab9eb":"markdown","e1920362":"markdown","1673433a":"markdown","43089c56":"markdown","7ba7b947":"markdown","c486197a":"markdown","83ec72d8":"markdown","107ae0ee":"markdown","8cf4cb56":"markdown","11ac7aad":"markdown","d8ad51fb":"markdown","44bb0a0e":"markdown","d4b23d24":"markdown","5acbc01b":"markdown","543737f0":"markdown","196bab0a":"markdown","7be2a1b6":"markdown","15f78505":"markdown","fa62e0c2":"markdown","d9bc5699":"markdown","78cb3755":"markdown","921335a8":"markdown","731e68f5":"markdown","4b127f66":"markdown","abf6e197":"markdown","2feffd3a":"markdown"},"source":{"94d65d3b":"from IPython.display import Image\nImage(url= \"https:\/\/static1.squarespace.com\/static\/5006453fe4b09ef2252ba068\/5095eabce4b06cb305058603\/5095eabce4b02d37bef4c24c\/1352002236895\/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg\")","fc9b4682":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.patches as  mpatches","6b4de348":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")","b3dd056b":"train.head(10)","9177498f":"train","3d5de1bf":"test = pd.read_csv(\"..\/input\/titanic\/test.csv\")","04eb2521":"test.head(10)","8adb9ddd":"print(\"Training data shape: \", train.shape)\nprint(\"Testing data shape: \", test.shape)\n","aad612c8":"print(train.info())\nprint(\"-----------------------------------------\")\nprint(test.info())","c368233b":"train.isnull().sum().sort_values(ascending = False)","042b24ad":"color = sns.dark_palette(\"#69d\", reverse=True, as_cmap=True)\nsns.heatmap(train.isnull(),cmap = color)","1068cebc":"test.isnull().sum().sort_values(ascending = False)","1dfb90ba":"color = sns.color_palette(\"ch:start=.2,rot=-.3\", as_cmap=True)\nsns.heatmap(test.isnull(),cmap = color)","d900a8ee":"train.describe(include=\"all\").T","cb484a01":"test.describe(include=\"all\").T","4f8114e2":"train[\"Sex\"].value_counts(dropna = False)","fcc6fac0":"# Mean of survival by sex\ntrain[['Sex','Survived']].groupby('Sex',as_index = False).mean().sort_values(by = 'Survived', ascending = False)","20e46b7d":"sns.barplot(x = \"Sex\",y = \"Survived\", data = train)\nplt.xlabel(\"Sex\",fontsize=15)\nplt.ylabel(\"Survival Probability\",fontsize=15)\nplt.title(\"Survival Probability by Gender\", fontsize=20)\nplt.show()","c81a94ec":"train[\"Pclass\"].value_counts(dropna = False)","61e13901":"# Mean of survival by passenger class\ntrain[['Pclass','Survived']].groupby('Pclass',as_index = False).mean().sort_values(by = 'Survived', ascending = False)","7d8e70ee":"sns.barplot(x = \"Pclass\",y = \"Survived\", data = train, palette = \"muted\")\nplt.xlabel(\"Sex\",fontsize=15)\nplt.ylabel(\"Survival Probability\",fontsize=15)\nplt.title(\"Survival Probability by Passenger class\", fontsize=20)\nplt.show()","f73dee7a":"# Survival by gender and passenger class\nplot = sns.factorplot(x = 'Pclass', y = 'Survived', hue = 'Sex',\n                     data = train, kind = 'bar') #,color = )\nplot.despine(left = True)\nplt.ylabel(\"Survival Probability\",fontsize=15)\nplt.title(\"Survival Probability by Sex and Passenger class\", fontsize=20)\nplt.show()","36b95e0a":"train[\"Embarked\"].value_counts(dropna = False)\n","51ecdf08":"# Mean of survival by passenger class\ntrain[['Embarked','Survived']].groupby('Embarked',as_index = False).mean().sort_values(by = 'Survived', ascending = False)","56466c25":"color = sns.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=True)\nsns.barplot(x = \"Embarked\",y = \"Survived\", data = train, palette = \"Paired\")\nplt.xlabel(\"Embarked\",fontsize=15)\nplt.ylabel(\"Survival Probability\",fontsize=15)\nplt.title(\"Survival Probability by Embarked\", fontsize=20)\nplt.show()","0d8763a2":"sns.factorplot('Pclass', col = 'Embarked', data = train, kind ='count', \n               palette = \"OrRd\")","5b31279e":"g = sns.FacetGrid(train, row = 'Embarked', size = 3, aspect = 1.6)\ng.map(sns.pointplot,'Pclass','Survived','Sex', palette = 'YlGn')\ng.add_legend()\nplt.show()","657a2e8c":"sns.heatmap(train[['Survived','SibSp','Parch','Age',\n                        'Fare']].corr(), annot = True,\n            fmt = '.2f', cmap = 'coolwarm')","db2f475e":"train['SibSp'].value_counts(dropna = False)","cee40bd5":"# Mean of survival by SibSp\ntrain[['SibSp','Survived']].groupby('SibSp',\n                                         as_index = False).mean().sort_values(by = 'Survived',\n                                                                             ascending = False)","8835f362":"sns.barplot(x = 'SibSp', y = 'Survived', data =  train, \n            palette = \"copper_r\")\nplt.ylabel('Survived Probability')\nplt.xlabel('Survived Probability by SibSp')\nplt.show()","0d0fd96d":"train['Parch'].value_counts(dropna = False)","2870bacc":"# Mean of survival by SibSp\ntrain[['Parch','Survived']].groupby('Parch',\n                                         as_index = False).mean().sort_values(by = 'Survived',\n                                                                             ascending = False)","06a4c107":"sns.barplot(x = 'Parch', y = 'Survived', data =  train, \n            palette = \"hot_r\")\nplt.ylabel('Survived Probability')\nplt.xlabel('Survived Probability by Parch')\nplt.show()","1a29c57d":"train[\"Age\"].isnull().sum()","8b323f41":"# Passenger age distribution\nsns.distplot(train[\"Age\"],label= 'Skewness: %.2f'%(train['Age'].skew()))\nplt.legend(loc = 'best')\nplt.title('Passenger Age Distibution')\nplt.show()","27274c83":"# Age distribution by survival\ng = sns.FacetGrid(train, col = 'Survived')\ng.map(sns.distplot,'Age', color = \"red\")\nplt.show()","a2c7969c":"sns.kdeplot(train['Age'][train[\"Survived\"]==0],\n            hue = train[\"Survived\"])\nsns.kdeplot(train['Age'][train[\"Survived\"]==1],\n            hue = train[\"Survived\"])\nplt.xlabel('Age')\nplt.title(\"Passenger Age Distribution by Survival\")\nplt.show()","1b75bb89":"train[\"Fare\"].isnull().sum()","560e57e5":"# Passenger by Fare \nsns.distplot(train[\"Fare\"],label= 'Skewness: %.2f'%(train['Fare'].skew()))\nplt.legend(loc = 'best')\nplt.title('Passenger Age Distibution')\nplt.show()","7f8c55a3":"# droping ticket and cabin feature from train and test data\ntrain = train.drop(['Ticket','Cabin'],axis = 1)\ntest = test.drop(['Ticket','Cabin'],axis = 1)","9e382d20":"# Finding the most frequent value of Embarked in train\nmode = train[\"Embarked\"].dropna().mode()[0]\nmode","84a1227f":"# Fillinh missing values in Embarked with mode\ntrain[\"Embarked\"].fillna(mode, inplace = True)","f7683964":"# Missing values in test \ntest.isnull().sum().sort_values(ascending = False)","e110b9af":"# Computing Median of fare in test\nmedian = test['Fare'].dropna().median()\nmedian","42fe9328":"# Filling missing values in Fare with median\ntest['Fare'].fillna(median, inplace = True)","b13f2fde":"# Combining the train_dat and test\ncombine = pd.concat([train,test],axis = 0).reset_index(drop = True)\ncombine.head()","d93c1437":"# Missing values in the combined data\ncombine.isnull().sum().sort_values(ascending = False)","de400954":"combine[\"Sex\"] = combine['Sex'].map({'male' : 0,'female' : 1})","218ec83b":"sns.factorplot(y = 'Age', x = 'Sex', hue = 'Pclass', kind = 'box',\n              data = combine, palette = 'bright')\nsns.factorplot(y = 'Age', x = 'Parch', kind = 'box', data = combine,\n              palette = 'bright')\nsns.factorplot(y = 'Age', x = 'SibSp', kind = 'box', data = combine,\n              palette = 'bright')\nplt.show()","643c5e43":"sns.heatmap(combine.drop(['Survived','Name','PassengerId','Fare'],\n                       axis = 1).corr(), annot = True,cmap = 'coolwarm')\nplt.show()","f66494e9":"# check number of missing ages\nage_nan_indices = list(combine[combine[\"Age\"].isnull()].index)\nlen(age_nan_indices)","8ab34ad3":"# loop through list and impute missing ages\nfor index in age_nan_indices:\n    median_age = combine['Age'].median()\n    predict_age = combine[\"Age\"][(combine['SibSp'] == combine.iloc[index]['SibSp'])\n                                & (combine['Parch'] == combine.iloc[index]['Parch'])\n                                &(combine['Pclass'] == combine.iloc[index]['Pclass'])].median()\n    if np.isnan(predict_age):\n        combine[\"Age\"].iloc[index] = median_age\n    else:\n        combine[\"Age\"].iloc[index] = predict_age","77b625e5":"combine[\"Age\"].isnull().sum()","51884fe5":"# passenger by Fare distribution\nsns.distplot(combine['Fare'], label = 'Skewness: %.2f'%(combine[\"Fare\"].skew()))\nplt.legend(loc = 'best')\nplt.title(\"Passenger Fare Distribution\")\nplt.show()","da75f38b":"# Get title from name\ncombine['Title'] = [name.split(\",\")[1].split('.')[0].strip() for name in \n                   combine[\"Name\"]]\ncombine[['Name','Title']].head()","5b2af7b3":"combine[\"Title\"].value_counts()","7b325b07":"combine[\"Title\"].nunique()","3ee51f82":"# Simplify title\ncombine[\"Title\"] = combine[\"Title\"].replace(['Dr','Rev','Col',\n                                'Major','Lady','Jonkheer','Don',\n                                 'the Countess','Sir','Dona'],'Rare')\ncombine['Title'] = combine['Title'].replace(['Mlle','Ms'],'Miss')\ncombine['Title'] = combine['Title'].replace('Mme','Mrs')","414a8859":"sns.countplot(combine[\"Title\"], edgecolor=(0,0,0),\n                  linewidth=2)\nplt.show()","0c90b3e9":"# Mean of survival by name title\ncombine[['Title','Survived']].groupby(['Title'],as_index = False).mean().sort_values(by = 'Survived',\n                                                         ascending = False)\n    ","2eca4741":"sns.factorplot(x = 'Title', y = 'Survived', data = combine, kind = 'bar')\nplt.ylabel(\"Survived Probability\")\nplt.title(\"Mean of Survival by Title\")\nplt.show()","2982f552":"# Drop Name column\ncombine = combine.drop(['Name'],axis = 1)\ncombine.head(10)","e317eafb":"# Calculate family size from SibSp and Parch\ncombine[\"Family Size\"] = combine[\"SibSp\"] + combine[\"Parch\"] + 1\ncombine[[\"SibSp\",\"Parch\",\"Family Size\"]].head(10)","46ff8f85":"# Mean of survival by family size\ncombine[['Family Size','Survived']].groupby('Family Size', \n                                            as_index = False).mean().sort_values(by = 'Survived',\n                                                                                 ascending = False)","db42264d":"# Create a IsAlone feature\ncombine[\"IsAlone\"] = 0\ncombine.loc[combine[\"Family Size\"] == 1,'IsAlone'] = 1","32983e11":"# Mean of survival by IsAlone\ncombine[[\"IsAlone\",\"Survived\"]].groupby('IsAlone', as_index = False).mean().sort_values(by = 'Survived',\n                                                                                       ascending = False)","a3ef8652":"combine = combine.drop(['SibSp','Parch','Family Size'], axis = 1)\ncombine.head()","5a7d9ecb":"# Age*Class\ncombine[\"Age Band\"] = pd.cut(combine[\"Age\"],5)\ncombine[['Age Band','Survived']].groupby('Age Band', as_index = False).mean().sort_values(by = \n                                                                        'Age Band')","ac01461b":"# Assign ordinals to each Age Band\ncombine.loc[combine[\"Age\"] <= 16.136, 'Age'] = 0\ncombine.loc[(combine['Age'] > 16.136) & (combine['Age'] <= 32.102),'Age'] = 1\ncombine.loc[(combine['Age'] > 32.102) & (combine['Age'] <= 48.068),'Age'] = 2\ncombine.loc[(combine['Age'] > 48.068) & (combine['Age'] <= 64.034),'Age'] = 3\ncombine.loc[combine[\"Age\"] > 64.034, \"Age\"] = 4","37f108f4":"# Drop Age Band feature\ncombine = combine.drop('Age Band', axis = 1)\ncombine","6d03337a":"# Age and Pclass data types\ncombine[[\"Age\", \"Pclass\"]].dtypes","58c13bb6":"combine","d6d152ef":"# Convert Ordinal Age into Integer\ncombine[\"Age\"] = combine[\"Age\"].astype('int')\ncombine[\"Age\"].dtype","f2cca89c":"# Create Age * Class Feature\ncombine[\"Age*Class\"] = combine[\"Age\"] * combine[\"Pclass\"]\ncombine[[\"Age\", \"Pclass\",\"Age*Class\"]].head(10)","f20df4f8":"# Encode Title and Embarked feature\ncombine = pd.get_dummies(combine, columns = [\"Title\"])\ncombine = pd.get_dummies(combine, columns = [\"Embarked\"], prefix = 'Em')\ncombine.head()","e5185d10":"# Divide fare into four bands\ncombine['Fare band'] = pd.cut(combine[\"Fare\"], 4)\ncombine[[\"Fare band\",\"Survived\"]].groupby(['Fare band'],as_index = False).mean().sort_values(by = 'Fare band')","cd1e5305":"# Assign ordinals to each Age Band\ncombine.loc[combine[\"Fare\"] <= 128.0, 'Fare'] = 0\ncombine.loc[(combine['Fare'] > 128.0) & (combine['Fare'] <= 256.0),'Fare'] = 1\ncombine.loc[(combine['Fare'] > 256.0) & (combine['Fare'] <= 384.0),'Fare'] = 2\ncombine.loc[combine['Fare'] > 384.0,'Fare'] = 3","341f6c52":"# convert Fare into integer\ncombine[\"Fare\"] = combine[\"Fare\"].astype('int')\ncombine[\"Fare\"]","0609b8a3":"# Droping Fare band feature\ncombine = combine.drop('Fare band',axis = 1)","ca53a267":"combine.head(10)","13d28d95":"train = combine[:len(train)]\ntest = combine[len(train):]","2acb173a":"train.head(10)","b49d461f":"# Drop passenger ID column from and training set\ntrain = train.drop('PassengerId', axis = 1)\ntrain.head()","5a8b7135":"#Converting survived back to integer\ntrain[\"Survived\"] = train[\"Survived\"].astype('int')\ntrain.head()","89858c71":"test.head()","2f6251fe":"# Droping the Survived nad PssengerId\ntest  = test.drop([\"Survived\"],axis = 1)\ntest.head()","1cf199d2":"updated = pd.concat([train, test], axis = 0).reset_index(drop = True)\nupdated","f48b1a57":"X_train = train.drop(\"Survived\",axis = 1)\ny_train = train[\"Survived\"]\nX_test = test.drop('PassengerId',axis = 1).copy()","ebd786a0":"print(\"X_train shape: \", X_train.shape)\nprint(\"X_test shape: \", X_test.shape)\nprint(\"y_train shape: \", y_train.shape)","2191ebcc":"from sklearn.linear_model import LogisticRegression","08c58ba1":"lr = LogisticRegression(random_state = 0)\nlr.fit(X_train,y_train)\npredictions1 = lr.predict(X_test)","87534e27":"lr.score(X_train,y_train)","9a8ba24f":"from sklearn.svm import SVC","869a9346":"svc = SVC()\nsvc.fit(X_train,y_train)\npredictions2 = svc.predict(X_test)","a7a506bf":"svc.score(X_train,y_train)","7278ef1b":"from sklearn.linear_model import Perceptron","c28d304b":"perceptron = Perceptron()\nperceptron.fit(X_train,y_train)\npredictions3 = perceptron.predict(X_test)","d5aeb698":"perceptron.score(X_train,y_train)","04c3b8dd":"from sklearn.linear_model import SGDClassifier","813a1f0d":"sgd = SGDClassifier()\nsgd.fit(X_train,y_train)\npredictions4 = sgd.predict(X_test)","e65d6b07":"sgd.score(X_train,y_train)","5974eacb":"from sklearn.ensemble import RandomForestClassifier","12fc0798":"random_forest  = RandomForestClassifier()\nrandom_forest.fit(X_train,y_train)\npredictions5 = random_forest.predict(X_test)","f13372d3":"random_forest.score(X_train,y_train)","db2a5901":"from sklearn.neighbors import KNeighborsClassifier","bb7ad1de":"knn = KNeighborsClassifier()\nknn.fit(X_train,y_train)\npredictions6 = knn.predict(X_test)","c578612a":"knn.score(X_train,y_train)","d4945c8d":"from sklearn.tree import DecisionTreeClassifier","6ac6b0b8":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train,y_train)\npredictions7 = decision_tree.predict(X_test)","7463b002":"decision_tree.score(X_train,y_train)","7780e2b8":"from sklearn.svm import LinearSVC","012f438e":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train,y_train)\npredictions8 = linear_svc.predict(X_test)","eef947ea":"linear_svc.score(X_train,y_train)","3f7a32bc":"from sklearn.naive_bayes import GaussianNB","c45bdbf2":"naive = GaussianNB()\nnaive.fit(X_train,y_train)\npredictions9 = naive.predict(X_test)","56b18cfe":"naive.score(X_train,y_train)","7871a36a":"from catboost import CatBoostClassifier","7b18df56":"catboost = CatBoostClassifier()\ncatboost.fit(X_train,y_train)\npredictions10 = catboost.predict(X_test)","ee904f27":"catboost.score(X_train,y_train)","569f6dc3":"from sklearn.model_selection import cross_val_score","bd910f89":"models = pd.DataFrame({\"Model\" : ['Support vector Machines','KNN',\n                                 'Logistic Regression','Random Forest',\n                                 'Naive Bayes','Perceptron',\n                                  'Stochastic Gradient Descent',\n                                  'Linear SVC','Decision tree',\n                                  'Cat Boost'],\n                       'Score':[svc.score(X_train,y_train),\n                                knn.score(X_train,y_train),\n                               lr.score(X_train,y_train),\n                               random_forest.score(X_train,y_train),\n                               naive.score(X_train,y_train),\n                               perceptron.score(X_train,y_train),\n                               sgd.score(X_train,y_train),\n                               linear_svc.score(X_train,y_train),\n                               decision_tree.score(X_train,y_train),\n                               catboost.score(X_train,y_train)]})\nmodels.sort_values(by = 'Score', ascending = False, ignore_index = True)","7a4d04da":"classifiers = []\nclassifiers.append(LogisticRegression())\nclassifiers.append(SVC())\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(GaussianNB())\nclassifiers.append(Perceptron())\nclassifiers.append(LinearSVC())\nclassifiers.append(SGDClassifier())\nclassifiers.append(DecisionTreeClassifier())\nclassifiers.append(RandomForestClassifier())\nclassifiers.append(CatBoostClassifier())\nlen(classifiers)","67bf131b":"cv_results = []\nfor classifier in classifiers:\n    cv_results.append(cross_val_score(classifier,X_train,y_train,\n                                     scoring='accuracy',cv=10))","5c106528":"cv_mean = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_mean.append(cv_result.mean())\n    cv_std.append(cv_result.std())","b0d02f40":"cv = pd.DataFrame({'Cross Validation Mean': cv_mean,\n                   'Cross Validation Std': cv_std,\n                   'Models':['Logistic Regression','Support Vector Machine',\n                             'KNN','GausianNB','Perceptron',\n                            'Linear SVC','Stochastic Gradient Descent',\n                             'Decision Tree','Random Forest','Cat Boost']})\ncv.sort_values(by = 'Cross Validation Mean',ascending = False, \n               ignore_index = True)","fdf06e92":"plt.rcParams['figure.dpi'] = 250\nfig = plt.figure(figsize=(5, 1.5), facecolor='#f6f5f5')\nfig.tight_layout(pad=100)\ngs = fig.add_gridspec(1, 2)\ngs.update(wspace=0.4, hspace=10)\n\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#00A4CCFF']*6)\n\nax = fig.add_subplot(gs[0, 0])\nfor s in [\"right\", \"top\"]:\n    ax.spines[s].set_visible(False)\nax.set_facecolor(background_color)\nax_sns = sns.barplot(ax=ax, x=cv['Models'], \n                      y=cv['Cross Validation Mean'], \n                      zorder=2, linewidth=0, alpha=1, saturation=1, color = '#2874A6')\nax_sns.set_ylabel(\"Cross Val Score\",fontsize=8, weight='bold')\nplt.xticks(rotation = 90)\nax_sns.set_xlabel(\"Alogorithm's Name\",fontsize=8, weight='bold')\nax_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.tick_params(labelsize=4, width=0.5, length=1.5)\n\n","bbf093aa":"plt.rcParams['figure.dpi'] = 250\nfig = plt.figure(figsize=(5, 1.5), facecolor='#f6f5f5')\nfig.tight_layout(pad=100)\ngs = fig.add_gridspec(1, 2)\ngs.update(wspace=0.4, hspace=10)\n\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#00A4CCFF']*6)\n\nax = fig.add_subplot(gs[0, 0])\nfor s in [\"right\", \"top\"]:\n    ax.spines[s].set_visible(False)\nax.set_facecolor(background_color)\nax_sns = sns.barplot(ax=ax, x=cv['Models'], \n                      y=cv['Cross Validation Std'], \n                      zorder=2, linewidth=0, alpha=1, saturation=1, color = '#ff3333')\nax_sns.set_ylabel(\"Cross Val Standard Deviation\",fontsize=8, weight='bold')\nplt.xticks(rotation = 90)\nax_sns.set_xlabel(\"Alogorithm's Name\",fontsize=8, weight='bold')\nax_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax_sns.tick_params(labelsize=4, width=0.5, length=1.5)\n\n","9dc872ad":"from sklearn.model_selection import GridSearchCV","5de2bc15":"param_grid = {'C': [0.1,1,10,100,1000],\n             'gamma':[1,0.1,0.01,0.001,0.0001],\n             'kernel': ['rbf']}\ngrid = GridSearchCV(SVC(),param_grid, refit = True, verbose = 3)\ngrid.fit(X_train,y_train)","ba553d84":"print(\"Best paramters: \",grid.best_params_)\nprint(\"Best estimator: \",grid.best_estimator_)","188755a9":"# Trainig Accuracy\nsvc = SVC(C = 100, gamma = 0.01, kernel = 'rbf')\nsvc.fit(X_train,y_train)\ny_prediction = svc.predict(X_test)\ns = svc.score(X_train,y_train)\nprint(\"Our SVC Training Accuracy Score increase \",s)","9cea9d78":"y_prediction","26a1456c":"len(y_prediction)","85a804f9":"final_submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_prediction})\nfinal_submission","9230a3ec":"final_submission.shape","722aca5b":"final_submission.to_csv(\"Titanic.csv\",index=False)","edef695e":"# 9. Naive Byes","1a30c49b":"# 6. KNeighbors Classifier","990135e3":"# Feature Encoding","29ac5622":"# Hyperparameter Tuning for SVM","385a152d":" Confusion Matrix Accuracy Score Classification Report","5a641853":"# drop and fill missing values","d00b546b":"# 3. Perceptron","9d089e80":"# 10. Boosting","09cd4112":"It is the process of tuning the parameters of model.So, I will tune the paramters of SVC model","d63b8b4d":"# Mean and Standard deviation of cross validation results","1aa9365c":" Importing Classifier Modules","42004b7f":"## EXPLORATORY DATA ANALYSIS (EDA)","1ceb40da":"# Categorical variable : Embarked","5886d665":"Accuracy Score","7d181a70":" Confusion Matrix Accuracy Score Classification Report","99c2b1a8":"# 2. Support Vector Machine","256b7b3a":"## Titanic Disaster Survival","f9a668e2":"# 8. Linear SVC ","c36d7791":"# IsAlone","58faf1ea":" Confusion Matrix Accuracy Score Classification Report","d0ab8211":" Accuracy Score ","9b146f6c":"## Summary Statistics of Testing data","3c970578":"# Model Evaluation and Hyperparameter","02509f1d":"We see Age is not correlated with Sex but is negatively correlated with\nSibSp, Parch and Pclass.","ea2ebe0c":"## Data description\n    Survived: 0 = Did not survive, 1 = Survived\n\n    Pclass: Ticket class where 1 = First class, 2 = Second class, 3 = Third class. This can also be seen as a proxy for socio-economic status.\n\n    Sex: Male or female\n\n    Age: Age in years, fractional if less than 1\n\n    SibSp: Number of siblings or spouses aboard the titanic\n\n    Parch: Number of parents or children aboard the titanic\n\n    Ticket: Passenger ticket number\n\n    Fare: Passenger fare\n\n    Cabin: Cabin number\n\n    Embarked: Point of embarkation where C = Cherbourg, Q = Queenstown, S = Southampton\n","9780ca1f":" Accuracy Score ","524cd30b":"## IMPORTING THE DATASETS","a1f256bc":" Confusion Matrix Accuracy Score Classification Report","39492aad":"# 4. SGDClassifier","c146e898":"# Data Wrangling","ff064749":"# Numerical variable : Age","d2340559":"## TESTING DATA\nThe test set should be used to see how well your model performs on unseen data. \nFor the test set, we do not provide the ground truth for each passenger. \nIt is your job to predict these outcomes. For each passenger in the test set, \nuse the model you trained to predict whether or not they survived the sinking of the Titanic.","71783b58":"# Data Transformation","a24f860e":"# Data Preprocessing","fd7ab9eb":"# Numerical variable : SibSp","e1920362":"  # 1.Logistic Regression","1673433a":"# Feature Engineering","43089c56":"## Feature Analysis","7ba7b947":"Missing data in testing set by columns","c486197a":"# K-Fold cross validation","83ec72d8":" Confusion Matrix Accuracy Score Classification Report","107ae0ee":"# Numericals variables correlation with survival","8cf4cb56":"# Numerical variable : Parch","11ac7aad":". Data Transformation\n. Feature Engineering\n. Feature Encoding","d8ad51fb":"# Categorical variable : Pclass","44bb0a0e":"# Survival probability by all categorical variables","d4b23d24":"## TRAINING DATA\nThe training set should be used to build your machine learning models. \nFor the training set, we provide the outcome (also known as the \u201cground truth\u201d) \nfor each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class.\nYou can also use feature engineering to create new features.","5acbc01b":"Once the models are trained, so the next step is to assess the performance of these models and to find the best prediction model accuracy.","543737f0":"## IMPORT LIBRARIES","196bab0a":"# 7. Decision Tree Classifier","7be2a1b6":" Confusion Matrix Accuracy Score Classification Report","15f78505":"# 5. Random Forest Classifier","fa62e0c2":"# Training Accuracy","d9bc5699":". Title\n. IsAlone\n. Age*Class","78cb3755":"Missing data in training set by columns","921335a8":"# Modeling","731e68f5":"Mapping the Sex column where male = 0 and 1 = female","4b127f66":"# Spliting the data into Training and Testing set","abf6e197":" Confusion Matrix Accuracy Score Classification Report","2feffd3a":"## Summary Statistics of Training data"}}