{"cell_type":{"59acb648":"code","7618e4b3":"code","7b6a9744":"code","9a81309a":"code","28e12ade":"code","d147e3ee":"code","f3dbe597":"code","d04e2f9b":"code","e77b27da":"code","cd3e6818":"code","8b951632":"code","a3b6ed01":"code","161f2ccf":"code","127658dc":"code","b3905311":"code","9a19d55a":"code","ccca4f39":"code","422ba6a7":"code","a2512ffd":"code","f219c8da":"code","e8fe79eb":"code","37853d84":"code","33cae491":"code","24e7a987":"code","bda3c59d":"code","11d26580":"code","f206166a":"code","ccb9fd4a":"code","cc0f40f7":"code","b5e5a47a":"code","daf8f404":"code","075c3495":"code","e086a790":"code","e9f1879e":"code","decd15a8":"code","22fdbbe1":"code","2791e6b1":"code","9e93a7b6":"code","35065116":"code","e18cd95f":"code","d5da7c42":"code","d49b621b":"code","64bfe6ba":"code","dc337131":"code","679b8fdf":"code","1b7a369e":"code","f2d9869e":"code","241c707e":"code","a864a92a":"code","eb7ec6b5":"code","43f8df8d":"markdown","ea18d6e7":"markdown","2e9ddccc":"markdown","48627d70":"markdown","a988ac47":"markdown","4dfc8965":"markdown","787c68f9":"markdown","c42e4377":"markdown","d31c3404":"markdown","961d8593":"markdown","9bac6709":"markdown","8bd6389b":"markdown","ec392d77":"markdown","1bc43da2":"markdown","8709fb2d":"markdown","d0018f36":"markdown","f817200c":"markdown","112d70e1":"markdown","4a3dcbb2":"markdown"},"source":{"59acb648":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","7618e4b3":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score","7b6a9744":"from sklearn.datasets import load_iris","9a81309a":"iris = load_iris()\ntype(iris) ## Specialized Bunch Object","28e12ade":"print(iris.DESCR)","d147e3ee":"len(iris)","f3dbe597":"# Creating X as a feature object\nX = iris.data","d04e2f9b":"X # Just a numpy array with measurements lined up (Sepal-length, Sepal-width, Petal-length, Petal-width)","e77b27da":"# Grabbing Labels now\ny = iris.target","cd3e6818":"print(f'{y}')","8b951632":"## We have three classes above, class-0, class-1, class-2","a3b6ed01":"## One hot encoding can be easily done using Keras\nfrom keras.utils import to_categorical","161f2ccf":"# Type casting 'y'\ny = to_categorical(y)","127658dc":"y.shape","b3905311":"## y has 150 instances with 3 values per label","9a19d55a":"print(f'{y}') # one-hot encoded format","ccca4f39":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","422ba6a7":"X_train # training data","a2512ffd":"X_test # testing features","f219c8da":"y_train # labels for training data","e8fe79eb":"y_test # labels for testing features","37853d84":"from sklearn.preprocessing import MinMaxScaler","33cae491":"scaler_object = MinMaxScaler()","24e7a987":"scaled_X_train = scaler_object.fit_transform(X_train)","bda3c59d":"scaled_X_test = scaler_object.transform(X_test) # we won't fit the test data as that would be cheating :P ;)","11d26580":"X_train.max()","f206166a":"scaled_X_train.max()","ccb9fd4a":"scaled_X_test.max()","cc0f40f7":"X_train","b5e5a47a":"scaled_X_train","daf8f404":"## Activating model session on GPU\nimport keras\nimport tensorflow.compat.v1 as tf\n\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\ntf.compat.v1.keras.backend.set_session(sess)","075c3495":"# Building a Sequential Keras model\nfrom keras.models import Sequential\nfrom keras.layers import Dense","e086a790":"# Creating a model instance and generating simple layers\nmodel = Sequential()\nmodel.add(Dense(16,input_dim=4, activation='relu')) # I used 16 neurons, input_dim = 4 since we expect 4 features, and Rectified Linear Unit as activ. fn.\nmodel.add(Dense(16,input_dim=4, activation='relu')) # Adding another dense layer\nmodel.add(Dense(3,activation='softmax')) # Each neuron will have a probability of belonging to a particular class as we've three classes\n## The output of the above 3 neurons will look something like [0.1,0.3,0.6] with 3rd class having the highest probability.\n## Since we used softmax, it will give us a basic idea where our max probability is leaning towards!\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n## Since we've three categories, hence, we used loss = categorical_crossentropy to perform loss","e9f1879e":"# Let's check the shape of the model\nmodel.summary()","decd15a8":"# Also known as fitting the model\nhistory = model.fit(scaled_X_train, y_train, batch_size=8, epochs=240, steps_per_epoch=10, verbose=2)","22fdbbe1":"import matplotlib.pyplot as plt","2791e6b1":"# list all data in history\nprint(history.history.keys())","9e93a7b6":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","35065116":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e18cd95f":"model.predict_classes(scaled_X_test) # Predicts the classes","d5da7c42":"# Let's compare these predictions above to our unseen 'y_test' data\npredictions = model.predict_classes(scaled_X_test)","d49b621b":"y_test.argmax(axis=1) # from the one-hot encoded version of y_test, argmax will report back the predicted classes at each index","64bfe6ba":"from sklearn.metrics import confusion_matrix,classification_report","dc337131":"model.metrics_names","679b8fdf":"model.evaluate(x=scaled_X_test,y=y_test)","1b7a369e":"print(confusion_matrix(y_test.argmax(axis=1),predictions))\nprint('------------------------------------------------------')\nprint('------------------------------------------------------')\nprint(classification_report(y_test.argmax(axis=1),predictions))","f2d9869e":"model.save('iris_model.h5')","241c707e":"from keras.models import load_model","a864a92a":"iris_model = load_model('iris_model.h5')","eb7ec6b5":"iris_model.predict_classes(X_test)","43f8df8d":"`Converting into one-hot encoded system`\n##### e.g; Since we've three classes, [0,1,2] Let's create a list with the Index positions of these classes:\n1. Class 0 ----> [1, 0, 0]\n2. Class 1 ----> [0, 1, 0]\n3. Class 2 ----> [0, 0, 1]","ea18d6e7":"**<font size=\"3\"><a href=\"#chap1\">1. Imports<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap2\">2. Loading the dataset<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap3\">3. Reading the dataset<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap4\">4. Split the Data into Training and Test<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap5\">5. Preprocessing and Standardizing the Data<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap6\">6. Building the Network with Keras<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap7\">7. Model Training<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap8\">8. Predicting the model<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap9\">9. Model Performance evaluation<\/a><\/font>**\n**<br><font size=\"3\"><a href=\"#chap10\">10. Saving the model<\/a><\/font>**","2e9ddccc":"![Graphical view for Data Clustering](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/5\/56\/Iris_dataset_scatterplot.svg\/1200px-Iris_dataset_scatterplot.svg.png)","48627d70":"<a id=\"chap2\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Loading the dataset<\/h3>","a988ac47":"<a id=\"chap1\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Imports<\/h3>","4dfc8965":"`# Let's split the data into a train\/test set. You can also split it 3 ways, i.e; train\/test\/validation.`","787c68f9":"<a id=\"chap10\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Loading and saving the model<\/h3>","c42e4377":"<a id=\"chap5\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Preprocessing and Standardizing the data<\/h3>","d31c3404":"`Let's grab the feature and the Label information`","961d8593":"While working with Neural Networks, we get better performance when we standardize the data. Standardization just means normalizing the values to all fit between a certain range, like 0-1, or -1 to 1.\n\n> e.g. if we take an array of numbers and divide it with it's max value in array, we get the output of numbers in between 0-1\n`np.array([2,4,6,8])\/8 will give the output as array([0.25, 0.5 , 0.75, 1.])`\n\nThe scikit learn library also provides a nice function for this known as the [MinMaxScaler](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.MinMaxScaler.html)","9bac6709":"<a id=\"chap4\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Splitting the dataset<\/h3>","8bd6389b":"We're going to use the famous **IRIS dataset**.\nMore info on the data set is available on [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Iris_flower_data_set)","ec392d77":"<a id=\"chap8\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Model Prediction<\/h3>","1bc43da2":"<a id=\"chap9\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Model Performance Evaluation<\/h3>","8709fb2d":"<a id=\"chap6\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Network Building using KERAS<\/h3>","d0018f36":"![](https:\/\/s3.amazonaws.com\/assets.datacamp.com\/blog_assets\/Machine+Learning+R\/iris-machinelearning.png)","f817200c":"<a id=\"chap3\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Reading the dataset<\/h3>","112d70e1":"<a id=\"1.1\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">IRIS DATASET using Scikit-Learn<\/h3>","4a3dcbb2":"<a id=\"chap7\"><\/a>\n<h3 style=\"background-color:gold;font-family:newtimeroman;font-size:200%;text-align:center\">Model Training<\/h3>"}}