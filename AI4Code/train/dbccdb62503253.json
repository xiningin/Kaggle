{"cell_type":{"16b9550c":"code","c0391568":"code","2bbc6380":"code","73b53b3d":"code","46a0bd3e":"code","668ddc7d":"code","27a7f514":"code","47e5750f":"code","0e7b2c2f":"code","84308354":"code","f5d0d2cf":"code","5e8a68d3":"code","a30177be":"code","4f8eb2ee":"code","a99bc4dc":"code","7633b191":"code","af873153":"code","3be78aac":"code","a1f35b90":"code","e1878375":"code","7e8b93ac":"code","2220ba02":"code","ecb5990e":"code","b6cd7e8f":"code","1097a63f":"markdown","a9979726":"markdown","7d4d098b":"markdown","50fe03ee":"markdown"},"source":{"16b9550c":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport time\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","c0391568":"data_dir='..\/input\/wild-animals\/Animals\/'","2bbc6380":"Name=[]\nfor file in os.listdir(data_dir):\n    Name+=[file]\nprint(Name)\nprint(len(Name))","73b53b3d":"N=[]\nfor i in range(len(Name)):\n    N+=[i]\nnormal_mapping=dict(zip(Name,N)) \nreverse_mapping=dict(zip(N,Name)) ","46a0bd3e":"datax0=[]\ndatay0=[]\npaths=[]\ncount=0\nfor file in Name:\n    path=os.path.join(data_dir,file)\n    for im in tqdm(os.listdir(path)):\n        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(48,48))\n        image=img_to_array(image)\n        image=image\/255.0\n        datax0.append(image)\n        datay0.append(count)\n        paths.append(os.path.join(path,im))\n    count=count+1","668ddc7d":"import random\nnum0=random.sample(range(len(paths)),k=9)\nprint(num0)","27a7f514":"fig,axs = plt.subplots(3,3,figsize=(14,14))\nfor i in range(9):\n    image_input = cv2.imread(paths[num0[i]])\n    r=i\/\/3\n    c=i%3\n    axs[r][c].set_xticks([])\n    axs[r][c].set_yticks([])\n    axs[r][c].set_title(reverse_mapping[datay0[num0[i]]])\n    ax=axs[r][c].imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","47e5750f":"labels = open('..\/input\/yolo-coco-data\/coco.names').read().strip().split('\\n')\nprint(labels)","0e7b2c2f":"weights_path = '..\/input\/yolo-coco-data\/yolov3.weights'\nconfiguration_path = '..\/input\/yolo-coco-data\/yolov3.cfg'\nprobability_minimum = 0.5\nthreshold = 0.3","84308354":"network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\nlayers_names_all = network.getLayerNames()\nlayers_names_output = [layers_names_all[i[0]-1] for i in network.getUnconnectedOutLayers()]","f5d0d2cf":"image_input = cv2.imread(paths[50])\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (8,8)\nplt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","5e8a68d3":"blob = cv2.dnn.blobFromImage(image_input, 1\/255.0, (416,416), swapRB=True, crop=False)\nblob_to_show = blob[0,:,:,:].transpose(1,2,0)\nnetwork.setInput(blob)\noutput_from_network = network.forward(layers_names_output)\nnp.random.seed(42)\ncolours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')","a30177be":"bounding_boxes = []\nconfidences = []\nclass_numbers = []\nh,w = image_input.shape[:2]\n\nfor result in output_from_network:\n    for detection in result:\n        scores = detection[5:]\n        class_current = np.argmax(scores)\n        confidence_current = scores[class_current]\n        if confidence_current > probability_minimum:\n            box_current = detection[0:4] * np.array([w, h, w, h])\n            x_center, y_center, box_width, box_height = box_current.astype('int')\n            x_min = int(x_center-(box_width\/2))\n            y_min = int(y_center-(box_height\/2))\n            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n            confidences.append(float(confidence_current))\n            class_numbers.append(class_current)\n\nprint(class_numbers[-1])                  \nprint(labels[class_numbers[-1]])            ","4f8eb2ee":"results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n\nif len(results) > 0:\n    for i in results.flatten():\n        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n        colour_box_current = [int(j) for j in colours[class_numbers[i]]]\n        cv2.rectangle(image_input, (x_min, y_min), (x_min + box_width, y_min + box_height),\n                      colour_box_current, 5)\n        text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])], confidences[i])\n        cv2.putText(image_input, text_box_current, (x_min, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX,\n                    1.5, colour_box_current, 5)","a99bc4dc":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (8,8)\nplt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","7633b191":"def ImagePath(path):\n    \n    bounding_boxes = []\n    confidences = []\n    class_numbers = []\n    \n    image_input = cv2.imread(path)\n    blob = cv2.dnn.blobFromImage(image_input, 1\/255.0, (416,416), swapRB=True, crop=False)\n    blob_to_show = blob[0,:,:,:].transpose(1,2,0)\n    network.setInput(blob)\n    output_from_network = network.forward(layers_names_output)\n    h,w = image_input.shape[:2]\n\n    for result in output_from_network:\n        for detection in result:\n            scores = detection[5:]\n            class_current = np.argmax(scores)\n            confidence_current = scores[class_current]\n            if confidence_current > probability_minimum:\n                box_current = detection[0:4] * np.array([w, h, w, h])\n                x_center, y_center, box_width, box_height = box_current.astype('int')\n                x_min = int(x_center-(box_width\/2))\n                y_min = int(y_center-(box_height\/2))\n                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n                confidences.append(float(confidence_current))\n                class_numbers.append(class_current)\n\n    %matplotlib inline\n    plt.rcParams['figure.figsize'] = (8,8)\n    plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n    plt.show()\n    \n    labels2=[]\n    for item in sorted(set(class_numbers)):\n        labels2+=[labels[item]]\n        \n    return labels2","af873153":"ImagePath(paths[50])","3be78aac":"tobjects=[]\n\ndef ExtractImage(path, show=False):\n    \n    bounding_boxes = []\n    confidences = []\n    class_numbers = []\n\n    image_input = cv2.imread(path)\n    blob = cv2.dnn.blobFromImage(image_input, 1\/255.0, (416,416), swapRB=True, crop=False)\n    blob_to_show = blob[0,:,:,:].transpose(1,2,0)\n    network.setInput(blob)\n    output_from_network = network.forward(layers_names_output)\n    h,w = image_input.shape[:2]\n\n    for result in output_from_network:\n        for detection in result:\n            scores = detection[5:]\n            class_current = np.argmax(scores)\n            confidence_current = scores[class_current]\n            if confidence_current > probability_minimum:\n                box_current = detection[0:4] * np.array([w, h, w, h])\n                x_center, y_center, box_width, box_height = box_current.astype('int')\n                x_min = int(x_center-(box_width\/2))\n                y_min = int(y_center-(box_height\/2))\n                \n                if x_min<0:\n                    x_min=0\n                if y_min<0:\n                    y_min=0\n                \n                obj=image_input[int(y_min):int(y_min+box_height),int(x_min):int(x_min+box_width)]\n              \n                obj1 = Image.fromarray(np.uint8(obj))\n                obj2 = np.asarray(obj1.resize((64,64)))\/255.0 \n                tobjects.append(obj2)\n\n                if show:\n                    _ = plt.figure(figsize=(3,3))\n                    _ = plt.xticks([])\n                    _ = plt.yticks([])\n                    _ = plt.imshow(cv2.cvtColor(obj, cv2.COLOR_BGR2RGB))\n\n    return None","a1f35b90":"ExtractImage(paths[50],show=True)","e1878375":"print(len(paths))","7e8b93ac":"for i in tqdm(range(len(paths))):\n    ExtractImage(paths[i],show=False)","2220ba02":"tobjects_ar=np.array(tobjects)\nprint(tobjects_ar.shape)\nnp.save('tobjects',tobjects_ar)","ecb5990e":"# loaded_ar=np.load('tobjects.npy')\n# print(loaded_ar.shape)","b6cd7e8f":"fig,axs = plt.subplots(3,3,figsize=(14,14))\nfor i in range(9):\n    r=i\/\/3\n    c=i%3\n    axs[r][c].set_xticks([])\n    axs[r][c].set_yticks([])\n    ax=axs[r][c].imshow(cv2.cvtColor(tobjects[num0[i]].astype('float32'),cv2.COLOR_BGR2RGB))\nplt.show()","1097a63f":"# Set rectangle at detected area","a9979726":"# Extract rectangle image","7d4d098b":"# Output detected object","50fe03ee":"# Show images"}}