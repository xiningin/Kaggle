{"cell_type":{"60e08a65":"code","169e047f":"code","70734434":"code","4e951720":"code","a1ebc0b0":"code","d852bba1":"code","7591058c":"code","4dfae760":"code","1f3d7eb2":"code","b41cbbfc":"code","b9561c9d":"code","b33e903f":"code","f3d07acc":"code","8be64251":"code","ef365e98":"code","19e517a9":"code","fc58862b":"code","cdd8f592":"code","54b44df7":"code","5cd30475":"code","de93d5ca":"code","c2659ec2":"code","c437a1d5":"code","a968580e":"code","788121f5":"code","a53250a9":"markdown","8ba4e6d7":"markdown","e7c78a65":"markdown","c1d4b9fc":"markdown","da48c4ee":"markdown","bfe7d8dc":"markdown","23ee3672":"markdown","1daef8fa":"markdown","222dd185":"markdown","ff15c1b6":"markdown","50924c10":"markdown","9d192742":"markdown","e4e7412e":"markdown","27e075ec":"markdown","e2ed73dd":"markdown","cd4aa5b0":"markdown","f43405f5":"markdown"},"source":{"60e08a65":"import numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport time\nfrom typing import Tuple, Optional, Dict\n\n# DEAP\nfrom deap import base, creator, tools, algorithms\n\n# OR-TOOLS\nfrom ortools.linear_solver import pywraplp\n\nnp.random.seed(seed=42)\nrandom.seed(a=42)","169e047f":"def fitness_of(genotype: np.ndarray) -> float:\n    \"\"\"\n    Evaluates the fitness of a genotype.\n    \n    If a genotype is not feasible (excedes the capacity of the knapsack)\n    it fitness is zero.\n    \n    Note: maybe better penalize the violation so that a \n    \"slightly\" infieasible solution is not equal to a \n    higly infeasible solution.\n    \n    :param genotype:\n        the genotype for which you want to evaluate the fitness\n        \n    :return: the fitness value of the genotype\n    \"\"\"\n    is_feasible = (genotype*weights).sum() <= capacity\n    if is_feasible:    \n        return (genotype*values).sum()\n    else:\n        return 0.0","70734434":"def cross_over(father: np.ndarray, mother: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Implements a One Point Crossover over two individuals.\n    \n    Generates two sons, with inverted heredity\n    \n    :param father:\n        the first individual to cross\n    :param mother:\n        the second individual to cross\n        \n        \n    :return: first son(father|mother), second son(mother|father), when crossover happened\n    \"\"\"\n    cross_point = np.random.randint(len(father)+1)\n    son1 = np.append(father[:cross_point], mother[cross_point:])\n    son2 = np.append(mother[:cross_point], father[cross_point:])\n\n    return son1, son2, cross_point","4e951720":"def selection(population: np.ndarray, fitness: np.ndarray, taboo:Optional[int]=None) -> int: \n    \"\"\"\n    Implements the Roulette Wheel Selection over a population.\n    \n    :param population:\n        the population from which select the individual\n    :param fitness:\n        the fitness of each individual in the population\n    :param taboo:\n        if not None, an index of an individual that can not be selected\n    \n    :return: the index of the indivual selected\n    \"\"\"\n    f_copy = np.copy(fitness)\n    f_copy = np.clip(f_copy, 0, None)\n    if taboo is not None:\n        f_copy[taboo] = 0\n    r = np.random.uniform(0, f_copy.sum())    \n    for x in range(len(fitness)):\n        if f_copy[:x+1].sum() > r:\n            return x\n    \n    # Pick a random individual\n    return random.sample([i_ for i_ in range(len(population)) if taboo == None or not i_ == taboo], 1)[0]","a1ebc0b0":"def replace_individual(x:int, new_ind: np.ndarray, population: np.ndarray, age: np.ndarray, fitness: np.ndarray):\n    \"\"\"\n    Replaces an individual of a population with a new one.\n    \n    Kind of simulate the death of a individual.\n    \n    :param x:\n        the position in the population of the individual to replace\n    :param new_ind:\n        the new genotype to welcome in the population\n    :param population:\n        the population in which the replacement must be done\n    :param age:\n        the age of each individual in the population\n    :param fitness:\n        the fitness of each individual in the population\n    \"\"\"\n    population[x] = new_ind\n    age[x] = 0\n    fitness[x] = fitness_of(population[x])","d852bba1":"def mutate_drop(genotype: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Mutation that drops a item from the knapsack.\n    \n    Tends to fix infeasibility issues.\n    \n    Note: it can be implemented in a more efficient way by avoiding\n    the calculation of fitness_function in the while condition.\n    \n    :param genotype:\n        a genotype to mutate\n        \n    :return: \n        the mutated genotype\n    \"\"\"\n    while fitness_of(genotype) <= 0.0001 and genotype.sum() > 0:        \n        x_ = random.sample(list(np.argwhere(genotype == 1)), 1)[0]\n        genotype[x_] = 0\n    return genotype \n\ndef mutate_pop(genotype: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Mutation that adds item to the genotype.\n    \n    If population has very few items, crossovoer will have hard\n    time in increasing this number. This mutation may help newborn to have\n    more items in their knapsack.\n    \n    This is similar to the improve function of\n    [Gunther R. Raidl, An Improved Genetic Algorithm for the Multiconstrained\n    0\u20131 Knapsack Problem]. \n    \n    Note: it can be implemented in a more efficient way by avoiding\n    the calculation of fitness_function in the while condition.\n    \n    :param genotype:\n        a genotype to mutate\n        \n    :return: \n        the mutated genotype\n    \"\"\"\n    def small_enough_items(genotype) -> list():\n        \"\"\" Gets the items that are small enough to be added to a solution \"\"\"\n        residual_cap = capacity - (genotype*weights).sum()\n        return np.argwhere((weights < residual_cap) & (genotype == 0))\n    \n    smallies = small_enough_items(genotype)\n    while len(smallies) > 0:        \n        x_ = random.sample(list(smallies), 1)[0]\n        genotype[x_] = 1\n        smallies = small_enough_items(genotype)\n            \n    return genotype \n    \n    \n    if genotype.sum() < len(genotype):\n        genotype[random.sample(list(np.argwhere(genotype == 0)), 1)[0]] = 1\n    return genotype \n\ndef mutate_switch(genotype: np.ndarray, likelihood: np.ndarray= None) -> np.ndarray:\n    \"\"\"\n    Mutation that pops an item and adds an another one. Pretty much \n    similar to Bit Flip Mutation\n    \n    If population has very few items, crossovoer will have hard\n    time in increasing this number. This mutation may help.\n    \n    This is a repair function similar to the one in \n    [Gunther R. Raidl, An Improved Genetic Algorithm for the Multiconstrained\n    0\u20131 Knapsack Problem]. \n    \n    Note: it can be implemented in a more efficient way by avoiding\n    the calculation of fitness_function in the while condition.\n    \n    :param genotype:\n        a genotype to mutate\n    :param likelihood:\n        (optional) a numpy array stating the likelihood of each gene to be in the \n        optimal solution, if None a random flip mutation will be actuated\n        \n    :return: \n        the mutated genotype\n    \"\"\"\n    if genotype.sum() > 0 and genotype.sum() < len(genotype):\n        items_in = list(np.argwhere(genotype == 1))\n        items_out = list(np.argwhere(genotype == 0))\n                             \n        if likelihood is None:\n            from_x = random.sample(items_in, 1)[0]\n            to_x = random.sample(items_out, 1)[0]\n        else:\n            # Higher probability to remove items with less likelihood\n            from_x = selection(items_in, np.take(1\/likelihood, items_in))\n            # Higher probability to insert items with more likelihood\n            to_x = selection(items_out, np.take(likelihood, items_out))\n        \n        to_gene = genotype[to_x]\n        #print(f\"{from_x}-{to_x}\")\n        genotype[to_x] = genotype[from_x]\n        genotype[from_x] = to_gene\n\n    return genotype","7591058c":"def print_generation(generation, population, fitness):\n    print(f\"--- Population at generation {str(generation)} ---\")\n    for i_ in range(len(population)):\n        print(f\"{i_}: {population[i_]} => {fitness[i_]}\")","4dfae760":"def GA(population_0: np.ndarray, n_iterations: int, \n       mutation_p: float, mates_p: float,       \n       do_pop_mutation: bool,\n       pop_max_age: int,\n       do_drop_mutation: bool,\n       do_switch_mutation: bool,\n       do_weighted_switch_mutation: bool,\n       print_evolution: bool) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Implements a naive genetic algorithm.\n    \n    Relies on the existance of some global variables (I know..., I know...):      \n        capacity:\n             Capacity of the knapsack\n        values:\n            Value associated to each item, to be maximized in the o.f.\n        weights:\n            Weight of each item, the sum must not exceed the capacity\n        n_genes:\n            Number of items that can be selected = number of genes in a individual\n    \n    :param population_0:\n        the initial population\n    :param n_iterations:\n        the number of iterations to perform (the only implemented stopping criteria)\n    :param mutation_p:\n        the mutation probability, For example, 0.2 measn that a (feasible) individual\n        have a probability of 20% to be mutated\n    :param mates_p:\n        the expected number of mates each generation as percentage of total population.\n        E.g.: 0.2 => 20%, if population has 10 individual then on average will mate 2 \n        pairs of them. Each mate generates two twins\n    :param do_pop_mutation:\n        Perform pop mutation\n    :param pop_max_age:\n        Max age for pop mutation\n    :param do_drop_mutation:\n        Perform drop mutation\n    :param do_switch_mutation:\n        Perform switch mutation    \n    :param do_weighted_switch_mutation:\n        Switch mutation is \"weighted\"\n    :param print_evolution:\n        if True, detailed evolution parameters are printed on-the-go\n        \n    :return: \n        - the fitting of the best individual of the population alive in each iteration,\n        - the average fitting of a population alive in each iteration,\n        - the fitting of the \"chosen one\", the most fitting individual existed up to a given\n        iteration, for each iteration\n        - the population existing at the last iteration    \n    \"\"\"\n    population = np.copy(population_0)\n    \n    n_individuals = len(population)\n    \n    age = np.zeros(n_individuals) \n\n    best_of_generation = np.zeros(n_iterations)\n    average_of_generation = np.zeros(n_iterations)\n    chosen_one_at_gen = np.zeros(n_iterations)\n\n    fitness = np.asarray([fitness_of(x) for x in population])\n    chosen_one = None\n    for i in range(n_iterations):\n        #fitness = np.asarray([fitness_of(x) for x in population])\n        \n        if print_evolution:\n            print_generation(i, population, fitness)\n            \n        if chosen_one is None or fitness.max() > fitness_of(chosen_one):\n            chosen_one = np.copy(population[np.argmax(fitness)])\n\n        # Update counters for plotting\n        best_of_generation[i] = fitness.max()\n        average_of_generation[i] = fitness.mean()\n        chosen_one_at_gen[i] = fitness_of(chosen_one)\n\n        age = age + 1 \n        for mate in range(int(n_individuals*mates_p) + 1):\n            if fitness.sum() > 0.00001:\n                # Select who is going to reproduce itself\n                father_x = selection(population, fitness)\n                mother_x = selection(population, fitness, father_x)\n                son1, son2, cross_point = cross_over(population[father_x], population[mother_x])\n\n                # Select two elders that are going to die\n                older1_x = selection(population, age)\n                older2_x = selection(population, age, older1_x)\n                \n                # Replace the individuals\n                replace_individual(older1_x, son1, population, age, fitness)\n                replace_individual(older2_x, son2, population, age, fitness)\n                \n                if print_evolution:\n                    print(f\"Crossing: {father_x} + {mother_x} ({cross_point}) => {son1}, {son2} in {older1_x},{older2_x} \")\n        \n        # Mutations\n        if do_weighted_switch_mutation:\n            likelihood = values\/weights\n        \n        for g in range(n_individuals):\n            # Common mutation on \"sane\"  individuals\n            if do_switch_mutation:\n                if(np.random.uniform() < mutation_p): \n                    if print_evolution:\n                        before = np.copy(population[g])\n                        \n                    if do_weighted_switch_mutation:\n                        population[g] = mutate_switch(population[g], likelihood)\n                    else:\n                        population[g] = mutate_switch(population[g])\n                        \n                    fitness[g] = fitness_of(population[g])\n                    if print_evolution:\n                        print(f\"Switch-mutation of {g}: {before} => {population[g]}\")\n                        \n            # Mutation on newborn\n            if do_pop_mutation:\n                if age[g] <= pop_max_age:\n                    if print_evolution:\n                        before = np.copy(population[g])\n                    population[g] = mutate_pop(population[g])\n                    fitness[g] = fitness_of(population[g])\n                    if print_evolution:\n                        print(f\"Pop-mutation of {g}: {before} => {population[g]}\")\n            \n            # Mutation on infeasible individuals\n            if do_drop_mutation:\n                if fitness[g] <= 0.00001:\n                    if print_evolution:\n                        before = np.copy(population[g])\n                    population[g] = mutate_drop(population[g])\n                    fitness[g] = fitness_of(population[g])\n                    if print_evolution:\n                        print(f\"Drop-mutation of {g}: {before} => {population[g]}\")\n                \n    return best_of_generation, average_of_generation, chosen_one_at_gen, population","1f3d7eb2":"def run_and_plot(population_0: np.ndarray, n_iterations: int, \n                 mutation_p: float, mates_p: float,\n                 do_pop_mutation: bool,\n                 pop_max_age: int,\n                 do_drop_mutation: bool,\n                 do_switch_mutation: bool,\n                 do_weighted_switch_mutation: bool,\n                 subplot_rows= 1, subplot_cols=1, subplot_index=1):\n    \"\"\"\n    Runs a GA algorithm starting from a population \"0\" and plot the behaviour of main kpis on a subplot\n    \n    :param population_0:\n        the initial population\n    :param n_iterations:\n        the number of iterations to perform (the only implemented stopping criteria)\n    :param mutation_p:\n        the mutation probability, For example, 0.2 measn that a (feasible) individual\n        have a probability of 20% to be mutated\n    :param mates_p:\n        the expected number of mates each generation as percentage of total population.\n        E.g.: 0.2 => 20%, if population has 10 individual then on average will mate 2 \n        pairs of them. Each mate generates two twins\n    :param do_pop_mutation:\n        Perform pop mutation\n    :param pop_max_age:\n        Max age for pop mutation\n    :param do_drop_mutation:\n        Perform drop mutation\n    :param do_switch_mutation:\n        Perform switch mutation    \n    :param do_weighted_switch_mutation:\n        Switch mutation is \"weighted\"\n    :param subplot_rows:\n        subplot rows in the plot\n    :param subplot_cols:\n        subplot columns in the plot\n    :param subplot_index:\n        index of this subplot in the plot\n    \"\"\"\n    x_axes = tuple([i for i in range(n_iterations)])\n    print_evolution = False\n    best_of_generation, average_of_generation, chosen_one_at_gen, _ = GA(population_0, n_iterations,\n                                                                         mutation_p, mates_p,\n                                                                         do_pop_mutation,\n                                                                         pop_max_age,\n                                                                         do_drop_mutation,\n                                                                         do_switch_mutation,\n                                                                         do_weighted_switch_mutation,\n                                                                         False)\n    solution = chosen_one_at_gen[n_iterations-1]\n    plt.subplot(subplot_rows, subplot_cols, subplot_index)\n    plt.plot(x_axes, tuple(best_of_generation))\n    plt.plot(x_axes, tuple(chosen_one_at_gen))\n    plt.plot(x_axes, tuple(average_of_generation))\n    plt.title(f\"its:{n_iterations}, mut_p:{mutation_p}, inds:{len(population_0)}, mates:{mates_p} \" \n              + f\"=> {solution} : gap: {0 if opt is None else (opt - solution)*100\/opt:.2f}%,\"\n              + f\"Pop:{str(do_pop_mutation)}: {pop_max_age}, \"\n              + f\"Drop:{str(do_drop_mutation)}, \"\n              + f\"Switch:{str(do_switch_mutation)}\/{str(do_weighted_switch_mutation)}\")","b41cbbfc":"# Location of instance files\ndef load_instance(instance_dir, instance) -> Tuple[float, np.ndarray, np.ndarray,\n                                                   float, int, Dict[int, Tuple[float, float]]]:\n    \"\"\"\n    Loads and parse a Pisinger knapsack instance\n    \n    :param instance_dir:\n        the path to folder where instances are\n    :param instance:\n        the name of the instance to load from instance dir\n    \n    :return:\n        A tuple with:\n        - Capacity of the knapsack: int\n        - Value associated to each item: np.ndarray\n        - Weight of each item np.ndarray\n        - Number of items that can be selected = number of genes in a individual: int\n        - Optimal solution value: int\n        - Items: DEAP input dict with the population: Dict\n    \n    \"\"\"\n    items = np.genfromtxt(instance_dir + instance + \"_items.csv\", delimiter=',',skip_header=1)\n    info = np.genfromtxt(instance_dir + instance + \"_info.csv\", delimiter=',')\n\n    # Capacity of the knapsack\n    capacity = info[1, 1]\n\n    # Value associated to each item\n    values = items.astype(int)[:, 1]\n\n    # Weight of each item\n    weights = items.astype(int)[:, 2]\n\n    # Number of items that can be selected = number of genes in a individual\n    n_genes = len(values)\n\n    # Optimal solution value\n    opt = info[2, 1]\n    \n    # This dict is useful for DEAP\n    # Create the item dictionary: item name is an integer, and value is \n    # a (weight, value) 2-uple.\n    items = {}\n    # Create random items and store them in the items' dictionary.\n    for i in range(n_genes):\n        items[i] = (weights[i], values[i])   \n\n    \n    return capacity, values, weights, opt, n_genes, items","b9561c9d":"# Load Instance\ncapacity, values, weights, opt, n_genes, items = load_instance(\n    '..\/input\/kp01pisinger\/', \n    'knapPI_1_500_1000_1')","b33e903f":"# Setup an initial population\npopulation_0 = np.random.randint(2, size=[100, n_genes])","f3d07acc":"# Make plottings a little bit bigger\nplt.rcParams['figure.figsize'] = [20,10]","8be64251":"# Execute and plot the behaviour\nrun_and_plot(population_0, n_iterations=200, mutation_p=0.3, mates_p=0.5, \n             do_pop_mutation=True, pop_max_age=100, do_drop_mutation=True, \n             do_switch_mutation=False,\n             do_weighted_switch_mutation=False)\nplt.show()","ef365e98":"run_and_plot(population_0, n_iterations=200, mutation_p=0.3, mates_p=0.5, \n             do_pop_mutation=True, pop_max_age=100, do_drop_mutation=True, \n             do_switch_mutation=True,\n             do_weighted_switch_mutation=True)\nplt.show()","19e517a9":"if False:\n    best_of_generation, average_of_generation, chosen_one_at_gen, population = GA(\n        population_0, n_iterations=10, mutation_p=0.2, mates_p=0.2, \n        do_pop_mutation=True, pop_max_age=100, do_drop_mutation=True, \n        do_switch_mutation=False,\n        do_weighted_switch_mutation=False,\n        print_evolution=True)","fc58862b":"def optimize() -> Tuple[np.ndarray, float]:\n    \"\"\"\n    Solves the loaded instance to optimality using general purpose solver:\n    \n    Relies on the existance of same global variables as GA:\n        capacity:\n             Capacity of the knapsack\n        values:\n            Value associated to each item, to be maximized in the o.f.\n        weights:\n            Weight of each item, the sum must not exceed the capacity\n        n_genes:\n            Number of items that can be selected = number of genes in a individual\n    \n    :return:\n        - x_sol: the optimal solution\n        - obj_val: the value of the optimal solution\n    \n    \"\"\"\n    program = pywraplp.Solver('KP01', pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n    x = np.zeros(n_genes).astype(pywraplp.Variable)\n\n    # Generate variables\n    for i in range(n_genes):\n        x[i] = program.BoolVar(f'x{str(i)}')\n\n    # Add objective function\n    program.Maximize((x*values).sum())\n\n    # Add constraint\n    program.Add((x * weights).sum() <= capacity, \"c10\")\n\n    # Optimize\n   \n    status = program.Solve()\n    \n\n    # Get objective\n    obj_val = program.Objective().Value()\n    \n\n    # Print solution\n    x_sol = np.asarray([x[i].solution_value() for i in range(n_genes)])\n\n    return x_sol, obj_val","cdd8f592":"tstart = time.time()\nx_sol, obj_val = optimize()\nsolve_time = time.time() - tstart\nprint(f\"Solve time={solve_time}\")\nprint(str(obj_val))","54b44df7":"# Create classes\ncreator.create(\"Fitness\", base.Fitness, weights=(-1.0, 1.0))\ncreator.create(\"Individual\", set, fitness=creator.Fitness)\n    \n# Set initial population\ntoolbox = base.Toolbox()\ntoolbox.register(\"attr_item\", random.randrange, n_genes)\ntoolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n    toolbox.attr_item, 100)\ntoolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n\n# Define the evaluation function\ndef evalKnapsack(individual):\n    weight = 0.0\n    value = 0.0\n    for item in individual:\n        weight += items[item][0]\n        value += items[item][1]\n    if weight > capacity:\n        return 10000, 0             # Ensure overweighted bags are dominated\n    return weight, value\n\ndef cxSet(ind1, ind2):\n    \"\"\"Apply a crossover operation on input sets. The first child is the\n    intersection of the two sets, the second child is the difference of the\n    two sets.\n    \"\"\"\n    temp = set(ind1)                # Used in order to keep type\n    ind1 &= ind2                    # Intersection (inplace)\n    ind2 ^= temp                    # Symmetric Difference (inplace)\n    return ind1, ind2\n\ndef mutSet(individual):\n    \"\"\"Mutation that pops or add an element.\"\"\"\n    if random.random() < 0.5:\n        if len(individual) > 0:     # We cannot pop from an empty set\n            individual.remove(random.choice(sorted(tuple(individual))))\n    else:\n        individual.add(random.randrange(n_genes))\n    return individual,\n\n\ntoolbox.register(\"evaluate\", evalKnapsack)\ntoolbox.register(\"mate\", cxSet)\ntoolbox.register(\"mutate\", mutSet)\ntoolbox.register(\"select\", tools.selNSGA2)","5cd30475":"# Get best solution\ndef get_best_DEAP_sol(hof):\n    best = None\n    for i_ in hof.items:\n        fit = i_.fitness.values[1]\n        if best is None or fit > best:\n            best = fit    \n    return best","de93d5ca":"NGEN = 200  # Numbe rof generations\nMU = 100  # Number of individual in initial population\nLAMBDA = 100  # The number of children to produce at each generation.\nCXPB = 0.7  # The probability that an offspring is produced by crossover.\nMUTPB = 0.2  # The probability that an offspring is produced by mutation.\n\npop = toolbox.population(n=MU)\nhof = tools.ParetoFront()\nstats = tools.Statistics(lambda ind: ind.fitness.values)\nstats.register(\"avg\", np.mean, axis=0)\nstats.register(\"std\", np.std, axis=0)\nstats.register(\"min\", np.min, axis=0)\nstats.register(\"max\", np.max, axis=0)\n\nfinal_pop = algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, NGEN, stats,\n                          halloffame=hof, verbose=False)","c2659ec2":"best = get_best_DEAP_sol(hof)\nprint(f\"Best solution value is {best} : gap: {(opt - best)*100\/opt:.2f}%,\" )","c437a1d5":"NGEN = 1800  # Perform more iterations starting from the previous results\nfinal_pop = algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, NGEN, stats,\n                          halloffame=hof, verbose=False)","a968580e":"best = get_best_DEAP_sol(hof)\nprint(f\"Best solution value is {best} : gap: {(opt - best)*100\/opt:.2f}%,\" )","788121f5":"# Load Instance\nfor inst in ['knapPI_1_500_1000_1', 'knapPI_2_500_1000_1', 'knapPI_3_500_1000_1', 'knapPI_14_200_1000_1']:\n    capacity, values, weights, opt, n_genes, items = load_instance(\n        '..\/input\/kp01pisinger\/', \n        inst)\n    \n    # Mine\n    population_0 = np.random.randint(2, size=[100, n_genes])    \n    tstart = time.time()\n    best_of_generation, average_of_generation, chosen_one_at_gen, population = GA(\n        population_0, n_iterations=200, mutation_p=0.3, mates_p=0.5, \n        do_pop_mutation=True, pop_max_age=100, do_drop_mutation=True, \n        do_switch_mutation=True,\n        do_weighted_switch_mutation=True,\n        print_evolution=False)    \n    solve_time = time.time() - tstart\n    best = chosen_one_at_gen[199]    \n    print(f\"{inst}:\\tMine:\\tbest solution value is {best} : gap: {(opt - best)*100\/opt:.2f}%, Solve time={solve_time:.2f}s\" )    \n    \n    # DEAP\n    NGEN = 2000  # Perform more iterations starting from the previous results\n    \n    toolbox.register(\"attr_item\", random.randrange, n_genes)\n    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n        toolbox.attr_item, 100)\n    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n    pop = toolbox.population(n=MU)\n    hof = tools.ParetoFront()\n    tstart = time.time()    \n    algorithms.eaMuPlusLambda(pop, toolbox, MU, LAMBDA, CXPB, MUTPB, NGEN, stats,\n                          halloffame=hof, verbose=False)\n    solve_time = time.time() - tstart\n    best = get_best_DEAP_sol(hof)\n    print(f\"{inst}:\\tDEAP:\\tbest solution value is {best} : gap: {(opt - best)*100\/opt:.2f}%, Solve time={solve_time:.2f}s\" )    \n    \n    # OR-Tools\n    tstart = time.time()\n    _, best = optimize()\n    solve_time = time.time() - tstart\n    print(f\"{inst}:\\tOR-TOOLS:\\tbest solution value is {best} : gap: {(opt - best)*100\/opt:.2f}%, Solve time={solve_time:.2f}s\" )    \n    \n    print(\"-------\")","a53250a9":"## Conclusions","8ba4e6d7":"Activate this code to have a detailed log of what is going on at every iteration","e7c78a65":"The simple \"from scratch\" implementation of GA for KP01 (let's call it \"mine\" implementation) performs better than the general purpose DEAP implementation when only a limited number of iterations. On the long run DEAP strongly outperform the mine GA, with some exeptions.\n\nA generic and open implementation of the B&C (+heuristics) performs strongly better than both mine and DEAP GA implementations.","c1d4b9fc":"## Have a deep look on what is going on","da48c4ee":"## Tests over other instances","bfe7d8dc":"I compared the results turning on\/off the different types of mutations, with a population of 100 or 1000 individuals, and some values between 100 to 1000 for max generations number. For what concerns the swap mutation I compared several different values of mutation_p from 0.05 to 0.4, combined with different values of mates_p. I performed this tests over a *single* instance from the Pisinger set, the 'knapPI_1_500_1000_1' so this might not be the best configuration in general. All plotting are omitted for the sake of synthesis, I report here some considerations:\n\n#### Drop\nSince we allowed the initial population to be potentially infeasible, the drop mutation is necessary to create at least\na feasible individual when population 0 has none: must have.\n\n#### Switch\nLooks like is not producing anything good: turn off.\n\n#### Pop\nSpeeds up the search, generally a pretty good solution is obtained much faster with this mutation active. It also improves the overall quality of the solutions on the long run: must have.\n\n#### Generations\nIncreasing the number of generations over 200 does not realy help. \n\nSince the algorithm depends on the original population, it is a good idea to measure or at least watch the plots of several different executions. \n\nThe best results for the best configuration are the following.","23ee3672":"## Exact approach with general purpose optimization software","1daef8fa":"## Results","222dd185":"# Genetic algorithms for 0-1 Knapsack Problem: a simple implementation","ff15c1b6":"We actually can manipulate the mutation process in a \"problem-specific way\". Since we know that items with high \"value\/weight\" are more likely to be in the optimal solution, we can use this \"likelihood\" value to pilot the selection. We can use the same Roulette Wheel we used for selection and obtain better results.","50924c10":"Note also that the best solution is obtained with very hight mate_p values: 50% means, roughly speaking, that a number of individuals equal to the overall population is produced every generation. This means that the algorithm strongly relies on the crossing to replace unfitting individuals.","9d192742":"## Run DEAP","e4e7412e":"I basically followed the example provided by the DEAP team. Just removed the condition \"len(individual) > MAX_ITEM\" in evalKnapsack() as is not part of the KP01 general formulation.\n\nThe main differences between this methods and mine above is:\n    - a multiple fitness function, in DEAP we give high fitness scores to individual that have an high value *and* a low weight. \n    - selection on a given generation is performed over from both the offspring and the (mutated) population\n    - the offspring of crossover operations will see only the first child surviving","27e075ec":"In this notebook:\n- I propose a simple implementation of a Genetic Algorithm (GA) for the 0-1 Knapsack Problem (KP01), following the instructions provided in https:\/\/www.tutorialspoint.com\/genetic_algorithms\/genetic_algorithms_survivor_selection.htm, adding here and there some personal prior knowledge.\n\n- I present the results of such simple implementation obtained over some of the \"Pisinger\" KP01 instances (a well-known benchmark instance-set, see http:\/\/hjemmesider.diku.dk\/~pisinger\/codes.html).\n\n- I compare such results with the ones obtained using an open source implementation of general purpose techniques, i.e.: Branch And Cut implementation of Google OR-Tools (https:\/\/developers.google.com\/optimization\/mip\/mip), and with an open source implementation of Genetic Algorithm (DEAP: https:\/\/deap.readthedocs.io\/en\/master\/overview.html, and https:\/\/deap.readthedocs.io\/en\/master\/examples\/ga_knapsack.html for ready to use knapsack example)","e2ed73dd":"This indicates the fact that some ad-hoc alteration of the random mutation process may improve the results of the evolution process, so I incidentally demonstrated here the existence of God.","cd4aa5b0":"## Simple Genetic Algorithm implementation from scratch","f43405f5":"## Run GA over an instance\nInstances for this notebook are taken from the Pisinger Knapsack01 instance set available in http:\/\/hjemmesider.diku.dk\/~pisinger\/codes.html. Since the original format is not actually a csv, I adapted it manually for some of these instance so that they can be loaded easily.\n\nHere I discuss the result for one these instances."}}