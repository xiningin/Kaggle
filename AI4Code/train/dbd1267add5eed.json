{"cell_type":{"099537a0":"code","5ea39a4f":"code","38abfdc8":"code","ebe404db":"code","7237f22b":"code","0f23399b":"code","e27fc0f3":"code","921cdadb":"code","181f4631":"code","9f26276f":"code","84ef0f84":"code","ff59e3a0":"code","760dd10c":"code","3066d3e9":"code","5c72fc8d":"code","529fd795":"code","280a541d":"code","d588e236":"code","1a9a8608":"code","cf6365bf":"code","9f6b8af7":"code","db721824":"code","8a93bb56":"code","7d368bae":"code","b0ebfedf":"code","1444f122":"code","b1e00b65":"code","da08a143":"code","d7fc891d":"code","63df9d07":"code","7baaae2b":"code","e04c9432":"code","f4e0dbd8":"code","54be102b":"code","1ed1b569":"code","a76e4686":"code","875f41c7":"code","9d6bfb49":"code","30e54355":"code","693cdae6":"code","c46f9315":"code","273c7ef2":"code","204eacb2":"code","d27288d4":"code","1c6d0f9d":"code","54e35d30":"code","ea2beb2e":"code","1d6ce508":"code","322d67e6":"code","9169e5d7":"code","e0527e07":"code","60aca240":"code","e1dc4c70":"code","889fd070":"markdown"},"source":{"099537a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5ea39a4f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Plotting\n%matplotlib inline\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (10,10) #Make the plots bigger by default\nplt.rcParams[\"lines.linewidth\"] = 2 #Setting the default line width\nplt.style.use(\"ggplot\")\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom datetime import datetime\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom tensorflow.keras.optimizers import RMSprop\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping , ReduceLROnPlateau\nfrom sklearn.metrics import mean_absolute_error\n\nimport warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","38abfdc8":"df = pd.read_csv('..\/input\/pfizer-stock-data\/PFE.csv')\ndf.head()","ebe404db":"df.isnull().sum()\n","7237f22b":"fig=make_subplots(specs=[[{\"secondary_y\":False}]])\nfig.add_trace(go.Scatter(x=df['Date'],y=df['Open'].rolling(window=7).mean(),name=\"PFIZER\"),secondary_y=False,)\nfig.update_layout(autosize=False,width=900,height=500,title_text=\"PFIZER\")\nfig.update_xaxes(title_text=\"year\")\nfig.update_yaxes(title_text=\"prices\",secondary_y=False)\nfig.show()","0f23399b":"df['Open'].plot(figsize=(12,8));\nplt.ylabel(\"open price\");","e27fc0f3":"df.plot(subplots=True, figsize=(20, 40))\nplt.show()","921cdadb":"df[\"Date\"]=pd.to_datetime(df.Date,dayfirst=True)\ndf.set_index(\"Date\",inplace=True)\ndf","181f4631":"df=df.asfreq(\"d\")\ndf = df.fillna(method  = \"bfill\")","9f26276f":"df['Total Pos'] = df.sum(axis=1)\n","84ef0f84":"df['Total Pos'].plot(figsize=(10,8))\nplt.title('Total Portfolio Value')","ff59e3a0":"df['Daily Return'] = df['Total Pos'].pct_change(1)\n","760dd10c":"df['Daily Return'].mean()\n","3066d3e9":"df['Daily Return'].plot(kind='kde')\n","5c72fc8d":"SR = df['Daily Return'].mean()\/df['Daily Return'].std()\n","529fd795":"all_plot = df\/df.iloc[0]\nall_plot.plot(figsize=(24,16))","280a541d":"df.hist(bins=100,figsize=(12,6));\nplt.tight_layout()","d588e236":"df.resample(rule='A').mean()\n","1a9a8608":"title = 'Yearly Mean Closing Price'\ndf['Open'].resample('A').mean().plot.bar(title=title,color=['#b41f7d'], figsize=(24,10));\nplt.plot(figsize=(30,40))","cf6365bf":"df['Open'].resample('M').max().plot.bar(figsize=(18,12),color='#1f77b4');\n","9f6b8af7":"ax = df['Open'].plot(figsize=(24,6),title=title)\n","db721824":"df['6-month-SMA'] = df['Open'].rolling(window=6).mean()\ndf['12-month-SMA'] = df['Open'].rolling(window=12).mean()\ndf['2-month-SMA'] = df['Open'].rolling(window=2).mean()","8a93bb56":"df.head(13)\n","7d368bae":"df[[\"Open\",\"6-month-SMA\",\"12-month-SMA\",\"2-month-SMA\"]].plot(figsize=(24,10));\n","b0ebfedf":"df[[\"Open\",\"6-month-SMA\"]].plot(figsize=(24,12));\n","1444f122":"df[['Open','6-month-SMA']].iloc[:400].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","b1e00b65":"df['EWMA12'] = df['Open'].ewm(span=14,adjust=True).mean()\n","da08a143":"df[['Open','EWMA12']].plot(figsize=(24,12));\n","d7fc891d":"df[['Open','EWMA12']].iloc[:720].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","63df9d07":"span = 8\nalpha = 2\/(span+1);","7baaae2b":"df['EWMA12'] = df['Open'].ewm(alpha=alpha,adjust=False).mean()\n","e04c9432":"model=SimpleExpSmoothing(df[\"Open\"])\n","f4e0dbd8":"model.fit(smoothing_level=alpha,optimized=False)\n","54be102b":"fitted_model=model.fit(smoothing_level=alpha,optimized=False)\n","1ed1b569":"fitted_model.fittedvalues\n","a76e4686":"fitted_model.fittedvalues.shift(-1)\n","875f41c7":"df[\"SES12\"]=fitted_model.fittedvalues.shift(-1)\n","9d6bfb49":"df[['Close',\"SES12\"]].plot(figsize=(30,15)).autoscale(axis='x',tight=True);\n","30e54355":"df['DESadd12'] = ExponentialSmoothing(df['Open'], trend='add').fit().fittedvalues.shift(-1)\ndf.head()","693cdae6":"df[['Open',  'SES12', 'DESadd12']].plot(figsize=(24,12))","c46f9315":"df[['Open','EWMA12','DESadd12']].iloc[:800].plot(figsize=(12,6)).autoscale(axis='x',tight=True);\n","273c7ef2":"data = df.filter(['Open'])\n\ndataset = data.values\n\ntraining_data_len = int(np.ceil( len(dataset) * .95 ))\n\ntraining_data_len","204eacb2":"scaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","d27288d4":"train_data = scaled_data[0:int(training_data_len), :]\n\nx_train = []\ny_train = []\n\nfor i in range(60, len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i, 0])\n    if i<= 61:\n        print(x_train)\n        print(y_train)\n        print()\n        \n\nx_train, y_train = np.array(x_train), np.array(y_train)\n\n\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))","1c6d0f9d":"    model = Sequential()    \n    model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1],1)))\n    model.add(Dropout(0.2))\n    model.add(LSTM(units = 40, return_sequences = True))\n    model.add(Dropout(0.2))\n    model.add(LSTM(units = 30, return_sequences = True))\n    model.add(Dropout(0.2))\n    model.add(LSTM(units = 20))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=1))\n    \n    model.compile(optimizer='adam', loss='mean_squared_error')\n    \n    model.summary()","54e35d30":"callbacks = [EarlyStopping(patience=3, monitor='val_loss', mode='min'), \n             ReduceLROnPlateau(patience=2, verbose=1)]  ","ea2beb2e":"history =model.fit(x_train, y_train, \n                        epochs=10,\n                        batch_size=128,\n                        callbacks=[callbacks],\n                        )","1d6ce508":"test_data = scaled_data[training_data_len - 60: , :]\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])\n    \n# Convert the data to a numpy array\nx_test = np.array(x_test)\n\n# Reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n\n# Get the models predicted price values \npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))","322d67e6":"mean_absolute_error(y_test, predictions)","9169e5d7":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n# Visualize the data\nplt.figure(figsize=(16,6))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Open Price USD ($)', fontsize=18)\nplt.plot(train['Open'])\nplt.plot(valid[['Open', 'Predictions']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\nplt.show()","e0527e07":"predictions = model.predict(x_test)\n","60aca240":"valid[['Open','Predictions']].iloc[:100].plot(figsize=(12,6)).autoscale(axis='x',tight=True);","e1dc4c70":"valid.head()\n","889fd070":"# LSTM MODEL\u00b6\u00b6\n"}}