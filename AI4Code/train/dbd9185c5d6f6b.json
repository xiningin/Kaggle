{"cell_type":{"a60174a3":"code","a59893f8":"code","06569fd7":"code","cddbe43f":"code","fe51e94d":"code","3b6f53d2":"code","ad54fb14":"code","de8c8747":"code","0640dd03":"code","6c3a3f27":"code","a8c49827":"code","16fbff29":"code","1ec08252":"markdown","ca6060ea":"markdown","5d21a2e8":"markdown","d0d1514a":"markdown","169a0206":"markdown","c9daa46c":"markdown"},"source":{"a60174a3":"# imports\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom scipy import stats, special\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import interpolate\nimport json\n\nimport traceback\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import lognorm\nfrom scipy.optimize import curve_fit\nimport string\nfrom scipy.integrate import quad\n\nfrom sklearn import mixture\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import SGDRegressor, LinearRegression, Lasso, Ridge, LogisticRegression\nfrom sklearn.base import clone\nfrom sklearn.pipeline import Pipeline, make_pipeline\n\nimport numpy as np\nimport pandas as pd\npd.options.display.float_format = '{:.2f}'.format\n\n# https:\/\/images.plot.ly\/plotly-documentation\/images\/python_cheat_sheet.pdf\n# https:\/\/www.apsnet.org\/edcenter\/disimpactmngmnt\/topc\/EpidemiologyTemporal\/Pages\/ModellingProgress.aspx\n","a59893f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","06569fd7":"def country_slice(df, country='China', province=''):\n    if province is None or pd.isna(province):\n        return df[(df['Country_Region']==country) & (pd.isna(df['Province_State']) == True) ]\n    else:\n        return df[(df['Country_Region']==country) & (df['Province_State']==province)]\n","cddbe43f":"train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv')\ntrain['Date'] = pd.to_datetime(train['Date'])\ntrain = train.sort_values(by=['Country_Region','Province_State','Date'])\ntrain['DailyConfirmedCases'] = train['ConfirmedCases'].diff()\ntrain['DailyFatalities'] = train['Fatalities'].diff()\ntrain['Province_State'] = [ v if not pd.isna(v) else '' for v in train['Province_State'] ]\ntrain['Days'] = (train['Date'] - min(train['Date'])).dt.days\ntrain_bak = train  # make a backup\n\n# replace negatives with a 0\n# train.query('DailyConfirmedCases < 0')\n# pd.isna( train.query('Country_Region==\"Algeria\" & Date==\"2020-03-25\"')['Province_State'] )\nfilter = train['DailyConfirmedCases']<0\ntrain.loc[filter,'DailyConfirmedCases'] = 0\ntrain.loc[filter,'DailyFatalities'] = 0\nfilter = np.isnan(train['DailyConfirmedCases'])\ntrain.loc[filter,'DailyConfirmedCases'] = 0\ntrain.loc[filter,'DailyFatalities'] = 0\n\ntrain.to_csv('train_daily.csv',index=False)\n\ntest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv')\ntest['Date'] = pd.to_datetime(test['Date'])\ntest['Province_State'] = [ v if not pd.isna(v) else '' for v in test['Province_State'] ]\ntest['Days'] = (test['Date'] - min(test['Date'])).dt.days\ntest\n\n# filter training data upto the test date\ntrain = train[train['Date']<min(test['Date'])]\n\nmin(test['Date'])\n\nsubmission = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/submission.csv')\nsubmission\n\n# countries with a Province\ntrain[train['Province_State'].isna()==False]\n\nprint(f'train days={max(train[\"Days\"])}, min_date={min(train[\"Date\"])}, max_date={max(train[\"Date\"])}')\nprint(f'test days={max(test[\"Days\"])}, min_date={min(test[\"Date\"])}, max_date={max(test[\"Date\"])}')\n","fe51e94d":"def fpoly(x, a, b, c):\n    return a*x**2 + b*x + c\n\ndef flinear(x, a, b, c):\n    return a*(x+b)+c\n\ndef fgauss(x,a,x0,sigma):\n    return a*np.exp(-(x-x0)**2\/(2*sigma**2))\n\ndef predict(fun, x, popts=None, scale=1.):\n    return scale * fun(x, *popts)","3b6f53d2":"# example\n# fun = fgauss\n# fun = flinear\nfun = fpoly\nmetric = 'DailyConfirmedCases'\ndf = country_slice(train, country='Afghanistan', province='')\ny = np.array(df[metric])\nx = np.array(range(len(y)))\nplt.plot(x,y,label=metric)\n# popts, pcov = curve_fit(fun,x,y,p0=[0.23709127,  32.24503999, -12.60506309])\npopts, pcov = curve_fit(fun,x,y)\nprint(popts)\n# plt.plot(x,fun(x,*popts))\nplt.plot(x,predict(fun,x,popts,scale=1.),label='scale 1')\nplt.plot(x,predict(fun,x,popts,scale=2.),label='scale 2')\nax = plt.gca()\nax.legend()","ad54fb14":"# example\n# fun = fgauss\n# fun = flinear\nfun = fpoly\ndf = country_slice(train, country='Bahamas')\ny = np.array(df['DailyConfirmedCases'])\nx = np.array(range(len(y)))\nplt.plot(x,y)\n# popts, pcov = curve_fit(fun,x,y,p0=[3851.107624, 20.45838, 6.834536])\npopts, pcov = curve_fit(fun,x,y)\nprint(popts)\nplt.plot(x,fun(x,*popts))","de8c8747":"# example\nfun = fgauss\n# fun = flinear\ndf = country_slice(train, country='China', province='Hubei')\ny = np.array(df['DailyConfirmedCases'])\nx = np.array(range(len(y)))\nplt.plot(x,y)\n# popts, pcov = curve_fit(fun,x,y,p0=[3851.107624, 20.45838, 6.834536])\npopts, pcov = curve_fit(fun,x,y,p0=[5000, 20, 10])\nprint(popts)\nplt.plot(x,fun(x,*popts))","0640dd03":"# train.query('DailyConfirmedCases>0').quantile([0.1, 0.25, 0.5, 0.75, 0.9])\nMEAN_MAX = 150\nMEAN_MIN = 10\nAMP_MAX_FATALITIES = 1000\nAMP_MAX_CASES = 10 * AMP_MAX_FATALITIES\nMIN_CASES = 100\n\ntry_params = [ None ]\nfor amp in [5000, 1000, 10]:\n    for x0 in [100, 70, 40, 20]:\n        for sd in [100, 40, 10]:\n            try_params.append([amp, x0, sd])\n            \n\ndef fit(x, y, metric):\n    fun   = fgauss\n    popts = None\n    p0    = None\n    x     = np.array(x)\n    y     = np.array(y)\n\n    try:\n        for fun in [fgauss, fpoly]:\n            for p0 in try_params:\n                try:\n                    amp = max(y)\n                    popts, _ = curve_fit(fun, x, y, p0=p0)\n                    if popts[0] < 1 or popts[1] < MEAN_MIN or popts[1] > MEAN_MAX:\n                        raise Exception\n                    elif metric == 'DailyConfirmedCases' and popts[0] > max(y) * 10:\n                        raise Exception\n                    elif metric == 'DailyFatalities' and popts[0] > max(y) * 10:\n                        raise Exception\n                    else:\n                        return popts, fun\n                except:\n                    pass\n    except Exception as e:\n        print(f'Something went wrong in fit, country={country}, province={province}, metric={metric}. {e}')\n        \n    return popts, fun\n\nmodels = dict()\nmodel_means = []\nmodel_amps = []\n# for i, row in list(train[['Country_Region','Province_State']].drop_duplicates().iterrows())[:10]:\nfor i, row in list(train[['Country_Region','Province_State']].drop_duplicates().iterrows()):\n    country = row[0]\n    province = row[1]\n    models[country + '_' + province] = dict()\n    for metric in ['DailyConfirmedCases', 'DailyFatalities']:\n        df = country_slice(train, country, province)\n        if df.empty:\n            raise Exception(f'Dataframe is empty')\n        y  = df[metric]\n        x  = range(len(y))\n        popts, fun = fit(x, y, metric)  \n        if popts is None:\n            print(f'country={country}, province={province} has popts={popts}')\n#         print(f'popts={popts}, fun={fun}, metric={metric}, country={country}, province={province}')\n        models[country + '_' + province][metric] = {'fun':fun, 'popts':popts } \n        if fun == fgauss:\n            model_amps.append(popts[0])\n            model_means.append(popts[1])\n    \n# models\nprint(f'{len(model_means)} {len(list(models.keys()))}')\nplt.plot(model_means, model_amps, 'b.')\nplt.yscale('log')\nplt.xlabel('Means')\nplt.ylabel('Amplitude')","6c3a3f27":"# SCALE = 2.  # scaling factor for predictions\nSCALE = 1.5\nMAX_RMSE = int(1e7)\n\ndef plot_fit_country(train, country='China', province='', fun=fgauss, popts=None, metric='DailyConfirmedCases'):\n    \n    tmp = country_slice(train, country, province)\n    \n    y = np.array(tmp[ metric ])\n    x = np.array(list(range(len(y))))\n    y_pred = predict(fun,x,popts,scale=SCALE)\n    tmp_rmse = mean_squared_error(y, y_pred)\n    \n    if tmp_rmse > MAX_RMSE:\n        print(f'RMSE more than {MAX_RMSE}! {country} {province} {fun} {popts}')\n    \n    plt.plot(x,y,'b-+', label='Actual')\n    plt.plot(x,y_pred,'r.', label='Predicted')\n    if len(province) > 0:\n        title = f'Prediction for {province}, {country}'\n    else:\n        title = f'Prediction for {country}'\n    title += f'\\nScale={SCALE} RMSE={round(tmp_rmse,4)}'\n    plt.title(title)\n    plt.ylabel(metric)\n    plt.xlabel(f'Time since {min(tmp[\"Date\"])}')\n    ax = plt.gca()\n    ax.legend()\n    \n    \ndef plot_country(train_bak, models, country='Italy', province=''):\n    nrows = 2\n    ncols = 1\n    index = 1\n    \n    plt.subplots_adjust(hspace=1.)\n    \n    for index, metric in enumerate(['DailyConfirmedCases','DailyFatalities']):\n        model = models[country + '_' + province][metric]\n        ax = plt.subplot(nrows,ncols,index+1)\n    #     plot_fit_country(train_bak, country=country, province=province, fun=fun, popts=popts, metric=metric)\n        plot_fit_country(train_bak, country=country, province=province, fun=model['fun'], popts=model['popts'], metric=metric)\n        dates = sorted(train_bak['Date'].drop_duplicates().tolist())\n        test_date_index = dates.index(test['Date'].min())\n        test_date_str = str(test[\"Date\"].min()).replace('00:00:00','')\n        plt.axvline(test_date_index,0,10000,label=f'Test {test_date_str}',linestyle='--')\n#         ax = plt.gca()\n        ax.legend()\n    \n    \n    \n# country_province_to_show = {'China':'Hubei', 'Diamond Princess':None, 'Korea, South':None, 'Taiwan*':None, 'Japan':None,\n#                             'US':'New York', 'US':'California', 'Spain':None, 'Italy':None, 'Germany':None, \n#                             'Turkey':None, 'Canada':'British Columbia', 'Colombia':None}\n# for country, province in list(country_province_to_show.items()):\nqueries = ['Bahamas', 'Senegal', 'Afghanistan', 'Australia_New South Wales', 'Colombia', 'Japan', \n           'China_Hubei', 'Italy', 'Spain', 'Taiwan*', 'US_New York',\n           'Canada_British Columbia'\n          ]\nfor q in queries:\n    if '_' not in q:\n        province = ''\n        country = q\n    else:\n        country, province = q.split('_')\n    plot_country(train_bak, models, country=country, province=province)\n    plt.show()","a8c49827":"def calc_cumsum_predict(train, models, test, country, province):\n    \"\"\"\n    Returns the cumulative sum for submission {'ConfirmedCases': []}, num_rows = test.shape[0]\n    \"\"\"\n    tmp_test = country_slice(test,country, province)\n    tmp = country_slice(train,country, province)\n   \n    ret = dict()\n    for metric in ['DailyConfirmedCases', 'DailyFatalities']:\n        metric_ret = metric.replace('Daily','')\n        model = models[country + '_' + province][metric]\n        popts, fun = model['popts'], model['fun']\n#         print(metric, fun, popts)\n        \n        #calculate test\n        x_pred = np.array(list(range( tmp.shape[0], tmp.shape[0]+tmp_test.shape[0] )))\n        y_pred = np.array(predict(fun,x_pred,popts,scale=SCALE)).clip(0).round(4)\n        \n        #calculate cumsum for train+test\n        y = np.array(tmp[metric])\n        x = np.array(list(range( len(y) )))\n        concat_x = np.concatenate([x,x_pred])\n        concat_y = np.concatenate([y,y_pred])\n        cumulative_y = np.cumsum(concat_y)\n        \n        #truncate to only test for submission\n        ret[metric_ret] = cumulative_y[tmp.shape[0]:]\n    \n#         print(ret[metric_ret][:2] )\n\n    return ret\n\n\n\nout = []\ncountry_state_df = train[['Country_Region','Province_State']].drop_duplicates()\n\nfor i, row in list(country_state_df.iterrows()):\n    country = row[0]\n    province = row[1]\n    \n#     if country != 'Senegal':\n#     if country != 'Italy':\n#         continue\n        \n    tmp_test = country_slice(test, country, province)\n    \n    y_submit = calc_cumsum_predict(train, models, test, country, province)\n    tmp_test['ConfirmedCases'] = y_submit['ConfirmedCases']\n    tmp_test['Fatalities'] = y_submit['ConfirmedCases'] if y_submit['Fatalities'][0] > y_submit['ConfirmedCases'][0] else y_submit['Fatalities']\n#     print(f\"{country} {province} tmp_test{len(tmp_test['ConfirmedCases'])} y_submit{len(y_submit['ConfirmedCases'])}\")\n    \n    out.append(tmp_test)\n\nresults = pd.concat(out)\n\nresults.to_csv('results.csv',index=False)\nresults[submission.columns].to_csv('submission.csv',index=False)\nprint(f'Results saved to results.csv {results.shape}, submission_shape={submission.shape}, total_cases={results[\"ConfirmedCases\"].sum()}, total_fatalities={results[\"Fatalities\"].sum()}')\n\n# results","16fbff29":"results.describe()","1ec08252":"# Examples","ca6060ea":"# Load datasets","5d21a2e8":"# Submit results","d0d1514a":"# Display predictions","169a0206":"# Assumptions\nThe number of new ConfirmedCases per day follows a Gaussian distribution. \n\n# Algorithm\nIf the number of cases\/fatalities is < 100, fit a second degree polynomial curve. Otherwise, fit a Gaussian distribution with different initial parameters, if it fails, try fitting a second degree polynomial curve.\n\n# Observations\nThe Gaussian fit tend to underestimate the true number of confirmed cases so I used a scaling factor of 1.5 when predicting.\nIf the estimated amplitude is more than 10 times the highest number of daily cases \/ fatality, then try another parameter.\n\n# Evaluation\nTo have a public leaderboard for this forecasting task, we will be using data from 7 days before to 7 days after competition launch. Only use data prior to 2020-04-1 for predictions on the public leaderboard period. Use up to and including the most recent data for predictions on the private leaderboard period.\n\n# Deadline\nApril 15, 2020 (11:59pm UTC) - Final submission deadline.","c9daa46c":"# Model building"}}