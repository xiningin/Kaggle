{"cell_type":{"0b00131d":"code","456414b9":"code","e1297f02":"code","e0aeb603":"code","280ace5d":"code","c6a1e0b7":"code","04012d09":"code","74f451cd":"code","8bb31632":"code","70274a67":"code","161e75ba":"code","26f6848d":"code","7ab2e4e9":"code","9617d7fa":"code","4d756cb6":"code","da6151ef":"code","73bcd00d":"code","b46e3e48":"code","a47a28db":"code","4006a434":"code","d8d9c48d":"code","e276612d":"code","c0b0f1ae":"code","a5cf1791":"code","72ca9087":"code","580ead69":"code","9e367887":"code","396466a5":"code","99816de5":"code","75f8d638":"code","1624e4c9":"code","bc3fcc3f":"code","63713967":"code","eb530c72":"code","3ea1b023":"code","c1901dfe":"code","92d9facf":"code","fda5aab2":"code","a9883dbb":"code","df20aa0d":"code","956c52ed":"code","8facef63":"code","94cdb542":"code","980055a8":"code","eee34302":"code","5092f232":"code","63e13949":"code","1ef6596a":"code","509359f4":"code","b378441f":"code","832a7844":"code","0d3750c9":"code","82178e50":"code","294159b5":"code","51c30671":"code","37c7ead7":"code","2f25863e":"code","d3d12b8a":"code","0e874459":"code","14972161":"code","98915cc2":"code","01e95e57":"code","3da5793d":"code","b11e4b84":"code","51b934fc":"code","0835e4f9":"code","0dc2fb74":"code","eda65767":"code","e82a02d3":"code","d303f4ad":"code","a8a3a4ba":"code","6cede1d4":"code","c102b9b3":"markdown","8ab124f2":"markdown","f0477d75":"markdown","214f74e1":"markdown","935e0a4c":"markdown","5c9c2f61":"markdown","61e386b8":"markdown","970b1c97":"markdown","adb550d4":"markdown","0a63809e":"markdown","455d266d":"markdown","2e245815":"markdown","80d34e21":"markdown","df947c75":"markdown"},"source":{"0b00131d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/nlp-specialization-data\/'):\n    print(dirname)\n    #for filename in filenames:\n    #   print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","456414b9":"def read_file(filepath):\n    \n    with open(filepath) as f:\n        str_text = f.read()\n    \n    return str_text","e1297f02":"len(\"rahul\")","e0aeb603":"len(read_file('\/kaggle\/input\/nlp-specialization-data\/Novel - Moby-Dick By Herman Melville.txt'))","280ace5d":"print(read_file('\/kaggle\/input\/nlp-specialization-data\/Novel - Moby-Dick By Herman Melville.txt')[:5000])","c6a1e0b7":"import spacy\nimport en_core_web_sm\n\nnlp = en_core_web_sm.load()\nnlp.max_length = 1198623","04012d09":"def read_file(filepath):\n    \n    with open(filepath) as f:\n        str_text = f.read()\n    \n    return str_text[:250000]","74f451cd":"def separate_punc(doc_text):\n    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-\/:;<=>?@[\\\\]^_`{|}~\\t\\n ']","8bb31632":"d = read_file('\/kaggle\/input\/nlp-specialization-data\/Novel - Moby-Dick By Herman Melville.txt')\ntokens = separate_punc(d)","70274a67":"type(tokens)","161e75ba":"len(tokens)","26f6848d":"tokens[:10]","7ab2e4e9":"# organize into sequences of tokens\ntrain_len = 25+1 # 25 training words , then one target word\n\n# Empty list of sequences\ntext_sequences = []\n\nfor i in range(train_len, len(tokens)):\n    \n    # Grab train_len# amount of characters\n    seq = tokens[i-train_len:i]\n    \n    # Add to list of sequences\n    text_sequences.append(seq)","9617d7fa":"print(read_file('\/kaggle\/input\/nlp-specialization-data\/Novel - Moby-Dick By Herman Melville.txt')[:1000])","4d756cb6":"' '.join(text_sequences[0])","da6151ef":"' '.join(text_sequences[1])","73bcd00d":"' '.join(text_sequences[2])","b46e3e48":"len(text_sequences) #Every sentence is containing 26 words","a47a28db":"len(tokens) # These are total number of words in the whole novel","4006a434":"print(len(text_sequences[0]))\nprint(text_sequences[0])","d8d9c48d":"from keras.preprocessing.text import Tokenizer","e276612d":"# integer encode sequences of words\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(text_sequences)\nsequences = tokenizer.texts_to_sequences(text_sequences)","c0b0f1ae":"print(len(sequences[0]))\nprint(sequences[0])","a5cf1791":"type(tokenizer.index_word)","72ca9087":"' '.join(text_sequences[0])","580ead69":"i=0\nfor a in tokenizer.index_word:\n    print(a,\"--->\",tokenizer.index_word[a])\n    i+=1\n    if i==20 : break ","9e367887":"for i in sequences[0]:\n    print(f'{i} : {tokenizer.index_word[i]}')","396466a5":"i=0\nfor a in tokenizer.word_counts:\n    print((a,tokenizer.word_counts[a]))\n    i+=1\n    if i==10 : break ","99816de5":"vocabulary_size = len(tokenizer.word_counts)\nvocabulary_size","75f8d638":"i=6990\nfor a in range(i,7000):\n    print(a,\"--->\",tokenizer.index_word[a])\n    #i+=1\n    #if i==6999 : break ","1624e4c9":"# tokenizer.index_word","bc3fcc3f":"import numpy as np","63713967":"len(sequences)","eb530c72":"len(sequences[0])","3ea1b023":"sequences = np.array(sequences)","c1901dfe":"sequences.shape","92d9facf":"sequences","fda5aab2":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,LSTM,Embedding","a9883dbb":"def create_model(vocabulary_size, seq_len):\n    model = Sequential()\n    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n    model.add(LSTM(150, return_sequences=True))\n    model.add(LSTM(150))\n    model.add(Dense(150, activation='relu'))\n\n    model.add(Dense(vocabulary_size, activation='softmax'))\n    \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n   \n    model.summary()\n    \n    return model","df20aa0d":"from tensorflow.keras.utils import to_categorical","956c52ed":"print(sequences.shape)\nsequences","8facef63":"# First 25 words\nprint(sequences[:,:-1].shape)\nsequences[:,:-1]","94cdb542":"# last Word\nprint(sequences[:,-1].shape)\nsequences[:,-1]","980055a8":"X = sequences[:,:-1]","eee34302":"X.shape","5092f232":"y = sequences[:,-1]","63e13949":"y.shape","1ef6596a":"y = to_categorical(y, num_classes=vocabulary_size)","509359f4":"y.shape","b378441f":"seq_len = X.shape[1]","832a7844":"seq_len","0d3750c9":"# define model\nmodel = create_model(vocabulary_size, seq_len)\n#model = create_model(vocabulary_size, seq_len)","82178e50":"model.fit(X, y, batch_size=512, epochs=250,verbose=1,validation_batch_size=.20)","294159b5":"from pickle import dump,load","51c30671":"# save the model to file\nmodel.save('epochBIG.h5')\n# save the tokenizer\ndump(tokenizer, open('epochBIG', 'wb'))","37c7ead7":"from random import randint\nfrom pickle import load\nfrom keras.models import load_model\nfrom keras.preprocessing.sequence import pad_sequences","2f25863e":"def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n    '''\n    INPUTS:\n    model : model that was trained on text data\n    tokenizer : tokenizer that was fit on text data\n    seq_len : length of training sequence\n    seed_text : raw string text to serve as the seed\n    num_gen_words : number of words to be generated by model\n    '''\n    \n    # Final Output\n    output_text = []\n    \n    # Intial Seed Sequence\n    input_text = seed_text\n    \n    # Create num_gen_words\n    for i in range(num_gen_words):\n        \n        # Take the input text string and encode it to a sequence\n        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n        \n        # Pad sequences to our trained rate (25 words in the video)\n        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n        \n        # Predict Class Probabilities for each word\n        #pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n        predict_x=model.predict(pad_encoded) \n        pred_word_ind=np.argmax(predict_x,axis=1)[0]\n        #print(pred_word_ind)\n        # Grab word\n        pred_word = tokenizer.index_word[pred_word_ind] \n        \n        # Update the sequence of input text (shifting one over with the new word)\n        input_text += ' ' + pred_word\n        \n        output_text.append(pred_word)\n        \n    # Make it look like a sentence.\n    return ' '.join(output_text)","d3d12b8a":"print(text_sequences[0])","0e874459":"import random\nrandom_pick = random.randint(0,len(text_sequences))","14972161":"random_seed_text = text_sequences[random_pick]","98915cc2":"print(random_seed_text)","01e95e57":"seed_text = ' '.join(random_seed_text)\nseed_text","3da5793d":"model = load_model('epochBIG.h5')","b11e4b84":"tokenizer = load(open('epochBIG', 'rb'))","51b934fc":"generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=3)","0835e4f9":"text=' It is a way I have of driving off the spleen and regulating the circulation.  Whenever I find'\nprint(text)","0dc2fb74":"generate_text(model,tokenizer,seq_len,seed_text=text,num_gen_words=3)","eda65767":"print(read_file('\/kaggle\/input\/nlp-specialization-data\/Novel - Moby-Dick By Herman Melville.txt')[250000:251000])","e82a02d3":"test_text='Three better,more likely sea-officers and men, each in his own different way,could not readily be found, and they were every'\nprint(test_text)","d303f4ad":"generate_text(model,tokenizer,seq_len,seed_text=test_text,num_gen_words=1)","a8a3a4ba":"seed_text = \"landsman has had fresh fruit to his daily hand and broken the world 's fresh bread to my mouldy crusts away whole oceans away from that\"","6cede1d4":"generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=3)","c102b9b3":"---\n\n----","8ab124f2":"## 5. Fit model","f0477d75":"## 1. Functions for Processing Text\n\n### a. Reading in files as a string text","214f74e1":"### c. Create Sequences of Tokens","935e0a4c":"### e. Convert to Numpy Matrix","5c9c2f61":"### b. Tokenize and Clean Text","61e386b8":"## 6. Generating New Text","970b1c97":"# <center> Text Generation - Next Word Prediction","adb550d4":"### Download Model Object","0a63809e":"## 3. Train \/ Test Split","455d266d":"## 2. Creating an LSTM based model","2e245815":"## 7. Grab a random Text Sequence","80d34e21":"### d. Keras Tokenization","df947c75":"## 4. Training the Model"}}