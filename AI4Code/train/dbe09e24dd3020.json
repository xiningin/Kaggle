{"cell_type":{"c26da4cc":"code","5af3fb05":"code","bee22e4b":"code","fee07b21":"code","60c7aa36":"code","4a45f661":"code","d4928ecd":"code","e312376a":"code","300461c8":"code","8126346d":"code","ec80705a":"code","ccf8d664":"code","271aca60":"code","7772d640":"code","1ea7ebb3":"markdown","49d95989":"markdown","d427dac1":"markdown","97f3ab7e":"markdown","6e28d7dd":"markdown","ca8b9179":"markdown","9fd36f4c":"markdown","c9297856":"markdown","c4f88ad6":"markdown","632bebc5":"markdown","3785ebf7":"markdown","b05cdc96":"markdown","7289d928":"markdown","97db27d7":"markdown","0290201b":"markdown","60e06b48":"markdown","fbfb7b00":"markdown","86e1bcc4":"markdown","975b499d":"markdown","40d03d49":"markdown","4ef5bc3f":"markdown","3cf72e1d":"markdown"},"source":{"c26da4cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5af3fb05":"import surprise\n\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\nfrom surprise import AlgoBase\nfrom surprise import PredictionImpossible\nimport heapq\n\n\nfrom surprise import Dataset \nfrom surprise import Reader\nfrom surprise.model_selection import train_test_split\nfrom surprise import accuracy\nfrom surprise.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score,classification_report\n\nimport os\nprint(os.listdir(\"..\/input\/the-movies-dataset\"))\n\n","bee22e4b":"import itertools\n\nfrom surprise import accuracy\nfrom collections import defaultdict\n\nclass RecommenderMetrics:\n\n    def MAE(predictions):\n        return accuracy.mae(predictions, verbose=False)\n\n    def RMSE(predictions):\n        return accuracy.rmse(predictions, verbose=False)\n\n    def GetTopN(predictions, n=10, minimumRating=4.0):\n        topN = defaultdict(list)\n\n\n        for userID, movieID, actualRating, estimatedRating, _ in predictions:\n            if (estimatedRating >= minimumRating):\n                topN[int(userID)].append((int(movieID), estimatedRating))\n\n        for userID, ratings in topN.items():\n            ratings.sort(key=lambda x: x[1], reverse=True)\n            topN[int(userID)] = ratings[:n]\n\n        return topN\n\n    def HitRate(topNPredicted, leftOutPredictions):\n        hits = 0\n        total = 0\n\n        # For each left-out rating\n        for leftOut in leftOutPredictions:\n            userID = leftOut[0]\n            leftOutMovieID = leftOut[1]\n            # Is it in the predicted top 10 for this user?\n            hit = False\n            for movieID, predictedRating in topNPredicted[int(userID)]:\n                if (int(leftOutMovieID) == int(movieID)):\n                    hit = True\n                    break\n            if (hit) :\n                hits += 1\n\n            total += 1\n\n        # Compute overall precision\n        return hits\/total\n\n    def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n        hits = 0\n        total = 0\n\n        # For each left-out rating\n        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n            # Only look at ability to recommend things the users actually liked...\n            if (actualRating >= ratingCutoff):\n                # Is it in the predicted top 10 for this user?\n                hit = False\n                for movieID, predictedRating in topNPredicted[int(userID)]:\n                    if (int(leftOutMovieID) == movieID):\n                        hit = True\n                        break\n                if (hit) :\n                    hits += 1\n\n                total += 1\n\n        # Compute overall precision\n        return hits\/total\n\n    def RatingHitRate(topNPredicted, leftOutPredictions):\n        hits = defaultdict(float)\n        total = defaultdict(float)\n\n        # For each left-out rating\n        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n            # Is it in the predicted top N for this user?\n            hit = False\n            for movieID, predictedRating in topNPredicted[int(userID)]:\n                if (int(leftOutMovieID) == movieID):\n                    hit = True\n                    break\n            if (hit) :\n                hits[actualRating] += 1\n\n            total[actualRating] += 1\n\n        # Compute overall precision\n        for rating in sorted(hits.keys()):\n            print (rating, hits[rating] \/ total[rating])\n\n    def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n        summation = 0\n        total = 0\n        # For each left-out rating\n        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n            # Is it in the predicted top N for this user?\n            hitRank = 0\n            rank = 0\n            for movieID, predictedRating in topNPredicted[int(userID)]:\n                rank = rank + 1\n                if (int(leftOutMovieID) == movieID):\n                    hitRank = rank\n                    break\n            if (hitRank > 0) :\n                summation += 1.0 \/ hitRank\n\n            total += 1\n\n        return summation \/ total\n\n    # What percentage of users have at least one \"good\" recommendation\n    def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n        hits = 0\n        for userID in topNPredicted.keys():\n            hit = False\n            for movieID, predictedRating in topNPredicted[userID]:\n                if (predictedRating >= ratingThreshold):\n                    hit = True\n                    break\n            if (hit):\n                hits += 1\n\n        return hits \/ numUsers\n\n    def Diversity(topNPredicted, simsAlgo):\n        n = 0\n        total = 0\n        simsMatrix = simsAlgo.compute_similarities()\n        for userID in topNPredicted.keys():\n            pairs = itertools.combinations(topNPredicted[userID], 2)\n            for pair in pairs:\n                movie1 = pair[0][0]\n                movie2 = pair[1][0]\n                innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n                innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n                similarity = simsMatrix[innerID1][innerID2]\n                total += similarity\n                n += 1\n\n        S = total \/ n\n        return (1-S)\n\n    def Novelty(topNPredicted, rankings):\n        n = 0\n        total = 0\n        for userID in topNPredicted.keys():\n            for rating in topNPredicted[userID]:\n                movieID = rating[0]\n                rank = rankings[movieID]\n                total += rank\n                n += 1\n        return total \/ n\n","fee07b21":"ratings=pd.read_csv('..\/input\/the-movies-dataset\/ratings.csv')\nmovies=pd.read_csv('..\/input\/the-movies-dataset\/movies_metadata.csv')\nratings.drop_duplicates(inplace=True)\nmovies.drop_duplicates(inplace=True)\n","60c7aa36":"ratings.head()","4a45f661":"movies.head()\nmovies.rename(columns={'id':'movieId'}, inplace=True)","d4928ecd":"ratings.drop_duplicates()","e312376a":"print('the number of unique users we have is:', len(ratings.userId.unique()))\nprint('the number of unique books we have is:', len(ratings.movieId.unique()))","300461c8":"fig, ax = plt.subplots(figsize=(12,8))\nax.set_title('Ratings distribution', fontsize=15)\nsns.countplot(ratings['rating'])\nax.set_xlabel(\"ratings in interval\")\nax.set_ylabel(\"Total number of ratings\")","8126346d":"ratings_per_user = ratings.groupby(by='userId')['rating'].count()\nratings_per_user.describe()\n\n","ec80705a":"\nratings_per_movie = ratings.groupby(by='movieId')['rating'].count()\nratings_per_movie.describe()","ccf8d664":"# Surprise dataframe \n\nreader = Reader()\nratings = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n","271aca60":"#split into train and test \n\ntrain_ratings, test_ratings = train_test_split(ratings, test_size=.20, random_state = 42)\nprint(\"Size of trainset: \", train_ratings.n_ratings)\nprint(\"Size of testset: \", len(test_ratings))","7772d640":"class ContentKNNAlgorithm(AlgoBase):\n\n    def __init__(self, k=40, sim_options={}):\n        AlgoBase.__init__(self)\n        self.k = k\n\n    def fit(self, train_ratings):\n        AlgoBase.fit(self, train_ratings)\n\n        # Compute item similarity matrix based on content attributes\n\n        # Load up genre vectors for every movie\n        ml = movies\n        genres = ml.genres\n        years=ml.timestamp #do i need to convert timestamp into datetime ? \n      \n        \n        print(\"Computing content-based similarity matrix...\")\n            \n        # Compute genre distance for every movie combination as a 2x2 matrix\n        self.similarities = np.zeros((self.train_ratings.n_items, self.train_ratings.n_items))\n        \n        for thisRating in range(self.train_ratings.n_items):\n            if (thisRating % 100 == 0):\n                print(thisRating, \" of \", self.train_ratings.n_items)\n            for otherRating in range(thisRating+1, self.train_ratings.n_items):\n                thisMovieID = int(self.train_ratings.to_raw_iid(thisRating))\n                otherMovieID = int(self.train_ratings.to_raw_iid(otherRating))\n                genreSimilarity = self.computeGenreSimilarity(thisMovieID, otherMovieID, genres)\n                yearSimilarity = self.computeYearSimilarity(thisMovieID, otherMovieID, years)\n                #mesSimilarity = self.computeMiseEnSceneSimilarity(thisMovieID, otherMovieID, mes)\n                self.similarities[thisRating, otherRating] = genreSimilarity * yearSimilarity\n                self.similarities[otherRating, thisRating] = self.similarities[thisRating, otherRating]\n                \n        print(\"...done.\")\n                \n        return self\n    \n    def computeGenreSimilarity(self, movie1, movie2, genres):\n        genres1 = genres[movie1]\n        genres2 = genres[movie2]\n        sumxx, sumxy, sumyy = 0, 0, 0\n        for i in range(len(genres1)):\n            x = genres1[i]\n            y = genres2[i]\n            sumxx += x * x\n            sumyy += y * y\n            sumxy += x * y\n        \n        return sumxy\/math.sqrt(sumxx*sumyy)\n    \n    def computeYearSimilarity(self, movie1, movie2, years):\n        diff = abs(years[movie1] - years[movie2])\n        sim = math.exp(-diff \/ 10.0)\n        return sim\n    \n   \n    def estimate(self, u, i):\n\n        if not (self.train_ratings.knows_user(u) and self.train_ratings.knows_item(i)):\n            raise PredictionImpossible('User and\/or item is unkown.')\n        \n        # Build up similarity scores between this item and everything the user rated\n        neighbors = []\n        for rating in self.train_ratings.ur[u]:\n            genreSimilarity = self.similarities[i,rating[0]]\n            neighbors.append( (genreSimilarity, rating[1]) )\n        \n        # Extract the top-K most-similar ratings\n        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n        \n        # Compute average sim score of K neighbors weighted by user ratings\n        simTotal = weightedSum = 0\n        for (simScore, rating) in k_neighbors:\n            if (simScore > 0):\n                simTotal += simScore\n                weightedSum += simScore * rating\n            \n        if (simTotal == 0):\n            raise PredictionImpossible('No neighbors')\n\n        predictedRating = weightedSum \/ simTotal\n\n        return predictedRating\n    ","1ea7ebb3":"* Coverage :\n\nIt's the pourcentage of <user, item> pairs that can be predicted \nIt depends on the size of the dataset : the bigger its size ( lots of users\/ratings ) the better is the coverage, and better coverage means better performance because the model has lots of data to work with \n\n* Diversity :\n\nIt's ( 1 -S) where S is the average similarity between recommendation pairs, \nThe system recommends stuff that the user hasnn't seen\/watched yet \n\n* Novelty : \n\nHigh Novelty means the system recommends different stuff to the user ( smthng far from his\/her taste ) which is not always a good thing \n=> long tail \n\n* Churn :\n\nIt's recommending random stuff to the user \n\n* Responsiveness :\n\nfor example let's suppose a certain user who was a big fan of scify suddenly got bored with that genre and switched to romance, the system might pick up on that sudden change of taste a day \/ a week or even a month later ... ","49d95989":"Before diving into the code, let's understand first the different ways in which you can evaluate a Recommender system","d427dac1":"# Basics of Recommender Systems ","97f3ab7e":"It's recommending a movie to a user that is similar to the movies he or she gave a high rating \nFor example let's say user A loves the movie Titanic, the the recommender engine will recommend him The notebook \n\n","6e28d7dd":"For now, we'll work on ratings dataset ","ca8b9179":"**By definition :** A recommendation engine filters the data using different algorithms and recommends the most relevant items to users. It first captures the past behavior of a customer and based on that, recommends products which the users might be likely to buy.","9fd36f4c":"In this notebook, i'll cover a lot of concepts of recommendation systems, from basics to more advanced concepts \n\nSections : \n1. Basics of Recommender systems\n2. Evaluation metrics\n3. Content-based Filtering\n   * Similarity metrics\n   * K-NN \n4. Collaborative Filtering\n   * Measuring similarity and sparsity \n   * User-based collaborative filtering\n   * Item-based collaborative filtering \n   * Tuning collaborative filtering algorithms \n   ","c9297856":"The class RecommenderMetrics defines all of the metrics that i talked about earlier :","c4f88ad6":"And here's where the role of Recommender Engines comes into play, it's such a powerful tool that is used everywhere nowadays.\nIn 2008, Netflix offered 100,000 to whoever can improve their recommendation engine's accuracy by 10% which pushed lots of data scientists to do exhaustive research on the topic and come up with new algorithms and more optimized solutions..\nso basically, if it wasn't for that price that Netflix offered, this topic wouldn't be this popular","632bebc5":"Min nb of ratings per user is 1 and the max rating is 18276","3785ebf7":"Most ratings are somewhat high ( 3.0 and 4.0 ) ,seems like there are lots of good movies in the dataset ","b05cdc96":"* **Hit Rate (HR) :**\n\nIt measures accuracy of top n recommendation for a user \nIt's the number of hits ( movies that are correctly predicted as rated ) divided by the total number of users \n**How to calculate number of hits ?** \n=> leave one out cross validation : it's basically removing one movie from the top n recommended movies then run the algorithm again and if in the new generated top n movies, the removed movie exists then number of hits + = 1..and we keep on doing that over and over again for zach movie in the top n..\n\n*The below ones are variations of HR :*\n\n* **arHR :**  \n\nit measures the rank of an item in the top n recommended items \nIf it appears on top of the list of recommendations ( high rank ) then it's a very good recommendation and vice versa \n\n* **cHR :**\n\nIt ignores the predicted ratings lower than a certain value ( for example if the rating meter is from 0 to 5 then let's pick value equals to 4 ) \nSo CHR computes hit rate for ratings >= 4\n\n--------------------------------------------------------------------------------------------------------\n\nNB : Recommender systems with high hit rate may have very low RMSE !! but take into account that hit rate metric matters more than RMSE, because the higher its value, the better are the recommendations\n","7289d928":"the reason why we only kept these 3 columns is because later on, we'll compute a similarity matrix that only needs users and their ratings on the available movies and it will be used to generate recommendation ","97db27d7":"since it's a small dataset, we won't get very good recommensations, but it's ok, u can apply chat u'll learn in this notebook on movielens bigger dataset\n\nLet's check distribution of ratings :","0290201b":"For this notebook, i'll use MovieLens dataset ( the small version ).\nIt has 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users.\nGrab the dataset from this link : https:\/\/grouplens.org\/datasets\/movielens\/","60e06b48":"To measure similarity between movies, we'll use cosine similarity \n\nThe algorithm we'll use is K-NN ","fbfb7b00":"# Evaluation Metrics ","86e1bcc4":"In today\u2019s world, every customer is faced with multiple choices and might waste a lot of time browsing around on the internet and trawling through various sites hoping to find something tailored to their tastes.\n\nBut if there was an app that could recommend products\/content based on what they have seen\/purchased\/rated previously, that would be a massive help. Instead of wasting time on various sites.","975b499d":"Now that we have an intuition of recommendation engines, let\u2019s now look at how they work.","40d03d49":"* **MAE and RMSE :**\n\nThey both compute error fraction ( difference between predicted value and the real value ) \nin our case, the value is the user's rating on a certain movie  \n\n! RMSE penalizes more (outputs a higher value than MAE ) when there's high error ( because of the root squared ) \n\n![image.png](attachment:0b09f280-2c17-4004-8955-2b2df2bb8720.png)\n\n![image.png](attachment:97e6790c-6896-470f-babc-f2db32bbdb62.png)\n","4ef5bc3f":"# Content based filtering","3cf72e1d":"Min nb of ratings per movie is 1  ( poor movie :'( ) and Max nb of ratings is 91921 ( waaah it must be a really popular one, could it be titanic ? )"}}