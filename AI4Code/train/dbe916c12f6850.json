{"cell_type":{"4e80a0ff":"code","1ab9951f":"code","fc4467d4":"code","2abe4d16":"code","a0cfd0b0":"code","ade3cd9b":"code","baa088e7":"code","dddd7232":"code","f4ab2425":"code","d95ee420":"code","b9a4b7d4":"code","e76d51bb":"code","4fce4ce4":"code","301d2c33":"code","a932a554":"code","ecb401fc":"code","4206c796":"code","39e7e1ba":"code","1caabb82":"code","41715bd0":"code","18c42e07":"markdown","e205a884":"markdown","e6fced5c":"markdown","87c8204a":"markdown","a62b94a3":"markdown","cad3bc25":"markdown","7c202260":"markdown"},"source":{"4e80a0ff":"# Load necesssary packages\nimport pandas as pd","1ab9951f":"# Load dataset\ndf = pd.read_csv(\"\/kaggle\/input\/starbucks-customer-retention-malaysia-survey\/Starbucks satisfactory survey.csv\")","fc4467d4":"# Overview Dataset\ndf.info()","2abe4d16":"# Check data unique\nx = 1\nfor i in range(0,20):\n    print(f'''\n          {df.columns[x]}\n          {df.iloc[:,x].unique()}\n          ''')\n    x = x + 1","a0cfd0b0":"# Rename all column\nx = 1\na = list(df.columns)\nb = ['gender','age','status','income','visitNo','method','timeSpend','location','membershipCard','itemPurchase','spendPurchase','productRate','priceRate','promoRate','ambianceRate','wifiRate','serviceRate','chooseRate','promoMethod','loyal']\ncol_name = {\n    a[1]:b[0]\n}\nfor i in range(0,len(b)-1):\n    col_name[a[x+1]] = b[x]\n    x = x + 1\nprint(col_name)\ndf.rename(columns=col_name,inplace=True)\ndf.head()","ade3cd9b":"# Remove timestamp col and add id col\ndf.drop(columns='Timestamp',inplace = True)\ndf.reset_index(inplace=True)\ndf.rename(columns={'index':'id'},inplace=True)\ndf.head()","baa088e7":"a = list(set(df['promoMethod']))\nb = list(set(df['itemPurchase']))\npromo = []\nitem = []\nfor i in a:\n    c = str(i).split(';')\n    for j in c:\n        promo.append(j)\nfor i in b:\n    c = str(i).split(';')\n    for j in c:\n        item.append(j)","dddd7232":"print(list(set(item)))\nprint(list(set(promo)))","f4ab2425":"# I found that item has some inconsistent values so I will remove it\nitem = list(set(item))\npromo = list(set(promo))\nitem = [i for i in item if i not in ['Never buy any','never','Nothing ']]\npromo = [i for i in promo if i != 'nan']\nprint(item)\nprint(promo)","d95ee420":"a = ['Never ','never', 'Never buy', 'I dont like coffee']\ndf['method'].replace(a,'Never',inplace=True)\ndf['method'].unique()","b9a4b7d4":"b = ['Never buy any','never','Nothing ']\ndf['itemPurchase'].replace(b,'Never',inplace=True)\ndf[df['itemPurchase'].isin(b)]","e76d51bb":"# It can be seen that this person has just bought for the first time and is quite disappointed with our store\n# So I will use people who share this characteristic to infer a reasonable value for the missing value\ndf[df.isna().any(axis=1)]","4fce4ce4":"df.loc[(df['visitNo'] == 'Never') & (df['loyal'] == 'No')]\ndf['method'].fillna('Never', inplace=True)\ndf['promoMethod'].fillna('Never hear', inplace=True)\ndf.isna().any()","301d2c33":"item","a932a554":"a1 = pd.DataFrame()\nb = df['itemPurchase']\nx = 0\nnever = []\ncake = []\ncold_drink = []\ncoffee = []\nsandwiches = []\njuices = []\njaws_chip = []\npastries = []\nitem_list = [cold_drink,sandwiches,never,cake,jaws_chip,coffee,pastries,juices]\n\n\nfor i in item_list:\n    for j in b:\n        if item[x] in j.split(';'):\n            item_list[x].append('Yes')\n        else:\n            item_list[x].append('No')\n    x = x + 1\na1['itemPurchase'] = b\na1['itemPurchase_0'] = never\na1['itemPurchase_1'] = cake\na1['itemPurchase_2'] = cold_drink\na1['itemPurchase_3'] = coffee\na1['itemPurchase_4'] = sandwiches\na1['itemPurchase_5'] = juices\na1['itemPurchase_6'] = jaws_chip\na1['itemPurchase_7'] = pastries\na1[a1['itemPurchase_3']=='Yes'].count()['itemPurchase']","ecb401fc":"promo","4206c796":"a2 = pd.DataFrame()\nb = df['promoMethod']\nx = 0\nweb_app = []\nemail = []\napplication_offer = []\nmouth = []\nsocial_media = []\nbillboards = []\ndeal_site = []\nstore_display = []\nnever_hear = []\npromo_list = [web_app, never_hear, application_offer, social_media, store_display, email, deal_site, billboards, mouth]\n\nfor i in promo_list:\n    for j in b:\n        if promo[x] in j.split(';'):\n            promo_list[x].append('Yes')\n        else:\n            promo_list[x].append('No')\n    x = x + 1\na2['promoMethod'] = b\na2['promoMethod_0'] = never_hear\na2['promoMethod_1'] = web_app\na2['promoMethod_2'] = email\na2['promoMethod_3'] = application_offer\na2['promoMethod_4'] = mouth\na2['promoMethod_5'] = social_media\na2['promoMethod_6'] = billboards\na2['promoMethod_7'] = deal_site\na2['promoMethod_8'] = store_display","39e7e1ba":"# Concat datafram\ndf_test = pd.concat([df, a1, a2], axis=1)\n# df_test.drop(columns=['promoMethod','itemPurchase'],inplace=True)\ndf_test.info()","1caabb82":"# Reorder columns\ndf1 = df_test.iloc[:,0:10]\ndf2 = df_test.iloc[:,22:30]\ndf3 = df_test.iloc[:,11:19]\ndf4 = df_test.iloc[:,31:40]\ndf5 = df_test.iloc[:,20]\ndf_final = pd.concat([df1,df2,df3,df4,df5],axis=1)\ndf_final.info()","41715bd0":"df_final.to_csv('starbucks-customer-survey-final.csv',index=False)","18c42e07":"# Rename columns\nWe're going to make all the column names more readable, and we'll remove the `timestamp` column and add the `id` column to ensure the uniqueness of each row.","e205a884":"### We split and find the unique value of 2 columns `promoMethod` & `itemPurchase`","e6fced5c":"# Startbuck Case Study\n*Author: Nguy\u1ec5n Gia Huy*\n# Load","87c8204a":"# Evaluate dataset\n- The dataset has 122 rows and 21 columns\n- There is 1 row containing the value NA\n- In column `6. How do you usually enjoy Starbucks?` there are some inconsistent input values \u200b\u200blike: **\"Never, never , Never buy, I dont like coffee\"**, this error may come from the surveyor close\n- In 2 columns `19. How do you come to hear of promotions at Starbucks? Check all that apply` and `10. What do you most frequently purchase at Starbucks?` may contain more than 1 choice for 1 response, which makes it difficult for the next analysis step.","a62b94a3":"# Inconsistent data handling\nHere we will deal with 2 columns `method` & `itemPurchase`","cad3bc25":"# Handling missing values\nSince only 1 row contains the missing value, we can easily remove it without affecting the bias or significance of the survey. But here I will use the alternative of replacing the missing value with a reasonable value based on the properties that this row has.","7c202260":"# Separate column\nOnce you have found the unique values \u200b\u200bof the two columns `promoMethod` & `itemPurchase`, convert those values \u200b\u200binto columns containing **Yes** or **No**\n- The column `itemPurchase` will divide by the following values: *cake, cold_drink, coffee, sandwiches, juices, jaws_chip, pastries,never*\n- The `promoMethod` column will divide by the following values: *web_app, email, application_offer, mouth, social_media, billboards, deal_site, store_display, never_hear*"}}