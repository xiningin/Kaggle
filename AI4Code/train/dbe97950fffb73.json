{"cell_type":{"11e1d2f1":"code","610cb1ec":"code","45ff319a":"code","835e2f9f":"code","5e65f1be":"code","58e48066":"code","9700453f":"code","407e405e":"code","ad9a1a93":"code","f85fa259":"code","9abfa7ad":"code","578d9a4d":"markdown","3538ee01":"markdown","53dfc13d":"markdown","c10a7a31":"markdown","22ef1d78":"markdown","4b2ecbda":"markdown","b13862da":"markdown","0202d886":"markdown","ee83ae8b":"markdown","0949e118":"markdown","19c45cf2":"markdown"},"source":{"11e1d2f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","610cb1ec":"train_df = pd.read_csv('..\/input\/kuc-hackathon-winter-2018\/drugsComTrain_raw.csv')\ntest_df = pd.read_csv('..\/input\/kuc-hackathon-winter-2018\/drugsComTest_raw.csv')\n\ntrain_df.head()","45ff319a":"import matplotlib.pyplot as plt\n\nplt.hist(train_df['rating']);","835e2f9f":"# extract only review as feature, rating as target\nX_train = train_df['review']\ny_train = train_df['rating']\nX_test = test_df['review']\ny_test = test_df['rating']","5e65f1be":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\n\n# ngram_range=(1,2) so that the model can deal with text such as \"not good\" as one word\nvect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1,2))\nX_train = vect.fit_transform(X_train.tolist())\nX_test = vect.transform(X_test.tolist())\n\n","58e48066":"nb = MultinomialNB().fit(X_train, y_train)\n\ntrain_pred = nb.predict(X_train)\ntest_pred = nb.predict(X_test)\n\nprint('Training Accuracy:', accuracy_score(y_train, train_pred))\nprint('Testing Accuracy:', accuracy_score(y_test, test_pred))","9700453f":"# only use rather extreme rating as predicting standard\ntrain_df['new_rating'] = train_df[(train_df['rating'] > 7) | (train_df['rating'] < 4)]['rating']\ntest_df['new_rating'] = test_df[(test_df['rating'] > 7) | (test_df['rating'] < 4)]['rating']\n\n# 1 is good rating, 0 is bad rating\ntrain_df['new_rating'] = train_df['new_rating'].apply(lambda x: 1 if x > 7 else 0)\ntest_df['new_rating'] = test_df['new_rating'].apply(lambda x: 1 if x > 7 else 0)\n\ntrain_df.head()","407e405e":"X_train = train_df['review']\nX_test = test_df['review']\ny_train = train_df['new_rating']\ny_test = test_df['new_rating']\n","ad9a1a93":"vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1,2))\nX_train = vect.fit_transform(X_train.tolist())\nX_test = vect.transform(X_test.tolist())\n\nnb = MultinomialNB().fit(X_train, y_train)\ntrain_pred = nb.predict(X_train)\ntest_pred = nb.predict(X_test)\n\nprint('Training Accuracy:', accuracy_score(y_train, train_pred))\nprint('Testing Accuracy:', accuracy_score(y_test, test_pred))","f85fa259":"alphas = np.array([0.001, 0.01, 0.1, 0, 1, 10, 100])\n\ntrain_accu = []\ntest_accu = []\n\nfor alpha in alphas:\n    nb = MultinomialNB(alpha=alpha).fit(X_train, y_train)\n    train_pred = nb.predict(X_train)\n    test_pred = nb.predict(X_test)\n    \n    train_accu.append(accuracy_score(y_train, train_pred))\n    test_accu.append(accuracy_score(y_test, test_pred))\n\nprint('Training Accuracies')\nprint(train_accu)\nprint('Testing Accuracies')\nprint(test_accu)","9abfa7ad":"plt.figure(figsize=(10, 6))\nplt.plot(list(range(len(alphas))),train_accu, label='Training');\nplt.plot(list(range(len(alphas))), test_accu, label='Testing');\nplt.xticks(list(range(len(alphas))), alphas);\nplt.xlabel('Alpha');\nplt.ylabel('Accuracy')\nplt.legend();","578d9a4d":"# Objection\nIn this project I will implement some simple text processing and machine learning skills in order to be practicing and familiar with how to deal with data of text format. I would like to build a model to predict whether the rating (target) is good or bad based on the review (feature) it provided. The goal is to let the model learn the meaning in the text. ","3538ee01":"# Hyperparameter (alpha)\nthe primary hyperparameter of MultinomialNB is alpha. I attempt to use 7 different alpha to see which one performs the best.","53dfc13d":"# What I have learned\nIn this project I have learned how to use CountVectorizer to extract meanings behind the reviews (either positive or negative in this case) and how hyperparameter impacts the ML model, although it did not differ a lot in this project.","c10a7a31":"# Prediction2","22ef1d78":"# Extract feature and target\nFor the purpose of this project, I only extract review column and rating column from the dataset.","4b2ecbda":"# More Preprocessing\nTo make the claddifier work better, I will only use ratings better than 7 and ratings worse than 4. The former one will be grouped as positive rating (1), and the latter one will be begative rating (0).","b13862da":"Now we got a much better prediction accuracy due to preprocessing of rating columns. \nHowever, the model is still overfitting. So, I am going to work on the model's hyperparameter to make it better.","0202d886":"It looks like alpha did not have lots of impact on accuracy in the range from 0.001 to 1.","ee83ae8b":"# Prediction1","0949e118":"# Distribution of the ratings","19c45cf2":"It looks like the model is overfitting\nIf we just predict the exact rating of each review, it might be hard for model to have a good prediction.\nTherefore, I decided to modify the rating columns to improve my model."}}