{"cell_type":{"3b7bc73a":"code","e8c30a55":"code","7529f8f1":"code","32dceb2a":"code","c34ddaab":"code","f472e78b":"code","ca0c1073":"code","ac805c51":"code","86df9503":"code","ac755ab3":"code","6b7d63d2":"code","bda4a8a8":"code","d330c552":"code","8cd7bdf6":"code","6b5a487f":"code","f4cf986a":"code","9d92c20d":"code","ff5d5642":"code","3efc56dc":"code","292b7b10":"code","185bce65":"code","d6b005e2":"code","4b86df80":"code","cdad3dd2":"code","e41b31c2":"code","1aae5314":"code","cf753a9e":"code","4d264a48":"code","ef91031b":"code","6c6e44ee":"code","2139ee2c":"code","a36743ef":"code","a8dbb707":"code","7365e0ee":"code","52eeb5ae":"code","57f05920":"code","b821b75f":"code","7639b7a1":"code","6d48e10d":"code","5856489e":"code","8f6f321e":"code","4b11515b":"code","6f31d2b1":"code","8b98e4b1":"code","76586a3e":"code","e8ed8474":"code","2a97cc6a":"markdown","c23ff5b4":"markdown","f8fbcf5b":"markdown","0b87319b":"markdown","ab808341":"markdown","5a77abf7":"markdown","38ae0782":"markdown","c21838f5":"markdown"},"source":{"3b7bc73a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8c30a55":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","7529f8f1":"train =pd.read_csv(r'..\/input\/reduce-marketing-waste-hackerearth-ml-challenge\/train.csv') \ntest = pd.read_csv(r'..\/input\/reduce-marketing-waste-hackerearth-ml-challenge\/test.csv')","32dceb2a":"train.shape, test.shape","c34ddaab":"train.head()","f472e78b":"train['source'] = 'train'\ntest['source'] = 'test'\ndata = pd.concat([train,test],ignore_index=True)","ca0c1073":"data.head()","ac805c51":"data.shape","86df9503":"data.dtypes","ac755ab3":"data.nunique()","6b7d63d2":"data.drop(['Geography','Lead_name','Contact_no','POC_name','Lead_POC_email'],axis=1,inplace=True)","bda4a8a8":"data.isnull().sum()","d330c552":"data['Date_of_creation'] = pd.to_datetime(data['Date_of_creation'].values,format='%Y-%m-%d')","8cd7bdf6":"data['Designation'].value_counts()","6b5a487f":"data['Designation'] = data['Designation'].replace({'Chairman\/CEO\/President':'Chairman\/CEO\/President',\n                                              'CEO\/Chairman\/President':'Chairman\/CEO\/President',\n                                              'Chief Executive Officer':'CEO',\n                                              'Vice President \/ GM (04-present) : VP Sales and Marketing (01-04)':'Vice President\/GM'})","f4cf986a":"plt.figure(figsize=(20,10))\nsns.countplot(x='Designation', data = data)\nplt.show()","9d92c20d":"data['Fund_category'].value_counts()","ff5d5642":"plt.figure(figsize=(14,7))\nsns.countplot(x='Fund_category', data = data)\nplt.show()","3efc56dc":"data['Industry'].value_counts()","292b7b10":"data['Industry'].replace(np.nan,'Banks',inplace=True)","185bce65":"data['Internal_rating'].value_counts()","d6b005e2":"data['Internal_rating'].replace({-1.00:1.00,\n                                82.34:4.00},inplace=True)","4b86df80":"plt.figure(figsize=(14,7))\nsns.countplot(x='Internal_rating', data = data)\nplt.show()","cdad3dd2":"data['Last_lead_update'].value_counts()","e41b31c2":"data['Last_lead_update'].replace(np.nan,'No track',inplace=True)","1aae5314":"data['Location'].value_counts()","cf753a9e":"data['Location'].replace(np.nan,'Aurangabad',inplace=True)","4d264a48":"data['Deal_value'] = data['Deal_value'].str.replace('$', '')\ndata['Weighted_amount'] = data['Weighted_amount'].str.replace('$', '')","ef91031b":"data['Weighted_amount'] = data['Weighted_amount'].astype(float)\ndata['Deal_value'] = data['Deal_value'].astype(float)","6c6e44ee":"data['Weighted_amount'].fillna(data['Weighted_amount'].mean(),inplace=True)\ndata['Deal_value'].fillna(data['Deal_value'].mean(),inplace=True)","2139ee2c":"data['Resource'].value_counts()","a36743ef":"data['Resource'] = data['Resource'].map({'We have all the requirements':'Yes',\n                                        'Cannot deliver':'No',\n                                        'Not enough':'No',\n                                        'Deliverable':'Yes'})","a8dbb707":"data['Resource'].replace(np.nan,'Yes',inplace=True)","7365e0ee":"plt.figure(figsize=(12,6))\nsns.countplot(x='Resource', data = data)\nplt.show()","52eeb5ae":"data.isnull().sum()","57f05920":"data['Last_lead_update'].value_counts()","b821b75f":"data['Last_lead_update'].replace('?','No track',inplace=True)","7639b7a1":"sns.boxplot(x = 'Success_probability',data = data)\nplt.show()","6d48e10d":"data.loc[data['Success_probability']>100]","5856489e":"data.loc[data['Success_probability']<0]","8f6f321e":"data['Success_probability'] = data['Success_probability'].apply(lambda x:100.0 if x>100 else x)\ndata['Success_probability'] = data['Success_probability'].apply(lambda x:0.0 if x<0 else x)","4b11515b":"data.drop('Internal_POC',axis=1,inplace=True)\ntrain_m = data.loc[data['source']=='train']\ntest_m = data.loc[data['source']=='test']\n\ntest_m.drop(['source','Success_probability',],axis=1,inplace=True)\ntrain_m.drop('source',axis=1,inplace=True)","6f31d2b1":"df = pd.DataFrame(train_m['Success_probability'].values,index=train_m['Date_of_creation'],columns=['Success_proabability'])","8b98e4b1":"weekly=df.resample(rule='W').mean()\nplt.figure(figsize=(20,5))\nsns.lineplot(data=weekly, palette = ['green'])\nplt.title('Success_probability Weekly Variation')\nplt.ylabel('Success_Probability')\nplt.show()","76586a3e":"month = df.resample(rule='M').mean()\nplt.figure(figsize=(20,5))\nsns.lineplot(data = month, palette = ['green'])\nplt.title('Success_probability Monthly Variation')\nplt.ylabel('Success_Probability')\nplt.show()","e8ed8474":"year = df.resample(rule='A').mean()\nplt.figure(figsize=(20,5))\nsns.lineplot(data = year, palette = ['green'])\nplt.title('Success_probability Yearly Variation')\nplt.ylabel('Success_Probability')\nplt.show()","2a97cc6a":"##### dropping unique values features","c23ff5b4":"### Data Visualization","f8fbcf5b":"* Checking if **Success_probability** is greater than 100 or smaller than 0,","0b87319b":"* Looks like there is some values let's fix them.","ab808341":"### Data Cleaning & Feature engineering","5a77abf7":"* Its generally a good idea to combine both train and test data sets into one, perform feature engineering and then divide them later again. This saves the trouble of performing the same steps twice on test and train. Lets combine them into a dataframe \u2018data\u2019 with a \u2018source\u2019 column specifying where each observation belongs.","38ae0782":"* Now let's convert data back into train and test data sets. Its generally a good idea to export both of these as modified data sets so that they can be re-used for multiple sessions. This can be achieved using following code:","c21838f5":"Not finished, I am currently working on it."}}