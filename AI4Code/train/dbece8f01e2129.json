{"cell_type":{"7b992a79":"code","5825c342":"code","65cde429":"code","35e77390":"code","2a831091":"code","d45bd653":"code","f6f8431f":"code","e9685a82":"code","01db2270":"code","22ad8535":"code","3c4e2599":"code","7a95046d":"code","bd6207fc":"code","6f38a77a":"code","7346ed8a":"code","48c423de":"code","bd598fa4":"code","d732852f":"code","55791331":"code","8aa41c26":"code","e46bd776":"code","bfa83c89":"code","63d7fa52":"code","8c7e8d3e":"code","ca2e3bff":"code","b6614b91":"code","464b3f0e":"code","d5a9503e":"code","e2a2e9f0":"code","e77c2a1d":"code","d519862a":"code","7b04c75b":"code","3fcee460":"code","144af3fd":"code","add3a742":"code","10ea9fa3":"code","cf733576":"code","75dd0890":"code","e2705067":"code","54406dce":"markdown","3f71d437":"markdown","7a0996f7":"markdown","e567aec6":"markdown","321ff1f1":"markdown","c084b916":"markdown","bfcfa9b0":"markdown","2b30fc3c":"markdown","3d149a57":"markdown","c608a263":"markdown","e15888c6":"markdown","4e498e7f":"markdown","aee6d08b":"markdown","7d81ceb7":"markdown","5e0c2abf":"markdown","2dec28e8":"markdown","c1017d30":"markdown","4428696d":"markdown","57e4a944":"markdown","2bbcbf99":"markdown","8ab55ab5":"markdown","9ca681c4":"markdown","7cef446f":"markdown","c402d0a3":"markdown","2a720923":"markdown"},"source":{"7b992a79":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport os.path\nimport matplotlib.pyplot as plt\n!pip install klib\nimport klib\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, precision_recall_curve, classification_report, average_precision_score\n\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_score,f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\n\n# import packages for hyperparameters tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","5825c342":"#input data\nroot_dir = '\/kaggle\/input\/widsdatathon2021\/'\n\nsample_submission = pd.read_csv(os.path.join(root_dir, \n                    'SampleSubmissionWiDS2021.csv'))\nsolution_template = pd.read_csv(os.path.join(root_dir, \n                    'SolutionTemplateWiDS2021.csv'))\nData_dictionary = pd.read_csv(os.path.join(root_dir,   \n                   'DataDictionaryWiDS2021.csv'))\nUnlabled_data = pd.read_csv(os.path.join(root_dir,     \n                'UnlabeledWiDS2021.csv'))\nTraining_data = pd.read_csv(os.path.join(root_dir,     \n                'TrainingWiDS2021.csv'))","65cde429":"display(Data_dictionary.shape)\ndisplay(Unlabled_data.shape)\ndisplay(Training_data.shape)\ndisplay(solution_template.shape)","35e77390":"Training_data.isna().any().any()","2a831091":"Training_data.drop('Unnamed: 0', axis = 1, inplace = True)","d45bd653":"display(Training_data.shape)","f6f8431f":"display(Unlabled_data.shape)\nUnlabled_data.head()","e9685a82":"Unlabled_data.isna().any().any()","01db2270":"Unlabled_data.drop('Unnamed: 0', axis = 1, inplace = True)","22ad8535":"display(Unlabled_data.shape)\nUnlabled_data.head()","3c4e2599":"Training_data.info(verbose=True, null_counts=True)","7a95046d":"Training_data.dtypes.value_counts()","bd6207fc":"Training_data.isnull().sum()","6f38a77a":"def calc_missing_values(df_name):\n    \n    '''\n    Returns total number and percentage of missing value in each column of a\n    given dataframe.    \n    '''\n    # sum of missing values in each column\n    missing_values = df_name.isnull().sum() \n    \n    # percentage of missing values in each column\n    per_missing = df_name.isnull().sum() * 100 \/ len(df_name)\n    \n    # Table with sum and percentage of missing values\n    missing_table = pd.concat([missing_values, per_missing],axis = 1)\n        \n    # Assign column names\n    missing_table_rename = missing_table.rename(columns ={0: 'Missing Values', 1:'% of missing values'})\n    \n    # Sort it by percentage of missing values\n    \n    sorted_table = missing_table_rename[missing_table_rename.iloc[:,1] !=0].\\\n    sort_values('% of missing values', ascending = False).round(1)\n    \n    print('Out of ' + str(df_name.shape[1])+ ' columns in this dataframe '+ str(sorted_table.shape[0])+ \\\n                         ' columns have missing values')\n    \n    return sorted_table\n        ","7346ed8a":"# Training data\nmissing_train = calc_missing_values(Training_data)\nmissing_train[:20].style.background_gradient(cmap='viridis')","48c423de":"# Test data\nmissing_test = calc_missing_values(Unlabled_data)\nmissing_test[:20].style.background_gradient(cmap='cividis')","bd598fa4":"train_df = klib.data_cleaning(Training_data) # removes duplicate and empty row\/col","d732852f":"test_df = klib.data_cleaning(Unlabled_data) # removes duplicate and empty row\/cols#","55791331":"#train_df = Training_data\n#test_df = Unlabled_data","8aa41c26":"train_df['diabetes_mellitus'].value_counts(normalize = True)","e46bd776":"train_df['diabetes_mellitus'].astype(int).plot.hist();","bfa83c89":" train_df.dtypes","63d7fa52":"cat_col_train = Training_data.select_dtypes('object').columns\ndisplay(len(cat_col_train))\ndisplay(cat_col_train)","8c7e8d3e":"cat_col_test = Unlabled_data.select_dtypes('object').columns\ndisplay(len(cat_col_test))\ndisplay(cat_col_test)","ca2e3bff":"#klib.cat_plot(test_df)","b6614b91":"cat_list = Training_data.select_dtypes('object').columns\ndisplay(cat_list)","464b3f0e":"# Creating Label Encoder object\nle = LabelEncoder()\nfor ob in cat_list:\n    train_df[ob] = le.fit_transform(train_df[ob].astype(str))\n    test_df[ob] = le.fit_transform(test_df[ob].astype(str))\nprint(train_df.info())    \nprint(test_df.info()) ","d5a9503e":"train_df.fillna(-9999,inplace = True)\ntrain_df.isnull().sum()","e2a2e9f0":"test_df.fillna(-9999,inplace = True)\ntest_df.isnull().sum()","e77c2a1d":"Target = 'diabetes_mellitus'\ntrain_labels = train_df[Target]\ntrain_df_NT = train_df.drop(columns = [Target])\nfeatures = list(train_df_NT.columns)\nprint('Training data shape:', train_df_NT.shape)\nprint('Test data shape:', test_df.shape)","d519862a":"X, y = train_df_NT, train_labels","7b04c75b":"# standardize dataset\nX = StandardScaler().fit_transform(X)\n#y = StandardScaler().fit_transform(y.reshape(len(y),1))[:,0]","3fcee460":"#create the train and validation set for cross-validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)","144af3fd":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\n\nmodel = keras.Sequential([\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='relu', input_shape=[172]),\n    layers.Dropout(0.5),\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='sigmoid'),\n    layers.Dropout(0.5),\n    \n    layers.Dense(1, activation='sigmoid'),\n])","add3a742":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)","10ea9fa3":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=20,\n    min_delta=0.0001,\n    restore_best_weights=True,\n)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    batch_size=1024,\n    epochs=500,\n    callbacks=[early_stopping],\n    verbose=0, # hide the output because we have so many epochs\n)","cf733576":"# Start the plot at epoch 5\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[5:, ['loss', 'val_loss']].plot()\nhistory_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['val_loss'].min(), \n              history_df['val_binary_accuracy'].max()))","75dd0890":"preds = model.predict_proba(test_df)","e2705067":"# Submission dataframe\nsubmit = test_df[['encounter_id']]\nsubmit['diabetes_mellitus'] = preds\nsubmit.to_csv('xgb_cls.csv',index=False)\nsubmit.tail(20)","54406dce":"Training data has 130157 entries and 180 variables. ","3f71d437":"# Missing  data handling","7a0996f7":"## <span style='color:purple'> Data Exploration <\/span>\n","e567aec6":"## <span style='color:purple'>  Import libraries <\/span>","321ff1f1":"Training data has 130157 entries and 181 variables. ","c084b916":"### Columns","bfcfa9b0":"Define our model just like we did for the regression tasks, with one exception. In the final layer include a 'sigmoid' activation so that the model will produce class probabilities.","2b30fc3c":"## Test data","3d149a57":"There are some missing data in training data.","c608a263":"There is class imbalance in this dataset.","e15888c6":"# Categorical features","4e498e7f":"### Column types in training and test data","aee6d08b":"Test data has 10234 entries and 179 variables which is 1 less than the training data due to the presence of TARGET column.","7d81ceb7":"Let's take a look at the learning curves as always, and also inspect the best values for the loss and accuracy we got on the validation set.","5e0c2abf":"There are three unique datatypes.","2dec28e8":"## Target Column in Training data","c1017d30":"## Training data","4428696d":"## Missing values","57e4a944":"The model in this particular problem can take quite a few epochs to complete training, so we'll include an early stopping callback for convenience.","2bbcbf99":"# Missing Values","8ab55ab5":"This column do not contain useful information so let's drop it.","9ca681c4":"# <span style='color:purple'>  Women in Data Science Datathon 2021       <\/span>\n\n<div style=\"text-align: justify;\n             font-size:18px\">\nObjective of <span style='color:purple'> WiDS Datathon 2021  <\/span> is to develop models and make predictions to determine whether a patient admitted to ICU has been diagnosed with a particular type of diabetes, Diabetes Mellitus, using labeled training data from the first 24 hours of intensive care.\n    <\/div>","7cef446f":"### Number of unique column datatypes ","c402d0a3":"Add the cross-entropy loss and accuracy metric to the model with its compile method","2a720923":"## <span style='color:purple'> Input data <\/span>"}}