{"cell_type":{"a5a785b1":"code","d7b4ab4c":"code","d4e7b21f":"code","268c1251":"code","a13b59db":"code","a5b6732d":"code","10125a35":"code","0e27d0d2":"code","74ffbf42":"code","e0de9994":"code","9ff6ee2a":"code","044c6bf9":"code","48efc41f":"code","6a7378ad":"code","87635276":"code","51d1d271":"code","626f1697":"code","de4411be":"markdown","54c02cbe":"markdown","0ec6075b":"markdown","7e4feed6":"markdown","b8aa7e4a":"markdown","bab091ca":"markdown","ac1bf357":"markdown","7b93e484":"markdown","2df377d6":"markdown","3cce51eb":"markdown","57cc5af1":"markdown","f10018be":"markdown","59f4e40f":"markdown"},"source":{"a5a785b1":"import os\nimport json\nimport random\nimport collections\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom random import shuffle\n\nimport keras\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.utils import Sequence\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import Adam\n#from tensorflow.keras.models import Sequential\n\n\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\n\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom sklearn import model_selection as sk_model_selection","d7b4ab4c":"!pip install -q nnAudio -qq\nimport torch\nfrom nnAudio.Spectrogram import CQT1992v2","d4e7b21f":"sample_submission = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')\ntest=sample_submission\n\ndisplay(test.head(3))","268c1251":"def get_train_file_path(image_id):\n    return \"..\/input\/g2net-gravitational-wave-detection\/train\/{}\/{}\/{}\/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)\n\ndef get_test_file_path(image_id):\n    return \"..\/input\/g2net-gravitational-wave-detection\/test\/{}\/{}\/{}\/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)\n\ntest['file_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(test.head(3))","a13b59db":"Q_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\ndef visualize_sample_qtransform(\n    _id, \n    pathx,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    x = np.load(pathx)\n    plt.figure(figsize=(16, 3))\n    for i in range(3):\n        waves = x[i] \/ np.max(x[i])\n        waves = torch.from_numpy(waves).float()\n        image = Q_TRANSFORM(waves)\n        \n        plt.subplot(1, 3, i + 1)\n        plt.imshow(image.squeeze())\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} \", fontsize=16)\n    plt.show()","a5b6732d":"for i in random.sample(test.index.tolist(), 1):\n    _id = test.iloc[i][\"id\"]\n    _path = test.iloc[i][\"file_path\"]\n    visualize_sample_qtransform(_id,_path)","10125a35":"class Dataset(Sequence):\n    def __init__(self,df,is_train=True,batch_size=16,shuffle=True):\n        self.idx = df[\"id\"].values\n        self.paths = df[\"file_path\"].values\n        self.y =  df[\"target\"].values\n        self.is_train = is_train\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.wave_transform = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=64)\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n    \n    def apply_qtransform(self,pathx,transform): \n        waves = np.load(pathx)\n        waves = np.hstack(waves)\n        waves = waves \/ np.max(waves)\n        waves = torch.from_numpy(waves).float()\n        image = transform(waves)\n        image = np.array(image)\n        image = np.transpose(image,(1,2,0))\n        return image \n    \n    def __getitem__(self,ids):\n        batch_paths = self.paths[ids * self.batch_size:(ids + 1) * self.batch_size]\n        \n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n        list_x = np.array([self.apply_qtransform(x,self.wave_transform) for x in batch_paths])\n        batch_X = np.stack(list_x)\n        if self.is_train:\n            return batch_X, batch_y\n        else:\n            return batch_X\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","0e27d0d2":"test_dataset = Dataset(test,is_train=False)","74ffbf42":"for i in range(1):\n    image = test_dataset[i]\n    print(image.shape)\n    plt.imshow(image[0])\n    plt.show() ","e0de9994":"!pip install -U efficientnet","9ff6ee2a":"import efficientnet.keras as efn","044c6bf9":"def create_model(): \n    inputs = layers.Input(shape=(69,193,1))\n    efficientnet_layers = efn.EfficientNetB7(include_top=False,input_shape=(),weights='imagenet',pooling='avg')\n    model = Sequential()\n    \n    model.add(inputs)\n    model.add(keras.layers.Conv2D(3,3,activation='relu',padding='same'))\n    model.add(efficientnet_layers)\n    model.add(Dropout(0.3))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    \n    model.compile(optimizer = Adam(lr = 0.000001),\n                loss = \"binary_crossentropy\",\n                metrics = [\"acc\"])\n\n    return model\n\nmodel = create_model()\nmodel.summary()","48efc41f":"model.load_weights('..\/input\/g2net-keras-weights\/model_weights.h5')","6a7378ad":"preds = model.predict(test_dataset)\npreds = preds.reshape(-1)","87635276":"submission = pd.DataFrame({'id':sample_submission['id'],'target':preds})","51d1d271":"submission","626f1697":"submission.to_csv('submission.csv',index=False)","de4411be":"# LB Scores\n![10.JPG](attachment:218d0ca8-c266-49ff-80b5-473d83a26cd9.JPG)","54c02cbe":"# EDA","0ec6075b":"#  Custom Data Generator","7e4feed6":"## \u2600\ufe0f Importing Libraries","b8aa7e4a":"1. https:\/\/www.kaggle.com\/mrigendraagrawal\/tf-g2net-eda-and-starter\n1. https:\/\/www.kaggle.com\/yasufuminakama\/g2net-efficientnet-b7-baseline-inference\n1. https:\/\/medium.com\/analytics-vidhya\/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3","bab091ca":"# Inference","ac1bf357":"# Loading Weights","7b93e484":"# Loading Data","2df377d6":"### Hi kagglers, This is `Inference` notebook using `Keras`.\n\n> \n>  [G2Net Keras baseline [Training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/g2net-keras-baseline-training)\n\n\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","3cce51eb":"# References","57cc5af1":"#### Each data sample (npy file) contains 3 time series (1 for each detector) and each spans 2 sec and is sampled at 2,048 Hz.","f10018be":"# \ud83d\udd73\ufe0f G2Net Keras [Inference]","59f4e40f":"# Model"}}