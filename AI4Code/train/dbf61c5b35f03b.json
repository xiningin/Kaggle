{"cell_type":{"cad2f514":"code","0bf5128b":"code","13049351":"code","0c516624":"code","8c9fa1fa":"code","66d274d8":"code","b2961e65":"code","5db62647":"code","a11ef26d":"code","18cd4a25":"code","8a8daf86":"code","262f4144":"code","b555da52":"code","d5980ea5":"code","cf9d38b7":"code","6edf7d6c":"code","e5efeea3":"code","c0845894":"code","341c2807":"code","12af1216":"code","19dd3257":"markdown","12c644a5":"markdown","00e5cd24":"markdown","c3473a86":"markdown","7ee115c6":"markdown","c68336b1":"markdown","07a826f8":"markdown","fef12c5a":"markdown","8cc072b9":"markdown","3c0a978e":"markdown","d92435d4":"markdown","53327381":"markdown","e7335497":"markdown","9c73a599":"markdown","079ee56a":"markdown","f871ea89":"markdown","206c3203":"markdown","4f21cb27":"markdown","b722fd47":"markdown","e8f082e4":"markdown"},"source":{"cad2f514":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0bf5128b":"# read train \ntrain = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\ntrain.head()","13049351":"# read test \ntest= pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head()","0c516624":"# put labels into y_train variable\nY_train = train[\"label\"]\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) \nY_train.head(20)","8c9fa1fa":"# visualize number of digits classes\nplt.figure(figsize=(20,7))\ng = sns.countplot(Y_train, palette=\"icefire\")\nplt.title(\"Number of digit classes\")\nY_train.value_counts()","66d274d8":"# plot some samples\nimg = X_train.iloc[0].as_matrix()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[0,0])\nplt.axis(\"off\")\nplt.show()","b2961e65":"# plot some samples\nimg = X_train.iloc[3].as_matrix()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[3,0])\nplt.axis(\"off\")\nplt.show()","5db62647":"# Normalize the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","a11ef26d":"# Reshape\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","18cd4a25":"# Label Encoding \nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY_train = to_categorical(Y_train, num_classes = 10)","8a8daf86":"# Split the train and the validation set for the fitting\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","262f4144":"# Some examples\nplt.imshow(X_train[2][:,:,0],cmap='gray')\nplt.show()","b555da52":"# \nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n#\nmodel.add(Conv2D(filters = 15, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 24, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(280, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","d5980ea5":"# Define the optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","cf9d38b7":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","6edf7d6c":"epochs = 15  # for better result increase the epochs\nbatch_size = 250","e5efeea3":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.6,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.6,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","c0845894":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0] \/\/ batch_size)","341c2807":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","12af1216":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","19dd3257":"<a id=\"16\"><\/a>\n### Fit the model","12c644a5":"<a id=\"1\"><\/a>\n## Loading the Data Set\n* In this part we load and visualize the data.","00e5cd24":"<a id=\"18\"><\/a>\n## Conclusion\n* http:\/\/scs.ryerson.ca\/~aharley\/vis\/conv\/flat.html\n* HW\n* If you have any question I will be very happy to hear it.","c3473a86":"<a id=\"7\"><\/a>\n### Max Pooling\n* It makes down-sampling or sub-sampling (Reduces the number of parameters)\n* It makes the detection of features invariant to scale or orientation changes.\n* It reduce the amount of parameters and computation in the network, and hence to also control overfitting. \n* <a href=\"https:\/\/ibb.co\/ckTjN9\"><img src=\"https:\/\/preview.ibb.co\/gsNYFU\/maxpool.jpg\" alt=\"maxpool\" border=\"0\"><\/a>","7ee115c6":"<a id=\"4\"><\/a>\n## Convolutional Neural Network \n* CNN is used for image classification, object detection \n* <a href=\"https:\/\/ibb.co\/kV1j9p\"><img src=\"https:\/\/preview.ibb.co\/nRkBpp\/gec2.jpg\" alt=\"gec2\" border=\"0\"><\/a>","c68336b1":"<a id=\"17\"><\/a>\n### Evaluate the model\n* Test Loss visualization\n* Confusion matrix\n","07a826f8":"<a id=\"10\"><\/a>\n## Implementing with Keras","fef12c5a":"<a id=\"2\"><\/a>\n## Normalization, Reshape and Label Encoding \n* Normalization\n    * We perform a grayscale normalization to reduce the effect of illumination's differences.\n    * If we perform normalization, CNN works faster.\n* Reshape\n    * Train and test images (28 x 28) \n    * We reshape all data to 28x28x1 3D matrices.\n    * Keras needs an extra dimension in the end which correspond to channels. Our images are gray scaled so it use only one channel. \n* Label Encoding  \n    * Encode labels to one hot vectors \n        * 2 => [0,0,1,0,0,0,0,0,0,0]\n        * 4 => [0,0,0,0,1,0,0,0,0,0]","8cc072b9":"Convolution Layer=>Filtre k\u0131sm\u0131 olarak da ge\u00e7er.Yani \u00f6rne\u011fin elimizde bir kedi resmi olsun.Kedi resminin kendi \u00f6zg\u00fc \u00f6zellikleri vard\u0131r.Kedinin g\u00f6z\u00fc,kuyru\u011fu..vb \u0130\u015fte bu filtre sayesinde convolution katman\u0131 kullanarak ay\u0131rt etme i\u015flemi yap\u0131yoruz.\n\nKedinin g\u00f6z\u00fc kula\u011f\u0131 kuyru\u011fu bunlar\u0131 belirleyen \u015feyler bir feature' detection d\u0131r.Bunlar\u0131n sonucunda hangi b\u00f6lgenin ne oldu\u011funu anlamak ise Feature Maps sayesinde ger\u00e7ekle\u015fir.\n!!!!!! Feature detector basit kenarlar\u0131 ve karma\u015f\u0131k cizgilerin bulunmas\u0131n\u0131 sa\u011flayarak resmi b\u00fcy\u00fck \u00f6l\u00e7\u00fcde tan\u0131mam\u0131za yard\u0131m eder.\u00d6rne\u011fin 5 rakam\u0131ndaki resimde basit kenar ve karma\u015f\u0131k kenarlar tespit edilir daha sonra bu kenarlar ve \u00e7izgilerden yola \u00e7\u0131karak resmin hangi say\u0131 oldu\u011funu anlar\u0131z.\n\nPooling Layer=> \u00d6rne\u011fin resim \u00fczerindeki kedinin kula\u011f\u0131n\u0131 belirledik bu 5x5 matris boyutunda olsun bu \u00e7ok b\u00fcy\u00fck yer kaplayacakt\u0131r.Bunun yerine matrisde kula\u011f\u0131n ortas\u0131nda ki say\u0131y\u0131 tutar\u0131z yada maximum say\u0131y\u0131 tutar\u0131z.B\u00f6ylelikle tek bir say\u0131 ile kula\u011f\u0131 ifade etmi\u015f oluruz m\u00fckemmel bir h\u0131z kazanm\u0131\u015f oluruz. Daha sonraki ad\u0131mda ise kedinin farkl\u0131 pozisyonlar\u0131 de\u011ferlendirilir \u00f6rne\u011fin amuda kalkm\u0131\u015f bir kedinin yada sa\u011fa bakan bir kedinin kula\u011f\u0131n\u0131 alg\u0131lamay\u0131 ba\u015farmak gerek.Sabit bir a\u00e7\u0131dan de\u011fil t\u00fcm a\u00e7\u0131lardan kontrol etmek gerek.\n\nConvolution Layer2=> Ne kadar fazla katman\u0131m\u0131z olursa o kadar iyi s\u0131n\u0131fland\u0131rma yapar\u0131z asl\u0131nda derin \u00f6\u011frenmenin amac\u0131 bu derinlik artt\u0131k\u00e7a verimlili\u011fi art\u0131rabiliriz :) \n\nPooling Layer2=> Burda bir \u00f6nceki ad\u0131mda olu\u015fturdu\u011fumuz filitreleme ad\u0131m\u0131ndan sonra tekrar resme g\u00f6re elemeler yap\u0131yoruz.\u00d6rne\u011fin kendinin kendi g\u00f6re kuyruk \u015fekli var buna g\u00f6re eleme i\u015flemi yapabiriz\n\nFlatten=> Burda Ann i\u015flemi uygulayaca\u011f\u0131m\u0131z i\u00e7in feature'lar\u0131m\u0131z\u0131 flatten ile d\u00fczle\u015ftirece\u011fiz\n\nSame Padding=>\u00d6rne\u011fin elimizde 5x5 bir matrisden olu\u015fan bir resim olsun.\u00dczerine 3x3 bir filitre matris uygulayal\u0131m ve \u00e7\u0131kan matris sonucu 3x3 olur.Ancak bu istedi\u011fimiz bir \u015fey de\u011fil c\u00fcnk\u00fc veri ve bilgi kaybediyoruz. Bu y\u00fczden same padding y\u00f6ntemini kullan\u0131yoruz.5x5^lik olan matrisimizi yanlar\u0131na 0 koyarak 7x7 format\u0131na d\u00f6n\u00fc\u015ft\u00fcr\u00fcp onun \u00fczerine 3x3 filitre uyguluyoruz ve sonu\u00e7 5x5 oluyor.\n\nMax Pooling=>Ama\u00e7 boyut k\u00fc\u00e7\u00fcltmektir.\u00c7ok b\u00fcy\u00fck size'ler bize zmana kaybettirir.Max pooling de matris i\u00e7indeki en b\u00fcy\u00fck de\u011feri seceriz.\n\nFlatting=>\u00d6rne\u011fin elimizde 2x2 bir matris olsun.Bu matrisi 4x1'lik formata \u00e7evirmeye flatting ad\u0131 verilir.As\u0131l ama\u00e7;Ann i\u00e7in input haz\u0131rl\u0131\u011f\u0131 yapmakt\u0131r\n\nFull Connection=>Basit bir ANN i\u015flemidir.Ancak burda dikkat edilmesi gereken bir\u015fey vard\u0131r;Ann'de t\u00fcm node'lar aras\u0131nda ba\u011flant\u0131 yapmak zorunda de\u011filiz ama full connction da bunu yapmak zorunday\u0131z.","3c0a978e":"<a id=\"15\"><\/a>\n### Data Augmentation\n* To avoid overfitting problem, we need to expand artificially our handwritten digit dataset\n* Alter the training data with small transformations to reproduce the variations of digit.\n* For example, the number is not centered The scale is not the same (some who write with big\/small numbers) The image is rotated.\n* <a href=\"https:\/\/ibb.co\/k24CUp\"><img src=\"https:\/\/preview.ibb.co\/nMxXUp\/augment.jpg\" alt=\"augment\" border=\"0\"><\/a>\n    \n","d92435d4":"<a id=\"12\"><\/a>\n### Define Optimizer   \n* Adam optimizer: Change the learning rate\n","53327381":"# Convolutional Neural Networks (CNN)\n<font color='blue'>\n<br>Content: \n* [Loading the Data Set](#1)\n* [Normalization, Reshape and Label Encoding ](#2)\n* [Train Test Split](#3)\n* [Convolutional Neural Network](#4)\n    * [What is Convolution Operation?](#5)\n    * [Same Padding](#6)\n    * [Max Pooling](#7)\n    * [Flattening](#8)\n    * [Full Connection](#9)\n* [Implementing with Keras](#10)\n    * [Create Model](#11)\n    * [Define Optimizer](#12)\n    * [Compile Model](#13)\n    * [Epochs and Batch Size](#14)\n    * [Data Augmentation](#15)\n    * [Fit the Model](#16)\n    * [Evaluate the Model](#17)\n* [Deep Learning Tutorial for Beginners](https:\/\/www.kaggle.com\/kanncaa1\/deep-learning-tutorial-for-beginners)\n* [Artificial Neural Network with Pytorch](https:\/\/www.kaggle.com\/kanncaa1\/pytorch-tutorial-for-deep-learning-lovers)\n* [Convolutional Neural Network with Pytorch](https:\/\/www.kaggle.com\/kanncaa1\/pytorch-tutorial-for-deep-learning-lovers)\n* [Recurrent Neural Network with Pytorch](https:\/\/www.kaggle.com\/kanncaa1\/recurrent-neural-network-with-pytorch)\n* [Conclusion](#18)\n","e7335497":"<a id=\"11\"><\/a>\n### Create Model\n* conv => max pool => dropout => conv => max pool => dropout => fully connected (2 layer)\n* Dropout: Dropout is a technique where randomly selected neurons are ignored during training\n* <a href=\"https:\/\/ibb.co\/jGcvVU\"><img src=\"https:\/\/preview.ibb.co\/e7yPPp\/dropout.jpg\" alt=\"dropout\" border=\"0\"><\/a>","9c73a599":"<a id=\"13\"><\/a>\n### Compile Model\n* categorical crossentropy\n* We make binary cross entropy at previous parts and in machine learning tutorial\n* At this time we use categorical crossentropy. That means that we have multi class.\n* <a href=\"https:\/\/ibb.co\/jm1bpp\"><img src=\"https:\/\/preview.ibb.co\/nN3ZaU\/cce.jpg\" alt=\"cce\" border=\"0\"><\/a>\n","079ee56a":"<a id=\"8\"><\/a>\n### Flattening\n* <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/image.ibb.co\/c7eVvU\/flattenigng.jpg\" alt=\"flattenigng\" border=\"0\"><\/a>","f871ea89":"<a id=\"6\"><\/a>\n### Same Padding\n* As we keep applying conv layers, the size of the volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features.\n* input size and output size are same.\n* <a href=\"https:\/\/ibb.co\/jUPkUp\"><img src=\"https:\/\/preview.ibb.co\/noH5Up\/padding.jpg\" alt=\"padding\" border=\"0\"><\/a>","206c3203":"<a id=\"14\"><\/a>\n### Epochs and Batch Size\n* Say you have a dataset of 10 examples (or samples). You have a **batch size** of 2, and you've specified you want the algorithm to run for 3 **epochs**. Therefore, in each epoch, you have 5 **batches** (10\/2 = 5). Each batch gets passed through the algorithm, therefore you have 5 iterations **per epoch**.\n* reference: https:\/\/stackoverflow.com\/questions\/4752626\/epoch-vs-iteration-when-training-neural-networks","4f21cb27":"<a id=\"5\"><\/a>\n### What is Convolution Operation?\n* We have some image and feature detector(3*3)\n* Feature detector does not need to be 3 by 3 matrix. It can be 5 by 5 or 7 by 7.\n* Feature detector = kernel = filter\n* Feauture detector detects features like edges or convex shapes. Example, if out input is dog, feature detector can detect features like ear or tail of the dog.\n* feature map = conv(input image, feature detector). Element wise multiplication of matrices.\n* feature map = convolved feature\n* Stride = navigating in input image.\n* We reduce the size of image. This is important bc code runs faster. However, we lost information. \n* We create multiple feature maps bc we use multiple feature detectors(filters).\n* Lets look at gimp. Edge detect: [0,10,0],[10,-4,10],[0,10,0]\n* <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/image.ibb.co\/m4FQC9\/gec.jpg\" alt=\"gec\" border=\"0\"><\/a>\n* After having convolution layer we use ReLU to break up linearity. Increase nonlinearity. Because images are non linear.\n* <a href=\"https:\/\/ibb.co\/mVZih9\"><img src=\"https:\/\/preview.ibb.co\/gbcQvU\/RELU.jpg\" alt=\"RELU\" border=\"0\"><\/a>","b722fd47":"<a id=\"9\"><\/a>\n### Full Connection\n* Neurons in a fully connected layer have connections to all activations in the previous layer\n* Artificial Neural Network\n* <a href=\"https:\/\/ibb.co\/hsS14p\"><img src=\"https:\/\/preview.ibb.co\/evzsAU\/fullyc.jpg\" alt=\"fullyc\" border=\"0\"><\/a>","e8f082e4":"<a id=\"3\"><\/a>\n## Train Test Split\n* We split the data into train and test sets.\n* test size is 10%.\n* train size is 90%."}}