{"cell_type":{"08d9caa0":"code","974f41ba":"code","99a81c8f":"code","e73773a8":"code","36e45edd":"code","00d89222":"code","2a41e1ce":"code","e8ad7905":"code","6bdd239e":"code","d1fc8a7a":"code","20b033f0":"code","fa5d27cf":"code","3861a4be":"code","ac07a5a4":"code","cb629493":"code","7aec65ba":"code","ece0b778":"code","0a7c323d":"code","452adacc":"code","982fa340":"code","eb12a508":"code","cbe4b345":"code","efaae965":"code","94f9e951":"code","710ffe98":"code","91e59e16":"code","37452627":"code","76fd1f79":"code","a5434f5a":"code","505e50ef":"code","20da3714":"code","dd377e32":"code","3c2c0b75":"code","abc879d9":"code","41392734":"code","790493b4":"code","ff40aaaa":"code","c58f3a9a":"code","44eade68":"code","82454faf":"code","6ca12dab":"code","56b83118":"code","2b58b35a":"code","283ac4ec":"code","010ebd13":"code","e1496f3b":"code","933fdb73":"code","ce10396f":"code","33349e5d":"code","bcb262ac":"code","1d2b658a":"code","5b89d755":"code","c3dafc05":"code","3eb7fc49":"code","2c4527d0":"code","7a9f7f9d":"code","3697f58c":"code","2634cce6":"code","4b29693a":"code","205ba0cd":"code","a1ba9b35":"code","bf9a7e16":"code","40dc6aa9":"code","0850069a":"code","4a1a69bd":"code","dbb2fb29":"code","c8097335":"code","285ec19d":"code","55090070":"code","c2748626":"code","f6484cc3":"code","ce94733c":"code","fdf7af08":"code","3d9c81e0":"code","db8061dd":"code","6290b965":"code","977236b8":"code","e35a722e":"code","1a1be6d6":"code","9915c393":"code","b89d71f4":"markdown","a2ecca63":"markdown","fac5039d":"markdown","b5c71133":"markdown","b4bb530f":"markdown","20100a58":"markdown","eec63031":"markdown","493c400a":"markdown","5ced1d3c":"markdown","6247322c":"markdown","2e6c4065":"markdown","00c21ad2":"markdown","b97a67bb":"markdown","d306b45f":"markdown"},"source":{"08d9caa0":"!pip install dexplot -q\n!pip install datasist -q\n!pip install xlrd -q\n%pip install autoviz -q\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport dexplot as dxp\nimport datasist as ds\nimport pickle\nfrom autoviz.AutoViz_Class import AutoViz_Class\nimport plotly.express as px","974f41ba":"import plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff\n\n\n\nfrom sklearn.compose import make_column_transformer,ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold,cross_val_score,RepeatedStratifiedKFold,train_test_split\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,LabelEncoder,LabelBinarizer\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nfrom numpy import absolute,mean,std\nfrom imblearn.over_sampling import SMOTE,ADASYN\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,accuracy_score,auc\nfrom imblearn.ensemble import BalancedRandomForestClassifier,EasyEnsembleClassifier,BalancedBaggingClassifier\nfrom sklearn.metrics import classification_report,f1_score,roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV,RandomizedSearchCV,StratifiedKFold,cross_val_score\nfrom sklearn.svm import LinearSVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom xgboost import XGBClassifier\n\n# for model explanation\nimport shap \nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\n\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)\n","99a81c8f":"data = pd.read_csv('..\/input\/insurance-company-complaints\/Insurance_Company_Complaints__Resolutions__Status__and_Recoveries.csv',parse_dates=True)\ndata['Opened'] = pd.to_datetime(data['Opened'])\ndata['Closed'] = pd.to_datetime(data['Closed'])","e73773a8":"data.head()","36e45edd":"data.info()","00d89222":"ds.structdata.describe(data)","2a41e1ce":"ds.structdata.get_unique_counts(data)","e8ad7905":"ds.structdata.display_missing(data)","6bdd239e":"data['Status'].value_counts()","d1fc8a7a":"def dataset_info(dataset, dataset_name: str):\n    print(f\"Dataset Name: {dataset_name} \\\n        | Number of Samples: {dataset.shape[0]} \\\n        | Number of Columns: {dataset.shape[1]}\")\n    print(30*\"=\")\n    print(\"Column             Data Type\")\n    print(dataset.dtypes)\n    print(30*\"=\")\n    missing_data = dataset.isnull().sum()\n    if sum(missing_data) > 0:\n        print(missing_data[missing_data.values > 0])\n    else:\n        print(\"No Missing Data on this Dataset!\")\n    print(30*\"=\")\n    print(\"Memory Usage: {} MB\".\\\n         format(np.round(\n         dataset.memory_usage(index=True).sum() \/ 10e5, 3\n         )))","20b033f0":"dataset_info(data,'insurance')","fa5d27cf":"data['year_open'], data['month_open'],data['date_open'] = data['Opened'].dt.year, data['Opened'].dt.month,data['Opened'].dt.day\ndata['year_close'], data['month_close'],data['date_close'] = data['Closed'].dt.year, data['Closed'].dt.month,data['Closed'].dt.day","3861a4be":"data.sample(5)","ac07a5a4":"dxp.count('Status',data =data,figsize=(10,5),cmap='rainbow',title = 'Distribution for Target Column')","cb629493":"dxp.count(val='Status', data=data, split='Conclusion',cmap='bold',figsize=(15,5),title='Distribution of Status w.r.t Conclusion')","7aec65ba":"dxp.count(val='Status', data=data, split='Reason',cmap='bold_r',figsize=(15,5),title='Distribution of Status w.r.t Conclusion')","ece0b778":"dxp.count('Reason',data =data,figsize=(15,5),cmap='viridis',title='Distribution of Reason')","0a7c323d":"dxp.count('Conclusion',data =data,figsize=(10,5),cmap='plasma',title='Distribution of Conclusion')","452adacc":"coverage_count  = data['SubCoverage'].value_counts()\ncoverage_count = coverage_count[:10,]\nplt.figure(figsize=(20,5))\nsns.barplot(coverage_count.index, coverage_count.values, alpha=0.8)\nplt.title('Top 10 Insurance SubCoverage')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('SubCoverage', fontsize=12)\nplt.show()","982fa340":"coverage_count  = data['Coverage'].value_counts()\ncoverage_count = coverage_count[:10,]\nplt.figure(figsize=(20,5))\nsns.barplot(coverage_count.index, coverage_count.values, alpha=0.8)\nplt.title('Top 10 Insurance Coverage')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('coverage', fontsize=12)\nplt.show()","eb12a508":"data_status = data['Status'].value_counts()\n\nlabel_re = data_status.index\nsize_re = data_status.values\n\n\ntrace = go.Pie(\n         labels = label_re,\n         values = size_re,\n         marker = dict(colors = ['gold' 'lightgreen', 'orange', 'yellow', 'pink']),\n         name = 'complaint status',\n         hole = 0.2)\n\ndf2 = [trace]\n\nlayout1 = go.Layout(\n           title = 'Distribution of complaints status')\nfig = go.Figure(data = df2, layout = layout1)\npy.iplot(fig)","cbe4b345":"dxp.hist(val='Recovery', data=data,figsize=(10,5),title='Histogram for Recovery')","efaae965":"AV = AutoViz_Class()\n\n# Let's now visualize the plots generated by AutoViz.\nreport_2 = AV.AutoViz(\"Insurance_Company_Complaints__Resolutions__Status__and_Recoveries.csv\")","94f9e951":"fig = px.area(data, x=\"year_open\", y=\"Recovery\", color=\"Status\", line_group=\"Status\",title='Area Plot for Year wise Recovery')\nfig.show()","710ffe98":"fig = px.violin(data, y=\"date_open\", x=\"Status\", color=\"Status\", box=True, points=\"all\",title='Violin Plot for Status')\nfig.show()","91e59e16":"fig = px.violin(data, y=\"date_close\", x=\"Status\", color=\"Status\", box=True, points=\"all\",title='Violin plot for Closing Date w.r.t Status')\nfig.show()","37452627":"fig = px.box(data, y=\"Recovery\", x=\"Status\", color=\"Status\", points=\"all\",title='Box Plot for Recovery Done w.r.t Status')\nfig.show()","76fd1f79":"data[data['Company'] == '21st Century Insurance Company'][['Opened', 'Reason', 'Status','Closed']].head(10).style.background_gradient('Pastel1')","a5434f5a":"group_ops = data.groupby(['Company', 'Status'])[['Opened','Closed']]\ngroup_ops.first()","505e50ef":"data_comp = data['Company'].value_counts()\ndata_comp = data_comp[:10,]\n\n\nlabel_re = data_comp.index\nsize_re = data_comp.values\n\n\ntrace = go.Pie(\n         labels = label_re,\n         values = size_re,\n         name = 'company',\n         hole = 0.2)\n\ndf2 = [trace]\n\nlayout1 = go.Layout(\n           title = 'Top 10 Distribution of Insurance company')\nfig = go.Figure(data = df2, layout = layout1)\npy.iplot(fig)","20da3714":"data_depo = data['Disposition'].value_counts()\ndata_depo = data_depo[:10,]\n\n\nlabel_re = data_depo.index\nsize_re = data_depo.values\n\n\ntrace = go.Pie(\n         labels = label_re,\n         values = size_re,\n         name = 'company',\n         hole = 0.2)\n\ndf2 = [trace]\n\nlayout1 = go.Layout(\n           title = 'Top 10 Distribution of Deposition')\nfig = go.Figure(data = df2, layout = layout1)\npy.iplot(fig)","dd377e32":"plt.rcParams['figure.figsize'] = (15, 10)\nsns.heatmap(data.corr(), cmap = 'copper')\nplt.title('Heat Map for Correlations', fontsize = 20)\nplt.show()","3c2c0b75":"data[['Company','date_open']].groupby(['Company'], \n                as_index = False).mean().sort_values(by = 'date_open', ascending = False)","abc879d9":"df = data.copy()\nscores = pd.DataFrame(columns=['Model', 'Score'])\nscores_ohe = pd.DataFrame(columns=['Model', 'Score'])","41392734":"df = ds.feature_engineering.drop_missing(df,50)","790493b4":"df = ds.feature_engineering.fill_missing_cats(df)\ndf = ds.feature_engineering.fill_missing_num(df)\n\nds.structdata.display_missing(df)","ff40aaaa":"df = df.drop(['File No.','Opened', 'Closed'], axis = 1)","c58f3a9a":"df['month_close'] = df.month_close.astype('int')\ndf['date_close'] = df.date_close.astype('int')\ndf['year_close'] = df.year_close.astype('int')\n# let's check the columns after deleting the columns\nprint(df.columns)\nprint(100*'*')\ndf.head()","44eade68":"df_ohe = df.copy()\nx = df.drop(['Status'], axis = 1)\ny = df['Status']\n\nprint(\"Shape of x :\", x.shape)\nprint(\"Shape of y :\", y.shape)","82454faf":"le = LabelEncoder()\nfor i in range(0,x.shape[1]):\n    if x.dtypes[i]=='object':\n        x[x.columns[i]] = le.fit_transform(x[x.columns[i]])\n        \nprint(x)","6ca12dab":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n\nprint(\"Shape of X_train :\", X_train.shape)\nprint(\"Shape of X_test :\", X_test.shape)\nprint(\"Shape of y_train :\", y_train.shape)\nprint(\"Shape of y_test :\", y_test.shape)","56b83118":"train_cols_list = X_train.columns.values.tolist()","2b58b35a":"from collections import Counter\nprint('Classes and number of values in trainset',Counter(y_train))","283ac4ec":"oversample = ADASYN()\nX_train,y_train = oversample.fit_resample(X_train,y_train)\nprint('Classes and number of values in trainset after ADSYN:',Counter(y_train))","010ebd13":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","e1496f3b":"%%time\nclassifiers = [\n\n    #GLM\n    LogisticRegression(),\n\n    #Navies Bayes\n    BernoulliNB(),\n    GaussianNB(),\n\n    #Discriminant Analysis\n\n    #Ensemble Methods\n    AdaBoostClassifier(),\n    BaggingClassifier(),\n    ExtraTreesClassifier(),\n    GradientBoostingClassifier(),\n    RandomForestClassifier(),\n\n\n]\n\n\ndef find_best_algorithms(classifier_list, X, y):\n    # Cross validate model with Kfold stratified cross validation\n    kfold = StratifiedKFold(n_splits=10,random_state=None)\n\n    # Grab the cross validation scores for each algorithm\n    cv_results = [cross_val_score(classifier, X, y, scoring = \"accuracy\", cv = kfold) for classifier in classifier_list]\n    cv_means = [cv_result.mean()  for cv_result in cv_results]\n    cv_std = [cv_result.std() for cv_result in cv_results]\n    algorithm_names = [alg.__class__.__name__ for alg in classifiers]\n\n    # Create a DataFrame of all the CV results\n    cv_results = pd.DataFrame({\n        \"Mean\": cv_means,\n        \"Std\": cv_std,\n        \"Algorithm\": algorithm_names\n    }).sort_values(by='Mean')\n    return cv_results\n\n\nalgorithm_results = find_best_algorithms(classifiers, X_train, y_train)\nalgorithm_results\n","933fdb73":"model_lr = LogisticRegression()\nmodel_lr.fit(X_train, y_train)\n\nlrpred = model_lr.predict(X_test)\n\nprint(\"Training Accuracy: \", model_lr.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_lr.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, lrpred,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,lrpred)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# confusion matrix\ncm = confusion_matrix(y_test, lrpred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'rainbow')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, lrpred)\nprint(cr)\nscores = scores.append({'Model': 'Logistic Regression', 'Score': roc_score}, ignore_index=True)","ce10396f":"model_lr_cv = LogisticRegressionCV(cv=10)\nmodel_lr_cv.fit(X_train, y_train)\n\nlrpred_cv = model_lr_cv.predict(X_test)\n\nprint(\"Training Accuracy: \", model_lr_cv.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_lr_cv.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, lrpred_cv,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,lrpred_cv)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# confusion matrix\ncm = confusion_matrix(y_test, lrpred_cv)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'viridis')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, lrpred_cv)\nprint(cr)\nscores = scores.append({'Model': 'Logistic RegressionCV', 'Score': roc_score}, ignore_index=True)","33349e5d":"model_nb = GaussianNB()\nmodel_nb.fit(X_train, y_train)\n\nnbpred = model_nb.predict(X_test)\n\nprint('F1 Score',f1_score(y_test, nbpred,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,nbpred)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# confusion matrix\ncm = confusion_matrix(y_test, nbpred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'twilight')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, nbpred)\nprint(cr)\nscores = scores.append({'Model': 'GaussianNB', 'Score': roc_score}, ignore_index=True)","bcb262ac":"model_u = RandomForestClassifier(n_estimators=100, class_weight='balanced',random_state=0)\nmodel_u.fit(X_train, y_train)\n\ny_pred_rf = model_u.predict(X_test)\n\nprint(\"Training Accuracy: \", model_u.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_u.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'winter')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\nscores = scores.append({'Model': 'Random-Forest', 'Score': roc_score}, ignore_index=True)","1d2b658a":"model_gb = GradientBoostingClassifier()\nmodel_gb.fit(X_train, y_train)\n\ny_pred_rf = model_gb.predict(X_test)\n\nprint(\"Training Accuracy: \", model_gb.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_gb.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'vlag')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\nscores = scores.append({'Model': 'Gradient Boosting', 'Score': roc_score}, ignore_index=True)","5b89d755":"model_xgb = XGBClassifier()\nmodel_xgb.fit(X_train, y_train)\n\ny_pred_rf = model_xgb.predict(X_test)\n\nprint(\"Training Accuracy: \", model_xgb.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_xgb.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'vlag_r')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\nscores = scores.append({'Model': 'XGradient Boosting', 'Score': roc_score}, ignore_index=True)","c3dafc05":"model_brf = BalancedRandomForestClassifier(n_estimators = 100,max_depth=8, random_state = 0)\n\nmodel_brf.fit(X_train, y_train)\ny_pred_brf = model_brf.predict(X_test)\n\nprint(\"Training Accuracy: \", model_brf.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_brf.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_brf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_brf)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_brf)\nprint(cr)\n\n# making a confusion matrix\nplt.rcParams['figure.figsize'] = (5, 5)\ncm = confusion_matrix(y_test, y_pred_brf)\nsns.heatmap(cm, annot = True, cmap = 'magma')\nplt.show()\nscores = scores.append({'Model': 'Balanced RF', 'Score': roc_score}, ignore_index=True)","3eb7fc49":"model1 = EasyEnsembleClassifier(n_estimators = 100, random_state = 0)\n\nmodel1.fit(X_train, y_train)\ny_pred_ef = model1.predict(X_test)\n\nprint(\"Training Accuracy: \", model1.score(X_train, y_train))\nprint('Testing Accuarcy: ', model1.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_ef,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_ef)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_ef)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test, y_pred_ef)\nsns.heatmap(cm, annot = True, cmap = 'copper')\nplt.show()\nscores = scores.append({'Model': 'Easy-Ensemble CLF', 'Score': roc_score}, ignore_index=True)","2c4527d0":"model2 = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(),\n                                 sampling_strategy = 'auto',\n                                 replacement = False,\n                                 random_state = 0)\n\nmodel2.fit(X_train, y_train)\ny_pred_bc = model2.predict(X_test)\n\nprint(\"Training Accuracy: \", model2.score(X_train, y_train))\nprint('Testing Accuarcy: ', model2.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_bc,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_bc)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_bc)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test, y_pred_bc)\nsns.heatmap(cm, annot = True, cmap = 'Purples')\nplt.show()\nscores = scores.append({'Model': 'Balanced Bagging Classifier', 'Score': roc_score}, ignore_index=True)","7a9f7f9d":"scores.sort_values(by='Score', ascending=False)","3697f58c":"n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\nmax_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nprint(random_grid)","2634cce6":"rf_random = RandomizedSearchCV(estimator=model_u, param_distributions=random_grid,\n                              n_iter = 100, scoring='f1_weighted', \n                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n                              return_train_score=True)\n\nrf_random.fit(X_train, y_train)","4b29693a":"rf_random.best_params_","205ba0cd":"rf_random.cv_results_","a1ba9b35":"# fitting up tuned model param.\nmodel_tuned = RandomForestClassifier(n_estimators =  944,min_samples_split = 10,min_samples_leaf= 1,max_depth = None,bootstrap= False)\nmodel_tuned.fit(X_train, y_train)\n\ny_pred_rf = model_tuned.predict(X_test)\n\nprint(\"Training Accuracy: \", model_tuned.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_tuned.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'YlOrBr')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)","bf9a7e16":"model_pipeline = Pipeline(steps=[('scaling',StandardScaler()),\n                                 ('RFTuned', RandomForestClassifier(n_estimators =  944,min_samples_split = 10,min_samples_leaf= 1,max_depth = None,bootstrap= False))])\nmodel_pipeline.fit(X_train, y_train)\n\nmodel_pipeline_pred = model_pipeline.predict(X_test)\n\nprint(\"Training Accuracy: \", model_pipeline.score(X_train, y_train))\nprint('Testing Accuarcy: ', model_pipeline.score(X_test, y_test))\nprint('F1 Score',f1_score(y_test, model_pipeline_pred,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test,model_pipeline_pred)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test, model_pipeline_pred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'RdGy')\nplt.show()\n\n# classification report\ncr = classification_report(y_test, model_pipeline_pred)\nprint(cr)\n","40dc6aa9":"df_ohe.head()","0850069a":"X = df_ohe.drop(['Status'], axis = 1)\nY = df_ohe['Status']\n\nprint(\"Shape of x :\", X.shape)\nprint(\"Shape of y :\", Y.shape)","4a1a69bd":"categorical_feature_mask = X.dtypes == object\ncategorical_cols = X.columns[categorical_feature_mask].tolist()\n\nfrom sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(handle_unknown='ignore', sparse = False)\n# Apply ohe on data\nohe.fit(X[categorical_cols])\ncat_ohe = ohe.transform(X[categorical_cols])\n\n#Create a Pandas DataFrame of the hot encoded column\nohe_df = pd.DataFrame(cat_ohe, columns = ohe.get_feature_names(input_features = categorical_cols))\n#concat with original data and drop original columns\nfinal_ohe_df = pd.concat([X, ohe_df], axis=1).drop(columns = categorical_cols, axis=1)\nX = final_ohe_df","dbb2fb29":"X_train_ohe, X_test_ohe, y_train_ohe, y_test_ohe = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n\nprint(\"Shape of x_train :\", X_train_ohe.shape)\nprint(\"Shape of x_test :\", X_test_ohe.shape)\nprint(\"Shape of y_train :\", y_train_ohe.shape)\nprint(\"Shape of y_test :\", y_test_ohe.shape)","c8097335":"from collections import Counter\nprint('Classes and number of values in trainset',Counter(y_train_ohe))","285ec19d":"oversample = ADASYN()\nX_train_ohe,y_train_ohe = oversample.fit_resample(X_train_ohe,y_train_ohe)\nprint('Classes and number of values in trainset after ADSYN:',Counter(y_train_ohe))","55090070":"sc = StandardScaler()\nX_train_ohe = sc.fit_transform(X_train_ohe)\nX_test_ohe = sc.transform(X_test_ohe)","c2748626":"model_lr_ohe = LogisticRegression(C=1,solver = 'lbfgs',random_state=2)\nmodel_lr_ohe.fit(X_train_ohe, y_train_ohe)\n\nlrpred = model_lr_ohe.predict(X_test_ohe)\n\nprint(\"Training Accuracy: \", model_lr_ohe.score(X_train_ohe, y_train_ohe))\nprint('Testing Accuarcy: ', model_lr_ohe.score(X_test_ohe, y_test_ohe))\nprint('F1 Score',f1_score(y_test_ohe, lrpred,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test_ohe,lrpred)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test_ohe, lrpred)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'rainbow')\nplt.show()\n\n# classification report\ncr = classification_report(y_test_ohe, lrpred)\nprint(cr)\nscores_ohe = scores_ohe.append({'Model': 'LogisticRegression', 'Score': roc_score}, ignore_index=True)","f6484cc3":"model_uohe = RandomForestClassifier(n_estimators=100, class_weight='balanced',random_state = 0)\nmodel_uohe.fit(X_train_ohe, y_train_ohe)\n\ny_pred_rf = model_uohe.predict(X_test_ohe)\n\nprint(\"Training Accuracy: \", model_uohe.score(X_train_ohe, y_train_ohe))\nprint('Testing Accuarcy: ', model_uohe.score(X_test_ohe, y_test_ohe))\nprint('F1 Score',f1_score(y_test_ohe, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test_ohe,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test_ohe, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'winter')\nplt.show()\n\n# classification report\ncr = classification_report(y_test_ohe, y_pred_rf)\nprint(cr)\nscores_ohe = scores_ohe.append({'Model': 'Random-Forest', 'Score': roc_score}, ignore_index=True)","ce94733c":"modelrf_ohe = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(),\n                                 sampling_strategy = 'auto',\n                                 replacement = False,\n                                 random_state = 0)\n\nmodelrf_ohe.fit(X_train_ohe, y_train_ohe)\ny_pred_bc = modelrf_ohe.predict(X_test_ohe)\n\nprint(\"Training Accuracy: \", modelrf_ohe.score(X_train_ohe, y_train_ohe))\nprint('Testing Accuarcy: ', modelrf_ohe.score(X_test_ohe, y_test_ohe))\nprint('F1 Score',f1_score(y_test_ohe, y_pred_bc,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test_ohe,y_pred_bc)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# making a classification report\ncr = classification_report(y_test_ohe,  y_pred_bc)\nprint(cr)\n\n# making a confusion matrix\ncm = confusion_matrix(y_test_ohe, y_pred_bc)\nsns.heatmap(cm, annot = True, cmap = 'Purples')\nplt.show()\nscores_ohe = scores_ohe.append({'Model': 'Balanced Bagging Classifier', 'Score': roc_score}, ignore_index=True)","fdf7af08":"model_brf_ohe = BalancedRandomForestClassifier(n_estimators = 100,max_depth=8, random_state = 0)\n\nmodel_brf_ohe.fit(X_train_ohe, y_train_ohe)\ny_pred_brf_ohe = model_brf_ohe.predict(X_test_ohe)\n\nprint(\"Training Accuracy: \", model_brf_ohe.score(X_train_ohe, y_train_ohe))\nprint('Testing Accuarcy: ', model_brf_ohe.score(X_test_ohe, y_test_ohe))\nprint('F1 Score',f1_score(y_test_ohe, y_pred_brf_ohe,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test_ohe,y_pred_brf_ohe)\nprint(\"ROC AUC Score - \",roc_score)\n\n\n# making a classification report\ncr = classification_report(y_test_ohe,  y_pred_brf_ohe)\nprint(cr)\n\n# making a confusion matrix\nplt.rcParams['figure.figsize'] = (5, 5)\ncm = confusion_matrix(y_test_ohe, y_pred_brf_ohe)\nsns.heatmap(cm, annot = True, cmap = 'magma')\nplt.show()\nscores_ohe = scores_ohe.append({'Model': 'Balanced RF', 'Score': roc_score}, ignore_index=True)","3d9c81e0":"model_xgb_ohe = XGBClassifier()\nmodel_xgb_ohe.fit(X_train_ohe, y_train_ohe)\n\ny_pred_rf = model_xgb_ohe.predict(X_test_ohe)\n\nprint(\"Training Accuracy: \", model_xgb_ohe.score(X_train_ohe, y_train_ohe))\nprint('Testing Accuarcy: ', model_xgb_ohe.score(X_test_ohe, y_test_ohe))\nprint('F1 Score',f1_score(y_test_ohe, y_pred_rf,average = 'weighted'))\nroc_score = multiclass_roc_auc_score(y_test_ohe,y_pred_rf)\nprint(\"ROC AUC Score - \",roc_score)\n\n# confusion matrix\ncm = confusion_matrix(y_test_ohe, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, cmap = 'winter')\nplt.show()\n\n# classification report\ncr = classification_report(y_test_ohe, y_pred_rf)\nprint(cr)\nscores_ohe = scores_ohe.append({'Model': 'XGradient Boosting', 'Score': roc_score}, ignore_index=True)","db8061dd":"scores_ohe.sort_values('Score',ascending=False)","6290b965":"dxp.bar(x = 'Model',y = 'Score',data = scores,cmap='geyser',figsize=(10,5),title='Model Score without OHE')","977236b8":"dxp.bar(x = 'Model',y = 'Score',data = scores_ohe,cmap='sunsetdark_r',figsize=(10,5),title='Model Score with OHE')","e35a722e":"importances = model_u.feature_importances_\nindices = np.argsort(importances)\n\nfeatures = train_cols_list\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","1a1be6d6":"## Using Random Forest Model For Interpretation\nshap_values = shap.TreeExplainer(model_u).shap_values(X_train)","9915c393":"shap.summary_plot(shap_values, train_cols_list, plot_type=\"bar\")","b89d71f4":"* <b> Since Data is Imbalanced Using Imblearn Balanced Classifiers <\/b>","a2ecca63":"## END","fac5039d":"* <b> Setting up ML Pipeline<\/b>\n\n##### Validation of Pipeline created","b5c71133":"## 2.Data Preprocessing and Feature Extraction\n### Data Preprocessing follows these two approaches-\n* Without One-hot Encoded Variables \n* With One-hot Encoded Variables","b4bb530f":"### 3.2 Model Traning with One-hot  Encoded Features","20100a58":"# Insurance Company Complaint Prediction\n\n<img src = \"https:\/\/cdn.wpforms.com\/wp-content\/uploads\/2019\/03\/create-a-complaint-form.jpg\">\n\n## Dataset Description\n\n### Features Available in Dataset -\n* Company          \n* File No.            \n* Opened       \n* Closed       \n* Coverage             \n* SubCoverage         \n* Reason               \n* SubReason            \n* Disposition          \n* Conclusion           \n* Recovery       \n* Status      \n\n<b> Data for this Notebook can be found [here](https:\/\/catalog.data.gov\/dataset\/insurance-company-complaints-resolutions-status-and-recoveries). <\/b>\n\n","eec63031":"##### Dropping Features Having more than 50 % null values","493c400a":"#### The insurance complaint year opened plays significant role in model's output followed by closing year & closing date since its multi class classification stacked bar plot shows impact of classes on model performance.","5ced1d3c":"## 1. Exploratory Data Analysis","6247322c":"* <b> Fixing up Imbalance Classes with AdaSyn","2e6c4065":"* <b>Univariate and Bivariate Analysis<\/b>","00c21ad2":"* <b> Hyper Parameter Tuning for Random Forest Model <\/b>","b97a67bb":"## 4.Feature Importance\/Model Explanation using Shap","d306b45f":"## 3.Predictive Modelling\n### 3.1 Model Training without OHE features\n#### Model Selection and Hyperparameter Tuning"}}