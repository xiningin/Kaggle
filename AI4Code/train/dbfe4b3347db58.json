{"cell_type":{"c115eb4e":"code","037f44f6":"code","22a6a536":"code","1dd86591":"code","d95811fc":"code","b2eaebe5":"code","e771fce6":"code","1b700635":"code","6600966f":"code","38339a9c":"code","bd054f8d":"code","42b15e59":"code","51972094":"code","37032ef5":"code","531a5af4":"code","30fe1429":"code","9bf69f0d":"code","7fc35897":"markdown","ffffe32f":"markdown"},"source":{"c115eb4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","037f44f6":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.combine import SMOTEENN\nfrom collections import Counter\n\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import precision_score,accuracy_score\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV,RepeatedStratifiedKFold\n\nfrom sklearn.metrics import roc_curve,roc_auc_score, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.multiclass import OneVsRestClassifier","22a6a536":"df = pd.read_csv('\/kaggle\/input\/zoo-animals\/zoo.csv')\ndf.head()","1dd86591":"df.shape","d95811fc":"df.info()","b2eaebe5":"df.isna().sum()","e771fce6":"fig = px.pie(names=df['class_type'].value_counts().index,\n            values=df['class_type'].value_counts(),\n            title='Class Type Distribution')\n\nfig.update_traces(textposition='inside',marker = dict(colors=px.colors.qualitative.Pastel2))\nfig.show()","1b700635":"\nx = df.drop(['animal_name','class_type'],1)\ny= df['class_type']\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state=104,test_size=0.2)","6600966f":"counter = Counter(y_train)\nfor k,v in counter.items():\n    per = v\/len(y_train)*100\n    print('Class=%d, n=%d (%.3f%%)'% (k,v,per))\n   \n(px.bar(x=counter.keys(),\n       y=counter.values(),\n       text=counter.values())\n.update_traces(marker=dict(color='lightyellow', line=dict(color='gold',width=2)))\n.add_annotation(x=4,y=30,showarrow=False,text='Dataset is imbalance',font=dict(color='red',size=15)))","38339a9c":"models =[('LR', LogisticRegression(max_iter=1000)),('SVC',SVC()),\n         ('XGB',XGBClassifier(eval_metric='mlogloss')),('DT',DecisionTreeClassifier()),\n         ('RF',RandomForestClassifier()),('Ridge',RidgeClassifier()),\n         ('LGBM',LGBMClassifier()),('ADA',AdaBoostClassifier()),\n         ('KNN',KNeighborsClassifier(n_neighbors=2)),('GNB',GaussianNB())]\n\nresults = []\nnames = []\nfinal_result = []\n\nfor name,model in models:\n    model.fit(x_train,y_train)\n    model_score = model.predict(x_test)\n    score = precision_score(y_test,model_score,average='macro')\n    results.append(score)\n    names.append(name)\n    final_result.append((name,score))\n    \nfinal_result.sort(key=lambda k:k[1],reverse=True)","bd054f8d":"final_result","42b15e59":"x_train1,x_test1,y_train1,y_test1 = train_test_split(x,y,random_state=104,test_size=0.2)\n\ncounter = Counter(y_train1)\nfor k,v in counter.items():\n    per = v\/len(y_train1)*100\n    print('Class=%d, n=%d (%.3f%%)'% (k,v,per))\n   \n(px.bar(x=counter.keys(),\n       y=counter.values(),\n       text=counter.values(),\n       title='Before SMOTE')\n.update_traces(marker=dict(color='azure', line=dict(color='teal',width=2)))\n.update_layout(margin={'b':0,'l':0,'r':0,},\n                 paper_bgcolor='rgb(248, 248, 255)',\n                 plot_bgcolor='rgb(248, 248, 255)',\n                 title={'font':{\n                             'family':'monospace',\n                             'size':22,\n                             'color': 'grey'\n                         },\n                        'x':0.45,'y':0.9}))","51972094":"oversample = SMOTE(k_neighbors=2)\nx_train1,y_train1 = oversample.fit_resample(x_train1,y_train1)","37032ef5":"counter = Counter(y_train1)\nfor k,v in counter.items():\n    per = v\/len(y_train1)*100\n    print('Class=%d, n=%d (%.3f%%)'% (k,v,per))\n   \n(px.bar(x=counter.keys(),\n       y=counter.values(),\n       text=counter.values(),\n       title='After SMOTE')\n.update_traces(marker=dict(color='azure', line=dict(color='teal',width=2)))\n.update_layout(margin={'b':0,'l':0,'r':0,},\n                 paper_bgcolor='rgb(248, 248, 255)',\n                 plot_bgcolor='rgb(248, 248, 255)',\n                 title={'font':{\n                             'family':'monospace',\n                             'size':22,\n                             'color': 'grey'\n                         },\n                        'x':0.45,'y':0.9}))","531a5af4":"models =[('LR', LogisticRegression(max_iter=1000)),('SVC',SVC()),\n         ('XGB',XGBClassifier(eval_metric='mlogloss')),('DT',DecisionTreeClassifier()),\n         ('RF',RandomForestClassifier()),('Ridge',RidgeClassifier()),\n         ('LGBM',LGBMClassifier()),('ADA',AdaBoostClassifier()),\n         ('KNN',KNeighborsClassifier(n_neighbors=2)),('GNB',GaussianNB())]\n\nresults_smote = []\nnames_smote = []\nfinal_result_smote = []\n\nfor name,model in models:\n    model.fit(x_train1,y_train1)\n    model_score = model.predict(x_test1)\n    score = precision_score(y_test1,model_score,average='macro')\n    results_smote.append(score)\n    names_smote.append(name)\n    final_result_smote.append((name,score))\n    \nfinal_result_smote.sort(key=lambda k:k[1],reverse=True)","30fe1429":"final_result_smote","9bf69f0d":"clf = OneVsRestClassifier(LogisticRegression())\nclf.fit(x_train, y_train)\npred = clf.predict(x_test)\npred_prob = clf.predict_proba(x_test)\n\n# roc curve for classes\nfpr = {}\ntpr = {}\nthresh ={}\n\nn_class = 7\n\nfor i in range(n_class):    \n    fpr[i], tpr[i], thresh[i] = roc_curve(y_test, pred_prob[:,i], pos_label=i)\n    \n# plotting    \nplt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\nplt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\nplt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\nplt.plot(fpr[3], tpr[3], linestyle='--',color='yellow', label='Class 3 vs Rest')\nplt.plot(fpr[4], tpr[4], linestyle='--',color='pink', label='Class 4 vs Rest')\nplt.plot(fpr[5], tpr[5], linestyle='--',color='gold', label='Class 5 vs Rest')\nplt.plot(fpr[6], tpr[6], linestyle='--',color='red', label='Class 6 vs Rest')\n\nplt.title('Multiclass ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.savefig('Multiclass ROC',dpi=300);    ","7fc35897":"\n# <span style=\"color:blue;\"><p style=\"text-align:center;\"> SMOTE(OverSampling) <\/p><\/span>","ffffe32f":"# <span style=\"color:blue;\"><p style=\"text-align:center;\"> Multiclass ROC Curve <\/p><\/span>"}}