{"cell_type":{"c68c48ab":"code","194cf2d3":"code","a4d966bb":"code","eaa9b7e8":"code","64b9cedb":"code","b015532b":"code","64026471":"code","e63c22c0":"code","8eb30311":"code","a0b16c50":"code","06d743c5":"code","d98c0e3f":"code","05786aa8":"code","d19e9ac7":"code","4fb76a8d":"code","26e567b3":"code","aca3f881":"code","2c38c909":"code","1d691057":"code","d14d11b0":"code","a76c8b69":"code","196e9af9":"code","863bd22a":"code","85f7948c":"code","c4ba17c5":"code","ca348639":"markdown","2b1a0bdf":"markdown","a15a5bfb":"markdown","f54fb5f3":"markdown","ce86600c":"markdown"},"source":{"c68c48ab":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","194cf2d3":"import pandas as pd\nimport numpy as np\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix\n\nfrom sklearn import manifold\n\ndata_dir = '..\/input\/petfinder-pawpularity-score'","a4d966bb":"train = pd.read_csv(data_dir + '\/train.csv')\ntest = pd.read_csv(data_dir + '\/test.csv')\nsample_submission = pd.read_csv(data_dir + '\/sample_submission.csv')","eaa9b7e8":"train.shape, test.shape, sample_submission.shape","64b9cedb":"train.head()","b015532b":"train.describe()","64026471":"train.info()","e63c22c0":"train.isnull().sum()","8eb30311":"from cycler import cycler\n\nraw_light_palette = [\n    (0, 122, 255), # Blue\n    (255, 149, 0), # Orange\n    (52, 199, 89), # Green\n    (255, 59, 48), # Red\n    (175, 82, 222),# Purple\n    (255, 45, 85), # Pink\n    (88, 86, 214), # Indigo\n    (90, 200, 250),# Teal\n    (255, 204, 0)  # Yellow\n]\n\nraw_dark_palette = [\n    (10, 132, 255), # Blue\n    (255, 159, 10), # Orange\n    (48, 209, 88),  # Green\n    (255, 69, 58),  # Red\n    (191, 90, 242), # Purple\n    (94, 92, 230),  # Indigo\n    (255, 55, 95),  # Pink\n    (100, 210, 255),# Teal\n    (255, 214, 10)  # Yellow\n]\n\nraw_gray_light_palette = [\n    (142, 142, 147),# Gray\n    (174, 174, 178),# Gray (2)\n    (199, 199, 204),# Gray (3)\n    (209, 209, 214),# Gray (4)\n    (229, 229, 234),# Gray (5)\n    (242, 242, 247),# Gray (6)\n]\n\nraw_gray_dark_palette = [\n    (142, 142, 147),# Gray\n    (99, 99, 102),  # Gray (2)\n    (72, 72, 74),   # Gray (3)\n    (58, 58, 60),   # Gray (4)\n    (44, 44, 46),   # Gray (5)\n    (28, 28, 39),   # Gray (6)\n]\n\nlight_palette = np.array(raw_light_palette)\/255\ndark_palette = np.array(raw_dark_palette)\/255\ngray_light_palette = np.array(raw_gray_light_palette)\/255\ngray_dark_palette = np.array(raw_gray_dark_palette)\/255\n\nmpl.rcParams['axes.prop_cycle'] = cycler('color',dark_palette)\nmpl.rcParams['figure.facecolor']  = gray_dark_palette[-2]\nmpl.rcParams['figure.edgecolor']  = gray_dark_palette[-2]\nmpl.rcParams['axes.facecolor'] =  gray_dark_palette[-2]\n\nwhite_color = gray_light_palette[-2]\nmpl.rcParams['text.color'] = white_color\nmpl.rcParams['axes.labelcolor'] = white_color\nmpl.rcParams['axes.edgecolor'] = white_color\nmpl.rcParams['xtick.color'] = white_color\nmpl.rcParams['ytick.color'] = white_color\n\nmpl.rcParams['figure.dpi'] = 200\n\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right'] = False","a0b16c50":"# Heatmap for the entire data\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 12))\ntrain_corr = train.corr()\n\nmask = np.zeros_like(train_corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(train_corr, ax=ax,\n           square=True, center=0, linewidth=1,\n           cmap=sns.diverging_palette(240, 10, as_cmap=True),\n           cbar_kws={'shrink': .82},\n           mask=mask,\n           annot=True,\n           annot_kws={'size':7}\n           )\nax.set_title(f'Correlation', loc='left', fontweight='bold')\nplt.show()","06d743c5":"df = train.drop(['Pawpularity'], axis=1)\ndf_label = train['Pawpularity'].copy()","d98c0e3f":"# correlation > 0.099\n\nfig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2)\nplt.figure(figsize=(14, 6))\nplt.rc('font', size=10)\n\nsns.scatterplot(data=df, x='Subject Focus', y=df_label, alpha=0.1, ax=ax0)\nsns.scatterplot(data=df, x='Accessory', y=df_label, alpha=0.1, ax=ax1)\nsns.scatterplot(data=df, x='Group', y=df_label, alpha=0.1, ax=ax2)\nsns.scatterplot(data=df, x='Blur', y=df_label, alpha=0.1, ax=ax3)\n\nfig.tight_layout()\nplt.show()","05786aa8":"# correlation < 0.099 : group 1 \n\nfig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2)\nplt.figure(figsize=(14, 6))\nplt.rc('font', size=10)\n\nsns.scatterplot(data=df, x='Eyes', y=df_label, alpha=0.1, ax=ax0)\nsns.scatterplot(data=df, x='Face', y=df_label, alpha=0.1, ax=ax1)\nsns.scatterplot(data=df, x='Near', y=df_label, alpha=0.1, ax=ax2)\nsns.scatterplot(data=df, x='Action', y=df_label, alpha=0.1, ax=ax3)\n\nfig.tight_layout()\nplt.show()","d19e9ac7":"# correlation < 0.099 : group 2\n\nfig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2)\nplt.figure(figsize=(14, 6))\nplt.rc('font', size=10)\n\nsns.scatterplot(data=df, x='Collage', y=df_label, alpha=0.1, ax=ax0)\nsns.scatterplot(data=df, x='Human', y=df_label, alpha=0.1, ax=ax1)\nsns.scatterplot(data=df, x='Occlusion', y=df_label, alpha=0.1, ax=ax2)\nsns.scatterplot(data=df, x='Info', y=df_label, alpha=0.1, ax=ax3)\n\nfig.tight_layout()\nplt.show()","4fb76a8d":"sns.kdeplot(x=train['Pawpularity'])","26e567b3":"train_100 = train[train['Pawpularity'] > 90]\ntrain_100.head()","aca3f881":"attributes = ['Subject Focus', 'Blur', 'Action', 'Near', 'Collage', 'Info']\nattributes_corr = ['Subject Focus', 'Accessory', 'Group', 'Blur']\n\nscatter_matrix(train_100[attributes_corr], figsize=(12, 8))","2c38c909":"train_100_label = train_100['Pawpularity']\ntrain_100 = train_100[attributes_corr]","1d691057":"# Dimension reduction Visualization \n\ntsne = manifold.TSNE(n_components=2, random_state=42)\ntransformed_data = tsne.fit_transform(train_100)\n\ntsne_df = pd.DataFrame(np.column_stack((transformed_data, train_100_label)),\n                      columns=['X', 'y', 'label']\n                      )\ntsne_df.loc[:, 'label'] = tsne_df['label'].astype(int)","d14d11b0":"tsne_df.head()","a76c8b69":"# Cluster Visualization \n\ngrid = sns.FacetGrid(tsne_df, hue='label', size=8)\ngrid.map(plt.scatter, \"X\", 'y').add_legend()","196e9af9":"train_30 = train[(train['Pawpularity'] >= 20) & (train['Pawpularity'] <= 40)]\ntrain_30_label = train_30['Pawpularity']\ntrain_30 = train_30[attributes_corr]","863bd22a":"# Dimension reduction Visualization \n\ntsne = manifold.TSNE(n_components=2, random_state=42)\ntransformed_data = tsne.fit_transform(train_30)\n\ntsne_df = pd.DataFrame(np.column_stack((transformed_data, train_30_label)),\n                      columns=['X', 'y', 'label']\n                      )\ntsne_df.loc[:, 'label'] = tsne_df['label'].astype(int)","85f7948c":"# Cluster Visualization (40 > Pawpularity > 30)\n\ngrid = sns.FacetGrid(tsne_df, hue='label', size=8)\ngrid.map(plt.scatter, \"X\", 'y').add_legend()","c4ba17c5":"features = [\n    f for f in train.columns if f not in ('Id', 'Pawpularity')\n]\ntrain_features = train[features]\ndf_train = train_features.melt(value_vars=features)\n\nplt.figure(figsize=(15,7))\nsns.countplot(data=df_train, y='variable', hue='value')\nplt.show()","ca348639":"### F..Fireworks?","2b1a0bdf":"Several datas with different characteristics are shown in the section where the Pawpularity score is most distributed. (30, 100)","a15a5bfb":"below_original code (very thanks subinium) : https:\/\/www.kaggle.com\/subinium\/tps-may-categorical-eda","f54fb5f3":"**Photo Metadata**  \nThe train.csv and test.csv files contain metadata for photos in the training set and test set, respectively. Each pet photo is labeled with the value of 1 (Yes) or 0 (No) for each of the following features:  \n\n* Focus - Pet stands out against uncluttered background, not too close \/ far.\n* Eyes - Both eyes are facing front or near-front, with at least 1 eye \/ pupil decently clear.\n* Face - Decently clear face, facing front or near-front.\n* Near - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n* Action - Pet in the middle of an action (e.g., jumping).\n* Accessory - Accompanying physical or digital accessory \/ prop (i.e. toy, digital sticker), excluding collar and leash.\n* Group - More than 1 pet in the photo.\n* Collage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n* Human - Human in the photo.\n* Occlusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.\n* Info - Custom-added text or labels (i.e. pet name, description).\n* Blur - Noticeably out of focus or noisy, especially for the pet\u2019s eyes and face. For Blur entries, \u201cEyes\u201d column is always set to 0.","ce86600c":"Original Code (Grandmaster, Tensor girl) : https:\/\/www.kaggle.com\/usharengaraju\/tensorflow-probability-ngboost-w-b"}}