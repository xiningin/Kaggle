{"cell_type":{"f0917435":"code","86868c18":"code","b3828262":"code","379a456a":"code","68dc73db":"code","97237b1d":"code","94a8ea5a":"code","602abe78":"code","86005bf6":"code","6de9c1f2":"code","f23b8a54":"code","ac755caa":"code","48d993eb":"code","3c78272b":"code","22200786":"code","bc5518f6":"code","ba01e415":"markdown","18e5533c":"markdown","9c9a3fba":"markdown","993ed734":"markdown"},"source":{"f0917435":"###################\n# I Initialization\n###################\n\n#+++++++++++++++++++++++++++\n# Install required libraries\n#+++++++++++++++++++++++++++\n\n!pip install wget > NULL\n!pip install padelpy > NULL\n\n#+++++++++++++++\n# Load libraries\n#+++++++++++++++\n\nimport os\nimport wget\nfrom pathlib import Path # for path in Windows and Unix\nimport zipfile\nimport numpy as np\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport matplotlib.pyplot as plt\n\n#+++++++++++++++++++++++++++\n# Define the working folders\n#+++++++++++++++++++++++++++\n\n# see https:\/\/careerkarma.com\/blog\/python-list-files-in-directory\/\n# See https:\/\/medium.com\/@ageitgey\/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f\nproject_data_folder = Path('\/kaggle\/input\/betalactamase\/')\nos.mkdir('\/kaggle\/temp\/')\nproject_temp_folder = Path('\/kaggle\/temp\/')\nproject_result_folder = Path('\/kaggle\/working\/')\n\n#+++++++++++++++++\n# Load the dataset\n#+++++++++++++++++\n\n# Combine all csv files into one single dataset\n# see https:\/\/www.kaggle.com\/thedataprof\/getting-started-with-the-beta-lactamase-dataset\n\nall_csv = glob.glob('\/kaggle\/input\/betalactamase\/*.csv')\ndf = pd.concat( (pd.read_csv(csv)) for csv in all_csv )\ndf.head()","86868c18":"########\n# II EDA\n########\n\n#+++++++++++++++++++++++++++++++++++++\n# Visualize the number of missing data\n#+++++++++++++++++++++++++++++++++++++\n\n# See https:\/\/github.com\/dataprofessor\/beta-lactamase\/blob\/main\/beta_lactamase_data.ipynb\n\nmissing = df.pchembl_value.isnull().sum()\nnonmissing = df.pchembl_value.notnull().sum()\n\nx = ['Missing', 'Non-Missing']\ny = [missing, nonmissing]\n\n# Setup plot\nfig, ax = plt.subplots()\n\n# Make bar plot\np = ax.bar(x, y, color = ['#F8766D', '#00BFC4'], ec = 'black')\n\nax.set_title('pChEMBL Missing Data', fontsize=14, fontweight='bold', pad=15)\n#ax.set_xticklabels(x, fontweight='bold')\n\nax.set_ylim(0,70000)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\n\n# Label above bar\nfor index, data in enumerate(y):\n    plt.text(x=index-0.1 , y =data+1000 , s=f\"{data}\" , fontdict=dict(fontsize=14))\n\nfig.set_size_inches(5,4.5)\nplt.show()","b3828262":"#+++++++++++++++++++++++++++++++++++++\n# Non-missing data with pChEMBL value\n#+++++++++++++++++++++++++++++++++++++\n\n# Non-missing data with pChEMBL value\nimport numpy as np\ndf2 = df[df.pchembl_value.notnull()]\n\n# see https:\/\/github.com\/dataprofessor\/beta-lactamase\/blob\/main\/beta_lactamase_data.ipynb\nprint('Number of unique ChEMBL ID:', str(len(df.molecule_chembl_id.unique()) )  )\nprint('Total number of ChEMBL ID: ', str(len(df)) )\nprint('Number of missing ChEMBL ID: ', str(df.molecule_chembl_id.isnull().sum()) )","379a456a":"#++++++++++++++++\n# Top 50 targets\n#++++++++++++++++\n\n# https:\/\/github.com\/dataprofessor\/beta-lactamase\/blob\/main\/beta_lactamase_data.ipynb\nimport matplotlib.pyplot as plt\n\nunique = len(df.molecule_chembl_id.unique())\nnot_unique = len(df) - unique\n\nx = ['Unique', 'Redundant']\ny = [unique, not_unique]\n\ndf2.target_pref_name.value_counts()[0:50].plot.bar(figsize=(24,4), color='#00BFC4', ec='black')\n\nplt.title('Top 50 Targets', fontsize=14, fontweight='black', pad=15)\nplt.show()","68dc73db":"#+++++++++++++++++++++++++\n# Top 10 Bioactivity units\n#+++++++++++++++++++++++++\n\n# see https:\/\/github.com\/dataprofessor\/beta-lactamase\/blob\/main\/beta_lactamase_data.ipynb\ndf2.standard_type.value_counts()[:10].plot.bar(figsize=(8,4), color='#00BFC4', ec='black')\nplt.title('Top Bioactivity Units', fontsize=14, fontweight='black', pad=15)\nplt.show()","97237b1d":"#++++++++++++++++++\n# Assay categories \n#++++++++++++++++++\n\n#see https:\/\/github.com\/dataprofessor\/beta-lactamase\/blob\/main\/beta_lactamase_data.ipynb\nbao_labels = df2.bao_label.value_counts()\nbao_labels.plot.bar(figsize=(8,4), color='#00BFC4', ec='black')\n\nplt.title('Histogram of BioAssay Ontology', fontsize=14, fontweight='black', pad=15)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","94a8ea5a":"#+++++++++++++++\n# pchembl values\n#+++++++++++++++\n\n# see https:\/\/github.com\/dataprofessor\/beta-lactamase\/blob\/main\/beta_lactamase_data.ipynb\ndf2.pchembl_value.hist(bins=40, figsize=(8,4), color='#00BFC4', ec='black')\nplt.title('Histogram of pChEMBL values', fontsize=14, fontweight='black', pad=15)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","602abe78":"####################\n# III Data Wrangling\n####################\n\n#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n# Remove row with missing canonical_smiles and missing pchembl_value\n#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\ndf = df[df['canonical_smiles'].notna()]\ndf = df[df['pchembl_value'].notna()]","86005bf6":"#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n# Extract from the dataset the majority molecule: molecule_chembl_id\n#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n# see https:\/\/github.com\/dataprofessor\/beta-lactamase\/blob\/main\/beta_lactamase_data.ipynb\n\ndf = df[df['target_pref_name'] == 'Beta-lactamase AmpC']\ndf = df[df['standard_type'] == 'Potency']\ndf == df[df['bao_label'] == 'assay format']","6de9c1f2":"#++++++++++++++++++++++++++++++\n# Removes duplicated nolecules\n#+++++++++++++++++++++++++++++\n\n# See https:\/\/github.com\/sayalaruano\/MidtermProject-MLZoomCamp\/blob\/main\/EDA_beta_lactamase_drug_discovery_project.ipynb\n\ndef combine_molecule_duplicates(dataset):\n    '''\n    Function to replace duplicated molecules by one single row with mean of standard_value and \n    pchembl_value of duplicated rows. The replacement is applied only if standard deviation of \n    pchembl_value is lower than 2.\n\n        Parameters:\n            dataset (DataFrame): A pandas DataFrame with duplicated molecules\n        \n        Returns: \n            dataset (DataFrame): A pandas DataFrame without duplicated molecules\n    '''\n    # Calculate standard deviation of all molecules\n    std_by_uniqueID = dataset.groupby(\"molecule_chembl_id\").std()\n\n    # Filter standard deviation of duplicated molecules lower than 2\n    std_by_uniqueID = std_by_uniqueID[std_by_uniqueID.pchembl_value < 2]\n\n    # Calculate mean of all molecules\n    mean_by_uniqueID = dataset.groupby(\"molecule_chembl_id\").mean()\n    \n    # Filter mean of duplicated molecules that have standard deviation lower than 2\n    mean_by_uniqueID = mean_by_uniqueID.filter(items = std_by_uniqueID.index, axis=0)\n\n    # Create a dictionary of rows with mean values of standard_value and pchembl_value\n    new_rows = {}\n\n    for i in mean_by_uniqueID.index:\n        rows = dataset.loc[dataset.molecule_chembl_id == i].copy()\n        row = rows.iloc[0].copy()\n        row.standard_value = mean_by_uniqueID.loc[i].standard_value\n        row.pchembl_value = mean_by_uniqueID.loc[i].pchembl_value\n        new_rows[i] = row\n    \n    # Convert dictionary to dataframa\n    df_new_rows = pd.DataFrame(new_rows).T\n    \n    # Delete duplicated molecules from the original dataset\n    dataset = dataset.drop_duplicates(subset=[\"molecule_chembl_id\"], keep=False)\n\n    # Add new rows to the original dataset\n    dataset = pd.concat([dataset, df_new_rows], axis=0).reset_index(drop=True)\n\n    return dataset\n\n# Replace duplicated molecules by mean of their standard_value and pchembl_value\ndf = combine_molecule_duplicates(df)","f23b8a54":"#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n# Use PaDelPy to convert smiles annotation to chemical structures infomrmations\n#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n# See https:\/\/opensourcelibs.com\/lib\/padelpy\n# See https:\/\/youtu.be\/rEmDyZHz5U8\n# See https:\/\/github.com\/dataprofessor\/padel\n\ndf2 = df[['canonical_smiles', 'molecule_chembl_id']]\nfile_path = project_temp_folder \/ 'molecule.smi'\ndf2.to_csv(file_path, sep='\\t', index=False, header=False)","ac755caa":"os.mkdir('\/kaggle\/temp\/Fingerprints')","48d993eb":"url = 'https:\/\/github.com\/dataprofessor\/padel\/raw\/main\/fingerprints_xml.zip'\nfile_path = project_temp_folder \/ 'Fingerprints' \/ 'fingerprints_xml.zip'\nfile_path = str(file_path)\nwget.download(url, file_path)","3c78272b":"with zipfile.ZipFile(file_path, 'r') as zip_ref:\n    zip_ref.extractall(str(project_temp_folder \/ 'Fingerprints'))\n\nxml_files = glob.glob(str(project_temp_folder \/ 'Fingerprints\/*.xml'))\nxml_files.sort()\n\nFP_list = ['AtomPairs2DCount',\n 'AtomPairs2D',\n 'EState',\n 'CDKextended',\n 'CDK',\n 'CDKgraphonly',\n 'KlekotaRothCount',\n 'KlekotaRoth',\n 'MACCS',\n 'PubChem',\n 'SubstructureCount',\n 'Substructure']\n\nfp = dict(zip(FP_list, xml_files))","22200786":"from padelpy import padeldescriptor\n\nfingerprint = 'Substructure'\n\nfingerprint_output_file = str(project_temp_folder \/ 'Substructure.csv')\nfingerprint_descriptortypes = fp[fingerprint]\n\npadeldescriptor(#mol_dir='molecule.smi', \n                mol_dir = str(project_temp_folder \/ 'molecule.smi'),\n                d_file=fingerprint_output_file, #'Substructure.csv'\n                #descriptortypes='SubstructureFingerprint.xml', \n                descriptortypes= fingerprint_descriptortypes,\n                detectaromaticity=True,\n                standardizenitro=True,\n                standardizetautomers=True,\n                threads=2,\n                removesalt=True,\n                log=True,\n                fingerprints=True)\n\ndescriptors = pd.read_csv(fingerprint_output_file)\ndescriptors","bc5518f6":"# combine descriptor and filtered dataset\ndf3 = pd.merge(df, descriptors, how =\"inner\", left_on=['molecule_chembl_id'], right_on=['Name'])\n\nfile_path = project_result_folder \/ 'beta-lactamase_filtered_dataset.csv'\ndf3.to_csv(file_path, index=False)","ba01e415":"# III Data Wrangling","18e5533c":"# II EDA","9c9a3fba":"# Introduction\n\nThis project proposed by [Data Professor](https:\/\/www.youtube.com\/channel\/UCV8e2g4IWQqK71bbzGDEI4Q) aims to build models predicting molecules binding to the Beta-Lactamase protein. For the complete project description, see this [video](https:\/\/www.youtube.com\/watch?v=_GtEgiWWyK4) on the [Data Professor](https:\/\/www.youtube.com\/channel\/UCV8e2g4IWQqK71bbzGDEI4Q) channel.\nThis notebook comports the initial EDA and data processing. ","993ed734":"# I Initialization"}}