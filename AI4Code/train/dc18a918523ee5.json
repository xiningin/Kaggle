{"cell_type":{"bc0588ea":"code","21f5a141":"code","e1879b46":"code","a7f6f1af":"code","c43311b6":"code","f4d04979":"code","41b6d588":"code","89a31bb1":"code","9aa97291":"code","c11a0b3a":"code","d0832342":"code","0bab4bee":"code","ffc8023b":"code","6ba7cb71":"code","f057efec":"code","e37b6837":"code","a525b02e":"code","20253f34":"code","c03770b7":"code","fa35213f":"code","75e2cc28":"code","82378602":"code","90df54d0":"code","715f69dd":"code","3610eb38":"code","085489de":"code","ac407943":"code","b72cb2e6":"code","12143a2a":"code","7f0beaee":"code","86ab4a11":"code","0f9a1d8e":"code","472a953c":"code","46e631d6":"code","9a845107":"code","08a13b19":"code","927e27df":"code","282392e8":"code","24f74379":"markdown","f12ae95c":"markdown","3b48da51":"markdown","097f3bef":"markdown","22edf844":"markdown","87d74114":"markdown","329a6e6e":"markdown","0f58473b":"markdown","510546ad":"markdown","d32faeb9":"markdown","315212d4":"markdown"},"source":{"bc0588ea":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import  auc, roc_curve, classification_report \n\nfrom lightgbm import LGBMClassifier, plot_importance","21f5a141":"train = pd.read_csv('\/kaggle\/input\/janatahack-crosssell-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/janatahack-crosssell-prediction\/test.csv')","e1879b46":"data = pd.concat([train,test], axis=0)\ndata.head()","a7f6f1af":"train.groupby(['Gender','Response'])['id'].count().to_frame()","c43311b6":"fig, ax = plt.subplots(nrows=6,ncols=1, figsize=(10,60))\ncols = train.columns.values.tolist()\ncols = [c for c in cols if c not in ('id', 'Age', 'Annual_Premium', 'Vintage','Policy_Sales_Channel', 'Response')]\n\nfor i in range(len(cols)):\n    tmp = train.groupby([cols[i],'Response'])['id'].count().to_frame().reset_index()\n    tmp = tmp.rename(columns={'id':'Number of Users'})\n    sns.barplot(x=cols[i], y='Number of Users', hue='Response', data=tmp, ax = ax[i]).set_title('Count Graph of {}'.format(cols[i]))","f4d04979":"#train.loc[train['Response']==0, ['Age','Vintage']]","41b6d588":"cont_var = ['Age', 'Annual_Premium', 'Vintage']\n\nfig, ax = plt.subplots(nrows = 3, ncols=1, figsize=(30,15))\n\nfor i in range(len(cont_var)):\n    print(cont_var[i])\n    sns.kdeplot(train.loc[train['Response']==0, cont_var[i]], label='0', ax = ax[i]).set_title('kde plot of {}'.format(cont_var[i]), fontsize=30)\n    sns.kdeplot(train.loc[train['Response']==1, cont_var[i]], label='1', ax = ax[i])\n    ","89a31bb1":"data","9aa97291":"gender_bias= {\n'Male' : 0,\n'Female' : 1\n}\n\n\nvehicle = { '< 1 Year' :0,\n'1-2 Year' : 1,\n'> 2 Years' : 2}\n\n\nvehicle_damage = { 'No' : 0,\n'Yes' : 1}\n\n","c11a0b3a":"data['Gender'] = data['Gender'].map(gender_bias)\ndata['Vehicle_Age'] = data['Vehicle_Age'].map(vehicle)\ndata['Vehicle_Damage'] = data['Vehicle_Damage'].map(vehicle_damage)","d0832342":"sns.kdeplot(data.loc[data['Response']==1, 'Gender'])\nsns.kdeplot(data.loc[data['Response']==0, 'Gender'])","0bab4bee":"data","ffc8023b":"group_vars = ['Region_Code', 'Policy_Sales_Channel']\n\nagg_vars = ['Annual_Premium', 'Vintage', 'Age']\n\n\nfor g in group_vars:\n    for a in agg_vars:\n        data[f'{g}_{a}_count'] = data.groupby(data[g])[a].transform('count')\n        data[f'{g}_{a}_mean'] = data.groupby(data[g])[a].transform('mean')\n        data[f'{g}_{a}_std'] = data.groupby(data[g])[a].transform('std')\n        data[f'{g}_{a}_min'] = data.groupby(data[g])[a].transform('min')\n        data[f'{g}_{a}_max'] = data.groupby(data[g])[a].transform('max')","6ba7cb71":"data['Response']","f057efec":"X = data.iloc[:len(train)]\nY = data.iloc[len(train):]\nX['Response'].tail()","e37b6837":"x = X.drop(columns=['Response','id'])\ny = X['Response']","a525b02e":"x.fillna(method='ffill', inplace=True)","20253f34":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)","c03770b7":"model = LGBMClassifier(\n        boosting_type = 'gbdt',\n        max_depth = 8,\n        learning_rate = 0.01,\n        n_estimators = 5000,\n        objective = 'binary',\n        subsample = 0.8,\n        reg_lambda = 2)\n\nmodel.fit(x_train, y_train, eval_metric='auc', \n          eval_set=[(x_test, y_test)], early_stopping_rounds=200, verbose=100)\n","fa35213f":"\nplot_importance(model, max_num_features=10, figsize=(10,10))","75e2cc28":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(model,x,y,cv=3,scoring=\"roc_auc\")\nprint(score.mean())","82378602":"X","90df54d0":"print(x.shape, y.shape)\nprint(y.value_counts())","715f69dd":"\n\nsm = SMOTE(sampling_strategy='minority', random_state=55, k_neighbors=5)\nOver_x, Over_y = sm.fit_resample(x, y)","3610eb38":"print(Over_y.value_counts())","085489de":"x_train,x_test,y_train,y_test=train_test_split(Over_x, Over_y, stratify = Over_y, test_size=0.2,random_state=7)","ac407943":"scale = RobustScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.transform(x_test)","b72cb2e6":"lbmodel = LGBMClassifier(\n        boosting_type = 'gbdt',\n        max_depth = 8,\n        learning_rate = 0.01,\n        n_estimators = 5000,\n        objective = 'binary',\n        subsample = 0.8,\n        reg_lambda = 2)\n\nlbmodel.fit(x_train, y_train, eval_metric='auc', \n          eval_set=[(x_test, y_test)], early_stopping_rounds=200, verbose=100)","12143a2a":"lbmodel = LGBMClassifier(\n        boosting_type = 'gbdt',\n        max_depth = 8,\n        learning_rate = 0.01,\n        n_estimators = 5000,\n        objective = 'binary',\n        subsample = 0.8,\n        reg_lambda = 2)\n\nlbmodel.fit(x_train, y_train)\npred = lbmodel.predict(x_test)\n\n\n\nprint(classification_report(pred, y_test))\ny_score = lbmodel.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","7f0beaee":"Final = Y.drop(columns=['id','Response'])","86ab4a11":"Final = scale.transform(Final)","0f9a1d8e":"Final_prediction = lbmodel.predict_proba(x_test)[:,1]s","472a953c":"result=pd.DataFrame(Y[\"id\"],columns=[\"id\",\"Response\"])\nresult[\"Response\"]=Final_prediction\nresult.to_csv(\"LGBM_prediction.csv\",index=0)","46e631d6":"\nscaled_x = pd.DataFrame(scale.fit_transform(x), columns=x.columns)","9a845107":"%%time\nfolds = 5\n\nauc_score = []\nskf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\nfinal_prediction = pd.DataFrame()\n    \nfor train, test in skf.split(scaled_x,y):\n    X_train, X_test = scaled_x.iloc[train], scaled_x.iloc[test]\n    Y_train, Y_test = y.iloc[train], y.iloc[test]\n   \n    # FInding Best Iteration\n    \n    lbmodel = LGBMClassifier(\n        boosting_type = 'gbdt',\n        max_depth = 8,\n        learning_rate = 0.01,\n        n_estimators = 5000,\n        objective = 'binary',\n        subsample = 0.8,\n        reg_lambda = 2)\n\n    lbmodel.fit(X_train, Y_train, eval_metric='auc', \n              eval_set=[(X_test, Y_test)], early_stopping_rounds=200, verbose=100)\n    \n    num_iteration=lbmodel.best_iteration_\n\n    \n    #   Model Running\n    \n    lbmodel = LGBMClassifier(\n        boosting_type = 'gbdt',\n        max_depth = 8,\n        learning_rate = 0.01,\n        n_estimators = num_iteration,\n        objective = 'binary',\n        subsample = 0.8,\n        reg_lambda = 2)\n\n    lbmodel.fit(x_train, y_train)\n    pred = lbmodel.predict(x_test)\n\n\n\n    print(classification_report(pred, y_test))\n    y_score = lbmodel.predict_proba(x_test)[:,1]\n    fpr, tpr, _ = roc_curve(y_test, y_score)\n    print ('Area under curve (AUC): ', auc(fpr,tpr))\n    score = auc(fpr,tpr)\n    auc_score.append(score)\n    \n    \n    # Making FInal Prediction\n    \n    prediction = pd.DataFrame( lbmodel.predict_proba(Final)[:,1])\n    final_prediction = pd.concat([final_prediction, prediction], axis=1)\n    \n    \n        \naverage_score = np.mean(auc_score)\nprint('The average auc score is ', average_score)   \n","08a13b19":"final_prediction","927e27df":"a = final_prediction.mean(axis=1)\na","282392e8":"result=pd.DataFrame(Y[\"id\"],columns=[\"id\",\"Response\"])\nresult[\"Response\"]=a\nresult.to_csv(\"LGBM_prediction_Fold.csv\",index=0)","24f74379":"# Visualization","f12ae95c":"# Lets do some magic now","3b48da51":"# 1) Over sampling","097f3bef":"# Lets Try Stratified Folding But without Over Sampling","22edf844":"# 4) Lets make prediction On Final Data","87d74114":"# Feature Engineering","329a6e6e":"# Final Score we got is = 0.839727","0f58473b":"# Lets Take their average","510546ad":"# Basic Modelling","d32faeb9":"# 3) lets use base model again","315212d4":"# 2) Power Transformation"}}