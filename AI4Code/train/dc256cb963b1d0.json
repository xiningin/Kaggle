{"cell_type":{"325ea92e":"code","2ef8e497":"code","82a60c8b":"code","38b10a4f":"code","4a933a3d":"code","35a04778":"code","abbe9fcc":"code","aad49a20":"code","e949fa53":"code","5988e48c":"code","5fd6c2e3":"markdown","16502fae":"markdown","15190a3f":"markdown","74c414a7":"markdown","d8326abe":"markdown"},"source":{"325ea92e":"from sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.neural_network import MLPRegressor\n\nimport pandas as pd","2ef8e497":"#Loading in the dataset\ndiabetes_data = load_diabetes()\n\n#----FILL IN HERE----#\nX = diabetes_data['data'] #the model inputs\nfeature_names = diabetes_data['feature_names']\ny = diabetes_data['target'] #the model output, what we want to predict!\n#--------------------#","82a60c8b":"#Taking a look at the data\n#  -note that the features have been normalized already for us (brought into a reasonable, standard range)\npd.DataFrame(data = X, columns = feature_names)","38b10a4f":"#Getting the train\/test split\n\n#----FILL IN HERE----#\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2021) #the random state here means that we'll ALWAYS get the same split\n#--------------------#","4a933a3d":"#Taking a look at our train\/test sets\nprint('The train set has', X_train.shape[0], 'observations and the test set has', X_test.shape[0], 'observations')","35a04778":"#Training the model\n\n#----FILL IN HERE----#\nlm = LinearRegression() #instantiating the model--if we wanted to get fancy, we could pass in extra parameters here!\nlm.fit(X_train, y_train); #we fit the model with ONLY the training data!\n#--------------------#","abbe9fcc":"#Taking a look at the coefficient values that we arrived at\n\n#----FILL IN HERE----#\ncoefficients = lm.coef_\n#--------------------#\n\nfor i in range(len(coefficients)):\n    if i == 0:\n        print('Intercept:', round(coefficients[i], 3))\n    else:\n        print(feature_names[i] + ':', round(coefficients[i], 3))","aad49a20":"#Evaluating the model on completely new data (test set)\n\n#----FILL IN HERE----#\npreds = lm.predict(X_test)\ntest_mse = mean_squared_error(preds, y_test)\n#--------------------#\n\nprint('We achieved a MSE of', round(test_mse, 3), 'on the test set')","e949fa53":"#Looking at what this performance means for any individual observation\n\n#----FILL IN HERE----#\ntest_idx = 27\n#--------------------#\n\npred = lm.predict(X_test[test_idx].reshape(1, -1))\nactual = y_test[test_idx]\n\nprint('For test observation', test_idx, 'we predicted', round(pred[0], 3), 'and the actual value is', actual)","5988e48c":"#Training and evaluating our model\n#  -notice that the process of instantiating, training, and testing is very consistent in sklearn!\nMLP = MLPRegressor(random_state = 2021, hidden_layer_sizes = (100, ), max_iter = 5000)\nMLP.fit(X_train, y_train)\n\npreds = MLP.predict(X_test)\ntest_mse = mean_squared_error(preds, y_test)\n\nprint('We achieved a MSE of', round(test_mse, 3), 'on the test set') ","5fd6c2e3":"# Contextualizing linear regression's performance\n\nIt turns out that our linear regression model does pretty well on this data set. To better contextualize the MSE obtained by our model, let's see how well we can do with a higher-powered model: a **neural network.**\n\nNote that even though the two models perform similarly for this particular dataset, this won't usually be the case. Also, linear regression models can only handle very specific types of inputs, whereas neural networks are much more flexible--they can even handle image, audio, and text as inputs!","16502fae":"# Reading in the data\nWe're using an `sklearn` native dataset, which should only really be used for basic testing or demonstration purposes. You can see the dataset's documentation [here](https:\/\/scikit-learn.org\/stable\/datasets\/toy_dataset.html#diabetes-dataset).\n\nQuoting directly from the documentation:\n> _Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline._","15190a3f":"# Training and evaluating a linear regression model\nHere, `sklearn` bundles everything together for us: we tell it we want a **linear regression** model and then it defines the **functional form**, the **loss function**, and performs **optimization** to find the best $\\beta$ values given our training data. \n\nSee `sklearn`'s [documentation](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LinearRegression.html) for more info about how they implement linear regression!","74c414a7":"# Splitting into training and testing sets\nThe training set will be used to fit our model (find the best $\\beta$ values) and the test set will be used to evaluate our model's ability to generalize to _new_ data.","d8326abe":"# Setup\nWe'll most be using the `sklearn` library, which supports a lot of different machine learning models. Check out the documentation [here](https:\/\/scikit-learn.org\/stable\/index.html)."}}