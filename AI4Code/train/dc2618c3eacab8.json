{"cell_type":{"98903610":"code","79b5b987":"code","dfad94bf":"code","4e7d02d4":"code","46386a36":"code","fa3ebc7c":"code","c7f9c356":"code","9cca152b":"code","206c8bd0":"code","2438bfe5":"code","03c47c71":"code","8199931e":"code","4b0109bb":"code","bf427af9":"code","ab6f448a":"code","518e92b0":"code","818069e6":"code","dbb8c0ae":"code","5c2eab22":"code","f4c75c1f":"code","ba428732":"code","71cde0b9":"code","e68fad82":"code","a62c9e9d":"code","80fd7947":"code","e4ea68b0":"code","2a1cc59e":"code","bdf2a376":"code","4ac540fd":"code","3a4f2e0b":"code","67db87d2":"code","151d904b":"code","c9ad21c4":"code","66c1b9de":"code","41c67d26":"code","11f97eb5":"code","eb273242":"code","1686422d":"code","bc6c01f7":"code","076156f0":"code","9a02b880":"code","0a786cbe":"code","2ec8a333":"code","1360cdf8":"code","1ef9fafc":"code","6a6a7573":"code","1d6bc7d2":"code","6a4829a5":"code","27755a5f":"code","ae67562f":"code","169c59d5":"code","2b8114c1":"code","e536c3a8":"code","1b816859":"code","be1023ee":"code","812211ae":"code","10b25689":"code","5856efcd":"code","75a69d13":"code","fc691d14":"code","f68cb7cc":"code","d28ec38c":"markdown","8d3e672b":"markdown","745c7d7a":"markdown","6d42dcb3":"markdown","3b235087":"markdown","1c30afa2":"markdown","96c1940e":"markdown","f4ca0130":"markdown","edf54ee3":"markdown","f8a511c5":"markdown","4377dc35":"markdown","328dc3e3":"markdown","dfeeddc9":"markdown","4f68cc14":"markdown","23c4d40c":"markdown","2dbe6814":"markdown","4900b09f":"markdown","5b741536":"markdown","10b84d97":"markdown","5a036527":"markdown","73052785":"markdown","afafa459":"markdown","7036c1d9":"markdown","1afcf7d7":"markdown","882bb8ed":"markdown","9cd78237":"markdown","3f37b1b1":"markdown","5cbb112d":"markdown","a08e022f":"markdown","3b504df8":"markdown","4f733302":"markdown","bc6c2e74":"markdown","e4038809":"markdown","a0397af0":"markdown","f140e3a0":"markdown","673dfa32":"markdown","e69796ff":"markdown","39a69d6c":"markdown","80dd6932":"markdown","6ce7ba6b":"markdown","0ea6cc5c":"markdown"},"source":{"98903610":"import scipy as sp\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pandas as pd\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom datetime import  datetime, timedelta\nfrom statsmodels.tsa.stattools import  adfuller\nfrom statsmodels.graphics.tsaplots import  plot_pacf, plot_acf\nfrom statsmodels.graphics.tsaplots import  plot_acf\nfrom statsmodels.graphics.gofplots import  qqplot\nfrom statsmodels.tsa.seasonal import  seasonal_decompose\nfrom statsmodels.tsa.arima_model import  ARIMA\nfrom statsmodels.tsa.statespace.sarimax import  SARIMAX\nfrom sklearn.metrics import mean_squared_error\nimport itertools\nfrom scipy.stats import boxcox\nfrom statsmodels.tsa.api  import ExponentialSmoothing\n\n\nfrom  pylab import rcParams\nrcParams['figure.figsize'] = 25,8\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","79b5b987":"series = pd.read_csv('..\/input\/monthly-armed-robberies-in-boston\/Robberies.csv')\nsplit_point = len(series) - 12\ndataset, validation = series[0:split_point], series[split_point:]\nprint('Dataset %d, Validation %d' % (len(dataset), len(validation)))","dfad94bf":"dataset.head()","4e7d02d4":"validation.head()","46386a36":"dataset.tail()","fa3ebc7c":"# creating date range according to the data\n# data has dates from 1966-01-31 to 1974-10-31 with monthly frequency\ndate = pd.date_range(start='1\/1\/1966', end='11\/1\/1974', freq='M')\ndate","c7f9c356":"# replacing original date column with newly created\ndataset['Months'] = date\n\n# setting date column as index of the dataframe\ndataset.set_index('Months', inplace=True)\ndataset.head()","9cca152b":"# stats\ndataset.describe().T","206c8bd0":"dataset.plot()\nplt.show()","2438bfe5":"sns.boxplot(x = dataset.index.month, y = dataset['Robberies'])\nplt.show()","03c47c71":"monthly_rabberies_across_years = pd.pivot_table(dataset,\n                                                values = 'Robberies',\n                                                columns = dataset.index.year,\n                                                index = dataset.index.month_name())\nmonthly_rabberies_across_years.plot()\nplt.grid()\nplt.legend(loc='best');","8199931e":"# year wise box plot\nsns.boxplot(x = dataset.index.year, y = dataset['Robberies'])\nplt.show()","4b0109bb":"# ACF plot\nplot_acf(dataset, lags=100);","bf427af9":"# PACF plot\nplot_pacf(dataset);","ab6f448a":"'''\nNull hypothesis:Series is not stationary\nAlternate hypothesis: Series is stationary\n'''\n\ntest_result = adfuller(dataset.values)\nprint('ADF Statistic: %f' % test_result[0])\nprint('p-value: %f' % test_result[1])\nprint('Critical Values:')\nfor key, value in test_result[4].items():\n    print('\\t%s: %.5f' % (key, value))","518e92b0":"df_diff1 = dataset.diff(periods=1).dropna()\n\ntest_result = adfuller(df_diff1.values)\nprint('ADF Statistic: %f' % test_result[0])\nprint('p-value: %f' % test_result[1])\nprint('Critical Values:')\nfor key, value in test_result[4].items():\n    print('\\t%s: %.5f' % (key, value))","818069e6":"plot_acf(df_diff1, lags=100);","dbb8c0ae":"plot_pacf(df_diff1);","5c2eab22":"dataset.index","f4c75c1f":"# split data such that last two years are taken into test data remainig for train data\ntrain_end = datetime(1972, 12, 31)\ntest_end = datetime(1974, 10, 31)\n\ntrain = dataset[ : train_end]\ntest = dataset[train_end+timedelta(days=1) : test_end]","ba428732":"train.shape","71cde0b9":"test.shape","e68fad82":"# order = (1, 1, 1): ACF value 1, Differencing by 1, PACF value 1\narima_model = ARIMA(train, order = (1, 1, 1))\nmodel_fit = arima_model.fit()\nprint(model_fit.summary())","a62c9e9d":"arima_forecast = model_fit.forecast(steps = len(test))","80fd7947":"plt.plot(train, label='Train')\nplt.plot(test, label='Test')\nplt.plot(test.index, arima_forecast[0], label='Forecast')","e4ea68b0":"rmse = np.sqrt(mean_squared_error(test.Robberies, arima_forecast[0]))\nprint(rmse)","2a1cc59e":"def MAPE(y_true, y_pred):\n    return np.mean((np.abs(y_true-y_pred))\/(y_true))*100\n\nmape = MAPE(test['Robberies'].values, arima_forecast[0])\nmape","bdf2a376":"results_df = pd.DataFrame({'Test RMSE': rmse,'Test MAPE':mape}\n                           ,index=['ARIMA(1,1,1)'])\n\nresults_df","4ac540fd":"# parameters for grid search\np = q = range(0, 4)\nd= range(1,2)\npdq = list(itertools.product(p, d, q))\nprint('parameter combinations for the Model')\nfor i in range(1,len(pdq)):\n    print('Model: {}'.format(pdq[i]))","3a4f2e0b":"# Grid search technique\narima_df = pd.DataFrame(columns=['param', 'AIC'])\n\nfor param in pdq:\n    try:\n        model = ARIMA(train, order = param)\n        model_fit = model.fit()\n        print('ARIMA_params',param, '- AIC{}', model_fit.aic)\n        arima_df = arima_df.append({'param': param, 'AIC': model_fit.aic}, ignore_index = True)\n    except:\n        continue\n\nprint('==============================================')\narima_df = arima_df.sort_values('AIC')\nprint('Best params for ARIMA')\nprint(arima_df.head(1))","67db87d2":"arima_model = ARIMA(train, order = (0, 1, 2))\nmodel_fit = arima_model.fit()\n\narima_forecast = model_fit.forecast(steps = len(test))","151d904b":"rmse = np.sqrt(mean_squared_error(test.Robberies, arima_forecast[0]))\nprint(rmse)","c9ad21c4":"mape = MAPE(test['Robberies'].values, arima_forecast[0])\nprint(mape)","66c1b9de":"results_df_temp = pd.DataFrame({'Test RMSE': rmse,'Test MAPE': mape}\n                           ,index=['Tuned ARIMA(0, 1, 2)'])\n\nresults_df = pd.concat([results_df, results_df_temp])\nresults_df","41c67d26":"residuals = test['Robberies'] - arima_forecast[0]\nqqplot(residuals,line=\"s\");","11f97eb5":"data = [x[0] for x in train.values]\ntransformed, lam = boxcox(data)\n\n# the forecast will be Box-Cox transformed values.\n# Hence, we need to invest the values back to original scale.\ndef boxcox_inverse(value, lam):\n    if lam == 0:\n        return np.exp(value)\n    return np.exp(np.log(lam * value + 1) \/ lam)","eb273242":"# Fit the model with transformed data\narima_model = ARIMA(transformed, order=(0, 1, 2))\nmodel_fit = arima_model.fit()\n\n# Forecast for test\narima_forecast = model_fit.forecast(steps = len(test))\n\n# Invert the transformation\narima_forecast = boxcox_inverse(arima_forecast[0], lam)\n\n# Check RMSE\nrmse = np.sqrt(mean_squared_error(test.Robberies, arima_forecast))\n\n# Check error\nmape = MAPE(test['Robberies'].values, arima_forecast[0])\n\nresults_df_temp = pd.DataFrame({'Test RMSE': rmse,'Test MAPE': mape}\n                           ,index=['Transformed ARIMA(0, 1, 2)'])\n\nresults_df = pd.concat([results_df, results_df_temp])\nresults_df","1686422d":"predictions = []\ndata = [x[0] for x in train.values]\n\n\nfor i in range(0, len(test)):\n        \n    # predict\n    model = ARIMA(data, order=(0, 1, 2))\n    model_fit = model.fit()\n    yhat = model_fit.forecast()[0]\n    predictions.append(yhat)\n    \n    # observation\n    obs = test.iloc[i].values[0]\n    data.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))","bc6c01f7":"rmse = np.sqrt(mean_squared_error(test.Robberies, predictions))\nrmse","076156f0":"mape = MAPE(test['Robberies'].values, predictions)\nmape","9a02b880":"results_df_temp = pd.DataFrame({'Test RMSE': rmse,'Test MAPE': mape}\n                           ,index=['Rolling ARIMA(0, 1, 2)'])\n\nresults_df = pd.concat([results_df, results_df_temp])\nresults_df","0a786cbe":"plt.plot(train, label='Train')\nplt.plot(test.index,test, label='Test')\nplt.plot(test.index, predictions, label='Forecast')\nplt.legend(loc='best')\nplt.grid()","2ec8a333":"model_TES_add = ExponentialSmoothing(train, trend='additive', seasonal='additive', initialization_method='estimated')\nmodel_TES_add = model_TES_add.fit(optimized=True)\nmodel_TES_add.summary()","1360cdf8":"TES_add_predict =  model_TES_add.forecast(len(test))\n\nrmse = np.sqrt(mean_squared_error(test.Robberies, TES_add_predict))\nmape = MAPE(test['Robberies'], TES_add_predict)","1ef9fafc":"results_df_temp = pd.DataFrame({'Test RMSE': rmse,'Test MAPE': mape}\n                           ,index=['Exponential Smoothing'])\n\nresults_df = pd.concat([results_df, results_df_temp])\nresults_df","6a6a7573":"plt.plot(train, label='Train')\nplt.plot(test.index,test, label='Test')\nplt.plot(test.index, TES_add_predict, label='Forecast')\nplt.legend(loc='best')\nplt.grid()","1d6bc7d2":"validation.shape","6a4829a5":"validation.head()","27755a5f":"validation.tail()","ae67562f":"date = pd.date_range('11\/1\/1974', '11\/1\/1975', freq='M')\ndate","169c59d5":"validation['Months'] = date\nvalidation.set_index('Months', inplace=True)\nvalidation.head()","2b8114c1":"model_TES_add = ExponentialSmoothing(dataset, trend='additive', seasonal='additive', initialization_method='estimated')\nmodel_TES_add = model_TES_add.fit(optimized=True)\nmodel_TES_add.summary()","e536c3a8":"TES_add_predict =  model_TES_add.forecast(len(validation))\nplt.plot(validation, label='Validation')\nplt.plot(validation.index, TES_add_predict, label='Forecast')\nplt.legend()\nplt.show()","1b816859":"series.head()","be1023ee":"series.tail()","812211ae":"date = pd.date_range('1\/1\/1966', '11\/1\/1975', freq='M')\ndate","10b25689":"series['Months'] = date\nseries.set_index('Months', inplace=True)\nseries.head()","5856efcd":"forecast_date = pd.date_range('11\/1\/1975', '11\/1\/1976', freq='M')\nforecast_date","75a69d13":"model_TES_add = ExponentialSmoothing(series, trend='additive', seasonal='additive', initialization_method='estimated')\nmodel_TES_add = model_TES_add.fit(optimized=True)\nTES_add_predict =  model_TES_add.forecast(12)","fc691d14":"yhat","f68cb7cc":"plt.plot(series, label='Data')\nplt.plot(forecast_date, TES_add_predict, label='Forecast')\nplt.legend()\nplt.show()","d28ec38c":"**Inference:** Final model is Exponential Smoothing","8d3e672b":"# Transformation\n**Let's check if transforming the data with Box-Cox method will improve our model** ","745c7d7a":"## Splitting data onto dataset and validation","6d42dcb3":"**Concluion:** We will stick to paramerets which we got from hyper parameter tuning. That is, ACF=0, Differencing=1 and PACF=2 (0, 1, 2) withoud transformation","3b235087":"# Differencing by 1 lab value\n(`y` at time `t`) - (`y` at time `t-1`)","1c30afa2":"**Inference**\n1. Total of 106 records\n2. Mean robberies as 173.10\n3. Standard deviation is larger than mean: robberies are increasing yearly","96c1940e":"# Data analysis","f4ca0130":"**Inference:** Error increased, transformation is a bad idea","edf54ee3":"# Exponential Smoothing model","f8a511c5":"## Preprocessing original dada","4377dc35":"# Stationary test\n**Stationary test means all the data are around mean and varience of the entire data. To forecast any time series, stationary data is required. In case, data is not stationary we use differencing technique to transform non-stationary series into stationary series** ","328dc3e3":"**Inference:** Graph shows strong up-trend, which means presence of non-stationary data. Let's check bt **A**uto**c**orrelation **F**unction plot and **P**artial **A**utocorrelation **F**unction plot.","dfeeddc9":"# Forecasting for next 1 year","4f68cc14":"# Conclusion\n**It is forecasted that armed robberies are going to be increased in the next one year. Government and police has to take measure accordingly by imposing strict measures and deploying more man-force for patrolling**","23c4d40c":"**Inference:** p-value is greater than threshold 0.05(commenly taken threshold in statistics). Hence, we fail to reject hull hypothesis.So the series is  non-stationary.<br>\n**Differencing is required**","2dbe6814":"# Reading data ","4900b09f":"# Preprocessing","5b741536":"**Incerence:** There is almost 14% of error","10b84d97":"**Inference:** Slow decay in in ACF and random trend in PACF shows trend in data. Let's conform by statistical test.","5a036527":"# Forecasting Monthly Armed Robberies in Boston","73052785":"**Inference:** No much improvement in the model accuracy","afafa459":"**Inference:** Our goal is to reduce MAPE. Let's see if Exponential Smoothing will do a better job.","7036c1d9":"## Model fitting and forecasting","1afcf7d7":"## Preprocessing validation data","882bb8ed":"# ARIMA model\n**Since, we have trend to capture ARIMA model is best suited**","9cd78237":"## Manually creating next 1 year date fields","3f37b1b1":"## Model builting and forecasting the trend","5cbb112d":"## Building the model","a08e022f":"# Validation","3b504df8":"# Train-test split","4f733302":"## Dickey-Fuller test","bc6c2e74":"## Rolling forecasting to capture random variation","e4038809":"**Inference:** Both graph shows no strong seasonality","a0397af0":"## Hyperparameter tuning\n**We will look for paramerers with least AIC value**","f140e3a0":"## Forecasting","673dfa32":"## Transforming date column","e69796ff":"**Contents**\n\n1. Splitting dataset into data and validation\n2. Transforming date column\n3. Data analysis\n4. Dickey-Fuller test for stationarity\n5. ACF PACF plots\n6. Defferencing to make the series stationary\n7. Train-test split\n8. Box-Cox transformation\n9. Building ARIMA model\n10. Hyperparameter tuning\n11. Rolling forecasting to capture random variation\n12. Exponential Smoothning\n13. Validation\n14. Forecasting for next 1 year","39a69d6c":"## ACF and PCAF plots","80dd6932":"**Inference:** Linear up-trend but no seasionality","6ce7ba6b":"## Mean Absolute Percentage Error","0ea6cc5c":"**Inference:** p-value is less than threshold 0.05(commenly taken threshold in statistics). Hence, we  reject hull hypothesis.So the series is stationary at t-1 differencing.<br>"}}