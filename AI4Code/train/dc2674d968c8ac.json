{"cell_type":{"ba6b38e9":"code","ca82755b":"code","1a3628db":"code","e1242419":"code","a2e9bb64":"code","84913110":"code","03dd6730":"code","6c9d35eb":"code","08fad436":"code","904b89c6":"code","1335d10c":"markdown","8f537937":"markdown","75342b71":"markdown","ba3d13f3":"markdown","01bec911":"markdown","003aa20e":"markdown","05bbb4cd":"markdown","778aa900":"markdown","3819fef7":"markdown"},"source":{"ba6b38e9":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import plot_model\n\nphysical_devices = tf.config.list_physical_devices('GPU')\ntf.config.experimental.set_memory_growth(physical_devices[0], enable=True)","ca82755b":"TRAIN_FILE_PATH = '\/kaggle\/input\/ag-news-classification-dataset\/train.csv'\nTEST_FILE_PATH = '\/kaggle\/input\/ag-news-classification-dataset\/test.csv'\n\ndata = pd.read_csv(TRAIN_FILE_PATH)\ntestdata = pd.read_csv(TEST_FILE_PATH)\n\nX_train = data['Title'] + \" \" + data['Description'] # Combine title and description (better accuracy than using them as separate features)\ny_train = data['Class Index'].apply(lambda x: x-1).values # Class labels need to begin from 0\n\nx_test = testdata['Title'] + \" \" + testdata['Description'] # Combine title and description (better accuracy than using them as separate features)\ny_test = testdata['Class Index'].apply(lambda x: x-1).values # Class labels need to begin from 0\n\nmaxlen = X_train.map(lambda x: len(x.split())).max() # max length of sentences in train dataset\ndata.head()","1a3628db":"vocab_size = 10000 # arbitrarily chosen\nembed_size = 32 # arbitrarily chosen\n\n# Create and fit tokenizer\ntok = Tokenizer(num_words=vocab_size)\ntok.fit_on_texts(X_train.values)\n\n# Tokenize data\nX_train = tok.texts_to_sequences(X_train)\nx_test = tok.texts_to_sequences(x_test)\n\n# Pad data\nX_train = pad_sequences(X_train, maxlen=maxlen)\nx_test = pad_sequences(x_test, maxlen=maxlen)","e1242419":"model = Sequential()\nmodel.add(Embedding(vocab_size, embed_size, input_length=maxlen))\nmodel.add(Bidirectional(LSTM(128, return_sequences=True))) # bidirectional LSTMs since this isn't a timeseries problem\nmodel.add(Bidirectional(LSTM(64, return_sequences=True)))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(1024))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(512))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(4, activation='softmax'))\nmodel.summary()","a2e9bb64":"callbacks = [\n    EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=1e-4,\n        patience=4,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        filepath='weights.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","84913110":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # sparse categorical crossentropy loss because data is not one-hot encoded\nmodel.fit(X_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=20, callbacks=callbacks)","03dd6730":"model.load_weights('weights.h5')\nmodel.save('model.hdf5')","6c9d35eb":"labels = ['World News', 'Sports News', 'Business News', 'Science-Technology News']\n\ntest = ['New evidence of virus risks from wildlife trade', 'Coronavirus: Bank pumps \u00a3100bn into UK economy to aid recovery', \n        'Trump\\'s bid to end Obama-era immigration policy ruled unlawful', 'David Luiz\u2019s future with Arsenal to be decided this week']\ntest_seq = pad_sequences(tok.texts_to_sequences(test), maxlen=maxlen)\ntest_preds = [labels[np.argmax(i)] for i in model.predict(test_seq)]\n\nfor news, label in zip(test, test_preds):\n    print('{} - {}'.format(news, label))","08fad436":"preds = [np.argmax(i) for i in model.predict(x_test)]\ncm  = confusion_matrix(y_test, preds)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(16,12), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(4), labels, fontsize=12)\nplt.yticks(range(4), labels, fontsize=12)\nplt.show()","904b89c6":"print(\"Recall of the model is {:.2f}\".format(recall_score(y_test, preds, average='micro')))\nprint(\"Precision of the model is {:.2f}\".format(precision_score(y_test, preds, average='micro')))","1335d10c":"# Tokenize and pad loaded text","8f537937":"# Plot confusion matrix","75342b71":"# Test model with some arbitrary data","ba3d13f3":"# Importing libraries","01bec911":"# Define model","003aa20e":"# Load weights with best val accuracy","05bbb4cd":"# Get precision and recall scores","778aa900":"# Compile and fit model","3819fef7":"# Load and prep data"}}