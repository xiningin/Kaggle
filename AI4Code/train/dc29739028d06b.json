{"cell_type":{"cf54972b":"code","678783d6":"code","ffc30565":"code","2c059f31":"code","a5fe88d1":"code","7f29ab94":"code","c96c8489":"code","e6c8c878":"code","2d5add9c":"code","beb2e2d3":"code","15c7c18b":"code","c5ff9602":"code","d2268d25":"code","60b809f6":"code","c516eb15":"code","ee69e6f4":"code","38e8e99a":"code","365370ed":"code","273e2caf":"code","1dfa6da1":"code","a7cdc98b":"code","971ae5a2":"code","89ab558a":"code","b030752b":"code","b723d44d":"code","408020da":"code","61e4066a":"code","c9163a7f":"code","c0fa3556":"code","0765d195":"code","4f9839cd":"code","133b2bf8":"code","080283c5":"code","6e913268":"code","1c6ef887":"code","bfef40c3":"code","c90e5e4e":"code","31e118be":"code","9c578e9e":"code","adc5b854":"code","99c60c63":"code","f4822772":"code","364a9566":"code","513de6e1":"code","f7e5b7ae":"code","d998207a":"code","3c2e6261":"code","606758b7":"code","ce73e26e":"code","4969e225":"code","04c60713":"code","d10f7d5d":"code","6fd4127a":"code","1af14f11":"code","f6416b09":"code","d7ac1840":"code","45656ed5":"code","b1a8f557":"code","bcd2a050":"code","9dbe376a":"code","0c4107bf":"code","7b87b985":"code","ca549afe":"code","1548c7cd":"code","ff26d59d":"code","883d1e1a":"code","829ccaae":"code","69952c0e":"code","064cf049":"code","e8c3bb97":"code","6d504afe":"code","b6d675c7":"code","f1c0cda5":"code","9f88ace2":"code","6ea379f2":"code","bf1c907a":"code","78463f14":"code","40758872":"code","673aa355":"code","66e54e92":"code","7ad84ce9":"code","91df6b18":"code","9dec2016":"code","edcd45c0":"code","18fdb932":"code","afeeb4a9":"code","c02f20bf":"code","03c53a91":"code","d0f7559c":"code","96fa1233":"code","92f38f7c":"code","e948ee9f":"code","482eda84":"code","1aef8b15":"markdown","8cea549b":"markdown","1f8b8c24":"markdown","b3e25bc3":"markdown","e2945a36":"markdown","72af996a":"markdown","bfa2b8aa":"markdown","3bb22874":"markdown","6e3aef09":"markdown","498643cb":"markdown","da470824":"markdown","e6912c47":"markdown","4accb16f":"markdown","2efad0f5":"markdown","3b7b41a3":"markdown","e3ecb51e":"markdown","a597f305":"markdown","c0c2964e":"markdown","bb374efb":"markdown","574e8ea7":"markdown","89927b57":"markdown","b7e321e0":"markdown","a15ffa21":"markdown","6a251417":"markdown","0889db40":"markdown","a69a5d52":"markdown","0d0d3ac6":"markdown","bc13f445":"markdown","20b2245e":"markdown","a7353d81":"markdown","c69587b1":"markdown","aa8ac468":"markdown","5f93f5f6":"markdown","00733162":"markdown","b6cff4f9":"markdown","f5f62326":"markdown","26c806e4":"markdown","03dff4d5":"markdown","77f7a7c6":"markdown","054dcc9e":"markdown","7a716897":"markdown"},"source":{"cf54972b":"# Data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Data visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# command for work offline\nplotly.offline.init_notebook_mode(connected=True)","678783d6":"%%time\ndf = pd.read_csv('..\/input\/heart.csv')","ffc30565":"df.sample(5)","2c059f31":"df.columns","a5fe88d1":"df.info()","7f29ab94":"# Basic descriptive statistics for each column\ndf.describe()","c96c8489":"df.shape","e6c8c878":"def missing_data(data):\n    null_columns = data.columns[data.isnull().any()]\n    return data[null_columns].isnull().sum()\n\nmissing_data(df)","2d5add9c":"# Correlation heatmap beetween the columns\nplt.rcParams['figure.figsize']=(35,16)\nhm=sns.heatmap(df.corr(), annot = True, linewidths=.5, cmap='Blues')\nhm.set_title(label='Heatmap of dataset', fontsize=20)\nhm;","beb2e2d3":"sns.pairplot(df[['age','trestbps', 'cp', 'thalach','chol','target']],hue='target',\n             palette = sns.color_palette(\"GnBu_d\"), size=2.5)","15c7c18b":"sns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(figsize=[7, 5])\nsns.countplot(x = \"target\", data = df)","c5ff9602":"df['target'].value_counts()\n# There is approximately the same number of people sick of hearts as of non-sick ","d2268d25":"fig, ax = plt.subplots(figsize=[7, 5])\npalette = sns.color_palette(\"RdBu\", n_colors=2)\nsns.countplot(x = \"target\", hue = \"sex\", data = df, palette = palette)","60b809f6":"df['age'].describe()","c516eb15":"df['age'].value_counts()[ : 10]","ee69e6f4":"fig, ax = plt.subplots(figsize=[14, 5])\nsns.countplot(x = \"age\", data = df)","38e8e99a":"fig, axe = plt.subplots(figsize = [7, 5])\nsns.distplot(df['age'], color = 'r');","365370ed":"trace = go.Histogram(x = df['age'], name = 'age', marker=dict(color='darkcyan'))\n\nlayout = go.Layout(\n    title=\"Histogram Frequency Counts of Age\"\n)\n\n\nfig = go.Figure(data=go.Data([trace]), layout=layout)\nplotly.offline.iplot(fig, filename='histogram-freq-counts of ')","273e2caf":"Adults = df[(df['age'] >= 29) & (df['age'] <= 33)]\nMiddle_Age = df[(df['age'] > 33) & (df['age'] <= 40)]\nSenior = df[(df['age'] > 40) & (df['age'] <= 66)]\nRetired = df[df['age'] > 66]","1dfa6da1":"x_ = ['Adults', 'Middle_Age', 'Senior', 'Retired']\ny_ = [len(Adults), len(Middle_Age), len(Senior), len(Retired)]","a7cdc98b":"trace = go.Bar(\n    x=x_,\n    y=y_,\n    textposition = 'auto',\n    name='target 0',\n    marker=dict(\n        color='rgba(255, 135, 141,0.7)',\n        line=dict(\n            color='rgba(255, 135, 141,1)',\n            width=1.5),\n        ),\n    opacity=1\n)\n\n\ndata = [trace]\n\nplotly.offline.iplot(data, filename='bar-chart')","971ae5a2":"colors = ['#FEBFB3', '#E1396C', '#96D38C', '#D0F9B1']\n\ntrace = go.Pie(labels=x_, values=y_,\n               hoverinfo='label+percent',\n               textfont=dict(size=20),\n               marker=dict(colors=colors, \n                           line=dict(color='#000000', width=2)))\n\nplotly.offline.iplot([trace], filename='pie-chart')","89ab558a":"fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(16, 8))\nwomen = df[df['sex'] == 0]\nmen = df[df['sex'] == 1]\n\nax = sns.distplot(women[women['target'] == 1].age, bins=18, label = 'sick', ax = axes[0], kde =False, color=\"green\")\nax = sns.distplot(women[women['target'] == 0].age, bins=40, label = 'not_sick', ax = axes[0], kde =False, color=\"red\")\nax.legend()\nax.set_title('Female')\n\nax = sns.distplot(men[men['target']==1].age, bins=18, label = 'sick', ax = axes[1], kde = False, color=\"green\")\nax = sns.distplot(men[men['target']==0].age, bins=40, label = 'not_sick', ax = axes[1], kde = False, color=\"red\")\nax.legend()\nax.set_title('Male');","b030752b":"df.groupby('target')['age'].mean()","b723d44d":"df['sex'].value_counts()\/len(df)","408020da":"ax, figure = plt.subplots(figsize = [7,5])\nsns.countplot(x = \"sex\", data = df, palette = sns.cubehelix_palette(8))","61e4066a":"# We will select randomly the same number of Male than Female and plot the distribution of sick people in function of their sex\nnb_0 = df.loc[df['sex'] == 0, ['sex']].count()[0]\nnb_1 = df.loc[df['sex'] == 1, ['sex']].count()[0]\n\nprint('Male   : ', nb_1)\nprint('Female : ', nb_0)","c9163a7f":"nb_0 = df.loc[df['sex'] == 0, ['sex']].count()[0]\nnb_1 = df.loc[df['sex'] == 1, ['sex']].count()[0]\n\nprint('Male   : ', nb_1)\nprint('Female : ', nb_0)","c0fa3556":"df0 = df[df['sex'] == 0].sample(nb_0)\ndf1 = df[df['sex'] == 1].sample(nb_0)","0765d195":"print(df0.shape)\nprint(df1.shape)","4f9839cd":"# We concatenate df1 and df2\ndfBis = pd.concat([df0,df1])","133b2bf8":"ax, figure = plt.subplots(figsize = [7,5])\nsns.countplot(x = \"target\", hue = \"sex\", data = dfBis, palette = sns.cubehelix_palette(8))","080283c5":"df['chol'].describe()","6e913268":"ax, figure = plt.subplots(figsize = [7,5])\nsns.distplot(df['chol'], color = 'b');","1c6ef887":"ax, figure = plt.subplots(figsize = [9,5])\nsns.distplot(df[df['target'] == 0].chol, label = \"not sick\", color = 'r');\nsns.distplot(df[df['target'] == 1].chol, label = \"sick\", color = 'b');\nax.legend()","bfef40c3":"df[df['target'] == 0]['chol'].describe()","c90e5e4e":"df[df['target'] == 1]['chol'].describe()","31e118be":"trace0 = go.Box(\n    x=df[df['target'] == 0].target,\n    y=df['chol'],\n    marker=dict(\n        color='#FF851B'\n    ),\n    name='not_sick'\n)\n\ntrace1 = go.Box(\n    x=df[df['target'] == 1].target,\n    y=df['chol'],\n    marker=dict(\n        color='#FF4136'\n    ),\n    name = 'sick'\n)\n\n\nplotly.offline.iplot([trace0, trace1], filename='pie-chart')","9c578e9e":"palette2 = sns.color_palette(\"RdBu\", n_colors=2)\nfig, ax2 = plt.subplots(figsize=[5, 5])\nax = sns.stripplot(x = \"target\", y = \"chol\", data = df, jitter=True, linewidth=1, palette = palette2);","adc5b854":"ax, figure = plt.subplots(figsize = [7, 5])\nsns.violinplot(x = \"sex\", y = \"chol\", hue=\"target\", data = df, palette = \"muted\", split=True)","99c60c63":"ax, figure = plt.subplots(figsize = [9,5])\nsns.regplot(x=\"age\", y=\"chol\", data=df);","f4822772":"trace = go.Scatter(\n    x = df['age'],\n    y = df['chol'],\n    mode = 'markers',\n    marker = dict(\n        size = 10,\n        color = 'rgba(255, 182, 193, .9)',\n        line = dict(\n            width = 2,\n        )\n    )\n)\n\ndata = [trace]\n\n# Plot and embed in ipython notebook!\nplotly.offline.iplot(data, filename='scatter')","364a9566":"df.groupby('age')['chol'].mean()","513de6e1":"ax, figure = plt.subplots(figsize = [12,5])\nsns.pointplot(x=\"age\", y=\"chol\", data=df, color = \"#feda6a\")","f7e5b7ae":"df['cp'].value_counts()\/len(df)","d998207a":"ax, figure = plt.subplots(figsize = [7, 5])\npalette2 = sns.color_palette(\"GnBu_d\")\nsns.countplot(x = \"cp\", data = df, palette = palette2)","3c2e6261":"ax, figure = plt.subplots(figsize = [7, 5])\npalette2 = sns.color_palette(\"GnBu_d\")\nsns.countplot(x = \"cp\", hue = 'target', data = df, palette = palette2)","606758b7":"fig, ax = plt.subplots(figsize=[7, 5])\nsns.pointplot(x = \"cp\", y = \"chol\", hue = \"target\", data = df)","ce73e26e":"palette2 = sns.color_palette(\"RdBu\", n_colors=3)\nfig, ax2 = plt.subplots(figsize=[7, 5])\nax = sns.stripplot(x = \"cp\", y = \"chol\", data = df, jitter=True, linewidth=1, palette = palette2);","4969e225":"fig, ax = plt.subplots(figsize=[7, 5])\nsns.pointplot(x = \"cp\", y = \"chol\", hue = \"sex\", data = df)","04c60713":"ax, figure = plt.subplots(figsize = [12,7])\nsns.boxplot(x = \"sex\", y = \"age\", hue = \"cp\", data = df)","d10f7d5d":"ax1, figure = plt.subplots(figsize = [7, 5])\nax1 = sns.distplot(df[df['target'] == 0].trestbps, color = 'yellow')","6fd4127a":"ax2, figure = plt.subplots(figsize = [7, 5])\nax2 = sns.distplot(df[df['target'] == 1].trestbps, color = 'green')","1af14f11":"ax, figure = plt.subplots(figsize = [7, 5])\nsns.boxplot(x = 'target', y = 'trestbps', data = df)","f6416b09":"ax, figure = plt.subplots(figsize = [7, 5])\nsns.violinplot(x = \"target\", y = \"trestbps\", hue=\"sex\", data = df, palette = \"muted\", split=True)","d7ac1840":"ax, figure = plt.subplots(figsize = [7,5])\nsns.boxplot(x = 'sex', y = 'trestbps', data = df)","45656ed5":"df['fbs'].value_counts()\/len(df)","b1a8f557":"ax, figure = plt.subplots(figsize = [7,5])\nsns.countplot(x = \"fbs\", hue = 'target', data = df, palette = sns.color_palette(\"cubehelix\", 8))","bcd2a050":"ax, figure = plt.subplots(figsize = [15,7])\nsns.countplot(x = \"age\", hue = 'fbs', data = df, palette = sns.cubehelix_palette(8, start=.5, rot=-.75))","9dbe376a":"ax, figure = plt.subplots(figsize = [7,5])\nsns.violinplot(x = \"fbs\", y = \"age\", data = df[df['fbs'] == 1], palette = \"Set2\", split=True)","0c4107bf":"ax, figure = plt.subplots(figsize = [7,5])\nsns.stripplot(x = \"fbs\", y = \"age\", data = df)","7b87b985":"ax, figure = plt.subplots(figsize = [9,5])\nsns.regplot(x=\"age\", y=\"thalach\", data=df, color = \"red\");","ca549afe":"sns.jointplot(x=\"age\", y=\"thalach\", data=df)","1548c7cd":"ax, figure = plt.subplots(figsize = [7,5])\nsns.distplot(df['thalach'], color = \"pink\")","ff26d59d":"df['thal'].value_counts()","883d1e1a":"ax, figure = plt.subplots(figsize = [7,5])\nsns.countplot(x = \"thal\", data = df)","829ccaae":"ax, figure = plt.subplots(figsize = [7,5])\nsns.countplot(x = \"thal\", hue = \"target\", data = df)","69952c0e":"cols = df.shape[1]","064cf049":"X = df.iloc[:, : cols - 1].values\ny = df.iloc[:, cols - 1].values","e8c3bb97":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_ = scaler.fit_transform(X)","6d504afe":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, auc","b6d675c7":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","f1c0cda5":"lrc = LogisticRegression()\nlrc.fit(X_train, y_train)\nprint(\"Logistics Regression accurary - training: \", lrc.score(X_train,y_train))\nprint(\"Logistics Regression accurary - test: \", lrc.score(X_test,y_test))","9f88ace2":"y_scores_lr = lrc.decision_function(X_test)\ny_score_list = list(zip(y_test[0:20], y_scores_lr[0:20]))\n\n# show the decision_function scores for first 20 instances\ny_score_list","6ea379f2":"y_proba_lr = lrc.predict_proba(X_test)\ny_proba_list = list(zip(y_test[0:20], y_proba_lr[0:20,1]))\n\n# show the probability of positive class for first 20 instances\ny_proba_list","bf1c907a":"precision, recall, thresholds = precision_recall_curve(y_test, y_scores_lr)\nclosest_zero = np.argmin(np.abs(thresholds))\nclosest_zero_p = precision[closest_zero]\nclosest_zero_r = recall[closest_zero]\n\nplt.figure(figsize = [12,7])\nplt.xlim([0.0, 1.01])\nplt.ylim([0.0, 1.01])\nplt.plot(precision, recall, label='Precision-Recall Curve')\nplt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\nplt.xlabel('Precision', fontsize=16)\nplt.ylabel('Recall', fontsize=16)\nplt.axes().set_aspect('equal')\nplt.show()","78463f14":"y_score_lr = lrc.decision_function(X_test)\nfpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_lr)\nroc_auc_lr = auc(fpr_lr, tpr_lr)\n\nplt.figure(figsize = [12,7])\nplt.xlim([-0.01, 1.00])\nplt.ylim([-0.01, 1.01])\nplt.plot(fpr_lr, tpr_lr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc_lr))\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curve ', fontsize=16)\nplt.legend(loc='lower right', fontsize=13)\nplt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\nplt.axes().set_aspect('equal')\nplt.show()","40758872":"cm_lrc = confusion_matrix(y_test,lrc.predict(X_test))\n\n\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cm_lrc,annot = True, linewidths=.5, cmap='Spectral')\nplt.title(\"Test for Test Dataset\")\nplt.xlabel(\"predicted y values\")\nplt.ylabel(\"real y values\")\nplt.show()\n\n# Accuracy = TP + TN \/ (TP + TN + FP + FN)\n# Precision = TP \/ (TP + FP)\n# Recall = TP \/ (TP + FN)  Also known as sensitivity, or True Positive Rate\n# F1 = 2 * Precision * Recall \/ (Precision + Recall) \nprint(\"precision_score: \", precision_score(y_test,lrc.predict(X_test)))\nprint(\"recall_score: \", recall_score(y_test,lrc.predict(X_test)))\nprint(\"f1_score: \",f1_score(y_test,lrc.predict(X_test)))","673aa355":"%%time\nparam_grid = {'C': [1,0.01,0.1,10,100],\n              'penalty' : [\"l1\", \"l2\"],\n              'class_weight' : [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n          }\n\nlr = LogisticRegression()\n\nlr_cv = GridSearchCV(\n    estimator = LogisticRegression(random_state=12,solver=\"liblinear\"),\n    param_grid = param_grid, \n     scoring='roc_auc',\n    cv = 5\n   )\n\nlr_cv.fit(X_train, y_train)\n\nprint(\"tuned hyperparameters :(best parameters) \",lr_cv.best_params_)\nprint(\"accuracy on test set:\",lr_cv.best_score_)\nprint('accuracy on training set : ',lr_cv.score(X_train, y_train))\nprint('accuracy on test set : ',lr_cv.score(X_test, y_test))","66e54e92":"%%time\n\ngrid = {'C':[0.01, 0.1, 1, 10, 100]} \nsvm = LinearSVC(max_iter = 10000).fit(X_train, y_train)\nsvm_cv = GridSearchCV(svm, grid, cv = 10, n_jobs = -1)\nsvm_cv.fit(X_train, y_train)\n\nprint(\"tuned hyperparameters :(best parameters) \",svm_cv.best_params_)\nprint(\"accuracy on test set:\",svm_cv.best_score_)\nprint('accuracy on training set : ',svm.score(X_train, y_train))","7ad84ce9":"from matplotlib import cm\n\n\nplt.figure(figsize = [7,15])\nplt.xlim([-0.01, 1.00])\nplt.ylim([-0.01, 1.01])\nfor c in [0.01, 0.1, 1, 10, 100]:\n    svm = LinearSVC(max_iter = 10000).fit(X_train, y_train)\n    y_score_svm = svm.decision_function(X_test)\n    fpr_svm, tpr_svm, _ = roc_curve(y_test, y_score_svm)\n    roc_auc_svm = auc(fpr_svm, tpr_svm)\n    accuracy_svm = svm.score(X_test, y_test)\n    print(\"C = {:.2f}  accuracy = {:.2f}   AUC = {:.2f}\".format(c, accuracy_svm, \n                                                                    roc_auc_svm))\n    plt.plot(fpr_svm, tpr_svm, lw=3, alpha=0.7, \n             label='SVM (C = {:0.2f}, area = {:0.2f})'.format(c, roc_auc_svm))\n\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate (Recall)', fontsize=16)\nplt.plot([0, 1], [0, 1], color='k', lw=0.5, linestyle='--')\nplt.legend(loc=\"lower right\", fontsize=11)\nplt.title('ROC curve: ', fontsize=16)\nplt.axes().set_aspect('equal')\n\nplt.show()","91df6b18":"%%time\n\nSVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\n\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=5, scoring=\"accuracy\", n_jobs = -1, verbose = 1)\n\ngsSVMC.fit(X_train,y_train)\n\nSVMC_best = gsSVMC.best_estimator_\n\n# Best score\nprint(gsSVMC.best_score_)","9dec2016":"%%time\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nprint('Naives bayes accuracy - training : ', nb.score(X_train, y_train))\nprint('Naives bayes accuracy - test : ', nb.score(X_test, y_test))","edcd45c0":"%%time\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint('Knn accuracy - training : ', knn.score(X_train, y_train))\nprint('Knn accuracy - test : ', knn.score(X_test, y_test))","18fdb932":"acc_knn_train = []\nacc_knn_test = []\nfor k in range(1,21):\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(X_train, y_train)\n    score_train = knn.score(X_train, y_train)\n    score_test = knn.score(X_test, y_test)\n    acc_knn_train.append(score_train)\n    acc_knn_test.append(score_test)","afeeb4a9":"fig, ax = plt.subplots(figsize = [7, 5])\nax.plot(range(1,21), acc_knn_train, label='train_score')\nax.plot(range(1,21), acc_knn_test, label='test_score')\nplt.xticks(np.arange(1,21,1))\nplt.xlabel(\"K value\")\nplt.ylabel(\"Score\")\nlegend = ax.legend(loc='top right', shadow=True)\nplt.show()","c02f20bf":"%%time\ntr = DecisionTreeClassifier()\ntr.fit(X_train, y_train)\nprint('Decision Tree accuracy - training', tr.score(X_train, y_train))\nprint('Decision Tree accuracy - test', tr.score(X_test, y_test))","03c53a91":"%%time\nrfc = RandomForestClassifier(n_estimators=200, min_samples_leaf=3, max_features=0.5)\nrfc.fit(X_train, y_train)\nrfc.predict(X_test)\nprint('Random Forest accuracy - training : ', rfc.score(X_train, y_train))\nprint('Random Forest accuracy  - test :', rfc.score(X_test, y_test))","d0f7559c":"%%time\netc = ExtraTreesClassifier()\netc.fit(X_train, y_train)\netc.predict(X_test)\nprint('Extra Tree Classifier accuracy - training', etc.score(X_train, y_train))\nprint('Extra Tree Classifier accuracy - test', etc.score(X_test, y_test))","96fa1233":"%%time\nadaboost = AdaBoostClassifier()\nadaboost.fit(X_train, y_train)\nprint('AdaBoost accuracy - training', adaboost.score(X_train, y_train))\nprint('AdaBoost accuracy - test', adaboost.score(X_test, y_test))","92f38f7c":"%%time\nbag = BaggingClassifier()\nbag.fit(X_train, y_train)\nprint('Bagging accuracy - training', bag.score(X_train, y_train))\nprint('Bagging accuracy - test', bag.score(X_test, y_test))","e948ee9f":"mlp = MLPClassifier()\nmlp.fit(X_train, y_train)\nprint('Neural Networks accuracy - training', etc.score(X_train, y_train))\nprint('Neural Networks accuracy - test', etc.score(X_test, y_test))","482eda84":"%%time\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\ndef build_classifier():\n    classifier = Sequential()\n    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train)\nmean = accuracies.mean()\nvariance = accuracies.std()\nprint('Accuracy : ', mean)\nprint('Variance : ', variance)","1aef8b15":"### AdaBoostClassifier","8cea549b":"<h1 style=\"color: #539DC2;\">EDA<\/h1>","1f8b8c24":"##### We can see that female are more likely to be sick than male","b3e25bc3":"<br>","e2945a36":"### Age","72af996a":"### Artificial Neural Network","bfa2b8aa":"### Knn","3bb22874":"### Decision Tree","6e3aef09":"# Predicting Heart Disease","498643cb":"##### For both Female and Male peoples are more likely to be sick if they are older","da470824":"### Extra Tree Classifier","e6912c47":"<h1 style=\"color: #539DC2;\">Model<\/h1>","4accb16f":"##### There are no missing values in the dataset","2efad0f5":"In this Notebook we will predict if a person present heart disease or not.\nWe will first perform exploratory data analysis on the dataset and identify\nrelationship between heart disease and the others variables.\nWe will finish by using ML algorithms to make future prediction on unlabeled dataset.","3b7b41a3":"### Trestbps (resting blood pressure) analysis","e3ecb51e":"### Linear SVM","a597f305":"##### We can see that most people with a thal of 2 are sick","c0c2964e":"##### Display 5 rows randomly","bb374efb":"## Neural Network with Keras","574e8ea7":"##### We can see that people with chest pain are more likely to be sick","89927b57":"### Kernelized SVM","b7e321e0":"### Cp (Chest pain type) analysis","a15ffa21":"### Thal analysis","6a251417":"<ul>\n  <li style=\"color: #539DC2;\"><span style=\"color: #539DC2\">Introduction<\/li>\n  <li style=\"color: #539DC2;\"><span style=\"color: #539DC2\">Exploratory Data Analysis (EDA)<\/li>\n  <li style=\"color: #539DC2;\"><span style=\"color: #539DC2\">Model<\/li>\n<\/ul> ","0889db40":"### Naives bayes","a69a5d52":"## Content","0d0d3ac6":"#### Loading packages","bc13f445":"### Logistic Regression","20b2245e":"### BaggingClassifier","a7353d81":"### RandomForest","c69587b1":"<h1 style=\"color: #539DC2;\">Introduction<\/h1>","aa8ac468":"### Thalach (maximum heart rate achieved)","5f93f5f6":"<ol>\n  <li>age<\/li>\n  <li>sex<\/li>\n  <li>chest pain type (4 values)<\/li>\n  <li>resting blood pressure<\/li>\n  <li>serum cholestoral in mg\/dl<\/li>\n  <li>fasting blood sugar > 120 mg\/dl<\/li>\n  <li>resting electrocardiographic results (values 0,1,2)<\/li>\n  <li>maximum heart rate achieved<\/li>\n  <li>exercise induced angina<\/li>\n  <li>oldpeak = ST depression induced by exercise relative to rest<\/li>\n  <li>the slope of the peak exercise ST segment<\/li>\n  <li>number of major vessels (0-3) colored by flourosopy<\/li>\n  <li>thal: 3 = normal; 6 = fixed defect; 7 = reversable defect<\/li>   \n<\/ol> ","00733162":"__Kevin.F__  \n_17\/03\/2019_","b6cff4f9":"### Cholesterol analysis","f5f62326":"### Age\/fbs","26c806e4":"<br>","03dff4d5":"### Target analysis","77f7a7c6":"### Fbs (Fasting blood sugar) analysis","054dcc9e":"#### Variables :","7a716897":"### Sex analysis"}}