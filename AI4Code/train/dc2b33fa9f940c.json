{"cell_type":{"7f791f88":"code","4ce2cc4f":"code","50cb8e66":"code","00fc090d":"code","e9ee71d4":"code","5c7107c1":"code","f11df049":"code","76cd81e1":"code","ca379a9a":"code","9ab36ba9":"code","50bcc105":"code","93f9486d":"code","4a79a039":"code","fd47bbfd":"code","4f438541":"code","84ca0c93":"code","e51c5d3e":"code","a86f99c8":"code","d1e9a111":"code","9350952b":"code","b94a5861":"code","385621a6":"code","5a565081":"code","688d26cc":"code","9af5107d":"code","0627339d":"code","a64d5386":"code","503d612b":"code","9e457e9a":"code","684f5c86":"code","fe893ee4":"code","825e8c8d":"code","996fa559":"code","180e0bad":"code","f1a4721d":"code","5c47503d":"code","6af1b5bd":"code","046fed93":"code","a912c811":"code","68474a4e":"code","6c55b24b":"code","78e205e1":"code","ceb077ba":"code","6ae41d14":"code","1d1a7df2":"code","c98718b4":"code","8d51dd60":"code","a7770863":"code","ee0e41a5":"code","cbd88517":"code","7f9a9f43":"markdown","f7b9746b":"markdown","bdc9f7ae":"markdown","0fc8fad2":"markdown","6f81c508":"markdown","b060ae7a":"markdown","cc64ff77":"markdown","b3070676":"markdown","fe5ac800":"markdown","6323111c":"markdown"},"source":{"7f791f88":"!ls ..\/input\/breastcancer-dataset\/","4ce2cc4f":"import sys; print(\"Python\", sys.version)\nimport numpy; print(\"NumPy\", numpy.__version__)\nimport scipy; print(\"SciPy\", scipy.__version__)\nimport sklearn; print(\"Scikit-Learn\", sklearn.__version__)","50cb8e66":"\n\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as s\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nimport pickle","00fc090d":"data = pd.read_csv('..\/input\/breastcancer-dataset\/data.csv')","e9ee71d4":"data.shape","5c7107c1":"data.head()","f11df049":"df = data.drop('Unnamed: 32', axis=1)","76cd81e1":"df['diagnosis'].value_counts()","ca379a9a":"df.diagnosis = df.diagnosis.astype('category')","9ab36ba9":"df.head()","50bcc105":"X = df.drop(labels='diagnosis',axis=1)\nY= df['diagnosis']\ncol=X.columns","93f9486d":"col","4a79a039":"X.isnull().sum()","fd47bbfd":"X.head()","4f438541":"\n# X = mms.transform(X)\n\ndf_norm = (X - X.mean()) \/ (X.max() - X.min())\ndf_norm = pd.concat([df_norm, Y], axis=1)","84ca0c93":"# X=pd.DataFrame(X)\n# X.columns=col","e51c5d3e":"df_norm.head()","a86f99c8":"#Explore correlations\nplt.rcParams['figure.figsize']=(12,8)\ns.set(font_scale=1.4)\ns.heatmap(df.drop('diagnosis', axis=1).drop('id',axis=1).corr(), cmap='coolwarm')","d1e9a111":"plt.rcParams['figure.figsize']=(10,5)\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='radius_mean',data=df, ax=ax1)\ns.boxplot('diagnosis',y='texture_mean',data=df, ax=ax2)\ns.boxplot('diagnosis',y='perimeter_mean',data=df, ax=ax3)\ns.boxplot('diagnosis',y='area_mean',data=df, ax=ax4)\ns.boxplot('diagnosis',y='smoothness_mean',data=df, ax=ax5)\nf.tight_layout()\n\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='compactness_mean',data=df, ax=ax2)\ns.boxplot('diagnosis',y='concavity_mean',data=df, ax=ax1)\ns.boxplot('diagnosis',y='concave points_mean',data=df, ax=ax3)\ns.boxplot('diagnosis',y='symmetry_mean',data=df, ax=ax4)\ns.boxplot('diagnosis',y='fractal_dimension_mean',data=df, ax=ax5)    \nf.tight_layout()","9350952b":"g = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"radius_mean\", hist=False, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"texture_mean\", hist=True, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"perimeter_mean\", hist=True, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"area_mean\", hist=True, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"smoothness_mean\", hist=True, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"compactness_mean\", hist=True, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"concavity_mean\", hist=True, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"concave points_mean\", hist=True, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"symmetry_mean\", hist=True, rug=True)\n\ng = s.FacetGrid(df, col='diagnosis', hue='diagnosis')\ng.map(s.distplot, \"fractal_dimension_mean\", hist=True, rug=True)","b94a5861":"\nplt.rcParams['figure.figsize']=(10,5)\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='radius_se',data=df, ax=ax1, palette='cubehelix')\ns.boxplot('diagnosis',y='texture_se',data=df, ax=ax2, palette='cubehelix')\ns.boxplot('diagnosis',y='perimeter_se',data=df, ax=ax3, palette='cubehelix')\ns.boxplot('diagnosis',y='area_se',data=df, ax=ax4, palette='cubehelix')\ns.boxplot('diagnosis',y='smoothness_se',data=df, ax=ax5, palette='cubehelix')\nf.tight_layout()\n\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='compactness_se',data=df, ax=ax2, palette='cubehelix')\ns.boxplot('diagnosis',y='concavity_se',data=df, ax=ax1, palette='cubehelix')\ns.boxplot('diagnosis',y='concave points_se',data=df, ax=ax3, palette='cubehelix')\ns.boxplot('diagnosis',y='symmetry_se',data=df, ax=ax4, palette='cubehelix')\ns.boxplot('diagnosis',y='fractal_dimension_se',data=df, ax=ax5, palette='cubehelix')    \nf.tight_layout()\n\n","385621a6":"plt.rcParams['figure.figsize']=(10,5)\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='radius_worst',data=df, ax=ax1, palette='coolwarm')\ns.boxplot('diagnosis',y='texture_worst',data=df, ax=ax2, palette='coolwarm')\ns.boxplot('diagnosis',y='perimeter_worst',data=df, ax=ax3, palette='coolwarm')\ns.boxplot('diagnosis',y='area_worst',data=df, ax=ax4, palette='coolwarm')\ns.boxplot('diagnosis',y='smoothness_worst',data=df, ax=ax5, palette='coolwarm')\nf.tight_layout()\n\nf, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\ns.boxplot('diagnosis',y='compactness_worst',data=df, ax=ax2, palette='coolwarm')\ns.boxplot('diagnosis',y='concavity_worst',data=df, ax=ax1, palette='coolwarm')\ns.boxplot('diagnosis',y='concave points_worst',data=df, ax=ax3, palette='coolwarm')\ns.boxplot('diagnosis',y='symmetry_worst',data=df, ax=ax4, palette='coolwarm')\ns.boxplot('diagnosis',y='fractal_dimension_worst',data=df, ax=ax5, palette='coolwarm')    \nf.tight_layout()","5a565081":"Y.tail()","688d26cc":"X_norm = df_norm.drop(labels='diagnosis',axis=1)\nY_norm= df_norm['diagnosis']\ncol=X_norm.columns\n\nle = LabelEncoder()\nle.fit(Y_norm)","9af5107d":"X","0627339d":"Y_norm=le.transform(Y_norm)\n","a64d5386":"Y_norm=pd.DataFrame(Y_norm)\nY_norm.tail()","503d612b":"columns = df_norm.columns","9e457e9a":"# Functionalize model fittting\n\ndef FitModel(X,Y,algo_name,algorithm,gridSearchParams,cv):\n    np.random.seed(10)\n    \n    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n    \n    grid = GridSearchCV(\n        estimator=algorithm,\n        param_grid=gridSearchParams,\n        cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n    \n    \n    grid_result = grid.fit(x_train, y_train)\n    best_params = grid_result.best_params_\n    pred = grid_result.predict(x_test)\n    cm = confusion_matrix(y_test, pred)\n   # metrics =grid_result.gr\n    print(pred)\n    pickle.dump(grid_result,open(algo_name,'wb'))\n   \n    print('Best Params :',best_params)\n    print('Classification Report :',classification_report(y_test,pred))\n    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n    print('Confusion Matrix : \\n', cm)","684f5c86":"param ={\n            'C': [0.1, 1, 100, 1000],\n            'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n        }\nFitModel(X_norm,Y_norm,'SVC_norm',SVC(),param,cv=5)","fe893ee4":"param ={\n            'n_estimators': [100, 500, 1000, 2000],\n           \n        }\nFitModel(X_norm,Y_norm,'Random Forest',RandomForestClassifier(),param,cv=10)","825e8c8d":"np.random.seed(10)\n\nx_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n\n\nforest = RandomForestClassifier(n_estimators=1000)\nfit = forest.fit(x_train, y_train)\naccuracy = fit.score(x_test, y_test)\npredict = fit.predict(x_test)\ncmatrix = confusion_matrix(y_test, predict)\n\n#--------------------------------------------------------------------------------------#\n# Perform k fold cross-validation\n\n\nprint ('Accuracy of Random Forest: %s' % \"{0:.2%}\".format(accuracy))\n","996fa559":"#%%Feature importances\nimportances = forest.feature_importances_\nindices = np.argsort(importances)[::-1]\n\nprint(\"Feature ranking:\")\nfor f in range(X.shape[1]):\n    print(\"feature %s (%f)\" % (list(X)[f], importances[indices[f]]))","180e0bad":"feat_imp = pd.DataFrame({'Feature':list(X),\n                        'Gini importance':importances[indices]})\nplt.rcParams['figure.figsize']=(12,12)\ns.set_style('whitegrid')\nax = s.barplot(x='Gini importance', y='Feature', data=feat_imp)\nax.set(xlabel='Gini Importance')\nplt.show()","f1a4721d":"param ={\n            'n_estimators': [100, 500, 1000, 2000],\n           \n        }\nFitModel(X_norm,Y_norm,'XGBoost_norm',XGBClassifier(),param,cv=5)","5c47503d":"df_norm.head()","6af1b5bd":"from imblearn.over_sampling import SMOTE","046fed93":"sm =SMOTE(random_state=42)\nX_res , Y_res = sm.fit_resample(X_norm,Y_norm)","a912c811":"sm.fit_sample(X_norm,Y_norm)","68474a4e":"param ={\n            'n_estimators': [100, 500, 1000, 2000],\n           }\nFitModel(X_res,Y_res,'Random Forest',RandomForestClassifier(),param,cv=10)","6c55b24b":"param ={\n            'C': [0.1, 1, 100, 1000],\n            'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n        }\nFitModel(X_res,Y_res,'SVC',SVC(),param,cv=5)","78e205e1":"param ={\n            'n_estimators': [100, 500, 1000, 2000],\n           \n        }\nFitModel(X_res,Y_res,'XGBoost',XGBClassifier(),param,cv=10)","ceb077ba":"feat_imp.index = feat_imp.Feature","6ae41d14":"feat_to_keep = feat_imp.iloc[1:15].index","1d1a7df2":"\ntype(feat_to_keep),feat_to_keep\n","c98718b4":"X_res= pd.DataFrame(X_res)\nY_res = pd.DataFrame(Y_res)\nX_res.columns = X_norm.columns\n\nparam ={\n            'n_estimators': [100, 500, 1000, 2000],\n           \n        }\nFitModel(X_res[feat_to_keep],Y_res,'Random Forest',RandomForestClassifier(),param,cv=10)","8d51dd60":"loaded_model = pickle.load(open(\"XGBoost_norm\",\"rb\"))","a7770863":"\npred1 = loaded_model.predict(x_test)\nloaded_model.best_params_","ee0e41a5":"X_res.columns","cbd88517":"x_train1,x_test1,y_train1,y_test1 = train_test_split(X_res,Y_res, test_size = 0.2)\n    \ntrain=pd.concat([y_train1,x_train1],axis=1)\ntrain.to_csv('.\/train.csv',index=False,header=False)\n    \n\ny_train.to_csv('.\/Y-train.csv')\n\n    \ntest=pd.concat([y_test1,x_test1],axis=1)\ntest.to_csv('.\/test.csv',index=False,header=False)\n    \ny_test.to_csv('.\/Y-test.csv')\n    ","7f9a9f43":"# Feature Selection","f7b9746b":"# Fitting the ML Model","bdc9f7ae":"# Random Forest","0fc8fad2":"# XGBoost","6f81c508":"# Reloading the Saved Model","b060ae7a":"## SVC ML Model","cc64ff77":"# Normalization and Feature Scaling ","b3070676":"# Feature Engineering","fe5ac800":"# BALANCING THE DATASET","6323111c":"#  Visualization "}}