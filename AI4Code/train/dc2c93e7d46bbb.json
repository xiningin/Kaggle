{"cell_type":{"76eac125":"code","4c47b1ae":"code","59c44701":"code","50eb3da9":"code","4edf3728":"code","57b7dcb1":"code","db006248":"code","b36e6309":"code","e652158f":"code","cded82c3":"code","5aee5c62":"code","42057268":"code","a6e7d628":"code","19a0e01b":"code","2b89c9e2":"code","2ff5fcc5":"code","e6c6ad1b":"code","596c2aee":"code","6cbe6c89":"code","47c77e9e":"code","75d82433":"code","aa220842":"code","5901db2f":"code","e52fcca8":"code","f6919f9b":"code","3a099f0d":"code","cdd751f5":"markdown","2a3a8e98":"markdown","fdc90623":"markdown","9c4143ef":"markdown","c92b76cf":"markdown","8f012a21":"markdown","736265c1":"markdown","d6c5f6a4":"markdown","8102c556":"markdown","be3e8a87":"markdown","e3f249b2":"markdown","721ddd6a":"markdown","9630b5a6":"markdown","3c594de2":"markdown","5310af82":"markdown","ea46e0ba":"markdown","8a46cbf3":"markdown","26dd3074":"markdown","f2ee037e":"markdown","a4064ed2":"markdown","d7a12dad":"markdown","6e119ed9":"markdown","df7ecb24":"markdown","fcc4abd2":"markdown","b1c41284":"markdown","dac85b1e":"markdown"},"source":{"76eac125":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns; #sns.set()\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, cross_validate, KFold\n%matplotlib inline\nimport warnings\npd.options.mode.chained_assignment = None  # default='warn'\n# warnings.filterwarnings('ignore') # disable all warnings\nwarnings.filterwarnings(action='once') # warn only once","4c47b1ae":"data = pd.read_csv('..\/input\/who_suicide_statistics.csv')","59c44701":"data.head()","50eb3da9":"data.describe()","4edf3728":"data.astype('object').describe()","57b7dcb1":"na_stats = pd.DataFrame([],columns=['count_na','prop_na'])\nna_stats['count_na'] = (data.isna().sum())\nna_stats['prop_na'] = (data.isna().sum()\/data.shape[0])\nna_stats","db006248":"nan_suicides = data.suicides_no.isnull().groupby([data['country']]).sum().astype(int).reset_index(name='count')\nnan_population = data.population.isnull().groupby([data['country']]).sum().astype(int).reset_index(name='count')\ncount_by_country = pd.DataFrame(data.groupby(data['country'])['suicides_no'].count())\ncount_by_country = count_by_country.reset_index()\n\nprop = pd.DataFrame([], columns = ['country', 'prop_suicides_nan', 'prop_population_nan'])\nprop['prop_suicides_nan'] = nan_suicides['count']\/count_by_country['suicides_no']\nprop['prop_population_nan'] = nan_population['count']\/count_by_country['suicides_no']\nprop['country'] = nan_suicides['country']\n\n# Only show countries that have some missing data.\nprop[prop['prop_suicides_nan'] > 0].sort_values(by=['prop_suicides_nan'], ascending=False)","b36e6309":"data_clean = data.dropna()\ndata_clean.head()","e652158f":"target_country = \"United States\"\nfig, ax = plt.subplots(figsize=(12,6))\nax.set_title( 'Suicides by age ({})'.format(target_country))\np = sns.scatterplot(x=\"year\", y=\"suicides_no\", data=data_clean,hue='age',style='sex')","cded82c3":"target_country = \"United States\"\nfig, ax = plt.subplots(figsize=(12,6))\nax.set_title( 'Suicides by sex ({})'.format(target_country))\nsui_by_sex = data_clean[data_clean[\"country\"].str.contains(target_country)].groupby(['sex','year'],as_index=False).sum()\np = sns.scatterplot(x=\"year\", y=\"suicides_no\", data=sui_by_sex,hue='sex')","5aee5c62":"agemap = {}\ni = 0\nfor x in data.age.unique():\n    agemap[x] = i\n    i+=1\n\n# since there are only two values here, we can do a mapping for gender. If >2 types listed, we could do a one-hot encoding instead.\ngendermap = {}\ni = 0\nfor x in data.sex.unique():\n    gendermap[x] = i\n    i+=1\n    \ndata_clean['age_id'] = data['age'].map(agemap)\ndata_clean['sex_id'] = data['sex'].map(gendermap)\n","42057268":"x = data_clean.drop(['sex','age'], axis = 1)\nx = pd.get_dummies(x)\ny = x[['suicides_no']]\nx = x.drop('suicides_no',axis=1)","a6e7d628":"corr = data_clean.corr()\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, vmax=.3, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","19a0e01b":"# Separate the suicides and population values by gender\ndata_by_gender = data_clean.loc[data_clean['sex_id'] == 1]\ndata_by_females = data_clean.loc[data_clean['sex_id'] == 0]\n#data_by_gender['f_suicides_no'] = data_by_gender.merge(data_by_females, on=['country', 'year', 'age'])[['suicides_no_y']]\ndata_by_gender.rename(columns={'suicides_no':'m_suicides_no'}, inplace=True)\ndata_by_gender.rename(columns={'population':'m_population'}, inplace=True)\n\n# Wrangle the data into the right format without redundant columns\ndata_by_gender = data_by_gender.merge(data_by_females, on=['country', 'year', 'age'])\ndata_by_gender = data_by_gender.drop(labels=['age','age_id_y','sex_x','sex_y','sex_id_y','sex_id_x'],axis=1)\ndata_by_gender.rename(columns={'population':'f_population', 'age_id_x': 'age_id'}, inplace=True)\ndata_by_gender.rename(columns={'suicides_no':'f_suicides_no'}, inplace=True)","2b89c9e2":"data_by_gender.head()","2ff5fcc5":"x_s = pd.get_dummies(data_by_gender)\ny_s = x_s[['f_suicides_no','m_suicides_no']]\nx_s = x_s.drop(['f_suicides_no','m_suicides_no'],axis=1)\n\n# Just doing a sanity check to make sure the data looks the way we want it.\nx_s.head()","e6c6ad1b":"corr_by_gender = data_by_gender.corr()\nsns.heatmap(corr_by_gender, vmax=.3, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","596c2aee":"# split into train\/test\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=314)\n\n# and again by gender\nx_s_train, x_s_test, y_s_train, y_s_test = train_test_split(x_s, y_s, test_size=0.25, random_state=314)","6cbe6c89":"reg = LinearRegression().fit(x_train, y_train)\ny_hat = reg.predict(x_test)\ny_hat = pd.DataFrame(y_hat,columns=['suicides_no'])\n\n#compute metrics\n\nmse = (metrics.mean_squared_error(y_pred=y_hat, y_true=y_test ))\nr2 = metrics.r2_score(y_pred=y_hat, y_true=y_test)\nfig, ax = plt.subplots(figsize=(12,6))\nsns.scatterplot(x=y_test['suicides_no'],y=y_hat['suicides_no'])\nax.set(xlabel = 'Actual y', ylabel=\"Predicted y\")\nplt.show()\nprint('The r-squared value is: {}, and MSE is: {}'.format(r2, mse))","47c77e9e":"kf = KFold(5,shuffle=True)\nreg_cv = LinearRegression()\nlas_cv = Lasso()\nkn_cv = KNeighborsRegressor(n_neighbors=30)\nreg_cv_model = cross_validate(reg_cv, X=x, y=y, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nlas_cv_model = cross_validate(las_cv, X=x, y=y, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nkn_cv_model = cross_validate(kn_cv, X=x, y=y, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\n\nreg_cv_scores = cross_val_score(reg_cv, X=x, y=y, cv=kf)\nlas_cv_scores = cross_val_score(las_cv, X=x, y=y, cv=kf)\nkn_cv_scores = cross_val_score(kn_cv, X=x, y=y, cv=kf)\nprint('Linear Regression: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, reg_cv_scores.mean()), ('\\nLasso: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, las_cv_scores.mean())), ('\\nk-NN Regressor: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, kn_cv_scores.mean())))\n","75d82433":"x_usa = data_clean.drop(['sex','age'], axis = 1)\nx_usa = x_usa[x_usa['country'].str.contains(\"United States\")]\nx_usa = x_usa.drop('country',axis=1)\nx_usa = pd.get_dummies(x_usa)\ny_usa = x_usa[['suicides_no']]\nx_usa = x_usa.drop('suicides_no',axis=1);\nx_usa_train, x_usa_test, y_usa_train, y_usa_test = train_test_split(x_usa, y_usa, test_size=0.25, random_state=314)","aa220842":"reg_usa = LinearRegression().fit(x_usa_train, y_usa_train)\ny_usa_hat = reg_usa.predict(x_usa_test)\ny_usa_hat = pd.DataFrame(y_usa_hat,columns=['suicides_no'])\n\n#compute metrics\nmse_usa = (metrics.mean_squared_error(y_pred=y_usa_hat, y_true=y_usa_test ))\nr2_usa = metrics.r2_score(y_pred=y_usa_hat, y_true=y_usa_test)\n\n#fig_usa, ax_usa = plt.subplots(figsize=(12,6))\n\nfig, ax = plt.subplots()\nax.scatter(x=y_usa_test['suicides_no'],y=y_usa_hat['suicides_no'])\nplt.xlabel('Actual y')\nplt.ylabel('Predicted y')\nplt.show()\n#ax_usa.set(xlabel = 'Actual y', ylabel=\"Predicted y\")\n\nprint('The r-squared value is: {}, and MSE is: {}'.format(r2_usa, mse_usa))","5901db2f":"kf = KFold(5,shuffle=True)\nreg_cv = LinearRegression()\nlas_cv = Lasso()\nkn_cv = KNeighborsRegressor(n_neighbors=30)\nreg_cv_model = cross_validate(reg_cv, X=x_usa, y=y_usa, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nlas_cv_model = cross_validate(las_cv, X=x_usa, y=y_usa, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nkn_cv_model = cross_validate(kn_cv, X=x_usa, y=y_usa, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\n\nreg_cv_scores = cross_val_score(reg_cv, X=x_usa, y=y_usa, cv=kf)\nlas_cv_scores = cross_val_score(las_cv, X=x_usa, y=y_usa, cv=kf)\nkn_cv_scores = cross_val_score(kn_cv, X=x_usa, y=y_usa, cv=kf)\nprint('Linear Regression: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, reg_cv_scores.mean()), ('\\nLasso: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, las_cv_scores.mean())), ('\\nk-NN Regressor: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, kn_cv_scores.mean())))","e52fcca8":"# Pick a target gender, m or f\ntarget = 'f_suicides_no'\nreg = LinearRegression().fit(x_s_train, y_s_train[target])\ny_s_hat = reg.predict(x_s_test)\ny_s_hat = pd.DataFrame(y_s_hat,columns=[target])\n\n#compute metrics\n\nmse = (metrics.mean_squared_error(y_pred=y_s_hat[target], y_true=y_s_test[target] ))\nr2_s = metrics.r2_score(y_pred=y_s_hat, y_true=y_s_test[target])\nfig, ax = plt.subplots(figsize=(12,6))\nsns.scatterplot(x=y_s_test[target],y=y_s_hat[target])\nax.set(xlabel = 'Actual y', ylabel=\"Predicted y\")\nplt.show()\nprint('The r-squared value is: {}, and MSE is: {}'.format(r2, mse))","f6919f9b":"kf = KFold(5,shuffle=True)\nreg_cv = LinearRegression()\nlas_cv = Lasso()\nkn_cv = KNeighborsRegressor(n_neighbors=30)\nreg_cv_model = cross_validate(reg_cv, X=x_s, y=y_s[target], cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nlas_cv_model = cross_validate(las_cv, X=x_s, y=y_s[target], cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nkn_cv_model = cross_validate(kn_cv, X=x_s, y=y_s[target], cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\n\nreg_cv_scores_s = cross_val_score(reg_cv, X=x_s, y=y_s[target], cv=kf)\nlas_cv_scores_s = cross_val_score(las_cv, X=x_s, y=y_s[target], cv=kf)\nkn_cv_scores_s = cross_val_score(kn_cv, X=x_s, y=y_s[target], cv=kf)\nprint('Linear Regression: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, reg_cv_scores_s.mean()), ('\\nLasso: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, las_cv_scores_s.mean())), ('\\nk-NN Regressor: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, kn_cv_scores_s.mean())))","3a099f0d":"print('The results are much better. We can more accurately predict {} by {} percent over our attempt to predict suicides for both genders.'.format(target, np.round((reg_cv_scores_s.mean()\/reg_cv_scores.mean())*100 - 100,2)))\n","cdd751f5":"Now let's take a closer look at the differences in the number of suicides between men and women.","2a3a8e98":"Now we can drop the sex and age columns since we've completed the mapping and added it to the data set.","fdc90623":"We saw some missing values in the first few rows (i.e. the NaNs). Let's find out how many missing values are in the data set. We'll first find how many missing values are in each column, then we'll calculate what proportion of the data points are missing.","9c4143ef":"Let's load the data into a Pandas dataframe.","c92b76cf":"If we want to perform further analysis, it's a good idea to map the ages and genders to values.","8f012a21":"So we can see that Mongolia, Switzerland, Denmark, San Marino, Cuba, and the Phillipines have mostly missing data for suicides, and Bermuda, the Cayman Islands, and Saint Kitts and Nevis have most of the population data missing. I'm not sure why this is, but for my porposes here, I'm OK with dropping entries missing values for now. There are methods for missing data imputation, but I've decided not going to do any imputation in this notebook.\n\nLet's go ahead and drop the missing value entries, this will make the data easier to work with.","736265c1":"Let's get a quick view of how the features of our dataset are correlated with each other.","d6c5f6a4":"<a id='predictions'><\/a>\n# Predictions\nLet's use linear regression to try to predict the number of suicides given the rest of the data. We'll first train one model for all countries and age groups.\n","8102c556":"Take a peek at the first few rows of data, and view some summary statistics to get a high-level understanding of what's going on in the data.","be3e8a87":"It seems that and female suicides are slightly positively coorelated, whereas age and male suicides are slightly negatively correlated. Interesting! ","e3f249b2":"We'll load a few libraries that we may need in this analysis. ","721ddd6a":"Looks good! Now that we've separated male and female suicides, let's see if they're correlated with each other.","9630b5a6":"<a id='transformations'><\/a>\n# Transforming the data","3c594de2":"<a id='visualizations'><\/a>\n# Visualizations\nNow that we have the data cleaned up a bit, let's use some visualizations to get a sense of what trends and patterns might exist.","5310af82":"# Exploring the WHO suicides data\n\nThis notebook employs a few simple techniques for exploring the WHO suicides dataset from Kaggle. \n### Table of Contents\n[Data preparation](#preparation)\n<br>\n[Visualizations](#visualizations)\n<br>\n[Transformations](#transformations)\n<br>\n[Predictions](#predictions)","ea46e0ba":"Hmm, the plot of predicted y vs actual y looks pretty scattered. The closer the alignment of points along the 45 degree line, would indicate a stronger fit. Let's use k-fold cross-validation to compare our Linear Regression model with other models such as Lasso and kNN.","8a46cbf3":"First, we'll split the data into training and test sets.","26dd3074":"First we'll set a target country to examine, then we'll plot the number of suicides per year for each age group, and adjust the shape of the data point by gender.","f2ee037e":"Now let's try to predict by gender only. ","a4064ed2":"Now we can train a linear regression model to predict the number of suicides. ","d7a12dad":"Like the Linear Rergession model, this doesn't look too good. The k-NN modle fit is the worst of the three! Let's see if we can make better predictions by constraining the model by country. We'll pick the USA as an example.","6e119ed9":"<a id='preparation'><\/a>\n# Data preparation","df7ecb24":"As we suspected, we see better performance when the model is restricted to a specific country.","fcc4abd2":"Let's perform 5-fold cross-validation to compare our country-specific Linear Regression model with the Lasso and a kNN regressor.","b1c41284":"Population and suicides_no are correlated, which makes intuitive sense. sex_id and suicides_no are correlated as men tend to commit more suicides than women. Let's now see if male suicides are correlated with female suicides.","dac85b1e":"Ok so about 5% of the suicides_no and 12% of population data are missing. Let's see how this breaks down by country."}}