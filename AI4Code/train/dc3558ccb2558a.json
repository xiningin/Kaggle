{"cell_type":{"99004430":"code","bcbae713":"code","a63e62c5":"code","20a1f10b":"code","ef27986d":"code","e81ee6ad":"code","8b80a6e3":"code","739a6bd8":"code","322308e0":"code","4fba45f1":"code","80ff4c6e":"code","a722c15d":"code","42a58827":"code","7a954bd9":"code","4e385c89":"code","89bfb049":"code","7b77763a":"code","d0629731":"code","bdd24128":"code","a31aa724":"code","c256935b":"code","507d4799":"code","93813654":"code","8f048385":"code","fde3b437":"code","6e53b5b1":"code","856412b7":"code","bcc79cf7":"code","b350ae21":"code","8ddac134":"code","51a9a4b1":"code","584bce5b":"code","9b5310b2":"code","5b7a385a":"code","78f7b20e":"code","4c0d337b":"code","1ea659bd":"code","32bf91b6":"code","416d68ec":"markdown","4431c636":"markdown","da89089e":"markdown","e723b290":"markdown","b4b04192":"markdown","4d2bf85d":"markdown","c194f854":"markdown","e511d3fd":"markdown","a2920367":"markdown","cfb0f930":"markdown","9248b439":"markdown","9573eace":"markdown","9380f1c9":"markdown"},"source":{"99004430":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bcbae713":"import matplotlib.pyplot as plt #for ploting \nimport seaborn as sns \nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline            ","a63e62c5":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","20a1f10b":"df_train.head(10)","ef27986d":"df_train.shape","e81ee6ad":"df_train.columns","8b80a6e3":"df_train.SalePrice.describe()","739a6bd8":"#HISTOGRAM\nsns.distplot(df_train.SalePrice)","322308e0":"#skewness\nprint(\"Skewness: %f\" % df_train.SalePrice.skew()) #It tells about the shifting of data toward the tail","4fba45f1":"#Kurtosis \nprint(\"Kurtosis: %f\" % df_train.SalePrice.kurtosis())","80ff4c6e":"#ScatterPlot grlivarea\/saleprice\ndata = pd.concat([df_train['SalePrice'], df_train['GrLivArea']], axis=1)\ndata.plot.scatter(x ='GrLivArea', y ='SalePrice', ylim=(0,800000) )","a722c15d":"#scatterplot b\/w totalBsmt\/saleprice\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000) )","42a58827":"#box plot overallqual\/saleprice\nvar = 'OverallQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8,6))\nfig = sns.boxplot(x=var, y='SalePrice', data=data)\nfig.axis(ymin=0, ymax=800000);","7a954bd9":"#box plot YearBuilt\/saleprice\nvar = 'YearBuilt'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16,8))\nfig = sns.boxplot(x=var, y='SalePrice', data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);   #Rotate 90 degree to x markers","4e385c89":"#correlation matrix\ncorrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=.8,square=True);\n","89bfb049":"k=10\ncols = corrmat.nlargest(k,'SalePrice')['SalePrice'].index\ncm= np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm,cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10},\n                yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","7b77763a":"sns.set()\ncols = ['SalePrice','OverallQual','GrLivArea','GarageCars','TotalBsmtSF',\n       'FullBath','YearBuilt']\nsns.pairplot(df_train[cols], size = 10)\nplt.show();","d0629731":"#missing data\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent*100], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","bdd24128":"#dealingwithmissingdata\ndf_train = df_train.drop((missing_data[missing_data['Total']>1]).index,1)\ndf_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n\n","a31aa724":"df_train.isnull().sum().max()\n\n","c256935b":"from scipy.stats import norm \nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats","507d4799":"#standardizing Data\nsaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of distribution:')\nprint(low_range)\nprint('\\nouter range(high) of distribution:')\nprint(high_range)\n\n    \n","93813654":"#bivariate analysis saleprice\/grlivarea\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'],df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","8f048385":"#deleting points\ndf_train.sort_values(by = 'GrLivArea', ascending=False)[:2]\ndf_train = df_train.drop(df_train[df_train['Id']== 1299].index)\ndf_train = df_train.drop(df_train[df_train['Id']== 524].index)","fde3b437":"#bivariate analysis saleprice\/TotalBsmtSF\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'],df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","6e53b5b1":"#histo and normalprobablity plot\nsns.distplot(df_train['SalePrice'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt);","856412b7":"#apply log transformation\ndf_train['SalePrice'] = np.log(df_train['SalePrice'])","bcc79cf7":"#transformed histo and normalprobablity plot\nsns.distplot(df_train['SalePrice'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt);","b350ae21":"#histo and normalprobablity plot on GrLivArea\nsns.distplot(df_train['GrLivArea'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt);","8ddac134":"#transformation \ndf_train['GrLivArea'] = np.log(df_train['GrLivArea'])","51a9a4b1":"#transformed histo and normalprobablity plot on GrLivArea\nsns.distplot(df_train['GrLivArea'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt);","584bce5b":"#histo and normalprobablity plot on TotalBsmtSF\nsns.distplot(df_train['TotalBsmtSF'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(df_train['TotalBsmtSF'], plot=plt);","9b5310b2":"#create column for new variable (one is enough because it's a binary categorical feature)\n#if area>0 it gets 1, for area==0 it gets 0\ndf_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\ndf_train['HasBsmt'] = 0 \ndf_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1","5b7a385a":"#transform data\ndf_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])","78f7b20e":"#histogram and normal probability plot\nsns.distplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","4c0d337b":"#scatter plot\nplt.scatter(df_train['GrLivArea'],df_train['SalePrice'])","1ea659bd":"#scatter plot\nplt.scatter(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], df_train[df_train['TotalBsmtSF']>0]\n            ['SalePrice']);","32bf91b6":"#convert categorical variable into dummy\ndf_train = pd.get_dummies(df_train)","416d68ec":"Relationship with categorical features","4431c636":"# Final Step for Target Based Cleaning","da89089e":"In Case of positive skewness log transformation works\n","e723b290":"Removing (TotalBsmtSF > 3000) is optional  and not to be worried about","b4b04192":"# **Filling Out Missing Data**","4d2bf85d":"Using Bivariate ","c194f854":"The above coorelation heatmap matrix is too dense to study ","e511d3fd":"1. It is often considered as if there is more than 15% of missing data then the feature should be deleted.\n2. If there is a feature with missing data that has weak correlation with Target can also be deleted.\n","a2920367":"# Lets solve the problem of outliers","cfb0f930":"as it can be observe that low range is close to zero but high range varies from 1 to 7","9248b439":"# Lets plot pairplot for features with high coorelation with SalePrice","9573eace":"Test for homoscedasticity is the dispersion of scatter plot ","9380f1c9":"The two outliers are the one with 7.\n"}}