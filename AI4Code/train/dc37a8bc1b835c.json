{"cell_type":{"14fc661f":"code","27d9daf5":"code","e053a44b":"code","26f7f7ea":"code","88b8d440":"code","c0b226af":"code","861deba0":"code","26244644":"code","a25928b0":"code","2d81b785":"code","ccc2c636":"code","2be2b04b":"code","59862c61":"code","b36507f8":"code","f8dfde3f":"code","0078f35c":"markdown","25e3d141":"markdown","b742172a":"markdown","c9c4943a":"markdown","98236658":"markdown","41c7ea14":"markdown","cca71155":"markdown","17a729a9":"markdown"},"source":{"14fc661f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.gofplots import qqplot\nfrom scipy.stats import shapiro\nfrom scipy.stats import normaltest\nimport warnings\nimport scipy.stats as st\nimport statsmodels as sm\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.axes\n\n\n\n","27d9daf5":"df=pd.read_csv('..\/input\/diabetes-diagnosis\/diabetesdiagnosis.csv', sep=',')\n","e053a44b":"def qqplotJona(datos):\n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):   \n        try:\n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n                print(headers[i])        \n                qqplot(df[headers[i]] , line='s')\n                plt.show()\n        except Exception:\n            pass\n            ","26f7f7ea":"qqplotJona(df)","88b8d440":"def shapiroJona(datos):\n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):    \n        print(headers[i])        \n        stat, p = shapiro(df[headers[i]].to_numpy())\n        print('Estadisticos=%.3f, p=%.3f' % (stat, p))            \n        print('Estadisticos=',stat)            \n        print('p=',p)            \n        alpha = 0.05\n        if p > alpha:\n           print('La muestra parece Gaussiana o Normal (no se rechaza la hip\u00f3tesis nula H0)')\n        else:\n           print('La muestra no parece Gaussiana o Normal(se rechaza la hip\u00f3tesis nula H0)')\n","c0b226af":"shapiroJona(df)","861deba0":"def dAgostinoJona(datos):\n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):    \n        print(headers[i])        \n        stat, p = normaltest(df[headers[i]].to_numpy())\n        print('Estadisticos=%.3f, p=%.3f' % (stat, p))            \n        print('Estadisticos=',stat)            \n        print('p=',p)            \n        alpha = 0.05\n        if p > alpha:\n           print('La muestra parece Gaussiana o Normal (no se rechaza la hip\u00f3tesis nula H0)')\n        else:\n           print('La muestra no parece Gaussiana o Normal(se rechaza la hip\u00f3tesis nula H0)')","26244644":"dAgostinoJona(df)","a25928b0":"def getBestDistributionJona(data):\n    dist_names = [\n        \"norm\",\"invgauss\",\"johnsonsu\",\"cauchy\",\"vonmises_line\",\"cauchy\",\"vonmises_line\",\"exponnorm\",\"hypsecant\"\n        # \"alpha\",\"anglit\",\"arcsine\",\"beta\",\"betaprime\",\"bradford\",\"burr\",\"cauchy\",\"chi\",\"chi2\",\"cosine\",\"dgamma\",\"dweibull\",\"erlang\",\"expon\",\"exponnorm\",\"exponweib\",\"exponpow\",\"f\",\"fatiguelife\",\"fisk\",\"foldcauchy\",\"foldnorm\",\"frechet_r\",\"frechet_l\",\"genlogistic\",\"genpareto\",\"gennorm\",\"genexpon\",\"genextreme\",\"gausshyper\",\"gamma\",\"gengamma\",\"genhalflogistic\",\"gilbrat\",\"gompertz\",\"gumbel_r\",\"gumbel_l\",\"halfcauchy\",\"halflogistic\",\"halfnorm\",\"halfgennorm\",\"hypsecant\",\"invgamma\",\"invgauss\",\"invweibull\",\"johnsonsb\",\"johnsonsu\",\"ksone\",\"kstwobign\",\"laplace\",\"levy\",\"levy_l\",\"levy_stable\",\"logistic\",\"loggamma\",\"loglaplace\",\"lognorm\",\"lomax\",\"maxwell\",\"mielke\",\"nakagami\",\"ncx2\",\"ncf\",\"nct\",\"norm\",\"pareto\",\"pearson3\",\"powerlaw\",\"powerlognorm\",\"powernorm\",\"rdist\",\"reciprocal\",\"rayleigh\",\"rice\",\"recipinvgauss\",\"semicircular\",\"t\",\"triang\",\"truncexpon\",\"truncnorm\",\"tukeylambda\",\"uniform\",\"vonmises\",\"vonmises_line\",\"wald\",\"weibull_min\",\"weibull_max\",\"wrapcauchy\"\n    ]\n    dist_results = []\n    params = {}\n    for dist_name in dist_names:\n      # Try to fit the distribution\n        try:\n            # Ignore warnings from data that can't be fit\n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n                dist = getattr(st, dist_name)\n                param = dist.fit(data)\n\n                params[dist_name] = param\n                # Applying the Kolmogorov-Smirnov test\n                D, p = st.kstest(data, dist_name, args=param)\n                print(\"p value for \"+dist_name+\" = \"+str(p))\n                dist_results.append((dist_name, p))\n        except Exception:\n            pass\n    # select the best fitted distribution\n    best_dist, best_p = (max(dist_results, key=lambda item: item[1]))\n    # store the name of the best fit and its p value\n\n    print(\"Best fitting distribution: \"+str(best_dist))\n    print(\"Best p value: \"+ str(best_p))\n    print(\"Parameters for the best fit: \"+ str(params[best_dist]))\n\n    return best_dist, best_p, params[best_dist]","2d81b785":"#getBestDistributionJona(df['Pregnancies']) ejemplo de uso\ndef KolmogorovSmirnov(datos):    \n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):    \n        print(headers[i]) \n        getBestDistributionJona(df[headers[i]])","ccc2c636":"KolmogorovSmirnov(df)","2be2b04b":"def best_fit_distribution(data, bins=200, ax=None):\n    \"\"\"Model data by finding best fit distribution to data\"\"\"\n    # Get histogram of original data\n    y, x = np.histogram(data, bins=bins, density=True)\n    x = (x + np.roll(x, -1))[:-1] \/ 2.0\n\n    # Distributions to check\n    DISTRIBUTIONS = [        \n        st.norm,st.invgauss,st.johnsonsu,st.cauchy,st.vonmises_line,st.cauchy,st.vonmises_line,st.exponnorm,st.hypsecant\n        #st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy\n    ]\n\n    # Best holders\n    best_distribution = st.norm\n    best_params = (0.0, 1.0)\n    best_sse = np.inf\n\n    # Estimate distribution parameters from data\n    for distribution in DISTRIBUTIONS:\n\n        # Try to fit the distribution\n        try:\n            # Ignore warnings from data that can't be fit\n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n\n                # fit dist to data\n                params = distribution.fit(data)\n\n                # Separate parts of parameters\n                arg = params[:-2]\n                loc = params[-2]\n                scale = params[-1]\n\n                # Calculate fitted PDF and error with fit in distribution\n                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n                sse = np.sum(np.power(y - pdf, 2.0))\n\n                # if axis pass in add to plot\n                try:\n                    if ax:\n                        pd.Series(pdf, x).plot(ax=ax)\n                    end\n                except Exception:\n                    pass\n\n                # identify if this distribution is better\n                if best_sse > sse > 0:\n                    best_distribution = distribution\n                    best_params = params\n                    best_sse = sse\n\n        except Exception:\n            pass\n\n    return (best_distribution.name, best_params)","59862c61":"def make_pdf(dist, params, size=10000):\n    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n\n    # Separate parts of parameters\n    arg = params[:-2]\n    loc = params[-2]\n    scale = params[-1]\n\n    # Get sane start and end points of distribution\n    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n\n    # Build PDF and turn into pandas Series\n    x = np.linspace(start, end, size)\n    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n    pdf = pd.Series(y, x)\n\n    return pdf","b36507f8":"def ajustarDistribucionSSE(datos):\n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):   \n        try: \n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n                titulo=headers[i]\n                print(titulo)\n                matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n                matplotlib.style.use('ggplot')\n                data=df[headers[i]]\n                plt.figure(figsize=(12,8))\n                ax = data.plot(kind='hist', bins=50, density=True, alpha=0.5, color='#aabbcc')\n                dataYLim = ax.get_ylim()\n                # Find best fit distribution\n                best_fit_name, best_fit_params = best_fit_distribution(data, 200, ax)\n                best_dist = getattr(st, best_fit_name)\n                # Update plots\n                ax.set_ylim(dataYLim)\n                ax.set_title(titulo)\n                ax.set_xlabel(titulo)\n                ax.set_ylabel('Frequency')\n                # Make PDF with best params\n                pdf = make_pdf(best_dist, best_fit_params)\n                # Display\n                plt.figure(figsize=(12,8))\n                ax = pdf.plot(lw=2, label='PDF', legend=True)\n                data.plot(kind='hist', bins=50, density=True, alpha=0.5, label='Data', legend=True, ax=ax)\n                param_names = (best_dist.shapes + ', loc, scale').split(', ') if best_dist.shapes else ['loc', 'scale']\n                param_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_names, best_fit_params)])\n                dist_str = '{}({})'.format(best_fit_name, param_str)\n                ax.set_title(titulo+' \\n' + dist_str)\n                ax.set_xlabel(titulo)\n                ax.set_ylabel('Frequency')\n        except Exception:\n            pass","f8dfde3f":"ajustarDistribucionSSE(df)","0078f35c":"AJUSTE DE DISTRIBUCI\u00d3N USANDO SUMA DE CUADRADOS DEL ERROR","25e3d141":"# LINKOGRAF\u00cdA\n[https:\/\/hub.mybinder.turing.ac.uk\/user\/relopezbriega-blog-8r7y7cqu\/notebooks\/content\/notebooks\/DistStatsPy.ipynb](https:\/\/hub.mybinder.turing.ac.uk\/user\/relopezbriega-blog-8r7y7cqu\/notebooks\/content\/notebooks\/DistStatsPy.ipynb)\n[https:\/\/machinelearningparatodos.com\/como-saber-si-una-variable-sigue-una-distribucion-normal-en-python\/](https:\/\/machinelearningparatodos.com\/como-saber-si-una-variable-sigue-una-distribucion-normal-en-python\/)\n[https:\/\/www.cienciadedatos.net\/documentos\/pystats01-ajuste-distribuciones-python.html](https:\/\/www.cienciadedatos.net\/documentos\/pystats01-ajuste-distribuciones-python.html)\n[https:\/\/stackoverflow.com\/questions\/37487830\/how-to-find-probability-distribution-and-parameters-for-real-data-python-3](https:\/\/stackoverflow.com\/questions\/37487830\/how-to-find-probability-distribution-and-parameters-for-real-data-python-3)\n[https:\/\/stackoverflow.com\/questions\/6620471\/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python](https:\/\/stackoverflow.com\/questions\/6620471\/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python)\n[https:\/\/stackoverflow.com\/questions\/6615489\/fitting-distributions-goodness-of-fit-p-value-is-it-possible-to-do-this-with\/16651524#16651524](https:\/\/stackoverflow.com\/questions\/6615489\/fitting-distributions-goodness-of-fit-p-value-is-it-possible-to-do-this-with\/16651524#16651524)\n[https:\/\/glowingpython.blogspot.com\/2012\/07\/distribution-fitting-with-scipy.html](https:\/\/glowingpython.blogspot.com\/2012\/07\/distribution-fitting-with-scipy.html)\n[https:\/\/docs.scipy.org\/doc\/scipy\/reference\/stats.html](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/stats.html)\n[https:\/\/www.statsmodels.org\/devel\/datasets\/generated\/elnino.html#el-nino-sea-surface-temperatures](https:\/\/www.statsmodels.org\/devel\/datasets\/generated\/elnino.html#el-nino-sea-surface-temperatures)\n","b742172a":"AJUSTE DE DISTRIBUCI\u00d3N A TRAV\u00c9S DE Kolmogorov-Smirnov","c9c4943a":"DETECTANDO NORMALIDAD APLICANDO SHAPIRO-WILK","98236658":"LEYENDO DATASET","41c7ea14":"DETECTANDO NORMALIDAD APLICANDO CUANTILES TE\u00d3RICOS","cca71155":"DETECTANDO NORMALIDAD APLICANDO K^2 de D\u2019Agostino","17a729a9":"# DETECTANDO NORMALIDAD Y AJUSTE DE DISTRIBUCION\nIMPORTANDO LIBRERIAS \n\n<p>Donde esta implementado:<\/p>\n<p>Kaggle:<\/p>\n<p><a href=\"https:\/\/www.kaggle.com\/jofrantoba\/detectando-normalidad-y-ajuste-de-distribucion\" target=\"_blank\">https:\/\/www.kaggle.com\/jofrantoba\/detectando-normalidad-y-ajuste-de-distribucion<\/a><\/p>\n<p>Deepnote:<\/p>\n<p><a href=\"https:\/\/deepnote.com\/project\/DETECTANDO-NORMALIDAD-Y-AJUSTANDO-DATOS-A-DISTRIBUCIONES-DE-PROBABILIDAD-kEWYcPyIQjqqReTFEd1xmQ\/%2Fdetectando-normalidad-y-ajuste-de-distribucion.ipynb\" target=\"_blank\">https:\/\/deepnote.com\/project\/DETECTANDO-NORMALIDAD-Y-AJUSTANDO-DATOS-A-DISTRIBUCIONES-DE-PROBABILIDAD-kEWYcPyIQjqqReTFEd1xmQ\/%2Fdetectando-normalidad-y-ajuste-de-distribucion.ipynb<\/a><\/p>\n<p>Google Colab:<\/p>\n<p><a href=\"\" target=\"_blank\">https:\/\/colab.research.google.com\/drive\/1x-9mXChFDdQOCyQlW8RgA3gICmzEFAMZ?usp=sharing<\/a><\/p>"}}