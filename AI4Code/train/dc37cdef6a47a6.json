{"cell_type":{"26f1c98e":"code","7aaacea9":"code","2a418807":"code","670dcf18":"code","34dddf5f":"code","23f04b73":"code","cd2a006d":"code","6a8b53d1":"code","4dbc2e10":"code","823ca305":"code","5d7447e9":"code","7a34348b":"code","815d78a4":"code","1b38be2b":"code","1ce2f30f":"code","d47eac37":"code","e78ff676":"code","1cd1d3f8":"code","35375072":"code","039114db":"code","6d6037ed":"code","2bcec433":"code","c55712b2":"code","6931784e":"code","e7d01fb3":"code","59abeb09":"code","df625ed6":"code","2cd5ea47":"code","2a100c70":"code","0fdf8ad2":"code","c901070f":"code","b02be7b5":"code","51947faa":"code","55467688":"code","2cd6f2b0":"code","9fcdd796":"code","72b9fb91":"code","68fd27a9":"code","1af5d1e2":"code","cc31c9a2":"code","f2b8a8c2":"code","126a8aa3":"code","d3c38722":"code","a7ffe746":"code","0e1b6cbb":"code","13fe5e4a":"markdown","ebb38512":"markdown","675568a9":"markdown","6f0f4152":"markdown","5fc9249d":"markdown","a06b3a54":"markdown","cdafca25":"markdown","da493112":"markdown","df904af6":"markdown","5f2e5fe0":"markdown","4677f0f6":"markdown","870da800":"markdown","600b7ffa":"markdown","3b1f34d3":"markdown","f9500964":"markdown","de87d9cb":"markdown","923199b7":"markdown","4a019f74":"markdown","cd546afc":"markdown"},"source":{"26f1c98e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7aaacea9":"df = pd.read_csv('\/kaggle\/input\/air-passengers\/AirPassengers.csv')\ndf.head()","2a418807":"df['Month'] = pd.to_datetime(df['Month'], format = '%Y-%m')","670dcf18":"df.dtypes","34dddf5f":"df = df.set_index('Month')\ndf.head()","23f04b73":"import warnings\nwarnings.filterwarnings('ignore')","cd2a006d":"\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (12, 6))\nplt.plot(df)\nplt.xlabel ('Date')\nplt.ylabel ('No. of Passengers')\nplt.title('Air Passengers Data', fontsize = 18)","6a8b53d1":"rolmean = df['#Passengers'].rolling(12).mean()\nrolsd = df['#Passengers'].rolling(12).std()\nprint(rolmean, rolsd)","4dbc2e10":"plt.figure(figsize = (12, 6))\norign = plt.plot(df, color='blue', label = 'original data')\nmean = plt.plot(rolmean, color='red', label = 'Rolling mean data')\nstd = plt.plot(rolsd, color='black', label = 'Rolling std data')\nplt.legend()\nplt.xlabel ('Date')\nplt.ylabel ('No. of Passengers')\nplt.title('Rolling mean & STD data', fontsize = 18)","823ca305":"# Dickey-Fuller Test\nfrom statsmodels.tsa.stattools import adfuller\nprint('Results of Dickey-Fuller Test: ')\ndftest = adfuller(df['#Passengers'], autolag='AIC' )\ndftest\ndfoutput = pd.Series(dftest[0:4], index = ['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nprint(dfoutput)\nfor key, values in dftest[4].items():\n    print(f'critical values ({key}) : {values}')\n#     print(f'')\n#     dfoutput['critical values(%s)'%key] = values \n\n# print(dfoutput)","5d7447e9":"df_log = np.log(df)\ndf_log.head()\nplt.figure(figsize = (12, 6))\nplt.plot(df_log)","7a34348b":"rolmean_log = df_log['#Passengers'].rolling(12).mean()\nrolstd_log = df_log['#Passengers'].rolling(12).std()\nplt.figure(figsize = (12, 6))\nplt.plot(df_log, color='blue', label = 'Rolling log Original')\nplt.plot(rolmean_log, color='red', label = 'Rolling log mean')\nplt.legend()","815d78a4":"dif_log = df_log['#Passengers'] - rolmean_log\ndif_log.head()\n\n# dif_log.rename(column='pas')\ndif_log.dropna(inplace = True)\n# dif_log\n# rolmean_log \ndif_log.head()","1b38be2b":"def test_stationary(timeseries):\n    # rolling stats\n    rolmean1 = timeseries.rolling(12).mean()\n    rolstd1 = timeseries.rolling(12).std()\n    # Rolling stats plot\n    plt.figure(figsize = (12, 6))\n    plt.plot(timeseries, color='blue', label = 'Rolling log Original')\n    plt.plot(rolmean1, color='red', label = 'Rolling log mean')\n    plt.plot(rolstd1, color='black', label = 'Rolling log std')\n    plt.legend()\n    #Dickey-Fuller Test\n    print('Results of Dickey-Fuller Test: ')\n    dftest = adfuller(timeseries, autolag='AIC' )\n    dftest\n    dfoutput = pd.Series(dftest[0:4], index = ['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    dfoutput\n    for key, values in dftest[4].items():\n        dfoutput['critical values(%s)'%key] = values \n    print(dfoutput)\n    ","1ce2f30f":"test_stationary(dif_log)","d47eac37":"dif_log_sft = df_log['#Passengers'] - df_log['#Passengers'].shift(1)\ndif_log_sft.head()\nplt.figure(figsize = (12, 6))\nplt.plot(dif_log_sft)","e78ff676":"dif_log_sft.dropna(inplace = True)\ndif_log_sft.head()\ntest_stationary(dif_log_sft)","1cd1d3f8":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecompose = seasonal_decompose(df_log)\ntrend = decompose.trend\nseasonal = decompose.seasonal\nresidual = decompose.resid\n\nplt.figure(figsize = (12, 6))\nplt.subplot(411)\nplt.plot(df_log, label = 'Origional')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label = 'Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal, label = 'Seasonal')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label = 'Residual')\nplt.legend(loc='best')\n","35375072":"df_log_decompose = residual['#Passengers']\ndf_log_decompose.dropna(inplace = True) \ndf_log_decompose.head(10)\ntest_stationary(df_log_decompose)","039114db":"from statsmodels.tsa.ar_model import AR\nmodel = AR(dif_log_sft)\nmodel_ar = model.fit()","6d6037ed":"plt.figure(figsize = (12, 6))\nplt.plot(dif_log_sft)\nplt.plot(model_ar.fittedvalues, color='red' )\nplt.title('RSS : %.4f'% np.nansum((model_ar.fittedvalues - dif_log_sft)**2))","2bcec433":"predict_ARIMA_dif = pd.Series(model_ar.fittedvalues, copy = True)\npredict_ARIMA_dif","c55712b2":"# Cumulative Sum to reverse differencing:\npredict_ARIMA_dif_cumsum = predict_ARIMA_dif.cumsum() \npredict_ARIMA_dif_cumsum ","6931784e":"# Adding 1st month value which was previously removed while differencing:\npredict_ARIMA_log = pd.Series(df_log['#Passengers'].iloc[0], index = df_log.index)\npredict_ARIMA_log = predict_ARIMA_log.add(predict_ARIMA_dif_cumsum, fill_value=0)\npredict_ARIMA_log.head()","e7d01fb3":"# Taking Exponent to reverse Log Transform:\npredict_ARIMA = np.exp(predict_ARIMA_log)\npredict_ARIMA.head()","59abeb09":"plt.figure(figsize = (12, 6))\nplt.plot(df)\nplt.plot(predict_ARIMA)\nplt.title('RMSE: %.4f'% np.sqrt(np.nansum((predict_ARIMA-df['#Passengers'])**2)\/len(df['#Passengers'])))","df625ed6":"from statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nplt.figure(figsize = (12, 6))\nplot_acf(dif_log_sft, ax=plt.gca(), lags = 20) # q \nplt.show()\nplt.figure(figsize = (12, 6))\nplot_pacf(dif_log_sft, ax=plt.gca(), lags = 20) # p \nplt.show()","2cd5ea47":"from statsmodels.tsa.arima_model import ARIMA\nmodel = ARIMA(df_log, order=(2, 1, 2))  \nresults_ARIMA = model.fit(disp=1)  ","2a100c70":"\nplt.figure(figsize = (12, 6))\nplt.plot(dif_log_sft)\nplt.plot(results_ARIMA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-dif_log_sft)**2))\n","0fdf8ad2":"predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\npredictions_ARIMA_diff.head()","c901070f":"# Cumulative Sum to reverse differencing:\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_diff_cumsum.head()","b02be7b5":"# Adding 1st month value which was previously removed while differencing:\npredictions_ARIMA_log = pd.Series(df_log['#Passengers'].iloc[0], index=df_log.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\npredictions_ARIMA_log.head()","51947faa":"# Taking Exponent to reverse Log Transform:\npredict_ARIMA = np.exp(predictions_ARIMA_log)\npredict_ARIMA.head()","55467688":"plt.plot(df)\nplt.plot(predict_ARIMA)\nplt.title('RMSE: %.4f'% np.sqrt(sum((predict_ARIMA-df['#Passengers'])**2)\/len(df['#Passengers'])))","2cd6f2b0":"results_ARIMA.plot_predict(1, 264)","9fcdd796":"x = results_ARIMA.forecast(steps = 120)\nnp.exp(x[0])","72b9fb91":"#divide into train and test set\ntrain = df[:int(0.75*(len(df)))]\ntest = df[int(0.75*(len(df))):]\n\nplt.plot(train)\nplt.plot(test, color='red')","68fd27a9":"from sklearn.metrics import mean_squared_error\n\nmodel = ARIMA(train, order = (1,1,1))\nmodel_fit = model.fit(disp = 1)","1af5d1e2":"start = test.index.min()\nend = test.index.max()\n\npredict = model_fit.predict(start = start, end = end)\n","cc31c9a2":"mse = mean_squared_error(df[start : end], predict)\nrmse = mse ** 0.5 #(sqrt of mse)\nprint (f'MSE : {mse} , RMSE : {rmse}')\n","f2b8a8c2":"predict_ARIMA_dif = pd.Series(predict, copy = True)\npredict_ARIMA_dif.head() ","126a8aa3":"predict_ARIMA_dif_cumsum = predict_ARIMA_dif.cumsum()\npredict_ARIMA_dif_cumsum.head() ","d3c38722":"predict_ARIMA_log = pd.Series(test['#Passengers'].iloc[0], index = test.index)\npredict_ARIMA_log = predict_ARIMA_log.add(predict_ARIMA_dif_cumsum, fill_value=0)\npredict_ARIMA_log.head()","a7ffe746":"df_sft = df['#Passengers'] - df['#Passengers'].shift()","0e1b6cbb":"plt.plot(df)\nplt.plot(predict_ARIMA_log, color='red')\nplt.title('RMSE: %.4f'% np.sqrt(np.nansum((predict_ARIMA_log-df_sft)**2)\/len(df_sft)))","13fe5e4a":"Set Month as index","ebb38512":"# ARIMA MODEL","675568a9":"Another example ARIMA Model with Train and Test data on this.","6f0f4152":"Creating function to re-use for dickey-Fuller test and plots","5fc9249d":"if we want only values:","a06b3a54":"# Rolling Mean and SD\n","cdafca25":"Fell free to comment with suggestions or any clarifications for further active discussions. \nMy e-mailid is mcommahesh@gmail.com\n","da493112":"AR Model","df904af6":"converting Month to date type","5f2e5fe0":"deleting NaN values to avoid issues","4677f0f6":"# Reversing the transformations\n# Fitted or predicted values:","870da800":"# Dickey-Fuller Test","600b7ffa":"Predictions: we have 144 rows data and predicting another 10 years (10*12 = 120). total 144+120 = 264.\npridiction plots:\n","3b1f34d3":"# Reversing the transformations\n# Fitted or predicted values:\n","f9500964":"Decomposition:\nIn this approach, both trend and seasonality are modeled separately and the remaining part of the series is returned.","de87d9cb":"Plot with Original Data","923199b7":"Try order values ( ex: order=(2, 1, 2) or (1, 1, 1) ) changes until we get RSS less value.","4a019f74":"P-Value and Test Statistic values are high, need to go for log values.\nMaking Time Series Stationary","cd546afc":"#ACF and PACF for p and q values. (before ARIMA)"}}