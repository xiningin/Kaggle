{"cell_type":{"f063ab96":"code","24d3e09c":"code","29cc5f51":"code","ba3ab619":"code","0ee137fd":"code","448e3669":"code","9b6549ea":"code","537ba6d1":"code","d2dc66ee":"code","ba0ac6cc":"code","2da77267":"code","292a64ce":"code","fc89f6c2":"code","b8410059":"code","a63ca8c8":"code","80c7b3f4":"code","e858c821":"code","6d0d5ba4":"code","138796c5":"code","cbb1267e":"code","12427326":"code","068ce021":"code","41cf10a5":"code","c29a9650":"code","da98d9ec":"code","1031ff7f":"code","b961633a":"code","ba6a2b80":"code","3a1eb676":"code","d8df25ac":"code","01248cc6":"code","17feff22":"code","d7eb167a":"code","2734e2e2":"code","e718bb9c":"code","10cd9803":"code","a1541af9":"code","e5decd76":"code","c5b39516":"code","ca88f5d0":"code","5720dae8":"code","097af87a":"markdown","57c1abcd":"markdown","a29838c7":"markdown","4c76b027":"markdown","48cae32b":"markdown","74421a1d":"markdown","9d77efdd":"markdown","4ed39007":"markdown","e7f1cfda":"markdown","4b8fd37e":"markdown","2a412ed0":"markdown","467946d1":"markdown","1070d8f9":"markdown","c7ef2751":"markdown","4eeee8cf":"markdown","17da8ff1":"markdown","ef606eff":"markdown","ab8003d7":"markdown","284c762c":"markdown","1491299f":"markdown","c76feabb":"markdown","45f9899c":"markdown","13d78536":"markdown","3a7b4644":"markdown","8596a91a":"markdown","55ae862f":"markdown","4f09ddb9":"markdown","cdcd8a65":"markdown","b358f0d5":"markdown","94b8218c":"markdown","2ce52f5e":"markdown","0844320e":"markdown","d76d2464":"markdown","72eb18a9":"markdown","491547f7":"markdown","022a136f":"markdown","41404c8d":"markdown","3db74e3d":"markdown","3750d0a1":"markdown","57b18352":"markdown","fbcfa3ea":"markdown","74e1a6a0":"markdown","a260f390":"markdown","4cf18455":"markdown","01a41d43":"markdown"},"source":{"f063ab96":"%%html\n<style>\n  table {margin-left: 0 !important;}\n<\/style>","24d3e09c":"!pip install tensorflow-datasets","29cc5f51":"import os\nimport random\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","ba3ab619":"seed = 1729\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)","0ee137fd":"x_train, y_train = tfds.as_numpy(\n    tfds.load('mnist', \n              batch_size = -1,\n              split = 'train',\n              as_supervised = True))\n\nx_test, y_test = tfds.as_numpy(\n    tfds.load('mnist', \n              batch_size = -1,\n              split = 'test',\n              as_supervised = True))","448e3669":"plt.rcParams.update({'font.size': 16})\n\nfig = plt.figure(figsize = (16, 12))\ncolumns = 8\nrows    = 5\n\nfor i in range(1, columns * rows + 1):\n    rnd = np.random.randint(0, len(x_train))\n    img = np.reshape(x_train[rnd], (28, 28))\n    fig.add_subplot(rows, columns, i)\n    plt.title(y_train[rnd])\n    plt.axis('off')\n    plt.imshow(img, cmap = 'gray')\n\nplt.show()","9b6549ea":"y_train = np.expand_dims(y_train, axis = 1)\ny_test  = np.expand_dims(y_test, axis = 1)\n\ny_train = to_categorical(y_train, num_classes = 10)\ny_test  = to_categorical(y_test, num_classes = 10)\n\nx_train = x_train \/ 255\nx_test  = x_test \/ 255","537ba6d1":"i = Input(x_train.shape[1:])\n\na = Flatten()(i)\n\na = Dense(512, activation = 'relu')(a)\na = Dropout(0.3)(a)\n\na = Dense(10, activation = 'softmax')(a)\n\nmodel_NNS = Model(i ,a)","d2dc66ee":"model_NNS.compile(optimizer = 'rmsprop',\n                  loss = \"categorical_crossentropy\",\n                  metrics = [\"accuracy\"])\n\nmodel_NNS.summary()","ba0ac6cc":"i = Input(x_train.shape[1:])\n\nb = Flatten()(i)\n\nb = Dense(512, activation = 'relu')(b)\nb = Dropout(0.3)(b)\n\nb = Dense(256, activation = 'relu')(b)\nb = Dropout(0.2)(b)\n\nb = Dense(128, activation = 'relu')(b)\nb = Dropout(0.2)(b)\n\nb = Dense(64, activation = 'relu')(b)\nb = Dropout(0.2)(b)\n\nb = Dense(10, activation = 'softmax')(b)\n\nmodel_NNC = Model(i ,b)","2da77267":"model_NNC.compile(optimizer = 'rmsprop',\n                  loss = \"categorical_crossentropy\",\n                  metrics = [\"accuracy\"])\n\nmodel_NNC.summary()","292a64ce":"i = Input(x_train.shape[1:])\n\nc = Conv2D(32, (3,3), activation ='relu', padding = 'same')(i)\nc = BatchNormalization()(c)\nc = Conv2D(32, (3,3), activation ='relu', padding = 'same')(c)\nc = BatchNormalization()(c)\nc = MaxPooling2D(2,2)(c)\n\nc = Conv2D(64, (3,3), activation ='relu', padding = 'same')(c)\nc = BatchNormalization()(c)\nc = Conv2D(64, (3,3), activation ='relu', padding = 'same')(c)\nc = BatchNormalization()(c)\nc = MaxPooling2D(2,2)(c)\n\nc = Conv2D(128, (3,3), activation ='relu', padding = 'same')(c)\nc = BatchNormalization()(c)\nc = Conv2D(128, (3,3), activation ='relu', padding = 'same')(c)\nc = BatchNormalization()(c)\nc = MaxPooling2D(2,2)(c)\n\nc = Conv2D(256, (3,3), activation ='relu', padding = 'same')(c)\nc = BatchNormalization()(c)\nc = Conv2D(256, (3,3), activation ='relu', padding = 'same')(c)\nc = BatchNormalization()(c)\nc = MaxPooling2D(2,2)(c)\n\nc = Flatten()(c)\n\nc = Dense(512, activation = 'relu')(c)\nc = Dropout(0.3)(c)\n\nc = Dense(256, activation = 'relu')(c)\nc = Dropout(0.2)(c)\n\nc = Dense(128, activation = 'relu')(c)\nc = Dropout(0.2)(c)\n\nc = Dense(64, activation = 'relu')(c)\nc = Dropout(0.2)(c)\n\nc = Dense(10, activation = 'softmax')(c)\n\nmodel_CNN = Model(i, c)","fc89f6c2":"model_CNN.compile(optimizer = 'rmsprop',\n                  loss = \"categorical_crossentropy\",\n                  metrics = [\"accuracy\"])\n\nmodel_CNN.summary()","b8410059":"batch_size = 2048\n\ntrain_gen = ImageDataGenerator(rotation_range = 10,\n                               horizontal_flip = False,\n                               vertical_flip = False,\n                               width_shift_range = 0.1,\n                               height_shift_range = 0.1,\n                               rescale = 1.,\n                               zoom_range = 0.2,\n                               fill_mode = 'nearest',\n                               cval = 0)\n\ntrain_generator_NNS = train_gen.flow(x_train, y_train, batch_size)\n# utilizado para o treinamento da rede sem a normaliza\u00e7\u00e3o dos dados\ntrain_generator_NNS_N = train_gen.flow(x_train * 255, y_train, batch_size)\n# ----------------------------------------------------------------\ntrain_generator_NNC = train_gen.flow(x_train, y_train, batch_size)\ntrain_generator_CNN = train_gen.flow(x_train, y_train, batch_size)\n\nsteps_per_epoch = x_train.shape[0] \/\/ batch_size\n\ncheckpoint_NNS = ModelCheckpoint('model_NNS.h5', \n                                 monitor = 'val_loss', \n                                 verbose = 0, \n                                 save_best_only = True, \n                                 mode = 'auto')\n\n# checkpoint utilizado para o treinamento da rede sem a normaliza\u00e7\u00e3o dos dados\ncheckpoint_NNS_N = ModelCheckpoint('model_NNS_N.h5', \n                                   monitor = 'val_loss', \n                                   verbose = 0, \n                                   save_best_only = True, \n                                   mode = 'auto')\n\ncheckpoint_NNC = ModelCheckpoint('model_NNC.h5', \n                                 monitor = 'val_loss', \n                                 verbose = 0, \n                                 save_best_only = True, \n                                 mode = 'auto')\n\ncheckpoint_CNN = ModelCheckpoint('model_CNN.h5', \n                                 monitor = 'val_loss', \n                                 verbose = 0, \n                                 save_best_only = True, \n                                 mode = 'auto')","a63ca8c8":"epochs = 50","80c7b3f4":"%%time\nhistory_NNS = model_NNS.fit(train_generator_NNS, \n                            validation_data = (x_test, y_test), \n                            steps_per_epoch = steps_per_epoch, \n                            epochs = epochs,\n                            callbacks = [checkpoint_NNS])","e858c821":"%%time\nhistory_NNS_N = model_NNS.fit(train_generator_NNS_N, \n                              validation_data = (x_test * 255, y_test), \n                              steps_per_epoch = steps_per_epoch, \n                              epochs = epochs,\n                              callbacks = [checkpoint_NNS_N])","6d0d5ba4":"%%time\nhistory_NNC = model_NNC.fit(train_generator_NNC, \n                            validation_data = (x_test, y_test), \n                            steps_per_epoch = steps_per_epoch, \n                            epochs = epochs,\n                            callbacks = [checkpoint_NNC])","138796c5":"%%time\nhistory_CNN = model_CNN.fit(train_generator_CNN, \n                            validation_data = (x_test, y_test), \n                            steps_per_epoch = steps_per_epoch, \n                            epochs = epochs,\n                            callbacks = [checkpoint_CNN])","cbb1267e":"model_NNS   = tf.keras.models.load_model('model_NNS.h5')\nmodel_NNS_N = tf.keras.models.load_model('model_NNS_N.h5')\nmodel_NNC   = tf.keras.models.load_model('model_NNC.h5')\nmodel_CNN   = tf.keras.models.load_model('model_CNN.h5')","12427326":"def plot_accuracy_hist(model_history, fig_tittle):\n\n    plt.rcParams.update({'font.size': 14})\n\n    fig = plt.figure(figsize = (16, 4))\n    columns = 2\n    rows = 1\n\n    fig.suptitle(fig_tittle, fontsize = 20, y = 1.08)\n    fig.add_subplot(rows, columns, 1)\n\n    plt.title('Accuracy')\n    plt.ylim(0, 1.1)\n    \n    plt.plot(model_history.history['accuracy'], \n             color='green', \n             label = 'Train Accuracy')\n\n    plt.plot(model_history.history['val_accuracy'], \n             color='red', \n             label = 'Test Accuracy', \n             linestyle='dashed')\n\n    plt.legend()\n\n    fig.add_subplot(rows, columns, 2)\n\n    plt.title('Loss')\n    plt.plot(model_history.history['loss'], \n             color='green', \n             label = 'Train Loss')\n\n    plt.plot(model_history.history['val_loss'], \n             color='red', \n             label = 'Test Loss', \n             linestyle='dashed')\n\n    plt.legend()\n\n    plt.show()\n\nplot_accuracy_hist(history_NNS, 'Neural Network - Simple - Normalized')\nplot_accuracy_hist(history_NNS_N, 'Neural Network - Simple - Not Normalized')\nplot_accuracy_hist(history_NNC, 'Neural Network - Complex')\nplot_accuracy_hist(history_CNN, 'Convolutional Neural Network')","068ce021":"def pred(model, x_test):\n    pred_prob = model.predict(x_test)\n    pred = np.argmax(pred_prob, axis = 1)\n    return pred\n\nprint('Classification Report - Neural Network - Simple - Normalized')\nprint('------------------------------------------------------------')\nprint(classification_report(np.argmax(y_test, axis = 1), \n                            pred(model_NNS, x_test)))\nprint(\"Accuracy: %.4f\" % accuracy_score(np.argmax(y_test, axis = 1), \n                                        pred(model_NNS, x_test)))\nprint('------------------------------------------------------------\\n')\n\nprint('------------------------------------------------------------')\nprint('Classification Report - Neural Network - Simple - Not Normalized')\nprint(classification_report(np.argmax(y_test, axis = 1), \n                            pred(model_NNS_N, x_test * 255)))\nprint(\"Accuracy: %.4f\" % accuracy_score(np.argmax(y_test, axis = 1), \n                                        pred(model_NNS_N, x_test * 255)))\nprint('------------------------------------------------------------\\n')\n\nprint('------------------------------------------------------------')\nprint('Classification Report - Neural Network - Complex')\nprint(classification_report(np.argmax(y_test, axis = 1), \n                            pred(model_NNC, x_test)))\nprint(\"Accuracy: %.4f\" % accuracy_score(np.argmax(y_test, axis = 1), \n                                        pred(model_NNC, x_test)))\nprint('------------------------------------------------------------\\n')\n\nprint('------------------------------------------------------------')\nprint('\\nClassification Report - Convolutional Neural Network')\nprint(classification_report(np.argmax(y_test, axis = 1), \n                            pred(model_CNN, x_test)))\nprint(\"Accuracy: %.4f\" % accuracy_score(np.argmax(y_test, axis = 1), \n                                        pred(model_CNN, x_test)))\nprint('------------------------------------------------------------\\n')","41cf10a5":"plt.rcParams.update({'font.size': 16})\n\ndef plot_confusion_mtx(model, x_test, plot_tittle):\n    pred_prob = model.predict(x_test)\n    pred = np.argmax(pred_prob, axis = 1)\n\n    CM = confusion_matrix(np.argmax(y_test, axis = 1), pred)\n\n    plot_confusion_matrix(conf_mat = CM, figsize = (16, 8))\n    plt.title(plot_tittle)\n    plt.xticks(range(10), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    plt.yticks(range(10), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    plt.show()\n\nplot_confusion_mtx(model_NNS, x_test, 'Neural Network - Simple - Normalized')\nplot_confusion_mtx(model_NNS_N, x_test * 255, 'Neural Network - Simple - Not Normalized')\nplot_confusion_mtx(model_NNC, x_test, 'Neural Network - Complex')\nplot_confusion_mtx(model_CNN, x_test, 'Convolutional Neural Network')","c29a9650":"y_true = np.argmax(y_test, axis = 1)\npred_prob = model_CNN.predict(x_test)\ny_pred = np.argmax(pred_prob, axis = 1)\nerrors = (y_pred - y_true != 0)\nhits = (y_pred - y_true == 0)\n\ny_test_erros  = y_pred[errors]\ny_true_errors = y_true[errors]\nx_test_errors = x_test[errors]\n\ny_test_hits  = y_pred[hits]\ny_true_hits = y_true[hits]\nx_test_hits = x_test[hits]\n\nprint('Convolutional Neural Network')\nprint('quantidade de erros: \\t' + str(len(y_test_erros)))\nprint('quantidade de hits: \\t' + str(len(y_test_hits)))","da98d9ec":"plt.rcParams.update({'font.size': 12})\n\nfig = plt.figure(figsize = (16, 12))\ncolumns = 8\nrows = 5\n\nfor i in range(1, columns * rows + 1):\n    img = np.reshape(x_test_errors[i], (28, 28))\n    fig.add_subplot(rows, columns, i)\n    plt.title('predicted: ' + str(y_test_erros[i]) + \n              '\\ntrue label: ' + str(y_true_errors[i]))\n    plt.axis('off')\n    plt.imshow(img, cmap = 'gray')\n\nplt.show()","1031ff7f":"plt.rcParams.update({'font.size': 12})\n\nfig = plt.figure(figsize = (16, 12))\ncolumns = 8\nrows = 5\n\nfor i in range(1, columns * rows + 1):\n    rnd = np.random.randint(0, len(x_test_hits))\n    img = np.reshape(x_test_hits[rnd], (28, 28))\n    fig.add_subplot(rows, columns, i)\n    plt.title('predicted: ' + str(y_test_hits[rnd]) + \n              '\\ntrue label: ' + str(y_true_hits[rnd]))\n    plt.axis('off')\n    plt.imshow(img, cmap = 'gray')\n\nplt.show()","b961633a":"from sklearn.ensemble import RandomForestClassifier","ba6a2b80":"x_train, y_train = tfds.as_numpy(\n    tfds.load('mnist', \n              batch_size = -1,\n              split = 'train',\n              as_supervised = True))\n\nx_test, y_test = tfds.as_numpy(\n    tfds.load('mnist', \n              batch_size = -1,\n              split = 'test',\n              as_supervised = True))","3a1eb676":"x_train = x_train.reshape([x_train.shape[0], -1]).astype('float32')\nx_test  = x_test.reshape([x_test.shape[0], -1]).astype('float32')\n\nx_train.shape","d8df25ac":"%%time\nRF = RandomForestClassifier(n_estimators = 100,\n                            criterion = 'gini',\n                            max_depth = 256,\n                            min_samples_split = 15,\n                            min_samples_leaf = 10,\n                            n_jobs = -1,             # Paralelizado entre todos os CPUs\n                            random_state = seed)     # Nosso n\u00famero m\u00e1gico de escolha\n\nRF.fit(x_train, y_train)","01248cc6":"pred = RF.predict(x_test)\n\nprint('------------------------------------------------------------')\nprint('Classification Report -Random Forest')\nprint(classification_report(y_test, pred))\nprint(\"Accuracy: %.4f\" % accuracy_score(y_test, pred))\nprint('------------------------------------------------------------\\n')","17feff22":"plt.rcParams.update({'font.size': 16})\n\ndef plot_confusion_mtx(model, x_test, plot_tittle):\n    pred= model.predict(x_test)\n\n    CM = confusion_matrix(y_test, pred)\n\n    plot_confusion_matrix(conf_mat = CM, figsize = (16, 8))\n    plt.title(plot_tittle)\n    plt.xticks(range(10), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    plt.yticks(range(10), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    plt.show()\n\nplot_confusion_mtx(RF, x_test, 'Random Forest - Not Optimized')","d7eb167a":"y_pred = RF.predict(x_test)\nerrors = (y_pred - y_test != 0)\nhits = (y_pred - y_test == 0)\n\ny_test_erros  = y_pred[errors]\ny_true_errors = y_test[errors]\nx_test_errors = x_test[errors]\n\ny_test_hits  = y_pred[hits]\ny_true_hits = y_test[hits]\nx_test_hits = x_test[hits]\n\nprint('Random Forest - Not Optimized')\nprint('quantidade de erros: \\t' + str(len(y_test_erros)))\nprint('quantidade de hits: \\t' + str(len(y_test_hits)))","2734e2e2":"from hyperopt import hp, fmin, tpe, STATUS_OK, Trials","e718bb9c":"hyper_space = {'n_estimators': hp.quniform('n_estimators', 25, 500, 5),\n               'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n               'max_depth': hp.quniform('max_depth', 1, 100, 1),\n               'min_samples_split': hp.quniform('min_samples_split', 5, 50, 1),\n               'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 20, 1)}","10cd9803":"def hyper_RF(hyper_space):\n    \n    global best_score\n    \n    RF = RandomForestClassifier(n_estimators = int(hyper_space['n_estimators']),\n                                criterion = hyper_space['criterion'],\n                                max_depth = int(hyper_space['max_depth']),\n                                min_samples_split = int(hyper_space['min_samples_split']),\n                                min_samples_leaf = int(hyper_space['min_samples_leaf']),\n                                n_jobs = -1,\n                                random_state = seed)\n\n    RF.fit(x_train, y_train)\n\n    pred = RF.predict(x_test)\n    acc = 1 - accuracy_score(y_test, pred)\n    \n    if (acc < best_score):\n        best_score = acc\n    \n    return {'loss': acc, 'status': STATUS_OK }","a1541af9":"%%time\ntrials = Trials()\nneval = 50\nbest_score = 0\n\nbest_hyper = fmin(fn = hyper_RF,\n                  space = hyper_space,\n                  algo = tpe.suggest,\n                  max_evals = neval,\n                  trials = trials,\n                  rstate = np.random.RandomState(seed))\n\nbest_hyper","e5decd76":"OPT_RF = RandomForestClassifier(n_estimators = int(best_hyper['n_estimators']),\n                                criterion = [\"gini\", \"entropy\"][best_hyper['criterion']],\n                                max_depth = int(best_hyper['max_depth']),\n                                min_samples_split = int(best_hyper['min_samples_split']),\n                                min_samples_leaf = int(best_hyper['min_samples_leaf']),\n                                n_jobs = -1, \n                                random_state = seed)\n\nOPT_RF.fit(x_train, y_train)","c5b39516":"pred = OPT_RF.predict(x_test)\n\nprint('------------------------------------------------------------')\nprint('Classification Report - Random Forest - Optimized')\nprint(classification_report(y_test, pred))\nprint(\"Accuracy: %.4f\" % accuracy_score(y_test, pred))\nprint('------------------------------------------------------------\\n')","ca88f5d0":"plot_confusion_mtx(OPT_RF, x_test, 'Random Forest - Optimized')","5720dae8":"y_pred = OPT_RF.predict(x_test)\nerrors = (y_pred - y_test != 0)\nhits = (y_pred - y_test == 0)\n\ny_test_erros  = y_pred[errors]\ny_true_errors = y_test[errors]\nx_test_errors = x_test[errors]\n\ny_test_hits  = y_pred[hits]\ny_true_hits = y_test[hits]\nx_test_hits = x_test[hits]\n\nprint('Random Forest - Optimized')\nprint('quantidade de erros: \\t' + str(len(y_test_erros)))\nprint('quantidade de hits: \\t' + str(len(y_test_hits)))","097af87a":"Conforme solicitado pelo enunciado vamos treinar uma rede adicional sem a normaliza\u00e7\u00e3o dos dados para avaliar o efeito.","57c1abcd":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.ap\u00f3s 50 \u00e9pocas de treino. <span style=\"color:red\"><strong>Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste.<\/strong><\/span> Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <\/br>","a29838c7":"- **Quest\u00e3o 2:** <br>\n<span style=\"color:red\"><strong>Resolva o mesmo problema da Quest\u00e3o 1 utilizando o algoritmo Random Forests.<\/strong><\/span> Tentem trabalhar a hiperparametriza\u00e7\u00e3o para aumento do desempenho. Compare o seu melhor resultado com o resultado obtido na Quest\u00e3o 1 e comente.<\/br>","4c76b027":"Finalmente vamos analisar a performance do modelo visualizando algumas imagens com erro de classifica\u00e7\u00e3o e algumas imagens com acerto de classifica\u00e7\u00e3o do melhor modelo que \u00e9 o convolucional.","48cae32b":"# An\u00e1lise Preditiva Avan\u00e7ada\n\n\n## Trabalho Individual\n- **Curso:** FGV MBA - Business Analytics e Big Data\n- **Disciplina:** An\u00e1lise Preditiva Avan\u00e7ada\n- **Professor:** Hitoshi Nagano e Gustavo Mirapalheta\n- **Tarefa:** Trabalho Subistitutivo de Prova\n- **Kaggle:** Este notebook pode ser acessado no [Kaggle](https:\/\/www.kaggle.com\/rodrigonca\/an-lise-preditiva-avan-ada-trabalho-individual)\n\n|Github|Kaggle|Nome|Matricula|E-mail|\n|---|---|---|---|---|\n|<a href=\"https:\/\/github.com\/RodriGonca\"><img src=\"https:\/\/avatars2.githubusercontent.com\/u\/50252438?s=460&v=4\" title=\"RodriGonca\" width=\"40\" height=\"40\"><\/a>|<a href=\"https:\/\/www.kaggle.com\/rodrigonca\"><img src=\"https:\/\/storage.googleapis.com\/kaggle-avatars\/images\/3511253-kg.png\" title=\"RodriGonca\" width=\"40\" height=\"40\"><\/a>|Rodrigo Goncalves|A57566093|[rodrigo.goncalves@me.com](rodrigo.goncalves@me.com)|","74421a1d":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.ap\u00f3s 50 \u00e9pocas de treino. <span style=\"color:red\"><strong>Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste.<\/strong><\/span> Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <\/br>","9d77efdd":"Definimos nosso modelo em uma fun\u00e7\u00e3o que utiliza os valores presentes em nosso espa\u00e7o de busca.","4ed39007":"# Enunciado\n\n- **Instru\u00e7\u00f5es** <br>\nTurma: MSP 11924-TBABD-T1\nDisciplina: An\u00e1lise Preditiva Avan\u00e7ada (Professores Mirapalheta e Hitoshi)<\/br>\n\n- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. Qual o n\u00famero de camadas que voc\u00ea consideraria ideal?<\/br>\n\n- **Quest\u00e3o 2:** <br>\nResolva o mesmo problema da Quest\u00e3o 1 utilizando o algoritmo Random Forests. Tentem trabalhar a hiperparametriza\u00e7\u00e3o para aumento do desempenho. Compare o seu melhor resultado com o resultado obtido na Quest\u00e3o 1 e comente.<\/br>\n\n- **Anti-pl\u00e1gio** <br>\nAnti-pl\u00e1gio ativado<\/br>\n\n- **Data Final** <br>\n8 de junho de 2020 23:59<\/br>","e7f1cfda":"O c\u00f3digo abaixo faz o download e carrega os tensores de treino e teste do dataset mnist.","4b8fd37e":"Come\u00e7amos por instalar o pacote com os datasets padr\u00f5es do tensorflow e importando as libraries necess\u00e1rias.","2a412ed0":"Vamos iniciar com uma rede neural de apenas `1` ***hiden layer*** com `512` neur\u00f4nios, fun\u00e7\u00e3o de ativa\u00e7\u00e3o ***relu***, seguida de um ***dropout*** de `30%` para regulariza\u00e7\u00e3o da rede e com um ***output layer*** com `10` neur\u00f4nios, com a fun\u00e7\u00e3o de ativa\u00e7\u00e3o ***softmax***, representando a probabilidade de cada um dos 10 d\u00edgitos poss\u00edveis `[0, 1, 2, 3, 4, 5, 6, 7, ,8, 9]`","467946d1":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. <span style=\"color:red\"><strong>Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.<\/strong><\/span> ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. <span style=\"color:red\"><strong>Qual o n\u00famero de camadas que voc\u00ea consideraria ideal?<\/strong><\/span> <\/br>","1070d8f9":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, <span style=\"color:red\"><strong>defina e elabore uma rede neural sequencial<\/strong><\/span>, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <\/br>","c7ef2751":"- **Quest\u00e3o 2:** <br>\nResolva o mesmo problema da Quest\u00e3o 1 utilizando o algoritmo Random Forests. <span style=\"color:red\"><strong>Tentem trabalhar a hiperparametriza\u00e7\u00e3o para aumento do desempenho.<\/strong><\/span> Compare o seu melhor resultado com o resultado obtido na Quest\u00e3o 1 e comente.<\/br>","4eeee8cf":"Para finalizar vamos avaliar a performance do modelo com hiperpar\u00e2metros otimizados.","17da8ff1":"Com o modelo treinado faremos a predi\u00e7\u00e3o dos d\u00edgitos e verificamos a acur\u00e1cia do modelo de **Random Forest**","ef606eff":"Para o treinamento destas redes neurais \u00e9 necess\u00e1rio fazer:\n- a transforma\u00e7\u00e3o do shape dos tensores de labels de `(60000,)` para `(60000, 1)`\n- a transforma\u00e7\u00e3o dos lables para dummies utilizando a fun\u00e7\u00e3o `to_categorical()`\n- e tamb\u00e9m \u00e9 aconselh\u00e1vel a normaliza\u00e7\u00e3o dos dados entre `0` e `1`.","ab8003d7":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. <span style=\"color:red\"><strong>Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.<\/strong><\/span> ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <\/br>","284c762c":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, <span style=\"color:red\"><strong>apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede.<\/strong><\/span> Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <\/br>","1491299f":"Tamb\u00e9m criamos uma rede convolucional para verificar se existe melhora na acur\u00e1cia de classifica\u00e7\u00e3o das imagens.","c76feabb":"Para permitir a reprodutibilidade dos resultados inicializamos os seeds dos m\u00f3dulos rand\u00f4micos do Python, Numpy e Tensorflow.\n\n> *I remember once going to see him when he was ill at Putney. I had ridden in taxi cab number 1729 and remarked that the number seemed to me rather a dull one, and that I hoped it was not an unfavourable omen. \"No,\" he replied, \"it is a very interesting number; it is the smallest number expressible as the sum of two cubes in two different ways.*\n\n[G. H. Hardy](https:\/\/en.wikipedia.org\/wiki\/G._H._Hardy) quoting [Srinivasa Ramanujan](https:\/\/en.wikipedia.org\/wiki\/Srinivasa_Ramanujan)","45f9899c":"Visualizando algumas imagens do dataset de treino.","13d78536":"Iniciamos por importar o classificador `RandomForestClassifier` da library Scikit Learn.","3a7b4644":"Iniciamos por definir um espa\u00e7o de busca de hiperpar\u00e2metros.","8596a91a":"Dos `4` modelos desenvolvidos verificamos que que o modelo convolucional \u00e9 o que apresenta maior acur\u00e1cia e maior velocidade de converg\u00eancia dos par\u00e2metros.\n\nAdicionalmente verificamos que o modelo de rede neural simples treinado sem a normaliza\u00e7\u00e3o dos dados apresenta uma curva de aprendizado mais lenta que o modelo simples com a normaliza\u00e7\u00e3o, como neste dataset os valores se encontram entre `0` e `255` a quest\u00e3o da normaliza\u00e7\u00e3o n\u00e3o \u00e9 significante, por\u00e9m em datasets onde o intervalo entre os valores \u00e9 grande a n\u00e3o normaliza\u00e7\u00e3o pode causar problemas para a converg\u00eancia dos par\u00e2metros.","55ae862f":"Vamos carregar novamente dos datasets de treino e teste do mnist para garantir que estamos trabalhando sem nenhuma transforma\u00e7\u00e3o indesejada inserida pelos passos anteriores.","4f09ddb9":"Abaixo alguns erros de classifica\u00e7\u00e3o do melhor modelo desenvolvido.","cdcd8a65":"Abaixo alguns acertos de classifica\u00e7\u00e3o do melhor modelo desenvolvido.","b358f0d5":"O input do tensor \u00e9 de `(28, 28, 1)` que s\u00e3o transformados em um vetor de `(784)` neur\u00f4nios, seguidos de um vetor de `(512)` e finalmente um vetor de `(10)`","94b8218c":"Para isso vamos utilizar a library `hyperopt` para otimzar os hiperpar\u00e2metros do modelo de forma autom\u00e1tica.","2ce52f5e":"Para o treinamento da **Random Forest** faremos o reshape dos tensores para que cada pixel represente uma vari\u00e1vel do modelo.","0844320e":"Conforme os resultados obtidos neste exerc\u00edcio o melhor modelo \u00e9 a rede neural convolucional com aproximadamente **`99.5%`** de acur\u00e1cia contra cerca de **`97%`** da nossa **Random Forest** otimizada.\n\nAdicionalmente para encontrar a nossa melhor parametriza\u00e7\u00e3o de **Random Forest** foi necess\u00e1rio **`1 Hr e 57 Min`** contra **`14 Min`** para a **Rede Neural Convolucional**","d76d2464":"- **Quest\u00e3o 1:** <br>\n<span style=\"color:red\"><strong>Tomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras<\/strong><\/span>, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <\/br>","72eb18a9":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados. <span style=\"color:red\"><strong>ap\u00f3s 50 \u00e9pocas de treino.<\/strong><\/span> Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <\/br>","491547f7":"# Quest\u00e3o 2","022a136f":"# Refer\u00eancias\n\n- [Advanced-Predictive-Analysis-CNN-Implementation](https:\/\/www.kaggle.com\/rodrigonca\/advanced-predictive-analysis-cnn-implementation) por [Daniel Campos](https:\/\/www.kaggle.com\/danielferrazcampos), [Leandro Daniel](https:\/\/www.kaggle.com\/leandrodaniel), [Rodrigo Goncalves](https:\/\/www.kaggle.com\/rodrigonca) e [Ygor Lima](https:\/\/www.kaggle.com\/ygorlima1)\n\n- [Hyperopt Documentation](http:\/\/hyperopt.github.io\/hyperopt\/)\n\n- [Hyperparameter Optimization in Python - Part 2: Hyperopt](https:\/\/towardsdatascience.com\/hyperparameter-optimization-in-python-part-2-hyperopt-5f661db91324) por [Jakub Czakon](https:\/\/towardsdatascience.com\/@jakub.czakon)\n\n- [Scikit-Learn - Metrics and scoring: quantifying the quality of predictions](https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html)\n\n- [Scikit Learn - RandomForestClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html)\n\n- [Uma introdu\u00e7\u00e3o as redes neurais convolucionais utilizando o Keras](https:\/\/medium.com\/data-hackers\/uma-introdu%C3%A7%C3%A3o-as-redes-neurais-convolucionais-utilizando-o-keras-41ee8dcc033e), por [Alan Melo Clappis](https:\/\/medium.com\/@clappis)\n\n- [Tensorflow Datasets](https:\/\/www.tensorflow.org\/datasets\/overview)\n\n- [Tensorflow 2.0 API Documentation](https:\/\/www.tensorflow.org\/api_docs)","41404c8d":"# Quest\u00e3o 1","3db74e3d":"Iniciamos o treinamento do modelo de **Random Forest** com alguns hiperpar\u00e2metros iniciais:\n\n|Par\u00e2metro|Fun\u00e7\u00e3o|Valor|\n|---|---|---|\n|`n_estimators`|N\u00famero de arvores|`100`|\n|`criterion`|Crit\u00e9rio de avalia\u00e7\u00e3o da qualidade da separa\u00e7\u00e3o de um n\u00f3|`gini`|\n|`max_depth`|Profundidade m\u00e1xima da arvore|`256`|\n|`min_samples_split`|O n\u00famero m\u00ednimo de observa\u00e7\u00f5es para a divis\u00e3o de um n\u00f3|`15`|\n|`min_samples_leaf`|N\u00famero m\u00ednimo de observa\u00e7\u00f5es de um n\u00f3|`10`|\n","3750d0a1":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre. Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados. ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. <span style=\"color:red\"><strong>Qual o n\u00famero de camadas que voc\u00ea consideraria ideal?<\/strong><\/span> <\/br>","57b18352":"Iniciamos o objeto `Trials` que ir\u00e1 armazenar o resultdado de cada itera\u00e7\u00e3o (total de 50 itera\u00e7\u00f5es `neval = 50`) do processo de otimiza\u00e7\u00e3o realizado pela fun\u00e7\u00e3o `fmin`.","fbcfa3ea":"# Desenvolvimento","74e1a6a0":"- **Quest\u00e3o 2:** <br>\nResolva o mesmo problema da Quest\u00e3o 1 utilizando o algoritmo Random Forests.Tentem trabalhar a hiperparametriza\u00e7\u00e3o para aumento do desempenho.  <span style=\"color:red\"><strong>Compare o seu melhor resultado com o resultado obtido na Quest\u00e3o 1 e comente.<\/strong><\/span><\/br>","a260f390":"Adicionamos em uma segunda rede com mais `3` ***hiden layers***, com `(256)` neur\u00f4nios, seguido de `(128)` neur\u00f4nios, seguido de `(64)` neur\u00f4nios e finalmente `(10)` neur\u00f4nios.","4cf18455":"- **Quest\u00e3o 1:** <br>\nTomando por base o conjunto de dados MNIST, padr\u00e3o do pacote Keras, defina e elabore uma rede neural sequencial, apresentando os formatos dos tensores de entrada e sa\u00edda, bem como os tensores intermedi\u00e1rios na rede. <span style=\"color:red\"><strong>Treine e teste o modelo de rede neural sequencial desenvolvido, de forma que ele consiga atingir uma precis\u00e3o de pelo menos 97% no teste, no reconhecimento das imagens de n\u00fameros escritos \u00e0 m\u00e3o livre.<\/strong><\/span> Compare o desempenho da rede neural no treino utilizando dados normalizados e n\u00e3o normalizados.ap\u00f3s 50 \u00e9pocas de treino. Aumente o n\u00famero de camadas internas da rede neural e determine se isto melhora ou n\u00e3o a qualidade dos resultados no teste. Qual o n\u00famero de camadas que voc\u00ea consideraria ideal? <\/br>","01a41d43":"Finalmente realizamos o treinamento de uma **Random Forest** com os hiperpar\u00e2metros \u00f3timos encontrados em nosso espa\u00e7o de busca. "}}