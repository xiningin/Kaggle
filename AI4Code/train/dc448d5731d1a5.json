{"cell_type":{"af5bf37d":"code","7fc56bc8":"code","50503282":"code","1cc049d3":"code","821be93f":"code","aa7b1858":"code","009b5210":"code","cc5c7e97":"code","ad36255e":"code","2e980742":"code","dbadea91":"code","66342146":"code","808e18ec":"code","013e31a8":"code","e47c9e6e":"code","71bd7802":"code","66044f40":"code","5a9ee86e":"code","6bd622f0":"code","597123e7":"code","7e08a00a":"code","4863037e":"code","08a3f327":"code","7d8e6850":"code","4ce066f9":"code","24173956":"code","95eda663":"code","87366c6b":"code","65fb0be6":"code","9f86d325":"code","e4688d76":"code","a6c4d3ac":"code","3ed336ff":"code","03c7bbee":"code","61a2813b":"code","77d2851a":"code","9dca16b2":"code","64fb31a3":"code","9f09aa46":"code","4ee57760":"code","b4d65bd5":"code","7c456f03":"code","bcb7f2c8":"code","669e8bdc":"code","c21a4b64":"code","8777c99d":"code","e3d3abed":"code","396e1ac8":"code","fe1f2bf1":"code","2581598e":"code","842b1180":"code","0cfdcad1":"code","45ae82f7":"code","a5a479af":"code","8908f511":"markdown","e148ecfe":"markdown","16eae0c9":"markdown","74328679":"markdown","86107ae5":"markdown","39699ce5":"markdown","ca12e4d3":"markdown","0871bf63":"markdown","9a773229":"markdown","2fc9cea4":"markdown","ab5e6776":"markdown","eb6772db":"markdown","1278094d":"markdown","01f6593a":"markdown","cea1634f":"markdown","c3ed0991":"markdown","5748afb7":"markdown","20c60fda":"markdown","a5b814d2":"markdown","f41514bb":"markdown","0fbe78af":"markdown","d195ffeb":"markdown","6fbb3464":"markdown","72653b63":"markdown","cbee9f8b":"markdown","2204d6d1":"markdown","aca34bc6":"markdown","f1c5ae35":"markdown","c2a768c0":"markdown","0ef3d7ab":"markdown","65a1c9ac":"markdown","b0c1b2c3":"markdown","27956ff8":"markdown","6abe350c":"markdown","41850a23":"markdown"},"source":{"af5bf37d":"import pandas as pd\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.cm as cm\n# full documentation: http:\/\/www.statsmodels.org\/dev\/_modules\/statsmodels\/stats\/outliers_influence.html#variance_inflation_factor\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\nimport seaborn as sb\nsb.set()\n","7fc56bc8":"def nan_values(raw_data, typ):\n    for i in raw_data.columns:\n        if str(raw_data[i].dtypes) == str(typ):\n             for j in range(len(raw_data[i].unique())):\n                if str(raw_data[i].unique()[j]) == '':\n                    print(i)\n                    \n#unique columns count and values function\ndef unique_columns(raw_data, typ):\n    s = 0\n    for i in raw_data.columns:\n        if str(raw_data[i].dtypes) == str(typ):\n            if s==0:\n                print('<Unique variables of', typ, 'features>')\n                print('#\\t   Column\\t       Count\\t     variables')\n                print('-\\t  -------\\t      ------\\t    ----------\\n')\n            s+=1 \n            print(s,'\\t', i,' \\t\\t', len(raw_data[i].unique()),' \\t', raw_data[i].unique())\n\n#Identifies null columns\ndef null_columns(raw_data):\n    print('<No of null rows in each column>\\n', 'Columns\\t No\\t Type\\n', '--------\\t ----    -----')\n    for i in raw_data.columns:\n        if raw_data[i].isnull().sum() != 0:\n           print(i, '  \\t', raw_data[i].isnull().sum(), '\\t', raw_data[i].dtype)\n    print('\\nTotal rows:',len(raw_data))\n        \ndef columns_type(raw_data, typ):\n    columns = []\n    s = 0\n    for i in raw_data.columns:\n        if str(raw_data[i].dtypes) == str(typ):\n            if s==0:\n                print('<', typ, 'columns>')\n                print('#\\t   Column\\t')\n                print('-\\t  -------\\t')\n            s+=1 \n            print(s,'\\t', i)\n            columns.append(i)\n            \ndef unique_col_comparison(data1, data2,  typ):\n    s = 0\n    for i in data1.columns:\n        if str(data1[i].dtypes) == str(typ):\n            if s==0:\n                print('<Unique variables of', typ, 'features>')\n                print('#\\t   Column\\t       Count Train\\t    Count Test')\n                print('-\\t  -------\\t      ---------\\t\\t    ---------\\n')\n            s+=1\n            if len(data1[i].unique()) != len(data2[i].unique()):\n                print(s,'\\t', i,' \\t\\t', len(data1[i].unique()),' \\t\\t\\t', len(data2[i].unique()))\n\ndef scaleMinMax(data):\n    for col in num_col + ord_col:\n        data[col] = (data[col] - data[col].min()) \/ (data[col].max() - data[col].min())\n\n# learn all regressors, write accuracy\nall_rmse_train = {}\n\n# there we will store accuracies\nall_acc_train = {}\n\n\n\n\ndef models_fit(x_train, y_train, x_test):\n    all_regr_models = [\n    LinearRegression(),\n    Ridge(), \n    RidgeCV(),\n    LassoCV(max_iter=100000),\n    ElasticNetCV()]\n    for model in all_regr_models:\n    \n        # get the regressor name \n        model_name = model.__class__.__name__ \n        print(\"\u2666 \", model_name)\n    \n    # train model\n        model.fit(x_train, y_train)\n    \n    # calculate rmse on train set\n        y_train_pred = model.predict(x_train)\n        mse_train = mean_squared_error(y_train, y_train_pred)\n        rmse_train = math.sqrt(mse_train)\n        print(\"- rmse_train =\", round(rmse_train,7))\n    \n    # calculate model accuracy on train set\n        model_acc_train = explained_variance_score(y_train, y_train_pred)\n        print(\"- model_acc_train =\", round(model_acc_train,7))\n    \n    # save its rmse on train set\n        all_rmse_train[model_name] = rmse_train\n        all_acc_train[model_name] = model_acc_train\n    \n    # predict data on test set (result variable for competition)\n        y_test_pred_log1p = model.predict(x_test)\n        y_test_pred = np.expm1(y_test_pred_log1p)","50503282":"train_data, test_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv'), pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","1cc049d3":"train_data.head(5)","821be93f":"##Converting Test data (float columns) to Int64, similar to Train Data\nfor i in test_data.columns:\n    if test_data[i].dtype != train_data[i].dtype:\n        print(i, test_data[i].dtype, train_data[i].dtype)\n        test_data[i] = test_data[i].fillna(0)\n        test_data[i] = test_data[i].astype(int)","aa7b1858":"def con_cat(df):\n    df['MSSubClass'] = df['MSSubClass'].apply(str)\n    df['OverallCond'] = df['OverallCond'].astype(str)\n    df['OverallQual'] = df['OverallQual'].astype(str)\ncon_cat(train_data)\ncon_cat(test_data)","009b5210":"print('<Rows and Columns in Train and Test data (rows, columns)>\\n', 'Train Data:', train_data.shape, '\\n Test Data:', test_data.shape)","cc5c7e97":"view = train_data.iloc[:,[0,3,4, 19, 20, 77, 80]]\nview.head(10).sort_values(by ='SalePrice', ascending=False)\\\n.style.format({\"Id\":\"{:}\",\"SalePrice\":\"${:,.0f}\",\n               \"LotFrontage\":\"{:,.0f}\", \"MasVnrArea\":\"{:,.0f}\", \"GarageYrBlt\":\"{:,.0f}\"})\\\n.hide_index()\\\n.bar(subset = ['YearRemodAdd'], color='lightgreen')\\\n.bar(subset = ['LotFrontage'], color='lightgreen')\\\n.bar(subset = ['LotArea'], color='lightgreen')\\\n.bar(subset = ['YearBuilt'], color='lightgreen')\\\n.bar(subset = ['YrSold'], color ='lightgreen')","ad36255e":"sb.set_style(\"whitegrid\")\nfig = plt.figure(constrained_layout=True, figsize =(30,8))\ngrid = gridspec.GridSpec(ncols=6, nrows=4, figure=fig)\n\n\n# --------- Boxplot plot Vertical ---------\nax1 = fig.add_subplot(grid[:, 0:2])\nax1.set_title('SalePrice Segmented by SaleCondition')\nax1.annotate('Outlier', xy = (0.1, 600000), xytext=(0.7, 666666),arrowprops=dict(facecolor='black', shrink=0))\nsb.swarmplot(y='SalePrice', x='SaleCondition', data=train_data,size = 2,ax=ax1)\n\n\n# ----- Education Distribution ---------\nax2 = fig.add_subplot(grid[:, 2:4])\nax2.set_title('Zoning Classification')\nnames_= list(train_data['MSZoning'].value_counts().index)\nsize_= list(train_data['MSZoning'].value_counts().values)\nlabels = [f'{name}: {values}' for name,values in zip(names_,size_)]\n\n#-->Creating circle \nmy_circle = plt.Circle( (0,0), 0.7, color='white')\n\n#-->customizing Wedges\nplt.pie(size_, labels= labels , wedgeprops = {'linewidth' : 12,'edgecolor':'white'})\nax2= plt.gcf()\nax2.gca().add_artist(my_circle);","2e980742":"nan_p = []\ncolumns = train_data.columns\nfor i in columns:\n    prcnt = len(train_data[i][train_data[i].isna() == True]) \/ len(train_data[i])*100\n    nan_p.append(prcnt)\nNan_values = pd.DataFrame({'Features' : columns, 'NaN_Prcnt': nan_p}).sort_values(by = 'NaN_Prcnt', ascending = False)\nNan_values = Nan_values[Nan_values.NaN_Prcnt > 1]\n \nplt.figure(figsize=(10,7))\nplt.title('Percentage of NaN values in Categorical Features', size = 20)\nplt.xlabel(\"Features with Highest NaN values\")\nsb.barplot(x = Nan_values.NaN_Prcnt, y = Nan_values.Features, orient = 'h', palette = 'rainbow')\nplt.show()\nprint('We can remove features with NaN values that are more than 10%.')","dbadea91":"null_columns(train_data)\nprint(\"\\nMost of these are object features and having a null values means that they may have a classified value 'nan' to show that feature isn't present in that catogery. For example, if one home doesn't have a garage all features related to it will have a nan value. Alhough, there may be an error as BsmtQual, BsmtCond & BsmtFinType1 are 37 null values but BsmtExposure and BsmtFinType2 are 38.\\n\\nWe need to analyse the basement values to indentify that one variable.\")","66342146":"#Indentifying false basement values\ns = 0\nprint('<Shows null values - False if not-null>\\n')\nprint('Count\\t #\\t BsmtQual\\t BsmtExposure\\t BsmtFinType1\\t BsmtFinType2\\t BsmtCond')\nfor i in range(len(train_data)):\n    if train_data['BsmtExposure'].isnull()[i] or train_data['BsmtFinType2'].isnull()[i]== True:\n        if train_data['BsmtQual'].isnull()[i]== False:\n            s+=1\n            print(s,'\\t', i,'\\t', train_data['BsmtQual'].isnull()[i],'\\t\\t',\n                  train_data['BsmtExposure'].isnull()[i], '\\t\\t', train_data['BsmtFinType1'].isnull()[i],\n               '\\t\\t', train_data['BsmtFinType2'].isnull()[i],'\\t\\t', train_data['BsmtCond'].isnull()[i])\nprint('\\nAs it is evident from the index value of 332 and 948, that there is an inconsistency as the whole row should be null or not-null, meaning that if the data shows no basement so other values related to basement should be no basement too.')","808e18ec":"tdata = train_data.copy()","013e31a8":"tdata = tdata.drop([332, 948], axis = 0).reset_index(drop = True)\ntdata = tdata.drop(['PoolQC', 'MiscFeature'], axis=1)\nprint('After removing Index row 332 and 948, Rows left in dataframe are:', tdata.shape[0])","e47c9e6e":"print('<Shows electrical null values>\\n')\nprint('#\\t Electrical')\nfor i in range(len(tdata)):    \n    if tdata['Electrical'].isnull()[i] == True:\n        print(i, '\\t', tdata['Electrical'].isnull()[i])","71bd7802":"tdata = tdata.drop([1377], axis = 0).reset_index(drop = True)\nprint('After removing Index row 1377, Rows left in dataframe are:', tdata.shape[0])","66044f40":"tdata.info()","5a9ee86e":"print('Numerical Features Distribution')\nfig, axes = plt.subplots(15, 2, figsize=(20, 60), sharey=False)\nfig.subplots_adjust(top=0.9)\nfig.tight_layout(pad=1.0)\n#fig.suptitle('Numerical Features Distribution of Training Dataset', size=25)\ns, c, cs = 0, 0, 0\nfor i in tdata.columns:\n    if tdata[i].dtype == 'int64':\n        s+=1\n        if s > 1 and c < 15:\n            sb.histplot(tdata[i], ax=axes[c, cs])\n            cs+=1\n            if cs > 1:\n                c+=1; cs=0","6bd622f0":"print('Numerical Features Distribution of Testing Dataset')\nfig, axes = plt.subplots(10, 3, figsize=(20, 60), sharey=False)\nfig.subplots_adjust(top=0.9)\nfig.tight_layout(pad=1.0)\n#fig.suptitle('Numerical Features Distribution', size=25)\ns, c, cs =0, 0, 0\nfor i in test_data.columns:\n    if test_data[i].dtype == 'int64':\n        s+=1\n        if s > 1 and c < 10:\n            sb.histplot(test_data[i], ax=axes[c, cs])\n            cs+=1\n            if cs > 2:\n                c+=1; cs=0","597123e7":"log_price = np.log(tdata['SalePrice'])\nt1data = tdata.copy()\n# Then we add it to our data frame\nt1data['log_price'] = log_price","7e08a00a":"t2data = t1data.copy()\nt2data = t2data.drop(['Alley','Fence', 'FireplaceQu','LotFrontage','GarageYrBlt',\n 'GarageCond', 'GarageType', 'GarageQual', 'GarageFinish', 'BsmtFinType2', 'BsmtExposure', \n'BsmtQual', 'BsmtCond', 'BsmtFinType1', 'Id', 'PoolArea'], axis=1)\n\n#Testdata\ntest_id = test_data.copy()\n\n#test\ntest1_data = test_data.drop(['Id', 'PoolArea', 'PoolQC', 'MiscFeature', 'Alley','Fence', 'FireplaceQu','LotFrontage','GarageYrBlt',\n 'GarageCond', 'GarageType', 'GarageQual', 'GarageFinish', 'BsmtFinType2', 'BsmtExposure', \n'BsmtQual', 'BsmtCond', 'BsmtFinType1'], axis=1)","4863037e":"fig, axes = plt.subplots(1,2, figsize=(13, 5), sharey=False)\nfig.suptitle('Distribution after Adjusting the SalePrice', size=25)\nsb.histplot(t2data['SalePrice'], ax=axes[0])\n#sb.histplot(t2data['log_lotArea'], ax=axes[1])\nsb.histplot(t2data['log_price'], ax=axes[1])\nprint('We can now observe normal distribution')","08a3f327":"null_columns(t2data)\nprint('We can consider removing PoolQC and MiscFeature Columns, as the ratio of nan rows are significanly high')","7d8e6850":"print('Training and Test Datasets Categorical Features Comparison')\nprint('Left: Training, Right: Test')\nfig, axes = plt.subplots(26, 2, figsize=(20, 80), sharey=False)\nfig.subplots_adjust(top=0.9)\nfig.tight_layout(pad=5)\n#fig.suptitle('Categorical Features Distribution', size=25)\ns, c, cs =0, 0, 0\nfor i in t2data.columns:\n    if t2data[i].dtype == 'object':\n        t2data[i] = t2data[i].fillna(\"None\")\n        s+=1\n        if s > 0 and c < 26:\n            sb.countplot(x = i, data = t2data, ax=axes[c, cs])\n            cs+=1\n            sb.countplot(x = i, data = test1_data, ax=axes[c, cs])\n            if cs > 0:\n                c+=1; cs=0","4ce066f9":"corr = t2data.corr()\nprint('Closer the feature value to 1, more will be its weight on target feature')\ncorr_sp = corr[\"SalePrice\"]\ncorr_sp = corr_sp.to_frame()\ncorr_sp.style.background_gradient(cmap='rainbow')","24173956":"data_cleaned = t2data.copy()","95eda663":"train_target = data_cleaned['log_price']\ndata_cleaned = data_cleaned.drop(['SalePrice', 'log_price'],axis=1)","87366c6b":"num_col=[]; cat_col=[]; ord_col=[]\nfor i in data_cleaned.columns:\n    if str(data_cleaned[i].dtype) == 'object':\n        data_cleaned[i] = data_cleaned[i].fillna('None')\n        test1_data[i] = test1_data[i].fillna('None')\n        cat_col.append(i)\n        pass\n    if  str(data_cleaned[i].dtype)=='float64':\n        if data_cleaned[i].nunique() < 50:\n            data_cleaned[i] = data_cleaned[i].fillna(0)\n            test1_data[i] = test1_data[i].fillna(0) #testdata\n            ord_col.append(i)\n        else:\n            data_cleaned[i] = data_cleaned[i].fillna(0)\n            test1_data[i] = test1_data[i].fillna(0) #testdata\n            num_col.append(i)\n        pass\n    if str(data_cleaned[i].dtype) == 'int64':\n        if data_cleaned[i].nunique() < 50:\n            data_cleaned[i] = data_cleaned[i].fillna(0)\n            test1_data[i] = test1_data[i].fillna(0) #testdata\n            ord_col.append(i)\n        else:\n            data_cleaned[i] = data_cleaned[i].fillna(0)\n            test1_data[i] = test1_data[i].fillna(0)\n            num_col.append(i)#testdata\n        pass","65fb0be6":"null_columns(test1_data)","9f86d325":"null_columns(data_cleaned)","e4688d76":"scaleMinMax(data_cleaned)\nscaleMinMax(test1_data)","a6c4d3ac":"# all features where we want to check for multicollinearity\n# since our categorical data is not yet preprocessed, we will only take the numerical ones\nvariables = data_cleaned[num_col]\n\n# note that each variable has its own variance inflation factor as this measure is variable specific (not model specific)\nvif = pd.DataFrame()\n\n# here we make use of the variance_inflation_factor, which will basically output the respective VIFs \nvif[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n# Finally, I like to include names so it is easier to explore the result\nvif[\"Features\"] = variables.columns\npd.set_option('display.max_rows', 500)\nvif.style.format({\"VIF\":\"{:,.2f}\"})","3ed336ff":"print('variance inflation factor helps in identifying multicollinearity, we will remove the features with highest VIF')","03c7bbee":"data_no_multicollinearity = data_cleaned.drop(['1stFlrSF', '2ndFlrSF',\n 'GrLivArea','YearRemodAdd',  'BsmtFinSF1'],axis=1)\ntest_data_nomulti = test1_data.drop(['1stFlrSF', '2ndFlrSF',\n 'GrLivArea', 'YearRemodAdd', 'BsmtFinSF1'],axis=1)\ndata_no_multicollinearity","61a2813b":"unique_col_comparison(data_no_multicollinearity, test_data_nomulti, 'object')","77d2851a":"print('As there are some features that have different number of unique variables in both datasets, we will combine the datasets to create an equal number of dummy variables')","9dca16b2":"data_all = pd.concat([data_no_multicollinearity, test_data_nomulti],\n                      keys = ['train', 'test']).reset_index()","64fb31a3":"data_all = data_all.drop(['level_1', 'level_0'], axis = 1)\ndata_all.head(5)","9f09aa46":"cat_col = data_all.select_dtypes(include=object).columns\ndata_all = pd.get_dummies(data_all, prefix=cat_col)","4ee57760":"data_dummies_train = data_all[:len(data_no_multicollinearity)]\ndata_dummies_test = data_all[len(data_no_multicollinearity):]","b4d65bd5":"data_dummies_test.head(5)","7c456f03":"train_inputs = data_dummies_train.copy()\ntest_inputs = data_dummies_test.copy()","bcb7f2c8":"reg = LinearRegression()\n# Fit the regression with the scaled TRAIN inputs and targets\nreg.fit(train_inputs, train_target)","669e8bdc":"y_hat = reg.predict(train_inputs)","c21a4b64":"plt.scatter(train_target, y_hat)\nplt.xlabel('Actual Targets',size=25)\nplt.ylabel('Predictions',size=25)\nplt.show()","8777c99d":"reg.score(train_inputs, train_target)","e3d3abed":"# Calculation of Mean Squared Error (MSE)\nprint('LR-RMSE: ', np.sqrt(mean_squared_error(train_target, y_hat)))","396e1ac8":"sb.displot(train_target - y_hat)\n\nplt.title(\"Residuals PDF\", size=18)\n\n# In the best case scenario this plot should be normally distributed\n# Given the definition of the residuals (y_train - y_hat), negative values imply\n# that y_hat (predictions) are much higher than y_train (the targets)","fe1f2bf1":"#Bias = reg.intercept_\n#print('The bias is:', Bias)","2581598e":"# Create a regression summary where we can compare them with one-another\nreg_summary = pd.DataFrame(train_inputs.columns.values, columns=['Features'])\nreg_summary['Weights'] = reg.coef_\nreg_summary.head(10).sort_values(by ='Weights', ascending=False)","842b1180":"# Once we have trained and fine-tuned our model, we can proceed to testing it\n# Testing is done on a dataset that the algorithm has never seen\n# Luckily we have prepared such a dataset\n# Our test inputs are 'x_test', while the outputs: 'y_test' \n# We SHOULD NOT TRAIN THE MODEL ON THEM, we just feed them and find the predictions\n# If the predictions are far off, we will know that our model overfitted\ny_hat_test = reg.predict(test_inputs)\n","0cfdcad1":"pred_target = np.exp(y_hat_test)\ndf_pf = pd.DataFrame(pred_target, columns=['PRED-Reg'])\ndf_pf","45ae82f7":"predicted = np.exp(y_hat_test)","a5a479af":"preds = pd.DataFrame({'Id' : test_id['Id'], 'SalePrice': predicted})\npreds.to_csv('sumbmissionHP.csv', index = False)","8908f511":">## 4. Linear Regression Model","e148ecfe":"### 3.2. Populating the Null Values","16eae0c9":"### 3.7. Separating Train and Test Data for Modeling","74328679":"#### 3.4.1. Removing Columns with Multicollinearity","86107ae5":"#### Features Distribution Comparison in Both Datasets","39699ce5":"### 2.2. Indentifying Outliers through Exploring PDF ","ca12e4d3":"### 3.4. Multicollinearity","0871bf63":"### 3.6. Creating Dummies for Categorical Values","9a773229":"### 3.1. Features Correlation with Target Value","2fc9cea4":"### 3.5. Combining the Train and Testdata","ab5e6776":"print('Categorical Features Distribution of Training Dataset')\nfig, axes = plt.subplots(11, 3, figsize=(20, 60), sharey=False)\nfig.subplots_adjust(top=0.9)\nfig.tight_layout(pad=5)\n#fig.suptitle('Categorical Features Distribution', size=25)\ns, c, cs =0, 0, 0\nfor i in t2data.columns:\n    if t2data[i].dtype == 'object':\n        t2data[i] = t2data[i].fillna(\"None\")\n        s+=1\n        if s > 0 and c < 11:\n            sb.countplot(x = i, data = t2data, ax=axes[c, cs])\n            cs+=1\n            if cs > 2:\n                c+=1; cs=0","eb6772db":"### 4.3. RMSE","1278094d":"#### 2.1.2 Basement Null Values ","01f6593a":"### 2.1. Exploratory Data Analysis (EDA)","cea1634f":"#### 3.5.1. Unique Variables of Cat Features of Train and Test Datasets","c3ed0991":"#### 2.1.1 Indentifying Null Values","5748afb7":"#### 2.2.2. Categorical Features","20c60fda":"### 4.4. Residual PDFs","a5b814d2":"## House Prices Prediction - Machine Learning","f41514bb":"#### 2.1.3. Electrical Null Value","0fbe78af":">## 2. Data Preprocessing ","d195ffeb":">## 1. Importing the Libraries","6fbb3464":"print('Distribution of Features along Target')\nfig, axes = plt.subplots(16, 4, figsize=(20, 80), sharey=True)\nfig.subplots_adjust(top=0.9)\nfig.tight_layout(pad=5)\n#fig.suptitle('Categorical Features Distribution', size=25)\ns, c, cs =0, 0, 0\nfor i in t2data.columns:\n    if t2data[i].dtype == 'int64' or 'float64':\n        s+=1\n        if s > 0 and c < 16:\n            sb.scatterplot(x = i, y = 'log_price', data = t2data, ax=axes[c, cs],)\n            cs+=1\n            if cs > 3:\n                c+=1\n                cs=0","72653b63":"### 4.2. Visualising the Predicted and Actual Target Values (Training Data)","cbee9f8b":"## 5. Testing","2204d6d1":"### 3.3. Standardizing","aca34bc6":"#### 2.2.1. Numerical Features","f1c5ae35":">## Data Description","c2a768c0":"train_inputs = data_dummies_train.copy()\ntest_inputs = data_dummies_test.copy()\n# Create a scaler object\nscaler = StandardScaler()\n# Fit the inputs (calculate the mean and standard deviation feature-wise)\nscaler.fit(train_inputs)\ntrain_inputs_scaled = scaler.transform(train_inputs)\ntrain_inputs_scaled\n\n#scaling test data\nscaler = StandardScaler()\nscaler.fit(test_inputs)\ntest_inputs_scaled = scaler.transform(test_inputs)\ntest_inputs_scaled","0ef3d7ab":"MSSubClass: Identifies the type of dwelling involved in the sale.\t\n\n        20\t1-STORY 1946 & NEWER ALL STYLES\n        30\t1-STORY 1945 & OLDER\n        40\t1-STORY W\/FINISHED ATTIC ALL AGES\n        45\t1-1\/2 STORY - UNFINISHED ALL AGES\n        50\t1-1\/2 STORY FINISHED ALL AGES\n        60\t2-STORY 1946 & NEWER\n        70\t2-STORY 1945 & OLDER\n        75\t2-1\/2 STORY ALL AGES\n        80\tSPLIT OR MULTI-LEVEL\n        85\tSPLIT FOYER\n        90\tDUPLEX - ALL STYLES AND AGES\n       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n       150\t1-1\/2 STORY PUD - ALL AGES\n       160\t2-STORY PUD - 1946 & NEWER\n       180\tPUD - MULTILEVEL - INCL SPLIT LEV\/FOYER\n       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n\nMSZoning: Identifies the general zoning classification of the sale.\n\t\t\n       A\tAgriculture\n       C\tCommercial\n       FV\tFloating Village Residential\n       I\tIndustrial\n       RH\tResidential High Density\n       RL\tResidential Low Density\n       RP\tResidential Low Density Park \n       RM\tResidential Medium Density\n\t\nLotFrontage: Linear feet of street connected to property\n\nLotArea: Lot size in square feet\n\nStreet: Type of road access to property\n\n       Grvl\tGravel\t\n       Pave\tPaved\n       \t\nAlley: Type of alley access to property\n\n       Grvl\tGravel\n       Pave\tPaved\n       NA \tNo alley access\n\t\t\nLotShape: General shape of property\n\n       Reg\tRegular\t\n       IR1\tSlightly irregular\n       IR2\tModerately Irregular\n       IR3\tIrregular\n       \nLandContour: Flatness of the property\n\n       Lvl\tNear Flat\/Level\t\n       Bnk\tBanked - Quick and significant rise from street grade to building\n       HLS\tHillside - Significant slope from side to side\n       Low\tDepression\n\t\t\nUtilities: Type of utilities available\n\t\t\n       AllPub\tAll public Utilities (E,G,W,& S)\t\n       NoSewr\tElectricity, Gas, and Water (Septic Tank)\n       NoSeWa\tElectricity and Gas Only\n       ELO\tElectricity only\t\n\t\nLotConfig: Lot configuration\n\n       Inside\tInside lot\n       Corner\tCorner lot\n       CulDSac\tCul-de-sac\n       FR2\tFrontage on 2 sides of property\n       FR3\tFrontage on 3 sides of property\n\t\nLandSlope: Slope of property\n\t\t\n       Gtl\tGentle slope\n       Mod\tModerate Slope\t\n       Sev\tSevere Slope\n\t\nNeighborhood: Physical locations within Ames city limits\n\n       Blmngtn\tBloomington Heights\n       Blueste\tBluestem\n       BrDale\tBriardale\n       BrkSide\tBrookside\n       ClearCr\tClear Creek\n       CollgCr\tCollege Creek\n       Crawfor\tCrawford\n       Edwards\tEdwards\n       Gilbert\tGilbert\n       IDOTRR\tIowa DOT and Rail Road\n       MeadowV\tMeadow Village\n       Mitchel\tMitchell\n       Names\tNorth Ames\n       NoRidge\tNorthridge\n       NPkVill\tNorthpark Villa\n       NridgHt\tNorthridge Heights\n       NWAmes\tNorthwest Ames\n       OldTown\tOld Town\n       SWISU\tSouth & West of Iowa State University\n       Sawyer\tSawyer\n       SawyerW\tSawyer West\n       Somerst\tSomerset\n       StoneBr\tStone Brook\n       Timber\tTimberland\n       Veenker\tVeenker\n\t\t\t\nCondition1: Proximity to various conditions\n\t\n       Artery\tAdjacent to arterial street\n       Feedr\tAdjacent to feeder street\t\n       Norm\tNormal\t\n       RRNn\tWithin 200' of North-South Railroad\n       RRAn\tAdjacent to North-South Railroad\n       PosN\tNear positive off-site feature--park, greenbelt, etc.\n       PosA\tAdjacent to postive off-site feature\n       RRNe\tWithin 200' of East-West Railroad\n       RRAe\tAdjacent to East-West Railroad\n\t\nCondition2: Proximity to various conditions (if more than one is present)\n\t\t\n       Artery\tAdjacent to arterial street\n       Feedr\tAdjacent to feeder street\t\n       Norm\tNormal\t\n       RRNn\tWithin 200' of North-South Railroad\n       RRAn\tAdjacent to North-South Railroad\n       PosN\tNear positive off-site feature--park, greenbelt, etc.\n       PosA\tAdjacent to postive off-site feature\n       RRNe\tWithin 200' of East-West Railroad\n       RRAe\tAdjacent to East-West Railroad\n\t\nBldgType: Type of dwelling\n\t\t\n       1Fam\tSingle-family Detached\t\n       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n       Duplx\tDuplex\n       TwnhsE\tTownhouse End Unit\n       TwnhsI\tTownhouse Inside Unit\n\t\nHouseStyle: Style of dwelling\n\t\n       1Story\tOne story\n       1.5Fin\tOne and one-half story: 2nd level finished\n       1.5Unf\tOne and one-half story: 2nd level unfinished\n       2Story\tTwo story\n       2.5Fin\tTwo and one-half story: 2nd level finished\n       2.5Unf\tTwo and one-half story: 2nd level unfinished\n       SFoyer\tSplit Foyer\n       SLvl\tSplit Level\n\t\nOverallQual: Rates the overall material and finish of the house\n\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\n       5\tAverage\n       4\tBelow Average\n       3\tFair\n       2\tPoor\n       1\tVery Poor\n\t\nOverallCond: Rates the overall condition of the house\n\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\t\n       5\tAverage\n       4\tBelow Average\t\n       3\tFair\n       2\tPoor\n       1\tVery Poor\n\t\t\nYearBuilt: Original construction date\n\nYearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\n\nRoofStyle: Type of roof\n\n       Flat\tFlat\n       Gable\tGable\n       Gambrel\tGabrel (Barn)\n       Hip\tHip\n       Mansard\tMansard\n       Shed\tShed\n\t\t\nRoofMatl: Roof material\n\n       ClyTile\tClay or Tile\n       CompShg\tStandard (Composite) Shingle\n       Membran\tMembrane\n       Metal\tMetal\n       Roll\tRoll\n       Tar&Grv\tGravel & Tar\n       WdShake\tWood Shakes\n       WdShngl\tWood Shingles\n\t\t\nExterior1st: Exterior covering on house\n\n       AsbShng\tAsbestos Shingles\n       AsphShn\tAsphalt Shingles\n       BrkComm\tBrick Common\n       BrkFace\tBrick Face\n       CBlock\tCinder Block\n       CemntBd\tCement Board\n       HdBoard\tHard Board\n       ImStucc\tImitation Stucco\n       MetalSd\tMetal Siding\n       Other\tOther\n       Plywood\tPlywood\n       PreCast\tPreCast\t\n       Stone\tStone\n       Stucco\tStucco\n       VinylSd\tVinyl Siding\n       Wd Sdng\tWood Siding\n       WdShing\tWood Shingles\n\t\nExterior2nd: Exterior covering on house (if more than one material)\n\n       AsbShng\tAsbestos Shingles\n       AsphShn\tAsphalt Shingles\n       BrkComm\tBrick Common\n       BrkFace\tBrick Face\n       CBlock\tCinder Block\n       CemntBd\tCement Board\n       HdBoard\tHard Board\n       ImStucc\tImitation Stucco\n       MetalSd\tMetal Siding\n       Other\tOther\n       Plywood\tPlywood\n       PreCast\tPreCast\n       Stone\tStone\n       Stucco\tStucco\n       VinylSd\tVinyl Siding\n       Wd Sdng\tWood Siding\n       WdShing\tWood Shingles\n\t\nMasVnrType: Masonry veneer type\n\n       BrkCmn\tBrick Common\n       BrkFace\tBrick Face\n       CBlock\tCinder Block\n       None\tNone\n       Stone\tStone\n\t\nMasVnrArea: Masonry veneer area in square feet\n\nExterQual: Evaluates the quality of the material on the exterior \n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       Po\tPoor\n\t\t\nExterCond: Evaluates the present condition of the material on the exterior\n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       Po\tPoor\n\t\t\nFoundation: Type of foundation\n\t\t\n       BrkTil\tBrick & Tile\n       CBlock\tCinder Block\n       PConc\tPoured Contrete\t\n       Slab\tSlab\n       Stone\tStone\n       Wood\tWood\n\t\t\nBsmtQual: Evaluates the height of theement\n\n       Ex\tExcellent (100+ inches)\t\n       Gd\tGood (90-99 inches)\n       TA\tTypical (80-89 inches)\n       Fa\tFair (70-79 inches)\n       Po\tPoor (<70 inches\n       NA\tNo Basement\n\t\t\nBsmtCond: Evaluates the general condition of the basement\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical - slight dampness allowed\n       Fa\tFair - dampness or some cracking or settling\n       Po\tPoor - Severe cracking, settling, or wetness\n       NA\tNo Basement\n\t\nBsmtExposure: Refers to walkout or garden level walls\n\n       Gd\tGood Exposure\n       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n       Mn\tMimimum Exposure\n       No\tNo Exposure\n       NA\tNo Basement\n\t\nBsmtFinType1: Rating of basement finished area\n\n       GLQ\tGood Living Quarters\n       ALQ\tAverage Living Quarters\n       BLQ\tBelow Average Living Quarters\t\n       Rec\tAverage Rec Room\n       LwQ\tLow Quality\n       Unf\tUnfinshed\n       NA\tNo Basement\n\t\t\nBsmtFinSF1: Type 1 finished square feet\n\nBsmtFinType2: Rating of basement finished area (if multiple types)\n\n       GLQ\tGood Living Quarters\n       ALQ\tAverage Living Quarters\n       BLQ\tBelow Average Living Quarters\t\n       Rec\tAverage Rec Room\n       LwQ\tLow Quality\n       Unf\tUnfinshed\n       NA\tNo Basement\n\nBsmtFinSF2: Type 2 finished square feet\n\nBsmtUnfSF: Unfinished square feet of basement area\n\nTotalBsmtSF: Total square feet of basement area\n\nHeating: Type of heating\n\t\t\n       Floor\tFloor Furnace\n       GasA\tGas forced warm air furnace\n       GasW\tGas hot water or steam heat\n       Grav\tGravity furnace\t\n       OthW\tHot water or steam heat other than gas\n       Wall\tWall furnace\n\t\t\nHeatingQC: Heating quality and condition\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       Po\tPoor\n\t\t\nCentralAir: Central air conditioning\n\n       N\tNo\n       Y\tYes\n\t\t\nElectrical: Electrical system\n\n       SBrkr\tStandard Circuit Breakers & Romex\n       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n       Mix\tMixed\n\t\t\n1stFlrSF: First Floor square feet\n \n2ndFlrSF: Second floor square feet\n\nLowQualFinSF: Low quality finished square feet (all floors)\n\nGrLivArea: Above grade (ground) living area square feet\n\nBsmtFullBath: Basement full bathrooms\n\nBsmtHalfBath: Basement half bathrooms\n\nFullBath: Full bathrooms above grade\n\nHalfBath: Half baths above grade\n\nBedroom: Bedrooms above grade (does NOT include basement bedrooms)\n\nKitchen: Kitchens above grade\n\nKitchenQual: Kitchen quality\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor\n       \t\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n\nFunctional: Home functionality (Assume typical unless deductions are warranted)\n\n       Typ\tTypical Functionality\n       Min1\tMinor Deductions 1\n       Min2\tMinor Deductions 2\n       Mod\tModerate Deductions\n       Maj1\tMajor Deductions 1\n       Maj2\tMajor Deductions 2\n       Sev\tSeverely Damaged\n       Sal\tSalvage only\n\t\t\nFireplaces: Number of fireplaces\n\nFireplaceQu: Fireplace quality\n\n       Ex\tExcellent - Exceptional Masonry Fireplace\n       Gd\tGood - Masonry Fireplace in main level\n       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n       Fa\tFair - Prefabricated Fireplace in basement\n       Po\tPoor - Ben Franklin Stove\n       NA\tNo Fireplace\n\t\t\nGarageType: Garage location\n\t\t\n       2Types\tMore than one type of garage\n       Attchd\tAttached to home\n       Basment\tBasement Garage\n       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n       CarPort\tCar Port\n       Detchd\tDetached from home\n       NA\tNo Garage\n\t\t\nGarageYrBlt: Year garage was built\n\t\t\nGarageFinish: Interior finish of the garage\n\n       Fin\tFinished\n       RFn\tRough Finished\t\n       Unf\tUnfinished\n       NA\tNo Garage\n\t\t\nGarageCars: Size of garage in car capacity\n\nGarageArea: Size of garage in square feet\n\nGarageQual: Garage quality\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor\n       NA\tNo Garage\n\t\t\nGarageCond: Garage condition\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor\n       NA\tNo Garage\n\t\t\nPavedDrive: Paved driveway\n\n       Y\tPaved \n       P\tPartial Pavement\n       N\tDirt\/Gravel\n\t\t\nWoodDeckSF: Wood deck area in square feet\n\nOpenPorchSF: Open porch area in square feet\n\nEnclosedPorch: Enclosed porch area in square feet\n\n3SsnPorch: Three season porch area in square feet\n\nScreenPorch: Screen porch area in square feet\n\nPoolArea: Pool area in square feet\n\nPoolQC: Pool quality\n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       NA\tNo Pool\n\t\t\nFence: Fence quality\n\t\t\n       GdPrv\tGood Privacy\n       MnPrv\tMinimum Privacy\n       GdWo\tGood Wood\n       MnWw\tMinimum Wood\/Wire\n       NA\tNo Fence\n\t\nMiscFeature: Miscellaneous feature not covered in other categories\n\t\t\n       Elev\tElevator\n       Gar2\t2nd Garage (if not described in garage section)\n       Othr\tOther\n       Shed\tShed (over 100 SF)\n       TenC\tTennis Court\n       NA\tNone\n\t\t\nMiscVal: $Value of miscellaneous feature\n\nMoSold: Month Sold (MM)\n\nYrSold: Year Sold (YYYY)\n\nSaleType: Type of sale\n\t\t\n       WD \tWarranty Deed - Conventional\n       CWD\tWarranty Deed - Cash\n       VWD\tWarranty Deed - VA Loan\n       New\tHome just constructed and sold\n       COD\tCourt Officer Deed\/Estate\n       Con\tContract 15% Down payment regular terms\n       ConLw\tContract Low Down payment and low interest\n       ConLI\tContract Low Interest\n       ConLD\tContract Low Down\n       Oth\tOther\n\t\t\nSaleCondition: Condition of sale\n\n       Normal\tNormal Sale\n       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n       AdjLand\tAdjoining Land Purchase\n       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n       Family\tSale between family members\n       Partial\tHome was not completed when last assessed (associated with New Homes)\n","65a1c9ac":"### 4.1. Model Fitting","b0c1b2c3":"![house_home_colors_live_building.jpeg](attachment:15f5e88f-5cfd-45ad-afb6-769c33f63f78.jpeg)","27956ff8":">## 3. Feature Engineering","6abe350c":"### 4.6. Weights and Bias","41850a23":"t2data = t2data[t2data['1stFlrSF'] < 2200]\nt2data = t2data[t2data['TotalBsmtSF'] < 2500]\nt2data = t2data[t2data['GrLivArea'] < 3000].reset_index()"}}