{"cell_type":{"ac308ced":"code","62ceb481":"code","1bcf58fa":"code","ae77a421":"code","6bd6d4ab":"code","e900ac78":"code","f883804e":"code","3cb6abc3":"code","a2986410":"code","c12851d7":"code","930fa0b0":"code","d4df8953":"code","8670f0ab":"code","958f16fb":"code","520dd2aa":"code","c08889b8":"code","83119962":"code","c075129b":"code","aa846903":"code","3ed8d2d3":"code","6aa30137":"code","07c6cabf":"code","d70574ba":"code","f6204980":"code","7b56a374":"code","00ffd852":"code","115fe63d":"code","016d5d51":"code","73f1c069":"code","12671d92":"code","dadee18d":"code","c23fdc04":"code","13820ef1":"code","c9c24529":"code","55277e53":"code","b50f2dad":"code","e9052b42":"code","db62a8ed":"code","5e19e040":"code","73258e73":"code","f2eed1b7":"code","1586fd21":"code","2c96f833":"code","ff3cd3fa":"code","47c3d34e":"code","fe014811":"code","dafc2d33":"code","ffb5b479":"code","5875be1e":"markdown","6e618941":"markdown","98cf44b7":"markdown","50f725a2":"markdown","7c7d2ea6":"markdown","a9e814f5":"markdown","0034a8dd":"markdown","4ea160fd":"markdown","acb629c8":"markdown"},"source":{"ac308ced":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","62ceb481":"from collections import Counter\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import KFold\nfrom nltk.corpus import stopwords","1bcf58fa":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nprint(set(train.columns).difference(set(test.columns)))","ae77a421":"test[\"revenue\"] = np.nan\nall_movies = pd.concat([train, test])\nall_movies.head()","6bd6d4ab":"all_movies.shape","e900ac78":"def clean_belongs_to_collection(x):\n    if x is np.nan:\n        return \"\"\n    x = x[1:-1]\n    return eval(x)['name']\n\nall_movies[\"collection\"] = all_movies[\"belongs_to_collection\"].apply(clean_belongs_to_collection)\nprint(all_movies[\"collection\"].isnull().sum())\nprint(all_movies[\"collection\"].head())","f883804e":"def get_genres(x):\n    if x is np.nan:\n        return \"\"\n    genres = list()\n    for genre_dict in eval(x):\n        genres.append(genre_dict['name'])\n    return \",\".join(genres)\n\nall_movies[\"genres_list\"] = all_movies[\"genres\"].apply(get_genres)\nprint(all_movies[\"genres_list\"].isnull().sum())\nall_movies[\"genres_list\"].head()","3cb6abc3":"genres = list()\nfor i in range(all_movies.shape[0]):\n    genres += (all_movies.iloc[i][\"genres_list\"].split(\",\"))\ngenres = Counter(genres)\ngenres.most_common(25)","a2986410":"for genre, count in genres.most_common(25)[:-2]:\n    all_movies[genre] = all_movies[\"genres_list\"].apply(lambda x: 1 if genre in x else 0)\nall_movies = all_movies.drop([\"genres_list\"], axis=1)\nall_movies.isnull().sum()","c12851d7":"all_movies[\"has_webpage\"] = all_movies[\"homepage\"].apply(lambda x: 0 if x is np.nan else 1)\n# I'll use imdb_id to scrape critic scores in a later kernel\nall_movies = all_movies.drop([\"belongs_to_collection\", \"genres\",\n                              \"homepage\", \"imdb_id\", \"poster_path\"], axis=1)","930fa0b0":"dummy_orig_langs = pd.get_dummies(all_movies[\"original_language\"], prefix=\"original_lang\")\nall_movies = pd.concat([all_movies,dummy_orig_langs], axis=1)","d4df8953":"stop_words = set(stopwords.words('english'))\ntext_cols = [\"overview\", \"tagline\"]\novw_words = list()\ntag_words = list()\nfor i in range(all_movies.shape[0]):\n    try:\n        ovw_words += (all_movies.iloc[i][\"overview\"].replace(\",\",\"\").replace(\".\",\"\").lower().split())\n        tag_words += (all_movies.iloc[i][\"tagline\"].replace(\",\",\"\").replace(\".\",\"\").lower().split())\n    except AttributeError as e:\n        continue\novw_words = Counter([w for w in ovw_words if len(w) > 4 and w not in stop_words])\ntag_words = Counter([w for w in tag_words if len(w) > 4 and w not in stop_words])\nprint(ovw_words.most_common(10))\nprint(tag_words.most_common(10))","8670f0ab":"for word, _ in ovw_words.most_common(100):\n    col = \"overview_\"+word\n    all_movies[col] = all_movies[\"overview\"].apply(lambda x: 0 if x is np.nan else 1 if word in x.lower() else 0)\nfor word, _ in tag_words.most_common(100):\n    col = \"tagline_\"+word\n    all_movies[col] = all_movies[\"tagline\"].apply(lambda x: 0 if x is np.nan else 1 if word in x.lower() else 0)\nall_movies.shape","958f16fb":"ovw_high_var_list = list()\ntag_high_var_list = list()\ntrain_idx = train.shape[0]\ntrain = all_movies.iloc[:train_idx]\novw_cols = [col for col in list(train.columns) if \"overview_\" in col]\ntag_cols = [col for col in list(train.columns) if \"tagline_\" in col]\nfor col in ovw_cols:\n    ovw_high_var_list.append((col, train[train[col] == 1][\"revenue\"].var()))\nfor col in tag_cols:\n    tag_high_var_list.append((col, train[train[col] == 1][\"revenue\"].var()))\novw_high_var_list = sorted(ovw_high_var_list, key=lambda x: x[1], reverse=True)\ntag_high_var_list = sorted(tag_high_var_list, key=lambda x: x[1], reverse=True)\n\n# take the top half of variances in revenue\novw_drop_cols = [x[0] for x in ovw_high_var_list[50:]]\ntag_drop_cols = [x[0] for x in tag_high_var_list[50:]]\nall_movies = all_movies.drop((ovw_drop_cols + tag_drop_cols), axis=1)\nall_movies.shape","520dd2aa":"all_movies.isnull().sum()","c08889b8":"all_movies[\"status\"].value_counts()","83119962":"all_movies.loc[all_movies['title'].isnull(), 'title'] = all_movies.loc[all_movies['title'].isnull(), 'original_title']\nall_movies['status'].fillna(\"Released\", inplace = True)\n\n# fill runtime based on info found at https:\/\/www.imdb.com\nall_movies.loc[all_movies['title']=='Happy Weekend', 'runtime'] = 81\nall_movies.loc[all_movies['title']=='Miesten v\u00e4lisi\u00e4 keskusteluja', 'runtime'] = 90\nall_movies.loc[all_movies['title']=='Nunca en horas de clase', 'runtime'] = 100\nall_movies.loc[all_movies['title']=='Pancho, el perro millonario', 'runtime'] = 91\nall_movies.loc[all_movies['title']=='La caliente ni\u00f1a Julietta', 'runtime'] = 93\nall_movies.loc[all_movies['title']=='\u041a\u043e\u0440\u043e\u043b\u0451\u0432', 'runtime'] = 130\n\n# release date of Jails, Hospitals & Hip-Hop movie : May 2000\nall_movies.loc[all_movies['release_date'].isnull(), 'release_date'] = '5\/1\/00'","c075129b":"#all_movies[\"release_day\"] = all_movies[\"release_date\"].apply(lambda x: int(x.split(\"\/\")[1])).astype(int)\nall_movies[\"release_month\"] = all_movies[\"release_date\"].apply(lambda x: x.split(\"\/\")[0])\nall_movies[\"release_month\"].value_counts()","aa846903":"# this function was used above as get_genres\ndef get_list_of_values(x, key):\n    if x is np.nan:\n        return \"\"\n    vals = list()\n    for val in eval(x):\n        vals.append(val[key])\n    return \",\".join(vals)\n\ndef find_most_common(col, n):\n    values = list()\n    for i in range(all_movies.shape[0]):\n        values += all_movies.iloc[i][col].split(\",\")\n    return Counter(values).most_common(n)\n\ndef one_hot_encode_most_common(new_col, list_col, cmn_lst):\n    for name, cnt in cmn_lst:\n        all_movies[new_col+\"_\"+name] = all_movies[list_col].apply(\n            lambda x: 1 if name in x else 0)\n    return None\n\n# production companies\nall_movies[\"companies_list\"] = all_movies[\"production_companies\"].apply(\n    get_list_of_values, args=('name',))\nmost_cmn_comps = find_most_common(\"companies_list\", 10)\none_hot_encode_most_common(\"production_companies\", \"companies_list\", most_cmn_comps)\n\n# production countries\nall_movies[\"countries_list\"] = all_movies[\"production_countries\"].apply(\n    get_list_of_values, args=('iso_3166_1',))\nmost_cmn_countries = find_most_common(\"countries_list\", 25)\none_hot_encode_most_common(\"production_countries\", \"countries_list\", most_cmn_countries)\n\n# spoken languages\nall_movies[\"spoken_lang_list\"] = all_movies[\"spoken_languages\"].apply(\n    get_list_of_values, args=('iso_639_1',))\nmost_cmn_langs = find_most_common(\"spoken_lang_list\", 25)\none_hot_encode_most_common(\"spoken_languages\", \"spoken_lang_list\", most_cmn_langs)\n\n# Keywords\nall_movies[\"keywords_list\"] = all_movies[\"Keywords\"].apply(\n    get_list_of_values, args=('name',))\nmost_cmn_kywds = find_most_common(\"keywords_list\", 25)\none_hot_encode_most_common(\"Keywords\", \"keywords_list\", most_cmn_kywds)\n\n# cast\nall_movies.loc[all_movies['cast'].isnull(), 'cast'] = \"[{'gender':'','gender':'','gender':''}]\"\nall_movies['cast_gender_0'] = all_movies['cast'].apply(lambda x: np.nan if len(eval(x)) < 1 else eval(x)[0]['gender'])\nall_movies['cast_gender_1'] = all_movies['cast'].apply(lambda x: np.nan if len(eval(x)) < 2 else eval(x)[1]['gender'])\nall_movies['cast_gender_2'] = all_movies['cast'].apply(lambda x: np.nan if len(eval(x)) < 3 else eval(x)[2]['gender'])\n\nall_movies.shape","3ed8d2d3":"all_movies = all_movies.drop([\"release_date\", \"production_companies\", \"production_countries\",\n                             \"spoken_languages\", \"Keywords\", \"cast\", \"crew\", \"overview\", \"tagline\",\n                             \"companies_list\", \"countries_list\", \"spoken_lang_list\",\"keywords_list\"], axis=1)","6aa30137":"all_movies.isnull().sum()","07c6cabf":"all_movies[\"cast_gender_0\"].value_counts()","d70574ba":"# there are more than two genders\ndummy_genders_0 = pd.get_dummies(all_movies[\"cast_gender_0\"], prefix=\"first_cast_gender\")\nall_movies = pd.concat([all_movies, dummy_genders_0], axis=1)\ndummy_genders_1 = pd.get_dummies(all_movies[\"cast_gender_1\"], prefix=\"scnd_cast_gender_1\")\nall_movies = pd.concat([all_movies, dummy_genders_1], axis=1)\ndummy_genders_2 = pd.get_dummies(all_movies[\"cast_gender_2\"], prefix=\"thrd_cast_gender_2\")\nall_movies = pd.concat([all_movies, dummy_genders_2], axis=1)\nall_movies = all_movies.drop([\"cast_gender_0\", \"cast_gender_1\", \"cast_gender_2\"], axis=1)","f6204980":"all_movies[[col for col in all_movies.columns.tolist() if col != \"revenue\"]].isnull().sum().sum()","7b56a374":"dummy_months = pd.get_dummies(all_movies[\"release_month\"], prefix=\"month\")\nall_movies = pd.concat([all_movies, dummy_months], axis=1)","00ffd852":"all_movies = all_movies.drop(['original_language','original_title','status','title',\n                             'collection'], axis=1)","115fe63d":"all_movies.dtypes","016d5d51":"num_movies = all_movies.select_dtypes(include=['float64'])\nnum_movies = pd.concat([num_movies, all_movies[[\"budget\"]]], axis=1)\nnum_movies.describe()","73f1c069":"def normalize_col(df, col):\n    df[col+\"_norm\"] = (df[col] - df[col].min()) \/ (df[col].max() - df[col].min())\n    return None\n\nnormalize_col(all_movies, \"popularity\")\nnormalize_col(all_movies, \"runtime\")\nnormalize_col(all_movies, \"budget\")","12671d92":"all_movies[[\"popularity_norm\", \"runtime_norm\", \"budget_norm\"]].describe()","dadee18d":"train = all_movies.iloc[:train_idx]\ntest = all_movies.iloc[train_idx:]","c23fdc04":"all_movies.columns.tolist()","13820ef1":"month_pivot = train.pivot_table(index=\"release_month\", values=\"revenue\", aggfunc=np.mean)\nmonth_pivot.plot.bar()","c9c24529":"all_movies[\"release_month\"].dtype","55277e53":"all_movies[\"summer\"] = all_movies[\"release_month\"].apply(lambda x: 1 if x in ['5','6','7'] else 0)\nall_movies[\"winter\"] = all_movies[\"release_month\"].apply(lambda x: 1 if x in ['11', '12'] else 0)","b50f2dad":"train_idx = train.shape[0]\ntrain = all_movies.iloc[:train_idx]\ntest = all_movies.iloc[train_idx:]","e9052b42":"train.columns.tolist()","db62a8ed":"simple_features = ['popularity_norm', 'runtime_norm', 'budget_norm']\nother_features = ['has_webpage']\noverview_features = [col for col in train.columns.tolist() if \"overview\" in col]\ntagline_features = [col for col in train.columns.tolist() if \"tagline\" in col]\ncompany_features = [col for col in train.columns.tolist() if \"production_companies\" in col]\ncountry_features = [col for col in train.columns.tolist() if \"production_countries\" in col]\nspoken_lang_features = [col for col in train.columns.tolist() if \"spoken_languages\" in col]\nkeyword_features = [col for col in train.columns.tolist() if \"Keywords_\" in col]\ncast_gender_features = [col for col in train.columns.tolist() if \"cast_gender_\" in col]\nmonth_features = [col for col in train.columns.tolist() if \"month_\" in col]\nseason_features = ['summer', 'winter']\njune = ['month_6']\nall_features =  [col for col in train.columns.tolist() if col not in [\"revenue\", \"id\", \"released_month\",\n                                                                     \"budget\", \"popularity\", \"runtime\"]]\ngenre_features = ['Drama',\n 'Comedy',\n 'Thriller',\n 'Action',\n 'Romance',\n 'Adventure',\n 'Crime',\n 'Science Fiction',\n 'Horror',\n 'Family',\n 'Fantasy',\n 'Mystery',\n 'Animation',\n 'History',\n 'Music',\n 'War',\n 'Documentary',\n 'Western',\n 'Foreign']","5e19e040":"feature_sets = [simple_features,other_features,overview_features,tagline_features,\n                company_features,country_features,spoken_lang_features,keyword_features,\n                cast_gender_features,month_features,season_features,june,\n                all_features,genre_features]\nfeature_set_strings = [\"simple_features\",\"other_features\",\"overview_features\",\"tagline_features\",\n                \"company_features\",\"country_features\",\"spoken_lang_features\",\"keyword_features\",\n                \"cast_gender_features\",\"month_features\", \"season_features\", \"june\",\n                       \"all_features\",\"genre_features\"]\n\ny = train[\"revenue\"]\nk_s = [3,5,7,9,11,13,15, 17, 19]\nmodel_results = list()\nfor feature_set, set_string in zip(feature_sets, feature_set_strings):\n    print(set_string)\n    features = list(set((feature_set + simple_features)))\n    X = train[features]\n    kf = KFold(n_splits=5, random_state=319, shuffle=True)\n    feature_set_errors = list()\n    for k in k_s:\n        i = 0\n        print(str(k)+\" neighbors\")\n        for train_idx, test_idx in kf.split(X):\n            i +=1\n            model = KNeighborsRegressor(n_neighbors=k)\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n            model.fit(X_train, y_train)\n            predictions = model.predict(X_test)\n            error = np.sqrt(mean_squared_log_error(y_test, predictions))\n            feature_set_errors.append(error)\n            print(\"Fold \"+str(i) + \": \"+str(round(error,4)))\n        print(set_string + \" \"+ str(k)+\" neigbors mean: \" + str(round(np.mean(feature_set_errors),4)))\n        model_results.append([(set_string+\"_\"+str(k)), round(np.mean(feature_set_errors),4)])","73258e73":"model_results = sorted(model_results, key=lambda x: x[1])\nmodel_results[:30]","f2eed1b7":"all_features = simple_features + other_features + company_features + country_features + june\nmy_hunch = simple_features + company_features + june\nfeature_sets = [simple_features,other_features,company_features,country_features,\n                june, all_features, my_hunch]\nfeature_set_strings = ['simple_features','other_features','company_features','country_features',\n                       'june', 'all_features', 'my_hunch']\n\ny = train[\"revenue\"]\nk_s = [k for k in range(1,8)]\nmodel_results = list()\nfor feature_set, set_string in zip(feature_sets, feature_set_strings):\n    print(set_string)\n    features = list(set((feature_set + simple_features)))\n    X = train[features]\n    kf = KFold(n_splits=5, random_state=319, shuffle=True)\n    feature_set_errors = list()\n    for k in k_s:\n        i = 0\n        print(str(k)+\" neighbors\")\n        for train_idx, test_idx in kf.split(X):\n            i +=1\n            model = KNeighborsRegressor(n_neighbors=k)\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n            model.fit(X_train, y_train)\n            predictions = model.predict(X_test)\n            error = np.sqrt(mean_squared_log_error(y_test, predictions))\n            feature_set_errors.append(error)\n            print(\"Fold \"+str(i) + \": \"+str(round(error,4)))\n        print(set_string + \" \"+ str(k)+\" neigbors mean: \" + str(round(np.mean(feature_set_errors),4)))\n        model_results.append([(set_string+\"_\"+str(k)), round(np.mean(feature_set_errors),4)])","1586fd21":"model_results = sorted(model_results, key=lambda x: x[1])\nmodel_results[:25]","2c96f833":"all_features = simple_features + other_features + company_features + country_features + june\nmy_hunch = simple_features + company_features + june\nfeature_sets = [simple_features,other_features,company_features,country_features,\n                june, all_features, my_hunch]\nfeature_set_strings = ['simple_features','other_features','company_features','country_features',\n                       'june', 'all_features', 'my_hunch']\n\ny = train[\"revenue\"]\nk_s = [k for k in range(1,20)]\nmodel_results = list()\nfor feature_set, set_string in zip(feature_sets, feature_set_strings):\n    features = list(set((feature_set + simple_features)))\n    X = train[features]\n    kf = KFold(n_splits=5, random_state=319, shuffle=True)\n    feature_set_errors = list()\n    for k in k_s:\n        for train_idx, test_idx in kf.split(X):\n            model = KNeighborsRegressor(n_neighbors=k)\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n            model.fit(X_train, y_train)\n            predictions = model.predict(X_test)\n            error = np.sqrt(mean_squared_log_error(y_test, predictions))\n            feature_set_errors.append(error)\n        model_results.append([(set_string+\"_\"+str(k)), round(np.mean(feature_set_errors),4)])\nmodel_results = sorted(model_results, key=lambda x: x[1])\nmodel_results[:25]","ff3cd3fa":"my_hunch = simple_features + company_features + june\nfeature_sets = [company_features, my_hunch]\nfeature_set_strings = ['company_features','my_hunch']\n\ny = train[\"revenue\"]\nk_s = [k for k in range(1,30)]\nmodel_results = list()\nfor feature_set, set_string in zip(feature_sets, feature_set_strings):\n    features = list(set((feature_set + simple_features)))\n    X = train[features]\n    kf = KFold(n_splits=5, random_state=319, shuffle=True)\n    feature_set_errors = list()\n    for k in k_s:\n        for train_idx, test_idx in kf.split(X):\n            model = KNeighborsRegressor(n_neighbors=k)\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n            model.fit(X_train, y_train)\n            predictions = model.predict(X_test)\n            error = np.sqrt(mean_squared_log_error(y_test, predictions))\n            feature_set_errors.append(error)\n        model_results.append([(set_string+\"_\"+str(k)), round(np.mean(feature_set_errors),4)])\nmodel_results = sorted(model_results, key=lambda x: x[1])\nmodel_results[:25]","47c3d34e":"features = (company_features + simple_features)\nknn = KNeighborsRegressor(n_neighbors=17)\nknn.fit(train[features], train['revenue'])\npredictions17 = knn.predict(test[features])","fe014811":"submission_df = {\"id\": test['id'], \"revenue\": predictions17}\nsubmission17 = pd.DataFrame(submission_df)\nsubmission17.to_csv(\"knn_submission_17.csv\", index=False)","dafc2d33":"features = (company_features + simple_features)\nknn = KNeighborsRegressor(n_neighbors=3)\nknn.fit(train[features], train['revenue'])\npredictions3 = knn.predict(test[features])","ffb5b479":"submission_df = {\"id\": test['id'], \"revenue\": predictions3}\nsubmission3 = pd.DataFrame(submission_df)\nsubmission3.to_csv(\"knn_submission_3.csv\", index=False)","5875be1e":"Now, test company, country, june features with between 1 and 7 neighbors. More than 7 seems to underfit.","6e618941":"Summer and winter months when the family is all together seem to be like better months for movie revenue. I'll simplify the month features to one hot encode summer and winter months.","98cf44b7":"Looks like I was wrong for these models with much fewer features.","50f725a2":"Code in below cell is lifted from dgk1's excellent kernel found [here](https:\/\/www.kaggle.com\/dgk1234\/basic-fe-lgbm).","7c7d2ea6":"# Data Exploration","a9e814f5":"To use KNN I need to normalized the two numeric columns, budget, runtime and populatrity, ","0034a8dd":"# Modeling","4ea160fd":"Still convinced from an initial result that k=17 is going to underfit.","acb629c8":"# Data Cleaning"}}