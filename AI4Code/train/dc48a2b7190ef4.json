{"cell_type":{"ae16acbe":"code","e91ee692":"code","b07b69a9":"code","76d2d497":"code","fa6ae712":"code","41925f63":"code","01a46a98":"code","745e4e5c":"code","40b90578":"code","46f37347":"code","9bbd9517":"code","2d3afa4d":"code","0b6e2e0e":"code","f5a26563":"code","d058e03d":"code","55eeffa7":"code","ccc2d328":"code","644a0c79":"code","67b6122d":"code","17a84e1c":"code","1873e9a9":"code","7c7d3532":"code","a476588b":"code","5e371ab4":"code","0b2caa06":"code","29520e3b":"code","fbcf567a":"markdown","717d5ec5":"markdown","99d758aa":"markdown","7bea44fe":"markdown","72925595":"markdown","c0ef5896":"markdown"},"source":{"ae16acbe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom scipy.cluster.hierarchy import linkage,dendrogram\nfrom sklearn.cluster import AgglomerativeClustering\n\n\n# data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e91ee692":"df=pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\",sep=\",\")","b07b69a9":"df.head()","76d2d497":"sns.heatmap(df.corr(),annot=True)","fa6ae712":"df.isnull().sum() # I dont have any null values","41925f63":"data=df.drop(\"Outcome\",axis=1)","01a46a98":"data.head() # Now I dont have Outcome column,Hence I have to create new one","745e4e5c":"wcss=[]# We will try to minimaze wcss \n\nfor K in range(1,15):\n    \n    Kmeans = KMeans(n_clusters=K)\n    Kmeans.fit(data)\n    wcss.append(Kmeans.inertia_) # inertia_ calculates wcss.\n    \nplt.plot(range(1,15),wcss)\nplt.xlabel(\"Number of K values\")\nplt.ylabel(\"Wcss\")\nplt.grid()\n    \n    ","40b90578":"n_Kmeans = KMeans(n_clusters = 2)\nclusters = n_Kmeans.fit_predict(data)\ndf[\"Kmeans_Label\"]= clusters","46f37347":"df.head()","9bbd9517":"df.shape #Data has 768 rows,I am going to use this to measure label accuracy","2d3afa4d":"accuracy=[]\n\nfor i in range(df.shape[0]):\n    if df.Outcome[i]==df.Kmeans_Label[i]:\n        accuracy.append(df.Kmeans_Label[i])\n        \n    \n    \n    ","0b6e2e0e":"plt.scatter(x=\"Insulin\",y=\"Glucose\",data=df,c=\"Outcome\") # original","f5a26563":"df.Outcome.unique()","d058e03d":"df.Kmeans_Label.unique() # \"2\"","55eeffa7":"plt.scatter(x=\"Insulin\",y=\"Glucose\",data=df,c=\"Kmeans_Label\") # \nplt.xlabel(\"Insulin\")\nplt.ylabel(\"Glucose\")","ccc2d328":"len(accuracy) # only 285 values of Kmeans_Label are same with Outcome.","644a0c79":"print(\"Accuracy:\",len(accuracy)\/df.shape[0])","67b6122d":"from sklearn.preprocessing import normalize # I want to normalize my data so in this way My clustering result might be better than Kmeans Clustering\ndata_scaled = normalize(data)\ndata2= pd.DataFrame(data_scaled, columns=data.columns)\ndata2.head()","17a84e1c":"from scipy.cluster.hierarchy import linkage,dendrogram\n\nmerg = linkage(data2,method=\"ward\")\ndendrogram(merg,leaf_rotation=90)\n\nplt.xlabel(\"Data Points\")\nplt.ylabel(\"Euclidean Distance\")\nplt.axhline(y=6, color='r', linestyle='--')","1873e9a9":"from sklearn.cluster import AgglomerativeClustering\ncluster = AgglomerativeClustering(n_clusters=2,affinity='euclidean', linkage='ward')  \ndf[\"Hierarchical_Label\"]=cluster.fit_predict(data2)","7c7d3532":"df.head()","a476588b":"plt.scatter(x=\"Insulin\",y=\"Glucose\",data=df,c=\"Outcome\") # original","5e371ab4":"plt.scatter(x=\"Insulin\",y=\"Glucose\",data=df,c=\"Hierarchical_Label\") \nplt.ylabel(\"Glucose\")","0b2caa06":"accuracy=[]\n\nfor i in range(df.shape[0]):\n    if df.Outcome[i]==df.Hierarchical_Label[i]:\n        accuracy.append(df.Hierarchical_Label[i])\n        ","29520e3b":"print(\"Accuracy:\",len(accuracy)\/df.shape[0]) ","fbcf567a":"As you see There are some mistakes in my data so I want to measure sucess of my label accuracy","717d5ec5":"## Kmeans Cluster","99d758aa":" -Objective of K-means is  group similar data points together and discover underlying patterns \n \n -To achieve this objective, K-means looks for a fixed number (k) of clusters in a dataset so K indicate number of cluster.\n \n -A cluster refers to a collection of data points aggregated together because of certain similarities.\n To find best K value for our data,I am going to use elbow method.\n","7bea44fe":"Optimum K value is 2","72925595":"## Hierarchical Clustring\n","c0ef5896":"To create Outcome columns.I am going to show you two options \"Kmeans Cluster and Hierarchy\""}}