{"cell_type":{"f23326a4":"code","24b7f2d6":"code","11b69b94":"code","5cf0f375":"code","d32ad417":"code","7b14640e":"code","1d01e031":"code","cf08645a":"code","53720e8c":"code","a41d2330":"code","ddae0304":"code","b0c5362f":"code","3e941745":"code","86ca7b0c":"code","26d49ace":"code","9ac6b740":"code","1ba13440":"code","c0388609":"code","f5efd2b1":"code","0a910dac":"code","5c9371ad":"code","22b01a77":"code","c798e1f6":"code","75cf12e7":"code","57655fbb":"code","6d4a6e44":"code","a89221d3":"code","e33badeb":"code","8fc1b6f3":"code","3e5653bb":"code","b431d4f8":"code","cc0e3ed1":"code","c5ecd831":"code","31ea7c56":"code","5f6b245e":"code","9b8b39eb":"code","c90ce070":"code","cda9f722":"code","25447f04":"code","710e446c":"code","8674893e":"code","b2c6a095":"code","25b656b5":"code","0e1a8769":"code","ad587613":"code","b3317393":"code","42d049f7":"code","d17d5f83":"code","5cadfbf0":"code","37b91684":"code","abf96109":"code","6e3a5751":"code","7255f35f":"code","81ffdc8c":"code","294bdc18":"code","b89c06bf":"code","0568d8ed":"code","e6755a8a":"markdown","14e546b0":"markdown","4e893cb9":"markdown","80bb7505":"markdown","52f4b6e8":"markdown","36c5b576":"markdown","3fad4282":"markdown","496ad693":"markdown","453ac410":"markdown"},"source":{"f23326a4":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","24b7f2d6":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom  tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, Huber\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping,ReduceLROnPlateau\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\nimport os\nimport random\nimport shutil\nimport zipfile","11b69b94":"root_dir = '\/kaggle\/input\/cotton-disease-dataset\/Cotton Disease\/'\ndef read_dir(path):\n    for dirpath , dirnames, filename in os.walk(path):\n        print(f\"{dirpath} : has {len(dirnames)} folder(s)  and {len(filename)} images init.\")\n\nread_dir(root_dir)","5cf0f375":"train_dir = f\"{root_dir}\/train\/\"\ntest_dir = f\"{root_dir}\/test\/\"\nval_dir = f\"{root_dir}\/val\/\"","d32ad417":"import pathlib\ndata_dir = pathlib.Path(train_dir)\nclass_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\nclass_names","7b14640e":"def view_image(target_dir, className):\n    for i in className:\n        folder = target_dir + '\/' + i\n        random_image = random.sample(tf.io.gfile.listdir(folder), 1)\n        image = mpimg.imread(folder + '\/' + random_image[0])\n        plt.figure(figsize=(10, 7))\n        plt.title(f' {i} : Image Shape :{image.shape}')\n        plt.axis(False)\n        plt.imshow(image)\n        plt.show()\nview_image(train_dir, class_names)","1d01e031":"def data_generator():\n    train_gen = ImageDataGenerator(rescale= 1.\/255.,\n                                   rotation_range=25,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip= True,\n                                   fill_mode='nearest',\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1)\n\n    train_data = train_gen.flow_from_directory(train_dir ,target_size= (224, 224),\n                                               batch_size= 32,\n                                               class_mode= 'categorical',\n                                               )\n\n    test_gen = ImageDataGenerator(rescale = 1.\/255.)\n    test_data = test_gen.flow_from_directory(test_dir, target_size= (224, 224),\n                                             batch_size= 32,\n                                             class_mode= 'categorical')\n\n    val_gen = ImageDataGenerator(rescale= 1. \/ 255.)\n    val_data = val_gen.flow_from_directory(val_dir, target_size=(224, 224),\n                                             batch_size=32,\n                                             class_mode='categorical')\n\n    return [train_data, test_data, val_data]\n\ntrain_data, test_data, val_data = data_generator()","cf08645a":"def cnn_model():\n    base_model = Sequential()\n    base_model.add(Conv2D(32, (3,3), padding = 'same',\n                       input_shape= (224,224,3), activation='relu'))\n    base_model.add(tf.keras.layers.BatchNormalization(1))\n    base_model.add(MaxPooling2D(pool_size=(3,3)))\n    base_model.add(Dropout(0.25))\n\n\n    base_model.add(Conv2D(64, (3,3), padding = 'same',\n                     activation='relu'))\n    base_model.add(tf.keras.layers.BatchNormalization(1))\n    base_model.add(MaxPooling2D(pool_size=(3,3)))\n    base_model.add(Dropout(0.25))\n\n    base_model.add(Conv2D(64, (3, 3), padding='same',\n                     activation='relu'))\n    base_model.add(tf.keras.layers.BatchNormalization(1))\n    base_model.add(MaxPooling2D(pool_size=(2)))\n    base_model.add(Dropout(0.25))\n\n    base_model.add(Conv2D(128, (3, 3), padding='same',\n                     activation='relu'))\n    base_model.add(tf.keras.layers.BatchNormalization(1))\n    base_model.add(MaxPooling2D(pool_size=(2)))\n    base_model.add(Dropout(0.25))\n\n\n    base_model.add(Flatten())\n    base_model.add(Dense(1024, 'relu'))\n    base_model.add(tf.keras.layers.BatchNormalization())\n    base_model.add(Dropout(0.25))\n    base_model.add(Dense(4, 'softmax'))\n    \n    return base_model\n\n","53720e8c":"optimal_curve_model = cnn_model()\noptimal_curve_model.summary()","a41d2330":"optimal_curve_model.compile(loss = CategoricalCrossentropy(), optimizer = Adam(), metrics = ['accuracy'])\n\nscheduler = LearningRateScheduler(lambda epoch: 1e-4 *10 **(epoch\/20))\noptimal_history = optimal_curve_model.fit(train_data, batch_size=32, epochs=50,\n                        validation_data=val_data, callbacks=[scheduler], steps_per_epoch=len(train_data), validation_steps=int(0.25 * len(test_data)))","ddae0304":"def plot_optimal_curve(history):\n    lrs = 1e-4 * (10 ** (tf.range(50) \/ 20))\n    plt.figure(figsize=(10, 7))\n    plt.semilogx(lrs, history.history['loss'])\n    plt.ylabel('loss')\n    plt.xlabel('epochs')\n    plt.show()\n\nplot_optimal_curve(optimal_history)","b0c5362f":"train_model = cnn_model()\ntrain_model.compile(loss = BinaryCrossentropy(),\n              optimizer = Adam(lr = 0.001),\n              metrics= ['accuracy'])\n\n\n# reduceLRO = ReduceLROnPlateau(monitor = 'val_loss', factor= 0.2,\n#    plot_optimal_curve                        patience = 10, verbose=1, mode = 'auto',\n#                               min_delta=0.001, cooldown=5, min_lr=0.01\n#                               )\n\n# early_stop = EarlyStopping(monitor='val_loss', mode='min',\n#                            patience=5)\n\n# callbacks = [early_stop, reduceLRO]\n\nmodel_history = train_model.fit(train_data, batch_size= 32, epochs=30,\n                   validation_data=val_data,  steps_per_epoch=len(train_data), validation_steps=int(0.25 * len(val_data)))","3e941745":"train_model.save('cotton_cnn.h5')","86ca7b0c":"def plot_loss_acc(history):\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n\n    epochs = range(len(history.history['loss']))\n \n    plt.plot(epochs, loss, label = 'loss')\n    plt.plot(epochs, val_loss, label = 'val loss')\n    plt.title('loss')\n    plt.xlabel('epochs')\n    plt.legend();\n    plt.show()\n    \n    plt.figure()\n  \n    plt.plot(epochs, acc, label = 'train accuracy')\n    plt.plot(epochs, val_acc, label = 'validation accuracy')\n    plt.title('accuracy')\n    plt.xlabel('epochs')\n    plt.legend();\n    plt.show()\n\n","26d49ace":"plot_loss_acc(model_history)","9ac6b740":"\nmodel_eval = train_model.evaluate(test_data)\nprint(model_eval)","1ba13440":"class_names","c0388609":"def resize_image(shape, index):\n    \n    data_path = f\"{test_dir}\/{class_names[index]}\"\n    random_select = random.sample(os.listdir(data_path), 1)\n    image = tf.io.read_file(data_path + '\/' + random_select[0])\n    image = tf.image.decode_image(image)\n    image = tf.image.resize(image, size = [shape, shape])\n\n    image = image \/ 255.\n    return image\n\n# test_image = resize_image(224)","f5efd2b1":"def predict_image(model ,className, index):\n\n    test_image = resize_image(224, index)\n    pred = model.predict(tf.expand_dims((test_image), axis=0))\n    print(tf.round(pred))\n    \n    if len(pred[0]) > 1:\n      pred_class = className[pred.argmax()] \n    else:\n      pred_class = className[int(tf.round(pred)[0][0])]\n    plt.figure(figsize=(10, 7))\n    plt.imshow(test_image)\n    plt.title(f'prediction : {pred_class}')\n    plt.axis(False)\n    \n\n    plt.show()\n","0a910dac":"predict_image(train_model, class_names, 0) ","5c9371ad":"predict_image(train_model, class_names, 1)\n# this image seems like leaves have not infection but kind of looks like a curl virus.\n# you might have to inpect the diseased cotton plant directory for more clouser.","22b01a77":"predict_image(train_model, class_names, 2)","c798e1f6":"predict_image(train_model, class_names, 3)","75cf12e7":"print(tf.__version__)","57655fbb":"import tensorflow_hub as hub\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n","6d4a6e44":"#global variables\n\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCH = 25\n\ninput_shape = (224,224, 3)","a89221d3":"# data preprocessing \n\ntrain_data_tl = image_dataset_from_directory(train_dir, image_size = IMAGE_SIZE,\n                                             batch_size=BATCH_SIZE, label_mode = 'categorical')\n\nval_data_tl = image_dataset_from_directory(val_dir, image_size = IMAGE_SIZE, \n                                            batch_size = BATCH_SIZE, label_mode = 'categorical', shuffle = False)\n\ntest_data_tl = image_dataset_from_directory(test_dir, image_size = IMAGE_SIZE, \n                                            batch_size = BATCH_SIZE, label_mode = 'categorical', shuffle = False)","e33badeb":"# insert data augmentation as layer into the model, this allows us to utilize GPU for image augmentation process\n\ndata_aug =Sequential([\n    \n    preprocessing.RandomZoom(0.2),\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomHeight(0.2),\n    preprocessing.RandomWidth(0.2),\n    preprocessing.RandomRotation(0.2)\n], name = 'data_augmentation')","8fc1b6f3":"#compare original vs augmentated images\n\ndef view_augmented_image(data):\n    target_class = random.choice(data.class_names)\n    target_dir = f\"{train_dir}\/{target_class}\"\n    random_image = random.choice(os.listdir(target_dir))\n    img_path = f\"{target_dir}\/{random_image}\"\n\n    img = mpimg.imread(img_path)\n    plt.figure(figsize=(10, 7))\n    plt.title(f\" Original {target_class} image : Shape : {img.shape}\")\n    plt.axis(False)\n    plt.imshow(img)\n\n\n    aug_img = data_aug(tf.expand_dims(img, axis = 0))\n    plt.figure()\n    plt.axis(False)\n    plt.title(f\"Augmented {target_class} image\")\n    plt.imshow(tf.squeeze(aug_img)\/255.)\n","3e5653bb":"view_augmented_image(train_data_tl)","b431d4f8":"# Creating tensorboard callback in case if needed for publishing the results\n\nimport datetime\ndef tensorboard_callback(dir_name, model):\n    logs = dir_name + \"\/\" + model + \"\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n    callback = tf.keras.callbacks.TensorBoard(log_dir = logs)\n    print(f\"saved in {logs}\")\n    return callback","cc0e3ed1":"##Creating a base model using functional API\n\nbase_model_1 = tf.keras.applications.EfficientNetB0(include_top = False) \nbase_model_1.trainable = False\n\ninputs = layers.Input(shape = input_shape)\nx = data_aug(inputs)\nx = base_model_1(x, training = False)\nx = layers.GlobalAveragePooling2D()(x)\nx = Flatten()(x)\noutputs = layers.Dense(4, activation = 'softmax', name = 'output')(x)\n\nmodel_tl = tf.keras.Model(inputs , outputs)\nmodel_tl.compile(loss = CategoricalCrossentropy(), optimizer = Adam(lr = 0.001), metrics = ['accuracy'])\n\nmodel_tl.summary()","c5ecd831":"# modelcheckpoint to store weights \n\ncheckpoint_path = 'modelcheckpoint\/checkpoint.ckpt'\nckpt_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only = True, save_best_only = False,\n                                                   save_freq = 'epoch', verbose = 1)","31ea7c56":"history_tl = model_tl.fit(train_data_tl, batch_size = BATCH_SIZE, epochs = EPOCH, \n                    validation_data = val_data_tl, validation_steps = int(0.25*len(val_data_tl)), \n                    callbacks = [tensorboard_callback('tensorboard_dir','ef_net_dat_aug'), ckpt_callback])","5f6b245e":"model_tl.evaluate(val_data_tl)","9b8b39eb":"model_tl.evaluate(test_data_tl)","c90ce070":"model_tl.load_weights(checkpoint_path)","cda9f722":"loaded_weight = model_tl.evaluate(test_data_tl)","25447f04":"plot_loss_acc(history_tl)","710e446c":"# Total layers in efficeintNetB0\n\nfor i, layers in enumerate(model_tl.layers[2].layers):\n    print(i, layers.name, layers.trainable)","8674893e":"# retaining only last 10 layers in order to fine tune our model\nbase_model_1.trainable = True\n\nfor layer in base_model_1.layers[:-10]:\n    layer.trainable = False\n\nmodel_tl.compile(loss = CategoricalCrossentropy(), optimizer = Adam(lr = 0.0001), \n                metrics = ['accuracy'])\n","b2c6a095":"print(len(model_tl.trainable_variables))","25b656b5":"#training model from where we left off last time i,e from 25 epochs onwards\n\nfine_t_history = model_tl.fit(train_data_tl,batch_size = BATCH_SIZE, validation_data = val_data_tl, epochs = EPOCH + 10, validation_steps = int(0.25* len(val_data_tl)),\ninitial_epoch = history_tl.epoch[-1], callbacks = [tensorboard_callback('tensorboard_dir','fine_tune')])","0e1a8769":"fine_tune_eval = model_tl.evaluate(val_data_tl)","ad587613":"fine_tune_eval = model_tl.evaluate(test_data_tl)","b3317393":"model_tl.save('cotton-tl-classifier')","42d049f7":"\ndef compare_history(original_history, new_history, initial_epochs=5):\n    \"\"\"\n    Compares two model history objects.\n    \"\"\"\n    # Get original history measurements\n    acc = original_history.history[\"accuracy\"]\n    loss = original_history.history[\"loss\"]\n\n    val_acc = original_history.history[\"val_accuracy\"]\n    val_loss = original_history.history[\"val_loss\"]\n\n    # Combine original history with new history\n    total_acc = acc + new_history.history[\"accuracy\"]\n    total_loss = loss + new_history.history[\"loss\"]\n\n    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n    \n    # Make plots\n    plt.figure(figsize=(8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(total_acc, label='Training Accuracy')\n    plt.plot(total_val_acc, label='Validation Accuracy')\n    plt.plot([initial_epochs-1, initial_epochs-1],\n              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(total_loss, label='Training Loss')\n    plt.plot(total_val_loss, label='Validation Loss')\n    plt.plot([initial_epochs-1, initial_epochs-1],\n              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()","d17d5f83":"compare_history(history_tl, fine_t_history, 25)","5cadfbf0":"prob = model_tl.predict(test_data_tl)\ny_preds = prob.argmax(axis = 1)","37b91684":"model_tl.evaluate(test_data_tl)","abf96109":"y_labels = []\n\nfor images, labels in test_data_tl.unbatch():\n  y_labels.append(labels.numpy().argmax())\ny_labels[:10]","6e3a5751":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\naccuracy_score(y_labels, y_preds)","7255f35f":"import itertools\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n  If classes is passed, confusion matrix will be labelled, if not, integer class values\n  will be used.\n  Args:\n    y_true: Array of truth labels (must be same shape as y_pred).\n    y_pred: Array of predicted labels (must be same shape as y_true).\n    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n    figsize: Size of output figure (default=(10, 10)).\n    text_size: Size of output figure text (default=15).\n    norm: normalize values or not (default=False).\n    savefig: save confusion matrix to file (default=False).\n  \n  Returns:\n    A labelled confusion matrix plot comparing y_true and y_pred.\n  Example usage:\n    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n                          y_pred=y_preds, # predicted labels\n                          classes=class_names, # array of class label names\n                          figsize=(15, 15),\n                          text_size=10)\n  \"\"\"  \n  # Create the confustion matrix\n  cm = confusion_matrix(y_true, y_pred)\n  cm_norm = cm.astype(\"float\") \/ cm.sum(axis=1)[:, np.newaxis] # normalize it\n  n_classes = cm.shape[0] # find the number of classes we're dealing with\n\n  # Plot the figure and make it pretty\n  fig, ax = plt.subplots(figsize=figsize)\n  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n  fig.colorbar(cax)\n\n  # Are there a list of classes?\n  if classes:\n    labels = classes\n  else:\n    labels = np.arange(cm.shape[0])\n  \n  # Label the axes\n  ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes), # create enough axis slots for each class\n         yticks=np.arange(n_classes), \n         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n         yticklabels=labels)\n  \n  # Make x-axis labels appear on bottom\n  ax.xaxis.set_label_position(\"bottom\")\n  ax.xaxis.tick_bottom()\n\n\n  plt.xticks(rotation = 70, fontsize = text_size)\n  plt.yticks(fontsize = text_size)\n\n  # Set the threshold for different colors\n  threshold = (cm.max() + cm.min()) \/ 2.\n\n  # Plot the text on each cell\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    if norm:\n      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n    else:\n      plt.text(j, i, f\"{cm[i, j]}\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n\n  # Save the figure to the current working directory\n  if savefig:\n    fig.savefig(\"confusion_matrix.png\")\n  \n# Make a function to predict on images and plot them (works with multi-class)\ndef pred_and_plot(model, filename, class_names):\n  \"\"\"\n  Imports an image located at filename, makes a prediction on it with\n  a trained model and plots the image with the predicted class as the title.\n  \"\"\"\n  # Import the target image and preprocess it\n  img = load_and_prep_image(filename)\n\n  # Make a prediction\n  pred = model.predict(tf.expand_dims(img, axis=0))\n\n  # Get the predicted class\n  if len(pred[0]) > 1: # check for multi-class\n    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n  else:\n    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n\n  # Plot the image and predicted class\n  plt.imshow(img)\n  plt.title(f\"Prediction: {pred_class}\")\n  plt.axis(False);","81ffdc8c":"class_names = test_data_tl.class_names\n\nimport numpy as np\nmake_confusion_matrix(y_labels, y_preds, class_names)","294bdc18":"print(classification_report(y_labels, y_preds))","b89c06bf":"def transform_img(filename, image_shape = 224, scale = True):\n  img = tf.io.read_file(filename)\n\n  img = tf.io.decode_image(img, channels = 3)\n  img = tf.image.resize(img, [image_shape, image_shape])\n\n  if scale:\n\n    return img \/ 255.\n  \n  else: \n    return img","0568d8ed":"plt.figure(figsize = (17,10))\n\nfor i in range(3):\n  class_name = random.choice(class_names)\n  filename = random.choice(os.listdir(test_dir +'\/' + class_name))\n  filepath = test_dir +class_name + '\/' + filename\n  print(filepath)\n\n  img = transform_img(filepath, scale = False)\n\n  pred_prob = model_tl.predict(tf.expand_dims(img, axis = 0))\n  pred_class = class_names[pred_prob.argmax()]\n\n  plt.subplot(1, 3, i+1)\n\n  plt.imshow(img\/255.)\n\n  if class_name == pred_class:\n    title_color = 'g'\n  else:\n    title_color = 'r'\n\n  plt.title( f\"actual : {class_name}, \\n predicted : {pred_class}, \\n probaility : {pred_prob.max():.2f}\", c = title_color)\n  plt.axis(False);\n","e6755a8a":"## 1. Data Overview\n---------\n- ### Data contains 4 classes __*'diseased cotton leaf', 'diseased cotton plant','fresh cotton leaf', 'fresh cotton plant'*__ and each class contains 3 subclasses for ***train, test and validation data***\n--------","14e546b0":"# 4. Predictions\n-----------","4e893cb9":"## 3. Modelling \n---------\n### 3.1 Find learning curve\n- ### *cnn_model* defines the CNN structure which is used for classification purposes\n- ### First, the ***LearningRateScheduler()*** callback function is used to find the optimal learning curve of the cnn_model.\n- ### It allows us to understand how and at what rate the model is learning, later we can tweak the learning rate values.  \n--------","80bb7505":"#### WOW!! It just took a huge detour after ***lr = 0.001***\n-----------","52f4b6e8":"# Cotton Leaf Disease Classifier\n\n## **Alright!! Lets do it in a way that everyone could understand**","36c5b576":"# Transfer Learning and Feature Extraction","3fad4282":"# 3 Model Evaluation\n------------\n- ### Lets plot the curves and see how our model has performed  \n------","496ad693":"## 2. Data preparation\n---------\n- ### Following function transforms train_data into an *augmented data* while test and validation data is only *rescaled* \n--------","453ac410":"---------\n- ### Lets take a look at radom images from each class\n--------"}}