{"cell_type":{"54e1ed57":"code","ef1cd2dd":"code","931735c5":"code","88101a76":"code","63c6aa7b":"code","485d6f38":"code","d6ac2476":"code","20093937":"code","a3079136":"code","b8eb1b88":"code","cfb52917":"code","bb9a2c9a":"code","ae01d4f3":"code","fcca4cda":"code","43e689cf":"code","3657404a":"code","6b52df8a":"code","7696643f":"code","396cd70b":"code","1abbc49a":"code","23fa9043":"code","ba613b0b":"code","8b2c81ac":"code","2a3def81":"code","82b52050":"code","f0c070f7":"code","e6215463":"code","3a44e3c1":"code","272dbd43":"code","af1e7c3d":"markdown","ac9be9f2":"markdown"},"source":{"54e1ed57":"import pandas as pd\nimport numpy as np","ef1cd2dd":"DF = pd.read_csv('..\/input\/predicting-a-pulsar-star\/pulsar_stars.csv')\nDF.head()","931735c5":"DF.info()","88101a76":"DF.describe()","63c6aa7b":"np.unique(DF['target_class'])","485d6f38":"Features = DF.columns[:-1]\nLabel = DF.columns[-1]","d6ac2476":"X = DF[Features].values\ny = DF[Label].values","20093937":"X.shape","a3079136":"y.shape","b8eb1b88":"y.shape","cfb52917":"from sklearn.model_selection import train_test_split as tts\nX_train,X_test,y_train,y_test = tts(X,y,stratify=y,random_state =1,test_size=0.2)","bb9a2c9a":"from sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.base import clone\ndef My_pipe(estimator,Compression = True):\n    if Compression:\n        return make_pipeline(StandardScaler(),\n                        PCA(n_jobs = 2),\n                            clone(estimator))\n    return make_pipeline(StandardScaler(),\n                            clone(estimator))","ae01d4f3":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nLr = LogisticRegression(random_state=1,max_iter=10000,solver='liblinear',C=10)\nLr_pipe = My_pipe(estimator=Lr,Compression=False)","fcca4cda":"scores = cross_val_score(estimator=Lr_pipe,X=X_train,y=y_train,cv=10,scoring='f1')","43e689cf":"print(scores.mean(),' +\/- ',scores.std())","3657404a":"from sklearn.svm import SVC\nsv  =SVC(random_state=1,kernel='linear')\nsvc_pipe = My_pipe(estimator=sv,Compression=False)","6b52df8a":"scores = cross_val_score(estimator=svc_pipe,X=X_train,y=y_train,cv=10,scoring='f1')","7696643f":"print(scores.mean(),scores.std())","396cd70b":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=1,n_estimators=100)\nforest_pipe = My_pipe(estimator=rfc,Compression=False)","1abbc49a":"scores_forest = cross_val_score(estimator=forest_pipe,X=X_train,y=y_train,cv=10,scoring='f1',n_jobs=-1)","23fa9043":"print(scores_forest.mean(),' +\/- ',scores_forest.std())","ba613b0b":"forest_pipe.fit(X_train,y_train)","8b2c81ac":"y_train_pred = forest_pipe.predict(X_train)\ny_pred_test = forest_pipe.predict(X_test)","2a3def81":"from sklearn.metrics import f1_score\nf1_train_1 = f1_score(y_pred=y_train_pred,y_true=y_train,pos_label=1)\nf1_test_1 = f1_score(y_pred=y_pred_test,y_true=y_test,pos_label=1)","82b52050":"print('train : ' ,f1_train_1)\nprint('test : ',f1_test_1)","f0c070f7":"f1_train_0 = f1_score(y_pred=y_train_pred,y_true=y_train,pos_label=0)\nf1_test_0 = f1_score(y_pred=y_pred_test,y_true=y_test,pos_label=0)","e6215463":"print('train : ' ,f1_train_0)\nprint('test : ',f1_test_0)","3a44e3c1":"N_train_1 = X_train[y_train==1].shape[0]\nn_test_1 = X_test[y_test==1].shape[0]\nf1_avg_train = (N_train_1*(f1_train_1) +(X_train.shape[0]-N_train_1)*f1_train_0)\/X_train.shape[0]\nf1_avg_test = (n_test_1*(f1_test_1) +(X_test.shape[0]-n_test_1)*f1_test_0)\/X_test.shape[0]","272dbd43":"print('f1 avg train :',(f1_avg_train))\nprint('f1 avg test :',(f1_avg_test))","af1e7c3d":"*I'm not going do any visualizations here, and there is not much preprocessing *\n<p> F1 score is a good metric when dealing with unbalanced labels<\/p>\n*Micro, and macro metrics are also good but i'm going to consider only f1 score *\n\n<p> This is my first kaggle kernel so please don't expect a detailed explanation <\/p>","ac9be9f2":"So random_forest with 100 trees is the good estimator\n<p> The reason to choose Random forest is cz of its performance after doing 10 fold cross validation<\/p> "}}