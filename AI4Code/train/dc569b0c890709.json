{"cell_type":{"783beb92":"code","64d49f2c":"code","45b96411":"code","a7dc9a9d":"code","aed84785":"code","7c1b721d":"code","c2f5987a":"code","ed94b47d":"code","e5e34e0e":"code","a5d76988":"code","9989fae8":"code","bd5a85c8":"code","272aeb82":"code","3f9ab73f":"code","4b535ef3":"code","6922ffd4":"code","b7fc7094":"code","dc9fa06b":"code","6e85eb09":"code","1fa96e88":"code","5c718b31":"code","a2f507f8":"code","8e906b4c":"code","b097d371":"code","a315f821":"markdown","78cbae45":"markdown","63964f69":"markdown","ec29eb27":"markdown","3fdd0d5e":"markdown","642b7dd2":"markdown","d3d48a3a":"markdown","7260e891":"markdown","fccfb0b6":"markdown","3c8d89c2":"markdown"},"source":{"783beb92":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tabulate import tabulate \nfrom sklearn.model_selection import GridSearchCV\nplt.style.use('dark_background')","64d49f2c":"dataset = pd.read_csv(\"..\/input\/diabetes-classification-problem\/kaggle_diabetes.csv\")","45b96411":"dataset.head(10)","a7dc9a9d":"dataset.tail(10)","aed84785":"dataset.info()","7c1b721d":"dataset.describe()","c2f5987a":"dataset[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = dataset[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)","ed94b47d":"p = dataset.hist(figsize = (10,10))\n#Finding the distribution of the data for normal distribution we use mean for nan values and for skewed data we use median","e5e34e0e":"dataset['Glucose'].fillna(dataset['Glucose'].mean(), inplace = True)\ndataset['BloodPressure'].fillna(dataset['BloodPressure'].mean(), inplace = True)\ndataset['SkinThickness'].fillna(dataset['SkinThickness'].median(), inplace = True)\ndataset['Insulin'].fillna(dataset['Insulin'].median(), inplace = True)\ndataset['BMI'].fillna(dataset['BMI'].median(), inplace = True)","a5d76988":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(dataset.corr(), annot=True)  # seaborn has very simple solution for heatmap","9989fae8":"dataset[['Age', 'Outcome']].groupby(['Outcome'], as_index=False).mean().sort_values(by='Outcome', ascending=False)","bd5a85c8":"dataset[['Pregnancies', 'Outcome']].groupby(['Outcome'], as_index=False).mean().sort_values(by='Outcome', ascending=False).round().astype(int)","272aeb82":"g = sns.FacetGrid(dataset, col='Outcome')\ng.map(plt.hist, 'Age', bins=20)","3f9ab73f":"g = sns.FacetGrid(dataset, col='Outcome')\ng.map(plt.hist, 'Pregnancies', bins=15)","4b535ef3":"g = sns.FacetGrid(dataset, col='Outcome')\ng.map(plt.hist, 'DiabetesPedigreeFunction', bins=10)","6922ffd4":"g = sns.FacetGrid(dataset, col='Outcome')\ng.map(plt.hist, 'Glucose', bins=15)","b7fc7094":"X = dataset.iloc[:,:-1]\ny = dataset.iloc[:,-1]\n#Import Libraries\nfrom sklearn.preprocessing import StandardScaler\n#----------------------------------------------------\n#Standard Scaler for Data\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(X)","dc9fa06b":"from sklearn.model_selection import train_test_split\nX_train ,X_test , y_train , y_test = train_test_split(X,y , test_size = 0.2 , random_state = 42)","6e85eb09":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(solver = \"liblinear\" , max_iter = 200)\nclassifier.fit(X_train, y_train)\nprint(\"logistic regression training score is \" + str(classifier.score(X_train , y_train)))\nprint(\"logistic regression test score is \" + str(classifier.score(X_test , y_test)))\nprint('----------------------------------------------------')\n# Making the Confusion Matrix\naccuracy = classifier.score(X_test , y_test)\nfrom sklearn.model_selection import GridSearchCV\nparameters = [{'C': [1, 10, 100], 'solver': ['liblinear'] , 'max_iter' :range(100,1000,100)},\n              {'C': [1, 10, 100], 'solver': ['sag'] , 'max_iter' : range(100,1000,100)}]\ngrid_search = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search = grid_search.fit(X_train, y_train)\naccuracy = grid_search.best_score_\n\nfrom sklearn.metrics import confusion_matrix\ny_pred = grid_search.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(5,5))\np=sns.heatmap(cm, annot=True)\n\nprint(accuracy)\nprint(grid_search.best_params_)\n\nprint(\"logistic regression training score is \" , grid_search.score(X_train , y_train))\nprint(\"logistic regression test score is \" , grid_search.score(X_test , y_test))\nprint('----------------------------------------------------')\nLogisticregressionscoretraining = grid_search.score(X_train , y_train)\nLogisticregressionscoretest = grid_search.score(X_test , y_test)","1fa96e88":"#Import Libraries\nfrom sklearn.neural_network import MLPClassifier\n#----------------------------------------------------\n#Applying MLPClassifier Model \nMLPClassifierModel = MLPClassifier(activation='tanh',\n                                   solver='lbfgs',  \n                                   learning_rate='constant',\n                                   early_stopping= False,\n                                   alpha=0.0001 ,hidden_layer_sizes=(256,128,64,32,16),random_state=33 , max_iter=800)\nMLPClassifierModel.fit(X_train, y_train)\n#Calculating Details\nprint('MLPClassifierModel Train Score is : ' , MLPClassifierModel.score(X_train, y_train))\nprint('MLPClassifierModel Test Score is : ' , MLPClassifierModel.score(X_test, y_test))\nMLPClassifierModelTrainScore =  MLPClassifierModel.score(X_train, y_train)\nMLPClassifierModelTestScore = MLPClassifierModel.score(X_test, y_test)","5c718b31":"#Import Libraries\nfrom sklearn.svm import SVC\nSVCModel = SVC(kernel= 'rbf')\nSVCModel.fit(X_train, y_train)\n#Calculating Details\nprint('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))\nprint('----------------------------------------------------')\naccuracy = SVCModel.score(X_test, y_test)\nparameters = [{'C': [1, 10, 100], 'kernel': ['linear'] },\n              {'C': [1, 10, 100], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\ngrid_search = GridSearchCV(estimator = SVCModel,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\n\ngrid_search = grid_search.fit(X_train, y_train)\naccuracy = grid_search.best_score_\n\n\ny_pred = grid_search.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(5,5))\np=sns.heatmap(cm, annot=True)\n\nprint(accuracy)\nprint(grid_search.best_params_)\nprint('SVCModel Train Score is : ' , grid_search.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , grid_search.score(X_test, y_test))\nprint('----------------------------------------------------')\nSVCModelscoretraining = grid_search.score(X_train, y_train)\nSVCModelscoretest = grid_search.score(X_test, y_test)","a2f507f8":"#Import Libraries\nfrom sklearn.naive_bayes import GaussianNB\nGaussianNBModel = GaussianNB()\nGaussianNBModel.fit(X_train, y_train)\nprint('GaussianNBModel Train Score is : ' , GaussianNBModel.score(X_train, y_train))\nprint('GaussianNBModel Test Score is : ' , GaussianNBModel.score(X_test, y_test))\nprint('----------------------------------------------------')\nGaussianNBModelscoretrain = GaussianNBModel.score(X_train, y_train)\nGaussianNBModelscoretest = GaussianNBModel.score(X_test, y_test)","8e906b4c":"#Import Libraries\nfrom sklearn.neighbors import KNeighborsClassifier\nKNeighborsClassifierModel = KNeighborsClassifier(n_neighbors = 1, weights='uniform',\n                                               algorithm = 'auto')    \nKNeighborsClassifierModel.fit(X_train, y_train)\nprint('KNeighborsclassifierModel Train Score is : ' , KNeighborsClassifierModel.score(X_train, y_train))\nprint('KNeighborsclassifierModel Test Score is : ' , KNeighborsClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')\nKNeighborsClassifierModelscoretraining = KNeighborsClassifierModel.score(X_train, y_train)\nKNeighborsClassifierModelscoretest = KNeighborsClassifierModel.score(X_test, y_test)","b097d371":"models = pd.DataFrame({\n                          'Model': ['logistic regression ',\n                                    'KNN', \n                                    'Naive Bayes', \n                                    'Linear SVC', \n                                    'Neural networks'],\n                       \n                          'Scoretrain': [Logisticregressionscoretraining, \n                                         KNeighborsClassifierModelscoretraining, \n                                         GaussianNBModelscoretrain, \n                                         SVCModelscoretraining, \n                                         MLPClassifierModelTrainScore],\n                       \n                             'scoretest':[Logisticregressionscoretest,\n                                          KNeighborsClassifierModelscoretest,\n                                         GaussianNBModelscoretest,\n                                          SVCModelscoretest,\n                                          MLPClassifierModelTestScore]})\nprint(\"SVC showed the best score with both training set and test set\")               \nprint(tabulate(models , headers = ['Model' , 'Train' , 'Test'] , tablefmt = 'psql' , showindex =False)) ","a315f821":"## **Scaling the data**","78cbae45":"## **Applying KNN**","63964f69":"# **Importing the data**","ec29eb27":"# **Importing libraries**","3fdd0d5e":"## **Splitting the data**","642b7dd2":"## **Applying Naive Bayes**\n","d3d48a3a":"## **Applying neural networks**","7260e891":"## **Applying Logistic Regression**","fccfb0b6":"## **Applying support vector classification**","3c8d89c2":"## **Comparing all algorithms**"}}