{"cell_type":{"39c7782e":"code","5e01806a":"code","e8a55446":"code","36ac9a4e":"code","de901290":"code","65552eb8":"code","3db5b182":"code","5c81a3b0":"code","bc35a71b":"code","c60d8f83":"code","1f752f02":"code","20c75d43":"code","20606df5":"code","6c0f788f":"code","41b9598c":"code","7b97649c":"code","437e8d26":"code","5919a75f":"code","3374cc4c":"code","64ea207a":"code","7fd25e95":"code","99e68c59":"code","a63b9264":"code","941360b0":"code","20d33eaf":"markdown","432f83c3":"markdown","d796e9ea":"markdown","cca6695c":"markdown","c9dd3091":"markdown","cafcf14a":"markdown","37a2e6bf":"markdown"},"source":{"39c7782e":"import pandas as pd\nimport os\nimport zipfile\nprint(os.listdir(\"..\/input\/dogs-vs-cats\"))\nimport tensorflow as tf\n\n\n#For splitting the dataset in test and val sets\nfrom sklearn.model_selection import train_test_split\n\n#For use of Keras Squence class that allows the load of batches\nfrom skimage.io import imread\nfrom skimage.transform import resize\nimport numpy as np\nimport math\n\n#For plot the images and graphs\n#pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n#magic function that work much like OS command-line calls\n%matplotlib inline \n#with this backend, the output of plotting commands is displayed inline within frontends like Jupyter notebooks, directly below the code cell that produced it\nimport seaborn as sns\nimport random\n\n#For metrics\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import (precision_recall_curve, PrecisionRecallDisplay)\n\n#For tensorflow dataset\nimport tensorflow_datasets as tfds","5e01806a":"#TFDS - download the data and save it as tfrecord files\n(tfds_train, tfds_test), ds_info = tfds.load(\n    'cats_vs_dogs',\n    split=['train', 'train'],\n    shuffle_files=True, #shuffles files during training\n    as_supervised=True, #memorizes files as tuple rather than dict (default)\n    with_info=True,\n)","e8a55446":"def normalize_img(image, label):\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n  return tf.cast(image, tf.float32) \/ 255., label\n\ntfds_train = tfds_train.map(\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntfds_train = tfds_train.cache()\ntfds_train = tfds_train.shuffle(ds_info.splits['train'].num_examples)\ntfds_train = tfds_train.batch(128)\ntfds_train = tfds_train.prefetch(tf.data.experimental.AUTOTUNE)\n","36ac9a4e":"tfds_test = tfds_test.map(\n    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntfds_test = tfds_test.batch(128)\ntfds_test = tfds_test.cache()\ntfds_test = tfds_test.prefetch(tf.data.experimental.AUTOTUNE)","de901290":"with zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n\n    \nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \ntrain_path = \"\/kaggle\/working\/train\"\ntrain_filenames = os.listdir(train_path)\nprint(train_filenames[:5])\n\n\ntrain_labels = []\nfor filename in train_filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        train_labels.append(1)\n    else:\n        train_labels.append(0)\n","65552eb8":"train_df = pd.DataFrame({\n    'filename': [train_path+'\/'+filename for filename in train_filenames],\n    'category': train_labels\n})\n\ntype(train_df)\n","3db5b182":"train_df.head()","5c81a3b0":"train_df.tail()","bc35a71b":"#Reduce the df for do some tests\ntrain_df = train_df[0:12000]\ntrain_df.shape","c60d8f83":"train_df['category'].value_counts().plot.bar()","1f752f02":"w=10\nh=10\nfig=plt.figure(figsize=(12, 12))\ncolumns = 3\nrows = 3\nfor i in range(1, columns*rows +1):\n    sample = imread(train_df['filename'][i])\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(sample)\nplt.show()","20c75d43":"train_df.info()","20606df5":"# Splitting in train set e validation set\ntrain_df, valid_df = train_test_split(train_df, test_size=0.2)","6c0f788f":"import tensorflow \nfrom tensorflow.keras import utils\nfrom keras.utils import Sequence\n\n#Use of Keras Sequence for extraction of mini-batches from dataset\nclass DFTOBATCHSequence(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return math.ceil(len(self.x) \/ self.batch_size)\n\n# This method __getitem__ returns a batch in numpy array format\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n\n        return np.array([\n            resize(imread(file_name), (128, 128))\n               for file_name in batch_x]), np.array(batch_y)\n\n    \n    \n#Use of Keras Sequence for extraction labels of mini-batches from dataset\nclass PREDICTSequence(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return math.ceil(len(self.x) \/ self.batch_size)\n\n# This method __getitem__ returns a batch in numpy array format without labels\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n\n        return np.array([\n            resize(imread(file_name), (128, 128))\n               for file_name in batch_x])","41b9598c":"train_x = train_df.filename\ntrain_y = train_df.category\n\n\nprint(train_y.shape)\ntrain_y = np.asarray(train_y).astype('float32').reshape((-1,1)) \nprint(train_y.shape)\n\nval_x = valid_df.filename\nval_y = valid_df.category\n\n\nprint(val_y.shape)\nval_y = np.asarray(val_y).astype('float32').reshape((-1,1)) \nprint(val_y.shape)\n\nbatch_size = 15\n\nds_train = DFTOBATCHSequence(train_x, train_y, batch_size)\nds_val = DFTOBATCHSequence(val_x, val_y, batch_size)\n\nds_train_ = PREDICTSequence(train_x, train_y, batch_size)","7b97649c":"ds_train.__getitem__(0)","437e8d26":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras import layers, callbacks\n\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.0001, # minimium amount of change to count as an improvement\n    patience=2, # how many epochs to wait before stopping\n    restore_best_weights=True, \n)\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding='valid', activation='relu', input_shape=(128, 128, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid')) # 1 or 2? because we have cat and dog classes\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n\nmodel.summary()","5919a75f":"# Method fit is called for 500 epochs on the training dataset and use the callbacks for stop when there is no improvement of val_loss\nhisotry = model.fit(ds_train,\n                    validation_data=ds_val,\n                    epochs=30,\n                    callbacks=[early_stopping], # callbacks are put in a list\n                    )","3374cc4c":"#Evaluation of the model performance\nhistory_frame = pd.DataFrame(hisotry.history)\nhistory_frame.head()","64ea207a":"sns.lineplot(data=history_frame.loc[:, ['loss', 'val_loss']])\nplt.title(\"Loss Function on training set and validation set\")\nplt.xlabel(\"Epochs\")\n\n#history_frame.loc[:, ['loss', 'val_loss']].plot()\n#history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","7fd25e95":"sns.lineplot(data=history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']])\nplt.title(\"Accuracy on training set and validation set\")\nplt.xlabel(\"Epochs\")","99e68c59":"#Predictions by fitted model\ny_predict = model.predict(ds_train_)","a63b9264":"#Confusion Matrix\ncm = confusion_matrix(train_y, y_predict.round())\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot() ","941360b0":"#Precision and Recall\nprecision, recall, thresholds = precision_recall_curve(train_y, y_predict)\ndisp = PrecisionRecallDisplay(precision=precision, recall=recall)\ndisp.plot()","20d33eaf":"<img src=\"attachment:directory.JPG\" width=\"280px\">","432f83c3":"# See sample image","d796e9ea":"As we can see the distributions are balanced.","cca6695c":"# Prepare Training Data","c9dd3091":"# **Import Library**","cafcf14a":"# With Keras Sequence","37a2e6bf":"# With TFDS"}}