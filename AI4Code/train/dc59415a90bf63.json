{"cell_type":{"f3220c42":"code","cc372d14":"code","29c135bd":"code","77d12fd0":"code","9d371410":"code","80fdd200":"code","d1275227":"code","7ad7732a":"code","960e8528":"code","2353c8aa":"code","967361f5":"code","bf9c77ec":"code","f793a680":"code","06380963":"code","5cb67db9":"code","4ac1d62d":"code","063de30a":"code","2ca145f8":"code","d3cbbe14":"code","07a17ae7":"code","6880fa89":"code","11662642":"code","6fbf54d0":"code","a88bff3c":"code","bbe416e3":"code","21b4df31":"code","7025c929":"code","88011c76":"code","45d0cdea":"code","c204fc30":"code","e76b73c0":"code","4e6293b1":"code","ff38d66d":"code","cf8cd6aa":"code","7629c069":"code","ce94766d":"code","84da5ea4":"code","32bc44db":"code","1afed1a6":"code","5bbe627c":"code","a63f42a4":"code","dea44c85":"code","cce55463":"code","9edefcfa":"code","2d9c4615":"code","3101e2af":"code","8289c21a":"code","906aa0a4":"code","3f8556e7":"code","cd513648":"code","1585abcc":"code","29a4de52":"code","1bfef925":"code","a50c79a4":"code","c661f853":"markdown","20103671":"markdown","f75d3514":"markdown","be126093":"markdown","e6ab2360":"markdown","87590d8b":"markdown","ddc30737":"markdown","3c1a1e64":"markdown","5540f675":"markdown","08bdfb16":"markdown","880d951c":"markdown","27b28597":"markdown","6bf83167":"markdown","52040fb1":"markdown","6143e450":"markdown","e26e02d1":"markdown","f451607e":"markdown","f62c9843":"markdown","4c332ea0":"markdown","3d23e735":"markdown","1543f122":"markdown","cb749cfe":"markdown","18cd449c":"markdown","4dac128e":"markdown","d9f00a13":"markdown","ec0e4fe2":"markdown","b877f260":"markdown","b23ca96d":"markdown","9818d875":"markdown","eae9d755":"markdown","67b05a3c":"markdown","aa79ad47":"markdown","b34e72a0":"markdown","b959d2c3":"markdown","1fdfd20f":"markdown","79e6d934":"markdown","862b8604":"markdown","da79aa0b":"markdown","4fafffee":"markdown","470cc587":"markdown","c60507d3":"markdown","f2bdc0fb":"markdown","51463da5":"markdown"},"source":{"f3220c42":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","cc372d14":"import os\nimport os.path\nfrom pathlib import Path\nimport glob","29c135bd":"from PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","77d12fd0":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers","9d371410":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve","80fdd200":"from keras.optimizers import RMSprop,Adam,Optimizer","d1275227":"from tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19","7ad7732a":"from warnings import filterwarnings\n\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","960e8528":"Brain_CT_Path = Path(\"..\/input\/brain-ct-hemorrhage-dataset\/Data\")","2353c8aa":"JPG_Path = list(Brain_CT_Path.glob(r\"**\/*.jpg\"))","967361f5":"JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],JPG_Path))","bf9c77ec":"JPG_Path_Series = pd.Series(JPG_Path,name=\"JPG\").astype(str)","f793a680":"JPG_Labels_Series = pd.Series(JPG_Labels,name=\"CATEGORY\")","06380963":"Main_Data = pd.concat([JPG_Path_Series,JPG_Labels_Series],axis=1)","5cb67db9":"print(Main_Data.head(-1))","4ac1d62d":"Main_Data[\"CATEGORY\"].replace({\"11[11]\":\"Hemorrhage\",\"11[11]\":\"Hemorrhage\",\"12[12]\":\"Hemorrhage\",\"13[13]\":\"Hemorrhage\",\n                               \"14[14]\":\"Hemorrhage\",\"15[15]\":\"Hemorrhage\",\"17[17]__\":\"Hemorrhage\",\n                               \"19[19]\":\"Hemorrhage\",\"1[1]\":\"Hemorrhage\",\"20[20]_2\":\"Hemorrhage\",\n                               \"21[21] _2\":\"Hemorrhage\",\"2[2]\":\"Hemorrhage\",\"3[3]\":\"Hemorrhage\",\"4[4]\":\"Hemorrhage\",\"5[5]\":\"Hemorrhage\",\n                               \"6[6]\":\"Hemorrhage\",\"7[7]\":\"Hemorrhage\",\"8[8]\":\"Hemorrhage\",\"9[9]\":\"Hemorrhage\"},inplace=True)","063de30a":"Main_Data[\"CATEGORY\"].replace({\"N10[N10]\":\"Normal\",\"N11[N11]\":\"Normal\",\"N12[N12]\":\"Normal\",\"N13[N13]\":\"Normal\",\"N14[N14]\":\"Normal\",\n                               \"N15[N15]\":\"Normal\",\"N15[N15]\":\"Normal\",\n                               \"N16[N16]\":\"Normal\",\"N17[N17]\":\"Normal\",\"N18[N18]\":\"Normal\",\n                               \"N19[N19]\":\"Normal\",\"N1[N1]\":\"Normal\",\"N20[N20]\":\"Normal\",\"N21[N21]\":\"Normal\",\n                               \"N22[N22]\":\"Normal\",\"N23[N23]\":\"Normal\",\"N24[N24]\":\"Normal\",\n                               \"N25[N25]\":\"Normal\",\"N26[N26]\":\"Normal\",\"N27[N27]\":\"Normal\",\"N2[N2]\":\"Normal\",\n                               \"N3[N3]\":\"Normal\",\"N4[N4]\":\"Normal\",\"N5[N5]\":\"Normal\",\n                               \"N6[N6]\":\"Normal\",\"N7[N7]\":\"Normal\",\"N8[N8]\":\"Normal\",\"N9[N9]\":\"Normal\"},inplace=True)","2ca145f8":"print(Main_Data.head(-1))","d3cbbe14":"print(Main_Data[\"CATEGORY\"].value_counts())","07a17ae7":"Main_Data = Main_Data.sample(frac=1).reset_index(drop=True)","6880fa89":"print(Main_Data.head(-1))","11662642":"plt.style.use('dark_background')","6fbf54d0":"sns.countplot(Main_Data[\"CATEGORY\"])\nplt.show()","a88bff3c":"Main_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","bbe416e3":"sns.histplot(Main_Data['CATEGORY'].index)\nplt.show()","21b4df31":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Data[\"JPG\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Data[\"CATEGORY\"][0])","7025c929":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Data[\"JPG\"][25])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Data[\"CATEGORY\"][6769])","88011c76":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Data[\"JPG\"][i]))\n    ax.set_title(Main_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","45d0cdea":"Train_Data,Test_Data = train_test_split(Main_Data,train_size=0.9,shuffle=True,random_state=42)","c204fc30":"print(\"TRAIN SHAPE: \",Train_Data.shape)\nprint(\"TEST SHAPE: \",Test_Data.shape)","e76b73c0":"print(Train_Data.head(-1))\nprint(\"----\"*20)\nprint(Test_Data.head(-1))","4e6293b1":"Generator = ImageDataGenerator(rescale=1.\/255,\n                               zoom_range=0.2,\n                              shear_range=0.2,\n                              rotation_range=40,\n                              horizontal_flip=True,\n                               fill_mode=\"nearest\",\n                              validation_split=0.1)","ff38d66d":"Test_Generator = ImageDataGenerator(rescale=1.\/255)","cf8cd6aa":"example_Image = Train_Data[\"JPG\"][99]\nLoad_Image = image.load_img(example_Image,target_size=(200,200))\nArray_Image = image.img_to_array(Load_Image)\nArray_Image = Array_Image.reshape((1,) + Array_Image.shape)\n\ni = 0\nfor batch in Generator.flow(Array_Image,batch_size=1):\n    plt.figure(i)\n    IMG = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\nplt.show()","7629c069":"Train_IMG_Set = Generator.flow_from_dataframe(dataframe=Train_Data,\n                                             x_col=\"JPG\",\n                                             y_col=\"CATEGORY\",\n                                             color_mode=\"grayscale\",\n                                             class_mode=\"categorical\",\n                                             subset=\"training\")","ce94766d":"Validation_IMG_Set = Generator.flow_from_dataframe(dataframe=Train_Data,\n                                                  x_col=\"JPG\",\n                                                  y_col=\"CATEGORY\",\n                                                  color_mode=\"grayscale\",\n                                                  class_mode=\"categorical\",\n                                                  subset=\"validation\")","84da5ea4":"Test_IMG_Set = Generator.flow_from_dataframe(dataframe=Test_Data,\n                                                 x_col=\"JPG\",\n                                                 y_col=\"CATEGORY\",\n                                                 color_mode=\"grayscale\",\n                                                 class_mode=\"categorical\")","32bc44db":"for data_batch,label_batch in Train_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","1afed1a6":"for data_batch,label_batch in Validation_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","5bbe627c":"print(\"TRAIN: \")\nprint(Train_IMG_Set.class_indices)\nprint(Train_IMG_Set.classes[0:5])\nprint(Train_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_IMG_Set.class_indices)\nprint(Validation_IMG_Set.classes[0:5])\nprint(Validation_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")","a63f42a4":"print(Test_IMG_Set.batch_size)\nprint(Test_IMG_Set.image_shape)","dea44c85":"Model = Sequential()\n\nModel.add(Conv2D(12,(3,3),activation=\"relu\",\n                 input_shape=(256,256,1)))\nModel.add(BatchNormalization())\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(24,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.2))\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(64,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.5))\nModel.add(MaxPooling2D((2,2)))\n\n\n#\nModel.add(TimeDistributed(Flatten()))\nModel.add(Bidirectional(LSTM(32,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\nModel.add(Bidirectional(GRU(32,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\n\n#\nModel.add(Flatten())\nModel.add(Dense(256,activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(Dense(2,activation=\"softmax\"))","cce55463":"Call_Back = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=5,mode=\"min\")","9edefcfa":"Model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","2d9c4615":"CNN_Model = Model.fit(Train_IMG_Set,\n                      validation_data=Validation_IMG_Set,\n                            callbacks=Call_Back,\n                      epochs=50)","3101e2af":"Model_Results = Model.evaluate(Test_IMG_Set,verbose=False)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])","8289c21a":"print(Model.summary())","906aa0a4":"plt.plot(CNN_Model.history[\"accuracy\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","3f8556e7":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","cd513648":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"accuracy\"])\nplt.ylabel(\"LOSS - ACCURACY\")\nplt.legend()\nplt.show()","1585abcc":"plt.plot(CNN_Model.history[\"val_loss\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"VAL LOSS - VAL ACCURACY\")\nplt.legend()\nplt.show()","29a4de52":"Dict_Summary = pd.DataFrame(CNN_Model.history)\nDict_Summary.plot()\n","1bfef925":"Prediction = Model.predict(Test_IMG_Set)\nPrediction = Prediction.argmax(axis=-1)","a50c79a4":"fig, axes = plt.subplots(nrows=5,\n                         ncols=5,\n                         figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Test_Data[\"JPG\"].iloc[i]))\n    ax.set_title(f\"PREDICTION:{Prediction[i]}\")\nplt.tight_layout()\nplt.show()","c661f853":"Loss Function We Used:\n\n\n![](https:\/\/gombru.github.io\/assets\/cross_entropy_loss\/intro.png)","20103671":"# LABEL","f75d3514":"#### OPTIMIZER","be126093":"* LSTM and GRU are iterative layers","e6ab2360":"* file path is determined","87590d8b":"* we don't need diversification for test data, we will use it as it is","ddc30737":"* less problem of gradient disappearance in LSTM and GRU","3c1a1e64":"# PATH","5540f675":"#### IGNORING WARNINGS","08bdfb16":"# TRANSFORMATION TO SERIES","880d951c":"# CNN STRUCTURE WITH LSTM \/ RCNN","27b28597":"* we used it with Dropout so that the model does not shift to overfitting orientation\n* we made return_success True because we wanted each process to generate output separately","6bf83167":"* it is converted to DataFrame","52040fb1":"* we wanted the training of the model to stop where the loss value is minimal","6143e450":"#### MODEL LAYERS","e26e02d1":"#### GENERAL","f451607e":"# VISUALIZATION","f62c9843":"* we used LSTM and GRU layers both with fully-connetted layers and Conv2D\n* RCNN structure is created in this way\n* we determined the LSTM and GRU layers as bidirectional","4c332ea0":"# TRANSFORMATION TO DATAFRAME","3d23e735":"* it is converted to Series structure before it is converted to DataFrame","1543f122":"# SHUFFLING","cb749cfe":"* LSTM and GRU serve to inject past information into the future, thereby reducing the gradient destruction problem","18cd449c":"* Activation Function:\n\n![](http:\/\/rasbt.github.io\/mlxtend\/user_guide\/general_concepts\/activation-functions_files\/activation-functions.png)","4dac128e":"* the categories of the images are separated","d9f00a13":"#### SCALER & TRANSFORMATION","ec0e4fe2":"#### How Generator Applied Image Look Like","b877f260":"#### PREDICTION","b23ca96d":"#### ACCURACY CONTROL","9818d875":"* we divided it into test and training set\n* we set the shuffle parameter to True for training quality\n* we told it to use the same data as random state","eae9d755":"#### APPLYING GENERATOR AND TRANSFORMATION TO TENSOR","67b05a3c":"* we used diversification so that the model does not shift to the overfitting orientation","aa79ad47":"* we have to change the names because the categories in the data are complex","b34e72a0":"* we also used dropout within the GRU and LSTM layers to prevent the model from shifting to the overfitting orientation\n* recurrent_dropout means transmission damping ratio of iterative layers","b959d2c3":"#### IMAGE PROCESS","1fdfd20f":"* we have to mix the data to increase the success of the model and maintain its objectivity.","79e6d934":"#### CHECKING","862b8604":"#### REPLACING","da79aa0b":"# IMAGE GENERATOR","4fafffee":"# PACKAGES AND LIBRARIES","470cc587":"* all images in the file path are assigned to a list","c60507d3":"#### CHECKING","f2bdc0fb":"#### PATH","51463da5":"# DETERMINATION TRAIN AND TEST DATA"}}