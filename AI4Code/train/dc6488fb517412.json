{"cell_type":{"b75d29f1":"code","7d6b77b6":"code","d42968a2":"code","bb7bc04e":"code","adbcfd2c":"code","0f79fb17":"code","05756382":"code","a6028980":"code","41ed1ee0":"code","035704c1":"code","9b5ed2f9":"code","85adfbcd":"code","6478868a":"code","46df0147":"code","a3dc17ba":"code","3eccb15a":"code","a407cd9f":"code","60096f0a":"code","7c135905":"code","1ab5e0e1":"code","301c15e1":"code","33261f1e":"code","64a612c0":"code","115b479f":"code","8d5a3aab":"code","18da28f9":"code","d36103f8":"code","47affabd":"code","8e56bb0c":"code","e611f69a":"code","65eb0ee1":"code","106a7bb3":"code","9b6ebce4":"code","c45484cb":"code","60f55fe2":"code","1ffe4e81":"code","14acdac3":"code","3433084c":"code","204f7c19":"code","91f38b0e":"code","a6101d16":"code","40b05e4e":"code","5aba5537":"code","30c84583":"code","fa046202":"code","367c96d3":"code","ebb38536":"code","0b1fe8ec":"code","721afecd":"code","daa63f8b":"code","442f2be2":"code","07b2b217":"code","ed6b3a8a":"code","067d008a":"code","29070d72":"code","c5ecec45":"code","aec40e61":"code","7747fb11":"code","547bcc98":"code","788da779":"code","d461f774":"code","eb32ddd3":"code","76cfb302":"code","870273f0":"code","d0895a66":"code","61c17b41":"code","626103ac":"code","980ffb41":"code","3375e357":"code","346be4ca":"code","4fb5119a":"code","e09196b9":"code","5185bd2e":"code","244dae55":"code","27a56922":"markdown","ae138107":"markdown","81aa7ee1":"markdown","e1443306":"markdown","f25a1e7b":"markdown","a5dbeab2":"markdown","1e23783c":"markdown","54e0ce57":"markdown","7ea9af34":"markdown","e6cd8d84":"markdown","8bffbb3d":"markdown","84e38bf7":"markdown","6dfa3bd8":"markdown","d5d4e70d":"markdown","d02ac384":"markdown","ef7fc778":"markdown"},"source":{"b75d29f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d6b77b6":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, make_scorer, accuracy_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform as sp_uniform\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.metrics.pairwise import pairwise_kernels\nfrom sklearn.metrics.pairwise  import cosine_similarity\nfrom sklearn.metrics.pairwise import chi2_kernel\nfrom sklearn.feature_selection import SelectFromModel","d42968a2":"pd.set_option('display.max_rows', None)","bb7bc04e":"train= pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv', sep=',')\nsub_sample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv', sep=',')\ntest= pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv', sep=',')","adbcfd2c":"test.info()","0f79fb17":"print(train.shape, test.shape, sub_sample.shape)","05756382":"sub_sample.head()","a6028980":"train.info()","41ed1ee0":"train.head()","035704c1":"train.isna().sum()","9b5ed2f9":"train.describe()","85adfbcd":"train = train.set_index('PassengerId')","6478868a":"train.groupby(by=['Pclass'])['Fare'].median()","46df0147":"train.loc[(train['Fare'].isna()) & (train['Pclass']==1), 'Fare']=63.58\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==2), 'Fare']=22.72\ntrain.loc[(train['Fare'].isna()) & (train['Pclass']==3), 'Fare']=10.96","a3dc17ba":"train['Age'] = train['Age'].replace(np.nan, train['Age'].median())","3eccb15a":"train['Cabin'] =train['Cabin'].str[0]","a407cd9f":"#train[train['Cabin'].isna()].groupby(by=['Pclass', 'Fare'])['Survived'].sum()","60096f0a":"train['Cabin'] = train['Cabin'].fillna('Z')","7c135905":"train.groupby(by=['Cabin'])['Survived'].mean()","1ab5e0e1":"df_cabin = pd.get_dummies(train['Cabin'], prefix='Cabin')","301c15e1":"train.groupby(by=['Embarked'])[['Fare','Survived']].mean()","33261f1e":"train[train['Embarked'].isna()].groupby(by=['Pclass'])['Survived'].mean()","64a612c0":"train.loc[(train['Embarked'].isna()) & (train['Pclass']==1), 'Embarked']='Z1'\ntrain.loc[(train['Embarked'].isna()) & (train['Pclass']==2), 'Embarked']='Z2'\ntrain.loc[(train['Embarked'].isna()) & (train['Pclass']==3), 'Embarked']='Z3'\n#train['Embarked'] = train['Embarked'].fillna('S')","115b479f":"df_embarked = pd.get_dummies(train['Embarked'], prefix='Embark')","8d5a3aab":"train['Ticket'] = train['Ticket'].str.replace('[^a-zA-Z]', '').str[:2]\ntrain['Ticket'] = train['Ticket'].str.strip()","18da28f9":"train['Ticket'] = train['Ticket'].fillna('ZZ')","d36103f8":"train.loc[train['Ticket']=='', 'Ticket']='NN'","47affabd":"train.groupby(by=['Ticket'])['Survived'].mean()","8e56bb0c":"df_tiket = pd.get_dummies(train['Ticket'], prefix='ticket')","e611f69a":"#train['Name'] = train['Name'].str.split(',',1).str[0]","65eb0ee1":"#test['Survived'] =2\n#df_name = pd.concat([train, test], axis=0)","106a7bb3":"#df_name.groupby(by=['Name','Pclass','Sex','Age','Survived'])['Fare'].mean()","9b6ebce4":"df_name = pd.concat([train['Name'], test['Name']], axis=0)","c45484cb":"le = LabelEncoder()\ndf_name = le.fit_transform(df_name)","60f55fe2":"train['Name'] = le.transform(train['Name'])","1ffe4e81":"train['Name'].head()","14acdac3":"train['Sex'] = train['Sex'].apply(lambda x: 1 if x=='female' else 0)","3433084c":"train['Sex'].value_counts()","204f7c19":"train['Pclass'] = train['Pclass'].astype('str')\ndf_pclass = pd.get_dummies(train['Pclass'], prefix='class')","91f38b0e":"df_pclass.head()","a6101d16":"# introducing a new feature : the size of families (including the passenger)\ntrain['FamilySize'] = train['Parch'] + train['SibSp'] + 1","40b05e4e":"# introducing other features based on the family size\ntrain['Singleton'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFamily'] = train['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntrain['LargeFamily'] = train['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","5aba5537":"df = pd.concat([train['Fare'], train['Age'],train['FamilySize'], train['Singleton'], train['SmallFamily'], train['LargeFamily'], train['Sex'], df_cabin, df_tiket, df_pclass, df_embarked ,train['Name'],train['Survived']], axis=1)","30c84583":"#incuding the Name encoder\ndf1 = pd.concat([train['Fare'], train['Age'],train['FamilySize'], train['Singleton'], train['SmallFamily'], train['LargeFamily'], train['Sex'],df_cabin, df_tiket, df_pclass, df_embarked], axis=1)","fa046202":"df.columns","367c96d3":"plt.figure(figsize=(15,10))\nsns.heatmap(data=df.corr())","ebb38536":"df = df.drop(columns='Survived')","0b1fe8ec":"df.head()","721afecd":"km = KMeans(n_clusters=3, random_state=22, n_init=20)\ndf_km = km.fit_predict(df)\ndf_km = pd.DataFrame(df_km, index=df.index)\ndf_km = df_km.astype('str')\ndf_km = pd.get_dummies(df_km)","daa63f8b":"df_km.head()","442f2be2":"df = pd.concat([df, df_km], axis=1)","07b2b217":"df_target = train['Survived']","ed6b3a8a":"clf = RandomForestClassifier(n_estimators=200, max_features='sqrt')\nclf = clf.fit(df, df_target)","067d008a":"features = pd.DataFrame()\nfeatures['feature'] = df.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(25, 25))","29070d72":"import optuna","c5ecec45":"def objective(trial , data = df , target = df_target):\n    train_x , test_x , train_y , test_y = train_test_split(data , target , \\\n            test_size = 0.028059109276941666 , random_state = 22)\n\n    #test_size = 0.028059109276941666\n    params = {\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 1e-5 , 10),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda' , 1e-5 , 10),\n        'num_leaves' : trial.suggest_int('num_leaves' , 11 , 800),\n        'learning_rate' : trial.suggest_uniform('learning_rate' , 0.0000001 , 0.1),\n        'max_depth' : trial.suggest_int('max_depth' , 5 , 400),\n        'n_estimators' : trial.suggest_int('n_estimators' , 1 , 9999),\n        'min_child_samples' : trial.suggest_int('min_child_samples' , 1 , 110),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-5 , 1),\n        'subsample' : trial.suggest_uniform('subsample' , 1e-5 , 1.0),\n        'colsample_bytree' : trial.suggest_loguniform('colsample_bytree' , 1e-5 , 1),\n        'random_state' : trial.suggest_categorical('random_state' , [1,22,2022,1509]),\n        'metric' : 'accuracy',\n        'device_type' : 'cpu',\n    }\n    model = lightgbm.LGBMClassifier(**params)\n    model.fit(train_x , train_y , eval_set = [(test_x , test_y)] ,eval_metric='logloss', early_stopping_rounds = 2000 , \\\n             verbose = False)\n    preds = model.predict(test_x)\n    acc = accuracy_score(test_y , preds)\n    return acc","aec40e61":"study = optuna.create_study(direction = 'maximize' , study_name = 'lgbm')\nstudy.optimize(objective , n_trials = 1)\nprint('numbers of the finished trials:' , len(study.trials))\nprint('the best params:' , study.best_trial.params)\nprint('the best value:' , study.best_value)","7747fb11":"#the best value: 0.7808267997148967\nparams= {'reg_alpha': 0.000493095633250276, 'reg_lambda': 0.2799468729577344, 'num_leaves': 220, 'learning_rate': 0.058683299033376934, 'max_depth': 97, 'n_estimators': 9161, 'min_child_samples': 108, 'min_child_weight': 1.7359084365325016e-05, 'subsample': 0.7381682823837273, 'colsample_bytree': 0.29845810314125426, 'random_state': 1509}","547bcc98":"#the best value: 0.7811831789023521\nparams2 = {'reg_alpha': 0.02242367265240423, 'reg_lambda': 0.0006085533155144086, 'num_leaves': 238, 'learning_rate': 0.03240605916351265, 'max_depth': 65, 'n_estimators': 5361, 'min_child_samples': 27, 'min_child_weight': 0.00011308353926700071, 'subsample': 0.5688435861948473, 'colsample_bytree': 0.06746586089945723, 'random_state': 22}","788da779":"#the best value: 0.7804704205274412\nparams1= {'reg_alpha': 0.009415444471348289, 'reg_lambda': 1.2556528225033043, 'num_leaves': 25, 'learning_rate': 0.00835886426230468, 'max_depth': 230, 'n_estimators': 3653, 'min_child_samples': 9, 'min_child_weight': 0.0002224399318225647, 'subsample': 0.9780174338845454, 'colsample_bytree': 0.7969641118752326, 'random_state': 1}","d461f774":"test = test.set_index('PassengerId')\n\n#Fare\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==1), 'Fare']=63.58\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==2), 'Fare']=22.72\ntest.loc[(test['Fare'].isna()) & (test['Pclass']==3), 'Fare']=10.96\n\n#Age\ntest['Age'] = test['Age'].replace(np.nan, test['Age'].median())\n\n#Cabin\ntest['Cabin'] =test['Cabin'].str[0]\ntest['Cabin'] = test['Cabin'].fillna('Z')\ndft_cabin = pd.get_dummies(test['Cabin'], prefix='Cabin')\n\n#Embarked\ntest.loc[(test['Embarked'].isna()) & (test['Pclass']==1), 'Embarked']='Z1'\ntest.loc[(test['Embarked'].isna()) & (test['Pclass']==2), 'Embarked']='Z2'\ntest.loc[(test['Embarked'].isna()) & (test['Pclass']==3), 'Embarked']='Z3'\n#test['Embarked'] = test['Embarked'].fillna('S')\ndft_embarked = pd.get_dummies(test['Embarked'], prefix='Embark')\n\n#Ticket\ntest['Ticket'] = test['Ticket'].str.replace('[^a-zA-Z]', '').str[:2]\ntest['Ticket'] = test['Ticket'].str.strip()\ntest['Ticket'] = test['Ticket'].fillna('ZZ')\ntest.loc[test['Ticket']=='', 'Ticket']='NN'\ndft_tiket = pd.get_dummies(test['Ticket'], prefix='ticket')\n\n#Name\n#test['Name'] = test['Name'].str.split(',',1).str[0]\ntest['Name'] = le.transform(test['Name'])\n\n#Sex\ntest['Sex'] = test['Sex'].apply(lambda x: 1 if x=='female' else 0)\n\n#Pclass\ntest['Pclass'] = test['Pclass'].astype('str')\ndft_pclass = pd.get_dummies(test['Pclass'], prefix='class')\n\n#Family Size\ntest['FamilySize'] = test['Parch'] + test['SibSp'] + 1\n\ntest['Singleton'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFamily'] = test['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\ntest['LargeFamily'] = test['FamilySize'].map(lambda s: 1 if 5 <= s else 0)","eb32ddd3":"dft = pd.concat([test['Fare'], test['Age'],test['FamilySize'], test['Singleton'], test['SmallFamily'], test['LargeFamily'], test['Sex'],dft_cabin,dft_tiket, dft_pclass, dft_embarked, test['Name']], axis=1)","76cfb302":"dft1 = pd.concat([test['Fare'], test['Age'],test['FamilySize'], test['Singleton'], test['SmallFamily'], test['LargeFamily'], test['Sex'], dft_cabin, dft_tiket, dft_pclass, dft_embarked], axis=1)","870273f0":"dft.head()","d0895a66":"dft_km = km.predict(dft)\ndft_km = pd.DataFrame(dft_km, index=dft.index)\ndft_km = dft_km.astype('str')\ndft_km = pd.get_dummies(dft_km)","61c17b41":"dft = pd.concat([dft, dft_km], axis=1)","626103ac":"dft.columns","980ffb41":"list(set(df.columns)-set(dft.columns))","3375e357":"df_target.head()","346be4ca":"params1['metric'] = 'accuracy'\nparams1['device'] = 'cpu'\npreds = np.zeros(dft.shape[0])\noof_preds = np.zeros(df.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 22 , shuffle = True)\nroc = []\nn = 0\nfor trn_idx , val_idx in kf.split(df , df_target):\n    train_x = df.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model = lightgbm.LGBMClassifier(**params1)\n    model.fit(train_x , train_y , eval_set = [(val_x , val_y)] ,eval_metric='logloss', early_stopping_rounds = 8000 , verbose = False)\n    clf = CalibratedClassifierCV(model, cv='prefit', method='sigmoid')\n    clf.fit(train_x , train_y)\n    preds += clf.predict_proba(dft)[:,1]\/kf.n_splits\n    oof_preds += clf.predict_proba(df)[:,1]\/kf.n_splits\n    roc.append(accuracy_score(val_y , clf.predict(val_x)))\n    fpr, tpr, thresholds = roc_curve(val_y , clf.predict_proba(val_x)[:,1])\n    gmeans = np.sqrt(tpr * (1-fpr))\n    ix = np.argmax(gmeans)\n    print(n+1 , roc[n], 'Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n    n+=1","4fb5119a":"sub_sample.head()","e09196b9":"sub_sample['Survived'] = preds","5185bd2e":"#simple threshold\nsub_sample['Survived'] = sub_sample['Survived'].apply(lambda x: 1 if x>0.405749 else 0)","244dae55":"sub_sample.to_csv('submission.csv',index=False)","27a56922":"# Using Optuna with Lgbm","ae138107":"## Preprocessing the Test_set","81aa7ee1":"Keep only the first 2 letter for ticket and replace space with N and nan wi1th ZZ","e1443306":"Strategy to fillna for Fare will be based on the median value of Passenger Class","f25a1e7b":"Analysis of possible strategy to fillna for Embarked field.\nSince the Passenger Class seems to be correlated to the possibility to Survive. 3 different embark classes will be created to fillna","a5dbeab2":"Convert NAN to ZZ","1e23783c":"One Hot encoder for Pclass","54e0ce57":"Get the Fatures related to Family size. An idea taken from:\nhttps:\/\/medium.datadriveninvestor.com\/start-with-kaggle-a-comprehensive-guide-to-solve-the-titanic-challenge-8ac5815b0473","7ea9af34":"For Cabin Feature, estract only the first letter, then fillna with Z","e6cd8d84":"Encoding the sex feature","8bffbb3d":"using the Median to fill all the NAN for Age","84e38bf7":"Convert '' with NN","6dfa3bd8":"Using Only the Surname from the \"Name\" field","d5d4e70d":"### Utils","d02ac384":"## Load Data","ef7fc778":"### Data Preprocessing"}}