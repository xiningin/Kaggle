{"cell_type":{"5e77b2e7":"code","b5c7b0db":"code","ffc5ce12":"code","7ca9693b":"code","0a3bd9e5":"code","9219ecec":"code","319d4d89":"code","89c86b54":"code","dbe625bb":"code","33f1d817":"code","fc97bbad":"code","065c7ce3":"code","ed0e79e3":"code","c5cbc18c":"code","8a892c42":"code","c3600fc8":"code","cb2f7430":"markdown","281ff68f":"markdown","9cac7048":"markdown","ba8075a9":"markdown","24cae9ce":"markdown","6c735856":"markdown"},"source":{"5e77b2e7":"import torch\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset","b5c7b0db":"input_size=28\nsequence_length =28\nnum_layers=2\nhidden_size=256\n\nlearning_rate = 0.001\nnum_epochs = 5\n\nnum_classes =10\nbatch_size = 64","ffc5ce12":"class SimpleRNN(nn.Module):\n    def __init__(self, input_size, num_layers, hidden_size, sequence_length, num_classes):\n        super(SimpleRNN, self).__init__()\n        self.num_layers = num_layers\n        self.hidden_size= hidden_size\n        \n        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc1 = nn.Linear(hidden_size * sequence_length, num_classes)\n    \n    def forward(self, x):\n        \n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n        \n        out, _ = self.rnn(x, h0)\n#         print(out.shape)\n        out = out.reshape(out.shape[0], -1)\n        out = self.fc1(out)\n        return out\n        \n            \n    ","7ca9693b":"class SimpleGRU(nn.Module):\n    def __init__(self, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes, sequence_length=sequence_length):\n        super(SimpleGRU, self).__init__()\n        self.hidden_size  = hidden_size\n        self.num_layers = num_layers\n        \n        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc1 = nn.Linear(hidden_size * sequence_length, num_classes)\n    \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n        \n        out,_ = self.gru(x, h0)\n        out = out.reshape(out.shape[0], -1)\n        out = self.fc1(out)\n        return out\n        \n        ","0a3bd9e5":"class SimpleLSTM(nn.Module):\n    def __init__(self, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, sequence_length=sequence_length, num_classes=num_classes):\n        super(SimpleLSTM, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc1 = nn.Linear(hidden_size * sequence_length, num_classes)\n        \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device)\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device)\n        \n        out, _ = self.lstm(x,(h0, c0))\n        out = out.reshape(out.size(0), -1)\n        out = self.fc1(out)\n        return out","9219ecec":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","319d4d89":"# model = SimpleRNN().to(device=device)\n\n# model = SimpleGRU().to(device=device)\n\nmodel = SimpleLSTM().to(device=device)","89c86b54":"x = torch.randn(64,28,28).to(device=device)\ny = model(x)\ny.shape","dbe625bb":"import pandas as pd\nimport numpy as np\n\nclass MnistDataset(Dataset):\n    def __init__(self, datapath):\n        super(MnistDataset).__init__()\n        df = pd.read_csv(datapath, dtype=np.float)\n        \n        self.x = torch.from_numpy(df.iloc[:, 1:].values)\n        self.x = self.x.reshape(self.x.size(0), 1, 28, 28).squeeze(1) # GRU and RNN expect N * 28 * 28\n        self.x = self.x.float()\n        \n        self.y = torch.from_numpy(df.iloc[:, 0].values)\n        self.y = self.y.long()\n        \n        self.n_samples = df.shape[0]\n    \n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n    \n    def __len__(self):\n        return self.n_samples\n        ","33f1d817":"train_dataset = MnistDataset(\"..\/input\/mnist-in-csv\/mnist_train.csv\")\ntest_dataset = MnistDataset(\"..\/input\/mnist-in-csv\/mnist_test.csv\")","fc97bbad":"x, y = train_dataset[0]\nx.shape, y.shape","065c7ce3":"train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)","ed0e79e3":"loss_criterion  = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)","c5cbc18c":"current_loss = 0\nfor epoch in range(num_epochs):\n    for data, target in train_dataloader:\n        data = data.to(device=device)\n        target = target.to(device=device)\n        \n        score = model(data)\n        loss = loss_criterion(score, target)\n        current_loss = loss\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n    print(f\"At epoch: {epoch}, loss: {current_loss}\")","8a892c42":"def check_accuracy(dlr,model):\n    \n    total_correct = 0\n    total_samples = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n        for x, y in dlr:\n            x = x.to(device=device)\n            y = y.to(device=device)\n            \n            score = model(x)\n            _,predictions = score.max(1)\n            \n            total_correct += (y==predictions).sum()\n            total_samples += predictions.size(0)\n            \n    model.train()\n    print(f\"total samples: {total_samples} total_correct: {total_correct} accuracy : {float(total_correct\/total_samples)* 100}\")\n            ","c3600fc8":"check_accuracy(train_dataloader, model)\ncheck_accuracy(test_dataloader, model)","cb2f7430":"### A LSTM","281ff68f":"Working towards RNN. from here : https:\/\/github.com\/aladdinpersson\/Machine-Learning-Collection\/blob\/master\/ML\/Pytorch\/Basics\/pytorch_rnn_gru_lstm.py","9cac7048":"### defining hyperparameters","ba8075a9":"### import libraries","24cae9ce":"## lets design an rnn","6c735856":"### A GRU"}}