{"cell_type":{"23ee380c":"code","86194d53":"code","d68351ef":"code","5e655601":"code","22cb625c":"code","d6db46f8":"code","6665945d":"code","496f11f1":"code","66ed5736":"code","880df7c2":"code","992f0f48":"code","52660daf":"code","28418a30":"code","67c6c54a":"code","be78503f":"code","8fb35cf3":"code","6802c61c":"code","7e1a1209":"code","f7737135":"markdown"},"source":{"23ee380c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86194d53":"df = pd.read_csv(\"\/kaggle\/input\/body-fat-prediction-dataset\/bodyfat.csv\")","d68351ef":"df.head()","5e655601":"def ralph_size(x):\n    i = x[\"Chest\"]\n    if i <= 86.4:\n        return \"XS\"\n    elif i > 86.4 and i <= 94:\n        return \"S\"\n    elif i > 94 and i <= 101.6:\n        return \"M\"\n    elif i > 101.6 and i <= 114.3:\n        return \"L\"\n    elif i > 114.3 and i <= 121.9:\n        return \"XL\"\n    else:\n        return \"XXL\"\n    \n    \ndf[\"Size\"] = df.apply(ralph_size, axis = 1)\ndf","22cb625c":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel","d6db46f8":"X = df.drop(\"Size\", axis = 1)\ny = df[\"Size\"]","6665945d":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\nX_train.shape, X_test.shape","496f11f1":"from sklearn.ensemble import RandomForestClassifier","66ed5736":"classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1, max_depth=5,\n                                       n_estimators=100, oob_score=True)\nclassifier_rf.fit(X_train, y_train)","880df7c2":"oob_score = classifier_rf.oob_score_\nprint(\"oob_score:\", oob_score)","992f0f48":"classifier_rf.score(X_test, y_test)","52660daf":"rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n\nparams = {\n    'max_depth': [2,3,5,10,20],\n    'min_samples_leaf': [5,10,20,50,100,200],\n    'n_estimators': [10,25,30,50,100,200]\n}","28418a30":"from sklearn.model_selection import GridSearchCV","67c6c54a":"# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator=rf,\n                           param_grid=params,\n                           cv = 4,\n                           n_jobs=-1, verbose=1, scoring=\"accuracy\")","be78503f":"grid_search.fit(X_train, y_train)","8fb35cf3":"grid_search.best_score_\nrf_best = grid_search.best_estimator_\nrf_best","6802c61c":"from sklearn.tree import plot_tree\nplt.figure(figsize=(80,40))\nplot_tree(rf_best.estimators_[3], feature_names = X.columns,filled=True);","7e1a1209":"rf_best.feature_importances_\nimp_df = pd.DataFrame({\n    \"Varname\": X_train.columns,\n    \"Imp\": rf_best.feature_importances_\n})\n\nimp_df.sort_values(by=\"Imp\", ascending=False)","f7737135":"random forest: https:\/\/www.analyticsvidhya.com\/blog\/2021\/06\/understanding-random-forest\/"}}