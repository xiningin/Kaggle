{"cell_type":{"821010aa":"code","08a31b3e":"code","c22746e0":"code","ea9c5f0f":"code","8f7acbb9":"code","e383ed5e":"code","9c215828":"code","256994cc":"code","f48a5770":"code","f20f1f5a":"code","8dd6dd55":"code","dce5bb68":"code","59b355e4":"code","c6874da0":"code","ca14fa7a":"code","d22bb81f":"code","c3a4eaa4":"code","404fc76b":"code","055e05d3":"code","5ff36e1e":"code","9997b7c0":"code","b5ebe0fc":"code","118a6f68":"code","bbc6d2e6":"code","86f56cba":"code","dd638eb8":"code","0992e781":"markdown","4f96e139":"markdown","2af31dfb":"markdown","c43a695c":"markdown","640ebf29":"markdown","396bf897":"markdown","6269deb7":"markdown","96cf5318":"markdown","e1f010af":"markdown","a8a1a871":"markdown","57cb8c1c":"markdown","57342e73":"markdown","082d2fad":"markdown","aa018f3b":"markdown","d5170da9":"markdown","1f33b205":"markdown","812e7303":"markdown","ef6a0157":"markdown","fb4c74ac":"markdown","02e60771":"markdown","ba926c8f":"markdown","0f7d46f6":"markdown","49c48c0e":"markdown","83f24b2b":"markdown","3ceb6c34":"markdown","936c2f69":"markdown","43b45029":"markdown","8ddcb3be":"markdown","647e5566":"markdown","b45384d9":"markdown","d8c0c004":"markdown","1184abd7":"markdown","208e24f6":"markdown","db114bb3":"markdown"},"source":{"821010aa":"from IPython.display import Image, HTML\nImage(url='https:\/\/s3.amazonaws.com\/drivendata-public-assets\/nepal-quake-bm-2.JPG')","08a31b3e":"# Create DataFrame\nimport pandas as pd\n\n# Math transformations\nimport numpy as np\nimport math\n\n# Data Viz\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot, plot\n\n# Stats\nfrom scipy import stats\nfrom scipy.stats import randint\n\n# Train test split\nfrom sklearn.model_selection import train_test_split\n\n# Feature engineering\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, scale\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA\n\n# Machine Learning\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Fine-tune\nfrom sklearn.model_selection import RandomizedSearchCV, cross_val_score\nfrom sklearn.model_selection import GridSearchCV, validation_curve, StratifiedKFold","c22746e0":"features = pd.read_csv('https:\/\/s3.amazonaws.com\/drivendata\/data\/57\/public\/train_values.csv').set_index('building_id')\ntarget = pd.read_csv('https:\/\/s3.amazonaws.com\/drivendata\/data\/57\/public\/train_labels.csv').set_index('building_id')","ea9c5f0f":"df=pd.concat([features,target],axis=1)\ndisplay(HTML('<h3>A picture from aggregated DataFrame:<\/h3> <br>'))\ndisplay(df.head())","8f7acbb9":"display(HTML('<h4>Memory usage of each attribute in megabytes:<\/h4><br>'))\ndf.memory_usage(deep=True)\/(10**6)","e383ed5e":"display(HTML(f'<h4>Shape of the data: {df.shape}<\/h4>'))","9c215828":"eda,_ = train_test_split(df, test_size=.2, random_state=42)","256994cc":"# !pip3 install 'pandas-profiling[notebook]'\n# from pandas_profiling import ProfileReport\n\n# profile = ProfileReport(eda,)\n# profile.to_notebook_iframe()","f48a5770":"# This transformation needs in order to avoid confusion of damage_grade variable as continous\npd.set_option('mode.chained_assignment', None)\neda['damage_grade(eda)'] = np.where(eda.damage_grade==1,'(1) Low', \n                                    np.where(eda.damage_grade==2,'(2) Medium', \n                                             np.where(eda.damage_grade==3,'(3) High',0)))","f20f1f5a":"fig = px.pie(eda.groupby('damage_grade(eda)').age.count().reset_index(), values='age', names='damage_grade(eda)' , title='Damage Grade Distribution')\nfig.show()","8dd6dd55":"fig = px.bar(eda.groupby(['age','damage_grade(eda)']).roof_type.count().reset_index().rename(columns={'roof_type':'count'}),\n             x=\"age\", y=\"count\", color=\"damage_grade(eda)\", title=\"Check if the age of the building affect on damage due to earthquake?\")\nfig.update_xaxes(range=[0, 100])\nfig.show()","dce5bb68":"def draw_subplotted_pie_chart(eda ,col, labels, target_col):\n    pd.set_option('mode.chained_assignment', None)    \n\n    fig = make_subplots(rows=1, cols=4, specs=[[{'type':'domain'}, \n                                                {'type':'domain'},\n                                                {'type':'domain'},\n                                                {'type':'domain'}]], subplot_titles = labels)\n    for i,lb in enumerate(labels):\n        eda_labeled = eda[eda[target_col]==lb]\n        eda_counted = pd.DataFrame(eda_labeled.groupby(col)[col].count()).rename(columns={\n            col:'Count'}).reset_index()\n        fig.add_trace(go.Pie(values=eda_counted.Count, labels=eda_counted[col], name=lb),1,i+1)\n    fig.update_layout(title_text=f'{col} distribution for each {target_col}')\n    iplot(fig)\n\nlabels=['0-10','10-15','15-30','30-995']\neda['age_cut']=pd.qcut(eda.age,4,labels=labels)\ndraw_subplotted_pie_chart(eda,'damage_grade(eda)',labels, 'age_cut')","59b355e4":"import warnings\nwarnings.filterwarnings('ignore')\nsns.FacetGrid(eda,hue='damage_grade',height=5,aspect=2,palette=\"viridis\")\\\n    .map(sns.distplot,'area_percentage')\\\n    .add_legend()\nplt.title(\"Area Percentage\")","c6874da0":"fig, ax = plt.subplots(1,1,figsize=(10,8))\ncor=eda.corr()\ncor=pd.DataFrame(cor)\nsns.heatmap(cor,cmap=\"viridis\",ax=ax)","ca14fa7a":"df_pre = df.reset_index().copy()\n\n# Select data from datatype of each attr which is other than numbers and apply encoder\ndf_enc=df_pre.select_dtypes(exclude=[\"number\"])\nenc = OneHotEncoder(sparse=False,dtype=np.int64)\nenc_matrix=enc.fit_transform(df_enc)\n\n# Concat the encoded matrix with the other ones\ndf_basic = pd.concat([pd.DataFrame(enc_matrix, \n                                   columns=enc.get_feature_names(list(df_enc))),\n                      df_pre],\n                     axis=1).drop(list(df_enc), axis=1)\n\n# Divide dataset by target and feature variables\ny = df_basic.loc[:,'damage_grade']\nX = df_basic.drop(['damage_grade','building_id'], axis=1)","d22bb81f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,\n                                                    random_state=42, stratify=y)\ncv = StratifiedKFold(5, random_state=42)","c3a4eaa4":"dt = DecisionTreeClassifier(random_state=42)\ncvs_res=cross_val_score(dt, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1, verbose=5)\nprint(f'\\nCross validated accuracy scores: {cvs_res}\\n\\n')\ndt.fit(X_train, y_train)\n\ndt_predictions=dt.predict(X_test)\nprint(f'accuracy_score: {accuracy_score(y_test, dt_predictions)}\\n\\n')\nprint(classification_report(y_test, dt_predictions))","404fc76b":"\n%%time\nparam_dist = {\n              \"max_depth\": np.linspace(75,125,5, dtype=np.int64),\n              \"max_leaf_nodes\": np.linspace(2000,2500,10, dtype=np.int64),\n    \n}\ntree_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), param_dist, cv=5, n_jobs=-1, verbose=10)\ntree_cv.fit(X,y)\nprint(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\nprint(\"Best score is {}\".format(tree_cv.best_score_))","055e05d3":"def plot_cm(cf_matrix, save=False):\n    labels=['Grade 1','Grade 2','Grade 3']\n    sns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, xticklabels=labels, yticklabels=labels,\n            fmt='.2%')\n    if save:\n        plt.savefig('best_dt_conf.png')","5ff36e1e":"dt_best = DecisionTreeClassifier(max_depth=75, max_leaf_nodes=2333, random_state=42)\ndt_best.fit(X_train,y_train)\ndt_predictions=dt_best.predict(X_test)\nprint(f'accuracy_score: {accuracy_score(y_test, dt_predictions)}\\n\\n')\nprint(classification_report(y_test, dt_predictions))\ncf_matrix = confusion_matrix(y_test, dt_predictions)\nplot_cm(cf_matrix)","9997b7c0":"%%time\nrf = RandomForestClassifier(random_state=42, n_jobs=-1, oob_score=True)\nrf.fit(X_train, y_train)\n\ncvs_res=cross_val_score(rf, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1, verbose=5)\nprint(f'\\nCross validated accuracy scores: {cvs_res}\\n\\n')\n\nrf_predictions=rf.predict(X_test)\nprint(f'\\naccuracy_score: {accuracy_score(y_test, rf_predictions)}\\n\\n')\nprint(classification_report(y_test, rf_predictions))","b5ebe0fc":"def plot_oob(acc,oob,parameters):\n    rf_best_oob=pd.DataFrame(parameters,columns=['Number of Tree'])\n    rf_best_oob['Accuracy Score'],rf_best_oob['Out-of-bag Score'] = acc,oob\n    dd=rf_best_oob[['Accuracy Score','Out-of-bag Score']].stack().reset_index().rename({'level_0':'Number of Tree',\n                                                                                        'level_1':'Score Type',\n                                                                                        0:'Score'},axis=1)\n    dd=dd.replace({'Number of Tree':{key:value for (key,\n                                                    value) in zip(np.arange(0,6,1),\n                                                                  rf_best_oob[['Number of Tree']].values)}})\n    fig=px.line(dd, x='Number of Tree', y='Score', color='Score Type', labels={'index':'Fold ID'})\n    fig.update_xaxes(type='category')\n    fig.show()","118a6f68":"%%time\nacc,oob=[],[]\nfor i in [10, 100, 300, 500, 700, 900]:\n    rf = RandomForestClassifier(n_estimators=i, random_state=42, n_jobs=-1, oob_score=True,verbose=1)\n    rf.fit(X_train, y_train)\n    rf_predictions=rf.predict(X_test)\n    acc.append(accuracy_score(y_test, rf_predictions))\n    oob.append(rf.oob_score_)\n\n# Plot\nplot_oob(acc,oob,[10, 100, 300, 500, 700, 900])","bbc6d2e6":"%%time\nrf_best = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_best.fit(X_train,y_train)\nrf_predictions=rf_best.predict(X_test)\nprint(f'accuracy_score: {accuracy_score(y_test, rf_predictions)}\\n\\n')\nprint(classification_report(y_test, rf_predictions))\ncf_matrix = confusion_matrix(y_test, rf_predictions)\nplot_cm(cf_matrix)","86f56cba":"%%time\ndt_f = DecisionTreeClassifier(random_state = 24, max_depth=75, max_leaf_nodes=2333)\ndt_f.fit(X_train,y_train)\ndt_f_pred=dt_f.predict(X_test)\n\nrf_f = RandomForestClassifier(n_estimators=100, random_state = 24)\nrf_f.fit(X_train,y_train)\nrf_f_pred=rf_f.predict(X_test)\n\n# Classification Report\ndisplay(HTML('<h4>Decision Trees Classification Report<\/h4>'))\nprint(classification_report(y_test, dt_f_pred))\ndisplay(HTML('<h4>Random Forest Classification Report<\/h4>'))\nprint(classification_report(y_test, rf_f_pred))\n\n#Confusion Matrix\ncm_dt=confusion_matrix(y_test,dt_f_pred)\nconf_matrix_dt=pd.DataFrame(data=cm_dt,columns=['Predicted:1','Predicted:2','Predicted:3'],\n                                         index=['Actual:1','Actual:2','Actual:3'])\ncm_rf=confusion_matrix(y_test,rf_f_pred)\nconf_matrix_rf=pd.DataFrame(data=cm_rf,columns=['Predicted:1','Predicted:2','Predicted:3'],\n                                         index=['Actual:1','Actual:2','Actual:3'])\n","dd638eb8":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,7), sharey=True)\nfig.suptitle('Comparison of Decision Tree and Random Forests Classifiers')\nsns.heatmap(conf_matrix_dt, annot=True,fmt='d',cmap=\"rocket_r\",ax=ax1, cbar=False)\nsns.heatmap(conf_matrix_rf, annot=True,fmt='d',cmap=\"rocket_r\",ax=ax2)","0992e781":"The data can be imported from `Amazon AWS Storage`. This version of data provided by `drivendata` for educational competetion purposes. In order to import data from the urls, `pandas.read_csv()` function can be used. Data divided into two part, features and target values for each building. It will be investigate both features and target values in next sections. ","4f96e139":"<a name='comparison'><\/a>\n## Comparison","2af31dfb":"- ***OBSERVATIONS***\n    - 1: represents low damage\n    - 2: represents a medium amount of damage\n    - 3: represents almost complete destruction\n    - `9.57%` of bulidings were less damaged by earthquake.\n    - `57%` of bulidings were medium damaged \n    - `33.5%` of bulidings were highly damaged due to earthquake.","c43a695c":"<a name='create-test'><\/a>\n## Create a test set\n\nRandomly selected 80% of the data will be used for [Exploratory Data Analysis](#eda) section. This will be prevent the concept of data snooping$^{[2]}$.","640ebf29":"* Remove `building_id` in order to avoid misguide the model\n* There are so many outliers, however, Random Forests algorithm is robust to the outliers$^{[3]}$\n* Should change encoding system with `LabelEncoder` or `OneHotEncoder` considering whether each feature is *incremental* or not.\n* There isn't any missing values in the dataset\n* Since binary variable not belong to coordinate system `PCA`\u00a0is failing to reducing dimensions of the dataset. Thus, this step will be skipped.$^{[4]}$ ","396bf897":"<a name='eda'><\/a>\n# Explatory Data Analysis","6269deb7":"<script src=\"https:\/\/polyfill.io\/v3\/polyfill.min.js?features=es6\"><\/script>\n<script type=\"text\/javascript\" id=\"MathJax-script\" async\n  src=\"https:\/\/cdn.jsdelivr.net\/npm\/mathjax@3\/es5\/tex-chtml.js\">\n<\/script>\n        \nEvery year The National Earthquake Information Center (NEIC) records an average of 20,000 earthquakes all around to world. This number is fairly huge, but we can infer from that in order to understand more that is huge, averagely 50 earthquake occured in each day$^{[1]}$.\n\n\nIn 2015 April 25, an intense earthquake occured in Central Nepal at local time of 11:56 a.m. My goal is the predict level of damage of the buildings in 2015 Gorkha earthquake in Nepal. The data that was collected through surveys by [Kathmandu Living Labs](http:\/\/www.kathmandulivinglabs.org\/) and the [Central Bureau of Statistics](https:\/\/cbs.gov.np\/) will be used in this notebook. This data one of the largest post-disaster dataset ever collected, it includes various information that influence various aspects of science.\n\n**Note:** The triple dots in the below means there are some hidden codes. It can be opened by clicking on them. This is same for all triple dots in the notebook. (If there is not triple dots or no code hidden, do not consider this note)","96cf5318":"* ***Age of building vs Damage***","e1f010af":"* ***Basic Engineering***\n\nThere is no incremental feature in the dataset. Therefore, `OneHotEncoder` is sufficient for feature engineering.","a8a1a871":"\n\n<div style=\"width:100%;text-align:center;\">\n    <h1>\n        Predicting Nepal earthquake damage on buildings using the tree-based machine learning methods \n    <\/h1>\n    <h3>\n        Ibrahim Onur Serbetci\n    <\/h3>\n<\/div>\n\n# Table of Contents\n1. [Problem Description](#problem)\n1. [Import Libraries](#import-libraries)\n1. [Get the Data](#get-the-data)\n    1. [Take a quick look at data structure](#quick-look)\n    1. [Create a test set](#create-test)\n1. [Exploratory Data Analysis](#eda)\n    1. [Description of Features](#desc)\n    1. [Discover and Visualize](#graph)\n    1. [Looking for Correlations](#cor)\n    1. [Insights from Data Analysis](#eda-res)\n1. [Feature Engineering](#feature)\n1. [Machine Learning](#ml)\n    1. [Decision Tree Classifier](#dt)\n        1. [Fine Tune Decision Trees](#dt-f)\n    1. [Random Forest Classifier](#rf)\n        1. [Fine Tune Random Forest](#rf-f)\n    1. [Comparison](#comparison)\n1. [References](#ref)","57cb8c1c":"* ***Area of building vs Damage***","57342e73":"<a name='problem'><\/a>\n# Problem Description","082d2fad":"**[1]** FEDERAL EMERGENCY MANAGEMENT AGENCY, Semisonic Sleuths. AMERICAN GEOPHYSICAL UNION, Accessed December 20, 2020, http:\/\/www.fema.gov\/media-library-data\/20130726-1646-20490-4697\/fema253.pdf.\n\n**[2]** A. G\u00e9ron, Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow. O'Reilly, 2019.\n\n**[3]** L. Breiman, \"Random Forests\", Machine Learning, vol. 45, no. 1, pp. 5-32, 2001. Available: 10.1023\/a:1010933404324 [Accessed 10 January 2021].\n\n**[4]** B. Walker, \"PCA Is Not Feature Selection\", Towards Data Science, 2019. .","aa018f3b":"<a name='rf'><\/a>\n## Random Forest Classifier","d5170da9":"It looks like such a big data, automating some steps would help the process.","1f33b205":"<a name='ref'><\/a>\n# References","812e7303":"<a name='eda-res'><\/a>\n## Insights from Data Analysis","ef6a0157":"- ***FURTHER OBSERVATIONS***\n    - The age is making difference on damage grade until 15.\n","fb4c74ac":"- ***OBSERVATIONS***\n    - Around 90% of building ages fall under \\[0-50] range\n    - 2nd highest no. of bulidings are in the category high damage.\n    - Inferences, can be seen by pie chart below more easily.","02e60771":"You can inspect full data from the [link](http:\/\/eq2015.npc.gov.np\/)","ba926c8f":"<a name='dt'><\/a>\n## Decision Tree Classifier","0f7d46f6":"* ***Investigate target variable (Damage Grade)***","49c48c0e":"<a name='feature'><\/a>\n# Feature Engineering","83f24b2b":"After reading all the report, some interesting piece will be investigate in next section.","3ceb6c34":"<a name='rf-f'><\/a>\n### Fine Tune Random Forest Classifier","936c2f69":"<a name='dt-f'><\/a>\n### Fine Tune Decision Tree Classifier","43b45029":"It will be easier to aggregate `features` and `target` for future operations. `pandas.concat()` function could be used in order to do it. \u00a0 ","8ddcb3be":"<a name='get-the-data'><\/a>\n# Get the data","647e5566":"<a name='graph'><\/a>\n## Discover and Visualize\n\nIn this section, some of questions will be discussed briefly in order to analyse the data and get to know. Some of the basic questions will be answered in this chapter which are as follows. \n* What is distribution of damages on all buildings?\n* How the age of the building affects damage due to earthquakes?\n* What is the distribution of area of the buildings affected by damage due to earthquakes?","b45384d9":"<a name='ml'><\/a>\n# Machine Learning","d8c0c004":"<a name='import-libraries'><\/a>\n# Import Libraries\n\nVarious libraries have been imported for various tasks. These are,\n* Create data frame\n    * [Pandas](https:\/\/pandas.pydata.org\/)\n* Linear Algebra or math operations\n    * [Numpy](https:\/\/numpy.org\/)\n    * [Math](https:\/\/docs.python.org\/3\/library\/math.html)\n* Data Visualization\n    * [Matplotlib](https:\/\/matplotlib.org\/)\n    * [Plotly](https:\/\/plotly.com\/)\n    * [Seaborn](https:\/\/seaborn.pydata.org\/)\n* Statistics\n    * [Scipy](https:\/\/www.scipy.org\/)\n* Machine Learning\n    * [Scikit-learn](https:\/\/scikit-learn.org\/stable\/)\n        * Train test Split:\n            * [model_selection.train_test_split()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html)\n        * Feature Engineering and preprocessing:\n            * [preprocessing.LabelEncoder()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html)\n            * [preprocessing.OneHotEncoder()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OneHotEncoder.html)\n            * [preprocessing.scale()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.scale.html)\n            * [compose.ColumnTransformer()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.compose.ColumnTransformer.html)\n            * [decomposition.PCA()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html)\n        * Fitting the model and evaluation:\n            * [tree.DecisionTreeClassifier()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html)\n            * [ensemble.RandomForestClassifier()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html)\n            * [metrics.classification_report()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.classification_report.html)\n            * [metrics.confusion_matrix()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html)\n            * [metrics.accuracy_score()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.accuracy_score.html)\n        * Fine Tuning the hyperparameter:\n            * [model_selection.RandomizedSearchCV()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RandomizedSearchCV.html)\n            * [model_selection.cross_val_score()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.cross_val_score.html)\n            * [model_selection.GridSearchCV()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html)\n            * [model_selection.validation_curve()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.validation_curve.html)\n            * [model_selection.StratifiedKFold()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.StratifiedKFold.html)","1184abd7":"<a name='quick-look'><\/a>\n## Take a Quick Look at Data Structures\n\nIt will be much easier to look at the data before [Exploratory Data Analysis](#eda). It may be necessary check the how much space it is taken by the data.","208e24f6":"<a name='corr'><\/a>\n## Looking for Correlations","db114bb3":"<a name='desc'><\/a>\n## Description of Features\n* **geo_level_1_id, geo_level_2_id, geo_level_3_id (type: int):** geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). Possible values: level 1: 0-30, level 2: 0-1427, level 3: 0-12567.\n\n* **count_floors_pre_eq (type: int):** number of floors in the building before the earthquake.\n\n* **age (type: int):** age of the building in years.\n\n* **area_percentage (type: int):** normalized area of the building footprint.\n\n* **height_percentage (type: int):** normalized height of the building footprint.\n\n* **land_surface_condition (type: categorical):** surface condition of the land where the building was built. Possible values: n, o, t.\n\n* **foundation_type (type: categorical):** type of foundation used while building. Possible values: h, i, r, u, w.\n\n* **roof_type (type: categorical):** type of roof used while building. Possible values: n, q, x.\n\n* **ground_floor_type (type: categorical):** type of the ground floor. Possible values: f, m, v, x, z.\n\n* **other_floor_type (type: categorical):** type of constructions used in higher than the ground floors (except of roof). Possible values: j, q, s, x.\n\n* **position (type: categorical):** position of the building. Possible values: j, o, s, t.\n\n* **plan_configuration (type: categorical):** building plan configuration. Possible values: a, c, d, f, m, n, o, q, s, u.\n\n* **has_superstructure_adobe_mud (type: binary):** flag variable that indicates if the superstructure was made of Adobe\/Mud.\n\n* **has_superstructure_mud_mortar_stone (type: binary):** flag variable that indicates if the superstructure was made of Mud Mortar - Stone.\n\n* **has_superstructure_stone_flag (type: binary):** flag variable that indicates if the superstructure was made of Stone.\n\n* **has_superstructure_cement_mortar_stone (type: binary):** flag variable that indicates if the superstructure was made of Cement Mortar - Stone.\n\n* **has_superstructure_mud_mortar_brick (type: binary):** flag variable that indicates if the superstructure was made of Mud Mortar - Brick.\n\n* **has_superstructure_cement_mortar_brick (type: binary):** flag variable that indicates if the superstructure was made of Cement Mortar - Brick.\n\n* **has_superstructure_timber (type: binary):** flag variable that indicates if the superstructure was made of Timber.\n\n* **has_superstructure_bamboo (type: binary):** flag variable that indicates if the superstructure was made of Bamboo.\n\n* **has_superstructure_rc_non_engineered (type: binary):** flag variable that indicates if the superstructure was made of non-engineered reinforced concrete.\n\n* **has_superstructure_rc_engineered (type: binary):** flag variable that indicates if the superstructure was made of engineered reinforced concrete.\n\n* **has_superstructure_other (type: binary):** flag variable that indicates if the superstructure was made of any other material.\n\n* **legal_ownership_status (type: categorical):** legal ownership status of the land where building was built. Possible values: a, r, v, w.\n\n* **count_families (type: int):** number of families that live in the building.\n\n* **has_secondary_use (type: binary):** flag variable that indicates if the building was used for any secondary purpose.\n\n* **has_secondary_use_agriculture (type: binary):** flag variable that indicates if the building was used for agricultural purposes.\n\n* **has_secondary_use_hotel (type: binary):** flag variable that indicates if the building was used as a hotel.\n\n* **has_secondary_use_rental (type: binary):** flag variable that indicates if the building was used for rental purposes.\n\n* **has_secondary_use_institution (type: binary):** flag variable that indicates if the building was used as a location of any institution.\n\n* **has_secondary_use_school (type: binary):** flag variable that indicates if the building was used as a school.\n\n* **has_secondary_use_industry (type: binary):** flag variable that indicates if the building was used for industrial purposes.\n\n* **has_secondary_use_health_post (type: binary):** flag variable that indicates if the building was used as a health post.\n\n* **has_secondary_use_gov_office (type: binary):** flag variable that indicates if the building was used fas a government office.\n\n* **has_secondary_use_use_police (type: binary):** flag variable that indicates if the building was used as a police station.\n\n* **has_secondary_use_other (type: binary):** flag variable that indicates if the building was secondarily used for other purposes.\n\nProfiling the data will be help for studying each feature."}}