{"cell_type":{"b56edd55":"code","a2a4d1b9":"code","248d6dfb":"code","9ca64af2":"code","d1ae8f35":"code","0d0ede51":"code","d167a9ea":"code","14d6cefd":"code","ed68e386":"code","bd5a0179":"code","92ca1675":"code","e12dd2d8":"code","9a37657e":"code","87cbcb30":"code","b82e5ee8":"code","82e5146b":"code","d45e01be":"code","e0b4e63f":"code","faf7cbc5":"code","e75341bf":"code","548f7993":"code","88c5c6a5":"code","12ff9162":"code","3001aa0a":"code","362353f6":"code","82823745":"code","3fbcdd33":"code","f3ef234e":"code","224de58d":"code","5732d0f3":"code","578643b5":"code","150456e9":"code","7825e56f":"code","14eafce5":"code","58ac45c4":"code","a79ce3c2":"code","96ae3bc4":"code","e3f2f088":"code","043303bb":"code","8224da1e":"code","e6ec9a92":"code","73c110e9":"code","370b8f11":"code","868590b8":"code","ee742765":"code","058fd710":"code","d253714d":"code","e9ee3ac0":"code","cde0718d":"code","bb865f7d":"code","60c78bf3":"code","5e68decf":"code","00fb439d":"code","e0a94cdf":"code","5dfe8a55":"code","06bad0ac":"code","a8a67931":"code","0db0d053":"code","83bbcb83":"code","aef77db3":"code","451a5513":"code","b0a329b1":"code","12a48051":"markdown","acb449e8":"markdown","e871d014":"markdown","0c848ec6":"markdown","bb0ff14b":"markdown","a3c6369c":"markdown","a5a56fe7":"markdown","0e735f4c":"markdown","b1627447":"markdown","e49b8e84":"markdown","5c311db3":"markdown","08a5625e":"markdown","22eeac88":"markdown","c70e58fb":"markdown","a98f01c6":"markdown","1056ad88":"markdown","2b6bb10c":"markdown","1856d7a7":"markdown","43e9113e":"markdown","b621e868":"markdown","dd35bf0d":"markdown","130fd649":"markdown","1f51562d":"markdown","cddfa635":"markdown","a533fe96":"markdown","910137da":"markdown","a046ba74":"markdown","8e43914c":"markdown","4555a868":"markdown","eefa5a33":"markdown","049f120b":"markdown","25c0f819":"markdown","a767054d":"markdown","3388df37":"markdown","80e6f1f9":"markdown","675abd8d":"markdown","9d9a9580":"markdown","5d34ee28":"markdown","2c10330c":"markdown","7ca838e7":"markdown","48dd53d3":"markdown","3b236679":"markdown","c6c02499":"markdown","e26f6c26":"markdown","0e52ddbf":"markdown","c16a411c":"markdown","6747bc6e":"markdown","745ba662":"markdown","5f91cd45":"markdown","1dadf28d":"markdown","82fd49c8":"markdown","c3abccdd":"markdown","7f41bc73":"markdown","9f6bbed0":"markdown","c630c0c1":"markdown","00fed20b":"markdown","10cf55b2":"markdown","8efa0740":"markdown","b423ea1c":"markdown","26772f40":"markdown"},"source":{"b56edd55":"import numpy as np \nimport pandas as pd \n\nfrom sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error \n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","a2a4d1b9":"df2 = pd.read_csv('..\/input\/OLX_Car_Data_CSV.csv',encoding= 'latin1')\ndf2 = df2.sample(frac=1).reset_index(drop=True)# shuffle\nnRow, nCol = df2.shape\nprint(f'There are {nRow} rows and {nCol} columns')","248d6dfb":"display(df2.head(5))\ndf2.columns","9ca64af2":"cat_val = ['Brand', 'Condition', 'Fuel', 'Model',\n       'Registered City', 'Transaction Type']\n\nfor col in cat_val:\n    print ([col],\" : \",df2[col].unique())","d1ae8f35":"sns.heatmap(pd.DataFrame(df2.isnull().sum()),annot=True,\n            cmap=sns.color_palette(\"cool\"),linewidth=1,linecolor=\"white\")\n","0d0ede51":"print(\"Number of Null values in train dataset\\n\")\nprint(df2.isnull().sum(axis = 0))","d167a9ea":"#Train dataset\ndf2['Brand'].fillna(value='unknown', inplace=True)\ndf2['Condition'].fillna(value='unknown', inplace=True)\ndf2['Fuel'].fillna(value='unknown', inplace=True)\ndf2['Model'].fillna(value='unknown', inplace=True)\ndf2['Registered City'].fillna(value='unknown', inplace=True)\ndf2['Transaction Type'].fillna(value='unknown', inplace=True)","14d6cefd":"print(\"Number of Null values in train dataset\\n\")\nprint(df2.isnull().sum(axis = 0))","ed68e386":"#Train dataset\ndf2['KMs Driven'].fillna((df2['KMs Driven'].mean()),inplace = True) #average data \n# df2['Year'].fillna(df2['Year'].value_counts().index[0],inplace = True) #most frequent data","bd5a0179":"print(\"Number of Null values in train dataset\\n\")\nprint(df2.isnull().sum(axis = 0))","92ca1675":"df2=df2.dropna() #drop rows with atleast a column with missing values\n","e12dd2d8":"print(\"Train : \", df2.shape)","9a37657e":"df2.dtypes","87cbcb30":"#Train dataset\ndf2.describe()","b82e5ee8":"sns.distplot(df2[\"Price\"])","82e5146b":"sns.distplot(df2[\"KMs Driven\"])","d45e01be":"sns.distplot(df2[\"Year\"])","e0b4e63f":"cols=['Price']\n\n\nfor i in cols:\n    quartile_1,quartile_3 = np.percentile(df2[i],[25,75])\n    quartile_f,quartile_l = np.percentile(df2[i],[1,99])\n    IQR = quartile_3-quartile_1\n    lower_bound = quartile_1 - (1.5*IQR)\n    upper_bound = quartile_3 + (1.5*IQR)\n    print(i,lower_bound,upper_bound,quartile_f,quartile_l)\n\n    df2[i].loc[df2[i] < lower_bound] = quartile_f\n    df2[i].loc[df2[i] > upper_bound] = quartile_l\n","faf7cbc5":"def remove_outlier(df_in, col_name):\n    q1 = df_in[col_name].quantile(0.25)\n    q3 = df_in[col_name].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    return df_out\n\ndf2=remove_outlier(df2, 'Price')\n# df2=remove_outlier(df2, 'KMs Driven')\n# df2=remove_outlier(df2, 'Year')","e75341bf":"sns.distplot(df2[\"Price\"])","548f7993":"df2['Damaged'] = np.where(df2['KMs Driven']> 2000000, 'too_old', 'old')","88c5c6a5":"df2.head()","12ff9162":"#Train Dataset\ndf2.hist(bins = 50 , figsize = (20,20))\nplt.show()","3001aa0a":"\nsns.pairplot(df2, x_vars=['Brand', 'Condition', 'Fuel', 'KMs Driven', 'Model',\n       'Registered City', 'Transaction Type', 'Year'], y_vars=[\"Price\"],aspect=1);\n","362353f6":"plt.scatter(df2['Brand'], df2['Price'], color='blue')\nplt.title('Price Vs Brand', fontsize=14)\nplt.xlabel('Brand', fontsize=14)\nplt.ylabel('Price', fontsize=14)\nplt.grid(True)\nplt.show()","82823745":"plt.scatter(df2['KMs Driven'], df2['Price'], color='red')\nplt.title('Price Vs KMs Driven', fontsize=14)\nplt.xlabel('KMs Driven', fontsize=14)\nplt.ylabel('Price', fontsize=14)\nplt.grid(True)\nplt.show()","3fbcdd33":"plt.scatter(df2['Registered City'], df2['Price'], color='green')\nplt.title('Price Vs Registered City', fontsize=14)\nplt.xlabel('Registered City', fontsize=14)\nplt.ylabel('Price', fontsize=14)\nplt.grid(True)\nplt.show()","f3ef234e":"df2[df2[\"Condition\"] == \"Used\"][\"Fuel\"].value_counts().plot.pie(autopct = \"%1.0f%%\",colors = [\"grey\",\"orange\"],startangle = 60,                                                              wedgeprops={\"linewidth\":2,\"edgecolor\":\"white\"},shadow =True)\ncirc = plt.Circle((0,0),.1,color=\"white\")\nplt.gca().add_artist(circ) \n","224de58d":"df2[df2[\"Condition\"] == \"New\"][\"Fuel\"].value_counts().plot.pie(autopct = \"%1.0f%%\",colors = [\"grey\",\"orange\"],startangle = 60,                                                              wedgeprops={\"linewidth\":2,\"edgecolor\":\"white\"},shadow =True)\ncirc = plt.Circle((0,0),.1,color=\"white\")\nplt.gca().add_artist(circ) \n","5732d0f3":"ax = sns.countplot(\"Condition\",hue=\"Fuel\",data=df2[df2[\"Transaction Type\"] == \"Cash\"],palette=[\"r\",\"b\",\"g\"])\nax.set_facecolor(\"white\")","578643b5":"plt.figure(figsize=(18,10))\nax = sns.pointplot(df2[\"Year\"],df2[\"Price\"],color=\"w\") # line is of white color\nax.set_facecolor(\"k\") #background is black\nplt.grid(True,color=\"grey\",alpha=.3) # grid is on and its color is grey\nplt.title(\"Average Price by year\")\nplt.show()","150456e9":"# df2=df2.drop(['Transaction Type','Registered City'], axis=1)\n# test=test.drop(['Transaction Type','Registered City'], axis=1)","7825e56f":"df3=pd.get_dummies(df2,drop_first=True)\ndf3.head()","14eafce5":"df_y = df3['Price'].values\ndf_X = df3.drop(['Price'], axis=1)\n","58ac45c4":"test_size = 0.30\n\n#Split into train and test\nX_train, X_test, Y_train, Y_test = train_test_split(df_X,df_y, test_size=test_size,shuffle=True, random_state = 3)\n\n\nX_test.to_csv(\"cleaned_test_set.tsv\", sep='\\t', encoding='utf-8',index=False)\n\ntemp2 = pd.DataFrame(data=Y_test.flatten())\ntemp2.columns = temp2.iloc[0]\ntemp2 = temp2.reindex(temp2.index.drop(0)).reset_index(drop=True)\ntemp2.columns.name = None\ntemp2.to_csv(\"actual_price_test.tsv\", sep='\\t', encoding='utf-8',index=False)\n","a79ce3c2":"rf = RandomForestRegressor()\n\nparam_grid = { \"criterion\" : [\"mse\"]\n              , \"min_samples_leaf\" : [3]\n              , \"min_samples_split\" : [3]\n              , \"max_depth\": [10]\n              , \"n_estimators\": [500]}","96ae3bc4":"gs = GridSearchCV(estimator=rf, param_grid=param_grid, cv=2, n_jobs=-1, verbose=1)\ngs = gs.fit(X_train, Y_train)","e3f2f088":"print(gs.best_score_)\nprint(gs.best_params_)\n ","043303bb":"bp = gs.best_params_\nrf_regressor = RandomForestRegressor(criterion=bp['criterion'],\n                              min_samples_leaf=bp['min_samples_leaf'],\n                              min_samples_split=bp['min_samples_split'],\n                              max_depth=bp['max_depth'],\n                              n_estimators=bp['n_estimators'])\nrf_regressor.fit(X_train, Y_train)","8224da1e":"print(\"Train R^2 Score:\")\nprint('Score: %.2f' % rf_regressor.score(X_train, Y_train))","e6ec9a92":"#Predicting the Price using cross validation (KFold method)\ny_pred_rf = cross_val_predict(rf_regressor, X_train, Y_train, cv=10 )\n\n#Random Forest Regression Accuracy with cross validation\naccuracy_rf = metrics.r2_score(Y_train, y_pred_rf)\nprint('Cross-Predicted(KFold) Random Forest Regression Accuracy: %.2f '% accuracy_rf)","73c110e9":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","370b8f11":"scores = cross_val_score(rf_regressor, X_train, Y_train,\n                         scoring=\"neg_mean_squared_error\", cv=5)\nlin_rmse_scores = np.sqrt(-scores)\n\ndisplay_scores(lin_rmse_scores)","868590b8":"print(\"Test R^2 Score:\")\nprint('Score: %.2f' % rf_regressor.score(X_test, Y_test))","ee742765":"y_pred=rf_regressor.predict(X_train)\ny_pred[0:5]","058fd710":"list(Y_train[0:5])","d253714d":"# The root mean squared error\ny_pred =rf_regressor.predict(X_train)\n\nforest_mse = mean_squared_error(Y_train, y_pred)\nforest_rmse = np.sqrt(forest_mse)\n\nprint(\"Root Mean squared error (training): %.2f\"\n      % forest_rmse)","e9ee3ac0":"ranking = np.argsort(-rf_regressor.feature_importances_)\nf, ax = plt.subplots(figsize=(15, 100))\nsns.barplot(x=rf_regressor.feature_importances_[ranking], y=X_train.columns.values[ranking], orient='h')\nax.set_xlabel(\"feature importance\")\nplt.tight_layout()\nplt.show()","cde0718d":"\nX_train1 = X_train.iloc[:,ranking[:30]]\nX_test1 = X_test.iloc[:,ranking[:30]]\n","bb865f7d":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(X_train1.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","60c78bf3":"regr = LinearRegression()\n\nregr.fit(X_train, Y_train)","5e68decf":"print('Train R^2 \\nscore: %.2f' % regr.score(X_train, Y_train))","00fb439d":"# The root mean squared error\ny_pred =regr.predict(X_train)\n\nlin_mse = mean_squared_error(Y_train, y_pred)\nlin_rmse = np.sqrt(lin_mse)\n\nprint(\"Root Mean squared error (training): %.2f\"\n      % lin_rmse)\n","e0a94cdf":"#Predicting the Price using cross validation (KFold method)\ny_pred_kf = cross_val_predict(regr, X_train, Y_train, cv=10 )\n\n#Accuracy with cross validation (KFold method)\naccuracy_lf = metrics.r2_score(Y_train, y_pred_kf)\nprint('Cross-Predicted(KFold) Linear Regression Accuracy: %.2f' % accuracy_lf)\n","5dfe8a55":"scores = cross_val_score(regr, X_train, Y_train,\n                         scoring=\"neg_mean_squared_error\", cv=5)\nlin_rmse_scores= np.sqrt(-scores)\n\ndisplay_scores(lin_rmse_scores)","06bad0ac":"#intercept\nprint('Intercept: \\n', regr.intercept_)\n\n# The coefficients\nprint('Coefficients: \\n', regr.coef_)","a8a67931":"y_pred[0:5]","0db0d053":"list(Y_train[0:5])","83bbcb83":"y_pred = regr.predict(X_train)\nplt.figure(figsize=(12,7))\nplt.grid(True)\nplt.title('Scatter Plot of Predicted Price Vs Actual Price', y=1, size=20)\nplt.scatter(Y_train, y_pred)\nplt.xlabel(\"Actual Price\")\nplt.ylabel(\"Predictions\")","aef77db3":"plt.figure(figsize=(12,7)) \nplt.grid(True)\nplt.title('Residual Plot for Linear Regression', y=1, size=20) \nsns.residplot(Y_train,y_pred) # regression Residual Plot for linear regression model using bootstrapping","451a5513":"print('Test R^2 \\nscore: %.2f' % regr.score(X_test, Y_test))","b0a329b1":"submission = rf_regressor.predict(X_test)\nfilename = 'submission.csv'\n\ntemp2 = pd.DataFrame(data=submission.flatten())\ntemp2.columns = temp2.iloc[0]\ntemp2 = temp2.reindex(temp2.index.drop(0)).reset_index(drop=True)\ntemp2.columns.name = None\ntemp2.to_csv(\"submission.tsv\", sep='\\t', encoding='utf-8',index=False)","12a48051":"Determine outliers in dataset","acb449e8":"#### Test R squared score","e871d014":"### <a id=\"3-2\" > 3.2 Pairplot of different features with \"Price\"<\/a>","0c848ec6":"### <a id=\"3-7\" > 3.7 Encoding the categorical data (one hot Encoding)<\/a>","bb0ff14b":"### <a id=\"5-1-1\" > Grid searching of hyperparameters<\/a>","a3c6369c":"One thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into our learning model because this means that there isn't much redundant or superfluous data in our training set. Here are two most correlated features are that of \"Fuel_Petrol\" and \"Year\".","a5a56fe7":"#### Checking values of categorical attributes","0e735f4c":"## <a id=\"6\"> 6. Final prediction and Conclusion<\/a>","b1627447":"***","e49b8e84":"**Replace the NaN-Values with dummies <br>Replacing \"NaN\" with \"unknown\" to treat it as a categorical values in their respective columns**","5c311db3":"There are too many missing values in the dataset. So instead of removing them <br>we will fill it median, average or most frequent\ndata.<br>\nWe will consider \"NaN\" as some data point. So let's replace it with word \"unknown\" <br>to treat it as a categorical \nvalue in its respective columns.","08a5625e":"It can be observed that there is some linear relationship (rougly) between dependent variable \"Price\"\nand independent variables \"Brand\", \"KMs Driven\", \"Registered City\" and \"Year\" .\n\nSo let's draw these plots separately for clear view.","22eeac88":"### <a id=\"5-2-1\" >Train R squared score<\/a>","c70e58fb":"## <a id=\"5\"> 5. Model<\/a>","a98f01c6":"## <a id=\"1\"> 1. Importing Data <\/a>","1056ad88":"### <a id=\"2-4\" > 2.4 Remove Outliers<\/a>","2b6bb10c":"Let's run the Linear Regression to check if removing the less dominant features improved the model from earlier version.","1856d7a7":"### <a id=\"5-1-2\" > K-Fold cross validation <\/a>","43e9113e":"**Train and Cross Validation score is quite comparable. So we can say that our model in not overfitting. <br>It is generalizing better.**","b621e868":"(Click on the below links to navigate to different sections of the notebook)\n# **Overview**  \n- <a href=\"#1\"> 1. Importing Data<\/a>\n- <a href=\"#2\"> 2. Preprocessing the Dataset<\/a>\n  -  <a href=\"#2-1\" > 2.1 Check for NULLS (missing data)<\/a>\n  -  <a href=\"#2-2\" > 2.2 Filling the missing data<\/a>\n  -  <a href=\"#2-3\" > 2.3 Check the datatype of columns<\/a>\n  -  <a href=\"#2-4\" > 2.4 Remove Outliers<\/a>\n  -  <a href=\"#2-5\" > 2.5 Feature Engineering<\/a>\n- <a href=\"#3\"> 3. Explanatory Data Analysis <\/a>\n  -  <a href=\"#3-1\" > 3.1 Distribution of \"KMs Driven\", \"Price\", \"Year\" <a>\n  -  <a href=\"#3-2\" > 3.2 Pairplot of different features with \"Price\"<\/a>\n  -  <a href=\"#3-3\" > 3.3 Percentage of each \"fuel\" types for \"Used\" condition<\/a>\n  -  <a href=\"#3-4\" > 3.4 Percentage of each \"fuel\" types for \"New\" condition<\/a>\n  -  <a href=\"#3-5\" > 3.5 Count plot of \"Used\" and \"New\" having Transaction Type \"Cash\" for Fuel features<\/a>\n  -  <a href=\"#3-6\" > 3.6 Variation of Price with Year<\/a>\n  -  <a href=\"#3-7\" > 3.7 Encoding the categorical data (one hot Encoding)<\/a>\n- <a href=\"#4\"> 4. Divide the data into training and testing data <\/a>\n- <a href=\"#5\"> 5. Model<\/a>\n  -  <a href=\"#5-1\" > A. Random forest Regressor<\/a>\n     -  <a href=\"#5-1-1\" > Grid searching of hyperparameters<\/a>\n     -  <a href=\"#5-1-2\" > K-Fold cross validation<\/a>\n     -  <a href=\"#5-1-3\" > Correlation Matrix<\/a>\n     -  <a href=\"#5-1-4\" > A. Random forest Regressor<\/a>\n  -  <a href=\"#5-2\" > B. Linear Regression<\/a>\n     -  <a href=\"#5-2-1\" > Train R squared score<\/a>\n     -  <a href=\"#5-2-2\" > Root mean squared error<\/a>\n     -  <a href=\"#5-2-3\" > K-Fold Cross Validation<\/a>\n     -  <a href=\"#5-2-4\" > Scatter Plot of Predicted Price Vs Actual Price<\/a>  \n     -  <a href=\"#5-2-5\" > Residual Plot<\/a> \n- <a href=\"#6\"> 6. Final prediction and Conclusion<\/a>\n\n","dd35bf0d":"#### Comparison of first five predicted and actual price in train_set","130fd649":"### <a id=\"5-2-3\" >K-Fold Cross Validation<\/a>","1f51562d":"Let's find what features are most important","cddfa635":"#### Comparison of first five predicted and actual price in train_set","a533fe96":"Let's now fill the missing values in the column \"KMs Driven\" with average values.","910137da":"#### Intercept and coefficients","a046ba74":"## <a id=\"4\"> 4.  Divide the data into training and test data <\/a>","8e43914c":"## <a id=\"3\">3. Explanatory Data Analysis <\/a>","4555a868":"#### After removing outlier in 'Price'","eefa5a33":"## <a id=\"5-1\" > A. Random forest Regressor<\/a>","049f120b":"Keeping 30 most dominant features","25c0f819":"### <a id=\"3-5\" > 3.5 Count plot of \"Used\" and \"New\" having Transaction Type \"Cash\" for Fuel features<\/a>","a767054d":"Visual display of null values in each columns for quick overview","3388df37":"#### Root mean squared error","80e6f1f9":"### <a id=\"5-2-5\" >Residual Plot<\/a> ","675abd8d":"### <a id=\"2-1\" > 2.1 Check for NULLS (missing data)<\/a>","9d9a9580":"### <a id=\"2-3\" > 2.3 Check the datatype of columns<\/a>","5d34ee28":"### <a id=\"3-1\" > 3.1 Distribution of \"KMs Driven\", \"Price\", \"Year\" in train dataset<a>","2c10330c":"Linear Regression gives a score of  80% on final test dataset <br>\n10-Fold Cross Validation score in case of Linear Regression =  80%<br>\n***\nRandom Forest Regressor gives a score of 85% final test dataset <br>\n10-Fold Cross Validation score in case of Random Forest Regressor = 86%<br>","7ca838e7":"#### Cross validation score","48dd53d3":"### <a id=\"5-2-2\" >Root mean squared error<\/a>","3b236679":"### <a id=\"5-2-4\" >Scatter Plot of Predicted Price Vs Actual Price<\/a> ","c6c02499":"### <a id=\"5-1-3\" > Correlation Matrix <\/a>","e26f6c26":"Pairplot to visualize the realtionship between the target and independent features","0e52ddbf":"#### Cross validation score","c16a411c":"We can observe that new car uses CNG less than old car.","6747bc6e":"#### Distribution of \"KMs Driven\" in train dataset","745ba662":"#### Distribution of \"Year\" in train dataset","5f91cd45":"### <a id=\"3-4\" > 3.4 Percentage of each \"fuel\" types for \"New\" condition<\/a>","1dadf28d":"### <a id=\"3-6\" > 3.6 Variation of Price with Year<\/a>","82fd49c8":"#### Training R squared score","c3abccdd":"## <a id=\"5-2\" > B. Linear Regression<\/a>","7f41bc73":"#### Distribution of \"Price\" in train dataset","9f6bbed0":"### <a id=\"3-3\" > 3.3 Percentage of each \"fuel\" types for \"Used\" condition<\/a>","c630c0c1":"Now we will do cross validation . This is because we split dataset in train and test. It may happen that test and train does not have uniform distribution of samples. So to make sure our model doesn't overfit i.e to generalize it we will do cross validation.","00fed20b":"## <a id=\"2\" > 2. Preprocessing the Dataset<\/a>","10cf55b2":"#### Test R squared score","8efa0740":"### <a id=\"2-5\" > 2.5 Feature Engineering<\/a>","b423ea1c":"Price of cars whose price is more than 1500000 it considered as expensive.","26772f40":"### <a id=\"2-2\" > 2.2 Filling the missing data<\/a>"}}