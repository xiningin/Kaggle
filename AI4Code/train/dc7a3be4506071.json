{"cell_type":{"e81a1e1e":"code","8006ada3":"code","ff03cdcc":"code","d0e99b1f":"code","a78b627c":"code","1998d16d":"code","e9b54fd4":"code","2025a9eb":"code","4abbfa0e":"code","7d54f4b0":"code","928502a4":"code","a381eb19":"code","d440e664":"code","f4e74db5":"code","887aeb76":"code","cb149f45":"code","f6881c74":"code","4cd2b1fb":"code","b08a0be4":"code","d67cffc8":"code","19fbf434":"code","3f0989ae":"markdown","faa3c084":"markdown","437a4ce3":"markdown","e5253919":"markdown","6310e1a7":"markdown","13d762ba":"markdown","096d6399":"markdown","f20594ea":"markdown","2a6cc500":"markdown","2938d741":"markdown","a4dfa635":"markdown"},"source":{"e81a1e1e":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport os\nimport math\nimport random\nimport cv2\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()","8006ada3":"GCS_PATH = KaggleDatasets().get_gcs_path('gan-getting-started')\nfn_monet = tf.io.gfile.glob(str(GCS_PATH + '\/monet_jpg\/*.jpg'))\nfn_photo = tf.io.gfile.glob(str(GCS_PATH + '\/photo_jpg\/*.jpg'))","ff03cdcc":"BATCH_SIZE =  4\n\n\ndef parse_function(filename):\n    image_string = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = (tf.cast(image,tf.float32)\/ 127.5) - 1\n    image = tf.reshape(image, [256, 256,3])\n    return image\n\ndef data_augment(image):\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    if p_crop > .5:\n        image = tf.image.resize(image, [286, 286])\n        image = tf.image.random_crop(image, size=[256, 256, 3])\n        if p_crop > .9:\n            image = tf.image.resize(image, [300, 300])\n            image = tf.image.random_crop(image, size=[256, 256, 3])\n    \n    if p_rotate > .9:\n        image = tf.image.rot90(image, k=3)\n    elif p_rotate > .7:\n        image = tf.image.rot90(image, k=2)\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=1)\n        \n    if p_spatial > .6:\n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n        if p_spatial > .9:\n            image = tf.image.transpose(image)\n    \n    return image\n\nnum_parallel_calls=tf.data.experimental.AUTOTUNE\ndef getSet(filenames):\n    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n    dataset = dataset.shuffle(len(filenames))\n    dataset = dataset.map(parse_function, num_parallel_calls)\n    dataset = dataset.map(data_augment, num_parallel_calls)\n    dataset = dataset.repeat()\n    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(num_parallel_calls)\n    return dataset\n\nmonet_ds=getSet(fn_monet)\nphoto_ds=getSet(fn_photo)","d0e99b1f":"OUTPUT_CHANNELS = 3\n\ndef downsample(filters, size, apply_instancenorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(layers.Conv2D(filters, size, strides=2, padding='same',kernel_initializer=initializer, use_bias=False))\n\n    if apply_instancenorm:\n        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    result.add(layers.LeakyReLU())\n\n    return result","a78b627c":"def upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(layers.Conv2DTranspose(filters, size, strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n\n    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    if apply_dropout:\n        result.add(layers.Dropout(0.5))\n\n    result.add(layers.ReLU())\n\n    return result","1998d16d":"def Generator():\n    inputs = layers.Input(shape=[256,256,3])\n\n    # bs = batch size\n    #\u4e0b\u91c7\u6837\u5c42\u5217\u8868\n    down_stack = [\n        downsample(64, 4, apply_instancenorm=False), # (bs, 128, 128, 64) 256\/2\u5411\u4e0a\u53d6\u6574\uff08\u56e0\u4e3apadding\u662fsame\uff0c\u5426\u5219(256-4+1)\/2\u5411\u4e0a\u53d6\u6574\uff09\n        downsample(128, 4), # (bs, 64, 64, 128)\n        downsample(256, 4), # (bs, 32, 32, 256)\n        downsample(512, 4), # (bs, 16, 16, 512)\n        downsample(512, 4), # (bs, 8, 8, 512)\n        downsample(512, 4), # (bs, 4, 4, 512)\n        downsample(512, 4), # (bs, 2, 2, 512)\n        downsample(512, 4), # (bs, 1, 1, 512)\n    ]\n    #\u4e0a\u91c7\u6837\u5c42\u5217\u8868\n    up_stack = [\n        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024) 1*2\uff08\u56e0\u4e3apadding\u662fsame\uff0c\u5426\u5219(1*2-4+1)\uff09\uff0c\u6b64\u5916\u8fd8\u62fc\u63a5\u4e86\u4e00\u4e2a\u5f20\u91cf\uff0c\u56e0\u6b64\u901a\u9053\u6570\u589e\u52a0\n        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n        upsample(512, 4), # (bs, 16, 16, 1024)\n        upsample(256, 4), # (bs, 32, 32, 512)\n        upsample(128, 4), # (bs, 64, 64, 256)\n        upsample(64, 4), # (bs, 128, 128, 128)\n    ]\n\n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,strides=2,padding='same',kernel_initializer=initializer,activation='tanh') # (bs, 256, 256, 3)\uff0c\u6700\u540e\u4e00\u5c42\uff0c\u91cd\u65b0\u53d8\u6210\u539f\u6765\u5927\u5c0f\n\n    x = inputs\n\n    #\u8fdb\u884c\u4e0b\u91c7\u6837\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])#\u6700\u4e0b\u5c42\u7684\u5728\u6700\u524d\n\n    #\u8fdb\u884c\u4e0a\u91c7\u6837\uff0c\u5e76\u4e14\u8fdb\u884c\u8de8\u63a5\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = layers.Concatenate()([x, skip])\n\n    x = last(x)\n\n    return keras.Model(inputs=inputs, outputs=x)","e9b54fd4":"tf.keras.utils.plot_model(Generator(), show_shapes=True, dpi=64)","2025a9eb":"def Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n\n    x = inp\n\n    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n\n    zero_pad1 = layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n    conv = layers.Conv2D(512, 4, strides=1,kernel_initializer=initializer,use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n\n    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n\n    leaky_relu = layers.LeakyReLU()(norm1)\n\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n\n    last = layers.Conv2D(1, 4, strides=1,\n                         kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\u8be5\u9274\u522b\u5668\u4e0d\u8f93\u51fa\u5355\u4e2a\u8282\u70b9\uff0c\u800c\u662f\u8f93\u51fa\u8f83\u5c0f\u76842D\u56fe\u50cf\uff0c\u5176\u5177\u6709\u6307\u793a\u771f\u5b9e\u5206\u7c7b\u7684\u8f83\u9ad8\u50cf\u7d20\u503c\u548c\u6307\u793a\u5047\u5206\u7c7b\u7684\u8f83\u4f4e\u503c\n\n    return tf.keras.Model(inputs=inp, outputs=last)","4abbfa0e":"tf.keras.utils.plot_model(Discriminator(), show_shapes=True, dpi=64)","7d54f4b0":"class CycleGan(keras.Model):\n    def __init__(self,monet_generator,photo_generator,monet_discriminator,photo_discriminator,lambda_cycle=15):\n        super(CycleGan, self).__init__()\n        self.m_gen = monet_generator\n        self.p_gen = photo_generator\n        self.m_disc = monet_discriminator\n        self.p_disc = photo_discriminator\n        self.lambda_cycle = lambda_cycle\n        \n    def compile(self,m_gen_optimizer,p_gen_optimizer,m_disc_optimizer,p_disc_optimizer,gen_loss_fn,disc_loss_fn,cycle_loss_fn,identity_loss_fn):\n        super(CycleGan, self).compile()\n        self.m_gen_optimizer = m_gen_optimizer\n        self.p_gen_optimizer = p_gen_optimizer\n        self.m_disc_optimizer = m_disc_optimizer\n        self.p_disc_optimizer = p_disc_optimizer\n        \n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n        \n    def train_step(self, batch_data):\n        real_monet, real_photo = batch_data\n        #real_monet\u4e3ay\uff0creal_photo\u4e3ax\uff0cm_gen\u4e3aG\uff0cp_gen\u4e3aF\uff0cp_disc\u4e3aDX\uff0cm_disc\u4e3aDY\n        \n        with tf.GradientTape(persistent=True) as tape:\n            fake_monet = self.m_gen(real_photo, training=True)#G(x)\n            cycled_photo = self.p_gen(fake_monet, training=True)#F(G(x))\n\n            fake_photo = self.p_gen(real_monet, training=True)#F(y)\n            cycled_monet = self.m_gen(fake_photo, training=True)#G(F(y))\n\n            same_monet = self.m_gen(real_monet, training=True)#G(y)\n            same_photo = self.p_gen(real_photo, training=True)#F(x)\n\n            disc_real_monet = self.m_disc(real_monet, training=True)#DY(y)\n            disc_real_photo = self.p_disc(real_photo, training=True)#DX(x)\n\n            disc_fake_monet = self.m_disc(fake_monet, training=True)#DY(G(x))\n            disc_fake_photo = self.p_disc(fake_photo, training=True)#DX(F(y))\n\n            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)#\u7528\u4e8e\u8bad\u7ec3\u751f\u6210\u5668\u7684\u635f\u5931\u51fd\u6570\uff08\u57fa\u672c\u90e8\u5206\uff09\n            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)#\u7528\u4e8e\u8bad\u7ec3\u751f\u6210\u5668\u7684\u635f\u5931\u51fd\u6570\uff08\u57fa\u672c\u90e8\u5206\uff09\n\n            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)#\u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931\uff0c\u4e58\u4ee5lambda\n\n            # evaluates total generator loss\n            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)#\u7528\u4e8e\u8bad\u7ec3\u751f\u6210\u5668\u7684\u603b\u635f\u5931\u51fd\u6570\n            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)#\u7528\u4e8e\u8bad\u7ec3\u751f\u6210\u5668\u7684\u603b\u635f\u5931\u51fd\u6570\n\n            # evaluates discriminator loss\n            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)#\u7528\u4e8e\u8bad\u7ec3\u9274\u522b\u5668\u7684\u635f\u5931\u51fd\u6570\n            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)#\u7528\u4e8e\u8bad\u7ec3\u9274\u522b\u5668\u7684\u635f\u5931\u51fd\u6570\n\n        # \u635f\u5931\u51fd\u6570\u5bf9\u7f51\u7edc\u5f53\u4e2d\u7684\u53c2\u6570\u6c42\u68af\u5ea6\uff08\u4e4b\u524d\u7531\u7f51\u7edc\u8f93\u51fa\u7ed3\u679c\u65f6\uff0c\u8bbe\u7f6e\u4e86training\u4e3aTrue\uff0c\u56e0\u6b64\u53ef\u4ee5\u5bf9\u7f51\u7edc\u4e2d\u7684\u53c2\u6570\u6c42\u68af\u5ea6\uff09\n        monet_generator_gradients = tape.gradient(total_monet_gen_loss,self.m_gen.trainable_variables)#\u751f\u6210\u5668\u7684\u603b\u635f\u5931\u51fd\u6570\u5bf9\u751f\u6210\u5668\u7684\u6240\u6709\u53c2\u6570\u6c42\u68af\u5ea6\n        photo_generator_gradients = tape.gradient(total_photo_gen_loss,self.p_gen.trainable_variables)#\u751f\u6210\u5668\u7684\u603b\u635f\u5931\u51fd\u6570\u5bf9\u751f\u6210\u5668\u7684\u6240\u6709\u53c2\u6570\u6c42\u68af\u5ea6\n        monet_discriminator_gradients = tape.gradient(monet_disc_loss,self.m_disc.trainable_variables)#\u9274\u522b\u5668\u7684\u635f\u5931\u51fd\u6570\u5bf9\u9274\u522b\u5668\u7684\u6240\u6709\u53c2\u6570\u6c42\u68af\u5ea6\n        photo_discriminator_gradients = tape.gradient(photo_disc_loss,self.p_disc.trainable_variables)#\u9274\u522b\u5668\u7684\u635f\u5931\u51fd\u6570\u5bf9\u9274\u522b\u5668\u7684\u6240\u6709\u53c2\u6570\u6c42\u68af\u5ea6\n\n        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,self.m_gen.trainable_variables))#\u4f18\u5316\u5668\u5411\u524d\u8fed\u4ee3\u4e00\u6b65\n        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,self.p_gen.trainable_variables))#\u4f18\u5316\u5668\u5411\u524d\u8fed\u4ee3\u4e00\u6b65\n        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,self.m_disc.trainable_variables))#\u4f18\u5316\u5668\u5411\u524d\u8fed\u4ee3\u4e00\u6b65\n        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,self.p_disc.trainable_variables))#\u4f18\u5316\u5668\u5411\u524d\u8fed\u4ee3\u4e00\u6b65\n        \n        return {\"monet_gen_loss\": total_monet_gen_loss,\"photo_gen_loss\": total_photo_gen_loss,\"monet_disc_loss\": monet_disc_loss,\"photo_disc_loss\": photo_disc_loss}","928502a4":"with strategy.scope():\n    def discriminator_loss(real, generated):\n        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)#\u5bf9\u4e8e\u771f\u5b9e\u6837\u672c\uff0c\u901a\u8fc7\u9274\u522b\u5668\u540e\u4e0e\u51681\u77e9\u9635\u8ba1\u7b97\u4ea4\u53c9\u71b5\uff0c\u4f7f\u5f97D\u5bf9\u771f\u5b9e\u6570\u636e\u8f93\u51fa\u5c3d\u53ef\u80fd\u63a5\u8fd11\n        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)#\u5bf9\u4e8e\u751f\u6210\u6837\u672c\uff0c\u901a\u8fc7\u9274\u522b\u5668\u540e\u4e0e\u51680\u77e9\u9635\u8ba1\u7b97\u4ea4\u53c9\u71b5\uff0c\u4f7f\u5f97D\u5bf9\u751f\u6210\u6570\u636e\u8f93\u51fa\u5c3d\u53ef\u80fd\u63a5\u8fd10\n        total_disc_loss = real_loss + generated_loss\n        return total_disc_loss * 0.5","a381eb19":"with strategy.scope():\n    def generator_loss(generated):\n        return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)#\u5bf9\u4e8e\u751f\u6210\u6837\u672c\uff0c\u901a\u8fc7\u9274\u522b\u5668\u540e\u4e0e\u51681\u77e9\u9635\u8ba1\u7b97\u4ea4\u53c9\u71b5\uff0c\u4f7f\u5f97D\u5bf9\u751f\u6210\u6570\u636e\u8f93\u51fa\u5c3d\u53ef\u80fd\u63a5\u8fd11","d440e664":"with strategy.scope():\n    def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))#\u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931\n        return LAMBDA * loss1","f4e74db5":"with strategy.scope():\n    def identity_loss(real_image, same_image, LAMBDA):\n        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n        return LAMBDA * 0.5 * loss","887aeb76":"with strategy.scope():\n    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","cb149f45":"with strategy.scope():\n    monet_generator=Generator()\n    photo_generator=Generator()\n    monet_discriminator=Discriminator()\n    photo_discriminator=Discriminator()\nwith strategy.scope():\n    cycle_gan_model = CycleGan(monet_generator,photo_generator,monet_discriminator,photo_discriminator)\n    cycle_gan_model.compile(\n            m_gen_optimizer = monet_generator_optimizer,\n            p_gen_optimizer = photo_generator_optimizer,\n            m_disc_optimizer = monet_discriminator_optimizer,\n            p_disc_optimizer = photo_discriminator_optimizer,\n            gen_loss_fn = generator_loss,\n            disc_loss_fn = discriminator_loss,\n            cycle_loss_fn = calc_cycle_loss,\n            identity_loss_fn = identity_loss\n        )","f6881c74":"steps_per_epoch=(max(len(fn_monet), len(fn_photo)))\/\/BATCH_SIZE\ncycle_gan_model.fit(tf.data.Dataset.zip((monet_ds, photo_ds)),epochs=25,steps_per_epoch=steps_per_epoch)","4cd2b1fb":"testset = tf.data.Dataset.from_tensor_slices(fn_photo)\ntestset = testset.shuffle(len(fn_photo))\ntestset = testset.map(parse_function, num_parallel_calls)\ntestset=testset.batch(1)\ntestset = testset.prefetch(num_parallel_calls)\n\n\n_, ax = plt.subplots(5, 2, figsize=(20, 20))\nfor i, img in enumerate(testset.take(5)):\n    prediction = monet_generator(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Input Photo\")\n    ax[i, 1].set_title(\"Monet-esque\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","b08a0be4":"import PIL\n\ndef predict_and_save(input_ds, generator_model, output_path):\n    i = 1\n    for img in input_ds:\n        prediction = generator_model(img, training=False)[0].numpy() # make predition\n        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)   # re-scale\n        im = PIL.Image.fromarray(prediction)\n        im.save(output_path+\"\/\"+str(i)+'.jpg')\n        i += 1","d67cffc8":"import os\nos.makedirs('..\/images\/') # Create folder to save generated images\n\npredict_and_save(testset, monet_generator, '..\/images\/')","19fbf434":"import shutil\nshutil.make_archive('\/kaggle\/working\/images\/', 'zip', '..\/images')\n\nprint(f\"Generated samples: {len([name for name in os.listdir('..\/images\/') if os.path.isfile(os.path.join('..\/images\/', name))])}\")","3f0989ae":"# \u63d0\u4ea4","faa3c084":"# \u635f\u5931\u51fd\u6570\n\n\u7528\u4e8e\u8bad\u7ec3\u9274\u522b\u5668\u7684\u635f\u5931\u51fd\u6570","437a4ce3":"# \u8bad\u7ec3","e5253919":"\u7528\u4e8e\u8bad\u7ec3\u751f\u6210\u5668\u7684\u635f\u5931\u51fd\u6570\uff08\u57fa\u672c\u90e8\u5206\uff09","6310e1a7":"\u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931","13d762ba":"# \u9274\u522b\u5668\u7684\u5b9e\u73b0\n\n\u9274\u522b\u5668\u4f7f\u7528\u7684\u662f\u666e\u901a\u7684\u4e0b\u91c7\u6837\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4e0b\u91c7\u68373\u6b21\u540e\uff0c\u8f93\u51fa\u4e00\u4e2a$30\\times30$\u7684\u77e9\u9635\u4f5c\u4e3a\u7ed3\u679c\uff0c\u5177\u6709\u6307\u793a\u771f\u5b9e\u5206\u7c7b\u7684\u8f83\u9ad8\u50cf\u7d20\u503c\u548c\u6307\u793a\u5047\u5206\u7c7b\u7684\u8f83\u4f4e\u503c","096d6399":"\u81ea\u6211\u4e00\u81f4\u635f\u5931\uff08\u8bba\u6587\u4e2d\u6ca1\u6709\u7684\u90e8\u5206\uff09","f20594ea":"# \u53ef\u89c6\u5316\u7ed3\u679c","2a6cc500":"# \u8bfb\u53d6\u6570\u636e\n\n\u8bfb\u53d6jpg\u6587\u4ef6","2938d741":"# \u751f\u6210\u5668\u7684\u5b9e\u73b0\n\n\u751f\u6210\u5668\u4f7f\u7528U-Net\u6765\u5b9e\u73b0\u3002U-Net\u4e3b\u8981\u88ab\u7528\u4e8e\u56fe\u50cf\u5206\u5272\u3002\u7531\u4e8e\u662f\u4e2a\u56fe\u50cf\u5230\u56fe\u50cf\u7684\u7f51\u7edc\uff0c\u56e0\u6b64\u5728CycleGAN\u4e2d\u53ef\u4ee5\u88ab\u7528\u4e8e\u751f\u6210\u5668\n\nU-Net\u9996\u5148\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e0b\u91c7\u6837\uff0c\u65b9\u6cd5\u662f\u4f7f\u7528\u6b65\u957f\u4e3a2\u7684$4\\times 4$**\u5377\u79ef**\uff0c\u4f7f\u7528padding=\"same\"\uff0c\u5c06\u4f7f\u5f97\u5377\u79ef\u540e\u56fe\u7247\u7684\u5c3a\u5bf8\u53d8\u4e3a\u201c\u539f\u5c3a\u5bf8\/\u6b65\u957f\u201c\u7684\u5411\u4e0a\u53d6\u6574\uff08\u5982\u679cpadding=\"valid\"\uff0c\u5219\u56fe\u7247\u7684\u5c3a\u5bf8\u4f1a\u53d8\u4e3a\u201c(\u539f\u5c3a\u5bf8-\u5377\u79ef\u6838\u5c3a\u5bf8+1)\/\u6b65\u957f\u201c\u7684\u5411\u4e0a\u53d6\u6574\uff09\u3002\u7b2c\u4e00\u6b21\u5377\u79ef\uff0c\u4f7f\u752864\u4e2a\u5377\u79ef\u6838\u5c063\u901a\u9053\u53d8\u621064\u901a\u9053\uff0c\u4e4b\u540e\u6bcf\u4e00\u6b21\u4f7f\u7528\u7684\u5377\u79ef\u6838\u6570\u76ee\u662f\u4e0a\u4e00\u6b21\u7684\u4e24\u500d\uff0c\u4ece\u800c\u5c06\u901a\u9053\u6570\u589e\u5927\u4e00\u500d\uff0c\u6700\u5927\u589e\u5927\u5230512\u901a\u9053\u3002**\u4fdd\u5b58\u4e0b\u91c7\u6837\u7684\u6bcf\u4e00\u6b65\u7684\u7ed3\u679c**\uff0c\u5728\u4e4b\u540e\u4f1a\u7528\u5230\u3002\n\n\u7b49\u5230\u628a\u56fe\u7247\u5927\u5c0f\u5377\u79ef\u5230$1\\times 1$\u540e\uff0c\u8f6c\u4e3a\u5bf9\u56fe\u7247\u8fdb\u884c\u5347\u91c7\u6837\uff0c\u65b9\u6cd5\u662f\u4f7f\u7528\u6b65\u957f\u4e3a2\u7684$4\\times 4$**\u9006\u5377\u79ef**\uff0c\u4f7f\u7528padding=\"same\"\uff0c\u5c06\u4f7f\u5f97\u5377\u79ef\u540e\u56fe\u7247\u7684\u5c3a\u5bf8\u53d8\u4e3a\u201c\u539f\u5c3a\u5bf8\\*\u6b65\u957f\u201c\uff08\u5982\u679cpadding=\"valid\"\uff0c\u5219\u56fe\u7247\u7684\u5c3a\u5bf8\u4f1a\u53d8\u4e3a\u201c\u539f\u5c3a\u5bf8\\*\u6b65\u957f-\u5377\u79ef\u6838\u5c3a\u5bf8+1\u201c\uff09\u6700\u540e\u4e00\u6b21\u5377\u79ef\uff0c\u4f7f\u75283\u4e2a\u5377\u79ef\u6838\u5c0664\u901a\u9053\u53d8\u62103\u901a\u9053\uff0c\u4e4b\u524d\u6bcf\u4e00\u6b21\u4f7f\u7528\u7684\u5377\u79ef\u6838\u6570\u76ee\u662f\u524d\u4e00\u6b21\u76841\/2\u500d\uff0c\u4ece\u800c\u5c06\u901a\u9053\u6570\u51cf\u5c11\u4e00\u534a\uff0c\u4ece512\u901a\u9053\u5f00\u59cb\u51cf\u5c11\u3002\u4e0a\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u6b21\u4f1a\u6cbf\u901a\u9053\u7ef4\u5ea6\u62fc\u63a5\u4e0b\u91c7\u6837\u8fc7\u7a0b\u4e2d\u5bf9\u5e94\u6b65\u7684\u7ed3\u679c\u3002","a4dfa635":"# CycleGAN\n\nCycleGAN\u5305\u542b\u4e24\u4e2a\u751f\u6210\u5668$G$\u548c$F$\uff0c\u5bf9\u5e94\u4e24\u4e2a\u9274\u522b\u5668$D_X$\u548c$D_Y$\n\n* \u751f\u6210\u5668\uff1a$G(x)$\uff0c$x$\u4e3a\u5206\u5e03$p_x$\u4e2d\u53d6\u6837\u7684\u6837\u672c\uff0c\u76ee\u6807\u662f\u5176\u751f\u6210\u7684\u6837\u672c\u548c\u5206\u5e03$p_y$\u4e2d\u53d6\u6837\u7684\u6837\u672c$y$\u5c3d\u53ef\u80fd\u63a5\u8fd1\n* \u9274\u522b\u5668\uff1a$D_Y(y)$\uff0c\u76ee\u6807\u662f\u5c3d\u53ef\u80fd\u533a\u5206$G(x)$\u548c$y$\uff0c\u8f93\u51fa\u5c5e\u4e8e$G(p_x)$\u800c\u4e0d\u5c5e\u4e8e$p_y$\u7684\u6982\u7387\n\n**\u5bf9\u6297\u6027\u635f\u5931**1\uff1a$L_{GAN}(G,D_Y)=E_{y\\sim p_y}(logD_Y(y))+E_{x\\sim p_x}(logD_Y(G(x)))$\n\n* \u751f\u6210\u5668\uff1a$F(y)$\uff0c$y$\u4e3a\u5206\u5e03$p_y$\u4e2d\u53d6\u6837\u7684\u6837\u672c\uff0c\u76ee\u6807\u662f\u5176\u751f\u6210\u7684\u6837\u672c\u548c\u5206\u5e03$p_x$\u4e2d\u53d6\u6837\u7684\u6837\u672c$x$\u5c3d\u53ef\u80fd\u63a5\u8fd1\n* \u9274\u522b\u5668\uff1a$D_X(x)$\uff0c\u76ee\u6807\u662f\u5c3d\u53ef\u80fd\u533a\u5206$ F(y)$\u548c$x$\uff0c\u8f93\u51fa\u5c5e\u4e8e$F(p_y)$\u800c\u4e0d\u5c5e\u4e8e$p_x$\u7684\u6982\u7387\n\n**\u5bf9\u6297\u6027\u635f\u5931**2\uff1a$L_{GAN}(F,D_X)=E_{x\\sim p_x}(logD_X(x))+E_{y\\sim p_y}(logD_X(F(y)))$\n\n\u5c3d\u7ba1\u4e0a\u8ff0\u7684\u5bf9\u6297\u6027\u635f\u5931\u80fd\u591f\u8ba9\u751f\u6210\u5668$G$\u548c\u751f\u6210\u5668$F$\u5b66\u4e60\u5230$p_x$\u548c$p_y$\uff0c\u4f46\u662f\u5374\u6ca1\u6709\u4fdd\u8bc1\u4ece$x$\u5f97\u5230$G(x)$\u65f6\u56fe\u50cf\u7684\u5185\u5bb9\u4e0d\u53d8\uff0c\u56e0\u4e3a$G(x)$\u53ea\u9700\u8981\u7b26\u5408$p_y$\u5373\u53ef\uff0c\u5e76\u6ca1\u6709\u5bf9\u5176\u65bd\u52a0\u7ea6\u675f\uff0c\u6240\u4ee5$x$\u5230$G(x)$\u5305\u542b\u5f88\u591a\u79cd\u53ef\u80fd\u7684\u6620\u5c04\n\n\u4e3a\u6b64\uff0c\u4f7f\u7528**\u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931**\u6765\u4f5c\u4e3a\u7ea6\u675f\uff0c\u4f7f\u5f97$G$\u751f\u6210\u7684$G(x)$\u5728\u5185\u5bb9\u4e0a\u4ecd\u7136\u80fd\u548c$x$\u4fdd\u6301\u4e00\u81f4\n\n\u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931\uff1a$L_{cyc}(G,F)=E_{x\\sim p_x}[||F(G(x))-x||_1]+E_{y\\sim p_y}[||G(F(y))-y||_1]$\n\n\u603b\u4f53\u635f\u5931\uff1a$L(G,F,D_X,D_Y)=L_{GAN}(G,D_Y)+L_{GAN}(F,D_X)+\\lambda L_{cyc}(G,F)$\n\n\u4ee5\u4e0a\u662fCycleGAN\u8bba\u6587\u4e2d\u7684\u5185\u5bb9\uff0c\u5b9e\u73b0\u7684\u65f6\u5019\u6211\u4eec\u5b9e\u9645\u4e0a\u662f\u8fd9\u4e48\u505a\u7684\uff1a\n\n* \u5bf9\u9274\u522b\u5668$Y $\u800c\u8a00\uff0c\u8981\u6700\u5c0f\u5316\u7684\u635f\u5931\u51fd\u6570\u4e3a\uff1a$D_Y(y)$\u63a5\u8fd10\u7684\u7a0b\u5ea6+$D_Y(G(x))$\u63a5\u8fd11\u7684\u7a0b\u5ea6\n* \u5bf9\u9274\u522b\u5668$X $\u800c\u8a00\uff0c\u8981\u6700\u5c0f\u5316\u7684\u635f\u5931\u51fd\u6570\u4e3a\uff1a$D_X(x)$\u63a5\u8fd10\u7684\u7a0b\u5ea6+$D_X(F(y))$\u63a5\u8fd11\u7684\u7a0b\u5ea6\n* \u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931\u4e3a\uff1a$F(G(x))$\u4e0e$x$\u7684\u8ddd\u79bb\uff08\u50cf\u7d20\u5e73\u5747\uff09+$G(F(y))$\u4e0e$y$\u7684\u8ddd\u79bb\uff08\u50cf\u7d20\u5e73\u5747\uff09\n* \u5bf9\u751f\u6210\u5668$G$\u800c\u8a00\uff0c\u8981\u6700\u5c0f\u5316\u7684\u635f\u5931\u51fd\u6570\u4e3a\uff1a$D_Y(G(x))$\u63a5\u8fd10\u7684\u7a0b\u5ea6+$\\lambda$*\u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931\n* \u5bf9\u751f\u6210\u5668$F$\u800c\u8a00\uff0c\u8981\u6700\u5c0f\u5316\u7684\u635f\u5931\u51fd\u6570\u4e3a\uff1a$D_X(F(y))$\u63a5\u8fd10\u7684\u7a0b\u5ea6+$\\lambda$*\u5faa\u73af\u4e00\u81f4\u6027\u635f\u5931\n\n\u6211\u4eec\u8ba9\u9274\u522b\u5668\u8f93\u51fa\u4e00\u4e2a$30\\times30$\u7684\u77e9\u9635\u4f5c\u4e3a\u7ed3\u679c\uff0c\u5e76**\u4e0e\u51680\u77e9\u9635\u6216\u51681\u77e9\u9635\u8ba1\u7b97\u4ea4\u53c9\u71b5**\uff0c\u4ee5\u8861\u91cf\u8f93\u51fa\u7ed3\u679c\u63a5\u8fd10\u6216\u63a5\u8fd11\u7684\u7a0b\u5ea6\n\n\u672c\u4ee3\u7801\u8fd8\u5305\u62ec\u4e00\u4e2a\u81ea\u6211\u4e00\u81f4\u6027\u635f\u5931\uff0c\u8fd9\u662f\u8bba\u6587\u4e2d\u6ca1\u6709\u7684\u90e8\u5206\uff0c\u8ba1\u7b97\u7684\u662f$G(y)$\u4e0e$y$\u7684\u8ddd\u79bb\uff08\u50cf\u7d20\u5e73\u5747\uff09+$F(x)$\u4e0e$x$\u7684\u8ddd\u79bb\uff08\u50cf\u7d20\u5e73\u5747\uff09\uff0c\u540c\u6837\u4e58\u4ee5$\\lambda$\u540e\u52a0\u5230\u4e86\u751f\u6210\u5668\u7684\u635f\u5931\u51fd\u6570\u4e0a"}}