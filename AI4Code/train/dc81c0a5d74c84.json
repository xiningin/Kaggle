{"cell_type":{"7c786dd2":"code","50170dbe":"code","7467365c":"code","0032d8f3":"code","898223d1":"code","e82cbf3e":"code","3143d6f5":"code","91d74ca5":"code","9adedc17":"code","7ca9bce7":"code","99342ba0":"code","9a96f315":"code","d8cf4655":"code","fcd4f696":"code","ec1e80be":"code","3afbb7b8":"code","ed9e2fac":"code","21aa1756":"code","3ca11e28":"code","ec8d053c":"code","487c9869":"code","caeb319d":"code","27b8e49e":"code","25fe15f0":"code","919b1ac5":"code","9d89786e":"code","a12fae15":"code","e43ba939":"code","dab3f690":"code","2941ec86":"code","61c15dab":"code","9af48c49":"code","6100efc3":"code","5037d5d6":"code","6ec40790":"code","b01709c5":"code","b3ca3fcf":"code","c892c5b4":"code","ae840226":"code","9aa16801":"code","230d8c6e":"code","ef253a22":"code","f692c2c6":"code","005c0eb8":"code","47a1d9ba":"code","d4d8a0e7":"code","770599d3":"code","12a35fbf":"code","4ab16ac0":"code","ccddd6f2":"code","95520339":"code","d02457c5":"code","21f78ccb":"code","381f3a65":"code","a752980e":"code","5e3477e6":"code","d728083f":"code","1fa8d266":"markdown","1fc31703":"markdown","505ed8f3":"markdown","c883c21a":"markdown","f29a68d4":"markdown","003cedb9":"markdown","cabfcf48":"markdown","6269c60a":"markdown","59a53a8e":"markdown","8eb99fdd":"markdown","42e1ec2d":"markdown","016d577b":"markdown","2e5159b3":"markdown","c09b9236":"markdown","ef6cee2b":"markdown","d9971b33":"markdown","26008fca":"markdown","e0da9e78":"markdown","e1044deb":"markdown","0f8c2dc7":"markdown","0c20dd7d":"markdown","f3a08785":"markdown","305c319a":"markdown","c17c0705":"markdown","42223267":"markdown","801a161d":"markdown","48cca68f":"markdown","42f236af":"markdown","237a9ce4":"markdown","4eee8307":"markdown","d0434a40":"markdown","6cb54b34":"markdown","12578821":"markdown","36e409ed":"markdown","b721a895":"markdown","88a0a85a":"markdown","f6ea89aa":"markdown","e122b152":"markdown","c03c636f":"markdown","2c53b57a":"markdown"},"source":{"7c786dd2":"import numpy as np \nimport pandas as pd\nimport os\n\n#Data Visualization:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Text Color\nfrom termcolor import colored\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (8, 6)","50170dbe":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7467365c":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain.head()","0032d8f3":"test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest.head()","898223d1":"print('train : {} , test : {}'.format(colored(train.shape,'blue'),colored(test.shape,'blue')))","e82cbf3e":"gender_submission=pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ngender_submission.head()","3143d6f5":"# #Survivors By gneder\nsns.countplot(x='Survived',hue='Sex',data=train)\nplt.title('#Survivors by gender')\nplt.show()","91d74ca5":"train.groupby(['Sex']).Survived.mean().plot.bar(color=['fuchsia', 'blue'])\nplt.xlabel('Sex')\nplt.ylabel('% of Survivors')\nplt.title('Sex vs Survived')\nplt.show()","9adedc17":"sns.violinplot(x='Survived',y='Age',data=train)\nplt.title('Survived VS Age')\nplt.show()","7ca9bce7":"# Distribution of Age\nsns.displot(x='Age',data=train,color='r',bins=45)\nplt.show()","99342ba0":"train.groupby(['Pclass']).Survived.agg(['count','mean'])","9a96f315":"sns.countplot(x='Survived',hue='Pclass',data=train)\nplt.show()","d8cf4655":"train.Embarked.value_counts().to_frame()","fcd4f696":"sns.countplot(x='Survived',hue='Embarked',data=train)\nplt.title('#Survivors by port of embarkation')\nplt.show()","ec1e80be":"train.groupby(['Embarked']).Survived.mean().plot.barh(color=['Red','green','blue' ])\nplt.xlabel('% fo Survivors')\nplt.show()","3afbb7b8":"train.groupby(['SibSp']).Survived.agg(['count','mean'])","ed9e2fac":"train.groupby(['Parch']).Survived.agg(['count','mean'])","21aa1756":"train.groupby(['SibSp','Parch']).Survived.agg(['count','mean'])","3ca11e28":"#Fare Distribution:\n\ntrain.Fare.hist(bins=70,color='b')\nplt.xlabel('Fare')\nplt.show()","ec8d053c":"for col in ['Name','Ticket','Cabin']:\n    print('Conrdinality of {} is : {} '.format(colored(col,'green'),colored(len(train[col].unique()),'blue')))","487c9869":"heatmap=sns.heatmap(train.corr(),annot=True,cmap='coolwarm')","caeb319d":"train.corr()[['Survived']].T","27b8e49e":"ntrain=train.shape[0] # will be used to split combined data set\n\ndata=pd.concat((train,test)).reset_index(drop=True)\nprint('The shape of the combined dataframe is:', colored(data.shape,'blue'))","25fe15f0":"data.info()","919b1ac5":"train.describe()","9d89786e":"#Check for missing values :\ntrain.isnull().sum()","a12fae15":"# Check if there any missing values in train set\nax = train.isna().sum().sort_values().plot(kind = 'barh', figsize = (8, 7),color='b')\nplt.title('Percentage of Missing Values Per Column in Train Set', fontdict={'size':15})\nfor p in ax.patches:\n    percentage ='{:,.0f}%'.format((p.get_width()\/train.shape[0])*100)\n    width, height =p.get_width(),p.get_height()\n    x=p.get_x()+width+0.02\n    y=p.get_y()+height\/2\n    ax.annotate(percentage,(x,y))","e43ba939":"test.isnull().sum()","dab3f690":"# Check if there any missing values in test set\nax = test.isna().sum().sort_values().plot(kind = 'barh', figsize = (8, 7),color='b')\nplt.title('Percentage of Missing Values Per Column in Train Set', fontdict={'size':15})\nfor p in ax.patches:\n    percentage ='{:,.0f}%'.format((p.get_width()\/train.shape[0])*100)\n    width, height =p.get_width(),p.get_height()\n    x=p.get_x()+width+0.02\n    y=p.get_y()+height\/2\n    ax.annotate(percentage,(x,y))","2941ec86":"#lets save the location of Nan values first :\ncabin_nan=np.where(data.Cabin.isnull(),1,0)\nage_nan=np.where(data.Age.isnull(),1,0)","61c15dab":"data['Cabin']=data['Cabin'].fillna(data.Cabin.value_counts().index[0])\ndata['Embarked']=data['Embarked'].fillna(data.Embarked.value_counts().index[0])\ndata['Age']=data['Age'].fillna(data['Age'].mean())\ndata['Fare']=data['Fare'].fillna(data['Fare'].mean())","9af48c49":"data['CabinNan']=cabin_nan\ndata['AgeNan']=age_nan","6100efc3":"data['cabinLetter']=data.Cabin.apply(lambda x:x[0])\ndata['cabinLetter'].value_counts()","5037d5d6":"data['familySize']=data.SibSp+data.Parch+1","6ec40790":"sns.factorplot(x=\"familySize\",y=\"Survived\",data = data).set_ylabels('Survived Probability')\nplt.show()","b01709c5":"data['Alone']=[1 if Fsize==1 else 0 for Fsize in data['familySize']]\ndata['withFamily']=[1 if Fsize>=2 else 0 for Fsize in  data['familySize']]","b3ca3fcf":"data.Name.sample(10)","c892c5b4":"import re\ndata[\"NameTitle\"] = data.Name.apply(lambda x:re.search(' ([A-Z][a-z]+)\\. ',x).group(1))","ae840226":"data.NameTitle.value_counts()","9aa16801":"data[data.NameTitle=='Dr'][['Sex','Age','NameTitle']]","230d8c6e":"data.loc[[796],['NameTitle']]='Mrs' \ndata.loc[[796]]","ef253a22":"#Col and Major:\ndata[(data.NameTitle=='Col')|(data.NameTitle=='Major')|(data.NameTitle=='Jonkheer')|(data.NameTitle=='Capt')][['Sex','NameTitle']]","f692c2c6":"data[data['NameTitle']=='Ms']","005c0eb8":"data['NameTitle']=data['NameTitle'].replace(['Lady','Mme','Dona','Countess'],'Mrs')\ndata['NameTitle']=data['NameTitle'].replace(['Mlle','Ms'],'Miss')\ndata['NameTitle']=data['NameTitle'].replace(['Rev','Dr','Major','Don','Capt','Col','Sir','Jonkheer'],'Mr')","47a1d9ba":"sns.factorplot(x=\"Survived\", y =\"NameTitle\", data=data, kind=\"bar\", size=6)\nplt.show()","d4d8a0e7":"def Create_Cat(col,q):\n    return pd.qcut(data['Age'],  q=q, labels=False)\n    \ndata['Age_Cat']=Create_Cat('Age',4)\ndata['Fare_Cat']=Create_Cat('Fare',4)","770599d3":"numericalFeatures = [feature for feature in data.columns if data[feature].dtypes!='O']\nCategoricalFeatures=[feature for feature in data.columns if data[feature].dtype=='O']","12a35fbf":"from sklearn.preprocessing import LabelEncoder\nfor col in CategoricalFeatures:\n    data[col]=LabelEncoder().fit_transform(data[col])","4ab16ac0":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\ndata[['Age','Fare']]=sc.fit_transform(data[['Age','Fare']])","ccddd6f2":"# Separate train and test data from the combined dataframe\ntrain_df=data[:ntrain]\ntest_df=data[ntrain:].drop(['Survived'],axis=1)\n\n# Check the shapes of the split dataset\ntrain_df.shape, test_df.shape","95520339":"data.head()","d02457c5":"#Separete the features and the target varaibles:\ndrop_cols=['Survived','PassengerId','Name','Ticket','CabinNan','AgeNan']\nX=train_df.drop(drop_cols,axis=1)\ny=train_df.Survived.astype(int)\n# Split data into train and test sets\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=44)","21f78ccb":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(X_train,y_train)\ny_predict= lr.predict(X_test)\nprint('score =',lr.score(X_test,y_test))\nprint (\"Accuracy = %.2f\" % (accuracy_score(y_test,y_predict)))","381f3a65":"from catboost import CatBoostClassifier\n\ncb = CatBoostClassifier(iterations=1000,\n                           depth=3,\n                           learning_rate=0.002,\n                           loss_function='Logloss',\n                           verbose=False)\ncb.fit(X_train,y_train)\n\n\n\ny_predict= cb.predict(X_test)\nprint('score =',cb.score(X_test,y_test))\nprint (\"Accuracy = %.2f\" % (accuracy_score(y_test,y_predict)))","a752980e":"from xgboost.sklearn import XGBClassifier\nXgC = XGBClassifier(learning_rate=0.001,n_estimators=3000,\n                                max_depth=2, min_child_weight=0,\n                                subsample=0.5,\n                                colsample_bytree=0.5,\n                                scale_pos_weight=1, seed=44,\n                                reg_alpha=0.001)\nXgC.fit(X_train,y_train)\n\ny_predict= XgC.predict(X_test)\nprint('score =',XgC.score(X_test,y_test))\nprint (\"Accuracy = %.2f\" % (accuracy_score(y_test,y_predict)))","5e3477e6":"from sklearn.ensemble import RandomForestClassifier\nclf=RandomForestClassifier(n_estimators=100)\nclf.fit(X_train,y_train)\n\ny_predict= clf.predict(X_test)\nprint (\"Accuracy = %.2f\" % (accuracy_score(y_test,y_predict)))","d728083f":"X_Submission=test_df.drop(drop_cols[1:],axis=1)\npredictions = cb.predict(X_Submission)\n\n# Generate Submission\noutput = pd.DataFrame({'PassengerId':test.PassengerId, 'Survived':predictions})\noutput.to_csv('gender_submission.csv', index=False)\nprint(\"Submission successfully saved\")","1fa8d266":"**74% of female and 18% of male survived form the titanc.**","1fc31703":"* **Catboost** ","505ed8f3":"**Maybe We can extract Name title ;)**\n\nFor that we will use Regular Expressions, the title is always starting with one capital letter after that we have small letters and finaly there's end point.","c883c21a":"This two columns save the locations of NaN values in the two columns Cabin and Age","f29a68d4":"###  Lable Encoding ","003cedb9":"* **Passanger Class (Pclass) :**","cabfcf48":"This is my first kernel at Kaggle. I choosed the Titanic competition because it's a very good way to introduce feature engineering and classification models.\n\n**objective** : Predict if a passenger can survived on the titanic or not.\n\n![Titanic](https:\/\/pngimg.com\/uploads\/titanic\/titanic_PNG6.png)\n\n* **Content :**\n1. [Introduction](#Intro)\n2. [Importing Libraries](#ImportingLibraries)\n3. [Loading the data](#LoadingData)\n4. [Exploratory data Analysis](#EDA)\n5. [Data Preprocessing](#Pre-Processing)\n6. [Modling](#Modling)\n7. [Submition](#Submition)","6269c60a":"* **Conrdinality:**","59a53a8e":"#### Handling Missing values :","8eb99fdd":"***The Cabin column contains maximum null values in both datasets.***","42e1ec2d":"* **Passenger Fare :**","016d577b":"<a id=\"Intro\"><\/a>\n<div class=\"alert alert-block alert-info\">\n<b>Introduction<\/b>\n<\/div>","2e5159b3":"**Thanks for your time :)**","c09b9236":"### Feature Engineering","ef6cee2b":"* **XgBoostClassifier :**","d9971b33":"* **Split the data**:","26008fca":"* **Familly (SibSp and Parch):**","e0da9e78":"<a id=\"Submition\"><\/a>\n<div class=\"alert alert-block alert-info\">\n<b>Submition<\/b>","e1044deb":"Correlations between the target variable and numerical variables aren't high","0f8c2dc7":"**62% of survivors are using the class 1**\n\nTravling in a Higher class increase the probability of surviving","0c20dd7d":"*  **Fill in missing values :**","f3a08785":"<a id=\"Modling\"><\/a>\n\n<div class=\"alert alert-block alert-info\">\n<b>Modling<\/b><center>\n","305c319a":"* **Logistic Regression :**","c17c0705":"Let's Combine train and test set for easy preprocessing","42223267":"* **Correlation**","801a161d":"<a id=\"EDA\"><\/a>\n\n<div class=\"alert alert-block alert-info\">\n<b>Exploratory data Analysis<\/b><center>","48cca68f":"Here I will create a new feature where I will get first letter from every Cabin in the dataset.","42f236af":"there just one female with Dr as a NameTitle and her age is 49. So we can change her title to Mrs","237a9ce4":"**Women more likely to survive than men**","4eee8307":"* **Passanger Age :**","d0434a40":"<a id=\"ImportingLibraries\"><\/a>\n<div class=\"alert alert-block alert-info\">\n<b>Importing Libraries<\/b>","6cb54b34":"* **Port of Embarkation :**\n\n\n*  C = Cherbourg\n* Q = Queenstown \n* S = Southampton","12578821":"All Majors, Colonels, Capt and Jonkheer are male gender so we can use Mr as a Name title","36e409ed":"* For Embarked and Cabin variables. I choose to use the most popular value\n* For Age and Fare I will use the mean value","b721a895":"* **Surivors and gender :**","88a0a85a":"<a id=\"Pre-Processing\"><\/a>\n\n<div class=\"alert alert-block alert-info\">\n<b>Data Pre-Processing<\/b><center>\n","f6ea89aa":"* Name :","e122b152":"**We can see that the cordinality of Name,Ticket and Cabin is high**","c03c636f":"* Random Forest:","2c53b57a":"<a id=\"LoadingData\"><\/a>\n<div class=\"alert alert-block alert-info\">\n<b>Loading the data<\/b><center>"}}