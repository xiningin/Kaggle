{"cell_type":{"6116ebe2":"code","de0dafad":"code","317e6813":"code","52b999cc":"code","075af5e3":"code","d3e77627":"code","919020d6":"code","97382884":"code","e9339cc5":"code","db5e3a0c":"code","70c539b7":"code","577ee980":"code","325994e8":"code","5e601dfb":"code","33afe588":"code","1006194d":"code","490d6779":"code","58d0750e":"code","6aa0b33f":"code","0249b6f5":"code","3c60dedd":"markdown","dff63042":"markdown","b639ffa9":"markdown","1861bc6a":"markdown","4a84b0e9":"markdown","802939cc":"markdown","017cf98d":"markdown","5e6be207":"markdown","3c770ed7":"markdown","12f7dc2f":"markdown","ad89db27":"markdown","7f41a775":"markdown"},"source":{"6116ebe2":"import numpy as np\nfrom numpy import interp\nimport pandas as pd\nimport os\nimport math","de0dafad":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","317e6813":"from statistics import mean\nfrom sklearn import model_selection\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, classification_report\nfrom sklearn.multiclass import OneVsRestClassifier","52b999cc":"fetal_health_df = pd.read_csv(\"..\/input\/fetal-health-classification\/fetal_health.csv\")\nfetal_health_df.drop_duplicates(inplace = True)","075af5e3":"fetal_health_df.head()","d3e77627":"fetal_health_df.info()","919020d6":"fetal_health_df.shape","97382884":"X = fetal_health_df.drop(columns = ['fetal_health'],axis = 1)\ny = fetal_health_df['fetal_health'].to_numpy()\ny = preprocessing.label_binarize(y, classes=[1.0, 2.0, 3.0])","e9339cc5":"plt.figure(figsize=(12, 6))\nsns.countplot(fetal_health_df['fetal_health'], palette='viridis')\nplt.title('Dependent variable distribution plot')\nplt.xlabel('Fetal Health')","db5e3a0c":"correlation = fetal_health_df.corr()\nplt.figure(figsize=(20, 12))\nsns.heatmap(correlation, cmap=\"coolwarm\", annot=True)","70c539b7":"col_names = X.columns","577ee980":"feature_selection_classifier = DecisionTreeClassifier()\nsfm = SelectFromModel(estimator=feature_selection_classifier)\nX_transformed = sfm.fit_transform(X, y)\nsupport = sfm.get_support()","325994e8":"selected_cols = [x for x, y in zip(col_names, support) if y == True]","5e601dfb":"#X_selected = fetal_health_df[selected_cols]\nX_selected=fetal_health_df.loc[:, fetal_health_df.columns.isin(selected_cols)]","33afe588":"X_selected.head()","1006194d":"scaler = preprocessing.StandardScaler() \nX_scaled = scaler.fit_transform(X_selected) ","490d6779":"n_bins = 1 + round(math.log(len(X_selected.axes[0])))\nprint(n_bins)","58d0750e":"stratified_kf = model_selection.StratifiedKFold(n_splits = n_bins, shuffle=True)","6aa0b33f":"fetal_health_classifier = OneVsRestClassifier(RandomForestClassifier(n_estimators=1000, class_weight='balanced', random_state = 42))\n\nfig1 = plt.figure(figsize=[12,12])\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nall_f1_score = []\nprecision_dict = dict()\nrecall_dict = dict()\n\n\nfor i, (train_index, test_index) in enumerate(stratified_kf.split(X_scaled, y.argmax(1))):\n    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    fetal_health_classifier.fit(X_train, y_train)\n    y_pred = fetal_health_classifier.predict(X_test)\n    prediction_proba = fetal_health_classifier.predict_proba(X_test)\n    fpr, tpr, t = roc_curve(y_test[:, 1], prediction_proba[:, 1])\n    precision_dict[i], recall_dict[i], _ = precision_recall_curve(y_test[:, 1], prediction_proba[:, 1])\n    f1score = f1_score(y_test, y_pred, average='weighted')\n    all_f1_score.append(f1score)\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n    \n\nmean_fi_score = mean(all_f1_score)\nprint(\"Mean F1-score across all folds: \", mean_fi_score)\nplt.plot([0, 1], [0, 1], linestyle = '--', lw = 2, color = 'black')\nmean_tpr = np.mean(tprs, axis=0)\nmean_auc = auc(mean_fpr, mean_tpr)\nprint(\"Mean ROC across all folds: \", mean_auc)\nplt.plot(mean_fpr, mean_tpr, color='blue', label=r'Mean ROC(AUC=%0.2f)' % (mean_auc), lw = 2, alpha=1)\n         \n         \nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","0249b6f5":"fig2 = plt.figure(figsize=[12,12])\n\nfor i in range(len(precision_dict)):\n    plt.plot(recall_dict[i], precision_dict[i], lw=2, label='Fold %d' % i)\n    \n    \n    \nplt.xlabel(\"recall\")\nplt.ylabel(\"precision\")\nplt.legend(loc=\"best\")\nplt.title(\"precision vs. recall curve\")\nplt.show()","3c60dedd":"# Feature Selection\nTrain DecisionTreeClassifier over the data and select the features using feature importance generated by the model","dff63042":"**Approach:**\n\n1. Fetch the data from dataset and identify independent and dependent\/target variables\n2. Since it is a multi-class problem, we need to binarise the target variable.\n3. Understand the distribution of target variable\n4. Understand the correlation between different variables\n5. Select the independent variables that contribute the most towards the model and create a dataframe using only those variables\n6. Scale the independent variables\n7. Decide the number of folds to be used in ***Stratified K-Fold***\n8. Derive various metrics like ***ROC curve, F1 Score, Precision and Recall*** for the classification model over the Stratified K folds.","b639ffa9":"# Understand the dependent variable distribution plot","1861bc6a":"![Fetal Health Classification](https:\/\/stream.org\/wp-content\/uploads\/Scientist-Fetus-Embryo-healthy-Life-Baby-Science-Studies-900.jpg)","4a84b0e9":"The target class **'fetal_health'** is unbalanced.","802939cc":"**Aim:**\n\nTo classify fetal health as ***Normal, Suspect, Pathological*** as the outcome of Cardiotocogram (CTG) exam. This will help to prevent child and maternal mortality.","017cf98d":"## Scaling the independent variables","5e6be207":"# Calculate ROC curve, F1 score, Precision and Recall","3c770ed7":"## Deciding number of bins to be created for Stratified k-fold\n\nSince the target variable distribution is non-uniform, we will use Stratified KFold for evaluating our model over different sets of data.\n\nTo decide the number of folds, we will use Sturge's rule: \n\n> Number of Bins = 1 + log(N)","12f7dc2f":"Dividing the data into Independent and Dependent variables. \n\nWe will have to binarize the target variable(y) because roc_curve is restricted to binary classification or multi-label classification.","ad89db27":"# Understand the correlation between differnt variables in the dataset","7f41a775":"Image source: Google Images"}}