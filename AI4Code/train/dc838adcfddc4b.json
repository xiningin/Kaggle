{"cell_type":{"f958d085":"code","2a68544e":"code","13b90491":"code","55a9f4d5":"code","b585248e":"code","7c760139":"code","8708cbc9":"code","b048cdc0":"code","cbc921cd":"code","29bc4199":"code","874205b4":"code","21d3018e":"code","c5ffe623":"code","065cfdc9":"code","da1a65ba":"code","0556eb3c":"code","81e3bca2":"code","3e1e5c51":"markdown","cbe516de":"markdown","91e384a4":"markdown","12e7ccaf":"markdown","28dccb77":"markdown","4c965f29":"markdown","70243bf3":"markdown","ad040581":"markdown","d225c952":"markdown","d6c76497":"markdown","a20d7df8":"markdown"},"source":{"f958d085":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2a68544e":"data_train = pd.read_csv('..\/input\/train.csv')\ndata_test = pd.read_csv('..\/input\/test.csv')\n# data_train.head()\ndata_train.tail(20)","13b90491":"data_train.describe().T","55a9f4d5":"data_train.info()","b585248e":"sns.set_style('darkgrid')\nsns.countplot(data=data_train, x='Survived', hue='Sex')","7c760139":"sns.countplot(data=data_train, x='Survived',hue='Pclass')","8708cbc9":"sns.distplot(data_train['Age'].dropna(), bins=30)","b048cdc0":"figure = plt.figure(figsize=(10,6))\nsns.boxplot(data=data_train, x='Pclass', y='Age')","cbc921cd":"first_mean = round(data_train[data_train['Pclass'] == 1]['Age'].dropna().mean())\nsecond_mean = round(data_train[data_train['Pclass'] == 2]['Age'].dropna().mean())\nthird_mean = round(data_train[data_train['Pclass'] == 3]['Age'].dropna().mean())\n\n# creating function to fill missing age\ndef filling(col):\n    Age = col[0]\n    Pclass = col[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return first_mean\n        elif Pclass == 2:\n            return second_mean\n        else:\n            return third_mean\n    else:\n        return Age\n\ndata_train['Age'] = data_train[['Age', 'Pclass']].apply(filling, axis=1)","29bc4199":"sex = pd.get_dummies(data_train['Sex'],drop_first=True)\nembarked = pd.get_dummies(data_train['Embarked'],drop_first=True)","874205b4":"X_train = pd.concat([data_train[['Age', 'SibSp', 'Parch']], sex, embarked], axis=1)\ny_train = data_train['Survived']","21d3018e":"data_test['Age'] = data_test[['Age', 'Pclass']].apply(filling, axis=1)\nsex = pd.get_dummies(data_test['Sex'],drop_first=True)\nembarked = pd.get_dummies(data_test['Embarked'],drop_first=True)\nX_test = pd.concat([data_test[['Age', 'SibSp', 'Parch']], sex, embarked], axis=1)","c5ffe623":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100)\nmodel.fit(X_train, y_train)\nmodel.score(X_train, y_train)","065cfdc9":"predictions = model.predict(X_test)\ndata_test['Survived'] = predictions","da1a65ba":"submit = data_test[['PassengerId', 'Survived']]\nsubmit.to_csv('submission.csv', index=False)","0556eb3c":"y_test=data_test['Survived']","81e3bca2":"# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=10)\nprint(X_train,X_test,y_train,y_test)","3e1e5c51":"We see that there are some missing value in 'Age' column, we will deal with it later. For now we will continue on our exploration of datasets.","cbe516de":"We want to fill the missing value in Age. Looking at the boxplot above we can say that older person is more likely to afford higher class ticket. So based off this interpretation we will fill the missing value with age's average based on passenger class.","91e384a4":"We can see that there is more female that survive than male.","12e7ccaf":"## Exploratory Data Analysis","28dccb77":"Finally we've got our X_train and y_train","4c965f29":"### Next we will repeat the same process as above on our test data so we can use it for our prediction later.","70243bf3":"## Machine Learning Using Random Forest","ad040581":"# Predicting Titanic Survival","d225c952":"Based off passenger class there is more likely the passenger with higher class tend to survive.","d6c76497":"## Data Processing ","a20d7df8":"Since Sex and Embarked columns are categorical data, we will use dummy variables to get their values for our machine learning model."}}