{"cell_type":{"84bef3d2":"code","cdd7ca3f":"code","1eb64b2c":"code","d0f5a92c":"code","29436c4f":"code","617b7862":"code","5e8f6b95":"code","3069c9f5":"code","3edbc829":"code","0922bee0":"code","4a4a96f3":"code","33cc15f5":"code","56c4a0a8":"code","82c2832a":"code","a2cea8fd":"code","c5dcb966":"code","e742ea8e":"code","9dc5f341":"code","6fcf1264":"code","6f271cca":"code","772c9979":"code","809c9995":"code","e3e97ced":"code","a33d379e":"code","a73d755c":"code","3ea6330c":"code","ece2b7f7":"code","98ee49bc":"code","d3cdb07c":"code","e33c0dfa":"code","24ab9bf0":"code","d12a114f":"code","67671c96":"code","d382d7de":"code","f6cf4cca":"code","a619c642":"code","df07f6ba":"code","047d3b3a":"code","fc5f6a55":"code","29d4a98a":"code","90c65ccb":"code","b4c6fef6":"code","b2229dac":"code","725691dd":"code","e6b36a30":"code","4da8a829":"code","5f027b2a":"code","745efd3f":"code","fa0f75b2":"code","23e833f0":"code","eb0cdd4a":"code","4d547760":"code","194e3f80":"code","f8fbf577":"code","4ed1111d":"code","711e03aa":"code","b1763b36":"code","a9ecbf34":"code","1282f5de":"code","d087459a":"code","1dac33bb":"code","0858a153":"code","41154743":"code","3d1ef4fc":"code","bb571ded":"code","0d1e4733":"code","5ebb2704":"code","983bd96e":"code","2abaf6a3":"code","407274c6":"code","4dc66e7f":"code","84c146c2":"code","4a3ad28a":"code","52ee2bef":"code","b60a9743":"code","66b27696":"code","823c76e7":"code","f5575fa4":"code","c184312d":"code","27126f6c":"code","f6e9ade2":"code","926deaf3":"code","317b0aa5":"code","557b3ddc":"code","0b786df5":"code","bd95a819":"code","fdfddadf":"code","4fd7a5ea":"code","70c4d359":"code","0c160a7e":"code","6dc2c054":"code","611915a6":"code","9fdf26a8":"code","a8039a8d":"code","e9b4d41d":"code","646dd70a":"code","e8844f13":"code","e9b26873":"code","3f4562be":"code","89b3b500":"code","5c844424":"code","7757498b":"code","83b740a3":"code","2434b0d6":"code","2e40c985":"code","0ac5928a":"code","ee28c196":"code","cb5d0399":"code","8e155634":"code","0d66ba04":"code","8099969f":"code","c524b5b2":"code","24c4d721":"code","005df683":"code","e261f144":"code","92d04e65":"code","28c19eb5":"code","262a524d":"code","3413e4f1":"code","8bf164c3":"code","6c4b3004":"code","dfc9bcb7":"code","d661edbf":"code","0bd4c1fa":"code","dd2d4be6":"code","973ddbeb":"code","b0cb1754":"code","ca7649c8":"code","caca6c42":"code","3815ae93":"code","a3c7f0f3":"code","8541cdf4":"markdown","dbca947a":"markdown","5821aa57":"markdown","2bc439a2":"markdown","05dbd29f":"markdown","e30d24ce":"markdown","f63b5ef0":"markdown","ea8abd55":"markdown","771d5b18":"markdown","3af2d369":"markdown","50c6a631":"markdown","62df4461":"markdown","3ae9303c":"markdown","20ee1ec2":"markdown","beaefb08":"markdown","cdfd13a5":"markdown","37d9526b":"markdown","cb84e05a":"markdown","e2ed6272":"markdown","7bf264f0":"markdown","04f4baf5":"markdown","02c52c3a":"markdown","9970f929":"markdown","bb870472":"markdown","031fd513":"markdown","ee5f3e3c":"markdown","fc07391d":"markdown","130d67ec":"markdown","0a00e3e8":"markdown","d15378e5":"markdown","da29810c":"markdown","305a4c80":"markdown","e6e24d05":"markdown","816c170b":"markdown","d270a18b":"markdown","03578f08":"markdown","67b04bec":"markdown","bf655ada":"markdown","94938eb3":"markdown","2fb7d1b0":"markdown","8f8a3a14":"markdown","cbe50903":"markdown","9ed969d4":"markdown","0ce9dc95":"markdown","6fba7fe2":"markdown","3bdc7656":"markdown","51f4728c":"markdown","3dbd367a":"markdown","679ccf9f":"markdown","a4817393":"markdown","04009eb3":"markdown","987485ba":"markdown","0f0b8a2a":"markdown","15effa9f":"markdown","4b7e410d":"markdown","7395580a":"markdown","21012294":"markdown","15b9b222":"markdown","0494e7cf":"markdown","5d73d249":"markdown","59af682d":"markdown","a7babe56":"markdown","c9cd2503":"markdown","ee00e7d1":"markdown","85a36bb4":"markdown","2e944c63":"markdown","cab4b7f7":"markdown","cbddb559":"markdown","48cd4624":"markdown","257f7886":"markdown","4f3dac6d":"markdown","dce61c06":"markdown","71192b93":"markdown","1bcdcfee":"markdown","40303511":"markdown","15b9cbef":"markdown","0beb5cdb":"markdown","884def8f":"markdown","9b5859e5":"markdown","55371784":"markdown","b5c18df1":"markdown","3f5ef23a":"markdown","ac3c3628":"markdown"},"source":{"84bef3d2":"import numpy as np\nimport pandas as pd\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport scipy.stats as stats\nimport pingouin as pg\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set()\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cdd7ca3f":"raw_df = pd.read_csv('\/kaggle\/input\/canberra-real-estate-sales-20062019\/property_sales_canberra.csv')","1eb64b2c":"raw_df.head()","d0f5a92c":"raw_df.info()","29436c4f":"raw_df.describe(include='all')","617b7862":"# Checking raw datasets\n\ndesc = []\nfor i in raw_df.columns:\n    desc.append([i,\n                     raw_df[i].dtypes,\n                     raw_df[i].isna().sum(),\n                     round((raw_df[i].isna().sum())\/len(raw_df)*100,2),\n                     raw_df[i].nunique(),\n                     raw_df[i].drop_duplicates().sample(2).values])\npd.DataFrame(desc, columns = ['dataFeatures', 'dataType',' null', 'nullPct', 'unique', 'uniqueSample'])","5e8f6b95":"plt.figure(figsize=(15,8))\nsns.heatmap(raw_df.isnull(), yticklabels=False, cbar=False, cmap='rocket_r')\nplt.show()","3069c9f5":"raw_df.isna().sum()","3edbc829":"df = raw_df.copy()","0922bee0":"len(df.columns)  # checking","4a4a96f3":"categorical_columns = list(df.describe(exclude='number').columns)\nnumerical_columns = list(df.describe().columns)","33cc15f5":"numerical_columns.remove('postcode')\ncategorical_columns.append('postcode')","56c4a0a8":"categorical_columns, len(categorical_columns)","82c2832a":"numerical_columns, len(numerical_columns)","a2cea8fd":"for i in numerical_columns:\n    plt.figure(figsize = (8,8))\n    sns.distplot(df[i], kde=False)","c5dcb966":"numerical_columns_noprice = numerical_columns.copy()","e742ea8e":"numerical_columns_noprice.remove('price')","9dc5f341":"numerical_columns_noprice","6fcf1264":"for i in numerical_columns_noprice:\n    sns.scatterplot(df[i], df['price'])\n    plt.show()","6f271cca":"df[numerical_columns].describe()","772c9979":"df[categorical_columns].describe(include='all')","809c9995":"# Correlation Inspection\n\ntarget = 'price'\nk = 7 # number of variables for heat map\ncols = df[numerical_columns].corr().nlargest(k, target)[target].index\ncm = df[cols].corr()\nplt.figure(figsize=(10,6))\nsns.heatmap(cm, annot=True, cmap = 'viridis')\nplt.title('Correlation')\nplt.show()","e3e97ced":"# Removing 'lat' and 'lon'\ndf.drop(['lat', 'lon'], axis=1, inplace=True)","a33d379e":"df.head(3)","a73d755c":"df['suburb'].nunique(), df['suburbid'].nunique()","3ea6330c":"df.drop('suburbid', axis=1, inplace=True)","ece2b7f7":"df.head(3)","98ee49bc":"df['datesold'] = pd.to_datetime(df['datesold'])\ntype(df['datesold'][0])  # checking","d3cdb07c":"df.isna().sum()","e33c0dfa":"# Percentage of missing values in 'price' column compare to all entries\n\ndf['price_null'] = np.where(df['price'].isnull(), 1, 0)\nprint(f\"Missing values ratio: {round(df['price_null'].mean()* 100, 3) }%\")","24ab9bf0":"# Removing missing values in 'price' column\n\ndf.drop(['price_null'], axis=1, inplace=True)\ndf = df.dropna(subset=['price'])","d12a114f":"print(f\"Null values in 'price' column: {df['price'].isna().sum()}\")  # checking","67671c96":"df.isna().sum()  # Checking the remaining missing values","d382d7de":"# Percentage of missing values in 'bathrooms' column compare to all entries\n\ndf['bathrooms_null'] = np.where(df['bathrooms'].isnull(), 1, 0)\nprint(f\"Missing values ratio: {df['bathrooms_null'].mean()}\")","f6cf4cca":"# Checking 'bathrooms' column before preprocessing technique\n\ndf.drop(['bathrooms_null'], axis=1, inplace=True)\nmin_b = df['bathrooms'].min()\nmax_b = df['bathrooms'].max()\nmean_b = df['bathrooms'].mean()\nmedian_b = df['bathrooms'].median()\nstd_b = df['bathrooms'].std()\n\nprint(\"Statistics for 'bathrooms' column before dropping missing values:\\n\")\nprint(\"Minimum 'bathrooms': \", min_b) \nprint(\"Maximum 'bathrooms': \", max_b)\nprint(\"Mean 'bathrooms': \", mean_b)\nprint(\"Median 'bathrooms': \", median_b)\nprint(\"Standard deviation of 'bathrooms': \", std_b)","a619c642":"sns.distplot(df['bathrooms'], kde=False)\nplt.show()\n\n# Skewed distribution","df07f6ba":"pg.qqplot(df.bathrooms, dist='norm')\nplt.show()\n\n# It can be seen from Q-Q Plot diagram below that 'bathrooms' column is not normally distributed.  ","047d3b3a":"df['bathrooms'].value_counts()","fc5f6a55":"df['bathrooms'].fillna(df['bathrooms'].median(), inplace=True)\ndf['bathrooms'].isna().sum()","29d4a98a":"df['bathrooms'] = df['bathrooms'].astype(int)\ntype(df['bathrooms'][0])  # checking","90c65ccb":"# Checking 'bathrooms' column after preprocessing technique\n\nmin_b2 = df['bathrooms'].min()\nmax_b2 = df['bathrooms'].max()\nmean_b2 = df['bathrooms'].mean()\nmedian_b2 = df['bathrooms'].median()\nstd_b2 = df['bathrooms'].std()\n\nprint(\"Statistics for 'bathrooms' column after dropping missing values:\\n\")\nprint(\"Minimum 'bathrooms': \", min_b2) \nprint(\"Maximum 'bathrooms': \", max_b2)\nprint(\"Mean 'bathrooms': \", mean_b2)\nprint(\"Median 'bathrooms': \", median_b2)\nprint(\"Standard deviation of 'bathrooms': \", std_b2)","b4c6fef6":"df.isna().sum()","b2229dac":"df.head()","725691dd":"categorical_columns = list(df.describe(exclude='number').columns)\nnumerical_columns = list(df.describe().columns)","e6b36a30":"numerical_columns.remove('postcode')","4da8a829":"numerical_columns","5f027b2a":"categorical_columns.append('postcode')","745efd3f":"categorical_columns","fa0f75b2":"#  Reordering Columns\n\ndf_categorical = df[categorical_columns]\ndf_numerical = df[numerical_columns]\ndf = pd.concat([df_numerical, df_categorical], axis=1)\ndf.head(3)","23e833f0":"df.describe(include='all')","eb0cdd4a":"sns.pairplot(df, size=2.5, palette='mako') \nplt.tight_layout()","4d547760":"def stats_(feature):\n    min_ = df[feature].min()\n    max_ = df[feature].max()\n    mean_ = df[feature].mean()\n    median_ = df[feature].median()\n    std_ = df[feature].std()\n\n    print(f\"Statistics for '{feature}' column:\\n\")\n    print(f\"Minimum '{feature}': \", min_)\n    print(f\"Maximum '{feature}': \", max_)\n    print(f\"Mean '{feature}': \", mean_)\n    print(f\"Median '{feature}': \", median_)\n    print(f\"Standard deviation of '{feature}': \", std_)\n    \ndef detect_outlier_iqr(data):\n    outliers=[]\n    data_sorted = sorted(data)\n    q1, q3= np.percentile(data,[25,75])\n    iqr = q3 - q1\n    lower_bound = q1 -(1.5 * iqr) \n    upper_bound = q3 +(1.5 * iqr) \n    \n    for y in data_sorted:\n        if y < lower_bound or y > upper_bound:\n            outliers.append(y)\n    return outliers","194e3f80":"# Checking the amount of outliers in the dataset based on 'lower whisker and upper whisker'\n\nfor i in df_numerical.columns:\n    print(f\"Number of outliers in '{i}' column: \", len(detect_outlier_iqr(df[i])))","f8fbf577":"numerical_columns","4ed1111d":"stats_('price')","711e03aa":"plt.figure(figsize=(5,5))\nsns.boxplot(data=df['price'])\nplt.xticks(rotation=90)\nplt.title('price')\nplt.show()","b1763b36":"# Data are heavily right-skewed\n\nplt.figure(figsize=(10,10))\nsns.distplot(df['price'], kde=False, bins=100)\nplt.xticks(rotation=90)\nplt.title('price')\nplt.show()","a9ecbf34":"# Creating 'PriceRange' column to better see where the distribution of the outliers\n\ndf['PriceRange'] = np.where(df['price'] <= 1000000, '0 - 1M',  \n                                       np.where ((df['price'] > 1000000) & (df['price'] <= 2000000), '1M - 2M',\n                                                np.where((df['price'] > 2000000) & (df['price'] <= 3000000), '2M - 3M',\n                                                        np.where((df['price']>3000000) & (df['price']<=4000000), '3M - 4M',\n                                                                np.where((df['price']>4000000) & (df['price']<=5000000), '4M - 5M',\n                                                                        np.where((df['price']>5000000) & (df['price']<=6000000), '5M - 6M',\n                                                                                np.where((df['price']>6000000) & (df['price']<=7000000), '6M - 7M', \n                                                                                         np.where((df['price']>7000000) & (df['price']<=8000000), '7M - 8M', \n                                                                                                 np.where((df['price']>8000000) & (df['price']<=9000000), '8M -9 M', ''\n                                                                                                                 )))))))))","1282f5de":"df.groupby(['PriceRange']).agg({'PriceRange': ['count']})","d087459a":"df.drop(df[\n    (df['PriceRange']=='5M - 6M') |\n    (df['PriceRange']=='6M - 7M') |\n    (df['PriceRange']=='7M - 8M') \n].index, inplace=True)","1dac33bb":"df['parking'].value_counts()","0858a153":"list_parking_drop = [18, 27, 12, 16, 21, 31]\nlist_parking_drop_index = df[df['parking'].isin(list_parking_drop)].index\ndf.drop(list_parking_drop_index, inplace=True)","41154743":"df[df['parking'].isin(list_parking_drop)].index  # checking the missing values after dropping them","3d1ef4fc":"df['parking'].value_counts()  # checking the missing values after dropping them","bb571ded":"df['bathrooms'].value_counts()","0d1e4733":"df.drop(df[\n    (df['bathrooms']==9) |\n    (df['bathrooms']==21) |\n    (df['bathrooms']==8) \n].index, inplace=True)","5ebb2704":"df['bathrooms'].value_counts()  # checking the missing values after dropping them","983bd96e":"df['bedrooms'].value_counts()","2abaf6a3":"df.drop(df[\n    (df['bedrooms']==9) |\n    (df['bedrooms']==14) |\n    (df['bedrooms']==12) |\n    (df['bedrooms']==11) \n].index, inplace=True)","407274c6":"df['bedrooms'].value_counts()  # checking the missing values after dropping them","4dc66e7f":"df.info()","84c146c2":"df.describe(include='all')","4a3ad28a":"df.head(3)","52ee2bef":"sns.pairplot(df, size=2.5, hue='propertyType', palette='mako')\nplt.tight_layout()","b60a9743":"df['yearsold'] = df['datesold'].dt.year","66b27696":"df['monthsold'] = df['datesold'].dt.month","823c76e7":"df['daysold'] = df['datesold'].dt.day","f5575fa4":"df['quarters'] = np.where((df['monthsold'] >= 1) & (df['monthsold'] <= 3), 'q1',\n                        np.where((df['monthsold'] >= 4) & (df['monthsold'] <= 6), 'q2',\n                                np.where((df['monthsold'] >= 7) & (df['monthsold'] <= 9), 'q3', 'q4')))\ndf['quarters'].value_counts()","c184312d":"df['seasons'] = np.where((df['monthsold'] >= 3) & (df['monthsold'] <= 5), 'spring',\n                        np.where((df['monthsold'] >= 6) & (df['monthsold'] <= 8), 'summer',\n                                np.where((df['monthsold'] >= 9) & (df['monthsold'] <= 11), 'fall', 'winter')))\ndf['seasons'].value_counts()","27126f6c":"df.head(3)","f6e9ade2":"df_house_year = df[df['propertyType']=='house'].groupby('yearsold').median()\ndf_unit_year = df[df['propertyType']=='unit'].groupby('yearsold').median()\nlist_year = sorted(df['yearsold'].value_counts().index)\n\nplt.figure(figsize=(10,10))\n\ndf_house_year['price'].plot(kind='line', color='r',label='House')\ndf_unit_year['price'].plot(kind='line', color='g',label='Unit')\n\nplt.ylabel('price')\nplt.xticks(list_year, rotation=90)\nplt.legend()\nplt.show()","926deaf3":"# Checking the amount of data that needs to be dropped\n\ndf[df['yearsold']<2007]['price'].count()","317b0aa5":"# Dropping the data\n\ndf.drop(df[df['yearsold']<2007].index, inplace=True)\ndf['yearsold'].unique()","557b3ddc":"# The aftermath after dropping data before 2007.\n\ndf_house_year = df[df['propertyType']=='house'].groupby('yearsold').median()\ndf_unit_year = df[df['propertyType']=='unit'].groupby('yearsold').median()\nlist_year = sorted(df['yearsold'].value_counts().index)\n\nplt.figure(figsize=(10,10))\n\ndf_house_year['price'].plot(kind='line', color='r',label='House')\ndf_unit_year['price'].plot(kind='line', color='g',label='Unit')\n\nplt.ylabel('price')\nplt.xticks(list_year, rotation=90)\nplt.legend()\nplt.show()","0b786df5":"# Creating the ratios based on quarterly sales per year\nlist_year = sorted(df['yearsold'].value_counts().index)\nlist_ratio_quarters = [df[df['yearsold']==i]['quarters'].value_counts(normalize=True) for i in list_year]\n\n# Creating a ratio dataframe for all sales that happen throughout the period based on their quarters\ndf_list_ratio_quarters = pd.DataFrame(list_ratio_quarters)\ndf_list_ratio_quarters.reset_index(inplace=True)\ndf_list_ratio_quarters.fillna(0, inplace=True)\ndf_list_ratio_quarters  # checking\n\n# Creating series based on their quarters\nlist_ratio_q1 = [df_list_ratio_quarters.loc[:,'q1']]\nlist_ratio_q2 = [df_list_ratio_quarters.loc[:,'q2']]\nlist_ratio_q3 = [df_list_ratio_quarters.loc[:,'q3']]\nlist_ratio_q4 = [df_list_ratio_quarters.loc[:,'q4']]\n\nlist_vstack = np.vstack([list_ratio_q1, list_ratio_q2, list_ratio_q3, list_ratio_q4])\n\npal = sns.color_palette(\"Set1\")\nplt.figure(figsize=(10,10))\nplt.stackplot(list_year, list_vstack, labels=('q1', 'q2', 'q3', 'q4'),colors=pal, alpha=0.4)\nplt.xlabel('Years')\nplt.ylabel('Ratio')\nplt.xticks(rotation=90)\nplt.legend()\nplt.show()","bd95a819":"# Creating the ratios based on quarterly sales per year\nlist_year2 = sorted(df['yearsold'].value_counts().index)\nlist_nonratio_quarters = [df[df['yearsold']==i]['quarters'].value_counts() for i in list_year2]\n\n# Creating a ratio dataframe for all sales that happen throughout the period based on their quarters\ndf_list_ratio_quarters2 = pd.DataFrame(list_nonratio_quarters)\ndf_list_ratio_quarters2.reset_index(inplace=True)\ndf_list_ratio_quarters2.fillna(0, inplace=True)\ndf_list_ratio_quarters2  # checking","fdfddadf":"# Checking the distribution of quarters in general\n\nlist_quarters_dist = 'q1 q2 q3 q4'.split()\n\nfor i in list_quarters_dist:\n    sns.distplot(df_list_ratio_quarters2[i])\n    plt.show()","4fd7a5ea":"# QQ plot q1\n\npg.qqplot(df_list_ratio_quarters2.sort_values('q1')['q1'], dist='norm')\nplt.title('QQ plot q1')\nplt.show()","70c4d359":"# QQ plot q2\n\npg.qqplot(df_list_ratio_quarters2.sort_values('q2')['q2'], dist='norm')\nplt.title('QQ plot q2')\nplt.show()","0c160a7e":"# QQ plot q3\n\npg.qqplot(df_list_ratio_quarters2.sort_values('q3')['q3'], dist='norm')\nplt.title('QQ plot q3')\nplt.show()","6dc2c054":"# QQ plot q4\n\npg.qqplot(df_list_ratio_quarters2.sort_values('q4')['q4'], dist='norm')\nplt.title('QQ plot q4')\nplt.show()","611915a6":"print(stats.skew(df_list_ratio_quarters2['q1']))\nprint(stats.skew(df_list_ratio_quarters2['q2']))\nprint(stats.skew(df_list_ratio_quarters2['q3']))\nprint(stats.skew(df_list_ratio_quarters2['q4']))\n\n# some data are close to 0, which means that those data are close to normal.\n# ** this is not an exact number, but the further away from zero (0), the more non- normal the data.","9fdf26a8":"# Dataset that has over 5000 rows use Kolmogorov-Smirnov test\n\ndef k_smirnov_result(arr):\n    D, p = stats.kstest(arr, 'norm')\n    alpha = 0.05 \n\n    # H0 : Data comes from a normal distribution\n    # H1 : Data does not come from a normal distribution\n\n    print(f\"Kolmogorov-Smirnov: W={D}, p={p}\")\n    if p < alpha:\n        print('The null hyphotesis can be rejected, thus data does not come from a normal distribution \\n')\n    else:\n        print('The null hyphotesis can not be rejected, thus data comes from a normal distribution \\n')","a8039a8d":"k_smirnov_result(df_list_ratio_quarters2['q1'])\nk_smirnov_result(df_list_ratio_quarters2['q2'])\nk_smirnov_result(df_list_ratio_quarters2['q3'])\nk_smirnov_result(df_list_ratio_quarters2['q4'])","e9b4d41d":"# Kruskal- Wallis test\n\nkruskal_stats, p = stats.kruskal(df_list_ratio_quarters2['q1'], df_list_ratio_quarters2['q2'], df_list_ratio_quarters2['q3'], df_list_ratio_quarters2['q4'])\n\ndef kruskal_w_result(arr1, arr2, arr3, arr4):\n    kruskal_stats, p = stats.kruskal(arr1, arr2, arr3, arr4)\n    alpha = 0.05 \n\n    # H0 : mu_array1 = mu_array2 = mu_array3 = mu_array4\n    # H1 : mu_array1 != mu_array2 != mu_array3 != mu_array4\n\n    print(f\"Kruskal- Wallis: W={kruskal_stats}, p={p}\")\n    if p < alpha:\n        print('The null hyphotesis can be rejected, thus: mu_array1 != mu_array2 != mu_array3 != mu_array4 \\n')\n    else:\n        print('The null hyphotesis can not be rejected, thus: mu_array1 = mu_array2 = mu_array3 = mu_array4 \\n')","646dd70a":"kruskal_w_result(df_list_ratio_quarters2['q1'], df_list_ratio_quarters2['q2'], df_list_ratio_quarters2['q3'], df_list_ratio_quarters2['q4'])","e8844f13":"list_rasio_seasons = [df[df['yearsold']==i]['seasons'].value_counts(normalize=True) for i in list_year]\nlist_rasio_seasons[0]  # checking","e9b26873":"# Creating the ratios of real estate sales based on seasons per year\n\nlist_year = sorted(df['yearsold'].value_counts().index)\nlist_ratio_seasons = [df[df['yearsold']==i]['seasons'].value_counts(normalize=True) for i in list_year]\n\n# Creating a ratio dataframe for all sales that happen throughout the period based on its seasons\ndf_list_ratio_seasons = pd.DataFrame(list_ratio_seasons)\ndf_list_ratio_seasons.reset_index(inplace=True)\ndf_list_ratio_seasons.fillna(0, inplace=True)\ndf_list_ratio_seasons  # checking\n\n# Creating series based on its quarters\nlist_ratio_summer = [df_list_ratio_seasons.loc[:,'summer']]\nlist_ratio_fall = [df_list_ratio_seasons.loc[:,'fall']]\nlist_ratio_winter = [df_list_ratio_seasons.loc[:,'winter']]\nlist_ratio_spring = [df_list_ratio_seasons.loc[:,'spring']]\n\nlist_vstack = np.vstack([list_ratio_summer, list_ratio_fall, list_ratio_winter, list_ratio_spring])\n\npal = sns.color_palette(\"Set1\")\nplt.figure(figsize=(10,10))\nplt.stackplot(list_year, list_vstack, labels=('summer', 'fall', 'winter', 'spring'),colors=pal, alpha=0.4)\nplt.xlabel('Years')\nplt.ylabel('Ratio')\nplt.xticks(rotation=90)\nplt.legend()\nplt.show()","3f4562be":"# Creating a df_suburb table\n\ndf_suburb = df.groupby('suburb').count()['price'].sort_values(ascending=False)\ndf_suburb = df_suburb.reset_index()\ndf_suburb.rename(columns={'price': 'amount_of_sales'}, inplace=True)","89b3b500":"# Creating a bar plot for all real estate sales throughout the years based on its suburbs\n\nplt.figure(figsize=(20,10))\nsns.barplot(df_suburb['suburb'], df_suburb['amount_of_sales'], alpha=0.5)\nplt.xticks(rotation=90)\nplt.show()","5c844424":"plt.figure(figsize=(25,15))\nsns.countplot(df['suburb'], alpha=0.8, hue=df['propertyType'], palette='coolwarm')\nplt.xticks(rotation=90)\nplt.show()","7757498b":"sales_count_suburb_type = df.groupby(['suburb','propertyType'])[['price']].count()\nsales_count_suburb_type.rename(columns={'price': 'amount_of_sales'}, inplace=True)\nsales_count_suburb_type.nlargest(20, 'amount_of_sales')","83b740a3":"# Creating the crosstab data frame\n\ndf_house_unit_outweigh = pd.crosstab(index=df['suburb'], columns=df['propertyType'])\ndf_house_unit_outweigh.reset_index(inplace=True)","2434b0d6":"# Unit sales outweigh house sales\n\nlist_unit_outweigh = np.where(df_house_unit_outweigh['house'] < df_house_unit_outweigh['unit'], 1, 0)\ndf_house_unit_outweigh['unit_outweigh'] = list_unit_outweigh\n\ndf_house_unit_outweigh[df_house_unit_outweigh['unit_outweigh']==1].sort_values('unit', ascending=False)[:10]","2e40c985":"# House sales outweigh unit sales\n\nlist_house_outweigh = np.where(df_house_unit_outweigh['house'] > df_house_unit_outweigh['unit'], 1, 0)\ndf_house_unit_outweigh['house_outweigh'] = list_house_outweigh\n\ndf_house_unit_outweigh[df_house_unit_outweigh['house_outweigh']==1].sort_values('house', ascending=False)[:10]","0ac5928a":"# Creating df_suburb_yearsold (mean)\n\ndf_suburb_yearsold = df.groupby(['suburb', 'yearsold']).mean()[['price']].reset_index()","ee28c196":"# Creating df_suburb_yearsold2 (count)\n\ndf_suburb_yearsold2 = df.groupby(['suburb', 'yearsold']).count()[['price']].reset_index()","cb5d0399":"# latest_yearsold, latest_mean_price\ndf_suburb_head = df_suburb.copy()\nsuburb_head_syear = [df_suburb_yearsold[df_suburb_yearsold['suburb']==i]['yearsold'].iloc[-1] for i in df_suburb_head['suburb']]\nsuburb_head_sprice = [df_suburb_yearsold[df_suburb_yearsold['suburb']==i]['price'].iloc[-1] for i in df_suburb_head['suburb']]\ndf_suburb_head['latest_yearsold'], df_suburb_head['latest_mean_price'] = suburb_head_syear, suburb_head_sprice\n\n# latest_number_sales\nsuburb_head_snum = [df_suburb_yearsold2[df_suburb_yearsold2['suburb']==i]['price'].iloc[-1] for i in df_suburb_head['suburb']]\ndf_suburb_head['latest_number_sales'] = suburb_head_snum\n\n# latest_num_house, latest_num_unit\nlist_series_property_1a = [df[(df['suburb']==i) & (df['yearsold']==j)]['propertyType'].value_counts() for i, j in zip(df_suburb_head['suburb'], df_suburb_head['latest_yearsold'])]\ndf_suburb_head['latest_num_house'], df_suburb_head['latest_num_unit'] = 0, 0\n\nfor i in range(len(list_series_property_1a)):\n    if len(list_series_property_1a[i]) == 1:\n        if list_series_property_1a[i].index == 'house':\n            df_suburb_head['latest_num_house'].iloc[i] = list_series_property_1a[i].values\n            df_suburb_head['latest_num_unit'].iloc[i] = 0            \n        else:\n            df_suburb_head['latest_num_house'].iloc[i] = 0\n            df_suburb_head['latest_num_unit'].iloc[i] = list_series_property_1a[i].values\n    else:\n        df_suburb_head['latest_num_house'].iloc[i] = list_series_property_1a[i][0]\n        df_suburb_head['latest_num_unit'].iloc[i] = list_series_property_1a[i][1]\n\n# latest_ratio_house, latest_ratio_unit\nlist_series_property = [round(df[(df['suburb']==i) & (df['yearsold']==j)]['propertyType'].value_counts(normalize=True), 3) for i, j in zip(df_suburb_head['suburb'], df_suburb_head['latest_yearsold'])]\ndf_suburb_head['latest_ratio_house'], df_suburb_head['latest_ratio_unit'] = 0, 0\n\nfor i in range(len(list_series_property)):\n    if len(list_series_property[i]) == 1:\n        if list_series_property[i].index == 'house':\n            df_suburb_head['latest_ratio_house'].iloc[i] = list_series_property[i].values\n            df_suburb_head['latest_ratio_unit'].iloc[i] = 0            \n        else:\n            df_suburb_head['latest_ratio_house'].iloc[i] = 0\n            df_suburb_head['latest_ratio_unit'].iloc[i] = list_series_property[i].values\n    else:\n        df_suburb_head['latest_ratio_house'].iloc[i] = list_series_property[i][0]\n        df_suburb_head['latest_ratio_unit'].iloc[i] = list_series_property[i][1]","8e155634":"df_suburb_head.head()","0d66ba04":"df_suburb_head.tail()","8099969f":"sns.lmplot(x='yearsold', y='price',hue='propertyType', data=df, col='suburb', x_estimator=np.median, col_wrap=3, palette='coolwarm')\nplt.ylim(50000, 5000000)\nplt.xlim(2007, 2019)\nplt.title('Real Estate Pricing Trend Over the Years Based on Suburbs and Property Type')\nplt.show()","c524b5b2":"# Creating a function to show top houses\/ units from each suburb grouped by the type of the property and number of bedrooms, bathrooms, and parking lots.\n\ndef ideal_house_unit(suburb, property_type, num_top):\n    ideal_house_df = df.groupby(['suburb','propertyType','bedrooms','bathrooms', 'parking'])[['price']].count()\n    ideal_house_df.rename(columns={'price': 'number_of_sales'}, inplace=True)\n    df_largest_reset = ideal_house_df.loc[suburb, property_type].nlargest(num_top, 'number_of_sales').reset_index()\n    \n    list_recent_year_reset = []\n    list_recent_price_reset = []\n    \n    for i in range(num_top):\n        list_recent_year_reset.append(df[\n        (df['suburb']==suburb) &\n        (df['propertyType']==property_type) &\n        (df['bedrooms']==df_largest_reset.loc[i, 'bedrooms']) &  \n        (df['bathrooms']==df_largest_reset.loc[i, 'bathrooms']) &\n        (df['parking']==df_largest_reset.loc[i, 'parking']) \n    ]['yearsold'].iloc[-1])\n    \n    df_largest_reset['latest_year'] = list_recent_year_reset\n    \n    for i in range(num_top):\n        list_recent_price_reset.append(round(df[\n        (df['suburb']==suburb) &\n        (df['propertyType']==property_type) &\n        (df['yearsold']==list_recent_year_reset[i]) &\n        (df['bedrooms']==df_largest_reset.loc[i, 'bedrooms']) & \n        (df['bathrooms']==df_largest_reset.loc[i, 'bathrooms']) &\n        (df['parking']==df_largest_reset.loc[i, 'parking'])\n    ]['price'].median(), 2))\n    \n    df_largest_reset['latest_price_median'] = list_recent_price_reset\n    \n    return df_largest_reset","24c4d721":"def print_df_ideal_spec(df):\n    print(\"Mean of 'latest_price_median': \", df['latest_price_median'].mean())\n    print(\"Min of 'latest_price_median': \", df['latest_price_median'].min())\n    print(\"Max of 'latest_price_median': \", df['latest_price_median'].max())\n    print(\"Standard Deviation of 'latest_price_median': \", df['latest_price_median'].std())\n    print(\"Sum of 'number_of_sales': \", df['number_of_sales'].sum())","005df683":"# Ideal Houses in Kambah\n\ndisplay(ideal_house_unit('Kambah', 'house', 10))\nprint_df_ideal_spec(ideal_house_unit('Kambah', 'house', 10))","e261f144":"# Ideal Houses in Ngunnawal\n\ndisplay(ideal_house_unit('Ngunnawal', 'house', 10))\nprint_df_ideal_spec(ideal_house_unit('Ngunnawal', 'house', 10))","92d04e65":"# Ideal Houses in Gordon\n\ndisplay(ideal_house_unit('Gordon', 'house', 10))\nprint_df_ideal_spec(ideal_house_unit('Gordon', 'house', 10))","28c19eb5":"# Ideal Houses in Dunlop\n\ndisplay(ideal_house_unit('Dunlop', 'house', 10))\nprint_df_ideal_spec(ideal_house_unit('Dunlop', 'house', 10))","262a524d":"# Ideal Houses in MacGregor\n\ndisplay(ideal_house_unit('MacGregor', 'house', 10))\nprint_df_ideal_spec(ideal_house_unit('MacGregor', 'house', 10))","3413e4f1":"# Ideal Units in Kingston\n\ndisplay(ideal_house_unit('Kingston', 'unit', 10))\nprint_df_ideal_spec(ideal_house_unit('Kingston', 'unit', 10))","8bf164c3":"# Ideal Units in Braddon\n\ndisplay(ideal_house_unit('Braddon', 'unit', 10))\nprint_df_ideal_spec(ideal_house_unit('Braddon', 'unit', 10))","6c4b3004":"# Ideal Units in Belconnen\n\ndisplay(ideal_house_unit('Belconnen', 'unit', 10))\nprint_df_ideal_spec(ideal_house_unit('Belconnen', 'unit', 10))","dfc9bcb7":"# Ideal Units in Turner\n\ndisplay(ideal_house_unit('Turner', 'unit', 10))\nprint_df_ideal_spec(ideal_house_unit('Turner', 'unit', 10))","d661edbf":"# Ideal Units in Bruce\n\ndisplay(ideal_house_unit('Bruce', 'unit', 10))\nprint_df_ideal_spec(ideal_house_unit('Bruce', 'unit', 10))","0bd4c1fa":"# Creating a count plot for all real estate sales throughout the years based on its postal codes\n\nplt.figure(figsize=(20,10))\nsns.countplot(df['postcode'], alpha=0.5)\nplt.xticks(rotation=90)\nplt.show()","dd2d4be6":"plt.figure(figsize=(25,15))\nsns.countplot(df['postcode'], alpha=0.8, hue=df['propertyType'], palette='Spectral')\nplt.xticks(rotation=90)\nplt.show()","973ddbeb":"sales_count_postcode_type = df.groupby(['postcode','propertyType'])[['price']].count()\nsales_count_postcode_type.rename(columns={'price': 'amount_of_sales'}, inplace=True)\nsales_count_postcode_type.nlargest(20, 'amount_of_sales')","b0cb1754":"sns.lmplot(x='yearsold', y='price',hue='propertyType', data=df, col='postcode', x_estimator=np.median, col_wrap=3, palette='Spectral')\nplt.ylim(50000, 5000000)\nplt.xlim(2007, 2019)\nplt.title('Real Estate Pricing Trend Over the Years Based on Postal Codes and Property Type')\nplt.show()","ca7649c8":"sns.lmplot(x=\"yearsold\", y=\"price\", hue=\"parking\", data=df,  x_estimator=np.median, palette='Spectral')\nplt.title('Parking Lots vs Price')\nplt.show()","caca6c42":"sns.lmplot(x=\"yearsold\", y=\"price\", hue=\"bathrooms\", data=df,  x_estimator=np.median, palette='Spectral')\nplt.title('Bathrooms vs Price')\nplt.show()","3815ae93":"sns.lmplot(x=\"yearsold\", y=\"price\", hue=\"bedrooms\", data=df,  x_estimator=np.median, palette='Spectral')\nplt.title('Bedrooms vs Price')\nplt.show()","a3c7f0f3":"# Correlation Inspection\n\ntarget2 = 'price'\nk2 = 8 # number of variables for heat map\ncols2 = df.corr().nlargest(k2, target2)[target2].index\ncm2 = df[cols2].corr()\nplt.figure(figsize=(10,6))\nsns.heatmap(cm2, annot=True, cmap = 'viridis')\nplt.title('Correlation')\nplt.show()","8541cdf4":"- __Checking Outliers in 'parking' Columns__","dbca947a":"> #### Removing Features","5821aa57":"__It can be seen from the table above:__\n\n- 3 data items have 9 bedrooms\n- 1 data item has 14 bedrooms\n- 1 data item has 12 bedrooms\n- 1 data item has 11 bedrooms\n\nFor the purpose of this analysis, all data that are mentioned above are going to be dropped","2bc439a2":"> #### Dealing with Missing Values","05dbd29f":"- __20 Postal Codes with the Highest Amount of Real Estate Sales Grouped By Their Property Type:__","e30d24ce":"The distribution for each quarter is __relatively not normal.__","f63b5ef0":"- __Distribution of Suburbs Real Estate Sales Throughout the Period in Canberra Based on Property Type:__","ea8abd55":"It can be seen from the table above that 'unit' property type had an insignificant role in the most recent real estate sales in these suburbs.","771d5b18":"- __Real Estate Pricing Trend Over the Years Based on Postal Codes and Property Type:__","3af2d369":"- __20 Suburbs with the Highest Amount of Real Estate Sales Grouped By Their Property Type:__","50c6a631":"> #### Questions\n- What features affect the real estate prices in Canberra?\n- What is the real estate price in Canberra going to be like in the near future according to the given datasets?","62df4461":"This diagram shows that parking lots had little to no effect in the real estate price throughout these years.","3ae9303c":"- __Column named 'suburbid' is going to be removed since it is literally just conveying the id of the suburbs from 'suburb' column__","20ee1ec2":"- __Hypothesis Testing Using Kruskal Wallis Test:__","beaefb08":"These were the suburbs that had house sales outweigh their unit sales throughout the period.","cdfd13a5":"## Preprocessing","37d9526b":"- __Using Scatter Plot to See the Relationship Between 'price' Column and Other Numerical Columns:__","cb84e05a":"- __Conclusion:__\n\nIt can be seen through this heat map that bedrooms and bathrooms are the top two features with the highest correlation value with the price. Meanwhile, parking and the rest of the features have fairly moderate and relatively low correlation values.\n\nIn addition, the exact day and month when the property was sold has no implication to the price of the property. On the other hand, the year when the property was sold and the location of the property that is conveyed through postal code have minor implications to the price.","e2ed6272":"- __Real Estate Pricing Trend Over the Years Based on Suburbs and Property Type:__","7bf264f0":"- __Updating Categorical and Numerical Columns:__","04f4baf5":"## Introduction","02c52c3a":"- __Bedrooms and Price Relationship:__","9970f929":"> #### Import the Raw Dataset","bb870472":"Replacing missing values in 'bathrooms' column with its median, since it is not possible replacing them with its mean because 'bathrooms' datasets are not normally distributed.","031fd513":"- __Checking Outliers in 'price' Columns:__","ee5f3e3c":"> #### Descriptive Statistics of the Variables","fc07391d":"Through this diagram it can be seen that the price of zero to two bedrooms groups were relatively stable throughout the period. Meanwhile, the rest of the groups experienced an upward trend that were also depended on the number of the bedrooms.","130d67ec":"- __Parking Lots and Price Relationship:__","0a00e3e8":"__Conclusion:__ Through this Kruskal- Wallis test it is proven that sales among all quarters were relatively the same.","d15378e5":"- __Converting 'datesold' Column Data Type to Date Type:__","da29810c":"Throughout 2007 to 2019 there were some fluctuations in the amount of real estate sales per quarter. However, the ratios of sales among all quarters were relatively the same. In addition, only the 4th quarter experienced a decline in real estate sales in 2019.","305a4c80":"> #### Dealing with Outliers","e6e24d05":"- __Both 'lat' and 'lon' columns, that display latitude and longitude of a place respectively, are going to be dropped in this visualization notebook, since there are other columns such as 'suburb' and 'postcode' that conveys the location of the unit\/ house__","816c170b":"> #### Background Stories\n\nThe world was experiencing a global financial crisis around 2007 to 2008 due to excessive risk-taking by banks combined with the bursting of the United States housing bubble caused the values of securities tied to U.S. real estate to plummet, damaging financial institutions globally and culminating an international banking crisis. The crisis sparked the Great Recession, which at the time was the most severe global recession since the \"Great Depression\". Canberra as the capital city of Australia was no exception to this crisis.\n\nThrough this project, we hope to understand how the real estate market in Canberra responded to the global financial crisis and what is the aftermath pricing trend. We are also hoping to gain any valuable insight into the Canberra real estate market.","d270a18b":"- __Missing values in the 'price' column are going to be removed as this analysis is depended on the historical data of this feature__","03578f08":"> #### The Scope of the Research Problem\n- Historical data from 2007 - 2019\n- Maximum real estate price capped at 5M (for analysis and visualization)","67b04bec":"## Visualization","bf655ada":"Through this heat map it can be seen that 'lat', and 'lon' columns have relatively small correlation with the 'price' column, while 'bedrooms' has the highest.","94938eb3":"It can be seen through this diagram that there was an upward trend in the real estate price from 2007 to 2019. The magnitude of the price increase throughout this period was depended on the number of bathrooms.","2fb7d1b0":"> #### Column Descriptions\n- datesold = date when the property was sold\n- price = price of the property when it was sold\n- suburb = suburbs in Canberra, Australia\n- postcode = postal code of a place\n- lat = latitude of the location\n- lon = longitude of the location\n- parking = number of parking lots\n- bathrooms = number of bathrooms\n- bedrooms = number of bedrooms\n- propertyType = type of the property\n- suburbid = the id of the suburbs","8f8a3a14":"- __Splitting 'datesold' Column:__","cbe50903":"- __Ideal Houses in Top 5 Suburbs with the Highest House Sales Throughout 2007 to 2019:__","9ed969d4":"> #### Import Modules","0ce9dc95":"## Data Cleaning and Visualization","6fba7fe2":"- __Checking Categorical Features Through Describe Method:__","3bdc7656":"Through this table, it can be seen that house was the dominant type of the property that was sold in the top 20 suburbs with the highest real estate sales grouped by their property type. In addition, Kingston and Braddon were the only suburbs that had unit sales surpass their house sales throughout these years.","51f4728c":"- __Dealing with 'bathrooms' Column Missing Values:__","3dbd367a":"__It can be seen from the table above:__\n\n- 2 data items have 9 bathrooms\n- 1 data item has 21 bathrooms\n- 1 data item has 8 bathrooms\n\nFor the purpose of this analysis, all data that are mentioned above are going to be dropped","679ccf9f":"These were the top 5 suburbs with the highest real estate sales throughout the period; Kambah, Ngunnawal, Gordon, Dunlop, and Kingston. In addition, Kambah, Ngunnawal, and Gordon were the only suburbs which had sales that were above 1000. It can also be seen that most of the sales were contributed by house sales instead of unit sales. ","a4817393":"- __5 Suburbs with the Highest Amount of Real Estate Sales:__","04009eb3":"- __Checking Numerical Features Through Describe Method:__","987485ba":"- __5 Suburbs with the Least Amount of Real Estate Sales:__","0f0b8a2a":"Dropping outliers based on 'lower whisker and upper whisker' is not the best decision, since the datasets are already heavily skewed and dropping it might reduce a lot of valuable information. It is a must to examine the dataset from feature to feature.","15effa9f":"- __Bathrooms and Price Relationship:__","4b7e410d":"- __Dividing 'monthsold' Column Based on 4 Seasons:__","7395580a":"It can be seen from the diagram above that generally the price of a house in Canberra is more expensive than its unit.","21012294":"- __Checking the Distribution of the Datasets Numerical Features Through Bar Plots:__","15b9b222":"> #### Users\n- Users & renters\n- Property investors\n- Renovators","0494e7cf":"It can be seen through the stack plot that the amount of real estate sales in the winter season was commonly lower than other seasons.","5d73d249":"- __Determining Numerical and Categorical Features:__","59af682d":"The line graph indicates that throughout 2000 to 2019, house prices experienced a huge upward trend even though there was a huge dip in 2006. Meanwhile, unit price remained relatively stable from 2007 to 2019 and only experienced slight fluctuations throughout the period. However, through this graph it can also be seen that there are a lot of missing data before 2007, thus data with year 2007 are going to be dropped. ","a7babe56":"- __Distribution of Postal Codes Real Estate Sales Throughout the Period in Canberra Based on Property Type:__","c9cd2503":"Data were obtained from HtAG\u00ae. HtAG\u00ae or Higher than Average Growth is an analytics portal that assists real estate professionals, investors and home buyers in making property-related decisions with the help of timely and actionable real estate market data. HtAG\u00ae leverages the benefits of machine learning to rank the growth potential of over 420 Local Government Areas and 6,200 suburbs, Australia wide.","ee00e7d1":"- __Checking Outliers in 'bedrooms' Columns:__","85a36bb4":"- __Ranking of Postal Codes in Canberra Solely Based on Real Estate Sales Throughout the Period:__","2e944c63":"- __Ideal Units in Top 5 Suburbs with the Highest Unit Sales Throughout 2007 to 2019:__","cab4b7f7":"Standard deviation for 'bathrooms' column after filling missing values with its median is almost the same as before the preprocessing technique. There is only a small decline in standard deviation of the 'bathrooms' column after the preprocessing process (it is barely noticable).","cbddb559":"__It can be seen from the table above:__\n\n- 2 data items have 18 parking lots\n- 1 data item has 27 parking lots\n- 1 data item has 12 parking lots\n- 1 data item has 16 parking lots\n- 1 data item has 21 parking lots\n- 1 data item has 31 parking lots\n\nFor the purpose of this analysis, all data that are mentioned above are going to be dropped","48cd4624":"This bar graph shows the number of real estate sales from 2007 to 2019 based on suburbs and property type. It can be seen that only few suburbs had unit sales that outweigh their house sales.","257f7886":"Only 3 postal codes had unit sales outweigh their house sales, these postal codes are 2612, 2604, and 2617.","4f3dac6d":"It can be seen through these linear model regression plots that unit sales trends are often missing or have little to no records in some suburbs. This phenomenon can be caused by unit property type does not exist in some suburbs as well as insignificant role of unit property type in the majority of real estate sales.","dce61c06":"- __Ranking of Suburbs in Canberra Solely Based on Real Estate Sales Throughout the Period:__","71192b93":"- __Canberra Real Estate Pricing Trend Throughout the Years Based on Its Property Type:__","1bcdcfee":"> **For further explanations and analysis about this project, kindly visit my GitHub link for this project:**\nhttps:\/\/github.com\/bolaubi\/Canberra_RealEstateSales_20072019_BenedictLaiman","40303511":"- __Checking Outliers in 'bathrooms' Columns:__","15b9cbef":"- __Performance of Real Estate Sales Based on Yearly Quarters and Seasons:__","0beb5cdb":"# Canberra Real Estate Sales 2007-2019","884def8f":"Through these linear regression model plots it can also be seen that the trend of unit sales being insignificant in real estate sales was also happening in these model plots that were based on postal codes.","9b5859e5":"__It can be seen from the table above:__\n\n- 2 data items in the range 5M - 6M\n- 1 data item in the range 6M - 7M\n- 2 data items in the range 7M - 8M\n\nFor the purpose of this analysis, all data that are mentioned above are going to be dropped. Hence, the maximum real estate price for this analysis is capped at 5M.","55371784":"Converting 'bathrooms' column data type to integer","b5c18df1":"These were the suburbs that had unit sales outweigh their house sales throughout the period.","3f5ef23a":"> #### Changing Data Type ","ac3c3628":"- __Dividing 'monthsold' Column Based on 4 Quarters:__"}}