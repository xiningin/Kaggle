{"cell_type":{"c77f270a":"code","1917498a":"code","7766598f":"code","2739753a":"code","40fe22cc":"code","d08a8e3b":"code","8c9379b4":"code","569e1f84":"code","5c4bfff7":"code","4561a4de":"code","a988f1d9":"code","9e85d87d":"code","7aebaaae":"code","506d4248":"code","cf219a56":"code","789d6ab7":"code","c724684e":"code","1fecfdf0":"code","82240267":"code","6b880cd4":"code","422bd681":"code","7c47a226":"code","a1f5ed3d":"code","2c6d5661":"code","b354dc26":"code","d915d505":"code","25bb8dfb":"code","bc376246":"code","6ae9cada":"code","8951bde1":"code","e6ebc8c7":"code","cdb80ac6":"code","02809a04":"code","cf1d00aa":"code","0498f2ed":"code","b987e9d1":"code","1609bd48":"code","7361f38d":"code","507b0faf":"code","8afe695b":"code","b66f61e4":"code","de1c42af":"code","c7fafe22":"code","a3602b17":"code","a088d08f":"code","47e90f53":"code","19fe5740":"code","b3406a35":"code","9c4f4b94":"code","0c494116":"code","541f28de":"code","c32b5f0c":"code","6dc5423c":"code","08bdd253":"code","1aa8fc4f":"code","4a28bccb":"code","44e1febe":"code","9965ef35":"code","10bfe1d8":"code","7c96a257":"code","1aacca6e":"code","ef3bec8e":"code","a860c675":"code","4ee2ee30":"code","21ab2e8d":"code","d1fb59ae":"code","70772249":"code","a895b196":"code","98e110e3":"code","0ec60a0b":"code","55333205":"code","26e4c1d4":"code","24dbddc5":"code","4b1c3021":"code","fb567821":"code","abd697fb":"code","9f644fa2":"code","57829a3f":"code","1d32bef4":"code","f9f37e42":"code","06bb9c47":"code","b6ba1b83":"code","cbd83b29":"code","05e9cf3e":"code","32d5715b":"code","02534fd5":"code","25d246aa":"code","04a8d53f":"code","179236f2":"code","4f1916c5":"code","8a9215b0":"code","4b8597d5":"code","f5cc0a44":"code","4a2cb394":"code","525e861b":"code","8365d96b":"code","c5d1f6b9":"code","895c6581":"code","4a1287f7":"code","af700e9f":"code","e7b2e00a":"code","caddab8b":"code","279e9f2c":"markdown","7c671ac2":"markdown","f50be67f":"markdown","05fa892c":"markdown","81e9489a":"markdown","5774bb6c":"markdown","75270ae8":"markdown","64ab86e1":"markdown","3722ce9a":"markdown","a7269543":"markdown","041d735a":"markdown","b7dea355":"markdown","17fb6a32":"markdown","81d26c86":"markdown","168cb37e":"markdown","0404f353":"markdown","3f233d2a":"markdown","f1f510b1":"markdown","fb4bbaf9":"markdown","4788fab9":"markdown","0939a955":"markdown","c56c0968":"markdown","42c1469f":"markdown","0369933a":"markdown","25f4da8d":"markdown","eaff06cc":"markdown","d1562196":"markdown","84c3e595":"markdown","637b5865":"markdown","f97f91e7":"markdown","4e7a1059":"markdown","d34a685e":"markdown","09a75a0f":"markdown","479457c5":"markdown","7e05dd6e":"markdown","7b86d095":"markdown","4fdcb298":"markdown","2d95935c":"markdown","5c511be7":"markdown","f77a1925":"markdown","d5974123":"markdown","b3096d0f":"markdown","2100191e":"markdown","66cedce8":"markdown"},"source":{"c77f270a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1917498a":"# Import the required libs\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV,KFold,cross_val_score\n\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\nfrom sklearn.metrics import r2_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n","7766598f":"# Load the dataset\nhouse = pd.read_csv('..\/input\/us-house-pricing\/train.csv')\nhouse.head()","2739753a":"# Check the shape of the data\nhouse.shape","40fe22cc":"# Check the info of the data\nhouse.info()","d08a8e3b":"# Check the datatypes\nhouse.dtypes","8c9379b4":"# Check columns of the data\nhouse.columns","569e1f84":"# check the description of the data\nhouse.describe()","5c4bfff7":"#Check the duplictes in data\nduplicate_house = house[house.duplicated()]\nprint(house.shape)\nprint(duplicate_house.shape)","4561a4de":"pd.set_option('display.max_rows', None) # TO be able to see the maxrows\n# Check the null values columns\nhouse.isnull().mean(axis=0).sort_values(ascending = False)","a988f1d9":"# Check the null values row wise\n# house.isnull().mean(axis=1).sort_values(ascending=True).head(10)","9e85d87d":"# Drop the null values more than 40%\nnull_cols = house.columns[house.isnull().mean() > 0.4]\nhouse.drop(null_cols, axis=1,  inplace=True)\nhouse.isnull().mean(axis=0).sort_values(ascending=False).head(20)","7aebaaae":"# Id is unique column, we dont need it to be present.\nhouse = house.drop(['Id'],axis='columns')","506d4248":"pd.set_option('display.max_columns', None) # TO be able to see the maxcolss\nhouse.head()","cf219a56":"# Actual numeric variables\n#['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n# 'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars',\n# 'GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','SalePrice','YearBuilt','YearRemodAdd','GarageYrBlt''YrSold' ]\n\n#Actual Categoric variable\n#['MSSubClass','MSZoning','Street','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType',\n# 'HouseStyle','OverallQual','OverallCond','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation',\n#'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','Electrical','KitchenQual','Functional',\n# 'GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','SaleType','SaleCondition','CentralAir']\n","789d6ab7":"house['YearBuilt_age'] = 2020-house.YearBuilt\nhouse['YearRemodAdd_age'] = 2020-house.YearRemodAdd\nhouse['GarageYrBlt_age'] = 2020-house.GarageYrBlt\nhouse['YrSold_age'] = 2020-house.YrSold\nhouse[['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold','YearBuilt_age','YearRemodAdd_age',\n             'GarageYrBlt_age','YrSold_age']].head()\n","c724684e":"# drop the original year columnsb\nhouse = house.drop(['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold'],axis='columns')","1fecfdf0":"numeric_vars = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF',\n                '2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n                'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch',\n                'PoolArea','MiscVal','SalePrice','MoSold','YearBuilt_age','YearRemodAdd_age','GarageYrBlt_age','YrSold_age']\n\ncat_vars = ['MSSubClass','MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType',\n            'HouseStyle','OverallQual','OverallCond','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation',\n            'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','Electrical','KitchenQual','Functional',\n            'GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','SaleType','SaleCondition','CentralAir']","82240267":"#  - Columns which required null value imputation\n# LotFrontage     0.177397\n# GarageFinish    0.055479\n# GarageType      0.055479\n# GarageCond      0.055479\n# GarageQual      0.055479\n# GarageYrBlt     0.055479\n# BsmtExposure    0.026027\n# BsmtFinType2    0.026027\n# BsmtFinType1    0.025342\n# BsmtCond        0.025342\n# BsmtQual        0.025342\n# MasVnrType      0.005479\n# MasVnrArea      0.005479","6b880cd4":"# Imputation of numeric missing values\nhouse.LotFrontage.fillna(house.LotFrontage.mean(), inplace= True)\nhouse.MasVnrArea.fillna(house.MasVnrArea.mean(), inplace= True)\nhouse.MasVnrType.fillna('None',inplace=True)\nhouse.BsmtQual.fillna('NA',inplace=True)\nhouse.BsmtCond.fillna('NA',inplace=True)\nhouse.BsmtExposure.fillna('NA',inplace=True)\nhouse.BsmtFinType1.fillna('NA',inplace=True)\nhouse.BsmtFinType2.fillna('NA',inplace=True) \nhouse.GarageType.fillna('NA',inplace=True)\nhouse.GarageYrBlt_age.fillna(-1,inplace=True)\nhouse.GarageFinish.fillna('NA',inplace=True)\nhouse.GarageQual.fillna('NA',inplace=True)\nhouse.GarageCond.fillna('NA',inplace=True)\nhouse.Electrical.fillna('Mix',inplace=True)","422bd681":"# cross check the null values after imputing\nhouse.isnull().mean()","7c47a226":"numeric_vars = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1',\n                'BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF',\n                '2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath',\n                'BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\n                'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars',\n                'GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch',\n                '3SsnPorch','ScreenPorch','PoolArea','MiscVal',\n                'SalePrice','MoSold','YearBuilt_age','YearRemodAdd_age',\n                'GarageYrBlt_age','YrSold_age']\nhouse[numeric_vars].describe()","a1f5ed3d":"# Handle outliers for below variables\n# GrLivArea      \n# GarageArea       \n# TotalBsmtSF      \n# 1stFlrSF        \n# FullBath         \n# TotRmsAbvGrd     \n","2c6d5661":"col_name = ['GrLivArea','TotalBsmtSF','1stFlrSF','BsmtFinSF1','LotArea','GarageArea','MasVnrArea']","b354dc26":"GrLivAreaq99 = house.GrLivArea.quantile(0.99)\nTotalBsmtSFq99 = house.TotalBsmtSF.quantile(0.99)\nTotalBsmtSFq05 = house.TotalBsmtSF.quantile(0.01)\n\nhouse = house[house['GrLivArea']<=GrLivAreaq99]\nhouse = house[house['TotalBsmtSF']<=TotalBsmtSFq99]\nhouse = house[house['TotalBsmtSF']>=TotalBsmtSFq05]\n\nsns.boxplot(house['GrLivArea'])\nplt.show()\nsns.boxplot(house['TotalBsmtSF'])\nplt.show()","d915d505":"# stFlrSFq99 = house['1stFlrSF'].quantile(0.95)\n# house = house[house['1stFlrSF']<=stFlrSFq99]\n# sns.boxplot(house['1stFlrSF'])\n# plt.show()\n# sns.boxplot(house['BsmtFinSF1'])\n# plt.show()","25bb8dfb":"# 'GarageArea','MasVnrArea'\n# GarageAreaq99 = house['GarageArea'].quantile(0.95)\n# MasVnrAreaq99 = house['MasVnrArea'].quantile(0.95)\n\n# house = house[house['GarageArea']<=GarageAreaq99]\n# house = house[house['MasVnrArea']<=MasVnrAreaq99]\n\n# sns.boxplot(house['GarageArea'])\n# plt.show()\n# sns.boxplot(house['MasVnrArea'])\n# plt.show()","bc376246":"# LotAreaq99 = house['LotArea'].quantile(0.95)\n# house = house[house['LotArea']<=LotAreaq99]\n\n# sns.boxplot(house['LotArea'])\n# plt.show()\n","6ae9cada":"## Bivariate Analysis of Numeric variables\n\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nsns.scatterplot(x = house.GrLivArea, y = house.SalePrice)\nplt.subplot(2,3,2)\nsns.scatterplot(x = house.GarageCars, y = house.SalePrice)\nplt.subplot(2,3,3)\nsns.scatterplot(x = house.GarageArea, y = house.SalePrice)\nplt.subplot(2,3,4)\nsns.scatterplot(x = house.TotalBsmtSF, y = house.SalePrice)\nplt.subplot(2,3,5)\nsns.scatterplot(x = house['1stFlrSF'], y = house.SalePrice)\nplt.subplot(2,3,6)\nsns.scatterplot(x = house.YearBuilt_age, y = house.SalePrice)\n","8951bde1":"cat_vars = ['MSSubClass','MSZoning','Street','LotShape',\n            'LandContour','Utilities','LotConfig','LandSlope',\n            'Neighborhood','Condition1','Condition2','BldgType',\n            'HouseStyle','OverallQual','OverallCond','RoofStyle',\n            'RoofMatl','Exterior1st','Exterior2nd','MasVnrType',\n            'ExterQual','ExterCond','Foundation','BsmtQual',\n            'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n            'Heating','HeatingQC','Electrical','KitchenQual','Functional',\n            'GarageType','GarageFinish','GarageQual','GarageCond',\n            'PavedDrive','SaleType','SaleCondition','CentralAir']","e6ebc8c7":"#Check the value counts of cat variables \nfor var in cat_vars :\n    print(house[var].value_counts())","cdb80ac6":"house.head()","02809a04":"# From the above we could there are few unbalanced variables which will not help is analysing the data. Lets drop them.\nhouse = house.drop(['Street', 'Utilities', 'Condition2', 'RoofMatl', 'Heating'], axis='columns')\nhouse.shape","cf1d00aa":"# Performing Univariate analysis on Categoric variables\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nhouse.HouseStyle.value_counts().plot.bar()\nplt.subplot(2,3,2)\nhouse.OverallQual.value_counts().plot.bar()\nplt.subplot(2,3,3)\nhouse.BsmtExposure.value_counts().plot.bar()\nplt.subplot(2,3,4)\nhouse.HeatingQC.value_counts().plot.bar()\nplt.subplot(2,3,5)\nhouse.GarageFinish.value_counts().plot.bar()\nplt.subplot(2,3,6)\nhouse.SaleType.value_counts().plot.bar()\n","0498f2ed":"#Bivariate analysis\nsns.catplot(x=\"MSSubClass\", y=\"SalePrice\", data=house)","b987e9d1":"sns.catplot(x=\"MSZoning\", y=\"SalePrice\",kind=\"boxen\", data=house)\nplt.show()","1609bd48":"sns.catplot(x=\"LotShape\", y=\"SalePrice\",kind=\"violin\", data=house)\nplt.show()","7361f38d":"sns.catplot(x=\"LandContour\", y=\"SalePrice\", kind=\"bar\", data=house)","507b0faf":"sns.catplot(x=\"SaleCondition\", y=\"SalePrice\", kind=\"bar\", data=house)","8afe695b":"sns.catplot(x=\"LotConfig\", y=\"SalePrice\", kind=\"point\", data=house)","b66f61e4":"# Check most correlated variables with the target variable.\nplt.figure(figsize=(20,20))\nsns.heatmap(house[numeric_vars].corr(), annot=True)","de1c42af":"# Check the most correlated variables\ncorr = house[numeric_vars].corr()\nprint(corr['SalePrice'].sort_values(ascending=False)[:10], '\\n')\nprint(corr['SalePrice'].sort_values(ascending=False)[-5:])","c7fafe22":"cat_vars = ['MSSubClass','MSZoning','LotShape',\n            'LandContour','LotConfig','LandSlope',\n            'Neighborhood','Condition1','BldgType',\n            'HouseStyle','OverallQual','OverallCond','RoofStyle',\n            'Exterior1st','Exterior2nd','MasVnrType',\n            'ExterQual','ExterCond','Foundation','BsmtQual',\n            'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n            'HeatingQC','Electrical','KitchenQual','Functional',\n            'GarageType','GarageFinish','GarageQual','GarageCond',\n            'PavedDrive','SaleType','SaleCondition','CentralAir']","a3602b17":"house[cat_vars].info()","a088d08f":"house[['LotShape','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n            'HeatingQC','CentralAir','KitchenQual','GarageFinish','GarageQual','GarageCond',\n             'ExterCond']].head()","47e90f53":"# Lable encoding for ordinal variables\nhouse['LotShape'] = house.LotShape.map({'IR1':0,'IR2':1,'IR3':2,'Reg':3})\nhouse['LandSlope'] = house.LandSlope.map({'Gtl':0,'Mod':1,'Sev':2})\nhouse['ExterQual'] = house.ExterQual.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhouse['BsmtQual'] = house.BsmtQual.map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhouse['BsmtCond'] = house.BsmtCond.map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhouse['BsmtExposure'] = house.BsmtExposure.map({'NA':0,'No':1,'Mn':2,'Av':3,'Gd':4})\nhouse['BsmtFinType1'] = house.BsmtFinType1.map({'NA':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\nhouse['BsmtFinType2'] = house.BsmtFinType2.map({'NA':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\nhouse['HeatingQC'] = house.HeatingQC.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhouse['CentralAir'] = house.CentralAir.map({'N':0,'Y':1})\nhouse['KitchenQual'] = house.KitchenQual.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhouse['GarageFinish'] = house.GarageFinish.map({'NA':0,'Unf':1,'RFn':2,'Fin':3})\nhouse['GarageQual'] = house.GarageQual.map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhouse['GarageCond'] = house.GarageCond.map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhouse['ExterCond'] = house.ExterCond.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhouse['PavedDrive'] =house.PavedDrive.map({'N':0,'P':1,'Y':2})\nhouse[['LotShape','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n            'HeatingQC','CentralAir','KitchenQual','GarageFinish','GarageQual','GarageCond',\n             'ExterCond']].head()","19fe5740":"house.head()","b3406a35":"# Create dummy variables\ndum_col = pd.get_dummies(house[['MSZoning','LandContour','LotConfig','Neighborhood','Condition1','BldgType','HouseStyle','RoofStyle',\n 'Exterior1st','Exterior2nd','MasVnrType','Foundation','Electrical','Functional','GarageType','SaleType','SaleCondition']], drop_first = True)\nhouse = pd.concat([house, dum_col], axis='columns')\nprint(house.shape)\nhouse.head()\n","9c4f4b94":"house = house.drop(['MSZoning','LandContour','LotConfig','Neighborhood','Condition1','BldgType','HouseStyle','RoofStyle',\n                    'Exterior1st','Exterior2nd','MasVnrType','Foundation','Electrical','Functional','GarageType','SaleType','SaleCondition'], axis= 'columns')\n","0c494116":"print(house.shape)\nhouse.head()","541f28de":"# Plot the displot to check the distribution of target variable SalePrice\nsns.distplot(house.SalePrice)\nplt.show()","c32b5f0c":"house.SalePrice.skew()","6dc5423c":"plt.hist(house.SalePrice, color='red')","08bdd253":"house.SalePrice = np.log(house.SalePrice)\nplt.hist(house.SalePrice, color='blue')\nplt.show()","1aa8fc4f":"house.SalePrice.skew()","4a28bccb":"sns.distplot(house.SalePrice)\nplt.show()","44e1febe":"house.head()","9965ef35":"# Create X, y datsets\n\ny = house['SalePrice']\nX = house.drop(['SalePrice'], axis=1)","10bfe1d8":"y.head()","7c96a257":"X.shape","1aacca6e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33)","ef3bec8e":"X_train.head()","a860c675":"y_train.head()","4ee2ee30":"X_test.head()","21ab2e8d":"y_test.head()","d1fb59ae":"# Scale the numeric data in dataset\nto_be_scaled = ['MSSubClass','LotFrontage','LotArea','MasVnrArea','BsmtFinSF1',\n                'BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF',\n                '2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath',\n                'BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\n                'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars',\n                'GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch',\n                '3SsnPorch','ScreenPorch','PoolArea','MiscVal',\n                'MoSold','YearBuilt_age','YearRemodAdd_age',\n                'GarageYrBlt_age','YrSold_age']","70772249":"scaler = StandardScaler()\n# Train data scaling\nX_train[to_be_scaled] = scaler.fit_transform(X_train[to_be_scaled])\n\n# Test data scaling\nX_test[to_be_scaled] = scaler.fit_transform(X_test[to_be_scaled])\n\nX_train.head()","a895b196":"# Build basic Linear regression model\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\n# Perform RFE to get the best 25 features\nrfe = RFE(lm, 25)\nrfe = rfe.fit(X_train,y_train)","98e110e3":"rfe.ranking_","0ec60a0b":"rfe.support_","55333205":"# Zip columns, support and ranking together\nrfe_scores = pd.DataFrame(list(zip(X_train.columns,rfe.support_,rfe.ranking_)))\nrfe_scores.columns = ['Column_Names','Status','Rank']","26e4c1d4":"rfe_scores.sort_values(by=['Rank'], ascending=False).head(25)","24dbddc5":"rfe_cols = list(rfe_scores[rfe_scores.Status==True].Column_Names)","4b1c3021":"rfe_cols","fb567821":"X_train = X_train[rfe_cols]\nX_test = X_test[rfe_cols]","abd697fb":"X_train.head()","9f644fa2":"X_test.head()","57829a3f":"ridge = Ridge(alpha=0.1)\nridge.fit(X_train,y_train)\n\ny_train_pred = ridge.predict(X_train)\nprint(r2_score(y_train,y_train_pred))\ny_test_pred = ridge.predict(X_test)\nprint(r2_score(y_test,y_test_pred))","1d32bef4":"# Ridge Regression with different alpha values\n# Hyperparameters tuning\nparams = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n\n\nridge = Ridge()\n\n# cross validation\nfolds = 5\nR_model_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nR_model_cv.fit(X_train, y_train) ","f9f37e42":"R_cv_results = pd.DataFrame(R_model_cv.cv_results_)\nR_cv_results = R_cv_results[R_cv_results['param_alpha']<=200]\nR_cv_results.head()","06bb9c47":"# plotting mean test and train scoes with alpha \nR_cv_results['param_alpha'] = R_cv_results['param_alpha'].astype('int32')\n\n# plotting\nplt.plot(R_cv_results['param_alpha'], R_cv_results['mean_train_score'])\nplt.plot(R_cv_results['param_alpha'], R_cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","b6ba1b83":"R_model_cv.best_params_","cbd83b29":"ridge = Ridge(alpha=3.0)\nridge.fit(X_train,y_train)\n\ny_train_pred = ridge.predict(X_train)\nprint(r2_score(y_train,y_train_pred))\ny_test_pred = ridge.predict(X_test)\nprint(r2_score(y_test,y_test_pred))","05e9cf3e":"model_parameter = list(ridge.coef_)\nmodel_parameter.insert(0,ridge.intercept_)\ncols = X_train.columns\ncols.insert(0,'constant')\nridge_coef = pd.DataFrame(list(zip(cols,model_parameter)))\nridge_coef.columns = ['Feature','Coef']","32d5715b":"ridge_coef.sort_values(by='Coef',ascending=False)","02534fd5":"alpha =0.001\nlasso = Lasso(alpha=alpha)        \nlasso.fit(X_train, y_train)\n\ny_train_pred = lasso.predict(X_train)\nprint(r2_score(y_train,y_train_pred))\ny_test_pred = lasso.predict(X_test)\nprint(r2_score(y_test,y_test_pred))","25d246aa":"lasso = Lasso()\n# cross validation\nparams = {'alpha': [0.000001,0.00001,0.0001, 0.0005, 0.001,0.005, 0.001,0.005,0.01, 0.05, 0.1]}\n\nl_model_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nl_model_cv.fit(X_train, y_train) ","04a8d53f":"l_cv_results = pd.DataFrame(l_model_cv.cv_results_)\nl_cv_results.head()","179236f2":"# plotting mean test and train scoes with alpha \nl_cv_results['param_alpha'] = l_cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.plot(l_cv_results['param_alpha'], l_cv_results['mean_train_score'])\nplt.plot(l_cv_results['param_alpha'], l_cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","4f1916c5":"l_model_cv.best_params_","8a9215b0":"alpha =0.0005\n\nlasso = Lasso(alpha=alpha)       \nlasso.fit(X_train, y_train) \n\ny_train_pred = lasso.predict(X_train)\nprint(r2_score(y_train,y_train_pred))\ny_test_pred = lasso.predict(X_test)\nprint(r2_score(y_test,y_test_pred))\n","4b8597d5":"model_parameter = list(lasso.coef_)\nmodel_parameter.insert(0,lasso.intercept_)\ncols = X_train.columns\ncols.insert(0,'constant')\nlasso_coef = pd.DataFrame(list(zip(cols,model_parameter)))\nlasso_coef.columns = ['Feature','Coef']","f5cc0a44":"lasso_coef.sort_values(by='Coef',ascending=False).head(20)","4a2cb394":"##Q1","525e861b":"## Lasso\nfrom sklearn.metrics import mean_squared_error\nalpha =0.0005\n\nlasso = Lasso(alpha=alpha)       \nlasso.fit(X_train, y_train) \n\ny_train_pred = lasso.predict(X_train)\nprint(r2_score(y_train,y_train_pred))\ny_test_pred_l = lasso.predict(X_test)\nprint(r2_score(y_test,y_test_pred_l))\n\nprint ('RMSE is: ', mean_squared_error(y_test, y_test_pred_l))","8365d96b":"alpha =0.0005*2\n\nlasso = Lasso(alpha=alpha)       \nlasso.fit(X_train, y_train) \n\ny_train_pred = lasso.predict(X_train)\nprint(r2_score(y_train,y_train_pred))\ny_test_pred_l = lasso.predict(X_test)\nprint(r2_score(y_test,y_test_pred_l))\n\nprint ('RMSE is: ', mean_squared_error(y_test, y_test_pred_l))\n","c5d1f6b9":"#lasso\nmodel_parameter = list(lasso.coef_)\nmodel_parameter.insert(0,lasso.intercept_)\ncols = X_train.columns\ncols.insert(0,'constant')\nlasso_coef = pd.DataFrame(list(zip(cols,model_parameter)))\nlasso_coef.columns = ['Feature','Coef']\nlasso_coef.sort_values(by='Coef',ascending=False).head(20)","895c6581":"ridge = Ridge(alpha=3.0)\nridge.fit(X_train,y_train)\n\ny_train_pred = ridge.predict(X_train)\nprint(r2_score(y_train,y_train_pred))\ny_test_pred = ridge.predict(X_test)\nprint(r2_score(y_test,y_test_pred))\n\nprint ('RMSE is: ', mean_squared_error(y_test, y_test_pred))","4a1287f7":"ridge = Ridge(alpha=3.0*2)\nridge.fit(X_train,y_train)\n\ny_train_pred = ridge.predict(X_train)\nprint(r2_score(y_train,y_train_pred))\ny_test_pred = ridge.predict(X_test)\nprint(r2_score(y_test,y_test_pred))\n\nprint ('RMSE is: ', mean_squared_error(y_test, y_test_pred))","af700e9f":"model_parameter = list(ridge.coef_)\nmodel_parameter.insert(0,ridge.intercept_)\ncols = X_train.columns\ncols.insert(0,'constant')\nridge_coef = pd.DataFrame(list(zip(cols,model_parameter)))\nridge_coef.columns = ['Feature','Coef']\nridge_coef.sort_values(by='Coef',ascending=False)","e7b2e00a":"#Q3","caddab8b":"house = pd.read_csv('..\/input\/us-house-pricing\/train.csv')\nnull_cols = house.columns[house.isnull().mean() > 0.4]\nhouse.drop(null_cols, axis=1,  inplace=True)\nhouse['YearBuilt_age'] = 2020-house.YearBuilt\nhouse['YearRemodAdd_age'] = 2020-house.YearRemodAdd\nhouse['GarageYrBlt_age'] = 2020-house.GarageYrBlt\nhouse['YrSold_age'] = 2020-house.YrSold\nhouse[['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold','YearBuilt_age','YearRemodAdd_age',\n             'GarageYrBlt_age','YrSold_age']].head()\n\nhouse = house.drop(['Id','OverallQual','Neighborhood','BldgType','YearBuilt_age','GrLivArea'],axis='columns')\n\nhouse = house.drop(['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold'],axis='columns')\nhouse.LotFrontage.fillna(house.LotFrontage.mean(), inplace= True)\nhouse.MasVnrArea.fillna(house.MasVnrArea.mean(), inplace= True)\nhouse.MasVnrType.fillna('None',inplace=True)\nhouse.BsmtQual.fillna('NA',inplace=True)\nhouse.BsmtCond.fillna('NA',inplace=True)\nhouse.BsmtExposure.fillna('NA',inplace=True)\nhouse.BsmtFinType1.fillna('NA',inplace=True)\nhouse.BsmtFinType2.fillna('NA',inplace=True) \nhouse.GarageType.fillna('NA',inplace=True)\nhouse.GarageYrBlt_age.fillna(-1,inplace=True)\nhouse.GarageFinish.fillna('NA',inplace=True)\nhouse.GarageQual.fillna('NA',inplace=True)\nhouse.GarageCond.fillna('NA',inplace=True)\nhouse.Electrical.fillna('Mix',inplace=True)\n\n\nTotalBsmtSFq99 = house.TotalBsmtSF.quantile(0.99)\nTotalBsmtSFq05 = house.TotalBsmtSF.quantile(0.01)\n\n\nhouse = house[house['TotalBsmtSF']<=TotalBsmtSFq99]\nhouse = house[house['TotalBsmtSF']>=TotalBsmtSFq05]\n\nhouse = house.drop(['Street', 'Utilities', 'Condition2', 'RoofMatl', 'Heating'], axis='columns')\n\nhouse['LotShape'] = house.LotShape.map({'IR1':0,'IR2':1,'IR3':2,'Reg':3})\nhouse['LandSlope'] = house.LandSlope.map({'Gtl':0,'Mod':1,'Sev':2})\nhouse['ExterQual'] = house.ExterQual.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhouse['BsmtQual'] = house.BsmtQual.map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhouse['BsmtCond'] = house.BsmtCond.map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhouse['BsmtExposure'] = house.BsmtExposure.map({'NA':0,'No':1,'Mn':2,'Av':3,'Gd':4})\nhouse['BsmtFinType1'] = house.BsmtFinType1.map({'NA':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\nhouse['BsmtFinType2'] = house.BsmtFinType2.map({'NA':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\nhouse['HeatingQC'] = house.HeatingQC.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhouse['CentralAir'] = house.CentralAir.map({'N':0,'Y':1})\nhouse['KitchenQual'] = house.KitchenQual.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhouse['GarageFinish'] = house.GarageFinish.map({'NA':0,'Unf':1,'RFn':2,'Fin':3})\nhouse['GarageQual'] = house.GarageQual.map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhouse['GarageCond'] = house.GarageCond.map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\nhouse['ExterCond'] = house.ExterCond.map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\nhouse['PavedDrive'] =house.PavedDrive.map({'N':0,'P':1,'Y':2})\n\ndum_col = pd.get_dummies(house[['MSZoning','LandContour','LotConfig','Condition1','HouseStyle','RoofStyle',\n 'Exterior1st','Exterior2nd','MasVnrType','Foundation','Electrical','Functional','GarageType','SaleType','SaleCondition']], drop_first = True)\nhouse = pd.concat([house, dum_col], axis='columns')\nhouse = house.drop(['MSZoning','LandContour','LotConfig','Condition1','HouseStyle','RoofStyle',\n                    'Exterior1st','Exterior2nd','MasVnrType','Foundation','Electrical','Functional','GarageType','SaleType','SaleCondition'], axis= 'columns')\nhouse.SalePrice = np.log(house.SalePrice)\ny = house['SalePrice']\nX = house.drop(['SalePrice'], axis=1)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33)\nto_be_scaled = ['MSSubClass','LotFrontage','LotArea','MasVnrArea','BsmtFinSF1',\n                'BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF',\n                '2ndFlrSF','LowQualFinSF','BsmtFullBath',\n                'BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\n                'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars',\n                'GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch',\n                '3SsnPorch','ScreenPorch','PoolArea','MiscVal',\n                'MoSold','YearRemodAdd_age',\n                'GarageYrBlt_age','YrSold_age']\nscaler = StandardScaler()\n# Train data scaling\nX_train[to_be_scaled] = scaler.fit_transform(X_train[to_be_scaled])\n\n# Test data scaling\nX_test[to_be_scaled] = scaler.fit_transform(X_test[to_be_scaled])\n# Build basic Linear regression model\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\n# Perform RFE to get the best 25 features\nrfe = RFE(lm, 25)\nrfe = rfe.fit(X_train,y_train)\n# Zip columns, support and ranking together\nrfe_scores = pd.DataFrame(list(zip(X_train.columns,rfe.support_,rfe.ranking_)))\nrfe_scores.columns = ['Column_Names','Status','Rank']\nrfe_cols = list(rfe_scores[rfe_scores.Status==True].Column_Names)\nX_train = X_train[rfe_cols]\nX_test = X_test[rfe_cols]\nalpha =0.0005\nlasso = Lasso(alpha=alpha)       \nlasso.fit(X_train, y_train)\ny_train_pred = lasso.predict(X_train)\ny_test_pred_l = lasso.predict(X_test)\nmodel_parameter = list(lasso.coef_)\nmodel_parameter.insert(0,lasso.intercept_)\ncols = X_train.columns\ncols.insert(0,'constant')\nlasso_coef = pd.DataFrame(list(zip(cols,model_parameter)))\nlasso_coef.columns = ['Feature','Coef']\nlasso_coef.sort_values(by='Coef',ascending=False).head(20)\n","279e9f2c":"### 7.2 Scale the numeric data","7c671ac2":"  - SaleCondition Partial is high in salesprice","f50be67f":"### 4.6 Correlation between variables","05fa892c":"  - LotConfig FR3 and CulDSac are high in saleprice","81e9489a":"### 7.1 Train_Test_split","5774bb6c":"### 4.5 Categoric variable analysis","75270ae8":"  - Lotshape IR3, IR2, IR1, Reg are in order from high to low","64ab86e1":"## 5. Handling Categoric variables","3722ce9a":"  - MSZoning FV and RL are higher in salesprice","a7269543":"A US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them on at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia. The data is provided in the CSV file .","041d735a":"  - LandContour HLS is high in salesprice ","b7dea355":"## 7. Model Building","17fb6a32":"### 7.4 Ridge Regression","81d26c86":"#### The company wants to know:\n\n  - Which variables are significant in predicting the price of a house, and\n\n  - How well those variables describe the price of a house.\n\nAlso, determine the optimal value of lambda for ridge and lasso regression.","168cb37e":"  - We could see data is skewed at right side, we should make sure that model will be learning this skewed data well, for that we should be using transformation to make this data to be normally distributed.","0404f353":"  - From the above we could see that there is no null values present in the data.","3f233d2a":"  - We could see MSSunClass 60 is having high saleprice","f1f510b1":"## 8. Conclusion","fb4bbaf9":"  - From the above we could see there are null values, lets drop the columns having more than 40% null values as we cannot impute 40% of the data, which leads missleading in data.","4788fab9":"## 6. Distribution of Target Variable","0939a955":"### 7.3 Linear Model Buildding","c56c0968":"  - Could see that there is no duplicates in the data","42c1469f":"#### Comments :\n  - From the above graphs we can see that, these variables are ordinal in nature.","0369933a":"## 1. Import required Libraries","25f4da8d":"Comments :\n  -  From the above heat map we could see,\nPositive correlated variables\n  - SalePrice       1.000000\n  - GrLivArea       0.719458\n  - GarageCars      0.650723\n  - GarageArea      0.635808\n  - TotalBsmtSF     0.626748\n  - 1stFlrSF        0.606937\n\nNegatively correlated variables\n  - KitchenAbvGr       -0.141602\n  - EnclosedPorch      -0.144823\n  - GarageYrBlt_age    -0.354134\n  - YearRemodAdd_age   -0.528923\n  - YearBuilt_age      -0.538377\n","eaff06cc":"#### Comments :\n   - From the above we can see that, GrLivArea, GarageArea, TotalBsmtSF and 1stFlrSF are positively linear with the target variable\n   - YearBuilt_age negatively linear with the target variable","d1562196":"  - Above are the most correlated(positively\/negatively) variables ","84c3e595":"### 4.2 Numeric and Categoric variables","637b5865":"#### Comments :\n  - The best value of alpha for ridge regression is 3.0 \n  - The training r2 score is 0.86\n  - The test r2 score is 0.85","f97f91e7":"## 2. Load the Dataset","4e7a1059":"### 4.3 Imputing missing values","d34a685e":"# Surprise Housing Assignment","09a75a0f":"The company is looking at prospective properties to buy to enter the market. You are required to build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.","479457c5":"  - For 0.1 value of alpha the r2 score for train and test are 0.86, 0.85 respectively","7e05dd6e":"### 7.5 Lasso Regression","7b86d095":"## Assignmnet Description","4fdcb298":"#### From the above two techniques of Lasso and Ridge Regression, we can say that both almost having the same r2 value.\n  \n#### Ridge Regression :\n       - The optimal alpha value is 3.0\n       - Train r2 score -   0.86\n       - Test r2 score  -   0.85\n       \n            \n#### Lasso Regression :\n       - The optimal alpha value is 0.0005\n       - Train r2 score -   0.86\n       - Test r2 score  -   0.85\n       \n  \n  - When comparing the complexity, it is better to use Lasso because as we have large number of variables, Lasso will make the feature selection among the present variables, but Ridge will not reduce columns, it will keep all variables with the reducing the coefficient of variables.\n  \n#### The 5 most significant variables are :\n \n    - OverallQual             10.997687\n    - Neighborhood_Crawfor    0.174573\n    - BldgType_Twnhs          0.160316\n    - YearBuilt_age           0.151231\n    - GrLivArea               0.13925\n    \n    \n#### All significant coefficients are :\n  - OverallQual              11.028226\n  - Neighborhood_Crawfor     0.176165\n  - BldgType_Twnhs           0.159435\n  - YearBuilt_age            0.150105\n  - GrLivArea                0.139850\n  - Neighborhood_NridgHt     0.130701\n  - MSZoning_RM              0.104217\n  - CentralAir               0.098680\n  - Neighborhood_StoneBr     0.094979\n  - SaleCondition_Partial    0.093448\n  - GarageType_NA            0.083390\n  - MSZoning_RH              0.077983\n  - Neighborhood_Veenker     0.065933\n  - Functional_Typ           0.055249\n  - Foundation_Wood          0.027489\n  - Neighborhood_ClearCr     0.000000\n  - MSZoning_RL             -0.000000\n  - SaleCondition_Normal     0.000000\n  - Functional_Maj2         -0.014591\n  - Exterior1st_BrkComm     -0.074586\n  \n### The most significant variable is overallQual which increases the saleprice by 11%, followed by Neighborhood_Crawfor(0.176165), BldgType_Twnhs(0.159435), YearBuilt_age(0.150105) and GrLivArea(0.139850)","2d95935c":"## 4. Perform EDA on the Dataset","5c511be7":"### 4.1 Checking Null values","f77a1925":"### Subjective questions","d5974123":"## 3.Inspect the Data","b3096d0f":"## Business Goal \n\nYou are required to model the price of houses with the available independent variables. This model will then be used by the management to understand how exactly the prices vary with the variables. They can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns. Further, the model will be a good way for management to understand the pricing dynamics of a new market.","2100191e":"  - Now target variable looks normally distributed.","66cedce8":"### 4.4 Numeric variable analysis"}}