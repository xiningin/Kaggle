{"cell_type":{"0018b4e3":"code","2a497a66":"code","ca1be15e":"code","bdd6c99b":"code","70d8bcc4":"code","654a4941":"code","6d5f419f":"code","7511cbdb":"code","23e08d4d":"code","6d62885a":"code","5b6c5c95":"code","57e18207":"code","df4a1b29":"code","a8ed1f7c":"code","8609e947":"code","74900f58":"code","c087cb8d":"code","8a5ecafb":"code","ffc704e4":"code","1a8b0e85":"code","a6198adb":"code","bbc14204":"code","128848ac":"code","186c5fa7":"code","c5475532":"code","cd066b0c":"code","875e007a":"code","d9fd19c7":"code","531e2690":"code","8f2a86d3":"code","134472bb":"code","a8665d15":"code","75978e0e":"code","cca3e735":"code","71396d54":"markdown","19605a78":"markdown","537eb5d7":"markdown","e881016a":"markdown","db62424f":"markdown","dbac09e0":"markdown","65e233f7":"markdown","a1f453ef":"markdown","4d8fcd08":"markdown","8018f1de":"markdown","ac4e1a77":"markdown","ca43db00":"markdown","6a1dcd79":"markdown","9eca8fd9":"markdown","78e0569f":"markdown","9e4c047d":"markdown","36f49c82":"markdown","7d0bbff0":"markdown","96b3a118":"markdown","69099a5a":"markdown","82ebad16":"markdown","5546f3d9":"markdown","f72b5d72":"markdown","1a84405d":"markdown","07c92812":"markdown","71c294b5":"markdown"},"source":{"0018b4e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2a497a66":"df_test = pd.read_csv('..\/input\/test.csv')\ndf_train = pd.read_csv('..\/input\/train.csv')","ca1be15e":"df_train.head()\n","bdd6c99b":"del df_train['PassengerId']\ndel df_train['Name']\ndf_id = df_test.pop('PassengerId')#vamos aproveitar essa coluna para concatenar nosso resultado da predi\u00e7\u00e3o com os ids dos passageiros.\ndel df_test['Name']","70d8bcc4":"df_test.head()","654a4941":"\ndf_train.head()","6d5f419f":"del df_train['Ticket']\ndel df_test['Ticket']\ndf_train.head()","7511cbdb":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","23e08d4d":"print(df_train.isnull().sum())\ndf_train.isnull().sum().plot(kind='Bar')","6d62885a":"del df_train['Cabin']\ndel df_test['Cabin']\ndf_train.head()","5b6c5c95":"sns.boxplot(x='Pclass',y='Age',hue='Sex', data=df_train )","57e18207":"\ndef test_class(df):\n    #indice 0- classe 1, indice 1-classe 2 ,indice 2-classe 3.\n    media_homem =[]\n    media_mulher=[]\n    \n    #Vamos criar as vari\u00e1veis com os valores das m\u00e9dias dos homens e mulheres por classe:\n    for x in range(1,4):\n        media_homem.append(int(df['Age'][(df['Sex']=='male')&(df['Pclass']==x)].mean()))\n        media_mulher.append(int(df['Age'][(df['Sex']=='female')&(df['Pclass']==x)].mean()))\n    \n    return(media_homem, media_mulher)\n\n\ndef input_age(df):\n    age = df[0]\n    pclass=df[1]\n    sex=df[2]\n    \n    if pd.isnull(age):\n        if pclass == 1:\n            if sex == 'male':\n                return med_men[0]\n            else:\n                return  med_women[0]\n        elif pclass == 2:\n            if sex == 'male':\n                return  med_men[1]\n            else:\n                return med_women[1]\n        else:\n            if sex == 'male':\n                return  med_men[2]\n            else:\n                return med_women[2]\n    else:\n        return age   ","df4a1b29":"med_men,med_women = test_class(df_train)\ndf_train['Age'] = df_train[['Age','Pclass','Sex']].apply(input_age, axis=1)\n\n#agora iremos fazer o mesmo com o dataset test\nmed_men,med_women = test_class(df_test)\ndf_test['Age'] = df_test[['Age','Pclass','Sex']].apply(input_age, axis=1)","a8ed1f7c":"print(df_train.isnull().sum())\ndf_train.isnull().sum().plot(kind='Bar', title='NaN df_train')\n\n","8609e947":"df_train.dropna(inplace=True)\nprint(df_train.isnull().sum())\ndf_train.isnull().sum().plot(kind='Bar', title='NaN df_train')","74900f58":"print(df_test.isnull().sum())\ndf_test.isnull().sum().plot(kind='Bar', title='NaN df_test')\n","c087cb8d":"df_test[df_test['Fare'].isnull()==True]","8a5ecafb":"df_test.fillna(value=(df_test['Fare'][df_test['Pclass']==3].mean()),inplace=True)\nprint(df_test.isnull().sum())\ndf_test.isnull().sum().plot(kind='Bar')","ffc704e4":"df_train = pd.get_dummies(df_train, drop_first=True)","1a8b0e85":"df_train.head()","a6198adb":"df_test = pd.get_dummies(df_test, drop_first=True)\ndf_test.head()","bbc14204":"from sklearn.tree import DecisionTreeClassifier","128848ac":"X= df_train.drop(labels='Survived', axis=1)\ny= df_train['Survived']","186c5fa7":"dtc = DecisionTreeClassifier()","c5475532":"dtc.fit(X,y)","cd066b0c":"dtc.score(X,y)","875e007a":"pred = dtc.predict(df_test)","d9fd19c7":"df_result = pd.DataFrame(data={'PassengerId':df_id.values , 'Survived':pred})","531e2690":"df_result.to_csv(path_or_buf='.\/sub_decision_tree.csv',index=False)","8f2a86d3":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=100)\n","134472bb":"rfc.fit(X,y)\nrfc.score(X,y)","a8665d15":"pred_rf = rfc.predict(df_test)\n","75978e0e":"df_result_rf = pd.DataFrame(data={'PassengerId':df_id.values , 'Survived':pred_rf})","cca3e735":"df_result_rf.to_csv(path_or_buf='.\/sub_random_forest.csv',index=False)","71396d54":"![image.png](attachment:image.png)","19605a78":"Arquivo criado  Para enviar nossa predi\u00e7\u00e3o, basta sair do modo edi\u00e7\u00e3o do kernel, clicar na op\u00e7\u00e3o **Output** do kernel(fica a esquerda da tela), selecionar o arquivo gerado e clicar em **submmit** .","537eb5d7":"## Get Dummies, como usar?","e881016a":"## Importando os datasets\nCome\u00e7aremos importando os datasets train.csv e test.csv. Iremos realizar algumas opera\u00e7\u00f5es com eles para conseguirmos usar as colunas como features dos modelos.","db62424f":"Podemos ver que duas colunas possuem NaN, com perfis diferentes. 'Age' cont\u00e9m 177 NaN, onde podemos abordar preenchendo esses valores com a m\u00e9dia. 'Cabin' no entanto, possui grande quantidade de NaN para serem tratadas, portanto iremos descartar essa coluna do nosso dataset:\n","dbac09e0":"O comando *get_dummies* identifica as colunas que diferentes de int e float, criando uma matriz de 0 e 1 para indicar os elementos.\n\nEx.: Coluna: **Sex**  - - - - - - - - - - - - - - - -matriz:   sex_female : sex_male  \n\n\n        male                           0         1                                                          \n         \n        female                         1         0\n             \n        female                         1         0\n             \n        male                           0         1            \n        \nMas n\u00e3o \u00e9 necess\u00e1rio ter duas colunas neste caso para saber se o passageiro \u00e9 homem ou mulher, por isso dentro da fun\u00e7\u00e3o **get_dummies** tem um par\u00e2mentro **drop_first**, que retira a primeira coluna da matriz gerada.\nIsso acontece do mesmo jeito da coluna **Embarked**, que possui 3 categorias.\n\nEnt\u00e3o podemos concluir que a gera\u00e7\u00e3o da matriz e sua utiliza\u00e7\u00e3o segue a regra **N-1**, onde **N** \u00e9 o n\u00famero de elementos dentro da categoria(vari\u00e1vel).\n\nVamos aplicar a mesma t\u00e9cnica no dataset df_test:\n","65e233f7":"![image.png](attachment:image.png)","a1f453ef":"Analisando o NaN faltante, vemos que trata-se de um valor de Fare da classe 3. Portanto, iremos completar esse dado com a m\u00e9dia de valores em 'Fare' para a classe 3.","4d8fcd08":"## Limpando o dataset: O que usar?\nComo podemos ver, nosso dataset tem colunas que trazem informa\u00e7\u00f5es que n\u00e3o ser\u00e3o relevantes para nosso modelo, como 'PassengerId' e 'Name'. Vamos deletar essas colunas do nosso dataset:\n","8018f1de":"Ok, conseguimos preencher nossos dados de 'Age' que estavam faltando.\nAgora temos apenas 2 campos da coluna 'Embarked' que est\u00e3o faltando. Podemos apagar essas linhas que nosso modelo n\u00e3o ser\u00e1 afetado. Usaremos *df_train.dropna(inplace=True)* onde *inplace=True* siginifica que iremos afetar  nosso dataset original com esta mudan\u00e7a:\n","ac4e1a77":"Chegamos aos mesmos 0.97 de precis\u00e3o do algor\u00edtimo DecisionTree, ser\u00e1 que conseguiremos evoluir nosso LB Score (Leader Board Score)? ","ca43db00":"Vamos aplicar nossa fun\u00e7\u00e3o usando a fun\u00e7\u00e3o apply(), depois iremos ver o resultado.","6a1dcd79":"Seguiremos o mesmo passo de envio para o desafio.\n\nVamos ver nosso resultado:","9eca8fd9":"## Missing values (NaN), o que fazer?\nTemos algumas op\u00e7\u00f5es de abordagem para tratar os valores faltantes em colunas e tabelas, entre as mais populares est\u00e3o:\n <l>\n  - **Deletar a linha que contem NaN**: Todas as colunas s\u00e3o afetadas, perdendo valores que est\u00e3o na mesma linha que o NaN. Recomendado para grandes datasets onde a perda de dados n\u00e3o afetar\u00e1 o resultado de predi\u00e7\u00e3o. Comando usado: pd.dropna()\n    \n  - **Deletar a coluna que contem NaN**: Apenas a coluna que cont\u00e9m os valores NaN, mantendo os valores das outras colunas. Recomendado para colunas onde a grande maioria dos dados s\u00e3o NaN, dificultando o tratamento desses valores\n  \n  - **Completar os dados NaN**: Usando fun\u00e7\u00f5es como m\u00e9dia de valores, por exemplo, podemos completar os dados faltantes usando a fun\u00e7\u00e3o dp.fillna(). Indicado para colunas num\u00e9ricas n\u00e3o categ\u00f3ricas.\n <\/l>\n \n Vamos analisar como est\u00e3o nossos NaN no dataset:","78e0569f":"Nossa pontua\u00e7\u00e3o atingiu um Score de 0.70813, o que comparado com nosso Score de treino (0.97) est\u00e1 indicando um prov\u00e1vel *overfitting*, ou seja, estamos \"enviesando\" nosso modelo.\n\nVamos partir agora para outro algoritmo, Random Forest, que tende a lidar  melhor com a quest\u00e3o do *overfitting* do algoritmo Decision Tree. ","9e4c047d":"Podemos ver acima que o m\u00e9todo predict gera um vetor com o nosso target **'Survived'**. Temos agora que concatenar com os **'Passenger_Id'** para poder enviar o desafio.","36f49c82":"Vamos tratar nossa coluna 'Age'. Mas primeiro, vamos analisar como ela est\u00e1 relacionada com o restante do nosso dataset:\n","7d0bbff0":"# Comparando Algoritmos\n## Decision Tree x Random Forest\n\nIremos realizar neste kernel uma an\u00e1lise dos resultados da aplica\u00e7\u00e3o dos algoritmos Decision tree e Random Forest no dataset Titanic. Ambos s\u00e3o considerados algoritmos de classifica\u00e7\u00e3o, e esperamos obter um resultado melhor com Random Forest.\nPara saber qual se sai melhor, iremos gerar dos arquivos e submete-los no desafio do kaggle, que ira retornar nosso percentual de precis\u00e3o de acerto, quanto maior melhor (max.:1, min.:0). ","96b3a118":"## Decision Tree \nEstamos prontos para come\u00e7ar a treinar nosso modelo. Vamos usar a biblioteca Scikit-Learn para nossa predi\u00e7\u00e3o.\n\nNossos dataset j\u00e1 est\u00e3o dividos entre train e test, portanto n\u00e3o precisamos usar a fun\u00e7\u00e3o de split para a divis\u00e3o dos dados.\nVamos diretos para o fit, treinar o modelo para a predi\u00e7\u00e3o.\n","69099a5a":"## Analisando a precis\u00e3o do modelo\nDepois que treinamos o modelo, podemos ver como ele se saiu usando nosso dataset de treino. Para isso, vamos analisar o score, que \u00e9 o percentual de acerto do modelo, que nosso algoritmo obteve ao processar o dataset.","82ebad16":"A coluna Ticket tamb\u00e9m nos traz uma aleatoriedade que n\u00e3o ajudara o nosso modelo a classificar quem sobreviveu ou n\u00e3o, portanto vamos tirar do dataset:","5546f3d9":"Vemos que temos diferen\u00e7a da m\u00e9dia quando as pessoas s\u00e3o de classes diferentes e tamb\u00e9m entre homens e mulheres. Agora podemos adotar uma forma de tratar esses NaN levando em considera\u00e7\u00e3o essas diferen\u00e7as, para n\u00e3o criarmos distor\u00e7\u00f5es em nosso dataset.\nCriaremos uma fun\u00e7\u00e3o para definir qual media que iremos usar para preencher em cada caso espec\u00edfico, considerando a classe e sexo do passageiro.","f72b5d72":"Conseguimos 97% de acerto, um n\u00famero bem alto. Agora temos que gerar nosso arquivo com as predi\u00e7\u00f5es do dataset test.csv e envia-lo para o desafio do kaggle. O arquivo deve seguir o padr\u00e3o solicitado pelo Kaggle, conforme modelo que foi deixado como exemplo para ser seguido(gender_submission.csv) ","1a84405d":"Agora temos nosso dataset sem NaN.\nIremos tratar agora as vari\u00e1veis categ\u00f3ricas.","07c92812":"As vari\u00e1veis categ\u00f3ricas n\u00e3o se encaixam muito bem nos nossos algoritmos, elas devem ser tratadas antes de usarmos como features para nosso modelo.\nUma forma que temos de tratar \u00e9 usar uma fun\u00e7\u00e3o da biblioteca Pandas, que facilita muito nosso trabalho com esse tratamento.\n","71c294b5":"## YES!!\n\nApenas alterando nosso algoritmo, conseguimos aumentar nosso Score para **0.75**, o  que j\u00e1 \u00e9 um avan\u00e7o.\nNo entanto, estamos bem longe dos 0.97 que chegamos de Score com nosso dataset de treino.\n\nIsso pode reamente indicar que estamos tendo problemas de Overfitting usando essa abordagem. Mesmo o Random Forest lidando melhor com isso, n\u00e3o conseguiu um desempenho t\u00e3o bom. \n\n# Aproveite esse kernel, fa\u00e7a altea\u00e7\u00f5es nos par\u00e2metros, altere as features e tente obter resultados melhores com esses dois algoritmos.\n### Para isso, d\u00ea um *FORK* e inicie seu proprio kernel a partir deste.\n\n## Bons estudos!!"}}