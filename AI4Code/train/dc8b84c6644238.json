{"cell_type":{"6053bb1c":"code","038efbb0":"code","52be4b81":"code","16ff088c":"code","c94e81cc":"code","d311f07f":"code","6cd8e6a9":"code","4333c1f8":"code","4c4da38d":"code","8a7edfb7":"code","102ed6cd":"code","2f1df525":"code","10c78984":"code","eaec19f4":"code","ffe0eed3":"code","c13884b3":"code","f96272d4":"code","5600c2e9":"code","1a8db91c":"markdown"},"source":{"6053bb1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.metrics import r2_score\nimport os, glob\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RepeatedStratifiedKFold, RepeatedKFold\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","038efbb0":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))","52be4b81":"def realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  \/ (\n                                      df_book_data['bid_size1']+ df_book_data[\n                                  'ask_size1'])\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock, int(stock_id)","16ff088c":"def past_realized_volatility_per_stock(list_file, train_df, prediction_column_name, train=True, models=None):\n    df_past_realized = pd.DataFrame()\n    models_arr = []\n    for file in list_file:\n        df_realized_vol_per_stock, stock_id = realized_volatility_per_time_id(file, prediction_column_name)\n        test_stock = train_df.query('stock_id == @stock_id')\n        if train:\n            \n            test_stock_full, model = get_features_and_model(test_stock, df_realized_vol_per_stock)\n            models_arr.append(model)\n            df_past_realized = pd.concat([df_past_realized, test_stock_full])\n            \n        elif models:\n            test_stock_full = get_features_and_model(test_stock, df_realized_vol_per_stock, \n                                                     train=False, model=models[stock_id])\n            df_past_realized = pd.concat([df_past_realized, test_stock_full])\n            \n    return df_past_realized, models_arr","c94e81cc":"def fitting_model(test_stock_full):\n    \n    \n    X = test_stock_full[test_stock_full.columns[5:].tolist()]\n    y = test_stock_full['target']\n    model = XGBRegressor(n_estimators=500, max_depth=10, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n\n    model.fit(X, y)\n    test_stock_full['boost_pred'] = model.predict(X)\n    get_score(test_stock_full,'boost_pred') \n    return test_stock_full, model","d311f07f":"def get_features_and_model(test_stock, df_past_realized_train, train=True, model=None):\n        \n    # features\n    test_stock.loc[:,'diff'] = test_stock['target'].diff(2).values\n    for i in range(2,7):\n        test_stock.loc[:, 'laged_' + str(i)]  = test_stock.target.shift(i).values\n    \n    \n    laged_col = ['laged_' + str(i) for i in range(2,7)]\n    test_stock.loc[:, ['mean', 'std']] = test_stock[laged_col].agg(['mean','std'], axis=1).values\n    test_stock_full = test_stock.merge(df_past_realized_train[['row_id','pred']], on = ['row_id'], how = 'left')\n    \n    if train:\n        # fit model\n        test_stock_full.dropna(inplace=True)\n        test_stock_full, model = fitting_model(test_stock_full)\n        return test_stock_full, model\n    elif model:\n        X = test_stock_full[test_stock_full.columns[5:].tolist()]\n        test_stock_full['boost_pred'] = model.predict(X)\n        return test_stock_full\n    else:\n        print('Some problems!')\n        return None","6cd8e6a9":"def rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\n\ndef get_score(df,pred_col):\n    R2 = round(r2_score(y_true = df['target'], y_pred = df[pred_col]),3)\n    RMSPE = round(rmspe(y_true = df['target'], y_pred = df[pred_col]),3)\n    print(f'Performance of the column {pred_col} : R2 score: {R2}, RMSPE: {RMSPE}')","4333c1f8":"list_order_book_file_train = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\ntrain = pd.read_csv('\/kaggle\/input\/optiver-realized-volatility-prediction\/train.csv')\ntrain['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)","4c4da38d":"# test_stock = train.query('stock_id == 0')\n# print(test_stock.shape)\n# test_stock.reset_index(inplace=True)","8a7edfb7":"sns.displot(test_stock['target'])\nplt.show()\nsns.lineplot(x='index',y='target', data=test_stock)\nplt.show()","102ed6cd":"# ACF FEATURES\n\n\n# sm.tsa.acf(test_stock['target'], nlags=3)[1:]\n# sm.tsa.acf(test_stock['diff'], nlags=3, missing='drop')[1:]\n\n# test_stock_full, model = get_features_and_model(test_stock, df_past_realized_train)","2f1df525":"df_past_realized_train, models = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\n                                                                    train_df = train,\n                                                           prediction_column_name='pred')\ndf_past_realized_train.head()","10c78984":"# get_score(test_stock_full,'pred') \n# get_score(test_stock_full,'laged_2') \n# get_score(test_stock_full,'boost_pred') ","eaec19f4":"import pickle\nwith open('models.pkl', 'wb') as pickle_file:\n    pickle.dump(models, pickle_file)","ffe0eed3":"test = pd.read_csv('\/kaggle\/input\/optiver-realized-volatility-prediction\/test.csv')\ntest['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)","c13884b3":"list_order_book_file_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\ndf_naive_pred_test, models_arr = past_realized_volatility_per_stock(list_file=list_order_book_file_test, train_df=test,\n                                                           prediction_column_name='target', train=False, models=models)","f96272d4":"test","5600c2e9":"if df_naive_pred_test[0].empty:\n    test['target'] = 0\n    test.to_csv('submission.csv',index = False)\n    print('Empty!')\nelse:\n    df_naive_pred_test.to_csv('submission.csv',index = False)","1a8db91c":"# HOW CAN I GET LAGED FEATURES??????"}}