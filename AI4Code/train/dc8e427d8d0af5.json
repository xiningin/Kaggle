{"cell_type":{"504d1882":"code","3c27a475":"code","24513df0":"code","6b763273":"code","f8adebe6":"code","6d1f7ad4":"code","368133ed":"code","f5f2a8da":"code","ce3230d7":"code","4cdec994":"code","39f41aeb":"code","c81ffff7":"code","1e7f1257":"code","812b8ecb":"code","08173bd0":"code","86db9848":"code","193b7441":"code","446858c4":"code","8a58db20":"code","14b0caed":"code","64a0b25c":"code","486a222c":"code","8607c2e3":"code","33d16716":"code","3eadd0b7":"code","ba57276a":"code","ebfdf437":"code","68d92cf2":"code","3ac3bf56":"code","7e6ccab4":"code","91c76538":"code","2746d8a4":"code","d2c669c2":"code","1afeb7d3":"code","c90d5842":"code","531a5807":"code","f6e463b2":"code","fafb47c2":"code","d6b9ae33":"code","3404c3e7":"code","1e1aa035":"code","4bbaf801":"code","96212e4f":"markdown","f1571bf1":"markdown","9a1805f3":"markdown","c8ca650b":"markdown","9a276901":"markdown","0726ea9a":"markdown","60da44c5":"markdown","8c6a3418":"markdown","0a76b526":"markdown","bbce618a":"markdown","a8ceb57e":"markdown","02ce26af":"markdown","0fe27b90":"markdown","9db2e893":"markdown","7f73968e":"markdown","7c1e1ada":"markdown","a60f5c9d":"markdown","6632b779":"markdown","aeb22bd9":"markdown","bc587544":"markdown","7e95e090":"markdown","b958deb9":"markdown"},"source":{"504d1882":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","3c27a475":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","24513df0":"# Local\n# df = pd.read_csv('orbits - orbits.csv')\n\n# Kaggle\ndf = pd.read_csv('\/kaggle\/input\/asteroid-impacts\/orbits - orbits.csv')\ndf.head()","6b763273":"df","f8adebe6":"df.info()","6d1f7ad4":"df.isnull().sum()","368133ed":"df = df.dropna()","f5f2a8da":"df.isnull().sum()","ce3230d7":"plt.figure(figsize=(20,10))\nplt.title('Hazardous Count')\nsns.countplot(data=df, x ='Hazardous');","4cdec994":"df = df.drop('Object Name', axis=1)","39f41aeb":"df","c81ffff7":"plt.figure(figsize=(20,20))\nsns.heatmap(data=pd.get_dummies(df).corr(), annot=True);","1e7f1257":"sns.pairplot(data=df, hue='Hazardous')","812b8ecb":"df.corr()['Hazardous'].sort_values()","08173bd0":"plt.figure(figsize=(20,10))\nplt.title('Classification Count colored by Hazardous')\nsns.countplot(data=df, x='Classification', hue='Hazardous');","86db9848":"X = df.drop('Hazardous', axis=1)\ny = df['Hazardous']\nX = pd.get_dummies(X, drop_first=True)\ny = pd.get_dummies(y, drop_first=True)","193b7441":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","446858c4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","8a58db20":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","14b0caed":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier","64a0b25c":"from warnings import filterwarnings\nfilterwarnings('ignore')","486a222c":"from sklearn.metrics import classification_report,precision_score, recall_score,f1_score","8607c2e3":"def fit_and_score(models, X_train, X_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_scores = {}\n    model_recall = {}\n    model_f1 = {}\n    model_precision = {}\n    \n    for name, model in models.items():\n        model.fit(X_train,y_train)\n        y_preds = model.predict(X_test)\n        print(name)\n        print(classification_report(y_test, y_preds))\n        print('\\n')\n        model_scores[name] = model.score(X_test,y_test)\n        model_recall[name] = recall_score(y_test, y_preds)\n        model_f1[name] = f1_score(y_test, y_preds)\n        model_precision[name] = precision_score(y_test, y_preds)\n\n    model_scores = pd.DataFrame(model_scores, index=['Score']).transpose()\n    model_scores = model_scores.sort_values('Score')\n    model_recall = pd.DataFrame(model_recall, index=['Recall']).transpose()\n    model_recall = model_recall.sort_values('Recall')\n    model_f1 = pd.DataFrame(model_f1, index=['F1']).transpose()\n    model_f1 = model_f1.sort_values('F1')\n    model_precision = pd.DataFrame(model_precision, index=['Precision']).transpose()\n    model_precision = model_precision.sort_values('Precision')\n        \n    return model_scores, model_recall, model_f1, model_precision","33d16716":"models = {'LogisticRegression': LogisticRegression(max_iter=10000),\n          'KNeighborsClassifier': KNeighborsClassifier(),\n          'SVC': SVC(),\n          'DecisionTreeClassifier': DecisionTreeClassifier(),\n          'RandomForestClassifier': RandomForestClassifier(),\n          'AdaBoostClassifier': AdaBoostClassifier(),\n          'GradientBoostingClassifier': GradientBoostingClassifier(),\n          'XGBClassifier': XGBClassifier(objective='binary:logistic',eval_metric=['logloss']),\n          'XGBRFClassifier': XGBRFClassifier(objective='binary:logistic',eval_metric=['logloss']),\n          'LGBMClassifier':LGBMClassifier(),\n         'CatBoostClassifier': CatBoostClassifier(verbose=0)}","3eadd0b7":"model_scores, model_recall, model_f1, model_precision = fit_and_score(models, X_train, X_test, y_train, y_test)","ba57276a":"from sklearn.model_selection import cross_val_score","ebfdf437":"def get_baseline_cv_scores(model, X, y, cv=5):\n    \n    model_scores = {}\n    model_recall = {}\n    model_f1 = {}\n    model_precision = {}\n    \n    for name, model in models.items():\n        \n        print(name)\n        cv_accuracy = cross_val_score(model,X,y,cv=cv,\n                             scoring='accuracy')\n        print(f'Cross Validaion accuracy Scores: {cv_accuracy}')\n        print(f'Cross Validation accuracy Mean Score: {cv_accuracy.mean()}')\n\n        cv_precision = cross_val_score(model,X,y,cv=cv,\n                             scoring='precision')\n        print(f'Cross Validaion precision Scores: {cv_precision}')\n        print(f'Cross Validation precision Mean Score: {cv_precision.mean()}')\n\n        cv_recall = cross_val_score(model,X,y,cv=cv,\n                             scoring='recall')\n        print(f'Cross Validaion recall Scores: {cv_recall}')\n        print(f'Cross Validation recall Mean Score: {cv_recall.mean()}')\n\n        cv_f1 = cross_val_score(model,X,y,cv=cv,\n                             scoring='f1')\n        print(f'Cross Validaion f1 Scores: {cv_f1}')\n        print(f'Cross Validation f1 Mean Score: {cv_f1.mean()}') \n        print('\\n')\n\n        model_scores[name] = cv_accuracy.mean()\n        model_recall[name] = cv_precision.mean()\n        model_f1[name] = cv_recall.mean()\n        model_precision[name] = cv_f1.mean()\n    \n    return model_scores, model_recall, model_f1, model_precision","68d92cf2":"models = {'LogisticRegression': LogisticRegression(max_iter=10000),\n          'KNeighborsClassifier': KNeighborsClassifier(),\n          'SVC': SVC(),\n          'DecisionTreeClassifier': DecisionTreeClassifier(),\n          'RandomForestClassifier': RandomForestClassifier(),\n          'AdaBoostClassifier': AdaBoostClassifier(),\n          'GradientBoostingClassifier': GradientBoostingClassifier(),\n          'XGBClassifier': XGBClassifier(objective='binary:logistic',eval_metric=['logloss']),\n          'XGBRFClassifier': XGBRFClassifier(objective='binary:logistic',eval_metric=['logloss']),\n          'LGBMClassifier':LGBMClassifier(),\n         'CatBoostClassifier': CatBoostClassifier(verbose=0)}","3ac3bf56":"model_scores, model_recall, model_f1, model_precision = get_baseline_cv_scores(models, X_train, y_train, cv=5)","7e6ccab4":"model_f1 = pd.DataFrame(model_f1, index=['F1'])","91c76538":"model_f1.transpose().sort_values('F1')","2746d8a4":"from sklearn.metrics import classification_report, plot_confusion_matrix,plot_roc_curve","d2c669c2":"model = AdaBoostClassifier()\nmodel.fit(X_train, y_train)\ny_preds = model.predict(X_test)","1afeb7d3":"print(classification_report(y_test, y_preds))","c90d5842":"plot_confusion_matrix(model, X_test,y_test)","531a5807":"plot_roc_curve(model, X_test,y_test)","f6e463b2":"def get_cv_score(model, X, y, cv=5):\n    \n    \n    cv_accuracy = cross_val_score(model,X,y,cv=cv,\n                         scoring='accuracy')\n    print(f'Cross Validaion accuracy Scores: {cv_accuracy}')\n    print(f'Cross Validation accuracy Mean Score: {cv_accuracy.mean()}')\n    \n    cv_precision = cross_val_score(model,X,y,cv=cv,\n                         scoring='precision')\n    print(f'Cross Validaion precision Scores: {cv_precision}')\n    print(f'Cross Validation precision Mean Score: {cv_precision.mean()}')\n    \n    cv_recall = cross_val_score(model,X,y,cv=cv,\n                         scoring='recall')\n    print(f'Cross Validaion recall Scores: {cv_recall}')\n    print(f'Cross Validation recall Mean Score: {cv_recall.mean()}')\n    \n    cv_f1 = cross_val_score(model,X,y,cv=cv,\n                         scoring='f1')\n    print(f'Cross Validaion f1 Scores: {cv_f1}')\n    print(f'Cross Validation f1 Mean Score: {cv_f1.mean()}')   \n    \n    cv_merics = pd.DataFrame({'Accuracy': cv_accuracy.mean(),\n                         'Precision': cv_precision.mean(),\n                         'Recall': cv_recall.mean(),\n                         'f1': cv_recall.mean()},index=[0])\n    \n    return cv_merics","fafb47c2":"cv_merics = get_cv_score(model, X_train, y_train, cv=5)","d6b9ae33":"cv_merics","3404c3e7":"feat_importances = model.feature_importances_","1e1aa035":"feat_importances = pd.DataFrame(model.feature_importances_, index=X.columns.values)","4bbaf801":"plt.figure(figsize=(20,10))\nplt.title('Feature Importances')\nplt.xticks(rotation=90)\nsns.barplot(data=feat_importances.sort_values(0).T);","96212e4f":"## Reading the dataset","f1571bf1":"# Asteroid Impacts Classification\n\nGoing to take the following approach:\n\n1. Problem definition\n2. Data\n3. Evaluation\n4. Features\n5. Modelling\n6. Model Evaluation\n7. Experimentation \/ Improvements","9a1805f3":"We will drop the Object Name","c8ca650b":"# 5. Modelling","9a276901":"# 2. Data\n\nData from: https:\/\/www.kaggle.com\/shrushtijoshi\/asteroid-impacts\n\n## Context\n\nAn asteroid's orbit is computed by finding the elliptical path about the sun that best fits the available observations of the object. That is, the object's computed path about the sun is adjusted until the predictions of where the asteroid should have appeared in the sky at several observed times match the positions where the object was actually observed to be at those same times. As more and more observations are used to further improve an object's orbit, we become more and more confident in our knowledge of where the object will be in the future.\nWhen the discovery of a new near Earth asteroid is announced by the Minor Planet Center, Sentry automatically prioritizes the object for an impact risk analysis. If the prioritization analysis indicates that the asteroid cannot pass near the Earth or that its orbit is very well determined, the computationally intensive nonlinear search for potential impacts is not pursued. If, on the other hand, a search is deemed necessary then the object is added to a queue of objects awaiting analysis. Its position in the queue is determined by the estimated likelihood that potential impacts may be found.\n\n## Content\n\nSentry is a highly automated collision monitoring system that continually scans the most current asteroid catalog for possibilities of future impact with Earth over the next 100 years. This dataset includes the Sentry system's list of possible asteroid impacts with Earth and their probability, in addition to a list of all known near Earth asteroids and their characteristics.\n\n## Acknowledgements\n\nThe asteroid orbit and impact risk data was collected by NASA's Near Earth Object Program at the Jet Propulsion Laboratory (California Institute of Technology).","0726ea9a":"# 6. Model Evalution","60da44c5":"# 3. Evaluation\n\nAs this is a classification problem, we will use the classification metics for evauluting the model","8c6a3418":"## Model Imports","0a76b526":"## Confusion Matirx","bbce618a":"We will go with the AdaBoostClassifier to bulid our model.","a8ceb57e":"As the labels are in-balanced, we will use F1 scores to evaluate the model.","02ce26af":"## Data Exporation","0fe27b90":"## Feature Importances","9db2e893":"## Baseline Evalution using Cross-validation","7f73968e":"## Baseline Model Scores","7c1e1ada":"Since there is only one row with a missing data, we will drop that","a60f5c9d":"## ROC Curve","6632b779":"# 1. Problem Definition\n\nHow we can use various python based Machine Learning Model and the given parameters to predict the asteroid Hazardous?","aeb22bd9":"# 4. Features\n\n## Input \/ Features\n\n    Object Name - Asteroid Name\n    Epoch (TDB) - Epoch\n    Orbit Axis (AU) - Orbit Axis\n    Orbit Eccentricity- Eccentricity\n    Orbit Inclination (deg)- Inclination\n    Perihelion Argument (deg)- Perihelion Argument\n    Node Longitude (deg) - Node Longitude\n    Mean Anomoly (deg)- Mean Anomaly\n    Perihelion Distance (AU) - Perihelion Distance\n    Aphelion Distance (AU) - Aphelion Distance\n    Orbital Period (yr) - Orbital Period\n    Minimum Orbit Intersection Distance (AU) - Minimum Orbit Inclination\n    Orbital Reference - Orbital Reference\n    Asteroid Magnitude - Asteroid Magnitude\n    Classification - Asteroid Classiication\n\n## Output \/ Label\n    Hazardous - Hazard","bc587544":"## Standard Imports","7e95e090":"## Evalution using Cross-Validation","b958deb9":"## Classification Report"}}