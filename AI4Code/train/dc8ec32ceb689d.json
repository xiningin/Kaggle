{"cell_type":{"17a5b409":"code","3eb232ca":"code","9ce8ce5c":"code","8c4f5dba":"code","71d59aef":"code","df2f105b":"code","9a7039a3":"code","cf67f722":"code","c281586e":"code","9cf7f151":"code","ce0e4e0c":"code","f304b627":"code","61b6de26":"code","c9529f7e":"code","386c0f53":"code","777d4a49":"code","37f37cf1":"code","61b3f220":"code","9074db21":"code","fe483452":"code","4d11d05b":"code","650046dd":"code","6f10874d":"code","b68403a4":"code","923dcbb2":"code","83d53ede":"code","032ae5f7":"code","b69ca1b1":"code","648c6436":"code","fc5b95c3":"code","5c5bb876":"code","fc02ce64":"code","bb8581aa":"markdown","661382b3":"markdown","7cbb0155":"markdown","d5d14468":"markdown","d7973b62":"markdown","5366f619":"markdown","5e99d346":"markdown","4a1cf058":"markdown","693bf91e":"markdown","15167488":"markdown","14963756":"markdown","2157dc12":"markdown","732017ee":"markdown","e338a6e8":"markdown","516918d1":"markdown","cc888d27":"markdown","ca06604f":"markdown","b35f86fe":"markdown","ba11795f":"markdown","56e6758c":"markdown","75828449":"markdown"},"source":{"17a5b409":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3eb232ca":"survey_data = pd.read_csv('..\/input\/bank_customer_survey.csv')","9ce8ce5c":"#Sample of dataset\nsurvey_data.head()","8c4f5dba":"#Listing column names in the dataset\nsurvey_data.columns","71d59aef":"#number of rows in the dataset\nsurvey_data.count()[0]","df2f105b":"#Check if there are any missing values\nsurvey_data.isnull().sum()","9a7039a3":"survey_data.describe()","cf67f722":"survey_data[['job', 'y']].groupby(\"job\").mean().reset_index()","c281586e":"some_data = survey_data[['job', 'y']].groupby(\"job\").mean().reset_index().sort_values(\"y\", ascending=False)\nsns.barplot(y = \"job\", x = 'y',data = some_data)","9cf7f151":"some_data = survey_data[['marital', 'y']].groupby(\"marital\").mean().reset_index().sort_values(\"y\", ascending=False)\nsns.barplot(y = \"marital\", x = 'y',data = some_data)","ce0e4e0c":"fig, axes = plt.subplots(1,1, figsize = (15,5))\nsns.countplot(x = survey_data['education'], hue = survey_data[\"y\"])","f304b627":"some_data = survey_data[['education', 'y']].groupby(\"education\").mean().reset_index().sort_values(\"y\", ascending=False)\nsns.barplot(y = \"education\", x = 'y',data = some_data)","61b6de26":"fig, axes = plt.subplots(1,1, figsize = (15,5))\nsns.countplot(x = survey_data['default'], hue = survey_data[\"y\"])","c9529f7e":"some_data = survey_data[['default', 'y']].groupby(\"default\").mean().reset_index().sort_values(\"y\", ascending=False)\nsns.barplot(y = \"default\", x = 'y',data = some_data)","386c0f53":"some_data = survey_data[['housing', 'y']].groupby(\"housing\").mean().reset_index().sort_values(\"y\", ascending=False)\nsns.barplot(y = \"housing\", x = 'y',data = some_data)","777d4a49":"some_data = survey_data[['loan', 'y']].groupby(\"loan\").mean().reset_index().sort_values(\"y\", ascending=False)\nsns.barplot(y = \"loan\", x = 'y',data = some_data)","37f37cf1":"yes_summary = survey_data.groupby(\"y\")\nyes_summary.mean().reset_index()","61b3f220":"pd.DataFrame(abs(survey_data.corr()['y']).reset_index().sort_values('y',ascending = False))","9074db21":"# Compute the correlation matrix\ncorr = survey_data.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 15))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .5})","fe483452":"survey_data['education'].value_counts()","4d11d05b":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor col in survey_data.columns:\n    if(survey_data[col].dtype == 'object'):\n        survey_data.loc[:,col] = le.fit_transform(survey_data.loc[:,col])","650046dd":"survey_data.head()","6f10874d":"X = survey_data.iloc[:,:-1].values\ny = survey_data.iloc[:,-1].values","b68403a4":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","923dcbb2":"from sklearn import model_selection\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nseed = 7\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\ncart = DecisionTreeClassifier()\nnum_trees = 100\nmodel = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed, n_jobs=-1)\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\nprint(results.mean())","83d53ede":"from sklearn.ensemble import RandomForestClassifier\nseed = 7\nnum_trees = 100\nmax_features = 3\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\nmodel = RandomForestClassifier(n_estimators=num_trees, max_features=max_features, n_jobs=-1)\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\nprint(results.mean())","032ae5f7":"from sklearn.ensemble import ExtraTreesClassifier\nseed = 7\nnum_trees = 100\nmax_features = 7\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\nmodel = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features, n_jobs=-1)\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\nprint(results.mean())","b69ca1b1":"from sklearn.ensemble import AdaBoostClassifier\nseed = 7\nnum_trees = 30\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\nmodel = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\nresults = model_selection.cross_val_score(model, X, y, cv=kfold, n_jobs=-1)\nprint(results.mean())","648c6436":"from sklearn.ensemble import GradientBoostingClassifier\nseed = 7\nnum_trees = 100\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\nmodel = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\nprint(results.mean())","fc5b95c3":"from xgboost import XGBClassifier\nseed = 7\nnum_trees = 100\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\nmodel = XGBClassifier(n_estimators=num_trees, random_state=seed)\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\nprint(results.mean())","5c5bb876":"from catboost import CatBoostClassifier\ncategorical_features_indices = [1, 2, 3, 4, 6, 7, 8, 9, 10, 15]\nmodel=CatBoostClassifier(iterations=50, depth=10, learning_rate=0.1, loss_function='Logloss')\nmodel.fit(x_train, y_train,cat_features=categorical_features_indices,eval_set=(x_test, y_test),plot=True)\n\nprint(model.get_best_score())\n","fc02ce64":"# from sklearn.linear_model import LogisticRegression\n# from sklearn.tree import DecisionTreeClassifier\n# from sklearn.svm import SVC\n# from sklearn.ensemble import VotingClassifier\n# seed = 7\n# kfold = model_selection.KFold(n_splits=10, random_state=seed)\n# # create the sub models\n# estimators = []\n# model1 = LogisticRegression()\n# estimators.append(('logistic', model1))\n# model2 = DecisionTreeClassifier()\n# estimators.append(('cart', model2))\n# model3 = SVC()\n# estimators.append(('svm', model3))\n# # create the ensemble model\n# ensemble = VotingClassifier(estimators)\n# results = model_selection.cross_val_score(ensemble, X, y, cv=kfold, n)\n# print(results.mean())","bb8581aa":"# Classification","661382b3":"## To be continued","7cbb0155":"## Extra Tree Classifier","d5d14468":"# Dataset Overview","d7973b62":"Looks like students have the highest mean of all followed by retired","5366f619":"### Corelation of all other features with the outcome","5e99d346":"# Boosting models","4a1cf058":"# Import python libraries and dataset","693bf91e":"Duration is the most corelated feature with y","15167488":"The above graph shows close score for tertiary and unkown, hence its okay to consider the unknown as tertiary.","14963756":"## Statistical overview","2157dc12":"## XGBoost","732017ee":"## Catboost","e338a6e8":"## Detailed information about featuresin dataset\n\n## Customer information\n1. **age :** (numeric)\n2. **job :** type of job (categorical: \"admin.\",\"blue-collar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\",\"unknown\")\n3. **marital :** marital status (categorical: \"divorced\",\"married\",\"single\",\"unknown\"; note: \"divorced\" means divorced or widowed)\n4. **education :** (categorical: \"primary\",\"secondary\",\"tertiary\",\"unknown\")\n5. **default :** has credit in default? (categorical: \"no\",\"yes\",\"unknown\")\n6. **balance :** in eur\n7. **housing :** has housing loan? (categorical: \"no\",\"yes\",\"unknown\")\n8. **loan :** has personal loan? (categorical: \"no\",\"yes\",\"unknown\")\n\n## related with the last contact of the current campaign:\n9. **contact :** contact communication type (categorical: \"cellular\",\"telephone\") \n10. **month :** last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n11. **day_of_week :** last contact day of the week (categorical: \"mon\",\"tue\",\"wed\",\"thu\",\"fri\")\n12. **duration :** last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n\n## other attributes:\n13. **campaign:** number of contacts performed during this campaign and for this client (numeric, includes last contact)\n14. **pdays :** number of days that passed by after the client was last contacted from a previous campaign (numeric; -1 means client was not previously contacted)\n15. **previous :** number of contacts performed before this campaign and for this client (numeric)\n16. **poutcome :** outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")\n17. **y :** Whether or not the customer has term deposit ","516918d1":"## Random forest classifier","cc888d27":"## Random forest classifier","ca06604f":"## Bagging Classifier","b35f86fe":"## adaboost","ba11795f":"## Stochastic Gradient Boosting","56e6758c":"## Dealing with categorical data\nThere are no missing values in the data.\nMost of the features are categorical in nature ex, type of job, education, marital status.\nSome fields are binary, containing yes or no.\nWe need to somehow categorise the \"unknown\" values to any category. ","75828449":"Observations:\n* Average balance of subscribers for term deposit is more than non subscribers\n* Average duration of call is also more more those with y = 1\n* Average number of days passed since last contact(pdays) is also high for those with y = 1."}}