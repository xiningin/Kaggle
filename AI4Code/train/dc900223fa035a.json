{"cell_type":{"23e293ed":"code","cbe3c9f4":"code","94ed78cc":"code","012e6e59":"code","6fb0e7d1":"code","8bd363e4":"code","f76b2ba1":"code","28b4399a":"code","a17a33c9":"code","57627949":"code","41d0c14a":"code","389ead10":"code","500630ef":"code","7dbd6b35":"code","ce9f6100":"code","4722bef7":"code","c62d1b76":"markdown","28485dd4":"markdown","7e6e9dc0":"markdown","8e6a59cf":"markdown","e3096d8f":"markdown","38f052b2":"markdown","0b2ea093":"markdown","f3a669a9":"markdown","ac14fb01":"markdown"},"source":{"23e293ed":"## imports \nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import classification_report, roc_auc_score, plot_roc_curve\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom hyperopt import Trials, fmin, tpe, hp, STATUS_OK,STATUS_FAIL\n\nfrom catboost import CatBoostClassifier\ndata = pd.read_csv(\"\/kaggle\/input\/telecom-users-dataset\/telecom_users.csv\")\n\n","cbe3c9f4":"data.head()\ndata.drop(['Unnamed: 0','customerID'],axis=1,inplace=True)","94ed78cc":"data.describe()","012e6e59":"cat_cols = list(set(data.columns.tolist()) - set(['tenure','MonthlyCharges','TotalCharges']))\nlen(cat_cols)","6fb0e7d1":"## defining number of rows\nrows = len(cat_cols)\/\/3 + 1\nfig,axes = plt.subplots(ncols=3,nrows=rows, figsize=(25,30))\nrow = 0\nfor index,col_name in enumerate(cat_cols):\n    if index!=0 and index%3 == 0:\n        row+=1\n    ax = sns.countplot(x=col_name,hue='Churn',data=data,ax = axes[row][index % 3])\n    ax.set(title= \"Count of \" + col_name + \" column\")\n    \n    \n    \n    ","8bd363e4":"cat_cols_to_keep = []\nfor i in cat_cols:\n    ord_enc = OrdinalEncoder()\n    data[i + \"_code\"] = ord_enc.fit_transform(data[[i]])\n    cat_cols_to_keep.append(i + \"_code\")","f76b2ba1":"data.head()","28b4399a":"## filtering for required columns and converting total charges to float. \ndata_filtered = data[cat_cols_to_keep]\n\ndata_filtered = data_filtered.astype(int)\ndata_filtered[['tenure','MonthlyCharges','TotalCharges']] = data[['tenure','MonthlyCharges','TotalCharges']]\n\n\ndef convert_x(x):\n    try:\n        return float(x)\n    except:\n        return np.NaN\ndata_filtered['TotalCharges'] = data_filtered['TotalCharges'].apply(convert_x)\ndata_filtered = data_filtered.dropna(subset=['TotalCharges'])\ncat_cols_to_keep.remove('Churn_code')","a17a33c9":"## separating target and features\ntarget = data_filtered['Churn_code']\ndata_filtered.drop('Churn_code',axis=1,inplace=True)\n\n## train test split \nX_train,X_test,y_train,y_test = train_test_split(data_filtered,target,test_size=0.2,random_state=42)","57627949":"## objective function - takes parameters selected, uses cross_val_score with defaults to return the loss.\ndef objective_function(params):\n    clf = CatBoostClassifier(iterations = int(params['iterations']), cat_features = cat_cols_to_keep, \n                            verbose = 0, learning_rate = params['learning_rate'], loss_function = 'CrossEntropy',\n                            random_seed = 42, max_depth = int(params['max_depth']))\n    loss = 1 - cross_val_score(clf, X_train,y_train, scoring='roc_auc').mean()\n    return {'loss': loss, 'status':STATUS_OK,'clf':clf}","41d0c14a":"## search space - since it is a small dataset, i am only tuning iterations, learning rate and max_depth of the tree.\nsearch_space =   { \n                    'iterations': hp.uniform('iterations', 300, 1000),\n                    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n                    'max_depth' : hp.uniform('max_depth',3,10)\n                 }","389ead10":"trials = Trials()\nbest = fmin(objective_function,search_space,trials=trials,algo=tpe.suggest,max_evals=20)\n\nbest_clf = trials.best_trial['result']['clf']\nbest_clf.fit(X_train,y_train)\npreds = best_clf.predict_proba(X_test)","500630ef":"roc_auc_score(y_test,preds[:,1])","7dbd6b35":"ax = plt.figure(figsize=(10,10)).gca()\nplot_roc_curve(best_clf,X_test,y_test,ax=ax)","ce9f6100":"labelled_preds = best_clf.predict(X_test)\nprint(str(classification_report(y_test,labelled_preds)))","4722bef7":"y = best_clf.feature_importances_\nx = {ky:y[index] for index,ky in enumerate(X_train.columns.tolist())}\n\n\nx_v = []\ny_v = []\nsorted_values = sorted(x.items(), key = lambda y : y[1], reverse=True)\nfor i,j in sorted_values:\n    x_v.append(i)\n    y_v.append(j)\n\nplt.figure(figsize=(30,10))\nax = sns.barplot(x=x_v,y=y_v,palette = 'Blues_r')\nax.set(xlabel='feature',ylabel='score',title = 'Feature Importances')\nax.set_xticklabels(labels = x_v,rotation=45, ha='right')","c62d1b76":"To optimise, we will use a library called hyperopt, which automatically selects the next best parameters to evaluate the model on. We just need to pass a range of values for which to constrict the paramters on. \nThere are three things required - \n* Objective Function - The function used by hyperopt internal algorithm to evaluate the model on. The objective function is always minimised, hence we need to return **1 - cross_val_score**, which will inturn maximise, cross_val_score.\n* **Algorithm** - TPE - Tree parzen estimator. Read on the research article for more information.\n* **Search space** to pick the parameters from. \n","28485dd4":"I am using **catboost** because almost all the columns are categorical and it handles these categorical columns very well.","7e6e9dc0":"## EDA\n* Since, most of the columns are categorical in nature, it does not make sense to plot histograms.\n* Below, is a plot where every counts of every categorical column is displayed, w.r.t churn column.","8e6a59cf":" **If you like the notebook, don't forget to upvote.**","e3096d8f":"#### Feature Engineering - \n* Converting total charges to float and removing nulls.","38f052b2":"#### Encoding all cateogorical values to ordinals.","0b2ea093":"#### Model","f3a669a9":"* Looks like contract node and tenure are the two most contributing factors to churn prediction.\n* Adding more paramters to tune and increasing the number of evaluations for hyperopt can help.\n\nFeel free, to use this as a started notebook and improve the AUC further.","ac14fb01":"### Observations \n* People with month-to-month contract display a higher chance of leaving.\n* Same with people, with no device protection.\n"}}