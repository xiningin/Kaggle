{"cell_type":{"452e23fc":"code","cb6dd868":"code","93ba00ed":"code","bdc1af79":"code","0a0c8f5d":"code","d301b9bd":"code","67d620f4":"code","383ae313":"code","dea97413":"code","814ac431":"code","d7e337ac":"code","5364c8c0":"code","f4558522":"code","4ccf796d":"code","c53ebe7f":"code","38b6f152":"code","4c30e84e":"code","1bf6e4f3":"code","2c35b0ef":"code","41fd2d22":"code","6cbaf118":"code","299b7018":"code","06e192f0":"markdown","c657a6ef":"markdown","97269acb":"markdown","f3d3e783":"markdown","ad594f9b":"markdown","6e2f6b31":"markdown","a09f6eeb":"markdown","d1f44b03":"markdown","8871a655":"markdown","2e633697":"markdown","9e7cab98":"markdown","7c033711":"markdown","08147b24":"markdown","867a2cc6":"markdown","8e8e1de7":"markdown","1ba67acf":"markdown"},"source":{"452e23fc":"import os\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","cb6dd868":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Flatten,BatchNormalization,MaxPooling2D,Activation\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import layers \n","93ba00ed":"train_dir = '..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/'","bdc1af79":"parasitized_data = os.listdir('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/')\n#print(parasitized_data[:10])","0a0c8f5d":"uninfected_data = os.listdir('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected')\n#print(uninfected_data[:10])","d301b9bd":"plt.figure(figsize = (12,12))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    img = cv2.imread('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/' + \"\/\" + parasitized_data[i])\n    plt.imshow(img)\n    plt.title('PARASITIZED : 1')\n    plt.tight_layout()\nplt.show()\n","67d620f4":"plt.figure(figsize = (12,12))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    img = cv2.imread('..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected' + \"\/\" + uninfected_data[i+1])\n    plt.imshow(img)\n    plt.title('UNINFECTED : 0')\n    plt.tight_layout()\nplt.show()","383ae313":"BATCH_SIZE = 100\nIMG_SHAPE = 224","dea97413":"data_gen = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)\ntrain_data_gen = data_gen.flow_from_directory(batch_size=BATCH_SIZE,\n                                              directory=train_dir,\n                                              shuffle = True,\n                                              target_size = (IMG_SHAPE, IMG_SHAPE),\n                                              subset='training')\nvalid_data_gen = data_gen.flow_from_directory(batch_size=BATCH_SIZE,\n                                              directory=train_dir,\n                                              shuffle = True,\n                                              target_size = (IMG_SHAPE, IMG_SHAPE),\n                                              subset='validation')","814ac431":"train_data_gen.class_indices","d7e337ac":"from tensorflow.keras.applications.vgg16 import VGG16\nbase_model = VGG16(input_shape=(IMG_SHAPE, IMG_SHAPE, 3),\n                  include_top = False,\n                  weights = 'imagenet')","5364c8c0":"for layer in base_model.layers:\n    layer.trainable = False","f4558522":"x = layers.Flatten()(base_model.output)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(2, activation='sigmoid')(x)\n\n","4ccf796d":"model = tf.keras.models.Model(base_model.input, x)","c53ebe7f":"model.compile(optimizer = 'adam' , loss = 'binary_crossentropy', metrics = ['accuracy'])","38b6f152":"model.summary()","4c30e84e":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\nhis = model.fit(train_data_gen, validation_data= valid_data_gen, steps_per_epoch = BATCH_SIZE, epochs = 5, callbacks=callback)","1bf6e4f3":"fig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.set_facecolor('w')\nax.grid(b=True)\nax.plot(his.history['accuracy'], color='red')\nax.plot(his.history['val_accuracy'], color ='green')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()\n\n\nfig = plt.figure(figsize=(10,7))\nax = fig.add_subplot(111)\nax.set_facecolor('w')\nax.grid(b=True)\nax.plot(his.history['loss'], color='red')\nax.plot(his.history['val_loss'], color ='green')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()\n","2c35b0ef":"model.save('my_model.h5')\n","41fd2d22":"test_image = r\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized\/C100P61ThinF_IMG_20150918_144104_cell_163.png\"","6cbaf118":"from keras.preprocessing import image\ndef load(filename):\n    img = cv2.imread(filename)\n    plt.imshow(img)\n    img = image.load_img(test_image, target_size = (IMG_SHAPE, IMG_SHAPE))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis = 0)\n    index = model.predict(img)\n    index = index.argmax().item()\n    if index == 0:\n        return \"Parasitic\"\n    elif img == 1:\n        return \"Non-Parasitic\"\n    else :\n        return\n    \nimage = load(test_image)\nprint(image)\n#model.predict(image)","299b7018":"#### if you like this notebook, please upvote, it motivates me a lot!\n#### if you have any suggestion to improve this notebook please comment! ","06e192f0":"# Malaria Skin Classification using Transfer Learning","c657a6ef":"## Training","97269acb":"## Data Loading","f3d3e783":"So, Here we are not including top layer as it gives 1000 outputs. We are doing binary classification. So we will include our Fully connected layer which contains only 2 output.","ad594f9b":"Our model is performing well.","6e2f6b31":"### Freezing the layers","a09f6eeb":"![image.png](attachment:1cf3b043-dbe2-4dd7-89ba-d422b097c8cd.png)","d1f44b03":"![image.png](attachment:3898146c-e3e6-4694-8e8c-fccd34bb61ae.png)","8871a655":"## Creating Model","2e633697":"## Prediction\nTesting with our own Image","9e7cab98":"## Data Processing","7c033711":"## Imports","08147b24":"## Tranfer Learning\nTransfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem.\nTransfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n\nThe most common incarnation of transfer learning in the context of deep learning is the following workflow:\n1. Take layers from a previously trained model.\n2. Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n3. Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n4. Train the new layers on your dataset.","867a2cc6":"## Model Performance","8e8e1de7":"VGG16 is a pre-trained model that takes in (224,224) RGB images and converts them into features.The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. ImageNet is a dataset of over 15 million labeled high-resolution images belonging to roughly 22,000 categories. The images were collected from the web and labeled by human labelers using Amazon\u2019s Mechanical Turk crowd-sourcing tool.","1ba67acf":"## Model Achitecture of VGG16"}}