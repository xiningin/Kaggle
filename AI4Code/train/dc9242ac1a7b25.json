{"cell_type":{"56b5f66a":"code","b471aa1b":"code","a53bce88":"code","d30f0261":"code","138b5dad":"code","2dba9602":"code","d1417386":"code","1ed00652":"code","85c81f99":"code","d34eff74":"code","33c6918a":"code","c46ff7ce":"code","6bab975d":"code","341e53ea":"code","6a34b801":"markdown","355ca43c":"markdown","b4aaaf3b":"markdown","1bd6b4d3":"markdown","87f6ff10":"markdown","2380bb3f":"markdown","61a7c3b8":"markdown","e3953b0e":"markdown","0ce56966":"markdown","4a30cee2":"markdown","d1c1ad44":"markdown","7319797c":"markdown","0ca077ea":"markdown","808dfdfc":"markdown","4f10ad03":"markdown","f17f02f7":"markdown"},"source":{"56b5f66a":"import numpy as np\nimport string\nimport matplotlib.pyplot as plt","b471aa1b":"data = \"\"\"\nTo be, or not to be, that is the question:\nWhether 'tis nobler in the mind to suffer\nThe slings and arrows of outrageous fortune,\nOr to take arms against a sea of troubles\nAnd by opposing end them. To die\u2014to sleep,\nNo more; and by a sleep to say we end\nThe heart-ache and the thousand natural shocks\nThat flesh is heir to: 'tis a consummation\nDevoutly to be wish'd. To die, to sleep;\nTo sleep, perchance to dream\u2014ay, there's the rub:\nFor in that sleep of death what dreams may come,\nWhen we have shuffled off this mortal coil,\nMust give us pause\u2014there's the respect\nThat makes calamity of so long life.\nFor who would bear the whips and scorns of time,\nTh'oppressor's wrong, the proud man's contumely,\nThe pangs of dispriz'd love, the law's delay,\nThe insolence of office, and the spurns\nThat patient merit of th'unworthy takes,\nWhen he himself might his quietus make\n\"\"\"","a53bce88":"# remove \\n\ndata = data.replace(\"\\n\", \" \")\n\n# lower cases\ndata = data.lower()\n\n# remove punctuation\ndata = data.translate(str.maketrans('', '', string.punctuation))\n\n# remove first and last character\ndata = data[1:-1]","d30f0261":"data","138b5dad":"chars = sorted(set(data))\n\nchar_to_idx = {c:i for (i,c) in enumerate(chars)}\nidx_to_char = {i:c for (i,c) in enumerate(chars)}","2dba9602":"data_size, char_size = len(data), len(chars)\n\nhidden_size = 10\nweight_sd = 0.1\nz_size = hidden_size + char_size\nt_steps = 25","d1417386":"def sigmoid(x):\n    return 1 \/ (1 + np.exp(-x))\n\ndef dsigmoid(y):\n    return y * (1 - y)\n\ndef tanh(x):\n    return np.tanh(x)\n\ndef dtanh(y):\n    return 1 - y * y","1ed00652":"def forward(x, u, q):\n    z = np.row_stack((q, x))\n\n    a = sigmoid(np.dot(wa, z) + ba)\n    b = sigmoid(np.dot(wb, z) + bb)\n    c = tanh(np.dot(wc, z) + bc)\n    d = sigmoid(np.dot(wd, z) + bd)\n\n    e = a * u + b * c\n    h = d * tanh(e)\n\n    v = np.dot(wv, h) + bv\n    y = np.exp(v) \/ np.sum(np.exp(v))\n\n    return z, a, b, c, d, e, h, v, y","85c81f99":"def optimize(grads, theta, lr=0.05):\n    dwa, dwb, dwc, dwd, dwv, dba, dbb, dbc, dbd, dbv = grads\n    wa, wb, wc, wd, wv, ba, bb, bc, bd, bv = theta\n    \n    wa -= dwa * lr\n    wb -= dwb * lr\n    wc -= dwc * lr\n    wd -= dwd * lr\n    wv -= dwv * lr\n    \n    ba -= dba * lr\n    bb -= dbb * lr\n    bc -= dbc * lr\n    bd -= dbd * lr\n    bv -= dbv * lr\n    \n    return wa, wb, wc, wd, wv, ba, bb, bc, bd, bv","d34eff74":"losses = {}\nz, a, b, c, d, e, h, v, y = {}, {}, {}, {}, {}, {}, {}, {}, {}\nq, x, u = {}, {}, {}","33c6918a":"wa, wb, wc, wd = [np.random.randn(hidden_size, z_size) * weight_sd + 0.5 for x in range(4)]\nba, bb, bc, bd = [np.zeros((hidden_size, 1)) for x in range(4)]\n\n# output\nwv = np.random.randn(char_size, hidden_size) * weight_sd\nbv = np.zeros((char_size, 1))","c46ff7ce":"q[-1] = np.zeros((hidden_size, 1))\nu[-1] = np.zeros((hidden_size, 1))\n\npointer = 25\nt_steps = 25\n\ninputs = ([char_to_idx[ch] for ch in data[pointer: pointer + t_steps]])\ntargets = ([char_to_idx[ch] for ch in data[pointer + 1: pointer + t_steps + 1]])","6bab975d":"for epoch in range(1000):\n    \n    loss = 0\n    \n    # Forward propagation\n    for t in range(len(inputs)):\n        x[t] = np.zeros((char_size, 1))\n        x[t][inputs[t]] = 1\n\n        z[t], a[t], b[t], c[t], d[t], e[t], h[t], v[t], y[t] = forward(x[t], u[t - 1], q[t - 1])\n\n        u[t], q[t] = e[t], h[t]\n\n        loss += -np.log(y[t][targets[t], 0])\n\n\n    dh_next = np.zeros_like(q[0])\n    de_next = np.zeros_like(u[0])\n    dwa, dwb, dwc, dwd, dwv, dba, dbb, dbc, dbd, dbv = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n\n    # Backward propagation\n    for t in reversed(range(len(inputs))):\n        target = targets[t]\n\n        dv = np.copy(y[t])\n        dv[target] -= 1\n\n        dwv += np.dot(dv, h[t].T)\n        dbv += dv\n\n        dh = np.dot(wv.T, dv)\n        dh += dh_next\n\n        dd = dh * tanh(e[t])\n        dd = dsigmoid(d[t]) * dd\n\n        dwd += np.dot(dd, z[t].T)\n        dbd += dd\n\n        de = np.copy(de_next)\n        de += dh * d[t] * dtanh(tanh(e[t]))\n\n        dc = de * b[t]\n        dc = dtanh(c[t]) * dc\n\n        dwc += np.dot(dc, z[t].T)\n        dbc += dc\n\n        db = de * dc\n        db = dsigmoid(b[t]) * db\n\n        dwb += np.dot(db, z[t].T)\n        dbb += db\n\n        da = de * u[t - 1]\n        da = dsigmoid(a[t]) * da\n\n        dwa += np.dot(da, z[t].T)\n        dba += da\n\n        dz = (np.dot(wa.T, da) \n              + np.dot(wb.T, db) \n              + np.dot(wc.T, dc) \n              + np.dot(dd.T, dd))\n\n        dh_next = dz[:hidden_size, :]\n        de_next = a[t] * de\n\n    \n    grads = dwa, dwb, dwc, dwd, dwv, dba, dbb, dbc, dbd, dbv\n    theta = wa, wb, wc, wd, wv, ba, bb, bc, bd, bv\n\n    # optimize with SGD the training data\n    wa, wb, wc, wd, wv, ba, bb, bc, bd, bv = optimize(grads, theta)\n        \n    losses[epoch] = loss","341e53ea":"plt.plot(list(losses.keys()), [losses[x] for x in list(losses.keys())])","6a34b801":"<h2>Forked from Alin Cijov<\/h2>","355ca43c":"Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems.<br>\n<br>\nThis is a behavior required in complex problem domains like machine translation, speech recognition, and more.<br>\n<br>\nLSTMs are a complex area of deep learning. It can be hard to get your hands around what LSTMs are, and how terms like bidirectional and sequence-to-sequence relate to the field.","b4aaaf3b":"### LSTM implementation","1bd6b4d3":"If you liked this implementation, don't forget to up-vote :)\n\nP.S: The architecture of LSTM is drawn by me, a little Picasso.","87f6ff10":"![LSTM.png](attachment:LSTM.png)","2380bb3f":"### Plotting the graph","61a7c3b8":"### Data preparation","e3953b0e":"### Training","0ce56966":"### Creating the data","4a30cee2":"### Activations functions","d1c1ad44":"### Prepare dictionaries","7319797c":"### LSTM architecture","0ca077ea":"### Definition of LSTM","808dfdfc":"### Initialize the variables","4f10ad03":"### Importing libraries","f17f02f7":"### Prepare the parameters"}}