{"cell_type":{"04be1d9f":"code","76e86eeb":"code","a9c485f2":"code","645ffcd9":"code","840f743d":"code","208d9efd":"code","c0fe36e8":"code","992d228e":"code","d5a0e22f":"code","49d1cd11":"code","3876b1e0":"code","c853c32c":"code","4adf87c8":"code","c102ecfd":"code","83bd62af":"code","21ee307c":"code","0e7a749c":"code","c2bca902":"code","3c1d0c6e":"code","ab926b09":"code","8f356584":"code","05642680":"code","836fa222":"code","255aa88f":"code","bcdff383":"markdown","7d2d9be6":"markdown","59e66e44":"markdown","b8ac1600":"markdown","a99c0af6":"markdown","580fffa1":"markdown","ff0a3b69":"markdown","5124026c":"markdown","a2bca354":"markdown","54db5aed":"markdown","997cad40":"markdown","c8967173":"markdown","1ca8c0df":"markdown","22c28330":"markdown","ccba17df":"markdown","931dc8bf":"markdown"},"source":{"04be1d9f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76e86eeb":"# Vital imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings # To ignore warnings\nimport sweetviz as sw # Exploratory library","a9c485f2":"# Adding Global options for pandas o\/p and warnings\nwarnings.filterwarnings(\"ignore\") # To ignore warnings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)","645ffcd9":"# This will provide the pandas dataframe\nhousing_df = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nhousing_df = housing_df.drop(['Id', 'MiscFeature'], axis=1)\nhousing_df_y = housing_df['SalePrice']\nhousing_df_x = housing_df.drop(['SalePrice'], axis=1)\nhousing_df.head()","840f743d":"# Constructing sweetviz report\nreport = sw.analyze(housing_df)\nreport.show_html('housing_report.html')","208d9efd":"# Total missing values \npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nhousing_df_x.isnull().sum()","c0fe36e8":"housing_df_x.describe()","992d228e":"# Methods for immupting\n\n# LotFrontage has missing values and they are filled with mean\ndef imputeLotFrontage(df):\n    df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())\n\n\n# Alley missing values means no alley. So, populate NA with NoAly\ndef imputeAlley(df):\n    df['Alley'] = df['Alley'].fillna('NoAly')\n    \n\n# There are 8 missing values for Masonyr Venner type and Area so let's fill them with None and 0. Then replace None with\n# \"NoVenner\" to avoid issues with None datatype\ndef impureVnrTypeArea(df):\n    df['MasVnrType'] = df['MasVnrType'].fillna('None')\n    df['MasVnrArea'] = df['MasVnrArea'].fillna(0)\n    # Replace code --> Replace None with NoVenner in MasVnrType\n    df['MasVnrType'] = np.where((df.MasVnrType == 'None'),'NoVenner',df.MasVnrType)\n    \n# Make NA items in basement quality, condition, exposure, finished type1, finished type 2 with \"NoBsmt\"\ndef imputeBsmtQCEFT(df):\n    df['BsmtQual'] = df['BsmtQual'].fillna('NoBsmt')\n    df['BsmtCond'] = df['BsmtCond'].fillna('NoBsmt')\n    df['BsmtExposure'] = df['BsmtExposure'].fillna('NoBsmt')\n    df['BsmtFinType1'] = df['BsmtFinType1'].fillna('NoBsmt')\n    df['BsmtFinType2'] = df['BsmtFinType2'].fillna('NoBsmt')\n\n\n# Make NA in Electrical to most frequent \"SBrkr\"\ndef imputeElectrical(df):\n    df['Electrical'] = df['Electrical'].fillna('SBrkr')\n\n    \n# Make NA in FireplaceQu to \"NoFP\"\ndef imputeFireplaceQuality(df):\n    df['FireplaceQu'] = df['FireplaceQu'].fillna('NoFP')\n    \n    \n# Make NA in Garage type, year, Finish, quality, condition to \"NoGar\", \"2000\", \"NoGar\", \"NoGar\", \"NoGar\" respectively\ndef imputeGarageDetails(df):\n    df['GarageType'] = df['GarageType'].fillna('NoGar')\n    df['GarageYrBlt'] = df['GarageYrBlt'].fillna(2000)\n    df['GarageFinish'] = df['GarageFinish'].fillna('NoGar')\n    df['GarageQual'] = df['GarageQual'].fillna('NoGar')\n    df['GarageCond'] = df['GarageCond'].fillna('NoGar')\n    \n    \n# Make NA for Pool quality to \"NoPool\", Fence to \"NoFence\"\ndef imputePoolFence(df):\n    df['PoolQC'] = df['PoolQC'].fillna('NoPool')\n    df['Fence'] = df['Fence'].fillna('NoFence')","d5a0e22f":"# handy method to trigger various impute methods to make test and train implementation quick\n\n\ndef aggregateImputeMethodTrigger(df):\n    # Filling LotFrontage missing values with \n    imputeLotFrontage(df)\n\n    # Making NA in Alley to NoAly to make better representation\n    imputeAlley(df)\n\n    # Make NA to None and 0 in Masonyr Venner type and Area\n    impureVnrTypeArea(df)\n\n    # Make NA items in basement quality, condition, exposure, finished type1, finished type 2 with \"NoBsmt\"\n    imputeBsmtQCEFT(df)\n\n\n    # Make NA in Electrical to most frequent \"SBrkr\"\n    imputeElectrical(df)\n\n    # Make NA in FireplaceQu to \"NoFP\"\n    imputeFireplaceQuality(df)\n\n    # Make NA in Garage type, year, Finish to \"NoGar\", \"2000\", \"NoGar\" respectively\n    imputeGarageDetails(df)\n\n    # Make NA for Pool quality to \"NoPool\", Fence to \"NoFence\"\n    imputePoolFence(df)","49d1cd11":"# Initiating imputing process for train data frame\naggregateImputeMethodTrigger(housing_df_x)","3876b1e0":"# Revalidating whether missing values still exists or not\nhousing_df_x.isnull().sum()","c853c32c":"# Handling the categorical columns that can be represented in numbers\n\n# Handling street Rep\ndef handlingStreet(df):\n    df['Street'] = np.where((df.Street == 'Pave'), 1, df.Street)\n    df['Street'] = np.where((df.Street == 'Grvl'), 0, df.Street)  \n    df['Street'] = pd.to_numeric(df['Street'])\n\n#   handling Alley Rep\ndef handlingAlley(df):\n    df['Alley'] = np.where((df.Alley == 'NoAly'), 0, df.Alley)\n    df['Alley'] = np.where((df.Alley == 'Grvl'), 1, df.Alley)\n    df['Alley'] = np.where((df.Alley == 'Pave'), 2, df.Alley)\n    df['Alley'] = pd.to_numeric(df['Alley'])\n\n# Handling Lot Shape reg to irreg start with 1 because it's no yes or no\ndef handlingLotShape(df):\n    df['LotShape'] = np.where((df.LotShape == 'Reg'), 1, df.LotShape)\n    df['LotShape'] = np.where((df.LotShape == 'IR1'), 2, df.LotShape)\n    df['LotShape'] = np.where((df.LotShape == 'IR2'), 3, df.LotShape)\n    df['LotShape'] = np.where((df.LotShape == 'IR3'), 4, df.LotShape)\n    df['LotShape'] = pd.to_numeric(df['LotShape'])\n    \n# Handling Utilities least to most\ndef handlingUtilities(df):\n    df['Utilities'] = np.where((df.Utilities == 'ELO'), 1, df.Utilities)\n    df['Utilities'] = np.where((df.Utilities == 'NoSeWa'), 2, df.Utilities)\n    df['Utilities'] = np.where((df.Utilities == 'NoSewr'), 3, df.Utilities)\n    df['Utilities'] = np.where((df.Utilities == 'AllPub'), 4, df.Utilities)\n    df['Utilities'] = pd.to_numeric(df['Utilities'])\n\n# Handling LandSlope least to most\ndef handlingLandSlope(df):\n    df['LandSlope'] = np.where((df.LandSlope == 'Gtl'), 1, df.LandSlope)\n    df['LandSlope'] = np.where((df.LandSlope == 'Mod'), 2, df.LandSlope)\n    df['LandSlope'] = np.where((df.LandSlope == 'Sev'), 3, df.LandSlope)\n    df['LandSlope'] = pd.to_numeric(df['LandSlope'])\n\n\n# In order to best differentiate condition 1 and 2 we will add prefix like c1 and c2\ndef handlingConditions(df):\n    df['Condition1'] = 'c1' + df['Condition1']\n    df['Condition2'] = 'c2' + df['Condition2']\n\n\n# Drop year sold, month sold, convert year build and year remodeled into numbers related to the year sold\ndef handlingYears(df):\n    df['builtYearsSpanned'] = df['YrSold'] - df['YearBuilt']\n    df['remodelYearsSpanned'] = df['YrSold'] - df['YearRemodAdd']\n    df.drop(['YearBuilt', 'YearRemodAdd', 'MoSold'], axis=1, inplace=True)\n\n# In order to best differentiate Exterior 1 and 2 we will add prefix like e1 and e2\ndef handlingExteriors(df):\n    df['Exterior1st'] = 'e1' + df['Exterior1st']\n    df['Exterior2nd'] = 'e2' + df['Exterior2nd']\n\n# Numbering Exterior quality, condition\ndef handlingExteriorQualityCondition(df):\n    # Quality    \n    df['ExterQual'] = np.where((df.ExterQual == 'Po'), 1, df.ExterQual)\n    df['ExterQual'] = np.where((df.ExterQual == 'Fa'), 2, df.ExterQual)\n    df['ExterQual'] = np.where((df.ExterQual == 'TA'), 3, df.ExterQual)\n    df['ExterQual'] = np.where((df.ExterQual == 'Gd'), 4, df.ExterQual)\n    df['ExterQual'] = np.where((df.ExterQual == 'Ex'), 5, df.ExterQual)\n    df['ExterQual'] = pd.to_numeric(df['ExterQual'])\n    \n    \n    # Condition    \n    df['ExterCond'] = np.where((df.ExterCond == 'Po'), 1, df.ExterCond)\n    df['ExterCond'] = np.where((df.ExterCond == 'Fa'), 2, df.ExterCond)\n    df['ExterCond'] = np.where((df.ExterCond == 'TA'), 3, df.ExterCond)\n    df['ExterCond'] = np.where((df.ExterCond == 'Gd'), 4, df.ExterCond)\n    df['ExterCond'] = np.where((df.ExterCond == 'Ex'), 5, df.ExterCond)\n    df['ExterCond'] = pd.to_numeric(df['ExterCond'])\n    \n# handling Basement Columsn\ndef handlingBasement(df):\n     # Quality  \n    df['BsmtQual'] = np.where((df.BsmtQual == 'NoBsmt'), 0, df.BsmtQual)\n    df['BsmtQual'] = np.where((df.BsmtQual == 'Po'), 1, df.BsmtQual)\n    df['BsmtQual'] = np.where((df.BsmtQual == 'Fa'), 2, df.BsmtQual)\n    df['BsmtQual'] = np.where((df.BsmtQual == 'TA'), 3, df.BsmtQual)\n    df['BsmtQual'] = np.where((df.BsmtQual == 'Gd'), 4, df.BsmtQual)\n    df['BsmtQual'] = np.where((df.BsmtQual == 'Ex'), 5, df.BsmtQual)\n    df['BsmtQual'] = pd.to_numeric(df['BsmtQual'])\n    \n    # Condition    \n    df['BsmtCond'] = np.where((df.BsmtCond == 'NoBsmt'), 0, df.BsmtCond)\n    df['BsmtCond'] = np.where((df.BsmtCond == 'Po'), 1, df.BsmtCond)\n    df['BsmtCond'] = np.where((df.BsmtCond == 'Fa'), 2, df.BsmtCond)\n    df['BsmtCond'] = np.where((df.BsmtCond == 'TA'), 3, df.BsmtCond)\n    df['BsmtCond'] = np.where((df.BsmtCond == 'Gd'), 4, df.BsmtCond)\n    df['BsmtCond'] = np.where((df.BsmtCond == 'Ex'), 5, df.BsmtCond)\n    df['BsmtCond'] = pd.to_numeric(df['BsmtCond'])\n    \n    # Exposure\n    df['BsmtExposure'] = np.where((df.BsmtExposure == 'NoBsmt'), -1, df.BsmtExposure)\n    df['BsmtExposure'] = np.where((df.BsmtExposure == 'No'), 0, df.BsmtExposure)\n    df['BsmtExposure'] = np.where((df.BsmtExposure == 'Mn'), 1, df.BsmtExposure)\n    df['BsmtExposure'] = np.where((df.BsmtExposure == 'Av'), 3, df.BsmtExposure)\n    df['BsmtExposure'] = np.where((df.BsmtExposure == 'Gd'), 5, df.BsmtExposure)\n    df['BsmtExposure'] = pd.to_numeric(df['BsmtExposure'])\n    \n    # FinType1\n    df['BsmtFinType1'] = np.where((df.BsmtFinType1 == 'NoBsmt'), -1, df.BsmtFinType1)\n    df['BsmtFinType1'] = np.where((df.BsmtFinType1 == 'Unf'), 0, df.BsmtFinType1)\n    df['BsmtFinType1'] = np.where((df.BsmtFinType1 == 'LwQ'), 1, df.BsmtFinType1)\n    df['BsmtFinType1'] = np.where((df.BsmtFinType1 == 'Rec'), 2, df.BsmtFinType1)\n    df['BsmtFinType1'] = np.where((df.BsmtFinType1 == 'BLQ'), 3, df.BsmtFinType1)\n    df['BsmtFinType1'] = np.where((df.BsmtFinType1 == 'ALQ'), 5, df.BsmtFinType1)\n    df['BsmtFinType1'] = np.where((df.BsmtFinType1 == 'GLQ'), 8, df.BsmtFinType1)\n    df['BsmtFinType1'] = pd.to_numeric(df['BsmtFinType1'])\n    \n    # FinType2\n    df['BsmtFinType2'] = np.where((df.BsmtFinType2 == 'NoBsmt'), -1, df.BsmtFinType2)\n    df['BsmtFinType2'] = np.where((df.BsmtFinType2 == 'Unf'), 0, df.BsmtFinType2)\n    df['BsmtFinType2'] = np.where((df.BsmtFinType2 == 'LwQ'), 1, df.BsmtFinType2)\n    df['BsmtFinType2'] = np.where((df.BsmtFinType2 == 'Rec'), 2, df.BsmtFinType2)\n    df['BsmtFinType2'] = np.where((df.BsmtFinType2 == 'BLQ'), 3, df.BsmtFinType2)\n    df['BsmtFinType2'] = np.where((df.BsmtFinType2 == 'ALQ'), 5, df.BsmtFinType2)\n    df['BsmtFinType2'] = np.where((df.BsmtFinType2 == 'GLQ'), 8, df.BsmtFinType2)\n    df['BsmtFinType2'] = pd.to_numeric(df['BsmtFinType2'])\n\n    \n# Numbering heating Quality & Condition\ndef handlingHeatingQC(df):\n    # Quality & Condition    \n    df['HeatingQC'] = np.where((df.HeatingQC == 'Po'), 1, df.HeatingQC)\n    df['HeatingQC'] = np.where((df.HeatingQC == 'Fa'), 2, df.HeatingQC)\n    df['HeatingQC'] = np.where((df.HeatingQC == 'TA'), 3, df.HeatingQC)\n    df['HeatingQC'] = np.where((df.HeatingQC == 'Gd'), 4, df.HeatingQC)\n    df['HeatingQC'] = np.where((df.HeatingQC == 'Ex'), 5, df.HeatingQC)\n    df['HeatingQC'] = pd.to_numeric(df['HeatingQC'])\n    \n    # Central Air\n    df['CentralAir'] = np.where((df.CentralAir == 'N'), 0, df.CentralAir)\n    df['CentralAir'] = np.where((df.CentralAir == 'Y'), 1, df.CentralAir)\n    df['CentralAir'] = pd.to_numeric(df['CentralAir'])\n    \n    \n# Numbering Kitchen Quality\ndef handlingKitQual(df):\n    # Quality   \n    df['KitchenQual'] = np.where((df.KitchenQual == 'Po'), 1, df.KitchenQual)\n    df['KitchenQual'] = np.where((df.KitchenQual == 'Fa'), 2, df.KitchenQual)\n    df['KitchenQual'] = np.where((df.KitchenQual == 'TA'), 3, df.KitchenQual)\n    df['KitchenQual'] = np.where((df.KitchenQual == 'Gd'), 4, df.KitchenQual)\n    df['KitchenQual'] = np.where((df.KitchenQual == 'Ex'), 5, df.KitchenQual)\n    df['KitchenQual'] = pd.to_numeric(df['KitchenQual'])\n    \n# Number house Functionality\ndef handlingFunctionality(df):\n    df['Functional'] = np.where((df.Functional == 'Sal'), 1, df.Functional)\n    df['Functional'] = np.where((df.Functional == 'Sev'), 2, df.Functional)\n    df['Functional'] = np.where((df.Functional == 'Maj2'), 3, df.Functional)\n    df['Functional'] = np.where((df.Functional == 'Maj1'), 4, df.Functional)\n    df['Functional'] = np.where((df.Functional == 'Mod'), 5, df.Functional)\n    df['Functional'] = np.where((df.Functional == 'Min2'), 6, df.Functional)\n    df['Functional'] = np.where((df.Functional == 'Min1'), 7, df.Functional)\n    df['Functional'] = np.where((df.Functional == 'Typ'), 8, df.Functional)\n    df['Functional'] = pd.to_numeric(df['Functional'])\n    \n\n# Hanling Fireplace Quality\ndef handlingFireplaceQu(df):\n    # Quaity\n    df['FireplaceQu'] = np.where((df.FireplaceQu == 'NoFP'), 0, df.FireplaceQu)\n    df['FireplaceQu'] = np.where((df.FireplaceQu == 'Po'), 1, df.FireplaceQu)\n    df['FireplaceQu'] = np.where((df.FireplaceQu == 'Fa'), 2, df.FireplaceQu)\n    df['FireplaceQu'] = np.where((df.FireplaceQu == 'TA'), 3, df.FireplaceQu)\n    df['FireplaceQu'] = np.where((df.FireplaceQu == 'Gd'), 4, df.FireplaceQu)\n    df['FireplaceQu'] = np.where((df.FireplaceQu == 'Ex'), 5, df.FireplaceQu)\n    df['FireplaceQu'] = pd.to_numeric(df['FireplaceQu'])\n\n    \n# Handling Garage Info\ndef handlingGarage(df):\n    # Year Built as time span\n    df['garageYearsSpanned'] = df['YrSold'] - df['GarageYrBlt']\n    # Drop YrSold and garage Built Year\n    df.drop(['YrSold', 'GarageYrBlt'], axis=1, inplace=True)\n\n    # Garage Interior\n    df['GarageFinish'] = np.where((df.GarageFinish == 'NoGar'), 0, df.GarageFinish)\n    df['GarageFinish'] = np.where((df.GarageFinish == 'Unf'), 1, df.GarageFinish)\n    df['GarageFinish'] = np.where((df.GarageFinish == 'RFn'), 3, df.GarageFinish)\n    df['GarageFinish'] = np.where((df.GarageFinish == 'Fin'), 5, df.GarageFinish)\n    df['GarageFinish'] = pd.to_numeric(df['GarageFinish'])\n    \n    # Garage Quality\n    df['GarageQual'] = np.where((df.GarageQual == 'NoGar'), 0, df.GarageQual)\n    df['GarageQual'] = np.where((df.GarageQual == 'Po'), 1, df.GarageQual)\n    df['GarageQual'] = np.where((df.GarageQual == 'Fa'), 2, df.GarageQual)\n    df['GarageQual'] = np.where((df.GarageQual == 'TA'), 3, df.GarageQual)\n    df['GarageQual'] = np.where((df.GarageQual == 'Gd'), 4, df.GarageQual)\n    df['GarageQual'] = np.where((df.GarageQual == 'Ex'), 5, df.GarageQual)\n    df['GarageQual'] = pd.to_numeric(df['GarageQual'])\n    \n    # Garage Condition\n    df['GarageCond'] = np.where((df.GarageCond == 'NoGar'), 0, df.GarageCond)\n    df['GarageCond'] = np.where((df.GarageCond == 'Po'), 1, df.GarageCond)\n    df['GarageCond'] = np.where((df.GarageCond == 'Fa'), 2, df.GarageCond)\n    df['GarageCond'] = np.where((df.GarageCond == 'TA'), 3, df.GarageCond)\n    df['GarageCond'] = np.where((df.GarageCond == 'Gd'), 4, df.GarageCond)\n    df['GarageCond'] = np.where((df.GarageCond == 'Ex'), 5, df.GarageCond)\n    df['GarageCond'] = pd.to_numeric(df['GarageCond'])\n    \n    # Numbering Paved Drive\n    df['PavedDrive'] = np.where((df.PavedDrive == 'N'), 1, df.PavedDrive)\n    df['PavedDrive'] = np.where((df.PavedDrive == 'P'), 3, df.PavedDrive)\n    df['PavedDrive'] = np.where((df.PavedDrive == 'Y'), 5, df.PavedDrive)\n    df['PavedDrive'] = pd.to_numeric(df['PavedDrive'])\n    \n# Numbering pool Quality\ndef handlingPoolQC(df):\n    df['PoolQC'] = np.where((df.PoolQC == 'NoPool'), 0, df.PoolQC)\n    df['PoolQC'] = np.where((df.PoolQC == 'Fa'), 2, df.PoolQC)\n    df['PoolQC'] = np.where((df.PoolQC == 'TA'), 3, df.PoolQC)\n    df['PoolQC'] = np.where((df.PoolQC == 'Gd'), 4, df.PoolQC)\n    df['PoolQC'] = np.where((df.PoolQC == 'Ex'), 5, df.PoolQC)\n    df['PoolQC'] = pd.to_numeric(df['PoolQC'])\n","4adf87c8":"# Calling various categorical to numerical convertion methods\n\ndef aggregateCtoNTools(df):\n    handlingStreet(df)\n    handlingAlley(df)\n    handlingLotShape(df)\n    handlingUtilities(df)\n    handlingLandSlope(df)\n    handlingConditions(df)\n    handlingYears(df)\n    handlingExteriors(df)\n    handlingExteriorQualityCondition(df)\n    handlingBasement(df)\n    handlingHeatingQC(df)\n    handlingKitQual(df)\n    handlingFunctionality(df)\n    handlingFireplaceQu(df)\n    handlingGarage(df)\n    handlingPoolQC(df)","c102ecfd":"# Calling categorical conversions on the training set\naggregateCtoNTools(housing_df_x)","83bd62af":"def gatherCategoricalIndexes(df):\n    data = housing_df_x.dtypes\n    scaling = []\n    encoding = []\n    for i in range(len(data)):\n        if (data[i] != 'object'):\n            scaling.append(i)\n        else:\n            encoding.append(i)\n    return scaling, encoding","21ee307c":"# One Hot Encoding the rest of the fields\n# We are doing handle_unknown ignore because there is a possibility that we might see new values in test. If you are sure \n# that there will be no new values we can go with drop_first\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nscalingCols, encodingCols = gatherCategoricalIndexes(housing_df_x)\nct = ColumnTransformer(\n    [(\"Min Maxing\", MinMaxScaler(), scalingCols),\n     (\"Encode\", OneHotEncoder(handle_unknown='ignore'), encodingCols)])\nct.fit(housing_df_x)\nencode_train_X = ct.transform(housing_df_x)\nencode_train_X.shape","0e7a749c":"# Applying XGBoost algorithm\nimport xgboost\nreg = xgboost.XGBRegressor().fit(encode_train_X, housing_df_y)\ny_pred = reg.predict(encode_train_X)","c2bca902":"# This competition is considering  Mean_squared_log_error let's see our score for training\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error, r2_score\nmean_squared_log_error(housing_df_y, y_pred)","3c1d0c6e":"# Using Seaborn to construct the plot\nframe = { 'real': housing_df_y, 'predicted': y_pred }\n  \nresult = pd.DataFrame(frame)\n\nimport seaborn as sns\nsns.scatterplot(data=result, x=\"real\", y=\"predicted\")","ab926b09":"# reading the testing data\nhousing_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nhousing_test = housing_test.drop(['Id', 'MiscFeature'], axis=1)\nhousing_test.head()","8f356584":"# We are againg reading to create the submission file.\nhousing_res = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","05642680":"# Performing missing values filling like NA for the known columns like PoolQC .... like training\naggregateImputeMethodTrigger(housing_test)\n# Performing Encoding values for the known columns like External Condition .... like training\naggregateCtoNTools(housing_test)\n# Go to the above methods definition to see the implementation\n\n# Still there might me some missing values in test set. So, let's go with mode for them. As a result, we will handle\n# both categorical and numerical in one go\nhousing_test = housing_test.fillna(housing_test.mode().iloc[0])\n\n# Now we want to Scale and Encode like the training set and want to do predictions\ny_pred = reg.predict(ct.transform(housing_test))\n","836fa222":"# Creating a submission file with id and sales price\n\nhousing_res['SalePrice'] = y_pred\nsubmissionFrame = housing_res[['Id', 'SalePrice']]\nsubmissionFrame.head()","255aa88f":"# Finally we are writing this to a submission file\nsubmissionFrame.to_csv('submissionxgboost.csv', index= False)","bcdff383":"# 6. We are speaking only about testing set from now on...","7d2d9be6":"# Great you are done with training and you are satisfied with the results. Now you want predict sales values for the testing set and want to submit it. After all, that is the main requirement of this.","59e66e44":"**It's very less there is a possibility that we might have overfitted it. If the testset value is very high we have to revisit this**\n","b8ac1600":"# 2. Exploratory Data Analysis using Pandas\nAlthough Sweetviz is providing huge info. It's always a good idea to work with pandas menthods if we are working on data preprocesing.\n\nThis gives us better control and ease of access","a99c0af6":"**Please go through the below methods to see which fields we are imputing **\n\n**We are performing various imputing operations on 18 fields**\n\nThis is the key step in this problem solving. i.e., identifying NA's which we can actually resolve w\/o any conflict","580fffa1":"### The End","ff0a3b69":"# Understanding Above missing values and how to tackle them.\n1. After seeing the missing values count in Alley, PoolQC, Fence, FirePlaceQu that's more than 80%. We will be very tentative to drop them and go ahead with the other columns\n2. But if some columns are missing these many values then missing values also have some meaning for those columns. Let's unnderstand than and clean this data set\n\n**Upon going through the data description I come to know that NA means it is not available. For example PoolQC has NA means there is no pool in that building. But pandas considering this NA as missing value. So, to avoid this confusion let's alter the NA values to some other values which make sense and don't confuse pandas.**","5124026c":"# 4. One Hot or Numerical Encoding\n\nThis is yet another key step in this notebook. Please read comments on specific methods to better understand why it wrote.\n\nMost importantly we will try to guage string values to numbers.\n\nFor Example ExterCond columns has the following values 'Po' --> Poor, 'Fa' --> Fair, 'TA', 'Gd' --> Good, 'Ex' --> Excellent so we can give numbers 1 to 5 respectively and con avoid generating 5 columns unnecessarely when we go with Encoding.\n\nThere are numerous columns of this sort. We will do the same for all of them.","a2bca354":"# Visualizing the train predictions....\n\nIf it's linear then the training is done perfectly","54db5aed":"# Using Column Transform to do Encoding and scaling at the same time\n\nIf the type is object we do encoding else scaling\nBelow method will identify the columns and return the list for scaling and encoding ","997cad40":"# 5. Let's go with the Training  Phase\n\nIf you are new to machine learning. You might hear from lot of people that it's important to learn preprocessing than model building.\nYou can exactly see that here. Model build is hardly 3 lines but preprocessing is IDK but they are alot","c8967173":"# Below methods provides an interface to run all the above methods in one shot","1ca8c0df":"# Advanced Housing Price Prediction using XGBoost","22c28330":"# Missing values were resolved for the training set. We can go ahead with other preprocessing steps now","ccba17df":"# 1. Reading and exploring data with SweetViz\nSweetviz generates an interactive HTML file when we pass the pandas dataFrame. In which we will get various valuable insights. In one word we can perform entire Exploratory data analysis with that package.","931dc8bf":"# 3. Imputing NA values as we found and agreed in step 2"}}