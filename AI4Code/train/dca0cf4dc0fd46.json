{"cell_type":{"db2bd9c7":"code","8ab1bac6":"code","bb73733d":"code","73b7c371":"code","8efedda3":"code","7ec57c7d":"code","36a66b16":"code","a0ee7eca":"code","806e8ca2":"code","18ee4824":"code","4dc57bc3":"code","bbd6c405":"code","1897e197":"code","4ca48562":"code","6134349f":"code","6beaae97":"code","40cbc4fc":"code","2cfd99a0":"code","363cc7bd":"code","2aa46590":"code","81040943":"code","574fd0e6":"code","0382fb3a":"code","0150ad67":"markdown","253f0dad":"markdown","224b887b":"markdown","2d577287":"markdown","b9d9c0f3":"markdown","0cfd1171":"markdown","43b8ea58":"markdown","b12b30e3":"markdown","9da310ef":"markdown","2ee4e325":"markdown"},"source":{"db2bd9c7":"pip install autoviz","8ab1bac6":"pip install xlrd","bb73733d":"!pip install deep_autoviml","73b7c371":"import pandas as pd\nfrom deep_autoviml import deep_autoviml as deepauto","8efedda3":"df = pd.read_csv('..\/input\/voicegender\/voice.csv')\ndf.head()","7ec57c7d":"df.info()","36a66b16":"df.describe()","a0ee7eca":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()\ntarget='label'\ndf1 = AV.AutoViz(filename=\"\",sep=',', depVar=target, dfte=df, header=0, verbose=1, \n                 lowess=False, chart_format='svg', max_rows_analyzed=150000, max_cols_analyzed=30)","806e8ca2":"from sklearn.preprocessing import LabelEncoder\nLE = LabelEncoder()\ndf[\"label\"] = LE.fit_transform(df[\"label\"])\ndf['label'].unique()","18ee4824":"df[\"label\"].value_counts()","4dc57bc3":"df.corr().abs()['label'].sort_values(ascending = False)","bbd6c405":"import sklearn.model_selection\ntrain, test = sklearn.model_selection.train_test_split(df,stratify=df[\"label\"], train_size=.80, random_state=1)\nprint(train.shape, test.shape)","1897e197":"target = 'label'","4ca48562":"keras_model_type =  \"fast1\" ## always try \"fast\" first, then \"fast2\", \"auto\", etc.\n### always set early_stopping to True first and then change it to False\n#### You always need 15 max_trials to get something decent #####\n#### always set tuner to \"storm\" and then \"optuna\". \n\nproject_name = \"Gender Recognition by Voice Identify a voice as male or female\"\nmodel_options = {'char_limit':50, 'cat_feat_cross_flag':False,\n                 'max_trials': 10, \"tuner\": \"storm\"}\nkeras_options = {\"patience\":10, 'class_weight': True, 'early_stopping': True, \n                 'lr_scheduler': '', \"optimizer\": 'RMS'}","6134349f":"model, cat_vocab_dict = deepauto.fit(train, target, keras_model_type=keras_model_type,\n        project_name=project_name, keras_options=keras_options,  \n        model_options=model_options, save_model_flag=True, use_my_model='',\n        model_use_case='', verbose=1)","6beaae97":"predictions = deepauto.predict(model, project_name, test_dataset=test,\n                                 keras_model_type=keras_model_type, \n                                 cat_vocab_dict=cat_vocab_dict)","40cbc4fc":"y_test = test[target].values\ny_test","2cfd99a0":"y_preds = predictions[-1]\ny_preds","363cc7bd":"print(F'Real value:',y_test[11])\nprint(F'Prediction:',y_preds[11])","2aa46590":"print(F'Real value:',y_test[1])\nprint(F'Prediction:',y_preds[1])","81040943":"import numpy as np\nlabels = np.unique(y_test)\ntarget_names = np.unique(y_test)\nlabels, target_names","574fd0e6":"from deep_autoviml.utilities.utilities import plot_classification_results","0382fb3a":"plot_classification_results(y_test, y_preds, \n                            labels, target_names, title_string='deep autoviml fast')","0150ad67":"<h1 style='background-color:#4C66E0; font-family:newtimeroman; font-size:190%; text-align:center; border-radius: 15px 50px;' >Deep_Autoviml<\/h1>\n\n\n#### Build keras pipelines and models in a single line of code!\n\n<img src=\"https:\/\/github.com\/AutoViML\/deep_autoviml\/raw\/master\/logo.jpg\" width=\"800px\">\n\n#### Link \n[Here](https:\/\/github.com\/AutoViML\/deep_autoviml)","253f0dad":"## Imports Lab","224b887b":"## Read the data","2d577287":"\n<h1 style='background-color:#4C66E0; font-family:newtimeroman; font-size:190%; text-align:center; border-radius: 15px 50px;' >Auto Viz<\/h1>\n\n\n#### Automatically Visualize any dataset, any size with a single line of code.\n\n#### AutoViz performs automatic visualization of any dataset with one line. Give any input file (CSV, txt or json) and AutoViz will visualize it.\n\n\n<img src=\"https:\/\/autoviz.io\/static\/core\/img\/logo.png\" width=\"800px\">\n\n\nLink\n\n###### [[Here](https:\/\/pypi.org\/project\/autoviz\/)]\n","b9d9c0f3":"## preprocessing ","0cfd1171":"## ","43b8ea58":"## Split the Dataset Training 80 % and Tsting 20 %","b12b30e3":"## Check the Model Real value & Prediction\n","9da310ef":"\n<h1 style='background-color:#4C66E0; font-family:newtimeroman; font-size:190%; text-align:center; border-radius: 15px 50px;' > Gender Recognition by Voice <\/h1>\n\n\n\n#### Identify a voice as male or female\n\n#### The goal of the project is to work Visualization and Deep Learning in the single line.\n\n\n\n\n\n\n<img src=\"https:\/\/www.thesoftwarereport.com\/wp-content\/uploads\/2021\/03\/Voice-Recognition-Technology.jpg\" width=\"800px\">\n\n#### Description\nVoice Gender\nGender Recognition by Voice and Speech Analysis\n\nThis database was created to identify a voice as male or female, based upon acoustic properties of the voice and speech. \nThe dataset consists of 3,168 recorded voice samples, collected from male and female speakers. \n\n##### Link Dataset \n###### [Here](https:\/\/www.kaggle.com\/primaryobjects\/voicegender)\n\nSpecial thanks to Mr.RSESHA for the tool deep_autoviml \n\nThis is his project \n\n\n###### [Here](https:\/\/www.kaggle.com\/rsesha\/water-quality-classification-deep-autoviml\/comments)","2ee4e325":"## Good Luck "}}