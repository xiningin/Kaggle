{"cell_type":{"54cb9590":"code","c8a5aff8":"code","3c0e4df6":"code","5e7d3402":"code","d2250243":"code","0fab8cc9":"code","a6ea6ed5":"code","8296bf90":"code","ce218f7c":"code","f0c61bea":"code","32e172c4":"code","bbc75d43":"markdown","93f9cdae":"markdown","74b655fc":"markdown","7b937cfa":"markdown","ac528b8a":"markdown","05918716":"markdown","702d1085":"markdown","25bd2b2d":"markdown","50316045":"markdown","e5558df4":"markdown","5c969ff2":"markdown","3038e714":"markdown","6705f2f5":"markdown"},"source":{"54cb9590":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#load the libs\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport os\nprint(tf.__version__)\nprint(os.listdir(\"..\/input\"))","c8a5aff8":"#import data and define the classes\ntrain_data = pd.read_csv(\"..\/input\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\nclass_names = [0,1,2,3,4,5,6,7,8,9]\n\n#print out training data\nprint(train_data.shape)\nprint(train_data.head())","3c0e4df6":"#split out the data into features (pixel values) and categorical labels (digit values 0-9)\ntrain_x = train_data.iloc[:,1:].values.astype('float32') # all pixel values\ntrain_y = train_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n\ntest_x = test_data.iloc[:,].values.astype('float32') # all pixel values\n\n#reshape the features to be 28x28\ntrain_x = train_x.reshape(train_x.shape[:1] + (28, 28, 1))\ntest_x = test_x.reshape(test_x.shape[:1] + (28, 28, 1))\n\n#change the labels to be one-hot encoded\ntrain_y = keras.utils.to_categorical(train_y)\nnum_classes = train_y.shape[1]\n\n#normalize pixel values using minmax (values between 0 and 1 inclusive)\ntrain_x = train_x \/ 255\ntest_x = test_x \/ 255","5e7d3402":"# Create callbacks for tensorboard and early stopping\nmy_callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, min_delta=0, monitor='val_loss')]","d2250243":"plt.figure()\nplt.imshow(train_x[0].reshape(28, 28))\nplt.colorbar()\nplt.grid(False)\nplt.show()\n\n#plot a group of features and labels to check data\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_x[i].reshape(28, 28), cmap=plt.cm.binary)\n    plt.xlabel(class_names[np.argmax(train_y[i])])\nplt.show()","0fab8cc9":"#define the model and layers\nmodel = keras.Sequential([ \n    #start: 1@28x28 image matrices\n\n    #convolution with 32 filters that use a 3x3 kernel (convolution window) and stride of 1\n    keras.layers.Conv2D(32, (3,3), input_shape=(28, 28, 1), strides=(1,1), activation='relu'),\n    #now: 32@26x26\n\n    #subsampling using max pooling and a 2x2 filter (largest element from the rectified feature map)\n    keras.layers.MaxPool2D(pool_size=(2,2)),\n    #now: 32@13x13 matricies\n\n    #convolution with 64 filters that use a 3x3 kernel (convolution window) and stride of 1\n    keras.layers.Conv2D(64, (3,3), strides=(1,1), activation='relu'),\n    #now: 64@11x11\n\n    #subsampling using max pooling\n    keras.layers.MaxPool2D(pool_size=(2,2)),\n    #now: 64@5x5\n\n    #flatten to a single vector\n    keras.layers.Flatten(),\n    #now: flattened to 1600\n\n    #first fully connected layer with 128 units\n    keras.layers.Dense(128, activation=tf.nn.relu),\n\n    #drop 20% of units to help prevent overfitting\n    keras.layers.Dropout(0.2),\n\n    #softmax layer for classification\n    keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n])","a6ea6ed5":"#compile the model\nmodel.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#print a summary of the model\nmodel.summary()","8296bf90":"#train the model\nmodel.fit(x=train_x, \n            y=train_y,\n            batch_size=32,\n            epochs=30,\n            verbose=1,\n            callbacks = my_callbacks,\n            validation_split=0.05,\n            shuffle=True\n            )\n","ce218f7c":"#make predictions on the test features\npredictions = model.predict(test_x)","f0c61bea":"def plot_value_array(i, predictions_array):\n    predictions_array = predictions_array[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1]) \n    predicted_label = np.argmax(predictions_array)\n    thisplot[predicted_label].set_color('red')\n\ndef plot_image(i, predictions_array, img):\n    img = img.reshape(img.shape[0] ,28, 28)\n    predictions_array, img = predictions_array[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(img, cmap=plt.cm.binary)\n    predicted_label = np.argmax(predictions_array)\n    plt.xlabel(\"{} - prob:{:2.0f}%\".format(class_names[predicted_label], 100*np.max(predictions_array)), color='red')\n\n# Plot the first X test images, their predicted label, and the true label\n# Color correct predictions in blue, incorrect predictions in red\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, predictions, test_x)\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions)\nplt.show()","32e172c4":"#submissions for Kaggle\n#cat_predictions = np.argmax(predictions, axis=1)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": np.argmax(predictions, axis=1)})\nsubmissions.to_csv(\"my_submissions.csv\", index=False, header=True)","bbc75d43":"Import the MNIST data from input folder","93f9cdae":"Model graph on Tensorboard:\n![](https:\/\/storage.googleapis.com\/kaggle-datasets\/80861\/187841\/kaggle_mnist_3.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1543112528&Signature=k7f2%2BqvPAmFWIPrLSqZijF%2Fxe5JXzUZyelLAIwCQQiuHYSPS4DpeBZKzMHepKli4GVvzNf1ozICIQvDQMp9H87LDW2aZCRzkTPdeFP%2BmE2ASPhOGqkulukNHlyJbIjZqEIwO23fcGpXcE15%2BONS2H%2B2D1H9mNjwnH%2BXsxjoLjHG64cXZl8bxKXDz%2F1pDq%2FGrq0J2gilmstKRqsFG4TZ5A2dB85bG2QnE1xZx93RQpypLbG%2B1Z6bICHzsEGg2LVcs%2FFrYp3GRt7C12QO9fceRS%2FyB%2Fw9tpaWy5KsnRDQMd7lmWQOsbaLG%2BgVxjgFnTrp4GL3anySP4IUYHbB2PKq3Jg%3D%3D)    ","74b655fc":"Accuracy and loss metrics in Tensorboard:\n![](https:\/\/storage.googleapis.com\/kaggle-datasets\/80861\/187841\/kaggle_mnist_1.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1543113399&Signature=R2fdeYcsRdYoA1q4y6OPyazqy%2Fza1COKyKFRyKrJ6c4maSPWacELZrBJtvVndBShPxNXO7arloATk4LY4J0dZzk4w1hBxz68OOMvTCQnbiSZVpc7%2FauiQfTCd6YfulTLr%2BSPBva3g3y2XlZX3mMpcZTUXw1eaz1%2FIjGofGG5tzz56EXAZlLH%2Fn4VVwVBUGBUiJsWetCdxsaIpyyP05ihgvglMVBJMX7uh8ExMj%2BxQ96eNa3F1vL7mdoLcnTgcc2h2nEodTvpfoWbc08RdxzZQJd119Qj3U%2Fho0e0vAlOCZMlKui%2FwLei089TBZA6PvZzfsFGqInhswWok39DNeBRSw%3D%3D)![](https:\/\/storage.googleapis.com\/kaggle-datasets\/80861\/187841\/kaggle_mnist_4.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1543112449&Signature=rlHEMqkO5vBDtfErz7z0R4S%2BWJt9V0At367VugcDzsQ5wtqPi5oR1IxsdnEPZ%2BTqBZJ11Dignaf64b5FIovN5b%2B5nv1Be9Inw0LjpP8WSwyOIBLivzFUhTcn4rBf4QRCn7NdDa9q72pPig0P1CRK9F1mLUWopd4AgzDYZYyqKqJn66aVPROe1TTWoOUG3ujOUfuQJrWtHF2akxZunp%2BUzB8MMwrTjq4jiwZR4dE2nx19uHxOFPUdqiSi3rx9HTSYOYSQDmpnVlQfbdLVQB%2FpeqN8NjXqWhoP6s15LxHOIDzd7%2Bw9ZOycNnQEarcZoUNI7maVCZEAft%2FLm%2BWUQTfCYQ%3D%3D)","7b937cfa":"Create submission file for Kaggle","ac528b8a":"Make prediction on the test data","05918716":"This is my first submission and notebook on Kaggle. I'm still learning and any comments would be appreciated. Hope some may find this useful.","702d1085":"Compile and summarize the model. Use adam optimizer and categorical cross entropy for loss (takes input of one-hot encoded targets)","25bd2b2d":"Define the model using Keras and TensorFlow backend (channels first)","50316045":"View an example of features","e5558df4":"Create Keras callbacks for use during training","5c969ff2":"Train the model using batch_size of 32 and up to 30 epochs (depending on improvement of validation accuracy).","3038e714":"Process the data by splitting training data into features and labels. Then apply preprocessing to the data to get it ready for input into the model.","6705f2f5":"Plot a table of test features (images) and the predicted targets (digits). Display the confidence via probability of the prediction under each image."}}