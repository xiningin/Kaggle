{"cell_type":{"f2025f20":"code","d145934d":"code","6e891ac8":"code","aa216e3c":"code","7ecfa732":"code","487518d1":"code","1b0fc2a3":"code","2576c206":"code","7e8ae240":"code","dc83889c":"code","c341cc1e":"code","abf47a60":"code","9bfab8ee":"code","aaef6b23":"code","efc4d840":"code","ab601fcc":"code","131c349a":"markdown","35a74fb7":"markdown","0951d530":"markdown","6e06715c":"markdown","4b0927c1":"markdown"},"source":{"f2025f20":"opts = {}\n#opts['tf_version'] = 1.14                      # current version also works with tf 2.2\nopts['imageType_train'] = '.tif'\nopts['imageType_test'] = '.tif'\nopts['number_of_channel'] = 3                   # Set if to '3' for RGB images and set it to '1' for grayscale images\nopts['treshold'] = 0.5                          # treshold to convert the network output (stage 1) to binary masks\n## input & output directories\nopts['train_dir'] = '..\/input\/segmentation-of-nuclei-in-cryosectioned-he-images\/tissue images\/'\nopts['train_label_dir'] = '..\/input\/segmentation-of-nuclei-in-cryosectioned-he-images\/Annotator 1 (biologist)\/mask binary\/'\nopts['train_label_masks'] = '..\/input\/segmentation-of-nuclei-in-cryosectioned-he-images\/Annotator 1 (biologist)\/label masks modify\/'\nopts['train_dis_dir'] = '..\/input\/segmentation-of-nuclei-in-cryosectioned-he-images\/Annotator 1 (biologist)\/distance maps\/'\nopts['results_save_path'] ='\/kaggle\/working\/images\/'\nopts['models_save_path'] ='\/kaggle\/working\/models\/'\n\nopts['epoch_num_stage1'] = 20                   # number of epochs for stage 1\nopts['quick_run'] = 0.01                         # step = (len(train)\/batch_size) \/ quick_run (set it to large numbers just debugging the code)\nopts['batch_size'] = 16                          # batch size\nopts['random_seed_num'] = 19                    # keep it constant to be able to reproduce the results\nopts['k_fold'] = 10                             # set to '1' to have no cross validation (much faster training but 2-3% degradation in performance)\nopts['save_val_results'] = 1                    # set to '0' to skip saving the validation results in training\nopts['init_LR'] = 0.001                         # initial learning rate for stage 1 and stage 2\nopts['LR_decay_factor'] = 0.5                   # learning rate scheduler\nopts['LR_drop_after_nth_epoch'] = 8            # learning rate scheduler\nopts['crop_size'] = 512                         # crop size for training\nopts['pretrained_model'] = 'efficientnetb0'     # future development \nopts['use_pretrained_flag'] = 0                 # if you want to use a pretrained model in the encoder set it to one\n\n","d145934d":"## disabeling warning msg\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n# 0 = all messages are logged (default behavior)\n# 1 = INFO messages are not printed\n# 2 = INFO and WARNING messages are not printed\n# 3 = INFO, WARNING, and ERROR messages are not printed\nimport warnings\nwarnings.simplefilter('ignore')\nimport sys\nsys.stdout.flush() # resolving tqdm problem","6e891ac8":"import numpy as np\nimport tensorflow as tf\nimport math\nfrom matplotlib.colors import rgb_to_hsv, hsv_to_rgb\nimport random\n\nimport keras\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Activation, add\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.models import Model, load_model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint,LearningRateScheduler,CSVLogger\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam\n#import segmentation_models as sm\nfrom albumentations import*\nimport cv2\nfrom random import shuffle                            #\nimport os\nimport matplotlib.pyplot as plt\nfrom skimage.io import imsave\n\n\nimport time                                           # measuring training and test time\nfrom glob import glob                                 # path control\nimport tqdm\nfrom scipy.ndimage.morphology import binary_fill_holes\nfrom skimage.morphology import remove_small_objects\nfrom scipy.ndimage.filters import gaussian_filter\nimport skimage.morphology\nfrom skimage import io, exposure, img_as_uint, img_as_float\nfrom skimage.io import imsave, imread\nfrom skimage.morphology import label\nfrom skimage.morphology import watershed\nfrom skimage.feature import peak_local_max\n#import segmentation_models as sm\nfrom scipy import ndimage as ndi","aa216e3c":"tf.__version__","7ecfa732":"# Dice loss function\ndef dice_coef(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n#####################################################################################\n# Combination of Dice and binary cross entophy loss function\ndef bce_dice_loss(y_true, y_pred):\n    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n########################################################################################\n# custom callsback (decaying learning rate)\ndef step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, epochs_drop=1000):\n    '''\n    Wrapper function to create a LearningRateScheduler with step decay schedule.\n    '''\n    def schedule(epoch):\n        return initial_lr * (decay_factor ** np.floor(epoch\/epochs_drop))\n    \n    return LearningRateScheduler(schedule, verbose = 1)\n#######################################################################################################\ndef binary_unet( IMG_CHANNELS, LearnRate):\n    inputs = Input((None, None, IMG_CHANNELS))\n    #s = Lambda(lambda x: x \/ 255) (inputs)\n\n    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (inputs)\n    c1 = Dropout(0.1) (c1)\n    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (p1)\n    c2 = Dropout(0.1) (c2)\n    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (p2)\n    c3 = Dropout(0.1) (c3)\n    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (p3)\n    c4 = Dropout(0.1) (c4)\n    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (p4)\n    c5 = Dropout(0.1) (c5)\n    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c5)\n\n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (u6)\n    c6 = Dropout(0.1) (c6)\n    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (u7)\n    c7 = Dropout(0.1) (c7)\n    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='glorot_uniform', padding='same') (c9)\n\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9) # for binary\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer = Adam(lr=LearnRate), loss= bce_dice_loss , metrics=[dice_coef]) #for binary\n\n    #model.summary()\n    return model\n#######################################################################################################\ndef deeper_binary_unet(IMG_CHANNELS, LearnRate):\n    # Build U-Net model\n    inputs = Input((None, None, IMG_CHANNELS))\n    #s = Lambda(lambda x: x \/ 255) (inputs)\n\n    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (inputs)\n    c1 = Dropout(0.1) (c1)\n    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n    c2 = Dropout(0.1) (c2)\n    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n    c3 = Dropout(0.1) (c3)\n    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n    c4 = Dropout(0.1) (c4)\n    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n    \n    \n    c4_new = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n    c4_new = Dropout(0.1) (c4_new)\n    c4_new = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4_new)\n    p4_new = MaxPooling2D(pool_size=(2, 2)) (c4_new)\n\n    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4_new)\n    c5 = Dropout(0.1) (c5)\n    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n    \n    \n    u6_new = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6_new = concatenate([u6_new, c4_new])\n    c6_new = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6_new)\n    c6_new = Dropout(0.1) (c6_new)\n    c6_new = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6_new)\n\n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c6_new)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = Dropout(0.1) (c6)\n    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = Dropout(0.1) (c7)\n    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n    model_deeper = Model(inputs=[inputs], outputs=[outputs])\n    model_deeper.compile(optimizer = Adam(lr=LearnRate), loss= bce_dice_loss , metrics=[ dice_coef])\n    #model_deeper.summary()\n    return model_deeper","487518d1":"# augmentation function\ndef albumentation_aug(p=1.0, crop_size_row = 448, crop_size_col = 448 ):\n    return Compose([\n        RandomCrop(crop_size_row, crop_size_col, always_apply=True, p=1),\n        CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n        RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, brightness_by_max=True, p=0.4),\n        HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.1),\n        HorizontalFlip(always_apply=False, p=0.5),\n        VerticalFlip(always_apply=False, p=0.5),\n        RandomRotate90(always_apply=False, p=0.5),\n        #ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=20, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.3),\n    ], p=p) # --> this p has the second proiroty comapred to the p inside each argument (e.g. HorizontalFlip(always_apply=False, p=0.5) )\n###########################################################\ndef albumentation_aug_light(p=1.0, crop_size_row = 448, crop_size_col = 448):\n    return Compose([\n        RandomCrop(crop_size_row, crop_size_col, always_apply=True, p=1.0),\n        HorizontalFlip(always_apply=False, p=0.5),\n        VerticalFlip(always_apply=False, p=0.5),\n        RandomRotate90(always_apply=False, p=0.5),\n        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=20, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.1),\n    ], p=p, additional_targets={'mask1': 'mask','mask2': 'mask'}) # --> this p has the second proiroty comapred to the p inside each argument (e.g. HorizontalFlip(always_apply=False, p=0.5) )\n","1b0fc2a3":"def get_dice_1(true, pred):\n    \"\"\"\n        Traditional dice\n    \"\"\"\n    # cast to binary 1st\n    true = np.copy(true)\n    pred = np.copy(pred)\n    true[true > 0] = 1\n    pred[pred > 0] = 1\n    inter = true * pred\n    denom = true + pred\n    return 2.0 * np.sum(inter) \/ np.sum(denom)\n##############################################################################################\ndef get_fast_aji(true, pred):\n    \"\"\"\n    AJI version distributed by MoNuSeg, has no permutation problem but suffered from \n    over-penalisation similar to DICE2\n    Fast computation requires instance IDs are in contiguous orderding i.e [1, 2, 3, 4] \n    not [2, 3, 6, 10]. Please call `remap_label` before hand and `by_size` flag has no \n    effect on the result.\n    \"\"\"\n    true = np.copy(true) # ? do we need this\n    pred = np.copy(pred)\n    true_id_list = list(np.unique(true))\n    pred_id_list = list(np.unique(pred))\n\n    true_masks = [None,]\n    for t in true_id_list[1:]:\n        t_mask = np.array(true == t, np.uint8)\n        true_masks.append(t_mask)\n    \n    pred_masks = [None,]\n    for p in pred_id_list[1:]:\n        p_mask = np.array(pred == p, np.uint8)\n        pred_masks.append(p_mask)\n    \n    # prefill with value\n    pairwise_inter = np.zeros([len(true_id_list) -1, \n                               len(pred_id_list) -1], dtype=np.float64)\n    pairwise_union = np.zeros([len(true_id_list) -1, \n                               len(pred_id_list) -1], dtype=np.float64)\n\n    # caching pairwise\n    for true_id in true_id_list[1:]: # 0-th is background\n        t_mask = true_masks[true_id]\n        pred_true_overlap = pred[t_mask > 0]\n        pred_true_overlap_id = np.unique(pred_true_overlap)\n        pred_true_overlap_id = list(pred_true_overlap_id)\n        for pred_id in pred_true_overlap_id:\n            if pred_id == 0: # ignore\n                continue # overlaping background\n            p_mask = pred_masks[pred_id]\n            total = (t_mask + p_mask).sum()\n            inter = (t_mask * p_mask).sum()\n            pairwise_inter[true_id-1, pred_id-1] = inter\n            pairwise_union[true_id-1, pred_id-1] = total - inter\n    #\n    pairwise_iou = pairwise_inter \/ (pairwise_union + 1.0e-6)\n    # pair of pred that give highest iou for each true, dont care \n    # about reusing pred instance multiple times\n    paired_pred = np.argmax(pairwise_iou, axis=1)\n    pairwise_iou = np.max(pairwise_iou, axis=1)\n    # exlude those dont have intersection\n    paired_true = np.nonzero(pairwise_iou > 0.0)[0]\n    paired_pred = paired_pred[paired_true]\n    # print(paired_true.shape, paired_pred.shape)\n    overall_inter = (pairwise_inter[paired_true, paired_pred]).sum()\n    overall_union = (pairwise_union[paired_true, paired_pred]).sum()\n    #\n    paired_true = (list(paired_true + 1)) # index to instance ID\n    paired_pred = (list(paired_pred + 1))\n    # add all unpaired GT and Prediction into the union\n    unpaired_true = np.array([idx for idx in true_id_list[1:] if idx not in paired_true])\n    unpaired_pred = np.array([idx for idx in pred_id_list[1:] if idx not in paired_pred])\n    for true_id in unpaired_true:\n        overall_union += true_masks[true_id].sum()\n    for pred_id in unpaired_pred:\n        overall_union += pred_masks[pred_id].sum()\n    #\n    aji_score = overall_inter \/ overall_union\n    return aji_score\n##############################################################################################\ndef remap_label(pred, by_size=False):\n    \"\"\"\n    Rename all instance id so that the id is contiguous i.e [0, 1, 2, 3] \n    not [0, 2, 4, 6]. The ordering of instances (which one comes first) \n    is preserved unless by_size=True, then the instances will be reordered\n    so that bigger nucler has smaller ID\n    Args:\n        pred    : the 2d array contain instances where each instances is marked\n                  by non-zero integer\n        by_size : renaming with larger nuclei has smaller id (on-top)\n    \"\"\"\n    pred_id = list(np.unique(pred))\n    pred_id.remove(0)\n    if len(pred_id) == 0:\n        return pred # no label\n    if by_size:\n        pred_size = []\n        for inst_id in pred_id:\n            size = (pred == inst_id).sum()\n            pred_size.append(size)\n        # sort the id by size in descending order\n        pair_list = zip(pred_id, pred_size)\n        pair_list = sorted(pair_list, key=lambda x: x[1], reverse=True)\n        pred_id, pred_size = zip(*pair_list)\n\n    new_pred = np.zeros(pred.shape, np.int32)\n    for idx, inst_id in enumerate(pred_id):\n        new_pred[pred == inst_id] = idx + 1    \n    return new_pred\n\n##############################################################################################\ndef get_fast_pq(true, pred, match_iou=0.5):\n    \"\"\"\n    `match_iou` is the IoU threshold level to determine the pairing between\n    GT instances `p` and prediction instances `g`. `p` and `g` is a pair\n    if IoU > `match_iou`. However, pair of `p` and `g` must be unique\n    (1 prediction instance to 1 GT instance mapping).\n    If `match_iou` < 0.5, Munkres assignment (solving minimum weight matching\n    in bipartite graphs) is caculated to find the maximal amount of unique pairing.\n    If `match_iou` >= 0.5, all IoU(p,g) > 0.5 pairing is proven to be unique and\n    the number of pairs is also maximal.\n    Fast computation requires instance IDs are in contiguous orderding\n    i.e [1, 2, 3, 4] not [2, 3, 6, 10]. Please call `remap_label` beforehand\n    and `by_size` flag has no effect on the result.\n    Returns:\n        [dq, sq, pq]: measurement statistic\n        [paired_true, paired_pred, unpaired_true, unpaired_pred]:\n                      pairing information to perform measurement\n    \"\"\"\n    assert match_iou >= 0.0, \"Cant' be negative\"\n\n    true = np.copy(true)\n    pred = np.copy(pred)\n    true_id_list = list(np.unique(true))\n    pred_id_list = list(np.unique(pred))\n\n    true_masks = [None, ]\n    for t in true_id_list[1:]:\n        t_mask = np.array(true == t, np.uint8)\n        true_masks.append(t_mask)\n\n    pred_masks = [None, ]\n    for p in pred_id_list[1:]:\n        p_mask = np.array(pred == p, np.uint8)\n        pred_masks.append(p_mask)\n\n    # prefill with value\n    pairwise_iou = np.zeros([len(true_id_list) - 1,\n                             len(pred_id_list) - 1], dtype=np.float64)\n\n    # caching pairwise iou\n    for true_id in true_id_list[1:]:  # 0-th is background\n        t_mask = true_masks[true_id]\n        pred_true_overlap = pred[t_mask > 0]\n        pred_true_overlap_id = np.unique(pred_true_overlap)\n        pred_true_overlap_id = list(pred_true_overlap_id)\n        for pred_id in pred_true_overlap_id:\n            if pred_id == 0:  # ignore\n                continue  # overlaping background\n            p_mask = pred_masks[pred_id]\n            total = (t_mask + p_mask).sum()\n            inter = (t_mask * p_mask).sum()\n            iou = inter \/ (total - inter)\n            pairwise_iou[true_id - 1, pred_id - 1] = iou\n    #\n    if match_iou >= 0.5:\n        paired_iou = pairwise_iou[pairwise_iou > match_iou]\n        pairwise_iou[pairwise_iou <= match_iou] = 0.0\n        paired_true, paired_pred = np.nonzero(pairwise_iou)\n        paired_iou = pairwise_iou[paired_true, paired_pred]\n        paired_true += 1  # index is instance id - 1\n        paired_pred += 1  # hence return back to original\n    else:  # * Exhaustive maximal unique pairing\n        #### Munkres pairing with scipy library\n        # the algorithm return (row indices, matched column indices)\n        # if there is multiple same cost in a row, index of first occurence\n        # is return, thus the unique pairing is ensure\n        # inverse pair to get high IoU as minimum\n        paired_true, paired_pred = linear_sum_assignment(-pairwise_iou)\n        ### extract the paired cost and remove invalid pair\n        paired_iou = pairwise_iou[paired_true, paired_pred]\n\n        # now select those above threshold level\n        # paired with iou = 0.0 i.e no intersection => FP or FN\n        paired_true = list(paired_true[paired_iou > match_iou] + 1)\n        paired_pred = list(paired_pred[paired_iou > match_iou] + 1)\n        paired_iou = paired_iou[paired_iou > match_iou]\n\n    # get the actual FP and FN\n    unpaired_true = [idx for idx in true_id_list[1:] if idx not in paired_true]\n    unpaired_pred = [idx for idx in pred_id_list[1:] if idx not in paired_pred]\n    # print(paired_iou.shape, paired_true.shape, len(unpaired_true), len(unpaired_pred))\n\n    #\n    tp = len(paired_true)\n    fp = len(unpaired_pred)\n    fn = len(unpaired_true)\n    # get the F1-score i.e DQ\n    dq = tp \/ (tp + 0.5 * fp + 0.5 * fn)\n    # get the SQ, no paired has 0 iou so not impact\n    sq = paired_iou.sum() \/ (tp + 1.0e-6)\n\n    return [dq, sq, dq * sq], [paired_true, paired_pred, unpaired_true, unpaired_pred]","2576c206":"# other useful finction for training\n\ndef get_id_from_file_path(file_path, indicator):\n    return file_path.split(os.path.sep)[-1].replace(indicator, '')\n############################################################\ndef chunker(seq, seq2, size):\n    return ([seq[pos:pos + size], seq2[pos:pos + size]] for pos in range(0, len(seq), size))\n############################################################\ndef data_gen_heavy(list_files, list_files2, batch_size, p , size_row, size_col, distance_unet_flag = 0, augment=False, BACKBONE_model = 'efficientnetb0', use_pretrain_flag =1):\n    #preprocess_input = sm.get_preprocessing(BACKBONE_model)\n    crop_size_row = size_row\n    crop_size_col = size_col\n    aug = albumentation_aug(p, crop_size_row, crop_size_col)\n\n    while True:\n        #shuffle(list_files)\n        for batch in chunker(list_files,list_files2, batch_size):\n            #X = [cv2.resize(cv2.imread(x), (size, size)) for x in batch]\n            X = []\n            Y = []\n\n            for count in range(len(batch[0])):\n                # x = cv2.resize(cv2.imread(batch[0][count]), (size_col, size_row))\n                # x_mask = cv2.resize(cv2.imread(batch[1][count], cv2.IMREAD_GRAYSCALE), (size_col, size_row))\n                x = cv2.imread(batch[0][count])\n                x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n                x_mask = cv2.imread(batch[1][count], cv2.IMREAD_GRAYSCALE)\n                \n                x_mask_temp = np.zeros((x_mask.shape[0], x_mask.shape[1]))\n                x_mask_temp[x_mask == 255] = 1\n                \n\n                if distance_unet_flag == False:\n                    if augment:\n                        augmented = aug(image= x, mask= x_mask_temp)\n                        x = augmented['image']\n                        if use_pretrain_flag == 1:\n                            x = preprocess_input(x)\n                        x_mask_temp = augmented['mask']\n                        x = x\/255\n                    X.append(x)\n                    Y.append(x_mask_temp)\n                    #imsave('\/media\/masih\/wd\/projects\/MoNuSAC_binary\/results\/images\/an\/{}_binary.png'.format(get_id_from_file_path(batch[0][count], '.png')), x_mask_epithelial)\n                    #imsave('\/media\/masih\/wd\/projects\/MoNuSAC_binary\/results\/images\/an\/{}.png'.format(get_id_from_file_path(batch[0][count], '.tif')), x)\n                else:\n                    if augment:\n                        augmented = aug(image=x, mask=x_mask)\n                        x = augmented['image']\n                        if use_pretrain_flag == 1:\n                            x = preprocess_input(x)\n                        x_mask = augmented['mask']\n\n                    X.append(x)\n                    x_mask = (x_mask - np.min(x_mask))\/ (np.max(x_mask) - np.min(x_mask) + 0.0000001)\n                    Y.append(x_mask)\n\n                del x_mask\n                del x_mask_temp\n                del x\n            Y = np.expand_dims(np.array(Y), axis=3)\n            Y = np.array(Y)\n            yield np.array(X), np.array(Y)\n","7e8ae240":"# create folders to save the best models and images (if needed) for each fold\nif not os.path.exists('\/kaggle\/working\/images\/'):\n    os.makedirs('\/kaggle\/working\/images\/')\nif not os.path.exists('\/kaggle\/working\/models\/'):\n    os.makedirs('\/kaggle\/working\/models\/')    \nif not os.path.exists(opts['results_save_path']+ 'stage1\/validation\/pure_unet'):\n    os.makedirs(opts['results_save_path'] + 'stage1\/validation\/pure_unet')\nif not os.path.exists(opts['results_save_path']+ 'stage1\/validation\/watershed_unet'):\n    os.makedirs(opts['results_save_path'] + 'stage1\/validation\/watershed_unet')    \n","dc83889c":"train_files = glob('{}*{}'.format(opts['train_dir'], opts['imageType_train']))\ntrain_files_mask = glob('{}*.png'.format(opts['train_label_dir']))\ntrain_files_dis = glob('{}*.png'.format(opts['train_dis_dir']))\ntrain_files_labels = glob('{}*.tif'.format(opts['train_label_masks']))\n\n\ntrain_files.sort()\ntrain_files_mask.sort()\ntrain_files_dis.sort()\ntrain_files_labels.sort()\nprint(\"Total number of training images:\", len(train_files))","c341cc1e":"# we have 10 organ in this dataset\ntrain_files","abf47a60":"# creating 10 folds to perfrom 10 fold cross-validation (for each fold images from the 9 organs are used for training and the images from one organ are used as validation)\n\nfor k in range(opts['k_fold']):\n    if k ==0:\n        fold1 = train_files[0: int(np.round(len(train_files) \/ opts['k_fold']))]\n    else:\n        globals()[\"fold\" + str(k + 1)] = train_files[int(np.round(len (train_files) \/ opts['k_fold']) * k): int(np.round(len(train_files) \/ opts['k_fold']) * (k+1))]\nprint(\"length of each fold:\", len(fold1))\n\n# for binary mask\nfor k in range(opts['k_fold']):\n    if k ==0:\n        fold_mask1 = train_files_mask[0: int(np.round(len(train_files_mask) \/ opts['k_fold']))]\n    else:\n        globals()[\"fold_mask\" + str(k + 1)] = train_files_mask[int(np.round(len (train_files_mask) \/ opts['k_fold']) * k): int(np.round(len(train_files_mask) \/ opts['k_fold']) * (k+1))]\n\n# for distance mask\nfor k in range(opts['k_fold']):\n    if k ==0:\n        fold_dis1 = train_files_dis[0: int(np.round(len(train_files_dis) \/ opts['k_fold']))]\n    else:\n        globals()[\"fold_dis\" + str(k + 1)] = train_files_dis[int(np.round(len (train_files_dis) \/ opts['k_fold']) * k): int(np.round(len(train_files_dis) \/ opts['k_fold']) * (k+1))]\n\n# for label masks (just for evaluation)\nfor k in range(opts['k_fold']):\n    if k ==0:\n        fold_label1 = train_files_labels[0: int(np.round(len(train_files_labels) \/ opts['k_fold']))]\n    else:\n        globals()[\"fold_label\" + str(k + 1)] = train_files_labels[int(np.round(len (train_files_labels) \/ opts['k_fold']) * k): int(np.round(len(train_files_labels) \/ opts['k_fold']) * (k+1))]\n","9bfab8ee":"# main training loop (for all 10 fold cross-validation)\nstart_time = time.time()\ndice_pure_unet = np.zeros([opts['k_fold'],len(fold1)])\nAJI_pure_unet = np.zeros([opts['k_fold'],len(fold1)])\nPQ_pure_unet = np.zeros([opts['k_fold'],len(fold1)])\n\ndice_unet_watershed = np.zeros([opts['k_fold'],len(fold1)])\nAJI_unet_watershed = np.zeros([opts['k_fold'],len(fold1)])\nPQ_unet_watershed = np.zeros([opts['k_fold'],len(fold1)])\n\n\n\nfor K_fold in range(opts['k_fold']):    \n    train = []\n    train_mask = []\n    train_dis = []\n    \n    val = eval('fold' + str(K_fold + 1))\n    val_mask = eval('fold_mask' + str(K_fold + 1))\n    val_dis = eval('fold_dis' + str(K_fold + 1))\n    val_label = eval('fold_label' + str(K_fold + 1))\n\n    for ii in range(opts['k_fold']):\n        if ii != K_fold:\n            train = eval('fold' + str(ii + 1)) + train\n\n    for ii in range(opts['k_fold']):\n        if ii != K_fold:\n            train_mask = eval('fold_mask' + str(ii + 1)) + train_mask\n\n    for ii in range(opts['k_fold']):\n        if ii != K_fold:\n            train_dis = eval('fold_dis' + str(ii + 1)) + train_dis\n\n    if opts['k_fold'] == 1: # for no cross validation the training will be with all training images\n        train = train_files\n        train_mask = train_files_mask\n        train_dis = train_files_dis\n   \n    random.Random(opts['random_seed_num']).shuffle(train)\n    random.Random(opts['random_seed_num']).shuffle(train_mask)\n    random.Random(opts['random_seed_num']).shuffle(train_dis)\n \n\n    ## creating validation data for each fold (just for evaluation)\n    # it is not included in the main training loop for a faster training\n    validation_X = []\n    validation_Y = []\n    validation_DIS = []\n    if len(val)<200: # memory consideration\n        for an in range(len(val)):\n            x = cv2.imread(val[an])\n            x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n\n            aug = albumentation_aug_light(1, opts['crop_size'], opts['crop_size'])\n            #augmented = aug(image=x)\n            #x = augmented['image']\n            if opts['use_pretrained_flag'] == 1:\n                x = preprocess_input(x)\n            img_mask = imread(val_label[an])\n            x = x\/255\n            validation_X.append(x)\n            validation_Y.append(img_mask)\n\n    else:\n        for an in range(200):\n            x = cv2.imread(val[an])\n            x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n\n            aug = albumentation_aug_light(1, opts['crop_size'], opts['crop_size'])\n            #augmented = aug(image=x)\n            #x = augmented['image']\n            if opts['use_pretrained_flag'] ==1:\n                x = preprocess_input(x)\n            img_mask = imread(val_label[an])\n            x = x\/255\n            validation_X.append(x)\n            validation_Y.append(img_mask)\n\n    validation_X = np.array(validation_X)\n    validation_Y = np.array(validation_Y)\n    \n    \n    model_path = opts['models_save_path'] + 'raw_unet_{}.h5'.format(K_fold+1)\n    logger = CSVLogger(opts['models_save_path']+ 'raw_unet_{}.log'.format(K_fold + 1))\n    LR_drop = step_decay_schedule(initial_lr= opts['init_LR'], decay_factor = opts['LR_decay_factor'], epochs_drop = opts['LR_drop_after_nth_epoch'])\n    model_raw = deeper_binary_unet(opts['number_of_channel'], opts['init_LR'])\n    checkpoint = ModelCheckpoint(model_path, monitor='val_dice_coef', verbose=1, save_best_only=True, mode='max', save_weights_only = True)\n    \n    # training\n    history = model_raw.fit_generator(data_gen_heavy(train,\n                                                     train_mask,\n                                                     opts['batch_size'],\n                                                     1,\n                                                     opts['crop_size'], opts['crop_size'],\n                                                     distance_unet_flag=0,\n                                                     augment=True,\n                                                     BACKBONE_model=opts['pretrained_model'],\n                                                     use_pretrain_flag=opts['use_pretrained_flag']),\n                                      validation_data=data_gen_heavy(val,\n                                                                     val_mask,\n                                                                     opts['batch_size'],\n                                                                     1,\n                                                                     opts['crop_size'], opts['crop_size'],\n                                                                     distance_unet_flag=0,\n                                                                     augment=True,\n                                                                     BACKBONE_model=opts['pretrained_model'],\n                                                                     use_pretrain_flag=opts['use_pretrained_flag']),\n                                      validation_steps=1,\n                                      epochs=opts['epoch_num_stage1'], verbose=1,\n                                      callbacks=[checkpoint, logger, LR_drop],\n                                      steps_per_epoch=(len(train) \/\/ opts['batch_size']) \/\/ opts['quick_run'])\n    \n    model_raw.load_weights(opts['models_save_path'] + 'raw_unet_{}.h5'.format(K_fold + 1))\n\n    ## predication on validation set\n    preds_val = model_raw.predict(validation_X, verbose=1, batch_size=1)\n    preds_val_t = (preds_val > opts['treshold']).astype(np.uint8)\n\n\n    for val_len in range(len(preds_val)):\n        # with watershed post processing\n        local_maxi = peak_local_max(np.squeeze(preds_val[val_len]), indices=False,exclude_border=False, footprint=np.ones((15, 15)))\n        markers = ndi.label(local_maxi)[0]\n        labels = watershed(-np.squeeze(preds_val[val_len]), markers,mask = np.squeeze(preds_val_t[[val_len]]))\n        labels[np.squeeze(preds_val_t[[val_len]])==0] = 0\n        \n        # without post processing \n        pred = np.squeeze(preds_val_t[val_len])\n        label_pred = skimage.morphology.label(pred)\n        \n        label_pred = remap_label(label_pred)\n        validation_Y[val_len] = remap_label(validation_Y[val_len])\n        labels = remap_label(labels)\n        \n        imsave(opts['results_save_path'] + 'stage1\/validation\/watershed_unet\/{}.png'.format(get_id_from_file_path(val[val_len], opts['imageType_train'])),labels.astype(np.uint16))\n        imsave(opts['results_save_path'] + 'stage1\/validation\/pure_unet\/{}.png'.format(get_id_from_file_path(val[val_len], opts['imageType_train'])),label_pred.astype(np.uint16))\n\n\n        \n        dice_pure_unet[K_fold, val_len]= get_dice_1(validation_Y[val_len], label_pred)\n        AJI_pure_unet[K_fold, val_len] = get_fast_aji(validation_Y[val_len], label_pred,)\n        PQ_pure_unet[K_fold, val_len] = get_fast_pq(validation_Y[val_len], label_pred,)[0][2]\n        \n        dice_unet_watershed[K_fold, val_len]= get_dice_1(validation_Y[val_len],labels, )\n        AJI_unet_watershed[K_fold, val_len] = get_fast_aji(validation_Y[val_len], labels)\n        PQ_unet_watershed[K_fold, val_len]  = get_fast_pq(validation_Y[val_len], labels)[0][2]\n        \n        \n    print('==========')    \n    print('average dice pure Unet for fold{}:'.format(K_fold), np.mean(dice_pure_unet[K_fold, :]))\n    print('average AJI pure Unet for fold{}:'.format(K_fold), np.mean(AJI_pure_unet[K_fold, :]))\n    print('average PQ pure Unet for fold{}:'.format(K_fold), np.mean(PQ_pure_unet[K_fold, :]))\n\n    print('==========') \n    \n    print('==========')    \n    print('average Dice Unet watershed for fold{}:'.format(K_fold), np.mean(dice_unet_watershed[K_fold, :]))\n    print('average AJI Unet watershed for fold{}:'.format(K_fold), np.mean(AJI_unet_watershed[K_fold, :]))\n    print('average PQ Unet watershed for fold{}:'.format(K_fold), np.mean(PQ_unet_watershed[K_fold, :]))\n    print('==========') \nfinish_time = time.time() \nprint('==========') \nprint('total training time (all 10 folds):',  (finish_time- start_time)\/60, 'minutes')\n","aaef6b23":"import pandas as pd\norgan_name = ['Human_AdrenalGland', 'Human_Larynx', 'Human_LymphNodes', 'Human_Mediastinum', \n              'Human_Pancreas','Human_Pleura', 'Human_Skin', 'Human_Testes' , 'Human_Thymus', 'Human_ThyroidGland']\ndf = pd.DataFrame({'Oragn': organ_name, 'DICE mean': np.mean(dice_pure_unet, axis = 1), \n                   'AJI mean': np.mean(AJI_pure_unet, axis = 1),\n                   'PQ mean': np.mean(PQ_pure_unet, axis = 1)\n                  }) \ndf.to_csv('final_scores_pure_unet.csv', index=False)\nprint('averge overall dice score (pure Unet):',\"{:.2f}\".format(np.mean(dice_pure_unet)*100), '%')\nprint('averge overall AJI score (pure Unet):', \"{:.2f}\".format(np.mean(AJI_pure_unet)*100), '%')\nprint('averge overall PQ score (pure Unet):', \"{:.2f}\".format(np.mean(PQ_pure_unet)*100), '%')\ndf","efc4d840":"import pandas as pd\norgan_name = ['Human_AdrenalGland', 'Human_Larynx', 'Human_LymphNodes', 'Human_Mediastinum', \n              'Human_Pancreas','Human_Pleura', 'Human_Skin', 'Human_Testes' , 'Human_Thymus', 'Human_ThyroidGland']\ndf = pd.DataFrame({'Oragn': organ_name, 'DICE mean': np.mean(dice_unet_watershed, axis = 1), \n                   'AJI mean': np.mean(AJI_unet_watershed, axis = 1),\n                   'PQ mean': np.mean(PQ_unet_watershed, axis = 1),\n                  }) \ndf.to_csv('final_scores_unet_watershed.csv', index=False)\nprint('averge overall dice score (Unet + watershed):', \"{:.2f}\".format(np.mean(dice_unet_watershed)*100),'%')\nprint('averge overall AJI score (Unet + watershed):', \"{:.2f}\".format(np.mean(AJI_unet_watershed)*100),'%')\nprint('averge overall PQ score (Unet + watershed):', \"{:.2f}\".format(np.mean(PQ_unet_watershed)*100),'%')\n\ndf","ab601fcc":"np.save('dice_pure_unet.npy', dice_pure_unet)\nnp.save('AJI_pure_unet.npy', AJI_pure_unet)\nnp.save('PQ_pure_unet.npy', PQ_pure_unet)\n\nnp.save('dice_unet_watershed.npy', dice_unet_watershed)\nnp.save('AJI_unet_watershed.npy', AJI_unet_watershed)\nnp.save('PQ_unet_watershed.npy', PQ_unet_watershed)","131c349a":"defining functions that are used in training and testing","35a74fb7":"Here you set all parameters thay you may need for training and testing","0951d530":"* evaluation indexes (from the hovernet paper: https:\/\/github.com\/vqdang\/hover_net\/blob\/master\/src\/metrics\/stats_utils.py)","6e06715c":"importing required libraries","4b0927c1":"# U-Net standard model (with binary labels)"}}