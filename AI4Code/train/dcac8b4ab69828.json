{"cell_type":{"085ef12c":"code","6aad625d":"code","f96e05cb":"code","5335d3f3":"code","d2850d14":"code","80f285c8":"code","cd3c4d9c":"code","0605e880":"code","ba552d82":"code","b8cbcc7e":"code","23a63f53":"code","bf09e881":"code","0f2cb42b":"markdown","50652f77":"markdown","ef1af413":"markdown","f2052cab":"markdown","4e457575":"markdown","d89a0945":"markdown","e5a265b0":"markdown","91bc4ead":"markdown","0b34796d":"markdown","90fdfcae":"markdown","cffb8d67":"markdown","9df67285":"markdown","48ae50c8":"markdown","c3cd812b":"markdown"},"source":{"085ef12c":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport os\nimport glob\nimport itertools\nimport collections\n\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport numpy as np\nimport torch\nimport imagehash\n\nimport matplotlib.pyplot as plt\n\n\ntrain = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')","6aad625d":"def run():\n\n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n    ]\n\n    petids = []\n    hashes = []\n    for path in tqdm(glob.glob('..\/input\/petfinder-pawpularity-score\/train\/*.jpg')):\n\n        image = Image.open(path)\n        imageid = path.split('\/')[-1].split('.')[0]\n\n        petids.append(imageid)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n\n    return petids, np.array(hashes)\n\n%time petids, hashes_all = run()","f96e05cb":"hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()","5335d3f3":"%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()\/256 for i in range(hashes_all.shape[0])])","d2850d14":"def show_pairs(lower_sim=0.0, upper_sim=1.0, max_shown=100):\n    indices1 = np.where((sims > lower_sim) & (sims <= upper_sim))\n    indices2 = np.where(indices1[0] != indices1[1])\n    dups = {tuple(sorted([petids[index1], petids[index2]])): sims[index1, index2] \n                for index1, index2 in zip(indices1[0][indices2], indices1[1][indices2])}\n    print('Found %d pairs' % len(dups))\n    \n    cnt = 1\n    for (id1, id2), sim in dups.items():\n        path1 = f'..\/input\/petfinder-pawpularity-score\/train\/{id1}.jpg'\n        path2 = f'..\/input\/petfinder-pawpularity-score\/train\/{id2}.jpg'\n        pawp1 = train[train['Id'] == id1]['Pawpularity'].iloc[-1]\n        pawp2 = train[train['Id'] == id2]['Pawpularity'].iloc[-1]\n\n        image1 = cv2.imread(path1)\n        image2 = cv2.imread(path2)\n        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n\n        fig, axes = plt.subplots(nrows=1, ncols=2)\n        fig.set_size_inches(12, 6)\n        axes[0].title.set_text(f'Pawpularity: {pawp1} \\n ID: {id1}')\n        axes[0].imshow(image1)\n        axes[1].title.set_text(f'Pawpularity: {pawp2} \\n ID: {id2}')\n        axes[1].imshow(image2)\n        fig.suptitle(f'Simularity: {sim}')\n        plt.show()\n        \n        if cnt >= max_shown:\n            break\n        \n        cnt += 1\n    \n    return dups","80f285c8":"def offdiagonal(X, axis1, axis2):\n    X = np.moveaxis(X, (axis1, axis2), (-2, -1))\n    *s, n, _ = X.shape\n    X = X.reshape(*s, n*n)[..., :-1].reshape(*s, n-1, n+1)[..., 1:].reshape(*s, n, n-1)\n    return np.moveaxis(X, (-2, -1), (axis1, axis2))\n\n\nplt.figure(figsize=(12, 4))\nplt.title('Distribution of similarity')\nplt.boxplot(offdiagonal(sims, 0, 1).flatten(), vert=False);","cd3c4d9c":"dups_90_00 = show_pairs(0.9, 1.0, max_shown=5)","0605e880":"dups_85_90 = show_pairs(0.85, 0.9, max_shown=5)","ba552d82":"dups_80_85 = show_pairs(0.80, 0.85, max_shown=5)","b8cbcc7e":"!mkdir ..\/working\/petfinder-pawpularity-score-clean\n!cp -r ..\/input\/petfinder-pawpularity-score\/* ..\/working\/petfinder-pawpularity-score-clean","23a63f53":"ids1 = np.array(list(dups_90_00.keys()))[:, 0]\nids2 = np.array(list(dups_90_00.keys()))[:, 1]\n\ntrain_new = train[~train[\"Id\"].isin(ids2)]\ntrain_new = train_new.reset_index(drop=True)\n\ntrain_new.to_csv('..\/working\/petfinder-pawpularity-score-clean\/train.csv', \n                 index=False)\ntrain_new","bf09e881":"for id1, id2 in dups_90_00.keys():\n    path2 = f'..\/working\/petfinder-pawpularity-score-clean\/train\/{id2}.jpg'\n    os.remove(path2)","0f2cb42b":"In this range, almost all images appear to be duplicates. However, for those that do not have a similarity of 1, there must have been a very slight modification to the image. The most obvious pair is the one below, where you can observe that the right image has a slightly higher contrast.\n\n![](https:\/\/i.postimg.cc\/KYnpctkn\/pair1.png)","50652f77":"## Similarity 0.85 - 0.9\n- 5 pairs in this range\n- Interesting patterns can be seen.","ef1af413":"In this box plot, we can see isolated clusters around 1, which we assume to be duplicate images.\n\nNow, let's look at the images for each threshold range of similarity.","f2052cab":"Calculate hash values of every train image. This takes around 10 minutes in a Kaggle Notebook.","4e457575":"# PetFinder | Identify Duplicates and Share Findings\n\n![](https:\/\/i.postimg.cc\/W1TZZrhN\/download-5.png)\n\nAs mentioned by the admin in the [discussion](https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/278309), there are duplicate images in the dataset. In this notebook, I will try to:\n* identify those duplicates\n* share the findings\n* create a dataset without the duplicates\n\nThe findings are also summarized in [Discussion](https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/278497).\n\nThe method for identifying duplicates is based on the [notebook \"Let's find out duplicate images with imagehash\"](https:\/\/www.kaggle.com\/appian\/let-s-find-out-duplicate-images-with-imagehash) shared by [Appian](https:\/\/www.kaggle.com\/appian) for the previous PetFinder competition. This method uses image hashes, and is very simple yet powerful.\n\n# Table of Contents\n* [Identify duplicates](#1)\n* [Share the findings](#2)\n* [Create new dataset](#3)","d89a0945":"Define a function that allow us to display and retrieve the pairs with in a given threshold range of similarity.","e5a265b0":"<a id=\"2\"><\/a>\n# Share the findings\n\nFirst, let's look at the distribution of similarity using a box plot. \n\nNote that the similarity is expressed in matrix form, and that we are only interested in the non-diagonal component, since the diagonal component is always 1, which is the similarity to itself.","91bc4ead":"<a id=\"1\"><\/a>\n# Identify duplicates\nAgain, this method is based on [Let's find out duplicate images with imagehash](https:\/\/www.kaggle.com\/appian\/let-s-find-out-duplicate-images-with-imagehash).","0b34796d":"## Similarity 0.8-0.85\n- 174 pairs in this range\n- Most of the pairs are completely different, but some interesting patterns can be seen.","90fdfcae":"### Interesting patterns\n- The same pet photographed at a slight different time  \n\n![](https:\/\/i.postimg.cc\/wvgf13Ln\/pairs2.png)  \n![](https:\/\/i.postimg.cc\/7Lf7m4Db\/pairs3.png)\n\n\n- Cropped\n\n![](https:\/\/i.postimg.cc\/Pxy6YhMJ\/pairs4.png)  \n![](https:\/\/i.postimg.cc\/zBYBKYGs\/pairs5.png)","cffb8d67":"<a id=\"3\"><\/a>\n# Create new dataset\nHere, I create a dataset that excludes only obvious duplicates with a similarity of 0.9 or higher.   \nYou can make your own dataset with different thresholds or processing of Pawpularity, too.\n\nThe dataset is also uploaded as a Kaggle Dataset. Feel free to use it.  \nhttps:\/\/www.kaggle.com\/schulta\/petfinder-pawpularity-score-clean","9df67285":"### Interesting patterns\n- Different pets with the same background and the same frame  \n![](https:\/\/i.postimg.cc\/Zn0LNNRs\/download.png)\n\n- Similar pets with similar background and the same frame  \n![](https:\/\/i.postimg.cc\/wxPXP73H\/download-1.png)\n\n- Cropped  \n![](https:\/\/i.postimg.cc\/br2t89dP\/download-2.png)\n\n- Different pets with the same template  \n![](https:\/\/i.postimg.cc\/P51Q1TXH\/download-4.png)","48ae50c8":"Calculate similarity (normalized to 0-1 range) between all image pairs.","c3cd812b":"## Similarity 0.9 - 1\n\n* 27 pairs in this range\n* Most pairs are idendical, at least in appearance"}}