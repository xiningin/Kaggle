{"cell_type":{"938b8285":"code","9024ac2c":"code","30dab411":"code","e84342f3":"code","9b7c4c7c":"code","a395ba8e":"code","d037490a":"code","098e34dd":"code","97cce224":"code","2f67045c":"code","053c0e8b":"code","207f3794":"code","70e34e13":"code","fa3ce46f":"code","eaaea315":"code","43b0d138":"markdown","d2821264":"markdown","f108ee4b":"markdown","93dec609":"markdown","492b2cdd":"markdown","77e68de8":"markdown"},"source":{"938b8285":"import random\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, AdamW, get_scheduler","9024ac2c":"config = {\n    'fold_num': 5,\n    'seed': 1234,\n    #'model': 'roberta-base',\n    #'model': '..\/input\/robertalarge',\n    'model': 'allenai\/longformer-base-4096',\n    #'model': 'allenai\/longformer-large-4096',\n    'max_len': 1024,\n    'epochs': 5,\n    'train_bs': 6,\n    'valid_bs': 6,\n    'lr': 3e-5,\n    'num_workers': 0,\n    'weight_decay': 1e-2,\n    'num_warmup_steps': 1000,\n    'lr_scheduler_type': 'linear',\n    'gradient_accumulation_steps': 1,\n}","30dab411":"labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim',\n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\nlabels2index = {\n    'Lead': 1, 'Position': 3, 'Claim': 5, 'Counterclaim': 7, 'Rebuttal': 9, 'Evidence': 11, 'Concluding Statement': 13\n}\n","e84342f3":"def set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nset_seed(config['seed'])\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","9b7c4c7c":"#tokenizer = AutoTokenizer.from_pretrained(config['model'], add_prefix_space=True)\ntokenizer = AutoTokenizer.from_pretrained('..\/input\/test-notebook\/roberta_trained', add_prefix_space=True)","a395ba8e":"class MyDataset(Dataset):\n    def __init__(self, df, phase='Train'):\n        self.df = df\n        self.phase = phase\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        text = self.df.text.values[idx]\n        if self.phase == 'Train':\n            label = self.df.tagging.values[idx]\n            return {'text': text, 'label': label}\n        else:\n            return {'text': text}\n\n\ndef collate_fn(data):\n    input_ids, attention_mask = [], []\n    text = [item['text'] for item in data]\n    tokenized_inputs = tokenizer(\n        text,\n        max_length=config['max_len'],\n        padding='max_length',\n        truncation=True,\n        is_split_into_words=True,\n        return_tensors='pt'\n    )\n\n    if 'label' in data[0].keys():\n        label = [item['label'] for item in data]\n        tokenized_inputs['labels'] = torch.LongTensor(label)\n\n    return tokenized_inputs","d037490a":"#model = AutoModelForTokenClassification.from_pretrained(config['model'], num_labels=15).to(device)\n#model.load_state_dict(torch.load('..\/input\/feedback-prize-train\/roberta_trained\/pytorch_model.bin'))\nmodel = AutoModelForTokenClassification.from_pretrained('..\/input\/feedback-prize-train\/roberta_trained\/', num_labels=15).to(device)","098e34dd":"test_df = pd.read_csv('..\/input\/feedback-prize-2021\/sample_submission.csv')\ntest_df.head(5)","97cce224":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('..\/input\/feedback-prize-2021\/test'))):\n    test_names.append(f.replace('.txt', ''))\n    with open('..\/input\/feedback-prize-2021\/test\/' + f, 'r', encoding='utf-8') as f:\n        text = ''\n        for line in f.readlines():\n            #text += line.replace('\\n', '').replace('\\xa0', '')\n            text += line.replace('\\n', ' ')\n        test_texts.append(text)\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\ntest_texts['text'] = test_texts['text'].apply(lambda x: x.split())\ntest_texts","2f67045c":"test_dataset = MyDataset(test_texts, phase='Test')\ntest_iter = DataLoader(test_dataset, batch_size=config['valid_bs'], collate_fn=collate_fn, shuffle=False,\n                        num_workers=config['num_workers'])","053c0e8b":"y_pred = []\n\nwith torch.no_grad():\n    model.eval()\n    tk = tqdm(test_iter, total=len(test_iter), position=0, leave=True)\n    for step, batch in enumerate(tk):\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        output = model(input_ids=batch['input_ids'],\n                       attention_mask=batch['attention_mask']).logits\n\n        y_pred.extend(output.argmax(-1).cpu().numpy())\n        \ny_pred = np.array(y_pred)","207f3794":"y_pred[0][:200]","70e34e13":"final_preds = []\n\nfor i in tqdm(range(len(test_texts))):\n    idx = test_texts.id.values[i]\n    pred = ['']*(len(y_pred[i])-2)\n\n    for j in range(1, len(y_pred[i])-1):\n        pred[j-1] = labels[y_pred[i][j]]\n\n    pred = [x.replace('B-','').replace('I-','') for x in pred]\n    \n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n        if cls == 'O':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'O' and cls != '' and end - j > 10:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end\n        \nfinal_preds[0]","fa3ce46f":"sub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns\nsub.to_csv('submission.csv', index=False)","eaaea315":"sub","43b0d138":"## A Pytorch version NER Baseline [LB: 0.545]\n### Part of this kernel is from zzy's [Pytorch NER infer](https:\/\/www.kaggle.com\/zzy990106\/pytorch-ner-infer)\n\n### Training: [Feedback Prize Train](https:\/\/www.kaggle.com\/hjhgjghhg\/feedback-prize-train\/edit\/run\/82681035)\n\n### Infer: This kernel\n\n### Upvote if you find this kernel useful!\ud83e\udd17","d2821264":"## Load Model","f108ee4b":"## Load Test Data","93dec609":"## Predict","492b2cdd":"## Set Seed","77e68de8":"## Config"}}