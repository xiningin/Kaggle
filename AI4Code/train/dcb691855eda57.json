{"cell_type":{"c4fa081e":"code","ae9cc183":"code","f6926286":"code","2dd2c864":"code","f4155f58":"code","8993d230":"markdown","5c79c27a":"markdown","16319981":"markdown","9757675e":"markdown"},"source":{"c4fa081e":"import os,json\nfrom time import time\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n","ae9cc183":"data_path = '..\/input'\nsubmission_path = '.'\ndef load_df(file):\n    print('loading file {} >>>'.format(file))\n    df = pd.read_csv(os.path.join(data_path,file))\n    print('file dimension:', df.shape)\n#     display(df.head())\n    return df\n\ndef load_json(file):\n    with open(os.path.join(data_path,file)) as json_file:  \n        attr_map = json.load(json_file)\n    return attr_map","f6926286":"# update name to map to submission format\ndef expand_attr(df, attrs):\n    r = []\n    for col in attrs:\n        sub_df = df[df[col].notna()]\n        tmp = sub_df['itemid'].astype(str).apply(lambda s: s+'_'+col)\n        try:\n            sub_df[col] = sub_df[col].astype(int).astype(str)\n        except:\n            sub_df[col] = sub_df[col].astype(str)\n        tmp = pd.concat([tmp,sub_df[col]], axis=1)\n        tmp.columns = ['id','tagging']\n        r.append(tmp)\n#         display(tmp.head(2))\n    return pd.concat(r)\n\n\ndef create_submit(submit_df, pred_df):\n    return pd.concat([submit_df,pred_df])","2dd2c864":"%%time\nsubmit_df = pd.DataFrame([],columns=['id','tagging'])\n\nfor cat in ['beauty','mobile','fashion']:\n    print('#'*30,'Category:',cat,'#'*30)\n    train = load_df(cat+'_data_info_train_competition.csv')\n    test = load_df(cat+'_data_info_val_competition.csv')    \n    attr_info = load_json(cat+'_profile_train.json')\n    \n    for col in attr_info.keys():\n        print('\\t processing attribute:',col)\n        pipeline = Pipeline([\n            ('vect', CountVectorizer(min_df=1,ngram_range=(1,3))),\n            ('clf', LogisticRegression()),\n        ])\n        \n        parameters = {\n            'vect__ngram_range': [(1,3),(1,5)],\n        }\n\n        # fit first model\n        train_wo_na = train[~train.isna()[col]]\n        pipeline.fit(train_wo_na['title'], train_wo_na[col])\n        \n        # grid search for best estimator\n        t0 = time()\n        grid_search = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=2,scoring='accuracy')\n        grid_search.fit(train_wo_na['title'], train_wo_na[col])\n        \n        print(\"done in %0.3fs\" % (time() - t0))\n        print(grid_search.cv_results_['mean_test_score'])\n\n        print(\"Best score: %0.5f\" % grid_search.best_score_)\n        print(\"Best parameters set:\")\n        best_parameters = grid_search.best_estimator_.get_params()\n        for param_name in sorted(parameters.keys()):\n            print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n        \n        # predict on test dataset, select top 2, instead of just one.\n        estimator = grid_search.best_estimator_\n        probs = estimator.predict_proba(test['title'])\n        best_2 = pd.DataFrame(np.argsort(probs, axis=1)[:,-2:],columns=['top2','top1'])\n        test[col] = best_2.apply(lambda row: ' '.join(estimator.classes_[[row['top1'],row['top2']]].astype(int).astype(str)) ,axis=1)\n        \n        # save models\n#         joblib.dump(pipeline, os.path.join(checkpoints_path,'model_{}_{}.ckpt'.format(cat,col)))\n        \n    display(test.head(2))\n    test.fillna(0,inplace=True)\n    pred_df = expand_attr(test, attr_info); print(pred_df.shape)\n    submit_df = create_submit(submit_df, pred_df); print(submit_df.shape)\n    ","f4155f58":"submit_df.to_csv(os.path.join(submission_path,'baseline_top2.csv'),index=False)","8993d230":"Baseline + Top 2 prediction","5c79c27a":"This solution only used the most common **CountVectorizer**, **LogisticRegression** with simple Gridsearch. Default parameters are taken except for `ngram_range`. \n\nThe result can be further improved with model stacking and more sophisticated feature creation. ","16319981":"helper functions","9757675e":"One thing our team has learnt is never underestimating the power of conventional models, like Logistics Regression. We believe simple models should always be attempted before fancy neural nets and deeplearning. \n\nHere, we demonstrate how to use simply CountVectorizer + Logistic Regression to achieve near top 10 score."}}