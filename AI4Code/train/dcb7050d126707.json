{"cell_type":{"bfcdcef1":"code","ca6d57e6":"code","a272d316":"markdown","d25b0239":"markdown"},"source":{"bfcdcef1":"## install detoxify from dataset\n!cp -r ..\/input\/detoxify-sourcemodels\/detoxify .\n!pip install -q .\/detoxify\n!rm -r .\/detoxify\n\n\n## copy detoxify pretrained models and transformers configuration files from dataset to local caches\n!mkdir -p  \/root\/.cache\/torch\/hub\/checkpoints\n!mkdir -p  \/root\/.cache\/huggingface\/transformers\n!cp -r ..\/input\/detoxify-sourcemodels\/torch\/hub\/checkpoints \/root\/.cache\/torch\/hub\n!cp -r ..\/input\/detoxify-sourcemodels\/huggingface\/transformers \/root\/.cache\/huggingface\n\n\n# Setting environment variable TRANSFORMERS_OFFLINE=1 will tell Transformers to use local files only and will not try to look things up.\n# It\u2019s possible to run Transformers in a firewalled or a no-network environment or in a Kaggle inference kernel !\nimport os\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"","ca6d57e6":"from detoxify import Detoxify\n\n# each model takes in either a string or a list of strings\nresults = Detoxify('original').predict('example text')\nresults = Detoxify('unbiased').predict(['example text 1','example text 2'])\nresults = Detoxify('multilingual').predict(['example text','exemple de texte','texto de ejemplo','testo di esempio','texto de exemplo','\u00f6rnek metin','\u043f\u0440\u0438\u043c\u0435\u0440 \u0442\u0435\u043a\u0441\u0442\u0430'])\n\n\n# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\nmodel = Detoxify('original', device='cuda')\n\n\n# optional to display results nicely (will need to pip install pandas)\n\nimport pandas as pd\n\npd.DataFrame(results)","a272d316":"#### Quick prediction\n\nNow you can use pretrained Detoxify models without internet connection.\n\nSee https:\/\/github.com\/unitaryai\/detoxify for details","d25b0239":"## Prepare environment"}}