{"cell_type":{"0f274de7":"code","0fa60956":"code","62782c1b":"code","19a3ca77":"code","f2d854b7":"code","cd6266f6":"code","0e52f51e":"code","deff5cdc":"code","e7eaeb5d":"code","db3bce60":"code","284e5059":"code","af11fef8":"code","fa00f5fc":"code","127cbaab":"code","160125f9":"markdown","0f42fae0":"markdown","288e1585":"markdown","98ab2040":"markdown","eb4b6e55":"markdown","1c3fda6c":"markdown","cedfa02a":"markdown","ee8208d2":"markdown"},"source":{"0f274de7":"import numpy as np\nimport pandas as pd\n\n\nimport os\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\n## removes tensorflow warning\nimport tensorflow as tf \n\nimport IPython.display as display\n\n","0fa60956":"print(tf.__version__)\nprint(\"Num GPUs available : \", len(tf.config.list_physical_devices('GPU')))\n\nBATCH = 32\nNB_CLASS = 104\nEPOCH = 18\nTRAIN_IMAGE_NUMBER = 12753\nVAL_IMAGE_NUMBER = 3712\nTEST_IMAGE_NUMBER = 7382","62782c1b":"local_path = os.path.join('\/kaggle','input','tpu-getting-started','tfrecords-jpeg-224x224')\n\n\ntrain_filenames = [ fileu for fileu in glob(os.path.join(local_path,'train\/*'))]\nval_filenames = [ fileu for fileu in glob(os.path.join(local_path,'val\/*'))]\ntest_filenames = [ fileu for fileu in glob(os.path.join(local_path,'test\/*'))]\n\n\nprint(f'Total Training TFRECORD FILES : {len(train_filenames)}')\nprint(f'Total Validation TFRECORD FILES : {len(val_filenames)}')\nprint(f'Total Testing TFRECORD FILES : {len(test_filenames)}')","19a3ca77":"AUTO = tf.data.experimental.AUTOTUNE\nignore_order = tf.data.Options()\n\nignore_order.experimental_deterministic = False\n","f2d854b7":"def decode_image(image):\n    \n    image = tf.image.decode_jpeg(image,channels=3)\n    image = tf.cast(image,tf.float32)\n    image = tf.reshape(image,[224,224,3])\n    \n    return image\n\n\ndef read_training_tfrecord(example_proto):\n    image_feature_description = {\n        'class' : tf.io.FixedLenFeature([] , tf.int64),\n        'image' : tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example_proto, image_feature_description)\n    \n    image = decode_image(example['image'])\n    \n    label = tf.cast(example['class'], tf.int32)\n    \n    label = tf.one_hot(label, NB_CLASS)\n        \n        \n    return image, label\n\n\ndef read_testing_tfrecord(example_proto):\n    \n    image_feature_description = {\n        'id' : tf.io.FixedLenFeature([], tf.string),\n        'image' : tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example_proto, image_feature_description)\n    \n    image = decode_image(example['image'])\n    \n    ids = example['id']\n    \n    return image, ids\n    \n    \n ## We do not want to the data to be shuffled for testing, so we separate process   \ndef load_dataset(filenames,style):\n    \n    \n    dataset = tf.data.TFRecordDataset(filenames,num_parallel_reads=AUTO)\n    \n    \n    if style =='training' or style=='validation' : \n        \n        dataset = dataset.with_options(ignore_order)\n    \n        dataset = dataset.map(read_training_tfrecord)\n            \n        dataset = dataset.cache().shuffle(1000).prefetch(buffer_size=32)\n\n        dataset = dataset.batch(BATCH)\n        \n    else :\n        \n        ignore_order.experimental_deterministic = True\n        \n        dataset = dataset.with_options(ignore_order)\n        \n        dataset = dataset.map(read_testing_tfrecord)\n        \n        dataset = dataset.prefetch(buffer_size=32).batch(BATCH)\n        \n    \n    return dataset\n\n    ","cd6266f6":"train_dataset = load_dataset(train_filenames,style = 'training')\n\nval_dataset = load_dataset(val_filenames, style = 'validation')\n\n\ntest_dataset = load_dataset(test_filenames, style = 'testing')","0e52f51e":"def display_batch(image_batch,label_batch):\n    plt.figure(figsize=(10,10))\n    \n    for k in range(16):\n        \n        ax = plt.subplot(4,4,k+1)\n        \n        plt.imshow(image_batch[k] \/255.)\n        \n        \n        #plt.title('Classes : '+ str(id_batch[k]))\n        #because one_hot_encoding applied\n        plt.axis('off')\n\nimage_batch, label_batch = next(iter(train_dataset))     \ndisplay_batch(image_batch, label_batch)\n        ","deff5cdc":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.optimizers import schedules\n\nimport tensorflow_addons as tfa\n\n\n\n## Possible imporvements\n\n# - Using sparseCorssEntropy instead of hot encoding\n# - training also the base model\n# - Solid LearningRateScheduler","e7eaeb5d":"\ndef build_model():\n    \n    base_model = tf.keras.applications.Xception(\n        include_top=False,\n        weights=\"imagenet\",\n        input_tensor=None,\n        input_shape=(224,224,3),\n    )\n    \n    base_model.trainable = False\n        \n    data_aug = Sequential([\n        \n        layers.Rescaling(1.\/127.5, offset=-1),\n        \n        layers.RandomFlip(\"horizontal_and_vertical\"),\n        \n        layers.RandomRotation(0.3)])\n    \n    model = Sequential([\n        \n        data_aug,\n              \n        base_model,\n        \n        layers.GlobalAveragePooling2D(),\n    \n        layers.Dense(1024, activation = 'relu'),\n    \n        layers.Dropout(0.2),\n        \n        layers.Dense(256, activation = 'relu'),\n        \n        layers.Dropout(0.2),\n    \n        layers.Dense(NB_CLASS,activation = 'softmax')\n    ])\n    \n\n    \n    return model","db3bce60":"class PrintLR(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,model.optimizer.lr.numpy()))\n##not really usefull","284e5059":"def training():\n\n    init_lr = 0.001\n\n    \n    lr_scheduler = schedules.ExponentialDecay(\n        init_lr, decay_steps=int(np.ceil(TRAIN_IMAGE_NUMBER\/BATCH)), decay_rate=0.94, staircase=True)\n\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n        patience=3, restore_best_weights=True)\n\n    checkpoint_path = '.\/training_1\/cp.ckpt'\n\n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n        checkpoint_path,save_weights_only=True, save_best_only=True, verbose = 1\n    )\n\n    with tf.device('\/device:GPU:0'):\n        model = build_model()\n\n        model.compile(optimizer=keras.optimizers.Adam(learning_rate = lr_scheduler),\n                      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n                      metrics=tfa.metrics.F1Score(num_classes=NB_CLASS, average = 'macro', threshold=0.5)\n        )\n   \n        \n    history = model.fit(\n        train_dataset,\n        epochs=EPOCH,\n        validation_data=val_dataset,\n        callbacks=[checkpoint_cb, early_stopping_cb],\n)\n    \n    return model","af11fef8":"def test(model):\n    testing_image = test_dataset.map(lambda image, ids : image)\n\n    testing_ids = test_dataset.map(lambda image, ids: ids).unbatch()\n\n\n    test_ids = next(iter(testing_ids.batch(TEST_IMAGE_NUMBER))).numpy().astype('U')\n\n\n    predictions_raw = model.predict(testing_image, batch_size = BATCH)\n\n    pred = np.argmax(predictions_raw, axis=-1)\n\n\n    predictions_raw = model.predict(testing_image, batch_size = BATCH)\n\n    pred = np.argmax(predictions_raw, axis=-1)\n    \n    \n    submission_df = pd.DataFrame(data ={'id': test_ids, 'label' : pred} ).set_index('id')\n\n\n    submission_df.to_csv('submission.csv')\n\n    return\n","fa00f5fc":"model = training()","127cbaab":"test(model)","160125f9":"### SETUP for TPU utilisation\n\n\n1. `num_parallel_reads=AUTO` instructs the API to read from multiple files if available. It figures out how many automatically.\n2. `experimental_deterministic = False` disables data order enforcement. We will be shuffling the data anyway so order is not important. With this setting the API can use any TFRecord as soon as it is streamed in.\n3. However for predictions we should keep the order so this variable must be set to `True`","0f42fae0":"### Building model\n\n\nFor the model, let's use Xception pre-trained model on imageNet, Inception module is really powerful.  \nConcerning top layers, no real research\/comparison were performed. So one way to improve the model would be to try different architecture. ","288e1585":"1. Early Stopping isn't really useful here, because i didn't trained on many epoch\n2. The ExponnetialDecay is also not really useful, however one must note that even if Adam optimizer modify itself learning rate, adding a scheduler fixes the upper limit of learning rate modified \n3. About the metric, again it is not useful to work with F1_score directly, however it gives a glimpse of your model capacity ( because this is the exact metric used by kaggle on this competition","98ab2040":"## Loading files","eb4b6e55":"## Model Predictions","1c3fda6c":"## Simple Visualisation","cedfa02a":"Let's first define some variables, counting images from TFRecords might be fastidious, so i directly computed sizes\n","ee8208d2":"## Librairies"}}