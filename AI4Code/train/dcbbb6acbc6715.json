{"cell_type":{"d766e7bc":"code","9d6a67a5":"code","d3991dea":"code","78060b30":"code","71220243":"code","d19ffba4":"code","59bc3443":"code","5faec8a4":"code","fcb89705":"code","a8717563":"code","a70e621b":"code","da5451fb":"code","6b61d04b":"code","9b9cb9d3":"code","484314a7":"code","1387fb7b":"code","7d9eea16":"code","49d39653":"code","5a2f1f54":"code","7c993321":"code","c7b58002":"code","9ac5ce67":"markdown","196893e0":"markdown","35a601f8":"markdown","82890918":"markdown","5c47dbf2":"markdown","0a4e548a":"markdown","0de426ce":"markdown","0ec78e72":"markdown","cc6f2416":"markdown","00853ee9":"markdown","ee90a03e":"markdown","cd985aa5":"markdown","5d8f1efc":"markdown","e17c05c2":"markdown","2d63ac71":"markdown","72be0a9d":"markdown","e5cab364":"markdown","cc0f409e":"markdown","efcdb413":"markdown","f7682d02":"markdown","17e93bd0":"markdown","5448016b":"markdown"},"source":{"d766e7bc":"#importing the required\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout","9d6a67a5":"DATADIR = \"..\/input\/cat-and-dog\/training_set\/training_set\"\nCATEGORIES=[\"cats\",\"dogs\"]\nfor category in CATEGORIES: \n    count=0\n    path = os.path.join(DATADIR,category) \n    for img in os.listdir(path):  \n        img_array = cv2.imread(os.path.join(path,img) ,cv2.COLOR_RGB2BGR)  \n        plt.imshow(img_array, cmap='gray') \n        plt.show()  # display!\n        count=count+1\n\n        if count==3:\n            break  ","d3991dea":"training_data=[]\nIMG_SIZE=120\n\ndef create_training():\n    for category in  CATEGORIES:#cats and dogs\n        path=os.path.join(DATADIR,category)#directory+cats\/dogs\n        class_num=CATEGORIES.index(category)#Convert the labels to 1 and 0\n        for img in os.listdir(path): # iterate over each image per dogs and cats\n            try:\n                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)#read in as grayscale image\n                new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))#convert to array\n                training_data.append([new_array, class_num])#append separately the features and lables into training data\n            except Exception as e:\n                pass\n                \ncreate_training()","78060b30":"TESTDIR=\"..\/input\/cat-and-dog\/test_set\/test_set\"\ntest_data=[]\n\ndef create_test():\n    for category in  CATEGORIES:\n        path=os.path.join(TESTDIR,category)\n        class_num=CATEGORIES.index(category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n                new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n                test_data.append([new_array, class_num])\n            except Exception as e:\n                pass\n                \ncreate_test()","71220243":"import random\nrandom.shuffle(training_data)","d19ffba4":"X=[]\ny=[]\n\n\nfor features, label  in training_data:\n        X.append(features)#extract the feature matrix\n        y.append(label)#extract the corresponding label\n        \nX_test=[]\ny_test=[]\n\n\nfor features, label  in test_data:\n        X_test.append(features)#extract the feature matrix\n        y_test.append(label)#extract the corresponding label ","59bc3443":"X=tf.keras.utils.normalize(X, axis=1)","5faec8a4":"X_test=tf.keras.utils.normalize(X_test, axis=1)","fcb89705":"X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny = np.array(y)\nX_test = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny_test = np.array(y)","a8717563":"model = Sequential()\n\n#Convulation layer 1\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=X.shape[1:]))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.2))\n\n#Convulation layer 2\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.2))\n\n#converting to 1D before passing to dense laye\nmodel.add(Flatten())\n\n#Dense Layer\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dropout(0.5))\n\n#Output layer\nmodel.add(Dense(1, activation='sigmoid'))\n                     ","a70e621b":"from tensorflow import keras","da5451fb":"from tensorflow.keras.optimizers import Adam\nopt = Adam(lr=0.001)","6b61d04b":"model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])","9b9cb9d3":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')","484314a7":"model.summary()","1387fb7b":"hist=model.fit(X, y, epochs=15, validation_data=(X_test, y_test), batch_size=32, callbacks=[early, checkpoint])","7d9eea16":"import matplotlib.pyplot as plt\n\nplt.plot(hist.history[\"accuracy\"])\nplt.plot(hist.history['val_accuracy'])\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\",\"Loss\",\"Validation Loss\"])\nplt.show()","49d39653":"model.save(\"cat-and-dog-CNN\")#save the model","5a2f1f54":"CATEGORIES=[\"DOG\", \"CAT\"]\n\n#function to reshape image to feed into prediction \ndef prepare(filepath):\n    X_predict=[]\n    IMG_SIZE = 120  \n    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)#read in the image\n    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))#resize the image\n    for features in new_array:\n        X_predict.append(features)#append the features \n    X_predict=tf.keras.utils.normalize(X, axis=1)\n    X_predict = np.array(X_predict).reshape(-1, IMG_SIZE, IMG_SIZE, 1)#reshape the image for TF\n    return X_predict#return prediction\n\n","7c993321":"path=\"..\/input\/custom2\/apN288W_460s.jpg\" #image of cat\nprediction = model.predict([prepare(path)])#pass the image into prepare function\nimg=cv2.imread(path, cv2.COLOR_RGB2BGR)\nplt.imshow(img, cmap='gray')  \nplt.show()\nprint(CATEGORIES[int(prediction[0][0])])#since the prediction is in 1 or 0 we will print the corresponding category  ","c7b58002":"path=\"..\/input\/custom2\/1-5ee32feff0aa7__700.jpg\" #image of dog\nprediction = model.predict([prepare(path)])\nimg=cv2.imread(path, cv2.COLOR_RGB2BGR)\nplt.imshow(img)  # graph it\nplt.show()\nprint(CATEGORIES[int(prediction[0][0])]) ","9ac5ce67":"After creating the layers in our model its time to compile the model.\n\nAdaptive Moment Estimation(ADAM) is an algorithm for optimization technique for gradient descent.This algorithm is used to accelerate the gradient descent algorithm by taking into consideration the \u2018exponentially weighted average\u2019 of the gradients. We have maually specified the learning rate of Adam. A small learing rate requires many updates before reaching minimum points.\n\nOur focus in the model is to reduce losses to improve the performance of the model. Since in the output layer we are uisng Sigmoid activation , we will be using categorical crossentropy loss function. It is a multi-class classification function, it is used to quantify probability distribution between classes. Our model consists of two classes: \"cats\" and \"dogs\".\n\n","196893e0":"Since some of the images were broken in the dataset I have decided to use exception handling to deal with few broken images.\n\nLets collect our samples in training_data and test_data.","35a601f8":"Now since the function is ready lets pass image into the function","82890918":"Before fitting the data into the model , lets check the structure of the model.","5c47dbf2":"After compiling the model it is time for us to train the model. We have used two predefined api s in keras:\n\nModelCheckpoint saves a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved. We will only select the best model\/weights from the save.\n\nAssuming the goal of a training is to minimize the loss. With EarlyStopping , the metric to be monitored would be 'loss', training loop will check at end of every epoch whether the loss is no longer decreasing Once it's found no longer decreasing the training terminates. Since we will be running an epoch of 15 we will set the patience to 12.\n","0a4e548a":"Before feeding the image to prediction we will resize, grayscale and reshape the image. For that lets create a function.","0de426ce":"The first layer of our model is Convulation layer expects an input of 4 dimensional. So our task is to reshape our X into 4  dimensions(no. of samples, length, breadth, dimension ) . So we have reshaped X. ","0ec78e72":"A classification mode for predicting dogs and cats images using CNN has been made.  \n\nThe dataset of cats and dogs has been taken from Kaggle dataset. It consists of 10000(approx.) samples of cats and dogs jpgs. The dataset is already categorized into training(8000 samples) and test folders(2000 samples). The dataset will be loaded into image array of training_data and test_data.\n","cc6f2416":"Now once the training data is randomized ,it is time to extract the features and labels of the data into X and y for both training and test data.","00853ee9":"After the features has been extracted to X. The value of X will be brought into decimal by dividing the value with 255(since 255 is the highest value in pixel).  So basically we will normalize X i.e. X=X\/255","ee90a03e":"To test the model I have used random image of a cat and dog from the internet. Lets predict","cd985aa5":"With the accuracy of model increasing as the loss decreases. I havedecided to keep the no. of epochs at 15 to prevent overfitting the model as the dataset  is not that large. While training the model the model will be validated on test data. On optimising the epochs I have found the no. of epochs as 32 gives a better result so I have decided to go ahead with it.","5d8f1efc":"The first layer of our model is Convulation 2D layer expects an input of 3 dimensional.\nSo our task is to reshape our X into a compatible input to Convo Layer : (no. of samples , length, breadth, height ) .","e17c05c2":"The model accuacy averages to 98% after 15 epochs . Results may vary due to probabilistic nature of the algorithm or evaluation procedure, or differences in numerical precision","2d63ac71":"I have used architectural principles of the VGG models. Its consists of a block containing 1 Convulation Layer of small 3x3 filter followed by max pooling layer. \n\nThe model uses three such blocks with 32, 64, 128 no.of filters. Each convulation layer consists of non-linera activation function and initializer.\n\nEach block consists of : 2D convulation network -> non-linear activation function -> pooling layer -> dropout\n \nConvulation network : Consists of filters (2D matrix of 1 and 0 s). The task of the filter is to detect features in each portion of image. The filter sweeps over the entire image returns a feature map. The dimension of the filter is defined as kernel. In both the Convultaion layer a kernel size of 3 x 3 has been used with 64 number of filters. The feature map is multiplied by non-linear fraction to add weights to each value of the matrix.\n\nMax Pooling : It extracts a maximum value from a 2 x 2 pixel frame . The task of max pooling layer is to highlight the significant features of the image and reduces the dimension of the image. Another type of such layer is average pooling layer which generalises the image features picking average.\n\nDropout: To increase regularization of the model we use Dropout technique. It drops output information from one layer to the next making the training more susceiptable to changes and hence a more robust model. We have used 20% dropout in convulation layer and 50% on dense layers.\n","72be0a9d":"Since the dataset is already classified into different folders. The training data will be containing all the \"cats\" then followed by all the \"dogs\". The training of the model will be skewed in favour of \"cats\" in the beginning and then for the \"dogs\". So I have decided to randomize the training dataset. ","e5cab364":"\nBefore loading the data into training and test datasest, lets view some images of cat and dog from the dataset.","cc0f409e":"Before the data is fed to dense layer\/ fully connected layer, the data needs to be converted to 1D. So we use the Flatten function.\n\nThe Dense layer accepts input in 1D format. The dense layer multiplies n inputs with 1D inputs resulting in n x no. of inputs. Each n stands for nodes which activates the input with certain weights(decimal less than 1) . This is done to train the model with random weights everytime.\n\nThe output layer consists of a single dense node with Sigmoid activation which returns the prediction in probability instead of 1 or 0.\n\nWe have used a dense layer with 128 nodes and output dense layer with 1 node .\n\nSince we are expecting a probability as output we have used Sigmoid function.","efcdb413":"Now that our model has been trained lets visualise the results.","f7682d02":"The first layer of our model is Convulation 2D layer expects an input of 3 dimensional. So our task is to reshape our X into a compatible input to Convo Layer : (no. of samples , length, breadth, height ) .\nSince our samples are in grayscale thus height of 1","17e93bd0":"This was a simple prediction of Dog and Cat using basic CNN model\n\n\nThanks for watching :)","5448016b":"Since the dataset contained images of varying dimensions, a fixed 120 x 120 pixel has been set for the image , so that it is easy to feed the image into tensor.\n\nThe images has been coverted into grayscale using cv2. Since in the sample our goal is to identify a cat or a dog, the color may not be a significant distinguishbale parameter, so to say the color may have a more significant role when comparison between reptiles vs dog\/cat family. Again it just a self notion. Both RGB and grayscale will work in this model."}}