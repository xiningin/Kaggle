{"cell_type":{"dbc4e8c4":"code","ac7cfed3":"code","753367bf":"code","f24e309a":"code","8bfb3032":"code","0fd7befb":"code","14106ccf":"code","b4630977":"code","3d8e2ecf":"code","5d2c1e93":"code","2ad49b01":"code","32c74691":"code","b0a42a5f":"code","506976a7":"code","96e40caa":"code","e5421be4":"code","5e8fdc35":"code","c94d0c14":"code","3af22018":"code","818a5eb8":"code","84abb166":"code","df760e66":"code","2aa87888":"code","627c6589":"code","4f57ddf1":"code","d369db80":"code","c97d7efe":"code","129270c1":"code","e2f792d0":"code","b4312119":"code","11a35d42":"code","fd0d9b6a":"code","07b32ee7":"code","82f83afe":"code","f30c0b72":"code","6f47cc2e":"code","e82edee7":"code","ea12f972":"code","4706b661":"code","98460b1c":"code","f7082ebb":"code","278555e2":"code","25c298a8":"code","a9e9a41d":"code","82413b65":"code","7b23d286":"code","4f03085f":"code","8f737199":"code","7009c1d5":"code","ce3889e5":"code","a24b3738":"code","55282749":"code","482ecd14":"code","80b937f7":"code","fb363d61":"code","9362b77e":"markdown","3caba408":"markdown","27afdafe":"markdown","db367d2e":"markdown","bcdeaf62":"markdown","5633ab09":"markdown"},"source":{"dbc4e8c4":"pip install -U keras-tuner","ac7cfed3":"# \u0418\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\n\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras import utils\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pathlib\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom keras.layers import LeakyReLU\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import ElasticNetCV\nfrom keras.layers.normalization import BatchNormalization\n\n%matplotlib inline \n\ntry:\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nprint(tf.__version__)\n\n%load_ext tensorboard\n\nfrom numpy.random import seed\nseed(1)\ntf.compat.v1.set_random_seed(1)","753367bf":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\ndataTrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndataTest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ndataTrain.head(5)\n","f24e309a":"print (dataTrain.shape)\nprint (dataTest.shape)","8bfb3032":"# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043a\u043e\u043f\u0438\u0438 \u0442\u0430\u0431\u043b\u0438\u0446 \u0434\u0430\u043d\u043d\u044b\u0445\ntrain = dataTrain.copy()\ntest = dataTest.copy()","0fd7befb":"# \u0423\u0434\u0430\u043b\u044f\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0446\u044b \"Id\"\ntrain.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)\ntrain.shape\n# \u0423\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u0441\u0442\u0440\u043e\u043a \u0431\u0435\u0437 \u0446\u0435\u043b\u0438 \ntrain = train[pd.notnull(train[\"SalePrice\"]) ]\ntrain.shape","14106ccf":"# \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\nallData = pd.concat((train, test)).reset_index(drop=True)\nprint(\"allData size is : {}\".format(allData.shape))","b4630977":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0441\u043e\u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u044f \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nallData_na = (allData.isnull().sum() \/ len(allData)) * 100\nallData_na = allData_na.drop(allData_na[allData_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :allData_na})\nmissing_data = missing_data.T\nmissing_dataSort = sorted(missing_data)\n#print('\\n'.join(missing_dataSort))\nf, ax = plt.subplots(figsize=(10, 4))\nplt.xticks(rotation='90')\nsns.barplot(x=allData_na.index, y=allData_na)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)\n","3d8e2ecf":"# \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0430 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\nallData_na = (allData.isnull().sum() \/ len(allData)) * 100\nallData_na = allData_na.drop(allData_na[allData_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :allData_na})\nmissing_data.iloc[0:5]","5d2c1e93":"# \u041e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043d\u0430\u0438\u043c\u0435\u043d\u043e\u0432\u0430\u043d\u0438\u0439 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432 \u0441 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438 \u0432 \u0430\u043b\u0444\u0430\u0432\u0438\u0442\u043d\u043e\u043c \u043f\u043e\u0440\u044f\u0434\u043a\u0435\nprint(' - '.join(missing_dataSort))","2ad49b01":"# \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439, \u0441\u0440\u0435\u0434\u043d\u0438\u043c\u0438 (\u0433\u0434\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e)\nnoneDataMean = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']\nfor i in noneDataMean:\n    allData[noneDataMean] = allData[noneDataMean].fillna(allData[noneDataMean].mean())\nallData.iloc[0:5]","32c74691":"# \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439, \u043d\u0443\u043b\u044f\u043c\u0438 (\u0433\u0434\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e)\nnoneDataNull = ['BsmtFinSF1', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual', 'GarageCars', 'GarageArea']\nfor i in noneDataNull:\n    allData[i] = allData[i].fillna(0)\nallData.iloc[0:5]","b0a42a5f":"# \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u043d\u043e\u043c\u0438\u043d\u043e\u0442\u0438\u0432\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0441\u0442\u0440\u043e\u043a\u0430\u043c\u0438 'No'\nnoneDataNomin = ['Alley', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', \n                 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'Utilities', 'MSZoning']\nfor i in noneDataNomin:\n    allData[i] = allData[i].fillna('No')\nallData.iloc[0:5]","506976a7":"# \u0421\u043f\u0438\u0441\u043e\u043a \u043d\u043e\u043c\u0438\u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nnominative = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', \n             'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'ExterQual', \n              'ExterCond', 'Foundation', 'BsmtCond', 'BsmtFinType1', 'HeatingQC', 'CentralAir', 'BsmtFinType2', 'Heating', 'Electrical', 'BsmtFullBath', \n              'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', \n              'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageCars', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature']\n\n# \u0421\u043f\u0438\u0441\u043e\u043a \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nqualitative = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'OverallQual', 'OverallCond', 'MSSubClass', 'MasVnrArea','ExterQual', \n                'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtFinType1', 'HeatingQC', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n                '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', \n                'Fireplaces', 'FireplaceQu', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', \n                'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscVal', 'SalePrice']","96e40caa":"# \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043d\u0435\u0434\u043e\u0441\u0442\u0430\u044e\u0449\u0438\u0445 \u0438 \u043f\u0440\u0435\u043e\u0431\u0440\u043e\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u043e\u043c\u0438\u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \n\n#allData['YearBuilt'] = allData['YearBuilt'] - min(allData['YearBuilt']) + 20\n#-----\n#allData['YearRemodAdd'] = allData['YearRemodAdd'] - min(allData['YearRemodAdd']) + 20\n#-----\nExterQual = {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['ExterQual'] = allData['ExterQual'].map(ExterQual)\n#-----\nExterCond = {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['ExterCond'] = allData['ExterCond'].map(ExterCond)\n#-----\nBsmtQual = {'No':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['BsmtQual'] = allData['BsmtQual'].map(BsmtQual)\n#-----\nBsmtCond = {'No':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['BsmtCond'] = allData['BsmtCond'].map(BsmtCond)\n#-----\nallData[\"BsmtExposure\"] = allData[\"BsmtExposure\"].fillna('Non')\nfor i in allData[\"BsmtExposure\"].unique():\n    allData[\"BsmtExposure\" + str(i)] = (allData[\"BsmtExposure\"] == i).astype(float)\nallData.drop([\"BsmtExposure\"], axis=1, inplace=True)\n#-----\nBsmtFinType1 = {'No':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6}\nallData['BsmtFinType1'] = allData['BsmtFinType1'].map(BsmtFinType1)\n#-----\nBsmtFinType2 = {'No':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6}\nallData['BsmtFinType2'] = allData['BsmtFinType2'].map(BsmtFinType1)\n#-----\nHeatingQC = {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['HeatingQC'] = allData['HeatingQC'].map(HeatingQC)\n#-----\nCentralAir = {'N':0, 'Y':1}\nallData['CentralAir'] = allData['CentralAir'].map(CentralAir)\n#-----\nKitchenQual = {0:0,'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['KitchenQual'] = allData['KitchenQual'].map(KitchenQual)\n#-----\nFireplaceQu = {'No':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['FireplaceQu'] = allData['FireplaceQu'].map(FireplaceQu)\n#-----\nallData['Functional'] = allData['Functional'].fillna('Typ')\n#-----\nallData['GarageYrBlt'] = allData['GarageYrBlt'].fillna(allData['GarageYrBlt'].mean())\n#allData['GarageYrBlt'] = allData['GarageYrBlt'] - min(allData['GarageYrBlt']) + 20\n#-----\nGarageFinish = {'No':0, 'Unf':1, 'RFn':2, 'Fin':3}\nallData['GarageFinish'] = allData['GarageFinish'].map(GarageFinish)\n#-----\nGarageCond = {'No':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['GarageCond'] = allData['GarageCond'].map(GarageCond)\n#-----\nGarageQual = {'No':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}\nallData['GarageQual'] = allData['GarageQual'].map(GarageQual)\n#-----\nPavedDrive = {'N':1, 'P':2, 'Y':3}\nallData['PavedDrive'] = allData['PavedDrive'].map(PavedDrive)\n#-----\nPoolQC = {'No':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4}\nallData['PoolQC'] = allData['PoolQC'].map(PoolQC)\n#-----\nFence = {'No':0, 'MnWw':1, 'GdWo':2, 'MnPrv':3, 'GdPrv':4}\nallData['Fence'] = allData['Fence'].map(Fence)\n#-----\nallData['YrSold'] = allData['YrSold'] +1 #- min(allData['YrSold']) + 5\n#-----\nallData.iloc[0:5]","e5421be4":"'''\n# \u041f\u043e\u0438\u0441\u043a \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442 \u0441\u0442\u0440\u043e\u043a\u0438 \"No\" \u0432 \u0442\u0430\u0431\u043b\u0438\u0446\u0435\ncolName = all_data.columns.tolist() \nfor i in colName:\n    try:\n        print (list(all_data[i]).index('No'))\n    except ValueError:\n        pass\n'''","5e8fdc35":"# \u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\n#allData.describe().T","c94d0c14":"# \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0430 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\nallData_na = (allData.isnull().sum() \/ len(allData)) * 100\nallData_na = allData_na.drop(allData_na[allData_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :allData_na})\nmissing_data.iloc[0:10]","3af22018":"# \u0412\u044b\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\ntrainAnaliticQ = allData[:len(allData) - len(dataTest)]\ntrainAnaliticN = allData[:len(allData) - len(dataTest)]\nprint(trainAnaliticQ.shape)\nprint(trainAnaliticN.shape)\nallAnalitic = allData.copy()\nprint(allAnalitic.shape)","818a5eb8":"# \u041d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0435 \u0432\u0441\u0435\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043d\u0435 \u0432\u0445\u043e\u0434\u044f\u0449\u0438\u0445 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nlistQualitative = list(set(trainAnaliticQ.columns.tolist()) - set(qualitative))\n# \u0412\u044b\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u043a\u043e\u043d\u0432\u0435\u0440\u0442\u0430\u0446\u0438\u0435\u0439 \u0432 Int \u0434\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\ntrainAnaliticQ = trainAnaliticQ.drop(listQualitative, \n                      axis=1)\ntrainAnaliticQ = trainAnaliticQ.astype(int)\ntrainAnaliticQ.iloc[0:5]","84abb166":"# \u0410\u043d\u0430\u043b\u0438\u0437 \u043a\u043e\u043e\u0440\u0435\u043b\u044f\u0446\u0438\u0438 \u0432\u0441\u0435\u0445 \u043f\u0435\u0440\u0435\u043c\u043d\u043d\u044b\u0445 \u0441 \u0446\u0435\u043b\u044c\u044e\n\"\"\"fig, ax = plt.subplots(round(len(qualitative)\/5), 5, figsize = (40, 100))\nfor var, subplot in zip(qualitative, ax.flatten()):\n    sns.set(font_scale = 1.5) \n    sns.regplot(x = var, y = 'SalePrice', data = trainAnaliticQ, ax = subplot);\"\"\"\n #   sns.boxplot(x=var, y='SalePrice', data = trainAnaliticQ, ax = subplot)","df760e66":"# \u041d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0435 \u0432\u0441\u0435\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043d\u0435 \u0432\u0445\u043e\u0434\u044f\u0449\u0438\u0445 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a \u043d\u043e\u043c\u0438\u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nlistNominative = list(set(trainAnaliticN.columns.tolist()) - set(nominative))\n# \u0412\u044b\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043d\u043e\u043c\u0438\u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0433\u0438\u0441\u0442\u043e\u043a\u0440\u0430\u043c\u043c\ntrainAnaliticN = trainAnaliticN.drop(listNominative, \n                      axis = 1)\n# \u0412\u044b\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043d\u043e\u043c\u0438\u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0433\u0438\u0441\u0442\u043e\u043a\u0440\u0430\u043c\u043c\nallAnaliticN = allAnalitic.drop(listNominative, \n                      axis = 1)","2aa87888":"# \u0410\u043d\u0430\u043b\u0438\u0437 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430\n\"\"\"fig, ax = plt.subplots(round(len(nominative)\/5), 5, figsize = (40, 100))\nfor variable, subplot in zip(nominative, ax.flatten()):\n    sns.set(font_scale = 1.5)  \n    sns.countplot(trainAnaliticN[variable], ax = subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\"\"\"","627c6589":"# \u0410\u043d\u0430\u043b\u0438\u0437 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043e\u0431\u0449\u0435\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430\n\"\"\"fig, ax = plt.subplots(round(len(nominative)\/5), 5, figsize = (40, 100))\nfor variable, subplot in zip(nominative, ax.flatten()):\n    sns.set(font_scale = 1.5)  \n    sns.countplot(allAnaliticN[variable], ax = subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\"\"\"","4f57ddf1":"# \u0410\u043d\u0430\u043b\u0438\u0437 \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0439 \u043c\u0435\u0436\u0434\u0443 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u043c\u0438 \u0438 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u043c\u0438 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u043c\u0438\n\"\"\"fig, ax = plt.subplots(round(len(nominative)\/5), 5, figsize = (40, 100))\nfor var, subplot in zip(nominative, ax.flatten()):\n    sns.set(font_scale = 1.5) \n    sns.boxplot(x = var, y = 'SalePrice', data = allAnalitic, ax = subplot)\"\"\"","d369db80":"# \u0423\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u043d\u043e\u043c\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u0441 \u043c\u0430\u043b\u043e\u0439 \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u0435\u0439\nallData = allData.drop(['Street', 'Utilities', 'Condition2', 'RoofMatl', 'Heating', 'PoolQC', 'GarageCond', 'Fence', \n                        'Functional', 'Exterior1st', 'Exterior2nd', 'RoofStyle', 'BsmtHalfBath', 'Neighborhood', 'Electrical'], axis=1)","c97d7efe":"# \u041e\u0442\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u043e\u0442 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\ntrain = allData[:len(allData) - len(dataTest)]\ntest = allData[len(allData) - len(dataTest):]\nprint(train.shape)\nprint(test.shape)","129270c1":"sns.lmplot(x=\"GrLivArea\", y = \"SalePrice\", data=train);","e2f792d0":"# \u0423\u0434\u0430\u0435\u043d\u0438\u0435 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432\ntrain = train.drop(train[(train['GrLivArea'] > 4000)].index)\ntrain = train.drop(train[(train['SalePrice'] > 600000)].index)\ntrain = train.drop(train[(train['LotArea'] > 100000)].index)\ntrain = train.drop(train[(train['OpenPorchSF'] > 450)].index)\ntrain = train.drop(train[(train['MiscVal'] > 3000)].index)\n# \u0412\u044b\u0432\u043e\u0434 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\nsns.lmplot(x=\"GrLivArea\", y = \"SalePrice\", data=train);","b4312119":"train.shape","11a35d42":"# \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\nallData = pd.concat((train, test)).reset_index(drop=True)\nprint(\"allData size is : {}\".format(allData.shape))","fd0d9b6a":"# \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\nparamData = ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Condition1', \n             'BldgType', 'HouseStyle', 'MasVnrType', 'Foundation', \n             'CentralAir', 'GarageType', 'MiscFeature', 'MoSold', 'YrSold', 'SaleCondition', 'SaleType']\nfor p in paramData:\n    for i in allData[p].unique():\n        allData[p + str(i)] = (allData[p] == i).astype(float)\n    allData.drop([p], axis=1, inplace=True)\nallData.iloc[0:5]","07b32ee7":"# \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0426\u0435\u043d\u044b\nSaleDate = allData['SalePrice']","82f83afe":"sns.lmplot(x=\"GrLivArea\", y = \"SalePrice\", data=allData);","f30c0b72":"# \u0421\u043f\u0438\u0441\u043e\u043a \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0441 \u043d\u0435\u043e\u0446\u0435\u043d\u043e\u0447\u043d\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nlistNorm = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea','BsmtFinType1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n            '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea', 'WoodDeckSF', \n            'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n# \u0412\u044b\u0432\u043e\u0434 \u0433\u0438\u0441\u0442\u043e\u0433\u0440\u0430\u043c\u043c\n\"\"\"fig, ax = plt.subplots(round(len(listNorm)\/5), 5, figsize = (40, 30))\nfor var, subplot in zip(listNorm, ax.flatten()):\n    sns.set(font_scale = 1.5) \n    try:\n        sns.distplot(allData[var], color=\"m\", ax = subplot)\n    except RuntimeError as re:\n        if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n            sns.distplot(allData, kde_kws={'bw': 0.1})\n        else:\n            raise re\"\"\"","6f47cc2e":"# \u0421\u043f\u0438\u0441\u043e\u043a \u043e\u0442\u043e\u0431\u0440\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445\nlistNormNew = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea','BsmtFinType1', 'BsmtUnfSF', 'TotalBsmtSF', \n            '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea', 'WoodDeckSF', \n            'OpenPorchSF']\n# \u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\nfor param in listNormNew:\n    print()\n    (mu, sigma) = norm.fit(allData[param])\n    allData[param] = np.log1p(allData[param])\n\"\"\"# \u0412\u044b\u0432\u043e\u0434 \u0433\u0438\u0441\u0442\u043e\u0433\u0440\u0430\u043c\u043c\nfig, ax = plt.subplots(round(len(listNormNew)\/5), 5, figsize = (40, 30))\nfor var, subplot in zip(listNormNew, ax.flatten()):\n    sns.set(font_scale = 1.5) \n    sns.distplot(allData[var], color=\"m\", ax = subplot)\"\"\"","e82edee7":"# \u0421\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\nmean = allData.mean(axis=0)\n# \u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u043e\u0435 \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0435\nstd = allData.std(axis=0)\n# \u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\nallData -= mean\nallData \/= std","ea12f972":"# \u041e\u0442\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u043e\u0442 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\ntrain = allData[:len(allData) - len(dataTest)]\ntest = allData[len(allData) - len(dataTest):]\nprint(train.shape)\nprint(test.shape)","4706b661":"\"\"\"# \u041a\u043e\u0440\u0435\u043b\u044f\u0446\u0438\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0441 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u0443\u0435\u043c\u043e\u0439 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u043e\u0439\ncorrmat = train.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)\"\"\"","98460b1c":"train[\"SalePrice\"] = SaleDate[:len(allData) - len(dataTest)]","f7082ebb":"# \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0432\u0441\u0435\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 float\ntrain.astype(float)\ntest.astype(float)\n\n# \u0412\u044b\u0431\u043e\u0440\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445. \u0420\u0430\u0437\u0431\u0438\u0432\u043a\u0430 \u043d\u0430 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0443\u044e, \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0443\u044e \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0438\ntrainDataset, validationDataset = np.split(train, [int(.8*len(train))])\n# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0431\u043e\u0440\u043e\u043a \u043a \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044e \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u044c\u044e \ntrainInput = trainDataset.copy()\ndel trainInput['SalePrice']\ntrainTarget = trainDataset['SalePrice']\nvalidationInput = validationDataset.copy()\ndel validationInput['SalePrice']\nvalidationTarget = validationDataset['SalePrice']\ntestInput = test.copy()\ntestInput.drop(['SalePrice'], axis=1, inplace=True)\nprint(trainInput.shape)\nprint(trainTarget.shape)\nprint(validationInput.shape)\nprint(validationTarget.shape)\nprint(testInput.shape)","278555e2":"# \u041c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\nscalerMX = MinMaxScaler(feature_range = (0.2,0.8))\nscalerMX.fit(trainInput)\ntrainInputS = pd.DataFrame(scalerMX.transform(trainInput))\ntrainInputS.columns = trainInput.columns.tolist()\ntestInputS = pd.DataFrame(scalerMX.transform(validationInput))\ntestInputS.columns = validationInput.columns.tolist()","25c298a8":"#  \u041a\u043b\u0430\u0441\u0441 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0445\u043e\u0434\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u0435\u0442\u0438\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 15 == 0: print('')\n    print('.', end = '')\nearly_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)","a9e9a41d":"def createModel(inputShape):\n    model = Sequential()\n    model.add(Dense(8192, input_dim = inputShape, kernel_regularizer=keras.regularizers.l2(0.01), activation = \"relu\"))\n    model.add(Dense(2048, activation = \"relu\"))\n    model.add(Dense(1024, activation = \"relu\"))\n    model.add(Dense(1024, activation = \"relu\"))\n    model.add(Dense(1024, activation = \"relu\"))\n    model.add(Dense(1024, activation = \"relu\"))\n    model.add(layers.Dropout(0.05))\n    model.add(Dense(1))\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)\n    model.compile(loss = 'mae', optimizer = optimizer, metrics = [\"mse\", \"mae\"])\n    return model","82413b65":"modelG = createModel(trainInput.shape[1])\nearly_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\nhistory = modelG.fit(trainInput, trainTarget, validation_split = 0.2, batch_size = 20, epochs = 60, verbose = 1, callbacks = [early_stop, PrintDot()])","7b23d286":"# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\npredsData = modelG.predict(validationInput)\nfor i in range(10):\n    print(\"\u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0439 \u0440\u043e\u0441\u0442:\", round(predsData[i][0], 3), \", \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u0440\u043e\u0441\u0442:\", round(validationTarget.values[i], 3))\ndifference = predsData.T[0] - validationTarget.values\nprint('\\n\u0421\u0440\u0435\u0434\u043d\u044f\u044f \u043e\u0448\u0438\u0431\u043a\u0430', sum(abs(difference))\/len(difference))","4f03085f":"# \u0413\u0440\u0430\u0444\u0438\u043a \u0445\u043e\u0434\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\ndef plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error')\n  plt.plot(hist['epoch'], hist['mae'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mae'],\n           label = 'Val Error')\n  plt.ylim([0, 200000])\n  plt.legend()\n\nplot_history(history)","8f737199":"preds_test = modelG.predict(testInput).T[0]","7009c1d5":"# \u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440 \u043f\u0440\u0438\u043c\u0435\u0440\u0430 \u043e\u0444\u043e\u0440\u043c\u043b\u0435\u043d\u0438\u044f \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0434\u043b\u044f \u043e\u0442\u043f\u0440\u0430\u0432\u043a\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 \u043d\u0430 Kaggle.com\ndataSamplie = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ndataSamplie.iloc[0:5]","ce3889e5":"# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0444\u0430\u0439\u043b\u0430 \u043a \u043e\u0442\u043f\u0440\u0430\u0432\u043a\u0435\noutput = pd.DataFrame({'Id': testInput.index,\n                       'SalePrice': preds_test})\noutput[\"Id\"] = np.arange(1461, 1461 + len(output))\noutput.to_csv('submission.csv', index=False)","a24b3738":"\"\"\"!rm -rf test_directory\n!rm -rf untitled_project\"\"\"\n\"\"\"# \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043d\u0430\u0431\u043e\u0440\u0430 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\nfrom numpy.random import seed\nseed(1)\nimport tensorflow\ntensorflow.random.set_seed(1)\"\"\"","55282749":"\"\"\"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\n\nclass RegressionHyperModel(HyperModel):\n    def __init__(self, input_shape):\n        self.input_shape = input_shape\n    def build(self, hp):\n        model = Sequential()\n        activation_choice = hp.Choice('activation', values=['relu', 'sigmoid', 'tanh', 'elu', 'selu'])\n        optimizer_choice = hp.Choice('optimizer', values=['adam', 'adamax', 'nadam', 'adadelta', 'rMSprop', 'adagrad'])\n        model.add(\n            layers.Dense(\n                units=hp.Int('units', 1024, 2048, 128, default=512),\n                activation = activation_choice,\n                input_shape = input_shape\n            )\n        )\n        for i in range(hp.Int('num_layers', 2, 10)):\n              model.add(layers.Dense(units=hp.Int('units_' + str(i),\n                                                  min_value = 256,\n                                                  max_value = 2048,\n                                                  step = 256),\n                                     activation = hp.Choice('activation', values=['relu', 'sigmoid', 'tanh', 'elu', 'selu'])))\n        model.add(\n            layers.Dropout(\n                hp.Float(\n                    'dropout',\n                    min_value = 0.0,\n                    max_value = 0.1,\n                    step = 0.01)\n            )\n        )\n        model.add(layers.Dense(1))\n        if optimizer_choice == 'adam':\n            model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp.Choice('learning_rate', values = [2e-0, 1e-0, 1e-1])), loss = 'mse',metrics = ['mse'])\n        elif optimizer_choice == 'adamax':\n            model.compile(optimizer = keras.optimizers.Adamax(learning_rate = hp.Choice('learning_rate', values = [1.5, 0.9, 0.3])), loss = 'mse',metrics = ['mse'])\n        elif optimizer_choice == 'nadam':\n            model.compile(optimizer = keras.optimizers.Nadam(learning_rate = hp.Choice('learning_rate', values = [1.5, 0.9, 0.3])), loss = 'mse',metrics = ['mse'])\n        elif optimizer_choice == 'rMSprop':\n            model.compile(optimizer = keras.optimizers.RMSprop(learning_rate = hp.Choice('learning_rate', values = [1.5, 0.9, 0.3])), loss = 'mse',metrics = ['mse'])\n        elif optimizer_choice == 'adagrad':\n            model.compile(optimizer = keras.optimizers.Adagrad(learning_rate = hp.Choice('learning_rate', values = [24, 18, 12])), loss = 'mse',metrics = ['mse'])\n        else:\n            model.compile(optimizer = keras.optimizers.Adadelta(learning_rate = hp.Choice('learning_rate', values = [1500, 900, 300])), loss = 'mse',metrics = ['mse'])\n        return model\n\ninput_shape = (trainInput.shape[1],)\nhypermodel = RegressionHyperModel(input_shape)\n\"\"\"","482ecd14":"\"\"\"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c tuner\ntuner = BayesianOptimization(\n            hypermodel,\n            objective = 'val_mse',\n            max_trials = 200,\n            seed = 1,\n            executions_per_trial = 1\n        )\"\"\"","80b937f7":"\"\"\"# \u0417\u0430\u043f\u0443\u0441\u043a \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0435\u0439\ntuner.search(trainInput, \n             trainTarget, \n             epochs = 60,\n             validation_data = (validationInput, validationTarget), \n             verbose = 2)\"\"\"","fb363d61":"\"\"\"# \u041f\u0440\u043e\u0441\u043c\u043e\u0442\u0440 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\ntuner.results_summary(5)\"\"\"\n\"\"\"# \u0412\u044b\u0431\u043e\u0440 \u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\nbest_model = tuner.get_best_models(num_models=1)[0]\n#loss, mse = best_model.evaluate(testInput, testTarget)\"\"\"","9362b77e":"# \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 Keras Tuner","3caba408":"# Keras Tuner","27afdafe":"# \u0410\u043d\u0430\u043b\u0438\u0437 \u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","db367d2e":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","bcdeaf62":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043b\u043e\u0433\u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0438 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0439. \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","5633ab09":"# \u0418\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a"}}