{"cell_type":{"08530b87":"code","c08cddaf":"code","7a4f08d2":"code","893867cf":"code","592b4198":"code","d7ba2070":"code","3a206148":"code","7ee4b0a1":"code","4c4a9de5":"code","097053b9":"code","337db725":"code","b970202c":"code","d43371f2":"code","94a8450c":"code","7fdadc6d":"code","1d80ef04":"code","a73f195b":"code","268200ee":"code","ccb1edec":"code","de1a2698":"code","f9669760":"markdown","da77b75c":"markdown","cd52813c":"markdown","acda9b57":"markdown","3e7053e7":"markdown","02ad48fe":"markdown","39071065":"markdown","883c9bd3":"markdown","3011c538":"markdown","cdfbc0ab":"markdown","dbe026c0":"markdown"},"source":{"08530b87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport tensorflow \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense ","c08cddaf":"classifier = Sequential()","7a4f08d2":"classifier.add(Conv2D(filters = 32,kernel_size = (3, 3),\n                      input_shape = (512, 512, 3), activation = \"sigmoid\"))","893867cf":"classifier.add(MaxPooling2D(pool_size = (6,6)))","592b4198":"classifier.add(Conv2D(filters = 32,kernel_size = (3, 3), activation = \"relu\"))\nclassifier.add(MaxPooling2D(pool_size = (6,6)))","d7ba2070":"classifier.add(Flatten())","3a206148":"classifier.add(Dense(units = 128, activation = \"sigmoid\"))\nclassifier.add(Dense(units = 4, activation = \"sigmoid\"))","7ee4b0a1":"classifier.compile(optimizer = \"adam\", loss = \"CategoricalCrossentropy\", metrics = [\"accuracy\"])","4c4a9de5":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","097053b9":"train_datagen = ImageDataGenerator(\n                                   rescale=1.\/255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)","337db725":"test_datagen = ImageDataGenerator(rescale=1.\/255)","b970202c":"training_dataset = train_datagen.flow_from_directory('\/kaggle\/input\/brain-tumor-classification-mri\/Training\/',\n                                                     target_size=(512, 512),\n                                                     batch_size=64,\n                                                     class_mode='categorical')","d43371f2":"testing_dataset = test_datagen.flow_from_directory('\/kaggle\/input\/brain-tumor-classification-mri\/Testing\/',\n                                                   target_size=(512, 512),\n                                                   batch_size=64,\n                                                   class_mode='categorical')","94a8450c":"classifier.fit(training_dataset,\n               steps_per_epoch = 44,\n               epochs = 100,\n               validation_data = testing_dataset,\n               validation_steps = 8)","7fdadc6d":"# serialize model to JSON\nfrom keras.models import model_from_json\nmodel_json = classifier.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","1d80ef04":"# serialize weights to HDF5\nclassifier.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","a73f195b":"# load json and create model\n'''\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n'''","268200ee":"# load weights into new model\n'''\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n'''","ccb1edec":"'''\n# Individual predictions\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\ntest_image = image.load_img('dataset\/single_prediction\/OIP.jpg', target_size = (512, 512)) # Cargamos la imagen con un tama\u00f1o igual a\n                                                                                           # los anteriores\ntest_image = image.img_to_array(test_image) # Convertimos la imagen en un array\ntest_image = np.expand_dims(test_image, axis = 0) # Modificamos las dimensions\nresult = classifier.predict(test_image) # Prediccion\nprint(training_dataset.class_indices)\nprint(result)\n'''","de1a2698":"# evaluate loaded model on test data\n'''\nloaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nscore = loaded_model.evaluate(X, Y, verbose=0)\nprint(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n'''","f9669760":"### Image transformations","da77b75c":"## For later use","cd52813c":"## Compilation","acda9b57":"## Flattening","3e7053e7":"## Save Progress","02ad48fe":"## Convolution layer + Max pooling","39071065":"## Full Connection","883c9bd3":"## Another Convolution layer + Max pooling","3011c538":"## Classifier","cdfbc0ab":"## Loading images","dbe026c0":"## Fitting the model with the supplied images"}}