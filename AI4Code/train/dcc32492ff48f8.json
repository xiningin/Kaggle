{"cell_type":{"60f7ef16":"code","791dc481":"code","d541fc12":"code","f6162d94":"code","34ea5dc3":"code","31c87d16":"code","2297e196":"code","c6a6f1ad":"code","5747c434":"code","b47b2de5":"code","71d8b237":"code","a36350da":"code","ae3a515a":"code","3dd13d8a":"code","a62e38ea":"code","af65dd6a":"code","04206118":"markdown","cc002ea7":"markdown","cf36d958":"markdown","96bfa486":"markdown","fc7f9760":"markdown","e6d53f65":"markdown","59c820c6":"markdown","90582756":"markdown","2c408f4e":"markdown","53c7df19":"markdown","63c4869f":"markdown","6429cdce":"markdown","210b658c":"markdown"},"source":{"60f7ef16":"# importing some awesome libraries\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport torch\nfrom torch.utils.data import ConcatDataset\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchsummary import summary\nimport time\nimport copy","791dc481":"# creation of really helpful functions\n\n# function to print images\ndef print_img(img):\n    img = img.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    img = std * img + mean\n    img = np.clip(img, 0, 1)\n    plt.figure(figsize = (2.5, 2.5))\n    plt.axis('off')\n    plt.imshow(img)\n\n\n# function to train model\ndef train_model(model, criterion, optimizer, num_epochs):\n    since = time.time()\n    best_model = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch + 1, num_epochs))\n        \n        # train\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n        for inputs, labels in train_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            with torch.set_grad_enabled(True):\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n        epoch_loss = running_loss \/ train_size\n        epoch_acc = running_corrects.double() \/ train_size\n        print('Train Loss: {:.4f} Train Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n        \n        # validate\n        model.eval()\n        running_loss = 0.0\n        running_corrects = 0\n        for inputs, labels in val_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            with torch.set_grad_enabled(False):\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n        epoch_loss = running_loss \/ val_size\n        epoch_acc = running_corrects.double() \/ val_size\n        print('Val Loss: {:.4f} Val Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n        print('-' * 30)\n        if epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_model = copy.deepcopy(model.state_dict())\n        \n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best Val Acc: {:.4f}'.format(best_acc))\n    model.load_state_dict(best_model)\n    return model\n\n\n# function to predict images and display the accuracy\ndef visualize_predictions(model, dataset):\n    labels = []\n    predictions = []\n    acc = 0\n    was_training = model.training\n    model.eval()\n    with torch.no_grad():\n        for i in range(len(dataset)):\n            input, label = dataset[i]\n            input = input[np.newaxis,:]\n            input = input.to(device)\n            output = model(input)\n            _, preds = torch.max(output, 1)\n            if class_names[label] == class_names[preds]:\n                acc += 1\n            labels.append(class_names[label])\n            predictions.append(class_names[preds])\n    print('Test Accuracy: {:.4f}'.format(acc\/len(dataset)))\n    model.train(mode=was_training)\n    return labels, predictions","d541fc12":"# creates a transforms sequence for the train set\ntransf_train = transforms.Compose([\n    transforms.Resize(60),\n    transforms.RandomCrop(54),\n    transforms.ToTensor(), # converts pixels [0-255] to tensors [0-1]\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n\n# creates a second transforms sequence for the train set\ntransf_train2 = transforms.Compose([\n    transforms.Resize(57),\n    transforms.RandomRotation(10),\n    transforms.RandomCrop(54),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n# creates the transforms sequence for the test and val sets\ntransf_test = transforms.Compose([\n    transforms.Resize(54),\n    transforms.CenterCrop(54),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n\n# loads the images and applies the transformations\ntrain_set = torchvision.datasets.ImageFolder('..\/input\/chest-xray-pneumonia\/chest_xray\/train', transform = transf_train)\ntrain_set2 = torchvision.datasets.ImageFolder('..\/input\/chest-xray-pneumonia\/chest_xray\/train', transform = transf_train2)\ntest_set = torchvision.datasets.ImageFolder('..\/input\/chest-xray-pneumonia\/chest_xray\/test', transform = transf_test)\nval_set = torchvision.datasets.ImageFolder('..\/input\/chest-xray-pneumonia\/chest_xray\/val', transform = transf_test)\n\n# number of images in each set\ntrain_size = len(train_set)\ntest_size = len(test_set)\nval_size = len(val_set)\nprint('Train: {} images, Test: {} images, Validation: {} images'.format(train_size, test_size, val_size))","f6162d94":"# class labels\nclass_names = train_set.classes\n\n# a normal x-ray\nimg, label = train_set[0]\nprint('Label:', class_names[label])\nprint_img(img)","34ea5dc3":"# a pneumonia x-ray\nimg, label = train_set[-1]\nprint('Label:', class_names[label])\nprint_img(img)","31c87d16":"counter = []\nx_n = 0\nx_p = 0\n\nfor i in train_set:\n    if i[1] == 1:\n        counter.append(\"Pneumonia\")\n        x_p += 1\n    else:\n        counter.append(\"Normal\")\n        x_n += 1\n\nprint('Train set')\nprint('Normal:', x_n, '\/ Pneumonia:', x_p)\nsns.countplot(x=counter);","2297e196":"counter = []\nx_n = 0\nx_p = 0\n\nfor i in test_set:\n    if i[1] == 1:\n        counter.append(\"Pneumonia\")\n        x_p += 1\n    else:\n        counter.append(\"Normal\")\n        x_n += 1\n\nprint('Test set')\nprint('Normal:', x_n, '\/ Pneumonia:', x_p)\nsns.countplot(x=counter);","c6a6f1ad":"counter = []\nx_n = 0\nx_p = 0\n\nfor i in val_set:\n    if i[1] == 1:\n        counter.append(\"Pneumonia\")\n        x_p += 1\n    else:\n        counter.append(\"Normal\")\n        x_n += 1\n\nprint('Validation set')\nprint('Normal:', x_n, '\/ Pneumonia:', x_p)\nsns.countplot(x=counter);","5747c434":"train_set2, _ = train_test_split(train_set2, test_size= 3875\/train_size, shuffle=False)\ntrain_set = ConcatDataset([train_set, train_set2])","b47b2de5":"counter = []\nx_n = 0\nx_p = 0\n\nfor i in train_set:\n    if i[1] == 1:\n        counter.append(\"Pneumonia\")\n        x_p += 1\n    else:\n        counter.append(\"Normal\")\n        x_n += 1\n\nprint('Train set')\nprint('Normal:', x_n, '\/ Pneumonia:', x_p)\nsns.countplot(x=counter);","71d8b237":"train_set, val_set = train_test_split(train_set, test_size=0.2)\n\ntrain_size = len(train_set)\nval_size = len(val_set)","a36350da":"# object to load batches of instances\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size = 32, shuffle = True, num_workers = 2)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size = 32, shuffle = True, num_workers = 2)","ae3a515a":"# import pretrained model\nmodel = torchvision.models.resnet50(pretrained = True)\n\n# number of features in the input of the linear layer\nnum_ftrs = model.fc.in_features\n\n# sets the number of features of the linear layer\nmodel.fc = torch.nn.Linear(num_ftrs, len(class_names))\n\n# parameters\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\nnum_epochs = 5\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# model summary\nsummary(model, (3, 50, 50), 16)","3dd13d8a":"# train the model\nmodel = train_model(model, criterion, optimizer, num_epochs)","a62e38ea":"# predicting the test set\nlabels, predictions = visualize_predictions(model, test_set)","af65dd6a":"# confusion matrix\nmatrix = confusion_matrix(labels, predictions)\nplt.figure()\nplot_confusion_matrix(matrix, figsize=(4,4))\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=10)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=10)\nplt.xlabel('Predicted', fontsize=12)\nplt.ylabel('Real', fontsize=12)\nplt.show()","04206118":"# Model implementation and training","cc002ea7":"A normal chest x-ray depicts clear lungs without any areas of abnormal opacification. On the other hand, bacterial pneumonia typically exhibits a focal lobar consolidation in the image. The goal of this notebook is to create a model that can accurately classify x-rays as \"Normal\" or \"Pneumonia\".\n\nYou can read more about the dataset here: https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia","cf36d958":"This notebook has the following sections:\n\n1. Data loading and preprocessing\n2. Model implementation and training\n3. Prediction of unseen data","96bfa486":"Lets visualize the distribution of the dataset.","fc7f9760":"Taking a look at a couple x-rays.","e6d53f65":"That's better.\n\nNow we create a new validation set because 16 images is not enough.","59c820c6":"Lets balance the train set a bit.","90582756":"# Prediction of unseen data","2c408f4e":"I'll load a model that was pretrained with a huge amount of images and adapt it to this dataset. This process is called transfer learning.\n\nFor more on the topic, refer to: https:\/\/pytorch.org\/tutorials\/beginner\/transfer_learning_tutorial.html","53c7df19":"Seems like the model learned to classify the x-rays pretty well.\n\nThanks for reading!","63c4869f":"# X-ray images classification with PyTorch and transfer learning","6429cdce":"Lastly, lets use the trained model to predict unseen images and see if it can generalize well.","210b658c":"# Data loading and preprocessing"}}