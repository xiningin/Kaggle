{"cell_type":{"bab7fd93":"code","fd538741":"code","8d9eee6b":"code","27874a24":"code","1c31aaab":"code","9b16863a":"code","c86b754f":"code","bf2fc07f":"code","4ef7bd5e":"code","0cf78aea":"code","b02abc9e":"code","3895c1b6":"code","8e742c36":"code","6ec9d64b":"code","81c5c13f":"code","c4a6161a":"code","9f48cbc9":"code","fe0d4699":"code","dbdee310":"code","87b9946e":"code","c842f639":"code","06fbae74":"code","9aee14cf":"code","459e6b1c":"code","102a959b":"code","8a02f033":"code","cdb47b94":"code","9332ace2":"code","230f3250":"code","95ed4253":"code","5ef12c4f":"code","bc027404":"code","d2d5551a":"code","468cdc46":"code","e4689672":"code","9cbc28c0":"code","86eb55a3":"code","9c7e98f1":"code","1e8627b2":"code","e4974e36":"code","b1bd2f53":"code","b5901c9d":"code","de8547ec":"code","81a010f3":"code","8dc43115":"code","4c81ddd9":"code","a9dbe0da":"code","ac462188":"code","1dce967c":"code","862f10a2":"code","58c3c2d8":"code","192abc59":"code","c569b5ef":"code","b9004b6a":"code","6457af4d":"code","7b5c7af4":"code","f262a5e3":"code","0cac3aac":"code","eb3192a6":"code","3a817d05":"code","748279a5":"code","68e83d09":"code","f7c761d7":"code","2dbf45ea":"code","7dfda286":"code","b3f164ca":"code","1756aca6":"code","69a1100f":"code","7afcc15b":"code","49225975":"code","814f2939":"markdown","a0d95fb0":"markdown","7a040f32":"markdown","e12411ef":"markdown","82db7f63":"markdown","5423f09e":"markdown","65e4efd7":"markdown","ff8a98c4":"markdown","c243d173":"markdown","67af1b6b":"markdown","ddcfd755":"markdown","45ad742f":"markdown","73ae45c2":"markdown","a8937e7c":"markdown","c302501f":"markdown","647b0a67":"markdown","1bc4d0b9":"markdown","bcc19401":"markdown","08f6a95c":"markdown","15b3cb09":"markdown","05333139":"markdown","19e634ac":"markdown","0ce0afda":"markdown","8ff4c15a":"markdown","798e1536":"markdown","558984df":"markdown","02bfa120":"markdown","685518a7":"markdown","cc316b3b":"markdown","233eadc7":"markdown"},"source":{"bab7fd93":"import numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport random\nimport pandas as pd\nimport scipy.stats as stat\nimport seaborn as sns\nimport os\nimport pandas\nimport sklearn\n\nfrom IPython.display import Image\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n# Para ter repetibilidade nos resultados\nrandom_state = 1\n\n# Tratar valores infinitos como np.NaN\npandas.options.mode.use_inf_as_na = True\n\n# IMPORTANTE para tornar figuras interativas\n%matplotlib notebook\n\n# Tamanho padr\u00e3o das figuras\nfigsize=(10,6)\n\n# Verifica\u00e7\u00e3o do local para carga de dados\npath = os.environ['PATH']\n\nif path.startswith('C'):\n    IN_KAGGLE = False\nelse:\n    IN_KAGGLE = True\n    \n\n# Bibliotecas espec\u00edficas do livro Introduction to Machine Learning with Python\n# https:\/\/github.com\/amueller\/introduction_to_ml_with_python\n# pip install mglearn\n\nimport mglearn\n\n\n# Configura\u00e7\u00e3o do n\u00famero de linhas e colunas a serem apresentadas em listagens\npd.set_option('display.max_row', 1000)\n\npd.set_option('display.max_columns', 50)\n","fd538741":"os.listdir('..\/input')","8d9eee6b":"# Fun\u00e7\u00e3o de convers\u00e3o de dados copiada de https:\/\/github.com\/shakedzy\/dython\/blob\/master\/dython\/_private.py\n# Autor Shaked Zychlinski\n\ndef convert(data, to):\n    converted = None\n    if to == 'array':\n        if isinstance(data, np.ndarray):\n            converted = data\n        elif isinstance(data, pd.Series):\n            converted = data.values\n        elif isinstance(data, list):\n            converted = np.array(data)\n        elif isinstance(data, pd.DataFrame):\n            converted = data.as_matrix()\n    elif to == 'list':\n        if isinstance(data, list):\n            converted = data\n        elif isinstance(data, pd.Series):\n            converted = data.values.tolist()\n        elif isinstance(data, np.ndarray):\n            converted = data.tolist()\n    elif to == 'dataframe':\n        if isinstance(data, pd.DataFrame):\n            converted = data\n        elif isinstance(data, np.ndarray):\n            converted = pd.DataFrame(data)\n    else:\n        raise ValueError(\"Unknown data conversion: {}\".format(to))\n    if converted is None:\n        raise TypeError('cannot handle data conversion of type: {} to {}'.format(type(data),to))\n    else:\n        return converted","27874a24":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\n\ndef redes_neurais_regressao(X_, Y_, to_scale=True):\n\n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    #Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala vari\u00e1veis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n        Y_escale = Y_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_escale, test_size=0.1, random_state=random_state,shuffle =True)\n\n    estimatorNN = MLPRegressor(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=False,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\n    estimatorNN.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorNN.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Rede Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    mean_error = mean_absolute_error(y_test, estimatorNN.predict(x_test))\n    print('\\nErro {}'.format(mean_error))\n    \n    mean_s_error = mean_squared_error(y_test, estimatorNN.predict(x_test))\n    print('\\nErro {}'.format(mean_s_error))\n    \n    r2 = r2_score(y_test, estimatorNN.predict(x_test)) \n    print('\\nR2 Score {}'.format(r2))\n    \n    return estimatorNN,r2","1c31aaab":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ndef redes_neurais_classificacao(X_, Y_, to_scale=True):\n\n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala vari\u00e1veis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n\n    estimatorNN = MLPClassifier(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=False,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\n    estimatorNN.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorNN.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Rede Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    # TN FP\n    # FN TP\n    confusion = confusion_matrix(y_test, estimatorNN.predict(x_test))\n    print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n    \n    f1 = f1_score(y_test, estimatorNN.predict(x_test), average ='micro')\n    print(\"\\nf1 score: {:.2f}\".format( f1   ))\n    \n    erro = np.sum(np.abs(estimatorNN.predict(x_test)-y_test))\/len(y_test)\n    print('\\nErro {}'.format(erro))\n    \n    \n    print(classification_report(y_test, estimatorNN.predict(x_test),\n        target_names=[\"Falso\", \"Positivo\"]))\n    \n    return estimatorNN,erro","9b16863a":"from sklearn.tree import DecisionTreeRegressor\n\ndef arvore_regressao(X_, Y_, to_scale=True):\n    \n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala vari\u00e1veis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n    \n    estimatorTree = DecisionTreeRegressor(max_depth=5, random_state = random_state)\n    estimatorTree.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorTree.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('\u00c1rvore Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    print('Import\u00e2ncias {}'.format(estimatorTree.feature_importances_))\n    \n    mean_error = mean_absolute_error(y_test, estimatorTree.predict(x_test))\n    print('\\nErro {}'.format(mean_error))\n    \n    mean_s_error = mean_squared_error(y_test, estimatorTree.predict(x_test))\n    print('\\nErro {}'.format(mean_s_error))\n    \n    r2 = r2_score(y_test, estimatorTree.predict(x_test)) \n    print('\\nR2 Score {}'.format(r2))\n    \n    return estimatorTree,r2\n    \n","c86b754f":"from sklearn.tree import DecisionTreeClassifier\n\ndef arvore_classificacao(X_, Y_, to_scale=True):\n    \n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala vari\u00e1veis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n    \n    estimatorTree = DecisionTreeClassifier(max_depth=5, random_state = random_state)\n    estimatorTree.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorTree.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('\u00c1rvore Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n\n    \n    \n    print('Import\u00e2ncias {}'.format(estimatorTree.feature_importances_))\n    \n    confusion = confusion_matrix(y_test, estimatorTree.predict(x_test))\n    print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n    \n    f1 = f1_score(y_test, estimatorTree.predict(x_test), average ='micro')\n    print(\"\\nf1 score: {:.2f}\".format( f1   ))\n    \n    erro = np.sum(np.abs(estimatorTree.predict(x_test)-y_test))\/len(y_test)\n    print('\\nErro {}'.format(erro))\n    \n    \n    print(classification_report(y_test, estimatorTree.predict(x_test),\n        target_names=[\"Falso\", \"Positivo\"]))\n    \n    return estimatorTree,erro\n    \n    ","bf2fc07f":"if IN_KAGGLE:\n    world_happiness = pd.read_csv(\"..\/input\/world-happiness\/2016.csv\")\nelse:\n    world_happiness = pd.read_csv(\"2016.csv\")\n\n# Conjunto completo\nworld_happiness = world_happiness.loc[:,['Country', 'Region', 'Happiness Rank', 'Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']]\n\n\n\n#world_happiness = shuffle(world_happiness).reset_index(drop=True)\n\n# Conjunto resumido para treinamento de modelos\nworld_happiness_resumido = world_happiness.loc[:,[ 'Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity']]\n\n# Cria vari\u00e1veis para treinamento de modelos\n\ncolunas_fonte = [ \n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity'\n]\n\ncolunas_objetivo = [ \n       'Happiness Score'\n]\n\nworld_happiness_resumido_X = world_happiness_resumido.loc[:,colunas_fonte] \nworld_happiness_resumido_Y = world_happiness_resumido.loc[:,colunas_objetivo]\n\n\nworld_happiness.head(35)","4ef7bd5e":"if IN_KAGGLE:\n    tips = pd.read_csv('..\/input\/snstips\/tips.csv')\n    if 'Unnamed: 0' in tips.columns:\n        tips.drop(['Unnamed: 0'], inplace=True, axis=1)\nelse:\n    tips = sns.load_dataset('tips')\n\ntips.head()\n","0cf78aea":"from sklearn.datasets import load_breast_cancer\n\ncancer = load_breast_cancer()\n\ncancer_data = cancer['data']\n# 1 benigno, 0 maligno\ncancer_target = cancer['target']\ncancer_target_names  = cancer['target_names']\ncancer_feature_names = cancer['feature_names']","b02abc9e":"cancer_data_DF = pd.DataFrame(cancer_data,columns=cancer_feature_names) \ncancer_data_DF.head()","3895c1b6":"cancer_target_DF = pd.DataFrame(cancer_target,columns=['target']) \ncancer_target_DF.head()","8e742c36":"world_happiness_resumido_X.var()","6ec9d64b":"from sklearn.feature_selection import VarianceThreshold\n\nsel = VarianceThreshold(threshold=0.05)\nworld_happiness_resumido_VarianceThreshold = sel.fit_transform(world_happiness_resumido_X)\nworld_happiness_resumido_VarianceThreshold[0:5,:]","81c5c13f":"world_happiness_resumido_X.head()","c4a6161a":"world_happiness_resumido_X.shape","9f48cbc9":"world_happiness_resumido_VarianceThreshold.shape","fe0d4699":"_,_ = redes_neurais_regressao(world_happiness_resumido_X, \n                              world_happiness_resumido_Y\n                                       )","dbdee310":"_,_ = redes_neurais_regressao(world_happiness_resumido_VarianceThreshold, \n                              world_happiness_resumido_Y\n                                       )","87b9946e":"estimatorArvore,_ = arvore_regressao(world_happiness_resumido_VarianceThreshold, \n                              world_happiness_resumido_Y)","c842f639":"min_max_scaler = preprocessing.MinMaxScaler()\ncancer_data_DF_scaled = min_max_scaler.fit_transform(cancer_data_DF)\ncancer_data_DF_scaled = pd.DataFrame(cancer_data_DF_scaled,columns=cancer_feature_names) \ncancer_data_DF_scaled.head()","06fbae74":"cancer_data_DF_scaled.var()","9aee14cf":"cancer_data_DF_scaled.shape","459e6b1c":"from sklearn.feature_selection import VarianceThreshold\n\nsel = VarianceThreshold(threshold=0.02)\ncancer_data_DF_scaled_VarianceThreshold = sel.fit_transform(cancer_data_DF_scaled)\ncancer_data_DF_scaled_VarianceThreshold.shape","102a959b":"_,_ = redes_neurais_classificacao(cancer_data_DF_scaled, \n                              cancer_target_DF\n                                       )","8a02f033":"_,_ = redes_neurais_classificacao(cancer_data_DF_scaled_VarianceThreshold, \n                              cancer_target_DF\n                                       )","cdb47b94":"\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\n\nworld_happiness_resumido_SelectKBest = SelectKBest(f_regression, k=2).fit_transform(world_happiness_resumido_X, np.ravel(world_happiness_resumido_Y))\n\nfig, ax = plt.subplots(1, 1, figsize=figsize)\nplt.scatter(world_happiness_resumido_SelectKBest[:,0], \n            world_happiness_resumido_SelectKBest[:,1], \n            s=world_happiness_resumido_Y.values**3)\nplt.grid(True)\nplt.tight_layout()","9332ace2":"estimatorNN,_ = redes_neurais_regressao(world_happiness_resumido_SelectKBest, world_happiness_resumido_Y)","230f3250":"estimatorArvore,_ = arvore_regressao(world_happiness_resumido_SelectKBest, world_happiness_resumido_Y)","95ed4253":"\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\ncancer_data_SelectKBest = SelectKBest(f_classif, k=2).fit_transform(\n    cancer_data_DF_scaled, np.ravel(cancer_target_DF))\n\nfig, ax = plt.subplots(1, 1, figsize=figsize)\nplt.scatter(cancer_data_SelectKBest[:,0], \n            cancer_data_SelectKBest[:,1], \n            s=(cancer_target_DF.values+1)*30)\nplt.grid(True)\nplt.tight_layout()","5ef12c4f":"_,_ = redes_neurais_classificacao(cancer_data_SelectKBest, \n                              cancer_target_DF\n                                       )","bc027404":"from sklearn.feature_selection import SelectFromModel\n\nestimatorArvore,_ = arvore_regressao(world_happiness_resumido_X, world_happiness_resumido_Y)\n\nmodel = SelectFromModel(estimatorArvore, prefit=True)\nworld_happiness_resumido_SelectKBest = model.transform(world_happiness_resumido_X)\n","d2d5551a":"world_happiness_resumido_X.shape","468cdc46":"world_happiness_resumido_SelectKBest.shape","e4689672":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(world_happiness_resumido_SelectKBest[:,0], \n            world_happiness_resumido_SelectKBest[:,1], \n            s=world_happiness_resumido_Y.values**3)\nplt.grid(True)","9cbc28c0":"estimatorArvore,_ = arvore_regressao(world_happiness_resumido_SelectKBest, world_happiness_resumido_Y)","86eb55a3":"from sklearn.feature_selection import SelectFromModel\n\nestimatorArvore,_ = arvore_classificacao(cancer_data_DF_scaled, cancer_target_DF)\n\nmodel = SelectFromModel(estimatorArvore, prefit=True)\ncancer_data_SelectKBest = model.transform(cancer_data_DF)\n","9c7e98f1":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(cancer_data_SelectKBest[:,0], \n            cancer_data_SelectKBest[:,1], \n            s=(cancer_target_DF.values+1)*30)\nplt.grid(True)","1e8627b2":"_,_ = redes_neurais_classificacao(cancer_data_SelectKBest, \n                              cancer_target_DF\n                                       )","e4974e36":"from sklearn.feature_selection import SelectPercentile\n\nselect = SelectPercentile(percentile=50)\nselect.fit(world_happiness_resumido_X, world_happiness_resumido_Y)\nworld_happiness_resumido_SelectPercentile = select.transform(world_happiness_resumido_X)\nprint(\"X.shape: {}\".format(world_happiness_resumido_X.shape))\nprint(\"X_SelectPercentile.shape: {}\".format(world_happiness_resumido_SelectPercentile.shape))","b1bd2f53":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(world_happiness_resumido_SelectPercentile[:,0], \n            world_happiness_resumido_SelectPercentile[:,1], \n            s=world_happiness_resumido_Y.values**3)\nplt.grid(True)","b5901c9d":"estimatorNN,_ = redes_neurais_regressao(world_happiness_resumido_SelectPercentile, world_happiness_resumido_Y)","de8547ec":"estimatorArvore,_ = arvore_regressao(world_happiness_resumido_SelectPercentile, world_happiness_resumido_Y)","81a010f3":"from sklearn.decomposition import FactorAnalysis\nfactor = FactorAnalysis(n_components=2, random_state=random_state).fit(world_happiness_resumido_X)\nworld_happiness_resumido_factor = factor.transform(world_happiness_resumido_X)","8dc43115":"pd.DataFrame(factor.components_,columns=world_happiness_resumido_X.columns)\n","4c81ddd9":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(world_happiness_resumido_factor[:,0], \n            world_happiness_resumido_factor[:,1], \n            s=world_happiness_resumido_Y.values**3)\nplt.grid(True)","a9dbe0da":"_,_ = redes_neurais_regressao(world_happiness_resumido_factor, world_happiness_resumido_Y)","ac462188":"_,_ = arvore_regressao(world_happiness_resumido_factor, world_happiness_resumido_Y)","1dce967c":"from sklearn.decomposition import FactorAnalysis\nfactor = FactorAnalysis(n_components=2, random_state=random_state).fit(cancer_data_DF)\ncancer_data_DF_factor = factor.transform(cancer_data_DF)","862f10a2":"pd.DataFrame(factor.components_,columns=cancer_data_DF.columns)\n","58c3c2d8":"fig, ax = plt.subplots(1, 1, figsize=(19,10))\nplt.scatter(cancer_data_DF_factor[:,0], \n            cancer_data_DF_factor[:,1], \n            s=(cancer_target_DF.values+1)*30)\nplt.grid(True)","192abc59":"_,_ = redes_neurais_classificacao(cancer_data_DF_factor, cancer_target_DF)","c569b5ef":"_,_ = arvore_classificacao(cancer_data_DF_factor, cancer_target_DF)","b9004b6a":"# fonte Introduction to Machine Learning with Python\n# by Andreas C. M\u00fcller and Sarah Guido\n\nimport mglearn\nmglearn.plots.plot_pca_illustration()","6457af4d":"\n\npca = PCA(random_state=random_state).fit(world_happiness_resumido_X)\nprint ('Vari\u00e2ncia por componente: {}'.format(pca.explained_variance_ratio_))\npd.DataFrame(pca.components_,columns=world_happiness_resumido_X.columns)\n","7b5c7af4":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit (world_happiness_resumido_X)\nworld_happiness_resumido_X_scaled = scaler.transform(world_happiness_resumido_X)\n\npca = PCA(random_state=random_state).fit(world_happiness_resumido_X_scaled)\nprint ('Vari\u00e2ncia por componente: {}'.format(pca.explained_variance_ratio_))\npd.DataFrame(pca.components_,columns=world_happiness_resumido_X.columns)","f262a5e3":"# Vari\u00e2ncia do conjunto original\n\nworld_happiness_resumido_X.var()","0cac3aac":"# Vari\u00e2ncia dos dados projetados\n\nworld_happiness_resumido_PCA = PCA(random_state=random_state).fit_transform(world_happiness_resumido_X_scaled)\nnp.var(world_happiness_resumido_PCA, axis=0)","eb3192a6":"# PCA n\u00e3o garante separabilidade do conjunto\n\nfrom sklearn.decomposition import PCA\n\nworld_happiness_resumido_PCA = PCA(n_components=2,random_state=random_state).fit_transform(world_happiness_resumido_X_scaled)\n\nfig, ax = plt.subplots(1, 1, figsize=figsize)\nplt.scatter(world_happiness_resumido_PCA[:,0], world_happiness_resumido_PCA[:,1], s=world_happiness_resumido_Y.values**3)","3a817d05":"from sklearn.manifold import TSNE\ntsne = TSNE(random_state=random_state)\n# use fit_transform instead of fit, as TSNE has no transform method\n# default 2 componentes\nworld_happiness_tsne = tsne.fit_transform(world_happiness_resumido_X_scaled)\n\nplt.figure(figsize=figsize)\nplt.scatter(world_happiness_tsne[:,0], world_happiness_tsne[:,1], s=world_happiness_resumido_Y.values**3)\n\nplt.xlabel(\"t-SNE feature 0\")\nplt.xlabel(\"t-SNE feature 1\")","748279a5":"world_happiness_resumido_X_scaled.shape","68e83d09":"world_happiness_tsne.shape","f7c761d7":"# Kernel PCA pode melhorar a separabilidade\n# http:\/\/scikit-learn.org\/stable\/auto_examples\/decomposition\/plot_kernel_pca.html#sphx-glr-auto-examples-decomposition-plot-kernel-pca-py\n\n\nfrom sklearn.decomposition import PCA, KernelPCA\n\n\nkpca = KernelPCA(\n    kernel=\"sigmoid\", \n    fit_inverse_transform=True)\n\nworld_happiness_resumido_PCA = kpca.fit_transform(world_happiness_resumido_X_scaled)\n\nfig, ax = plt.subplots(1, 1, figsize=figsize)\nplt.scatter(world_happiness_resumido_PCA[:,0], world_happiness_resumido_PCA[:,1], s=world_happiness_resumido_Y.values**3)","2dbf45ea":"world_happiness_resumido_X_scaled.shape","7dfda286":"world_happiness_resumido_PCA.shape","b3f164ca":"_,_ = arvore_regressao(world_happiness_resumido_PCA, world_happiness_resumido_Y)","1756aca6":"from sklearn.datasets import load_breast_cancer\ncancer = load_breast_cancer()\nscaler = StandardScaler()\nscaler.fit(cancer.data)\nX_scaled = scaler.transform(cancer.data)\n\nfrom sklearn.decomposition import PCA\n# keep the first two principal components of the data\npca = PCA(n_components=2)\n# fit PCA model to breast cancer data\npca.fit(X_scaled)\n# transform data onto the first two principal components\nX_pca = pca.transform(X_scaled)\nprint(\"Original shape: {}\".format(str(X_scaled.shape)))\nprint(\"Reduced shape: {}\".format(str(X_pca.shape)))\n\nplt.figure(figsize=(8, 8))\nmglearn.discrete_scatter(X_pca[:, 0], X_pca[:, 1], cancer.target)\nplt.legend(cancer.target_names, loc=\"best\")\nplt.gca().set_aspect(\"equal\")\nplt.xlabel(\"First principal component\")\nplt.ylabel(\"Second principal component\")","69a1100f":"plt.matshow(pca.components_, cmap='viridis')\nplt.yticks([0, 1], [\"First component\", \"Second component\"])\nplt.colorbar()\nplt.xticks(range(len(cancer.feature_names)),\ncancer.feature_names, rotation=60, ha='left')\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Principal components\")","7afcc15b":"_,_ = redes_neurais_classificacao(X_pca[:,0:2], cancer_target_DF)","49225975":"_,_ = arvore_classificacao(X_pca[:,0:2], cancer_target_DF)","814f2939":"## Treinamento de \u00e1rvore de decis\u00e3o para regress\u00e3o\n\nUsada ao longo do caderno para testar efeitos da redu\u00e7\u00e3o de dimensionalidade\n\nhttp:\/\/scikit-learn.org\/stable\/auto_examples\/tree\/plot_tree_regression.html","a0d95fb0":"<font size=\"10\" color=\"black\">Redu\u00e7\u00e3o de dimensionalidade<\/font>\n\nEduardo Chaves Ferreira\n\n","7a040f32":"## KernelPCA\n\nTransforma o espa\u00e7o original atrav\u00e9s de Kernels para s\u00f3 ent\u00e3o aplicar PCA\n\nVer exemplo em http:\/\/scikit-learn.org\/stable\/auto_examples\/decomposition\/plot_kernel_pca.html","e12411ef":"## Carrega dados para exerc\u00edcio\n","82db7f63":"## Treinamento de rede neural para classifica\u00e7\u00e3o\n\nUsada ao longo do caderno para testar efeitos da redu\u00e7\u00e3o de dimensionalidade\n\nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html","5423f09e":"Data set de gorgetas com vari\u00e1veis categ\u00f3ricas","65e4efd7":"## Treinamento de rede neural para regress\u00e3o\n\nUsada ao longo do caderno para testar efeitos da redu\u00e7\u00e3o de dimensionalidade\n\nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPRegressor.html","ff8a98c4":"## An\u00e1lise de Fatores\n\nIdentifica novas vari\u00e1veis (fatores) que justifiquem as correla\u00e7\u00f5es existentes entre as vari\u00e1veis","c243d173":"# 2- Carga de dados\n\n\n","67af1b6b":"# 9- Redu\u00e7\u00e3o de dimensionalidade por cria\u00e7\u00e3o de vari\u00e1veis","ddcfd755":"## Dados de exemplo\n\nWorld happiness report (http:\/\/worldhappiness.report\/).\n\nSomente vari\u00e1veis num\u00e9ricas","45ad742f":"## Treinamento de \u00e1rvore de decis\u00e3o para classifica\u00e7\u00e3o\n\nUsada ao longo do caderno para testar efeitos da redu\u00e7\u00e3o de dimensionalidade\n\nhttp:\/\/scikit-learn.org\/stable\/auto_examples\/tree\/plot_tree_Classifier.html","73ae45c2":"Dados sobre tumores (somente informa\u00e7\u00f5es num\u00e9ricas)\n\nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.datasets.load_breast_cancer.html","a8937e7c":"#### <br>\n<font size=\"8\" color=\"red\">EXERC\u00cdCIO<\/font>\n\nRealize a an\u00e1lise acima para cancer_data_DF\n","c302501f":"#### <br>\n<font size=\"8\" color=\"red\">EXERC\u00cdCIO<\/font>\n\nRealize a an\u00e1lise acima para cancer_data_DF\n\n\n","647b0a67":"#### <br>\n<font size=\"8\" color=\"red\">EXERC\u00cdCIO<\/font>\n\nRealize a an\u00e1lise acima para cancer_data_DF\n","1bc4d0b9":"# Estat\u00edstica Univariada\n\nVerifica correla\u00e7\u00f5es lineares entre vari\u00e1veis e entre elas com a vari\u00e1vel dependente\n\nNo caso de classifica\u00e7\u00e3o \u00e9 chamada analysis of variance (ANOVA).","bcc19401":"#### <br>\n<font size=\"8\" color=\"red\">EXERC\u00cdCIO<\/font>\n\nRealize a an\u00e1lise acima para cancer_data_DF\n","08f6a95c":"## TSNE\n\nM\u00e9todo de visualiza\u00e7\u00e3o de conjuntos de dados de alta dimensionalidade\n\nBusca proximidade dos pontos no espa\u00e7o original e tenta preservar tal proximidade em espa\u00e7o de menor dimens\u00e3o","15b3cb09":"## An\u00e1lise de correla\u00e7\u00e3o linear\n\nhttp:\/\/scikit-learn.org\/stable\/modules\/feature_selection.html","05333139":"# 1- Importa\u00e7\u00e3o de bibliotecas e fun\u00e7\u00f5es gerais usadas no caderno","19e634ac":"## An\u00e1lise de vari\u00e2ncia\n\nhttp:\/\/scikit-learn.org\/stable\/modules\/feature_selection.html\n\nVari\u00e1veis com maior vari\u00e2ncia tendem a ser melhor descriminadores, ou seja, s\u00e3o mais adequadas para utiliza\u00e7\u00e3o em algoritmos de classifica\u00e7\u00e3o e regress\u00e3o.\n\nVarianceThreshold seleciona colunas cuja vari\u00e2ncia esteja acima de determinado valor, passado como par\u00e2metro\n\n","0ce0afda":"## SelectPercentil","8ff4c15a":"#### <br>\n<font size=\"8\" color=\"red\">EXERC\u00cdCIO<\/font>\n\nRealize a an\u00e1lise acima para cancer_data_DF\n","798e1536":"## An\u00e1lise de Componentes Principais (PCA)\n\nhttps:\/\/www.dummies.com\/programming\/big-data\/data-science\/data-science-using-python-to-perform-factor-and-principal-component-analysis\/\n\nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html\n\nRotaciona dataset de forma a diminuir correla\u00e7\u00e3o\n\nOs componentes s\u00e3o ordenados por vari\u00e2ncia\n\nH\u00e1 tantos componentes quanto dimens\u00f5es no espa\u00e7o original\n\nUtilizado para diminui\u00e7\u00e3o de dimensionalidade e escolha de componentes (ou eixos) principais.\n\n","558984df":"## SelectFromModel\nhttp:\/\/scikit-learn.org\/stable\/modules\/feature_selection.html","02bfa120":"# 8- Redu\u00e7\u00e3o de dimensionalidade por sele\u00e7\u00e3o de vari\u00e1veis\n\nhttp:\/\/scikit-learn.org\/stable\/modules\/feature_selection.html\n\nTem o objetivo de descartar parte das vari\u00e1veis de forma a simplificar os modelos e facilitar sua converg\u00eancia","685518a7":"#### <br>\n<font size=\"8\" color=\"red\">EXERC\u00cdCIO<\/font>\n\nRealize a an\u00e1lise acima para cancer_data_DF\n","cc316b3b":"# Refer\u00eancias\n\nLivros usados como refer\u00eancia:\n\nIntroduction to Machine Learning with Python\n\nPython Data Science Handbook (https:\/\/www.oreilly.com\/library\/view\/python-data-science\/9781491912126\/)\n\nVisualiza\u00e7\u00e3o:\n\nhttps:\/\/python-graph-gallery.com\/\n\nhttp:\/\/www.apnorton.com\/blog\/2016\/12\/19\/Visualizing-Multidimensional-Data-in-Python\/\n\nhttps:\/\/towardsdatascience.com\/the-art-of-effective-visualization-of-multi-dimensional-data-6c7202990c57\n\nhttps:\/\/www.oreilly.com\/library\/view\/python-data-science\/9781491912126\/ch04.html\n\nhttps:\/\/matplotlib.org\/mpl_toolkits\/mplot3d\/tutorial.html","233eadc7":"## O que ser\u00e1 tratado no curso\n\n\n- Sele\u00e7\u00e3o de vari\u00e1veis\n\n- Cria\u00e7\u00e3o de vari\u00e1veis\n\n\n\n\n"}}