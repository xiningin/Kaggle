{"cell_type":{"ae815125":"code","1541b415":"code","f8477d8f":"code","74748942":"code","381a1944":"code","3a084c87":"code","1977981f":"code","adc27057":"code","e0fd88c7":"code","f5eac176":"code","93c90233":"code","ccf8f698":"code","bb8fc3bd":"code","ae804340":"code","a1650706":"code","48bd6e99":"code","36429c72":"code","7092004c":"code","2d7c59e2":"code","199aeb8e":"code","1205110f":"code","89fb98c1":"code","cb3daeb5":"code","32666371":"code","6a13cf1b":"code","cd710ec0":"code","767c86c1":"code","ae62368a":"code","488ddd7c":"code","4c8eeead":"code","f3f7f3f4":"code","9fab551b":"code","b034980b":"code","962eb758":"code","31e445f6":"code","33a08ea2":"code","cba7404b":"code","f20ba381":"code","0b369697":"markdown","b3c704a5":"markdown","12229522":"markdown","d8d9720a":"markdown","9e921395":"markdown","71d7d7b5":"markdown","8852596d":"markdown","20d23766":"markdown","b290718f":"markdown","0f28c82e":"markdown"},"source":{"ae815125":"# import packages\nimport csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OrdinalEncoder\n\nfrom sklearn.preprocessing import StandardScaler","1541b415":"#read data\ntraining_features_data = pd.read_csv(\"..\/input\/flu-shot-learning-h1n1-seasonal-flu-vaccines\/training_set_features.csv\",\n                    sep=',')\n\n\ntraining_set_labels = pd.read_csv(\"..\/input\/flu-shot-learning-h1n1-seasonal-flu-vaccines\/training_set_labels.csv\",\n                    sep=',')\n\n\ntest_features_data = pd.read_csv(\"..\/input\/flu-shot-learning-h1n1-seasonal-flu-vaccines\/test_set_features.csv\",\n                    sep=',')\n","f8477d8f":"print(test_features_data.shape)  \nprint(training_set_labels.shape) ","74748942":"#eliminate null values\n\n#for float types\ntraining_features_data=training_features_data.fillna(training_features_data.mean())\n\n#for string types\ntraining_features_data=training_features_data.fillna('out-of-category')","381a1944":"#check no missing values are left \ntraining_features_data.isna().sum()","3a084c87":"#encoding categorical features (str-->float)\nenc = OrdinalEncoder()\n\nenc.fit(training_features_data)\ntraining_features_data_arr=enc.transform(training_features_data)\n\ncol_names_list=training_features_data.columns\nencoded_categorical_df=pd.DataFrame(training_features_data_arr, columns=col_names_list)","1977981f":"#normalization(make all values bet. 0-1)\nscaler = StandardScaler()\nscaler.fit(encoded_categorical_df)\nnormalized_arr=scaler.transform(encoded_categorical_df)\n\nnormalized_df=pd.DataFrame(normalized_arr, columns=col_names_list)","adc27057":"#check if data types are correct or not \nnormalized_df.info()","e0fd88c7":"#check types of test dataset\ntest_features_data.info()","f5eac176":"#eliminate null values\n\n#for float types\ntest_features_data=test_features_data.fillna(test_features_data.mean())\n\n#for string types\ntest_features_data=test_features_data.fillna('out-of-category')","93c90233":"#check no missing values are left \ntest_features_data.isna().sum()","ccf8f698":"#encoding categorical features  (str-->float)\nenc = OrdinalEncoder()\nenc.fit(test_features_data)\ntest_features_data_arr=enc.transform(test_features_data)\n\ncol_names_list=test_features_data.columns\ntest_encoded_categorical_df=pd.DataFrame(test_features_data_arr, columns=col_names_list)","bb8fc3bd":"#check data types\ntest_encoded_categorical_df.info()","ae804340":"#normalization(bet. 0-1)\n\n#using minmax scaler(look up)\ntest_normalized_arr=scaler.transform(test_encoded_categorical_df)\ntest_normalized_df=pd.DataFrame(test_normalized_arr, columns=col_names_list)","a1650706":"#import sklearn methods \nfrom sklearn.metrics import roc_curve, classification_report, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.ensemble import RandomForestRegressor","48bd6e99":"# split df to X and Y\ny = training_set_labels.loc[:, 'seasonal_vaccine'].values\nX = normalized_df\n","36429c72":"# split data into 80-20 for training set \/ test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=42)\n\n# cross-validation with 5 splits\ncv = StratifiedShuffleSplit(n_splits=5, random_state = 42)","7092004c":"# display test scores and return result string and indexes of false samples\ndef display_test_scores(test, pred):\n    str_out = \"\"\n    str_out += (\"TEST SCORES\\n\")\n    str_out += (\"\\n\")\n\n    #print AUC score\n    auc = roc_auc_score(test, pred)\n    str_out += (\"AUC: {:.4f}\\n\".format(auc))\n    str_out += (\"\\n\")\n    \n    false_indexes = np.where(test != pred)\n    return str_out, false_indexes\n","2d7c59e2":"#decision tree regressor\nregressor = DecisionTreeRegressor(random_state = 0)\n\n# parameters \nparameters = {\n                \"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n                \"splitter\": [\"best\",\"random\"],\n                }\n\n# grid search for parameters\ngrid1 = GridSearchCV(estimator=regressor, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid1.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid1.best_params_, grid1.best_score_))\n\n# detailed dataframe of gridsearch\ndetailed_grid_results1 = pd.DataFrame(grid1.cv_results_)\ndetailed_grid_results1\n\n# prediction results\ny_pred1 = grid1.predict(X_test)\n\n# print accuracy metrics\nresults1, false1 = display_test_scores(y_test, y_pred1)\nprint(results1)","199aeb8e":"#Bayesian Ridge for regression \n\nclf_ridge = linear_model.BayesianRidge()\n\n\n# parameters \nparameters = {\n                'alpha_init': [None, 1],\n                'lambda_init': [1, 1e-3],\n            }\n\n\n# grid search for parameters\ngrid2 = GridSearchCV(estimator=clf_ridge, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid2.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid2.best_params_, grid2.best_score_))\n\n# prediction results\ny_pred2 = grid2.predict(X_test)\n\n#y_pred = 1\/(1+np.exp(-y_pred))\n\n\n# print accuracy metrics\nresults2, false2 = display_test_scores(y_test, y_pred2)\nprint(results2)","1205110f":"regr = SVR(C=1.0, epsilon=0.2)\n\n# parameters \nparameters = {\n                'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n                'C': [0.01,0.1,1,10,100],\n                'max_iter': [100,1000],\n            }\n\n# grid search for parameters\ngrid3 = GridSearchCV(estimator=regr, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid3.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid3.best_params_, grid3.best_score_))\n\n# prediction results\ny_pred3 = grid3.predict(X_test)\n\n# print accuracy metrics\nresults3, false3 = display_test_scores(y_test, y_pred3)\nprint(results3)","89fb98c1":"reg = SGDRegressor( tol=1e-3, random_state=42)\n\n\n# parameters \nparameters = {\n                'alpha': [0.0001, 0.001, 0.01, 1],\n                'max_iter': [10,100,1000],\n                'learning_rate': ['invscaling', 'optimal', 'adaptive'],\n            }\n\n# grid search for parameters\ngrid4 = GridSearchCV(estimator=reg, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid4.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid4.best_params_, grid4.best_score_))\n\n\n# prediction results\ny_pred4 = grid4.predict(X_test)\n\ny_pred4 = 1\/(1+np.exp(-y_pred4))\n\n\n# print accuracy metrics\nresults4, false4 = display_test_scores(y_test, y_pred4)\nprint(results4)","cb3daeb5":"rfr = RandomForestRegressor(random_state=0)\n\n# parameters \nparameters = {\n                'n_estimators': [20, 50, 100],\n            }\n\n# grid search for parameters\ngrid5 = GridSearchCV(estimator=rfr, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid5.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid5.best_params_, grid5.best_score_))\n\n\n\n# prediction results\ny_pred5 = grid5.predict(X_test)\n\n# print accuracy metrics\nresults5, false5 = display_test_scores(y_test, y_pred5)\nprint(results5)\n","32666371":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_absolute_error\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nmodel_1 = RandomForestRegressor(random_state=0, n_estimators=100)\nmodel_2 = SGDRegressor(tol=1e-3, alpha= 0.001, learning_rate='adaptive', max_iter=100)\nmodel_3 = linear_model.BayesianRidge(alpha_init=None, lambda_init= 0.001)\n\n\ncv_mae_1 = []\ncv_mae_2 = []\ncv_mae_3 = []\n\n\n\nfor X_train_list, X_test_list in kf.split(X):\n    model_1.fit(X.loc[X_train_list], y[X_train_list])\n    pred_1 = model_1.predict(X.loc[X_test_list])\n    err_1 = mean_absolute_error(y[X_test_list], pred_1)\n    cv_mae_1.append(err_1)\n    \n\n    model_2.fit(X.loc[X_train_list], y[X_train_list])\n    pred_2 = model_2.predict(X.loc[X_test_list])\n    err_2 = mean_absolute_error(y[X_test_list], pred_2)\n    cv_mae_2.append(err_2)\n    \n    model_3.fit(X.loc[X_train_list], y[X_train_list])\n    pred_3 = model_3.predict(X.loc[X_test_list])\n    err_3 = mean_absolute_error(y[X_test_list], pred_3)\n    cv_mae_3.append(err_3)\n    \n    ","6a13cf1b":"from scipy import stats\nprint(stats.ttest_rel(cv_mae_1,cv_mae_2))\nprint(stats.ttest_rel(cv_mae_3,cv_mae_2))\nprint(stats.ttest_rel(cv_mae_3,cv_mae_1))\n\n#\u00fc\u00e7 modeli kar\u015f\u0131la\u015ft\u0131rd\u0131k; hepsi significant \u00e7\u0131kt\u0131, en b\u00fcy\u00fck olan modeli se\u00e7iyoruz, eyv:dd\n","cd710ec0":"#Bayesian Ridge for regression \n\n#clf_ridge = linear_model.BayesianRidge(alpha_init=None, lambda_init=0.001)\n#clf_ridge.fit(X,y)\n\n# prediction results\n#y_pred = clf_ridge.predict(test_normalized_df)\n\n#y_pred = 1\/(1+np.exp(-y_pred))\n","767c86c1":"#Random forest regressor\n\nrfr = RandomForestRegressor(random_state=0, n_estimators=100)\nrfr.fit(X,y)\n\n# prediction results\ny_pred = rfr.predict(test_normalized_df)","ae62368a":"np.sum(np.logical_or(np.array(y_pred) > 1, np.array(y_pred) < 0), axis=0)","488ddd7c":"#negative values are handled by \"sigmoid\"\n#reg = SGDRegressor(alpha= 0.001, learning_rate='adaptive', max_iter=100)\n#reg.fit(X,y)\n\n# prediction results\n#y_pred = reg.predict(test_normalized_df)\n\n#y_pred = 1\/(1+np.exp(-y_pred))\n","4c8eeead":"#pred sonu\u00e7lar\u0131n\u0131 dosyaya yazd\u0131rma\n\ndf_pred_seasonal_vaccine=pd.DataFrame(y_pred, columns=['seasonal_vaccine'])\ndf_pred_seasonal_vaccine[\"respondent_id\"] = df_pred_seasonal_vaccine.index\n\ndf_pred_seasonal_vaccine=df_pred_seasonal_vaccine[['respondent_id', 'seasonal_vaccine']]\n\ndf_pred_seasonal_vaccine.to_csv('\/kaggle\/working\/df_seasonal.csv', columns=['respondent_id', 'seasonal_vaccine'], \n                            index=False, sep=',')","f3f7f3f4":"df_pred_seasonal_vaccine.head()","9fab551b":"df_pred_h1n1_vaccine = pd.read_csv(\"..\/input\/h1n1-rf\/df (1).csv\",\n                    sep=',')\n","b034980b":"df_pred_h1n1_vaccine.head()","962eb758":"df_final = df_pred_h1n1_vaccine.merge(df_pred_seasonal_vaccine, on=\"respondent_id\", how = 'inner')","31e445f6":"df_final.head()","33a08ea2":"df_final['respondent_id'] = df_final['respondent_id'].astype(int) + 26707","cba7404b":"#pred sonu\u00e7lar\u0131n\u0131 dosyaya yazd\u0131rma\n\n#df_final=df[['respondent_id', 'h1n1_vaccine', 'seasonal_vaccine' ]]\n\ndf_final.to_csv('\/kaggle\/working\/df_denemeee_son.csv', columns=['respondent_id', 'h1n1_vaccine', 'seasonal_vaccine' ], \n                            index=False, sep=',')","f20ba381":"df_final.head()","0b369697":"# Regressor-1: Decision Tree regressor","b3c704a5":"# Regressor-5: RandomForestRegressor","12229522":"# **test dataset**","d8d9720a":"# **train dataset**","9e921395":"# t-test","71d7d7b5":">  if p-value<=0.05 --> difference of two model is significant(yani iki modelin fark\u0131 belirgin, yani iki model farkl\u0131)\n\n>  if p-value>0.05 --> difference of two model is NOT significant(yani iki model \u00e7ok farkl\u0131 de\u011fil)","8852596d":"# Regressor-2: Bayesian-Ridge","20d23766":"# **regression**","b290718f":"# Regressor-4: SGDRegressor","0f28c82e":"# Regressor-3: SVR"}}