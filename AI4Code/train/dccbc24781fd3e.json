{"cell_type":{"6476ea83":"code","6223eb9d":"code","86860dab":"code","35171edd":"code","cab73c75":"code","997431f5":"code","e375b181":"code","830763e9":"code","5f746c46":"code","20bfbe2c":"code","46d947cc":"code","a1b4036b":"code","3f1ac8a3":"code","f8d1f1c4":"code","49956bbc":"code","a6006971":"code","a4698f8b":"code","6b645f41":"code","9747622a":"code","69d7ad36":"code","ad21f407":"code","ceabc2d4":"code","8ba65f0c":"code","3fb588f7":"code","07775f95":"code","5f514dc7":"code","6c8224b3":"code","a781f34d":"code","42b47d41":"code","e1e71dd9":"code","5d90d7f7":"code","aada53f1":"code","51a7bfff":"code","27150d04":"code","615b7335":"code","1b44b307":"code","f60729b2":"code","cf73e661":"code","f3a99e3d":"code","fbeac988":"code","d68c664e":"code","44c8a92a":"markdown"},"source":{"6476ea83":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm, skew\nfrom scipy import stats\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6223eb9d":"# Read training and testing data sets\ntrain = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv')\nall_data = pd.concat([train, test], axis='index')","86860dab":"# Shape of data\nprint(\"Training Data Shape: \",train.shape)\nprint(\"Testing Data Shape: \", test.shape)","35171edd":"# data info\ntrain.info()","cab73c75":"# Split data into Input variables and Target Variable\n# remove the Id column from training data (not useful)\ny_train = train['SalePrice']\nX_train = train.drop(['SalePrice', 'Id'], axis='columns')\n\n# remove Id column from testing data but keep it for submission\nX_test = test.drop(['Id'], axis='columns')\nX_test_ids = test['Id']","997431f5":"# Explore some stats about our target variable SalePrice\ny_train.describe()","e375b181":"# Explore the distribution of the target variable\nsns.histplot(data= y_train)","830763e9":"# it is apparently not normally distributed, let's see how far it is from normal distribution\n# using Q\u2013Q (quantile-quantile) plot\nfig = plt.figure()\nres = stats.probplot(x = y_train, plot= plt, dist='norm')\nplt.show()","5f746c46":"# divide columns into categorical and numeric\ncat_cols = X_train.select_dtypes('object').columns.to_list()\nnum_cols = X_train.select_dtypes('number').columns.to_list()","20bfbe2c":"# Check Numeric Variables First\nprint(f'There are {len(num_cols)} numeric variables') # excluding the Id column\n\n# Let's see how they correlate with the target variable\nnum_corr_target = X_train[num_cols].corrwith(y_train, axis='index').sort_values(ascending=False)\n\n# Let's see how many highly correlate (has correlation coefficient >= |0.5|)\nprint(f'Numeric features with high correlation (>= |0.5|) to target variable:')\nhigh_num_corr_target = num_corr_target[num_corr_target >= abs(0.5)]\nprint(high_num_corr_target)\n\nhigh_num_corr_target_matrix = train[high_num_corr_target.index.to_list() + ['SalePrice']].corr()\nhigh_num_corr_target_matrix","46d947cc":"# Visualize the correlation matrix using heatmap\nfig, ax = plt.subplots(figsize=(11, 9))\nsns.heatmap(high_num_corr_target_matrix, annot= True)\nplt.show()\n\n# Observations:\n# OverallQual, GrLivArea, GarageCars are the top 3 correlated features\n# There is multicollinearity in the data. For example GarageCars and GarageArea are highly correlated (0.88)\n# and both of them are highly correlated with the SalePrice.\n# If you think about it, the space of garage and number of cars that can fit are closely related to each other.","a1b4036b":"# Having a closer look on the most correlated feature (OverallQual)\nfig, ax = plt.subplots(figsize=(11, 9))\nsns.boxplot(x=\"OverallQual\", y=\"SalePrice\", data=train)\nplt.show()\n\n# The positive correlation is obvious with a slightly upward curve.\n# Which indicates that as the overall quality of the house increases the price increases\n# Except for 2 candidate outliers (in my opinion), there are no extreme cases.\n# 1st candidate: expensive house in level 4\n# 2nd candidate: expensive house in level 8","3f1ac8a3":"# Having a closer look on the second most correlated feature (GrLivArea)\nfig, ax = plt.subplots(figsize=(11, 9))\n# sns.scatterplot(x=\"GrLivArea\", y=\"SalePrice\", data=train)\nsns.regplot(x=\"GrLivArea\", y=\"SalePrice\", data=train, ci=None, line_kws={\"color\":\"black\"})\nplt.show()\n\n# The positive linear relation is quite obvious here as well\n# Which indicates that as the (above ground) living area increases the price increases as well\n# There are 2 outliers (Id:1289 & 523) with huge living areas but very low prices (<200,000)\nX_train['GrLivArea'].sort_values(ascending=False).head(2)","f8d1f1c4":"# Check completeness of data\ncol_has_null = all_data.isna().sum()\ncol_w_null = col_has_null[col_has_null > 0].index.to_list()\ncol_has_null[col_has_null > 0].sort_values(ascending = False)","49956bbc":"# Primary strategies for filling missing data (will see as we go if we need other strategies)\n# For numerical features: assign 0\n# For categorical features: assign None\n\n# I make a copy so that I can compare before and after\nall_data_original = all_data.copy()\n\n# I will make a list of ordinal and categorical features that will need encoding\nordinal_features = []\nnominal_features = []","a6006971":"# From the description of features, we find that there are multiple columns that use the same quality measures\n# So we will encode them to an ordinal variable, so we can apply it to the different columns\nquality_ordinal_encoder = OrdinalEncoder(categories=\n                                         [['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n                                         ['Reg' 'IR1' 'IR2' 'IR3'],\n                                         ['None', 'Unf', 'RFn', 'Fin']])","a4698f8b":"# Pool Data : Quality and Area\n# From the data description we know that Quality is categorical where NA means no pool\n# So we can assign value None instead\nall_data['PoolQC'] = all_data['PoolQC'].fillna('None')\nprint(\"PoolQC after filling missing values\")\nprint(all_data[['PoolQC']].value_counts())","6b645f41":"# Now let's check if there are pools that have no quality\nall_data[(all_data['PoolQC'] == 'None') & (all_data['PoolArea'] > 0 )][['Id', 'PoolArea', 'PoolQC']]\n# There are 3 houses !","9747622a":"# A nice idea by ERIK BRUIN is to infer the quality of pool from the overall quality of the whole house\nall_data[(all_data['PoolQC'] == 'None') & (all_data['PoolArea'] > 0 )][['Id', 'PoolArea', 'PoolQC', 'OverallQual']]","69d7ad36":"# Assign the quality of pool to the mean of overall quality (overall quality scale is twice of the pool quality scale)\nall_data.loc[all_data['Id'] == 2421, 'PoolQC'] = 'Fa'\nall_data.loc[all_data['Id'] == 2504, 'PoolQC'] = 'TA'\nall_data.loc[all_data['Id'] == 2600, 'PoolQC'] = 'Fa'\n\nall_data[all_data['Id'].isin([2421,2504,2600])][['Id', 'PoolArea', 'PoolQC', 'OverallQual']]\n\n# PoolQC will be ordinal encoded\nordinal_features.append('PoolQc')","ad21f407":"# Misc Features\n# From the data description we know that Misc is categorical where NA means no extra features\n# So we can assign value None instead\nall_data['MiscFeature'] = all_data['MiscFeature'].fillna('None')\nprint(\"MiscFeature after filling missing values\")\nall_data[['MiscFeature']].value_counts()\n\n# MiscFeature will be one hot encoded\nnominal_features.append('MiscFeature')","ceabc2d4":"# Alley\n# From the data description we know that Alley is categorical where NA means no alley access\n# So we cann assign value None instead\nall_data['Alley'] = all_data['Alley'].fillna('None')\nprint('Alley after filling missing values')\nall_data['Alley'].value_counts()\n\n# Alley will be one hot encoded\nnominal_features.append('Alley')","8ba65f0c":"# Fence\n# From the data description we know that Fence is categorical where NA means no Fence\n# So we cann assign value None instead\nall_data['Fence'] = all_data['Fence'].fillna('None')\nprint('Fence after filling missing values')\nall_data['Fence'].value_counts()\n\n# Fence will be one hot encoded\nnominal_features.append('Fence')","3fb588f7":"# FirePlace Quality\n# From the data description we know that FirePlace Quality is categorical where NA means no Fire Place\n# So we cann assign value None instead\nall_data['FireplaceQu'] = all_data['FireplaceQu'].fillna('None')\nprint('FireplaceQu after filling missing values')\nall_data['FireplaceQu'].value_counts()","07775f95":"# Now let's check if there are Fireplaces that have no quality\nall_data[(all_data['FireplaceQu'] == 'None') & (all_data['Fireplaces'] > 0)][['Id', 'Fireplaces', 'FireplaceQu']]\n# There are none ! Everything looks good\n\n# FireplaceQu will be ordinal encoded\nordinal_features.append('FireplaceQu')","5f514dc7":"# LotFrontage\n# We know from the description that LotFrontage is numerical where NA is a missing value\n# Another nice idea by ERIK BRUIN is to infer the LotFrontage from the values of the neighborhood\n# But first let's check that all the neighborhoods have at least one value\nprint (all_data['Neighborhood'].nunique() == all_data[all_data['LotFrontage'].notna()]['Neighborhood'].nunique())","6c8224b3":"# Yes looks great! Now, let's assign the median value of LotFrontage from the same neighborhood\nall_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","a781f34d":"# Let's also have a look on other Lot features (LotShape, LotConfig)\n\n# LotShape\n# from the descriptions it looks like an ordinal feature\nprint(all_data['LotShape'].unique()) #  Add values to ordinal encoder\nordinal_features.append('LotShape')\n\n#LotConfig\nprint(all_data['LotConfig'].unique())\n# Doesn't seem like an ordinal feature, so will consider as nominal\nnominal_features.append('LotConfig')","42b47d41":"# Garage\n# There are multiple Garage variables with missing values\n# GarageCond       159\n# GarageYrBlt      159\n# GarageFinish     159\n# GarageQual       159\n# GarageType       157\n# In addition to 2 variables with 1 missing data\n# GarageCars       1\n# GarageArea       1\n\n# First let's check if the nulls happen for the same records\nall_data[(all_data['GarageCond'].isna()) & (all_data['GarageYrBlt'].isna()) & (all_data['GarageFinish'].isna()) & (all_data['GarageQual'].isna()) & (all_data['GarageType'].isna())].shape\n# So 157 out of 159 are common","e1e71dd9":"# Now let's see the 2 cases where the difference happens\nall_data[(all_data['GarageType'].notnull()) & (all_data['GarageCond'].isna())][['Id','GarageCond','GarageYrBlt','GarageFinish','GarageQual','GarageType','GarageCars','GarageArea', 'YearBuilt']]\n\n# House 2127 looks like it has a garage (figure out how to fill the values)\n# House 2577 looks like it doesn't have a garage (adjust values to reflect no garage)","5d90d7f7":"# For house 2127, I will consider the GarageYrBlt equal to YearBuilt (1910)\n# I will check the most common properties of Garages for houses built at that year\nall_data[all_data['YearBuilt'] == 1910].groupby(['GarageCond','GarageYrBlt','GarageFinish','GarageQual']).size().sort_values(ascending=False)","aada53f1":"# Set the values for the garage properties of 2127\nall_data.loc[all_data['Id'] == 2127,['GarageCond','GarageYrBlt','GarageFinish','GarageQual']] = ['Fa',1910,'Unf','TA']\nall_data.loc[all_data['Id'] == 2127,['GarageCond','GarageYrBlt','GarageFinish','GarageQual']]","51a7bfff":"# Set the values for the garage properties of 2577\nall_data.loc[all_data['Id'] == 2577,['GarageType']] = np.NaN\nall_data.loc[all_data['Id'] == 2577,['GarageCars']] = 0\nall_data.loc[all_data['Id'] == 2577,['GarageArea']] = 0\nall_data.loc[all_data['Id'] == 2577,['GarageCond','GarageYrBlt','GarageFinish','GarageQual','GarageType','GarageCars','GarageArea']]","27150d04":"# Now all the values should be equal to 158 and we can start handling them\nall_data[(all_data['GarageCond'].isna()) & (all_data['GarageYrBlt'].isna()) & (all_data['GarageFinish'].isna()) & (all_data['GarageQual'].isna()) & (all_data['GarageType'].isna())].shape","615b7335":"# 'GarageCond',\n# 'GarageYrBlt',\n# 'GarageFinish',\n# 'GarageQual',\n# 'GarageType',\n# 'GarageCars'\n# 'GarageArea'\n\n# GarageCond\n# from the descriptions it is an ordinal feature\n# let's fill the missing values\nall_data['GarageCond'] = all_data['GarageCond'].fillna('None')\nall_data['GarageCond'].value_counts() # --> 158 None as expected\nordinal_features.append('GarageCond')","1b44b307":"# GarageYrBlt\n# We will follow the same logic as YearRemodAdd\n# YearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\nall_data['GarageYrBlt'] = all_data['GarageYrBlt'].fillna(all_data['YearBuilt'])\nall_data[all_data['GarageCond'] == 'None'][['YearBuilt','GarageYrBlt']]","f60729b2":"# GarageFinish\n# from description it is an ordinal feature\nprint(all_data['GarageFinish'].unique()) # --> added the values to ordinal encoder up\nall_data['GarageFinish'] = all_data['GarageFinish'].fillna('None')\nordinal_features.append('GarageFinish')","cf73e661":"# GarageQual\n# from description it is an ordinal feature\nprint(all_data['GarageQual'].unique())\nall_data['GarageQual'] = all_data['GarageQual'].fillna('None')\nordinal_features.append('GarageQual')","f3a99e3d":"# GarageType\n# from description it is a nominal feature\nprint(all_data['GarageType'].unique())\nall_data['GarageType'] = all_data['GarageType'].fillna('No Garage')\nnominal_features.append('GarageType')","fbeac988":"# GarageCars\n# from description it is an ordinal feature\nprint(all_data['GarageCars'].value_counts())\nall_data['GarageCars'] = all_data['GarageCars'].fillna(0)\n\nprint('GarageCars after filling missing values') # remember it was 1 missing value and we filled it manually\nprint(all_data['GarageCars'].value_counts())\n\nordinal_features.append('GarageCars')","d68c664e":"# GarageArea\n# from description it is an ordinal feature\n# it doesn't make sense to print unique values since it is an area\nall_data['GarageArea'] = all_data['GarageArea'].fillna(0) # remember it was 1 missing value and we filled it manually\nordinal_features.append('GarageArea')","44c8a92a":"This notebook is inpired by [Detailed EDA by Erik Bruin](https:\/\/www.kaggle.com\/erikbruin\/house-prices-lasso-xgboost-and-a-detailed-eda\/report#loading-and-exploring-data)\n"}}