{"cell_type":{"f39b54d7":"code","e4ddfb0f":"code","7a4afc6b":"code","c82a59ab":"code","80605a2d":"code","5711694a":"code","ec7962f8":"code","c8f40df9":"code","bfac6c69":"code","5f23c5b4":"code","74b38ede":"code","3e5b0ba3":"code","50839f41":"code","b0c34418":"code","b65b0774":"code","9df78967":"code","41fb331f":"code","fa4d1418":"code","43a7ead2":"code","5e590c55":"code","b26520a8":"code","f2e8b20c":"code","2d9ed685":"code","07cc0053":"code","932c7ac1":"code","a2301a9e":"code","161be006":"code","fb4832e7":"code","e817bc5c":"code","3bc530a1":"code","6b53c94d":"code","ab680726":"code","af9aea62":"code","8e68d51c":"code","0ae598f0":"code","7bcc11c5":"code","784a0d4a":"code","0cf386d5":"code","8ac0b3a6":"code","87f3b81d":"code","164e170f":"code","bc935077":"code","d952bd92":"code","1a7bf72d":"code","7de0b57b":"code","4004c134":"code","47e56eaf":"code","6ba23fd7":"code","5035b70f":"code","2b9c1c9f":"code","87840bc3":"code","069954e6":"code","f41cf5f2":"code","056d2564":"code","05bd038a":"code","7ff0e3ac":"code","f95d8045":"code","0558e751":"code","c65f793d":"code","dbf85496":"code","4469212d":"code","d3cb605b":"code","39c9d900":"code","9fe1c3c7":"code","abf5660e":"code","9637cd30":"code","fb7f390e":"code","161559f0":"markdown","7ecaa281":"markdown","1449deb6":"markdown","8c7a592c":"markdown","cb1e2e1d":"markdown","388445d4":"markdown","895a898e":"markdown","5ffb5a45":"markdown","8f36db42":"markdown","d1a12297":"markdown","a52cfa50":"markdown","3a0ead89":"markdown","bb278fe8":"markdown","4603dee1":"markdown","6e9cecf3":"markdown","f2ce3257":"markdown","97054ec7":"markdown","af013d98":"markdown","82cb1d15":"markdown","16bd4431":"markdown","efa9fcd3":"markdown","ad38c2be":"markdown","a401f6b0":"markdown","94913ee8":"markdown","b4a4b8e6":"markdown","b4b22013":"markdown","6ee40428":"markdown","62bb4ca1":"markdown","c80498b4":"markdown","cd5e75e7":"markdown","8adf730a":"markdown","7d77558c":"markdown","5417727d":"markdown","932aed1d":"markdown","7a019d61":"markdown","fb971639":"markdown","95b2334a":"markdown","0111091b":"markdown","745c11be":"markdown","e680d3ff":"markdown","722319e7":"markdown","2d42b4d4":"markdown","aaa0b0a7":"markdown","63f95ea2":"markdown","caf47df6":"markdown","ce4eaf95":"markdown","418f93bc":"markdown","3b76f508":"markdown"},"source":{"f39b54d7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.spatial.distance import cosine\nimport os","e4ddfb0f":"path = '..\/input\/movielens-100k-dataset\/ml-100k\/'","7a4afc6b":"user = pd.read_csv(path+'u.user',header=None, delimiter='|',\n                  names=['userid','age','gender','occupation','zipcode'])\nuser.head(3)","c82a59ab":"#we will need this to pick the genre names to instill as column names in the movie dataframe\ngenre_info = (pd.read_csv(path+'u.genre',\n                          header=None,sep='|',index_col=1,\n                          names=['genre','index']))\ngenre_info.head()","80605a2d":"column_titles = ['movieid','movietitle', 'moviedate','video_release_date',\n                'imdb_url']+list(genre_info.values[:,0])\n\nmovie = pd.read_csv(path+'u.item',encoding='latin-1',sep='|',\n                   header=None, names=column_titles)\nmovie.head(3)","5711694a":"#drop unneeded columns\nmovie.drop(columns=['video_release_date','imdb_url'],inplace=True)\n\n#remove the year from the movietitle column and keep only the year in the moviedate column\nmovie['moviedate'] = movie['movietitle'].apply(lambda x: x[-5:-1])\nmovie['movietitle'] = movie['movietitle'].apply(lambda x: x[:-7])\n\nmovie.head(3)","ec7962f8":"ratings = pd.read_csv(path+'u.data',delimiter='\\t',header=None,\n                names=['userid','movieid','rating','timestamp'])\nratings.head(3)","c8f40df9":"#we will merge the ratings dataset with the movie titles, to make it more understandable \n#and we will lose the ratings['timestamp'] column in the process\n\nratings = pd.merge(ratings[['userid', 'movieid', 'rating']],\n                   movie[['movieid', 'movietitle']],\n                   how='left', left_on='movieid', right_on='movieid')\nratings.head(3)","bfac6c69":"# are there null values in any of the 3 datasets? No, there are not\nratings.isna().sum().sum(), user.isna().sum().sum(), movie.isna().sum().sum()","5f23c5b4":"rated = ratings[['rating','movietitle','movieid']].groupby(['movieid','movietitle']).mean()\nrated['number_of_reviews'] = ratings['movieid'].value_counts()[(np.arange(1682)+1)].values\nrated['movieid'] = (np.arange(1682)+1)\nrated['movietitle'] = ratings.drop_duplicates(subset='movieid').\\\n                      sort_values(by='movieid')['movietitle'].values\nrated.sort_values(by=['rating'],ascending=False).head()","74b38ede":"rated[(rated['movietitle']=='Casablanca')|(rated['movietitle']=='Citizen Kane')]","3e5b0ba3":"C = int(ratings.shape[0]\/movie.shape[0])\nprint('average number of ratings per movie: ',C)\nm = 3\nbayesian_averages = []\nfor movieid in np.sort(ratings['movieid'].unique()):\n    temp = ratings[ratings['movieid']==movieid]\n    numerator = C * m * temp['rating'].sum()\n    denominator = C + temp.shape[0]\n    bayesian_averages.append(numerator\/denominator)","50839f41":"rated['bayesian_average_rating'] = bayesian_averages\nrated.sort_values(by=['bayesian_average_rating'],ascending=False).head(10)","b0c34418":"def top_by_genre(genre,n=10):\n    \n    movieids = movie[movie[genre]==1]['movieid'].values\n    return rated.iloc[movieids].sort_values(by='bayesian_average_rating',ascending=False)[:n]\n\n\ntop_by_genre('Action',5)","b65b0774":"from sklearn.metrics import pairwise\nfrom scipy.spatial.distance import cosine","9df78967":"# Pearson correlation as similarity metric\n\npivoted = ratings.pivot(index='userid',columns='movieid',values='rating').fillna(value=0)\n\n\nuserids = user['userid'].values\nuser_sim = np.zeros((userids.shape[0],userids.shape[0]))\n\nfor i in (userids-1):\n    vector1 = pivoted.iloc[i].values\n    \n    for j in (userids-1)[i:]:\n        \n        vector2 = pivoted.iloc[j].values\n        user_sim[i,j] = np.corrcoef(vector1,vector2)[1,0]","41fb331f":"sns.heatmap(user_sim);","fa4d1418":"#copy values across diagonal\nfor i in np.arange(user_sim.shape[0]):\n    for j in np.arange (i, user_sim.shape[0]):\n        user_sim[j,i] = user_sim[i,j]","43a7ead2":"sns.heatmap(user_sim);","5e590c55":"#np.save('user2user_similarity.npy',user_sim)\n#user_sim = np.load('user2user_similarity.npy')","b26520a8":"#cosine similarity among users\npivoted = ratings.pivot(index='userid',columns='movieid',values='rating').fillna(value=0)\n\n\nuserids = user['userid'].values\nuser_cos_sim = np.zeros((userids.shape[0],userids.shape[0]))\n\nfor i in (userids-1):\n    vector1 = pivoted.iloc[i].values\n    \n    for j in (userids-1)[i:]:\n        \n        vector2 = pivoted.iloc[j].values\n        user_cos_sim[i,j] = 1 - cosine(vector1,vector2)","f2e8b20c":"sns.heatmap(user_cos_sim);","2d9ed685":"#copy values across diagonal\nfor i in np.arange(user_cos_sim.shape[0]):\n    for j in np.arange (i, user_cos_sim.shape[0]):\n        user_cos_sim[j,i] = user_cos_sim[i,j]","07cc0053":"#sanity check\npool = np.arange(943)\nins = np.random.choice(pool,size=2,replace=False)\nuser_cos_sim[ins[0],ins[1]], user_cos_sim[ins[1],ins[0]]","932c7ac1":"sns.heatmap(user_cos_sim);","a2301a9e":"#np.save('user2user_cosine_similarity.npy',user_cos_sim)\n#user_cos_sim = np.load('user2user_cosine_similarity.npy')","161be006":"def similar_users(userid,n=10,method='cosine'):\n\n    if method == 'cosine': matrix = user_cos_sim\n    else: \n        if method == 'pearson': matrix = user_sim\n        else: \n            print('choose method, either \\'cosine\\' or \\'pearson\\'')\n            return None\n    \n    args = np.argsort(matrix[userid-1])[::-1][1:n+1]\n\n    frame = pd.DataFrame()\n    frame['userid'] = args\n    frame['similarity_score'] = matrix[userid-1,args]\n    return frame\n\n\n\nprint('users similar to user',15)\nprint('')\nsimilar_users(15,n=5,method='cosine')","fb4832e7":"def top_rated_by_user(userid,n=5):\n    temp = ratings[ratings['userid']==userid]\n    return temp.sort_values(by='rating',ascending=False).iloc[:n]\n\n\nprint('top rated movies by user',18)\nprint('')\ntop_rated_by_user(18)","e817bc5c":"def top_rated_by_user(userid,n=5,bayesian_finetune=False):\n    \n    temp = ratings[ratings['userid']==userid]\n    rate_sorted = temp.sort_values(by='rating',ascending=False)\n    \n    if bayesian_finetune==False:\n        return rate_sorted.iloc[:n]\n    \n    else:\n        if n<100: k = 100\n        else: k = n\n        bayesian_ratings = pd.DataFrame(rated[['movieid','bayesian_average_rating']].values,\n                           columns=['movieid','bayesian_rating'])\n        temp = rate_sorted.iloc[:k]\n        temp = temp.merge(bayesian_ratings,how='inner',\n                          on='movieid')\n        temp = temp.sort_values(by='bayesian_rating',\n                                ascending=False).reset_index().iloc[:n]\n        return temp[['movieid','movietitle','rating','bayesian_rating']]","3bc530a1":"top_rated_by_user(54,10)","6b53c94d":"top_rated_by_user(54,10,bayesian_finetune=True)","ab680726":"top_rated_by_user(54,10).merge(top_rated_by_user(54,10,bayesian_finetune=True),\n                            how='inner',on=['movieid','movietitle','rating'])","af9aea62":"\ndef recommend_similar_user_prefs(userid, similarity='cosine', bayesian_finetune=True):\n    \n    #initializations\n    burned_movieids = ratings[ratings['userid']==userid]['movieid'].values\n    sim_userids = similar_users(userid,n=5,method=similarity)['userid'].values\n\n    #user1\n    temp = top_rated_by_user(sim_userids[0],100,bayesian_finetune=bayesian_finetune)\n    valid_mask = [not i in burned_movieids for i in temp['movieid'].values]\n    valid_indices = np.argwhere(valid_mask).squeeze()\n    recommend_movieids = temp.iloc[valid_indices]['movieid'].values[:4]\n    burned_movieids = np.hstack((burned_movieids,recommend_movieids))\n\n    #user2\n    temp = top_rated_by_user(sim_userids[1],100,bayesian_finetune=bayesian_finetune)\n    valid_mask = [not i in burned_movieids for i in temp['movieid'].values]\n    valid_indices = np.argwhere(valid_mask).squeeze()\n    temp_indices = temp.iloc[valid_indices]['movieid'].values[:3]\n    recommend_movieids = np.hstack((recommend_movieids,temp_indices))\n    burned_movieids = np.hstack((burned_movieids,temp_indices))\n\n    #user3\n    temp = top_rated_by_user(sim_userids[2],100,bayesian_finetune=bayesian_finetune)\n    valid_mask = [not i in burned_movieids for i in temp['movieid'].values]\n    valid_indices = np.argwhere(valid_mask).squeeze()\n    temp_indices = temp.iloc[valid_indices]['movieid'].values[:3]\n    recommend_movieids = np.hstack((recommend_movieids,temp_indices))\n    #burned_movieids = np.hstack((burned_movieids,temp_indices))\n\n    #final list\n    recommendations = movie.iloc[recommend_movieids-1]\n    return recommendations.reset_index()[['movieid','movietitle']]\n\n\nrecommend_similar_user_prefs(325,similarity='pearson',bayesian_finetune=False)","8e68d51c":"#cosine similarity among movies\n\nrows = movie.shape[0]\nmovie_cos_sim = np.zeros((rows,rows))\nmovie_data = movie.iloc[:,3:].values\n\nfor i in np.arange(rows):\n    vector1 = movie_data[i]\n    \n    for j in (np.arange(rows))[i:]:\n        \n        vector2 = movie_data[j]\n        movie_cos_sim[i,j] = 1 - cosine(vector1,vector2)","0ae598f0":"sns.heatmap(movie_cos_sim);","7bcc11c5":"# copy values across diagonal\nfor i in np.arange(movie_cos_sim.shape[0]):\n    for j in np.arange (i, movie_cos_sim.shape[0]):\n        movie_cos_sim[j,i] = movie_cos_sim[i,j]","784a0d4a":"sns.heatmap(movie_cos_sim);","0cf386d5":"#np.save('movie2movie_cosine_similarity.npy',movie_cos_sim)\n#movie_cos_sim = np.load('movie2movie_cosine_similarity.npy')","8ac0b3a6":"top_rated_by_user(1,1,bayesian_finetune=True)","87f3b81d":"movieid = 50\ndef recommend_from_favorite(userid):\n    \n    movieid = top_rated_by_user(userid,1,bayesian_finetune=True).values.squeeze()[0]\n    \n    recomm_indices = np.argsort(movie_cos_sim[movieid-1])[::-1][1:11]\n    recomm_titles = movie['movietitle'][recomm_indices].values\n    recomm_movieids = recomm_indices + 1\n    recomm_similarities = np.sort(movie_cos_sim[movieid-1])[::-1][1:11]\n    \n    recommendations = pd.DataFrame()\n    recommendations['movieid'] = recomm_movieids\n    recommendations['movietitle'] = movie['movietitle'][recomm_indices].values\n    recommendations['similarity_with_top_rated'] = recomm_similarities\n\n    return recommendations","164e170f":"#demonstration\nprint('favorite movie of user 1: ',top_rated_by_user(1,1,bayesian_finetune=True)['movietitle'][0])\nprint('')\nprint('recommendations based on user\\'s favorite movie:')\nrecommend_from_favorite(1)","bc935077":"#function to predict ratings for a given movie for a given user\ndef predict_ratings(userid, movieid, similarity='cosine'):\n    \n    ##########___________________________________________\n    if similarity == 'cosine': sim_vector = user_cos_sim[userid-1].copy()\n    else:\n        if similarity=='pearson': sim_vector = user_sim[userid-1].copy()\n        else:\n            print('pick either \\'cosine\\' or \\'pearson\\' as a similarity metric')\n            #return None\n    \n    sorted_indices = np.argsort(sim_vector)[::-1][1:]\n    #----------------------------------------------------------------------------\n    #----------------------------------------------------------------------------\n    \n    temp_ratings = ratings[ratings['movieid']==movieid]\n    users = temp_ratings['userid']\n\n    \n    \n    indices_user = temp_ratings['userid'].values -1 #indices of user matrix of users who've rated said movie\n    \n    rate_array = np.zeros((user.shape[0]),dtype='int') #array of ratings, users who havent rated will be 0\n    rate_array[indices_user] = temp_ratings['rating'].values\n\n    #compute weighted average\n    aggregate_sims = sim_vector[indices_user].sum()\n    summation = np.sum(sim_vector*rate_array)\n    prediction = summation\/aggregate_sims\n    \n\n    return prediction\n\n\n\npredict_ratings(userid=33, movieid=1, similarity='cosine')","d952bd92":"userid = 220\nsimilarity='cosine'\n\ndef recommend_predicted_highrated (userid, similarity='cosine'):\n\n    watched_movieids = ratings[ratings['userid']==userid]['movieid'].values\n    not_watched_ids = np.argwhere([not i in watched_movieids for i in movie['movieid']]).squeeze()\n    predicted_ratings = []\n\n    for movieid in not_watched_ids: \n        predicted_ratings.append(predict_ratings(userid=userid, movieid=movieid+1, similarity=similarity))\n    \n    sorted_predicted_ratings = np.sort(predicted_ratings)[::-1]\n    sorted_indices = np.argsort(predicted_ratings)[::-1]\n    recommendations = movie.iloc[sorted_indices][['movieid','movietitle']]\n    recommendations['predicted_rating'] = sorted_predicted_ratings\n    recommendations = recommendations.reset_index(drop=True)\n    return recommendations.head(12)\n\nrecommend_predicted_highrated(184)","1a7bf72d":"import torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable","7de0b57b":"path = '..\/input\/movielens-100k-dataset\/ml-100k\/'","4004c134":"train = pd.read_csv(path+'u1.base',sep='\\t',header=None,\n                   names=['userid','movieid','rating','timestamp'])\ntrain = train.drop(columns='timestamp')\ntrain.head(3)","47e56eaf":"test = pd.read_csv(path+'u1.test',sep='\\t',header=None,\n                  names=['userid','movieid','rating','timestamp'])\ntest = test.drop(columns='timestamp')\ntest.head(3)","6ba23fd7":"unique_users = train['userid'].append(test['userid']).nunique()\nprint('number of unique users present in the train-test data:', unique_users)\nunique_movies = train['movieid'].append(test['movieid']).nunique()\nprint('number of unique movies present in the train-test data:', unique_movies)","5035b70f":"indices_users = user['userid'].values\nindices_movies = movie['movieid'].values\nindices_users.shape,indices_movies.shape","2b9c1c9f":"#function that transforms data into an array with rows being users, columns being movies, values being ratings\ndef users_and_movies_array(df):  \n    \n    users_and_movies = np.zeros((943,1682)) #shape=[n_users,n_movies]\n    \n    #for each userid and movieid, assign rating to the corresponding position of users_and_movies matrix \n    for user_id,movie_id,rating in zip(df['userid'],df['movieid'],df['rating']):\n        users_and_movies[user_id-1,movie_id-1] = rating\n        \n    return users_and_movies","87840bc3":"#run the data-transforming function\ntrain_array = users_and_movies_array(train)\ntest_array = users_and_movies_array(test)\n\n#get tensors\ntrain_tensor = torch.FloatTensor(train_array)\ntest_tensor = torch.tensor(test_array)","069954e6":"class AE(nn.Module):\n    def __init__(self,):\n        super(AE,self).__init__()\n        self.l1 = nn.Linear(1682,50)  # input dim is n_movies\n        self.l2 = nn.Linear(50,20)\n        self.l3 = nn.Linear(20,10)\n        self.l4 = nn.Linear(10,20)\n        self.l5 = nn.Linear(20,50)\n        self.out_layer = nn.Linear(50,1682)\n        self.act = nn.Sigmoid()\n        \n    def forward(self,x):\n        x = self.act(self.l1(x))\n        x = self.act(self.l2(x))\n        x = self.act(self.l3(x))\n        x = self.act(self.l4(x))\n        x = self.act(self.l5(x))\n        x = self.out_layer(x)\n        return x","f41cf5f2":"lr = 1e-3\nn_epochs = 251\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = AE()\nloss_fn = nn.MSELoss()\noptimizer = optim.RMSprop(model.parameters(),lr=lr,weight_decay=0.3)\nprint(model)","056d2564":"model.train()\nmodel.to(device)\nn_users = 943\nn_movies = 1682\nloss_history = []\n\nfor epoch in range(1,n_epochs):\n    \n    epoch_loss = 0\n    n_nonzero = 0 #users who've rated at least one movie\n    \n    for i in range (n_users): #run a training iter for each user\n        \n        x = Variable(train_tensor[i]).unsqueeze(0)\n        y = x.clone()\n        if y.sum() > 0:\n            preds = model(x)\n            y.require_grad = False\n            preds [y==0] = 0\n            loss = loss_fn(preds,y)\n            loss.backward()\n            optimizer.step()\n            \n            #_________________________________________________\n            #we apply mean correction when computing epoch loss because...\n            #...otherwise it will be a very small number, as most entries...\n            #...of each vector are zero\n            mean_corrector = n_movies\/((y>0).sum()+1e-10)  \n            epoch_loss += np.sqrt(loss.data*mean_corrector)\n            n_nonzero += 1\n    corrected_epoch_loss = epoch_loss\/n_nonzero\n    #_________________________________________________________\n    \n    loss_history.append(corrected_epoch_loss)\n    if (epoch==1) | (epoch%50==0):\n        print('epoch:',epoch,'loss:',corrected_epoch_loss)","05bd038a":"plt.plot(loss_history)","7ff0e3ac":"test_loss = 0\nn_nonzero = 0 #users who've rated at least one movie\n\nfor i in range (n_users):\n    \n    x = Variable(train_tensor[i]).unsqueeze(0)\n    y = Variable(test_tensor[i]).unsqueeze(0)\n    y.require_grad = False\n\n    if y.sum()>0:\n        \n        preds = model(x)\n        preds [y==0] = 0\n        loss = loss_fn(preds,y)\n        mean_corrector = n_movies\/((y>0).sum()+1e-10)\n        test_loss += np.sqrt(loss.data*mean_corrector)\n        n_nonzero += 1\n        \n    corrected_test_loss = test_loss\/n_nonzero\n    \nprint('test loss:',corrected_test_loss)","f95d8045":"random_user_id = 430\n\npreds = model(train_tensor[random_user_id+1])\n\n\njuxtapose = pd.DataFrame()\njuxtapose['title'] = movie['movietitle']\njuxtapose['ground_truth_rating'] = test_tensor[random_user_id+1]\njuxtapose['predicted_rating'] = preds.detach().numpy()\n\nif (test_tensor[random_user_id+1]).sum() == 0: print('user has no ratings in the test set')\nelse: \n    print(random_user_id)\n    display(juxtapose[juxtapose['ground_truth_rating']>0].head())","0558e751":"#make recommendations\n\nrandom_user_id = 3#np.random.choice(np.arange(943))\n\npreds = model(train_tensor[random_user_id+1])\n\nrecommendations = pd.DataFrame()\nrecommendations['title'] = movie['movietitle']\nrecommendations['predicted_rating'] = preds.detach().numpy()\nrecommendations[train_array[random_user_id+1]==0]\\\n                                                .sort_values(by='predicted_rating',ascending=False)\\\n                                                .reset_index(drop=True)[:10]","c65f793d":"def boltzmannize(array):\n    array = array.copy()\n    array[array==0] = -1\n    array[(array>0)&(array<4)] = 0\n    array[array>=4] = 1\n    return array","dbf85496":"train_array_boltz = boltzmannize(train_array)\ntest_array_boltz = boltzmannize(test_array)\n\ntrain_tensor_boltz = torch.FloatTensor(train_array_boltz)\ntest_tensor_boltz = torch.tensor(test_array_boltz)\n\nfrom torch.utils.data import DataLoader\nbatch_size=100\ntrainload = DataLoader(train_tensor_boltz,batch_size=batch_size)","4469212d":"class RBM():\n    def __init__(self, nv, nh):\n        self.W = torch.randn(nh, nv)\n        self.a = torch.randn(1, nh)\n        self.b = torch.randn(1, nv)\n    def sample_h(self, x):\n        wx = torch.mm(x, self.W.t())\n        activation = wx + self.a.expand_as(wx)\n        p_h_given_v = torch.sigmoid(activation)\n        return p_h_given_v, torch.bernoulli(p_h_given_v)\n    def sample_v(self, y):\n        wy = torch.mm(y, self.W)\n        activation = wy + self.b.expand_as(wy)\n        p_v_given_h = torch.sigmoid(activation)\n        return p_v_given_h, torch.bernoulli(p_v_given_h)\n    def train(self, v0, vk, ph0, phk):\n        self.W += (torch.mm(v0.t(),ph0) - torch.mm(vk.t(),phk)).t()\n        self.b += torch.sum((v0 - vk), 0)\n        self.a += torch.sum((ph0 - phk), 0)\n    def predict(self, x):\n        _, h = self.sample_h(x)\n        _, v = self.sample_v(h)\n        return v","d3cb605b":"nv = len(train_tensor_boltz[0])\nnh = 100\nrbm = RBM(nv, nh)\nn_epochs = 201","39c9d900":"loss_history = []\nfor epoch in range(1, n_epochs + 1):\n    epoch_loss = 0\n    rmse = 0\n    s = 0.\n    for x in trainload:\n        vk = x\n        v0 = x\n        ph0,_ = rbm.sample_h(v0)\n        for k in range(10):\n            _,hk = rbm.sample_h(vk)\n            _,vk = rbm.sample_v(hk)\n        vk[v0<0] = v0[v0<0]\n        phk,_ = rbm.sample_h(vk)\n        rbm.train(v0, vk, ph0, phk)\n        epoch_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n        rmse += np.sqrt(torch.mean((v0[v0>=0] - vk[v0>=0])**2))\n        s += 1.\n    corrected_loss = epoch_loss\/s\n    loss_history.append(corrected_loss)\n    if (epoch==1) | (epoch%10==0):\n        print(f'Epoch: {epoch} | Training Loss: {corrected_loss} | RMSE: {rmse}')","9fe1c3c7":"plt.plot(loss_history)","abf5660e":"test_loss = 0\nrmse_ts = 0\ns = 0.\nfor id_user in range(943):\n    v = train_tensor_boltz[id_user:id_user+1]\n    vt = test_tensor_boltz[id_user:id_user+1]\n    if len(vt[vt>=0]) > 0:\n        _,h = rbm.sample_h(v)\n        _,v = rbm.sample_v(h)\n        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n        rmse_ts += np.sqrt(torch.mean((vt[vt>=0] - v[vt>=0])**2))\n        s += 1.\nprint('Test Loss: '+str(test_loss\/s))\nprint('RMSE: '+str(rmse_ts))","9637cd30":"random_user_id = 292\n\npreds = rbm.predict(train_tensor_boltz[random_user_id+1:random_user_id+2])\n\n\njuxtapose = pd.DataFrame()\njuxtapose['title'] = movie['movietitle']\njuxtapose['ground_truth_rating'] = test_tensor_boltz[random_user_id+1]\njuxtapose['predicted_rating'] = preds.detach().numpy().squeeze()\n\nif (test_tensor_boltz[random_user_id+1]).sum() == -1682: print('user has no ratings in the test set')\nelse: \n    print(random_user_id)\n    display(juxtapose[juxtapose['ground_truth_rating']>=0].head())","fb7f390e":"#make recommendations\n\nrandom_user_id = np.random.choice(np.arange(943))\n\npreds = rbm.predict(train_tensor_boltz[random_user_id+1:random_user_id+2])\n#unseen_movies_indices\n\nrecommendations = pd.DataFrame()\nrecommendations['title'] = movie['movietitle']\nrecommendations['predicted_rating'] = preds.detach().numpy().squeeze()\nprint(f'movies user {random_user_id} might like')\nprint(recommendations[recommendations['predicted_rating']==1]['title'].values)","161559f0":"______________________________________________________________________________\n# 4th Recommendation Engine\n\n#### predicts how the user will rate movies he hasn't watched, recommends those with highest predicted ratings\n________________________________________________________________________________","7ecaa281":"Instantiate model and initialize some parameters","1449deb6":"Produce recommendations.","8c7a592c":"Train model and plot loss during training","cb1e2e1d":"Produce recommendations.\n\nFor a given user, feed the user's rating vector into the AE, predict ratings of movies the user has not watched, sort them from highest to lowest rated.","388445d4":"________________________________________________________________________\n# 5th Recommendation Engine\n### deep learning to predict user ratings\n____________________________________________________________________","895a898e":"Produce some predictions and juxtapose them with ground truth, to get a feel of the results","5ffb5a45":"#### Generally Most Popular Movies","8f36db42":"Function that makes recommendations:\n\nGiven a userid, find movies the user has not watched, predict user's ratings on these movies, pick ten highest predictions.","d1a12297":"1) construct movie-movie similarity matrix. \n\n2) find a user's favorite movie, using bayesian averages.\n\n3) return the movies that are most similar to the user's favorite.","a52cfa50":"Train model and plot loss during training","3a0ead89":"## Boltzmann Machine","bb278fe8":"## Autoencoder","4603dee1":"Since each user may have given top ratings to multiple movies, we could sort his favorite, top-rated movies, by bayesian average ratings.\n\nWe enhance the function top_rated_by_user by adding the bayesian_finetune parameter","6e9cecf3":"Then we make similarity matrix with cosine similarity","f2ce3257":"The generated recommendations seem, and are, highly sub-optimal. A single below-five rating will spoil a movie's average, and most popular movies, which have been reviewed hundreds of times, will have lower average rating than a B-movie that got a single rating of 5 (like the computed suggestions above).\n\nAs we can see below, a movie such as 'Casablanca' or 'Citizen Kane', which would be considered as a better and more popular movie by nearly any standard, has lower average rating:","97054ec7":"Design model","af013d98":"Here we see that the two approaches (with or without Bayesian averages) have only a few results in common:","82cb1d15":"Since this is computationally heavy, we will only compute half of the similarity matrix.\n\nThe matrix is symmetrical in respect to its diagonal, so after computed the upper half we will copy the values to the lower half.","16bd4431":"_______________________\n# 2nd Recommendation Engine\n### Recommends Favorite Movies of Users Most Similar to Given User\n______________________________\n\nPipeline:\n\n1) Compute two user-to-user similarity matrices, one with cosine similarity and the other with Pearson correlation as similarity metrics.\n\n2) Function that takes a userid and picks the most similar users, and function that picks a user's favorite movies.\n\n3) Combining functions of step 2, make function that picks the most similar users to a given user, picks their favorite movies and present them, making sure our user has not watched these and that there is no overlap whatsoever of the picks among users.\n___________________________________________________________________________________________________","efa9fcd3":"Here we will train an autoencoder to predict how a user would rate a movie. \n\nThe dataset has already train and test sets prepared for us, but we need to transform them into matrices of shape [n_users, n_movies], with data being the ratings.\n\nLet's import pytorch, then import train-test data and prepare them for model training.","ad38c2be":"### User to user similarity matrix","a401f6b0":"_______________________________________________\n# 1st Recommendation Engine\n### Baseline Recommendation of Most Popular Movies\n\n\n_______________________________________\n\nTwo variations:\n\n1) Most popular movies in general\n\n2) Most popular movies for a given genre\n\n_________________________________________\n","94913ee8":"# Approaches to Recommender Systems","b4a4b8e6":"We see above that the system works, as the user's favorite movie is Star Wars and the system returned the most popular sci-fi, similar to Star Wars, movies.","b4b22013":"To account for the popularity of a movie (as indicated by the number of ratings), we will compute the Bayesian average of movies, which take into account the number of times a movie was rated, in proportion with the average number of ratings per movie.","6ee40428":"Next we make a function that takes as input a userid and displays the most similar users. Parameters are the number of similar users to display, and the type of similarity metric to be used, cosine or pearson.","62bb4ca1":"Design model","c80498b4":"We will explore five approaches to recommendation systems, with variations on these approaches.\n\n1) Popularity-based recommendations. This is our baseline system, recommending either the most popular movies in general, or the most popular for a given genre.\n\n2) Recommendations based on user similarity. Recommends favorite movies of users most similar to a given user.\n\n3) Recommendations based on movie similarity. Recommends movies similar to the user's favorite.\n\n4) Another user-similarity-based engine. Computes average ratings weighted by user similarity, recommends highest-rated.\n\n5) Deep Learning models. An Autoencoder and a Boltzmann Machine predict user ratings, top predictions constituting our recommendations.","cd5e75e7":"Function to display the n most highly rated movies of a given user","8adf730a":"Algo:\n\n1) Find similar users.\n\n2) Find four most highrated movies from user1. If they don't overlap with our user's history, keep, otherwise pick fifth,sixth,etc until you get four non-overlapping. Store these movies in array, store ids in array with 'burned' movies, to compare with picks made in the next steps and make sure there is no overlap.\n\n3) User2. Pick three best. Make sure no overlapping, append to array with recommended. also keep movieids in array with 'burned'.\n\n4) User3, as user2.\n\n* If at any point there are no more movies from a user, just continue on. You'll end up with a shorter recommendation, which is ok.","7d77558c":"# Data Preparation","5417727d":"In this notebook we explored five approaches:\n\n1) Popularity-based recommendations, simply recommending the most popular movies.\n\n2) Recommending the favorite movies of users most similar to a given user.\n\n3) Recommending movies similar to the user's favorite.\n\n4) Computing average ratings weighted by user similarity, recommends highest-rated.\n\n5) Predicting a user's ratings through deep learning models, with top predictions constituting our recommendations.\n__________________________________________________________________________\n\nMost of these techniques yielded pretty interesting and valid results, and even the baseline recommendations can be useful. The Boltzmann Machine was weird, but some of its recommendations might still be integrated with those of another system's, adding an element of surprise and variety in the mix.","932aed1d":"Instantiate model and initialize some parameters","7a019d61":"recommend_similar_user_prefs(userid, n=10, similarity='cosine', bayesian_finetune=True)","fb971639":"Produce some predictions and juxtapose them with ground truth, to get a feel of the results","95b2334a":"#### Top-Rated per Genre","0111091b":"_________________________________________________\n# Conclusion","745c11be":"Test model","e680d3ff":"We pick movies with the highest average rating, sort them in descending order.","722319e7":"First we make similarity matrix with Pearson coefficient","2d42b4d4":"### Function to recommend favorite movies from similar users","aaa0b0a7":"implement the bayesian average additional sort, and make a function that takes a userid and outputs movie recommendations. internally it finds the n most similar users, finds their top rated movies, sorts them additionally with bayesian averages, picks a few from each user, makes sure the movie list does not contain duplicates or movies the user has seen, and gives the result.","63f95ea2":"___________________________________________________________________\n# 3rd Recommendation Engine\n### Recommends movies most similar to user's favorite\n____________________________________________________________________","caf47df6":"The Bayesian averages have worked, and produced sensible results. \n\nThe list of the top 10 rated movies is now comprised of some of the most famous and critically-acclaimed movies.\n\nWe could also play around with the C parameter to finetune the results although, again, the results are already quite satisfactory. \n\nNext we write a small function to display the top-rated movies per genre, and demonstrate by displaying the top 5 action movies.","ce4eaf95":"1) Choose a user.\n\n2) Choose a movie.\n\n3) Calculate weighted average of the movie's ratings, weights being the similarity of each reviewer to our picked user.\n\n4) Repeat step 3 for all movies -- you now got a matrix of educated guesses of how much the user will like each movie.\n\n5) The highest ranking entries of the matrix are our recommendations.","418f93bc":"### Preliminary functions","3b76f508":"This is an experimental technique, which produces very mediocre results. \n\nWe use the same data we trained the AE with, only this time the ratings will be binary (1: like, 0: dislike, -1: not rated)."}}