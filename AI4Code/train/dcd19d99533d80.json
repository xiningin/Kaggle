{"cell_type":{"35b4a7c7":"code","00526d55":"code","1a887b8c":"code","9ee5778c":"code","3b301e30":"code","96b4ea91":"code","523a1188":"code","df7949e1":"code","46b1033b":"code","910a3292":"code","3db43adb":"code","9ef17e74":"code","69cf253d":"code","61556bf8":"code","0acd83f3":"code","e1f302b4":"code","9c98d444":"code","43a555d6":"code","ad574471":"markdown","f1737467":"markdown","3a13ce51":"markdown","375a4e95":"markdown","b988a92e":"markdown","dbaf7058":"markdown","eba86f56":"markdown","7b30ce65":"markdown","de8a6d7c":"markdown","0b305b45":"markdown"},"source":{"35b4a7c7":"import pandas as pd\nimport numpy as  np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import ReduceLROnPlateau","00526d55":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\n\nimg_rows, img_cols = 28, 28\nnum_classes = 10\n\ndef prep_data(raw):\n    y = raw[:, 0]\n    out_y = keras.utils.to_categorical(y, num_classes)\n    \n    x = raw[:,1:]\n    num_images = raw.shape[0]\n    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n    out_x = out_x \/ 255\n    return out_x, out_y\n\nfashion_file = \"..\/input\/Kannada-MNIST\/train.csv\"\nfashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\nx, y = prep_data(fashion_data)\n\nprint(\"Setup Complete\")","1a887b8c":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\n\n\n# Your Code Here\nmodel=Sequential()","9ee5778c":"model.add(Conv2D(12, kernel_size=(3,3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols,1)))","3b301e30":"model.add(Conv2D(20, activation='relu', kernel_size=3))\nmodel.add(Conv2D(20, activation='relu', kernel_size=3))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","96b4ea91":"model.compile(loss = \"categorical_crossentropy\",\n             optimizer = 'adam',\n             metrics = ['accuracy'])","523a1188":"model.fit(x,y,\n                 batch_size = 100,\n                 epochs = 4,\n                 validation_split = 0.2)","df7949e1":"#define model name\nsecond_model=Sequential()\n\n#fist lay\nsecond_model.add(Conv2D(17, kernel_size=(3,3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols,1)))\n\n#the remaining layers\nsecond_model.add(Conv2D(50, activation='relu', kernel_size=3))\nsecond_model.add(Conv2D(50, activation='relu', kernel_size=3))\nsecond_model.add(Flatten())\nsecond_model.add(Dense(100, activation='relu'))\nsecond_model.add(Dense(10, activation='softmax'))\n\n#compile\nsecond_model.compile(loss = \"categorical_crossentropy\",\n             optimizer = 'adam',\n             metrics = ['accuracy'])\n\n#fit\/train model\nsecond_model.fit(x,y,\n                 batch_size = 100,\n                 epochs = 7,\n                 validation_split = 0.2)\n","46b1033b":"train=pd.read_csv('..\/input\/Kannada-MNIST\/train.csv')\ntest=pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')\nsample_sub=pd.read_csv('..\/input\/Kannada-MNIST\/sample_submission.csv')","910a3292":"#print('The Train  dataset has {} rows and {} columns'.format(train.shape[0],train.shape[1]))\n#print('The Test  dataset has {} rows and {} columns'.format(test.shape[0],test.shape[1]))\n","3db43adb":"#train.head(3)","9ef17e74":"#test.head(3)\n#test=test.drop('id',axis=1)\n","69cf253d":"test=pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')","61556bf8":"\ntest=test.drop('id',axis=1)\ntest=test\/255\ntest=test.values.reshape(-1,28,28,1)","0acd83f3":"test.shape","e1f302b4":"y_pre=second_model.predict(test)     ##making prediction\ny_pre=np.argmax(y_pre,axis=1) ##changing the prediction intro labels","9c98d444":"sample_sub['label']=y_pre\nsample_sub.to_csv('submission.csv',index=False)","43a555d6":"sample_sub.head()","ad574471":"Before jumping to all complex stuff about Convolutions and all,we will simply understand our data.We will learn and gain basic understanding about this data.","f1737467":"# Compile Your Model","3a13ce51":"Now you can see that there are 785 columns in the training dataset given.I will describe each one of them here...\n- **Label :** This contains the label which are going to predict.That is our target value.Here it is numbers from 0 to 9.We will plot a bar graph and see the distribution of this target value later.\n- **Pixel0 to Pixel783: **These are the pixel values of the image metrics.That is each row contains 28 * 28 = 784 (0-783 here) values here.Each one of these values indicates the pixel value at i x 28 + j th pixel position in the image metric.Simple !\n","375a4e95":"### Understanding the data <a id=\"1\" ><\/a>","b988a92e":"# Add the remaining layers","dbaf7058":"# Fit The Model","eba86f56":"# Start the model","7b30ce65":"# Create A New Model","de8a6d7c":"### Loading data","0b305b45":"# Add the first layer"}}