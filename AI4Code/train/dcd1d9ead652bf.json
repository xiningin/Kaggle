{"cell_type":{"5ece8d4a":"code","d33604e5":"code","3eebaad1":"code","e90e5fb4":"code","fe1663d2":"code","4813cb91":"code","9e394db8":"code","db2ee4f8":"code","69943758":"code","864cd669":"code","c4ac0d84":"code","50c716a2":"code","8f887b73":"code","8874a862":"code","69bb5fed":"code","c79262ff":"code","c66953b9":"code","b1b24f68":"code","c8bb0e21":"code","949b8e2d":"code","a0564ede":"code","fedf713e":"code","2158231e":"code","652d696d":"code","09f5dd30":"code","a6038934":"code","7005ec4a":"code","2fdd10dd":"code","b9f4f0b3":"code","7e008135":"code","346ab5af":"code","fe793e7c":"code","69588978":"code","6483c2d9":"code","03793c64":"code","9d17fe33":"code","c213e5d7":"code","11137525":"code","3f7922c2":"code","450e1cb9":"code","0edafe28":"code","ca8f8b45":"code","3020dfd0":"code","143e99c7":"code","83e7ef41":"code","ebe57e58":"code","8dd7f3f9":"code","87ff7ff1":"code","0f43c425":"code","87692bf1":"code","b386016f":"code","1986d39b":"code","d288a111":"code","fe026672":"code","b56cc857":"code","e5fa50f6":"code","6f8628ca":"code","3ce1a1f0":"code","1da35f25":"code","2d16ef34":"code","60c1e11f":"code","1e9aa306":"code","1d6c4640":"code","f1a7e95d":"code","2366fae5":"code","475eaaa4":"code","d4be457e":"code","44056923":"code","8ca0c343":"code","89f4d52d":"code","08bb52b7":"code","840d2345":"code","3aa25052":"code","496d323e":"code","4cd3027b":"code","db766c5f":"markdown","09d98dd5":"markdown","019fdaa6":"markdown","5f98e9f8":"markdown","4ffecfba":"markdown","40c3c5df":"markdown","3a7fe540":"markdown","b3c80f08":"markdown","a64e21ca":"markdown","098f10fa":"markdown","eee045f0":"markdown","f47317db":"markdown","2f7ff752":"markdown","2f599250":"markdown","46f2184c":"markdown","35b26e45":"markdown","3da03572":"markdown","ce3e2719":"markdown","0460d7b5":"markdown","e8b19317":"markdown","fcef60f4":"markdown","236daf71":"markdown","372d9951":"markdown","929f4a39":"markdown","e6ebbb21":"markdown"},"source":{"5ece8d4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d33604e5":"import numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\n\nfrom datetime import datetime\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","3eebaad1":"import warnings\nwarnings.filterwarnings('ignore')","e90e5fb4":"matplotlib.rcParams.update({'font.size': 14})","fe1663d2":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","4813cb91":"TRAIN_DATASET_PATH = '..\/input\/real-estate-price-prediction-moscow\/train.csv'\nTEST_DATASET_PATH = '..\/input\/real-estate-price-prediction-moscow\/test.csv'","9e394db8":"train_df = pd.read_csv(TRAIN_DATASET_PATH)","db2ee4f8":"test_df = pd.read_csv(TEST_DATASET_PATH)","69943758":"train_df.dtypes","864cd669":"train_df['Id'] = train_df['Id'].astype(str)\ntrain_df['DistrictId'] = train_df['DistrictId'].astype(str)","c4ac0d84":"plt.figure(figsize = (16, 8))\n\ntrain_df['Price'].hist(bins=30)\nplt.ylabel('Count')\nplt.xlabel('Price')\n\nplt.title('Target distribution')\nplt.show()","50c716a2":"train_df.describe()","8f887b73":"train_df.select_dtypes(include='object').columns.tolist()","8874a862":"train_df['DistrictId'].value_counts()","69bb5fed":"train_df['Ecology_2'].value_counts()","c79262ff":"train_df['Ecology_3'].value_counts()","c66953b9":"train_df['Shops_2'].value_counts()","b1b24f68":"train_df['Rooms'].value_counts()","c8bb0e21":"train_df['Rooms_outlier'] = 0\ntrain_df.loc[(train_df['Rooms'] == 0) | (train_df['Rooms'] >= 6), 'Rooms_outlier'] = 1\ntrain_df.head()","949b8e2d":"train_df.loc[train_df['Rooms'] == 0, 'Rooms'] = 1\ntrain_df.loc[train_df['Rooms'] >= 6, 'Rooms'] = train_df['Rooms'].mode()","a0564ede":"train_df['Rooms'].value_counts()","fedf713e":"train_df['KitchenSquare'].value_counts()","2158231e":"condition = (train_df['KitchenSquare'].isna()) \\\n             | (train_df['KitchenSquare'] > 20 )\n        \ntrain_df.loc[condition, 'KitchenSquare'] = train_df['KitchenSquare'].mean()\ntrain_df.loc[train_df['KitchenSquare'] < 2] = train_df['KitchenSquare'].mean()","652d696d":"train_df['KitchenSquare'].value_counts()","09f5dd30":"train_df['HouseFloor'].sort_values().unique()","a6038934":"train_df['Floor'].sort_values().unique()","7005ec4a":"(train_df['Floor'] > train_df['HouseFloor']).sum()","2fdd10dd":"train_df['HouseFloor_outlier'] = 0\ntrain_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\ntrain_df.loc[train_df['HouseFloor'] > 95, 'HouseFloor_outlier'] = 1\ntrain_df.loc[train_df['Floor'] > train_df['HouseFloor'], 'HouseFloor_outlier'] = 1","b9f4f0b3":"train_df.loc[train_df['HouseFloor_outlier'] == 1] = train_df['HouseFloor'].median()","7e008135":"floor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\nfloor_outliers","346ab5af":"train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor']\\\n                                                .apply(lambda x: random.randint(1, x))","fe793e7c":"(train_df['Floor'] > train_df['HouseFloor']).sum()","69588978":"train_df['HouseYear'].sort_values(ascending=False)\ntrain_df['HouseYear'].sort_values(ascending=True)","6483c2d9":"train_df.loc[train_df['HouseYear'] > 2020, 'HouseYear'] = 2020\ntrain_df.loc[train_df['HouseYear'] < 1700, 'HouseYear'] = train_df['HouseYear'].mode","03793c64":"train_df.isna().sum()","9d17fe33":"condition = train_df['Rooms'].isna()\n             \n        \ntrain_df.loc[condition, 'Rooms'] = train_df['Rooms'].mode","c213e5d7":"train_df['LifeSquare_nan'] = train_df['LifeSquare'].isna() * 1\n\ncondition = (train_df['LifeSquare'].isna()) \\\n             & (~train_df['Square'].isna()) \\\n             & (~train_df['KitchenSquare'].isna())\n        \ntrain_df.loc[condition, 'LifeSquare'] = train_df.loc[condition, 'Square'] \\\n                                            - train_df.loc[condition, 'KitchenSquare'] - 3","11137525":"\ncondition = train_df['Healthcare_1'].isna()\n             \n        \ntrain_df.loc[condition, 'Healthcare_1'] = train_df['Healthcare_1'].mode","3f7922c2":"train_df.isna().sum()","450e1cb9":"class DataPreprocessing:\n    \"\"\"\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n    def __init__(self):\n        \"\"\"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043a\u043b\u0430\u0441\u0441\u0430\"\"\"\n        self.medians = None\n        self.kitchen_square_quantile = None\n        \n    def fit(self, X):\n        \"\"\"\u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\"\"\"       \n        # \u0420\u0430\u0441\u0447\u0435\u0442 \u043c\u0435\u0434\u0438\u0430\u043d\n        self.medians = X.median()\n        self.kitchen_square_quantile = X['KitchenSquare'].quantile(.975)\n    \n    def transform(self, X):\n        \"\"\"\u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        X.loc[X['Rooms'] >= 6, 'Rooms'] = self.medians['Rooms']\n        \n        # KitchenSquare\n        condition = (X['KitchenSquare'].isna()) \\\n                    | (X['KitchenSquare'] > self.kitchen_square_quantile)\n        \n        X.loc[condition, 'KitchenSquare'] = self.medians['KitchenSquare']\n\n        X.loc[X['KitchenSquare'] < 3, 'KitchenSquare'] = 3\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        \n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor']].index\n        X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\\\n                                            .apply(lambda x: random.randint(1, x))\n        \n        # HouseYear\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # Healthcare_1\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n            \n        # LifeSquare\n        X['LifeSquare_nan'] = X['LifeSquare'].isna() * 1\n        condition = (X['LifeSquare'].isna()) & \\\n                      (~X['Square'].isna()) & \\\n                      (~X['KitchenSquare'].isna())\n        \n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] - X.loc[condition, 'KitchenSquare'] - 3\n        \n        \n        X.fillna(self.medians, inplace=True)\n        \n        return X","0edafe28":"binary_to_numbers = {'A': 0, 'B': 1}\n\ntrain_df['Ecology_2'] = train_df['Ecology_2'].replace(binary_to_numbers)\ntrain_df['Ecology_3'] = train_df['Ecology_3'].replace(binary_to_numbers)\ntrain_df['Shops_2'] = train_df['Shops_2'].replace(binary_to_numbers)","ca8f8b45":"district_size = train_df['DistrictId'].value_counts().reset_index()\\\n                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n\ndistrict_size.head()","3020dfd0":"train_df = train_df.merge(district_size, on='DistrictId', how='left')\ntrain_df.head()","143e99c7":"(train_df['DistrictSize'] > 100).value_counts()","83e7ef41":"train_df['IsDistrictLarge'] = (train_df['DistrictSize'] > 100).astype(int)","ebe57e58":"med_price_by_district = train_df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                            .rename(columns={'Price':'MedPriceByDistrict'})\n\nprint(med_price_by_district.head(),med_price_by_district.shape)","8dd7f3f9":"train_df = train_df.merge(med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\ntrain_df.head()","87ff7ff1":"def floor_to_cat(X):\n\n    X['floor_cat'] = 0\n\n    X.loc[X['Floor'] <= 3, 'floor_cat'] = 1  \n    X.loc[(X['Floor'] > 3) & (X['Floor'] <= 5), 'floor_cat'] = 2\n    X.loc[(X['Floor'] > 5) & (X['Floor'] <= 9), 'floor_cat'] = 3\n    X.loc[(X['Floor'] > 9) & (X['Floor'] <= 15), 'floor_cat'] = 4\n    X.loc[X['Floor'] > 15, 'floor_cat'] = 5\n\n    return X\n\n\ndef floor_to_cat_pandas(X):\n    bins = [X['Floor'].min(), 3, 5, 9, 15, X['Floor'].max()]\n    X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n    \n    X['floor_cat'].fillna(-1, inplace=True)\n    return X\n\n\ndef year_to_cat(X):\n\n    X['year_cat'] = 0\n\n    X.loc[X['HouseYear'] <= 1941, 'year_cat'] = 1\n    X.loc[(X['HouseYear'] > 1941) & (X['HouseYear'] <= 1945), 'year_cat'] = 2\n    X.loc[(X['HouseYear'] > 1945) & (X['HouseYear'] <= 1980), 'year_cat'] = 3\n    X.loc[(X['HouseYear'] > 1980) & (X['HouseYear'] <= 2000), 'year_cat'] = 4\n    X.loc[(X['HouseYear'] > 2000) & (X['HouseYear'] <= 2010), 'year_cat'] = 5\n    X.loc[(X['HouseYear'] > 2010), 'year_cat'] = 6\n\n    return X\n\n\ndef year_to_cat_pandas(X):\n    bins = [X['HouseYear'].min(), 1941, 1945, 1980, 2000, 2010, X['HouseYear'].max()]\n    X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n    \n    X['year_cat'].fillna(-1, inplace=True)\n    return X","0f43c425":"bins = [train_df['Floor'].min(), 3, 5, 9, 15, train_df['Floor'].max()]\npd.cut(train_df['Floor'], bins=bins, labels=False)","87692bf1":"bins = [train_df['Floor'].min(), 3, 5, 9, 15, train_df['Floor'].max()]\npd.cut(train_df['Floor'], bins=bins)","b386016f":"train_df = year_to_cat(train_df)\ntrain_df = floor_to_cat(train_df)\ntrain_df.head()","1986d39b":"med_price_by_floor_year = train_df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\nmed_price_by_floor_year.head()","d288a111":"train_df = train_df.merge(med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\ntrain_df.head()","fe026672":"class FeatureGenetator():\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447\"\"\"\n    \n    def __init__(self):\n        self.DistrictId_counts = None\n        self.binary_to_numbers = None\n        self.med_price_by_district = None\n        self.med_price_by_floor_year = None\n        self.house_year_max = None\n        self.floor_max = None\n        self.house_year_min = None\n        self.floor_min = None\n        self.district_size = None\n        \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        # Binary features\n        self.binary_to_numbers = {'A': 0, 'B': 1}\n        \n        # DistrictID\n        self.district_size = X['DistrictId'].value_counts().reset_index() \\\n                               .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n                \n        # Target encoding\n        ## District, Rooms\n        df = X.copy()\n        \n        if y is not None:\n            df['Price'] = y.values\n            \n            self.med_price_by_district = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                                            .rename(columns={'Price':'MedPriceByDistrict'})\n            \n            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()\n            \n        ## floor, year\n        if y is not None:\n            self.floor_max = df['Floor'].max()\n            self.floor_min = df['Floor'].min()\n            self.house_year_max = df['HouseYear'].max()\n            self.house_year_min = df['HouseYear'].min()\n            df['Price'] = y.values\n            df = self.floor_to_cat(df)\n            df = self.year_to_cat(df)\n            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\n            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()\n        \n\n        \n    def transform(self, X):\n        \n        # Binary features\n        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}\n        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)\n        \n        # DistrictId, IsDistrictLarge\n        X = X.merge(self.district_size, on='DistrictId', how='left')\n        \n        X['new_district'] = 0\n        X.loc[X['DistrictSize'].isna(), 'new_district'] = 1\n        \n        X['DistrictSize'].fillna(5, inplace=True)\n        \n        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)\n        \n        # More categorical features\n        X = self.floor_to_cat(X)  # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 floor_cat\n        X = self.year_to_cat(X)   # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 year_cat\n        \n        # Target encoding\n        if self.med_price_by_district is not None:\n            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\n            X['MedPriceByDistrict'].fillna(self.med_price_by_district_median, inplace=True)\n            \n        if self.med_price_by_floor_year is not None:\n            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\n            X['MedPriceByFloorYear'].fillna(self.med_price_by_floor_year_median, inplace=True)\n        \n        return X\n    \n    def floor_to_cat(self, X):\n        bins = [self.floor_min, 3, 5, 9, 15, self.floor_max]\n        X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n\n        X['floor_cat'].fillna(-1, inplace=True)\n        return X\n     \n    def year_to_cat(self, X):\n        bins = [self.house_year_min, 1941, 1945, 1980, 2000, 2010, self.house_year_max]\n        X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n\n        X['year_cat'].fillna(-1, inplace=True)\n        return X","b56cc857":"train_df.columns.tolist()","e5fa50f6":"feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',\n                 'Helthcare_2', 'Shops_1', 'Shops_2']\n\nnew_feature_names = ['Rooms_outlier', 'HouseFloor_outlier', 'HouseYear_outlier', 'LifeSquare_nan', 'DistrictSize',\n                     'new_district', 'IsDistrictLarge',  'MedPriceByDistrict', 'MedPriceByFloorYear']\n\ntarget_name = 'Price'","6f8628ca":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\n\nX = train_df.drop(columns=target_name)\ny = train_df[target_name]","3ce1a1f0":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=21)","1da35f25":"preprocessor = DataPreprocessing()\npreprocessor.fit(X_train)\n\nX_train = preprocessor.transform(X_train)\nX_valid = preprocessor.transform(X_valid)\ntest_df = preprocessor.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","2d16ef34":"features_gen = FeatureGenetator()\nfeatures_gen.fit(X_train, y_train)\n\nX_train = features_gen.transform(X_train)\nX_valid = features_gen.transform(X_valid)\ntest_df = features_gen.transform(test_df)\n\nX_train.type, X_valid.type, test_df.type","60c1e11f":"X_train = X_train[feature_names + new_feature_names]\nX_valid = X_valid[feature_names + new_feature_names]\ntest_df = test_df[feature_names + new_feature_names]","1e9aa306":"X_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()","1d6c4640":"rf_model = RandomForestRegressor(random_state=21, criterion='mse')\nrf_model.fit(X_train, y_train)","f1a7e95d":"y_train_preds = rf_model.predict(X_train)\ny_test_preds = rf_model.predict(X_valid)\n\nevaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)","2366fae5":"cv_score = cross_val_score(rf_model, X_train, y_train, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=21))\ncv_score","475eaaa4":"cv_score.mean()","d4be457e":"feature_importances = pd.DataFrame(zip(X_train.columns, rf_model.feature_importances_), \n                                   columns=['feature_name', 'importance'])\n\nfeature_importances.sort_values(by='importance', ascending=False)","44056923":"from sklearn.ensemble import StackingRegressor, VotingRegressor, BaggingRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\ngb = GradientBoostingRegressor()\n\nstack = StackingRegressor([('lr', lr), ('rf', rf_model)], final_estimator=gb)\nstack.fit(X_train, y_train)","8ca0c343":"y_train_preds = stack.predict(X_train)\ny_test_preds = stack.predict(X_valid)\n\nevaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)","89f4d52d":"test_df.shape","08bb52b7":"test_df","840d2345":"submit = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/sample_submission.csv')\nsubmit.head()","3aa25052":"predictions = rf_model.predict(test_df)\npredictions","496d323e":"submit['Price'] = predictions\nsubmit.head()","4cd3027b":"submit.to_csv('rf_submit.csv', index=False)","db766c5f":"c-v","09d98dd5":"Healthcare_1","019fdaa6":"# types","5f98e9f8":"na objects","4ffecfba":"rooms","40c3c5df":"evaluation","3a7fe540":"MedPriceByFloorYear","b3c80f08":"# outliers  ","a64e21ca":"Dummies","098f10fa":"MedPriceByDistrict","eee045f0":"# new features","f47317db":"fit","2f7ff752":"LifeSquare","2f599250":"rooms","46f2184c":"# path to data, upload","35b26e45":"DistrictSize, IsDistrictLarge","3da03572":"# test forecasting","ce3e2719":"HouseYear","0460d7b5":"HouseFloor, Floor","e8b19317":"# feature selection","fcef60f4":"# EDA  ","236daf71":"# train\/test split","372d9951":"# model","929f4a39":"**\u0412\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432**","e6ebbb21":"KitchenSquare"}}