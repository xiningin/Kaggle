{"cell_type":{"bdb69256":"code","493c96fc":"code","693a7402":"code","e282688f":"markdown"},"source":{"bdb69256":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\nfrom xgboost import XGBClassifier\nimport pdb\n\n\n\ndata_path = Path('\/kaggle\/input\/abstraction-and-reasoning-challenge\/')\ntraining_path = data_path \/ 'training'\nevaluation_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'\n\ndef plot_result(test_input, test_prediction,\n                input_shape):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 2, figsize=(15,15))\n    test_input = test_input.reshape(input_shape[0],input_shape[1])\n    axs[0].imshow(test_input, cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Actual Target')\n    test_prediction = test_prediction.reshape(input_shape[0],input_shape[1])\n    axs[1].imshow(test_prediction, cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Model Prediction')\n    plt.tight_layout()\n    plt.show()\n    \ndef plot_test(test_prediction, task_name):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 1, figsize=(15,15))\n    axs.imshow(test_prediction, cmap=cmap, norm=norm)\n    axs.axis('off')\n    axs.set_title(f'Test Prediction {task_name}')\n    plt.tight_layout()\n    plt.show()\n    \n# https:\/\/www.kaggle.com\/inversion\/abstraction-and-reasoning-starter-notebook\ndef flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\n\n\nsample_sub1 = pd.read_csv(data_path\/'sample_submission.csv')\nsample_sub1 = sample_sub1.set_index('output_id')\nsample_sub1.head()\n\ndef get_moore_neighbours(color, cur_row, cur_col, nrows, ncols):\n\n    if cur_row<=0: top = -1\n    else: top = color[cur_row-1][cur_col]\n        \n    if cur_row>=nrows-1: bottom = -1\n    else: bottom = color[cur_row+1][cur_col]\n        \n    if cur_col<=0: left = -1\n    else: left = color[cur_row][cur_col-1]\n        \n    if cur_col>=ncols-1: right = -1\n    else: right = color[cur_row][cur_col+1]\n        \n    return top, bottom, left, right\n\ndef get_tl_tr(color, cur_row, cur_col, nrows, ncols):\n        \n    if cur_row==0:\n        top_left = -1\n        top_right = -1\n    else:\n        if cur_col==0: top_left=-1\n        else: top_left = color[cur_row-1][cur_col-1]\n        if cur_col==ncols-1: top_right=-1\n        else: top_right = color[cur_row-1][cur_col+1]   \n        \n    return top_left, top_right\n\ndef make_features(input_color, nfeat):\n    nrows, ncols = input_color.shape\n    feat = np.zeros((nrows*ncols,nfeat))\n    cur_idx = 0\n    for i in range(nrows):\n        for j in range(ncols):\n            feat[cur_idx,0] = i\n            feat[cur_idx,1] = j\n            feat[cur_idx,2] = input_color[i][j]\n            feat[cur_idx,3:7] = get_moore_neighbours(input_color, i, j, nrows, ncols)\n            feat[cur_idx,7:9] = get_tl_tr(input_color, i, j, nrows, ncols)\n            feat[cur_idx,9] = len(np.unique(input_color[i,:]))\n            feat[cur_idx,10] = len(np.unique(input_color[:,j]))\n            feat[cur_idx,11] = (i+j)\n            feat[cur_idx,12] = len(np.unique(input_color[i-local_neighb:i+local_neighb,\n                                                         j-local_neighb:j+local_neighb]))\n\n            cur_idx += 1\n        \n    return feat\n\ndef features(task, mode='train'):\n    num_train_pairs = len(task[mode])\n    feat, target = [], []\n    \n    global local_neighb\n    for task_num in range(num_train_pairs):\n        input_color = np.array(task[mode][task_num]['input'])\n        #print(input_color)\n        target_color = task[mode][task_num]['output']\n        #print(target_color)\n        nrows, ncols = len(task[mode][task_num]['input']), len(task[mode][task_num]['input'][0])\n\n        target_rows, target_cols = len(task[mode][task_num]['output']), len(task[mode][task_num]['output'][0])\n        \n        if (target_rows!=nrows) or (target_cols!=ncols):\n            print('Number of input rows:',nrows,'cols:',ncols)\n            print('Number of target rows:',target_rows,'cols:',target_cols)\n            not_valid=1\n            return None, None, 1\n\n        imsize = nrows*ncols\n        #offset = imsize*task_num*3 #since we are using three types of aug\n        feat.extend(make_features(input_color, nfeat))\n        target.extend(np.array(target_color).reshape(-1,))\n            \n    return np.array(feat), np.array(target), 0\n\n# mode = 'eval'\nmode = 'test'\nif mode=='eval':\n    task_path = evaluation_path\nelif mode=='train':\n    task_path = training_path\nelif mode=='test':\n    task_path = test_path\n\nall_task_ids = sorted(os.listdir(task_path))\n\nnfeat = 13\nlocal_neighb = 5\nvalid_scores = {}\n\nmodel_accuracies = {'ens': []}\npred_taskids = []\n\nfor task_id in all_task_ids:\n\n    task_file = str(task_path \/ task_id)\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n\n    feat, target, not_valid = features(task)\n    if not_valid:\n        print('ignoring task', task_file)\n        print()\n        not_valid = 0\n        continue\n\n    xgb =  XGBClassifier(n_estimators=10, n_jobs=-1)\n    xgb.fit(feat, target, verbose=-1)\n\n\n#     training on input pairs is done.\n#     test predictions begins here\n\n    num_test_pairs = len(task['test'])\n    for task_num in range(num_test_pairs):\n        cur_idx = 0\n        input_color = np.array(task['test'][task_num]['input'])\n        nrows, ncols = len(task['test'][task_num]['input']), len(\n            task['test'][task_num]['input'][0])\n        feat = make_features(input_color, nfeat)\n\n        print('Made predictions for ', task_id[:-5])\n\n        preds = xgb.predict(feat).reshape(nrows,ncols)\n        \n        if (mode=='train') or (mode=='eval'):\n            ens_acc = (np.array(task['test'][task_num]['output'])==preds).sum()\/(nrows*ncols)\n\n            model_accuracies['ens'].append(ens_acc)\n\n            pred_taskids.append(f'{task_id[:-5]}_{task_num}')\n\n#             print('ensemble accuracy',(np.array(task['test'][task_num]['output'])==preds).sum()\/(nrows*ncols))\n#             print()\n\n        preds = preds.astype(int).tolist()\n#         plot_test(preds, task_id)\n        sample_sub1.loc[f'{task_id[:-5]}_{task_num}',\n                       'output'] = flattener(preds)\n        \n\n\nif (mode=='train') or (mode=='eval'):\n    df = pd.DataFrame(model_accuracies, index=pred_taskids)\n    print(df.head(10))\n\n    print(df.describe())\n    for c in df.columns:\n        print(f'for {c} no. of complete tasks is', (df.loc[:, c]==1).sum())\n\n    df.to_csv('ens_acc.csv')\n\n\n\nsample_sub1.head()\n\n\n\nsample_sub1.to_csv('submission1.csv')","493c96fc":"data_path = Path('\/kaggle\/input\/abstraction-and-reasoning-challenge\/')\ntraining_path = data_path \/ 'training'\nevaluation_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'\ntraining_tasks = sorted(os.listdir(training_path))\neval_tasks = sorted(os.listdir(evaluation_path))\n\n\nT = training_tasks\nTrains = []\nfor i in range(400):\n    task_file = str(training_path \/ T[i])\n    task = json.load(open(task_file, 'r'))\n    Trains.append(task)\n    \nE = eval_tasks\nEvals= []\nfor i in range(400):\n    task_file = str(evaluation_path \/ E[i])\n    task = json.load(open(task_file, 'r'))\n    Evals.append(task)\n    \n    \ncmap = colors.ListedColormap(\n    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n# 0:black, 1:blue, 2:red, 3:greed, 4:yellow,\n# 5:gray, 6:magenta, 7:orange, 8:sky, 9:brown\nplt.figure(figsize=(5, 2), dpi=200)\nplt.imshow([list(range(10))], cmap=cmap, norm=norm)\nplt.xticks(list(range(10)))\nplt.yticks([])\nplt.show()\n\ndef plot_task(task):\n    n = len(task[\"train\"]) + len(task[\"test\"])\n    fig, axs = plt.subplots(2, n, figsize=(4*n,8), dpi=50)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    fig_num = 0\n    for i, t in enumerate(task[\"train\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Train-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Train-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    for i, t in enumerate(task[\"test\"]):\n        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Test-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Test-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        fig_num += 1\n    \n    plt.tight_layout()\n    plt.show()\n    \n\ndef plot_picture(x):\n    plt.imshow(np.array(x), cmap = cmap, norm = norm)\n    plt.show()\n    \n    \ndef Defensive_Copy(A): \n    n = len(A)\n    k = len(A[0])\n    L = np.zeros((n,k), dtype = int)\n    for i in range(n):\n        for j in range(k):\n            L[i,j] = 0 + A[i][j]\n    return L.tolist()\n\n\ndef Create(task, task_id = 0):\n    n = len(task['train'])\n    Input = [Defensive_Copy(task['train'][i]['input']) for i in range(n)]\n    Output = [Defensive_Copy(task['train'][i]['output']) for i in range(n)]\n    Input.append(Defensive_Copy(task['test'][task_id]['input']))\n    return Input, Output\n\n\ndef Recolor(task):\n    Input = task[0]\n    Output = task[1]\n    Test_Picture = Input[-1]\n    Input = Input[:-1]\n    N = len(Input)\n    \n    for x, y in zip(Input, Output):\n        if len(x) != len(y) or len(x[0]) != len(y[0]):\n            return -1\n        \n    Best_Dict = -1\n    Best_Q1 = -1\n    Best_Q2 = -1\n    Best_v = -1\n    # v ranges from 0 to 3. This gives an extra flexibility of measuring distance from any of the 4 corners\n    Pairs = []\n    for t in range(15):\n        for Q1 in range(1,8):\n            for Q2 in range(1,8):\n                if Q1+Q2 == t:\n                    Pairs.append((Q1,Q2))\n                    \n    for Q1, Q2 in Pairs:\n        for v in range(4):\n    \n  \n            if Best_Dict != -1:\n                continue\n            possible = True\n            Dict = {}\n                      \n            for x, y in zip(Input, Output):\n                n = len(x)\n                k = len(x[0])\n                for i in range(n):\n                    for j in range(k):\n                        if v == 0 or v ==2:\n                            p1 = i%Q1\n                        else:\n                            p1 = (n-1-i)%Q1\n                        if v == 0 or v ==3:\n                            p2 = j%Q2\n                        else :\n                            p2 = (k-1-j)%Q2\n                        color1 = x[i][j]\n                        color2 = y[i][j]\n                        if color1 != color2:\n                            rule = (p1, p2, color1)\n                            if rule not in Dict:\n                                Dict[rule] = color2\n                            elif Dict[rule] != color2:\n                                possible = False\n            if possible:\n                \n                # Let's see if we actually solve the problem\n                for x, y in zip(Input, Output):\n                    n = len(x)\n                    k = len(x[0])\n                    for i in range(n):\n                        for j in range(k):\n                            if v == 0 or v ==2:\n                                p1 = i%Q1\n                            else:\n                                p1 = (n-1-i)%Q1\n                            if v == 0 or v ==3:\n                                p2 = j%Q2\n                            else :\n                                p2 = (k-1-j)%Q2\n                           \n                            color1 = x[i][j]\n                            rule = (p1,p2,color1)\n                            \n                            if rule in Dict:\n                                color2 = 0 + Dict[rule]\n                            else:\n                                color2 = 0 + y[i][j]\n                            if color2 != y[i][j]:\n                                possible = False \n                if possible:\n                    Best_Dict = Dict\n                    Best_Q1 = Q1\n                    Best_Q2 = Q2\n                    Best_v = v\n                \n                \n    if Best_Dict == -1:\n        return -1 #meaning that we didn't find a rule that works for the traning cases\n    \n    #Otherwise there is a rule: so let's use it:\n    n = len(Test_Picture)\n    k = len(Test_Picture[0])\n    \n    answer = np.zeros((n,k), dtype = int)\n   \n    for i in range(n):\n        for j in range(k):\n            if Best_v == 0 or Best_v ==2:\n                p1 = i%Best_Q1\n            else:\n                p1 = (n-1-i)%Best_Q1\n            if Best_v == 0 or Best_v ==3:\n                p2 = j%Best_Q2\n            else :\n                p2 = (k-1-j)%Best_Q2\n           \n            color1 = Test_Picture[i][j]\n            rule = (p1, p2, color1)\n            if (p1, p2, color1) in Best_Dict:\n                answer[i][j] = 0 + Best_Dict[rule]\n            else:\n                answer[i][j] = 0 + color1\n                                    \n           \n            \n    return answer.tolist()\n\n\nFunction = Recolor\n\ntraining_examples = []\nfor i in range(400):\n    task = Trains[i]\n    basic_task = Create(task,0)\n    a = Function(basic_task)\n  \n    if  a != -1 and task['test'][0]['output'] == a:\n        plot_picture(a)\n        plot_task(task)\n        print(i)\n        training_examples.append(i)\n        \n        \nevaluation_examples = []\n\n\nfor i in range(400):\n    task = Evals[i]\n    basic_task = Create(task,0)\n    a = Function(basic_task)\n    \n    if a != -1 and task['test'][0]['output'] == a:\n       \n        plot_picture(a)\n        plot_task(task)\n        print(i)\n        evaluation_examples.append(i)\n        \n        \nsample_sub2 = pd.read_csv(data_path\/ 'sample_submission.csv')\nsample_sub2.head()\n\n\ndef flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\n\nexample_grid = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndisplay(example_grid)\nprint(flattener(example_grid))\n\nSolved = []\nProblems = sample_sub2['output_id'].values\nProposed_Answers = []\nfor i in  range(len(Problems)):\n    output_id = Problems[i]\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    f = str(test_path \/ str(task_id + '.json'))\n   \n    with open(f, 'r') as read_file:\n        task = json.load(read_file)\n    \n    n = len(task['train'])\n    Input = [Defensive_Copy(task['train'][j]['input']) for j in range(n)]\n    Output = [Defensive_Copy(task['train'][j]['output']) for j in range(n)]\n    Input.append(Defensive_Copy(task['test'][pair_id]['input']))\n    \n    solution = Recolor([Input, Output])\n   \n    \n    pred = ''\n        \n    if solution != -1:\n        Solved.append(i)\n        pred1 = flattener(solution)\n        pred = pred+pred1+' '\n        \n    if pred == '':\n        pred = flattener(example_grid)\n        \n    Proposed_Answers.append(pred)\n    \nsample_sub2['output'] = Proposed_Answers\nsample_sub2.to_csv('submission2.csv', index = False)","693a7402":"sample_sub1 = sample_sub1.reset_index()\nsample_sub1 = sample_sub1.sort_values(by=\"output_id\")\n\nsample_sub2 = sample_sub2.sort_values(by=\"output_id\")\nout1 = sample_sub1[\"output\"].astype(str).values\nout2 = sample_sub2[\"output\"].astype(str).values\n\nmerge_output = []\nfor o1, o2 in zip(out1, out2):\n    o = o1.strip().split(\" \")[:1] + o2.strip().split(\" \")[:2]\n    o = \" \".join(o[:3])\n    merge_output.append(o)\nsample_sub1[\"output\"] = merge_output\nsample_sub1[\"output\"] = sample_sub1[\"output\"].astype(str)\nsample_sub1.to_csv(\"submission.csv\", index=False)","e282688f":"This kernel shows an `ensemble` method in this competition.  \n\nI take the code from two kernels and ensemble their results \n\n- https:\/\/www.kaggle.com\/szabo7zoltan\/colorandcountingmoduloq \n- https:\/\/www.kaggle.com\/meaninglesslives\/using-decision-trees-for-arc"}}