{"cell_type":{"85193a33":"code","5b75fb87":"code","aef6cbac":"code","50b21e4c":"code","e6583e15":"code","daae0c65":"code","ca17ad5d":"code","7201a724":"code","275e56a3":"code","0c9c00cf":"code","3cd81c91":"code","80e44297":"code","3196f50f":"code","8b3aa40e":"code","25f93176":"code","177e1dc5":"code","0cdc23d8":"code","4d81b8ac":"code","b530ef8d":"code","bf63d935":"code","603498a9":"code","11966d5f":"code","f68220b0":"code","287a2023":"code","52d57dab":"code","efb63ce1":"code","13289683":"code","9aa33bb4":"code","137e74bd":"code","14bda7ee":"code","836a09e8":"code","fad22abe":"code","185f849c":"code","2c1b83de":"code","b38d374e":"code","2685f9ab":"code","18615d7a":"code","b1e9de48":"code","e8bc1802":"code","919ff271":"code","f0ead275":"code","40fadb0e":"code","2102a805":"code","9fddf041":"code","ec8dc5fa":"code","f4c545b9":"code","eede0db5":"code","af7b8322":"code","11791e13":"code","a61f649d":"code","3ddd8ff4":"code","2e76020e":"code","10dd842f":"code","f559f8bf":"code","3017ef65":"code","31f4eb47":"code","4cacc51d":"code","b5cee3ac":"code","875198a4":"code","4b8d70a9":"code","7e9b39a7":"code","d4395302":"code","513953d3":"code","6ac2aff0":"code","d943fb21":"code","c68bfae9":"code","affc8dd6":"code","35348a30":"code","8d43b9d5":"code","28d9e594":"code","a57f169a":"code","bad86523":"code","85f38e2d":"markdown","51704925":"markdown","21158a82":"markdown","f5861f90":"markdown","88ec8999":"markdown","02e99e5e":"markdown","68f1f8a9":"markdown","acd50ec5":"markdown","7448460c":"markdown","fc60fdd5":"markdown","316ad118":"markdown","8b5b79f5":"markdown","97c986f9":"markdown","62db7ef8":"markdown","97c8fca4":"markdown","282e4696":"markdown","cfe03625":"markdown","185a10b6":"markdown","0bb7c8bb":"markdown","50156d30":"markdown","1ec2210b":"markdown","65c59cfb":"markdown","aec3df1f":"markdown","4174ac7c":"markdown","fc4fc1b3":"markdown","d8fe9ff5":"markdown","59876e1e":"markdown","fff4e980":"markdown"},"source":{"85193a33":"import pandas as pd\nimport numpy as np\nimport pandas as pd\n\n# For Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# To Scale our data\nfrom sklearn.preprocessing import scale\n\n# To perform KMeans clustering \nfrom sklearn.cluster import KMeans\n\n# To perform Hierarchical clustering\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","5b75fb87":"import warnings\nwarnings.filterwarnings('ignore')","aef6cbac":"#importing Dataset already uploaded to ANACONDA cloud\ndf_original = pd.read_csv('..\/input\/Country-data.csv')\ndf = pd.read_csv('..\/input\/Country-data.csv')","50b21e4c":"df.head()","e6583e15":"df.shape","daae0c65":"df.info()","ca17ad5d":"#Checking outliers for ciontinuous variables\n# Checking outliers at 25%,50%,75%,90%,95% and 99%\ndf.describe(percentiles=[.25,.50,.75,.90,.95,.99])","7201a724":"from sklearn.preprocessing import StandardScaler","275e56a3":"scaler = StandardScaler()","0c9c00cf":"y= df.pop('country')","3cd81c91":"X = df.copy()","80e44297":"x = scaler.fit_transform(X)","3196f50f":"x","8b3aa40e":"from sklearn.decomposition import PCA","25f93176":"pca = PCA(svd_solver = 'randomized', random_state=42)","177e1dc5":"pca.fit(x)","0cdc23d8":"pca.components_","4d81b8ac":"pca.explained_variance_ratio_","b530ef8d":"plt.ylabel('Cumulative Variance')\nplt.xlabel('Number of Components')\nplt.bar(range(1,len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)","bf63d935":"var_cumu = np.cumsum(pca.explained_variance_ratio_)\nvar_cumu","603498a9":"plt.plot(range(1,(len(var_cumu)+1)),var_cumu)\nplt.title('Scree Plot')\nplt.xlabel('Cumulative Variance')\nplt.ylabel('Number of Components')","11966d5f":"from sklearn.decomposition import IncrementalPCA","f68220b0":"pc5 = PCA(n_components = 5, random_state=42)","287a2023":"df_pc5 = pc5.fit_transform(x)","52d57dab":"df_pc5.shape","efb63ce1":"df_pc5[:10]","13289683":"df5 = pd.DataFrame(df_pc5, columns=['PC1','PC2','PC3','PC4','PC5'])","9aa33bb4":"df5.head()","137e74bd":"df5_final = pd.concat([df5,y], axis=1)","14bda7ee":"df5_final.head()","836a09e8":"plt.figure(figsize=(20,5))\n# For PC1\nplt.subplot(1,5,1)\nplt.title('PC1')\nplt.boxplot(df5_final.PC1)\n\nQ1 = df5_final.PC1.quantile(0.05)\nQ3 = df5_final.PC1.quantile(0.95)\nIQR = Q3-Q1\ndf5_final = df5_final[(df5_final.PC1>=Q1) & (df5_final.PC1<=Q3)]\n\n# For PC2\nplt.subplot(1,5,2)\nplt.title('PC2')\nplt.boxplot(df5_final.PC2)\n\nQ1 = df5_final.PC2.quantile(0.05)\nQ3 = df5_final.PC2.quantile(0.95)\nIQR = Q3-Q1\ndf5_final = df5_final[(df5_final.PC2>=Q1) & (df5_final.PC2<=Q3)]\n\n\n# For PC3\nplt.subplot(1,5,3)\nplt.title('PC3')\nplt.boxplot(df5_final.PC3)\n\nQ1 = df5_final.PC3.quantile(0.05)\nQ3 = df5_final.PC3.quantile(0.95)\nIQR = Q3-Q1\ndf5_final = df5_final[(df5_final.PC3>=Q1) & (df5_final.PC3<=Q3)]\n\n\n# For PC4\nplt.subplot(1,5,4)\nplt.title('PC4')\nplt.boxplot(df5_final.PC4)\n\nQ1 = df5_final.PC4.quantile(0.05)\nQ3 = df5_final.PC4.quantile(0.95)\nIQR = Q3-Q1\ndf5_final = df5_final[(df5_final.PC4>=Q1) & (df5_final.PC4<=Q3)]\n\n\n# For PC5\nplt.subplot(1,5,5)\nplt.title('PC5')\nplt.boxplot(df5_final.PC5)\n\nQ1 = df5_final.PC5.quantile(0.05)\nQ3 = df5_final.PC5.quantile(0.95)\nIQR = Q3-Q1\ndf5_final = df5_final[(df5_final.PC5>=Q1) & (df5_final.PC5<=Q3)]","fad22abe":"### Clustering - Calculating the Hopkins statistic#Calculating the Hopkins statistic\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nimport numpy as np\nfrom math import isnan\n \ndef hopkins(X):\n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    H = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","185f849c":"hopkins(df5_final.drop('country', axis =1))","2c1b83de":"df6_final = df5_final.drop('country', axis = 1)","b38d374e":"#First we'll do the silhouette score analysis\nfrom sklearn.metrics import silhouette_score\n\nss = []\nfor k in range(2,10):\n    kmeans = KMeans(n_clusters = k).fit(df6_final)\n    ss.append([k,silhouette_score(df6_final, kmeans.labels_)])","2685f9ab":"plt.title('Silhoette')\nplt.plot(pd.DataFrame(ss)[0], pd.DataFrame(ss)[1]);","18615d7a":"#Now let's proceed to the elbow curve method\nfrom sklearn.metrics import silhouette_score\n\nssd = []\nfor k in range(1,10):\n    model = KMeans(n_clusters = k, max_iter = 50).fit(df6_final)\n    ssd.append([model.inertia_])\n\nprint(ssd)","b1e9de48":"plt.title('Elbow')\nplt.plot(ssd)","e8bc1802":"range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n\nfor num_clusters in range_n_clusters:\n    \n    # intialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(df6_final)\n    \n    cluster_labels = kmeans.labels_\n    \n    # silhouette score\n    silhouette_avg = silhouette_score(df6_final, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))","919ff271":"#Let's perform K means using K=\nmodel_clus2 = KMeans(n_clusters = 3, max_iter = 50, random_state = 50)\nmodel_clus2.fit(df6_final)","f0ead275":"# Let's add the cluster Ids to the PCs data \n\ndat_km = pd.concat([df5_final.reset_index().drop('index', axis=1), pd.Series(model_clus2.labels_)], axis =1)","40fadb0e":"dat_km.head()","2102a805":"dat_km.columns = ['PC1', 'PC2', 'PC3','PC4','PC5', 'country','ClusterID']\ndat_km.head()","9fddf041":"# Check the count of observation per cluster\ndat_km['ClusterID'].value_counts()","ec8dc5fa":"# Plot the Cluster with respect to the clusters obtained\n\nplt.figure(figsize=(15,4))\n\nplt.subplot(1,3,1)\nsns.scatterplot(x='PC1', y ='PC2', hue = 'ClusterID', palette=['green','dodgerblue','red'], legend='full', data = dat_km)\nplt.subplot(1,3,2)\nsns.scatterplot(x='PC1', y ='PC3', hue = 'ClusterID', palette=['green','dodgerblue','red'], legend='full', data = dat_km)\nplt.subplot(1,3,3)\nsns.scatterplot(x='PC2', y ='PC3', hue = 'ClusterID', palette=['green','dodgerblue','red'], legend='full', data = dat_km)\n","f4c545b9":"# Let's merge the original data with the data(ClusterID)\ndat5 = pd.merge(df_original, dat_km, how = 'inner', on = 'country')\ndat5.head()","eede0db5":"dat5.shape","af7b8322":"dat6 = dat5[['country','child_mort', 'income','gdpp', 'PC1', 'PC2', 'ClusterID']]","11791e13":"dat6.groupby('ClusterID').count()","a61f649d":"child_mort = dat6.groupby(['ClusterID']).child_mort.mean()\nincome = dat6.groupby(['ClusterID']).income.mean()\ngdpp = dat6.groupby(['ClusterID']).gdpp.mean()","3ddd8ff4":"final_df = pd.concat([child_mort, income, gdpp], axis = 1)","2e76020e":"final_df","10dd842f":"plt.figure(figsize=(20, 8))\nplt.subplot(1,3,1)\nsns.boxplot(x='ClusterID', y='income', data=dat6)\n\nplt.subplot(1,3,2)\nsns.boxplot(x='ClusterID', y='child_mort', data=dat6)\n\nplt.subplot(1,3,3)\nsns.boxplot(x='ClusterID', y='gdpp', data=dat6)","f559f8bf":"# List of Countries which need Attention.\n\ndat6[dat6['ClusterID']==2]['country']","3017ef65":"rfm_df = df[['child_mort', 'income','gdpp']]\n\n# instantiate\nscaler = StandardScaler()\n\n# fit_transform\nrfm_df_scaled = scaler.fit_transform(rfm_df)\nrfm_df_scaled.shape","31f4eb47":"rfm_df_scaled[:10]","4cacc51d":"# single linkage\nplt.figure(figsize=(20,10))\nplt.title('Dendrogram - Single Linkage')\nmergings = linkage(rfm_df_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\n\nplt.show()","b5cee3ac":"# complete linkage\nplt.figure(figsize=(20,10))\nplt.title('Dendrogram - Complete Linkage')\nmergings = linkage(rfm_df_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","875198a4":"# 3 clusters\ncluster_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )\ncluster_labels","4b8d70a9":"# assign cluster labels\nrfm_df_scaled = pd.DataFrame(rfm_df_scaled)\nrfm_df_scaled.columns = ['child_mort', 'income','gdpp']\nrfm_df_scaled.head()\nrfm_df_scaled['cluster_labels'] = cluster_labels\n","7e9b39a7":"rfm_df_scaled['country'] = df_original['country']\nrfm_df_scaled.groupby('cluster_labels').count()","d4395302":"# Plot the Cluster with respect to the clusters obtained\n\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,3,1)\nsns.scatterplot(x='child_mort', y ='income', hue = 'cluster_labels', palette=['green','dodgerblue','red'], legend='full', data = rfm_df_scaled)\nplt.subplot(1,3,2)\nsns.scatterplot(x='child_mort', y ='gdpp', hue = 'cluster_labels', palette=['green','dodgerblue','red'], legend='full', data = rfm_df_scaled)\nplt.subplot(1,3,3)\nsns.scatterplot(x='gdpp', y ='income', hue = 'cluster_labels', palette=['green','dodgerblue','red'], legend='full', data = rfm_df_scaled)\n","513953d3":"rfm_df_scaled[rfm_df_scaled['cluster_labels']==0].head(10)","6ac2aff0":"rfm_df_scaled[rfm_df_scaled['cluster_labels']==1].head(10)","d943fb21":"rfm_df_scaled[rfm_df_scaled['cluster_labels']==2]","c68bfae9":"plt.figure(figsize=(20,8))\nplt.subplot(1,3,1)\nsns.boxplot(x='cluster_labels', y='income', data=rfm_df_scaled)\n\nplt.subplot(1,3,2)\nsns.boxplot(x='cluster_labels', y='child_mort', data=rfm_df_scaled)\n\nplt.subplot(1,3,3)\nsns.boxplot(x='cluster_labels', y='gdpp', data=rfm_df_scaled)","affc8dd6":"rfm_df_scaled[rfm_df_scaled['cluster_labels']==1]['country']","35348a30":"# List of Countries which need Attention.\n\ndf_H = rfm_df_scaled[rfm_df_scaled['cluster_labels']==1]\ndf_H = df_H[['country', 'child_mort','income', 'gdpp']]\ndf_H.head(30)","8d43b9d5":"# List of Countries which need Attention.\n\ndf_K = dat6[dat6['ClusterID']==2]\ndf_K = df_K[['country', 'child_mort','income', 'gdpp']]\ndf_K.head(30)","28d9e594":"df_combined = pd.concat([df_K, df_H], join = 'inner' )\ndf_combined.head(20)\n\ndf_combined.head()","a57f169a":"plt.figure(figsize=(15,15))\nplt.subplot(1,3,1)\nplt.title('child_mort')\nsns.barplot(x=\"child_mort\", y=\"country\", data=df_combined.sort_values(by=['income'], ascending = True))\n\nplt.subplot(1,3,2)\nplt.title('income')\nsns.barplot(x=\"income\", y=\"country\", data=df_combined.sort_values(by=['income'], ascending = True))\n\nplt.subplot(1,3,3)\nplt.title('gdpp')\nsns.barplot(x=\"gdpp\", y=\"country\", data=df_combined.sort_values(by=['income'], ascending = True))\n","bad86523":"# Bottom 20 Countries which need help\ndf_combined.sort_values(by=['income'], ascending = True)[:20]['country']","85f38e2d":"### Cluster Profiling","51704925":"### Importing Libaries","21158a82":"### Making the Scree Plot","f5861f90":"`The graph starts flattening after 5 components, contributing to almost 95% variance`","88ec8999":"### K-Means Suggestion\n- Countries in Cluster 2 have an average child mortality 90, 90\/1000 child die before the age of 5\n- Countries in Cluster 2 have an average gdpp of 553 which is very low compared to clusters 0 & 1\n- Countries in Cluster 2 have an average income of 1600 which is very low compared to clusters 0 & 1","02e99e5e":"### Merging the 2 results and analysing","68f1f8a9":"**Problem**\n\nX International is an international humanitarian NGO that is committed to fighting poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities. It runs a lot of operational projects from time to time along with advocacy drives to raise awareness as well as for funding purposes.\n\nAfter the recent funding programs, they have been able to raise around $ 10 million. Now the CEO of the NGO needs to decide how to use this money strategically and effectively. The significant issues that come while making this decision are mostly related to choosing the countries that are in the direst need of aid.\n\n> The NGO wants to identify the countries based on the socioeconomic factors **Child Mortality, Income, GDPP**","acd50ec5":"### Data Description","7448460c":"### Look at the silhouette score plot and choose the optimal number of cluster","fc60fdd5":"### Complete linkage","316ad118":"#### `Observation`\n- None of the rows have missing values\n\n- All variables are int64\/float64 excluding country, no categorical variables\n\n- *No Data Preparation or Dummy variable creation is required for the columns in this dataset*","8b5b79f5":"### Principal Component Analysis","97c986f9":"### Single Linkage","62db7ef8":"### Clustering - Calculating the Hopkins statistic","97c8fca4":"### Creating a PCA with 5 components","282e4696":"## KMeans with the K we have choosed = 3","cfe03625":"# K-Means Clustering","185a10b6":"### Heirarchical Clustring - Suggestion\n- Countries in Cluster 2 have good income,gdpp and low child mortality.\n- Countries in Cluster 1 have income almost similar to Cluster 0 but with high child mortality.\n\n- **In my analysis countries from Cluster 1 should be considered**","0bb7c8bb":"### Scaling the Data","50156d30":"###  Look at the Elbow Curve plot and choose the optimal number of cluster","1ec2210b":" **From the above Graph Countries which need Attention**\n- Child Mortality : Mozambique, Malawi, Togo, Guinea, Comoros\n- Income: Congo, Dem. Rep.,Niger, Central African Republic, Sierra Leone, Burkina Faso, Haiti\n- GDPP: Congo, Dem. Rep.,Niger, Central African Republic, Sierra Leone, Burkina Faso, Haiti","65c59cfb":"# Hierarchical Clustering","aec3df1f":"![Approach.JPG](attachment:Approach.JPG)","4174ac7c":"![4-watercolour-political-map-of-the-world-michael-tompsett.jpg](attachment:4-watercolour-political-map-of-the-world-michael-tompsett.jpg)","fc4fc1b3":"### Checking for Missing Data","d8fe9ff5":"### Let's perfrom Outlier treatment","59876e1e":"### Making a dataframe out of it for convinience","fff4e980":"`End`"}}