{"cell_type":{"3391eb7d":"code","09cdd383":"code","000f9f1a":"code","b3e50bc7":"code","af3479e0":"code","4ba6f893":"code","4a4d7810":"code","11301abd":"code","74d65a1a":"code","e0e71cc2":"code","8fb89bc7":"code","40595529":"code","4e67d0fc":"code","3b8d68ea":"code","1dd6495e":"code","d2a98a02":"code","8802b27d":"code","fe771fb7":"code","96a25c82":"code","a5d75ebc":"code","a5624d11":"code","0973e2b5":"code","c8c34ab4":"code","84508f9c":"code","02e08ccd":"code","48e352ac":"code","73eaf7f7":"code","8eccc525":"code","4df7fab8":"code","b7cbc8ae":"code","1b317957":"code","8e3589be":"code","66f826c0":"code","14968b35":"code","5ce28e2c":"code","a569df16":"code","e4bc81b0":"code","25e7891b":"markdown","692ca514":"markdown"},"source":{"3391eb7d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats\nimport lightgbm as lgb\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport gc\nimport json\npd.set_option('display.max_columns', 1000)\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\nimport seaborn as sns\nsns.set_style(\"whitegrid\")","09cdd383":"\ndef existing_data(data):\n    total = data.isnull().count() - data.isnull().sum()\n    percent = 100 - (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    tt = pd.DataFrame(tt.reset_index())\n    return(tt.sort_values(['Total'], ascending=False))","000f9f1a":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","b3e50bc7":"def read_data():\n    print(f'Read data')\n    train_df = pd.read_csv('..\/input\/data-science-bowl-2019\/train.csv')\n    test_df = pd.read_csv('..\/input\/data-science-bowl-2019\/test.csv')\n    train_labels_df = pd.read_csv('..\/input\/data-science-bowl-2019\/train_labels.csv')\n    specs_df = pd.read_csv('..\/input\/data-science-bowl-2019\/specs.csv')\n    sample_submission_df = pd.read_csv('..\/input\/data-science-bowl-2019\/sample_submission.csv')\n    print(f\"train shape: {train_df.shape}\")\n    print(f\"test shape: {test_df.shape}\")\n    print(f\"train labels shape: {train_labels_df.shape}\")\n    print(f\"specs shape: {specs_df.shape}\")\n    print(f\"sample submission shape: {sample_submission_df.shape}\")\n    return train_df, test_df, train_labels_df, specs_df, sample_submission_df","af3479e0":"train_df, test_df, train_labels_df, specs_df, sample_submission_df = read_data()","4ba6f893":"total = train_df.isnull().sum().sort_values(ascending = False)\npercent = (train_df.isnull().sum()\/train_df.isnull().count() * 100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], keys = ['Total', 'Percent'], axis = 1)\nmissing_data","4a4d7810":"total = test_df.isnull().sum().sort_values(ascending = False)\nprecent = (train_df.isnull().sum()\/train_df.isnull().count()*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], keys = ['Total', 'Percent'], axis = 1)\nmissing_data","11301abd":"total = train_labels_df.isnull().sum().sort_values(ascending = False)\npercent = (train_labels_df.isnull().sum()\/train_labels_df.isnull().count()* 100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], keys = ['Total', 'Percent'], axis = 1)\nmissing_data","74d65a1a":"train_df.groupby('world')['game_session'].count().sort_values(ascending = False).plot(kind = 'bar', figsize = (20,10), title = 'world distribution in train set', rot = 360)","e0e71cc2":"train_df.groupby('type')['game_session'].count().sort_values(ascending = False).plot(kind = 'bar', figsize = (20,10), rot = 360)","8fb89bc7":"train_df.groupby('event_code')['game_session'].count().sort_values(ascending = True).plot(kind = 'barh', figsize = (20,10), title = 'Event_code distribution in train set')","40595529":"train_types = train_df['type'].value_counts()\ntest_types = train_df['type'].value_counts()","4e67d0fc":"train_types","3b8d68ea":"fig = make_subplots(rows=1, cols =2, specs = [[{'type':'domain'}, {'type': 'domain'}]])\n\nfig.add_trace(go.Pie(values = train_types, labels = train_types.index.tolist(), name = 'Train', hole = .3), 1,1)\nfig.add_trace(go.Pie(values=test_types, labels=test_types.index.tolist(), name=\"Test\" , hole=.3),1, 2)\n\nfig.update_traces(hoverinfo = 'label + percent + value', textinfo = 'percent', textfont_size = 17, textposition = 'inside', marker = dict(colors = ['gold', 'mediumturquoise', 'darkorange', 'plum'], line = dict(color = '#000000', width = 3)))\n\nfig.update_layout(title_text = 'Media Type of The Game or Video', height = 500, width = 800, annotations = [dict(text = 'Train', x = 0.18, y=0.5, font_size = 20, showarrow = False), dict(text='Test', x = 0.82, font_size = 20, showarrow = False)])\n","1dd6495e":"train_df.groupby('installation_id').count()['event_id'].plot(kind = 'hist', title = 'distribution of installation_id ', figsize = (15,5), bins = 40)","d2a98a02":"train_df.groupby('installation_id').count()['event_id'].apply(np.log1p).plot(kind = 'hist', title = 'distribution of installation_id in train set (log1p scale) ', bins = 40, figsize = (15,5))","8802b27d":"train_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\ntrain_df['date'] = train_df['timestamp'].dt.date\ntrain_df['hour'] = train_df['timestamp'].dt.hour\ntrain_df['weekday_name'] = train_df['timestamp'].dt.weekday_name","fe771fb7":"train_df","96a25c82":"train_df.groupby('date')['event_id'].count().plot(figsize = (20,5), color = 'green')","a5d75ebc":"train_df.groupby('hour')['event_id'].count().plot(figsize = (20,5), color = 'red') ","a5624d11":"train_df.groupby('weekday_name')['event_id'].count().T[['Monday','Tuesday','Wednesday',\n                     'Thursday','Friday','Saturday',\n                     'Sunday']].plot(figsize = (15,5))","0973e2b5":"train_df['game_time'].plot(kind = 'hist', bins = 100, title = 'Game time', figsize = (15,5))","c8c34ab4":"train_df['game_time'].apply(np.log1p).plot(kind = 'hist', bins = 100 ,figsize = (15,5) ,title = 'Log1p scale of Game time')","84508f9c":"train_df.groupby('title')['event_id'].count().sort_values(ascending = True).plot(kind = 'barh', figsize = (15,15), title = 'Game\/Vedeo title')","02e08ccd":"train_df.groupby('event_code').count()['event_id'].sort_values(ascending = False).plot(kind = 'bar', figsize = (15,5))","48e352ac":"sample_train = train_df.sample(100000)","73eaf7f7":"extracted_event_data = pd.io.json.json_normalize(sample_train.event_data.apply(json.loads))","8eccc525":"extracted_event_data.head(15)","4df7fab8":"missing_data(extracted_event_data)","b7cbc8ae":"stat_event_data = existing_data(extracted_event_data)\nstat_event_data","1b317957":"stat_event_data[['index','Percent']].head()","8e3589be":"specs_df['args'][0]","66f826c0":"specs_args_extracted = pd.DataFrame()\nfor i in range(0, specs_df.shape[0]):\n    for arg_item in json.loads(specs_df.args[i]):\n        new_df = pd.DataFrame({'event_id':specs_df['event_id'][i],\n                              'info': specs_df['info'][i],\n                              'args_name': arg_item['name'],\n                              'args_type': arg_item['type'],\n                              'args_info': arg_item['info']}, index = [i])\n        specs_args_extracted = specs_args_extracted.append(new_df)","14968b35":"specs_args_extracted","5ce28e2c":"tmp = specs_args_extracted.groupby(['event_id'])['info'].count()\ndf = pd.DataFrame({'event_id': tmp.index, 'count': tmp.values})\nplt.figure(figsize = (6,4))\nax = sns.distplot(df['count'], kde = True, hist = False, bins = 40)\nplt.title('Distribution of number of arguments per event_id')\nplt.xlabel('Number of arguments'); plt.ylabel('Density')","a569df16":"train_df[(train_df.event_code == 4100) & (train_df.installation_id == '0006a69f') & (train_df.title == 'Bird Measurer (Assessment)')]['event_data'].tolist()","e4bc81b0":"train_df[(train_df.installation_id == '0006a69f') & ((train_df.type == \"Assessment\") & (train_df.title == 'Bird Measurer (Assessment)') & (train_df.event_code == 4110) | (train_df.type == 'Assessment') & (train_df.title != ''))]","25e7891b":"# Extract features from specs\/args","692ca514":"## train_df EDA"}}