{"cell_type":{"49e08439":"code","8bb1ebf0":"code","f662f035":"code","f956940c":"code","2822ee04":"code","4802a1f7":"code","885885ec":"code","89164e91":"code","d344f48c":"code","943811f0":"code","9d3efcbb":"code","4f5bf965":"code","10c09144":"code","f1c2d65b":"code","9a469f5f":"code","61757b80":"code","b290663f":"markdown"},"source":{"49e08439":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8bb1ebf0":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","f662f035":"pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\")","f956940c":"index = \"id\"\nlabel = \"target\"\nx = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/train.csv\", index_col=index)\ntest_csv = \"\/kaggle\/input\/tabular-playground-series-oct-2021\/test.csv\"\nx","2822ee04":"y = x.pop(label)","4802a1f7":"y","885885ec":"x.info()","89164e91":"x.describe()","d344f48c":"x.dtypes","943811f0":"x.isna().sum().sort_values(ascending=False)[:10]","9d3efcbb":"from sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV","4f5bf965":"from xgboost import XGBClassifier\nparams = {\n    'max_depth': 6,\n    'n_estimators': 17500,\n    'learning_rate': 0.021065232180933688,\n    'subsample': 0.9,\n    'colsample_bytree': 0.2,\n    'colsample_bylevel': 0.30000000000000004,\n    'min_child_weight': 292.65754478395786,\n    'reg_lambda': 6.287542520595498,\n    'reg_alpha': 142.19347996952186,\n    'gamma': 0.020280285370407516,\n    'booster': 'gbtree',\n    'eval_metric': 'auc',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'use_label_encoder': False\n}","10c09144":"thr_drop = VarianceThreshold(0.17)\nsc = StandardScaler()\nclf = RandomForestClassifier(n_jobs=-1)\npipe = make_pipeline(sc, thr_drop, clf)","f1c2d65b":"pipe.fit(x, y)","9a469f5f":"test_df = pd.read_csv(test_csv, index_col=index)\nypred = pipe.predict(test_df)","61757b80":"salama4ai_submission = pd.DataFrame({index: pd.read_csv(test_csv)[index], label: ypred})\nsalama4ai_submission.to_csv(\"submission.csv\", index=False)","b290663f":"##### so there is not any null values"}}