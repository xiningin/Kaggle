{"cell_type":{"2c1104cc":"code","dab7f1b3":"code","caa791c8":"code","9622f38e":"code","6976cb4f":"code","6b9225d7":"code","00e549a2":"code","abb65087":"code","2c28038c":"code","603d8ffe":"code","5cc9570d":"code","746390ae":"code","9c5e9c59":"code","d2114678":"code","2c3dcd8b":"code","00cda52c":"code","7cb2e04e":"code","30576c1c":"code","b34d86ef":"code","e74f8cbc":"code","ebf90fdf":"code","e477bfe3":"markdown"},"source":{"2c1104cc":"import pandas as pd\nimport numpy as np\nimport zipfile as zf\nfrom matplotlib import pyplot as plt","dab7f1b3":"train_archive = zf.ZipFile('\/kaggle\/input\/whats-cooking\/train.json.zip', 'r')\ntest_archive = zf.ZipFile('\/kaggle\/input\/whats-cooking\/test.json.zip', 'r')\n\ntrain_json = train_archive.read('train.json')\ntest_json = test_archive.read('test.json')\n\ntrain = pd.read_json(train_json)\ntest = pd.read_json(test_json)\n\ntrain_data = pd.DataFrame(train)\ntest_data = pd.DataFrame(test)\n\ntrain_data = train_data.explode('ingredients')\ntest_data = test_data.explode('ingredients')","caa791c8":"train_data","9622f38e":"train_data = train_data.loc[train_data['ingredients'].isin(test_data['ingredients'].values)]\ntest_data = test_data.loc[test_data['ingredients'].isin(train_data['ingredients'].values)]","6976cb4f":"#t = train_data.groupby(['ingredients','cuisine']).size().to_frame('count')\n#t = t.sort_values(by=['id']).where(t['id']==1).head(100)\n#t = t.reset_index()\n#t.pivot(index='ingredients', columns='cuisine', values='count')","6b9225d7":"train_data.insert(0,'bit_sign',1)","00e549a2":"train_data = pd.pivot_table(train_data, values='bit_sign', index=['id','cuisine'],\n                            columns=['ingredients']) #, aggfunc=np.sum)\n","abb65087":"train_data = train_data.reset_index()\ntrain_data = train_data.fillna(0)","2c28038c":"train_data","603d8ffe":"train_X = train_data.drop(['cuisine','id'], axis=1).values\ntrain_X","5cc9570d":"train_X.shape","746390ae":"train_data['cuisine'] = train_data['cuisine'].map(\n    { \n        'greek':0, \n        'southern_us':1, \n        'filipino':2, \n        'indian':3, \n        'jamaican':4,\n        'spanish':5, \n        'italian':6, \n        'mexican':7, \n        'chinese':8, \n        'british':9, \n        'thai':10,\n        'vietnamese':11, \n        'cajun_creole':12, \n        'brazilian':13, \n        'french':14, \n        'japanese':15,\n        'irish':16, \n        'korean':17, \n        'moroccan':18, \n        'russian':19\n    }\n)\n\ntrain_Y = train_data['cuisine'].values\ntrain_Y","9c5e9c59":"import tensorflow.keras as tf\n\nmodel = tf.models.Sequential()\n\n\nmodel.add(tf.layers.Dense(768, activation='relu'))\n#model.add(tf.layers.Dropout(0.5))\n\n#model.add(tf.layers.Dense(2048, activation='relu'))\n#model.add(tf.layers.Dropout(0.5))\n#model.add(tf.layers.Dense(256, activation='relu'))\n#model.add(tf.layers.Dense(512, activation='relu'))\n#model.add(tf.layers.Dropout(0.5))\n#model.add(tf.layers.Dense(1024, activation='relu'))\n\nmodel.add(tf.layers.Dense(256, activation='relu'))\n#model.add(tf.layers.BatchNormalization())\n#model.add(tf.layers.Dropout(0.5))\n\n\nmodel.add(tf.layers.Dense(20, activation='softmax'))\nmodel.compile(optimizer='adam'\n              ,loss='sparse_categorical_crossentropy'\n              ,metrics=['accuracy']\n             )\n\n#model.summary()\n\nres = model.fit(train_X, train_Y, epochs=10, validation_split=0.1)","d2114678":"test_data","2c3dcd8b":"test_data.insert(0,'bit_sign',1)","00cda52c":"test_data = pd.pivot_table(test_data, values='bit_sign', index=['id'],\n                            columns=['ingredients'])\n","7cb2e04e":"test_data = test_data.reset_index()\ntest_data = test_data.fillna(0)\ntest_data","30576c1c":"test_X = test_data.drop(['id'], axis=1).values\ntest_X.shape\ntest_X","b34d86ef":"prediction = np.argmax(model.predict(test_X), axis=1)","e74f8cbc":"prediction = prediction.reshape(9944,1)","ebf90fdf":"res_set = pd.DataFrame.from_records(prediction)\nres_set.insert(0,'id',test_data['id'])\nres_set.columns = ['id','cuisine']\n\n\nres_set['cuisine'] = res_set['cuisine'].map(\n    { \n        0:'greek', \n        1:'southern_us', \n        2:'filipino', \n        3:'indian', \n        4:'jamaican',\n        5:'spanish', \n        6:'italian', \n        7:'mexican', \n        8:'chinese', \n        9:'british', \n        10:'thai',\n        11:'vietnamese', \n        12:'cajun_creole', \n        13:'brazilian', \n        14:'french', \n        15:'japanese',\n        16:'irish', \n        17:'korean', \n        18:'moroccan', \n        19:'russian'\n    }\n)\n\n\n\n#res_set\nres_set.to_csv('submission.csv', index=False)","e477bfe3":"**Model**"}}