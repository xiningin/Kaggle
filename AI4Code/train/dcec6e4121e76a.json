{"cell_type":{"8356c86f":"code","c283f7dc":"code","cbe20d00":"code","9fba98a5":"code","a4198630":"code","cf0d1ae9":"code","aed9dcb4":"code","50d2ec69":"code","320bcae4":"code","aa56fc54":"code","74f1b034":"code","d23b0f4f":"code","887e6f73":"code","a4fe6ed8":"code","4da7022e":"code","9f53d404":"code","eecea8da":"code","ec383fc7":"code","bcb4a66d":"code","45e49a49":"code","eaf1d986":"markdown","f91d899d":"markdown","1db43e0c":"markdown","a0649dd1":"markdown","134dfbc7":"markdown","9cbffe6d":"markdown","c19dd36f":"markdown","203de5b3":"markdown","a2cd8ebc":"markdown","7254ea77":"markdown"},"source":{"8356c86f":"import time\nstart = time.time()\n\nimport numpy as np\nimport pandas as pd\n\nfrom fastai.vision import *\nfrom fastai.callbacks import *\n\nfrom pathlib import Path\n\nimport os\nimport shutil\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport PIL\n\nnp.random.seed(10)\n\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2","c283f7dc":"# Create Training and Test dataframe from input data \ndata_folder = Path(\"..\/input\")\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/sample_submission.csv\")","cbe20d00":"df1 = train_df[train_df.has_cactus==0].copy()\ndf2 = df1.copy()\ntrain_df = train_df.append([df1, df2], ignore_index=True)","9fba98a5":"sns.countplot('has_cactus', data=train_df)\nplt.title('Classes', fontsize=15)\nplt.show()","a4198630":"test_img = ImageList.from_df(test_df, path=data_folder\/'test', folder='test')\n\ntrfm = get_transforms(do_flip=True, flip_vert=True, max_rotate=10.0, max_zoom=1.1,\n                      max_lighting=0.2, max_warp=0.2, \n                      p_affine=0.75, p_lighting=0.75 ,xtra_tfms=[contrast(scale=(0.5, 1), p=0.75)])\n#trfm1 = get_transforms(do_flip=True, flip_vert=True)\nimagesize = 64\nbatchsize = 64\n### Created the function train data as I wanted to vary the image sizes while training and it will give some flexibility \n### in creating data \ndef train_data (imagesize,batchsize) : \n    train_img = (ImageList.from_df(train_df, path=data_folder\/'train', folder='train')\n        .split_by_rand_pct(0.2,seed =344) ##20% of the data is used as validation\n        .label_from_df()\n        .add_test(test_img)\n        .transform(trfm, size=imagesize)\n        .databunch(path='.', bs=batchsize, device= torch.device('cuda:0'))\n        .normalize(imagenet_stats)\n       )\n    return train_img","cf0d1ae9":"data = train_data(imagesize,batchsize)","aed9dcb4":"train_img1 = train_data(64,64)\n","50d2ec69":"train_img1.show_batch(rows=5, figsize=(10,10))\n","320bcae4":"nmodels = 3","aa56fc54":"def get_ensemble(nmodels):\n    ens_model = [] # Empty List of ensemble model, I will store the trained learner object here \n    learning_rate =[2.95e-02,3e-02,3e-02] # List of learning rate for each model \n    model_list = [models.densenet161,models.densenet161,models.densenet201] ##List of Models . You can add resnet ones in the mix\n    for i in range(nmodels):\n        print(f'-----Training model: {i+1}--------')\n             \n        data = train_data(64,64)\n        learn_resnet = cnn_learner(data, model_list[i], metrics=[error_rate, accuracy,AUROC()],\n                                   model_dir=\"\/tmp\/model\/\")\n\n        print('training for 128x128')\n        learn_resnet.set_data = train_data(128,64) # Train the model for imagesize 128\n        learn_resnet.lr_find()\n        learn_resnet.recorder.plot(suggestion=True)\n        learn_resnet.fit_one_cycle(3,slice(learning_rate[i])) # using the learning rate for the first model \n        \n        print('training for 150x150')\n        learn_resnet.set_data = train_data(150,96) #Train the model for imagesize 150\n        learn_resnet.fit_one_cycle(3,slice(learning_rate[i]))   # using the learning rate assigned for the first model   \n        \n        learn_resnet.save(f'ensem_model_{i}.weights')\n        ens_model.append(learn_resnet)\n        print(f'-----Training of model {i+1} complete----')\n    return ens_model","74f1b034":"ens = get_ensemble(3) # ens is a list type of object which will contain my three learnt model","d23b0f4f":"end = time.time()\nprint(end - start) ## This is to calculate training time to keep me sane.","887e6f73":"#Prepare test predictions\nens_test_preds = [] ## Creating a list of predictions \nfor mdl in ens:\n    preds,_ = mdl.TTA(ds_type=DatasetType.Test)\n    print(np.array(preds).shape)\n    ens_test_preds.append(np.array(preds)) ## create a list of prediction numpy arrays . ","a4fe6ed8":"ens_preds = np.mean(ens_test_preds, axis =0) ## Average the prediction from various numpy arrays using numpy mean function","4da7022e":"ens_preds.shape","9f53d404":"test_df.has_cactus = ens_preds[:, 0] ##update the prediction in the test data\ntest_df.head()\n","eecea8da":"test_df.to_csv('submission.csv', index=False)","ec383fc7":"interp = ClassificationInterpretation.from_learner(ens[0])\ninterp1 = ClassificationInterpretation.from_learner(ens[1])\ninterp2 = ClassificationInterpretation.from_learner(ens[2])\n","bcb4a66d":"interp.plot_confusion_matrix()\ninterp1.plot_confusion_matrix()\ninterp2.plot_confusion_matrix()","45e49a49":"interp.plot_top_losses(6, figsize=(10,10),heatmap = True)\ninterp1.plot_top_losses(6, figsize=(10,10),heatmap = False)\ninterp2.plot_top_losses(6, figsize=(10,10),heatmap = False)\n\n","eaf1d986":"## Model Prediction\nNow since the model is trained , we are going to call Test Time Augmentation function of Fastai to get a prediction of test dataset \n### What is Test Time Augmentation ?\nSimilar to what Data Augmentation is doing to the training set, the purpose of Test Time Augmentation is to perform random modifications to the test images. Thus, instead of showing the regular, \u201cclean\u201d images, only once to the trained model, we will show it the augmented images several times. We will then average the predictions of each corresponding image and take that as our final guess.","f91d899d":"Below are the comparison of data after the oversampling ","1db43e0c":"### Ensembling of fastai pretrained models. \n\nI have taken  major reference from the below blog which I felt is very informative . Some of the functions are probably not compatible with the version I have and hence direct adoption will not work . Also , I have not done freezing and unfreeing of layers in this version. As it was taking much time without great benefit.\nhttps:\/\/towardsdatascience.com\/kaggle-planet-competition-how-to-land-in-top-4-a679ff0013ba\nhttps:\/\/towardsdatascience.com\/ensembling-convnets-using-keras-237d429157eb\n\n## Ensembling :\n\nThere are many different types of ensembles;\ne.g \n1. Simple Averaging\n2. Bagging\n3. Boosting\n\n Stacking involves training a learning algorithm to combine the predictions of several other learning algorithms. For the sake of this example, I will use one of the simplest forms of Stacking, which involves taking an average of outputs of models in the ensemble. Since averaging doesn\u2019t take any parameters, there is no need to train this ensemble (only its models).\n ![image.png](attachment:image.png)\n \n \n ### Model1 = densenet161\n ### Model2 = densenet161\n ### Model3 = densenet201","a0649dd1":"## Data Exploration \n\nTaking reference from the Kernel \n\nhttps:\/\/www.kaggle.com\/benjaminwarner\/aerial-cactus-prediction-using-fast-ai-resnet-34\n\nHere we can understand that there is a class imbalance between cactus and non cactus images . Therefore copying the non-cactus data multiple time in the training dataset so that the dataset becomes almost equal between cactus and non-cactus records to create oversampling","134dfbc7":"# Aerial Cactus Identification\n\n> To assess the impact of climate change on Earth's flora and fauna, it is vital to quantify how human activities such as logging, mining, and agriculture are impacting our protected natural areas. Researchers in Mexico have created the VIGIA project, which aims to build a system for autonomous surveillance of protected areas. A first step in such an effort is the ability to recognize the vegetation inside the protected areas\n\nIn this competition,we need to create an algorithm that can identify a specific type of cactus (Columnar Cactus) in aerial imagery.\n\nWe have small size 32*32 images which is used to train a model and test against the validation and test data to accurately classify the cactus","9cbffe6d":"### Lets see how the training data sample looks like.","c19dd36f":"## Create Transformation and DataBunch\nUsing Fastai now we are creating transformation . Refer the optimum transformation paramters in the below Kernel .I have added only contrasts into the transformation\n\nhttps:\/\/www.kaggle.com\/kenseitrg\/simple-fastai-exercise\n\n","203de5b3":"## Initialize library\n> The fastai library simplifies training fast and accurate neural nets using modern best practices. It's based on research in to deep learning best practices undertaken at fast.ai, including \"out of the box\" support for vision, text, tabular, and collab (collaborative filtering) models\n\n Here we are going to use fastai vision library with various pretained model ensemble to classify the aerial cactus images into cactus and non-cactus","a2cd8ebc":"### Why it does , what it does\n\nWe can plot top losses from the learner and also keep the heatmap true to bring in a little explainability into the prediction as to where the convnet looked through the layer and how it predicted , what it predicted ","7254ea77":"## Confusion Matrix\nLet us create the confusion matrix using the out of the box functions . We are passing the individual trained models from the list to see how it fares\n\nA confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n\nThis is how a confusion matrix looks like .\n\n![image.png](attachment:image.png)\n\n#### Terms :\n\u2022 Positive (P) : Observation is positive (for example: is a cactus).\n\u2022 Negative (N) : Observation is not positive (for example: is not a cactus).\n\u2022 True Positive (TP) : Observation is positive, and is predicted to be positive.\n\u2022 False Negative (FN) : Observation is positive, but is predicted negative.\n\u2022 True Negative (TN) : Observation is negative, and is predicted to be negative.\n\u2022 False Positive (FP) : Observation is negative, but is predicted positive.\n"}}