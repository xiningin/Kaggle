{"cell_type":{"89d7b473":"code","f0f14c08":"code","ddffabfc":"code","7a6b96c1":"code","139fcdc5":"code","b1b53efa":"code","f09fa5c1":"code","f2dd7384":"code","2297ea73":"code","2574f35a":"code","6be92dd4":"code","37b1d5d0":"code","f27ebfa3":"code","4c6de2f2":"code","c51127af":"code","7e5c3635":"code","449498f5":"code","0962405a":"code","bc102cb5":"code","73f74f65":"code","2b5f42f9":"code","b119f131":"code","0ade0314":"code","4cd4da0d":"code","881eab16":"code","675697b2":"code","4f323e15":"code","4eee1fd7":"code","7fb047d3":"code","b91f442f":"code","afbf7b34":"code","6ff53f6e":"code","0dba208a":"code","bb2fd411":"code","34b09972":"code","2e9269d2":"code","db145702":"code","0a4b6faf":"code","b96b6e18":"code","1ffe0442":"code","a780a7d9":"code","233564f5":"code","bcbee2d1":"code","17e7c3ef":"code","f85f53ea":"code","c9d9d938":"code","fcacf07f":"code","145bc408":"code","da77693a":"code","00418c21":"markdown","5b21b99b":"markdown","65ae4567":"markdown","0f486bb9":"markdown","91352b8b":"markdown","b49e8885":"markdown","b19326cd":"markdown","809a5b4a":"markdown","e9003e12":"markdown","e539ab30":"markdown","2b6e322f":"markdown","30efc774":"markdown","b9c7b35a":"markdown","d02db111":"markdown","d2f7b003":"markdown","232511b1":"markdown","379abfc0":"markdown","c69dbe9e":"markdown","f973faa5":"markdown","c11967f6":"markdown","6655dfc3":"markdown","c29d94b2":"markdown","0472cd72":"markdown","134b1c86":"markdown","53b76d08":"markdown","a44e5eac":"markdown","cccffbb5":"markdown","9b4dd7db":"markdown","0001bf90":"markdown","12cc4649":"markdown","88145c34":"markdown","4ad98126":"markdown","185a970d":"markdown","72f69324":"markdown","5e7847eb":"markdown","09d4df2c":"markdown","e101c378":"markdown","47d5d836":"markdown","6dbd2363":"markdown","e5ffa99f":"markdown","0a591664":"markdown","c54aeb1a":"markdown","36b3db0d":"markdown","8735e71f":"markdown","685de164":"markdown","a8627db4":"markdown","d9b17670":"markdown","4b7989b6":"markdown","fc715fca":"markdown","6b22000f":"markdown","d31d49de":"markdown"},"source":{"89d7b473":"import pandas as pd\nimport numpy as np\nimport datetime, warnings, scipy\nimport matplotlib.pyplot as plt\nimport math\nimport category_encoders as ce\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\n\nwarnings.filterwarnings(\"ignore\")","f0f14c08":"airlines = pd.read_csv('..\/input\/airlines.csv')\nairports = pd.read_csv('..\/input\/airports.csv')\nflights = pd.read_csv('..\/input\/flights.csv')","ddffabfc":"# visualize airlines dataset\nairlines.head(10)","7a6b96c1":"len(airlines)\nprint('There are %d airlines in dataset' % len(airlines))","139fcdc5":"# info airlines dataset\nairlines.info()","b1b53efa":"# describe airlines dataset\nairlines.describe()","f09fa5c1":"# visualize airports dataset\nairports.head()","f2dd7384":"len(airports)\nprint('There are %d airports in dataset' % len(airports))","2297ea73":"# info airports dataset\nairports.info()","2574f35a":"# describe airports dataset\nairports.describe()","6be92dd4":"# visualize flights dataset\nflights.head()","37b1d5d0":"flights.tail()","f27ebfa3":"len(flights)\nprint('There are %d flights in dataset' % len(flights))","4c6de2f2":"# info flights dataset\nflights.info()","c51127af":"# describe flights dataset\nflights.describe()","7e5c3635":"# lower case to columns headers\n\nairlines.columns = airlines.columns.str.lower()\nairports.columns = airports.columns.str.lower()\nflights.columns = flights.columns.str.lower()","449498f5":"flights.isna().sum()","0962405a":"# drop column big amount NA values\nflights = flights[flights.columns.difference(['cancellation_reason', 'air_system_delay', 'security_delay',\n                                              'airline_delay', 'late_aircraft_delay', 'weather_delay'])]","bc102cb5":"# drop NA values\nflights = flights.dropna()","73f74f65":"len(flights)\nprint('There are %d flights in dataset' % len(flights))","2b5f42f9":"# just keep important columns\n# order columns\nflights = flights[['month', 'day_of_week', 'airline', 'origin_airport', 'destination_airport',\n                   'scheduled_departure', 'departure_delay', 'scheduled_arrival', 'arrival_delay',\n                   'scheduled_time', 'elapsed_time', 'distance']]","b119f131":"# new columns time_delay to check on air time delay\nflights['time_delay'] = flights.elapsed_time - flights.scheduled_time","0ade0314":"# correlation matrix\nsns.heatmap(flights.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","4cd4da0d":"# day of week amount of flights\nplt.hist(flights['day_of_week'],bins=[1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5])\nplt.title(\"Histogram Days Of Week\")\nplt.xlim()\nplt.show()","881eab16":"# distance distribution\nplt.hist(flights['distance'], bins='auto')\nplt.title(\"Histogram distance\")\nplt.xlim((50, 2000))\nplt.show()","675697b2":"# most crowded origin airports ranking\nairport_origin_weight = flights.groupby(['origin_airport']).month.count().sort_values(ascending = False)\nairport_origin_weight.head(10)","4f323e15":"# market shere total flights per airline\nairline_weight = flights.groupby(['airline']).month.count().sort_values(ascending = False)\/len(flights)\nairline_weight","4eee1fd7":"# market share \"padding time\" flights per airline\ndf_filter = flights[(flights['departure_delay'] >= 1 ) & (flights['arrival_delay'] <=3 ) \n        & (flights['arrival_delay'] >=-3 ) & (flights['time_delay'] <=-1 )]\nairline_weight_filter = df_filter.groupby(['airline']).month.count().sort_values(ascending = False)\/len(df_filter)\nairline_weight_filter","7fb047d3":"# rate of padding times per airlines\nairline_weight = pd.DataFrame(airline_weight)\nairline_weight_filter = pd.DataFrame(airline_weight_filter)\ndf_padding = pd.merge(airline_weight,airline_weight_filter,on='airline', how='left')\ndf_padding['rate'] = df_padding.month_y\/df_padding.month_x\ndf_padding.rate.sort_values(ascending = False)","b91f442f":"# check unnamed airports\nflights.origin_airport.unique()","afbf7b34":"# drop unnamed airports rows. from 4250000th row airport is unnamed\nflights = flights[0:4250000]","6ff53f6e":"# create new dataset flights2. not necessary\nflights2 = flights[:]","0dba208a":"# hour truncated\nflights2['scheduled_departure_hour'] = flights2.scheduled_departure\nflights2['scheduled_arrival_hour'] = flights2.scheduled_arrival\nflights2['scheduled_departure_hour'] = flights2.scheduled_departure\/100\nflights2['scheduled_arrival_hour'] = flights2.scheduled_arrival\/100\nflights2['scheduled_departure_hour'] = np.fix(flights2.scheduled_departure_hour)\nflights2['scheduled_arrival_hour'] = np.fix(flights2.scheduled_arrival_hour)","bb2fd411":"# days_of_week rename values\nflights2.day_of_week = flights2.day_of_week.replace([1, 2, 3, 4, 5, 6, 7], ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday'])\nflights2.day_of_week.unique()","34b09972":"# create dummy variable for days_of_week\ndummy = pd.get_dummies(flights2.day_of_week)\nflights2 = pd.concat([flights2, dummy], axis=1)\n","2e9269d2":"# month rename values\nflights2.month = flights2.month.replace([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n                                      ['january', 'february', 'march', 'april', 'may', 'june', \n                                       'july', 'august', 'september', 'october', 'november', 'december'])\nflights2.month.unique()","db145702":"# create dummy variable for months\ndummy = pd.get_dummies(flights2.month)\nflights2 = pd.concat([flights2, dummy], axis=1)","0a4b6faf":"# binary encoding to airlines column\nflights2['airline2'] = flights2.airline\nencoder_airlines = ce.BinaryEncoder(cols=['airline'])\nencoder_airlines.fit(flights2)\nflights2 = encoder_airlines.transform(flights2)","b96b6e18":"# binary encoding to origin_airport column\nflights2['origin_airport2'] = flights2.origin_airport\nencoder_origin_airport = ce.BinaryEncoder(cols=['origin_airport'])\nflights2 = encoder_origin_airport.fit_transform(flights2)","1ffe0442":"# binary encoding to destination_airport column\nflights2['destination_airport2'] = flights2.destination_airport\nencoder_destination_airport = ce.BinaryEncoder(cols=['destination_airport'])\nflights2 = encoder_destination_airport.fit_transform(flights2)","a780a7d9":"# binary encoding to scheduled_departure_hour column\nflights2['scheduled_departure_hour2'] = flights2.scheduled_departure_hour\nencoder_scheduled_departure_hour = ce.BinaryEncoder(cols=['scheduled_departure_hour'])\nflights2 = encoder_scheduled_departure_hour.fit_transform(flights2)","233564f5":"# binary encoding to scheduled_arrival_hour column\nflights2['scheduled_arrival_hour2'] = flights2.scheduled_arrival_hour\nencoder_scheduled_arrival_hour = ce.BinaryEncoder(cols=['scheduled_arrival_hour'])\nflights2 = encoder_scheduled_arrival_hour.fit_transform(flights2)","bcbee2d1":"flights3 = flights2[flights2.columns.difference(['month', 'day_of_week', 'scheduled_departure', \n                                                'scheduled_arrival', 'elapsed_time', 'time_delay', 'airline2',\n                                                'origin_airport2', 'destination_airport2', 'scheduled_departure_hour2',\n                                                'scheduled_arrival_hour2', 'departure_delay'])] # departure_delay\n# drop arrival_delay outliers\nflights3 = flights3[flights3['arrival_delay']<500]","17e7c3ef":"def rmse(y, y_pred):\n    return np.sqrt(np.mean(np.square(y - y_pred)))","f85f53ea":"rmse_baseline = rmse(flights3.arrival_delay,0)\nprint('The RSME BaseLine is',rmse_baseline)","c9d9d938":"# standar normalize arrival_delay, distance, schedule_time and departure_delay\n\nstd_arrival_delay = flights3.arrival_delay.std()\nmean_arrival_delay = flights3.arrival_delay.mean()\n\nflights3.arrival_delay=(flights3.arrival_delay-flights3.arrival_delay.mean())\/flights3.arrival_delay.std()\nflights3.distance=(flights3.distance-flights3.distance.mean())\/flights3.distance.std()\nflights3.scheduled_time=(flights3.scheduled_time-flights3.scheduled_time.mean())\/flights3.scheduled_time.std()\n#flights3.departure_delay=(flights3.departure_delay-flights3.departure_delay.mean())\/flights3.departure_delay.std()","fcacf07f":"# split 30% testing 70% training dataset\ntrain,test=train_test_split(flights3,test_size=0.3,random_state=0)\ntrain_X=train[train.columns.difference(['arrival_delay'])]\ntrain_Y=train['arrival_delay']\ntest_X=test[test.columns.difference(['arrival_delay'])]\ntest_Y=test['arrival_delay']","145bc408":"#from sklearn.model_selection import KFold #for K-fold cross validation\n#from sklearn.model_selection import cross_val_score #score evaluation\n#from sklearn.model_selection import cross_val_predict #prediction\n#from sklearn.tree import DecisionTreeRegressor\n#from sklearn.linear_model import LinearRegression\n\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\nxyz=[]\naccuracy=[] # el % de aciertos en la matriz de confusion\nstd=[]\nclassifiers=['DecisionTree', 'LinearRegression']\nmodels=[DecisionTreeRegressor(), LinearRegression()] # Decision Tree Model\nfor i in models:\n    model = i\n    cv_result = cross_val_score(model,train_X,train_Y, cv = kfold,scoring = \"neg_mean_squared_error\")\n    cv_result=cv_result\n    xyz.append(cv_result.mean())\n    std.append(cv_result.std())\n    accuracy.append(cv_result)\nnew_models_dataframe2=pd.DataFrame({'CV Mean':xyz,'Std':std},index=classifiers)       \nnew_models_dataframe2","da77693a":"final_model=LinearRegression()\nfinal_model.fit(train_X,train_Y) #con la data train_X predice el valor de train_Y\nprediction=final_model.predict(test_X)\nrsme_denormalize = rmse(prediction*std_arrival_delay+mean_arrival_delay,\n                        test_Y*std_arrival_delay+mean_arrival_delay)\nprint('The RSME of the Linear Regression is',rsme_denormalize)","00418c21":"Correlation matrix show relation between variables. Target correlate variables cannot be use for prediction because there are unknown at the moment of prediction.","5b21b99b":"This is the ranking of 'padding time' flights. We can see that Southwest Airlines Co.(WN) and United Air Lines Inc.(UA) are the airlines that encourage most the 'padding time'. For example, WN get 50% more of market share in 'padding time' flights than in total flights.","65ae4567":"# Visualization","0f486bb9":"Drop certian columns to avoid NA values.","91352b8b":"There are some attributes that have many categories so we should not convert to dummies, but must be numerical. The process to get numerical values without converting to dummies is binarizing. Like computers work =)","b49e8885":"Ranking of the most crowded airports. Atlanta, Chicago and Dallas are the podium.","b19326cd":"# Cross Validation","809a5b4a":"# Baseline","e9003e12":"# Import Datasets","e539ab30":"Drop certian columns that are not useful to the model.","2b6e322f":"Many NA values in certian columns. Could be a problem if we keep these lines.","30efc774":"# Padding Time","b9c7b35a":"In airports dataset there are geolocate information that might be usefull in future analysis.","d02db111":"# Previsualization","d2f7b003":"Make a train test splir datastet to avoid overfitting process. Test dataset will be 30% of the total data. Train dataset will be 70% of the total data.","232511b1":"We create the variable to visualize, but will not be usefull for prediction.","379abfc0":"The results are not the best. The RMSE is very high and its almost the same as airlines preditcions. Adding some weather information woulb be usefull to improve the prediction. ","c69dbe9e":"# Create New Columns","f973faa5":"Short distatance flights are more frecuent than long distance flights.","c11967f6":"checking latitude and longitude, we can check the map location using Tableau Software using the following link.\n\nhttps:\/\/public.tableau.com\/profile\/federico.garcia.blanco#!\/vizhome\/AirportsLocation\/Sheet1?publish=yes","6655dfc3":"Dummy variables to make easier the prediction models.","c29d94b2":"We can see that Saturday is the less crowded day to travel by flight. Job flights would be the reason of this kind of distribution.","0472cd72":"# Train Test Split","134b1c86":"# Normalize Variables","53b76d08":"Use lower case to make easier the code from scratch. Will be usefull for future.","a44e5eac":"# Create Dummies Variables","cccffbb5":"# Apply Model","9b4dd7db":"Applying model to predict the class","0001bf90":"There are some airports that are unnamed. Should be drop of dataset.","12cc4649":"Truncate hours to make easier the analysis. Taking just the entire hour.","88145c34":"This is the market share of 'padding time' flights.","4ad98126":"Not NA values in airlines dataset","185a970d":"# Drop Unnamed Airports Info ","72f69324":"The process of normalizing variables is needed to compare variables.","5e7847eb":"# Code Hours Time","09d4df2c":"Not many airlines in dataset. There are just airlines flying inside the country.","e101c378":"# Create Binary Encoding Categories","47d5d836":"Cross Validation process is usefull to avoid overfitting too. If there are an overfitting process, the algorithm will learn very well to predict the class. The algorithm must be useful working with new data, thats why avoiding overfitting is so important","6dbd2363":"This is the market share ranking of total flights.","e5ffa99f":"There are some columns that cannot be use for prediction model beacuase there is unknown information at the moment of prediction. Thats why we drop the columns.","0a591664":"# NA Values","c54aeb1a":"If you are running the code on your computer, must check before path direction to import datasets. In Kaggle kernels datasets are imported as done above.","36b3db0d":"Define the metric error. Being a continuos variable problem, RMSE is a good method.","8735e71f":"There are just 3 airports with NA values in latitude and longitude.","685de164":"This is the baseline. Any model we can create, must be better than airlines model. The new model must get a lower RMSE.","a8627db4":"# Drop Certian Columns","d9b17670":"# Error Metrics RMSE","4b7989b6":"# Exclude Certian Columns","fc715fca":"> # Import Libraries","6b22000f":"After dropping certian columns, we drop lines with NA values. There are a few lines, not representative.","d31d49de":"Import different libraries to avoid futures errors. 'filterwarnings' is used to avoid warnings messages."}}