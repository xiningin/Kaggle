{"cell_type":{"a6fd3d44":"code","aa923dfd":"code","fccc1385":"code","261c1e80":"code","abc13bd2":"code","7484ed67":"code","87284599":"code","6ac6cca1":"code","f9068084":"code","fa4818aa":"code","9b8edff4":"code","2ff2683e":"code","ad641021":"code","5d3e3469":"code","23b6ae66":"code","36f85ac4":"code","4018399f":"code","993dd56d":"code","c8972286":"code","9c42282c":"code","3c103b2c":"code","85e1fb7a":"code","7e8d6122":"code","fae66517":"code","3f1fef6f":"code","e28318fd":"code","3fd28256":"code","bfef6dea":"code","33dbfba4":"code","afd01384":"code","5bce113b":"code","82298f9a":"code","10e71412":"code","b2fc865a":"code","3dc74bab":"code","1f2dc0b1":"code","f1210e58":"code","c2768a73":"code","d0f96e33":"code","d7ee0a02":"code","e1d4855d":"code","480cb91c":"code","ac1d1d5e":"code","623d3d2d":"code","3cc68744":"code","db39a9e6":"code","70a5c3ed":"code","3abf538e":"code","4ca10eff":"code","e1ec4946":"code","91f1eb5a":"code","a1822e9d":"code","1c2ce21f":"code","9061e9b1":"code","1b1dd23c":"code","a514e53f":"code","8bc9af1f":"code","ef0819a3":"code","04490c7a":"code","081571dd":"code","0b169e47":"code","13ddbec4":"code","fc535f40":"code","bf327c66":"markdown","75a64b4f":"markdown","502ce700":"markdown","3a6aeb42":"markdown","9a8936f2":"markdown","adf5a697":"markdown","44b9726f":"markdown","a2145704":"markdown","7382e827":"markdown","2242256d":"markdown","5c16068c":"markdown","9c9302ca":"markdown","925d2e04":"markdown","208555e0":"markdown","7964d5fc":"markdown","55ae5d4f":"markdown","3607fde8":"markdown","1d2bc7df":"markdown","e7a25213":"markdown","93198b78":"markdown","fa9282f6":"markdown","a20caedc":"markdown","ee7fba04":"markdown","3a186c77":"markdown","0c7dccab":"markdown","79ba76b6":"markdown","a1002bd5":"markdown","16f61fee":"markdown","7f5a739d":"markdown","0b0f9499":"markdown","be24def0":"markdown","cd52ed9a":"markdown","51b3bcd9":"markdown","7c5c26c2":"markdown","742d7735":"markdown","96f383b7":"markdown","7b4a0303":"markdown","e629f60b":"markdown","4546eb23":"markdown","baa576ba":"markdown","225b9e76":"markdown","e335ef0e":"markdown","6e19c01a":"markdown","21aefd6d":"markdown","b856781b":"markdown","e9a66ca4":"markdown"},"source":{"a6fd3d44":"import numpy as np\nimport math\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aa923dfd":"df = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","fccc1385":"print('Dataframe shape:', df.shape)","261c1e80":"df.info()","abc13bd2":"df.head()","7484ed67":"def null_percentage(data):\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','Percent Missing'])\n\nprint('''Null values:\\n\n{}'''.format(null_percentage(df)))","87284599":"cols = df.columns\ncolours = ['#000099', '#ffff00']\nsns.heatmap(df[cols].isnull(), cmap=sns.color_palette(colours))","6ac6cca1":"df.drop(columns=['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am', 'RISK_MM'], axis=1, inplace=True)","f9068084":"numerical_cols = [var for var in df.columns if df[var].dtype=='f8']\ncategorical_cols = [var for var in df.columns if df[var].dtype=='O']","fa4818aa":"print('Numerical Columns: \\n{}\\n'.format(numerical_cols))\nprint('Categorical Columns: \\n{}\\n'.format(categorical_cols))","9b8edff4":"df.describe()","2ff2683e":"for var in categorical_cols:\n    print(var, ' has {} unique values'.format(len(df[var].unique())))","ad641021":"df['Date'] = pd.to_datetime(df['Date'])\n\n# Extracting Year, Month and Day from Date Column\ndf['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.month\ndf['Day'] = df['Date'].dt.day\n\n# Dropping original Date column\ndf.drop('Date', inplace=True, axis=1)","5d3e3469":"# Reviewing date changes\ndf.head()","23b6ae66":"categorical_cols = [var for var in df.columns if df[var].dtype=='O']\n\ncategorical_nulls = df[categorical_cols].isnull().sum()\n\nfor var in categorical_cols:\n    print(var, ' has: \\n{} unique values\\n {} null values\\n'.format(len(df[var].unique()), categorical_nulls[var]))","36f85ac4":"def location_percentage(data):\n    total = df['Location'].value_counts()\n    percent = round(df['Location'].value_counts()\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','%'])\n\nprint('''Location Values:\n{}'''.format(location_percentage(df)))","4018399f":"# Location dummies\nlocation_dummies = pd.get_dummies(df.Location, drop_first=True).head()\nlocation_dummies.head()","993dd56d":"def WindGustDir_percentage(data):\n    total = df['WindGustDir'].value_counts()\n    percent = round(df['WindGustDir'].value_counts()\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','%'])\n\nWindGustDir_null = df['WindGustDir'].isnull().sum() \/ len(df['WindGustDir'])\n\nprint('''WindGustDir Values:\n{}\nNull percentage = {}%'''.format(WindGustDir_percentage(df), round(WindGustDir_null * 100, 2)))","c8972286":"# WidGustDir Dummies\nWindGustDir_dummies = pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True)\nWindGustDir_dummies.head()","9c42282c":"def WindDir9am_percentage(data):\n    total = df['WindDir9am'].value_counts()\n    percent = round(df['WindDir9am'].value_counts()\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','%'])\n\nWindDir9am_null = df['WindDir9am'].isnull().sum() \/ len(df['WindDir9am'])\n\nprint('''WindDir9am Values:\n{}\nNull percentage = {}%'''.format(WindDir9am_percentage(df), round(WindDir9am_null * 100, 2)))","3c103b2c":"# WindDir9am Dummies\nWindDir9am_dummies = pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True)\nWindDir9am_dummies.head()","85e1fb7a":"def WindDir3pm_percentage(data):\n    total = df['WindDir3pm'].value_counts()\n    percent = round(df['WindDir3pm'].value_counts()\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','%'])\n\nWindDir3pm_null = df['WindDir3pm'].isnull().sum() \/ len(df['WindDir3pm'])\n\nprint('''WindDir3pm Values:\n{}\nNull percentage = {}%'''.format(WindDir3pm_percentage(df), round(WindDir3pm_null * 100, 2)))","7e8d6122":"# WindDir3pm Dummies\nWindDir3pm_dummies = pd.get_dummies(df.WindDir3pm, drop_first=True, dummy_na=True)\nWindDir3pm_dummies.head()","fae66517":"def RainToday_percentage(data):\n    total = df['RainToday'].value_counts()\n    percent = round(df['RainToday'].value_counts()\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','%'])\n\nRainToday_null = df['RainToday'].isnull().sum() \/ len(df['RainToday'])\n\nprint('''RainToday Values:\n{}\nNull percentage = {}%'''.format(RainToday_percentage(df), round(RainToday_null * 100, 2)))","3f1fef6f":"# RainToday Dummies\nRainToday_dummies = pd.get_dummies(df.RainToday, drop_first=True, dummy_na=True)\nRainToday_dummies.head()","e28318fd":"# Exploring 'RainTomorrow' values (labels)\ndef rain_tomorrow_percentage(data):\n    total = df['RainTomorrow'].value_counts()\n    percent = round(df['RainTomorrow'].value_counts()\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','%'])\n\nprint('''RainTomorrow Values:\n{}'''.format(rain_tomorrow_percentage(df)))","3fd28256":"f, ax2 = plt.subplots(figsize=(5, 5))\nax2 = sns.countplot(x=\"RainTomorrow\", data=df, palette='Blues')\nplt.show()","bfef6dea":"df[numerical_cols].head()","33dbfba4":"round(df[numerical_cols].describe(), 2)","afd01384":"# As we can see from the difference in 75% percentile and max values, it is likely we have outliers in:\n# 'Rainfall', 'WindSpeed9am' and 'WindSpeed3pm'\n\n# Plotting suspected outliers\nplt.figure(figsize=(15,10))\n\nplt.subplot(3, 1, 2)\nfig = sns.boxplot(x='Rainfall', data=df)\nfig.set_title('')\n\nplt.subplot(3, 2, 2)\nfig = sns.boxplot(x='WindSpeed9am', data=df)\nfig.set_title('')\n\nplt.subplot(3, 2, 1)\nfig = sns.boxplot(x='WindSpeed3pm', data=df)\nfig.set_title('')","5bce113b":"# Plotting Histograms to check skew\n\nplt.figure(figsize=(15,10))\n\nplt.subplot(3, 1, 2)\nfig = df['Rainfall'].hist(bins=20)\nfig.set_xlabel('Rainfall')\n\nplt.subplot(3, 2, 2)\nfig = df['WindSpeed9am'].hist(bins=20)\nfig.set_xlabel('WindSpeed9am')\n\nplt.subplot(3, 2, 1)\nfig = df['WindSpeed3pm'].hist(bins=20)\nfig.set_xlabel('WindSpeed3pm')","82298f9a":"#IQR for Rainfall\nQ1 = df['Rainfall'].quantile(0.25)\nQ3 = df['Rainfall'].quantile(0.75)\nIQR = Q3 - Q1\nLower_bound = Q1 - (IQR * 1.5)\nUpper_bound = Q3 + (IQR * 1.5)\nprint('Rainfall has outliers: < {} or > {}'.format(Lower_bound, Upper_bound))","10e71412":"# Removing Rainfall outliers\ndf = df[~((df['Rainfall'] < - 1.20) |(df['Rainfall'] > 2.0))]\nprint(df.shape)","b2fc865a":"#IQR for WindSpeed9am\nQ1 = df['WindSpeed9am'].quantile(0.25)\nQ3 = df['WindSpeed9am'].quantile(0.75)\nIQR = Q3 - Q1\nLower_bound = Q1 - (IQR * 1.5)\nUpper_bound = Q3 + (IQR * 1.5)\nprint('WindSpeed9am has outliers: < {} or > {}'.format(Lower_bound, Upper_bound))","3dc74bab":"# Removing WindSpeed9am outliers\ndf = df[~((df['WindSpeed9am'] < - 11.0) |(df['WindSpeed9am'] > 37.0))]\nprint(df.shape)","1f2dc0b1":"#IQR for WindSpeed3pm\nQ1 = df['WindSpeed3pm'].quantile(0.25)\nQ3 = df['WindSpeed3pm'].quantile(0.75)\nIQR = Q3 - Q1\nLower_bound = Q1 - (IQR * 1.5)\nUpper_bound = Q3 + (IQR * 1.5)\nprint('WindSpeed3pm has outliers: < {} or > {}'.format(Lower_bound, Upper_bound))","f1210e58":"# Removing WindSpeed3pm outliers\ndf = df[~((df['WindSpeed3pm'] < - 3.5) |(df['WindSpeed3pm'] > 40.5))]\nprint(df.shape)","c2768a73":"# Reviewing Histograms after outlier removal\nplt.figure(figsize=(15,10))\n\nplt.subplot(3, 1, 2)\nfig = df['Rainfall'].hist(bins=20)\nfig.set_xlabel('Rainfall')\n\nplt.subplot(3, 2, 2)\nfig = df['WindSpeed9am'].hist(bins=20)\nfig.set_xlabel('WindSpeed9am')\n\nplt.subplot(3, 2, 1)\nfig = df['WindSpeed3pm'].hist(bins=20)\nfig.set_xlabel('WindSpeed3pm')","d0f96e33":"# Viewing number of nulls \npd.DataFrame(df[numerical_cols].isnull().sum().sort_values(ascending=False)).head(12)","d7ee0a02":"# Filling null numericals with mean\nfor col in numerical_cols:\n    mean = df[col].mean()\n    df[col].fillna(mean, inplace=True)  ","e1d4855d":"corr_matrix = df.corr()\n\nplt.figure(figsize=(16,12))\nplt.title('Correlation Heatmap of Rain in Australia Dataset')\nax = sns.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='white')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nax.set_yticklabels(ax.get_yticklabels(), rotation=30)           \nplt.show()","480cb91c":"categorical_cols","ac1d1d5e":"df = pd.concat([df, pd.get_dummies(df['Location'],dummy_na=True, prefix='Location', columns=categorical_cols)],axis=1).drop(['Location'],axis=1)\ndf = pd.concat([df, pd.get_dummies(df['WindGustDir'],dummy_na=True, prefix='WindGustDir', columns=categorical_cols)],axis=1).drop(['WindGustDir'],axis=1)\ndf = pd.concat([df, pd.get_dummies(df['WindDir9am'],dummy_na=True, prefix='WindDir9am', columns=categorical_cols)],axis=1).drop(['WindDir9am'],axis=1)\ndf = pd.concat([df, pd.get_dummies(df['WindDir3pm'],dummy_na=True, prefix='WindDir3pm', columns=categorical_cols)],axis=1).drop(['WindDir3pm'],axis=1)\ndf = pd.concat([df, pd.get_dummies(df['RainToday'],dummy_na=True, prefix='RainToday', columns=categorical_cols)],axis=1).drop(['RainToday'],axis=1)\n","623d3d2d":"df.head()","3cc68744":"X = df.drop('RainTomorrow', axis=1)\ny = df['RainTomorrow']\n\nprint('''X Shape: {}\ny Shape: {}'''.format(X.shape, pd.DataFrame(y).shape))","db39a9e6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n# Checking shapes of each set\nprint('''X train: {}\nX test: {}\ny train: {}\ny test: {}'''.format(X_train.shape, X_test.shape, pd.DataFrame(y_train).shape, pd.DataFrame(y_test).shape))","70a5c3ed":"scaler = StandardScaler()\ncols = pd.DataFrame(X_train).columns\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns= cols)\nX_test = pd.DataFrame(scaler.transform(X_test), columns=cols)","3abf538e":"# Viewing scaled training set\nX_train.head()","4ca10eff":"# Viewing scaled test set\nX_test.head()","e1ec4946":"from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nrandom_state = 42","91f1eb5a":"log_reg = LogisticRegression(random_state=random_state)\nlog_reg.fit(X_train, y_train)\n\nlog_reg_pred = log_reg.predict(X_test)\n\nlog_reg_cm = confusion_matrix(y_test, log_reg_pred)\n\nprint('Model accuracy score:\\n{}\\nConfusion Matrix:\\n{}'. format(round(accuracy_score(y_test, log_reg_pred), 4), log_reg_cm))","a1822e9d":"# Checking for over\/under fitting\nprint('Training set score: \\n{}\\nTest set score: \\n{}'.format(round(log_reg.score(X_train, y_train), 4), round(log_reg.score(X_test, y_test), 4)))","1c2ce21f":"param_grid = {'C' : [1, 25, 50, 75, 100]}\n\nlog_reg_2 = LogisticRegression(random_state=random_state, solver='lbfgs')\n\ngrid_search_log = GridSearchCV(log_reg_2, param_grid, scoring=\"roc_auc\", cv=5)\n\ngrid_search_log.fit(X_train, y_train)","9061e9b1":"print('Best Parameters:\\n{}'.format(grid_search_log.best_params_))","1b1dd23c":"# Using our best parameters\nlog_reg_3 = LogisticRegression(random_state=random_state, C=50)\nlog_reg_3.fit(X_train, y_train)\n\nlog_reg_3_pred = log_reg_3.predict(X_test)\n\nlog_reg_3_cm = confusion_matrix(y_test, log_reg_3_pred)\n\nprint('Model accuracy score:\\n{}\\nConfusion Matrix:\\n{}'. format(round(accuracy_score(y_test, log_reg_3_pred), 4), log_reg_3_cm))","a514e53f":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)","8bc9af1f":"xgb_pred = xgb.predict(X_test)\n\nxgb_cm = confusion_matrix(y_test, xgb_pred)\n\nprint('Model accuracy score:\\n{}\\nConfusion Matrix:\\n{}'. format(round(accuracy_score(y_test, xgb_pred), 4), xgb_cm))","ef0819a3":"# Checking for over\/under fitting\nprint('Training set score: \\n{}\\nTest set score: \\n{}'.format(round(xgb.score(X_train, y_train), 4), round(xgb.score(X_test, y_test), 4)))","04490c7a":"param_grid = {\n     'eta'    : [0.01, 0.15, 0.30 ] ,\n     'max_depth'        : [ 3, 6, 9],\n     'min_child_weight' : [ 1, 3, 5],\n     'gamma'            : [ 0.0, 0.2, 0.4 ]\n     }\n\nxgb_2 = XGBClassifier(random_state=random_state)\n\ngrid_search = GridSearchCV(xgb_2, param_grid, n_jobs=4, scoring=\"roc_auc\", cv=5)\n\ngrid_search.fit(X_train, y_train)","081571dd":"print('Best Parameters:\\n{}'.format(grid_search.best_params_))","0b169e47":"# Using our best parameters\nxgb_3 = XGBClassifier(eta=0.01, gamma=0.4, max_depth=9, min_child_weight=3)\nxgb_3.fit(X_train, y_train)\n\nxgb_3_pred = xgb_3.predict(X_test)\n\nxgb_3_cm = confusion_matrix(y_test, xgb_3_pred)\n\nprint('Model accuracy score:\\n{}\\nConfusion Matrix:\\n{}'. format(round(accuracy_score(y_test, xgb_3_pred), 4), xgb_3_cm))","13ddbec4":"#\u00a0Accuracy scores of each model\nlog_reg_acc = round(accuracy_score(y_test, log_reg_pred), 4)\nlog_reg_3_acc = round(accuracy_score(y_test, log_reg_3_pred), 4)\nxgb_acc = round(accuracy_score(y_test, xgb_pred), 4)\nxgb_3_acc = round(accuracy_score(y_test, xgb_3_pred), 4)","fc535f40":"# Creating dataframe showing accuracy scores of each model\ncompare = {'Model': ['Logistic Regression Original', 'Logistic Regression Tuned', 'XGBoost Original', 'XGBoost Tuned'],\n          'Accuracy score': [log_reg_acc, log_reg_3_acc, xgb_acc, xgb_3_acc]}\n\npd.DataFrame(data=compare)\n ","bf327c66":"#### Viewing data with dummies","75a64b4f":"#### Using grid-search to find better parameters for Logistic Regression","502ce700":"#### Viewing statistical properties of numericals","3a6aeb42":"#### Location variable\n* 49 unique values\n* 0 null values","9a8936f2":"## 3. Data cleaning <a id=\"3\"><\/a>","adf5a697":"#### WindDir3pm variable\n* 17 unique values\n* 3778 null values","44b9726f":"#### WindDir9am variable\n* 17 unique values\n* 10013 null values","a2145704":"#### Splitting data into X and y variables","7382e827":"#### Taking care of nulls","2242256d":"### 6.2 XGBoost<a id=\"6.2\"><\/a>","5c16068c":"#### RainToday variable\n* 3 unique values\n* 1406 null values","9c9302ca":"### 3.2. Handling Categoricals<a id=\"3.2\"><\/a>","925d2e04":"# Will it rain tomorrow? ","208555e0":"<a id=\"0\"><\/a>\n![Rains](https:\/\/media.giphy.com\/media\/xUPGcCYOXmcQqhVQli\/giphy.gif)","7964d5fc":"#### Previewing first 5 rows of data","55ae5d4f":"#### Using grid-search to find better parameters for XGBoost","3607fde8":"[Back to top](#0)","1d2bc7df":"#### Visualising missing data","e7a25213":"## Contents\n1. [ Importing Libraries and Data](#1)\n1. [ Exploratory Data Analysis](#2)\n1. [ Data Cleaning](#3)\n    - [ Handling Numericals](#3.1)\n    - [ Handling Categoricals](#3.2)\n1. [ Splitting data](#4)\n1. [ Feature Scaling](#5)\n1. [ Model Training](#6)\n    - [ Logistic Regression](#6.1)\n    - [ XGBoost](#6.2)\n1. [ Comparing Models](#7)\n1. [ Conclusion](#8)","93198b78":"#### Handling of Date column","fa9282f6":"#### Viewing shape of the data set","a20caedc":"As we can see from the comparison table, our best model is the XGBoost model in which we used our best parameters from grid search. This model gives us a high accuracy of 87.85%. From these results we can conclude that we have a reliable model for predicting future rainy days given we know todays data.","ee7fba04":"* ##### As we can see from the boxplots, all suspected variables contain outliers","3a186c77":"#### Viewing information (Variable data types and counts)","0c7dccab":"- This dataset contains daily weather observations from numerous Australian weather stations.\n\n- Classification problem: Did it rain the next day? Yes (1) or No (0).\n\n- For this problem I will be using **Logistic Regression** and **XGBoost**","79ba76b6":"## 1. Importing Libraries and Data <a id=\"1\"><\/a>","a1002bd5":"#### WindGustDir variable\n* 17 unique values\n* 9330 null values","16f61fee":"#### Splitting data into training and test sets","7f5a739d":"#### Removing outliers using IQR","0b0f9499":"## 4. Splitting data<a id=\"4\"><\/a>","be24def0":"#### Reviewing categoricals","cd52ed9a":"## 2. Exploratory Data Analysis <a id=\"2\"><\/a>","51b3bcd9":"## 7. Comparing models<a id=\"7\"><\/a>","7c5c26c2":"## 6. Model Training<a id=\"6\"><\/a>","742d7735":"### 3.1. Handling Numericals<a id=\"3.1\"><\/a>","96f383b7":"#### RainTomorrow variable\n* 2 unique values\n* 0 null values","7b4a0303":"#### Seperating numerical and categorical columns","e629f60b":"## 8. Conclusion<a id=\"8\"><\/a>","4546eb23":"## 5. Feature Scaling<a id=\"5\"><\/a>","baa576ba":"####\u00a0Dropping columns with over 30% missing data and un-needed RISK_MM column","225b9e76":"#### Viewing cardinality of categoricals","e335ef0e":"### 6.1. Logistic Regression<a id=\"6.1\"><\/a>","6e19c01a":"#### Finding percentage of missing data in each column","21aefd6d":"#### Replacing categoricals with dummies of each column","b856781b":"#### Viewing correlations","e9a66ca4":"* ##### As we can see our columns are a generally less skewed with the outliers removed, Rainfall is still skewed due to most values being '0'"}}