{"cell_type":{"6dfb08bf":"code","85f0644f":"code","a0f9afda":"code","c98616d4":"code","40442219":"code","bc5397c0":"code","4d7379bb":"code","c0f6bc82":"code","49f71aea":"code","ba6256ae":"code","3ff309a6":"code","12020393":"code","4ccd3dab":"code","c0db5da7":"code","2c8eb1c2":"markdown","4147c621":"markdown","18ee637c":"markdown","f40d420b":"markdown","755364da":"markdown"},"source":{"6dfb08bf":"import numpy as np\nimport os\nimport tensorflow as tf\nimport tensorflow.keras as K\nimport matplotlib.pyplot as plt","85f0644f":"seed = 24\nbatch_size = 32\nnum_classes = 16","a0f9afda":"classes = os.listdir('..\/input\/miniimagenet-itjim-internship-2020-task6\/dataset\/train')","c98616d4":"shed = K.optimizers.schedules.ExponentialDecay(\n    0.01, 100000, decay_rate=0.95)\nopt = K.optimizers.Adam(learning_rate=shed)","40442219":"def build_fc_model(channels=3, img_size=84):\n    \n    inputs = K.layers.Input((img_size, img_size, channels))\n    flat = K.layers.Flatten()(inputs)\n    first_dense = K.layers.Dense(\n        channels*img_size**2)(flat)\n    first_dense = K.layers.LeakyReLU()(first_dense)\n    drop = K.layers.Dropout(0.3)(first_dense)\n    \n    second_dense = K.layers.Dense(img_size*5)(drop)\n    second_dense = K.layers.LeakyReLU()(second_dense)\n    last_dense = K.layers.Dense(img_size*2)(second_dense)\n    last_dense = K.layers.LeakyReLU()(last_dense)\n    outputs = K.layers.Dense(num_classes, activation='softmax')(last_dense)\n\n    model = K.models.Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer=opt,\n                    loss='categorical_crossentropy',\n                    metrics=['categorical_accuracy', \n                             K.metrics.Recall(), \n                             K.metrics.Precision()])\n\n    return model","bc5397c0":"def residual_block(x):\n    filters = x.shape[-1]\n    y = K.layers.Conv2D(filters, (3,3), padding=\"same\")(x)\n    l_relu = K.layers.LeakyReLU()(y)\n    bn = K.layers.BatchNormalization()(l_relu)\n    y = K.layers.Conv2D(filters, (3, 3), padding=\"same\")(bn)\n    \n    out = K.layers.Add()([x, y])\n    out = K.layers.BatchNormalization()(out)\n    out = K.layers.Conv2D(filters, (3, 3), padding=\"same\")(out)\n    return out\n\ndef build_cnn_model(channels=3, img_size=84):\n    \n    inputs = K.layers.Input((img_size, img_size, channels))\n    # inputs = K.layers.Lambda(lambda x: x \/ 255)(inputs)\n\n    conv1 = K.layers.Conv2D(channels, (3, 3), padding='same')(inputs)\n    conv1 = K.layers.LeakyReLU()(conv1)\n    conv1 = K.layers.Dropout(0.3)(conv1)\n    conv2 = K.layers.Conv2D(channels*5, (3, 3), padding='same')(conv1)\n    conv2 = K.layers.LeakyReLU()(conv2)\n    pool1 = K.layers.MaxPooling2D((2, 2))(conv2)\n    \n    bottleneck = K.layers.Conv2D(channels, (3, 3), padding='same')(pool1)\n    bottleneck = K.layers.LeakyReLU()(bottleneck)\n    bottleneck = K.layers.Dropout(0.3)(bottleneck)\n    conv_last = K.layers.Conv2D(1, (3, 3), padding='same')(bottleneck)\n    conv_last = K.layers.LeakyReLU()(conv_last)\n    pool2 = K.layers.MaxPooling2D((2, 2))(conv_last)\n    pool2 = K.layers.Flatten()(pool2)\n    outputs = K.layers.Dense(num_classes, activation='softmax')(pool2)\n    \n    model = K.models.Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer=opt,\n                    loss='categorical_crossentropy',\n                    metrics=['categorical_accuracy', K.metrics.Recall(), K.metrics.Precision()])\n                  # metrics=['accuracy'])\n\n    return model\n\ndef build_resnet_model(channels=3, img_size=84):\n    \n    inputs = K.layers.Input((img_size, img_size, channels))\n    # inputs = K.layers.Lambda(lambda x: x \/ 255)(inputs)\n\n    conv1 = K.layers.Conv2D(channels, (3, 3), padding='same')(inputs)\n    conv1 = K.layers.LeakyReLU()(conv1)\n    conv1 = K.layers.Dropout(0.3)(conv1)\n    res = residual_block(conv1)\n    conv2 = K.layers.Conv2D(channels, (3, 3), padding='same')(res)\n    conv2 = K.layers.LeakyReLU()(conv2)\n    pool = K.layers.MaxPooling2D((2, 2))(conv2)\n    pool = K.layers.Flatten()(pool)\n    outputs = K.layers.Dense(num_classes, activation='softmax')(pool)\n    \n    model = K.models.Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer=opt,\n                    loss='categorical_crossentropy',\n                    metrics=['categorical_accuracy', K.metrics.Recall(), K.metrics.Precision()])\n                  # metrics=['accuracy'])\n\n    return model","4d7379bb":"train_set = K.preprocessing.image_dataset_from_directory(\n    '..\/input\/miniimagenet-itjim-internship-2020-task6\/dataset\/train',\n    color_mode=\"rgb\", batch_size=batch_size, image_size=(84, 84),\n    shuffle=True, seed=seed, label_mode='categorical')\n\nval_set = K.preprocessing.image_dataset_from_directory(\n    '..\/input\/miniimagenet-itjim-internship-2020-task6\/dataset\/val',\n    color_mode=\"rgb\", batch_size=batch_size, image_size=(84, 84),\n    shuffle=True, seed=seed, label_mode='categorical')\n\ntest_set = K.preprocessing.image_dataset_from_directory(\n    '..\/input\/miniimagenet-itjim-internship-2020-task6\/dataset\/test',\n    color_mode=\"rgb\", batch_size=batch_size, image_size=(84, 84),\n    shuffle=True, seed=seed, label_mode='categorical')","c0f6bc82":"def show_sample(dataset, grid=(4, 4)):\n    fig, ax = plt.subplots(grid[0], grid[1])\n    i = j = 0\n    for batch in dataset.take(1):\n\n        for x in batch:\n            for c, img in enumerate(x):\n                #print(img.shape)\n                ax[i][j].imshow(np.uint8(img))\n                ax[i][j].set_title('{}'.format(\n                    classes[c]), fontsize=11)\n                ax[i][j].axis('off')\n                j += 1\n                if j == grid[0]:\n                    j = 0\n                    i += 1\n                if i == grid[1]:\n                    break\n            plt.tight_layout()\n            plt.show()\n            break","49f71aea":"train_gen = K.preprocessing.image.ImageDataGenerator(\n    horizontal_flip=True, rescale=1\/255)\ntrain_gen = train_gen.flow_from_directory(\n        '..\/input\/miniimagenet-itjim-internship-2020-task6\/dataset\/train',\n        target_size=(84, 84),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nval_gen = K.preprocessing.image.ImageDataGenerator(\n    rescale=1\/255)\nval_gen = val_gen.flow_from_directory(\n        '..\/input\/miniimagenet-itjim-internship-2020-task6\/dataset\/val',\n        target_size=(84, 84),\n        batch_size=batch_size,\n        class_mode='categorical')\n\ntest_gen = K.preprocessing.image.ImageDataGenerator(\n    rescale=1\/255)\ntest_gen = test_gen.flow_from_directory(\n        '..\/input\/miniimagenet-itjim-internship-2020-task6\/dataset\/test',\n        target_size=(84, 84),\n        batch_size=batch_size,\n        class_mode='categorical')","ba6256ae":"epochs = 10","3ff309a6":"best_chpt = K.callbacks.ModelCheckpoint(filepath='{epoch}_{model}_best.ckpt',\n                                        monitor='val_loss',\n                                        mode='max',\n                                        save_best_only=True, \n                                        save_weights_only=True,\n                                       verbose=1)\nruntime_chpt = K.callbacks.ModelCheckpoint(filepath='{epoch}_{model}_last.ckpt',\n                                           monitor=\"val_loss\",\n                                           save_weights_only=True,\n                                           save_freq=int(batch_size*5))","12020393":"fc_model = build_fc_model()\n\"\"\"\nfc_history = fc_model.fit(\n    train_set, steps_per_epoch=len(train_set)\/\/batch_size, \n    epochs=epochs, validation_data=val_set)\n    # callbacks=[best_chpt])\n\"\"\"\nfc_history = fc_model.fit_generator(\n    train_gen, epochs=epochs, validation_data=val_gen,\n    steps_per_epoch=len(train_gen)\/\/batch_size)\n# I might get back to checkpointing but for now it seems as a waste of time\npreds = fc_model.predict(test_set)\n#preds = np.argmax(probs, axis=1)\nclasses = train_set.class_names\n#classes = [classes[x] for x in preds]\nshow_sample(test_set)\nfc_model.save_weights('fc_model_weights.h5')","4ccd3dab":"cnn_model = build_cnn_model()\n\"\"\"\nfc_history = fc_model.fit(\n    train_set, steps_per_epoch=len(train_set)\/\/batch_size, \n    epochs=epochs, validation_data=val_set)\n    # callbacks=[best_chpt])\n\"\"\"\ncnn_history = cnn_model.fit_generator(\n    train_gen, epochs=epochs, validation_data=val_gen,\n    steps_per_epoch=len(train_gen)\/\/batch_size)\n# I might get back to checkpointing but for now it seems as a waste of time\nprobs = cnn_model.predict(test_set)\n#preds = np.argmax(probs, axis=1)\nclasses = train_set.class_names\n#classes = [classes[x] for x in preds]\nshow_sample(test_set)\ncnn_model.save_weights('cnn_model_weights.h5')","c0db5da7":"mini_resnet = build_resnet_model()\n\"\"\"\nfc_history = fc_model.fit(\n    train_set, steps_per_epoch=len(train_set)\/\/batch_size, \n    epochs=epochs, validation_data=val_set)\n    # callbacks=[best_chpt])\n\"\"\"\nres_history = mini_resnet.fit_generator(\n    train_gen, epochs=epochs, validation_data=val_gen,\n    steps_per_epoch=len(train_gen)\/\/batch_size)\n# I might get back to checkpointing but for now it seems as a waste of time\npreds = mini_resnet.predict(test_set)\n#preds = np.argmax(probs, axis=1)\nclasses = train_set.class_names\n#classes = [classes[x] for x in preds]\nshow_sample(test_set)\nmini_resnet.save_weights('res_model_weights.h5')","2c8eb1c2":"Training FC model","4147c621":"Questions remaining unanswered yet:\n* How model checkpoint callback of keras actually works? Trying to use one of this callbacks just causes overflow of memory.\n* How to properly modularize repitative blocks and use them afterward?\n* What is going on with CE loss with default keras 'categorical crossentropy'?\n* How long would it take to compile TF for my local machine? Inprecise answer - at least 3 days (after that I lost my patience)\n\nWhile I implimented many optimizations in pytorch, my knowledge of Tensorflow is limited. ","18ee637c":"### Task 6 for IT-Jim Summer Internship 2020.<br>\nMore about IT-Jim: https:\/\/www.it-jim.com","f40d420b":"First we will build a basic fully-connected model which will just flatten an output and feedforward it through a few linear layers.","755364da":"Next I will try to build as close replica of CNN model as I build in pytorch and a Mini-Resnet. One issue though arisen: I think I built residual block correctly but I am not sure (and accuracy metrics suggest either I am wrong somewhere or in pytorch version I did deep-tunning(TM) ). Nevertheless, I do understand what I do in pytorch while in keras many things are hidden (or require even more explicit rewriting)."}}