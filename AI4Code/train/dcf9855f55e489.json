{"cell_type":{"dda7be3b":"code","536dfcb4":"code","c16a9bef":"code","c9d0f589":"code","5d966baf":"code","1b4af2b3":"code","118bca90":"code","f793fd72":"code","930eab56":"code","0be71976":"code","3d4ac36a":"code","3a2b5715":"code","e03991b2":"code","ed7da6dd":"code","f6757f9e":"code","e0232f7e":"code","1eb92f15":"code","a61c5ebb":"code","a5b07999":"code","72283b61":"code","34d8d76a":"code","31abbd54":"code","529f5cd1":"code","542acc5d":"code","0a637a33":"code","e2767d54":"code","382d50aa":"code","c666073e":"code","7bfbd63c":"code","f5e73f51":"code","849a1296":"code","393a6507":"code","f0744a16":"code","6783a4a0":"code","b42afc1d":"code","f3836a70":"code","2b26997e":"code","22a53f4d":"code","749e43ff":"code","6caaa68e":"code","7f75c263":"code","255e6a31":"markdown","f5f5c91c":"markdown","4f89886a":"markdown","a51a36d0":"markdown","9172164b":"markdown","325b82ff":"markdown","ef8878bc":"markdown","b36f64bf":"markdown","0f765b0a":"markdown","acf63dc3":"markdown","904d117e":"markdown","e1b30d91":"markdown","1440c56a":"markdown","fcd0cac6":"markdown","26bcead6":"markdown","4ac71b71":"markdown","9b37e806":"markdown","e8349603":"markdown","e500f1df":"markdown"},"source":{"dda7be3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","536dfcb4":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas_profiling import ProfileReport\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nimport pandas_profiling as pp\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.metrics import mean_squared_error,classification_report\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.decomposition import PCA\nimport warnings\nwarnings.filterwarnings('ignore')","c16a9bef":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndf.head()","c9d0f589":"df.tail()","5d966baf":"df.info()","1b4af2b3":"df.describe()","118bca90":"df['target'].value_counts()","f793fd72":"df.shape","930eab56":"df.isnull().sum()","0be71976":"plt.figure(figsize = (8, 8))\nsns.distplot(df['age'], color='blue')\nplt.title('age distribution', fontsize = 14)\nplt.show()","3d4ac36a":"print(\"Skewness of age : \", df['age'].skew())","3a2b5715":"print(\"Maximum age : \", df['age'].max())\nprint(\"Minimum age : \", df['age'].min())\nprint(\"Average age : \", round(df['age'].mean()))","e03991b2":"df['sex'].value_counts()","ed7da6dd":"df.groupby(['sex','target'])['target'].count()","f6757f9e":"vgames_profile = ProfileReport(df, title='Heart Disease')\nvgames_profile","e0232f7e":"df['cp'].value_counts()","1eb92f15":"plt.figure(figsize = (8, 6))\nsns.histplot(df['cp'])\nplt.title('cp histplot', fontsize = 15)\nplt.show()","a61c5ebb":"f, ax = plt.subplots(1,3, figsize=(24, 6))\n\nsns.histplot(df['trestbps'], ax=ax[0])\nax[0].set_title(\"trestbps histplot\")\n\nsns.distplot(df['trestbps'], ax=ax[1])\nax[1].set_title('trestbps distplot')\n\nsns.stripplot(x=df['target'], y=df['trestbps'], ax=ax[2])\nax[2].set_title('trestbps vs target')\n\nplt.grid()\n\nplt.show()","a5b07999":"print(\"Skewness of trestbps : \", df['trestbps'].skew())","72283b61":"f, ax = plt.subplots(1,3, figsize=(24, 6))\n\nsns.histplot(df['chol'], ax=ax[0])\nax[0].set_title(\"Chol histplot\")\n\nsns.distplot(df['chol'], ax=ax[1])\nax[1].set_title('Chol distplot')\n\nsns.stripplot(x=df['target'], y=df['chol'], ax=ax[2])\nax[2].set_title('chol vs target')\n\nplt.grid()\n\nplt.show()","34d8d76a":"print(\"Skewness of chol : \",df['chol'].skew())","31abbd54":"plt.figure(figsize=(8, 5))\nsns.countplot(df['fbs'])\nplt.title('fbs',fontsize=14)\nplt.show()","529f5cd1":"plt.figure(figsize=(8, 5))\nsns.countplot(df['restecg'])\nplt.title('restecg',fontsize=14)\nplt.show()","542acc5d":"f, ax = plt.subplots(1,3, figsize=(24, 6))\n\nsns.histplot(df['thalach'], ax=ax[0])\nax[0].set_title(\"thalach histplot\")\n\nsns.distplot(df['thalach'], ax=ax[1])\nax[1].set_title('thalach distplot')\n\nsns.stripplot(x=df['target'], y=df['thalach'], ax=ax[2])\nax[2].set_title('thalach vs target')\n\nplt.grid()\n\nplt.show()","0a637a33":"plt.figure(figsize=(8, 5))\nsns.countplot(df['exang'])\nplt.title('exang',fontsize=14)\nplt.show()","e2767d54":"f, ax = plt.subplots(1,3, figsize=(24, 6))\n\nsns.histplot(df['oldpeak'], ax=ax[0])\nax[0].set_title(\"oldpeak histplot\")\n\nsns.distplot(df['oldpeak'], ax=ax[1])\nax[1].set_title('oldpeak distplot')\n\nsns.stripplot(x=df['target'], y=df['oldpeak'], ax=ax[2])\nax[2].set_title('oldpeak vs target')\n\nplt.grid()\n\nplt.show()\n","382d50aa":"plt.figure(figsize=(8, 5))\nsns.countplot(df['slope'])\nplt.title('slope',fontsize=14)\nplt.show()","c666073e":"plt.figure(figsize=(8, 5))\nsns.countplot(df['ca'])\nplt.title('ca',fontsize=14)\nplt.show()","7bfbd63c":"plt.figure(figsize=(8, 5))\nsns.countplot(df['thal'])\nplt.title('thal',fontsize=14)\nplt.show()","f5e73f51":"df['age'].describe()","849a1296":"df.loc[(df['age']>=29.0) & (df['age']<=47.50), 'age'] = 0\ndf.loc[(df['age']>47.50) & (df['age']<=55.0), 'age'] = 1\ndf.loc[(df['age']>55.0) & (df['age']<61.0), 'age'] = 2\ndf.loc[(df['age']>=61.0) & (df['age']<=77), 'age'] = 3","393a6507":"df['age'].value_counts()","f0744a16":"df['trestbps'] = (df['trestbps'] - df['trestbps'].mean()) \/ df['trestbps'].std()\ndf['chol'] = (df['chol'] - df['chol'].mean()) \/ df['chol'].std()\ndf['thalach'] = (df['thalach'] - df['thalach'].mean()) \/ df['thalach'].std()\ndf['oldpeak'] = (df['oldpeak'] - df['oldpeak'].mean()) \/ df['oldpeak'].std()","6783a4a0":"df.head()","b42afc1d":"X = df.drop('target',axis=1)\ny = df['target']\n\nX = RobustScaler().fit_transform(X)","f3836a70":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","2b26997e":"lr = LogisticRegression()\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\nprint(\"Logistic Regression score : \", lr.score(X_test, y_test))\nprint(\"classificatioon report\")\nprint(classification_report(y_pred, y_test))","22a53f4d":"dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\nprint(\"Decision tree classifier score : \", dt.score(X_test, y_test))\nprint(\"classificatioon report\")\nprint(classification_report(y_pred, y_test))","749e43ff":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nprint(\"Random forest classifier score : \", rf.score(X_test, y_test))\nprint(\"classificatioon report\")\nprint(classification_report(y_pred, y_test))","6caaa68e":"clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n     max_depth=1, random_state=0).fit(X_train, y_train)\nclf.score(X_test, y_test)\ny_pred = clf.predict(X_test)\nprint(\"Gradient boosting classifier score : \", clf.score(X_test, y_test))\nprint(\"classificatioon report\")\nprint(classification_report(y_pred, y_test))","7f75c263":"neigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X_train, y_train)\nneigh.score(X_test, y_test)\ny_pred = neigh.predict(X_test)\nprint(\"Gradient boosting classifier score : \", neigh.score(X_test, y_test))\nprint(\"classificatioon report\")\nprint(classification_report(y_pred, y_test))","255e6a31":"**Logistic regression and Random forest classifier perform best accuracy in this dataset**\n\n**If you like this dont't forget to upwote it**","f5f5c91c":"Our dataset is balanced","4f89886a":"Age column is continuous variable let's try convert in categorical","a51a36d0":"trestbps is positive skewd","9172164b":"Unique value count in cp columns","325b82ff":"Age is negative skewd","ef8878bc":"Total unique values in target column","b36f64bf":"**Kneighbours classifier**","0f765b0a":"Shape of dataset","acf63dc3":"There are no null values we are good to go","904d117e":"chol is positive skewed","e1b30d91":"**Decison tree classifier**","1440c56a":"Slit into X and y","fcd0cac6":"**Gradient boosting classifier**","26bcead6":"Convert some columns to normal distribution","4ac71b71":"Let's check null value","9b37e806":"**Logistic Regression**","e8349603":"**Random forest classifier**","e500f1df":"Split into train and test"}}