{"cell_type":{"bbd5ba29":"code","484904a3":"code","4f3659f3":"code","69f926dd":"code","15fbcfc4":"code","6d089510":"code","ec93b380":"code","007bd3e3":"code","325137a7":"code","dfeb34ff":"code","7d3bfb30":"code","44185352":"code","0fff0d72":"code","0e634452":"code","9fcad6a4":"code","5592c424":"markdown","b51bb910":"markdown","1c0e0ee0":"markdown","754335c1":"markdown","4866e9b3":"markdown"},"source":{"bbd5ba29":"import numpy as np                      # for numerical computation\nimport pandas as pd                     # for data analysis and data manipulation\nimport matplotlib.pyplot as plt         # for data visualization\nimport seaborn as sns                   # for data visualization\nimport tensorflow as tf                 # for machine learning and deep neural network","484904a3":"# Create synthetic dataset\ndef synthetic_data(beta, beta0, sample_size, noise_sigma, seed):  \n    #Model: y = X beta + beta0 + noise\n    X = tf.zeros((sample_size, beta.shape[0]))\n    X = tf.random.normal(shape = X.shape, mean = 0, stddev = 1.0, seed = seed)\n    y = tf.matmul(X, tf.reshape(beta, (-1, 1))) + beta0 + tf.random.normal(shape = (sample_size, 1), mean = 0, stddev = noise_sigma, seed = seed)\n    return X, y\n\nbeta  = tf.constant([1.5, -2.3, 0.8])\nbeta0 = tf.constant(6.1)\nsample_size = 1000\nnoise_sigma = 0.1\nseed = 123\nfeatures, response = synthetic_data(beta, beta0, sample_size, noise_sigma, seed)","4f3659f3":"features","69f926dd":"response[:10]","15fbcfc4":"# Reading Data in Batch\ndef read_batch(batch_size, X, y):\n    sample_size = X.shape[0]\n    indices = list(range(sample_size))\n    np.random.shuffle(indices)           # read data at random\n    for i in range(0, sample_size, batch_size):\n        batch_indices = tf.constant(indices[i : min(i + batch_size, sample_size)])\n        yield tf.gather(X, batch_indices), tf.gather(y, batch_indices)\n        #use yield to iterate over a sequence, but not to store the entire sequence in memory","6d089510":"# Test our function\n# if batch_size = x, meaning that we want to read our data with lenght x \nbatch_size = 10\nfor X, y in read_batch(batch_size, features, response):\n        print(X)","ec93b380":"#Initialize Model Parameters\nbeta  = tf.Variable(tf.random.normal(shape = (3, 1), mean = 0, stddev = 0.01),\n                    trainable = True)\nbeta0 = tf.Variable(tf.zeros(1), trainable = True)","007bd3e3":"# Define the Model\ndef linear_reg(X, beta, beta0):  \n    #Create the linear regression model\n    return tf.matmul(X, beta) + beta0","325137a7":"# Define Loss function\n\ndef loss_func(y_hat, y):\n    #Squared Loss Function\n    return 1 \/ 2 * (y_hat - tf.reshape(y, y_hat.shape)) ** 2\n\n","dfeb34ff":"# Define the Optimization Algorithm\ndef sgd(params, grads, learning_rate, batch_size):\n    #Batch Stochastic Gradient Descent\n    for param, grad in zip(params, grads):\n        param.assign_sub(learning_rate * grad \/ batch_size)","7d3bfb30":"learning_rate = 0.03\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for X, y in read_batch(batch_size, features, response):\n        with tf.GradientTape() as g:\n            #Calculate Batch Loss in `X` and `y`\n            loss = loss_func(linear_reg(X, beta, beta0), y) \n            #Compute Gradient on Loss with respect to [`beta`, `beta0`]\n            dloss_beta, dloss_beta0 = g.gradient(loss, [beta, beta0])\n        #Update parameters using their gradient\n        sgd([beta, beta0], [dloss_beta, dloss_beta0], learning_rate, batch_size)\n    train_l = loss_func(linear_reg(features, beta, beta0), response)\n    print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_l)): 0.4f}')","44185352":"print(f'Estimating beta: {beta.numpy()}')\nprint(f'Estimating beta0: {beta0.numpy()}') ","0fff0d72":"# Real Beta\nbeta\n","0e634452":"# Real Beta0\nbeta0","9fcad6a4":"# Reference:\n# Deep dive to deep learning","5592c424":"# Train Our Model","b51bb910":" our goal is build a linear regression model with ANN. \n<br\/>\nlet me create synthetic dataset","1c0e0ee0":"#### our neural net is something like this\n\n![image.png](attachment:ab42405e-1b61-4d20-8ae5-e15af39e5168.png)\n\n#### Before we start train our model, we have to initialize W(parameters)","754335c1":"### In this notebook we I want to introduce you With linear neural network and implement it from scratch in python","4866e9b3":"First of all we have to define a function that read our data batch-batch"}}