{"cell_type":{"04a4044f":"code","df889052":"code","37890ee1":"code","e5291483":"code","c87dd56d":"code","988ffa9e":"code","3b098a45":"code","8d5db438":"code","ff5033f7":"code","00a8a624":"code","ccbaf534":"code","07551250":"code","ebb1511e":"code","a4e3effb":"code","ae2ac819":"code","47e05273":"code","d4d3efb7":"code","5338a5b9":"code","e69e44f8":"code","cdda5f30":"code","f47747e1":"code","e48117e4":"code","5e40a1e6":"code","f58c40c6":"code","549a8941":"code","51addbd0":"code","329e16cc":"code","bc574acb":"code","97a2a2a5":"markdown","cd500587":"markdown","5b3f4869":"markdown","f2548146":"markdown","9b116799":"markdown","71f00f75":"markdown","688b0451":"markdown","63e82383":"markdown","481a3b1b":"markdown","a06d7197":"markdown","c426b93e":"markdown","452879d5":"markdown","2485fbe4":"markdown","fd367dfb":"markdown","f9846ee4":"markdown","01ece19d":"markdown","fb9fa7ce":"markdown","0d78869a":"markdown","0faeccfd":"markdown","0595e645":"markdown","b008db52":"markdown","e760621d":"markdown","dbb182d4":"markdown","3f06c12e":"markdown","c74e9344":"markdown","b3ce6a3f":"markdown","93a095b0":"markdown"},"source":{"04a4044f":"import sys\nimport os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm_notebook as T\nimport platform\n\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch import optim, nn\nfrom torch.nn import functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torch.autograd import Variable\nfrom torchvision import transforms\n\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\n\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\n","df889052":"data_dir = '..\/input\/chest-xray-bsp\/Chest_Xray_BSP'\ntrain_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(data_dir, 'test.csv'))\ntrain_dir = f'{data_dir}\/train\/'\ntest_dir = f'{data_dir}\/test\/'","37890ee1":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 24\nseed_everything(SEED)","e5291483":"label_to_idx = {'Normal': 0, 'Viral_Pneumonia': 1, 'Bacterial_Pneumonia': 2, 'Covid': 3}\nidx_to_label = {0: 'Normal', 1: 'Viral_Pneumonia', 2: 'Bacterial_Pneumonia', 3: 'Covid'}\ntrain_df['label'] = train_df['Diagnosis'].map(label_to_idx)\ntest_df['label'] = test_df['Diagnosis'].map(label_to_idx)","c87dd56d":"# Courtesy: https:\/\/www.kaggle.com\/ratthachat\/aptos-eye-preprocessing-in-diabetic-retinopathy\nfrom matplotlib import pyplot as plt\nimport os\nimport random\n\n%matplotlib inline\nfig = plt.figure(figsize=(60, 40))\nfor class_id in sorted(train_df['label'].unique()):\n    for i, (idx, row) in enumerate(train_df.loc[train_df['label'] == class_id].sample(3, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"{train_dir}\/{row['image_name']}\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (320, 320))\n        plt.imshow(image, cmap='bone')\n        ax.set_title('Label: %s Name: %s' % (row['Diagnosis'], row['image_name']))","988ffa9e":"from matplotlib import pyplot as plt\n%matplotlib inline\ntrain_df.label.hist()\ntest_df.label.hist()","3b098a45":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu:0\")","8d5db438":"params = {'num_classes':4, 'criterion':nn.BCEWithLogitsLoss(), 'mixed_precision':False,\n         'IMG_SIZE':256, 'num_epoch': 16, 'batch_size':32, 'learning_rate':2e-3, 'num_worker':4, 'n_fold':5}","ff5033f7":"from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nskf = StratifiedKFold(n_splits=params['n_fold'], random_state=SEED)\nX = train_df['image_name']\ny = train_df['label']\ntrain_idx = []\nval_idx = []\nfor i, (train_index, val_index) in enumerate(skf.split(X, y)):\n    train_idx = train_index\n    val_idx = val_index\n    break\ntrain = train_df.loc[train_idx]\nvalid = train_df.loc[val_idx]","00a8a624":"class CXRDataset(Dataset):\n    def __init__(self, dirname, df, dim, transformer):\n        super(Dataset, self).__init__()\n        self.data = df\n        self.dim = dim\n        self.dirname = dirname\n        self.transformer = transformer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, item):\n        img_name = os.path.join(self.dirname, self.data.loc[item, 'image_name'])\n        image = cv2.imread(img_name)\n        image = cv2.resize(image, (self.dim, self.dim))\n        image = Image.fromarray(image)\n        raw_label = [self.data.loc[item, 'label']]\n        \n        label = np.zeros((len(raw_label), params['num_classes']))\n        label[np.arange(len(raw_label)),raw_label] = 1\n        label = torch.LongTensor(label)\n                        \n        return self.transformer(image), label\n","ccbaf534":"# Data Augmentations\ntrain_transform = transforms.Compose([\n    transforms.RandomRotation(360),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n    ])\n\nval_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n    ])\n","07551250":"class CXRPretrainedModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = torchvision.models.resnet50(pretrained=True)\n        self.model.fc = nn.Linear(2048, 256)\n        self.out = nn.Linear(256, params['num_classes'])\n    \n    def forward(self, x):\n        x = self.model.conv1(x)\n        x = self.model.bn1(x)\n        x = self.model.relu(x)\n        x = self.model.maxpool(x)\n        x = self.model.layer1(x)\n        x = self.model.layer2(x)\n        x = self.model.layer3(x)\n        x = self.model.layer4(x)\n        x = self.model.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.model.fc(x)\n        x = self.out(x)\n        return x\n","ebb1511e":"pretrained_model = CXRPretrainedModel().to(device)\ncriterion = params['criterion']\nlr = params['learning_rate']\nplist = [\n    {'params': pretrained_model.model.parameters(), 'lr':lr\/100},\n    {'params': pretrained_model.out.parameters(), 'lr':lr}\n]\noptimizer = optim.Adam(plist, lr=lr)\nlr_reduce_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True, threshold=1e-4, threshold_mode='rel', cooldown=0, min_lr=1e-7, eps=1e-08)","a4e3effb":"mixed_precision = params['mixed_precision']\nif mixed_precision:\n    ! git clone https:\/\/github.com\/NVIDIA\/apex\n    os.chdir('apex')\n    ! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\/\n    os.chdir('..\/')\n    from apex import amp\n    amp.initialize(basic_model, optimizer, opt_level='O1')","ae2ac819":"def save_model(valid_loss, valid_f1, best_valid_loss, best_valid_f1, best_state, savepath):\n    if valid_loss<best_valid_loss:\n        print(f'Validation loss has decreased from:  {best_valid_loss:.4f} to: {valid_loss:.4f}. Saving checkpoint')\n        torch.save(best_state, savepath+'_loss.pth')\n        best_valid_loss = valid_loss\n    if valid_f1>best_valid_f1:\n        print(f'Validation F1 score has increased from:  {best_valid_f1:.4f} to: {valid_f1:.4f}. Saving checkpoint')\n        torch.save(best_state, savepath + '_f1.pth')\n        best_valid_f1 = valid_f1\n    else:\n        torch.save(best_state, savepath + '_last.pth')\n    return best_valid_loss, best_valid_f1 ","47e05273":"from sklearn.metrics import f1_score\n\ndef train_val(epoch, dataloader, model, optimizer, train=True, mode='train'):\n    t1 = time.time()\n    running_loss = 0\n    epoch_samples = 0\n    pred = []\n    lab = []\n    if train:\n        model.train()\n        print(\"Initiating train phase ...\")\n    else:\n        model.eval()\n        print(\"Initiating val phase ...\")\n    for idx, (img,labels) in enumerate(dataloader):\n        epoch_samples += img.size(0)\n        with torch.set_grad_enabled(train):\n            img = img.to(device, dtype=torch.float)\n            labels = torch.squeeze(labels).to(device, dtype=torch.float)\n            outputs = model(img)\n            loss = criterion(outputs, labels)\n            running_loss += loss.sum().item()\n            if train:\n                if mixed_precision:\n                    with amp.scale_loss(loss, optimizer) as scaled_loss:\n                        scaled_loss.backward()\n                else:\n                    loss.backward()\n\n                    optimizer.step()\n                    optimizer.zero_grad()\n\n        elapsed = int(time.time() - t1)\n        eta = int(elapsed \/ (idx+1) * (len(dataloader)-(idx+1)))\n        pred.extend(torch.argmax(outputs, dim=1).detach().cpu().numpy())\n        lab.extend(torch.argmax(labels, dim=1).cpu().numpy())\n        \n        if train:\n            msg = f\"Epoch: {epoch} Progress: [{idx}\/{len(dataloader)}] loss: {(running_loss\/epoch_samples):.4f} Time: {elapsed}s ETA: {eta} s\"\n        else:\n            msg = f'Epoch {epoch} Progress: [{idx}\/{len(dataloader)}] loss: {(running_loss\/epoch_samples):.4f} Time: {elapsed}s ETA: {eta} s'\n        print(msg, end= '\\r')\n    history.loc[epoch, f'{mode}_loss'] = running_loss\/epoch_samples\n    history.loc[epoch, f'{mode}_time'] = elapsed\n    if mode=='val':\n        f1 = f1_score(lab, pred, average='weighted')\n        lr_reduce_scheduler.step(running_loss)\n        msg = f'{mode} Loss: {running_loss\/epoch_samples:.4f} \\n {mode} F1 Score: {f1:.4f}'\n        print(msg)\n        history.loc[epoch, f'{mode}_loss'] = running_loss\/epoch_samples\n        history.loc[epoch, f'{mode}_f1_score'] = f1\n        history.to_csv(f'history.csv', index=False)\n        return lab, pred, running_loss\/epoch_samples, f1\n    elif mode == 'test':\n        f1 = f1_score(lab, pred, average='weighted')\n        return lab, pred, running_loss\/epoch_samples, f1\n    else:\n        return model","d4d3efb7":"train_dataset = CXRDataset(train_dir, train.reset_index(drop=True), params['IMG_SIZE'], train_transform)\ntrain_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True, num_workers=4)\nval_dataset = CXRDataset(train_dir, valid.reset_index(drop=True), params['IMG_SIZE'], val_transform)\nval_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=params['batch_size']\/\/2, shuffle=True,num_workers= params['num_worker'])\ntest_dataset = CXRDataset(test_dir, test_df.reset_index(drop=True), params['IMG_SIZE'], val_transform)\ntest_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=params['batch_size']\/\/2, shuffle=True,num_workers= params['num_worker'])","5338a5b9":"import gc\nimport time\n\ndef main(model):\n    prev_epoch_num = 0\n    best_valid_loss = np.inf\n    best_valid_f1 = 0.0\n  \n    for epoch in range(params['num_epoch']):\n        torch.cuda.empty_cache()\n        print(gc.collect())\n\n        model = train_val(epoch, train_data_loader, model=model, optimizer=optimizer, train=True, mode='train')\n        _, _, valid_loss, valid_f1 = train_val(epoch, val_data_loader, model=model, optimizer=optimizer, train=False, mode='val')\n        print(\"#\"*20)\n        print(f\"Epoch {epoch} Report:\")\n        print(f\"Validation Loss: {valid_loss :.4f} Validation F1 Score: {valid_f1 :.4f}\")\n        best_state = {'model': model.state_dict(), 'optim': optimizer.state_dict(), 'scheduler':lr_reduce_scheduler.state_dict(), \n        \n        # 'cyclic_scheduler':cyclic_scheduler.state_dict(), \n#             'scaler': scaler.state_dict(),\n        'best_loss':valid_loss, 'best_f1':valid_f1, 'epoch':epoch}\n        best_valid_loss, best_valid_f1 = save_model(valid_loss, valid_f1, best_valid_loss, best_valid_f1, best_state, '.\/CXR_model')\n        print(\"#\"*20)","e69e44f8":"if mixed_precision:\n    amp.initialize(pretrained_model, optimizer, opt_level='O1')","cdda5f30":"history = pd.DataFrame()\nmain(pretrained_model)","f47747e1":"tmp = torch.load('.\/CXR_model_f1.pth')\nprint('Model loaded')\n# loadinig weights\npretrained_model.load_state_dict(tmp['model'])\npredictions, actual_labels, test_loss, test_f1 = train_val(-1, test_data_loader, model=pretrained_model, optimizer=optimizer, train=False, mode='test')\nprint(f'Test Loss: {test_loss} Test F1: {test_f1}')","e48117e4":"predictions = [idx_to_label[p] for p in predictions]\nactual_labels = [idx_to_label[p] for p in actual_labels]","5e40a1e6":"from matplotlib import pyplot as plt\nfrom matplotlib.pyplot import figure\nfigure(num=None, figsize=(8, 6), dpi=80, edgecolor='k')\nhistory = pd.read_csv('.\/history.csv')\nplt.plot(history['train_loss'], label='train loss')\nplt.plot(history['val_loss'], label='validation loss')\n\nplt.title('Training history')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()","f58c40c6":"figure(num=None, figsize=(8, 6), dpi=80, facecolor='1', edgecolor='k')\nplt.plot(history['val_f1_score'], label='validation f1 score')\n\nplt.title('Training history')\nplt.ylabel('F1 Score')\nplt.xlabel('Epoch')\nplt.legend()","549a8941":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nlabels = list(idx_to_label.values())\ncm = confusion_matrix(predictions, actual_labels, labels)\n# Normalise\ncmn = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\nfig, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=labels, yticklabels=labels)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show(block=False)","51addbd0":"! pip install -q pytorch-gradcam","329e16cc":"from gradcam import GradCAM, GradCAMpp\nfrom gradcam.utils import visualize_cam\n\ndef grad_cam_gen(model, img, mixed_precision = False, device = 'cuda'):\n    if mixed_precision:\n        model, optim = amp.initialize(model, optim, opt_level='O1')\n         \n    configs = [dict(model_type='resnet', arch=model, layer_name='layer4')]\n    for config in configs:\n        config['arch'].to(device).eval()\n\n    cams = [\n    [cls.from_config(**config) for cls in (GradCAM, GradCAMpp)]\n        for config in configs]\n\n    for _, gradcam_pp in cams:\n        mask_pp, _ = gradcam_pp(img)\n        heatmap_pp, result_pp = visualize_cam(mask_pp, img)\n        result_pp = result_pp.cpu().numpy()\n        #convert image back to Height,Width,Channels\n        result_pp = np.transpose(result_pp, (1,2,0))\n        return result_pp\n","bc574acb":"from torchvision import models\n\n%matplotlib inline\nfig = plt.figure(figsize=(70, 56))\nfor class_id in sorted(test_df['label'].unique()):\n    for i, (idx, row) in enumerate(test_df.loc[test_df['label'] == class_id].sample(3, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"{test_dir}\/{row['image_name']}\"\n        image = cv2.imread(path)\n        image = cv2.resize(image, (256, 256))\n        image = Image.fromarray(image)\n        image = val_transform(image)\n        prediction = torch.argmax(pretrained_model(torch.unsqueeze(image.to(device), dim=0)))\n        prediction = prediction.data.cpu().numpy()\n        pred_label = idx_to_label[int(prediction)]\n        image = grad_cam_gen(pretrained_model.model, torch.unsqueeze(image, dim=0).cuda())\n        plt.imshow(image, cmap='bone')\n        ax.set_title('Label: %s Prediction: %s' % (row['Diagnosis'], pred_label))","97a2a2a5":"## Dataset\nI have collected and curated around 6k chest X-ray images with their respective abnormality types. The data is collected from the following sources:\n\n- [Chest X-Ray Images (Pneumonia)](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia)\n- [COVID Chest X-ray Dataset](https:\/\/github.com\/ieee8023\/covid-chestxray-dataset)","cd500587":"## Augmentations\nAugmentations are used to increase diversity of data available for training models, without actually collecting new data. It helps the model to genearalize and prevents overfitting.","5b3f4869":"### Prediction\n\nNow we will load our best model and predict labels for test data using it.","f2548146":"## Setting Parameters for training","9b116799":"## Sample Images from Our Dataset","71f00f75":"## GradCAM","688b0451":"### Creating model object, loss fucntion and optimizers","63e82383":"A deep learing model can be compared to a black box. In our case, input and output data are feeded to it's two ends and it learns to map input to output during training.\n\nWith all the resources we have by now, we can develop our pipeline for training a model. We will use **[Pytorch](https:\/\/pytorch.org\/)** for the task. The procedures are described step by step below.","481a3b1b":"###  Convolutional Neural Networks \n\nConvolutional Neural Network is a special variant of Deep Neural Network. In Convolutional Neural Networks, every image input is treated as a a matrix of pixel values which represents the amount of darkness at a given pixel in the image. Unlike, tradational neural networks which treats an image as a one dimentional network, CNNs considers the location of pixels and the neighbours for classification.\n\n<br>\n\n![](http:\/\/www.mdpi.com\/information\/information-07-00061\/article_deploy\/html\/images\/information-07-00061-g001.png)\n\n<br>\n\n### Key components of Convolutional Neural Network. \n\n- **A. Convolutional layer: ** In this layer, a kernel (or weight) matrix is used to extract low level features from the images. The kernel with its weights rotates over the image matrix in a sliding window fashion in order to obtained the convolved output. The kernel matrix behaves like a filter in an image extracting particular information from the original image matrix. During the colvolution process, The weights are learnt such that the loss function is minimized.\n\n- **B. Stride: ** Stride is defined as the number of steps the kernel or the weight matrix takes while moving across the entire image moving N pixel at a time. If the weight matrix moves N pixel at a time, it is called stride of N.\n\n![](http:\/\/deeplearning.net\/software\/theano\/_images\/numerical_padding_strides.gif) \nImage Credits - www.deeplearning.net\n\n- **C. Pooling Layer:**  Pooling layers are used to extract the most informative features from the generated convolved output. \n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/e\/e9\/Max_pooling.png)\n\n- **D. Output Layer:** To generate the final output, a dense or a fully connected layer is applied with the softmax activation function. Softmax function is used to generate the probabilities for each class of the target variable. \n\n**Courtesy: [A Very Comprehensive Tutorial : NN + CNN](https:\/\/www.kaggle.com\/shivamb\/a-very-comprehensive-tutorial-nn-cnn)**\n","a06d7197":"### Dataset and Dataloader\n\nThere are several ways to load and feed data into a DNN. In Pytorch, we usually do it using `Dataset`. It is a class that samples chunks\/batches of data from dataset. `Dataloader` is another class that uses `Dataset` to retrive data and\/or corresponding outputs as batches. Later, these data batches are fed into model for training. In the following section, we will inherit pytorch's Dataset class and modify it in such a way that it will load images and corresponding abnormality levels and return them after applying some preprocessing. ","c426b93e":"## Loss","452879d5":"### Adding a Fixed Seed Value\n\nA fixed seed value always yields the same set of random numbers. ","2485fbe4":"### Training with a Pretrained Model\n\nTraining a model from scratch often requires a long time to converge and it does not generalize well. To avoid this problem, it is a common practice to use a model that was trained over a large dataset before and is well-generalized. One major advantage of using a pretrained model is that their top layers are capable of extracting general features irrespective of any image domain. We initiate training from the weights of that pretrained model. Sometimes, we freeze selective top layers to avoid overfitting and force it to generalize well.","fd367dfb":"## Confusion Matrix","f9846ee4":"### Check Whether GPU is available or not\n\nGPUs are optimized to do matrix operations much faster than CPUs. Since training models involve large matrix operations, using GPU facility would make these operations much faster and more precise. However, not all computers come with GPUs. So, we will check whether there is GPU available and if so, then we will load our data and model into it.","01ece19d":"### Loading all necessary libraries","fb9fa7ce":"## F1 Score ","0d78869a":"## Next Tasks\n\n- Add ConvXNet model\n- Multilabel Classification\n- Add `learning rate scheduler`, `layer wise different learning rate` etc magic features for better optimization.","0faeccfd":"# Diving into Deep Learning","0595e645":"## Mixed Precision\n\nMixed precision is the combined use of different numerical precisions in a computational method.\n\nHalf precision (also known as FP16) data compared to higher precision FP32 vs FP64 reduces memory usage of the neural network, allowing training and deployment of larger networks, and FP16 data transfers take less time than FP32 or FP64 transfers.\n\nSingle precision (also known as 32-bit) is a common floating point format (float in C-derived programming languages), and 64-bit, known as double precision (double).\n\nDeep Neural Networks (DNNs) have led to breakthroughs in a number of areas, including image processing and understanding, language modeling, language translation, speech processing, game playing, and many others. DNN complexity has been increasing to achieve these results, which in turn has increased the computational resources required to train these networks.\n\nSource: [NVIDIA Accelerated Computing](https:\/\/docs.nvidia.com\/deeplearning\/performance\/mixed-precision-training\/index.html)","b008db52":"### Metric\nWe are going to use [F Score](https:\/\/machinelearningmastery.com\/classification-accuracy-is-not-enough-more-performance-measures-you-can-use\/) for our model evaluation.","e760621d":"### Train-Validation Split\n\nInstead of training over the whole dataset, we often split it into two parts named train and validation sets and train over the train set only. We then monitor the model's performance over the validation set. A good validation set resembles test dataset i.e., their class distribution are same and the metrics obtained over them should be close. \n\nIf the dataset is quiet large, it is safe to assume that it's class distribution will be similar to that of test\/unknown data. We use `Stratified Split` to create a validation dataset with same class elements ratio. ","dbb182d4":"Deep Learning has been being widely applied in medical domain applications. Medical image classification, localization and segementation tasks requires expert analysis by specialists. Due to the vastness of data and their complex patterns, it is incredibly hard to hand label them. Deep learning can be of a great assistance in these sort of tasks.\n\nIn this notebook, we will explore a specific medical dataset on detection of 4 types of abnormalities in chest X-ray images.  ","3f06c12e":"# Prediction Visualization","c74e9344":"### Data Distribution","b3ce6a3f":"### Funtions for Training and Evaluation","93a095b0":"## Possible Aproaches towards solving\n\nThis problem can be treated as a **Classification** problem. Here, output is a column vector of length dimension `4x1` for each input. If the level is *`n`*, then the *`n`*th row is `1` and the rest are `0` "}}