{"cell_type":{"32584039":"code","4f96fae0":"code","148dd4f5":"code","9117b105":"code","739df7dd":"code","946bab75":"code","29d7bf63":"code","ec286f42":"code","3da32272":"code","1d0d9e1b":"code","e827c51a":"code","46d71e34":"code","6d815af6":"code","59bfa061":"code","99598585":"code","12ae4e7b":"code","6d49dc61":"code","05404928":"code","3d48bcd5":"code","c33940fa":"code","5c972059":"code","eb3bf167":"code","38d43dd1":"code","b64815ca":"code","310f1cf9":"code","4a22fa6a":"code","7e9f533b":"code","bcc781b1":"code","af392a2d":"code","0a9bf0c7":"code","c8a1f6ca":"code","c6b88019":"code","50a5ed5c":"markdown","80be1c8d":"markdown","d9d0da6c":"markdown","987a7fe8":"markdown","e720ea6a":"markdown","bda61e86":"markdown","32528098":"markdown","e1c8589e":"markdown","53f61be7":"markdown","1f0bd996":"markdown"},"source":{"32584039":"#libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.model_selection import ShuffleSplit, KFold\nfrom sklearn.model_selection import cross_val_score\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4f96fae0":"%%time\nPATH_TO_DATA = '..\/input\/mlcourse-dota2-win-prediction'\ndf_train_features = pd.read_csv(os.path.join(PATH_TO_DATA,'train_features.csv'), index_col='match_id_hash')\ndf_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_targets.csv'), index_col='match_id_hash')","148dd4f5":"df_train_features.shape, df_train_targets.shape","9117b105":"df_train_features.head()","739df7dd":"df_train_targets.head()","946bab75":"X = df_train_features.values\ny = df_train_targets['radiant_win'].values","29d7bf63":"x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3,random_state=17)","ec286f42":"x_train.shape, x_valid.shape, y_train.shape, y_valid.shape","3da32272":"np.bincount(y)","1d0d9e1b":"#logistic Regression\nC = 1\npenalty = 'l2'\nmax_iter = 100\nsolver = 'liblinear'\nrandom_state = 17\nn_jobs = -1\nverbose = 1\n\nclf_lr = LogisticRegression(C=C,\n                            penalty=penalty,\n                            max_iter=max_iter, \n                            random_state=random_state,\n                            verbose=verbose,\n                            n_jobs=n_jobs,\n                           solver=solver)","e827c51a":"%%time\nclf_lr.fit(x_train, y_train)\ny_pred = clf_lr.predict(x_valid)\nprint('Log Regression validation roc_auc score {} '.format(roc_auc_score(y_pred, y_valid)))","46d71e34":"cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=17)","6d815af6":"%%time\n#calcuate ROC-AUC for each split\n#logistic Regression\nC = 1\npenalty = 'l2'\nmax_iter = 50\nsolver = 'liblinear'\nrandom_state = 17\nn_jobs = -1\nverbose = 1\n\nclf_lr_1 = LogisticRegression(C=C,\n                            penalty=penalty,\n                            max_iter=max_iter, \n                            random_state=random_state,\n                            verbose=verbose,\n                            n_jobs=n_jobs,\n                           solver=solver)\n\ncv_scores_lr1 = cross_val_score(clf_lr_1, X, y, cv=cv, scoring='roc_auc')","59bfa061":"%%time\n#logistic Regression\n\nC = 0.1\npenalty = 'l2'\nsolver = 'saga'\nmax_iter = 150\nrandom_state = 17\nn_jobs = -1\nverbose = 1\nclass_weight = 'balanced'\n\nclf_lr_2 = LogisticRegression(C=C,\n                            penalty=penalty,\n                            max_iter=max_iter, \n                            random_state=random_state,\n                            verbose=verbose,\n                            n_jobs=n_jobs,\n                            class_weight=class_weight,\n                            solver=solver)\n\n# calcuate ROC-AUC for each split\ncv_scores_lr2 = cross_val_score(clf_lr_2, X, y, cv=cv, scoring='roc_auc')","99598585":"cv_scores_lr2 > cv_scores_lr1","12ae4e7b":"import json\nwith open(os.path.join(PATH_TO_DATA, 'train_matches.jsonl')) as f:\n    # read the 18-th line\n    for i in range(18):\n        line = f.readline()\n    \n    # read JSON into a Python object \n    match = json.loads(line)","6d49dc61":"player = match['players'][2]\n#player","05404928":"player['kills'], player['deaths'], player['assists']","3d48bcd5":"player['ability_uses']","c33940fa":"%matplotlib inline\nfrom matplotlib import pyplot as plt","5c972059":"for player in match['players']:\n    plt.plot(player['times'], player['gold_t'])\n    \nplt.title('Gold change for all players');","eb3bf167":"try:\n    import ujson as json\nexcept ModuleNotFoundError:\n    import json\n    print ('Please install ujson to read JSON oblects faster')\n    \ntry:\n    from tqdm import tqdm_notebook\nexcept ModuleNotFoundError:\n    tqdm_notebook = lambda x: x\n    print ('Please install tqdm to track progress with Python loops')\n    \ndef read_matches(matches_file):\n    \n    MATCHES_COUNT = {\n        'test_matches.jsonl': 10000,\n        'train_matches.jsonl': 39675,\n    }\n    _, filename = os.path.split(matches_file)\n    total_matches = MATCHES_COUNT.get(filename)\n    \n    with open(matches_file) as fin:\n        for line in tqdm_notebook(fin, total=total_matches):\n            yield json.loads(line)","38d43dd1":"def add_new_features(df_features, matches_file):\n    \n    # Process raw data and add new features\n    for match in read_matches(matches_file):\n        match_id_hash = match['match_id_hash']\n\n        # Counting ruined towers for both teams\n        radiant_tower_kills = 0\n        dire_tower_kills = 0\n        for objective in match['objectives']:\n            if objective['type'] == 'CHAT_MESSAGE_TOWER_KILL':\n                if objective['team'] == 2:\n                    radiant_tower_kills += 1\n                if objective['team'] == 3:\n                    dire_tower_kills += 1\n\n        # Write new features\n        df_features.loc[match_id_hash, 'radiant_tower_kills'] = radiant_tower_kills\n        df_features.loc[match_id_hash, 'dire_tower_kills'] = dire_tower_kills\n        df_features.loc[match_id_hash, 'diff_tower_kills'] = radiant_tower_kills - dire_tower_kills","b64815ca":"%%time\n# copy the dataframe with features\ndf_train_features_extended = df_train_features.copy()\n\n# add new features\nadd_new_features(df_train_features_extended, os.path.join(PATH_TO_DATA, 'train_matches.jsonl'))","310f1cf9":"df_train_features_extended.head()","4a22fa6a":"df_train_features_extended.shape","7e9f533b":"%%time\ncv_scores_extended = cross_val_score(clf_lr_2, df_train_features_extended, y, cv=cv, scoring='roc_auc')","bcc781b1":"print('Base features: mean={} scores={}'.format(cv_scores_lr2.mean(), \n                                                cv_scores_lr2))\nprint('Extended features: mean={} scores={}'.format(cv_scores_extended.mean(), \n                                                    cv_scores_extended))","af392a2d":"cv_scores_extended > cv_scores_lr2","0a9bf0c7":"df_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'),index_col='match_id_hash')","c8a1f6ca":"%%time\n# Build the same features for the test set\ndf_test_features_extended = df_test_features.copy()\nadd_new_features(df_test_features_extended, os.path.join(PATH_TO_DATA, 'test_matches.jsonl'))","c6b88019":"clf_lr_2.fit(df_train_features_extended.values, y)\ndf_submission_base = pd.DataFrame(\n    {'radiant_win_prob': clf_lr_2.predict_proba(df_test_features_extended.values)[:, 1]}, \n    index=df_test_features.index,\n)\ndf_submission_base.to_csv('submission.csv')","50a5ed5c":"### Performing Cross-Validation","80be1c8d":"### Working with Logistic Regression","d9d0da6c":"Lets start writing code get the predictions","987a7fe8":"## Data description\n\nWe have the following files:\n\n- `sample_submission.csv`: example of a submission file\n- `train_matches.jsonl`, `test_matches.jsonl`: full \"raw\" training data \n- `train_features.csv`, `test_features.csv`: features created by organizers\n- `train_targets.csv`: results of training games (including the winner)","e720ea6a":"From the above command we can say that the target distribution is more or less  balanced.","bda61e86":"- This notebook shows how logistic Regression performs for this data.\n- Also this code performs better than Random Forest baseline from [mlcourse.ai](https:\/\/www.kaggle.com\/kashnitsky\/dota-2-win-prediction-random-forest-starter)","32528098":"#### Example: time series for each player's gold.","e1c8589e":" ** CREDITS ** \n -  Thanks to [ODS](https:\/\/mlcourse.ai\/)","53f61be7":"### Working with Actual Test set","1f0bd996":"### Working with all available information on Dota games"}}