{"cell_type":{"6f375d80":"code","73baec2a":"code","96e70d83":"code","e2d8c6f1":"code","80d8de89":"code","6f0a2bd3":"code","99cd9478":"code","e7c0f6f7":"code","2ce702a0":"code","6a69f3c0":"code","3fc7c448":"code","63007568":"code","54cb9f10":"markdown","c0051853":"markdown","e20a59df":"markdown","0eff40db":"markdown","7085e92c":"markdown","ce7524cd":"markdown","a05dc35b":"markdown","0a96c43d":"markdown","b0edb94a":"markdown","8207976e":"markdown","19cbca9b":"markdown","aa63fa9d":"markdown"},"source":{"6f375d80":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","73baec2a":"df = pd.read_csv(\"..\/input\/CSV_datasetsix_vowel_dataset_with_class.csv\")\ndf.head()","96e70d83":"pix=[]\nfor i in range(784):\n    pix.append('pixel'+str(i))\nfeatures=pix\nX = df.loc[:, features].values\ny = df.loc[:,'class'].values\n\nX_train, X_test, y_train, y_test = train_test_split(\n X, y, test_size = 0.30, random_state = 100)\ny_train=y_train.ravel()\ny_test=y_test.ravel()","e2d8c6f1":"def row2img(data):\n    return np.asfarray(data).reshape((28,28))","80d8de89":"data=X_train[11]\nf, ax1 = plt.subplots(1, 1, sharey=True)\nf.suptitle('Respective image of X_train[11]', size='20')\nax1.imshow(255-row2img(data), cmap=plt.cm.binary);","6f0a2bd3":"X_train = tf.keras.utils.normalize(X_train,axis=1)\nX_test = tf.keras.utils.normalize(X_test,axis=1)","99cd9478":"model=tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(7,activation=tf.nn.softmax))","e7c0f6f7":"model.compile(optimizer='adam',\n                loss='sparse_categorical_crossentropy', metrics=['accuracy'])","2ce702a0":"model.fit(X_train,y_train,epochs=50)","6a69f3c0":"_,acc=model.evaluate(X_test,y_test)\nprint('Accuracy: {}'.format(acc))","3fc7c448":"pred=model.predict([X_test])\nprint('Predicted Label: ',np.argmax(pred[11]))","63007568":"f, (ax1) = plt.subplots(1, 1, sharey=True)\nax1.set_title('Actual Label: '+str(y_test[11]))\nax1.imshow(255-row2img(X_test[11]),cmap=plt.cm.binary);\n","54cb9f10":"## Predict","c0051853":"## Compiling Model","e20a59df":"## Normalize the dataset","0eff40db":"## Loading Data","7085e92c":"# <font color='tomato'>Neural Network<\/font> on Telugu Vowel Dataset","ce7524cd":"## Building Neural Network","a05dc35b":"## Seeing the Images in the dataset","0a96c43d":"## Importing Libraries","b0edb94a":"## Accuracy and Loss","8207976e":"## <font color='tomato'>Accuracy of the model is: <\/font><font color='MediumSpringGreen'>84.17<\/font>","19cbca9b":"## Conclusion:\n* <pre><font color='navy' face='lucida console'><strong>Since the Neural Networks needs lots of data for the training purpose.\n  So the data that we have is not sufficient to train the model to get better reults when compared to the models like SVM and K-NNC.<\/strong><\/font><\/pre>","aa63fa9d":"## Splitting data into 'train' and 'test'"}}