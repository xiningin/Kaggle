{"cell_type":{"2cbf709a":"code","1f251171":"code","ebe45fb3":"code","030fd4d7":"code","ffa3ac28":"code","e261a3d6":"code","e722b621":"code","b3539a6c":"code","a3defa84":"code","a8968dbb":"code","90147c6f":"code","23d7cadd":"code","cc6211fa":"code","ff0e8a18":"code","4045778e":"code","39b43076":"code","a9b51ad0":"code","572625dc":"markdown","3b79f22a":"markdown","14475644":"markdown","ef95a9c3":"markdown","7bf6007d":"markdown","d795b886":"markdown","f9d1c42e":"markdown","efde312f":"markdown","fda9e327":"markdown","2c85dc0b":"markdown"},"source":{"2cbf709a":"conda install pytorch torchvision -c pytorch","1f251171":"pip install -r ..\/input\/requirement\/requirements.txt","ebe45fb3":"!pip install matplotlib","030fd4d7":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport cv2\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\n\nfrom skimage import transform\nimport torchvision\nimport sys","ffa3ac28":"from detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nimport matplotlib.pyplot as plt\nfrom blimpy.utils import rebin\nfrom PIL import Image\nfrom IPython.display import display\nimport matplotlib.patches as patches","e261a3d6":"%matplotlib inline","e722b621":"cfg = get_cfg()\n# cfg.MODEL.DEVICE = \"cpu\" # comment out this line if using a gpu\n# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0  # set threshold for this model\n# Find a model from detectron2's model zoo. You can use the https:\/\/dl.fbaipublicfiles... url as well\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\")\npredictor = DefaultPredictor(cfg)","b3539a6c":"index = 4 # an index to select one filtered sample\ninput_w = 640 # expected input width of the detectron2 model\ninput_h = 480 # expected input height of the detectron2 model\niou_thresh = 0.1\ndata = np.load(\"..\/input\/energy-detection-mid-resolution\/filtered.npy\")\nsample = data[index,:,:]","a3defa84":"def object_detection(sample, input_w, input_h, iou_thresh):\n    device = torch.cuda.current_device() \n    input = transform.resize(sample, (input_w, input_h)) # upsample the input image to expected input size of the detectron2 model\n    input_orig = torch.from_numpy(input).float().to(device)\n    input = F.normalize(input_orig) # Normalize data\n    input = torch.log(input) # Take log-scale of data\n    input = cv2.cvtColor(np.float32(input.cpu()),cv2.COLOR_GRAY2RGB) # convert grayscale input to 3 channel\n    outputs = predictor(input) # apply model inference on preprocessed data\n    # Process the output of model for further use in plotting\n    base_box = outputs['instances'].pred_boxes.tensor\n    base_score = outputs['instances'].scores.cpu().numpy()\n    nms_index = torchvision.ops.nms(base_box, outputs['instances'].scores, iou_thresh) # Applying nms on boxes to select reasonable outputs\n    box_nms = []\n    scores_nms = []\n    for i in nms_index:\n        box_nms.append(base_box[i].cpu().numpy())\n        scores_nms.append(base_score[i])\n    output_instance = detectron2.structures.Instances((input_w, input_h))\n    output_instance.set(\"pred_boxes\", detectron2.structures.Boxes(box_nms))\n    output_instance.set(\"scores\", torch.tensor(scores_nms))\n    return output_instance","a8968dbb":"# Save the algorithm output\noutputs = object_detection(sample, input_w, input_h, iou_thresh)\nout_name = \"object_detection_output.pickle\"\ntorch.save(outputs, out_name)","90147c6f":"outputs = torch.load(\"object_detection_output.pickle\")","23d7cadd":"# These are taken from the SETI energy detection github https:\/\/github.com\/FX196\/SETI-Energy-Detection\nMAX_PLT_POINTS      = 65536                  # Max number of points in matplotlib plot\nMAX_IMSHOW_POINTS   = (8192, 4096)           # Max number of points in imshow plot\n\nplt_args = {\n            'aspect':'auto',\n            'origin':'lower',\n            'rasterized':True,\n            'interpolation':'nearest',\n            'cmap':'viridis'\n            }\ndef plot_segment(plot_data):\n    dec_fac_x, dec_fac_y = 1, 1\n    if plot_data.shape[0] > MAX_IMSHOW_POINTS[0]:\n        dec_fac_x = int(plot_data.shape[0] \/ MAX_IMSHOW_POINTS[0])\n\n    if plot_data.shape[1] > MAX_IMSHOW_POINTS[1]:\n        dec_fac_y = int(plot_data.shape[1] \/ MAX_IMSHOW_POINTS[1])\n\n    print('Downsampling by a factor of (%d, %d)' %(dec_fac_x, dec_fac_y))\n    plot_data = rebin(plot_data, dec_fac_x, dec_fac_y)\n    plt.figure(figsize=(10, 6))\n    plt.imshow(plot_data, **plt_args)\n    \n# Modified based on the original plot_segment, plot data with detection box\ndef plot_segment_box(plot_data, boxes):\n    dec_fac_x, dec_fac_y = 1, 1\n    if plot_data.shape[0] > MAX_IMSHOW_POINTS[0]:\n        dec_fac_x = int(plot_data.shape[0] \/ MAX_IMSHOW_POINTS[0])\n\n    if plot_data.shape[1] > MAX_IMSHOW_POINTS[1]:\n        dec_fac_y = int(plot_data.shape[1] \/ MAX_IMSHOW_POINTS[1])\n    fig, ax = plt.subplots(1)\n    print('Downsampling by a factor of (%d, %d)' %(dec_fac_x, dec_fac_y))\n    plot_data = rebin(plot_data, dec_fac_x, dec_fac_y)\n    for i in boxes:\n        rect = patches.Rectangle(i[0], i[1], i[2],linewidth=1,edgecolor='r',facecolor='none')\n        ax.add_patch(rect)\n    plt.figure(figsize=(10, 6))\n    ax.imshow(plot_data, **plt_args)","cc6211fa":"# Select a sample from the data\nsample = data[index,:,:]","ff0e8a18":"plot_segment(sample)","4045778e":"# plot upsampled data\nplot_segment(transform.resize(sample, (input_w, input_h)))","39b43076":"# Process the proposed boxes generated from detectron2 models\npred_box = outputs.pred_boxes.tensor.cpu().numpy()\nboxes_plot = []\nfor i in pred_box:\n    boxes_plot.append([(i[0], i[1]), i[2]-i[0], i[3]-i[1]])","a9b51ad0":"# Plot upsampled data and detection boxes\nplot_segment_box(transform.resize(sample, (input_w, input_h)), boxes_plot)","572625dc":"## Introduction\nThe objective of this notebook is to identify and draw out interesting segmentation of signals from SETI observation data. In order to do so, we apply object detection algorithm using a pretrained detectron2 model (maskrcnn R50 + FPN). The data used in this notebook is preprocessed with energy detection algorithm posted at this repo: https:\/\/github.com\/FX196\/SETI-Energy-Detection. Generally, the algorithm shows promising results because the model is able to draw out regions with high energy input.\n\nNote: This notebook requires gpu to run.","3b79f22a":"### Run the object detection algorithm","14475644":"Define some functions for plotting data","ef95a9c3":"## Installing Required Packages","7bf6007d":"### Download Model from Detectron2","d795b886":"### Basic Setup","f9d1c42e":"This notebook allows you to run object detection algorithm, or load output from it","efde312f":"Plots","fda9e327":"### Visualize the Results","2c85dc0b":"### Or Load output from object detection algorithm"}}