{"cell_type":{"3613f7e7":"code","c0752a4c":"code","0cee142c":"code","2261746d":"code","9ad38e22":"code","9b5c70cc":"code","5221f7f0":"code","44a078e3":"code","417dcd76":"code","a8f4fd08":"code","d71f6c75":"code","dd837d1f":"code","7dfd9e63":"code","3b3f3d8b":"code","b8cd95d9":"code","d3caca7e":"code","7e7340c5":"code","951ecdde":"code","31027a3d":"code","6f5b5bbc":"code","63d4fc3b":"markdown","6e91fe59":"markdown","ae223dbf":"markdown","e20b3792":"markdown","224c707c":"markdown","16ffa9a9":"markdown","e414ca61":"markdown","2438dd12":"markdown","3f765276":"markdown","07341e97":"markdown","2ecf3e6c":"markdown","029d1d7b":"markdown","c0334203":"markdown","297a6c74":"markdown","9920f6af":"markdown","dc2df4a6":"markdown","7090e9d7":"markdown"},"source":{"3613f7e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c0752a4c":"# Importing libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn import linear_model, preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import neighbors, datasets \nfrom sklearn.model_selection import cross_val_predict, cross_validate","0cee142c":"# data import\ndf = pd.read_csv('..\/input\/predict-pizza-price\/Pizza-Price.csv',index_col=0)\ndf.replace(('yes', 'no'), (1, 0), inplace=True) # replace yes\/no by 1\/0 for modeling\ndf","2261746d":"df.describe()","9ad38e22":"df.info()","9b5c70cc":"corrMatrix = df.corr()\nsns.heatmap(corrMatrix, annot=True, cmap=\"coolwarm\")\nplt.show()","5221f7f0":"# Target distribution\n\nsns.displot(df['Price'],kde = True);","44a078e3":"# Representation of Price depending on Size\n\nplt.figure(figsize=(10,6))\nplt.scatter(df['Price'],df[' Size by Inch'],s=50);\nplt.title(\"Price evolution with Size\")\nplt.ylabel(\"Size\")\nplt.xlabel(\"Price\")\nplt.legend([\"Size by Inch\"])\nplt.show()","417dcd76":"# Representation of Size distribution\n\nplt.figure(figsize=(10,7))\nplt.pie(x=df[' Size by Inch'].value_counts(),labels = df[' Size by Inch'].value_counts().index,explode =[0.1,0.1,0.1,0.1], shadow = True);","a8f4fd08":"# Representation of Price depending on Extras\n\nfig, ((ax1, ax2, ax3)) = plt.subplots(3, 1,figsize=(12,12))\nfig.suptitle('Price by Extras')\nax1.scatter(df['Price'], df[\"Extra Mushroom\"], label='Extra Mushroom')\nax1.legend(loc=\"center\")\nax1.set_ylim([-0.1, 1.1])\nax2.scatter(df['Price'], df['Extra Cheeze'], label='Extra Cheeze',color='green')\nax2.legend(loc=\"center\")\nax3.scatter(df['Price'], df['Extra Spicy'], label='Extra Spicy', color='orange')\nax3.legend(loc=\"center\")\n\n\nfor ax in fig.get_axes():\n    ax.label_outer()","d71f6c75":"# Define features and target\n\ny = df['Price']\nx = df.drop(['Price'], axis=1)","dd837d1f":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(solver='liblinear')\nlr.fit(x,y)\nlr.score(x,y)","7dfd9e63":"from sklearn import svm\nclf = svm.SVC(gamma=0.01,kernel='poly')\nclf.fit(x, y)\nclf.score(x,y)\n","3b3f3d8b":"knn = neighbors.KNeighborsClassifier(n_neighbors=4,metric = 'minkowski')\nknn.fit(x, y)\nknn.score(x,y)\n","b8cd95d9":"from sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor()\nrf.fit(x,y)\nrf.score(x,y)","d3caca7e":"from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\ndt_clf = DecisionTreeClassifier()\ndt_clf.fit(x,y)\ndt_clf.score(x,y)","7e7340c5":"from sklearn.linear_model import LinearRegression\nlin_r = LinearRegression()\nlin_r.fit(x,y)\nlin_r.score(x,y)","951ecdde":"from sklearn.linear_model import ElasticNetCV\nmodel_en  = ElasticNetCV(cv=8,l1_ratio=(0.1, 0.25, 0.5, 0.7, 0.75, 0.8, 0.85, 0.9, 0.99), alphas=(0.001, 0.01, 0.02, 0.025, 0.05, 0.1, 0.25, 0.5, 0.8, 1.0))\nmodel_en.fit(x,y)\nmodel_en.score(x,y)","31027a3d":"print(\" LogisticRegression score = \", lr.score(x,y))\nprint(\" SVM score = \", clf.score(x,y))\nprint(\" KNN score = \", knn.score(x,y))\nprint(\" Random Forest = \", rf.score(x,y))\nprint(\" Decision Tree = \", dt_clf.score(x,y))\nprint(\" Linear Regression = \", lin_r.score(x,y))\nprint(\" Elastic Net = \", model_en.score(x,y))","6f5b5bbc":"# Example of predictions\nCheeze = [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1] # Cheeze parameter\nMushroom = [0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,] # Mushroom parameter\nSpicy = [0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,] # Spicy parameter\nSize = [8,8,8,8,9,9,9,9,12,12,12,12,15,15,15,15] # Size parameter\n\ndf_predict = pd.DataFrame({'Extra Cheeze':Cheeze , 'Extra Mushroom':Mushroom , 'Size by Inch': Spicy, 'Extra Spicy': Size}) # initialisation of a dataframe for prediction\nprice = rf.predict(df_predict) # predicted values\ndf_predict.insert(4, \"Price_predicted\", price) # merge with price predicted column\ndf_predict[\"Price_predicted\"] = df_predict[\"Price_predicted\"].astype(\"int\") # int format\ndf_predict","63d4fc3b":"### 4.1.5) Decision Tree","6e91fe59":"### 4.1.4) Random Forest","ae223dbf":"# 1) DataFrame Analyze","e20b3792":"# 6) Prediction","224c707c":" # 4) Modeling","16ffa9a9":"![getty_835271096_410065.jpg](attachment:6de4b43e-09b2-4fd1-9d86-3dec726f05ea.jpg)","e414ca61":"# Initialization","2438dd12":"### 4.2.1) Elastic Net","3f765276":"# 2) Data vizualisation","07341e97":"### 4.1.3) KNN","2ecf3e6c":"### 4.1.1) Logistic Regression","029d1d7b":"# 5 ) Scores","c0334203":"### 4.1.2) SVM","297a6c74":"### 4.2.1) Linear Regression","9920f6af":"# 3 ) Preprocessing","dc2df4a6":"## 4.1) Classification","7090e9d7":"## 4.2) Regression"}}