{"cell_type":{"be3effa6":"code","7c180c6b":"code","e81aa2e3":"code","449f613c":"code","60f44a62":"code","f9b89602":"code","ba835d91":"code","9dd5354c":"code","e5aed8f7":"code","9785a110":"code","87638684":"code","fab32c33":"code","111e0565":"markdown","de82ecf3":"markdown","514465f6":"markdown","e0f9b78a":"markdown","238733d0":"markdown"},"source":{"be3effa6":"import pandas as pd\nimport numpy as np\nimport random\n\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\n\ntorch.manual_seed(1)","7c180c6b":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","e81aa2e3":"train = pd.read_csv(\"..\/input\/2021-ai-w5-p1\/train.csv\")\ntest = pd.read_csv(\"..\/input\/2021-ai-w5-p1\/test.csv\")","449f613c":"train.head()","60f44a62":"r = random.randint(0, len(train) - 1)\nX_single_data = np.array(train.iloc[r,:-1])\n\n\nimport matplotlib.pyplot as plt\nplt.imshow(X_single_data.reshape(28,28))\nprint(train.iloc[r,0])","f9b89602":"# 0~255\nx_train = train.drop([\"label\"], axis=1)\nx_train \/= 255\nx_test = test \/ 255\ny_train = train.label","ba835d91":"x_train_data=torch.FloatTensor(np.array(x_train)).to(device)\ny_train_data=torch.LongTensor(np.array(y_train)).to(device)\nx_test_data=torch.FloatTensor(np.array(x_test)).to(device)\n\nprint(x_train_data.shape, y_train_data.shape)\nprint(x_test_data.shape)","9dd5354c":"# \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nlearning_rate = 1e-2\ntraining_epochs = 3000","e5aed8f7":"features = 28 * 28\nnbclass = 10\n\nW = torch.zeros((features, nbclass), requires_grad=True, device = device)\nb = torch.zeros(1, requires_grad=True, device = device)\n\noptimizer = optim.SGD([W, b], lr = learning_rate)\n\nfor epoch in range(training_epochs + 1):\n    \n    cost = F.cross_entropy((x_train_data.matmul(W) + b), y_train_data)\n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n    \n\n    # 100\ubc88\ub9c8\ub2e4 \ub85c\uadf8 \ucd9c\ub825\n    if epoch % 1000 == 0:\n        print('Epoch {:4d}\/{} Cost: {:.6f}'.format(\n            epoch, training_epochs, cost.item()))\n\nprint('Learning finished')","9785a110":"with torch.no_grad():\n    hypothesis = F.softmax(x_train_data.matmul(W) + b, dim=1)\n    predict = torch.argmax(hypothesis, dim=1)\n\n    correct_prediction = predict.float() == y_train_data\n    accuracy = correct_prediction.sum().item() \/ len(correct_prediction)\n    print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))","87638684":"with torch.no_grad():\n    hypothesis = F.softmax(x_test_data.matmul(W) + b, dim=1)\n    predict = torch.argmax(hypothesis, dim=1)","fab32c33":"submit = pd.read_csv(\"..\/input\/2021-ai-w5-p1\/sample_submit.csv\")\n\nfor i, value in enumerate(predict):\n    submit[\"label\"][i] =value.item()\n\nsubmit.label = submit.label.astype(int)\n    \nsubmit.to_csv(\"submit_10.csv\", index = False)","111e0565":"# Train Accuracy","de82ecf3":"# Train","514465f6":"# Set Parameters","e0f9b78a":"# Score Table\n\n\n| id | learning rate | epochs | score | baseline |\n|:---:|:---:|:---:|:---:|:---:|\n|01| 1e-2 |  500 | 0.8500 |   |\n|02| 1e-2 | 1000 | 0.8701 |   |\n|03| 1e-2 | 2000 | 0.8500 |   |\n|04| 1e-2 | 3000 | 0.8922 | \u2713 |\n|05| 1e-2 | 5000 | 0.9000 |   | \n|06| 1e-3 | 2000 | 0.8181 |   |\n|07| 1e-3 | 3000 | 0.8336 |   | \n|08| 1e-3 | 5000 | 0.8498 |   |\n|09| 1e-3 | 10000| 0.8700 | \u2713 |\n|10| 1e-4 | 5000 | 0.7582 |   |\n|11| 1e-4 | 10000| 0.7906 |   |\n|12| 1e-5 | 60000| 0.7640 |   |\n","238733d0":"# Visualization"}}