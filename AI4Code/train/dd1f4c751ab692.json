{"cell_type":{"2d3b7542":"code","5a114425":"code","9effaef4":"code","90d43373":"code","4ef0970d":"code","468f1b61":"code","fbc9ecd9":"code","e8add627":"code","d5ce3bd9":"code","990c5c85":"code","ef27f20a":"code","7d60b241":"code","357fcd37":"code","5609fb88":"code","6c65213a":"code","36ca359a":"code","e509637f":"code","edf3a231":"code","447bdefe":"code","16caed71":"code","452725d1":"code","816e9ab3":"code","0c4b0f4e":"code","c451a198":"code","8558b24a":"code","33a3a744":"code","f4d729d4":"code","90d519ef":"code","e6c928df":"code","a2a06957":"code","e24b0d36":"code","939aa597":"code","18be715a":"code","f11c7510":"markdown","10344911":"markdown","d5088c21":"markdown","ea2d529b":"markdown","4bfc3af0":"markdown","1c1692ee":"markdown","6030f46f":"markdown","947c5900":"markdown","32e6a450":"markdown","674d92d6":"markdown","0f31ff0f":"markdown","72634ba3":"markdown","7880c5cb":"markdown","cb1d5d8d":"markdown","5914d93d":"markdown","d9c9125c":"markdown","0c6baded":"markdown","bbcf96f8":"markdown","9b07a327":"markdown","b3b4e011":"markdown","44524367":"markdown","a47cfda7":"markdown","8b1b0908":"markdown","578d0f28":"markdown","56806b59":"markdown","30deef5e":"markdown","e219446a":"markdown","bebf2d5b":"markdown"},"source":{"2d3b7542":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#Importing libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5a114425":"#Importing data\ndata = pd.read_csv('..\/input\/500-person-gender-height-weight-bodymassindex\/500_Person_Gender_Height_Weight_Index.csv')\ndata.head()","9effaef4":"data.isnull().any()","90d43373":"#Seeing what columns we have, what the data types there are, \n#and what number of entries per column we have.\ndata.info()","4ef0970d":"# Set default plot grid\nsns.set_style('whitegrid')","468f1b61":"# Index Historgram: Frequency of values falling under each Index [0,1,2,3,4,5]\nplt.rcParams['figure.figsize'] = (6, 6)\nsns.countplot(data['Index'], palette='YlGnBu')\nax = plt.gca()\nax.set_title(\"Histogram of Index\")","fbc9ecd9":"# Height Historgram: Frequency of values falling under certain height intervals\nplt.rcParams['figure.figsize'] = (30, 10)\nsns.countplot(data['Height'], palette='YlGnBu')\nax = plt.gca()\nax.set_title(\"Histogram of Height\")","e8add627":"# Weight Historgram: Frequency of values falling under certain weight intervals\nplt.rcParams['figure.figsize'] = (30, 10)\nsns.countplot(data['Weight'], palette='YlGnBu')\nax = plt.gca()\nax.set_title(\"Histogram of Weight\")","d5ce3bd9":"# Plot relation between weight and height\nsns.jointplot(x='Weight', y='Height', data=data, kind='kde')","990c5c85":"# Trend in Gender based on relationship between Height and Weight\nsns.lmplot(x='Height', y='Weight', hue='Gender', data=data,\n           fit_reg=True, height=7, aspect=1.25, palette = \"Accent\")\nax = plt.gca()\nax.set_title(\"Height Vs Weight Data Grouped by Gender\")","ef27f20a":"# Trend in Index based on relationship between Height and Weight \nsns.lmplot(x='Height', y='Weight', hue='Index', data=data,\n           fit_reg=True, height=7, aspect=1.25, palette='Accent')\nax = plt.gca()\nax.set_title(\"Height Vs Weight Data Grouped by Index\")","7d60b241":"# Segregate data based on whether the gender is Male or Female\nmale_data = data[data['Gender']=='Male']\nfemale_data = data[data['Gender']=='Female']","357fcd37":"# Trend in Index based on relationship between Height and Weight \nmale_data = data[data['Gender']=='Male']\nfemale_data = data[data['Gender']=='Female']\nsns.lmplot(x='Height', y='Weight', hue='Index', data=male_data,\n           fit_reg=True, height=7, aspect=1.25,palette='Accent')\nax = plt.gca()\nax.set_title(\"Male Height Vs Weight Data Grouped by Index\")\n\nsns.lmplot(x='Height', y='Weight', hue='Index', data=female_data,\n           fit_reg=True, height=7, aspect=1.25,palette='Accent')\nax = plt.gca()\nax.set_title(\"Female Height Vs Weight Data Grouped by Index\")","5609fb88":"# Gives us basic correlation index for numerical variables\ndata.corr()","6c65213a":"# Provides visual context for correlations via color scale\nplt.rcParams['figure.figsize'] = (8, 7)\nsns.heatmap(data.corr(), annot=True)","36ca359a":"plt.rcParams['figure.figsize'] = (8, 7)\nsns.heatmap(male_data.corr(), annot=True)","e509637f":"plt.rcParams['figure.figsize'] = (8, 7)\nsns.heatmap(female_data.corr(), annot=True)","edf3a231":"# Ordinal Encoding\ndata[\"Gender\"] = data[\"Gender\"].astype('category')\ndata[\"Gender_Enc\"] = data[\"Gender\"].cat.codes\ndata.head()\n","447bdefe":"# One Hot Encoding\ndummies = pd.get_dummies(data['Gender'])\ndata = data.join(dummies)\ndata.head()","16caed71":"# Dropping last two columns with dummy values from one-hot encoding as they are redundant\ndata = data.drop(columns=['Male', 'Female'], axis=1)\ndata.head()","452725d1":"# Select columns to add to X and y sets\nfeatures = list(data.columns.values)\nfeatures.remove('Gender')\nfeatures.remove('Index')\nX = data[features]\ny = data['Index']","816e9ab3":"# Import additional required libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import confusion_matrix,classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score","0c4b0f4e":"# Import required class from sklearn library\nfrom sklearn.model_selection import train_test_split\n\n# Split X and y into train and test\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 0)","c451a198":"# Import required class from sklearn library\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Fit k-nearest neighbors classifier with training sets for n = 3\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)","8558b24a":"# Run a prediction\ny_pred = knn.predict(X_test)","33a3a744":"# Import remaining required classes from sklearn\nfrom sklearn.metrics import confusion_matrix,classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score","f4d729d4":"#Get confusion matrix\nprint(confusion_matrix(y_test,y_pred))","90d519ef":"# Get classification report\nprint(classification_report(y_test,y_pred))","e6c928df":"# Get accuracy score\nscore = np.mean(y_pred == y_test)\nprint(score)","a2a06957":"# Get error rate\nerror = np.mean(y_pred != y_test)\nprint(error)","e24b0d36":"sns.regplot(x=y_test, y=y_pred)","939aa597":"fig = sns.jointplot(x=y_test, y=y_pred, kind='hex')\nx0, x1 = fig.ax_joint.get_xlim()\ny0, y1 = fig.ax_joint.get_ylim()\nlims = [max(x0, y0), min(x1, y1)]\nfig.ax_joint.plot(lims, lims, ':k')    ","18be715a":"df = pd.DataFrame({ 'ytest':y_test,'ypred':y_pred})\nsns.residplot('ytest','ypred',data=df) ","f11c7510":"Once again, let's see if this changes for people of different genders.","10344911":"This means we have no null values in the data. Next we want to check:\n - what features we are working with\n - how much data there is","d5088c21":"### Prepare Data","ea2d529b":"(IN PROGRESS)","4bfc3af0":"## Importing Libraries and Data","1c1692ee":"We need to see if the data set is complete with valid entries. This means checking if there are:\n - any null value entries\n - an equal number of entries for all features (columns)","6030f46f":"## Building Model","947c5900":"Here we can see that the results from Ordinal Encoding and One-Hot Encoding are very similar.\n\nThe new column `Male` from One-Hot Encoding is the same as the column `Gender_Enc` from Ordinal Encoding.  <br \/>\nThis happens to be the case since we are working with the categorical variable `Gender` which only has two exclusive values in the data.\n\nSo, for this case it does not matter which encoded values for `Gender` we use.","32e6a450":"To test our model, we will:\n - Run and compare the models predictions to the real values using `X_test` and `y_test`\n - Produce a confusion matrix and classification report\n - Get mean accuracy scores and error rate for the model","674d92d6":"### Train Model","0f31ff0f":"Before moving on to creating the predictive model, we need to find a way to include our non-numeric variable which is the Gender.\nEven though we found that it does not \n\nKnowing gender is a categorical value (Male\/Female based on the data description) we need to encode the data for Gender to make it useable.\n\nThere are 2 ways we can do this:\n - Ordinal Encoding:\n     - Assign arbitrary numbers such as 1 to `Female` and 0 to `Male` (similar to a Boolean\/Truth value) to differentiate them\n     - End up with one new column with number values from 0 to n representing n unique values\n - One-Hot Encoding:\n     - Create dummy variables, where we produce new columns for `Female` and `Male` and have binary values (0 or 1) for each of them\n     - End up with n new columns representing n unique values, but we only use n-1 of these columns dropping the last one as it ends up being redundant in nature","72634ba3":"Since we want to predict what Index a person would be assigned based on their height, weight, and gender we will be making `Index` our target value or y. <br>\nSo, this makes our features `Height`, `Weight`, and `Gender_Enc` or X. <br>","7880c5cb":"### Test and Evaluate Model","cb1d5d8d":"We can first check the distribution of data","5914d93d":"# Exploratory Data Analysis","d9c9125c":"For making our predictive model we will need to proceed with certain steps:\n - Assign our data instances and target value (X and y columns)\n - Split data into training and test sets\n - Train our model\n - Test and evaluate the model","0c6baded":"We can also see if there are any correlation in the data by producing correlation matrices.","bbcf96f8":"## Processing Data","9b07a327":"This tells us that there are 4 feature columns - `Gender`, `Height`, `Weight`, and `Index` (BMI Index). \n\nKnowing that BMI is a calculated value, we can say that the variables we will be working with are `Gender`,`Height`, and `Weight`.\n\nWe can verify this with the data description given to us:\n\n>Gender : Male \/ Female\n\n>Height : Number (cm)\n\n> Weight : Number (Kg)\n\n>Index :\n0 - Extremely Weak, 1 - Weak, 2 - Normal, 3 - Overweight, 4 - Obesity, 5 - Extreme Obesity","b3b4e011":"We can make out distinct bands in the data based on the index value.\n\nSo, there is a general positive correlation between height and weight when categorized by index value.\n\nNow, let us see if there are any discrepencies in the relation when looking at each gender separately.","44524367":"The distribution of height vs weight does not follow any trends when categorized by gender.\n\nSo, we can hypothesize that gender does not affect the index\/BMI value significantly.","a47cfda7":"Let's compare the results of the predictor to the actual values using a plot.","8b1b0908":"Next we split the X and y data between the training set and testing set.","578d0f28":"Now that we have seen how well our model predicts index values, let us see if the results can compare to the output from using a formula for calculating BMI. <br>\nWe can compare performance based on accuracy and time complexity.","56806b59":"## Reviewing Data","30deef5e":"Here we will introduce our model and train it to fit the data we give it. <br>\nWe will be using the k-nearest neighbours algorithm first.","e219446a":"## Data Visualization\n\nNow we can start looking for trends in the data.","bebf2d5b":"From these figures we see that not all points lie on the line of equality (where `y_test` equals `y_pred` indicating a correct prediction. <br>\nThis tells us the model is not as accurate as we may like it to be."}}