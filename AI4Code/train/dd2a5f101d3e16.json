{"cell_type":{"7c136240":"code","d89b5c54":"code","07cc4517":"code","0f3d5dd4":"code","5024351b":"code","608caf51":"code","bf3b21a6":"code","55ad49f4":"code","d04aeaff":"code","f166d6ea":"code","5e2110f5":"code","e0496228":"code","4dce5302":"code","3b3ccd16":"code","891931f4":"code","772f8609":"code","7c312314":"code","0560c3ec":"code","a3b64761":"code","1c7cadfd":"code","ea4fc9d2":"code","41cf8f62":"markdown","4fbcc02b":"markdown","1c29d696":"markdown","b9fd30b7":"markdown","30a167da":"markdown","026eee92":"markdown","0be108bd":"markdown","0a804a20":"markdown","4cad7c6a":"markdown","a4510ca8":"markdown","58349798":"markdown","fde5f38b":"markdown","2678538f":"markdown"},"source":{"7c136240":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#sns.set()\n#%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d89b5c54":"df = pd.read_csv('..\/input\/facebook-ads\/Facebook_Ads_2.csv', encoding = 'ISO-8859-1')\ndf.head()","07cc4517":"# define a variable for peaple who click & don't clicked the ads\nclicked = df[df['Clicked'] == 1]\nclicked","0f3d5dd4":"not_clicked = df[df['Clicked'] == 0]\nnot_clicked","5024351b":"# show summary of the datasets based on the information of the peaple who click & don't click the Ad\n\nprint('Total =', len(df))\n\nprint('Number of customers who clicked on Ad =', len(clicked))\nprint('Percentage Clicked =', 1.*len(clicked) \/ len(df) * 100.0,'%')\n\nprint(\"Number of customers who doesn't clicked on Ad\", len(clicked))\nprint(\"Percentage of who doesn't clicked on Ad\", 1.*len(clicked) \/ len(df) * 100.0,'%')","608caf51":"sns.set(rc={'figure.figsize':(15,10)})\nsns.scatterplot(data=df, x=df['Time Spent on Site'], y=df['Salary'], hue = df['Clicked'])","bf3b21a6":"df.head()","55ad49f4":"# while i want to do a model prediction so i need to remove catogrical columns that i don't need in predict proccess \ndf.drop(['Names', 'emails', 'Country'], axis=1, inplace=True)\ndf.head()","d04aeaff":"# let's now define X and y for the spilting\nX = df.drop('Clicked',axis=1).values\ny = df['Clicked'].values","f166d6ea":"from sklearn import preprocessing\n# defining X \n# Scale the inputs using 'preprocessing.scale()' which scales each variable (column in X) with respect to itself\nX = preprocessing.scale(X)","5e2110f5":"#from sklearn.preprocessing import StandardScaler\n#sc = StandardScaler\n#X = sc.fit_transform(X) ","e0496228":"from sklearn.model_selection import train_test_split","4dce5302":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","3b3ccd16":"# Let's now build the model\nfrom sklearn.linear_model import LogisticRegression","891931f4":"clf = LogisticRegression()","772f8609":"clf.fit(X_train, y_train)","7c312314":"y_pred = clf.predict(X_test)\ny_pred","0560c3ec":"y_test","a3b64761":"from sklearn.metrics import confusion_matrix, accuracy_score , classification_report","1c7cadfd":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred) * 100\nsns.heatmap(cm, annot=True, fmt='d')","ea4fc9d2":"# Visualising the Training set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, clf.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('orange', 'blue')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('orange', 'blue'))(i), label = j)\nplt.title('Facebook Ad: Customer Click Prediction (Testing set)')\nplt.xlabel('Time Spent on Site')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","41cf8f62":"### Importing Dataset & Extracting Features","4fbcc02b":"### Data Exploration (EDA)","1c29d696":"# Dataset\n#### You can fine the dataset Here (https:\/\/www.kaggle.com\/reddynitin\/facebook-ads)","b9fd30b7":"### Now let's visualize the split training model and see what it's show","30a167da":"### Model Evaluation & Prediction ","026eee92":"#### it seems good ;) let's evaluate","0be108bd":"### Data Splitting & Preprocessing","0a804a20":"#### It gives 86% & i think it's good score for regression model so i will accepted the score","4cad7c6a":"### Model Training & Predicting","a4510ca8":"## Please leave an upvote and comment to helps me continue my data science journy and improves my work. Thanks","58349798":"# Introduction \n  \n#### In this project i will using logistic regression model to predict if the customer will click in the adversiting link based in there salaries and time spent in the facebook site \/ app ","fde5f38b":"### Importing Libraries","2678538f":"## Libraries and tools using in this project \n\n#### 1 - Python\n#### 2 - Pandas\n#### 3 - Numpy\n#### 4 - Scikit-Learn\n#### 5 - Matplotlib\n#### 6 - Seaborne"}}