{"cell_type":{"219ab258":"code","9982887e":"code","70afa7bd":"code","95f1e8f4":"code","a23e1f53":"code","ed533193":"code","dda1de36":"code","6cae0e9a":"code","a4442f4f":"code","78f6ba86":"code","2bc2f826":"code","6e4f01b9":"code","042a9448":"code","8eaa1d20":"code","417c4587":"code","59022a9f":"code","85f5ac6d":"code","a3b4c3d5":"code","536c17bf":"code","9a7435e2":"code","6994429f":"code","50257a20":"code","5796cf1c":"code","4d0dde32":"code","43d4b06b":"code","472db6d4":"code","281a782f":"code","4aabe4d4":"code","eaab84d3":"code","b0d79c83":"code","54bf314f":"code","61bb95c2":"code","039461b3":"code","c23567aa":"code","155a1269":"code","dc395ee5":"code","b31a81ad":"markdown","2bbe9412":"markdown","74b1c085":"markdown","a55822ed":"markdown"},"source":{"219ab258":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9982887e":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","70afa7bd":"df=pd.read_csv('\/kaggle\/input\/fetal-health-classification\/fetal_health.csv')\ndf.head()","95f1e8f4":"# shape of datset\nprint(f'rows : {df.shape[0]}')\nprint(f'columns : {df.shape[1]}')","a23e1f53":"# info of dataset\ndf.info()","ed533193":"# nan values\ndf.isna().sum()","dda1de36":"# hence no nan values","6cae0e9a":"# statistical info of dataset\ndf.describe().T","a4442f4f":"# correlation matrix for the dataset\nplt.figure(figsize=(15,15))\nsns.heatmap(df.corr(), annot=True)","78f6ba86":"sns.countplot(df['fetal_health'])","2bc2f826":"# 1: Normal, 2; suspect, 3: pathologic","6e4f01b9":"# boxplots\nfig, axes=plt.subplots(7,3, figsize=(20,25))\nfor i,j in enumerate(df.columns):\n  ax=axes[int(i\/3), i%3]\n  sns.boxplot(df[j], ax=ax)\n","042a9448":"y=df['fetal_health']\nX=df.drop('fetal_health', axis=1)","8eaa1d20":"# distribution plot of dataset\nfig, axes=plt.subplots(11,2, figsize=(20,20))\nfor i,j in enumerate(df.columns):\n  ax=axes[int(i\/2), i%2]\n  sns.distplot(df[j], ax=ax)","417c4587":"# scaling the dataset\nfrom sklearn.preprocessing import StandardScaler\nscalar=StandardScaler()\nX=scalar.fit_transform(X)","59022a9f":"from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\nfrom sklearn.linear_model import LogisticRegression","85f5ac6d":"X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3, random_state=42)","a3b4c3d5":"# shape after spliting\nprint('shape after spliting')\nprint('*'*30)\nprint(f'X_test : {X_test.shape}')\nprint(f'X_train : {X_train.shape}')\nprint(f'y_test : {y_test.shape}')\nprint(f'y_train : {y_train.shape}')","536c17bf":"# logistic regression\nlor=LogisticRegression()\nlor.fit(X_train,y_train)\npred_lor=lor.predict(X_test)\nscore_lor=cross_val_score(lor,X,y,cv=5)\nprint(score_lor)","9a7435e2":"score_lor.mean()","6994429f":"# classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nreport_lor=classification_report(y_test,pred_lor)\nprint(report_lor)","50257a20":"# 88% accuracy for logistic regression","5796cf1c":"# confusion matrix\ncm=confusion_matrix(y_test,pred_lor)\nsns.heatmap(cm,annot=True)\nplt.xlabel('Predicted Value')\nplt.ylabel('Actual Values')","4d0dde32":"# random forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrf.fit(X_train,y_train)\npred_rf=rf.predict(X_test)\nscore_rf=cross_val_score(rf,X,y,cv=5)\nprint(score_rf)","43d4b06b":"score_rf.mean()","472db6d4":"# classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nreport_rf=classification_report(y_test,pred_rf)\nprint(report_rf)\n\n# confusion matrix\ncm=confusion_matrix(y_test,pred_rf)\nsns.heatmap(cm,annot=True)\nplt.xlabel('Predicted Value')\nplt.ylabel('Actual Values')","281a782f":"# 94% accuracy with random forest classification","4aabe4d4":"# decision tree\nfrom sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(X_train,y_train)\npred_dt=dt.predict(X_test)\nscore_dt=cross_val_score(dt,X,y,cv=5)\nprint(score_dt)","eaab84d3":"score_dt.mean()","b0d79c83":"# classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nreport_dt=classification_report(y_test,pred_dt)\nprint(report_dt)\n\n# confusion matrix\ncm=confusion_matrix(y_test,pred_dt)\nsns.heatmap(cm,annot=True)\nplt.xlabel('Predicted Value')\nplt.ylabel('Actual Values')","54bf314f":"# 94% accuracy with decision tree classification","61bb95c2":"# xgb classifier\nfrom xgboost import XGBClassifier\nxgb=XGBClassifier()\nxgb.fit(X_train,y_train)\npred_xgb=xgb.predict(X_test)\nscore_xgb=cross_val_score(xgb,X,y,cv=5)\nprint(score_xgb)","039461b3":"score_xgb.mean()","c23567aa":"# classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nreport_xgb=classification_report(y_test,pred_xgb)\nprint(report_xgb)\n\n# confusion matrix\ncm=confusion_matrix(y_test,pred_xgb)\nsns.heatmap(cm,annot=True)\nplt.xlabel('Predicted Value')\nplt.ylabel('Actual Values')","155a1269":"# 95% accuracy with XGB classifier","dc395ee5":"# hence XGB classfier with 95% accuracy","b31a81ad":"# Importing of Libraries and Dataset","2bbe9412":"# Model Building","74b1c085":"# EDA and Visualization","a55822ed":"# Preprocessing"}}