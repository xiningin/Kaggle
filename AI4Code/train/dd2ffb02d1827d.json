{"cell_type":{"cbf23d3b":"code","15b312f6":"code","1051e4d6":"code","715b0219":"code","e9c5af2e":"code","4303a3b6":"code","ad238af0":"code","bf7a13ea":"code","7f70b3b7":"code","f58e2a36":"code","3158ff63":"code","d506d21d":"code","b52492c3":"code","0843b815":"code","15a44306":"code","b6faf9cf":"code","6461513e":"code","02fc1316":"code","6cc60109":"code","7f9c782b":"code","097272e5":"code","92a2c567":"code","8df5885b":"code","23b54821":"code","1180202c":"code","88a19665":"code","783d7403":"code","5f4577b8":"code","fec60507":"code","1a5ee509":"code","1664a2c4":"code","638cea74":"code","f36b49a3":"code","4eaf9da0":"code","61a55b30":"code","b274ad2c":"code","3187bc64":"code","a44922ae":"code","74fe69ae":"code","7ecc3fb6":"code","6adf03a0":"code","d00fde0f":"code","636f70f4":"code","6cc0ca7d":"code","deb9cfec":"code","a461b9d9":"code","53045ddc":"code","6e9c881d":"code","f8390545":"code","7666283c":"code","e0b6e33e":"code","842a2d35":"code","684ab97a":"code","d938c8a4":"code","23f9fabb":"code","7cd3d10b":"code","bab038bb":"code","bb6945ac":"code","7dc75071":"code","c5b03d52":"code","f5cd66f0":"code","150e76a8":"code","7ab8d8ac":"code","e9d1b710":"code","0ec6a247":"code","cad04f94":"code","e0ffbb1c":"code","1b979709":"markdown","f3e13c92":"markdown","dd6bb5d7":"markdown","0ad6234d":"markdown","0a359eb6":"markdown","e7ed432a":"markdown","a4891cfd":"markdown","e1f4128a":"markdown","a5fe2bb1":"markdown","74f447fc":"markdown","2c4e4536":"markdown","1a38f31a":"markdown","b62a409c":"markdown","f8e57add":"markdown","f47159a9":"markdown","3d259063":"markdown","c4631d92":"markdown","24c65f75":"markdown","ca720a39":"markdown","69a91a24":"markdown","81afdb58":"markdown","27e286a5":"markdown","c20007f5":"markdown","8c03fdcd":"markdown","418eba49":"markdown","00677326":"markdown","9bc10673":"markdown","16ccce30":"markdown","9fee7559":"markdown","339246a8":"markdown","3ecc8f53":"markdown","b9c33271":"markdown","f8365f76":"markdown","f210909e":"markdown","b427c44a":"markdown","a296b4cc":"markdown","f59c3fa6":"markdown","1f959b66":"markdown","df3da186":"markdown","4912467c":"markdown","231dcf67":"markdown"},"source":{"cbf23d3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","15b312f6":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import set_config","1051e4d6":"pd.options.mode.chained_assignment = None  # default='warn'","715b0219":"data = pd.read_csv(\"..\/input\/used-car-auction-prices\/car_prices.csv\",low_memory=False ,names=range(17))\ndata.head(5)","e9c5af2e":"data.iloc[408162]","4303a3b6":"# create an empty list and fill it with the index of all not NaN-values in column 16\nfaulty_entry_rows = []\n\nfor index, row in data[16].notna().iteritems():\n    if row == True:\n        faulty_entry_rows.append(index)\n        \n# 26 rows have to many entries, these rows will be dropped from the dataset        \nprint(\"Number of entries with too many columns: \",len(faulty_entry_rows))\n\ndata.drop(labels=faulty_entry_rows, axis=0, inplace=True)\n\n# drop column 16\ndata.drop(labels=16, axis=1, inplace=True)\n\n# new column names\ncolumn_names = data.iloc[0]\n\ndata.columns = column_names\n\n# drop first row --> names are now the headers\ndata.drop(labels=0, axis=0, inplace=True)","ad238af0":"data.head()","bf7a13ea":"data.info()","7f70b3b7":"data.describe()","f58e2a36":"len(data)","3158ff63":"data = data.drop_duplicates()\nlen(data)","d506d21d":"# Percentage of missing values\ndata.isnull().sum().sort_values(ascending=False)\/len(data)*100","b52492c3":"round(data.transmission.value_counts()\/sum(data.transmission.value_counts())*100,2)","0843b815":"data.transmission = data.transmission.fillna(\"automatic\")","15a44306":"data.body.unique()","b6faf9cf":"data.body = data.body.str.lower()","6461513e":"plt.figure(figsize=(9,5))\nchart = sns.countplot(x=data.body)\nchart.set_xticklabels(chart.get_xticklabels(), rotation=90);","02fc1316":"def number_cars_in_type(car_type):\n    '''takes car type e.g. suv and calculates the absolute number of suv models '''\n    car_dict = {}\n    \n    for index, car_number in data.body.value_counts().iteritems():\n        if car_type in index:\n            car_dict[f\"{index}\"] = car_number\n            \n    return car_dict","6cc60109":"def percentage_body_type(car_type):\n    '''calculates percentage of specific car body type'''\n    body_type_series = pd.Series(number_cars_in_type(car_type))\n    \n    body_perc = sum(body_type_series)\/sum(data.body.value_counts())\n    \n    return body_perc","7f9c782b":"body_type_list = [\"sedan\",\"suv\",\"cab\",\"hatchback\",\"coupe\",\"van\",\"convertible\",\"wagon\"]\n\nfor i in body_type_list:\n    print(\"Share of {} cars in dataset: \".format(i),round(percentage_body_type(i)*100,2),\"%\")","097272e5":"# number of nan values in the body column\nmissing_body_values = data.body.isnull().sum()\nmissing_body_values","92a2c567":"# calculate the absolute number of missing values per body type according to the percentage\nbody_perc_dict = {}\n\nfor i in body_type_list:\n    body_perc_dict[f\"{i}\"] = percentage_body_type(i)\n    \n\nfor key, value in body_perc_dict.items():\n    body_perc_dict[key] = round(value * missing_body_values)","8df5885b":"body_perc_series = pd.Series(body_perc_dict)\n\ncounter_body_perc = 0\n\nfor key, value in body_perc_series.iteritems():\n    if counter_body_perc <= body_perc_series[key]:\n        data.body = data.body.fillna(key)\n        counter_body_perc += 1","23b54821":"def standardise_body_types(batch):\n    '''standardises models types into specific body types'''\n    for index, value in batch.iteritems():\n        if \"suv\" in value:\n            batch[index] = \"suv\"\n        elif \"sedan\" in value:\n            batch[index] = \"sedan\" \n        elif \"convertible\" in value:\n            batch[index] = \"convertible\" \n        elif \"hatchback\" in value:\n            batch[index] = \"hatchback\" \n        elif \"coupe\" in value:\n            batch[index] = \"coupe\"\n        elif \"koup\" in value:\n            batch[index] = \"coupe\"\n        elif \"van\" in value:\n            batch[index] = \"van\"\n        elif \"cab\" in value:\n            batch[index] = \"cab\"\n        elif \"supercrew\" in value:\n            batch[index] = \"cab\"\n        elif \"wagon\" in value:\n            batch[index] = \"wagon\"\n        else:\n            pass \n        \n    return batch","1180202c":"# Split the big dataset into 20 batches, this should be less computationally costly \nbatch_list = np.array_split(data.body, 20)\n    \nfor batch in batch_list:\n    standardise_body_types(batch)\n\nnew_body_series = pd.concat(batch_list, axis=0)\nnew_body_series.value_counts()","88a19665":"data.drop(\"body\", axis=1, inplace=True)\ndata[\"body_new\"] = new_body_series","783d7403":"condition_y = data.condition.value_counts().sort_index()\ncondition_x = data.condition.value_counts().sort_index().index\n\n\nplt.figure(figsize=(12,5))\nsns.barplot(x=condition_x, y=condition_y).set(title=\"Distribution of measured conditions\", xlabel=\"Condition\", ylabel=\"Amount\");","5f4577b8":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n#imputer.fit([data.condition])\ndata.condition = imputer.fit_transform(data[[\"condition\"]])","fec60507":"data.condition.isnull().sum()","1a5ee509":"data.trim.nunique()","1664a2c4":"data.trim.value_counts().tail(20)","638cea74":"data.model.nunique()","f36b49a3":"data.model.value_counts().head(10)","4eaf9da0":"condition_y = data.model.value_counts().sort_index()\ncondition_x = data.model.value_counts().sort_index().index\n\n\nplt.figure(figsize=(12,5))\nsns.barplot(x=condition_x, y=condition_y).set(title=\"Distribution of measured conditions\", xlabel=\"Condition\", ylabel=\"Amount\");","61a55b30":"data.model.fillna(\"Altima\", inplace=True)","b274ad2c":"data.make.unique()","3187bc64":"len(data.make.unique())","a44922ae":"# lowercase all data \ndata.make = data.make.str.lower()\n\n# Already reduced the number of unique manufacturers \nlen(data.make.unique())","74fe69ae":"plt.figure(figsize=(12,5))\nchart = sns.countplot(x=data.make)\nchart.set_xticklabels(chart.get_xticklabels(), rotation=90);","7ecc3fb6":"data.make.fillna(\"ford\", inplace=True)","6adf03a0":"def standardise_body_types(batch):\n    '''standardises models types into specific body types'''\n    for index, value in batch.iteritems():\n        if \"chev\" in value:\n            batch[index] = \"chevrolet\"\n        elif \"ford\" in value:\n            batch[index] = \"ford\" \n        elif \"hyundai\" in value:\n            batch[index] = \"hyundai\" \n        elif \"vw\" in value:\n            batch[index] = \"volkswagen\" \n        elif \"dodge\" in value:\n            batch[index] = \"dodge\"\n        elif \"merced\" in value:\n            batch[index] = \"mercedes\"\n        elif \"mazda\" in value:\n            batch[index] = \"mazda\"\n        elif \"rover\" in value:\n            batch[index] = \"landrover\"\n        elif \"gmc\" in value:\n            batch[index] = \"gmc\"\n        else:\n            pass \n        \n    return batch","d00fde0f":"batch_list = np.array_split(data.make, 20)\n    \nfor batch in batch_list:\n    standardise_body_types(batch)\n\nnew_make_series = pd.concat(batch_list, axis=0)\nnew_make_series.value_counts().head()","636f70f4":"print(\"There are \",new_make_series.nunique(),\"different car manufacturers listed in this dataset\")","6cc0ca7d":"data.drop(\"make\", axis=1, inplace=True)\ndata[\"make_new\"] = new_make_series","deb9cfec":"print(\"Number of cars with unknown color: \",data.color.isnull().sum())\n\ndata.color.value_counts().head(7)","a461b9d9":"# The 749 NaN values are assigned to the color black, since it is the most common\ndata.color.fillna(\"black\", inplace=True)","53045ddc":"def calc_percentage(column):\n    '''Calculate the percentage of each unique  element based on the population'''\n    color_perc_dict = {}\n    \n    for index, row in column.value_counts().iteritems():\n        color_perc_dict[f\"{index}\"] = row\/sum(data.color.value_counts())\n        \n    return color_perc_dict\n\ncolor_dict = calc_percentage(data.color)","6e9c881d":"def turn_percentage_into_absolute(column):\n    '''turn percentages into actual amount per color that needs to be distributed'''\n    column_dict = calc_percentage(column)\n    \n    for key, value in column_dict.items():\n        if len(key) > 1:\n            amount = value * column.value_counts()[\"\u2014\"]\n            column_dict[key] = round(amount)\n        \n    column_dict.pop(\"\u2014\", None)\n    \n    # Since the percentages need to be rounded and do not quite yield the same amount than \"absolute_minus\"\n    # the small delta is added to the black values, since it is the largest amount\n    delta = column.value_counts()[\"\u2014\"] - sum(column_dict.values())\n    column_dict[\"black\"] = column_dict[\"black\"] + delta\n    \n    return column_dict","f8390545":"def index_of_minus(column):\n    '''The list of indices of \"-\" will be used to fill data.color with colors'''\n    minus_index_list = []\n    \n    for index, value in column.iteritems():\n        if value == \"\u2014\":\n            minus_index_list.append(index)\n            \n    return minus_index_list\n\n\ndef create_series(column):\n    '''Transform the color_dict into series with indices of \"-\" values and as many rows per color as the amount of value in color_dict'''\n    minus_index_list = index_of_minus(column)\n    series_list = []\n    \n    for key, value in turn_percentage_into_absolute(column).items():\n        series = pd.Series(key, index= range(0,value))\n        series_list.append(series)\n        \n    column_series = pd.concat(series_list, axis=0)\n    # dict() work-around --> can't Series(zip())\n    column_series = dict(zip(minus_index_list, column_series))\n    \n    column_series = pd.Series(column_series)\n    \n    return column_series","7666283c":"color_series = create_series(data.color)","e0b6e33e":"# replace the the \"-\" values by indexing the color_series\nfor index, color in color_series.iteritems():\n    data.color[index] = color","842a2d35":"plt.figure(figsize=(12,5))\nchart = sns.countplot(x=data.color)\nchart.set_xticklabels(chart.get_xticklabels(), rotation=45);","684ab97a":"data.interior.unique()","d938c8a4":"print(\"Number of cars with unknown interior color: \",data.interior.isnull().sum())\n\ndata.interior.value_counts().head(5)","23f9fabb":"# The 749 NaN-Values are filled with \"black\", since it is a very small proportion of the complete dataset and black is the most common color \ndata.interior.fillna(\"black\", inplace=True)","7cd3d10b":"interior_series = create_series(data.interior)\n\n# replace the the \"-\" values by indexing the color_series\nfor index, color in interior_series.iteritems():\n    data.interior[index] = color\n    \nplt.figure(figsize=(12,5))\nchart = sns.countplot(x=data.interior)\nchart.set_xticklabels(chart.get_xticklabels(), rotation=45);","bab038bb":"imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\ndata.odometer = imputer.fit_transform(data[[\"odometer\"]])","bb6945ac":"data.year = pd.to_numeric(data.year)\ndata.sellingprice = pd.to_numeric(data.sellingprice)","7dc75071":"fig, ax = plt.subplots(1,2,figsize=(8,5))\nfig.tight_layout(pad=4)\nindex = 0\nfor column in [data.year,data.sellingprice]:\n    sns.boxplot(y=column, ax=ax[index])\n    index += 1","c5b03d52":"data.head(5)","f5cd66f0":"body_x = data.body_new.value_counts()\nbody_y = data.body_new.value_counts().index\n\nsns.barplot(x=body_x, y=body_y, palette=\"crest\").set(title=\"Different car body types\")","150e76a8":"sns.scatterplot(x=data.sellingprice,y=data.odometer).set(title=\"Correlation between price and odometer\")","7ab8d8ac":"sns.catplot(x=\"sellingprice\", y=\"body_new\",kind=\"violin\", data=data).set(title=\"Car prices depending on type\")","e9d1b710":"sns.catplot(x=\"year\", y=\"sellingprice\", kind=\"boxen\", data=data, height=5, aspect=3).set(title=\"Influence of manufacturing date on price\")","0ec6a247":"sns.pairplot(data)","cad04f94":"scaler = StandardScaler()\n\nfor col in [\"year\",\"odometer\",\"condition\"]:\n    scaler.fit(data[[f\"{col}\"]])\n    data[f\"{col}\"] = scaler.transform(data[[f\"{col}\"]])","e0ffbb1c":"# Through encoding all categorical variables, the dataset is inflated by alot. When selecting variables for a model, the features should be selected wisely. \n\nfor col in [\"body_new\",\"make_new\",\"transmission\",\"color\",\"interior\"]:\n    dummies = pd.get_dummies(data[f\"{col}\"])\n    data = pd.concat([data, dummies], axis=1)\n    data = data.drop(col, axis=1)","1b979709":"#### Transmission\nAlmost 12% of all transmission values are missing","f3e13c92":"<a id=\"duplicates\"><\/a>\n### 1.3 Duplicates","dd6bb5d7":"#### Trim ","0ad6234d":"<a id=\"preprocessing\"><\/a>\n## 3.0 Preprocessing","0a359eb6":"![error_import.PNG](attachment:7e971714-15fa-4f11-b55f-81f2f4f36ac3.PNG)\n\n\nWhen importing this dataset you will encounter this error message. There is at least one row with faulty data entry. For now the solution is to give the names parameter to pd.read_csv and increase to column numbers. We will tackle this problem very soon ;)","e7ed432a":"<a id=\"visualization\"><\/a>\n## 2.0 Visualization","a4891cfd":"The violinplots tell us that most car types have very similar mean prices, although suvs, sedans, convertibles and coupes be very exspensive. Ranging from 170.000 to 230.000 dollars. ","e1f4128a":"There are no duplicate values in this dataset ","a5fe2bb1":"Similar to the color column, about 17k values are marked as \"-\". Now I can call the \"create_series\" function on the interior column and it will split up the values according to the interior color distribution. ","74f447fc":"<a id=\"encoding\"><\/a>\n### 3.2 Encoding","2c4e4536":"### Let's gooo... now we have data we can work with !","1a38f31a":"#### Interior","b62a409c":"Fill the NaN values with following values according to percentage!","f8e57add":"# Project Overview\n## [1.0 Data cleaning](#cleaning)\n### [1.1 Data entry errors](#entry)\n### [1.2 Overview](#overview)\n### [1.3 Duplicates](#duplicates)\n### [1.4 Missing data](#missing)\n### [1.5 Outliers](#outliers)\n## [2.0 Visualization](#visualization)\n## [3.0 Preprocessing](#preprocessing)\n### [3.1 Scaling](#scaling)\n### [3.2 Encoding](#encoding)\n### [3.3 Balancing](#buffering)","f47159a9":"<a id=\"cleaning\"><\/a>\n## 1.0 Data cleaning","3d259063":"There is clearly a trend that newer cars are more valueable than older ones. There might be a slight increase in car prices once cars become older than 20 years, because then they officially become \"classic\". ","c4631d92":"An overwhelming 96% of all known cars has an automatic transmission. Because of this the missing data in the transmission column will be updated with \"automatic\".","24c65f75":"<a id=\"buffering\"><\/a>\n### 3.3 Balancing","ca720a39":"#### Odometer","69a91a24":"Looking at the distribution of the data I think it would make sense to impute the mean() of the conditions into the NaN-values. ","81afdb58":"By examining the unique values in the \"make\" column (manufacturer), I noticed that some of the names are capitalized and others are lowercase. Just like in the \"body\" column. \nFurthermore the data entry was not standardized. There are entries called \"vw\" and others are \"volkswagen\" etc. ","27e286a5":"Since these values are not standardised and all manufacturers have the same furnishing, I will drop this column in the feature selection chapter. Also there are 1975 different styles and this seems not sensible for my model.","c20007f5":"<a id=\"missing\"><\/a>\n### 1.3 Missing data","8c03fdcd":"Most likely I will also not include the model into my machine learning model, but just in case I filled the missing values with the most common model type \"Altima\"","418eba49":"#### Body","00677326":"Before we can create the final list. We should look at the distribution of the car \"makers\".","9bc10673":"![tintout.png](attachment:78d65ddb-e911-453c-ae7d-2f9187e30abe.png)","16ccce30":"<a id=\"entry\"><\/a>\n### 1.2 Overview","9fee7559":"<a id=\"entry\"><\/a>\n### 1.1 Data entry errors","339246a8":"Problem: The column \"Transmission\" contains almost exclusively \"automatic\" as a value. The few cars in the record that have a manual transmission, will not really have an impact on the weight of \"Transmission\". \nThere are two different solutions for this problem:\n\n * 1) Do not include the column transmission into the model\n * 2) Balancing\n \n ![balancing.PNG](attachment:01e844d9-1d94-4506-a015-a82db1310aa4.PNG)\n \n \n #### Balancing\n Is the action if duplicating instances of the minority class (oversampling) or redcuing the majority class (undersampling). Since oversampling means making copies of already existing entries, this can cause data leakage between training and testing set.\nThere is another alternative to regular oversampling called SMOTE - Synthetic Minority Oversampling Technique. New datapoints are generated on a linear basis from the minority instances. \n\nIn this situation I would probably delete the \"Transmission\" column, since the difference in frequency of the instances is very extreme. ","3ecc8f53":"#### Color","b9c33271":"Here we encounter multiple problems:\n* 1) Some of the entries are lowercase others are uppercase\n* 2) We are only interested in the body, but some entries have specific names indicating        the manufacturer (e.g. g sedan, g coupe, elantra coupe, ...)","f8365f76":"<a id=\"outliers\"><\/a>\n### 1.5 Outliers","f210909e":"#### Make","b427c44a":"This dataset was very dirty and I took some time to really dig deep and clean it for machine learning models. It is alot of code so feel free to use the links above to navigate the project :) ","a296b4cc":"Actually convert all bodies into standardised body types\n","f59c3fa6":"#### Model","1f959b66":"#### Condition","df3da186":"<a id=\"scaling\"><\/a>\n### 3.1 Scaling","4912467c":"Unfortunately I noticed that in the color column two different ways of giving no information were used. \n* 1) np.nan (749 NaN-values)\n+ 2) \"-\" (~ 24700 values)\n\nSince there are almost 24.7k values marked as \"-\" filling all these values with \"black\" could potentially effect the accuracy of the ml model. ","231dcf67":"In order to increase performance and usability I decided to convert all car types into eight overriding classes. I looked up the different car types and they differ in size, but most of them have a very low proportion in the overall dataset and I believe these would decrease a models performance. "}}