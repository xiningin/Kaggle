{"cell_type":{"bb58c15b":"code","925479a9":"code","aae18aa0":"code","d5d8502c":"code","2cd8bc59":"code","5ff7f2bf":"code","dfa0f343":"code","b6092265":"code","3714fda7":"code","a8e99b27":"code","d494658e":"code","a6fc07e2":"code","9914ac01":"code","a5d41e9b":"code","8bc2c7c0":"code","f06d1fa5":"code","ef8e5c01":"code","7f4ca1e0":"markdown","da094cfa":"markdown","1f42f981":"markdown","d88318be":"markdown","373f5348":"markdown","59a01e4c":"markdown","b1ec721a":"markdown","9cac3faf":"markdown","dcb939ee":"markdown"},"source":{"bb58c15b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, BatchNormalization, Activation\nfrom keras.layers import Add, Flatten, AveragePooling2D, Dense, Dropout\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import plot_model\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","925479a9":"# Directories\nTRAIN_DIR = '\/kaggle\/input\/digit-recognizer\/train.csv'\nTEST_DIR = '\/kaggle\/input\/digit-recognizer\/test.csv'\nSUBMISSION_DIR = '\/kaggle\/input\/digit-recognizer\/sample_submission.csv'","aae18aa0":"# Load the data\ntrain_df = pd.read_csv(TRAIN_DIR)\ntest_df = pd.read_csv(TEST_DIR)\n\n# Reshape and Normalize\nX_train = train_df.drop(columns = ['label']).values.reshape(-1, 28, 28, 1) \/ 255\nY_train = train_df['label'].values\n\nX_test = test_df.values.reshape(-1, 28, 28, 1) \/ 255","d5d8502c":"# Convert to categorical\nY_train = to_categorical(Y_train, num_classes = 10)","2cd8bc59":"# Train Validation Split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2)","5ff7f2bf":"# Function to generate a Residual Block\n# Skip connection between Conv2D - ReLu - BatchNorm - Conv2D\ndef residual_block(inputs, filters, strides = 1):\n    # Skip connection\n    y = inputs\n\n    # Main connection\n    x = Conv2D(filters = filters, kernel_size = 3, strides = strides, padding = 'same')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv2D(filters = filters, kernel_size = 3, strides = 1, padding = 'same')(x)\n    x = BatchNormalization()(x)\n    \n    # Match the dimensions of skip connection\n    if strides > 1:\n        y = Conv2D(filters = filters, kernel_size = 3, strides = strides, padding = 'same')(y)\n        y = BatchNormalization()(y)\n        \n    # Concatenate the connections\n    x = Add()([x, y])\n    x = Activation('relu')(x)\n    \n    return x","dfa0f343":"# Function to generate a ResNet model\n# At the beginning of each stage downsample feature map\n# by a convolutional layer with strides = 2 and double the\n# number of filters.\n# The kernel size is the same for each residual block\ndef resnet(input_shape, num_classes, filters, stages):\n    # Start model\n    inputs = Input(shape = input_shape)\n    x = Conv2D(filters = filters, kernel_size = 7, strides = 1, padding = 'same')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # Stack residual blocks\n    for stage in stages:\n        x = residual_block(x, filters, strides = 2)\n        for i in range(stage - 1):\n            x = residual_block(x, filters)\n        filters = filters * 2\n        \n    # Pool -> Flatten -> Classify\n    x = AveragePooling2D(4)(x)\n    x = Flatten()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(int(filters \/ 4), activation = 'relu')(x)\n    outputs = Dense(num_classes, activation = 'softmax')(x)\n    \n    # Instantiate model and return\n    model = Model(inputs = inputs, outputs = outputs)\n    return model","b6092265":"model = resnet(input_shape = X_train[0].shape, num_classes = 10,\n               filters = 65, stages = [2])\nplot_model(model)","3714fda7":"# Set loss function, optimizer and callback\noptimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-8, decay = 0.0)\nmodel.compile(optimizer = optimizer, loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])\n\nlearning_rate_callback = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 3,\n                                           verbose = 1, factor = 0.5, min_lr = 0.00001)","a8e99b27":"# Data Augmentation\ndatagen = ImageDataGenerator(\n    featurewise_center = False,\n    samplewise_center = False,\n    featurewise_std_normalization = False,\n    samplewise_std_normalization = False,\n    zca_whitening = False,\n    rotation_range = 10,\n    zoom_range = 0.1,\n    shear_range = 0.1,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = False,\n    vertical_flip = False\n)\n\ndatagen.fit(X_train)","d494658e":"EPOCHS = 30\nBATCH_SIZE = 86","a6fc07e2":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = BATCH_SIZE),\n                                           epochs = EPOCHS, validation_data = (X_val, Y_val),\n                                           verbose = 2, steps_per_epoch = X_train.shape[0] \/\/ BATCH_SIZE,\n                                           callbacks = [learning_rate_callback])","9914ac01":"# Plot the loss and accuracy curves for training and validation\nfig, ax = plt.subplots(2, 1)\n\nax[0].plot(history.history['loss'], color = 'b', label = 'Training Loss')\nax[0].plot(history.history['val_loss'], color = 'r', label = 'Validation Loss', axes = ax[0])\nlegend = ax[0].legend(loc = 'best', shadow = True)\n\nax[1].plot(history.history['accuracy'], color = 'b', label = 'Training Accuracy')\nax[1].plot(history.history['val_accuracy'], color = 'r', label = 'Validation Accuracy')\nlegend = ax[1].legend(loc = 'best', shadow = True)","a5d41e9b":"# Function to plot confusion matrix\ndef plot_confusion_matrix(cm, classes):\n    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n    \n    thresh = cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment = 'center', \n                 color = 'white' if cm[i, j] > thresh else 'black')\n        \n    plt.tight_layout()\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')","8bc2c7c0":"# Predict the values from validation dataset\nY_pred = model.predict(X_val)\n\n# Convert predictions to one hot vectors\nY_pred_classes = np.argmax(Y_pred, axis = 1)\n\n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val, axis = 1)\n\n# Compute confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n\n# Plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10))","f06d1fa5":"# Predict results\nresults = model.predict(X_test)\n\n# Select the indexx with maximum probability\nresults = np.argmax(results, axis = 1)\nresults = pd.Series(results, name = 'Label')","ef8e5c01":"submission = pd.concat([pd.Series(range(1, 28001), name = 'ImageId'), results], axis = 1)\nsubmission.to_csv('submission.csv', index = False)","7f4ca1e0":"## Confusion Matrix","da094cfa":"# Import Libraries and Load Dataset","1f42f981":"# References\n- [ResNets are Awesome! (state-of-the-art)](https:\/\/www.kaggle.com\/jmosinski\/resnets-are-awesome-state-of-the-art)","d88318be":"# Train the model","373f5348":"# Data Augmentation","59a01e4c":"# Generate the ResNet Model","b1ec721a":"## Training and Validation Curves","9cac3faf":"# Submission","dcb939ee":"# Evaluate the Model"}}