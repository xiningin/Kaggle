{"cell_type":{"81a463e0":"code","2310779d":"code","44f01bcd":"code","6304988a":"code","b2f3dd09":"code","4bf41722":"code","3bea5b8f":"code","99c773bb":"code","b99ab25d":"code","18719cc9":"markdown","29709242":"markdown","8a4377e9":"markdown"},"source":{"81a463e0":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime","2310779d":"start_time = datetime.timestamp(datetime.now())\ncrypto_df = pd.read_csv(\"..\/input\/g-research-crypto-forecasting\/train.csv\")\nprint(\"load in\",datetime.timestamp(datetime.now())-start_time,\"seconds\")","44f01bcd":"crypto_df.head(10)","6304988a":"# https:\/\/www.kaggle.com\/toomuchsauce\/g-crypto-interactive-dashboard-indicators\n\ndef reduce_memory(df):\n    \n    before = df.memory_usage().sum()  \n    \n    for col in df.columns:        \n        dtype = df[col].dtype\n        if dtype == 'float64':\n            c_min = df[col].min()\n            c_max = df[col].max()        \n            if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                df[col] = df[col].astype(np.float32)\n            else:\n                df[col] = df[col].astype(np.float64)\n\n    df['Asset_ID'] = df['Asset_ID'].astype('int8')\n    df['Count'] = df['Count'].astype('int32')\n    df['timestamp'] = df['timestamp'].astype('uint32')\n                    \n    after = df.memory_usage().sum()\n    \n    print('Memory taken before transformation : ', before)\n    print('Memory taken after transformation : ', after)\n    print('Memory taken reduced by : ',( before - after) * 100\/ before, '%')\n    \n    return df\n\ncrypto_df = reduce_memory(crypto_df)","b2f3dd09":"crypto_df.to_feather('train.feather')","4bf41722":"#del crypto_df\nstart_time = datetime.timestamp(datetime.now())\ncrypto_df = pd.read_feather(\"train.feather\")\nprint(\"load in\",datetime.timestamp(datetime.now())-start_time,\"seconds\")","3bea5b8f":"crypto_df.head(10)","99c773bb":"df1 = pd.DataFrame({'timestamp':crypto_df.timestamp.unique()}).sort_values(['timestamp'])\ndf2 = pd.DataFrame({'Asset_ID':crypto_df.Asset_ID.unique()}).sort_values(['Asset_ID'])\ndf_x = df1.merge(df2, how='cross').set_index(['timestamp','Asset_ID'],drop=True)\ncrypto_df=df_x.join(crypto_df.set_index(['timestamp','Asset_ID'],drop=True).sort_index()[['Open','High','Low','Close','Volume','VWAP','Target']],how='left').fillna(0).reset_index()\ndel df1\ndel df2\ndel df_x\ncrypto_df.to_feather('transformed_train.feather')","b99ab25d":"crypto_df.head(10)","18719cc9":"## **Transform data to fill gaps**","29709242":"# **Speed-up data loading!**","8a4377e9":"Train.csv is a big file that takes some time to load. I created this notebook to have a feather version of the file which will be much faster to load. You don't need to run this notebook. If you want, you can just use the output as your input and speed-up the data loading **from one minute to one second!**\n\nTo load the feather file, just add data from this notebook and open the file with <code>pd.read_feather('..\/input\/speed-up-data-loading\/train.feather')<\/code>\n\nI changed the datatypes of the DataFrame (I took most of the code from [this](https:\/\/www.kaggle.com\/toomuchsauce\/g-crypto-interactive-dashboard-indicators) notebook) to reduce the size of the dataset. If you want to use the original data types, you can skip the call to reduce_memory function.\n\nAt the end of the notebook I fill the gaps to have all the assets for all the existing timestamps. This is convenient for me, anyone not interested in this format can ignore the <code>transformed_train.feather<\/code> file and just use <code>train.feather<\/code>"}}