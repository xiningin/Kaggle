{"cell_type":{"ad2dd43c":"code","2ecae18e":"code","74e34acb":"code","462cfd45":"code","a56e54d9":"code","bd80089b":"code","3251e91d":"code","41717a6f":"code","2fbbfdef":"code","cdca708e":"code","3495e070":"code","232d23b2":"code","2bac672d":"markdown","7e98eaf2":"markdown","69622e63":"markdown"},"source":{"ad2dd43c":"import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom skimage.feature import hog\nfrom skimage import exposure\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom skimage.feature import canny\nfrom skimage.filters import sobel\nfrom skimage.morphology import watershed\nfrom scipy import ndimage as ndi\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom skimage.segmentation import mark_boundaries\nfrom scipy import signal\nimport cv2\nimport glob, pylab, pandas as pd\nimport pydicom, numpy as np\nimport tqdm\nimport gc\ngc.enable()\nimport glob\n\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom skimage import exposure","2ecae18e":"ROOT_FOLDER = '\/kaggle\/input\/rsna-intracranial-hemorrhage-detection'\nTRAIN_CSV = ROOT_FOLDER + '\/stage_1_train.csv'\nTRAIN_FOLDER = ROOT_FOLDER + '\/stage_1_train_images'\nTEST_FOLDER = ROOT_FOLDER + '\/stage_1_test_images'","74e34acb":"train_files = glob.glob(TRAIN_FOLDER + '\/*.dcm')\nlen(train_files)","462cfd45":"\ntest_files = glob.glob(TEST_FOLDER + '\/*.dcm')\nlen(test_files)","a56e54d9":"df = pd.read_csv(TRAIN_CSV,header=None)\ndf.head()","bd80089b":"df.shape","3251e91d":"import cv2\nfrom IPython.display import display, Image\ndef cvshow(image, format='.png', rate=255 ):\n    decoded_bytes = cv2.imencode(format, image*rate)[1].tobytes()\n    display(Image(data=decoded_bytes))\n    return","41717a6f":"j = 0\nnImg = 10\nimg_ar = np.empty(0)\nwhile img_ar.shape[0]!=nImg:\n    dcm_file = train_files[j]\n    dcm_data = pydicom.read_file(dcm_file)\n    img = np.expand_dims(dcm_data.pixel_array,axis=0)    \n    if j==0:\n        img_ar = img\n    elif (j%100==0):\n        print(j,'images loaded')\n    else:\n        img_ar = np.concatenate([img_ar,img],axis=0)\n    j += 1","2fbbfdef":"def imgtile(imgs,tile_w):\n    assert imgs.shape[0]%tile_w==0,\"'imgs' cannot divide by 'th'.\"\n    r=imgs.reshape((-1,tile_w)+imgs.shape[1:])\n    return np.hstack(np.hstack(r))\n\n#usage\ntiled = imgtile(img_ar,5)\n# cvshow(tiled)\ntiled.shape","cdca708e":"img = tiled.astype(np.float32)\ncvshow(cv2.resize( img, (1024,512), interpolation=cv2.INTER_LINEAR ))","3495e070":"plt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=0.7, hspace=0)  #adjust this to change vertical and horiz. spacings..\nnImg = 3  #no. of images to process\nfor j in range(nImg):\n    q = j+1\n    img = np.array(pydicom.read_file(train_files[j]).pixel_array)\n    \n#     # Contrast stretching\n    p2, p97 = np.percentile(img, (2, 97))\n    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p97))\n    \n    # Equalization\n    img_eq = exposure.equalize_hist(img)\n\n    # Adaptive Equalization\n    img_adapteq = exposure.equalize_adapthist(img)\n    \n    plt.subplot(nImg,7,q*7-6)\n    plt.imshow(img, cmap=plt.cm.bone)\n    plt.title('Original Image')\n    \n    \n    plt.subplot(nImg,7,q*7-5)    \n    plt.imshow(img_rescale, cmap=plt.cm.bone)\n    plt.title('Contrast stretching')\n    \n    \n    plt.subplot(nImg,7,q*7-4)\n    plt.imshow(img_eq, cmap=plt.cm.bone)\n    plt.title('Equalization')\n    \n    \n    plt.subplot(nImg,7,q*7-3)\n    plt.imshow(img_adapteq, cmap=plt.cm.bone)\n    plt.title('Adaptive Equalization')\nplt.show()","232d23b2":"plt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=0.7, hspace=0)  #adjust this to change vertical and horiz. spacings..\nnImg = 3  #no. of images to process\nfor j in range(nImg):\n    q = j+1\n    img = np.array(pydicom.read_file(test_files[j]).pixel_array)\n    \n#     # Contrast stretching\n    p2, p97 = np.percentile(img, (2, 97))\n    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p97))\n    \n    # Equalization\n    img_eq = exposure.equalize_hist(img)\n\n    # Adaptive Equalization\n    img_adapteq = exposure.equalize_adapthist(img)\n    \n    plt.subplot(nImg,7,q*7-6)\n    plt.imshow(img, cmap=plt.cm.bone)\n    plt.title('Original Image')\n    \n    \n    plt.subplot(nImg,7,q*7-5)    \n    plt.imshow(img_rescale, cmap=plt.cm.bone)\n    plt.title('Contrast stretching')\n    \n    \n    plt.subplot(nImg,7,q*7-4)\n    plt.imshow(img_eq, cmap=plt.cm.bone)\n    plt.title('Equalization')\n    \n    \n    plt.subplot(nImg,7,q*7-3)\n    plt.imshow(img_adapteq, cmap=plt.cm.bone)\n    plt.title('Adaptive Equalization')\nplt.show()","2bac672d":"## Train Image","7e98eaf2":"## Test Images","69622e63":"## Visualizing Images \n\nThis is read and Visualizing Images Demo."}}