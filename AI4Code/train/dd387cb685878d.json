{"cell_type":{"132e9747":"code","e1d99abb":"code","93593b79":"code","aeac9c47":"code","60b96507":"code","e1aef184":"code","05e744b4":"code","e84117e6":"code","0c76e41e":"code","994de164":"code","231e5271":"code","33a8eebb":"code","b13c9f9c":"code","9044ebae":"code","4a7da173":"markdown","3648d6fd":"markdown","18a325c0":"markdown","833db887":"markdown","279f24bb":"markdown","276a8cc3":"markdown","c154f3d5":"markdown","46ff943a":"markdown"},"source":{"132e9747":"import numpy as np\nimport pandas as pd\nimport os\nfrom keras.preprocessing.image import ImageDataGenerator","e1d99abb":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom skimage import io","93593b79":"class CNN(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=(3,3))\n        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(3,3))\n        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n        self.flatten = nn.Flatten()\n        self.dropout = nn.Dropout(0.2)\n        self.lin1 = nn.Linear(3136, 64)\n        self.lin2 = nn.Linear(64, num_classes)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool2(x)\n        x = self.flatten(x)\n        x = self.dropout(x)\n        x = F.relu(self.lin1(x))\n        x = self.lin2(x)\n        \n        return x","aeac9c47":"# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Hyperparameters\nin_channels = 1\nnum_classes = 131\nlr = 0.001\nbatch_size = 64\nnum_epochs = 10","60b96507":"class MedicalMNIST(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        self.annotations = df\n        self.root_dir = root_dir\n        self.transform = transform\n    def __len__(self):\n        return len(self.annotations)\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n        image = io.imread(img_path)\n        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return (image, y_label)","e1aef184":"mp = {}\ndf = []\nfor idx, category in enumerate(os.listdir(\"..\/input\/medical-mnist\")):\n    mp[category] = idx\n    for image in os.listdir(\"..\/input\/medical-mnist\/\"+category):\n        df.append([category+\"\/\"+image, mp[category]])\ndf = np.array(df)\ndf = pd.DataFrame(df)\ndf.head()","05e744b4":"dataset = MedicalMNIST(df=df, root_dir=\"..\/input\/medical-mnist\",\n                       transform=transforms.ToTensor())","e84117e6":"io.imread(\"..\/input\/medical-mnist\/\"+df[0][0]).shape","0c76e41e":"len(dataset)","994de164":"train_set, test_set = torch.utils.data.random_split(dataset,\n                                                   [48954,10000])\n","231e5271":"train_loader = DataLoader(train_set, batch_size=(batch_size), shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=(batch_size), shuffle=True)","33a8eebb":"model = CNN(in_channels, num_classes).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr)","b13c9f9c":"# train network\ndef train(model, num_epochs):\n    for epoch in range(num_epochs):\n        for batch, (data, targets) in enumerate(train_loader):\n            data = data.to(device=device)\n            targets = targets.to(device=device)\n            \n            #Forward\n            scores = model(data)\n            loss = criterion(scores, targets)\n            \n            #Backward\n            optimizer.zero_grad()\n            loss.backward()\n            \n            # Gradient descent\n            optimizer.step()\n            \n        print(epoch, \"Current Loss:\", loss)\n            \ntrain(model, num_epochs)","9044ebae":"def evaluate(loader, model):\n    correct = 0\n    total = 0\n    model.eval()\n    with torch.no_grad():\n        for x,y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n            \n            scores = model(x)\n            _, pred = scores.max(1)\n            correct += (pred == y).sum()\n            total += pred.size(0)\n        print(\"Accuracy:\", correct\/total*100, \"%\")\n    \nevaluate(train_loader, model)\nevaluate(test_loader, model)","4a7da173":"# Training","3648d6fd":"<hr>","18a325c0":"# Getting Pytorch Imports","833db887":"# Getting parameters ready","279f24bb":"# Loading Data","276a8cc3":"# Initializing","c154f3d5":"# Creating the CNN","46ff943a":"# Evaluation"}}