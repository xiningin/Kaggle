{"cell_type":{"a615c455":"code","e769c65b":"code","953222ef":"code","ca0a9acb":"code","5e7ab399":"code","67f54fbc":"code","9316e5f3":"code","4d9f75d0":"code","4ba49c50":"code","d9aa8e28":"code","4774a728":"code","1c681427":"code","dd67935e":"code","e71e7de8":"code","8061112f":"code","194ddee9":"code","403cc092":"code","caf0dc2f":"code","573f542d":"code","c6dd7cce":"code","83a49844":"code","707487ca":"code","2c1d7e8a":"code","96db422b":"code","e9092d4d":"code","e2a1a6bf":"code","1ed6f094":"code","163f0a2d":"code","14790b95":"code","972a0f43":"code","b70930d6":"code","a3bb3a6e":"code","49ff776b":"code","2f6349b7":"code","8677d8cb":"code","8758db43":"code","6cadffe7":"code","1f70c729":"code","1e250212":"code","bf00d6c0":"code","4b120263":"code","cb3bc2ce":"code","644f35e8":"code","c7c97c16":"code","e048a301":"code","608ac780":"code","707e216c":"code","c4288272":"code","a3a65e9b":"code","ec0ba3e1":"code","8b2adddc":"code","c5208ba5":"code","b39143f4":"code","c3193ae1":"code","3f7caa9a":"markdown","2283f84f":"markdown","fad34a39":"markdown","ae4ade1c":"markdown","757299b1":"markdown","7d47d2fc":"markdown","6b68a593":"markdown","03423c13":"markdown","2e04b5a8":"markdown","65576eb5":"markdown","c80b43db":"markdown","514d7914":"markdown","5daf2500":"markdown","fdc2cd3a":"markdown","b0d52c41":"markdown","a7e9624b":"markdown","fb055a5b":"markdown","1da8a4e9":"markdown","f42e18d7":"markdown","7b7186f3":"markdown","40f8d7a1":"markdown","c8f7629a":"markdown"},"source":{"a615c455":"import gc\nimport re #regular expressions\nimport os\nimport time\nimport pickle \nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom itertools import product\nfrom xgboost import XGBRegressor, plot_importance\nfrom matplotlib.pylab import rcParams\nfrom sklearn.preprocessing import LabelEncoder\n\nsns.set(style=\"darkgrid\")\nrcParams['figure.figsize'] = 12, 4","e769c65b":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","953222ef":"items = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ncats = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ntrain = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","ca0a9acb":"plt.figure(figsize=(10, 4))\nplt.xlim(-100, 3000)\nflierprops = dict(marker='o', markerfacecolor='green', markersize=6,\n                  linestyle='none', markeredgecolor='black') #style of outliers\nsns.boxplot(x=train.item_cnt_day, flierprops=flierprops)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price, flierprops=flierprops)","5e7ab399":"train = (\n    train\n    [\n        (train['item_price'] > 0) &\n        (train['item_price'] < 300000) &\n        (train['item_cnt_day'] < 1000)\n    ]\n    .reset_index(drop = True)\n)\n\ntrain.loc[train['item_cnt_day'] < 0, 'item_cnt_day'] = 0","67f54fbc":"for i in [(0, 57), (1, 58), (10, 11)]:\n    train.loc[train['shop_id'] == i[0], 'shop_id'] = i[1]\n    test.loc[test['shop_id'] == i[0], 'shop_id'] = i[1]","9316e5f3":"shops.head()","4d9f75d0":"shops.loc[shops['shop_name'] == '\u0421\u0435\u0440\u0433\u0438\u0435\u0432 \u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"', 'shop_name'] = '\u0421\u0435\u0440\u0433\u0438\u0435\u0432\u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"'\nshops['city'] = shops.shop_name.str.split(' ').map(lambda x: x[0])\nshops['category'] = shops.shop_name.str.split(' ').map(lambda x: x[1])\nshops.loc[shops['city'] == '!\u042f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u042f\u043a\u0443\u0442\u0441\u043a'","4ba49c50":"categories = []\nfor categ in shops['category'].unique():\n    if len(shops[shops['category'] == categ]) > 4:\n        categories.append(categ)\nshops['category'] = shops['category'].apply(lambda x: x if x in categories else 'other')","d9aa8e28":"shops['shop_category'] = LabelEncoder().fit_transform(shops['category'])\nshops['shop_city'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id', 'shop_category', 'shop_city']]\nshops.head()","4774a728":"cats.head()","1c681427":"cats['type_code'] = (\n    cats['item_category_name']\n    .apply(\n        lambda x: x.split(' ')[0]\n    )\n    .astype(str)\n)\ncats.loc[\n    (cats['type_code'] == '\u0418\u0433\u0440\u043e\u0432\u044b\u0435') |\n    (cats['type_code'] == '\u0410\u043a\u0441\u0435\u0441\u0441\u0443\u0430\u0440\u044b'),\n    'category'\n] = '\u0418\u0433\u0440\u044b'\ncats.head()","dd67935e":"categories = []\nfor categ in cats['type_code'].unique():\n    if len(cats[cats['type_code'] == categ]) > 4: \n        categories.append(categ)\ncats['type_code'] = cats['type_code'].apply(lambda x: x if x in categories else 'etc')","e71e7de8":"cats['type_code'] = LabelEncoder().fit_transform(cats['type_code'])\ncats['split'] = (\n    cats['item_category_name']\n    .apply(lambda x: x.split('-'))\n)\ncats['subtype'] = (\n    cats['split']\n    .apply(\n        lambda x: x[1].strip() if len(x) >= 2 else x[0].strip()\n    )\n)\ncats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\ncats = cats[['item_category_id', 'subtype_code', 'type_code']]\ncats.head()","8061112f":"def name_correction(x):\n    x = x.lower() #lower case\n    x = x.partition('[')[0] # partition by square brackets\n    x = x.partition('(')[0] # partition by curly brackets\n    x = re.sub('\\W+', ' ', x) # remove special characters\n    x = x.replace('  ', ' ') # replace double spaces with single spaces\n    x = x.strip() # remove leading and trailing white space\n    return x","194ddee9":"items.head()","403cc092":"# split item names by first bracket\nitems['name1'], items['name2'] = items['item_name'].str.split('[', 1).str\nitems['name1'], items['name3'] = items['item_name'].str.split('(', 1).str\n\n# replace special characters and turn to lower case\nitems['name2'] = items['name2'].str.replace('\\W+', ' ').str.lower()\nitems['name3'] = items['name3'].str.replace('\\W+', ' ').str.lower()\n\n# fill nulls with '0'\nitems = items.fillna('0')\n\nitems['item_name'] = items['item_name'].apply(lambda x: name_correction(x))\n\n# return all characters except the last if name 2 is not \"0\" - the closing bracket\nitems['name2'] = items['name2'].apply(lambda x: x[:-1] if x != '0' else '0')","caf0dc2f":"items.head()","573f542d":"items['type'] = (\n    items['name2']\n    .apply(\n        lambda x: x[0:8] if x.split(' ')[0] == 'xbox' else x.split(' ')[0]\n    )\n)\nitems.loc[\n    (items['type'] == 'x360') |\n    (items['type'] == 'xbox360') |\n    (items['type'] == 'xbox 360'),\n    'type'\n] = 'xbox 360'\nitems.loc[items['type'] == '', 'type'] = 'mac'\nitems.type = (\n    items['type']\n    .apply(\n        lambda x: x.replace(' ', '')\n    )\n)\nitems.loc[\n    (items['type'] == 'pc' ) |\n    (items['type'] == 'p\u0441') |\n    (items['type'] == 'p\u0441'),\n    'type'\n] = 'p\u0441'\n\nitems.loc[items['type'] == '\u0440s3' , 'type'] = '\u0440s3'","c6dd7cce":"items.head()","83a49844":"group_sum = (\n    items\n    .groupby('type')\n    .agg({'item_id': 'count'})\n    .reset_index()\n)\n\ndrop_cols = []\nfor categ in group_sum['type'].unique():\n    if group_sum.loc[(group_sum['type'] == categ), 'item_id'].values[0] <= 39:\n        drop_cols.append(categ)\n\nitems['name2'] = (\n    items['name2']\n    .apply(\n        lambda x: 'other' if x in drop_cols else x\n    )\n)\nitems = items.drop(['type'], axis=1)","707487ca":"items.head()","2c1d7e8a":"items['name2'] = LabelEncoder().fit_transform(items['name2'])\nitems['name3'] = LabelEncoder().fit_transform(items['name3'])\n\nitems.drop(['item_name', 'name1'], axis=1, inplace=True)\nitems.head()","96db422b":"matrix = []\ncols  = ['date_block_num', 'shop_id', 'item_id']\nfor i in range(34):\n    sales = train[train['date_block_num'] == i]\n    matrix.append(\n        np.array(\n            list(product(\n                [i],\n                sales['shop_id'].unique(),\n                sales['item_id'].unique()\n            )),\n            dtype = np.int16\n        )\n    )\n\nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix = matrix.astype({\n    'date_block_num': np.int8, \n    'shop_id': np.int8, \n    'item_id': np.int16\n})\nmatrix.sort_values(cols, inplace=True)","e9092d4d":"# create revenue column\ntrain['revenue'] = train['item_cnt_day'] * train['item_price']","e2a1a6bf":"group = (\n    train\n    .groupby(['date_block_num', 'shop_id', 'item_id'])\n    .agg({\n        'item_cnt_day': 'sum'\n    })\n)\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (\n    matrix['item_cnt_month']\n    .fillna(0)\n    .astype(np.float16)\n)","1ed6f094":"#Create test set for 34th month.\ntest['date_block_num'] = 34\ntest = (\n    test\n    .astype({\n        'date_block_num': np.int8, \n        'shop_id': np.int8, \n        'item_id': np.int16\n    })\n)","163f0a2d":"#Concatenate train and test\nmatrix = pd.concat(\n    [matrix, test.drop(['ID'], axis=1)],\n    ignore_index=True, sort=False, keys=cols\n)\nmatrix.fillna(0, inplace=True)","14790b95":"#Add all our data categories to matrix\nmatrix = pd.merge(matrix, shops, on='shop_id', how='left')\nmatrix = pd.merge(matrix, items, on='item_id', how='left')\nmatrix = pd.merge(matrix, cats, on='item_category_id', how='left')\nmatrix = (\n    matrix\n    .astype({\n        'shop_city': np.int8,\n        'shop_category': np.int8,\n        'item_category_id': np.int8,\n        'subtype_code': np.int8,\n        'name2': np.int8,\n        'name3': np.int16,\n        'type_code': np.int8\n    })\n)","972a0f43":"# Define a lag feature function\ndef lag_feature(df, lags, cols):\n    for col in cols:\n        tmp = df[['date_block_num', 'shop_id', 'item_id', col]]\n        for i in lags:\n            shifted = tmp.copy()\n            shifted.columns = ['date_block_num', 'shop_id', 'item_id', col + \"_lag_\" + str(i)]\n            shifted['date_block_num'] = shifted['date_block_num'] + i\n            df = pd.merge(df, shifted, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n    return df","b70930d6":"#Add item_cnt_month lag features.\nmatrix = lag_feature(matrix, [1, 2, 3], ['item_cnt_month'])","a3bb3a6e":"#Add the previous month's average item_cnt.\ngroup = (\n    matrix\n    .groupby('date_block_num')\n    .agg({\n        'item_cnt_month' : 'mean'\n    })\n)\ngroup.columns = ['date_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on='date_block_num', how=\"left\")\nmatrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_avg_item_cnt'])\nmatrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)","49ff776b":"#Add lag values of item_cnt_month for month \/ item_id.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'item_id'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_item_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id'], how='left')\nmatrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1, 2, 3], ['date_item_avg_item_cnt'])\nmatrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)","2f6349b7":"#Add lag values for item_cnt_month for every month \/ shop combination.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'shop_id'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_shop_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id'], how='left')\nmatrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1, 2, 3], ['date_shop_avg_item_cnt'])\nmatrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)","8677d8cb":"#Add lag values for item_cnt_month for month\/shop\/item.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'shop_id', 'item_id'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_shop_item_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_id'], how='left')\nmatrix['date_shop_item_avg_item_cnt'] = matrix['date_shop_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1, 2, 3], ['date_shop_item_avg_item_cnt'])\nmatrix.drop(['date_shop_item_avg_item_cnt'], axis=1, inplace=True)","8758db43":"#Add lag values for item_cnt_month for month\/shop\/item subtype.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'shop_id', 'subtype_code'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_shop_subtype_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\nmatrix['date_shop_subtype_avg_item_cnt'] = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\nmatrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)","6cadffe7":"#Add lag values for item_cnt_month for month\/city.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'shop_city'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_city_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_city'], how='left')\nmatrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\nmatrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)","1f70c729":"#Add lag values for item_cnt_month for month\/city\/item.\ngroup = (\n    matrix\n    .groupby(['date_block_num', 'item_id', 'shop_city'])\n    .agg({\n        'item_cnt_month': 'mean'\n    })\n)\ngroup.columns = ['date_item_city_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\nmatrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\nmatrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)","1e250212":"group = (\n    train\n    .groupby('item_id')\n    .agg({\n        'item_price': 'mean'\n    })\n)\ngroup.columns = ['item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = matrix.merge(group, on='item_id', how='left')\nmatrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n\n\ngroup = (\n    train\n    .groupby(['date_block_num', 'item_id'])\n    .agg({\n        'item_price': 'mean'\n    })\n)\ngroup.columns = ['date_item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = matrix.merge(group, on=['date_block_num', 'item_id'], how='left')\nmatrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\nlags = [1, 2, 3]\nmatrix = lag_feature(matrix, lags, ['date_item_avg_item_price'])\n\nfor i in lags:\n    matrix['delta_price_lag_' + str(i)] = (\n        matrix['date_item_avg_item_price_lag_' + str(i)] -\\\n        matrix['item_avg_item_price']\n    ) \/ matrix['item_avg_item_price']\n\ndef select_trends(row) :\n    for i in lags:\n        if row['delta_price_lag_' + str(i)]:\n            return row['delta_price_lag_' + str(i)]\n    return 0\n\nmatrix['delta_price_lag_'] = matrix.apply(select_trends, axis=1)\nmatrix['delta_price_lag_'] = matrix['delta_price_lag_'].astype(np.float16)\nmatrix['delta_price_lag_'].fillna(0, inplace=True)\n\nfeatures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\nfor i in lags:\n    features_to_drop.append('date_item_avg_item_price_lag_' + str(i))\n    features_to_drop.append('delta_price_lag_' + str(i))\nmatrix.drop(features_to_drop, axis=1, inplace=True)","bf00d6c0":"group = (\n    train\n    .groupby(['date_block_num', 'shop_id'])\n    .agg({\n        'revenue': 'sum'\n    })\n)\ngroup.columns = ['date_shop_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = matrix.merge(group, on=['date_block_num', 'shop_id'], how='left')\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\ngroup = (\n    group\n    .groupby('shop_id')\n    .agg({\n        'date_block_num': 'mean'\n    })\n)\ngroup.columns = ['shop_avg_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = matrix.merge(group, on='shop_id', how='left')\nmatrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\nmatrix['delta_revenue'] = (\n    matrix['date_shop_revenue'] - matrix['shop_avg_revenue']\n) \/ matrix['shop_avg_revenue']\nmatrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float32)\n\nmatrix = lag_feature(matrix, [1], ['delta_revenue'])\nmatrix['delta_revenue_lag_1'] = matrix['delta_revenue_lag_1'].astype(np.float32)\nmatrix.drop(\n    ['date_shop_revenue', 'shop_avg_revenue', 'delta_revenue'],\n    axis=1, inplace=True\n)","4b120263":"#Add month and number of days in each month to matrix\nmatrix['month'] = matrix['date_block_num'] % 12\ndays = pd.Series([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\nmatrix['days'] = matrix['month'].map(days).astype(np.int8)","cb3bc2ce":"#Add the month of each shop and item first sale.\nmatrix['item_shop_first_sale'] = (\n    matrix['date_block_num'] - matrix.groupby(['item_id', 'shop_id'])['date_block_num'].transform('min')\n)\nmatrix['item_first_sale'] = (\n    matrix['date_block_num'] - matrix.groupby(['item_id'])['date_block_num'].transform('min')\n)","644f35e8":"#Delete first three months from matrix. They don't have lag values.\nmatrix = matrix[matrix['date_block_num'] >= 4]\nmatrix.head().T","c7c97c16":"data = matrix.copy()","e048a301":"data[data['date_block_num'] == 34].shape","608ac780":"data.isnull().sum()","707e216c":"data.shape","c4288272":"#Use month 34 as validation for training.\nX_train = data[data.date_block_num <= 32].drop(['item_cnt_month'], axis=1)\nY_train = data[data.date_block_num <= 32]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)","a3a65e9b":"X_train = X_train.fillna(0)\nY_train = Y_train.fillna(0)\nX_valid = X_valid.fillna(0)\nY_valid = Y_valid.fillna(0)\nX_tets = X_test.fillna(0)","ec0ba3e1":"Y_train = Y_train.clip(0, 20)\nY_valid = Y_valid.clip(0, 20)","8b2adddc":"from sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\nfrom optuna import create_study\nimport xgboost as xgb\nimport copy\nfrom sklearn.metrics import r2_score","c5208ba5":"model = XGBRegressor(\n    max_depth=8,\n    n_estimators=800,\n    min_child_weight=0.8, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,\n    used_ram_limit= \"12gb\",\n)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric='rmse',\n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds=200\n)","b39143f4":"Y_pred = model.predict(X_valid).clip(0, 20)\nY_test = model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    'ID': test.index, \n    'item_cnt_month': Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)","c3193ae1":"def plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1, 1, figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nplot_features(model, (10, 14))","3f7caa9a":"Several entries looks like the data for same stores but for different period.","2283f84f":"* Add average item price to matix. \n* Add lag values of item price per month.\n* Add delta price values - how current month average pirce relates to global average.","fad34a39":"The goal of the competition to predict future sales of items in set of '1C' company's stores for one month given historical data.","ae4ade1c":"### Item Categories Data Cleaning","757299b1":"Create matrix format dataframe for every month, shop and item id to aggregate data to monthly data. 'Item_cnt_day' summed up to ' item_cnt_month'.","7d47d2fc":"Clean item type","6b68a593":"### Shop Dataframe Cleaning","03423c13":"## 3. Modelling","2e04b5a8":"### Outliers","65576eb5":"## 2. Data preparation & Feature Enginering","c80b43db":"#### Libraries and data","514d7914":"### xgboost","5daf2500":"### Item Data Cleaning","fdc2cd3a":"Clean item names","b0d52c41":"Change some shop names and add 'city' and 'category' columns to dataframe.","a7e9624b":"### Introduction","fb055a5b":"Remove outliers, chosing thresholds visually - the items sold more than 1000 in one day, and the item with price higher than 300 thounds.","1da8a4e9":"## 1. Data Cleaning","f42e18d7":"Use only large enough categories","7b7186f3":"* Add total shop revenue per month to matrix. \n* Add lag values of revenue per month.\n* Add delta revenue values - how current month revenue relates to global average. ","40f8d7a1":"Feature Enginering. Add lags to matrix.","c8f7629a":"Also remove rows with negative price value and make zero negative item_cnt_day."}}