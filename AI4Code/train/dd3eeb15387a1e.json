{"cell_type":{"b7e1a4e2":"code","ebc20d2f":"code","a20d0cfd":"code","98bfeb04":"code","d3b6d7c6":"code","7602a1d3":"code","613bfab2":"code","a8efb303":"code","4343e765":"code","bf36e73e":"code","c11f7c51":"code","2f406949":"code","5570dfb2":"code","f056b156":"code","4d8a193f":"code","2ef16282":"code","e5598f62":"code","d45642f2":"code","cd353f68":"code","a7e59256":"code","6bc2547d":"code","825d634d":"markdown","21793057":"markdown","5cd96254":"markdown","b2fee3b4":"markdown","b9291783":"markdown","1cf99dc0":"markdown","14ee8ea5":"markdown","1781f4cb":"markdown","85232fb4":"markdown","ac1b19b8":"markdown"},"source":{"b7e1a4e2":"import tensorflow as tf\nfrom keras.layers import Input, Lambda, Dense, Flatten,GlobalAveragePooling2D,BatchNormalization,Dropout,Activation\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split","ebc20d2f":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a20d0cfd":"train_dir = '..\/input\/riceleafs\/RiceLeafs\/train'\ntest_dir = '..\/input\/riceleafs\/RiceLeafs\/validation'","98bfeb04":"classes=[]\nfor file in os.listdir(train_dir):\n    classes+=[file]\nprint(classes)\nprint(len(classes))","d3b6d7c6":"brownspot = [train_dir + '\/BrownSpot\/' + img for img in os.listdir(train_dir + '\/BrownSpot')[:9]]\nhealthy = [train_dir  + '\/Healthy\/' + img for img in os.listdir(train_dir + '\/Healthy')[:9]]\nhispa = [train_dir  + '\/Hispa\/' + img for img in os.listdir(train_dir + '\/Hispa')[:9]]\nleafblast = [train_dir  + '\/LeafBlast\/' + img for img in os.listdir(train_dir + '\/LeafBlast')[:9]]","7602a1d3":"from PIL import Image\nplt.figure(figsize=(16,16))\nfor i,k  in enumerate(brownspot):\n    image = Image.open(k)\n    plt.subplot(3,3,i+1)\n    plt.imshow(image)\n    plt.title(\"Brown Spot\")","613bfab2":"plt.figure(figsize=(16,16))\nfor i,k  in enumerate(hispa):\n    image = Image.open(k)\n    plt.subplot(3,3,i+1)\n    plt.imshow(image)\n    plt.title(\"Hispa\")","a8efb303":"plt.figure(figsize=(16,16))\nfor i,k  in enumerate(leafblast):\n    image = Image.open(k)\n    plt.subplot(3,3,i+1)\n    plt.imshow(image)\n    plt.title(\"Leaf Blast\")","4343e765":"plt.figure(figsize=(16,16))\nfor i,k  in enumerate(healthy):\n    image = Image.open(k)\n    plt.subplot(3,3,i+1)\n    plt.imshow(image)\n    plt.title(\"Healthy\")","bf36e73e":"dataset=[]\nshape=(224,224)\ncount=0\nfor file in os.listdir(train_dir):\n    path=os.path.join(train_dir,file)\n    t=0\n    for im in os.listdir(path):\n        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=shape)\n        image=img_to_array(image)\n        image=image\/255.0\n        dataset+=[[image,count]]\n        t+=1\n    count=count+1","c11f7c51":"testset=[]\ncount=0\nfor file in os.listdir(test_dir):\n    path=os.path.join(test_dir,file)\n    t=0\n    for im in os.listdir(path):\n        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=shape)\n        image=img_to_array(image)\n        image=image\/255.0\n        testset+=[[image,count]]\n        t+=1\n    count=count+1","2f406949":"data,trainlabels = zip(*dataset)\ntest,testlabels = zip(*testset)","5570dfb2":"labels1=to_categorical(trainlabels)\nlabels=np.array(labels1)","f056b156":"data=np.array(data)\ntest=np.array(test)","4d8a193f":"trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=42)","2ef16282":"print(trainx.shape)\nprint(testx.shape)\nprint(trainy.shape)\nprint(testy.shape)","e5598f62":"datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=30,zoom_range=0.2,\n                        width_shift_range=0.1,height_shift_range=0.2,shear_range=0.2)","d45642f2":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape = (224,224,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128,activation = 'relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(256,activation = 'relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(4,activation = 'softmax')\n\n],    name = 'Conv2D_Model')\n\nmodel.summary()","cd353f68":"LEARNING_RATE = 0.001 #@param {type:\"number\"}\n\nmodel.compile(optimizer = tf.keras.optimizers.Adam(),\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])","a7e59256":"his=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=10)","6bc2547d":"get_acc = his.history['accuracy']\nvalue_acc = his.history['val_accuracy']\nget_loss = his.history['loss']\nvalidation_loss = his.history['val_loss']\n\nepochs = range(len(get_acc))\nplt.plot(epochs, get_acc, 'r', label='Accuracy of Training data')\nplt.plot(epochs, value_acc, 'b', label='Accuracy of Validation data')\nplt.title('Training vs validation accuracy')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","825d634d":"**FITTING THE MODEL**","21793057":"**HEALTHY LEAFS**","5cd96254":"**Inference :- We can use pretrained model here to further improve the accuracy and loss.**","b2fee3b4":"**PREPROCESSING THE TRAIN DATASET**","b9291783":"**LEAF BLAST LEAF**","1cf99dc0":"**DATA AUGMENTATION**","14ee8ea5":"**BROWN SPOT LEAFS**","1781f4cb":"**Context**\n\nI found this dataset when it was not uploaded on Kaggle and was scattered across the internet. This dataset is a collection of multiple data sets I found online. The size of this dataset is ~ 7 GB due to the high resolution of images. The number of images in the dataset is\n3355 .jpg files.\n\n**Content**\n\nThe dataset has been divided into two groups, train and validation.\nInside the two folders are 4 categories of types:\n\nBrownSpot\nHealthy\nHispa\nLeafBlast\n\nNote: The image resolution in the images is not uniform.\n\nPossible Datasets that can be used alongside\n\nRice Leaf Disease Dataset by Marsh\n\nRice Image Dataset by Huy Minh Do\n\nPlant Pathology2020\n\n**Resources**\n\nUCI - Rice Disease","85232fb4":"**PREPROCESSING THE TEST DATASET**","ac1b19b8":"**HISPA LEAFS**"}}