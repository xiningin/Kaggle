{"cell_type":{"7136c4a0":"code","3e28c901":"code","0f746379":"code","51a82bdf":"code","1ffb0fb8":"code","fed9bc83":"code","d397e46c":"code","e77b10b3":"code","24250f4a":"code","79021929":"code","2e368b6d":"code","f76e794e":"code","f0c0a52a":"markdown"},"source":{"7136c4a0":"# some libs to be used\nprint('loading libs...')\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport tqdm\nimport keras\nimport datetime\nfrom keras import backend as K\nfrom keras import callbacks\nfrom scipy import stats\nfrom sklearn.model_selection import KFold,RepeatedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom kaggle.competitions import nflrush\nprint('done')","3e28c901":"# loading env\nenv = nflrush.make_env()","0f746379":"# some constants to be used\nDF_NAME= []\nPATH = '..\/input\/nfl-big-data-bowl-2020\/'\nSEED = 1229\nNFOLDS = 5\nNREPEATS = 5","51a82bdf":"# some functions to be used\n\n# func for seeding\ndef SeedEverything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    return\n\n# func for loading data\ndef DataLoading(path, df_name):\n    files = os.listdir(f'{path}')\n    for i in range(len(files)):\n        s0 = files[i]\n        s1 = files[i][:-4]\n        s2 = files[i][-4:]\n        if s2 =='.csv':\n            print('loading:'+ s1 + '...')\n            globals()[s1] = pd.read_csv(f'{path}'+ s0,  dtype={'WindSpeed': 'object'})\n            df_name.append(s1)\n        elif s2 == '.pkl':\n            print('loading:'+ s1 + '...')\n            globals()[s1] = pd.read_pickle(f'{path}'+ s0,  dtype={'WindSpeed': 'object'})\n            df_name.append(s1)\n        else:\n            pass\n    print('successfully loading: ')\n    print(df_name)\n    print('done')\n    return df_name\n\n# func for data analysis\ndef DataStatistics(df):   \n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values \n    summary['Missing_percentage'] = round((summary['Missing']\/df.shape[0])*100, 1)\n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n       \n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n    summary.set_index('Name',inplace=True)\n    summary = summary.T\n    return summary\n\n# func for showing data\ndef DataShowing(df_name, start=0, end=49, seeall = True):\n    if seeall:\n        pd.set_option('display.max_rows', None)\n        pd.set_option('display.max_columns', None)   \n    df_name.sort(reverse=True)\n    for i in range(len(df_name)):\n        s = df_name[i]\n        df = globals()[s]\n        print('data shape of ' + s + ':' + f'{df.shape}')\n        df = df.iloc[:,start:end]\n        if df.empty:\n            pass\n        else:\n            print('looking over the statistics of all features of ' + s + '...')\n            display(DataStatistics(df))\n            print('looking over the statistics of the num_type_features of ' + s + '...')\n            display(df.describe())\n        return\n\n# func for processing training data \ndef DataProcessing(train):\n    train['PossessionTeam'] = train['PossessionTeam'].map(map_abbr)\n    train['HomeTeamAbbr'] = train['HomeTeamAbbr'].map(map_abbr)\n    train['VisitorTeamAbbr'] = train['VisitorTeamAbbr'].map(map_abbr)\n    train['HomePossesion'] = train['PossessionTeam'] == train['HomeTeamAbbr']\n    \n    train = pd.concat([train.drop(['OffenseFormation'], axis=1), \n                      pd.get_dummies(train['OffenseFormation'], prefix='Formation')], axis=1)\n    globals()['dummy_col'] = train.columns\n    train['GameClock'] = train['GameClock'].apply(strtoseconds)\n    train['PlayerHeight'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m\/%d\/%Y\"))\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()\/seconds_in_year, axis=1)\n    train['WindSpeed'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed'] = train['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))\/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed'] = train['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))\/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed'] = train['WindSpeed'].apply(str_to_float)\n    train['PlayDirection'] = train['PlayDirection'].apply(lambda x: x is 'right')\n    train['Team'] = train['Team'].apply(lambda x: x.strip()=='home')\n    train['GameWeather'] = train['GameWeather'].str.lower()\n    indoor = \"indoor\"\n    train['GameWeather'] = train['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n    train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather'] = train['GameWeather'].apply(map_weather)\n    train['IsRusher'] = train['NflId'] == train['NflIdRusher']\n    train.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate', 'WindDirection','NflId', 'NflIdRusher'],\n               axis=1, inplace=True)\n    train = train.sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index()\n    train.drop(['GameId', 'PlayId', 'index', 'IsRusher', 'Team'], axis=1, inplace=True)\n    cat_features = []\n    for col in train.columns:\n        if train[col].dtype =='object':\n            cat_features.append(col)\n    train.drop(cat_features, axis=1,inplace=True)\n    train.fillna(-999, inplace=True)\n    globals()['players_col'] = []\n    for col in train.columns:\n        if train[col][:22].std()!=0:\n            players_col.append(col)    \n    X_train = np.array(train[players_col]).reshape(-1, 11*22)\n    play_col = train.drop(players_col+['Yards'], axis=1).columns\n    X_play_col = np.zeros(shape=(X_train.shape[0], len(play_col)))\n    for i, col in enumerate(play_col):\n        X_play_col[:, i] = train[col][::22]\n    X_train = np.concatenate([X_train, X_play_col], axis=1)\n    y_train = np.zeros(shape=(X_train.shape[0], 199))\n    for i,yard in enumerate(train['Yards'][::22]):\n        y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n    return X_train, y_train\n    \n    \n\n# func for convert str to seconds   \ndef strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])\/60\n    return ans\n\n# func for convert str to float \ndef str_to_float(txt):\n    try:\n        return float(txt)\n    except:\n        return -1\n    \n# func for map weather    \ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\n# func for metric\ndef crps(y_true, y_pred):\n    ans = 0\n    ground_t = y_true.argmax(1)\n    for i, t in enumerate(ground_t):\n        for n in range(-99, 100):\n            h = n>=(t-99)\n            \n            ans+=(y_pred[i][n+99]-h)**2\n            \n    return ans\/(199*len(y_true))\n\n# RAdam class\n\n__all__ = ['RAdam']\nclass RAdam(keras.optimizers.Optimizer):\n    \"\"\"RAdam optimizer.\n    # Arguments\n        learning_rate: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay: float >= 0. Learning rate decay over each update.\n        weight_decay: float >= 0. Weight decay for each param.\n        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n            algorithm from the paper \"On the Convergence of Adam and\n            Beyond\".\n        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n        min_lr: float >= 0. Minimum learning rate after warmup.\n    # References\n        - [Adam - A Method for Stochastic Optimization](https:\/\/arxiv.org\/abs\/1412.6980v8)\n        - [On the Convergence of Adam and Beyond](https:\/\/openreview.net\/forum?id=ryQu7f-RZ)\n        - [On The Variance Of The Adaptive Learning Rate And Beyond](https:\/\/arxiv.org\/pdf\/1908.03265v1.pdf)\n    \"\"\"\n    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n        learning_rate = kwargs.pop('lr', learning_rate)\n        super(RAdam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n            self.total_steps = K.variable(total_steps, name='total_steps')\n            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n            self.min_lr = K.variable(min_lr, name='min_lr')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.initial_weight_decay = weight_decay\n        self.initial_total_steps = total_steps\n        self.amsgrad = amsgrad\n\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n\n        if self.initial_decay > 0:\n            lr = lr * (1. \/ (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n\n        if self.initial_total_steps > 0:\n            warmup_steps = self.total_steps * self.warmup_proportion\n            decay_steps = K.maximum(self.total_steps - warmup_steps, 1)\n            decay_rate = (self.min_lr - lr) \/ decay_steps\n            lr = K.switch(\n                t <= warmup_steps,\n                lr * (t \/ warmup_steps),\n                lr + decay_rate * K.minimum(t - warmup_steps, decay_steps),\n            )\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n        else:\n            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        beta_1_t = K.pow(self.beta_1, t)\n        beta_2_t = K.pow(self.beta_2, t)\n\n        sma_inf = 2.0 \/ (1.0 - self.beta_2) - 1.0\n        sma_t = sma_inf - 2.0 * t * beta_2_t \/ (1.0 - beta_2_t)\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n\n            m_corr_t = m_t \/ (1.0 - beta_1_t)\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                v_corr_t = K.sqrt(vhat_t \/ (1.0 - beta_2_t))\n                self.updates.append(K.update(vhat, vhat_t))\n            else:\n                v_corr_t = K.sqrt(v_t \/ (1.0 - beta_2_t))\n            r_t = K.sqrt((sma_t - 4.0) \/ (sma_inf - 4.0) *\n                         (sma_t - 2.0) \/ (sma_inf - 2.0) *\n                         sma_inf \/ sma_t)\n\n            p_t = K.switch(sma_t >= 5, r_t * m_corr_t \/ (v_corr_t + self.epsilon), m_corr_t)\n\n            if self.initial_weight_decay > 0:\n                p_t += self.weight_decay * p\n\n            p_t = p - lr * p_t\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    @property\n    def lr(self):\n        return self.learning_rate\n\n    @lr.setter\n    def lr(self, learning_rate):\n        self.learning_rate = learning_rate\n\n    def get_config(self):\n        config = {\n            'learning_rate': float(K.get_value(self.learning_rate)),\n            'beta_1': float(K.get_value(self.beta_1)),           \n            'beta_2': float(K.get_value(self.beta_2)),\n            'decay': float(K.get_value(self.decay)),\n            'weight_decay': float(K.get_value(self.weight_decay)),\n            'epsilon': self.epsilon,\n            'amsgrad': self.amsgrad,\n            'total_steps': float(K.get_value(self.total_steps)),\n            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n            'min_lr': float(K.get_value(self.min_lr)),\n        }\n        base_config = super(RAdam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\n# func for building the model\ndef ModelBuild(X_train, y_train):\n    score = 0\n    i = 0\n    folds = RepeatedKFold(n_splits=NFOLDS,  n_repeats=NREPEATS, random_state = SEED)\n    splits = folds.split(X_train,y_train)\n    for fold_n, (train_index, valid_index) in enumerate(splits):\n        X_tr, X_val = X_train[train_index], X_train[valid_index]\n        y_tr, y_val = y_train[train_index], y_train[valid_index]\n        \n        globals()['model' + str(i)] = keras.models.Sequential([\n            keras.layers.Dense(units=512, input_shape=[X_tr.shape[1]], activation='relu'),\n            keras.layers.BatchNormalization(),\n            keras.layers.Dropout(0.3),\n            keras.layers.Dense(units=256, activation='relu'),\n            #keras.layers.BatchNormalization(),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(units=256, activation='relu'),\n            #keras.layers.BatchNormalization(),\n            keras.layers.Dense(units=199, activation='sigmoid')\n            ])\n        globals()['model' + str(i)] .compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-5), loss='mse')\n        es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=15,verbose=1, mode='auto', restore_best_weights=True)\n        rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=10, min_lr=1e-6, mode='auto', verbose=1)\n        globals()['model' + str(i)].fit(X_tr,[y_tr], validation_data=(X_val,[y_val]), callbacks=[es, rlr],epochs=100, batch_size=128, verbose=0)\n        cv_predict= globals()['model' + str(i)].predict(X_val)\n        crps_res = crps(y_val,cv_predict)\n        print(f'The CV score is: {crps_res}')\n        score +=crps_res      \n        i += 1\n    score = score\/(NFOLDS*NREPEATS)\n    print(f'The averge CV score is: {score}')\n    return\n    \n\n# func for make prediction\ndef make_pred(df, sample, env, model):\n    df['OffenseFormation'] = df['OffenseFormation'].apply(lambda x: x if x in off_form else np.nan)\n    df = pd.concat([df.drop(['OffenseFormation'], axis=1), pd.get_dummies(df['OffenseFormation'], prefix='Formation')], axis=1)\n    missing_cols = set( dummy_col ) - set( test.columns )-set('Yards')\n    for c in missing_cols:\n        df[c] = 0\n    df = df[dummy_col]\n    df.drop(['Yards'], axis=1, inplace=True)\n    df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n    df['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\n    df['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].map(map_abbr)\n    df['HomePossesion'] = df['PossessionTeam'] == df['HomeTeamAbbr']\n    df['GameClock'] = df['GameClock'].apply(strtoseconds)\n    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m\/%d\/%Y\"))\n    seconds_in_year = 60*60*24*365.25\n    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()\/seconds_in_year, axis=1)\n    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))\/2 if not pd.isna(x) and '-' in x else x)\n    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))\/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    df['WindSpeed'] = df['WindSpeed'].apply(str_to_float)\n    df['PlayDirection'] = train['PlayDirection'].apply(lambda x: x is 'right')\n    df['Team'] = df['Team'].apply(lambda x: x.strip()=='home')\n    indoor = \"indoor\"\n    df['GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n    df['GameWeather'] = df['GameWeather'].apply(lambda x: x.lower().replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly').replace('clear and sunny', 'sunny and clear').replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    df['GameWeather'] = df['GameWeather'].apply(map_weather)\n    df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n    \n    df = df.sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index()\n    df = df.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate', 'WindDirection', 'NflId', 'NflIdRusher', 'GameId', 'PlayId', 'index', 'IsRusher', 'Team'], axis=1)\n    cat_features = []\n    for col in df.columns:\n        if df[col].dtype =='object':\n            cat_features.append(col)\n\n    df = df.drop(cat_features, axis=1)\n    df.fillna(-999, inplace=True)\n    X = np.array(df[players_col]).reshape(-1, 11*22)\n    play_col = df.drop(players_col, axis=1).columns\n    X_play_col = np.zeros(shape=(X.shape[0], len(play_col)))\n    for i, col in enumerate(play_col):\n        X_play_col[:, i] = df[col][::22]\n    X = np.concatenate([X, X_play_col], axis=1)\n    y_pred = np.zeros(199).reshape(1,199)\n    for i in range(NFOLDS*NREPEATS):\n        globals()['y_pred' + str(i)] = globals()['model' + str(i)].predict(X)\n        y_pred += globals()['y_pred' + str(i)]\n    y_pred = y_pred\/(NFOLDS*NREPEATS)\n    for pred in y_pred:\n        prev = 0\n        for i in range(len(pred)):\n            if pred[i]<prev:\n                pred[i]=prev\n            prev=pred[i]\n    y_pred = pd.DataFrame(data=y_pred,columns=sample.columns)\n    #y_pred.iloc[:,:85] = 0\n    #y_pred.iloc[:,130:] = 1\n    env.predict(y_pred)\n    return y_pred\n\n\n","1ffb0fb8":"# seeding \nSeedEverything(SEED)","fed9bc83":"# loading data\ndf_name = DataLoading(PATH, DF_NAME)","d397e46c":"# looking at the original data\n# DataShowing(df_name)","e77b10b3":"# some variables to be used\nmap_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\nfor abb in train['PossessionTeam'].unique():\n    map_abbr[abb] = abb\noff_form = train['OffenseFormation'].unique()","24250f4a":"# processing traing data\nX_train, y_train = DataProcessing(train)","79021929":"# building the NN model\nmodel = ModelBuild(X_train, y_train)","2e368b6d":"# making predictions\nfor test, sample in tqdm.tqdm(env.iter_test()):\n    make_pred(test, sample, env, model)","f76e794e":"# submitting\nenv.write_submission_file()","f0c0a52a":"Coding based on https:\/\/www.kaggle.com\/bgmello\/neural-networks-feature-engineering-for-the-win \n\n**Main change: Using KFold**"}}