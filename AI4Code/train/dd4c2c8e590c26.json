{"cell_type":{"81cb628a":"code","093c204f":"code","4664ded6":"code","c4c6fad0":"code","e22227f1":"code","59e1dcd8":"code","19776dbb":"code","53e7965d":"code","55d1c79f":"code","b59ecba7":"code","54063a93":"code","50731675":"code","21731cf5":"code","0d5624d2":"code","e176e075":"code","7c151a80":"markdown","06fd613e":"markdown","3bcb98f4":"markdown","efc3a591":"markdown","9ad45968":"markdown","916574da":"markdown"},"source":{"81cb628a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","093c204f":"df=pd.read_csv(r\"\/kaggle\/input\/indian-liver-patient-records\/indian_liver_patient.csv\")","4664ded6":"np.random.seed(0)\ndf.sample(10)","c4c6fad0":"df.info()","e22227f1":"df.isnull().sum()","59e1dcd8":"df['Albumin_and_Globulin_Ratio'].fillna(df['Albumin_and_Globulin_Ratio'].mean(), inplace = True)\ndf.isnull().sum()","19776dbb":"df.shape","53e7965d":"df.describe()","55d1c79f":"# fig = plt.figure(figsize = (15,20))\ndf.hist(figsize = (15,20))","b59ecba7":"df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})","54063a93":"df.head(10)","50731675":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score","21731cf5":"X = df.drop([\"Dataset\"],axis = 1)\nY = df[\"Dataset\"]","0d5624d2":"scaler=MinMaxScaler()\nscaled_values=scaler.fit_transform(X)\nX.loc[:,:]=scaled_values\nX_train, X_test, Y_train, Y_test=train_test_split(X,Y,stratify=Y, test_size=0.3,random_state=42)\nX_train.shape, Y_train.shape, X_test.shape, Y_test.shape","e176e075":"model_gaussNB = GaussianNB()\nmodel_gaussNB.fit(X_train, Y_train)\ny_pred = model_gaussNB.predict(X_test)\nK_fold = StratifiedKFold(n_splits=10)\nscores = cross_val_score(model_gaussNB, X_train, Y_train, cv=K_fold, n_jobs=4, scoring='accuracy')\n\nprint(scores)\nscore_gaussNB = round(np.mean(scores) * 100, 3)\nprint(\"Score: {}\".format(score_gaussNB))\nacc_gaussNB = round(np.mean(accuracy_score(Y_test, y_pred)) * 100, 3)\nprint(\"Accuracy: {}\".format(acc_gaussNB))","7c151a80":"### Seems like there are only 4 rows with null values. With this information I believe we should use mean for imputation","06fd613e":"## Checking for null values","3bcb98f4":"## This notebook was generated to practice data cleaning and implmentation of Naive Bayes. The dataset is very clean and hardly needs work ","efc3a591":"## Reading the file","9ad45968":"## Implementing Naive Bayes","916574da":"## Peeking into the data"}}