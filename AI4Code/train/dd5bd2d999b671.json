{"cell_type":{"264e9540":"code","5c3ed70d":"code","f8d05b99":"code","e3cd3e75":"code","2ff32387":"code","ee2012d8":"code","f4f3dc1b":"code","52849c8d":"code","75b282a2":"code","2c35c0d9":"code","b5986d00":"code","f24536f3":"code","1336f12f":"code","84ac2eab":"code","211880bf":"code","2ee265bc":"code","4abbf7a0":"code","5dd41d2c":"code","ff751aa8":"markdown"},"source":{"264e9540":"# Import the required libraries\n\nimport os\nimport random\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img","5c3ed70d":"# Store the base directory path\n\nbase_dir = os.path.join(\"\/kaggle\/input\/kermany2018\/oct2017\/OCT2017 \/\")\nprint('Base directory --> ', os.listdir(base_dir))","f8d05b99":"# Store the train, validation and test directory paths\n\ntrain_dir = os.path.join(base_dir + \"train\/\")\nprint(\"Train Directory --> \", os.listdir(train_dir))\n\nvalidation_dir = os.path.join(base_dir + \"val\/\")\nprint(\"Validation Directory --> \", os.listdir(validation_dir))\n\ntest_dir = os.path.join(base_dir + \"test\/\")\nprint(\"Test Directory --> \", os.listdir(test_dir))","e3cd3e75":"# Plot each type of image in the dataset\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 10))\n\ndrusen = random.choice(os.listdir(train_dir + \"DRUSEN\"))\ndrusen_image = load_img(train_dir + \"DRUSEN\/\" + drusen)\nax[0].imshow(drusen_image)\nax[0].set_title(\"DRUSEN\")\nax[0].axis(\"Off\")\n\ndme = random.choice(os.listdir(train_dir + \"DME\"))\ndme_image = load_img(train_dir + \"DME\/\" + dme)\nax[1].imshow(dme_image)\nax[1].set_title(\"DME\")\nax[1].axis(\"Off\")\n\ncnv = random.choice(os.listdir(train_dir + \"CNV\"))\ncnv_image = load_img(train_dir + \"CNV\/\" + cnv)\nax[2].imshow(cnv_image)\nax[2].set_title(\"CNV\")\nax[2].axis(\"Off\")\n\nnormal = random.choice(os.listdir(train_dir + \"NORMAL\"))\nnormal_image = load_img(train_dir + \"NORMAL\/\" + normal)\nax[3].imshow(normal_image)\nax[3].set_title(\"NORMAL\")\nax[3].axis(\"Off\")\n\nplt.show()","2ff32387":"INPUT_SHAPE = (150, 150, 3)","ee2012d8":"resnet = tf.keras.applications.ResNet50(\n    include_top = False, \n    weights='imagenet', \n    input_tensor = None,\n    input_shape = INPUT_SHAPE, \n    pooling = None, \n    classes=1000\n)","f4f3dc1b":"resnet.trainable = False","52849c8d":"model = tf.keras.models.Sequential([\n    \n    resnet,\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation = 'relu'),\n    tf.keras.layers.Dense(4, activation = 'softmax')\n])","75b282a2":"model.summary()","2c35c0d9":"metrics_list = ['accuracy',\n                tf.keras.metrics.AUC(),\n                tfa.metrics.CohenKappa(num_classes = 4),\n                tfa.metrics.F1Score(num_classes = 4)]","b5986d00":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = metrics_list)","f24536f3":"train_datagen = ImageDataGenerator(rescale = 1.\/255)\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 100)","1336f12f":"validation_datagen = ImageDataGenerator(rescale = 1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 16)","84ac2eab":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_directory(test_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 44)","211880bf":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch = (83484\/100),\n    epochs = 10,\n    validation_data = validation_generator,\n    validation_steps = (32\/16),\n    verbose = 1)","2ee265bc":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.figure(figsize=(7,7))\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure(figsize = (7,7))\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","4abbf7a0":"model.predict(test_generator, steps = int(968\/44))","5dd41d2c":"from sklearn.metrics import confusion_matrix, classification_report\nimport pandas as pd\n\nY_pred = model.predict(test_generator, int(968\/44))\ny_pred = np.argmax(Y_pred, axis = 1)\n\ncm = confusion_matrix(test_generator.classes, y_pred)\ndf_cm = pd.DataFrame(cm, list(test_generator.class_indices.keys()), list(test_generator.class_indices.keys()))\n\nfig, ax = plt.subplots(figsize = (10,8))\nsns.set(font_scale = 1.4) # for label size\nsns.heatmap(df_cm, annot = True, annot_kws = {\"size\": 16}, cmap = plt.cm.Blues)\nplt.title('Confusion Matrix\\n')\nplt.savefig('confusion_matrix.png', transparent = False, bbox_inches = 'tight', dpi = 400)\nplt.show()\n\nprint('Classification Report\\n')\ntarget_names = list(test_generator.class_indices.keys())\nprint(classification_report(test_generator.classes, y_pred, target_names = target_names))","ff751aa8":"**This notebook implements a ResNet50 on OCT image dataset to classify the diseases**"}}