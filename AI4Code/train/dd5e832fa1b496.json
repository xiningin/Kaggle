{"cell_type":{"acfd2bf9":"code","e35bb5c7":"code","e40e1179":"code","a3669da9":"code","86024953":"code","6f44f93a":"code","e634daee":"code","9e633f07":"code","dc5f1a0d":"code","2cba67bf":"code","9506aaa7":"code","b1930da7":"code","eece3857":"code","c66ec7b3":"code","bc90613e":"code","3ed1881d":"markdown","fe1c0134":"markdown","e9024f2c":"markdown"},"source":{"acfd2bf9":"!pip install  ..\/input\/numpy-indexed-v035\/numpy_indexed-0.3.5-py2.py3-none-any.whl -qq","e35bb5c7":"import pickle\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport gc\nimport numpy_indexed as npi\ngc.enable()","e40e1179":"# reduce cols for use to save memory capacity\nfeatures = [f'f_{i}' for i in range(300)]\n\n# load data\ntrain_df = pd.read_parquet('..\/input\/speed-up-reading-csv-to-pickle\/train_low_mem.parquet')\ndisplay(train_df)","a3669da9":"# split train data\ntrain = train_df[train_df['time_id'].isin(range(1000))]\nvalid = train_df[train_df['time_id'].isin(range(1000, 1220))]\n\ndisplay(train)\ndisplay(valid)","86024953":"# prepare for training\ntr_y = train['target'].values\ntr_x = train[['investment_id'] + features ].values\nval_y = valid['target'].values\nval_x = valid[['investment_id'] + features].values\nval_time_id = valid['time_id']","6f44f93a":"del train_df, train, valid\ngc.collect()","e634daee":"import numpy_indexed as npi\n\n# numpy_indexed example \n\ngroups = np.array([1, 1, 1, 2, 2, 3, 3, 1])\ngroup = npi.group_by(groups)\ngroup.split(np.arange(len(groups)))","9e633f07":"from scipy.stats import pearsonr\nfrom sklearn.metrics import mean_squared_error\n\nclass MetricCorr:\n    def __init__(self, time_id: pd.Series):\n        self.time_id = npi.group_by(time_id.values)\n\n    def corrs(self, preds, target):\n        labels = self.time_id.split(target)\n        corrs = [pearsonr(preds, rank)[0] for preds, rank in zip(self.time_id.split(preds), labels)]\n        return corrs\n\n    def corr_mean_lgb(self, preds: np.ndarray, data: lgb.Dataset):\n        labels = self.time_id.split(data.get_label())\n        corr_mean = np.mean([pearsonr(preds, rank)[0] for preds, rank in zip(self.time_id.split(preds), labels)])\n        return 'corr_mean', corr_mean, True\n\n    def rmse_lgb(self, preds: np.ndarray, data: lgb.Dataset):\n        labels = data.get_label()\n        rmse = np.sqrt(mean_squared_error(preds, labels))\n        return 'rmse', rmse, False\n\nmetric = MetricCorr(val_time_id)","dc5f1a0d":"params = {\n        'objective': 'regression',\n        'learning_rate': 0.05,\n        'num_leaves': 63,\n        'max_depth': 6,\n        'verbosity': -1,\n        'min_data_in_leaf': 300,\n        'metrics': 'None',\n    }\n\ndef single_lightgbm(tr_x, tr_y, val_x, val_y, params, categorical_features=[], seed=None):\n    lgb_train = lgb.Dataset(tr_x, tr_y, categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(val_x, val_y, categorical_feature=categorical_features)\n\n    if seed is not None:\n        params['seed'] = seed\n        print('seed', seed)\n    evals_result = { }\n\n    model = lgb.train(params, lgb_train, valid_sets=lgb_eval,\n                      verbose_eval=50,\n                      num_boost_round=1000,\n                      evals_result=evals_result,\n                      feval=[metric.corr_mean_lgb, metric.rmse_lgb])\n    \n    pred = model.predict(val_x)\n    return pred, model, evals_result","2cba67bf":"pred, model, evals_result = single_lightgbm(tr_x, tr_y, val_x, val_y, params, categorical_features=[0], seed=0)","9506aaa7":"import matplotlib.pyplot as plt\nplt.subplot(211)\nplt.plot(evals_result['valid_0']['corr_mean'], label='Pearson correlation')\nplt.legend()\nplt.subplot(212)\nplt.plot(evals_result['valid_0']['rmse'], label='RMSE')\nplt.legend()\nplt.xlabel('itration');","b1930da7":"# Histogram of predicted values per iteration\nitr_list = [100, 300, 500, 1000]\npreds = []\nfor itr in itr_list:\n    pred_ = model.predict(val_x, num_iteration=itr)\n    preds.append(pred_)\n\nfor i in range(4):\n    plt.subplot(2, 2, i + 1)\n    plt.hist(preds[i], bins=50, range=(-1.5, 1.5))\n    plt.ylim(0, 280000)\n    plt.title(f'num_iteration: {itr_list[i]}')\nplt.tight_layout()","eece3857":"for i in range(4):\n    plt.hist(preds[i], alpha=0.4, bins=50, range=(-1.5, 1.5), label=f'num_round{itr_list[i]}')\nplt.legend()\nplt.tight_layout()","c66ec7b3":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nfor i in range(4):\n    valid_corrs = metric.corrs(val_y, preds[i])\n    plt.plot(range(1000, 1220), valid_corrs, label=f'num_round {itr_list[i]}')\n    plt.xlabel('time_id')\n    plt.ylabel('corr')\nplt.legend()\nplt.title('Pearson correlation by time_id')\nplt.tight_layout()","bc90613e":"del tr_y, tr_x, val_y, val_x\ngc.collect()","3ed1881d":"Ver1:\n\nI made two changes to this notebook https:\/\/www.kaggle.com\/yosukeyama\/ubiquant-simple-lgbm-train-infer\n\n* added a custom metric \n* Verification set is separated by time_id\n\nVer2:\n\n* use all the features.\n\nVer4:\n\n* Use recent data of time_id for training\n\nVer5:\n\n* 5seed averaging\n\nVer6:\n\n* np.corrcoef -> scipy.stats.pearsonr\n* Check predictions by changing iteration.\n\n","fe1c0134":"## lgb model","e9024f2c":"## metric"}}