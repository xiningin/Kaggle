{"cell_type":{"1849de14":"code","275b2f84":"code","f6e36e51":"code","7deb5a0b":"code","471eed24":"code","793de27f":"code","43482cf4":"code","61f46b0b":"code","10c2ff45":"code","551f0ed8":"code","cf5855ec":"code","2fc79f1f":"code","e015fd4a":"code","14bf6177":"code","344120ea":"code","f1e8c434":"code","bf5daec0":"code","246f1590":"code","889bea38":"code","d9b4dc43":"code","5b6359bf":"code","bf122bfa":"code","0e3debc4":"code","4556f55e":"code","d04ec472":"code","478c7bbd":"code","23536b83":"code","086e6bc1":"code","5e12dd1d":"code","241ca902":"code","9aaf795c":"code","083862dc":"code","81b41335":"code","b737d11c":"code","ec0c7187":"code","da661b0c":"code","2490859b":"code","50c9438a":"code","8ad57b7d":"code","ecb7845d":"code","5782be53":"code","8f67e564":"code","86510a95":"code","a4050c10":"code","f40feeab":"code","b5c26de6":"code","19630ea7":"code","1f8e3d67":"code","796f2be8":"code","64037366":"code","3c7b4dc5":"code","e760b8ef":"code","49f5e33b":"code","3e7e4c50":"code","10a97a64":"code","9c38f104":"code","28ffe4aa":"code","6f8284cc":"code","7835bc4c":"code","18b5fa43":"code","6d600d90":"code","46170468":"code","2abbf037":"code","da3fc4e7":"markdown","d6d59c0b":"markdown"},"source":{"1849de14":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","275b2f84":"data=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndata","f6e36e51":"data.Embarked.unique()\ndata['Embarked_s']=data['Embarked'].replace('Q',0).replace('C',0).replace('S',1)\ndata['Embarked_c']=data['Embarked'].replace('S',0).replace('Q',0).replace('C',1)\ndata['Embarked_q']=data['Embarked'].replace('C',0).replace('S',0).replace('Q',1)","7deb5a0b":"#data.Sex= data.Sex.map( {'M': 1, 'F': 0, 'O': 3} )\ndata['Sex'].replace( 'female', 0, inplace=True )\ndata['Sex'].replace( 'male', 1, inplace=True )\ndata","471eed24":"#data=data[data.Embarked!=0]\n#data=data[data[('Embarked')].map(data['Embarked'].value_counts())>0]*\n#data","793de27f":"data.isnull().sum()","43482cf4":"#data.Sex=data.Sex.fillna(0)\n#data.Age=data.Age.fillna(0)\n#data.Cabin=data.Cabin.fillna(0)\n#data.Embarked_s=data.Embarked_s.fillna(0)\n#data.Embarked_c=data.Embarked_c.fillna(0)\n#data.Embarked_q=data.Embarked_q.fillna(0)","61f46b0b":"data['Survived']","10c2ff45":"data.isnull().sum()","551f0ed8":"data.dtypes","cf5855ec":"x = data.drop(columns = ['Survived','Ticket','Cabin','PassengerId','Name','Embarked'])","2fc79f1f":"y = data[['Survived']]","e015fd4a":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)","14bf6177":"x.head()","344120ea":"x.dtypes","f1e8c434":"x","bf5daec0":"x.Embarked_q.unique()","246f1590":"nom_cols =[]\nord_cols = []\nnum_cols=[0,4,5]\nnull_cols=[1,2,6,7,8]\n#Kbin_cols=[0,1,4],\nbinarizer_cols=[3]","889bea38":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,KBinsDiscretizer,Binarizer\nfrom sklearn.impute import SimpleImputer,KNNImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import set_config\nfrom sklearn.preprocessing import StandardScaler\n\ntrans = make_column_transformer((OneHotEncoder(sparse=False),nom_cols),\n                                (KNNImputer(n_neighbors=45),null_cols),\n                                (OrdinalEncoder(), ord_cols),(StandardScaler(),num_cols)\n                                 ,(Binarizer(threshold=55),binarizer_cols),remainder= 'passthrough')\nset_config(display= 'diagram')\ntrans\n#trans = make_column_transformer((OneHotEncoder(sparse=False),nom_cols),(SimpleImputer(strategy='mean'),null_cols),\n                                 #(OrdinalEncoder(), ord_cols),(StandardScaler(),num_cols),(KBinsDiscretizer(),Kbins_cols)\n                                 #,(Binarizer(threshold=55),binarizer_cols),remainder= 'passthrough')\n#set_config(display= 'diagram')\n#trans","d9b4dc43":"from sklearn.tree import DecisionTreeClassifier \nalgorithm_x=DecisionTreeClassifier(criterion='entropy')","5b6359bf":"from sklearn.neighbors import KNeighborsClassifier\nalgorithm = KNeighborsClassifier(15) #\nalgorithm","bf122bfa":"from sklearn.pipeline import make_pipeline\npipe = make_pipeline(trans,algorithm)\npipe_x=make_pipeline(trans,algorithm_x)\npipe","0e3debc4":"pipe_x","4556f55e":"pipe.fit(x_train,y_train)","d04ec472":"pipe_x.fit(x_train,y_train)","478c7bbd":"pred_x=pipe_x.predict(x_test)\npred_x","23536b83":"from sklearn.metrics import accuracy_score, plot_confusion_matrix\naccuracy_score(pred_x,y_test)*100","086e6bc1":"pred=pipe.predict(x_test)\npred","5e12dd1d":"from sklearn.metrics import accuracy_score, plot_confusion_matrix\naccuracy_score(pred,y_test)*100","241ca902":"import matplotlib as plt \nplot_confusion_matrix(pipe,x_test,y_test)","9aaf795c":"from imblearn.over_sampling import RandomOverSampler\nover= RandomOverSampler()\no_x , o_y = over.fit_resample(x,y)\no_y.value_counts()","083862dc":"from imblearn.over_sampling import SMOTE\nover= RandomOverSampler()\n_x , o_y = over.fit_resample(x,y)\no_y.value_counts()","81b41335":"from imblearn.pipeline import make_pipeline\ns = SMOTE()\nn_pipe = make_pipeline(trans,s,algorithm)\nn_pipe","b737d11c":"accuracy_score(pred,y_test)*100","ec0c7187":"from sklearn.linear_model import LogisticRegression as lr\nalgorithm_2 = lr(solver='liblinear')\npipe_2 = make_pipeline(trans,algorithm_2)\npipe_2","da661b0c":"pipe_2.fit(x_train,y_train)","2490859b":"pred_2 = pipe_2.predict(x_test)\npred_2","50c9438a":"accuracy_score(pred_2,y_test)*100","8ad57b7d":"from sklearn.model_selection import KFold, cross_val_score,StratifiedKFold\nkf=StratifiedKFold(n_splits=4)\nnp.mean(cross_val_score(pipe,x,y,cv=kf,scoring='accuracy')*100)","ecb7845d":"from sklearn.svm import SVC\nmodel1=SVC(kernel='linear')\npipe_1 = make_pipeline(trans,algorithm)\npipe_1\npipe_1.fit(x_train,y_train)\npred_1=pipe.predict(x_test)\naccuracy_score(pred_1,y_test)*100","5782be53":"from sklearn.ensemble import BaggingClassifier\nmodel2=BaggingClassifier(base_estimator=SVC(3))\nmodel2","8f67e564":"y_test.shape","86510a95":"pipe5=make_pipeline(trans,model2)\npipe5","a4050c10":"pipe5.fit(x_train,y_train)\npred5=pipe5.predict(x_test)","f40feeab":"pred5.shape","b5c26de6":"accuracy_score(pred5,y_test)*100","19630ea7":"data1=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndata1","1f8e3d67":"data1['Sex'].replace( 'female', 0, inplace=True )\ndata1['Sex'].replace( 'male', 1, inplace=True )","796f2be8":"data1.isnull().sum()","64037366":"#data1.Age=data1.Age.fillna(0)\ndata1.Cabin=data1.Cabin.fillna(0)\ndata1.Fare=data1.Fare.fillna(0)","3c7b4dc5":"data1.isnull().sum()","e760b8ef":"#data1=data1[data1.Embarked!=0]\n#data1=data1[data1[('Embarked')].map(data1['Embarked'].value_counts())>0]\n#data1","49f5e33b":"#data1.loc[data1['Sex']=='male']=1\n#data1.loc[data1['Sex']=='female']=0","3e7e4c50":"data1['Embarked_s']=data1['Embarked'].replace('Q',0).replace('C',0).replace('S',1)\ndata1['Embarked_c']=data1['Embarked'].replace('S',0).replace('Q',0).replace('C',1)\ndata1['Embarked_q']=data1['Embarked'].replace('C',0).replace('S',0).replace('Q',1)","10a97a64":"data1.head()","9c38f104":"x1 = data1.drop(columns = ['Ticket','Cabin','PassengerId','Name','Embarked'])\nx1","28ffe4aa":"x1.isnull().sum()","6f8284cc":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,KBinsDiscretizer,Binarizer\nfrom sklearn.impute import SimpleImputer,KNNImputer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import set_config\nfrom sklearn.preprocessing import StandardScaler\n\ntrans = make_column_transformer((OneHotEncoder(sparse=False),nom_cols),\n                                (KNNImputer(n_neighbors=45),null_cols),\n                                (OrdinalEncoder(), ord_cols),(StandardScaler(),num_cols)\n                                 ,(Binarizer(threshold=55),binarizer_cols),remainder= 'passthrough')\nset_config(display= 'diagram')\ntrans","7835bc4c":"pred123=pipe_x.predict(x1)\npred123","18b5fa43":"#survival_prediction=algorithm.predict(x1)\n#survival_prediction","6d600d90":"submit=pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","46170468":"submit['Survived']=pred123\nsubmit.to_csv('submission.csv', index=False)","2abbf037":"submit.Survived.value_counts()","da3fc4e7":"**2. Replace the values in 'Embarked' column and make separate values for each of the following values it contains in that column\nNote : We are converting strings into int to prevent further errors that would occur in the followig steps**","d6d59c0b":"**If you want to remove 0 value in 'Embarked' column then simply run the code given below and get the required data .**"}}