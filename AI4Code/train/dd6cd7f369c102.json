{"cell_type":{"e07aa913":"code","11dc6e69":"code","7bafdd7f":"code","a390015f":"code","1a1edaec":"code","f0a967df":"code","85f9e824":"code","67a75993":"code","b32bf059":"code","4fe27056":"code","fd4be820":"code","54d49a40":"code","2dd6ee9b":"code","49629978":"code","0c28579b":"code","81901afb":"code","a15441de":"code","e36ae403":"code","b01ae50b":"code","a3ef6f61":"code","f4ad60fe":"code","09f6617e":"code","43ec47cc":"code","a6cfd31a":"code","67095136":"code","d4a68877":"code","35e19f73":"code","594ad920":"code","d647d186":"code","3baf459d":"code","6868ee33":"code","5c2b6da1":"code","acd4f978":"code","e5e0dd80":"code","6f50bfce":"code","e74e3b62":"code","4f1594d0":"code","cae11f1e":"code","7ab49a73":"code","c9587199":"markdown","ff816862":"markdown","5e0d0a3a":"markdown","f9c7c35e":"markdown","0fe16d54":"markdown","32766459":"markdown","693e20df":"markdown","fc5b93d1":"markdown","b0d521b0":"markdown","50576ed4":"markdown","3de29e42":"markdown","27c4a87e":"markdown","d58a06a8":"markdown","40be406a":"markdown","2d1fe5f0":"markdown","ec95d8ec":"markdown","ef7f0c98":"markdown","c4c9be40":"markdown","5d9fd782":"markdown","f3f6f7e0":"markdown","16e2b1da":"markdown","d95a5120":"markdown","09c48920":"markdown","47419426":"markdown","06dfbfbb":"markdown","ae729722":"markdown","87f57ef8":"markdown","36449954":"markdown","b2cd387d":"markdown","3c1606dc":"markdown","82c0a55c":"markdown","45d461a5":"markdown","41e58b3a":"markdown","f11b35e1":"markdown","66872382":"markdown","b3f04ef1":"markdown","760c614f":"markdown","44aa5eba":"markdown","a7844246":"markdown","8bb7c9ae":"markdown"},"source":{"e07aa913":"# Importing modules\nimport re\nimport pandas as pd\nimport spacy\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom IPython.display import display\nfrom wordcloud import WordCloud, STOPWORDS","11dc6e69":"# Setting to use seaborn style for plots\nmatplotlib.style.use(\"seaborn\")","7bafdd7f":"# Loading data\ntrain = pd.read_csv(\"..\/input\/twitter-sentiment-analysis-hatred-speech\/train.csv\")\ntest = pd.read_csv(\"..\/input\/twitter-sentiment-analysis-hatred-speech\/test.csv\")","a390015f":"# Displaying sample obervations\ndisplay(train.head())\ndisplay(test.head())","1a1edaec":"# Label encodings\nlabels = {0: \"not offensive\", 1: \"offensive\"}\nprint(labels)","f0a967df":"display(train.info())","85f9e824":"display(test.info())","67a75993":"# Visualising distribution of observations among categories\n\nplt.figure(figsize=(6, 6))\n\n# Creates pie chart\nplt.pie(\n    train[\"label\"].value_counts(),\n    autopct = \"%.2f%%\",\n    labels = [\"Not Offensive\", \"Offensive\"],\n    colors = [\"#00ff00\", \"#ff0000\"]\n)\n\n# Creates circle\ncircle = plt.Circle((0,0), 0.80,fc='white')\n\n# Adds circle object to the existing figure (pie chart)\nfig = plt.gcf()\nfig.gca().add_artist(circle)\n\nplt.show()","b32bf059":"# Plotting histogram for number of tokens in each observation\nax1 = train.tweet.str.split().map(lambda x: len(x)).hist(figsize=(10, 6))\nax1.set(xlabel=\"( Number of Tokens )\", ylabel=\"( Number of Observations )\")","4fe27056":"# Plotting boxplot for number of tokens in each observation\nax2 = train.tweet.str.split().map(lambda x: len(x)).plot.box(figsize=(6,8))\nax2.set_ylabel(\"( Number of Tokens )\")","fd4be820":"def preprocess_tweets(df_series):\n    \"\"\" Removes account tags (@user) and all non-alphanumeric characters except whitespace.\n        \n    Args:\n        df_series (pd.series): Pandas series object containing tweets.\n        \n    Returns: \n        df_series (pd.series): Preprocessed series object. \n    \"\"\"\n    \n    # Removes '@user' tags\n    df_series = df_series.str.replace(\"@user\", \"\", regex=False)\n    \n    # Removes non alphanumeric characters\n    df_series = df_series.str.replace(\"[^a-zA-Z0-9 ]\", \" \")\n    return df_series\n    \n\ndef tokenize(sentence, remove_stopwords=False):\n    \"\"\" Tokenizes given sentence.\n        \n    Args:\n        sentence (str): Sentence to be tokenized\n        remove_stopwords (bool): removes stop words if set True. Defaults to False.\n        \n    Returns: \n        tokens (list): Tokenized array\n    \"\"\"\n    \n    if remove_stopwords:\n        stop_words = set(stopwords.words('english'))\n        tokens = sentence.split()\n        tokens = [token for token in tokens if not token.lower() in stop_words]\n        return tokens\n        \n    return sentence.split()\n    \n\ndef create_corpus(df_series, remove_stopwords=False):\n    \"\"\" Creates preprocessed, lemmatized word corpus from pandas series.\n        \n    Args:\n        df_series (pd.series): Pandas series object containing tweets.\n        remove_stopwords (bool): removes stop words if set True. Defaults to False.\n        \n    Returns: \n        corpus (list): Tokenized, Lemmatized word corpus. \n    \"\"\"\n    \n    corpus = []\n    lm = WordNetLemmatizer()\n    df_series = preprocess_tweets(df_series)\n    \n    for tweet in df_series:\n        corpus.extend([lm.lemmatize(word) for word in tokenize(tweet, remove_stopwords=remove_stopwords)])\n    \n    return corpus\n    \n\noffensive_corpus = create_corpus(train[train[\"label\"]==1].tweet, remove_stopwords=True)\nnon_offensive_corpus = create_corpus(train[train[\"label\"]==0].tweet, remove_stopwords=True)","54d49a40":"def plot_word_cloud(corpus):\n    \"\"\" Creates and plots the word cloud from word corpus.\n        \n    Args:\n        corpus (list): word corpus containing all the tokens.\n        \n    Returns: Nothing\n    \n    \"\"\"\n    \n    # creates word cloud\n    word_cloud = WordCloud(\n        max_words = 100,\n        max_font_size = 50,\n        collocations = False\n    ).generate(str(corpus))\n    \n    # plots word cloud\n    fig = plt.figure(figsize=(13, 13))\n    plt.axis('off')\n    plt.imshow(word_cloud)\n    plt.plot()","2dd6ee9b":"# Word cloud of non-offensive tokens\nplot_word_cloud(non_offensive_corpus)","49629978":"# Word cloud of offensive tokens\nplot_word_cloud(offensive_corpus)","0c28579b":"def create_ner_dict(df_series):\n    \"\"\" Creates and returns dictionary having text phrases and their named entity.\n    \n    Args:\n        df_series (pd.series): Pandas series object containing sentences.\n    \n    Returns:\n        NER_dict (dict): Dictionary of text phrases from sentences of df_series and \n                         corresponding named entities.\n    \"\"\"\n    \n    NER = spacy.load(\"en_core_web_sm\")\n    NER_dict = {\"text\": [], \"named_entity\":[]}\n    \n    # Preprocessing tweets\n    preprocessed_tweets = preprocess_tweets(df_series)\n    \n    # Removing stop words and creating named entity recognition dict\n    for tweet in preprocessed_tweets:\n        sentence = tokenize(tweet, remove_stopwords=True)\n        sentence = ' '.join(map(str, sentence))\n        doc = NER(sentence)\n        NER_dict[\"text\"].extend([token.text for token in doc.ents])\n        NER_dict[\"named_entity\"].extend([token.label_ for token in doc.ents])\n        \n    return NER_dict","81901afb":"# Named entity recognition of tweets of different categories\nnon_offensive_NER_dict = create_ner_dict(train[train[\"label\"]==0].tweet)\noffensive_NER_dict = create_ner_dict(train[train[\"label\"]==1].tweet)","a15441de":"# Converting to DataFrame\nnon_offensive_NER_df = pd.DataFrame.from_dict(non_offensive_NER_dict)\noffensive_NER_df = pd.DataFrame.from_dict(offensive_NER_dict)","e36ae403":"# Displaying sample observations\ndisplay(non_offensive_NER_df.head())\ndisplay(offensive_NER_df.head())","b01ae50b":"# Plotting named entities mentioned most times in Non-Offensive tweets\nnon_offensive_NER_df.groupby(\"named_entity\").agg({\"text\": pd.Series.nunique}).plot.barh(figsize=(8,11))","a3ef6f61":"# Plotting named entities mentioned most times in Offensive tweets\noffensive_NER_df.groupby(\"named_entity\").agg({\"text\": pd.Series.nunique}).plot.barh(figsize=(8,11))","f4ad60fe":"# Creates new df containing count of text by each named entity of Non offensive tweets\nnon_offensive_NER_text_occurances = non_offensive_NER_df.groupby(\"named_entity\").agg({\"text\": list})\nnon_offensive_NER_text_occurances[\"text_counts\"] = non_offensive_NER_text_occurances.agg({\"text\": Counter})[\"text\"]","09f6617e":"display(non_offensive_NER_text_occurances)","43ec47cc":"# Creates new df containing count of text by each named entity of Offensive tweets\noffensive_NER_text_occurances = offensive_NER_df.groupby(\"named_entity\").agg({\"text\": list})\noffensive_NER_text_occurances[\"text_counts\"] = offensive_NER_text_occurances.agg({\"text\": Counter})[\"text\"]","a6cfd31a":"def sort_dict_by_value(dictionary, reverse=False):\n    \"\"\" Returns list of (value, key) tuples sorted by value.\n    \n    Args:\n        dictionary (dict): Dict of key, value pairs.\n        reverse (bool): Sorts in descending order if set True. Defaults to False\n        \n    Returns:\n        list: Contains (value, key) tuples sorted by value\n    \"\"\"\n    \n    return sorted(\n        dict((value, key) for (key, value) in dictionary.items()).items(),\n        reverse=reverse\n    )\n\n\ndef max_val_of_dict(dictionary):\n    \"\"\" Returns list containing maximum value and its corresponding \n        key in a dict.\n        \n    Args:\n        dictionary (dict): Dict of key, value pairs.\n            \n    Returns:\n        list: Contains corresponding key of maximum value in the dictionary\n              and the maximum value itself.\n    \"\"\"\n    \n    max_key = max(dictionary, key=dictionary.get)\n    max_value = dictionary[max_key]\n    \n    return [max_key, max_value]","67095136":"# displays highest repeated text by each named entity in Non offensive tweets\nn_rows, n_cols = non_offensive_NER_text_occurances.shape\n\nfor i in range(n_rows):\n    non_offensive_NER_text_occurances[\"text_counts\"][i] = sort_dict_by_value(\n                                                                non_offensive_NER_text_occurances[\"text_counts\"][i],\n                                                                reverse=True\n                                                            )\n\nnon_offensive_NER_text_occurances.reset_index(inplace=True)\ndisplay(non_offensive_NER_text_occurances)","d4a68877":"# displays highest repeated text by each named entity in Offensive tweets\nn_rows, n_cols = offensive_NER_text_occurances.shape\n\nfor i in range(n_rows):\n    offensive_NER_text_occurances[\"text_counts\"][i] = sort_dict_by_value(\n                                                                offensive_NER_text_occurances[\"text_counts\"][i],\n                                                                reverse=True\n                                                            )\n\noffensive_NER_text_occurances.reset_index(inplace=True)\n\ndisplay(offensive_NER_text_occurances)","35e19f73":"# These are the named entities that we want to explore further\nreq_entities = [\"EVENT\", \"GPE\", \"LANGUAGE\", \"NORP\", \"ORG\"]\nn_req_entities = len(req_entities)","594ad920":"# Visualizes most repetetive Non offensive text phrases from each named entity\nfig1, ax3 = plt.subplots(n_req_entities, constrained_layout=True, figsize=(10, 12))\nfig1.suptitle(\"Frequent text (Non offensive) grouped by each entity\\n(y-axis: Text phrase; x-axis: Count)\", fontsize=20)\n\nfor i in range(n_req_entities):\n    x, yticklabels = list(zip(\n                        *non_offensive_NER_text_occurances[non_offensive_NER_text_occurances[\"named_entity\"] == req_entities[i]][\"text_counts\"].values[0][:5]))\n    ax3[i].barh(yticklabels, x, color='green')\n    ax3[i].set_title(\"Entity: \" + req_entities[i], fontsize=15)\n    ax3[i].tick_params(labelsize=12)\n    ax3[i].invert_yaxis()","d647d186":"# Visualizes most repetetive Offensive text phrases from each named entity\nfig2, ax4 = plt.subplots(n_req_entities, constrained_layout=True, figsize=(10, 12))\nfig2.suptitle(\"Frequent text (Offensive) grouped by each entity\\n(y-axis: Text phrase; x-axis: Count)\", fontsize=20)\n\nfor i in range(n_req_entities):\n    x, yticklabels = list(zip(\n                        *offensive_NER_text_occurances[offensive_NER_text_occurances[\"named_entity\"] == req_entities[i]][\"text_counts\"].values[0][:5]))\n    ax4[i].barh(yticklabels, x, color='crimson')\n    ax4[i].set_title(\"Entity: \" + req_entities[i], fontsize=15)\n    ax4[i].tick_params(labelsize=12)\n    ax4[i].invert_yaxis()","3baf459d":"def get_hash_tags(df_series):\n    \"\"\" Collects all hash tags from a given pandas series.\n    \n    Args:\n        df_series (pd.Series): Pandas series object containing text data.\n    \n    Returns:\n        hash_tags (list): List of hash tags from the pandas series.\n    \"\"\"\n    \n    hash_tags = []\n    for text in df_series:\n        hash_tags.extend(re.findall(r'#(\\w+)', text))\n        \n    return hash_tags","6868ee33":"non_offensive_hashtags = get_hash_tags(train[train[\"label\"]==0][\"tweet\"])\noffensive_hashtags = get_hash_tags(train[train[\"label\"]==1][\"tweet\"])","5c2b6da1":"# Word cloud of top mentioned hashtags in Non-offensive tweets\nplot_word_cloud(non_offensive_hashtags)","acd4f978":"# Word cloud of top mentioned hashtags in Offensive tweets\nplot_word_cloud(offensive_hashtags)","e5e0dd80":"# Count of each hashtags\nnon_offensive_hashtag_counts = Counter(non_offensive_hashtags)\noffensive_hashtag_counts = Counter(offensive_hashtags)","6f50bfce":"# Creating hashtag counts DataFrame for easy manipulation and visualization\n\nnon_offensive_hashtag_counts_df = pd.DataFrame.from_dict(non_offensive_hashtag_counts, orient=\"index\").reset_index()\nnon_offensive_hashtag_counts_df.columns = [\"hashtag\", \"count\"]\nnon_offensive_hashtag_counts_df.sort_values(\"count\", ascending=False, inplace=True)\ndisplay(non_offensive_hashtag_counts_df.head())\n\noffensive_hashtag_counts_df = pd.DataFrame.from_dict(offensive_hashtag_counts, orient=\"index\").reset_index()\noffensive_hashtag_counts_df.columns = [\"hashtag\", \"count\"]\noffensive_hashtag_counts_df.sort_values(\"count\", ascending=False, inplace=True)\ndisplay(offensive_hashtag_counts_df.head())","e74e3b62":"# Bar plot of top hashtag counts in Non-offensive tweets \nax5 = non_offensive_hashtag_counts_df.head(50).plot.barh(y=\"count\", figsize=(10, 14))\nax5.set(xlabel=\"( counts )\", ylabel=\"( hashtag )\")\nax5.set_yticklabels(non_offensive_hashtag_counts_df.head(50).agg({\"hashtag\": lambda x: '#'+x}).values.flatten())\nax5.invert_yaxis()\nplt.show()","4f1594d0":"# Bar plot of top hashtag counts in Offensive tweets \nax6 = offensive_hashtag_counts_df.head(50).plot.barh(y=\"count\", figsize=(10, 14), color=\"crimson\")\nax6.set(xlabel=\"( counts )\", ylabel=\"( hashtag )\")\nax6.set_yticklabels(offensive_hashtag_counts_df.head(50).agg({\"hashtag\": lambda x: '#'+x}).values.flatten())\nax6.invert_yaxis()\nplt.show()","cae11f1e":"def count_rows_with_hashtag(df_series):\n    \"\"\" Counts the number of rows containing at least one hashtag (#example).\n    \n    Args:\n        df_series (pd.Series): Pandas series containing text data.\n        \n    Returns:\n        count (int): Count of number of rows containing at least one hashtag.\n    \"\"\"\n    \n    count = 0\n    for tweet in df_series:\n        if re.search(r'#(\\w+)', tweet):\n            count+=1\n    \n    return count","7ab49a73":"# Counts number of rows containing a hashtag\nhashtag_tweet_count = count_rows_with_hashtag(train[\"tweet\"])\n\ntrain_rows, train_cols = train.shape\n\nplt.figure(figsize=(6, 6))\n\n# Creates pie chart\nplt.pie(\n    [hashtag_tweet_count, train_rows-hashtag_tweet_count],\n    autopct = \"%.2f%%\",\n    labels = [\"With hashtag\", \"Without hashtag\"],\n    explode = [0, 0.06],\n    shadow = True,\n    colors = [\"#1AC9E6\", \"#1DE4BD\"]\n)\n\nplt.show()","c9587199":"# **Now, we can have a look at length of each tweets**","ff816862":"*Let's check how much data falls under each category.*","5e0d0a3a":"By :  <a href=\"https:\/\/www.linkedin.com\/in\/bala-murugan-62073b212\/\">Balamurugan P","f9c7c35e":"* Offensive tweets which reflects racism or sexism are relatively lesser in number.\n* Due to this class imbalance, Accuracy may not be a good option for checking performance of our models. Instead, confusion matrix can be a good option.","0fe16d54":"![image.png](attachment:a2ee3733-165b-4eac-88f7-c4f4f2cc25c3.png)","32766459":"* The Above visualisation shows the most frequent hashtags which were present in offensive tweets.","693e20df":"* The Above visualisation shows the most frequent hashtags which were present in non-offensive tweets.","fc5b93d1":"*Knowing the max number of words in the dataset will be helpful later.*","b0d521b0":"# **Checking the distribution of categories**","50576ed4":"# **Creating word cloud from our corpus**","3de29e42":"*Word cloud shows the highly frequent words*","27c4a87e":"*Let's explore some rows of our DataFrames and check their schema.*","d58a06a8":"The task is to squeeze out as much insights as possible from just a single feature (tweets).\n\nThe dataset contains tweets categorized as \"Offensive (racism\/sexism)\" labelled as 1 and \"Not offensive\" labelled as 0.\n\nThis dataset contains around 50k tweets split into training and testing data.\n\n\nAnalysis was done using,\n* *Different kinds of visualizations like pie chart, bar chart, box plot etc.*\n* *Creating Word clouds.*\n* *Extracting information from hashtags.*\n* *Named Entity Recognition.*","40be406a":"# **Finding named entity for all the words in our tweets data**","2d1fe5f0":"*Word corpus is helpful for analysing data and useful for Named entity recognition, creating word clouds etc...*","ec95d8ec":"* From the visualisation we can infer that most of the times tweets are about a specific person or an organisation.\n* Offensiveness in tweets also targets a specific person, organisation, nationalities, religious or political groups.","ef7f0c98":"*Hashtags always hold some meaningful insights. They mostly express the essence of the whole tweet in one word or denotes the person or place or something about which the tweet talks about.*","c4c9be40":"* We can clearly see the words like \"racist\", \"black\", \"hate\", \"race\" which reflects offensiveness. Which were not present in the case of non-offensive corpus.","5d9fd782":"* From the visualisations we can see the most frequent words grouped by each named entity across categories.","f3f6f7e0":"# **Introduction**","16e2b1da":"* The dataset contains three columns - \"id\", \"label\", \"tweet\"\n* Column \"id\" is not useful for classification.\n* Column \"tweet\" contains the tweets and column \"label\" contains their category.\n* There is no null values.","d95a5120":"# **Conclusion**\n\n1. *The dataset contains three columns - \"id\", \"label\", \"tweet\".*\n2. *Column \"id\" is not useful for classification.*\n3. *Column \"tweet\" contains the tweets and column \"label\" contains their category.*\n4. *There is no null values in the dataset.*\n5. *Distribution of categories: 7.01 %  Offensive; 92.99 %  Not offensive.*\n6. *Most of the tweets have around 5 to 20 tokens.*\n7. *The number of tokens between 25th and 75th %ile (Interquartile range) of data ranges from 9 to 17 tokens, median being 13 tokens.* \n8. *Max length of any tweet in the dataset is less than 35 tokens.*\n9. *We can see words like \"racist\", \"black\", \"hate\", \"race\" which are highly frequent in offensive tweets.*\n10. *Most of the times tweets are about a specific person or an organisation.*\n11. *Offensiveness in tweets mostly targets a specific person followed by organisations, religious, national or political parties.*\n12. *Most frequent hashtags in Non-offensive tweets are \"#love\", \"#positive\", \"#healthy\", \"#smile\", \"#thankful\" which mostly reflects positivity.*\n13. *Frequent hashtags in offensive tweets are \"#black\", \"#hate\", \"#feminismiscancer\", \"#feminismisterrorism\", \"#hatred\", \"#race\" which reflects offensiveness.*\n14. *73.39 %  contains atleast one hashtag and only 26.61 %  does'nt contains a hashtag.*\n15. *Hashtags can be helpful to improve model performance since they express what the tweet talks about most of the times.*","09c48920":"*We can even use just hashtags to classify our tweets. Even a piece of data matters a lot.*","47419426":"# **What proportion of tweets contains a hashtag?**","06dfbfbb":"# **Visualizing top mentioned hashtags under each category**","ae729722":"# **Exploring DataFrames**","87f57ef8":"# **Let's import the dependancies**","36449954":"* Most of the tweets have around 5 to 20 tokens.","b2cd387d":"![image.png](attachment:d9737ce4-38a8-4317-bdaf-e141deef3b4c.png)","3c1606dc":"# **Finding most repeated text phrases under each named entity**","82c0a55c":"# **Let's load our data**","45d461a5":"# **Exploratory Data Analysis on Twitter Sentiment Analysis dataset**","41e58b3a":"* The number of tokens between 25th and 75th %ile (Interquartile range) of data ranges from 9 to 17 tokens, median being 13 tokens.\n* Max length of any tweet in the dataset is less than 35 tokens.","f11b35e1":"*Let's find and visualize highly frequent text phrases grouped by each named entity.*","66872382":"* From our Pie chart, It is clear that most of the tweets contains a hashtag.\n* These hashtags can help us classify the tweets more accurately.","b3f04ef1":"*Let's look a bit deeper.*","760c614f":"# **Visualizes frequency of each named entities in our data**","44aa5eba":"# **Preprocessing tweets and creating word corpus**","a7844246":"![image.png](attachment:ba47c20d-ebb8-4754-b4f4-b372d5c22717.png)","8bb7c9ae":"*To check what the offensive and non-offensive tweets talks about the most*"}}