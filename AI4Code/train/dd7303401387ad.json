{"cell_type":{"aea4d694":"code","daad031b":"code","5d63b8ae":"code","69d1aa77":"code","e4c4e3c5":"code","8dc2d847":"code","5ac98254":"code","199b0812":"code","db60d4d9":"code","047db0ce":"code","0ba9dcc2":"code","a6a92df0":"code","2a463f83":"code","4cb68647":"code","192fd8ed":"code","086440b3":"code","409b2ad4":"code","0e253172":"code","9c4ae058":"code","7d562416":"code","23f5d30f":"code","feb4d7e1":"code","ab8d41f2":"code","db6b1de7":"code","124313cb":"code","1c21baaf":"code","2ec05f3d":"code","451ab795":"code","0989f868":"code","d12cbe51":"code","ac04b7a4":"code","eed1e12c":"code","9c6629e4":"code","2810506d":"code","432ba8f1":"code","59bd83d9":"code","b9ccdc2d":"code","810936e7":"code","efe3fa22":"code","78e0eb84":"code","f9785356":"code","ed07622c":"code","7d8722ad":"code","8b07cfe4":"code","8afafff8":"code","784bf117":"code","77f6a726":"code","8674d01c":"code","29a1fa89":"code","bc715598":"code","1f40dca6":"code","0b493049":"code","d6efbc24":"code","6c855793":"code","9a10a4ca":"code","7230c8fe":"code","6cb5ff0f":"code","8206b454":"code","63a3e321":"code","c077d78f":"code","4a2a474c":"code","e4abfea7":"code","91f57439":"code","974618ac":"code","51addc14":"markdown","a40ffef1":"markdown","50ab68fc":"markdown","a31f7ff1":"markdown","f278b56f":"markdown","ae208521":"markdown","e2ce718b":"markdown","5ea7de37":"markdown","09647775":"markdown","d876e39c":"markdown","76ba6f16":"markdown","71d8d5c8":"markdown","88021d6d":"markdown","bfe6c227":"markdown","24749025":"markdown","168e136e":"markdown"},"source":{"aea4d694":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport random\n# from google.colab import files\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelBinarizer\nfrom scipy import sparse\n# import kaggle\nsns.set_style(\"darkgrid\")\npd.options.display.float_format = '{:.2f}'.format","daad031b":"# files.upload() \n# !mkdir ~\/.kaggle\n# !cp kaggle.json ~\/.kaggle\/kaggle.json\n# !chmod 600 \/root\/.kaggle\/kaggle.json\n# !kaggle competitions download tabular-playground-series-dec-2021","5d63b8ae":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","69d1aa77":"train = pd.read_csv(\"train.csv\")\ntrain = reduce_mem_usage(train)\ntest = pd.read_csv(\"test.csv\")\ntest = reduce_mem_usage(test)\n\ntrain.head()","e4c4e3c5":"# target - Cover_Type\n# 54 features except ID\ntrain.info()","8dc2d847":"np.unique(train.Cover_Type)\nviz = train.groupby(['Cover_Type']).agg({'Cover_Type':'count'})\\\n           .rename(columns = {'Cover_Type':'cnt'}).reset_index()\nsns.barplot(data= viz,x = 'Cover_Type', y = 'cnt'), print(viz)\n# very unbalanced sample","5ac98254":"# Exclude categorial\ncol = train.columns\nnot_soil_col = [i for i in col if 'Soil' not in i]\nnot_soil_col = [i for i in not_soil_col if 'Id' not in i ]\nnot_soil_col = [i for i in not_soil_col if 'Cover_Type' not in i ]\nnot_soil_col = [i for i in not_soil_col if 'Wilder' not in i ]\nnot_soil_col","199b0812":"train.loc[:,not_soil_col].describe()","db60d4d9":"train['target_cat'] = train.Cover_Type.astype('category')\nrand_row = random.sample(range(len(train.Cover_Type)), 100000)\nsample_for_viz = train.iloc[rand_row, :]\n\nfor feature in not_soil_col:\n  if feature != 'target_cat':\n    sns.displot(data = sample_for_viz, x = feature, hue = 'target_cat', kind = 'kde')\n    plt.show()\n  else:\n    pass  ","047db0ce":"plt.figure(figsize=(8,8), dpi = 150)\ncorr_matrix = train.loc[:, ['Elevation',\n 'Aspect',\n 'Slope',\n 'Horizontal_Distance_To_Hydrology',\n 'Vertical_Distance_To_Hydrology',\n 'Horizontal_Distance_To_Roadways',\n 'Hillshade_9am',\n 'Hillshade_Noon',\n 'Hillshade_3pm',\n 'Horizontal_Distance_To_Fire_Points', 'Cover_Type']].corr().round(3)\nsns.heatmap(corr_matrix, vmin = -1, vmax = 1, linewidths=0.5, cmap = 'Reds_r', annot=True, center=0)","0ba9dcc2":"plt.figure(figsize=(5,5), dpi = 150)\nplt.subplot(131)\nsns.scatterplot(data = sample_for_viz, x = 'Horizontal_Distance_To_Hydrology', y = 'Vertical_Distance_To_Hydrology', hue = 'target_cat')\nplt.subplot(132)\nsns.scatterplot(data = sample_for_viz, x = 'Horizontal_Distance_To_Hydrology', y = 'Horizontal_Distance_To_Fire_Points', hue = 'target_cat')\nplt.subplot(133)\nsns.scatterplot(data = sample_for_viz, x = 'Horizontal_Distance_To_Roadways', y = 'Horizontal_Distance_To_Fire_Points', hue = 'target_cat')\nplt.subplots_adjust(left=None, bottom=None, right=3, top=None, wspace=1, hspace=None)","a6a92df0":"wild_area_t = [i for i in train.columns if 'Wilder' in i]\nprint(wild_area_t)\nfor feature in wild_area_t:\n  print('Number of unique values: ', np.unique(train[feature]))\n  # train[feature] = train[feature].astype('int')\ntrain.loc[:,wild_area_t].head()","2a463f83":"viz = train.agg({'Wilderness_Area1':'sum',\t'Wilderness_Area2':'sum',\t'Wilderness_Area3':'sum',\t'Wilderness_Area4':'sum'})\nviz.plot(kind = 'bar', color = 'aquamarine', edgecolor = 'black')\n# wildernes area count\ntrain['Wilderness_Area_cnt'] = train.loc[:,wild_area_t].agg(sum)","4cb68647":"viz = train.groupby(['target_cat']).agg({'Wilderness_Area1':'sum',\t'Wilderness_Area2':'sum',\t'Wilderness_Area3':'sum',\t'Wilderness_Area4':'sum'})\\\n           .rename(columns = {'Cover_Type':'cnt'}).reset_index()\nviz.set_index('target_cat').transpose().plot(kind = 'bar')","192fd8ed":"viz.set_index('target_cat').transpose()","086440b3":"plt.figure(figsize=(5,6), dpi = 150)\nsoil_t = [i for i in train.columns if 'Soil_Type' in i]\nsoil_data = train.loc[:,soil_t].sum().sort_values(ascending=True)\nsoil_data.plot(kind = 'barh', color = 'orange', edgecolor = 'black')\nplt.rcParams.update({'font.size': 8})","409b2ad4":"plt.figure(figsize=(12,12), dpi = 150)\naggregating = dict(zip(soil_t, ['sum']*len(soil_t)))\nsoil_data_by_target = train.groupby(['target_cat']).agg(aggregating)\nsoil_data_by_target","0e253172":"soil_data_by_target.transpose().plot(kind = 'bar', figsize=(24,12), width = 1, edgecolor = 'black') ","9c4ae058":"train = train.query('Cover_Type != 5')\nX = train.drop(['target_cat', 'Cover_Type', 'Id', 'Soil_Type8', 'Soil_Type15'], axis=1)\ny = train.loc[:, 'Cover_Type']\n# y = LabelBinarizer().fit_transform(y) # from sklearn\n# y = sparse.csr_matrix(y) # from scipy\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 12)","7d562416":"(pd.DataFrame(y_train).groupby('Cover_Type').agg({'Cover_Type': 'count'})\/len(y_test)).plot(kind = 'bar')\n(pd.DataFrame(y_test).groupby('Cover_Type').agg({'Cover_Type': 'count'})\/len(y_test)).plot(kind = 'bar')","23f5d30f":"pd.DataFrame(y_train).groupby('Cover_Type').agg({'Cover_Type': 'count'})","feb4d7e1":"pd.DataFrame(y_test).groupby('Cover_Type').agg({'Cover_Type': 'count'})","ab8d41f2":"from sklearn.utils import resample \ndominating_classes = pd.DataFrame(y_train).query('Cover_Type == 1 | Cover_Type == 2') # more than half of train set is the class 1 or 2\nminority_classes = pd.DataFrame(y_train).query('Cover_Type != 1 & Cover_Type != 2') \nresampled_domin_classes = resample(dominating_classes, \n                                 replace=False,    \n                                 n_samples=400000)\nresampled_domin_classes","db6b1de7":"y_train_down = pd.concat([resampled_domin_classes, minority_classes], axis = 0)\nX_train_down = X_train.loc[y_train_down.index,:]\ny_train_down.groupby('Cover_Type').agg({'Cover_Type': 'count'}).plot(kind = 'bar')\nplt.show()\ny_train_down.groupby('Cover_Type').agg({'Cover_Type': 'count'})","124313cb":"# X_train.iloc[y_train_down.index,:]\n","1c21baaf":"y_train_down.groupby('Cover_Type').agg({'Cover_Type': 'count'})\n","2ec05f3d":"# classes = np.unique(y)\n# for c in classes:\n#   y_train_c = y_train.apply(lambda x: 1 if x == c else 0)\n#   log_reg = LogisticRegression(C = 0.01)\n#   log_reg.fit(X_train, y_train_c)\n#   accuracy = metrics.accuracy_score(log_reg.predict(X_train), y_train)\n#   print('train accuracy = ', accuracy)","451ab795":"# classes = np.unique(y)\n# for c in classes:\n#   y_train_c = y_train.apply(lambda x: 1 if x == c else 0)\n#   log_reg = SGDClassifier(loss='log', penalty='l2', learning_rate = 'optimal', alpha = 0.0001, n_jobs = -1)\n#   log_reg.fit(X_train, y_train_c)\n#   accuracy = metrics.accuracy_score(log_reg.predict(X_train), y_train)\n#   print('train accuracy = ', accuracy)","0989f868":"class_weights = y_train_down.groupby('Cover_Type').agg({'Cover_Type': 'count'})\/len(y_train_down)\nclass_weights = dict(class_weights.Cover_Type)\nclass_weights","d12cbe51":"# from sklearn.model_selection import GridSearchCV\n\n# hyperparam_rf = {'n_estimators': [i for i in range(50,120,20)],\n#               'max_depth': [i for i in range(20,41,10)],\n#               'min_samples_leaf': [i for i in range(1,3)]\n#               }\n# hyperparam_rf              ","ac04b7a4":"[i for i in range(50,200,10)]","eed1e12c":"# rf = RandomForestClassifier(warm_start = True, n_jobs = -1, class_weight = class_weights)\n# clf = GridSearchCV(rf, hyperparam_rf, cv = 3, verbose = 3) # strtified\n# # clf\n# clf.fit(X_train_down, y_train_down.Cover_Type)","9c6629e4":"# print('GSCV best score: ',clf.best_score_)\n# clf.best_params_","2810506d":"print(classification_report(y_train_down, clf.predict(X_train_down)))","432ba8f1":"print(classification_report(y_test, clf.predict(X_test)))","59bd83d9":"test = \nsubmis = pd.DataFrame(clf.predict(test.drop(['Id', 'Soil_Type8', 'Soil_Type15'], axis=1)))\\\n    .rename(columns = {0:'Cover_Type'})\n# submis","b9ccdc2d":"pd.concat([test['Id'], submis], axis = 1).to_csv('grid_search_RF_10_12_2021_19_22.csv', index = False)","810936e7":"rf = RandomForestClassifier(n_estimators = 110, max_depth = 40, warm_start = True,\n                            n_jobs = -1, class_weight=class_weights,min_samples_leaf = 1)\nrf.fit(X_train_down, y_train_down.Cover_Type)","efe3fa22":"plt.figure(figsize=(10,10), dpi =70)\nfi_rf = pd.DataFrame(dict(zip(X_train.columns,list(rf.feature_importances_))), index = ['FeatureImportance'])\nfi_rf = fi_rf.transpose().sort_values(by = 'FeatureImportance', ascending=0).iloc[:11,]\nsns.barplot(data = fi_rf.transpose(),orient='h')","78e0eb84":"import lightgbm","f9785356":"lgb = lightgbm.LGBMClassifier(max_depth=10, class_weight = class_weights)\nlgb.fit(X_train_down, y_train_down.Cover_Type)","ed07622c":"print(classification_report(y_train_down, lgb.predict(X_train_down)))","7d8722ad":"print(classification_report(y_train, lgb.predict(X_train)))","8b07cfe4":"print(classification_report(y_test, lgb.predict(X_test)))","8afafff8":"hyperparam_lgmb = {'n_estimators': [i for i in range(300,320,10)],\n              'max_depth': [i for i in range(60,64,3)],\n              'num_leaves': [i for i in range(100,140,10)]\n              }\nhyperparam_lgmb    ","784bf117":"lgbm = lightgbm.LGBMClassifier(class_weight = class_weights, n_jobs = -1)\nclf_lgbm = GridSearchCV(lgbm, hyperparam_lgmb, cv = 3, verbose = 3) # strtified\nclf_lgbm.fit(X_train_down, y_train_down.Cover_Type)","77f6a726":"print('GSCV LGBM best score: ',clf_lgbm.best_score_)\nclf_lgbm.best_params_","8674d01c":"print(classification_report(y_test, clf_lgbm.predict(X_test)))","29a1fa89":"test.loc[:,wild_area_t].agg(sum, axis = 1)\nsubmis = pd.DataFrame(clf_lgbm.predict(test.drop(['Id', 'Soil_Type8', 'Soil_Type15'], axis=1)))\\\n    .rename(columns = {0:'Cover_Type'})\nsubmis\npd.concat([test['Id'], submis], axis = 1).to_csv('grid_search_LGBM_14_12_2021_00_50.csv', index = False)","bc715598":"test.loc[:,wild_area_t].agg(sum, axis = 1)\nsubmis = pd.DataFrame(clf_lgbm.predict(test.drop(['Id', 'Soil_Type8', 'Soil_Type15'], axis=1)))\\\n    .rename(columns = {0:'Cover_Type'})\nsubmis\npd.concat([test['Id'], submis], axis = 1).to_csv('grid_search_LGBM_14_12_2021_18_50.csv', index = False)","1f40dca6":"train.columns","0b493049":"lgbm_2 = lightgbm.LGBMClassifier(class_weight = class_weights, n_jobs = -1, \n                              max_depth =  39, n_estimators = 220, num_leaves = 80)\nlgbm_2.fit(X_train_down, y_train_down.Cover_Type)","d6efbc24":"lgbm_2 = lightgbm.LGBMClassifier(class_weight = class_weights, n_jobs = -1, \n                              max_depth =  60, n_estimators = 310, num_leaves = 130)\nlgbm_2.fit(X_train_down, y_train_down.Cover_Type)","6c855793":"plt.figure(figsize=(10,10), dpi =70)\nplt.subplot(121)\nfi_lgbm = pd.DataFrame(dict(zip(X_train.columns,list(lgbm_2.feature_importances_))), index = ['FeatureImportance'])\nfi_lgbm = fi_lgbm.transpose().sort_values(by = 'FeatureImportance', ascending=0).iloc[:11,]\nsns.barplot(data = fi_lgbm.transpose(),orient='h')\nplt.title('LGBM')\n# lgbm_2.feature_importances_\nplt.subplot(122)\nfi_rf = pd.DataFrame(dict(zip(X_train.columns,list(rf.feature_importances_))), index = ['FeatureImportance'])\nfi_rf = fi_rf.transpose().sort_values(by = 'FeatureImportance', ascending=0).iloc[:11,]\nsns.barplot(data = fi_rf.transpose(),orient='h')\nplt.title('RF')\nplt.subplots_adjust(left=1, bottom=None, right=2, top=None, wspace=1, hspace=None)","9a10a4ca":"hyperparam_log_reg = {'alpha': [1, 0.01, 0.001, 0.0005, 0.0001, 0.00001]}\nhyperparam_log_reg","7230c8fe":"# not_soil_col.append('Wilderness_Area_cnt')\nnot_soil_col\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nscaled_numerical = pd.DataFrame(ss.fit_transform(X_train.loc[:,not_soil_col]), index = X_train.index)\nscaled_numerical.columns = not_soil_col\n\nscaled_numerical_down = pd.DataFrame(ss.fit_transform(X_train_down.loc[:,not_soil_col]), index = X_train_down.index)\nscaled_numerical_down.columns = not_soil_col\n\nX_train_new = pd.concat([scaled_numerical, X_train.drop(columns = not_soil_col)], axis = 1)\nX_train_new_down = pd.concat([scaled_numerical_down, X_train_down.drop(columns = not_soil_col)], axis = 1)\n\ntest['Wilderness_Area_cnt'] = test.loc[:,wild_area_t].agg(sum, axis = 1)\nscaled_numerical_test = pd.DataFrame(ss.fit_transform(test.loc[:,not_soil_col]), index = test.index)\nscaled_numerical_test.columns = not_soil_col\ntest_new = pd.concat([scaled_numerical_test, test.drop(columns = not_soil_col)], axis = 1)\n\n\nscaled_numerical_valid = pd.DataFrame(ss.fit_transform(X_test.loc[:,not_soil_col]), index = X_test.index)\nscaled_numerical_valid.columns = not_soil_col\nX_test_new = pd.concat([scaled_numerical_valid, X_test.drop(columns = not_soil_col)], axis = 1)","6cb5ff0f":"# log_reg = SGDClassifier(loss = 'log', n_jobs = -1, class_weight=class_weights,warm_start=True, verbose = 1)\n# clf_log_reg = GridSearchCV(log_reg, hyperparam_log_reg, cv = 3, verbose = 3 ) # strtified\n# clf_log_reg.fit(X_train_new_down, y_train_down.Cover_Type)","8206b454":"print('GSCV best score: ',clf_log_reg.best_score_)\nclf_log_reg.best_params_","63a3e321":"print(classification_report(y_test, clf_log_reg.predict(X_test_new)))","c077d78f":"# !pip install catboost","4a2a474c":"from catboost import CatBoostClassifier","e4abfea7":"cat_mod = CatBoostClassifier(loss_function='MultiClass', class_weights = class_weights,iterations=10000)\ncat_mod.fit(X_train_down, y_train_down.Cover_Type, plot = True, \n            cat_features = list(X_train_down.drop(columns = not_soil_col).columns))","91f57439":"print(classification_report(y_test, cat_mod.predict(X_test)))","974618ac":"test.loc[:,wild_area_t].agg(sum, axis = 1)\nsubmis = pd.DataFrame(cat_mod.predict(test.drop(['Id', 'Soil_Type8', 'Soil_Type15'], axis=1)))\\\n    .rename(columns = {0:'Cover_Type'})\nsubmis\npd.concat([test['Id'], submis], axis = 1).to_csv('cat_boost_15_12_2021_14_18.csv', index = False)","51addc14":"Resampling -- trying to reduce size of dataset and correct imbalances without loosing generality","a40ffef1":"# Logistic Regression","50ab68fc":"# Numerical Features","a31f7ff1":"Distribution of numerical features for different cover type","f278b56f":"reduce memory usage","ae208521":"## Imports","e2ce718b":"Correlation matrix for target and numerical features","5ea7de37":"# Models","09647775":"## Boosting","d876e39c":"# Intro","76ba6f16":"# Categorial features","71d8d5c8":"Submit 1","88021d6d":"## Trees and Random Forest","bfe6c227":"# Some geographical notations:\n\n* **Altitude** (**slope**)\n\nThe altitude is the slope or angle of the light source to the horizon, from 0 degree(on the horizon) to 90 degrees (overhead). The default is 45 degrees, please see the figure below.\n\n * **Hillshades**\n\n\nShaded relief, or hillshading, is a technique where a lighting effect is added to a map based on elevation variations within the landscape. It provides a clearer picture of the topography by mimicing the sun\u2019s effects (illumination, shading and shadows) on hills and canyons.\n\nhttps:\/\/earthquake.usgs.gov\/education\/geologicmaps\/images\/hillshades.jpg\n\n* **Elevation** \n\nis distance above sea level. Elevations are usually measured in meters or feet. They can be shown on maps by contour lines, which connect points with the same elevation; ","24749025":"Solar Type","168e136e":"Wilderness Area"}}