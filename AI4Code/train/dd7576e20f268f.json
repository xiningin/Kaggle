{"cell_type":{"40e00eca":"code","11e88be1":"code","43a2b852":"code","de99503b":"code","e2d86b53":"code","ee77699f":"code","6d65757b":"code","b9abaf32":"code","ea47677b":"code","6ef8b2ea":"code","ab687d94":"code","378b7594":"code","4f6000a4":"code","df312eb7":"code","805e584a":"code","506d75bb":"code","df3321fa":"code","396fcccd":"code","d796c9a6":"code","fa0f0054":"code","6fc7efb1":"code","645dc6ca":"code","d28dbcf0":"code","158f0fef":"code","421d6f9d":"code","5bede2b5":"code","2084b4ad":"code","a7e0ccc3":"code","411b48ce":"code","00c6957a":"code","c0b3a530":"code","6b09bc04":"code","a960f20b":"code","47c7537d":"code","df8dac67":"code","56d40387":"code","867606b4":"code","f1a67fcd":"code","29dd1f31":"code","bb0f3e75":"code","839de4d3":"code","e1cf8144":"code","59b4b704":"code","eb6de969":"code","0b4f6f8e":"code","f3e5c05a":"code","7cd4a41a":"code","0791e4ce":"code","8aa4c61e":"code","e6ea5ccf":"code","e1b11543":"code","84a408e5":"code","61356245":"code","2f40f65c":"code","628d9d28":"code","8efdc130":"code","605e69ac":"code","d2762b70":"code","d08c1c65":"code","c2226041":"code","23367c04":"markdown","459dd8ad":"markdown","ee5f8cae":"markdown","33e926ec":"markdown","28cf55bc":"markdown","f5a945d1":"markdown","4a6bc561":"markdown","aab4748b":"markdown","8d5f8d7d":"markdown","6294bac1":"markdown","9eb444dd":"markdown","719ffdf2":"markdown","4f240b50":"markdown","3d50c10d":"markdown","5e207eab":"markdown","ce2bc6b9":"markdown","6f2ff3c5":"markdown","a407811e":"markdown","83b6a792":"markdown","9528a279":"markdown","e9db0c14":"markdown","a78d2a27":"markdown","6dc54838":"markdown","c10df789":"markdown","5922143e":"markdown","a9ea076e":"markdown","401dd508":"markdown","72fdc705":"markdown","b98d84a7":"markdown","b624affc":"markdown","26c4b95f":"markdown","60ee8bbc":"markdown","3ddda050":"markdown","b228c10e":"markdown","bdcec2dc":"markdown","15f81154":"markdown","310ae58c":"markdown","0129cdfd":"markdown","90992822":"markdown","9df86ee8":"markdown","92703c43":"markdown","62eee50f":"markdown","7bc47cba":"markdown","a1ce4169":"markdown","c80ce3d4":"markdown","204ff8a9":"markdown","9cab41e8":"markdown","6d1732d3":"markdown"},"source":{"40e00eca":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n%matplotlib inline\nwarnings.filterwarnings('ignore')","11e88be1":"df=pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf.head()","43a2b852":"df.shape","de99503b":"df.describe()","e2d86b53":"df.isnull().sum()","ee77699f":"df.info()","6d65757b":"sns.countplot(x='target',data=df)","b9abaf32":"df['target'].value_counts()","ea47677b":"df.groupby('sex')['target'].value_counts()","6ef8b2ea":"## We can visualize the value counts of the sex variable wrt target as follows -\nax = sns.catplot(y=\"target\", col=\"sex\", data=df, kind=\"count\", height=5,  palette=\"Accent\")","ab687d94":"plt.figure(figsize=(15,6))\nsns.distplot(df['age'])\nplt.show()","378b7594":"plt.figure(figsize=(15,6))\nsns.boxplot(x='target',y='age',data=df,palette='viridis')\nplt.title('Heart Attacks by Age',size=15)\nplt.xlabel('No Heart Attack vs. Heart Attack',size=15)\nplt.ylabel('Age',size=15);","4f6000a4":"plt.figure(figsize=(20,10))\nc= df.corr()\nsns.heatmap(c,cmap=\"Blues\",annot=True);","df312eb7":"##Now, I will view its frequency distribution as follows :\ndf['cp'].value_counts()\n##It can be seen that cp is a categorical variable and it contains 4 types of values - 0, 1, 2 and 3.","805e584a":"##Visualize the frequency distribution of cp variable\nplt.figure(figsize=(15,6))\nsns.countplot(x=\"cp\", data=df, palette=\"magma\")\nplt.show()","506d75bb":"df.groupby('cp')['target'].value_counts()","df3321fa":"plt.figure(figsize=(15,6))\nsns.countplot(x='target',data=df,palette='magma',hue='cp')\nplt.title('Number of No Heart Attacks vs. Heart Attacks by Chest Pain type',size=15)\nplt.xlabel('Patients',size=15)\nplt.ylabel('Count',size=15);\n","396fcccd":"sns.catplot(data = df, x = 'sex', y = 'thalach', palette = 'colorblind', hue = 'target')","d796c9a6":"sns.boxplot(x=\"target\", y=\"thalach\", data=df)\nplt.show()","fa0f0054":"df.groupby('exang')['target'].value_counts()","6fc7efb1":"sns.catplot(kind = 'bar', data = df, y = 'exang', x = 'sex', hue = 'target',palette='PuBuGn_r')\nplt.show()","645dc6ca":"plt.figure(figsize=(15,6))\nsns.countplot(x='fbs',data=df,palette='Set3',hue='target')\nplt.xlabel('0-> fps <120 , 1-> fps>120',size=15)\nplt.ylabel('Count',size=15);\n","d28dbcf0":"plt.figure(figsize=(15,6))\nsns.countplot(x='restecg',data=df,palette='cividis',hue='target')\nplt.xlabel('resting electrocardiographic',size=15)\nplt.ylabel('Count',size=15);\n","158f0fef":"plt.figure(figsize=(15,6))\nsns.countplot(x='slope',data=df,palette='BuGn',hue='target')\nplt.xlabel('peak exercise ST segment',size=15)\nplt.ylabel('Count',size=15);\n","421d6f9d":"plt.figure(figsize=(15,6))\nsns.factorplot(y='trestbps',data=df,x='cp',hue='target',palette='Set2')\nplt.title('Trestbps V\/S Chest Pain',size=15);","5bede2b5":"sns.catplot(data = df, x = 'sex', y = 'oldpeak', palette = 'colorblind', hue = 'target');","2084b4ad":"from sklearn.model_selection import train_test_split","a7e0ccc3":"x = df.drop('target',axis=1)\ny = df['target']","411b48ce":"x_train, x_cv, y_train, y_cv = train_test_split(x, y, test_size=0.30, random_state=40)","00c6957a":"x_train.shape, x_cv.shape, y_train.shape, y_cv.shape","c0b3a530":"from sklearn.preprocessing import StandardScaler","6b09bc04":"scaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(x_train)\n\nX_test_scaled = scaler.transform(x_cv)\n","a960f20b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","47c7537d":"model = LogisticRegression(random_state=40)","df8dac67":"model.fit(X_train_scaled, y_train)","56d40387":"pred_cv = model.predict(X_test_scaled)","867606b4":"accuracy_score(y_cv, pred_cv)","f1a67fcd":"# import confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n \ncm = confusion_matrix(y_cv, pred_cv)\nprint(cm)\n\n# f, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(cm, annot=True)\nplt.title('Confusion matrix of the classifier')\nplt.xlabel('Predicted')\nplt.ylabel('True')","29dd1f31":"# import classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_cv, pred_cv))","bb0f3e75":"from sklearn.preprocessing import StandardScaler","839de4d3":"scaler = StandardScaler()\nscaler.fit(df.drop('target',axis=1))\nscaled_features = scaler.transform(df.drop('target',axis=1))\ndf_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\n","e1cf8144":"from sklearn.model_selection import train_test_split\n","59b4b704":"X_train, X_test, Y_train, Y_test = train_test_split(scaled_features,df['target'],\n                                                    test_size=0.30)","eb6de969":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score","0b4f6f8e":"accuracy_rate = []\n\nfor i in range(1,41):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    score=cross_val_score(knn,df_feat,df['target'],cv=10)\n    accuracy_rate.append(score.mean())\n","f3e5c05a":"plt.figure(figsize=(10,6))\n\nplt.plot(range(1,41),accuracy_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Accuracy Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Accuracy Rate')","7cd4a41a":"knn = KNeighborsClassifier(n_neighbors=31)","0791e4ce":"knn.fit(X_train,Y_train)","8aa4c61e":"pred = knn.predict(X_test)\naccuracy_score(Y_test, pred)\n","e6ea5ccf":"# import confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n \ncm = confusion_matrix(Y_test, pred)\nprint(cm)\n\n# f, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title('Confusion matrix of the classifier')\nplt.xlabel('Predicted')\nplt.ylabel('True')","e1b11543":"# import classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(Y_test, pred))","84a408e5":"\nfrom sklearn.model_selection import train_test_split","61356245":"x = df.drop('target',axis=1)\ny = df['target']","2f40f65c":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=42)","628d9d28":"from sklearn.ensemble import RandomForestClassifier","8efdc130":"rf= RandomForestClassifier(n_estimators =600, random_state=42,max_depth=2) ","605e69ac":"rf.fit(x_train,y_train) \n","d2762b70":"pred = rf.predict(x_test)\naccuracy_score(y_test, pred)","d08c1c65":"# import confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n \ncm = confusion_matrix(y_test, pred)\nprint(cm)\n\n# f, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title('Confusion matrix of the classifier')\nplt.xlabel('Predicted')\nplt.ylabel('True')","c2226041":"# import classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","23367c04":"### Fitting train data into model","459dd8ad":"### Effect of SLOPE on Heart Disease","ee5f8cae":"### Standard Scaling","33e926ec":"### Initialize Model","28cf55bc":"### Fitting train data into model","f5a945d1":"### Attributes and their meanings","4a6bc561":"## Analysis of target vs exang","aab4748b":"### Fitting train data into model","8d5f8d7d":"### Conclusion :\nAfter trying and testing 3 different algorithms, the best accuracy on the dataset is achieved by Logistic Regression (92.30%), followed by RandomForest (87.91%) and KNN Classifier (83.51%)","6294bac1":"age: The person's age in years\n\nsex: The person's sex (1 = male, 0 = female)\n\ncp: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n\ntrestbps: The person's resting blood pressure (mm Hg on admission to the hospital)\n\nchol: The person's cholesterol measurement in mg\/dl\n\nfbs: The person's fasting blood sugar (> 120 mg\/dl, 1 = true; 0 = false)\n\nrestecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n\nthalach: The person's maximum heart rate achieved\n\nexang: Exercise induced angina (1 = yes; 0 = no)\n\noldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot)\n\nslope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n\nca: The number of major vessels (0-3)\n\nthal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n\ntarget: Heart disease (0 = no, 1 = yes)","9eb444dd":"### Effect of AGE on Heart Disease","719ffdf2":"### Confusion Matrix","4f240b50":"### Effect of RESTECG on Heart Disease","3d50c10d":"### Predicting Accuracy","5e207eab":"### Standard Scaling","ce2bc6b9":"### Interpretations:\nFrom this correlation we can conclude that chol and fbs don't have any major impact on cardiac problems.\nExcept these two features all the other features are contributing towards heart disease to a certain extent.","6f2ff3c5":"### Effect of FBS on Heart Disease","a407811e":"### Interpretations :\n    1. The above plot confirms the findings that -\n    2. There are 165 patients suffering from heart disease, and\n    3. There are 138 patients who do not have any heart disease.\n### So this is a pretty much balanced dataset","83b6a792":"### Splitting Train and Test data","9528a279":"### Initialize Model","e9db0c14":"## Analysis of target vs thalach","a78d2a27":"# Logistic Regression :\nLet us make our first model to predict the target variable. We will start with Logistic Regression which is used for predicting binary outcome.\n\nLogistic Regression is a classification algorithm. It is used to predict a binary outcome (1 \/ 0, Yes \/ No, True \/ False) given a set of independent variables.\n\nLogistic regression is an estimation of Logit function. Logit function is simply a log of odds in favor of the event.\n\nThis function creates a s-shaped curve with the probability estimate, which is very similar to the required step wise function\n","6dc54838":"# Exploratory Data Analysis","c10df789":"### Interpretation :\nMedian Age of patients with no heart attacks is higher.\n50-60 years of age is the most crucial year in terms of heart disease.","5922143e":"### Interpretation :\nFeature (the peak exercise ST segment slope) has three symbolic values (flat,downsloping,upsloping)\n\nTherefore People having up sloping are more prone to Heart Disease than flat and downsloping. ","a9ea076e":"### Interpretation :\nAn electrocardiogram (ECG) is a test which measures the electrical activity of your heart to show whether or not it is working normally. An ECG records the heart's rhythm and activity on a moving strip of paper or a line on a screen. \n \nWith above graph as a refrence we can say that if resting electrocardiographic is 1 i.e. having ST-T wave abnormality then the person has more chances of suffering from Heart Disease.","401dd508":"### Confusion Matrix","72fdc705":"### Interpretation :\nthere is an increased level of exang in men. this might be leading to heart disease in men.","b98d84a7":"### Interpretation :\nAs Chest pain increases Blood Pressure will also increase along with the chances of Heart Disease.","b624affc":"### Interpretations :\nThere are four types of chest pains.\nChest pain type 0 had less heart attack occurences. It also had the most patients with no heart attacks.\nChest pain type 2 had most heart attack occurences. \nChest pain type 3 had least heart attack occurences.\n\nSo we can conclude that most of the heart attacks are caused by chest pain type 2 .","26c4b95f":"### Initialize model","60ee8bbc":"### Splitting Train and Test data","3ddda050":"# Random Forest Classifier :\nRandomForest is a tree based bootstrapping algorithm wherein a certain no. of weak learners (decision trees) are combined to make a powerful prediction model.\n\nFor every individual learner, a random sample of rows and a few randomly chosen variables are used to build a decision tree model.\n\nFinal prediction can be a function of all the predictions made by the individual learners.\n\nIn case of regression problem, the final prediction can be mean of all the predictions.\n\nThere are some parameters worth exploring with the sklearn RandomForestClassifier:\nn_estimators\nmax_features\n\nn_estimators = ususally bigger the forest the better, there is small chance of overfitting here. The more estimators you give it, the better it will do. We will use the value of 600.\n\nmax depth of each tree (default none, leading to full tree) - reduction of the maximum depth helps fighting with overfitting. We will limit at 2.\n","b228c10e":"### Predicting Accuracy","bdcec2dc":"# KNN Classifier :\nK-Nearest Neighbors (KNN) is one of the simplest algorithms used in Machine Learning for regression and classification problem.\n\nKNN algorithms use data and classify new data points based on similarity measures (e.g. distance function). \n\nClassification is done by a majority vote to its neighbours.","15f81154":"### Interpretation :\nPeople having fps < 120 have more chance of having Heart Disease than people havnig fps >120","310ae58c":"## Analysis of target vs cp","0129cdfd":"### Interpretations :\nWe can see that the values of target variable are plotted wrt sex : (1 = male; 0 = female).\n\ntarget variable also contains two integer values 1 and 0 : (1 = Presence of heart disease; 0 = Absence of heart disease)\n\nThe above plot confirms our findings that -\n1. Out of 96 females - 72 have heart disease and 24 do not have heart disease.\n2. Similarly, out of 207 males - 93 have heart disease and 114 do not have heart disease.","90992822":"### Importing necessary libraries and The Dataset","9df86ee8":"### Confusion Matrix","92703c43":"# Problem Statement : \n## HEART DISEASE PREDICTION ","62eee50f":"### Predicting Accuracy","7bc47cba":"## Splitting Train and Test data","a1ce4169":"### Let's take a look at the dataset ","c80ce3d4":"### Interpretation :\nThe age is mostly normally distributed","204ff8a9":"### Interpretation :\nBased on the above plot we can conclude that if Old peak is less than 2 then people will have more chances of having heart disease.","9cab41e8":"### Interpretation :\nWe can see that those people suffering from heart disease (target = 1) have relatively higher heart rate (thalach) as compared to people who are not suffering from heart disease (target = 0).\n\nThis is a symptom called Trachycardia.","6d1732d3":"# Model Building"}}