{"cell_type":{"fc3f541a":"code","cee81702":"code","97fe1003":"code","95bd7215":"code","61768c1e":"code","31042d91":"code","3a645a61":"code","656f9753":"code","2f20606f":"code","d774b62b":"code","5b29d917":"code","ffcea71e":"code","825aa1e1":"code","be85bcab":"code","89722468":"code","4a7304ff":"code","47e7b704":"code","933bd6f0":"code","6da916ee":"code","63750fee":"code","279dc87e":"code","e59c2d6a":"code","4144b35d":"code","fabadadc":"code","cf5c40cc":"code","fcc7ab04":"markdown","abb042c1":"markdown","befc0dce":"markdown","a5a3c9e2":"markdown","c7a30e71":"markdown","14053304":"markdown","bc81e150":"markdown","3493fa68":"markdown","506e03fa":"markdown","a94184e0":"markdown","71bc80e4":"markdown"},"source":{"fc3f541a":"# Import dependencies \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport os\nimport pathlib\nimport gc\nimport sys\nimport math \nimport time \nimport tqdm \nfrom tqdm import tqdm \nimport random\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow_hub as hub\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import StratifiedKFold ","cee81702":"# global config\n# When you would like to use another pre-trained model in TensorFlow Hub, you can change 'model_url'. \nconfig = {\n    'data_path': '..\/input\/petfinder-pawpularity-score',\n    'model_1_path': '..\/input\/effnet-v2-s-feature-vector',\n    'model_2_path': '..\/input\/vit-l32',\n    'model_3_path': '..\/input\/keras-xception',\n    'input_path': '..\/input', \n    'output_path': '.\/',\n    'model_1_url': \"https:\/\/tfhub.dev\/google\/imagenet\/efficientnet_v2_imagenet21k_s\/feature_vector\/2\",\n    'nfolds': 10,\n    'batch_size': 16,\n    'learning_rate': 1e-4,\n    'num_epochs': 10,\n    'image_size': (384, 384),\n    'input_shape': (384, 384, 3),\n    'blend_weight': 1\/3,\n}\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# For reproducible results    \ndef seed_all(s):\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(s) \nglobal_seed = 42\nseed_all(global_seed)","97fe1003":"data_folder = config['data_path']\ntrain_folder = os.path.join(data_folder, 'train')\ntest_folder = os.path.join(data_folder, 'test')\nsample_submission_path = data_folder + '\/sample_submission.csv'\n\ntrain_df = pd.read_csv(os.path.join(data_folder, 'train.csv'))\nprint(train_df.shape)\ntest_df = pd.read_csv(os.path.join(data_folder, 'test.csv'))\nprint(test_df.shape)\n#sample_df = pd.read_csv(sample_submission_path)\n#print(sample_df.shape)\n\n#train_path = pathlib.Path(train_folder); print(train_path)\n#train_photo_list = list(train_path.iterdir()); print(len(train_photo_list))\n#test_path = pathlib.Path(test_folder); print(test_path)\n#test_photo_list = list(test_path.iterdir()); print(len(test_photo_list))\n\ntrain_df","95bd7215":"# Pawpularity Scaling\nscaler = train_df['Pawpularity'].max()\ntrain_df['Pawpularity_scaled'] = train_df['Pawpularity'] \/ scaler\n\n# add 'Path' column\npath_list = []\nfor id in train_df['Id']:\n    path = os.path.join(train_folder, id) + '.jpg'\n    path_list.append(path)\ntrain_df['Path'] = path_list\n\n# Data Shuffling\ntrain_df_shuffled=train_df.iloc[np.random.permutation(train_df.index)].reset_index(drop=True)\n\n# split validation data\nkf = KFold(n_splits=config['nfolds'])\nfor nfold, (train_index, val_index) in enumerate(kf.split(train_df_shuffled)):\n    train_df_shuffled.loc[val_index, 'fold'] = nfold\nprint(train_df_shuffled.groupby(['fold', train_df_shuffled.fold]).size())\nprint()\n    \n#skf = StratifiedKFold(n_splits=config['nfolds'], shuffle=True, random_state=global_seed)\n#for nfold, (train_index, val_index) in enumerate(skf.split(X=train_df.index,\n#                                                           y=train_df.target)):\n#    train_df.loc[val_index, 'fold'] = nfold\n#print(train_df.groupby(['fold', train_df.target]).size())\n\ntrain_df_shuffled","61768c1e":"p_trains = []\np_valids = []\nfor p in range(3):\n    p_fold = p\n    p_train = train_df_shuffled.query(f'fold != {p_fold}').reset_index(drop=True)\n    p_valid = train_df_shuffled.query(f'fold == {p_fold}').reset_index(drop=True)\n    p_trains.append(p_train)\n    p_valids.append(p_valid)\n    print('-'*30)\n    print(f'train-{p}\\n', p_train.Pawpularity.describe())\n    print()\n    print(f'valid-{p}\\n', p_valid.Pawpularity.describe())\n    print()","31042d91":"@tf.function\ndef preprocessing_img(img):\n    img = tf.expand_dims(img, axis=0)\n    img = tf.image.resize(img, config['image_size'])\n    #img \/= 255.0\n    return img\n\ndef load_and_preprocessing_img(path_list):\n    img_list = []\n    for path in path_list:\n        img_raw = tf.io.read_file(path)\n        img_tensor = tf.image.decode_image(img_raw)\n        img_list.append(preprocessing_img(img_tensor))        \n    img_batch = tf.concat(img_list, axis=0)\n    return img_batch\n\nclass ImageSequence(keras.utils.Sequence):\n    def __init__(self, df, batch_size=config['batch_size'], mode='train'):\n        self.l = None\n        self.x = df.Path\n        self.y = df.Pawpularity_scaled\n        self.batch_size = batch_size \n        self.num_samples = len(df)\n        self.mode = mode\n\n    def __len__(self):\n        self.l = self.num_samples \/\/ self.batch_size\n        return self.l\n\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx+1) * self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx+1) * self.batch_size]\n        \n        batch_x_img = load_and_preprocessing_img(batch_x)\n        return batch_x_img, np.array(batch_y)\n","3a645a61":"train_gens = []\nvalid_gens = []\n\nfor p in range(3):\n    train_gen = ImageSequence(p_trains[p], mode='train')\n    valid_gen = ImageSequence(p_valids[p], mode='valid')\n    \n    train_gens.append(train_gen)\n    valid_gens.append(valid_gen)\n    \n    print('-'*30)\n    print(f'train_gen_{p+1} length', len(train_gen))\n    print(f'valid_gen_{p+1} length', len(valid_gen))\n    \n    sample = next(iter(train_gen))\n    print(sample[0].shape)\n    print(sample[1].shape)","656f9753":"\"\"\"\n# Downloading models from TensorFlow Hub (Internet should be avairable).\nbase_model_1 = tf.keras.Sequential([\n    hub.KerasLayer(config['model_1_url'], trainable=False),\n    tf.keras.layers.Dense(512, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\"\"\"\n\nbase_model_1 = tf.keras.Sequential([\n    tf.keras.models.load_model(config['model_1_path']),\n    tf.keras.layers.Dense(512, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\ndata_augmentation = tf.keras.models.Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomRotation(0.1),\n    preprocessing.RandomZoom(0.1),\n])\n\ninputs_1 = keras.Input(shape=config['input_shape'])\nx_1 = data_augmentation(inputs_1)\nx_1 = tf.keras.layers.Resizing(384, 384)(x_1)\nx_1 = tf.keras.layers.Rescaling(1. \/ 255)(x_1)\noutputs_1 = base_model_1(x_1)\nmodel_1 = keras.Model(inputs_1, outputs_1)\n\nmodel_1.summary()","2f20606f":"model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\ntrain_gen = train_gens[0]\nvalid_gen = valid_gens[0]\n\nfit_history_1 = model_1.fit_generator(train_gen, epochs=5,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","d774b62b":"# Finetuning\nfor l in model_1.layers:\n    l.trainable = True\n    \nmodel_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n                loss='mean_squared_error',\n                metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\nmodel_1.summary()","5b29d917":"fit_history_1 = model_1.fit_generator(train_gen, epochs=2,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","ffcea71e":"\"\"\"\n# downloading models from vit-keras (Internet should be avairable).\n!pip install vit-keras -q\n!pip install tensorflow-addons -q\n\nfrom vit_keras import vit\n\nvit_model = vit.vit_l32(\n    image_size=384,\n    pretrained=True,\n    include_top=False,\n    pretrained_top=False,\n)\n\"\"\"\n\nvit_model = tf.keras.models.load_model(config['model_2_path'])\n\nbase_model_2 = tf.keras.Sequential([\n    vit_model,\n    tf.keras.layers.Dense(256, activation='selu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\ndata_augmentation = tf.keras.models.Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomRotation(0.1),\n    preprocessing.RandomZoom(0.1),\n])\n\ninputs_2 = keras.Input(shape=config['input_shape'])\nx_2 = data_augmentation(inputs_2)\nx_2 = tf.keras.layers.Resizing(384, 384)(x_2)\nx_2 = tf.keras.layers.Rescaling(1. \/ 255)(x_2)\noutputs_2 = base_model_2(x_2)\nmodel_2 = keras.Model(inputs_2, outputs_2)\n\nmodel_2.summary()","825aa1e1":"for layer in vit_model.layers:\n    layer.trainable = False\n\nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\nfrom tensorflow.keras.optimizers import Adam\n\nnum_epochs = 3\nnum_train_steps = len(train_gen) * num_epochs\n\nlr_scheduler = PolynomialDecay(\n    initial_learning_rate=1e-3, end_learning_rate=1e-4, decay_steps=num_train_steps\n)\n\nmodel_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\nmodel_2.summary()","be85bcab":"train_gen = train_gens[1]\nvalid_gen = valid_gens[1]\n\nfit_history_2 = model_2.fit_generator(train_gen, epochs=num_epochs,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","89722468":"# Finetuning\nfor layer in vit_model.layers:\n    layer.trainable = True\n\nnum_epochs = 2\nnum_train_steps = len(train_gen) * num_epochs\n\nlr_scheduler = PolynomialDecay(\n    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n)\n\nmodel_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\n\nmodel_2.summary()","4a7304ff":"fit_history_2 = model_2.fit_generator(train_gen, epochs=num_epochs,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","47e7b704":"\"\"\"\n# downloading models (Internet should be avairable).\nbase_model_3 = tf.keras.Sequential([\n    tf.keras.applications.xception.Xception(\n        include_top=False, weights='imagenet', \n        input_shape=(299, 299, 3)),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(512, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\"\"\"\nxception_model =  tf.keras.models.load_model(config['model_3_path'])\n\nbase_model_3 = tf.keras.Sequential([\n    xception_model,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(512, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='selu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation=None)\n])\n\ndata_augmentation = tf.keras.models.Sequential([\n    preprocessing.RandomFlip('horizontal'),\n    preprocessing.RandomRotation(0.1),\n    preprocessing.RandomZoom(0.1),\n])\n\ninputs_3 = keras.Input(shape=config['input_shape'])\nx_3 = data_augmentation(inputs_3)\nx_3 = tf.keras.layers.Resizing(299, 299)(x_3)\nx_3 = tf.keras.layers.Rescaling(1. \/ 255)(x_3)\noutputs_3 = base_model_3(x_3)\nmodel_3 = keras.Model(inputs_3, outputs_3)\n\nfor l in xception_model.layers:\n    l.trainable = False\n\nmodel_3.summary()","933bd6f0":"model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\ntrain_gen = train_gens[2]\nvalid_gen = valid_gens[2]\n\nfit_history_3 = model_3.fit_generator(train_gen, epochs=3,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","6da916ee":"# Finetuning\nfor l in model_3.layers:\n    l.trainable = True\n    \nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\nfrom tensorflow.keras.optimizers import Adam\n\nnum_epochs = 2\nnum_train_steps = len(train_gen) * num_epochs\n\nlr_scheduler = PolynomialDecay(\n    initial_learning_rate=1e-4, end_learning_rate=1e-5, decay_steps=num_train_steps\n)\n\nmodel_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss='mean_squared_error',\n              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])\n\nmodel_3.summary()","63750fee":"fit_history_3 = model_3.fit_generator(train_gen, epochs=num_epochs,\n                                      steps_per_epoch=len(train_gen),\n                                      verbose=1,\n                                      validation_data=valid_gen,\n                                      validation_steps=len(valid_gen))","279dc87e":"def preprocess_dataframe(df, mode='train', shuffle=True, nfolds=None):\n    if mode == 'train':\n        img_folder = train_folder\n        \n        # Pawpularity Scaling\n        df['Pawpularity'] = df['Pawpularity'] \/ df['Pawpularity'].max()\n    else:\n        img_folder = test_folder\n    \n    # add 'Path' column\n    path_list = []\n    for img_id in df['Id']:\n        path = os.path.join(img_folder, img_id) + '.jpg'\n        path_list.append(path)\n    df['Path'] = path_list\n    \n    # Data Shuffling\n    if shuffle == True:\n        df = df.iloc[np.random.permutation(df.index)].reset_index(drop=True)\n        \n    # split validation data\n    if nfolds is not None:\n        kf = KFold(n_splits=config['nfolds'])\n        for nfold, (train_index, val_index) in enumerate(kf.split(df)):\n            df.loc[val_index, 'fold'] = nfold\n        \n    return df\n\ntest_df = preprocess_dataframe(test_df, mode='test', shuffle=False)\ntest_df","e59c2d6a":"class TestImageSequence(keras.utils.Sequence):\n    def __init__(self, df, batch_size=config['batch_size']):\n        self.l = None\n        self.x = df.Path\n        self.y = None \n        self.num_samples = len(df)\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        if self.num_samples % self.batch_size == 0:\n            self.l = self.num_samples \/\/ self.batch_size\n        else:\n            self.l = self.num_samples \/\/ self.batch_size + 1\n        return self.l\n\n    def __getitem__(self, idx):\n        if (idx+1) * self.batch_size <= self.l:\n            batch_x = self.x[idx * self.batch_size:(idx+1) * self.batch_size]\n        else:\n            batch_x = self.x[idx * self.batch_size:]\n        batch_x_img = load_and_preprocessing_img(batch_x)\n        return batch_x_img\n    \n# When the batch_size is not '1', submission was failed because of some errors.\ntest_gen = TestImageSequence(test_df, batch_size=1)\nprint(len(test_gen))\n\nsample =  next(iter(test_gen))\nprint(sample.shape)","4144b35d":"pred_score_1 = model_1.predict_generator(test_gen)\npred_score_1 = pred_score_1 * scaler # scaler == train_df['Pawpularity'].max()\n\npred_score_2 = model_2.predict_generator(test_gen)\npred_score_2 = pred_score_2 * scaler # scaler == train_df['Pawpularity'].max()\n\npred_score_3 = model_3.predict_generator(test_gen)\npred_score_3 = pred_score_3 * scaler # scaler == train_df['Pawpularity'].max()\n\nprint(pred_score_1)\nprint(pred_score_2)\nprint(pred_score_3)","fabadadc":"pred_score = np.mean([pred_score_1, pred_score_2, pred_score_3], axis=0)\n\nprint(pred_score.shape)","cf5c40cc":"test_df['Pawpularity'] = pred_score\nsubmission_df = test_df[['Id', 'Pawpularity']]\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df","fcc7ab04":"### 3.1 Model_1 (EfficientNet V2 trained on imagenet-21k)","abb042c1":"# 4. Prediction","befc0dce":"### 4.2 Model Ensemble","a5a3c9e2":"# 0. Settings","c7a30e71":"---\n## [PetFinder.my - Pawpularity Contest][1]\n---\n**Comments**: Thanks to previous great Notebooks.\n\n[Vision Transformer (ViT) Fine-tuning][2]\n\n[1]: https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\n[2]: https:\/\/www.kaggle.com\/raufmomin\/vision-transformer-vit-fine-tuning","14053304":"# 1. DataFrame Preprocessing","bc81e150":"### 3.2 Model_2 (ViT)","3493fa68":"### 3.3 Model_3 (Xception)","506e03fa":"### 4.1 Test DataGenerator","a94184e0":"# 2. DataGenerator","71bc80e4":"# 3. Model Training"}}