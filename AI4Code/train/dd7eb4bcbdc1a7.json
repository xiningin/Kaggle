{"cell_type":{"726cc291":"code","f686e6b8":"code","81a4ca37":"code","44edfc9c":"code","426ce896":"code","4d1ee224":"code","964254a2":"code","d839bd1d":"code","4d581cb0":"code","d805f1f2":"code","4ad5a38e":"code","2421058f":"code","3fe0217a":"code","0b621aa9":"code","46f0edc2":"code","89ed9dbb":"code","0c20753c":"code","fdeef2d8":"code","1ced5587":"code","4c5f91ab":"code","df86b7a7":"code","14d629d8":"code","4221f07e":"code","9cf86651":"code","61a81a0e":"code","66f02234":"code","0615f67f":"code","9d38f2e2":"code","de62a758":"code","9fec65ce":"code","c38d5e88":"code","2df88723":"code","98d1e52f":"code","79491628":"code","28f11af3":"markdown","673fe32f":"markdown","306a15cc":"markdown","ef4f7ac9":"markdown","78f0934f":"markdown","215d52cc":"markdown","7567bb0a":"markdown","6db296de":"markdown","b936b836":"markdown","115890a8":"markdown","e1235ef9":"markdown","4ebf1b43":"markdown","04634715":"markdown","9b4ac1c6":"markdown","e27410a6":"markdown","7d317f09":"markdown","f1304570":"markdown","9a1242da":"markdown","307926c1":"markdown","08182827":"markdown","80ee27fd":"markdown","85a54aee":"markdown","439f26bb":"markdown","47b38898":"markdown","577dbe6f":"markdown","052bff12":"markdown","8a3e1128":"markdown","f253e1ce":"markdown","521eef1a":"markdown","3d145f45":"markdown"},"source":{"726cc291":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt","f686e6b8":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n","81a4ca37":"train.head()","44edfc9c":"test.head()","426ce896":"train_drop = train.drop(columns = ['Survived'])\ny = train.Survived\nn_train = train.shape[0]","4d1ee224":"print(train_drop .info())\nprint(test.info())","964254a2":"# grouping the ages every five years\nage_group = train.Age \/\/ 5 + 1\n\n# fill the NaN values in the feature\nage_group.fillna(0, inplace = True)\n\n# total people\nnum_people = train.shape[0]\n\n# number of deaths and survivors by age\ndeath_age_group = age_group[train[\"Survived\"] == 0].value_counts()\nsurvivor_age_group = age_group[train[\"Survived\"] == 1].value_counts()\n\n# sorting the index\nind = np.sort(death_age_group.index.values)\n\n# the width of the bars\nwidth = 0.8\n\n# ploating graph\nplt.figure(figsize=(12, 10))\n\ndeath_bar = plt.bar(ind,death_age_group[ind]\/num_people,width)\nsurvivor_bar = plt.bar(ind,survivor_age_group[ind]\/num_people,width, bottom = death_age_group[ind]\/num_people)\n\nplt.title('Percentage of Passengers by Age Group', fontdict={'fontsize':20})\nage_groups_ticks = ['None'] + ['{}-{}'.format(int(i * 5), int((i + 1)* 5)) for i in ind[0:]]\nplt.xticks(ind, age_groups_ticks)\nplt.legend((death_bar[0], survivor_bar[0]), ('Deceased', 'Survived'))\n\nplt.show()\n","d839bd1d":"train[train.Age <= 15].Survived.value_counts(normalize = True)","4d581cb0":"train[train.Age >= 15].Survived.value_counts(normalize = True)","d805f1f2":"# number of deaths and survivors by class\ndeath_class = train.Pclass[train[\"Survived\"] == 0].value_counts()\nsurvivor_class = train.Pclass[train[\"Survived\"] == 1].value_counts()\n\n#index\nind = [1, 2, 3]\n\n# ploating graph\nplt.figure(figsize=(12, 10))\n\ndeath_class_bar = plt.bar(ind,death_class[ind].values\/num_people, width)\nsurvivor_class_bar = plt.bar(ind,survivor_class[ind].values\/num_people, width, bottom = death_class[ind].values\/num_people)\n\nplt.title('Percentage of Passengers by Class', fontdict={'fontsize':20})\nplt.xticks(ind, ('First','Second','Third'))\nplt.legend((death_class_bar[0], survivor_class_bar[0]), ('Deceased', 'Survived'))\n\nplt.show()\n\n\n","4ad5a38e":"train.groupby('Pclass').Survived.value_counts(normalize = True, sort = False)","2421058f":"# number of deaths and survivors by class\ndeath_gender = train.Sex[train[\"Survived\"] == 0].value_counts()\nsurvivor_gender = train.Sex[train[\"Survived\"] == 1].value_counts()\n\n#index\nind = ['male','female']\n\n# ploating graph\nplt.figure(figsize=(12, 10))\n\ndeath_gender_bar = plt.bar(ind,death_gender[ind].values\/num_people, width)\nsurvivor_gender_bar = plt.bar(ind,survivor_gender[ind].values\/num_people, width, bottom = death_gender[ind].values\/num_people)\n\nplt.title('Percentage of Passengers by Gender', fontdict={'fontsize':20})\nplt.xticks(ind, ('Male','Female'))\nplt.legend((death_gender_bar[0], survivor_gender_bar[0]), ('Deceased', 'Survived'))\n\nplt.show()","3fe0217a":"train.groupby('Sex').Survived.value_counts(normalize = True, sort = False)","0b621aa9":"all_data = pd.concat((train_drop , test), sort = False).reset_index(drop = True)","46f0edc2":"all_data[\"Title\"] = all_data.Name.str.extract(r'\\b(\\w+)\\.')","89ed9dbb":"all_data.info()","0c20753c":"all_data.Title.value_counts()","fdeef2d8":"all_data.Title[all_data.Age.isna() == True].value_counts()","1ced5587":"#creating a dictionary with the titles that have NaN values\nmissing_age = all_data.Title[all_data.Age.isna() == True].value_counts().index.values\n\n#fill the dictionary with the mean of the ages\nage_na_fills = {}\nfor title in missing_age:\n    age_na_fills[title] = round(all_data[(all_data.Title == title).values].Age.mean())\n\n#replacing the NaN values\nall_data[\"Age\"] = all_data.apply(lambda row: age_na_fills.get(row.Title) if np.isnan(row['Age']) else row['Age'], axis=1)","4c5f91ab":"all_data.info()","df86b7a7":"all_data.Embarked.value_counts()","14d629d8":"all_data.Embarked = all_data.Embarked.fillna('S')\nall_data.Fare = all_data.Fare.fillna(all_data.Fare.mean())","4221f07e":"#Creating dummies variables\nall_data = pd.get_dummies(all_data, columns = ['Pclass','Sex', 'Embarked','Title'], drop_first = True)\n\n#Dropping unecessary features\nall_data = all_data.drop(columns = ['PassengerId','Name','Ticket','Cabin'])","9cf86651":"X = all_data[0:n_train]\nX_pred = all_data[n_train:]","61a81a0e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","66f02234":"#10-fold cross validation for logistic regression\nlogreg = LogisticRegression(solver = 'liblinear')\nscore_logreg = cross_val_score(logreg, X , y, cv = 10, scoring = 'accuracy')\nscore_logreg.mean()","0615f67f":"#10-fold cross validation for SVM\nsvc = SVC(gamma = 'auto')\nscore_svc = cross_val_score(svc, X , y, cv = 10, scoring = 'accuracy')\nscore_svc.mean()","9d38f2e2":"#10-fold cross validation for Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=100)\nscore_rf = cross_val_score(random_forest, X , y, cv = 10, scoring = 'accuracy')\nscore_rf.mean()","de62a758":"#Serching for the optimal value of K for KNN\nk_range = range(1,31)\nk_scores = []\n\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors = k)\n    score_knn = cross_val_score(knn, X , y, cv = 10, scoring = 'accuracy')\n    k_scores.append(score_knn.mean())","9fec65ce":"#plot the value of K for KNN versus the cross validation accuracy\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross Validation Accuracy')\n","c38d5e88":"#10-fold cross validation for KNN (K= 4)\nknn = KNeighborsClassifier(n_neighbors = 4)\nscore_knn = cross_val_score(knn, X , y, cv = 10, scoring = 'accuracy')\nscore_knn.mean()","2df88723":"logreg.fit(X,y)\ny_pred = logreg.predict(X_pred)","98d1e52f":"sub = pd.DataFrame({'PassengerId':test.PassengerId,'Survived':y_pred})\nsub.to_csv(\"titanic.csv\", index = False)","79491628":"import pandas as pd\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","28f11af3":"We can see that we have some missing information:\n  - Train: Age, Cabin, Embarked\n  - Test: Age, Fare, Cabin\n    ","673fe32f":"# 2. Data Preparation","306a15cc":"In all models we define a K-fold cross validation using K =10","ef4f7ac9":"So we can replace the NaN values with the mean of the age ","78f0934f":"The best accuracy is when K = 4.","215d52cc":"As we can see more than half of the children survived.","7567bb0a":"Let's check the proportion of deaths group by age, class and gender.","6db296de":"## 3.1 Logistic Regression","b936b836":"The features Fare and Embarked still have NaN values. So we're going to replace the NaN valeus of Fare with the avarege of the all fares and the feature Embarked with the place where more people embarked (Southampton). ","115890a8":"As we can see there's no missing value in the feature Title. So we're going to use it to complete the missing values in the feature Age. Firts of all let's check the Title's values.","e1235ef9":"But with the adults the situation is different.","4ebf1b43":"The lower is the class, the higher the death rate.","04634715":"# 3. Model selection","9b4ac1c6":"Now let's clean the data set. Creating dummies variables and drop unnecessary features","e27410a6":"## 3.4 K-Neighbor","7d317f09":"## 1.3 Gender","f1304570":"## 1.1 Age","9a1242da":"The death rate is lower in women.","307926c1":"And the Title's values that the Age are NaN","08182827":"Dropping the \"Survived\" column from the train dataset.","80ee27fd":"## 3.3 Random Forest","85a54aee":"# Submission","439f26bb":"Putting all datasets together","47b38898":"As we can see the model that has the best performance is Logistic Regression. So we're going to use it to predict the result of the problem.","577dbe6f":"## 3.2 Support Vector Machine (SVM)","052bff12":"Uploading data from csv files","8a3e1128":"Creating a new feature: \"Tilte\"","f253e1ce":"# 1. Data Visualization","521eef1a":"## 1.2 Class","3d145f45":"Finally let's separete de train dataset from the test data set"}}