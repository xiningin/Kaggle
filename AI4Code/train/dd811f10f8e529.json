{"cell_type":{"25598d17":"code","99060c62":"code","22d126bf":"code","a1b44f57":"code","b4a99e27":"code","7082abf5":"code","a4f41227":"code","bfcea479":"code","b8ff5c51":"code","78f2fed5":"code","205662c7":"code","3231d42e":"code","ebe7cdfc":"code","713ee867":"code","ec73f440":"code","d4b25af1":"code","9cdaf424":"code","debb8670":"code","a97ec1a8":"code","5221f988":"code","c7b56c05":"code","fcfc9d42":"code","703d58ee":"code","b99196ab":"code","1d9c1419":"code","cfc3c445":"code","66f4b586":"code","97d4b824":"code","cf91c899":"code","84452c0c":"code","b514c9bc":"code","80c5b8fc":"code","8182fa73":"code","00d8fcea":"code","57e13c27":"code","dc66d212":"code","ef1a27ef":"code","85267e6c":"code","5ab483b4":"code","41c41d26":"markdown","3871c096":"markdown","4613f8b5":"markdown","c71e662a":"markdown","2e14e51e":"markdown","fd84ec60":"markdown","90f8ffe7":"markdown","6406b487":"markdown","7bf6184d":"markdown","ff8e3290":"markdown","0b4d5972":"markdown","429b0218":"markdown","bbeeae05":"markdown","15413553":"markdown","b2992ae1":"markdown","b0f0b27e":"markdown","3e49adac":"markdown","dbb37b6b":"markdown","c2b8ee02":"markdown","51896f91":"markdown","c335b5e1":"markdown","2d70197d":"markdown","6f965b52":"markdown"},"source":{"25598d17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99060c62":"import missingno as msno\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\nfrom sklearn.metrics import mean_squared_error, r2_score","22d126bf":"df = pd.read_csv(\"\/kaggle\/input\/hitters\/Hitters.csv\") #reads the file\ndf.head() #returns the first 5 values","a1b44f57":"df.info() ","b4a99e27":"df.isnull().sum() #returns the number of null values in columns","7082abf5":"msno.bar(df);  # visualizing missing values","a4f41227":"df = df.dropna() \ndms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\ny = df[[\"Salary\"]]\nX_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis = 1).astype(\"float64\")\nX = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","bfcea479":"X.head()","b8ff5c51":"y.head()","78f2fed5":"ridge = Ridge().fit(X_train, y_train) #we created a model\nridge","205662c7":"ridge.coef_ #coefficients","3231d42e":"ridge.intercept_ #fixed value - b0","ebe7cdfc":"y_pred = ridge.predict(X_train) #we guessed with X_train.\ny_pred[:10] ","713ee867":"#train error\n#RMSE = Root Mean Square Error\nRMSE = np.sqrt(mean_squared_error(y_train, y_pred))\nRMSE","ec73f440":"# RMSE with cross validation\nnp.sqrt(np.mean(-cross_val_score(ridge, X_train, y_train, cv = 10, scoring =\"neg_mean_squared_error\")))\n","d4b25af1":"#test error\ny_test_pred = ridge.predict(X_test) # we guessed with X_test.\nRMSE = np.sqrt(mean_squared_error(y_test, y_test_pred))\nRMSE","9cdaf424":"alphas = 10**np.linspace(10,-2,100)*0.5\nridgeCV = RidgeCV(alphas = alphas, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridgeCV.fit(X_train, y_train)","debb8670":"ridgeCV.alpha_ # optimum alpha value","a97ec1a8":"ridge_tuned = Ridge(alpha = ridgeCV.alpha_).fit(X_train, y_train)\ny_pred = ridge_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","5221f988":"lasso = Lasso().fit(X_train, y_train)#we created a model\nlasso","c7b56c05":"lasso.coef_ ##coefficients","fcfc9d42":"lasso.intercept_ #fixed value - b0","703d58ee":"lasso.predict(X_train)[:10] #we guessed with X_train.","b99196ab":"lasso.predict(X_test)[:10] #we guessed with X_test.","1d9c1419":"#test error\ny_pred = lasso.predict(X_test)\nRMSE = np.sqrt(mean_squared_error(y_test, y_pred)) \nRMSE","cfc3c445":"alphas =  np.random.randint(0,1000,100)\nlassoCV = LassoCV(alphas = alphas, cv = 10, max_iter = 100000).fit(X_train, y_train)","66f4b586":"lassoCV.alpha_ # optimum alpha value","97d4b824":"final_lasso = Lasso(alpha = lassoCV.alpha_).fit(X_train, y_train)","cf91c899":"y_pred = final_lasso.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","84452c0c":"em = ElasticNet().fit(X_train, y_train)","b514c9bc":"em.coef_","80c5b8fc":"em.intercept_","8182fa73":"em.predict(X_train)[:10]","00d8fcea":"em.predict(X_test)[:10]","57e13c27":"y_pred = em.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","dc66d212":"r2_score(y_test, y_pred)","ef1a27ef":"alphas = 10**np.linspace(10,-2,100)*0.5\nemCV = ElasticNetCV(alphas = alphas, cv = 10).fit(X_train, y_train)","85267e6c":"emCV.alpha_","5ab483b4":"elanet_tuned = ElasticNet(alpha = emCV.alpha_).fit(X_train, y_train)\ny_pred = elanet_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","41c41d26":"<a id = \"1\"><\/a>\n# <font color = \"#483D8B\"> Ridge Regression <\/font>","3871c096":"<a id = \"2.1\"><\/a>\n## Lasso Regression Model","4613f8b5":"<a id =\"3.3\"><\/a>\n## ElasticNet Regression Model Tuning","c71e662a":"## Some linear regression models are used in this notebook","2e14e51e":"1.  [Ridge Regression](#1) \n    * [Ridge Regression Model](#1.1)\n    * [Ridge Regression Predict](#1.2)\n    * [Ridge Regression Model Tuning](#1.3)\n    * [Ridge Regression Final Model](#1.4) \n2. [Lasso Regression](#2)\n    * [Lasso Regression Model](#2.1)\n    * [Lasso Regression Predict](#2.2)\n    * [Lasso Regression Model Tuning](#2.3)\n    * [Lasso Regression Final Model](#2.4)  \n3.  [ElasticNet Regression](#3)\n    * [ElasticNet Regression Model](#3.1) \n    * [ElasticNet Regression Predict](#3.2) \n    * [ElasticNet Regression Model Tuning](#3.3) \n    * [ElasticNet Regression Final Model](#3.4) ","fd84ec60":"<a id =\"3.4\"><\/a>\n## ElasticNet Regression Final Model","90f8ffe7":"<a id = \"1.2\"><\/a>\n## Ridge Regression Predict","6406b487":"<a id = \"2.3\"><\/a>\n\n## Lasso Regression Model Tuning","7bf6184d":"<a id = \"1.1\"><\/a>\n## Ridge Regression Model ","ff8e3290":"<a id = \"3\"><\/a>\n# <font color = \"#483D8B\"> ElasticNet Regression <\/font>","0b4d5972":"<a id = \"2\"><\/a>\n# <font color = \"#483D8B\"> Lasso Regression <\/font>","429b0218":"<a id =\"3.1\"><\/a>\n## ElasticNet Regression Model","bbeeae05":"<a id = \"2.2\"><\/a>\n\n## Lasso Regression Predict","15413553":"**Elastic Net Regression is a mixture of Ridge regression and Lasso regression.**","b2992ae1":"**Regression models are a method of predicting the dependent variable using independent variables. \nOne of them, linear regression, is a method of predicting output by establishing a linear relationship between using independent inputs. Ridge regression is a type of regression that uses L2 regulation.**\n** Our goal is to minimize the sum of squares of the difference between real values \u200b\u200b(y) and the regression curve we create. **","b0f0b27e":"<a id =\"3.2\"><\/a>\n## ElasticNet Regression Predict","3e49adac":"There are 20 columns in total.\n* 16 - integer\n* 3 - object or string\n* 1 - float","dbb37b6b":"### Introduction\n\n**I'm trying to improve myself in machine learning. And I enjoy sharing what I learned here. Today, I will share 3 linear regression models. Good reading!**","c2b8ee02":"<a id = \"1.3\"><\/a>\n## Ridge Regression Model Tuning","51896f91":"**Lasso (Least Absolute Shrinkage and Selection Operator) is similar to Ridge regression. The main difference here is that Ridge regression uses L2 penalty, while Lasso regression uses L1 penalty.**","c335b5e1":"<a id = \"2.4\"><\/a>\n## Lasso Regression Final Model","2d70197d":"<a id = \"1.4\"><\/a>\n## Ridge Regression Final Model","6f965b52":"**Importing Libraries**"}}