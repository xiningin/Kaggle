{"cell_type":{"3045c7ba":"code","ccc84d59":"code","5904f7ce":"code","2fcbc207":"code","8793742d":"code","688e38ba":"code","f0b2b394":"code","6e7b7b67":"code","c2b7bf72":"code","2267b0f0":"code","387f8d20":"code","590123eb":"code","431a7588":"code","ada49b52":"code","000d7de9":"code","b47cd32f":"code","aa36385e":"code","57ceaf0b":"code","8d8f2143":"code","25db2108":"code","d2cba8e5":"code","0b30c122":"code","6c7fc4d3":"code","58bda388":"code","4c78a940":"code","c273d5f9":"code","64cfa1b4":"code","4750c3d5":"code","77fdefe0":"code","06ffc02c":"code","1f9d9f3e":"code","6aebf9bb":"code","c1c8600d":"code","b3346873":"code","c2f5f5f0":"code","3b2e0444":"markdown","335450cf":"markdown","72e94fc6":"markdown","31cb45ae":"markdown","693158f2":"markdown","8c8d218e":"markdown","ab4afc6a":"markdown","4902d27e":"markdown","db471749":"markdown","2b25f5c1":"markdown","4b609b13":"markdown","6c397c08":"markdown","f35b4090":"markdown","8e8255c0":"markdown","7d17b4bb":"markdown","28f23151":"markdown","fb28f270":"markdown"},"source":{"3045c7ba":"INPUT_DIR = '\/kaggle\/input\/anime-recommendation-database-2020'\n!ls {INPUT_DIR}","ccc84d59":"import numpy as np\nimport pandas as pd\n\nrating_df = pd.read_csv(INPUT_DIR + '\/animelist.csv', \n                        low_memory=False, \n                        usecols=[\"user_id\", \"anime_id\", \"rating\"]\n                        #, nrows=90000000\n                        )\nrating_df.head(4)","5904f7ce":"# User should rate atleast 400 animies\nn_ratings = rating_df['user_id'].value_counts()\nrating_df = rating_df[rating_df['user_id'].isin(n_ratings[n_ratings >= 400].index)].copy()\nlen(rating_df)","2fcbc207":"# Scaling BTW (0 , 1.0)\nmin_rating = min(rating_df['rating'])\nmax_rating = max(rating_df['rating'])\nrating_df['rating'] = rating_df[\"rating\"].apply(lambda x: (x - min_rating) \/ (max_rating - min_rating)).values.astype(np.float64)\n\nAvgRating = np.mean(rating_df['rating'])\nprint('Avg', AvgRating)","8793742d":"# Removing Duplicated Rows\nduplicates = rating_df.duplicated()\n\nif duplicates.sum() > 0:\n    print('> {} duplicates'.format(duplicates.sum()))\n    rating_df = rating_df[~duplicates]\n\nprint('> {} duplicates'.format(rating_df.duplicated().sum()))","688e38ba":"g = rating_df.groupby('user_id')['rating'].count()\ntop_users = g.dropna().sort_values(ascending=False)[:20]\ntop_r = rating_df.join(top_users, rsuffix='_r', how='inner', on='user_id')\n\ng = rating_df.groupby('anime_id')['rating'].count()\ntop_animes = g.dropna().sort_values(ascending=False)[:20]\ntop_r = top_r.join(top_animes, rsuffix='_r', how='inner', on='anime_id')\n\npd.crosstab(top_r.user_id, top_r.anime_id, top_r.rating, aggfunc=np.sum)","f0b2b394":"# Encoding categorical data\nuser_ids = rating_df[\"user_id\"].unique().tolist()\nuser2user_encoded = {x: i for i, x in enumerate(user_ids)}\nuser_encoded2user = {i: x for i, x in enumerate(user_ids)}\nrating_df[\"user\"] = rating_df[\"user_id\"].map(user2user_encoded)\nn_users = len(user2user_encoded)\n\nanime_ids = rating_df[\"anime_id\"].unique().tolist()\nanime2anime_encoded = {x: i for i, x in enumerate(anime_ids)}\nanime_encoded2anime = {i: x for i, x in enumerate(anime_ids)}\nrating_df[\"anime\"] = rating_df[\"anime_id\"].map(anime2anime_encoded)\nn_animes = len(anime2anime_encoded)\n\nprint(\"Num of users: {}, Num of animes: {}\".format(n_users, n_animes))\nprint(\"Min rating: {}, Max rating: {}\".format(min(rating_df['rating']), max(rating_df['rating'])))","6e7b7b67":"# Shuffle\nrating_df = rating_df.sample(frac=1, random_state=73)\n\nX = rating_df[['user', 'anime']].values\ny = rating_df[\"rating\"]","c2b7bf72":"# Split\ntest_set_size = 10000 #10k for test set\ntrain_indices = rating_df.shape[0] - test_set_size \n\nX_train, X_test, y_train, y_test = (\n    X[:train_indices],\n    X[train_indices:],\n    y[:train_indices],\n    y[train_indices:],\n)\n\nprint('> Train set ratings: {}'.format(len(y_train)))\nprint('> Test set ratings: {}'.format(len(y_test)))","2267b0f0":"X_train_array = [X_train[:, 0], X_train[:, 1]]\nX_test_array = [X_test[:, 0], X_test[:, 1]]","387f8d20":"# Accelerator check\nimport tensorflow as tf\n\nTPU_INIT = True\n\nif TPU_INIT:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    !nvidia-smi\n    \nprint(tf.__version__)","590123eb":"import keras\nfrom keras import layers \nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras.optimizers import Adam","431a7588":"# Embedding layers\nfrom keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten\n\ndef RecommenderNet():\n    embedding_size = 128\n    \n    user = Input(name = 'user', shape = [1])\n    user_embedding = Embedding(name = 'user_embedding',\n                       input_dim = n_users, \n                       output_dim = embedding_size)(user)\n    \n    anime = Input(name = 'anime', shape = [1])\n    anime_embedding = Embedding(name = 'anime_embedding',\n                       input_dim = n_animes, \n                       output_dim = embedding_size)(anime)\n    \n    #x = Concatenate()([user_embedding, anime_embedding])\n    x = Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedding, anime_embedding])\n    x = Flatten()(x)\n        \n    x = Dense(1, kernel_initializer='he_normal')(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"sigmoid\")(x)\n    \n    model = Model(inputs=[user, anime], outputs=x)\n    model.compile(loss='binary_crossentropy', metrics=[\"mae\", \"mse\"], optimizer='Adam')\n    \n    return model\n\nif TPU_INIT:    \n    with tpu_strategy.scope():\n        model = RecommenderNet()\nelse:\n    model = RecommenderNet()\n\nmodel.summary()","ada49b52":"# Callbacks\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n\nstart_lr = 0.00001\nmin_lr = 0.00001\nmax_lr = 0.00005\nbatch_size = 10000\n\nif TPU_INIT:\n    max_lr = max_lr * tpu_strategy.num_replicas_in_sync\n    batch_size = batch_size * tpu_strategy.num_replicas_in_sync\n\nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = .8\n\ndef lrfn(epoch):\n    if epoch < rampup_epochs:\n        return (max_lr - start_lr)\/rampup_epochs * epoch + start_lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        return max_lr\n    else:\n        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n\n\nlr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=0)\n\ncheckpoint_filepath = '.\/weights.h5'\n\nmodel_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n                                        save_weights_only=True,\n                                        monitor='val_loss',\n                                        mode='min',\n                                        save_best_only=True)\n\nearly_stopping = EarlyStopping(patience = 3, monitor='val_loss', \n                               mode='min', restore_best_weights=True)\n\nmy_callbacks = [\n    model_checkpoints,\n    lr_callback,\n    early_stopping,   \n]","000d7de9":"# Model training\nhistory = model.fit(\n    x=X_train_array,\n    y=y_train,\n    batch_size=batch_size,\n    epochs=20,\n    verbose=1,\n    validation_data=(X_test_array, y_test),\n    callbacks=my_callbacks\n)\n\nmodel.load_weights(checkpoint_filepath)","b47cd32f":"#Training results\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history.history[\"loss\"][0:-2])\nplt.plot(history.history[\"val_loss\"][0:-2])\nplt.title(\"model loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"test\"], loc=\"upper left\")\nplt.show()","aa36385e":"def extract_weights(name, model):\n    weight_layer = model.get_layer(name)\n    weights = weight_layer.get_weights()[0]\n    weights = weights \/ np.linalg.norm(weights, axis = 1).reshape((-1, 1))\n    return weights\n\nanime_weights = extract_weights('anime_embedding', model)\nuser_weights = extract_weights('user_embedding', model)","57ceaf0b":"df = pd.read_csv(INPUT_DIR + '\/anime.csv', low_memory=True)\ndf = df.replace(\"Unknown\", np.nan)","8d8f2143":"# Fixing Names\ndef getAnimeName(anime_id):\n    try:\n        name = df[df.anime_id == anime_id].eng_version.values[0]\n        if name is np.nan:\n            name = df[df.anime_id == anime_id].Name.values[0]\n    except:\n        print('error')\n    \n    return name\n\ndf['anime_id'] = df['MAL_ID']\ndf[\"eng_version\"] = df['English name']\ndf['eng_version'] = df.anime_id.apply(lambda x: getAnimeName(x))\n\ndf.sort_values(by=['Score'], \n               inplace=True,\n               ascending=False, \n               kind='quicksort',\n               na_position='last')\n\ndf = df[[\"anime_id\", \"eng_version\", \n         \"Score\", \"Genders\", \"Episodes\", \n         \"Type\", \"Premiered\", \"Members\"]]","25db2108":"def getAnimeFrame(anime):\n    if isinstance(anime, int):\n        return df[df.anime_id == anime]\n    if isinstance(anime, str):\n        return df[df.eng_version == anime]","d2cba8e5":"cols = [\"MAL_ID\", \"Name\", \"Genders\", \"sypnopsis\"]\nsypnopsis_df = pd.read_csv(INPUT_DIR + '\/anime_with_synopsis.csv', usecols=cols)\n\ndef getSypnopsis(anime):\n    if isinstance(anime, int):\n        return sypnopsis_df[sypnopsis_df.MAL_ID == anime].sypnopsis.values[0]\n    if isinstance(anime, str):\n        return sypnopsis_df[sypnopsis_df.Name == anime].sypnopsis.values[0]","0b30c122":"#pd.reset_option('all')\npd.set_option(\"max_colwidth\", None)\n\ndef find_similar_animes(name, n=10, return_dist=False, neg=False):\n    try:\n        index = getAnimeFrame(name).anime_id.values[0]\n        encoded_index = anime2anime_encoded.get(index)\n        weights = anime_weights\n        \n        dists = np.dot(weights, weights[encoded_index])\n        sorted_dists = np.argsort(dists)\n        \n        n = n + 1            \n        \n        if neg:\n            closest = sorted_dists[:n]\n        else:\n            closest = sorted_dists[-n:]\n\n        print('animes closest to {}'.format(name))\n\n        if return_dist:\n            return dists, closest\n        \n        rindex = df\n\n        SimilarityArr = []\n\n        for close in closest:\n            decoded_id = anime_encoded2anime.get(close)\n            sypnopsis = getSypnopsis(decoded_id)\n            anime_frame = getAnimeFrame(decoded_id)\n            \n            anime_name = anime_frame.eng_version.values[0]\n            genre = anime_frame.Genders.values[0]\n            similarity = dists[close]\n            SimilarityArr.append({\"anime_id\": decoded_id, \"name\": anime_name,\n                                  \"similarity\": similarity,\"genre\": genre,\n                                  'sypnopsis': sypnopsis})\n\n        Frame = pd.DataFrame(SimilarityArr).sort_values(by=\"similarity\", ascending=False)\n        return Frame[Frame.anime_id != index].drop(['anime_id'], axis=1)\n\n    except:\n        print('{}!, Not Found in Anime list'.format(name))","6c7fc4d3":"find_similar_animes('Dragon Ball Z', n=5, neg=False)","58bda388":"find_similar_animes('Your Name.', n=5, neg=False)","4c78a940":"find_similar_animes('Sword Art Online', n=5, neg=False)","c273d5f9":"find_similar_animes('Black Clover', n=5, neg=False)","64cfa1b4":"print('> picking up random user')\n\nratings_per_user = rating_df.groupby('user_id').size()\nrandom_user = ratings_per_user[ratings_per_user < 500].sample(1, random_state=None).index[0]\nprint('> user_id:', random_user)","4750c3d5":"#pd.reset_option('all')\npd.set_option(\"max_colwidth\", None)\n\ndef find_similar_users(item_input, n=10,return_dist=False, neg=False):\n    try:\n        index = item_input\n        encoded_index = user2user_encoded.get(index)\n        weights = user_weights\n    \n        dists = np.dot(weights, weights[encoded_index])\n        sorted_dists = np.argsort(dists)\n        \n        n = n + 1\n        \n        if neg:\n            closest = sorted_dists[:n]\n        else:\n            closest = sorted_dists[-n:]\n\n        print('> users similar to #{}'.format(item_input))\n\n        if return_dist:\n            return dists, closest\n        \n        rindex = df\n        SimilarityArr = []\n        \n        for close in closest:\n            similarity = dists[close]\n\n            if isinstance(item_input, int):\n                decoded_id = user_encoded2user.get(close)\n                SimilarityArr.append({\"similar_users\": decoded_id, \n                                      \"similarity\": similarity})\n\n        Frame = pd.DataFrame(SimilarityArr).sort_values(by=\"similarity\", \n                                                        ascending=False)\n        \n        return Frame\n    \n    except:\n        print('{}!, Not Found in User list'.format(name))","77fdefe0":"similar_users = find_similar_users(int(random_user), \n                                   n=5, \n                                   neg=False)\n\nsimilar_users = similar_users[similar_users.similarity > 0.4]\nsimilar_users = similar_users[similar_users.similar_users != random_user]\nsimilar_users.head(5)","06ffc02c":"from wordcloud import WordCloud\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef showWordCloud(all_genres):\n    genres_cloud = WordCloud(width=700, height=400, \n                             background_color='white', \n                             colormap='gnuplot').generate_from_frequencies(all_genres)\n    \n    plt.figure(figsize=(10,8)) \n    plt.imshow(genres_cloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\ndef getFavGenre(frame, plot=False):\n        frame.dropna(inplace=False)\n        all_genres = defaultdict(int)\n        \n        genres_list = []\n        for genres in frame['Genders']:\n            if isinstance(genres, str):\n                for genre in genres.split(','):\n                    genres_list.append(genre)\n                    all_genres[genre.strip()] += 1    \n        if plot:\n            showWordCloud(all_genres)\n        \n        return genres_list\n\n    \ndef get_user_preferences(user_id, plot=False, verbose=0):\n    animes_watched_by_user = rating_df[rating_df.user_id==user_id]\n    user_rating_percentile = np.percentile(animes_watched_by_user.rating, 75)\n    animes_watched_by_user = animes_watched_by_user[animes_watched_by_user.rating >= user_rating_percentile]\n    top_animes_user = (\n        animes_watched_by_user.sort_values(by=\"rating\", ascending=False)#.head(10)\n        .anime_id.values\n    )\n    \n    anime_df_rows = df[df[\"anime_id\"].isin(top_animes_user)]\n    anime_df_rows = anime_df_rows[[\"eng_version\", \"Genders\"]]\n    \n    if verbose != 0:\n        print(\"> User #{} has rated {} movies (avg. rating = {:.1f})\".format(\n          user_id, len(animes_watched_by_user),\n          animes_watched_by_user['rating'].mean(),\n        ))\n    \n        print('> preferred genres')\n    \n    if plot:\n        getFavGenre(anime_df_rows, plot)\n        \n    return anime_df_rows#.eng_version.values","1f9d9f3e":"user_pref = get_user_preferences(random_user, plot=True, verbose=1)\nprint('> animes highly rated by this user')\n\npd.DataFrame(user_pref).head(5)","6aebf9bb":"def get_recommended_animes(similar_users, n=10):\n    recommended_animes = []\n    anime_list = []\n    \n    for user_id in similar_users.similar_users.values:\n        pref_list = get_user_preferences(int(user_id), verbose=0)\n        pref_list = pref_list[~ pref_list.eng_version.isin(user_pref.eng_version.values)]\n        anime_list.append(pref_list.eng_version.values)\n        \n    anime_list = pd.DataFrame(anime_list)\n    sorted_list = pd.DataFrame(pd.Series(anime_list.values.ravel()).value_counts()).head(n)\n    \n    for i, anime_name in enumerate(sorted_list.index):        \n        n_user_pref = sorted_list[sorted_list.index == anime_name].values[0][0]\n        if isinstance(anime_name, str):\n            try:\n                frame = getAnimeFrame(anime_name)\n                anime_id = frame.anime_id.values[0]\n                genre = frame.Genders.values[0]\n                sypnopsis = getSypnopsis(int(anime_id))\n                recommended_animes.append({#\"anime_id\": anime_id ,\n                                            \"n\": n_user_pref,\n                                            \"anime_name\": anime_name, \n                                            \"Genders\": genre, \n                                            \"sypnopsis\": sypnopsis})\n            except:\n                pass\n    \n    return pd.DataFrame(recommended_animes)","c1c8600d":"recommended_animes = get_recommended_animes(similar_users, n=10)\ngetFavGenre(recommended_animes, plot=True)\n\nprint('\\n> Top recommendations for user: {}'.format(random_user))\nrecommended_animes","b3346873":"print(\"Showing recommendations for user: {}\".format(random_user))\nprint(\"===\" * 25)\n\nanimes_watched_by_user = rating_df[rating_df.user_id==random_user]\nanime_not_watched_df = df[\n    ~df[\"anime_id\"].isin(animes_watched_by_user.anime_id.values)\n]\n\nanime_not_watched = list(\n    set(anime_not_watched_df['anime_id']).intersection(set(anime2anime_encoded.keys()))\n)\n\nanime_not_watched = [[anime2anime_encoded.get(x)] for x in anime_not_watched]\n\nuser_encoder = user2user_encoded.get(random_user)\n\nuser_anime_array = np.hstack(\n    ([[user_encoder]] * len(anime_not_watched), anime_not_watched)\n)\n\nuser_anime_array = [user_anime_array[:, 0], user_anime_array[:, 1]]\nratings = model.predict(user_anime_array).flatten()\n\ntop_ratings_indices = (-ratings).argsort()[:10]\n\nrecommended_anime_ids = [\n    anime_encoded2anime.get(anime_not_watched[x][0]) for x in top_ratings_indices\n]\n\nResults = []\ntop_rated_ids = []\n\nfor index, anime_id in enumerate(anime_not_watched):\n    rating = ratings[index]\n    id_ = anime_encoded2anime.get(anime_id[0])\n    \n    if id_ in recommended_anime_ids:\n        top_rated_ids.append(id_)\n        try:\n            condition = (df.anime_id == id_)\n            name = df[condition]['eng_version'].values[0]\n            genre = df[condition].Genders.values[0]\n            score = df[condition].Score.values[0]\n            sypnopsis = getSypnopsis(int(id_))\n        except:\n            continue\n            \n        Results.append({#\"anime_id\": id_, \n                        \"name\": name, \n                        \"pred_rating\": rating,\n                        \"genre\": genre, \n                        'sypnopsis': sypnopsis})\n\nprint(\"---\" * 25)\nprint(\"> Top 10 anime recommendations\")\nprint(\"---\" * 25)\n\n\nResults = pd.DataFrame(Results).sort_values(by='pred_rating', ascending=False)\nResults","c2f5f5f0":"model.save('anime_model.h5')\n\nfrom IPython.display import FileLink\nFileLink(r'.\/anime_model.h5')","3b2e0444":"### **sypnopsis data**","335450cf":"## **Data Preprocessing**","72e94fc6":"### **anime meta data**","31cb45ae":"## **User preferences**","693158f2":"![](https:\/\/i.pinimg.com\/originals\/1f\/cb\/2a\/1fcb2af4376fe78b6d82197bd1fdbff6.gif)","8c8d218e":"## **Extracting weights from model**","ab4afc6a":"## **Task 2**: Finding Similar Users (User Based Recommendation)","4902d27e":"![](https:\/\/steamuserimages-a.akamaihd.net\/ugc\/993512070845192516\/C18040A95DB14DD58438DDDEBF721BA8ABAD0E84\/)","db471749":"![CF](https:\/\/dataconomy.com\/wp-content\/uploads\/2015\/03\/Beginners-Guide-Recommender-Systems-Collaborative-Filtering-620x340.jpg)\n\n## **Collaborative Filtering**\n+ **predicting** what **users** will **like** based on their **similarity to other users.**\n+ **Advantages:** capable of accurately recommending complex items such as movies without requiring an \u201cunderstanding\u201d of the item itself. \n+ many  have been used in measuring (**user similarity** or **item similarity**) in **recommender systems.** \n+ **Task 1**: finding similar animes\n+ **Task 2**: finding similar users\n+ **Task 3**: Recommending Animes for a random user","2b25f5c1":"## **Task 1**: Finding Similar Animes (Item Based Recommendation)","4b609b13":"## **Ranking based Recommendation**","6c397c08":"![](https:\/\/content.codecademy.com\/programs\/code-foundations-path\/ds-survey\/utilitymatrix.gif)","f35b4090":"### **these animes are my fav**","8e8255c0":"## **Task 3**: **Recommending** animes for a user","7d17b4bb":"![](https:\/\/i.pinimg.com\/originals\/26\/fd\/49\/26fd49fa54b204fbaf6301efefd53ae2.gif)","28f23151":"![](https:\/\/64.media.tumblr.com\/1b942774dc6d4240cfbb3da22d99a681\/tumblr_phsucvmeDT1sivxmj_500.gifv)","fb28f270":"## **Model Building**"}}