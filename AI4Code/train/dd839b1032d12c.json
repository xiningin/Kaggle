{"cell_type":{"e0d9ddd5":"code","f0d5a99a":"markdown"},"source":{"e0d9ddd5":"from scipy.stats import spearmanr \nfrom fastai.text import *\n\nclass SpearmanRho(Callback):\n    def on_epoch_begin(self, **kwargs):\n        # Reset\n        self.spearman_rho = 0\n        self.spearman_scores = []\n        # Calculate the output scores \n        self.targets = None\n        self.outputs = None\n    def on_batch_end(self, last_output, last_target, **kwargs):\n        if self.targets is None:\n            self.targets = last_target\n        else:\n            self.targets = torch.cat((self.targets, last_target))\n        if self.outputs is None:\n            self.outputs = last_output\n        else:\n            self.outputs = torch.cat((self.outputs, last_output))\n    \n    def on_epoch_end(self, last_output, last_target, last_metrics, **kwargs):\n        for i in range(self.outputs.shape[1]):\n            # Calculate spearman score across the differerent metrics\n            spearman_score =\\\n            spearmanr(self.outputs.permute(1, 0)[i], \n                      self.targets.permute(1, 0)[i])\n            self.spearman_scores.append(spearman_score[0]) \n        self.spearman_rho = np.nanmean(self.spearman_scores)\n        nan_count = sum([np.isnan(x) for x in self.spearman_scores])\/len(self.spearman_scores)\n        if nan_count > 0:\n            print(\"The number of nan in the spearman scores is: \"+str(nan_count))\n        return add_metrics(last_metrics, self.spearman_rho)","f0d5a99a":"Hi all, the following is code I wrote for my Fastai model in order to track the Spearman Rho statistic. Since this is the eventual score we are comparing it against, it only makes sense for us to track it to get a general sense of how we are performing. \n\nSimply add this to your learner similar to the following example:\n\n```\nlearner = Learner(databunch, \n                  custom_transformer_model, \n                  metrics=[SpearmanRho()])\n```\n\nHope this helps!"}}