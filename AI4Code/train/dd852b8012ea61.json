{"cell_type":{"bb7967b6":"code","4c474083":"code","b2f14088":"code","ae9905b0":"code","22ba4e38":"code","196c6cfe":"code","2cff1d94":"code","07829040":"code","4d8b2406":"code","805c1ebb":"code","24440892":"code","42af4314":"code","6130e026":"code","9c9a72f1":"code","40f153a6":"code","e266472e":"code","e8bf981f":"code","a93374d6":"code","ccb4e24c":"code","5e834155":"code","aa2df321":"code","bfb71ffa":"code","9c0377e5":"code","8a5b8820":"code","716a56ae":"code","20048f13":"code","ddc03418":"code","1a9c18f9":"code","6a78b243":"code","e4644636":"code","021a821d":"code","5840e7d7":"code","9c1fb472":"code","b3348ec6":"code","1e070844":"code","3d3274ae":"code","8af94fb4":"code","21ebeb8c":"code","7f708959":"code","7be68898":"code","e2c4f4bc":"code","e4f3ff7f":"code","3cc64e64":"markdown","942e9118":"markdown","438e2bbd":"markdown","f13c9146":"markdown","92c8a910":"markdown","6654f2cd":"markdown","da1b56f3":"markdown","f6930da6":"markdown","b2dee569":"markdown","f8ead10b":"markdown","7dba4951":"markdown","9e98672f":"markdown","40ee4481":"markdown","0c73139a":"markdown","f5636e79":"markdown","3c73a8c8":"markdown","95ea8cb6":"markdown","cbde804f":"markdown","51c4e96d":"markdown","b25a1bdb":"markdown","5caf0237":"markdown","8fc4bad8":"markdown","84ed4355":"markdown"},"source":{"bb7967b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4c474083":"#reading train dataset\ntrain = pd.read_csv(\"..\/input\/fashion-mnist_train.csv\")\nprint(train.shape)","b2f14088":"# let's look at first five train samples\ntrain.head()","ae9905b0":"train.iloc[0].value_counts()","22ba4e38":"# reading test dataset\ntest = pd.read_csv(\"..\/input\/fashion-mnist_test.csv\")\nprint(test.shape)","196c6cfe":"# let's look at first five test samples\ntest.head()","2cff1d94":"# put labels into Y_train variable\nY_train = train[\"label\"].values\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"], axis = 1)\nX_train.head()","07829040":"# put labels into Y_test variable\nY_test = test[\"label\"].values\n# Drop 'label' column\nX_test = test.drop(labels = [\"label\"], axis = 1)\nX_test.head()","4d8b2406":"plt.figure(figsize=(14,8))\nsns.countplot(Y_train, palette=\"icefire\")\nplt.title(\"Number of classes\")\nplt.show()","805c1ebb":"plt.figure(figsize=(14,8))\nsns.countplot(Y_test, palette=\"icefire\")\nplt.title(\"Number of classes\")\nplt.show()","24440892":"# plot some samples\nplt.figure(figsize=(4,4))\nplt.title(Y_train[0])\nplt.imshow(X_train.values.reshape(-1,28,28)[0],cmap=\"gray\")","42af4314":"# plot some samples\nplt.figure(figsize=(4,4))\nplt.title(Y_train[17])\nplt.imshow(X_train.values.reshape(-1,28,28)[17],cmap=\"gray\")","6130e026":"plt.figure(figsize = (14,8))\n\nfor i in range(10):\n    plt.subplot(2, 5, i+1)\n    img = train[train.label == i].iloc[0, 1:].values\n    img = img.reshape((28,28))\n    plt.imshow(img, cmap='gray')\n    plt.title(\"Class: \" + str(i))\n    plt.axis('off')\n    \nplt.show()","9c9a72f1":"# Normalize the data\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0\nprint(\"X_train shape: \",X_train.shape)\nprint(\"X_test shape: \",X_test.shape)","40f153a6":"X_train.head()","e266472e":"X_test.head()","e8bf981f":"# Reshaping\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nprint(\"X_train shape: \",X_train.shape)\nprint(\"X_test shape: \",X_test.shape)","a93374d6":"# Label Encoding (be careful! run just once!)\nfrom keras.utils.np_utils import to_categorical \n\n# convert to one-hot-encoding(one hot vectors)\nY_train = to_categorical(Y_train, num_classes = 10)\n# convert to one-hot-encoding(one hot vectors)\nY_test = to_categorical(Y_test, num_classes = 10)\n\nprint(Y_train.shape)\nprint(Y_test.shape)","ccb4e24c":"# Split the train and the validation set for the fitting\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 2)\nprint(\"x_train shape: \",x_train.shape)\nprint(\"x_val shape: \",x_val.shape)\nprint(\"y_train shape: \",y_train.shape)\nprint(\"y_val shape :\",y_val.shape)","5e834155":"# Some examples\nplt.imshow(x_train[4].reshape(28,28),cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()","aa2df321":"import warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\n\nmodel = Sequential()\n\n#1. LAYER\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\n\n#2. LAYER\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n#3. LAYER\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\n\n#4. LAYER\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n#FULLY CONNECTED LAYER\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.25))\n\n#OUTPUT LAYER\nmodel.add(Dense(10, activation='softmax'))","bfb71ffa":"model.summary()","9c0377e5":"optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)","8a5b8820":"# # Define the optimizer\n# optimizer = RMSprop(lr = 0.001, rho=0.9, epsilon=1e-08, decay=0.0)","716a56ae":"# Compile the model\nmodel.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","20048f13":"epochs = 50 # for better result increase the epochs\nbatch_size = 100","ddc03418":"# Data Augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.1,  # randomly rotate images in the range\n        zoom_range = 0.1, # Randomly zoom image\n        width_shift_range=0.1,  # randomly shift images horizontally\n        height_shift_range=0.1,  # randomly shift images vertically\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(x_train)","1a9c18f9":"# # save the best weights\n# checkpointer = ModelCheckpoint(filepath=\"..\/yourPath\/fashion_mnist_model.h5\", verbose=1, save_best_only=True)","6a78b243":"history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                              shuffle=True, #veriler random gelip e\u011fitilir\n                              epochs=epochs, validation_data = (x_val, y_val),\n                              verbose = 2, steps_per_epoch=x_train.shape[0] \/\/ batch_size)\n#                               callbacks=[checkpointer]) #we save the best weights with checkpointer","e4644636":"# # save model to json\n# model_json = model.to_json() #fashion_mnist_model.h5 - I saved the file in JSON format.\n# with open(\"..\/yourPath\/fashion_mnist_model.json\", \"w\") as json_file:\n#     json_file.write(model_json)","021a821d":"# # load the best weights which we saved\n# model_best = load_model(\"..\/yourPath\/fashion_mnist_model.h5\")","5840e7d7":"plt.figure(figsize=(14,5))\nplt.subplot(1, 2, 1)\nplt.suptitle('Train Results', fontsize=10)\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], color='b', label='Training Loss')\nplt.plot(history.history['val_loss'], color='r', label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['acc'], color='green', label='Training Accuracy')\nplt.plot(history.history['val_acc'], color='orange', label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","9c1fb472":"print('Train accuracy of the model: ',history.history['acc'][-1])","b3348ec6":"print('Train loss of the model: ',history.history['loss'][-1])","1e070844":"print('Validation accuracy of the model: ',history.history['val_acc'][-1])","3d3274ae":"print('Validation loss of the model: ',history.history['val_loss'][-1])","8af94fb4":"score = model.evaluate(X_test,Y_test,verbose=0)\nprint(\"Test Loss:\",score[0])\nprint(\"Test Accuracy:\",score[1])","21ebeb8c":"print(X_test.shape)\nplt.imshow(X_test[100].reshape(28,28),cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()","7f708959":"trueY = Y_test[100]\nimg = X_test[100]\ntest_img = img.reshape(1,28,28,1)\n\npreds = model.predict_classes(test_img)\nprob = model.predict_proba(test_img)\n\nprint(\"trueY: \",np.argmax(trueY))#i\u00e7lerinden en y\u00fcksek olan de\u011feri se\u00e7er\nprint(\"Preds: \",preds)\nprint(\"Prob: \",prob)","7be68898":"# image_path = \"..\/yourPath\/test_image.jpg\"\n\n# test_image_orjinal = image.load_img(image_path) # orjinal renkli g\u00f6r\u00fcnt\u00fc\n\n# test_image = image.load_img(image_path, target_size=(48,48), grayscale=True)\n# test_data = image.img_to_array(test_image)\n# test_img = test_data.reshape(1,48,48,1)\n\n# preds = model_best.predict_classes(test_img)\n# prob = model_best.predict_proba(test_img)\n\n# print(\"Preds: \",preds)\n# print(\"Prob: \",prob)","e2c4f4bc":"Y_pred = model.predict(X_test)\nY_pred_classes = np.argmax(Y_pred, axis = 1)\nY_true = np.argmax(Y_test, axis = 1)\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\nf,ax = plt.subplots(figsize = (12,12))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.1, cmap = \"gist_yarg_r\", linecolor=\"black\", fmt='.0f', ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","e4f3ff7f":"for i in range(len(confusion_mtx)):\n    print(\"Class:\",str(i))\n    print(\"Number of Wrong Prediction:\", str(sum(confusion_mtx[i])-confusion_mtx[i][i]), \"out of 1000\")\n    print(\"Percentage of True Prediction: {:.2f}%\".format(confusion_mtx[i][i] \/ 10))\n    print(\"***********************************************************\")","3cc64e64":"# Orhan SERTKAYA","942e9118":"<img src=\"https:\/\/github.com\/zalandoresearch\/fashion-mnist\/raw\/master\/doc\/img\/embedding.gif\" alt=\"cce\" border=\"0\">","438e2bbd":"<a id=\"10\"><\/a>\n### Fit the Model","f13c9146":"<a id=\"2\"><\/a> <br>\n## Loading the Data Set\n* **In this part we load and visualize the data.**","92c8a910":"<a id=\"1\"><\/a> <br>\n# INTRODUCTION\n* **In this kernel, we will be working on Fashion MNIST Dataset (Implementing with Keras).**","6654f2cd":"<a id=\"9\"><\/a>\n### Data Augmentation","da1b56f3":"<a id=\"11\"><\/a>\n## Evaluate the model\n* **Validation and Loss visualization**","f6930da6":"<a id=\"5\"><\/a>\n## Convolutional Neural Network ","b2dee569":"<a id=\"4\"><\/a>\n## Train-Test Split\n* **We split the data into train and test sets.**\n* **test size is 10%.**\n* **train size is 90%.**","f8ead10b":"Content:\n* [Introduction](#1):\n* [Loading the Data Set](#2):\n* [Normalization, Reshape and Label Encoding](#3):\n* [Train-Test Split](#4):\n* [Convolutional Neural Network(Implementing with Keras)](#5):\n* [Define Optimizer](#6):\n* [Compile Model](#7):\n* [Epochs and Batch Size](#8):\n* [Data Augmentation](#9):\n* [Fit the Model](#10):\n* [Evaluate the model](#11):\n* [Predict For Random Sample](#12):\n* [Reading,Resizing and Testing the test image](#13):\n* [Confusion Matrix](#14):\n* [Conclusion](#15):","7dba4951":"<a id=\"15\"><\/a>\n# Conclusion\n* **If you like it, please upvote.**\n* **If you have any question, I will be appreciate to hear it.**","9e98672f":"* **For example,let's look at first sample pixel values**","40ee4481":"<a id=\"8\"><\/a>\n### Epochs and Batch Size","0c73139a":"<a id=\"6\"><\/a>\n### Define Optimizer   \n* **Adam optimizer: Change the learning rate**","f5636e79":"## Let's take a look at the Fashion MNIST dataset!","3c73a8c8":"<a id=\"7\"><\/a>\n### Compile Model\n* **Categorical crossentropy**\n* **We make binary cross entropy at previous parts and in machine learning tutorial**\n* **At this time we use categorical crossentropy. That means that we have multiclass**\n <a href=\"https:\/\/ibb.co\/jm1bpp\"><img src=\"https:\/\/preview.ibb.co\/nN3ZaU\/cce.jpg\" alt=\"cce\" border=\"0\"><\/a>","95ea8cb6":"## Implementing with Keras","cbde804f":"<a id=\"12\"><\/a>\n### Predict For Random Sample","51c4e96d":"<img src=\"https:\/\/github.com\/zalandoresearch\/fashion-mnist\/raw\/master\/doc\/img\/fashion-mnist-sprite.png\" alt=\"cce\" border=\"0\">","b25a1bdb":"<a id=\"14\"><\/a>\n### Confusion Matrix","5caf0237":"# Convolutional Neural Networks (CNNs \/ ConvNets)","8fc4bad8":"<a id=\"3\"><\/a> <br>\n## Normalization, Reshape and Label Encoding \n* **Normalization**\n    * We perform a grayscale normalization to reduce the effect of illumination's differences.\n    * If we perform normalization, CNN works faster.\n* **Reshaping**\n    * Train and test images (28 x 28) \n    * We reshape all data to 28x28x1 3D matrices.\n    * Keras needs an extra dimension in the end which correspond to channels. Our images are gray scaled so it use only one channel. \n* **Label Encoding**\n    * Encode labels to one hot vectors \n        * 2 => [0,0,1,0,0,0,0,0,0,0]\n        * 4 => [0,0,0,0,1,0,0,0,0,0]","84ed4355":"<a id=\"13\"><\/a>\n### Reading,Resizing and Testing the test image"}}