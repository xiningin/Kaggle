{"cell_type":{"abcfc3a3":"code","bb3021d8":"code","ddcc2aa0":"code","5248be36":"code","39e9fa67":"code","106c392f":"code","587480f5":"code","9e2a3d87":"code","8fd039c3":"code","4afe5bce":"code","30c9cfd1":"code","27f5df07":"code","9df68935":"code","038c672e":"code","567adf1a":"code","2bfef26d":"code","bae2b6fb":"code","ba275b33":"code","89a8db86":"code","ffad7307":"markdown","144e8110":"markdown","cca1be54":"markdown","9de4d0cf":"markdown"},"source":{"abcfc3a3":"import tensorflow as tf\nimport keras\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import jaccard_score\n\nfrom scipy import stats\n\nimport seaborn as sns\n\nimport skimage\nfrom skimage.transform import rotate\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPool2D, UpSampling2D, GlobalMaxPool2D, GlobalAveragePooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Input\nfrom tensorflow.keras.models import Model, load_model\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import NASNetMobile, Xception, DenseNet121, MobileNetV2, InceptionV3, InceptionResNetV2, vgg16, resnet50, inception_v3, xception, DenseNet201\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import CSVLogger\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom datetime import datetime\n\nimport numpy as np\nimport os\nimport cv2\nimport pandas as pd\n# import imutils\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt","bb3021d8":"df = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ndf","ddcc2aa0":"df_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/train.csv')\n\ndf_train = df_train.dropna(subset=['Age']).drop(['Cabin', 'Embarked'], axis=1)\n# df_test = df_test.dropna(subset=['Age']).drop(['Cabin', 'Embarked'], axis=1)\n\ndf_train","5248be36":"for num, i in enumerate(df_train['Name']):\n    df_train['Name'][num] = i.split(',')[0]\n\nfor num, i in enumerate(df_test['Name']):\n    df_test['Name'][num] = i.split(',')[0]\n    \ndf_train","39e9fa67":"df_train['Sex'] = df_train['Sex'].replace(['male', 'female'], [1, 0])\ndf_test['Sex'] = df_test['Sex'].replace(['male', 'female'], [1, 0])\ndf_train","106c392f":"Names = np.unique(df_train['Name'])\nNames","587480f5":"df_train['Name'] = df_train['Name'].replace(Names,range(len(Names)))\ndf_train","9e2a3d87":"Tickets = np.unique(df_train['Ticket'])\nTickets","8fd039c3":"df_train['Ticket'] = df_train['Ticket'].replace(Tickets,range(len(Tickets)))\ndf_train","4afe5bce":"# Number of Name and Ticket are too much, so I will drop them!!!!!!!\ndf_train.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\ndf_test.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n\ndf_train = df_train.reset_index().drop(['index'], axis=1)\ndf_train","30c9cfd1":"X = df_train.drop(['Survived'], axis=1)\nX","27f5df07":"Y = df_train['Survived']\nY","9df68935":"X = np.array(X)\nY = np.array(Y)\nX[:5], Y[:5]","038c672e":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report","567adf1a":"kfold = KFold(n_splits=5, random_state=42)\n\nprint('===============================================================')\nDT_model = DecisionTreeClassifier(criterion='entropy', max_depth=None)\nfor count, (train_index, valid_index) in enumerate(kfold.split(X)):\n    DT_model = DT_model.fit(X[train_index], Y[train_index])\n    y_pred = DT_model.predict(X[valid_index])\n    y_train_score = DT_model.score(X[train_index], Y[train_index])\n    y_valid_score = DT_model.score(X[valid_index], Y[valid_index])\n    y_score = DT_model.score(X, Y)\n    print('KFold :', count+1)\n    print('Decision Tree Train Score :', y_train_score)\n    print('Decision Tree Validation Score :', y_valid_score)\n    print('Decision Tree Score :', y_score, '\\n')\n    print(classification_report(Y[valid_index], y_pred))\n    print('===============================================================')\n    \ny_pred = DT_model.predict(X)\ny_score = DT_model.score(X, Y)\nprint('Final Decision Tree Model')\nprint('Decision Tree Final Score :', y_score, '\\n')\nprint(classification_report(Y, y_pred))\nprint('===============================================================')","2bfef26d":"from sklearn.naive_bayes import GaussianNB","bae2b6fb":"print('===============================================================')\ngnb_model = GaussianNB()\nfor count, (train_index, valid_index) in enumerate(kfold.split(X)):\n    gnb_model.fit(X[train_index], Y[train_index])\n    y_pred = gnb_model.predict(X[valid_index])\n    y_train_score = gnb_model.score(X[train_index], Y[train_index])\n    y_valid_score = gnb_model.score(X[valid_index], Y[valid_index])\n    y_score = gnb_model.score(X, Y)\n    print('KFold :', count+1)\n    print('GaussianNB Train Score :', y_train_score)\n    print('GaussianNB Validation Score :', y_valid_score)\n    print('GaussianNB Score :', y_score, '\\n')\n    print(classification_report(Y[valid_index], y_pred))\n    print('===============================================================')\n    \ny_pred = gnb_model.predict(X)\ny_score = gnb_model.score(X, Y)\nprint('Final GaussianNB Model')\nprint('GaussianNB Final Score :', y_score, '\\n')\nprint(classification_report(Y, y_pred))\nprint('===============================================================')","ba275b33":"from sklearn.neural_network import MLPClassifier","89a8db86":"print('===============================================================')\nMLP_model = MLPClassifier(hidden_layer_sizes=(64,64), random_state=1)\nfor count, (train_index, valid_index) in enumerate(kfold.split(X)):\n    MLP_model.fit(X[train_index], Y[train_index])\n    y_pred = MLP_model.predict(X[valid_index])\n    y_train_score = MLP_model.score(X[train_index], Y[train_index])\n    y_valid_score = MLP_model.score(X[valid_index], Y[valid_index])\n    y_score = MLP_model.score(X, Y)\n    print('KFold :', count+1)\n    print('MLPClassifier Train Score :', y_train_score)\n    print('MLPClassifier Validation Score :', y_valid_score)\n    print('MLPClassifier Score :', y_score, '\\n')\n    print(classification_report(Y[valid_index], y_pred))\n    print('===============================================================')\n    \ny_pred = MLP_model.predict(X)\ny_score = MLP_model.score(X, Y)\nprint('Final MLPClassifier Model')\nprint('MLPClassifier Final Score :', y_score, '\\n')\nprint(classification_report(Y, y_pred))\nprint('===============================================================')","ffad7307":"# Neural Network","144e8110":"# Decision Tree","cca1be54":"# Na\u00efve Bayes","9de4d0cf":"# Cleansing Data"}}