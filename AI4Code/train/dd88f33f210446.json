{"cell_type":{"053e7619":"code","0e59a7bb":"code","943aaa82":"code","9db1e791":"code","23b1d033":"code","727c08cd":"code","019af2c1":"code","135b8823":"code","b1554467":"code","2b70e160":"code","25c56b56":"code","f02f19fe":"code","52723e1e":"code","d98dd4e1":"code","25690823":"code","ad8e4cc6":"code","a97650ab":"code","4f8b03cc":"code","2d2f5d2f":"code","4d951d0f":"code","db91c8f5":"code","828553c3":"code","2b4c8259":"code","23268731":"code","f453c6e3":"code","e5edfb5c":"code","20139486":"code","cdfaffd2":"code","e8ce398d":"code","b5f72693":"code","fa397f1a":"code","92687c54":"code","d8fef53c":"markdown","b71f86a1":"markdown","98406f70":"markdown","c1885c47":"markdown","16e601ff":"markdown","3bb7d2e8":"markdown","85233245":"markdown","1b36965e":"markdown","88e2c80c":"markdown"},"source":{"053e7619":"# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline","0e59a7bb":"# Fetching the data\ntrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain_data.head()","943aaa82":"test_data.head()","9db1e791":"# Fill in the missing values\ntrain_data.fillna(0, inplace=True)\ntest_data.fillna(0, inplace=True)","23b1d033":"train_data.head(20)","727c08cd":"train_data.columns.values","019af2c1":"train_data.shape","135b8823":"# See data related to the sex of the passengers\n\ncolors = ['lightseagreen', 'lightcyan']\nlabels = ['male', 'female']\nvalues = []\nexplode = (0, 0.1)\n\nvalues.append(train_data['Sex'].value_counts()['male'])\nvalues.append(train_data['Sex'].value_counts()['female'])\n\nfig = plt.figure(figsize = (10, 5))\n\nplt.pie(values, \n        labels=labels, \n        colors=colors, \n        autopct='%.2f',\n        explode=explode)\nplt.axis('equal')\nplt.show()","b1554467":"# Display number of passengers based on sex\n\ncolors = ['lightseagreen', 'lightcyan']\nlabels = ['male', 'female']\nvalues = []\n\nvalues.append(len(train_data.loc[(train_data['Survived'] == 1) & (train_data['Sex'] == 'male')]))\nvalues.append(len(train_data.loc[(train_data['Survived'] == 1) & (train_data['Sex'] == 'female')]))\n\nfig = plt.figure(figsize = (10, 5))\n\nplt.bar(labels[0], values[0], color='lightcyan', width = 0.4)\nplt.bar(labels[1], values[1], color='lightseagreen', width = 0.4)\nplt.xlabel('Sex')\nplt.ylabel('Number of passangers')\nplt.legend(loc='best')\nfor i, v in enumerate(values):\n    plt.text(x=i-0.02, y=v+1, s=str(v), color='red', fontweight='bold')\n\nplt.show()","2b70e160":"# Change the empty age with age avg.\nrounded_avg = round(train_data['Age'].mean())\ntrain_data['Age'] = train_data['Age'].replace(0, float(rounded_avg))\nfloat(rounded_avg)","25c56b56":"# Display median age value related to passengers survivability\n\n# Using seaborn library\npal = sns.cubehelix_palette(3, rot=-.5, light=.5)\nfigure = sns.FacetGrid(train_data, hue=\"Survived\", aspect=4, palette=pal)\nfigure.map(sns.kdeplot, 'Age', shade= True)\nfigure.set(xlim=(0, train_data['Age'].max()))\nfigure.add_legend()\n\nax = plt.subplots(1, 1, figsize = (26, 5))\nage_avg = train_data[[\"Age\", \"Survived\"]].groupby(['Age'], as_index=False).mean()\nsns.barplot(x='Age', y='Survived', data=age_avg)","f02f19fe":"# Comparing Pclass values\n\nsns.barplot(x='Pclass', y='Survived', palette=\"mako\", data=train_data)","52723e1e":"# Analizing embarking data\n# the value '0' is signaling empty value\n\nsns.barplot(x='Embarked', y='Survived', palette='magma', data=train_data)","d98dd4e1":"# Display corentions between passengers features and the survivability\nfig , ax = plt.subplots(figsize =(12, 10))\ncolormap = sns.diverging_palette(250, 30, l=65, center=\"dark\", as_cmap=True)\n\n# Compute pairwise correlation of columns\nfig = sns.heatmap(\n      train_data.corr(), \n      cmap = colormap,\n      ax=ax,\n      annot=True, \n      square=True, \n      annot_kws={'fontsize':14})\n    \nplt.title('Survivability related to passengers data', y=1, size=16)","25690823":"# Get the null values\ntrain_data.isnull().sum()","ad8e4cc6":"# Display data types of columns\ntrain_data.dtypes","a97650ab":"# Replace the male and female strings with integer values\n\ntrain_data['Sex'] = train_data['Sex'].map({'female': 0, 'male': 1})\ntest_data['Sex'] = test_data['Sex'].map({'female': 0, 'male': 1})","4f8b03cc":"# Replace Embarked string indices with integer ones\ntrain_data['Embarked'] = train_data['Embarked'].fillna(0)\ntrain_data['Embarked'] = train_data['Embarked'].map({'S':1, 'C':2, 'Q':3, 0:0})\ntest_data['Embarked'] = test_data['Embarked'].fillna(0)\ntest_data['Embarked'] = test_data['Embarked'].map({'S':1, 'C':2, 'Q':3, 0:0})","2d2f5d2f":"# Droping redundant columns\nX_train = train_data.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\nY_train = train_data['Survived']\ntest_Id = test_data['PassengerId']\nX_test = test_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n\nX_train.shape, Y_train.shape, X_test.shape","4d951d0f":"# Imports\nfrom sklearn.linear_model import SGDClassifier, LinearRegression, LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier","db91c8f5":"score_tracker = {}","828553c3":"# Linear Regression\n\nlr = LinearRegression()\nlr.fit(X_train, Y_train)\nY_pred_lr = lr.predict(X_test)\naccuracy = round(lr.score(X_train, Y_train) * 100, 2)\nscore_tracker['linear regression'] = accuracy\naccuracy","2b4c8259":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred_sgd = sgd.predict(X_test)\naccuracy = round(sgd.score(X_train, Y_train) * 100, 2)\nscore_tracker['sgd'] = accuracy\naccuracy","23268731":"# Decision Tree\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train, Y_train)\nY_pred_dt = dt.predict(X_test)\naccuracy = round(dt.score(X_train, Y_train) * 100, 2)\nscore_tracker['decision tree'] = accuracy\naccuracy","f453c6e3":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred_svm = svc.predict(X_test)\naccuracy = round(svc.score(X_train, Y_train) * 100, 2)\nscore_tracker['svm'] = accuracy\naccuracy","e5edfb5c":"# K-Neighbors Classifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred_knn = knn.predict(X_test)\naccuracy = round(knn.score(X_train, Y_train) * 100, 2)\nscore_tracker['knn'] = accuracy\naccuracy","20139486":"# Logistic Reression\n\n#lr = LogisticRegression()\n#lr.fit(X_train, Y_train)\n#Y_pred_logr = lr.predict(X_test)\n#accuracy = round(lr.score(X_train, Y_train) * 100, 2)\n#score_tracker['logistic regression'] = accuracy\n#accuracy","cdfaffd2":"# Statistics regarding ML algorithm accuracy\n\ndata_dict = {'ML algorithms': score_tracker.keys(), 'Accuracy': score_tracker.values()}\ndata = pd.DataFrame.from_dict(data_dict)\ndata = pd.DataFrame.sort_values(data, by=['Accuracy'], ascending=False)\nplt.figure(figsize = (16, 6))\nplt.title('ML Algorithm Accuracy')\nplt.xlabel('Accuracy (%)')\nplt.ylabel('Algorithm')\nsns.barplot(x='Accuracy', y='ML algorithms', data=data, palette='cubehelix')","e8ce398d":"# Imports\nimport tensorflow as tf","b5f72693":"# Creating and training the Tensorflow model\n\ntf.random.set_seed(42)\n\n# Creating the model\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Dense(100, activation='relu'),\n  tf.keras.layers.Dense(100, activation='relu'),\n  tf.keras.layers.Dense(1)\n])\n\n# Compiling the model\nmodel.compile(loss = tf.keras.losses.mae,\n              optimizer = tf.keras.optimizers.SGD(lr=0.01),\n              metrics = ['mae'])\n\n# Fitting the model\nmodel.fit(X_train, Y_train, epochs = 100)","fa397f1a":"Y_pred_tf = model.predict(X_test)\naccuracy = round(lr.score(X_train, Y_train) * 100, 2)\naccuracy","92687c54":"submission_data = pd.DataFrame({'PassengerId': test_Id, 'Survived': Y_pred_dt})\nsubmission_data.to_csv('titanic.csv', index=False)","d8fef53c":"## Load the data","b71f86a1":"## Visualize the data","98406f70":"## Fitting models\n* trying out ML algorithms\n* determine which one fits the needs of our problem","c1885c47":"![Titanic art](https:\/\/bookpalace.com\/acatalog\/CotonTitanic.jpg)","16e601ff":"### Writting the submissions for Kaggle","3bb7d2e8":"# Kaggle Titanic Challenge - Machine Learning from Disaster\n- Solution done by Mos Daniele\n- Version 0.1","85233245":"### Using Sklearn ML algorithms","1b36965e":"## Replace values and remodel the data","88e2c80c":"## Tensorflow training tryout\n\n"}}