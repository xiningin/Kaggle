{"cell_type":{"ef0596a8":"code","3e7c1624":"code","74c7bf03":"code","506809b9":"code","294faf61":"code","36341da0":"code","4fd24683":"code","88ee2fb8":"code","4f923db5":"code","a0cc8c6e":"code","d2af6fc5":"code","fcaf41b5":"code","393835d9":"code","d26f18a2":"code","1d2e9e0f":"code","fd319231":"code","80378fb0":"code","4c4df3de":"code","bd34fd7c":"markdown","add33ded":"markdown","f2e97fed":"markdown","651f3118":"markdown","0933dbe7":"markdown","48f77ab7":"markdown","1fdb4ad8":"markdown","896bc0dd":"markdown","6e3a5fae":"markdown","005732a5":"markdown","8c12683b":"markdown","d8ed3383":"markdown"},"source":{"ef0596a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3e7c1624":"import pandas as pd                 # pandas is a dataframe library\nimport matplotlib.pyplot as plt     # matplotlib.pyplot plots data\nimport numpy as np                  # numpy provides N-dim object support\nimport seaborn as sns\nimport sklearn\n%matplotlib inline  ","74c7bf03":"filename = '\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv'\ndf = pd.read_csv(filename)","506809b9":"df.shape","294faf61":"df.head()","36341da0":"df.corr()","4fd24683":"plt.figure(figsize = (10,10))\nplt.style.use('default')\nsns.heatmap(df.corr(), annot = True)","88ee2fb8":"from sklearn.model_selection import train_test_split\n\nX = df.drop('DEATH_EVENT', axis=1)\nY = df['DEATH_EVENT']","4f923db5":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)","a0cc8c6e":"x_train.shape, y_train.shape","d2af6fc5":"x_test.shape, y_test.shape","fcaf41b5":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.metrics import accuracy_score","393835d9":"log_clf = LogisticRegression(C=1, solver='liblinear')\n\nsvc_clf = SVC(C=1, kernel='linear', gamma='auto')\n\nnaive_clf = GaussianNB()\n\nvoting_clf_hard = VotingClassifier(estimators=[('lr', log_clf), \n                                               ('svc', svc_clf), \n                                               ('naive', naive_clf)],\n                                   voting='hard')","d26f18a2":"for clf_hard in (log_clf, svc_clf, naive_clf, voting_clf_hard):\n    \n    clf_hard.fit(x_train, y_train)\n    y_pred = clf_hard.predict(x_test)\n    \n    print(clf_hard.__class__.__name__, accuracy_score(y_test, y_pred))","1d2e9e0f":"svc_clf.fit(x_train, y_train)\n# Predict value using training data\ny_pred = svc_clf.predict(x_test)","fd319231":"\n#import performance metrics library\nfrom sklearn import metrics\n\n# Predict value using training data\ny_pred = svc_clf.predict(x_train)\n\n# Accuracy\nprint(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train, y_pred)))\nprint()","80378fb0":"# Predict value using test data\ny_pred = svc_clf.predict(x_test)\n\n# Accuracy\nprint(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, y_pred)))\nprint()","4c4df3de":"print(\"Confusion Matrix\")\nprint(\"{0}\".format(metrics.confusion_matrix(y_test, y_pred)))\nprint(\"\")\n\nprint(\"Classification Report\")\nprint(metrics.classification_report(y_test, y_pred))","bd34fd7c":"# Algorithm Chossing","add33ded":"Confusion metric","f2e97fed":"# Import library","651f3118":"Heatmap","0933dbe7":"# Train, test split","48f77ab7":"Loop for accuracy with many estimator","1fdb4ad8":"Performance on test data","896bc0dd":"## Voting Classifier","6e3a5fae":"Performance on training data","005732a5":"So we choose SVC classification:","8c12683b":"# Data sourcing","d8ed3383":"## Data exlore"}}