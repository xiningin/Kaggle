{"cell_type":{"f4a6d87d":"code","166c5745":"code","af0f2b3c":"code","5723c5a2":"code","fd134c41":"code","5e0a3c35":"code","61344e2a":"code","9f622365":"code","b8aac2d4":"code","f30f9f5b":"code","7bb3fd89":"code","6fa432a7":"code","e35c8bf8":"code","41c0a33a":"code","c32ab351":"code","423997fe":"code","c9ac9540":"code","c345ccbd":"code","09b90858":"code","151a9c91":"code","a412870e":"code","82cb2a52":"code","68e517e3":"code","21bbdd70":"code","d3d269ad":"code","af956f9b":"code","0d2cbbe3":"code","0eba6727":"code","91cb47e0":"code","a2a663b3":"code","7194c883":"code","4f2be92e":"code","cefe025a":"code","a542b0d2":"code","9aa1e1a1":"code","75acbabe":"code","d857e98c":"code","7131e67a":"code","3bc767d4":"code","4f5bae45":"code","6d8bd7e6":"code","00a1b520":"code","54e0d9d2":"code","16d0ea81":"code","410f2405":"code","5d7ea80d":"code","df82bd67":"code","cdba641f":"code","313ce4c2":"code","04e84745":"code","6e3dd49e":"code","286ecb12":"code","d98af274":"code","f96cbc36":"code","9266976a":"code","e746c0ff":"code","686a4bb3":"code","e918649d":"code","33485440":"code","6337749e":"code","e148f772":"code","4d1cdcc5":"code","f09437a0":"code","590dbeda":"code","c98550ef":"code","0426ae69":"code","2fce1b81":"code","85320d72":"markdown","b8543b9f":"markdown","3b5c866a":"markdown","ba0eb1cb":"markdown","746868b3":"markdown","4391a059":"markdown","48337ff6":"markdown","b6db2c18":"markdown","3f88e023":"markdown","1f16c402":"markdown","20801a14":"markdown","2de0a9f6":"markdown","54994ba2":"markdown","adec173c":"markdown","023538ed":"markdown","de4479de":"markdown","f07e8115":"markdown","12e9bb4d":"markdown","246238e0":"markdown","ea6ba600":"markdown","343ecaa5":"markdown","ea0596ea":"markdown","5acafc97":"markdown","4b1da569":"markdown","d98bf270":"markdown","e78d82f6":"markdown","0c04c24f":"markdown","22d0383f":"markdown","d1bb5aae":"markdown","f692c435":"markdown","e2f56cc6":"markdown","9c95017e":"markdown","754d2ca9":"markdown","d7e9443e":"markdown","74433fbc":"markdown","904bc2f9":"markdown","497c034b":"markdown","1f0d1c3a":"markdown","6d08493e":"markdown","a5caa9a4":"markdown","0d369299":"markdown","5c63ae2b":"markdown","f92f41c2":"markdown","b8071a98":"markdown","a13907d7":"markdown"},"source":{"f4a6d87d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom plotly import tools\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\n\ndf = pd.read_csv('..\/input\/bank.csv')\nterm_deposits = df.copy()\ndata1=df.copy()\n# Have a grasp of how our data looks.\ndf.head()","166c5745":"df.shape","af0f2b3c":"df.describe()","5723c5a2":"# No missing values.\ndf.info()","fd134c41":"f, ax = plt.subplots(1,2, figsize=(16,8))\n\ncolors = [\"#FA5858\", \"#64FE2E\"]\nlabels =\"Did not Open Term Suscriptions\", \"Opened Term Suscriptions\"\n\nplt.suptitle('Information on Term Suscriptions', fontsize=20)\n\ndf[\"deposit\"].value_counts().plot.pie(explode=[0,0.05], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors, \n                                             labels=labels, fontsize=15, startangle=25)\n\n\n# ax[0].set_title('State of Loan', fontsize=16)\nax[0].set_ylabel('% of Term Deposit Account', fontsize=14)\n\n# sns.countplot('loan_condition', data=df, ax=ax[1], palette=colors)\n# ax[1].set_title('Condition of Loans', fontsize=20)\n# ax[1].set_xticklabels(['Good', 'Bad'], rotation='horizontal')\npalette = [\"#64FE2E\", \"#FA5858\"]\n\nsns.barplot(x=\"education\", y=\"balance\", hue=\"deposit\", data=df, palette=palette, estimator=lambda x: len(x) \/ len(df) * 100)\nax[1].set(ylabel=\"(%)\")\nax[1].set_xticklabels(df[\"education\"].unique(), rotation=0, rotation_mode=\"anchor\")\nplt.show()","5e0a3c35":"import matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n\ndf.hist(bins=20, figsize=(14,10), color='#E14906', edgecolor ='black')\nplt.show()","61344e2a":"df['deposit'].value_counts()","9f622365":"plt.style.use('seaborn-white')\nfig = plt.figure(figsize=(20,20))\nax1 = fig.add_subplot(221)\nax2 = fig.add_subplot(222)\nax3 = fig.add_subplot(212)\n\ng = sns.boxplot(x=\"default\", y=\"balance\", hue=\"deposit\",\n                    data=df, palette=\"muted\", ax=ax1)\n\ng.set_title(\"Amount of Balance by Term Suscriptions\")\n\n# ax.set_xticklabels(df[\"default\"].unique(), rotation=45, rotation_mode=\"anchor\")\n\ng1 = sns.boxplot(x=\"job\", y=\"balance\", hue=\"deposit\",\n                 data=df, palette=\"RdBu\", ax=ax2)\n\ng1.set_xticklabels(df[\"job\"].unique(), rotation=90, rotation_mode=\"anchor\")\ng1.set_title(\"Type of Work by Term Suscriptions\")\n\ng2 = sns.violinplot(data=df, x=\"education\", y=\"balance\", hue=\"deposit\", palette=\"RdBu_r\")\n\ng2.set_title(\"Distribution of Balance by Education\")\n\n\nplt.show()","b8aac2d4":"df.head()","f30f9f5b":"# Drop the Job Occupations that are \"Unknown\"\ndf = df.drop(df.loc[df[\"job\"] == \"unknown\"].index)\n\n# Admin and management are basically the same let's put it under the same categorical value\nlst = [df]\n\nfor col in lst:\n    col.loc[col[\"job\"] == \"admin.\", \"job\"] = \"management\"","7bb3fd89":"df.columns","6fa432a7":"suscribed_df = df.loc[df[\"deposit\"] == \"yes\"]\n\noccupations = df[\"job\"].unique().tolist()\n\n# Get the balances by jobs\nmanagement = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"management\"].values\ntechnician = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"technician\"].values\nservices = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"services\"].values\nretired = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"retired\"].values\nblue_collar = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"blue-collar\"].values\nunemployed = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"unemployed\"].values\nentrepreneur = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"entrepreneur\"].values\nhousemaid = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"housemaid\"].values\nself_employed = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"self-employed\"].values\nstudent = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"student\"].values\n\n\nages = [management, technician, services, retired, blue_collar, unemployed, \n         entrepreneur, housemaid, self_employed, student]\n\ncolors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)',\n          'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', \n          'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)',\n         'rgba(229, 126, 56, 0.5)', 'rgba(229, 56, 56, 0.5)',\n         'rgba(174, 229, 56, 0.5)', 'rgba(229, 56, 56, 0.5)']\n\ntraces = []\n\nfor xd, yd, cls in zip(occupations, ages, colors):\n        traces.append(go.Box(\n            y=yd,\n            name=xd,\n            boxpoints='all',\n            jitter=0.5,\n            whiskerwidth=0.2,\n            fillcolor=cls,\n            marker=dict(\n                size=2,\n            ),\n            line=dict(width=1),\n        ))\n\nlayout = go.Layout(\n    title='Distribution of Ages by Occupation',\n    yaxis=dict(\n        autorange=True,\n        showgrid=True,\n        zeroline=True,\n        dtick=5,\n        gridcolor='rgb(255, 255, 255)',\n        gridwidth=1,\n        zerolinecolor='rgb(255, 255, 255)',\n        zerolinewidth=2,\n    ),\n    margin=dict(\n        l=40,\n        r=30,\n        b=80,\n        t=100,\n    ),\n    paper_bgcolor='rgb(224,255,246)',\n    plot_bgcolor='rgb(251,251,251)',\n    showlegend=False\n)\n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","e35c8bf8":"# Balance Distribution\nfig = plt.figure(figsize=(12,8))\n\nsns.violinplot(x=\"balance\", y=\"job\", hue=\"deposit\", palette=\"RdBu_r\",\n            data=df);\n\nplt.title(\"Job Distribution of Balances by Deposit Status\", fontsize=16)\n\nplt.show()","41c0a33a":"\n# Create a Balance Category\ndf[\"balance_status\"] = np.nan\nlst = [df]\n\nfor col in lst:\n    col.loc[col[\"balance\"] < 0, \"balance_status\"] = \"negative\"\n    col.loc[(col[\"balance\"] >= 0) & (col[\"balance\"] <= 30000), \"balance_status\"] = \"low\"\n    col.loc[(col[\"balance\"] > 30000) & (col[\"balance\"] <= 40000), \"balance_status\"] = \"middle\"\n    col.loc[col[\"balance\"] > 40000, \"balance_status\"] = \"high\"\n    \n# balance by balance_status\nnegative = df[\"balance\"].loc[df[\"balance_status\"] == \"negative\"].values.tolist()\nlow = df[\"balance\"].loc[df[\"balance_status\"] == \"low\"].values.tolist()\nmiddle = df[\"balance\"].loc[df[\"balance_status\"] == \"middle\"].values.tolist()\nhigh = df[\"balance\"].loc[df[\"balance_status\"] == \"high\"].values.tolist()\n\n\n# Get the average by occupation in each balance category\njob_balance = df.groupby(['job', 'balance_status'])['balance'].mean()\n\n\ntrace1 = go.Bar(\n    x=[-199.0, -392.0, -209.0, -247.0, -233.0, -270.0, -271.0, 0, -276.0, -134.5],width=5,\n    y=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n         \"services\", \"student\", \"technician\", \"unemployed\"],\n    name='Negative Balance',\n    marker=dict(\n        color='rgb(246, 46, 46)'\n    )\n)\ntrace2 = go.Bar(\n    x=[319.5, 283.0, 212.0, 313.0, 409.0, 274.5, 308.5, 253.0, 316.0, 330.0],width=5,\n    y=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n         \"services\", \"student\", \"technician\", \"unemployed\"],\n    name='Low Balance',\n    marker=dict(\n        color='rgb(246, 97, 46)'\n    )\n)\ntrace3 = go.Bar(\n    x=[2128.5, 2686.0, 2290.0, 2366.0, 2579.0, 2293.5, 2005.5, 2488.0, 2362.0, 1976.0],width=5,\n    y=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n         \"services\", \"student\", \"technician\", \"unemployed\"],\n    name='Middle Balance',\n    marker=dict(\n        color='rgb(246, 179, 46)'\n    )\n)\ntrace4 = go.Bar(\n    x=[14247.5, 20138.5, 12278.5, 12956.0, 20723.0, 12159.0, 12223.0, 13107.0, 12063.0, 15107.5],width=5,\n    y=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n         \"services\", \"student\", \"technician\", \"unemployed\"],\n    name='High Balance',\n    marker=dict(\n        color='rgb(46, 246, 78)'\n    )\n)\n\n\ndata = [trace1, trace2, trace3, trace4]\n\n","c32ab351":"\nlayout = go.Layout(\n    title='Mean Balance in Account<br> <i> by Job Occupation<\/i>',\n    font=dict(\n        size=12\n    ),\n    legend=dict(\n        font=dict(\n            size=16\n        )\n    )\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='polar-area-chart')","423997fe":"df['marital'].value_counts()","c9ac9540":"vals = df['marital'].value_counts().tolist()\nlabels = ['married', 'divorced', 'single']\n\ndata = [go.Bar(\n            x=labels,\n            y=vals,\n    marker=dict(\n    color=\"#FE9A2E\")\n    )]\n\nlayout = go.Layout(\n    title=\"Count by Marital Status\",\n)\n\nfig = go.Figure(data=data, layout=layout)\n\n\n\niplot(fig, filename='basic-bar')","c345ccbd":"# Distribution of Balances by Marital status\nsingle = df['balance'].loc[df['marital'] == 'single'].values\nmarried = df['balance'].loc[df['marital'] == 'married'].values\ndivorced = df['balance'].loc[df['marital'] == 'divorced'].values\n\n\nsingle_dist = go.Histogram(\n    x=single,\n    \n    name='single',\n    marker=dict(\n        color='#6E6E6E'\n    )\n)\n\n\nmarried_dist = go.Histogram(\n    x=married,\n     \n    name='married',\n    marker=dict(\n        color='#2E9AFE'\n    )\n)\n\ndivorced_dist = go.Histogram(\n    x=divorced,\n     \n    name='divorced',\n    marker=dict(\n        color='#FA5858'\n    )\n)\n\n\nfig = tools.make_subplots(rows=3, print_grid=False)\n\nfig.append_trace(single_dist, 1, 1)\nfig.append_trace(married_dist, 2, 1)\nfig.append_trace(divorced_dist, 3, 1)\n\n\nfig['layout'].update(showlegend=True, title=\"Balance Distributions by Marital Status\",\n                    height=1000, width=800)\n\niplot(fig, filename='custom-sized-subplot-with-subplot-titles')","09b90858":"df.head()","151a9c91":"# Notice how divorced have a considerably low amount of balance.\nfig = ff.create_facet_grid(\n    df,\n    x='duration',\n    y='balance',\n    color_name='marital',\n    show_boxes=False,\n    marker={'size': 10, 'opacity': 1.0},\n    colormap={'single': 'rgb(165, 242, 242)', 'married': 'rgb(253, 174, 216)', 'divorced': 'rgba(201, 109, 59, 0.82)'}\n)\n\niplot(fig, filename='facet - custom colormap')","a412870e":"#Plotting Range of Income for marital Groups \n\nfig = ff.create_facet_grid(\n    df,\n    y='balance',\n    facet_row='marital',\n    facet_col='deposit',\n    trace_type='box',\n)\n\niplot(fig, filename='facet - box traces')","82cb2a52":"df.head()","68e517e3":"df = df.drop(df.loc[df[\"education\"] == \"unknown\"].index)\ndf['education'].unique()","21bbdd70":"df['marital\/education']=df['marital']+'\/'+df['education']   \ndf.head()","d3d269ad":"education_groups = df.groupby(['marital\/education'], as_index=False)['balance'].median()\neducation_groups.head()","af956f9b":"fig = plt.figure(figsize=(12,8))\n\nsns.barplot(x=\"balance\", y=\"marital\/education\", data=education_groups,\n            label=\"Total\", palette=\"RdBu\")\n\nplt.title('Median Balance by Educational\/Marital Group', fontsize=16)\nplt.show()","0d2cbbe3":"loan_balance = df.groupby(['marital\/education', 'loan'], as_index=False)['balance'].median()\n\nno_loan = loan_balance['balance'].loc[loan_balance['loan'] == 'no'].values\nhas_loan = loan_balance['balance'].loc[loan_balance['loan'] == 'yes'].values\n\nlabels = loan_balance['marital\/education'].unique().tolist()\n\ntrace0 = go.Scatter(\n    x=no_loan,\n    y=labels,\n    mode='markers',\n    name='No Loan',\n    marker=dict(\n        color='rgb(175,238,238)',\n        line=dict(\n            color='rgb(0,139,139)',\n            width=1,\n        ),\n        symbol='circle',\n        size=16,\n    )\n)\ntrace1 = go.Scatter(\n    x=has_loan,\n    y=labels,\n    mode='markers',\n    name='Has a Loan',\n    marker=dict(\n        color='rgb(250,128,114)',\n        line=dict(\n            color='rgb(178,34,34)',\n            width=1,\n        ),\n        symbol='circle',\n        size=16,\n    )\n)\n\ndata = [trace0, trace1]\n","0eba6727":"layout = go.Layout(\n    title=\"The Impact of Loans to Married\/Educational Clusters\",\n    xaxis=dict(\n        showgrid=False,\n        showline=True,\n        linecolor='rgb(102, 102, 102)',\n        titlefont=dict(\n            color='rgb(204, 204, 204)'\n        ),\n        tickfont=dict(\n            color='rgb(102, 102, 102)',\n        ),\n        showticklabels=False,\n        dtick=10,\n        ticks='outside',\n        tickcolor='rgb(102, 102, 102)',\n    ),\n    margin=dict(\n        l=140,\n        r=40,\n        b=50,\n        t=80\n    ),\n    legend=dict(\n        font=dict(\n            size=10,\n        ),\n        yanchor='middle',\n        xanchor='right',\n    ),\n    width=1000,\n    height=800,\n    paper_bgcolor='rgb(255,250,250)',\n    plot_bgcolor='rgb(255,255,255)',\n    hovermode='closest',\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='lowest-oecd-votes-cast')","91cb47e0":"df.head()","a2a663b3":"import seaborn as sns\nsns.set(style=\"ticks\")\n\nsns.pairplot(df, hue=\"marital\/education\", palette=\"Set1\")\nplt.show()","7194c883":"df.head()","4f2be92e":"plt.figure(figsize=(14,8))\nsns.heatmap(df.corr(), annot = True,cmap=\"OrRd\")\nplt.show()","cefe025a":"term_deposits=df.copy()\nterm_deposits.deposit.value_counts()","a542b0d2":"term_deposits.deposit=term_deposits.deposit.map({'yes':1,'no':0})\nterm_deposits.housing=term_deposits.housing.map({'yes':1,'no':0})\nterm_deposits.deposit.value_counts()","9aa1e1a1":"plt.figure(figsize=(14,8))\nsns.heatmap(term_deposits.corr(), annot = True,cmap=\"OrRd\")\nplt.show()","75acbabe":"dep = term_deposits['deposit']\nterm_deposits.drop(labels=['deposit'], axis=1,inplace=True)\nterm_deposits.insert(0, 'deposit', dep)\nterm_deposits.head()\n# housing has a -20% correlation with deposit let's see how it is distributed.\n# 52 %\nterm_deposits[\"housing\"].value_counts()\/len(term_deposits)","d857e98c":"df_new=pd.get_dummies(data1, drop_first=True)\ndf_new.head()\ndf_new.columns","7131e67a":"df_new.head()","3bc767d4":"df_new[\"loan_yes\"].value_counts()\/len(term_deposits)*100","4f5bae45":"from sklearn.model_selection import StratifiedShuffleSplit\n# Here we split the data into training and test sets and implement a stratified shuffle split.\nstratified = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=40)\n\nfor train_set, test_set in stratified.split(df_new, df_new[\"loan_yes\"]):\n    stratified_train = df_new.loc[train_set]\n    stratified_test = df_new.loc[test_set]\n    \nstratified_train[\"loan_yes\"].value_counts()\/len(stratified_train)","6d8bd7e6":"\nstratified_test[\"loan_yes\"].value_counts()\/len(stratified_test)","00a1b520":"\ntrain_data = stratified_train # Make a copy of the stratified training set.\ntest_data = stratified_test\nprint(train_data.shape)\nprint(test_data.shape)","54e0d9d2":"train_data['deposit_yes'].value_counts()","16d0ea81":"X_train=train_data.drop(['deposit_yes'], axis=1)\ny_train=train_data.deposit_yes\nX_test=test_data.drop('deposit_yes', axis=1)\ny_test=test_data.deposit_yes","410f2405":"numerical_columns = ['age','balance','day','duration','campaign','pdays','previous']\ntrain_data[numerical_columns].head()","5d7ea80d":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain_data[numerical_columns]=scaler.fit_transform(train_data[numerical_columns])\ntest_data[numerical_columns]=scaler.transform(test_data[numerical_columns])\ntrain_data[numerical_columns].head()","df82bd67":"from sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nbaselog_model = LogisticRegression()\nbaselog_model.fit(X_train,y_train)\ny_pred = baselog_model.predict(X_test)\nprint(accuracy_score(y_pred,y_test))\n","cdba641f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\ndict_of_algos={'LR':LogisticRegression(),'svc':SVC(),'KNC':KNeighborsClassifier(),'DT':tree.DecisionTreeClassifier(),'MLPc':MLPClassifier(),\n               'GRBC':GradientBoostingClassifier(),'RFC':RandomForestClassifier(),'GNB':GaussianNB()}","313ce4c2":"def accuracy_of_algos(dict_of_algos):\n    dict_of_accuracy={}\n    for k,v in dict_of_algos.items():\n        v.fit(X_train,y_train)\n        y_pred = v.predict(X_test)\n        dict_of_accuracy[k] = accuracy_score(y_pred,y_test)\n        y=v.score(X_train,y_train)\n    print(dict_of_accuracy)\n\nprint(accuracy_of_algos(dict_of_algos))  ","04e84745":"# Time for Classification Models\nimport time\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n\ndict_classifiers = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Nearest Neighbors\": KNeighborsClassifier(),\n    \"Linear SVM\": SVC(),\n    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n    \"Decision Tree\": tree.DecisionTreeClassifier(),\n    \"Random Forest\": RandomForestClassifier(n_estimators=18),\n    \"Neural Net\": MLPClassifier(alpha=1),\n    \"Naive Bayes\": GaussianNB()\n}","6e3dd49e":"\nno_classifiers = len(dict_classifiers.keys())\n\ndef batch_classify(X_train, Y_train,X_test, verbose = True):\n    df_results = pd.DataFrame(data=np.zeros(shape=(no_classifiers,4)), columns = ['classifier', 'train_score', 'training_time','test_score'])\n    count = 0\n    for key, classifier in dict_classifiers.items():\n        t_start = time.clock()\n        classifier.fit(X_train, Y_train)\n        t_end = time.clock()\n        t_diff = t_end - t_start\n        train_score = classifier.score(X_train, Y_train)\n        \n        y_pred=classifier.predict(X_test)\n        test_score=accuracy_score(y_test,y_pred)\n        \n        df_results.loc[count,'classifier'] = key\n        df_results.loc[count,'train_score'] = train_score\n        df_results.loc[count,'training_time'] = t_diff\n        df_results.loc[count,'test_score']=test_score\n        if verbose:\n            print(\"trained {c} in {f:.2f} s\".format(c=key, f=t_diff))\n        count+=1\n    return df_results","286ecb12":"df_results = batch_classify(X_train, y_train,X_test)\nprint(df_results.sort_values(by='train_score', ascending=False))","d98af274":"# Use Cross-validation.\nfrom sklearn.model_selection import cross_val_score\n\n# Logistic Regression\nlog_reg = LogisticRegression()\nlog_scores = cross_val_score(log_reg, X_train, y_train, cv=3)\nlog_reg_mean = log_scores.mean()\n\n# SVC\nsvc_clf = SVC()\nsvc_scores = cross_val_score(svc_clf, X_train, y_train, cv=3)\nsvc_mean = svc_scores.mean()\n\n# KNearestNeighbors\nknn_clf = KNeighborsClassifier()\nknn_scores = cross_val_score(knn_clf, X_train, y_train, cv=3)\nknn_mean = knn_scores.mean()\n\n# Decision Tree\ntree_clf = tree.DecisionTreeClassifier()\ntree_scores = cross_val_score(tree_clf, X_train, y_train, cv=3)\ntree_mean = tree_scores.mean()\n\n# Gradient Boosting Classifier\ngrad_clf = GradientBoostingClassifier()\ngrad_scores = cross_val_score(grad_clf, X_train, y_train, cv=3)\ngrad_mean = grad_scores.mean()\n\n# Random Forest Classifier\nrand_clf = RandomForestClassifier(n_estimators=18)\nrand_scores = cross_val_score(rand_clf, X_train, y_train, cv=3)\nrand_mean = rand_scores.mean()\n\n# NeuralNet Classifier\nneural_clf = MLPClassifier(alpha=1)\nneural_scores = cross_val_score(neural_clf, X_train, y_train, cv=3)\nneural_mean = neural_scores.mean()\n\n# Naives Bayes\nnav_clf = GaussianNB()\nnav_scores = cross_val_score(nav_clf, X_train, y_train, cv=3)\nnav_mean = nav_scores.mean()\n\n# Create a Dataframe with the results.\nd = {'Classifiers': ['Logistic Reg.', 'SVC', 'KNN', 'Dec Tree', 'Grad B CLF', 'Rand FC', 'Neural Classifier', 'Naives Bayes'], \n    'Crossval Mean Scores': [log_reg_mean, svc_mean, knn_mean, tree_mean, grad_mean, rand_mean, neural_mean, nav_mean]}\n\nresult_df = pd.DataFrame(data=d)","f96cbc36":"# All our models perform well but I will go with GradientBoosting.\nresult_df = result_df.sort_values(by=['Crossval Mean Scores'], ascending=False)\nresult_df","9266976a":"from sklearn.metrics import accuracy_score\n\ngrad_clf = GradientBoostingClassifier()\ngrad_clf.fit(X_train, y_train)","e746c0ff":"y_pred=grad_clf.predict(X_test)\nprint (\"Gradient Boost Classifier Train accuracy is %2.2f\" % accuracy_score(y_test, y_pred))\n","686a4bb3":"accuracy_score(y_test, y_pred)","e918649d":"y_test.value_counts()","33485440":"from sklearn.metrics import confusion_matrix\n# 4697: no's, 4232: yes\nconf_matrix = confusion_matrix(y_test, y_pred)\nf, ax = plt.subplots(figsize=(10, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', linewidths=.5, ax=ax)\nplt.title(\"Confusion Matrix\", fontsize=20)\nplt.subplots_adjust(left=0.15, right=0.99, bottom=0.15, top=0.99)\nax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=False)\nax.set_xticklabels([\"Predicted False Deposits\",'Predicted True Deposits'])\nax.set_yticklabels(['Actual False Deposits', 'Actual Deposits'], fontsize=16, rotation=360)\nplt.show()\n","6337749e":"# Let's find the scores  for precision and recall.\nfrom sklearn.metrics import precision_score, recall_score\n\n# The model is only retaining 60% of clients that agree to suscribe a term deposit.\nprint('The model is {c} % sure that the potential client will subscribe to a term deposit'.format(c=np.round(precision_score(y_test, y_pred),2)*100))\nprint('The model is retaining {c} % of clients that agree to subscribe a term deposit'.format(c=np.round(recall_score(y_test, y_pred),2)*100))\n","e148f772":"from sklearn.metrics import f1_score\n\nf1_score(y_test, y_pred)*100","4d1cdcc5":"from sklearn.metrics import precision_recall_curve\nplt.figure(figsize=(14,8))\ny_prob=grad_clf.predict_proba(X_test)[:,1]\nprecisions, recalls, threshold = precision_recall_curve(y_test, y_prob)\nplt.plot(threshold,recalls[:-1],marker='.',label='recall')\nplt.plot(threshold,precisions[:-1],marker='.',label='precision')\nplt.legend(frameon=True,fontsize=20)\nplt.axvline(x=0.563,c='black')\n\nplt.show()","f09437a0":"from sklearn.metrics import roc_curve\ngrd_fpr, grd_tpr, threshold = roc_curve(y_test, y_prob)\n","590dbeda":"def graph_roc_curve(false_positive_rate, true_positive_rate, label=None):\n    plt.figure(figsize=(10,6))\n    plt.title('ROC Curve \\n Gradient Boosting Classifier', fontsize=18)\n    plt.plot(false_positive_rate, true_positive_rate, label=label)\n    plt.plot([0, 1], [0, 1], '#0C8EE0')\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.annotate('ROC Score of 91.73% \\n ', xy=(0.25, 0.9), xytext=(0.4, 0.85),\n            arrowprops=dict(facecolor='#F75118', shrink=0.05),\n            )\n    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n                arrowprops=dict(facecolor='#F75118', shrink=0.05),\n                )\n    \n    \ngraph_roc_curve(grd_fpr, grd_tpr, threshold)\nplt.show()","c98550ef":"from sklearn.metrics import roc_auc_score\n\nprint('Gradient Boost Classifier Score: ', roc_auc_score(y_test, y_prob))\n","0426ae69":"# Our three classifiers are grad_clf, nav_clf and neural_clf\nfrom sklearn.ensemble import VotingClassifier\n\nvoting_clf = VotingClassifier(\n    estimators=[('gbc', grad_clf), ('nav', nav_clf), ('neural', neural_clf)],\n    voting='hard'\n)\n\nvoting_clf.fit(X_train, y_train)\ny_pred=voting_clf.predict(X_test)\nprint(accuracy_score(y_test,y_pred))","2fce1b81":"from sklearn.model_selection import GridSearchCV\n\nparam_test3 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1000,2000), 'min_samples_leaf':range(30,71,10),'n_estimators':range(20,81,10)}\ngsearch = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n                                                               max_features='sqrt', subsample=0.8, random_state=10),\n                        param_grid = param_test3, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n\ngsearch.fit(X_train,y_train)\ngsearch.best_params_, gsearch.best_score_","85320d72":"## Correlation Matrix","b8543b9f":"<a id = 'accepted_rejected'><\/a>","3b5c866a":"### First Distribution of Age of customers with respect to Occupation","ba0eb1cb":"### Let's see how the numerical data is distributed.","746868b3":"<a id=\"analysis_correlation\"> <\/a>","4391a059":"<h3>Clustering Marital Status and Education: <\/h3>\n\n<ul> \n    <li><b>Marital Status: <\/b>  As discussed previously, the impact of a divorce has a significant impact on the balance of the individual. <\/li>\n    <li><b>Education: <\/b> The level of education also has a significant impact on the amount of balance a prospect has.<\/li>\n    <li><b> Loans: <\/b> Whether the prospect has a previous loan has a significant impact on the amount of balance he or she has. <\/li>\n<\/ul>","48337ff6":"<h3> Marital Status <\/h3>\nWell in this analysis we found out that most <b> \ndivorced individuals <\/b> are broke. No wonder since they have to split financial assets! Nevertheless, since no further insights have been found we will proceed to clustering marital status with education status. Let's see if we can find other groups of people in the sample population.","b6db2c18":"\n<h3> Exploring the Basics <\/h3>\n<a id=\"overall_analysis\"><\/a>\n## Summary:\n***\n<ul>\n<li type=\"square\"> <b>Mean Age<\/b> is aproximately 41 years old. (Minimum: 18 years old and Maximum: 95 years old.)<\/li><br>\n<li type=\"square\"> The <b>mean balance<\/b> is 1,528. However, the Standard Deviation (std) is a high number so we can understand through this that the balance is heavily distributed across the dataset.<\/li><br>\n<li type=\"square\">As the data information said it will be better to drop the duration column since duration is highly correlated in whether a potential client will buy a term deposit. Also, <b>duration is obtained after the call is made to the potential client<\/b> so if the target client has never received calls this feature is not that useful. The reason why duration is highly correlated with opening a term deposit  is because the more the bank talks to a target client the higher the probability the target client will open a term deposit since a higher duration means a higher interest (commitment) from the potential client. <\/li><br>\n<\/ul>\n\n**Note: There are not that much insights we can gain from the descriptive dataset since most of our descriptive data is located not in the \"numeric\" columns but in the \"categorical columns\".**\n","3f88e023":"### Parameter Optimization for Gradient Boosting Classifier","1f16c402":"### Now let's see which occupation tended to have more balance in their accounts","20801a14":"# Outline Index: <br>\n***\nA. **Attribute Descriptions**<br>\nI. *[Bank client data](#bank_client_data)<br>\nII. *[Related with the last contact of the current campaign](#last_contact)<br>\nIII. [Other attributes](#other_attributes) <br>\n\nB. **Structuring the data:** <br>\nI. *[Overall Analysis of the Data](#overall_analysis)<br>\nII. *[Data Structuring and Conversions](#data_structuring) <br>\n\nC. **Exploratory Data Analysis (EDA)**<br>\nI. *[Accepted vs Rejected Term Deposits](#accepted_rejected) <br>\nII. *[Distribution Plots](#distribution_plots) <br>\n\n\n\nE. **Correlations that impacted the decision of Potential Clients.** <br>\nI. *[Analysis of our Correlation Matrix](#analysis_correlation) <br>\nII. [Negative Relationship between H.Loans and Term Deposits](#negative_correlation) <br>\n\nF. ** Classification Model **<br>\nI. [Introduction](#classification_model)<br> \nII. [Stratified Sampling](#Stratified_sampling)<br>\nIII. [Classification Models](#Models)<br>\nIV. [Confusion Matrix](#confusion)<br>\nV. [Precision and Recall Curve](#precision_recall)<br>\nVI. [Roc_auc_curve](#roc_auc) <br>\nVII. [Parameter Optimization](#parameter_optimization)<br>\n\nG. ** Next Campaign Strategy**<br>\nI. [Actions the Bank should Consider](#bank_actions)<br>\n\n# A. Attributes Description: <br>\n\nInput variables:<br>\n# Ai. bank client data:<br>\n<a id=\"bank_client_data\"><\/a>\n1 - **age:** (numeric)<br>\n2 - **job:** type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')<br>\n3 - **marital:** marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)<br>\n4 - **education:** (categorical: primary, secondary, tertiary and unknown)<br>\n5 - **default:** has credit in default? (categorical: 'no','yes','unknown')<br>\n6 - **housing:** has housing loan? (categorical: 'no','yes','unknown')<br>\n7 - **loan:** has personal loan? (categorical: 'no','yes','unknown')<br>\n8 - **balance:** Balance of the individual.\n# Aii. Related with the last contact of the current campaign:\n<a id=\"last_contact\"><\/a>\n8 - **contact:** contact communication type (categorical: 'cellular','telephone') <br>\n9 - **month:** last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')<br>\n10 - **day:** last contact day of the week (categorical: 'mon','tue','wed','thu','fri')<br>\n11 - **duration:** last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.<br>\n# Aiii. other attributes:<br>\n<a id=\"other_attributes\"><\/a>\n12 - **campaign:** number of contacts performed during this campaign and for this client (numeric, includes last contact)<br>\n13 - **pdays:** number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)<br>\n14 - **previous:** number of contacts performed before this campaign and for this client (numeric)<br>\n15 - **poutcome:** outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')<br>\n\nOutput variable (desired target):<br>\n21 - **y** - has the client subscribed a term deposit? (binary: 'yes','no')","2de0a9f6":" # Analysis of data by Occupation","54994ba2":"## So we are able to predict values in test Data with `84.4%` Accuracy","adec173c":"## Dummy Variable Creation for Data with Categorical Values","023538ed":"### Let's see the group who had loans from the marital\/education group","de4479de":"<a id='precision_recall'><\/a>","f07e8115":"## The Probablity threshold for Balanced value of Precision vs Recall is `0.563`","12e9bb4d":"### Avoiding Overfitting:\nBrief Description of Overfitting<br>\nThis is an error in the modeling algorithm that takes into consideration random noise in the fitting process rather than the pattern itself. You can see that this occurs when the model gets an awsome score in the training set but when we use the test set (Unknown data for the model) we get an awful score. This is likely to happen because of overfitting of the data (taking into consideration random noise in our pattern). What we want our model to do is to take the overall pattern of the data in order to correctly classify whether a potential client will suscribe to a term deposit or not. In the examples above, it is most likely that the Decision Tree Classifier and Random Forest classifiers are overfitting since they both give us nearly perfect scores (100% and 99%) accuracy scores. <br><br>\n\n\nHow can we avoid Overfitting?<br>\nThe best alternative to avoid overfitting is to use cross validation. Taking the training test and splitting it. For instance, if we split it by 3, 2\/3 of the data or 66% will be used for training and 1\/3 33% will be used or testing and we will do the testing process three times. This algorithm will iterate through all the training and test sets and the main purpose of this is to grab the overall pattern of the data.","246238e0":"## Let's Analyze the data with respect to the Customer's Marital Status","ea6ba600":"## Scaling Numerical Features to a common scale\nSince Numerical Coulumns are on Different Scales and may impact our Prediction","343ecaa5":"# Bank Marketing DataSet - Intelligent Targeting:\n***\n## Marketing Introduction:\n*The process by which companies create value for customers and build strong customer relationships in order to capture value from customers in return.*\n\n***\n\n**Marketing campaigns** are characterized by  focusing on the customer needs and their overall satisfaction. Nevertheless, there are different variables that determine whether a marketing campaign will be successful or not. There are certain variables that we need to take into consideration when making a marketing campaign. <br>\n\n## The 4 Ps:\n1) Segment of the <b>Population:<\/b> To which segment of the population is the marketing campaign going to address and why? This aspect of the marketing campaign is extremely important since it will tell to which part of the population should most likely receive the message of the marketing campaign. <br><br>\n2) Distribution channel to reach the customer's <b>place<\/b>: Implementing the most effective strategy in order to get the most out of this marketing campaign. What segment of the population should we address? Which instrument should we use to get our message out? (Ex: Telephones, Radio, TV, Social Media Etc.)<br><br>\n3) <b> Price:<\/b> What is the best price to offer to potential clients? (In the case of the bank's marketing campaign this is not necessary since the main interest for the bank is for potential clients to open depost accounts in order to make the operative activities of the bank to keep on running.)<br><br>\n4) <b> Promotional<\/b> Strategy: This is the way the strategy  is going to be implemented and how are potential clients going to be address. This should be the last part of the marketing campaign analysis since there has to be an indepth analysis of previous campaigns (If possible) in order to learn from previous mistakes and to determine how to make the marketing campaign much more effective.","ea0596ea":"# ROC Curve (Receiver Operating Characteristic):\nThe **ROC curve** tells us how well our classifier is classifying between term deposit suscriptions (True Positives) and non-term deposit suscriptions. The **X-axis** is represented by False positive rates (Specificity) and the **Y-axis** is represented by the True Positive Rate (Sensitivity.) As the line moves the threshold of the classification changes giving us different values. The closer is the line to our top left corner the better is our model separating both classes.\n","5acafc97":"<a id ='Models'><\/a>","4b1da569":"<a id='roc_auc'><\/a>","d98bf270":"\n## Final Model using Gradient boosting Algorithm","e78d82f6":"<a id='parameter_optimization'><\/a>","0c04c24f":"# Confusion Matrix: \n<a id=\"confusion\"><\/a>\n<img src=\"https:\/\/computersciencesource.files.wordpress.com\/2010\/01\/conmat.png\">\n\n## Insights of a Confusion Matrix: \nThe main purpose of a confusion matrix is to see how our model is performing when it comes to classifying potential clients that are likely to suscribe to a term deposit. We will see in the confusion matrix four terms the True Positives, False Positives, True Negatives and False Negatives.<br><br>\n\n**Positive\/Negative:** Type of Class (label) [\"No\", \"Yes\"]\n**True\/False:** Correctly or Incorrectly classified by the model.<br><br>\n\n**True Negatives (Top-Left Square):** This is the number of **correctly** classifications of the \"No\" class or potenial clients that are **not willing** to suscribe a term deposit. <br><br>\n\n**False Negatives (Top-Right Square):** This is the number of **incorrectly** classifications of the \"No\" class or potential clients that are **not willing** to suscribe a term depositt. <br><br>\n\n**False Positives (Bottom-Left Square):** This is the number of **incorrectly** classifications of the \"Yes\" class or potential clients that are **willing** to suscribe a term deposit. <br><br>\n\n**True Positives (Bottom-Right Square):** This is the number of **correctly** classifications of the \"Yes\" class or potenial clients that are **willing** to suscribe a term deposit.","22d0383f":"### In order to maintain the Same Ratio in our Train and Test set we will use stratified Sampling technique","d1bb5aae":"## Count of Yes vs No in Deposit Columns","f692c435":"<h3> Analysis by Occupation criteria: <\/h3>\n<ul> \n    <li> <b> Number of Occupations: <\/b>  Management is the occupation that is more prevalent in this dataset.<\/li>\n    <li><b>Age by Occupation: <\/b>  As expected, the retired are the ones who have the highest median age while student are the lowest.<\/li>\n    <li><b> Balance by Occupation: <\/b> Management and Retirees are the ones who have the highest balance in their accounts. <\/li>\n    <\/ul>","e2f56cc6":"<h2> <b>Classification Model:<\/b> <\/h2>","9c95017e":"<a id='Stratified_sampling'><\/a>","754d2ca9":"### Let's Create A baseline model for Benchmarking\n<a id='classification_model'><\/a>","d7e9443e":"### Let's Plot the Data\nSelect Area to zoom in using Mouse Cursor","74433fbc":"### Let's Combine the Education Level with Marital Status and Analyze","904bc2f9":"<a id ='negative_correlation'><\/a>","497c034b":"# What is a Term Deposit? \nA **Term deposit** is a deposit that a bank or a financial institurion offers with a fixed rate (often better than just opening deposit account) in which your money will be returned back at a specific maturity time. For more information with regards to Term Deposits please click on this link from Investopedia:  https:\/\/www.investopedia.com\/terms\/t\/termdeposit.asp","1f0d1c3a":"### Which Features Influence the Result of a Term Deposit Suscription?\n### \n<a id=\"decision\"><\/a>\nThe top three most important features for our classifier are **Duration (how long it took the conversation between the sales representative and the potential client), contact (number of contacts to the potential client within the same marketing campaign), month (the month of the year).\n\n\n","6d08493e":"### Separate the labels(y) and the features(X)","a5caa9a4":"Fortunately, there are no <b>missing values<\/b>. If there were missing values we will have to fill them with the median, mean or mode. I tend to use the median but in this scenario there is no need to fill any missing values. This will definitely make our job easier!","0d369299":"## GradientBoosting Classifier Wins!\nGradient Boosting classifier is the best model to predict whether or not a **potential client** will suscribe to a term deposit or not.  84% accuracy!","5c63ae2b":"<a id='distribution_plots'><\/a>","f92f41c2":"<a id=\"data_structuring\"><\/a>","b8071a98":"# What Actions should the Bank Consider?\n<a id=\"bank_actions\"><\/a>\n\n\n\n## Suggestions and Conclusions for the Next Marketing Campaign:\n1) **Term Deposit Prediction**: Our Model predicts with 84.6% Accuracy for new customers based on Data that whether he is going to opne a Term Deposit or Not. <br><br>\n2) **Seasonality:** Potential clients opted to suscribe term deposits during the seasons of **fall** and **winter**. The next marketing campaign should focus its activity throghout these seasons. <br><br>\n3) **Campaign Calls:** A policy should be implemented that states that no more than 3 calls should be applied to the same potential client in order to save time and effort in getting new potential clients. Remember, the more we call the same potential client, the likely he or she will decline to open a term deposit. <br><br>\n4) **Age Category:** The next marketing campaign of the bank should target potential clients in their 20s or younger and 60s or older. The youngest category had a 60% chance of suscribing to a term deposit while the eldest category had a 76% chance of suscribing to a term deposit. It will be great if for the next campaign the bank addressed these two categories and therefore, increase the likelihood of more term deposits suscriptions. <br><br>\n5) **Occupation:** Not surprisingly, potential clients that were students or retired were the most likely to suscribe to a term deposit. Retired individuals, tend to have more term deposits in order to gain some cash through interest payments. Remember, term deposits are short-term loans in which the individual (in this case the retired person) agrees not to withdraw the cash from the bank until a certain date agreed between the individual and the financial institution. After that time the individual gets its capital back and its interest made on the loan. Retired individuals tend to not spend bigly its cash so they are morelikely to put their cash to work by lending it to the financial institution. Students were the other group that used to suscribe term deposits.<br><br>\n6) **House Loans and Balances:** Potential clients in the low balance and no balance category were more likely to have a house loan than people in the average and high balance category. What does it mean to have a house loan? This means that the potential client has financial compromises to pay back its house loan and thus, there is no cash for he or she to suscribe to a term deposit account. However, we see that potential clients in the average and hih balances are less likely to have a house loan and therefore, more likely to open a term deposit. Lastly, the next marketing campaign should focus on individuals of average and high balances in order to increase the likelihood of suscribing to a term deposit. <br><br>\n\n7) **Develop a Questionaire during the Calls:** Since duration of the call is the feature that most positively correlates with whether a potential client will open a term deposit or not, by providing an interesting questionaire for potential clients during the calls the conversation length might increase. Of course, this does not assure us that the potential client will suscribe to a term deposit! Nevertheless, we don't loose anything by implementing a strategy that will increase the level of engagement of the potential client leading to an increase probability of suscribing to a term deposit, and therefore an increase in effectiveness for the next marketing campaign the bank will excecute. <br><br>\n\nBy combining all these strategies and simplifying the market audience the next campaign should address, it is likely that the next marketing campaign of the bank will be more effective than the current one.\n\n\n\n\n","a13907d7":"### Using advanced Classification Algos for prediction and Comparing their Accuracy"}}