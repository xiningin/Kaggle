{"cell_type":{"ba562b58":"code","09266378":"code","72f08b78":"code","112c6064":"code","03f40e24":"markdown","ae9bc876":"markdown","38a2205c":"markdown","b45c7ea1":"markdown","d771d3e9":"markdown","73edffb4":"markdown","67ec4e07":"markdown","f845bc4a":"markdown","5b882ec8":"markdown","55f029e7":"markdown"},"source":{"ba562b58":"import os\nimport logging\nimport requests\nimport numpy as np\nimport pandas as pd\nfrom requests.exceptions import HTTPError, ConnectionError\nimport json\n\nlogging.getLogger()\nlogging.basicConfig(level=logging.DEBUG)\n\n'''\nGenerate paras, image text, image\/text OCR text\n'''\nclass DataPuller():\n    def __init__(self, input_dir, metadata_path):\n        self.input_dir = input_dir\n        self.metadata_path = metadata_path\n        self.paper_details_df = None\n\n    def load(self):\n        '''\n        Loads all the data and\n        flattens the data structure by joining metadata with paragraphs\n        Drops papers without full text. # TODO\n        '''        \n        metadata = pd.read_csv(self.metadata_path)\n        \n        # read paper details\n        paper_texts = []\n        for (dirpath, dirnames, filenames) in os.walk(self.input_dir):\n            for file in filenames:\n                if(file.endswith(\".json\")):\n                    with open(os.path.join(dirpath, file), 'r') as f:\n                        paper_texts.append(json.loads(f.read()))\n        \n        # merge paper details with metadata\n        paper_details_df = pd.DataFrame.from_records(paper_texts)\n        paper_details_df = paper_details_df.drop(labels=['abstract'], axis=1)\n        logging.info(\"Loaded paper details for {} papers\".format(len(paper_details_df)))\n        metadata['paper_id'] = metadata['sha']\n        paper_details_df = paper_details_df.merge(metadata, on='paper_id', how='left')\n        paper_details_df = paper_details_df[paper_details_df['title'].notna()]\n        self.paper_details_df = paper_details_df.reset_index()\n        logging.info(\"Successfully merged paper details with metadata . Total records after merging {}\".format(len(self.paper_details_df)))\n\n        records = []\n        count = 0  \n        # Get all abstract first\n        for i in metadata.index:            \n            row = metadata.iloc[i]\n            records.append(self.get_record(row=row, \n                                        idx=count, \n                                        doc=row['abstract'],\n                                        doc_type='abstract'))\n        \n            count += 1\n        logging.info(\"Loaded abstract for {} papers\".format(count))\n        for i in self.paper_details_df.index:            \n            row = self.paper_details_df.iloc[i]\n            \n            for para in row['body_text']:\n                records.append(self.get_record(row=row, \n                                                idx=count, \n                                                doc=para['text'],\n                                                doc_type='para'))\n                count += 1    \n\n            for k, fig in row['ref_entries'].items():\n                records.append(self.get_record(row=row, \n                                                idx=count, \n                                                doc=fig['text'],\n                                                doc_type='caption'))\n                count += 1\n\n        docs_df = pd.DataFrame.from_records(records)\n        logging.info(\"Data puller total records : {}\".format(len(docs_df)))\n        docs_df = docs_df.drop_duplicates(subset='id')\n        logging.info(\"Data puller total records after dropping dupes : {}\".format(len(docs_df)))\n        return docs_df\n\n    def get_record(self, row, idx, doc, doc_type):\n        return {\n            'id': str(row['paper_id']) + '_' + str(idx),\n            'paper_id': row['paper_id'],\n            'paper_title': row['title'],\n            'display_text': doc,\n            'text': str(row['title']) + ' . ' + str(doc),\n            'doc_type': doc_type,\n            'link': row['url'],\n            'date': row['publish_time'],\n            'authors': row['authors'],\n            'journal': row['journal']\n        }","09266378":"# Format:\n# {\n# 'id': <str>,\n# 'paper_id': <str>,\n# 'paper_title': <str>,\n# 'display_text': <str>,\n# 'text': <str>,\n# 'doc_type': <str>, #['abstract', 'para', 'caption']\n# 'link': <str>,\n# 'date': <str>,\n# 'authors': <str>,\n# 'journal': <str>\n# }","72f08b78":"from urllib.request import urlopen\nfrom IPython.display import IFrame\nfrom urllib.parse import quote\n\ndef query_to_url(query):\n    return \"https:\/\/sfr-med.com\/search?q=\" + quote(query + \" COVID -19\")\n\n\ndef render_url(url):\n    html = urlopen(url).read()\n    html = html.decode(\"utf-8\")\n\n    # Eliminate header and search bar\n    html = html.split(\"<div class=\\\"slds-col slds-large-size_2-of-12\\\">\")[0] + html.split(\"<\/form>\")[1]\n    \n    filename = \".\/tmp.html\"\n    open(filename, \"w\").write(html)\n    return IFrame(src=filename, width=1300, height=600)\n\n\ndef display_query(query):\n    try:\n        url = query_to_url(query)\n        display(render_url(url))\n    except:\n        print(\"Error rendering...\")\n\n        \nqueries = \"\"\"\n - What is the range of incubation periods for COVID-19 in humans?\n - What is the prevalence of asymptomatic shedding and transmission?\n - What is the prevalence of asymptomatic shedding and transmission in children?\n - Seasonality of transmission.\n - How long are individuals contagious?\n - Physical science of the coronavirus (e.g., charge distribution, adhesion to hydrophilic\/phobic surfaces, environmental survival to inform decontamination efforts for affected areas and provide information about viral shedding).\n - Persistence and stability on a multitude of substrates and sources (e.g., nasal discharge, sputum, urine, fecal matter, blood).\n - Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).\n - Natural history of the virus and shedding of it from an infected person\n - Implementation of diagnostics and products to improve clinical processes\n - Disease models, including animal models for infection, disease and transmission\n - Tools and studies to monitor phenotypic change and potential adaptation of the virus\n - Immune response and immunity\n - Effectiveness of movement control strategies to prevent secondary transmission in health care and community settings\n - Effectiveness of personal protective equipment (PPE) and its usefulness to reduce risk of transmission in health care and community settings\n - Role of the environment in transmission\n\"\"\".strip().split(\"\\n\")","112c6064":"import time\nfor query in queries[:1]:\n    query = query.strip()\n    print(query)\n    display_query(query)\n    time.sleep(0.5)","03f40e24":"## Authors (in no particular order): \n - Andre Esteva, AndreEstevaSFDC, aesteva@salesforce.com\n - Anuprit Kale, AnupritK, akale@salesforce.com\n - Dragomir Radev, dragomirradev, dradev@salesforce.com\n - Kazuma Hashimoto, kazumahashimoto, k.hashimoto@salesforce.com\n - Wenpeng Yin, wyin@salesforce.com\n - Romain Paulus, romainfpaulus, rpaulus@salesforce.com\n - Richard Socher, richards, rsocher@salesforce.com","ae9bc876":"# What is known about transmission, incubation, and environmental stability?\n","38a2205c":"## System Components\nIn the subsections below we describe the key AI components of the system - the data puller, retrieval component, question answering component, and paragraph ranker.\n\n\n### Data Puller\nThe code in this section defines the classes needed for data pulling","b45c7ea1":"\n### Step 2: Question-answering \n\nNext, we take the retrieved documents, along with the text query, and run them through a question answering engine which returns a set of text answers. The system's final output is then the retrieved paragraphs with the text answers potentially highlighted, along with the document titles.\n\n![image.png](attachment:image.png)","d771d3e9":"## Search Engine Architecture\n\nThe system is composed of two steps, below, along with a series of sub-modules.\n\n### Step 1. Document Retrieval\nFirst, we parse and vectorize the existing scientific literature into a document index, and retrieve documents from this index given a text query from the user. \n\nWe  take the given Kaggle text corpus - the scientific articles, their paragraphs, image captions, and other components - and feed each into a TF-IDF vectorizer, which stores the resultant vectors into a document index. \n\nWhen a text query comes in from a user, we then apply the same TF-IDF vectorizer on the query to obtain a query vector. Using k-nearest-neighbors retrieval, we return the top-N similar *paragraph* vectors from the document index. We then rank these based on relevance, citation count, and recency to obtain a sorted list of the N most relevant paragraphs (and their corresponding documents) to a given query.\n\n![image.png](attachment:image.png)\n\n","73edffb4":"**Example of retrieved data in json format**","67ec4e07":"# Task Description\n\nGiven the increasing number of scientific publications on COVID-19 and related topics, a semantic search engine capable of extracting relevant publications for complex questions and queries has the potential to decrease the difficulty of finding the right information in a timely and up-to-date fashion. Here we present a system architecture for semantic search across the provided COVID-19 publications, and show the output for some of the task-specific subqueries provided. \n\nFor brevity, we do not include all of our code, given that it is designed to run on a web application. More below.","f845bc4a":"# Results\n\nIn the cells below, we sequentially run a few of the provided task queries (below) through our system.\n\n**Task Details**<br>\nWhat is known about transmission, incubation, and environmental stability? What do we know about natural history, transmission, and diagnostics for the virus? What have we learned about infection prevention and control?\n\n**System queries:**\n - What is the range of incubation periods for COVID-19 in humans?\n - How long are individuals contagious?\n - What is the prevalence of asymptomatic shedding and transmission?\n - What is the prevalence of asymptomatic shedding and transmission in children?\n - Seasonality of transmission.\n - Physical science of the coronavirus (e.g., charge distribution, adhesion to hydrophilic\/phobic surfaces, environmental survival to inform decontamination efforts for affected areas and provide information about viral shedding).\n - Persistence and stability on a multitude of substrates and sources (e.g., nasal discharge, sputum, urine, fecal matter, blood).\n - Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).\n - Natural history of the virus and shedding of it from an infected person\n - Implementation of diagnostics and products to improve clinical processes\n - Disease models, including animal models for infection, disease and transmission\n - Tools and studies to monitor phenotypic change and potential adaptation of the virus\n - Immune response and immunity\n - Effectiveness of movement control strategies to prevent secondary transmission in health care and community settings\n - Effectiveness of personal protective equipment (PPE) and its usefulness to reduce risk of transmission in health care and community settings\n - Role of the environment in transmission\n","5b882ec8":"### TF-IDF & Retrieval\nOur text retrieval system and QA engine follows our recent work on open-domain QA over Wikipedia [(Asai et al., 2020)](https:\/\/arxiv.org\/abs\/1911.10470). Like Wikipedia articles, we first split all the biomedical research papers in our database into abstract and paragraphs, and build a TF-IDF retrieval model following [DrQA](https:\/\/github.com\/facebookresearch\/DrQA). We have two options for the term-based retrieval step, either direct paragraph-level retrieval or hierarchical retrieval (first, article-level retrieval, and then paragraph-level re-ranking, as in [Asai et al. (2020)](https:\/\/arxiv.org\/abs\/1911.10470)). We employed the former option as our first version. By either of the options, the term-based retrieval system returns top-N paragraphs, given an input query. The term-based retrieval system can be replaced with other search engines on demand.\n\n### Question-Answering and Paragraph Ranking\nOur system then uses the sequential paragraph selector model proposed in [Asai et al. (2020)](https:\/\/arxiv.org\/abs\/1911.10470). The official code and trained models are available on [Github](https:\/\/github.com\/AkariAsai\/learning_to_retrieve_reasoning_paths). The objective of this step is to further verify which paragraphs are more relevant to provide answers for each query. Instead of separately giving a relevance score for each of the top-N paragraphs, the sequential paragraph selector model can select sets of a few paragraphs by modeling relationships between them (i.e. using so-called \"multi-hop\" reasoning).\n\nIn that paper, all the experiments were conducted on Wikipedia-oriented datasets (HotpotQA, SQuAD, Natural Questions), but our target documents come from biomedical research articles. (For more details about the datasets, please refer to the paper.) To fill the gap, we further fine-tuned the HotpotQA-based model with the [PubMedQA dataset](https:\/\/github.com\/pubmedqa\/pubmedqa). Each training example in the PubMedQA dataset can be considered as a set of a question and its related paragraphs, and we assume the related paragraphs are the ground-truth paragraphs to be selected for the question. To train the sequential paragraph selector model, we also need negative examples, and we follow [Asai et al. (2020)](https:\/\/arxiv.org\/abs\/1911.10470) to use paragraphs with the highest TF-IDF scores given the question. We modified the original beam search, so that different paths in the beam search can include more diverse paragraphs to avoid extracting the same answers from different paths.\n\nFinally, the selected sets (or paths) of the paragraphs are fed into an extractive reading comprehension model based on [Asai et al. (2020)](https:\/\/arxiv.org\/abs\/1911.10470). There are three models for the three datasets, HotpotQA, SQuAD, and Natural Questions, and we observed that the SQuAD-based model matches our demand for the COVID-19 project, based on the question types covered by the different datasets. (It is worth trying to further fine-tune the models with biomedical extractive QA datasets.)\n\nUnlike working on the benchmark QA datasets, there are no ground-truth answers in the real-world application, and we do not need to output the best hypothesis from the model. Therefore our system highlights multiple answer candidates (text spans) extracted from the selected paragraphs, so that the users can decide which is more useful.","55f029e7":"# Search Engine\n\nThe running application can be found at https:\/\/sfr-med.com\/search\n\n![search_engine_front_end.png](attachment:search_engine_front_end.png)"}}