{"cell_type":{"8c5194ed":"code","b5db46ff":"code","096d8db8":"code","e1af89d6":"code","1afd373e":"code","af0d7477":"code","a775a9bc":"code","f0c830af":"code","394c136b":"code","512f3301":"code","8c101faf":"code","59048d28":"code","dbb05d0c":"code","0b7235b3":"code","b87c3838":"code","d728b377":"code","5b56beaf":"markdown","145a84a4":"markdown","497c2a2b":"markdown","9cc915c7":"markdown","bf2f0ad4":"markdown","79ec1e07":"markdown","aa874698":"markdown","4d745ab0":"markdown","c03380e4":"markdown","b8f3cf9c":"markdown","da0da49d":"markdown","b6eea0e9":"markdown","b73d4f1b":"markdown"},"source":{"8c5194ed":"import matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\nimport torch\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","b5db46ff":"df = pd.read_csv('..\/input\/Advertising.csv')\ndf.info()","096d8db8":"# removing the inbuilt index column\ndf.drop('Unnamed: 0', axis = 1, inplace=True)\ndf.head()","e1af89d6":"sns.pairplot(df)\nplt.show()","1afd373e":"x = df.drop('Sales', axis =1).values\ny = df[['Sales']].values","af0d7477":"# n = 200, d = 3\nprint(x.shape)\nprint(y.shape)","a775a9bc":"# Converting the numpy array features to pytorch tensors. \ninputs = torch.from_numpy(x)\ntargets = torch.from_numpy(y)","f0c830af":"print(inputs.shape)\nprint(targets.shape)","394c136b":"w = torch.randn(1,3, requires_grad=True, dtype = torch.double)\nb = torch.randn(1, requires_grad=True,  dtype = torch.double)\nprint(w,b)","512f3301":"'''Function to apply y = X.WT + b'''\ndef model(x):\n    return torch.mm(x, w.t()) + b\n\n'''Function to find the mean squared error between predicted and actual labels.  '''\n\ndef mse(t1, t2):\n    diff = t1-t2\n    return torch.sum(diff*diff)\/diff.numel()","8c101faf":"epochs = 1000\nlr = 1e-5\nloss_tr = []\nfor i in range(epochs):\n    preds = model(inputs)    \n    loss = mse(preds, targets)\n    loss.backward()\n    \n    with torch.no_grad():\n        w -= w.grad * lr\n        b -= b.grad * lr\n        w.grad.zero_()\n        b.grad.zero_() \n    if i%100==0:\n        print('[{:3}\/{}] Loss : {:3.3f}'.format(i, epochs, loss.item()))\n    loss_tr.append(loss.item())","59048d28":"print('Final Loss :', min(loss_tr))\nprint('Weights    :' , w)\nprint('Bias       :' , b)","dbb05d0c":"sns.set(style='darkgrid')\nplt.plot(loss_tr)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss per epoch')\nplt.show()","0b7235b3":"y_preds = model(inputs)","b87c3838":"sns.residplot(y_preds.data.numpy(), targets.data.numpy())\nplt.title(\"Residuals\")\nplt.show()","d728b377":"plt.figure(figsize=(10,15))\n\nplt.subplot(311)\nsns.regplot(x=\"TV\", y=\"Sales\", data=df, label = 'Actual')\nplt.scatter( df[['TV']].values, y_preds.data.numpy(),color = 'r', marker = '+', label='Predicted')\nplt.legend()\n\nplt.subplot(312)\nsns.regplot(x=\"Radio\", y=\"Sales\", data=df, label = 'Actual')\nplt.scatter( df[['Radio']].values, y_preds.data.numpy(),color = 'r', marker = '+', label='Predicted')\nplt.legend()\n\nplt.subplot(313)\nsns.regplot(x=\"Newspaper\", y=\"Sales\", data=df, label = 'Actual')\nplt.scatter( df[['Newspaper']].values, y_preds.data.numpy(),color = 'r', marker = '+', label='Predicted')\nplt.legend()\n\nplt.show()\n","5b56beaf":"## [1] Reading Data:","145a84a4":"## [3] Splitting features and target variable","497c2a2b":"## [4] Data modeling: ","9cc915c7":"## [6] Testing phase:","bf2f0ad4":"## [2] Pair Plots:","79ec1e07":"Now to check if the perdiction is right, we can do (pred-actual) and this value should be near 0 for all datapoints, these are called residuals. ","aa874698":"Iteratively predicting the values and finding the loss, and changing the weights and biases slightly towards the gradient. ","4d745ab0":"From these, we'll get to know if the target variable has any linear relation with any of the features or not. ","c03380e4":"## [7] Conclusion: \n* Pytorch tensors and storing the gradients, are really helpful in these scenarios. \n* Even after 1000 epochs model has a mse loss of around 4. \n* It is still able to get the general trend of the data and can predict the sales to some extent. ","b8f3cf9c":"Now we can visualize the general trend of actual and predicted values as :","da0da49d":"## [5] Training phase:","b6eea0e9":"For Linear Regression, we need weights and biases and since we have 1 target variable and 3 features, weights will be (1,3) and biases will be (1)","b73d4f1b":"PyTorch is an open-source machine learning library for Python, based on Torch, used for applications such as natural language processing. It is primarily developed by Facebook's artificial-intelligence research group, and Uber's \"Pyro\" Probabilistic programming language software is built on it"}}