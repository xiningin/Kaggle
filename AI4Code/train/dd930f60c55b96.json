{"cell_type":{"55faae0c":"code","e078c6df":"code","c049a982":"code","06474706":"code","4df948f4":"code","94209d90":"code","1292258b":"code","b83e6c70":"code","e2db50db":"code","ae8ee28e":"code","fec7c798":"code","32625708":"code","9537c707":"code","ca5b0a64":"markdown","cd2f8c82":"markdown","18ee1eaf":"markdown","05975725":"markdown"},"source":{"55faae0c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# All import packages written below\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport sklearn.preprocessing\nfrom sklearn.metrics import r2_score\nfrom keras.layers import Dense,Dropout,SimpleRNN,LSTM\nfrom keras.models import Sequential\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e078c6df":"#Plotting hourly energy usage:\n\nAEP = pd.read_csv('..\/input\/hourly-energy-consumption\/AEP_hourly.csv', index_col=[0], parse_dates=[0])\n\nmau = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\nbieudo = AEP.plot(style='.',figsize=(15,5), color=mau[0], title='AEP')\n\n#Data transformation\ndef create_features(df, label=None):\n    df = df.copy()\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n\n    X = df[['hour', 'dayofweek', 'quarter', 'month', 'year',\n            'dayofyear', 'dayofmonth', 'weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X\n\nX, y = create_features(AEP, label='AEP_MW')\nfeatures_and_target = pd.concat([X, y], axis=1)\nprint(features_and_target)\nplt.show()\n\nplt.figure(figsize=(15,6))\ndata_csv = AEP.dropna()\ndataset = data_csv.values\ndataset = dataset.astype('float32')\nmax_value = np.max(dataset)\nmin_value = np.min(dataset)\nscalar = max_value - min_value\ndataset = list(map(lambda x: (x-min_value) \/ scalar, dataset))\nplt.plot(dataset)\nprint(max_value, min_value)","c049a982":"#choosing DOM_hourly.csv data for analysis\nfpath='..\/input\/hourly-energy-consumption\/DOM_hourly.csv'\n\n#Let's use datetime(2012-10-01 12:00:00,...) as index instead of numbers(0,1,...)\n#This will be helpful for further data analysis as we are dealing with time series data\ndf = pd.read_csv(fpath, index_col='Datetime', parse_dates=['Datetime'])\ndf.head()\n\n#checking missing data\ndf.isna().sum()\n\n#Data visualization\n\ndf.plot(figsize=(16,4),legend=True)\n\nplt.title('DOM hourly power consumption data - BEFORE NORMALIZATION')\n\nplt.show()","06474706":"#Normalize DOM hourly power consumption data\n\ndef normalize_data(df):\n    scaler = sklearn.preprocessing.MinMaxScaler()\n    df['DOM_MW']=scaler.fit_transform(df['DOM_MW'].values.reshape(-1,1))\n    return df\n\ndf_norm = normalize_data(df)\ndf_norm.shape\n\n#Visualize data after normalization\n\ndf_norm.plot(figsize=(16,4),legend=True)\n\nplt.title('DOM hourly power consumption data - AFTER NORMALIZATION')\n\nplt.show()","4df948f4":"# train data for deep learning models\n\ndef load_data(stock, seq_len):\n    X_train = []\n    y_train = []\n    for i in range(seq_len, len(stock)):\n        X_train.append(stock.iloc[i - seq_len: i, 0])\n        y_train.append(stock.iloc[i, 0])\n\n    # 1 last 6189 days are going to be used in test\n    X_test = X_train[110000:]\n    y_test = y_train[110000:]\n\n    # 2 first 110000 days are going to be used in training\n    X_train = X_train[:110000]\n    y_train = y_train[:110000]\n\n    # 3 convert to numpy array\n    X_train = np.array(X_train)\n    y_train = np.array(y_train)\n\n    X_test = np.array(X_test)\n    y_test = np.array(y_test)\n\n    # 4 reshape data to input into RNN models\n    X_train = np.reshape(X_train, (110000, seq_len, 1))\n\n    X_test = np.reshape(X_test, (X_test.shape[0], seq_len, 1))\n\n    return [X_train, y_train, X_test, y_test]\n","94209d90":"#create train, test data\nseq_len = 20 #choose sequence length\n\nX_train, y_train, X_test, y_test = load_data(df, seq_len)\n\nprint('X_train.shape = ',X_train.shape)\nprint('y_train.shape = ', y_train.shape)\nprint('X_test.shape = ', X_test.shape)\nprint('y_test.shape = ',y_test.shape)\n","1292258b":"#RNN model\n\nrnn_model = Sequential()\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=False))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(Dense(1))\n\nrnn_model.summary()\n\nrnn_model.compile(optimizer=\"adam\",loss=\"MSE\")\nrnn_model.fit(X_train, y_train, epochs=10, batch_size=1000)","b83e6c70":"#r2 score for the values predicted by the above trained SIMPLE RNN model\n\nrnn_predictions = rnn_model.predict(X_test)\n\nrnn_score = r2_score(y_test,rnn_predictions)\nprint(\"R2 Score of RNN model = \",rnn_score)","e2db50db":"# compare the actual values vs predicted values by plotting a graph\n\ndef plot_predictions(test, predicted, title):\n    plt.figure(figsize=(16, 4))\n    plt.plot(test, color='blue', label='Actual power consumption data')\n    plt.plot(predicted, alpha=0.7, color='orange', label='Predicted power consumption data')\n    plt.title(title)\n    plt.xlabel('Time')\n    plt.ylabel('Normalized power consumption scale')\n    plt.legend()\n    plt.show()\n\n\nplot_predictions(y_test, rnn_predictions, \"Predictions made by simple RNN model\")\n","ae8ee28e":"#train model for LSTM\n\nlstm_model = Sequential()\n\nlstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\nlstm_model.add(Dropout(0.15))\n\nlstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True))\nlstm_model.add(Dropout(0.15))\n\nlstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=False))\nlstm_model.add(Dropout(0.15))\n\nlstm_model.add(Dense(1))\n\nlstm_model.summary()\n\nlstm_model.compile(optimizer=\"adam\",loss=\"MSE\")\nlstm_model.fit(X_train, y_train, epochs=10, batch_size=1000)\n","fec7c798":"#r2 score for the values predicted by the above trained LSTM model\nlstm_predictions = lstm_model.predict(X_test)\n\nlstm_score = r2_score(y_test, lstm_predictions)\nprint(\"R^2 Score of LSTM model = \",lstm_score)\n","32625708":"#actual values vs predicted values by plotting a graph\nplot_predictions(y_test, lstm_predictions, \"Predictions made by LSTM model\")","9537c707":"#RNN, LSTM model by plotting data in a single graph\nplt.figure(figsize=(15,8))\n\nplt.plot(y_test, c=\"orange\", linewidth=3, label=\"Original values\")\nplt.plot(lstm_predictions, c=\"red\", linewidth=3, label=\"LSTM predictions\")\nplt.plot(rnn_predictions, alpha=0.5, c=\"green\", linewidth=3, label=\"RNN predictions\")\nplt.legend()\nplt.title(\"Predictions vs actual data\", fontsize=20)\nplt.show()","ca5b0a64":"And finally, we can compare the RNN model against the LTSM model by plotting them on a single graph with the actual data.","cd2f8c82":"That's the simple RNN model used against the energy data, finishing off with a plot the predicted values against the actual values.\n\nNext, we move on to LSTM model as highlighted in the 'Towards Data Science' article on Recurrent Neural Network models.","18ee1eaf":"Before moving on to the **RNN model**, a good explaination for beginners to machine learning using RRN models is available at this [link](https:\/\/towardsdatascience.com\/learn-how-recurrent-neural-networks-work-84e975feaaf7) ","05975725":"As you will observe from the plot graph which compares the predicted values to the data set, the trained LTSM model provides an accurate prediction of energy values."}}