{"cell_type":{"2b0fe622":"code","d4f4f4ca":"code","b638723c":"code","e2b34ebd":"code","63c708dc":"code","fc50f0f1":"code","8014775c":"code","a50f6bf2":"code","e3198e52":"code","8a7d2ff3":"code","2d6f4a5a":"code","844a1de5":"code","6aaacf2b":"code","1e363e7e":"code","44bb0547":"code","09b91129":"code","c49855ce":"code","7e1810e0":"code","8c6d3d2d":"code","203a7ec9":"code","ec00766d":"code","52900e71":"code","82d7c813":"code","e20e926f":"markdown","44eed794":"markdown","9f1c5f0a":"markdown","91dac19f":"markdown","5d3c7c42":"markdown","5f26e352":"markdown","461b94f6":"markdown","0f72154c":"markdown","dbdb0708":"markdown","76809d04":"markdown","03994f2b":"markdown","3706b3db":"markdown","8e504ab5":"markdown","875da001":"markdown","20e2c468":"markdown","d824597b":"markdown","834a946c":"markdown","929854f0":"markdown","e18955d6":"markdown","7568ab4a":"markdown","41d48595":"markdown","38529a7f":"markdown","b287b733":"markdown","e1e9fbd2":"markdown","0f6fb1ee":"markdown","542f74c4":"markdown","2158cbf5":"markdown","568ac319":"markdown","1197cdf8":"markdown","cf248cfb":"markdown","15127fc7":"markdown","c7c54619":"markdown","d1c1ffec":"markdown","07da2a31":"markdown"},"source":{"2b0fe622":"#import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#import os\n#print(os.listdir(\"..\/input\"))\nimport spacy\nimport random \nfrom collections import Counter #for counting\nimport seaborn as sns #for visualization\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn')\nsns.set(font_scale=2)","d4f4f4ca":"articles = pd.read_csv('..\/input\/articles.csv')","b638723c":"nlp = spacy.load('en')","e2b34ebd":"doc = nlp(articles['text'][0][:500]) ","63c708dc":"df_token = pd.DataFrame()\n\nfor i, token in enumerate(doc):\n    df_token.loc[i, 'text'] = token.text\n    df_token.loc[i, 'lemma'] = token.lemma_,\n    df_token.loc[i, 'pos'] = token.pos_\n    df_token.loc[i, 'tag'] = token.tag_\n    df_token.loc[i, 'dep'] = token.dep_\n    df_token.loc[i, 'shape'] = token.shape_\n    df_token.loc[i, 'is_alpha'] = token.is_alpha\n    df_token.loc[i, 'is_stop'] = token.is_stop","fc50f0f1":"df_token","8014775c":"from spacy import displacy","a50f6bf2":"sentence_spans = list(doc.sents)\ndisplacy.render(sentence_spans, style='dep', jupyter=True)","e3198e52":"spacy.displacy.render(doc, style='ent',jupyter=True)","8a7d2ff3":"articles['author'].value_counts()","2d6f4a5a":"from nltk.corpus import stopwords\nimport string\nstopwords = stopwords.words('english')\npunctuations = string.punctuation","844a1de5":"# Define function to cleanup text by removing personal pronouns, stopwords, and puncuation\ndef cleanup_text(docs):\n    texts = []\n    counter = 1\n    for doc in docs:\n        if counter % 100 == 0:\n            print('Processed {} out of {}'.format(counter, len(docs)))\n        counter += 1\n        doc = nlp(doc, disable=['parser', 'ner'])\n        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n        tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n        tokens = ' '.join(tokens)\n        texts.append(tokens)\n    return pd.Series(texts)","6aaacf2b":"def make_barplot_for_author(Author):\n    author_text = [text for text in articles.loc[articles['author'] == Author]['text']]\n\n    author_clean = cleanup_text(author_text)\n    author_clean = ' '.join(author_clean).split()\n    author_clean = [word for word in author_clean if word not in '\\'s']\n    author_counts = Counter(author_clean)\n\n    NUM_WORDS = 25\n    author_common_words = [word[0] for word in author_counts.most_common(NUM_WORDS)]\n    author_common_counts = [word[1] for word in author_counts.most_common(NUM_WORDS)]\n\n    plt.figure(figsize=(15, 12))\n    sns.barplot(x=author_common_counts, y=author_common_words)\n    plt.title('Words that {} use frequently'.format(Author), fontsize=20)\n    plt.show()","1e363e7e":"Author = 'Adam Geitgey'\nmake_barplot_for_author(Author)","44bb0547":"for title in articles.loc[articles['author'] == 'Adam Geitgey']['title']:\n    print(title)","09b91129":"Author = 'Slav Ivanov'\nmake_barplot_for_author(Author)","c49855ce":"for title in articles.loc[articles['author'] == 'Slav Ivanov']['title']:\n    print(title)","7e1810e0":"Author = 'Arthur Juliani'\nmake_barplot_for_author(Author)","8c6d3d2d":"for title in articles.loc[articles['author'] == 'Arthur Juliani']['title']:\n    print(title)","203a7ec9":"Author = 'Milo Spencer-Harper'\nmake_barplot_for_author(Author)","ec00766d":"for title in articles.loc[articles['author'] == 'Milo Spencer-Harper']['title']:\n    print(title)","52900e71":"Author = 'Dhruv Parthasarathy'\nmake_barplot_for_author(Author)","82d7c813":"Author = 'William Koehrsen'\nmake_barplot_for_author(Author)","e20e926f":"- Most of his articles deals the neural networks.\n- Using SpaCy, we can infer the main subject of articles.","44eed794":"- Most frequent words are 'q', 'network' and 'action'. \n- There are some words which are relevant with Reinforcement learning.\n- Let's see the titles.","9f1c5f0a":"## Store the informations of tokens","91dac19f":"- As you can see, there are many authors. \n- Let's analyze the top 5 authors.","5d3c7c42":"- Yes, as you can see, he has written many articles of the face recognition and image recognition using deep learning.","5f26e352":"- Do you know the 'William Koehrsen'? I know 'William Koehrsen' because of his amazing kernels!\n- He is a kernel master, 8th ranker for now!\n- Let's find the words he likes.","461b94f6":"- As you can see, the tokens and relevant information are extraced very easily.","0f72154c":"# Visualize the structure of sentence","dbdb0708":"## Slav Ivanov","76809d04":"- Most frequent words are gpu, use and cpu. \n- Because the 'network' is shown, we can think he wrote some articles about deep learing with GPU.","03994f2b":"- You can see the tables, in this URL. https:\/\/spacy.io\/usage\/linguistic-features#section-named-entities\n- Ok, let's find the entities using SpaCy and visualize.","3706b3db":"## Arthur Juliani","8e504ab5":"- Using displacy with keyword \"dep\",  we can visulize the structure of sentences easily.","875da001":"- Most frequent words are image and network. \n- Have he frequently written the articles about image for neural network?","20e2c468":"- SpaCy works well!","d824597b":"# Read dataset","834a946c":"- As you can see, sentences are well-divided.","929854f0":"- Tokenization using SpaCy works well. \n- How about using SpaCy?","e18955d6":"## Dhruv Parthasarathy","7568ab4a":"- Good! ","41d48595":"# Spectial guest!","38529a7f":"# Read text using spacy and extract tokens","b287b733":"# Conclusion","e1e9fbd2":"- Spacy have built-in entity-types\n\n\n| Type | Description | \n|:--------|:--------|\n| PERSON | People, including fictional. | \n| NORP | Nationalities or religious or political groups. | \n| FAC | Buildings, airports, highways, bridges, etc. | \n| ORG | Companies, agencies, institutions, etc. | \n| GPE | Countries, cities, states. | \n| LOC | Non-GPE locations, mountain ranges, bodies of water. | \n| PRODUCT | Objects, vehicles, foods, etc. (Not services.) | \n| EVENT | Named hurricanes, battles, wars, sports events, etc. | \n| WORK_OF_ART | Titles of books, songs, etc. | \n| LAW | Named documents made into laws. | \n| LANGUAGE | Any named language. | \n| DATE | Absolute or relative dates or periods. | \n| TIME | Times smaller than a day. | \n| PERCENT | Percentage, including \"%\". | \n| MONEY | Monetary values, including unit. | \n| QUANTITY | Measurements, as of weight or distance. | \n| ORDINAL | \"first\", \"second\", etc. | \n| CARDINAL | Numerals that do not fall under another type | ","0f6fb1ee":"# Authors ","542f74c4":"- As you know that, many his kernel deals the much stuff of features. Below are his kernels.\n- https:\/\/www.kaggle.com\/willkoehrsen\/introduction-to-manual-feature-engineering\n- https:\/\/www.kaggle.com\/willkoehrsen\/automated-feature-engineering-basics\n- https:\/\/www.kaggle.com\/willkoehrsen\/introduction-to-manual-feature-engineering-p2","2158cbf5":"## Milo Spencer-Harper","568ac319":"## Adam Geitgey","1197cdf8":"# Background\n- I want to analyze the text with SpaCy.\n- The documentation of SpaCy is very helpful! You can check it! https:\/\/spacy.io\/\\\n- I referred to this kernel, https:\/\/www.kaggle.com\/enerrio\/scary-nlp-with-spacy-and-keras. Thanks to [Aaron Marques](https:\/\/www.kaggle.com\/enerrio)","cf248cfb":"- Using SpaCy, we can extract his JOB! because he is working in \"Feature Labs\". :)","15127fc7":"- The article is a bit long. Let's use some part of the article.","c7c54619":"# Find entity","d1c1ffec":"- Oh, feature is the most frequent used word!","07da2a31":"- Top 3 words are neuron, neural and network. Is he author about deep learning?\n- Let's see the titles!"}}