{"cell_type":{"19e8a7f6":"code","b73667fe":"code","eb604d39":"code","6f238b48":"code","e073e009":"code","3b74bd49":"code","0e1f7ece":"code","9cb76058":"code","4aa1a88f":"code","7a2f2776":"code","5c6ff276":"code","804f103c":"code","b4eee8b0":"code","b429fdcc":"code","903c3bf7":"code","195735e4":"code","32f618f3":"code","c595a734":"code","db99a0e1":"code","fcb7f78f":"code","f9dee6df":"code","859a8b80":"code","6eb17827":"code","71761d53":"code","448da900":"code","3a38bca6":"code","5c415162":"code","1e789f47":"code","0bedeee8":"code","d87a5fe9":"code","d44988fb":"code","068c4e7c":"code","41915aea":"code","42aea197":"code","5932437f":"code","5e3d62b6":"code","9f0340aa":"code","74716ca2":"code","6284a306":"code","571ff346":"code","29ef92d0":"code","46a9a55f":"code","1f89dc04":"code","6de2d81d":"code","a2e585a9":"code","73d79d68":"code","eaf2bd58":"markdown","99d77b64":"markdown","40899000":"markdown","456e3df7":"markdown","267c73bf":"markdown","de8fcd3e":"markdown","3c965220":"markdown","8fcc0ff9":"markdown","eef29cb8":"markdown"},"source":{"19e8a7f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b73667fe":"# importing the necessary libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","eb604d39":"# Reading the dataset\n\ndf = pd.read_csv(\"\/kaggle\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv\")\n\ndf.head()","6f238b48":"df.shape","e073e009":"# Describing the Dataset\n\ndf.describe()","3b74bd49":"# getting info about the datasets\n\ndf.info()","0e1f7ece":"# To look for the null values\n\ndf.isnull().sum()","9cb76058":"df['Gender'].unique()","4aa1a88f":"df['Gender'].value_counts()","7a2f2776":"df['Gender'] = df['Gender'].fillna(\"Female\")\ndf.head()","5c6ff276":"df['Gender'].isnull().sum()","804f103c":"df['Married'].value_counts()","b4eee8b0":"df['Married'] = df['Married'].fillna(\"No\")","b429fdcc":"df['Dependents'].value_counts()","903c3bf7":"df['Dependents'] = df['Dependents'].fillna(\"3+\")","195735e4":"df['Self_Employed'].value_counts()","32f618f3":"df['Self_Employed'] = df['Self_Employed'].fillna(\"Yes\")","c595a734":"df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].mean())","db99a0e1":"df['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean())","fcb7f78f":"df['Credit_History'].value_counts()","f9dee6df":"df['Credit_History'] = df['Credit_History'].fillna(0.0)","859a8b80":"df.isnull().sum()","6eb17827":"# Lets separate the categorical and numerical columns \n\ncat_data = []\nnum_data = []\n\nfor i,c in enumerate(df.dtypes):\n    if c == object:\n        cat_data.append(df.iloc[:, i])\n    else:\n        num_data.append(df.iloc[:, i])","71761d53":"# Converting them into dataframe\n\ncat_data = pd.DataFrame(cat_data).transpose()\nnum_data = pd.DataFrame(num_data).transpose()","448da900":"# Numerical Data\n\nnum_data.head()","3a38bca6":"num_data.isnull().sum().any()","5c415162":"# Categorical Data\n\ncat_data.head()","1e789f47":"cat_data.isnull().sum().any()","0bedeee8":"# Dropping the ID Column from cat_data\ncat_data.drop('Loan_ID', axis = 1, inplace = True)","d87a5fe9":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","d44988fb":"# Transforming the Categorical Columns\n\nfor i in cat_data:\n    cat_data[i] = le.fit_transform(cat_data[i])","068c4e7c":"cat_data.head()","41915aea":"mapping = {\n    1.0 : 1,\n    0.0 : 0\n}","42aea197":"num_data.loc[:, \"Credit_History\"] = num_data.Credit_History.map(mapping)","5932437f":"num_data.head()","5e3d62b6":"# concating the both the numerical and categorical column after the operations\n\ndf = pd.concat([cat_data, num_data], axis = 1)","9f0340aa":"df.head()","74716ca2":"X = df.drop('Loan_Status', axis = 1)\ny = df['Loan_Status']","6284a306":"# Splitting the Data into train-test split\n\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n\n    \nprint('X_train shape', X_train.shape)\nprint('y_train shape', y_train.shape)\nprint('X_test shape', X_test.shape)\nprint('y_test shape', y_test.shape)\n","571ff346":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)\n","29ef92d0":"# Using the various model for training\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nmodels = {\n    'LogisticRegression' : LogisticRegression(random_state = 42),\n    'KNeighborsClassifier' : KNeighborsClassifier(),\n    'SVC' : SVC(random_state = 42),\n    'DecisionTreeClassifier' : DecisionTreeClassifier(max_depth = 5, random_state = 42)\n}","46a9a55f":"# Building the Functions\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n\ndef loss(y_true, y_pred, retu=False):\n    pre = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    loss = log_loss(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    \n    if retu:\n        return pre, rec, f1, loss, acc\n    else:\n        print('  pre: %.4f\\n  rec: %.4f\\n  f1: %.4f\\n  loss: %.4f\\n  acc: %.4f' % (pre, rec, f1, loss, acc))","1f89dc04":"# Evaluating the model\n\ndef train_eval(models, X, y):\n    for name, model in models.items():\n        print(name, ':')\n        model.fit(X, y)\n        loss(y, model.predict(X))\n        print('#'*40)","6de2d81d":"train_eval(models, X_train, y_train)","a2e585a9":"# Usingthe Stratified K Fold to split the model\n\nfrom sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits = 10, random_state = 42, shuffle = True)\n\ndef train_eval(models, X, y, folds):\n    # Since (iloc don't work on numpy array) we will change X & y to dataframe because we will use iloc\n    X = pd.DataFrame(X)\n    y = pd.DataFrame(y)\n    \n    idx = [' pre', ' rec', ' f1', ' loss', ' acc']\n    for name, model in models.items():\n        ls = []\n        print(name, ':')\n        \n        for train, test in folds.split(X, y):\n            model.fit(X.iloc[train], y.iloc[train])\n            y_pred = model.predict(X.iloc[test])\n            ls.append(loss(y.iloc[test], y_pred, retu = True))\n            \n        print(pd.DataFrame(np.array(ls).mean(axis = 0), index = idx)[0])\n        \n        print('#'*40)","73d79d68":"train_eval(models, X_train, y_train, skf)\n","eaf2bd58":"Using Label Encoder for the Categorical Columns","99d77b64":"So there is 614 rows and 13 columns in the above datasets\n\n","40899000":"If you liked this notebook please ipvote","456e3df7":"Since we have already taken care of all the missing values so there is False values  ","267c73bf":"After handling the missing data individually we can see that there is no null values so we can do the remaining analysis smoothly","de8fcd3e":"## Training","3c965220":"Since we have already taken care of all the missing values so there is False values ","8fcc0ff9":"We can see that the data is having some values","eef29cb8":"### Preprocessing the Data"}}