{"cell_type":{"69f04972":"code","3daa2831":"code","fdf88544":"code","adba367f":"code","0051344e":"code","125bbb42":"code","0c6612ff":"code","e06038b3":"code","dae0a499":"code","367c2039":"code","5b291337":"code","7f60a829":"code","070f9c64":"code","2d3570e4":"code","e7399d98":"code","263cd11f":"code","7b12673c":"code","d0087848":"code","3e274ef4":"code","5c2f9088":"code","72508cc7":"markdown","a4b17cd3":"markdown","8631ff28":"markdown","fdf6f5bd":"markdown","ff99a721":"markdown","f3165497":"markdown","540c1860":"markdown"},"source":{"69f04972":"# business = 0\n# entertainment = 1\n# politics = 2\n# sport = 3\n# tech = 4","3daa2831":"#Import library\nimport matplotlib.pyplot as plt\nfrom gensim.models import Word2Vec, KeyedVectors\nimport numpy as np\nimport nltk, re\nfrom sklearn.datasets import load_files\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score","fdf88544":"news_data = load_files(\"..\/input\/bbc-dataset\/bbc\")\nx, y = news_data.data, news_data.target","adba367f":"print(x[0])\nprint(y[0])\nprint(x[10])\nprint(y[10])","0051344e":"documents = []\n\nstemmer = WordNetLemmatizer()\n\nfor sen in range(0, len(x)):\n    # Remove all the special characters\n    document = re.sub(r'\\W', ' ', str(x[sen]))\n    \n    # remove all single characters\n    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n    \n    # Remove single characters from the start\n    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n    \n    # Substituting multiple spaces with single space\n    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n    \n    # Removing prefixed 'b'\n    document = re.sub(r'^b\\s+', '', document)\n    \n    # Converting to Lowercase\n    document = document.lower()\n    \n    # Lemmatization\n    document = document.split()\n\n    document = [stemmer.lemmatize(word) for word in document]\n    document = ' '.join(document)\n    \n    documents.append(document)","125bbb42":"print(documents[0])\nprint(y[0])\nprint(documents[10])\nprint(y[10])","0c6612ff":"import spacy\nimport en_core_web_lg\nnlp = en_core_web_lg.load()","e06038b3":"import pandas as pd\ndf = pd.DataFrame(documents, columns=['data'])","dae0a499":"df.head()","367c2039":"def get_vec(x):\n  doc = nlp(x)\n  vec = doc.vector\n  return vec","5b291337":"df['vec'] = df['data'].apply(lambda x: get_vec(x))\ndf.head()","7f60a829":"data = np.array(df['vec'])\ndata = data.reshape(-1, 1)\ndata = np.concatenate(np.concatenate(data, axis = 0), axis = 0).reshape(-1, 300)","070f9c64":"data.shape","2d3570e4":"x_train, x_test, y_train, y_test = train_test_split(data, y, test_size=0.4, random_state=42, stratify=y)\nx_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42, stratify=y_test)","e7399d98":"print('x_train:', x_train.shape)\nprint('y_train:', y_train.shape)\n\nprint('x_valid:', x_valid.shape)\nprint('y_valid:', y_valid.shape)\n\nprint('x_test :', x_test.shape)\nprint('y_test: ', y_test.shape)","263cd11f":"plt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nplt.hist(y_train)\nplt.title('train')\nplt.xticks([0, 1, 2, 3, 4], ['business', 'entertainment', 'politics', 'sport', 'tech'], rotation=20)\n\nplt.subplot(1,3,2)\nplt.hist(y_test)\nplt.title('test')\nplt.xticks([0, 1, 2, 3, 4], ['business', 'entertainment', 'politics', 'sport', 'tech'], rotation=20)\n\nplt.subplot(1,3,3)\nplt.hist(y_valid)\nplt.title('valid')\nplt.xticks([0, 1, 2, 3, 4], ['business', 'entertainment', 'politics', 'sport', 'tech'], rotation=20)","7b12673c":"model = RandomForestClassifier(n_estimators=501, max_depth=13, random_state=42, max_leaf_nodes=15)\nmodel.fit(x_train, y_train) ","d0087848":"y_pred = model.predict(x_train)\nprint(confusion_matrix(y_train,y_pred))\nprint(classification_report(y_train,y_pred))\nprint('F1-macro: ', f1_score(y_train, y_pred, average='macro'))","3e274ef4":"y_pred = model.predict(x_valid)\nprint(confusion_matrix(y_valid,y_pred))\nprint(classification_report(y_valid,y_pred))\nprint('F1-macro: ', f1_score(y_valid, y_pred, average='macro'))","5c2f9088":"y_pred = model.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\nprint('F1-macro: ', f1_score(y_test, y_pred, average='macro'))","72508cc7":"# Random Forest","a4b17cd3":"# Preprocessing","8631ff28":"# Embedding","fdf6f5bd":"# Read Data","ff99a721":"# Split Data","f3165497":"# Label","540c1860":"# Import Library"}}