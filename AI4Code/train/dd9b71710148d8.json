{"cell_type":{"7f71384f":"code","a92dfb52":"code","0917510d":"code","3deb8618":"code","2deeb973":"code","09239176":"code","c8b4dc70":"code","d8845a69":"code","1d4b9ba1":"code","f415cb66":"code","6409c7d5":"code","15e1bca7":"code","815874b8":"code","25e1eaa4":"code","fdb98a04":"code","0c29cbd3":"code","d48a156a":"code","24fcd596":"code","c1bd1e06":"code","2f4b702d":"code","adc71a5e":"code","e6b6b73f":"code","f10e642a":"code","c398b00f":"code","1ac7454b":"code","30742635":"code","488ff2ac":"code","b4d957b3":"code","3052b3f8":"code","a269df3b":"code","5a9b257a":"code","acdab35e":"markdown","8a525e71":"markdown","6869e8a6":"markdown","a947c52a":"markdown","2f632ee4":"markdown"},"source":{"7f71384f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cufflinks as cf\nimport plotly.offline\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a92dfb52":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ncombine = [train_data, test_data]","0917510d":"#Check the datatypes within the data\ntrain_data.info()\nprint('\\nThe number of samples in the training data is {}.'.format(train_data.shape[0]))\nprint(\"===============================================================\\n\")\n\n#Check the numerical values of the data\ntrain_data.describe()\ntrain_data.Pclass","3deb8618":"#Check the datatypes within the provided data\ntest_data.info()\nprint('\\nThe number of samples in the training data is {}.'.format(test_data.shape[0]))\nprint(\"===========================================================================\\n\")\n\n#Check the numerical values of the data\ntest_data.describe()","2deeb973":"train.shape","09239176":"#Checking the unique values within each category of the data\n#Sex has male or female, etc.\ntrain_data.nunique()","c8b4dc70":"#Checking the individual column 'Sex'\ntrain_data['Sex'].unique()","d8845a69":"#Checking the individual column 'Fare'\ntrain_data['Embarked'].unique()","1d4b9ba1":"train_data['Pclass'].unique()","f415cb66":"#Check missing values in train data\ntrain_data.isnull().sum()","6409c7d5":"#Removing columns\ntrain = train_data.drop(['Age', 'Cabin', 'Embarked', 'PassengerId', 'Name', 'Ticket', 'Fare'], axis = 1)","15e1bca7":"#Relationship analysis (No outliers)\ncolormap = plt.cm.viridis\ncorrelation = train.corr()\nsns.heatmap(correlation, xticklabels = correlation.columns, yticklabels = correlation.columns, cmap = colormap, annot = True)","815874b8":"#Pclass at index 0 is 1st class, pclass at index 1 is 2nd class, pclass at index 2 is 3rd class\n#This array contains data of who survived from each class\npclass = [0, 0, 0]\nfor i in range(0, 891, 1):\n   if train.Survived[i] == 1:\n        if train.Pclass[i] == 1:\n            pclass[0] = pclass[0] + 1\n        if train.Pclass[i] == 2:\n            pclass[1] = pclass[1] + 1\n        if train.Pclass[i] == 3:\n            pclass[2] = pclass[2] + 1\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\ndiff_class = [1, 2 , 3]\nax.bar(diff_class, pclass, color = 'g')\nplt.show()","25e1eaa4":"#Visualizing the Survival of Males and Females\n#Using Seaborn to create this barplot is much easier than what I did above\nsns.barplot(x = 'Sex', y = 'Survived', data = train, color = \"red\")\nplt.show()","fdb98a04":"#Implementing plotly to make a visually appealing barplot of the Pclass survival rate by mean\ntrain[['Survived', 'Pclass']].groupby(['Pclass'], as_index = False).mean().iplot(kind = 'bar')","0c29cbd3":"train.isnull().sum()","d48a156a":"#for dataset in combine:\n    #dataset['Sex'] = train['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\ntrain.Sex = train.Sex.map({\"female\":0,\"male\":\"1\"})\n#train.Pclass= train.Pclass.map({\"1\":0,\"2\":1,\"3\":2})\n#train['Sex'].fillna(train['Sex'].mode()[0], inplace=True)\n","24fcd596":"train.isnull().sum()","c1bd1e06":"x_train,x_test,y_train,y_test=train_test_split(\n    train.drop([\"Survived\"],axis=1),\n    train.Survived,\n    test_size = 0.2,\n    random_state = 0,\n    stratify = train.Survived\n)","2f4b702d":"#Droping \"irrelevant\" columns\ntest = test_data.drop(['Age', 'Cabin', 'Embarked', 'Name', 'Ticket', 'Fare'], axis = 1)","adc71a5e":"train.shape","e6b6b73f":"test.shape","f10e642a":"#Checking out the test data\ntest.info()","c398b00f":"#Logistic Regression Model\ntrain.Pclass = train.Pclass.astype(float)\ntrain.Sex = train.Sex.astype(float)\nnp.nan_to_num(train)\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\n\nY_pred = lr.predict(x_test)\nacc_lr = accuracy_score(y_test,Y_pred)\nacc_lr","1ac7454b":"#Stochastic Gradient Descent\nsgd = SGDClassifier()\nsgd.fit(x_train,y_train)\nY_pred = sgd.predict(x_test)\nacc_sgd = accuracy_score(y_test,Y_pred)\nacc_sgd","30742635":"#Decision Tree\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(x_train, y_train)\nY_pred = decision_tree.predict(x_test)\nacc_decision = accuracy_score(y_test,Y_pred)\nacc_decision","488ff2ac":"#From the Titanic Tutorial:\n\n\n#Sample of \"gender_submission.csv\" claims that all the female passengers survived, we'll test that here\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","b4d957b3":"#Sample of the number of men who survived\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","3052b3f8":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Stochastic Gradient Descent', 'Decision Tree'],\n    'Score': [acc_lr, acc_sgd, acc_decision]})\nmodels.sort_values(by='Score', ascending=False)","a269df3b":"predictions = lr.predict(x_test)\npredictions","5a9b257a":"#ValueError: array length 179 does not match index length 418\npredictions = lr.predict(x_test)\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","acdab35e":"# 1. Import Data and Necessary Packages","8a525e71":"# 2. Exploratory Data Analysis","6869e8a6":"# 5. Model Selection\/Submission","a947c52a":"# 4. Models","2f632ee4":"# 3. Pre-Models"}}