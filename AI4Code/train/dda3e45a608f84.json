{"cell_type":{"f4114911":"code","2bcbd428":"code","51ddc223":"code","5b49dc0f":"code","06cd2b3b":"code","62712155":"code","b49290ae":"code","21dde6f3":"code","b577eedd":"code","d1253550":"code","35fcce97":"code","62bc2372":"code","ae13d964":"code","0fe611ff":"code","4a560092":"code","e3e55289":"code","3cbbcf15":"code","e6c33308":"code","0677e68e":"code","e59654a5":"markdown","bb44b0f3":"markdown","7c4dc233":"markdown","31999fc0":"markdown","d7ebc581":"markdown","61e99773":"markdown","f0dfdd92":"markdown","78f85669":"markdown","ad187a83":"markdown","7f13c01f":"markdown","3141a0bb":"markdown","358c4a66":"markdown","7dfe5416":"markdown","6f4beb18":"markdown"},"source":{"f4114911":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2bcbd428":"import random\nimport math\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use('fivethirtyeight')","51ddc223":"df = pd.read_csv('\/kaggle\/input\/women-entrepreneurship-and-labor-force\/Dataset3.csv', delimiter = ';')","5b49dc0f":"df.head()","06cd2b3b":"developed = df[df['Level of development'] == 'Developed']","62712155":"ei = df['Entrepreneurship Index'].values\nwei = df['Women Entrepreneurship Index'].values\nflfp = df['Female Labor Force Participation Rate'].values","b49290ae":"def Estimate(val, mu=0, median=0, n=7, m=1000):\n    \n    means = []\n    medians = []\n    \n    for _ in range(m):\n        xs = random.sample(list(val), n)\n        xbar = np.mean(xs)\n        median = np.median(xs)\n        means.append(xbar)\n        medians.append(median)\n        \n    print('rmse of xbar is: ', RMSE(means, mu))\n    print('rmse of median is: ', RMSE(medians, mu))\n    \ndef RMSE(estimates, actual):\n    e2 = [(estimate - actual) ** 2 for estimate in estimates]\n    mse = np.mean(e2)\n    return math.sqrt(mse)","21dde6f3":"df.describe()","b577eedd":"print('Estimation in wei: ')\nEstimate(wei, mu=47.835294, median=44.500000)\nprint('\\n')\nprint('Estimation in ei: ')\nEstimate(ei, mu=47.241176, median=42.700000)\nprint('\\n')\nprint('Estimation in flfp: ')\nEstimate(flfp, mu=58.481765, median=61.000000)","d1253550":"def EstimateVar(val, sigma=0, n=7, m=1000):\n    \n    estimates1 = []\n    estimates2 = []\n    \n    for _ in range(m):\n        xs = [random.sample(list(val), n)]\n        biased = np.var(xs)\n        unbiased = np.var(xs, ddof=1)\n        estimates1.append(biased)\n        estimates2.append(unbiased)\n        \n    print('mean error of biased: ', MeanError(estimates1, sigma ** 2))\n    print('mean error of unbiased: ', MeanError(estimates2, sigma ** 2))\n    \ndef MeanError(estimates, actual):\n    errors = [estimate - actual for estimate in estimates]\n    return np.mean(errors)","35fcce97":"print('Estimation in wei: ')\nEstimateVar(wei, sigma=14.268480)\nprint('\\n')\nprint('Estimation in ei: ')\nEstimateVar(ei, sigma=16.193149)\nprint('\\n')\nprint('Estimation in flfp: ')\nEstimateVar(flfp, sigma=13.864567)","62bc2372":"def SimulateSample(val, n=9, m=1000):\n    mu = np.mean(val)\n    means = []\n    for j in range(m):\n        xs = random.sample(list(val), n)\n        xbar = np.mean(xs)\n        means.append(xbar)\n        \n    return means","ae13d964":"x_bars_ei = SimulateSample(ei)\nx_bars_wei = SimulateSample(wei)\nx_bars_flfp = SimulateSample(flfp)","0fe611ff":"print('rmse of x_bars_ei: ', RMSE(x_bars_ei, 47.241176))\nprint('rmse of x_bars_wei: ', RMSE(x_bars_wei, 47.835294))\nprint('rmse of x_bars_flfp: ', RMSE(x_bars_flfp, 58.481765))\nprint('\\n')\nprint('90% Confidence Interval of x_bars_ei: ', np.percentile(x_bars_ei, 5), np.percentile(x_bars_ei, 95))\nprint('90% Confidence Interval of x_bars_wei: ', np.percentile(x_bars_wei, 5), np.percentile(x_bars_wei, 95))\nprint('90% Confidence Interval of x_bars_flfp: ', np.percentile(x_bars_flfp, 5), np.percentile(x_bars_flfp, 95))","4a560092":"def EvalCdf(sample, x):\n    count = 0\n    \n    for i in sample:\n        if i <= x:\n            count += 1\n    prob = count \/ len(sample)\n    return prob","e3e55289":"cdf_ei = [EvalCdf(sorted(x_bars_ei), x) for x in sorted(x_bars_ei)]\ncdf_wei = [EvalCdf(sorted(x_bars_wei), x) for x in sorted(x_bars_wei)]\ncdf_flfp = [EvalCdf(sorted(x_bars_flfp), x) for x in sorted(x_bars_flfp)]","3cbbcf15":"plt.figure(figsize = (15, 8))\n\nplt.plot(sorted(x_bars_ei), cdf_ei)\nplt.axvline(np.percentile(x_bars_ei, 5), 0, ls = '--', color = 'blue')\nplt.axvline(np.percentile(x_bars_ei, 95), 0, ls = '--', color = 'blue')\nplt.axvline(np.mean(x_bars_ei), 0, ls = ':', color = 'red')\nplt.axvline(np.mean(ei), 0, ls = ':', color = 'green')","e6c33308":"plt.figure(figsize = (15, 8))\n\nplt.plot(sorted(x_bars_wei), cdf_wei)\nplt.axvline(np.percentile(x_bars_wei, 5), 0, ls = '--', color = 'blue')\nplt.axvline(np.percentile(x_bars_wei, 95), 0, ls = '--', color = 'blue')\nplt.axvline(np.mean(x_bars_wei), 0, ls = ':', color = 'red')\nplt.axvline(np.mean(wei), 0, ls = ':', color = 'green')","0677e68e":"plt.figure(figsize = (15, 8))\n\nplt.plot(sorted(x_bars_flfp), cdf_flfp)\nplt.axvline(np.percentile(x_bars_flfp, 5), 0, ls = '--', color = 'blue')\nplt.axvline(np.percentile(x_bars_flfp, 95), 0, ls = '--', color = 'blue')\nplt.axvline(np.mean(x_bars_flfp), 0, ls = ':', color = 'red')\nplt.axvline(np.mean(flfp), 0, ls = ':', color = 'green')","e59654a5":"Why estimating variance?\n\n1. There are 2 formulae for the variance; one is using 'n' in the denominator.\n2. Other one is using 'n-1' in the denominator.\n3. When ","bb44b0f3":"***2. Estimator for Variance (sigma squared):***","7c4dc233":"                                                 -- Under construction -- ","31999fc0":"# Purpose:","d7ebc581":"***What is the conclusion?***\n\nIn all three variables, the rmse of sample mean is less than that of the median; therefore, we would say that the sample mean (xbar) is a good juxtapose of the population mean, and not the median.","61e99773":"# Confidence Intervals:","f0dfdd92":"# Pre-requisite:","78f85669":"***1. To demonstrate the better estimator for the population mean; sample mean or the median.***\n\n***2. To characterize the uncertainty of the the estimate; that is, to compute the sampling error and the confidence interval.***","ad187a83":"1. [Autumn of Matriarch: The complete guide to EDA - 1](https:\/\/www.kaggle.com\/ritikpnayak\/autumn-of-matriarch-the-complete-guide-to-eda-1)\n\n2. [Autumn of Matriarch: The complete guide to EDA - 2](https:\/\/www.kaggle.com\/ritikpnayak\/autumn-of-matriarch-the-complete-guide-to-eda-2)\n\n3. [Autumn of Matriarch: The complete guide to EDA - 3](https:\/\/www.kaggle.com\/ritikpnayak\/autumn-of-matriarch-the-complete-guide-to-eda-3)","7f13c01f":"The concepts explained in this notebook have previously been explained by me in a yet lucid notebook, kindly refer to that, as this notebook would sure be less inclusive than that was.\n\n[Estimation, Confidence Interval and Standard Error](https:\/\/www.kaggle.com\/ritikpnayak\/estimation-confidence-interval-and-standard-error) - link to the notebook.","3141a0bb":"***1. Estimator for the population mean (mu):***","358c4a66":"# Sampling distributions:","7dfe5416":"# Estimation:","6f4beb18":"# Previously in the series:"}}