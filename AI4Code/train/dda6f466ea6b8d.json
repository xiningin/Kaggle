{"cell_type":{"957013e8":"code","f0b61e9f":"code","f8879787":"code","812e4457":"code","6cc06d02":"code","18cc5468":"code","63edc2ed":"code","1a271c69":"code","5825e05b":"code","768b0062":"code","c06079ae":"code","2f564b47":"code","8aea4039":"code","aa8b6259":"code","c112d320":"code","c9494ccd":"code","a7e1ecd2":"code","6d76eac0":"code","3ec41afd":"code","1a048542":"code","2ede9d3c":"code","4e07cf12":"code","02e0c614":"code","5113490d":"code","f6adfb03":"code","a1fb2103":"code","83e49bb3":"code","fa22a6ea":"code","33a676ae":"code","861ad817":"code","ba389990":"code","84f4fd94":"code","e5917cb6":"code","0526a2e1":"code","cc5fe13b":"code","ebf4c765":"code","6ed804e7":"code","3a429690":"code","bd2a3dfc":"code","2a8121f2":"code","ff9bd468":"markdown","92ce82cc":"markdown","e9199fad":"markdown","a7f7d6ee":"markdown","cf689b4b":"markdown","2bd5bd04":"markdown","abbac8c1":"markdown","cecd100e":"markdown","4f3d94b1":"markdown","d4a9a6cf":"markdown","f049d1eb":"markdown","238bed17":"markdown"},"source":{"957013e8":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # Plotting\nimport seaborn as sns # Plotting\n\n# Import Image Libraries - Pillow and OpenCV\nfrom PIL import Image\nimport cv2\n\n# Import PyTorch and useful fuctions\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torchvision\nimport torch.optim as optim\nimport torchvision.models as models # Pre-Trained models\n\n# Import useful sklearn functions\nimport sklearn\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\n\nimport time\nfrom tqdm import tqdm_notebook\n\nimport os\nprint(os.listdir(\"..\/input\"))\nbase_dir = \"..\/input\/aptos2019-blindness-detection\/\"","f0b61e9f":"train_csv = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\ntest_csv = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')","f8879787":"print('Train Size = {}'.format(len(train_csv)))\nprint('Public Test Size = {}'.format(len(test_csv)))","812e4457":"train_csv.head()","6cc06d02":"counts = train_csv['diagnosis'].value_counts()\nclass_list = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferate']\nfor i,x in enumerate(class_list):\n    counts[x] = counts.pop(i)\n\nplt.figure(figsize=(10,5))\nsns.barplot(counts.index, counts.values, alpha=0.8, palette='bright')\nplt.title('Distribution of Output Classes')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Target Classes', fontsize=12)\nplt.show()","18cc5468":"fig = plt.figure(figsize=(30, 6))\n# display 20 images\ntrain_imgs = os.listdir(base_dir+\"\/train_images\")\nfor idx, img in enumerate(np.random.choice(train_imgs, 16)):\n    ax = fig.add_subplot(2, 16\/\/2, idx+1, xticks=[], yticks=[])\n    im = Image.open(base_dir+\"\/train_images\/\" + img)\n    plt.imshow(im)\n    lab = train_csv.loc[train_csv['id_code'] == img.split('.')[0], 'diagnosis'].values[0]\n    ax.set_title('Severity: %s'%lab)","63edc2ed":"fig = plt.figure(figsize=(30, 6))\n# display 20 images\ntest_imgs = os.listdir(base_dir+\"\/test_images\")\nfor idx, img in enumerate(np.random.choice(test_imgs, 16)):\n    ax = fig.add_subplot(2, 16\/\/2, idx+1, xticks=[], yticks=[])\n    im = Image.open(base_dir+\"\/test_images\/\" + img)\n    plt.imshow(im)","1a271c69":"# Our own custom class for datasets\nclass CreateDataset(Dataset):\n    def __init__(self, df_data, data_dir = '..\/input\/', transform=None):\n        super().__init__()\n        self.df = df_data.values\n        self.data_dir = data_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_name,label = self.df[index]\n        img_path = os.path.join(self.data_dir, img_name+'.png')\n        image = cv2.imread(img_path)\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","5825e05b":"transforms = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.4),\n    #transforms.ColorJitter(brightness=2, contrast=2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n])","768b0062":"train_path = \"..\/input\/aptos2019-blindness-detection\/train_images\/\"\ntest_path = \"..\/input\/aptos2019-blindness-detection\/test_images\/\"","c06079ae":" train_data = CreateDataset(df_data=train_csv, data_dir=train_path, transform=transforms)","2f564b47":"# Set Batch Size\nbatch_size = 32\n\n# Percentage of training set to use as validation\nvalid_size = 0.2\n\n# obtain training indices that will be used for validation\nnum_train = len(train_data)\nindices = list(range(num_train))\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# Create Samplers\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\nvalid_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)","8aea4039":"model = models.resnet101(pretrained=False)\nmodel.load_state_dict(torch.load(\"..\/input\/pretrained-models\/resnet101-5d3b4d8f.pth\"))\n# for param in model.parameters():\n#     param.requires_grad = False\nmodel.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\nmodel.fc = nn.Sequential(\n                nn.Linear(in_features=2048, out_features=1024, bias=True),\n                nn.Linear(in_features=1024, out_features=1, bias=True)\n            )","aa8b6259":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')\n    model.cuda()","c112d320":"# Trainable Parameters\npytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))","c9494ccd":"# specify loss function (categorical cross-entropy loss)\ncriterion = nn.MSELoss()\n\n# specify optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.00015)","a7e1ecd2":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","6d76eac0":"# number of epochs to train the model\nn_epochs = 15\n\nvalid_loss_min = np.Inf\n\n# keeping track of losses as it happen\ntrain_losses = []\nvalid_losses = []\nval_kappa = []\ntest_accuracies = []\nvalid_accuracies = []\nkappa_epoch = []\nbatch = 0\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    ###################\n    # train the model #\n    ###################\n    model.train()\n    for data, target in tqdm_notebook(train_loader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda().float()\n        target = target.view(-1, 1)\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n        # Update Train loss and accuracies\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for data, target in tqdm_notebook(valid_loader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda().float()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        target = target.view(-1, 1)\n        with torch.set_grad_enabled(True):\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n        #output = output.cohen_kappa_score_kappa_score)\n        y_actual = target.data.cpu().numpy()\n        y_pred = output[:,-1].detach().cpu().numpy()\n        val_kappa.append(cohen_kappa_score(y_actual, y_pred.round()))        \n    \n    # calculate average losses\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n    valid_kappa = np.mean(val_kappa)\n    kappa_epoch.append(np.mean(val_kappa))\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n        \n    # print training\/validation statistics \n    print('Epoch: {} | Training Loss: {:.6f} | Val. Loss: {:.6f} | Val. Kappa Score: {:.4f}'.format(\n        epoch, train_loss, valid_loss, valid_kappa))\n    \n    ##################\n    # Early Stopping #\n    ##################\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'best_model.pt')\n        valid_loss_min = valid_loss","3ec41afd":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(valid_losses, label='Validation loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend(frameon=False)","1a048542":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nplt.plot(kappa_epoch, label='Val Kappa Score\/Epochs')\nplt.legend(\"\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Kappa Score\")\nplt.legend(frameon=False)","2ede9d3c":"model.load_state_dict(torch.load('best_model.pt'))","4e07cf12":"test_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.ToPILImage(),\n    torchvision.transforms.Resize((224, 224)),\n    #torchvision.transforms.ColorJitter(brightness=2, contrast=2),\n    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n])","02e0c614":"test_csv['diagnosis'] = -1","5113490d":"test_data = CreateDataset(df_data=test_csv, data_dir=test_path, transform=test_transforms)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)","f6adfb03":" def round_off_preds(preds, coef=[0.5, 1.5, 2.5, 3.5]):\n    for i, pred in enumerate(preds):\n            if pred < coef[0]:\n                preds[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                preds[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                preds[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                preds[i] = 3\n            else:\n                preds[i] = 4\n    return preds","a1fb2103":"def predict(testloader):\n    '''Function used to make predictions on the test set'''\n    model.eval()\n    preds = []\n    for batch_i, (data, target) in enumerate(testloader):\n        data, target = data.cuda(), target.cuda()\n        output = model(data)\n        pr = output.detach().cpu().numpy()\n        for i in pr:\n            preds.append(i.item())\n            \n    return preds","83e49bb3":"preds1 = np.array(predict(testloader=test_loader))","fa22a6ea":"preds2 = np.array(predict(testloader=test_loader))","33a676ae":"preds3 = np.array(predict(testloader=test_loader))","861ad817":"preds4 = np.array(predict(testloader=test_loader))","ba389990":"preds5 = np.array(predict(testloader=test_loader))","84f4fd94":"preds6 = np.array(predict(testloader=test_loader))","e5917cb6":"preds7 = np.array(predict(testloader=test_loader))","0526a2e1":"preds8 = np.array(predict(testloader=test_loader))","cc5fe13b":"preds = (preds1 + preds2 + preds3 + preds4 + \n         preds5 + preds6 + preds7 + preds8)\/8.0","ebf4c765":"preds = round_off_preds(preds)","6ed804e7":"sample_sub = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')","3a429690":"sample_sub.diagnosis = preds\nsample_sub.diagnosis = sample_sub['diagnosis'].astype(int)","bd2a3dfc":"sample_sub.head()","2a8121f2":"sample_sub.to_csv('submission.csv', index=False)","ff9bd468":"# Define Model Architecture","92ce82cc":"# Generating Submission File","e9199fad":"# Loading Data + EDA","a7f7d6ee":"# Inference","cf689b4b":"# Import the essentials","2bd5bd04":"# Visualizing Test Set","abbac8c1":"# Introduction\nThe goal of this competition is to detect blindness before it happens, organized by APTOS, data taken from Aravind Eye Hospitals here in my home country India.\nThis kernel is meant to provide a good starting point for those who use PyTorch for training and fine-tuning your models.\n\n\n### Motivation: (From Competition Description)\n\nMillions of people suffer from diabetic retinopathy, the leading cause of blindness among working aged adults. Aravind Eye Hospital in India hopes to detect and prevent this disease among people living in rural areas where medical screening is difficult to conduct. Successful entries in this competition will improve the hospital\u2019s ability to identify potential patients.\n\n\n### Evaluation Metric:\n**Quadratic Kappa Score**  is a very useful, but under-utilised, metric. Sometimes in machine learning we are faced with a multi-class classification problem. In those cases, measures such as the accuracy, or precision\/recall do not provide the complete picture of the performance of our classifier.\n\nCohen\u2019s kappa statistic is a very good measure that can handle very well both multi-class and imbalanced class problems. \n\nCohen\u2019s kappa is always less than or equal to 1. Values of 0 or less, indicate that the classifier is useless. There is no standardized way to interpret its values. Landis and Koch (1977) provide a way to characterize values. According to their scheme a value < 0 is indicating no agreement , 0\u20130.20 as slight, 0.21\u20130.40 as fair, 0.41\u20130.60 as moderate, 0.61\u20130.80 as substantial, and 0.81\u20131 as almost perfect agreement.\n\nReferences: \n[Cohen's Kappa Statistic](https:\/\/thedatascientist.com\/performance-measures-cohens-kappa-statistic\/), [Wiki](https:\/\/en.wikipedia.org\/wiki\/Cohen%27s_kappa)\n\n#### Please UPVOTE this kernel if you find this useful.","cecd100e":"### TTA (Test Time Augmentation)","4f3d94b1":"# Visualizing Training Data","d4a9a6cf":"# Data Processing","f049d1eb":"#### Give this kernel an upvote if you found this helpful.\n\n**Credits:** Abhishek's [Inference Kernel](https:\/\/www.kaggle.com\/abhishek\/pytorch-inference-kernel-lazy-tta)","238bed17":"# Training (Fine Tuning) and Validation"}}