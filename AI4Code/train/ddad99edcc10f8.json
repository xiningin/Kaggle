{"cell_type":{"4698941a":"code","caa28ae6":"code","123bebc0":"code","9b5c7cfa":"code","dfbd56f8":"code","256a4ce2":"code","55c46d80":"code","59630d7f":"code","0f87209f":"code","624cd649":"code","21038647":"code","3ed0ef48":"code","717be053":"code","df9b7cd1":"code","63faf9fc":"code","92e735e5":"code","a11e296c":"code","57d1e650":"code","8ef1884b":"code","5ed64171":"code","ad776d3f":"code","f1a179a2":"code","4673a635":"code","2fa2afb5":"code","061dbf48":"code","c639dbc4":"code","016213ff":"code","e6e6d53d":"code","46b100c0":"code","6e676f46":"code","b15a227c":"code","a18bebde":"code","ecba045f":"code","2d499f13":"code","a5b8a293":"code","04915da3":"code","772c6ccf":"code","b93b972b":"code","8c7b5fb5":"code","590545bb":"code","0f20d62e":"code","2d428195":"code","5d9d4a8a":"code","3749657b":"code","7f344a22":"code","010c8e9d":"code","38cdc611":"code","71cb18de":"code","4f83c0c4":"code","732b2c95":"code","6c6f4821":"code","db556c42":"code","04be8c94":"code","42766a10":"code","846dd6bb":"code","f1f2174d":"code","9b9c3689":"code","c37c52e5":"markdown","0c1953ea":"markdown","0a0e7a25":"markdown","62f20eca":"markdown","b5ff84b1":"markdown","c6483b68":"markdown","81478c2b":"markdown","ed5494f2":"markdown","8e7bca40":"markdown","55ffeba5":"markdown","7186d255":"markdown"},"source":{"4698941a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","caa28ae6":"#reading the files\ntrain=pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv',parse_dates=['Date'])\ntest=pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv',parse_dates=['Date'])\ng=train","123bebc0":"train.head()","9b5c7cfa":"train.shape","dfbd56f8":"test.tail()","256a4ce2":"test.shape","55c46d80":"#describing the details of train and test dataframe\ntrain.info()","59630d7f":"test.info()","0f87209f":"#checking for missing values in train and set\ntrain.isnull().any()","624cd649":"test.isnull().any()","21038647":"#visualizing missing data for train and test\nimport missingno as msno\nmsno.matrix(train)","3ed0ef48":"msno.matrix(test)","717be053":"#identifying null values\ntrain['Province_State'].isnull().value_counts()","df9b7cd1":"#dropping unecessary columns\ntrain.drop(columns=['Province_State','Id'],axis=1,inplace=True)\ntest.drop(columns=['Province_State','ForecastId'],axis=1,inplace=True)","63faf9fc":"train.head()","92e735e5":"test.head()","a11e296c":"#dataframe for plotting the cases and fatalities around the world\ntrain_data_by_country = train.groupby(['Date','Country_Region'],as_index=False).agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum'})","57d1e650":"train_data_by_country","8ef1884b":"#visualizing clean train and test datasets\nmsno.matrix(train)","5ed64171":"msno.matrix(test)","ad776d3f":"#checking trend of confirmed cases around top countries\ntopc=[\"US\",\"China\",\"Spain\",'France','United Kingdom','Italy','Brazil','Belgium','Germany','Iran','Canada']\nimport plotly.express as px\nimport plotly\nplotly.offline.init_notebook_mode(connected = True)\nfor i in topc:\n    df=train_data_by_country[train_data_by_country['Country_Region']==i]\n    fig=px.line(df,x=\"Date\",y=\"ConfirmedCases\",title='Daily Analysis of Confirmed Cases in' + \" \" +i)\n    fig.show()","f1a179a2":"#checking trend of fatalities around top countries\nfor i in topc:\n    df=train_data_by_country[train_data_by_country['Country_Region']==i]\n    fig=px.line(df,x='Date',y='Fatalities',title='Daily Analysis of Fatalities for' + \" \" +i,color_discrete_map={'Fatalities':'Red'})\n    fig.show()","4673a635":"#setting DatetimeIndex for train\ntrain=train.set_index(['Date'])","2fa2afb5":"#visualizing Confirmed Cases per month around the world\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nplt.title('Confirmed Cases on Monthly Basis around the world')\nplt.ylabel('Confirmed Cases')\ntrain.ConfirmedCases.resample('M').plot(figsize=(10,10))","061dbf48":"#visualising fatalities per month around the world\nplt.title('Fatalities on Monthly Basis around the world')\nplt.ylabel('Fatalities')\ntrain.Fatalities.resample('M').plot(figsize=(10,10))","c639dbc4":"#plotting both the independent variables\ntrain.plot(figsize=(10,10))\nplt.title('Ratio of Confirmed Cases to Fatalities around the world for every month')","016213ff":"s=train_data_by_country['Country_Region'].tolist()","e6e6d53d":"pip install country_converter","46b100c0":"#generating iso3 names of the countries\nimport country_converter as cc\niso_alpha=cc.convert(names=s,to='ISO3')","6e676f46":"#combining the codes into the dataframe train_data_by_country\ntrain_data_by_country['iso_codes']=iso_alpha","b15a227c":"train_data_by_country","a18bebde":"#generating choropleth maps for visualizing day to day analysis of all confirmed cases around the world\ntrain_date=train_data_by_country['Date'].astype(str)\nfig_1=px.choropleth(train_data_by_country,locations='iso_codes',color='ConfirmedCases',hover_name='Country_Region',\n                 hover_data=['ConfirmedCases'],animation_frame=train_date,\n                  color_continuous_scale=px.colors.sequential.Purpor,title='Confirmed Cases around the world on daily basis')\n\nfig_1.show()","ecba045f":"#generating choropleth maps for visualizing day to day analysis of all fatalities around the world\ntrain_date=train_data_by_country['Date'].astype(str)\nfig_2=px.choropleth(train_data_by_country,locations='iso_codes',color='Fatalities',hover_name='Country_Region',\n                 hover_data=['Fatalities'],animation_frame=train_date,\n                color_continuous_scale=px.colors.sequential.PuRd,title='Fatalities around the world on daily basis')\nfig_2.show()","2d499f13":"#adding the date column\ntrain['Date']=train.index","a5b8a293":"#removing the Datetime Index of train\ntrain.index=g.index","04915da3":"#separating train date into day,month and year values and adding it to the train\ntrain['Day']=train['Date'].dt.day\ntrain['Month']=train['Date'].dt.month\ntrain['Year']=train['Date'].dt.year","772c6ccf":"#dropping the year column in train\ntrain.drop(columns=['Year'],inplace=True)","b93b972b":"#separating test date into day,month and year values and adding it to the test\ntest['Day']=test['Date'].dt.day\ntest['Month']=test['Date'].dt.month\ntest['Year']=test['Date'].dt.year","8c7b5fb5":"#dropping the year column in test\ntest.drop(columns='Year',inplace=True)","590545bb":"test.head()","0f20d62e":"train.head()","2d428195":"del train['Date']\ndel test['Date']","5d9d4a8a":"#converting the independent variables into int datatype\ntrain['ConfirmedCases'] = train['ConfirmedCases'].apply(int)\ntrain['Fatalities'] = train['Fatalities'].apply(int)","3749657b":"cases = train.ConfirmedCases\nfatalities = train.Fatalities\ndel train['ConfirmedCases']\ndel train['Fatalities']","7f344a22":"#Handling Categorical data\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nlb = LabelEncoder()\ntrain['Country_Region'] = lb.fit_transform(train['Country_Region'])\ntest['Country_Region'] = lb.transform(test['Country_Region'])","010c8e9d":"scaler = StandardScaler()\nx_train = scaler.fit_transform(train.values)\nx_test = scaler.transform(test.values)","38cdc611":"#using xgboost for prediction \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import VotingRegressor","71cb18de":"#fitting the model\ndt=DecisionTreeRegressor(random_state=0)\nlg=LGBMRegressor()\nlr=LinearRegression()\nclassifier=[('Linear Regression',lr),('DecisionTreeRegressor',dt),('GradientBoosting',lg)]","4f83c0c4":"vc=VotingRegressor(estimators=classifier)\nvc.fit(x_train,cases)","732b2c95":"#predicting the confirmed cases\ncases_pred = vc.predict(x_test)\ncases_pred","6c6f4821":"#rounding off the cases to nearest number\ncases_pred = np.around(cases_pred,decimals = 0)\ncases_pred","db556c42":"#fitting the model\nvc=VotingRegressor(estimators=classifier)\nvc.fit(x_train,fatalities)","04be8c94":"#predicting the fatalities\nfatalities_pred = vc.predict(x_test)\nfatalities_pred","42766a10":"#rounding off the Fatalities to nearest number\nfatalities_pred = np.around(fatalities_pred,decimals = 0)\nfatalities_pred","846dd6bb":"#submitting the required result\nsubmission=pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/submission.csv')\nsubmission['ConfirmedCases'] = cases_pred\nsubmission['Fatalities'] = fatalities_pred","f1f2174d":"submission.head(10)","9b9c3689":"submission.to_csv(\"submission.csv\" , index = False)","c37c52e5":"The use of group by function has enabled us to diaplay all the cases and fatalities worldwide taking place on daily.\n","0c1953ea":"* During the month of January,the fatalities starts to grow at very slow rate ranging around 100-300.\n\n* During the month of February,there is an gradual increase in the number of fatalities ranging around 2500 till the end of month.\n\n* During the month of March the fatalities happen at a constant rate till mid-month(around 2800-3000) but shows sharp increase at the end of the month(reaching more than 10000).\n\n* During the month of April-May,the fatalities start to grow exponentially making it a global calamity till date ranging around 10000-35000. \n","0a0e7a25":"It was seen in the dataset that the **'Province_State'** column of the training dataset was dropped due to null values being more than 50%,but some countries involved values in the **'Province_State'** too,so to include that countries,we will use groupby with aggregation function of sum for all the countries which are repeated and combining them into an single country for better day to day analysis. ","62f20eca":"While most of the countries show exponential trend,**China** shows constant trend of confirmed cases around beginning of March.","b5ff84b1":"* During the month of January,the cases are growing at a slow rate mainly on countries around **China**.Cases are less than 10000.\n\n* During the month of February,there is an gradual increase in the number of Confirmed Cases reaching more than 50000 at end of the month.The cases are at constant rate when half of the month is passed till the end of the month.\n\n* During the month of March,the rate of Confirmed Cases is like previous month (constant around 60000) and it is continued till mid-march but starts increasing by the end of the month from 60000 to more than 100000.\n\n* During the month of April and May,the cases start to grow exponentially till date indicating worse effects more than 300000.\n\n","c6483b68":"Similarly,we can calaculate trend of confirmed cases and fatalities of any country.","81478c2b":"While most of the countries shows exponential trend in fatalities,**China** shows constant fatality rate around mid-march to mid-april then after sharp increase it becomes constant at beginning of may.","ed5494f2":"There are no iso3 or iso2 codes of countries to plot them on choropleth.Therefore,without including them from an another dataset we can make use of a library known as **'country_converter'** to find all relevant details about any country.\n\nMore details at-https:\/\/pypi.org\/project\/country-converter\/","8e7bca40":"# **Background**\n\nThe White House Office of Science and Technology Policy (OSTP) pulled together a coalition research groups and companies (including Kaggle) to prepare the COVID-19 Open Research Dataset (CORD-19) to attempt to address key open scientific questions on COVID-19. Those questions are drawn from National Academies of Sciences, Engineering, and Medicine\u2019s (NASEM) and the World Health Organization (WHO).\n\n# The Challenge\n\nKaggle is launching a companion COVID-19 forecasting challenges to help answer a subset of the NASEM\/WHO questions. While the challenge involves forecasting confirmed cases and fatalities between April 15 and May 14 by region, the primary goal isn't only to produce accurate forecasts. It\u2019s also to identify factors that appear to impact the transmission rate of COVID-19.\n\nYou are encouraged to pull in, curate and share data sources that might be helpful. If you find variables that look like they impact the transmission rate, please share your finding in a notebook.\n\nAs the data becomes available, we will update the leaderboard with live results based on data made available from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE).\n\nWe have received support and guidance from health and policy organizations in launching these challenges. We're hopeful the Kaggle community can make valuable contributions to developing a better understanding of factors that impact the transmission of COVID-19.\n\n# Objective\n\nIn this challenge, you will be predicting the cumulative number of confirmed COVID19 cases in various locations across the world, as well as the number of resulting fatalities, for future dates.","55ffeba5":"The Fatalities started to occur at very slow pace from January to mid-march as compared to occurence of Confirmed Cases but after mid-march till date, the rate of fatalities is increasing gradually.","7186d255":"**If you like this notebook do upvote it.**\n\nDo provide your valuable feedback.\n\nDo checkout my other notebooks at https:\/\/www.kaggle.com\/tmchls"}}