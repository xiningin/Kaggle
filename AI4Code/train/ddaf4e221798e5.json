{"cell_type":{"2ce41a84":"code","74ee3f42":"code","8eaf94a6":"code","f417f761":"code","42dc8f1a":"code","44da66dd":"code","f9b433af":"code","d832c4dd":"code","721c1b5d":"code","2066e513":"code","390bddeb":"code","4673ffe2":"code","8443e279":"code","2636c42d":"code","e1c51545":"code","d9178a41":"code","9f544d7d":"code","d5768eef":"code","3eda9c65":"code","cb04bf4a":"code","773c8c6f":"code","59086a7c":"code","8db1a8dd":"code","dd61b58a":"code","e8d8e5e5":"code","8fd185ae":"code","9137e558":"code","736ce5b9":"code","3df7e479":"code","5b229b5f":"code","a3a9cfd7":"code","8bc754eb":"code","1353c720":"code","934ab196":"code","75971c73":"code","7ffd9b14":"code","05f3271e":"code","2fc44d65":"code","2462257d":"code","105357e6":"code","887686e4":"code","48e3a35b":"code","449daf0a":"code","63f3edae":"code","4d40294f":"code","fce7b1aa":"code","a85a182a":"code","096d28c8":"code","1ebdca84":"code","7a678ba2":"code","7776f7bb":"code","54268174":"code","ba89b13d":"code","a3b5f144":"code","78eb2812":"code","23465541":"code","303eab5c":"code","dacbc549":"code","aa6c1311":"code","fe274663":"code","77f4904b":"code","bb31b0ff":"code","b48eb558":"code","4b90ce67":"code","25763b8d":"code","06c1c615":"code","e669dc03":"code","33f22ad5":"code","915fa424":"code","62b29ab1":"markdown","fa7cc8a2":"markdown","1b10fb30":"markdown","942cf32c":"markdown","d70dbe89":"markdown","3765cee8":"markdown","935fa2cb":"markdown","c046896c":"markdown","085f808e":"markdown","d99b0551":"markdown","d995d002":"markdown","4abdeac0":"markdown","8636c8b9":"markdown","bc8542ce":"markdown"},"source":{"2ce41a84":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfrom mpl_toolkits.mplot3d import Axes3D\nimport statsmodels.api as sm\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom scipy.stats import levene\nfrom scipy.stats import shapiro\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import ShuffleSplit, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import tree\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nimport os\nimport os.path\nfrom pathlib import Path\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical","74ee3f42":"filterwarnings(\"ignore\", category=DeprecationWarning) \nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","8eaf94a6":"Fish = Path(\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\")\n# there are fish photos in that path","f417f761":"File_Path = list(Fish.glob(r\"**\/*.png\"))\n# all photos","42dc8f1a":"print(File_Path[0:10])","44da66dd":"Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],File_Path))\n# name of fishes","f9b433af":"print(Labels[0:10])","d832c4dd":"file = pd.Series(File_Path,name=\"Files\").astype(str)\nlabel = pd.Series(Labels,name=\"Category\")","721c1b5d":"List_Vis = []\nfor i inList_Vis\n    image = cv2.imread(i)\n    List_Vis.append(np.array(image,\"uint8\"))\n# it has a loaded conversion process","2066e513":"print(List_Vis[2:3])\n# png to array","390bddeb":"print(List_Vis.dtype)","4673ffe2":"List_Vis = pd.Series(List_Vis,name=\"Array\")","8443e279":"Vis_Data = pd.concat([List_Vis,label],axis=1)","2636c42d":"figure = plt.figure(figsize=(5,5))\nplt.imshow(Vis_Data[\"Array\"][10])","e1c51545":"figure = plt.figure(figsize=(5,5))\nplt.imshow(Vis_Data[\"Array\"][3])","d9178a41":"figure = plt.figure(figsize=(5,5))\nplt.imshow(Vis_Data[\"Array\"][54])","9f544d7d":"Main_Data = pd.concat([file,label],axis=1)","d5768eef":"print(Main_Data[\"Category\"][-2:])","3eda9c65":"Main_Data = Main_Data[Main_Data[\"Category\"].apply(lambda x: x[-2:] != \"GT\")]\n# not need GT","cb04bf4a":"print(Main_Data[\"Category\"][-2:])","773c8c6f":"Main_Data = Main_Data.sample(frac=1).reset_index(drop=True)\n# we need to shuffle it, because of perfect training","59086a7c":"print(Main_Data.head())","8db1a8dd":"print(Main_Data[\"Category\"].value_counts())\n# There are 9 different fish","dd61b58a":"plt.imshow(plt.imread(Main_Data[\"Files\"][5]))\nplt.show()","e8d8e5e5":"plt.imshow(plt.imread(Main_Data[\"Files\"][44]))\nplt.show()","8fd185ae":"train_data, test_data = train_test_split(Main_Data, train_size=0.7, shuffle=True, random_state=1)","9137e558":"print(train_data.head())","736ce5b9":"print(train_data.shape)","3df7e479":"print(train_data.columns)","5b229b5f":"print(test_data.head())","a3a9cfd7":"print(test_data.shape)","8bc754eb":"print(test_data.columns)","1353c720":"Train_Gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n                              validation_split=0.2)","934ab196":"print(Train_Gen.dtype)","75971c73":"print(Train_Gen.col_axis)","7ffd9b14":"print(Train_Gen.data_format)","05f3271e":"Test_Gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)","2fc44d65":"print(Test_Gen.dtype)","2462257d":"print(Test_Gen.col_axis)","105357e6":"print(Test_Gen.data_format)","887686e4":"Train_Img = Train_Gen.flow_from_dataframe(dataframe=train_data,\n                                         x_col=\"Files\",\n                                         y_col=\"Category\",\n                                         target_size=(224,224),\n                                         color_mode=\"rgb\",\n                                         class_mode=\"categorical\",\n                                         batch_size=32,\n                                         shuffle=True,\n                                         seed=42,\n                                         subset=\"training\")\n\nValidation_Img = Train_Gen.flow_from_dataframe(dataframe=train_data,\n    x_col='Files',\n    y_col='Category',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\n\nTest_Img = Test_Gen.flow_from_dataframe(dataframe=test_data,\n    x_col='Files',\n    y_col='Category',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","48e3a35b":"print(Train_Img.classes[0:20])","449daf0a":"print(Train_Img.dtype)","63f3edae":"print(Train_Img.split)","4d40294f":"print(Validation_Img.classes[0:20])","fce7b1aa":"print(Validation_Img.dtype)","a85a182a":"print(Validation_Img.split)","096d28c8":"print(Test_Img.classes[0:20])","1ebdca84":"print(Test_Img.dtype)","7a678ba2":"print(Test_Img.split)","7776f7bb":"Pretained_M = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n                                               include_top=False,\n                                               weights=\"imagenet\",\n                                               pooling=\"avg\")","54268174":"Pretained_M.trainable = False","ba89b13d":"print(Pretained_M.input)","a3b5f144":"print(Pretained_M.output)","78eb2812":"model = tf.keras.models.Sequential([\n  # inputs \n  tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255),\n  tf.keras.layers.Flatten(input_shape=(113,)),\n  # hiddens layers\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  # output layer\n  tf.keras.layers.Dense(9,activation=\"softmax\")\n])","23465541":"model.compile(optimizer=\"rmsprop\",\n             loss=\"categorical_crossentropy\",\n             metrics=[\"accuracy\"])","303eab5c":"Callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)","dacbc549":"ANN = model.fit(Train_Img,\n                validation_data = Validation_Img,\n                epochs = 5, callbacks=Callback)","aa6c1311":"results = model.evaluate(Test_Img)","fe274663":"print(\"LOSS:  \" + \"%.4f\" % results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % results[1])","77f4904b":"predictANN = model.predict(Test_Img)\npredictANN = [np.argmax(i) for i in predictANN]","bb31b0ff":"print(predictANN[20])","b48eb558":"print(model.summary())","4b90ce67":"plt.plot(ANN.history[\"accuracy\"])\nplt.plot(ANN.history[\"val_accuracy\"])\nplt.ylabel(\"ACC\")\nplt.legend()\nplt.show()","25763b8d":"HistoryDict = ANN.history\n\nval_losses = HistoryDict[\"val_loss\"]\nval_acc = HistoryDict[\"val_accuracy\"]\nacc = HistoryDict[\"accuracy\"]\nlosses = HistoryDict[\"loss\"]\nepochs = range(1,len(val_losses)+1)","06c1c615":"plt.plot(epochs,val_losses,\"bo\",label=\"LOSS\")\nplt.plot(epochs,val_acc,\"r\",label=\"ACCURACY\")\nplt.title(\"LOSS & ACCURACY\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"Loss & Acc\")\nplt.legend()\nplt.show()","e669dc03":"plt.plot(epochs,acc,\"bo\",label=\"ACCURACY\")\nplt.plot(epochs,val_acc,\"r\",label=\"ACCURACY VAL\")\nplt.title(\"ACCURACY & ACCURACY VAL\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"ACCURACY & ACCURACY VAL\")\nplt.legend()\nplt.show()","33f22ad5":"plt.plot(epochs,losses,\"bo\",label=\"LOSS\")\nplt.plot(epochs,val_losses,\"r\",label=\"LOSS VAL\")\nplt.title(\"LOSS & LOSS VAL\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"LOSS & LOSS VAL\")\nplt.legend()\nplt.show()","915fa424":"Dict_Summary = pd.DataFrame(ANN.history)\n\nDict_Summary.plot()","62b29ab1":"#### TRANSFORMATION TO SERIES","fa7cc8a2":"# PACKAGES AND LIBRARIES","1b10fb30":"#### SPLITTING TRAIN & TEST","942cf32c":"# ARRAY DATA","d70dbe89":"#### VISUALIZATION","3765cee8":"#### CHECKING","935fa2cb":"# PATH PROCESS","c046896c":"#### ANN MODEL","085f808e":"#### IGNORING WARNINGS","d99b0551":"**if you want you can use that, but we will use Rescaling() for ANN**","d995d002":"# DATA FOR PREDICTION \/ VERSION I","4abdeac0":"#### PRETAINED MODEL","8636c8b9":"#### IMAGE GENERATOR","bc8542ce":"##### VISUALIZATION"}}