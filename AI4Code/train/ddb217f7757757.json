{"cell_type":{"216819aa":"code","da94cd90":"code","0cbbd48a":"code","3462f7d2":"code","cb4850b6":"code","2278b17a":"code","976b868a":"markdown","609a8657":"markdown","8c9103cd":"markdown","c60dbd78":"markdown","1ee39365":"markdown","34cfa586":"markdown","30c64698":"markdown"},"source":{"216819aa":"import sys\nsys.path.append(\"..\/input\/maskrcnn-utils\/\")","da94cd90":"!pip install -U torchvision","0cbbd48a":"import collections\nimport os\nimport numpy as np\nimport torch\nimport torch.utils.data\nfrom PIL import Image, ImageFile\nimport pandas as pd\nfrom tqdm import tqdm\nfrom numba import jit\nfrom model import get_instance_segmentation_model\nimport torch\nfrom engine import train_one_epoch, evaluate\nimport utils\nimport transforms as T\nfrom tqdm import tqdm\nimport numpy as np\nimport torch\nimport pandas as pd\nfrom model import get_instance_segmentation_model\nfrom torchvision import transforms\nfrom PIL import Image\nimport itertools\n\nImageFile.LOAD_TRUNCATED_IMAGES = True","3462f7d2":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated: [start0] [length0] [start1] [length1]... in 1d array\n    shape: (height,width) of array to return\n    Returns numpy array according to the shape, 1 - mask, 0 - background\n    '''\n    shape = (shape[1], shape[0])\n    s = mask_rle.split()\n    # gets starts & lengths 1d arrays\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n    starts -= 1\n    # gets ends 1d array\n    ends = starts + lengths\n    # creates blank mask image 1d array\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    # sets mark pixles\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    # reshape as a 2d mask image\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\n\n\nclass FashionDataset(torch.utils.data.Dataset):\n    def __init__(self, image_dir, df_path, height, width, transforms=None):\n        self.transforms = transforms\n        self.image_dir = image_dir\n        self.df = pd.read_csv(df_path, nrows=10000)\n        self.height = height\n        self.width = width\n        self.image_info = collections.defaultdict(dict)\n        self.df['CategoryId'] = self.df.ClassId.apply(lambda x: str(x).split(\"_\")[0])\n        temp_df = self.df.groupby('ImageId')['EncodedPixels', 'CategoryId'].agg(lambda x: list(x)).reset_index()\n        size_df = self.df.groupby('ImageId')['Height', 'Width'].mean().reset_index()\n        temp_df = temp_df.merge(size_df, on='ImageId', how='left')\n        for index, row in tqdm(temp_df.iterrows(), total=len(temp_df)):\n            image_id = row['ImageId']\n            image_path = os.path.join(self.image_dir, image_id)\n            self.image_info[index][\"image_id\"] = image_id\n            self.image_info[index][\"image_path\"] = image_path\n            self.image_info[index][\"width\"] = self.width\n            self.image_info[index][\"height\"] = self.height\n            self.image_info[index][\"labels\"] = row[\"CategoryId\"]\n            self.image_info[index][\"orig_height\"] = row[\"Height\"]\n            self.image_info[index][\"orig_width\"] = row[\"Width\"]\n            self.image_info[index][\"annotations\"] = row[\"EncodedPixels\"]\n\n    def __getitem__(self, idx):\n        # load images ad masks\n        img_path = self.image_info[idx][\"image_path\"]\n        img = Image.open(img_path).convert(\"RGB\")\n        img = img.resize((self.width, self.height), resample=Image.BILINEAR)\n\n        info = self.image_info[idx]\n        mask = np.zeros((len(info['annotations']), self.width, self.height), dtype=np.uint8)\n        labels = []\n        for m, (annotation, label) in enumerate(zip(info['annotations'], info['labels'])):\n            sub_mask = rle_decode(annotation, (info['orig_height'], info['orig_width']))\n            sub_mask = Image.fromarray(sub_mask)\n            sub_mask = sub_mask.resize((self.width, self.height), resample=Image.BILINEAR)\n            mask[m, :, :] = sub_mask\n            labels.append(int(label) + 1)\n\n        num_objs = len(labels)\n        boxes = []\n        new_labels = []\n        new_masks = []\n\n        for i in range(num_objs):\n            try:\n                pos = np.where(mask[i, :, :])\n                xmin = np.min(pos[1])\n                xmax = np.max(pos[1])\n                ymin = np.min(pos[0])\n                ymax = np.max(pos[0])\n                if abs(xmax - xmin) >= 20 and abs(ymax - ymin) >= 20:\n                    boxes.append([xmin, ymin, xmax, ymax])\n                    new_labels.append(labels[i])\n                    new_masks.append(mask[i, :, :])\n            except ValueError:\n                continue\n\n        if len(new_labels) == 0:\n            boxes.append([0, 0, 20, 20])\n            new_labels.append(0)\n            new_masks.append(mask[0, :, :])\n\n        nmx = np.zeros((len(new_masks), self.width, self.height), dtype=np.uint8)\n        for i, n in enumerate(new_masks):\n            nmx[i, :, :] = n\n\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(new_labels, dtype=torch.int64)\n        masks = torch.as_tensor(nmx, dtype=torch.uint8)\n\n        image_id = torch.tensor([idx])\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"masks\"] = masks\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        target[\"iscrowd\"] = iscrowd\n\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.image_info)","cb4850b6":"def get_transform(train):\n    transforms = []\n    # converts the image, a PIL image, into a PyTorch Tensor\n    transforms.append(T.ToTensor())\n    if train:\n        # during training, randomly flip the training images\n        # and ground-truth for data augmentation\n        transforms.append(T.RandomHorizontalFlip(0.5))\n    return T.Compose(transforms)\n\n\nnum_classes = 46 + 1\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\ndataset_train = FashionDataset(\"..\/input\/imaterialist-fashion-2019-FGVC6\/train\/\",\n                               \"..\/input\/imaterialist-fashion-2019-FGVC6\/train.csv\",\n                               256,\n                               256,\n                               transforms=get_transform(train=True))\n\n\nmodel_ft = get_instance_segmentation_model(num_classes)\nmodel_ft.to(device)\n\ndata_loader = torch.utils.data.DataLoader(\n    dataset_train, batch_size=4, shuffle=True, num_workers=8,\n    collate_fn=lambda x: tuple(zip(*x)))\n\nparams = [p for p in model_ft.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.001,\n                            momentum=0.9, weight_decay=0.0005)\n\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                               step_size=5,\n                                               gamma=0.1)\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    train_one_epoch(model_ft, optimizer, data_loader, device, epoch, print_freq=10)\n    lr_scheduler.step()\n\ntorch.save(model_ft.state_dict(), \"model.bin\")","2278b17a":"def refine_masks(masks, labels):\n   # Compute the areas of each mask\n   areas = np.sum(masks.reshape(-1, masks.shape[-1]), axis=0)\n   # Masks are ordered from smallest to largest\n   mask_index = np.argsort(areas)\n   # One reference mask is created to be incrementally populated\n   union_mask = {k:np.zeros(masks.shape[:-1], dtype=bool) for k in np.unique(labels)}\n   # Iterate from the smallest, so smallest ones are preserved\n   for m in mask_index:\n       label = labels[m]\n       masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask[label]))\n       union_mask[label] = np.logical_or(masks[:, :, m], union_mask[label])\n   # Reorder masks\n   refined = list()\n   for m in range(masks.shape[-1]):\n       mask = masks[:, :, m].ravel(order='F')\n       rle = to_rle(mask)\n       label = labels[m] - 1\n       refined.append([masks[:, :, m], rle, label])\n   return refined\n\n\nnum_classes = 46 + 1\n\ndataset_test = FashionDataset(\"..\/input\/imaterialist-fashion-2019-FGVC6\/test\/\", \n                              \"..\/input\/imaterialist-fashion-2019-FGVC6\/sample_submission.csv\", 512, 512,\n                              transforms=None)\n\nsample_df = pd.read_csv(\"..\/input\/imaterialist-fashion-2019-FGVC6\/sample_submission.csv\")\n\n\nmodel_ft = get_instance_segmentation_model(num_classes)\nmodel_ft.load_state_dict(torch.load(\"model.bin\"))\nmodel_ft = model_ft.to(device)\n\nfor param in model_ft.parameters():\n    param.requires_grad = False\n\nmodel_ft.eval()\n\n\nsub_list = []\nmissing_count = 0\nsubmission = []\nctr = 0\n\ntk0 = tqdm(range(3200))\ntt = transforms.ToTensor()\nfor i in tk0:\n    img = dataset_test[i]\n    img = tt(img)\n    result = model_ft([img.to(device)])[0]\n    masks = np.zeros((512, 512, len(result[\"masks\"])))\n    for j, m in enumerate(result[\"masks\"]):\n        res = transforms.ToPILImage()(result[\"masks\"][j].permute(1, 2, 0).cpu().numpy())\n        res = np.asarray(res.resize((512, 512), resample=Image.BILINEAR))\n        masks[:, :, j] = (res[:, :] * 255. > 127).astype(np.uint8)\n\n    lbls = result['labels'].cpu().numpy()\n    scores = result['scores'].cpu().numpy()\n\n    best_idx = 0\n    for scr in scores:\n      if scr > 0.8:\n        best_idx += 1\n\n    if best_idx == 0:\n      sub_list.append([sample_df.loc[i, 'ImageId'], '1 1', 23])\n      missing_count += 1\n      continue\n\n    if masks.shape[-1] > 0:\n        #lll = mask_to_rle(masks[:, :, :4], scores[:4], lbls[:4])\n        masks = refine_masks(masks[:, :, :best_idx], lbls[:best_idx])\n        for m, rle, label in masks:\n            sub_list.append([sample_df.loc[i, 'ImageId'], ' '.join(list(map(str, list(rle)))), label])\n    else:\n        sub_list.append([sample_df.loc[i, 'ImageId'], '1 1', 23])\n        missing_count += 1\n\nsubmission_df = pd.DataFrame(sub_list, columns=sample_df.columns.values)\nprint(\"Total image results: \", submission_df['ImageId'].nunique())\nprint(\"Missing Images: \", missing_count)\nsubmission_df = submission_df[submission_df.EncodedPixels.notnull()]\nfor row in range(len(submission_df)):\n   line = submission_df.iloc[row,:]\n   submission_df.iloc[row, 1] = line['EncodedPixels'].replace('.0','')\nsubmission_df.head()\nsubmission_df.to_csv(\"submission.csv\", index=False)","976b868a":"### get torchvision utils for mask-rcnn","609a8657":"### import everything useful","8c9103cd":"### result\n\nTo run the code properly, download the attached dataset and run it locally instead of kaggle kernels. :) \n\nThe approach wont give you 0.17+ directly. It requires very small modifications to get that kind of score. I\u2019ll leave those modifcations as an exercise to the reader.\n\nIf you have any questions, feel free to ask.","c60dbd78":"### install latest torchvision","1ee39365":"### create dataset class for getting batches of images","34cfa586":"### train the model","30c64698":"### make predictions"}}