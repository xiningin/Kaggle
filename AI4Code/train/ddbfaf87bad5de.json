{"cell_type":{"4804df9e":"code","57e4b246":"code","5513703b":"code","362ed404":"code","5b9a5601":"code","fb77fab3":"code","6ba0c2ed":"code","5ef1514d":"code","4bd84bfe":"code","4ca9de63":"code","36227a56":"code","809f8654":"code","306b690d":"code","d8f108da":"code","b8ea1353":"code","1b7d6bc0":"code","28a9995e":"code","eaa6ffdf":"code","594dc6f2":"code","2c17a90b":"code","e8402b62":"code","38b52488":"code","2a8396b9":"code","ba407e37":"code","5080bad5":"code","371c3111":"code","2529cb95":"code","6f53e5df":"code","1e0e0d71":"code","0922fbbc":"code","61dd718b":"code","f9d05961":"code","e74e415b":"markdown","9f6771db":"markdown","92cf5141":"markdown","52d4d7a7":"markdown","cb591845":"markdown","893b2bf5":"markdown","acd48c10":"markdown","da99fde7":"markdown","844cb166":"markdown"},"source":{"4804df9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","57e4b246":"import re\nimport numpy as np\nimport pandas as pd\nimport nltk\nimport keras\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nimport plotly.express as px\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\npd.options.display.max_colwidth = 1000\npd.options.display.max_rows  = 100\npd.set_option(\"display.min_rows\", 200)\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(mode='min',patience=5)\n","5513703b":"train = pd.read_csv(\"..\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv\",encoding='latin-1')\ntrain_data = train[[\"OriginalTweet\",\"Sentiment\"]]","362ed404":"print(\"Ccunt Of Labels : {} \".format(train_data.Sentiment.value_counts().to_dict()))\nprint(\"Total number of Labels : {}\".format(len(train_data.Sentiment.unique())))","5b9a5601":"def change_sen(sentiment):\n    if sentiment == \"Extremely Positive\":\n        return \"Positive\"\n    elif sentiment == \"Extremely Negative\":\n        return \"Negative\"\n    elif sentiment == \"Negative\":\n        return \"Negative\"\n    elif sentiment == \"Positive\":\n        return \"Positive\"\n    else:\n        return \"Neutral\"","fb77fab3":"train_data['Sentiment'] = train_data['Sentiment'].apply(lambda x : change_sen(x))\n\ncount_dict = train_data['Sentiment'].value_counts().to_dict()\nLabels = list(count_dict.keys())\nvalues = list(count_dict.values())\n","6ba0c2ed":"px.pie(values = values,names = Labels,hole=.5,title = \"Label Counts In Percentage\")","5ef1514d":"stop_words = stopwords.words('english')\ntrain_data[\"OriginalTweet\"]  = train_data['OriginalTweet'].apply(lambda x:x.lower())","4bd84bfe":"def clean_data(text):\n    text = str(text).strip()\n    text = text.replace(\"?\",\"\")\n    text = re.sub(r\"http\\S+\",\"\",text)\n    text = re.sub(r\"@\\w+\",\"\",text)\n    text = re.sub(r\"#\\w+\",\"\",text)\n    text = re.sub(r\"\\d+\",\"\",text)\n    text = re.sub(r\"<.*?>\",\"\",text)\n    text = text.split()\n    text = \" \".join([word for word in text if not word in stop_words])\n    #text - str(text).strip()\n    return text","4ca9de63":"train_data[\"OriginalTweet\"] = train_data['OriginalTweet'].apply(lambda x : clean_data(x))","36227a56":"train_data['Sentiment'].unique()\nl = dict()\nfor idx,lbl in enumerate(train_data['Sentiment'].unique()):\n    l[lbl] = idx \n    \ntrain_data['Sentiment'] = train_data['Sentiment'].map(l)\n\nmax_len = np.max(train_data['OriginalTweet'].apply(lambda x : len(x)))","809f8654":"train,test = train_test_split(train_data,test_size = 0.3)","306b690d":"X_train = train[[\"OriginalTweet\"]]\ny_train = train[[\"Sentiment\"]]\nX_test = test[['OriginalTweet']]\ny_test = test[[\"Sentiment\"]]","d8f108da":"X_train.shape,y_train.shape,X_test.shape,y_test.shape","b8ea1353":"tokenizer = Tokenizer()","1b7d6bc0":"tokenizer.fit_on_texts(X_train[\"OriginalTweet\"])\nvocab_length = len(tokenizer.word_index) + 1","28a9995e":"x_train = tokenizer.texts_to_sequences(X_train[\"OriginalTweet\"])\nx_test = tokenizer.texts_to_sequences(X_test[\"OriginalTweet\"])","eaa6ffdf":"x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\nx_test = pad_sequences(x_test, maxlen=max_len, padding='post')","594dc6f2":"print(\"Vocab length:\", vocab_length)\nprint(\"Max sequence length:\", max_len)","2c17a90b":"embedding_dim = 16","e8402b62":"model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_length,embedding_dim,input_length = max_len),\n                            tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64,return_sequences = True)), #256\n                            tf.keras.layers.GlobalAveragePooling1D(),\n                            tf.keras.layers.Dropout(0.5),\n                            tf.keras.layers.Dense(16,activation = 'relu',activity_regularizer=tf.keras.regularizers.L2(0.01)),\n                            tf.keras.layers.Dropout(0.5),\n                            tf.keras.layers.Dense(3,activation = 'softmax')])\nmodel.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])","38b52488":"model.summary()","2a8396b9":"tf.keras.utils.plot_model(model)","ba407e37":"y_train = to_categorical(y_train, 3)\ny_test = to_categorical(y_test, 3)","5080bad5":"num_epochs = 10\nhistory = model.fit(x_train, y_train, epochs=num_epochs, validation_data=(x_test, y_test))","371c3111":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","2529cb95":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","6f53e5df":"model_1 = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_length,embedding_dim,input_length = max_len),\n    tf.keras.layers.LSTM(256,return_sequences = True),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(16,activation = 'relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(3,activation = 'softmax')\n])","1e0e0d71":"model_1.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])","0922fbbc":"num_epochs = 100\nhistory = model_1.fit(x_train, y_train, epochs=num_epochs, validation_data=(x_test, y_test),callbacks=[early_stopping])","61dd718b":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","f9d05961":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e74e415b":"# Splitting Dataset","9f6771db":"# Load Dataset","92cf5141":"# **Modelling**","52d4d7a7":"# LSTM","cb591845":"# Padding (Sequences)","893b2bf5":"# Tokenizing","acd48c10":"# Bidirectional GRU","da99fde7":"# Preprocessing","844cb166":"# Import Requirements"}}