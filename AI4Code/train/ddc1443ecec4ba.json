{"cell_type":{"eaf31a2e":"code","bfb5d303":"code","cdba5bcf":"code","22c0c2d7":"code","9bd00bba":"code","0813936f":"code","e67cfa5f":"code","b41c7ac0":"code","a2ffc614":"code","69f68c7b":"code","0b9817f5":"code","e1c8e609":"code","ff9c4530":"code","c55a15b9":"code","89dcd703":"code","489facd0":"code","7e009d15":"code","3f4f21ca":"code","8b419c0e":"code","0aa00cea":"code","0c25f50a":"code","9b0ebb70":"code","1e90828e":"code","99bf998e":"code","adae76e0":"code","336c52f7":"code","efc2c3cf":"code","b1cc4361":"code","1d258520":"code","814852e6":"code","8b58c8e4":"code","cc187c4f":"code","2b0dec27":"code","2e861b1c":"code","dbb499ed":"code","00c5c7e8":"code","5bafeb4f":"code","378c782e":"code","ba94e087":"code","ba30461a":"code","25a53f36":"code","5671ed6f":"code","a7d60e24":"code","bf9f5b5a":"code","9503b590":"code","e1f3f6cf":"code","f5f9fac3":"code","a4c17ad6":"code","93088ca5":"code","96c6eef3":"code","d2f25e6b":"code","4c974a43":"code","7246f679":"code","273fe18f":"code","e1901755":"code","66da67f9":"code","03508ebe":"code","72c1d952":"code","7f09c696":"code","b55c8092":"code","7d63e06f":"code","42fd26e3":"code","acb142c4":"code","de4a5aa4":"markdown","0a1a247d":"markdown","2d1a7c6f":"markdown","3ce9f9b5":"markdown","a93aa662":"markdown","ef84d015":"markdown","4a91300b":"markdown","d22db5f5":"markdown","15448799":"markdown","3142a126":"markdown","a0021641":"markdown","149b7554":"markdown","8666f562":"markdown","c36a6054":"markdown","1cb92b08":"markdown","eaf224df":"markdown","581c2b2f":"markdown","5899ccc6":"markdown","7928e19c":"markdown","2798d38e":"markdown","4e84f76f":"markdown","7f4bf729":"markdown","505082d3":"markdown","a2589ebd":"markdown"},"source":{"eaf31a2e":"#importing libraries\n                                             \nimport pandas as pd                                    # for dataframe\nimport numpy as np                                     # for numerical operations\nfrom fancyimpute import KNN                            # for knn imputations\nfrom scipy.stats import chi2_contingency               # for scientific calculations\nimport matplotlib.pyplot as plt                        # for visualisations\nimport seaborn as sns                                  # for visualisatons\nfrom random import randrange,uniform                   # to generate random number\nfrom sklearn.model_selection import train_test_split   # for implementing stratified sampling\nfrom sklearn import tree                               # for implementing decision tree algorithm in data\nfrom sklearn.tree import export_graphviz               #  plot tree\nfrom sklearn.metrics import accuracy_score             # for implementing decision tree algorithm in data\nfrom sklearn.metrics import confusion_matrix           # for calculating error metrics of various models\nfrom sklearn.ensemble import RandomForestClassifier    # for implementing random forest model on data\nimport statsmodels.api as sn                           # for applying logistic model on data set\nfrom sklearn.neighbors import KNeighborsClassifier     # for implementing knn model\nfrom sklearn.naive_bayes import GaussianNB             # for implementing naive bayes\nfrom sklearn import model_selection                    # for selecting model\nfrom sklearn.metrics import classification_report,roc_auc_score,roc_curve # for model evaluation\nfrom sklearn.metrics import classification_report      # for model evaluation\nimport pickle                                          # for saving the final modelimport seaborn as sns #for plotting\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor  # for calculating VIF\nfrom statsmodels.tools.tools import add_constant\nnp.random.seed(123) #ensure reproducibility\npd.options.mode.chained_assignment = None  #hide any pandas warnings","bfb5d303":"hdata = pd.read_csv(\"..\/input\/heart.csv\")","cdba5bcf":"hdata.head(10)","22c0c2d7":"hdata.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']\n","9bd00bba":"hdata['sex'][hdata['sex'] == 0] = 'female'\nhdata['sex'][hdata['sex'] == 1] = 'male'\n\nhdata['chest_pain_type'][hdata['chest_pain_type'] == 1] = 'typical angina'\nhdata['chest_pain_type'][hdata['chest_pain_type'] == 2] = 'atypical angina'\nhdata['chest_pain_type'][hdata['chest_pain_type'] == 3] = 'non-anginal pain'\nhdata['chest_pain_type'][hdata['chest_pain_type'] == 4] = 'asymptomatic'\n\nhdata['fasting_blood_sugar'][hdata['fasting_blood_sugar'] == 0] = 'lower than 120mg\/ml'\nhdata['fasting_blood_sugar'][hdata['fasting_blood_sugar'] == 1] = 'greater than 120mg\/ml'\n\nhdata['rest_ecg'][hdata['rest_ecg'] == 0] = 'normal'\nhdata['rest_ecg'][hdata['rest_ecg'] == 1] = 'ST-T wave abnormality'\nhdata['rest_ecg'][hdata['rest_ecg'] == 2] = 'left ventricular hypertrophy'\n\nhdata['exercise_induced_angina'][hdata['exercise_induced_angina'] == 0] = 'no'\nhdata['exercise_induced_angina'][hdata['exercise_induced_angina'] == 1] = 'yes'\n\nhdata['st_slope'][hdata['st_slope'] == 1] = 'upsloping'\nhdata['st_slope'][hdata['st_slope'] == 2] = 'flat'\nhdata['st_slope'][hdata['st_slope'] == 3] = 'downsloping'\n\nhdata['thalassemia'][hdata['thalassemia'] == 1] = 'normal'\nhdata['thalassemia'][hdata['thalassemia'] == 2] = 'fixed defect'\nhdata['thalassemia'][hdata['thalassemia'] == 3] = 'reversable defect'\n\nhdata['target'][hdata['target'] == 0] = 'no'\nhdata['target'][hdata['target'] == 1] = 'yes'\n\n","0813936f":"#Encoding Variable\n#Assigning levels to the categories\nlis = []\nfor i in range(0, hdata.shape[1]):\n    if(hdata.iloc[:,i].dtypes == 'object'):\n        hdata.iloc[:,i] = pd.Categorical(hdata.iloc[:,i])\n        hdata.iloc[:,i] = hdata.iloc[:,i].cat.codes \n        hdata.iloc[:,i] = hdata.iloc[:,i].astype('object')\n        lis.append(hdata.columns[i])\n","e67cfa5f":"sns.countplot(x=\"target\", data=hdata, palette=\"bwr\")\nplt.show()","b41c7ac0":"countNoDisease = len(hdata[hdata.target == 0])\ncountHaveDisease = len(hdata[hdata.target == 1])\nprint(\"Percentage of Patients Haven't Heart Disease: {:.2f}%\".format((countNoDisease \/ (len(hdata.target))*100)))\nprint(\"Percentage of Patients Have Heart Disease: {:.2f}%\".format((countHaveDisease \/ (len(hdata.target))*100)))\n","a2ffc614":"countFemale = len(hdata[hdata.sex == 0])\ncountMale = len(hdata[hdata.sex == 1])\nprint(\"Percentage of Female Patients: {:.2f}%\".format((countFemale \/ (len(hdata.sex))*100)))\nprint(\"Percentage of Male Patients: {:.2f}%\".format((countMale \/ (len(hdata.sex))*100)))\n","69f68c7b":"hdata.groupby('target').mean()\n","0b9817f5":"pd.crosstab(hdata.age,hdata.target).plot(kind=\"bar\",figsize=(20,6))\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.savefig('heartDiseaseAndAges.png')\nplt.show()","e1c8e609":"pd.crosstab(hdata.sex,hdata.target).plot(kind=\"bar\",figsize=(15,6),color=['blue','#AA1111' ])\nplt.title('Heart Disease Frequency for Sex')\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","ff9c4530":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='cholesterol',y='thalassemia',data=hdata,hue='target')\nplt.show()","c55a15b9":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='thalassemia',y='resting_blood_pressure',data=hdata,hue='target')\nplt.show()","89dcd703":"plt.scatter(x=hdata.age[hdata.target==1], y=hdata.thalassemia[(hdata.target==1)], c=\"green\")\nplt.scatter(x=hdata.age[hdata.target==0], y=hdata.thalassemia[(hdata.target==0)])\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Maximum Heart Rate\")\nplt.show()","489facd0":"pd.crosstab(hdata.fasting_blood_sugar,hdata.target).plot(kind=\"bar\",figsize=(15,6),color=['#FFC300','#581845' ])\nplt.title('Heart Disease Frequency According To FBS')\nplt.xlabel('FBS - (Fasting Blood Sugar > 120 mg\/dl) (1 = true; 0 = false)')\nplt.xticks(rotation = 0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency of Disease or Not')\nplt.show()","7e009d15":"hdata.dtypes","3f4f21ca":"#### Missing Value Analysis\nhdata.isnull().sum()","8b419c0e":"hdata.head(10)","0aa00cea":"# checking statistical values of dataset\nhdata.describe()","0c25f50a":"# store numeric variables in cnames\ncnames=['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression','num_major_vessels']","9b0ebb70":"# Plot boxplot to visualise outliers\n%matplotlib inline\nplt.boxplot(hdata['resting_blood_pressure'])","1e90828e":"# Detect outliers and replace with NA\n\nfor i in cnames:\n    #print(i)\n    q75,q25=np.percentile(hdata.loc[:,i],[75,25])  # extract quartiles \n    iqr=q75-q25                                         # calculate IQR\n    minimum=q25-(iqr*1.5)                               # calculate inner and outer frames\n    maximum=q75+(iqr*1.5)\n    \n    #print(minimum)\n    #print(maximum)\n    hdata.loc[hdata.loc[:,i] < minimum, i] = np.nan\n    hdata.loc[hdata.loc[:,i] > maximum, i] = np.nan\n\n    missing_value=pd.DataFrame(hdata.isnull().sum())   # calculating missing values","99bf998e":"hdata=pd.DataFrame(KNN(k=3).fit_transform(hdata),columns=hdata.columns)  #performing knn imputation\nhdata.isnull().sum()    ","adae76e0":"##Correlation analysis\n#Correlation plot\ndf_corr = hdata.loc[:,cnames]\ndf_corr","336c52f7":"#Set the width and hieght of the plot\nf, ax = plt.subplots(figsize=(7, 5))\n\n#Generate correlation matrix\ncorr = df_corr.corr()\n\n#Plot using seaborn library\nsns.heatmap(corr, annot = True, cmap='coolwarm',linewidths=.1)\nplt.show()","efc2c3cf":"X = add_constant(hdata)\npd.Series([variance_inflation_factor(X.values, i) \n               for i in range(X.shape[1])], \n              index=X.columns)\n","b1cc4361":"# Normality Check\n%matplotlib inline\nplt.hist(hdata['chest_pain_type'],bins='auto')\n","1d258520":"plt.hist(hdata['age'],bins='auto')","814852e6":"#Normalisation\nfor i in cnames:\n    #print(i)\n    hdata[i]=(hdata[i]-np.min(hdata[i]))\/(np.max(hdata[i])-np.min(hdata[i]))","8b58c8e4":"hdata.head(10)","cc187c4f":"# replace target variable  with yes or no\nhdata['target'] = hdata['target'].replace(0, 'No')\nhdata['target'] = hdata['target'].replace(1, 'Yes')","2b0dec27":"# to handle data imbalance issue we are dividing our dataset on basis of stratified sampling\n# divide data into train and test\nX=hdata.values[:,0:13]\nY=hdata.values[:,13]\nX_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2)","2e861b1c":"# Decision tree - we will build the model on train data and test it on test data\nC50_model = tree.DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n# predict new test cases\nC50_Predictions = C50_model.predict(X_test) # applying decision tree model on test data set\n","dbb499ed":"data1=hdata.drop(['target'],axis=1)","00c5c7e8":"#Create dot file to visualise tree  #http:\/\/webgraphviz.com\/\ndotfile = open(\"pt.dot\", 'w')\ndf = tree.export_graphviz(C50_model, out_file=dotfile,feature_names=data1.columns)","5bafeb4f":"# Confusion matrix of decision tree\nCM = pd.crosstab(y_test, C50_Predictions)\nCM","378c782e":"#let us save TP, TN, FP, FN\nTN=CM.iloc[0,0]\nFP=CM.iloc[0,1]\nFN=CM.iloc[1,0]\nTP=CM.iloc[1,1]","ba94e087":"#check accuracy of model\naccuracy=((TP+TN)*100)\/(TP+TN+FP+FN)\naccuracy","ba30461a":"# check false negative rate of the model\nfnr=FN*100\/(FN+TP)\nfnr","25a53f36":"print(classification_report(y_test,C50_Predictions))","5671ed6f":"RF_model = RandomForestClassifier(n_estimators = 700).fit(X_train, y_train)\nRF_model","a7d60e24":"# Apply RF on test data to check accuracy\nRF_Predictions = RF_model.predict(X_test)\n# To evaluate performance of any classification model we built confusion metrics\nCM =pd.crosstab(y_test, RF_Predictions)\nCM","bf9f5b5a":"#let us save TP, TN, FP, FN\nTN=CM.iloc[0,0]\nFP=CM.iloc[0,1]\nFN=CM.iloc[1,0]\nTP=CM.iloc[1,1]","9503b590":"#check accuracy of model\naccuracy=((TP+TN)*100)\/(TP+TN+FP+FN)\naccuracy","e1f3f6cf":"# check  of the model\nfnr=FN*100\/(FN+TP)\nfnr","f5f9fac3":"print(classification_report(y_test,RF_Predictions))","a4c17ad6":"# knn implementation\nknn_model=KNeighborsClassifier(n_neighbors=4).fit(X_train,y_train)\n","93088ca5":"# predict knn_predictions \nknn_predictions=knn_model.predict(X_test)","96c6eef3":"# build confusion metrics\nCM=pd.crosstab(y_test,knn_predictions)\nCM","d2f25e6b":"# try K=1 through K=25 and record testing accuracy\nk_range = range(1, 26)\n\n# We can create Python dictionary using [] or dict()\nscores = []\nfrom sklearn import metrics\n# We use a loop through the range 1 to 26\n# We append the scores in the dictionary\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    scores.append(metrics.accuracy_score(y_test, y_pred))\n\nprint(scores)","4c974a43":"#let us save TP, TN, FP, FN\nTN=CM.iloc[0,0]\nFP=CM.iloc[0,1]\nFN=CM.iloc[1,0]\nTP=CM.iloc[1,1]","7246f679":"#check accuracy of model\naccuracy=((TP+TN)*100)\/(TP+TN+FP+FN)\naccuracy","273fe18f":"# check false negative rate of the model\nfnr=FN*100\/(FN+TP)\nfnr","e1901755":"print(classification_report(y_test,knn_predictions))","66da67f9":"# Naive Bayes implementation\nNB_model=GaussianNB().fit(X_train,y_train)","03508ebe":"# predict test cases \nNB_predictions=NB_model.predict(X_test)","72c1d952":"# build confusion metrics\nCM=pd.crosstab(y_test,NB_predictions)\nCM","7f09c696":"#let us save TP, TN, FP, FN\nTN=CM.iloc[0,0]\nFP=CM.iloc[0,1]\nFN=CM.iloc[1,0]\nTP=CM.iloc[1,1]","b55c8092":"#check accuracy of model\naccuracy=((TP+TN)*100)\/(TP+TN+FP+FN)\naccuracy","7d63e06f":"# check false negative rate of the model\nfnr=FN*100\/(FN+TP)\nfnr","42fd26e3":"print(classification_report(y_test,NB_predictions))","acb142c4":"methods = [ \"C50_model\",\"RF_model\",\"knn_model\",\"NB_model\"]\naccuracy = [75.4,75.4,77.0, 73.7]\ncolors = [\"purple\", \"magenta\",\"#CFC60E\",\"#0FBBAE\"]\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel(\"Accuracy %\")\nplt.xlabel(\"Algorithms\")\nsns.barplot(x=methods, y=accuracy, palette=colors)\nplt.show()","de4a5aa4":"**KNN MODEL**","0a1a247d":"Fitting of decision tree model to data set","2d1a7c6f":"From this we can predict that data is not uniformly distributed so we will go for normalisation","3ce9f9b5":"**MODEL DEVELOPMENT**","a93aa662":"Let fit the knn model in dataset","ef84d015":"Exploratory Data Analysis.\nconverting some variables to proper data types to improve interpretation","4a91300b":"Fitting of random forest model to dataset","d22db5f5":"**NAIVE BAYES**","15448799":"DECISION TREE","3142a126":"Now we evaluate the model","a0021641":"**Scatterplot **for thalassemia vs. resting_blood_pressure","149b7554":"**CLASSIFICATION REPORT**","8666f562":" **CLASSIFICATION REPORT**","c36a6054":"**DIAGNOSING HEART DISEASES**","1cb92b08":"**CLASSIFICATION REPORT******","eaf224df":"**COMPARING MODELS**","581c2b2f":"**CLASSIFICATION REPORT**","5899ccc6":"**Scatter plot** for thalassemia and cholesterol","7928e19c":"Loading the data","2798d38e":"**FEATURE SELECTION**","4e84f76f":"In this data set all variables are equally important. No need to drop any variable from data set.","7f4bf729":"**Outlier Analysis****","505082d3":"**RANDOM FOREST**","a2589ebd":"It's a clean, easy to understand set of data. However, the meaning of some of the column headers are not obvious. Here's what they mean,\n\n1. age: The person's age in years\n2. sex: The person's sex (1 = male, 0 = female)\n3. cp: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n4. trestbps: The person's resting blood pressure (mm Hg on admission to the hospital)\n5. chol: The person's cholesterol measurement in mg\/dl\n6. fbs: The person's fasting blood sugar (> 120 mg\/dl, 1 = true; 0 = false)\n7. restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n8. thalach: The person's maximum heart rate achieved\n9. exang: Exercise induced angina (1 = yes; 0 = no)\n10. oldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)\n11. slope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n12. ca: The number of major vessels (0-3)\n13. thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n14. target: Heart disease (0 = no, 1 = yes)\nTo avoid  Hypothesizing  I'm going to take a look at online guides on how heart disease is diagnosed, and look up some of the terms above.\n\nDiagnosis: The diagnosis of heart disease is done on a combination of clinical signs and test results. The types of tests run will be chosen on the basis of what the physician thinks is going on 1, ranging from electrocardiograms and cardiac computerized tomography (CT) scans, to blood tests and exercise stress tests 2.\n\nLooking at information of heart disease risk factors led me to the following: high cholesterol, high blood pressure, diabetes, weight, family history and smoking 3. According to another source 4, the major factors that can't be changed are: increasing age, male gender and heredity. Note that thalassemia, one of the variables in this dataset, is heredity. Major factors that can be modified are: Smoking, high cholesterol, high blood pressure, physical inactivity, and being overweight and having diabetes. Other factors include stress, alcohol and poor diet\/nutrition.\n\nI can see no reference to the 'number of major vessels', but given that the definition of heart disease is \"...what happens when your heart's blood supply is blocked or interrupted by a build-up of fatty substances in the coronary arteries\", it seems logical the more major vessels is a good thing, and therefore will reduce the probability of heart disease.\n\nGiven the above, I would hypothesis that, if the model has some predictive ability, we'll see these factors standing out as the most important.\n\nLet's change the column names to be a bit clearer,\n"}}