{"cell_type":{"48fb5854":"code","709fea0c":"code","25cd54c6":"code","a584e2fe":"code","b0043b04":"code","6e71179e":"code","08abe717":"code","5501b450":"code","3f5bdabc":"code","133f4373":"code","ba2c182b":"code","073be458":"code","fe6c18df":"code","9cdb338d":"code","942652d1":"code","172924b3":"code","99e1ec36":"code","1f6908ed":"code","c8897acd":"code","65bd496e":"code","bfbc0873":"code","8d6aa3af":"code","b21be9b4":"code","690b449e":"code","87d4b191":"code","aaeb006d":"code","03e4b428":"code","7f17e1cf":"code","92f14c7f":"code","a0539384":"code","a0391a94":"code","fdac7285":"markdown","02af656e":"markdown","bf2af998":"markdown","e802549c":"markdown","7b4c5529":"markdown","0f68a322":"markdown","2b8e2c3c":"markdown","23956116":"markdown","850a1d8b":"markdown","0fc576db":"markdown","a5e02280":"markdown","2648e860":"markdown","1a86e95b":"markdown","2225bc38":"markdown","440836c4":"markdown","1264e14e":"markdown","629b90c3":"markdown","9440dcc6":"markdown","cfe370b5":"markdown","1990e832":"markdown"},"source":{"48fb5854":"# Checking the files available in this notebook \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","709fea0c":"### Importing the general libraries we shall use in this notebook\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # plotting library that use matplot in background\nimport matplotlib.pyplot as plt # to plot some parameters in seaborn\n\n# Reading the dataset\ndataset = pd.read_csv('..\/input\/german-credit-data-with-risk\/german_credit_data.csv', index_col=None)","25cd54c6":"dataset.head()","a584e2fe":"# Cleaning up the dataset\ndataset = dataset.drop('Unnamed: 0', axis='columns')\ndataset.head()","b0043b04":"# How much data do we have?\nprint(f'Our dataset has {dataset.shape[0]} rows and {dataset.shape[1]} columns')\n\n# Do we have any missing data?\nprint(dataset.info())\n\n# What are the types of features (numerical vs categorical) ?\n\n\n# What is the distribution of the target variable? \ndataset['Risk'].value_counts()\n","6e71179e":"sns.set_context('talk', font_scale=.9)\n# Example of types of analysis that can be done\n\n# Count plot helps us visualize the number of elements per category\nsns.countplot(data=dataset, x='Job', hue='Risk')\nplt.show()\n\n# Box plot helps us see the mean value of a category \"Sex\" per \"Age\" in our dataset\nsns.catplot(data=dataset, x='Sex', y='Age', kind='box')\nplt.show()\n\n# Split violin plots help us contrast the distribution across a hue value \"Risk\"\nsns.violinplot(data=dataset, x='Sex', y='Age', hue='Risk', split=True)\nplt.show()\n\n# Displot help us visualize the distribution with histograms\nsns.displot(data=dataset, row='Sex', y='Age', col='Risk')\nplt.show()","08abe717":"# Write your code here (you can reuse\/copy most of the code used in the \"Gender analysis\" and replace some of the target variables)\n# Displot help us visualize the distribution with histograms\n# sns.displot(data=dataset, row='Purpose', y='Credit amount', col='Risk')\n# plt.show()\n\nsns.countplot(data=dataset, x='Housing', hue='Sex')\nplt.show()\n","5501b450":"# Could age be better represented?\n\n# Let's see how age is distributed\nsns.displot(dataset['Age'])\nplt.show()\n\n#Let us split age into categories\ninterval = (18, 25, 35, 60, 120)\ncats = ['Young Adult', 'Adult', 'Senior', 'Elder']\ndataset[\"Age_cat\"] = pd.cut(dataset['Age'], interval, labels=cats)","3f5bdabc":"dataset.head()","133f4373":"# Could Credit Amount be better represented?\n\n# Let's see how is credit amount distributed\nsns.displot(dataset['Credit amount'])\nplt.show()\n\n# Another way to represent long tail numerical distributions is to transform them\n# using e.g., a log function\nsns.displot(np.log10(dataset['Credit amount']))\nplt.show()\n\n# Apply the new distribution to the dataset\ndataset['Credit amount'] = np.log10(dataset['Credit amount'])","ba2c182b":"dataset.head()","073be458":"# Dealing with Missing values of Saving account and Checking account\ndataset['Saving accounts'] = dataset['Saving accounts'].fillna('no_inf')\ndataset['Checking account'] = dataset['Checking account'].fillna('no_inf')","fe6c18df":"dataset.head()","9cdb338d":"# Sci-kit learn has a proper OneHotEncoder which we could use as part of our pipeline. However, \n# for exploration reasons, the OneHotEncoder of Sci-kit learner does not keep track of what value\n\ndef one_hot_encoder(df, column_name, exclude_col = False):\n    merged_df = df.merge(pd.get_dummies(df[column_name], drop_first=False, prefix=column_name), left_index=True, right_index=True)\n    if exclude_col:\n        del merged_df[column_name] # Exclude the original column\n    return merged_df","942652d1":"# Let us see our columns before we apply the one-hot-encoding\ndataset.columns","172924b3":"# Given the change is more meaningful, let us copy to another dataset (we can always compare them both at a later time)\ndataset_ready = dataset.copy()\n\n\n# category_features = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Risk'] #'Age_cat']\n\n# Note to DIEGO: Uncomment this line of code to include the age category\ncategory_features = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Risk', 'Age_cat']\n\nfor cat in category_features:\n    dataset_ready = one_hot_encoder(dataset_ready, cat, exclude_col=True)","99e1ec36":"# Let us inspect how the categorical features have not been expanded in each column \ndataset_ready.columns\n\ndataset_ready.head()","1f6908ed":"# Importing the libraries we will use in this part of the class\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score # to split the data\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report, f1_score, precision_score, recall_score #To evaluate our model\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Algorithmns models to be compared\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\n# TODO: Add here any new model you may want to try out (ANN, etc.)\n\n# Creating the X and y variables\ndataset_ready_x = dataset_ready.drop(['Risk_bad', 'Risk_good', 'Age', 'Sex_male'], axis='columns')\nX = dataset_ready_x.values\nfeature_names = dataset_ready_x.columns\n\ny = dataset_ready['Risk_bad'].values\n\n# Spliting X and y into train and test version\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)","c8897acd":"# Experiment with different models \nclassifier = LogisticRegression(solver='liblinear')\n# classifier = KNeighborsClassifier()\n# classifier = DecisionTreeClassifier()\n# classifier = GaussianNB()\n# classifier = RandomForestClassifier()\n# classifier = SVC()\n# classifier = MLPClassifier()\n# classifier = XGBClassifier()\n# classifier = [...]\n\nclassifier_name = classifier.__class__.__name__\n\nscoring_type = 'accuracy'\nkfold = KFold(n_splits=5, random_state=42, shuffle=True) # Ensuring all methods are evaluated on the same fold\n\nscore = cross_val_score(classifier, X_train, y_train, cv=kfold, scoring=scoring_type)\nprint(f'Average {scoring_type} performance of the {classifier_name} model = {np.mean(score)}')\n    ","65bd496e":"#Testing the model \n#Predicting using our model\n\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\n\n# Check the obtained results\nprint(f\"Accuracy of our model's prediction {accuracy_score(y_test,y_pred)}\")","bfbc0873":"from sklearn.dummy import DummyClassifier\n\nstrategies = ['most_frequent', 'uniform', 'stratified']\n\nfor strategy in strategies:\n\n    dummy_clf = DummyClassifier(strategy=strategy)\n    dummy_clf.fit(X_train, y_train)\n\n    #Testing the dummy model \n    y_pred = dummy_clf.predict(X_test)\n\n    # Check the obtained results\n    print(f'Performance of a baseline using the {strategy}, Accuracy = {accuracy_score(y_test,y_pred)} ')","8d6aa3af":"#Testing the model \n#Predicting using our  model\ny_pred = classifier.predict(X_test)\n\n# Check the obtained results\nprint(f\"\"\"Performance of our choosen model: \n      \\t Accuracy = {accuracy_score(y_test, y_pred)} \n      \\t Precision = {precision_score(y_test,y_pred)} \n      \\t Recall = {recall_score(y_test, y_pred)} \n      \\t F1 = {f1_score(y_test, y_pred)}\"\"\")\n\n# print(classification_report(y_test, y_pred))\n        \nstrategies = ['most_frequent', 'uniform', 'stratified']\n\nprint(f'\\nDUMMY Classifiers (Baseline)')\nfor strategy in strategies:\n\n    dummy_clf = DummyClassifier(strategy=strategy)\n    dummy_clf.fit(X_train, y_train)\n\n    #Testing the dummy model \n    y_pred_dummy = dummy_clf.predict(X_test)\n\n    # Check the obtained results\n    print(f\"\"\"Performance of {strategy} baseline: \n          Accuracy = {accuracy_score(y_test, y_pred_dummy)} \n          Precision = {precision_score(y_test,y_pred_dummy)} \n          Recall = {recall_score(y_test, y_pred_dummy)} \n          F1 = {f1_score(y_test, y_pred_dummy)}\"\"\")","b21be9b4":"# Plot the confusion matrix\nplot_confusion_matrix(classifier, X_test, y_test)","690b449e":"#Seting the Hyper Parameters\n# param_grid = {\"penalty\": ['none', 'l2', 'l1', 'elasticnet'],\n#               \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n#               \"max_iter\": [100, 300]}\n\n# #Creating the classifier\n# model = LogisticRegression()\n\n# grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='f1', verbose=1)\n# grid_search.fit(X_train, y_train)","87d4b191":"# print(grid_search.best_score_)\n# print(grid_search.best_params_)","aaeb006d":"# best_model = LogisticRegression(penalty='none', solver='sag', max_iter=300)\n\n# # training with the best params\n# best_model.fit(X_train, y_train)\n\n# # testing\n# y_pred = best_model.predict(X_test)\n\n# # Check the obtained results\n# print(f1_score(y_test,y_pred))\n# print(confusion_matrix(y_test, y_pred))\n# print(classification_report(y_test, y_pred))","03e4b428":"from sklearn.inspection import permutation_importance\n\n# Using the permutation importance method (test set)\nresult = permutation_importance(\n    classifier, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n)\nsorted_idx = result.importances_mean.argsort()\n\nfig, ax = plt.subplots()\nfig.set_size_inches(18.5, 10.5)\nax.boxplot(\n    result.importances[sorted_idx].T, vert=False, labels=feature_names\n)\nax.set_title(\"Permutation Importances (test set)\")\nfig.tight_layout()\nplt.show()\n","7f17e1cf":"# Using the permutation importance method (test set)\nresult = permutation_importance(\n    classifier, X_train, y_train, n_repeats=10, random_state=42, n_jobs=2\n)\nsorted_idx = result.importances_mean.argsort()\n\nfig, ax = plt.subplots()\nfig.set_size_inches(18.5, 10.5)\nax.boxplot(\n    result.importances[sorted_idx].T, vert=False, labels=feature_names\n)\nax.set_title(\"Permutation Importances (train set)\")\nfig.tight_layout()\nplt.show()","92f14c7f":"import eli5\n\neli5.show_weights(classifier, feature_names=feature_names.values, top=100)","a0539384":"classifier.predict(X_test[0:2])","a0391a94":"eli5.show_prediction(classifier, X_test[0], feature_names=feature_names.values, show_feature_values=True)","fdac7285":"# Context: German Credit Report\n\nThe original dataset contains entries with 20 categorial\/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The original dataset can be found [here](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Statlog+%28German+Credit+Data%29)\n\nWe will use a simplified version of the dataset with only **9 features** in our class. ","02af656e":"# A few words about the Kaggle's Python Environment\n\nThe python environment in Kaggle already comes with many helpful analytics libraries:\n- Numpy\n- Pandas\n- Matplotlib\n- Seaborn\n- SKLearn\n- ELI5\n\nThe environment is defined by the `kaggle\/python` Docker image. If you want to learn more on what is the configuration of the cloud image you are running your code, please check the [GitHub repository](https:\/\/github.com\/kaggle\/docker-python).\n\n## Input\n\nThere is only one file available for reading in this notebook, the **German Credit dataset** we will use in our hands-on session. \nThe dataset is available at `\/kaggle\/input\/german-credit-data-with-risk\/german_credit_data.csv`.\n\n## Saving data\n\nYou can write up to **20 GB** to the current directory`kaggle\/working` that gets preserved across sessions. That is, next time you open this notebook and start the session, the file will be available to you.\n\nYou can also write temporary files to `\/kaggle\/temp\/`, but they won't be saved outside of the current session\n\n## Helpful shortcuts\n\nAll the shortcuts below work when the target cell is selected (not when editing). \n- a: To insert cell above\n- b: To insert cell below   \n- dd: To delete cell\n- m: Change the cell to markdown \n- y: Change the cell to code\n\nFor more shortcuts, please check this [notebook](https:\/\/www.kaggle.com\/naushads\/keyboard-shortcuts-for-kaggle-kernels).\n","bf2af998":"### Exploring why the model predicts certain classes\n\nNow that we explored the most important features of the model, we can also try to explain **why** the model predicts certain classes for some records.","e802549c":"# Part 7. Re-evaluating the performance of models - Exploring other performance metrics\n\nLet us try to evaluate our model using other performance metrics:\n- Precision\n- Recall\n- F1 score (harmonic mean between precision and recall)","7b4c5529":"## Part 1: Exploring the dataset\n\n1. Explore the dataset features and the target variable\n - How much data do we have?\n - Do we have any missing data? (NaN)\n - What are the types of features in our dataset?\n - How is the distribution of the target variable?\n\nTip: Check out the [Pandas API](https:\/\/pandas.pydata.org\/) for functions that can help with data exploration.\n ","0f68a322":"Now, let us set up some dummy baselines perform when predicting the test data:\n- **Most Frequent:** Compare against a model that always predicts \"good\" risk\n- **Uniform:** Compare against a model that predicts 50 \/ 50 good and bad risk (toss of a coin) \n- **Stratified:** Compare against a model that predicts 70% good and 30% bad (randomly) ","2b8e2c3c":"Then, we will experiment with several models to choose a few appropriate ones. Here are the models we shall experiment with:\n- [RandomForestClassifier](https:\/\/scikit-learn.org\/stable\/modules\/ensemble.html#forests-of-randomized-trees)\n- [LogisticRegression](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n- [DecisionTreeClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n- [KNeighborsClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n- [GaussianNB](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n- [Support Vector Machine Classifier (SVC)](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html#sklearn.svm.SVC)\n- [MLPClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html)\n- [XGBoost](https:\/\/xgboost.readthedocs.io\/en\/stable\/python\/python_api.html#module-xgboost.sklearn)\n- More classifiers can be found [here](https:\/\/scikit-learn.org\/stable\/supervised_learning.html#supervised-learning)","23956116":"# Part 3. Preparing the dataset for our Modeling (Feature Engineering) (Together)\n\nNow that we have explored some of the features our dataset contains, we should evaluate their quality and the potential for extracting more informative features by applying some domain knowledge, or combining features together. \n\n- Are there features that could be better represented?\n- Can we extract other features based on the current set?","850a1d8b":"# Part 2: Analysing the distribution and relationship of features\n\nIn this part of the hands-on session, we shall explore the relationship between features and their respective distribution in the dataset.\n- Do we have a biased dataset?\n- How some features relate to good\/bad credit?\n\n","0fc576db":"# Part 8. Explaining the model\n\n## What features are the most important?\n\nWe measure the importance of a feature by calculating the increase in the model\u2019s prediction error after **permuting the feature**. \n- A feature is \u201cimportant\u201d if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction. \n- A feature is \u201cunimportant\u201d if shuffling its values leaves the model error unchanged, because in this case the model ignored the feature for the prediction.\n\n","a5e02280":"# Part 8. Fine tuning the model (Optional)","2648e860":"The next steps use ELI5 library which **does not support** the following classifiers:\n- GaussianNB\n- MLPClassifier\n- XGBoost (dependency conflict version)","1a86e95b":"### Encoding categorical features\n\nCategorical features poses a problem to (some) ML models: \n- How to represent categorical features like Housing = {own, free}?\n\n**Solution 1 - Integer encoding:** We could represent them using numerical values - Housing = {own = 1, free = 2} \n\n| Housing | \n| -- |\n| 1 | \n| 2 | \n\n- The problem of this representation is that it assumes an ordered relationship: \n - does \"own\" housing comes before than \"free\" housing? Does this question even makes sense? \n\n**Solution 2 - One-Hot encoding:** Instead of represengin Housing = {own = 1, free = 2} we turn Housing into a matrix:\n\n\n| Housing_own | Housing_free | \n| -- | -- |\n| 1 | 0 | \n| 0 | 1 | \n","2225bc38":"Write some observations you found on the distribution across features here\n- Observation 1...","440836c4":"# Part 6b. Evaluating the performance of models - Setting up Baseline Models","1264e14e":"Write your observations of Part 1 here\n- Our dataset has X rows and Y columns\n- [...]\n","629b90c3":"### Exploring the effect size of each feature","9440dcc6":"# Part 4. Predicting the Risk (Modeling)\n\nFirst, we will split the dataset into:\n- Features (X) and target variable (y)\n- Training (75%) and test sets (25%)","cfe370b5":"# Part 6a. Evaluating the performance of models - Predicting the test set\n\nWe have seen many models have good accuracy in our training data. **But how good is our models really?**\n\nLet us see how well our model perdicts the unseen test data.\n\n\n","1990e832":"# Experiment by analysing other features in the dataset!\n- What about Checking account vs Age vs Risk?\n- What about Savings account vs Credit amount?\n- What people from different type of Checking Account (little, moderate, rich) ask credit for? \n- ...\n"}}