{"cell_type":{"64d446d0":"code","3aa36705":"code","ac01d2ad":"code","091f4dfe":"code","892d48d2":"code","fd0d1500":"code","76a221c6":"code","24a4f4c4":"code","b1c0a5ee":"code","4c15f167":"code","01a09abe":"code","02d91acf":"code","9a860366":"code","b421bbc6":"code","9243fb49":"code","d1a53b6b":"markdown","e337e0aa":"markdown","d3938549":"markdown","e00eafc6":"markdown","7a6beafa":"markdown","8a0d2fb5":"markdown"},"source":{"64d446d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3aa36705":"# Get the highlights of the data\ndata = pd.read_csv('..\/input\/Admission_Predict.csv')\ndata.describe()","ac01d2ad":"data.rename(columns={'LOR ':'LOR'}, inplace = True)","091f4dfe":"sns.boxplot(x=\"University Rating\", y=\"GRE Score\",\n            data=data)\nsns.despine(offset=10, trim=True)","892d48d2":"sns.boxplot(x=\"University Rating\", y=\"TOEFL Score\",\n            data=data)\nsns.despine(offset=10, trim=True)","fd0d1500":"sns.boxplot(x=\"University Rating\", y=\"SOP\",\n            data=data)\nsns.despine(offset=10, trim=True)","76a221c6":"sns.boxplot(x=\"University Rating\", y=\"LOR\",\n            data=data)\nsns.despine(offset=10, trim=True)","24a4f4c4":"sns.boxplot(x=\"University Rating\", y=\"CGPA\",\n            data=data)\nsns.despine(offset=10, trim=True)","b1c0a5ee":"data.columns","4c15f167":"from sklearn.preprocessing import StandardScaler\ndata2 = data[['GRE Score', 'TOEFL Score', 'SOP',\n       'LOR', 'CGPA', 'Research','University Rating']]\nscaler = StandardScaler()\ndata3 = scaler.fit_transform(data2)\ndata4 = pd.DataFrame(data3)","01a09abe":"data4.iloc[6]","02d91acf":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nX = data[['GRE Score', 'TOEFL Score', 'SOP',\n       'LOR', 'CGPA', 'Research', 'Chance of Admit ']]\nY = data['University Rating']\nX_train = pd.DataFrame(X[:100])\nY_train = pd.DataFrame(Y[:100])\nregressor.fit(X_train, Y_train)\nX_test = pd.DataFrame(X[100:])\nY_test = pd.DataFrame(Y[100:])\nY_pred = regressor.predict(X_test)\nY_pred_df = pd.DataFrame(Y_pred)\nprint(regressor.predict(np.array([328, 112, 4, 4.5, 9.1, 1, 0.78]).reshape(1, -1)))","9a860366":"import statsmodels.formula.api as sm\narr = (pd.DataFrame(np.ones(((400,1)), dtype = int)))\nX1 = pd.concat([arr, X], axis = 1)\nX_opt = X1.iloc[:, [0,1,2,3,4,5,6,7]]\nregressor_OLS = sm.OLS(endog = Y, exog = X_opt).fit()\nSUMM = regressor_OLS.summary()\nregressor_OLS.summary()","b421bbc6":"regressor_OLS.pvalues.round(3)\ndef backwardElimination(x, y, SL):\n    numVars = len(x.iloc[1, :])\n    cols = pd.Series(x.columns)\n#    print(cols)\n    for i in range(0, numVars):\n        regressor_OLS = sm.OLS(endog = y, exog = x).fit()\n        pvals = regressor_OLS.pvalues.round(5)\n#        print(pvals)\n        if max(pvals) >= SL:\n            for j in range(0, len(pvals)):\n#                print(j)\n#                print(pvals[j])\n#                print(SL)\n#                print(cols.iloc[j])\n                if pvals[j] >= SL:\n#                    print(cols.iloc[j])\n                    x = x.drop(columns = cols.iloc[j])\n                    cols = cols.drop(index = j)\n                    cols = cols.reset_index(drop=True)\n#                    print(x.columns)\n#                    print(cols)\n                    numVars = numVars - 1\n#                    print(numVars)\n                    break\n        else:\n            break\n    regressor_OLS = sm.OLS(endog = y, exog = x).fit()\n    return x, regressor_OLS\n\nX_best_fit, best_reg_model = backwardElimination(X_opt, Y, 0.05)\nbest_reg_model.summary()","9243fb49":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nX = X_best_fit\nY = data['University Rating']\nX_train = pd.DataFrame(X[:100])\nY_train = pd.DataFrame(Y[:100])\nregressor.fit(X_train, Y_train)\nX_test = pd.DataFrame(X[100:])\nY_test = pd.DataFrame(Y[100:])\nY_pred = regressor.predict(X_test)\nY_pred_df = pd.DataFrame(Y_pred)\nprint(regressor.predict(np.array([1, 112, 4, 4.5, 9.1]).reshape(1, -1)))","d1a53b6b":"# Compare the Predictions after Backward Elimination","e337e0aa":"# Linear Regression Model for Predicting the University Rating basing other Scores","d3938549":"# Automation of Backward Elimination","e00eafc6":"# Key Observations\n* Not all the features of the dataset are impacting the resultant feature.\n* Linear Regression on all features yeilds ok results.\n* After Backward elimination, we had deleted the unsiginificant columns freeing data to be crunched and we were able to yeild better results with less data to be crunched.\n* We found that to get in a better University the most important features are \n     1. TOEFL\n     2. SOP\n     3. LOR\n     4. CGPA","7a6beafa":"# Backward Elimination","8a0d2fb5":"# Significane Value set to 0.05 for Backward Elemination"}}