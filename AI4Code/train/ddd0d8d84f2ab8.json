{"cell_type":{"c57594f4":"code","6321f0e5":"code","02f3758f":"code","583cd51b":"code","eea10a97":"code","9679509a":"code","3e9d0ea4":"code","5cfee86d":"code","73549fac":"code","521a8490":"code","c32d6c64":"code","b5f617ab":"code","b9929a2f":"code","20947310":"markdown","ea1d39a9":"markdown","dc774642":"markdown"},"source":{"c57594f4":"import numpy as np \nimport pandas as pd\npd.options.display.max_columns = None\n%config Completer.use_jedi = False\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","6321f0e5":"train_data = pd.read_csv('..\/input\/carinsurance\/carInsurance_train.csv')\ntest_data = pd.read_csv('..\/input\/carinsurance\/carInsurance_test.csv')","02f3758f":"train_data.head()","583cd51b":"def onehot_encode(train_data, columns):\n    dummies = pd.get_dummies(train_data[columns], prefix = columns)\n    train_data = pd.concat([train_data, dummies], axis =1)\n    train_data = train_data.drop(columns, axis=1)\n    \n    return train_data","eea10a97":"def preprocess_inputs(train_data):\n    \n    train_data = train_data.copy()\n    \n    # Days passed have more than 3000 values as -1 replacing it with nan to drop.\n    \n    train_data['DaysPassed'] = train_data['DaysPassed'].replace(-1, np.nan)\n    \n    # Droping unwanted features\n    \n    train_data.drop('Id', axis=1, inplace=True)\n    \n    null_columns = train_data.loc[:, train_data.isna().mean() > 0.25].columns\n    train_data.drop(null_columns, axis =1, inplace=True)\n            \n    \n    # maping and treating the null values\n    \n    train_data['Communication'] = train_data.Communication.map({'telephone' : 0, 'cellular' : 1})\n    train_data['Communication'] = train_data['Communication'].fillna(train_data['Communication'].median())\n    train_data['Communication'] = train_data['Communication'].astype('int')\n    \n    train_data['Education'] =train_data.Education.map({'tertiary' : 3, 'primary' : 1 , 'secondary' : 2,})\n    train_data['Education'] = train_data['Education'].fillna(train_data['Education'].median())\n    train_data['Education'] = train_data['Education'].astype('int')\n    \n    # To drop only 19 missing values from jobs\n    \n    train_data=train_data.dropna()\n    \n    # mapping categorical columns\n    \n    train_data['Marital'] = train_data.Marital.map({'single' : 1, 'married' : 2, 'divorced': 3})\n    train_data['LastContactMonth'] = train_data.LastContactMonth.map({'jan' :1, 'may' :5, 'jun' : 6, 'mar' : 3, 'nov' :11, 'jul' : 7, 'aug' :8, 'sep':9, 'apr'  :4,\n       'feb' : 2, 'oct' :10, 'dec' :12})\n    \n    # encode jobs feature\n    \n    train_data = onehot_encode(train_data, 'Job')\n    \n    \n    # Duratin column\n\n    train_data['callduration'] = (pd.to_datetime(train_data['CallEnd']) - pd.to_datetime(train_data['CallStart'])).apply(lambda x : x.seconds)\n    \n    train_data.drop(['CallEnd', 'CallStart'], axis=1, inplace=True)\n    \n    return train_data\n","9679509a":"train_data = preprocess_inputs(train_data)","3e9d0ea4":"X = train_data.drop('CarInsurance',axis =1)\ny = train_data['CarInsurance']","5cfee86d":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","73549fac":"X_train,X_test,y_train,y_test = train_test_split(X,y, train_size = 0.7, random_state =1)","521a8490":"sc.fit(X_train)\n\nX_train = pd.DataFrame(sc.transform(X_train), columns =X.columns)\nX_test = pd.DataFrame(sc.transform(X_test), columns =X.columns)","c32d6c64":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.ensemble import GradientBoostingClassifier","b5f617ab":"models = {\n    'Knn' : KNeighborsClassifier(),\n    'lr' : LogisticRegression(),\n    'LSVC': LinearSVC(), \n    'svc' : SVC(),\n    'GB' : GradientBoostingClassifier()\n    \n}\n\nfor name,model in models.items():\n    model.fit(X_train,y_train)\n    print(name + ' trained')","b9929a2f":"for name, model in models.items():\n    print(name + 'Acuuracy : {:.2f}%'. format(model.score(X_test,y_test)* 100))","20947310":"# Preprocessing","ea1d39a9":"# Scaling and Splitting","dc774642":"# Results"}}