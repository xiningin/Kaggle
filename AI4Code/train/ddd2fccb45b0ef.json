{"cell_type":{"2e111eb8":"code","0b28c145":"code","d738a3bd":"code","31f52a48":"code","41aa76d7":"code","e8a4d9ce":"code","4ca9fd4f":"code","a1431445":"code","e83e853c":"code","8e54fdeb":"code","3a188c76":"code","eedfe6f6":"code","578d904f":"code","40febfb6":"code","88d1864b":"code","7a0c3962":"code","a9fe0732":"code","0f159484":"code","c34e9b1d":"code","bbcf187b":"code","d92dc523":"code","dd84bda3":"code","d4d179d5":"code","d883d5d7":"code","2b8566f5":"markdown","f06a22f5":"markdown","e4747a07":"markdown","31363486":"markdown","97690ca9":"markdown"},"source":{"2e111eb8":"import pandas as pd       \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\nimport random\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import callbacks\nimport tensorflow_addons as tfa\nfrom keras.models import Model\nfrom keras import backend as K","0b28c145":"#Reproducible results\nfrom numpy.random import seed\nseed(42)\nfrom tensorflow.random import set_seed\nset_seed(42)\n\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)","d738a3bd":"df_train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv', index_col = 'id')\nY_train = df_train['target'].copy()\nX_train = df_train.copy().drop('target', axis = 1)\n\nX_test = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv', index_col = 'id')","31f52a48":"train_knn = np.load(\"..\/input\/tps6-boost-your-score-with-knn-features\/add_feat_train.npy\")\ntest_knn = np.load(\"..\/input\/tps6-boost-your-score-with-knn-features\/add_feat_test.npy\")\n\nscaler = MinMaxScaler()\ntrain_knn = pd.DataFrame(scaler.fit_transform(train_knn))\ntest_knn = pd.DataFrame(scaler.transform(test_knn),index = range (200000,300000,1))\n\ntrain_knn.columns = [('knn_{0:d}').format(i) for i in range(1,10)]\ntest_knn.columns = [('knn_{0:d}').format(i) for i in range(1,10)]","41aa76d7":"X_train = pd.concat([X_train, train_knn], axis=1)\nX_test = pd.concat([X_test, test_knn], axis=1)","e8a4d9ce":"X_train","4ca9fd4f":"X_test","a1431445":"class_map = {'Class_1': 0,\n            'Class_2': 1,\n            'Class_3': 2,\n            'Class_4': 3,\n            'Class_5': 4,\n            'Class_6': 5,\n            'Class_7': 6,\n            'Class_8': 7,\n            'Class_9': 8}\nY_train = Y_train.map(class_map).astype('int')\nY_train","e83e853c":"#Converting target series to matrix for multiclass classification on Keras\n\nY_train = to_categorical(Y_train)\nY_train","8e54fdeb":"cce = keras.losses.CategoricalCrossentropy()\n\ndef custom_metric(y_true, y_pred):\n    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n    loss = K.mean(cce(y_true, y_pred))\n    return loss\n\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_custom_metric',\n    patience=10,\n    min_delta=0.0000001,\n    restore_best_weights=True,\n)\n\n#New callback\nplateau = callbacks.ReduceLROnPlateau(\n    monitor='val_custom_metric',\n    factor = 0.5,                                     \n    patience = 2,                                   \n    min_delt = 0.0000001,                                \n    cooldown = 0,                               \n    verbose = 1\n) ","3a188c76":"def res_model():\n\n    inputs = layers.Input(shape = (75,))\n    knn_fts = layers.Input(shape = (9,))\n    \n    #Embedding + Convolution\n    embed = layers.Embedding(360, 8, embeddings_regularizer='l2')(inputs)\n    embed = layers.Conv1D(12, kernel_size=1, activation='relu')(embed)\n    embed = layers.Flatten()(embed)\n    \n    knn = layers.BatchNormalization()(knn_fts)\n    \n    #Residual Blocks Layers\n    x1 = layers.Dropout(0.3)(layers.Concatenate()([embed, knn]))\n    x1 = layers.Dense(units = 32, activation = 'relu', kernel_initializer = \"he_normal\")(x1)\n    x1 = layers.BatchNormalization()(x1) \n    x2 = layers.Dropout(0.4) (layers.Concatenate()([embed, x1]))\n    x2 = layers.Dense(units = 32, activation = 'relu', kernel_initializer = \"he_normal\")(x2)\n    x2 = layers.BatchNormalization()(x2)\n    x3 = layers.Dropout(0.3) (layers.Concatenate()([embed, x1, x2]))\n    x3 = layers.Dense(units = 16, activation = 'relu', kernel_initializer = \"he_normal\")(x3)\n    x3 = layers.BatchNormalization()(x3)\n    x4 = layers.Dropout(0.3) (layers.Concatenate()([embed, x1, x2 ,x3]))\n    x4 = layers.Dense(units = 16, activation = 'relu', kernel_initializer = \"he_normal\")(x4)\n    x4 = layers.BatchNormalization()(x4)\n    \n    #Final Layer (Output)\n    outputs = layers.Dense(9, activation = 'softmax', kernel_initializer = \"lecun_normal\")(x4)\n    \n    model = keras.Model(inputs=[inputs, knn_fts], outputs=outputs)\n    \n    return model","eedfe6f6":"keras.backend.clear_session()\n\nmodel = res_model()\nmodel.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=0.0002), metrics=custom_metric)\n\nmodel.summary()","578d904f":"X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 42\n                                                    , stratify = Y_train)","40febfb6":"history = model.fit([X_train_split.iloc[:, :75], X_train_split.iloc[:, 75:]], Y_train_split,\n          batch_size = 256, epochs = 100,\n          validation_data=([X_val_split.iloc[:, :75], X_val_split.iloc[:, 75:]], Y_val_split),                    \n          callbacks=[early_stopping, plateau]);","88d1864b":"score = model.evaluate([X_val_split.iloc[:, :75], X_val_split.iloc[:, 75:]], Y_val_split, verbose = 0)\nprint('Test loss: {}'.format(score[0]))\nprint('Test accuracy: {}%'.format(score[1] * 100))","7a0c3962":"fig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x = history.epoch, y = history.history['loss'])\nsns.lineplot(x = history.epoch, y = history.history['val_loss'])\nax.set_title('Learning Curve (Loss)')\nax.set_ylabel('Loss')\nax.set_xlabel('Epoch')\nax.legend(['train', 'test'], loc='best')\nplt.show()","a9fe0732":"Y_train = df_train['target'].copy()\nY_train = Y_train.map(class_map).astype('int')\nY_train","0f159484":"def prediction (X_train, Y_train, X_test):\n    \n    keras.backend.clear_session()\n\n    kfold = StratifiedKFold(n_splits = 25)\n\n    y_pred = np.zeros((100000,9))\n    train_oof = np.zeros((200000,9))\n    \n    for idx in kfold.split(X=X_train, y=Y_train):\n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X_train.iloc[train_idx]\n        ytrain = Y_train.iloc[train_idx]\n        xval = X_train.iloc[val_idx]\n        yval = Y_train.iloc[val_idx]\n        \n        ytrain = to_categorical(ytrain)\n        yval = to_categorical(yval)\n        \n        # fit model for current fold\n        model = res_model()\n        model.compile(loss='categorical_crossentropy'\n                      , optimizer = keras.optimizers.Adam(learning_rate=0.0002), metrics=custom_metric)\n        \n        model.fit([xtrain.iloc[:, :75], xtrain.iloc[:, 75:]], ytrain,       \n        batch_size = 256, epochs = 100,\n        validation_data=([xval.iloc[:, :75], xval.iloc[:, 75:]], yval),  \n        callbacks=[early_stopping, plateau]);\n\n        #create predictions\n        y_pred += model.predict([X_test.iloc[:, :75], X_test.iloc[:, 75:]])\/kfold.n_splits\n        print(y_pred)\n               \n        val_pred = model.predict([xval.iloc[:, :75], xval.iloc[:, 75:]])\n        # getting out-of-fold predictions on training set\n        train_oof[val_idx] = val_pred\n        \n        # calculate and append logloss\n        fold_logloss = metrics.log_loss(yval,val_pred)\n        print(\"Logloss: {0:0.5f}\". format(fold_logloss))\n  \n    return y_pred, train_oof","c34e9b1d":"nn_pred, train_oof = prediction (X_train, Y_train, X_test)","bbcf187b":"print(\"Logloss: {0:0.6f}\".format(metrics.log_loss(Y_train,train_oof)))","d92dc523":"train_oof = pd.DataFrame(train_oof, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'])\ntrain_oof","dd84bda3":"pred_test = pd.DataFrame(nn_pred, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'])\npred_test","d4d179d5":"train_oof.to_csv('nn_train_oof.csv', index=False)\ntrain_oof","d883d5d7":"output = pred_test\noutput['id'] = X_test.index\noutput.to_csv('submission.csv', index=False)\n\noutput","2b8566f5":"## Importing Libraries and Datasets","f06a22f5":"My other notebooks in this competition:\n- [Tabular Playground Series - June\/2021: Starter - EDA + Base LightGBM](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-starter-eda-base-lgbm)\n- [Tabular Playground Series - June\/2021: Simple Neural Network with Keras](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-simple-nn-with-keras)\n- [Tabular Playground Series - June\/2021: Keras Neural Network with Embedding Layer](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-keras-nn-with-embedding)\n- [Tabular Playground Series - June\/2021: Wide and Deep Neural Network with Keras](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-wide-and-deep-nn-w-keras)\n- [Tabular Playground Series - June\/2021: LightAutoML with KNN Features](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-lightautoml-w-knn-feats)","e4747a07":"## Creating and Evaluating the NN","31363486":"# <center>Tabular Playground Series - June\/2021<center>\n## <center>Keras Neural Network with Skip Connections<center>\n---\n\n- Neural Network inspired by [@pourchot's](https:\/\/www.kaggle.com\/pourchot) notebook [Simple Neural Network](https:\/\/www.kaggle.com\/pourchot\/simple-neural-network).\n- Using KNN features provided by [@melanie7744's](https:\/\/www.kaggle.com\/melanie7744) notebook [TPS6-Boost your score with KNN features](https:\/\/www.kaggle.com\/melanie7744\/tps6-boost-your-score-with-knn-features).\n\n    \n<br>\n<br>    \n    \n![NN](https:\/\/i.imgur.com\/4up4HK2.png)\n <center>Simplified Representation of the Neural Network<center>\n<br>\n","97690ca9":"## Making Predictions"}}