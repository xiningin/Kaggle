{"cell_type":{"72828fb7":"code","edcf42ac":"code","9509f302":"code","522cbcf3":"code","64b2c13d":"code","28102bae":"code","4ddcf01e":"code","73e5cf19":"code","1648f303":"code","bc42f53a":"code","9fc1dbc0":"code","1de9c12a":"code","180b89ef":"code","463d6bc1":"code","bb262b0f":"markdown","0b8e28e8":"markdown","5c8441d2":"markdown","c477cd7a":"markdown","37789414":"markdown","d6fad33f":"markdown","a2f3994e":"markdown","00aa37df":"markdown"},"source":{"72828fb7":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","edcf42ac":"import os\n\nclasses = os.listdir(\"..\/input\/flowers\/flowers\")\nclasses","9509f302":"image_size = (240, 134)\nbatch_size = 64\n\n# https:\/\/keras.io\/api\/preprocessing\/image\/#image_dataset_from_directory-function\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/flowers\/flowers\",\n    validation_split=0.1,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes,\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/flowers\/flowers\",\n    validation_split=0.1,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes,\n)","522cbcf3":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(classes[np.argmax(labels[i])])\n        plt.axis(\"off\")","64b2c13d":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.25),\n    ]\n)","28102bae":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","4ddcf01e":"IMG_HEIGHT_SIZE = 128\nIMG_WIDTH_SIZE = 128\n\nresize_and_rescale = keras.Sequential(\n    [\n      layers.experimental.preprocessing.CenterCrop(IMG_HEIGHT_SIZE, IMG_WIDTH_SIZE),\n      layers.experimental.preprocessing.Rescaling(1.\/255)\n    ]\n)","73e5cf19":"#plt.figure(figsize=(10, 10))\n#for images, _ in train_ds.take(1):\n#    for i in range(9):\n#        resized_images = resize_and_rescale(images)\n#        ax = plt.subplot(3, 3, i + 1)\n#        plt.imshow(resized_images[i].numpy().astype(\"uint8\"))\n#        plt.axis(\"off\")","1648f303":"def make_model(input_shape, num_classes):\n    \n    inputs = keras.Input(shape=input_shape)\n    \n    x = resize_and_rescale(inputs)\n    # Image augmentation block\n    #x = data_augmentation(inputs)\n\n    #x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(512, activation=\"relu\")(x)\n    x = layers.Dropout(0.25)(x)\n    x = layers.Dense(256, activation=\"relu\")(x)\n    x = layers.Dropout(0.25)(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dropout(0.25)(x)\n\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    outputs = layers.Dense(units, activation=activation)(x)\n    \n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=len(classes))\nmodel.summary()","bc42f53a":"epochs = 100\n\n# https:\/\/keras.io\/api\/callbacks\/\n\n#callbacks = [\n#    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n#]\n\nopt = keras.optimizers.Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, epsilon=1.0, amsgrad=False)\n\nmodel.compile(\n   optimizer=opt,\n   loss=\"categorical_crossentropy\",\n   metrics=[\"accuracy\"],\n)\n\nhistory = model.fit(\n   train_ds, epochs=epochs, validation_data=val_ds,\n)","9fc1dbc0":"# Metrics\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(go.Scatter(\n    y=history.history['loss'],\n    mode='lines+markers',\n    name='training loss'\n), row=1, col=1)\n\nfig.add_trace(go.Scatter(\n    y=history.history['val_loss'],\n    mode='lines+markers',\n    name='validation loss'\n), row=1, col=1)\n\n\nfig.add_trace(go.Scatter(\n    y=history.history['accuracy'],\n    mode='lines+markers',\n    name='training accuracy'\n), row=1, col=2)\n\nfig.add_trace(go.Scatter(\n    y=history.history['val_accuracy'],\n    mode='lines+markers',\n    name='validation accuracy'\n), row=1, col=2)\n\nfig.update_xaxes(title_text='Epoch')\n\nfig.update_layout(\n    title_text=\"Training History Metrics\",\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"right\", x=1)\n)\n\nfig.show()","1de9c12a":"model_json = model.to_json()\n\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","180b89ef":"from tensorflow.keras.models import model_from_json\n\n# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")","463d6bc1":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        \n        pred = loaded_model.predict(np.array([images[i].numpy().astype(\"uint8\")]))\n        \n        plt.title(classes[np.argmax(pred)])\n        plt.axis(\"off\")","bb262b0f":"# Tarea Semana 11","0b8e28e8":"# Visualize the data","5c8441d2":"# Model","c477cd7a":"# Load the model","37789414":"## Deep Learning\nIntente Mejorar el score del notebook 2 ajustando los hiperpar\u00e1metros\n\n1. Modifique la arquitectura para que mejore la predicci\u00f3n. (5 pts)\n2. Grafique el accuracy y el loss por epoch tanto del train como del test. (5 pts)\n3. Grafique al menos 10 im\u00e1genes con su respectiva predicci\u00f3n (debe indicar si la predicci\u00f3n es correcta o no). (10 pts)","d6fad33f":"# Save the model","a2f3994e":"# Data Augmentation","00aa37df":"# Train the model"}}