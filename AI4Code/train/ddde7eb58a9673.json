{"cell_type":{"6d425472":"code","604fabed":"code","efc8f0ee":"code","c9a948aa":"code","204e9fb9":"code","1ceb64d4":"code","af8c808e":"code","2a124e17":"code","4338fb67":"code","20060d74":"code","0f1b06b5":"code","88e416bc":"code","d07f905b":"code","dd409691":"code","256f09f3":"code","936a8c87":"code","1376b2b0":"code","4feff367":"code","e8f8e6bf":"code","ec40d3f3":"code","7436d7b9":"code","db1bb2f6":"code","fe2ccf5d":"code","03c48651":"code","2c4b47b5":"code","5593cebb":"code","fd084d55":"code","0857b55f":"code","0d6b874f":"code","3fe386eb":"code","3b38b710":"code","2e90c8e7":"code","9f5ed3f3":"code","8fa5cb02":"code","b92911b8":"code","6f8a48d2":"code","d564e046":"code","5e31a261":"code","033e49ca":"code","45e29a5e":"code","2d42f217":"code","9f04d278":"code","6af0b0c4":"markdown","59645374":"markdown","a5e6be37":"markdown","29f46fe0":"markdown","dd06c360":"markdown","17648565":"markdown","c845b88f":"markdown"},"source":{"6d425472":"import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot","604fabed":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","efc8f0ee":"df_train.head(5)","c9a948aa":"df_test.head(5)","204e9fb9":"gender_submission.head(5)\n# head()\ub97c \ud65c\uc6a9\ud558\uc5ec \ubcfc\ub54c PassengerId\ub97c \ud1b5\ud574\uc11c test data\uc758 \uacb0\uacfc\ub97c \uc608\uce21\ud560 \uc218 \uc788\uc74c\uc744 \uc608\uc0c1\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n# When using head(), it can be expected that the result of test data can be predicted through PassengerId.","1ceb64d4":"# 'Survived' column\uc744 \uc798 \ubd99\uc600\ub294\uc9c0 \ud655\uc778 \ud569\ub2c8\ub2e4.\n# Check if the 'Survived' column is attached properly.\ndf_test['Survived'] = gender_submission['Survived']\ndf_test.head(5)","af8c808e":"#\ud1b5\uacc4\uc801\uc73c\ub85c \ubd84\ud3ec\uac00 \uc5b4\ub5a0\ud55c\uc9c0 Pair Plot \ubc0f \uc5ec\ub7ec \uadf8\ub798\ud504\ub97c \ud1b5\ud558\uc5ec \ubd84\uc11d\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Let's analyze how the distribution is statistically through pair plots and several graphs.\n\nsns.pairplot(data = df_train)","2a124e17":"def analysis(data):\n    print(\"1. \uccab\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 Data\uc758 Heatmap \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.\uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc0c9\uae54\uc774 \uc9c4\ud558\ub3c4\ub85d \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    print(\"2. \ub450\ubc88\uc9f8 \uadf8\ub798\ud504\ub294 null ratio\ub97c \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n    sns.heatmap(data.corr(), annot=True, cmap='Reds')\n    null_percent = 100*(data.isnull().sum()\/len(data))\n    null_percent = null_percent[null_percent>0].sort_values()\n    plt.figure(figsize= (10,4))\n    sns.barplot(x=null_percent.index, y= null_percent)\n    plt.xticks(rotation=90)","4338fb67":"analysis(df_train)","20060d74":"analysis(df_test)","0f1b06b5":"fat=ols(formula='Survived~PassengerId+Pclass+Age+Sex+SibSp+Parch+Fare+Embarked', data=df_train).fit()\nprint(fat.summary())\n\n# \ud1b5\uacc4\uc801\uc73c\ub85c\ub294 \uc131\ubcc4\uc5d0 \ub530\ub978 \uad6c\ubd84\uacfc Pclass\uc5d0 \ub530\ub77c \uc0dd\uc874\ub960\uc774 \uc601\ud5a5\ub3c4\uac00 \uac00\uc7a5 \ub192\uc740 \uac83\uc73c\ub85c \ub098\uc654\uace0, \n# OLS Regression\uc73c\ub85c \uc608\uce21\uc2dc \uc0c1\uae30\uc758 8\uac1c \ubcc0\uc218\ub9cc\uc73c\ub85c \ubcf8\ub2e4\uba74, R-squre 0.4\/ Adjust R-square 0.39\uc218\uc900\uc758 \uc608\uce21\uc774 \uac00\ub2a5 \ud560 \uac83\uc73c\ub85c \uc608\uc0c1 \ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# Statistically, it was found that the survival rate was the most influential according to the classification according to gender and Pclass.\n# When predicting with OLS regression, if we consider only the above 8 variables, it was expected that the R-squre 0.4\/ Adjust R-square 0.39 level could be predicted.","88e416bc":"# \uc22b\uc790 \ud0c0\uc785\uc758 \ub370\uc774\ud130 \ucd94\ucd9c\n# Numeric Feature Enginearing\n\nnum_cols = [col for col in df_train.columns if df_train[col].dtype in ['int64','float64']]\ndf_train[num_cols].describe()","d07f905b":"df_train.corr(method='pearson')","dd409691":"df_train.info()","256f09f3":"# \ub370\uc774\ud130\ub0b4 \uc911\ubcf5 \uac12\uc740 \uc5c6\ub294\uc9c0 \ud655\uc778\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n# Let's check that there are no duplicate values in the data.\n\ndf_train=df_train.drop_duplicates()","936a8c87":"df_train.info()","1376b2b0":"# \uc65c\ub3c4\uc640 \ucca8\ub3c4\ub97c \ud655\uc778\ud558\ub294 \uacbd\uc6b0 Regression Modeling\ud560 \uacbd\uc6b0 \ub9ce\uc774 \ubcf4\ub098, \uae08\ubc88\uc758 \uacbd\uc6b0\ub294 \ub2e8\uc21c\ud788 \uc6b0\ub9ac\uac00 \uc54c\uace0 \uc2f6\uc740 Y\uac12(Survived)\uc758 \ubd84\ud3ec\uac00 3:2\ub77c\ub294 \uac83\n# \uc815\ub3c4 \ubc16\uc758 \uc815\ubcf4\ub97c \uc5bb\uc744\uc218 \uc5c6\uc5c8\uc2b5\ub2c8\ub2e4.\n\n# When checking skewness and kurtosis, it is often seen in Regression Modeling, but in this case, we could not simply obtain information other than that the distribution of Y-value (Survived) we wanted to know was 3:2.\nprint(f'skew: {df_train.Survived.skew()}')\nprint(f'kert: {df_train.Survived.kurt()}')\nsns.distplot(df_train.Survived, fit = norm)\nf = plt.figure()\nprobplot(df_train.Survived, plot = plt)\nplt.show()","4feff367":"def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x)","e8f8e6bf":"numeric_cols = [col for col in df_train if df_train[col].dtype in ['int64','float64']]\nnumeric_cols.remove('Survived')\ny = 'Survived'\nover_column_name = list()\n\nfor i in numeric_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, y, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)\n\nprint('Column\ub0b4 \ubcc0\uc218\uac00 20\uac1c \uc774\uc0c1\uc758 Column\uc740 \ud558\ub2e8\uacfc \uac19\uc2b5\ub2c8\ub2e4.\\n\ubcc0\uc218 20\uac1c \ubbf8\ub9cc\uc758 Column\uacfc Survived \uc22b\uc790 \ubd84\ud3ec\ub294 \uadf8\ub798\ud504\uc640 \uac19\uc2b5\ub2c8\ub2e4.')\nprint(over_column_name)","ec40d3f3":"print(num_cols)\nnum_cols.remove('PassengerId')\n\nfig, ax = plt.subplots(3, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(num_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(60)\n        \nplt.tight_layout()","7436d7b9":"cat_cols = [col for col in df_train if df_train[col].dtype not in ['int64','float64']]\nprint(cat_cols)\ncat_cols.remove('Name')\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(cat_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\n        \nplt.tight_layout()","db1bb2f6":"# train data\uc0c1 null\uac12\uc744 \ud655\uc778\ndf_train.isna().sum()","fe2ccf5d":"df_train=df_train.drop(['Name','Ticket'],axis=1)\ndf_test=df_test.drop(['Name','Ticket'],axis=1)","03c48651":"# Cabin \uc815\ubcf4\ub294 \ub2e4 \ubc84\ub9ac\uae30 \uc544\uae4c\uc6cc \uae00\uc790\uc218\ub97c \ubcc0\uc218\ub85c \ud55c\ubc88 \ud65c\uc6a9\ud574\ubcfc \uc0dd\uac01\uc785\ub2c8\ub2e4.\n# Rather than deleting the Cabin column, I will use \"len()\" to use the number of characters in the variable.\ndf_train['CabinCode'] = df_train['Cabin'].apply(lambda x : len(str(x)) if x!='nan' else 0)\ndf_test['CabinCode'] = df_test['Cabin'].apply(lambda x  : len(str(x)) if x!='nan' else 0)","2c4b47b5":"df_train=df_train.drop(['Cabin'],axis=1)\ndf_test=df_test.drop(['Cabin'],axis=1)","5593cebb":"# nan\uac12 \uc5ed\uc2dc \ud558\ub098\uc758 \ubcc0\uc218\uac00 \uc544\ub2d0\uae4c\ub77c\ub294 \uac00\uc815\ud558\uc5d0 \uae08\ubc88 \ubd84\uc11d\uc5d0\uc11c\ub294 null\uac12\uc5d0 \ub300\ud55c \ubcf4\uc815 \uc5c6\uc774 \uc9c4\ud589\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n# Assuming that the nan value is also a variable, in this analysis, we will proceed without correction for the null value.\n\ndf_train=pd.get_dummies(df_train)\ndf_test=pd.get_dummies(df_test)","fd084d55":"df_train.info()\ndf_test.info()","0857b55f":"df_train.head(5)","0d6b874f":"# 7:3\uc73c\ub85c \uc81c\uacf5\ub41c train data\ub97c train\uacfc validation data\ub85c \uad6c\ubd84\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.3\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)","3fe386eb":"# \"read.csv\"\ub97c \uc4f0\ub2e4\ubcf4\uba74 \uac00\ub054 Unnamed: 0\uc73c\ub85c \ubb38\uc81c\ubc1c\uc0dd\uc774 \ub9ce\uc774 \ubc1c\uc0dd\ud568\n# \uadf8\ub798\uc11c \uc800\ub294 \ubd84\uc11d\uc2dc \ubb34\uc870\uac74 \ub123\uc5b4\uc11c \uc2e4\ud589\ud558\uace4 \ud569\ub2c8\ub2e4.\n\n# When I use the \"read.csv\" function, sometimes I get a lot of problems with Unnamed: 0. So, when I analyze, I put it in unconditionally and run it.\n#train = train.drop(['Unnamed: 0'], axis= 1)\n#validation = validation.drop(['Unnamed: 0'], axis= 1)\n#test = df_test.drop(['Unnamed: 0'], axis= 1)","3b38b710":"drop_col = ['Survived']\ny_nm = 'Survived'\n\ndf_train_x = train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test.drop(drop_col, axis = 1)\ndf_test_y = pd.DataFrame(df_test[y_nm])","2e90c8e7":"LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42)","9f5ed3f3":"start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start","8fa5cb02":"# Importance \ud655\uc778 \n# \uc8fc\uc694 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ubcc0\uc218\uac00 \ubb34\uc5c7\uc778\uc9c0 \ud655\uc778\uc744 \ud558\uace0, \uc774\ub97c \uadf8\ub798\ud504\ud654 \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4.\n# We checked the variables that have a major impact, and graphed them.\n\nfeature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png')","b92911b8":"# for loop\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac00\uc7a5 \ub192\uc740 accuracy\ub97c \uc0b0\ucd9c\ud558\ub294 \ub85c\uc9c1\uc744 \ub123\uc5c8\uc2b5\ub2c8\ub2e4. \n# I put the logic that yields the highest accuracy using a for loop.\n\nresult_lst =[]\nmax_accuracy =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_accuracy <= accuracy:\n        max_accuracy = accuracy\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score', 'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('\ucd5c\uace0 Accuracy-SCORE =%f, \uc784\uacc4\uce58=%f'%(max_accuracy, opt_threshold))\nprint('Threshold \uc124\uc815 \uc644\ub8cc')","6f8a48d2":"predict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel()","d564e046":"conf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train))","5e31a261":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","033e49ca":"Accuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","45e29a5e":"predict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","2d42f217":"predict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_test_y.values.ravel(), pred_test, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_test_y.values.ravel(), pred_test),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_test_y.values.ravel(), pred_test))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_test_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","9f04d278":"test_result= pd.DataFrame(pred_test)\ntest_result.columns = ['Survived']\npredict = test_result['Survived']\nId_No = df_test['PassengerId']\nsubmission = pd.DataFrame({'PassengerId': Id_No, \"Survived\": predict})\nsubmission['Survived'] = submission['Survived'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","6af0b0c4":"## 6.\uc81c\ucd9c\uc790\ub8cc \uc791\uc131(Prepare submission materials)","59645374":"## 2. \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30(Read Dataset)","a5e6be37":"## 5. \ubaa8\ub378 \uacb0\uacfc \ubd84\uc11d(Analyze model results)\n#### \ubaa8\ub378\uc744 \ud1b5\ud574 \ub098\uc628 train, validation, test \uacb0\uacfc\uce58(precision\uc5d0\uc11c\ubd80\ud130 F1-Score, AUROC\uae4c\uc9c0)\ub97c \uc0b0\uc2dd\uc744 \uc9c1\uc811 \uacc4\uc0b0\ud558\uc5ec \uacb0\uacfc\uac00 \ub098\uc624\ub3c4\ub85d \uad6c\ud604\ud574 \ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n#### I tried to implement the results by directly calculating the train, validation, and test results (from precision to F1-Score, AUROC) through the model.","29f46fe0":"## 3. \ud0d0\uc0c9\uc801 \ub370\uc774\ud130 \ubd84\uc11d (EDA)\n#### \ud5a5\ud6c4 \ub2e8\uacc4\ubcc4\ub85c Competition \ucc38\uc5ec\ub97c \ud558\uba74\uc11c def \ud568\uc218\ub85c \ubb36\uc5b4\uc11c \uc790\ub3d9\uc73c\ub85c \ud560 \uc218 \uc788\ub3c4\ub85d \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.\n#### \uc6b0\uc120 \ud574\ub2f9 \ub370\uc774\ud130\uc758 Column\ub4e4\uc774 \uc5b4\ub5a4 \uac83\uc774 \uc788\uace0, \ud1b5\uacc4\uc801\uc73c\ub85c \uc5b4\ub5a0\ud55c \uacb0\uacfc\uac00 \uc788\ub294\uc9c0 \ud655\uc778\ud560 \uac81\ub2c8\ub2e4.\n\n#### In the future, while participating in the competition step by step, \n#### I plan to bind it with the def function so that it can be done automatically.\n#### First, I will check what the columns of the data are and what the statistical results are.","dd06c360":"## 4. \ubaa8\ub378\ub9c1(Modeling) \n#### \ud559\uc2b5 \uc9c4\ud589\uc744 \uc704\ud558\uc5ec Train, validation, test data\ub97c \ub098\ub204\uace0, HyperParameter\ub97c \ub123\uc5b4 \ud559\uc2b5\uae4c\uc9c0 \uc2dc\ud0a4\uaca0\uc2b5\ub2c8\ub2e4.\n#### In order to proceed with the training, we will divide the Train, validation, and test data, and put HyperParameter to train it.","17648565":"#### \ucc98\uc74c\uc73c\ub85c kaggle\uc5d0 \ucc38\uc5ec\ud558\uc5ec \ucf54\ub4dc\ub97c \uc62c\ub9bd\ub2c8\ub2e4. \n#### \ub300\ud68c Rule\uacfc Scoring\uae30\uc900\uc5d0 \ub530\ub77c \ud0c0\uc774\ud0c0\ub2c9 \uc0dd\uc874\uc790 \uc608\uce21\uc758 Accuracy\ub97c \uac00\uc7a5 \ub192\uac8c \uc0b0\ucd9c\ud558\ub294 \ubaa8\ub378\uc744 \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.    \n#### This is my first time participating in kaggle. \n#### In this code, I tried to make a model with high accuracy to predict the Titanic survivor.","c845b88f":"## 1. \ubaa8\ub4c8 \ubd88\ub7ec\uc624\uae30 (Import module)\n \n#### \uc81c\uac00 \uac00\uc7a5 \uc790\uc8fc \uc4f0\ub294 \ubaa8\ub4c8\ub4e4\uc744 \ubd88\ub7ec\uc62c \uc608\uc815\uc785\ub2c8\ub2e4.\n#### It will load all the modules I use the most."}}