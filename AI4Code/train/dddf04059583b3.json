{"cell_type":{"a55f9e7f":"code","4db09775":"markdown"},"source":{"a55f9e7f":"import datetime\nimport os,sys\nimport numpy as np\nimport pandas as pd\nimport gresearch_crypto\n\nenv = gresearch_crypto.make_env()\niter_test = env.iter_test()\n\n\nclass gresearch_guada():\n    \"\"\"docstring for gresearch_guada\"\"\"\n    def __init__(self):\n        #super(gresearch_guada, self).__init__()\n        ### \u8bad\u7ec3\u96c6\n        self.train = '\/kaggle\/input\/g-research-crypto-forecasting\/train.csv'\n        ### \u8865\u5145\u8bad\u7ec3\u6570\u636e\u96c6\u2014\u2014\uff08\u9a8c\u8bc1\u96c6\uff09\n        self.supplemental_train = '\/kaggle\/input\/g-research-crypto-forecasting\/supplemental_train.csv'\n        ### \u8d44\u4ea7\u4fe1\u606f\u6570\u636e\u96c6\uff0c\u5305\u542b14\u4e2a\u865a\u62df\u8d27\u5e01\u8d44\u4ea7\n        self.asset_details = '\/kaggle\/input\/g-research-crypto-forecasting\/asset_details.csv'\n        ### \u6d4b\u8bd5\u6570\u636e\u6837\u4f8b\n        self.example_test = '\/kaggle\/input\/g-research-crypto-forecasting\/example_test.csv'\n        #self.env = gresearch_crypto.make_env()\n        #self.iter_test = self.env.iter_test()\n\n    def dataReader(self, datasetName):\n        ### \u6570\u636e\u96c6\u8bfb\u53d6\n        if datasetName == 'train':\n            ### \u83b7\u53d6train\u6570\u636e\u96c6\n            df = pd.read_csv(self.train, usecols=['Target', 'Asset_ID', 'timestamp'], dtype={'Asset_ID': 'int8'})\n        elif datasetName == 'supplemental_train':\n            ### \u83b7\u53d6supplemental_train\n            df = pd.read_csv(self.supplemental_train, usecols=['Target', 'Asset_ID', 'timestamp'], dtype={'Asset_ID': 'int8'})\n        else:\n            print(\"ERROR [1018] - message: \u6570\u636e\u96c6\u4f20\u5165\u53c2\u6570\u9519\u8bef!\")\n        return df\n\n    def dataFillNan(self, train_data, columns, fillType):\n        ## \u7a7a\u7f3a\u503c\u586b\u5145\n        if fillType == \"0\":\n            ### fixed value fillnan\n            fixed_value = input(\"\u8bf7\u8f93\u5165\" + columns + \"\u5217\u56fa\u5b9a\u586b\u5145\u503c\uff1a(eg: \u63a8\u8350\u503c\uff1a\" + str(Counter(train_data[columns]).most_common(3)) + \")\uff1a\")\n            #self.logging.info(\"kaggle.\" + sys._getframe().f_code.co_name + \".service Message: \u5df2\u83b7\u53d6\u7f3a\u5931\u503c\u586b\u5145\u53c2\u6570\uff1a{'\u7f3a\u5931\u503c\u586b\u5145\u65b9\u6cd5':'\u56fa\u5b9a\u503c\u586b\u5145','\u56fa\u5b9a\u503c':\" + fixed_value + \"},\u51c6\u5907\u5f00\u59cb\u7f3a\u5931\u503c\u586b\u5145......\")\n            train_data[columns].fillna(fixed_value, inplace=True)\n            if train_data[columns].isnull().any():\n                print(\"\u4ecd\u65e7\u6709\u7a7a\u503c\")\n                #self.logging.error(\"kaggle.\" + sys._getframe().f_code.co_name + \".service Message: \u6570\u636e\u96c6\u5217\" + columns +\"\u7f3a\u5931\u503c\u4ee5\u56fa\u5b9a\u503c\u65b9\u5f0f\u586b\u5145\u5931\u8d25\uff0c\u8bf7\u67e5\u770b\u539f\u56e0\uff01\")\n            else:\n                print(\"\u8be5\u5217\u65e0\u7a7a\u503c\")\n                #self.logging.info(\"kaggle.\" + sys._getframe().f_code.co_name + \".service Message: \u6570\u636e\u96c6\u5217\" + columns +\"\u7f3a\u5931\u503c\u4ee5\u56fa\u5b9a\u503c\u65b9\u5f0f\u586b\u5145\u6210\u529f\uff01\")\n            return train_data\n        elif fillType == \"1\":\n            ### before value fillnan\n            return \"\u524d\u503c\u586b\u5145\u6cd5 \u6682\u672a\u5f00\u653e......\"\n        elif fillType == \"2\":\n            ### \u4e2d\u4f4d\u6570\u586b\u8865\n            if train_data[columns].dtypes == 'float64' :\n                train_data[columns].fillna(train_data[columns].median(),inplace=True)\n            else:\n                print(\"\u8be5\u5217\u6570\u636e\u7c7b\u578b\u4e0d\u652f\u6301\u4e2d\u4f4d\u6570\u586b\u5145\uff01\")\n            return train_data\n        elif fillType == \"3\":\n            ## \u4f17\u6570\u586b\u8865\u6cd5\n            if train_data[columns].dtypes == 'float64' :\n                train_data[columns].fillna(train_data[columns].mode(),inplace=True)\n            else:\n                print(\"\u8be5\u5217\u6570\u636e\u7c7b\u578b\u4e0d\u652f\u6301\u4f17\u6570\u586b\u5145\uff01\")\n                #continue\n            return train_data\n            #train_data[columns].fillna(train_data[columns].mode(),inplace=True)\n        elif fillType == \"4\":\n            ## \u56de\u5f52\u586b\u8865\u6cd5\n            #self.logging.info(\"kaggle.\" + sys._getframe().f_code.co_name + \".service Message: \u5df2\u83b7\u53d6\u7f3a\u5931\u503c\u586b\u5145\u53c2\u6570\uff1a{'\u7f3a\u5931\u503c\u586b\u5145\u65b9\u6cd5':'\u56de\u5f52\u586b\u5145','\u5f53\u524d\u5217\u56de\u5f52':\" + str(train_data[columns].mode()) + \"},\u51c6\u5907\u5f00\u59cb\u7f3a\u5931\u503c\u586b\u5145......\")\n            if train_data[columns].dtypes == 'float64':\n                #self.logging.info(\"kaggle.\" + sys._getframe().f_code.co_name + \".service Message: \u5df2\u83b7\u53d6\u7f3a\u5931\u503c\u586b\u5145\u53c2\u6570\uff1a{'\u7f3a\u5931\u503c\u586b\u5145\u65b9\u6cd5':'\u56de\u5f52\u586b\u8865\u6cd5','\u586b\u5145\u503c':}\")\n                imp = IterativeImputer(max_iter=10, random_state=0)\n                imp.fit(train_data)\n                np.round(imp.transform(train_data))\n            else:\n                print(\"\u6570\u636e\u7c7b\u578b\u4e0d\u652f\u6301\u56de\u5f52\u586b\u5145\u6cd5\uff01\")\n                #self.logging.info(\"kaggle.\" + sys._getframe().f_code.co_name + \".service Message: \u6570\u636e\u7c7b\u578b\u4e0d\u652f\u6301\u56de\u5f52\u586b\u5145\u6cd5\uff01\uff08\u8bf4\u660e*\uff1a\u8be5\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u7f3a\u5931\u503c\u4e3a\u5b9a\u91cf\u7684\u6570\u636e\u7c7b\u578b\uff09\")\n        else:\n            ### \u5176\u4ed6\u586b\u5145\u6cd5\n            return \"\u5176\u4ed6\u586b\u5145\u6cd5 \u6682\u672a\u5f00\u653e......\"\n\n    def datetimeProc(self, datasetName):\n        ## \u6570\u636e\u96c6\u65f6\u95f4\u5904\u7406\n        datasetName['datetime'] = pd.to_datetime(datasetName['timestamp'], unit='s')\n        #print(datasetName['datetime'])\n        datasetName = datasetName.set_index('datetime').drop('timestamp', axis=1)\n        datasetName = datasetName[(datasetName.index.year == 2021) & (datasetName.index.month > 5)]\n        #print(datasetName)\n        \n        dfs = {asset_id:datasetName[datasetName['Asset_ID'] == asset_id].resample('1min').interpolate().copy() for asset_id in datasetName['Asset_ID'].unique()}\n        #print(dfs)\n        ## delete $datasetName dataset\n        del datasetName\n        return dfs\n        \n\n## \u7c7b\u5b9e\u4f8b\u5316\ngresearch_guada = gresearch_guada()\n\n## \u8bfb\u53d6train.csv\ndf = gresearch_guada.dataReader(\"train\")\n\n## \u521d\u6b65\u5904\u7406datetime\u5b57\u6bb5\ndfs = gresearch_guada.datetimeProc(df)\n\nfor df_test, df_pred in iter_test:\n    print(df_pred)\n    df_test['datetime'] = pd.to_datetime(df_test['timestamp'], unit='s')\n    print(df_test)\n    for _, row in df_test.iterrows():\n        try:\n            df = dfs[row['Asset_ID']]\n            closest_train_sample = df.iloc[df.index.get_loc(row['datetime'], method='nearest')]\n            df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = closest_train_sample['Target']\n        except:\n            df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = 0\n    #df_pred['Target'] = df_pred['Target'].fillna(0)\n    df_pred = gresearch_guada.dataFillNan(df_pred, 'Target', '2')\n    print(df_pred)\n    env.predict(df_pred)\n\n","4db09775":"* median fillnan \n* mode fillnan\n* \u201c0\u201d fillnan"}}