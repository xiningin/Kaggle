{"cell_type":{"e86cd038":"code","4d1a8d24":"code","947c2cfd":"code","ecd00648":"code","f7d5ba41":"code","f0cb106c":"code","791e3f32":"code","adffa2e2":"code","e0f964d2":"code","94a3b669":"code","eaf3d547":"code","42c2d62b":"code","92defcfb":"markdown","56e3bf0f":"markdown"},"source":{"e86cd038":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306eimport\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nfrom tqdm import tqdm\nimport librosa\n\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport umap\n","4d1a8d24":"# Path\u306e\u60c5\u5831\u3092dataclass\u3067\u4fdd\u5b58\u3057\u3066\u304a\u304f\n@dataclass(frozen=True)\nclass DataPath:\n    input_dir: str = '..\/input\/hah-data-science-challenge'\n    train_wav_dir: str = f'{input_dir}\/train\/train'\n    test_wav_dir: str = f'{input_dir}\/test\/test'\n    train_csv: str = f'{input_dir}\/train.csv'\n    test_csv: str = f'{input_dir}\/test.csv'\n\ndata_path = DataPath()","947c2cfd":"df_train = pd.read_csv(data_path.train_csv)\ndf_test = pd.read_csv(data_path.test_csv)","ecd00648":"df_train['file_path'] = data_path.train_wav_dir +'\/' +df_train['\u30d5\u30a1\u30a4\u30eb']\ndf_test['file_path'] = data_path.test_wav_dir +'\/'+ df_test['\u30d5\u30a1\u30a4\u30eb']","f7d5ba41":"df = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)","f0cb106c":"# \u30b0\u30e9\u30d5\u306e\u8272\u3092\u7d20\u6750\u306b\u3088\u3063\u3066\u5909\u3048\u305f\u3044\u306e\u3067\u4f5c\u3063\u3066\u304a\u304f\ndf['\u7d20\u6750']='\u306d\u3058\uff1a'+df['\u306d\u3058']+'_\u30d7\u30ec\u30fc\u30c8\uff1a'+df['\u30d7\u30ec\u30fc\u30c8']\ncolor = df['\u7d20\u6750'].tolist()","791e3f32":"from typing import List\n\n# \u30d5\u30fc\u30ea\u30a8\u5909\u63db\u7528\u306ehepler\u30af\u30e9\u30b9\u3092\u4f5c\u308b\u3002\nclass FourieTransformHelper:\n    def __init__(self,  \n                 file_names: List[str],\n                 input_dir: str=None):\n        if isinstance(file_names, list):\n            self.file_names = file_names\n        else:\n            raise TypeError(f'file_names type is {type(file_names)} not list!')\n        self.input_dir = input_dir\n        self.spectra, self.frequencies = [], []\n        \n    def _get_spectrum(self, signal, sample_rate):\n        # \u53c2\u8003 https:\/\/medium.com\/analytics-vidhya\/simplifying-audio-data-fft-stft-mfcc-for-machine-learning-and-deep-learning-443a2f962e0e\n        fft = np.fft.fft(signal)\n        spectrum = np.abs(fft)\n        f = np.linspace(0, sample_rate, int(len(spectrum)\/2))\n        spectrum = spectrum[:int(len(spectrum)\/2)]\n        frequency = f[:int(len(spectrum)\/2)]\n        return spectrum, frequency\n    \n    def _get_filename(self, file_name):\n            if self.input_dir:\n                return f'{self.input_dir}\/{file_name}'\n            else:\n                return file_name\n    \n    def get_spectra(self):\n        for file_name in tqdm(self.file_names):\n            file_path = self._get_filename(file_name)\n            audio, sample_rate = librosa.load(file_path)\n            # \u9069\u5f53\u306a\u9577\u3055\u306b\u5207\u308a\u53d6\u308b\u3002\u30ad\u30ea\u306e\u3044\u3044\u6570\u5b57\u306b\u3057\u305f\u3002\n            audio = audio[:40000]\n            spectrum, frequency = self._get_spectrum(audio, sample_rate)\n            self.spectra.append(spectrum)\n            self.frequencies.append(frequency)                ","adffa2e2":"file_names = df['file_path'].tolist()","e0f964d2":"helper = FourieTransformHelper(file_names)\nhelper.get_spectra()","94a3b669":"# \u30d4\u30fc\u30af\u5024\u306f\u97f3\u306e\u5927\u304d\u3055\uff08\u6e2c\u5b9a\u6a5f\u307e\u3067\u306e\u8ddd\u96e2\u306e\u307f\u306b\u95a2\u4fc2\u3059\u308b\u3068\u3057\u3066\uff09\n# \u30b9\u30da\u30af\u30c8\u30eb\u3092\u6a19\u6e96\u5316\u3059\u308b\u3002\nspectra = minmax_scale(np.array(helper.spectra), axis=1)","eaf3d547":"def visualize_embed(embed: np.array, color: List[str], title: str) -> None:\n    fig = px.scatter(x=embed[:, 0], y=embed[:, 1], color=color, title=title)\n    fig.show()","42c2d62b":"\npca = PCA(n_components=2)\npca_embed = pca.fit_transform(spectra)\nvisualize_embed(pca_embed, color, 'PCA')\n\ntsne_embed = TSNE().fit_transform(spectra)\nvisualize_embed(tsne_embed, color, 't-SNE')\n\numap_embed = umap.UMAP().fit_transform(spectra)\nvisualize_embed(umap_embed, color, 'UMAP')","92defcfb":"# \u307e\u3068\u3081\n\u30b9\u30da\u30af\u30c8\u30eb\u306b\u5bfe\u3057\u3066\u4e09\u3064\u306e\u6b21\u5143\u524a\u6e1b\u306e\u624b\u6cd5\uff08PCA, t-SNE, UMAP\uff09\u3092\u884c\u3044\u307e\u3057\u305f\u3002<br>\n\u7d50\u679c\u3068\u3057\u3066\u3001\u30cd\u30b8\u3068\u30d7\u30ec\u30fc\u30c8\u306e\u6761\u4ef6\u304c\u540c\u3058\u3082\u306e\u306f\u6982\u306d\u91cd\u306a\u3089\u305a\u5206\u89e3\u3067\u304d\u308b\u3068\u308f\u501f\u308a\u307e\u3057\u305f\u3002<br>\n\u3064\u307e\u308a\u3001\u5143\u3005\u306e\u77e5\u308a\u305f\u3044\u3068\u601d\u3063\u3066\u3044\u305f\u3001\u30cd\u30b8\u3068\u30d7\u30ec\u30fc\u30c8\u306b\u3088\u3063\u3066\u30b9\u30da\u30af\u30c8\u30eb\u5f62\u72b6\u304c\u5909\u308f\u308a\u305d\u3046\u3060\u3068\u3044\u3046\u4eee\u5b9a\u306f\u3042\u308b\u7a0b\u5ea6\u771f\u3067\u3042\u308b\u3060\u308d\u3046\u3002<br>\n","56e3bf0f":"# \u8208\u5473\n\u30cd\u30b8\u3068\u30d7\u30ec\u30fc\u30c8\u306b\u3088\u3063\u3066\u30b9\u30da\u30af\u30c8\u30eb\u5f62\u72b6\u304c\u5909\u308f\u308a\u305d\u3046\u3060\u3068\u8003\u3048\u305f\u3002<br>\n\u3053\u308c\u304c\u4e8b\u5b9f\u304b\u78ba\u304b\u3081\u308b\u305f\u3081\u3001PCA, T-SNE, UMAP\u3092\u4f7f\u3063\u3066\u6b21\u5143\u524a\u6e1b\u3092\u884c\u3044\u5dee\u304c\u6349\u3048\u308c\u308b\u306e\u304b\u53ef\u8996\u5316\u3057\u3066\u307f\u308b\u3002<br>"}}