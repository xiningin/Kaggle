{"cell_type":{"13c391f6":"code","164fc8f8":"code","9cf10d44":"code","90af6409":"code","62befe52":"code","3e16ae7c":"code","e09eaeb4":"code","d1215983":"code","46f05c0e":"code","1e1d203b":"code","864125d9":"code","de827e6a":"code","c35bc46e":"code","ca6b83ce":"code","49b47d05":"code","42307f68":"code","eea0ffd4":"code","97dcde67":"code","5c4de683":"code","1c1f90e3":"code","7eb55a10":"code","677771d2":"code","fb36e8d1":"code","f53db03f":"code","9e1a5b96":"code","baf41fb9":"code","6464db13":"code","8e4eb281":"markdown","34623a14":"markdown","f3803ec3":"markdown","1adc034f":"markdown","5aa4683d":"markdown","290662ce":"markdown","6fc3210c":"markdown","0fab6bfb":"markdown","18147f9d":"markdown","5bbbe28a":"markdown","72cd99ad":"markdown","e448471c":"markdown","42c8a521":"markdown","bf42fd38":"markdown","2b39253a":"markdown","e78372fa":"markdown"},"source":{"13c391f6":"import pandas as pd\nimport numpy as np","164fc8f8":"dataset = pd.read_csv('..\/input\/data-cleaning\/BL-Flickr-Images-Book.csv')\ndataset.head()","9cf10d44":"to_drop = ['Edition Statement',\n                 'Corporate Author',\n                 'Corporate Contributors',\n                 'Former owner',\n                 'Engraver',\n                 'Contributors',\n                 'Issuance type',\n                 'Shelfmarks']","90af6409":"dataset.head()","62befe52":"dataset.drop(columns=to_drop, inplace = True)","3e16ae7c":"dataset.head()","e09eaeb4":"dataset['Identifier'].is_unique","d1215983":"dataset = dataset.set_index('Identifier')\ndataset.head()","46f05c0e":"dataset.iloc[206]","1e1d203b":"dataset.dtypes","864125d9":"dataset.loc[1905:, 'Date of Publication'].head()","de827e6a":"extr = dataset['Date of Publication'].str.extract(r'^(d{4})', expand = False)\nextr.head()","c35bc46e":"dataset['Place of Publication'].head(10)","ca6b83ce":"dataset.loc[4157862]","49b47d05":"pub = dataset['Place of Publication']\nlondon = pub.str.contains('London')\nlondon[:5]","42307f68":" dataset['Place of Publication'].head()","eea0ffd4":"university_towns = []\nwith open('..\/input\/data-cleaning\/university_towns.txt') as file:\n    for line in file:\n        if '[edit]' in line:\n            # Remember this `state` until the next is found\n            state = line\n        else:\n            # Otherwise, we have a city; keep `state` as last-seen\n            university_towns.append((state, line))","97dcde67":"university_towns[:5]","5c4de683":"towns_df = pd.DataFrame(university_towns,\n                        columns=['State', 'RegionName'])\ntowns_df.head()","1c1f90e3":"def get_citystate(item):\n    if ' (' in item:\n        return item[:item.find(' (')]\n    elif '[' in item:\n        return item[:item.find('[')]\n    else:\n        return item","7eb55a10":"towns_df = towns_df.applymap(get_citystate)","677771d2":"towns_df.head()","fb36e8d1":"olympics_df = pd.read_csv('..\/input\/data-cleaning\/olympics.csv')\nolympics_df.head()","f53db03f":"olympics_df = pd.read_csv('..\/input\/data-cleaning\/olympics.csv', header = 1)\nolympics_df.head()","9e1a5b96":"new_names = {'Unnamed: 0': 'Country',\n        '? Summer': 'Summer Olympics',\n        '01 !': 'Gold',\n        '02 !': 'Silver',\n        '03 !': 'Bronze',\n        '? Winter': 'Winter Olympics',\n        '01 !.1': 'Gold.1',\n        '02 !.1': 'Silver.1',\n        '03 !.1': 'Bronze.1',\n        '? Games': '# Games',\n        '01 !.2': 'Gold.2',\n        '02 !.2': 'Silver.2',\n        '03 !.2': 'Bronze.2'}","baf41fb9":"olympics_df.rename(columns=new_names, inplace=True)","6464db13":"olympics_df.head()","8e4eb281":"Above, we defined a list that contains the names of all the columns we want to drop. Next, we call the drop() function on\nour object, passing in the inplace parameter as True and the axis parameter as 1. This tells Pandas that we want the\nchanges to be made directly in our object and that it should look for the values to be dropped in the columns of the\nobject.","34623a14":"# <b style=\"color:blue\">Dropping Columns in a DataFrame:<\/b>\nOften, you\u2019ll find that not all the categories of data in a dataset are useful to you. For example, you might have a dataset\ncontaining student information (name, grade, standard, parents\u2019 names, and address) but want to focus on analyzing\nstudent grades.\nIn this case, the address or parents\u2019 names categories are not important to you. Retaining these unneeded categories\nwill take up unnecessary space and potentially also bog down runtime.\nPandas provides a handy way of removing unwanted columns or rows from a DataFrame with the drop() function. Let\u2019s\nlook at a simple example where we drop a number of columns from a DataFrame.\nFirst, let\u2019s create a DataFrame out of the CSV file \u2018BL-Flickr-Images-Book.csv\u2019. In the examples below, we pass a relative\npath to pd.read_csv, meaning that all of the datasets are in a folder named Datasets in our current working directory:","f3803ec3":"# Table of Contents\n* Dropping Columns in a DataFrame\n* Changing the Index of a DataFrame\n* Tidying up Fields in the Data\n* Combining str Methods with NumPy to Clean Columns\n* Cleaning the Entire Dataset Using the applymap Function\n* Renaming Columns and Skipping Rows\n* Python Data Cleaning: Recap and Resources","1adc034f":"While we could have cleaned these strings in the for loop above, Pandas makes it easy. We only need the state name and\nthe town name and can remove everything else. While we could use Pandas\u2019 .str() methods again here, we could also\nuse applymap() to map a Python callable to each element of the DataFrame.","5aa4683d":"# <b style=\"color:blue\"> Renaming Columns and Skipping Rows:<\/b>\nOften, the datasets you\u2019ll work with will have either column names that are not easy to understand, or unimportant\ninformation in the first few and\/or last rows, such as definitions of the terms in the dataset, or footnotes.","290662ce":"# Load the dataset","6fc3210c":"When we inspect the DataFrame again, we\u2019ll see that the unwanted columns have been removed:","0fab6bfb":"Alternatively, we could also remove the columns by passing them to the columns parameter directly instead of\nseparately specifying the labels to be removed and the axis where Pandas should look for the labels:","18147f9d":"# <b style=\"color:blue\">Combining str Methods with NumPy to Clean Columns: <\/b>","5bbbe28a":"# <b style=\"color:blue\">Changing the Index of a DataFrame:<\/b>","72cd99ad":"# import the required modules and get started!","e448471c":"# <b style=\"color:blue\">Cleaning the Entire Dataset Using the applymap Function:<\/b>\n\nIn certain situations, you will see that the \u201cdirt\u201d is not localized to one column but is more spread out.\nThere are some instances where it would be helpful to apply a customized function to each cell or element of a\nDataFrame. Pandas .applymap() method is similar to the in-built map() function and simply applies a function to all the\nelements in a DataFrame.\nLet\u2019s look at an example. We will create a DataFrame out of the \u201cuniversity_towns.txt\u201d file:","42c8a521":"So far, we have removed unnecessary columns and changed the index of our DataFrame to something more sensible. In\nthis section, we will clean specific columns and get them to a uniform format to get a better understanding of the\ndataset and enforce consistency. In particular, we will be cleaning Date of Publication and Place of Publication.\nUpon inspection, all of the data types are currently the object dtype, which is roughly analogous to str in native\nPython.\nIt encapsulates any field that can\u2019t be neatly fit as numerical or categorical data. This makes sense since we\u2019re working\nwith data that is initially a bunch of messy strings:","bf42fd38":"Data scientists spend a large amount of their time cleaning datasets and getting them down to a form with which they\ncan work. In fact, a lot of data scientists argue that the initial steps of obtaining and cleaning data constitute 80% of the\njob.\nTherefore, if you are just stepping into this field or planning to step into this field , it is important to be able to deal with\nmessy data, whether that means missing values, inconsistent formatting, malformed records, or nonsensical outliers.\nIn this tutorial, we\u2019ll leverage Python\u2019s Pandas and NumPy libraries to clean data.\nWe\u2019ll cover the following:\nDropping unnecessary columns in a DataFrame\nChanging the index of a DataFrame\nUsing .str() methods to clean columns\nUsing the DataFrame.applymap() function to clean the entire dataset, element-wise\nRenaming columns to a more recognizable set of labels\nSkipping unnecessary rows in a CSV file","2b39253a":"We can access each record in a straightforward way with loc[]. Although loc[] may not have all that intuitive of a\nname, it allows us to do label-based indexing, which is the labeling of a row or record without regard to its position:","e78372fa":"# <b style=\"color:blue\">Tidying up Fields in the Data:<\/b>"}}