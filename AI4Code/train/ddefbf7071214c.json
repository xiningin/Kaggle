{"cell_type":{"a4186ca3":"code","9f64e63c":"code","920c1770":"code","a4d53087":"code","3a758238":"code","c2a563e0":"code","3e1f2389":"code","035851fc":"code","94d0421b":"code","be727b6f":"code","cd78e7ce":"code","368c481e":"code","0f9c2c43":"code","ee9f8b41":"code","8dd1314e":"code","0532fb28":"code","154998af":"code","47165283":"code","eb01fdb1":"code","1d554262":"code","bcc0f38d":"code","db1eda71":"code","8d79446b":"code","26256970":"code","29ec0c39":"code","d7de77ab":"code","1b948c3b":"code","5e03155b":"code","2bbedb5a":"code","e7149f60":"code","8e6d4f16":"code","fab90346":"code","2501d01b":"code","d905ff94":"code","3b41da7b":"code","6eb1e0b9":"code","16878651":"code","6dc728bf":"markdown","f55cd905":"markdown","9c244472":"markdown","db0bb50e":"markdown","0f28055c":"markdown","f9f7f61b":"markdown","8715db47":"markdown","5fff3276":"markdown","f0d0d567":"markdown","262fc02c":"markdown","2321a7d1":"markdown","453da67f":"markdown","30b1a676":"markdown","7cd2c266":"markdown","e8986008":"markdown","673128f9":"markdown","32ba0e85":"markdown","2abc158f":"markdown","6266a7d3":"markdown"},"source":{"a4186ca3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9f64e63c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","920c1770":"df = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head()","a4d53087":"df.info()","3a758238":"df.describe()","c2a563e0":"df.isnull().sum()","3e1f2389":"sns.countplot(df['quality']);","035851fc":"df.columns","94d0421b":"g = sns.FacetGrid(df, hue=\"quality\",height=5)\ng = g.map(sns.distplot, \"alcohol\")\nplt.legend();","be727b6f":"g = sns.FacetGrid(df, hue=\"quality\",height=5)\ng = g.map(sns.distplot, \"pH\")\nplt.legend();","cd78e7ce":"from statsmodels.formula.api import ols      # For calculation of Ordinary least squares for ANOVA\nfrom statsmodels.stats.anova import _get_covariance,anova_lm # For n-way ANOVA\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd # For performing the Tukey-HSD test\nfrom statsmodels.stats.multicomp import MultiComparison # To compare the levels  independent variables with the \nimport scipy.stats as stats ","368c481e":"df_melt = pd.melt(df.reset_index(), id_vars=['index'], value_vars=['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar','chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density','pH', 'sulphates', 'alcohol','quality'])","0f9c2c43":"df_melt.head()","ee9f8b41":"df_melt['variable'].unique()","8dd1314e":"df_melt.columns = ['index', 'treatments', 'value']","0532fb28":"model = ols('value ~ C(treatments)', data=df_melt).fit()\nanova_table = anova_lm(model, typ=2)\nanova_table\n#Type 1 2 and 3 yield same result if the data is balanced","154998af":"### lets check for quality and alcohol","47165283":"formula = 'alcohol ~ C(quality)'\nmodel = ols(formula, df).fit()\naov_table = anova_lm(model)\naov_table","eb01fdb1":"formula = 'pH ~ C(quality)'\nmodel = ols(formula, df).fit()\naov_table = anova_lm(model)\naov_table","1d554262":"sns.pointplot(x='quality', y='alcohol', data=df,ci=0.95,color='g');\nsns.pointplot(x='quality', y='pH', data=df,ci=0.95,color='r');","bcc0f38d":"#Causal relation bwetween pH and quality\nmc = MultiComparison(df['pH'], df['quality'])\nmc_results = mc.tukeyhsd(alpha=0.05)\nprint(mc_results)","db1eda71":"#causal relation bwetween alcohol and quality\nmc = MultiComparison(df['alcohol'], df['quality'])\nmc_results = mc.tukeyhsd(alpha=0.05)\nprint(mc_results)","8d79446b":"import statsmodels.api as sm","26256970":"X = df.drop('quality',axis=1)\ny = df['quality']","29ec0c39":"model = sm.OLS(y, X).fit()\npredictions = model.predict(X)","d7de77ab":"print(model.summary())","1b948c3b":"from scipy.stats import pearsonr\nfrom statsmodels.compat import lzip\nimport statsmodels.stats.api as sms\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","5e03155b":"df[df.columns].corr(method='pearson')","2bbedb5a":"plt.figure(figsize=(15,6))\nsns.heatmap(df.corr(method='pearson'),annot=True);","e7149f60":"#Formulae = (1\/1-R^2)\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns","8e6d4f16":"vif\n# All VIF values are different , if two or more than two values have same VIF or variability the ","fab90346":"sns.residplot(predictions,y-predictions);","2501d01b":"name = ['GQ', 'p-value']\ntest = sms.het_goldfeldquandt(y-predictions,X)\nlzip(name, test)\n#failed to reject null hypothesis so data is homoscedastic","d905ff94":"from scipy.stats import shapiro\nshapiro(np.abs(y-predictions))\n# Error term is normally distributed as it rejects the null hypothesis","3b41da7b":"res = model.resid\nfig = sm.qqplot(res,fit=True,line='45')\nplt.show()\n##Red line denotes normal line\n##blue dots are the error terms","6eb1e0b9":"from sklearn.metrics import mean_squared_error\nimport math\nprint('MSE',mean_squared_error(y,predictions))\nprint('RMSE',math.sqrt(mean_squared_error(y,predictions)))","16878651":"from sklearn.metrics import mean_absolute_error\nprint('MAE',mean_absolute_error(y,predictions))","6dc728bf":"## Linear Regression Assumptions","f55cd905":"### Quality based on pH value","9c244472":"### Test for checking Homoscadesticity is the Goldfeldquandt test","db0bb50e":"### Calculate OLS model(ordinary least square )","0f28055c":"* 98.7% of dependent variability explained by this model\n* Adj. R-squared:0.987\n* R-squared:0.987\n","f9f7f61b":" F values is less than 0.05 which means of all groups means are not equal.Data is statistically significant","8715db47":"### Mean Square Error(MSE)\/Root Mean Square Error(RMSE)","5fff3276":"## Thumb rules to help interpret goodness of fit in Regression model\n1. R-sq \/ Adj R-sq shows Goodness of fit. More favorable to have higher value (0-1)\n2. Prob (F-statistic) Less than Alpha Reject\n3. Log-Likelihood: - Goodness of fit (Higher the better when comparing multiple models)\n4. AIC(Akaike's Information Criterion),BIC(Bayesian Information Criterion):- Goodness of fit (Lower the better the when comparing multiple models)","f0d0d567":"*certain group means are not equal as per tukey HSD test for alcohol and PH.\nCan be done similarly for remaining column with respect to quality.*","262fc02c":"### mean Absolute Error","2321a7d1":"#### R Square\/Adjusted R Square","453da67f":"## Assumptions tested\n1. Omnibus\/Prob(Omnibus) \u2013 a test of the skewness and kurtosis of the residual Omnimbus preferably closer to Zero & Prob(Omnibus) preferably closer to 1\n2. Skew \u2013 a measure of data symmetry. We want to see something close to zero, indicating the residual distribution is normal.\n3. Kurtosis \u2013 a measure of \"peakiness\", or curvature of the data. Higher peaks lead to greater Kurtosis. Greater Kurtosis can be interpreted as a tighter clustering of residuals around zero, implying a better model with few outliers\n4. Durbin-Watson \u2013 tests for Auto correlation We hope to have a value between 1.5 and 2.5\n5. Jarque-Bera (JB)\/Prob(JB) \u2013 like the Omnibus test in that it tests both skew and kurtosis.\n6. Condition Number \u2013 This test measures the sensitivity of a function's output as compared to its input. When we have multicollinearity, we can expect much higher fluctuations to small changes in the data, hence, we hope to see a relatively small number.","30b1a676":"### Basic EDA","7cd2c266":"### ANOVA method","e8986008":"### Normal Distirbution of Error term","673128f9":"### Variance Inflation Factor","32ba0e85":"### Quality based on alcohol content","2abc158f":"horizontal bands show homoscedasticity","6266a7d3":"## Model Evaluation"}}