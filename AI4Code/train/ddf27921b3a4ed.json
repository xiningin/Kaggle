{"cell_type":{"dced0ab0":"code","5bb25683":"code","063f3612":"code","a8597348":"code","326afb3a":"code","0c9ff358":"code","6f920b09":"code","794fadad":"code","a4e38b17":"code","63bfb39b":"code","f0038832":"code","f3be0b34":"code","5fc09700":"code","d6581cb9":"code","ca59e25f":"code","e7c17862":"code","942cded4":"code","60319231":"code","48e93e1b":"code","bba37cb0":"code","2b92a1af":"code","f8e1f602":"code","a1079140":"code","505dbc4a":"code","5186600f":"code","2f457678":"code","70aedbe0":"code","e182db92":"code","ee83d880":"code","f47570df":"markdown","da274139":"markdown","275cbce6":"markdown","2fcd17ec":"markdown","108814aa":"markdown","b916e4df":"markdown","867c83dc":"markdown","1fdcbc07":"markdown","d2c43d1a":"markdown","44a07dd5":"markdown","9968f4f1":"markdown","f8be454b":"markdown","f27abab4":"markdown"},"source":{"dced0ab0":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","5bb25683":"from fastai import *\nfrom fastai.vision import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nfrom fastai.callbacks import *\n\nimport PIL\nimport cv2","063f3612":"# Set seed for all\ndef seed_everything(seed=1358):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything()","a8597348":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","326afb3a":"PATH = Path('..\/input\/aptos2019-blindness-detection')","0c9ff358":"df = pd.read_csv(PATH\/'train.csv')\ndf.head()","6f920b09":"!ls ..\/input\/resnet50\/","794fadad":"# copy pretrained weights for resnet50 to the folder fastai will search by default\nPath('\/tmp\/.cache\/torch\/checkpoints\/').mkdir(exist_ok=True, parents=True)\n!cp '..\/input\/resnet50\/resnet50.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth'","a4e38b17":"df.diagnosis.value_counts() ","63bfb39b":"IMG_SIZE = 512\n\ndef _load_format(path, convert_mode, after_open)->Image:\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0), 10) ,-4 ,128)\n                    \n    return Image(pil2tensor(image, np.float32).div_(255)) #return fastai Image format\n\nvision.data.open_image = _load_format\n    \nsrc = (\n    ImageList.from_df(df,PATH,folder='train_images',suffix='.png')\n        .split_by_rand_pct(0.2, seed=42)\n        .label_from_df(cols='diagnosis',label_cls=FloatList)    \n    )\nsrc","f0038832":"tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.3, max_warp=0.0, max_lighting=0.2)","f3be0b34":"data = (\n    src.transform(tfms,size=128)\n    .databunch()\n    .normalize(imagenet_stats)\n)\ndata","5fc09700":"# Definition of Quadratic Kappa\nfrom sklearn.metrics import cohen_kappa_score\ndef quadratic_kappa(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')\n\nlearn = cnn_learner(data, base_arch=models.resnet50 ,metrics=[quadratic_kappa],model_dir='\/kaggle',pretrained=True)","d6581cb9":"# Find a good learning rate\nlearn.lr_find()\nlearn.recorder.plot()","ca59e25f":"lr = 1e-2\nlearn.fit_one_cycle(3, lr)","e7c17862":"# progressive resizing\nlearn.data = data = (\n    src.transform(tfms,size=224)\n    .databunch()\n    .normalize(imagenet_stats)\n)\nlearn.lr_find()\nlearn.recorder.plot()","942cded4":"lr = 1e-2\nlearn.fit_one_cycle(20, lr)","60319231":"learn.unfreeze()\n\nlearn.lr_find()\nlearn.recorder.plot()","48e93e1b":"learn.fit_one_cycle(8, slice(1e-6,1e-3))","bba37cb0":"valid_preds = learn.get_preds(ds_type=DatasetType.Valid)","2b92a1af":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","f8e1f602":"optR = OptimizedRounder()\noptR.fit(valid_preds[0],valid_preds[1])","a1079140":"coefficients = optR.coefficients()\nprint(coefficients)","505dbc4a":"# test_df = pd.read_csv(PATH\/'test.csv')\n# test_df.head()\nsample_df = pd.read_csv(PATH\/'sample_submission.csv')\nsample_df.head()","5186600f":"learn.data.add_test(ImageList.from_df(sample_df,PATH,folder='test_images',suffix='.png'))","2f457678":"preds,y = learn.get_preds(DatasetType.Test)\n","70aedbe0":"test_predictions = optR.predict(preds, coefficients)","e182db92":"sample_df.diagnosis = test_predictions.astype(int)\nsample_df.head()","ee83d880":"sample_df.to_csv('submission.csv',index=False)","f47570df":"# Data","da274139":"Now switching to 224x224 size which is usually used for ResNet 50:","275cbce6":"\n\n# Predictions","2fcd17ec":"# Libraries import","108814aa":"# Ben's Preprocessing Functions","b916e4df":"This part is taken from @abhishek great kernel: https:\/\/www.kaggle.com\/abhishek\/optimizer-for-quadratic-weighted-kappa","867c83dc":"These functions are taken from famous kernel https:\/\/www.kaggle.com\/ratthachat\/aptos-updatedv14-preprocessing-ben-s-cropping. Below I am showing how they can be applied for fast.ai pipeline. ","1fdcbc07":"# Model","d2c43d1a":"Let's train with small image size first to get some rough approximation","44a07dd5":"Initially I forked from this [kernel](https:\/\/www.kaggle.com\/khursani8\/fast-ai-starter-resnet34), changed architecture to ResNet 50, added augmentation and did some initial tuning of parameters like learning rate.","9968f4f1":"# Metric Optimization","f8be454b":"So our train set is definitely imbalanced, majority of images are normal (without illness).","f27abab4":"In later versions I plugged in OptimizedRounder class and Ben's processing functions."}}