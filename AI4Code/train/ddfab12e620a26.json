{"cell_type":{"8a8470e9":"code","aaf925a5":"code","9175c3ec":"code","b142b1b0":"code","b3332dc5":"code","d8247c11":"code","90faffd6":"code","f6a4a59b":"code","04a5a9a3":"code","c732aa0d":"code","cbdb42f0":"code","a50c0f41":"code","a1df67c6":"code","bf0d9389":"code","c71bcf5d":"code","d7a76b28":"code","22257c25":"code","dc1944e1":"code","0a9f3b64":"code","36174c9c":"markdown","a2f8c69e":"markdown","56933754":"markdown","a1580ad1":"markdown","d772c703":"markdown","9fc28354":"markdown","750f127e":"markdown","7e3fdcb9":"markdown","a3db9a54":"markdown","5ee47088":"markdown","4248c072":"markdown","cb8f8727":"markdown","9940a06b":"markdown","b9717dba":"markdown","ddaa5a55":"markdown","56937158":"markdown","2fb60664":"markdown","1a154f31":"markdown","ee6ce10b":"markdown","cdc21526":"markdown","e7f81a18":"markdown"},"source":{"8a8470e9":"# Data Manipulation & Visualization\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns # used for plot interactive graph. \nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n\n# Text Manipulation\nimport re\nfrom wordcloud import STOPWORDS\nfrom nltk import FreqDist, word_tokenize\nfrom nltk import bigrams, trigrams\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nstopwords = set(STOPWORDS)\n\n# Machine Learning\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix,mean_squared_error,mean_absolute_error,log_loss,accuracy_score,classification_report\nfrom sklearn.metrics import precision_score\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing","aaf925a5":"train = pd.read_csv(\"..\/input\/product-sentiment-classification\/Participants_Data\/Train.csv\")\ntest = pd.read_csv(\"..\/input\/product-sentiment-classification\/Participants_Data\/Test.csv\")","9175c3ec":"# we take only what we need\ntrain = train[['Product_Description','Product_Type','Sentiment']]","b142b1b0":"fig,ax = plt.subplots(ncols=2,nrows=1,dpi=100,figsize=(17,5))\nsns.countplot(data=train,x=\"Product_Type\",hue=\"Sentiment\",edgecolor=\"black\",ax=ax[0],linewidth=2)\nax[0].legend(loc=\"upper left\",labels=[\"Cannot say\",\"Negative\",\"Positive\",\"No sentiment\"])\nax[0].set_title('Sentiment by product in train set',size=17)\nax[0].set_xlabel(\"Product type\")\n\nsns.countplot(data=train,x=\"Sentiment\",edgecolor=\"black\",ax=ax[1],linewidth=2)\nax[1].legend(loc=\"upper left\")\nax[1].set_title('Sentiment distribution in train set',size=17)\nax[1].set_xticklabels([\"Cannot say\",\"Negative\",\"Positive\",\"No sentiment\"])\nax[1].set_xlabel(\"\")\n\nplt.show() ","b3332dc5":"test_str = train.loc[0, 'Product_Description']\n\ndef clean_text(text):\n    text = re.sub(r'\\n',' ', text) # Remove line breaks\n    text=  re.sub('@mention',' ', text )\n    text=  re.sub('{link}',' ', text )\n    text=  re.sub('\u00db\u00aa',' ', text )\n    text=  re.sub('  ',' ', text )\n    text=  re.sub('RT',' ', text )\n    text=  re.sub('\/\/',' ', text )\n    text=  re.sub('&quot',' ', text )\n    text=  re.sub('&amp',' ', text )\n    text=  re.sub(r'[^\\w\\s]',' ', text )\n    text=  re.sub(' +',' ', text )\n    return text\n\ndef process_text(df):\n    df['description'] = df['Product_Description'].apply(lambda x: clean_text(x))\n    return df\n\nprint(\"Original text: \" + test_str)\nprint(\"Cleaned text: \" + clean_text(test_str))\n","d8247c11":"train = process_text(train)\ntest = process_text(test)\ntrain.drop('Product_Description',1,inplace=True)\ntest.drop('Product_Description',1,inplace=True)","90faffd6":"plt.figure(figsize=(10,5))\nword_freq = FreqDist(w for w in word_tokenize(' '.join(train['description']).lower()) if \n                     (w not in stopwords) & (w.isalpha()))\ndf_word_freq = pd.DataFrame.from_dict(word_freq, orient='index', columns=['count'])\ntop20w = df_word_freq.sort_values('count',ascending=False).head(5)\nlast20w=df_word_freq.sort_values('count',ascending=False).tail(5)\n\nsns.barplot(top20w['count'],top20w.index,color='purple',edgecolor=\"black\",linewidth=2)\nplt.title(\"Top 5 words in train\",size=17)\nplt.show()","f6a4a59b":"fig,axes=plt.subplots(ncols=2,figsize=(17,5),dpi=100)\n###bigrams\nbigram = list(bigrams([w for w in word_tokenize(' '.join(train['description']).lower()) if \n              (w not in stopwords) & (w.isalpha())]))\nfq = FreqDist(bg for bg in bigram)\nbgdf = pd.DataFrame.from_dict(fq, orient='index', columns=['count'])\nbgdf.index = bgdf.index.map(lambda x: ' '.join(x))\nbgdf = bgdf.sort_values('count',ascending=False)\n\n#trigrams\ntrigram = list(trigrams([w for w in word_tokenize(' '.join(train['description']).lower()) if \n              (w not in stopwords) & (w.isalpha())]))\ntr_fq = FreqDist(bg for bg in trigram)\ntrdf = pd.DataFrame.from_dict(tr_fq, orient='index', columns=['count'])\ntrdf.index = trdf.index.map(lambda x: ' '.join(x))\ntrdf = trdf.sort_values('count',ascending=False)\n\nsns.barplot(bgdf.head(10)['count'], bgdf.index[:10], ax=axes[1],color='green',edgecolor='black',linewidth=2)\nsns.barplot(trdf.head(10)['count'], trdf.index[:10],ax=axes[0], color='red',edgecolor='black',linewidth=2)\n\naxes[0].set_title('Top 10 Trigrams',size=18)\naxes[1].set_title('Top 10 Bigrams',size=18)\n\nplt.show()","04a5a9a3":"d = '..\/input\/masks-for-wordcloud\/'\ncomments_mask = np.array(Image.open(d + 'oval.jpg'))\n\nlong_string = ','.join(list(train['description'].values))\nwordcloud = WordCloud(background_color='black',max_words=500, contour_width=5, contour_color='black',\n                      width=1000,height=200,stopwords=stopwords,mask=comments_mask)\nwordcloud.generate(str(long_string))\nwordcloud.to_image()","c732aa0d":"from sklearn.model_selection import train_test_split\n\nX = train['description']\ny = train['Sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","cbdb42f0":"nb = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', MultinomialNB())\n              ])\n\nnb.fit(X_train, y_train)\n\ny_pred = nb.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='viridis',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n Naive Bayes',size=16)\nplt.show()","a50c0f41":"lr = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', LogisticRegression())\n              ])\n\nlr.fit(X_train, y_train)\n\ny_pred = lr.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='Spectral',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n Logistic Regression',size=16)\nplt.show()","a1df67c6":"lsvc = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', LinearSVC())\n              ])\n\nlsvc.fit(X_train, y_train)\n\ny_pred = lsvc.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='Blues',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n Linear SVC',size=16)\nplt.show()","bf0d9389":"rf = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', RandomForestClassifier(n_estimators=300))\n              ])\n\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='BuGn',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n Random Forest',size=16)\nplt.show()","c71bcf5d":"xgb = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', XGBClassifier(objective=\"multi:softmax\",n_estimators=200,learning_rate=0.01))\n              ])\n\nxgb.fit(X_train, y_train)\n\ny_pred = xgb.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='Set1',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n XGB Classifier',size=16)\nplt.show()","d7a76b28":"test['Sentiment']= nb.predict(test.description)","22257c25":"fig,ax = plt.subplots(ncols=2,nrows=1,dpi=100,figsize=(17,5))\nsns.countplot(data=test,x=\"Product_Type\",hue=\"Sentiment\",edgecolor=\"black\",ax=ax[0],linewidth=2)\nax[0].legend(loc=\"upper left\",labels=[\"Negative\",\"Positive\",\"No sentiment\"])\nax[0].set_title('Sentiment by Product in test set',size=17)\nax[0].set_xlabel(\"Product type\")\n\nsns.countplot(data=test,x=\"Sentiment\",edgecolor=\"black\",ax=ax[1],linewidth=2)\nax[1].legend(loc=\"upper left\")\nax[1].set_title('Sentiment test set',size=17)\nax[1].set_xticklabels([\"Negative\",\"Positive\",\"No sentiment\"])\nax[1].set_xlabel(\"\")\n\nplt.show()","dc1944e1":"submission = pd.DataFrame(nb.predict_proba(test.description))\nsubmission.head()","0a9f3b64":"submission.to_csv('sample_submission.csv',index=False)","36174c9c":"<a id='obj'><\/a>\n# Loading data...","a2f8c69e":"###\u00a0Metrics:\n\n* #### Multinomial NB - Accuracy:0.66 - Weighted Precision: 0.88\n* #### Logistic Regression - Accuracy:0.67 - Weighted Precision: 0.79\n* #### Linear SVC - Accuracy:0.67 - Weighted Precision: 0.71\n* #### Random Forest - Accuracy:0.67 - Weighted Precision: 0.77\n* #### Multinomial NB - Accuracy:0.65 - Weighted Precision: 0.86\n\n### Naive Bayes win!","56933754":"<a id='eda'><\/a>\n# What we find in the train set?","a1580ad1":"## Top 5 Words","d772c703":"## Random Forest","9fc28354":"## Multinomial NB","750f127e":"<a id='textclassification'><\/a>\n# Text Classification","7e3fdcb9":"<a id='textanalysis'><\/a>\n# Text Analysis","a3db9a54":"## Linear SVC","5ee47088":"<a id='eda2'><\/a>\n# What we find in test set?","4248c072":"## XGB Classifier","cb8f8727":"<a id='submission'><\/a>\n\n# Submission","9940a06b":"Analyzing sentiments related to various products such as Tablet, Mobile and various other gizmos can be fun and difficult especially when collected across various demographics around the world. Analyzing these sentiments will not only help us serve the customers better but can also reveal lot of customer traits present\/hidden in the reviews.\n\nSo the task of this dataset is to correctly classify product description sentiment: our goal,insted, is to investigate which supervised machine learning methods are best suited to solve it.\n\n\n# Table of contents\n\n* [Loading data...](#obj)\n* [What we find in train set?](#eda)\n* [Text Cleaning](#textcleaning)\n* [Text Analysis](#textanalysis)\n* [Text Classification](#textclassification)\n* [What we find in test set?](#eda2****)\n* [Submission](#submission)","b9717dba":"### This is just a little example on how NLP multi-class classification can be made, there are a lot of way to improve on this.\n### If you liked please upvote!","ddaa5a55":"## Logistic Regression","56937158":"<a id='textcleaning'><\/a>\n# Text Cleaning","2fb60664":"**Positive sentiment is focused only on 9th Product and overall the most present sentiment is Positive(2) and Neutral(3)**","1a154f31":"### Let'see the predicted sentiment distribution in test set ( Will it be real? According to Multinomial Naive Bayes ): ","ee6ce10b":"## Top 10 Bigrams and Trigrams","cdc21526":"We are now ready to experiment with different machine learning models, evaluate their accuracy and find the source of any potential issues.\nWe will benchmark the following five models:\n* (Multinomial) Naive Bayes\n* Logistic Regression\n* Linear Support Vector Machine\n* Random Forest\n* XGB Classifier\n\n**For evaluating our models performance we must take into account the strong label imbalance; for this purpose its better to choose an alternative metrics than standard accuracy:**\n* Precision (tp \/ (tp + fp) ) measures the ability of a classifier to identify only the correct instances for each class.\n\n**Since we need to \"weight\" the score, we averaging precision weighted by label**","e7f81a18":"## WordCloud"}}