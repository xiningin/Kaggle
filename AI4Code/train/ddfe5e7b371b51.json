{"cell_type":{"4e9f4f54":"code","cd12f484":"code","e1466783":"code","c9c3b617":"code","2f9f26ec":"code","3850912c":"code","4d0d21f2":"code","4ea3578f":"code","93bb35fd":"code","d69a0a54":"code","fb4c6105":"code","a6293adb":"code","1f08647d":"code","04ffb396":"code","fe2def9f":"code","cb03a4bf":"code","b47c469e":"code","b9666ebe":"code","4aa48c5e":"code","ad8e1cba":"code","1b4110f4":"markdown","0fbb5d21":"markdown","fa7dc89e":"markdown","8b51d213":"markdown","2ffbc9f2":"markdown","cbe4ebf1":"markdown","69f1f228":"markdown"},"source":{"4e9f4f54":"!pip install feedparser\nimport feedparser\nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# sklearn\n# ML classificators\nfrom sklearn.linear_model import SGDClassifier\n# ML selecao de dados de treino e teste\nfrom sklearn.model_selection import train_test_split, cross_val_score\n# confusion matrics\nfrom sklearn.metrics import confusion_matrix\n# metrics\nfrom sklearn import metrics\n# vetorizador\nfrom sklearn.feature_extraction.text import TfidfVectorizer","cd12f484":"# get news\nrssAll = {\n    'nfl': 'https:\/\/www.espn.com\/espn\/rss\/nfl\/news',\n    'nba': 'https:\/\/www.espn.com\/espn\/rss\/nba\/news',\n    'motor': 'https:\/\/www.espn.com\/espn\/rss\/rpm\/news',\n    'futebol': 'https:\/\/www.espn.com\/espn\/rss\/soccer\/news',\n    'mlb': 'https:\/\/www.espn.com\/espn\/rss\/mlb\/news',\n    'nhl': 'https:\/\/www.espn.com\/espn\/rss\/nhl\/news',\n    'Poker': 'https:\/\/www.espn.com\/espn\/rss\/poker\/master'\n}\n\n# creating dataframe\ntipo = []\ntitulo = []\ntexto = []\nfor i in rssAll.items():\n    for j in feedparser.parse(i[1]).entries:\n        tipo.append(i[0])\n        titulo.append(j['title'])\n        texto.append(j['title'] + '. ' + j['summary'])\ndf = pd.DataFrame({'tipo': tipo, 'titulo': titulo, 'miniNews': texto})\n# get uniques news categories\ntipos = df['tipo'].unique()","e1466783":"# showing categories news (uniques)\ntipos","c9c3b617":"# creating words dictionary\ntextos = df['miniNews']\npalavras = textos.str.lower().str.split()\n\ndicionario = set()\nlista = []\nfor i in palavras:\n    dicionario.update(i)\n    for j in i:\n        lista.append(j)\n\npalavraEposicao = dict(zip(dicionario, range(len(dicionario))))","2f9f26ec":"palavraEposicao","3850912c":"def textToNro(txt):\n    global tipos\n    return list(tipos).index(txt)\n\n\ndf['tipoN'] = df['tipo'].apply(textToNro)","4d0d21f2":"# Split data train and test using sklearn\nX = textos\ny = df.tipoN\n\nXtreino, Xteste, ytreino, yteste = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)","4ea3578f":"# vectorizing data train\ntxtvetorizado = TfidfVectorizer()\nvetorXtreino = txtvetorizado.fit_transform(Xtreino)","93bb35fd":"# training data\n#\nmodelo = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\nmodelo.fit(vetorXtreino, ytreino)","d69a0a54":"# vectorizing data test\nvetorXteste = txtvetorizado.transform(Xteste)","fb4c6105":"# predicting\nprevisao = modelo.predict(vetorXteste)","a6293adb":"# showing metrics\nmetrics.classification_report(yteste.values, previsao, target_names=tipos)","1f08647d":"# analysing predicts data with confusion matrix\nconfusion_matrix = confusion_matrix(yteste.values, previsao)\npd.crosstab(yteste.values, previsao, rownames=['Real'], colnames=['Previsto'], margins=True)","04ffb396":"texto = []\n# reading rss\nrssHighLights = {'ESPN': 'https:\/\/www.espn.com\/espn\/rss\/news'}\ndfespn = pd.DataFrame(columns=['mininews'])\nfor i in rssHighLights.items():\n    for j in feedparser.parse(i[1]).entries:\n        texto.append(j['title'] + '. ' + j['summary'])\n\n# saving rss news in dataframe\ndfespn['mininews'] = texto","fe2def9f":"# showing 5 examples\ndfespn.sample(5)","cb03a4bf":"# vectorize the news read.\nnovoVetor = txtvetorizado.transform(dfespn['mininews'])","b47c469e":"# predicting the news\nprevisoes = modelo.predict(novoVetor)","b9666ebe":"for noticia, tipoNoticia in zip(dfespn['mininews'], previsoes):\n    print(f'{noticia}: ')\n    print(f'PREDICT==> {tipos[tipoNoticia].upper()}')\n    time.sleep(1)","4aa48c5e":"import textblob\nfrom textblob import TextBlob\n\ndef getSentiment(txt=''):\n    txt = TextBlob(txt)\n    return txt.sentiment.polarity","ad8e1cba":"cont = []\nfor i in tipos:\n    cont.append(len(df[df['tipo'] == i]))\n\nfig1, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8))\n\nax1.pie(cont, labels=tipos, autopct='%1.1f%%')\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax1.set_title('FACT: Categorias nos feeds (%)')\n\np = n = t = 0\n\nfor i in range(0, len(df)):\n    polarity = getSentiment(df.iloc[i]['miniNews'])\n    if polarity != 0:\n        t += 1\n        if polarity > 0:\n            p += 1\n        else:\n            n += 1\n\nax2.pie([p, n], labels=['positive', 'negative'], autopct='%1.1f%%')\nax2.axis('equal')  \nax2.set_title('FACT: Humor (%)')\n\ncont = []\ndfespn['tipo'] = previsoes\nfor c, v in enumerate(tipos):\n    cont.append(len(dfespn[dfespn['tipo'] == c]))\nax3.pie(cont, labels=tipos, autopct='%1.1f%%')\nax3.axis('equal')  \nax3.set_title('PREDICT: LAST NEWS CATEGORIES ')\n\np = n = t = 0\n\nfor i in range(0, len(dfespn)):\n    polarity = getSentiment(dfespn.iloc[i]['mininews'])\n    if polarity != 0:\n        t += 1\n        if polarity > 0:\n            p += 1\n        else:\n            n += 1\n\nax4.pie([p, n], labels=['positive', 'negative'], autopct='%1.1f%%')\nax4.axis('equal')  \nax4.set_title('PREDICT: LAST NEWS HUMOR RATE (%)')","1b4110f4":"# Conclusion\n\nThis is a simple example for you to test your knowledge with text and feelings classifiers.\n\nMy suggestions:\n- always test other classifiers (sklearn)\n- increase your dataset and evaluate forecasts.\n- if you use news from your country, a facilitator is to use the googletrans library to translate your text, but always assess whether the translation is to your satisfaction.\n- make your text all lowercase\n- remove special signs\n- remove blank spaces\n- use stemming and lemmatization techniques to reduce processing\n- removing the stopwords will also help with processing.\n\nGood fun in your ratings.\nStrong hug.","0fbb5d21":"As a source of information, we will use espn's RSS feed. The goal is to train and test on specific feeds and make the forecast in the highlights news feed.\n\nComo fonte de informa\u00e7\u00e3o, utilizaremos o feed RSS da espn. O objetivo \u00e9 treinar e testar em cima de feeds espec\u00edficos e efetuar a previs\u00e3o no feed de not\u00edcias em destaque.\n\n","fa7dc89e":"# NEWS CLASSIFICATION\n\n**Machine Learning python code predicting sports news category and classifying the feeling (polarity) of the text.**\n\n**Script python ML para prever categoria da not\u00edcia esportiva e classificando o sentimento (polaridade) do texto.**\n\nThe purpose of this example is to use the SGDClassifier (ML Text Classifier) to predict which category of news is based on its text.\n\nO objetivo deste exemplo \u00e9 utilizar o SGDClassifier (ML Classificador de texto) para prever qual a categoria de uma not\u00edcia, baseada em seu texto.","8b51d213":"Creating variable in the dataframe, making reference to the type of news, not with the categorical name but with a numerical value.\n\nCriando a variavel no dataframe, fazendo referencia ao tipo da noticia, nao com o nome categorico mas com um valor numerico.","2ffbc9f2":"Now, see the dashboard with statistical data on the composition of the news and its mood rate.\n\nTo check the sentimental polarity level of the news, I used the TextBlob\n\nAgora, veja o dashboard com dados estatisticos da composicao das noticias e sua taxa de humor.\n\nPara verificar qual o nivel de polaridade sentimental da noticia, utilizei a biblioteca TextBlob","cbe4ebf1":"Now, we will predict the categories of new news, reading the news from a new feed.\n\nAgora sim, iremos prever as categorias de novas noticias, lendo as noticias de um novo feed.","69f1f228":"# CONCLUS\u00c3O\n\nEste \u00e9 um simples exemplo para voc\u00ea testar seu conhecimento com classificadores de texto e sentimentos.\n\nMinhas sugest\u00f5es: \n- sempre testar outros classificadores (sklearn)\n-  aumente o seu dataset e avalie as previs\u00f5es.\n- caso utilize not\u00edcias de seu pa\u00eds, um facilitador \u00e9 utilizar a biblioteca googletrans para traduzir o seu texto, mas sempre avalie se a tradu\u00e7\u00e3o est\u00e1 a seu contento. \n- deixe seu texto todo em min\u00fasculo\n- retirar sinais especiais\n- retirar espa\u00e7os em brancos\n- use as t\u00e9cnicas de stemming e lemmatization para reduzir no processamento\n- remover as stopwords tamb\u00e9m ajudar\u00e1 no processamento.\n\nBoa divers\u00e3o em suas classifica\u00e7\u00f5es. \nForte abra\u00e7o."}}