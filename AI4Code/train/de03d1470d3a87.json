{"cell_type":{"cca1561a":"code","44517d61":"code","6590ea56":"code","4e0d2711":"code","b0dc412b":"code","6f4b3957":"code","33314c13":"code","4094719c":"code","c3ad9929":"code","a2b03bca":"code","5dddf3fa":"code","a6132df0":"code","1a9c8a7c":"code","5d700c20":"code","feeb26c4":"code","21c896e0":"code","fa22b0b9":"code","d7b9f26e":"code","8e5ac570":"code","d2bf57b6":"code","ee5849f0":"code","75c98b13":"code","4b77506e":"code","a4ef6083":"code","472c7efe":"code","1b81a891":"code","6b44ee8c":"code","6e263e10":"code","2036b500":"code","951f898d":"markdown","f99f328f":"markdown","12b05bf7":"markdown","1fb33baa":"markdown","557e21e1":"markdown","5301b034":"markdown","2b0a9dae":"markdown","e2d421cb":"markdown","77e4fe14":"markdown","9a219676":"markdown","773f6912":"markdown","6aae48ce":"markdown","70cd3f33":"markdown","5d1f5317":"markdown","d6aff80f":"markdown","ecc93046":"markdown","f19f13f0":"markdown","3bed7ab2":"markdown","d09d268a":"markdown","2d0fd1e9":"markdown","c00d6b53":"markdown","0702686d":"markdown","b1d96e90":"markdown","4c9ceb3d":"markdown","6aa6fa71":"markdown","fa751e69":"markdown","417ca3f2":"markdown","7b3731c9":"markdown","80955489":"markdown","cf13ca9d":"markdown","06f61881":"markdown","311090cb":"markdown","8a5049be":"markdown","f8cfc507":"markdown","ea1ff2a2":"markdown","ef5e3283":"markdown","4c66bfdc":"markdown","9b44e857":"markdown","3bdfb2d8":"markdown","1b172874":"markdown","7b1122c6":"markdown","9ed341a2":"markdown"},"source":{"cca1561a":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nimport matplotlib.pylab as plt\nimport pandas as pd","44517d61":"data_dir = \"..\/input\/flowers-recognition\/flowers\"","6590ea56":"pixels =224\nBATCH_SIZE = 32\nIMAGE_SIZE = (pixels, pixels)\nNUM_CLASSES = 5","4e0d2711":"datagen_kwargs = dict(rescale = 1.\/255, validation_split = .20)\ndataflow_kwargs = dict(target_size = IMAGE_SIZE, batch_size = BATCH_SIZE, interpolation = \"bilinear\")","b0dc412b":"# Generating batches of tensor image-data and creating validation dataset.\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\nvalid_generator = valid_datagen.flow_from_directory( data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)","6f4b3957":"train_datagen = valid_datagen\ntrain_generator = train_datagen.flow_from_directory( data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)","33314c13":"labels_idx = (train_generator.class_indices)\nidx_labels = dict((v,k) for k,v in labels_idx.items())\n#Let's take a look how to map classes.\nidx_labels","4094719c":"model = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n    hub.KerasLayer(\"https:\/\/tfhub.dev\/google\/imagenet\/resnet_v1_101\/feature_vector\/4\", trainable=False),\n    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name = 'flower_class') \n])\n\nmodel.build([None, 224, 224, 3])","c3ad9929":"model.compile(\n    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n    metrics=['accuracy'])","a2b03bca":"model.summary()","5dddf3fa":"steps_per_epoch = train_generator.samples \/\/ train_generator.batch_size\nvalidation_steps = valid_generator.samples \/\/ valid_generator.batch_size","a6132df0":"model.fit(\n    train_generator,\n    epochs=5, \n    steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)","1a9c8a7c":"sample_test_images, ground_truth_labels = next(valid_generator)\nprediction = model.predict(valid_generator)","5d700c20":"len(prediction)","feeb26c4":"predicted_idx = tf.math.argmax(prediction, axis = -1)","21c896e0":"print (predicted_idx)","fa22b0b9":"y_actual = pd.Series(valid_generator.classes)\ny_predicted = pd.Series(predicted_idx)","d7b9f26e":"pd.crosstab(y_actual, y_predicted, rownames = ['Actual'], colnames=['Predicted'], margins=True)","8e5ac570":"predicted_results = y_predicted\ntruth = y_actual","d2bf57b6":"from sklearn.metrics import classification_report\nreport = classification_report(truth, predicted_results)\nprint(report)","ee5849f0":"base_model = tf.keras.applications.ResNet101V2(\n    input_shape = (224, 224, 3), \n    include_top = False, \n    weights = 'imagenet')","75c98b13":"model2 = tf.keras.Sequential([\n  base_model,\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax', name = 'flower_class')\n])","4b77506e":"model2.compile(\n  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n  loss=tf.keras.losses.CategoricalCrossentropy(\n  from_logits=True, label_smoothing=0.1),\n  metrics=['accuracy']\n)\nmodel2.fit(\n    train_generator,\n    epochs=5, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)","a4ef6083":"print(\"Number of layers in the base model: \", len(base_model.layers))\nbase_model.trainable = True","472c7efe":"# Freezing all the layers before the 'fine_tune_at' layer\nfine_tune_at = 300\nfor layer in base_model.layers[: fine_tune_at]:\n    layer.trainable = False","1b81a891":"model3 = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax', name = 'flower_class')\n])","6b44ee8c":"model3.compile(\n    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n    loss=tf.keras.losses.CategoricalCrossentropy(\n        from_logits=True, label_smoothing=0.1),\n    metrics=['accuracy']\n)","6e263e10":"model3.summary()","2036b500":"fine_tune_epochs = 2\nsteps_per_epoch = train_generator.samples \/\/ train_generator.batch_size\nvalidation_steps = valid_generator.samples \/\/ valid_generator.batch_size\nmodel3.fit(\n    train_generator,\n    epochs=fine_tune_epochs, \n    steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)","951f898d":"<h2><span style=\"color:Purple\">Building the Model<\/span> <\/h2>","f99f328f":"Let's traing the model. First, let me determine the number of batches for training and cross-validation data.","12b05bf7":"If you want you can directly load the dataset using get_file() method. `data_dir = tf.keras.utils.get_file('flower_photos','https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz', untar=True`. By default, you can see this dataset in .keras file such as `\/root\/.keras\/datasets\/flower_photos` on your machine. Now that I am going to create a variable for directory of dataset. ","1fb33baa":"To evaluate the model, metrics are used. I am going to use sklearn library to see metrics. ","557e21e1":"<h2><span style=\"color:Purple\">Predicting the Data<\/span> <\/h2>","5301b034":"![](https:\/\/images.unsplash.com\/photo-1496483648148-47c686dc86a8?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1052&q=80)","2b0a9dae":"Let's take a look summary of model.","e2d421cb":"I am going to use ResNet model to analyze image classification. To use this model, you need to preprocess. Let me standardize image size to [223, 223, 3], and normalize pixel value tu a [0,1] range. First,let's create variable for hyperparameters.","77e4fe14":"This results say that the model has good performance for classification problem. \n\n<h2><span style=\"color:Purple\">Using the tf.keras.applications Module<\/span> <\/h2>\n\nKeras is an API, which is a high level library. This module became a part of  the TensorFlow ecosystem in 2019. You can use Keras to fine tune your models. tf.keras.applications lets you determine which layers to retrain and which layers to untouched. Let's create a new base model using tf.keras.applications. ","9a219676":"Let me display the result using print command.","773f6912":"<h2><span style=\"color:Purple\">Compiling the Model<\/span> <\/h2>","6aae48ce":"<h2><span style=\"color:Purple\">Resources<\/span> <\/h2>","70cd3f33":"Datasets are ready to build the model. I am going to train using pretrain model. ","5d1f5317":"My model has 0.996 accuracy value. This is a good value. That is all. In this tutorial, I showed how to use the pretrained model. To do pretrained model, there are two convenient ways: TensorFlow Hub and the tf.keras.applications module. You can easily train the your model according to your analysis using the pretrained models.","d6aff80f":"Let me train the model.","ecc93046":"Now, do the same for the training data generator. ","f19f13f0":"After the model is built I am going to compile the model. To do this, let me specify the loss funciton and pick an optimizer.","3bed7ab2":"<h2><span style=\"color:Purple\">Fine-Tuning Model<\/span> <\/h2>\nYou can fine tune your model using tf.keras.applications. Let's take a look number of layer in base model. ","d09d268a":"As you can see, there are 377 layers. I am going to take 370 layers as the starting layer for fine tuning. I want these layers not to be trained.","2d0fd1e9":"Each row represents predicted value and each column display actual values. \nNow that let's take a look statistical report using sklearn library.","c00d6b53":"I am going to define class name. To do this, let me map flower class names.","0702686d":"Now that I am going to build the model again. ","b1d96e90":"<h2><span style=\"color:Purple\">Training the Model<\/span> <\/h2>","4c9ceb3d":"Now that I am going to fit model.","6aa6fa71":"You can use predict() method to score these validation images. Let's see predictions for first batch.","fa751e69":"<h2><span style=\"color:Purple\">Preprocessing the Dataset<\/span> <\/h2>","417ca3f2":"To evaluate the model, I am going to use confusion matrix, which compare model output with ground truth. To do this let me convert classes into Pandas Series structure and create variable, which include predictions.","7b3731c9":"<h2><span style=\"color:Purple\">Introduction<\/span> <\/h2>\n\nClassical methods showed poor performance for image and text classification problems. The models which based on deep learning used to solve these problems. There are very much popular models which tested and open source that they are avaible for transfer learning.\nThe models such as ResNet are prebuilted and very complicated structures. TensorFlow Hub proposed a variety of ML models. You can use these model writting a single line of code.\nIn this tutorial, I am going to show how to use models pretrained in TensorFlow Hub. If you want to install Tensorflow Hub, you can use `pip install --upgrade tensorflow_hub` command. After installing, first of all, to use I am going to import this library `import tensorflow_hub as hub` command.\n\n<h2><span style=\"color:Purple\">Using the model in TensorFlow Hub<\/span> <\/h2>\n\nFor example, you can use a pretrained text embedding model in tensorFlow Hub such as `model = hub.KerasLayer(\"https:\/\/tfhub.dev\/google\/nnlm-en-dim128\/2\")`\nToken in this model based text embedding trained on English Google News 200B corpus. Text embedding is a multidimensional vector of numeric representation. Note that you can onlu load and use it to get a result with your own data. \n\nYou can choose the model in [TensorFlow Hub](https:\/\/tfhub.dev\/) according to your the dataset. There are very much model for image, text, video, and audio datasets.\n\n<h2><span style=\"color:Purple\">Image Classification by Transfer Learning<\/span> <\/h2>\n\nIn this section, I am going to talk about how to analyze with transfer learning for classification problem. To show this, let me use flower photos dataset which provided by google. \nFirst of all, let's import libraries.","80955489":"<h2><span style=\"color:Purple\">Loading the Dataset<\/span> <\/h2>","cf13ca9d":"First, I specified input shape and then I set include_top to False so I can add my own Dense layer for the classification output. \nNow that I am going to build Sequential model based on base model and add GlobalAveragePooling2D layer. ","06f61881":"I am going to split dataset into train and validation.  While validation dataset uses for cross validation, the other dataset uses for training model. ","311090cb":"Don't forget to follow on Tirendaz Academy [YouTube-Tr](https:\/\/youtube.com\/c\/tirendazakademi), [YouTube-Eng](https:\/\/www.youtube.com\/channel\/UCFU9Go20p01kC64w-tmFORw), [Twitter](https:\/\/twitter.com\/TirendazAcademy), [Medium](https:\/\/tirendazacademy.medium.com), [GitHub](https:\/\/github.com\/TirendazAcademy) and [LinkedIn](https:\/\/www.linkedin.com\/in\/tirendaz-academy)","8a5049be":"Now that let me compile and fit the model.","f8cfc507":"To see metrics my model, I going to create variables.","ea1ff2a2":"Now that I am going to define some hyperparameters such as pixel values and batch size.","ef5e3283":"<h1><span style=\"color:purple\">Transfer Learning with TensorFlow<\/span> <\/h1>","4c66bfdc":"- [KC Tung, 2021, TensorFlow 2 Pocket Reference](https:\/\/www.amazon.com\/TensorFlow-Pocket-Reference-Building-Deploying\/dp\/1492089184)\n- [TensorFlow Tutorial](https:\/\/www.tensorflow.org\/tutorials)","9b44e857":"Then I am going to produce the matrix.","3bdfb2d8":"<h2><span style=\"color:Purple\">Evaluating the Model<\/span> <\/h2>","1b172874":"Let me compile the model.","7b1122c6":"Let's take a look summary of the model3.","9ed341a2":"731 images and 5 corresponding classes in the cross-validation data print out on the screen. The highest probability in each row represents the prediction. I am going to find position where the highest probability occurs for each row."}}