{"cell_type":{"e28c1550":"code","3b741add":"code","5108d14a":"code","4bd84e24":"code","5f85ca81":"code","ddc85114":"code","7ac2a75f":"code","8ade4013":"code","bbe92fe5":"code","467adfbf":"code","fd98abec":"code","6b5e6b80":"code","4a415652":"code","d0d5f1f6":"code","6012dc0b":"markdown"},"source":{"e28c1550":"#Load the require libraries for processing\n\nimport tensorflow as tf\nimport numpy as np \n\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\n\n\n#Required libraries for keras model\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD, Adam\nimport matplotlib.pyplot as plt\nfrom keras import Input\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator","3b741add":"#Load the files \n\ntrain = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntarget = train['label']\ntrain  = train.drop(['label'], axis=1)\n","5108d14a":"#Convert the train and test to arrays and reshape and normalize\nfull = pd.concat([train, test])\nfull=full.to_numpy()\nfull=full.reshape(-1, 28, 28 )\n#Get the dimensions\nfull.shape","4bd84e24":"#Plot an image\nim=full[0]\nimport matplotlib.pyplot as plt\nplt.imshow(im, cmap=\"gray\")","5f85ca81":"#resize the numpy arrays for VGG16 - the CV alg requires a 32 x 32 array rather that 28 x 28.\nfull = np.pad(full, ((0,0), (2,2), (2,2)), mode='constant')\nfull = stacked_img = np.stack([full, full, full], axis=3)\nfull.shape","ddc85114":"#Get back the train and test set\nfull=full.astype(\"float32\")\nfull = full\/255\ntrain=full[:42000, :, :, :]\ntest=full[42000:, :, :, :]","7ac2a75f":" \n#Create a train and validation set\nX_train, X_val, Y_train, Y_val = train_test_split(train, target, test_size = 0.2, random_state = 1 )","8ade4013":"#Retain the validation answers for measuring performance later\nY_val_access = Y_val","bbe92fe5":"#Convert the target to a dummy variable \nY_val=to_categorical(Y_val, num_classes=10)\nY_train=to_categorical(Y_train, num_classes=10)","467adfbf":"### Model\n\ndef create_model():\n    VGG = VGG16(\n    input_shape=(32, 32, 3),\n    weights='imagenet',\n    include_top=False,\n    )        \n    \n    model =tf.keras.Sequential([VGG,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dense(10, activation='softmax')\n    ])\n    \n    return model","fd98abec":"#Create an image generator class for augmentation to improve generalisation\nim = ImageDataGenerator(zoom_range=0.1, rotation_range=15, height_shift_range= 0.05, width_shift_range= 0.05)\nflow=im.flow(X_train, Y_train, batch_size=32)","6b5e6b80":"#Build model with standard Adam as optimizer \nmymod=create_model()\nmymod.summary()\nmymod.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","4a415652":"#Fit the model. Each time we do 20 epochs and retain the prediction probabilities for validation and test set - we will average the predictions later.\n\n\npredictions_val = np.zeros(shape=(5, X_val.shape[0], 10))\npredictions_test = np.zeros(shape=(5,  test.shape[0], 10))\n\n#Run 5 times\n\nfor i in range(5):\n    print('training model ', i+1, '...')\n    perf = mymod.fit_generator(flow, epochs=10, steps_per_epoch= X_train.shape[0]\/32, validation_data=(X_val, Y_val), verbose=0)\n    pred_val = mymod.predict(X_val)\n    pred_test = mymod.predict(test)\n    predictions_val[i, :, :] = pred_val\n    predictions_test[i, :, :] = pred_test\n    \n\n#Average to ensemble the predictions\npvall = np.zeros(shape=( X_val.shape[0], 10))\nptall = np.zeros(shape=( test.shape[0], 10))\n\nfor i in range(10):\n    pv1 = np.mean(predictions_val[:, :, i], axis=0)\n    pt1 = np.mean(predictions_test[:, :, i], axis=0)\n    pvall[:, i] = pv1\n    ptall[:, i] = pt1\n\n#Get hold out accuracy\npreds_val= np.argmax(pvall,axis = 1)\npreds_test = np.argmax(ptall, axis=1)\nval_acc = np.mean(preds_val == Y_val_access)\nprint('Overall validation accuracy is', val_acc)\n    ","d0d5f1f6":"#Predict the test\npreds= pd.Series(preds_test,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),preds],axis = 1)\nsubmission.to_csv(\"MINST.csv\",index=False)","6012dc0b":"This notebook utilises the VGG vision model to classify the MNIST data set. Using this model I obtainned 99.65% accuracy. I found that the straight model was around 99.2% accurate, augmentation lifted it to 99.3% and averaging models did the rest. It runs slowly on the CPU due to vast number of trainable parameters in the nn architecture of VGG16 so it utilizes the GPU on Kaggle as an accelerator. It should take around 20 minutes to run.\n\nI found the following notebooks extremely helpful for creating this:\n\nhttps:\/\/www.kaggle.com\/ateplyuk\/mnist-efficientnet\n\nhttps:\/\/www.kaggle.com\/cdeotte\/25-million-images-0-99757-mnist\n"}}