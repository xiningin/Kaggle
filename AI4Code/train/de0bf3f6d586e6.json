{"cell_type":{"6bd486c4":"code","2cdb6b1b":"code","5a6ba27d":"code","83b4c0c5":"code","db815a3f":"code","787a987f":"code","2ac7cfb0":"code","56ddc78a":"code","fdffa161":"code","08b4162a":"code","ee62cadd":"code","1ba60bfa":"code","41ef5af3":"code","23d61ad4":"code","3fecbabe":"code","14341d1f":"code","545471cb":"code","96e7f147":"code","590fab82":"code","a83583e9":"code","cded4438":"code","44c39771":"code","49e0f2b8":"code","1ad5634b":"code","e554a8cc":"code","3a75a41b":"code","b2a55012":"code","faf0b725":"code","2bb364c9":"code","3809154f":"code","94b37e84":"code","99812749":"code","e6793f5e":"code","6a48bd3c":"code","8fc91cbc":"code","fcf536c9":"code","c81ee6d8":"code","95a4a38e":"code","b21fab7d":"code","10bcdaee":"code","365dfc56":"code","1171fa7e":"code","90c150e6":"code","68d3e3db":"code","e3f1fe10":"code","a9c6ee01":"code","2266a77a":"code","7e10ae60":"code","884fd4e6":"code","5cc2d1bd":"code","746e42de":"code","86ff45ee":"code","3f816a2d":"code","2fbadab1":"code","6e08970f":"code","5f72f827":"code","2b5951a9":"code","6b6627aa":"code","a16d812e":"code","f525af1b":"markdown","a3c9ff44":"markdown","3b4409e4":"markdown","33e979c4":"markdown","140d2b9f":"markdown","1912abcf":"markdown","103e86e4":"markdown","cc75a9d3":"markdown","bc5a07e9":"markdown","ef094a5b":"markdown","8eaae1a7":"markdown","036fd13d":"markdown","30343e87":"markdown","45ea47e1":"markdown","7ddb6176":"markdown","7d006f65":"markdown","39dbd7c0":"markdown","0fc9da3a":"markdown","0eab0ed9":"markdown","77002faf":"markdown","62996e30":"markdown","0eee18db":"markdown","2f1ba1f9":"markdown","0ee35100":"markdown","473901df":"markdown","20d93794":"markdown","b4c42ada":"markdown","58fbd57a":"markdown","e3f278b5":"markdown","388f0130":"markdown","1aecb64f":"markdown","17b97e73":"markdown","d461a776":"markdown","c19d0c60":"markdown","98206177":"markdown","a004203e":"markdown","020cb66d":"markdown","a4bd84b5":"markdown","8ff6b7c2":"markdown","af4aa6e8":"markdown","46e2716b":"markdown","c697d7f3":"markdown","77753aca":"markdown","a7e6c668":"markdown","bab5caca":"markdown","805a4537":"markdown","d355d7c3":"markdown","e48c2b75":"markdown","0cf06ce0":"markdown","0a85da08":"markdown","05635864":"markdown","13ca1d93":"markdown","28f50e4a":"markdown","11520199":"markdown","77fcff46":"markdown","e8819d0b":"markdown","fbf064a2":"markdown","dff568c5":"markdown","6474f6a5":"markdown","14df13bb":"markdown","c13ba143":"markdown"},"source":{"6bd486c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2cdb6b1b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Activation, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam,RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.metrics import confusion_matrix","5a6ba27d":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","83b4c0c5":"train.shape","db815a3f":"train.head()","787a987f":"X = train.drop('label', axis=1)\ny = train['label']","2ac7cfb0":"test.shape","56ddc78a":"train['label'].value_counts()","fdffa161":"sns.countplot(train['label'])","08b4162a":"X.shape","ee62cadd":"first_row = X.iloc[0]","1ba60bfa":"first_mat = first_row.values.reshape(28,28)","41ef5af3":"plt.imshow(first_mat);","23d61ad4":"plt.figure(figsize=(15,10))\nfor i in range(10):\n    plt.subplot(2,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X.iloc[i].values.reshape(28,28))\n    plt.xlabel(y[i])","3fecbabe":"input_shape = (28, 28, 1)","14341d1f":"unique_labels = y.unique()","545471cb":"print(sorted(unique_labels))\nnum_labels = len(unique_labels)\nnum_labels","96e7f147":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","590fab82":"y_train.shape","a83583e9":"X_train.shape","cded4438":"X_train = X_train.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)","44c39771":"X_train.shape","49e0f2b8":"X_train = X_train \/ 255.\nX_test = X_test \/ 255.","1ad5634b":"###  Model Definition\nmodel = Sequential()\n\n# add 32 convolution filters used each of size 5x5 with relu activation\nmodel.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Valid', activation='relu', input_shape=(28, 28, 1)))\n\n\n# add another 32 convolution filters used each of size 3x3 with relu activation\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', activation='relu'))\n\n# adding pooling layer with a MaxPool2D filter of size 2x2 summarize the presence of features\n# in patches of the feature map.\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n\n# turn on and off neurons randomly for reducing interdependent learning amongst the neurons.\nmodel.add(Dropout(0.2))\n\n# add 64 convolution filters used each of size 5x5 with relu activation\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), padding='Valid', activation='relu'))\n\n# add 64 convolution filters used each of size 3x3 with relu activation\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n\n# adding pooling layer with a MaxPool2D filter of size 2x2 summarize the presence of features\n# in patches of the feature map.\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\n# turn on and off neurons randomly for reducing interdependent learning amongst the neurons.\nmodel.add(Dropout(0.2))\n\n# # Flattens the data.\nmodel.add(Flatten())\n\n# add densely-connected NN layer, to fully connected to drives the final classification decision.\nmodel.add(Dense(519, activation=\"relu\"))\n\n# turn on and off neurons randomly for reducing interdependent learning amongst the neurons.\nmodel.add(Dropout(0.5))\n\n# output a softmax to let the output to be interpreted as probabilities\nmodel.add(Dense(10, activation=\"softmax\"))\n","e554a8cc":"model.summary()","3a75a41b":"# model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])","b2a55012":"model.compile(loss='categorical_crossentropy',\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])","faf0b725":"y_train = to_categorical(y_train, num_classes = num_labels)\ny_test = to_categorical(y_test, num_classes = num_labels)","2bb364c9":"reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=2, factor=0.5, min_lr=0.0000001)","3809154f":"img_data_gen = ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=10,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=False,\n    vertical_flip=False)","94b37e84":"# epochs     - One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE\nnum_epochs = 3 # replace it to 30\n# batch size -Total number of training examples present in a single batch.\nbatch_size = 64\n\ntrain_generator = img_data_gen.flow(X_train, y_train, batch_size=batch_size)\ntest_generator = img_data_gen.flow(X_test, y_test, batch_size=batch_size)","99812749":"X,y = next(train_generator)\nX.shape,y.shape","e6793f5e":"# Save the model to disk\nmodel.save('MNIST-1.h5')","6a48bd3c":"#start training\n\nhistory = model.fit_generator(train_generator,\n                    epochs=num_epochs,\n                    validation_data=test_generator,\n                    callbacks=[reduce_lr])","8fc91cbc":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1]) ","fcf536c9":"y_true =  [np.argmax(i) for i in y_test]\npredictions = model.predict(X_test)\ny_pred = [np.argmax(i) for i in predictions]\nplt.figure(figsize=(15,8))\nsns.heatmap(confusion_matrix(y_true, y_pred), cmap=\"coolwarm\", annot=True , fmt=\"d\");","c81ee6d8":"history.history['accuracy']","95a4a38e":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')","b21fab7d":"predictions[0]","10bcdaee":"np.argmax(predictions[0])","365dfc56":"np.argmax(y_test[0])","1171fa7e":"def plot_image(i, predictions_array, true_label, img):\n    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.imshow(img, cmap=plt.cm.binary)\n\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        color = 'blue'\n    else:\n        color = 'red'\n\n    plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n                                100*np.max(predictions_array),\n                                true_label),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n    predictions_array, true_label = predictions_array, true_label[i]\n    plt.grid(False)\n    plt.xticks(range(10))\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1])\n    predicted_label = np.argmax(predictions_array)\n\n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('blue')","90c150e6":"num_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, predictions[i], np.argmax(np.array(y_test), axis=1), X_test.reshape(-1,28,28))\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions[i], np.argmax(np.array(y_test), axis=1))\nplt.tight_layout()\nplt.show()","68d3e3db":"errors = pd.DataFrame(np.argmax(y_test, axis=1), columns=['label'])","e3f1fe10":"errors.reset_index(inplace=True)","a9c6ee01":"errors","2266a77a":"errors['predictions'] = y_pred","7e10ae60":"errors.loc[errors['label'] - errors['predictions'] != 0, 'error'] = 1","884fd4e6":"errors[errors['error']==1]","5cc2d1bd":"num_errors = len(errors[errors['error']==1].index)","746e42de":"print(\"number of errors is: {}\".format(num_errors))","86ff45ee":"err_index = errors[errors['error']==1].index","3f816a2d":"plt.figure(figsize=(15,10))\nfor i in range(10):\n    err_index = errors[errors['error']==1].index[i]\n    plt.subplot(2,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_test[err_index].reshape(28,28))\n    plt.xlabel(\"true is {}, predicted as {}\".format(np.argmax(y_test[err_index]), y_pred[err_index]))","2fbadab1":"test = test \/ 255\ntest = test.values.reshape(-1, 28, 28, 1)","6e08970f":"final_predictions = model.predict(test)","5f72f827":"final_predictions","2b5951a9":"final_predictions = list(map(lambda x : np.argmax(np.round(x)), final_predictions))","6b6627aa":"final_predictions[:10]","a16d812e":"predicted_labels = pd.Series(final_predictions, name=\"Label\")\nimage_id = pd.Series(range(1, len(predicted_labels)+1),name=\"ImageId\")\n\nresults = pd.concat([image_id,predicted_labels],axis=1)\n\nresults.to_csv(\"MNIST.csv\",index=False)","f525af1b":"reshape it to 28x28","a3c9ff44":"#### 7.4 Reshaping and Scaling data","3b4409e4":"<img src=\"https:\/\/miro.medium.com\/max\/2510\/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" height=\"100\">","33e979c4":"Let us take a look to the first row","140d2b9f":"#### 7.8 Image proccessing","1912abcf":"#### 1.2.1 CNN Layers","103e86e4":"1.2.1.1 Convolutional Layers\n\nthe major block in CNN is Convolutional layers, which apply filtering to the input that results an activation, repeating applying the filter (kernel) on the input will create a feature map that summarizes the presence of detected features in the input.","cc75a9d3":"let see how many unique labels we have","bc5a07e9":"1.2.1.3 Fully Connected Layer\n\nAfter the two previous steps in CNN process ends, breaking down the image into features, and analyzing them independently. The result of this process will be flatted and feeds into a fully connected neural network structure that drives the final classification decision.","ef094a5b":"Let us see the first 10 prediction images","8eaae1a7":"#### 1.3 MNIST","036fd13d":"Let us take a loot to the first prediction","30343e87":"now we can plot that image","45ea47e1":"### 3. Import Libraries","7ddb6176":"# Digit-Recognition by Convolutional Neural Networks (CNN)","7d006f65":"Reduce learning rate when a metric has stopped improving.\nModels often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.","39dbd7c0":"here is a simple example of a standard 2D CNN","0fc9da3a":"### 2. Problem","0eab0ed9":"because we are using the ```categorical_crossentropy``` loss method, we need to convert ```y_train```, ```y_test``` using one hot encoder.","77002faf":"#### 1.1 Artificial neural networks","62996e30":"The goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.","0eee18db":"### 8. Model Evaluation","2f1ba1f9":"#### 7.5 Build Neural Network Model","0ee35100":"Before training the model, we need to compile :\n* Loss function \u2014 This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n* Optimizer \u2014This is how the model is updated based on the data it sees and its loss function.\n* Metrics \u2014Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified","473901df":"let display the model errors","20d93794":"<img src=\"https:\/\/summations.github.io\/assets\/img\/posts\/channelplot\/image-matrix.png\" width=\"600\">","b4c42ada":"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the results to identify cats in other images. They do this without any prior knowledge of cats, for example, that they have fur, tails, whiskers and cat-like faces. Instead, they automatically generate identifying characteristics from the examples that they process.","58fbd57a":"<img src=\"https:\/\/corochann.com\/wp-content\/uploads\/2017\/02\/mnist_plot.png\" width=\"300\">","e3f278b5":"let us plot the first 10 images","388f0130":"Because we want to reduce over-fitting, i will use a Data Augmentation technique. \nData augmentation applies a transformation to an image according to given parameters. For example it rotates, shears, zooms etc. the image such that the model learns to generalize and not remember specific data. If the model overfits, it will perform very well on the images that it already knows but will fail if new images are given to it.","1aecb64f":"for our case, we will feed the CNN model with graysacle images, graysacle image is one in which the value of each pixel is a single sample representing only an amount of light.\nwhich will be stored as (rows, columns, 1) in our case it will be (28, 28, 1)","17b97e73":"Let us count the labels.","d461a776":"#### 1.4 Images\nRGB images is stored as 3D numpy array (rows, columns, channels), rows is images height of the image and columns is the width of the image.\nChannels consists of Red, Green and Blue components of each individual pixel. for example a (0,0,0) pixel is displayed as black, and a pixel whose color components are (255,255,255) is displayed as white.","c19d0c60":"<img src=\"https:\/\/datascience-enthusiast.com\/figures\/max_pool1.png\" width=\"500\">","98206177":"#### 1.2 Convolutional neural network CNN)","a004203e":"### 7. Neural network model","020cb66d":"# accuracy vs. validation accuracy","a4bd84b5":"We can see that the prediction is an array of 10 elements, each element representing the model \"confidence\" value for the corresponding class.\nand to get the correct prediction we need to get the Max \"confidence\" value for each input","8ff6b7c2":"as you can see we have label wich define the actual digit and 784pixels - pixels[0-783].\ni will seperate train data to (X, y) - y will be label only, and X will be the whole data without the label.","af4aa6e8":"input dimension is (w,n,3) - (wxn) image with 3 channels (R,G,B)","46e2716b":"[MNIST](https:\/\/www.kaggle.com\/c\/digit-recognizer) (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.","c697d7f3":"#### 7.1 Define Variables","77753aca":"#### 7.6 Model Compiling and Training","a7e6c668":"### 5. EDA - Exploratory data analysis","bab5caca":"1.2.1.2 Pooling Layer\n\nPooling is required to down sample the detection of features in feature maps by summarizing the presence of features in patches of the feature map. there is many pooling methods one of the common pooling methods is 'max pooling', which summarize the max activated presence of a feature.","805a4537":"Confusion matrix","d355d7c3":"Let's display the architecture of our model.","e48c2b75":"The model says that the first digit is ```3```, let see the acutal class","0cf06ce0":"#### 7.2 Train\/Test Split","0a85da08":"[Artificial neural networks](https:\/\/en.wikipedia.org\/wiki\/Artificial_neural_network) are computing systems that are inspired by, but not identical to, biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with task-specific rules.","05635864":"it looks like the digit ```1```","13ca1d93":"### 6. Preprocessing that data","28f50e4a":"42,000 images to train and learn from.","11520199":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/600\/1*yjy3dwRL-vmSpmUG7UNJYg@2x.png\" width=200>","77fcff46":"Cool the model is right !","e8819d0b":"28,000 images to test","fbf064a2":"<img src=\"https:\/\/www.researchgate.net\/profile\/Baptiste_Wicht\/publication\/322505397\/figure\/fig5\/AS:583063998308353@1516024698839\/A-valid-convolution-of-a-5x5-image-with-a-3x3-kernel-The-kernel-will-be-applied-to.png\" width=\"200\">","dff568c5":"#### 7.7 Reduce Learning Rate (LR)","6474f6a5":"### 4. Gathering data","14df13bb":"<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/4\/46\/Colored_neural_network.svg\/800px-Colored_neural_network.svg.png\" width=\"250\">","c13ba143":"### 1. Background"}}