{"cell_type":{"9ca4711f":"code","114a67c6":"code","129f8cd7":"code","9c41b857":"code","fc6aeef9":"code","d709105e":"code","56146608":"code","b2c406cf":"code","49e4ce1e":"code","88f0b754":"code","c97dcd22":"code","6104229e":"code","691f8d6a":"code","a1b46700":"markdown","69e6b099":"markdown","cf3e2c25":"markdown","4e6e5a12":"markdown","05f00cdf":"markdown","78c57fc1":"markdown","3b6b8f84":"markdown","606e12a6":"markdown","723948d2":"markdown","b03440ab":"markdown","0efcbb11":"markdown","a7e58beb":"markdown"},"source":{"9ca4711f":"!pip install tensorflow keras numpy mnist matplotlib","114a67c6":"import mnist #Dataset\nimport numpy as np\nimport matplotlib.pyplot as plt #Graph\nfrom keras.models import Sequential #ANN\nfrom keras.layers import Dense #Layers in ANN\nfrom keras.utils import to_categorical\n\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report ","129f8cd7":"#load dataset\ntrain_images = mnist.train_images() #training data images\ntrain_labels = mnist.train_labels() #training data labels\ntest_images = mnist.test_images() #testing data images\ntest_labels = mnist.test_labels() #testing data labels","9c41b857":"#normalization of data\n#normalize pixels from the range (0, 255) to (0, 1) to train our network easily.\ntrain_images = train_images \/ 255\ntest_images = test_images \/ 255\n\n#Flatten the image from 28 x 28 to 1-d array of size 784 to pass it to the neural network.\ntrain_images = train_images.reshape((-1, 784))\ntest_images = test_images.reshape((-1, 784))\n\nprint(test_images.shape) #(10000, 784)\nprint(train_images.shape) #(60000, 784)","fc6aeef9":"#Building the model\nmodel = Sequential()\n\n#input layer\nmodel.add(Dense(256, activation = 'tanh', input_dim = 784))\n\n#hidden layer\nmodel.add(Dense(7, activation = 'relu'))\nmodel.add(Dense(10, activation = 'relu'))\nmodel.add(Dense(10, activation = 'relu'))\nmodel.add(Dense(10, activation = 'relu'))\n\n#output layer\nmodel.add(Dense(10, activation = 'softmax'))","d709105e":"#Compiling the model\n#loss function measures how well the neural network worked\n#and then tries to improve it using optimizer.\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","56146608":"#train the model\nmodel.fit(train_images, to_categorical(train_labels), #to_categorical converts 2 into [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] \n      epochs = 25, #iterations\n      batch_size = 64) #number of sample per gradient update during training\n","b2c406cf":"#evaluate the model\nmodel.evaluate(test_images, to_categorical(test_labels))","49e4ce1e":"model.save_weights('model.h5')","88f0b754":"#predict on the first five test images\npredictions = model.predict(test_images[:6])\nprint('Actual labels: ' , test_labels[:6])\nprint('predictions by our model: ' , np.argmax(predictions, axis = 1))","c97dcd22":"#ref https:\/\/www.kaggle.com\/grfiv4\/plot-a-confusion-matrix\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","6104229e":"for i in range(0, 3):\n    img = test_images[i]\n    img = np.array(img, dtype = 'float')\n    pixels = img.reshape((28, 28))\n    plt.imshow(pixels)\n    plt.show()\n\npredictions = model.predict(test_images)\nprint(confusion_matrix(test_labels, np.argmax(predictions, axis = 1)))\n\nplot_confusion_matrix(confusion_matrix(test_labels, np.argmax(predictions, axis = 1)), \n                      normalize    = True,\n                      target_names = ['0', '1', '2',  '3',  '4', '5',  '6', '7',  '8', '9'],\n                      title        = \"Confusion Matrix, Normalized\")","691f8d6a":"import pandas as pd\nsub = pd.DataFrame(np.argmax(predictions, axis = 1))\nsub.index.name = 'ImageId'\nsub.index += 1\nsub.columns = ['Label']\nsub.to_csv(\"submission_ffann.csv\", header = True) ","a1b46700":"# Loading dataset\nIn this step, dataset is loaded and train and test data is seperated from dataset.","69e6b099":"# Sample images and confusion matrix","cf3e2c25":"\n# Normalization of data\nNormalizing pixels from the range (0, 255) to (0, 1) to train our network easily.\n\n# Flattening of images\nFlatten the image from 28 x 28 to 1-d array of size 784 to pass it to the neural network.\n","4e6e5a12":"# Training the model","05f00cdf":"# Plotting confusion matrix\nConfusion matrix shows relationship between actual labels and labels predicted by our model.","78c57fc1":"# Evaluation of model\nEvaluating model on test data","3b6b8f84":"# Neural network architecture\nOur neural network architecture has 256 neurons in input layer, 37 neurons in hidden layer, and 10 neurons in output layer. Neural network architecture is taken from here: http:\/\/www.iraj.in\/journal\/journal_file\/journal_pdf\/1-5-139024255920-25.pdf","606e12a6":"# Sample predictions","723948d2":"# Compiling the model\nLoss function measures how well the neural network worked\nand then tries to improve it using optimizer.","b03440ab":"# Installing machine learning libraries","0efcbb11":"# Importing machine learning libraries and dataset","a7e58beb":"# Accuracy of 96.7% on test data is reported."}}