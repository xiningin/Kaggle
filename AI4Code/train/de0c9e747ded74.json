{"cell_type":{"e5cf0ec9":"code","13fbd7a8":"code","4c33d7d9":"code","d638d1be":"code","d9224cda":"code","863d97a3":"code","ee3845e8":"code","a5bcd79f":"code","89faf03a":"code","a9c752af":"code","8352c704":"code","5af3ae69":"code","ab731cdf":"markdown","08de1ee1":"markdown","af6c5fee":"markdown","1b005f8f":"markdown","f58b5169":"markdown","d6c85ce1":"markdown","be83a194":"markdown","5375fe89":"markdown","e08fec4c":"markdown","0c4ea6aa":"markdown","74755625":"markdown","ba8b9fb2":"markdown"},"source":{"e5cf0ec9":"!pip install self-supervised -Uq","13fbd7a8":"from fastai.vision.all import *\n\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nfrom self_supervised.vision.swav import *\n\nfrom sklearn.model_selection import StratifiedKFold\nimport torchvision.models as models\nfrom cuml.neighbors import NearestNeighbors","4c33d7d9":"df = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ndf.head()","d638d1be":"sk_fold = StratifiedKFold(5)\ndf['is_valid'] = False\nfor i, (trn_idx, val_idx) in enumerate(sk_fold.split(df, df.label_group)):\n    df.loc[val_idx, 'is_valid'] = True\n    break\n    \ndf.groupby('is_valid').label_group.value_counts()","d9224cda":"sum(df.label_group.value_counts() < 5)","863d97a3":"def get_x(x): return '..\/input\/shopee-product-matching\/train_images\/' + x['image']\n\ndef get_dls(size, bs, workers=None):\n    path = Path('..\/input\/shopee-product-matching\/train_images\/')\n    \n    db = DataBlock(blocks = (ImageBlock(), CategoryBlock()),\n              get_x = get_x, get_y=ColReader('label_group'),\n              splitter=ColSplitter(),\n              item_tfms=RandomResizedCrop(size, min_scale=1.))\n    dls = db.dataloaders(df, bs=bs, num_workers=workers)\n    return dls","ee3845e8":"bs, resize, size = 24, 256, 224\ndls = get_dls(resize, bs)","a5bcd79f":"## Model\narch = \"resnet50\"\nencoder = create_encoder(arch, pretrained=True, n_in=3)\nmodel = create_swav_model(encoder)\n\n## SwAV callback\nK = bs*2**4\naug_pipelines = get_swav_aug_pipelines(num_crops=[2, 6],\n                                       crop_sizes=[size,int(3\/4*size)], \n                                       min_scales=[0.25, 0.20],\n                                       max_scales=[1.00, 0.35],\n                                       rotate=True, rotate_deg=10, jitter=True, bw=True, blur=False)\ncbs=[SWAV(aug_pipelines, crop_assgn_ids=[0,1], K=K, queue_start_pct=0.5, temp=0.1)]","89faf03a":"learn = Learner(dls, model, cbs=cbs)","a9c752af":"b = dls.one_batch()\nlearn._split(b)\nlearn('before_batch')\nlearn.swav.show(n=5);","8352c704":"lr, wd = 1e-2, 1e-2\nepochs = 5 # try using 40 or 50\nlearn.unfreeze()\nlearn.fit_flat_cos(epochs, lr, wd=wd, pct_start=0.5)","5af3ae69":"save_name = f'swav_iwang_sz{size}_epc{epochs}'\nlearn.save(save_name)\ntorch.save(learn.model.encoder.state_dict(), learn.path\/learn.model_dir\/f'{save_name}_encoder.pth')\nlearn.recorder.plot_loss()","ab731cdf":"# Self-supervised learning with fastai\n\nInspired by [Ayush Thakur's work](https:\/\/www.kaggle.com\/ayuraj\/v2-self-supervised-pretraining-with-swav?scriptVersionId=59516445), I started exploring more about SwAV. The results in the [paper](https:\/\/arxiv.org\/abs\/2006.09882) were quite impressive. Hence, I decided to implement it.\n\nLucky for me, I found a pytorch implementation. Also, it used fastai. This was like a dream come true. Fastai is my comfort zone. You can find more about the [implementation here](https:\/\/keremturgutlu.github.io\/self_supervised\/). I will highly recommend checking out the documentation. Not just SwAV, the repository has fastai implementations of other state-of-the-art algorithms as well.\n\nI followed [this tutorial](https:\/\/keremturgutlu.github.io\/self_supervised\/04%20-%20training_swav_iwang.html) for creating this notebook that you are reading now. So, if something looks off or doesn't make sense, then please refer the original tutorial.\n\nLets get started . . .","08de1ee1":"### Training \n\nTime to train the model . . . ","af6c5fee":"Before we actually training the model, lets look at some of the samples. ","1b005f8f":"Lets create our dataloaders . . . ","f58b5169":"This notebook is only intended for learning. To get better score, try using different model architecture, bigger image size, etc.\n\nI can find the inference notebook, [here](https:\/\/www.kaggle.com\/ankursingh12\/shopee-swav-inference)\n\nHope you enjoyed reading this notebook. If yes, then please consider **upvoting**!","d6c85ce1":"There are 9620 `label_group` with less than 5 postings. Quite a lot, huh! (lets handle it in version-2).\n\n### Dataloaders\n\nFor now, lets create some helper functions to create dataloaders.","be83a194":"To train the model, we will also need a validation set. I will use simple `StratifiedKFold` technique to split my data into train & validation set.","5375fe89":"### Model & Callbacks\n\nFinally, lets initialize our model & SwAV callbacks","e08fec4c":"Great, we have our data, model, & also the callbacks. Fastai has this amazing class called `Learner` which put everything together for training.","0c4ea6aa":"### Installation & imports","74755625":"### Reading Data","ba8b9fb2":"As per the warning, there are some label groups with less than 5 posting. lets see how many such label group we have . . . "}}