{"cell_type":{"30d42492":"code","05a35e96":"code","24f7faaa":"code","827391cd":"code","bcdb23fc":"code","8a9297a8":"code","5112a0d8":"code","2cf1315a":"code","95519222":"code","2d7d4651":"code","0f95afc9":"code","de2e48bf":"code","7f3e5c2d":"code","3fc01fa3":"code","6cd80f3e":"markdown","1f901a4a":"markdown","975df8f4":"markdown","6a952b6b":"markdown","58d259a4":"markdown","c0398dfd":"markdown","9a54f0f4":"markdown","12a78734":"markdown","51ad2601":"markdown","83eb9462":"markdown","63f5e5e3":"markdown","4e20b9dd":"markdown","f6aa63cd":"markdown","42d67663":"markdown","82ab5975":"markdown","c064e6a7":"markdown","ee0d512e":"markdown","a7ca40d1":"markdown","bb560c6f":"markdown","bf2e5fff":"markdown","14b463d1":"markdown","798f2b1e":"markdown","6f43906e":"markdown","e5139ce2":"markdown","fde5fc01":"markdown"},"source":{"30d42492":"from tensorflow.keras.datasets import boston_housing\n(train_data,train_targets),(test_data, test_targets)=(boston_housing.load_data())","05a35e96":"# Let's see shape of datasets:\nprint(f\"The shape of train dataset: {train_data.shape}\")\nprint(f\"The shape of test dataset: {test_data.shape}\")","24f7faaa":"# Let's see target variable:\nprint(f\"The train target: {train_targets[:20]}\")","827391cd":"mean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis=0)\ntrain_data \/= std\ntest_data -= mean\ntest_data \/= std","bcdb23fc":"# Creating a function for buiding the model:\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\ndef build_model():\n    model = keras.Sequential([\n        layers.Dense(64, activation=\"relu\"),\n        layers.Dense(64, activation=\"relu\"),\n        layers.Dense(1)\n    ])\n    model.compile(optimizer=\"rmsprop\", \n                  loss=\"mse\", \n                  metrics=[\"mae\"])\n    return model","8a9297a8":"import numpy as np\nk = 4 \nnum_val_samples = len(train_data) \/\/ k\nnum_epochs = 100 \nall_scores = [] \nfor i in range(k):\n    # Preparing the validation data:\n    print(f\"Processing fold #{i}\")\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate(\n        [train_data[:i * num_val_samples],\n         train_data[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_targets = np.concatenate(\n        [train_targets[:i * num_val_samples],\n         train_targets[(i + 1) * num_val_samples:]],\n        axis=0)\n    # Instantiating the model\n    model = build_model()   \n    # Training the model\n    model.fit(partial_train_data, \n              partial_train_targets,                   \n              epochs=num_epochs, \n              batch_size=16, \n              verbose=0)\n    # Evaluating the model\n    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)     \n    all_scores.append(val_mae)","5112a0d8":"print(f\"All score: {all_scores}\")\nprint(f\"The mean of all scores: {np.mean(all_scores)}\")","2cf1315a":"num_epochs = 500 \nall_mae_histories = [] \nfor i in range(k):\n    print(f\"Processing fold #{i}\")\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate(\n        [train_data[:i * num_val_samples],\n         train_data[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_targets = np.concatenate(\n        [train_targets[:i * num_val_samples],\n         train_targets[(i + 1) * num_val_samples:]],\n        axis=0)\n    # Instantiating the model\n    model = build_model()  \n    # Training the model\n    history = model.fit(partial_train_data, \n                        partial_train_targets,\n                        validation_data=(val_data, val_targets),\n                        epochs=num_epochs, \n                        batch_size=16, \n                        verbose=0)\n    mae_history = history.history[\"val_mae\"]\n    all_mae_histories.append(mae_history)","95519222":"average_mae_history = [\n    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]","2d7d4651":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nplt.figure(figsize = (16, 10))\nplt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Validation MAE\")\nplt.show()","0f95afc9":"plt.figure(figsize = (16, 10))\ntruncated_mae_history = average_mae_history[10:]\nplt.plot(range(1, len(truncated_mae_history) + 1), truncated_mae_history)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Validation MAE\")\nplt.show()","de2e48bf":"model = build_model() \nmodel.fit(train_data, \n          train_targets,\n          epochs=130, \n          batch_size=16, \n          verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(test_data, test_targets)","7f3e5c2d":"print(f\"Test mae score: {test_mae_score}\")","3fc01fa3":"predictions = model.predict(test_data)\nprint(f\"The predicted price of first sample: {predictions[0]}\")","6cd80f3e":"### As you can see, the prices are between 10,000 and 50,000","1f901a4a":"### As you can see, validation MAE stops improving significantly after 120\u2013140 epochs.\n\n### Let's train the final model and evaluate.","975df8f4":"# <span style = \"color: OrangeRed\"> Regression Analysis with Keras <\/span>","6a952b6b":"# <span style = \"color: Orange\"> The Boston Housing Price Dataset <\/span> ","58d259a4":"### I am going to train the model a bit longer: 500 epochs. To keep a record of how well the model does at each epoch, we\u2019ll modify the training loop to save the per-epoch validation score log for each fold.","c0398dfd":"### I\u2019ll build with two intermediate layers, each with 64 units. Note that the regression model ends with a single unit and no activation.\n\n### To compile the model, I'll use mse loss function, the square of the difference between the predictions and the targets and monitore with mae, the absolute value of the difference between the predictions and the targets.","9a54f0f4":"![](https:\/\/images.unsplash.com\/photo-1564013799919-ab600027ffc6?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1170&q=80)","12a78734":"### The goal of regression analysis is to predict a continuous value. In this example, I will show you how to build the regression model. ","51ad2601":"### Let's see all scores and mean of all scores.","83eb9462":"### Let's see plotting validation scores.","63f5e5e3":"## <span style = \"color: Orange\"> Building the Model <\/span>","4e20b9dd":"### Let's predict new data using test dataset.","f6aa63cd":"# <span style = \"color:OrangeRed\"> Resource<\/span>","42d67663":"## <span style = \"color: Orange\"> Predicting New Data <\/span> ","82ab5975":"# <span style = \"color: Orange\"> Loading the Dataset <\/span> ","c064e6a7":"### Each feature in the input data has a different scale. A widespread best practice for dealing with such data is to do feature-wise normalization.\n\n### To normalize, I am going to subtract the mean of the feature and divide by the standard deviation. ","ee0d512e":"##  <span style = \"color: Orange\"> Preparing the Data <\/span> ","a7ca40d1":"### The Boston housing data was collected in 1978 and each of the 506 entries represent aggregated data about 14 features for homes from various suburbs in Boston, Massachusetts. The dataset consists of 404 training samples and 102 test samples.","bb560c6f":"### Let's build the history of successive mean K-fold validation scores","bf2e5fff":"### To evaluate our model, I am going to split the data into a training set and a validation set. Because we have small dataset we can use K-fold validation.","14b463d1":"### Don\u2019t forget to follow us on [YouTube](https:\/\/youtube.com\/c\/tirendazakademi) \ud83c\udf9e, [GitHub](https:\/\/github.com\/tirendazacademy) \ud83c\udf31, [Twitter](https:\/\/twitter.com\/@tirendazacademy) \ud83d\ude0e, [LinkedIn](https:\/\/www.linkedin.com\/in\/tirendaz-academy) \ud83d\udc4d","798f2b1e":"## <span style = \"color: Orange\"> Creating Validation Dataset <\/span> ","6f43906e":"### [Chollet, F. 2021, Deep Learning with Python](https:\/\/www.manning.com\/books\/deep-learning-with-python-second-edition)","e5139ce2":"### The predicted price of first house is $95,724. That is it. I hope you enjoy it. ","fde5fc01":"### To see better graph, I am going to use the first data point."}}