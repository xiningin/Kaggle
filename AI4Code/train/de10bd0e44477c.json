{"cell_type":{"d6ad9f39":"code","714eb6c1":"code","710d5201":"code","a66f5b7f":"code","21b9594c":"code","7c328415":"code","613e3cfe":"code","3418e27e":"code","025d21e5":"code","91673f90":"code","c16ace93":"code","c89152e6":"code","92e2bc70":"code","267145b4":"markdown"},"source":{"d6ad9f39":"\"\"\"\ncreated on: 24\/08\/21 23:04\nauthor: @preet\n\"\"\"","714eb6c1":"# Import the required libraries\nimport cv2\nimport numpy as np","710d5201":"# Load Yolo\nnet = cv2.dnn.readNet(\"..\/input\/yolo-coco-data\/yolov3.weights\", \"..\/input\/yolo-coco-data\/yolov3.cfg\")","a66f5b7f":"# Load class names from 'coco.names'\nclasses = []\nwith open(\"..\/input\/yolo-coco-data\/coco.names\", \"r\") as f:\n    classes = [line.strip() for line in f.readlines()]\nprint(classes)","21b9594c":"layer_names = net.getLayerNames()\nprint(layer_names)","7c328415":"# net.getUnconnectedOutLayers()\n# net.getUnconnectedOutLayersNames()\noutputlayers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\nprint(outputlayers)","613e3cfe":"# Loading the image\nimg = cv2.imread(\"..\/input\/yolo-v3\/sample_1.jpeg\")\nimg = cv2.resize(img, None, fx=0.7, fy=0.7)\nheight, width, channels = img.shape\ncolors = np.random.uniform(0, 255, size=(len(classes),3))","3418e27e":"\"\"\"\ncv2.imshow(\"Sample Image\", img)\ncv2.waitKey(0)\ncv2.destroyAllWindows\n\"\"\"","025d21e5":"# Detecting Objects\nblob = cv2.dnn.blobFromImage(img, 0.00392, (416,416), (0,0,0), True, crop = False)","91673f90":"for b in blob:\n    for n,img_blob in enumerate(b):\n        cv2.imshow(str(n), img_blob)\n        cv2.waitKey(1000)\n        cv2.destroyAllWindows","c16ace93":"net.setInput(blob)\nouts = net.forward(outputlayers)\nprint(outs)","c89152e6":"boxes=[]\nclass_ids=[]\nconfidences=[]\nfor out in outs:\n    for detection in out:\n        scores = detection[5:]\n        class_id = np.argmax(scores)\n        confidence = scores[class_id]\n        if confidence > 0.5:\n            # Object detected\n            center_x = int(detection[0]*width)\n            center_y = int(detection[1]*height)\n            w = int(detection[2]*width)\n            h = int(detection[3]*height)\n            # cv2.circle(img, (center_x, center_y), 10, (0,255,0), 2)\n            # Rectangle coordinates\n            x = int(center_x - w\/2)\n            y = int(center_y - h\/2)\n            # cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n            boxes.append([x, y, w, h])\n            class_ids.append(class_id)\n            confidences.append(float(confidence))","92e2bc70":"indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\nfont = cv2.FONT_HERSHEY_PLAIN\nfor i in range(len(boxes)):\n    if i in indexes:\n        x, y, w, h = boxes[i]\n        label = str(classes[class_ids[i]])\n        color = colors[i]\n        cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n        cv2.putText(img, label, (x, y+30), font, 1, color, 3)","267145b4":"# Object Detection Using Yolo with OpenCV\nI have used the following dataset from kaggle: https:\/\/www.kaggle.com\/valentynsichkar\/yolo-coco-data"}}