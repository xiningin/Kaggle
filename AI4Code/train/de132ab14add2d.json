{"cell_type":{"f4621730":"code","39c9c649":"code","f4e1a764":"code","4f9ac90b":"code","053f266b":"code","fde52b80":"code","0de61d8d":"code","944b7190":"code","79d5ccfc":"code","d580543c":"code","06451db0":"code","b4296836":"code","bc95feaf":"code","0531bfbe":"code","4851ed83":"code","054de2d1":"code","f41aa495":"code","a4092028":"code","b140f1bb":"code","363eae87":"code","d180d3f3":"code","d004fb72":"code","bd0b110c":"code","b447b815":"code","b70b66cd":"code","ad023236":"code","bae2602c":"code","655ea384":"code","114e421f":"code","9d42e46c":"code","312c5fe7":"code","6d346ef3":"code","d85d2c5f":"markdown","511a4fc7":"markdown","52f54c77":"markdown","1ef42e98":"markdown","0386954c":"markdown","9baa2e17":"markdown","78cec77a":"markdown","949fda2f":"markdown","89a8a9f4":"markdown","9600b8de":"markdown","d2d5b4e9":"markdown","ce0ac0d1":"markdown","5f57666b":"markdown","ef73425b":"markdown","b83a7984":"markdown","3ab37a3e":"markdown","9ebca663":"markdown","91cf449e":"markdown","adb69454":"markdown","be7c23ae":"markdown","d324acf0":"markdown"},"source":{"f4621730":"import numpy as np \nimport pandas as pd\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\npd.set_option('display.max_columns', None)","39c9c649":"hr = pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')","f4e1a764":"hr.head()","4f9ac90b":"hr.info()","053f266b":"hr = hr.drop(['enrollee_id', 'city'], axis = 1)","fde52b80":"hr['company_size'].unique()","0de61d8d":"for i in range(len(hr.index)):\n    if hr['company_size'][i] == '10\/49':\n        hr['company_size'][i] = '10-49'","944b7190":"hr['experience'].unique()","79d5ccfc":"for i in range(len(hr.index)):\n    if hr['experience'][i] == '>20':\n        hr['experience'][i] = '21'\n    elif hr['experience'][i] == '<1':\n        hr['experience'][i] = '0'","d580543c":"hr['last_new_job'].unique()","06451db0":"for i in range(len(hr.index)):\n    if hr['last_new_job'][i] == '>4':\n        hr['last_new_job'][i] = '5'\n    elif hr['last_new_job'][i] == 'never':\n        hr['last_new_job'][i] = '0'","b4296836":"retarget = {0.0: 'Not looking for job change',\n           1.0: 'Looking for job change'}\nhr['target'] = hr['target'].map(retarget)","bc95feaf":"target = hr.groupby('target').agg({'target': 'count'}).rename(columns = {'target': 'count'}).reset_index()\n\nfig = px.pie(target, values = 'count', names = 'target')\nfig.update_traces(textposition = 'inside', \n                  textinfo = 'percent + label', \n                  hole = 0.5, \n                  marker = dict(colors = ['#32384D','#E29930'], line = dict(color = 'white', width = 2)))\n\nfig.update_layout(title_text = 'Job search', title_x = 0.5, title_y = 0.53, title_font_size = 32, title_font_family = 'Calibri Black', title_font_color = 'black',\n                  showlegend = False)\n                  \nfig.show()","0531bfbe":"gender = hr.groupby(['gender', 'target']).agg({'target': 'count'}).rename(columns = {'target': 'count'}).reset_index()\nexperience = hr.groupby(['relevent_experience', 'target']).agg({'target': 'count'}).rename(columns = {'target': 'count'}).reset_index()\neducation_level = hr.groupby(['education_level', 'target']).agg({'target': 'count'}).rename(columns = {'target': 'count'}).reset_index()\nenrolled = hr.groupby(['enrolled_university', 'target']).agg({'target': 'count'}).rename(columns = {'target': 'count'}).reset_index()\nmajor_discipline = hr.groupby(['major_discipline', 'target']).agg({'target': 'count'}).rename(columns = {'target': 'count'}).reset_index()\ncompany_type = hr.groupby(['company_type', 'target']).agg({'target': 'count'}).rename(columns = {'target': 'count'}).reset_index()","4851ed83":"fig = plt.figure(figsize = (22, 22))\nfig.patch.set_facecolor('#fafafa')\n\nplt.subplot(321)\nsns.set_style('white')\nplt.title('Gender', size = 14)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\na = sns.barplot(data = gender, x = gender['gender'], y = gender['count'], hue = gender['target'], palette = ['#32384D', '#E29930'])\nfor p in a.patches:\n    height = p.get_height()\n    a.annotate(f'{height:g}', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.ylabel('')\nplt.xlabel('')\nplt.legend(loc = 'upper left')\n\nplt.subplot(322)\nplt.title('Relevent experience', size = 14)\na2 = sns.barplot(data = experience, x = experience['relevent_experience'], y = experience['count'], hue = experience['target'], palette = ['#32384D', '#E29930'])\nfor p in a2.patches:\n    height = p.get_height()\n    a2.annotate(f'{height:g}', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(323)\nplt.title('Education', size = 14)\na3 = sns.barplot(data = education_level, x = education_level['education_level'], y = education_level['count'], hue = education_level['target'], palette = ['#32384D', '#E29930'])\nfor p in a3.patches:\n    height = p.get_height()\n    a3.annotate(f'{height:g}', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(324)\nplt.title('Enrolled university', size = 14)\na4 = sns.barplot(data = enrolled, x = enrolled['enrolled_university'], y = enrolled['count'], hue = enrolled['target'], palette = ['#32384D', '#E29930'])\nfor p in a4.patches:\n    height = p.get_height()\n    a4.annotate(f'{height:g}', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(325)\nplt.title('Major discipline', size = 14)\na5 = sns.barplot(data = major_discipline, x = major_discipline['major_discipline'], y = major_discipline['count'], hue = major_discipline['target'], palette = ['#32384D', '#E29930'])\nfor p in a5.patches:\n    height = p.get_height()\n    a5.annotate(f'{height:g}', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(326)\nplt.title('Company type', size = 14)\na6 = sns.barplot(data = company_type, x = company_type['company_type'], y = company_type['count'], hue = company_type['target'], palette = ['#32384D', '#E29930'])\nfor p in a6.patches:\n    height = p.get_height()\n    a6.annotate(f'{height:g}', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.show()","054de2d1":"# Function for calculating the percentage of people in each group\ndef percent(data):\n    data['percent'] = 0\n    for i in range(len(data.index)):\n        if data.index[i] % 2 == 0:\n            data.iloc[i, 3] = round((data.iloc[i, 2] \/ (data.iloc[i, 2] + data.iloc[i+1, 2])) * 100, 1)\n        else:\n            data.iloc[i, 3] = round((data.iloc[i, 2] \/ (data.iloc[i, 2] + data.iloc[i-1, 2])) * 100, 1)\n            \npercent(gender)\npercent(experience)\npercent(education_level)\npercent(enrolled)\npercent(major_discipline)\npercent(company_type)","f41aa495":"fig = plt.figure(figsize = (22, 22))\nfig.patch.set_facecolor('#fafafa')\n\nplt.subplot(321)\nsns.set_style('white')\nplt.title('Gender', size = 14)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\na = sns.barplot(data = gender, x = gender['gender'], y = gender['percent'], hue = gender['target'], palette = ['#32384D', '#E29930'])\nfor p in a.patches:\n    height = p.get_height()\n    a.annotate(f'{height:g}%', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(322)\nplt.title('Relevent experience', size = 14)\na2 = sns.barplot(data = experience, x = experience['relevent_experience'], y = experience['percent'], hue = experience['target'], palette = ['#32384D', '#E29930'])\nfor p in a2.patches:\n    height = p.get_height()\n    a2.annotate(f'{height:g}%', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend(loc = 'upper right')\n\nplt.subplot(323)\nplt.title('Education', size = 14)\na3 = sns.barplot(data = education_level, x = education_level['education_level'], y = education_level['percent'], hue = education_level['target'], palette = ['#32384D', '#E29930'])\nfor p in a3.patches:\n    height = p.get_height()\n    a3.annotate(f'{height:g}%', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(324)\nplt.title('Enrolled university', size = 14)\na4 = sns.barplot(data = enrolled, x = enrolled['enrolled_university'], y = enrolled['percent'], hue = enrolled['target'], palette = ['#32384D', '#E29930'])\nfor p in a4.patches:\n    height = p.get_height()\n    a4.annotate(f'{height:g}%', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(325)\nplt.title('Major discipline', size = 14)\na5 = sns.barplot(data = major_discipline, x = major_discipline['major_discipline'], y = major_discipline['percent'], hue = major_discipline['target'], palette = ['#32384D', '#E29930'])\nfor p in a5.patches:\n    height = p.get_height()\n    a5.annotate(f'{height:g}%', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(326)\nplt.title('Company type', size = 14)\na6 = sns.barplot(data = company_type, x = company_type['company_type'], y = company_type['percent'], hue = company_type['target'], palette = ['#32384D', '#E29930'])\nfor p in a6.patches:\n    height = p.get_height()\n    a6.annotate(f'{height:g}%', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('')\n\nplt.show()","a4092028":"exp_no_nan = hr[pd.isna(hr['experience']) == False]\nexp_no_nan['experience'] = exp_no_nan['experience'].astype('int')\n\nlastjob_no_nan = hr[pd.isna(hr['last_new_job']) == False]\nlastjob_no_nan['last_new_job'] = lastjob_no_nan['last_new_job'].astype('int')","b140f1bb":"fig = plt.figure(figsize = (20, 20))\nfig.patch.set_facecolor('#fafafa')\n\nplt.subplot(221)\nsns.set_style('white')\nplt.title('City Development Index', size = 14)\nsns.kdeplot(hr.query('target == \"Looking for job change\"')['city_development_index'], color = '#32384D', shade = True, label = 'Looking for job change', alpha = 0.5)\nsns.kdeplot(hr.query('target == \"Not looking for job change\"')['city_development_index'], color = '#E29930', shade = True, label = 'Not looking for job change', alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\nplt.legend(loc = 'upper left')\n\nplt.subplot(222)\nplt.title('Years of experience', size = 14)\nsns.kdeplot(exp_no_nan.query('target == \"Looking for job change\"')['experience'], color = '#32384D', shade = True, label = 'Looking for job change', alpha = 0.5)\nsns.kdeplot(exp_no_nan.query('target == \"Not looking for job change\"')['experience'], color = '#E29930', shade = True, label = 'Not looking for job change', alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\n\nplt.subplot(223)\nplt.title('Training hours', size = 14)\nsns.kdeplot(hr.query('target == \"Looking for job change\"')['training_hours'], color = '#32384D', shade = True, label = 'Looking for job change', alpha = 0.5)\nsns.kdeplot(hr.query('target == \"Not looking for job change\"')['training_hours'], color = '#E29930', shade = True, label = 'Not looking for job change', alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\n\nplt.subplot(224)\nplt.title('Years from last job to current job', size = 14)\nsns.kdeplot(lastjob_no_nan.query('target == \"Looking for job change\"')['last_new_job'], color = '#32384D', shade = True, label = 'Looking for job change', alpha = 0.5)\nsns.kdeplot(lastjob_no_nan.query('target == \"Not looking for job change\"')['last_new_job'], color = '#E29930', shade = True, label = 'Not looking for job change', alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\n\nplt.show()","363eae87":"cs = hr.groupby(['target', 'company_size']).agg({'target': 'count'}).rename(columns = {'target': 'count'}).reset_index()\n\nfig = px.sunburst(cs, path = ['target', 'company_size'], values = 'count', color = 'target',\n                 color_discrete_map = {'Looking for job change': '#32384D', 'Not looking for job change': '#E29930'},\n                 width = 700, height = 700)\n\nfig.update_layout(annotations = [dict(text = 'Affect of company size on the desire to change job', \n                                      x = 0.5, y = 1.1, font_size = 24, showarrow = False, \n                                      font_family = 'Calibri Black',\n                                      font_color = 'black')])\n\nfig.update_traces(textinfo = 'label + percent parent')\n                  \nfig.show()","d180d3f3":"hr.dropna(inplace = True)\n\nretarget2 = {'Not looking for job change': 0, 'Looking for job change': 1}\nhr['target'] = hr['target'].map(retarget2)\n\nhr['experience'] = hr['experience'].astype('int')\n        \nhr['last_new_job'] = hr['last_new_job'].astype('int')","d004fb72":"matrix = np.triu(hr.corr())\nplt.figure(figsize=(13, 10))\nsns.heatmap(hr.corr(), annot = True, cmap = 'YlOrBr', fmt=\".2f\", mask = matrix,\n            vmin = -1, vmax = 1, linewidths = 0.1, linecolor = 'white', cbar = False)\nplt.show()","bd0b110c":"X = hr.drop(['target'], axis = 1)\ny = hr['target']\n\nnum_cols = X.select_dtypes(include = ['int64', 'float64']).columns.to_list()\ncat_cols = X.select_dtypes(include = ['object']).columns.to_list()\n\ndef label_encoder(df):\n    for i in cat_cols:\n        le = LabelEncoder()\n        df[i] = le.fit_transform(df[i])\n    return df\n\nsc = StandardScaler()\nX[num_cols] = sc.fit_transform(X[num_cols])\n\nX = label_encoder(X)\n\nX.head()","b447b815":"hr['target'].value_counts()","b70b66cd":"from imblearn.over_sampling import SMOTE\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2021)\n\nsmote = SMOTE()\n\nX_train_balanced, Y_train_balanced = smote.fit_resample(X_train, y_train)\n\nY_train_balanced.value_counts()","ad023236":"results = pd.DataFrame(columns = ['LR', 'RF', 'XGB', 'LGBM', 'CB'], index = range(4))","bae2602c":"lg = LogisticRegression(random_state = 2021)\nlg.fit(X_train_balanced, Y_train_balanced)\ny_pred = lg.predict(X_test)\ny_prob = lg.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 0] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 0] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 0] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 0] = round(roc_auc_score(y_test, y_prob), 3)\nlg_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(lg, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(lg, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(lg, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(lg, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(lg_cm, cmap = 'YlOrBr', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Not looking for job change', 'Looking for job change'], xticklabels = ['Predicted not looking for job change', 'Predicted looking for job change'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp = pd.DataFrame(columns = ['feature', 'importance (abs coef)'], index = range(11))\nfor i in range(len(f_imp.index)):\n    f_imp.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp['importance (abs coef)'] = abs(lg.coef_)[0]\nf_imp = f_imp.sort_values('importance (abs coef)', ascending = False)\nf_imp[0:11].style.background_gradient(cmap = 'YlOrBr')","655ea384":"rf = RandomForestClassifier(random_state = 2021, max_depth = 5)\nrf.fit(X_train_balanced, Y_train_balanced)\ny_pred = rf.predict(X_test)\ny_prob = rf.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 1] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 1] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 1] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 1] = round(roc_auc_score(y_test, y_prob), 3)\nrf_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(rf, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(rf, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(rf, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(rf, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(rf_cm, cmap = 'YlOrBr', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},\n           yticklabels = ['Not looking for job change', 'Looking for job change'], xticklabels = ['Predicted not looking for job change', 'Predicted looking for job change'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp2 = pd.DataFrame(columns = ['feature', 'importance'], index = range(11))\nfor i in range(len(f_imp2.index)):\n    f_imp2.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp2['importance'] = rf.feature_importances_\nf_imp2 = f_imp2.sort_values('importance', ascending = False)\nf_imp2[0:11].style.background_gradient(cmap = 'YlOrBr')","114e421f":"xgb = XGBClassifier(random_state = 2021, max_depth = 5, objective = 'binary:logistic', eval_metric = 'logloss')\nxgb.fit(X_train_balanced, Y_train_balanced)\ny_pred = xgb.predict(X_test)\ny_prob = xgb.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 2] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 2] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 2] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 2] = round(roc_auc_score(y_test, y_prob), 3)\nxgb_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(xgb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(xgb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(xgb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(xgb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(xgb_cm, cmap = 'YlOrBr', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},\n           yticklabels = ['Not looking for job change', 'Looking for job change'], xticklabels = ['Predicted not looking for job change', 'Predicted looking for job change'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp3 = pd.DataFrame(columns = ['feature', 'importance'], index = range(11))\nfor i in range(len(f_imp3.index)):\n    f_imp3.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp3['importance'] = xgb.feature_importances_\nf_imp3 = f_imp3.sort_values('importance', ascending = False)\nf_imp3[0:11].style.background_gradient(cmap = 'YlOrBr')","9d42e46c":"lgbm = LGBMClassifier(random_state = 2021, max_depth = 5, num_leaves = 50)\nlgbm.fit(X_train_balanced, Y_train_balanced)\ny_pred = lgbm.predict(X_test)\ny_prob = lgbm.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 3] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 3] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 3] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 3] = round(roc_auc_score(y_test, y_prob), 3)\nlgbm_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(lgbm, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(lgbm, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(lgbm, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(lgbm, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(lgbm_cm, cmap = 'YlOrBr', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},\n           yticklabels = ['Not looking for job change', 'Looking for job change'], xticklabels = ['Predicted not looking for job change', 'Predicted looking for job change'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp4 = pd.DataFrame(columns = ['feature', 'importance'], index = range(11))\nfor i in range(len(f_imp4.index)):\n    f_imp4.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp4['importance'] = lgbm.feature_importances_\nf_imp4 = f_imp4.sort_values('importance', ascending = False)\nf_imp4[0:11].style.background_gradient(cmap = 'YlOrBr')","312c5fe7":"cb = CatBoostClassifier(random_state = 2021, depth = 5, iterations = 500, verbose = False)\ncb.fit(X_train_balanced, Y_train_balanced)\ny_pred = lgbm.predict(X_test)\ny_prob = lgbm.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 4] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 4] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 4] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 4] = round(roc_auc_score(y_test, y_prob), 3)\nlgbm_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(cb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(cb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(cb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(cb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(lgbm_cm, cmap = 'YlOrBr', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},\n           yticklabels = ['Not looking for job change', 'Looking for job change'], xticklabels = ['Predicted not looking for job change', 'Predicted looking for job change'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp5 = pd.DataFrame(columns = ['feature', 'importance'], index = range(11))\nfor i in range(len(f_imp5.index)):\n    f_imp5.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp5['importance'] = cb.feature_importances_\nf_imp5 = f_imp5.sort_values('importance', ascending = False)\nf_imp5[0:11].style.background_gradient(cmap = 'YlOrBr')","6d346ef3":"plt.figure(figsize = (10, 7))\nsns.heatmap(results[results.columns.to_list()].astype(float), cmap = 'YlOrBr', annot = True, linewidths = 1, cbar = False, annot_kws = {'fontsize': 12},\n           yticklabels = ['Precision', 'Recall', 'F1', 'ROC AUC'])\nsns.set(font_scale = 1.5)\nplt.yticks(rotation = 0)\nplt.show()","d85d2c5f":"The missing values in this data are not the ones that can be easily to impute, because if you restore incorrectly, you may actually see non-existent correlations and, in general, the data logic may be lost. Therefore, the EDA will be performed on all available data, and for modeling, all rows with missing values will be deleted.","511a4fc7":"Some more EDA :) The correlation map was not made earlier, because there were missing values and it was impossible to convert the necessary columns to a numeric format.","52f54c77":"# CatBoost","1ef42e98":"# Distribution of job changing by gender, relevet experience, education, enrolled university, major discipline and company type","0386954c":"# Preparing data for EDA ","9baa2e17":"![](https:\/\/icma.org\/sites\/default\/files\/Talent-Development.jpg)","78cec77a":"# \ud83d\udea7\ud83d\udea7\ud83d\udea7WORK IN PROGRESS\ud83d\udea7\ud83d\udea7\ud83d\udea7","949fda2f":"# Basic information","89a8a9f4":"# XGB","9600b8de":"# LGBM","d2d5b4e9":"# Conclusions of EDA","ce0ac0d1":"# Logistic Regression","5f57666b":"# Preparing data for modeling","ef73425b":"# Random Forest","b83a7984":"# EDA","3ab37a3e":"# Distribution of job changing by cdi, experience, company size, last job and training hours","9ebca663":"**For modeling I will use 5 models:**\n\n1. Logistic Regression\n2. Random Forest\n3. XGB\n4. LGBM\n5. CatBoost\n\nAnd also I will check Cross-validation with 5 folds.","91cf449e":"# Modeling","adb69454":"1. People with no relevant experience are more inclined to search for a new job.\n2. Specialists with graduate education are more likely than others to look for a new job.\n3. People who signed up for the full time course are more likely than others to look for a new job.\n4. People who have a major discipline STEM (Science, Technology, Engineering and Mathematics) are more likely than others to look for a new job.\n5. The CDI (City Development Index) has a big role in the desire to change job: more than half of the specialists with a low CDI are looking for a new job - in cities with a high CDI, which is not strange, the situation is the opposite, more than half of the specialists are not interested in finding a new job.\n6. People working in Data Science for the first 8 years are more likely to look for a new job, and more than half of the specialists working in this field for more than 20 years are not looking for a new job.","be7c23ae":"# Results","d324acf0":"It's not good idea to modeling with imbalanced data, so I will use SMOTE (Synthetic Minority Over-sampling Technique) - one of the most commonly used resampling techniques to solve the imbalance problem."}}