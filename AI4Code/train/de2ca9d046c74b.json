{"cell_type":{"c448fb4f":"code","52b02732":"code","56317fd7":"code","d5fd45fc":"code","3b4d2f94":"code","3748771c":"code","1e347c5c":"code","5d4338da":"code","52c8b3f9":"code","0efa9217":"code","a3f01c48":"code","56cc27b5":"code","f55a4f2d":"code","27a84999":"code","ea17e307":"code","0e158122":"code","1d6b4373":"code","f3ac6a65":"code","aab411c3":"code","0651fe2f":"code","a4b9eaac":"code","186c58ee":"code","8d836696":"code","11f9c6bd":"code","5bd05ab4":"code","96d57e1d":"code","b1f6e1ea":"code","58ed6318":"code","c9350f2e":"code","f9723b6a":"code","800f4cea":"code","365c5d39":"code","32a95d26":"code","65f182dd":"code","a8d2786f":"code","de7d75f0":"code","ecc9e69d":"code","7ab86d29":"code","821718de":"code","5572c37a":"code","f6117da7":"code","1cf59e21":"code","2dacf292":"code","2acaf3da":"code","d664e906":"code","a50397fe":"code","ba78b43e":"code","4f69407f":"code","17291820":"code","48485222":"code","278f33cd":"code","265c029b":"code","f06cf05f":"code","d4f8b729":"code","5cc897af":"code","aba320ca":"code","1b72e4c6":"code","328cd1e9":"code","58c7fe62":"code","d213b4ec":"code","6eaec554":"markdown","22f961e4":"markdown","32dd3fc7":"markdown","1fb06110":"markdown","12200ab2":"markdown","d6efc41a":"markdown"},"source":{"c448fb4f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","52b02732":"#Import libiraies\nimport pandas as pd     \nimport numpy as np      \nimport matplotlib.pyplot as plt  \n%matplotlib inline\nimport seaborn as sns  ","56317fd7":"# read the data\ntrain = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/train_V2.csv')\ntrain.head()","d5fd45fc":"#See the no.of rows and features\ntrain.shape","3b4d2f94":"pd.options.display.max_columns = 60","3748771c":"#More information about the features and the data types\ntrain.info()","1e347c5c":"# It is a time to detect the Missing values so let's see how many missing values in our data  \ntrain.isna().sum()","5d4338da":"# Here I dropped this missing value \ntrain.drop(2744604,inplace=True)","52c8b3f9":"#Finally we haven't have any missing data\ntrain.isna().sum().sum()","0efa9217":"#Here we collect all these distance that user walked into one feature \ntrain['all_distance']=train['rideDistance']+train['walkDistance']+train['swimDistance']\n#Delete the old feature of distance \ntrain.drop(columns=['walkDistance','swimDistance','rideDistance'],axis=1,inplace=True)","a3f01c48":"#Here  we collect all the medicine that user taked into one feature \ntrain['medicine']=train['boosts']+train['heals']\n\ntrain.drop(columns=['boosts','heals'],axis=1,inplace=True)","56cc27b5":"\ntrain.drop(columns=['Id','groupId','matchId','rankPoints','matchType'],inplace=True)","f55a4f2d":"sns.distplot(train['medicine'])\n","27a84999":"#Drop users that used more than 40 medicine help which may be hacker\ntrain.drop(train[train['medicine'] > 40].index, inplace=True)","ea17e307":"#Distribution of  medicine feature after detect outliers \nsns.distplot(train['medicine'])","0e158122":"#Let's see the distribution of Kills of user\nsns.distplot(train['kills'])","1d6b4373":"# Drop the user that kill more than 20 kills \ntrain.drop(train[train['kills'] > 20].index, inplace=True)","f3ac6a65":"#distribution of kills feature after \nsns.distplot(train['kills'],bins=[0,5,10,15,20])","aab411c3":"sns.distplot(train['longestKill'])","0651fe2f":"# Drop the user that kill an enemy from more than 600 kills \ntrain.drop(train[train['longestKill'] > 600].index, inplace=True)","a4b9eaac":"sns.distplot(train['longestKill'])","186c58ee":"sns.distplot(train.killStreaks)","8d836696":"train.drop(train[train['killStreaks']>12].index,inplace=True)","11f9c6bd":"sns.distplot(train.killStreaks)","5bd05ab4":"sns.distplot(train.weaponsAcquired)","96d57e1d":"train.drop(train[train['weaponsAcquired'] >= 80].index, inplace=True)","b1f6e1ea":"sns.distplot(train['weaponsAcquired'])","58ed6318":"train.head()","c9350f2e":"train.shape","f9723b6a":"print('We delete {} rows and {} columns'.format(4446966-4445429,29-21))","800f4cea":"# define dependant and independant features\nX=train.drop(columns=['winPlacePerc'])\ny=train['winPlacePerc']","365c5d39":"from sklearn.feature_selection import f_regression\nfrom sklearn.feature_selection import SelectKBest\nbest_feature = SelectKBest(score_func=f_regression,k='all')\nfit = best_feature.fit(X,y)","32a95d26":"score = pd.DataFrame(fit.scores_)\ncolumns = pd.DataFrame(X.columns)\nfeatureScores = pd.concat([columns,score],axis=1)\nfeatureScores.columns = ['Feature','Score']\nfeatureScores = featureScores.sort_values(by='Score',ascending=False).reset_index(drop=True)\n\nfeatureScores","65f182dd":"# Select the most 10 features \nX= X[featureScores.Feature[:10].values]","a8d2786f":"\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler","de7d75f0":"#Split data into train and test data\nX_train ,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)","ecc9e69d":"# prepare steps to pipeline with linear regression model\nsteps=[('Scalar',StandardScaler()), ('Linear Regression',LinearRegression())]","7ab86d29":"pipeline = Pipeline(steps)","821718de":"pipeline.fit(X_train,y_train)","5572c37a":"y_pred=pipeline.predict(X_test)","f6117da7":"\nprint(' Linear Regression score {}'.format(pipeline.score(X_test,y_test)))","1cf59e21":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import *","2dacf292":"print('Root mean square error {}'.format(np.sqrt(mean_squared_error(y_test,y_pred))))","2acaf3da":"# Random forest regressor  \nregressor = RandomForestRegressor(n_estimators = 20, random_state = 0)","d664e906":"regressor.fit(X_train,y_train)","a50397fe":"y_pred=regressor.predict(X_test)","ba78b43e":"accuracy=r2_score(y_test,y_pred)\nprint('The accuracy is {}'.format(accuracy))","4f69407f":"from sklearn.metrics import mean_squared_error\nprint('Root mean square error {}'.format(np.sqrt(mean_squared_error(y_test,y_pred))))","17291820":"test = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/test_V2.csv')","48485222":"#Here we collect all these distance that user walked into one feature \ntest['all_distance']=test['rideDistance']+test['walkDistance']+test['swimDistance']\n#Delete the old feature of distance \ntest.drop(columns=['walkDistance','swimDistance','rideDistance'],axis=1,inplace=True)\n#Here  we collect all the medicine that user taked into one feature \ntest['medicine']=test['boosts']+test['heals']\n\ntest.drop(columns=['boosts','heals'],axis=1,inplace=True)\ntest.drop(columns=['Id','groupId','matchId','rankPoints','matchType'],inplace=True)\ntest.drop(test[test['medicine'] > 40].index, inplace=True)\ntest.drop(test[test['kills'] > 20].index, inplace=True)\ntest.drop(test[test['longestKill'] > 600].index, inplace=True)\ntest.drop(test[test['killStreaks']>12].index,inplace=True)\ntest.drop(test[test['weaponsAcquired'] >= 80].index, inplace=True)\n","278f33cd":"test.head()","265c029b":"# import submission data\nsubmission=pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/sample_submission_V2.csv')","f06cf05f":"test1=test","d4f8b729":"test1 = test1[X.columns]","5cc897af":"test1=StandardScaler().fit_transform(test1)\ntest1=pd.DataFrame(test1,columns=X.columns)","aba320ca":"prediction = regressor.predict(test1)","1b72e4c6":"test['winPlacePerc'] = prediction","328cd1e9":"submission['winPlacePerc'] = test['winPlacePerc']","58c7fe62":"submission","d213b4ec":"submission.to_csv('submission.csv',index=False)","6eaec554":"# Test ","22f961e4":"Doing same process and analysis which we do in train to test data set ","32dd3fc7":"# Outlier detection","1fb06110":"# Machine Learning ","12200ab2":"# Feature Engineering","d6efc41a":"# Feature Selection "}}