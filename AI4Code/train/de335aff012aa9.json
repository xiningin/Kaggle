{"cell_type":{"7e542e46":"code","956f61b5":"code","3dfd5143":"code","577ac94f":"code","7cb49a29":"code","fd949c46":"code","e708549b":"code","0ce08c8a":"code","a8bc0e69":"code","154d28f2":"code","f26bde21":"code","f67f1525":"code","18ef593c":"code","c2537ed0":"code","7b8c03bc":"code","7c3276e6":"code","eb868738":"markdown"},"source":{"7e542e46":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","956f61b5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","3dfd5143":"df1 = pd.read_csv(\"\/kaggle\/input\/classifying-liver-disease-patients\/train.csv\")\ndf2 = pd.read_csv(\"\/kaggle\/input\/classifying-liver-disease-patients\/test.csv\")","577ac94f":"print(df1.shape)\ndf1 = df1.dropna(how='any',axis=0) \nprint(df1.shape)\ntemp = df1['GENDER'].map({'Male':1,'Female':0})\ndf1['GENDER'] = temp\n\ntemp = df2['GENDER'].map({'Male':1,'Female':0})\ndf2['GENDER'] = temp","7cb49a29":"df1\ndf2","fd949c46":"x = df1.iloc[:, 1:-1].values\ny = df1.iloc[:, 11:12].values\nz = df2.iloc[:, 1:]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)","e708549b":"print(x)\nprint(y)\nprint(z)\ntype(x)","0ce08c8a":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nxtrain = scaler.fit_transform(x_train) \nxtest = scaler.fit_transform(x_test) \n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics \n\nclf = DecisionTreeClassifier()\n\nclf = clf.fit(xtrain,y_train)\n\ny_pred = clf.predict(xtest)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","a8bc0e69":"from sklearn.linear_model import LogisticRegression \nclassifier = LogisticRegression(random_state = 0) \nclassifier.fit(xtrain, y_train)\n\ny_pred = classifier.predict(xtest)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","154d28f2":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='linear')\nsvclassifier.fit(xtrain, y_train)\ny_pred = svclassifier.predict(xtest)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","f26bde21":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='poly', degree=8)\nsvclassifier.fit(xtrain, y_train)\ny_pred = svclassifier.predict(xtest)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","f67f1525":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='rbf')\nsvclassifier.fit(xtrain, y_train)\n\ny_pred = svclassifier.predict(xtest)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","18ef593c":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='sigmoid')\nsvclassifier.fit(xtrain, y_train)\n\ny_pred = svclassifier.predict(xtest)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","c2537ed0":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=7)\nclassifier.fit(xtrain, y_train)\n\ny_pred = classifier.predict(xtest)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","7b8c03bc":"from sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(n_estimators = 2000, random_state = 0)\n\nrf.fit(xtrain, y_train)\n\ny_pred = rf.predict(xtest)\n\nfrom sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n\nerrors = abs(y_pred - y_test)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n\nmape = 100 * (errors \/ y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","7c3276e6":"xtrain1 = scaler.fit_transform(x)\n\nfrom sklearn.linear_model import LogisticRegression \nclassifier = LogisticRegression(random_state = 0) \nclassifier.fit(xtrain1, y)\n\ny_pred = classifier.predict(z)","eb868738":"I got more accuracy for logistic regression"}}