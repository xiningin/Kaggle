{"cell_type":{"7c90b07a":"code","e5c18047":"code","70619fc5":"code","c8ba99f2":"code","ab43a250":"code","59e82fed":"code","b98987a3":"code","1c2d5fe4":"code","10245d8d":"code","d08b9a69":"code","90a0ff9b":"code","000b09a4":"code","8a904fbb":"code","6de3364b":"code","9926849a":"code","29c98b7b":"markdown","07bfd900":"markdown","21d6a543":"markdown"},"source":{"7c90b07a":"# necessary imports \nimport numpy as np\nimport pandas as pd \nimport re\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.metrics import f1_score","e5c18047":"# Load the data\ndf = pd.read_csv('..\/input\/nlp-getting-started\/train.csv',index_col='id')\ndf.head()","70619fc5":"df.info()","c8ba99f2":"# drop unnecessary cols\ndf.drop(['keyword','location'],axis=1,inplace=True)","ab43a250":"def process_tweet(tweet):\n    stopwords_english = stopwords.words('english')\n    stemmer = PorterStemmer()\n    \n    tweet = re.sub(r'\\$\\w*','',tweet) # remove tickers\n    tweet = re.sub(r'^RT[\\s]+','',tweet) # remove retweet text RT  if any\n    tweet = re.sub(r'https?:\\\/\\\/.*[\\r\\n]*','',tweet) # remove hyperlinks\n    tweet = re.sub(r'#','',tweet) # remove #tag sign\n    \n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n    \n    tokens = tokenizer.tokenize(tweet)\n    \n    tweets_clean = []\n    \n    for word in tokens:\n        if (word not in stopwords_english) and (word not in string.punctuation): # remove punctuation and stopwords\n            stem = stemmer.stem(word) # apply stemming\n            tweets_clean.append(stem)\n\n    return tweets_clean","59e82fed":"def build_freqs(result, tweets, targets):\n    \n    for target, tweet in zip(targets,tweets):\n        for word in process_tweet(tweet):\n            pair = (word,target)\n            result[pair] = result.get(pair,0) + 1\n            \n    return result","b98987a3":"freqs = build_freqs({}, tweets=df['text'].values, targets=df['target'].values)","1c2d5fe4":"def lookup(freqs,word,target):\n    return freqs.get((word,target), 0)","10245d8d":"def train(freqs, x,y):\n    loglikelihood = {}\n    logprior = 0\n    \n    vocab = set([k[0] for k in freqs.keys()])\n    V = len(vocab)\n    \n    N_pos = N_neg = 0\n    for pair in freqs.keys():\n        if pair[1] > 0:\n            N_pos += freqs[pair]\n        else:\n            N_neg += freqs[pair]\n    \n    D = len(y)\n    \n    D_pos = np.sum(y > 0)\n    D_neg = D - D_pos\n    \n    logprior = np.log(D_pos) - np.log(D_neg)\n    \n    for word in vocab:\n        freq_pos = lookup(freqs,word,1)\n        freq_neg = lookup(freqs,word,0)\n        \n        p_w_pos = (freq_pos + 1)\/(N_pos + V)\n        p_w_neg = (freq_neg + 1)\/(N_neg + V)\n        \n        loglikelihood[word] = np.log(p_w_pos \/ p_w_neg)\n        \n    return logprior, loglikelihood\n\nlogprior, loglikelihood = train(freqs,df['text'].values, df['target'].values)","d08b9a69":"def predict(tweet, logprior, loglikelihood):\n    word_l = process_tweet(tweet)\n    \n    p = 0\n    \n    p += logprior\n    \n    for word in word_l:\n        if word in loglikelihood:\n            p += loglikelihood[word]\n    \n    return p","90a0ff9b":"def test(x,y,logprior,loglikelihood):\n    accuracy = 0\n    \n    y_hats = []\n    \n    for tweet in x:\n        if predict(tweet, logprior,loglikelihood) > 0:\n            y_hats_i = 1\n        else:\n            y_hats_i = 0\n            \n        y_hats.append(y_hats_i)\n    \n    error = np.abs(y - y_hats).sum() \/ len(x)\n    \n    accuracy = 1 - error \n\n    return accuracy, f1_score(y,y_hats), y_hats","000b09a4":"# Test on Training Set\naccuracy, f1, preds = test(df['text'].values, df['target'].values, logprior, loglikelihood)","8a904fbb":"print('Accuracy: ',accuracy)\nprint('F1-score: ',f1)","6de3364b":"# load test set\n\ntf = pd.read_csv('..\/input\/nlp-getting-started\/test.csv',index_col='id')\nx = tf['text'].values\ny = np.ones((len(x),1))\n\n_, _, preds = test(x,y,logprior, loglikelihood)\n\nsub = pd.DataFrame({'id': tf.index.values, 'target': preds})\nsub.head()","9926849a":"sub.to_csv('submission.csv',index=False)","29c98b7b":"# Feature Extraction","07bfd900":"# Preprocess tweets","21d6a543":"# Evaluation"}}