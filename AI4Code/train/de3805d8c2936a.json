{"cell_type":{"19026167":"code","923de303":"code","87b3438d":"code","191a700a":"code","8e925bc7":"code","2e41ca54":"code","0b1e654d":"code","8140f761":"code","3be51eb8":"code","736f7d63":"code","8374c938":"code","a2370950":"code","65aa8079":"code","f3ef4448":"code","3a40f6ea":"code","5eee8770":"code","086bd9d6":"code","6f205269":"code","2a32ea7b":"code","d0bb90f5":"code","a2e7774c":"code","9b013c40":"code","e659fe89":"code","a0fed212":"markdown","08cfcca4":"markdown","380cbe68":"markdown","60bd6f68":"markdown","8e4e16f7":"markdown","5861aceb":"markdown","8db0c717":"markdown","14b98061":"markdown","4b3a77e9":"markdown","5afdc165":"markdown"},"source":{"19026167":"!pip install efficientnet tensorflow_addons > \/dev\/null","923de303":"import os\nimport math\nimport random\nimport re\nimport warnings\nfrom pathlib import Path\nfrom typing import Optional, Tuple\n\nimport efficientnet.tfkeras as efn\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools","87b3438d":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","191a700a":"Y_train = train[\"label\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\n# free some space\ndel train \n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()","8e925bc7":"X_train.isnull().any().describe()","2e41ca54":"test.isnull().any().describe()","0b1e654d":"X_train = X_train \/ 255.0\ntest = test \/ 255.0","8140f761":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","3be51eb8":"Y_train = tf.keras.utils.to_categorical(Y_train, num_classes = 10)","736f7d63":"X_train = X_train.repeat(2, axis=1).repeat(2, axis=2)\ntest = test.repeat(2, axis=1).repeat(2, axis=2)","8374c938":"# This data is used for random forests, etc.\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=0)","a2370950":"plt.imshow(X_train[3])","65aa8079":"efficientnet_size = 7\nweights = \"imagenet\"\nsize = 56","f3ef4448":"model = tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Conv2D(filters = 3, kernel_size = 1, padding = 'Same', \n                 activation ='relu', input_shape = (size,size,1)))\n\nmodel.add(getattr(efn, f\"EfficientNetB{efficientnet_size}\")(\n        weights=weights, include_top=False, input_shape=(size, size, 3)))\n\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\n# model.add(tf.keras.layers.MaxPool2D())\n\nmodel.add(tf.keras.layers.Flatten())\n# model.add(tf.keras.layers.Dense(512, name=\"dense_before_arcface\", kernel_initializer=\"he_normal\"))\n\nmodel.add(tf.keras.layers.Dense(10, activation = \"softmax\"))","3a40f6ea":"# Define the optimizer\noptimizer = tf.keras.optimizers.Adam(lr=0.0001)","5eee8770":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","086bd9d6":"model.summary()","6f205269":"tf.random.set_seed(0)\n\nhistory = model.fit(X_train,\n                    Y_train,\n                    epochs=10,\n                    batch_size=128,\n                    validation_data=(X_val, Y_val),\n                   )","2a32ea7b":"def plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.plot(hist['epoch'], hist['accuracy'],\n           label='Train Accuracy')\n  plt.plot(hist['epoch'], hist['val_accuracy'],\n           label = 'Val Accuracy')\n  plt.ylim([0.9,1.0])\n  plt.legend()\n  plt.show()\n    \n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.plot(hist['epoch'], hist['loss'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_loss'],\n           label = 'Val Error')\n  plt.ylim([0.0,0.1])\n  plt.legend()\n  plt.show()\n\n\nplot_history(history)","d0bb90f5":"pred = model.predict_classes(test)","a2e7774c":"submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")","9b013c40":"submission[\"Label\"] = pred","e659fe89":"submission.to_csv(\"submission.csv\",index=False)","a0fed212":"# Check for null and missing values","08cfcca4":"# Resize","380cbe68":"# Split training and valdiation","60bd6f68":"# EfficientNetB7","8e4e16f7":"# Normalization","5861aceb":"# Prediction","8db0c717":"# To Categorical","14b98061":"# Data preparation","4b3a77e9":"# Training","5afdc165":"# Reshape"}}