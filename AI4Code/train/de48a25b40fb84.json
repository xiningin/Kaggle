{"cell_type":{"e74d615e":"code","4d6af50e":"code","a3bc9646":"code","8dd67e1a":"code","62f0cd24":"code","aea17c4c":"code","93b2f5ae":"code","346755fc":"code","d4109abb":"code","df6dc82d":"code","5611db43":"code","7b529198":"markdown","fe76943c":"markdown","694c8e21":"markdown","bda9eefb":"markdown","25c8c971":"markdown","9da835be":"markdown","5acfd966":"markdown","b2081005":"markdown"},"source":{"e74d615e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4d6af50e":"base = pd.read_csv('..\/input\/kc_house_data.csv')\nbase.head()","a3bc9646":"X = base.iloc[:,[3,4,5,6,7,11,12,13,14,17,18]]\nX.head()","8dd67e1a":"y = base.iloc[:,2]\ny.head()","62f0cd24":"X = X.values\ny = y.values.reshape(-1,1)","aea17c4c":"from sklearn.preprocessing import StandardScaler\nscaler_X = StandardScaler()\nX = scaler_X.fit_transform(X)\nscaler_y = StandardScaler()\ny = scaler_y.fit_transform(y)","93b2f5ae":"from sklearn.model_selection import train_test_split\nX_treinamento, X_teste, y_treinamento, y_teste = \\\ntrain_test_split(X, y, test_size=.2, random_state=0)","346755fc":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import mean_absolute_error","d4109abb":"dic_loss = {}\nlr_ = []\nmae_ = []\n\nlr_list = [.000001,.000005,.00001,.00005,.0001,.0005,.001,.005,.01,.05]\ncount = 0\n\nfor lr in lr_list:\n    \n    print('lr =',lr)\n    count += 1\n    print(str(count)+'\/'+str(len(lr_list)))\n\n    opt = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n    \n    model = Sequential()\n    model.add(Dense(6, input_dim=11, activation='relu'))\n    model.add(Dense(6, activation='relu'))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mse', optimizer=opt, metrics=['mse','mae'])\n    history = model.fit(X_treinamento, y_treinamento, epochs=100, verbose=0, batch_size=25)\n    \n    previsoes = model.predict(X_teste)\n\n    previsoes = scaler_y.inverse_transform(previsoes)\n    #y_teste = scaler_y.inverse_transform(y_teste)\n\n    mae = mean_absolute_error(scaler_y.inverse_transform(y_teste), previsoes)\n    \n    dic_loss[str(lr)] = history.history['loss']\n    lr_.append(lr)\n    mae_.append(mae)","df6dc82d":"import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [15, 10]\n\ndf = pd.DataFrame(dic_loss)\ndf.plot().grid()","5611db43":"plt.semilogx(lr_, mae_)","7b529198":"As can be seen, **lr=0.001** is a good value for this problem, since the conversion is fast and the **MAE** is low.","fe76943c":"## Scale the data","694c8e21":"## Plotting loss values and the MAE for each learning rate","bda9eefb":"## Read the dataset","25c8c971":"## Split the dataset into training and testing","9da835be":"## Import modules","5acfd966":"## Build the network and fit the model in a loop with diferent learning rates\nLoss function values are stored in a dictionary for later plotting. MAEis also calculated with the testing dataset for each iteration.","b2081005":"## Turn into numpy arrays"}}