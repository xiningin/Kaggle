{"cell_type":{"406cd341":"code","824cea82":"code","67131465":"code","1d721c6f":"code","f3c0012d":"code","9908a3f6":"code","fc080a6b":"code","8f36720d":"code","30d7d6a4":"code","0cc0d062":"code","81d85a7c":"code","4ad66b91":"code","84433354":"code","c50326b5":"code","f342f72d":"code","ce9c6235":"code","d105e561":"code","98d03da2":"markdown","31def7ac":"markdown","246b2263":"markdown","72476ee0":"markdown","405a3dee":"markdown","29c436bf":"markdown","e0ca757c":"markdown","f9a73623":"markdown","750258d0":"markdown","c9b5ade3":"markdown","9e6c5539":"markdown","d432e258":"markdown"},"source":{"406cd341":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","824cea82":"real = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/True.csv\")\nfake = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/Fake.csv\")","67131465":"real.head()","1d721c6f":"fake.head()","f3c0012d":"real['label'] = 1\nfake['label'] = 0\ndata = pd.concat([real, fake])","9908a3f6":"import seaborn as sns\nsns.set_style(\"darkgrid\")\nsns.countplot(data['label']);","fc080a6b":"data.isnull().sum()","8f36720d":"data.columns","30d7d6a4":"import matplotlib.pyplot as plt\ndata['subject'].value_counts()\nplt.figure(figsize = (10,10))\nsns.set_style(\"darkgrid\")\nsns.countplot(data['subject']);","0cc0d062":"plt.figure(figsize = (10,10))\nsns.set_style(\"dark\")\nchart = sns.countplot(x = \"label\", hue = \"subject\" , data = data , palette = 'muted')\nchart.set_xticklabels(chart.get_xticklabels(),rotation=90)","81d85a7c":"data['text'] = data['title'] + \" \" + data['text']\ndata = data.drop(['title', 'subject', 'date'], axis=1)","4ad66b91":"from nltk.corpus import stopwords\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords.words('english'), \n                min_font_size = 10).generate(\" \".join(data[data['label'] == 0].text)) \n  \n# plot the word cloud for fake news data                      \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.show() ","84433354":"from wordcloud import WordCloud\n\nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords.words('english'), \n                min_font_size = 10).generate(\" \".join(data[data['label'] == 1].text)) \n  \n# plot the WordCloud image for genuine news data                     \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.show() ","c50326b5":"#splitting data for training and testing\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(data['text'],data['label'],test_size=0.2, random_state = 1)","f342f72d":"#Multinomial NB\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nimport sklearn.metrics as metrics                                                 \nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\n\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', MultinomialNB())\n])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n\nscore = metrics.accuracy_score(y_test, prediction)\nprint(\"accuracy:   %0.3f\" % (score*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\n\n\n\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()\n\n","ce9c6235":"#SVM\nfrom sklearn.svm import LinearSVC\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', LinearSVC())\n])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n\nscore = metrics.accuracy_score(y_test, prediction)\nprint(\"accuracy:   %0.3f\" % (score*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\n\n\n\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()\n","d105e561":"#Passive Aggressive Classifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\npipe = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf',  PassiveAggressiveClassifier())\n])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n\nscore = metrics.accuracy_score(y_test, prediction)\nprint(\"accuracy:   %0.3f\" % (score*100))\ncm = metrics.confusion_matrix(y_test, prediction, labels=[0,1])\n\n\n\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, prediction),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()","98d03da2":"There are no null values.","31def7ac":"# Classification","246b2263":"# Analyzing data","72476ee0":"It is clear from the graph that all the genuine news belong to two subjects of political news and world news. Why?","405a3dee":"It is clear from the plot that our **data is balanced**.","29c436bf":"We have to split the data and try different classification methods. We will try Naive Bayes, SVM and passive aggessive classifiers. ","e0ca757c":"There are lot of real and fake news about 'Donald Trump'.","f9a73623":"# Word clouds","750258d0":"References\n\n* https:\/\/www.youtube.com\/watch?v=xyq-zYr1cnI     \n* https:\/\/www.kaggle.com\/madz2000\/nlp-using-glove-embeddings-99-8-accuracy\n* https:\/\/www.datacamp.com\/community\/tutorials\/scikit-learn-fake-news","c9b5ade3":"Making a new column named 'label' which specifies whether the news is fake or not.","9e6c5539":"This is a beginner friendly notebook that classifies the data using few models and evaluates the performance. If you are an absolute beginner, this [article](http:\/\/medium.com\/@joyceannie111\/fake-news-detection-using-nlp-techniques-c2dc4be05f99) would explain the concepts in more detail.","d432e258":"According to our analysis, SVM and passive aggressive classifier have similar performance."}}