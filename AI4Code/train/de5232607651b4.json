{"cell_type":{"6aa40671":"code","a16203e4":"code","79f9f08e":"code","2be28892":"code","e544b71b":"code","6916f65e":"code","a964169f":"code","13d49452":"code","87a58fda":"code","47db3c89":"code","fe75e697":"code","04277245":"code","92f57f61":"code","1ef16e92":"code","acb6d22a":"code","e0ceed1c":"code","65cbbe3f":"code","c0c04631":"code","b32f1ecb":"code","643a77fe":"code","0148bb3d":"code","0a8af8e5":"code","348b5c9d":"code","56bf668b":"code","2c1fa4fc":"code","7e42bbc0":"code","7b99d8d1":"code","2267266b":"code","cc540953":"code","4c38261c":"code","6c463d2f":"code","b534a65c":"code","64ef72f2":"code","01b3ba99":"code","f4fbde54":"code","0c6ad772":"code","a73cd22c":"code","37d98448":"code","a79a7954":"code","405392ec":"code","8cf132f9":"code","7cabe7fb":"code","f9da57fd":"code","467904b9":"code","03844ca0":"code","2fd5d936":"code","eded188f":"code","b8d003b5":"code","1c254f3b":"code","c93aeffe":"code","1a2e4a47":"code","ef83c0cf":"code","83023517":"code","7ef5d5e1":"code","54de9eba":"code","e20b718c":"code","fcb12047":"code","cb79be98":"code","5afbcab7":"code","3198693d":"code","fc611bb2":"code","d3b83851":"code","5e70f822":"code","4dd803db":"code","b5a97c01":"code","ebc620d7":"code","fe8870c9":"code","115212a1":"code","9065df39":"code","c66f7ce0":"code","20f13d14":"code","c9fda8a3":"code","93c98a16":"code","1b681e25":"code","2caffd92":"code","852cc656":"code","4de0d26f":"markdown","c7001997":"markdown","dc01c865":"markdown","f85e8aa3":"markdown","3cd123ac":"markdown","1905b563":"markdown","9cec0dbe":"markdown","b52c9388":"markdown","d887d060":"markdown","5d66c68f":"markdown","b3ac7ff1":"markdown","3adebe73":"markdown","59a01e14":"markdown","8c044b70":"markdown","0c9526a3":"markdown","2a5c1d7a":"markdown","e1d26347":"markdown","eb3f4b5d":"markdown","8f431d98":"markdown","b91c5782":"markdown","2ba6efd4":"markdown","d74d8342":"markdown","cc52b637":"markdown","2153be3d":"markdown","986cc2d1":"markdown","25fad201":"markdown","ca2a0d8d":"markdown","5ac6fec2":"markdown","83a94c54":"markdown","4a0a0e3e":"markdown"},"source":{"6aa40671":"# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","a16203e4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","79f9f08e":"# Importing Pandas and NumPy\nimport pandas as pd, numpy as np, seaborn as sns,matplotlib.pyplot as plt","2be28892":"pd.set_option('display.max_columns', None)","e544b71b":"# Importing all datasets\nchurn_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/churn_data.csv\")\nchurn_data.head()","6916f65e":"customer_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/customer_data.csv\")\ncustomer_data.head()","a964169f":"internet_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/internet_data.csv\")\ninternet_data.head()","13d49452":"# Merging on 'customerID'\ndf_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')","87a58fda":"# Final dataframe with all predictor variables\ntelecom = pd.merge(df_1, internet_data, how='inner', on='customerID')","47db3c89":"# Let's see the head of our master dataset\ntelecom.head()","fe75e697":"# Let's check the dimensions of the dataframe\ntelecom.shape","04277245":"# let's look at the statistical aspects of the dataframe\ntelecom.describe()","92f57f61":"# Let's see the type of each column\ntelecom.info()","1ef16e92":"#The varaible was imported as a string we need to convert it to float\n# telecom['TotalCharges'] = telecom['TotalCharges'].astype(float) \ntelecom.TotalCharges = pd.to_numeric(telecom.TotalCharges, errors='coerce')","acb6d22a":"telecom.info()","e0ceed1c":"\nplt.figure(figsize=(20,40))\nplt.subplot(10,2,1)\nax = sns.distplot(telecom['tenure'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('Tenure (months)')\nplt.subplot(10,2,2)\nax = sns.countplot(x='PhoneService', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,3)\nax =sns.countplot(x='Contract', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,3)\nax =sns.countplot(x='Contract', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,4)\nax =sns.countplot(x='PaperlessBilling', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,5)\nax =sns.countplot(x='PaymentMethod', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,6)\nax =sns.countplot(x='Churn', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,7)\nax =sns.countplot(x='gender', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,8)\nax =sns.countplot(x='SeniorCitizen', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,9)\nax =sns.countplot(x='Partner', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,10)\nax =sns.countplot(x='Dependents', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,11)\nax =sns.countplot(x='MultipleLines', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,12)\nax =sns.countplot(x='InternetService', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,13)\nax =sns.countplot(x='OnlineSecurity', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,14)\nax =sns.countplot(x='OnlineBackup', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,15)\nax =sns.countplot(x='DeviceProtection', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,16)\nax =sns.countplot(x='TechSupport', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,17)\nax =sns.countplot(x='StreamingTV', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,18)\nax =sns.countplot(x='StreamingMovies', data=telecom)\nax.set_ylabel('# of Customers')\nplt.subplot(10,2,19)\nax = sns.distplot(telecom['MonthlyCharges'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('MonthlyCharges')\nplt.subplot(10,2,20)\nax = sns.distplot(telecom['TotalCharges'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('TotalCharges');","65cbbe3f":"sns.pairplot(telecom)\nplt.show()","c0c04631":"plt.figure(figsize=(25, 10))\nplt.subplot(1,3,1)\nsns.boxplot(x = 'tenure', y = 'Churn', data=telecom)\nplt.subplot(1,3,2)\nsns.boxplot(x = 'MonthlyCharges', y = 'Churn', data=telecom)\nplt.subplot(1,3,3)\nsns.boxplot(x = 'TotalCharges', y = 'Churn', data=telecom)\nplt.show()","b32f1ecb":"# List of variables to map\n\nvarlist =  ['PhoneService', 'PaperlessBilling', 'Churn', 'Partner', 'Dependents']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the housing list\ntelecom[varlist] = telecom[varlist].apply(binary_map)","643a77fe":"telecom.head()","0148bb3d":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(telecom[['Contract', 'PaymentMethod', 'gender', 'InternetService']], drop_first=True)\n\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom, dummy1], axis=1)","0a8af8e5":"telecom.head()","348b5c9d":"# Creating dummy variables for the remaining categorical variables and dropping the level with big names.\n\n# Creating dummy variables for the variable 'MultipleLines'\nml = pd.get_dummies(telecom['MultipleLines'], prefix='MultipleLines')\n# Dropping MultipleLines_No phone service column\nml1 = ml.drop(['MultipleLines_No phone service'], 1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ml1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineSecurity'.\nos = pd.get_dummies(telecom['OnlineSecurity'], prefix='OnlineSecurity')\nos1 = os.drop(['OnlineSecurity_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,os1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineBackup'.\nob = pd.get_dummies(telecom['OnlineBackup'], prefix='OnlineBackup')\nob1 = ob.drop(['OnlineBackup_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ob1], axis=1)\n\n# Creating dummy variables for the variable 'DeviceProtection'. \ndp = pd.get_dummies(telecom['DeviceProtection'], prefix='DeviceProtection')\ndp1 = dp.drop(['DeviceProtection_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,dp1], axis=1)\n\n# Creating dummy variables for the variable 'TechSupport'. \nts = pd.get_dummies(telecom['TechSupport'], prefix='TechSupport')\nts1 = ts.drop(['TechSupport_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ts1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingTV'.\nst =pd.get_dummies(telecom['StreamingTV'], prefix='StreamingTV')\nst1 = st.drop(['StreamingTV_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,st1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingMovies'. \nsm = pd.get_dummies(telecom['StreamingMovies'], prefix='StreamingMovies')\nsm1 = sm.drop(['StreamingMovies_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,sm1], axis=1)","56bf668b":"telecom.head()","2c1fa4fc":"# We have created dummies for the below variables, so we can drop them\ntelecom = telecom.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)","7e42bbc0":"# Checking for outliers in the continuous variables\nnum_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]","7b99d8d1":"# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\nnum_telecom.describe(percentiles=[.25, .5, .75, .90, .95, .99])","2267266b":"# Adding up the missing values (column-wise)\ntelecom.isnull().sum()","cc540953":"print('No. of Null Records for TotalCharges:',telecom.TotalCharges.isnull().sum())","4c38261c":"print('No. of Records for TotalCharges:',len(telecom))","6c463d2f":"print('No. of non Records for TotalCharges:',len(telecom)-telecom.TotalCharges.isnull().sum())","b534a65c":"# Checking the percentage of missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","64ef72f2":"telecom = telecom.dropna()\ntelecom = telecom.reset_index(drop=True)\n\n","01b3ba99":"# Checking percentage of missing values after removing the missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","f4fbde54":"from sklearn.model_selection import train_test_split","0c6ad772":"# Putting feature variable to X\nX = telecom.drop(['Churn','customerID'], axis=1)\n\nX.head()","a73cd22c":"# Putting response variable to y\ny = telecom['Churn']\n\ny.head()","37d98448":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","a79a7954":"from sklearn.preprocessing import StandardScaler","405392ec":"scaler = StandardScaler()\n\nX_train[['tenure','MonthlyCharges','TotalCharges']] = scaler.fit_transform(X_train[['tenure','MonthlyCharges','TotalCharges']])\n\nX_train.head()","8cf132f9":"X_test[['tenure','MonthlyCharges','TotalCharges']] = scaler.transform(X_test[['tenure','MonthlyCharges','TotalCharges']])\n\nX_test.head()","7cabe7fb":"### Checking the Churn Rate\nchurn = (sum(telecom['Churn'])\/len(telecom['Churn'].index))*100\nchurn","f9da57fd":"# Importing matplotlib and seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","467904b9":"# Let's see the correlation matrix \nplt.figure(figsize = (25,25))        # Size of the figure\nsns.heatmap(telecom.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","03844ca0":"plt.figure(figsize=(10,8))\ntelecom.corr()['Churn'].sort_values(ascending = False).plot(kind='bar');","2fd5d936":"X_test = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n                       'StreamingTV_No','StreamingMovies_No'], 1)\nX_train = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n                         'StreamingTV_No','StreamingMovies_No'], 1)","eded188f":"plt.figure(figsize = (25,25))\nsns.heatmap(X_train.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","b8d003b5":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nmodel = XGBClassifier()\n","1c254f3b":"# fit the model with the training data\nmodel.fit(X_train,y_train)","c93aeffe":"# predict the target on the train dataset\npredict_train = model.predict(X_train)\npredict_train","1a2e4a47":"trainaccuracy = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', trainaccuracy)","ef83c0cf":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif.tail()","83023517":"features_to_remove = vif.loc[vif['VIF'] >= 4.99,'Features'].values\nfeatures_to_remove = list(features_to_remove)\nprint(features_to_remove)","7ef5d5e1":"X_train = X_train.drop(columns=features_to_remove, axis = 1)\nX_train.head()","54de9eba":"X_test = X_test.drop(columns=features_to_remove, axis = 1)\nX_test.head()","e20b718c":"# fit the model with the training data\nmodel.fit(X_train,y_train)","fcb12047":"# predict the target on the train dataset\npredict_train = model.predict(X_train)\npredict_train","cb79be98":"trainaccuracy = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', trainaccuracy)","5afbcab7":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","3198693d":"from sklearn import metrics\n# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train, predict_train )\nprint(confusion)\n","fc611bb2":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","d3b83851":"# Let's see the sensitivity of our model\ntrainsensitivity= TP \/ float(TP+FN)\ntrainsensitivity","5e70f822":"# Let us calculate specificity\ntrainspecificity= TN \/ float(TN+FP)\ntrainspecificity","4dd803db":"# Calculate false postive rate - predicting churn when customer does not have churned\nprint(FP\/ float(TN+FP))","b5a97c01":"# Positive predictive value \nprint (TP \/ float(TP+FP))","ebc620d7":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","fe8870c9":"draw_roc(y_train,predict_train)","115212a1":"#Looking at the confusion matrix again","9065df39":"from sklearn.metrics import precision_score, recall_score\nprecision_score(y_train,predict_train)","c66f7ce0":"recall_score(y_train,predict_train)","20f13d14":"# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data\\n\\n',predict_test)","c9fda8a3":"confusion2 = metrics.confusion_matrix(y_test, predict_test )\nprint(confusion2)","93c98a16":"# Let's check the overall accuracy.\ntestaccuracy= accuracy_score(y_test,predict_test)\ntestaccuracy","1b681e25":"# Let's see the sensitivity of our lmodel\ntestsensitivity=TP \/ float(TP+FN)\ntestsensitivity","2caffd92":"# Let us calculate specificity\ntestspecificity= TN \/ float(TN+FP)\ntestspecificity","852cc656":"# Let us compare the values obtained for Train & Test:\nprint(\"Train Data Accuracy    :{} %\".format(round((trainaccuracy*100),2)))\nprint(\"Train Data Sensitivity :{} %\".format(round((trainsensitivity*100),2)))\nprint(\"Train Data Specificity :{} %\".format(round((trainspecificity*100),2)))\nprint(\"Test Data Accuracy     :{} %\".format(round((testaccuracy*100),2)))\nprint(\"Test Data Sensitivity  :{} %\".format(round((testsensitivity*100),2)))\nprint(\"Test Data Specificity  :{} %\".format(round((testspecificity*100),2)))","4de0d26f":"# VIF","c7001997":"#### Dropping the repeated variables","dc01c865":"#### Checking the Correlation Matrix","f85e8aa3":"# VIF","3cd123ac":"Now we don't have any missing values","1905b563":"#### Dropping highly correlated dummy variables","9cec0dbe":"#### Converting some binary variables (Yes\/No) to 0\/1","b52c9388":"# XGBClassifier","d887d060":"#### Combining all data files into one consolidated dataframe","5d66c68f":"### Step 6: Looking at Correlations","b3ac7ff1":"### Step 4: Test-Train Split","3adebe73":"# Plotting the ROC Curve","59a01e14":"The XGBoost has an immensely high predictive power which makes it the best choice for accuracy in events as it possesses both linear model and the tree learning algorithm, making the algorithm almost 10x faster than existing gradient booster techniques.\n\nThe support includes various objective functions, including regression, classification and ranking.","8c044b70":"# EDA","0c9526a3":"## Telecom Churn Case Study\nWith 21 predictor variables we need to predict whether a particular customer will switch to another telecom provider or not. In telecom terminology, this is referred to as churning and not churning, respectively.","2a5c1d7a":"### Step 11: Making predictions on the test set","e1d26347":"After dropping highly correlated variables now let's check the correlation matrix again.","eb3f4b5d":"#### For categorical variables with multiple levels, create dummy features (one-hot encoded)","8f431d98":"### Step 2: Inspecting the Dataframe","b91c5782":"It means that 11 * 100\/7043 = 0.1561834%, best is to remove these observations from the analysis","2ba6efd4":"### Step 5: Feature Scaling","d74d8342":"We have almost 27% churn rate","cc52b637":"# Final Observation:","2153be3d":"#### Checking for Outliers","986cc2d1":"### Step 7: Model Building\nLet's start by splitting our data into a training set and a test set.","25fad201":"## Precision and Recall","ca2a0d8d":"#### Checking for Missing Values and Inputing Them","5ac6fec2":"Now you can see that you have all variables as numeric.","83a94c54":"From the distribution shown above, you can see that there no outliers in your data. The numbers are gradually increasing.","4a0a0e3e":"### Step 1: Importing and Merging Data"}}