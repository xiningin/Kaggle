{"cell_type":{"332083b4":"code","27683904":"code","7db8477f":"code","4166b18c":"code","148267df":"code","37451d3e":"code","c8a2d22a":"code","3fe5efab":"code","cabcc113":"code","e4815edd":"code","0b2afc6d":"code","bd487c68":"code","3ceccb4f":"code","05b4f915":"code","14aaf789":"code","7ca3a2f2":"code","b68088c3":"code","dbf963bb":"code","0a6b9099":"code","77625523":"code","7b880c44":"code","f6f78ca4":"code","f77f9ee6":"code","3f4305d3":"code","c77d31e9":"code","1ad07571":"code","3ac8696f":"code","61388913":"code","8aa61097":"code","90a81cf8":"code","e36ff734":"code","6fa7ed31":"code","050532b5":"code","72e9d02c":"code","de743d32":"code","ca0ea995":"code","8b195776":"markdown","b6492482":"markdown","03809ead":"markdown","707a5bca":"markdown","163e5db2":"markdown","78b7362b":"markdown","e5b5d0d7":"markdown","e6e70721":"markdown","aa489f7b":"markdown","773c34a8":"markdown","b2a5c04d":"markdown","203d0458":"markdown","b433a767":"markdown","94ceabb8":"markdown","5240a837":"markdown"},"source":{"332083b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport seaborn as sns\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image, ImageDraw, ImageFont\nimport tensorflow as tf","27683904":"tf.enable_eager_execution()","7db8477f":"train_df = pd.read_csv('..\/input\/train.csv')","4166b18c":"train_df.head()","148267df":"print('Total records of datatframe: ', len(train_df))","37451d3e":"print('Distinct image id:', len(train_df['image_id'].unique()))","c8a2d22a":"fontsize = 50\n\n# From https:\/\/www.google.com\/get\/noto\/\n!wget -q --show-progress https:\/\/noto-website-2.storage.googleapis.com\/pkgs\/NotoSansCJKjp-hinted.zip\n!unzip -p NotoSansCJKjp-hinted.zip NotoSansCJKjp-Regular.otf > NotoSansCJKjp-Regular.otf\n!rm NotoSansCJKjp-hinted.zip\n\nfont = ImageFont.truetype('.\/NotoSansCJKjp-Regular.otf', fontsize, encoding='utf-8')","3fe5efab":"unicode_map = {codepoint: char for codepoint, char in pd.read_csv('..\/input\/unicode_translation.csv').values}","cabcc113":"print('Total unicode character provided:', len(unicode_map))","e4815edd":"def map_name_to_image(image_name):\n    img_raw = tf.io.read_file(tf.strings.join(['..\/input\/train_images\/', image_name, '.jpg']))\n    image = tf.image.decode_jpeg(img_raw)\n    return image","0b2afc6d":"def map_image_to_width_height(image):\n    return tf.shape(image)","bd487c68":"name_ds = tf.data.Dataset.from_tensor_slices(train_df['image_id'])\nimage_ds = name_ds.map(map_name_to_image)\nimage_width_height = image_ds.map(map_image_to_width_height)","3ceccb4f":"for img in image_ds:\n    print(img.shape)\n    break","05b4f915":"widths = []\nheights = []\nfor width, height, channel in image_width_height:\n    widths.append(width.numpy())\n    heights.append(height.numpy())","14aaf789":"# Assign width and height to each image in dataframe\ntrain_df['width'] = pd.Series(widths)\ntrain_df['height'] = pd.Series(heights)","7ca3a2f2":"train_df.head()","b68088c3":"sum(train_df['width']==train_df['height'])","dbf963bb":"# This function takes in a filename of an image, and the labels in the string format given in train.csv, and returns an image containing the bounding boxes and characters annotated\ndef visualize_training_data(image_fn, labels):\n    # Read image\n    imsource = Image.open(image_fn).convert('RGBA')\n    bbox_canvas = Image.new('RGBA', imsource.size)\n    char_canvas = Image.new('RGBA', imsource.size)\n    \n    # Convert annotation string to array\n    if(labels is not np.nan):\n        labels = np.array(labels.split(' ')).reshape(-1, 5)\n        bbox_draw = ImageDraw.Draw(bbox_canvas) # Separate canvases for boxes and chars so a box doesn't cut off a character\n        char_draw = ImageDraw.Draw(char_canvas)\n\n        for codepoint, x, y, w, h in labels:\n            x, y, w, h = int(x), int(y), int(w), int(h)\n            char = unicode_map[codepoint] # Convert codepoint to actual unicode character\n\n            # Draw bounding box around character, and unicode character next to it\n            bbox_draw.rectangle((x, y, x+w, y+h), fill=(255, 255, 255, 0), outline=(255, 0, 0, 255))\n            char_draw.text((x + w + fontsize\/4, y + h\/2 - fontsize), char, fill=(0, 0, 255, 255), font=font)\n\n        imsource = Image.alpha_composite(Image.alpha_composite(imsource, bbox_canvas), char_canvas)\n    imsource = imsource.convert(\"RGB\") # Remove alpha for saving in jpg format.\n    return np.asarray(imsource)","0a6b9099":"# plot some image\nnp.random.seed(1337)\n\nfor i in range(10):\n    img, labels, w, h = train_df.values[np.random.randint(len(train_df))]\n    viz = visualize_training_data('..\/input\/train_images\/{}.jpg'.format(img), labels)\n    \n    plt.figure(figsize=(15, 15))\n    plt.title(img)\n    plt.imshow(viz, interpolation='lanczos')\n    plt.show()","77625523":"train_df['aspect_ratio'] = train_df['width'] \/ train_df['height']","7b880c44":"train_df.describe()","f6f78ca4":"plt.hist(train_df['width'])\nplt.show()","f77f9ee6":"plt.hist(train_df['height'])\nplt.show()","3f4305d3":"print('Number of image having NaN label:', sum(train_df['labels'].isna()))","c77d31e9":"np.random.seed(2444)\n\nNaN_train_df = train_df[train_df['labels'].isna()]\n\nfor i in range(10):\n    img, labels, w, h, ar = NaN_train_df.values[np.random.randint(len(NaN_train_df))]\n    viz = visualize_training_data('..\/input\/train_images\/{}.jpg'.format(img), labels)\n    \n    plt.figure(figsize=(15, 15))\n    plt.title(img)\n    plt.imshow(viz, interpolation='lanczos')\n    plt.show()","1ad07571":"NaN_train_df.head()","3ac8696f":"def count_codepoint_freq(labels):\n    labels = np.array(labels.split(' ')).reshape(-1, 5)\n    code_point = pd.Series(labels[:, 0])\n    return code_point.value_counts(sort=False)\n","61388913":"labels_series = train_df['labels']\nall_labels = labels_series.str.cat(sep=' ')\nlabel_counts = count_codepoint_freq(all_labels)","8aa61097":"print('Number of valid characters in all images: ', len(all_labels))","90a81cf8":"print('Number codepoint appearing in training set: %d, compared to total codepoints in dict: %d'%(len(label_counts), len(unicode_map)))","e36ff734":"plt.figure(figsize=(30, 5))\nsns.barplot(label_counts.index[:20], label_counts.values[:20])","6fa7ed31":"print('Codepoint that has the most appearance:', np.argmax(label_counts), ' with freq = ', np.max(label_counts))","050532b5":"print('Codepoint that has the least appearance:', np.argmin(label_counts), ' with freq = ', np.min(label_counts))","72e9d02c":"label_counts.describe()","de743d32":"plt.hist(label_counts.values, bins=100)\nplt.show()","ca0ea995":"train_df.to_csv('train_df_plus.csv', index=False)","8b195776":"## 2.1. Image height and width:","b6492482":"- We can see that the counts of each code points varies so much compared to each other\n- Below we will see the distribution and histogram of the **value count** of codepoints","03809ead":"## 2.2. Image labels:\n- First, we are gonna look at some NaN labeled image\n- Then, we will see the distribution of labels (characters) over all training set","707a5bca":"- This visualizing code is used from https:\/\/www.kaggle.com\/anokas\/kuzushiji-visualisation","163e5db2":"### 2.2.1. NaN Label:","78b7362b":"- Distribution of 10 different code point in training set","e5b5d0d7":"### 2.2.2. Distribution of labels","e6e70721":"## 1.1. Load training data:","aa489f7b":"- Width and height are not too unequal","773c34a8":"## 1.2. Load unicode translation:\n- Firstly, you have to download the Japanese font\n- This code is used from https:\/\/www.kaggle.com\/anokas\/kuzushiji-visualisation","b2a5c04d":"- So the number of unique image in dataframe is also the number of records, which means each image has 1 label row","203d0458":"- Read the data into tensorflow Dataset","b433a767":"- We can see that the mean of characters appearing in training set is 162","94ceabb8":"# 2. Quick EDA","5240a837":"# 1. Load data:"}}