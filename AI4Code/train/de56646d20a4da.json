{"cell_type":{"6bf9edd6":"code","6ca98e84":"code","5be81a50":"code","d820475f":"code","cfdf4295":"code","a8103903":"code","c5bf43ff":"code","16d90c96":"code","3f7b158d":"code","668b6c63":"code","d130c454":"code","6b64995b":"code","e01121d1":"code","992b6f40":"code","28c4e556":"code","d036a7ee":"code","fd472f57":"code","9a13276b":"code","f832cb53":"code","8e9420e2":"code","e828383f":"code","a85aa5a1":"code","d203fe79":"code","1b6d98c5":"code","476d8379":"code","a6589eee":"code","89a9d219":"code","3b00b6fe":"markdown","bd5d2b33":"markdown","6c870230":"markdown","3c7e21a8":"markdown","049e67b8":"markdown","c0a783aa":"markdown","7cdea47c":"markdown","836f83d5":"markdown"},"source":{"6bf9edd6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6ca98e84":"!pip install git+https:\/\/gitlab.com\/nyker510\/vivid","5be81a50":"INPUT_DIR = '\/kaggle\/input\/titanic\/'\ntrain_df = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n\ny = train_df.pop('Survived')","d820475f":"import re\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nfrom vivid.featureset import AbstractAtom\nfrom vivid.featureset.molecules import create_molecule, MoleculeFeature","cfdf4295":"def get_title(name):\n    if re.search(' ([A-Za-z]+)\\.', name):\n        return re.search(' ([A-Za-z]+)\\.', name).group(1)\n    return \"\"\n\nclass TitanicBasicAtom(AbstractAtom):\n    def call(self, input_df, y=None):\n        output_df = input_df.copy()\n        output_df['Cabin'] = output_df['Cabin'].apply(lambda x: 1 if type(x) == str else 0)\n\n        output_df['Age'] = output_df['Age'].fillna(-1).astype(int)\n\n        output_df['Fare'] = output_df['Fare'].fillna(-1).astype(int)\n\n        output_df['Sex'] = output_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n        output_df['Title'] = output_df['Name'].apply(get_title)\n        output_df['Title'] = output_df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n        output_df['Title'] = output_df['Title'].replace('Mlle', 'Miss')\n        output_df['Title'] = output_df['Title'].replace('Ms', 'Miss')\n        output_df['Title'] = output_df['Title'].replace('Mme', 'Mrs')\n        title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n        output_df['Title'] = output_df['Title'].map(title_mapping)\n        output_df['Title'] = output_df['Title'].fillna(-1)\n\n        output_df['Embarked'] = output_df['Embarked'].fillna('S')\n        output_df['Embarked'] = output_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n        output_df.drop(['PassengerId', 'Ticket', 'Name'], axis=1, inplace=True)\n\n        return output_df","a8103903":"TitanicBasicAtom().generate(train_df, y)","c5bf43ff":"# create new molecule\nbasic_molecule = create_molecule(atoms=[TitanicBasicAtom()], name='basic')\n\n# create feature\nbasic_feature = MoleculeFeature(basic_molecule, root_dir='\/kaggle\/working\/')\n\n# feature has fit method.\nbasic_feature.fit(train_df, y)","16d90c96":"from vivid.out_of_fold.boosting import XGBoostClassifierOutOfFold, LGBMClassifierOutOfFold\nfrom vivid.out_of_fold.boosting.block import create_boosting_seed_blocks\nfrom vivid.out_of_fold.linear import LogisticOutOfFold\nfrom vivid.out_of_fold.ensumble import RFClassifierFeatureOutOfFold\nfrom vivid.out_of_fold.base import BaseOutOfFoldFeature\nfrom vivid.core import MergeFeature, EnsembleFeature","3f7b158d":"class KaggleKernelMixin:\n    def save_best_models(self, best_models):\n        pass\n\nclass CustomLGBM(KaggleKernelMixin, LGBMClassifierOutOfFold):\n    initial_params = {\n        'n_estimators': 10000,\n        'objective': 'binary',\n        'feature_fraction': .9,\n        'learning_rate': .05,\n        'max_depth': 5,\n        'num_leaves': 17\n    }","668b6c63":"class LogisticOptuna(KaggleKernelMixin, LogisticOutOfFold):\n    initial_params = {\n        'input_scaling': 'standard'\n    }\n\nclass XGB(KaggleKernelMixin, XGBoostClassifierOutOfFold):\n    pass\n\nclass SimpleLGBM(KaggleKernelMixin, LGBMClassifierOutOfFold):\n    initial_params = {\n        'n_estimators': 10000,\n        'learning_rate': .05,\n        'reg_lambda': 1.,\n        'reg_alpha': 1.,\n        'feature_fraction': .7,\n        'max_depth': 3,\n    }\n    \nclass RF(KaggleKernelMixin, RFClassifierFeatureOutOfFold):\n    initial_params = {'n_estimators': 125, 'max_features': 0.2, 'max_depth': 25, 'min_samples_leaf': 4, 'n_jobs': -1}","d130c454":"from sklearn.ensemble import ExtraTreesClassifier\nfrom rgf.sklearn import RGFClassifier\nfrom sklearn.linear_model import LogisticRegression","6b64995b":"class ExtraTree(KaggleKernelMixin, BaseOutOfFoldFeature):\n    model_class = ExtraTreesClassifier\n    initial_params = {'n_estimators': 100, 'max_features': 0.5, 'max_depth': 18, 'min_samples_leaf': 4, 'n_jobs': -1}\n    \nclass RGF(KaggleKernelMixin, BaseOutOfFoldFeature):\n    model_class = RGFClassifier\n    initial_params = {'algorithm': 'RGF_Sib', 'loss': 'Log'}\n    \nclass Logistic(KaggleKernelMixin, BaseOutOfFoldFeature):\n    model_class = LogisticRegression\n    init_params = { 'input_scaling': 'standard' }","e01121d1":"from keras import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier","992b6f40":"from copy import deepcopy\nfrom sklearn.base import ClassifierMixin","28c4e556":"class NN(ClassifierMixin, KerasClassifier):\n    def __call__(self, n_input):\n        clf = Sequential()\n        clf.add(Dense(12, input_dim=n_input, activation='relu'))\n        clf.add(Dense(6, activation='relu'))\n        clf.add(Dense(1, activation='sigmoid'))\n        clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n        return clf\n\n    def fit(self, X, y):\n        self.sk_params['n_input'] = X.shape[1]\n        super().fit(X, y)\n        return self","d036a7ee":"class KerasNN(KaggleKernelMixin, BaseOutOfFoldFeature):        \n    model_class = NN\n    initial_params = {\n        'epochs': 100,\n        'batch_size': 32,\n    }","fd472f57":"single_models = [\n    Logistic(parent=basic_feature, name='logistic', add_init_param={ 'input_scaling': 'standard' }),\n    XGB(parent=basic_feature, name='xgb'),\n    SimpleLGBM(parent=basic_feature, name='lgbm'),\n    ExtraTree(parent=basic_feature, name='extra'),\n    RGF(parent=basic_feature, name='rgf'),\n    RF(parent=basic_feature, name='rf'),\n    KerasNN(parent=basic_feature, name='keras_nn')\n]\n\nens = EnsembleFeature(single_models[:], name='ensumble', root_dir=basic_feature.root_dir)\nsingle_models += [ens]\n\nmerged = MergeFeature([*single_models, basic_feature], name='merged', root_dir=basic_feature.root_dir)\n\nstacking_models = [\n    Logistic(parent=merged,name='logistic_stacked', add_init_param={ 'input_scaling': 'standard' }),\n    SimpleLGBM(parent=merged, name='lgbm_stacked')\n]","9a13276b":"models = [\n    *single_models,\n    *stacking_models\n]","f832cb53":"oof_df = pd.DataFrame()\nfor m in models:\n    df_i = m.fit(train_df, y)\n    oof_df = pd.concat([oof_df, df_i], axis=1)","8e9420e2":"oof_df","e828383f":"from vivid.metrics import binary_metrics\n\nscore_df = None\nfor c in oof_df.columns:\n    score = binary_metrics(y, oof_df[c])\n    if score_df is None:\n        score_df = score.rename(columns={ 'score': c })\n    else:\n        score_df[c] = score.values[:, 0]","a85aa5a1":"score_df.T.sort_values('auc', ascending=False)","d203fe79":"import seaborn as sns","1b6d98c5":"sns.clustermap(data=oof_df)","476d8379":"from vivid.utils import timer","a6589eee":"OUTPUT_DIR = '\/kaggle\/working\/'","89a9d219":"for m in models:\n    with timer(logger=m.logger, format_str='{:.3f}[s]'):\n        pred = m.predict(test_df)\n    \n    sub_df = pd.DataFrame()\n    sub_df['Survived'] = np.round(pred.values[:, 0]).astype(np.int)\n    sub_df['PassengerId'] = test_df['PassengerId']\n    sub_df.to_csv(os.path.join(OUTPUT_DIR, m.name + '.csv'), index=False)","3b00b6fe":"# Vivid meets titanic\n\n## What\n\n`vivid` is a machine learning framework.\n\nrepo: https:\/\/gitlab.com\/nyker510\/vivid\n\n## Purpose\n\n`vivid` \u3092\u4f7f\u3063\u3066 titanic \u306e submit \u3092\u3059\u308b\u3053\u3068\u304c\u76ee\u7684\n\n* create feature\n* single and stacking model\n* evaluate score","bd5d2b33":"## Molecule and Feature\n\nRoughly speaking,\n\n* Moldecule: set of `atoms`\n* Feature: trainable object\n\n## Procedur\n\n* step1: create new `Molecule` and add name to the set\n* step2: create new Feature from `molecule`","6c870230":"Install Vivid Module","3c7e21a8":"## Predict\n\npredict test dataset. Just call `model.predict` like sklean.","049e67b8":"## Modeling","c0a783aa":"\u81ea\u524d\u3067\u3082\u4f5c\u308c\u308b\u3088","7cdea47c":"### Feature Engineering\n\nThis code is taken from [https:\/\/qiita.com\/r2en\/items\/61b3b7fa70d2b65021d0](https:\/\/qiita.com\/r2en\/items\/61b3b7fa70d2b65021d0). \nThanks!!\n\nBasic Feature Engineering. `vivid` provides `AbstractAtom` class for creating feature logic.\n\nJust define `call` method. `call` receive training dataframe and target, \nand return feature dataframe.","836f83d5":"### Out Of Fold Score\n\ncalculate binary metrics for all model Out-Of-Fold predict."}}