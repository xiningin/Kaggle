{"cell_type":{"a1e6e54e":"code","5b453f6b":"code","0b367df3":"code","eca827d1":"code","0996c84d":"code","f1ef39bf":"code","8934847f":"code","78b1ec28":"code","7d1fbb20":"code","042efa17":"code","c8ecb0c2":"code","e2e39485":"code","da913fca":"code","1c6d946b":"code","e0a09b58":"code","ccb46da7":"code","7f9b5e2b":"code","c512de98":"code","35a78352":"code","fdc4810b":"code","b0dbdf64":"code","ccf2f11d":"code","cac84231":"code","3b75bdd0":"code","49948fdd":"code","c1d971f9":"code","9d1c47cc":"code","240a803c":"code","8cd3e7e9":"code","0a7d8c34":"code","085a4f74":"code","b93aa77f":"code","03557037":"code","43140811":"code","27791711":"code","83dcf54d":"code","94f25132":"code","c22b2f2d":"code","7b1a8d9e":"code","563dbf13":"code","bfc03a5a":"code","09fa8f8e":"code","9d286f84":"code","496984bb":"code","8f322522":"code","71dfebfd":"code","de0c04a3":"code","14b2840c":"code","b02544a5":"code","feeb557d":"code","c5981eb3":"code","5f6310c2":"code","43976454":"code","21fbe1d2":"code","a8a79d7b":"code","d9ce3e30":"code","47759ace":"code","07a993fe":"code","fcc5f634":"code","40e17191":"code","cb37930c":"code","622a1a01":"code","d6bcce8b":"code","0b45d097":"code","00bd5fe3":"code","367ab062":"code","953766ab":"code","3a5cd071":"code","813af458":"code","9e6679cd":"code","d5e2e743":"code","31eb6915":"code","f6901f64":"code","5cb17301":"code","b10df3c3":"code","96da42a2":"code","8109988e":"markdown","c01a3e14":"markdown","cd648d33":"markdown","8574adef":"markdown","f0c1ab2f":"markdown","437dc1e8":"markdown","f221ad74":"markdown","c15b8827":"markdown","43fb80e7":"markdown","0af6c5d2":"markdown","6c74ee9b":"markdown","154ced4f":"markdown","d1a85a57":"markdown","a8b321df":"markdown","b91aebcc":"markdown","ee6f4784":"markdown","eb77b02f":"markdown","91f23735":"markdown","03d2189f":"markdown","2dd685d9":"markdown","21c5d383":"markdown","bce3adb6":"markdown","fac47b4a":"markdown","d11140cf":"markdown","c4fbd218":"markdown","f127de25":"markdown","86bebf11":"markdown","9d1b833a":"markdown","16b0d631":"markdown","88bcc8e6":"markdown","058665d1":"markdown","89bd3590":"markdown","eddea07c":"markdown","fc502839":"markdown","a690e9d3":"markdown","eaa721f9":"markdown","002c58c3":"markdown","d486ce24":"markdown","7911f675":"markdown","2151a3cd":"markdown","c1b4c782":"markdown","3a946eb1":"markdown","1d1a137a":"markdown","b9584108":"markdown","6738360d":"markdown","6ba0ea81":"markdown","cfbc83dc":"markdown","3204b2f1":"markdown","88a4eefe":"markdown","2b136736":"markdown","7aafffd8":"markdown","6180de01":"markdown","083faac2":"markdown","6fb6db34":"markdown","5b07c59f":"markdown","c018ce43":"markdown","66fa4459":"markdown","d6bba382":"markdown","b2cc5c5f":"markdown","f84bf274":"markdown","7c521520":"markdown","7a8a6b81":"markdown","a38f39d6":"markdown","2fd25e0c":"markdown","4ae3174c":"markdown","945e7570":"markdown","93adebb8":"markdown","c54fc398":"markdown","fdb3bf87":"markdown","3d75882f":"markdown","f68abfc7":"markdown","95c27ff1":"markdown","5f4f3130":"markdown","6b07c1fd":"markdown","41dcd936":"markdown","b70d6677":"markdown","7701c2f4":"markdown","4b558971":"markdown","09b9077c":"markdown","4593f2c7":"markdown","41f82780":"markdown"},"source":{"a1e6e54e":"import pandas as pd                  # Pandas for data analysis \nimport numpy as np                   # Numpy for mathematical process \nimport scipy.stats as stats          # For statistics\nfrom scipy import stats\nfrom scipy.stats import norm, skew  \n\n%matplotlib inline\n\nimport pandas_profiling              # Perform various statistical operations on your data\nimport seaborn as sns                # For data visualization  \nimport matplotlib.pyplot as plt      # For data visualization ","5b453f6b":"house_train=pd.read_csv('..\/input\/train.csv') # Read the training File\nprint(house_train.shape)\nhouse_train.head()","0b367df3":"# Drop the \"Id\" Column as it has no relavency with remaining data. It's just a high cardinal continious number range.\n\nhouse_train.drop(['Id'],inplace=True,axis=1)\nhouse_train.shape","eca827d1":"# Lets seperate our the target variable from train data.\n# Sale_price=house_train['SalePrice']\n\n# house_train.drop(['SalePrice'],axis=1,inplace=True)","0996c84d":"house_test = pd.read_csv('..\/input\/test.csv')\n\n# Here we store the id's of test data seperately, Because of final submission.\ntest_id=house_test['Id']\n\nhouse_test.drop('Id',inplace=True,axis=1)\nhouse_test.head()","f1ef39bf":"house_data=house_train.append(house_test,sort=False)","8934847f":"house_data.head()","78b1ec28":"# check the final dataframe\nhouse_data.shape","7d1fbb20":"house_data.info()","042efa17":"house_data.describe()","c8ecb0c2":"# I commented this out because it takes a lot much time.\n# house_data.profile_report(title='Pandas Profiling before Data Preprocessing', style={'full_width':True})","e2e39485":"# plotly\nimport plotly\nfrom plotly.offline import init_notebook_mode, iplot\nplotly.offline.init_notebook_mode(connected=True)\ninit_notebook_mode(connected=True)\nimport plotly.offline as py\nimport plotly.graph_objs as go\n","da913fca":"# Top 25 columsn with their null values.\n# house_data.isnull().sum().sort_values(ascending=False)[:25]","1c6d946b":"# create trace \ntrace = go.Bar(\n                x = house_data.isnull().sum().sort_values(ascending=False)[:25].index,\n                y = house_data.isnull().sum().sort_values(ascending=False)[:25].values,\n                name = \"Null Value Count\",\n                marker = dict(color = 'rgba(255, 174, 255, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))\ndata = [trace]\n\nlayout = go.Layout(\n                   title=\"Null Value Count for each feature\",\n                   xaxis= dict(title= 'Feature Name',ticklen= 15,zeroline= False),\n                   yaxis= dict(title= 'Count',ticklen= 15,zeroline= False))\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","e0a09b58":"house_data['PoolQC'].value_counts()","ccb46da7":"# Impute the missing values with None.\nhouse_data['PoolQC'].fillna('None',inplace=True)","7f9b5e2b":"house_data['MiscFeature'].value_counts()","c512de98":"house_data['MiscFeature'].fillna('None',inplace=True)","35a78352":"house_data['Alley'].value_counts()","fdc4810b":"house_data['Alley'].fillna('None',inplace=True)","b0dbdf64":"house_data['Fence'].value_counts()","ccf2f11d":"house_train['Fence'].fillna('None',inplace=True)","cac84231":"house_data['FireplaceQu'].value_counts()","3b75bdd0":"house_data['FireplaceQu'].fillna(\"None\",inplace=True)","49948fdd":"house_data[['Neighborhood','LotFrontage']]","c1d971f9":"house_data.groupby('Neighborhood')['LotFrontage'].median()","9d1c47cc":"house_data[\"LotFrontage\"] = house_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","240a803c":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    house_data[col] = house_data[col].fillna('None')","8cd3e7e9":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    house_data[col] = house_data[col].fillna(0)","0a7d8c34":"for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    house_data[col] = house_data[col].fillna(0)","085a4f74":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    house_data[col] = house_data[col].fillna('None')","b93aa77f":"house_data[\"MasVnrType\"] = house_data[\"MasVnrType\"].fillna(\"None\")\nhouse_data[\"MasVnrArea\"] =house_data[\"MasVnrArea\"].fillna(0)","03557037":"house_data['MSZoning'].isnull().sum()","43140811":"house_data['MSZoning'].value_counts()","27791711":"house_data['MSZoning'] = house_data['MSZoning'].fillna(house_data['MSZoning'].mode()[0])","83dcf54d":"house_data['Fence'].fillna('None',inplace=True)","94f25132":"# fill with the attribute which have max count. i.e mode() of the columns\n\n# Functional\nhouse_data['Functional'].fillna(house_data['Functional'].mode()[0],inplace=True)\n#Exterior1st\nhouse_data['Exterior1st'].fillna(house_data['Exterior1st'].mode()[0],inplace=True)\n# Exterior2nd\nhouse_data['Exterior2nd'].fillna(house_data['Exterior2nd'].mode()[0],inplace=True)\n# KitchenQual\nhouse_data['KitchenQual'].fillna(house_data['KitchenQual'].mode()[0],inplace=True)\n# SaleType\nhouse_data['SaleType'].fillna(house_data['SaleType'].mode()[0],inplace=True)\n# Electrical\nhouse_data['Electrical'].fillna(house_data['Electrical'].mode()[0],inplace=True)","c22b2f2d":"print(house_train['Utilities'].value_counts())\nprint('------'*15)\nprint(house_test['Utilities'].value_counts())","7b1a8d9e":"house_data['Utilities'].value_counts()","563dbf13":"all_data = house_data.drop(['Utilities'], axis=1)","bfc03a5a":"all_data.isnull().sum().sort_values(ascending=False).head(10)","09fa8f8e":"all_data['Fence'].value_counts()","9d286f84":"all_data.isnull().sum().sort_values(ascending=False).head()","496984bb":"all_data.head()","8f322522":"all_data.shape","71dfebfd":"# checking for the ouliers\n\nfig, ax = plt.subplots()\nax.scatter(x = house_train['GrLivArea'], y = house_train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()     ","de0c04a3":"#Deleting outliers\n# That's how you drop the ouliers but currently we are keeping them, Will try to see how droping the outliers impacts the result\n\n#--------------------------------------------------------------------------\n\n# house_train = house_train.drop(house_train[(house_train['GrLivArea']>4000) & (house_train['SalePrice']<300000)].index)\n\n# #Check the graphic again\n# fig, ax = plt.subplots()\n# ax.scatter(house_train['GrLivArea'], house_train['SalePrice'])\n# plt.ylabel('SalePrice', fontsize=13)\n# plt.xlabel('GrLivArea', fontsize=13)\n# plt.show()","14b2840c":"# all_data.profile_report(title='Pandas Profiling after Data Preprocessing', style={'full_width':True})","b02544a5":"#MSSubClass=The building class\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","feeb557d":"from sklearn import preprocessing\n\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = preprocessing.LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(all_data.shape))","c5981eb3":"# Adding total sqfootage feature \nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']","5f6310c2":"plt.figure(figsize=(10,8))\nsns.distplot(house_train['SalePrice'],fit=norm)\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(house_train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n#Positively skewed.\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')","43976454":"# Q-Q plot\nplt.figure()\nstats.probplot(house_train['SalePrice'],plot=plt)\nplt.show()","21fbe1d2":"target=np.log(house_train['SalePrice'])\nprint(target.skew())\nstats.probplot(target,plot=plt)\nplt.show()\n#Better than earlier.\nSale_price = np.log1p(house_train['SalePrice'])","a8a79d7b":"len(Sale_price)","d9ce3e30":"all_data.head()","47759ace":"numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: {} \".format(len(skewed_feats)))\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","07a993fe":"skewness.plot(kind='bar',figsize=(12,7))","fcc5f634":"skewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    #all_data[feat] += 1\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n    \n#all_data[skewed_features] = np.log1p(all_data[skewed_features])","40e17191":"all_data = pd.get_dummies(all_data)\nprint(all_data.shape)","cb37930c":"all_data.head()","622a1a01":"train=all_data[all_data['SalePrice'].notnull()]","d6bcce8b":"test=all_data[all_data['SalePrice'].isnull()]\ntest.drop(['SalePrice'],axis=1,inplace=True)","0b45d097":"print(train.shape)\ntrain.head(5)","00bd5fe3":"print(test.shape)\ntest.head(5)","367ab062":"plt.figure(figsize=(10,8))\ncorr=house_data.corr()\nsns.heatmap(corr)\nnumeric_feature=house_data.select_dtypes(include=np.number)","953766ab":"highly_corr=corr['SalePrice'].sort_values(ascending=False)\nnew=highly_corr[highly_corr.apply(lambda x:x>0.4)].to_frame().index\nplt.figure(figsize=(10,10))\ncorr_2=numeric_feature[new].corr()\nsns.heatmap(corr_2)","3a5cd071":"house_train[\"SalePrice\"] = np.log1p(house_train[\"SalePrice\"])\ny_train=house_train['SalePrice'].values","813af458":"#shows the positively coorrelated features with SalePrice\n\n#new=pd.DataFrame(data=highly_corr,index=highly_corr.keys())\nnew=highly_corr.to_frame()\n# Or we can use directly .to_frame()\n    #sns.set(style='darkgrid')\n#plt.subplots(figsize=(8,8))\n\nnew.plot(kind='bar',figsize=(10,10))\n#The plot shows the correlation between the Sale_price and the other features of the train data.\nprint(new)","9e6679cd":"highly_corr[highly_corr.apply(lambda x:x<0)]\n# negatively correlated features with the SalePrice.","d5e2e743":"print(train.shape)\ntrain.head()","31eb6915":"print(test.shape)\ntest.head()","f6901f64":"train.head()","5cb17301":"Y=train['SalePrice']\nX=train.drop('SalePrice',axis=1)","b10df3c3":"Y.head()","96da42a2":"X.head()","8109988e":"#### SalePrice distribution","c01a3e14":"<a id =\"section3\"><\/a>\n## 3. Loading Train & Test data","cd648d33":"An __outlier__ is an object that __deviates significantly__ from the rest of the objects. They can be caused by measurement or __execution error__. \n\n- When we have large data set that time the impact of outlier got nullified up to some extent but when the data is limited like the current one. Outliers impacts the final result a lot.\n\n- Let's explore these outliers","8574adef":"------\n\n### <font color='red'>Question:<\/font>\n\nWhy we need to check the normality of the target feature? And what if it not normal,\n- Does normality actually impacts the final prediction result?\n\n----\n","f0c1ab2f":"__BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath and BsmtHalfBath__\n\nMissing values are likely __zero__ for having __No basement__\n","437dc1e8":"#### Adding one more important feature\n\nSince area related features are very important to determine house prices, we add one more feature which is the total area of basement, first and second floor areas of each house","f221ad74":"<h1 style='text-align:Center'>House Price Pridiction<\/h1>\n\n\n![](https:\/\/media.giphy.com\/media\/5xtDarqCp0eomZaFJW8\/giphy.gif)\n","c15b8827":"We can see at the bottom __(GrLivArea>400)__ right two with extremely large GrLivArea that are of a low price. These values are huge oultliers. \n\n- Therefore, we can safely delete them.","43fb80e7":"> <a id=\"section301\"><\/a>\n### 3.1 Train data","0af6c5d2":"__GarageYrBlt, GarageArea and GarageCars__ \n\nReplacing missing data with __0__ (Since __No garage = no cars in such garage__.)","6c74ee9b":"__Drop train id column__","154ced4f":"## Check for skewness in other features","d1a85a57":"## Table of Contents\n1. [Problem Statement](#section1)<br>\n2. [Importing Libraries](#section2)<br>\n3. [Loading Train & Test data](#section3)<br>\n     - 3.1  [Train Data](#section301)<br>\n     - 3.2 [Test Data](#section302)<br>\n     - 3.3 [Describing the Data fields](#section303)<br>\n     - 3.4 [Club both train and test data together](#section304)<br>\n     - 3.5 [Pandas Profiling before Data Preprocessing](#section305)<br>\n4. [Data Pre-processing](#section4)<br>\n    - 4.1 [Imputing missing values](#section401)<br>\n    - 4.2 [Impute the LotFrontage with neighborhood median strategy](#section402)<br>\n    - 4.3 [Droping all value constant Utilities Column](#section403)<br>\n    - 4.4 [Pandas Profiling after Data Preprocessing](#section404)<br>\n5. [Model Training](#section5)<br>\n    - 5.1 [Creating the dummy variable of the given catagorical variable](#section501)<br>\n    - 5.2 [Train & Test split](#section502)<br>\n    - 5.3 [Modelling](#section503)<br>","a8b321df":"### Label Encoding some categorical variables that may contain information in their ordering set","b91aebcc":"__MSZoning (The general zoning classification)__\n\n- Since there are only __4 missing values__ in case if the missing size is large then we need to do apply the proper **imputation techniques**.\n\n'**RL**' is by far the **most common value**. So we can fill in missing values with 'RL'","ee6f4784":"The next part of this kernel is in progress. Very soon will upload it. If you have any idea\/suggestions about this notebook, please let me know. Any feedback about further improvements would be genuinely appreciated.","eb77b02f":"```info()``` function is basically describes about the null values in the data set.","91f23735":"- To treat skewness of the dataset here we gonna use __[Box-Cox Transformation](https:\/\/nickcdryan.com\/2017\/04\/19\/the-box-cox-transformation\/)__.\n\n- Box-Cox transformation is a family of power transform functions that are used to __stabilize variance__ and make a dataset look more like a __normal distribution__.","03d2189f":"<a id=\"section403\"><\/a>\n### 4.3 Droping Utilities Column (constant attribute)","2dd685d9":"__Test data obserbation__\n- Test data have 1459 rows(1 less to training data)\n- 79 columns \n- test data have one less column (__SalePrice__ which need to be predict ) compare to the training data training data.","21c5d383":"- Fill the remaining missing values in columns with __Mode()__ strategy.","bce3adb6":"__Fence__\n\nData description says __NA__ means __no fence__.","fac47b4a":"#### There is an another method to check normal distribution called Q-Q plot.","d11140cf":"<a id=\"section2\"><\/a>\n## 2. Importing Libraries","c4fbd218":"<a id=\"section302\"><\/a>\n### 3.2 Test data file","f127de25":"__MasVnrArea and MasVnrType__ \n\n__NA__ most likely means __no masonry veneer__ for these houses. We can fill __0__ for the area and __None__ for the type.","86bebf11":"### Skewness Treatment ","9d1b833a":"<a id=\"section304\"><\/a>\n### 3.4 Club both train and test data together\n- __why So?__\n - By clubing both train and test data set we make __one data file__. And then it become easier to bring all change in one single file rather than doing same work __twice__.\n ","16b0d631":"- If the data is __normally distributed__, the points in the __QQ-normal plot__ lie on a __straight diagonal line__.","88bcc8e6":"__Log transformation__ of the target variable has helped us fixing its __skewed__ distribution and the new distribution looks __closer to normal__. ","058665d1":"__Train data observation__\n- Data have 1460 rows \n- 88 Columns","89bd3590":"-----\n## <font color='red'>Question:<\/font>\n\nDoes creating new features actually impacts the final result?\n\n-----\n","eddea07c":"### Is it OK to remove outliers from data?\n\n- This is a bit dubious one, Some said it is better to drop all the outliers and vice-versa. But dropping outlier with deceded the model robustness. Which mean when model face some oulier point in test dataset it behaves drastically bad. \n\n- But not dropping outliers also create problem with model prediction as, outliers could impact the model too.\n- However, removing all them may affect badly our models if ever there were also outliers in the test data. That's why , instead of removing them all, we will just manage to make some of our models robust on them. You can refer to the modelling part of this notebook for that.\n\nSo what to do ...\n\n- So during model training its better to drop only extreme ouliers.\n\n[Read More](https:\/\/stats.stackexchange.com\/questions\/200534\/is-it-ok-to-remove-outliers-from-data\/200923)\n\n","fc502839":"__Now let's again check for the null values in the dataset__.","a690e9d3":"<a id=\"section1\"><\/a>\n## 1. Problem Statement\n______\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith __79 explanatory__ variables describing (almost) every aspect of residential homes in Ames, Iowa.\n\n\n<br>\n<center><h3>This competition challenges you to predict the final price of each home<\/h3><\/center>","eaa721f9":"__Pandas profiling Observation__","002c58c3":"### <font color='blue'>Skewness Visualization<\/font>","d486ce24":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/5407\/media\/housesbanner.png)","7911f675":"#### Observations from Pandas Profiling before Data Processing ","2151a3cd":"```describe()```function gives us the following __statistical__ insights about the given __DataFrame__, which can be clearly observed in the above table :\n\n   - Count explains the number of non null values in the data set.\n   - If __mean__ is less then median that means the distribution plot is **left skewed**.\n   - If __mean__ is more thatn median that means the distribution plot is **right skewed**.\n   - 75% - 25% == **IQR**(**Inter Qurtile Range**)\n   - If max value is very high compare to the 75th percentile value then possibly it is an outlier<br>\n   \n#### For Outliers = <img src=\"https:\/\/cdn.kastatic.org\/googleusercontent\/8bSRVB7q_zWxFliXcZVQSBDtip3sMGRkkHGLVzvflS3goQZZhmhrSD9u1cSduXh-9DJ9sSjCqVyozwQ_FwJNkptC\">\n   \n   \n   \n   ","c1b4c782":"----------\n### <font color='red'>Question<\/font> :\n\nCan we train our model directly on label Encoded categorical features?\n\n-------","3a946eb1":"## Overview","1d1a137a":"<a id=\"section305\"><\/a>\n### 3.5 Pandas Profiling before Data Preprocessing\n\n<img src=\"https:\/\/raw.githubusercontent.com\/insaid2018\/Term-2\/master\/images\/Pandas%20profiling.png\" height=\"500\" width=\"500\"\/>","b9584108":"This notebook is going to be focused on solving the problem of _predicting house prices_ for _house buyers and house sellers_.\n\nA house value is simply more than __location__ and __square footage__. Like the features that make up a person, an educated party would want to know all aspects that give a house its value.\n","6738360d":"__FireplaceQu__\n\nData description says __NA__ means __no fireplace__.","6ba0ea81":"__LotFrontage__ (Linear feet of street connected to property  )\n\n<center><img src=\"https:\/\/static.planetminecraft.com\/files\/resource_media\/screenshot\/1222\/check-this-out1_2449820.jpg\"\/><\/center>\n\nSince the area of each street connected to the house property most likely have a __similar area__ to other houses in its neighborhood , we can fill in missing values by the __median__ __LotFrontage__ of the __neighborhood__.","cfbc83dc":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTa4CEL3Uu1dhpn7UmDQlr09zwErbvbiht6Gl3PiYj50Z9UGXR_)","3204b2f1":"> - Group by __neighborhood__ and fill in missing value by the __median LotFrontage__ of all the neighborhood","88a4eefe":"At the top where we perform pandas_profiling we see there are many skewed features ","2b136736":"-----\n\n## <font color='red'>Question: <\/font>\n\nWhy do we need to tread the skewed features?\n\n----","7aafffd8":"<a id=\"section303\"><\/a>\n### 3.3 Describing the Data fields","6180de01":"### If this notebook helped you in any way or you liked it, please upvote and\/or leave a comment!! :)","083faac2":"<a id =\"section4\"><\/a>\n## 4. Data Pre-processing\n\nData preprocessing is a data mining technique which is used to __transform__ the __raw data__ in a useful and __efficient format__.\n\n__Steps Involved in Data Preprocessing:__\n\n-  __Imputing missing values__\n-  __Data Cleaning__\n- __Data Transformation__\n\n\nAfter observing the housing Data our main focus for this kernal is gonna be the:\n   - __Data Cleaning__\n   - __Data Transformation__\n","6fb6db34":"#### Time to seperate the train and test data again.","5b07c59f":"#### Null value count plot for different features .","c018ce43":"## But Wait, Do we know why we need to treat skewed features.\n- Transform data  to Normal Distribution \n---\n\n__Answer__: As (linear) models love normally distributed data. Since for Linear Regression DataDistribution needs to be __Normally distributed__.\n\nSo we need to treat all these skewed features.\n\nAs all the other Machine Learning algorithms doesn't got affected with the Normality of features.","66fa4459":"__ MiscFeature__\n\nData description says __NA__ means __no misc feature__.","d6bba382":"#### Transforming some numerical variables that are really categorical","b2cc5c5f":"__Here are the few data insight that we have got though Pandas Profiling__\n\n__(1) Total variable - 80__ and __total observation - 2919__\n - 34 Numeric\n - 46 Catagorical \n - 1  Boolean\n\n__(2) Number of Missing cells = 15424 (6.5%)__\n\n__(3) Extreme missing values__\n\n- Alley has 2721 (93.2%) missing values\n- Fence has 2348 (80.4%) missing values\tMissing\n- FireplaceQu has 1420 (48.6%) missing values\t\n- MiscFeature has 2814 (96.4%) missing values\n- PoolQC has 2909 (99.7%) missing values\t\n- SalePrice has 1459 (50.0%) missing values\n\n__(4) Number of zeros__\n\nThese zeros represent the abscence of a feature. eg:  0 in __2ndFlrSF__: Signifies the abscence of 2nd flow in the house.**\n- 2ndFlrSF has 1668 (57.1%) zeros\t\n- 3SsnPorch has 2882 (98.7%) zeros\n- BsmtFinSF2 has 2571 (88.1%) zeros\n- Fireplaces has 1420 (48.6%) zeros\n- LowQualFinSF has 2879 (98.6%) zeros\n- MasVnrArea has 1738 (59.5%) zeros\n- MiscVal has 2816 (96.5%) zeros\t\n- OpenPorchSF has 1298 (44.5%) zeros\n- PoolArea has 2906 (99.6%) zeros\n- ScreenPorch has 2663 (91.2%) zeros\t\n- TotalBsmtSF has 78 (2.7%) zeros\t\n- WoodDeckSF has 1523 (52.2%) zeros\n\n__(5) Skewness__\n\n- MiscVal is highly right skewed (\u03b31 = 21.95848032)\n\n### Read more about [Kurtosis and skewness](https:\/\/www.spcforexcel.com\/knowledge\/basic-statistics\/are-skewness-and-kurtosis-useful-statistics)","f84bf274":"<center><img src='https:\/\/media1.giphy.com\/media\/ciliDVG6ZOCRi\/giphy.gif?cid=ecf05e47d6634eaeec4c8259f4df4591f9637c8fa340238d&rid=giphy.gif' height=200 width=300\/><\/center>","7c521520":"### why ?\n\n- __Investigation of Target Variable__\n\n\nWe are investigating the nature of the __target__ or __response variable__ here; i.e. __SalePrice__. On the basis of our findings here, we can transform the variable.\n\n__Why are we doing this?__\n\nThis is to ensure the __model predictions__ behave better. What this means is, in regression it is necessary that the __residuals follow a normal distribution__. Now, if the predicted values are normally distributed then the residuals are as well and vice versa. For a detailed explaination refer to this [link here](https:\/\/stats.stackexchange.com\/questions\/60410\/normality-of-dependent-variable-normality-of-resid****uals).\n","7a8a6b81":"As this contains lot of features lets reduce down and consider those which have good correlation with the target variable.\n","a38f39d6":"__PoolQC__\n\nData description says NA means __No Pool__. That make sense, given the huge ratio of __missing value (+99%)__ which means majority of houses have __no Pool__ at all in general.","2fd25e0c":"__BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1 and BsmtFinType2__ \n\nFor all these categorical basement-related features, __NaN__ means that there is __no basement__.","4ae3174c":"-----\n\n## <font color='red'> Question:<\/font>\n\nDoes dummyfication of features always gives better result?\n\n-----","945e7570":"<a id=\"section401\"><\/a>\n### 4.1 Imputing missing values","93adebb8":"Generates profile reports from a pandas DataFrame. The pandas ```df.describe()``` function is great but a little basic for serious __exploratory data analysis(EDA)__. pandas_profiling extends the pandas DataFrame with ```df.profile_report()`` for quick data analysis.","c54fc398":"- Here all +ve skewed features are __Right Skewed__ one and -ve skewed are __Left Skewed__ one.","fdb3bf87":"#### Getting dummy categorical features","3d75882f":"- **Fence** : data description says NA means \"no **Fence\"**","f68abfc7":"## More features engeneering\n","95c27ff1":"<a id=\"section404\"><\/a>\n### 4.4 Pandas Profiling after Data Preprocessing ","5f4f3130":"__Alley__\n\n Data description says __NA__ means __no alley access__.","6b07c1fd":"### Correlation Plot","41dcd936":"__GarageType, GarageFinish, GarageQual and GarageCond__ \n\nReplacing missing data with None","b70d6677":"__Utilities__ (Type of utilities available)\n\nFor this categorical feature all records are __AllPub__, except for one __NoSeWa__ and __2 NA__ . Since the house with __NoSewa__ is in the training set, this feature won't help in predictive modelling. We can then safely remove it.\n\n- So here situation was like training model on such data that you never gonna see in test data set.\n- If you train your model on such data this will not anyhow __impacts your prediction__.\n- It just __adversely impacts the model training time__. \n- So it's better to __drop such features__.","7701c2f4":"- In house data we have __79__ features,description of all are down below.","4b558971":"<a id=\"section402\"><\/a>\n### 4.2 Impute the LotFrontage with neighborhood median strategy","09b9077c":"__This is a time-consuming process.So be patience and wait for the output__\n\n>   - __Important Note:__\n    - when you have large data set don't try this because when you run pandas profiling tons of calulatioins are going in the backend. So For large dataset you system might run out of memory. \n    \n\n- So it is advised to run Pandas Profiling only when you have limited data.\n","4593f2c7":"### Outlier Treatment","41f82780":"| __Column Name__                     | __Description__                                                                               |\n| ------------------------------- |:-----------------------------------------------------------------------------------------:| \n| ID                              | ID of the applicant.                                                                      | \n| SalePrice                                   | The property's sale price in dollars. This is the target variable that you're trying to predict.                                |\n| MSSubClass       | The building class                                        | \n| MSZoning                   | The general zoning classification                                                                |\n| LotFrontage                      | Linear feet of street connected to property                                              |\n| LotArea                    | Lot size in square feet                                      |\n| Street            | Type of road access                  |\n| Alley                           | Type of alley access                  |\n| LotShape               | General shape of property |\n| LandContour                | Flatness of the property                                           |\n| Utilities                     | Type of utilities available                                                                                                                |\n| LotConfig               |  Lot configuration          |\n| LandSlope        | Slope of property\n                                         |\n| Neighborhood | Physical locations within Ames city limits                   |\n| Condition1               | Proximity to main road or railroad                                                   |\n| Condition2 | Proximity to main road or railroad (if a second is present)|\n| BldgType | Type of dwelling |\n|HouseStyle| Style of dwelling |\n|OverallQual| Overall material and finish quality |\n|OverallCond | Overall condition rating |\n|YearBuilt| Original construction date |\n|YearRemodAdd| Remodel date |\n|RoofStyle| Type of roof |\n|RoofMatl |Roof material |\n| Exterior1st| Exterior covering on house|\n| Exterior2nd| Exterior covering on house (if more than one material)|\n| MasVnrType| Masonry veneer type|\n| MasVnrArea| Masonry veneer area in square feet|\n| ExterQual| Exterior material quality|\n| ExterCond:| Present condition of the material on the exterior|\n| Foundation:| Type of foundation|\n| BsmtQual| Height of the basement|\n| BsmtCond:| General condition of the basement|\n| BsmtExposure| Walkout or garden level basement walls|\n| BsmtFinType1| Quality of basement finished area|\n| BsmtFinSF1| Type 1 finished square feet|\n| BsmtFinType2| Quality of second finished area (if present)|\n| BsmtFinSF2| Type 2 finished square feet|\n| BsmtUnfSF| Unfinished square feet of basement area|\n| TotalBsmtSF| Total square feet of basement area|\n| Heating| Type of heating|\n| HeatingQC| Heating quality and condition|\n| CentralAir| Central air conditioning|\n| Electrical| Electrical system|\n| 1stFlrSF| First Floor square feet|\n| 2ndFlrSF| Second floor square feet|\n| LowQualFinSF| Low quality finished square feet (all floors)|\n| GrLivArea| Above grade (ground) living area square feet|\n| BsmtFullBath| Basement full bathrooms|\n| BsmtHalfBath| Basement half bathrooms|\n| FullBath| Full bathrooms above grade|\n| HalfBath| Half baths above grade|\n| Bedroom| Number of bedrooms above basement level|\n| Kitchen| Number of kitchens|\n| KitchenQual| Kitchen quality|\n| TotRmsAbvGrd| Total rooms above grade (does not include bathrooms)|\n| Functional| Home functionality rating|\n| Fireplaces| Number of fireplaces|\n| FireplaceQu| Fireplace quality|\n| GarageType| Garage location|\n| GarageYrBlt| Year garage was built|\n| GarageFinish| Interior finish of the garage|\n| GarageCars| Size of garage in car capacity|\n| GarageArea| Size of garage in square feet|\n| GarageQual| Garage quality|\n| GarageCond| Garage condition|\n| PavedDrive| Paved driveway|\n| WoodDeckSF| Wood deck area in square feet|\n| OpenPorchSF| Open porch area in square feet|\n| EnclosedPorch| Enclosed porch area in square feet|\n| 3SsnPorch| Three season porch area in square feet|\n| ScreenPorch| Screen porch area in square feet|\n| PoolArea| Pool area in square feet|\n| PoolQC| Pool quality|\n| Fence| Fence quality|\n| MiscFeature| Miscellaneous feature not covered in other categories|\n| MiscVal| $Value of miscellaneous feature| \n| MoSold| Month Sold |\n| YrSold| Year Sold |\n| SaleType| Type of sale |\n| SaleCondition| Condition of sale|"}}