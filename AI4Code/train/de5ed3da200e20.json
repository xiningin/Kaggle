{"cell_type":{"9f815238":"code","9af13936":"code","7ac92794":"code","21adf041":"code","293724d3":"code","88b87062":"code","18e0b040":"code","dc17094b":"code","a1c5ce25":"code","e27828a4":"code","bb6d608f":"code","f9ed4cbc":"code","53152b5b":"code","c494989c":"code","531b8cd5":"code","476ff223":"code","bfbc53fd":"code","38c60477":"code","db63eaee":"code","33a4bc70":"code","945bb8bf":"code","be9453d9":"code","4d64a7fd":"code","adde6fca":"code","ceab1811":"code","abc28dd2":"code","285a346b":"code","b4ea8040":"code","826c89c3":"code","32e58537":"code","329f9974":"code","acbd5a31":"code","b42f9260":"code","9085f7fe":"code","145d5a3b":"code","44b9d3df":"code","8021ab42":"code","c235cb94":"code","4c584a0a":"code","7786c03d":"code","4183adbc":"code","a116bf92":"code","aa0c07c4":"code","ac22890d":"code","f3491e85":"code","a397e7b5":"code","98c4ee60":"code","e921df9e":"markdown","85d06b17":"markdown","910ecf4e":"markdown","f9fa6449":"markdown","2cf7aa04":"markdown","ed1ffe9a":"markdown","8b3efdae":"markdown","565c135e":"markdown","8dbfe893":"markdown","2b284c2c":"markdown","951f5957":"markdown","c5f3655a":"markdown","9aa51a74":"markdown","9de60042":"markdown","13d51dde":"markdown","2bc0bd27":"markdown","7ba17a39":"markdown","e0be0719":"markdown","f0559440":"markdown","a239a647":"markdown","399f2d34":"markdown","f845ea57":"markdown","123c19f8":"markdown","68bb9dbf":"markdown","e4fd3918":"markdown","7b236a0a":"markdown","4da77906":"markdown","9a82699b":"markdown","6dbc3f98":"markdown","19ee6656":"markdown","6bdd70b1":"markdown","552fe23c":"markdown","9ba1d83b":"markdown","acdca773":"markdown","7ab119df":"markdown","c451d3af":"markdown","9da42343":"markdown","5f55194d":"markdown","51e1103b":"markdown","8674b432":"markdown","8457a739":"markdown","076dc455":"markdown","55758e6d":"markdown","59f93afd":"markdown","93284ea1":"markdown","03df8ca8":"markdown","0eb0c4b4":"markdown","5dc13680":"markdown","2e5e2fa0":"markdown","89072d68":"markdown","855ba739":"markdown","2b0225d5":"markdown","72ae70cf":"markdown","cfab2e43":"markdown","c68c55fa":"markdown","e2e1e612":"markdown","5fd30ed6":"markdown","e89c83c8":"markdown","515bbc91":"markdown","a4b43a14":"markdown","1e75aa72":"markdown","4f6acb29":"markdown","3e88abd2":"markdown","aeb4497a":"markdown","95cef629":"markdown","6fbcd808":"markdown","e896378a":"markdown","08abbe45":"markdown","1aca1bbb":"markdown","eccf7859":"markdown","6fd68e65":"markdown","12fe3c31":"markdown","cf81b28c":"markdown","e1e51968":"markdown","c2655493":"markdown","a2dd6e60":"markdown","6064b538":"markdown"},"source":{"9f815238":"!pip install xplotter --upgrade\n!pip install pycountry-convert\n!pip install geopy\n!pip install folium\n!pip install geopandas","9af13936":"# Importing libraries\nimport pandas as pd\nimport os\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Maps\nimport folium\nfrom folium.plugins import Fullscreen\nfrom pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2, country_name_to_country_alpha3, country_alpha2_to_country_name\nfrom geopy.geocoders import Nominatim\nimport geopandas as gpd\n\n# Xplotter\nfrom xplotter.insights import *\nfrom xplotter.formatter import format_spines","7ac92794":"# Defining directory variables\nDATA_PATH = '..\/input\/netflix-shows'\nFILENAME = 'netflix_titles.csv'","21adf041":"# Reading the csv file\ndf = pd.read_csv(os.path.join(DATA_PATH, FILENAME))\nprint(f'The dataset has {df.shape[0]} rows and {df.shape[1]} columns')\ndf.head()","293724d3":"# Balance of Netflix products\nplot_donut_chart(df=df, col='type', colors=['dimgrey', 'crimson'],\n                 title='Does Netflix had more \\nMovies or TV Shows on 2019?')","88b87062":"# Creating a new datetime column for date_added info\ndf_prep = df.copy()\ndf_prep['date_added_dt'] = pd.to_datetime(df_prep['date_added'])\n\n# Creating new columns for movie type\ndf_prep['is_tvshow'] = (df_prep['type'] == 'TV Show') * 1\ndf_prep['is_movie'] = (df_prep['type'] == 'Movie') * 1\n\n# Sorting by date and applying a cumulative sum on type flags\ndf_prep.sort_values(by='date_added_dt', inplace=True)\ndf_prep['cumul_tvshow'] = df_prep['is_tvshow'].cumsum()\ndf_prep['cumul_movie'] = df_prep['is_movie'].cumsum()\n\n# Plotting figure\nfig, ax = plt.subplots(figsize=(16, 7))\nsns.lineplot(x='date_added_dt', y='cumul_tvshow', data=df_prep, ax=ax, \n             color='crimson', label='TV Shows', linewidth=3.5, markers='x')\nsns.lineplot(x='date_added_dt', y='cumul_movie', data=df_prep, ax=ax, \n             color='dimgrey', label='Movies')\n\n# Extracting max y value\nmax_tvshow = df_prep['cumul_tvshow'].max()\nmax_movie = df_prep['cumul_movie'].max()\nmax_ylabel = max_movie if max_movie >= max_tvshow else max_tvshow\n\n# Setting y limit and title\nax.set_ylim(0, max_ylabel)\nax.set_title('Cumulative Count of TV Shows and Movies \\nbased on the date they are added', size=18)\n\n# Additional customization\nformat_spines(ax)\nax.set_ylabel('Cumulative Count', size=12)\nax.set_xlabel('Date Added', size=12)\nax.fill_between(x=df_prep['date_added_dt'], y1=df_prep['cumul_movie'], y2=df_prep['cumul_tvshow'],\n                color='silver', alpha=.5)\n\n# Finishing plot\nplt.legend(loc='upper left')\nplt.tight_layout()\nplt.show()","18e0b040":"# Setting snapshot date\ndf_prep['catalog_date'] = df_prep['date_added_dt'].max()\n\n# Computing deltas\ndf_prep['days_on_catalog'] = (df_prep['catalog_date'] - df_prep['date_added_dt']).dt.days\ndf_prep['months_on_catalog'] = (df_prep['days_on_catalog'] \/ 30)\ndf_prep['years_on_catalog'] = (df_prep['days_on_catalog'] \/ 365)\n\n# Creating figure and plotting statistical analysis\ncolors = ['dimgrey', 'crimson']\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(17, 7))\nplot_distplot(df=df_prep, col='days_on_catalog', hue='type', ax=axs[0], color_list=colors,\n              title='Age distribution (in days) \\nfor titles on Netflix by type')\nplot_distplot(df=df_prep, col='days_on_catalog', hue='type', ax=axs[1], palette=colors, kind='box',\n              title='Boxplot for age (in days) \\nof titles by type')","dc17094b":"df_prep['years_on_catalog'] = round(df_prep['years_on_catalog'], 0)\nplot_countplot(df=df_prep, col='years_on_catalog', hue='type', figsize=(17, 10), palette=colors,\n               title='How many years\u00b9 do movies and TV shows on recent catalog have?\\n\\n\u00b9Years rounded to 0 decimal places')","a1c5ce25":"# Top 5 oldest movies\ncols = ['type', 'title', 'country', 'date_added', 'release_year', 'duration']\nprint(f'Top 5 movies with most days on catalog')\ndf_prep.query('type == \"Movie\"').sort_values(by='days_on_catalog', ascending=False).head().loc[:, cols]","e27828a4":"# Top 5 newest movies\nprint(f'Top 5 movies recently added on catalog')\ndf_prep.query('type == \"Movie\"').sort_values(by='days_on_catalog', ascending=True).head().loc[:, cols]","bb6d608f":"# Top 5 oldest movies\nprint(f'Top 5 TV Shows with most days on catalog')\ndf_prep.query('type == \"TV Show\"').sort_values(by='days_on_catalog', ascending=False).head().loc[:, cols]","f9ed4cbc":"# Top 5 newest movies\nprint(f'Top 5 TV shows recently added on catalog')\ndf_prep.query('type == \"TV Show\"').sort_values(by='days_on_catalog', ascending=True).head().loc[:, cols]","53152b5b":"# Creating a function for extracting people on cast\ndef num_people_on_cast(cast_str, splitter=','):\n    try:\n        return int(len(cast_str.split(splitter)))\n    except AttributeError as ae:\n        return np.nan\n\n# Extracting total people on cast\ndf_prep['num_people_on_cast'] = df_prep['cast'].apply(lambda x: num_people_on_cast(x))\n\n# Plotting figure\nfig, ax = plt.subplots(figsize=(17, 10))\nplot_countplot(df=df_prep, col='num_people_on_cast', ax=ax, size_labels=10,\n               title='How many people are usually part of titles on Netflix?', size_title=18)\n\n# Customizing chart\nax.set_xticklabels(ax.get_xticks(), rotation=0)\nax.set_xlabel('Number of people on cast', size=14)\nplt.xticks(fontsize=(14))\nplt.show()","c494989c":"# Defining function for extracting individual names from cast list\ndef extract_list_from_string(cast_str, splitter=','):\n    try:\n        return [c.strip() for c in cast_str.split(splitter)]\n    except AttributeError as ae:\n        return np.nan\n\n# Extracting actors and actresses\ncast_list = extract_list_from_string(''.join(list(df_prep['cast'].fillna(' ').values)))\ndf_cast = pd.DataFrame(cast_list, columns=['name'])\n\n# Counting appearence\nplot_countplot(df=df_cast, col='name', top=30, order=True, orient='h', figsize=(17, 16),\n               title='Who appears most on Netflix catalog?\\nA top 30 chart', size_title=18)\n\n# Customizing chart\nplt.yticks(fontsize=(18))\nplt.tight_layout()\nplt.show()","531b8cd5":"# Creating subsets for movies and TV shows\ndf_movies = df_prep.query('type == \"Movie\"')\ndf_tvs = df_prep.query('type == \"TV Show\"')\n\n# Extracting actors and actresses\nmovies_cast_list = extract_list_from_string(''.join(list(df_movies['cast'].fillna(' ').values)))\ndf_cast_movies = pd.DataFrame(movies_cast_list, columns=['name'])\ntvs_cast_list = extract_list_from_string(''.join(list(df_tvs['cast'].fillna(' ').values)))\ndf_cast_tvs = pd.DataFrame(tvs_cast_list, columns=['name'])\n\n# Counting appearence\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(17, 16))\n\n# Plotting appearence on movies and TV Shows\nplot_countplot(df=df_cast_movies, col='name', top=30, order=True, orient='h', ax=axs[0],\n               title='Who appears most on Netflix movies?', size_title=18, palette='Greys_r')\nplot_countplot(df=df_cast_tvs, col='name', top=30, order=True, orient='h', ax=axs[1],\n               title='Who appears most on Netflix TV shows?', size_title=18, palette='Reds_r')\n\n# Tighting layout\nplt.tight_layout()\nplt.setp(axs[0].get_yticklabels(), fontsize=18)\nplt.setp(axs[1].get_yticklabels(), fontsize=18)\naxs[1].set_ylabel('')\nplt.show()","476ff223":"# Top 10 directors\nplot_countplot(df=df, col='director', top=10, orient='h', order=True, figsize=(17, 10), palette='viridis',\n               title='Top 10 directors with most appearence on Netflix catalog', size_title=18)\nplt.yticks(fontsize=(18))\nplt.show()","bfbc53fd":"#  Function for extracting useful country info by its name\ndef get_country_info(col):\n    try:\n        cn_a2_code =  country_name_to_country_alpha2(col)\n    except:\n        cn_a2_code = 'Unknown'\n    try:\n        cn_a3_code =  country_name_to_country_alpha3(col)\n    except:\n        cn_a3_code = 'Unknown'\n    try:\n        cn_continent = country_alpha2_to_continent_code(cn_a2_code)\n    except:\n        cn_continent = 'Unknown' \n    return (cn_a2_code, cn_a3_code, cn_continent)\n\n# Defining geolocator and function for extracting coordinates\ngeolocator = Nominatim(user_agent='thipanini94@gmail.com')\ndef get_geocode(country):\n    try:\n        # Geolocate the center of the country\n        loc = geolocator.geocode(country)\n        # And return latitude and longitude\n        return (loc.latitude, loc.longitude)\n    except:\n        # Return missing value\n        return np.nan\n    \n# Creating a dictionary of countries and geolocation (in case of API error)\ncountry_dict = {'US': (39.7837304, -100.4458825),\n                 'IN': (22.3511148, 78.6677428),\n                 'GB': (54.7023545, -3.2765753),\n                 'Unknown': (51.1461391, 12.233285),\n                 'CA': (61.0666922, -107.991707),\n                 'FR': (46.603354, 1.8883335),\n                 'JP': (36.5748441, 139.2394179),\n                 'ES': (39.3260685, -4.8379791),\n                 'KR': (36.638392, 127.6961188),\n                 'DE': (51.0834196, 10.4234469),\n                 'MX': (22.5000485, -100.0000375),\n                 'CN': (35.000074, 104.999927),\n                 'AU': (-24.7761086, 134.755),\n                 'EG': (26.2540493, 29.2675469),\n                 'TR': (38.9597594, 34.9249653),\n                 'HK': (22.2793278, 114.1628131),\n                 'IT': (42.6384261, 12.674297),\n                 'BR': (-10.3333333, -53.2),\n                 'TW': (23.9739374, 120.9820179),\n                 'BE': (50.6402809, 4.6667145),\n                 'AR': (-34.9964963, -64.9672817),\n                 'ID': (-2.4833826, 117.8902853),\n                 'PH': (12.7503486, 122.7312101),\n                 'NG': (9.6000359, 7.9999721),\n                 'TH': (14.8971921, 100.83273),\n                 'ZA': (-28.8166236, 24.991639),\n                 'CO': (2.8894434, -73.783892),\n                 'NL': (52.5001698, 5.7480821),\n                 'DK': (55.670249, 10.3333283),\n                 'IE': (52.865196, -7.9794599),\n                 'SE': (59.6749712, 14.5208584),\n                 'SG': (1.357107, 103.8194992),\n                 'PL': (52.215933, 19.134422),\n                 'AE': (24.0002488, 53.9994829),\n                 'NO': (60.5000209, 9.0999715),\n                 'NZ': (-41.5000831, 172.8344077),\n                 'RU': (64.6863136, 97.7453061),\n                 'IL': (31.5313113, 34.8667654),\n                 'CL': (-31.7613365, -71.3187697),\n                 'LB': (33.8750629, 35.843409),\n                 'MY': (4.5693754, 102.2656823),\n                 'PK': (30.3308401, 71.247499),\n                 'CZ': (49.8167003, 15.4749544),\n                 'CH': (46.813331250000005, 8.444947437939408),\n                 'UY': (-32.8755548, -56.0201525),\n                 'RO': (45.9852129, 24.6859225),\n                 'FI': (63.2467777, 25.9209164),\n                 'AT': (47.2, 13.2),\n                 'LU': (49.8158683, 6.1296751),\n                 'PE': (-6.8699697, -75.0458515),\n                 'SA': (25.6242618, 42.3528328),\n                 'GR': (38.9953683, 21.9877132),\n                 'HU': (47.1817585, 19.5060937),\n                 'IS': (64.9841821, -18.1059013),\n                 'BG': (42.6073975, 25.4856617),\n                 'JO': (31.1667049, 36.941628),\n                 'RS': (44.1534121, 20.55144),\n                 'KW': (29.2733964, 47.4979476),\n                 'QA': (25.3336984, 51.2295295),\n                 'MA': (31.1728205, -7.3362482),\n                 'KH': (13.5066394, 104.869423),\n                 'KE': (1.4419683, 38.4313975),\n                 'VN': (13.2904027, 108.4265113),\n                 'PT': (40.0332629, -7.8896263),\n                 'GH': (7.8573710000000005, -1.0840975468820433),\n                 'HR': (45.5643442, 17.0118954),\n                 'IR': (32.6475314, 54.5643516),\n                 'BD': (24.4768783, 90.2932426),\n                 'ZW': (-19.01688, 29.35365015971339),\n                 'SN': (14.46517725, -14.765340959100413),\n                 'MT': (35.8885993, 14.4476911),\n                 'SI': (45.8133113, 14.4808369),\n                 'VE': (8.0018709, -66.1109318),\n                 'UA': (49.4871968, 31.2718321),\n                 'KY': (19.703182249999998, -79.9174627243246),\n                 'GT': (15.6356088, -89.8988087),\n                 'NA': (-23.2335499, 17.3231107),\n                 'GE': (32.3293809, -83.1137366),\n                 'NP': (28.1083929, 84.0917139),\n                 'IQ': (33.0955793, 44.1749775),\n                 'DZ': (28.0000272, 2.9999825),\n                 'BM': (32.3018217, -64.7603583),\n                 'AF': (33.7680065, 66.2385139),\n                 'AL': (41.000028, 19.9999619),\n                 'LK': (7.5554942, 80.7137847),\n                 'SD': (14.5844444, 29.4917691),\n                 'BW': (-23.1681782, 24.5928742),\n                 'AO': (-11.8775768, 17.5691241),\n                 'SY': (34.6401861, 39.0494106),\n                 'BY': (53.4250605, 27.6971358),\n                 'BS': (24.7736546, -78.0000547),\n                 'AZ': (40.3936294, 47.7872508),\n                 'SO': (8.3676771, 49.083416),\n                 'AM': (40.7696272, 44.6736646),\n                 'UG': (1.5333554, 32.2166578),\n                 'JM': (18.1850507, -77.3947693),\n                 'SK': (48.7411522, 19.4528646),\n                 'NI': (12.6090157, -85.2936911),\n                 'KZ': (47.2286086, 65.2093197),\n                 'LV': (56.8406494, 24.7537645),\n                 'LI': (47.1416307, 9.5531527),\n                 'MW': (-13.2687204, 33.9301963),\n                 'MU': (-20.2759451, 57.5703566),\n                 'MN': (46.8250388, 103.8499736),\n                 'ME': (42.9868853, 19.5180992),\n                 'PA': (8.559559, -81.1308434),\n                 'WS': (-13.7693895, -172.1200508),\n                 'EC': (-1.3397668, -79.3666965),\n                 'DO': (19.28131815, -70.035906834967),\n                 'PY': (-23.3165935, -58.1693445),\n                 'PR': (18.2214149, -66.41328179513847),\n                 'CY': (34.9823018, 33.1451285),\n                 'CU': (23.0131338, -80.8328748),\n                 'LT': (55.3500003, 23.7499997)}","38c60477":"# Extracting number of titles references for each country\ncountry_list = extract_list_from_string(','.join(list(df['country'].fillna('Unknown').values)))\ndf_countries = pd.DataFrame(pd.DataFrame(country_list, columns=['country_name']).value_counts())\ndf_countries.reset_index(inplace=True)\ndf_countries.columns = ['country_name', 'num_titles']\n\n# Joining with country codes from pycountry-convert\ndf_countries['codes'] = df_countries['country_name'].apply(lambda x: get_country_info(x))\ndf_countries['country_a2'] = df_countries['codes'].apply(lambda x: x[0])\ndf_countries['country_a3'] = df_countries['codes'].apply(lambda x: x[1])\ndf_countries['continent'] = df_countries['codes'].apply(lambda x: x[2])\n\n# Extracting latitude and longitude coordinates from geopy\n#df_countries['geolocate'] = df_countries['country_name'].apply(lambda x: geolocate(x))\n\n# Extracting latitude and longitude coordinates from countries dictionary already saved\ndf_countries['geolocate'] = df_countries['country_a2'].map(country_dict)\ndf_countries['latitude'] = df_countries['geolocate'].apply(lambda x: x[0])\ndf_countries['longitude'] = df_countries['geolocate'].apply(lambda x: x[1])\n\n# Extracting latitude and longitude coordinates from countries dictiona\ndf_countries.head(10)","db63eaee":"#from folium.plugins import FastMarkerCluster\n\n# Extracting locations\nlocations = list(df_countries['geolocate'])\ndf_countries['norm_titles_radius'] = np.log1p(df_countries['num_titles'])\n\n# Creating a map using folium\nmap1 = folium.Map(location=[35, -0], zoom_start=2.0, tiles='cartodbpositron')\n\n# Plugin: FastMarkerCluster\n#FastMarkerCluster(data=locations).add_to(map1)\n\n# Iterating over each row\nfor i in range(len(df_countries)):\n    loc = df_countries['geolocate'][i]\n    country = df_countries['country_name'][i]\n    titles = df_countries['num_titles'][i]\n    tooltip = f'<b><i>Country:<\/b><\/i> {country}\\n<b><i>Titles:<\/b><\/i> {titles}'\n    \n    radius = df_countries['norm_titles_radius'][i] * 2\n    \n    # Adding CircleMarker plugin\n    folium.CircleMarker(location=loc, radius=radius, color='crimson', \n                        popup=tooltip, fill=True).add_to(map1)\n\nmap1","33a4bc70":"# Defining a style function for Choropleth\ndef style_function(feature):\n    \"\"\"\n    Customize maps\n    \"\"\"\n    return {\n        'fillColor': '#ffaf00',\n        'color': 'grey',\n        'weight': 1.0,\n        'dashArray': '5, 5'\n    }\n\n# Defining a highlight function for Choropleth\ndef highlight_function(feature):\n    \"\"\"\n    Customize maps\n    \"\"\"\n    return {\n        'fillColor': '#ffaf00',\n        'color': 'white',\n        'weight': 1.5,\n        'dashArray': '5, 5'\n    }","945bb8bf":"# Extracting a world map model from github\nurl = 'https:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data'\nworld_geo = f'{url}\/world-countries.json'\njson_data = gpd.read_file(f'{url}\/world-countries.json')\n\n# Joining data for custom tooltips\nglobal_data = json_data.merge(df_countries, how='left', left_on='id', right_on='country_a3').fillna(0)\nglobal_data = global_data.loc[:, ['name', 'num_titles', 'geometry']]\n\n# Creating a map using folium\nm = folium.Map(\n    location=[35, 0], \n    zoom_start=1.50,\n    tiles='openstreetmap'\n)\n\n# Choropleth map\nfolium.Choropleth(\n    geo_data=world_geo,\n    name='Netflix Around the World',\n    data=df_countries.query('country_a3 != \"Unknown\"'),\n    columns=['country_a3', 'norm_titles_radius'],\n    key_on='feature.id',\n    fill_color='Reds',\n    fill_opacity=.9,\n    line_opacity=.7,\n    nan_fill_color='white',\n    nan_fill_opacity=0.9,\n    legend_name='Log of Number of Titles'\n).add_to(m)\n\n# Adding a fullscreen button plugin\nFullscreen(\n    position='topright',\n    title='Expand me',\n    title_cancel='Exit me',\n    force_separate_button=True\n).add_to(m)\n\n# Customizing tooltips\nfolium.GeoJson(\n    global_data,\n    style_function=style_function,\n    highlight_function=highlight_function,\n    tooltip=folium.GeoJsonTooltip(fields=['name', 'num_titles'],\n                                  aliases=['Country:', 'Number of Titles:'],\n                                  labels=True,\n                                  sticky=True)\n).add_to(m)\n    \nm","be9453d9":"# Extracting the age of the title in years\ndf_prep['title_age_years'] = datetime.now().year - df_prep['release_year']\n\n# Extracting title's duration information\ndf_prep['duration_num'] = df_prep['duration'].apply(lambda x: int(x.split(' ')[0]))\ndf_prep['duration_scale'] = df_prep['duration'].apply(lambda x: x.split(' ')[-1].strip())\n\n# Fixing duration scale name\ndf_prep['duration_scale'] = df_prep['duration_scale'].apply(lambda x: 'Season' if x in ('Season', 'Seasons') else x)\n\n# Filtering movies and tvshows\nmovies = df_prep.query('is_movie == 1')\ntvshows = df_prep.query('is_tvshow == 1')\n\n# Plotting duration on movies\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(17, 15))\nplot_distplot(df=movies, col='duration_num', ax=axs[0], color='dimgrey',\n              title='Distribution of movies duration in minutes')\nplot_countplot(df=tvshows, col='duration_num', ax=axs[1], color='crimson', size_labels=10,\n               title='TV Shows countplot by duration in seasons')\n\nplt.tight_layout()\nplt.show()","4d64a7fd":"# Sorting movies\nmovies.sort_values(by='duration_num', ascending=False).head().loc[:, cols]","adde6fca":"# Sorting movies\ntvshows.sort_values(by='duration_num', ascending=False).head().loc[:, cols]","ceab1811":"# Extracting top 10 countries with most titles on Netflix\ntop_countries = df_prep['country'].value_counts().index[:10]\ndf_countries = df_prep.query('country in (@top_countries)')\n\n# Defining figure and axis\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(17, 15))\n\n# Plotting average duration for movies of top 10 countries\nplot_aggregation(df=df_countries.query('type == \"Movie\"'), group_col='country', palette='Greys_r',\n                 value_col='duration_num', aggreg='mean', ax=axs[0], order=top_countries, size_title=20,\n                 title='Mean duration from movies of the top 10 countries \\nwith most titles on Netflix')\n\n# Plotting average number os seasons for TV shows of top 10 countries\nplot_aggregation(df=df_countries.query('type == \"TV Show\"'), group_col='country', palette='Reds_r',\n                 value_col='duration_num', aggreg='mean', ax=axs[1], order=top_countries, size_title=20,\n                 title='Average number of seasons from TV shows of the top 10 countries\\n with most titles on Netflix')\n\n# Tighting layout\nplt.tight_layout()\nplt.setp(axs[0].get_xticklabels(), fontsize=18)\nplt.setp(axs[1].get_xticklabels(), fontsize=18)\naxs[0].set_xlabel('')\naxs[0].set_ylabel('Duration in minutes')\naxs[1].set_ylabel('Duration in #Seasons')\nplt.show()","abc28dd2":"# Extracting a list for titles classification\nlisted_titles = pd.DataFrame(extract_list_from_string(' '.join(list(df_prep['listed_in'].values))))\nlisted_titles.columns = ['listed_in']\n\n# Plotting a bar chart with top N types\nplot_countplot(df=listed_titles, col='listed_in', orient='h', top=20, order=True, figsize=(17, 12),\n               title='Top 20 titles classification on Netflix catalog', size_title=20)\n\nplt.tight_layout()\nplt.yticks(fontsize=(18))\nplt.show()","285a346b":"!pip install wordcloud\n!pip install nltk","b4ea8040":"# Importing libraries\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom PIL import Image\nimport requests\n\n# Function for counting ngrams\ndef ngrams_count(corpus, ngram_range=(1, 1), n=-1, cached_stopwords=stopwords.words('english')):\n    \"\"\"\n    Applies text transformation for counting words in a n_gram range\n    \n    Parameters\n    ----------\n    :param corpus: text list to be analysed [type: list or pd.Series]\n    :param ngram_range: ngrams to be extracted from corpus [type: tuple, default=(1, 1)]\n    :param n: limits the returning of only the top N ngrams [type: int, default=-1]\n        *in case of n=-1, all ngrams will be returned\n    :param cached_stopwords: stopwords to be used on filtering words \n        *[type: list, default=stopwords.words('english')]\n        \n    Return\n    ------\n    :return df_count: DataFrame with columns \"ngram\" and \"count\" [type: pd.DataFrame]\n    \n    Application\n    -----------\n    df_count = ngrams_count(corpus=df['text_attribute'])\n    \"\"\"\n    \n    # Using CountVectorizer to build a bag of words using the given corpus\n    vectorizer = CountVectorizer(stop_words=cached_stopwords, ngram_range=ngram_range).fit(corpus)\n    bag_of_words = vectorizer.transform(corpus)\n    \n    # Summing words and generating a frequency list\n    sum_words = bag_of_words.sum(axis=0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n    total_list = words_freq[:n]\n    \n    # Returning a DataFrame with the ngrams count\n    return pd.DataFrame(total_list, columns=['ngram', 'count'])\n\n# Building a pre configured wordcloud object\ndef generate_wordcloud(corpus, ngram_range=(1, 1), n=-1, cached_stopwords=stopwords.words('english'),\n                       **kwargs):\n    \"\"\"\n    Applies a ngram count and generates a wordcloud object using a counter dictionary\n    \n    Parameters\n    ----------\n    :param corpus: text list to be analysed [type: list or pd.Series]\n    :param ngram_range: ngrams to be extracted from corpus [type: tuple, default=(1, 1)]\n    :param n: limits the returning of only the top N ngrams [type: int, default=-1]\n        *in case of n=-1, all ngrams will be returned\n    :param cached_stopwords: stopwords to be used on filtering words \n        *[type: list, default=stopwords.words('english')]\n    :param **kwargs: additional parameters\n        :arg width: wordcloud width [type: int, default=1280]\n        :arg height: wordcloud height [type: int, default=720]\n        :arg random_state: random seed for word positioning [type: int, defualt=42]\n        :arg colormap: colormap for wordcloud chart [type: string, default='viridis']\n        :arg background_color: wordcloud background color [type: string, default='white']\n        :arg mask: either an internet image url or an image array for using as mask\n            *[type: string or array, default=None]\n        \n    Return\n    ------\n    :return wordcloud: WordCloud object [type: wordcloud.WordCloud]\n    \n    Application\n    -----------\n    wordcloud = generate_wordcloud(corpus=df['text_attribute'])\n    \"\"\"\n    \n    # Generating a DataFrame with ngrams count\n    df_count = ngrams_count(corpus=corpus, ngram_range=ngram_range, n=n, \n                            cached_stopwords=cached_stopwords)\n    \n    # Transforming the ngram count into a dictionary\n    words_dict = {w: c for w, c in df_count.loc[:, ['ngram', 'count']].values}\n    \n    # Extracting kwargs for generating a wordcloud\n    width = kwargs['width'] if 'width' in kwargs else 1280\n    height = kwargs['height'] if 'height' in kwargs else 720\n    random_state = kwargs['random_state'] if 'random_state' in kwargs else 42\n    colormap = kwargs['colormap'] if 'colormap' in kwargs else 'viridis'\n    background_color = kwargs['background_color'] if 'background_color' in kwargs else 'white'\n    \n    # Creating a mask if applicable\n    mask = kwargs['mask'] if 'mask' in kwargs else None\n    try:\n        if type(mask) == str and mask is not None:\n            # Requesting the image url using requests and transforming it using PIL\n            img = Image.open(requests.get(mask, stream=True).raw)\n            mask_array = np.array(img)\n            \n            # If mask array is a 3-dimensional array, transformes it into a 2-dimensional\n            if len(mask_array.shape) == 3:\n                mask_array = mask_array[:, :, -1]\n            \n            # Creating a transformarion mask and changing pixels on it\n            transf_mask = np.ndarray((mask_array.shape[0], mask_array.shape[1]), np.int32)\n            for i in range(len(mask_array)):\n                transf_mask[i] = [255 if px == 0 else 0 for px in mask_array[i]]\n\n        # If mask argument is already given as an array\n        else:\n            transf_mask = mask\n            \n    except Exception as e:\n        # Error on requesting or preparing the mask - wordcloud will be generated without it\n        print(f'Error on requesting or preparing mask. WordCloud will be generated without mask')\n        transf_mask = None\n        \n    \n    # Generating wordcloud\n    wordcloud = WordCloud(width=width, height=height, random_state=random_state, colormap=colormap, \n                          background_color=background_color, mask=transf_mask).generate_from_frequencies(words_dict)\n    \n    return wordcloud\n\n# Plotting a custom wordcloud\ndef plot_wordcloud(corpus, ngram_range=(1, 1), n=-1, cached_stopwords=stopwords.words('english'),\n                   **kwargs):\n    \"\"\"\n    Generates a ngram count and a wordcloud object for plotting a custom wordcloud chart\n    \n    Parameters\n    ----------\n    :param corpus: text list to be analysed [type: list or pd.Series]\n    :param ngram_range: ngrams to be extracted from corpus [type: tuple, default=(1, 1)]\n    :param n: limits the returning of only the top N ngrams [type: int, default=-1]\n        *in case of n=-1, all ngrams will be returned\n    :param cached_stopwords: stopwords to be used on filtering words \n        *[type: list, default=stopwords.words('english')]\n    :param **kwargs: additional parameters\n        :arg width: wordcloud width [type: int, default=1280]\n        :arg height: wordcloud height [type: int, default=720]\n        :arg random_state: random seed for word positioning [type: int, defualt=42]\n        :arg colormap: colormap for wordcloud chart [type: string, default='viridis']\n        :arg background_color: wordcloud background color [type: string, default='white']\n        :arg mask: either an internet image url or an image array for using as mask\n            *[type: string or array, default=None]\n        :arg figsize: figure dimension [type: tuple, default=(20, 17)]\n        :arg ax: matplotlib axis in case of external figure defition [type: mpl.Axes, default=None]\n        :arg title: chart title [type: string, default=f'Custom WordCloud Plot']\n        :arg size_title: title size [type: int, default=18]\n        :arg save: flag for saving the image created [type: bool, default=None]\n        :arg output_path: path for image to be saved [type: string, default='output\/']\n        :arg img_name: filename for image to be saved \n            [type: string, default='wordcloud.png']\n        \n    Return\n    ------\n    This function returns nothing besides the plot of a custom wordcloud\n    \n    Application\n    -----------\n    plot_wordcloud(corpus=df['text_attribute'])\n    \"\"\"\n    \n    # Extracting kwargs for generating a wordcloud\n    width = kwargs['width'] if 'width' in kwargs else 1280\n    height = kwargs['height'] if 'height' in kwargs else 720\n    random_state = kwargs['random_state'] if 'random_state' in kwargs else 42\n    colormap = kwargs['colormap'] if 'colormap' in kwargs else 'viridis'\n    background_color = kwargs['background_color'] if 'background_color' in kwargs else 'white'\n    mask = kwargs['mask'] if 'mask' in kwargs else None\n    \n    # Generating a pre configured wordcloud\n    wordcloud = generate_wordcloud(corpus=corpus, ngram_range=ngram_range, n=n, \n                                   cached_stopwords=cached_stopwords, width=width, height=height,\n                                   random_state=random_state, colormap=colormap, \n                                   background_color=background_color, mask=mask)\n    \n    # Extracting kwargs for figure plotting\n    figsize = kwargs['figsize'] if 'figsize' in kwargs else (20, 17)\n    ax = kwargs['ax'] if 'ax' in kwargs else None\n    title = kwargs['title'] if 'title' in kwargs else f'Custom WordCloud Plot'\n    size_title = kwargs['size_title'] if 'size_title' in kwargs else 18\n    \n    # Creating figure and plotting wordcloud\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)  \n    ax.imshow(wordcloud)\n    ax.axis('off')\n    ax.set_title(title, size=size_title, pad=20)\n    \n    # Saving image if applicable\n    if 'save' in kwargs and bool(kwargs['save']):\n        output_path = kwargs['output_path'] if 'output_path' in kwargs else 'output\/'\n        img_name = kwargs['img_name'] if 'img_name' in kwargs else f'wordcloud.png'\n        save_fig(fig=fig, output_path=output_path, img_name=img_name)\n\n# Plotting a bar chart for a ngram count \ndef plot_ngram_count(corpus, ngram_range=(1, 1), n=20, cached_stopwords=stopwords.words('english'),\n                     **kwargs):\n    \"\"\"\n    Plots a bar chart for a ngram count\n    \n    Parameters\n    ----------\n    :param corpus: text list to be analysed [type: list or pd.Series]\n    :param ngram_range: ngrams to be extracted from corpus [type: tuple, default=(1, 1)]\n    :param n: limits the returning of only the top N ngrams [type: int, default=20]\n        *in case of n=-1, all ngrams will be returned - be careful!\n    :param cached_stopwords: stopwords to be used on filtering words \n        *[type: list, default=stopwords.words('english')]\n    :param **kwargs: additional parameters\n        :arg x: x axis attribute on chart [type: string, default='count']\n        :arg y: y axis attribute on chart [type: string, default='ngram']\n        :arg figsize: figure dimension [type: tuple, default=(20, 17)]\n        :arg ax: matplotlib axis in case of external figure defition [type: mpl.Axes, default=None]\n        :arg title: chart title [type: string, default=f'Custom WordCloud Plot']\n        :arg size_title: title size [type: int, default=18]\n        :arg save: flag for saving the image created [type: bool, default=None]\n        :arg output_path: path for image to be saved [type: string, default='output\/']\n        :arg img_name: filename for image to be saved \n            [type: string, default='wordcloud.png']\n        \n    Return\n    ------\n    This function returns nothing besides the plot of a custom wordcloud\n    \n    Application\n    -----------\n    plot_ngram_count(corpus=df['text_attribute'])\n    \"\"\"\n    \n    # Generating a DataFrame with ngrams count\n    df_count = ngrams_count(corpus=corpus, ngram_range=ngram_range, n=n, \n                            cached_stopwords=cached_stopwords)\n    \n    # Extracting kwargs for figure plotting\n    x = kwargs['x'] if 'x' in kwargs else 'count'\n    y = kwargs['y'] if 'y' in kwargs else 'ngram'\n    figsize = kwargs['figsize'] if 'figsize' in kwargs else (20, 17)\n    ax = kwargs['ax'] if 'ax' in kwargs else None\n    palette = kwargs['palette'] if 'palette' in kwargs else 'viridis'\n    title = kwargs['title'] if 'title' in kwargs else f'$n{ngram_range[0]}gram$ Count on Corpus'\n    size_title = kwargs['size_title'] if 'size_title' in kwargs else 18\n    \n    # Creating figure and plotting wordcloud\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)  \n    sns.barplot(x=x, y=y, data=df_count, ax=ax, palette=palette)\n    ax.set_title(title, size=size_title, pad=20)\n    \n    # Customizing axis\n    format_spines(ax)\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n    plt.setp(ax.get_yticklabels(), fontsize=16)\n    \n    # Tighting layout\n    plt.tight_layout()\n    \n    # Saving image if applicable\n    if 'save' in kwargs and bool(kwargs['save']):\n        output_path = kwargs['output_path'] if 'output_path' in kwargs else 'output\/'\n        img_name = kwargs['img_name'] if 'img_name' in kwargs else f'wordcloud.png'\n        save_fig(fig=fig, output_path=output_path, img_name=img_name)","826c89c3":"# Plotting a custom wordcloud\nplot_wordcloud(df['description'])","32e58537":"# Plotting a wordcloud with background image\nurl_mask = 'https:\/\/cdn4.iconfinder.com\/data\/icons\/logos-and-brands-1\/512\/227_Netflix_logo-512.png'\nplot_wordcloud(df['description'], mask=url_mask, colormap='Reds_r',\n               title='A Custom WordCloud for Netflix Titles Description')","329f9974":"# Plotting ngrams charts\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(17, 12))\nplot_ngram_count(df['description'], ngram_range=(1, 1), ax=axs[0], palette='Blues_r',\n                 title='$Unigrams$ Count on Netflix Titles Description')\nplot_ngram_count(df['description'], ngram_range=(2, 2), ax=axs[1], palette='Greens_r',\n                 title='$Bigrams$ Count on Netflix Titles Description')","acbd5a31":"# Plotting and customizing a rating analysis\nplot_countplot(df, 'rating', order=True, figsize=(17, 10),\n               title='A Rating Analysis on Netflix Titles', size_title=18)\nplt.xticks(fontsize=16)\nplt.show()","b42f9260":"# Plotting and customizing a rating analysis\nplot_countplot(df, 'rating', hue='type', order=True, figsize=(17, 10), palette=['crimson', 'dimgrey'],\n               title='A Rating Analysis on Netflix Titles by Type', size_title=18)\nplt.xticks(fontsize=16)\nplt.show()","9085f7fe":"# Applying encoding on raw data\ntype_encoding = pd.get_dummies(df['type'])\ndf_type = df.merge(type_encoding, left_index=True, right_index=True)\n\n# Dropping old column\ndf_type.drop('type', axis=1, inplace=True)\ndf_type.loc[:, ['title', 'Movie', 'TV Show']].head()","145d5a3b":"# Defining a function for extracting top N from a column\ntop10_dir = list(df_type['director'].value_counts()[:10].index)\ntop50_dir = list(df_type['director'].value_counts()[:50].index)\ntop100_dir = list(df_type['director'].value_counts()[:100].index)\n\n# Creating a copy of previous DataFrame for keeping log of transformations\ndf_dir = df_type.copy()\n\n# Creating flags for top directors\ndf_dir['is_top10_director'] = df_dir['director'].apply(lambda x: 1 if x in top10_dir else 0)\ndf_dir['is_top50_director'] = df_dir['director'].apply(lambda x: 1 if x in top50_dir else 0)\ndf_dir['is_top100_director'] = df_dir['director'].apply(lambda x: 1 if x in top100_dir else 0)\ndf_dir['top_director_sum'] = df_dir['is_top10_director'] + df_dir['is_top50_director'] + df_dir['is_top100_director']\ndf_dir['is_top_director'] = df_dir['top_director_sum'].apply(lambda x: 1 if x > 0 else x)\n\n# Results\ndf_dir.loc[10:20, ['title', 'director', 'is_top_director', 'is_top10_director', 'is_top50_director', \n                   'is_top100_director']]","44b9d3df":"# Creating a copy of previous DataFrame for keeping log of transformations\ndf_cast = df_dir.copy()\n\n# Extracting how many people are part of the show\ndf_cast['cast_list'] = df_cast['cast'].fillna('').apply(lambda x: x.split(','))\ndf_cast['people_on_cast'] = df_cast['cast_list'].apply(lambda x: len(x))\n\n# Deleting auxiliar cast list column\ndf_cast.drop('cast_list', axis=1, inplace=True)\n\n# Results\ndf_cast.loc[:5, ['title', 'cast', 'people_on_cast']]","8021ab42":"# Extracting a list from cast column\ncast_list = extract_list_from_string(''.join(list(df_prep['cast'].fillna(' ').values)))\n\n# Extracting top 10, 30 and 50 actors from cast list\ntop_actors = pd.DataFrame(cast_list, columns=['actor'])\ntop10_actors = top_actors.head(10)['actor'].values\ntop30_actors = top_actors.head(30)['actor'].values\ntop50_actors = top_actors.head(50)['actor'].values\n\n# Defining a function for counting how many actors are on top list\ndef count_actors_on_top_list(cast_list, top_actors_list):\n    try:\n        return len([act for act in cast_list if act in top_actors_list])\n    except TypeError as te:\n        return 0\n\n# Returning the new features\ndf_cast['actors_on_top10_cast'] = df_cast['cast'].apply(lambda x: count_actors_on_top_list(extract_list_from_string(x), top10_actors))\ndf_cast['actors_on_top30_cast'] = df_cast['cast'].apply(lambda x: count_actors_on_top_list(extract_list_from_string(x), top30_actors))\ndf_cast['actors_on_top50_cast'] = df_cast['cast'].apply(lambda x: count_actors_on_top_list(extract_list_from_string(x), top50_actors))\n\n# Results\ndf_cast.sort_values(by='actors_on_top50_cast', ascending=False).head().loc[:, ['title', 'cast', \n                                                                               'people_on_cast', \n                                                                               'actors_on_top10_cast', \n                                                                               'actors_on_top30_cast',\n                                                                               'actors_on_top50_cast']]","c235cb94":"# Making a copy of the data\ndf_country = df_cast.copy()\n\n# Extracting how many countries the title are part\ndf_country['country_list'] = df_country['country'].fillna('').apply(lambda x: x.split(','))\ndf_country['num_countries'] = df_country['country_list'].apply(lambda x: len(x))\n\n# Extracting a unique list of countries\ncountry_list = extract_list_from_string(','.join(list(df['country'].fillna('Unknown').values)))\ncountries_info = pd.DataFrame(pd.DataFrame(country_list, columns=['country_name']).value_counts())\ncountries_info.reset_index(inplace=True)\ncountries_info.columns = ['country_name', 'num_titles']\n\n# Joining with country codes from pycountry-convert\ncountries_info['codes'] = countries_info['country_name'].apply(lambda x: get_country_info(x))\ncountries_info['continent'] = countries_info['codes'].apply(lambda x: x[2])\n\n# Joining with source dataset\ndf_country = df_country.merge(countries_info.loc[:, ['country_name', 'continent']], \n                              how='left', left_on='country', right_on='country_name')\n\n# Null values on new continent column are from titles assigned for more than 1 country\ndf_country.loc[:, ['continent']] = df_country.loc[:, ['continent']].fillna('Multiple')\n\n# Finally encoding the new continen column\ncountries_encoded = pd.get_dummies(df_country['continent'], prefix='continent')\ndf_country = df_country.merge(countries_encoded, how='left', left_index=True, right_index=True)\n\n# Dropping auxiliar columns\ndf_country.drop(['country_list', 'country_name', 'continent'], axis=1, inplace=True)\n\n# Results\ncountry_new_features = ['continent_AF', 'continent_AS', 'continent_EU', 'continent_Multiple',\n                        'continent_NA', 'continent_OC', 'continent_SA', 'continent_Unknown']\ndf_country.loc[:5, ['title', 'country'] + country_new_features]","4c584a0a":"# Extracting top N countries list\ntop3_countries = countries_info.query('country_name != \"Unknown\"').head(3)['country_name'].values\ntop5_countries = countries_info.query('country_name != \"Unknown\"').head(5)['country_name'].values\ntop10_countries = countries_info.query('country_name != \"Unknown\"').head(10)['country_name'].values\n\n# Defining a function for counting how many actors are on top list\ndef flag_country_on_top(country_list, top_country_list):\n    try:\n        return len([c for c in country_list if c in top_country_list])\n    except TypeError as te:\n        return 0\n\n# Returning the new features\ndf_country['country_on_top3'] = df_country['country'].apply(lambda x: flag_country_on_top(extract_list_from_string(x), top3_countries))\ndf_country['country_on_top5'] = df_country['country'].apply(lambda x: flag_country_on_top(extract_list_from_string(x), top5_countries))\ndf_country['country_on_top10'] = df_country['country'].apply(lambda x: flag_country_on_top(extract_list_from_string(x), top10_countries))\n\n# Results\ndf_country.head().loc[:, ['title', 'country', 'country_on_top3', 'country_on_top5', 'country_on_top10']]","7786c03d":"# Making a copy of the last changed dataset\ndf_date = df_country.copy()\n\n# Result cols\ndate_cols = ['title', 'date_added', 'day_added', 'month_added', 'year_added', 'quarter_added', \n             'semester_added', 'days_on_catalog', 'months_on_catalog', 'years_on_catalog', 'release_year', \n             'title_age_years']\n\n# Transforming the date add column into a datetime format\ndf_date['dt_added'] = pd.to_datetime(df_date['date_added'])\ndf_date['day_added'] = df_date['dt_added'].apply(lambda x: x.day)\ndf_date['month_added'] = df_date['dt_added'].apply(lambda x: x.month)\ndf_date['year_added'] = df_date['dt_added'].apply(lambda x: x.year)\ndf_date['quarter_added'] = df_date['month_added'].apply(lambda x: np.ceil(x \/ 4))\ndf_date['semester_added'] = df_date['month_added'].apply(lambda x: 1 if x <= 6 else 2)\n\n# Setting snapshot date\ndf_date['catalog_date'] = df_date['dt_added'].max()\n\n# Computing relative deltas between date added and actual date\ndf_date['days_on_catalog'] = (df_date['catalog_date'] - df_date['dt_added']).dt.days\ndf_date['months_on_catalog'] = df_date['days_on_catalog'].apply(lambda x: round(x \/ 30, 0))\ndf_date['years_on_catalog'] = df_date['months_on_catalog'].apply(lambda x: np.floor(x \/ 12))\ndf_date['title_age_years'] = df_date['catalog_date'].dt.year - df_date['release_year']\n\n# Results\ndf_date.head(10).loc[:, date_cols]","4183adbc":"# Results cols\ncat_date_cols = ['title', 'catalog_year', 'release_year', 'years_to_add_on_cat',\n                 'added_on_release_year']\n\n# New features\ndf_date['catalog_year'] = df_date['catalog_date'].apply(lambda x: x.year)\ndf_date['years_to_add_on_cat'] = df_date['catalog_year'] - df_date['release_year']\ndf_date['added_on_release_year'] = df_date['years_to_add_on_cat'].apply(lambda x: 1 if x == 0 else 0)\n\n# Results\ndf_date.head().loc[:, cat_date_cols]","a116bf92":"# Catalog addition on same year of release\ndf_date.sort_values(by='added_on_release_year', ascending=False).head().loc[:, cat_date_cols]","aa0c07c4":"# Making another copy of the original dataframe\ndf_listed = df_date.copy()\n\n# Results cols\nlisted_cols = ['title', 'listed_in', 'num_diff_types', 'top_listed_in',\n               'listed_in_Dramas', 'listed_in_Independent Movies', 'listed_in_International Movies',\n               'listed_in_Other']\n\n# Extracting a list of different titles type\nlisted_in_list = extract_list_from_string(' '.join(list(df_listed['listed_in'].fillna('').values)))\ndf_listed['listed_in_list'] = df_listed['listed_in'].fillna('').apply(lambda x: x.split(','))\ndf_listed['num_diff_types'] = df_listed['listed_in_list'].apply(lambda x: len(x))\n\n# Extracting the top listed in types\ntop_n = 5\ntop_listed_in = list(pd.DataFrame(listed_in_list, columns=['type']).value_counts().index[:top_n])\ntop_listed_in = [t[0] for t in top_listed_in]\ndf_listed['top_listed_in'] = df_listed['listed_in'].apply(lambda x: x if x in top_listed_in else 'Other')\n\n# Applying encoding on top listed in elements\ndf_listed = df_listed.merge(pd.get_dummies(df_listed['top_listed_in'], prefix='listed_in'),\n                            how='left', left_index=True, right_index=True)\n\n# Results\ndf_listed.head().loc[:, listed_cols]","ac22890d":"# Making a copy of the dataframe\ndf_duration = df_listed.copy()\n\n# Result cols\ndur_cols = ['title', 'duration', 'duration_num']\n\n# Extracting numerical info for title duration\ndf_duration['duration_num'] = df_duration['duration'].apply(lambda x: int(x.split(' ')[0]))\n\n# Results\ndf_duration.head().loc[:, dur_cols]","f3491e85":"# Splitting data by its type\nmovies = df_duration[df_duration['Movie'] == 1]\ntvshows = df_duration[df_duration['TV Show'] == 1]\n\n# Columns to be dropped\nto_drop = ['title', 'show_id', 'director', 'cast', 'country', 'date_added', 'rating', 'duration', \n           'dt_added', 'catalog_date', 'catalog_year', 'listed_in', 'description', 'listed_in_list', \n           'top_listed_in', 'year_added', 'Movie', 'TV Show', 'release_year']\n\n# Dropping columns\nX_movies = movies.drop(to_drop, axis=1)\nX_tvshows = tvshows.drop(to_drop, axis=1).dropna()\n\n# Preview of dataframes\nprint(f'Shape of movies data: {X_movies.shape}')\nprint(f'Shape of tv shows data: {X_tvshows.shape}')\n\nX_movies.head()","a397e7b5":"# Importing libraries\nfrom sklearn.decomposition import PCA\nfrom xplotter.formatter import format_spines\n\n# Creating a PCA with 2 components\npca = PCA(n_components=2)\nX_movies_2d = pca.fit_transform(X_movies)\nX_movies_2d = pd.DataFrame(X_movies_2d, columns=['dim_01', 'dim_02'])\n\n# Plotting the new 2D data\nfig, ax = plt.subplots(figsize=(17, 10))\nsns.scatterplot(x='dim_01', y='dim_02', data=X_movies_2d, alpha=.5, color='dimgrey', s=80)\n\n# Customizing chart\nformat_spines(ax)\nax.set_title('Representation of Netflix Movies in a 2D Array - PCA Results', size=18)\n\n# Sorting movies by dim 01\nsorted_movies_dim01 = X_movies_2d.sort_values(by='dim_01', ascending=False)\nsorted_movies_dim02 = X_movies_2d.sort_values(by='dim_02', ascending=False)\n\n# Retrieving top 3 movies by dim 01\ntop01_dim01_movie = movies.iloc[sorted_movies_dim01.index[0], :].title\ntop02_dim01_movie = movies.iloc[sorted_movies_dim01.index[1], :].title\ntop03_dim01_movie = movies.iloc[sorted_movies_dim01.index[2], :].title\n\n# Retrieving top 1 movies by dim 02\ntop01_dim02_movie = movies.iloc[sorted_movies_dim02.index[0], :].title\n\n# Making annotations\nax.annotate(top01_dim01_movie, xy=(sorted_movies_dim01['dim_01'].values[0]-300, \n                                   sorted_movies_dim01['dim_02'].values[0]-15), xycoords='data')\nax.annotate(top02_dim01_movie, xy=(sorted_movies_dim01['dim_01'].values[1]-300, \n                                   sorted_movies_dim01['dim_02'].values[1]+7), xycoords='data')\nax.annotate(top03_dim01_movie, xy=(sorted_movies_dim01['dim_01'].values[2]-300, \n                                   sorted_movies_dim01['dim_02'].values[2]+7), xycoords='data')\nax.annotate(top01_dim02_movie, xy=(sorted_movies_dim02['dim_01'].values[0]+50, \n                                   sorted_movies_dim02['dim_02'].values[0]), xycoords='data')\n\nplt.show()","98c4ee60":"# Creating a PCA with 2 components\npca = PCA(n_components=2)\nX_tvshows_2d = pca.fit_transform(X_tvshows)\nX_tvshows_2d = pd.DataFrame(X_tvshows_2d, columns=['dim_01', 'dim_02'])\n\n# Plotting the new 2D data\nfig, ax = plt.subplots(figsize=(17, 10))\nsns.scatterplot(x='dim_01', y='dim_02', data=X_tvshows_2d, alpha=.5, color='crimson', s=80)\n\n# Customizing chart\nformat_spines(ax)\nax.set_title('Representation of Netflix TV Shows in a 2D Array - PCA Results', size=18)\n\n# Sorting movies by dim 01\nsorted_tvshows_dim01 = X_tvshows_2d.sort_values(by='dim_01', ascending=False)\nsorted_tvshows_dim02 = X_tvshows_2d.sort_values(by='dim_02', ascending=False)\n\n# Retrieving top 3 movies by dim 01\ntop01_dim01_tvshow = tvshows.iloc[sorted_tvshows_dim01.index[0], :].title\ntop02_dim01_tvshow = tvshows.iloc[sorted_tvshows_dim01.index[1], :].title\ntop03_dim01_tvshow = tvshows.iloc[sorted_tvshows_dim01.index[2], :].title\n\n# Retrieving top 1 movies by dim 02\ntop01_dim02_tvshow = movies.iloc[sorted_tvshows_dim02.index[0], :].title\n\n# Making annotations\nax.annotate(top01_dim01_tvshow, xy=(sorted_tvshows_dim01['dim_01'].values[0], \n                                   sorted_tvshows_dim01['dim_02'].values[0]-2), xycoords='data')\nax.annotate(top02_dim01_tvshow, xy=(sorted_tvshows_dim01['dim_01'].values[1]+70, \n                                   sorted_tvshows_dim01['dim_02'].values[1]), xycoords='data')\nax.annotate(top03_dim01_tvshow, xy=(sorted_tvshows_dim01['dim_01'].values[2]+70, \n                                   sorted_tvshows_dim01['dim_02'].values[2]), xycoords='data')\nax.annotate(top01_dim02_tvshow, xy=(sorted_tvshows_dim02['dim_01'].values[0]+70, \n                                   sorted_tvshows_dim02['dim_02'].values[0]), xycoords='data')\n\nplt.show()","e921df9e":"Well, it seems that [Anupam Kher](https:\/\/www.google.com\/search?channel=fs&client=ubuntu&q=anupam+kher) is the actor who appears most considering the names on cast for all titles on Netflix catalog. Other common names includes [Takahiro Sakurai](https:\/\/www.google.com\/search?q=takahiro+sakurai&client=ubuntu&channel=fs&sxsrf=ALeKk02W_E6eaQ-4u8mhkSsoKZ477L3LWA%3A1621031057565&ei=kfieYILyIYbK_Qa38LeIDw&oq=takahiro+sakurai&gs_lcp=Cgdnd3Mtd2l6EAMyCAguEMsBEJMCMgIIADICCAAyAggAMgIIADIFCAAQywEyBQgAEMsBMgUIABDLATIFCAAQywEyBQgAEMsBOgcIABCwAxBDOg0ILhCwAxDIAxBDEJMCOgoILhCwAxDIAxBDOgYIIxAnEBM6BAgjECc6CAgAELEDEIMBOgQILhBDOgQIABBDOgUIABCxAzoFCC4QsQM6AgguOgcILhCxAxBDOgsIABCxAxDHARCjAjoHCAAQsQMQQzoKCC4QsQMQQxCTAjoLCAAQsQMQxwEQrwE6DggAELEDEIMBEMcBEKMCOggIABDHARCvAToICC4QsQMQkwI6BQguEMsBOgoILhCxAxANEJMCOgQILhANOgQIABANOgoIABDHARCvARANOgYIABANEAo6BggAEA0QHjoFCC4QkwJKBQg4EgExUJ-pA1jjwQNgzsIDaAZwAHgAgAGPAogBoSGSAQcwLjEwLjEwmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&sclient=gws-wiz&ved=0ahUKEwjC_uuim8rwAhUGZd8KHTf4DfEQ4dUDCA0&uact=5), [Om Puri](https:\/\/www.google.com\/search?q=om+puril&client=ubuntu&channel=fs&sxsrf=ALeKk02tU6yaTTUh61J9MO8idU-5KAEO-g%3A1621031117221&ei=zfieYNDwDM2m_QaG-oeACw&oq=om+puril&gs_lcp=Cgdnd3Mtd2l6EAMyBQguEJMCMgIIADICCAAyBQgAEMsBMgUIABDLATIFCAAQywEyBQgAEMsBMgUIABDLATIFCAAQywEyBQgAEMsBOgcIABCwAxBDOg0ILhCwAxDIAxBDEJMCOgoILhCwAxDIAxBDOgQIIxAnOgQILhBDOgQIABBDOggIABCxAxCDAToFCAAQsQM6CAguELEDEIMBOg4IABCxAxCDARDHARCvAToFCC4QsQM6AgguOggIABDHARCvAToECAAQCkoFCDgSATFQg1NY_1hg9VloAXAAeACAAf8BiAH2DJIBBTAuNC40mAEAoAEBqgEHZ3dzLXdpesgBB8ABAQ&sclient=gws-wiz&ved=0ahUKEwiQi6W_m8rwAhVNU98KHQb9AbAQ4dUDCA0&uact=5), [Paresh Rawal](https:\/\/www.google.com\/search?q=paresh+rawal&client=ubuntu&channel=fs&sxsrf=ALeKk03hYI6kzOgZbADhHQzKw4qs44Q6Wg%3A1621031130346&ei=2vieYLymFOzB_Qa516eQBw&oq=paresh+rawal&gs_lcp=Cgdnd3Mtd2l6EAMyBQguEJMCMgUIABDLATIFCAAQywEyBQgAEMsBMgUIABDLATIFCAAQywEyBQgAEMsBMgUIABDLATIFCAAQywEyBQgAEMsBOgoILhCwAxANEJMCOgcIABCwAxANOgkIABCwAxANEB46BggjECcQEzoECCMQJzoECAAQQzoICC4QsQMQgwE6CAgAELEDEIMBOgUILhCxAzoCCAA6BQgAELEDOgIILjoKCAAQxwEQrwEQQzoICAAQxwEQrwE6BwguEEMQkwI6CggAEMcBEK8BEAo6BAgAEAo6BQguEMsBUJc_WOtKYNBLaAFwAHgAgAGTAogBkRKSAQUwLjIuOZgBAKABAaoBB2d3cy13aXrIAQrAAQE&sclient=gws-wiz&ved=0ahUKEwi8-8XFm8rwAhXsYN8KHbnrCXIQ4dUDCA0&uact=5), [Andrea Libman](https:\/\/www.google.com\/search?q=andrea+libman&client=ubuntu&channel=fs&sxsrf=ALeKk00b0gfagSmkefMKaTXJKaNkFzZcWg%3A1621031142040&ei=5vieYM_EAe6mggfZhqfoDw&oq=andrea+libman&gs_lcp=Cgdnd3Mtd2l6EAMyBQguEJMCMgUIABDLATIFCAAQywEyBQgAEMsBMgUIABDLATIFCAAQywEyBQgAEMsBMgUIABDLATIFCAAQywEyBQgAEMsBOgcIABCwAxBDOgkIABCwAxAHEB46CAgAELADEMsBOg0ILhCwAxDIAxBDEJMCOgoILhCwAxDIAxBDOgQIIxAnOgQILhBDOgUIABCxAzoFCC4QsQM6CAguELEDEIMBOgIIADoICC4QsQMQkwI6CAgAELEDEIMBOgIILjoHCC4QsQMQCjoICAAQxwEQrwE6CwguELEDEIMBEJMCOgQILhAKOgcILhAKEMsBSgUIOBIBMVDRXliTaGCWaWgBcAB4AIABjAKIAZgUkgEGMC4xLjExmAEAoAEBqgEHZ3dzLXdpesgBD8ABAQ&sclient=gws-wiz&ved=0ahUKEwjPz4_Lm8rwAhVuk-AKHVnDCf0Q4dUDCA0&uact=5), [Kareena Kappor](https:\/\/www.google.com\/search?q=kareena+kapoor&client=ubuntu&hs=s73&channel=fs&sxsrf=ALeKk02svmj1JyDSY8f2YcxpKAz28KYK3Q%3A1621029439287&ei=P_KeYIPkEPK6ggeRj4uAAg&gs_ssp=eJzj4tTP1TcwMjc1yzJg9OLLTixKTc1LVMhOLMjPLwIAZtUIWQ&oq=kareena+kap&gs_lcp=Cgdnd3Mtd2l6EAMYADIICC4QywEQkwIyBQgAEMsBMgUIABDLATICCAAyAggAMgIIADICCAAyBQgAEMsBMgUIABDLATIFCAAQywE6CQgAELADEAcQHjoHCAAQsAMQQzoFCAAQsAM6DQguELADEMgDEEMQkwI6CgguELADEMgDEEM6BwguEEMQkwI6BAguEEM6BAgjECc6BQguELEDOgIILjoICC4QsQMQgwE6BQgAELEDOggIABCxAxCDAToICC4QsQMQkwI6BAguEAo6CAgAEMcBEK8BOgcILhANEJMCOgQIABANSgUIOBIBMVD7wWJYhc5iYL_UYmgCcAB4AIABpgKIAeEWkgEGMC4xLjEymAEAoAEBqgEHZ3dzLXdpesgBCcABAQ&sclient=gws-wiz) and others.\n\nLooking at the names on the chart includes actors, actresses, voice actors and voice actresses and everyone who ever made part of the movie or show. By talking on that, it would be nice to see the cast appearence for each type of tile (movies and TV shows). So the chart above will apply this analysis by counting people appearence only on movies (left - gray) and only on TV shows (right - red)","85d06b17":"After extracting all informations needed for working with countries, let's plot a map using the `folium` library that can answear the question: _how titles in Netflix catalog are distributed around the world?_ With the dataset above we could see the numbers in a table format (the DataFrame was already sorted by `num_titles`), but with maps we can visually see this answear in a more beautiful format.","910ecf4e":"<a id=\"4.1\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>4.1 New Features From \"type\" Column<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","f9fa6449":"<a id=\"3.8\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>3.8 Ratings on Netflix Catalog<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","2cf7aa04":"Ok. After doing a lot on feature extraction on this Netflix dataset, we built up a brand new dataset with features that can be used in some modeling step. On this last topic, we will split the whole data into two dataframes:\n\n- A movies dataframe;\n- A TV Show dataframe;\n\nThe idea is to get close to these two types of titles on Netflix catalog and maybe construct a clustering model to take a deeper look on those. Maybe we can find some new insights on how movies and TV shows can be grouped using unsupervised approaches.","ed1ffe9a":"___\n* **_Top 5 TV shows with most seasons_**\n___","8b3efdae":"On the road for gathering insights from Netflix titles dataset, let's take a deep dive on the `listed_in` column to extract some trends or patterns on how the catalog are distributed in termos of movies and TV shows types. There are more dramas than thrillers? How about comedy and cult movies?","565c135e":"<a id=\"1\"><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>1. Libraries and Project Variables<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","8dbfe893":"With this we can finish this intensive preparation step. At the end, we built a very intuitive dataset for each title type: movies and TV shows. After this, let's explore the application of a clustering algorithm for creating new groups for movies and TV shows to better understanding how titles can be grouped in a multidimensional space.","2b284c2c":"Now it seems we have a different scenario. By looking at the numbers, it's possible to see that [Anupam Kher](https:\/\/www.google.com\/search?channel=fs&client=ubuntu&q=anupam+kher) made 36 appearence on total and 25 of them were on movies. He's not like to beeing found on TV shows. Meanwhile, [Takahiro Sakurai](https:\/\/www.google.com\/search?q=takahiro+sakurai&client=ubuntu&channel=fs&sxsrf=ALeKk02W_E6eaQ-4u8mhkSsoKZ477L3LWA%3A1621031057565&ei=kfieYILyIYbK_Qa38LeIDw&oq=takahiro+sakurai&gs_lcp=Cgdnd3Mtd2l6EAMyCAguEMsBEJMCMgIIADICCAAyAggAMgIIADIFCAAQywEyBQgAEMsBMgUIABDLATIFCAAQywEyBQgAEMsBOgcIABCwAxBDOg0ILhCwAxDIAxBDEJMCOgoILhCwAxDIAxBDOgYIIxAnEBM6BAgjECc6CAgAELEDEIMBOgQILhBDOgQIABBDOgUIABCxAzoFCC4QsQM6AgguOgcILhCxAxBDOgsIABCxAxDHARCjAjoHCAAQsQMQQzoKCC4QsQMQQxCTAjoLCAAQsQMQxwEQrwE6DggAELEDEIMBEMcBEKMCOggIABDHARCvAToICC4QsQMQkwI6BQguEMsBOgoILhCxAxANEJMCOgQILhANOgQIABANOgoIABDHARCvARANOgYIABANEAo6BggAEA0QHjoFCC4QkwJKBQg4EgExUJ-pA1jjwQNgzsIDaAZwAHgAgAGPAogBoSGSAQcwLjEwLjEwmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&sclient=gws-wiz&ved=0ahUKEwjC_uuim8rwAhUGZd8KHTf4DfEQ4dUDCA0&uact=5) appeared 27 times overall but 21 of them were on TV shows.\n\nHow about directors? Let's see the top 10 directors with more appearence on Netflix catalog.","951f5957":"The age distribution of titles on the catalog are similar between movies and TV shows. One thing that can be pointed out is that movies are usually older than TV shows in terms of duration on catalog. We can see this by the boxtplot on the right where we have some outliers indicating really old movies (the median also reflects this behavior).","c5f3655a":"This topic will be responsible for allocating efforts on gathering insights from the Netflix data with useful tools built in `xplotter` Python package. As the project goes on, it will be possible to use the functions of `xplotter` for plotting some good charts that can be served for visualizing insights in beautiful and informative ways.\n\nFor presenting a good storytelling on this task, let's divide the Exploratory Data Analysis into subtopics, each one consisting on subjects that can generate good discussions and conclusions. So, let's not only write codes and plot charts, but discuss around them and use them as powerful tools for helping us on reaching our analysis goals. Let's go!","9aa51a74":"<a id=\"3.7\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>3.7 Can Netflix Draw our Attention Just by Titles Description?<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","9de60042":"<a id=\"3\"><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>3. EDA: Exploring Insights with xplotter<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","13d51dde":"<a id=\"4\"><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>4. Prep: Transforming the Data for a More Insights<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","2bc0bd27":"It seems like India is the country the provides movies to Netflix with highest duration (at the same time, the average number of seasons of Indian TV shows are quite low). On the other hand, we can see that Canada usually provides TV shows to Netflix with a high number of seasons in average.\n\nLet's go ahead with our exploration and take a look at new questions to be answeared with data.","7ba17a39":"___\n* **_Top 5 TV shows with most days on catalog_**\n___","e0be0719":"<a id=\"4.5\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>4.5 New Features From \"date_added\" Column<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","f0559440":"Wow nice! We just used the source `country` column on the dataset for extracting useful information about the continent with dummies encoding already applied. Those features combo good be important for further analysis, recommendation system or clusters creation from titles! Additionaly, we created a step for handling titles with more than one column assigned (it is represented by `continent_multiple_country` encoded feature).\n\nNow let's try to extract something similar we did on cast features and build up a code for looking the top 3, top 5 and top 10 countries for creating new features.","a239a647":"On this topic, let's explore the column `country` which says where the title comes from. On this scenario, it will be possible to visualize Netflix catalog from a global perspective. In a first step, let's extract the correct information of country by looking at each individual country on the column, even if it's given by a string splitted by comma.","399f2d34":"As a preprocessing step for a further clustering algorithm, let's take our almost 40-dimensional data and reduce its dimensionality for looking at it in a 2D or maybe 3D perspective. Maybe it could be a good improvement for a further KMeans algorithm.\n\nFor this, let's use the `PCA` algorithm from sklearn and make the reducting for either DataFrames for movies and tv shows.","f845ea57":"<a id=\"3.6\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>3.6 Dramas or Comedies? How Are Netflix Titles Listed In?<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","123c19f8":"<a id=\"4.3\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>4.3 New Features From \"cast\" Column<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","68bb9dbf":"Ok! Maybe in the future it would be nice to see titles that were added on catalog by the same year it were released. That could be a new proxy for even the movies or TV Shows provided by Netflix itself.\n\nThe next step will handle the extracting of features from `listed_in` column.","e4fd3918":"<a id=\"4.6\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>4.6 New Features From \"listed_in\" Column<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","7b236a0a":"___  \n`director`\n- Extracting the top N directors and making a categorical grouping\n    * **Idea:** apply encoding after limiting the categorical entries through top N extraction\n    * **Idea:** create an unique flag for saying if title's director are (1) or aren't (0) from top N\n___","4da77906":"___\n`listed_in`\n- Extracting the count of different genders the title is listed in\n- Extracting top N title gender\n    * **Idea:** apply encoding after limiting the categorical entries through top N extracting\n    * **Idea:** create an unique column for storing the count of how many title's gender are part of top N\n___","9a82699b":"The countplot above shows a distribution of people on cast for titles on Netflix catalog. We can see that there are 1,238 titles with 9 people on cast and this is the marjority configuration. A low quantity of titles have more than 15 people on cast.\n\nBut how about actors and actresses? Who are them? Let's make a little change on our dataset and extract who appears most on Netflix catalog.","6dbc3f98":"___\n* **_Top 5 movies with most days on catalog_**\n___","19ee6656":"<a id=\"5\"><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>5. PCA: Reducing the Multidimensional Space<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","6bdd70b1":"Awesome! Now still on text description analysis, let's use another excellent function for measuring a count for each word on the text corpus using *ngrams*. For this purpose, we will analyse two graphs: an unigram extraction and a bigram extraction.\n\nWith this we will see trends like how the words on titles descriptions are given alone (unigram) or in pairs (bigrams).\n\n*Obs: I also tried to use trigrams, but it wasn't very effective, as long as there are no trends os patterns on titles descriptions with three words together*","552fe23c":"___    \n`cast`\n- Counting how many people are part of title's cast\n    * **Idea:** extract a list for each index and counting the elements (people) on this list for each line\n- Extracting top N actors and making a categorical grouping\n    * **Idea:** apply encoding after limiting the categorical entries through top N extracting\n    * **Idea:** create an unique column for storing the count of how many people on title cast are part of top N\n___","9ba1d83b":"___\n* **_Top 5 TV shows recently added on catalog_**\n___","acdca773":"Well, by looking at the Netflix catalog, one good question to be made is: _how long do usually movies and tv shows last on catalog?_ You may have find yourself looking for a title that isn't on catalog anymore or else you probably got yourself surprised by finding some classical title on the list that you didn't expect.\n\nUsing the `date_added` column, let's set up some date for this snapshot (something around max `date_added`) and compute the difference between the date that each title was added do the streaming service and the snapshot date. With this information, it will be possible to see the distribution of titles by its ages.","7ab119df":"It seems like Netflix has (or had) more movies than TV shows in a percentage of 69% against 31% approximately. But this lends us to the next question: _this behavior was always like that?_ For ansewaring this question we should have in hands information about previous years of Netflix catalog but, if we take a look at the **date_added** column, maybe we could make an evolution analysis on how the balance of movies and TV shows showed up for Netflix's customers.","c451d3af":"Maybe the first question that can be in mind by looking at the data is: _does Netflix have more more tv shows or movies?_ This is a good question to answear using the data itself. So let's get our hands dirty and use our first function of `xplotter` for plotting a custom chart for looking at the balance between tv shows and movies.","9da42343":"___\n* **_Top 5 movies with highest duration_**\n___","5f55194d":"<a id=\"3.3\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>3.3 How Many People Compose the Cast and Who are Them?<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","51e1103b":"After going through a complete EDA process in a couple of possibilitties provided by the Netflix dataset, it's time to see if there is a rating analysis to be extracted on movies and TV Shows.\n\nFirst of all, let's see that we've got on the `rating` column on the dataset.","8674b432":"We reacher our goal by extracting some useful features from country column. With those ones, we can clearly see from which continent a Netflix title are from and beyond this we can see if the original country of the title are one of the tops in terms of presence on Netflix catalog.\n\nNow let's dive into `date_added` column for looking for new features based on date transformations.","8457a739":"This notebook aims to allocate the development related to exploratory analysis of insights related to [Netflix Movies and TV Shows](https:\/\/www.kaggle.com\/shivamb\/netflix-shows). Also, this notebook uses the tools presented on [xplotter](https:\/\/github.com\/ThiagoPanini\/xplotter) python package made by myself and published on PyPI repository. This is a real good effort for coding useful functions for making the Exploratory Data Analysis process a lot more easier for Data Scientists and Data Analysis through deliverying charts customization and matplotlib\/seaborn plots with a little few lines of code. I really hope you all enjoy it!\n\n<div align=\"center\">\n    <img src=\"https:\/\/i.imgur.com\/5XFP1Ha.png\" height=300 width=200 alt=\"xplotter Logo\">\n<\/div>\n\n___\n**_Description and context:_**\n_This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine._\n\n_In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service\u2019s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset._\n\n_Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings._\n\n_Some of the interesting questions (tasks) which can be performed on this dataset_\n\n* Understanding what content is available in different countries\n* Identifying similar content by matching text-based features\n* Network analysis of Actors \/ Directors and find interesting insights\n* Is Netflix has increasingly focusing on TV rather than movies in recent years.\n___","076dc455":"<a id=\"4.4\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>4.4 New Features From \"country\" Column<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","55758e6d":"<a id=\"3.1\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>3.1 TV Shows or Movies?<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","59f93afd":"<a id=\"4.2\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>4.2 New Features From \"director\" Column<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","93284ea1":"In one of the most exciting analysis, we can go deeper at the `description` column of the dataset to extract some text trends on how Netflix uses this feature for drawing the public attention. For this, let's use some functions for extracting information from raw text presenting on our dataset.","03df8ca8":"The new three columns available contain information about how many actors on cast are part on top 10, 30 or 50 cast list. It could be a good one for further analysis.","0eb0c4b4":"<a id=\"2\"><\/a>\n<font color=\"darkslateblue\" size=+2.5><b>2. Reading the Data<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","5dc13680":"By now, let's extract information on `duration` column for movies and TV shows for visualizing some patterns on Netflix catalog. The idea is to split the source data on this column in order to extract the numerical value and the scale. Looking at the data, it's possible to see that we have different scales for movies (minutes) and TV shows (seasons) and, because of this, we will plot two different charts for looking at titles duration for this two types.","2e5e2fa0":"Well, knowing Netflix as itself, it's not clearly possible to say that the evolution scenario is 100% real. It's said because movies or TV shows can be eliminated from catalog and, as long as the data is consisted of a catalog snapshot from 2019, there's no way to tell if some movies or tv shows were already eliminated in the past.\n\nMeanwhile, the linchart shows us that, in general, considering this catalog snapshot, the presence of movies are always higher than TV shows. By the way, it seems that the cumulative count of movies added on Netflix is increasing faster than the TV show rate.\n\n> **Note:** the cumulative count chart above is something we must investigate a little deeper because it goes to the opposite way to the affirmative: \"_In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service\u2019s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled._\"","89072d68":"Let's break the count analysis by title type.","855ba739":"By looking at the top titles on the tables above, it raised a idea on also looking at the people who were part of the movies or TV shows. With this we are talking about directors and cast. Let's use the `cast` column for creating a list of cast for each line and counting how many people participated on the movie or TV show creation.","2b0225d5":"Ok, very nice! The `people_on_cast` feature is one of those we took a look before. Let's now improve this \"feature extraction\" process by extracting a list of top 10, top 30 and top 50 actors with most participation on titles. After that, we will look on each title's cast and count how many actors and actresses are part of the top 10, 30 or 50 list.\n\nLet's try to build this.","72ae70cf":"There is another good format to see how is Netflix around the world: by using Choropleth maps.","cfab2e43":"Here we have a custom wordcloud chart for each world on `description` column. From user perspective, it can be said that these are all the words presented on Netflix titles description. Interesting how some words really pop up on eyes, like *life*, *young*, *new* and *love*.\n\nOn the continuous road to improvement, the `plot_wordcloud()` function can be used for plotting a custom wordcloud using a background mask. For this we can pass an image array (in case of reading a local image using PIL, for example) or even passing an internet image url string - the function handles the request by itself. Let's try to use the Netflix logo for customizing even more our WordCloud.","c68c55fa":"Now let's compute some additional features based on `release_year` column of the dataset. Basically, the idea is to iterate over Netflix catalog and see if the titles were added on catalog by the same year they were released - maybe it's a good proxy for \"important\" movies or TV Shows.","e2e1e612":"Maybe it was well known for almost everybody, but our preparation processing showed up Grey's Anatomy and Supernatural as the top two TV shows with most seasons on Netflix catalog. Let's use the country information to see the ones with longest movies and tv shows in average.","5fd30ed6":"Well, using maps is a good way to visualize the spread of Netflix around the world in termos of titles added on the streaming platform. ","e89c83c8":"After extracting useful insights from data on a really extensive session with beautiful and insightful charts, let's purpose a new section for applying transformation on the raw data in order to create new columns and maybe be prepared for a further modeling step.\n\nWho said we can't use this data for creating an unsupervised model for clustering titles and building a recommendation system? For making it formal, let's specify a wall of transformations that could be made using the data available. There are some new features that really could be used on relevant analysis.\n","515bbc91":"___\n`country`\n- Extracting the continent of the title by country name using *pycountry*\n- Extracting top N countries and making a categorical grouping\n    * **Idea:** apply encoding after limiting the categorical entries through top N extraction\n    * **Idea:** create an unique flag for saying if title's country are (1) or aren't (0) from top N\n___","a4b43a14":"___\n`date_added`\n- Extracting date features like:\n    * Month the title was added on catalog\n    * Quarter the title was added on catalog\n    * Four-month the title was added on catalog\n    * Semester the title was added on cataog\n- Extracting the \"title's age\" variable by applying a date diff between the date the title was added on catalog and a date reference (snapshot) of the catalog itseld\n    * Days on catalog\n    * Months on catalog\n    * Quarters on catalog\n    * Semesters on catalog\n    * Years on catalog\n___\n`release_year`\n- Extracting the general age of the title\n- Computing the difference between title release year and the year the title was added on catalog\n    * **Idea:** create a flag column for saying if the title was added on catalog on the same year it was released (maybe this is a good proxy for relevant titles)\n    * **Idea:** difference (in years) between release year and year the title was added on catalog \n___","1e75aa72":"After extracting an age information of the data, many things can be explored. The cells bellow brings us a vision of the top 5 oldest and newst movies and TV shows. Let's see if we are enjoying Netflix the right way!","4f6acb29":"___\n`type`\n- Encoding for creating new columns for *movies* and *tv shows*\n___  ","3e88abd2":"<a id=\"3.2\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>3.2 From the Oldest to the Newest Title<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","aeb4497a":"By the time, we could extract some titles type from listed in column and encoding the top ones. Next let's use the `duration` column for extracting features from movies and TV Shows.","95cef629":"Well done! By looking at the wordclouds above, we have already seen word trends like *life* and *young*. But now looking at bigram chart on the rights, it seems there are a lot of titles on Netflix catalog talking about *high school*, *young man* or woman, *new york*, *small town*, *best friend* and other. Really nice insight!","6fbcd808":"Ok, we can see that *International Movies*, *Dramas* and *Independent Movies* are the top 3 flavours of titles on Netflix. But one thing must be said: when looking at the `listed_in` column, it was possible to look at some \"typos\" on string entries that compose the attribute. The thing is that not all `listed_in` strings are delimited by comma, for example. Some of them were delimitted by space and that's why we can see things like *International Movies Crime TV Shows* in one category and not at least three different ones (maybe the correct was International Movies, Crime and TV Shows as separated categories).","e896378a":"<a id=\"top\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\">Table of Content<\/h3>\n\n* [1. Libraries and Project Variables](#1)\n* [2. Reading the Data](#2)\n* [3. EDA: Exploring Insights with xplotter](#3)\n    - [3.1 TV Shows or Movies](#3.1)\n    - [3.2 From the Oldest to the Newest Title](#3.2)\n    - [3.3 How Many People Compose the Cast and Who are Them?](#3.3)\n    - [3.4 From Where Netlix's Products Come From?](#3.4)\n    - [3.5 Movies and TV Shows Duration (Minutes and Seasons)](#3.5)\n    - [3.6 Dramas or Comedies? How Are Netflix Titles Listed In?](#3.6)\n    - [3.7 Can Netflix Draw our Attention Just by Titles Description?](#3.7)\n    - [3.8 Ratings on Netflix Catalog](#3.8)\n* [4. Prep: Transforming the Data for a More Insights](#4)\n    - [4.1 New Features From \"type\" Column](#4.1)\n    - [4.2 New Features From \"director\" Column](#4.2)\n    - [4.3 New Features From \"cast\" Column](#4.3)\n    - [4.4 New Features From \"country\" Column](#4.4)\n    - [4.5 New Features From \"date_added\" and \"release_year\" Columns](#4.5)\n    - [4.6 New Features From \"listed_in\" Column](#4.6)\n    - [4.7 New Features From \"duration\" Column](#4.7)\n    - [4.8 Final Preparation](#4.8)\n* [5. PCA: Reducing the Multidimensional Space](#5)","08abbe45":"<a id=\"3.5\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>3.5 Movies and TV Shows Duration (Minutes and Seasons)<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","1aca1bbb":"<a id=\"3.4\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>3.4 From Where Netlix's Products Come From?<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","eccf7859":"We can see some really known names on the top 10 list. If you don't recognize any of them, you should use more Netflix service :D","6fd68e65":"<a id=\"4.8\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>4.8 Final Preparation<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","12fe3c31":"After defining some useful variables to be used along the project development, the given dataset was read and a first look could be taken on its content. As the project description says, the data consists on the Netflix tv shows and movies catalog of 2019 (or a more recent epoch as long as it's possible to see some tv shows with relase dated of 2020).\n\nEven though, each row of the data has information about a tv show or a movie, like the title, cast, country, duration and others. On this first look, we can get a lot of ideas on how to implement a storytelling for presenting insights about the context.","cf81b28c":"<a id=\"4.7\"><\/a>\n<font color=\"dimgrey\" size=+2.0><b>4.7 New Features From \"duration\" Column<\/b><\/font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC<\/a>","e1e51968":"Let's see some titles that were added on Netflix catalog by the same year they were released.","c2655493":"Well, let's apply some code for using the country information on our source dataset grouping the number of titles that appear for each country. After that, we will apply some functions for extracting geolocation information from those countries, like codes in different systems (alpha2 and alpha3) and also coordinates (latitude and longitude).","a2dd6e60":"___\n*To be continued*\n___\n\nPlease tell me what do you think about this notebook and `xplotter` package! Leaving here a comment or upvoting this notebook will make me really happy. Your opinion is really important and I'm really excited to show you new implementations and new packages.\n\n* **xplotter on Github:** https:\/\/github.com\/ThiagoPanini\/xplotter\n* **xplotter on PyPI:** https:\/\/pypi.org\/project\/xplotter\/\n\n\n* **mlcomposer on Github:** https:\/\/github.com\/ThiagoPanini\/mlcomposer\n* **mlcomposer on PyPI:** https:\/\/pypi.org\/project\/mlcomposer\/\n___\n\n<font size=\"+1\" color=\"black\"><b>You can also visit my other kernels by clicking on the buttons<\/b><\/font><br>\n\n<a href=\"https:\/\/www.kaggle.com\/thiagopanini\/presenting-xplotter-and-mlcomposer-on-tps-may21\" class=\"btn btn-primary\" style=\"color:white;\">TPS May 2021<\/a>\n<a href=\"https:\/\/www.kaggle.com\/thiagopanini\/pycomp-predicting-survival-on-titanic-disaster\" class=\"btn btn-primary\" style=\"color:white;\">Titanic EDA<\/a>\n<a href=\"https:\/\/www.kaggle.com\/thiagopanini\/pycomp-exploring-and-modeling-housing-prices\" class=\"btn btn-primary\" style=\"color:white;\">Housing Prices<\/a>\n<a href=\"https:\/\/www.kaggle.com\/thiagopanini\/predicting-restaurant-s-rate-in-bengaluru\" class=\"btn btn-primary\" style=\"color:white;\">Bengaluru's Restaurants<\/a>\n<a href=\"https:\/\/www.kaggle.com\/thiagopanini\/sentimental-analysis-on-e-commerce-reviews\" class=\"btn btn-primary\" style=\"color:white;\">Sentimental Analysis E-Commerce<\/a>","6064b538":"___\n* **_Top 5 movies recently added on catalog_**\n___"}}