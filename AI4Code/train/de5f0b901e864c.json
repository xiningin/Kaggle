{"cell_type":{"d8f2813e":"code","824069ee":"code","a34e3ff6":"code","0e1d5bd9":"code","356ffdc0":"code","05c423ef":"code","10933b3b":"code","ac9259a8":"code","7d34bf39":"code","553b03d7":"code","e765beda":"code","1e9a8a3f":"code","52e38db0":"code","446d2f5a":"code","70925c84":"code","9273f5a8":"code","f1fc8aed":"code","a2969208":"code","151c1f85":"code","b5ae8607":"code","bc033538":"code","a96d6395":"code","869986ff":"markdown","c53dae34":"markdown","6d582795":"markdown","07cf16ad":"markdown","602faf24":"markdown","b31e8668":"markdown","8542a4aa":"markdown"},"source":{"d8f2813e":"pip install pyspark","824069ee":"from pyspark import SparkContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType\nfrom pyspark.sql.types import StructField\nfrom pyspark.sql.types import StringType\nimport pyspark.sql.functions as func\n\n\n\n\nimport time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True) \nfrom wordcloud import WordCloud\nimport warnings\nwarnings.filterwarnings('ignore')","a34e3ff6":"spark = SparkSession.builder \\\n                    .master(\"local[*]\") \\\n                    .appName(\"prokel\") \\\n                    .getOrCreate()\nsc=SparkContext.getOrCreate()","0e1d5bd9":"path=r'..\/input\/anime_filtered.csv'\nstart=time.time()\ndf_anime =spark.read.load( \n                            path,\n                            format='csv',\n                            header='true',\n                            inferSchema='true' \n                        ) \nend=time.time() \nprint('elapse=',end-start) ","356ffdc0":"path=r'..\/input\/users_filtered.csv'\nstart=time.time()\ndf_users=spark.read.load( \n                            path,\n                            format='csv',\n                            header='true',\n                            inferSchema='true' \n                        ) \nend=time.time() \nprint('elapse=',end-start) ","05c423ef":"path=r'..\/input\/animelists_filtered.csv'\nstart=time.time()\ndf_userlists=spark.read.load( \n                            path,\n                            format='csv',\n                            header='true',\n                            inferSchema='true' \n                        ) \nend=time.time() \nprint('elapse=',end-start) ","10933b3b":"print(type(df_anime))\ndf_anime.printSchema()\ndf_anime.show(10)","ac9259a8":"print(type(df_users))\ndf_users.printSchema()\ndf_users.show(10)\n","7d34bf39":"df_anime.count()","553b03d7":"print(type(df_userlists))\ndf_userlists.printSchema\ndf_userlists.show(10)","e765beda":"anime = df_anime.filter(df_anime.genre.isNotNull())\\\n                .select('anime_id','title','type','source','score',\\\n                        'scored_by','rank','popularity','genre')\n\nusers = df_users[df_users.gender.isin ('Female','Male')]\\\n                         .select('username','gender','user_completed',\\\n                                 'user_days_spent_watching','birth_date')\nuserlists = df_userlists[df_userlists.my_status.isin(1,2)\\\n                         & df_userlists.anime_id.isNotNull()]\\\n                        .select('username', 'anime_id', 'my_score')","1e9a8a3f":"df_anime.createOrReplaceTempView('v_anime')\ndfex=spark.sql(\"SELECT anime_id,title,type,source,score,\\\n                        scored_by,rank,popularity,genre from v_anime WHERE genre is not null\")","52e38db0":"anime.printSchema()\nusers.printSchema()\nuserlists.printSchema()","446d2f5a":"dfex.count()","70925c84":"userlists = userlists.join(users, on=['username'], how='inner')\nuserlists = userlists.join(anime, on=['anime_id'], how='left')","9273f5a8":"userlists.count()","f1fc8aed":"userlists_sub=userlists.filter(userlists.genre.isNotNull()).limit(100000)\nuserlists_sub.show(10)","a2969208":"anime_rank_100 = df_anime[df_anime.rank.isNotNull()]\\\n                         [df_anime.popularity!=0]\\\n                         [df_anime.rank<=100]\\\n                         .sort(df_anime.rank)\\\n                         .select('popularity','rank', 'title','type', \\\n                                 'source', 'scored_by','favorites','score')\nanime_rank_100=anime_rank_100.withColumn('rank',anime_rank_100.rank.cast('integer'))\\\n                             .withColumn('popularity',anime_rank_100.popularity.cast('integer'))\npopularity_and_rank_100 = anime_rank_100.where(anime_rank_100.popularity <= 100)\npopularity_and_rank_100=popularity_and_rank_100.withColumn(\"point\",\\\n                                   (popularity_and_rank_100.scored_by * \\\n                                   popularity_and_rank_100.favorites * \\\n                                   popularity_and_rank_100.score) \/ 10000000000\n                                  )\npopularity_and_rank_100.show()","151c1f85":"popularity_and_rank_1002=popularity_and_rank_100.dropna().toPandas()\ndata = [\n    {\n        'y':popularity_and_rank_1002[\"popularity\"],\n        'x': popularity_and_rank_1002[\"rank\"],\n        'mode': 'markers',\n        'marker': {\n            'color': popularity_and_rank_1002[\"popularity\"],\n            'size':  popularity_and_rank_1002[\"point\"],\n            'showscale': True,\n            'sizemin':4\n        },\n        \"text\" :  popularity_and_rank_1002[\"title\"]\n    }\n]\n\nlayout = go.Layout(title='In Terms Of Rank And Popularity TOP 100 Animes',\n                   xaxis=dict(title='Rank'),\n                   yaxis=dict( title='Popularity'),\n                   autosize=False,\n                   width=800,\n                   height=600\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","b5ae8607":"df_title = popularity_and_rank_1002['title'].tolist()\ndf_point  = popularity_and_rank_1002['point'].tolist()\nlist_popularity_and_rank_100 = []\n\nfor i in range(0, len(df_point)):\n    #for j in range(0, int(df_point[i])):\n        list_popularity_and_rank_100.append(df_title[i])\n\nlist_popularity_and_rank_100[-10:]","bc033538":"plt.subplots(figsize=(14,7))\nwordcloud = WordCloud(    collocations=False,\n                          background_color='white',\n                          width=1000,\n                          height=500\n                         ).generate(\" \".join(list_popularity_and_rank_100))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","a96d6395":"animegender = userlists.select('gender').groupBy('gender').count()\nanimegender=animegender.toPandas()\nplt.figure(figsize=(8,5))\nsns.barplot(x=animegender.gender,y=animegender['count'], palette=\"rocket\")\nplt.title('Gender Ratio',color = 'purple',fontsize=15)\nplt.show()","869986ff":"# 2. Importing Libraries ","c53dae34":"<a id=\"3\"><\/a> <br>\n## 3. Data Visualization","6d582795":"<a id=\"2\"><\/a> <br>\n## 2. Data Exploration and Preparation","07cf16ad":"# 1. Install pyspark","602faf24":"# Introduction","b31e8668":"![image.png](attachment:image.png)","8542a4aa":"# 3. Create a spark session and spark context"}}