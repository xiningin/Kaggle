{"cell_type":{"cbacfbdf":"code","2cab27c0":"code","ba484682":"code","047237cb":"code","48d2fec9":"code","f3d64a14":"code","65bc992d":"code","397ef002":"code","a56173cc":"code","2f787bcb":"code","42e42d84":"code","bd2d5f92":"code","6c2d3e8e":"markdown","7fd09ed0":"markdown","d262064a":"markdown","fd1cfffc":"markdown","c98750cc":"markdown","dd44f30f":"markdown","191bdf49":"markdown","2b86d7c8":"markdown","1d49d53f":"markdown","92c5ba5f":"markdown","11222dda":"markdown","32259886":"markdown","ff57804e":"markdown","7ba63707":"markdown","525fdbd5":"markdown","be8785ff":"markdown","e4a53f60":"markdown","273a5b80":"markdown","9f402c94":"markdown","6828412d":"markdown","4a5f2bc7":"markdown","c2b49242":"markdown","da8bc5ff":"markdown","661b02f3":"markdown"},"source":{"cbacfbdf":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2cab27c0":"df = pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')\ndf.columns = ['Serial No.','GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research', 'Chance of Admit']\ndf.head()","ba484682":"df = df.drop(['Serial No.'], axis=1)\ndf.isnull().sum()","047237cb":"df.describe()","48d2fec9":"fig = plt.figure(figsize=(14, 21))\nfig.add_subplot(321)\nsns.distplot(df['GRE Score'], kde=True)\nplt.title(\"Distribution of GRE Scores\")\n\nfig.add_subplot(322)\nsns.distplot(df['TOEFL Score'], kde=True)\nplt.title(\"Distribution of TOEFL Scores\")\n\nfig.add_subplot(323)\nsns.distplot(df['CGPA'], kde=True)\nplt.title(\"Distribution of CGPA\")\n\nfig.add_subplot(324)\nsns.distplot(df['SOP'], kde=False)\nplt.title(\"Distribution of SOP Ratings\")\n\nfig.add_subplot(325)\nsns.distplot(df['University Rating'], kde=False)\nplt.title(\"Distribution of University Rating\")\n\nplt.show()","f3d64a14":"fig = plt.figure(figsize=(14, 14))\nfig.add_subplot(221)\nsns.regplot(df['GRE Score'],df['Chance of Admit'])\nplt.title(\"GRE Scores vs Chance of Admit\")\n\nfig.add_subplot(222)\nsns.regplot(df['TOEFL Score'],df['Chance of Admit'])\nplt.title(\"TOEFL Scores vs Chance of Admit\")\n\nfig.add_subplot(223)\nsns.regplot(df['CGPA'],df['Chance of Admit'])\nplt.title(\"CGPA vs Chance of Admit\")\n\nplt.show()","65bc992d":"corr = df.corr()\nfig, ax = plt.subplots(figsize=(8, 8))\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, cmap=colormap, linewidths=.5, annot=True, fmt=\".2f\", mask=mask)\nplt.show()","397ef002":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:,:-1],df.iloc[:,-1],test_size = 0.20, shuffle=False)","a56173cc":"from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n\nmodels =[['Linear Regression', LinearRegression()],\n           ['Random Forest',RandomForestRegressor()],\n           ['K-Neighbours', KNeighborsRegressor(n_neighbors = 2)],\n           ['SVM', SVR()]]\n\nmodel_output = {}\nfor name,model in models:\n    model = model\n    model.fit(X_train, Y_train)\n    pred = model.predict(X_test)\n    model_output[f'{name}'] = np.sqrt(mean_squared_error(Y_test, pred))\n\nresults = pd.DataFrame(model_output.items())\nresults.columns = ['Model', 'RMSE']\nresults.index = np.arange(1,len(results)+1)\nresults = results.sort_values(by=['RMSE'], ascending=True)\nprint(\"Models Trained\")","2f787bcb":"fig = plt.figure(figsize=(8, 8))\nsns.barplot(results['Model'],results['RMSE'],palette=reversed(sns.color_palette(\"rocket\")))\nplt.title(\"Comparing all the Models\")\nplt.show()","42e42d84":"model = RandomForestRegressor()\nX = df.iloc[:,:-1]\nY = df.iloc[:,-1]\nmodel.fit(X,Y)\nfeature_names = X.columns\nfeatures = pd.DataFrame()\nfeatures['Features'] = X.columns\nfeatures['Importance'] = model.feature_importances_\nfeatures = features.sort_values(by=['Importance'], ascending=False)\nfeatures.index = np.arange(1,len(X.columns)+1)","bd2d5f92":"fig = plt.figure(figsize=(8, 8))\nsns.barplot(features['Features'],features['Importance'],palette=sns.color_palette(\"rocket\"))\nplt.title(\"Feature Importance\")\nplt.show()","6c2d3e8e":"Now it is time to visualize distribution of the variables","7fd09ed0":"From the graph above, it can be seen that the Linear Regression Model has the lowest Root Mean Squared Error (RMSE) while SVM has the largest RMSE. Since we suspect multicollinearity, we cannot use the Linear Regression model as it may be biased. Therefore, we choose the model with the next lowest RMSE and can tackle multicollinearity, which is Random Forest.","d262064a":"### Visualising importance of features","fd1cfffc":"## Visualising the results","c98750cc":"### Descriptive Statistics","dd44f30f":"This dataset was built with the purpose of helping students in shortlisting universities with their profiles. The predicted output gives them a fair idea about their chances for a particular university.","191bdf49":"# Data Modelling","2b86d7c8":"From the above correlation matrix it can be seen that TOEFL Scores and GRE Scores have a very high correlation. This can be a cause of multicollinearity in the model, therefore, a Linear Regression is not deemed fit for this dataset and we should proceed with other linear modelling techniques.","1d49d53f":"# <center> The End <\/center>","92c5ba5f":"It can be seen from the graphs above that all of our continuous independent variables have a strong positive correlation with the Chance of Admit. Moreover, we can expect GRE Scores, TOELF Score, and CGPA to have a positive linear relationship with the Chance of Admit.","11222dda":"# <center>Data cleaning and processing<\/center>","32259886":"# <center> Analysis of Graduate Admissions <\/center>","ff57804e":"Thank you for going through my notebook. Hopefully you have gained valuable insights into the dataset. As this was my first Kaggle notebook I would like if you Upvote as it will keep me boost my motivation! Kindly let me know if I can improve my work in any aspect.","7ba63707":"### Acknowledgements","525fdbd5":"### Inspiration","be8785ff":"Let us drop the **\"Serial No.\"** column as it is irrelevent. Let's also check for any null values in our dataset.","e4a53f60":"### Visualizing the relationship between the independent variables and the dependent variable","273a5b80":"### Finding important features","9f402c94":"From the Descriptive Statistcs, it can be observed that average GRE Score was 316\/340, TOEFL Score was 107\/120, and CGPA was 8.57\/10. From these statistics, it can be inferred that the students applying are mostly \"above average students\" in the traditional sense. Moreover, it can also be seen that 56% of the students ","6828412d":"This dataset is inspired by the UCLA Graduate Dataset and is created by Mohan S Acharya to estimate chances of graduate admission from an Indian perspective.","4a5f2bc7":"# <center>Visualizing the Data<\/center>","c2b49242":"Let's visualize the relationship between each of the continuous variables: GRE Score, TOEFL Score, and CGPA, with the Chance of Admit","da8bc5ff":"### Checking for Multicollinearity","661b02f3":"Although we have visualised the feature importance, they cannot be relied upon since multicolinearity affects the feature importance. However, in Random Forest, the existence of multicolinearity does not affect the prediction accuracy. Therefore the model can only be relied upon for the final predictions and not for feature importance. "}}