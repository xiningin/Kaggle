{"cell_type":{"032431d3":"code","cdf1237c":"code","3cb81beb":"code","e0b4d216":"code","a0c976a4":"code","1fe75862":"code","30d2e812":"code","3044dacd":"code","949d78cd":"code","3eef9933":"code","ccab1a92":"code","68276ce8":"code","ce43ee25":"code","a8744fcd":"code","b0371b77":"code","d15a9708":"code","a67592ae":"code","fffe2414":"code","ad16b010":"code","a6ed57d8":"code","60565b2e":"code","5d70b07b":"code","3c05f117":"code","287ae96a":"code","0c20b1f9":"code","0b381720":"code","41e55dae":"code","349c1f05":"code","3672dec3":"code","aab23df0":"code","4b84c04e":"code","c48954c6":"code","b75a5b3e":"code","9512e142":"code","975aff67":"code","3b17ea32":"code","7ff89c51":"code","682eba71":"code","fc7b7108":"code","4afe1ecb":"code","88d773b6":"code","21b7cc06":"code","98e0486d":"code","664c0121":"markdown","2b6439c3":"markdown","b93da7eb":"markdown","591901b8":"markdown","f708e8cb":"markdown","04639729":"markdown","7a2a9732":"markdown","27ec95f6":"markdown","d09b4de0":"markdown","14a691c0":"markdown","3b6bde41":"markdown","df6cab23":"markdown","e73cc663":"markdown","24d62041":"markdown","95d4de7d":"markdown","599d850c":"markdown","4c77291b":"markdown","70489612":"markdown","7ccb0af5":"markdown","602cbdce":"markdown","c57d261f":"markdown","7da1f8ad":"markdown","14a20e84":"markdown","c14886ac":"markdown","7cea1e71":"markdown","eb180760":"markdown","0d221c9b":"markdown","ef9a5229":"markdown","d2fc8ef3":"markdown","54c37a3a":"markdown","7418ac29":"markdown","4663636d":"markdown","6709a074":"markdown","e1b0b4a6":"markdown","010fec26":"markdown","170f7e93":"markdown","78b769c2":"markdown","81c3f03f":"markdown","6e21eb27":"markdown","a8780979":"markdown","7a2150c1":"markdown","c7ab4b0f":"markdown","57e2c33a":"markdown","3bd8ac63":"markdown"},"source":{"032431d3":"%pylab inline\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndata = pd.read_csv('..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv')\ndata = data.drop(['Unnamed: 0'], axis=1)","cdf1237c":"data = data.dropna(how='any') \ndata.to_csv('Womens_Clothing_clean.csv')","3cb81beb":"df = pd.read_csv('\/kaggle\/input\/womens-clothing-cleancsv\/Womens_Clothing_clean.csv')\ndf = df.drop(['Unnamed: 0'], axis=1)\n\nprint('Number of rows of original dataset: %d' % len(data))\nprint('Number of rows after dropping na: %d' % len(df))","e0b4d216":"df","a0c976a4":"print('Mean reviewer age: ' , round(df['Age'].mean(), 3))\nprint('Mean rating: ', round(df['Rating'].mean(), 3))","1fe75862":"# histogram for age\nage = pd.Series(df['Age'])\n# age.value_counts()\nage_plot = age.plot.hist(bins=20, rwidth=0.9, color='#607c8e', title = 'Age distribution')\nplt.xlabel('Age')","30d2e812":"# histogram for rating\nrating = pd.Series(df['Rating'])\n# rating.value_counts()\nrating_plot = rating.plot.hist(color='#607c8e')\nplt.title('Rating distribution')\nplt.xlabel('Rating')\nplt.ylabel('Frequency')","3044dacd":"rating_by_age = df.groupby('Age')['Rating'].mean()\n\nrating_by_age_plot = rating_by_age.plot(kind='bar', title='Ratings by Age', color='#4290be')\n\n","949d78cd":"rating_by_department = df.groupby('Department Name')['Rating'].mean()\n\nrating_by_department_plot = rating_by_department.plot(kind='bar', title='Ratings by Department', color='#4290be')\n","3eef9933":"rating_by_class = df.groupby('Class Name')['Rating'].mean()\nrating_by_class_plot = rating_by_class.plot(kind='bar', title='Ratings by Class', color='#4290be')","ccab1a92":"sentiment_df = df\nsentiment_df['label'] = ['pos' if rating == 5 else 'neg' for rating in df['Rating']] \nsentiment_df.head()","68276ce8":"from sklearn.model_selection import train_test_split\ntarget = [1 if label == 'pos'  else 0 for label in df['label']] # use 1 and 0 to represent labels\nreview_train, review_test, target_train, target_test = train_test_split(sentiment_df['Review Text'].values, target, test_size=0.20, random_state=1)\nprint(review_train)","ce43ee25":"from sklearn.feature_extraction.text import CountVectorizer\nstop_words=['in','of','at','a','the']\ntrigram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words) #initialize vectorizer using tri-gram and removing stop words\ntrigram_vectorizer.fit(review_train)\nX = trigram_vectorizer.transform(review_train) # convert training data\nX_test = trigram_vectorizer.transform(review_test) # convert testing data","a8744fcd":"from sklearn.metrics import accuracy_score\nfrom sklearn.svm import LinearSVC\n\n# using svm\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target_train, train_size = 0.75, random_state=1) # set random state to retain the same data split each time.  \n\n# Tuning hyperparameter c to adjust regularization and see which one yields the highest accuracy\nfor c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n    \n    svm = LinearSVC(C=c)\n    svm.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, svm.predict(X_val))))\n\n\n","b0371b77":"final_model = LinearSVC(C=0.005)\nfinal_model.fit(X, target_train)\nprint (\"Final Accuracy: %s\" \n       % accuracy_score(target_test, final_model.predict(X_test)))","d15a9708":"feature_to_coef = {\n    word: coef for word, coef in zip(\n        trigram_vectorizer.get_feature_names(), final_model.coef_[0]\n    )\n}\nprint('positive:')\n\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:10]:\n    print (best_positive)\n\nprint('\\nnegative:')\n    \nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:10]:\n    print (best_negative)\n    \n","a67592ae":"df","fffe2414":"reviews = df[['Review Text']]\nreviews['index'] = reviews.index\ndocuments = reviews\nreviews","ad16b010":"# Loading libraries for text processing\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\nimport numpy as np\nnp.random.seed(2018)\nimport nltk\nnltk.download('wordnet')","a6ed57d8":"# functions for stokenizing, stemming, lemmatizing, and removing stop words\nstemmer = SnowballStemmer('english')\ndef lemmatize_stemming(text):\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\ndef preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n            result.append(lemmatize_stemming(token))\n    return result\n","60565b2e":"doc_sample = documents[documents['index'] == 4].values[0][0]\nprint('original document: ')\nwords = []\nfor word in doc_sample.split(' '):\n    words.append(word)\nprint(words)\nprint('\\n\\n tokenized and lemmatized document: ')\nprint(preprocess(doc_sample))\n\n","5d70b07b":"processed_docs = documents['Review Text'].map(preprocess)\nprocessed_docs","3c05f117":"# using gensim library to generate bi-grams and tri-grams\nfrom gensim.models import Phrases\n\n# Add bigrams and trigrams to docs (only ones that appear 10 times or more).\nbigram = Phrases(processed_docs, min_count=10)\ntrigram = Phrases(bigram[processed_docs])\n\nfor idx in range(len(processed_docs)):\n    for token in bigram[processed_docs[idx]]:\n        if '_' in token:\n            # Token is a bigram, add to document.\n            processed_docs[idx].append(token)\n    for token in trigram[processed_docs[idx]]:\n        if '_' in token:\n            # Token is a bigram, add to document.\n            processed_docs[idx].append(token)","287ae96a":"dictionary = gensim.corpora.Dictionary(processed_docs)\nprint('Number of unique words in initital documents:', len(dictionary))\ncount = 0\nfor k, v in dictionary.iteritems():\n    print(k, v)\n    count += 1\n    if count > 10:\n        break\n\n# Filter out words that occur less than 10 documents.\ndictionary.filter_extremes(no_below=10)\nprint('Number of unique words after removing rare and common words:', len(dictionary))\n\n","0c20b1f9":"bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]","0b381720":"bow_doc_4 = bow_corpus[4]\nfor i in range(len(bow_doc_4)):\n    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4[i][0], \n                                               dictionary[bow_doc_4[i][0]], \nbow_doc_4[i][1]))","41e55dae":"print('Number of unique tokens: %d' % len(dictionary))\nprint('Number of documents: %d' % len(bow_corpus))","349c1f05":"from gensim.models import LdaModel\n\nnum_topics = 9\nlda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=4, workers=3, random_state=100)","3672dec3":"from pprint import pprint\n# Print the Keyword in the 10 topics\npprint(lda_model.print_topics())\ndoc_lda = lda_model[bow_corpus]","aab23df0":"from gensim.models import CoherenceModel\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nBaseline Coherence Score: ', coherence_lda)","4b84c04e":"def compute_coherence_values(dictionary, corpus, texts, max_topics = 25, min_topics=3, step_size=2):\n    \"\"\"\n    Compute c_v coherence for various number of topics\n\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n    \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in range(min_topics, max_topics, step_size):\n        model = gensim.models.LdaMulticore(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=4, workers=3, random_state=100) #workers = 3 to increase computation power\n        model_list.append(model)\n        coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherence_model.get_coherence())\n\n    return model_list, coherence_values","c48954c6":"model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow_corpus, texts=processed_docs, max_topics = 25, min_topics=3, step_size=2)","b75a5b3e":"# Show graph\nmax_topics = 25\nmin_topics=3\nstep_size=2\nx = range(min_topics, max_topics, step_size)\nplt.plot(x, coherence_values)\nplt.xlabel(\"Num Topics\")\nplt.ylabel(\"Coherence score\")\nplt.legend((\"coherence_values\"), loc='best')\nplt.show()","9512e142":"# Print the coherence scores\nfor m, cv in zip(x, coherence_values):\n    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))","975aff67":"optimal_num_topics = 17\nlda_model = gensim.models.LdaMulticore(bow_corpus, num_topics= 17, id2word=dictionary, passes=10, workers=3, random_state=100)","3b17ea32":"coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nFinal Model Coherence Score: ', coherence_lda)","7ff89c51":"def format_topics_sentences(ldamodel=lda_model, corpus=bow_corpus, texts=processed_docs):\n    # Init output\n    sent_topics_df = pd.DataFrame()\n\n    # Get main topic in each document\n    for i, row in enumerate(ldamodel[corpus]):\n        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n        # Get the Dominant topic, Perc Contribution and Keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0:  # => dominant topic\n                wp = ldamodel.show_topic(topic_num)\n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n            else:\n                break\n    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n\n    # Add original text to the end of the output\n    contents = pd.Series(texts)\n    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n    return(sent_topics_df)\n\n\ndf_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=bow_corpus, texts=processed_docs) #aggregates this information in a presentable table.\n\n# Format\ndf_dominant_topic = df_topic_sents_keywords.reset_index()\ndf_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n\n","682eba71":"# Show\ndf_dominant_topic","fc7b7108":"reviews.iloc[3497,0]","4afe1ecb":"# Group top 5 sentences under each topic\nsent_topics_sorteddf = pd.DataFrame()\n\nsent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n\nfor i, grp in sent_topics_outdf_grpd:\n    sent_topics_sorteddf = pd.concat([sent_topics_sorteddf, \n                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n                                            axis=0) # Perc_Contribution is percentage contribution of the topic in the given document.\n\n# Reset Index    \nsent_topics_sorteddf.reset_index(drop=True, inplace=True)\n\n# Format\nsent_topics_sorteddf.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n\n# Show\nsent_topics_sorteddf","88d773b6":"age_rating_by_topics = df_dominant_topic\nage_rating_by_topics['Rating'] = df['Rating']\nage_rating_by_topics['Age'] = df['Age']\n\n\nage_rating_by_topics.groupby('Dominant_Topic')['Age', 'Rating'].mean()\n","21b7cc06":"import pyLDAvis.gensim\npyLDAvis.enable_notebook()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","98e0486d":"\npyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)","664c0121":"### Preprocessing and vectorization","2b6439c3":"### Train Baseline LDA model","b93da7eb":"Preview sample processed documents:","591901b8":"*Took about 15 min to run models with different numbers of topic*","f708e8cb":"There isn't any big difference among ratings on clothing in different departments. ","04639729":"### Visualizing topics","7a2a9732":"## Clustering review text - Topic modeling using LDA\n\nTopic modeling is used to extract topics from large collections of documents. Latent Dirichlet Allocation (LDA) is one way to do topic modeling. ","27ec95f6":"#### Lemmatizing, stemming, removing stop words\n\n* Stopwords are removed.\n* Lemmatizing \u2014 words in third person are changed to first person and verbs in past and future tenses are changed into present.\n* Stemming \u2014 words are reduced to their root form.","d09b4de0":"#### Finding the most representative document for each topic \n\nTo help with understanding the topic, we find the documents a given topic has contributed to the most and infer the topic by reading that document.","14a691c0":"Remove na in data and store as a new csv file","3b6bde41":"### Labeling reviews as positive or negative\nSince there are way more customers rated items as 5, and in those reviews with ratings of less than 5, there are always some things the customers are not satisfied with, I will label reviews with a rating of 5 as positive and anything below as negative.","df6cab23":"### Prepare data","e73cc663":"From the above results we see that C=0.005 yields the highest accuracy. Therefore, we will deploy our final model using C=0.005","24d62041":"The age distribution plot indicates a slightly left skewed age distribution with median value around 35 - 40. Most of the customers who shop at this website are younger than 60 years old.","95d4de7d":"The biggest group of people give the highest rating of 5. ","599d850c":"#### Checking age and rating differences for each topic group","4c77291b":"### Vectorization\n\nIn order to feed the review text into machine learning algorithms, we need to convert the text into numbers. \n\nAfter testing out combinations of different text processing techniques such as tf-idf, bi-gram, stemming and others, using CountVectorizer with tri-gram and stop words yields the best accuracy.","70489612":"### Build classifier\n\nIn comparison to logistic regression, support vector machine (svm) yields higher accuracy and has shorter computation time. So I decided to use svm to fit the model.","7ccb0af5":"# Understanding Customer Using Reviews Data\n\nThe purpose of this project is to try out Python concepts and techniques I've learned from Computational Concept in HCDE to understand the customers in a women's clothing ecommerce webiste. To understand the customers, I will calculate and visualize descriptive statistics to gain a basic understanding of the dataset, conduct sentiment analysis on review text to uncover key words in positive and negative sentiments, and conduct topic modeling to find customer segments. ","602cbdce":"Mean age and mean rating: ","c57d261f":"## Descriptive statistics","7da1f8ad":"### split training and testing set for final model","14a20e84":"From the output we can see that words that strongly associate with positive reivews are words that usually express positive emotions such as 'perfect' and 'love.' In negative words, besides adjective that usually describe negative emotions, words related with the action of returning items are high on the list. ","c14886ac":"There are no major difference in age among different topic groups. Group 15 has the lowest rating. ","7cea1e71":"#### Finding the dominant topic in each review\n\nTo determine what topic a given document is about, we find the topic number that has the highest percentage contribution in that document.","eb180760":"The Rating by Age graph shows that the reviewers who are less than or equal to 76-year-old have similar mean ratings between 4 to about 4.5. Mean ratings of reviewers older than 76 fluctuate more. However, whether those reviewers who identified themselves as above 80 years old were reporting their real age remains questionable. Upon reading the reviews of those in the higher age group, I did not find any evidence of fake age, so I decided to keep data of those age groups. \n","0d221c9b":"#### Corpus and Dictionary \n\nThe two main inputs to the LDA topic model are the dictionary and the corpus.","ef9a5229":"#### Compute Bi\/Tri-gram\n\nBigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring.","d2fc8ef3":"Similarly, there isn't much difference among ratings on clothing in different class.","54c37a3a":"#### Compute Baseline Coherence Score\n","7418ac29":"## Sentiment Analysis on review text","4663636d":"### Hyperparameter Tuning\n\nFor the simplicity of the project, I will only tune the number of topics (K).\n\n\nC_v will be used as metric for performance comparison.","6709a074":"Let\u2019s look at the 10 most discriminating words for both positive and negative reviews. We\u2019ll do this by looking at the largest and smallest coefficients, respectively.","e1b0b4a6":"A sample review being processed","010fec26":"The interactive visualization allows you to explore the most relevant terms in each topic. By comparing the estimated term frequency with overall term frequency we can also identify words that are unique to the topic.","170f7e93":"### Interpreting topics\n\nSome topics are harder to interpret than others. By combining all the information above and based on my subjective interpretation, the following topic groups are formed:\n* Topic 1: petite buyer\n* Topic 2: loves to report back compliment they receive when wearing\n* Topic 3: recommender, also loves to try in store\n* Topic 4: loves the purchase because it fits very well.\n* Topic 5: the size run large for them and loves to tell that to other reviewers\n* Topic 6: loves reading reviews\n* Topic 7: buys during sales and usually happy purchase\n* Topic 8: recommender, buying fall and winter clothes\n* Topic 9: review reader\n* Topic 10: loves the high quality\n* Topic 11: jeans\/pants buyer, cares about the fit\n* Topic 12: intimacy clothing buyer, loves light weight\n* Topic 13: cami buyer, cares most about color\n* Topic 14: skirt buyer \n* Topic 15: disappointed buyer \n* Topic 16: bath suit buyer\n* Topic 17: (difficult to interpret)\n","78b769c2":"### Running final model\n\nBased on the coherence score above, I choose 17 topics for the final model. In previous model, I set the passes to be lower in order to save time, but in the final model we increases passes to 10 for a better training results.","81c3f03f":"## Dataset\n\nThe dataset used in this project is [the women's ecommerce clothing reviews](https:\/\/www.kaggle.com\/nicapotato\/womens-ecommerce-clothing-reviews) dataset found on Kaggle. This data set is real reviews from an anonymized women\u2019s clothing e-commerce platform. The data is a collection of 22641 Rows and 10 column variables. Each row consists of a written review as well as an additional feature of the customer information. All 10 variables are clothing ID, age, title, review text, rating, recommended IND, positive feedback count, division name, department name, and class name. \n","6e21eb27":"Look at terms in each topics","a8780979":"## Conclusion\n\nThere were a lot of assumptions made when exploring the data. For example, we assume that people honestly reported their age. Besides, not all customers would have leave reviews for the products they've purchased. So the exploration of customer segmentation only captures those who write reviews. Even though I was able to interpret some of the topics, but the interpretation is very subjective and it's not the most obvious. When doing customer segmentation in the real world (not just exploring python like me), it would be best to have other features about the customers. Features may come from other data collection methods such as large scale surveys. \n\nThank you for reading my exploration of the women's clothing reviews dataset!","7a2150c1":"Use clean data","c7ab4b0f":"Compared to the baseline model, the coherence score has increased. ","57e2c33a":"#### Plotting distribution of age and rating","3bd8ac63":"Process all review text"}}