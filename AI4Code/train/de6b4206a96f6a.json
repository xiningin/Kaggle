{"cell_type":{"4985eb78":"code","c14e8707":"code","7e24959f":"code","a9239167":"code","4c0f36f6":"code","2b382388":"code","57790d01":"code","5ec212d4":"code","082ff7c8":"code","a33edeaf":"code","6877004c":"code","47ec43a6":"code","6d18e1bf":"code","e97e8b30":"code","c458582b":"code","c2f072ad":"code","e310a45f":"code","2db6ed25":"code","82e3f76a":"code","a1f91343":"code","179d55b8":"code","fe726ab1":"code","e23ede8b":"code","24dbf3ed":"code","105bbf70":"code","0ab62785":"code","e1889ac9":"code","b66f4466":"code","92cead81":"code","f1eb71dd":"code","755416b3":"code","a41e29a5":"code","50fb4741":"code","43b6bbc1":"code","74d0ebcf":"code","f80e229d":"code","c3bdf6fc":"code","c5b7a6c5":"code","82c60814":"code","02ca7f19":"markdown","5e295bc4":"markdown","b6091e19":"markdown","9fb4a63a":"markdown","fe3a752f":"markdown","edcbff9b":"markdown","3f9be75f":"markdown","2ef58092":"markdown","3336aeb3":"markdown"},"source":{"4985eb78":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c14e8707":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ShuffleSplit, learning_curve\nfrom sklearn.metrics import roc_auc_score, make_scorer\nfrom sklearn.preprocessing import Imputer, MinMaxScaler, StandardScaler\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\n\nimport zipfile\n\nfrom IPython.display import Image","7e24959f":"path = '\/kaggle\/input\/home-credit-default-risk\/'\n\nPOS_CASH_balance = pd.read_csv(path+'POS_CASH_balance.csv')\nbureau_balance = pd.read_csv(path+'bureau_balance.csv')\napplication_train = pd.read_csv(path+'application_train.csv')\nprevious_application = pd.read_csv(path+'previous_application.csv')\ninstallments_payments = pd.read_csv(path+'installments_payments.csv')\ncredit_card_balance = pd.read_csv(path+'credit_card_balance.csv')\napplication_test = pd.read_csv(path+'application_test.csv')\nbureau = pd.read_csv(path+'bureau.csv')","a9239167":"# \u0412\u044b\u0432\u0435\u0434\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0441 \u043c\u043e\u0434\u0435\u043b\u044c\u044e \u0434\u0430\u043d\u043d\u044b\u0445\nImage(url = \"https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/home-credit\/home_credit.png\")","4c0f36f6":"# \u0412\u044b\u0432\u0435\u0434\u0435\u043c shape'\u044b \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nprint('application_train shape: {} rows, {} columns'.format(*application_train.shape))\nprint('application_test shape: {} rows, {} columns'.format(*application_test.shape))","2b382388":"application_train.set_index('SK_ID_CURR', inplace=True)\napplication_test.set_index('SK_ID_CURR', inplace=True)\n\ny = application_train['TARGET']","57790d01":"# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u0438 \u0432\u0435\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\ncategorical_features = [col for col in application_test.columns if application_test[col].dtype == 'object']\nnumerical_features = [col for col in application_test.columns if application_test[col].dtype != 'object']\n        \nprint('Data has {} categorical features, and {} numerical features'.format(\n    len(categorical_features), len(numerical_features)))","5ec212d4":"# \u0417\u0430\u043f\u0438\u043b\u0438\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0434\u043b\u044f \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u0432\u0435\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\ndef plot_features_hist(df, features, cols=3, bins=200, window_width=7.5, window_height=5):\n    cols = cols\n    rows = (len(features) + cols - 1) \/\/ cols\n    gs = gridspec.GridSpec(rows, cols)\n    fig = plt.figure(figsize=(cols * window_width, rows * window_height))\n    for feature, grd in zip(features,\n                            range(len(features))):\n        ax = plt.subplot(gs[grd \/\/ cols, grd % cols])\n        fig = plt.hist(df[feature].dropna(), bins=bins)\n        plt.title(str(feature)\n                  +' (min:'+str(round(min(df[feature].dropna())))\n                  +', mean:'+str(round(np.mean(df[feature].dropna())))\n                  +', max:'+str(round(max(df[feature].dropna())))+')')\n    plt.show()","082ff7c8":"plot_features_hist(application_train, numerical_features)","a33edeaf":"plot_features_hist(application_test, numerical_features)","6877004c":"print('application_test \"DAYS_EMPLOYED\" anomalies {}, {}%'.format(\n    len(application_test[application_test['DAYS_EMPLOYED']==365243]),\n    len(application_test[application_test['DAYS_EMPLOYED']==365243]) \/ len(application_test) * 100))\nprint('')\nprint('application_train \"DAYS_EMPLOYED\" anomalies {}, {}%'.format(\n    len(application_train[application_train['DAYS_EMPLOYED']==365243]),\n    len(application_train[application_train['DAYS_EMPLOYED']==365243]) \/ len(application_train) * 100))","47ec43a6":"application_train['DAYS_EMPLOYED_ANOM'] = application_train[\"DAYS_EMPLOYED\"] == 365243\napplication_train[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\napplication_test['DAYS_EMPLOYED_ANOM'] = application_test[\"DAYS_EMPLOYED\"] == 365243\napplication_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)","6d18e1bf":"application_train = pd.get_dummies(data=application_train, columns=categorical_features, dummy_na=True)\napplication_test = pd.get_dummies(data=application_test, columns=categorical_features, dummy_na=True)","e97e8b30":"print('application_train shape: {} rows {} columns'.format(*application_train.shape))\nprint('application_test shape: {} rows {} columns'.format(*application_test.shape))","c458582b":"application_train, application_test = application_train.align(application_test, join='inner', axis = 1)\n\nprint('application_train shape: ', application_train.shape)\nprint('application_test shape: ', application_test.shape)","c2f072ad":"missing_df = (application_train.isna().sum() \/ len(application_train)).reset_index()\nmissing_df.sort_values(ascending=False, by=0)","e310a45f":"def missing_indicator(df, features=None, inplace=False):\n    if not features:\n        features = df.columns\n    if not inplace:\n        df = df.copy()\n    for feature in df[features].columns:\n        if df[feature].isna().sum() > 0:\n            df['missing_'+feature] = df[feature].isna().astype(int)\n    return df","2db6ed25":"application_train = missing_indicator(application_train)\napplication_test = missing_indicator(application_test)\n\nprint('application_train shape: ', application_train.shape)\nprint('application_test shape: ', application_test.shape)","82e3f76a":"application_train, application_test = application_train.align(application_test, join='inner', axis = 1)\n\nprint('application_train shape: ', application_train.shape)\nprint('application_test shape: ', application_test.shape)","a1f91343":"binary_features_train = application_train[numerical_features].nunique()\nbinary_features_train = binary_features_train[binary_features_train<=2]\nbinary_features_train = binary_features_train.index\n\nbinary_features_test = application_test[numerical_features].nunique()\nbinary_features_test = binary_features_test[binary_features_test<=2]\nbinary_features_test = binary_features_test.index\n\nmin(binary_features_train == binary_features_test)","179d55b8":"binary_features_train","fe726ab1":"application_train[binary_features_train] = application_train[binary_features_train].fillna(0)\napplication_test[binary_features_test] = application_test[binary_features_test].fillna(0)","e23ede8b":"mean_imputer = Imputer(missing_values='NaN', strategy='mean')\napplication_train[numerical_features] = mean_imputer.fit_transform(application_train[numerical_features])\napplication_test[numerical_features] = mean_imputer.transform(application_test[numerical_features])","24dbf3ed":"application_train.corrwith(y).sort_values(ascending=False)","105bbf70":"application_train.corrwith(y).sort_values()","0ab62785":"!rm -r \/opt\/conda\/lib\/python3.6\/site-packages\/lightgbm\n!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM","e1889ac9":"!apt-get install -y -qq libboost-all-dev","b66f4466":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","92cead81":"!cd LightGBM\/python-package\/;python3 setup.py install --precompile","f1eb71dd":"!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","755416b3":"!nvidia-smi","a41e29a5":"param = {\n        'num_leaves': 10,\n        'max_bin': 127,\n        'min_data_in_leaf': 11,\n        'learning_rate': 0.02,\n        'min_sum_hessian_in_leaf': 0.00245,\n        'bagging_fraction': 1.0, \n        'bagging_freq': 5, \n        'feature_fraction': 0.05,\n        'lambda_l1': 4.972,\n        'lambda_l2': 2.276,\n        'min_gain_to_split': 0.65,\n        'max_depth': 14,\n        'save_binary': True,\n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'binary',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'auc',\n        'is_unbalance': True,\n        'boost_from_average': False,\n        'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0\n    }","50fb4741":"import lightgbm as lgb\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold","43b6bbc1":"%%time\nnfold = 2\n\ntarget = 'target'\npredictors = application_train.columns.values.tolist()\n\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(application_train))\npredictions = np.zeros(len(application_test))\n\ni = 1\nfor train_index, valid_index in skf.split(application_train, y.values):\n    print(\"\\nfold {}\".format(i))\n    xg_train = lgb.Dataset(application_train.iloc[train_index][predictors].values,\n                           label=y.iloc[train_index].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )\n    xg_valid = lgb.Dataset(application_train.iloc[valid_index][predictors].values,\n                           label=y.iloc[valid_index].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )   \n\n    \n    clf = lgb.train(param, xg_train, 5000, valid_sets = [xg_valid], verbose_eval=50, early_stopping_rounds = 50)\n    oof[valid_index] = clf.predict(application_train.iloc[valid_index][predictors].values, num_iteration=clf.best_iteration) \n    \n    predictions += clf.predict(application_test[predictors], num_iteration=clf.best_iteration) \/ nfold\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.2f}\".format(metrics.roc_auc_score(y.values, oof)))","74d0ebcf":"sample_submission = pd.read_csv(path+'sample_submission.csv')\nsample_submission","f80e229d":"my_submission = pd.DataFrame({'SK_ID_CURR': application_test.index, 'TARGET': predictions})\nmy_submission","c3bdf6fc":"my_submission.to_csv('submission.csv', index=False)","c5b7a6c5":"my_submission","82c60814":"from IPython.display import FileLink\nFileLink('submission.csv')","02ca7f19":"\u0422\u0435\u043f\u0435\u0440\u044c \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c, \u043d\u0435\u0442 \u043b\u0438 \u0443 \u043d\u0430\u0441 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0441\u043a\u043e\u0440\u0435\u043b\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0441 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439","5e295bc4":"\u0412 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0435 DAYS_EMPLOYED \u0447\u0430\u0441\u0442\u043e \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u0435\u0442\u0441\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 365243. \u0421\u043a\u043e\u0440\u0435\u0435 \u0432\u0441\u0435\u0433\u043e, \u044d\u0442\u043e \u043a\u0430\u043a\u0430\u044f-\u0442\u043e \u043e\u043f\u0435\u0447\u0430\u0442\u043a\u0430 \u0438\u043b\u0438 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u043d\u044b\u0439 \u0431\u0430\u0433 CRM-\u043a\u0438, \u043d\u0435 \u043c\u043e\u0436\u0435\u0442 \u0436\u0435 \u0441\u043e\u0442\u0440\u0443\u0434\u043d\u0438\u043a \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0442\u044b\u0441\u044f\u0447\u0443 \u043b\u0435\u0442 \u043d\u0430 \u043e\u0434\u043d\u043e\u043c \u043c\u0435\u0441\u0442\u0435. \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u0431\u0443\u0434\u0435\u0442 \u043c\u0435\u0442\u043a\u0430 \u043e \u043d\u0430\u043b\u0438\u0447\u0438\u0438 \u0442\u0430\u043a\u043e\u0433\u043e \u044f\u0432\u043b\u0435\u043d\u0438\u044f, \u0430 \u0441\u0430\u043c\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0432 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0435 \u0437\u0430\u043c\u0435\u043d\u0438\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u043c.","b6091e19":"\u0414\u0430\u043b\u0435\u0435 \u043c\u044b \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0432 \u0432\u0435\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u0445 \u0441\u0440\u0435\u0434\u043d\u0438\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438. \u041e\u0434\u043d\u0430\u043a\u043e \u0441\u0440\u0435\u0434\u0438 \u0432\u0435\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0445 \u043f\u0440\u0438\u043d\u0430\u043a\u043e\u0432 \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u044e\u0442\u0441\u044f \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u0438 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0432 \u043d\u0438\u0445 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u0441\u0442\u0440\u043e\u0433\u043e \u043d\u0443\u043b\u044f\u043c\u0438","9fb4a63a":"### Model selection","fe3a752f":"\u0414\u0430\u043b\u0435\u0435 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438","edcbff9b":"\u041f\u043e \u0432\u0441\u0435\u0439 \u0432\u0438\u0434\u0438\u043c\u043e\u0441\u0442\u0438, \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u043c \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0430\u0445 \u0440\u0430\u0437\u043d\u044b\u0439 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432, \u043f\u0440\u0438\u0432\u0435\u0434\u0451\u043c \u043a \u0435\u0434\u0438\u043d\u043e\u043c\u0443 \u0432\u0438\u0434\u0443","3f9be75f":"\u041c\u043e\u0434\u0435\u043b\u044c \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 ROC_AUC 0.75 \u043d\u0430 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","2ef58092":"\u0414\u0430\u043b\u0435\u0435 \u0440\u0430\u0437\u0431\u0435\u0440\u0451\u043c\u0441\u044f \u0441 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u043c\u0438","3336aeb3":"\u0422\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0439 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u043d\u0430\u0431\u043e\u0440\u044b \u0442\u0435\u043f\u0435\u0440\u044c \u0438\u043c\u0435\u044e\u0442 \u0440\u0430\u0437\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432. \u041f\u0440\u0438\u0432\u0435\u0434\u0451\u043c \u0438\u0445 \u043a \u0435\u0434\u0438\u043d\u043e\u043c\u0443 \u0432\u0438\u0434\u0443"}}