{"cell_type":{"18877a52":"code","15af77e5":"code","a87feac5":"code","bd550f8d":"code","21f40272":"code","d323c49d":"code","281cc484":"code","8c3ed52d":"code","9ccba776":"code","24f88445":"code","76e75643":"code","933d3f2b":"code","eb935f1e":"code","a2496ca5":"code","8cd2be9e":"code","cd125701":"code","81b72792":"code","0e7bd7b8":"code","1b50f4fa":"code","691a939e":"code","0f2d61f6":"code","4f26f11c":"code","55a8fc06":"code","fe56fd5d":"code","a9eadf67":"code","f17825b2":"code","a6614fc9":"code","751d64a4":"code","f24bb8db":"code","c145b2fc":"code","20c57780":"code","f0cad6be":"markdown","6c9dc38b":"markdown","11ac61d5":"markdown","881a44df":"markdown","b15a0957":"markdown","82f76e2b":"markdown","7707bc8a":"markdown","bdb614f9":"markdown","ffb23bc7":"markdown","a7a77453":"markdown","489c2e16":"markdown"},"source":{"18877a52":"#!pip install chart_studio","15af77e5":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pylab as plt\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\n\nfrom sklearn import model_selection\nimport tensorflow as tf\nfrom keras import optimizers, regularizers\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, LSTM, Conv1D, Activation, MaxPooling1D, Flatten\nimport keras.backend as K\n\n%matplotlib inline","a87feac5":"train = pd.read_csv('sales_train.csv', parse_dates=['date'], infer_datetime_format=True)\ntrain.head()","bd550f8d":"train.info()","21f40272":"train['sales'] = train.item_price * train.item_cnt_day\ntrain.head()","d323c49d":"daily_sales = train.groupby('date', as_index=False)['sales'].sum()\ndaily_sales = daily_sales.sort_values('date', axis=0)\ndaily_sales.head()","281cc484":"daily_sales_sp = go.Scatter(x=daily_sales.date, y=daily_sales.sales)\nlayout = go.Layout(title='Daily Sales', xaxis=dict(title='Date'), yaxis=dict(title='Daily Sales'))\nfig = go.Figure(data=[daily_sales_sp], layout=layout)\niplot(fig)","8c3ed52d":"daily_sales_by_store = train.groupby(['date', 'shop_id'], axis=0, as_index=False)['sales'].sum()\ndaily_sales_by_store_sp = []\nstores = np.sort(train.shop_id.unique())\nfor store in stores[26:36] :\n    dummy = daily_sales_by_store[daily_sales_by_store.shop_id == store]\n    daily_sales_by_store_sp.append(go.Scatter(x=dummy.date, y=dummy.sales, name='Store %s' % store))\n    \nlayout = go.Layout(title='Daily Sales by Store', xaxis=dict(title='Date'), yaxis=dict(title='Sales'))\nfig = go.Figure(data=daily_sales_by_store_sp, layout=layout)\niplot(fig)","9ccba776":"daily_sales_by_item = train.groupby(['date', 'item_id'], as_index=False, axis=0)['sales'].sum()\ndaily_sales_by_item = daily_sales_by_item.sort_values('date', axis=0)\n\nitems = train.item_id.unique()\ndaily_sales_by_item_sp = []\nfor item in items[450:550] :\n    dummy = daily_sales_by_item[daily_sales_by_item.item_id == item]\n    daily_sales_by_item_sp.append(go.Scatter(x=dummy.date, y=dummy.sales, name=('item %s' %item)))\n    \nlayout = go.Layout(title='Daily sales by item', xaxis=dict(title='Date'), yaxis=dict(title='sales'))\nfig = go.Figure(data=daily_sales_by_item_sp, layout=layout)\niplot(fig)","24f88445":"test = pd.read_csv('test.csv')\nprint(test.shape)\ntest.head()","76e75643":"df_train = train.groupby([train.date.apply(lambda x: x.strftime('%Y-%m')), 'item_id', 'shop_id']).sum().reset_index()\ndf_train = df_train[['date','item_id','shop_id','item_cnt_day']]\ndf_train = df_train.pivot_table(index=['item_id','shop_id'], columns='date',\n                                values='item_cnt_day',fill_value=0).reset_index()\ndf_train.head()","933d3f2b":"df_train.info()","eb935f1e":"df_test = pd.merge(test, df_train, on=['item_id','shop_id'], how='left')\ndf_test = df_test.fillna(0)\ndf_test = df_test.drop(labels=['ID', 'shop_id', 'item_id'], axis=1)\ndf_test.head()","a2496ca5":"last_month = '2015-12'\ny_train = df_test[last_month]\nx_train = df_test.drop(labels=[last_month], axis=1)\nx_train = x_train.to_numpy()\ny_train = y_train.to_numpy()\ntrain_x, valid_x, train_y, valid_y = model_selection.train_test_split(x_train, y_train, \n                                                                      train_size=0.8, shuffle=True)\nprint(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)","8cd2be9e":"x_test = df_test.drop(labels=['2013-01'], axis=1)\nx_test = x_test.to_numpy()\nprint(x_test.shape)","cd125701":"def saleModel_mlp(input_shape) :\n    x_input = Input(input_shape)\n    x = Dense(64, activation='relu', use_bias=True, kernel_regularizer=regularizers.l2(0.01),\n              bias_regularizer=regularizers.l2(0.02))(x_input)\n    x = Dense(32, activation='relu', use_bias=True, kernel_regularizer=regularizers.l2(0.01),\n              bias_regularizer=regularizers.l2(0.02))(x)\n    x_out = Dense(1, activation=None)(x)\n    \n    model = Model(inputs=x_input, outputs=x_out, name='saleModel_mlp')\n    \n    return model","81b72792":"mlpModel = saleModel_mlp(np.shape(train_x[1,:]))\nmlpModel.summary()","0e7bd7b8":"optim = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.99)\nmlpModel.compile(optimizer=optim, metrics=['accuracy'], loss='mean_squared_error')","1b50f4fa":"nepochs = 200\nmlp_history = mlpModel.fit(x=train_x, y=train_y, validation_data=(valid_x, valid_y), epochs=nepochs, \n                           batch_size=512, verbose=1, shuffle=True, validation_split=0.0)","691a939e":"fig = plt.figure(figsize=(8,4))\nplt.plot(range(nepochs), mlp_history.history['loss'], 'r', label='train')\nplt.plot(range(nepochs), mlp_history.history['val_loss'], 'b', label='valid')\nplt.legend()\nplt.title('multi-layer perceptron')\nplt.xlabel('epochs')\nplt.ylabel('loss');","0f2d61f6":"def saleModel_lstm(input_shape) :\n    x_input = Input(input_shape)\n    x = LSTM(units=32, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n                        kernel_initializer='glorot_uniform', return_sequences=True)(x_input)\n    x = LSTM(units=16, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n                        kernel_initializer='glorot_uniform', return_sequences=False)(x)\n    x_out = Dense(1, activation=None)(x)\n    \n    model = Model(inputs=x_input, outputs=x_out, name='saleModel_lstm')\n    \n    return model","4f26f11c":"train_xx = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\nvalid_xx = valid_x.reshape((valid_x.shape[0], valid_x.shape[1], 1))\ntest_xx = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\nprint(train_xx.shape, valid_xx.shape, test_xx.shape)","55a8fc06":"lstmModel = saleModel_lstm(np.shape(train_xx[1,:, :]))\nlstmModel.summary()","fe56fd5d":"lstmModel.compile(optimizer=optim, loss='mean_squared_error', metrics=['accuracy'])\nlstm_history = lstmModel.fit(x=train_xx, y=train_y, validation_data=(valid_xx, valid_y), verbose=1,\n                            epochs=100, batch_size=1024, shuffle=True)","a9eadf67":"fig = plt.figure(figsize=(8,4))\nplt.plot(range(100), lstm_history.history['loss'], 'r', label='train')\nplt.plot(range(100), lstm_history.history['val_loss'], 'b', label='valid')\nplt.legend()\nplt.title('LSTM')\nplt.xlabel('epochs')\nplt.ylabel('loss');","f17825b2":"def saleModel_cnn(input_shape) :\n    x_input = Input(input_shape)\n    x = Conv1D(filters=64, padding='valid', strides=1, kernel_size=3)(x_input)\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size=2, strides=None, padding='valid')(x)\n    \n    x = Conv1D(filters=32, padding='valid', strides=1, kernel_size=3)(x)\n    x = Activation('relu')(x)\n    x = MaxPooling1D(pool_size=2, strides=None, padding='valid')(x)\n    \n    x = Flatten()(x)\n    x_out = Dense(1, activation=None)(x)\n    \n    model = Model(inputs=x_input, outputs=x_out, name='saleModel_cnn')\n    \n    return model","a6614fc9":"cnnModel = saleModel_cnn(np.shape(train_xx[1,:,:]))\ncnnModel.summary()","751d64a4":"cnnModel.compile(optimizer=optim, loss='mse', metrics=['accuracy'])\ncnn_history = cnnModel.fit(x=train_xx, y=train_y, validation_data=(valid_xx, valid_y), verbose=1,\n                          epochs=nepochs, batch_size=512, shuffle=True)","f24bb8db":"fig = plt.figure(figsize=(5,4))\nplt.plot(range(nepochs), cnn_history.history['loss'], 'r', label='train')\nplt.plot(range(nepochs), cnn_history.history['val_loss'], 'b', label='valid')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.title('1D CNN');","c145b2fc":"mlp_pred = mlpModel.predict(x_test)\nlstm_pred = lstmModel.predict(test_xx)\ncnn_pred = cnnModel.predict(test_xx)\nprint(mlp_pred, lstm_pred, cnn_pred)","20c57780":"submission = pd.read_csv('sample_submission.csv')\nsubmission.item_cnt_month = lstm_pred\nsubmission.to_csv ('submission.csv', index = None, header = True)","f0cad6be":"# Deep Learning for Time Series Forecasting","6c9dc38b":"## 3. Load test data","11ac61d5":"### 2.2. Daily sales","881a44df":"### 2.3. Daily sales by store","b15a0957":"## 5. Multi-layer perceptron","82f76e2b":"## 6. LSTM","7707bc8a":"## 1. Load data","bdb614f9":"## 2. Explore data \n\n### 2.1. Overall daily sales","ffb23bc7":"### 2.4. Daily sales by item","a7a77453":"## 4. Prepare time series","489c2e16":"## 7. Convolutional NN"}}