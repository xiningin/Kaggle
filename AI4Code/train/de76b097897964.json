{"cell_type":{"f5d13e2e":"code","4acd91d2":"code","1c4b8cbb":"code","06671bfa":"code","3289825f":"code","aa20a5fa":"code","40b1c436":"code","f6988414":"code","59b1913c":"code","95d231a5":"code","fa91e8ac":"code","3fca9d33":"code","396249c2":"code","6285deb3":"code","1fe51454":"code","7d0d1a3b":"code","8aeb19ca":"code","a6079550":"code","d158c496":"code","04b7ec75":"code","f3a7d060":"code","85e9f366":"code","d278d5a6":"code","6e310fac":"code","2c267c79":"code","025c6860":"code","62899883":"code","a4cf01c3":"code","cba51bad":"code","0ac87db6":"code","56cb1cc9":"code","342b2181":"code","acdb39cf":"code","e0b0cbf6":"code","a39e2ece":"code","dad302b0":"code","caf712d0":"code","0241da03":"code","e4593b2b":"code","1695d1ec":"code","0e76ccb8":"code","49de0298":"code","67053e09":"code","94dea62d":"code","577d941e":"code","439d6061":"code","78392517":"code","42a85ba1":"code","e4de3645":"code","8e011d5e":"code","2c36929b":"code","fea3e0d2":"code","f3d47892":"code","f58c5689":"code","9932925a":"code","45f958f8":"code","0f68406c":"code","9e7cb920":"code","7714cbc9":"code","d23579c5":"code","803cebd1":"code","ae3654d4":"code","3e038093":"code","1181c0ca":"code","b95f05e2":"code","d9172591":"code","40695c01":"code","fcd86c59":"code","4b148a0a":"code","2c9ab183":"code","ad43cdfc":"code","2eebedd7":"code","6d4474bc":"code","425bd5e5":"code","dcf81503":"code","0fb22888":"code","10e01a6e":"code","4e513f89":"code","16edb0fb":"code","7c793c3c":"code","9f6c7d5e":"code","da3c7533":"code","82604296":"code","e4ffe188":"code","0e6242ed":"code","e92c67a4":"code","bf1c90a5":"code","19e81d45":"code","a29b2ee9":"code","a0860627":"code","c989a720":"code","7322cec3":"code","7cbfbb31":"code","63f89c39":"markdown","496f6709":"markdown","91047dcb":"markdown","07be69e3":"markdown","00154d10":"markdown","1789aa79":"markdown","9778df6d":"markdown","899cd608":"markdown","0178f722":"markdown","5d969c00":"markdown","57f5e2ae":"markdown","51562b4d":"markdown","0ff097b7":"markdown","30bdb490":"markdown","2204e2d4":"markdown","967377af":"markdown","5946abac":"markdown","0dabcd0c":"markdown","ba3ddca1":"markdown","643d2502":"markdown","5437533d":"markdown","3a43e80c":"markdown","8e0e5566":"markdown","72bc55c6":"markdown","7140e539":"markdown","0662fdc4":"markdown","9e2c2b39":"markdown","5ada69ae":"markdown","ae49a5f2":"markdown","49e0e5b0":"markdown","32f6a492":"markdown","bf991f00":"markdown","6e7700de":"markdown","874018b9":"markdown","4a6c07fe":"markdown","347403e7":"markdown","bd5247ec":"markdown","ff0d8d29":"markdown","bcae3eab":"markdown","d38392b7":"markdown","2124bbc7":"markdown","72a77044":"markdown","b326f3da":"markdown"},"source":{"f5d13e2e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))","4acd91d2":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import AxesGrid\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","1c4b8cbb":"df = pd.read_csv(\"..\/input\/kag_risk_factors_cervical_cancer.csv\")","06671bfa":"df.head()","3289825f":"df_nan = df.replace(\"?\", np.nan)","aa20a5fa":"df_nan.head()","40b1c436":"df1 = df_nan.convert_objects(convert_numeric=True)","f6988414":"df1.hist()\nfig = plt.gcf()\nfig.set_size_inches(25,17)","59b1913c":"H = df1['Hinselmann'].T.sum()\nS = df1['Schiller'].T.sum()\nC = df1['Citology'].T.sum()\nB = df1['Biopsy'].T.sum()\nH+S+C+B","95d231a5":"sns.heatmap(df1.isnull(), cbar=False)","fa91e8ac":"df1.columns = df1.columns.str.replace(' ', '')  #deleting spaces for ease of use","3fca9d33":"df1.drop(['STDs:Timesincefirstdiagnosis','STDs:Timesincelastdiagnosis','STDs:cervicalcondylomatosis','STDs:AIDS'],inplace=True,axis=1)","396249c2":"df1.isnull().T.any().T.sum()","6285deb3":"sns.heatmap(df1.isnull(), cbar=False)\ndf.shape","1fe51454":"df = df1[df1.isnull().sum(axis=1) < 10]","7d0d1a3b":"df.shape","8aeb19ca":"sns.heatmap(df.isnull(), cbar=False)","a6079550":"numerical_df = ['Age', 'Numberofsexualpartners', 'Firstsexualintercourse','Numofpregnancies', 'Smokes(years)',\n                'Smokes(packs\/year)','HormonalContraceptives(years)','IUD(years)','STDs(number)']\ncategorical_df = ['Smokes','HormonalContraceptives','IUD','STDs','STDs:condylomatosis',\n                  'STDs:vulvo-perinealcondylomatosis', 'STDs:syphilis','STDs:pelvicinflammatorydisease', 'STDs:genitalherpes',\n                  'STDs:molluscumcontagiosum','STDs:HIV','STDs:HepatitisB', 'STDs:HPV', 'STDs:Numberofdiagnosis',\n                  'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Dx', 'Hinselmann', 'Schiller','Citology', 'Biopsy']","d158c496":"for feature in numerical_df:\n    print(feature,'',df[feature].convert_objects(convert_numeric=True).mean())\n    feature_mean = round(df[feature].convert_objects(convert_numeric=True).mean(),1)\n    df[feature] = df[feature].fillna(feature_mean)","04b7ec75":"(df['Age'] == 0).astype(int).sum() # checking if any 0 values in a column that could not contain such values","f3a7d060":"for feature in categorical_df:\n    \n    df[feature] = df[feature].convert_objects(convert_numeric=True).fillna(0.0)\n    \n#Filling binominal values with 0, with the assumption that if present, feature would have been recorded","85e9f366":"df5 = df.copy()","d278d5a6":"df5['YAFSI'] = df5['Age'] - df5['Firstsexualintercourse']\ndf5['CNT'] = df.astype(bool).sum(axis=1)\ndf5['SEX'] = (df5['Numofpregnancies']+1) * (df5['Numberofsexualpartners']+1)\ndf5['FirstSexZ'] = (((df5['Firstsexualintercourse']+1) - (df5.loc[:,'Firstsexualintercourse'].mean())+1) \/ (df5.loc[:,'Firstsexualintercourse'].var()+1)*100)\ndf5['SexZ'] = (((df5['Numberofsexualpartners']+1) - (df5.loc[:,'Numberofsexualpartners'].mean())+1) \/ (df5.loc[:,'Numberofsexualpartners'].var()+1)*100)\ndf5['PILL'] = (((df5['HormonalContraceptives(years)']+1) - (df5.loc[:,'HormonalContraceptives(years)'].mean())+1) \/ (df5.loc[:,'HormonalContraceptives(years)'].var()+1)*100)\ndf5['SSY'] = df5['Age'] - df5['Smokes(years)']\ndf5['SPYP'] = df5['Numberofsexualpartners'] \/ df5['YAFSI']\ndf5['SP'] = df5['Smokes(years)'] \/ df5['Age']\ndf5['HCP'] = df5['HormonalContraceptives(years)'] \/ df5['Age']\ndf5['STDP'] = df5['STDs(number)'] \/ df5['Age']\ndf5['IUDP'] = df5['IUD(years)'] \/ df5['Age']\ndf5['TSP'] = df5['Smokes(packs\/year)'] * df5['Smokes(years)']\ndf5['NPP'] = df5['Numofpregnancies'] \/ df5['Age']\ndf5['NSPP'] = df5['Numberofsexualpartners'] \/ df5['Age']\ndf5['NDP'] = df5['STDs:Numberofdiagnosis'] \/ df5['Age']\ndf5['YAHC'] = df5['Age'] - df5['HormonalContraceptives(years)']\ndf5['YAIUD'] = df5['Age'] - df5['IUD(years)']\ndf5['NPSP'] = df5['Numofpregnancies'] \/ df5['Numberofsexualpartners']\ndf5['IUDSY'] = df5['IUD(years)'] \/ df5['YAFSI']\ndf5['HCSY'] = df5['HormonalContraceptives(years)'] \/ df5['YAFSI']","6e310fac":"df5.replace([np.inf, -np.inf], np.nan, inplace = True) #deleting extreme values caused by calculations","2c267c79":"df = df5.copy()","025c6860":"numerical_df = ['Age', 'Numberofsexualpartners', 'Firstsexualintercourse','Numofpregnancies', 'Smokes(years)',\n                'Smokes(packs\/year)','HormonalContraceptives(years)','IUD(years)','STDs(number)', 'YAFSI', 'CNT',\n                'FirstSexZ', 'SexZ', 'PILL','SSY','SPYP', 'SP', 'HCP', 'STDP', 'IUDP', 'TSP', 'NPP', 'NSPP', 'NDP',\n                'YAHC', 'YAIUD', 'NPSP', 'IUDSY', 'HCSY']","62899883":"#Adding in our newly created values to the NA filter\nfor feature in numerical_df:\n    print(feature,'',df[feature].convert_objects(convert_numeric=True).mean())\n    feature_mean = round(df[feature].convert_objects(convert_numeric=True).mean(),1)\n    df[feature] = df[feature].fillna(feature_mean)","a4cf01c3":"sns.heatmap(df.isnull(), cbar=False)","cba51bad":"df.columns[df.isna().any()].tolist()","0ac87db6":"figure = plt.figure(figsize=(6,9), dpi=100);    \ngraph = figure.add_subplot(111);\n\ndfN = df['Age']\nfreq = pd.value_counts(dfN)\nbins = freq.index\nx=graph.bar(bins, freq.values) #gives the graph without NaN\n\nplt.ylabel('Frequency')\nplt.xlabel('Age')\nfigure.show()","56cb1cc9":"dfN.eq(0).any().any()","342b2181":"df[df['Age'] > 58]","acdb39cf":"df['Age'] = np.clip(df['Age'], a_max=58, a_min=None)","e0b0cbf6":"figure = plt.figure(figsize=(6,9), dpi=100);    \ngraph = figure.add_subplot(111);\n\ndfN = df['Age']\nfreq = pd.value_counts(dfN)\nbins = freq.index\nx=graph.bar(bins, freq.values) #gives the graph without NaN\n\nplt.ylabel('Frequency')\nplt.xlabel('Age')\nfigure.show()","a39e2ece":"category_df = ['Hinselmann', 'Schiller','Citology', 'Biopsy']","dad302b0":"for feature in categorical_df:\n   sns.factorplot(feature,data=df,size=3,kind='count')","caf712d0":"corrmat = df.corr()","0241da03":"k = 30 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'HormonalContraceptives')['HormonalContraceptives'].index\n\ncm = df[cols].corr()\n\nplt.figure(figsize=(20,20))\n\nsns.set(font_scale=1.5)\nhm = sns.heatmap(cm, cbar=True, cmap='Set1' ,annot=True,vmin=0,vmax =1, square=True, fmt='.2f', annot_kws={'size': 12},\n                 yticklabels = cols.values, xticklabels = cols.values)\nplt.show()","e4593b2b":"df = df.round()","1695d1ec":"target = df['Hinselmann'] | df['Schiller'] | df['Citology'] | df['Biopsy'] ","0e76ccb8":"df = df.drop(columns=['Hinselmann', 'Schiller', 'Citology', 'Biopsy', 'Dx', 'Dx:Cancer', 'Smokes(years)', 'Smokes(packs\/year)'])","49de0298":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nX_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.4, random_state=1) # 60% training and 40% test\nX_tr, X_te, y_tr, y_te = train_test_split(df, target, test_size=0.2, random_state=1) # 60% training 20% test for SMOTE()","67053e09":"figure = plt.figure(figsize=(2,4), dpi=100);    \ngraph = figure.add_subplot(111);\n\ndf5 = y_train\nfreq = pd.value_counts(y_train)\nbins = freq.index\nx=graph.bar(bins, freq.values) #gives the graph without NaN\n\nplt.ylabel('Frequency')\nplt.xlabel('Level of Cancer Test Output in Training Set')\nfigure.show()","94dea62d":"## oversampling\nfrom imblearn.over_sampling import SMOTE, ADASYN\nX_trOVR, y_trOVR = SMOTE(random_state=2).fit_sample(X_tr, y_tr)","577d941e":"figure = plt.figure(figsize=(2,4), dpi=100);    \ngraph = figure.add_subplot(111);\n\ndf5 = y_trOVR\nfreq = pd.value_counts(y_trOVR)\nbins = freq.index\nx=graph.bar(bins, freq.values) #gives the graph without NaN\n\nplt.ylabel('Frequency')\nplt.xlabel('Level of Cancer Test Output in Oversampled Set')\nfigure.show()","439d6061":"#starting with a simple decision tree, attempting to classify the origional data into cancer test or no\nfrom sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)","78392517":"y_pred = clf.predict(X_test)\nprint(\"Accuracy of Decision Tree\",metrics.accuracy_score(y_test, y_pred))","42a85ba1":"import scikitplot as skplt\npreds = clf.predict(X_test)\nskplt.metrics.plot_confusion_matrix(y_true=y_test, y_pred=preds)\nplt.show()","e4de3645":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn import tree\nfrom sklearn.datasets import load_wine\nfrom IPython.display import SVG\nfrom graphviz import Source\nfrom IPython.display import display\n","8e011d5e":"import graphviz \ndot_data = tree.export_graphviz(clf, out_file=None) \ngraph = graphviz.Source(dot_data) \ngraph.render(\"Tree\") \ndot_data = tree.export_graphviz(clf, out_file=None, filled=True,\n                                feature_names=X_test.columns, class_names=[\"0\", \"1\"])  \ngraph = graphviz.Source(dot_data)  \ngraph","2c36929b":"importances = clf.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(1)\nplt.figure(figsize=(15,20), dpi=100); \nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), X_train.columns)\nplt.xlabel('Relative Importance')","fea3e0d2":"clf = tree.DecisionTreeClassifier()\nclf2 = clf.fit(X_trOVR, y_trOVR)","f3d47892":"y_pred2 = clf2.predict(X_te)","f58c5689":"print(\"Accuracy of Oversampled Decision Tree:\",metrics.accuracy_score(y_te, y_pred2))","9932925a":"import graphviz \ndot_data = tree.export_graphviz(clf2, out_file=None) \ngraph = graphviz.Source(dot_data) \ngraph.render(\"Tree\") \ndot_data = tree.export_graphviz(clf2, out_file=None, filled=True,\n                                feature_names=X_test.columns, class_names=[\"0\", \"1\"])  \ngraph = graphviz.Source(dot_data)  \ngraph ","45f958f8":"preds2 = clf2.predict(X_te)\nskplt.metrics.plot_confusion_matrix(y_true=y_te, y_pred=preds2)\nplt.show()","0f68406c":"#print('Value counts of each target variable:',target.value_counts())\n#cancer_df_label = target.astype(int)\n#cancer_df_label = cancer_df_label.values.ravel()\n\n#print('Final feature vector shape:',df.shape)\n#print('Final target vector shape',cancer_df_label.shape)","9e7cb920":"importances = clf2.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(1)\nplt.figure(figsize=(13,17), dpi=100); \nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), X_train.columns)\nplt.xlabel('Relative Importance')","7714cbc9":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel","d23579c5":"sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\nrand = sel.fit(X_train, y_train)\n#rand2 = sel.fit(X_trainOVR, y_trainOVR)","803cebd1":"selected_feat= X_train.columns[(sel.get_support())]\nlen(selected_feat)","ae3654d4":"print(selected_feat)","3e038093":"k = 16 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'HCSY')['HCSY'].index\n\ncm = df[selected_feat].corr()\n\nplt.figure(figsize=(16,16))\n\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, cmap='Set1' ,annot=True,vmin=0,vmax =1, square=True, fmt='.2f', annot_kws={'size': 10},\n                 yticklabels = cols.values, xticklabels = cols.values)\nplt.show()","1181c0ca":"dfFOR = df[selected_feat]","b95f05e2":"dfFOR.shape","d9172591":"X_train2, X_test2, y_train2, y_test2 = train_test_split(dfFOR, target, test_size=0.4, random_state=1) # 60% training and 40% test\nX_tr2, X_te2, y_tr2, y_te2 = train_test_split(dfFOR, target, test_size=0.2, random_state=1) # 80% training and 20% test","40695c01":"## oversampling\nX_trOVR2, y_trOVR2 = SMOTE(random_state=2).fit_sample(X_tr2, y_tr2)","fcd86c59":"clf3 = clf.fit(X_train2, y_train2)\nclf4 = clf.fit(X_trOVR2, y_trOVR2)","4b148a0a":"y_pred3 = clf3.predict(X_test2)\ny_pred4 = clf4.predict(X_te2)\nprint(\"Accuracy of Trimmed Decision Tree:\",metrics.accuracy_score(y_test2, y_pred3))\nprint(\"Accuracy of Trimmed Oversampled Decision Tree:\",metrics.accuracy_score(y_te2, y_pred4))\nprint(\"Recall of Trimmed Decision Tree:\",metrics.recall_score(y_test2, y_pred3))\nprint(\"Recall of Trimmed Oversampled Decision Tree:\",metrics.recall_score(y_te2, y_pred4))","2c9ab183":"preds3 = clf3.predict(X_test2)\nskplt.metrics.plot_confusion_matrix(y_true=y_test2, y_pred=preds3)\nplt.title('Trimmed DT')\nplt.show()\npreds4 = clf4.predict(X_te2)\nskplt.metrics.plot_confusion_matrix(y_true=y_te2, y_pred=preds4)\nplt.title('Trimmed and Oversampled DT')\nplt.show()","ad43cdfc":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import AdaBoostClassifier\n\nclfAB = AdaBoostClassifier(n_estimators=100)\nscores = cross_val_score(clfAB, X_train2, y_train2, cv=5)\nscores.mean()  ","2eebedd7":"clfABA = clfAB.fit(X_train, y_train)\ny_predAB = clfAB.predict(X_test)\nprint(\"Accuracy of Origional AdaBoost:\",metrics.accuracy_score(y_test, y_predAB))\n\nclfAB2 = clfAB.fit(X_train2, y_train2)\ny_predAB2 = clfAB2.predict(X_test2)\nprint(\"Accuracy of Trimmed AdaBoost:\",metrics.accuracy_score(y_test2, y_predAB2))\n\nclfAB3 = clfAB.fit(X_trOVR2, y_trOVR2)\ny_predAB2 = clfAB2.predict(X_te2)\nprint(\"Accuracy of Oversampled and Trimmed AdaBoost:\",metrics.accuracy_score(y_te2, y_predAB2))","6d4474bc":"skplt.metrics.plot_confusion_matrix(y_true=y_test, y_pred=y_predAB)\nplt.title('Origional Adaboost')\nplt.show()\n\npredAB2 = clfAB2.predict(X_test2)\nskplt.metrics.plot_confusion_matrix(y_true=y_test2, y_pred=predAB2)\nplt.title('Trimmed Adaboost')\nplt.show()\n\n#predAB3 = clfAB3.predict(X_test)\nskplt.metrics.plot_confusion_matrix(y_true=y_te2, y_pred=y_predAB2)\nplt.title('Adaboost Oversampled and Trimmed')\nplt.show()","425bd5e5":"from sklearn.svm import SVC\nclfs = SVC(gamma='auto')\nsvm = clfs.fit(X_train, y_train) \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)\nsv = svm.predict(X_test)","dcf81503":"from sklearn.svm import SVC\nclfs = SVC(gamma='auto')\nsvm = clfs.fit(X_train2, y_train2) \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)\nsvv = svm.predict(X_test2)","0fb22888":"clfs = SVC(gamma='auto')\nsvm = clfs.fit(X_trOVR2, y_trOVR2) \nSVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)\nsvvv = svm.predict(X_te2)","10e01a6e":"print(\"Accuracy of SVM\",metrics.accuracy_score(y_test, sv))\nprint(\"Accuracy of SVM Trimmed\",metrics.accuracy_score(y_test2, svv))\nprint(\"Accuracy of SVM Trimmed\",metrics.accuracy_score(y_te2, svvv))","4e513f89":"skplt.metrics.plot_confusion_matrix(y_true=y_test, y_pred=sv)\nplt.title('SVM Origional')\nplt.show()\n\nskplt.metrics.plot_confusion_matrix(y_true=y_test2, y_pred=svv)\nplt.title('SVM Trimmed')\nplt.show()\n\nskplt.metrics.plot_confusion_matrix(y_true=y_te2, y_pred=svvv)\nplt.title('SVM Trimmed and Oversampled')\nplt.show()","16edb0fb":"from sklearn.utils import resample\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom matplotlib import pyplot\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nimport statistics\n\n# load dataset\ndata = df\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = DecisionTreeClassifier()\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerDT = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperDT = min(1.0, np.percentile(stats, p))\nmeanDT = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanDT, lowerDT*100, upperDT*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerDT2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperDT2 = min(1.0, np.percentile(stats2, p))\nmeanDT2 = statistics.mean(stats2)\nprint('%.3f average recall, confidence interval %.2f%% and %.2f%%' % (meanDT2, lowerDT2*100, upperDT2*100))","7c793c3c":"# load dataset\ndata = df\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = RandomForestClassifier()\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerRF = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperRF = min(1.0, np.percentile(stats, p))\nmeanRF = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanRF, lowerRF*100, upperRF*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerRF2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperRF2 = min(1.0, np.percentile(stats2, p))\nmeanRF2 = statistics.mean(stats2)\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanRF2, lowerRF2*100, upperRF2*100))","9f6c7d5e":"# load dataset\ndata = dfFOR\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = DecisionTreeClassifier()\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerDTT = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperDTT = min(1.0, np.percentile(stats, p))\nmeanDTT = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanDTT, lowerDTT*100, upperDTT*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerDTT2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperDTT2 = min(1.0, np.percentile(stats2, p))\nmeanDTT2 = statistics.mean(stats2)\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanDTT2, lowerDTT2*100, upperDTT2*100))","da3c7533":"from sklearn.linear_model import LogisticRegression\n# load dataset\ndata = dfFOR\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = LogisticRegression(random_state=0, solver='lbfgs',class_weight='balanced')\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerLRT = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperLRT = min(1.0, np.percentile(stats, p))\nmeanLRT = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanLRT, lowerLRT*100, upperLRT*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerLRT2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperLRT2 = min(1.0, np.percentile(stats2, p))\nmeanLRT2 = statistics.mean(stats2)\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanLRT2, lowerLRT2*100, upperLRT2*100))","82604296":"from sklearn.linear_model import LogisticRegression\n# load dataset\ndata = df\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = LogisticRegression(random_state=0, solver='lbfgs',class_weight='balanced')\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerLR = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperLR = min(1.0, np.percentile(stats, p))\nmeanLR = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanLR, lowerLR*100, upperLR*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerLR2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperLR2 = min(1.0, np.percentile(stats2, p))\nmeanLR2 = statistics.mean(stats2)\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanLR2, lowerLR2*100, upperLR2*100))","e4ffe188":"from sklearn.svm import LinearSVC\n# load dataset\ndata = df\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = LinearSVC(random_state=0, tol=1e-5, class_weight='balanced')\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerS = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperS = min(1.0, np.percentile(stats, p))\nmeanSVC = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanSVC, lowerS*100, upperS*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerS2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperS2 = min(1.0, np.percentile(stats2, p))\nmeanSVC2 = statistics.mean(stats2)\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanSVC2, lowerS2*100, upperS2*100))","0e6242ed":"from sklearn.svm import LinearSVC\n# load dataset\ndata = dfFOR\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = LinearSVC(random_state=0, tol=1e-5, class_weight='balanced')\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerST = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperST = min(1.0, np.percentile(stats, p))\nmeanSVCT = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanSVCT, lowerST*100, upperST*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerST2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperST2 = min(1.0, np.percentile(stats2, p))\nmeanSVCT2 = statistics.mean(stats2)\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanSVCT2, lowerST2*100, upperST2*100))","e92c67a4":"from sklearn.ensemble import GradientBoostingClassifier\n# load dataset\ndata = df\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=2, random_state=0)\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerG = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperG = min(1.0, np.percentile(stats, p))\nmeanG = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanG, lowerG*100, upperG*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerG2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperG2 = min(1.0, np.percentile(stats2, p))\nmeanG2 = statistics.mean(stats2)\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanG2, lowerG2*100, upperG2*100))","bf1c90a5":"from sklearn.ensemble import GradientBoostingClassifier\n# load dataset\ndata = dfFOR\nvalues = data.values\n# configure bootstrap\nn_iterations = 100\nn_size = int(len(data) * 0.50)\n# run bootstrap\nstats = list()\nstats2 = list()\nfor i in range(n_iterations):\n\t# prepare train and test sets\n\ttrain = resample(values, n_samples=n_size)\n\ttest = np.array([x for x in values if x.tolist() not in train.tolist()])\n\t# fit model\n\tmodel = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=2, random_state=0)\n\tmodel.fit(train[:,:-1], train[:,-1])\n\t# evaluate model\n\tpredictions = model.predict(test[:,:-1])\n\tscore = accuracy_score(test[:,-1], predictions)\n\tscore2 = recall_score(test[:,-1], predictions, average = 'macro')\n\t#print(score)\n\tstats.append(score)\n\t#print(score2)\n\tstats2.append(score2)\n# plot scores\npyplot.hist(stats)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerGT = max(0.0, np.percentile(stats, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperGT = min(1.0, np.percentile(stats, p))\nmeanGT = statistics.mean(stats)\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanGT, lowerGT*100, upperGT*100))\n\n# plot scores\npyplot.hist(stats2)\npyplot.show()\n# confidence intervals\nalpha = 0.9\np = ((1.0-alpha)\/2.0) * 100\nlowerGT2 = max(0.0, np.percentile(stats2, p))\np = (alpha+((1.0-alpha)\/2.0)) * 100\nupperGT2 = min(1.0, np.percentile(stats2, p))\nmeanGT2 = statistics.mean(stats2)\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanGT2, lowerGT2*100, upperGT2*100))","19e81d45":"print('Decision Tree')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanDT, lowerDT*100, upperDT*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanDT2, lowerDT2*100, upperDT2*100))\nprint('Decision Tree Trimmed')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanDTT, lowerDTT*100, upperDTT*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanDTT2, lowerDTT2*100, upperDTT2*100))\nprint('Random Forest Classifier')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanRF, lowerRF*100, upperRF*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanRF2, lowerRF2*100, upperRF2*100))\nprint('Random Forest Classifier Trimmed')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanDT, lowerDT*100, upperDT*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanDT2, lowerDT2*100, upperDT2*100))\nprint('Logistic Regression')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanLR, lowerLR*100, upperLR*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanLR2, lowerLR2*100, upperLR2*100))\nprint('Logistic Regression Trimmed')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanLRT, lowerLRT*100, upperLRT*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanLRT2, lowerLRT2*100, upperLRT2*100))\nprint('SVC')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanSVC, lowerS*100, upperS*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanSVC2, lowerS2*100, upperS2*100))\nprint('SVC Trimmed')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanSVCT, lowerST*100, upperST*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanSVCT2, lowerST2*100, upperST2*100))\nprint('Gradient Boosting')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanG, lowerG*100, upperG*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanG2, lowerG2*100, upperG2*100))\nprint('Gradient Boosting Trimmed')\nprint('%.3f average Accuracy with confidence interval %.1f%% and %.1f%%' % (meanGT, lowerGT*100, upperGT*100))\nprint('%.3f average recall with confidence interval %.1f%% and %.1f%%' % (meanGT2, lowerGT2*100, upperGT2*100))\n","a29b2ee9":"clf = tree.DecisionTreeClassifier()\nclf2 = clf.fit(X_train2, y_train2)\n\nimportances = clf2.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(1)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), dfFOR.columns)\nplt.xlabel('Relative Importance')","a0860627":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\npermumtation_impor = PermutationImportance(clf2, random_state=2019).fit(X_test2, y_test2)\neli5.show_weights(permumtation_impor, feature_names = X_test2.columns.tolist())","c989a720":"from pdpbox import pdp, get_dataset, info_plots\nrandom_forest = RandomForestClassifier(n_estimators=500, random_state=2019).fit(X_test2, y_test2)\ndef pdpplot( feature_to_plot, pdp_model = clf2, pdp_dataset = X_test2, pdp_model_features = X_test2.columns):\n    pdp_cancer = pdp.pdp_isolate(model=pdp_model, dataset=pdp_dataset, model_features=pdp_model_features, feature=feature_to_plot)\n    fig, axes = pdp.pdp_plot(pdp_cancer, feature_to_plot, figsize = (13,6),plot_params={})\n     #_ = axes['pdp_ax'].set_ylabel('Probability of Cancer')\n    \npdpplot('CNT')\npdpplot('PILL')\npdpplot('TSP')\npdpplot('YAFSI')\npdpplot('YAHC')\npdpplot('SSY')\npdpplot('SEX')\npdpplot('SexZ')\npdpplot('HormonalContraceptives(years)')\npdpplot('YAIUD')\npdpplot('FirstSexZ')\npdpplot('Numofpregnancies')\npdpplot('YAIUD')\n\nplt.show()\n","7322cec3":"#Remember the trimmed data set\n#X_train2, X_test2, y_train2, y_test2 = train_test_split(dfFOR, target, test_size=0.4, random_state=1) # 60% training and 40% test\n\nclf = tree.DecisionTreeClassifier()\n\nclfFINAL = clf.fit(X_train2, y_train2)\ny_pred = clfFINAL.predict(X_test2)\n\nimport graphviz \ndot_data = tree.export_graphviz(clfFINAL, out_file=None) \ngraph = graphviz.Source(dot_data) \ngraph.render(\"Tree\") \ndot_data = tree.export_graphviz(clfFINAL, out_file=None, filled=True,\n                                feature_names=X_test2.columns, class_names=[\"0\", \"1\"])  \ngraph = graphviz.Source(dot_data)  \ngraph","7cbfbb31":"predicted_probas = clfFINAL.predict_proba(X_te2)\nskplt.metrics.plot_cumulative_gain(y_te2, predicted_probas)\nplt.show()\nprint(\"Accuracy of Decision Tree\",metrics.accuracy_score(y_test2, y_pred))\nprint(\"Recall of Decision Tree\",metrics.recall_score(y_test2, y_pred))","63f89c39":"Although SVM is a powerful model, it certainly does not seem to fit with the data and was unable to pick up on positive cancer tests. This model, however, does a great job of showing how much accuracy can fool, this model adds no value, but has great accuracy.  Moving on to some other methods","496f6709":"Dropping the specific features that were used to create the target to avoid data leak","91047dcb":"First the creation of a target variable, one that combines all the positive features of all cancer tests. In reality [target=1] = cancer test performed\nIn doing so all modeling can be of a categorical and binary nature, without the confusion of multiple classes.","07be69e3":"Creating a whole new set of features, mostly creating features with values using AGE, and denoting the length of the condition. A few of the features are common sense and add to the models. Smokes(packs\/year) and Smokes(years) will be deleted in favor of \"TSP\"\n\na few of the variables are Z-scores of other numberical variables such as Numofpregnancies, Numberofsexualpartners, HormonalContraceptives(years), and Firstsexualintercourse","00154d10":"To visualize the lack of certain values in the dataset, we will first graphically inspect the data. Wherever a bar is shown there is a mising value. ","1789aa79":"Initial testing shows that the Trimmed Decision tree performed really quite well, the rest of the modeling portion will be to verify that this is the correct model for us to use during deployment or to tune to a further degree.","9778df6d":"With only 1 positive in the set, we will take the risk and delete these extreme values, they can skew many of our features too easily","899cd608":"**PART 3: DATA MANIPULATION**\n\nThere are plenty of missing\/NaN values in this dataset, we need to efficiently filter and create a good way to delete them. Firstly, let's get rid of Time Since First Diagnosis and Time Since Last Diagnosis","0178f722":"**PART 5: DEPLOYMENT**","5d969c00":"There are still over 190 distinct measurements that have missing values. Due to the size of our dataset, instead of simply deleting them, lets come up with a better way of handling them. Let's see if there are some entries that are particularly bad (missing many values)\n\nAfter a few tests, the best limiting number is 10, with entries missing more than 10 variables are worthy of deletion","57f5e2ae":"There are 16 features that are chosen as important by the Random forest model, they are listed below. Limiting the inputs of models allows us to eliminate confusion within the model, as well as trimming the about of variables that the model has to compute.  ","51562b4d":"In theory, an ensemble method should be our best bet for data like this (small and difficult), but we don't see a hike in preformance","0ff097b7":"In order to get at the truth behind this model, we are going to examine the strength of the features against each other and hopefully glean what our business objective is:\na better understanding of what causes cervical cancer and how strong each risk factor is.","30bdb490":"As shown in person number 2: all \"?\" have been converted to a NAN","2204e2d4":"Although we show a fairly good accuracy, let us see how well the model did at picking up \"true\" cancer cases:","967377af":"Immediately there are signs for concern, as most important features in the Decision tree are not included\nHCSC, IUDSY, (NPSP is included)\n\nSo we will create a new dataframe that can hold this new trimmed dataset","5946abac":"As we begin to inspect feature importance, it is easiest to simply look at our decision tree. The beauty of such a simple model is contained in the simplicity of understanding. However, for other models something involving partial dependancy plots (each variable moving alone and its impact on the model output) may be more insightful. \nWe will keep the ranking of feature importances, but use a better model type to examine partial depandancies. ","0dabcd0c":"**PART 4: MODELING**","ba3ddca1":"To determine a true benchmark for performance, cross-validation is going to be the best option. Cross-validations allows the model to run multiple times, fitting to new data, then testing on other data. The preferred method for cross-validation is k-folds, however, but to the size of this dataset and the need to randomly include as many positive class members as possible, a bootstrapping method is used. Bootstrapping allows the model to go get a completely new sample each and every time WITH replacement. So sample 356 that is positive has an equal likelihood of appearing in every training and test sample. After this method has been performed some number of time (I will use 100) all of the models are averaged to gain a true understanding of the robustness of each model. \n\nI perform bootstrapped cross-validation with both the trimmed and original dataset for a number of models. ","643d2502":"Then to test the Acccuracy:","5437533d":"All double checked, we have no null values and have corrected missing values to mean values for categorical variables, and to 0 for binominal variables. Time to start considering Modeling! \n\nThe only feature that worries me is the age column. As shown below the distribution is highly right-tailed, with a few very \"extreme\" values. Will the few very extreme values have an impact on the modeling?","3a43e80c":"GREAT! Now we can fill values more efficiently with reasonable replacement values. This dataset contains two types of values, numerical, and binominal values indicating the presence of a certain diagnosis or risk factor in that patient. ","8e0e5566":"We see some very sparse features in the STDs feature group, we will leave them in for now and investigate later","72bc55c6":"This code is heavily populated with a \"?\" value. This value is either due to informal sampling, a failure in data input, or a combination of both. However, we can replace these values with something our computer can understand more easily, a NaN value","7140e539":"Very good, this particular model only missed 10 positive values and was able to effectively \"catch\" 27 risky patients, we can also visualize the image to inspect the relationships\n","0662fdc4":"SMOTE is an oversampling method that creates its own synthetic positive samples from the given data in order to overrepresent positive data examples. SMOTE uses a k-nearest-neighbors algorithm to synthetically create the sample class and has been shown to be especially effective in handwritten character recognition. ","9e2c2b39":"The numerically created variables seem to have a much larger impact on our models thus far. However, there is some multicollinearity here as shown in our heatmaps, and eliminating as many variables as possible should be helpful to our model. Therefore, in order to attempt at a smaller learning sample, a Random Forest feature selection tool is applied, attempting to trim down the variables.","5ada69ae":"***Introduction***\nChristian R. Lynn M.S. Data Science\n07\/13\/2019","ae49a5f2":"As we can see there are two distinct shapes of data in this project, a right-tailed distribution of a continuous variable, and many binominal variables that seem to take the shape (1\/0) with the zeros heavily outweighing the ones. Looking initially I see three problem features:\nAge, there are a few very large numbers that may influence the modeling process heavily\nSTDs:AIDS looks like there are no positives, and may be a great variable to trim out of modeling dataset\nSTDs:Vaginal Condylomatosis looks as if there are no positive instances as well. \n\nWhat is also very important to note is the lack of a target function. In this case, we are going to manufacture a target variable using some of the features above. \n\n'Hinselmann', 'Schiller','Citology', and 'Biopsy' are all tests for cancer\n\nHinselmann's test is also known as a colposcopy test, is an early diagnostic\/preventative test for cancer, it involves detecting and treating precancerous lesions early via colposcope.\n\nSchiller's test is a preliminary test for cancer in which the cervix is painted with a solution of iodine and potassium iodide and which highlights cancerous tissues white or yellow - this test is not known for being patricularly accurate, but will highlight most tissue that is unhealthy (inflammation, unceration...)\n\nA Cytology is a test preformed on body fluid that will help indicate the presence of canceroud tissue, it is not as accurate as a full bioposy, but is much easier to obtain a sample.\n\nThese features, along with biopsy will be used as the target variable for cancer. Concidering their lack of presence in the dataset as shown below:","49e0e5b0":"Our best performing model is.......\n\n\n\na simple decision tree.....\nWhile rather unclimactic, it is good to have validation that this modeling method is both able to stand up to some other pretty advanced methods, as well as being able to fit a variety of samples and still perform. Gradient boosting did offer some good numbers, but the great benifit of choosing a simple model over a more complex one will make life easier within deployment.","32f6a492":"FOR THE REMAINDER OF THIS KERNAL:\n* X_test, X_train, ect... is the basic data\n* X_test2, X_train2... is the data that used a RF feature selector to trim the data\n* X_testOVR2, trainOVR2 is data that has used SMOTE() oversampling\n* and X_trOVR2, y_trOVR2 is data that has used SMOTE() oversampling and has been trimmed","bf991f00":"Overall, this method looks rather robust and simple in explanation. How does this model compare when oversamples with the SMOTE method?","6e7700de":"In order to take a quick look at the data:","874018b9":"This is the final decision tree that will be left to production. Following a relatively simple set of questions or steps, this model is able to correctly identify cases where a cancer diagnosis is highly likely or times where a patient should be tested. Although not groundbreaking, this simple tool could be deployed to an API, able to be used by healthcare professionals using records they are already keeping. With some integration, a warning score could be displayed at the top of a patient's chart, giving statistical odds of danger. With more work and more data, there could be a steady improvement of this algorithm over time after deployment. Overall the lack of positive data is a concern. One that may be addressed at a later point with more data. ","4a6c07fe":"For our final deployment we look at our decision tree with trimmed features:","347403e7":"Let's take a deeper dive into what type of data we have. Graphically represented, we can understand all the data quite easily all at once","bd5247ec":"Features such as CNT, PILL, YAFSI, YAHC, and SEX all show that there is something to be learned from each feature itself. \nAs the CNT of features goes up, we see an increaced risk of cancer. PILL, suprisingly, seems to trend in the opposite direction. \nAs more data becomes available, features may be able to be studied like this. ","ff0d8d29":"This analysis will follow the CRISP-DM industry standard practices, following the basic format outlined below:\n* 1.) Business Understanding\n* 2.) Data Understanding\n* 3.) Data Preparation\n* 4.) Modeling\n* 5.) Deployment\n\nThis dataset obtained from Kaggle, is presented with the goal of identifying and creating a model to identify the risk factors associated with cervical cancer. However, due to the nature of the data, it is rather difficult to identify a superiorly performing model, and the understanding gained from any modeling technique is somewhat thin. ","bcae3eab":"AdaBoost did rather well with the raw dataset, and faltered the more data we took from the model. \nIt may an interesting model to choose if we need a more nuanced effort to train for final deployment","d38392b7":"**PARTS 1 AND 2: BUISNESS AND DATA UNDERSTANDING**","2124bbc7":"Splitting the data into two dataset splits, one is the more traditional split, with the other being a split that is specifically for SMOTE oversampling","72a77044":"According to our results so far SMOTE() is producing a better model.\nIn theory this should not be the case, as SMOTE upsampling this much data should be very difficult and would simply overfit the model","b326f3da":"We will fill all of the numerical value types with average values. After exhaustive investigating into the data, there was no need to more carefully fix the data."}}