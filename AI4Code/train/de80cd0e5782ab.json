{"cell_type":{"8da162c4":"code","25eb00da":"code","a6cf5416":"code","51a3266b":"markdown","ab0a0d44":"markdown","b7ab392b":"markdown","c43508e8":"markdown"},"source":{"8da162c4":"# Comment: Install Following Packages for Web Scrapping:\n\n\n#Code:\n# pip install selenium\n# pip install webdriver_manager\n# pip install webdriver","25eb00da":"# Comment: loading all the required library for webscrapping and saving the data into csv file.\n\n#Code:\n# import csv\n# from bs4 import BeautifulSoup\n# from selenium import webdriver\n# import pandas as pd\n\n\n# def get_url(search_term):\n\n#     Comment:  Genrate URL for search term\n\n#     Code:\n#     template='https:\/\/www.amazon.com\/s?k={}&ref=nb_sb_noss_2'\n#     search_term=search_term.replace(\" \",\"+\")\n    \n    \n#     Comment: add term query to url\n\n#     Code:\n#     url=template.format(search_term)\n    \n#     Comment: Add page query placeholder\n\n#     Code:\n#     url+='&page{}'  \n    \n#     return template.format(search_term)\n\n# def extract_record(item):\n#     Comment: First we will take the decrpition\n#     Code:\n#     atag=item.h2.a\n#     descrpition=atag.text.strip()\n#     new_url='https:\/\/www.amazon.com'+atag.get('href')\n    \n#     Comment:  Price\n#     Code:\n#     try:\n#         price_parent=item.find('span','a-price')\n#         price=price_parent.find('span','a-offscreen').text\n#     except AttributeError:\n#         return\n#     Comment: Ranking and rating of the user \n#     Code:\n#     try:\n#         rating=item.i.text\n#         review_count=item.find('span',{'class':'a-size-base'}).text\n#     except AttributeError:\n#         rating=\"\"\n#         review_count=\"\"\n        \n#     result=(descrpition,price,rating,review_count,new_url)\n    \n#     return result\n\n\n# def main():\n    \n#     Comment: this is a main function where we first load web driver\n#     Code:\n#     from webdriver_manager.chrome import ChromeDriverManager\n#     driver = webdriver.Chrome(ChromeDriverManager().install())\n    \n#     Comment: Take Input parameter\n#     Code:\n#     search_term=input('Enter the Keyword:')\n#     record=[]\n    \n#     Comment: create url to search\n#     Code:\n#     url=get_url(search_term)\n    \n#     for page in range(1,21):\n#         driver.get(url.format(page))\n#         soup=BeautifulSoup(driver.page_source,'html.parser')\n#         results=soup.find_all('div',{'data-component-type':'s-search-result'})\n        \n#         for item in results:\n#             u=extract_record(item)\n#             if u:\n#                 record.append(u)\n    \n#     driver.close()\n    \n#     df = pd.DataFrame(record, columns=['Descrpition','Price','Rating','ReviewCount','URL'])\n#     df.to_csv('FinalProductList.csv')\n     \n#     Commnet: Or we can do it in another way\n#     Code:\n#     with open(\"Productlists.csv\",'w',newline=\"\",encoding='utf-8') as f:\n#         writer=csv.writer(f)\n#         writer.writerow(['Descrpition','Price','Rating','ReviewCount','URL'])\n#         writer.writerow(record)\n#         print('Done')\n    ","a6cf5416":"# Comment:Run this function to run whole program\n# Code:\n# main()","51a3266b":"# \ud83d\udccc  **Note**: \n## I have commented all the since it wont run on Kaggle but  it can run on Jupyter Notebook.","ab0a0d44":"![](https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2020\/03\/featured_image-6.jpg)","b7ab392b":"# Web Scarpping Amazon for any product using user's input !!","c43508e8":"# What is Web Scrapping?\n-  Web scraping is the process of using bots to extract content and data from a website. \n-  Unlike screen scraping, which only copies pixels displayed onscreen, web scraping extracts underlying HTML code and, with it, data stored in a database.\n-  Web scraping is used to collect large information from websites. \n\n# What Packages are Top packages used in Web Scrapping?\n-  Requests\n-  Beautiful Soup \n-  lxml\n-  Selenium\n-  Scrapy\n\n# Steps for Web Scrapping:\n-  Step 1: Find the URL that you want to scrape\n-  Step 2: Inspecting the Page\n-  Step 3: Find the data you want to extract\n-  Step 4: Write the code\n-  Step 5: Run the code and extract the data\n-  Step 6: Store the data in the required format "}}