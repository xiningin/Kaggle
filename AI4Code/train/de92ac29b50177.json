{"cell_type":{"eb1f2a53":"code","5ba260a1":"code","c12a4c78":"code","691320e9":"code","950d7770":"code","5f39c8ca":"code","d80b87ca":"code","2e623cb0":"code","c82fe406":"code","db9417df":"code","f68b70be":"code","3a28d26f":"code","d12e5999":"markdown"},"source":{"eb1f2a53":"import os, sys\n\nimport skimage.io\nimport skimage.transform\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","5ba260a1":"import tensorflow as tf","c12a4c78":"tf.reset_default_graph()\n\ninput_tensor = tf.placeholder(tf.float32, [None, 112, 112, 3])\noutput_tensor = tf.placeholder(tf.float32, [None, 5])\nkeep_probability = tf.placeholder(tf.float32)\n\nw_init = tf.random_normal_initializer(stddev=0.001)\nb_init = tf.constant_initializer(0.001)\n\n# Convalution layer 1\n# input - [None,112,112,3], output - [None,56,56,32]\nw1 = tf.get_variable('W1', shape=[3, 3, 3, 32], initializer=w_init)\nb1 = tf.get_variable('b1', shape=[32], initializer=b_init)\nconv_1 = tf.nn.conv2d(input_tensor, w1, strides=[1, 1, 1, 1], padding=\"SAME\") + b1\nactiv_1 = tf.nn.relu(conv_1)\npool_1 = tf.nn.max_pool(activ_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n\n# Convalution layer\n# input - [None,56,56,32], output - [None,28,28,64]\nw2 = tf.get_variable('W2', shape=[3, 3, 32, 64], initializer=w_init)\nb2 = tf.get_variable('b2', shape=[64], initializer=b_init)\nconv_2 = tf.nn.conv2d(pool_1, w2, strides=[1, 1, 1, 1], padding=\"SAME\") + b2\nactiv_2 = tf.nn.relu(conv_2)\npool_2 = tf.nn.max_pool(activ_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n\n# Convalution layer\n# input - [None,28,28,64], output - [None,14,14,64]\nw3 = tf.get_variable('W3', shape=[3, 3, 64, 64], initializer=w_init)\nb3 = tf.get_variable('b3', shape=[64], initializer=b_init)\nconv_3 = tf.nn.conv2d(pool_2, w3, strides=[1, 1, 1, 1], padding=\"SAME\") + b3\nactiv_3 = tf.nn.relu(conv_3)\npool_3 = tf.nn.max_pool(activ_3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n\n# Convalution layer\n# input - [None,14,14,64], output - [None,7,7,32]\nw4 = tf.get_variable('W4', shape=[3, 3, 64, 32], initializer=w_init)\nb4 = tf.get_variable('b4', shape=[32], initializer=b_init)\nconv_4 = tf.nn.conv2d(pool_3, w4, strides=[1, 1, 1, 1], padding=\"SAME\") + b4\nactiv_4 = tf.nn.relu(conv_4)\npool_4 = tf.nn.max_pool(activ_4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n\n# input - [None,7,7,32], output - [None, 1568]\nflatten_1 = tf.reshape(pool_4, shape=[-1, 7*7*32])\n\n# Dence layer\n# input - [None, 1568], output - [None, 1024]\nw5 = tf.get_variable('W5', shape=[1568, 1024], initializer=w_init)\nb5 = tf.get_variable('b5', shape=[1024], initializer=b_init)\nactiv_5 = tf.nn.relu(tf.matmul(flatten_1, w5)) + b5\n\n# dropout\ndrop_1 = tf.nn.dropout(activ_5, keep_probability)\n\n# Dence layer\n# input - [None, 1024], output - [None, 5]\nw6 = tf.get_variable('W6', shape=[1024, 5], initializer=w_init)\nb6 = tf.get_variable('b6', shape=[5], initializer=b_init)\nlogit = tf.matmul(drop_1, w6) + b6\n\n# softmax\noutput = tf.nn.softmax(logit)\n\n# weigths adjustment\ncross_entropy = tf.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=output_tensor))\ntrain_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\n\n# calc accuraty\ncorrect_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(output_tensor, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))","691320e9":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255)","950d7770":"generator = datagen.flow_from_directory(\n    directory='..\/input\/flowers\/flowers\/',\n    target_size=(112, 112),\n    batch_size=4323,\n    class_mode='categorical', \n    shuffle=True)","5f39c8ca":"X, y = next(generator)\nX_train, y_train = X[:3500], y[:3500]\nX_test, y_test = X[3500:], y[3500:]","d80b87ca":"train_loss_history = []; train_acc_history = []; \ntest_loss_history = []; test_acc_history = []; \n\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)","2e623cb0":"for i in range(10000): \n    train_indexes = np.random.choice(3500, 128)\n    sess.run(\n        train_step, \n        feed_dict={\n            input_tensor: X_train[train_indexes], \n            output_tensor: y_train[train_indexes], \n            keep_probability: 0.35})\n\n    if (i%100 == 0):\n        acc_train, loss_train = sess.run(\n            [accuracy, cross_entropy], \n            feed_dict={\n            input_tensor: X_train[train_indexes], \n            output_tensor: y_train[train_indexes], \n            keep_probability: 1.0})\n        \n        train_loss_history.append(loss_train)\n        train_acc_history.append(acc_train)\n        \n        test_indexes = np.random.choice(823, 128)\n        acc_test, loss_test = sess.run(\n            [accuracy, cross_entropy],\n            feed_dict={\n            input_tensor: X_test[test_indexes], \n            output_tensor: y_test[test_indexes], \n            keep_probability: 1.0})\n        test_loss_history.append(loss_test)\n        test_acc_history.append(acc_test)\n        \n        sys.stdout.write('\\rstep: {0}, train loss: {1:.4}, train accuracy: {2:.5}{3:10}'.format(\n            i, loss_test, acc_test, ' '))","c82fe406":"fig, ax = plt.subplots(1,2,figsize=(20, 5))\nax[0].set_title('accuracy')\nax[0].plot(train_acc_history, label='train')\nax[0].plot(test_acc_history, label='test')\nax[0].legend()\nax[1].set_title('loss')\nax[1].plot(train_loss_history, label='train')\nax[1].plot(test_loss_history, label='test')\nax[1].legend()","db9417df":"w = sess.run(\n    [w1, w2, w3, w4, w5, w6],\n    feed_dict={\n    input_tensor: X_test[test_indexes], \n    output_tensor: y_test[test_indexes], \n    keep_probability: 1.0})\n\nfor i in range(6):\n    print('mean w{0}: {1:.5}'.format(i+1, w[i].mean()))","f68b70be":"b = sess.run(\n    [b1, b2, b3, b4, b5, b6],\n    feed_dict={\n    input_tensor: X_test[test_indexes], \n    output_tensor: y_test[test_indexes], \n    keep_probability: 1.0})\n\nfor i in range(6):\n    print('mean b{0}: {1:.5}'.format(i+1, b[i].mean()))","3a28d26f":"result = sess.run(\n    [conv_1, conv_2, conv_3,conv_4],\n    feed_dict={\n    input_tensor: X_test[test_indexes], \n    output_tensor: y_test[test_indexes], \n    keep_probability: 1.0})\n\nfor i in range(10):\n    fig, ax = plt.subplots(1,5, figsize=(20,5))\n    ax[0].imshow(X_test[test_indexes][i])\n    ax[1].imshow(result[0][i].mean(axis=2))\n    ax[2].imshow(result[1][i].mean(axis=2))\n    ax[3].imshow(result[2][i].mean(axis=2))\n    ax[4].imshow(result[3][i].mean(axis=2))\n    plt.show()","d12e5999":"TRAIN MODEL"}}