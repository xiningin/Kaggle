{"cell_type":{"2b8f45a3":"code","cdb45562":"code","09241ec7":"code","b1c343b3":"code","bb6764fe":"code","e000dc6f":"code","360ea20c":"code","33578bf0":"code","7de43fd0":"code","8cdeb5d5":"code","d0370a44":"code","179e64f5":"code","df4591ce":"code","2b47bb90":"code","3da06031":"code","10daddf5":"code","3977e9cb":"code","3750c586":"code","e07818bb":"code","8dbfe6ce":"code","b6e6dc23":"code","4b840bf3":"code","92ff4428":"code","90eb927f":"code","1088bd8e":"code","7a853796":"code","9336d96e":"code","593b5341":"code","6cf080ac":"code","ba749def":"code","f94bb599":"code","06065299":"code","63a74592":"code","8e2ee3fa":"code","c3552e01":"code","690fbf26":"code","42ac6090":"code","0b292e51":"markdown","087ef64a":"markdown","d3e04e87":"markdown"},"source":{"2b8f45a3":"import shutil\nshutil.move('..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset', '.\/COVID-19_Radiography_Dataset')","cdb45562":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","09241ec7":"import os\nimport random\nimport torch\nimport torchvision\nimport numpy as np\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(10)","b1c343b3":"class_names = ['normal', 'viral', 'covid']\nroot_dir = '.\/COVID-19_Radiography_Dataset'\nsource_dirs = ['Normal', 'Viral Pneumonia', 'COVID']\n\nprint('setting up training and test')\nif os.path.isdir(os.path.join(root_dir, source_dirs[1])):\n    print('creating test directory...')\n    os.mkdir(os.path.join(root_dir, 'test'))\n    os.mkdir(os.path.join(root_dir, 'validation'))\n\n    for i, d in enumerate(source_dirs):\n        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))\n\n    for c in class_names:\n        os.mkdir(os.path.join(root_dir, 'test', c))\n        os.mkdir(os.path.join(root_dir, 'validation', c))\n\n    for c in class_names:\n        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]\n        selected_images = random.sample(images, 80)\n        for image in selected_images:\n            source_path = os.path.join(root_dir, c, image)\n            target_path = os.path.join(root_dir, 'test', c, image)\n            shutil.move(source_path, target_path)\n            \n    for c in class_names:\n        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]\n        selected_images = random.sample(images, 80)\n        for image in selected_images:\n            source_path = os.path.join(root_dir, c, image)\n            target_path = os.path.join(root_dir, 'validation', c, image)\n            shutil.move(source_path, target_path)","bb6764fe":"class ChestXRayDataset(torch.utils.data.Dataset):\n    def __init__(self, image_dirs, transform):\n        def get_images(class_name):\n            images = [x for x in os.listdir(image_dirs[class_name]) if x[-3:].lower().endswith('png')]\n            print(f'Found {len(images)} {class_name} examples')\n            return images\n        \n        self.images = {}\n        self.class_names = ['normal', 'viral', 'covid']\n        \n        for class_name in self.class_names:\n            self.images[class_name] = get_images(class_name)\n            \n        self.image_dirs = image_dirs\n        self.transform = transform\n        \n    \n    def __len__(self):\n        return sum([len(self.images[class_name]) for class_name in self.class_names])\n    \n    \n    def __getitem__(self, index):\n        if self.image_dirs['normal']!='.\/COVID-19_Radiography_Dataset\/test\/normal':\n            class_name = random.choice(self.class_names)\n        else:\n            if index >=0 and index <=79:\n                class_name = 'normal'\n            elif index >=80 and index <=159:\n                class_name = 'viral'\n            else:\n                class_name = 'covid'\n        index = index % len(self.images[class_name])\n        image_name = self.images[class_name][index]\n        image_path = os.path.join(self.image_dirs[class_name], image_name)\n        image = Image.open(image_path).convert('RGB')\n        return self.transform(image), self.class_names.index(class_name)","e000dc6f":"train_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nvalidation_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","360ea20c":"train_dirs = {\n    'normal': '.\/COVID-19_Radiography_Dataset\/normal',\n    'viral': '.\/COVID-19_Radiography_Dataset\/viral',\n    'covid': '.\/COVID-19_Radiography_Dataset\/covid'\n}\n\ntrain_dataset = ChestXRayDataset(train_dirs, train_transform)","33578bf0":"validation_dirs = {\n    'normal': '.\/COVID-19_Radiography_Dataset\/validation\/normal',\n    'viral': '.\/COVID-19_Radiography_Dataset\/validation\/viral',\n    'covid': '.\/COVID-19_Radiography_Dataset\/validation\/covid'\n}\n\nvalidation_dataset = ChestXRayDataset(validation_dirs, validation_transform)","7de43fd0":"test_dirs = {\n    'normal': '.\/COVID-19_Radiography_Dataset\/test\/normal',\n    'viral': '.\/COVID-19_Radiography_Dataset\/test\/viral',\n    'covid': '.\/COVID-19_Radiography_Dataset\/test\/covid'\n}\n\ntest_dataset = ChestXRayDataset(test_dirs, test_transform)","8cdeb5d5":"batch_size = 4\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)","d0370a44":"class_names = train_dataset.class_names\n\n\ndef show_images(images, labels, preds):\n    plt.figure(figsize=(8, 4))\n    for i, image in enumerate(images):\n        plt.subplot(1, batch_size, i + 1, xticks=[], yticks=[])\n        image = image.numpy().transpose((1, 2, 0))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = image * std + mean\n        image = np.clip(image, 0., 1.)\n        plt.imshow(image)\n        col = 'green'\n        if preds[i] != labels[i]:\n            col = 'red'\n            \n        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)\n    plt.tight_layout()\n    plt.show()","179e64f5":"images, labels = next(iter(train_loader))\nshow_images(images, labels, labels)","df4591ce":"images, labels = next(iter(validation_loader))\nshow_images(images, labels, labels)","2b47bb90":"use_gpu = torch.cuda.is_available()","3da06031":"from torchvision.models import resnet50\nresnet50 = resnet50(pretrained=True)\nprint(resnet50)","10daddf5":"resnet50.fc = torch.nn.Linear(in_features=2048, out_features=3)\nif use_gpu:\n    resnet50 = resnet50.cuda()\nloss_fn = torch.nn.CrossEntropyLoss()\n#optimizer = torch.optim.Adam(resnet50.parameters(), lr=3e-5)\noptimizer = torch.optim.SGD(resnet50.parameters(), lr=3e-4, momentum=0.9)","3977e9cb":"from torch.autograd import Variable\ndef show_preds():\n    resnet50.eval()\n    images, labels = next(iter(validation_loader))\n    use_gpu = torch.cuda.is_available()\n    if use_gpu:\n        images, labels = Variable(images.cuda()), Variable(labels.cuda())\n    else:\n        images, labels = Variable(images), Variable(labels)\n    \n    outputs = resnet50(images)\n    _, preds = torch.max(outputs, 1)\n    \n    show_images(images.cpu(), labels.cpu(), preds.cpu())","3750c586":"def train(epochs):\n    print('Starting training..')\n    for e in range(0, epochs):\n        print('='*20)\n        print(f'Starting epoch {e + 1}\/{epochs}')\n        print('='*20)\n\n        train_loss = 0.\n        val_loss = 0.\n        use_gpu = torch.cuda.is_available()\n        resnet50.train() # set model to training phase\n\n        for train_step, (images, labels) in enumerate(train_loader):\n            optimizer.zero_grad()\n            if use_gpu:\n                images, labels = Variable(images.cuda()), Variable(labels.cuda())\n            else:\n                images, labels = Variable(images), Variable(labels)\n            outputs = resnet50(images)\n            \n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            if train_step % 400 == 0:\n                print('Evaluating at step', train_step)\n\n                accuracy = 0\n\n                resnet50.eval() # set model to eval phase\n\n                for val_step, (images, labels) in enumerate(validation_loader):\n                    if use_gpu:\n                        images, labels = Variable(images.cuda()), Variable(labels.cuda())\n                    else:\n                        images, labels = Variable(images), Variable(labels)\n                    outputs = resnet50(images)\n                    loss = loss_fn(outputs, labels)\n                    val_loss += loss.item()\n\n                    _, preds = torch.max(outputs, 1)\n                    if use_gpu:\n                        accuracy += sum((preds.cpu() == labels.cpu()).numpy())\n                    else:\n                        accuracy += sum((preds == labels).numpy())\n\n                val_loss \/= (val_step + 1)\n                accuracy = accuracy\/len(test_dataset)\n                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n\n                show_preds()\n\n                resnet50.train()\n\n                if accuracy >= 0.98:\n                    print('Performance condition satisfied, stopping..')\n                    return\n\n        train_loss \/= (train_step + 1)\n\n        print(f'Training Loss: {train_loss:.4f}')\n    print('Training complete..')","e07818bb":"show_preds()","8dbfe6ce":"train(epochs=2)","b6e6dc23":"show_preds()","4b840bf3":"test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4,shuffle=False)","92ff4428":"import pandas as pd\naccuracy=0\npredicitions_df=pd.DataFrame(columns = ['Original','Predicted'])\n\nfor _, (images, labels) in enumerate(test_loader):\n    if use_gpu:\n        images, labels = Variable(images.cuda()), Variable(labels.cuda())\n    else:\n        images, labels = Variable(images), Variable(labels)\n    outputs = resnet50(images)\n    loss = loss_fn(outputs, labels)\n    _, preds = torch.max(outputs, 1)\n    temp_df = pd.DataFrame(columns = ['Original','Predicted'])\n    if use_gpu:\n        temp_df['Original'] = labels.cpu().numpy()\n        temp_df['Predicted'] = preds.cpu().numpy()\n    else:\n        temp_df['Original'] = labels.numpy()\n        temp_df['Predicted'] = preds.numpy()\n    predicitions_df=pd.concat([predicitions_df,temp_df],axis=0)\n    accuracy += sum((preds.cpu() == labels.cpu()).numpy())\n\nprint('Overall Accuracy:'+ str(accuracy\/len(test_dataset)))","90eb927f":"len(predicitions_df[(predicitions_df['Original']==2) & (predicitions_df['Predicted']==2)])\/len(predicitions_df[(predicitions_df['Original']==2)])","1088bd8e":"from sklearn.metrics import confusion_matrix\ny_true = np.reshape(np.array(predicitions_df[['Original']].astype(int)),len(predicitions_df))\ny_pred = np.reshape(np.array(predicitions_df[['Predicted']].astype(int)),len(predicitions_df))\nconfusion_matrix(y_true, y_pred)","7a853796":"from torchvision.models import vgg19\nvgg19 = vgg19(pretrained=True)\nprint(vgg19)","9336d96e":"vgg19.classifier[6] = torch.nn.Linear(in_features=4096, out_features=3)\nif use_gpu:\n    vgg19 = vgg19.cuda()\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vgg19.parameters(), lr=3e-5)","593b5341":"from torch.autograd import Variable\ndef show_vgg_preds():\n    vgg19.eval()\n    images, labels = next(iter(validation_loader))\n    use_gpu = torch.cuda.is_available()\n    if use_gpu:\n        images, labels = Variable(images.cuda()), Variable(labels.cuda())\n    else:\n        images, labels = Variable(images), Variable(labels)\n    \n    outputs = vgg19(images)\n    _, preds = torch.max(outputs, 1)\n    \n    show_images(images.cpu(), labels.cpu(), preds.cpu())","6cf080ac":"def vgg_train(epochs):\n    print('Starting training vgg19..')\n    for e in range(0, epochs):\n        print('='*20)\n        print(f'Starting epoch {e + 1}\/{epochs}')\n        print('='*20)\n\n        train_loss = 0.\n        val_loss = 0.\n        use_gpu = torch.cuda.is_available()\n        vgg19.train() # set model to training phase\n\n        for train_step, (images, labels) in enumerate(train_loader):\n            optimizer.zero_grad()\n            if use_gpu:\n                images, labels = Variable(images.cuda()), Variable(labels.cuda())\n            else:\n                images, labels = Variable(images), Variable(labels)\n            outputs = vgg19(images)\n            \n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            if train_step % 400 == 0:\n                print('Evaluating at step', train_step)\n\n                accuracy = 0\n\n                vgg19.eval() # set model to eval phase\n\n                for val_step, (images, labels) in enumerate(validation_loader):\n                    if use_gpu:\n                        images, labels = Variable(images.cuda()), Variable(labels.cuda())\n                    else:\n                        images, labels = Variable(images), Variable(labels)\n                    outputs = vgg19(images)\n                    loss = loss_fn(outputs, labels)\n                    val_loss += loss.item()\n\n                    _, preds = torch.max(outputs, 1)\n                    if use_gpu:\n                        accuracy += sum((preds.cpu() == labels.cpu()).numpy())\n                    else:\n                        accuracy += sum((preds == labels).numpy())\n\n                val_loss \/= (val_step + 1)\n                accuracy = accuracy\/len(test_dataset)\n                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n\n                show_vgg_preds()\n\n                vgg19.train()\n\n                if accuracy >= 0.98:\n                    print('Performance condition satisfied, stopping..')\n                    return\n\n        train_loss \/= (train_step + 1)\n\n        print(f'Training Loss: {train_loss:.4f}')\n    print('Training complete..')","ba749def":"show_vgg_preds()","f94bb599":"batch_size = 4\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)","06065299":"vgg_train(epochs=2)","63a74592":"show_vgg_preds()","8e2ee3fa":"test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4,shuffle=False)","c3552e01":"import pandas as pd\naccuracy=0\nvgg_predicitions_df=pd.DataFrame(columns = ['Original','Predicted'])\n\nfor _, (images, labels) in enumerate(test_loader):\n    if use_gpu:\n        images, labels = Variable(images.cuda()), Variable(labels.cuda())\n    else:\n        images, labels = Variable(images), Variable(labels)\n    outputs = vgg19(images)\n    loss = loss_fn(outputs, labels)\n    _, preds = torch.max(outputs, 1)\n    temp_df = pd.DataFrame(columns = ['Original','Predicted'])\n    if use_gpu:\n        temp_df['Original'] = labels.cpu().numpy()\n        temp_df['Predicted'] = preds.cpu().numpy()\n        accuracy += sum((preds.cpu() == labels.cpu()).numpy())\n    else:\n        temp_df['Original'] = labels.numpy()\n        temp_df['Predicted'] = preds.numpy()\n        accuracy += sum((preds == labels).numpy())\n    vgg_predicitions_df=pd.concat([vgg_predicitions_df,temp_df],axis=0)    \n\nprint('Overall Accuracy:'+ str(accuracy\/len(test_dataset)))","690fbf26":"len(vgg_predicitions_df[(vgg_predicitions_df['Original']==2) & (vgg_predicitions_df['Predicted']==2)])\/len(vgg_predicitions_df[(vgg_predicitions_df['Original']==2)])","42ac6090":"from sklearn.metrics import confusion_matrix\ny_true = np.reshape(np.array(vgg_predicitions_df[['Original']].astype(int)),len(vgg_predicitions_df))\ny_pred = np.reshape(np.array(vgg_predicitions_df[['Predicted']].astype(int)),len(vgg_predicitions_df))\nconfusion_matrix(y_true, y_pred)","0b292e51":"### Data Visualization","087ef64a":"### Using pretrained resnet50 Model to compare results with transfer learning vs. a new model","d3e04e87":"### Using Vgg19"}}