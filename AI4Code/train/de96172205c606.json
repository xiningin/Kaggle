{"cell_type":{"c07fa860":"code","85d152d4":"code","5a3e795e":"code","739f93ee":"code","dbb9b354":"code","8e972dc0":"code","895ecfa2":"code","f40bc662":"code","bbe22d65":"code","f916acc3":"code","407dd726":"code","c6c1107e":"code","938e78cb":"code","bac0ebf2":"markdown","406b2b45":"markdown","62fa81df":"markdown","3b8303e2":"markdown","8a299c88":"markdown","1f678147":"markdown","6280347a":"markdown","0d6a0111":"markdown","dcede066":"markdown","d8d56f83":"markdown","e0c12f2b":"markdown","93c63aa4":"markdown","9ec7f869":"markdown"},"source":{"c07fa860":"######################################################Initial Packages########################################################\n#Basic Operating System Stuff\nimport os, gc, random\n\n#Basic dataframe, array, and math stuff\nimport pandas as pd #data frame\nimport math #math functions\nimport numpy as np    #numerical package\n\n#Scikit learn\nimport sklearn as sk  #scikit learn\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split as tts #train test split\nfrom sklearn.metrics import confusion_matrix, roc_curve, classification_report #for 2-class model\n\n#Tensorflow\nimport tensorflow as tf \nfrom tensorflow.python.client import device_lib #GPU Check\nimport tensorflow.keras #keras\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Sequential,Input,Model \nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Add, Activation, ZeroPadding2D,GlobalAveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization,Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, LeakyReLU  \nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint #use for early stopping and reduction on level-out\nfrom tensorflow.keras.initializers import glorot_uniform, he_uniform #to initialize random weights for filters\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.preprocessing import image as image_utils\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions, preprocess_input\nfrom tensorflow.keras.models import Model, load_model  #Can't do much without a model\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.utils import get_file, plot_model, to_categorical, model_to_dot\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications import ResNet50V2 \nimport tensorflow.keras.backend as K #let's write our own metrics and loss functions\n\n#Graphing\nimport cv2\nimport matplotlib.pyplot as plt\n\nprint(device_lib.list_local_devices()) #Let's see if Python recognizes my GPU, shall we?\n################################################conda ##############################################################################","85d152d4":"mirrored_strategy = tf.distribute.MirroredStrategy()\n#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"\/gpu:0\", \"\/gpu:1\", \":\/gpu:2\", \":gpu:3\"])\ndef reset_keras():\n    tensorflow.keras.backend.clear_session\nreset_keras()","5a3e795e":"random.seed(1234)\nimages,labels=[], []\nsize=100   #not enough free memory to read 299 x 299...so I scaled..If you have paid plan, please go big.\n\nfeatures = {\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n    'image': tf.io.FixedLenFeature([], tf.string)\n    }\n\ndef readFile(files):\n    mydata = tf.data.TFRecordDataset(files,num_parallel_reads=4).shuffle(buffer_size=10000).cache()\n    mydata = mydata.map(lambda x: tf.io.parse_example(x, features), num_parallel_calls=4)\n    for image_features in mydata:\n        image = tf.io.decode_raw(image_features['image'], tf.uint8)\n        image = tf.reshape(image, [299, 299])        \n        image=image.numpy()\n        image=cv2.resize(image,(size,size))\n        image=cv2.merge([image,image,image])        \n        images.append(image)\n        #labels.append(image_features['label_normal'].numpy()) #label_normal for 2-class classification\n        labels.append(image_features['label'].numpy()) #for multi-class classification\n","739f93ee":"reset_keras()\nfiles=['..\/input\/ddsm-mammography\/training10_0\/training10_0.tfrecords',\n          '..\/input\/ddsm-mammography\/training10_1\/training10_1.tfrecords',\n          '..\/input\/ddsm-mammography\/training10_2\/training10_2.tfrecords',\n          '..\/input\/ddsm-mammography\/training10_3\/training10_3.tfrecords',\n          '..\/input\/ddsm-mammography\/training10_4\/training10_4.tfrecords'\n          ]\n\nfor file in files:\n    readFile(file)\n","dbb9b354":"np.bincount(labels)\/len(labels)\n#1s and above are positive","8e972dc0":"x_train=np.array(images)\ny_train=np.array(labels)\ny_train=np.where(y_train==0, 0, y_train)\ny_train=np.where(y_train!=0, 1, y_train)\nnp.bincount(y_train)\/len(y_train)","895ecfa2":"reset_keras()\n\n#Per instructions, we need to combine both the val and test sets due to a parsing error during creation\nx_test=np.concatenate((np.load(\"..\/input\/ddsm-mammography\/cv10_data\/cv10_data.npy\"),np.load(\"..\/input\/ddsm-mammography\/test10_data\/test10_data.npy\")))        \ny_test=np.concatenate((np.load(\"..\/input\/ddsm-mammography\/cv10_labels.npy\"),np.load(\"..\/input\/ddsm-mammography\/test10_labels.npy\")))\n                      \ny_test=np.where(y_test==0, 0, y_test)\ny_test=np.where(y_test!=0, 1, y_test)\n\nsizeit=[]\nfor i in np.arange(x_test.shape[0]):\n    mytemp=cv2.resize(x_test[i,:,:,:],(size,size))\n    mytemp2=cv2.cvtColor(mytemp,cv2.COLOR_GRAY2RGB)\n    sizeit.append(mytemp2)\n\nx_test=np.asarray(sizeit)\n\nprint(x_train.shape, y_train.shape, x_test.shape, y_test.shape)","f40bc662":"reset_keras()\nfig, ax = plt.subplots(1,9, figsize=[18, 3])\nfig2, ax2 = plt.subplots(1,9, figsize=[18, 3])\nfor i in range(9):\n    ax[i].imshow(x_train[i, :,:,0], 'hot') \n    fig.subplots_adjust(wspace=0, hspace=0)\nfor i in range(9):\n    ax2[i].imshow(x_train[i+9, :,:,0]) \n    fig2.subplots_adjust(wspace=0, hspace=0)","bbe22d65":"base_model = ResNet50V2(input_shape=(size,size,3), weights='imagenet', include_top=False)\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.summary()","f916acc3":"reset_keras()\nbatch=128\nnumepochs=20\n#model.load_weights('..\/output\/kaggle\/working\/D:\/breast\/best_modelResNet.hdf5')\nearly = EarlyStopping(monitor='val_loss', mode='min', patience=5,restore_best_weights=True, verbose=1)\ncheckpoint = ModelCheckpoint(\"D:\/breast\/best_modelResNet.hdf5\", monitor='accuracy', verbose=1,\n    save_best_only=True, mode='auto')\n\nwith tf.device('\/GPU:0'):  #Use the GPU\n    model.compile(optimizer='adagrad',loss='binary_crossentropy', metrics=['accuracy'])\n    history = model.fit(x_train, y_train,validation_split=0.2,shuffle=True, epochs=numepochs, batch_size=batch,callbacks=[early,checkpoint])\n    loss_value, accuracy = model.evaluate(x_test, y_test)\n\n#1st 20 epochs, 128 batch size and adagrad\n#Cannot increase batch size using free compute cycles..recommend more epochs with different optimizers","407dd726":"loss_value, accuracy = model.evaluate(x_test, y_test)","c6c1107e":"reset_keras()\ndef Train_Val_Plot(acc,val_acc,loss,val_loss):\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,10))\n    fig.suptitle(\"Loss and Validation\")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['Training', 'Validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['Training', 'Validation'])\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],history.history['loss'],history.history['val_loss'])","938e78cb":"y_pred=np.round(model.predict(x_test),0)\ny_pred_prb=model.predict(x_test)\ntarget=[\"Negative\",\"Positive\"] \ncm=metrics.confusion_matrix(np.array(y_test), y_pred)\n#print(cm)\nprint('Accuracy:', np.round(metrics.accuracy_score(y_test, y_pred),3))\nprint('F1 Score:', np.round(metrics.f1_score(y_test, y_pred),3))\nprint('AUC:', np.round(metrics.roc_auc_score(y_test, y_pred_prb),3))\nprint('Specificity', np.round(cm[0,0]\/(cm[0,0]+cm[0,1]),3))\nprint(metrics.classification_report(y_test, y_pred,target_names=target))","bac0ebf2":"# Group","406b2b45":"# GPU and Memory Management","62fa81df":"# Libraries and GPU Checks","3b8303e2":"# Read Training","8a299c88":"# Metrics","1f678147":"# Read Test","6280347a":"# Build Model","0d6a0111":"# Read Function","dcede066":"# Plot Some Images","d8d56f83":"# Run Model","e0c12f2b":"# Plot","93c63aa4":"# Evaluate","9ec7f869":"# Verify Which Codes are 1 and Which are Zero"}}