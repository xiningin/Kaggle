{"cell_type":{"cd12611e":"code","f7d8580b":"code","4a6fa848":"code","5a4c43ff":"code","e96218df":"code","2e998cf2":"code","502a84c7":"code","3aa88f79":"code","65827db4":"code","6f88ac4c":"code","b6f588bc":"code","a0a9cf18":"code","eae4aa2f":"code","6015aa3a":"code","992f6181":"code","0f3595d9":"code","0ca0f6fb":"code","37988dfe":"code","759086cf":"code","5b4df711":"code","31252f50":"code","b61dfc7e":"markdown"},"source":{"cd12611e":"from IPython.display import display,HTML\n\nc1,c2,f1,f2,fs1,fs2=\\\n'#11ff66','#6611ff','Wallpoet','Orbitron',20,10\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' \n    style='font-family:\"\"\"+font+\\\n    \"\"\"; color:\"\"\"+fontcolor+\\\n    \"\"\"; font-size:\"\"\"+str(fontsize)+\"\"\"px;'>\n    %s<\/h1>\"\"\"%string))\n\ndhtml('Code Modules, Setting, & Functions')","f7d8580b":"!python3 -m pip install --upgrade pip \\\n--user --quiet --no-warn-script-location\n!python3 -m pip install --upgrade tensorflow==2.3.0 \\\n--user --quiet --no-warn-script-location\n!pip install mplcyberpunk --user --quiet","4a6fa848":"import warnings; warnings.filterwarnings('ignore')\nimport mplcyberpunk,numpy as np\nimport tensorflow as tf,pylab as pl\nfrom IPython.core.magic import register_line_magic\nfrom sklearn.metrics import \\\nclassification_report,confusion_matrix\npl.style.use('cyberpunk')\n\n@register_line_magic\ndef display_examples(pars):\n    pars=pars.split()\n    data,n=pars[0],int(pars[1])\n    if data=='mnist': data=mnist_test\n    if data=='cifar': data=cifar_test\n    batch=next(iter(data.batch(n)))\n    images=batch[0].numpy()\n    labels=batch[1].numpy() \n    fig=pl.figure(figsize=(2*n\/\/3,4.5))\n    for i in range(n):\n        ax=fig.add_subplot(3,n\/\/3,i+1)\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(np.squeeze(images[i]),\n                  cmap='bone')\n        ax.text(.85,.15,'{}'.format(labels[i]), \n                fontdict={'color':c1,'fontsize':30},\n                horizontalalignment='center',\n                verticalalignment='center', \n                transform=ax.transAxes)\n    pl.tight_layout(); pl.show()\n    \n@register_line_magic\ndef history_plot(yes):\n    global history\n    pl.figure(figsize=(10,10)); pl.subplot(211)\n    keys=list(history.history.keys())[0:4]\n    pl.plot(history.history[keys[0]],\n            color=c1,label=keys[0])\n    pl.plot(history.history[keys[2]],\n            color=c2,label=keys[2])\n    pl.xlabel('Epochs'); pl.ylabel('Loss')\n    pl.legend(); pl.grid(); pl.title('Loss Function')     \n    pl.subplot(212)\n    pl.plot(history.history[keys[1]],\n            color=c1,label=keys[1])\n    pl.plot(history.history[keys[3]],\n            color=c2,label=keys[3])\n    pl.xlabel('Epochs'); pl.ylabel('Accuracy')    \n    pl.legend(); pl.grid(); pl.title('Accuracy')\n    mplcyberpunk.add_glow_effects()\n    pl.tight_layout(); pl.show()\n    \n@register_line_magic\ndef display_reports(data):\n    global model,model_weights,buffer_size,c2,f2,fs2\n    model.load_weights(model_weights)\n    if data=='mnist': data=mnist_test\n    if data=='cifar': data=cifar_test\n    test_results=model.evaluate(\n        data.batch(buffer_size),verbose=0)\n    dhtml('\\ntest accuracy: {:.2f}%'\\\n          .format(test_results[1]*100),c2,f2,fs2)\n    batch=next(iter(data.batch(buffer_size)))\n    y_test=batch[1].numpy()\n    py_test=np.argmax(\n        model.predict(data.batch(buffer_size)),axis=-1)\n    dhtml('Classification Report',c2,f2,fs2)\n    print(classification_report(y_test,py_test))\n    dhtml('Confusion Matrix',c2,f2,fs2)\n    print(confusion_matrix(y_test,py_test))","5a4c43ff":"dhtml('Data Processing')","e96218df":"%%writefile tfpreprocess_mnist.py\nimport warnings; warnings.filterwarnings('ignore')\nimport tensorflow as tf,numpy as np,pandas as pd\nimport tensorflow_datasets as tfds\nfrom IPython.display import display,HTML\npd.set_option('precision',3)\ntf.keras.backend.set_floatx('float64')\ntfds.disable_progress_bar()\nimg_size=32\nbuffer_size,batch_size=10000,64\n\nc1,c2,f1,f2,fs1,fs2=\\\n'#11ff66','#6611ff','Wallpoet','Orbitron',20,10\n\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' \n    style='font-family:\"\"\"+font+\\\n    \"\"\"; color:\"\"\"+fontcolor+\\\n    \"\"\"; font-size:\"\"\"+str(fontsize)+\"\"\"px;'>\n    %s<\/h1>\"\"\"%string))\n\ndef load_mnist():\n    mnist=tfds.builder('mnist')\n    mnist.download_and_prepare()\n    ds=mnist.as_dataset(shuffle_files=False,\n                        split=['train','test'])\n    mnist_train,mnist_test=ds[0],ds[1]\n    dhtml(mnist.info.features['image'],c2,f2,fs2)\n    dhtml(mnist.info.features['label'],c2,f2,fs2)\n    mnist_train=mnist_train.map(\n        lambda item:(tf.image.resize(\n            tf.cast(item['image'],tf.float32),\n            [img_size,img_size])\/255., \n                     tf.cast(item['label'],tf.int32)))\n    mnist_test=mnist_test.map(\n        lambda item:(tf.image.resize(\n            tf.cast(item['image'],tf.float32),\n            [img_size,img_size])\/255., \n                     tf.cast(item['label'],tf.int32)))\n    tf.random.set_seed(123)\n    mnist_train=mnist_train.shuffle(\n        buffer_size=buffer_size,\n        reshuffle_each_iteration=False)\n    mnist_valid=mnist_train.take(buffer_size).batch(batch_size)\n    mnist_train=mnist_train.skip(buffer_size).batch(batch_size)\n    return mnist_train,mnist_valid,mnist_test","2e998cf2":"%run tfpreprocess_mnist.py\nmnist_train,mnist_valid,mnist_test=load_mnist()\n%display_examples mnist 9","502a84c7":"%%writefile tfpreprocess_cifar.py\nimport warnings; warnings.filterwarnings('ignore')\nimport tensorflow as tf,numpy as np,pandas as pd\nimport tensorflow_datasets as tfds\nfrom IPython.display import display,HTML\npd.set_option('precision',3)\ntf.keras.backend.set_floatx('float64')\ntfds.disable_progress_bar()\nimg_size=32\nbuffer_size,batch_size=10000,64\n\nc1,c2,f1,f2,fs1,fs2=\\\n'#11ff66','#6611ff','Wallpoet','Orbitron',20,10\n\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' \n    style='font-family:\"\"\"+font+\\\n    \"\"\"; color:\"\"\"+fontcolor+\\\n    \"\"\"; font-size:\"\"\"+str(fontsize)+\"\"\"px;'>\n    %s<\/h1>\"\"\"%string))\n\ndef load_cifar():\n    cifar=tfds.builder('cifar10')\n    cifar.download_and_prepare()\n    ds=cifar.as_dataset(shuffle_files=False,\n                        split=['train','test'])\n    cifar_train,cifar_test=ds[0],ds[1]\n    dhtml(cifar.info.features['image'],c2,f2,fs2)\n    dhtml(cifar.info.features['label'],c2,f2,fs2)\n    cifar_train=cifar_train.map(\n        lambda item:(tf.cast(item['image'],tf.float32)\/255., \n                     tf.cast(item['label'],tf.int32)))\n    cifar_test=cifar_test.map(\n        lambda item:(tf.cast(item['image'],tf.float32)\/255., \n                      tf.cast(item['label'],tf.int32)))\n    tf.random.set_seed(123)\n    cifar_train=cifar_train.shuffle(\n        buffer_size=buffer_size,\n        reshuffle_each_iteration=False)\n    cifar_valid=cifar_train.take(buffer_size).batch(batch_size)\n    cifar_train=cifar_train.skip(buffer_size).batch(batch_size)\n    return cifar_train,cifar_valid,cifar_test   ","3aa88f79":"%run tfpreprocess_cifar.py\ncifar_train,cifar_valid,cifar_test=load_cifar()\n%display_examples cifar 12","65827db4":"dhtml('CNN Construction. One Channel')","6f88ac4c":"%%writefile cnn_classify.py\nimport warnings; warnings.filterwarnings('ignore')\nfrom IPython.display import display\nimport tensorflow as tf,numpy as np\nimport tensorflow.keras.layers as tkl\nimport tensorflow.keras.utils as tku\nimport tensorflow.keras.callbacks as tkc\ntf.keras.backend.set_floatx('float64')\n\ndef cb(mw):\n    early_stopping=tkc.EarlyStopping(\n        monitor='val_loss',patience=20,verbose=2)\n    checkpointer=tkc.ModelCheckpoint(\n        filepath=mw,save_best_only=True,verbose=2,\n        save_weights_only=True,monitor='val_accuracy',mode='max')\n    lr_reduction=tkc.ReduceLROnPlateau(\n        monitor='val_loss',verbose=2,patience=10,factor=.8)\n    return [checkpointer,early_stopping,lr_reduction]\n\ndef main_block_cnn(channels,img_size=32,filters=32):\n    model=tf.keras.Sequential()\n    model.add(tkl.Input(\n        (img_size,img_size,channels),name='input'))\n    model.add(tkl.Conv2D(\n        filters=filters,kernel_size=(7,7),\n        strides=(1,1),padding='same',name='conv_1'))\n    model.add(tkl.LeakyReLU(alpha=.02,name='lrelu_1'))\n    model.add(tf.keras.layers.MaxPool2D(\n        pool_size=(2,2),name='pool_1'))\n    model.add(tkl.Dropout(.25,name='drop_1'))\n    model.add(tkl.Conv2D(\n        filters=3*channels*filters,kernel_size=(7,7),\n        strides=(1,1),padding='same',name='conv_2'))\n    model.add(tkl.LeakyReLU(alpha=.02,name='lrelu_2'))\n    model.add(tf.keras.layers.MaxPool2D(\n        pool_size=(2,2),name='pool_2'))\n    model.add(tkl.Dropout(.25,name='drop_2'))\n    model.add(tkl.Conv2D(\n        filters=filters,kernel_size=(7,7),\n        strides=(1,1),padding='same',name='conv_3'))\n    model.add(tkl.LeakyReLU(alpha=.02,name='lrelu_3'))\n    model.add(tf.keras.layers.MaxPool2D(\n        pool_size=(2,2),name='pool_3'))\n    model.add(tkl.Dropout(.25,name='drop_3'))\n    return model\n\ndef out_block_cnn(model,dense,num_classes,plot=True):\n    model.add(tkl.GlobalMaxPooling2D(name='gmpool'))   \n    model.add(tkl.Dense(dense,name='dense_1'))\n    model.add(tkl.LeakyReLU(alpha=.02,name='lrelu_4'))\n    model.add(tkl.Dropout(.5,name='drop_4'))\n    model.add(tkl.Dense(num_classes,name='out',\n                        activation='softmax'))\n    if plot:\n        display(tku.plot_model(model,show_shapes=True))\n    return model\n\ndef compile_model(model):\n    return model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss=tf.keras.losses\\\n        .SparseCategoricalCrossentropy(),\n        metrics=['accuracy'])","b6f588bc":"%run cnn_classify.py\nmodel=main_block_cnn(1)\nmodel.compute_output_shape(\n    input_shape=(batch_size,img_size,img_size,1))","a0a9cf18":"model=out_block_cnn(model,512,10)\ncompile_model(model)","eae4aa2f":"model_weights='\/checkpoints'\nhistory=model.fit(mnist_train,epochs=50,shuffle=True, \n                  validation_data=mnist_valid,\n                  callbacks=cb(model_weights))","6015aa3a":"%history_plot yes","992f6181":"%display_reports mnist","0f3595d9":"dhtml('CNN Construction. Three Channels')","0ca0f6fb":"model=main_block_cnn(3)\nmodel.compute_output_shape(\n    input_shape=(batch_size,img_size,img_size,3))","37988dfe":"model=out_block_cnn(model,1024,10)\ncompile_model(model)","759086cf":"history=model.fit(cifar_train,epochs=70,shuffle=True, \n                  validation_data=cifar_valid,\n                  callbacks=cb(model_weights))","5b4df711":"%history_plot yes","31252f50":"%display_reports cifar","b61dfc7e":"Reading classics [Python Machine Learning 3rd Edition](https:\/\/github.com\/rasbt\/python-machine-learning-book-3rd-edition\/blob\/master\/ch15\/ch15_part1.ipynb)"}}