{"cell_type":{"f024369a":"code","41f0cda9":"code","69d24821":"code","db9ece2a":"code","b1b0cb2f":"code","3e765d4a":"code","40825602":"code","372f4021":"code","2d553985":"code","12990291":"code","5440b8e9":"code","b440aa18":"code","723ed9b3":"code","d4903bf9":"code","a3e4858e":"code","c1e0144e":"code","866bd328":"code","e85b98f9":"code","543948e3":"code","35de3545":"code","87ee8ad1":"code","0cb65b70":"code","d67e09eb":"code","8872a018":"code","adf91142":"code","0ef252b2":"code","8c0c2841":"code","af22a007":"code","04b09fbe":"code","222912d7":"code","024fb320":"code","07df557f":"code","fc3397d4":"code","9f8c374a":"code","35303791":"code","44172c00":"code","4b96ec47":"code","ed129349":"code","3f4ea3bf":"code","dcbe0e11":"code","187bddd1":"code","a827af3a":"code","3da6c997":"code","6caa820c":"code","0aca778e":"code","b76f930c":"code","f5ad6a5d":"markdown","8a87c264":"markdown","4a0dea1c":"markdown","bb624e99":"markdown","ad2702cd":"markdown","5ff5450f":"markdown","370a6ad1":"markdown","2514f33d":"markdown","5619eb32":"markdown","0190ec1c":"markdown","2965878c":"markdown","2131440d":"markdown","f1af7ff1":"markdown","d7d5e841":"markdown","d56a75ce":"markdown","e40e5276":"markdown","c0e7487c":"markdown","0071775f":"markdown","b423ad31":"markdown","c3436a8c":"markdown","99826f9d":"markdown","0c123daf":"markdown","ee25df60":"markdown","bbb6816f":"markdown","517d2ef5":"markdown","a6bf1fda":"markdown","3d29d286":"markdown","3ecd5e04":"markdown","09c5955e":"markdown","39e7fa08":"markdown","38f0282f":"markdown","96dbcfa9":"markdown","7a04601c":"markdown","60f03af0":"markdown","27491f43":"markdown","e8a6eb2d":"markdown","60bfe5c7":"markdown","156b1c89":"markdown","f9bdcde2":"markdown","f1a52de1":"markdown","165f9016":"markdown","f4a8d211":"markdown","bf174869":"markdown","bc0deb19":"markdown","ef52fbd2":"markdown","8645ea1a":"markdown","c39131d3":"markdown","1f6ca01d":"markdown","2af6a9c8":"markdown","c63cf53f":"markdown","3e45f194":"markdown","167a91c8":"markdown","bfdab558":"markdown","83275d2e":"markdown","4983154b":"markdown","77ff5c68":"markdown","73abdf55":"markdown","dd54c125":"markdown"},"source":{"f024369a":"pip install plotly","41f0cda9":"## Ignore Warings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.options.display.float_format = '{:.2f}'.format\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom datetime import datetime\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","69d24821":"df = pd.read_csv(\"..\/input\/lending-loan-club-dataset\/loan.csv\")\ntype(df)","db9ece2a":"# Understanding what each column represents , and also what each row\/data point represents\ndf.head()","b1b0cb2f":"#rows x columns\ndf.shape","3e765d4a":"#data type of each variable\n#categorical: object - strings\n#numeric: float64, int64 - numbers\n#time based variables : timestamp- datetime data type\n#is the data type of the variable consistent with its variable description?\ndf.dtypes","40825602":"# Display columns missing values %\nround(100*(df.isnull().sum()\/len(df.index)),2)","372f4021":"print(df.id.nunique())\nprint(df.member_id.nunique())\n# Both columns have same number of unique values; Drop one of the columns\ndf = df.drop(['member_id'], axis=1)","2d553985":"# Drop columns having all nans\ndf = df.dropna(how='all', axis=1)\n\n# Drop columns - mths_since_last_delinq,mths_since_last_record,next_pymnt_d having more than 30% nans\ndf = df.drop(['mths_since_last_delinq', 'mths_since_last_record', 'next_pymnt_d'], axis=1)\n\n# Drop pymnt_plan column; only value in that column is n\nprint(df['pymnt_plan'].value_counts(),\"\\n\")\ndf = df.drop(['pymnt_plan'], axis=1)\n\n# Drop collections_12_mths_ex_med column; only values in that column are 0 and NA\nprint(df['collections_12_mths_ex_med'].value_counts(),\"\\n\")\ndf = df.drop(['collections_12_mths_ex_med'], axis=1)\n\n# Drop policy_code column; only value in that column is 1\nprint(df['policy_code'].value_counts(),\"\\n\")\ndf = df.drop(['policy_code'], axis=1)\n\n# Drop application_type column; only value in that column is INDIVIDUAL\nprint(df['application_type'].value_counts(),\"\\n\")\ndf = df.drop(['application_type'], axis=1)\n\n# Drop acc_now_delinq column; only value in that column is 0\nprint(df['acc_now_delinq'].value_counts(),\"\\n\")\ndf = df.drop(['acc_now_delinq'], axis=1)\n\n# Drop corresponding delinq_amnt column; only value in that column is also 0\nprint(df['delinq_amnt'].value_counts(),\"\\n\")\ndf = df.drop(['delinq_amnt'], axis=1)\n\n# Drop tax_liens column; only values in that column are 0 and NA\nprint(df['tax_liens'].value_counts(),\"\\n\")\ndf = df.drop(['tax_liens'], axis=1)\n\n# Drop chargeoff_within_12_mths column; only values in that column is 0\nprint(df['chargeoff_within_12_mths'].value_counts(),\"\\n\")\ndf = df.drop(['chargeoff_within_12_mths'], axis=1)\n\n# Drop initial_list_status column; only value in that column is F\nprint(df['initial_list_status'].value_counts(),\"\\n\")\ndf = df.drop(['initial_list_status'], axis=1)","12990291":"# Drop url column; it does not hold significance in analysis \ndf = df.drop(['url'], axis=1)\n\n# Drop desc column; Instead of desc, we can use purpose for analysis\ndf = df.drop(['desc'], axis=1)\n\n# Drop title and emp_title column; Not significant for analysis\ndf = df.drop(['emp_title','title'], axis=1)","5440b8e9":"# Remove rows which have loan status as current as our target column values are Fully Paid and Charged Off\ndf = df.loc[(df.loan_status != 'Current'), :]\n\n# Replace loan_status column values of Full Paid with 0 and Charged Off (or Defaulters) with 1\ndf.loan_status[df.loan_status == 'Fully Paid'] = 0\ndf.loan_status[df.loan_status == 'Charged Off'] = 1\n\ndf['loan_status'] = df['loan_status'].astype(\"int64\")","b440aa18":"# There are 3 values in home_ownership with value of NONE; We can impute NONE to OTHER\nprint(df['home_ownership'].value_counts(),\"\\n\")\ndf['home_ownership'] = df['home_ownership'].replace('NONE', 'OTHER')\n\n# Remove trailing xx in zip code column\nprint(df['zip_code'].head())\ndf['zip_code'] = df[['zip_code']].applymap(lambda x:str(x).rstrip('xx'))\n\n# Remove trailing months from term column and rename column as term_in_months\nprint()\nprint(df['term'].head())\ndf['term'] = df[['term']].applymap(lambda x:str(x).rstrip('months'))\ndf['term'] = df['term'].astype('int64')\ndf.rename(columns={'term':'term_in_months'},inplace=True)\n\n# Remove trailing % sign in int_rate and rename int_rate column as int_rate_percent\nprint()\nprint(df['int_rate'].head())\ndf['int_rate'] = df[['int_rate']].applymap(lambda x:str(x).rstrip('%'))\ndf['int_rate'] = df['int_rate'].astype('float64')\ndf.rename(columns={'int_rate':'int_rate_percent'},inplace=True)\n\n# Remove trailing % sign in revol_util and rename column as revol_util_percent\nprint()\nprint(df['revol_util'].head())\ndf['revol_util'] = df[['revol_util']].applymap(lambda x:str(x).rstrip('%'))\ndf['revol_util'] = df['revol_util'].astype('float64')\ndf.rename(columns={'revol_util':'revol_util_percent'},inplace=True)","723ed9b3":"# Change funded_amnt_inv type to int64\ndf['funded_amnt_inv'] = df['funded_amnt_inv'].astype(\"int64\")\n\n# Change grade and sub grades type to category\ndf['grade'] = df['grade'].astype(\"category\")\ndf['sub_grade'] = df['sub_grade'].astype(\"category\")","d4903bf9":"round(100*(df.isnull().sum()\/len(df.index)),2)","a3e4858e":"df.shape","c1e0144e":"df.head(10)","866bd328":"# Derive pub_rec_bankruptcies_b with values as NO if pub_rec_bankruptcies is 0 else YES\nprint(df['pub_rec_bankruptcies'].value_counts(),\"\\n\")\ndf[\"pub_rec_bankruptcies\"].fillna(0, inplace = True)\ndf['pub_rec_bankruptcies_b'] = df[['pub_rec_bankruptcies']].applymap(lambda x : 'NO' if x == 0 else 'YES')\ndf['pub_rec_bankruptcies_b'].describe()\n\n# Derive delinq_2yrs_b with values as NO if delinq_2yrs is 0 else YES\nprint(df['delinq_2yrs'].value_counts(),\"\\n\")\ndf['delinq_2yrs_b'] = df[['delinq_2yrs']].applymap(lambda x : 'NO' if x == 0 else 'YES')","e85b98f9":"df['emp_length'] = df[['emp_length']].applymap(lambda x:str(x).rstrip(\"year\").rstrip(\"years\").lstrip(\"<\").strip())\ndf.loc[(df['emp_length'] == \"nan\"),['emp_length']] = \"0\"","543948e3":"zip_mapping = {\n  0: \"1-100\",\n  1: \"101-200\",\n  2: \"201-300\",\n  3: \"301-400\",\n  4: \"401-500\",\n  5: \"501-600\",\n  6: \"601-700\",\n  7: \"701-800\",\n  8: \"801-900\",\n  9: \"900-901\"\n}\ndf['zip_code'] = df['zip_code'].astype('int64')\ndef get_zip_group(zip_code):\n    return zip_mapping[int(zip_code\/100)]\n\ndf['zip_code_group'] = df[['zip_code']].applymap(lambda x : get_zip_group(x))","35de3545":"dt_series = pd.to_datetime(df.issue_d.str.upper(), format='%b-%y', yearfirst=False)\ndf['issue_d_year'] = dt_series.dt.year\n\n# We can do same as above for earliest_cr_line\ndt_series = pd.to_datetime(df.earliest_cr_line.str.upper(), format='%b-%y', yearfirst=False)\ndf['earliest_cr_line_year'] = dt_series.dt.year","87ee8ad1":"fq = df['funded_amnt_inv'].quantile(0.25)\nsq = df['funded_amnt_inv'].quantile(0.50)\ntq = df['funded_amnt_inv'].quantile(0.75)\nprint(fq, sq, tq)","0cb65b70":"def get_loan_type(loan_amnt):\n    if loan_amnt <= fq:\n        return 'Small(<=5000)'\n    if (loan_amnt > fq) & (loan_amnt <= sq):\n        return 'Regular(>5000 & <=8733)'\n    elif (loan_amnt > sq) & (loan_amnt <= tq):\n        return 'Medium(>8733 & <=14000)'\n    else:\n        return 'Large(>14000)'\n\ndf['loan_type'] = df[['funded_amnt_inv']].applymap(lambda x : get_loan_type(x))\ndf['loan_type'].value_counts()","d67e09eb":"print(df.annual_inc.describe())\nfq = df.annual_inc.quantile(0.25)\nsq = df.annual_inc.quantile(0.50)\ntq = df.annual_inc.quantile(0.75)\ndef get_annual_inc_type(income):\n    if income <= fq:\n        return 'Very Low(<=40K)'\n    if (income > fq) & (income <= sq):\n        return 'Low(>40K & <=58.86K)'\n    elif (income > sq) & (income <= tq):\n        return 'Medium(>58.86K & <=82K)'\n    else:\n        return 'High(>82K)'\n\ndf['annual_inc_type'] = df[['annual_inc']].applymap(lambda x : get_annual_inc_type(x))\ndf['annual_inc_type'].head(10)\ndf.head(10)","8872a018":"ig, ax = plt.subplots(1, 3, figsize=(16,5))\n\nloan_amount = df[\"loan_amnt\"].values\nfunded_amount = df[\"funded_amnt\"].values\ninvestor_funds = df[\"funded_amnt_inv\"].values\n\nsns.distplot(loan_amount, ax=ax[0], color=\"#F7522F\")\nax[0].set_title(\"Loan Applied by Borrower\", fontsize=12)\nsns.distplot(funded_amount, ax=ax[1], color=\"#2F8FF7\")\nax[1].set_title(\"Amount Funded by Lender\", fontsize=12)\nsns.distplot(investor_funds, ax=ax[2], color=\"#2EAD46\")\nax[2].set_title(\"Total committed by Investors\", fontsize=12)\n","adf91142":"ig, ax = plt.subplots(1, 3, figsize=(16,5))\n\nloan_amount = df[\"loan_amnt\"].values\nfunded_amount = df[\"funded_amnt\"].values\ninvestor_funds = df[\"funded_amnt_inv\"].values\n\nsns.boxplot(loan_amount, ax=ax[0], color=\"#F7522F\")\nax[0].set_title(\"Loan Applied by Borrower\", fontsize=12)\nsns.boxplot(funded_amount, ax=ax[1], color=\"#2F8FF7\")\nax[1].set_title(\"Amount Funded by Lender\", fontsize=12)\nsns.boxplot(investor_funds, ax=ax[2], color=\"#2EAD46\")\nax[2].set_title(\"Total committed by Investors\", fontsize=12)\n\ndf['funded_amnt_inv'].describe()","0ef252b2":"print(df[\"loan_status\"].value_counts())\n\n# Slice data frame into good and bad loan status\ndf_good = df.loc[(df.loan_status == 0), :]\ndf_bad  = df.loc[(df.loan_status == 1), :]\n\nplt.figure(figsize=(12, 6))\ncolors = [\"#3791D7\", \"#D72626\"]\nlabels = \"Good Loans\", \"Bad Loans\"\ndf[\"loan_status\"].value_counts().plot.pie(explode=[0,0.2], autopct='%1.2f%%', shadow=True, colors=colors, labels=labels, fontsize=12, startangle=70)\nplt.ylabel('% of Loan Status', fontsize=14)\nplt.show()","8c0c2841":"print(df.groupby(\"term_in_months\").loan_status.count())\nprint(df.groupby(\"term_in_months\").loan_status.mean())\nplt.figure(figsize=(14, 8))\nplt.subplot(2, 2, 1)\nax1 = sns.countplot(x=\"term_in_months\", data = df)\nax1.set(xlabel='Term in months', ylabel=\"Count of Loans\")\n# subplot 2\nplt.subplot(2, 2, 2)\nax2 = sns.barplot(x=\"term_in_months\", y = \"loan_status\" , data = df)\nax2.set(xlabel='Term in months', ylabel='Average Bad Loan %')\nplt.show()","af22a007":"print(df.groupby([\"issue_d_year\", \"term_in_months\"]).loan_status.count())\nprint(df.groupby([\"issue_d_year\", \"term_in_months\"]).loan_status.mean())\nplt.figure(figsize=(14, 8))\nax = sns.barplot(x=\"issue_d_year\", y = \"loan_status\" , hue=\"term_in_months\", data = df)\nax.set(xlabel='Loan Issue Year', ylabel='Average Bad Loan %')\nplt.show()","04b09fbe":"print(df.groupby(\"grade\").loan_status.mean())\nplt.figure(figsize=(12, 6))\nax = sns.barplot(x=\"grade\", y = \"loan_status\" , data = df)\nax.set(xlabel=\"Grade\", ylabel='Average Bad Loan %')\nplt.show()","222912d7":"grade = df.groupby('grade', as_index=False).agg({\"loan_status\": \"mean\"}).sort_values(by=['loan_status'], ascending=False)\n\ndef get_bad_loan_count_g(grade):\n    return len(df[((df['grade']==grade) & (df['loan_status']==1))].index)\n    \ndef get_good_loan_count_g(grade):\n    return len(df[((df['grade']==grade) & (df['loan_status']==0))].index)    \n\ngrade['Good Loan Count'] = grade[['grade']].applymap(lambda x:get_good_loan_count_g(x))\ngrade['Bad Loan Count'] = grade[['grade']].applymap(lambda x:get_bad_loan_count_g(x))\ngrade.rename(columns={'grade':'Grade','loan_status':'Bad Loan %'}, inplace=True)\ngrade.set_index('Grade', inplace=True)\n\ngrade.style.background_gradient('coolwarm')","024fb320":"df_grade = df.loc[df['grade'].isin(['A','B','C','D'])]\nprint(df_grade.groupby([\"grade\", \"sub_grade\"]).loan_status.mean())\nplt.figure(figsize=(12, 6))\nax = sns.barplot(x=\"sub_grade\", y = \"loan_status\", data = df)\nax.set(xlabel= \"Sub Grade\", ylabel='Average Bad Loan %')\nplt.show()","07df557f":"print(df.groupby(\"home_ownership\").loan_status.mean())\nplt.figure(figsize=(12, 6))\nax = sns.barplot(x=\"home_ownership\", y = \"loan_status\" , data = df)\nax.set(xlabel='Home Ownership', ylabel='Average Bad Loan %')\nplt.show()","fc3397d4":"print(df.groupby(\"annual_inc_type\").loan_status.mean())\nplt.figure(figsize=(14, 6))\nax = sns.barplot(x=\"annual_inc_type\", y = \"loan_status\", data = df)\nax.set(xlabel='Annual Income', ylabel='Average Bad Loan %')\nplt.show()","9f8c374a":"print(\"\\nBad Loan Average grouped by verification status ->\")\nprint(df.groupby(\"verification_status\").loan_status.mean())\nprint(\"\\nBad Loan Average grouped by annual income type and verification status ->\")\nprint(df.groupby([\"annual_inc_type\",\"verification_status\"]).loan_status.mean())\nprint(\"\\nLoan Counts grouped by annual income type and verification status ->\")\nprint(df.groupby([\"annual_inc_type\",\"verification_status\"]).loan_status.count())\nplt.figure(figsize=(18, 12))\nplt.subplot(2, 2, 1)\nax1 = sns.barplot(y=\"verification_status\", x = \"loan_status\", data = df)\nax1.set(ylabel='Annual Income Verification Status', xlabel='Average Bad Loan %')\n# subplot 2\nplt.subplot(2, 2, 3)\nax2 = sns.barplot(y=\"annual_inc_type\", x = \"loan_status\", hue=\"verification_status\", data = df)\nax2.set(ylabel='Annual Income', xlabel='Average Bad Loan %')\nplt.show()","35303791":"print(df.groupby(\"purpose\").loan_status.mean().sort_values(ascending=False))\nplt.figure(figsize=(14, 6))\nax = sns.barplot(y=\"purpose\", x = \"loan_status\" , data = df)\nax.set(xlabel='Average Bad Loan %', ylabel=\"Purpose\")\nplt.show()","44172c00":"purpose = df.groupby('purpose', as_index=False).agg({\"loan_status\": \"mean\"}).sort_values(by=['loan_status'], ascending=False)\n\ndef get_bad_loan_count_p(purpose):\n    return len(df[((df['purpose']==purpose) & (df['loan_status']==1))].index)\n    \ndef get_good_loan_count_p(purpose):\n    return len(df[((df['purpose']==purpose) & (df['loan_status']==0))].index)    \n\npurpose['Good Loan Count'] = purpose[['purpose']].applymap(lambda x:get_good_loan_count_p(x))\npurpose['Bad Loan Count'] = purpose[['purpose']].applymap(lambda x:get_bad_loan_count_p(x))\npurpose.rename(columns={'purpose':'Purpose','loan_status':'Bad Loan %'}, inplace=True)\npurpose.set_index('Purpose', inplace=True)\n\npurpose.style.background_gradient('coolwarm')","4b96ec47":"fig = make_subplots(rows=1, cols=1)\ntrace = go.Histogram(x=df[\"int_rate_percent\"], y=df[\"loan_status\"], histfunc='avg', nbinsx=10, marker_color='#9D0B9F',\n    opacity=0.90)\nfig.append_trace(trace,1,1)\nfig.update_layout(bargap=0.1,\n                  title_text='Average Bad Loan vs Interest Rate',\n                  xaxis_title_text='Interest rate %', \n                  yaxis_title_text='Average Bad Loan %')\nfig.show()","ed129349":"print(df.groupby(\"pub_rec_bankruptcies_b\").loan_status.mean().sort_values(ascending=False))\nplt.figure(figsize=(14, 6))\nax = sns.barplot(x=\"pub_rec_bankruptcies_b\", y = \"loan_status\" , data = df)\nax.set(ylabel='Average Bad Loan %', xlabel=\"Public Record Bankruptcies\")\nplt.show()","3f4ea3bf":"print(df.groupby(\"loan_type\").loan_status.mean())\nplt.figure(figsize=(12, 6))\nax = sns.barplot(x=\"loan_type\", y = \"loan_status\" , data = df)\nax.set(xlabel='Loan Type',ylabel='Average Bad Loan %')\nplt.show()","dcbe0e11":"plt.figure(figsize=(12, 6))\nax = sns.boxplot(x=\"loan_status\", y=\"dti\", data=df)\nax.set(xlabel='Loan Status',ylabel='Debt to Income %')","187bddd1":"print(df.groupby(\"delinq_2yrs_b\").loan_status.count())\nprint(df.groupby(\"delinq_2yrs_b\").loan_status.mean())\nplt.figure(figsize=(12, 6))\nax = sns.barplot(x=\"delinq_2yrs_b\", y = \"loan_status\" , data = df)\nax.set(xlabel='Incidences of delinquency in last 2yrs',ylabel='Average Bad Loan %')\nplt.show()","a827af3a":"fig = make_subplots(rows=1, cols=1)\ntrace = go.Histogram(x=df[\"revol_util_percent\"], y=df[\"loan_status\"], histfunc='avg', nbinsx=10, marker_color='#330C73',\n    opacity=0.75)\nfig.append_trace(trace,1,1)\nfig.update_layout(bargap=0.1,\n                  title_text='Revol Util vs Bad Loan',\n                  xaxis_title_text='Revol Util %', \n                  yaxis_title_text='Average Bad Loan %')\nfig.show()","3da6c997":"plt.figure(figsize=(16, 8))\nax = sns.barplot(x=\"emp_length\", palette = sns.color_palette(\"Greys\",4), hue=\"loan_type\", y = \"loan_status\" , data = df, \n                order=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10+\"])\nax.set(xlabel='Exp in years', ylabel='Average Bad Loan %')\nplt.show()","6caa820c":"plt.figure(figsize=(14, 6))\nax = sns.barplot(y=\"zip_code_group\", x = \"loan_status\" , data = df)\nax.set(xlabel='Average Bad Loan %', ylabel=\"Zip Code Group\")\nplt.show()","0aca778e":"plt.figure(figsize=(16, 8))\nax = sns.barplot(x=\"home_ownership\", y = \"loan_status\" , hue=\"zip_code_group\", data = df)\nax.set(xlabel='Zip Group', ylabel='Average Bad Loan %')\nplt.show()","b76f930c":"statewise = df.groupby('addr_state', as_index=False).agg({\"loan_status\": \"mean\"}).sort_values(by=['loan_status'], ascending=False)\n\ndef get_bad_loan_count(addr_state):\n    return len(df[((df['addr_state']==addr_state) & (df['loan_status']==1))].index)\n    \ndef get_good_loan_count(addr_state):\n    return len(df[((df['addr_state']==addr_state) & (df['loan_status']==0))].index)    \n\nstatewise['Good Loan Count'] = statewise[['addr_state']].applymap(lambda x:get_good_loan_count(x))\nstatewise['Bad Loan Count'] = statewise[['addr_state']].applymap(lambda x:get_bad_loan_count(x))\n\nstatewise.rename(columns={'addr_state':'State','loan_status':'Bad Loan %'}, inplace=True)\nstatewise.set_index('State', inplace=True)\n\nstatewise.style.background_gradient('coolwarm')","f5ad6a5d":"Summary:\n\nAmong the subgrades too of lower Grades A to D - bad loan % increments in a consistent manner between the sub grades in each grade.\n\nGrades E to G already determined as higher risks.","8a87c264":"<h4>pub_rec_bankruptcies_b and delinq_2yrs_b<\/h4>\n    ","4a0dea1c":"<h4>Zip_Code<\/h4>\nZip Codes are orderly data , they are ordered numerically from east to west.Hence grouping them to infer the defaulter percentages for each group.\n","bb624e99":"Statewise analysis of loan percentage.\n\nFrom the gradient we can clearly make out 'CA' is one of the worst performing states in terms of number of bad loans.\n\nAnd 'NE' has the highest bad loan% (60%).","ad2702cd":"Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n\nPlot reveals that bad loan % increases steadily as the Revolving line utilization rate increases.","5ff5450f":"## DATA CLEANING","370a6ad1":"## Analysis of Annual Income vs Bad Loans","2514f33d":"## Analysis of Home Ownership vs Bad Loans","5619eb32":"## DATA UNDERSTANDING","0190ec1c":"## Case Study Objectives via EDA","2965878c":"Problem Statement:\n\n<h4>Understand what amount was mostly issued to borrowers<\/h4>","2131440d":"## DATA SUMMARIZATION","f1af7ff1":"## Analysis of Loan Term vs Bad Loans","d7d5e841":"<h4>Derive annual income buckets based upon IQR of annual income<\/h4>","d56a75ce":"Summary:\n\nThose who have annual income as not verified have 13% average of bad loans whereas those who have annual income as verified have 17% average of bad loans.\n\nAlso in each annual income category, the impact of income verification status seems strange. Those who have annual income verified or source verified have higher bad loan average than those who have annual income as not verified.","e40e5276":"Summary:\n\nThose who have high income are less likely to default on loans. Income>82000 have 11% average of bad loans.\n\nWhereas those who have very low income are more likely to default on loans. Income <=40000 have 18% average of bad loans.","c0e7487c":"## Analysis of Sub Grade vs Bad Loans","0071775f":"## DERIVED METRICS","b423ad31":"Summary:\n\nMost of the loans issued were in the range of 5,000 to 14,000.\nThe loans applied by potential borrowers, the amount issued to the borrowers and the amount funded by investors are similarly distributed, meaning that it is most likely that qualified borrowers are going to get the loan they had applied for.","c3436a8c":"## Analysis of grouped variables - Loan Issued Year and Term vs Bad Loans","99826f9d":"## Analysis of Revolving Utilization vs Bad Loans","0c123daf":"## Analysis of Interest Rate vs Bad Loans","ee25df60":"Summary:\n\nThose who are approved loan for small business are more likely to default on loans with an average of 27%.\n\nAnd those who are approved loans for purpose such as major purchase, wedding, car or credit card are least likely to default on loans with an average of around 10 to 11%.","bbb6816f":"Summary:\n\nFully paid or good loans consist 85.41% of total loans in the cleaned data frame.\n\nCharged off or bad loans consist 14.59% of total loans in the cleaned data frame.","517d2ef5":"Summary: \n\nGrade G has highest 34% average who default on loans.\n\nGrade F has second highest 33% average who default on loans.\n\nBetween Grades A to G - bad loan % increments in a consistent manner.","a6bf1fda":"\u2022 Determine the factors and attributes that contribute to Bad Loans.\n\n\u2022 Determine grouped factors that contribute to Bad Loans.\n\n\u2022 Analyse both Bad Loan Average and Number of Bad Loans.","3d29d286":"Summary:\n\nBetween 2007-2009, there were only 36 months term loans.\n\n2010-11 included 60 months term loans.\n\nAnd in last 2 years of the data set, there are more default loans among the 60 months term loans.\n\n27% of 60 months term loans defaulted in year 2011 and 21% of 60 months term loans defaulted in year 2010.","3ecd5e04":"## Analysis of delinq in last 2yrs vs Bad Loans","09c5955e":"## Business Understanding","39e7fa08":"<h4>Emp length<\/h4>\n    Bucketing emp length and standardizing the data.\n    Assumption made, candidates with less than 1 year of exp also bucketed in 1 year.","38f0282f":"Among the employee length, applicants with 0 years of exp are having higher probability of bad loans that is 25%.\n\nWhen grouped with loan amount we can also observe large amount loans are performing badly across all employee lengths. Also  in 10+ category the variance is significant.","96dbcfa9":"## Analysis of Purpose of Loan vs Bad Loans","7a04601c":"Summary:\nFrom the plot we can infer that the variance is very low among different categories hence it alone is unable predict bad loans %.","60f03af0":"## Analysis of Public Record Bankruptcies vs Bad Loans","27491f43":"## Analysis of Income Verification Status and Annual Income vs Bad Loans","e8a6eb2d":"## Analysis of Debt to Income Percentage vs Bad Loans","60bfe5c7":"The heat map of the purpose against the bad loan percentage along with counts also reveals that \"debt consolidation\" is the worst performing purpose in terms of count.","156b1c89":"Candidate with a home ownership of OTHER and from a zip group of 801-900 have a 40% probability of bad loans.","f9bdcde2":"Problem Statement:\n\n<h4>Percentage of good loans and bad loans<\/h4>","f1a52de1":"## Analysis of Grade vs Bad Loans","165f9016":"![image.png](attachment:image.png)","f4a8d211":"Plot reveals that bad loan % increases steadily as the interest rate increases.","bf174869":"## Analysis of States vs Bad Loans","bc0deb19":"Summary:\n\nIf loan term is 60 months then it has 25% average who default on loans as compared to loan term of 36 months which has 11% average who default on loans.\n\nAlso from the count plot, one can infer that number of entries of 36 months is approx 3 times number of entries of 60 months. Still it has 11% average who default on loans.","ef52fbd2":"Summary:\n\nThose who have public record bankrupt record are more likely to default on loans with an average of 22%.","8645ea1a":"## Analysis of Zip Code vs Bad Loans","c39131d3":"<h4>issue_d_year<\/h4>\nissue_d derives issue_d_year\n\nearliest_cr_line derives earliest_cr_line_year","1f6ca01d":"From the box plot we can infer that plots are similar for both good and bad loans, which signifies this field alone does not have much of impact on the bad loan %.","2af6a9c8":"<h4>Derive Loan received amount bucket column <\/h4>","c63cf53f":"## Derive target column which is loan_status","3e45f194":"Zip Codes 301-400 and 900-901 have higher bad loan % as compared to other zip codes groups.\n","167a91c8":"## Analysis of number of loans and bad loans per grade in a table","bfdab558":"## Analysis of Employee Length vs Bad Loans","83275d2e":"Summary:\n\nThere is less variance of bad loan % by the home ownership category.\n\nAll categories of home ownership (except others) have almost the same average of default loans.","4983154b":"When a person applies for a loan, there are two types of decisions that could be taken by the company:\n\n1. Loan accepted: If the company approves the loan, there are 3 possible scenarios described below:\n\n    a. Fully paid: Applicant has fully paid the loan (the principal and the interest rate)\n\n    b. Current: Applicant is in the process of paying the instalments, i.e. the tenure of the loan is not yet completed. These candidates are not labelled as 'defaulted'.\n\n    c. Charged-off: Applicant has not paid the instalments in due time for a long period of time, i.e. he\/she has defaulted on the loan \n\n\n2. Loan rejected: The company had rejected the loan (because the candidate does not meet their requirements etc.). Since the loan was rejected, there is no transactional history of those applicants with the company and so this data is not available with the company (and thus in this dataset)","77ff5c68":"## Analysis of Loan Amount vs Bad Loans","73abdf55":"Summary:\n\nThose who have incidences of delinquency in last 2 years default on loans with an average of 16%.\n\nThose who don't have any incidences of delinquency in last 2 years default on loans with an average of 14%.","dd54c125":"You work for a consumer finance company which specialises in lending various types of loans to urban customers. When the company receives a loan application, the company has to make a decision for loan approval based on the applicant\u2019s profile. Two types of risks are associated with the bank\u2019s decision:\n\nIf the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n\nIf the applicant is not likely to repay the loan, i.e. he\/she is likely to default, then approving the loan may lead to a financial loss for the company\n\nThe dataset given contains the information about past loan applicants and whether they \u2018defaulted\u2019 or not. The aim is to identify patterns which indicate if a person is likely to default, which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc.\n\nIn this case study, you will use EDA to understand how consumer attributes and loan attributes influence the tendency of default."}}