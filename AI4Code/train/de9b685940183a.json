{"cell_type":{"d493805d":"code","de1239cf":"code","6fc0042d":"code","63e4b569":"code","6069ceff":"markdown","6b01758e":"markdown","c3f64ba2":"markdown"},"source":{"d493805d":"from datetime import datetime, date\nimport pandas as pd\nfrom google.cloud import bigquery\nfrom bq_helper import BigQueryHelper\n\nbqh = BigQueryHelper(\"bigquery-public-data\", \"crypto_bitcoin\")\ndefault_val = \"2009-01-03 18:15:05+00:00\" # creation timestamp of the first Bitcoin block\n\nquery = f\"\"\"\nSELECT timestamp,\n       Lag(timestamp, 1, \"{default_val}\") OVER (ORDER BY timestamp ASC) as timestamp_prev,\n       TIMESTAMP_DIFF(timestamp, Lag(timestamp, 1, \"{default_val}\") OVER \n         (ORDER BY timestamp ASC), SECOND) AS seconds_elapsed\nFROM `bigquery-public-data.crypto_bitcoin.blocks` blocks\nORDER BY timestamp ASC;\n\"\"\"\n\ndf = bqh.query_to_pandas(query)\n\n# the below warning is due to the default Kaggle environment; they recently got rid of the manual pip install feature :(","de1239cf":"TWO_HOURS = 7200 # in seconds\ndf2 = df[df.seconds_elapsed >= TWO_HOURS]\nq2_ans1 = df2.shape[0]\nprint(\"Consecutive blocks took 2 hours or more to add \" + str(q2_ans1) + \" times throughout Bitcoin's history,\")\n\ndf3 = df2.copy(deep=True)\ndf3.loc[:, 'year'] = df2.apply(lambda row: str(row.timestamp)[:4], axis=1)\ndf3 = df3[df3['year'] != \"2009\"]\nq2_ans2 = df3.shape[0]\nprint(\"with only \" + str(q2_ans2) + \" occurring after 2009.\")\n\n# as the first year, 2009 was an extreme outlier, with an inconsistent numbers of miners and unstable block times","6fc0042d":"d0 = date(2009, 1, 3) # first block date added\nd1 = date(2010, 1, 1) # first day after 2009\ntime_since_origin = date.today() - d0\ntime_since_2010 = date.today() - d1\n\nq1_ans1 = int(time_since_origin.days \/ q2_ans1)\nq1_ans2 = int(time_since_2010.days \/ q2_ans2)\nprint(\"On average, we see a consecutive 2hr+ block added every \" + str(q1_ans1) + \" days.\")\nprint(\"However, post-2009, the average changes to about \" + str(q1_ans2) + \" days.\")","63e4b569":"# let us calculate the observed probability, post-2009\nobserved_p = q2_ans2 \/ (time_since_2010.days * 12) # divide by two to calculate 2 hour intervals, not 1 hr\nprint(\"The observed probability of a 2hr+ consecutive block is higher than calculated: \" + str(observed_p))","6069ceff":"This discrepancy may be explained in the human error in maintaining the expected 10 minute block times. As per Nasdaq's analysis (https:\/\/www.nasdaq.com\/articles\/bitcoin-has-hit-a-historically-slow-average-block-time-2021-06-29), it is extremely hard to guarantee a consistent block time, adding unfactored variance not accounted for in the Poisson model.","6b01758e":"Sources referenced:\n* https:\/\/bitinfocharts.com\/comparison\/bitcoin-confirmationtime.html#log&alltime\n* https:\/\/www.nasdaq.com\/articles\/bitcoin-has-hit-a-historically-slow-average-block-time-2021-06-29\n* https:\/\/blog.lopp.net\/bitcoin-block-time-variance\/\n* https:\/\/homepage.divms.uiowa.edu\/~mbognar\/applets\/pois.html\n* https:\/\/www.youtube.com\/watch?v=f1ZJPEKeTEY&pageId=102195317342105019645","c3f64ba2":"I used the Poisson distribution formula for calculating probability of x occurrences of an event over a fixed time and an expected value, lambda, using lambda=12 because twelve 10-minute expected block time intervals occur in two hours, and x=0 because we want to see no occurrences within that 2 hour block to signify a 2hr+ block addition time. This comes out to a probability value of 6.144 * 10^-6.\n\n"}}