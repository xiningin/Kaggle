{"cell_type":{"9a759616":"code","23b447b6":"code","1602c5c8":"code","68ca83d3":"code","3c5fc663":"code","5d5761b1":"code","ac81b5c0":"code","322c2125":"code","6cffbfde":"code","d3269d86":"code","657d11d2":"code","5fef9d4b":"code","cac84ab7":"code","3696ce64":"code","a75cd2b4":"code","480ee78b":"code","d6f122a1":"code","69ff7ac7":"code","c53e3e36":"code","1552c989":"code","9d990e0d":"code","5ef826fa":"code","99d756c9":"code","aeefd8f5":"code","e3312ef4":"code","f47c99eb":"code","2524d464":"code","04142da6":"code","7e093760":"markdown","ecb30600":"markdown","ec4f35ea":"markdown","417102a4":"markdown","cf602db7":"markdown","78518cd3":"markdown","a452dfb3":"markdown","5d1b0024":"markdown","29e4e6d0":"markdown","c2b994af":"markdown","c4846bbd":"markdown"},"source":{"9a759616":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt","23b447b6":"dataset = pd.read_csv(\"..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")","1602c5c8":"dataset.head()","68ca83d3":"dataset.tail()","3c5fc663":"dataset.shape","5d5761b1":"dataset = dataset.values","ac81b5c0":"training_data_ratio = 0.8\nnp.random.shuffle(dataset)\n\ntraining_dataset = dataset[:int(dataset.shape[0] * training_data_ratio), :]\nvalidation_dataset = dataset[int(dataset.shape[0] * training_data_ratio):, :]","322c2125":"print(\"The shape of training dataset: \", training_dataset.shape)\nprint(\"The shape of validation dataset: \", validation_dataset.shape)","6cffbfde":"# create a tokenizer\ntokenizer = keras.preprocessing.text.Tokenizer(num_words=12000, oov_token=\"<OOV>\")","d3269d86":"# fit tokenizer on training sentences\ntokenizer.fit_on_texts(training_dataset[:, 0])","657d11d2":"# show the word - value pair\ntokenizer.word_index","5fef9d4b":"# tokenize training sentences and validation sentences\nx_train = tokenizer.texts_to_sequences(training_dataset[:, 0])\nx_validation = tokenizer.texts_to_sequences(validation_dataset[:, 0])","cac84ab7":"# length of sequences in training set are different, so are sentences in validation set\nprint(\"The length of sentence in training set: \", len(x_train[0]))\nprint(\"The length of sentence in training set: \", len(x_train[100]))\n\nprint(\"The length of sentence in validation set: \", len(x_validation[0]))\nprint(\"The length of sentence in validation set: \", len(x_validation[100]))","3696ce64":"# pad the sentence to make them same length\nx_train = keras.preprocessing.sequence.pad_sequences(sequences=x_train, \n                                           maxlen=256,\n                                           padding=\"post\",\n                                           truncating=\"post\")\n\nx_validation = keras.preprocessing.sequence.pad_sequences(sequences=x_validation, \n                                                          maxlen=256,\n                                                          padding=\"post\",\n                                                          truncating=\"post\")","a75cd2b4":"print(\"The length of sentence in training set: \", len(x_train[0]))\nprint(\"The length of sentence in training set: \", len(x_train[100]))\n\nprint(\"The length of sentence in validation set: \", len(x_validation[0]))\nprint(\"The length of sentence in validation set: \", len(x_validation[100]))","480ee78b":"# convert training labels and validation labels to one-of-two encoding form\ny_train = training_dataset[: ,1]\ny_validation = validation_dataset[:, 1]\n\nprint(\"Training Labels: \", y_train)\nprint(\"Validation Labels: \", y_validation)","d6f122a1":"# convert string two integer\nmask_pos = (y_train == \"positive\")\nmask_neg = (y_train == \"negative\")\ny_train[mask_pos] = 1\ny_train[mask_neg] = 0\n\n\nmask_pos = (y_validation == \"positive\")\nmask_neg = (y_validation == \"negative\")\ny_validation[mask_pos] = 1\ny_validation[mask_neg] = 0","69ff7ac7":"# one-of-two encoding form\ny_train = keras.utils.to_categorical(y=y_train, num_classes=2)\ny_validation = keras.utils.to_categorical(y=y_validation, num_classes=2)","c53e3e36":"# have a look on part on training data\nprint(\"Part of Training Data: \")\nprint()\nprint(\"Sentences: \")\nprint(x_train[0:10])\nprint()\nprint(\"Labels: \")\nprint(y_train[0:10])","1552c989":"# have a look on part on validation data\nprint(\"Part of Validation Data: \")\nprint()\nprint(\"Sentences: \")\nprint(x_validation[0:10])\nprint()\nprint(\"Labels: \")\nprint(y_validation[0:10])","9d990e0d":"inputs = keras.layers.Input(shape=(256, ))\nx = keras.layers.Embedding(input_dim=12000, output_dim=48, input_length=256)(inputs)\nx = keras.layers.Flatten()(x)\nx = keras.layers.Dense(units=24, activation=\"relu\")(x)\nx = keras.layers.Dense(units=12, activation=\"relu\")(x)\noutputs = keras.layers.Dense(units=2, activation=\"softmax\")(x)\n\nmodel = keras.models.Model(inputs=inputs, outputs=outputs)","5ef826fa":"model.summary()","99d756c9":"model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"acc\"])","aeefd8f5":"class CustomCallback(keras.callbacks.Callback):\n    \n    def on_epoch_end(self, epoch, logs):\n        if logs[\"acc\"] >= 0.99:\n            self.model.stop_training = True\n    \ncustom_callback = CustomCallback()","e3312ef4":"history = model.fit(x=x_train,\n          y=y_train,\n          batch_size=32,\n          epochs=20,\n          callbacks=custom_callback,\n          validation_data=(x_validation, y_validation))","f47c99eb":"training_acc = history.history[\"acc\"]\nvalidation_acc = history.history[\"val_acc\"]\nepoch = list(range(len(training_acc)))\n\nplt.plot(epoch, training_acc, \"b\", label=\"Training Acc\")\nplt.plot(epoch, validation_acc, \"r\", label=\"Validation Acc\")\n\nplt.legend()\nplt.show()","2524d464":"# get the embedding layer in model\nembedding_layer = model.layers[1]\n\n# get the weight of embedding layer\nembedding_matrix = embedding_layer.get_weights()[0]","04142da6":"# each row in embedding matrix represents embedding vector of word\nembedding_matrix.shape","7e093760":"## Tokenize Sentence & Label for Neural Network","ecb30600":"## Split into Training & Validation Dataset","ec4f35ea":"## Performance of Training Process (Overfitting)","417102a4":"## Extract Embedding Vector","cf602db7":"### Model Callback","78518cd3":"## Define Model","a452dfb3":"### Model Architecture","5d1b0024":"## Train Model","29e4e6d0":"### Model Compilation","c2b994af":"## Load Dataset","c4846bbd":"## Import Package"}}