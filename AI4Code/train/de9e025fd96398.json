{"cell_type":{"adc6c418":"code","a0a526ad":"code","ddc84784":"code","4ce3ad53":"code","90745c2a":"code","0a0c0a56":"code","40e4adf5":"code","836d8727":"code","e3f8eb2e":"code","8d959e69":"code","0e6040db":"code","01f1e439":"code","b4e6a54e":"code","7bd753fc":"code","c72b5252":"code","25d9a52c":"code","5da4ba0f":"code","651e3df0":"code","426ae02d":"code","0b700e91":"code","4654580c":"code","7bc263bb":"code","16561e3c":"code","73b8be6d":"code","1a6b7460":"code","a24ba48e":"code","882403ae":"code","a7610f1f":"code","f157ed6e":"code","9999b129":"code","b82c2ce3":"code","7fc21a34":"markdown","a6309250":"markdown","c5878627":"markdown","8840d52b":"markdown","a849e4a6":"markdown","d1a33f17":"markdown","91e58298":"markdown","689f475c":"markdown","063b01b0":"markdown"},"source":{"adc6c418":"!pip -q install iterative-stratification tensorflow-io","a0a526ad":"import warnings\nwarnings.filterwarnings(\"ignore\")","ddc84784":"from collections import OrderedDict\nimport os\nfrom glob import glob\nfrom itertools import chain\nimport random\nfrom tqdm import tqdm\n\nimport cv2\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","4ce3ad53":"pd.set_option(\"display.max_rows\", 100)\npd.set_option(\"display.max_columns\", 100)\nsns.set_style(\"darkgrid\")","90745c2a":"TRAIN_PATH = \"..\/input\/arya-hw-lines\/train\/train\/\"\nTEST_PATH = \"..\/input\/arya-hw-lines\/test\/test\/\"","0a0c0a56":"train_files = sorted(glob(os.path.join(TRAIN_PATH, \"*.tif\")))\ntrain_labels = sorted(glob(os.path.join(TRAIN_PATH, \"*.gt.txt\")))","40e4adf5":"test_files = sorted(glob(os.path.join(TEST_PATH, \"*.tif\")))","836d8727":"print(f\"Training Data: {len(train_files), len(train_labels)}\")\nprint(f\"Testing Data: {len(test_files)}\")","e3f8eb2e":"train_captions = []\nfor file in tqdm(train_labels):\n    with open(file, \"r\") as f:\n        train_captions.append(f.read().strip())","8d959e69":"train_df = pd.DataFrame({\"ImagePath\": train_files, \"Label\": train_captions})","0e6040db":"train_df.head()","01f1e439":"def plot_grid(files, labels=None, h=3, w=3, title=\"\"):\n    if not labels:\n        labels = [\"\"]*len(files)\n    f, ax = plt.subplots(h, w, figsize=(18, 18))\n    for idx, (path, label) in enumerate(random.choices(list(zip(files, labels)), k=h*w)):\n        image = cv2.imread(path, 0)\n        \n        ax[idx \/\/ h, idx % w].imshow(image)\n        ax[idx \/\/ h, idx % w].axis(\"off\")\n        ax[idx \/\/ h, idx % w].set_title(f\"{path.split('\/')[-1]} - {label}\")\n    plt.tight_layout()\n    plt.suptitle(title)\n    plt.show()","b4e6a54e":"plot_grid(train_df[\"ImagePath\"].tolist(), train_df[\"Label\"].tolist(), title=\"Train Images\")","7bd753fc":"plot_grid(test_files, title=\"Test Images\")","c72b5252":"train_df[\"Length\"] = train_df[\"Label\"].astype(str).str.len()","25d9a52c":"train_df[\"Length\"].describe()","5da4ba0f":"train_df[\"Length\"].value_counts()","651e3df0":"unique_chars = sorted(list(set(\" \".join(train_captions))))\nprint(unique_chars)","426ae02d":"for i in unique_chars:\n    try:\n        train_df[i] = train_df[\"Label\"].str.count(i)\n    except:\n        print(i)","0b700e91":"# treating regex chars differently\ntrain_df[\"(\"] = train_df[\"Label\"].str.count(r\"\\(\")\ntrain_df[\")\"] = train_df[\"Label\"].str.count(r\"\\)\")\ntrain_df[\"*\"] = train_df[\"Label\"].str.count(r\"\\*\")\ntrain_df[\"+\"] = train_df[\"Label\"].str.count(r\"\\+\")\ntrain_df[\"?\"] = train_df[\"Label\"].str.count(r\"\\?\")\ntrain_df[\"[\"] = train_df[\"Label\"].str.count(r\"\\[\")\n\n# overwriting \".\" since it matches every element\ntrain_df[\".\"] = train_df[\"Label\"].str.count(r\"\\.\")","4654580c":"train_df.sample(n=5)","7bc263bb":"for i in unique_chars:\n    print(f\"{i} - {train_df[i].sum()}\")","16561e3c":"h_shape=[]\nw_shape=[]\naspect_ratio=[]\nfor idx in tqdm(range(len(train_df))):\n    image = cv2.imread(train_df[\"ImagePath\"][idx])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    h_shape.append(image.shape[0])\n    w_shape.append(image.shape[1])\n    aspect_ratio.append(1.0 * (image.shape[1] \/ image.shape[0]))","73b8be6d":"len(h_shape), len(w_shape), len(aspect_ratio)","1a6b7460":"plt.figure(figsize=(20, 20))\nplt.subplots_adjust(top = 0.5, bottom=0.01, hspace=1, wspace=0.4)\n\nplt.subplot(2, 2, 1)\nsns.histplot(np.array(h_shape) * np.array(w_shape), bins=50)\nplt.xticks(rotation=45)\n_ = plt.title(\"Area Image Distribution\", fontsize=20)\n\nplt.subplot(2, 2, 2)\nsns.histplot(h_shape, bins=50)\n_ = plt.title(\"Height Image Distribution\", fontsize=20)\n\nplt.subplot(2, 2, 3)\nsns.histplot(w_shape, bins=50)\n_ = plt.title(\"Width Image Distribution\", fontsize=20)\n\nplt.subplot(2, 2, 4)\nsns.histplot(aspect_ratio, bins=50)\n_ = plt.title(\"Aspect Ratio Distribution\", fontsize=20)","a24ba48e":"sample = train_df[train_df[\"Length\"]==1]\nplot_grid(sample[\"ImagePath\"].tolist(), sample[\"Label\"].tolist(), title=\"Label (len=1)\")","882403ae":"issue = [\"g04-036-07.tif\", \"d09-651z-05.tif\", \"f06-396z-09.tif\", \n         \"f04-310z-05.tif\", \"f07-425z-08.tif\", \"b06-032-09.tif\", \n         \"l06-637z-06.tif\", \"d03-229z-06.tif\", \"n10-277z-06.tif\", \n         \"n01-015z-04.tif\", \"n01-062z-07.tif\", \"d05-380z-06.tif\"]","a7610f1f":"problematic = train_df.loc[train_df[\"ImagePath\"].str.split(\"\/\").str[-1].isin(issue)]","f157ed6e":"plot_grid(problematic[\"ImagePath\"].tolist(), problematic[\"Label\"].tolist(), h=4, w=4, title=\"Difficult Cases\")","9999b129":"kfold = MultilabelStratifiedKFold(n_splits=5, shuffle=False)","b82c2ce3":"for fold, (train_idx, valid_idx) in enumerate(kfold.split(X=train_df[\"ImagePath\"], y=train_df[unique_chars])):\n    print(\"*\"*28)\n    print(\"*\"+\" \"*10+f\"FOLD {fold}\"+\" \"*10+\"*\")\n    print(\"*\"*28)\n    \n    print(f\"Train: {len(train_idx)}\")\n    train_cases = train_df.loc[train_idx]\n    for i in unique_chars:\n        print(f\"{i} - {train_cases[i].sum()}\")\n    \n    print(f\"\\nValidation: {len(valid_idx)}\")\n    valid_cases = train_df.loc[valid_idx]\n    for i in unique_chars:\n        print(f\"{i} - {valid_cases[i].sum()}\")\n    print(\"\\n\\n\")","7fc21a34":"### Unique Characters","a6309250":"## Stratification\nHere, I am testing if `MultiLabelStratifiedKFold` can be used as a validation strategy. Essentially splits will be made based on character counts, such that **each fold has equivalent number of count per character.**","c5878627":"## Image Dimensions","8840d52b":"All labels are in *CAPS*. Possibly the model will have trouble representing `d` & `D` both as capital letter - D","a849e4a6":"I'll keep on updating the notebook as I work on it.","d1a33f17":"## Train Labels","91e58298":"## Problematic Cases","689f475c":"## Random Visualization","063b01b0":"## Characters Distribution"}}