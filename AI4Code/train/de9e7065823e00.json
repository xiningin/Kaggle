{"cell_type":{"8c1735c3":"code","0b59a3d6":"code","c31e4a5e":"code","fa4fa9be":"code","7f44872e":"code","b8084de3":"code","22a7540e":"code","da6221ac":"code","f85efa30":"code","57dc9e21":"code","b99e46b3":"code","667f859b":"code","5599c184":"code","21fc92d1":"code","29ec190a":"code","5f3ebf0e":"code","920c461b":"code","2c815336":"code","6723391f":"code","ed0e1fb3":"code","037a3699":"code","ea718bbe":"code","edce55c2":"code","dc8d1c52":"code","6ddc4598":"code","3d177c18":"markdown","e8962df8":"markdown","7984f44d":"markdown","61c0476e":"markdown","fd4f9ef1":"markdown","cc937759":"markdown","64ef6cde":"markdown","55438a35":"markdown","274bd1b0":"markdown","5ba27269":"markdown","8b9f393d":"markdown","b06d6b2c":"markdown","7e689203":"markdown","d4956e91":"markdown","728c970e":"markdown","204ff464":"markdown","3ae69f9d":"markdown","1ea5b37d":"markdown","cc9b644f":"markdown","c7706368":"markdown","5ca8707f":"markdown"},"source":{"8c1735c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0b59a3d6":"#importing the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c31e4a5e":"#reading the input CSV file and storing it in a dataframe\ndf = pd.read_csv(\"..\/input\/youtube-new\/USvideos.csv\")","fa4fa9be":"#shape of the dataframe (dataset)\ndf.shape","7f44872e":"#statistical information about the data\ndf.describe()","b8084de3":"#checking for null values. It says increase the count by 1 whenever you find a null value in each column\ndf.isnull().sum()","22a7540e":"#number of unique values (no duplicates are counted)\ndf.nunique()","da6221ac":"#data type of each column\ndf.dtypes","f85efa30":"#datatype and number of non-null values in each column\ndf.info()","57dc9e21":"#prints first five rows of the dataframe\ndf.head()","b99e46b3":"#defining the size of the figure\nplt.figure(figsize = (20,4))\n\n#Important note: 1st digit in subplot indicates the number of rows in the plot, 2nd digit indicates the number of columns in the plot, 3rd digit indicates the index\n#So, we use 14 as we want one row and 4 columns.\nplt.subplot(141)\np1 = sns.distplot(df['likes'], color='green')\nplt.xticks(rotation='vertical')\np1.set_title('Distribution of number of likes')\n\nplt.subplot(142)\np2 = sns.distplot(df['dislikes'], color='red')\np2.set_title('Distribution of number of dislikes')\n\nplt.subplot(143)\np3 = sns.distplot(df['views'], color='blue')\np3.set_title('Distribution of number of views')\n\nplt.subplot(144)\np4 = sns.distplot(df['comment_count'], color='yellow')\np4.set_title('Distribution of number of comments')\n\nplt.subplots_adjust(wspace = 0.4)\nplt.xticks(rotation='vertical')\nplt.show()","667f859b":"#defining the size of the figure\nplt.figure(figsize = (20,4))\n\ndf['likes_log'] = np.log(df['likes']+1)\ndf['dislikes_log'] = np.log(df['dislikes']+1)\ndf['views_log'] = np.log(df['views']+1)\ndf['comments_log'] = np.log(df['comment_count']+1)\n\nplt.subplot(141)\np1 = sns.distplot(df['likes_log'], color='green')\np1.set_title('Log distribution of number of likes')\n\nplt.subplot(142)\np2 = sns.distplot(df['dislikes_log'], color='red')\np2.set_title('Log distribution of number of dislikes')\n\nplt.subplot(143)\np3 = sns.distplot(df['views_log'], color='blue')\np3.set_title('Log distribution of number of views')\n\nplt.subplot(144)\np4 = sns.distplot(df['comments_log'], color='yellow')\np4.set_title('Log distribution of number of comments')\n\nplt.show()","5599c184":"#adding a column with all entries 'None'\ndf['likesl'] = 'None'\ndf['dislikesl'] = 'None'\n\n#dropping one column\ndf.drop('likesl', axis=1)\n\n#dropping multiple columns (columns keyword is optional). Both the below statements yield the same result\ndf.drop(['dislikesl', 'likesl'], axis=1)\ndf.drop(columns=['dislikesl', 'likesl'], axis=1)","21fc92d1":"df.head()","29ec190a":"df.head()","5f3ebf0e":"#Percentage of likes, dslikes and comments\ndf['like_rate'] =  df['likes'] \/ df['views'] * 100\ndf['dislike_rate'] =  df['dislikes'] \/ df['views'] * 100\ndf['comment_rate'] =  df['comment_count'] \/ df['views'] * 100","920c461b":"#defining the size of the figure\nplt.figure(figsize = (20,4))\n\nplt.subplot(131)\np1 = sns.distplot(df['like_rate'], color='green')\nplt.xticks(rotation='vertical')\np1.set_title('Like rate')\n\nplt.subplot(132)\np2 = sns.distplot(df['dislike_rate'], color='red')\np2.set_title('Dislikes rate')\n\nplt.subplot(133)\np3 = sns.distplot(df['comment_rate'], color='blue')\np3.set_title('Views rate')\n\nplt.subplots_adjust(wspace = 0.4)\nplt.xticks(rotation='vertical')\nplt.show()","2c815336":"#Countplots\n# sns.set(style=\"darkgrid\")\n# ax = sns.countplot(x=df['like_rate'], data=df)","6723391f":"plt.figure(figsize = (20,6))\nplt.subplot(121)\nplt.scatter(df['like_rate'], df['dislike_rate'])\nplt.subplot(122)\nplt.scatter(df['like_rate'], df['comment_rate'])","ed0e1fb3":"#Correlation between views and likes\nplt.figure(figsize = (20,10))\nplt.scatter(df['views'], df['likes'])\nplt.xlabel('Views', fontsize=26)\nplt.ylabel('Likes', fontsize=26)\nplt.xticks(size = 15)\nplt.yticks(size = 15)","037a3699":"df['likes'].corr(df['views'])","ea718bbe":"df.corr(method='pearson')","edce55c2":"sns.heatmap(df.corr())","dc8d1c52":"df.corr(method ='kendall') ","6ddc4598":"plt.figure(figsize = (20,4))\n\nplt.subplot(121)\np1 = sns.distplot(df['likes_log'], color='green')\nplt.xticks(rotation='vertical')\np1.set_title('Distribution of number of likes')\n\nplt.subplot(122)\np3 = sns.distplot(df['views_log'], color='blue')\np3.set_title('Distribution of number of views')\n\n# plt.subplots_adjust(wspace = 0.4)\n# plt.xticks(rotation='vertical')\nplt.show()","3d177c18":"As you can see in the above plots, the values are so small and are not visible clearly. This gives us an indication that we have to plot a log distribution.","e8962df8":"Doing the above doesn't permanently delete the column from the dataframe. It deletes only in that execution of the cell. You can check so by doing df.head(). You can see that 'likesl' and 'dislikesl' columns are still present.","7984f44d":"Plotting scatter plots...","61c0476e":"**Frankly speaking, this is not accurate. Because, Pearson assumes that variables are linearly propotional whereas here, they are not actually so.**","fd4f9ef1":"The describe method helps us to get an idea of the data.","cc937759":"The above is called the heatmap and is a very good visualizaiton tool for understanding the correlation between all the attributes of the dataset. ***Personally, this is one of my favorites! ***","64ef6cde":"Since the columns comments_disabled, ratings_disabled and video_error_or_removed take only 2 unique values, we can understand before hand that their datatypes are boolean. We can confirm the same by running df.dtypes which gives the datatype of each column.","55438a35":"If you want to know the number of non-null values and data type of columns using a single command, you can do as below.","274bd1b0":"85% is a strong positive correlation. In other ways, it says as number of views increases, number of likes increases and it's valid for 85% of the data points. Few unusual outliers may have a huge impact on correlation.","5ba27269":"It can be seen that these distributions closely follow normal distribution. The first one (number of likes) is slightly right-skewed.","8b9f393d":"Correlation between views and likes can help us to understand:\n* How many viewers liked the video\n* What are the reasons or what influences a person watching the video like it","b06d6b2c":"It's **impressive** that there are 0 null values except for the description column. This rarely happens in real-world cases. Most of the times the columns will contain a lot of null (NaN: Not a number) values and there are different methods to replace this NaN values with the mean or median depending upon the problem at hand. You can also get rid of these specific rows or columns where data is NaN.","7e689203":"Datasets usually have thousands of rows, someitmes millions and even billions of rows. To know how the data actually looks, we need not print all the rows but only few rows using the below command. In that way we also don't consume a lot of memory.","d4956e91":"The reason this is happening is that you are not assigning the obtained dataframe to the current dataframe (namely df). Only by doing this will you be able to update df.","728c970e":"Let's plot this data to understand the distribution of the data. Since the most important columns are likes, dislikes, views and comments, we will plot them first. A univariate distribution (single variable) will be plotted.","204ff464":"This means that our dataset has 40949 rows (records) and 16 features (columns or attributes)","3ae69f9d":"Let's see how to add and remove a column from a dataframe. To add a column, access the column like you normally do using [] and initialize it to a list or a specific value (None, NaN...). To remove a column, use df.drop(column_names, axis). Axis = 1 (removes the entire column), axis = 0 (removes the index)","1ea5b37d":"We can see that for few videos, likes increased faster than views (for a small increase in number of views, there is a large increase in number of likes). For videos, it's the other way around. It can be seen that, most of the data points are concentrated in the box where views are less than 50 million views and likes are less than a million likes.","cc9b644f":"The standard correlation used by Pandas is Pearson correlation. So, the values used by Pearson method and df.corr() method are so close.","c7706368":"Pandas is a very good library for analyzing our dataset. Pandas stores the data in a dataframe.","5ca8707f":"Now, all the 4 columns will be deleted. Check below"}}