{"cell_type":{"fc0b7614":"code","f9781d14":"code","61313fb0":"code","9d7db528":"code","b7e2a187":"code","eeb05a59":"code","010b0e09":"code","8ed71846":"code","4ece60dd":"code","14dc65af":"code","3f9a13bd":"code","3b9f68ef":"code","a4d786e1":"code","12ce78dd":"code","5658c6e2":"code","a52a07cd":"code","da58976d":"code","ca4b8ed1":"code","0d7e2005":"code","b16c5125":"code","abe17738":"code","ff058c1f":"code","8be79a12":"code","2a4a6b10":"code","963bf10e":"code","96317e15":"code","ebb6f009":"code","d3b2e1f0":"code","6fa48381":"code","72912038":"code","9b42fe0f":"code","e2012751":"code","40e92977":"code","55e7f152":"markdown","13e68b89":"markdown","e528cd6a":"markdown","5a64e54a":"markdown"},"source":{"fc0b7614":"# DATA_PATH = '..\/input\/'\nDATA_PATH = '..\/input\/shopee-product-matching\/'\n\nimport psutil","f9781d14":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport gc\nimport cupy\n\n# import cudf, cuml, cupy\n# from cuml.feature_extraction.text import TfidfVectorizer\n# from cuml.neighbors import NearestNeighbors\n\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score","61313fb0":"COMPUTE_CV = True\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n\n# COMPUTE_CV = False\n\nif COMPUTE_CV:\n    train = pd.read_csv(DATA_PATH + 'train.csv')\n    train['image'] = DATA_PATH + 'train_images\/' + train['image']\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    # train_gf = cudf.read_csv(DATA_PATH + 'train.csv')\nelse:\n    train = pd.read_csv(DATA_PATH + 'test.csv')\n    train['image'] = DATA_PATH + 'test_images\/' + train['image']\n    # train_gf = cudf.read_csv(DATA_PATH + 'test.csv')\n    \nprint('train shape is', train.shape )\ntrain.head()","9d7db528":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof_hash'] = train.image_phash.map(tmp)","b7e2a187":"train.head()","eeb05a59":"if COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_hash'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","010b0e09":"# train['title_word'] = train['title'].apply(lambda x: x.lower().split(' '))\n\n# from gensim.test.utils import get_tmpfile\n# from gensim.models import KeyedVectors\n\n# vectors = KeyedVectors.load_word2vec_format(\"..\/input\/glove2word2vec\/glove_w2v.txt\") # import the data file","8ed71846":"# title_feats = []\n# for title in tqdm(train['title_word'].values[:]):\n#     title_feat = []\n#     for word in title:\n#         if word in vectors:\n#             title_feat.append(vectors[word])\n#     if len(title_feat) == 0:\n#         title_feat = np.random.rand(200)\n#     else:\n#         title_feat = np.vstack(title_feat).max(0)\n#     title_feats.append(title_feat)\n#     # break\n    \n# del vectors;","4ece60dd":"# from sklearn.preprocessing import normalize\n\n# # l2 norm to kill all the sim in 0-1\n# title_feats = np.vstack(title_feats)\n# title_feats = normalize(title_feats)","14dc65af":"# import cupy\n\n# preds = []\n# CHUNK = 1024*4\n\n# title_feats = cupy.array(title_feats)\n\n# print('Finding similar images...')\n# CTS = len(title_feats)\/\/CHUNK\n# if len(title_feats)%CHUNK!=0: CTS += 1\n# for j in range( CTS ):\n    \n#     a = j*CHUNK\n#     b = (j+1)*CHUNK\n#     b = min(b, len(title_feats))\n#     print('chunk',a,'to',b)\n    \n#     distances = cupy.matmul(title_feats, title_feats[a:b].T).T\n#     # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n    \n#     for k in range(b-a):\n#         IDX = cupy.where(distances[k,]>0.90)[0]\n#         # IDX = np.where(distances[k,]>0.95)[0][:]\n#         o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n#         preds.append(o)\n        \n# # del imagefeat, imgmodel","3f9a13bd":"# train['oof_w2v'] = preds\n\n# if COMPUTE_CV:\n#     train['f1'] = train.apply(getMetric('oof_w2v'),axis=1)\n#     print('CV score for baseline =',train.f1.mean())","3b9f68ef":"from PIL import Image\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nclass ShopeeImageDataset(Dataset):\n    def __init__(self, img_path, transform):\n        self.img_path = img_path\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index]).convert('RGB')\n        img = self.transform(img)\n        return img\n    \n    def __len__(self):\n        return len(self.img_path)","a4d786e1":"imagedataset = ShopeeImageDataset(\n    train['image'].values,\n    transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]))\n    \nimageloader = torch.utils.data.DataLoader(\n    imagedataset,\n    batch_size=40, shuffle=False, num_workers=2\n)","12ce78dd":"class ShopeeImageEmbeddingNet(nn.Module):\n    def __init__(self):\n        super(ShopeeImageEmbeddingNet, self).__init__()\n              \n#         model = models.resnet18(True)\n        model = models.resnet50(True)\n        model.avgpool = nn.AdaptiveMaxPool2d(output_size=(1, 1))\n        model = nn.Sequential(*list(model.children())[:-1])\n        model.eval()\n        self.model = model\n        \n    def forward(self, img):\n        out = self.model(img)\n        return out","5658c6e2":"!mkdir -p \/root\/.cache\/torch\/hub\/checkpoints\/\n!cp ..\/input\/pretrained-pytorch-models\/resnet18-5c106cde.pth \/root\/.cache\/torch\/hub\/checkpoints\/\n!cp ..\/input\/pretrained-pytorch-models\/resnet50-19c8e357.pth \/root\/.cache\/torch\/hub\/checkpoints\/","a52a07cd":"DEVICE = 'cuda'\n\nimgmodel = ShopeeImageEmbeddingNet()\nimgmodel = imgmodel.to(DEVICE)\n\nimagefeat = []\nwith torch.no_grad():\n    for data in tqdm(imageloader):\n        data = data.to(DEVICE)\n        feat = imgmodel(data)\n        feat = feat.reshape(feat.shape[0], feat.shape[1])\n        feat = feat.data.cpu().numpy()\n        \n        imagefeat.append(feat)","da58976d":"from sklearn.preprocessing import normalize\n\n# l2 norm to kill all the sim in 0-1\nimagefeat = np.vstack(imagefeat)\nimagefeat = normalize(imagefeat)","ca4b8ed1":"imagefeat = torch.from_numpy(imagefeat)\nimagefeat = imagefeat.cuda()","0d7e2005":"# Thresshold tuning\n# preds_list = []\n# for thresshold in range(98, 90, -1):\n#     preds = []\n#     CHUNK = 1024*4\n\n\n# #     print('Finding similar images...')\n#     CTS = len(imagefeat)\/\/CHUNK\n#     if len(imagefeat)%CHUNK!=0: CTS += 1\n#     for j in range( CTS ):\n\n#         a = j*CHUNK\n#         b = (j+1)*CHUNK\n#         b = min(b, len(imagefeat))\n# #         print('chunk',a,'to',b)\n\n#         distances = torch.matmul(imagefeat, imagefeat[a:b].T).T\n#         distances = distances.data.cpu().numpy()\n#         # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n\n#         for k in range(b-a):\n#             # IDX = cupy.where(distances[k,]>0.95)[0]\n#             IDX = np.where(distances[k,]>thresshold\/100)[0][:]\n#             o = train.iloc[IDX].posting_id.values\n#     #         o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n#             preds.append(o)\n#     preds_list.append(preds)\n        \n# # del imagefeat, imgmodel","b16c5125":"# for thres, preds in zip(range(98, 90, -1), preds_list):\n#     train['oof_cnn'] = preds\n\n#     if COMPUTE_CV:\n#         train['f1'] = train.apply(getMetric('oof_cnn'),axis=1)\n#         print('Thresshold: ', thres\/100, 'CV score for baseline =',train.f1.mean())","abe17738":"preds = []\nCHUNK = 1024*4\n\n\nprint('Finding similar images...')\nCTS = len(imagefeat)\/\/CHUNK\nif len(imagefeat)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n\n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b, len(imagefeat))\n    print('chunk',a,'to',b)\n\n    distances = torch.matmul(imagefeat, imagefeat[a:b].T).T\n    distances = distances.data.cpu().numpy()\n    # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n\n    for k in range(b-a):\n        # IDX = cupy.where(distances[k,]>0.95)[0]\n        IDX = np.where(distances[k,]>0.95)[0][:]\n        o = train.iloc[IDX].posting_id.values\n        o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \n# del imagefeat, imgmodel","ff058c1f":"train['oof_cnn'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_cnn'),axis=1)\n    print('CV score for baseline =',train.f1.mean())\n    \n# 0.6527899883424048 0.95\n# 0.6686372611222741 0.94\n# 0.6762305764407363 0.93","8be79a12":"if COMPUTE_CV:\n    label_group_count = train.groupby(['label_group']).size().reset_index()\n    label_group_count.columns = ['label_group', 'count']\n    label_group_count.sort_values(by='count', ascending=False, inplace=True)\n    label_group_count","2a4a6b10":"if COMPUTE_CV:\n    t1 = train[train['label_group'] == 1163569239].index\n    t2 = train[train['label_group'] == 159351600].index\n\n    cts = torch.matmul(imagefeat[t1], imagefeat[t2].T).T\n    cts = cts.data.cpu().numpy()\n\n    # rows = 3\n    # cols = 4\n    # fig, cells = plt.subplots(nrows=rows, ncols=cols, figsize=(15, 10))\n    # i = 0\n    # for r in range(rows):\n    #     for c in range(cols):\n    #         cells[r, c].set_ylim([0, 10])\n    #         cells[r, c].hist(cts[i][np.where(cts[i] >= 0)], bins=20)\n    #         i += 1\n    # plt.show()\n\n    vs = []\n    for dist in cts:\n        vs.extend(dist)\n\n    plt.hist(vs, bins=50)\n    plt.show()","963bf10e":"from sklearn.feature_extraction.text import TfidfVectorizer\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=55000)\ntext_embeddings = model.fit_transform(train.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","96317e15":"text_embeddings = torch.from_numpy(text_embeddings)\ntext_embeddings = text_embeddings.cuda()","ebb6f009":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(train)\/\/CHUNK\nif len(train)%CHUNK!=0: CTS += 1\nCTS_index = 0\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(train))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n    cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n    cts = cts.data.cpu().numpy()\n    print(cts.shape)\n    for k in range(b-a):\n        # IDX = np.where(cts[k,]>0.7)[0]\n        IDX = np.where(cts[k,]>0.7)[0]\n        o = train.iloc[IDX].posting_id.values\n        preds.append(o)\n        CTS_index += 1\n        \n# del model, text_embeddings","d3b2e1f0":"train['oof_text'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_text'),axis=1)\n    print('CV score for baseline =',train.f1.mean())\n    \n    \n# 0.6137154152579091 0.7\n# 0.6507316994356058 0.6","6fa48381":"if COMPUTE_CV:\n    label_group_count = train.groupby(['label_group']).size().reset_index()\n    label_group_count.columns = ['label_group', 'count']\n    label_group_count.sort_values(by='count', ascending=False, inplace=True)\n    label_group_count","72912038":"def combine_for_sub(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return np.unique(x)","9b42fe0f":"if COMPUTE_CV:\n    t1 = train[train['label_group'] == 1163569239].index\n    t2 = train[train['label_group'] == 159351600].index\n\n    cts = torch.matmul(text_embeddings[t1], text_embeddings[t2].T).T\n    cts = cts.data.cpu().numpy()\n\n    # rows = 3\n    # cols = 4\n    # fig, cells = plt.subplots(nrows=rows, ncols=cols, figsize=(15, 10))\n    # i = 0\n    # for r in range(rows):\n    #     for c in range(cols):\n    #         cells[r, c].set_ylim([0, 10])\n    #         cells[r, c].hist(cts[i][np.where(cts[i] > 0)], bins=20)\n    #         i += 1\n    # plt.show()\n\n    vs = []\n    for dist in cts:\n        vs.extend(dist)\n\n    plt.hist(vs, bins=50)\n    plt.show()","e2012751":"if COMPUTE_CV:\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    train['f1'] = train.apply(getMetric('oof'),axis=1)\n    print('CV Score =', train.f1.mean() )\n\ntrain['matches'] = train.apply(combine_for_sub,axis=1)","40e92977":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","55e7f152":"# title TFIDF","13e68b89":"# image CNN","e528cd6a":"# text word2vec","5a64e54a":"# image hash"}}