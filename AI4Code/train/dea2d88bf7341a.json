{"cell_type":{"365e9a05":"code","5359d753":"code","110c9df0":"code","200f5433":"code","44315107":"code","441d7b06":"code","4b4460d4":"code","d8f06365":"code","3ac25910":"code","6df57e48":"code","e664c8cd":"code","370b5e4b":"code","c666a4e3":"code","b9fb9368":"code","f795b91d":"code","84a388e7":"code","7cdf8739":"code","815dbf85":"code","fef17d96":"code","f45809ce":"code","456aecb8":"code","5623ef8c":"code","e34f979b":"code","387a89fe":"code","338344f8":"code","894cf939":"code","865e9248":"code","6911ceae":"code","e2c2c234":"code","9914567e":"code","eb6add2c":"code","52778ec3":"code","3dd40d42":"code","2b62e055":"code","e453f3f7":"code","b71d2750":"code","d3d06f79":"code","07003c32":"code","4ae29eed":"code","0820dafb":"code","eff75059":"code","f73598f9":"code","770eb1f0":"code","7de39627":"code","09035fb3":"code","16e5800e":"code","10859d4f":"code","0dd8aa8c":"code","7eca0e2b":"code","d95e80af":"code","58d19061":"markdown","e6d966cb":"markdown","9fc94acb":"markdown","cc510859":"markdown","4f70a9e7":"markdown","efd37d38":"markdown","70546356":"markdown","d25e44ef":"markdown","a7688609":"markdown","8eaa9b28":"markdown","41d8a607":"markdown","f4260821":"markdown","0ec1a321":"markdown","7c6ba5e6":"markdown","6a316427":"markdown","dc17a102":"markdown","c4afb806":"markdown","07796e68":"markdown","bac4ad92":"markdown","addd2126":"markdown","98c19602":"markdown","1d06c670":"markdown","8c7f328f":"markdown","0ac7263b":"markdown","1ce80dbc":"markdown","dc3e4656":"markdown","a0b7ac77":"markdown","f467095c":"markdown","b7bd37a1":"markdown","cf73ded6":"markdown","383dcee4":"markdown","e2d19ea1":"markdown","695c9e04":"markdown","33e58abf":"markdown"},"source":{"365e9a05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5359d753":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n!pip install pmdarima\nimport pmdarima as pm\n\n%config InlineBackend.figure_format = 'retina'","110c9df0":"df = pd.read_csv('..\/input\/taipei-mrt-volume\/Taipei_MRT_volume.csv')\ndf['date'] = pd.to_datetime(df['date'])\ndf.set_index('date', inplace=True)\n\ndf","200f5433":"df.plot(y='volume', figsize=(15,4))","44315107":"# Resample by week\ndf.resample('W').mean().plot(y='volume', figsize=(15,4))","441d7b06":"# Resample by month\ndf.resample('M').mean().plot(y='volume', figsize=(15,4))","4b4460d4":"# Daily average volume counts\ndf.groupby('weekday').mean().volume.plot.bar(rot=0)","d8f06365":"# Make new feature: month\ndates = df.index\nmonths = [date.month for date in dates]\n\ndf['month'] = months\n\ndf","3ac25910":"# Monthly average volume counts\ndf.groupby('month').mean().plot.bar(y='volume', rot=0)","6df57e48":"# Split dataframe to pre and post covid19\nprecovid = df[:'2019']\npostcovid = df['2020':]\n\n# Create an axis\nfig, ax = plt.subplots()\n\n# Plot the train and test sets on the axis ax\nprecovid.plot(y='volume', figsize=(15,4), ax=ax, label='Pre-COVID19')\npostcovid.plot(y='volume', ax=ax, label='Post-COVID19')\nplt.show()","e664c8cd":"# Monthly average volume counts\nf, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\nprecovid.groupby('month').mean().plot.bar(y='volume', ax=ax1, title='Pre-COVID19', legend=False, ylabel='Average Volume', rot=0)\npostcovid.groupby('month').mean().plot.bar(y='volume', ax=ax2, title='Post-COVID19', color='orange', legend=False, ylabel='Average Volume', rot=0)","370b5e4b":"df.plot(y='volume', figsize=(15,4))\nplt.xlim(xmax=np.datetime64('2015-12-31'))\n\n# Lunar New Year\nplt.axvline(np.datetime64('2015-02-18'), c='k')\n\n# Dragon Boat festival holiday\nplt.axvline(np.datetime64('2015-06-19'), c='k')\n\n# Typhoon Chan-Hom\nplt.axvline(np.datetime64('2015-07-10'), c='k')\n\n# Typhoon Soudelor\nplt.axvline(np.datetime64('2015-08-08'), c='k')\n\n# Typhoon Dujuan public holiday\nplt.axvline(np.datetime64('2015-09-29'), c='k')","c666a4e3":"# Dicky-Fuller test for stationarity\nadf = adfuller(df.volume)\nprint('Test statistic:', adf[0])\nprint('p-value:', adf[1])\nprint('Critical values:', adf[4])\n\n# Accept H0, accept that data is non-stationary. Volume data is non-stationary","b9fb9368":"# Take first difference\ndf_diff = df.diff().dropna()\n\ndf_diff.volume.plot(figsize=(15,4))","f795b91d":"# Repeat test for differenced volume\nadf = adfuller(df_diff.volume)\nprint('Test statistic:', adf[0])\nprint('p-value:', adf[1])\nprint('Critical values:', adf[4])\n# Reject H0. So data is now stationary.","84a388e7":"# Plot ACF and PACF\nfig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,8))\n\nplot_acf(df_diff.volume, lags=15, zero=False, ax=ax1)\nplot_pacf(df_diff.volume, lags=15, zero=False, ax=ax2)\n\n# Show plot\nplt.show()\n# PACF tails off --> MA(2)","7cdf8739":"# Convert timestamps to period to suppress sarimax warning; set to daily\ndf2 = df.copy()\ndf2.index = pd.DatetimeIndex(df2.index).to_period('D')\n\n# To convert back from period to timestamp\n# df2.index = df2.index.to_timestamp()\n\ndf2.index","815dbf85":"# Create empty list to store search results\norder_aic_bic=[]\n\n# Loop over p values from 0-2\nfor p in range(3):\n  # Loop over q values from 0-2\n    for q in range(3):\n      \t# create and fit ARMA(p,q) model\n        model = ARIMA(df2['volume'], order=(p,1,q))\n        results = model.fit()\n        \n        # Append order and results tuple\n        order_aic_bic.append((p, q, results.aic, results.bic))\n\n# Construct DataFrame from order_aic_bic\norder_df = pd.DataFrame(order_aic_bic, \n                        columns=['p', 'q', 'AIC', 'BIC'])\n\n# Print order_df in order of increasing AIC\nprint(order_df.sort_values(by='AIC'))\n\n# Print order_df in order of increasing BIC\nprint(order_df.sort_values(by='BIC'))        ","fef17d96":"# Fitting\nmodel = ARIMA(df2['volume'], order=(2,1,2))\n\narima = model.fit()\n\nprint(arima.summary())","f45809ce":"# Make function to plot forecast result\ndef plot_forecast(forecast):\n    # Extract prediction mean\n    mean_forecast = forecast.predicted_mean\n\n    # Get confidence intervals of predictions\n    confidence_intervals = forecast.conf_int()\n\n    # Select lower and upper confidence limits\n    lower_limits = confidence_intervals.loc[:,'lower volume']\n    upper_limits = confidence_intervals.loc[:,'upper volume']\n\n    # Plot prediction\n    fig, ax = plt.subplots()\n\n    df2.plot(y='volume', figsize=(15,5), ax=ax)\n    mean_forecast.plot(ax=ax)\n    ax.fill_between(lower_limits.index, lower_limits, upper_limits, color='pink')\n\n    ax.set_ylabel('Volume')\n    ax.set_xlim(xmin=np.datetime64('2020-01-01'))  \n    \n    return mean_forecast # dataframe of forecast","456aecb8":"# In sample prediction started days before end\nforecast = arima.get_prediction(start=-210)\n\nfc_df = plot_forecast(forecast)","5623ef8c":"# The next 60 days forecast\nforecast = arima.get_forecast(steps=60)\n\nfc_df = plot_forecast(forecast)","e34f979b":"# Print forecasted dataframe\nfc_df","387a89fe":"# Model diagnostics plot\n# NOTE: by default, statsmodels plot is too small. So, I add mpl.rc_context() to resize figures.\n\nwith mpl.rc_context():\n    mpl.rc(\"figure\", figsize=(8,5))\n    # Statsmodels diagnostics plot\n    arima.plot_diagnostics()\nplt.tight_layout()\nplt.show()","338344f8":"# Calculate the mean absolute error from residuals\nmae = np.mean(np.abs(arima.resid))\n\n# Print mean absolute error\nprint(mae)","894cf939":"\nnp.random.seed(42)\n\n# Set coefficients\nar_coefs = [1, -0.41, 0.22]\nma_coefs = [1, -0.88]\n\n# Generate data\ny = arma_generate_sample(ar_coefs, ma_coefs, nsample=100, scale=0.5)\n\nplt.plot(y)\nplt.ylabel(r'$y_t$')\nplt.xlabel(r'$t$')\nplt.show()","865e9248":"df.volume.plot(figsize=(15,4), style='.-')\nplt.xlim(xmax=np.datetime64('2015-03-01'))","6911ceae":"# Plot ACF and PACF\nfig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,8))\n\nplot_acf(df_diff.volume, lags=25, zero=False, ax=ax1)\nplot_pacf(df_diff.volume, lags=25, zero=False, ax=ax2)\n\n# Show plot\nplt.show()","e2c2c234":"# Perform additive decomposition\ndecomp = seasonal_decompose(df['volume'], period=7)\n\n# Plot decomposition\nwith mpl.rc_context():\n    mpl.rc(\"figure\", figsize=(15,8))\n    decomp.plot()","9914567e":"# Take difference by period=7 to convert to seasonal\ndf_diff_seasonal = df2.diff().diff(7).dropna()\n\ndf_diff_seasonal","eb6add2c":"df.plot(y='volume', figsize=(15,4), title='Original Dataset')\nplt.xlim(xmax=np.datetime64('2016-01-01'))\n\ndf_diff.plot(y='volume', figsize=(15,4), title='1st Order Differenced')\nplt.xlim(xmax=np.datetime64('2016-01-01'))\n\ndf_diff_seasonal.plot(y='volume', figsize=(15,4), title='Differenced for Seasonality')\nplt.xlim(xmax=np.datetime64('2016-01-01'))","52778ec3":"# Lags\nlags = np.arange(1, 7) # 7 is period\nlags = lags * 7\n\n# Create the figure \nfig, (ax1, ax2) = plt.subplots(2,1,figsize=(10,8))\n\n# Plot the ACF on ax1\nplot_acf(df_diff_seasonal.volume, lags=lags, zero=False, ax=ax1)\n\n# Plot the PACF on ax2\nplot_pacf(df_diff_seasonal.volume, lags=lags, zero=False, ax=ax2)\n\nplt.show()","3dd40d42":"# Automate SARIMA(p,d,q)(P,D,Q,S) searching\n# Period, S=7\n# First-order differencing, d=1, D_seasonal=1\n# Initial guesses p,q,P,Q=1\nmodel = pm.auto_arima(df.volume,\n                      seasonal=True, m=7,\n                      d=1, D=1, \n                      start_p=1, start_q=1,\n                      max_p=1, max_q=1,\n                      max_P=1, max_Q=1,\n                      trace=True,\n                      error_action='ignore',\n                      suppress_warnings=True) \n\n# Print model summary\nprint(model.summary())","2b62e055":"# Create a SARIMAX model\nmodel = SARIMAX(df2.volume, order=(0,1,1), seasonal_order=(1,1,0,7))\n\n# Fit the model\nsarima = model.fit()\n\n# Print the results summary\nprint(sarima.summary())","e453f3f7":"# In sample prediction started days before end\nforecast = sarima.get_prediction(start=-210)\n\nfc_df = plot_forecast(forecast)\nplt.ylim(0,3e6)","b71d2750":"# The next 60 days forecast\nforecast = sarima.get_forecast(steps=60)\n\nfc_df = plot_forecast(forecast)\nplt.ylim(0,3e6)","d3d06f79":"# Model diagnostics plot\n# NOTE: by default, statsmodels plot is too small. So, I add mpl.rc_context() to resize figures.\n\nwith mpl.rc_context():\n    mpl.rc(\"figure\", figsize=(8,5))\n    # Statsmodels diagnostics plot\n    sarima.plot_diagnostics()\nplt.tight_layout()\nplt.show()","07003c32":"# Calculate the mean absolute error from residuals\nmae = np.mean(np.abs(sarima.resid))\n\n# Print mean absolute error\nprint(mae)","4ae29eed":"# COVID data\n!wget https:\/\/raw.githubusercontent.com\/yohanesnuwara\/datasets\/master\/Taiwan_Covid_Data.csv","0820dafb":"# Read covid data\ncovid = pd.read_csv('.\/Taiwan_Covid_Data.csv')\ncovid = covid[['date', 'new_cases']]\ncovid = covid.fillna(0)\n\n# Make zeros from MRT start date to covid start date\nstart_date = np.datetime64('2015-01-01')\nend_date = np.datetime64('2020-01-16')\nd = np.arange(start_date, end_date)\nc = np.full(len(d), 0)\n\n# Into new dataframe\nzero_covid = pd.DataFrame({'date': d, 'new_cases': c})\ncovid = pd.concat((zero_covid, covid), axis=0)\n\n# Convert date column to index\ncovid['date'] = pd.to_datetime(covid['date'])\ncovid.set_index('date', inplace=True)\n\n# Make exog covid data: only until the end date of MRT date\ncovid = covid[:'2021-07-31']\n\n# Convert index timestamp to period\ncovid.index = pd.DatetimeIndex(covid.index).to_period('D')\n\ncovid.plot(figsize=(15,4))\nplt.xlim(xmin=np.datetime64('2020-01-01'))","eff75059":"# Create a SARIMAX model with covid data as exogeneous input\nmodel = SARIMAX(df2.volume, order=(0,1,1), seasonal_order=(1,1,0,7), exog=covid.new_cases)\n\n# Fit the model\nsarimax = model.fit()\n\n# Print the results summary\nprint(sarimax.summary())","f73598f9":"# In sample prediction started days before end\nforecast = sarimax.get_prediction(start=-210)\n\nfc_df = plot_forecast(forecast)\nplt.ylim(0,3e6)","770eb1f0":"# Calculate the mean absolute error from residuals\nmae = np.mean(np.abs(sarimax.resid))\n\n# Print mean absolute error\nprint(mae)","7de39627":"# Calculate MAE of different models we built\nmaes = [np.mean(np.abs(model.resid)) for model in [arima, sarima, sarimax]]\n\nmaes = pd.DataFrame({'Model': ['ARIMA', 'SARIMA', 'SARIMAX'],\n                     'MAE': maes})\n\nmaes","09035fb3":"plt.rcParams['font.size'] = 15\nfig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10,9))\n\n# Plot Passengers data\ndf2.plot(y='volume', ax=ax1, label='Data')\n\nmodels = [arima, sarimax]\nmodels_name = ['ARIMA(2,1,2)', 'SARIMAX(0,1,1)(1,1,0)7']\ncolors = ['red', 'orange']\n\nfor i in range(len([arima, sarima])):\n    # n days before end forecasting\n    forecast = models[i].get_prediction(start=-210)\n\n    # Extract prediction mean\n    mean_forecast = forecast.predicted_mean\n\n    # Get confidence intervals of predictions\n    confidence_intervals = forecast.conf_int()\n\n    # Select lower and upper confidence limits\n    lower_limits = confidence_intervals.loc[:,'lower volume']\n    upper_limits = confidence_intervals.loc[:,'upper volume']\n    \n    # Plot forecast\n    ax1.plot(mean_forecast.index, mean_forecast, label=models_name[i])\n\nax1.set_title('Taipei MRT Passengers Forecasting', size=20)\nax1.set_xlim(xmin=np.datetime64('2020-01-01'))\nax1.set_ylim(ymin=0)\nax1.set_xlabel('Date'); ax1.set_ylabel('Volume')\nax1.set_ylabel('Volume')\nax1.fill_between(lower_limits.index, lower_limits, upper_limits, color='pink')\n\n# Plot holidays\nax1.axvline(np.datetime64('2020-01-23'), color='r', ls='--', label='Chinese New Years')\nax1.axvline(np.datetime64('2021-02-10'), color='r', ls='--')\nax1.legend(fontsize=12, loc='lower center')\nax1.grid()\n\n# Plot COVID data\ncovid.plot(ax=ax2, color='r')\nax2.set_title('COVID19 Cases in Taiwan', size=20)\nax2.set_xlim(xmin=np.datetime64('2020-01-01'))\nax2.set_xlabel('Date'); ax2.set_ylabel('New Cases')\nax2.grid()\n\nplt.tight_layout()","16e5800e":"# df_shock = df.copy()\n# df_shock['volume_1'] = df_shock.volume.shift(1)\n# # df_shock = df_shock.dropna()\n# df_shock['log_shock'] = np.log(df_shock.volume \/ df_shock.volume_1)\n\n# df_shock.plot(y='log_shock', figsize=(15,4))\n# # plt.xlim(xmax=np.datetime64('2016-01-01'))\n# plt.xlim(xmin=np.datetime64('2021-01-01'))","10859d4f":"# df.diff().dropna().plot(y='volume', figsize=(15,4))\n# plt.xlim(xmax=np.datetime64('2016-01-01'))","0dd8aa8c":"# df_shock = df_shock.dropna()\n\n# df_shock","7eca0e2b":"# # Create figure and subplot\n# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8))\n\n# # Plot the ACF and PACF\n# plot_acf(df_shock['log_shock'], lags=15, zero=False,  ax=ax1)\n# plot_pacf(df_shock['log_shock'], lags=15, zero=False,  ax=ax2)\n\n# # Show figure\n# plt.show()","d95e80af":"# def shock_to_real(s, y_1):\n#     c = np.exp(1)**s\n#     y = y_1 * c\n#     return y\n\n# shock = np.linspace(1, 0.5, 30)\n# shock = shock * n\n\n# l = 1e6\n# L = []\n# for i in range(1, len(shock)):\n#     L.append(l)\n#     l = shock_to_real(shock[i-1], l)\n\n# plt.plot(L)","58d19061":"Our prediction gets better!","e6d966cb":"Based on the result above, MA coefficient is -0.50 and seasonal AR coefficient is 0.49 with period 7. The SARIMA formula as follows:\n\n$$y_t=-0.50\\epsilon_{t-1}+0.49y_{t-7}+c$$","9fc94acb":"# Prediction of Volume of MRT Train Passengers in Taipei using ARIMA","cc510859":"From the ACF-PACF plots above:\n* ACF cuts off at lag 1\n* PACF tails off\n\nSo this could be **SARIMA(p,d,q)(1,1,0)7**.","4f70a9e7":"We have improved our model A LOT using SARIMA. **Can we get better by including an exogeneous feature??** Including exogenous feature will make a SARIMAX model.\n\nThe most impactful factor that changes the time series behavior of passengers is COVID-19. Therefore, we will try to include another time series data of COVID-19 data as an exog features. The global COVID-19 data is publicly available [here](https:\/\/ourworldindata.org\/coronavirus\/country\/taiwan). Example of Taiwanese COVID cases can be retrieved from my GitHub repository. ","efd37d38":"I am curious to find out the drop of passengers through out a year. Take 2015.","70546356":"Based on the result above, AR coefficients are (-0.22, 0.14) and MA coefficients are (-0.68, -0.19). The ARMA formula as follows:\n\n$$y_t=-0.22y_{t-1}+0.14y_{t-2}-0.68\\epsilon_{t-1}-0.19\\epsilon_{t-2}+c$$","d25e44ef":"We will automate the process of searching the best model by the lowest AIC and BIC.","a7688609":"From the ACF-PACF plots above, it clearly shows large correlation at every 7-th lag. So, the period is 7.","8eaa9b28":"We have taken difference once to make the data stationary, therefore our ARIMA model will be **ARIMA(p,1,q)**.","41d8a607":"There are peaks of MRT passengers on every end of the years, in December.","f4260821":"# 3. Test for stationarity","0ec1a321":"Two models clearly competes; ARIMA(2,1,2) has the lowest AIC, and ARIMA(0,1,2) has the lowest BIC. We will choose the first model with the lowest AIC. ","7c6ba5e6":"# 5. ARIMA + Seasonality Forecasting","6a316427":"# 2. Time series analysis","dc17a102":"# 1. Read data","c4afb806":"Let's compare average of passengers volume before and after COVID-19 to see how passengers behavior change. ","07796e68":"Based on the result above, MA coefficient is -0.50 and seasonal AR coefficient is 0.49 with period 7. Coefficient for exogenous feature is -59.17. The SARIMA formula as follows:\n\n$$y_t=-0.50\\epsilon_{t-1}+0.49y_{t-7}-59.17z_t+c$$","bac4ad92":"From the plots above: \n\n* PACF tails off\n* ACF cuts off at lag 2\n\nWe are not certain whether it's purely an MA model {**ARIMA(0,1,2)**} **or** ARMA model {**ARIMA(p,0,2)**} with p still unknown.","addd2126":"We don't get a significant improvement with exog feature, but at least, the model improves. Here are the MAE results of our models.","98c19602":"We have seen that ARIMA alone cannot capture well the time series behavior. We will add seasonal effect to make SARIMA model. \n\nWe can see the passengers cycle at every 7 days, or weekly.","1d06c670":"# 6. ARIMA + Seasonality + Exogenous Forecasting","8c7f328f":"![image](https:\/\/user-images.githubusercontent.com\/51282928\/143527762-d77ca105-6a33-4cbf-a7c0-b760b738c081.png)","0ac7263b":"# 8. Conclusion","1ce80dbc":"# 4. ARIMA Forecasting","dc3e4656":"# 7. Final plot","a0b7ac77":"The drop of passengers correlate very well with holidays and catastrophic events such as typhoon. In Taiwan, offices and schools are closed during typhoon.","f467095c":"The volume of MRT passengers peak on Friday.","b7bd37a1":"Volume of passengers is the highest on January and December, and the lowest on June. This is probably due to typhoon that often strikes on the mid of year.","cf73ded6":"We could see there is a significant drop of passengers in early 2020 and mid 2021. It is clear that the possible cause is the increasing new cases of COVID-19.","383dcee4":"We analyzed the data of MRT passengers in Taipei from 2015 to mid 2021. Every week, the passengers peak on Friday, before entering the weekends. Over the year, January and December have the largest passengers. Holidays, such as Chinese New Year in January\/February, and typhoon in mid of the year, causes the number of passengers to drop. In general, there is a break of passengers started from 2020, due to COVID-19. When new COVID-19 cases explodes, such as in April 2021, the number of passengers significantly drop. \n\nAfter stationary test, we observed that first-order differencing will make the time series stationary. Then, we made 3 predictive models to forecast MRT passengers in the next 60 days. \n\nStarted from an ARIMA(2,1,2) model, we achieved MAE of 197,236 people. Then, we improved the model to include the seasonal effect. We observed that number of passengers cycle weekly, with period of 7. We made SARIMA(0,1,1)(1,1,0) and successfully improves the predictive performance to an MAE of 129,973 people. Finally, we tried to include Taiwanese COVID-19 data as an exogeneous feature to make a SARIMAX model. It still improves the performance, but very slightly.\n\nFurther improvement of this work can be transforming time series into stationary by **calculating log return instead of differencing** and **applying other forecasting models such as Prophet.**\n\n**Thank you!**","e2d19ea1":"From the searching above, the best model is $SARIMA \\space (0,1,1)(1,1,0)_7$.","695c9e04":"Let's automate the process of searching the best parameters for the SARIMA model.","33e58abf":"Given is historical data of volume of MRT passengers in Taipei from 2015 to mid 2021. "}}