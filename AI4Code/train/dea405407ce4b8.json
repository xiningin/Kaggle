{"cell_type":{"df649218":"code","b203a08a":"code","6730cf80":"code","3e47caa0":"code","b1a35aa7":"code","87d26bff":"code","6fdfefe1":"code","68caf673":"code","656a3d8f":"code","b36d50f6":"code","26b90346":"code","63ccf7cf":"code","235d4f25":"code","aec86cca":"code","93400759":"code","231daa34":"code","b0f50228":"code","f2e1894f":"code","3f16619b":"code","18524574":"code","60ab174f":"code","3c9cc174":"code","182524bc":"code","b6fa8b6c":"code","3f8fa605":"code","d7bedf24":"code","2771be35":"code","d0d8851b":"code","4f0ecd2e":"code","b3f4ede2":"code","f9a7e00a":"code","3ad57eaa":"code","98ecd7c6":"code","f9d716c7":"code","9cb14c6d":"code","b4fcd170":"code","8acc902a":"code","346d4964":"code","a49abc0e":"markdown","e0dc8c82":"markdown","b774cb9e":"markdown","b7345548":"markdown","a9770a48":"markdown","0056f156":"markdown","892b8690":"markdown","b87f5506":"markdown","9e40fb77":"markdown","e63cd534":"markdown"},"source":{"df649218":"import numpy as np\nimport pandas as pd","b203a08a":"re = pd.read_csv('..\/input\/RE.csv')","6730cf80":"re.head()","3e47caa0":"re.shape","b1a35aa7":"re.columns","87d26bff":"re1 = re.drop(['No', 'X1 transaction date'],1)","6fdfefe1":"re1.head()","68caf673":"re1.isnull().sum()","656a3d8f":"re1.info()","b36d50f6":"re1.describe()","26b90346":"re1['X4 number of convenience stores'].unique()","63ccf7cf":"re1.skew()","235d4f25":"re1.kurt()","aec86cca":"print(np.median(re1['X2 house age']))\nprint(np.median(re1['X3 distance to the nearest MRT station']))\nprint(np.median(re1['X4 number of convenience stores']))\nprint(np.median(re1['X5 latitude']))\nprint(np.median(re1['X6 longitude']))\nprint(np.median(re1['Y house price of unit area']))","93400759":"np.mean(re1)","231daa34":"import seaborn as sns\nsns.pairplot(re1, diag_kind = 'kde')","b0f50228":"X = re1.drop('Y house price of unit area',1)\ny = re1['Y house price of unit area']","f2e1894f":"from sklearn.model_selection import train_test_split","3f16619b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100) ","18524574":"from sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","60ab174f":"from sklearn.preprocessing import StandardScaler","3c9cc174":"sc = StandardScaler()","182524bc":"X_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","b6fa8b6c":"from sklearn.model_selection import KFold\nkfold = KFold(n_splits=10, random_state = 100)","3f8fa605":"dt = DecisionTreeRegressor(max_depth = 4, random_state = 100)\nbr = BaggingRegressor(base_estimator = dt, n_estimators = 100, random_state = 100)","d7bedf24":"rf = RandomForestRegressor()\nbr_fit = br.fit(X_train,y_train)","2771be35":"br_fit","d0d8851b":"br1 = BaggingRegressor(base_estimator = rf, random_state = 100)","4f0ecd2e":"br1_fit = br1.fit(X_train, y_train)","b3f4ede2":"y_pred = br_fit.predict(X_test) #decision tree","f9a7e00a":"y_pred = br1_fit.predict(X_test)#random forest","3ad57eaa":"# DECISION TREE BASE ESTIMATOR","98ecd7c6":"print(br.score(X_train,y_train)) ","f9d716c7":"print(br.score(X_test,y_test))","9cb14c6d":"# RANDOM FOREST BASE ESTIMATOR","b4fcd170":"print(br1.score(X_train,y_train))\nprint(br1.score(X_test,y_test))","8acc902a":"# USING KFOLD\nfrom sklearn.model_selection import cross_val_score\nres_br=cross_val_score(br,X_train,y_train.ravel(),cv=kfold)\nprint(np.mean(res_br))","346d4964":"from sklearn.model_selection import cross_val_score\nres_br1=cross_val_score(br1,X_train,y_train.ravel(),cv=kfold)\nprint(np.mean(res_br1))","a49abc0e":"5.\tPredict the model with test dataset","e0dc8c82":"The pair plot clearly explains the measure of skewness and the measure of peakedness of each of the features.\n\nKurtosis > 3 is said to be platykurtic. Here only the distance from the metro station is said to be platykuric and rest all are leptokurtic.","b774cb9e":"Kurtosis > 3 is said to be platykurtic. Here only the distance from the metro station is said to be platykuric and rest all are leptokurtic.","b7345548":"2.\tSplit the input data into dependent and independent variables","a9770a48":"In all the cases except for latitude and longitude median < mean hence the data is positively skewed.","0056f156":"4.\tApply Bagging classifier and train the model","892b8690":"6.","b87f5506":"Bagging classifier cannot be applied as the target variable is continuous. So bagging regressor is applied.","9e40fb77":"INFERENCES:\n\nThe accuracy for bagging regressor with Random forest as the base estimator is more than that with the decision tree.\nEven on applying kfold cross validation regressor with random forest as the base estimator shows high accuracy which indicates that random forest handles most of the problems like overfitting, bias and variance errors more effectively and efficiently when compared to that of a decision tree","e63cd534":"3.\tData split into test and train (70, 30 ratio)"}}