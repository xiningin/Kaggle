{"cell_type":{"fbb40457":"code","8767e191":"code","df4993c4":"code","8b7e8928":"code","550bfeaf":"code","f8d674ed":"code","efe69091":"code","ccbe51da":"code","6d20b869":"code","52dcac13":"code","191cd1af":"code","d915abc6":"code","ca339055":"code","02bc3803":"code","5950eecf":"code","44593641":"code","b389c987":"code","0a9c3ca9":"code","46060885":"code","77611003":"code","1c9f585e":"code","823bae6d":"code","e5955f55":"code","77917e26":"code","fe457014":"code","c4820c24":"code","4020f9bc":"code","a48fed28":"code","083625d3":"code","45994cc8":"code","5f633fc7":"code","24c281bc":"markdown","d2655c70":"markdown","201d0e20":"markdown","470dcdb5":"markdown","01949a1d":"markdown"},"source":{"fbb40457":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8767e191":"data = pd.read_csv('..\/input\/StudentsPerformance.csv')","df4993c4":"data.info()","8b7e8928":"#Renaming Columns\ndata.columns = ['gender', 'race', 'parentDegree', 'lunch', 'course', 'mathScore', 'readingScore', 'writingScore']","550bfeaf":"data.isna().sum()\n#No hay valores nulos","f8d674ed":"#Visualizamos los 10 primeros elementos\ndata.head(10)","efe69091":"#Calculamos m\u00ednmos y m\u00e1ximos para cada cosa\n\nprint('Maxima puntuaci\u00f3n en matem\u00e1ticas: ',max(data['mathScore']))\nprint('M\u00ednima puntuaci\u00f3n en matem\u00e1ticas: ',min(data['mathScore']))\nprint('Maxima puntuaci\u00f3n en lectura: ',max(data['readingScore']))\nprint('M\u00ednima puntuaci\u00f3n en lectura: ',min(data['readingScore']))\nprint('Maxima puntuaci\u00f3n en escritura: ',max(data['writingScore']))\nprint('M\u00ednima puntuaci\u00f3n en escritura: ',min(data['writingScore']))","ccbe51da":"#Calculamos el n\u00famero de estudiantes que han lagrado m\u00e1ximos\nprint('N\u00famero de estudiantes que han sacado la m\u00e1xima puntaci\u00f3n en matem\u00e1ticas: ', len(data[data['mathScore'] == 100]))\nprint('N\u00famero de estudiantes que han sacado la m\u00e1xima puntaci\u00f3n en lectura: ', len(data[data['readingScore'] == 100]))\nprint('N\u00famero de estudiantes que han sacado la m\u00e1xima puntaci\u00f3n en escritura: ', len(data[data['writingScore'] == 100]))","6d20b869":"#Estudiantes que han logrado lo m\u00e1ximo en las tres categor\u00edas\n\nperfect_writing = data['writingScore'] == 100\nperfect_reading = data['readingScore'] == 100\nperfect_math = data['mathScore'] == 100\n\nperfect_score = data[(perfect_math) & (perfect_reading) & (perfect_writing)]\nperfect_score","52dcac13":"print('N\u00famero de estudiantes que han sacado la m\u00e1xima puntaci\u00f3n en las tres \u00e1reas: ',len(perfect_score))","191cd1af":"#Numero de estudiantes que ha sacado el menor valor en las tres categor\u00edas\nminimum_math = data['mathScore'] == 0\nminimum_reading = data['readingScore'] == 17\nminimum_writing = data['writingScore'] == 10\n\n\n\nminimum_score = data[(minimum_math) & (minimum_reading) & (minimum_writing)]\nminimum_score","d915abc6":"print('N\u00famero de estudiantes que han sacado la m\u00ednima puntaci\u00f3n en las tres \u00e1reas: ', len(minimum_score))","ca339055":"#Agrupamos por raza y grado de estudios\ndata.groupby(['race','parentDegree']).mean()\n","02bc3803":"#Analizamos la media por g\u00e9nero\ndata.groupby(['gender']).mean()\n\n\n\n#Parece que las chicas son mejores que los chicos ...","5950eecf":"data.corr()\n#Hay una fuerte correlaci\u00f3n entre readingScore & writingScore, readingScore & mathScore and writingScore & mathScore","44593641":"f,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","b389c987":"data.describe()","0a9c3ca9":"sns.set_style('darkgrid')\n\nsns.pairplot(data, hue = 'gender')\nplt.show()\n\n","46060885":"\n\n\ncolor_list = ['red' if i=='female' else 'yellow' for i in data.loc[:,'gender']]\npd.plotting.scatter_matrix(data.loc[:, data.columns != 'gender'],\n                                       c=color_list,\n                                       figsize= [15,15],\n                                       diagonal='hist',\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = '*',\n                                       edgecolor= \"black\")\nplt.show()","77611003":"#Procentaje de chicos y de chicas\n\nsns.countplot(x=\"gender\", data=data)\ndata['gender'].value_counts()","1c9f585e":"\n\nplt.figure(figsize=(10,4))\n\nplt.subplot(1,3,1)\nsns.barplot(x = 'gender', y = 'readingScore', data = data)\n\nplt.subplot(1,3,2)\nsns.barplot(x = 'gender', y = 'writingScore', data = data)\n\nplt.subplot(1,3,3)\nsns.barplot(x = 'gender', y = 'mathScore', data = data)\n\nplt.tight_layout()\n\n\n#Parace que a los chicos se les da mejor las matem\u00e1ticas y a las chicas mejoran en lectura y en escritura","823bae6d":"plt.figure(figsize=(14,4))\n\nplt.subplot(1,3,1)\nsns.barplot(x = 'race', y = 'readingScore', data = data)\nplt.xticks(rotation = 90)\n\nplt.subplot(1,3,2)\nsns.barplot(x = 'race', y = 'writingScore', data = data)\nplt.xticks(rotation = 90)\n\nplt.subplot(1,3,3)\nsns.barplot(x = 'race', y = 'mathScore', data = data)\nplt.xticks(rotation = 90)\n\nplt.tight_layout()\n","e5955f55":"data.parentDegree.unique()","77917e26":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nx = data.drop(['race', 'parentDegree', 'lunch', 'course', 'gender'], axis=1)\ny= data['gender']\nknn.fit(x,y)\nprediction = knn.predict(x)\nprint('Predicci\u00f3n: {}'.format(prediction))","fe457014":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42)\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\nprint('La precisi\u00f3n de nuestro modelo es: ',knn.score(x_test,y_test))","c4820c24":"rg = np.arange(1, 25)\ntrain_accuracy = []\ntest_accuracy = []\nfor i, k in enumerate(rg):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train,y_train)\n    train_accuracy.append(knn.score(x_train, y_train))\n    test_accuracy.append(knn.score(x_test, y_test))\n\nplt.figure(figsize=[13,8])\nplt.plot(rg, test_accuracy, label = 'Precisi\u00f1on de test')\nplt.plot(rg, train_accuracy, label = 'Precisi\u00f3n de entrenamiento')\nplt.legend()\nplt.title('K VS Precisi\u00f3n')\nplt.xlabel('K')\nplt.ylabel('Precisi\u00f3n')\nplt.xticks(rg)\nplt.show()\nprint(\"La mejor precisi\u00f3n que podemos obtener es {} con K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))","4020f9bc":"data1 = data[data['race'] =='group A']\nx = np.array(data1.loc[:,'readingScore']).reshape(-1,1)\ny = np.array(data1.loc[:,'writingScore']).reshape(-1,1)\n# Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x=x,y=y)\nplt.xlabel('readingScore')\nplt.ylabel('writingScore')\nplt.show()","a48fed28":"from sklearn.linear_model import LinearRegression\nreg = LinearRegression()\n\npredict_space = np.linspace(min(x), max(x)).reshape(-1,1)\nreg.fit(x,y)\npredicted = reg.predict(predict_space)\nprint('R^2 score: ',reg.score(x, y))\n\nplt.plot(predict_space, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('readingScore')\nplt.ylabel('writingScore')\nplt.show()","083625d3":"from sklearn.metrics import roc_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ndata['race_binary'] = [1 if i == 'group E' else 0 for i in data.loc[:,'race']]\nx,y = data.loc[:,(data.columns != 'race') & (data.columns != 'race_binary')], data.loc[:,'race_binary']\nx = x.drop(['gender', 'parentDegree', 'lunch', 'course'], axis=1)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=42)\nlogreg = LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred_prob = logreg.predict_proba(x_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('Falsos positivos')\nplt.ylabel('Verdaderos positivos')\nplt.title('ROC')\nplt.show()","45994cc8":"from sklearn.model_selection import GridSearchCV\ngrid = {'n_neighbors': np.arange(1,50)}\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, grid, cv=3)\nknn_cv.fit(x,y)\n\n# Print hyperparameter\nprint(\"Hiperpar\u00e1metro K ajustado: {}\".format(knn_cv.best_params_)) \nprint(\"Mejor puntuaci\u00f3n: {}\".format(knn_cv.best_score_))","5f633fc7":"rg = np.arange(1, 25)\ntrain_accuracy = []\ntest_accuracy = []\nfor i, k in enumerate(rg):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train,y_train)\n    train_accuracy.append(knn.score(x_train, y_train))\n    test_accuracy.append(knn.score(x_test, y_test))\n\nplt.figure(figsize=[13,8])\nplt.plot(rg, test_accuracy, label = 'Precisi\u00f1on de test')\nplt.plot(rg, train_accuracy, label = 'Precisi\u00f3n de entrenamiento')\nplt.legend()\nplt.title('K VS Precisi\u00f3n')\nplt.xlabel('K')\nplt.ylabel('Precisi\u00f3n')\nplt.xticks(rg)\nplt.show()\nprint(\"La mejor precisi\u00f3n que podemos obtener es {} con K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))","24c281bc":"Mostramos la correlaci\u00f3n de columnas","d2655c70":"Cambiamos el nombre a las columnas para estandarizar:","201d0e20":"********","470dcdb5":"Buscamos si hay valores nulos","01949a1d":"La gr\u00e1fica anterior est\u00e1 fatal!, no vamos a sacar mucho ya que lo valores de la l\u00ednea azul deber\u00eda aproximarse a uno y hacer como una L invertida."}}