{"cell_type":{"a7b2cd19":"code","d7f9ac61":"code","5a3dbc1d":"code","4ff72e95":"code","973fa41b":"code","2cbb38c9":"code","55c141be":"code","41f9e59b":"code","12c720ee":"code","0db427bf":"code","a0c2ed02":"code","abc9e506":"code","dc91f63e":"code","5739a687":"code","0310986c":"code","cda23b02":"code","8f54521e":"code","c1b2c4c5":"code","cdff6c92":"code","30b25341":"code","2842dd2d":"code","1d52cb47":"code","e3a9ce7f":"code","1b6531b2":"code","f4824bd3":"code","f68f0ecd":"code","3196602c":"code","5aaf2dca":"code","843a8c4b":"code","0d0a033f":"code","a7ae6e46":"code","24ade778":"code","c6f529e1":"code","87a3f910":"markdown","937fac8c":"markdown","55e81963":"markdown","a2ae1b29":"markdown","a7d0c4df":"markdown","0af3af1c":"markdown"},"source":{"a7b2cd19":"#THIS CONTAINS THE CODE FOR THE BEST SUBMISSION","d7f9ac61":" import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport math\nimport copy\nfrom scipy import stats as stat\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport random\nfrom sklearn.linear_model import LogisticRegression\n\nrandom.seed(32)\nnp.random.seed(36)\n","5a3dbc1d":"data_train = pd.read_csv(\"..\/input\/data-mining-assignment-2\/train.csv\", sep=',')\ndata_test = pd.read_csv(\"..\/input\/data-mining-assignment-2\/test.csv\", sep=',')\n\ndata_train.head()","4ff72e95":"corr = data_train.corr()\ncorr\ngraph ,axis= plt.subplots()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\nsquare=True, ax=axis, annot = False)","973fa41b":"print(data_train[data_train.columns[0:]].corr()['Class'][:].sort_values(ascending=False)[:15])\nprint(data_train[data_train.columns[0:]].corr()['Class'][:].sort_values(ascending=True)[:15])","2cbb38c9":"data_train.drop(['Class'],axis=1).hist(figsize=(20,20))","55c141be":"data_test.hist(figsize=(20,20))","41f9e59b":"data_train.describe()","12c720ee":"data_test.describe()","0db427bf":"#Remove outliers\nindexNames = data_train[ (data_train['ID'] == 478) | (data_train['ID'] == 594) | (data_train['ID'] == 288) ].index\ndata_train = data_train.drop(indexNames)","a0c2ed02":"data_train=data_train.drop(['col5','col6','col19','col30','col46','col60','col59'],axis=1)\ndata_test=data_test.drop(['col5','col6','col19','col30','col46','col60','col59'],axis=1)\n\ndata_train[\"col49\"] = 15.6 * data_train[\"col49\"]\n\n#drop all float\n# data_train=data_train.drop(['col13','col23','col26','col32','col38','col42','col49','col54',],axis=1)\n# data_test=data_test.drop(['col13','col23','col26','col32','col38','col42','col49','col54',],axis=1)\n\n","abc9e506":"data_train_0=data_train[(data_train['Class']==0)]\ndata_train_1=data_train[(data_train['Class']==1)]\ndata_train_2=data_train[(data_train['Class']==2)]\ndata_train_3=data_train[(data_train['Class']==3)]","dc91f63e":"data_train_0.hist(figsize=(20,20))","5739a687":"data_train_1.hist(figsize=(20,20))","0310986c":"data_train_2.hist(figsize=(20,20))","cda23b02":"data_train_3.hist(figsize=(20,20))","8f54521e":"data_train=pd.get_dummies(data_train,columns=['col11','col37','col44'])\ndata_test=pd.get_dummies(data_test,columns=['col11','col37','col44'])\n\ndata_train=data_train.drop(['col11_Yes','col37_Female','col44_Yes'],axis=1)\ndata_test=data_test.drop(['col11_Yes','col37_Female','col44_Yes'],axis=1)\n\ndef replace_objs(s):\n    map1 = {\"Silver\":0,\"Gold\":1,\"Diamond\":2,\"Platinum\":3,\"Low\":0,\"Medium\":1,\"High\":2}\n    return map1[s]\n\ncolumn_objects=['col2','col56']\nfor name in column_objects:\n    data_train[name] = data_train[name].apply(replace_objs)\nfor name in column_objects:\n    data_test[name] = data_test[name].apply(replace_objs)","c1b2c4c5":"data_train_copy=data_train.copy()\ndata_test_copy=data_test.copy()","cdff6c92":"# ll=data_train[data_train.columns[1:]].corr()['Class'][:]\n# corr = data_train.corr()\n# columns = np.full((corr.shape[0],), True, dtype=bool)\n# for i in range(len(ll)):\n#     if(ll[i]<0.09 and ll[i]>-0.09):\n#         columns[i+1]=False\n# columns[3]=True\n# columns=columns.copy()\n# selected_columns = data_train.columns[columns]\n# data_train = data_train[selected_columns]\n# selected_columns =selected_columns[:-1]\n# data_test = data_test[selected_columns]","30b25341":"data_1=data_train[(data_train['Class']==1)]\ndata_train=pd.concat([data_train,data_1])\ndata_1=data_train[(data_train['Class']==2)]\ndata_train=pd.concat([data_train,data_1])","2842dd2d":"Y_train=data_train['Class']\ndata_train=data_train.drop(['ID','Class'],axis=1)\n","1d52cb47":"data_out=pd.DataFrame()\ndata_out['ID']=data_test['ID']\ndata_test=data_test.drop(['ID'],axis=1)","e3a9ce7f":"# corr = data_train.corr()\n# columns = np.full((corr.shape[0],), True, dtype=bool)\n# for i in range(corr.shape[0]):\n#     for j in range(i+1, corr.shape[0]):\n#         if corr.iloc[i,j] >= 0.96:\n# #             print(i,j)\n#             if columns[j]:\n# #                 print(\"--\",j)\n#                 columns[j] = False\n# selected_columns = data_train.columns[columns]\n# data_train = data_train[selected_columns]\n# data_test = data_test[selected_columns]\n\n# # selected_columns","1b6531b2":"scaler=StandardScaler()\nsclrfit=scaler.fit(pd.concat([data_train,data_test]))\ndata_train_norm=sclrfit.transform(data_train)\ndata_test_norm=sclrfit.transform(data_test)\ndata_train_n=pd.DataFrame(data_train_norm)\ndata_test_n=pd.DataFrame(data_test_norm)     ","f4824bd3":"pca10 = PCA(n_components=5,random_state=32)\npca10.fit(pd.concat([data_train_n,data_test_n]))\ndata_train_pca = pca10.transform(data_train_n)\ndata_test_pca = pca10.transform(data_test_n)  \ndata_train_pca=pd.DataFrame(data_train_pca)\ndata_test_pca=pd.DataFrame(data_test_pca)\ndata_train=pd.concat([data_train.reset_index(drop=True),data_train_pca.reset_index(drop=True)],axis=1)\ndata_test=pd.concat([data_test.reset_index(drop=True),data_test_pca.reset_index(drop=True)],axis=1)","f68f0ecd":"X_train,X_val,y_train,y_val=train_test_split(data_train, Y_train, test_size=0.13,random_state=42,stratify = Y_train)","3196602c":"data_train","5aaf2dca":"rf = RandomForestClassifier(n_estimators = 2000,criterion='entropy',max_features=25,random_state=18,max_depth=9,min_samples_split=4,min_samples_leaf=2) \nrf.fit(X_train,y_train)","843a8c4b":"cfm = confusion_matrix(y_val, rf.predict(X_val), labels = [0,1,2,3])\ncfm","0d0a033f":"print(classification_report(y_val,rf.predict(X_val)))","a7ae6e46":"rf.fit(data_train,Y_train)\nout=rf.predict(data_test)","24ade778":"data_out['Class']=pd.DataFrame(out)","c6f529e1":"from IPython.display import HTML\nimport base64\ndef create_download_link(df, title = \"Download CSV file\", filename = \"upsample_RF simple_final_last.csv\"):\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\"target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\ncreate_download_link(data_out)","87a3f910":"Remove on Basis of High Correlation among features and Low Correlation with output Class","937fac8c":"Generate Output","55e81963":"Normalisation and PCA","a2ae1b29":"# Pre Processing","a7d0c4df":"# Analysis","0af3af1c":"# FINAL MODEL\nMethods used for Parameter Tuning shown in ID_PSC file."}}