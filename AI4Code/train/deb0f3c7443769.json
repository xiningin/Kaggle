{"cell_type":{"741e1b4c":"code","7e1d56c8":"code","f440bc2d":"code","2fc7dd18":"code","91b4f704":"code","a71dcc32":"code","945e7044":"code","f5a79f8d":"code","82b90865":"code","fd123db1":"code","1fc7df57":"code","42892a72":"code","0c5c04bf":"code","df824379":"code","5c0e47ad":"code","f4bd81fe":"code","43bd4d00":"code","7195d487":"code","0b1e8523":"code","81bf6ece":"code","82ebce8f":"code","9ce68486":"code","60cccb79":"code","4b1267ef":"code","651fcd0e":"code","3a64e905":"code","0bed144a":"code","2b029f6a":"code","ed1c5204":"code","88a6ca53":"code","fa9d9604":"code","ac7e7321":"code","b502afac":"code","93a45534":"code","30046875":"code","9a8c250a":"code","9c223993":"code","179c052d":"code","13fcf838":"code","6be03a59":"code","638ec3c3":"code","32a4be5f":"code","b885edf3":"code","50627dd7":"code","b0e061a0":"code","dcc8f49d":"code","ae4f72eb":"code","b61e3e35":"code","2fd81f79":"code","0d9104b0":"code","1c493cd7":"code","804bd5fc":"code","3a415c2d":"code","c80e69ed":"code","ecd05376":"code","a42757ae":"code","fc786463":"markdown","554ccfef":"markdown","22183433":"markdown","088ab378":"markdown","4be8c2c4":"markdown","ccd61078":"markdown","d48747de":"markdown","8628b0cf":"markdown","4f4ed734":"markdown","4f360281":"markdown","40d7377b":"markdown","9d6cb822":"markdown","e2920305":"markdown","4165104c":"markdown","ce763a9e":"markdown","039ed41a":"markdown","b7e5bab8":"markdown","9b383a8e":"markdown","6e9537ea":"markdown","d3a0d08b":"markdown"},"source":{"741e1b4c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","7e1d56c8":"#This will just make the notebook easier to read down the line\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","f440bc2d":"#Read in the iris dataset and drop the redundant Id column\niris = pd.read_csv('..\/input\/Iris.csv').drop('Id',axis=1)","2fc7dd18":"#Check the top of the dataframe\niris.head(5)","91b4f704":"#More information about the data\niris.info()","a71dcc32":"#We'll start off with a pairplot differentiated by species\nsns.pairplot(data=iris, hue='Species', palette='inferno')","945e7044":"#Let's try looking at the data columns\nplt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.violinplot(x='Species', y='SepalLengthCm', data=iris, palette='plasma')\nplt.subplot(2,2,2)\nsns.violinplot(x='Species', y='SepalWidthCm', data=iris, palette='plasma')\nplt.subplot(2,2,3)\nsns.violinplot(x='Species', y='PetalLengthCm', data=iris, palette='plasma')\nplt.subplot(2,2,4)\nsns.violinplot(x='Species', y='PetalWidthCm', data=iris, palette='plasma')","f5a79f8d":"sns.heatmap(iris.corr(), annot=True, cmap='coolwarm')","82b90865":"#Let's see those two plots\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.scatterplot(x='PetalLengthCm', y='PetalWidthCm', data=iris, hue='Species', palette='inferno')\nplt.title('Petal Length vs Petal Width')\nplt.subplot(1,2,2)\nsns.scatterplot(x='PetalLengthCm', y='SepalLengthCm', data=iris, hue='Species', palette='inferno')\nplt.title('Petal Length vs Sepal Length')","fd123db1":"#Make a new dataframe for setosa\nsetosa = iris[iris['Species']=='Iris-setosa']","1fc7df57":"#Let's see sepal and petal kdeplots for the setosas\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.kdeplot(setosa['SepalWidthCm'], setosa['SepalLengthCm'], cmap=\"viridis\", shade=True, shade_lowest=False)\nplt.title('Setosa Sepal Width vs Sepal Length')\nplt.subplot(1,2,2)\nsns.kdeplot(setosa['PetalWidthCm'], setosa['PetalLengthCm'], cmap=\"viridis\", shade=True, shade_lowest=False)\nplt.title('Setosa Petal Width vs Petal Length')","42892a72":"from sklearn.model_selection import train_test_split","0c5c04bf":"#Let's break our train test split into one for petals and one for sepals\nX_petal = iris[['PetalLengthCm', 'PetalWidthCm']]\nX_sepal = iris[['SepalLengthCm', 'SepalWidthCm']]\ny = iris['Species']\nX_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_petal, y, test_size=0.30)\nX_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_sepal, y, test_size=0.30)","df824379":"from sklearn.linear_model import LogisticRegression","5c0e47ad":"#We'll make the model and fit it to the training data\nlogmodel_p = LogisticRegression()\nlogmodel_s = LogisticRegression()\nlogmodel_p.fit(X_train_p,y_train_p)\nlogmodel_s.fit(X_train_s,y_train_s)","f4bd81fe":"#Now for our predictions\npred_p = logmodel_p.predict(X_test_p)\npred_s = logmodel_s.predict(X_test_s)","43bd4d00":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, r2_score","7195d487":"#Here is our classification report and confusion matrix for the Logistic Regression model for petals\nprint(classification_report(y_test_p, pred_p))\nprint(confusion_matrix(y_test_p, pred_p))","0b1e8523":"#Here is our classification report and confusion matrix for the Logistic Regression model for sepals\nprint(classification_report(y_test_s, pred_s))\nprint(confusion_matrix(y_test_s, pred_s))","81bf6ece":"#Print accuracy scores\nprint('Using Logistic Regression:')\nprint('The accuracy using Petal information is ' + str(accuracy_score(y_test_p, pred_p)))\nprint('The accuracy using Sepal information is ' + str(accuracy_score(y_test_s, pred_s)))","82ebce8f":"from sklearn.neighbors import KNeighborsClassifier","9ce68486":"#We'll make the model and fit it to the training data using our n neighbors\nknn_p = KNeighborsClassifier(n_neighbors=3)\nknn_s = KNeighborsClassifier(n_neighbors=3)\nknn_p.fit(X_train_p,y_train_p)\nknn_s.fit(X_train_s,y_train_s)\npred_p = knn_p.predict(X_test_p)\npred_s = knn_s.predict(X_test_s)","60cccb79":"#Here is our classification report and confusion matrix for the KNN n=3 model for petals\nprint(classification_report(y_test_p, pred_p))\nprint(confusion_matrix(y_test_p, pred_p))","4b1267ef":"#Here is our classification report and confusion matrix for the KNN n=3 model for sepals\nprint(classification_report(y_test_s, pred_s))\nprint(confusion_matrix(y_test_s, pred_s))","651fcd0e":"#Print accuracy scores\nprint('Using KNN:')\nprint('The accuracy using Petal information is ' + str(accuracy_score(y_test_p, pred_p)))\nprint('The accuracy using Sepal information is ' + str(accuracy_score(y_test_s, pred_s)))","3a64e905":"from sklearn.tree import DecisionTreeClassifier","0bed144a":"#We'll make the model and fit it to the training data\ndtree_p = DecisionTreeClassifier()\ndtree_s = DecisionTreeClassifier()\ndtree_p.fit(X_train_p,y_train_p)\ndtree_s.fit(X_train_s,y_train_s)\npred_p = dtree_p.predict(X_test_p)\npred_s = dtree_s.predict(X_test_s)","2b029f6a":"#Here is our classification report and confusion matrix for the Decision Tree model for petals\nprint(classification_report(y_test_p, pred_p))\nprint(confusion_matrix(y_test_p, pred_p))","ed1c5204":"#Here is our classification report and confusion matrix for the Decision Tree model for sepals\nprint(classification_report(y_test_s, pred_s))\nprint(confusion_matrix(y_test_s, pred_s))","88a6ca53":"#Print accuracy scores\nprint('Using a Decision Tree:')\nprint('The accuracy using Petal information is ' + str(accuracy_score(y_test_p, pred_p)))\nprint('The accuracy using Sepal information is ' + str(accuracy_score(y_test_s, pred_s)))","fa9d9604":"from sklearn.ensemble import RandomForestClassifier","ac7e7321":"#We'll make the model and fit it to the training data using 100 estimators\nrfc_p = RandomForestClassifier(n_estimators=100)\nrfc_s = RandomForestClassifier(n_estimators=100)\nrfc_p.fit(X_train_p, y_train_p)\nrfc_s.fit(X_train_s, y_train_s)\npred_p = rfc_p.predict(X_test_p)\npred_s = rfc_s.predict(X_test_s)","b502afac":"#Here is our classification report and confusion matrix for the Random Forest model for petals\nprint(classification_report(y_test_p, pred_p))\nprint(confusion_matrix(y_test_p, pred_p))","93a45534":"#Here is our classification report and confusion matrix for the Random Forest model for sepals\nprint(classification_report(y_test_s, pred_s))\nprint(confusion_matrix(y_test_s, pred_s))","30046875":"#Print accuracy scores\nprint('Using a Random Forest:')\nprint('The accuracy using Petal information is ' + str(accuracy_score(y_test_p, pred_p)))\nprint('The accuracy using Sepal information is ' + str(accuracy_score(y_test_s, pred_s)))","9a8c250a":"from sklearn.svm import SVC","9c223993":"#We'll make the model and fit it to the training data\nsvc_model_p = SVC()\nsvc_model_s = SVC()\nsvc_model_p.fit(X_train_p,y_train_p)\nsvc_model_s.fit(X_train_s,y_train_s)\npred_p = svc_model_p.predict(X_test_p)\npred_s = svc_model_s.predict(X_test_s)","179c052d":"#Here is our classification report and confusion matrix for the SVM model for petals\nprint(classification_report(y_test_p, pred_p))\nprint(confusion_matrix(y_test_p, pred_p))","13fcf838":"#Here is our classification report and confusion matrix for the SVM model for sepals\nprint(classification_report(y_test_s, pred_s))\nprint(confusion_matrix(y_test_s, pred_s))","6be03a59":"#Print accuracy scores\nprint('Using SVM:')\nprint('The accuracy using Petal information is ' + str(accuracy_score(y_test_p, pred_p)))\nprint('The accuracy using Sepal information is ' + str(accuracy_score(y_test_s, pred_s)))","638ec3c3":"#Another train test split\nX = iris.drop('Species', axis=1)\ny = iris['Species']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","32a4be5f":"#We'll make the model and fit it to the training data\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)\npred = logmodel.predict(X_test)","b885edf3":"#Here is our classification report and confusion matrix for the Logistic Regression model\nprint(classification_report(y_test, pred))\nprint(confusion_matrix(y_test, pred))","50627dd7":"#Print accuracy scores\nprint('Using Logistic Regression:')\nprint('The accuracy is ' + str(accuracy_score(y_test, pred)))","b0e061a0":"#We will use n=3\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)","dcc8f49d":"#Here is our classification report and confusion matrix for the KNN n=3 model\nprint(classification_report(y_test, pred))\nprint(confusion_matrix(y_test, pred))","ae4f72eb":"#Print accuracy scores\nprint('Using KNN:')\nprint('The accuracy is ' + str(accuracy_score(y_test, pred)))","b61e3e35":"#We'll make the model and fit it to the training data\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\npred = dtree.predict(X_test)","2fd81f79":"#Here is our classification report and confusion matrix for the Decision Tree model\nprint(classification_report(y_test, pred))\nprint(confusion_matrix(y_test, pred))","0d9104b0":"#Print accuracy scores\nprint('Using a Decision Tree:')\nprint('The accuracy is ' + str(accuracy_score(y_test, pred)))","1c493cd7":"#We'll make the model and fit it to the training data using 100 estimators\nrfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)\npred = rfc.predict(X_test)","804bd5fc":"#Here is our classification report and confusion matrix for the Random Forest model\nprint(classification_report(y_test, pred))\nprint(confusion_matrix(y_test, pred))","3a415c2d":"#Print accuracy scores\nprint('Using a Random Forest:')\nprint('The accuracy is ' + str(accuracy_score(y_test, pred)))","c80e69ed":"#We'll make the model and fit it to the training data\nsvc_model = SVC()\nsvc_model.fit(X_train,y_train)\npred = svc_model.predict(X_test)","ecd05376":"#Here is our classification report and confusion matrix for the SVM model\nprint(classification_report(y_test, pred))\nprint(confusion_matrix(y_test, pred))","a42757ae":"#Print accuracy scores\nprint('Using SVM:')\nprint('The accuracy is ' + str(accuracy_score(y_test, pred)))","fc786463":"We could do a train test split on all the columns of the iris dataframe, but because of the relatively small size of the dataset, we would likely end up getting very high and very similar values for precision and recall (as we will see later). While this is good for a model, it may be more interesting to first predict the species just using the petal information or just using the sepal information to see larger differences between our models","554ccfef":"# Overall\n\nIt appears that using both the petal data and the sepal data together to build our models resulted in equal and better accuracy than the models trained above that used either but not both. Please give me feedback on what you think!","22183433":"# Exploratory Data Analysis","088ab378":"## Decision Tree","4be8c2c4":"## First we'll try Logistic Regression","ccd61078":"## Logistic Regression","d48747de":"## K Nearest Neighbors\n\nSimilar to earlier, instead of testing different values of n_neighbors to minimize our error, we will just use n=3 for simplicity","8628b0cf":"## Overall\nIt appears that overall it is best to use petal information to predict iris species, rather than sepal data to get a more accurate model","4f4ed734":"## SVM","4f360281":"# **Working with the Iris Species Dataset**\n\nThis is my first notebook on Kaggle and will mainly serve as a way to practice some Machine Learning concepts and exploratory data analysis on a dataset I find particularly interesting. As this is my first notebook, I would appreciate any feedback available!","40d7377b":"## Next we'll try K Nearest Neighbors","9d6cb822":"## Next, Decision Trees","e2920305":"## Next, expanding to a Random Forest","4165104c":"# Now on to the Machine Learning part\nFirst, the train test split","ce763a9e":"We could try various values for n_neighbors to minimize our error, but for simplicity we will just choose n=3","039ed41a":"## Finally, let's use a Support Vector Machine","b7e5bab8":"It appears petal length and petal width are the most correlated, followed by sepal length and petal length","9b383a8e":"# Putting it all together\n\nNow instead of just using either petal data or sepal data, we will use them both to predict the iris species","6e9537ea":"## Random Forest","d3a0d08b":"It appears the Setosa species is the most separable, so let's look at that by itself"}}