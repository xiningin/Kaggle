{"cell_type":{"c816a0b0":"code","e91806bf":"code","b3b58872":"code","6e7034af":"code","39be9201":"code","a35e31e1":"code","0f2a95ac":"code","2131b02b":"code","f4e9b44b":"code","7aafab03":"code","88b66b89":"code","1b866627":"code","0e2f3d1a":"code","a7f38b76":"code","fafe0b7e":"code","16c98882":"code","fa756cfc":"code","f1145d6d":"code","9f9675f9":"code","c2f93f7a":"markdown","759d4711":"markdown","811098c5":"markdown","bea9a7c2":"markdown","b84a4f7d":"markdown","b6480a3d":"markdown","133e3b9a":"markdown"},"source":{"c816a0b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e91806bf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl \nimport seaborn as sns\n# plt.style.use('seaborn-poster')\n%matplotlib inline\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')\n\nimport datetime\nfrom datetime import datetime  \nimport calendar # \u0438\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0443\u043b\u044c calendar \u0434\u043b\u044f \u0432\u044b\u0433\u0440\u0443\u0437\u043a\u0438 \u043c\u0435\u0441\u044f\u0446\u0435\u0432 \u0438 \u0434\u043d\u0435\u0439 \u043d\u0435\u0434\u0435\u043b\u0438\n\nimport warnings\nwarnings.filterwarnings ('ignore') # \u0438\u0433\u043d\u043e\u0440\u0438\u0440\u0443\u0435\u0442 \u043b\u0438\u0448\u043d\u0438\u0435 \u0441\u0438\u0441\u0442\u0435\u043c\u043d\u044b\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f\n\nfrom itertools import permutations, combinations\n\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\npd.set_option('max_rows',1000)\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.subplots as subplots\nimport plotly as py\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\nline_color = ['#008abc','#96508e','#4fcb93','#f86e35','#ddaa18','#20beff']\n\nfrom xgboost import XGBRegressor\n\nfrom xgboost import plot_importance\nfrom sklearn.inspection import partial_dependence, plot_partial_dependence\n\nfrom tensorflow.keras import utils #\u0414\u043b\u044f to_categorical\nimport numpy as np #Numpy\nfrom tensorflow.keras.optimizers import Adam, RMSprop, Nadam, SGD #\u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\nfrom tensorflow.keras.models import Sequential, Model #\u0414\u0432\u0430 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u043c\u043e\u0434\u0435\u043b\u0435\u0439\nfrom tensorflow.keras.layers import concatenate, Input, Dense, Dropout, \\\nBatchNormalization, Flatten, Conv1D, Conv2D, LSTM, GlobalMaxPooling1D, \\\nMaxPooling1D, RepeatVector\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler #\u041d\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0449\u0438\u043a\u0438\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator # \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u0440\u044f\u0434\u043e\u0432\n\nfrom pylab import rcParams\n\nimport scipy\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler          #\u041d\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0449\u0438\u043a\u0438\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator #\u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u0440\u044f\u0434\u043e\u0432\n\nfrom sklearn.preprocessing import StandardScaler # \nfrom sklearn.model_selection import train_test_split # \u0414\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u0438 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error #\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import concatenate, Input, Dense, Dropout, \\\n                                    BatchNormalization, Flatten, Conv1D,\\\n                                    Conv2D, MaxPooling2D, MaxPooling1D, LSTM\nimport math               \n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# rcParams['figure.figsize']=8,4\nrcParams['figure.facecolor']='powderblue'\nrcParams['axes.facecolor']='cornsilk'\nrcParams['axes.titlecolor']='maroon'\nrcParams['axes.titlesize']='12'\nrcParams['axes.grid']=True","b3b58872":"PredTrue=dict() # \u043f\u0443\u0441\u0442\u043e\u0439 \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u043f\u043e\u0434 4 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u043c\u0430\nfor dirname, _, filenames in sorted(os.walk('\/kaggle\/input')):\n    for e, filename in enumerate(filenames):\n        PredTrue[filename[:-8]]=pd.DataFrame() #  \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043d\u043e\u0432\u044b\u0439 \u044d\u043b\u0435\u043c\u0435\u043d\u0442 \u0432 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c \n        print('\\033[091m]', os.path.join(dirname, filename))\n        PredTrue[filename[:-8]]=pd.read_csv(os.path.join(dirname, filename), index_col=0) #  \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043d\u043e\u0432\u044b\u0439 \u044d\u043b\u0435\u043c\u0435\u043d\u0442 \u0434\u0430\u043d\u043d\u044b\u043c\u0438\nPredTrue        ","6e7034af":"sorted(list(PredTrue.keys())), PredTrue['PRED_norm_18_09'].shape","39be9201":"countries=['US', 'India', 'Brazil', 'United Kingdom', 'Russia']\ncountries","a35e31e1":"list(PredTrue.keys())","0f2a95ac":"'''\n\u041f\u0435\u0440\u0435\u0438\u043c\u0435\u043d\u0443\u0435\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0438 \u043c\u0430\u0441\u0441\u0438\u0432\u043e\u0432'''\nfor j in list(PredTrue.keys()):\n    for e, i in enumerate(PredTrue[j].columns):\n            PredTrue[j].rename(columns={i:countries[e]}, inplace= True)\n    print(PredTrue[j].tail())","2131b02b":"PredTrue['PRED_norm_18_09'].sample(3)","f4e9b44b":"PredTrue['PRED_norm_18_09'].index","7aafab03":"# PredTrue['PRED_norm_18_09'][countries[0]]","88b66b89":"sorted(list(PredTrue.keys()))","1b866627":"def VisualPlot(n=0):\n    '''\n        VisualPlot- \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u0435\u043c\u043e\u0441\u0442\u0438\n            \u0432\u0445\u043e\u0434: n - \u043d\u043e\u043c\u0435\u0440 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430 \u043c\u0430\u0441\u0441\u0438\u0432\u0430\n            \u0432\u044b\u0445\u043e\u0434: \u0438\u043d\u0442\u0435\u0440\u0430\u043a\u0442\u0438\u0432\u043d\u0430\u044f \u043f\u0430\u043d\u0435\u043b\u044c \u043f\u043e \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u0435\u043c\u043e\u0441\u0442\u0438\n    '''\n    fig = go.Figure()\n    count = 0\n    for e, i in enumerate(countries):\n        fig.add_trace(go.Scatter(x=PredTrue[sorted(list(PredTrue.keys()))[n]].index,\n                                 y=PredTrue[sorted(list(PredTrue.keys()))[n]][countries[e]],\\\n                                 connectgaps=True, \\\n                                 name=countries[e],\n                                 line=dict(width=4)))\n\n        count+=1\n\n    return fig.update_layout(title=sorted(list(PredTrue.keys()))[n], yaxis = dict(rangemode = 'tozero'))","0e2f3d1a":"VisualPlot(0)","a7f38b76":"VisualPlot(2)","fafe0b7e":"VisualPlot(1)","16c98882":"VisualPlot(3)","fa756cfc":"fig = go.Figure()\nn=1 # \ncount = 0\nfor e, i in enumerate(countries):\n    fig.add_trace(go.Scatter(x=PredTrue[sorted(list(PredTrue.keys()))[n]].index,\n                             y=PredTrue[sorted(list(PredTrue.keys()))[n]][countries[e]],\\\n                             connectgaps=True, \\\n                             name=countries[e],\n                             line=dict(width=4)))\n\n    count+=1\n        \nfig.update_layout(title=sorted(list(PredTrue.keys()))[n], yaxis = dict(rangemode = 'tozero'))","f1145d6d":"sorted(list(PredTrue.keys()))","9f9675f9":"fig = go.Figure()\n\ncount = 0\nfor e, i in enumerate(countries):\n    fig.add_trace(go.Scatter(x=PredTrue['Y_TRUE_norm_18_09'].index,\n                             y=PredTrue['Y_TRUE_norm_18_09'][countries[e]],\\\n                             connectgaps=True, \\\n                             name=countries[e],\n                             line=dict(width=4)))\n\n    count+=1\n        \nfig.update_layout(title='\u0417\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u0435\u043c\u043e\u0441\u0442\u044c_\u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0435', yaxis = dict(rangemode = 'tozero'))","c2f93f7a":"***\u0412\u044b\u0433\u0440\u0443\u0437\u0438\u043c \u0440\u0430\u043d\u0435\u0435 \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u0430\u0441\u0441\u0438\u0432\u044b \u043f\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044e \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u0435\u043c\u043e\u0441\u0442\u0438 Covid-19, \u0430\u043a\u0442\u0443\u0430\u043b\u044c\u043d\u044b\u0435 \u043d\u0430 19.11.2021\u0433\u043e\u0434\u0430, \u043f\u043e \u043f\u044f\u0442\u0438 \u0441\u0442\u0440\u0430\u043d\u0430\u043c, \u0441 \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u0435\u043c\u043e\u0441\u0442\u0438. \u041c\u0430\u0441\u0441\u0438\u0432\u044b \u0441 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u043c \"18_09\", \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0432 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432  \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0430\u0445 \u0431\u0435\u0437 \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u0438 \u043d\u0430 \u043e\u043a\u043d\u0430. \u041c\u0430\u0441\u0441\u0438\u0432\u044b \u0441 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u043c \"20_09\", \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0432 \u0445\u043e\u0434\u0435 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432, \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0430\u0445 \u0441 \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u043e\u0439 \u043d\u0430 \"\u043e\u043a\u043d\u0430\"***","759d4711":"# ***\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438 \u0440\u0430\u0431\u043e\u0442\u0430 \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438***\n","811098c5":"# ***\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u0435\u043c\u043e\u0441\u0442\u0438. \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0438 \u0432\u0435\u0440\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435***","bea9a7c2":"***\u041c\u0430\u0441\u0441\u0438\u0432\u044b \u0441 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u043c \"18_09\", \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0432 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0430\u0445 \u0431\u0435\u0437 \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u0438 \u043d\u0430 \u043e\u043a\u043d\u0430***","b84a4f7d":"***\u041c\u0430\u0441\u0441\u0438\u0432\u044b \u0441 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u043c \"20_09\", \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u044b \u0432 \u0445\u043e\u0434\u0435 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432, \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0430\u0445 \u0441 \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u043e\u0439 \u043d\u0430 \"\u043e\u043a\u043d\u0430\"***","b6480a3d":"# ***\u0427\u0435\u0440\u043d\u043e\u0432\u0438\u043a***","133e3b9a":"# **\u0418\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a****"}}