{"cell_type":{"f0810c54":"code","b5364c51":"code","68c43031":"code","1a684a3a":"code","f4923fb1":"code","1095ae11":"code","48317673":"code","d25aeea9":"code","bb706d3e":"code","4efbe398":"markdown","559d1e25":"markdown","77adf29a":"markdown","e6de2ff7":"markdown","a2b7cdf3":"markdown"},"source":{"f0810c54":"import os\nimport gc\nimport time\nimport psutil\nimport numpy as np\nimport pandas as pd\nimport random as rn\nimport seaborn as sns\n\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom contextlib import contextmanager\nfrom tensorflow import set_random_seed\n\nrn.seed(5)\nnp.random.seed(7)\nset_random_seed(2)\nos.environ['PYTHONHASHSEED'] = '3'","b5364c51":"timer_depth = -1\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    global timer_depth\n    timer_depth += 1\n    yield\n    pid = os.getpid()\n    py = psutil.Process(pid)\n    memoryUse = py.memory_info()[0] \/ 2. ** 30\n    print('----'*timer_depth + f'>>[{name}] done in {time.time() - t0:.0f} s ---> memory used: {memoryUse:.4f} GB', '')\n    if(timer_depth == 0):\n        print('\\n')\n    timer_depth -= 1","68c43031":"base_path = '..\/input'\nwith timer('read application data'):\n    app_train = pd.read_csv(os.path.join(base_path, 'application_train.csv'))","1a684a3a":"print(f'app_train shape : {app_train.shape}')\napp_train_target = app_train.pop('TARGET')\nprint('pop application train TARGET')\nprint(f'app_train shape : {app_train.shape}')","f4923fb1":"app_train = app_train.select_dtypes(include=['object'])\napp_train = app_train.fillna('XNA')\nprint(app_train.shape)\napp_train.head()","1095ae11":"def cal_woe(app_train, app_train_target):\n    num_events = app_train_target.sum()\n    num_non_events = app_train_target.shape[0] - app_train_target.sum()\n\n    feature_list = []\n    feature_iv_list = []\n    for col in app_train.columns:\n        if app_train[col].unique().shape[0] == 1:\n            del app_train[col]\n            print('remove constant col', col)\n\n        with timer('cope with %s' % col):\n            feature_list.append(col)\n\n            woe_df = pd.DataFrame()\n            woe_df[col] = app_train[col]\n            woe_df['target'] = app_train_target\n            events_df = woe_df.groupby(col)['target'].sum().reset_index().rename(columns={'target' : 'events'})\n            events_df['non_events'] = woe_df.groupby(col).count().reset_index()['target'] - events_df['events']\n            def cal_woe(x):\n                return np.log( ((x['non_events']+0.5)\/num_non_events) \/ ((x['events']+0.5)\/num_events)  )\n            events_df['WOE_'+col] = events_df.apply(cal_woe, axis=1)\n\n            def cal_iv(x):\n                return x['WOE_'+col]*(x['non_events'] \/ num_non_events - x['events'] \/ num_events)\n            events_df['IV_'+col] = events_df.apply(cal_iv, axis=1)\n\n            feature_iv = events_df['IV_'+col].sum()\n            feature_iv_list.append(feature_iv)\n\n            events_df = events_df.drop(['events', 'non_events', 'IV_'+col], axis=1)\n            app_train = app_train.merge(events_df, how='left', on=col)\n    iv_df = pd.DataFrame()\n    iv_df['feature'] = feature_list\n    iv_df['IV'] = feature_iv_list\n    iv_df = iv_df.sort_values(by='IV', ascending=False)\n    return app_train, iv_df\n\nwith timer('calculate WOE and IV'):\n    app_train, iv_df = cal_woe(app_train, app_train_target)","48317673":"app_train.head()","d25aeea9":"iv_df","bb706d3e":"iv_df.loc[iv_df['IV']>0.02]","4efbe398":"## Select Category Columns","559d1e25":"## Pop Target","77adf29a":"## Calculate WOE and IV","e6de2ff7":"Low information value features are not useful for prediction","a2b7cdf3":"This kernel is my implementation of  [weight of evidence(WOE) and information value(IV)](https:\/\/github.com\/h2oai\/h2o-meetups\/blob\/master\/2017_11_29_Feature_Engineering\/Feature%20Engineering.pdf)   \nWe can select category features according to its' information value."}}