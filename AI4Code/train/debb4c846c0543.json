{"cell_type":{"02d84eb3":"code","f2fe3c46":"code","7a13992d":"code","5f12064a":"code","38937c3c":"code","4b98377b":"code","c3c9193e":"code","98fea2f1":"code","b83f4aba":"code","0f984ea9":"code","3b8736b8":"code","1532bbbf":"code","b2c236ec":"code","6cd3abcf":"code","8a559d6d":"code","b3124de9":"code","91f0c956":"code","505fad93":"code","723a7e4f":"code","6e4cef87":"code","2bb40cc8":"code","47dba848":"code","37572063":"markdown","cb9f3674":"markdown","92ec57bb":"markdown","2db25f65":"markdown","40019e96":"markdown","0996ee67":"markdown","186d6e17":"markdown","3e80497e":"markdown","23de4bab":"markdown","71679dc6":"markdown","7037e4ba":"markdown"},"source":{"02d84eb3":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f2fe3c46":"import keras # Neural nets API\nimport numpy as np # Linear algebra\nimport pandas as pd # Data manipulation.","7a13992d":"# Load data into train and test pandas dataframe\ntrain_df=pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest_df=pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","5f12064a":"# view top 5 rows. \ntrain_df.head()","38937c3c":"test_df.head() # view top 5 rows of test data.","4b98377b":"# shape of both train and test dataset.\ntrain_df.shape ,test_df.shape","c3c9193e":"# drop target (label) into new one\ntarget=train_df[\"label\"]\ntrain_df.drop(\"label\",axis=1,inplace=True)","98fea2f1":"train_df.head()","b83f4aba":"train_df=train_df\/255 # normalize will work better with cnn\ntest_df=test_df\/255 # from [0:255] to [0:1]","0f984ea9":"X_train=train_df.values.reshape(-1,28,28,1) # reshaping to keras convention (sample,height,width,color)\ntest=test_df.values.reshape(-1,28,28,1)","3b8736b8":"from keras.utils.np_utils import to_categorical\ny_train=to_categorical(target,num_classes=10) # one hot encoding","1532bbbf":"y_train[0] # view first label after OHE.","b2c236ec":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,5))\n\nfor i in range(30):\n    plt.subplot(3,10,i+1)\n    plt.imshow(X_train[i].reshape((28,28)),cmap=plt.cm.binary)\n    plt.axis(\"off\")\nplt.subplots_adjust(wspace=0,hspace=0)\nplt.show()","6cd3abcf":"# train test split data one for training one for vaildation.\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_train,y_train,test_size=0.10,random_state=42)","8a559d6d":"plt.imshow(X_train[0].reshape((28,28))) # plot","b3124de9":"y_train[0] # result for above plot.","91f0c956":"batch_size=128\nnum_classes=10\nepochs=20\ninputshape=(28,28,1)","505fad93":"from keras.models import Sequential # import sequential convention so we can add layer after other.\nimport keras\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Dropout,Flatten,BatchNormalization\nmodel=Sequential()\n\n# add first convolutional layer.\nmodel.add(Conv2D(32,kernel_size=(5,5),activation=\"relu\",input_shape=inputshape))\n# add second convolutional layer\nmodel.add(Conv2D(64,(3,3),activation=\"relu\"))\n          \n# add maxpooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128,kernel_size=(5,5),activation=\"relu\"))\n# add second convolutional layer\nmodel.add(Conv2D(128,(3,3),activation=\"relu\"))\n\n# add one drop layer\nmodel.add(Dropout(0.25))\n\n# add flatten layer\nmodel.add(Flatten())\n\n# add dense layer\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dense(128,activation=\"relu\"))\n          \n# add another dropout layer\nmodel.add(Dropout(0.5))\n\n# add dense layer\nmodel.add(Dense(num_classes, activation='softmax'))","723a7e4f":"# complile the model and view its architecture\nmodel.compile(loss=\"categorical_crossentropy\",  optimizer=\"Adam\", metrics=['accuracy'])\nmodel.summary()","6e4cef87":"# callbacks\nfrom keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\nreduce_learning_rate = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 3, verbose = 1, factor = 0.3, min_lr = 0.00001)\ncheckpoint = ModelCheckpoint('save_weights.h5', monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\nearly_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 10, verbose = 1, restore_best_weights = True)\n\ncallbacks = [reduce_learning_rate, checkpoint, early_stopping]","2bb40cc8":"# train model\nmodel.fit(X_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(X_test,y_test),callbacks=callbacks)\naccuracy=model.evaluate(X_test,y_test)","47dba848":"pred = model.predict_classes(test)\nres = pd.DataFrame({\"ImageId\":list(range(1,28001)),\"Label\":pred})\nres.to_csv(\"output.csv\", index = False)","37572063":"- Label variable states the digit of each col","cb9f3674":"- Label dropped","92ec57bb":"- No label we need to predict .","2db25f65":"# 4. Split train data for validation","40019e96":"\n### Network Parameters:\n\n> - Batch Size - Number of rows from the input data to use it one iteratation from the training purpose  \n> - Num Classes - Total number of possible classes in the target variable  \n> - Epochs - Total number of iterations for which cnn model will run.","0996ee67":"# 2. Normalize and Reshape data to visualize images format.","186d6e17":"# 1. Import Libraries","3e80497e":"# 5. Model building.","23de4bab":"# Problem Statement.\n- Handwritten Digits recognizer.\n- Train dataset consists of 42k rows with 785 cols.\n- Test dataset consists of 28k rows with 784 cols.\n- hello world competition of Computer Vision. ","71679dc6":"# 3. visualize by reshaping data.","7037e4ba":"# Steps:\n1. Import libraries.\n2. Get data into pandas dataframe\n    - 2.1 drop label from train dataset.\n3. Pre-processing\n    - 3.1 Normalize data for better performance (Convert pixels values from [0:255] to [0:1])\n    - 3.2 Reshape data for keras convention (sample size,width,height,color) -- syntax\n    - 3.3 convert labels into one-hot-encode and also view OHE labels for understanding.\n    \n4. Visualize data with matplotlib\n5. Split train data for validation.\n6. Build model CNN using keras\n   - 6.1 Set parameters and stack layers\n   - 6.2 Get summary.\n   - 6.3 Define loss function and metrics \n   - 6.4 Train model with parameters.\n   - 6.5 Set callbacks to monitor val_acc and for Learning rate to stop when there won't increases in val_accuracy.\n7. Predict and submit."}}