{"cell_type":{"2f0a6f3e":"code","61f433f9":"code","81eafbf7":"code","679f0b26":"code","b53922d7":"code","af532ae1":"code","18ec32b8":"code","540979eb":"code","fe1bbb2e":"code","12b31aea":"code","f4a2f333":"code","b64020f1":"code","77f52b76":"code","1e911d1d":"code","19e2edc5":"code","b4822018":"code","eed53711":"code","0cdec50c":"code","df4b92b8":"code","a1cff52f":"code","a6d2fbd7":"code","83592a95":"code","ce63778e":"code","6cca718a":"code","882645ce":"code","34f4664d":"code","67f3f23e":"code","b0da0a31":"code","0337e1e7":"code","df962f78":"code","96c08741":"code","63b5d062":"code","de2d91df":"code","5bf45c73":"code","a8661269":"code","dc0238e3":"code","3f8c80c4":"code","a5a3a3a5":"code","bbde7968":"code","3c96030a":"code","4422729d":"code","c0fd1ead":"code","afc01eac":"code","7ad631f1":"code","2a39aabf":"code","4c0c90d7":"code","77aa54c9":"code","c14abf66":"code","73ee6d64":"code","931ae7f5":"code","7d8f9d23":"code","8a16abf2":"code","00e650da":"code","83a8d3d7":"code","c5366dda":"code","90471be5":"code","40b9cdc3":"code","278b30e5":"code","4082a72b":"code","52df4e5c":"code","da727fcc":"markdown","b72be4cc":"markdown","3d533407":"markdown","b1956ffc":"markdown","3bae78d9":"markdown","b1867a3e":"markdown","7cd648df":"markdown","acfe3ed8":"markdown","f460c35d":"markdown","f02b7c3d":"markdown","97573e5e":"markdown","3fac2084":"markdown","797259c3":"markdown"},"source":{"2f0a6f3e":"#machine_learning\n#SVM\n#KNN\n#LogisticRegression\n#RandomForest\n#DecisionTree","61f433f9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, plot_roc_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nimport matplotlib.image as pltimg\n%matplotlib inline","81eafbf7":"train = pd.read_csv('..\/input\/titanic\/train.csv')","679f0b26":"train.head()","b53922d7":"train.shape","af532ae1":"train.describe()","18ec32b8":"train.drop(['PassengerId', 'Name', 'Ticket', 'Fare',\"Embarked\"], axis = 1, inplace = True)\ntrain.loc[train['Sex']=='male','Sex'] = 1\ntrain.loc[train['Sex']=='female', 'Sex'] = 0","540979eb":"train['Survived'].value_counts()","fe1bbb2e":"sns.countplot(data=train, x='Survived')","12b31aea":"train.corr()['Survived'].sort_values()","f4a2f333":"sns.scatterplot(data=train, x='Age', y='Sex',hue='Survived')","b64020f1":"sns.pairplot(train,diag_kind='kde')","77f52b76":"sns.heatmap(train.corr(), annot=True,cmap='Greens')","1e911d1d":"sns.boxplot(data=train, x='Survived', y='Age')","19e2edc5":"train.isnull().sum()","b4822018":"100*(train.isnull().sum()\/len(train))","eed53711":"def missing_percent(train):\n    nan_percent= 100*(train.isnull().sum()\/len(train))\n    nan_percent= nan_percent[nan_percent>0].sort_values()\n    return nan_percent","0cdec50c":"nan_percent= missing_percent(train)","df4b92b8":"nan_percent","a1cff52f":"plt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","a6d2fbd7":"plt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\n\n#Set 1% threshold:\nplt.ylim(0,1)","83592a95":"nan_percent[nan_percent<1]","ce63778e":"train.drop(\"Cabin\", axis = 1, inplace = True)","6cca718a":"train[\"Age\"].fillna(train[\"Age\"].mean(), inplace = True)","882645ce":"train.isnull().sum()","34f4664d":"# Split Data into train,test","67f3f23e":"X = train.drop(\"Survived\", axis = 1, inplace = False)\ny = train[\"Survived\"]","b0da0a31":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)","0337e1e7":"scaler=StandardScaler()\nscaler.fit(X_train)","df962f78":"scaler_train=scaler.transform(X_train)\nscaler_test=scaler.transform(X_test)","96c08741":"Lr_model = LogisticRegression()\nLr_model.fit(scaler_train,y_train)","63b5d062":"y_pred= Lr_model.predict(scaler_test)","de2d91df":"plot_confusion_matrix(Lr_model, scaler_test, y_test)","5bf45c73":"print(classification_report(y_test, y_pred))","a8661269":"test_error_rate=[]\nfor k in range(1,30):\n    knn_midel=KNeighborsClassifier(n_neighbors=k)\n    knn_midel.fit(scaler_train,y_train)\n    y_p_test=knn_midel.predict(scaler_test)\n    test_error=1-accuracy_score(y_test,y_p_test)\n    test_error_rate.append(test_error)","dc0238e3":"test_error_rate","3f8c80c4":"plt.figure(figsize=(12,6))\nplt.plot(range(1,30),test_error_rate,label='test_error')\nplt.legend()\nplt.xlabel('k Value')\nplt.ylabel('Error')","a5a3a3a5":"knn_model=KNeighborsClassifier(n_neighbors=4)\nknn_model.fit(scaler_train,y_train)","bbde7968":"y_pred=knn_model.predict(scaler_test)","3c96030a":"plot_confusion_matrix(Lr_model, scaler_test, y_test)","4422729d":"print(classification_report(y_test, y_pred))","c0fd1ead":"svc = SVC()\nsvc.fit(scaler_train, y_train)\ny_pred = svc.predict(scaler_test)","afc01eac":"plot_confusion_matrix(Lr_model, scaler_test, y_test)","7ad631f1":"print(classification_report(y_test, y_pred))","2a39aabf":"kernels = ['Polynomial', 'RBF', 'Sigmoid','Linear']\n#A function which returns the corresponding SVC model\ndef getClassifier(ktype):\n    if ktype == 0:\n        # Polynomial kernal\n        return SVC(kernel='poly', degree=8, gamma=\"auto\")\n    elif ktype == 1:\n        # Radial Basis Function kernal\n        return SVC(kernel='rbf', gamma=\"auto\")\n    elif ktype == 2:\n        # Sigmoid kernal\n        return SVC(kernel='sigmoid', gamma=\"auto\")\n    elif ktype == 3:\n        # Linear kernal\n        return SVC(kernel='linear', gamma=\"auto\")","4c0c90d7":"kernels = ['Polynomial', 'RBF', 'Sigmoid','Linear']","77aa54c9":"for i in range(4):\n    svclassifier = getClassifier(i) \n    svclassifier.fit(scaler_train, y_train)# Make prediction\n    y_pred = svclassifier.predict(scaler_test)# Evaluate our model\n    print(\"Evaluation:\", kernels[i], \"kernel\")\n    print(classification_report(y_test,y_pred))","c14abf66":"def train_using_gini(scaler_train,y_train):\n  \n    # Creating the classifier object\n    clf_gini = DecisionTreeClassifier(criterion = \"gini\",\n            random_state = 100,max_depth=3, min_samples_leaf=5)\n  \n    # Performing training\n    clf_gini.fit(scaler_train, y_train)\n    return clf_gini","73ee6d64":"def tarin_using_entropy(scaler_train, y_train):\n  \n    # Decision tree with entropy\n    clf_entropy = DecisionTreeClassifier(\n            criterion = \"entropy\", random_state = 100,\n            max_depth = 3, min_samples_leaf = 5)\n  \n    # Performing training\n    clf_entropy.fit(scaler_train, y_train)\n    return clf_entropy","931ae7f5":"def prediction(scaler_test, clf_object):\n  \n    # Predicton on test with giniIndex\n    y_pred = clf_object.predict(scaler_test)\n    print(\"Predicted values:\")\n    print(y_pred)\n    return y_pred","7d8f9d23":"def cal_accuracy(y_test, y_pred):\n      \n    print(\"Confusion Matrix: \",\n        confusion_matrix(y_test, y_pred))\n      \n    print (\"Accuracy : \",\n    accuracy_score(y_test,y_pred)*100)\n      \n    print(\"Report : \",\n    classification_report(y_test, y_pred))","8a16abf2":"    clf_gini = train_using_gini(scaler_train, y_train)\n    clf_entropy = tarin_using_entropy(scaler_train, y_train)\n      \n    # Operational Phase\n    print(\"Results Using Gini Index:\")\n      \n    # Prediction using gini\n    y_pred_gini = prediction(X_test, clf_gini)\n    cal_accuracy(y_test, y_pred_gini)\n      \n    print(\"Results Using Entropy:\")\n    # Prediction using entropy\n    y_pred_entropy = prediction(scaler_test, clf_entropy)\n    cal_accuracy(y_test, y_pred_entropy)","00e650da":"RF = RandomForestClassifier(n_estimators = 100) ","83a8d3d7":"RF.fit(scaler_train, y_train)","c5366dda":"plot_confusion_matrix(Lr_model, scaler_test, y_test)","90471be5":"print(classification_report(y_test, y_pred))","40b9cdc3":"# group \/ ensemble of models\nestimator = []\nestimator.append(('LR', \n                  LogisticRegression(solver ='lbfgs', \n                                     multi_class ='multinomial', \n                                     max_iter = 200)))\nestimator.append(('SVC', SVC(gamma ='auto', probability = True)))\nestimator.append(('DTC', DecisionTreeClassifier()))\n  \n# Voting Classifier with hard voting\nvot_hard = VotingClassifier(estimators = estimator, voting ='hard')\nvot_hard.fit(scaler_train, y_train)\ny_pred = vot_hard.predict(scaler_test)\n  \n# using accuracy_score metric to predict accuracy\nplot_confusion_matrix(Lr_model, scaler_test, y_test)\nprint(classification_report(y_test, y_pred))\nprint(\"Hard Voting\")\n  \n","278b30e5":"# Voting Classifier with soft voting\nvot_soft = VotingClassifier(estimators = estimator, voting ='soft')\nvot_soft.fit(scaler_train, y_train)\ny_pred = vot_soft.predict(scaler_test)\n  \n# using accuracy_score\nplot_confusion_matrix(Lr_model, scaler_test, y_test)\nprint(classification_report(y_test, y_pred))\nprint(\"Soft Voting \")","4082a72b":"result=pd.DataFrame(data=[79,82,80,79,77,83],index=['Logistic Regression','KNN','SVM','Tree','Random Forest','Ensemble VotingClassifier'],columns=['Accuracy'])","52df4e5c":"result","da727fcc":"# Import and print the dataset","b72be4cc":"# Exploratory Data Analysis","3d533407":"# Ensemble VotingClassifier has the best accuracy","b1956ffc":"# 5- Random Forest","3bae78d9":"# 1- Logistic Regression","b1867a3e":"# Normalization Data","7cd648df":"# Missing Values","acfe3ed8":"# 4- Tree","f460c35d":"# 6- Ensemble VotingClassifier","f02b7c3d":"# Result","97573e5e":"# 2- KNN","3fac2084":"# 3- SVM","797259c3":"# Fit and test all machin learning models"}}