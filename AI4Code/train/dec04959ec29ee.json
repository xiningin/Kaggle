{"cell_type":{"5de8f780":"code","e582ee53":"code","b06a877b":"code","ef3c7690":"code","3903893b":"code","071327ef":"code","a21eb03e":"code","9d700ce5":"code","d90c8629":"code","1c033855":"code","c3a26962":"code","b9a14d14":"code","de29e8b4":"code","76bcaf7b":"code","9fede553":"code","59f90866":"code","34baa5be":"code","2bdd9a3b":"code","a6a0aba8":"code","1fccf2af":"code","2fc85a7d":"code","44188ac3":"code","f40a2758":"markdown","b16f9820":"markdown","cedb763f":"markdown","827de5ae":"markdown","d7a88b07":"markdown","f4faf229":"markdown","31e8092e":"markdown","3395519f":"markdown","4abf44f2":"markdown"},"source":{"5de8f780":"import numpy as np  # Data manipulation\nimport pandas as pd # Dataframe manipulation \nimport matplotlib.pyplot as plt # Plotting the data and the results\nimport matplotlib.image as mpimg # For displaying imagees\n%matplotlib inline\nimport warnings\nfrom skimage.transform import resize\nfrom keras import models\nfrom keras.layers import Conv2D, Dense,MaxPooling2D, Flatten\nimport keras.preprocessing  as kp\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import regularizers\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e582ee53":"# Disable warnings\nwarnings.filterwarnings(\"ignore\")","b06a877b":"# init image generator that will applay on train and validation image.\ndf = ImageDataGenerator( rescale=1.\/255,\n    rotation_range=0,\n    shear_range=0.3,\n    zoom_range=0.3\n    )\n\n# generator that rescale test image to be fit for predict.\ndf_test = ImageDataGenerator(rescale=1.\/255)","ef3c7690":"# applay image generator on train image (rescale and make image size (128,128)).\ntrain_gen = df.flow_from_directory(\n    \"..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Train\/\",\n    batch_size =256,\n    class_mode = 'binary', \n    target_size = (128, 128))","3903893b":"# applay image generator on validation image (rescale and make image size (128,128)).\nval_gen = df.flow_from_directory(\n    \"..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Validation\",\n    batch_size =256,\n    class_mode = 'binary', \n    target_size = (128, 128))","071327ef":"# applay image generator on test image (rescale and make image size (128,128)).\ntest_gen=df_test.flow_from_directory(\n    '..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Test',\n    target_size=(128, 128),\n    batch_size=256,\n    class_mode='binary')","a21eb03e":"# create kernal matrix size.\nkernel_=(3,3) ","9d700ce5":"# create model.\nmodel=models.Sequential()","d90c8629":"# add layer to model\nmodel.add(Conv2D(16, kernel_size=kernel_,\n                 input_shape = (128,128, 3),\n                 activation = 'relu',padding='valid'))\n\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(32, kernel_size=kernel_, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(32, kernel_size=kernel_, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(64, kernel_size=kernel_, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(64, kernel_size=kernel_, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units = 128, activation = 'relu'))\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\nmodel.summary()","1c033855":"# set compole parameter optimizer algorthem, loss function and accuracy.\nmodel.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])","c3a26962":"# This checkpoint object will store the model parameters\n# in the file \"weights.hdf5\"\ncheckpoint = ModelCheckpoint('weights.hdf5', monitor='val_loss',\nsave_best_only=True)\n# Store in a list to be used during training\ncallbacks_list = [checkpoint]\n# Fit the model on a training set,","b9a14d14":"# fit model on train data.\ntraining = model.fit(train_gen, epochs=10, \n                steps_per_epoch=70,\n                validation_data=val_gen,\n                validation_steps=50,\n                callbacks=callbacks_list)","de29e8b4":"# plot loss function for train and validation.\nplt.style.use('seaborn')\nplt.title('loss and validation loss with epochs', fontsize=16)\nplt.plot(training.history['loss'], marker='o', color=\"green\", label=\"loss\")\nplt.plot(training.history['val_loss'], marker='o',color=\"orange\", label=\"val_loss\")\nplt.legend()\nplt.show()","76bcaf7b":"# plot accuracy for train and validation data.\nplt.title('accuracy and validation accuracy with epochs', fontsize=16)\nplt.plot(training.history['accuracy'], marker='o', color=\"green\", label=\"accuracy\")\nplt.plot(training.history['val_accuracy'], marker='o',color=\"orange\", label=\"val_accuracy\")\nplt.legend()\nplt.show()","9fede553":"# restor parameter for best epoch and predict test data.\nmodel.load_weights('\/kaggle\/working\/weights.hdf5')\nmodel.predict_classes(test_gen)","59f90866":"# evaluate test data calculate accuracy and loss.\nmodel.evaluate(test_gen)","34baa5be":"# predict gender by a float number between 0 to 1 \n# if number is more than 0.5 that indicate Male and vice versa.\nresults = model.predict(test_gen)\nresults.sum()","2bdd9a3b":"# calculate test accuracy and loss.\ntest_loss, test_acc = model.evaluate_generator(test_gen, steps=50)\nprint('Test Accuracy:', round(test_acc*100,2),\"%\")\nprint('Test Loss:',test_loss)","a6a0aba8":"# display kernel matrix which use to get convlution.\nkernel_matrix = model.layers[0].get_weights()[0][:,:,0,0]\nplt.imshow(kernel_matrix)\nplt.title('Kernel Matrix')\nplt.show()","1fccf2af":"# new data from outside kaggle website to test on it.\nmale_path = '..\/input\/male-test\/'\nfemale_path = '..\/input\/female-test\/'","2fc85a7d":"# funtion that display image, its gender and precentage of gender.\ndef show_image(im, row, col, result):\n    if int(result*2) >= 1:\n        precentage = (round(float(((result[0]-0.5 ) +0.5 )* 100 ),2))\n        title = f\"Male:{precentage}%\"\n    else:\n        precentage = (round(float(((0.5-result[0])+0.5)* 100 ),2))\n        title = f\"Female:{precentage}%\"\n    \n    ax[row][col].imshow(im)\n    ax[row][col].set_title(title)\n    ax[row][col].axis(\"off\")","44188ac3":"# create subplot for outside image.\nfig, ax = plt.subplots(4,2,figsize=(10,10))\n\n# loop on new image predict and display.\nfor row in range(4):\n    im_0 = plt.imread(male_path + str(row+1) + '.jpg')\n    im_1 = plt.imread(female_path + str(row+1) + '.jpg')\n    \n    im_0_resize = resize(im_0, (128, 128))\n    im_1_resize = resize(im_1, (128, 128))\n    \n    im_0_resize = np.expand_dims(im_0_resize, axis =0)\n    im_1_resize = np.expand_dims(im_1_resize, axis =0)\n    \n    result_0 = model.predict(im_0_resize)\n    result_1 = model.predict(im_1_resize)\n    \n    show_image(im_0, row, 0, result_0)\n    show_image(im_1, row, 1, result_1)\n    \nplt.show()","f40a2758":"# Reading Data","b16f9820":"**_The notebook is structured in the following way:_**\n- Read train, test, validation image.\n- Init models and create layers.\n- Compile model and fit model on train data.\n- Predict and test model.\n- Predict new image out of data.","cedb763f":"## Classified test image","827de5ae":"# Train model","d7a88b07":"**Model Layers**","f4faf229":"### Thanks for Read My NoteBook :)","31e8092e":"**Importing Needed Liberies**","3395519f":"## New data classifier","4abf44f2":"## Male & Female \ud83d\udc6b | Image Classification Using Keras\n![](https:\/\/github.com\/MhmdSyd\/needed_image\/blob\/main\/gender-roles.png?raw=true)"}}