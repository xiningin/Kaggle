{"cell_type":{"bbab651c":"code","4ccfbaeb":"code","4fec34f0":"code","10b2d0cd":"code","ac1a43da":"code","61657c6f":"code","d9cc9052":"code","9e1f90bb":"markdown","51b6b6fa":"markdown","db8f46d6":"markdown"},"source":{"bbab651c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPool2D\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nsns.set_style({'xtick.bottom':False,\n               'ytick.left':False,\n               'axes.spines.bottom': False,\n               'axes.spines.left': False,\n               'axes.spines.right': False,\n               'axes.spines.top': False})\n\n# Any results you write to the current directory are saved as output.","4ccfbaeb":"fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,15))\nimg1 = plt.imread(\"..\/input\/car_data\/car_data\/train\/Audi S4 Sedan 2007\/00159.jpg\")\nimg2 = plt.imread(\"..\/input\/car_data\/car_data\/train\/Aston Martin V8 Vantage Convertible 2012\/00065.jpg\")\nimg3 = plt.imread(\"..\/input\/car_data\/car_data\/train\/Bentley Continental Flying Spur Sedan 2007\/00057.jpg\")\nimg4 = plt.imread(\"..\/input\/car_data\/car_data\/train\/Bugatti Veyron 16.4 Coupe 2009\/01249.jpg\")\n\nax = axes[0,0]\nax1 = axes[0,1]\nax2 = axes[1,0]\nax3 = axes[1,1]\n\nax.imshow(img1)\nax1.imshow(img2)\nax2.imshow(img3)\nax3.imshow(img4)","4fec34f0":"cnn = Sequential()\n#Adding 1st Convolution and Pooling Layer\ncnn.add(Conv2D(32,kernel_size=(3,3),input_shape=(128,128,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2)))\ncnn.add(Dropout(0.2))\n#Adding 2nd Convolution and Pooling Layer\ncnn.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2)))\ncnn.add(Dropout(0.2))\n#Adding 3rd Convolution and Pooling Layer\ncnn.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2)))\ncnn.add(Dropout(0.2))\n#Adding 4th Convolution and Pooling Layer\ncnn.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2)))\ncnn.add(Dropout(0.2))\n#Adding 5th Convolution and Pooling Layer\ncnn.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2,2)))\ncnn.add(Dropout(0.2))\n\n#Flatten\ncnn.add(Flatten())\n\n#Adding Input and Output Layer\ncnn.add(Dense(units=256,activation='relu'))\ncnn.add(Dense(units=256,activation='relu'))\ncnn.add(Dense(units=256,activation='relu'))\ncnn.add(Dense(units=196,activation='sigmoid'))\n\ncnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","10b2d0cd":"#Data agumentation\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_data = train_datagen.flow_from_directory('..\/input\/car_data\/car_data\/train',\n                                              target_size=(128,128),\n                                              batch_size=32,\n                                              class_mode='categorical')\ntest_data = test_datagen.flow_from_directory('..\/input\/car_data\/car_data\/test',\n                                              target_size=(128,128),\n                                              batch_size=32,\n                                              class_mode='categorical')","ac1a43da":"history = cnn.fit_generator(train_data,\n                            steps_per_epoch=100,\n                            epochs=30,\n                            validation_data=test_data,\n                            validation_steps=50)","61657c6f":"vals = pd.DataFrame.from_dict(history.history)\nvals = pd.concat([pd.Series(range(0,30),name='epochs'),vals],axis=1)\nvals.head()","d9cc9052":"fig,(ax,ax1) = plt.subplots(nrows=2,ncols=1,figsize=(16,16))\nsns.scatterplot(x='epochs',y='acc',data=vals,ax=ax,color='r')\nsns.lineplot(x='epochs',y='val_acc',data=vals,ax=ax,color='g')\nsns.scatterplot(x='epochs',y='loss',data=vals,ax=ax1,color='r')\nsns.lineplot(x='epochs',y='val_loss',data=vals,ax=ax1,color='g')\nax.legend(labels=['Test Accuracy','Training Accuracy'])\nax1.legend(labels=['Test Loss','Training Loss'])","9e1f90bb":"**Let's create the model for classification**","51b6b6fa":"**In this notebook we are going to explore Stanford car dataset and classify cars using CNN**","db8f46d6":"**Lets look at some images**"}}