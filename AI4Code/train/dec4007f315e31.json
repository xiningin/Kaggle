{"cell_type":{"cde95910":"code","627a213c":"code","69a5721d":"code","229fce7a":"code","1217c5fd":"code","5ec6a481":"code","dc871837":"code","534409f9":"code","d12abce0":"code","f09d808f":"code","8e8749c6":"code","d89db294":"code","9b76826a":"code","af6bd163":"code","a78c253e":"code","475fa6a6":"code","79bea112":"code","6f1f8552":"markdown","d4fa0ed1":"markdown","0d499c7b":"markdown","dcee60c3":"markdown","d3126c9a":"markdown","59256f55":"markdown","3f95baea":"markdown","78f896d5":"markdown","8d82331d":"markdown","7da677cf":"markdown","a6a644a6":"markdown","25a32373":"markdown","1a85482c":"markdown","f3896dc8":"markdown","02b35047":"markdown"},"source":{"cde95910":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport os\nfrom shutil import copyfile, move\nfrom tqdm import tqdm\nimport h5py","627a213c":"print(tf.__version__)\nprint(tf.test.is_gpu_available())","69a5721d":"training_df = pd.read_csv(\"..\/input\/train.csv\")\ntraining_df.head()","229fce7a":"src = \"..\/input\/train\/train\/\"\ndst = \"..\/sorted_training\/\"\n\nos.mkdir(dst)\nos.mkdir(dst+\"true\")\nos.mkdir(dst+\"false\")\n\nwith tqdm(total=len(list(training_df.iterrows()))) as pbar:\n    for idx, row in training_df.iterrows():\n        pbar.update(1)\n        if row[\"has_cactus\"] == 1:\n            copyfile(src+row[\"id\"], dst+\"true\/\"+row[\"id\"])\n        else:\n            copyfile(src+row[\"id\"], dst+\"false\/\"+row[\"id\"])","1217c5fd":"src = \"..\/sorted_training\/\"\ndst = \"..\/sorted_validation\/\"\n\nos.mkdir(dst)\nos.mkdir(dst+\"true\")\nos.mkdir(dst+\"false\")\n\nvalidation_df = training_df.sample(n=int(len(training_df)\/10))\n\nwith tqdm(total=len(list(validation_df.iterrows()))) as pbar:\n    for idx, row in validation_df.iterrows():\n        pbar.update(1)\n        if row[\"has_cactus\"] == 1:\n            move(src+\"true\/\"+row[\"id\"], dst+\"true\/\"+row[\"id\"])\n        else:\n            move(src+\"false\/\"+row[\"id\"], dst+\"false\/\"+row[\"id\"])","5ec6a481":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, Input\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\nfrom tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","dc871837":"batch_size = 64\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    horizontal_flip=True,\n    vertical_flip=True)\n\ntrain_data_dir = \"..\/sorted_training\"\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    shuffle=True,\n    target_size=(32, 32),\n    batch_size=batch_size,\n    class_mode='binary')\n\n\nvalidation_datagen = ImageDataGenerator(rescale=1. \/ 255)\nvalidation_data_dir = \"..\/sorted_validation\"\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(32, 32),\n    batch_size=batch_size,\n    class_mode='binary')\n\ninput_shape = (32,32,3)\nnum_classes = 2\n","534409f9":"dropout_dense_layer = 0.6\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout_dense_layer))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout_dense_layer))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","d12abce0":"model.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(lr=0.001),\n              metrics=['accuracy'])","f09d808f":"callbacks = [EarlyStopping(monitor='val_loss', patience=25),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]","8e8749c6":"epochs = 100\nhistory = model.fit_generator(train_generator,\n          validation_data=validation_generator,\n          epochs=epochs,\n          verbose=1,\n          shuffle=True,\n          callbacks=callbacks)","d89db294":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.show()","9b76826a":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.show()","af6bd163":"model.load_weights(\"best_model.h5\")","a78c253e":"test_folder = \"..\/input\/test\/\"\ntest_datagen = ImageDataGenerator(\n    rescale=1. \/ 255)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_folder,\n    target_size=(32,32),\n    batch_size=1,\n    class_mode='binary',\n    shuffle=False\n)","475fa6a6":"pred=model.predict_generator(test_generator,verbose=1)\npred_binary = [0 if value<0.50 else 1 for value in pred]  ","79bea112":"csv_file = open(\"sample_submission_cnn.csv\",\"w\")\ncsv_file.write(\"id,has_cactus\\n\")\nfor filename, prediction in zip(test_generator.filenames,pred_binary):\n    name = filename.split(\"\/\")[1].replace(\".tif\",\"\")\n    csv_file.write(str(name)+\",\"+str(prediction)+\"\\n\")\ncsv_file.close()","6f1f8552":"# Load the test data and evaluate the model","d4fa0ed1":"# Load the dataset","0d499c7b":"Display the losses and accuracy of the model over the training and validation sets.","dcee60c3":"Some really insightful comments about deep learning model optimization can be found here (https:\/\/karpathy.github.io\/2019\/04\/25\/recipe\/ ). ","d3126c9a":"# Model Creation: Convolutional Neural Network","59256f55":"The dataset being relatively small, data augmentation is very important to generalise and learn what a cactus look like. Based on the fact that cactus detection seems like an easy problem and we're dealing with a small amount of data, the batch size is kept small as training will be quick anyway.","3f95baea":"Even though it is considered good practice to import all libraries at the beginning of a script, I tend to import the ones related to the model architecture right before, as it makes them visible and gives expectations to a reader as to what to find in the architecture.","78f896d5":"Just a quick check to make verify Tensorflow version and whether the GPU is found.","8d82331d":"I then extract the validation from the folder where I stored the training set. Note that this time, the files are moved and not just copied.","7da677cf":"Load the best performing model based on the validation loss.","a6a644a6":"In order to prepare the dataset and use Keras' ImageDataGenerator, it was decided to extract the images to a new folder where images are sorted into 2 folders, one for images with cacti, and one for images without. It is, therefore, required to load the .csv file provided to retrieve the groundtruth and copy the files in the right folder.","25a32373":"Generate the submission .csv file.","1a85482c":"### The goal of this kernel is to create a simple Convolution Neural Network that will allow to differentiate images that contains cacti from images that do not. While better results closer to 100% accuracy could be designed using layers from pre-trained models such as VGG16, we want to stick with a fairly simple CNN architecture and see how far we can go, and whether pre-trained layers are even needed.","f3896dc8":"# Prepare the data","02b35047":"# Training"}}