{"cell_type":{"cc76b545":"code","61c2a423":"code","c2b9c36d":"code","85a93c7e":"code","7d21a227":"code","be4cea30":"code","c6194f0d":"code","da709b69":"code","51dbb304":"code","4ea976ed":"code","50778b72":"code","87419153":"code","c9ec44eb":"code","20c3b7ab":"code","e542a6fc":"code","f82ac8b1":"code","e542f014":"code","e18bae24":"code","db53f90b":"code","da1f9621":"code","c6bc9ccc":"code","de4e2d67":"code","af4d24ef":"code","4a300afd":"code","cdbf17b0":"code","ba73cda9":"code","6d747c4d":"code","80091cbf":"code","ce440f29":"code","763166fb":"code","f66737ae":"code","95d4b44f":"code","6d9791c9":"code","5057c70a":"code","c027c3e8":"code","0b20b8f9":"code","bbc9a213":"code","2d045920":"code","de236f34":"code","7cd5efdd":"code","6f0de9ff":"code","9f412134":"code","6b2eefc1":"code","6c0d5c2a":"code","b8c915fc":"code","2214f5a5":"code","441f594c":"markdown","59ce04da":"markdown","1b0d1dea":"markdown","570c66c9":"markdown","8c283e60":"markdown","e7a3a302":"markdown","56bc2b2c":"markdown","eb5100ea":"markdown","ee45affa":"markdown","12dbf200":"markdown","1f5bc319":"markdown","bb0f4147":"markdown","abbf540e":"markdown","cb5d3e7b":"markdown","ee749900":"markdown","aeb0088e":"markdown","69d58525":"markdown","aac7ef31":"markdown","d5f9672e":"markdown","33867afc":"markdown","6e0178a7":"markdown","81ae5820":"markdown","42383ff1":"markdown","8d13fc78":"markdown","a6eebd82":"markdown","fe596ff2":"markdown","33a1e4c3":"markdown","5b0cd8be":"markdown","86855c9e":"markdown","571145fd":"markdown","b51bf77b":"markdown","a42b315c":"markdown"},"source":{"cc76b545":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport geopandas as gdp\nimport seaborn as sns\nimport matplotlib \nimport shapefile as shp\nfrom shapely.geometry import Point, Polygon\nimport matplotlib.pyplot as plt\nfrom pyproj import Proj, transform\nimport pyproj\nimport geopandas \nimport mplleaflet\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","61c2a423":"pop_2017 = geopandas.read_file(\"..\/input\/population-2017\/istanbul_mahalle_bazli_2017_nufus.dbf\")\nshp_tweet= geopandas.read_file(\"..\/input\/shapefile-deneme\/norm2_18apl17.shp\")\nPandas_Table=geopandas.read_file(\"..\/input\/normtwitter\/norm2_18apl17.dbf\")\nist_ilc=geopandas.read_file(\"..\/input\/icleler\/istanbul_ilce.dbf\")","c2b9c36d":"inProj = pyproj.Proj(init='epsg:4326')\n# resulting projection, WGS84, long, lat\noutProj = pyproj.Proj(\"+proj=tmerc +lat_0=0 +lon_0=30 +k=1 +x_0=500000 +y_0=0 +a=6378137.0 +b=6356752.3142  +units=m +no_defs\")\n","85a93c7e":"y = []\n\nfor xy in zip( Pandas_Table[\"lon\"], Pandas_Table[\"lat\"]):\n    a = transform(inProj,outProj,xy[0],xy[1])\n    y.append(Point(a))\n    \ngeometry = y\n","7d21a227":"crs = {'init': 'epsg:4326'}\nPandas_Table = gdp.GeoDataFrame(Pandas_Table,\n                         crs=crs,\n                         geometry=geometry)","be4cea30":"pop_2017.tail()\n","c6194f0d":"ist_ilc.head(40)","da709b69":"Pandas_Table.head()","51dbb304":"data_wknd = Pandas_Table \ndata_wknd['inserttime'] = pd.to_datetime(data_wknd['inserttime'])\nstart_date = '2017-04-02 01:00:09.631735+03:00'\nend_date = '2017-04-03 23:59:38.891808+03:00'\nmask = (data_wknd['inserttime'] > start_date) & (data_wknd['inserttime'] <= end_date)","4ea976ed":"data_wknd = data_wknd.loc[mask].reset_index()\ndata_wknd.head()\ndata_wknd.info()","50778b72":"from math import sqrt\narrayunique=data_wknd.twitteruse.unique()\n\n\nuserdf = pd.DataFrame(arrayunique, columns =['twitteruse']) \nuserdf['lat']=0\nuserdf['lon']=0\nuserdf['arrr']=0\n\n\n\ndef fonkfonk(ts):\n    yuyo=data_wknd[data_wknd[\"twitteruse\"] == ts].reset_index()\n    aray = []\n    count = 0\n    for i in range(0,yuyo.shape[0]):\n        count = 0\n        for j in range(0,yuyo.shape[0]):\n            if sqrt(((yuyo['lat'][i]-yuyo['lat'][j])**2 ) + ((yuyo['lon'][i]-yuyo['lon'][j])**2 ))<0.0105:\n                count = count + 1\n        aray.append(count)\n    return [yuyo['lat'][aray.index(max(aray))],yuyo['lon'][aray.index(max(aray))]]\n\n\n\nuserdf['arrr'] = userdf['twitteruse'].apply(fonkfonk)\n\n\n\nuserdf.head()","87419153":"def hr_func_2(ts):\n    return ts[0]\ndef hr_func_3(ts):\n    return ts[1]\n\n\nuserdf['lat'] = userdf['arrr'].apply(hr_func_2)\nuserdf['lon'] = userdf['arrr'].apply(hr_func_3)\nuserdf.head()","c9ec44eb":"geometry = [Point(xy) for xy in zip( userdf[\"lon\"], userdf[\"lat\"])]\ngeometry[:3]","20c3b7ab":"l = []\n\nfor xy in zip( userdf[\"lon\"], userdf[\"lat\"]):\n    a = transform(inProj,outProj,xy[0],xy[1])\n    l.append(Point(a))\n    \ngeometry = l","e542a6fc":"crs = {'init': 'epsg:4326'}\nuserdf = gdp.GeoDataFrame(userdf,\n                         crs=crs,\n                         geometry=geometry)","f82ac8b1":"userdf.info()","e542f014":"ist_ilc['count'] = 0\narar\u0131m=[]             \n\na = 0\nfor i in range (1, ist_ilc.shape[0]-1):\n    for j in range(1, userdf.shape[0]):\n        if ist_ilc.geometry[i].contains(userdf.geometry[j]):\n            a = a + 1\n    arar\u0131m.append(a)\n    print(i)\n    a=0\n    \ntoplama_cnt = pd.concat([ist_ilc,pd.DataFrame(arar\u0131m,columns =['count3']) ], axis=1, sort=False)\ntoplama_cnt.head() ","e18bae24":"pop_2017['count'] = 0\narar\u0131m=[]\n\na = 0\nfor i in range (1, pop_2017.shape[0]-1):\n    for j in range(1, userdf.shape[0]):\n        if pop_2017.geometry[i].contains(userdf.geometry[j]):\n            a = a + 1\n    arar\u0131m.append(a)\n    print(i)\n    a=0\n    \ntoplama = pd.concat([pop_2017,pd.DataFrame(arar\u0131m,columns =['count3']) ], axis=1, sort=False)\ntoplama.head() ","db53f90b":"aray2=[]\n\nfor i in range (0, toplama_cnt.shape[0]-1):\n    if toplama_cnt['NUFUS_5747'][i]>0:\n        aray2.append(toplama_cnt['count3'][i]\/toplama_cnt['NUFUS_5747'][i])\n    else:\n        aray2.append(0)\n\ntoplama2 = pd.concat([toplama_cnt,pd.DataFrame(aray2,columns =['random1']) ], axis=1, sort=False)\n\ntoplama2.head(100)","da1f9621":"aray2=[]\n\nfor i in range (0, toplama.shape[0]-1):\n    if toplama['nufus17'][i]>0:\n        aray2.append(toplama['count3'][i]\/toplama['nufus17'][i])\n    else:\n        aray2.append(0)\n\ntoplama3 = pd.concat([toplama,pd.DataFrame(aray2,columns =['random1']) ], axis=1, sort=False)\n\ntoplama3.head(100)","c6bc9ccc":"toplama2.describe()","de4e2d67":"toplama3.describe()","af4d24ef":"toplama2['random1'].fillna(0, inplace=True)\ntoplama2['count3'].fillna(0, inplace=True)","4a300afd":"toplama3['random1'].fillna(0, inplace=True)\ntoplama3['count3'].fillna(0, inplace=True)","cdbf17b0":"toplama2['random3']=0\n\ndef stabilizer(ts):\n    if ts > 0.006:\n        return 0.006\n    else: \n        return ts \n\ntoplama2['random3'] = toplama2['random1'].apply(stabilizer)\ntoplama2.head()","ba73cda9":"toplama3['random3']=0\n\ndef stabilizer(ts):\n    if ts > 0.01:\n        return 0.01\n    else: \n        return ts \n\ntoplama3['random3'] = toplama3['random1'].apply(stabilizer)\ntoplama3.head()\n","6d747c4d":"liste=[0,0,0,0]\nliste[0]=toplama2['random1'].max()\nliste[1]=toplama2['random1'].min()\nliste[2]=toplama3['random1'].max()\nliste[3]=toplama3['random1'].min()\nliste","80091cbf":"from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\nfrom mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n\n# set a variable that will call whatever column we want to visualise on the map\nvariable = 'random3'\n# set the range for the choropleth\nvmin, vmax = 0, 3.2\n# create figure and axes for Matplotlib\nfig, ax = plt.subplots(1, figsize=(20, 20))\n# create map\ntoplama2.plot(column=variable, cmap='Paired', linewidth=0.8, ax=ax, edgecolor='0.8')\nax.axis('on')\n# add a title\nax.set_title('\u0130stanbul Twitter Kullan\u0131c\u0131 Yo\u011funlu\u011fu Haritas\u0131', fontdict={'fontsize': '25', 'fontweight' : '3'})\n\n# Create colorbar as a legend\nsm = plt.cm.ScalarMappable(cmap='Paired', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n# empty array for the data range\nsm._A = []\n# add the colorbar to the figure\ncbar = fig.colorbar(sm,cax=fig.add_axes([0.85, 0.50, 0.009, 0.17]))","ce440f29":"from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\nfrom mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n\n# set a variable that will call whatever column we want to visualise on the map\nvariable = 'random3'\n# set the range for the choropleth\nvmin, vmax = 0, 3.2\n# create figure and axes for Matplotlib\nfig, ax = plt.subplots(1, figsize=(20, 20))\n# create map\ntoplama3.plot(column=variable, cmap='Paired', linewidth=0.8, ax=ax, edgecolor='0.8')\nax.axis('on')\n# add a title\nax.set_title('\u0130stanbul Twitter Kullan\u0131c\u0131 Yo\u011funlu\u011fu Haritas\u0131', fontdict={'fontsize': '25', 'fontweight' : '3'})\n\n# Create colorbar as a legend\nsm = plt.cm.ScalarMappable(cmap='Paired', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n# empty array for the data range\nsm._A = []\n# add the colorbar to the figure\ncbar = fig.colorbar(sm,cax=fig.add_axes([0.85, 0.50, 0.009, 0.17]))","763166fb":"liste=[0,0]\nliste[0]=pop_2017['nufus17'].max()\nliste[1]=pop_2017['nufus17'].min()\nliste","f66737ae":"pop_2017['nufus17'].fillna(0, inplace=True)","95d4b44f":"from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\nfrom mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n\n# set a variable that will call whatever column we want to visualise on the map\nvariable = 'nufus17'\n# set the range for the choropleth\nvmin, vmax = 0, 100000\n# create figure and axes for Matplotlib\nfig, ax = plt.subplots(1, figsize=(20, 20))\n# create map\npop_2017.plot(column=variable, cmap='viridis_r', linewidth=0.8, ax=ax, edgecolor='0.8')\nax.axis('on')\n# add a title\nax.set_title('\u0130stanbul Nufus Verisi', fontdict={'fontsize': '25', 'fontweight' : '3'})\n\n# Create colorbar as a legend\nsm = plt.cm.ScalarMappable(cmap='viridis_r', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n# empty array for the data range\nsm._A = []\n# add the colorbar to the figure\ncbar = fig.colorbar(sm,cax=fig.add_axes([0.85, 0.50, 0.009, 0.17]))","6d9791c9":"from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\nfrom mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n\n# set a variable that will call whatever column we want to visualise on the map\nvariable = 'NUFUS_5747'\n# set the range for the choropleth\nvmin, vmax = 0, 720000\n# create figure and axes for Matplotlib\nfig, ax = plt.subplots(1, figsize=(20, 20))\n# create map\nist_ilc.plot(column=variable, cmap='viridis_r', linewidth=0.8, ax=ax, edgecolor='0.8')\nax.axis('on')\n# add a title\nax.set_title('\u0130stanbul Nufus Verisi', fontdict={'fontsize': '25', 'fontweight' : '3'})\n\n# Create colorbar as a legend\nsm = plt.cm.ScalarMappable(cmap='viridis_r', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n# empty array for the data range\nsm._A = []\n# add the colorbar to the figure\ncbar = fig.colorbar(sm,cax=fig.add_axes([0.85, 0.50, 0.009, 0.17]))","5057c70a":"ax = pop_2017.plot(figsize=(20, 20),alpha='0.6',edgecolor='0.8',color='grey')\nax.axis('off')\nuserdf.plot(ax=ax, alpha=0.3,color='tomato',markersize=1)\nax.set_title('\u0130stanbul Nisan 2017 Tweet Da\u011f\u0131l\u0131m\u0131', fontdict={'fontsize': '25', 'fontweight' : '3'})","c027c3e8":"ax = pop_2017.plot(figsize=(20, 20),alpha='0.6',edgecolor='0.8',color='grey')\nax.axis('on')\nPandas_Table.plot(ax=ax, alpha=0.3,color='g',markersize=1)\nax.set_title('\u0130stanbul Nisan 2017 Tweet Da\u011f\u0131l\u0131m\u0131', fontdict={'fontsize': '25', 'fontweight' : '3'})","0b20b8f9":"data_fw = Pandas_Table \ndata_fw['inserttime'] = pd.to_datetime(data_fw['inserttime'])\nstart_date = '2017-04-01 00:00:00.615668+03:00'\nend_date = '2017-04-10 00:00:00.615668+03:00'\nmask = (data_fw['inserttime'] > start_date) & (data_fw['inserttime'] <= end_date)\ndata_fw = data_fw.loc[mask]\ndata_fw.head()","bbc9a213":"data_sw = Pandas_Table \ndata_sw['inserttime'] = pd.to_datetime(data_sw['inserttime'])\nstart_date = '2017-04-10 00:00:00.615668+03:00'\nend_date = '2017-04-25 00:00:00.891808+03:00'\nmask = (data_sw['inserttime'] > start_date) & (data_sw['inserttime'] <= end_date)\ndata_sw = data_sw.loc[mask]\ndata_sw.info()","2d045920":"ax = pop_2017.plot(figsize=(20, 20),alpha='0.6',edgecolor='0.8',color='silver')\nax.axis('on')\nuserdf.plot(ax=ax, alpha=0.7,color='darkorange',markersize=1)\nax.set_title('Twitter Kullan\u0131c\u0131 Da\u011f\u0131l\u0131m\u0131', fontdict={'fontsize': '25', 'fontweight' : '3'})","de236f34":"ax = pop_2017.plot(figsize=(20, 20),alpha='0.6',edgecolor='0.8',color='silver')\nax.axis('on')\ndata_fw.plot(ax=ax, alpha=0.4,color='darkred',markersize=1)\nax.set_title('\u0130lk Haftan\u0131n Tweet Da\u011f\u0131l\u0131m\u0131', fontdict={'fontsize': '25', 'fontweight' : '3'})","7cd5efdd":"import folium\nmap_osm = folium.Map(location=[41.109550, 28.989620], tiles='cartodbpositron', zoom_start=10, control_scale=True,prefer_canvas=True)\nmap_osm","6f0de9ff":"from folium.plugins import HeatMap\ndf_copy = userdf.copy()\ndf_copy['count'] = 1\nHeatMap(data=df_copy[['lat', 'lon', 'count']].groupby(['lat', 'lon']).sum().reset_index().values.tolist(), \n        radius=8, max_zoom=13).add_to(map_osm)\nmap_osm","9f412134":"ad = Pandas_Table\nad['geometry'] = ad['geometry'].to_crs(epsg=4326)\nad['geoid'] = ad.index.astype(str)\n","6b2eefc1":"toplama2['geoid'] = toplama2.index.astype(str)\ndata= toplama2[['geoid','count3','geometry']]\n\ndata.head()\n","6c0d5c2a":"#data = data.loc[(data['nufus17'] > 0) & (data['nufus17'] <= 500)]\ndata = data.to_crs(epsg=4326)\nprint(data.crs)\ndata.info()\ndata.head()","b8c915fc":"from folium.plugins import MarkerCluster\n\n#marker_cluster = folium.MarkerCluster().add_to(map_osm)\n\nmap_osm.choropleth(geo_str=jsontxt, data=data, columns=['geoid', 'nufus17'], key_on=\"feature.id\",\n                   fill_color='YlOrRd', fill_opacity=0.9, line_opacity=0.2, line_color='white', line_weight=0,\n                   threshold_scale=[100, 250, 500, 1000, 2000],\n                   legend_name='Population in Istanbul', highlight=False, smooth_factor=1.0)","2214f5a5":"import folium\n\nm = folium.Map(location=[41.109550, 28.989620], tiles = 'cartodbpositron', zoom_start=10, control_scale=True)\n\nfolium.Choropleth(\n    geo_data=data,\n    name='Population in 2017',\n    data=data,\n    columns=['geoid', 'count3'],\n    key_on='feature.id',\n    fill_color='YlOrRd',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    line_color='white',\n    line_weight=0,\n    highlight=False,\n    smooth_factor=1.0,).add_to(m)\n    #threshold_scale=[100, 250, 500, 1000, 2000],\n    #legend_name= 'Population in \u0130stanbul'\nm","441f594c":"**Creating Choropleth Map of Normalized Data**","59ce04da":"**Reading Multiple Geodata Sources **","1b0d1dea":"* For Counties ","570c66c9":"**Clipping Weekend from DataSet**","8c283e60":"**Creating Map by overlaping two plots**","e7a3a302":"Fist Week ","56bc2b2c":"**Converting Lat\/Long to Projected Coordinates **","eb5100ea":"* * **Creating User Unique DataFrame of Data Weekend**","ee45affa":"**Folium **","12dbf200":"from math import sqrt\narrayunique=Pandas_Table.twitteruse.unique()\n\n\nyenidf = pd.DataFrame(arrayunique, columns =['twitteruse']) \nyenidf['lat']=0\nyenidf['lon']=0\nyenidf['arrr']=0\n\n\n\ndef fonkfonk(ts):\n    yuyo=Pandas_Table[Pandas_Table[\"twitteruse\"] == ts].reset_index()\n    aray = []\n    count = 0\n    for i in range(0,yuyo.shape[0]):\n        count = 0\n        for j in range(0,yuyo.shape[0]):\n            if sqrt(((yuyo['lat'][i]-yuyo['lat'][j])**2 ) + ((yuyo['lon'][i]-yuyo['lon'][j])**2 ))<0.0105:\n                count = count + 1\n        aray.append(count)\n    return [yuyo['lat'][aray.index(max(aray))],yuyo['lon'][aray.index(max(aray))]]\n\n\n\nyenidf['arrr'] = yenidf['twitteruse'].apply(fonkfonk)\n\n\n\nyenidf.head()","1f5bc319":"Users Only","bb0f4147":"crs = {'init': 'epsg:4326'}\nyenidf = gdp.GeoDataFrame(yenidf,\n                         crs=crs,\n                         geometry=geometry)","abbf540e":"from math import sqrt\narrayunique=Pandas_Table.twitteruse.unique()\n\n\nyenidf = pd.DataFrame(arrayunique, columns =['twitteruse']) \nyenidf['lat']=0\nyenidf['lon']=0\n\n\n\ndef fonkfonk(ts):\n    yuyo=Pandas_Table[Pandas_Table[\"twitteruse\"] == ts].reset_index()\n    aray = []\n    count = 0\n    for i in range(0,yuyo.shape[0]):\n        count = 0\n        for j in range(0,yuyo.shape[0]):\n            if sqrt(((yuyo['lat'][i]-yuyo['lat'][j])**2 ) + ((yuyo['lon'][i]-yuyo['lon'][j])**2 ))<0.0105:\n                count = count + 1\n        aray.append(count)\n    return yuyo['lat'][aray.index(max(aray))]\n\ndef fonkfonk2(ts):\n    yuyo=Pandas_Table[Pandas_Table[\"twitteruse\"] == ts].reset_index()\n    aray = []\n    count = 0\n    for i in range(0,yuyo.shape[0]):\n        count = 0\n        for j in range(0,yuyo.shape[0]):\n            if sqrt(((yuyo['lat'][i]-yuyo['lat'][j])**2 ) + ((yuyo['lon'][i]-yuyo['lon'][j])**2 ))<0.0105:\n                count = count + 1\n        aray.append(count)\n    return yuyo['lon'][aray.index(max(aray))]\n\n\n\nyenidf['lat'] = yenidf['twitteruse'].apply(fonkfonk)\nyenidf['lon'] = yenidf['twitteruse'].apply(fonkfonk2)\n\n\nyenidf.head()","cb5d3e7b":"**Creating Heatmap**","ee749900":"Second Week","aeb0088e":"All Tweets","69d58525":"geometry = [Point(xy) for xy in zip( yenidf[\"lon\"], yenidf[\"lat\"])]\ngeometry[:3]\n\n","aac7ef31":"**Arranging Values of Normalized Data Column**","d5f9672e":"* For Neighborhoods","33867afc":"* For Counties","6e0178a7":"**Checking Points whether in Polygons **","81ae5820":"* * **Creating User Unique DataFrame** ","42383ff1":"**Choropleth Map with Folium**","8d13fc78":"* For Neighborhoods","a6eebd82":"l = []\n\nfor xy in zip( yenidf[\"lon\"], yenidf[\"lat\"]):\n    a = transform(inProj,outProj,xy[0],xy[1])\n    l.append(Point(a))\n    \ngeometry = l","fe596ff2":"**Choropleth Map**","33a1e4c3":"**Analyzing Dataframes**","5b0cd8be":"def hr_func_2(ts):\n    return ts[0]\ndef hr_func_3(ts):\n    return ts[1]\n\n\nyenidf['lat'] = yenidf['arrr'].apply(hr_func_2)\nyenidf['lon'] = yenidf['arrr'].apply(hr_func_3)\nyenidf.head()","86855c9e":"*** Fast Method**","571145fd":"**Assigning the results to the new Dataframe**","b51bf77b":"**Adding Geometry Coloumn to new DataFrame**","a42b315c":"  **Creating User Unique DataFrame**\n* **Slow method  **"}}