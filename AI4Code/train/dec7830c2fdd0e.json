{"cell_type":{"9d460f23":"code","eccbec32":"code","ba637880":"code","9f5143dc":"code","c2ef1170":"code","b0f76435":"code","e4977c83":"code","a5b2465b":"code","d2652db7":"code","0a81f0fd":"code","f0ba8977":"code","b18c69b2":"code","a53acc2b":"code","b2f24cf5":"markdown","8b48eb3f":"markdown","48a4df33":"markdown","84adf6a1":"markdown","4efa2d62":"markdown"},"source":{"9d460f23":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eccbec32":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split, cross_val_predict,cross_validate\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import IsolationForest","ba637880":"#Exploring the Data\ndata = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndata.head()","9f5143dc":"#Missing Values\ndata.isnull().sum()","c2ef1170":"data.info()","b0f76435":"X = data.iloc[:,0:20]  #independent columns\ny = data.iloc[:,-1]    #target column i.e price range\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","e4977c83":"Features = ['time','ejection_fraction','serum_creatinine']\nx = data[Features]\ny = data[\"DEATH_EVENT\"]\n\n# Train Test split\ntrain_x, test_x,train_y,test_y = train_test_split(x,y, test_size=0.2, random_state=2)","a5b2465b":"#KNN Finding the Best K\nfrom sklearn.neighbors import KNeighborsClassifier\nmisclassified = []\nfor i in range(1, 30):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(train_x,train_y)\n    pred_i = knn.predict(test_x)\n    misclassified.append((test_y != pred_i).sum())\nprint(\"Misclassified = \", misclassified)","d2652db7":"#knn\nKNN_classifier = KNeighborsClassifier(n_neighbors=11)\nKNN_classifier.fit(train_x, train_y)\nprediction =  KNN_classifier.predict(test_x)\naccuracy_score = accuracy_score(test_y,prediction)\nprint(\"accuracy_score without outlier KNN=11 :\",accuracy_score)","0a81f0fd":"#Printing KNN Accuracy and Confusion Matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(test_y, prediction)\nac = accuracy_score(test_y, prediction)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Heart Not Failed', 'Heart Fail']); ax.yaxis.set_ticklabels(['Heart Not Failed', 'Heart Fail']);\n","f0ba8977":"#Finding the Best Max Leaf Node Value\nfrom sklearn.tree import DecisionTreeClassifier\n#from sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor leaves in range(2,10):\n    classifier = DecisionTreeClassifier(max_leaf_nodes = leaves, random_state=0, criterion='entropy')\n    classifier.fit(train_x, train_y)\n    y_pred = classifier.predict(test_x)\n    list1.append(accuracy_score(test_y,y_pred))\n#print(mylist)\nplt.plot(list(range(2,10)), list1)\nplt.show()\n","b18c69b2":"#Decision Tree Classifier\nclassifier = DecisionTreeClassifier(max_leaf_nodes = 2, random_state=0, criterion='entropy')\nclassifier.fit(train_x, train_y)\ny_pred = classifier.predict(test_x)\n#from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(test_y, y_pred)\nac = accuracy_score(test_y, y_pred)\nprint(\"Dec Tree Classifier acc without outlier:\",ac)\nprint(\"Confusion Matrix:\",cm)","a53acc2b":"#Plotting Confusion Matrix\n#cm = confusion_matrix(test_y, prediction)\n#ac = accuracy_score(test_y, prediction)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Heart Not Failed', 'Heart Fail']); ax.yaxis.set_ticklabels(['Heart Not Failed', 'Heart Fail']);","b2f24cf5":"**Model 1: KNN**","8b48eb3f":"**Feature Selection**","48a4df33":"**Model 2: Decision Tree Classifier**","84adf6a1":"**Import Libraries**","4efa2d62":"**Data Preprocessing**"}}