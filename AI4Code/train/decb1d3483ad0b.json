{"cell_type":{"8d16ddd1":"code","a4a4d8e6":"code","f23a6528":"code","a6578364":"code","98ac48c7":"code","e538c2fb":"code","0b375e35":"code","d000c4c9":"code","33dce7a1":"code","4fa1dc2c":"code","70878393":"code","c3fd2965":"code","70b40099":"code","33a25165":"code","20696a14":"code","a217712e":"code","e47c3347":"code","ec3e2c10":"code","c2a0ad34":"code","a01e4895":"code","5c76d9f4":"code","01b9a38d":"code","ce922d2e":"code","c5cabcc8":"code","a55ec070":"code","0622f424":"code","ea33ac0a":"code","907e9d26":"code","a75c1106":"code","2aa759e3":"code","1e6424e5":"code","7f0f453a":"code","7160bb2c":"code","91b4dc6f":"code","b022e2b0":"code","1aae05c3":"code","094f1497":"code","8580b158":"code","aa28c389":"code","b2a66795":"code","18be1f8d":"code","990a5994":"code","c35ebf40":"code","976730ae":"code","6a710b9f":"code","771efbd6":"code","90e45c42":"code","5fb92711":"code","a04dbae9":"code","c67bf1ce":"code","22bf405d":"code","fb12cb3f":"code","3a94ffba":"code","e22ad294":"code","5b1f4cdc":"code","5f52b57b":"code","f0753a4e":"code","0b87cd44":"code","60cdcadf":"code","620141a1":"code","1a1ea617":"code","cc71bcac":"code","c89f31c9":"code","c7315f71":"code","c6bf0fc9":"code","3f487033":"code","5326dee9":"code","a319929c":"code","0bb37cbc":"code","3dc91f63":"code","6fd0f1c8":"code","3c9f1972":"markdown","ac4f3047":"markdown","d616c8f7":"markdown","63977cf3":"markdown","59ab5627":"markdown","46048a01":"markdown","b4c8050b":"markdown","f16ede76":"markdown","0d6f5e53":"markdown","b7e1572d":"markdown","6669104a":"markdown","095bf3dc":"markdown","80a2ce61":"markdown","b5e569a7":"markdown","ecb3015a":"markdown","c705798c":"markdown","6b393254":"markdown","774d6143":"markdown","aaf355c0":"markdown","4bcf3652":"markdown"},"source":{"8d16ddd1":"import numpy as np\nimport pandas as pd\nimport librosa\nimport librosa.display\nimport soundfile as sf\nimport scipy.signal as signal\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport IPython.display as ipd\nfrom IPython.display import YouTubeVideo","a4a4d8e6":"data_tp_df=pd.read_csv('\/kaggle\/input\/rfcx-species-audio-detection\/train_tp.csv')\ndata_fp_df=pd.read_csv('\/kaggle\/input\/rfcx-species-audio-detection\/train_fp.csv')","f23a6528":"data_tp_df.head()","a6578364":"data_fp_df.head()","98ac48c7":"data_tp_df.info()","e538c2fb":"data_fp_df.info()","0b375e35":"def plot_count(feature, title, df, size=1):\n    '''\n    Plot count of classes \/ feature\n    param: feature - the feature to analyze\n    param: title - title to add to the graph\n    param: df - dataframe from which we plot feature's classes distribution \n    param: size - default 1.\n    '''\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:30], palette='Set1')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()  ","d000c4c9":"plot_count('species_id', 'TP: Species ID', data_tp_df, size=4)","33dce7a1":"plot_count('songtype_id', 'TP: Songtype ID', data_tp_df, size=2)","4fa1dc2c":"plot_count('species_id', 'FP: Species ID', data_fp_df, size=4)","70878393":"plot_count('songtype_id', 'FP: Songtype ID', data_fp_df, size=2)","c3fd2965":"def plot_feature_distribution(data_df, feature, feature2, title, kde_mode=False, hist_mode=True):\n    f, ax = plt.subplots(1,1, figsize=(12,6))\n    for item in list(data_df[feature2].unique()):\n        d_df = data_df.loc[data_df[feature2]==item]\n        try:\n            sns.distplot(d_df[feature], kde=kde_mode, hist=hist_mode, label=item)\n        except:\n            pass\n    plt.legend(labels=list(data_df[feature2].unique()), bbox_to_anchor=(1, 1), loc='upper right', ncol=2)\n    plt.title(title)\n    plt.show()","70b40099":"plot_feature_distribution(data_tp_df, 'f_min', 'species_id', \"Minimum frequency distribution, TP data, grouped by species id\")","33a25165":"plot_feature_distribution(data_tp_df, 'f_max', 'species_id', \"Maximum frequency distribution, TP data, grouped by species id\")","20696a14":"plot_feature_distribution(data_fp_df, 'f_min', 'species_id', \"Minimum frequency distribution, FP data, grouped by species id\")","a217712e":"plot_feature_distribution(data_fp_df, 'f_max', 'species_id', \"Maximum frequency distribution, FP data, grouped by species id\")","e47c3347":"plot_feature_distribution(data_tp_df, 'f_min', 'songtype_id', \"Minimum frequency distribution, TP data, grouped by songtype id\")","ec3e2c10":"plot_feature_distribution(data_tp_df, 'f_max', 'songtype_id', \"Maximum frequency distribution, TP data, grouped by songtype id\")","c2a0ad34":"plot_feature_distribution(data_fp_df, 'f_min', 'songtype_id', \"Minimum frequency distribution, FP data, grouped by songtype id\")","a01e4895":"plot_feature_distribution(data_fp_df, 'f_max', 'songtype_id', \"Maximum frequency distribution, FP data, grouped by songtype id\")","5c76d9f4":"plot_feature_distribution(data_tp_df, 't_min', 'species_id', \n                          \"Minimum time distribution, TP data, grouped by species id\", kde_mode=True, hist_mode=False)","01b9a38d":"plot_feature_distribution(data_tp_df, 't_max', 'species_id', \n                          \"Max time distribution, TP data, grouped by species id\", kde_mode=True, hist_mode=False)","ce922d2e":"plot_feature_distribution(data_tp_df, 't_min', 'songtype_id', \n                          \"Minimum time distribution, TP data, grouped by songtype id\", kde_mode=True, hist_mode=False)","c5cabcc8":"plot_feature_distribution(data_tp_df, 't_max', 'songtype_id', \n                          \"Max time distribution, TP data, grouped by songtype id\", kde_mode=True, hist_mode=False)","a55ec070":"plot_feature_distribution(data_fp_df, 't_min', 'species_id', \n                          \"Minimum time distribution, FP data, grouped by species id\", kde_mode=True, hist_mode=False)","0622f424":"plot_feature_distribution(data_fp_df, 't_max', 'species_id', \n                          \"Max time distribution, FP data, grouped by species id\", kde_mode=True, hist_mode=False)","ea33ac0a":"plot_feature_distribution(data_fp_df, 't_min', 'songtype_id', \n                          \"Minimum time distribution, FP data, grouped by songtype id\", kde_mode=True, hist_mode=False)","907e9d26":"plot_feature_distribution(data_fp_df, 't_max', 'songtype_id', \n                          \"Max time distribution, FP data, grouped by songtype id\", kde_mode=True, hist_mode=False)","a75c1106":"YouTubeVideo(\"7iUrEOy3coA\", width=800, height=450)","2aa759e3":"def plot_audio_file(data_df, idx):\n    audio_file_path = '\/kaggle\/input\/rfcx-species-audio-detection\/train\/'+data_df.recording_id[idx]+'.flac'\n    plt.figure(figsize=(12,6))\n    x , sr = librosa.load(audio_file_path)\n    librosa.display.waveplot(x, sr=sr)\n    plt.gca().set_title(f\"Waveplot - file: {data_df.recording_id[idx]}\")\n    plt.show()","1e6424e5":"def plot_spectrogram(data_df, idx):\n    audio_file_path = '\/kaggle\/input\/rfcx-species-audio-detection\/train\/'+data_df.recording_id[idx]+'.flac'\n    plt.figure(figsize=(12,6))\n    x , sr = librosa.load(audio_file_path)\n    xs = librosa.stft(x)\n    xdb = librosa.amplitude_to_db(abs(xs))\n    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.gca().set_title(f\"Spectrogram - file: {data_df.recording_id[idx]}\")\n    plt.colorbar()","7f0f453a":"def plot_mel_spectrogram(data_df, idx):\n    audio_file_path = '\/kaggle\/input\/rfcx-species-audio-detection\/train\/'+data_df.recording_id[idx]+'.flac'\n    plt.figure(figsize=(12,6))\n    x , sr = librosa.load(audio_file_path)\n    xs = librosa.feature.melspectrogram(x)\n    xdb = librosa.amplitude_to_db(abs(xs))\n    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.gca().set_title(f\"Mel spectrogram - file: {data_df.recording_id[idx]}\")\n    plt.colorbar()","7160bb2c":"def plot_harmonics_and_perceptual(data_df, idx):\n    audio_file_path = '\/kaggle\/input\/rfcx-species-audio-detection\/train\/'+data_df.recording_id[idx]+'.flac'\n    plt.figure(figsize=(12,6))\n    x , sr = librosa.load(audio_file_path)\n    y_harmonics, y_perceptual = librosa.effects.hpss(x)\n    plt.plot(y_perceptual, color = '#BBAA12')\n    plt.plot(y_harmonics, color = '#12AABB')\n    plt.legend((\"Perceptual\", \"Harmonics\"))\n    plt.title(f\"Harmonics and Perceptual - file: {data_df.recording_id[idx]}\")","91b4dc6f":"def plot_chroma_feature(data_df, idx):\n    hop_length=12\n    audio_file_path = '\/kaggle\/input\/rfcx-species-audio-detection\/train\/'+data_df.recording_id[idx]+'.flac'\n    plt.figure(figsize=(12,6))\n    x , sr = librosa.load(audio_file_path)\n    chromagram = librosa.feature.chroma_stft(x)\n    librosa.display.specshow(chromagram, sr=sr, x_axis='time', y_axis='chroma',hop_length=hop_length, cmap='coolwarm')\n    plt.title(f\"Chroma feature - file: {data_df.recording_id[idx]}\")","b022e2b0":"def play_sound(data_df, idx):\n    audio_file_path = '\/kaggle\/input\/rfcx-species-audio-detection\/train\/'+data_df.recording_id[idx]+'.flac'\n    return ipd.Audio(audio_file_path)","1aae05c3":"plot_audio_file(data_tp_df, 20)","094f1497":"plot_spectrogram(data_tp_df, 20)","8580b158":"plot_mel_spectrogram(data_tp_df, 20)","aa28c389":"plot_chroma_feature(data_tp_df, 20)","b2a66795":"plot_harmonics_and_perceptual(data_tp_df, 20)","18be1f8d":"play_sound(data_tp_df, 20)","990a5994":"plot_audio_file(data_tp_df, 50)","c35ebf40":"plot_spectrogram(data_tp_df, 50)","976730ae":"plot_mel_spectrogram(data_tp_df, 50)","6a710b9f":"plot_chroma_feature(data_tp_df, 50)","771efbd6":"plot_harmonics_and_perceptual(data_tp_df, 50)","90e45c42":"play_sound(data_tp_df, 50)","5fb92711":"plot_audio_file(data_tp_df, 100)","a04dbae9":"plot_spectrogram(data_tp_df, 100)","c67bf1ce":"plot_mel_spectrogram(data_tp_df, 100)","22bf405d":"plot_chroma_feature(data_tp_df, 100)","fb12cb3f":"plot_harmonics_and_perceptual(data_tp_df, 100)","3a94ffba":"play_sound(data_tp_df, 100)","e22ad294":"plot_audio_file(data_fp_df, 10)","5b1f4cdc":"plot_spectrogram(data_fp_df, 10)","5f52b57b":"plot_mel_spectrogram(data_fp_df, 10)","f0753a4e":"plot_chroma_feature(data_fp_df, 10)","0b87cd44":"plot_harmonics_and_perceptual(data_fp_df, 10)","60cdcadf":"play_sound(data_fp_df, 10)","620141a1":"plot_audio_file(data_fp_df, 70)","1a1ea617":"plot_spectrogram(data_fp_df, 70)","cc71bcac":"plot_mel_spectrogram(data_fp_df, 70)","c89f31c9":"plot_chroma_feature(data_fp_df, 70)","c7315f71":"plot_harmonics_and_perceptual(data_fp_df, 70)","c6bf0fc9":"play_sound(data_fp_df, 70)","3f487033":"plot_audio_file(data_fp_df, 100)","5326dee9":"plot_spectrogram(data_fp_df, 100)","a319929c":"plot_mel_spectrogram(data_fp_df, 100)","0bb37cbc":"plot_chroma_feature(data_fp_df, 100)","3dc91f63":"plot_harmonics_and_perceptual(data_fp_df, 100)","6fd0f1c8":"play_sound(data_fp_df, 100)","3c9f1972":"<a id=\"4\"><\/a><h1 style='background:#E3C6AD; border:0; color:black'><center>Sounds of the rainforest<\/center><\/h1> ","ac4f3047":"<h2 style='background:#B67B65; border:0; color:black'><center>Sound samples from FP set<\/center><\/h2> ","d616c8f7":"<h1 style='background:#E3C6AD; border:0; color:black'><center>Introduction<\/center><\/h1> \n","63977cf3":"We start by glimpsing the data (press `Output` buton to review the TP and FP train sets).","59ab5627":"<a href=\"#0\"><small>Go to top<\/small><\/a>","46048a01":"In this Notebook, I will:\n* Explore the **RFCX Species Audio Detection** dataset;\n* Review various techniques for signal augmentation in parallel with exploring the sounds of the rainforest.  \n\n<a id=\"0\"><\/a>\n### Content\n* <a href='#1'>Analysis preparation<\/a>  \n* <a href='#2'>Data ingestion<\/a>    \n* <a href='#3'>Data exploration<\/a>    \n* <a href='#4'>Sounds of the rainforest<\/a>    \n* <a href='#5'>References<\/a>    \n\nIn the final section of the Notebook, you can find additional resources for data exploration, signal data augmentation as well as few baseline models. ","b4c8050b":"<a href=\"#0\"><small>Go to top<\/small><\/a>","f16ede76":"<a href=\"#0\"><small>Go to top<\/small><\/a>","0d6f5e53":"<a id=\"5\"><\/a><h1 style='background:#135E46; border:0; color:black'><center>References<\/center><\/h1>   \n\nI include here various useful resources: papers, reviews, projects, trivia, notebooks.\n\n<h2 style='background:#478966; border:0; color:black'><center>Papers, reviews and projects<\/center><\/h2>   \n\n* [A pipeline for identification of bird and frog species in tropical soundscape recordings using a convolutional neural network](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S1574954120300637)\n\n* [Frog Sound Identification System for Frog Species Recognition](https:\/\/link.springer.com\/chapter\/10.1007\/978-3-642-36642-0_5)  \n\n* [Bird recognition - review of useful resources](https:\/\/github.com\/AgaMiko\/bird-recognition-review)   \n\n* [Detecting Frog Calling Activity Based on Acoustic Event Detection and Multi-label Learning](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S1877050916307700)\n\n* [Acoustic classification of Australian frogs for ecosystem\nsurveys](https:\/\/eprints.qut.edu.au\/103530\/1\/Jie_Xie_Thesis.pdf)  \n\n* [Data Augmentation Review](https:\/\/github.com\/AgaMiko\/data-augmentation-review)    \n\n* [Automatic recognition of frog calls using a multi-stage average spectrum](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0898122112002763)  \n\n* [A Baseline for Large-Scale Bird Species Identification in Field Recordings](http:\/\/ceur-ws.org\/Vol-2125\/paper_85.pdf).  \n\n* [Identifying Birds by Sound: Large-scale Acoustic Event Recognition for Avian Activity Monitoring](https:\/\/monarch.qucosa.de\/api\/qucosa%3A36986\/attachment\/ATT-0\/)   \n\n* [LifeCLEF 2019: Biodiversity Identification and Prediction Challenges](https:\/\/www.researchgate.net\/profile\/Henning_Mueller2\/publication\/331733244_LifeCLEF_2019_Biodiversity_Identification_and_Prediction_Challenges\/links\/5c8a35e592851c1df9407d46\/LifeCLEF-2019-Biodiversity-Identification-and-Prediction-Challenges.pdf)  \n\n<h2 style='background:#478966; border:0; color:black'><center>More resources<\/center><\/h2>   \n\n* [Calls of Frogs and Toads of the Northeast](https:\/\/musicofnature.com\/calls-of-frogs-and-toads-of-the-northeast\/)  \n\n* [Sounds of Frogs](https:\/\/www.fws.gov\/refuge\/clarks_river\/sounds_of_frogs.html)   \n\n* [Singing in the Rain Forest: How a Tropical Bird Song Transfers Information](https:\/\/journals.plos.org\/plosone\/article?id=10.1371\/journal.pone.0001580)\n\n<h2 style='background:#478966; border:0; color:black'><center>Trivia<\/center><\/h2>   \n\n\n* [Shazam for Birds: Three Apps That Recognize Bird Calls](https:\/\/lifehacker.com\/shazam-for-birds-three-apps-that-recognize-bird-calls-1797955537)  \n\n* [The Shazam App For Frogs!](https:\/\/www.iheartradio.ca\/virginradio\/calgary\/trending\/the-shazam-app-for-frogs-1.3430016)   \n\n* [Song Sleuth -  Helping you become a better birder](https:\/\/www.songsleuth.com\/#\/)  \n\n* [BirdNET - Bird sound identification](https:\/\/play.google.com\/store\/apps\/details?id=de.tu_chemnitz.mi.kahst.birdnet)\n\n\n<h2 style='background:#478966; border:0; color:black'><center>Notebooks<\/center><\/h2>   \n\n\n* [Audio Data Analysis Using librosa](https:\/\/www.kaggle.com\/hamditarek\/audio-data-analysis-using-librosa)  \n\n* [Birdcall Recognition: EDA and Audio FE](https:\/\/www.kaggle.com\/andradaolteanu\/birdcall-recognition-eda-and-audio-fe)    \n\n* [EDA and Audio Processing with Python](https:\/\/www.kaggle.com\/parulpandey\/eda-and-audio-processing-with-python)  \n\n* [Rainforest Connection Analysis Using librosa](https:\/\/www.kaggle.com\/hamditarek\/rainforest-connection-analysis-using-librosa)   \n\n* [RFCX: Audio Data Augmentation(Japanese+English)](https:\/\/www.kaggle.com\/hidehisaarai1213\/rfcx-audio-data-augmentation-japanese-english)  \n\n* [Tabular XGboost GPU + FFT GPU + Cuml = FAST](https:\/\/www.kaggle.com\/titericz\/0-525-tabular-xgboost-gpu-fft-gpu-cuml-fast)   ","b7e1572d":"<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/4\/48\/Hyperolius_tuberculatus.jpg\" width=\"400\"><\/img>","6669104a":"<a href=\"#0\"><small>Go to top<\/small><\/a>","095bf3dc":"<h1><center>Explore the Rainforest Soundscape<\/center><\/h1> \n\n\n<center><img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/a\/a8\/CRTO_Matthew-Gable.JPG\" width=\"400\"><\/img><\/center>","80a2ce61":"<a id=\"2\"><\/a><h1 style='background:#478966; border:0; color:black'><center>Data ingestion<\/center><\/h1> ","b5e569a7":"We define functions for display of:\n- Waveplots\n- Spectrograms  \n- Mel spectrograms  \n- Chroma feature\n- Harmonics and Perceptual sound wave components\n\n<div class=\"alert alert-block alert-info\">\n<b>Note:<\/b> We can build features for our model using the functions defined here.\n<\/div>\n<br>\nWe also define a function for playing the sound.\n\nWe then show Waveplots, Spectrograms, Mel Spectrograms, Chroma feature and combined Harmonics and Perceptual graphs for few of the recordings, from both the TP and FP train sets.","ecb3015a":"<a href=\"#0\"><small>Go to top<\/small><\/a>","c705798c":"<a href=\"#0\"><small>Go to top<\/small><\/a>","6b393254":"<a href=\"#0\"><small>Go to top<\/small><\/a>","774d6143":"<a id=\"1\"><\/a><h1 style='background:#135E46; border:0; color:black'><center>Analysis preparation<\/center><\/h1>","aaf355c0":"<a id=\"3\"><\/a><h1 style='background:#73A788; border:0; color:black'><center>Data exploration<\/center><\/h1> ","4bcf3652":"<h2 style='background:#D09D7B; border:0; color:black'><center>Sound samples from TP set<\/center><\/h2> "}}