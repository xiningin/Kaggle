{"cell_type":{"8301658b":"code","e4a3c051":"code","754c3f53":"code","9ef94225":"code","73fbdfeb":"code","4172a91e":"code","104d173e":"code","23a4bc34":"code","03a0f931":"code","a427858e":"code","a5421396":"code","58ac8138":"code","1288c821":"code","0048a318":"code","d39dd401":"code","d973b6ef":"code","a9033564":"code","bb7de8aa":"code","833bf91f":"code","7d22a064":"code","6572cad7":"code","6744fd38":"code","c4f0925d":"code","532b590d":"code","5287bab2":"code","9052ca9c":"code","74f6c206":"code","57f3abf9":"code","19d28ec0":"code","61098a91":"code","65debdf8":"code","f94deac2":"code","b50486ca":"code","dfaa3b69":"code","0096927a":"code","722cbece":"code","d45eed19":"code","ff4ad39b":"code","5ca89e8d":"code","7d668e62":"code","f87b722a":"code","1a9f41ba":"code","18ff81e7":"code","0c5688e2":"code","0baafa81":"code","66465655":"code","e8196594":"code","0042a9be":"code","fd504ea6":"code","7af67498":"code","44af2f79":"code","65c7977a":"code","8421c9ad":"code","61cd52c9":"code","2563d319":"code","0c13010e":"code","37debfde":"code","536cca78":"code","f3a614cb":"code","147872bf":"code","a5912311":"code","cbb9188b":"code","5c67300b":"code","9c22b811":"code","a4956dff":"code","01f7fd7f":"code","022c5978":"code","ddeb0454":"code","75ded56e":"code","98065a6d":"code","7c6d91e7":"code","2f906031":"code","86dd8d41":"code","684a786a":"code","1035fcf9":"code","c0bf48ca":"code","946d7b79":"code","b23888b9":"code","a43eb83f":"code","c5057f0d":"code","9b5a71d0":"code","ff05010c":"code","b32b0c7b":"code","ebf754ca":"code","02ff2ccb":"code","d6066f34":"code","66369425":"code","bfd87fb3":"markdown","4233a6ac":"markdown","5d5631a1":"markdown","d3938790":"markdown","024387f8":"markdown","0457b0bf":"markdown","e7d5c64d":"markdown","b94111d8":"markdown","cb00b806":"markdown","4417a4b2":"markdown","fd353208":"markdown","adf3f53a":"markdown","654ea2ee":"markdown","87050011":"markdown","22c50830":"markdown","729e1066":"markdown","0d716086":"markdown","879abed8":"markdown"},"source":{"8301658b":"num_days_R_prediction=21","e4a3c051":"#!pip install rpy2\nimport rpy2\n%load_ext rpy2.ipython\n%Rpush num_days_R_prediction","754c3f53":"%%R\nmax_days_prediction<-num_days_R_prediction","9ef94225":"bypass_weather=1 # =1 bypass weather_pi api calls","73fbdfeb":"# Get data from Github\nimport numpy as np\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\nimport pandas as pd\n\n#url_1 = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_19-covid-Confirmed.csv'\nurl_1 = 'https:\/\/github.com\/CSSEGISandData\/COVID-19\/raw\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv'\nconfirmed = pd.read_csv(url_1, error_bad_lines=False)\n\n#url_2 = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_19-covid-Deaths.csv'\nurl_2 = 'https:\/\/github.com\/CSSEGISandData\/COVID-19\/raw\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv'\ndeath = pd.read_csv(url_2, error_bad_lines=False)\n\n#url_3 = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_19-covid-Recovered.csv'\nurl_3 = 'https:\/\/github.com\/CSSEGISandData\/COVID-19\/raw\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_recovered_global.csv'\nrecover = pd.read_csv(url_3, error_bad_lines=False)\n\n# fix region names\nconfirmed['Country\/Region']= confirmed['Country\/Region'].str.replace(\"Mainland China\", \"China\")\nconfirmed['Country\/Region']= confirmed['Country\/Region'].str.replace(\"US\", \"United States\")\n\ndeath['Country\/Region']= death['Country\/Region'].str.replace(\"Mainland China\", \"China\")\ndeath['Country\/Region']= death['Country\/Region'].str.replace(\"US\", \"United States\")\n\nrecover['Country\/Region']= recover['Country\/Region'].str.replace(\"Mainland China\", \"China\")\nrecover['Country\/Region']= recover['Country\/Region'].str.replace(\"US\", \"United States\")","4172a91e":"confirmed.iloc[:,:]","104d173e":"population=pd.read_csv('\/home\/notebookuser\/notebooks\/covid19\/data\/population.csv', sep=',', encoding='latin1') \nconfirmed=pd.merge(confirmed, population,how='left' ,on=['Province\/State','Country\/Region'])\ndeath=pd.merge(death, population,how='left' ,on=['Province\/State','Country\/Region'])\nrecover=pd.merge(recover, population,how='left' ,on=['Province\/State','Country\/Region'])","23a4bc34":"# merge region confirmed + death + recover\nconfirmed['region']=confirmed['Country\/Region'].map(str)+'_'+confirmed['Province\/State'].map(str)\ndeath['region']=death['Country\/Region'].map(str)+'_'+death['Province\/State'].map(str)\nrecover['region']=recover['Country\/Region'].map(str)+'_'+recover['Province\/State'].map(str)\nconfirmed.iloc[:,:]","03a0f931":"# merge region death\ndeath.iloc[185:195,:]","a427858e":"# merge region recover\nrecover.iloc[175:185,:]","a5421396":"confirmed.iloc[185:195,:]","58ac8138":"confirmed.iloc[220:230,:]","1288c821":"def create_ts(df):\n  ts=df\n  ts=ts.drop(['Province\/State', 'Country\/Region','Lat', 'Long',' Population '], axis=1)\n  ts.set_index('region')\n  ts=ts.T\n  ts.columns=ts.loc['region']\n  ts=ts.drop('region')\n  ts=ts.fillna(0)\n  ts=ts.reindex(sorted(ts.columns), axis=1)\n  return (ts)","0048a318":"## JOAO - Fix - Drop Duplicates # Keep Last # Issue With Data source Change from John Hopkins institute\n#\nts=create_ts(confirmed.drop_duplicates(subset=['region'], keep='last', inplace=False) )\nts_d=create_ts(death.drop_duplicates(subset=['region'], keep='last', inplace=False) )\nts_rec=create_ts(recover.drop_duplicates(subset=['region'], keep='last', inplace=False) )","d39dd401":"# JOAO - FIX - Automation WarmUp of Plot Library\nimport matplotlib.pyplot as plt\nimport time\nplt.legend(loc = 'upper left')\nplt.show()","d973b6ef":"#\np=ts.reindex(ts.max().sort_values(ascending=False).index, axis=1)\np.iloc[:,0:3].plot(marker='*',figsize=(20,12)).set_title('Daily Update - Total Confirmed - Top_3 World Region ',fontdict={'fontsize': 22})\np.iloc[:,3:25].plot(marker='*',figsize=(20,12)).set_title('Daily Update - Total Confirmed - Major_4,25 2nd Areas',fontdict={'fontsize': 22})\n\np_d=ts_d.reindex(ts_d.max().sort_values(ascending=False).index, axis=1)\np_d.iloc[:,0:3].plot(marker='*',figsize=(20,12)).set_title('Daily Update - Total Deaths - Top_3 World Region',fontdict={'fontsize': 22})\np_d.iloc[:,3:25].plot(marker='*',figsize=(20,12)).set_title('Daily Update - Total Deaths - Major_4,25 2nd Areas',fontdict={'fontsize': 22})\n\np_r=ts_rec.reindex(ts_rec.max().sort_values(ascending=False).index, axis=1)\np_r.iloc[:,0:3].plot(marker='*',figsize=(20,12)).set_title('Daily Update - Total Recovered - Top_3 World Region',fontdict={'fontsize': 22})\np_r.iloc[:,3:25].plot(marker='*',figsize=(20,12)).set_title('Daily Update - Total Recovered - Major_4,25 2nd Areas',fontdict={'fontsize': 22})","a9033564":"#!pip install pyweatherbit\n#\nfrom weatherbit.api import Api\nimport json  \nimport pandas as pd  \nfrom pandas.io.json import json_normalize \n\n### API - Joao\nfrom datetime import datetime\n#\n#api_key=\"46f953cbca334ea1b85ab5d47dbc9aa0\" # joao@fuelbigdata.com\napi_key=\"27a4e12ebc7f41b2bd6e300015f1a090\" # jpacerqueira.consult.bigdata@gmail.com\n#\n\napi = Api(api_key)\napi.set_granularity('daily')\n\n# # Set the granularity of the API - Options: ['daily','hourly','3hourly']\n# # Will only affect forecast requests.\n\n#api.get_forecast(lat='Lat', lon='Lon')\n#my_end_date=datetime.today().strftime('%Y-%m-%d')\n\n#### United Kingdom\n#lat1='55.378100'\n#lon1='-3.436000'\n#api.get_history(lat=lat1,lon=lon1, start_date='2020-03-29',end_date=my_end_date)\n","bb7de8aa":"##\n#### My List of Countries and Regions to train and represent data\nmy_train_list=[\n ### JOAO - LIST of Countries - Start here\n     #   'Andorra_nan', \n        'United States_nan',\n        'United Kingdom_nan',\n        'Italy_nan',\n        'Spain_nan',  \n        'Netherlands_nan',\n        'France_nan', \n        'Belgium_nan',\n        'Portugal_nan',\n        'Switzerland_nan',\n        'Germany_nan',\n        'Japan_nan',\n        'Poland_nan',\n  ### JOAO - LIST of Countries - Finish here\n        'Korea, South_nan',\n        'China_Hubei',\n        'China_Beijing',\n        'China_Guangdong',\n        'China_Shanghai',\n      #  'China_Shanxi',\n      #  'China_Sichuan',  'China_Xinjiang',\n      #  'China_Yunnan', 'China_Zhejiang',\n      #  'China_Anhui', 'China_Beijing',\n      #  'China_Chongqing', 'China_Fujian', 'China_Gansu',\n      #  'China_Guangdong', 'China_Guangxi', 'China_Guizhou',\n      #  'China_Hainan', 'China_Hebei', 'China_Heilongjiang', 'China_Henan',\n      #  'China_Hubei', 'China_Hunan', 'China_Inner Mongolia',\n      #  'China_Jiangsu', 'China_Jiangxi', 'China_Jilin', 'China_Liaoning',\n      #  'China_Ningxia', 'China_Qinghai', 'China_Shaanxi',\n      #  'China_Shandong', 'China_Shanghai', 'China_Shanxi',\n      #  'China_Sichuan', 'China_Tianjin', 'China_Tibet', 'China_Xinjiang',\n      #  'China_Yunnan', 'China_Zhejiang',\n      #  'Morocco_nan',\n        'Australia_New South Wales',\n      #  'Australia_Queensland',\n      #  'Australia_South Australia', 'Australia_Victoria', \n        'Brazil_nan',\n      #  'Cambodia_nan',\n      #  'Canada_British Columbia',\n        'Canada_Ontario',\n        'Canada_Quebec',\n      #  'Egypt_nan',\n        'China_Hong Kong',\n        'China_Macau',\n        'Finland_nan',\n        'India_nan',\n        'Iran_nan',\n        'Malaysia_nan',\n      #  'Nepal_nan',\n        'Norway_nan',\n        'Philippines_nan', 'Russia_nan', 'Singapore_nan',\n    #   'Sri Lanka_nan', 'Thailand_nan', 'United Arab Emirates_nan',\n        'Sweden_nan',\n        'Taiwan*_nan',\n        'Turkey_nan', \n        'Vietnam_nan',\n       ]\n#","833bf91f":"# ################## already done since API is limited to 500 call per day\n## consume Wether data From 15\/03\/2020 forward to end_date=30\/03\/2020\n#\n### Location in confirmed array to start in pos 1='Albania_nan' 61 = 'China_Hong Kong'\n### Only run for Countries in above : my_train_list \nvpos=len(confirmed.iloc[1])-1 #90# 89 #88 #87 #86 #85 #84 #83 #82 #81 #80 #79 #78 #77 #76 #75 #74 #1 #73\nprint('xcountry_region='+confirmed.iloc[1,vpos])\n\nmy_weather_fetch_list= my_train_list # ['Canada_Quebec'] #  ['Iran_nan'] #['Brazil_nan'] #\n\nstart_date_init=pd.to_datetime('today').strftime('%Y\/%m\/%d') # '2020-04-18'\nprint('start_date_init=',start_date_init)\noffset_days=-1 # -1 to start yesterday pick today # API free-tier just picks one per api call!\nmax_days=1 #1\n\nw=pd.DataFrame(columns=['date','region','min','max'])\nif bypass_weather != 1 :\n    for h in range(0,max_days):\n        offset_days=h\n        start_date=pd.to_datetime(start_date_init)\n        #\n        end_date=(start_date+pd.DateOffset(days=offset_days+1)).strftime('%Y-%m-%d')\n        start_date=(start_date+pd.DateOffset(days=offset_days)).strftime('%Y-%m-%d')\n        prnt_start_date=pd.to_datetime(start_date).strftime('%Y\/%m\/%d')\n        prnt_end_date=pd.to_datetime(end_date).strftime('%Y\/%m\/%d')\n        #\n        for i in range (1,len(confirmed)):\n            if confirmed.iloc[i,vpos] not in my_weather_fetch_list:\n                continue\n            if confirmed.iloc[i,vpos] in my_weather_fetch_list:\n                #\n                # Clean JSON structure return from API Call\n                jas=\"\"\n                jas=api.get_history(lat=confirmed.iloc[i,2], lon=confirmed.iloc[i,3], start_date=start_date,end_date=end_date).json\n                if (((json_normalize(jas['data'])['min_temp'].values[0])=='')\n                     or (np.isnan((json_normalize(jas['data'])['min_temp'].values[0])) == True )):\n                    continue\n                try:\n                    w=w.append({'date':prnt_end_date,'region':confirmed.iloc[i,vpos] ,'min':json_normalize(jas['data'])['min_temp'].values[0],'max':json_normalize(jas['data'])['max_temp'].values[0]}, ignore_index=True)\n                except Exception:\n                    w=w.append({'date':prnt_end_date,'region':confirmed.iloc[i,vpos] ,'min':None,'max':None}, ignore_index=True)\n    #        \n#\ntable_columns=['date','region','min','max']\nw = w[w.columns.intersection(table_columns)]","7d22a064":"w.to_csv('data\/w_v2_v227.csv', index = False, header=True)","6572cad7":"w[:]","6744fd38":"# Joao - FIX - Improve Performance \n### Drop the Months of Jan, Feb < 26\/02 as\n### they are too in the Past and model no longuer trains in China Hubei only!\n\nts=ts[35:]\nts_d=ts_d[35:]\nts_rec=ts_rec[35:]","c4f0925d":"ts[:3]","532b590d":"ts[-4:]","5287bab2":"# Create data for R script\nts_conf=ts.reset_index()\nts_conf=ts_conf.rename(columns = {'index':'date'})\nts_conf['date']=pd.to_datetime(ts_conf['date'] ,errors ='coerce')\nts_conf.to_csv(r'\/home\/notebookuser\/notebooks\/covid19\/data\/ts_conf_r.csv')\n\nts_rec=ts_rec.reset_index()\nts_rec=ts_rec.rename(columns = {'index':'date'})\nts_rec['date']=pd.to_datetime(ts_rec['date'] ,errors ='coerce')\nts_rec.to_csv(r'\/home\/notebookuser\/notebooks\/covid19\/data\/ts_rec_r.csv')\n\n\nts_d=ts_d.reset_index()\nts_d=ts_d.rename(columns = {'index':'date'})\nts_d['date']=pd.to_datetime(ts_d['date'] ,errors ='coerce')\nts_d.to_csv(r'\/home\/notebookuser\/notebooks\/covid19\/data\/ts_d_r.csv')\n","9052ca9c":"%%R\n\n#install.packages('pracma')\n#install.packages('Metrics')\n#install.packages('readr')\n#install.packages('reshape')\n\nSys.setenv(TZ='GMT')\nSys.timezone()","74f6c206":"%%R\nrequire(pracma)\nrequire(Metrics)\nrequire(readr)\nall<- read_csv(\"\/home\/notebookuser\/notebooks\/covid19\/data\/ts_conf_r.csv\")\nall$X1<-NULL\ndate<-all[,1]\ndate[nrow(date) + 1,1] <-all[nrow(all),1]+1\npred_all<-NULL\nfor (n in 2:ncol(all)-1) {\n  Y<-ts(data = all[n+1], start = 1, end =nrow(all)+1)  \n  sig_w<-0.01\n  w<-sig_w*randn(1,100) # acceleration which denotes the fluctuation (Q\/R) rnorm(100, mean = 0, sd = 1)\n  sig_v<-0.01\n  v<-sig_v*randn(1,100)   \n  t<-0.45\n  phi<-matrix(c(1,0,t,1),2,2)\n  gama<-matrix(c(0.5*t^2,t),2,1)\n  H<-matrix(c(1,0),1,2)\n  #Kalman\n  x0_0<-p0_0<-matrix(c(0,0),2,1)\n  p0_0<-matrix(c(1,0,0,1),2,2)\n  Q<-0.01\n  R<-0.01\n  X<-NULL\n  X2<-NULL\n  pred<-NULL\n  for (i in 0:nrow(all)) {\n    namp <-paste(\"p\", i+1,\"_\",i, sep = \"\")\n    assign(namp, phi%*%(get(paste(\"p\", i,\"_\",i, sep = \"\")))%*%t(phi)+gama%*%Q%*%t(gama))\n    namk <- paste(\"k\", i+1, sep = \"\")\n    assign(namk,get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)%*%(1\/(H%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)+R)))\n    namx <- paste(\"x\", i+1,\"_\",i, sep = \"\")\n    assign(namx,phi%*%get(paste(\"x\", i,\"_\",i, sep = \"\")))\n    namE <- paste(\"E\", i+1, sep = \"\")\n    assign(namE,Y[i+1]-H%*%get(paste(\"x\", i+1,\"_\",i, sep = \"\")))\n    namx2 <- paste(\"x\", i+1,\"_\",i+1, sep = \"\")\n    assign(namx2,get(paste(\"x\", i+1,\"_\",i, sep = \"\"))+get(paste(\"k\", i+1, sep = \"\"))%*%get(paste(\"E\", i+1, sep = \"\")))\n    namp2 <- paste(\"p\", i+1,\"_\",i+1, sep = \"\")\n    assign(namp2,(p0_0-get(paste(\"k\", i+1, sep = \"\"))%*%H)%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\")))\n    X<-rbind(X,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[1])\n    X2<-rbind(X2,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[2])\n    if(i>2){\n      remove(list=(paste(\"p\", i-1,\"_\",i-2, sep = \"\")))\n      remove(list=(paste(\"k\", i-1, sep = \"\")))\n      remove(list=(paste(\"E\", i-1, sep = \"\")))\n      remove(list=(paste(\"p\", i-2,\"_\",i-2, sep = \"\")))\n      remove(list=(paste(\"x\", i-1,\"_\",i-2, sep = \"\")))\n      remove(list=(paste(\"x\", i-2,\"_\",i-2, sep = \"\")))}\n  }\n  pred<-NULL\n  pred<-cbind(Y,X,round(X2,4))\n  pred<-as.data.frame(pred)\n  pred$region<-colnames(all[,n+1])\n  pred$date<-date$date\n  pred$actual<-rbind(0,(cbind(pred[2:nrow(pred),1])\/pred[1:nrow(pred)-1,1]-1)*100)\n  pred$predict<-rbind(0,(cbind(pred[2:nrow(pred),2])\/pred[1:nrow(pred)-1,2]-1)*100)\n  pred$pred_rate<-(pred$X\/pred$Y-1)*100\n  pred$X2_change<-rbind(0,(cbind(pred[2:nrow(pred),3]-pred[1:nrow(pred)-1,3])))\n  pred_all<-rbind(pred_all,pred)\n}\npred_all<-cbind(pred_all[,4:5],pred_all[,1:3])\nnames(pred_all)[5]<-\"X2\"\npred_all=pred_all[with( pred_all, order(region, date)), ]\npred_all<-pred_all[,3:5]","57f3abf9":"p=%R pred_all","19d28ec0":"############ Merge R output due to package problem\n### Joao FIX - \n# t=ts_d    -  deaths\n# t=ts_rec  -  recovered\n# t=ts      -  confirmed\nt=ts\nt=t.stack().reset_index(name='confirmed')\nt.columns=['date', 'region','confirmed']\nt['date']=pd.to_datetime(t['date'] ,errors ='coerce')\nt=t.sort_values(['region', 'date'])\n\ntemp=t.iloc[:,:3]\ntemp=temp.reset_index(drop=True)\nfor i in range(1,len(t)+1):\n  if(temp.iloc[i,1] is not temp.iloc[i-1,1]):\n    temp.loc[len(temp)+1] = [temp.iloc[i-1,0]+ pd.DateOffset(1),temp.iloc[i-1,1], 0] \ntemp=temp.sort_values(['region', 'date'])\ntemp=temp.reset_index(drop=True)\ntemp['Y']=p['Y']\ntemp['X']=p['X']\ntemp['X2']=p['X2']\n\n# JOAO - FIX - temp fixed\n# Y,X,X2 nan issue from p revolved\n\np_pd=pd.DataFrame(p,columns=['Y','X','X2'])\n\np_pd['nindex'] = range(1, 1+len(p_pd))\ntemp['nindex']= range(1,1+len(temp))\n\n#temp_1 = temp.join(p_pd)\ntemp_1 = temp.merge(p_pd, on='nindex', how='inner', suffixes=('_1', '_2')).rename(columns={\"Y_2\": \"Y\", \"X_2\": \"X\", \"X2_2\" : \"X2\"})\ntemp_1 = temp_1.drop(columns=['Y_1', 'X_1','X2_1','nindex'])\n\n\ntemp=temp_1\ntemp.to_csv(r'\/home\/notebookuser\/notebooks\/covid19\/data\/temp.csv')","61098a91":"#\n### Joao - Test Later Weather from new file : w_v2.csv and w_v2_v2.csv\nw_v2=pd.read_csv('data\/w_v2.csv', sep=',', encoding='latin1')\nw_v2['date']=pd.to_datetime(w_v2['date'],format='%Y\/%m\/%d')\n\nw_v2_v2=pd.read_csv('data\/w_v2_v2.csv', sep=',', encoding='latin1')\nw_v2_v2['date']=pd.to_datetime(w_v2_v2['date'],format='%Y\/%m\/%d')\n\nw_v2_v227=pd.read_csv('data\/w_v2_v227.csv', sep=',', encoding='latin1')\nw_v2_v227['date']=pd.to_datetime(w_v2_v227['date'],format='%Y\/%m\/%d')\n\nw=pd.read_csv('data\/w.csv', sep=',', encoding='latin1')\nw['date']=pd.to_datetime(w['date'],format='%d\/%m\/%Y')\n\nw_forecast=pd.read_csv('data\/w_forecast.csv', sep=',', encoding='latin1')\nw_forecast['date']=pd.to_datetime(w_forecast['date'],format='%d\/%m\/%Y')\n\n### Append Weather fetched now to file w_v2_v2\nw_n_forward=w_v2_v2.append(w_v2_v227) \nw_n_forward=w_n_forward.drop_duplicates(subset=['date','region'], keep='last', inplace=False)\nw_n_forward=w_n_forward.sort_values(by=['region','date'], ascending=True)\nw_n_forward.to_csv(r'data\/w_v2_v2.csv', index = False, header=True)","65debdf8":"w_total=pd.DataFrame(columns=['date','region','min','max'])\nw_total=w.append(w_forecast).append(w_v2).append(w_v2_v2).append(w_v2_v227) \nw_total=w_total.drop_duplicates(subset=['date','region'], keep='last', inplace=False)\nw_total=w_total.sort_values(by=['region','date'], ascending=True)\n\nw_total.to_csv(r'data\/w_total.csv', index = False, header=True)","f94deac2":"w_in_model=pd.read_csv('data\/w_total.csv', sep=',', encoding='latin1')\n#\nw_in_model['date']=pd.to_datetime(w_in_model['date'],format='%Y\/%m\/%d')\nw_in_model.to_csv(r'data\/w_in_model.csv', index = False, header=True)","b50486ca":"w_in_model.tail(2)","dfaa3b69":"### JOAO - Fix -\n## t=ts confirmed\nt=ts\nt=t.stack().reset_index(name='confirmed')\nt.columns=['date', 'region','confirmed']\nt['date']=pd.to_datetime(t['date'] ,errors ='coerce')\nt=t.sort_values(['region', 'date'])\n\n# Add 1 Future day for prediction\nt=t.reset_index(drop=True)\nfor i in range(1,len(t)+1):\n    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n        t.loc[len(t)+1] = [t.iloc[i-1,0]+ pd.DateOffset(1),t.iloc[i-1,1], 0] \nt=t.sort_values(['region', 'date'])\nt=t.reset_index(drop=True)","0096927a":"### JOAO - Fix -\nt['1_day_change']=t['3_day_change']=t['7_day_change']=t['1_day_change_rate']=t['3_day_change_rate']=t['7_day_change_rate']=t['last_day']=0\n#\n### JOAO - Fix - ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in double_scalars\nfor i in range(1,len(t)):\n    if(t.iloc[i,1] is t.iloc[i-2,1]):\n        t.iloc[i,3]=t.iloc[i-1,2]-t.iloc[i-2,2]\n        t.iloc[i,6]=((t.iloc[i-1,2]*100 +1)\/(t.iloc[i-2,2]*100 -1 +1))*100\n        t.iloc[i,9]=t.iloc[i-1,2]\n    if(t.iloc[i,1] is t.iloc[i-4,1]):\n        t.iloc[i,4]=t.iloc[i-1,2]-t.iloc[i-4,2]\n        t.iloc[i,7]=((t.iloc[i-1,2]*100 +1)\/(t.iloc[i-4,2]*100 -1 +1))*100\n    if(t.iloc[i,1] is t.iloc[i-8,1]):\n        t.iloc[i,5]=t.iloc[i-1,2]-t.iloc[i-8,2]\n        t.iloc[i,8]=((t.iloc[i-1,2]*100 +1)\/(t.iloc[i-8,2]*100 -1 +1))*100\nt=t.fillna(0)  \nt=t.merge(temp[['date','region', 'X']],how='left',on=['date','region'])\nt=t.rename(columns = {'X':'kalman_prediction'}) \nt=t.replace([np.inf, -np.inf], 0)\n\n### Joao - Fix NaN Kalman_Filter\nt['kalman_prediction']=np.nan_to_num(t['kalman_prediction'])\nt['kalman_prediction']=round(t['kalman_prediction'])\n\n#\ntrain=t.merge(confirmed[['region',' Population ']],how='left',on='region')\ntrain=train.rename(columns = {' Population ':'population'})\ntrain['population']=train['population'].str.replace(r\" \", '')\ntrain['population']=train['population'].str.replace(r\",\", '')\ntrain['population']=train['population'].fillna(10000000) ### Fill 10M if nan\ntrain['population']=train['population'].astype('int32')\n### JOAO - Fix - ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n# train['infected_rate']=train['last_day']\/train['population']*10000\ntrain['infected_rate']=(((train['last_day'] +1)*100)\/((train['population'] +1)*100000) *10) # *100 - % converter\n #\n#### Joao , merge w weather only !?!\n##train=train.merge(w,how='left',on=['date','region'])\ntrain=train.merge(w_in_model,how='left',on=['date','region'])\n#\ntrain=train.sort_values(['region', 'date'])\n### fill missing weather \nfor i in range(0,len(train)):\n    if(np.isnan(train.iloc[i,13])):\n        if(train.iloc[i,1] is train.iloc[i-1,1]):\n            train.iloc[i,13]=train.iloc[i-1,13]\n            train.iloc[i,14]=train.iloc[i-1,14]","722cbece":"# Joao - Fix - Nulls are an issue\ntrain_notnull=train[train['kalman_prediction'] != 0.0 ] #.any(axis=1)]\ntrain_notnull[:]","d45eed19":"# Joao - Fix - Nulls are an issue\ntrain_nulls=train[train['kalman_prediction'].isnull() ] #.any(axis=1)]\ntrain_nulls[:]","ff4ad39b":"# Joao - Fix - Nulls are an issue\n\ntrain_nulls=train[train.isnull().any(axis=1)]\ntrain_nulls[:]\ntrain[-1:]","5ca89e8d":"train.to_csv(r'data\/train.csv', index = False, header=True)\n\n##Shared -- Ratio in Confirmed - 21Day Forecast -- train 25April2020 - I\nratiod=pd.read_csv('data\/train.csv', sep=',', encoding='latin1')\ntodayd=datetime.today().strftime('%Y-%m-%d')\nratiofn=\"Shared -- Ratio in Confirmed - \"+str(num_days_R_prediction)+\"Day Forecast -- train \"+todayd+\".csv\"\n\nratiod['population_percentage_infected_rate_confirmed']=ratiod['infected_rate']*100\nratiod['population_percentage_factor_9.8_10_infected_rate_confirmed']=ratiod['infected_rate']*100*9.8\nratiod['delta_new_cases']=ratiod['kalman_prediction']-ratiod['last_day']\nratiod['delta_new_cases_per_1M_hab']=ratiod['delta_new_cases']\/ratiod['population']*1000000\n\nratiod.to_csv(r'data\/'+ratiofn, index = False, header=True)\n\nratiod[-3:]","7d668e62":"# Select region\nregion='United States_nan'\n\nevaluation=pd.DataFrame(columns=['region','mse','rmse','mae'])\nplace=0\nfor i in range(1,len(t)):\n    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n        ex=np.array(t.iloc[i-len(ts):i,10])\n        pred=np.array(t.iloc[i-len(ts):i,2])\n        evaluation=evaluation.append({'region': t.iloc[i-1,1], 'mse': np.power((ex - pred),2).mean(),'rmse':sqrt(mean_squared_error(ex,pred)),'mae': (abs(ex - pred)).mean()}, ignore_index=True)\np=t[t['region']==region][['date','region','confirmed','kalman_prediction']]\n#p=p.rename(columns = {'confirmed':'recoverd'})\np.iloc[len(p)-1,2]=None\np=p.set_index(['date'])\np.iloc[:,1:].plot(marker='o',figsize=(16,8)).set_title('Kalman Prediction - Select Region to Change - {}'.format(p.iloc[0,0]))\n\nprint(evaluation[evaluation['region']==p.iloc[0,0]])","f87b722a":"# Select region\nregion='Russia_nan'\n\nevaluation=pd.DataFrame(columns=['region','mse','rmse','mae'])\nplace=0\nfor i in range(1,len(t)):\n    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n        ex=np.array(t.iloc[i-len(ts):i,10])\n        pred=np.array(t.iloc[i-len(ts):i,2])\n        evaluation=evaluation.append({'region': t.iloc[i-1,1], 'mse': np.power((ex - pred),2).mean(),'rmse':sqrt(mean_squared_error(ex,pred)),'mae': (abs(ex - pred)).mean()}, ignore_index=True)\np=t[t['region']==region][['date','region','confirmed','kalman_prediction']]\n#p=p.rename(columns = {'confirmed':'recoverd'})\np.iloc[len(p)-1,2]=None\np=p.set_index(['date'])\np.iloc[:,1:].plot(marker='o',figsize=(16,8)).set_title('Kalman Prediction - Select Region to Change - {}'.format(p.iloc[0,0]))\n\nprint(evaluation[evaluation['region']==p.iloc[0,0]])","1a9f41ba":"# Select region\nregion='Brazil_nan'\n\nevaluation=pd.DataFrame(columns=['region','mse','rmse','mae'])\nplace=0\nfor i in range(1,len(t)):\n    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n        ex=np.array(t.iloc[i-len(ts):i,10])\n        pred=np.array(t.iloc[i-len(ts):i,2])\n        evaluation=evaluation.append({'region': t.iloc[i-1,1], 'mse': np.power((ex - pred),2).mean(),'rmse':sqrt(mean_squared_error(ex,pred)),'mae': (abs(ex - pred)).mean()}, ignore_index=True)\np=t[t['region']==region][['date','region','confirmed','kalman_prediction']]\n#p=p.rename(columns = {'confirmed':'recoverd'})\np.iloc[len(p)-1,2]=None\np=p.set_index(['date'])\np.iloc[:,1:].plot(marker='o',figsize=(16,8)).set_title('Kalman Prediction - Select Region to Change - {}'.format(p.iloc[0,0]))\n\nprint(evaluation[evaluation['region']==p.iloc[0,0]])","18ff81e7":"# Select region\nregion='United Kingdom_nan'\n\nevaluation=pd.DataFrame(columns=['region','mse','rmse','mae'])\nplace=0\nfor i in range(1,len(t)):\n    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n        ex=np.array(t.iloc[i-len(ts):i,10])\n        pred=np.array(t.iloc[i-len(ts):i,2])\n        evaluation=evaluation.append({'region': t.iloc[i-1,1], 'mse': np.power((ex - pred),2).mean(),'rmse':sqrt(mean_squared_error(ex,pred)),'mae': (abs(ex - pred)).mean()}, ignore_index=True)\np=t[t['region']==region][['date','region','confirmed','kalman_prediction']]\n#p=p.rename(columns = {'confirmed':'recoverd'})\np.iloc[len(p)-1,2]=None\np=p.set_index(['date'])\np.iloc[:,1:].plot(marker='o',figsize=(16,8)).set_title('Kalman Prediction - Select Region to Change - {}'.format(p.iloc[0,0]))\n\nprint(evaluation[evaluation['region']==p.iloc[0,0]])","0c5688e2":"#!pip install h2o\nimport h2o\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\nh2o.init(min_mem_size='3G')\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression","0baafa81":"\ntrain=train.fillna(0)\n\n########################################################\n\n### Joao - Training  progression - When growth happened 2020\/03\/05 to 2020\/04\/12\n### Joao - FIX - Refresh this daily forward\n\n### Old Fixed manual ### Last run 17April2020\n##\n#train_df=train[train['date']>'2020-03-04']\n#train_df=train[train['date']<'2020-04-16']\n#boots=train_df[train_df['date']>='2020-04-08'] # some bootstrap to give more weight for recent days\n#train_df=train_df.append([boots[boots['date']>='2020-04-12']]*1000,ignore_index=True)\n\n### Train progression of the Virus ### In Country list or Spain only\n#region_to_train=my_train_list\n#train_df_v2=train_df[train_df['region'].isin(region_to_train)] # =='Spain_nan'] #\n#test=train[train['date']>='2020-04-03']\n#test=test[test['date']<'2020-04-17']\n#test_v2=test[test['region'].isin(region_to_train)]\n#valid_v2=test_v2[test_v2['date']>='2020-04-16']\n\n########################################################\n\nto_day=pd.to_datetime('today')\nfirst_train_date=(to_day+pd.DateOffset(days=-56)).strftime('%Y-%m-%d') # 9 weeks =56 days training\nlast_train_date=(to_day+pd.DateOffset(days=-1)).strftime('%Y-%m-%d')\nfirst_bootstrap_date=(to_day+pd.DateOffset(days=-9)).strftime('%Y-%m-%d')\nboost_bootstrap_date=(to_day+pd.DateOffset(days=-4)).strftime('%Y-%m-%d')\nfirst_test_date=(to_day+pd.DateOffset(days=-10)).strftime('%Y-%m-%d')\nlast_test_date=to_day.strftime('%Y-%m-%d')\nfirst_valid_date=(to_day+pd.DateOffset(days=-2)).strftime('%Y-%m-%d')\n\nprint('first_train_date=',first_train_date)\nprint('last_train_date=',last_train_date)\nprint('first_bootstrap_date=',first_bootstrap_date)\nprint('boost_bootstrap_date=',boost_bootstrap_date)\nprint('first_test_date=',first_test_date)\nprint('last_test_date=',last_test_date)\nprint('first_valid_date=',first_valid_date)\n\ntrain_df=train[train['date']>first_train_date]\ntrain_df=train[train['date']<last_train_date]\nboots=train_df[train_df['date']>=first_bootstrap_date] # some bootstrap to give more weight for recent days\ntrain_df=train_df.append([boots[boots['date']>=boost_bootstrap_date]]*5,ignore_index=True)\n\n### Train progression of the Virus ### In Country list or Spain only\nregion_to_train=my_train_list\ntrain_df_v2=train_df[train_df['region'].isin(region_to_train)] # =='Spain_nan'] #\ntest=train[train['date']>first_test_date]\ntest=test[test['date']<=last_test_date]\ntest_v2=test[test['region'].isin(region_to_train)]\nvalid_v2=test_v2[test_v2['date']>=first_valid_date]\n","66465655":"x_col=[#'region',\n            '1_day_change', '3_day_change','7_day_change',\n            '1_day_change_rate', \n            '3_day_change_rate',\n            '7_day_change_rate', \n            'last_day',\n            'min', 'max',\n            'infected_rate',\n            'kalman_prediction'\n          #  ,'population_percent_infected_rate_confirmed'\n          #  ,'delta_new_cases'\n          #  ,'delta_new_cases_per_1M_hab'\n          ]","e8196594":"x=train_df[x_col]\ny=train_df['confirmed']\nreg = LinearRegression().fit(x,y)\n\npred2=reg.predict(test[x_col]); pred2=pd.DataFrame(pred2); pred2=round(pred2)\npred2['confirmed']=test['confirmed'].values; pred2['date']=test['date'].values; pred2['region']=test['region'].values\n","0042a9be":"pred2.iloc[:25]","fd504ea6":"pred2.iloc[175:195]","7af67498":"pred2.iloc[220:240]","44af2f79":"#\ntrain_h20 = h2o.H2OFrame(train_df)\n###train_h20_hubei = h2o.H2OFrame(train_df_hubei) # different model for Hubei\n#\n### Joao - Italian Model\ntrain_h20_v2 = h2o.H2OFrame(train_df_v2) # different model for V2 region ### Spain This time\n\n\ntest_h20 = h2o.H2OFrame(test)\n#test_h20_hubei = h2o.H2OFrame(test_hubei)\ntest_h20_v2 = h2o.H2OFrame(test_v2)\n\nvalid_h20_v2=h2o.H2OFrame(valid_v2)\n\n#training_columns = ['region','1_day_change', '3_day_change', '7_day_change','1_day_change_rate','3_day_change_rate','7_day_change_rate','last_day', 'kalman_prediction','infected_rate', 'min', 'max']\ntraining_cols_v2 = ['region']+x_col #+['population_percent_infected_rate_confirmed','delta_new_cases','delta_new_cases_per_1M_hab']\ntraining_columns = training_cols_v2\n\n# Output parameter train against input parameters\nresponse_column = 'confirmed'\n\n# model = H2ORandomForestEstimator(ntrees=300, max_depth=12)\n# model.train(x=training_columns, y=response_column, training_frame=train_h20)\n\n###model_hubei = H2ORandomForestEstimator(ntrees=300, max_depth=12)\n###model_hubei.train(x=training_columns, y=response_column, training_frame=train_h20_hubei)\n\n### Joao - Model V2\nmodel_v2 = H2ORandomForestEstimator(ntrees=500, max_depth=23)\nmodel_v2.train(x=training_columns, y=response_column, training_frame=train_h20_v2, validation_frame=valid_h20_v2)\n","65c7977a":"#Print Model\n\nprint('# MSE on the training data = ',model_v2.mse())\nprint('# MSE on the validation data = ',model_v2.mse(valid=True))\nprint('# R^2 on the training data = ',model_v2.r2())\nprint('# R^2 on the validation data',model_v2.r2(valid=True))","8421c9ad":"model_v2.show()","61cd52c9":"#model_hubei.varimp(True).iloc[:,:] # Feature importance for Hubei Model RF\n### Joao -  Model V2\nmodlv2=model_v2.varimp(True).iloc[:,:] # Feature importance for Model V2 Global RF\nmodlv2.sort_values('percentage',ascending=False)","2563d319":"## Joao - Model Predictions - Country_nan _v2\nperformance = model_v2.model_performance(test_data=test_h20_v2)\n# # Model Create Predictions\npred=model_v2.predict(test_h20_v2);pred=pred.as_data_frame(); pred=round(pred)\n# #pred['daily_outcome']=test['daily_outcome'].values\npred['confirmed']=test_v2['confirmed'].values\npred['date']=test_v2['date'].values\npred['region']=test_v2['region'].values","0c13010e":"from string import ascii_letters\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"white\")\n# Compute the correlation matrix\ncorr = train.iloc[:,2:].corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.9, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nprint ('Correlation Matrix')","37debfde":"print('Correlation To Confirmed') \nprint (corr.confirmed)","536cca78":"import matplotlib.pyplot as plt\np=train[['date','region','min','max']].set_index('date')\n#\n#rg1='China_Hubei'\n#p=p[p['region']==rg1]\n#p.iloc[:,:].plot(marker='*',figsize=(12,4),color=['#19303f','#cccc00']).set_title('Daily Min\/Max Temperature - '+rg1,fontdict={'fontsize': 20})\n#\n## JOAO - Temp. Teast Italy - Data Supply finishes 13\/03\/2020\nregion_s=['Italy_nan','Spain_nan','United States_nan','United Kingdom_nan','Germany_nan','Iran_nan',\n          'Korea, South_nan','China_Hubei','Brazil_nan','Portugal_nan','Turkey_nan',\n          'Canada_Ontario','Canada_Quebec']\np=train[['date','region','min','max']].set_index('date')\nfor i in range(0,len(region_s)):     \n    pv=p[p['region']==region_s[i]]\n    pv.iloc[:,:].plot(marker='*',figsize=(12,4),color=['#19303f','#cccc00']).set_title('Daily Min\/Max Temperature - '+region_s[i],fontdict={'fontsize': 20})\n#","f3a614cb":"avg_temp=train[['region','confirmed','min','max']]  # from 20-02-20 to 06-04-2020\navg_temp=avg_temp.groupby(by='region').max()\navg_temp=avg_temp.sort_values('confirmed',ascending=False)\nprint( 'Most infected Areas Avg Temperature')\nprint(avg_temp.iloc[:100,1:])","147872bf":"%%R\n\n#install.packages('reshape')","a5912311":"%%R\n\nrequire(pracma)\nrequire(Metrics)\nrequire(readr)\nlibrary(reshape)\nall<- read_csv(\"\/home\/notebookuser\/notebooks\/covid19\/data\/ts_conf_r.csv\")\nall$X1<-NULL\n\n### JOAO - FIX\n#\n### Flexy Days maximum forward prediction =A Hint!= \"Error increases as number of days increases\"\ndays_prediction<-max_days_prediction # Set i days prediction # max_days_prediction=90 days forward prediction with Kalman Filter\n\nfor (i in 1: days_prediction) { \n  if( i>1) {all<-all_new}\n  date<-all[,1]\n  date[nrow(date) + 1,1] <-all[nrow(all),1]+1\n  pred_all<-NULL\n  for (n in 2:ncol(all)-1) {\n    Y<-ts(data = all[n+1], start = 1, end =nrow(all)+1)  \n    sig_w<-0.01\n    w<-sig_w*randn(1,100) # acceleration which denotes the fluctuation (Q\/R) rnorm(100, mean = 0, sd = 1)\n    sig_v<-0.01\n    v<-sig_v*randn(1,100)  \n    t<-0.45\n    phi<-matrix(c(1,0,t,1),2,2)\n    gama<-matrix(c(0.5*t^2,t),2,1)\n    H<-matrix(c(1,0),1,2)\n    #Kalman\n    x0_0<-p0_0<-matrix(c(0,0),2,1)\n    p0_0<-matrix(c(1,0,0,1),2,2)\n    Q<-0.01\n    R<-0.01\n    X<-NULL\n    X2<-NULL\n    pred<-NULL\n    for (i in 0:nrow(all)) {\n      namp <-paste(\"p\", i+1,\"_\",i, sep = \"\")\n      assign(namp, phi%*%(get(paste(\"p\", i,\"_\",i, sep = \"\")))%*%t(phi)+gama%*%Q%*%t(gama))\n      namk <- paste(\"k\", i+1, sep = \"\")\n      assign(namk,get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)%*%(1\/(H%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)+R)))\n      namx <- paste(\"x\", i+1,\"_\",i, sep = \"\")\n      assign(namx,phi%*%get(paste(\"x\", i,\"_\",i, sep = \"\")))\n      namE <- paste(\"E\", i+1, sep = \"\")\n      assign(namE,Y[i+1]-H%*%get(paste(\"x\", i+1,\"_\",i, sep = \"\")))\n      namx2 <- paste(\"x\", i+1,\"_\",i+1, sep = \"\")\n      assign(namx2,get(paste(\"x\", i+1,\"_\",i, sep = \"\"))+get(paste(\"k\", i+1, sep = \"\"))%*%get(paste(\"E\", i+1, sep = \"\")))\n      namp2 <- paste(\"p\", i+1,\"_\",i+1, sep = \"\")\n      assign(namp2,(p0_0-get(paste(\"k\", i+1, sep = \"\"))%*%H)%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\")))\n      X<-rbind(X,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[1])\n      X2<-rbind(X2,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[2])\n      if(i>2){\n        remove(list=(paste(\"p\", i-1,\"_\",i-2, sep = \"\")))\n        remove(list=(paste(\"k\", i-1, sep = \"\")))\n        remove(list=(paste(\"E\", i-1, sep = \"\")))\n        remove(list=(paste(\"p\", i-2,\"_\",i-2, sep = \"\")))\n        remove(list=(paste(\"x\", i-1,\"_\",i-2, sep = \"\")))\n        remove(list=(paste(\"x\", i-2,\"_\",i-2, sep = \"\")))}\n    } \n    pred<-NULL\n    pred<-cbind(Y,X,round(X2,4))\n    pred<-as.data.frame(pred)\n    pred$region<-colnames(all[,n+1])\n    pred$date<-date$date\n    pred$actual<-rbind(0,(cbind(pred[2:nrow(pred),1])\/pred[1:nrow(pred)-1,1]-1)*100)\n    pred$predict<-rbind(0,(cbind(pred[2:nrow(pred),2])\/pred[1:nrow(pred)-1,2]-1)*100)\n    pred$pred_rate<-(pred$X\/pred$Y-1)*100\n    pred$X2_change<-rbind(0,(cbind(pred[2:nrow(pred),3]-pred[1:nrow(pred)-1,3])))\n    pred_all<-rbind(pred_all,pred)\n  }\n  pred_all<-cbind(pred_all[,4:5],pred_all[,1:3])\n  names(pred_all)[5]<-\"X2\"\n  pred_all<-pred_all[,1:5]\n       \npred_all_today=pred_all[with( pred_all, order(region, date)), ]\nall_new=all\n#all_new[nrow(all_new),1]<-all_new[nrow(all),1]+1\ntemp<-with(pred_all_today, pred_all_today[date == all[nrow(all),1]+1, ])\ntemp<-cbind(temp[,1:2],temp[,4])\ntemp2<-reshape(temp, direction = \"wide\", idvar = \"date\", timevar = \"region\")\nrand_num<-runif(ncol(temp2)-1, 0.9, 1.05)\ntemp2[,2:ncol(temp2)]<-temp2[,2:ncol(temp2)]*rand_num\ncolnames(temp2)=colnames(all_new)\nall_new<-rbind(all_new,temp2)\nall_new[,2:ncol(all_new)]<-round(all_new[,2:ncol(all_new)])\nfor (i in 2:ncol(all_new)) {\n  all_new[nrow(all_new),i]=max(all_new[nrow(all_new)-1,i],all_new[nrow(all_new),i])}\n}","cbb9188b":"all_new=%R all_new","5c67300b":"all_new['date']=pd.to_datetime(all_new['date'],unit='d')","9c22b811":"#\n### Joao - Moving Forward ...\n# Select regions From my_train_list\n#\nregion=['date']+my_train_list\np_kalman=all_new[region]\n#p=all_new\n#p.iloc[len(p)-1,2]=None\np_kalman=p_kalman.set_index(['date'])\np_kalman.iloc[:,:].plot(marker='o',figsize=(24,14)).set_title('Kalman Prediction')\n#\np_kalman2=all_new[['date','United States_nan']] ## Joao\np_kalman2=p_kalman2.set_index(['date'])\np_kalman2.iloc[:,:].plot(marker='o',figsize=(24,14)).set_title('Kalman Prediction - Select Country\/Region to Change - {}'.format(p_kalman2.columns[0]))\n#\np_kalman3=all_new[['date','Italy_nan']] ## Joao\np_kalman3=p_kalman3.set_index(['date'])\np_kalman3.iloc[:,:].plot(marker='o',figsize=(24,14)).set_title('Kalman Prediction - Select Country\/Region to Change - {}'.format(p_kalman3.columns[0]))\n#\np_kalman4=all_new[['date','Spain_nan']] ## Joao\np_kalman4=p_kalman4.set_index(['date'])\np_kalman4.iloc[:,:].plot(marker='o',figsize=(24,14)).set_title('Kalman Prediction - Select Country\/Region to Change - {}'.format(p_kalman4.columns[0]))\n#","a4956dff":"### Joao - Dynamic plot all regions individually\n#print(region[:])\nfor i in range(1,len(region)):\n    country_print=region[i]\n    #print(\"here:\"+country_print)\n    p_kalman_rg=all_new[['date',country_print]]\n    p_kalman_rg=p_kalman_rg.set_index(['date'])\n    p_kalman_rg.iloc[:,:].plot(marker='o',figsize=(16,8)).set_title('Kalman Prediction - Select Country\/Region to Change - {}'.format(p_kalman_rg.columns[0]))\n    ","01f7fd7f":"max_p0=all_new[:]\nmax_p0=max_p0.max()\nmax_date=max_p0[:1]\nmax_p0=max_p0[1:]\nmax_p0=pd.DataFrame(max_p0)\nmax_p0=max_p0.astype(str)\nmax_p0['pred_confirmed']=max_p0[max_p0.columns[0]].str.split(' ').str[-1].astype(float)\nmax_p0[max_p0.columns[0]]=max_p0[max_p0.columns[0]][:-len(max_p0['pred_confirmed'])]\nmax_p0=max_p0.sort_values(by='pred_confirmed', ascending=False)\n#\nprint(\"### -- Confirmed max cases per country at last prediction date -- ###\")\nprint(max_date)\nmax_p0[:]","022c5978":"t.to_csv(r'data\/t_confirmed_global.csv', index = False, header=True)","ddeb0454":"all_new.to_csv(r'data\/prediction_kalman_filter_global.csv', index = False, header=True)","75ded56e":"t_iter=all_new.set_index(['date'])\nt_iter=t_iter.stack().reset_index(name='confirmed')\nt_iter.columns=['date', 'region','confirmed']\nt_iter['date']=pd.to_datetime(t_iter['date'] ,errors ='coerce')\nt_iter=t_iter.sort_values(['region', 'date'])\n\nt_iter=t_iter.reset_index(drop=True)\nfor i in range(1,len(t_iter)+1):\n    if(t_iter.iloc[i,1] is not t_iter.iloc[i-1,1]):\n        t_iter.loc[len(t_iter)+1] = [t_iter.iloc[i-1,0]+ pd.DateOffset(1),t_iter.iloc[i-1,1], 0] \nt_iter=t_iter.sort_values(['region', 'date'])\nt_iter=t_iter.reset_index(drop=True)\n\n### Joao - Fix - RuntimeWarning: divide by zero encountered in double_scalars\n#\nt_iter['1_day_change']=t_iter['3_day_change']=t_iter['7_day_change']=t_iter['1_day_change_rate']=t_iter['3_day_change_rate']=t_iter['7_day_change_rate']=t_iter['last_day']=0\nfor i in range(1,len(t_iter)):\n    if(t_iter.iloc[i,1] is t_iter.iloc[i-2,1]):\n        t_iter.iloc[i,3]=t_iter.iloc[i-1,2]-t_iter.iloc[i-2,2]\n        t_iter.iloc[i,6]=((t_iter.iloc[i-1,2]*100 +1)\/(t_iter.iloc[i-2,2]*100 -1 +1))*100\n        t_iter.iloc[i,9]=t_iter.iloc[i-1,2]\n    if(t_iter.iloc[i,1] is t_iter.iloc[i-4,1]):\n        t_iter.iloc[i,4]=t_iter.iloc[i-1,2]-t_iter.iloc[i-4,2]\n        t_iter.iloc[i,7]=((t_iter.iloc[i-1,2]*100 +1)\/(t_iter.iloc[i-4,2]*100 -1 +1))*100\n    if(t_iter.iloc[i,1] is t_iter.iloc[i-8,1]):\n        t_iter.iloc[i,5]=t_iter.iloc[i-1,2]-t_iter.iloc[i-8,2]\n        t_iter.iloc[i,8]=((t_iter.iloc[i-1,2]*100 +1)\/(t_iter.iloc[i-8,2]*100 -1 +1))*100\nt_iter=t_iter.fillna(0)  \n\n# t_iter=t_iter.merge(temp[['date','region', 'X']],how='left',on=['date','region'])\n# t_iter=t_iter.rename(columns = {'X':'kalman_prediction'}) \nt_iter=t_iter.replace([np.inf, -np.inf], 0)\nt_iter['kalman_prediction']=round(t_iter['confirmed'])\n\ntest_iter=t_iter.merge(confirmed[['region',' Population ']],how='left',on='region')\ntest_iter=test_iter.rename(columns = {' Population ':'population'})\ntest_iter['population']=test_iter['population'].str.replace(r\" \", '')\ntest_iter['population']=test_iter['population'].str.replace(r\",\", '')\ntest_iter['population']=test_iter['population'].fillna(10000000) # Fill 10M population if null\ntest_iter['population']=test_iter['population'].astype('int32')\n## Joao - Fix Divid By Zero\n#test_iter['infected_rate'] =test_iter['last_day']\/test_iter['population']*10000\n#test_iter['infected_rate'] =((test_iter['last_day']+1)*10000)\/((test_iter['population']+1)*100)*100\ntest_iter['infected_rate']=(((test_iter['last_day'] +1)*100)\/((test_iter['population'] +1)*100000) *10)\n#\ntest_iter=test_iter.merge(w,how='left',on=['date','region'])\n#test_iter=test_iter.sort_values(['region', 'date'])\n\ntest_iter_temp=test_iter[np.isnan(test_iter['min'])]\ntest_iter_temp=test_iter_temp.drop(columns=['min', 'max'])\ntest_iter_temp=test_iter_temp.merge(w_forecast,how='left',on=['date','region'])\ntest_iter=test_iter.dropna()\ntest_iter=test_iter.append(test_iter_temp)\ntest_iter=test_iter.sort_values(['region', 'date'])\n### fill missing weather \nfor i in range(0,len(test_iter)):\n    if(np.isnan(test_iter.iloc[i,13])):\n        if(test_iter.iloc[i,1] is test_iter.iloc[i-1,1]):\n            test_iter.iloc[i,13]=test_iter.iloc[i-1,13]+abs(test_iter.iloc[i-1,13]*.01)\n            test_iter.iloc[i,14]=test_iter.iloc[i-1,14]+abs(test_iter.iloc[i-1,14]*.01)\n","98065a6d":"test_iter=test_iter.fillna(0) \ntest_iter[test_iter.isnull().any(axis=1)]\n","7c6d91e7":"### JOAO - ERROR - ValueError: Index contains duplicate entries, cannot reshape\npred=reg.predict(test_iter[x_col]); pred=pd.DataFrame(pred); pred.columns = ['prediction'];pred=round(pred)\npred['confirmed']=test_iter['confirmed'].values; pred['date']=test_iter['date'].values; pred['region']=test_iter['region'].values\n\nfor i in range(1,len(pred)):\n    if(pred.iloc[i,3] is pred.iloc[i-1,3]):\n        if(pred.iloc[i,0]<pred.iloc[i-1,1]):\n            pred.iloc[i,0]=pred.iloc[i-1,1]\n### JOAO - Drop Duplicates\npred=pred.drop_duplicates(subset=['date','region'], keep='last', inplace=False)        \n### Joao - Save long term predictions\npred.to_csv('data\/pred_'+str(num_days_R_prediction)+'_days.csv', index = False, header=True)\n###\npred=pred.pivot(index='date',columns='region',values='prediction') # pivot pred df","2f906031":"pred[:]","86dd8d41":"region=[\n ### JOAO - LIST of Countries - Start here\n ###    'Andorra_nan', 'Morocco_nan',\n        'United States_nan',\n        'United Kingdom_nan',\n        'Italy_nan',\n        'Spain_nan',\n        'Germany_nan',\n        'France_nan',\n        'Turkey_nan',\n        'Iran_nan',\n        'China_Hubei',\n        'Belgium_nan',\n        'Brazil_nan',\n        'Switzerland_nan',\n        'Russia_nan',\n        'Netherlands_nan',\n        'Portugal_nan',\n        'Korea, South_nan',\n        'India_nan',\n        'Poland_nan',\n        'Australia_New South Wales',\n        'Sweden_nan',\n        'Singapore_nan',\n        'China_Hong Kong',\n        'Taiwan*_nan',\n        'Canada_Ontario',\n        'Canada_Quebec',\n        'China_Macau'\n  ### JOAO - LIST of Countries - Finish here     \n       ]\n\np=pred[region]\np[:].plot(marker='*',figsize=(24,14),title ='Major Areas Prediction')","684a786a":"#\nrgsx=['Italy_nan','Spain_nan','United States_nan','Switzerland_nan',\n      'Germany_nan','United Kingdom_nan','France_nan','Iran_nan',\n      'Sweden_nan','Netherlands_nan','Russia_nan','Poland_nan',\n      'Brazil_nan','Turkey_nan','Japan_nan',\n      'Portugal_nan','Canada_Ontario','Canada_Quebec','China_Hubei']\nfor i in range (0,len(rgsx)):\n        rg_print=rgsx[i]\n        pred_prg=pd.DataFrame()\n        pred_prg=pred[rg_print]\n        pred_prg[:].plot(marker='*',figsize=(16,8),title =rg_print+' - Prediction Long Term - Confirmed Cases Covid-19')\n        plt.legend(loc = 'upper left')\n        plt.show()\n#","1035fcf9":"#region=my_train_list\npv2=pred\npv2[:].plot(marker='*',figsize=(24,14),title ='World Global - Long Term - Major Areas Prediction')\nplt.legend(loc = 'upper left')\nplt.show()","c0bf48ca":"pv1=pv2[:] #p  #p2.append(p3).append(p4).append(p5).append(p6).append(p8).append(p9).append(p11)\np=pd.DataFrame(pv1)","946d7b79":"p[45:]","b23888b9":"pfname='data\/p+'+str(num_days_R_prediction)+'_confirmed_daily.csv'\np.to_csv(pfname, index = False, header=True)","a43eb83f":"#!pip install gmplot\n# Import the necessary libraries\nimport pandas as pd\nimport gmplot\n# For improved table display in the notebook\n#from IPython.display import display\nimport random ","c5057f0d":"heatmap=confirmed[['region','Lat','Long']]\np_m=p.T # pred.T #\n### JOAO - Change Global HeapMap print - USA is too small, as USA States datasets are not used! \n#heatmap=heatmap[heatmap['region'].isin(region)]  ## heatmap for region dataset only \nheatmap=heatmap[heatmap['region'].isin(confirmed['region'])] ## Global heatmap\np_m=p_m.reset_index()\nheatmap_m=heatmap.merge(p_m,how='left',on='region')\n","9b5a71d0":"heatmap_m[:]","ff05010c":"#!pip install folium\nimport folium\nimport re\n\nlat=46.99474\nlang=6.87237\n\np21_cluster=folium.Map(location=[lat,lang],zoom_start=6)\nfrom folium import plugins\ncluster=plugins.MarkerCluster().add_to(p21_cluster)\n\ncolors={'A':'darkgreen','B':'darkpurple','C':'pink','D':'beige','E':'red','F':'lightblue','G':'darkblue','H':'cadetblue','I':'gray',\n        'J':'lightred','K':'blue','L':'orange','M':'lightgreen','N':'orange','O':'purple','P':'lightgray','Q':'darkred','R':'green',\n        'S':'black','T':'blue','U':'purple','V':'green','X':'blue','Y':'beige','W':'pink','Z':'white'}\n\ndate_pred=(datetime.today()+pd.DateOffset(days=num_days_R_prediction)).strftime('%Y-%m-%d')\n\nfor lat,lng,num,totpred in zip(heatmap_m.Lat,heatmap_m.Long,range(0,heatmap_m.shape[0]), heatmap_m[heatmap_m.columns[-1]] ):\n    use_color=heatmap_m['region'][num][0]\n    print_region=re.sub('_nan',  '', heatmap_m['region'][num])\n    popup = folium.Popup( print_region+' pred_confirmed='+str(round(totpred))+' date='+date_pred , parse_html=True)\n    #\n    folium.Marker(\n                    [lat,lng],\n                    popup=popup,\n                    icon=folium.Icon(color=colors[use_color])\n            ).add_to(p21_cluster)\np21_cluster","b32b0c7b":"#\nregion_m2=region + ['Andorra_nan','Monaco_nan','San Marino_nan','Ireland_nan','Slovenia_nan','Slovakia_nan','Czechia_nan',\n                    'Hungary_nan','Ukraine_nan','Croatia_nan','Finland_nan','Norway_nan','Estonia_nan','Denmark_nan','Greece_nan',\n                    'Chile_nan','Argentina_nan','Mexico_nan','Ecuador_nan','Peru_nan','Colombia_nan','Costa Rica_nan',\n                    'South Africa_nan','Morocco_nan','Algeria_nan','Saudi Arabia_nan','Israel_nan','Japan_nan',\n                    'Singapore_nan','Canada_British Columbia']\nheatmap_m2=heatmap_m[heatmap_m['region'].isin(region_m2)].reset_index()\n#\nheatmap_m2[:]","ebf754ca":"import folium\nimport re\n\nlat=46.99474\nlang=6.87237\n\np21_reg_cluster=folium.Map(location=[lat,lang],zoom_start=6)\nfrom folium import plugins\ncluster=plugins.MarkerCluster().add_to(p21_reg_cluster)\n\ncolors={'A':'darkgreen','B':'darkpurple','C':'pink','D':'beige','E':'red','F':'lightblue','G':'darkblue','H':'cadetblue','I':'gray',\n        'J':'lightred','K':'blue','L':'orange','M':'lightgreen','N':'orange','O':'purple','P':'lightgray','Q':'darkred','R':'green',\n        'S':'black','T':'blue','U':'purple','V':'green','X':'blue','Y':'beige','W':'pink','Z':'white'}\n\ndate_pred=(datetime.today()+pd.DateOffset(days=num_days_R_prediction)).strftime('%Y-%m-%d')\n\nfor lat2,lng2,num2,totpred2 in zip(heatmap_m2.Lat,heatmap_m2.Long,range(0,heatmap_m2.shape[0]), heatmap_m2[heatmap_m2.columns[-1]] ):\n    use_color2=heatmap_m2['region'][num2][0]\n    print_region=re.sub('_nan',  '', heatmap_m2['region'][num2])\n    popup2 = folium.Popup( print_region+' pred_confirmed='+str(round(totpred2))+' date='+date_pred , parse_html=True)  \n    #\n    folium.Marker(\n                    [lat2,lng2],\n                    popup=popup2,\n                    icon=folium.Icon(color=colors[use_color2])\n            ).add_to(p21_reg_cluster)\np21_reg_cluster","02ff2ccb":"#\ndatemap=datetime.today().strftime('%Y-%m-%d')\np21_cluster.save(\"heatmaps\/Heatmap_Folium-Global-\"+datemap+\"-pred\"+str(num_days_R_prediction)+\"Days.html\")\n#\np21_reg_cluster.save(\"heatmaps\/Heatmap_Folium-Regional-\"+datemap+\"-pred\"+str(num_days_R_prediction)+\"Days.html\")","d6066f34":"print(\"Stats and Forecast Done for Today!\")\nprint(\"I'm done with this past month of March and now April!\")\nprint(\" April-May-June are going to be hard with this Global Lock-Down!\")","66369425":"exit()","bfd87fb3":"### Extract Weather Forecast Data","4233a6ac":"## Iterative Regression","5d5631a1":"### Load Data from Github - John Hopkins Institute ","d3938790":"### Build Train Set Data Structure","024387f8":"Please Follow this Docker container installation process in your MacBook\/Laptop before running this Python+R Notebook below.\n\n  - Installation setup of environment where this notebook runs can be found i \n  Container with Jupyter+H2o.ai+Python3+R+Spark in this [link_here](https:\/\/github.com\/jpacerqueira\/project_lost_saturn)\n  \n  Also :\n  - You need a Strong bandwith the install the Container environment it takes about 10-11 minutes to finish.\n  \n  - Good Luck,  stay safe! But investigate Corona virus(covid-19 or SARS-Cov-2) in your area and give the information back to the comunity!\n","0457b0bf":"## Create Time Series + Plots","e7d5c64d":"#### Weather History","b94111d8":"## Correlation Matrix And Temperature","cb00b806":"### Extract Weather Data","4417a4b2":"### Kalman X Days Ahead Prediction","fd353208":"## Pre Proccessing Data for ML Model","adf3f53a":"# CoronaVirus Prediction","654ea2ee":"\n## Prediction Heatmap","87050011":"## Get Population","22c50830":"## Regression - 1 Day Prediction","729e1066":"## Kalman Filter With R","0d716086":"### Number of Day to Predict 21","879abed8":"## Kalman 1 day Prediction with Evaluation"}}