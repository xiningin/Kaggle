{"cell_type":{"da2107fc":"code","4096aace":"code","55e297c2":"code","f4a508ba":"code","96e35f65":"code","c2547277":"code","45d025e6":"code","a7266e4f":"code","03c81550":"code","a4fe5651":"code","01507242":"code","a505d4ed":"code","7c6aec69":"code","54d12629":"code","216504ed":"code","a4bb2955":"code","b9530973":"code","149ef75a":"code","fc7c4805":"code","6256e4b6":"markdown","dc209636":"markdown","17d51036":"markdown","cc8dba95":"markdown","de36ef11":"markdown","75f26467":"markdown","0a637f5c":"markdown","9ca2770f":"markdown","3ef85e30":"markdown","4c646b1b":"markdown","56af6125":"markdown","366b7fbb":"markdown","867519ea":"markdown","18d7b564":"markdown","3646aec2":"markdown","7d9b0012":"markdown","8dcc3bdb":"markdown","c961913a":"markdown"},"source":{"da2107fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4096aace":"raw_data = pd.read_csv('\/kaggle\/input\/forest-fires-in-brazil\/amazon.csv', encoding = 'latin1', thousands = '.')","55e297c2":"month_list = raw_data.groupby('month').size()\nmonth_inspan = month_list.index.values.tolist()\nmonth_innum = [4,8,12,2,1,7,6,5,3,11,10,9]\nreplace_dic = {}\nfor i in range(len(month_inspan)):\n    replace_dic[month_inspan[i]] = month_innum[i]\nfire_data = raw_data.replace({'month': replace_dic})\nprint('Converted Data looks like this:')\nfire_data.head()","f4a508ba":"# sort the data, get the raw time line\nfire_data = fire_data.sort_values(by = ['state','year','month'])","96e35f65":"state_rownum = fire_data.groupby('state').size()\nprint(state_rownum)","c2547277":"Alagoas_data = fire_data.query(\"state == 'Alagoas'\")\nAlagoas_data.sort_values(by = ['year','month'])","45d025e6":"temp = set()\nfor i in range(len(Alagoas_data)):\n    # this is just for checking, so no matter how ugly the elements in temp set looks\n    if (Alagoas_data.iloc[i]['year'] * 100 + Alagoas_data.iloc[i]['month']) not in temp:\n        temp.add(Alagoas_data.iloc[i]['year'] * 100 + Alagoas_data.iloc[i]['month'])\n    else:\n        print('Duplicate Data')\n        print(Alagoas_data.iloc[i])","a7266e4f":"Alagoas_data.loc[(Alagoas_data.year == 2017)&(Alagoas_data.month ==1)]","03c81550":"print('Description of the fire dataset')\nprint(fire_data.describe())\nprint('\\n')\nprint('Description of Alagoas data')\nprint(Alagoas_data.describe())","a4fe5651":"2007.5 * 240 - 2007.461729 * 239","01507242":"data_16 = Alagoas_data.query(\"year == 2016\")\nprint(data_16)","a505d4ed":"data_17 = Alagoas_data.query(\"year == 2017\")\nprint(data_17)","7c6aec69":"fire_data = fire_data.drop(fire_data[(fire_data['state'] == 'Mato Grosso') | (fire_data['state'] == 'Paraiba') | (fire_data['state'] == 'Rio') ].index)\nif fire_data.iloc[258].empty == False:\n    fire_data = fire_data.drop(258)\nprint(fire_data.groupby('state').size())","54d12629":"fire_formatted = fire_data\n# need to do reset index otherwise rows removed will be an issue\nfire_formatted = fire_formatted.reset_index(drop = True)\nfor i in range(len(fire_formatted)):\n    fire_formatted.at[i,'happened_date'] = str(fire_formatted.at[i, 'year']) + '-' + str(fire_formatted.at[i, 'month'])\nfire_formatted","216504ed":"dt = pd.DataFrame(fire_formatted, columns = ['state', 'number','happened_date'])\n# group data by different states\ngroupby_state = dt.groupby('state')","a4bb2955":"fire = []\ntime = []\nstate_name = []\n\nfor i in range(len(dt)):\n    if dt.iloc[i,2] not in time:\n        time.append(dt.iloc[i,2])\n    if dt.iloc[i,0] not in state_name:\n        state_name.append(dt.iloc[i,0])\n\nfor state, item in groupby_state:\n        fire.append(item.iloc[:,1].values.tolist())\n\n\nfire_dt = pd.DataFrame(fire, columns = time)\nfire_dt.insert(loc = 0, column = 'state', value = state_name)","b9530973":"print('Head:')\nprint(fire_dt.head())\nprint('\\n')\nprint('Describe')\nprint(fire_dt.describe())\nprint('\\n')\nprint('info')\nprint(fire_dt.info())","149ef75a":"fire_dt.to_csv('state_timeline.csv')","fc7c4805":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(50,25))\nfor i in range(1, fire_dt.shape[0]):\n    plt.plot(fire_dt.columns[1:].tolist(), fire_dt.iloc[i,1:].values.tolist(), label = fire_dt.iloc[i,0], color = np.random.rand(3,))\n\nplt.xlabel('Date')\nplt.ylabel('Number')\nplt.xticks(rotation=90)\nplt.legend()\nplt.show()","6256e4b6":"It seems that we have dupicate rows with different 'number' item. It is because some states in Brazil share the same abbrevation. This problem cannot be solved in this dataset. What we can do is to remove all states with the same abbrevation, just keep the ones that could be analyze.\n\nOr you can visit [This Discussion](https:\/\/www.kaggle.com\/gustavomodelli\/forest-fires-in-brazil\/discussion\/117901) for dataset with whole state name. I already put the seperated dataset in my github and attached that link in my comment.\n\nLet's see what to be removed in the dataset provided by Kaggle:","dc209636":"\nWe can safely remove one of these two rows because they are exactly the same.","17d51036":"Than you can do other things like visualization by using this new dataset.","cc8dba95":"Then convert spanish month into numerical month.","de36ef11":"Than we can drop this duplicate row in the fire dataset, as well as ambiguous state abbrevations.","75f26467":"We can simply remove 'Mato Grosso', 'Paraiba', 'Rio' because these have two or three times items more than the other abbrevitions toward states.\n\nBut what's wrong with 'Alagoas'?","0a637f5c":"First inspect both fire dataset and Alagoas data by using df.describe()","9ca2770f":"Than locating the exact year by simple calculation","3ef85e30":"Split Alagoas from the raw dataset so you don't have to load the whole dataset for analyze.","4c646b1b":"Got it, the abnormal data will be either 2016 or 2017, let's inspect it.","56af6125":"Remenber use parameters \"encoding\" and \"thousands\" while importing the data, otherwise there will be an error with encoding or you will get 1.000 (number 'one' with decimal point) instead of 1000 if you want to read the number \"one thousand\"","366b7fbb":"Drop rows that is not useful:","867519ea":"## Remove abnormal data in state 'Alagoas'","18d7b564":"It is easy to find there are two month '1's in 2017, it is the duplicate month number we need to remove.","3646aec2":"There are two ways to find out the abnormal data, one is to use set in python to find the duplicated variables automatically, another one is quite tricky.","7d9b0012":"### Solution 2. Mathmetical T[](http:\/\/)rick","8dcc3bdb":"### Solution 1. Using python set","c961913a":"Now we can create a dataset with states and time line"}}