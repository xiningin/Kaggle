{"cell_type":{"6e4cdad4":"code","633e3f76":"code","bd0e2ff5":"code","bc13b25e":"code","edb964f9":"code","9afda2a6":"code","2cdeee34":"code","98015ba3":"code","f12ce576":"code","6d995988":"code","da014f7a":"code","92f33c76":"code","71f437b6":"code","ca5c9fa2":"markdown","363ffacf":"markdown","fd6ec1f9":"markdown","60036dfc":"markdown","6135b394":"markdown","b976b224":"markdown","b980081d":"markdown","c52815f0":"markdown","26fc5ed7":"markdown","67e6c5c3":"markdown","5f221695":"markdown","d4365db0":"markdown","c60a5dec":"markdown"},"source":{"6e4cdad4":"import numpy as np \nfrom sklearn import preprocessing\ninput_data = np.array([[2.6,-6.5,3.1],\n                      [-2.5,8.2,-3.4],\n                      [5.1,-6.4,5],\n                      [0.4,-0.5,9.8]])\n\ndata_binary = preprocessing.Binarizer(threshold=2.6).transform(input_data)\nprint(data_binary)\n","633e3f76":"\nprint(\"\\n\u00d6nce Standart sapmas\u0131 ve ortalama:\")\nprint(\"Ortalama =\", input_data.mean(axis=0))\nprint(\"Standart Sapma =\", input_data.std(axis=0))\n\ndata_scaled = preprocessing.scale(input_data)\nprint(\"\\nSonra:\")\nprint(\"Ortalama =\", data_scaled.mean(axis=0))\nprint(\"Standart Sapma =\", data_scaled.std(axis=0))\n\n","bd0e2ff5":"data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0, 1))\ndata_scaled_minmax = data_scaler_minmax.fit_transform(input_data)\nprint(\"\\nMin max de\u011ferlere g\u00f6re \u00f6l\u00e7eklenen datam\u0131z:\\n\", data_scaled_minmax)\n","bc13b25e":"data_normalized_mutlak_sapma = preprocessing.normalize(input_data, norm='l1')\ndata_normalized_toplam = preprocessing.normalize(input_data, norm='l2')\nprint(\"\\n mutlak sapma  normalized data:\\n\", data_normalized_mutlak_sapma)\nprint(\"\\n toplam deger  normalized data:\\n\", data_normalized_toplam)","edb964f9":"# baz\u0131 \u00f6rnek label tan\u0131mlayal\u0131m \ninput_labels = ['k\u0131rm\u0131z\u0131', 'siyah', 'k\u0131rm\u0131z\u0131', 'yesil', 'siyah', 'sar\u0131', 'beyaz']\n\n\n#\u015fimdi nesnemizi olu\u015ftural\u0131m ve \u00f6\u011fretelim \nencoder = preprocessing.LabelEncoder()\nencoder.fit(input_labels)\n\n#kelimeler ve say\u0131lar aras\u0131ndaki e\u015fle\u015fmeyi yazd\u0131ral\u0131m \n\nprint('\\n Label mapping :')\nfor i , item  in enumerate(encoder.classes_):\n    print(item , '---> ' , i)\n\n#Nas\u0131l performans g\u00f6sterdi\u011fini g\u00f6rmek i\u00e7in rastgele s\u0131ral\u0131 bir etiket k\u00fcmesi kodlayal\u0131m\n\ntest_labels = ['yesil', 'k\u0131rm\u0131z\u0131', 'siyah']\nencoded_values = encoder.transform(test_labels)\nprint(\"\\nLabels =\", test_labels)\nprint(\"Encoded values =\", list(encoded_values))\n\n\n\n#test i\u00e7in de decoded yapal\u0131m \nencoded_values = [3, 0, 4, 1]\ndecoded_list = encoder.inverse_transform(encoded_values)\nprint(\"\\nEncoded values =\", encoded_values)\nprint(\"Decoded labels =\", list(decoded_list))\n\n\n","9afda2a6":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nsns.set(style='white', context='notebook', palette='deep')","2cdeee34":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","98015ba3":"Y_train = train[\"label\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\n# free some space (eskisini siliyoruz , bellek harcamamas\u0131 i\u00e7in )\ndel train \n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()\n# bir di\u011fer g\u00f6sterimi \n#print(Y_train.value_counts(dropna=False))\n","f12ce576":"# check the data ( datam\u0131z\u0131 kontrol edelim )\nX_train.isnull().any().describe()\n#unique--> benzersiz ","6d995988":"test.isnull().any().describe()\n#bir di\u011fer g\u00f6sterimi ","da014f7a":"# Normalize the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0","92f33c76":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","71f437b6":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)\n","ca5c9fa2":"# Load Data ","363ffacf":"# Reshape ","fd6ec1f9":"### Normalization ( Normalle\u015ftimer  ) \nForm\u00fcl\u00fc \u00e7ok basit ve datam\u0131z\u0131 daha etkin k\u0131lmak i\u00e7in \u00e7ok kullan\u0131lan bir \u00f6ni\u015flemedir.\n\n## V'' = (  V -  Vmin )   \/ (  Vmax - Vmin) \n\nAmac\u0131m\u0131z : y\u00fcksek de\u011ferlere sahip \u00f6zniteliklerimizin d\u00fc\u015f\u00fck de\u011ferli \u00f6zniteliklerimize bask\u0131nl\u0131k **sa\u011flamamas\u0131** i\u00e7indir. \n\n\nBurada k\u00fc\u00e7\u00fck not olarakda mutlak sapma ile normalization da kullan\u0131l\u0131r ancak \nmutsap sapma tekni\u011fi daha \u00e7ok kullan\u0131l\u0131r . Sebebi isi baz\u0131 \u00f6zniteliklerimiz di\u011fer \u00f6zniteliklerimizen daha de\u011ferli olma olas\u0131l\u0131\u011f\u0131d\u0131r..\n","60036dfc":"#  Eksik ve bo\u015f de\u011ferleri kontrol edelim \u00b6\n","6135b394":"### Scaling ( \u00d6l\u00e7eklendirme ) \n\n Dizimizdeki **sat\u0131rda** en y\u00fcksek de\u011fer max de\u011fer se\u00e7ilir  \nBizim i\u00e7in **max** de\u011fer 1 dir \nnegatif say\u0131lar s\u0131f\u0131rd\u0131r \n\u00e7\u00fcnk\u00fc \u00f6l\u00e7eklendirmeyi 0-1 aras\u0131 yapar\u0131z negatif say\u0131lar\u0131 ortamatik **min** de\u011ferimiz olan 0 yapar\u0131z\n\n","b976b224":"Train ve test g\u00f6r\u00fcnt\u00fcleri (28px x 28px) pandalara konulmu\u015ftur.Dataframe 784 de\u011ferinde 1 boyutlu vekt\u00f6rlerdir . T\u00fcm verileri 28x28x1 3 boyutlu  matrislere g\u00f6re yeniden \u015fekillendiriyoruz.\n\nKeras, sonunda kanallara kar\u015f\u0131l\u0131k gelen ekstra bir boyut gerektirir. MNIST g\u00f6r\u00fcnt\u00fcler gri tonlamal\u0131d\u0131r, bu nedenle sadece bir kanal kullan\u0131r. RGB g\u00f6r\u00fcnt\u00fcleri i\u00e7in 3 kanal var, 784px vekt\u00f6rleri 28x28x3 3 boyutlu  matrislere yeniden \u015fekillendirirdik.\n\n","b980081d":"#  introduction to Deep Learning with  Keras  \n (Celal Bayar Universty  Software Engineer Deep Learning  Education ) \n## \n\n\n<a class=\"anchor\" id=\"0.\"><\/a>**\u0130\u00e7indekiler**\n* [1. Preprocessing Data (Veri \u00d6ni\u015fleme)](#1.)****\n* * [1.1. Binarization](#1.1.)\n* * [1.2. Mean removal](#1.2.)\n* * [1.3. Scaling  (\u00d6l\u00e7eklendirme)](#1.3.)\n* * [1.5. Normalization ](#1.4.)\n* * [1.6. Normalization ](#1.4.)\n* * [1.7. Load  Data ](#1.2.)\n* * [1.8. Check for null and missin value ](#1.3.)\n* * [1.9. Reshape (Yeniden \u015eekillendirme](#1.4.)\n* * [1.8. Split Ttraining  (Yeniden \u015eekillendirme](#1.4.)\n* [2. CNN  (Convolutional Neural Network) ](#2.)****\n* * [2.1. Define the Model ( Modeli Tan\u0131mla )  ](#1.3.)\n* * [2.2. Set the optimizer and Annealer (Optimize Edici ) ](#1.4.)\n* * [2.3. Data Augmentations   (Veri B\u00fcy\u00fctme ) ](#1.4.)\n","c52815f0":"# K\u00fct\u00fcphane  ekle ..... ","26fc5ed7":"### Mean Removal\nMakine \u00f6\u011frenimde olduk\u00e7a kullan\u0131lan bir \u00f6ni\u015fleme tekni\u011fidir !! \nortalamas\u0131 ve standart sapmas\u0131n\u0131  hesaplad\u0131\u011f\u0131m\u0131z bir y\u00f6ntemdir\nDatasetimizi  bu hesaplamara g\u00f6re yeniden  \u015fekillendirdi\u011fimiz bir \u00f6ni\u015fleme ad\u0131m\u0131d\u0131r.\n","67e6c5c3":"### Binarization\nBurada Dataset ' imizde  veri 'boolen'  de\u011ferlerine d\u00f6n\u00fc\u015ft\u00fcrmektir amac\u0131m\u0131z .  (true- false \/ 0 - 1)\n\nE\u015fik aral\u0131\u011f\u0131 belirleyin ve bu e\u015fik aral\u0131\u011f\u0131m\u0131z 0 (s\u0131f\u0131r ) olsun . negatif de\u011ferler  i\u00e7in False pozitif de\u011ferler i\u00e7in True sonucu d\u00f6necektir.\n\n### Peki 0 oldu\u011funda ne d\u00f6nd\u00fcr\u00fcr ?? :))) ","5f221695":"# Normalization\n\nAyd\u0131nlatma farkl\u0131l\u0131klar\u0131n\u0131n etkisini azaltmak i\u00e7in gri tonlamal\u0131 bir normalizasyon ger\u00e7ekle\u015ftiriyoruz.\n\n\n**\u00dcstelik, CNN [0..1] verisinde [0..255] 'den daha h\u0131zl\u0131 bir \u015fekilde yak\u0131nla\u015f\u0131r.**","d4365db0":"## Label Encoding \n\nS\u0131n\u0131fland\u0131rma yapt\u0131\u011f\u0131m\u0131zda bir\u00e7ok label ile  u\u011fra\u015f\u0131r\u0131z\nBu label  i\u00e7inde kelimeler, say\u0131lar vey ba\u015fka \u015feyler olarabilir\nSklearn  makine \u00f6\u011frenmesi k\u00fct\u00fcphanesin bar\u0131nd\u0131ran bir k\u00fct\u00fcphane\nve bu k\u00fct\u00fcphane onlar\u0131n say\u0131sal de\u011fer olmas\u0131n\u0131 ister \u00e7\u00fcnk\u00fc onlar\u0131 do\u011frudan kullabilmesi i\u00e7in \n","c60a5dec":"10 rakam i\u00e7in benzer say\u0131lar\u0131m\u0131z var. "}}