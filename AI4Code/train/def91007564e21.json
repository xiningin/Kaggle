{"cell_type":{"8098c760":"code","d2ff9e9f":"code","e8ed14e0":"code","594bcdb8":"code","488b661e":"code","8a3005d1":"code","009258ad":"code","e5742942":"code","0291cae7":"code","c8095aa8":"code","e7d1e150":"code","8968d5ff":"code","7d225373":"code","7e9b6524":"code","35748bcb":"code","b4c5760b":"code","600e9f7f":"code","6cc7a2c1":"code","fcdf82bd":"code","41c94a72":"code","7322dae8":"code","361b7fcd":"code","5b29d8be":"code","19faf095":"code","3189040a":"code","8a11ed6e":"code","bc00441c":"code","bfafd35e":"code","f1e9f683":"code","6020a2e2":"markdown","792a75dc":"markdown","c95e5563":"markdown","83e29b45":"markdown","149c290e":"markdown","271f12c4":"markdown","ebd0f7a6":"markdown","8d8f8818":"markdown","ec9cc6c2":"markdown","1fc2b3b4":"markdown","1c6ac63b":"markdown"},"source":{"8098c760":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport random\nimport warnings\nfrom sklearn.metrics import confusion_matrix\nwarnings.filterwarnings('ignore')\n\n#File Operation libraries\nimport glob\nfrom pathlib import Path\n\n#Visualisation Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mlxtend.plotting import plot_confusion_matrix\n\n#TensorFlow\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n#Image Transformation Libraries\nimport cv2\nfrom imgaug import augmenters as iaa\n\n# Any results you write to the current directory are saved as output.","d2ff9e9f":"print(os.listdir(\"..\/input\/chest_xray\/chest_xray\/\"))","e8ed14e0":"base_dir = \"..\/input\/chest_xray\/chest_xray\/\"\ntrain_dir = base_dir+'train\/'\ntest_dir = base_dir+'test\/'\nval_dir = base_dir+'val\/'","594bcdb8":"def get_df(path):\n    lst = []\n    normal_dir = Path(path + \"NORMAL\")\n    pneumonia_dir = Path(path + \"PNEUMONIA\")\n    normal_data = normal_dir.glob(\"*.jpeg\")\n    pneumonia_data = pneumonia_dir.glob(\"*.jpeg\")\n    for fname in normal_data:\n        lst.append((fname, 0))\n    for fname in pneumonia_data:\n        lst.append((fname, 1))\n    df = pd.DataFrame(lst, columns=['Image', 'Label'], index=None)\n    s = np.arange(df.shape[0])\n    np.random.shuffle(s)\n    df = df.iloc[s,:].reset_index(drop=True)\n    return df","488b661e":"df_train = get_df(train_dir)\ndf_val = get_df(val_dir)\ndf_test = get_df(test_dir)","8a3005d1":"df_train.shape, df_val.shape, df_test.shape","009258ad":"df_train['Label'].value_counts()","e5742942":"df_val['Label'].value_counts()","0291cae7":"df_test['Label'].value_counts()","c8095aa8":"fig, ax = plt.subplots(figsize=(8, 8))\nsns.countplot(df_train['Label'])\nax.set_title('Distribution of Images', fontsize=14)\nax.set_xlabel('Label', fontsize=12)\nax.set_ylabel('Count', fontsize=12)\nplt.show()","e7d1e150":"def transform_image(img_list):\n    img = cv2.resize(img_list, (224, 224))\n    #cv2 reads image in BGR format. Let's convert to RGB\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img   \n\ndef augment_image(img_list):\n    seq = iaa.OneOf([\n        iaa.Affine(\n            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n            rotate=(-25, 25)\n        ),\n        iaa.Fliplr(),\n        iaa.Multiply((1.2, 1.5))\n    ])\n    return seq.augment_image(img_list)\n\ndef transform_augment_batch(img_path_list, label_list, is_augment=False):\n    img_list = []\n    for i in range(len(img_path_list)):\n        img_list.append(transform_image(cv2.imread(str(img_path_list[i]))))\n    n = len(img_list)\n    if is_augment:\n        for i in range(n):\n            img = img_list[i]\n            img = augment_image(img)\n            img_list.append(img)\n        img_list = np.array(img_list)\n        label_list = np.append(label_list, label_list)\n    return img_list, label_list","8968d5ff":"fig, ax = plt.subplots(figsize=(12, 12))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    img = transform_image(cv2.imread(str(df_train.iloc[i, 0])))\n    plt.imshow(img)\n    if df_train.iloc[i, 1] == 0:\n        plt.title('Normal')\n    else:\n        plt.title('Pneumonia')\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","7d225373":"plt.subplots(figsize=(12, 12))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    img = transform_image(cv2.imread(str(df_train.iloc[i, 0])))\n    img = augment_image(img)\n    plt.imshow(img)\n    if df_train.iloc[i, 1] == 0:\n        plt.title('Normal')\n    else:\n        plt.title('Pneumonia')\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","7e9b6524":"val_labels = np.array(df_val.iloc[:, 1]).reshape((df_val.shape[0], 1))\nval_images, _ = transform_augment_batch(df_val.iloc[:, 0], df_val.iloc[:, 1], False)\nval_images = np.array(val_images)\nval_images = val_images \/ 255.0","35748bcb":"val_images.shape, val_labels.shape","b4c5760b":"test_labels = np.array(df_test.iloc[:, 1]).reshape((df_test.shape[0], 1))\ntest_images, _ = transform_augment_batch(df_test.iloc[:, 0], df_test.iloc[:, 1], False)\ntest_images = np.array(test_images)\ntest_images = test_images \/ 255.0","600e9f7f":"test_images.shape, test_labels.shape","6cc7a2c1":"# Let's start with the hyperparameters\nbase_learning_rate = 1e-3\nbatch_size=32\nepochs = 8","fcdf82bd":"# Placeholders\nX = tf.placeholder(dtype=tf.float32, shape=[None, 224, 224, 3])\nY = tf.placeholder(dtype=tf.float32, shape=[None, 1])\nis_train = tf.placeholder_with_default(False, shape=(), name=\"is_train\")","41c94a72":"global_step = tf.Variable(0, trainable=False)","7322dae8":"#Model from TensorHub\nmodule_spec = hub.load_module_spec(\"https:\/\/tfhub.dev\/google\/imagenet\/resnet_v2_50\/classification\/1\")\nmodule = hub.Module(module_spec)\nheight, width = hub.get_expected_image_size(module)","361b7fcd":"# images is a tensor of [batch, 224, 224, 3]\n# outputs is a tensor of [batch, 1001]\nfeatures = module(X)","5b29d8be":"#Use the features we got from graph and add sigmoid activation \nlogits = tf.layers.dense(inputs=features, units=1, activation='sigmoid')","19faf095":"#Learning Rate with exponential decay\nlearning_rate = tf.train.exponential_decay(base_learning_rate, global_step,1000, 0.96, staircase=True)","3189040a":"#Add loss, optimizer and accuracy to graph\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=Y))\nopt = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\naccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(logits), Y), tf.float32))","8a11ed6e":"#TF session\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)","bc00441c":"for epoch in range(epochs):\n    s = np.arange(df_train.shape[0])\n    np.random.shuffle(s)\n    X_dev = np.array(df_train.iloc[s, 0])\n    Y_dev = np.array(df_train.iloc[s, 1])\n    start_index = 0\n    counter = 0\n    while start_index < len(X_dev):\n        if start_index+batch_size <= len(X_dev):\n            end_index = start_index+batch_size\n        else:\n            end_index = len(X_dev)\n        #Select image paths in batches\n        x_dev = X_dev[start_index:end_index]\n        y_dev = Y_dev[start_index:end_index]\n        \n        #Transform images and augment\n        x_dev, y_dev = transform_augment_batch(x_dev, y_dev, True)\n        y_dev = y_dev.reshape((len(y_dev), 1))\n        \n        #Normalize\n        x_dev = x_dev \/ 255.0\n        \n        #Train model\n        _, cost, acc = sess.run([opt, loss, accuracy], feed_dict={X:x_dev, Y:y_dev, is_train:True})\n        start_index = end_index\n        counter += 1\n    val_acc = sess.run([accuracy], feed_dict={X:val_images, Y:val_labels, is_train:False})\n    test_logits = np.zeros((df_test.shape[0], 1))\n    start_index = 0\n    for i in range(0, df_test.shape[0], 16):\n        end_index = start_index + 16\n        test_batch_logits = sess.run([logits], feed_dict={X:test_images[start_index:end_index], \\\n                                                   Y:test_labels[start_index:end_index], is_train:False})\n        test_logits[start_index:end_index] = test_batch_logits[0]\n        start_index = end_index\n    test_acc = np.mean(np.equal(np.round(test_logits), test_labels))\n    print('Epoch:{0}, Test_Accuracy:{1}, Validation Accuracy:{2}'.format(epoch+1, test_acc, val_acc))","bfafd35e":"cm  = confusion_matrix(test_labels, np.round(test_logits))\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, cmap=plt.cm.Oranges)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.show()","f1e9f683":"true_negative, false_positive, false_negative, true_positive  = cm.ravel()\nprecision = true_positive \/ (true_positive + false_positive)\nrecall = true_positive \/ (true_positive + false_negative)\n\nprint('Precison of chest X-ray for pneumonia:{:.2f}'.format(precision))\nprint('Recall of chest X-ray for pneumonia:{:.2f}'.format(recall))","6020a2e2":"In this kernel, I will demonstrate the classification of chest X-ray images for pneumonia or normal. This is a binary image classification dataset. I will use TensorFlow Hub ResNet-50 transfer learning.\n\nI am also using imgaug for augmentation of images. Please verify my kernel [Data Augmentation in Python, TF, Keras, Imgaug](https:\/\/www.kaggle.com\/curiousprogrammer\/data-augmentation-in-python-tf-keras-imgaug) for more augmentation techniques.\n\nLet's start by importing necessary libraries.","792a75dc":"# Let's plot the confusion matrix","c95e5563":"# Deep Learning Model with TF Hub","83e29b45":"A helper function to generate dataframe with path and labels for train, validation and test sets.","149c290e":"# Let's arrange Validation and Test Data ","271f12c4":"Happy coding. Please upvote if you like this kernel.","ebd0f7a6":"# Time for some visualisations","8d8f8818":"# Training","ec9cc6c2":"Let's check precision and recall. In this case, we should get a good recall than precision.","1fc2b3b4":"There is a class imbalance pneumonia cases ~3x times the normal ones.\n\nLet's define a function to resize the images and to augment. Some of the images has 3 channels and some one. Let's make all images to RGB.","1c6ac63b":"As we visualise the training samples after shuffling, there is a visible difference between the normal samples vs the pneumonia samples.\n\nLet's visualise the samples after some augmentation."}}