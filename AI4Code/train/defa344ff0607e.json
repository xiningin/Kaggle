{"cell_type":{"4a948fad":"code","333628f5":"code","b8205c34":"code","8aa028e7":"code","05859d85":"code","5c6622bb":"code","f8c38966":"code","0660c555":"code","9cf3d86b":"code","729a3c55":"code","0093ec73":"code","3bc30142":"code","db9c875f":"code","12ed22d8":"code","b1214c0a":"code","44185c28":"code","2f96d2ad":"code","2d6b1299":"code","3df357d4":"code","6fd69587":"code","a721c73b":"code","73400e59":"code","ae9fda6d":"code","9afe73a4":"code","527879c1":"code","338f5bbf":"code","9a577f7c":"code","610f58de":"code","f21347e5":"markdown","85d582f0":"markdown","ae1a2828":"markdown","8c9040d4":"markdown","ce125a53":"markdown","7a4b6262":"markdown","9c37cb2a":"markdown","1de29047":"markdown","ca9f89ac":"markdown"},"source":{"4a948fad":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport cv2\n%matplotlib inline","333628f5":"import warnings\nwarnings.filterwarnings('ignore')","b8205c34":"#importing required libraries\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator , load_img ,img_to_array\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import classification_report,confusion_matrix","8aa028e7":"my_data_dir = '..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/'\ntrain_path = my_data_dir + 'train\/'\ntest_path = my_data_dir + 'test\/'\n\nimage_shape = (300,300,1)\nbatch_size = 32 #according your model and your choise","05859d85":"# view some images\nimg = plt.imread('..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/train\/def_front\/cast_def_0_1001.jpeg')\nplt.figure(figsize=(12,8))\nplt.imshow(img,cmap='gray')","5c6622bb":"img1 = plt.imread('..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/train\/def_front\/cast_def_0_1004.jpeg')\nplt.figure(figsize=(12,8))\nplt.imshow(img1,cmap='gray')","f8c38966":"image_gen = ImageDataGenerator(rescale=1\/255)# Rescale the image by normalzing it)\n","0660c555":"#we using keras inbuild function to ImageDataGenerator so we donnot need to lable all images into 0 and 1 it automatic create it and batch also during trainng \ntrain_set = image_gen.flow_from_directory(train_path,\n                                               target_size=image_shape[:2],\n                                                color_mode=\"grayscale\",\n                                               batch_size=batch_size,\n                                               class_mode='binary',shuffle=True)\n\ntest_set = image_gen.flow_from_directory(test_path,\n                                               target_size=image_shape[:2],\n                                               color_mode=\"grayscale\",\n                                               batch_size=batch_size,\n                                               class_mode='binary',shuffle=False)","9cf3d86b":"train_set.class_indices","729a3c55":"#Creating model\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=8, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=16, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=16, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(224))\nmodel.add(Activation('relu'))\n\n# Last layer\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor='val_loss',patience=2)","0093ec73":"results = model.fit_generator(train_set,epochs=20,\n                              validation_data=test_set,\n                             callbacks=[early_stop])","3bc30142":"losses = pd.DataFrame(model.history.history)\n","db9c875f":"losses[['loss','val_loss']].plot()","12ed22d8":"losses[['accuracy','val_accuracy']].plot()","b1214c0a":"#first we will find predict probability\npred_probability = model.predict_generator(test_set)","44185c28":"#here it's true label for test set\ntest_set.classes","2f96d2ad":"predictions = pred_probability > 0.5\n#if model predict greater than 0.5 it conveted to 1 means ok_front","2d6b1299":"print(classification_report(test_set.classes,predictions))","3df357d4":"plt.figure(figsize=(10,6))\nsns.heatmap(confusion_matrix(test_set.classes,predictions),annot=True)","6fd69587":"#we already have string of test path\ntest_path","a721c73b":"img = cv2.imread(test_path+'ok_front\/cast_ok_0_1020.jpeg',0)\nimg = img\/255 #rescalinng\npred_img =img.copy()","73400e59":"plt.figure(figsize=(12,8))\nplt.imshow(img,cmap='gray')","ae9fda6d":"prediction = model.predict(img.reshape(-1,300,300,1))\nif (prediction<0.5):\n    print(\"def_front\")\n    cv2.putText(pred_img, \"def_front\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\nelse:\n    print(\"ok_front\")\n    cv2.putText(pred_img, \"ok_front\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n    \nplt.imshow(pred_img,cmap='gray')\nplt.axis('off')\nplt.show()","9afe73a4":"img1 = cv2.imread(test_path+'def_front\/cast_def_0_1134.jpeg',0)\nimg1 = img1\/255\npred_img1 =img1.copy()","527879c1":"plt.figure(figsize=(12,8))\nplt.imshow(img1,cmap='gray')","338f5bbf":"model.predict_proba(img.reshape(1,300,300,1))","9a577f7c":"prediction = model.predict(img1.reshape(-1,300,300,1))\nif (prediction<0.5):\n    print(\"def_front\")\n    cv2.putText(pred_img1, \"def_front\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\nelse:\n    print(\"ok_front\")\n    cv2.putText(pred_img1, \"ok_front\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n    \nplt.imshow(pred_img1,cmap='gray')\nplt.axis('off')\nplt.show()","610f58de":"model.save('inspection_of_casting_products.h5')","f21347e5":"# view some image of dataset","85d582f0":"As you can see imagedatagenerator automatic convert all images class to it's respective folder, def_front folder to 0 and ok_front to 1.\nWhich reduce our work to convert it  using for loop.","ae1a2828":"# Importing required libraries","8c9040d4":"# Analizing model performance","ce125a53":"# Predict on some test images","7a4b6262":"# Note\n\n* This is version 4 of this notebook, Which contain full code to build classifier.\n* If you just want starting code check version 1 of this notebook","9c37cb2a":"# saving the model","1de29047":"# Convolutional model creation","ca9f89ac":"# Data preparation"}}