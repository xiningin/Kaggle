{"cell_type":{"01fd9243":"code","c0cd0953":"code","25d39319":"code","127f1223":"code","1af702e0":"code","64cd59af":"code","c5df9f86":"code","bbb0fd00":"code","fcbc5e34":"code","aa2508f1":"code","e3ccf6a1":"code","4c7f9462":"code","6fe31a56":"code","8b7976b5":"code","b4d85c30":"code","8866947d":"code","c84ee10f":"code","b85a6e85":"markdown"},"source":{"01fd9243":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c0cd0953":"import fastai\nfastai.__version__  # 2.0.15","25d39319":"# https:\/\/towardsdatascience.com\/deep-learning-image-classification-with-fast-ai-fc4dc9052106\nfrom fastai.vision.all import *\nset_seed(2)\n\nfrom fastai.metrics import error_rate, accuracy, RocAuc, CohenKappa, RocAucBinary\nimport warnings\nwarnings.filterwarnings('ignore')\npath = '..\/input\/chest-xray-pneumonia\/chest_xray'","127f1223":"# https:\/\/medium.com\/hackernoon\/histogram-equalization-in-python-from-scratch-ebb9c8aa3f23\n%matplotlib inline\nfrom IPython.display import display, Math, Latex\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# create our own histogram function\ndef get_histogram(image, bins):\n    # array with size of bins, set to zeros\n    histogram = np.zeros(bins)\n    \n    # loop through pixels and sum up counts of pixels\n    for pixel in image:\n        histogram[pixel] += 1\n    \n    # return our final result\n    return histogram\n\n# create our cumulative sum function\ndef cumsum(a):\n    a = iter(a)\n    b = [next(a)]\n    for i in a:\n        b.append(b[-1] + i)\n    return np.array(b)\n\nimg = Image.open('{}\/train\/NORMAL\/IM-0115-0001.jpeg'.format(path))\n\n# display the image\n# plt.imshow(img, cmap='gray')\n\n# convert our image into a numpy array\nimgnp = np.asarray(img)\n\n# put pixels in a 1D array by flattening out img array\nflat = imgnp.flatten()\n\n# show the histogram\n# plt.hist(flat, bins=50)\n\n# execute our histogram function\nhist = get_histogram(flat, 256)\n\n# execute the fn\ncs = cumsum(hist)\n\n# display the result\n# plt.plot(cs)\n\n# numerator & denomenator\nnj = (cs - cs.min()) * 255\nN = cs.max() - cs.min()\n\n# re-normalize the cumsum\ncs = nj \/ N\n\n# cast it back to uint8 since we can't use floating point values in images\ncs = cs.astype('uint8')\n# plt.plot(cs)\n\n# get the value from cumulative sum for every index in flat, and set that as img_new\nimg_new = cs[flat]\n\n# put array back into original shape since we flattened it\nimg_new = np.reshape(img_new, imgnp.shape)\n\n# set up side-by-side image display\nfig = plt.figure()\nfig.set_figheight(15)\nfig.set_figwidth(15)\n\nfig.add_subplot(1,2,1)\nplt.imshow(imgnp, cmap='gray')\n\n# display the new image\nfig.add_subplot(1,2,2)\nplt.imshow(img_new, cmap='gray')\n\nplt.show(block=True)","1af702e0":"import PIL\nfrom fastai.vision.core import PILImage\n# Parts taken from: \n# https:\/\/medium.com\/hackernoon\/histogram-equalization-in-python-from-scratch-ebb9c8aa3f23\n# https:\/\/medium.com\/@pierre_guillou\/2-2-fastai-the-new-radiology-tool-9f0b7db7bf91\n\n\n\nclass HistogramEqualization(Transform):\n    def __init__(self, prefix=None):\n        self.prefix = prefix or \"\"\n\n    def encodes(self, o):\n        # convert our image into a numpy array\n        imgnp = o.cpu().numpy()  # np.asarray(o[0]) # .permute(1, 2, 0))\n        \n        # put pixels in a 1D array by flattening out img array\n        flat = imgnp.flatten()\n        # execute our histogram function\n        hist = get_histogram(flat, 256)\n\n        # execute the fn\n        cs = cumsum(hist)\n        # numerator & denomenator\n        nj = (cs - cs.min()) * 255\n        N = cs.max() - cs.min()\n\n        # re-normalize the cumsum\n        cs = nj \/ N\n\n        # cast it back to uint8 since we can't use floating point values in images\n        cs = cs.astype('uint8')\n\n        # get the value from cumulative sum for every index in flat, and set that as img_new\n        img_new = cs[flat]\n\n        # put array back into original shape since we flattened it\n        img_new = np.reshape(img_new, o.shape)\n\n        ret = TensorImage(img_new) if (type(o) == TensorImage) else o\n        return ret\n        \n    def decodes(self, o):\n        return o\n    \nclass HistogramEqualization_item(Transform):\n    def __init__(self, prefix=None):\n        self.prefix = prefix or \"\"\n\n    def encodes(self, o):\n#         print(type(o))\n        if type(o) == PILImage:\n            ret = PIL.ImageOps.equalize(o)  \n        else:\n            ret = o\n        return ret\n    \n    def decodes(self, o):\n        return o","64cd59af":"data = ImageDataLoaders.from_folder(path, train='train', valid='test',\n                                    item_tfms=[Resize(size=384)],#, HistogramEqualization_item()],\n                                    batch_tfms=[*aug_transforms(min_scale=0.98, do_flip=False)], \n                                    max_zoom=1.1, max_lighting=0.2, bs=16, num_workers=8) ","c5df9f86":"# Show what the data looks like after being transformed\ndata.show_batch()","bbb0fd00":"# See the classes and count of classes in your dataset\nprint(data.c)\n# See the number of images in each data set\nprint(len(data.train_ds), len(data.valid_ds))","fcbc5e34":"learn = cnn_learner(data, densenet169, metrics=RocAucBinary()).to_fp16()\nfrom pathlib import Path\nlearn.path = Path('\/kaggle\/working\/')","aa2508f1":"# Augmentation of the weight decay to wd=0.1 and use of the callback function SaveModelCallback() in order to save the model after an epoch if its kappa score is the biggest.\nlearn.fit_one_cycle(1, wd=0.1)","e3ccf6a1":"# Save the model\nlearn.save('densenet169-auc-stage-1')\n# Load the Model\nlearn.load('densenet169-auc-stage-1')","4c7f9462":"# Unfreeze all layers of the CNN\nlearn.unfreeze()\n# Find the optimal learning rate and plot a visual\nsuggested = learn.lr_find()","6fe31a56":"# Fit the model over 4 epochs\nlearn.unfreeze()\nlearn.fit_one_cycle(4, lr_min=suggested.lr_min, lr_steep=suggested.lr_steep, wd=0.1)","8b7976b5":"# Save the model\nlearn.save('densenet169-auc-stage-2')\n# Load the Model\nlearn.load('densenet169-auc-stage-2')","b4d85c30":"learn.fit_one_cycle(4, lr_min=suggested.lr_min, lr_steep=suggested.lr_steep, wd=0.1)","8866947d":"# Rebuild interpreter and replot confusion matrix\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(12,12), dpi=60)","c84ee10f":"interp.plot_top_losses(8)","b85a6e85":"## Histogram equalization example"}}