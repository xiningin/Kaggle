{"cell_type":{"2dd20a58":"code","a1031c39":"code","d077147c":"code","ab85e8b3":"code","c842bfef":"code","d2f515e3":"code","66d7d662":"code","1c066f56":"code","4b98100d":"code","3ea0e287":"code","a5f16393":"code","a3a659f6":"code","5ffbaa6a":"code","2ff0fac1":"code","77661ec4":"code","5c8347ec":"code","3cf35977":"code","bca7b16e":"code","41d7c8e6":"code","8fac5054":"code","02dfbcc1":"code","4c5fd342":"code","d5d46954":"code","8ca08258":"code","9b3e7747":"markdown","19633f97":"markdown","57be2bb3":"markdown","255fe957":"markdown","61d85e5b":"markdown","d3d090c4":"markdown","42d21b74":"markdown","73fe768a":"markdown","cf2b07f9":"markdown","3ab0d76b":"markdown","23185f10":"markdown","7d788793":"markdown","84064380":"markdown","4e4b16a4":"markdown","8952a3c5":"markdown","d7910101":"markdown","c1ed235c":"markdown","87c52bd4":"markdown","e58097ab":"markdown","dc23bdf6":"markdown","a531c7a0":"markdown","c55959cb":"markdown","7a7639c8":"markdown","f7c9c026":"markdown","4fc976d4":"markdown"},"source":{"2dd20a58":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator","a1031c39":"tf.__version__","d077147c":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntraining_set = train_datagen.flow_from_directory('..\/input\/dogs-cats-images\/dataset\/training_set',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')","ab85e8b3":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_set = test_datagen.flow_from_directory('..\/input\/dogs-cats-images\/dataset\/test_set',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","c842bfef":"cnn = tf.keras.models.Sequential()","d2f515e3":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))","66d7d662":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","1c066f56":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","4b98100d":"cnn.add(tf.keras.layers.Flatten())","3ea0e287":"cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))","a5f16393":"cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","a3a659f6":"cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","5ffbaa6a":"cnn.fit(x = training_set, validation_data = test_set, epochs = 25)","2ff0fac1":"import numpy as np\nfrom keras.preprocessing import image","77661ec4":"test_image = image.load_img('..\/input\/single-predictions\/cat_or_dog1.jpg')","5c8347ec":"test_image","3cf35977":"# 1. Reassigning test_image to the same target_size as the other trained images.\n# 2. Converting the image to numpy array \n# 3. Adding the batch dimension to the data as while training we had that dimension too.\n\ntest_image = image.load_img('..\/input\/single-predictions\/cat_or_dog1.jpg', target_size = (64, 64))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)","bca7b16e":"result = cnn.predict(test_image)","41d7c8e6":"training_set.class_indices # This will show us the indexes of cat and dog","8fac5054":"if result[0][0] == 1: # First '[0]' represents the batch number. Since there is only 1 batch therefore 0.\n                      # Second '[0]' represents the image number. Since there is only 1 image therefore 0.\n  prediction = 'dog'\nelse:\n  prediction = 'cat'\n\nprint(prediction)","02dfbcc1":"test_image2 = image.load_img('..\/input\/single-predictions\/cat_or_dog2.jpg')\ntest_image2","4c5fd342":"test_image2 = image.load_img('..\/input\/single-predictions\/cat_or_dog2.jpg', target_size = (64, 64))\ntest_image2 = image.img_to_array(test_image2)\ntest_image2 = np.expand_dims(test_image2, axis = 0)\n\nresult = cnn.predict(test_image2)\n\nif result[0][0] == 1: \n  prediction = 'dog'\nelse:\n  prediction = 'cat'\n\nprint(prediction)","d5d46954":"test_image3 = image.load_img('..\/input\/single-predictions\/cat_or_dog3.jpg')\ntest_image3","8ca08258":"test_image3 = image.load_img('..\/input\/single-predictions\/cat_or_dog3.jpg', target_size = (64, 64))\ntest_image3 = image.img_to_array(test_image3)\ntest_image3 = np.expand_dims(test_image3, axis = 0)\n\nresult = cnn.predict(test_image3)\n\nif result[0][0] == 1: \n  prediction = 'dog'\nelse:\n  prediction = 'cat'\n\nprint(prediction)","9b3e7747":"# Building the CNN","19633f97":"2. Checking if our model predicts kitty cat correctly or not","57be2bb3":"This particluar image had 2 dogs and both of them were kind of out of focus. Our model did well ! ","255fe957":"This basic code is for testing out the Kaggle GPU processing power.","61d85e5b":"1. Checking out if model correctly predicts this good boi as dog","d3d090c4":"# Making some predictions","42d21b74":"# Data Preprocessing","73fe768a":"Step 1 - Convolution","cf2b07f9":"# Training the CNN","3ab0d76b":"Adding a second convolutional layer","23185f10":"# A basic CNN Cats and Dogs classifier.","7d788793":"Preprocessing the Test set","84064380":"# Importing some libraries","4e4b16a4":"3. Example -3 ","8952a3c5":"Training the CNN on the Training set and evaluating it on the Test set","d7910101":"Initialising the CNN","c1ed235c":"Step 3 - Flattening","87c52bd4":"Correct ! It's a dog ! ","e58097ab":"Step 4 - Full Connection","dc23bdf6":"Just want to point out how cute these pups are !","a531c7a0":"Preprocessing the Training set","c55959cb":"Step 2 - Pooling","7a7639c8":"Compiling the CNN","f7c9c026":"Step 5 - Output Layer","4fc976d4":"It correctly predicts this as cat too !"}}