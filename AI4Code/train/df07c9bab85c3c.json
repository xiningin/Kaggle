{"cell_type":{"55f3a26b":"code","a22865e0":"code","da85b3fb":"code","697d2d76":"code","107ff747":"code","52a6d960":"code","78e2e28f":"code","207e44aa":"code","7335752a":"code","d75d741b":"code","fbc53bf8":"code","45d84b8e":"code","617f57ac":"code","f2ecae61":"code","0034859a":"code","d223e4f1":"code","5d82822d":"code","0d793723":"code","7732aec3":"code","947dc5df":"code","2d7c00e6":"code","64683ab3":"code","0daad007":"code","2fabb4ba":"code","b395d0e9":"code","96b92488":"markdown","d26b5878":"markdown","0f4832cb":"markdown","81e40764":"markdown","e33c582e":"markdown","971bdb2a":"markdown","a7b2eec4":"markdown","b7c884f8":"markdown","db4c1699":"markdown","cac2fd45":"markdown","47428261":"markdown","ebed3778":"markdown","ba96ce9e":"markdown","781ad7fd":"markdown","78add510":"markdown","d1a5012d":"markdown","79680430":"markdown","a1e26cd9":"markdown","fe6a4e5a":"markdown"},"source":{"55f3a26b":"from fastai.vision.all import *\n\nimport hashlib\nimport psutil\nfrom joblib import Parallel, delayed\nfrom os.path import isfile\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\nimport cv2","a22865e0":"!ls ..\/input\/semi-conductor-image-classification-second-stage\/","da85b3fb":"path = Path('..\/input\/semi-conductor-image-classification-second-stage\/')","697d2d76":"df = pd.read_csv(path\/'defect_area.csv')\ndf.head()","107ff747":"neg_files = Path(path\/'train\/train_contest\/defect').ls()\npos_files = Path(path\/'train\/train_contest\/good_all').ls()\ntest_files = Path(path\/'test\/test_contest\/test').ls()\nfilenames,test_filenames, labels = [], [], []\nbad_files = []\nfor f in neg_files:\n    filenames.append(f.stem)\n    bad_files.append(f.stem)\n    labels.append(1)\nfor f in pos_files:\n    filenames.append(f.stem)\n    labels.append(0)\nfor f in test_files:\n    test_filenames.append(f.stem)","52a6d960":"df_bad = pd.DataFrame(bad_files,columns=['id'])\ndf_bad.head()","78e2e28f":"len(df_bad),len(df),len(df_bad)-len(df)","207e44aa":"ts = pd.concat([df,df_bad])['id'].drop_duplicates(keep=False)\nlen(ts.values)","7335752a":"def expand_path(p):\n    if isfile('..\/input\/semi-conductor-image-classification-second-stage\/train\/train_contest\/defect\/' + p + '.bmp'): return '..\/input\/semi-conductor-image-classification-second-stage\/train\/train_contest\/defect\/' + p + '.bmp'\n    if isfile('..\/input\/semi-conductor-image-classification-second-stage\/train\/train_contest\/good_all\/' + p + '.bmp'): return '..\/input\/semi-conductor-image-classification-second-stage\/train\/train_contest\/good_all\/' + p + '.bmp'\n    if isfile('..\/input\/semi-conductor-image-classification-second-stage\/test\/test_contest\/test\/' + p + '.bmp'): return '..\/input\/semi-conductor-image-classification-second-stage\/test\/test_contest\/test\/' + p + '.bmp'\n    return p\n\ndef getImageMetaData(p):\n    strFile = expand_path(p)\n    file = None;\n    bRet = False;\n    strMd5 = \"\";\n    \n    try:\n        file = open(strFile, \"rb\");\n        md5 = hashlib.md5();\n        strRead = \"\";\n        \n        while True:\n            strRead = file.read(8096);\n            if not strRead:\n                break;\n            md5.update(strRead);\n        #read file finish\n        bRet = True;\n        strMd5 = md5.hexdigest();\n    except:\n        bRet = False;\n    finally:\n        if file:\n            file.close()\n\n    return p,strMd5","d75d741b":"random.seed(42)\n_, axes = plt.subplots(3,2,figsize=(16,20))\nfor i in range(3):\n    f = random.choice(ts.values)\n    p = expand_path(f)\n    img = Image.open(p)\n    axes[i][0].imshow(img,cmap='gray')\n    axes[i][0].set_title(f)\n    \n    f = random.choice(ts.values)\n    p = expand_path(f)\n    img = Image.open(p)\n    axes[i][1].imshow(img,cmap='gray')\n    axes[i][1].set_title(f)","fbc53bf8":"len(filenames),len(labels)","45d84b8e":"df_new = pd.DataFrame(list(zip(filenames,labels)),columns=['id','label'])","617f57ac":"df_new['label'].value_counts().plot(kind='bar')","f2ecae61":"df_new['label'].value_counts()","0034859a":"rows = 3\n\n_, axes = plt.subplots(rows,rows,figsize=(16,10))\n\nfor i in range(rows):\n    for j in range(rows):\n        ts = df_new.sample()\n        idx = ts['id'].values[0]\n        label = ts['label'].values[0]\n        f = expand_path(idx)\n        img = Image.open(f)\n        axes[i][j].imshow(img,cmap='gray')\n        axes[i][j].set_title((f'{idx}\\nLabel: defect') if label else (f'{idx}\\nLabel: good') )\n        axes[i][j].set_axis_off()","d223e4f1":"df_test = pd.DataFrame(test_filenames,columns=['id'])\ndf_test['label'] = np.nan\ndf_new = df_new.append(df_test)","5d82822d":"img_meta_l = Parallel(n_jobs=psutil.cpu_count(), verbose=1)(\n    (delayed(getImageMetaData)(fp) for fp in df_new['id']))","0d793723":"img_meta_df = pd.DataFrame(np.array(img_meta_l))\nimg_meta_df.columns = ['id', 'strMd5']\ndf_new = df_new.merge(img_meta_df,on='id')\ndf_new['strMd5_count'] = df_new.groupby('strMd5')['id'].transform('count')\ndf_new['strMd5_train_count'] = df_new['strMd5'].map(df_new.groupby('strMd5')['label'].apply(lambda x:x.notnull().sum()))\ndf_new['strMd5_nunique'] = df_new.groupby('strMd5')['label'].transform('nunique').astype('int')\ndf_new[df_new.strMd5_count>1].strMd5_count.value_counts()","7732aec3":"strMd51 = df_new[(df_new.strMd5_count>1)&(df_new.strMd5_nunique==1)].strMd5.unique()\n#strMd5 = strMd51[0]\nfor strMd5 in strMd51[:5]:\n    size = len(df_new[df_new['strMd5'] == strMd5]['id'])\n    fig = plt.figure(figsize = (20, 5))\n    for idx, img_name in enumerate(df_new[df_new['strMd5'] == strMd5]['id'][:size]):\n        y = fig.add_subplot(1, size, idx+1)\n        img = cv2.imread(expand_path(img_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        class_id = df_new[df_new['id']==img_name]['label'].values\n        y.set_title(img_name+f' Label: {class_id}')\n        y.imshow(img)\n    plt.show()","947dc5df":"df_new[(df_new['strMd5_count']>1)&(df_new['label'].isnull())]","2d7c00e6":"strMd51 = df_new[(df_new['strMd5_count']>1)&(df_new['label'].isnull())].strMd5.unique()\n\nfor strMd5 in strMd51:\n    size = len(df_new[df_new['strMd5'] == strMd5]['id'])\n    fig = plt.figure(figsize = (20, 5))\n    for idx, img_name in enumerate(df_new[df_new['strMd5'] == strMd5]['id'][:size]):\n        y = fig.add_subplot(1, size, idx+1)\n        img = cv2.imread(expand_path(img_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        class_id = df_new[df_new['id']==img_name]['label'].values\n        y.set_title(img_name+f'\\n Label: {class_id}')\n        y.imshow(img)\n    plt.show()","64683ab3":"df_new[df_new['id']=='WEP934118D3A_41-APG_ITIS_H51_2_84_1']","0daad007":"df_final = pd.read_csv(path\/'submission_sample.csv')\ndf_final.head()","2fabb4ba":"df_final.shape, df_test.shape","b395d0e9":"df_final.to_csv('submission.csv',index=False)","96b92488":"seems like we can just turn this one in, let's try","d26b5878":"### Why we have label 1.1.nan.nan, are we having same file appear in both train and test?","0f4832cb":"# Class imblanace","81e40764":"# A simple EDA on the dataset\n\n\n### A tiny introduction\n\nHi Everyone from Math 6380p class, my name is Hao and currently a first year PhD student. My focus of research is in CV, NLP and time series analysis.\n\nAs many of you might know, I am actively playing kaggle and have learned a lot from the platform. Today I would like to share with you a simple EDA that might help you to know more about this homework dataset.\n\nHere is a break down:\n\n1. Dataset folders\n2. Data distribution\n3. Some gotchas\n\n     a. Are they semi-conductor chips?\n     \n     b. Duplicates in train\n     \n     c. Free lunch: Label data appears in train and test\n    \n\n\n\n\n","e33c582e":"As we scan over the dataset, we can easily identify some defect chips","971bdb2a":"# Are they semi-conductor chips?\n\n### From the 343 unlabeled data\n\nAs you can see, chips are usualy with few numbers on it, the one appears with a hole in the middle doesn't look like a chip\n\nAlso, defect chips normally have some scatches, some of this 343 unlabeled images appear to be a good one","a7b2eec4":"# How to check duplicates?\n\nI often run to the case that need to run a full scale large dataset to check if there are duplicates.\n\nThe most easy way for me is the following:\n\n1. Hash the image pixel values\n2. Check if any hash values are identical\n\nThe code below is trival, you can use any hash method you like. But this is a really fast way to scan a large dataset, as you can see, it only takes us 30s to run more than 40k images\n\n\n\n**GOTCHAS:**\n\n***If the image pixel shifted, hash won't work***\n","b7c884f8":"seems like someone accidentaly split train file into your test file, you might consider them as \"free answers\" :)\n\nSo a good way to do is to make sure you don't split this files into your validation","db4c1699":"### Folder breaks down\n\n1. defect_area.csv contains pascal voc format bbox annotation, which you don't need it if you just play with classification, however, there are more than 300 images doesn't have annotation. As I eyeballing the data, they seems to me are either **NOT chips** or **GOOD chips**\n2. submission_sample.csv is the file that you need to turn in to have a leader board score\n3. test folder contains all test images you need to run your prediction, folder convention in ImageNet style\n4. train folder contains all train images with sub-folder **good_all** and **defect**, folder convetion in ImageNet style\n5. The images are in .bmp format and signle channel BW images, image size (267,275)","cac2fd45":"We have 34459 train images in the dataset, good vs defect are roughly 1:4, which means **if test set are in the similar distribution**, simply predict good will result 80% correct in accuracy","47428261":"### TL,DR;\n\n1. The class is heavily imbalanced with a ratio of roughly 1:4\n2. There are noisy labels, some of them doesn't look like semi-conductor at all (roughly 300 images out of 30k train images)\n3. There are duplicates in the train\/test sets, they appear to have file name with **APG_ITIS** tags","ebed3778":"# Let's take a look of the labeled and unlabled examples","ba96ce9e":"# unlabeled data","781ad7fd":"# Duplicates appears in train and test\n\n### It would be nice if we can have some understanding of our test set","78add510":"### Full dataset EDA","d1a5012d":"# Duplicates\n\n### Let's check if the dataset contain duplicates\n\nIf you split a duplicates into both train and validation, there is a chance that your local cv has a high score but low test result. \n\nLet's make sure we don't have this problem, also, do we have examples appear in both tran and test?","79680430":"# Duplicates in the train set with different filename\n\n### The filename contains APG_ITIS seems to be the dupilcates","a1e26cd9":"# Submit\n\nIf you want to submit to kaggle, you need to genereate a submission file","fe6a4e5a":"In the **defect** folder, we have 7039 images, however, only 6696 of them has bbox label\n\n1. Either they are mislabeled or they don't know how to label them (no chips or good chips)"}}