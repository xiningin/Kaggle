{"cell_type":{"b0efde99":"code","97f9bf36":"code","baa1397e":"code","82680ab0":"code","c9b86aef":"code","c97ad4e1":"code","0f848afd":"code","6754dd10":"code","1aa4629a":"code","574ee1df":"code","5464202f":"code","910c554a":"markdown","6b2434cf":"markdown","f9ba77b7":"markdown","4465f277":"markdown","e252f69c":"markdown","04441c34":"markdown","e3f508d0":"markdown","53346333":"markdown","53e8eeed":"markdown","2e8eb98f":"markdown","492b5c69":"markdown"},"source":{"b0efde99":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.layers import Dense,Flatten,Reshape\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","97f9bf36":"img_rows=32\nimg_cols=32\nchannels=3\n\nimg_shape = (img_rows,img_cols,channels)\n\nzdim=3072","baa1397e":"def build_gen(img_shape,zdim):\n    model = Sequential()\n    model.add(Dense(128,input_dim=zdim))\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Dense(32*32*3,activation='tanh'))\n    model.add(Reshape(img_shape))\n    return model","82680ab0":"def build_dis(img_shape):\n    model=Sequential()\n    model.add(Flatten(input_shape=img_shape))\n    model.add(Dense(128))\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Dense(1,activation='sigmoid'))\n    return model","c9b86aef":"def build_gan(gen,dis):\n    model = Sequential()\n    model.add(gen)\n    model.add(dis)\n    return model","c97ad4e1":"dis_v = build_dis(img_shape)\ndis_v.compile(loss='binary_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","0f848afd":"gen_v = build_gen(img_shape,zdim)\ndis_v.trainable=False\ngan_v = build_gan(gen_v,dis_v)\ngan_v.compile(loss='binary_crossentropy',\n              optimizer=Adam()\n             )","6754dd10":"losses=[]\naccuracies=[]\niteration_checks=[]","1aa4629a":"def show_images(gen):\n    z = np.random.normal(0, 1, (16, zdim))\n    gen_imgs = gen.predict(z)\n    gen_imgs = 0.5*gen_imgs + 0.5\n\n    fig,axs = plt.subplots(4,4,figsize=(4,4),sharey=True,sharex=True)\n\n    cnt=0\n    for i in range(4):\n        for j in range(4):\n            axs[i, j].imshow(gen_imgs[cnt,:,:])\n            axs[i, j].axis('off')\n            cnt+=1\n\n    fig.show()","574ee1df":"def train(iterations,batch_size,interval):\n\n    (Xtrain, _),(_, _) = cifar10.load_data()\n    Xtrain = Xtrain\/127.5 - 1.0\n    # Xtrain = np.expand_dims(Xtrain,axis=3)\n\n    real = np.ones((batch_size,1))\n    fake = np.zeros((batch_size, 1))\n\n    for iteration in range(iterations):\n\n        ids = np.random.randint(0,Xtrain.shape[0],batch_size)\n        imgs = Xtrain[ids]\n\n        z=np.random.normal(0,1,(batch_size,zdim))\n        gen_imgs = gen_v.predict(z)\n\n        dloss_real = dis_v.train_on_batch(imgs,real)\n        dloss_fake = dis_v.train_on_batch(gen_imgs, fake)\n\n        dloss,accuracy = 0.5 * np.add(dloss_real,dloss_fake)\n\n        z = np.random.normal(0, 1, (batch_size, zdim))\n        gloss = gan_v.train_on_batch(z,real)\n\n        if (iteration+1) % interval == 0:\n            losses.append((dloss,gloss))\n            accuracies.append(100.0*accuracy)\n            iteration_checks.append(iteration+1)\n\n            print(\"%d [D loss: %f , acc: %.2f] [G loss: %f]\" %\n                  (iteration+1,dloss,100.0*accuracy,gloss))\n            show_images(gen_v)","5464202f":"train(20000,128,1000)","910c554a":"```import All Need```","6b2434cf":"```initial Values (Image shapes, Noise Vertor Dimention)```","f9ba77b7":"```Start Traning on GAN```","4465f277":"```Function For Traning in Mnist Data To Generate New Fake Data```","e252f69c":"```Build Generator Nework Function```","04441c34":"```Build GAN Network With Concatinate Generator Network & Discriminator Network```","e3f508d0":"```Build Discriminator Network Function```","53346333":"```Create Generator Network and Compile it```","53e8eeed":"```Create Discriminator Network and Compile it```","2e8eb98f":"```Function For Showing Generated Images During Training```","492b5c69":"```Define 3 Lists For Saving Accuracies, Losses and Number of Corresponding Iteration```"}}