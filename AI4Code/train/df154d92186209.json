{"cell_type":{"7bc577ea":"code","52a3c2da":"code","39bf5d28":"code","6eccbfe5":"code","b9cf9e59":"code","d4636412":"code","aa666799":"code","0353f7d9":"code","e4df94d4":"code","5bac8ec9":"code","8a8e77b1":"code","d1f01a07":"code","bdc08d27":"code","9e9566e6":"code","09341e92":"code","261d93f4":"code","1a6644f5":"code","4b4a0325":"code","1edf5555":"code","9ee64199":"code","c8487192":"code","2f9b3411":"code","055a676a":"markdown","8ff1e5e3":"markdown","a5460e0c":"markdown","ee8db854":"markdown","6d7b1eeb":"markdown","f5533b26":"markdown","c8b3bb33":"markdown","bdfdbe4f":"markdown","741fc866":"markdown","eef9da63":"markdown","ac73ad09":"markdown","da5fc16d":"markdown"},"source":{"7bc577ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","52a3c2da":"df = pd.read_csv('..\/input\/amazon-music-reviews\/Musical_instruments_reviews.csv')\ndf_copy = df.copy()\ndf.head(3)","39bf5d28":"df.reviewText   = df.reviewText + df.summary\ndf.reviewTime   = df.reviewTime.apply(lambda string: [int(i) for i in string.replace(',','').split()])\ndf['month']     = df.reviewTime.apply(lambda x: x[0])\ndf['date']      = df.reviewTime.apply(lambda x: x[1])\ndf['year']      = df.reviewTime.apply(lambda x: x[2])\ndf.drop(columns = ['asin','helpful','summary','unixReviewTime','reviewTime'],axis=0,inplace=True)\n\ndf.head(3)","6eccbfe5":"import string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import wordnet,WordNetLemmatizer\n\ndef remove_punctuation(the_string):\n    for c in string.punctuation:\n        the_string = str(the_string).replace(c,'')\n    return the_string\n\ndef remove_digits(the_string):\n    for c in range(10):        \n        the_string = str(the_string).replace(str(c),'')\n    return the_string\n\ndf.reviewText = df.reviewText.apply(remove_punctuation).apply(remove_digits)","b9cf9e59":"def remove_stopwords(sentence):\n    stopword_list = stopwords.words('english')\n    stopword_list.append(['www','http'])\n    new_sentence = ''\n    for word in sentence.split():\n        if word not in stopword_list:\n            new_sentence += ' '+word.lower()\n    return new_sentence[1:]\n\ndf.reviewText = df.reviewText.apply(remove_stopwords)","d4636412":"from nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\n\nwnl = WordNetLemmatizer()\n\ndef do_lemmatize(sentence):\n      \n    _list = nltk.pos_tag(str(sentence).split())   \n    \n    the_sentence = ''\n    for _tuple in _list:        \n        wrd    = _tuple[0]                      \n        if _tuple[1][0] in ['N','V','J','R']:\n            if _tuple[1][0]=='N':\n                pos_tg = 'n'\n            elif _tuple[1][0]=='V':\n                pos_tg = 'v'\n            elif _tuple[1][0]=='J':\n                pos_tg = 'a'\n            else:\n                pos_tg = 'r'\n        else:\n            pos_tg = 'n'\n            \n        the_sentence+=' ' + wnl.lemmatize(wrd,pos_tg)\n        \n    return the_sentence[1:]\n\ndf.reviewText = df.reviewText.apply(do_lemmatize)\n\ndel wnl\n\ndf.head(3)","aa666799":"from nltk.stem import SnowballStemmer\n\nsbs = SnowballStemmer('english')\n\ndef stem_tokens(sentence):\n    the_sentence = ''\n    for word in str(sentence).split():\n        the_sentence+=' '+sbs.stem(word)\n    return the_sentence\n\ndf.reviewText = df.reviewText.apply(stem_tokens)\n\ndel sbs\n\ndf.head(3)","0353f7d9":"df['n_words']      = df.reviewText.apply(lambda x:len(x))\ndf['unique_words'] = df.reviewText.apply(lambda string:len(set(str(string).split())))\n\ndf.head(3)","e4df94d4":"from textblob import TextBlob\n\ndef get_sentiment(string):\n    return list(TextBlob(string).sentiment)\n\ndf['tb_sentiment'] = df.reviewText.apply(get_sentiment)\ndf['polarity']     = df.tb_sentiment.apply(lambda x:x[0])\ndf['subjectivity'] = df.tb_sentiment.apply(lambda x:x[1])\ndf.drop(columns=['tb_sentiment'],axis=0,inplace=True)\ndf.head()","5bac8ec9":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nsentence_list = []\nfor index,row in df.iterrows():    \n    sentence_list.append(row.reviewText)    \n        \nV = TfidfVectorizer()\n_tuple   = V.fit_transform(sentence_list)\ncol_name = V.get_feature_names()  \n\ndel sentence_list","8a8e77b1":"temp = pd.DataFrame(_tuple)\ntemp.columns=['dat']\n\ndef get_tfidf_disp(temp):\n    array = list([])\n    for i in range(temp.shape[0]):\n        sentence_list = str(temp.dat[i]).split('\\n')\n        for sentence in sentence_list:\n            word_list = sentence.split('\\t')        \n            \n            word_list[0] = word_list[0].replace(',','').replace('(','').replace(')','').replace(':','')            \n            \n            _temp = word_list[0].split()\n            \n            if len(_temp)>0:\n                word_id = word_list[0].split()[1]                                \n                value = word_list[1]\n                array.append([i,word_id,float(value)])\n                                        \n    array = pd.DataFrame(array)\n    array.columns = ['doc','word_id','value']\n    array.sort_values(by='value',ascending=False,inplace=True)\n    return array\n\ntemp_array = get_tfidf_disp(temp)\ndel temp\n\ntemp_array.head(3)              ","d1f01a07":"#temp_array = temp_array[:200]\nselect_col = list(set([col_name[int(word_id)] for word_id in temp_array.word_id]))\n\ndel temp_array\n\nprint(*select_col)","bdc08d27":"array   = _tuple.toarray()\ntemp_df = pd.DataFrame(array)\ntemp_df.columns = col_name\n\ndel array\n\ntemp_df = temp_df[select_col]\ntemp_df.head(3)","9e9566e6":"for col in temp_df.columns:\n    df[col] = temp_df[col]\ndf.drop(columns=['reviewText'],axis=0,inplace=True)    \n\ndel temp_df\n\ndf.head()","09341e92":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n\ndef give_prediction(temp_df):\n   \n    y = [1 if i==5 else 0 for i in temp_df.overall]        \n    X = temp_df.drop(columns='overall',axis=0)\n    \n    # Train-Test Split\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=7)\n    print('sum of y-test = ',sum(y_test),len(y_test))\n\n    # Drop Unnecessary Columns before Training\n    X_train_id = X_train[['reviewerID','reviewerName']]\n    X_train.drop(columns=['reviewerID','reviewerName'],axis=0,inplace=True)\n\n    X_test_id = X_test[['reviewerID','reviewerName']]\n    X_test.drop(columns=['reviewerID','reviewerName'],axis=0,inplace=True)\n    \n    # Model Development\n    lr = LogisticRegression(max_iter=100, solver='liblinear',random_state=7)\n    lr.fit(X_train,y_train)\n    \n    # Get Predictions  \n    y_pred = lr.predict(X_test) \n    y_pred_proba = lr.predict_proba(X_test)\n    X_test_id['y_test']       = y_test\n    X_test_id['y_pred']       = y_pred\n    X_test_id['y_pred_proba'] = [r[0] for r in y_pred_proba]\n  \n    return X_test_id,lr.coef_\n\n","261d93f4":"df_345 = df.copy()\nresult_df,coef = give_prediction(df_345)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_345,result_df,coef","1a6644f5":"df_345 = df[df.overall>2]\nresult_df,coef_ = give_prediction(df_345)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_345,result_df,coef_","4b4a0325":"df_45 = df[df.overall>3]\nresult_df,coef_ = give_prediction(df_45)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_45,result_df,coef_","1edf5555":"df_word = df.copy()\ndf_word['nu_words'] = df_word.n_words - df_word.unique_words\ndf_word.drop(columns=['unique_words','month','date','year'],axis=0,inplace=True)\n\nresult_df,coef_ = give_prediction(df_word)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_word,result_df,coef_","9ee64199":"df_us = df[df.overall==5][:5000]\ndf_us = df_us.append(df[df.overall<5])\n\nresult_df,coef_ = give_prediction(df_us)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_us,result_df,coef_","c8487192":"df_os = df.copy()\nfor i in range(1):\n    df_os = df.append(df[df.overall<2])\n\nresult_df,coef_ = give_prediction(df_os)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_os,result_df,coef_","2f9b3411":"#df_cb = df.copy()\n\n# Under Sampling\ndf_cb = df[df.overall==5][:]\ndf_cb = df_cb.append(df[df.overall<5])\n\n# Feature Engineering\ndf_cb['nu_words'] = df_cb.n_words - df_cb.unique_words\ndf_cb.drop(columns=['unique_words','month','date','year'],axis=0,inplace=True)\n\n# Over Sampling\nfor i in range(0):\n    df_cb = df_cb.append(df_cb[df_cb.overall<2])\n    \n# Predictive Analysis    \nresult_df,coef_ = give_prediction(df_cb)\n\nprint('Accuracy Score = '        ,accuracy_score(result_df.y_test,result_df.y_pred))\nprint('\\nConfusion Matrix\\n'     ,confusion_matrix(result_df.y_test,result_df.y_pred))\nprint('\\nClassification Report\\n',classification_report(result_df.y_test,result_df.y_pred))\n\nresult_df.y_pred.hist(bins=2)\n\ndel df_cb,result_df,coef_","055a676a":"# Get Data","8ff1e5e3":"#### Orginal Dataset","a5460e0c":"# Data Cleaning Functions","ee8db854":"#### Drop Some Columns based on Knowledge","6d7b1eeb":"# Check Appropiate Dataset ","f5533b26":"# Feature Adding Functions","c8b3bb33":"UnderSampling","bdfdbe4f":"Combination of Above Methods (OverSampling + Column Elimination)","741fc866":"OverSampling","eef9da63":"# Model Training Functions ","ac73ad09":"#### Eliminating Target with Low Levels","da5fc16d":"### Top N Words"}}