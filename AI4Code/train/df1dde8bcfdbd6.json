{"cell_type":{"3d634872":"code","fcb7190f":"code","9a746a1d":"code","aaad66ba":"code","bd958d7c":"code","b7325165":"code","3da2fc97":"code","1cf0a06d":"code","fa630569":"code","35ea1149":"code","22e3c8fd":"code","d00a714b":"code","344dd4b2":"code","c70b1887":"code","f2811b06":"code","c1e9a1b5":"code","ec5e0088":"code","99253230":"code","9ef510a7":"code","d009662d":"code","4305174e":"code","b1fb9cf3":"code","6e33b5e7":"code","40e67245":"code","198c0bcc":"code","1a1e6b64":"code","afe7ba32":"code","4d3b41c6":"code","675c43ab":"code","f41f36f8":"code","92ebf0b7":"code","217ce33a":"markdown","d25a2311":"markdown","321c8534":"markdown","0e59ab45":"markdown","82757039":"markdown","b22c0a47":"markdown","770807bb":"markdown","768b58b4":"markdown"},"source":{"3d634872":"import numpy as np # linear algebra\nimport random\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport cv2\nimport shutil\nfrom glob import glob\n# Helper libraries\nimport matplotlib.pyplot as plt\nimport math\n%matplotlib inline\nprint(tf.__version__)","fcb7190f":"data_root='\/kaggle\/input\/covidct\/'\npath_positive_cases = os.path.join('\/kaggle\/input\/covidct\/CT_COVID\/')\npath_negative_cases = os.path.join('\/kaggle\/input\/covidct\/CT_NonCOVID\/')","9a746a1d":"# jpg and png files\npositive_images_ls = glob(os.path.join(path_positive_cases,\"*.png\"))\n\nnegative_images_ls = glob(os.path.join(path_negative_cases,\"*.png\"))\nnegative_images_ls.extend(glob(os.path.join(path_negative_cases,\"*.jpg\")))","aaad66ba":"covid = {'class': 'CT_COVID',\n         'path': path_positive_cases,\n         'images': positive_images_ls}\n\nnon_covid = {'class': 'CT_NonCOVID',\n             'path': path_negative_cases,\n             'images': negative_images_ls}","bd958d7c":"total_positive_covid = len(positive_images_ls)\ntotal_negative_covid = len(negative_images_ls)\nprint(\"Total Positive Cases Covid19 images: {}\".format(total_positive_covid))\nprint(\"Total Negative Cases Covid19 images: {}\".format(total_negative_covid))","b7325165":"image_positive = cv2.imread(os.path.join(positive_images_ls[51]))\nimage_negative = cv2.imread(os.path.join(negative_images_ls[22]))\n\nf = plt.figure(figsize=(8, 8))\nf.add_subplot(1, 2, 1)\nplt.imshow(image_negative)\nf.add_subplot(1,2, 2)\nplt.imshow(image_positive)","3da2fc97":"print(\"Image POS Shape {}\".format(image_positive.shape))\nprint(\"Image NEG Shape {}\".format(image_negative.shape))","1cf0a06d":"# print(image_positive)\n","fa630569":"# Create Train-Test Directory\nsubdirs  = ['train\/', 'test\/']\nfor subdir in subdirs:\n    labeldirs = ['CT_COVID', 'CT_NonCOVID']\n    for labldir in labeldirs:\n        newdir = subdir + labldir\n        os.makedirs(newdir, exist_ok=True)","35ea1149":"# Copy Images to test set\n\nrandom.seed(12)\ntest_ratio = 0.1\n########## yahan change\n\nfor cases in [covid, non_covid]:\n    total_cases = len(cases['images']) #number of total images\n    num_to_select = int(test_ratio * total_cases) #number of images to copy to test set\n    \n    print(cases['class'], num_to_select)\n    \n    list_of_random_files = random.sample(cases['images'], num_to_select) #random files selected\n\n    for files in list_of_random_files:\n        shutil.copy2(files, 'test\/' + cases['class'])","22e3c8fd":"# Copy Images to train set\nfor cases in [covid, non_covid]:\n    image_test_files = os.listdir('test\/' + cases['class']) # list test files \n    for images in cases['images']:\n        if images.split('\/')[-1] not in (image_test_files): #exclude test files from shutil.copy\n            shutil.copy2(images, 'train\/' + cases['class'])","d00a714b":"total_train_covid = len(os.listdir('\/kaggle\/working\/train\/CT_COVID'))\ntotal_train_noncovid = len(os.listdir('\/kaggle\/working\/train\/CT_NonCOVID'))\ntotal_test_covid = len(os.listdir('\/kaggle\/working\/test\/CT_COVID'))\ntotal_test_noncovid = len(os.listdir('\/kaggle\/working\/test\/CT_NonCOVID'))\n\nprint(\"Train sets images COVID: {}\".format(total_train_covid))\nprint(\"Train sets images Non COVID: {}\".format(total_train_noncovid))\nprint(\"Test sets images COVID: {}\".format(total_test_covid))\nprint(\"Test sets images Non COVID: {}\".format(total_test_noncovid))","344dd4b2":"batch_size = 32\nepochs = 50\nIMG_HEIGHT = 224\nIMG_WIDTH = 224","c70b1887":"train_image_generator = ImageDataGenerator(rescale=1.\/255,\n                                          horizontal_flip = True,\n                                          ) # Generator for our training data\ntest_image_generator = ImageDataGenerator(rescale=1.\/255,\n                                         horizontal_flip = True) # Generator for our validation data","f2811b06":"from keras.layers import Input, Lambda, Dense, Flatten, Dropout\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom keras import optimizers\n\nimport os\nos.environ['KERAS_BACKEND'] = 'theano'\nimport keras as ks\n\n# re-size all the images to this\nIMAGE_SIZE = [224, 224]","c1e9a1b5":"vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# don't train existing weights\nfor layer in vgg.layers:\n  layer.trainable = False\n  ","ec5e0088":"folders = glob('\/kaggle\/input\/covidct\/*\/')\nfolders\nvgg.summary()","99253230":"x = Flatten()(vgg.output)\nx = Dense(4096, activation='relu')(x)\nx = Dense(4096, activation='relu')(x)\nprediction = Dense(len(folders), activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)\n\n# view the structure of the model\nmodel.summary()\n\n# tell the model what cost and optimization method to use\n\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","9ef510a7":"train_dir = os.path.join('\/kaggle\/working\/train')\ntest_dir = os.path.join('\/kaggle\/working\/test')\n\n\ntotal_train = total_train_covid + total_train_noncovid\ntotal_test = total_test_covid + total_test_noncovid","d009662d":"train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n                                                           directory=train_dir,\n                                                           shuffle=True,\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                           class_mode='categorical')","4305174e":"test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n                                                              directory=test_dir,\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                              class_mode='categorical')","b1fb9cf3":"# fit the model\nr = model.fit_generator(\n  train_data_gen,\n  validation_data=test_data_gen,\n  epochs=26,\n  steps_per_epoch=len(train_data_gen),\n  validation_steps=len(test_data_gen)\n)\n# loss\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n# accuracies\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')","6e33b5e7":"last_layer = vgg.get_layer('block5_pool').output\nx = Flatten(name='flatten')(last_layer)\nx = Dense(128, activation='relu',name='fc1')(x)\nx = Dense(128, activation='relu',name='fc2')(x)\nprediction = Dense(len(folders), activation='softmax', name='output')(x)\n\nmodel = Model(inputs=vgg.input, outputs=prediction)\n\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adadelta',\n  metrics=['accuracy']\n)","40e67245":"r = model.fit_generator(\n  train_data_gen,\n  validation_data=test_data_gen,\n  epochs=26,\n  steps_per_epoch=len(train_data_gen),\n  validation_steps=len(test_data_gen)\n)\n# loss\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n# accuracies\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')","198c0bcc":"import time\nt=time.time()\n\nprint('Training time: %s' % (t - time.time()))\n(loss, accuracy) = model.evaluate(test_data_gen, verbose=2)\n\nprint(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))","1a1e6b64":"import tensorflow\nfrom tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout\nfrom tensorflow.keras.layers import InputLayer","afe7ba32":"model = Sequential([\n    Conv2D(16, (3,3), padding='same', activation='relu', input_shape=IMAGE_SIZE + [3]),\n    MaxPooling2D(2, 2),\n    Conv2D(32, (3,3), padding='same', activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(64, (3,3), padding='same', activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(128,(3,3), padding='same', activation='relu'),\n    MaxPooling2D(2,2),\n    Conv2D(64, (3,3), padding='same', activation='relu'),\n    MaxPooling2D(2,2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1, activation='sigmoid')\n    ])","4d3b41c6":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","675c43ab":"model.summary()","f41f36f8":"history = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=total_train \/\/ batch_size,\n    epochs=epochs,\n    validation_data=test_data_gen,\n    validation_steps=total_test \/\/ batch_size\n)","92ebf0b7":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","217ce33a":"iske baad old code hai","d25a2311":"model = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n    MaxPooling2D(),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1)\n])","321c8534":"### Create Train-Test Directory ","0e59ab45":"**n-1 layer hatao and fine tune**","82757039":"train_image_generator = ImageDataGenerator(rescale=1.\/255,\n                                          rotation_range = 40,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True) # Generator for our training data\ntest_image_generator = ImageDataGenerator(rescale=1.\/255,\n                                         rotation_range = 40,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True) # Generator for our validation data","b22c0a47":"***As classifier***","770807bb":"### Simple CNN Model\n[Tensorflow Tutorial](https:\/\/www.tensorflow.org\/tutorials\/images\/classification)","768b58b4":"model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])"}}