{"cell_type":{"fabbe6fd":"code","f6b319e9":"code","f3b60d0c":"code","ca65185b":"code","60de4efb":"code","8334ecfe":"code","fc8bf061":"code","ea831d20":"code","d28ff7f7":"code","9e886b01":"code","b16dc14a":"code","1f85780d":"code","9956b313":"code","45ed2287":"code","816a1d11":"code","96998735":"code","bc33cbc8":"code","8f85fc5d":"code","81af61e8":"code","b0cb8be1":"code","c98a4997":"code","870d113f":"markdown","0009ef92":"markdown"},"source":{"fabbe6fd":"!pip install --upgrade light-the-torch\n!ltt install torch torchvision torchaudio\n!pip install --upgrade git+http:\/\/github.com\/fastaudio\/fastaudio.git","f6b319e9":"# this is needed for the library\nimport pkg_resources\ndef placeholder(x):\n    raise pkg_resources.DistributionNotFound\npkg_resources.get_distribution = placeholder","f3b60d0c":"import pandas as pd\nfrom fastaudio.all import *\nfrom fastai.vision.all import *","ca65185b":"path = Path(\"..\/input\/rfcx-species-audio-detection\")\nfor i in path.ls():\n    print(i)","60de4efb":"train_path = path \/ 'train'\ntest_path = path \/ 'test'","8334ecfe":"train_files = get_audio_files(train_path)\nlen(train_files)","fc8bf061":"index =math.floor(random.random()*4727)\nprint(index)\n\n# random bird chirping from amazon!\naudio = AudioTensor.create(train_files[index])\naudio.show()","ea831d20":"df_train_tp = pd.read_csv(path\/ 'train_tp.csv')\ndf_train_tp[\"recording_id\"] = df_train_tp[\"recording_id\"].map(lambda x: \"train\/\"+x)\ndf_train_tp.head()","d28ff7f7":"df_train_tp.iloc[:]","9e886b01":"df_train_tp = df_train_tp.drop(['t_min', 't_max', 'f_min', 'f_max', 'songtype_id'],axis=1)\ndf_train_tp['species_id'] = df_train_tp['species_id'].astype(str)\ndf_train_tp.head()","b16dc14a":"df_train_tp['species_id'] = df_train_tp.groupby('recording_id')['species_id'].transform(\",\".join)\ndf_train_tp = df_train_tp.reset_index()","1f85780d":"df_train_tp","9956b313":"# this part is wizadry\naudio_to_spec = AudioToSpec.from_cfg(AudioConfig.BasicMelSpectrogram(n_fft=512))\ndata_augmentation = [AddNoise(color=NoiseColor.White, noise_level=0.1), SignalShifter(max_pct=0.3)]\n\nblocks = DataBlock(blocks=(AudioBlock, MultiCategoryBlock), get_x = ColReader('recording_id', pref=str(path.resolve()) + \"\/\" , suff='.flac'),\n                   get_y = ColReader('species_id', label_delim=','),\n                   item_tfms = data_augmentation,\n                   batch_tfms = audio_to_spec,\n                   splitter = RandomSplitter(valid_pct=0.2, seed=42))","45ed2287":"dls = blocks.dataloaders(df_train_tp,bs=24)","816a1d11":"dls.show_batch(ncols=3, nrows=2, figsize=(20, 10))","96998735":"learner = cnn_learner(dls, resnet18, config={\"n_in\":1})","bc33cbc8":"learner.lr_find()","8f85fc5d":"learner.fine_tune(10, base_lr=5e-2)","81af61e8":"learner.recorder.plot_loss()","b0cb8be1":"submission_df = pd.read_csv(path \/ 'sample_submission.csv')\nsubmission_df[\"recording_id\"] = submission_df[\"recording_id\"].map(lambda x: \"test\/\"+x)\nsubmission_df","c98a4997":"submission_df.to_csv('submission.csv', index=False)","870d113f":"It works !","0009ef92":"Trying fastaudio for myself : https:\/\/www.kaggle.com\/scart97\/fastaudio-starter-kit"}}