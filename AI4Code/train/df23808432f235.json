{"cell_type":{"88f3c119":"code","eb49140a":"code","c27fa7a1":"code","606a3f25":"code","cf2256b6":"code","0fb33836":"code","f98f7747":"code","5cc86061":"code","e83560ba":"code","267c661b":"code","83c89b2e":"code","95aa5c35":"code","4c37ec50":"code","3543f41b":"code","8a70f4bf":"code","e169d4bf":"code","9fbef2de":"code","afa0acb0":"code","eac6e1bc":"code","4fe0d1bf":"code","21ba95ac":"code","cad707a2":"code","fa89ebd8":"code","29bd18d5":"code","2800ef99":"code","c9e342db":"code","b7994e8a":"code","c2098827":"code","c1dcd831":"code","1f70741b":"code","117cd4c7":"code","2e7bb140":"markdown","be83f322":"markdown","1a25a0ad":"markdown","a839d274":"markdown","09a154ff":"markdown","892e5401":"markdown","3e0f2b94":"markdown","553d7245":"markdown","53c3324c":"markdown","94606edd":"markdown","ef399842":"markdown","38f6eca9":"markdown","5d145953":"markdown","473772b5":"markdown","9ddc6a6b":"markdown"},"source":{"88f3c119":"#Import libraries\nimport pandas as pd \nimport numpy as np\nimport sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBRegressor\n# Pandas configurations \nsns.set()\n%matplotlib inline\n#pd.set_option('display.float_format', lambda x: '%.2f' % x)\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 200)","eb49140a":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",props[col].dtype)\n            print(\"******************************\")\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return props, NAlist\n\n\n\n\n#Import data\nprint('Loading data...')\n\ntrain_2016 = pd.read_csv('..\/input\/zillow-prize-1\/train_2016_v2.csv', low_memory=False)\nproperties_2016, NAlist_2016 = reduce_mem_usage(pd.read_csv('..\/input\/zillow-prize-1\/properties_2016.csv',low_memory=False))\ntrain_2017 = pd.read_csv('..\/input\/zillow-prize-1\/train_2017.csv',low_memory=False)\nproperties_2017, NAlist_2017 = reduce_mem_usage(pd.read_csv('..\/input\/zillow-prize-1\/properties_2017.csv',low_memory=False))\n\n","c27fa7a1":"properties_2016.head()","606a3f25":"#Merging properties with the train dataset for exploratory analysis\nprint('Merging the data...')\n\ndf_train_2016 = train_2016.merge(properties_2016, how='left', on='parcelid')\ndf_train_2017 = train_2017.merge(properties_2017, how='left', on='parcelid')\n\nfull_df = pd.concat([df_train_2017,df_train_2016])\n#Check the train dataset\nprint('Our dataset contains {} rows and {} columns.'.format(full_df.shape[0], full_df.shape[1]))","cf2256b6":"# Just as informations about our data types\nsns.set_theme(style=\"whitegrid\")\nplt.title('Data types repartition')\nfull_df.dtypes.value_counts().plot.pie()\nprint('We can see that most of our data are numerical values')","0fb33836":"full_df.columns","f98f7747":"\"\"\"\n    Assign better names to all feature columns of 'properties' table\n\"\"\"\ndef rename_columns(df):\n     df.rename(columns={\n          'parcelid': 'parcelid',  # Unique identifier of parcels\n          'airconditioningtypeid': 'cooling_id',  # type of cooling system (if any), 1~13\n          'architecturalstyletypeid': 'architecture_style_id',  # Architectural style of the home, 1~27\n          'basementsqft': 'basement_sqft',  # Size of the basement\n          'bathroomcnt': 'bathroom_cnt',  # Number of bathrooms (including fractional bathrooms)\n          'bedroomcnt': 'bedroom_cnt',  # Number of bedrooms\n          'buildingclasstypeid': 'framing_id',  # The building framing type, 1~5\n          'buildingqualitytypeid': 'quality_id',  # building condition from best (lowest) to worst (highest)\n          'calculatedbathnbr': 'bathroom_cnt_calc',  # Same meaning as 'bathroom_cnt'?\n          'decktypeid': 'deck_id',  # Type of deck (if any)\n          'finishedfloor1squarefeet': 'floor1_sqft',  # Size of finished living area on first floor\n          'calculatedfinishedsquarefeet': 'finished_area_sqft_calc',  # calculated total finished living area\n          'finishedsquarefeet12': 'finished_area_sqft',  # Same meaning as 'finished_area_sqft_calc'?\n          'finishedsquarefeet13': 'perimeter_area',  # Perimeter living area\n          'finishedsquarefeet15': 'total_area',  # Total area\n          'finishedsquarefeet50': 'floor1_sqft_unk',  # Same meaning as 'floor1_sqft'?\n          'finishedsquarefeet6': 'base_total_area',  # Base unfinished and finished area\n          'fips': 'fips',  # Federal Information Processing Standard code\n          'fireplacecnt': 'fireplace_cnt',  # Number of fireplaces in the home (if any)\n          'fullbathcnt': 'bathroom_full_cnt',  # Number of full bathrooms\n          'garagecarcnt': 'garage_cnt',  # Total number of garages\n          'garagetotalsqft': 'garage_sqft',  # Total size of the garages\n          'hashottuborspa': 'spa_flag',  # Whether the home has a hot tub or spa\n          'heatingorsystemtypeid': 'heating_id',  # type of heating system, 1~25\n          'latitude': 'latitude',  # latitude of the middle of the parcel multiplied by 1e6\n          'longitude': 'longitude',  # longitude of the middle of the parcel multiplied by 1e6\n          'lotsizesquarefeet': 'lot_sqft',  # Area of the lot in sqft\n          'poolcnt': 'pool_cnt', # Number of pools in the lot (if any)\n          'poolsizesum': 'pool_total_size',  # Total size of the pools\n          'pooltypeid10': 'pool_unk_1',\n          'pooltypeid2': 'pool_unk_2',\n          'pooltypeid7': 'pool_unk_3',\n          'propertycountylandusecode': 'county_landuse_code',\n          'propertylandusetypeid': 'landuse_type_id' ,  # Type of land use the property is zoned for, 25 categories\n          'propertyzoningdesc': 'zoning_description',  # Allowed land uses (zoning) for that property\n          'rawcensustractandblock': 'census_1',\n          'regionidcity': 'city_id',  # City in which the property is located (if any)\n          'regionidcounty': 'county_id',  # County in which the property is located\n          'regionidneighborhood': 'neighborhood_id',  # Neighborhood in which the property is located\n          'regionidzip': 'region_zip',\n          'roomcnt': 'room_cnt',  # Total number of rooms in the principal residence\n          'storytypeid': 'story_id',  # Type of floors in a multi-story house, 1~35\n          'threequarterbathnbr': 'bathroom_small_cnt',  # Number of 3\/4 bathrooms\n          'typeconstructiontypeid': 'construction_id',  # Type of construction material, 1~18\n          'unitcnt': 'unit_cnt',  # Number of units the structure is built into (2=duplex, 3=triplex, etc)\n          'yardbuildingsqft17': 'patio_sqft',  # Patio in yard\n          'yardbuildingsqft26': 'storage_sqft',  # Storage shed\/building in yard\n          'yearbuilt': 'year_built',  # The year the principal residence was built\n          'numberofstories': 'story_cnt',  # Number of stories or levels the home has\n          'fireplaceflag': 'fireplace_flag',  # Whether the home has a fireplace\n          'structuretaxvaluedollarcnt': 'tax_structure',\n          'taxvaluedollarcnt': 'tax_parcel',\n          'assessmentyear': 'tax_year',  # The year of the property tax assessment (2015 for 2016 data)\n          'landtaxvaluedollarcnt': 'tax_land',\n          'taxamount': 'tax_property',\n          'taxdelinquencyflag': 'tax_overdue_flag',  # Property taxes are past due as of 2015\n          'taxdelinquencyyear': 'tax_overdue_year',  # Year for which the unpaid propert taxes were due\n          'censustractandblock': 'census_2'\n     }, inplace=True)\n        \nrename_columns(full_df)","5cc86061":"#full_df = full_df.drop('parcelid', axis=1)","e83560ba":"full_df.head()","267c661b":"# Visualization of the  missing value per columns\nplt.figure(figsize=(13, 40))\nplt.rcParams['axes.facecolor'] = '#eee'\nplt.rc('grid', color='#fff')\n(full_df.isnull().mean(axis=0)*100).sort_values().plot.barh(color =\"Lightblue\")\nplt.xlim(xmax=100)\nplt.title(\"Missing values rate\",fontsize=18)\nplt.xlabel(\"percentage\",fontsize=14)","83c89b2e":"print('Our target variable \"logerror\" has {} missing value(s)'.format(full_df['logerror'].isnull().sum()))","95aa5c35":"y = full_df['logerror']\nX = full_df.drop(['logerror', 'transactiondate', 'county_landuse_code', 'zoning_description'], axis=1)\n\n#print(f\"X shape: {X.shape}\")\n#print(f\"y shape: {y.shape}\")","4c37ec50":"numeric_cols = X.select_dtypes(include=[\"float64\",\"int64\"]).columns\ncategory_cols = X.select_dtypes(include=\"object\").columns","3543f41b":"for col in category_cols:\n    print(\"Unique values of the column {} : {}\".format(col, X[col].unique()))\n    print(\"Unique values of the column {} : {}\".format(col, X[col].nunique(dropna=True)))","8a70f4bf":"X[['spa_flag', 'fireplace_flag']] = X[['spa_flag', 'fireplace_flag']].fillna(False)\nX['tax_overdue_flag'] = X['tax_overdue_flag'].fillna('N')","e169d4bf":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","9fbef2de":"X_train.head()","afa0acb0":"# Preprocessing data\nnum_imp = SimpleImputer(missing_values=np.nan, strategy=\"constant\")\n# Preprocessing for categorical data\ncat_imp = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n\ncol_trans = ColumnTransformer(\n    transformers=[\n        ('numerical', num_imp, numeric_cols),\n        ('category', cat_imp, category_cols)\n])\n# Random forest model\nmodel_xgboost = XGBRegressor(random_state=0)\n\n#Pipeline\npipe = Pipeline(steps=[\n    ('preprocessor', col_trans),\n    ('model', model_xgboost )\n])\n\n# Defining parameters for the GridSearchCV\nparameters = {\n    'model__n_estimators': [100, 120, 150, 200],\n    'model__learning_rate': [0.02,0.05,0.07]\n}\n\nsearch = GridSearchCV(\n    estimator = pipe,\n    param_grid = parameters,\n    cv = 3\n)\n\n# Fit the model\nsearch.fit(X_train, y_train)\n\nprint('-----')\nprint(f'Best parameters {search.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{search.best_score_:.3f}'\n)\nprint('-----')","eac6e1bc":"print(search.score(X_train, y_train))","4fe0d1bf":"y_pred = search.predict(X_test)\ny_pred = pd.DataFrame(y_pred)\ny_pred.head()","21ba95ac":"print('Mean absolute error: ', mean_absolute_error(y_test, y_pred))","cad707a2":"sample_sub = pd.read_csv('..\/input\/zillow-prize-1\/sample_submission.csv')\nsample_sub['parcelid'] = sample_sub['ParcelId']\n\n\nX_valid = properties_2016\n\n\nsub = sample_sub.merge(X_valid, on='parcelid', how='left')","fa89ebd8":"sub.head()","29bd18d5":"rename_columns(X_valid)","2800ef99":"pd.set_option('display.float_format', lambda x: '%.4f' % x)\nX_valid = X_valid.drop(['county_landuse_code', 'zoning_description' ],axis=1)\npredictions = search.predict(X_valid)\npd.DataFrame(predictions).head()","c9e342db":"X_test.head()","b7994e8a":"X_valid.head()","c2098827":"sub['201610'] = predictions\nsub['201611'] = predictions\nsub['201612'] = predictions\nsub['201710'] = predictions\nsub['201711'] = predictions\nsub['201712'] = predictions","c1dcd831":"sub.head()","1f70741b":"sub = sub[['ParcelId', '201610', '201611', '201612', '201710', '201711', '201712']]\nsub.head()","117cd4c7":"print('Writing csv ...')\nsub.to_csv('xgboost_model.csv', index=False, float_format='%.4f') # Thanks to @inversion","2e7bb140":"# IV. Splitting the dataset into the train set and the test set","be83f322":"## III.2 Data analysis","1a25a0ad":"### III.2.1 Data type check","a839d274":"Since spa_flag, fireplace_flag and tax_overdue_flag have only one unique value and it's either True or 'Y', we could replace the missing values with False when the unique value is True and 'N' when the unique value is 'Y'.","09a154ff":"## III.1 Merging the data","892e5401":"## VI.1 Imputing missing values for numerical and categorical variables","3e0f2b94":"# III. Data exploratory","553d7245":"For preprocessing purpose, I identify the numerical and object columns.","53c3324c":"### III.2.2 Dataset Columns","94606edd":"# II. Import dataset","ef399842":"### III.2.3 Missing Values check","38f6eca9":"# VI. XGBoost model","5d145953":"# I. Import libraries","473772b5":"We notice there are a lot of columns with more than 90 % missing values.\nLet's check if our target variable has missing values.","9ddc6a6b":"Renaming columns for better understanding of our features as they are a bit confusing at first"}}