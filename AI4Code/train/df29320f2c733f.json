{"cell_type":{"b0bbe6e5":"code","5a98ed71":"code","9a2d61df":"code","db84faf1":"code","b90fb01e":"code","e9447f72":"code","2c40bf64":"code","687d9acb":"code","6497035b":"code","7e9c8d34":"code","3cd72af7":"code","defd18cd":"code","42635927":"code","aa1c738c":"code","7ad8d5ed":"code","ba33d7fb":"code","86cbcc0c":"code","e2accb40":"code","1d6598bf":"code","7d662264":"code","fae03518":"code","d2309c25":"code","f4386570":"code","62211a42":"code","1a996b4b":"code","54baad7c":"code","9aa2ae51":"code","a94ff82b":"code","41f325b7":"code","938fa8b7":"code","90db46b7":"code","ce2b4947":"code","bf4be0bb":"code","ad2f885e":"markdown","7c2ebd57":"markdown","8ed2ab8c":"markdown","de716267":"markdown","49c657ae":"markdown","d51386f8":"markdown","c6e0d063":"markdown","83047b7d":"markdown","5a0a0b3c":"markdown","1bd407f1":"markdown","1691ce21":"markdown","f41890d2":"markdown","ffedbdac":"markdown","030ba1fa":"markdown","501f48aa":"markdown","011c8767":"markdown","c3f372e3":"markdown","d5c235da":"markdown","42f35cae":"markdown","7bfc3dbf":"markdown","5fd4f2c0":"markdown","8da620bd":"markdown","04a2f2b4":"markdown","43e0695c":"markdown","721c29fa":"markdown","d54c2a1e":"markdown","27628846":"markdown","015767ea":"markdown","53382960":"markdown"},"source":{"b0bbe6e5":"# Import de algumas bibliotecas que ser\u00e3o utilizadas\nimport pandas as pd\n\nimport matplotlib\nimport matplotlib.pyplot as plt","5a98ed71":"def scatter_bylabel(xdata, ydata, label, color, pointsize = 150, figdpi = 300, figsize = (10, 10)) -> None:\n    \"\"\"Fun\u00e7\u00e3o auxiliar para facilitar a cria\u00e7\u00e3o de um scatter plot, que colore os pontos com base em suas *labels*\n        \n    Args:\n        xdata (pandas.Series): Dados do eixo X\n        ydata (pandas.Series): Dados do eixo Y\n        label (list): Lista com as labels presentes nos dados\n        color (list): Lista com as cores que devem ser utilizadas para cada label\n        pointsize (int): Tamanho do ponto\n        figdpi (int): DPI da figura gerada\n        figsize (tuple): Tupla com as dimens\u00f5es da figura\n    Returns:\n        Esta fun\u00e7\u00e3o n\u00e3o tem retorno\n    \"\"\"\n    fig = plt.figure(figsize = figsize, dpi = figdpi)\n    plt.scatter(xdata, ydata, pointsize, c = label, cmap = matplotlib.colors.ListedColormap(\n        color\n    ), edgecolors='black')","9a2d61df":"def scatter_point_to_classify(xdata, ydata, label, color, newpoint, pointsize = 150, \n                                                          figdpi = 300, figsize = (10, 10)):\n    \"\"\"Fun\u00e7\u00e3o auxiliar que adiciona um novo pontos antes de realizar um scatter plot. Utiliza como base a fun\u00e7\u00e3o\n    auxiliar scatter_bylabel\n        \n    Args:\n        xdata (pandas.Series): Dados do eixo X\n        ydata (pandas.Series): Dados do eixo Y\n        label (list): Lista com as labels presentes nos dados\n        color (list): Lista com as cores que devem ser utilizadas para cada label\n        newpoint (dict): Dicion\u00e1rio com os campos (pointx, pointy, color)\n        pointsize (int): Tamanho do ponto\n        figdpi (int): DPI da figura gerada\n        figsize (tuple): Tupla com as dimens\u00f5es da figura\n    Returns:\n        Esta fun\u00e7\u00e3o n\u00e3o tem retorno\n    \"\"\"\n    import numpy as np\n        \n    color = np.append(color, newpoint['color'])\n    xdata = np.append(xdata, newpoint['pointx'])\n    ydata = np.append(ydata, newpoint['pointy'])\n    label = np.append(label, newpoint['color'])\n    \n    scatter_bylabel(xdata, ydata, label, color, pointsize = pointsize, figdpi = figdpi, figsize = figsize)","db84faf1":"df = pd.read_csv('..\/input\/generatedrandompoints\/points.csv')\ndf.head()","b90fb01e":"color = df['label'].str.lower().unique()\nscatter_bylabel(df['pointx'], df['pointy'], df['label'], color, figdpi = None, figsize = (7, 7))","e9447f72":"from sklearn.neighbors import KNeighborsClassifier","2c40bf64":"knn = KNeighborsClassifier(n_neighbors = 3)","687d9acb":"pontos_attr = df.iloc[:, 0:-1]\npontos_attr.head()","6497035b":"pontos_labels = df['label']\npontos_labels.head()","7e9c8d34":"knn.fit(pontos_attr, pontos_labels)","3cd72af7":"newpoint = {\n    'color': 'red',\n    'pointx': 3,\n    'pointy': 6.5\n}","defd18cd":"scatter_point_to_classify(df['pointx'], df['pointy'], df['label'], \n                          color, newpoint, figdpi = None, figsize = (7, 7))","42635927":"knn.predict([[newpoint['pointx'], newpoint['pointy']]])","aa1c738c":"from sklearn.model_selection import train_test_split","7ad8d5ed":"x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, 0:-1], df['label'], train_size = 0.7)","ba33d7fb":"knn = KNeighborsClassifier(n_neighbors = 3)\n\nknn.fit(x_train, y_train)","86cbcc0c":"y_pred = knn.predict(x_test)\ny_pred","e2accb40":"from sklearn.metrics import accuracy_score, confusion_matrix","1d6598bf":"accuracy_score(y_test, y_pred)","7d662264":"from sklearn.metrics import plot_confusion_matrix","fae03518":"confusion_matrix(y_test, y_pred)","d2309c25":"fig, ax = plt.subplots(dpi = 110)\n\ndisp = plot_confusion_matrix(knn, x_test, y_test, cmap = plt.cm.Blues, \n                                 display_labels = df['label'].unique(), ax = ax)","f4386570":"from sklearn import datasets\n\niris = datasets.load_iris()","62211a42":"iris.data","1a996b4b":"iris.target","54baad7c":"irisdf = pd.DataFrame({\n    'sepal_length': iris.data[:, 0],\n    'sepal_width': iris.data[:, 1],\n    'petal_length': iris.data[:, 2],\n    'petal_width': iris.data[:, 3],\n    'label': iris.target\n})\n\nirisdf.head()","9aa2ae51":"import seaborn as sns","a94ff82b":"sns.pairplot(irisdf, hue = 'label')","41f325b7":"knn = KNeighborsClassifier(n_neighbors = 2)","938fa8b7":"x_train, x_test, y_train, y_test = train_test_split(irisdf.iloc[:, 0:-1], irisdf['label'], train_size = 0.7)","90db46b7":"knn.fit(x_train, y_train)","ce2b4947":"y_pred = knn.predict(x_test)\ny_pred","bf4be0bb":"fig, ax = plt.subplots(dpi = 110)\n\ndisp = plot_confusion_matrix(knn, x_test, y_test, cmap = plt.cm.Blues, \n                                 display_labels = iris.target_names, ax = ax)","ad2f885e":"Com ele carregados, o que temos de fazer \u00e9 criar uma inst\u00e2ncia do algoritmo. Neste passo, especificamos a quantidade de vizinhos que ser\u00e3o considerados no passo da an\u00e1lise de vizinhan\u00e7a que \u00e9 feita no kNN.","7c2ebd57":"<img src=\"https:\/\/suspicious-wescoff-e06084.netlify.app\/banner_notebook.png\"\/>\n\n# Exemplo de aplica\u00e7\u00e3o do K-Nearest Neighbors (kNN)\n\n- **Instrutores**: Adriano, Felipe Carvalho e Felipe Menino\n\n- **Realiza\u00e7\u00e3o**: Dia 15\/09\n\n- **Descri\u00e7\u00e3o**: Objetiva-se apresentar aos alunos exemplos de aplica\u00e7\u00e3o de algoritmos de classifica\u00e7\u00e3o utilizando K-Nearest Neighbors (kNN).\n\n* **Sum\u00e1rio**:\n    * [Livro **Introdu\u00e7\u00e3o ao Machine Learning**](https:\/\/dataat.github.io\/introducao-ao-machine-learning\/)\n    * [Exemplo de **Classifica\u00e7\u00e3o** em Python](https:\/\/www.kaggle.com\/phelpsmemo\/intro-ml-python-knn-worcap2020)\n    * [Exemplo de **Regress\u00e3o** em Python](https:\/\/www.kaggle.com\/lordadriano\/intro-ml-python-svr-worcap2020)\n    * [Exemplo de **Agrupamento** em R](https:\/\/www.kaggle.com\/oldlipe\/intro-ml-r-hiererquico-worcap2020)\n\n\n<hr style=\"border: 2px solid #0984e3;\">\n","8ed2ab8c":"### Utilizando o kNN para classificar pontos","de716267":"Feito isto, vamos organizar os dados para que eles possam ser utilizados. Neste passo de organiza\u00e7\u00e3o \u00e9 feita a separa\u00e7\u00e3o dos atributos que representam os pontos e seus *labels*.","49c657ae":"O que temos em m\u00e3os agora s\u00e3o os resultados gerados pelo algoritmo (`y_pred`) e os valores verdadeiros (`y_test`). Para este processo de avalia\u00e7\u00e3o, vamos utilizar as funcionalidades do m\u00f3dulo `sklearn.metrics`, que possui diversas fun\u00e7\u00f5es para a avalia\u00e7\u00e3o de algoritmos de classifica\u00e7\u00e3o e outros.\n\nVamos trabalhar aqui com as fun\u00e7\u00f5es `sklearn.metrics.accuracy_score`, que gera a acur\u00e1cia do resultado gerado pelo algoritmo e `sklearn.metrics.accuracy_score`, que gera a matriz de confus\u00e3o dos resultados.","d51386f8":"Essa visualiza\u00e7\u00e3o est\u00e1 um pouco confusa! N\u00e3o tem problema, o scikit-learn fornece tamb\u00e9m a fun\u00e7\u00e3o `sklearn.metrics.plot_confusion_matrix` para a visualiza\u00e7\u00e3o da matriz de confus\u00e3o.","c6e0d063":"### Trabalhando com o conjunto de dados do iris\n\n<hr>\n\nPublicado por Ronald Fisher em 1936, junto ao artigo *The Use of Multiple Measurements in Taxonomic Problems*, o *iris dataset* \u00e9 um dos conjuntos de dados mais conhecidos na \u00e1rea de reconhecimento de padr\u00f5es e minera\u00e7\u00e3o de dados. Suas caracter\u00edsticas o tornam propenso ao uso em tarefas de classifica\u00e7\u00e3o, agrupamento e diversos outros testes de algoritmos.\n\nO *iris dataset* \u00e9 composto por 4 atributos (Comprimento e largura das s\u00e9palas e p\u00e9talas) de 150 amostras, sendo essas divididas em tr\u00eas esp\u00e9cies de iris (Setosa, Virginica e versicolor). Cada uma dessas esp\u00e9cies s\u00e3o apresentadas na figura abaixo, junto com a identifica\u00e7\u00e3o de suas p\u00e9talas e s\u00e9palas.\n    \n<div align=\"left\">\n    <img src=\"https:\/\/suspicious-wescoff-e06084.netlify.app\/iris-datasetpng\"\/ width=\"650\">\n<\/div>","83047b7d":"Utilizando a biblioteca [Seaborn](https:\/\/seaborn.pydata.org\/), fa\u00e7amos a visualiza\u00e7\u00e3o das correla\u00e7\u00f5es que esses dados tem. ","5a0a0b3c":"#### Avaliando os resultados\n\nUma coisa importante e necess\u00e1ria quando estamos falando de classificadores \u00e9 a avalia\u00e7\u00e3o da qualidade de suas classifica\u00e7\u00f5es. Entender isso nos ajuda a tomar decis\u00f5es sobre quais par\u00e2metros precisam ser melhorados (Quando dispon\u00edveis), ou mesmo se precisamos fazer mudan\u00e7as e melhorias nos dados. Para isso, nesta se\u00e7\u00e3o, vamos ver um pouco sobre com o scikit-learn pode nos ajudar a resolver estes problemas. \n\nNeste processo de avalia\u00e7\u00e3o, a primeira coisa a ser feita \u00e9 criar subconjuntos de dados para que avalia\u00e7\u00f5es possam ser feitas, neste caso, vamos utilizar a fun\u00e7\u00e3o `sklearn.model_selection.train_test_split`, que divide o conjunto de dados em dois, `Treino` e `Teste`.\n\n> Este processo de separa\u00e7\u00e3o do conjunto de dados em treino e teste \u00e9 muito comum na \u00e1rea de classifica\u00e7\u00e3o. A ideia \u00e9 fazer com que o processo de treinamento ocorra com um conjunto de dados e sua avalia\u00e7\u00e3o seja feita com outro, que cont\u00e9m amostras que o modelo de classifica\u00e7\u00e3o at\u00e9 aquele ponto n\u00e3o viu.\n\nAs combina\u00e7\u00f5es poss\u00edveis para a quantidade de dados em cada um dos dois grupos varia de acordo com a aplica\u00e7\u00e3o. Neste caso, vamos aplicar 70% para treino e 30% para teste.","1bd407f1":"O retorno da fun\u00e7\u00e3o `datasets.load_iris` \u00e9 uma estrutura do tipo `sklearn.utils.Bunch`.\n\n> Por curiosidade, o tipo `sklearn.utils.Bunch` representa um *container* do scikit-learn para o armazenamento de dados, permitindo que os dados sejam acessados por chave ou atributo.\n\nPara acessar os dados \u00e9 poss\u00edvel utilizar o atributo\/chave `data`. As informa\u00e7\u00f5es dos `labels` de cada amostra est\u00e1 dispon\u00edvel no atributo `target`.","1691ce21":"## Classifica\u00e7\u00e3o de pontos\n<hr>\n\nO primeiro exerc\u00edcio que vamos fazer neste exemplo \u00e9 a classifica\u00e7\u00e3o de alguns pontos no plano cartesiano, atividade muito semelhante ao que foi apresentado no exemplo de defini\u00e7\u00e3o do kNN. Nesta atividade, ser\u00e1 utilizado um conjunto de dados composto por 123 pontos gerados aleatoriamente, sendo que, para cada ponto est\u00e1 associado uma cor. \u00c9 considerado que a cor representa a classe do ponto.\n\nOs dados est\u00e3o armazenados no arquivo `points.csv` e ser\u00e3o carregados com o aux\u00edlio da biblioteca [Pandas](https:\/\/pandas.pydata.org\/).","f41890d2":"Com tudo pronto o kNN pode ser treinado. Aqui cabe um adendo sobre a maneira a qual o kNN est\u00e1 implementado dentro do scikit-learn. Como vimos nas aulas te\u00f3ricas, o algoritmo do kNN n\u00e3o exige de um processo de treinamento expl\u00edcito, isso porque a cada amostra que precisa ser classificada todas as dist\u00e2ncias s\u00e3o calculadas e ent\u00e3o com base na an\u00e1lise dos vizinhos faz-se a defini\u00e7\u00e3o da classe.\n\nComo forma de evitar uma grande quantidade de compara\u00e7\u00f5es, neste processo a que estamos chamando de treinamento, a implementa\u00e7\u00e3o do scikit-learn vai criar um \u00edndice que possibilita buscas mais acertivas e r\u00e1pidas aos vizinhos mais pr\u00f3ximos de um ponto que se queira classificar.\n\nVamos aplicar o treinamento utilizando o m\u00e9todo `fit`, este que vai receber os valores dos pontos e seus respectivos `labels`.","ffedbdac":"Com os dados separados, vamos fazer o mesmo processo de \"treinamento\" do kNN e ent\u00e3o realizar as classifica\u00e7\u00f5es no conjunto de dados de teste.","030ba1fa":"Fa\u00e7amos a visualiza\u00e7\u00e3o da matriz de confus\u00e3o, isso vai nos ajudar a entender se as defini\u00e7\u00f5es de vizinhan\u00e7a que fizemos s\u00e3o boas o suficiente para estes dados.","501f48aa":"Bem, agora que sabemos qual \u00e9 a disposi\u00e7\u00e3o dos dados, vamos utilizar o kNN para realizar a classifica\u00e7\u00e3o deles! Vamos fazer isso utilizando o scikit-learn.","011c8767":"Exatamente! Mas veja, ele foi de encontro com a nossa an\u00e1lise neste ponto, e nos demais? Ser\u00e1 que ele consegue classificar corretamente em 100% dos casos ? Para isso, vamos falar um pouco sobre as ferramentas que o scikit-learn nos oferece para avaliar um classificador.","c3f372e3":"#### Defini\u00e7\u00e3o de fun\u00e7\u00f5es auxiliares\n\nCriar fun\u00e7\u00f5es auxiliares nos permite reutilizar c\u00f3digo e otimizar nosso tempo. Abaixo, s\u00e3o definidas algumas fun\u00e7\u00f5es auxiliares para facilitar algumas etapas. Fique \u00e0 vontade para modificar e usar essas fun\u00e7\u00f5es.\n","d5c235da":"Assim como vimos anteriormente, para nos ajudar a entender o desempenho que o algoritmo est\u00e1 apresentando, vamos separar o conjunto de dados em duas partes, `Treino` e `Teste`.","42f35cae":"Agora, vamos fazer a classifica\u00e7\u00e3o dos dados do conjunto de teste.","7bfc3dbf":"Atualmente, esse conjunto de dados est\u00e1 dispon\u00edvel no [UCI Machine Learning Repository](https:\/\/archive.ics.uci.edu\/ml\/datasets\/iris). Os dados tamb\u00e9m est\u00e3o dispon\u00edveis no m\u00f3dulo `sklearn.datasets`, que ser\u00e1 utilizado neste tutorial.\n\nPara come\u00e7ar, o conjunto de dados \u00e9 carregado com o aux\u00edlio do scikit-learn.","5fd4f2c0":"Veja o ponto vermelho, \u00e9 o ponto que queremos classificar. Fazendo uma an\u00e1lise r\u00e1pida e visual, \u00e9 poss\u00edvel perceber que este ponto tem uma boa quantidade de vizinhos roxos e verdes, se considerarmos que a an\u00e1lise de vizinhan\u00e7a vai utilizar a classe de 3 vizinhos, como definimos, \u00e9 poss\u00edvel afirmar que o resultado da classifica\u00e7\u00e3o do kNN deve ser a *label* `Purple`.","8da620bd":"Pronto! O kNN j\u00e1 est\u00e1 pronto para classificar os dados de teste.","04a2f2b4":"Bem, agora vamos come\u00e7ar a fazer as classifica\u00e7\u00f5es e ver como o kNN funciona em sua implementa\u00e7\u00e3o do scikit-learn. Primeiro, vamos criar um novo ponto, que vai ser classificado.\n\nEste novo ponto $P$ vai estar nas posi\u00e7\u00f5es $(3, 6.5)$. Para facilitar a visualiza\u00e7\u00e3o, ele ser\u00e1 adicionado ao plano com os demais pontos.","43e0695c":"Perceba que interessante, mesmo sendo um dado gerado artificialmente, ele tem algumas coisas interessantes, como a sobreposi\u00e7\u00e3o de pontos de classes diferentes.\n\nAgora que j\u00e1 fizemos o carregamento e visualiza\u00e7\u00e3o dos dados, vamos fazer a classifica\u00e7\u00e3o utilizando o [scikit-learn](https:\/\/scikit-learn.org\/). Para isso, vamos carregar do m\u00f3dulo `sklearn.neighbors`, a classe `KNeighborsClassifier`, que representa o classificador kNN.","721c29fa":"Feito! Seu kNN est\u00e1 pronto para realizar classifica\u00e7\u00f5es =D","d54c2a1e":"> Sabendo que a escala dos resultados do `sklearn.metrics.accuracy_score` est\u00e1 no intervalo $[0, 1]$, temos que os resultados gerados pelo nosso algoritmo de kNN acertou em 81% dos casos.\n\nAl\u00e9m disso, podemos gerar uma matriz de confus\u00e3o, que nos ajuda a entender onde os erros ocorreram.","27628846":"Apenas olhar a tabela dos dados n\u00e3o nos ajuda a entender muito bem eles, ent\u00e3o, vamos visualizar este conjunto de dados.\n\n> A visualiza\u00e7\u00e3o \u00e9 criada com o aux\u00edlio da fun\u00e7\u00e3o `scatter_bylabel`.","015767ea":"Como forma de facilitar essa visualiza\u00e7\u00e3o e tamb\u00e9m o uso desses dados, vamos criar um `pandas.DataFrame`, que v\u00edncula todas essas informa\u00e7\u00f5es.","53382960":"Agora, utilizando os dados de treino, vamos preparar nosso classificador."}}