{"cell_type":{"f6fe9962":"code","6273f5ef":"code","88c95a8f":"code","4e8e2c6f":"code","f919c06f":"code","23098784":"code","7d3f6d26":"code","eb13a6c5":"code","2ca0ee2e":"code","bd20ada5":"code","7324a39d":"code","96a6efe2":"code","efdff37e":"code","418966be":"code","6fd973c3":"code","bbad1d93":"markdown","55358d75":"markdown","bd997262":"markdown","61500b59":"markdown","5f9c6cb6":"markdown"},"source":{"f6fe9962":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsample = pd.read_csv('..\/input\/sample_submission.csv')\n\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\n\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.dayofweek\ntrain['year'] = train['date'].dt.year\n\ntest['month'] = test['date'].dt.month\ntest['day'] = test['date'].dt.dayofweek\ntest['year'] = test['date'].dt.year\n\ntrain['block'] = 60-((train['year']-2013)*12+train['month'])\ntrain['week'] = 260-((train['year']-2013)*52+train['date'].dt.week)","6273f5ef":"    # Grouping by Date\/Time to calculate number of trips\n    day_df = pd.Series(train.groupby(['date'])['sales'].sum())\n    # setting Date\/Time as index\n    day_df.index = pd.DatetimeIndex(day_df.index)\n    # Resampling to daily trips\n    day_df = day_df.resample('1D').apply(np.sum)\n\n    day_df.plot()","88c95a8f":"#Checking trend and autocorrelation\ndef initial_plots(time_series, num_lag):\n\n    #Original timeseries plot\n    plt.figure(1)\n    plt.plot(time_series)\n    plt.title('Original data across time')\n    plt.figure(2)\n    plot_acf(time_series, lags = num_lag)\n    plt.title('Autocorrelation plot')\n    plot_pacf(time_series, lags = num_lag)\n    plt.title('Partial autocorrelation plot')\n    \n    plt.show()\n\n    \n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(day_df)[1]))\n\n#plotting\ninitial_plots(day_df, 45)","4e8e2c6f":"#storing differenced series\ndiff_series = day_df.diff(periods=1).diff(periods=7)\n\n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(diff_series.dropna())[1]))\ninitial_plots(diff_series.dropna(), 30)","f919c06f":"    # Grouping by Date\/Time to calculate number of trips\n    week_df = pd.Series(train.groupby(['week'])['sales'].sum())\n    # setting Date\/Time as index\n    week_df.plot()\n    initial_plots(week_df, 45)","23098784":"#storing differenced series\ndiff_series = week_df.diff(periods=1)\n\n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(diff_series.dropna())[1]))\ninitial_plots(diff_series.dropna(), 55)","7d3f6d26":"    # Grouping by Date\/Time to calculate number of trips\n    month_df = pd.Series(train.groupby(['block'])['sales'].sum())\n    # setting Date\/Time as index\n    month_df.plot()\n    initial_plots(month_df, 45)","eb13a6c5":"#storing differenced series\ndiff_series = month_df.diff(periods=1).diff(periods=12)\n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(diff_series.dropna())[1]))\ninitial_plots(diff_series.dropna(), 30)","2ca0ee2e":"train_p=train.pivot_table(index=['store', 'item'], columns='date', values='sales')\ntrain_p.head()","bd20ada5":"def piv_clust(data,veld,kolom,waarde,komponent):\n    from sklearn.decomposition import TruncatedSVD,FastICA\n    df = data.pivot_table(index=veld, columns=kolom, values=waarde, fill_value=0, aggfunc=np.sum)            #pivot table > signal should follow\n    svd = TruncatedSVD(n_components=komponent, n_iter=7, random_state=42)                                    #decomp functions\n    ica = FastICA(n_components=komponent, max_iter=1000, tol=0.1)\n    df_norm =( (df - df.mean()) \/ (df.max() - df.min()) ).fillna(0)                                          #normalize\n    return pd.DataFrame( np.concatenate([svd.fit_transform(df_norm)*svd.singular_values_, ica.fit_transform(df_norm)],axis=1) , index=df.index,columns=['clus'+str(x) for x in range(komponent+komponent)]),svd.explained_variance_ratio_  #U*S\n\n\nitem_c,item_sing=piv_clust(train,'item',['store','block'],'sales',10)\nstore_c,store_sing=piv_clust(train,'store',['item','block'],'sales',10)\n#train_s,sing_s=piv_clust(train_df,'shop_id',['item_category_id','date_block_num'],'item_price',10)\n#train_si,sing_si=piv_clust(train_df[train_df['date_block_num']>10],'item_id',['date_y'],'item_cnt_day',10)","7324a39d":"train_t=train_p.merge(item_c,left_index=True,right_index=True)\ntrain_t=train_t.merge(store_c,left_index=True,right_index=True)\n","96a6efe2":"train_t.shape","efdff37e":"# Create linear regression object\nregr = linear_model.LinearRegression()\n\nfor xi in range(26,27):\n    # Train the model\n    x = train_t.iloc[:,1:]\n    y = train_t.iloc[:,0]\n    regr.fit(x, y)\n    # Make predictions\n    pred = regr.predict(x)\n    # The coefficients\n    print('Intercept: \\n', regr.intercept_)\n    print('Coefficients: \\n', regr.coef_)\n    # The mean squared error\n    print(xi,'MSRE: %.4f'%np.sqrt(((y-pred)*(y-pred)).mean()))\n    \n    train_f=train_p.iloc[:,:-1].merge(item_c,left_index=True,right_index=True)\n    train_f=train_f.merge(store_c,left_index=True,right_index=True)\n    pred =regr.predict(train_f)\n    print(pred)\n","418966be":"\ntest['block'] = 60-((test['year']-2013)*12+test['month'])\ntest.groupby(['store', 'item']).max()","6fd973c3":"col = [i for i in test.columns if i not in ['date','id']]\ny = 'sales'\nprint(train_p.shape)\nytrain=train_p.iloc[:,-1:]\ntrain_x, train_cv, y, y_cv = train_test_split(train_p.iloc[:,-1:].reset_index(),ytrain, test_size=0.2, random_state=2018)\n\ndef XGB_regressor(train_X, train_y, test_X, test_y, feature_names=None, seed_val=2017, num_rounds=300):\n    param = {}\n    param['objective'] = 'reg:linear'\n    param['eta'] = 0.2\n    param['max_depth'] = 12\n    param['silent'] = 0\n    param['eval_metric'] = 'mae'\n    param['min_child_weight'] = 1\n    param['subsample'] = 0.7\n    param['colsample_bytree'] = 0.7\n    param['seed'] = seed_val\n    num_rounds = num_rounds\n\n    plst = list(param.items())\n\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=10)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n        \n    return model    \n    \n    \nmodel = XGB_regressor(train_X = train_x, train_y = y, test_X = train_cv, test_y = y_cv)\ny_test = model.predict(xgb.DMatrix(pd.DataFrame(train_f,columns=train_p.iloc[:,-1:].columns).reset_index()), ntree_limit = model.best_ntree_limit)\nprint(y_test)\n#sample['sales'] = y_test\n#sample.to_csv('simple_xgb_starter.csv', index=False)","bbad1d93":"# week arima\n\n* week effect disappears\n* differencing there is a year effect left over\n","55358d75":"# trend - autocorrelation\n\n* there is a upward trend\n* there is a 7day  week autocorrelation effect\n* Yearly effects\n** there is a summer peak  effect\n** there is a 'halloween season' \n","bd997262":"# differencing\n\ntrend disappears as expected\n7day week effect remains","61500b59":"# month\n* year cycle very visible\n* differencing 1 month makes everything right\n","5f9c6cb6":"# a forecast brute"}}