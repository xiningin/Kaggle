{"cell_type":{"0f0577f3":"code","c82f952e":"code","1612fb32":"code","76323bc1":"code","76016b7d":"code","9d972407":"code","cefe9066":"code","ae167926":"code","0b30be1c":"code","26e2d0ba":"code","2a59b42e":"code","56eeb95d":"code","3ed44e80":"code","f303a71d":"code","8e9a958f":"code","73708101":"code","cd60adff":"code","d357ec1f":"code","7abdc373":"code","bf2004e7":"code","ebf98a5d":"code","771b2fd6":"code","df851eef":"code","ed23279b":"code","e5b3a1be":"code","ab5b3239":"code","3f20f2e7":"code","aa064c5f":"code","3ef7adba":"code","77aeeee8":"code","054c0e75":"code","e9d1b822":"code","1457c9b1":"code","099a95d5":"code","77f9f2f4":"code","b8311005":"code","015428b7":"code","813c383c":"code","53dc6a4a":"code","e7630044":"code","93b6b0ae":"code","52fd02f7":"code","442f573d":"code","f61ecc0a":"code","665dee6f":"code","e5cf7e0d":"code","43faceaf":"code","099fcb98":"code","3077376b":"code","257087af":"code","77c69408":"code","955bf8da":"code","9c61cf89":"code","725d2591":"code","a1c18dbd":"code","a47178db":"code","39381051":"code","81b23cc4":"code","d68f4c13":"code","838a1340":"code","ad8f951e":"code","eff821c8":"code","0bd05249":"code","a67fda09":"markdown","f489561d":"markdown","384094f9":"markdown","00daf988":"markdown","df0ddf01":"markdown","8a601a27":"markdown","d2d65aa9":"markdown","046e5d79":"markdown","ed6a25d6":"markdown","b8e8fc15":"markdown","28c87a78":"markdown","9e828b6d":"markdown","759d23b5":"markdown","2062ef82":"markdown","209604b3":"markdown","4496efa0":"markdown","043cd7d4":"markdown","f9517495":"markdown","c73566e5":"markdown","4f495d99":"markdown","6191c3cf":"markdown","6db5dfdf":"markdown"},"source":{"0f0577f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c82f952e":"import category_encoders as encoders\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import model_selection, metrics, naive_bayes\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC ","1612fb32":"df_heart = pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')","76323bc1":"df_heart.info()","76016b7d":"df_heart.isnull().sum()","9d972407":"categorical = [var for var in df_heart.columns if df_heart[var].dtype=='O']\nnumerical = [var for var in df_heart.columns if df_heart[var].dtype != 'O' and (var != 'HeartDisease')]\n\nprint ('Size of the base {}'.format(df_heart.shape))\nprint ('Total No. of variables {}'.format (len(categorical) + len(numerical)))\nprint ('Total No. of categorical variables {}'.format (len(categorical)))\nprint ('Total No. of numberical variables {}'.format (len(numerical)))","cefe9066":"df_heart['HeartDisease'].value_counts()","ae167926":"df_heart[numerical].describe()","0b30be1c":"%matplotlib inline\nimport matplotlib.pyplot as plt\n# base.hist(bins=50, figsize=(20,15))\n\nfor col in numerical:\n    df_heart[df_heart[col]>0][col].plot.hist(bins=50, grid=True, legend=None)\n    plt.title(col)\n    plt.show()","26e2d0ba":"for col in numerical:\n    if col != 'FastingBS': # Skip this variable since it is skewed\n        p75 = df_heart[df_heart[col] > 0][col].quantile(0.75)\n        p25 = df_heart[df_heart[col] > 0][col].quantile(0.25)\n        iqr = p75 - p25\n        upper_limit = p75 + (1.5 * iqr)\n        print('===={} with Upper Limit {:6.1f}, P75 {:6.1f}, P25 {:6.1f}, {} Outlier Records ========'.format(col, upper_limit, p75, p25, df_heart[df_heart[col] > upper_limit]['HeartDisease'].count()))\n        df_heart[col] = np.where (df_heart[col] > upper_limit, upper_limit, df_heart[col])","2a59b42e":"scaler = StandardScaler()\nencoder_num = scaler.fit_transform(df_heart[numerical])\nencoded_num = pd.DataFrame(encoder_num, columns =[numerical])\nencoded_num.shape\nprint(encoded_num.head(10))\nscaler.mean_","56eeb95d":"for var in categorical: \n    print('Unique Count = {}'.format(df_heart[var].nunique()))\n    #print(df_heart[var].value_counts())\n    print(df_heart[var].value_counts() \/ np.float(len(df_heart)))\n    print('')","3ed44e80":"df_target = df_heart['HeartDisease']\ndf_target.columns = ['target']\nprint(df_target)","f303a71d":"CATBoostENCODE = encoders.CatBoostEncoder()\n\n#for col in categorical:\nencoder_cat = CATBoostENCODE.fit_transform(df_heart[categorical], df_target)\nencoded_cat = pd.DataFrame(encoder_cat)\n#encoding = pd.concat([encoding, encoded_cat], axis=1) \n#df.drop(columns=[col], axis = 1, inplace=True)","8e9a958f":"encoded_cat.info()","73708101":"df_heart[categorical].info()","cd60adff":"encoded_cat.head(10)","d357ec1f":"df_heart.info()","7abdc373":"df_train = df_heart.copy()\ndf_train.info()","bf2004e7":"df_train.drop(numerical, axis=1, inplace=True)\ndf_train.info()","ebf98a5d":"df_train.drop(categorical, axis=1, inplace=True)\ndf_train.info()","771b2fd6":"df_train = pd.concat([df_train, encoded_num, encoded_cat], axis=1) \ndf_train.head(10)","df851eef":"Y = df_train.iloc[:,0:1]\nX = df_train.iloc[:,1:]","ed23279b":"X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2)","e5b3a1be":"# parameter list\n#p_cor = 0.75\n#p_feature = 20\np_cv = 5\np_score = 'accuracy'\n#balanced_accuracy\n#recall\n#recall\n#roc_auc","ab5b3239":"reg_param_grid = {\n    'penalty': ['l1', 'l2'],\n    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n}","3f20f2e7":"print('Train X = {}, Train Y ={}'.format(X_train.shape, Y_train.shape))","aa064c5f":"# clf_1 = LogisticRegression(max_iter=10000, class_weight='balanced', penalty='l2', C=1.0, solver='lbfgs')\nclf_1 = LogisticRegression(max_iter=10000, C=0.1)\ncv = model_selection.StratifiedKFold(n_splits=p_cv, random_state=100, shuffle=True)\nmodel_1 = model_selection.GridSearchCV(clf_1, reg_param_grid, cv=cv, scoring=p_score, n_jobs=-1, verbose=1)\nmodel_1.fit(X_train, Y_train.values.ravel())\n","3ef7adba":"print(model_1.best_estimator_)\nprint(model_1.best_params_)","77aeeee8":"p_train_1 = model_1.predict(X_train)\np_test_1 = model_1.predict(X_test)","054c0e75":"predicted_test = pd.DataFrame(p_test_1)\npredicted_train = pd.DataFrame(p_train_1)\nprint('=============================================')\nprint('Scoring Metrics for Regression (Validation)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\n\nprint('=============================================')\nprint('Scoring Metrics for Regression (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(Y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_train, predicted_train)).plot()","e9d1b822":"estimators = [25,50,75,100]\n# Maximum number of depth in each tree:\nmax_depth = [5]\n# Minimum number of samples to consider to split a node:\nmin_samples_split = [20, 50, 75, 100, 150, 200]\n# Minimum number of samples to consider at each leaf node:\n# model_data = get_encoding(model_data, 1)\n# X = model_data.copy()\nmin_samples_leaf = [25, 50, 75, 100, 150, 200]## Decision Tree","1457c9b1":"clf_2 = DecisionTreeClassifier()\n\ntree_param_grid = { \n    'max_depth': max_depth,\n    'min_samples_split': min_samples_split,\n    'min_samples_leaf': min_samples_leaf\n}\n\ncv = model_selection.StratifiedKFold(n_splits=p_cv, random_state=100, shuffle=True)\n\nmodel_2 = model_selection.GridSearchCV(clf_2, tree_param_grid, cv=cv, scoring=p_score, n_jobs=-1, verbose=1)\nmodel_2.fit(X_train, Y_train)\n","099a95d5":"print(model_2.best_estimator_)\nprint(model_2.best_params_)","77f9f2f4":"p_train_2 = model_2.predict(X_train)\np_test_2 = model_2.predict(X_test)","b8311005":"predicted_test = pd.DataFrame(p_test_2)\npredicted_train = pd.DataFrame(p_train_2)\nprint('=============================================')\nprint('Scoring Metrics for Decision Tree (Validation)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\n\nprint('=============================================')\nprint('Scoring Metrics for Decision Tree (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(Y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_train, predicted_train)).plot()","015428b7":"n_neighbors = [5,10, 20, 30, 40, 50]\n# Number of neighbors to use by default for kneighbors queries\nweights = ['uniform', 'distance']\n# weight function used in prediction\np = [1,2]\n# Power parameter for the Minkowski metric","813c383c":"clf_3 = KNeighborsClassifier()\n\nknn_params_grid={'n_neighbors':n_neighbors,\n           'weights':weights,\n           'p':p}","53dc6a4a":"cv = model_selection.StratifiedKFold(n_splits=p_cv, random_state=100, shuffle=True)\n\nmodel_3 = model_selection.GridSearchCV(clf_3, knn_params_grid, cv=cv, scoring=p_score, n_jobs=-1, verbose=1)\nmodel_3.fit(X_train, Y_train.values.ravel())\n","e7630044":"print(model_3.best_estimator_)\nprint(model_3.best_params_)","93b6b0ae":"p_train_3 = model_3.predict(X_train)\np_test_3 = model_3.predict(X_test)","52fd02f7":"predicted_test = pd.DataFrame(p_test_3)\npredicted_train = pd.DataFrame(p_train_3)\nprint('=============================================')\nprint('Scoring Metrics for KNN')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_test, predicted_test)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\nprint('=============================================')\nprint('Scoring Metrics for KNN (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(Y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_train, predicted_train)).plot()","442f573d":"estimators = [25,50,75,100]\n# Maximum number of depth in each tree:\nmax_depth = [5]\n# Minimum number of samples to consider to split a node:\nmin_samples_split = [20, 50, 75, 100, 150, 200]\n# Minimum number of samples to consider at each leaf node:\nmin_samples_leaf = [25, 50, 75, 100, 150, 200]## Decision Tree","f61ecc0a":"clf_4 = RandomForestClassifier()\n\nforest_params_grid={'n_estimators':estimators,\n           'max_depth':max_depth,\n           'min_samples_split':min_samples_split,\n           'min_samples_leaf':min_samples_leaf  }","665dee6f":"cv = model_selection.StratifiedKFold(n_splits=p_cv, random_state=100, shuffle=True)\n\nmodel_4 = model_selection.GridSearchCV(clf_4, forest_params_grid, cv=cv, scoring=p_score, n_jobs=-1, verbose=1)\nmodel_4.fit(X_train, Y_train.values.ravel())\n","e5cf7e0d":"print(model_4.best_params_)\nprint(model_4.best_estimator_)","43faceaf":"p_train_4 = model_4.predict(X_train)\np_test_4 = model_4.predict(X_test)","099fcb98":"predicted_test = pd.DataFrame(p_test_4)\npredicted_train = pd.DataFrame(p_train_4)\nprint('=============================================')\nprint('Scoring Metrics for Random Forest (Validation)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\n\nprint('=============================================')\nprint('Scoring Metrics for Random Forest (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(Y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_train, predicted_train)).plot()","3077376b":"C = [0.1, 1.0, 10, 100]\ngamma = [0.1,0.01,0.001, 0.0001]\nkernel = ['linear','rbf']\n#kernel = ['linear','poly','rbf','sigmoid']\n","257087af":"clf_5 = SVC(probability=True)\n\nSVC_params_grid={'C':C,\n           'gamma':gamma,\n           'kernel':kernel}","77c69408":"cv = model_selection.StratifiedKFold(n_splits=p_cv, random_state=100, shuffle=True)\n\nmodel_5 = model_selection.GridSearchCV(clf_5, SVC_params_grid, cv=cv, scoring=p_score, n_jobs=-1, verbose=1)\nmodel_5.fit(X_train, Y_train.values.ravel())","955bf8da":"print(model_5.best_params_)\nprint(model_5.best_estimator_)","9c61cf89":"p_train_5 = model_5.predict(X_train)\np_test_5 = model_5.predict(X_test)","725d2591":"predicted_test = pd.DataFrame(p_test_5)\npredicted_train = pd.DataFrame(p_train_5)\nprint('=============================================')\nprint('Scoring Metrics for SVM (Validation)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\n\nprint('=============================================')\nprint('Scoring Metrics for SVM (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(Y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_train, predicted_train)).plot()","a1c18dbd":"ensemble_size = 100\nclf_6 = XGBClassifier(n_estimators=100, n_jobs=-1)\n","a47178db":"clf_6.fit(X_train, Y_train.values.ravel())","39381051":"p_train_6 = clf_6.predict(X_train)\np_test_6 = clf_6.predict(X_test)","81b23cc4":"predicted_test = pd.DataFrame(p_test_6)\npredicted_train = pd.DataFrame(p_train_6)\nprint('=============================================')\nprint('Scoring Metrics for SVM (Validation)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\n\nprint('=============================================')\nprint('Scoring Metrics for SVM (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(Y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_train, predicted_train)).plot()","d68f4c13":"# Instantiate the learners (classifiers)\nlearner_1 = LogisticRegression(C=0.1, max_iter=10000, penalty='l1', solver='liblinear')\nlearner_2 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=25, min_samples_split=150)\nlearner_3 = KNeighborsClassifier(n_neighbors=50, p=1, weights='distance')\nlearner_4 = RandomForestClassifier(max_depth=5, min_samples_leaf=200, min_samples_split=20, n_estimators=25)\nlearner_5 = XGBClassifier(n_estimators=100, n_jobs=-1)\nlearner_6 = naive_bayes.GaussianNB()\nlearner_7 = SVC(gamma=0.001, probability=True)","838a1340":"# Instantiate the voting classifier\nvoting = VotingClassifier([('LogReg', learner_1),\n                           ('Tree', learner_2),\n                           ('KNN', learner_3),\n                           ('Forest', learner_4),\n                          ('XGBoost', learner_5),\n                          ('NB', learner_6)],\n                            voting='hard')\n","ad8f951e":"voting.fit(X_train, Y_train)","eff821c8":"p_train_voting = voting.predict(X_train)\np_test_voting = voting.predict(X_test)","0bd05249":"predicted_test = pd.DataFrame(p_test_voting)\npredicted_train = pd.DataFrame(p_train_voting)\nprint('=============================================')\nprint('Scoring Metrics for Soft Voting (Validation)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_test, predicted_test)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_test, predicted_test)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_test, predicted_test)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_test, predicted_test, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_test, predicted_test, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_test, predicted_test))\nprint('==================')\nprint(metrics.classification_report(Y_test, predicted_test, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_test, predicted_test)).plot()\n\n\nprint('=============================================')\nprint('Scoring Metrics for Soft Voting (Training)')\nprint('=============================================')\nprint('Balanced Accuracy Score = {}'.format(metrics.balanced_accuracy_score(Y_train, predicted_train)))\nprint('Accuracy Score = {}'.format(metrics.accuracy_score(Y_train, predicted_train)))\nprint('Precision Score = {}'.format(metrics.precision_score(Y_train, predicted_train)))\nprint('F1 Score = {}'.format(metrics.f1_score(Y_train, predicted_train)))\nprint('Recall Score = {}'.format(metrics.recall_score(Y_train, predicted_train, labels=['0','1'])))\nprint('ROC AUC Score = {}'.format(metrics.roc_auc_score(Y_train, predicted_train, labels=['0','1'])))\nprint('Confusion Matrix')\nprint('==================')\nprint(metrics.confusion_matrix(Y_train, predicted_train))\nprint('==================')\nprint(metrics.classification_report(Y_train, predicted_train, target_names=['0','1']))\nmetrics.ConfusionMatrixDisplay(metrics.confusion_matrix(Y_train, predicted_train)).plot()","a67fda09":"## Data Encoding and Standardization","f489561d":"### standardize the numerical variables","384094f9":"### Encoding for categorical variables","00daf988":"## Model 1 - Regression","df0ddf01":"### Check missing value","8a601a27":"### what is the distribution for the target","d2d65aa9":"### Study for numerical variables","046e5d79":"## Model 2 - Decision Tree","ed6a25d6":"## Exploratory Data Analysis","b8e8fc15":"This notebook uses ensemble technique of Voting to predict heart failure.  Various base models are built, and then followed by ensemble of Voting to combine the predictiion of these base models. \n\n## Summary\n\n* Check if there are any null values in the features\n* Handle the outliers for numerical variables by IRQ\n* Standardize the distribution of numerical variables by StandardScaler\n* Encode categorical variables by CatBoostEncoder\n* Perform the following Base Models\n    1 Regression \n    2 Decision Tree    \n    3 KNN\n    4 Random Forest\n    5 SVM\n    6 XGBoost\n* Apply the Soft Voting ensemble classifier in Scikit-learn to combine the prediction of the Base Models. \n* List out the performance metrics of Accuracy, Precision, F1, Recall, ROC AUC and Confusion Matrix","28c87a78":"## Model 3 - KNN","9e828b6d":"<div style=\"color:#D81F26;\n           display:fill;\n           border-style: solid;\n           border-color:#C1C1C1;\n           font-size:14px;\n           font-family:Calibri;\n           background-color:#373737;\">\n<h2 style=\"text-align: center;\n           padding: 10px;\n           color:#FFFFFF;\">\n======= Heart Failure Prediction =======\n<\/h2>\n<\/div>","759d23b5":"# About this notebook","2062ef82":"## Model 4 - Random Forest","209604b3":"### Separate the data into categorical and numerical","4496efa0":"## Model 5 - SVM Classifer","043cd7d4":"### Cap the outliers of numerical variables by IRQ","f9517495":"### Distribution of the numerical variables after the outlier replacement","c73566e5":"### Prepare the training data","4f495d99":"## Model 6 - XGBoost","6191c3cf":"## Model 6 - Voting Ensemble","6db5dfdf":"### Additional packages"}}