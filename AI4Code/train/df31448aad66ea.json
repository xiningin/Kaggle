{"cell_type":{"625bedeb":"code","c50a4561":"code","176e709e":"code","6e234544":"code","9e0282b9":"code","78e3898f":"code","e86b7531":"code","d41593ea":"code","9fc17dd5":"code","8425cf7f":"code","366ee346":"code","b1b4d7fb":"code","c8aa6993":"code","432c9d31":"code","111ea3d5":"code","b4b585ce":"code","991d4879":"code","607aa566":"code","eafab8a6":"code","0d4c27f7":"code","38c2c5be":"code","96cae668":"markdown","90af7bb1":"markdown","6e77cc30":"markdown"},"source":{"625bedeb":"%matplotlib inline\nimport cv2\nimport numpy as np\nimport pydicom as dicom\nimport json\nimport os\nimport shutil\nimport sys\nimport random\nfrom matplotlib import image\nimport matplotlib.pyplot as plt\nimport re\nfrom skimage.util.montage import montage2d\nmontage3d = lambda x, **k: montage2d(np.stack([montage2d(y, **k) for y in x],0))","c50a4561":"# number of bins to use in histogram for gaussian regression\nNUM_BINS = 100\n# number of standard deviatons past which we will consider a pixel an outlier\nSTD_MULTIPLIER = 2\n# number of points of our interpolated dataset to consider when searching for\n# a threshold value; the function by default is interpolated over 1000 points,\n# so 250 will look at the half of the points that is centered around the known\n# myocardium pixel\nTHRESHOLD_AREA = 250\n# number of pixels on the line within which to search for a connected component\n# in a thresholded image, increase this to look for components further away\nCOMPONENT_INDEX_TOLERANCE = 20\n# number of angles to search when looking for the correct orientation\nANGLE_SLICES = 36\nALL_DATA_DIR =  os.path.join('..', 'input', 'train', 'train')\nX_DIM, Y_DIM = 64, 64\nX_DIM, Y_DIM = 128, 128\nT_DIM = 30","176e709e":"class Dataset(object):\n    dataset_count = 0\n\n    def __init__(self, directory, subdir):\n        # deal with any intervening directories\n        while True:\n            subdirs = next(os.walk(directory))[1]\n            if len(subdirs) == 1:\n                directory = os.path.join(directory, subdirs[0])\n            else:\n                break\n\n        slices = []\n        for s in subdirs:\n            m = re.match(\"sax_(\\d+)\", s)\n            if m is not None:\n                slices.append(int(m.group(1)))\n\n        slices_map = {}\n        first = True\n        times = []\n        for s in slices:\n            files = next(os.walk(os.path.join(directory, \"sax_%d\" % s)))[2]\n            offset = None\n\n            for f in files:\n                m = re.match(\"IM-(\\d{4,})-(\\d{4})\\.dcm\", f)\n                if m is not None:\n                    if first:\n                        times.append(int(m.group(2)))\n                    if offset is None:\n                        offset = int(m.group(1))\n\n            first = False\n            slices_map[s] = offset\n\n        self.directory = directory\n        self.time = sorted(times)\n        self.slices = sorted(slices)\n        self.slices_map = slices_map\n        self.name = subdir\n\n    def _filename(self, s, t):\n        return os.path.join(self.directory,\"sax_%d\" % s, \"IM-%04d-%04d.dcm\" % (self.slices_map[s], t))\n\n    def _read_dicom_image(self, filename):\n        d = dicom.read_file(filename)\n        img = d.pixel_array\n        return np.array(img)\n\n    def _read_all_dicom_images(self):\n        f1 = self._filename(self.slices[0], self.time[0])\n        d1 = dicom.read_file(f1)\n        (x, y) = d1.PixelSpacing\n        (x, y) = (float(x), float(y))\n        f2 = self._filename(self.slices[1], self.time[0])\n        d2 = dicom.read_file(f2)\n\n        # try a couple of things to measure distance between slices\n        try:\n            dist = np.abs(d2.SliceLocation - d1.SliceLocation)\n        except AttributeError:\n            try:\n                dist = d1.SliceThickness\n            except AttributeError:\n                dist = 8  # better than nothing...\n\n        self.images = np.array([[self._read_dicom_image(self._filename(d, i))\n                                 for i in self.time]\n                                for d in self.slices])\n        self.dist = dist\n        self.area_multiplier = x * y\n\n    def load(self):\n        self._read_all_dicom_images()","6e234544":"base_path = os.path.join(ALL_DATA_DIR, '140')\ntData = Dataset(base_path,'140')\ntData.load()","9e0282b9":"%matplotlib inline\nplt.imshow(tData.images[0,0,:,:], cmap = 'bone')","78e3898f":"fig, ax1 = plt.subplots(1,1, figsize = (20,20))\nax1.imshow(montage3d(tData.images), cmap = 'bone')","e86b7531":"from scipy.ndimage import zoom\nrezoom = lambda in_data: zoom(in_data.images, [1, \n                                               T_DIM\/in_data.images.shape[1], \n                                               X_DIM\/in_data.images.shape[2], \n                                               Y_DIM\/in_data.images.shape[3]])\nimage_stack = rezoom(tData)\nprint(image_stack.shape)","d41593ea":"fig, ax1 = plt.subplots(1,1, figsize = (20,20))\nax1.imshow(montage3d(image_stack), cmap = 'bone')","9fc17dd5":"from glob import glob\nbase_path = os.path.join(ALL_DATA_DIR, '*')\nall_series = glob(base_path)\nfrom warnings import warn\ndef read_and_process(in_path):\n    try:\n        cur_data = Dataset(in_path,\n                           os.path.basename(in_path))\n        cur_data.load()\n        if cur_data.time is not None:\n            zoom_time = zoom(cur_data.time, [T_DIM\/len(cur_data.time)])\n        else:\n            zoom_time = range(T_DIM)\n        return [in_path, zoom_time, cur_data.area_multiplier, rezoom(cur_data)]\n    except Exception as e:\n        warn('{}'.format(e), RuntimeWarning)\n        return None","8425cf7f":"%%time\na,d,b,c = read_and_process(all_series[-100])\nprint(c.shape)","366ee346":"import dask\nimport dask.diagnostics as diag\nfrom bokeh.io import output_notebook\nfrom bokeh.resources import CDN\nfrom dask import bag as dbag\nfrom multiprocessing.pool import ThreadPool","b1b4d7fb":"np.random.seed(2018)\npath_bag = dbag.from_sequence(np.random.choice(all_series, 170))\nimage_bag = path_bag.map(read_and_process)","c8aa6993":"with diag.ProgressBar(), diag.Profiler() as prof, diag.ResourceProfiler(0.5) as rprof, dask.set_options(pool = ThreadPool(4)):\n    all_img_data = image_bag.compute()","432c9d31":"output_notebook(CDN, hide_banner=True)\ndiag.visualize([prof, rprof])","111ea3d5":"im_stack = np.concatenate([x[-1] for x in all_img_data if x is not None],0)\nprint(im_stack.shape)","b4b585ce":"am_stack = np.concatenate([ [x[2]]*x[-1].shape[0] for x in all_img_data if x is not None],0)\nprint(am_stack.shape)","991d4879":"path_stack = np.concatenate([ [os.path.basename(x[0])]*x[-1].shape[0] for x in all_img_data if x is not None],0)\nprint(path_stack.shape)","607aa566":"time_stack = np.concatenate([ [x[1]]*x[-1].shape[0] for x in all_img_data if x is not None],0)\nprint(time_stack.shape)","eafab8a6":"import pandas as pd\ntrain_targets = {int(k['Id']): k for k in pd.read_csv('..\/input\/train.csv').T.to_dict().values()}","0d4c27f7":"import h5py\nwith h5py.File('train_mri_{}_{}.h5'.format(X_DIM, Y_DIM), 'w') as w:\n    w.create_dataset('image', data = im_stack, compression = 9)\n    w.create_dataset('systole', data = [train_targets[int(c_id)]['Systole'] for c_id in path_stack])\n    w.create_dataset('diastole', data = [train_targets[int(c_id)]['Diastole'] for c_id in path_stack])\n    w.create_dataset('id', data = [int(c_id) for c_id in path_stack])\n    w.create_dataset('area_multiplier', data = am_stack)\n    w.create_dataset('time', data = time_stack)","38c2c5be":"!ls -lh *","96cae668":"# Overview\nA simple notebook to read in a few example datasets and package the rest of the datasets together for making training models easier (HDF5 instead of dicom mess). \n\nThe code uses code borrows heavily from the tutorial provided by Booz (https:\/\/github.com\/booz-allen-hamilton\/DSB2) in order to preprocess the data. You can make new kernels by having this dataset as a starting point","90af7bb1":"# Final Processing\nHere we randomly select half of the patients for further processing (since @Kaggle only lets us output 1GB or so of data)","6e77cc30":"# Load a test patient\nHere we load patient 140 as an example"}}