{"cell_type":{"b27f2a70":"code","e19033d0":"code","bb853b15":"code","96e596f6":"code","ecb26bf4":"code","4e018dd4":"code","342419be":"code","70e37265":"code","080f0159":"code","bcfa4383":"code","e647748c":"code","d629026b":"code","245d2d7b":"code","1ed38f0a":"code","313099f9":"code","ea712ac8":"code","22fa86ef":"code","74a7210f":"code","b603f1a2":"code","eb9156e9":"code","c1f008c4":"code","b584816d":"code","dad56a0e":"code","fa1ceb7a":"code","ab31a92e":"code","f334760e":"code","49b7261d":"markdown","92f333c3":"markdown","5212cf59":"markdown","b08810ae":"markdown","d12a11a8":"markdown","5222a5d2":"markdown","4ed8c41a":"markdown","e072057c":"markdown","187bfee1":"markdown","3ccb93c6":"markdown","0f7a312c":"markdown","44dfdf56":"markdown","2d3725fd":"markdown","07c0480e":"markdown","41b2f610":"markdown","8d7e18c3":"markdown"},"source":{"b27f2a70":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom  sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans","e19033d0":"data=pd.read_csv(\"..\/input\/mall-customer\/Mall_Customers (1).csv\")\ndata","bb853b15":"data.describe()","96e596f6":"data.isna().sum()","ecb26bf4":"KMean_data=data.iloc[:,3:]\nKMean_data","4e018dd4":"KMean_data.columns","342419be":"KMean_data.plot(kind=\"scatter\", x='Annual Income (k$)',   y='Spending Score (1-100)')\nplt.show()","70e37265":"k_range=range(1,10)\nsse=[]\nfor k in k_range:\n    km=KMeans(n_clusters=k)\n    km.fit(KMean_data[['Annual Income (k$)','Spending Score (1-100)']])\n    sse.append(km.inertia_)","080f0159":"plt.plot(k_range,sse)","bcfa4383":"model=KMeans(n_clusters=5)\nKMean_pred=model.fit_predict(KMean_data[['Annual Income (k$)','Spending Score (1-100)']])\nKMean_pred","e647748c":"KMean_data['cluster']=KMean_pred\nKMean_data","d629026b":"df1=KMean_data[KMean_data['cluster']==0]\ndf2=KMean_data[KMean_data['cluster']==1]\ndf3=KMean_data[KMean_data['cluster']==2]\ndf4=KMean_data[KMean_data['cluster']==3]\ndf5=KMean_data[KMean_data['cluster']==4]\n\n\nplt.scatter(df1['Annual Income (k$)'],df1['Spending Score (1-100)'],color='r')\nplt.scatter(df2['Annual Income (k$)'],df2['Spending Score (1-100)'],color='g')\nplt.scatter(df3['Annual Income (k$)'],df3['Spending Score (1-100)'],color='b')\nplt.scatter(df4['Annual Income (k$)'],df4['Spending Score (1-100)'],color='c')\nplt.scatter(df5['Annual Income (k$)'],df5['Spending Score (1-100)'],color='m')\n","245d2d7b":"import matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline\nimport numpy as np","1ed38f0a":"data","313099f9":"Hierarchial_Data = data.iloc[:, 3:5].values","ea712ac8":"Hierarchial_Data","22fa86ef":"import scipy.cluster.hierarchy as shc\n\nplt.figure(figsize=(10, 7))\nplt.title(\"Customer Dendograms\")\ndend = shc.dendrogram(shc.linkage(Hierarchial_Data, method='ward'))","74a7210f":"from sklearn.cluster import AgglomerativeClustering\n\nHierarchial_cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\nHierarchial_cluster.fit_predict(Hierarchial_Data)","b603f1a2":"plt.figure(figsize=(10, 7))\nplt.scatter(Hierarchial_Data[:,0], Hierarchial_Data[:,1], c=Hierarchial_cluster.labels_, cmap='rainbow')","eb9156e9":"from scipy import stats\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import normalize\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.datasets import load_iris","c1f008c4":"# Load Dataset\niris = load_iris()","b584816d":"iris","dad56a0e":"#Model Declaration\ndbscan = DBSCAN(eps=0.5, metric='euclidean', min_samples=5)","fa1ceb7a":"# Fit Model\ndbscan.fit(iris.data)","ab31a92e":"# Transoring Using PCA\npca = PCA(n_components=2).fit(iris.data)\npca_2d = pca.transform(iris.data)","f334760e":"# Plot based on Class\nfor i in range(0, pca_2d.shape[0]):\n    if dbscan.labels_[i] == 0:\n        c1 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='r', marker='+')\n    elif dbscan.labels_[i] == 1:\n        c2 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='g', marker='o')\n    elif dbscan.labels_[i] == -1:\n        c3 = plt.scatter(pca_2d[i, 0], pca_2d[i, 1], c='b', marker='*')\n\nplt.legend([c1, c2, c3], ['Cluster 1', 'Cluster 2', 'Noise'])\nplt.title('DBSCAN finds 2 clusters and Noise')\nplt.show()","49b7261d":"### We'll use same Data which we used for K-Means Clustering","92f333c3":"K-means is a centroid-based algorithm, or a distance-based algorithm, where we calculate the distances to assign a point to a cluster. In K-Means, each cluster is associated with a centroid.","5212cf59":"### DB-Scan Implementation","b08810ae":"# ","d12a11a8":"DBSCAN Clustering (where DBSCAN is short for Density-Based Spatial Clustering of Applications with Noise) involves finding high-density areas in the domain and expanding those areas of the feature space around them as clusters.","5222a5d2":"### Hierarchial Clustering Implementation","4ed8c41a":"# 3) DB-Scan Algorithm","e072057c":"### Dendogram for Hierarchial Clustering ","187bfee1":"# 2) Hierarchial Clustering","3ccb93c6":"## Comparison between Algorithms K-Means vs Hierarchial Clustering vs DBScan Algorithm","0f7a312c":"### Visualization for DB-Scan","44dfdf56":"# 1) K-Means Clustering","2d3725fd":"Hierarchical clustering, also known as hierarchical cluster analysis, is an algorithm that groups similar objects into groups called clusters. The endpoint is a set of clusters, where each cluster is distinct from each other cluster, and the objects within each cluster are broadly similar to each other.","07c0480e":"#### Import Required Libraries for DB-Scan Algorithm","41b2f610":"### Visualization of Clusters","8d7e18c3":"### Here also we will use different Data which will be of Iris (This time load with sklearn.datasets) "}}