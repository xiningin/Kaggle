{"cell_type":{"23faf7f6":"code","2f13c588":"code","00f8ae16":"code","dc3ace50":"code","a621e74c":"code","6b908608":"code","2398009a":"code","b77c423b":"code","267efd6e":"code","19f0ac9c":"code","e9210060":"code","36a9959c":"code","3a967650":"code","acb717ea":"code","8765cf02":"code","140abe48":"code","2d423d51":"code","be62b536":"code","668862c2":"code","e2ef7a50":"code","ab368a00":"code","023eb2ed":"code","47cca32f":"markdown","f321a0c6":"markdown","d89fbd9c":"markdown","f7280236":"markdown","83a631ef":"markdown","7e507429":"markdown","ff887dab":"markdown","3aecfab5":"markdown","a464139a":"markdown","ff0f9f17":"markdown","f34ac979":"markdown","8021fb20":"markdown","ab2386de":"markdown","16d0382b":"markdown","03bed515":"markdown","cd1d6388":"markdown","7b02a9ad":"markdown","e9a8fb83":"markdown"},"source":{"23faf7f6":"# Link for the script https:\/\/www.kaggle.com\/dimitreoliveira\/cloud-images-segmentation-utillity-script\nfrom cloud_images_segmentation_utillity_script import *\nfrom keras.models import load_model\n\n!pip install tta-wrapper --quiet\n\nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings(\"ignore\")","2f13c588":"train = pd.read_csv('..\/input\/understanding_cloud_organization\/train.csv')\nsubmission = pd.read_csv('..\/input\/understanding_cloud_organization\/sample_submission.csv')\n\n# Preprocecss data\ntrain['image'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\ntrain['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\nsubmission['image'] = submission['Image_Label'].apply(lambda x: x.split('_')[0])\ntest = pd.DataFrame(submission['image'].unique(), columns=['image'])\n\n# Create one column for each mask\ntrain_df = pd.pivot_table(train, index=['image'], values=['EncodedPixels'], columns=['label'], aggfunc=np.min).reset_index()\ntrain_df.columns = ['image', 'Fish_mask', 'Flower_mask', 'Gravel_mask', 'Sugar_mask']\n\nprint('Compete set samples:', len(train_df))\nprint('Test samples:', len(submission))\n\ndisplay(train.head())","00f8ae16":"X_train, X_val = train_test_split(train_df, test_size=0.2, random_state=seed)\nX_train['set'] = 'train'\nX_val['set'] = 'validation'\ntest['set'] = 'test'\n\nprint('Train samples: ', len(X_train))\nprint('Validation samples: ', len(X_val))","dc3ace50":"BACKBONE = 'resnet18'\nBATCH_SIZE = 32\nEPOCHS = 12\nLEARNING_RATE = 3e-4\nHEIGHT = 384\nWIDTH = 480\nCHANNELS = 3\nN_CLASSES = 4\nES_PATIENCE = 5\nRLROP_PATIENCE = 3\nDECAY_DROP = 0.5\nmodel_path = 'uNet_%s_%sx%s.h5' % (BACKBONE, HEIGHT, WIDTH)","a621e74c":"preprocessing = sm.get_preprocessing(BACKBONE)\n\naugmentation = albu.Compose([albu.HorizontalFlip(p=0.5),\n                             albu.VerticalFlip(p=0.5),\n                             albu.ShiftScaleRotate(rotate_limit=30, shift_limit=0.1, p=0.5)\n                            ])","6b908608":"train_base_path = '..\/input\/understanding_cloud_organization\/train_images\/'\ntest_base_path = '..\/input\/understanding_cloud_organization\/test_images\/'\ntrain_images_dest_path = 'base_dir\/train_images\/'\nvalidation_images_dest_path = 'base_dir\/validation_images\/'\ntest_images_dest_path = 'base_dir\/test_images\/'\n\n# Making sure directories don't exist\nif os.path.exists(train_images_dest_path):\n    shutil.rmtree(train_images_dest_path)\nif os.path.exists(validation_images_dest_path):\n    shutil.rmtree(validation_images_dest_path)\nif os.path.exists(test_images_dest_path):\n    shutil.rmtree(test_images_dest_path)\n    \n# Creating train, validation and test directories\nos.makedirs(train_images_dest_path)\nos.makedirs(validation_images_dest_path)\nos.makedirs(test_images_dest_path)\n\ndef preprocess_data(df, HEIGHT=HEIGHT, WIDTH=WIDTH):\n    '''\n    This function needs to be defined here, because it will be called with no arguments, \n    and must have the default parameters from the beggining of the notebook (HEIGHT and WIDTH)\n    '''\n    df = df.reset_index()\n    for i in range(df.shape[0]):\n        item = df.iloc[i]\n        image_id = item['image']\n        item_set = item['set']\n        if item_set == 'train':\n            preprocess_image(image_id, train_base_path, train_images_dest_path, HEIGHT, WIDTH)\n        if item_set == 'validation':\n            preprocess_image(image_id, train_base_path, validation_images_dest_path, HEIGHT, WIDTH)\n        if item_set == 'test':\n            preprocess_image(image_id, test_base_path, test_images_dest_path, HEIGHT, WIDTH)\n\n# Pre-procecss train set\npre_process_set(X_train, preprocess_data)\n\n# Pre-procecss validation set\npre_process_set(X_val, preprocess_data)\n\n# Pre-procecss test set\npre_process_set(test, preprocess_data)","2398009a":"train_generator = DataGenerator(\n                  directory=train_images_dest_path,\n                  dataframe=X_train,\n                  target_df=train,\n                  batch_size=BATCH_SIZE,\n                  target_size=(HEIGHT, WIDTH),\n                  n_channels=CHANNELS,\n                  n_classes=N_CLASSES,\n                  preprocessing=preprocessing,\n                  augmentation=augmentation,\n                  seed=seed)\n\nvalid_generator = DataGenerator(\n                  directory=validation_images_dest_path,\n                  dataframe=X_val,\n                  target_df=train,\n                  batch_size=BATCH_SIZE, \n                  target_size=(HEIGHT, WIDTH),\n                  n_channels=CHANNELS,\n                  n_classes=N_CLASSES,\n                  preprocessing=preprocessing,\n                  seed=seed)","b77c423b":"model = sm.Unet(backbone_name=BACKBONE, \n                encoder_weights='imagenet',\n                classes=N_CLASSES,\n                activation='sigmoid',\n                input_shape=(HEIGHT, WIDTH, CHANNELS))\n\ncheckpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, save_weights_only=True)\nes = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\nrlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n\nmetric_list = [dice_coef, sm.metrics.iou_score]\ncallback_list = [checkpoint, es, rlrop]\noptimizer = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)\n\nmodel.compile(optimizer=optimizer, loss=sm.losses.bce_dice_loss, metrics=metric_list)\nmodel.summary()","267efd6e":"STEP_SIZE_TRAIN = len(X_train)\/\/BATCH_SIZE\nSTEP_SIZE_VALID = len(X_val)\/\/BATCH_SIZE\n\nhistory = model.fit_generator(generator=train_generator,\n                              steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator,\n                              validation_steps=STEP_SIZE_VALID,\n                              callbacks=callback_list,\n                              epochs=EPOCHS,\n                              verbose=2).history","19f0ac9c":"plot_metrics(history, metric_list=['loss', 'dice_coef', 'iou_score'])","e9210060":"# Load model trained longer\nmodel = load_model('..\/input\/cloud-seg-resnet18-trainedlonger\/resnet18_trained_longer.h5', custom_objects={'RAdam':RAdam, 'binary_crossentropy_plus_dice_loss':sm.losses.bce_dice_loss, 'dice_coef':dice_coef, 'iou_score':sm.metrics.iou_score, 'f1-score':sm.metrics.f1_score})","36a9959c":"class_names = ['Fish  ', 'Flower', 'Gravel', 'Sugar ']\nbest_tresholds = [.5, .5, .5, .35]\nbest_masks = [25000, 20000, 22500, 15000]\n\nfor index, name in enumerate(class_names):\n    print('%s treshold=%.2f mask size=%d' % (name, best_tresholds[index], best_masks[index]))","3a967650":"train_metrics = get_metrics(model, train, X_train, train_images_dest_path, best_tresholds, best_masks, seed=seed, preprocessing=preprocessing, set_name='Train')\ndisplay(train_metrics)\n\nvalidation_metrics = get_metrics(model, train, X_val, validation_images_dest_path, best_tresholds, best_masks, seed=seed, preprocessing=preprocessing, set_name='Validation')\ndisplay(validation_metrics)","acb717ea":"from tta_wrapper import tta_segmentation\n\nmodel = tta_segmentation(model, h_flip=True, v_flip=True, h_shift=(-10, 10), v_shift=(-10, 10), merge='mean')","8765cf02":"test_df = []\n\nfor i in range(0, test.shape[0], 300):\n    batch_idx = list(range(i, min(test.shape[0], i + 300)))\n    batch_set = test[batch_idx[0]: batch_idx[-1]+1]\n    \n    test_generator = DataGenerator(\n                      directory=test_images_dest_path,\n                      dataframe=batch_set,\n                      target_df=submission,\n                      batch_size=1, \n                      target_size=(HEIGHT, WIDTH),\n                      n_channels=CHANNELS,\n                      n_classes=N_CLASSES,\n                      preprocessing=preprocessing,\n                      seed=seed,\n                      mode='predict',\n                      shuffle=False)\n    \n    preds = model.predict_generator(test_generator)\n\n    for index, b in enumerate(batch_idx):\n        filename = test['image'].iloc[b]\n        image_df = submission[submission['image'] == filename].copy()\n        pred_masks = preds[index, ].round().astype(int)\n        pred_rles = build_rles(pred_masks, reshape=(350, 525))\n        image_df['EncodedPixels'] = pred_rles\n\n        ### Post procecssing\n        pred_masks_post = preds[index, ].astype('float32') \n        for class_index in range(N_CLASSES):\n            pred_mask = pred_masks_post[...,class_index]\n            pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])\n            pred_masks_post[...,class_index] = pred_mask\n\n        pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))\n        image_df['EncodedPixels_post'] = pred_rles_post\n        ###\n        \n        test_df.append(image_df)\n\nsub_df = pd.concat(test_df)","140abe48":"# Choose 3 samples at random\nimages_to_inspect = np.random.choice(X_val['image'].unique(), 3, replace=False)\ninspect_set = train[train['image'].isin(images_to_inspect)].copy()\ninspect_set_temp = []\n\ninspect_generator = DataGenerator(\n                    directory=validation_images_dest_path,\n                    dataframe=inspect_set,\n                    target_df=train,\n                    batch_size=1, \n                    target_size=(HEIGHT, WIDTH),\n                    n_channels=CHANNELS,\n                    n_classes=N_CLASSES,\n                    preprocessing=preprocessing,\n                    seed=seed,\n                    mode='fit',\n                    shuffle=False)\n\npreds = model.predict_generator(inspect_generator)\n\nfor index, b in enumerate(range(len(preds))):\n    filename = inspect_set['image'].iloc[b]\n    image_df = inspect_set[inspect_set['image'] == filename].copy()\n    pred_masks = preds[index, ].round().astype(int)\n    pred_rles = build_rles(pred_masks, reshape=(350, 525))\n    image_df['EncodedPixels_pred'] = pred_rles\n    \n    ### Post procecssing\n    pred_masks_post = preds[index, ].astype('float32') \n    for class_index in range(N_CLASSES):\n        pred_mask = pred_masks_post[...,class_index]\n        pred_mask = post_process(pred_mask, threshold=best_tresholds[class_index], min_size=best_masks[class_index])\n        pred_masks_post[...,class_index] = pred_mask\n\n    pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))\n    image_df['EncodedPixels_pred_post'] = pred_rles_post\n    ###\n    inspect_set_temp.append(image_df)\n\n\ninspect_set = pd.concat(inspect_set_temp)\ninspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred')","2d423d51":"inspect_predictions(inspect_set, images_to_inspect, validation_images_dest_path, pred_col='EncodedPixels_pred_post')","be62b536":"# Choose 5 samples at random\nimages_to_inspect_test =  np.random.choice(sub_df['image'].unique(), 4, replace=False)\ninspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path)","668862c2":"inspect_predictions(sub_df, images_to_inspect_test, test_images_dest_path, label_col='EncodedPixels_post')","e2ef7a50":"submission_df = sub_df[['Image_Label' ,'EncodedPixels']]\nsubmission_df.to_csv('submission.csv', index=False)\ndisplay(submission_df.head())","ab368a00":"submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]\nsubmission_df_post.columns = ['Image_Label' ,'EncodedPixels']\nsubmission_df_post.to_csv('submission_post.csv', index=False)\ndisplay(submission_df_post.head())","023eb2ed":"# Cleaning created directories\nif os.path.exists(train_images_dest_path):\n    shutil.rmtree(train_images_dest_path)\nif os.path.exists(validation_images_dest_path):\n    shutil.rmtree(validation_images_dest_path)\nif os.path.exists(test_images_dest_path):\n    shutil.rmtree(test_images_dest_path)","47cca32f":"## With post-process","f321a0c6":"# Data generator","d89fbd9c":"## Train and validation split","f7280236":"## Model loss graph","83a631ef":"### Submission with post processing","7e507429":"# Threshold and mask size tunning\n - Here we could use some kind of parameter search, but to simplify I'm using default values","ff887dab":"# Model parameters","3aecfab5":"# Pre-process data","a464139a":"# Inspecting some of the validation set predictions\n\n## Without post-processing","ff0f9f17":"<center><img src=\"https:\/\/raw.githubusercontent.com\/dimitreOliveira\/MachineLearning\/master\/Kaggle\/Understanding%20Clouds%20from%20Satellite%20Images\/banner.png\" width=\"800\"><\/center>\n<h1><center>Understanding Clouds from Satellite Images<\/center><\/h1><p><\/p>\n<h2><center>Cloud Segmentation with utility scripts and Keras<\/center><\/h2>\n\n#### This kernel is to show the new feature on Kaggle, script notebooks. I'm not doing EDA here because I already did it on [my other kernel](https:\/\/www.kaggle.com\/dimitreoliveira\/understanding-clouds-eda-and-keras-u-net), the goal here is just to demonstrate how to use script notebook and how it can improve our work, making it faster and cleaner.\n#### I found this addition really cool as I always try to write clean and modular code, it always saves time later, this may be another push towards better software practices on data science projects.\n\nWhat you will find on the [script I made](https:\/\/www.kaggle.com\/dimitreoliveira\/cloud-images-segmentation-utillity-script):\n- All used dependencies\n- External repository codes (need internet option ON)\n- Seed function (to make model runs more reproducible)\n- Segmentation functions related to this competition\n- Multi-thread data process functions (to resize and apply transformations faster)\n- Model evaluation (training plots)\n- Model post-process (Set threshold and removing small masks)\n- Prediction evaluation (Generate metrics over predictions and sample evaluation)\n- Data generator\n- Learning rate schedulers\n\n##### If you have any request to update or add anything to the scripts please let me know in the comments.","f34ac979":"### Load data","8021fb20":"# Inspecting some of the test set predictions\n\n## Without post-process","ab2386de":"# Model evaluation","16d0382b":"## With post-processing","03bed515":"### Dependencies","cd1d6388":"# Model","7b02a9ad":"# Apply model to test set","e9a8fb83":"### Regular submission"}}