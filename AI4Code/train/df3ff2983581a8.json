{"cell_type":{"3d759c77":"code","0f634f7b":"code","a70a4398":"code","08086367":"code","fd16af06":"code","075d2c4f":"code","2d024687":"code","72f381d1":"code","e9eafab0":"code","0ffae450":"code","0a06bb7f":"code","fd9ad93a":"code","d9c9568d":"code","bfcb38bc":"code","280d7c82":"code","9acfb062":"code","8bb00099":"markdown","4e5c4ca2":"markdown","8c34ecb0":"markdown","833b3cc3":"markdown","93e53e7f":"markdown"},"source":{"3d759c77":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0f634f7b":"import os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2","a70a4398":"os.listdir('..\/input\/face-image-naim\/')","08086367":"#Code By Yaroslav Isaienkov https:\/\/www.kaggle.com\/ihelon\/google-landmark-retrieval-2020-eda\n\ndef create_full_path(name):\n    return os.path.join(\n        '..\/input\/face-image-naim\/',\n        name[0],\n        name[1],\n        name[2],\n        f'{name}.jpg'\n    )","fd16af06":"import torch\nimport fastai\nfrom fastai.tabular.all import *\nfrom fastai.text.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nfrom fastai import *\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)","075d2c4f":"from PIL import Image\n\nimg = Image.open(\"..\/input\/face-image-naim\/72940860_689361331560921_3037130318856323072_o.jpg\")\nimg","2d024687":"#Code by Yaroslav Isaienkov https:\/\/www.kaggle.com\/ihelon\/monet-eda-and-visualization-techniques\n\ndef visualize_images(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    w = int(n_images ** .5)\n    h = math.ceil(n_images \/ w)\n    \n    all_names = os.listdir(path)\n    image_names = all_names[:n_images]   \n    if is_random:\n        image_names = random.sample(all_names, n_images)\n            \n    for ind, image_name in enumerate(image_names):\n        img = cv2.imread(os.path.join(path, image_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        plt.subplot(h, w, ind + 1)\n        plt.imshow(img)\n        plt.xticks([])\n        plt.yticks([])\n    \n    plt.show()","72f381d1":"#Code by Yaroslav Isaienkov https:\/\/www.kaggle.com\/ihelon\/monet-eda-and-visualization-techniques\n\ndef batch_visualization(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    \n    w = int(n_images ** .5)\n    h = math.ceil(n_images \/ w)\n    \n    all_names = os.listdir(path)\n    \n    image_names = all_names[:n_images]\n    if is_random:\n        image_names = random.sample(all_names, n_images)\n    \n    for ind, image_name in enumerate(image_names):\n        img = cv2.imread(os.path.join(path, image_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        plt.subplot(h, w, ind + 1)\n        plt.imshow(img)\n        plt.axis(\"off\")\n    \n    plt.show()","e9eafab0":"naim_JPG_PATH = '..\/input\/face-image-naim\/'","0ffae450":"batch_visualization(naim_JPG_PATH, 1, is_random=True, figsize=(5, 5))","0a06bb7f":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nfrom __future__ import print_function, division\nfrom builtins import range, input\n# Note: you may need to update your version of future\n# sudo pip install -U future\n\nfrom keras.models import Model\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\n\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")","fd9ad93a":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nimage_path = '..\/input\/face-image-naim\/'\nimage_files = glob(image_path +  '\/*.jpg')# original was *\/*.JP*G, then I removed one * and change to jpg  to avoid error \"ValueError: 'a' cannot be empty unless no samples are taken\"","d9c9568d":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# look at an image for fun\n\nplt.imshow(image.load_img(np.random.choice(image_files)));","bfcb38bc":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# add preprocessing layer to the front of VGG\nresnet = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n\n# view the structure of the model\n# if you want to confirm we need activation_49\nresnet.summary()","280d7c82":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# make a model to get output before flatten\nactivation_layer = resnet.get_layer('conv5_block3_out')\n\n# create a model object\nmodel = Model(inputs=resnet.input, outputs=activation_layer.output)","9acfb062":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# get the feature map weights\nfinal_dense = resnet.get_layer('predictions')\nW = final_dense.get_weights()[0]\n\n#while True:\ni = 0\nfor i in range(10):\n  img = image.load_img(np.random.choice(image_files), target_size=(224, 224))\n  x = preprocess_input(np.expand_dims(img, 0))\n  fmaps = model.predict(x)[0] # 7 x 7 x 2048\n\n  # get predicted class\n  probs = resnet.predict(x)\n  classnames = decode_predictions(probs)[0]\n  print(classnames)\n  classname = classnames[0][1]\n  pred = np.argmax(probs[0])\n\n  # get the 2048 weights for the relevant class\n  w = W[:, pred]\n\n  # \"dot\" w with fmaps\n  cam = fmaps.dot(w)\n\n  # upsample to 224 x 224\n  # 7 x 32 = 224\n  cam = sp.ndimage.zoom(cam, (32, 32), order=1)\n\n  plt.subplot(1,2,1)\n  plt.imshow(img, alpha=0.8)\n  plt.imshow(cam, cmap='jet', alpha=0.5)\n  plt.subplot(1,2,2)\n  plt.imshow(img)\n  plt.title(classname)\n  plt.show();","8bb00099":"#Acknowledgment:\n\nYvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nYaroslav Isaienkov https:\/\/www.kaggle.com\/ihelon\/google-landmark-retrieval-2020-eda\n\nNaim Mhedhbi   https:\/\/www.kaggle.com\/naim99\/face-image-naim","4e5c4ca2":"#I hope you enjoy it Naim. It requires a lot of courage to make a Dataset with your own image.\n\nAnyway, if you don't like it I could delete it. Though the result was so nice. I hope you prefer to be immortalized on my \"work\".  At least, I didn't made any convolution VGG 16\/19. That would be insane. ","8c34ecb0":"#Image files","833b3cc3":"#Build the Model","93e53e7f":"#Not every Kaggler would have your courage to make a Dataset with your own image. I definitely won't. For my own sake.\n\nAll my support to you brave Naim."}}