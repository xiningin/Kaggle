{"cell_type":{"5659eb5f":"code","5b6101aa":"code","76b77967":"code","955a29a8":"code","c520b176":"code","833e6171":"code","797a2aca":"code","d026fa4e":"code","0ef1f134":"code","4e878c40":"code","20bd144d":"code","1f61692a":"code","4cca04b2":"code","619c2f66":"code","c688e777":"code","ab1dc9f8":"code","980ed662":"code","8e7893f4":"code","d7634011":"code","d1ef6504":"code","12c4cb9b":"code","2c466f97":"code","b86d1196":"code","9a8be24a":"code","7ca28f22":"code","dd1f4a27":"code","e241fce6":"code","55fa35d7":"code","6564fc8d":"code","fa67521d":"code","0677d48d":"code","79919eb2":"code","87d28790":"code","2d663a57":"code","c14e9b58":"code","d51d0e23":"code","7042abf4":"code","fe775559":"code","81795eb8":"code","e1971309":"code","c5a2b698":"code","421511ab":"code","4b5243a2":"code","9582e263":"code","9c5d79cc":"code","4bf2eab8":"code","bf2d0444":"code","a2e774e4":"code","1271f1f0":"code","f13b3281":"code","f32c3858":"code","33bf446e":"code","f59302d4":"code","0abd67f9":"code","d1ac48e7":"code","58bd10e1":"code","e13097f8":"code","f0cab6ce":"code","49c3bf11":"code","51334042":"code","56157338":"code","2ee89e9e":"code","fee10e96":"code","98ada811":"code","4c2968f1":"code","35506646":"code","0f94c691":"code","fa72f39b":"code","b83e6ea3":"code","46d56b6b":"code","34ebafe4":"code","d73f37e1":"code","6418f765":"code","c08edcc8":"code","ff01078b":"code","3104a8a3":"code","2dc4f3fc":"code","b47a7bb6":"code","2837ee42":"code","25d8b28f":"code","b61a8d02":"code","75958899":"code","90030952":"code","3c2bb20e":"code","6002d085":"code","caf1c11b":"code","09bd721a":"code","05921f33":"code","1b8cdcdd":"code","b00bcd22":"code","9eae2cba":"code","f4464c53":"code","2644cec4":"code","336f12c9":"code","120a7b14":"code","6bccd3da":"code","731b8f6b":"code","ebfbbda5":"code","9f6e3d91":"code","00b2aebf":"code","7f2e5032":"code","bcdfbe29":"code","696cf711":"code","9d5e33ea":"markdown","924c3769":"markdown","bb694525":"markdown","b2a8e966":"markdown","ad5261b2":"markdown","d6dcb5da":"markdown","228ebb15":"markdown","bac1c4ec":"markdown","2ec529ee":"markdown","2f62ac0f":"markdown","7b4fa04d":"markdown","217838c9":"markdown","f29bc1fe":"markdown","3723538a":"markdown","74200863":"markdown","00f617b8":"markdown","8627b5e0":"markdown","36c6a72f":"markdown","a6261947":"markdown","3e6fa13b":"markdown","8592d0c0":"markdown","f1546966":"markdown","4a25699a":"markdown","d4f93cfa":"markdown","8606b1cd":"markdown","f9ea34d5":"markdown","8e7f1057":"markdown","02511be9":"markdown","15f4b4bd":"markdown","82e4b34e":"markdown","8f8ec14d":"markdown","662458bd":"markdown","dfb16968":"markdown","039c4901":"markdown","c5358d44":"markdown","611bb5a5":"markdown","3bf7ab4e":"markdown","1209971a":"markdown","74b0af40":"markdown","14d9ccc8":"markdown","5aab86a8":"markdown","d25e993e":"markdown","5db54ad3":"markdown","24dc2fd4":"markdown","4256690a":"markdown","39db7811":"markdown","c75619a4":"markdown","4e59ea9c":"markdown","1fd7fee1":"markdown","528c3948":"markdown"},"source":{"5659eb5f":"## OS library for connecting to data\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5b6101aa":"## Basic Libraries to read data & analyze data\n\nimport numpy as np   \nimport pandas as pd\nimport scipy.stats as stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\n## Basic Libraries to standardize & split data before modelling\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\nfrom sklearn.model_selection import train_test_split\n\n## Basic Libraries to pickle models & model evaluation\n\nimport joblib\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import roc_auc_score,roc_curve,classification_report,confusion_matrix, plot_confusion_matrix\nfrom sklearn import metrics\nfrom time import time\n\n## Library to hide warnings in notebook\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","76b77967":"data_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")","955a29a8":"data_train.head()","c520b176":"data_train.tail()","833e6171":"data_train.shape","797a2aca":"data_train.info()","d026fa4e":"data_train.describe(include = \"all\").T","0ef1f134":"data_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")","4e878c40":"data_test.head()","20bd144d":"data_test.tail()","1f61692a":"data_test.shape","4cca04b2":"data_test.info()","619c2f66":"data_test.describe(include = \"all\").T","c688e777":" data_train.isnull().sum()","ab1dc9f8":"sns.boxplot(data = data_train)","980ed662":"Q1 = data_train.quantile(0.25)\nQ3 = data_train.quantile(0.75)\nIQR = Q3 - Q1\n((data_train < (Q1 - 1.5 * IQR)) | (data_train > (Q3 + 1.5 * IQR))).sum()","8e7893f4":" data_train.duplicated().sum()","d7634011":" data_test.isnull().sum()","d1ef6504":"sns.boxplot(data = data_test)","12c4cb9b":"Q1 = data_test.quantile(0.25)\nQ3 = data_test.quantile(0.75)\nIQR = Q3 - Q1\n((data_test < (Q1 - 1.5 * IQR)) | (data_test > (Q3 + 1.5 * IQR))).sum()","2c466f97":" data_test.duplicated().sum()","b86d1196":"data_train['Age'].fillna(value= data_train['Age'].mean(), inplace = True)","9a8be24a":" data_train.isnull().sum()","7ca28f22":"def remove_outlier(col):\n    sorted(col)\n    Q1,Q3=np.percentile(col,[25,75])\n    IQR=Q3-Q1\n    lower_range= Q1-(1.5 * IQR)\n    upper_range= Q3+(1.5 * IQR)\n    return lower_range, upper_range","dd1f4a27":"lratio,uratio=remove_outlier(data_train['Age'])\ndata_train['Age']=np.where(data_train['Age']>uratio,uratio,data_train['Age'])\ndata_train['Age']=np.where(data_train['Age']<lratio,lratio,data_train['Age'])\n\nlratio,uratio=remove_outlier(data_train['Fare'])\ndata_train['Fare']=np.where(data_train['Fare']>uratio,uratio,data_train['Fare'])\ndata_train['Fare']=np.where(data_train['Fare']<lratio,lratio,data_train['Fare'])\n\nlratio,uratio=remove_outlier(data_train['Parch'])\ndata_train['Parch']=np.where(data_train['Parch']>uratio,uratio,data_train['Parch'])\ndata_train['Parch']=np.where(data_train['Parch']<lratio,lratio,data_train['Parch'])\n\nlratio,uratio=remove_outlier(data_train['SibSp'])\ndata_train['SibSp']=np.where(data_train['SibSp']>uratio,uratio,data_train['SibSp'])\ndata_train['SibSp']=np.where(data_train['SibSp']<lratio,lratio,data_train['SibSp'])\n\n","e241fce6":"sns.boxplot(data = data_train)","55fa35d7":"data_train.drop(columns = ['PassengerId', 'Cabin'], inplace = True)\n","6564fc8d":"data_train.dropna(inplace = True)","fa67521d":"data_train.info()","0677d48d":"data_test['Age'].fillna(value= data_test['Age'].mean(), inplace = True)\ndata_test['Fare'].fillna(value= data_test['Fare'].mean(), inplace = True)","79919eb2":" data_test.isnull().sum()","87d28790":"lratio,uratio=remove_outlier(data_test['Age'])\ndata_test['Age']=np.where(data_test['Age']>uratio,uratio,data_test['Age'])\ndata_test['Age']=np.where(data_test['Age']<lratio,lratio,data_test['Age'])\n\nlratio,uratio=remove_outlier(data_test['Fare'])\ndata_test['Fare']=np.where(data_test['Fare']>uratio,uratio,data_test['Fare'])\ndata_test['Fare']=np.where(data_test['Fare']<lratio,lratio,data_test['Fare'])\n\nlratio,uratio=remove_outlier(data_test['Parch'])\ndata_test['Parch']=np.where(data_test['Parch']>uratio,uratio,data_test['Parch'])\ndata_test['Parch']=np.where(data_test['Parch']<lratio,lratio,data_test['Parch'])\n\nlratio,uratio=remove_outlier(data_test['SibSp'])\ndata_test['SibSp']=np.where(data_test['SibSp']>uratio,uratio,data_test['SibSp'])\ndata_test['SibSp']=np.where(data_test['SibSp']<lratio,lratio,data_test['SibSp'])","2d663a57":"sns.boxplot(data = data_test)","c14e9b58":"data_test.drop(columns = ['PassengerId', 'Cabin'], inplace = True)","d51d0e23":"data_test.dropna(inplace = True)","7042abf4":"data_test.info()","fe775559":"sns.pairplot(data_train[['Age', 'Fare']])","81795eb8":"sns.heatmap(data_train[['Age', 'Fare']].corr(), annot=True,fmt='.2f')\nplt.show()","e1971309":"sns.pairplot(data_test[['Age', 'Fare']])","c5a2b698":"sns.heatmap(data_test[['Age', 'Fare']].corr(), annot=True,fmt='.2f')\nplt.show()","421511ab":"oneHotCols=['Sex', 'Embarked']","4b5243a2":"data_train=pd.get_dummies(data_train, columns=oneHotCols)\ndata_train.head(10)","9582e263":"data_test=pd.get_dummies(data_test, columns=oneHotCols)\ndata_test.head(10)","9c5d79cc":"for feature in data_train.columns: \n    if data_train[feature].dtype == 'object': \n        data_train[feature] = pd.Categorical(data_train[feature]).codes","4bf2eab8":"data_train.info()","bf2d0444":"for feature in data_test.columns: \n    if data_test[feature].dtype == 'object': \n        data_test[feature] = pd.Categorical(data_test[feature]).codes","a2e774e4":"data_test.info()","1271f1f0":"def data_scaling( scaling_strategy , scaling_data , scaling_columns ):\n    if    scaling_strategy ==\"RobustScaler\" :\n        scaling_data[scaling_columns] = RobustScaler().fit_transform(scaling_data[scaling_columns])\n    elif  scaling_strategy ==\"StandardScaler\" :\n        scaling_data[scaling_columns] = StandardScaler().fit_transform(scaling_data[scaling_columns])\n    elif  scaling_strategy ==\"MinMaxScaler\" :\n        scaling_data[scaling_columns] = MinMaxScaler().fit_transform(scaling_data[scaling_columns])\n    elif  scaling_strategy ==\"MaxAbsScaler\" :\n        scaling_data[scaling_columns] = MaxAbsScaler().fit_transform(scaling_data[scaling_columns])\n    else :  # If any other scaling send by mistake still perform Robust Scalar\n        scaling_data[scaling_columns] = RobustScaler().fit_transform(scaling_data[scaling_columns])\n    return scaling_data\n# RobustScaler is better in handling Outliers :\nscaling_strategy = [\"RobustScaler\", \"StandardScaler\",\"MinMaxScaler\",\"MaxAbsScaler\"]\ndata_train_scale = data_scaling( scaling_strategy[0] , data_train, data_train.columns )\ndata_test_scale  = data_scaling( scaling_strategy [0] , data_test, data_test.columns )\n# Display Scaled Train and Test Features :\ndisplay('Train Head :',data_train_scale.head())\ndisplay(data_train_scale.columns)\ndisplay('Test Head :',data_test_scale.head())\ndisplay(data_test_scale.columns)","f13b3281":"data_train_scale.boxplot(figsize=(20,3))\nplt.xticks(rotation=90)\nplt.show()","f32c3858":"data_test_scale.boxplot(figsize=(20,3))\nplt.xticks(rotation=90)\nplt.show()","33bf446e":"data_train_scale.Survived.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=[\"red\",\"green\"])","f59302d4":"features = data_train_scale.drop('Survived',axis=1)\nlabels = data_train_scale['Survived']","0abd67f9":"X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size = 0.3, random_state =143)","d1ac48e7":"X_test = data_test_scale","58bd10e1":"display('Train shape :',X_train.shape)\ndisplay('Test shape :',X_test.shape)\ndisplay('Validation shape :',X_val.shape)","e13097f8":"def print_results(results):\n    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n\n    means = results.cv_results_['mean_test_score']\n    stds = results.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n        print('{} (+\/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))","f0cab6ce":"from sklearn.linear_model import LogisticRegression","49c3bf11":"lr = LogisticRegression()\nparameters = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n}\n\nlr_cv = GridSearchCV(lr, parameters, cv=5)\nlr_cv.fit(X_train, y_train.ravel())\n\nprint_results(lr_cv)","51334042":"lr_cv.best_estimator_","56157338":"plot_confusion_matrix(lr_cv, X_train, y_train, values_format ='d')\nplt.grid(None)\nclassNames = ['Not Survived(0)', 'Survived(1)']\nplt.ylabel('ACTUAL')\nplt.xlabel('PREDICTED')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\nplt.show();","2ee89e9e":"probs = lr_cv.predict_proba(X_train)\nprobs = probs[:, 1]\nlog_train_auc = roc_auc_score(y_train, probs)\nprint('Area Under Curve: %.3f' % log_train_auc)\nlog_train_fpr, log_train_tpr, log_train_thresholds = roc_curve(y_train, probs)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(log_train_fpr, log_train_tpr)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.show()","fee10e96":"probs = lr_cv.predict_proba(X_val)\nprobs = probs[:, 1]\nlog_val_fpr, log_val_tpr, log_val_thresholds = roc_curve(y_val, probs)","98ada811":"joblib.dump(lr_cv.best_estimator_, '..\/..\/..\/LR_model.pkl')","4c2968f1":"from sklearn.svm import SVC","35506646":"svc = SVC(probability=True)\nparameters = {\n    'kernel': ['linear', 'rbf'],\n    'C': [0.1, 1, 10],\n}\n\nsvm_cv = GridSearchCV(svc, parameters, cv=5)\nsvm_cv.fit(X_train, y_train.ravel())\n\nprint_results(svm_cv)","0f94c691":"svm_cv.best_estimator_","fa72f39b":"plot_confusion_matrix(svm_cv, X_train, y_train, values_format ='d')\nplt.grid(None)\nclassNames = ['Not Survived(0)', 'Survived(1)']\nplt.ylabel('ACTUAL')\nplt.xlabel('PREDICTED')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\nplt.show();","b83e6ea3":"probs = svm_cv.predict_proba(X_train)\nprobs = probs[:, 1]\nsvm_train_auc = roc_auc_score(y_train, probs)\nprint('Area Under Curve: %.3f' % svm_train_auc)\nsvm_train_fpr, svm_train_tpr, svm_train_thresholds = roc_curve(y_train, probs)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(svm_train_fpr, svm_train_tpr)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.show()","46d56b6b":"probs = svm_cv.predict_proba(X_val)\nprobs = probs[:, 1]\nsvm_val_fpr, svm_val_tpr, svm_val_thresholds = roc_curve(y_val, probs)","34ebafe4":"joblib.dump(svm_cv.best_estimator_, '..\/..\/..\/SVM_model.pkl')","d73f37e1":"from sklearn.neural_network import MLPClassifier","6418f765":"mlp = MLPClassifier()\nparameters = {\n    'hidden_layer_sizes': [(10,), (50,), (100,)],\n    'activation': ['relu', 'tanh', 'logistic'],\n    'learning_rate': ['constant', 'invscaling', 'adaptive']\n}\n\nmlp_cv = GridSearchCV(mlp, parameters, cv=5)\nmlp_cv.fit(X_train, y_train.ravel())\nprint_results(mlp_cv)","c08edcc8":"mlp_cv.best_estimator_","ff01078b":"plot_confusion_matrix(mlp_cv, X_train, y_train, values_format ='d')\nplt.grid(None)\nclassNames = ['Not Survived(0)', 'Survived(1)']\nplt.ylabel('ACTUAL')\nplt.xlabel('PREDICTED')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\nplt.show();","3104a8a3":"probs = mlp_cv.predict_proba(X_train)\nprobs = probs[:, 1]\nmlp_train_auc = roc_auc_score(y_train, probs)\nprint('Area Under Curve: %.3f' % mlp_train_auc)\nmlp_train_fpr, mlp_train_tpr, mlp_train_thresholds = roc_curve(y_train, probs)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(mlp_train_fpr, mlp_train_tpr)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.show()","2dc4f3fc":"probs = mlp_cv.predict_proba(X_val)\nprobs = probs[:, 1]\nmlp_val_fpr, mlp_val_tpr, mlp_val_thresholds = roc_curve(y_val, probs)","b47a7bb6":"joblib.dump(mlp_cv.best_estimator_, '..\/..\/..\/MLP_model.pkl')","2837ee42":"from sklearn.ensemble import RandomForestClassifier","25d8b28f":"rf = RandomForestClassifier()\nparameters = {\n    'n_estimators': [5, 50, 250],\n    'max_depth': [2, 4, 8, 16, 32, None]\n}\n\nrf_cv = GridSearchCV(rf, parameters, cv=5)\nrf_cv.fit(X_train, y_train.ravel())\n\nprint_results(rf_cv)","b61a8d02":"rf_cv.best_estimator_","75958899":"\nplot_confusion_matrix(rf_cv, X_train, y_train, values_format ='d')\nplt.grid(None)\nclassNames = ['Not Survived(0)', 'Survived(1)']\nplt.ylabel('ACTUAL')\nplt.xlabel('PREDICTED')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\nplt.show();","90030952":"probs = rf_cv.predict_proba(X_train)\nprobs = probs[:, 1]\nrf_train_auc = roc_auc_score(y_train, probs)\nprint('Area Under Curve: %.3f' % rf_train_auc)\nrf_train_fpr, rf_train_tpr, rf_train_thresholds = roc_curve(y_train, probs)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(rf_train_fpr, rf_train_tpr)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.show()","3c2bb20e":"probs = rf_cv.predict_proba(X_val)\nprobs = probs[:, 1]\nrf_val_fpr, rf_val_tpr, rf_val_thresholds = roc_curve(y_val, probs)","6002d085":"joblib.dump(rf_cv.best_estimator_, '..\/..\/..\/RF_model.pkl')","caf1c11b":"from sklearn.ensemble import GradientBoostingClassifier","09bd721a":"gb = GradientBoostingClassifier()\nparameters = {\n    'n_estimators': [5, 50, 250, 500],\n    'max_depth': [1, 3, 5, 7, 9],\n    'learning_rate': [0.01, 0.1, 1, 10, 100]\n}\n\ngb_cv = GridSearchCV(gb, parameters, cv=5)\ngb_cv.fit(X_train, y_train.ravel())\n\nprint_results(gb_cv)","05921f33":"gb_cv.best_estimator_","1b8cdcdd":"plot_confusion_matrix(gb_cv, X_train, y_train, values_format ='d')\nplt.grid(None)\nclassNames = ['Not Survived(0)', 'Survived(1)']\nplt.ylabel('ACTUAL')\nplt.xlabel('PREDICTED')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\nplt.show();","b00bcd22":"probs = gb_cv.predict_proba(X_train)\nprobs = probs[:, 1]\ngb_train_auc = roc_auc_score(y_train, probs)\nprint('Area Under Curve: %.3f' % gb_train_auc)\ngb_train_fpr, gb_train_tpr, gb_train_thresholds = roc_curve(y_train, probs)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(gb_train_fpr, gb_train_tpr)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.show()","9eae2cba":"probs = gb_cv.predict_proba(X_val)\nprobs = probs[:, 1]\ngb_val_fpr, gb_val_tpr, gb_val_thresholds = roc_curve(y_val, probs)","f4464c53":"joblib.dump(gb_cv.best_estimator_, '..\/..\/..\/GB_model.pkl')","2644cec4":"models = {}\n\nfor mdl in ['LR', 'SVM', 'MLP', 'RF', 'GB']:\n    models[mdl] = joblib.load('..\/..\/..\/{}_model.pkl'.format(mdl))","336f12c9":"models","120a7b14":"def evaluate_model(name, model, features, labels):\n    start = time()\n    pred = model.predict(features)\n    end = time()\n    accuracy = round(accuracy_score(labels, pred), 3)\n    precision = round(precision_score(labels, pred), 3)\n    recall = round(recall_score(labels, pred), 3)\n    print('{} -- Accuracy: {} \/ Precision: {} \/ Recall: {} \/ Latency: {}ms'.format(name,\n                                                                                   accuracy,\n                                                                                   precision,\n                                                                                   recall,\n                                                                                   round((end - start)*1000, 1)))","6bccd3da":"for name, mdl in models.items():\n    evaluate_model(name, mdl, X_train, y_train)","731b8f6b":"for name, mdl in models.items():\n    evaluate_model(name, mdl, X_val, y_val)","ebfbbda5":"plt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(log_train_fpr,log_train_tpr,color='green',label=\"Logit\")\nplt.plot(svm_train_fpr, svm_train_tpr,color='blue',label=\"SVM\")\nplt.plot(mlp_train_fpr,mlp_train_tpr,color='red',label=\"MLP\")\nplt.plot(rf_train_fpr, rf_train_tpr,color='orange',label=\"RF\")\nplt.plot(gb_train_fpr,gb_train_tpr,color='purple',label=\"GB\")\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Train Data')\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower right')","9f6e3d91":"plt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(log_val_fpr,log_val_tpr,color='green',label=\"Logit\")\nplt.plot(svm_val_fpr, svm_val_tpr,color='blue',label=\"SVM\")\nplt.plot(mlp_val_fpr,mlp_val_tpr,color='red',label=\"MLP\")\nplt.plot(rf_val_fpr, rf_val_tpr,color='orange',label=\"RF\")\nplt.plot(gb_val_fpr,gb_val_tpr,color='purple',label=\"GB\")\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Validation Data')\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower right')","00b2aebf":"probs = lr_cv.predict_proba(X_test)\nprobs = probs[:, 1]\npredictions = [int(round(value)) for value in probs]","7f2e5032":"data_submit = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")","bcdfbe29":"submission = pd.DataFrame({'PassengerId': data_submit[\"PassengerId\"], 'Survived' : predictions})\nsubmission.to_csv('Submission.csv', index=False)","696cf711":"submission.head()","9d5e33ea":"### Shape of train, test & validation data","924c3769":"### Building Gradient Boosting Classifier","bb694525":"### Predicting in Test Data with Logistics Regression","b2a8e966":"### Data Check - Null, Outliers & Duplicates Train Data","ad5261b2":"#### Validation Data - Accuracy, Precision, Recall, Latency","d6dcb5da":"### Data type conversion for modelling - Train & Test","228ebb15":"### Data Cleaning - Test Data","bac1c4ec":"### Correlation Check - Test Data (Numerical Variables)","2ec529ee":"### Building Random Forest Classifier","2f62ac0f":"\n### Confusion Matrix & ROC curve of Train Data","7b4fa04d":"### Reading Training Data & Basic EDA","217838c9":"### Boxplot after standardization - Train Data","f29bc1fe":"### This will be the first dataset everyone starts for kaggle competitions. The dataset is easy to interpret and can start with the basic libraries like numpy, pandas, seaborn & matplotlib. The objective is to predict whether a passenger in titanic survived or not survived based on the features or predictor variables.\n\n### More data analysis and feature additions can be made but in this notebook only basic EDA & data cleaning is covered for easier understanding. \n\n### Machine learning part covers almost all basic ways of building a model with hyper paramter tuning & cross validation (CV-5). In the evaluation part, the models are evaluated to find the best model and submission is made using best model.\n\n### Keep watching for more versions ","3723538a":"#### Logistics Regression seems to perform well with less variations in the validation data","74200863":"### Confusion Matrix & ROC curve of Train Data","00f617b8":"\n## Part 4 - Model Validation","8627b5e0":"### Confusion Matrix & ROC curve of Train Data","36c6a72f":"####  0 is Not Survived, 1 is Survived. Proportion is 62:38, balanced.","a6261947":"## Part 3 - Predictive Modelling","3e6fa13b":"### Reading Testing Data & Basic EDA","8592d0c0":"### Splitting train data into train & train validation","f1546966":"### Path of Kaggle Data","4a25699a":"### Correlation Check - Train Data (Numerical Variables)","d4f93cfa":"### Validation & Training Metrics Comparision","8606b1cd":"### Importing necessary libraries","f9ea34d5":"# Titanic ML Competition - Predict Survival","8e7f1057":"### Submitting the prediction results","02511be9":"# END","15f4b4bd":"### *Possible Missing values in Age, Cabin & Embarked*","82e4b34e":"### *Possible Missing values in Age, Fare & Cabin*","8f8ec14d":"### Checking proportion the target variable in train data","662458bd":"### Confusion Matrix & ROC curve of Train Data","dfb16968":"### *Not much correlation between variables both in train & test*","039c4901":"### Data Cleaning - Train Data","c5358d44":"### Building Support Vector Machine","611bb5a5":"### Building MLP Classifier","3bf7ab4e":"#### Train Data - Accuracy, Precision, Recall, Latency","1209971a":"### Standardizing the Train & Test Data","74b0af40":"## Part 2 - Data Analysis & Data Cleaning","14d9ccc8":"## Part 1 - Import Libraries & Data","5aab86a8":"### Defining a function for Best Parameters before modelling","d25e993e":"### Building Logistics Regression","5db54ad3":"### Boxplot after standardization - Test Data","24dc2fd4":"### Confusion Matrix & ROC curve of Train Data","4256690a":"#### ROC - Train Data","39db7811":"### Data Transformation - Train & Test","c75619a4":"### Importing the Pickled Models","4e59ea9c":"### Data Check - Null, Outliers & Duplicates Test Data","1fd7fee1":"#### ROC - Validation Data","528c3948":"### Defining a function to evaluate & compare the models"}}