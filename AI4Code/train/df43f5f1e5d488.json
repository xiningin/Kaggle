{"cell_type":{"ea71b9bd":"code","72188563":"code","75844f0e":"code","8534bdbb":"code","e2dc1e6d":"code","9887cb3e":"code","cbb94c2b":"code","a71c4374":"code","ac73acbb":"code","b273941a":"code","d86d569d":"code","a6298b63":"code","c4d918ce":"code","cf4476ce":"code","820cb27a":"code","acf7784c":"code","2b0a2e33":"code","d6a5103f":"code","93fb6eb6":"code","1cefc34f":"code","cb73cb68":"code","27bd2d95":"code","f3e8fa7b":"code","15770561":"code","3aa72432":"code","a175e124":"code","906b4b50":"code","e32f5dc9":"code","6f3b19b0":"code","be2bf67c":"code","151c141e":"code","75c385bc":"code","572d90bd":"code","a2e27d72":"code","132e0b68":"code","918f4a55":"code","6cc74759":"code","4ec598c8":"code","156f9652":"code","4e7f79a7":"code","e3eba1dc":"code","56d8608d":"code","a56ff674":"code","161ae278":"code","5e256683":"code","e91c94a4":"code","c5a0e6eb":"code","fff458ad":"code","7d681ede":"code","2015f8e8":"code","857d4690":"code","08591ef3":"code","b390348b":"code","19e67ee0":"code","e5ebdf11":"code","bb6b8ecd":"code","67d03b7b":"code","5e74c703":"code","a7c24ca8":"code","01437944":"code","987a5432":"code","c492ba7a":"code","529f34d9":"code","c10b520e":"code","19cc9616":"code","cbeb1545":"code","caf6fecc":"code","aa6ed290":"code","92f9ad63":"code","67b0f486":"code","24eb87be":"markdown","ab19a98b":"markdown","58f78d8c":"markdown","d1970c00":"markdown","95317615":"markdown","eeece4e1":"markdown","223d24c8":"markdown","08a1d11e":"markdown","7b595dd4":"markdown","403fbc26":"markdown","29e7251c":"markdown","10062a53":"markdown","5cf108a9":"markdown","e24a2c9a":"markdown","d2163b1f":"markdown","5e096803":"markdown","18f43de8":"markdown","f35022b3":"markdown","72b446f7":"markdown","f382e2a6":"markdown","29fabdb8":"markdown"},"source":{"ea71b9bd":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom mxnet import image, np, npx\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)\n\n#PLOT TYPE\nplt.style.use(\"classic\")","72188563":"Data_Path = Path(\"..\/input\/face-mask-detection\/Dataset\")","75844f0e":"PNG_Path = list(Data_Path.glob(r\"*\/*.png\"))","8534bdbb":"PNG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],PNG_Path))","e2dc1e6d":"PNG_Path_Series = pd.Series(PNG_Path,name=\"PNG\").astype(str)\nPNG_Labels_Series = pd.Series(PNG_Labels,name=\"CATEGORY\")","9887cb3e":"Main_Data = pd.concat([PNG_Path_Series,PNG_Labels_Series],axis=1)","cbb94c2b":"print(Main_Data.head(-1))","a71c4374":"print(Main_Data[\"CATEGORY\"].value_counts())","ac73acbb":"Main_Data = Main_Data.sample(frac=1).reset_index(drop=True)","b273941a":"print(Main_Data.head(-1))","d86d569d":"def general_showing(integer_of_image):\n\n    Example_PNG = Main_Data[\"PNG\"][integer_of_image]\n    Reading_IMG = cv2.imread(Example_PNG)\n    Transformation_RGB = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n\n    plt.xlabel(Transformation_RGB.shape)\n    plt.ylabel(Transformation_RGB.size)\n    plt.title(Main_Data[\"CATEGORY\"][integer_of_image])\n\n    plt.imshow(Transformation_RGB)\n","a6298b63":"figure = plt.figure(figsize=(7,7))\ngeneral_showing(5909)","c4d918ce":"figure = plt.figure(figsize=(7,7))\ngeneral_showing(3)","cf4476ce":"figure = plt.figure(figsize=(7,7))\ngeneral_showing(8976)","820cb27a":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(14,14))\n\nfor indexing,run_axes in enumerate(axis.flat):\n    Reading_IMG = cv2.imread(Main_Data[\"PNG\"][indexing])\n    Transformation_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n    \n    run_axes.set_xlabel(Transformation_IMG.shape)\n    run_axes.set_ylabel(Transformation_IMG.size)\n    run_axes.set_title(Main_Data[\"CATEGORY\"][indexing])\n    \n    run_axes.imshow(Transformation_IMG)\n    \nplt.tight_layout()\nplt.show()","acf7784c":"Train_Data,Test_Data = train_test_split(Main_Data,train_size=0.9,shuffle=True,random_state=42)","2b0a2e33":"print(Train_Data.shape)","d6a5103f":"print(Test_Data.shape)","93fb6eb6":"Train_IMG_Generator = ImageDataGenerator(rescale=1.\/255,\n                                        rotation_range=25,\n                                        shear_range=0.5,\n                                        zoom_range=0.5,\n                                        width_shift_range=0.2,\n                                        height_shift_range=0.2,\n                                        horizontal_flip=True,\n                                        fill_mode=\"nearest\",\n                                        validation_split=0.1)","1cefc34f":"Test_IMG_Generator = ImageDataGenerator(rescale=1.\/255)","cb73cb68":"Train_IMG_Set = Train_IMG_Generator.flow_from_dataframe(dataframe=Train_Data,\n                                                       x_col=\"PNG\",\n                                                       y_col=\"CATEGORY\",\n                                                       color_mode=\"rgb\",\n                                                       class_mode=\"categorical\",\n                                                       target_size=(128,128),\n                                                       subset=\"training\")","27bd2d95":"Validation_IMG_Set = Train_IMG_Generator.flow_from_dataframe(dataframe=Train_Data,\n                                                       x_col=\"PNG\",\n                                                       y_col=\"CATEGORY\",\n                                                       color_mode=\"rgb\",\n                                                       class_mode=\"categorical\",\n                                                       target_size=(128,128),\n                                                       subset=\"validation\")","f3e8fa7b":"Test_IMG_Set = Test_IMG_Generator.flow_from_dataframe(dataframe=Test_Data,\n                                                       x_col=\"PNG\",\n                                                       y_col=\"CATEGORY\",\n                                                       color_mode=\"rgb\",\n                                                       class_mode=\"categorical\",\n                                                       target_size=(128,128),\n                                                       shuffle=False)","15770561":"print(\"TRAIN: \")\nprint(Train_IMG_Set.class_indices)\nprint(Train_IMG_Set.classes[0:5])\nprint(Train_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_IMG_Set.class_indices)\nprint(Validation_IMG_Set.classes[0:5])\nprint(Validation_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")\nprint(Test_IMG_Set.class_indices)\nprint(Test_IMG_Set.classes[0:5])\nprint(Test_IMG_Set.image_shape)","3aa72432":"Example_Image = Train_Data[\"PNG\"][422]\nReading_Image = cv2.imread(Example_Image)\nTransformation_Image = cv2.cvtColor(Reading_Image,cv2.COLOR_BGR2RGB)\nArray_Image = image.img_to_array(Transformation_Image)\nArray_Image = Array_Image.reshape((1,)+Array_Image.shape)\n\ni = 0\n\nfor batch in Train_IMG_Generator.flow(Array_Image,batch_size=32):\n    plt.figure(i)\n    \n    Image = plt.imshow(image.img_to_array(batch[0]))\n    \n    i += 1\n    \n    if i % 4 == 0:\n        break\n\nplt.show()","a175e124":"Model = Sequential()\n\n#\nModel.add(Conv2D(32,(3,3),activation=\"relu\",input_shape=(128,128,3)))\nModel.add(BatchNormalization())\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(64,(3,3),padding=\"same\",activation=\"relu\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2)))\n\nModel.add(Conv2D(128,(3,3),padding=\"same\",activation=\"relu\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2)))\n\nModel.add(Conv2D(128,(3,3),padding=\"same\",activation=\"relu\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Flatten())\nModel.add(Dense(256,activation=\"relu\"))\nModel.add(Dropout(0.5))\n\n#\nModel.add(Dense(3,activation=\"softmax\"))","906b4b50":"Early_Stop = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")","e32f5dc9":"Model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","6f3b19b0":"print(Model.summary())","be2bf67c":"CNN_Sep_Model = Model.fit(Train_IMG_Set,validation_data=Validation_IMG_Set,callbacks=Early_Stop,epochs=50)","151c141e":"Grap_Data = pd.DataFrame(CNN_Sep_Model.history)\nfigure = plt.figure(figsize=(10,10))\n\nGrap_Data.plot()","75c385bc":"plt.plot(CNN_Sep_Model.history[\"accuracy\"])\nplt.plot(CNN_Sep_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","572d90bd":"plt.plot(CNN_Sep_Model.history[\"loss\"])\nplt.plot(CNN_Sep_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","a2e27d72":"Model.save(\"main_model.h5\")\nModel.save_weights(\"main_model_weight.h5\")","132e0b68":"Model_Results = Model.evaluate(Test_IMG_Set)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.4f\" % Model_Results[1])","918f4a55":"Prediction_Number = Model.predict(Test_IMG_Set)","6cc74759":"print(Prediction_Number[0:10])","4ec598c8":"Prediction = Prediction_Number.argmax(axis=-1)","156f9652":"print(Prediction[0:10])","4e7f79a7":"fig, axes = plt.subplots(nrows=5,\n                         ncols=5,\n                         figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Test_Data[\"PNG\"].iloc[i]))\n    ax.set_title(f\"PREDICTION:{Prediction[i]}\")\n    ax.set_xlabel(Test_Data[\"CATEGORY\"].iloc[i])\nplt.tight_layout()\nplt.show()","e3eba1dc":"CNN_Main_Model = load_model(\".\/main_model.h5\")","56d8608d":"Non_Seen_Image = \"..\/input\/face-mask-detection\/Dataset\/without_mask\/1023.png\"","a56ff674":"Reading_IMG = cv2.imread(Non_Seen_Image)\nTransformation_RGB = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n\nplt.xlabel(Transformation_RGB.shape)\nplt.ylabel(Transformation_RGB.size)\n\nplt.imshow(Transformation_RGB)","161ae278":"img = load_img(Non_Seen_Image, target_size=(128, 128))  # Loading image\nimg = image.img_to_array(img)  # Transforming image to array\nimg = img \/ 255  # Normalizing Image\nimg = np.expand_dims(img, axis=0)\n\nprint(img.shape)","5e256683":"Non_Seen_Predict = Model.predict(img)","e91c94a4":"Non_Seen_Predict = Non_Seen_Predict.argmax(axis=-1)\nprint(Non_Seen_Predict)","c5a0e6eb":"img_x = load_img(Non_Seen_Image, target_size=(128, 128))  # Loading image\nimg_x = image.img_to_array(img_x)  # Transforming image to array\nimg_x = img_x \/ 255  # Normalizing Image\nimg_x = np.expand_dims(img_x, axis=0)","fff458ad":"Non_Seen_Predict_x = Model.predict(img_x)[0]","7d681ede":"(startX, startY, prb) = Non_Seen_Predict_x","2015f8e8":"print(f\"{startX} x {startY} x {prb}\")","857d4690":"(h,w) = Transformation_RGB.shape[:2]","08591ef3":"print(f\"{h} x {w}\")","b390348b":"startX = int(startX * w)\nstartY = int(startY * h)\nprb = int(prb * w)","19e67ee0":"print(f\"{startX} x {startY} x {prb}\")","e5ebdf11":"Reading_cv = cv2.imread(Non_Seen_Image)","bb6b8ecd":"Mask_Image = \"..\/input\/face-mask-detection\/Dataset\/with_mask\/1009.png\"","67d03b7b":"Reading_IMG = cv2.imread(Mask_Image)\nTransformation_RGB = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\n\nplt.xlabel(Transformation_RGB.shape)\nplt.ylabel(Transformation_RGB.size)\n\nplt.imshow(Transformation_RGB)","5e74c703":"img = load_img(Mask_Image, target_size=(128, 128))  # Loading image\nimg = image.img_to_array(img)  # Transforming image to array\nimg = img \/ 255  # Normalizing Image\nimg = np.expand_dims(img, axis=0)\n\nprint(img.shape)","a7c24ca8":"Non_Seen_Predict_Mask = Model.predict(img)","01437944":"Non_Seen_Predict_Mask = Non_Seen_Predict_Mask.argmax(axis=-1)\nprint(Non_Seen_Predict_Mask)","987a5432":"img_x = load_img(Mask_Image, target_size=(128, 128))  # Loading image\nimg_x = image.img_to_array(img_x)  # Transforming image to array\nimg_x = img_x \/ 255  # Normalizing Image\nimg_x = np.expand_dims(img_x, axis=0)","c492ba7a":"Non_Seen_Predict_x_mask = Model.predict(img_x)[0]","529f34d9":"(startX, startY, prb) = Non_Seen_Predict_x_mask","c10b520e":"print(f\"{startX} x {startY} x {prb}\")","19cc9616":"(h,w) = Reading_IMG.shape[:2]","cbeb1545":"half_h = int(w \/ 2)\nhalf_w = int(h \/ 2)","caf6fecc":"print(f\"{half_h} x {half_w}\")","aa6ed290":"print(f\"{h} x {w}\")","92f9ad63":"startX = int(startX * w)\nstartY = int(startY * h)\nprb = int(prb * w)","67b0f486":"print(f\"{startX} x {startY} x {prb}\")","24eb87be":"#### TARGET PREDICT","ab19a98b":"#### HOW TO LOOK BY GENERATOR","58f78d8c":"##### MASK","d1970c00":"#### TO SERIES","95317615":"#### LABEL","eeece4e1":"#### STRUCTURE","223d24c8":"##### NO MASK","08a1d11e":"#### TO DATAFRAME","7b595dd4":"# VISUALIZATION","403fbc26":"#### SAVING","29e7251c":"# IMAGE GENERATOR","10062a53":"#### CHECKING","5cf108a9":"#### PATH","e24a2c9a":"* mask_weared_incorrect: 0\n* with_mask: 1\n* without_mask: 2","d2163b1f":"# PATH AND LABEL PROCESS","5e096803":"# SPLITTING TEST AND TRAIN DATA","18f43de8":"# PACKAGES AND LIBRARIES","f35022b3":"#### APPLY","72b446f7":"#### SHUFFLING","f382e2a6":"# MODEL","29fabdb8":"#### PREDICTION"}}