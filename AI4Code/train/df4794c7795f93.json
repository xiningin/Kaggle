{"cell_type":{"257b1781":"code","44b331c8":"code","33698c3e":"code","a36217a4":"code","f419d51b":"code","83136323":"code","c949234d":"code","5f839f82":"code","f6abb39c":"code","a064cff3":"code","a5222f58":"code","104a4cc7":"code","6dfab758":"code","f4725466":"code","20d5f9e5":"code","2492f162":"code","86a1573b":"code","b7754f6a":"markdown","49dfe739":"markdown","ba277676":"markdown"},"source":{"257b1781":"# Load Package\n## System\nimport warnings\nwarnings.filterwarnings('ignore')\n\n## Data Process\nimport numpy as np\nimport pandas as pd\n\n## ML Pipeline\nfrom sklearn.impute import SimpleImputer, MissingIndicator\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OrdinalEncoder\nimport xgboost as xgb\n","44b331c8":"# Load data\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission.dtypes","33698c3e":"# Save data\ntarget = train_df[[\"Survived\"]]\ntrain_df.drop('Survived', axis=1, inplace=True)","a36217a4":"# Join and Clean\ncombine = pd.concat([train_df, test_df])","f419d51b":"# EDA\ncombine.info()","83136323":"mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'the Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}","c949234d":"combine['Title'] = combine.Name.apply(lambda x: x.split(\".\")[0].split(\",\")[1].strip()).replace(mapping)\ncombine['Title'].unique()","5f839f82":"combine[\"is_married\"] = (combine[\"Title\"]==\"Mrs\")\ncombine[\"fsize\"] = combine.apply(lambda row:row['Parch']+row['SibSp'], axis=1)","f6abb39c":"miss_ind = Pipeline(steps=[\n    ('indicator', MissingIndicator(error_on_new=False)),\n])\n\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encode\", OrdinalEncoder()),\n])\n\nnumeric_transformer = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n])","a064cff3":"combine.loc[:, ['Age_MI', 'Cabin_MI']] = pd.DataFrame(miss_ind.fit_transform(combine[['Age', 'Cabin']]), columns=['Age_MI', 'Cabin_MI'])\ncombine.loc[:, ['Sex','Embarked', 'Title']] = categorical_transformer.fit_transform(combine[['Sex', 'Embarked', 'Title']])\ncombine.loc[:, ['Age', 'Fare']] = numeric_transformer.fit_transform(combine[['Age', 'Fare']])\ncombine['FareBin'] = pd.qcut(combine['Fare'], 4, labels=[1, 2, 3, 4])\ncombine['AgeBin'] = pd.cut(combine['Age'].astype(int), 5, labels=[1, 2, 3, 4, 5])\ncombine.loc[:, ['AgeBin', 'FareBin']] = categorical_transformer.fit_transform(combine[['AgeBin', 'FareBin']])\ncombine.drop(['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)","a5222f58":"train = combine[:len(target)]\ntest = combine[len(target):]","104a4cc7":"data_dmatrix = xgb.DMatrix(data=train,label=target)","6dfab758":"params = {'eval_metric': 'auc','colsample_bytree': 0.3,'learning_rate': 0.1,\n                'max_depth': 5, 'alpha': 10, 'tree_method':'gpu_hist'}\n\nxgb_cv = xgb.cv(dtrain=data_dmatrix, params=params, nfold=4,\n                    num_boost_round=50, early_stopping_rounds=10, metrics=\"auc\", as_pandas=True, seed=123)","f4725466":"xgb_cv.head()","20d5f9e5":"model = xgb.XGBClassifier(**params).fit(train, target)","2492f162":"submission['Survived'] = model.predict(test)","86a1573b":"submission.to_csv(\"xgb_gpu_submission.csv\", index=False)","b7754f6a":"**If you like this kernel, please upvote so that more people will see and learn from it**","49dfe739":"## Import packages","ba277676":"# Simple xgboost gpu implementation\n\nLearn how to use gpu in a hour!"}}