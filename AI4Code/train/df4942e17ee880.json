{"cell_type":{"e1029e66":"code","c44b5748":"code","f6b2fdf5":"code","5581804f":"code","07bddee1":"code","5f4c5ab7":"code","77f6f21c":"code","675c6288":"code","0271e4cb":"code","d21bb428":"code","5f8a26e5":"code","35817424":"code","d5dd2fe9":"code","bcdc2b46":"code","3ccdd9f7":"code","b93f0b01":"code","b43a3ad0":"code","b5dd5f12":"code","7471bdfe":"code","58bcacd6":"code","b827dd04":"markdown","52fb6542":"markdown","964408dd":"markdown","2a036938":"markdown","ba286e8d":"markdown","852d6012":"markdown","618b931b":"markdown","c94b446d":"markdown"},"source":{"e1029e66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c44b5748":"from tensorflow.keras.layers import Input, Dense, Flatten\nfrom keras import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.models import Sequential","f6b2fdf5":"image_size = [224, 224]","5581804f":"vgg = VGG16(input_shape = image_size + [3], weights = 'imagenet', include_top =  False)","07bddee1":"for layer in vgg.layers:\n    layer.trainable = False","5f4c5ab7":"from glob import glob\nfolders = glob('\/kaggle\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/*')","77f6f21c":"folders\n","675c6288":"x = Flatten()(vgg.output)","0271e4cb":"prediction = Dense(len(folders), activation = 'softmax')(x)","d21bb428":"model = Model(inputs = vgg.input, outputs = prediction)","5f8a26e5":"model.summary()","35817424":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","d5dd2fe9":"from keras.preprocessing.image import ImageDataGenerator","bcdc2b46":"train_data_gen = ImageDataGenerator(rescale = 1.\/255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)","3ccdd9f7":"test_data_gen = ImageDataGenerator(rescale = 1.\/255)","b93f0b01":"train_set = train_data_gen.flow_from_directory('\/kaggle\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/', target_size = (224,224), batch_size = 32, class_mode = 'categorical')","b43a3ad0":"test_set = test_data_gen.flow_from_directory('\/kaggle\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/valid\/', target_size = (224,224), batch_size = 32, class_mode = 'categorical')","b5dd5f12":"mod = model.fit_generator(\n  train_set,\n  validation_data=test_set,\n  epochs=10,\n  steps_per_epoch=len(train_set),\n  validation_steps=len(test_set)\n)","7471bdfe":"import matplotlib.pyplot as plt\nplt.plot(mod.history['loss'], label='train loss')\nplt.plot(mod.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n\n","58bcacd6":"plt.plot(mod.history['accuracy'], label='train accuracy')\nplt.plot(mod.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.show()","b827dd04":"Fitting the model","52fb6542":"Generating more images","964408dd":"As we are using VGG16 architecture, it expects the size of 224 by 224(Although, you can set your own size). We will set image size.","2a036938":"Some of the layers of VGG16 are already trained. To train them again is not a good practice. Thereby making it False","ba286e8d":"The first argument is the shape of input image plus **3**(as image is colured[RBG], for black_and_white add **1**).\nThe second one is the weights eqaul to imagenet. And,\nas we know it gives 1000 outputs. Third one excludes the top layer.","852d6012":"Importing necessary libraries.","618b931b":"Flattening the output layer","c94b446d":"Compiling the model"}}