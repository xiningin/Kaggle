{"cell_type":{"0071ab17":"code","2bfab71d":"code","9cf2a282":"code","69de4ff6":"code","fbfc5ec9":"code","3c4f5dd9":"code","70651191":"code","25b0e79c":"code","7e90a224":"code","39a4a570":"code","65c1f5a6":"code","574e7414":"code","81410812":"code","23ce7a6f":"code","54496ca1":"code","a167250c":"code","246eedda":"code","f798cf68":"code","75c9e817":"code","b24721df":"code","754716aa":"code","877cd94f":"code","f2c4dbbe":"code","a76db152":"code","e0e2e034":"code","ae150796":"code","8d9f7c8d":"markdown","51b1eef8":"markdown","fce9397d":"markdown","616c7403":"markdown","aecb749e":"markdown","54a22f10":"markdown","a27125b9":"markdown","3fab3d65":"markdown","dddca8ab":"markdown","ef993e13":"markdown","462e8bbb":"markdown","68464ba3":"markdown","b0587e12":"markdown","20a2573e":"markdown","8b212379":"markdown","d12c650f":"markdown","35b141e3":"markdown","1b823bc5":"markdown","969ece54":"markdown","4929724a":"markdown","b3dfe00c":"markdown","c09ee3e8":"markdown","d9d16c54":"markdown"},"source":{"0071ab17":"!pip install pandas_flavor","2bfab71d":"import numpy as np\nimport pandas as pd\nfrom pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","9cf2a282":"from pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef get_missing(df):        \n    tmp =  sorted(\n                [(col , str(df[col].dtypes) ,df[col].isna().sum(), np.round( df[col].isna().sum() \/ len(df) * 100,2) ) for col in df.columns if df[col].isna().sum() !=0 ],\n                key = lambda x: x[2], reverse=True)\n    \n    return pd.DataFrame(tmp).rename({0:\"Feature\", 1:\"dtype\", 2:\"count\", 3:\"percent\"},axis=1)  \n\n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_cols(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef get_object_cols(df):\n    return list(df.select_dtypes(exclude = np.number).columns)\n\n@register_dataframe_method\ndef get_object_df(df):\n    return df.select_dtypes(exclude = np.number)\n\n@register_dataframe_method\ndef get_discrete_cols(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef get_discrete_df(df,thresold):\n#     thresold in number of unique values\n    return df[ get_discrete_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef describe_discrete_cols(df,thresold, ascending=True):\n    \n    values = pd.DataFrame()\n    \n    for col in df.get_discrete_cols(thresold=thresold):\n        values[col] = [df[col].unique(), df[col].nunique()]\n        \n    return values.transpose().sort_values(by = 1,ascending=ascending).rename({0:\"Values\",1:\"cardinality\"},axis=1)\n\n@register_dataframe_method\ndef get_continuous_cols(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef get_continuous_df(df,thresold):\n    #     thresold in number of unique values\n    return df[ get_continuous_cols(df=df,thresold=thresold) ]\n\n\n@register_dataframe_method\ndef describe_continuous_cols(df,thresold, ascending=True):\n    return df[df.get_continuous_cols(thresold=thresold)].describe().T\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n\n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n\n            length = len(df[i])\n            tmp = np.round((length - df[i].between(lower_range,upper_range).sum())\/length * 100, 2)\n            if tmp != 0:\n                features[i] = tmp\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Outlier percent'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n\n@register_dataframe_method\ndef get_outlier_cols(df):\n    return df.IQR_percent().reset_index()[\"index\"].to_list()\n        \n@register_dataframe_method\ndef drop_row_outlier(df, cols, inplace=False):\n#     init empty index\n    indices = pd.Series(np.zeros(len(df), dtype=bool), index=df.index)\n\n    for col in cols:\n        low, top = df[col].IQR_range()\n        indices |= (df[col] > top) | (df[col] < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n\n@register_series_method\ndef drop_row_outlier(df, inplace=False):\n#     init empty index\n\n    low, top = df.IQR_range()\n    indices = (df > top) | (df < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n        \n@register_dataframe_method\ndef compare_cols(df,l_feat,r_feat, percent=False, percent_of_total=False):\n    \n#     [L_feat] {R_feat1: agg1, R_feat2: agg2}\n\n    \n    if percent or percent_of_total:\n        \n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})\n            \n            if percent: tmp[key +\" %\"] = tmp.groupby(level=0).apply(lambda x: np.round(100 * x \/ float(x.sum()),2))\n\n            if percent_of_total: tmp[key+\" % of total\"] = np.round(tmp[key + \" \" + val] \/ tmp[key + \" \" + val].sum() * 100 , 2)\n            \n            comp.append(tmp)\n            \n        return comp\n    \n    else:\n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})           \n            comp.append(tmp)\n            \n        return comp  \n    \n    \n\n@register_dataframe_method\ndef count_dtypes(df, ascending=False):\n    return pd.DataFrame(df.dtypes.value_counts(ascending=ascending)).rename({0:\"Count\"},axis=1)\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    display(pd.DataFrame(df.dtypes.value_counts(ascending=False) ).rename({0:\"count\"},axis=1))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = get_missing(df)\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())","69de4ff6":"\n\nimport itertools\ndef display_multiple_tables(table_list):\n    table_list = list(itertools.chain(*table_list) )\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')\n\n","fbfc5ec9":"titanic = pd.read_csv(\"..\/input\/titanic\/train.csv\")\niris = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\nheart = pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")","3c4f5dd9":"iris.about()","70651191":"iris.get_numeric_cols()","25b0e79c":"iris.get_numeric_df()","7e90a224":"iris.get_object_cols()","39a4a570":"iris.get_object_df()","65c1f5a6":"iris.get_discrete_cols(thresold = 5)","574e7414":"iris.get_discrete_df(thresold = 5)","81410812":"iris.describe_discrete_cols(thresold=5)","23ce7a6f":"iris.get_continuous_cols(thresold=5)","54496ca1":"iris.get_continuous_df(thresold=5)","a167250c":"iris.describe_continuous_cols(thresold=5)","246eedda":"iris.dtypes","f798cf68":"iris.dtypes_of_cols()","75c9e817":"iris.count_dtypes()","b24721df":"iris.IQR_range()","754716aa":"iris.IQR_percent()","877cd94f":"iris.get_outlier_cols()","f2c4dbbe":"print(f\"Before drop {len(iris)}\")\ntmp = iris.drop_row_outlier(inplace=False, cols=iris.get_outlier_cols())\ndisplay(tmp)\nprint(f\"After drop {len(tmp)}\")","a76db152":"display(*titanic.compare_cols([\"Pclass\",\"Sex\", \"Survived\"], {\"Survived\":\"count\"}, percent=True, percent_of_total=True))","e0e2e034":"cols = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n\n[display(*titanic.compare_cols([col, \"Survived\"], {\"Survived\":\"count\"}, percent=True, percent_of_total=True)) for col in cols]","ae150796":"cols = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n\n\ntables = [compare_cols(titanic, [col, \"Survived\"], {\"Survived\":\"count\"}, percent=True, percent_of_total=True) for col in cols]\n\ndisplay_multiple_tables(tables)","8d9f7c8d":"**This will give a general idea of what the dataset consists**","51b1eef8":"# get object features","fce9397d":"**Note Discrete features have a finite cardinality. It does not depend on the datatype**\n\nFor example a column can have dtype as int but have a cardinality of say 3, namely  [0,1,2]\n\n`get_discrete_cols` will return all discrete columns and takes input as thresold(cardinality). This thresold needs to be given manually, since it depends on the size and the data we are working with.\n\n`get_discrete_df` will do the same except returns pandas dataframe","616c7403":"# get numeric features ","aecb749e":"# Outliers","54a22f10":"**using `describe_discrete_cols` we can know more about the discrete features**","a27125b9":"`get_numeric_cols` will return columns with dtype as number(np.number i.e, int, float)\n\n`get_numeric_df` will return dataframe ","3fab3d65":"# Introduction\n\n**In datascience pipeline we use a lot of pandas methods from importing to training the model. But I have observed that certain functions get used a lot, especially which involves complex manipulation to data.\nThis inspired me create a set of methods which extend pandas, i.e, we could use the same dotted notation(OOPs) like pd.read_csv().\nSince I use these functions for all my projects, this lead me to think to make this as a separate notebook where everyone can see it, fork and probably provide feedback.**\n\n### if you find this helpful share it with people who are into datascience and drop an upvote which goes a long way in motivating me\n\nyou could check out my other notebooks where I have used this on actual kaggle projects\n\n[titanic](https:\/\/www.kaggle.com\/imams2000\/titanic-eda-insights-catboost-83-17-crossval)\n\n[Heart Disease](https:\/\/www.kaggle.com\/imams2000\/eda-and-ml-model-avg-recall-89)\n\n[Customer Personality Analysis](https:\/\/www.kaggle.com\/imams2000\/interactive-dashboard-and-eda#Importing-data-and-Initial-Impressions)\n\n[EDA for placements](https:\/\/www.kaggle.com\/imams2000\/eda-placements)\n\n[Advanced House Price predict](https:\/\/www.kaggle.com\/imams2000\/eda-advancedhousepricepredict)","dddca8ab":"# Describe Continuous features","ef993e13":"**I personally believe this is THE most important function out of all**\n\nThis is a wrapper for the groupby function of pandas(similar to pivot tables). Using this function will reveal key insights your data.\n\nthe function `compare_cols` expects left features and right features.\n\n\\[L_feat1, L_feat2\\] {R_feat1: agg1, R_feat2: agg2}\n\nwhere agg1 and agg2 are aggregation functions like count, sum\n\nlets consider a more complicated dataset like titanic\n\nsetting `percent=True` will calculate percentage for each category\n\nsetting `percent_of_total=True` will calculate the percent for all the categories","462e8bbb":"`get_continuous_cols` will return continuous columns regardless of the datatype with thresold as input.(similar explanation given above)\n\n`get_continuous_df` will return pandas dataframe","68464ba3":"# Get Continuous columns","b0587e12":"`IQR_range` will give IQR range for selected columns with numeric datatype\n\n`IQR_percent` will give the percent of outliers in data if exists\n\n`get_outlier_cols` will return list of columns with non zero outliers\n\n`drop_row_outlier` will drop all rows which are outside IQR range","20a2573e":"**To achieve this I will be using pandas_flavor. pandas_flavor is a package using which I can add additional custom methods to pandas**\n\nhere is the [docs](https:\/\/pypi.org\/project\/pandas-flavor\/)","8b212379":"using `describe_continuous_cols` we can find out more about continuous data","d12c650f":"`dtypes_of_cols` will return a properly looking pandas datataframe. (just a good looking version of df.dtypes)\n\n`count_dtypes` will count all the various dtypes avaliable","35b141e3":"**since scrolling is an issue for lots of columns use the `display_multiple_tables` to display it side by side**","1b823bc5":"# Compare columns","969ece54":"`get_object_cols` will return all columns with dtype other than number(other than np.number i.e, int, float)\n\n`get_object_df` will return dataframe ","4929724a":"# Dtypes of columns","b3dfe00c":"# The `about` method","c09ee3e8":"# Get discrete features","d9d16c54":"# Describe discrete columns"}}