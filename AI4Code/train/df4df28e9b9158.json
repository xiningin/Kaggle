{"cell_type":{"01dc37c8":"code","d64ae52c":"code","34eaeaa2":"code","7716f9be":"code","cd532037":"code","252d63ed":"code","2a61d68e":"code","0c104241":"code","a46255a2":"code","69461c40":"code","d5787b98":"code","6951e75f":"code","da3e9733":"code","b7a1b66c":"code","baa48818":"code","66fb89eb":"code","a4ab7f09":"code","31fdb57f":"code","8c08d502":"code","86478635":"code","16f6c5f9":"code","d7bb0240":"code","5ecfe6bb":"code","bedc1b14":"code","a5b7fb6a":"code","dfc2c045":"code","e6558f2c":"code","bcef9f65":"code","c9b3e927":"code","03583d80":"code","cc442557":"code","c34b1ecc":"code","c64c73c6":"code","66f8105b":"code","77c8c4ed":"code","52d3ea65":"code","7f544d2a":"code","08a8def6":"code","ed699ac5":"code","8f83d494":"code","dda11ecd":"code","92a603fe":"code","59733e59":"code","92d9af18":"code","d748d62a":"code","c8476c13":"code","c2165823":"code","61fda808":"code","8c272572":"code","635ec870":"code","0d419b91":"code","ab348aa7":"code","151091b8":"code","feb042b2":"code","9070dd2c":"code","0890dc29":"code","e783fed1":"code","e380d91a":"code","17a8dcd3":"code","ecbd06cb":"code","5133c4cf":"code","6eb94dce":"code","9cbcaa54":"code","16de8257":"code","28f2bc5a":"code","5cc49aa1":"code","3e79bacd":"code","f7e3c756":"code","ba4ef58d":"code","afbcbb86":"code","75bda970":"code","4ab983b3":"code","15e137db":"code","c71a0d70":"code","a17f025e":"code","311195a1":"code","0e138099":"code","57cec384":"code","db2130fb":"code","fbb3a3ca":"code","274e2e1d":"code","4ca75426":"code","879e88e0":"code","673913b7":"code","20560a52":"code","dd50933e":"code","0c1c3090":"code","8067aed0":"code","faeb8c98":"code","879c58de":"code","a136fda5":"code","4bddefd5":"code","351a3ce6":"code","444f36f2":"code","c84b710c":"code","b29bd7fc":"code","fad755e3":"code","5e84a246":"markdown","b4879d45":"markdown","a0d234ae":"markdown","42ea59f8":"markdown","6acf8db9":"markdown","5e115d8d":"markdown","7edead5d":"markdown","7c6ce2e3":"markdown","076c756d":"markdown","c656337e":"markdown","13155e8c":"markdown","13daf6e6":"markdown","79592ee4":"markdown","0b2f1fab":"markdown","eb30661e":"markdown","7a060f07":"markdown","f038f26d":"markdown","b7ef8963":"markdown","e2179f0f":"markdown","eafdb786":"markdown","dd62ec54":"markdown","c0182b1c":"markdown","2f7bccd7":"markdown","22183b2d":"markdown","45114807":"markdown","33334ef8":"markdown","7065daef":"markdown","a42f1332":"markdown","ecc17d6b":"markdown","b15c6fc9":"markdown","f5a79c6d":"markdown","f9afeb57":"markdown","bf48cf4a":"markdown","28d3efde":"markdown","7836f2b6":"markdown","59fb9d12":"markdown","ff1c2e9f":"markdown","e3141256":"markdown","2766780f":"markdown","1ac45459":"markdown","dcbf2b6c":"markdown","72efb982":"markdown","0a4843e3":"markdown"},"source":{"01dc37c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d64ae52c":"# \ub77c\uc774\ube0c\ub7ec\ub9ac \uc784\ud3ec\ud2b8\n\n# data manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n# sklearn models & tools\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\n\n# ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\nimport os\nprint(os.listdir(\"..\/input\"))","34eaeaa2":"submission = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/sample_submission.csv')\ntrain = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/test.csv')","7716f9be":"train.info()","cd532037":"test.info()","252d63ed":"train.head()","2a61d68e":"test.head()","0c104241":"train.describe()","a46255a2":"train.isnull().sum().sum()","69461c40":"test.isnull().sum().sum()","d5787b98":"train.target.value_counts()","6951e75f":"sns.countplot(train.target)","da3e9733":"train.loc[train.target==1].shape[0] \/ train.loc[train.target==0].shape[0]","b7a1b66c":"# ID_code \ubcc0\uc218 \uc81c\uac70\ntrain[\"Id\"] = train.index.values\noriginal_trainid = train.ID_code.values\ntrain.drop(\"ID_code\", axis=1, inplace=True)\n\ntest[\"Id\"] = test.index.values\noriginal_testid = test.ID_code.values\ntest.drop(\"ID_code\", axis=1, inplace=True)","baa48818":"# \uc0c1\uad00\uacc4\uc218 \ud3c9\uade0\n(train.corr()).mean().mean()","66fb89eb":"(train.drop([\"target\"], axis=1).corr()).mean().mean()","a4ab7f09":"train_correlations = train.drop([\"target\"], axis=1).corr()\ntrain_correlations = train_correlations.values.flatten()\ntrain_correlations = train_correlations[train_correlations != 1]\n\ntest_correlations = test.corr()\ntest_correlations = test_correlations.values.flatten()\ntest_correlations = test_correlations[test_correlations != 1]\n\nplt.figure(figsize=(20,5))\nsns.distplot(train_correlations, color=\"Red\", label=\"train\")\nsns.distplot(test_correlations, color=\"Green\", label=\"test\")\nplt.xlabel(\"Correlation values found in train (except 1)\")\nplt.ylabel(\"Density\")\nplt.title(\"Are there correlations between features?\"); \nplt.legend();","31fdb57f":"parameters = {'min_samples_leaf': [20, 25]}\nforest = RandomForestClassifier(max_depth=15, n_estimators=15)\ngrid = GridSearchCV(forest, parameters, cv=3, n_jobs=-1, verbose=2, scoring=make_scorer(roc_auc_score))","8c08d502":"grid","86478635":"# \ubaa8\ub378 \ud559\uc2b5\ngrid.fit(train.drop([\"target\"], axis=1).values, train.target.values)","16f6c5f9":"grid.best_params_","d7bb0240":"grid.best_score_","5ecfe6bb":"# \ubaa8\ub378\uc758 \ub0b4\uc7a5 \ud568\uc218\uc778 feature_importances_\ngrid.best_estimator_.feature_importances_ # shape : 200\n\n# \uc5b4\ub808\uc774 \ud615\ud0dc\ub85c \ubc18\ud658","bedc1b14":"# np.argsort(importances)[::-1][0:n_top] \n\n# \uc778\ub371\uc2a4 \uc624\ub984\ucc28\uc21c \uc815\ub82c -> \ub4a4\uc9d1\uc5b4\uc11c \ub0b4\ub9bc\ucc28\uc21c => \uc0c1\uc704 5\uac1c\uc758 \uc778\ub371\uc2a4","a5b7fb6a":"# train.drop([\"target\", \"ID_code\"], axis=1).columns.values","dfc2c045":"n_top = 5","e6558f2c":"importances = grid.best_estimator_.feature_importances_ # \ubcc0\uc218 \uc911\uc694\ub3c4\nidx = np.argsort(importances)[::-1][0:n_top] # \uc0c1\uc704 5\uac1c\uc758 \uc778\ub371\uc2a4\nfeature_names = train.drop([\"target\"], axis=1).columns.values # \ubcc0\uc218 \uc774\ub984\n\n# \ubcc0\uc218 \uc911\uc694\ub3c4 \uae30\uc900 \uc0c1\uc704 5\uac1c \ubcc0\uc218\uc758 \uc911\uc694\ub3c4 \uc2dc\uac01\ud654\nplt.figure(figsize=(20,5))\nsns.barplot(x=feature_names[idx], y=importances[idx]);\nplt.title(\"What are the top important features to start with?\");","bcef9f65":"train.var_81","c9b3e927":"(train.loc[train.target==0, feature_names[idx][0]]).mean()  # var81","03583d80":"fig, ax = plt.subplots(n_top,2,figsize=(20,5*n_top))\n\nfor n in range(n_top):\n    sns.distplot(train.loc[train.target==0, feature_names[idx][n]], ax=ax[n,0], color=\"Orange\", norm_hist=True)\n    sns.distplot(train.loc[train.target==1, feature_names[idx][n]], ax=ax[n,0], color=\"Red\", norm_hist=True)\n    sns.distplot(test.loc[:, feature_names[idx][n]], ax=ax[n,1], color=\"Mediumseagreen\", norm_hist=True)\n    ax[n,0].set_title(\"Train {}\".format(feature_names[idx][n]))\n    ax[n,1].set_title(\"Test {}\".format(feature_names[idx][n]))\n    ax[n,0].set_xlabel(\"\")\n    ax[n,1].set_xlabel(\"\")","cc442557":"top = train.loc[:, feature_names[idx]]\ntop.describe()","c34b1ecc":"top.join(train.target)","c64c73c6":"# scatter plot\n# top = top.join(train.target)\n# sns.pairplot(top, hue=\"target\")","66f8105b":"test.head()","77c8c4ed":"y_proba = grid.predict_proba(test.values)\ny_proba_train = grid.predict_proba(train.drop('target', axis=1).values)","52d3ea65":"(y_proba_train[:,1]).mean()","7f544d2a":"fig, ax = plt.subplots(2,1,figsize=(20,8))\nsns.distplot(y_proba_train[train.target==1,1], norm_hist=True, color=\"mediumseagreen\",\n             ax=ax[0], label=\"1\")\nsns.distplot(y_proba_train[train.target==0,1], norm_hist=True, color=\"coral\",\n             ax=ax[0], label=\"0\")\nsns.distplot(y_proba[:,1], norm_hist=True,\n             ax=ax[1], color=\"purple\")\nax[1].set_xlabel(\"Predicted probability for test data\");\nax[1].set_ylabel(\"Density\");\nax[0].set_xlabel(\"Predicted probability for train data\");\nax[0].set_ylabel(\"Density\");\nax[0].legend();","08a8def6":"train.head()","ed699ac5":"train.info()","8f83d494":"original_features = train.drop([\"target\", \"Id\"], axis=1).columns.values\noriginal_features","dda11ecd":"top","92a603fe":"pd.qcut(\n        train.loc[:, 'var_81'].values,\n        q=10,\n        labels=False)","59733e59":"np.round(train.loc[:, 'var_81'].values)","92d9af18":"# \uc911\uc694\ubcc0\uc218 qcut\ud55c \ubcc0\uc218 \uc0dd\uc131\nencoder = LabelEncoder()\nfor your_feature in top.drop(\"target\", axis=1).columns.values:\n    train[your_feature + \"_qbinned\"] = pd.qcut(\n        train.loc[:, your_feature].values,\n        q=10,\n        labels=False\n    )\n    train[your_feature + \"_qbinned\"] = encoder.fit_transform(\n        train[your_feature + \"_qbinned\"].values.reshape(-1, 1)\n    )","d748d62a":"# \uc911\uc694 \ubcc0\uc218 \ubc18\uc62c\ub9bc\ud55c \ubcc0\uc218 \uc0dd\uc131\nencoder = LabelEncoder()\nfor your_feature in top.drop(\"target\", axis=1).columns.values:\n    train[your_feature + \"_rounded\"] = np.round(train.loc[:, your_feature].values)\n    train[your_feature + \"_rounded_10\"] = np.round(10*train.loc[:, your_feature].values)\n    train[your_feature + \"_rounded_100\"] = np.round(100*train.loc[:, your_feature].values)","c8476c13":"# test\uc5d0\ub3c4 \uac19\uc774 \uc801\uc6a9\n\n# \uc911\uc694\ubcc0\uc218 qcut\ud55c \ubcc0\uc218 \uc0dd\uc131\nencoder = LabelEncoder()\nfor your_feature in top.drop(\"target\", axis=1).columns.values:\n    test[your_feature + \"_qbinned\"] = pd.qcut(\n        test.loc[:, your_feature].values,\n        q=10,\n        labels=False\n    )\n    test[your_feature + \"_qbinned\"] = encoder.fit_transform(\n        test[your_feature + \"_qbinned\"].values.reshape(-1, 1)\n    )\n\n# \uc911\uc694 \ubcc0\uc218 \ubc18\uc62c\ub9bc\ud55c \ubcc0\uc218 \uc0dd\uc131\nencoder = LabelEncoder()\nfor your_feature in top.drop(\"target\", axis=1).columns.values:\n    test[your_feature + \"_rounded\"] = np.round(test.loc[:, your_feature].values)\n    test[your_feature + \"_rounded_10\"] = np.round(10*test.loc[:, your_feature].values)\n    test[your_feature + \"_rounded_100\"] = np.round(100*test.loc[:, your_feature].values)","c2165823":"train.head(10)","61fda808":"# pd.qcut() : \ub370\uc774\ud130\ub97c \ub3d9\uc77c\ud55c \uae38\uc774\ub85c \ub098\ub214\ntrain['var_81_qbinned'].value_counts()","8c272572":"# KFold\ub85c \ub370\uc774\ud130 \ub098\ub220\uc11c RandomForestClassifier \ubaa8\ub378 \ub3cc\ub9bc\n\ncv = StratifiedKFold(n_splits=3, random_state=0)\nforest = RandomForestClassifier(max_depth=15, n_estimators=15, min_samples_leaf=20,\n                                n_jobs=-1)\n\nscores = []\nX = train.drop(\"target\", axis=1).values\ny = train.target.values\n\nfor train_idx, test_idx in cv.split(X, y):\n    x_train = X[train_idx]\n    x_test = X[test_idx]\n    y_train = y[train_idx]\n    y_test = y[test_idx]\n    \n    forest.fit(x_train, y_train)\n    y_proba = forest.predict_proba(x_test)\n    y_pred = np.zeros(y_proba.shape[0])\n    y_pred[y_proba[:,1] >= 0.166] = 1\n    \n    score = roc_auc_score(y_test, y_pred)\n    print(score)\n    scores.append(score)\n\nprint(np.round(np.mean(scores),4))\nprint(np.round(np.std(scores), 4))","635ec870":"# \uc911\uc694 \ubcc0\uc218 \ubf51\uae30 : feature_importances_\n\nimportances = forest.feature_importances_\nfeature_names = train.drop(\"target\", axis=1).columns.values\nidx = np.argsort(importances)[::-1][0:30]\n\nplt.figure(figsize=(20,5))\nsns.barplot(x=feature_names[idx], y=importances[idx]);\nplt.xticks(rotation=90);","0d419b91":"col1 = \"var_81\"\ncol2 = \"var_12\"\nN=70000","ab348aa7":"fig, ax = plt.subplots(1,1, figsize=(20,10))\nsns.kdeplot(train[col1].values[0:N], train[col2].values[0:N])\nax.scatter(train[col1].values[0:N], train[col2].values[0:N],\n           s=2, c=train.target.values[0:N], cmap=\"coolwarm\", alpha=0.5)\nax.set_xlabel(col1)\nax.set_xlabel(col2);","151091b8":"# fig, ax = plt.subplots(1,1, figsize=(20,10))\nsns.kdeplot(train[col1].values[0:N], train[col2].values[0:N])","feb042b2":"# var_81\nsns.kdeplot(train[col1].values[0:N])","9070dd2c":"# var_12\nsns.kdeplot(train[col2].values[0:N])","0890dc29":"combined = train.drop([\"target\", \"Id\"], axis=1).append(test.drop(\"Id\", axis=1))\ncombined.shape","e783fed1":"max_components = 10\nstart_components = 3\nn_splits = 3\nK = train.shape[0] # 400000\n\nX = train.loc[:, original_features].values[0:K]\ny = train.target.values[0:K]","e380d91a":"np.arange(start_components, max_components, 1)","17a8dcd3":"seeds = np.random.RandomState(0).randint(0,100, size=(max_components-start_components))\nseeds","ecbd06cb":"scaler = RobustScaler()\nX_scaled = scaler.fit_transform(X)","5133c4cf":"fit_gaussians = False","6eb94dce":"if fit_gaussians:\n    components = np.arange(start_components, max_components, 1)\n    kf = StratifiedKFold(random_state=0, n_splits=n_splits)\n    \n    scores = np.zeros(shape=(max_components-start_components, n_splits))\n\n    for m in components:\n        split=0\n        print(\"Components \" + str(m))\n        for train_index, test_index in kf.split(X_scaled, y):\n            print(\"Split \" + str(split))\n            x_train, x_test = X_scaled[train_index], X_scaled[test_index]\n            gm = GaussianMixture(n_components=m, random_state=seeds[m-start_components])\n            gm.fit(x_train)\n            score = gm.score(x_test)\n            scores[m-start_components,split] = score\n            split +=1\n    \n    print(np.round(np.mean(scores, axis=1), 2))\n    print(np.round(np.std(scores, axis=1), 2))\n    best_idx = np.argmax(np.mean(scores, axis=1))\n    best_component = components[best_idx]\n    best_seed = seeds[best_idx]\n    print(\"Best component found \" + str(best_component))\n    \nelse:\n    best_seed = seeds[0]\n    best_component = 3","9cbcaa54":"X = train.loc[:, original_features].values\n\ngm = GaussianMixture(n_components=best_component, random_state=best_seed)\nX_scaled = scaler.transform(X)\ngm.fit(X_scaled) # \uc2a4\ucf00\uc77c\ud55c \ub370\uc774\ud130\ub85c \ubaa8\ub378 \ud559\uc2b5","16de8257":"X","28f2bc5a":"gm.score_samples(X_scaled) # \uac01 \uc0d8\ud50c\uc5d0 \ub300\ud55c \uac1c\ubcc4 \uc810\uc218 \ubc30\uc5f4\uc744 \ubc18\ud658","5cc49aa1":"train[\"cluster\"] = gm.predict(X_scaled)\ntrain[\"logL\"] = gm.score_samples(X_scaled)\ntest[\"cluster\"] = gm.predict(test.loc[:, original_features].values)\ntest[\"logL\"] = gm.score_samples(test.loc[:, original_features].values)","3e79bacd":"train.head()","f7e3c756":"test.head()","ba4ef58d":"from sklearn.model_selection import train_test_split\nimport lightgbm as lgb","afbcbb86":"features = [c for c in train.columns if c not in ['Id', 'target']]\n\ncols = [\"target\",\"Id\"]\nX = train.drop(cols, axis=1)\ny = train[\"target\"]\n\nX_test = test.drop(\"Id\",axis=1)\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n#tree_model = DecisionTreeClassifier(random_state=0, max_depth=5, min_samples_split=5).fit(train_X, train_y)\n# test = test.drop('Id', axis=1)","75bda970":"X_test.shape","4ab983b3":"train_X.shape","15e137db":"val_X.shape","c71a0d70":"# params is based on following kernel https:\/\/www.kaggle.com\/brandenkmurray\/nothing-works\n# \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\ub294 \uc124\uc815\ub41c \ud30c\ub77c\ubbf8\ud130 \uac12\uc5d0 \uc804\uc801\uc73c\ub85c \ub2ec\ub824 \uc788\ub2e4.\nparams = {'objective' : \"binary\",  \n               'boost':\"gbdt\", # gbdt : Gradient Boosting Desicion Tree # \uc2e4\ud589\ud558\uace0\uc790 \ud558\ub294 \uc54c\uace0\ub9ac\uc998 \ud0c0\uc785 \uc815\uc758\n               'metric':\"auc\",\n               'boost_from_average':\"false\",\n               'num_threads':8,\n               'learning_rate' : 0.01, # \ucd5c\uc885 \uacb0\uacfc\uc5d0 \ub300\ud55c \uac01\uac01\uc758 Tree\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ubcc0\uc218\n               'num_leaves' : 13, # \uc804\uccb4 Tree\uc758 leave \uc218. Tree \ubaa8\ub378\uc758 \ubcf5\uc7a1\uc131\uc744 \ucee8\ud2b8\ub864\ud558\ub294 \uc8fc\uc694 \ud30c\ub77c\ubbf8\ud130.\n                # \uc774\uc0c1\uc801\uc73c\ub85c num_leaves\uc758 \uac12\uc740 2^(max_depth) \uac12\ubcf4\ub2e4 \uc801\uac70\ub098 \uac19\uc544\uc57c \ud55c\ub2e4. \ub9ce\uc73c\uba74 \uacfc\uc801\ud569 \uc720\ubc1c  \n               'max_depth':-1,  # tree\uc758 \ucd5c\ub300 \uae4a\uc774\n               'tree_learner' : \"serial\",\n               'feature_fraction' : 0.05, # \ubaa8\ub378\uc774 tree\ub97c \ub9cc\ub4e4 \ub54c \ub9e4\ubc88 \uac01\uac01\uc758 iteration\uc5d0\uc11c \ud30c\ub77c\ubbf8\ud130 \uc911 5%\ub97c \ub79c\ub364\ud558\uac8c \uc120\ud0dd\n               'bagging_freq' : 5,\n               'bagging_fraction' : 0.4, # \ub9e4\ubc88 iteration\uc744 \ub3cc \ub54c \uc0ac\uc6a9\ub418\ub294 \ub370\uc774\ud130\uc758 \uc77c\ubd80\ub97c \uc120\ud0dd\ud558\ub294\ub370 \ud2b8\ub808\uc774\ub2dd \uc18d\ub3c4\ub97c \ub192\uc774\uace0 \uacfc\uc801\ud569\uc744 \ubc29\uc9c0\ud560 \ub54c \uc8fc\ub85c \uc0ac\uc6a9\n               'min_data_in_leaf' : 80, # Leaf\uac00 \uac00\uc9c0\uace0 \uc788\ub294 \ucd5c\uc18c\ud55c\uc758 \ub808\ucf54\ub4dc \uc218, \uacfc\uc801\ud569 \ud574\uacb0\uc5d0 \uc0ac\uc6a9, \ub514\ud3f4\ud2b8 20(\ucd5c\uc801\uac12)\n               'min_sum_hessian_in_leaf' : 10.0,\n               'verbosity' : 1}","a17f025e":"import time","311195a1":"# %%time\n# y_pred_lgb = np.zeros(len(X_test))\n\n# num_round = 1000000 # \uc77c\ubc18\uc801\uc73c\ub85c 100 \uc774\uc0c1\n\n# fold_n=5\n# folds = StratifiedKFold(n_splits=fold_n, shuffle=True, random_state=10)\n\n# for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n#     print('Fold', fold_n, 'started at', time.ctime())\n#     X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n#     y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n#     # train \ub370\uc774\ud130\ub97c LightGBM\uc5d0 \ub9de\ub294 \ub370\uc774\ud130 \uc138\ud2b8 \ud3ec\ub9f7\uc73c\ub85c \ubcc0\ud658\n#     train_data = lgb.Dataset(X_train, label=y_train)\n#     valid_data = lgb.Dataset(X_valid, label=y_valid)\n        \n#     lgb_model = lgb.train(params, train_data, num_round,#change 20 to 2000\n#                     valid_sets = [train_data, valid_data], verbose_eval=1000, early_stopping_rounds = 3500)##change 10 to 200\n            \n#     y_pred_lgb += lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\/5 # folds.n_splits","0e138099":"test2 = pd.read_csv('\/kaggle\/input\/santander-customer-transaction-prediction\/test.csv')","57cec384":"# submission_lgb = pd.DataFrame({\n#         \"ID_code\": test2[\"ID_code\"],\n#         \"target\": y_pred_lgb\n#     })\n# submission_lgb.to_csv('submission_lgb.csv', index=False)","db2130fb":"# from catboost import CatBoostClassifier,Pool\n\n# train_pool = Pool(train_X, train_y)\n# cat_model = CatBoostClassifier(\n#                                iterations=3000,# change 25 to 3000 to get best performance \n#                                learning_rate=0.03,\n#                                objective=\"Logloss\",\n#                                eval_metric='AUC',\n#                               )\n# cat_model.fit(train_X,train_y,silent=True)\n# y_pred_cat = cat_model.predict(X_test)","fbb3a3ca":"# submission_cat = pd.DataFrame({\n#         \"ID_code\": test2[\"ID_code\"],\n#         \"target\": y_pred_cat\n#     })\n# submission_cat.to_csv('submission_cat.csv', index=False)","274e2e1d":"train.head()","4ca75426":"test.head()","879e88e0":"target = train['target']","673913b7":"folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\noof = np.zeros(len(train))\npredictions = np.zeros(len(test))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    num_round = 1000000\n    clf = lgb.train(params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3000)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) \/ folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","20560a52":"roc_auc_score(target, oof)","dd50933e":"submission_lgb2 = pd.DataFrame({\n        \"ID_code\": test2[\"ID_code\"],\n        \"target\": predictions\n    })\nsubmission_lgb2.to_csv('submission_lgb2.csv', index=False)","0c1c3090":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.countplot(train.cluster, palette=\"Set2\", ax=ax[0])\nsns.distplot(train.logL, color=\"Dodgerblue\", ax=ax[1]);","8067aed0":"train[\"logL\"].sort_values()","faeb8c98":"train[\"logL\"].argsort() # \uc624\ub984\ucc28\uc21c -> \uc81c\uc77c \ud070 \uac12\uc758 \uc778\ub371\uc2a4\uac00 \ub9e8 \uc544\ub798","879c58de":"train.groupby(\"cluster\").target.value_counts() \/ train.groupby(\"cluster\").size() * 100","a136fda5":"# cluster_occupation\n(train.groupby(\"cluster\").target.value_counts() \/ train.groupby(\"cluster\").size() * 100).loc[:, 1]","4bddefd5":"# target_occupation\n(train.groupby(\"target\").cluster.value_counts() \/ train.groupby(\"target\").size() * 100).loc[1, :]","351a3ce6":"# \uac01 cluster\uac00 target=1\uc77c \ud655\ub960\ncluster_occupation = train.groupby(\"cluster\").target.value_counts() \/ train.groupby(\"cluster\").size() * 100\ncluster_occupation = cluster_occupation.loc[:, 1] \n\n# target=1\uc778 \ub370\uc774\ud130\uac00 \uac01 \ud074\ub7ec\uc2a4\ud130\uc5d0 \uc18d\ud560 \ud655\ub960\ntarget_occupation = train.groupby(\"target\").cluster.value_counts() \/ train.groupby(\"target\").size() * 100\ntarget_occupation = target_occupation.loc[1, :]\ntarget_occupation.index = target_occupation.index.droplevel(\"target\")\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nax[0].set_title(\"How many % of the data per cluster has hot targets?\")\nsns.barplot(cluster_occupation.index, cluster_occupation.values, ax=ax[0], color=\"cornflowerblue\")\nax[0].set_ylabel(\"% of cluster data\")\nax[0].set_ylim([0,100])\n\nax[1].set_title(\"How many % of total hot targets are in one cluster?\")\nsns.barplot(target_occupation.index, target_occupation.values, ax=ax[1], color=\"tomato\")\nax[1].set_ylabel(\"% of hot targets\")\nax[1].set_ylim([0,100]);","444f36f2":"# # KFold\ub85c \ub370\uc774\ud130 \ub098\ub220\uc11c RandomForestClassifier \ubaa8\ub378 \ub3cc\ub9bc\n\n# cv = StratifiedKFold(n_splits=3, random_state=0)\n# forest = RandomForestClassifier(max_depth=15, n_estimators=15, min_samples_leaf=20,\n#                                 n_jobs=-1)\n\n# scores = []\n# X = train.drop(\"target\", axis=1).values\n# y = train.target.values\n\n# for train_idx, test_idx in cv.split(X, y):\n#     x_train = X[train_idx]\n#     x_test = X[test_idx]\n#     y_train = y[train_idx]\n#     y_test = y[test_idx]\n    \n#     forest.fit(x_train, y_train)\n#     y_proba = forest.predict_proba(x_test)\n#     y_pred = np.zeros(y_proba.shape[0])\n#     y_pred[y_proba[:,1] >= 0.166] = 1\n    \n#     score = roc_auc_score(y_test, y_pred)\n#     print(score)\n#     scores.append(score)\n\n# print(np.round(np.mean(scores),4))\n# print(np.round(np.std(scores), 4))","c84b710c":"gm.means_[0]","b29bd7fc":"gm.means_.shape","fad755e3":"plt.figure(figsize=(20,5))\nfor n in range(gm.means_.shape[0]): # \ud074\ub7ec\uc2a4\ud130 3\uac1c -> gm.means_.shape[0] : 3\n    plt.plot(gm.means_[n,:], 'o')\nplt.title(\"How do the gaussian means look like?\")\nplt.ylabel(\"Cluster mean value\")\nplt.xlabel(\"Feature\")","5e84a246":"#### \uc774\ud56d\ubd84\ud3ec\n- \uc9c8\ub7c9\ud568\uc218 : 1, 2, 3 (x\uac12 int)\n- \ubc00\ub3c4\ud568\uc218 : \uc5f0\uc18d\ub41c \uac12 (x\uac12 float)\n\n- ","b4879d45":"### feature \ubf51\uae30!! : starting point!\n\n- \ub79c\ub364 \ud3ec\ub808\uc2a4\ud2b8\ub85c \ub3cc\ub9bc\n- \uc131\ub2a5\uc740 \uc548 \uc88b\uc74c\n- \uc5ec\uae30\uc11c \uc911\uc694 \ubcc0\uc218 \ubf51\uc74c","a0d234ae":"train\n- ID_code(string)\n- target\n- 200 numerical variables, named from var_0 to var_199","42ea59f8":"#### feature importance \ub3d9\uc791 \uc6d0\ub9ac\n- feature importance\ub294 \ud2b8\ub9ac\uae30\ubc18 \ubaa8\ub378\uc5d0\uc11c \uc0ac\uc6a9\ub428\n- \uc911\uc694\ub3c4\ub97c \uad6c\ubd84\ud558\ub294\ub370\uc5d0\ub294 \ud2b8\ub9ac\uc758 \ubd84\ud560\uacfc \ubc00\uc811\ud55c \uad00\ub828\uc774 \uc788\uc74c.\n- \uc989 \ud2b9\uc815 \ubcc0\uc218\uac00 \ud2b8\ub9ac\ub97c \ubd84\ud560\ud558\ub294\ub370 \uc5bc\ub9c8\ub098 \uae30\uc5ec\ub97c \ud588\ub294\uc9c0\uc5d0 \ub530\ub77c \uc911\uc694\ub3c4\uac00 \uacb0\uc815\ub428\n\n**\ud2b8\ub9ac \ubd84\ud560**\n- \ud2b8\ub9ac\ub294 \uc21c\uc218\ub3c4\ub97c \uae30\uc900\uc73c\ub85c \ubd84\ud560. \uc989 \uac00\uc7a5 \uc798 \ubd84\ub958\uc2dc\ud0a4\ub294 \ubcc0\uc218\ub97c \uc21c\uc218\ub3c4\ub77c\ub294 \uae30\uc900\uc73c\ub85c \ud310\ub2e8\ud558\ub294 \uac83\n- \uc21c\uc218\ub3c4 \uacc4\uc0b0 : \uc5d4\ud2b8\ub85c\ud53c, \uc9c0\ub2c8\uacc4\uc218\n- \ud2b9\uc815 \ubcc0\uc218\ub85c \uc778\ud55c \uc21c\uc218\ub3c4\uc758 \ubcc0\ud654\ub7c9\uc744 \ud30c\uc545\ud558\uae30 \uc704\ud574(\ud2b9\uc815 \ubcc0\uc218\uc758 \uc911\uc694\ub3c4\ub97c \ud30c\uc545\ud558\uae30 \uc704\ud574 \uc21c\uc218\ub3c4\uc758 \ubcc0\ud654\ub7c9\uc744 \uacc4\uc0b0) <u>\uc5d4\ud2b8\ub85c\ud53c\ub97c \ud65c\uc6a9\ud55c \uc815\ubcf4\uc774\ub4dd\ub7c9<\/u> \ud639\uc740 <u>\uc9c0\ub2c8\uacc4\uc218\ub97c \uc774\uc6a9\ud55c \uc9c0\ub2c8 split<\/u>\uc744 \uacc4\uc0b0 -> \uc774\ub97c \uae30\uc900\uc73c\ub85c \ud2b8\ub9ac \ubd84\ud560\n- \uc774\ub54c '\uc815\ubcf4\uc774\ub4dd\ub7c9\uc774 \uac00\uc7a5 \ub192\uc740' \ud639\uc740 '\uc9c0\ub2c8 split\uc774 \uac00\uc7a5 \ub0ae\uc740' \ubcc0\uc218\ub97c \uc120\ud0dd\ud558\uc5ec \ud2b8\ub9ac\ub97c \ubd84\ud560\ud558\uace0, \uc911\uc694\ub3c4\uc5d0 \ubc18\uc601\ub41c\ub2e4.  \n\n**feature importance\ub294 \uc65c \uc808\ub300\uc801\uc778 \uc9c0\ud45c\uac00 \ub418\uc9c0 \ubabb\ud560\uae4c?**\n- feature importance\ub294 \ub178\ub4dc\uac00 \ubd84\uae30 \ud560\ub54c\uc758 \uc815\ubcf4 \uc774\ub4dd \ud639\uc740 \uc9c0\ub2c8 \uacc4\uc218\ub9cc\uc744 \uace0\ub824\ud558\uc5ec \uc911\uc694\ub3c4\ub97c \ubd80\uc5ec\ud558\uae30 \ub54c\ubb38\uc5d0 \uacfc\uc801\ud569\uc5d0 \ub300\ud574 \uace0\ub824\ud558\uc9c0 \ubabb\ud568","6acf8db9":"#### \ubc18\uc62c\ub9bc \ubc0f \ubd84\uc704\uc218 \uae30\ubc18 binning\n\n- pd.qcut() : \uc218\uce58\ud615 \ubcc0\uc218\ub97c \ud2b9\uc815 \uad6c\uac04\uc73c\ub85c \ub098\ub208 \ubc94\uc8fc\ud615 \ub808\uc774\ube14\uc744 \uc0dd\uc131\n    - \ub370\uc774\ud130\ub97c \ub3d9\uc77c\ud55c \uae38\uc774\ub85c \ub098\ub204\ub294 \uac83","5e115d8d":"\ubaa8\ub4e0 \ubcc0\uc218\uac00 \uc120\ud615 \uc0c1\uad00\uad00\uacc4\uac00 \uc544\ub2c8\ub2e4. ","7edead5d":"- EDA \ud544\uc694!! \ub370\uc774\ud130 \ud30c\uc545 \ud544\uc694!!\n- \uadf8\ub7f0\ub370 EDA\ub97c \uc5b4\ub5bb\uac8c \ud574\uc57c \ud560 \uc9c0??\n- EDA\ub97c \uc880 \ub354 \ud574\uc11c \uc5b4\ub5bb\uac8c \ubaa8\ub378\ub9c1\ud560\uc9c0 \uc815\ud574\uc57c \ud55c\ub2e4.","7c6ce2e3":"correlation \uad6c\ud574\uc11c \uc120\ud615\uad00\uacc4 \uc544\ub2d8\uc744 \ud655\uc778\ud558\uace0, \uc120\ud615 \ubaa8\ub378 \ub9d0\uace0 \ub2e4\ub978 \ubaa8\ub378\ub85c \ub3cc\ub824\ubcf4\uae30 : basemodel : lightGBM","076c756d":"- \ud074\ub7ec\uc2a4\ud130\ub9c1\uc73c\ub85c \ub370\uc774\ud130 \ubd84\ub958\n- \uc5b4\ub5a4 \uae30\uc900\uc73c\ub85c \ud074\ub7ec\uc2a4\ud130\ub9c1? -> \uac00\uc6b0\uc2dc\uc548 \ubd84\ud3ec\ub3c4?\n- \ubd84\ub958\ubcc4\ub85c target=1\uc774 \uc18d\ud55c \ube44\uc728 \ud655\uc778\ud558\uae30(\uadf8\ub798\ud504)\n- \uc5b4\ub5a4 \ud074\ub7ec\uc2a4\ud130\uc5d0 target=1\uc778 \ub370\uc774\ud130\uac00 \ub9ce\uc740\uc9c0 \ud655\uc778 \uac00\ub2a5, \uc21c\uc11c\ub3c4\n","c656337e":"## \ubaa8\ub378\ub9c1!!","13155e8c":"## \uc81c\ucd9c : \uc2a4\ucf54\uc5b4 0.73194","13daf6e6":"- \uac70\ub798 \uae08\uc561\uacfc \uc0c1\uad00\uc5c6\uc774 \uc55e\uc73c\ub85c \uc5b4\ub5a4 \uace0\uac1d\uc774 \ud2b9\uc815 \uac70\ub798\ub97c \ud560 \uac83\uc778\uc9c0\ub97c \ud30c\uc545\n- \n\n- \ud50c\ub7ab\ud3fc \uacb0\uc815 : \ucf54\ub7a9 \n- \ud15c\ud50c\ub9bf\n    - \ub370\uc774\ud130\uc640 \ubd84\uc11d \ubaa9\uc801\uc744 \ud30c\uc545\ud55c \ud6c4 \uc5b4\ub5a4 \ud504\ub85c\uc138\uc2a4\uc5d0 \ub530\ub77c \ubd84\uc11d\uc744 \uc9c4\ud589\ud560 \uac74\uc9c0(\uc5b4\ub5a4 \uac78 \ud560\uac74\uc9c0!)\n    - \uc798 \uc815\ub9ac\ub41c EDA \uac19\uc774 \ubcf4\uba74\uc11c \ub370\uc774\ud130 \ud30c\uc545 ","79592ee4":"- Gaussian Mixture Model\uc744 \ud559\uc2b5\uc2dc\ud0b4\uc73c\ub85c\uc368 \ub85c\uadf8 \uc6b0\ub3c4(log likelihood)\ub97c \ucd5c\ub300\ud654\ud558\uace0 \uc788\ub2e4.(logL)\n- \ub85c\uadf8 \uc6b0\ub3c4(logL)\uac00 \ub192\uc744 \uc218\ub85d \ub370\uc774\ud130\uac00 \uac00\uc6b0\uc2dc\uc548 \ubd84\ud3ec\uc5d0 \ub354 \uc798 \ub9de\ub294\ub2e4\ub294 \uac83\uc774\ub2e4.\n- \uc62c\ubc14\ub978 n_components\ub97c \uc120\ud0dd\ud558\ub294 \uac83\uc774 \uc5b4\ub835\uae30 \ub54c\ubb38\uc5d0 train \ub370\uc774\ud130\uc758 stratified k fold\ub97c \uc0ac\uc6a9\ud558\uc790.\n- \uc774\ub807\uac8c \ud558\uba74 train subset\uc5d0 \uac00\uc6b0\uc2dc\uc548\uc744 \uc801\ud569\uc2dc\ud0a4\uace0, test subset\uc5d0\uc11c \ub85c\uadf8 \uc6b0\ub3c4\uac00 \uc5bc\ub9c8\ub098 \ud070\uc9c0 \uac80\uc815\ud560 \uc218 \uc788\ub2e4.\n- \uc120\ud0dd\ud55c n_components\uc5d0 \ub300\ud574 3\ubc88(k=3) \uc774 \uc791\uc5c5\uc744 \uc218\ud589\ud558\uba74 solution\uc758 \uc548\uc804\uc131\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \uc5bb\uc744 \uc218 \uc788\ub2e4.\n- **n_components\uac00 \ud074\uc218\ub85d \ub85c\uadf8 \uc6b0\ub3c4 \uac12\uc774 \uac10\uc18c\ud558\ubbc0\ub85c n_components=3\uc77c \ub54c \ucda9\ubd84\ud558\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\ub2e4.**","0b2f1fab":"- train \ub370\uc774\ud130\uc758 target\uc5d0 \ub300\ud55c \ubcc0\uc218\ub4e4\uc758 \ubd84\ud3ec\uac00 \uc5b4\ub5a4\uc9c0?\n\n- \uc120\ud0dd\ub41c \uc0c1\uc704 \ubcc0\uc218\uc5d0 \ub300\ud574 train\uacfc test \ub370\uc774\ud130\uc758 \ud615\uc0c1\uc758 \ubd88\uc77c\uce58\ub97c \uad00\ucc30\ud560 \uc218 \uc788\ub294\uc9c0?","eb30661e":"Q. \uc65c \ub79c\ub364 \ud3ec\ub808\uc2a4\ud2b8\ub85c \uc911\uc694 \ubcc0\uc218\ub97c \ubf51\uc558\ub294\uc9c0?\n\nQ. \ubcc0\uc218 \uc120\ud0dd \ubc29\ubc95\uc73c\ub85c\ub294 \ub610 \uc5b4\ub5a4 \uac83\uc774 \uc788\ub294\uc9c0?\n\nQ. \uc911\uc694 \ubcc0\uc218\ub97c \uba87\uac1c\ub97c \ubf51\uc544\uc11c \ud0d0\uc0c9\ud558\ub294 \uac83\uc774 \uc804\uccb4 EDA\uc5d0 \uc5b4\ub5a4 \ub3c4\uc6c0\uc774 \ub418\ub294\uc9c0? ","7a060f07":"### feature importance\n- **\ud2b8\ub9ac \uae30\ubc18 \ubaa8\ub378**(randomforest, xgboost, lightgbm \ub4f1)\uc5d0\uc11c \uae30\ubcf8\uc801\uc73c\ub85c feature importance\ub97c API \ud639\uc740 \ubaa8\ub378 \ub0b4\uc7a5 \ud568\uc218\ub85c \uc81c\uacf5\n- API(plot_importance)\ub97c import\ud558\uac70\ub098 **feature_importances_** \ub0b4\uc7a5 \ud568\uc218\ub97c \uc774\uc6a9\ud574\uc11c \uc190\uc27d\uac8c \uad6c\ud604\n- \ud558\uc9c0\ub9cc \uc774\ub97c \ud1b5\ud574 \uad6c\ud55c \uc9c0\ud45c\uac00 \uc808\ub300\uc801\uc778 \uac83\uc774 \uc544\ub2d8.\n- feature importance\ub97c \uace0\ub824\ud558\uc5ec \ud2b9\uc131\ubcc4\ub85c A\/B test \ub97c \uc9c4\ud589\ud558\uba70 feature selection\uc744 \ud558\ub294 \uac83\uc774 \uc88b\ub2e4.","f038f26d":"### lightGBM\n\n- https:\/\/www.kaggle.com\/mjbahmani\/santander-ml-explainability","b7ef8963":"### catboost\n- https:\/\/www.kaggle.com\/mjbahmani\/santander-ml-explainability","e2179f0f":"Only some features are important to separate the structure of the data.","eafdb786":"- \uadf8\ub798\uc11c \uc5b4\ub5a4 \ud53c\ucc98\ub97c \uc0ac\uc6a9\ud574\uc57c \ub418\ub294\ub370?\n- \uc774\uc0c1\uce58 \ucc98\ub9ac\ub294 \uc5b4\ub5bb\uac8c \ud558\ub294\ub370?\n- \ud53c\ucc98 \uc120\ud0dd\uc744 \ud558\uae34 \ud558\ub294 \uac70\uc57c?","dd62ec54":"### lightGBM\n- https:\/\/www.kaggle.com\/gpreda\/santander-eda-and-prediction","c0182b1c":"\uc810\uc218(roc_auc_score)\uac00 \uadf8\ub2e5 \uc88b\uc9c0 \uc54a\ub2e4.","2f7bccd7":"- \uadf8\ub7ec\uba74 target\uc5d0 \ub530\ub77c \ub370\uc774\ud130\uc758 \ubd84\ud3ec\uac00 \ub9ce\uc774 \ub2e4\ub978 \ubcc0\uc218\ub4e4\uc774 \uc120\ud0dd\ub41c \uac83\uc77c \uac70\ub2e4.","22183b2d":"- train\uc758 target=0\uacfc test\uac00 \ube44\uc2b7\ud55c \ubaa8\uc591\uc774\ub2e4.\n- train\uc758 target=1\uc774 test\ub294 \ub9ce\uc774 \ub2e4\ub974\ub2e4. \uc65c \ub2e4\ub97c\uae4c?\n- test\uc5d0\ub3c4 target=0\uc774 \ud6e8\uc52c \ub9ce\uc744 \uac83\uc774\ub2e4.(\uac70\ub798\ub97c \ud558\uc9c0 \uc54a\uc744 \uace0\uac1d) => class imbalaced\n- target=1\uc740 \ub370\uc774\ud130\uc758 \uc218\uac00 \uc801\ub2e4.(\uac70\ub798\ub97c \ud560 \uace0\uac1d)\n- target=1\uacfc target=0\uc758 \ubd84\ud3ec \ubaa8\uc591\uc774 \ub2ec\ub77c\uc57c \ud655\uc2e4\ud558\uac8c \uad6c\ubd84 \uac00\ub2a5\ud558\uace0, \uc774\ub7ec\ud55c \ubcc0\uc218\ub97c \uc0ac\uc6a9\ud574\uc57c \uc608\uce21 \uc815\ud655\ub3c4\ub97c \ub192\uc77c \uc218 \uc788\ub2e4. ","45114807":"- cluster 2 has more hot target(1) than others\n- hot target(1)\uc758 \ub300\ubd80\ubd84\uc774 cluster 2\uc5d0 \uc704\uce58\ud55c\ub2e4.","33334ef8":"- target=1\uc778 \ub370\uc774\ud130\ub4e4\uc774 \uac11\uc790\uae30 \ub204\uc801\ub418\uc5b4\uc11c \uac70\uc758 \ub118\uc5b4\uac00\uc9c0 \uc54a\ub294 \ub0a0\uce74\ub85c\uc6b4 \uc9c0\uc810\uc774 \uc788\ub2e4.\n- \uc608\ub97c \ub4e4\uc5b4, 81\ubc88 \ubcc0\uc218\uc5d0\uc11c\ub294 10\uc5d0, 12\ubc88 \ubcc0\uc218\uc5d0\uc11c\ub294 13.5\uc5d0 \ub370\uc774\ud130\uac00 \ub204\uc801\ub418\uc5b4 \ub0a0\uce74\ub86d\uac8c \uc19f\uc740 \uc9c0\uc810\uc774 \uc788\ub2e4.(limit)\n- This finding could be a nice entry point(\uc9c4\uc785\uc810) for further feature engineering. => \uc774\ud6c4 \ud53c\ucc98 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1\uc5d0 \uc88b\uc740 \ucd9c\ubc1c\uc120\uc774 \ub420 \uac70\ub2e4.?","7065daef":"- some peeks for variables 81, 12\n- test \ub370\uc774\ud130\uc5d0\uc11c \ub204\uc801 \ubc00\ub3c4\uac00 \ub354 \ub0ae\ub2e4","a42f1332":"### feature engineering","ecc17d6b":"0.005\ub85c \uc0c1\uad00\uacc4\uc218\uac00 \ub9e4\uc6b0 \ub0ae\ub2e4!","b15c6fc9":"- top 10 feature\ub97c \ubf51\uc544\uc11c \uc0ac\uc6a9\ud558\uba74 \ub370\uc774\ud130\uc758 \ubcf8\uc9c8\uc744 \uc774\ud574\ud558\ub294\ub370 \ub3c4\uc6c0\uc774 \ub418\uace0, \uc0c8\ub85c\uc6b4 \ubcc0\uc218\ub97c \uc0dd\uc131\ud558\ub294\ub370 \uc5b4\ub5a0\ud55c \uc544\uc774\ub514\uc5b4\ub97c \uc5bb\uc744 \uc218 \uc788\uc744 \uac83\uc774\ub2e4.\n- \ub79c\ub364 \ud3ec\ub808\uc2a4\ud2b8\ub97c \uc774\uc6a9\ud574\uc11c \uc911\uc694 \ubcc0\uc218\ub97c \uc120\ud0dd -> \uc120\ud615 \uad00\uacc4\uac00 \uc5c6\uae30 \ub54c\ubb38\uc5d0 nonlinear model\uc744 \uc0ac\uc6a9\ud558\uba74 \uc88b\uc744 \uac83\uc774\ub2e4.(\ubcc0\uc218\uc758 \uc911\uc694\ub3c4(importance), \uc0c1\ud638\uc791\uc6a9(interaction)\uc744 \ubc1c\uacac\ud558\ub294\ub370 \ub3c4\uc6c0)\n- \ub79c\ub364 \ud3ec\ub808\uc2a4\ud2b8 \uc0ac\uc6a9\ud558\uba74 \uc5b4\ub5a4 \ubc29\uc2dd\uc73c\ub85c top 10 feature\ub97c \ubf51\ub294\uac00? \uae30\uc900\uc774 \ubb34\uc5c7\uc778\uac00?","f5a79c6d":"### ID_code \ube7c\uace0 \uc804\ubd80 numerical variable","f9afeb57":"#### \uc0c8\ub85c\uc6b4 \ubcc0\uc218 \uc911\uc694\ub3c4","bf48cf4a":"### class imbalanced \ubb38\uc81c \uc788\uc74c \n\n- stratifiedKFold\n- \uc131\ub2a5\ud3c9\uac00 : ?","28d3efde":"## \uc81c\ucd9c : \uc2a4\ucf54\uc5b4 0.84381 ","7836f2b6":"- train, test PDF \ub3d9\uc77c!!\n- train\uc758 target=0\uacfc target=1\uc758 PDF \uaf64 \ube44\uc2b7\ud568","59fb9d12":"### \uacb0\uce21\uce58 \uc5c6\uc74c","ff1c2e9f":"- train \ub370\uc774\ud130\uc5d0\uc11c 1\uc774\ub77c\uace0 \uc608\uce21\ud55c \uac83\ub4e4\uc758 \ud655\ub960\uac12\ub3c4 \uadf8\ub2e5 1\uc5d0 \uac00\uae5d\uc9c0 \uc54a\ub2e4. -> cut-off\uac00 \uc911\uc694\ud560\uae4c? \ud588\uc9c0\ub9cc \ud3c9\uac00 \uc9c0\ud45c\uac00 auc\ub2c8\uae4c \uc0c1\uad00\uc5c6\ub124.\n    - \uace1\uc120\uc774 \uc644\ub9cc\ud558\uae34 \ud558\uc9c0\ub9cc \uc81c\uc77c \ub192\uc740 \uac12\uc740 0.2 \uc815\ub3c4\n- test\ub294 \ub300\ubd80\ubd84 0\uc5d0 \uac00\uae4c\uc6b4 \ud655\ub960\uac12\uc73c\ub85c \uc608\uce21\ud588\ub2e4. -> \ub2f9\uc5f0 : 0\uc774 \ub9ce\uc73c\ub2c8\uae4c\n- \uba87 \uc5c6\ub294 1\uc744 \ucc3e\uc544\ub0b4\ub294 \uac83\uc774 \uc911\uc694!","e3141256":"### Gaussian Mixture Clustering \n\n#### Gaussian Mixture Model(GMM) : \n- \uac1c\ubcc4 \ub370\uc774\ud130\uac00 \uac00\uc6b0\uc2dc\uc548 \ubd84\ud3ec\uc5d0 \uc18d\ud55c\ub2e4\uace0 \uac00\uc815\uc744 \ud55c \uc0c1\ud0dc\uc5d0\uc11c \ud2b9\uc815 \uc815\uaddc\ubd84\ud3ec\uc5d0 \uc18d\ud560 \ud655\ub960\uc744 \ucd94\uc815 => \ud655\ub960 \uae30\ubc18 \uad70\uc9d1\ud654\n- \uac00\uc6b0\uc2dc\uc548 \ubd84\ud3ec = \uc815\uaddc\ubd84\ud3ec\n- \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc740 \uc11c\ub85c \ub2e4\ub978 \uc815\uaddc\ubd84\ud3ec \ud615\ud0dc\ub97c \uac00\uc9c4 \uc5ec\ub7ec \uac00\uc9c0 \ud655\ub960 \ubd84\ud3ec \uace1\uc120\uc73c\ub85c \uad6c\uc131\ub420 \uc218 \uc788\uc73c\uba70, \uc774\ub7ec\ud55c \uc11c\ub85c \ub2e4\ub978 \uc815\uaddc\ubd84\ud3ec\uc5d0 \uae30\ubc18\ud574 \uad70\uc9d1\ud654\ub97c \uc218\ud589\ud558\ub294 \uac83\uc774 GMM \uad70\uc9d1\ud654 \ubc29\uc2dd\uc774\ub2e4.\n- \uc608\ub97c \ub4e4\uc5b4 1000\uac1c\uc758 \ub370\uc774\ud130\uac00 \uc788\ub2e4\uba74 \uc774\ub97c \uad6c\uc131\ud558\ub294 \uc5ec\ub7ec \uac1c\uc758 \uc815\uaddc \ubd84\ud3ec \uace1\uc120\uc744 \ucd94\ucd9c\ud558\uace0, \uac1c\ubcc4 \ub370\uc774\ud130\uac00 \uc774 \uc911 \uc5b4\ub5a4 \uc815\uaddc\ubd84\ud3ec\uc5d0 \uc18d\ud558\ub294\uc9c0 \uacb0\uc815\ud558\ub294 \ubc29\uc2dd\n- \uc774\uc640 \uac19\uc740 \ubc29\uc2dd\uc740 GMM\uc5d0\uc11c\ub294 \ubaa8\uc218 \ucd94\uc815\uc774\ub77c\uace0 \ud55c\ub2e4. \ub300\ud45c\uc801\uc73c\ub85c 2\uac00\uc9c0 \ucd94\uc815\n    - 1) \uac1c\ubcc4 \uc815\uaddc \ubd84\ud3ec\uc758 \ud3c9\uade0\uacfc \ubd84\uc0b0\n    - 2) \uac01 \ub370\uc774\ud130\uac00 \uc5b4\ub5a4 \uc815\uaddc \ubd84\ud3ec\uc5d0 \ud574\ub2f9\ub418\ub294\uc9c0\uc758 \ud655\ub960\n- GaussianMixture \uac1d\uccb4\uc758 \uc8fc\uc694 \ud30c\ub77c\ubbf8\ud130 : n_components\n    - GaussianMixture\uc758 \ubaa8\ub378\uc758 \ucd1d \uac1c\uc218. \uad70\uc9d1\ud654 \uac1c\uc218\n- GMM\uc774 \ud2b9\ud788 \uc798 \uc801\uc6a9\ub418\ub294 \ub370\uc774\ud130 \ubd84\ud3ec : \ud0c0\uc6d0\ud615\uc73c\ub85c \uae38\uac8c \ub298\uc5b4\uc9c4 \ub370\uc774\ud130 \ubd84\ud3ec\n\n#### RobustScaler\n- \ud45c\uc900 \uc815\uaddc\ud654\n- sklearn.preprocessing.RobustScaler\n- \uc911\uc559\uac12(median)\uacfc IQR(interquartile range, \uc0ac\ubd84\uc704\uac12) \uc0ac\uc6a9. \n- **\uc774\uc0c1\uce58\uc758 \uc601\ud5a5\uc744 \ucd5c\uc18c\ud654**\n- \uc911\uc559\uac12\uc744 \uc81c\uac70\ud558\uace0 Quantile \ubc94\uc704(\uae30\ubcf8\uac12\uc740 IQR)\uc5d0 \ub530\ub77c \ub370\uc774\ud130\ub97c \uc2a4\ucf00\uc77c\ub9c1\n- IQR\uc740 1\ubd84\uc704(25\ubd84\uc704)\uc640 3\ubd84\uc704(75\ubd84\uc704) \uc0ac\uc774\uc758 \ubc94\uc704\uc774\ub2e4.\n- \ub370\uc774\ud130\uc5d0\uc11c \uc774\uc0c1\uce58\uc758 \uc874\uc7ac\ub97c \ud655\uc778\ud558\uace0 \uadf8\ub798\uc11c \uc774 \uc2a4\ucf00\uc77c\ub7ec\ub97c \uc0ac\uc6a9\ud558\uaca0\ub2e4\uace0 \ud558\uba74 \ub418\uaca0\ub2e4. ","2766780f":"### \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\n\n\ub354 \ube60\ub978 \uc18d\ub3c4\ub97c \uc704\ud574 :\n\n- bagging_fraction\uacfc baggin_freq \uc744 \uc124\uc815\ud558\uc5ec bagging \uc744 \uc801\uc6a9\n- feature_fraction\uc744 \uc124\uc815\ud558\uc5ec feature sub-sampling\uc744 \ud558\uae30\n- \uc791\uc740 max_bin \uac12\uc744 \uc0ac\uc6a9\n- save_binary \ub97c \uac12\uc744 \ud1b5\ud574 \ub2e4\uac00\uc624\ub294 \ud559\uc2b5\uc5d0\uc11c \ub370\uc774\ud130 \ub85c\ub529 \uc18d\ub3c4\ub97c \uc904\uc774\uae30\n- parallel learning \ubcd1\ub82c \ud559\uc2b5\uc744 \uc801\uc6a9\n- early_stopping_round : \ub9cc\uc57d \uc5b4\ub5a4 validation \ub370\uc774\ud130 \uc911 \ud558\ub098\uc758 \uc9c0\ud45c\uac00 \uc9c0\ub09c early_stopping_round \ub77c\uc6b4\ub4dc\uc5d0\uc11c \ud5a5\uc0c1\ub418\uc9c0 \uc54a\uc558\ub2e4\uba74 \ud559\uc2b5\uc744 \uc911\ub2e8\ud55c\ub2e4. \uc774\ub294 \uc9c0\ub098\uce5c iteration\uc744 \uc904\uc774\ub294\ub370 \ub3c4\uc6c0\uc774 \ub41c\ub2e4.\n\n\n\ub354 \ub098\uc740 \uc815\ud655\ub3c4\ub97c \uc704\ud574 :\n\n- \ud070 max_bin \uac12\uc744 \uc0ac\uc6a9 (\uc544\ub9c8 \uc18d\ub3c4\ub294 \ub290\ub824\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4)\n- \uc791\uc740 learning_rate \uac12\uc744 \ud070 num_iterations \uac12\uacfc \ud568\uaed8 \uc0ac\uc6a9\n- \ud070 num_leaves \uac12\uc744 \uc0ac\uc6a9 (\uc544\ub9c8 \uacfc\uc801\ud569\uc744 \uc720\ubc1c\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4)\n- \ub354 \ud070 \ud2b8\ub808\uc774\ub2dd \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\n- dart\ub97c \uc0ac\uc6a9\n- \ubc94\uc8fc\ud615 feature\ub97c \uc0ac\uc6a9\n\n\n\uacfc\uc801\ud569\uc744 \ud574\uacb0\ud558\uae30 \uc704\ud574 :\n\n- \uc791\uc740 max_bin \uac12\uc744 \uc0ac\uc6a9\n- \uc791\uc740 num_leaves \uac12\uc744 \uc0ac\uc6a9\n- min_data_in_leaf \uc640 min_sum_hessian_in_leaf \ud30c\ub77c\ubbf8\ud130\ub97c \uc0ac\uc6a9\n- bagging_fraction \uacfc bagging_freq \uc744 \uc0ac\uc6a9\ud558\uc5ec bagging \uc744 \uc801\uc6a9\n- feature_fraction\uc744 \uc138\ud305\ud558\uc5ec feature sub-sampling\uc744 \ud558\uae30\n- lambda_l1, lambda_l2 \uadf8\ub9ac\uace0 min_gain_to_split \ud30c\ub77c\ubbf8\ud130\ub97c \uc774\uc6a9\ud574 regularization (\uc815\uaddc\ud654) \ub97c \uc801\uc6a9\n- max_depth \ub97c \uc124\uc815\ud574 Deep Tree \uac00 \ub9cc\ub4e4\uc5b4\uc9c0\ub294 \uac83\uc744 \ubc29\uc9c0\n\n[\ucd9c\ucc98]https:\/\/nurilee.com\/2020\/04\/03\/lightgbm-definition-parameter-tuning\/","1ac45459":"\ubcc0\uc218\ub97c \ubf51\uc544\uc11c \uc598\ub124\ub97c \uac00\uc9c0\uace0 \ub370\uc774\ud130 \uc774\ud574 \uc5ec\ud589\uc744 \ub5a0\ub098\ubcf4\uc790~","dcbf2b6c":"- **\ub370\uc774\ud130 spot\ub2f9 \uac1c\ubcc4 \uc810\uc218(logL)\ub294 \ubc00\ub3c4\ub97c \uce21\uc815\ud558\ub294 \ucc99\ub3c4\ub85c \uc774\ud574\ud560 \uc218 \uc788\ub2e4.** \n- logL\uc774 \ub0ae\uc73c\uba74 \ub370\uc774\ud130 spot\uc774 \ub2e4\ub978 \ub370\uc774\ud130 \uc9c0\uc810\uacfc \uba40\ub9ac \ub5a8\uc5b4\uc9c4 \uacf3\uc5d0 \uc788\ub294 \uac83\uc774\ub2e4. -> \uba40\ub9ac \ub5a8\uc5b4\uc838 \uc788\ub2e4? -> \uc774\uc0c1\uce58\uc778\uac00?\n- logL\uc774 \ub192\uc73c\uba74 \uc774\uc6c3\uc774 \ub9ce\uc744 \uac83\uc774\ub2e4.(\uc8fc\ubcc0\uc5d0 \ub370\uc774\ud130\uac00 \ub9ce\ub2e4.) -> \uc774\uc0c1\uce58 \uc544\ub2d8\n- **\ub530\ub77c\uc11c \uac1c\ubcc4 logL-score\ub294 \ub370\uc774\ud130\uc758 \uc774\uc0c1\uce58\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud560 \uc218 \uc788\ub2e4.**\n    - \uad6c\uccb4\uc801\uc73c\ub85c logL-score\ub97c \ubcf4\uace0 \uc5b4\ub5bb\uac8c \uc774\uc0c1\uce58\ub97c \ud655\uc778\ud558\ub294\ub370?\n    - \uac00\uc7a5 \ub0ae\uc740 \ub370\uc774\ud130\ub4e4\uc744 \uc81c\uac70\ud574\uc57c \ub418\ub294 \uac70\uc57c?","72efb982":"## \uc81c\ucd9c : \uc2a4\ucf54\uc5b4 0.89692","0a4843e3":"- \uc774 \uc608\uce21\uac12\uc744 \uc81c\ucd9c\ud588\ub354\ub2c8 public leaderboard\uc5d0\uc11c \uc810\uc218 0.662 \ubc1b\uc74c\n- submission[\"target\"] = y_proba"}}