{"cell_type":{"49d3d4cf":"code","41aab9e2":"code","8707473d":"code","febd28e6":"code","c191c36f":"code","c2ee9c0d":"code","b9276ef2":"code","fd089b22":"code","54a53950":"code","a92ad837":"code","7d805c3b":"code","b3d574d2":"code","22723c95":"code","47cfe4d5":"code","f4de4214":"code","9ccf1735":"code","37d66482":"code","d64d3a29":"code","d5739fc7":"code","6eb0e883":"code","2a851d07":"code","52a654ce":"code","bb39be94":"code","20afcc1d":"code","740956f5":"code","5715684a":"code","e3a6560f":"code","3f700dc7":"code","83e74f26":"markdown","a33a7f22":"markdown","0480784d":"markdown","b8840d7b":"markdown","f405f2b0":"markdown","cff58da2":"markdown","4125c86f":"markdown","aeb1b3bd":"markdown","771fa9b7":"markdown","95c71ecd":"markdown","d762311b":"markdown","91029700":"markdown","e1937fbb":"markdown","8d72c7d2":"markdown","ee79220a":"markdown","bd28383a":"markdown","c96a1165":"markdown"},"source":{"49d3d4cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","41aab9e2":"# Import Dependencies\n%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler \n\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn import svm\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.layers.advanced_activations import ReLU\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten,Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\nimport keras\nimport cv2\nimport tensorflow\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix, confusion_matrix\n\n\n\n\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","8707473d":"Dataset = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\n","febd28e6":"Dataset.head()","c191c36f":"Dataset.info()","c2ee9c0d":"Dataset.shape","b9276ef2":"display(Dataset.isnull().sum())\n","fd089b22":"Dataset.isnull().sum().plot(kind='bar',color = 'pink')\nplt.title(\"Missing Data \")\nplt.show()","54a53950":"display(Dataset.DEATH_EVENT.value_counts())\n","a92ad837":"plt.figure(figsize=(10,8))\n\n\nsns.countplot(x='DEATH_EVENT', data=Dataset , palette='pink');\n","7d805c3b":"sns.pairplot(Dataset, hue=\"DEATH_EVENT\")\n","b3d574d2":"male_survived = Dataset[Dataset[\"sex\"]==1]\nfemale_survived = Dataset[Dataset[\"sex\"]==0]\nmale_sur= male_survived[male_survived[\"DEATH_EVENT\"]==0]\nfemale_sur= female_survived[female_survived[\"DEATH_EVENT\"]==0]\n\n\n\nlabels = ['Male_Survived','Male_Not Survived', \"Female_Survived\", \"Female_Not Survived\"]\n","22723c95":"\nvalues = [len(male_survived[Dataset[\"DEATH_EVENT\"]==0]),len(male_survived[Dataset[\"DEATH_EVENT\"]==1]),\n         len(female_survived[Dataset[\"DEATH_EVENT\"]==0]),len(female_survived[Dataset[\"DEATH_EVENT\"]==1])]\nfig = go.Figure(data=[go.Pie(labels=labels,values=values,hole=.3)])\nfig.update_layout(\n    title_text = \"gender Case :\"\n)\nfig.show()","47cfe4d5":"\nplt.subplots(figsize=(11, 11)) \nsns.heatmap(Dataset.corr(),annot=True)","f4de4214":"minmax_scaler = MinMaxScaler()\n\nDataset_normal = pd.DataFrame(minmax_scaler.fit_transform(Dataset), columns = Dataset.columns)\n\nDataset_normal","9ccf1735":"X = Dataset_normal.loc[:, Dataset_normal.columns != 'DEATH_EVENT']\ny =Dataset_normal['DEATH_EVENT']","37d66482":"\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=2)","d64d3a29":"X_train.shape","d5739fc7":"y_train.shape","6eb0e883":"model = SVC(kernel='rbf',random_state=1,C=1, gamma = 0.1)\n","2a851d07":"model.fit(X_train,y_train)\n","52a654ce":"y_pred = model.predict(X_test)\n","bb39be94":"print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n","20afcc1d":"Conv = confusion_matrix(y_test,y_pred)\nConv","740956f5":"classifier = KNeighborsClassifier(n_neighbors=5)\n","5715684a":"classifier.fit(X_train,y_train)\n\n","e3a6560f":"y_pred = classifier.predict(X_test)","3f700dc7":"print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred)*100)\n","83e74f26":"### predict model","a33a7f22":"# Check Missing Data","0480784d":"##### Fit Model","b8840d7b":"# Preprocessing for Data","f405f2b0":"### there survived are 203 and not survived are 96\n","cff58da2":"### KNN","4125c86f":"# Build Model","aeb1b3bd":"#### Accuracy","771fa9b7":"# Split data","95c71ecd":"# Visulization","d762311b":"### fit Model","91029700":"# Accurcy","e1937fbb":"### Normalize Data","8d72c7d2":"![image.png](attachment:image.png)","ee79220a":"#### predict Model","bd28383a":"### SVM","c96a1165":"# Correlation"}}