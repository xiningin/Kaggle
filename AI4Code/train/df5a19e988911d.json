{"cell_type":{"6b2e5177":"code","25326f52":"code","452d3368":"code","e139a644":"code","c09cfd5c":"code","b5dd6faa":"code","1dbc0ba9":"code","0ab6f3e3":"code","664440fa":"code","f444248c":"code","4c18a663":"code","9a4fd741":"code","1b7626df":"code","880e00e2":"code","6b2d8565":"code","c60f589e":"code","f9d68425":"code","1834d2fb":"code","d9cb72d1":"code","1749ef3e":"code","34c1ffe5":"code","cdf32f33":"code","f677ae6b":"code","0096ceee":"code","fc1bf01e":"code","88a453e6":"code","6173e87e":"code","a7ea753c":"code","6db0950e":"code","ba3be6dd":"code","e29d2000":"code","bfae0042":"code","4d5bcf4d":"code","ef6b34b1":"code","ea7081b5":"code","3757a7a1":"code","b31785d6":"code","d55b6aea":"code","7e2fb757":"code","8c841f27":"code","38675bc3":"code","40393ab9":"code","0ce0dadb":"code","f7695caf":"code","4082aeec":"code","cf24aaf2":"code","d8aa0676":"code","e86ac780":"markdown","c3107bd8":"markdown","fd5de3be":"markdown","eb182c35":"markdown","10d01d85":"markdown","4ed783d6":"markdown","d8bdf373":"markdown","e6e672cf":"markdown","ec4fbed9":"markdown","13555f98":"markdown","b33baafc":"markdown","f787cc58":"markdown","d8ba610a":"markdown","42d3415b":"markdown","f2baca21":"markdown","2874bb17":"markdown","3513ca96":"markdown","466c95d4":"markdown","d50227a9":"markdown","804380d4":"markdown","5f6fb5e2":"markdown","47eeda1f":"markdown","b4ef8b84":"markdown","de6b1f25":"markdown","def53707":"markdown","9b6d9a47":"markdown","6b4ead1b":"markdown","44a849f3":"markdown","c81bd0d1":"markdown","a91caf81":"markdown","26f487d5":"markdown"},"source":{"6b2e5177":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","25326f52":"import torch\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate","452d3368":"torch.cuda.set_device(0)","e139a644":"torch.cuda.get_device_name()","c09cfd5c":"traindf = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv\")\ntraindf.head()","b5dd6faa":"traindf.shape","1dbc0ba9":"classdata = (traindf.healthy + traindf.multiple_diseases+\n             traindf.rust + traindf.scab)","0ab6f3e3":"classdata.head()","664440fa":"any(classdata > 1)","f444248c":"#pathstr = \"\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/\"\ntraindf[\"image_id\"] =traindf[\"image_id\"].astype(\"str\") + \".jpg\"\ntraindf.head()","4c18a663":"traindf[\"label\"] = (0*traindf.healthy + 1*traindf.multiple_diseases+\n             2*traindf.rust + 3*traindf.scab)\ntraindf.drop(columns=[\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"],inplace=True)","9a4fd741":"traindf.head()","1b7626df":"# Creation of transformation object\ntransformations = get_transforms(do_flip = True,\n                                 flip_vert=True, \n                                 max_lighting=0.1, \n                                 max_zoom=1.05,\n                                 max_warp=0.,\n                                 max_rotate=15,\n                                 p_affine=0.75,\n                                 p_lighting=0.75\n                                )","880e00e2":"pathofdata = \"\/kaggle\/input\/plant-pathology-2020-fgvc7\/\"","6b2d8565":"data  = ImageDataBunch.from_df(path=pathofdata, \n                               df=traindf, \n                               folder=\"images\",\n                               label_delim=None,\n                               valid_pct=0.2,\n                               seed=100,\n                               fn_col=0, \n                               label_col=1, \n                               suffix='',\n                               ds_tfms=transformations, \n                               size=512,\n                               bs=64, \n                               val_bs=32,\n                               )","c60f589e":"data.show_batch(rows=3, figsize=(10,7))","f9d68425":"data = data.normalize()","1834d2fb":"learner = cnn_learner(data, \n                      models.resnet34, \n                      pretrained=True\n                      ,metrics=[error_rate, accuracy]).to_fp16()","d9cb72d1":"learner.model_dir = '\/kaggle\/working\/models'","1749ef3e":"learner.lr_find(start_lr=1e-07,end_lr=0.2, num_it=100) \nlearner.recorder.plot(suggestion=True)","34c1ffe5":"mingradlr = learner.recorder.min_grad_lr\nprint(mingradlr)","cdf32f33":"lr = mingradlr\nlearner.fit_one_cycle(10, lr)\n","f677ae6b":"learner.unfreeze()\nlearner.lr_find(start_lr=1e-07,end_lr=0.2, num_it=100) \nlearner.recorder.plot(suggestion=True)","0096ceee":"mingradlr1 = learner.recorder.min_grad_lr\nprint(mingradlr1)","fc1bf01e":"# Differential learning \nlearner.fit_one_cycle(7, slice(mingradlr1, mingradlr1\/20))","88a453e6":"learner.show_results()","6173e87e":"interp = ClassificationInterpretation.from_learner(learner)\ninterp.plot_confusion_matrix(title='Confusion matrix')","a7ea753c":"testdf = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv\")\ntestdf.head()","6db0950e":"sampsubmit = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\")\nsampsubmit.head()","ba3be6dd":"pathofdata = \"\/kaggle\/input\/plant-pathology-2020-fgvc7\/\"","e29d2000":"testdata= ImageList.from_folder(pathofdata+\"images\")","bfae0042":"testdata.filter_by_func(lambda x: x.name.startswith(\"Test\"))","4d5bcf4d":"testdata.items[0]","ef6b34b1":"img1 = open_image(testdata.items[0])\nimg2 = open_image(testdata.items[1])","ea7081b5":"learner.predict(img1)","3757a7a1":"val1 = learner.predict(img1)[2].tolist()\nval2 = learner.predict(img2)[2].tolist()","b31785d6":"val1","d55b6aea":"tdtd = testdata.items[0]","7e2fb757":"tdtd.name[:-4:]","8c841f27":"resultlist = []\nfor item in testdata.items:\n    img = open_image(item)\n    predval = learner.predict(img)[2].tolist()\n    predval.insert(0,item.name[:-4:])\n    resultlist.append(predval)","38675bc3":"resultlist[0:5]","40393ab9":"resultdf = pd.DataFrame(resultlist)\nresultdf.columns = sampsubmit.columns\nresultdf.head()","0ce0dadb":"resultdf.set_index(\"image_id\",inplace=True)\nresultdf.head()","f7695caf":"resultdf = resultdf.loc[sampsubmit.image_id,:]\nresultdf.head()","4082aeec":"resultdf.reset_index(inplace=True)","cf24aaf2":"resultdf.head()","d8aa0676":"resultdf.to_csv(\"submit.csv\",index=False)","e86ac780":"# Differential learning \n\nDifferential learning is also a very important concept. According to this concept, different learning rate is applied at different layer of deep neural network. In following line of code we are applying differential learning rate.","c3107bd8":"# Training the leraner \n\nWe are going to train our learner using fit one cycle method. Learner is trained by 10 cycle. We have allready got the optimized learning rate suggestion from fastai. ","fd5de3be":"In classdata we can see that, no value is greater than 1. Hence it is not multiclass classification problem.  We are going to take the following as class. Fastai can read image file path and its associated class from a Pandas DataFrame too. \n                              We are having file name and its class in a dataframe **traindf**. But we need the data is following format \n                              \n|     name     | label |\n|:------------:|-------|\n| Train_0.jpg  | 3     |\n| Train_1.jpg  | 1     |\n| Train_2.jpg  | 0     |","eb182c35":"## A discussion on output of confusion matrix.\n\nWe have denoted multiple_diseases as 1. And resnet34 is not very good in classifying, if image leaf is having multiple_diseases. ","10d01d85":"# Data \n\n## Data Description\nGiven a photo of an apple leaf, can you accurately assess its health? This competition will challenge you to distinguish between leaves which are healthy, those which are infected with apple rust, those that have apple scab, and those with more than one disease.\n\n## Files\n\n### train.csv\nimage_id: the foreign key for the parquet files\ncombinations: one of the target labels\nhealthy: one of the target labels\nrust: one of the target labels\nscab: one of the target labels\nimages\nA folder containing the train and test images, in jpg format.\n\n### test.csv\nimage_id: the foreign key for the parquet files\n\n### sample_submission.csv\nimage_id: the foreign key for the parquet files\ncombinations: one of the target labels\nhealthy: one of the target labels\nrust: one of the target labels\nscab: one of the target labels","4ed783d6":"# Reading test data\n\nWe have to read the data that we are going to perform using reading first all the paths of images and then we will filter out path of only  Test data files.","d8bdf373":"# Reading the image files","e6e672cf":"Let us define classes as follows \n\n|                            name                             | class |\n|:------------------:|-------|\n| healthy            | 0     |\n| multiple_diseases  | 1     |\n| rust               | 2     |\n| scab               | 3     |","ec4fbed9":"# Finding the learning rate ","13555f98":"Filtering the path of Test image data files.","b33baafc":"# Creation of ImageDataBunch object ","f787cc58":"## Submit the result","d8ba610a":"You might not believing on me that, we have till got the path of Test image files. No problem let it print. ","42d3415b":"Reading image file required for following\n\n- An transformation object\n- We have to create an ImageDataBunch object","f2baca21":"### 1cycle policy\nThe knowleledge in this cell about one cycle plicy, is taken from kernel https:\/\/www.kaggle.com\/qitvision\/a-complete-ml-pipeline-fast-ai.\n\n\n1cycle policy\nWe will use the one cycle policy proposed by Leslie Smith, arXiv, April 2018. The policy brings more disciplined approach for selecting hyperparameters such as learning rate and weight decay. This can potentially save us a lot of time from training with suboptimal hyperparameters. In addititon, Fastai library has implemented a training function for one cycle policy that we can use with only a few lines of code.\n\nSylvian Gugger wrote a very clear explanation of Leslie's proposal that I recommend for reading.\n\nFirst, we find the optimal learning rate and weight decay values. The optimal lr is just before the base of the loss and before the start of divergence. It is important that the loss is still descending where we select the learning rate.\n\nAs for the weight decay that is the L2 penalty of the optimizer, Leslie proposes to select the largest one that will still let us train at a high learning rate so we do a small grid search with 1e-2, 1e-4 and 1e-6 weight decays.\n\n### You can read more about this approach in following research paper\n\nhttps:\/\/arxiv.org\/pdf\/1803.09820.pdf\n","2874bb17":"We can see that image id is like \"Train_1\", \"Train_2\" etc. Now using shape attribute in above code shell, it is clear that in training folder we are having **1821** images. **Is this the case of multi class classification ?**.","3513ca96":"# Reading two image data\n\nFastai provides function open_image() which read and return one image tensor at a time. Following line of code is reading two images.","466c95d4":"## Prediction the data\n\npredict() method can be used to predict class of image. Following line of code is predicting and printing the output. Its come as tuple. The second element in tuple is a class tensor and last element is probability tensor to become in different class.","d50227a9":"Image analysis specific DataBunch in fastai is ImageDataBunch. There are infinite number of factory methods to create it. Structure of the data is like all images are in  a directory **\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\"**. In order to create more mess training and testing data are at same place. The class of images for training porpose has been given in a file **\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv\"**. ","804380d4":"### Transform result data into a dataframe","5f6fb5e2":"## A discussion on output of show_results() method.\n\nThe method showing classification results on 25 images. Out of 25 images 3 images has been predicted wrongly. But if you will look at wrongly classified image, the first image has been found in 2nd row from top and fifth column. This image is having more than one leaf. Let us concentrate on the second wrongly classified image. This image can be found in third row from top and in fifth column. And this image is also having many leaves. And same is the case with the third wrongly classified image.","47eeda1f":"# Importing required fastai modules and packages\n\npackage fastai.vision provides infinite number of functionalities to deal with computer vision problems like image classification, image segmentation etc...","b4ef8b84":"## Image of leaves","de6b1f25":"Second element of result ","def53707":"## Result list ","9b6d9a47":"### Explanation on arguments of  get_transforms() function\n\n- do_flip: if True, a random flip is applied with probability 0.5\n- flip_vert: requires do_flip=True. If True, the image can be flipped vertically or rotated by 90 degrees, otherwise only an horizontal flip is applied\n- max_rotate: if not None, a random rotation between -max_rotate and max_rotate degrees is applied with probability p_affine\n- max_zoom: if not 1. or less, a random zoom between 1. and max_zoom is applied with probability p_affine\n- max_lighting: if not None, a random lightning and contrast change controlled by max_lighting is applied with probability p_lighting\n- max_warp: if not None, a random symmetric warp of magnitude between -max_warp and maw_warp is applied with probability p_affine\n- p_affine: the probability that each affine transform and symmetric warp is applied\n- p_lighting: the probability that each lighting transform is applied\n- xtra_tfms: a list of additional transforms you would like to be applied","6b4ead1b":"![file:\/\/\/home\/raju\/Desktop\/download.png](attachment:image.png)","44a849f3":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcR25h4pKb39YYlqtsFr_mVoUMiE91pPKgsZNSbksgLi7mf2nPNI&usqp=CAU)","c81bd0d1":"Fastai provide functionality to find optimized learning rate. In order to find the optimized learning rate, the method **lr_find()** can be used. The method plot() defined on recorder can be used to plot a line plot between Loss vs. learning Rate. Fastai provide the suggestion also for optimize learning rate.","a91caf81":"# Introduction \n\n## Problem Statement\nMisdiagnosis of the many diseases impacting agricultural crops can lead to misuse of chemicals leading to the emergence of resistant pathogen strains, increased input costs, and more outbreaks with significant economic loss and environmental impacts. Current disease diagnosis based on human scouting is time-consuming and expensive, and although computer-vision based models have the promise to increase efficiency, the great variance in symptoms due to age of infected tissues, genetic variations, and light conditions within trees decreases the accuracy of detection.\n\n## Specific Objectives\n\nObjectives of \u2018Plant Pathology Challenge\u2019 are to train a model using images of training dataset to 1) Accurately classify a given image from testing dataset into different diseased category or a healthy leaf; 2) Accurately distinguish between many diseases, sometimes more than one on a single leaf; 3) Deal with rare classes and novel symptoms; 4) Address depth perception\u2014angle, light, shade, physiological age of the leaf; and 5) Incorporate expert knowledge in identification, annotation, quantification, and guiding computer vision to search for relevant features during learning.\n","26f487d5":"How output looks like ?"}}