{"cell_type":{"67a90375":"code","56e74ea6":"code","1277279c":"code","7707cc2a":"code","99de4d03":"code","b3d0b292":"code","3c31736d":"code","70a2bcd8":"code","005090ff":"code","94048354":"code","43843b3a":"code","7a5a9c74":"code","9623fdf8":"code","95fed05d":"markdown"},"source":{"67a90375":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 as cv2\nimport random\nfrom pathlib import Path\nfrom skimage import io, data,color\nfrom skimage.transform import rescale, resize, downscale_local_mean\n\n\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import classification_report \n\nfrom keras.models import Sequential\nfrom keras.layers.experimental import preprocessing\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Activation\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.models import load_model\n\nimport os\n\n","56e74ea6":"file = Path(\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\")\nFile_Path = list(file.glob(r\"**\/*.png\"))\nLabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],File_Path))\n\nFile_Path = pd.Series(File_Path).astype(str)\nLabels = pd.Series(Labels)\ndf = pd.concat([File_Path,Labels],axis=1)\ndf.columns = ['image', 'label']\n# Drop all the images that ends with (GT)\ndf = df[df[\"label\"].apply(lambda x: x[-2:] != \"GT\")].reset_index(drop=True)\n\nprint('-'*70)\nprint(df.head())\n\nprint('='*70)\nprint(df[\"label\"].value_counts())\nprint('-'*70)","1277279c":"# Display 15 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax ,in enumerate(axes.flat):\n    ax.imshow(plt.imread(df.image[i]))\n    ax.set_title(df.label[i])\nplt.tight_layout()\nplt.show()\nprint(df.image.shape)","7707cc2a":"x_interim, x_eval = train_test_split(df, test_size=0.2, random_state=42, shuffle=True) \n\n# split remaining data into train and test sets\nx_train, x_test = train_test_split(x_interim, test_size=0.2, random_state=52) \nx_eval1 = x_eval.copy()","99de4d03":"img_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\nx_train = img_gen.flow_from_dataframe(dataframe=x_train,\n    x_col='image',\n    y_col='label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)\n\nx_test = img_gen.flow_from_dataframe(dataframe=x_test,\n    x_col='image',\n    y_col='label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)\n\n\nx_eval = img_gen.flow_from_dataframe(dataframe=x_eval,\n    x_col='image',\n    y_col='label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","b3d0b292":"model = Sequential()\n\n# first convolutional layer with 32 filters\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224,224, 3))) #\n# add a second 2D convolutional layer with 64 filters\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) \n\n# reduce dimensionality through max pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2))) \n\n# third convolutional layer with 64 filters\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) \n\n\n# hiddens layers\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten(input_shape=())) \nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n# output layer\nmodel.add(Dense(9,activation=\"softmax\",name='preds'))\n\nmodel.summary()","3c31736d":"model.compile(\n    optimizer=\"rmsprop\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"])\nhist = model.fit(x_train,\n    validation_data = x_test,\n    epochs = 5)","70a2bcd8":"model.save('model.h5') # save('models\/DTSense_model_nama.h5')","005090ff":"# load pre-trained model\n\npretrained_cnn = tf.keras.models.load_model('model.h5') \n\n# evaluate model on test set\nscore = pretrained_cnn.evaluate(x_eval, verbose=0)\nprint('Test loss:', score[0]) # score[0])\nprint('Test accuracy:', score[1]) # score[1])\n\nprint(\"\")","94048354":"# evaluate model on holdout set\neval_score = pretrained_cnn.evaluate(x_eval,verbose=0) # evaluate(x_eval, y_eval, verbose=0)\n# print loss score\nprint('Eval loss:', eval_score[0])\n# print accuracy score\nprint('Eval accuracy:', eval_score[1])\npretrained_cnn_history = hist\n# print keys for pretrained_cnn_history dict\n#print(pretrained_cnn_history.keys())\n\nfig = plt.figure(1)\nplt.subplot(211)\n# plot the validation accuracy\nplt.plot(pretrained_cnn_history.history['val_accuracy'])\nplt.title('Validation accuracy and loss')\nplt.ylabel('Accuracy')\nplt.subplot(212)\n# plot the validation loss\nplt.plot(pretrained_cnn_history.history['val_loss'], 'r')\nplt.xlabel('Epoch')\nplt.ylabel('Loss value');\n","43843b3a":"# Predict the label of the test_images\npred = model.predict(x_eval)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (x_train.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred2 = [labels[k] for k in pred]\n","7a5a9c74":"from sklearn.metrics import classification_report\ny_eval = x_eval1.label\nprint(classification_report(y_eval, pred2))","9623fdf8":"# Display 15 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\ncolor = \"blue\" if pred2[i] == x_eval1.label.iloc[i] else \"red\"\nfor i, ax ,in enumerate(axes.flat):\n    ax.imshow(plt.imread(x_eval1.image.iloc[i]))\n    ax.set_title(f\"True: {x_eval1.label.iloc[i]}\\nPredicted: {pred2[i]}\",color=color)\nplt.subplots_adjust(hspace = 0.3)\nplt.suptitle(\"Model predictions (blue: correct, red: incorrect)\",y=0.98)\nplt.tight_layout()\nplt.show()\n","95fed05d":"Pretained_M = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n                                               include_top=False,\n                                               weights=\"imagenet\",\n                                               pooling=\"avg\")\nPretained_M.trainable = False"}}