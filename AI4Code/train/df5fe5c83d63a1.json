{"cell_type":{"e06db408":"code","8b52625c":"code","008a9247":"code","a99c93ed":"code","b580dc96":"code","6a6cc17d":"code","a5e7c776":"code","20ecdaea":"code","0e09b59c":"code","e6393f00":"code","2f380333":"code","667714b2":"markdown","e4b75790":"markdown","e58d3c66":"markdown","5e509f27":"markdown","ba325e9e":"markdown","fc3aac76":"markdown","dc13e2eb":"markdown","b739b886":"markdown","f38dfa85":"markdown","8b8329d3":"markdown","db5515e4":"markdown","ce356b65":"markdown","03fab55b":"markdown"},"source":{"e06db408":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\n# ensure consistency across runs\nfrom numpy.random import seed\nseed(1)\n\n# Imports to view data\nimport cv2\nfrom glob import glob\n\n#for alternative imports you can use \n#from keras.preprocessing.image import ImageDataGenerator\n#from keras.models import Sequential\n#from keras.layers import Conv2D, SeparableConv2D, Dense, Dropout, Flatten, LSTM,MaxPool2D, BatchNormalization\n#from keras import backend\n#from keras import Input\n#from keras.models import Model\n#from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\n\n\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, SeparableConv2D, Dense, Dropout, Flatten, LSTM,MaxPool2D, BatchNormalization\nfrom tensorflow.keras import backend\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\n","8b52625c":"# Loading the data\ntrain_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"\nval_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/val\"\ntest_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"\n\ntarget_size = (128,128)   \ntarget_dims = (128, 128, 3) # add channel for RGB\nn_batch_size = 32 ","008a9247":"data_augmentor = ImageDataGenerator(samplewise_center=True, rescale=1.\/255, shear_range=0.2,zoom_range = 0.2,samplewise_std_normalization=True)\n\ntrain_generator = data_augmentor.flow_from_directory(train_data_dir,  target_size=target_size, subset='training',batch_size= n_batch_size,class_mode='binary')\nval_generator = data_augmentor.flow_from_directory(val_data_dir, target_size=target_size,subset='validation',class_mode='binary')\ntest_generator = data_augmentor.flow_from_directory(test_data_dir, target_size=target_size,batch_size= 1,class_mode=None, shuffle=False)\n\n# \ntrain_generator.class_indices","a99c93ed":"data_augmentor = ImageDataGenerator(samplewise_center=True, rescale=1.\/255, shear_range=0.2,zoom_range = 0.2,samplewise_std_normalization=True,validation_split=0.2) \n\ntrain_generator = data_augmentor.flow_from_directory(train_data_dir,  target_size=target_size, subset='training',batch_size= n_batch_size,class_mode='binary')\nval_generator = data_augmentor.flow_from_directory(train_data_dir, target_size=target_size,subset='validation',class_mode='binary')\ntest_generator = data_augmentor.flow_from_directory(test_data_dir, target_size=target_size,batch_size= 1,class_mode=None, shuffle=False)","b580dc96":"input_path = '..\/input\/chest-xray-pneumonia\/\/chest_xray\/chest_xray\/'\n\ndef process_data(img_dims, batch_size):\n    # Data generation objects\n    train_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, vertical_flip=True)\n    test_val_datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n    directory=input_path+'train', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n\n    test_gen = test_val_datagen.flow_from_directory(\n    directory=input_path+'test', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n    \n    # I will be making predictions off of the test set in one batch size\n    # This is useful to be able to get the confusion matrix\n    test_data = []\n    test_labels = []\n\n    for cond in ['\/NORMAL\/', '\/PNEUMONIA\/']:\n        for img in (os.listdir(input_path + 'test' + cond)):\n            img = plt.imread(input_path+'test'+cond+img)\n            img = cv2.resize(img, (img_dims, img_dims))\n            img = np.dstack([img, img, img])\n            img = img.astype('float32') \/ 255\n            if cond=='\/NORMAL\/':\n                label = 0\n            elif cond=='\/PNEUMONIA\/':\n                label = 1\n            test_data.append(img)\n            test_labels.append(label)\n        \n    test_data = np.array(test_data)\n    test_labels = np.array(test_labels)\n    \n    return train_gen, test_gen, test_data, test_labels","6a6cc17d":"# Hyperparameters\nimg_dims = 150\nepochs = 10\nbatch_size = 32\n\n# Getting the data\ntrain_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)","a5e7c776":"# Input layer\ninputs = Input(shape=(img_dims, img_dims, 3))\n\n# First conv block\nx = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\nx = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Second conv block\nx = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Third conv block\nx = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Fourth conv block\nx = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = Dropout(rate=0.2)(x)\n\n# Fifth conv block\nx = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = Dropout(rate=0.2)(x)\n\n# FC layer\nx = Flatten()(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(rate=0.7)(x)\nx = Dense(units=128, activation='relu')(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(units=64, activation='relu')(x)\nx = Dropout(rate=0.3)(x)\n\n# Output layer\noutput = Dense(units=1, activation='sigmoid')(x)\n\n# Creating model and compiling\nmodel = Model(inputs=inputs, outputs=output)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Callbacks\ncheckpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\nlr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')","20ecdaea":"# Fitting the model\nhist = model.fit(\n           train_gen, steps_per_epoch=train_gen.samples \/\/ batch_size, \n           epochs=epochs, validation_data=test_gen, \n           validation_steps=test_gen.samples \/\/ batch_size, callbacks=[checkpoint, lr_reduce])","0e09b59c":"from sklearn.metrics import accuracy_score, confusion_matrix\n\npreds = model.predict(test_data)\n\nacc = accuracy_score(test_labels, np.round(preds))*100\ncm = confusion_matrix(test_labels, np.round(preds))\ntn, fp, fn, tp = cm.ravel()\n","e6393f00":"\nprint('CONFUSION MATRIX')\nprint(cm)\n\nprint('\\nTEST METRICS ----------------------')\nprecision = tp\/(tp+fp)*100\nrecall = tp\/(tp+fn)*100\n\nprint('Accuracy: {}%'.format(acc))\nprint('Precision: {}%'.format(precision))\nprint('Recall: {}%'.format(recall))\nprint('F1-score: {}'.format(2*precision*recall\/(precision+recall)))\n\nprint('\\nTRAIN METRICs ----------------------')\nprint('Train acc: {}'.format(np.round((hist.history['accuracy'][-1])*100, 2)))\n\n","2f380333":"fig, ax = plt.subplots(1, 2, figsize=(10, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(hist.history[met])\n    ax[i].plot(hist.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","667714b2":"****ACCURACY****\n\n","e4b75790":"****LOSS****\n","e58d3c66":"TRAINING: As epochs increase, the models accuracy stabilizes","5e509f27":" ****As training epochs increase, the model's accuracy stabilizes, while it also manages to reduce loss\nThis can be due to overfitting with the training data. However, there are wild fluctuations in validating the data which probably means, the number of epochs were too less for the model to stabilize its loss and accuracy\nRegarding the number of epochs, we can see that the trend either stabilizes or gets worse after 8 epochs, so we can conclude that for this, more epochs should be enough to train the models. This is overfitting \u2014 when the model adapts too well to a specific dataset and thus does not generalize well on new information. There are many ways to correct for this, one of which we\u2019ve implemented is called Early Stopping.****","ba325e9e":"The objective of this notebook is for me to develop an understanding of GANs in X-Ray screening. I have edited and referred Maxime's notebook ( https:\/\/www.kaggle.com\/maximedassen\/deep-learning-x-ray ) who provides a great view to begin in this sphere","fc3aac76":"# Generative Adversarial Networks for Deep Learning in Pneumonia with X-Ray images","dc13e2eb":"VALIDATION:  Fluctuations can be see in between epochs, and graph starts to exhibhit a downward trend as it nears the number of final epochs\n\n","b739b886":"From what I summarized in their nnotebook. Doctors differentiate between healthy and unhealthy lungs by way of clarity in lungs that does not include an unusual block(age)s\/opaque areas\n\nBacterial pneumonia (middle) typically exhibits a focal lobar consolidation, in the right upper lobe (red rectangle), whereas viral pneumonia (right) manifests with a more difuse interstitial pattern in both lungs (Kermany et al., 2018).\n\nHowever Deep Learning algorithms have a different approach to the same\nDeep Learning algorithms adapt fom natural image classification. CNNs are often used for such tasks but do not perform as good as capsule networks, a state of the art performance technology that is often utilized on the MNIST database, and for healthcare.\nCapsule networks often fill in where CNNs fall behind, with pooling layers, that result in some transitional invariance and lose a part of data that could be the most important feature detector","f38dfa85":"VALIDATION: Model performs good at reducing loss during testing than training, graph shows a complete and stable downtrend during validation","8b8329d3":"Resize, Normalize and Scale data Keras ImageDataGenerator class allows image rescaling, resizing options. here, image augmentation is applied and also converted every image into binary (0 and 1). Resizing and scaling is applied on images to save time in training.","db5515e4":"**Most of the experts got high sensitivity but low specificity, while the CNN-based system got high values on both sensitivity and specificity. Moreover, on the average weight error measure, the CNN-based system exceeds two human experts.**","ce356b65":"TRAINING: Graph exhibhits fluctuations in loss during training in the first phases and stabilizes towards the end but shows a sudden upward trend during the end\n","03fab55b":"They try to address the question, who performs better? Doctors or Deep Learning models?"}}