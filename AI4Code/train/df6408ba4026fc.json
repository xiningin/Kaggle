{"cell_type":{"c78ac7ea":"code","66fcd4e6":"code","77715911":"code","75f5993c":"code","359de8d2":"code","8e09407c":"code","0da3bd20":"code","643ec3da":"code","a365b73b":"code","e0e914e8":"code","eda6e11c":"code","8b9d5fd3":"code","f720d766":"code","75cac422":"code","6a3b3d87":"code","d5dd883c":"code","07d1936f":"code","ecbf3580":"code","cd0ecb09":"code","0b9317bc":"code","aae31c81":"markdown","edc323cb":"markdown","e0b480ad":"markdown","604c9818":"markdown","06ee2991":"markdown","8f14eb05":"markdown","2248a2fa":"markdown","b49ca5b4":"markdown","5e4e68c3":"markdown","de4edae8":"markdown","58c9ec0d":"markdown","b9b36243":"markdown","1b7529b6":"markdown","44d30e54":"markdown","240fc7ee":"markdown","e4e92557":"markdown","b9eb41b2":"markdown","47884a7b":"markdown","d5a2e918":"markdown","9fa8b92c":"markdown","3beac3a6":"markdown","272e98d8":"markdown","3d72386f":"markdown","739a07de":"markdown","3f28c9db":"markdown","6e72fb64":"markdown","a0fe4e11":"markdown","a73a5370":"markdown"},"source":{"c78ac7ea":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport torch\nfrom torch.nn import Linear, Tanh, Sigmoid, Module, BCELoss\nfrom torch.optim import Adam\n\nfrom umap import UMAP\n\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')","66fcd4e6":"data = pd.read_csv('\/kaggle\/input\/lyrics-dataset\/lyrics_features.csv', index_col=0)\nlabels = data.columns[-10:]\nX, Y = data.iloc[:, 2:-10].values, data.iloc[:, -10:].values\nprint(data.shape)\ndata.head()","77715911":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, \n                                                    test_size=0.1)\nto_tensor = lambda M: torch.from_numpy(M).float().cuda()\n\nX = to_tensor(X)\nY = to_tensor(Y)\n\nX_train = to_tensor(X_train)\nX_test = to_tensor(X_test)\nY_train = to_tensor(Y_train)\nY_test = to_tensor(Y_test)","75f5993c":"class MultiLabelNet(Module):\n    def __init__(self, n_feature, n_hidden, n_classes):\n        super().__init__()\n        \n        self.fc1 = Linear(n_feature, n_hidden)\n        self.act1 = Tanh()\n        self.fc2 = Linear(n_hidden, n_hidden)\n        self.act2 = Tanh()\n        self.fc3 = Linear(n_hidden, n_feature)\n        self.act3 = Tanh()\n        self.fc4 = Linear(n_feature, n_classes)\n        self.act4 = Sigmoid()\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act1(x)\n        x = self.fc2(x)\n        x = self.act2(x)\n        x = self.fc3(x)\n        x = self.act3(x)\n        x = self.fc4(x)\n        x = self.act4(x)\n        return x","359de8d2":"def get_score_over_labels(Y_pred, Y_true=Y.detach().cpu().numpy(), threshold=0.5):\n    scores = []\n    print('F1 Score over labels:')\n    for label in range(Y_true.shape[1]):\n        y_true = Y_true[:, label]\n        y_pred = np.where(Y_pred[:, label] > threshold, 1, 0)\n        score = f1_score(y_true, y_pred)\n        scores.append(score)\n        print(f'{labels[label].rjust(20)}: {score:.4f}')\n    print(f'Mean F1 Score: {np.mean(scores):.4f}')\n\n\ndef train(X_train, X_test, Y_train, Y_test, \n          n_epochs, model, optimizer, criterion, save_path):\n    valid_loss_min = np.Inf\n    best_model = None\n\n    for epoch in range(1, n_epochs+1):\n        # train the model\n        model.train()\n\n        optimizer.zero_grad()\n        output = model(X_train)\n\n        train_loss = criterion(output, Y_train)\n        train_loss.backward()\n        optimizer.step()\n        \n        # validate the model\n        model.eval()\n\n        output = model(X_test)\n        valid_loss = criterion(output, Y_test)\n\n        # print train\/val statistics\n        print(f'Epoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n        \n        # update best model if validation loss has decreased\n        if valid_loss < valid_loss_min:\n            print(f'Validation loss decreased ({valid_loss_min:.4f} --> {valid_loss:.4f}).')\n            best_model = model\n            valid_loss_min = valid_loss\n\n    print('Saving best model ...')\n    torch.save(best_model, save_path)\n    print(f'Minimum value of loss: {valid_loss_min:.4f}')\n\n    return best_model","8e09407c":"path_to_model = '.\/model.pth'\nmodel = MultiLabelNet(X.shape[1], 100, Y.shape[1]).cuda()\ncriterion = BCELoss()\noptimizer = Adam(model.parameters(), lr=0.001, amsgrad=True)\n\nmodel = train(X_train, X_test, Y_train, Y_test, 2000, model, optimizer, criterion, path_to_model)","0da3bd20":"model = torch.load(path_to_model).cuda()\nmodel.eval()\n\nprediction = model(X).detach().cpu().numpy()\nget_score_over_labels(prediction, threshold=0.15)","643ec3da":"cutted_model = torch.nn.Sequential(*(list(model.children())[:-2])).cuda()\ncutted_model.eval()\n\nsong_embeddings = cutted_model(X).detach().cpu().numpy()","a365b73b":"X = X.detach().cpu().numpy()\nX.shape, song_embeddings.shape","e0e914e8":"# just space cleaning\ntorch.cuda.empty_cache()","eda6e11c":"%%time\nreducer = UMAP(n_components=3)\nX_reduced = reducer.fit_transform(X)","8b9d5fd3":"%%time\nreducer = UMAP(n_components=3)\nsong_embeddings_reduced = reducer.fit_transform(song_embeddings)","f720d766":"X_reduced.shape, song_embeddings_reduced.shape","75cac422":"songs = pd.DataFrame(np.concatenate([data.iloc[:, :2].values.reshape(-1, 2), \n                                     X_reduced, \n                                     song_embeddings_reduced], \n                                    axis=1), \n                     columns=['Singer', 'Song', 'x1', 'y1', 'z1', 'x2', 'y2', 'z2'])\n\nfor col in songs.columns[2:]: # I dont know why are they casting to\n    songs[col] = songs[col].astype(float) # `object` while creating DF\nsongs.head()","6a3b3d87":"singers = songs.groupby(['Singer'], as_index=False)[songs.columns[2:]].mean()\nget_label = np.vectorize(lambda x: labels[x])\nsingers['Genre'] = get_label(data.groupby(['Singer'])[labels].sum().values.argmax(axis=1))\nsingers.head()","d5dd883c":"fig = px.scatter_3d(singers, x='x1', y='y1', z='z1',\n                    color='Genre', hover_name='Singer')\nfig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\nfig.show()","07d1936f":"fig = px.scatter_3d(singers, x='x2', y='y2', z='z2',\n                    color='Genre', hover_name='Singer')\nfig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\nfig.show()","ecbf3580":"def find_nearest_singers(singer_df, singer, metric, k=10):\n    dist_func = euclidean_distances if metric == 'euclidean' else cosine_similarity\n    ascending = True  if metric == 'euclidean' else False\n\n    singers_similarity = pd.DataFrame(dist_func(singer_df))\n    singer_index = singers[singers['Singer'] == singer].index[0]\n    top_similar = singers_similarity[singer_index].sort_values(ascending=ascending)[1:k+1]\n    top_similar_names = singers.loc[top_similar.index]['Singer'].values\n    top_similar_values = map(lambda x: round(x, 4), top_similar.values)\n\n    print(f'The nearest artists to {singer}:')\n    print('\\n'.join([f'{name.rjust(25)} - {values}' for name, values in zip(top_similar_names, top_similar_values)]))","cd0ecb09":"find_nearest_singers(singers[['x2', 'y2', 'z2']], 'Eminem', 'euclidean')","0b9317bc":"find_nearest_singers(singers[['x1', 'y1', 'z1']], 'Eminem', 'euclidean')","aae31c81":"# Idea","edc323cb":"That's all folks!  \n\nWhat have we achieved? Well, we created multi-genre classification neural net, looked at how singers located relative to each other in features and embeddings space on the 3D scatter plot and found the nearest singers to the chosen one.  \n\nThus, my goal was achieved. Even if results are not that good. \n\nI hope that [this dataset](https:\/\/www.kaggle.com\/detkov\/lyrics-dataset) and my work will help you in your projects, good luck!","e0b480ad":"If you don't want to use your limited GPU tume, just remove `cuda()` and `cpu()` from the code.","604c9818":"We define function that shows closest `k` singers to `singer` that we want to look at.  \nAvailible distance metrics are `cosine` and `euclidean`.","06ee2991":"Now let's remove last Linear layer (whick decreases amount of neurons from `n_hidden` to `n_features`) and the following Sigmoid activation function.  \nThen apply \"clipped\" NN to our data:","8f14eb05":"# Model definition and training","2248a2fa":"# Let's code it!","b49ca5b4":"We train the model","5e4e68c3":"Actually, even if model training results are not that good, embeddings helped us in separatng classes. `Hip-Hop\/Rap` is now more distant, `Pop`, `Rock` and `Country` are too more separable even at first sight. So the result is much more better than it was. ","de4edae8":"## Imports","58c9ec0d":"# Find nearest singers","b9b36243":"Now let's look at scatter plot with initial data, where songs-points are the vectors in the statistic features space:","1b7529b6":"And this is more like the truth.  \n\nSo **in this case** embeddings are good in their own space designed to divide classes, but not good to show real similarity between vectors.  \nAlso, possible way to improve results may be normalizing the space, but you can do it yourself.","44d30e54":"# Getting the dataset","240fc7ee":"Now we can evaluate the model's performance","e4e92557":"Now we can look to the nearest singers. We could use \"full\" vectors, but the amount of RAM does not allow us to do this. So we look at nearness based on reduced vectors.","b9eb41b2":"We reduce dimensionality of initial vectors and embeddings","47884a7b":"tags: music classification, multi label classification, pytorch pipeline, plotly","d5a2e918":"Then we define our training pipeline and the function that evaluates the result.","9fa8b92c":"Now we have embeddings with `n_features` amount of features and our initial data with the same size","3beac3a6":"We define simple fully-connected (dense) deep neural network. Since songs can have several genres, we have solve Multi-Class Classification task. Hence we'll use Sigmoid activation.","272e98d8":"Nwxt we create a songs and singers Data Frame with these features:  \n*   `x1`, `y1`, `z1` corresponding to the mean of reduced initial song vectors, i.e. initial coordinates;\n*   `x2`, `y2`, `z2` corresponding to the mean of reduced song embeddings, i.e. embedding coordinates;\n*   `Genre` corresponding to the most common genre in singer songs.","3d72386f":"# Reducing dimentionality and plotting 3D scatter plot","739a07de":"As we can see, results aren't that good, actually, for many genres they are bad. We can assume that this happened mostly due to the class imbalance. Other reasons: bad random seed, not tuned model parameters like amount of hidden layers, its dimentionality, not adjusted loss function and so on. \n\nBut we have what we have, so let's move on!  ","3f28c9db":"# Conclusion","6e72fb64":"Well, we clearly see that `Hip-Hop\/Rap` differs from other genres and its points are separated from the points of other genres. But other genres are almost not separable and a lot of points from different genres are located in one space location. Exactly this is what I wanted to avoid.  \n\nLet's look at embeddings now:","a0fe4e11":"Based on my own prior knowledge, I can say that this result is not correct.","a73a5370":"Initially, I wanted to understand whether it is possible to make a simple music recommendation system, based only on the statistics of the texts, without using NLP and the sound waves themselves. And what is a recommendation system? This is an offer of relevant artists, songs and genres.  \n\nFor this we need ... suddenly (no) data, namely, lyrics. Since the open datasets seemed not good enough, [this dataset](https:\/\/www.kaggle.com\/detkov\/lyrics-dataset) was gathered. With its help, statistical features were obtained, the process of extraction can be found [here](https:\/\/github.com\/NikitiusD\/Music-analysis\/blob\/master\/Song%20features%20extractor.ipynb). By the way, if you also want to work with this data, you can look at the [starter notebook](https:\/\/www.kaggle.com\/detkov\/starter-music-analysis-and-plotly-tutorial).  \n\nNow we are finally moving on to machine learning. We want to know which artists or songs are similar so that we can recommend them. What do we need to do for this? Well, firstly, present the songs in the form of vectors, since we can find the closest vectors to a given one. The artist's vector, for example, can be represented as the average of the vectors of his songs. \"But we already have vectors\", you say \u2014 those statistical features \u2014 and you'll be right. But this space of features can be poorly separable by genre and not the best way to show real \"semantic\" relations that exist between songs. Therefore, we will use one trick: we will train the neural network on these songs and their corresponding genres, and we will make the penultimate layer the same size as the incoming one (although this is not at all necessary, but indicative). Thus, we can get embeddings from the penultimate layer and then they will show some relations in the best way. \n"}}