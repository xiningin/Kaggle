{"cell_type":{"0d048089":"code","0a011d50":"code","c6e7da2d":"code","d8461a8a":"code","9344e02f":"code","a80fb31c":"code","88be66b0":"code","6419daee":"code","89cdbd0d":"code","e1e75ae7":"code","1140d8ef":"code","3d15254b":"code","d6661a57":"code","553f5879":"code","201e5f36":"code","b9f791c5":"code","00d8bf73":"code","3b75795a":"code","deb336fc":"code","4bac674b":"markdown","f75bb621":"markdown","9eafd9d2":"markdown","709bdde4":"markdown","f181c56d":"markdown","4aca3c0b":"markdown","855ffaea":"markdown","58880fc9":"markdown","4f2e4ec0":"markdown","af8d941d":"markdown","35e31be8":"markdown","7305e1aa":"markdown"},"source":{"0d048089":"# import libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\n\n","0a011d50":"# Load data using pandas.read_csv()\n\ndata = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nlabels = data.pop('label').to_numpy()\ndata = data.to_numpy().reshape(-1,28,28)\n\n# Add dimension\n\ndata = np.expand_dims(data,axis=-1)\nlabels = np.expand_dims(labels,axis=-1)\n\n# Fill the image with zeros around it\n\ndata = tf.pad(data,[[0,0],[2,2],[2,2],[0,0]])\n\nnum = data.shape[0] \/\/ 10\ntrain_data, val_data, test_data = tf.split(data,[num*8, num, num])\ntrain_label, val_label, test_label = tf.split(labels,[num*8, num, num])\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_data,train_label)).shuffle(33600,seed=42).batch(128)\nval_ds = tf.data.Dataset.from_tensor_slices((val_data,val_label)).shuffle(33600,seed=42).batch(128)\ntest_ds = tf.data.Dataset.from_tensor_slices((test_data,test_label)).shuffle(33600,seed=42).batch(128)\n# The shape of the picture\n\nimage_shape = (32,32,1)","c6e7da2d":"\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)","d8461a8a":"def identity_block(X, f, filters, stage, block):\n   \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n   \n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X = Add()([X, X_shortcut])# SKIP Connection\n    X = Activation('relu')(X)\n\n    return X","9344e02f":"def convolutional_block(X, f, filters, stage, block, s=2):\n   \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n\n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X","a80fb31c":"\ndef ResNet(input_shape=(224, 224, 3)):\n\n    X_input = Input(input_shape)\n\n    X = ZeroPadding2D((3, 3))(X_input)\n\n    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n\n    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n    \n    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n\n    return model\n\nbase_model = ResNet(input_shape=image_shape)\nheadModel = base_model.output\nheadModel = Flatten()(headModel)\nheadModel=Dense(400, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\nheadModel=Dense(300, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\nheadModel = Dense( 10,activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)\nmodel = Model(inputs=base_model.input, outputs=headModel)\nmodel.summary()\n","88be66b0":"\nfrom keras.callbacks import ModelCheckpoint\nmodel.compile(\n    optimizer=keras.optimizers.Adam(lr=0.0001),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\ncheckpointer_best_train = ModelCheckpoint(\n    filepath='.\/final_model3.h5',\n    monitor='loss', verbose=1, save_best_only=True, mode='min'\n)\n\ncallback_list = [checkpointer_best_train]\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',mode='max',\n                                    patience=10,restore_best_weights=True)\n\n# Using ReduceLROnPlateau, the learning rate is reduced by half when val_accuracy is not improved for 5 consecutive times\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',mode='max',factor=0.5,patience=5)\n\n# training\nhistory = model.fit(train_ds,batch_size=64 ,epochs=110,validation_data=val_ds,\n                    callbacks=callback_list)","6419daee":"\n\n\nhistory = model.fit(train_ds,batch_size=64 ,epochs=2,validation_data=val_ds,\n                    )","89cdbd0d":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","e1e75ae7":"model.evaluate(test_ds,verbose=2)","1140d8ef":"# intialize wights  resume from last train(transfer learning)\n'''\nfrom keras.optimizers import Adam\n\n#model_path = '\/content\/drive\/MyDrive\/final_model153.h5'\nmodel_path = '.\/final_model3.h5'\n\nmodel = load_model(model_path)\n\n\nadam = Adam(lr=0.0001)\nmodel.compile(\n    optimizer=adam,\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\ncheckpointer_best_train = ModelCheckpoint(\n    filepath='.\/final_model3.h5',\n    monitor='loss', verbose=1, save_best_only=True, mode='min'\n)\n\ncallback_list = [checkpointer_best_train]\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',mode='max',\n                                    patience=10,restore_best_weights=True)\n\n# Using ReduceLROnPlateau, the learning rate is reduced by half when val_accuracy is not improved for 5 consecutive times\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',mode='max',factor=0.5,patience=5)\n\n\nmodel.summary()\n'''","3d15254b":"# load data\n\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nsample_submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","d6661a57":"# process data\n\ntest = test.to_numpy().reshape(-1,28,28)\ntest = np.expand_dims(test,axis=-1)\ntest = tf.pad(test,[[0,0],[2,2],[2,2],[0,0]])\n\ntest.shape","553f5879":"sample_submission.shape","201e5f36":"# predict\nresult =  model.predict(test)\n\nresult.shape","b9f791c5":"# get predict label\npredict_label = np.argmax(result,axis=-1)\n\npredict_label.shape","00d8bf73":"# Show some prediction results\n\nplt.figure(figsize=(10,10))\n\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.imshow(test[i,...,0])\n    plt.xticks([])\n    plt.yticks([])\n    plt.xlabel(predict_label[i])","3b75795a":"sample_submission['Label'] = predict_label","deb336fc":"sample_submission.to_csv('submission.csv', index=False)","4bac674b":"# bulid ResNet model ","f75bb621":"# Identity Block\n\nIdentity block is the standard block used corresponding to the case where the input activation has the same dimensions as the output activation.\n\n![ResNet-Residual-Network-Keras-Implementation-Identity-Block.png](attachment:ResNet-Residual-Network-Keras-Implementation-Identity-Block.png)","9eafd9d2":"# Convolutional Block\nWe can use this type of block when the input and output dimensions don\u2019t match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path.\n\n![0mE2p.png](attachment:0mE2p.png)","709bdde4":"# accuracy","f181c56d":"Distinguished by the ResNet syntax, a \"shortcut\" or \"skip connection\" allows for the gradient to be re-propagated directly to previous layers\n\n![ResNet-Residual-Network-Architecture-Skip-Connections.png](attachment:ResNet-Residual-Network-Architecture-Skip-Connections.png)\n\n\n","4aca3c0b":"# accuracy","855ffaea":"#  Load data","58880fc9":"# # load data\n","4f2e4ec0":"# # intialize wights  resume from last train(transfer learning)\n","af8d941d":"# train modle","35e31be8":"# Show some prediction results","7305e1aa":"In this post, we will try the ResNet for image recognition. We will learn the Keras application tutorial for ResNet engineering from scratch. (Residual networks) is a deep neural network that is used as a backbone for many computer vision applications such as object detection, image segmentation, etc.\n"}}