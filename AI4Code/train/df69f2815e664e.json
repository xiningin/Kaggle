{"cell_type":{"37bc94a3":"code","572e986a":"code","cc4af9dd":"code","4975aec7":"code","44fcacbc":"code","8f140170":"code","566b0745":"code","57e871ef":"code","552e8f8f":"code","eddb48ae":"code","fae9b253":"code","959a608a":"code","f1d16110":"code","b6817b96":"code","9546e70b":"code","7667a7c1":"code","2e8029f9":"code","1d35617f":"code","16becaa9":"markdown","089cd688":"markdown","1a3c4f6f":"markdown"},"source":{"37bc94a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","572e986a":"import tensorflow as tf\nprint(tf.__version__)","cc4af9dd":"tf.test.is_gpu_available()","4975aec7":"from tensorflow import keras\nimport matplotlib.pyplot as plt\n%matplotlib inline","44fcacbc":"fashion_mnist = keras.datasets.fashion_mnist","8f140170":"(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()","566b0745":"train_images.shape","57e871ef":"train_labels.shape","552e8f8f":"test_images.shape","eddb48ae":"test_labels","fae9b253":"import numpy as np\n\ntrain_images = np.expand_dims(train_images, -1)\ntrain_images.shape\n\ntest_images = np.expand_dims(test_images, -1)\ntest_images.shape","959a608a":"model = tf.keras.Sequential()\n\n\"\"\"\nnumber of filters: increases exponentially, e.g. 2^n -->\u62df\u5408\u80fd\u529b\u5f3a\u5927\nksize: (3, 3) or (5, 5) --> \u7ecf\u9a8c\u4e4b\u8c08\npadding (default)='valid' --> \u5c3d\u91cf\u4e0dpadding\nMaxPool2D (default)=(2, 2) ---> shrink its size by a factor of 2x2\ninput_shape=(28, 28, 1)\n\"\"\"\n\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=train_images.shape[1:], activation='relu'))\nmodel.add(tf.keras.layers.MaxPool2D())\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n\n# To obtain a 2D data that can be fed in to the fully connected layer\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))","f1d16110":"model.summary()","b6817b96":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","9546e70b":"history = model.fit(train_images, train_labels, epochs=30, validation_data=(test_images, test_labels))","7667a7c1":"history.history.keys()","2e8029f9":"plt.plot(history.epoch, history.history.get('accuracy'), label='accuracy')\nplt.plot(history.epoch, history.history.get('val_accuracy'), label='val_accuracy')","1d35617f":"plt.plot(history.epoch, history.history.get('loss'), label='loss')\nplt.plot(history.epoch, history.history.get('val_loss'), label='val_loss')","16becaa9":"### Recognition of Images for CNNs:\n4-Dimensional Inputs:\n\nnone(size_of_sampling), height, width, no_channels(RGB)\n\n1: \u9ed1\u767d 3\uff1a\u5f69\u8272","089cd688":"Model\u7684\u7b2c\u4e00\u5c42\u5f88\u91cd\u8981\uff0c\u4e00\u822c\u4f7f\u7528\u5377\u79ef\u5c42\uff0c\u56e0\u4e3a\u5176\u5bf9\u4e0e\u56fe\u50cf\u4e2d\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\u8f83\u5f3a","1a3c4f6f":"**Conclusions:**\n1. \u5bf9\u4e8etrain\u6570\u636e\uff0c\u62df\u5408\u4ecd\u7136\u4e0d\u591f\n2. \u5bf9\u4e8etest\u6570\u636e\uff0c\u51fa\u73b0\u4e86\u8fc7\u62df\u5408"}}