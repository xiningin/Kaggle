{"cell_type":{"9f9e5306":"code","7fa68eff":"code","19c36531":"code","7ad187cb":"code","422a42cf":"code","59046226":"code","a3cf7f91":"code","7ae8d049":"code","bb98736e":"code","4a7aa6d5":"code","e4b28321":"code","f93e9e0f":"code","e583c0a1":"code","553702f4":"code","7c75583a":"code","953b9410":"code","d0fe1421":"code","b9a6bc3b":"code","d961d1e3":"code","71fa8c2d":"code","0ba846b0":"code","2412181c":"code","d261945f":"code","3ef5475e":"code","d33f6401":"code","c8a9bda8":"code","e26c746a":"code","63b83a74":"code","5e8992d8":"code","e62aab57":"code","b9758a3f":"code","3ab1d656":"code","c977856e":"code","a61cf4e4":"code","c4be8052":"code","2d0423ab":"code","fa464793":"code","890a630f":"code","4826d928":"code","cd07e451":"code","c3953a70":"code","77d66875":"code","6006af84":"code","cfad834f":"code","341db79f":"code","419d5a51":"code","707cd8a2":"code","5c1342b7":"code","1f606763":"code","9ba7b58c":"code","3bfb1b10":"code","68d1db99":"code","e43384ac":"code","168350c2":"code","c36039f0":"code","94005984":"code","9113fa3f":"code","74b03284":"code","726d0b79":"code","98b16883":"code","050ae564":"code","120f5afa":"code","842dee67":"code","7ec044eb":"code","3de86a72":"code","1a24a010":"code","b6d79abb":"code","4a434330":"code","38534d1f":"code","55a7bb53":"code","c71c0e1e":"code","87d335aa":"code","d39b1295":"code","e37e476b":"code","38d8bd90":"code","a12e3c0f":"code","c293f28c":"code","6055c9e9":"code","070e02d2":"code","640e569d":"code","2deaf70d":"code","27ee4bf5":"code","11d8e8c8":"code","9e5c3f92":"code","2f1292fa":"code","f37b2907":"code","f2be4105":"code","711191d6":"code","8c64d825":"code","6ba239dd":"code","9814262e":"code","99842bfd":"code","223369d8":"code","0150336d":"code","04743c1f":"code","6a5d631a":"code","7b2a607b":"code","27107f5d":"code","141d8553":"code","107ac4d5":"code","7a127f3e":"code","f3b50332":"code","bdffc68a":"markdown","df1982c2":"markdown","7f6f7e62":"markdown","76838205":"markdown","af9591ac":"markdown","d719e19a":"markdown","d0012191":"markdown","6b92eeb0":"markdown","39afb6d5":"markdown","75100cc0":"markdown","55162ba6":"markdown","dc5c126d":"markdown","53ab20f4":"markdown","36f36081":"markdown","0cc8de8f":"markdown","04601634":"markdown","43b0eb29":"markdown","0af6e8d5":"markdown","d33cbd11":"markdown","fedce828":"markdown","307bf923":"markdown","cee68624":"markdown","93d63eee":"markdown","76722b57":"markdown","751ee1b0":"markdown","b4da2b8b":"markdown","136d5fec":"markdown","a64b6f07":"markdown","4912f409":"markdown","851303c7":"markdown","926eb974":"markdown","5155537d":"markdown","7d714b4b":"markdown","13398665":"markdown","1fc21e3e":"markdown","69e66ab9":"markdown","f09460a4":"markdown","4ce2a90a":"markdown","1c4681c1":"markdown","c1832dff":"markdown","fd82ce1d":"markdown"},"source":{"9f9e5306":"! pip install pandas numpy matplotlib plotly dash-core-components scikit-learn dash missingpy yellowbrick","7fa68eff":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport dash_core_components as dcc\nimport sklearn\nimport plotly.figure_factory as ff\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression","19c36531":"df_fat_quantity = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Fat_Supply_Quantity_Data.csv')\ndf_food_quantity = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Food_Supply_Quantity_kg_Data.csv')\ndf_food_kcal = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Food_Supply_kcal_Data.csv')\ndf_protein_quantity = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Protein_Supply_Quantity_Data.csv')\ndf_food_description = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Supply_Food_Data_Descriptions.csv')","7ad187cb":"df_food_quantity.describe()","422a42cf":"x=df_food_quantity.corr(method='pearson').round(3)\nff.create_annotated_heatmap(z=x[['Deaths']].sort_values(by=['Deaths'],ascending=False).values, x = ['Deaths'], y=x[['Deaths']].sort_values(by=['Deaths'],ascending=False).index.to_list(), showscale=True, colorscale='Viridis')","59046226":"x=df_food_quantity.corr(method='pearson').round(3)\nff.create_annotated_heatmap(z=x.values, x = x.index.tolist(), y=x.index.to_list(), showscale=True, colorscale='Viridis')","a3cf7f91":"df_food_quantity.Deaths = df_food_quantity.Deaths.astype(np.float32)*100.0","7ae8d049":"df_food_quantity.Deaths = df_food_quantity.Deaths.map(lambda val: np.log(val + 1))","bb98736e":"df_food_quantity['Undernourished'] = df_food_quantity.apply(lambda row: 2.5 if row['Undernourished'] == '<2.5' else float(row['Undernourished']), axis = 1)","4a7aa6d5":"for feature_name in [\"Oilcrops\",'Alcoholic Beverages', 'Animal fats', 'Animal Products','Milk - Excluding Butter', 'Obesity', 'Vegetal Products']:\n    fig = go.Figure(px.histogram(df_food_quantity[feature_name],nbins=7))\n    fig.show()","e4b28321":"df_food_quantity = df_food_quantity.drop('Unit (all except Population)', axis=1)","f93e9e0f":"df_food_quantity = df_food_quantity.dropna()","e583c0a1":"df_food_quantity.iloc[:,1:24] = df_food_quantity.iloc[:, 1:24] * 2","553702f4":"# Mortality  = Deaths \/ Confirmed\ndf_food_quantity['Mortality'] = df_food_quantity['Deaths'] \/ df_food_quantity['Confirmed']","7c75583a":"# Distributions\nfig = px.bar(df_food_quantity, x = \"Country\", y =\"Confirmed\").update_xaxes(categoryorder=\"total descending\")\nfig.show()","953b9410":"fig = px.bar(df_food_quantity, x = \"Country\", y =\"Deaths\").update_xaxes(categoryorder=\"total descending\")\nfig.show()","d0fe1421":"# Distributions\n\n#Yemen data seem to be so over-evalued\nfig = px.bar(df_food_quantity, x = \"Country\", y =\"Mortality\").update_xaxes(categoryorder=\"total descending\")\nfig.show()","b9a6bc3b":"fig = px.scatter(df_food_quantity, x=\"Confirmed\", y = \"Deaths\",size = \"Active\", hover_name='Country', log_x=False,\n                 size_max=30, trendline = \"ols\", marginal_x = \"box\",marginal_y = \"violin\", template=\"simple_white\")\nfig.show()","d961d1e3":"# Investigate: does obesity rate affect impact of COVID-19","71fa8c2d":"fig = px.scatter(df_food_quantity[df_food_quantity.Country != 'Yemen'], x=\"Mortality\", y = \"Obesity\", size = \"Active\", hover_name='Country', log_x=False,\n                 size_max=30, template=\"simple_white\")\n\nfig.add_shape(\n        # Line Horizontal\n            type=\"line\",\n            x0=0,\n            y0=df_food_quantity[df_food_quantity.Country != 'Yemen']['Obesity'].mean(),\n            x1=df_food_quantity[df_food_quantity.Country != 'Yemen']['Mortality'].max(),\n            y1=df_food_quantity[df_food_quantity.Country != 'Yemen']['Obesity'].mean(),\n            line=dict(\n                color=\"crimson\",\n                width=4\n            ),\n    )\n\nfig.show()","0ba846b0":"fig = px.scatter(df_food_quantity, x=\"Deaths\", y = \"Obesity\", size = \"Mortality\", hover_name='Country', log_x=False,\n                 size_max=30, template=\"simple_white\")\n\nfig.add_shape(\n        # Line Horizontal\n            type=\"line\",\n            x0=0,\n            y0=df_food_quantity['Obesity'].mean(),\n            x1=df_food_quantity['Deaths'].max(),\n            y1=df_food_quantity['Obesity'].mean(),\n            line=dict(\n                color=\"crimson\",\n                width=4\n            ),\n    )\n\nfig.show()","2412181c":"df_high_ob = df_food_quantity[df_food_quantity.Obesity > df_food_quantity['Obesity'].mean()]\ndf_low_ob = df_food_quantity[df_food_quantity.Obesity <= df_food_quantity['Obesity'].mean()]","d261945f":"animal_features = ['Animal fats', 'Aquatic Products, Other', 'Eggs', 'Fish, Seafood', 'Meat',\n                   'Milk - Excluding Butter', 'Offals']\nvegetal_features = ['Alcoholic Beverages', 'Cereals - Excluding Beer', 'Fruits - Excluding Wine', 'Miscellaneous', 'Oilcrops', 'Pulses',\n                    'Spices', 'Starchy Roots', 'Stimulants', 'Sugar & Sweeteners', 'Sugar Crops', 'Treenuts',\n                    'Vegetable Oils', 'Vegetables']","3ef5475e":"fig = px.pie(values = df_high_ob[animal_features].mean().tolist(), names = animal_features,\n             title='Mean food intake by Animal products groups - High Obesity Countries')\nfig.show()","d33f6401":"fig = px.pie(values = df_low_ob[animal_features].mean().tolist(), names = animal_features,\n             title='Mean food intake by Animal products groups - Low Obesity Countries')\nfig.show()","c8a9bda8":"fig = px.pie(values = df_high_ob[vegetal_features].mean().tolist(), names = vegetal_features,\n             title='Mean food intake by Vegetal products groups - High Obesity Countries')\nfig.show()\n\nfig = px.pie(values = df_low_ob[vegetal_features].mean().tolist(), names = vegetal_features,\n             title='Mean food intake by Vegetal products groups - Low Obesity Countries')\nfig.show()","e26c746a":"df_food_quantity['ObesityAboveAverage'] = (df_food_quantity[\"Obesity\"] > df_food_quantity['Obesity'].mean()).astype(int)","63b83a74":"fig = px.scatter(df_food_quantity, x = 'Animal Products', y ='Vegetal Products',\n                 color='ObesityAboveAverage', hover_name = 'Country')\nfig.show()","5e8992d8":"fig = px.bar(df_food_quantity, x = \"Country\", y =\"Deaths\", facet_col = \"ObesityAboveAverage\")\nfig.update_xaxes(matches=None,categoryorder=\"total descending\")\nfig.show()","e62aab57":"fig = px.bar(df_food_quantity, x = \"Country\", y =\"Confirmed\", facet_col = \"ObesityAboveAverage\")\nfig.update_xaxes(matches=None,categoryorder=\"total descending\")\nfig.show()","b9758a3f":"fig = px.bar(df_food_quantity, x = \"Country\", y =\"Recovered\", facet_col = \"ObesityAboveAverage\")\nfig.update_xaxes(matches=None,categoryorder=\"total descending\")\nfig.show()","3ab1d656":"fig = px.scatter_matrix(df_food_quantity[['Meat', 'Milk - Excluding Butter', 'Fish, Seafood',\n                         'Cereals - Excluding Beer', 'Obesity','Mortality']])\nfig.show()","c977856e":"corr_food=df_food_quantity.loc[:, df_food_quantity.columns != 'ObesityAboveAvg'].corr(method='pearson')\ncorr_final=corr_food.abs().unstack().sort_values(ascending = False)\ncorr_final.drop(corr_final.head(32).index, inplace=True)\ncorr_confirmed = corr_final['Confirmed'].head(15)\ncorr_confirmed = corr_confirmed.drop(['Recovered', 'Deaths', 'Active', 'Undernourished', 'Obesity'])\ncorr_deaths = corr_final['Deaths'].head(15)\ncorr_deaths = corr_deaths.drop(['Recovered', 'Confirmed', 'Active', 'Undernourished', 'Obesity'])\ncorr_recovered = corr_final['Recovered'].head(14)\ncorr_recovered = corr_recovered.drop(['Confirmed', 'Deaths', 'Undernourished', 'Obesity'])","a61cf4e4":"corr_heatmap=df_food_quantity[['Deaths','Animal Products','Animal fats','Cereals - Excluding Beer','Eggs','Meat','Milk - Excluding Butter','Pulses','Starchy Roots','Sugar & Sweeteners','Vegetal Products']]\nx=corr_heatmap.corr(method='pearson')\nfig = go.Figure(ff.create_annotated_heatmap(z=x[['Deaths']].sort_values(by=['Deaths'],ascending=False).values, x = ['Deaths'], y=x[['Deaths']].sort_values(by=['Deaths'],ascending=False).index.to_list(), colorscale='Viridis'))\nfig.show()\n\ncorr_heatmap=df_food_quantity[['Confirmed','Animal Products','Animal fats','Cereals - Excluding Beer','Eggs','Meat','Milk - Excluding Butter','Pulses','Starchy Roots','Sugar & Sweeteners','Vegetal Products']]\nx=corr_heatmap.corr(method='pearson')\nfig = go.Figure(ff.create_annotated_heatmap(z=x[['Confirmed']].sort_values(by=['Confirmed'],ascending=False).values, x = ['Confirmed'], y=x[['Confirmed']].sort_values(by=['Confirmed'],ascending=False).index.to_list(), colorscale='Viridis'))\nfig.show()\n\ncorr_heatmap=df_food_quantity[['Recovered','Animal Products','Animal fats','Cereals - Excluding Beer','Eggs','Meat','Milk - Excluding Butter','Pulses','Starchy Roots','Sugar & Sweeteners','Vegetal Products']]\nx=corr_heatmap.corr(method='pearson')\nfig = go.Figure(ff.create_annotated_heatmap(z=x[['Recovered']].sort_values(by=['Recovered'],ascending=False).values, x = ['Recovered'], y=x[['Recovered']].sort_values(by=['Recovered'],ascending=False).index.to_list(), colorscale='Viridis'))\nfig.show()\n","c4be8052":"corr_heatmap=df_food_quantity[['Deaths','Confirmed','Recovered','Obesity','Undernourished', 'Mortality']]\nx=corr_heatmap.corr(method='pearson').round(3)\nff.create_annotated_heatmap(z=x.values, x=x.columns.to_list(), y=x.columns.to_list(), colorscale='Viridis', showscale=True)","2d0423ab":"obesity_set = df_food_quantity[df_food_quantity['Obesity'] == df_food_quantity['Obesity']].sort_values(by='Obesity', ascending=False).head(10)\nobesity_mean = obesity_set.describe().iloc[1]\nobesity_mean = pd.DataFrame(obesity_mean).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active'], axis=0)\nobesity_mean = obesity_mean.sort_values(by='mean', ascending=False).iloc[:11]","fa464793":"fig = px.pie(values = obesity_mean['mean'].values, names = obesity_mean.index.tolist(),\n             )\nfig.show()","890a630f":"undernutrition_set = df_food_quantity[df_food_quantity['Undernourished'] == df_food_quantity['Undernourished']].sort_values(by='Undernourished', ascending=False).head(10)\nundernutrition_mean = undernutrition_set.describe().iloc[1]\nundernutrition_mean = pd.DataFrame(undernutrition_mean).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active',], axis=0)\nundernutrition_mean = undernutrition_mean.sort_values(by='mean', ascending=False).iloc[:11]","4826d928":"fig = px.pie(values = undernutrition_mean['mean'].values, names = undernutrition_mean.index.tolist(),\n             )\nfig.show()","cd07e451":"feature_names = ['Animal fats', 'Alcoholic Beverages', 'Animal Products','Milk - Excluding Butter', 'Obesity', 'Vegetal Products']\nfor feature_name in feature_names:\n    fig = go.Figure(px.histogram(df_food_quantity[feature_name]))\n    fig.show()","c3953a70":"feature_names = ['Deaths', 'Recovered', 'Confirmed']\nfor feature_name in feature_names:\n    fig = go.Figure(px.histogram(df_food_quantity[feature_name]))\n    fig.show()","77d66875":"def zscore(mean, std, val):\n    epsilon = 0.000001\n    return (val - mean) \/ (epsilon + std)\nfeature_names=['Animal Products', 'Obesity', 'Vegetal Products','Animal fats', 'Milk - Excluding Butter' ]\nz_score_scaled_feature_names = ['Animal Products', 'Obesity', 'Vegetal Products']\nlog_scaled_feature_names = ['Animal fats', 'Milk - Excluding Butter']\n\ntraining_df_copy =df_food_quantity.copy()\nz_score_scaled_features = training_df_copy[z_score_scaled_feature_names].copy()\n\n# Apply z-score on 'Animal Products', 'Obesity' and 'Vegetal Products'\nfor feature_name in z_score_scaled_feature_names:\n    mean = z_score_scaled_features[feature_name].mean()\n    std = z_score_scaled_features[feature_name].std()\n    z_score_scaled_features[feature_name] = zscore(mean, std, z_score_scaled_features[feature_name])\n\nlog_scaled_features = training_df_copy[log_scaled_feature_names].copy()\nfor feature_name in log_scaled_feature_names:\n  # Apply log scaling for 'Cereals - Excluding Beer'\n    log_scaled_features[feature_name] = np.log(log_scaled_features[feature_name])","6006af84":"training_df_copy[z_score_scaled_feature_names]=z_score_scaled_features\ntraining_df_copy[log_scaled_feature_names] = log_scaled_features","cfad834f":"X = training_df_copy[feature_names]\ny = training_df_copy['Deaths']","341db79f":"from sklearn.utils import shuffle\n\nanimal_features = ['Animal fats', 'Aquatic Products, Other', 'Eggs', 'Fish, Seafood', 'Meat',\n                   'Milk - Excluding Butter', 'Offals']\nvegetal_features = ['Alcoholic Beverages', 'Cereals - Excluding Beer', 'Fruits - Excluding Wine', 'Miscellaneous', 'Oilcrops', 'Pulses',\n                    'Spices', 'Starchy Roots', 'Stimulants', 'Sugar & Sweeteners', 'Sugar Crops', 'Treenuts',\n                    'Vegetable Oils', 'Vegetables']\n\ndf_mort = df_food_quantity[df_food_quantity.Country != 'Yemen'][animal_features+vegetal_features+['Obesity','Mortality']]\n# df_mort = kg_df[['Animal Products','Vegetal Products','Obesity','Mortality']]\n\ndf_mort = shuffle(df_mort)\n\nmort_features = df_mort.columns.drop('Mortality')\nmort_target = 'Mortality'\n\nprint('Model features: ', mort_features)\nprint('Model target: ', mort_target)\n\nX = df_mort[mort_features]\ny = df_mort[mort_target]\n","419d5a51":"from missingpy import MissForest\n\n# Make an instance and perform the imputation\nimputer = MissForest()\nX_imputed = imputer.fit_transform(X)","707cd8a2":"X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, train_size=0.8, shuffle = True, random_state = 28)","5c1342b7":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n#Random Forest \nfrom sklearn.ensemble import RandomForestRegressor\nrandom_forest = RandomForestRegressor()\nrandom_forest.fit(X_train, y_train)\n\n#Arbre de regression\nfrom sklearn import tree\narbre_regression = tree.DecisionTreeRegressor()\narbre_regression.fit(X_train, y_train)\n\n# Regression lin\u00e9aire multiple\nfrom sklearn.linear_model import LinearRegression\nreg_multiple = LinearRegression()\nreg_multiple.fit(X_train, y_train)","1f606763":"print(reg_multiple.coef_)\nprint(reg_multiple.score(X_train, y_train))","9ba7b58c":"print('Mean squared error: %.2f'\n      % mean_squared_error(y_test, reg_multiple.predict(X_test)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, reg_multiple.predict(X_test)))","3bfb1b10":"print('Mean squared error: %.2f'\n      % mean_squared_error(y_test, random_forest.predict(X_test)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, random_forest.predict(X_test)))","68d1db99":"print('Mean squared error: %.2f'\n      % mean_squared_error(y_test, arbre_regression.predict(X_test)))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_test, arbre_regression.predict(X_test)))","e43384ac":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Create function to evaluate model on a few different scores\ndef show_scores(model, X_train, X_test, y_train, y_test):    \n    train_preds = model.predict(X_train)\n    test_preds = model.predict(X_test)\n    scores = {'Training MAE': mean_absolute_error(y_train, train_preds),\n              'Test MAE': mean_absolute_error(y_test, test_preds),\n              'Training MSE': mean_squared_error(y_train, train_preds),\n              'Test MSE': mean_squared_error(y_test, test_preds),\n              'Training R^2': r2_score(y_train, train_preds),\n              'Test R^2': r2_score(y_test, test_preds)}\n    return scores","168350c2":"from sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\n\n# First, we create a dict with our desired models\nmodels = {'Ridge':Ridge(random_state=28),\n          'SVR':SVR(),\n          'RandomForest':RandomForestRegressor(),\n          'XGBoost':XGBRegressor(n_estimators = 1000, learning_rate = 0.05)}\n\n# Now to build the function that tests each model\ndef model_build(model, X_train, y_train, X_test, y_test, scale=True):\n    \n    if scale:\n        regressor = Pipeline([\n            ('scaler', StandardScaler()),\n            ('estimator', model)\n        ])\n    \n    else:\n        regressor = Pipeline([\n            ('estimator', model)\n        ])\n\n    # Training\n    regressor.fit(X_train, y_train)\n\n    # Scoring the training set\n\n    train_preds = regressor.predict(X_train)\n    print(f\"R2 on single split: {regressor.score(X_train, y_train)}\")\n\n    # Cross validate\n    cv_score = cross_val_score(regressor, X_train, y_train, cv = 10)\n\n    print(f\"Cross validate R2 score: {cv_score.mean()}\")\n\n    # Scoring the test set\n    for k, v in show_scores(regressor, X_train, X_test , y_train, y_test).items():\n        print(\"     \", k, v)\n        \n    \nfor name, model in models.items():\n    print(f\"==== Scoring {name} model====\")\n    \n    if name == 'RandomForest' or name == 'XGBoost':\n        model_build(model, X_train, y_train, X_test, y_test, scale=False)\n    else:\n        model_build(model, X_train, y_train, X_test, y_test,)\n    print()\n    print(40*\"=\")\n        ","c36039f0":"model = RandomForestRegressor()\nmodel.fit(X_train, y_train)\n\ntest_preds = model.predict(X_test)\n\ntest_plot = pd.DataFrame(X_test, columns=X.columns)\ntest_plot['Mortality'] = y_test\ntest_plot['Mortality_pred'] = test_preds\n\ntest_plot.head()","94005984":"def plotTest(col, target, data):\n    fig, ax = plt.subplots(figsize=[10,8])\n\n    sns.regplot(x = col, y = target, data = data, ax = ax, label=target)\n    sns.regplot(x = col, y = target+'_pred', data = data, ax = ax, label=target+'_pred')\n\n    plt.legend();","9113fa3f":"import seaborn as sns\nplotTest('Animal fats', 'Mortality', test_plot)","74b03284":"There are MANY factors that are important to fight against the current COVID-19 epidemic. Maintaining good eating habits helps keep our immune system healthy and ready to combat a possible disease.\nIn this notebook I tried to explore possible patterns found in data of COVID-19 and food intake in different countries. One major goal was to find the influence of obesity rates in the effect of the disease in each country. Splitting countries into HOC and LOC groups, it was possible to create a classifier, with good accuracy, predicting in which group would a country be based on its food intake data.\nHaving this, we created regression models to try to predict the Mortality of COVID-19 in countries based on ther eating habits and obesity rate. Two approaches were taken: one with all food related features taken as parameters and a simpler one. Both have issues (mainly of spread and non-linearity), but we could show use of different models and metrics.","726d0b79":"df_fat_quantity = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Fat_Supply_Quantity_Data.csv')\ndf_food_quantity = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Food_Supply_Quantity_kg_Data.csv')\ndf_food_kcal = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Food_Supply_kcal_Data.csv')\ndf_protein_quantity = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Protein_Supply_Quantity_Data.csv')\ndf_food_description = pd.read_csv(r'..\/input\/covid19-healthy-diet-dataset\/Supply_Food_Data_Descriptions.csv')","98b16883":"df = pd.DataFrame()\ndf[[i+'-fat' for i in ['Country', 'Alcoholic Beverages', 'Animal fats',\n       'Cereals - Excluding Beer', 'Fruits - Excluding Wine', 'Miscellaneous',\n       'Milk - Excluding Butter', 'Stimulants', 'Sugar Crops',\n       'Sugar & Sweeteners', 'Vegetable Oils']]] = df_fat_quantity[['Country', 'Alcoholic Beverages', 'Animal fats',\n       'Cereals - Excluding Beer', 'Fruits - Excluding Wine', 'Miscellaneous',\n       'Milk - Excluding Butter', 'Stimulants', 'Sugar Crops',\n       'Sugar & Sweeteners', 'Vegetable Oils']]","050ae564":"df[[i+'-kcal' for i in df_food_kcal.columns[[2,4,5,6,7,9,11,13,14,15,16,19,20,21,22,23]]]]= df_food_kcal[df_food_kcal.columns[[2,4,5,6,7,9,11,13,14,15,16,19,20,21,22,23]]]","120f5afa":"df[[i+'-food' for i in df_food_quantity.columns[[1,2,3,12,17,18,19,21,23]]]]= df_food_quantity[df_food_quantity.columns[[1,2,3,12,17,18,19,21,23]]]","842dee67":"df[[i+'-protein' for i in df_protein_quantity.columns[[3,8]]]]= df_protein_quantity[df_protein_quantity.columns[[3,8]]]\ndf[[i+'-protein' for i in df_protein_quantity.columns[10:30]]]= df_protein_quantity[df_protein_quantity.columns[10:30]]","7ec044eb":"df['Undernourished-protein'] = df.apply(lambda row: 2.5 if row['Undernourished-protein'] == '<2.5' else float(row['Undernourished-protein']), axis = 1)","3de86a72":"for feature_name in df.columns:\n    fig = go.Figure(px.histogram(df[feature_name]))\n    fig.show()","1a24a010":"df = df.drop(columns=['Animal fats-food', 'Vegetal Products-food', 'Animal Products-kcal', 'Vegetal Products-kcal', 'Alcoholic Beverages-fat', 'Sugar Crops-fat', 'Sugar & Sweeteners-fat', 'Sugar & Sweeteners-food', 'Sugar Crops-protein','Aquatic Products, Other-kcal'])","b6d79abb":"x = np.corrcoef([df_food_quantity[\"Sugar & Sweeteners\"].values.tolist(),df_protein_quantity[\"Sugar & Sweeteners\"].values.tolist(),df_food_kcal['Sugar & Sweeteners'].values.tolist(),df_fat_quantity['Sugar & Sweeteners'].values.tolist()]).round(3)\nfig = go.Figure(ff.create_annotated_heatmap(z=x,x=['Sugar & Sweeteners-food',\"Sugar & Sweeteners-protein\",\"Sugar & Sweeteners-kcal\",\"Sugar & Sweeteners-fat\"],y=['Sugar & Sweeteners-food',\"Sugar & Sweeteners-protein\",\"Sugar & Sweeteners-kcal\",\"Sugar & Sweeteners-fat\"], colorscale='Viridis', showscale=True))\nfig.show()","4a434330":"for feature_name in df.columns[44:]:\n    fig = go.Figure(px.histogram(df[feature_name]))\n    fig.show()","38534d1f":"from missingpy import MissForest\n\n# Make an instance and perform the imputation\nimputer = MissForest()\nX = imputer.fit_transform(df[df.columns[1:]].values.tolist())","55a7bb53":"df[df.columns[1:]] = X","c71c0e1e":"corr_heatmap=df\nx=corr_heatmap.corr(method='pearson').round(3)\nfig = go.Figure(ff.create_annotated_heatmap(z=x[['Deaths-protein']].sort_values(by='Deaths-protein').values, x=['Deaths-protein'], y=x[['Deaths-protein']].sort_values(by='Deaths-protein').index.to_list(), colorscale='Viridis', showscale=True))\nfig.update_layout(height=1000)\nfig.show()","87d335aa":"corr_heatmap=df\nx=corr_heatmap.corr(method='pearson').round(3)\nfig = go.Figure(ff.create_annotated_heatmap(z=x[['Recovered-protein']].sort_values(by='Recovered-protein').values, x=['Recovered-protein'], y=x[['Recovered-protein']].sort_values(by='Recovered-protein').index.to_list(), colorscale='Viridis', showscale=True))\nfig.show()","d39b1295":"df = df.dropna()","e37e476b":"X = df[['Miscellaneous-protein', 'Sugar & Sweeteners-kcal', 'Meat-kcal', 'Pulses-kcal','Stimulants-protein','Oilcrops-kcal','Fruits - Excluding Wine-protein', 'Eggs-kcal']]\ny = df['Confirmed-protein']","38d8bd90":"X = df[['Miscellaneous-protein', 'Vegetables-protein', 'Obesity-protein', 'Undernourished-protein', 'Animal fats-fat']]\ny = df['Deaths-protein']","a12e3c0f":"X = df[['Miscellaneous-protein','Stimulants-fat' ,'Treenuts-protein', 'Eggs-kcal','Offals-protein']]\ny = df['Recovered-protein']","c293f28c":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nX_train, X_test, y_train, y_test = train_test_split(X.values.tolist(), y.values.tolist(), train_size=0.7, shuffle = True)\n#Random Forest \nfrom sklearn.ensemble import RandomForestRegressor\nrandom_forest = RandomForestRegressor()\nrandom_forest.fit(X_train, y_train)\n\n#Arbre de regression\nfrom sklearn import tree\narbre_regression = tree.DecisionTreeRegressor()\narbre_regression.fit(X_train, y_train)\n\n# Regression lin\u00e9aire multiple\nfrom sklearn.linear_model import LinearRegression\nreg_multiple = LinearRegression()\nreg_multiple.fit(X_train, y_train)\nprint('Mean squared error: %.2f'\n          % mean_squared_error(y_test, reg_multiple.predict(X_test)))\n    # The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n          % r2_score(y_test, reg_multiple.predict(X_test)))\n\nprint('Mean squared error: %.2f'\n          % mean_squared_error(y_test, arbre_regression.predict(X_test)))\n    # The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n          % r2_score(y_test, arbre_regression.predict(X_test)))\n\nprint('Mean squared error: %.2f'\n          % mean_squared_error(y_test, random_forest.predict(X_test)))\n    # The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n          % r2_score(y_test, random_forest.predict(X_test)))\n","6055c9e9":"test_df = pd.DataFrame()\ntest_df['random_forest_pred'] = random_forest.predict(X_test)\ntest_df['arbre_regression_pred'] = arbre_regression.predict(X_test)\ntest_df['regression_lineaire_mult_pred'] = reg_multiple.predict(X_test)","070e02d2":"from yellowbrick.regressor import ResidualsPlot\n\nvisualizer = ResidualsPlot(random_forest)\n\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show() ","640e569d":"from yellowbrick.regressor import ResidualsPlot\n\nvisualizer = ResidualsPlot(random_forest,hist=False, qqplot=True\n)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show() ","2deaf70d":"r2_score(y_test, random_forest.predict(X_test))","27ee4bf5":"from yellowbrick.regressor import ResidualsPlot\n\nvisualizer = ResidualsPlot(random_forest)\n\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show() ","11d8e8c8":"from yellowbrick.regressor import ResidualsPlot\n\nvisualizer = ResidualsPlot(random_forest,hist=False, qqplot=True\n)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show() ","9e5c3f92":"print('Mean squared error: %.5f'\n              % mean_squared_error(y_test, random_forest.predict(X_test)))","2f1292fa":"from sklearn.decomposition import PCA","f37b2907":"pca = PCA(n_components=6)\npca.fit(df[df.columns[1:20]])","f2be4105":"print(pca.explained_variance_ratio_)","711191d6":"X = pca.transform(df[df.columns[1:20]])\ny = df['Deaths-protein']","8c64d825":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nX_train, X_test, y_train, y_test = train_test_split(X.tolist(), y.values.tolist(), train_size=0.8, shuffle = True)\n#Random Forest w\nfrom sklearn.ensemble import RandomForestRegressor\nrandom_forest = RandomForestRegressor()\nrandom_forest.fit(X_train, y_train)\n\n#Arbre de regression\nfrom sklearn import tree\narbre_regression = tree.DecisionTreeRegressor()\narbre_regression.fit(X_train, y_train)\n\n# Regression lin\u00e9aire multiple\nfrom sklearn.linear_model import LinearRegression\nreg_multiple = LinearRegression()\nreg_multiple.fit(X_train, y_train)\n\nprint('Linear Regression')\nprint('Mean squared error: %.2f'\n          % mean_squared_error(y_test, reg_multiple.predict(X_test)))\n    # The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n          % r2_score(y_test, reg_multiple.predict(X_test)))\n\nprint('Regression Tree')\nprint('Mean squared error: %.2f'\n          % mean_squared_error(y_test, reg_multiple.predict(X_test)))\n    # The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n          % r2_score(y_test, reg_multiple.predict(X_test)))\n\nprint('Random Forest')\nprint('Mean squared error: %.2f'\n          % mean_squared_error(y_test, reg_multiple.predict(X_test)))\n    # The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n          % r2_score(y_test, reg_multiple.predict(X_test)))\n","6ba239dd":"print(X.shape)\nprint(y.shape)","9814262e":"r2_score(y_test, random_forest.predict(X_test))","99842bfd":"r2_score(y_test, arbre_regression.predict(X_test))","223369d8":"from yellowbrick.regressor import ResidualsPlot\n\nvisualizer = ResidualsPlot(reg_multiple)\n\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show() ","0150336d":"from yellowbrick.regressor import ResidualsPlot\n\nvisualizer = ResidualsPlot(reg_multiple,hist=False, qqplot=True\n)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show() ","04743c1f":"X = df[['Miscellaneous-protein', 'Vegetables-protein', 'Obesity-protein',  'Animal fats-fat']].values","6a5d631a":"from sklearn.preprocessing import StandardScaler\nscalerX = StandardScaler().fit(X)\nX_scaled = scalerX.transform(X)\n\n# Using the elbow method to find the optimal number of clusters\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X_scaled)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\n#plt.show()\nfigure = plt.gcf()  # get current figure\nfigure.set_size_inches(8, 4) # set figure's size manually to your full screen (32x18)\n#plt.savefig(\"Elbow.png\", bbox_inches='tight') # bbox_inches removes extra white spaces\nplt.show()","7b2a607b":"# K = 4 ","27107f5d":"num_opt_clusters=3\n\n# Fitting K-Means to the dataset\nkmeans = KMeans(n_clusters = num_opt_clusters, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X_scaled)\ndataset =df[['Miscellaneous-protein', 'Vegetables-protein', 'Obesity-protein', 'Animal fats-fat']].copy()\noriginal_len=dataset.shape[0]\nfor i in range(0,original_len):\n    dataset.loc[i,\"Cluster\"]=y_kmeans[i]\n    \nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.title('Cluster Analysis',fontsize=20, fontweight='bold')\nplt.xlabel('Obesity',fontsize=16, fontweight='bold')\nplt.ylabel('Confirmed',fontsize=16, fontweight='bold')\n\nfigure = plt.gcf()  # get current figure\nfigure.set_size_inches(32, 18) # set figure's size manually to your full screen (32x18)\nplt.show()","141d8553":"dataset['Deaths'] = df['Deaths-protein']\ndataset['Country'] = df['Country-fat']","107ac4d5":"dataset.groupby('Cluster').mean()","7a127f3e":"dataset.groupby('Cluster').count()","f3b50332":"In summary, a country\u2019s COVID-19 confirmed and active cases can somehow be explained relatively well by food categories such as the calorie contents of oilcrops, and the protein content in infant food and miscellaneous\nfood. On the other hand, the same cannot be said about the death and recovered cases. This could be due to the fact that these models do not satisfy the neccessary model assumptions of having equal variance and\nnormally distributed residuals. However, it is also important to note that mortality has not had an outcome, and hence the first model should only be taken as a grain of salt. \n\nHowever, recall that this model only talks about the correlation between food categories and the rate of deaths. \n\nThere is no evidence to suggest that a country\u2019s diet has an effect on the spread of COVID-19. Additionally, there are also many other factors causing the spread of COVID-19 that are totally uncorrelated with diet, eg. how active the general public are, the preventive measures implemented by the\ncountries, density of population etc.","bdffc68a":"Analysis: we see there is a relation between high consuption of Animal Products (comparing with Vegetal Products) and high obesity rates. Using the hover information you can find the country with highest Animal Products intake (Finland) and the one with highest Vegetal Products intake (Nigeria).","df1982c2":"In the figure above, we can see clearly that the \"high obesity rate\" countries have a worst impact from COVID-19.","7f6f7e62":"Indeed, we can now see that obesity has a stronger correlation with covid deaths than recovery and undernourished patients has a stronger correlation with covid recovery than deaths.\n\nThis could mean that in average, obese patients are most likely to die from covid while undernourished are most likely to survive. This is why obesity worsens outcomes from covid.\n\nSuch results are to be interpreted carefully as many other factors are to be taken into account - for example, undernourished patients are most likely to be in emerging countries, where the population is very young and most likely to survive.","76838205":"Analysis: The distributions are somewhat similar. The order of highest to lowest intake is the same (except for Offals and Animal fats). However, two things stand out:\n\nThe Milk - Excluding Butter intake int he first group is huge (almost  60% !)\nThe difference between the Fish, Seafood intake in both groups (the first - around  7% , the second - around  20% ).","af9591ac":"#### Undernutrition average diet ","d719e19a":"### Random Forest ","d0012191":"#### Health diet vs COVID19","6b92eeb0":"Indeed, we can now see that obesity has a stronger correlation with covid deaths than recovery and undernourished patients has a stronger correlation with covid recovery than deaths.\n\nThis could mean that in average, obese patients are most likely to die from covid while undernourished are most likely to survive. This is why obesity worsens outcomes from covid.\n\nSuch results are to be interpreted carefully as many other factors are to be taken into account - for example, undernourished patients are most likely to be in emerging countries, where the population is very young and most likely to survive.","39afb6d5":"#### High obesity rates countries : Animal products","75100cc0":"## Results ","55162ba6":"## Data Splitting","dc5c126d":"## Goal: predict Mortality ","53ab20f4":"### Regression Tree","36f36081":"**The goal of this analysis is to find out how a country\u2019s diet correlates with its COVID-19 mortality rate. With different food cultures across the world, it would be interesting to see what are the food categories that can best predict a country\u2019s rate of deaths. **","0cc8de8f":"By visualizing the histograms we can conclude the following:\n\nAnimal Products, Obesity and Vegetal Products have a roughly normal distribution. We'll probably just scale their values using z-score formula.\nAlcoholic Beverages, Animal Fats, Milk - Excluding Butter,  on the other hand, present a right skewed distribution. Maybe a log scalling we'll help us getting a normal distribution for those two features.","04601634":"#### Obesity average diet","43b0eb29":"#### Distributions  ","0af6e8d5":"#### Vegetal products","d33cbd11":"So, we are interested in the last \"row\" of this matrix. Nothing seems particularly linear, but we'll see what we can tell from building linear models.","fedce828":"### Method 2","307bf923":"# Conclusion","cee68624":"Now we can easily spot the differences. Here undernourished people consume way less animal products and much more starchy roots than the world's consumption in average or the obese people on average. Moreover, they seem to be consuming a bit more alcoholic beverages.","93d63eee":"# Data Exploratory and Analysis","76722b57":"The pie chart above looks a lot like the average pie chart diet we made earlier for the world consumption. The countries with the most obesity rate seem to consume more vegetables than people on average.","751ee1b0":"### Linear Regression","b4da2b8b":"## Missing Values","136d5fec":"### Food Quantity Data ","a64b6f07":"# PCA  ","4912f409":"The intake of Starchy Roots in Low Obesity Countries is almost  20% , double that of High Obesity Countries.\nThe intake of Alcoholic Beverages is at  5.8%  in Low Obesity Countries, as in High Obesity Countries it reaches almost  10% .","851303c7":"# Import packages","926eb974":"# K-Means ","5155537d":"#### Obesity between countries High or Low Obesity  ? ","7d714b4b":"### Response Variables","13398665":"## Train Models ","1fc21e3e":"# Supervised Approach","69e66ab9":"### Animal Products:  Which products make the difference between High and Low Obesity countries  ?","f09460a4":"### Diet vs COVID19 ","4ce2a90a":"## Improve Models ?  ","1c4681c1":"### Results \/ Predictions ","c1832dff":"## Predict Deaths ","fd82ce1d":"Conclusion: The \"high mortality\" and \"high death rate\" countries all seem to have an above average obesity rate."}}