{"cell_type":{"51c9502a":"code","a2e0211c":"code","9da9ec73":"code","4959dd31":"code","f32d13ba":"code","9e51aec4":"code","b0f4b972":"code","2af8a8c3":"code","2dff2fc0":"code","92c1b681":"code","6ff59bd0":"code","97eed50e":"code","d240cf03":"code","bb371070":"code","2f3ce01f":"code","3113269e":"code","fac36fa5":"code","2592e60e":"code","7f086802":"code","fcc7973a":"code","250da578":"code","bde6856c":"code","85e81ba0":"code","d0999c42":"code","068aabbe":"code","a8e4d8cf":"code","63bf2aac":"code","030998d3":"code","90ea6d72":"code","4374d95d":"code","91307e13":"code","a8cc2d41":"code","3b1d10bc":"code","ac8e2c9b":"code","88765664":"code","94a10ee0":"code","096e8e44":"code","214ab666":"code","71af2d45":"markdown","54e8f79b":"markdown","f0e50d6b":"markdown","e2e3f376":"markdown","943700b2":"markdown","da7dc5d9":"markdown","7694363e":"markdown","0a63daa5":"markdown","57889c7f":"markdown","34514d79":"markdown","7f14363e":"markdown","1d07e2d3":"markdown","9c9e530a":"markdown","0f5fa43f":"markdown"},"source":{"51c9502a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a2e0211c":"cr_loan = pd.read_csv('..\/input\/creditdefault\/cr_loan2.csv')","9da9ec73":"#\u00a0Structure\u00a0of\u00a0the\u00a0data\nprint(cr_loan.dtypes)\n","4959dd31":"#\u00a0Check\u00a0the\u00a0first\u00a0five\u00a0rows\u00a0of\u00a0the\u00a0data\nprint(cr_loan.head(5))\n","f32d13ba":"# Look at the distribution of loan amounts with a histogram\nn, bins, patches = plt.hist(x=cr_loan['loan_amnt'], bins='auto', color='blue',alpha=0.7, rwidth=0.85)\nplt.xlabel(\"Loan Amount\")\nplt.show()\n","9e51aec4":"print(\"There\u00a0are\u00a032\u00a0000\u00a0rows\u00a0of\u00a0data\u00a0so\u00a0the\u00a0scatter\u00a0plot\u00a0may\u00a0take\u00a0a\u00a0little\u00a0while\u00a0to\u00a0plot.\")\n#\u00a0Plot\u00a0a\u00a0scatter\u00a0plot\u00a0of\u00a0income\u00a0against\u00a0age\nplt.scatter(cr_loan['person_income'], cr_loan['person_age'],c='blue',alpha=0.5)\nplt.xlabel('Personal\u00a0Income')\nplt.ylabel('Persone\u00a0Age')\nplt.show()\n","b0f4b972":"#\u00a0Create\u00a0a\u00a0cross\u00a0table\u00a0of\u00a0the\u00a0loan\u00a0intent\u00a0and\u00a0loan\u00a0status\nprint(pd.crosstab(cr_loan['loan_intent'],cr_loan['loan_status'],margins = True))\n","2af8a8c3":"#\u00a0Create\u00a0a\u00a0cross\u00a0table\u00a0of\u00a0home\u00a0ownership,\u00a0loan\u00a0status,\u00a0and\u00a0grade\nprint(pd.crosstab(cr_loan['person_home_ownership'],[cr_loan['loan_status'],cr_loan['loan_grade']]))\n","2dff2fc0":"#\u00a0Create\u00a0a\u00a0cross\u00a0table\u00a0of\u00a0home\u00a0ownership,\u00a0loan\u00a0status,\u00a0and\u00a0average\u00a0percent\u00a0income\nprint(pd.crosstab(cr_loan['person_home_ownership'],cr_loan['loan_status'],values=cr_loan['loan_percent_income'],aggfunc='mean'))\n","92c1b681":"#\u00a0Create\u00a0the\u00a0cross\u00a0table\u00a0for\u00a0loan\u00a0status,\u00a0home\u00a0ownership,\u00a0and\u00a0the\u00a0max\u00a0employment\u00a0length\nprint(pd.crosstab(cr_loan['loan_status'],cr_loan['person_home_ownership'],values=cr_loan['person_emp_length'],aggfunc='max'))\n","6ff59bd0":"# Create the scatter plot for age and amount\nplt.scatter(cr_loan['person_age'], cr_loan['loan_amnt'], c='blue', alpha=0.5)\nplt.xlabel(\"Person Age\")\nplt.ylabel(\"Loan Amount\")\nplt.show()\n","97eed50e":"import matplotlib\n#\u00a0Use\u00a0Pandas\u00a0to\u00a0drop\u00a0the\u00a0record\u00a0from\u00a0the\u00a0data\u00a0frame\u00a0and\u00a0create\u00a0a\u00a0new\u00a0one\ncr_loan_new=cr_loan.drop(cr_loan[cr_loan['person_age']>100].index)\n#\u00a0Create\u00a0a\u00a0scatter\u00a0plot\u00a0of\u00a0age\u00a0and\u00a0interest\u00a0rate\ncolors=[\"blue\",\"red\"]\nplt.scatter(cr_loan_new['person_age'],cr_loan_new['loan_int_rate'],c=cr_loan_new['loan_status'],cmap=matplotlib.colors.ListedColormap(colors),alpha=0.5)\nplt.xlabel(\"Person\u00a0Age\")\nplt.ylabel(\"Loan\u00a0Interest\u00a0Rate\")\nplt.show()\n","d240cf03":"#\u00a0Print\u00a0an\u00a0array\u00a0of\u00a0columns\u00a0with\u00a0null\u00a0values\nprint(cr_loan.columns[cr_loan.isnull().any()])\n#\u00a0Print\u00a0the\u00a0top\u00a0five\u00a0rows\u00a0with\u00a0nulls\u00a0for\u00a0employment\u00a0length\nprint(cr_loan[cr_loan['person_emp_length'].isnull()].head())\n#\u00a0Replace\u00a0the\u00a0null\u00a0values\u00a0with\u00a0the\u00a0median\u00a0value\u00a0for\u00a0all\u00a0employment\u00a0lengths\ncr_loan['person_emp_length'].fillna((cr_loan['person_emp_length'].median()),inplace=True)\n#\u00a0Create\u00a0a\u00a0histogram\u00a0of\u00a0employment\u00a0length\nn,bins,patches=plt.hist(cr_loan['person_emp_length'],bins='auto',color='blue')\nplt.xlabel(\"Person\u00a0Employment\u00a0Length\")\nplt.show()\n","bb371070":"#\u00a0Print\u00a0the\u00a0number\u00a0of\u00a0nulls\nprint(cr_loan['loan_int_rate'].isnull().sum())\n#\u00a0Store\u00a0the\u00a0array\u00a0on\u00a0indices\nindices=cr_loan[cr_loan['loan_int_rate'].isnull()].index\n#\u00a0Save\u00a0the\u00a0new\u00a0data\u00a0without\u00a0missing\u00a0data\ncr_loan_clean=cr_loan.drop(indices)\n","2f3ce01f":"#\u00a0Create\u00a0two\u00a0data\u00a0sets\u00a0for\u00a0numeric\u00a0and\u00a0non-numeric\u00a0data\ncred_num=cr_loan_clean.select_dtypes(exclude=['object'])\ncred_str=cr_loan_clean.select_dtypes(include=['object'])\n#\u00a0One-hot\u00a0encode\u00a0the\u00a0non-numeric\u00a0columns\ncred_str_onehot=pd.get_dummies(cred_str)\n#\u00a0Union\u00a0the\u00a0one-hot\u00a0encoded\u00a0columns\u00a0to\u00a0the\u00a0numeric\u00a0ones\ncr_loan_prep=pd.concat([cred_num,cred_str_onehot],axis=1)\n#\u00a0Print\u00a0the\u00a0columns\u00a0in\u00a0the\u00a0new\u00a0data\u00a0set\nprint(cr_loan_prep.columns)\n","3113269e":"y = cr_loan_prep['loan_status'].copy()\ndf= cr_loan_prep.drop(['loan_status'],axis=1)\nX=df.copy()\nX.head()","fac36fa5":"from sklearn.model_selection import train_test_split\n#\u00a0Use\u00a0test_train_split\u00a0to\u00a0create\u00a0the\u00a0training\u00a0and\u00a0test\u00a0sets\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.4,random_state=123)\n","2592e60e":"#\u00a0Train\u00a0a\u00a0model\nimport xgboost as xgb\n\nclf_gbt = xgb.XGBClassifier().fit(X_train, np.ravel(y_train))\n\n#\u00a0Predict\u00a0with\u00a0a\u00a0model\ngbt_preds = clf_gbt.predict_proba(X_test)\n\n#\u00a0Create\u00a0dataframes\u00a0of\u00a0first\u00a0five\u00a0predictions,\u00a0and\u00a0first\u00a0five\u00a0true\u00a0labels\npreds_df = pd.DataFrame(gbt_preds[:,1][0:5],columns = ['prob_default'])\ntrue_df = y_test.head()\n#\u00a0Concatenate\u00a0and\u00a0print\u00a0the\u00a0two\u00a0data\u00a0frames\u00a0for\u00a0comparison\nprint(pd.concat([true_df.reset_index(drop=True),preds_df],axis=1))\n","7f086802":"preds_df.head()","fcc7973a":"from sklearn.metrics import classification_report\n#\u00a0Create\u00a0a\u00a0dataframe\u00a0for\u00a0the\u00a0probabilities\u00a0of\u00a0default\npreds_df1 = pd.DataFrame(gbt_preds[:,1], columns = ['prob_default'])\n#\u00a0Reassign\u00a0loan\u00a0status\u00a0based\u00a0on\u00a0the\u00a0threshold\npreds_df1['loan_status']=preds_df1['prob_default'].apply(lambda x: 1 if x > 0.5 else 0)\n#\u00a0Print\u00a0the\u00a0row\u00a0counts\u00a0for\u00a0each\u00a0loan\u00a0status\nprint(preds_df1['loan_status'].value_counts())\n#\u00a0Print\u00a0the\u00a0classification\u00a0report\ntarget_names = ['Non-Default', 'Default']\nprint(classification_report(y_test, preds_df1['loan_status'], target_names=target_names))\n","250da578":"from sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\n# Logistic Regression\n\nclf_logistic = LogisticRegression(solver='lbfgs')\nclf_logistic.fit(X_train,y_train)\n\n#\u00a0Create\u00a0predictions\u00a0and\u00a0store\u00a0them\u00a0in\u00a0a\u00a0variable\npreds = clf_logistic.predict_proba(X_test)\n\n#\u00a0Print\u00a0the\u00a0accuracy\u00a0score\u00a0the\u00a0model\nprint(clf_logistic.score(X_test, y_test))\n\n#\u00a0Plot\u00a0the\u00a0ROC\u00a0curve\u00a0of\u00a0the\u00a0probabilities\u00a0of\u00a0default\nprob_default = preds[:, 1]\nfallout, sensitivity,thresholds = roc_curve(y_test, prob_default)\nplt.plot(fallout, sensitivity, color = 'darkorange')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.show()\n\n#\u00a0Compute\u00a0the\u00a0AUC\u00a0and\u00a0store\u00a0it\u00a0in\u00a0a\u00a0variable\nauc = roc_auc_score(y_test, prob_default)\n","bde6856c":"print(preds[:5,:])","85e81ba0":"import xgboost as xgb\nfrom sklearn.model_selection import cross_val_score\nclf_gbt = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 7)\n\nclf_gbt.fit(X_train, np.ravel(y_train))\n","d0999c42":"\n#\u00a0Print\u00a0the\u00a0accuracy\u00a0score\u00a0the\u00a0model\nprint(clf_gbt.score(X_test, y_test))\n","068aabbe":"#\u00a0Plot\u00a0the\u00a0column\u00a0importance\u00a0for\u00a0this\u00a0model\nxgb.plot_importance(clf_gbt,importance_type='weight')\nplt.show()\n","a8e4d8cf":"\ngbt = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 7)\n\n#\u00a0Calculate\u00a0the\u00a0cross\u00a0validation\u00a0scores\u00a0for\u00a04\u00a0folds\ncv_scores = cross_val_score(gbt, X_train, np.ravel(y_train), cv = 4)\n\n#\u00a0Print\u00a0the\u00a0cross\u00a0validation\u00a0scores\nprint(cv_scores)\n\n#\u00a0Print\u00a0the\u00a0average\u00a0accuracy\u00a0and\u00a0standard\u00a0deviation\u00a0of\u00a0the\u00a0scores\nprint(\"Average\u00a0accuracy:\u00a0%0.2f\u00a0(+\/-\u00a0%0.2f)\" % (cv_scores.mean(),cv_scores.std()*2))\n","63bf2aac":"X_train.head()","030998d3":"X_test.head()","90ea6d72":"test_pred_df = X_test.copy()\ntest_pred_df.head()","4374d95d":"# Logistic Regression\n\nclf_logistic = LogisticRegression(solver='lbfgs')\nclf_logistic.fit(X_train,y_train)\n\n#\u00a0Create\u00a0predictions\u00a0and\u00a0store\u00a0them\u00a0in\u00a0a\u00a0variable\npreds = clf_logistic.predict_proba(test_pred_df)\n\n#\u00a0Print\u00a0the\u00a0accuracy\u00a0score\u00a0the\u00a0model\nprint(clf_logistic.score(test_pred_df, y_test))\n\n#\u00a0Calculating Probability of Default\nprob_default = preds[:, 1]\n","91307e13":"test_pred_df['prob_default'] = prob_default\ntest_pred_df['loss_given_default'] = 1\ntest_pred_df.head()","a8cc2d41":"#\u00a0Calculate\u00a0the\u00a0bank's\u00a0expected\u00a0loss\u00a0and\u00a0assign\u00a0it\u00a0to\u00a0a\u00a0new\u00a0column\ntest_pred_df['expected_loss'] = test_pred_df['prob_default'] * test_pred_df['loan_amnt']*test_pred_df['loss_given_default']\n\n#\u00a0Calculate\u00a0the\u00a0total\u00a0expected\u00a0loss\u00a0to\u00a0two\u00a0decimal\u00a0places\ntot_exp_loss = round(np.sum(test_pred_df['expected_loss']),2)\n#\u00a0Print\u00a0the\u00a0total\u00a0expected\u00a0loss\nprint('Total\u00a0expected\u00a0loss: ', '${:,.2f}'.format(tot_exp_loss))\n","3b1d10bc":"test_pred_df.head()","ac8e2c9b":"import xgboost as xgb\nfrom sklearn.model_selection import cross_val_score\n\nclf_gbt = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 7)\n\nclf_gbt.fit(X_train, np.ravel(y_train))\n","88765664":"X_test.head()","94a10ee0":"#\u00a0Print\u00a0the\u00a0accuracy\u00a0score\u00a0the\u00a0model\nprint(clf_gbt.score(X_test, y_test))\n\n","096e8e44":"#\u00a0Create\u00a0predictions\u00a0and\u00a0store\u00a0them\u00a0in\u00a0a\u00a0variable\npreds = clf_gbt.predict_proba(X_test)\n\n#\u00a0Calculating Probability of Default\nprob_default = preds[:, 1]\n\ntest_pred_df['prob_default'] = prob_default\ntest_pred_df['loss_given_default'] = 1\ntest_pred_df.head()","214ab666":"#\u00a0Calculate\u00a0the\u00a0bank's\u00a0expected\u00a0loss\u00a0and\u00a0assign\u00a0it\u00a0to\u00a0a\u00a0new\u00a0column\ntest_pred_df['expected_loss'] = test_pred_df['prob_default'] * test_pred_df['loan_amnt']*test_pred_df['loss_given_default']\n\n#\u00a0Calculate\u00a0the\u00a0total\u00a0expected\u00a0loss\u00a0to\u00a0two\u00a0decimal\u00a0places\ntot_exp_loss = round(np.sum(test_pred_df['expected_loss']),2)\n#\u00a0Print\u00a0the\u00a0total\u00a0expected\u00a0loss\nprint('Total\u00a0expected\u00a0loss: ', '${:,.2f}'.format(tot_exp_loss))\n","71af2d45":"## Applying One-Hot Encoding on Categorical Columns","54e8f79b":"# Default Classification Reporting","f0e50d6b":"## XGBoost and Cross Validation","e2e3f376":"## Calculating Expected Loss with Logistic Regression\nIt's time to estimate the total expected loss given all your decisions. The data frame\u00a0test_pred_df\u00a0has the probability of default for each loan and that loan's value. Use these two values to calculate the expected loss for each loan. Then, you can sum those values and get the total expected loss.\n![image.png](attachment:image.png)\n\nFor this exercise, you will assume that the exposure is the full value of the loan, and the loss given default is 100%. This means that a default on each the loan is a loss of the entire amount.\n\n","943700b2":"## Visualizing Performance(Using ROC Curve) of the Credit Risk Model based on Logistic Regression  ","da7dc5d9":"## Using Trees for Defaults Detection\n\nYou will now train a gradient boosted tree model on the credit data, and see a sample of some of the predictions. \n","7694363e":"## Data Preparation ","0a63daa5":"## Scatter Plots","57889c7f":"## Problem Statement | Predicting Loan Default\n\nCredit risk modeling refers to data driven risk models which calculates the chances of a borrower defaults on loan (or credit card). \nIf a borrower fails to repay loan, how much amount he\/she owes at the time of default and how much lender would lose from the outstanding amount. \n\n","34514d79":"## Replacing Missing Values","7f14363e":"# Initial Data Exploration(EDA)","1d07e2d3":"## Analysis of Loan Status\n\nThe pandas crosstab function builds a cross-tabulation table that can show the frequency with which certain groups of data appear. Here we see count of loan status for different loan intent.","9c9e530a":"# Steps to Solve the Loan Default Problem\n\n1. Problem Statement\n2. Exploratory Data Analysis\n3. Preprocessing\n4. Feature Selection and Importance\n5. Initial Classification for Exploration\n6. Improving Classification Performance with Cross Validation, Managing Dataset Imbalance etc\n7. Calculating Credit Risk\n ","0f5fa43f":"## Using XGBoost for Predicting Loan Default Risk"}}