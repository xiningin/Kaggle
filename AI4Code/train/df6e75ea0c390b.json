{"cell_type":{"c4f1cadf":"code","d1a7cb79":"code","5ab15e25":"code","fe524fb8":"code","fead0cbe":"code","24f8b7e2":"code","2bfc4824":"code","844f4859":"code","0815f8b7":"markdown","1166421c":"markdown","8a7aeb70":"markdown","7bf5c299":"markdown","f1618df2":"markdown","cffbf053":"markdown","e8936fb4":"markdown","397e1c3e":"markdown","83e315ea":"markdown"},"source":{"c4f1cadf":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndf_train = pd.read_csv(\"..\/input\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/test.csv\")","d1a7cb79":"df_train.head()","5ab15e25":"df_test.head()","fe524fb8":"import matplotlib.pyplot as plt\n\nprint(\"Pandas Version:\", pd.__version__)\n\ndef prepare_dataset(df):\n    X = df\n    Y = None\n    if 'label' in df.columns:\n        # to_numpy()\ub294 0.24.0 \uc774\uc0c1\ubd80\ud130 \uc9c0\uc6d0\n        Y = df[\"label\"].values.reshape([-1, 1])\n        X = df.drop(\"label\", axis=1)\n    \n    # to_numpy()\ub294 0.24.0 \uc774\uc0c1\ubd80\ud130 \uc9c0\uc6d0\n    X = X.values\n    return X, Y\n\ntrain_X, train_Y = prepare_dataset(df_train)\nsubmit_X, _ = prepare_dataset(df_test)\n\nntest = 10\nfig, ax = plt.subplots(nrows=1, ncols=ntest, figsize=(20, 3))\n\nindices = np.random.randint(0, train_X.shape[0], ntest)\nfor idx, i in enumerate(indices):    \n    ax[idx].imshow(train_X[i].reshape(28, 28))\n    ax[idx].set_title(train_Y[i])\n    \nplt.show()","fead0cbe":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n\ndef make_model(input_shape, label_cnt, dropout_r = 0.3):\n    model = Sequential()\n    \n    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(2, 2), padding='Same', activation='relu', input_shape=input_shape))\n    model.add(BatchNormalization())\n              \n    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='Same', activation='relu', input_shape=input_shape))\n    model.add(BatchNormalization())\n              \n    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='Same', activation='relu', input_shape=input_shape))\n    model.add(BatchNormalization())\n    \n    model.add(Flatten())\n    \n    model.add(Dense(512, activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(BatchNormalization())\n    \n    # \ucd9c\ub825 \ud06c\uae30\ub97c label\uc758 one-hot encoding\ud55c \uc0ac\uc774\uc988\uc640 \ub3d9\uc77c\ud558\uac8c \ub9de\ucdb0\uc900\ub2e4.\n    model.add(Dense(label_cnt, activation='softmax'))\n              \n    return model","24f8b7e2":"from keras.callbacks import ReduceLROnPlateau\n'''\nmonitor : \ud310\ub2e8\ud560 log\uc758 \uc774\ub984\nfactor : \ubcc0\uacbd\ud560 \ube44\uc728 (new_lr = lr * factor)\npatience : \ud574\ub2f9 \uac12 \ub9cc\ud07c\uc758 epoch\uc774 \uc9c0\ub0a0 \ub3d9\uc548 \uc815\ud655\ub3c4\uac00 \uc88b\uc544\uc9c0\uc9c0 \uc54a\uc73c\uba74 \uc801\uc6a9\ub41c\ub2e4.\n'''\nlr_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.25, min_lr=0.000001)","2bfc4824":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=16,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.15, # Randomly zoom image \n    width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=False,  # randomly flip images\n    vertical_flip=False)  # randomly flip images\n\ntrain_X, _ = prepare_dataset(df_train)\ndatagen.fit(train_X.reshape(-1, 28, 28, 1))","844f4859":"from keras.utils.np_utils import to_categorical\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\n\nwidth = 28\nheight = 28\nchannel = 1\nclasses = 10\n\n# \ub370\uc774\ud130 \uc0dd\uc131\ntrain_X, train_Y = prepare_dataset(df_train)\nsubmit_X, _ = prepare_dataset(df_test)\n\n# reshape to image\ntrain_X = train_X.reshape(-1, width, height, channel)\nsubmit_X = submit_X.reshape(-1, width, height, channel)\n\ntrain_X = train_X \/ 255.0\nsubmit_X = submit_X \/ 255.0\n\ntrain_Y = to_categorical(train_Y, num_classes = classes)\nprint(\"train_Y.shape=\", train_Y.shape)\n\n# \ubaa8\ub378 \uc0dd\uc131\nmodel = make_model((width, height, channel), label_cnt = classes, dropout_r=0.3)\nmodel.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nbatch_size = 400\ntotal_batch = int(train_X.shape[0] \/ batch_size)\nprint(\"total_batch=\",total_batch)\n\nepochs = 30\nn_splits = 10\n\nuse_generator = True\n\n# \ubaa8\ub378 \ud6c8\ub828 \ubc0f \ud3c9\uac00\nhistory = None\nif use_generator:\n    #\ubbf8\ub9ac \ub370\uc774\ud130\ub97c \ucabc\uac1c\uc11c validation data\ub85c \uc0ac\uc6a9\ud558\uac70\ub098, \uadf8\ub0e5 validation data\ub3c4 generator\ub85c \ub123\uac70\ub098 \ud55c\ub2e4.\n    #X_train, X_val, Y_train, Y_val = train_test_split(train_X, train_Y, test_size = 0.1, random_state=84)\n    history = model.fit_generator(datagen.flow(train_X, train_Y, batch_size=batch_size),\n                                  epochs = epochs,\n                                  #validation_data = (X_val, Y_val),\n                                  validation_data = datagen.flow(train_X, train_Y, batch_size=batch_size),\n                                  verbose = 2,\n                                  steps_per_epoch=total_batch,\n                                  validation_steps=total_batch,\n                                  callbacks=[lr_reduction])\nelse:     \n    history = model.fit(train_X, train_Y, batch_size=batch_size,\n                        epochs=epochs, validation_split=0.1)\n\n# show statistics:\nfig, ax = plt.subplots(1, 1, figsize=(12,8))\nax.plot(history.history['acc'], 'b-', label=\"accuracy\")\nax.set_title(\"accuracy\")\nplt.show()\n\n# test \ub370\uc774\ud130\ub85c submission.csv\uc0dd\uc131:\nsubmit_Y = model.predict(submit_X.reshape(-1, width, height, channel))\nsubmit_Y = np.argmax(submit_Y, axis=1)              \nids = [x for x in range(1, submit_Y.shape[0] + 1)]\npd_submit = pd.DataFrame({'ImageId':ids, 'Label':submit_Y})\npd_submit.to_csv(\"submission.csv\", index=False)\n","0815f8b7":"## 1. Introduction\n\n\uc774 \ubb38\uc81c\ub294  0~9 \uc0ac\uc774\uc758 \uc22b\uc790 \uc774\ubbf8\uc9c0\uc778 MNIST Dataset\uc758 subset\uc744 \uc608\uce21\ud574\uc11c \uc81c\ucd9c\ud558\ub294 \uac83\uc785\ub2c8\ub2e4. ","1166421c":"## 4. \ud6c8\ub828 \/ \uc81c\ucd9c\n\n\uc704\uc758 \ucf54\ub4dc\ub4e4\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc74c \uacfc\uc815\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n- \ub370\uc774\ud130 \uc0dd\uc131 \n- \ubaa8\ub378 \uc0dd\uc131\n- \ubaa8\ub378 \ud6c8\ub828 \ubc0f \ud3c9\uac00\n- test \ub370\uc774\ud130\ub85c submission.csv\uc0dd\uc131\n","8a7aeb70":"## 2. \ub370\uc774\ud130 \uc900\ube44\n\n\ub370\uc774\ud130\ub294 csv\ud30c\uc77c\uc5d0 \ud589\ub2f9 \uc774\ubbf8\uc9c0 pixel\uc774 pixel0~pixel783 column\uc73c\ub85c \ub4e4\uc5b4\uac00 \uc788\uc2b5\ub2c8\ub2e4.<br>\nMNIST \uc774\ubbf8\uc9c0\ub294 width\/height\/channel\uc774 28\/28\/1\uc785\ub2c8\ub2e4.\n\n\ub370\uc774\ud130 \ucc98\ub9ac\ub97c \uc27d\uac8c \ud558\uae30 \uc704\ud574 train\/test csv\ud30c\uc77c\uc744 pandas DataFrame\uc73c\ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4.","7bf5c299":"submission \uc608\uce21\uc744 \uc798\ud558\uae30 \uc704\ud574\uc11c\ub294 \ucd5c\ub300\ud55c \uc8fc\uc5b4\uc9c4 \uc774\ubbf8\uc9c0\ub97c \uc798 \ud559\uc2b5\ud574\uc57c \ud558\uba74\uc11c overfitting\uc744 \ud53c\ud574\uc57c \ud569\ub2c8\ub2e4.<br>\nImageDataGenerator\ub97c \uc0ac\uc6a9\ud558\uba74 \ub2e4\uc74c\uc758 \uc7a5\uc810\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\n- **\uc774\ubbf8\uc9c0 \ubcc0\ud615\uc744 \ud1b5\ud574 train\ub370\uc774\ud130\uc758 \uc218\ub97c \ubb34\ud55c\ud788 \ub298\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.**\n- **\ubaa8\ub378\uc774 \uc785\ub825\ub418\ub294 \ub370\uc774\ud130\ub294 \uc6d0\ubcf8 train \ub370\uc774\ud130\uc640 \ub2e4\ub974\ubbc0\ub85c train \ub370\uc774\ud130\uc5d0 \ub300\ud55c overfitting\uc744 \uc904\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4.**\n\n\nImageDataGenerator\ub294 \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\ub97c \ubcc0\ud615\ud574\uc11c \uc774\ubbf8\uc9c0\ub4e4\uc744  batch \ub2e8\uc704\ub85c \ub118\uaca8\uc90d\ub2c8\ub2e4.\n\nfit()\uc740 feature-wise\ud55c \ubcc0\ud615 \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud560\uc9c0 \uc54a\ub294\ub2e4\uba74 \uc0dd\ub7b5\ud574\ub3c4 \ub429\ub2c8\ub2e4. \ub2e8, \uae30\uc874 \ub370\uc774\ud130\uc758 \ud1b5\uacc4 \uac12\uc744 \uc0ac\uc6a9\ud574\uc11c \uc801\uc6a9\ud574\uc57c \ud558\ub294 \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud55c\ub2e4\uba74(featurewise_XXX, zca_whitening \ub4f1) fit()\uc744 \ud1b5\ud574 ImageDataGenerator\ub97c \uba3c\uc800 '\ud559\uc2b5(fit)' \uc2dc\ucf1c\uc57c \ud569\ub2c8\ub2e4.","f1618df2":"## 3. \ubaa8\ub378 \uc0dd\uc131\n\nConvolution \ub808\uc774\uc5b4\ub4e4 \uc774\ud6c4\uc5d0 FC \ub808\uc774\uc5b4\ub97c \ubd99\uc774\uace0 \ucd9c\ub825  \ud06c\uae30\ub97c 10\uc73c\ub85c \ud558\uace0 \ub9c8\uc9c0\ub9c9\uc740 activation\uc744 softmax\ub85c \ud569\ub2c8\ub2e4.<br>\nMNIST \uc774\ubbf8\uc9c0\uc758 \ucc28\uc6d0\uc740 (28,28,1)\ub85c \ub2e8\uc21c\ud558\ubbc0\ub85c layer\ub294 \uc801\ub2f9\ud788 \ub9cc\ub4e4\uace0 image augmentation\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 submission \uc815\ud655\ub3c4\ub97c \ub04c\uc5b4\uc62c\ub9ac\ub294 \uac83\uc5d0 \ub354 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.\n\n\ucd94\uac00\ub85c, CONV\/Activation\/BN\/Dropout\uc758 \uc21c\uc11c \ubc0f \uad6c\uc131 \ubc29\ubc95\uc5d0 \ub300\ud574\uc11c \uac80\uc0c9\ud55c \ub0b4\uc6a9\uc785\ub2c8\ub2e4.\n(\ucd9c\ucc98 : https:\/\/stackoverflow.com\/questions\/39691902\/ordering-of-batch-normalization-and-dropout)\n- BN \uc0ac\uc6a9\uc2dc\uc5d0\ub294 Dropout\uc774 \ud544\uc694 \uc5c6\uc2b5\ub2c8\ub2e4.(BN\uc774 Dropout\uacfc \ube44\uc2b7\ud55c regularization \ubc29\ubc95\uc744 \uc81c\uacf5\ud558\uae30 \ub54c\ubb38\uc5d0)\n    - https:\/\/arxiv.org\/pdf\/1801.05134.pdf\n- 2015\ub144\uc5d0 CONV\/FC\uc640 Activation \uc0ac\uc774\uc5d0 BN\uc774 \uc640\uc57c \ud55c\ub2e4\ub294 \ub17c\ubb38\uc774 \uc788\uc5c8\uc9c0\ub9cc, \uc774\ud6c4 \ub17c\ubb38 \uc800\uc790\ub3c4 Activation \uc774\ud6c4\uc5d0 BN\uc744 \ubc30\uce58\ud558\uace0 \uc788\ub2e4\ub294 \ub0b4\uc6a9\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n    - https:\/\/arxiv.org\/pdf\/1502.03167.pdf\n\n\ud14c\uc2a4\ud2b8 \uacb0\uacfc, \uc77c\ubc18\uc801\uc778 CONV\/POOLING\/FC(\ub9c8\uc9c0\ub9c9\uc740 softmax)\ub85c \ubaa8\ub378\uc744 \uad6c\uc131\ud574\ub3c4 90% \uc774\uc0c1 submission \uc815\ud655\ub3c4\uac00 \uc624\ub974\ub294 \uac83\uc744 \ud655\uc778\ud558\uc600\uc2b5\ub2c8\ub2e4. \n\nImageDataGenerator\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub370\uc774\ud130 \uc218\ub97c \ub298\ub9ac\uace0 overfitting \uc99d\uc0c1\uc744 \uc904\uc774\ub294 \uac83\uc73c\ub85c submission \uc815\ud655\ub3c4\ub97c 99%\uae4c\uc9c0 \ub298\ub9b4 \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.","cffbf053":"Learning Rate\ub294 optimizer\uac00 gradient descent\ub97c \ubc18\uc601\ud558\ub294 \uc815\ub3c4\uc785\ub2c8\ub2e4.<br>\n\uac12\uc774 \ud074 \uc218\ub85d loss\uac12\uc774 \uc801\uc5b4\uc9c0\ub294 \ubc29\ud5a5\uc73c\ub85c \ud30c\ub77c\uba54\ud130 \uac12\uc774 \ub354 \ud06c\uac8c \ubcc0\ud558\uc9c0\ub9cc Local minima(\uc9c0\uc5ed\uc801\uc73c\ub85c\ub294 loss\uac00 \uc791\uc740 \uac12\uc774\uc9c0\ub9cc \uc804\uccb4\uc801\uc73c\ub85c \ucd5c\uc18c\uac12\uc774 \uc544\ub2d8)\uc5d0 \ube60\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4. <br>\nKeras.callbacks\uc758 ReduceLROnPlateau \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc77c\uc815 epoch \uc774\ud6c4 \uc815\ud655\ub3c4\uac00 \ud5a5\uc0c1\ub418\uc9c0 \uc54a\uc73c\uba74 Learning Rate\ub97c \uc870\uc808\ud558\ub3c4\ub85d \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","e8936fb4":"test \ub370\uc774\ud130\ub294 label\uc774 \uc5c6\ub294 \uac83\uc744 \uc81c\uc678\ud558\uace0 train\uacfc \ub3d9\uc77c\ud55c \ud615\ud0dc\uc785\ub2c8\ub2e4.<br>\ntest\uc758 pixel0~pixel783 \uc73c\ub85c \uc0dd\uc131\ud55c model\uc5d0\uc11c \ub3cc\ub824\uc11c \uacb0\uacfc\ub97c \uc81c\ucd9c\ud574\uc57c \ud569\ub2c8\ub2e4.","397e1c3e":"# Kaggle Digit Recognizer - Keras \/ CNN \uad6c\ud604\n\n* **1. Introduction**\n* **2. \ub370\uc774\ud130 \uc900\ube44**\n* **3. \ubaa8\ub378 \uc0dd\uc131**\n* **4. \ud6c8\ub828 \/ \uc81c\ucd9c**","83e315ea":"train.csv, test.csv\ud30c\uc77c\uc744 \uc77d\uc5b4\uc11c Pandas DataFrame\uc73c\ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4.<br>\nDataFrame\uc744 numpy array\ub85c \ubcc0\ud658\ud558\uace0 train DataFrame\uc5d0\uc11c\ub294 label \uc815\ubcf4\ub3c4 \ucd94\ucd9c\ud569\ub2c8\ub2e4."}}