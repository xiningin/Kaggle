{"cell_type":{"aa9af37b":"code","6acc1542":"code","d257a503":"code","ab45c6d5":"code","d73ca32c":"code","e25cbebc":"code","e6a861a4":"code","9bec7679":"code","dd11636d":"code","e88c70e0":"code","8b6edae2":"code","412775bb":"code","04390397":"code","f68cec9f":"code","0a82dff5":"code","9666daac":"code","ab0d0fb1":"code","a44e1093":"code","00d10dc0":"code","c4c54a64":"code","86da70e6":"code","8081f63a":"code","c7edecc4":"code","3496d3a7":"code","26b93713":"code","7b176d96":"code","5c831c2f":"code","e0082249":"code","df758ce4":"code","db42e463":"code","3d74264f":"code","4c7a2a7f":"code","05ea2380":"code","76e9e22c":"code","c873794e":"code","5f4271be":"code","0934ed31":"code","351292aa":"code","f9e3f612":"code","7cf5172f":"code","a0511550":"code","d320d0ab":"code","a6c27878":"code","cbe04514":"code","398af6d8":"code","6737a6e9":"code","8d13cc4f":"code","8aeb6fd4":"code","d8079a09":"code","2e0bda45":"code","4c911b67":"code","26cc427b":"code","924681eb":"code","49791537":"code","bff15c94":"code","128f5227":"code","c880a498":"code","5894a522":"code","6ff27bdf":"code","6a39641c":"code","07acbe65":"code","c418ef62":"code","3dc387f4":"code","d09e055b":"code","3693fec7":"code","eacaa138":"code","b77a4d4c":"code","919f1209":"code","f224ce1d":"code","5558af12":"code","eff6e7de":"code","aab2f304":"code","5e55771a":"code","99c04820":"code","0a2bb1f4":"code","d4accd2a":"code","327cd7c9":"code","5578860e":"code","a6dc2437":"code","3550becf":"code","8796847d":"code","6b1733a7":"code","c92a0d64":"code","8e1eab88":"code","f07ae6a4":"code","d519251c":"code","4cf2a9fc":"code","1acf9480":"code","5280d013":"code","5e41b149":"code","a31846e0":"code","1dda0284":"code","e14c55cd":"code","4b91a506":"code","6599adee":"code","d6736fc5":"code","fd3e792f":"code","08306752":"code","d0b17409":"code","5d9fb690":"code","3ccbe1f6":"code","f75177a6":"code","f0ebd459":"code","05396d66":"code","5a9bf58e":"code","137b8245":"code","d6653594":"code","b8b7d098":"code","ccb6418c":"code","87f82e9b":"code","76c0dfb1":"code","9114bee2":"code","37650f7c":"code","b776a0c8":"code","a909c08b":"code","90dcffd4":"code","456c6479":"code","0359bcfa":"code","fe379b49":"code","25cbcc41":"code","852213be":"code","1885629c":"code","5b9dfea5":"code","f22f0154":"code","2e630b35":"code","5128bdf4":"markdown","6cf429db":"markdown","81c96623":"markdown","5ef4bf18":"markdown","7867f01c":"markdown","b24a843a":"markdown","fe2c5bfd":"markdown","61e9040b":"markdown","bb35adc8":"markdown","0d62d620":"markdown","4143bded":"markdown","dec37711":"markdown","bfc060fc":"markdown","37ffb2e8":"markdown","07567149":"markdown","63924971":"markdown","993a54f1":"markdown","8db07fcc":"markdown","8907b6a7":"markdown","43f3882d":"markdown","a3e9cbb7":"markdown","dd7604a0":"markdown","cb70567b":"markdown","8926fcc1":"markdown","7634fb67":"markdown","cb0c9f41":"markdown","05b0e237":"markdown","a0fe2679":"markdown","65d8d00b":"markdown","def23e2a":"markdown","8b98eedf":"markdown","a6da48d5":"markdown","d40a2b73":"markdown","42d88f5d":"markdown","c2379c86":"markdown","3c224071":"markdown","7feb4a39":"markdown","b49834bc":"markdown","a2aa9dcc":"markdown","9f030883":"markdown","460ce8e7":"markdown","01aac90d":"markdown","3c692e7d":"markdown","15f318d6":"markdown","f719ecee":"markdown","2f0a22e5":"markdown","16ccf2c5":"markdown","67f908d4":"markdown","8eb0f0b4":"markdown","3dccd547":"markdown","989b389d":"markdown","8132f767":"markdown","0a31afe3":"markdown","91d525b4":"markdown","63507405":"markdown","d4a4fe02":"markdown","eebf61ea":"markdown","1dc7196c":"markdown","dd828c11":"markdown","3d87938f":"markdown","d45349db":"markdown","e5b8f80d":"markdown","6945f796":"markdown","f873a648":"markdown","c1a59210":"markdown","98a7945a":"markdown","8ba534dd":"markdown","7a15dbee":"markdown","57feed0b":"markdown","bad041ce":"markdown","941a1d1a":"markdown","b0a92478":"markdown","622bee66":"markdown","1a401976":"markdown","e8cbd413":"markdown","c0116334":"markdown","d6abb7b0":"markdown","0d111d7f":"markdown","4ac74fcb":"markdown","99c4b8ea":"markdown","3cf1bde3":"markdown","9c81bff0":"markdown","1cbb1f42":"markdown","2cc1aa18":"markdown","88b29514":"markdown","7fa49751":"markdown","f65728ee":"markdown","2464de32":"markdown","b747688e":"markdown","97d4afa5":"markdown","ca812d2c":"markdown","9f5e7656":"markdown","0370dc8a":"markdown","0bb6fda6":"markdown"},"source":{"aa9af37b":"%matplotlib inline","6acc1542":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","d257a503":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer, f1_score, accuracy_score, classification_report, confusion_matrix","ab45c6d5":"from xgboost import XGBClassifier","d73ca32c":"train_data = pd.read_csv(\"..\/input\/airline-passenger-satisfaction\/train.csv\")","e25cbebc":"test_data = pd.read_csv(\"..\/input\/airline-passenger-satisfaction\/test.csv\")","e6a861a4":"train_data.head()","9bec7679":"train_data.shape","dd11636d":"test_data.head()","e88c70e0":"test_data.shape","8b6edae2":"def set_index(dataset):\n    \"\"\"\n    Makes \"Unnamed: 0\" index column.\n    \n    Arguments: a dataset.\n    \n    Returns: dataset with new index column\n    \"\"\"   \n    return dataset.set_index(\"Unnamed: 0\", inplace = True)","412775bb":"set_index(train_data)\nset_index(test_data)","04390397":"train_data.head()","f68cec9f":"test_data.head()","0a82dff5":"print(f'Unique items in `id` column, train data: {len(train_data[\"id\"].unique())}')\nprint(f'Unique items in `id` column, test data: {len(test_data[\"id\"].unique())}')","9666daac":"def drop_id(dataset):\n    \"\"\"\n    Makes Removes `id` column.\n    \n    Arguments: a dataset.\n    \n    Returns: dataset without `id` column\n    \"\"\" \n    return dataset.drop(\"id\", axis = 1, inplace = True)","ab0d0fb1":"drop_id(train_data)\ndrop_id(test_data)","a44e1093":"train_data.head()","00d10dc0":"train_data.info()","c4c54a64":"test_data.info()","86da70e6":"def plot_counts(col, order = None):\n    \"\"\"\n    Counts and plots categorical features.\n    \n    Arguments: a feature; optional: order of display.\n    \n    Returns: plot of counts in categorical features\n    \"\"\" \n    plt.figure(figsize = (7, 4))\n    \n    plt.subplot(121)\n    plt.title(\"In train data\")\n    sns.countplot(data = train_data, x = col, palette = \"coolwarm\", order = order)\n\n    plt.subplot(122)\n    plt.title(\"In test data\")\n    sns.countplot(data = test_data, x = col, palette = \"coolwarm\", order = order)\n\n    plt.tight_layout()\n    plt.show()","8081f63a":"plot_counts(\"Gender\", [\"Male\", \"Female\"])","c7edecc4":"plot_counts(\"Customer Type\", [\"Loyal Customer\", \"disloyal Customer\"])","3496d3a7":"plot_counts(\"Type of Travel\", [\"Personal Travel\", \"Business travel\"])","26b93713":"plot_counts(\"Class\", [\"Eco\", \"Eco Plus\", \"Business\"])","7b176d96":"plot_counts(\"satisfaction\", [\"satisfied\", \"neutral or dissatisfied\"])","5c831c2f":"for i in train_data.columns:\n    print(\"-----%s-----\" % i)\n    print(train_data[i].value_counts())","e0082249":"plot_counts(\"Inflight wifi service\", [0, 1, 2, 3, 4, 5])","df758ce4":"plot_counts(\"Departure\/Arrival time convenient\", [0, 1, 2, 3, 4, 5])","db42e463":"plot_counts(\"Ease of Online booking\", [0, 1, 2, 3, 4, 5])","3d74264f":"plot_counts(\"Gate location\", [0, 1, 2, 3, 4, 5])","4c7a2a7f":"plot_counts(\"Food and drink\", [0, 1, 2, 3, 4, 5])","05ea2380":"plot_counts(\"Online boarding\", [0, 1, 2, 3, 4, 5])","76e9e22c":"plot_counts(\"Seat comfort\", [0, 1, 2, 3, 4, 5])","c873794e":"plot_counts(\"On-board service\", [0, 1, 2, 3, 4, 5])","5f4271be":"plot_counts(\"Leg room service\", [0, 1, 2, 3, 4, 5])","0934ed31":"plot_counts(\"Baggage handling\", [1, 2, 3, 4, 5])","351292aa":"plot_counts(\"Checkin service\", [0, 1, 2, 3, 4, 5])","f9e3f612":"plot_counts(\"Inflight service\", [0, 1, 2, 3, 4, 5])","7cf5172f":"plot_counts(\"Cleanliness\", [0, 1, 2, 3, 4, 5])","a0511550":"train_data.satisfaction.unique()","d320d0ab":"def count_two_vars(var1, var2):\n    \"\"\"\n    Counts and plots a categorical feature against another categorical feature.\n    \n    Arguments: \n        two categorical features.\n    \n    Returns: \n        plot showing interaction between two categorical features\n    \"\"\" \n    fig, ax = plt.subplots(figsize = (8, 5))\n    \n    plt.subplot(121)\n    plt.title(\"In train data\")\n    sns.countplot(data = train_data, x = var1, hue = var2, order = [\"neutral or dissatisfied\", \"satisfied\"])\n\n    plt.subplot(122)\n    plt.title(\"In test data\")\n    sns.countplot(data = test_data, x = var1, hue = var2, order = [\"neutral or dissatisfied\", \"satisfied\"])\n\n    plt.tight_layout()\n    plt.show()","a6c27878":"count_two_vars(\"satisfaction\", \"Gender\")","cbe04514":"count_two_vars(\"satisfaction\", \"Cleanliness\")","398af6d8":"count_two_vars(\"satisfaction\", \"Inflight entertainment\")","6737a6e9":"def count_items_in_continuous_variables(dataset, feature):\n    \"\"\"\n    Counts items in continuous variables.\n    \n    Arguments: \n        A dataset, a feature.\n    \n    Returns: \n        Number of distinct items in a continuous variable.\n    \"\"\" \n    return print(f\"{len(dataset[feature].unique())} unique items in {feature} column\")","8d13cc4f":"count_items_in_continuous_variables(train_data, \"Age\")\ncount_items_in_continuous_variables(train_data, \"Flight Distance\")\ncount_items_in_continuous_variables(train_data, \"Departure Delay in Minutes\")\ncount_items_in_continuous_variables(train_data, \"Arrival Delay in Minutes\")","8aeb6fd4":"count_items_in_continuous_variables(test_data, \"Age\")\ncount_items_in_continuous_variables(test_data, \"Flight Distance\")\ncount_items_in_continuous_variables(test_data, \"Departure Delay in Minutes\")\ncount_items_in_continuous_variables(test_data, \"Arrival Delay in Minutes\")","d8079a09":"def check_nans(dataset):\n    \"\"\"\n    Checks if there are, and (if so) - which column holds missing values.\n    \n    Arguments: \n        A dataset.\n    \n    Returns: \n        Boolean statement against each feature confirming or denying missing values.\n    \"\"\" \n    \n    return dataset.isna().any()","2e0bda45":"check_nans(train_data)","4c911b67":"check_nans(test_data)","26cc427b":"train_data[train_data[\"Arrival Delay in Minutes\"].isna()]","924681eb":"test_data[test_data[\"Arrival Delay in Minutes\"].isna()]","49791537":"train_data[\"Arrival Delay in Minutes\"].fillna(0, inplace = True)\ntest_data[\"Arrival Delay in Minutes\"].fillna(0, inplace = True)","bff15c94":"check_nans(train_data[\"Arrival Delay in Minutes\"])","128f5227":"check_nans(test_data[\"Arrival Delay in Minutes\"])","c880a498":"def plot_distribution(col):\n    \"\"\"\n    Displays distribution of numeric features in both sets.\n    \n    Arguments: \n        A numeric feature.\n    \n    Returns: \n        Histogram of distributions of values in a feature found in train and test set.\n    \"\"\" \n    fig = plt.figure(figsize = (8, 5))\n    \n    plt.subplot(121)\n    plt.title(\"In train data\")\n    sns.histplot(train_data[col])\n    \n    plt.subplot(122)\n    plt.title(\"In test data\")\n    sns.histplot(test_data[col])\n    \n    plt.tight_layout()\n    plt.show()","5894a522":"plot_distribution(\"Age\")","6ff27bdf":"plot_distribution(\"Flight Distance\")","6a39641c":"def plot_delays(col):\n    \n    \"\"\"\n    Displays distribution of delayed minutes in both sets.\n    \n    Arguments: \n        A feature showing delay time.\n    \n    Returns: \n        Histogram of distributions of delay time in train and test set.\n    \"\"\" \n    \n    \n    fig = plt.figure(figsize = (8, 5))\n    \n    plt.subplot(121)\n    plt.hist(train_data[col], bins = 20)\n    plt.title(\"In train data\")\n    \n    plt.subplot(122)\n    plt.hist(test_data[col])\n    plt.title(\"In test data\")\n    \n    plt.tight_layout()\n    plt.show()","07acbe65":"plot_delays(\"Departure Delay in Minutes\")","c418ef62":"plot_delays(\"Arrival Delay in Minutes\")","3dc387f4":"numeric_features = train_data[[\"Age\", \"Flight Distance\", \"Departure Delay in Minutes\", \"Arrival Delay in Minutes\"]]","d09e055b":"fig, axs = plt.subplots(ncols = 4, nrows = 1, figsize = (12, 4))\nidx = 0\naxs = axs.flatten()\nfor k, v in numeric_features.items():\n    sns.boxplot(y = k, data = numeric_features, ax = axs[idx]) #color = \"Blues\"\n    idx += 1\nplt.tight_layout(pad = 0.5, w_pad = 0.5, h_pad = 5.0)","3693fec7":"numeric_features.describe().T","eacaa138":"label_encoder = LabelEncoder()","b77a4d4c":"train_data[\"satisfaction\"] = label_encoder.fit_transform(train_data[\"satisfaction\"])\ntest_data[\"satisfaction\"] = label_encoder.fit_transform(test_data[\"satisfaction\"])","919f1209":"train_data[\"satisfaction\"].unique()","f224ce1d":"train_one_hot = pd.get_dummies(train_data, columns = [\"Gender\", \"Customer Type\", \"Type of Travel\", \"Class\", \"Inflight wifi service\", \"Departure\/Arrival time convenient\", \"Ease of Online booking\", \"Gate location\", \"Food and drink\", \"Online boarding\", \"Seat comfort\", \"Inflight entertainment\", \"On-board service\", \"Leg room service\", \"Baggage handling\", \"Checkin service\", \"Inflight service\", \"Cleanliness\"])","5558af12":"test_one_hot = pd.get_dummies(test_data, columns = [\"Gender\", \"Customer Type\", \"Type of Travel\", \"Class\", \"Inflight wifi service\", \"Departure\/Arrival time convenient\", \"Ease of Online booking\", \"Gate location\", \"Food and drink\", \"Online boarding\", \"Seat comfort\", \"Inflight entertainment\", \"On-board service\", \"Leg room service\", \"Baggage handling\", \"Checkin service\", \"Inflight service\", \"Cleanliness\"])","eff6e7de":"train_one_hot.shape, test_one_hot.shape","aab2f304":"train_one_hot.columns.difference(test_one_hot.columns)","5e55771a":"test_one_hot[\"Checkin service_0\"] = 0\ntest_one_hot[\"Gate location_0\"] = 0\ntest_one_hot[\"Seat comfort_0\"] = 0","99c04820":"test_one_hot.head()","0a2bb1f4":"train_one_hot.columns","d4accd2a":"train_one_hot = train_one_hot[['Age', 'Flight Distance', 'Departure Delay in Minutes',\n       'Arrival Delay in Minutes', 'Gender_Female',\n       'Gender_Male', 'Customer Type_Loyal Customer',\n       'Customer Type_disloyal Customer', 'Type of Travel_Business travel',\n       'Type of Travel_Personal Travel', 'Class_Business', 'Class_Eco',\n       'Class_Eco Plus', 'Inflight wifi service_0', 'Inflight wifi service_1',\n       'Inflight wifi service_2', 'Inflight wifi service_3',\n       'Inflight wifi service_4', 'Inflight wifi service_5',\n       'Departure\/Arrival time convenient_0',\n       'Departure\/Arrival time convenient_1',\n       'Departure\/Arrival time convenient_2',\n       'Departure\/Arrival time convenient_3',\n       'Departure\/Arrival time convenient_4',\n       'Departure\/Arrival time convenient_5', 'Ease of Online booking_0',\n       'Ease of Online booking_1', 'Ease of Online booking_2',\n       'Ease of Online booking_3', 'Ease of Online booking_4',\n       'Ease of Online booking_5', 'Gate location_0', 'Gate location_1',\n       'Gate location_2', 'Gate location_3', 'Gate location_4',\n       'Gate location_5', 'Food and drink_0', 'Food and drink_1',\n       'Food and drink_2', 'Food and drink_3', 'Food and drink_4',\n       'Food and drink_5', 'Online boarding_0', 'Online boarding_1',\n       'Online boarding_2', 'Online boarding_3', 'Online boarding_4',\n       'Online boarding_5', 'Seat comfort_0', 'Seat comfort_1',\n       'Seat comfort_2', 'Seat comfort_3', 'Seat comfort_4', 'Seat comfort_5',\n       'Inflight entertainment_0', 'Inflight entertainment_1',\n       'Inflight entertainment_2', 'Inflight entertainment_3',\n       'Inflight entertainment_4', 'Inflight entertainment_5',\n       'On-board service_0', 'On-board service_1', 'On-board service_2',\n       'On-board service_3', 'On-board service_4', 'On-board service_5',\n       'Leg room service_0', 'Leg room service_1', 'Leg room service_2',\n       'Leg room service_3', 'Leg room service_4', 'Leg room service_5',\n       'Baggage handling_1', 'Baggage handling_2', 'Baggage handling_3',\n       'Baggage handling_4', 'Baggage handling_5', 'Checkin service_0',\n       'Checkin service_1', 'Checkin service_2', 'Checkin service_3',\n       'Checkin service_4', 'Checkin service_5', 'Inflight service_0',\n       'Inflight service_1', 'Inflight service_2', 'Inflight service_3',\n       'Inflight service_4', 'Inflight service_5', 'Cleanliness_0',\n       'Cleanliness_1', 'Cleanliness_2', 'Cleanliness_3', 'Cleanliness_4',\n       'Cleanliness_5', 'satisfaction']]","327cd7c9":"test_one_hot = test_one_hot[['Age', 'Flight Distance', 'Departure Delay in Minutes',\n       'Arrival Delay in Minutes', 'Gender_Female',\n       'Gender_Male', 'Customer Type_Loyal Customer',\n       'Customer Type_disloyal Customer', 'Type of Travel_Business travel',\n       'Type of Travel_Personal Travel', 'Class_Business', 'Class_Eco',\n       'Class_Eco Plus', 'Inflight wifi service_0', 'Inflight wifi service_1',\n       'Inflight wifi service_2', 'Inflight wifi service_3',\n       'Inflight wifi service_4', 'Inflight wifi service_5',\n       'Departure\/Arrival time convenient_0',\n       'Departure\/Arrival time convenient_1',\n       'Departure\/Arrival time convenient_2',\n       'Departure\/Arrival time convenient_3',\n       'Departure\/Arrival time convenient_4',\n       'Departure\/Arrival time convenient_5', 'Ease of Online booking_0',\n       'Ease of Online booking_1', 'Ease of Online booking_2',\n       'Ease of Online booking_3', 'Ease of Online booking_4',\n       'Ease of Online booking_5', 'Gate location_0', 'Gate location_1',\n       'Gate location_2', 'Gate location_3', 'Gate location_4',\n       'Gate location_5', 'Food and drink_0', 'Food and drink_1',\n       'Food and drink_2', 'Food and drink_3', 'Food and drink_4',\n       'Food and drink_5', 'Online boarding_0', 'Online boarding_1',\n       'Online boarding_2', 'Online boarding_3', 'Online boarding_4',\n       'Online boarding_5', 'Seat comfort_0', 'Seat comfort_1',\n       'Seat comfort_2', 'Seat comfort_3', 'Seat comfort_4', 'Seat comfort_5',\n       'Inflight entertainment_0', 'Inflight entertainment_1',\n       'Inflight entertainment_2', 'Inflight entertainment_3',\n       'Inflight entertainment_4', 'Inflight entertainment_5',\n       'On-board service_0', 'On-board service_1', 'On-board service_2',\n       'On-board service_3', 'On-board service_4', 'On-board service_5',\n       'Leg room service_0', 'Leg room service_1', 'Leg room service_2',\n       'Leg room service_3', 'Leg room service_4', 'Leg room service_5',\n       'Baggage handling_1', 'Baggage handling_2', 'Baggage handling_3',\n       'Baggage handling_4', 'Baggage handling_5', 'Checkin service_0',\n       'Checkin service_1', 'Checkin service_2', 'Checkin service_3',\n       'Checkin service_4', 'Checkin service_5', 'Inflight service_0',\n       'Inflight service_1', 'Inflight service_2', 'Inflight service_3',\n       'Inflight service_4', 'Inflight service_5', 'Cleanliness_0',\n       'Cleanliness_1', 'Cleanliness_2', 'Cleanliness_3', 'Cleanliness_4',\n       'Cleanliness_5', 'satisfaction']]","5578860e":"train_one_hot.head()","a6dc2437":"def separate_features_and_label(dataset):\n    \"\"\"\n    Separates features and labels in a dataset.\n    \n    Arguments: \n        A dataset.\n    \n    Returns: \n        Features, labels.\n    \"\"\" \n    features = dataset.drop(\"satisfaction\", axis = 1)\n    labels = dataset[\"satisfaction\"]\n    return (features, labels)","3550becf":"train_features, train_labels = separate_features_and_label(train_one_hot)","8796847d":"train_features.shape, train_labels.shape","6b1733a7":"test_ft, test_lb = separate_features_and_label(test_one_hot)","c92a0d64":"test_ft.shape, test_lb.shape","8e1eab88":"train_ft, val_ft, train_lb, val_lb = train_test_split(train_features, train_labels, \n                                                      test_size = 0.1, stratify = train_labels, random_state = 42)","f07ae6a4":"train_ft.shape, train_lb.shape, val_ft.shape, val_lb.shape","d519251c":"label_encoder.classes_","4cf2a9fc":"train_lb.unique()","1acf9480":"def plot_labels():\n    \"\"\"\n    Plots distribution of classes (labels) in all three sets.\n    \n    Arguments: \n        N\/A.\n    \n    Returns: \n        Plots of classes in train, validation, and test data.\n    \"\"\" \n    fig = plt.figure(figsize = (10, 4))\n    plt.subplot(131)\n    plt.title(\"In train data\")\n    sns.countplot(x = \"satisfaction\", data = pd.DataFrame(train_lb), palette = \"coolwarm\")\n    \n    plt.subplot(132)\n    plt.title(\"In val data\")\n    sns.countplot(x = \"satisfaction\", data = pd.DataFrame(val_lb), palette = \"coolwarm\")\n    \n    plt.subplot(133)\n    plt.title(\"In test data\")\n    sns.countplot(x = \"satisfaction\", data = pd.DataFrame(test_lb), palette = \"coolwarm\")\n    \n    plt.tight_layout()\n    plt.show()","5280d013":"plot_labels()","5e41b149":"scaler = MinMaxScaler()\ndef min_max_scaler(features):\n    \"\"\"\n    Scales features in dataset and makes all values floating point numbers.\n    \n    Arguments: \n        Features.\n    \n    Returns: \n        Dataset with features scaled between 0 and 1.\n    \"\"\" \n    scaled_features = scaler.fit_transform(features)\n    scaled_features = scaled_features.astype(\"float\")\n    \n    return scaled_features","a31846e0":"train_features_scaled = min_max_scaler(train_ft)\nval_features_scaled = min_max_scaler(val_ft)\ntest_features_scaled = min_max_scaler(test_ft)","1dda0284":"train_features_scaled.min(), train_features_scaled.max(), test_features_scaled.min(), test_features_scaled.max()","e14c55cd":"f1 = make_scorer(f1_score, average = \"weighted\")","4b91a506":"params_dt = {\n    \"max_depth\": [2, 4, 6, 8, 10],\n    \"min_samples_leaf\": [1, 2, 3, 4, 5]\n}","6599adee":"decision_tree_grid = GridSearchCV(DecisionTreeClassifier(), param_grid = params_dt, scoring = f1, cv = 5)","d6736fc5":"decision_tree_grid.fit(train_features_scaled, train_lb)","fd3e792f":"decision_tree_grid.best_params_","08306752":"decision_tree = DecisionTreeClassifier(max_depth = 10, min_samples_leaf = 1, random_state = 42)","d0b17409":"def classification_task(estimator, features, labels):\n    \"\"\"\n    Peforms classification by training (\"fit\", \"predict\") and evaluation (\"score\") of a modelling alogirthm.\n    \n    Arguments: \n        Estimator, features (X) and labels (y).\n    \n    Returns: \n        Model's performance measured in terms of accuracy and f1_score.\n    \"\"\"\n    estimator.fit(features, labels)\n    predictions = estimator.predict(features)\n    \n    print(f\"Accuracy: {accuracy_score(labels, predictions)}\")\n    print(f\"F1 score: {f1_score(labels, predictions, average = 'weighted')}\")","5d9fb690":"classification_task(decision_tree, train_features_scaled, train_lb)","3ccbe1f6":"classification_task(decision_tree, val_features_scaled, val_lb)","f75177a6":"print(classification_report(val_lb, decision_tree.predict(val_features_scaled)))","f0ebd459":"def plot_confusion_matrix(estimator, y, x):\n    \"\"\"\n    Plots confusion matrix of Actual and Predicted samples.\n    \n    Arguments: \n        Estimator, labels (y), and features (X).\n    \n    Returns: \n        Confusion matrix.\n    \"\"\"\n    plt.figure(figsize = (4, 3))\n    sns.heatmap(confusion_matrix(y, estimator.predict(x)),\n           annot = True,\n           fmt = \".0f\",\n           cmap = \"Blues\",\n           linewidths = 2,\n           linecolor = \"red\",\n           xticklabels = estimator.classes_,\n           yticklabels = estimator.classes_)\n    plt.title(\"Actual values\")\n    plt.ylabel(\"Predicted values\")\n    plt.tight_layout()\n    plt.show()","05396d66":"plot_confusion_matrix(decision_tree, val_lb, val_features_scaled)","5a9bf58e":"np.round(decision_tree.feature_importances_, 3) # 11 - 0.303, 19 - 0.146, 47 - 0.071","137b8245":"params_rf = {\n    \"n_estimators\": [10, 15, 20, 25],\n    \"max_depth\": [2, 4, 6, 8, 10],\n    \"min_samples_leaf\": [1, 2, 3, 4, 5]\n}","d6653594":"random_forest_grid = GridSearchCV(RandomForestClassifier(random_state = 42), param_grid = params_rf, cv = 5, scoring = f1)","b8b7d098":"random_forest_grid.fit(train_features_scaled, train_lb)","ccb6418c":"random_forest_grid.best_params_","87f82e9b":"random_forest = RandomForestClassifier(n_estimators = 20, max_depth = 10, min_samples_leaf = 2, random_state = 42)","76c0dfb1":"classification_task(random_forest, train_features_scaled, train_lb)","9114bee2":"classification_task(random_forest, val_features_scaled, val_lb)","37650f7c":"print(classification_report(val_lb, random_forest.predict(val_features_scaled)))","b776a0c8":"plot_confusion_matrix(random_forest, val_lb, val_features_scaled)","a909c08b":"np.round(random_forest.feature_importances_, 3) # 10 - 0.119, 19 - 0.062,  49 - 0.082","90dcffd4":"params_xgboost = {\n    \"n_estimators\": [5, 10, 5, 20, 25],\n    \"max_depth\": [2, 4, 6, 8, 10],\n    \"learning_rate\": [0.2, 0.4, 0.6, 0.8, 1]}","456c6479":"xgboost_grid = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric = 'logloss', random_state = 42), \n                            param_grid = params_xgboost, cv = 5, scoring = f1)","0359bcfa":"xgboost_grid.fit(train_features_scaled, train_lb)","fe379b49":"xgboost_grid.best_params_","25cbcc41":"xgboost = XGBClassifier(n_estimators = 25, max_depth = 8, learning_rate = 0.4, eval_metric = 'logloss', use_label_encoder=False, random_state = 42)","852213be":"classification_task(xgboost, train_features_scaled, train_lb)","1885629c":"classification_task(xgboost, val_features_scaled, val_lb)","5b9dfea5":"classification_task(xgboost, test_features_scaled, test_lb)","f22f0154":"print(classification_report(test_lb, xgboost.predict(test_features_scaled)))","2e630b35":"plot_confusion_matrix(xgboost, test_lb, test_features_scaled)","5128bdf4":"Both train and test data were loaded and stored in `train_data` and `test_data`, respectively.","6cf429db":"Despite being numeric features, it is important to check the unique units therein. The function below helps for computing them.","81c96623":"`Id` column most likely holds information about passengers' unique ID number in the Airline's database. A brief check confirms that there are 103904 unique entries in the training data, and 25976 - in the testing one. These figures are equal to the unique samples in each dataset.","5ef4bf18":"A brief check shows that features in training data expanded to 97, but those in the testing set - to 94. This discrepancy should be addressed. Otherwise, the model will return an error since the algorithm will be trained on 97 features, and tested on less.","7867f01c":"Misclassified samples in absolute terms (in a twice as large dataset) are less than those offered by Random Forest. Thus, it could be concluded that XGBoost was the algorithm that best modelled the relationship between features and labels.","b24a843a":"##### Gate location\nPassengers in train and test data share the same views in terms of convenience of airline's gate location.","fe2c5bfd":"##### Leg room service\nIt seems most people (both in train and test set) are happy with the offered leg room service.","61e9040b":"## III. Data Pre-porcessing\nSo far, both datasets were examined and cleaned. At this stage, both sets are pre-processed, i.e., prepared for modelling.\n\n### III.1. Encode labels\nTo encode lables means replacing string values in label (target) column (the one which should be predicted) with numeric ones. In this case, \"neurtral...\" and \"satisfied\" will be replaced with \"0\" and \"1\". Encoding in both sets is performed with `LabelEncoder()`.","bb35adc8":"##### Inflight wifi service\nMost passengers in both datasets were somewhat happy with wifi services during the flight. ","0d62d620":"The plots below confirm the labels in all three sets have similar distribution.","4143bded":"### II.1. Set index column","dec37711":"## I. Load data","bfc060fc":"The checks above confirm missing values in `Arrival Delay in Minutes` in both sets. The code lines below display the rows with no entries in this feature.","37ffb2e8":"##### Checkin service\nSimilarly, equal share of passengers in train and test data categorize airline's checkin service.","07567149":"\"Accuracy\" and \"f1 score\" on the testing set is around 98% - slighly less than on validation data but more than Decision Tree and Random Forest's results. Unfortunately, \"recall\" on class 1 is not as good as the one reached for class 0. Nonetheless, success metrics of 98% indicate for a really good classifier.","63924971":"`Id` column was removed by applying the function below over both sets.","993a54f1":"Train dataset has 25 features and more than 100000 samples.","8db07fcc":"##### Departure and Arrival time\nMost passengers (both in train and test data) consider departure and arrival times convenient for them.","8907b6a7":"##### Type of travel\nTwice as many passengers travelled on a business trip; the remaining used the airline services for personal reasons.","43f3882d":"Similar distribution is observed in the \"Flight Distance\" values, both in train and test data. It is skewed on the right, which suggests the mean and the median values are possitioned in the right side of the historgram.\n\nAnother function plots departure and arrival delays. Unique observations are many more than those in the previous features, which makes the function above somewhat inconvenient.","a3e9cbb7":"### III.2. Encode features\nSimilarly, categorical features should be encoded, too. `panda`'s `get_dummies` is the most appropriate function in this case. However, if it gets the whole dataset, only \"string\" containing features will be encoded; those with numeric values will remain as they are. Thus, the modelling algorithm will work but might regard them as distances between points which would be wrong. For this reason, all categorical features (in both datasets) - with strings and with numeric values, are passed through `get_dummies`.","dd7604a0":"### Imports","cb70567b":"##### Custormer type\nLoyal customers are three to four times more than the disloyal ones, in both datasets.","8926fcc1":"To reacall, a check above showed that there are missing values in one of the features. These are addressed here, before data is being passed through for plotting.","7634fb67":"310 rows in training data and 83 rows in testing data have `NaNs` in Arraval Delays. Missing values could be handled in several ways, e.g., by removing the rows without data, or by imputing the missing values. The second option is possible and prefered in this case. Missing entries could be replaced with \"0\", or with a mean value, or with neibouring numbers, etc. In this example, it could be assumed that the planes didn't delayed on landing and thus passengers left this field empty. For this reason, it is assumed that arriaval delay for these samples was equal to 0. Therefore, the code lines below replace missing values with zero.","cb0c9f41":"### III.6. Scale features\nLastly, values in all features are scaled, i.e., placed within one and the same range. Scaling avoids misinterpretation of data, e.g., considering larger values in one column for more important than smaller ones in another column. Data were scaled with `MinMaxScaler()`, which makes all values in a feature between 0 and 1.","05b0e237":"### III.4. Train - validation split\nOriginal data provide for a test set. It is a good practice to train and evaluate a model on a validation set. There are sufficient samples in training data, which allows allocating a small validation set. The code line below splits the training set into train and validation data. Their shape - both of features and labels, was checked thereafter.","a0fe2679":"The function below displays distribution in both sets, per feature.","65d8d00b":"## IV. Model Selection\n\nThe task here is to predict if a passenger was satisfied or not with airline's services. To that end, the authors of the dataset has provided a training data with all features and true responses. A few steps earlier, the latter were removed \/ separated from predicting variables. Now, the training and validation data are \"shown\" to several algorithms; the one that learns \"features-label\" relationship best and is capable to predict outcome (satisfaction) with minor errors, was selected as the best performing one.\n\n### IV.1. Decision Tree\nDecision Trees (DTs) are a non-parametric supervised learning method used for [classification](https:\/\/scikit-learn.org\/stable\/modules\/tree.html) and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. Decision Trees has several hyper-parameters but the ones used in this example are \"max_depth\" (i.e., the maximum number of nodes) and \"min_samples_leaf\" (i.e., the minimum number of samples required to be at a leaf node). \n\n`GridSearchCV()` is used for selecting the combination of hyper-parameters that returns the highest value of \"f1_score\" (a classification metric, harmonic mean of \"precision\" ($\\frac{TP}{TP + FP}$) and \"recall\" ($\\frac{TP}{TP + FN}$) ). It is instantiated and placed as a scoring parameter. ","def23e2a":"This Notebook explores the Kaggle's [Airline Passenger Satisfaction](https:\/\/www.kaggle.com\/teejmahal20\/airline-passenger-satisfaction) dataset. Passengers' survey responses help for revealing the factors, which are highly correlated to a satisfied (or dissatisfied) passenger, and for predicting his or her attitude towards the air journey.\n\nData come into two sets - training and testing one. They were explored and cleansed simultaneously. Insights were drawn by examining counts, plots, distributions, and relationships between variables. Three machine learning algorithms were tried and tested (Decision Tree, Random Forest, and XGBoost) before choosing the one that best predicts a passenger's satisfaction with airline services.","8b98eedf":"### III.5. Label distribution\nEach class (label) should be equally represented in train, validation, and test data for avoiding imbalance and model under- or overfitting. To that end, before to proceed further, label distribution in all sets was checked.\n\nTo recall, there are two classes (labels): \"neutral or dissatisfied\" denoted with [0] and \"satisfied\" denoted with [1]. ","a6da48d5":"This subsection explores value counts and distributions in all features. The function below counts items in categorical variables both in train and test data.","d40a2b73":"A brief check of train and test data confirms the values were properly scaled.","42d88f5d":"##### Class\nAlmost an equal share of passengers used Eco or Business class, in both datasets. A tiny number of people preferred Eco Plus. ","c2379c86":"Both checks confirm that there are not missing values (in both sets) anymore.","3c224071":"Another pre-processing step is to separate features and labels. The function below does exactly this.","7feb4a39":"##### Food and drink\nEqual share of passengers (both in train and test data) like and dislike food and drinks onboard.","b49834bc":"### IV.2. Random Forest\n[Random Forest](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html) is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Similrly, it has several tunable hyper-parameters. The ones that are tried and tested with Grid Search here are the number of estimators (i.e., decision trees), maximum depth (i.e., the number of nodes per tree), and minimus samples per leaf. \n\nSearching for the best combination of hyper-parameters was peformed with cross-validation over 5 folds.","a2aa9dcc":"Features in test data are now ordered in the same way.","9f030883":"### II.2. Remove `id` column","460ce8e7":"However, it does not perform better than Decision Tree. The model didn't overfit training data but still, there are 5 percentage points until reaching full accuracy and f1 score. It could also be assumed the irreducible error - the error intrinsic to data due to variance in its features, is 5%. Thus, reaching accuracy, precision, or recall above 95% would be hardly possible. \n\nSimilarly, Random Forest demonstrates higher recall rates for class \"0\" and much lower - for class 1.","01aac90d":"A brief check confirms the three columns were added to the testing data.","3c692e7d":"It would be interesting to see how many samples for each class were wrongly or properly predicted. The function below plots confision matrix - a simple table showing Actual (on horizontal line) and Predicted (on vertical line) values.","15f318d6":"It found that the best performing combination has 10 nodes in depth, each holding at least 1 sample per leaf.","f719ecee":"The code line below shows that the testing data does not have columns for null values in \"Checking_service\", \"Gate location\", and \"Seat comfort\". Perhaps, neither passenger in the testing data was completely dissatisfied with each of these services. To remedy this problem, we add the three columns in the testing data with values \"0\" for all samples. Thus, the algorithm will take into account that neither passenger reported dissatisfaction in terms of checkin, gate location, and seat comfort, but will see the same number of features as those in the training set.","2f0a22e5":"Most columns in both datasets contain numeric values (\"int64\" or \"float64\"). It seems as there are not missing values in both tables save in `Arrival Delay in Minutes`. These are handled later.","16ccf2c5":"So far, both datasets are one-hot-encoded (values for each category are displayed in a separate feature), and labels - encoded.","67f908d4":"The plot above does not reveal any discrepancies in train and test-group passengers in terms of their views regarding airplance's cleanliness.","8eb0f0b4":"##### Satisfaction\nNeutral or dissatisfied passengers prevail in both dataset. Imbalance is not observed, however - both train and test data contain similar share of each class.","3dccd547":"However, features in train and test set should appear in the same order. For this reason, the code lines below reorder columns in both sets. First, all columns in train data are listed.","989b389d":"##### Inflight service\nSatisfaction with inflight service is similar in train and test data.","8132f767":"Applying `feature_importances_` over the trained model shows the weight each column (feature) has. For example, the 11-th feature (\"Business class\") has the highest importance for determining a passenger's satisfaction.","0a31afe3":"##### Cleanliness\nMost passengers, both in training and in testing data, think onboard cleanliness is good enough.","91d525b4":"Distribution of passengers's age in both train and test data is similar. It seems the distribution is bimodal - one mode is formed around the age of 25-30, and the other - around 40.","63507405":"There are not outliers in \"Age\" column. Most passengers were aged between 27 and 51 (see the table below). The youngest one was 7, and the oldest - 85. The averged travelled distance was 1189.45 km. Most people declared a voyage between 414 and 1743 km. There are extreeme values, e.g., those above 3900 km. These are displayed as dots on the second boxplot. On the other hand, a large amount of data in \"Departure delay\" and \"Arrival delay\" seem to be outliers. Average delay was around 15 minutes but there are people who stated that their plane arrived or departed on the next day (i.e., delay of more than 24 hours). \n\nFor the time being, outliers are kept in the dataset.","d4a4fe02":"More women than men in both sets were not so happy with the journey. On the other hand, there is not a difference in terms of gender among those who declared satisfaction with the airline's services.","eebf61ea":"##### Gender\nShare of male and female passengers in both datasets is similar, i.e., in terms of Gender, this dataset is not imbalanced.","1dc7196c":"# Predict Airline Passenger Satisfaction","dd828c11":"##### On-board service\nThere are not differences between train and test data in terms of share of people liked or disliked on-boarding service.","3d87938f":"### IV.3. XGBoost\nFinally, an attempt was made to obtain better results with [XGBoost](https:\/\/xgboost.readthedocs.io\/en\/latest\/). It provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. In addition to number of estimators and their depth, an important hyper-parameter of XGBoost is its learning rate - smaller rate helps for better convergence and most likely - for better performance.","d45349db":"#### Distributions in numeric variables","e5b8f80d":"The plots above show counts in categorical features with \"string\" values, denoted as \"object\" in the checks above. Most columns, however, regardless of their numeric values, should also be considered \"categorical\". Features' values help for making distinction between \"categorical\" and \"non-categorical\" ones - those with discrete values are considered \"categorical\", and items in each category are counted with the function used so far. The code lines below print unique counts per category in each column.","6945f796":"Brief checks show that \"Unnamed: 0\" was successfully set as index column.","f873a648":"The confusion matrix shows that more samples of class 0 were properly predicted, whereas those of class 1 - not.","c1a59210":"##### Baggage handling\nMost people in train and test data like the way the airline handles passengers' luggage.","98a7945a":"Grid Search gets `DecisionTreeClassifier()` as an estimator and looks for the best combination of parameters by cross validating data on 5 folds.","8ba534dd":"Most passengers (in both sets) reported departure delay up to or around 200 minutes (circa 3 hours). On a tiny number of occasions, departure have been postponed for a longer period of time.","7a15dbee":"XGBoost justified its reputation as one of the strongest classification algorithm. It reaches more than 97% \"accuracy\" and \"f1 score\" on training data, and as high as 99% on validation samples. For this reason, **XGBoost** is selected as the one that best learned the relationship between predicting variables (features) and labels. Hence, its performance is evaluated on the **test** data as well.","57feed0b":"### II.3. Check for missing values and data types","bad041ce":"The function below helps for displaying how \"satisfaction\" interacts with other features. ","941a1d1a":"Random Forest found that features No. 11, 19, and 49 mostly impacted passengers' air experience. These hold feedback by people travelled for personal reasons (\"Type of Travel_Personal Travel\"), are happy with Internet connection onboard (\"Inflight wifi service_5\"), and with online boarding (\"Online boarding_5\").","b0a92478":"##### Ease of Online booking\nMore people - both in train and test data - admitted that online booking was not so easy for them.","622bee66":"Now, train data are passed through for grid search.","1a401976":"\"Accuracy\" and \"f1_score\" on training data are slightly less than 95% -  quite a good performance. The model reaches 96% on validation data. Thus, it could not be said that it overfits training samples. Slightly higer scores suggest that validation data might be easier for prediction than those the model has already seen.\n\nA classification report (displayed for validation data) shows how the model peforms on both classes in terms of precision, sensitivity (recall), and f1. Better results were obtained for class \"0\" - the one having more samples.","e8cbd413":"## II. Exploratory Data Analysis and Data Cleansing","c0116334":"Outliers in a dataset are those values which are extremely low or extremely high. Outliers might show errors in data (e.g., age 150, or travelled distance -20) or simply an example with rare characteristics. Outliers could be estimated with RANSAC - a `scikit learn` algorithm, or visualized on a boxplot. The latter is more simple and easier for interpretation approach. Thus, the code line below takes numeric features out of the training data and stores it in a variable. Thereafter, numeric features are displayed on boxplots.","d6abb7b0":"Similarly, people in both sets shared similar views in terms of inflight entertainment.","0d111d7f":"Label column (\"satisfaction\") in train data is moved to the end.","4ac74fcb":"Grid Search was performed in a similar manner - interim results are cross-validated on 5 folds; trees could be up to 10 nodes deep, the algorithm could compute accuracy and other success metrics with up to 25 trees, and the learning rate might range between 0.2 and 1.","99c4b8ea":"Similar delay was reported for arrival times - up to around 250 minutes, save some exceptions.  ","3cf1bde3":"Using the maximum number of estimators is expected to return the best result. However, trees should be 8 nodes deep instead of 10, and the learning rate -  reduced to 0.4.","9c81bff0":"The first column `Unnamed: 0` replicates `index` and should either be removed or set as an index one.\n\n`Gender` holds information about passengers gender (Female or Male).\n\n`Custormer Type` indicates if a passenge is a Loyal customer or disloyal one.\n\n`Age` shows information about passengers' actual age.\n\n`Type of Travel` describes the travel purpose - either Personal Travel, or Business Travel.\n\n`Class` shows the travel class in the plane: Business, Eco, or Eco Plus.\n\n`Fight distance` shows information about journey's distance.\n\n`Inflight wifi service` indicates satisfaction level of inflight wifi connection (graded between 1 and 5; 0 stands for Not Applicable).\n\n`Departure\/Arrival time convenient` holds information as if departure and arrival times are convenient for passengers.\n\n`Ease of Online booking` - if online booking is easy enough.\n\n`Gate location`: Satisfaction level of Gate location\n\n`Food and drink`: Satisfaction level of Food and drink\n\n`Online boarding`: Satisfaction level of online boarding\n\n`Seat comfort`: Satisfaction level of Seat comfort\n\n`Inflight entertainment`: Satisfaction level of inflight entertainment\n\n`On-board service`: Satisfaction level of On-board service\n\n`Leg room service`: Satisfaction level of Leg room service\n\n`Baggage handling`: Satisfaction level of baggage handling\n\n`Check-in service`: Satisfaction level of Check-in service\n\n`Inflight service`: Satisfaction level of inflight service\n\n`Cleanliness`: Satisfaction level of Cleanliness\n\n`Departure Delay in Minutes` shows delaying on departure\n\n`Arrival Delay in Minutes` shows delaying on arrival\n\n`Satisfaction` is the label column and holds information as to if a passenger is satisfied by the airline, or his\/her attitude is neutral or dissatisfied.","1cbb1f42":"##### Online boarding\nThere are not discrepancies between both sets in terms of passengers' attitude towards online boarding.","2cc1aa18":"Grid Search suggests to get the maximum of Random Forest - 20 estimators, 10 nodes deep and 2 sample per leaf.","88b29514":"##### Seat comfort\nMost passengers (equal shares in both sets) find airplane seats sufficiently comfortable.","7fa49751":"Test data has identical features and slightly less than 26 000 entries.","f65728ee":"### III.3. Separate features and labels","2464de32":"### II.5. Explore and deal with outliers","b747688e":"These values are hard-coded as estimators' hyper-parameters. All tasks (functions) related to training and evaluating model's performance are wrapped in a function (see below), which is applied over training and validation data.","97d4afa5":"### II.4. Explore counts and distributions","ca812d2c":"A brief check confirms the `id` column is no longer in the datasets.","9f5e7656":"A brief check shows that features and labels in both sets were properly separated.","0370dc8a":"A brief check confirms the labels were encoded successfully.","0bb6fda6":"There is \"Unnamed: 0\" column with indices, which was set for index one."}}