{"cell_type":{"36e6816d":"code","99e8d8dc":"code","cbd1c859":"code","67402512":"code","585d3d5e":"code","9f9d2938":"code","1b8ad9e5":"code","5f0e5f2f":"code","9bb483ed":"code","ada797b2":"code","6115fb80":"code","4faaf03e":"code","85218377":"markdown","c30918d9":"markdown","d9585f22":"markdown","04ac20bd":"markdown","c8884b4e":"markdown","20e82361":"markdown","debe94e7":"markdown","262ca2d0":"markdown","af2aa68a":"markdown"},"source":{"36e6816d":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nlyrics_df = pd.read_csv('..\/input\/arctic-monkeys-lyrics\/lyrics.csv')","99e8d8dc":"import string, re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\n\n\ndef remove_punc(lyrics):\n    return \"\".join([c for c in lyrics if c not in string.punctuation])\n\ndef remove_stopwords(lyrics):\n    return [w for w in lyrics if w not in stopwords.words('english')]\n\nmarkers = ['[', ']','Verse','1','2','3','Chorus','Spoken Intro','Intro','Bridge','PreChorus', 'and','And','Outro']\ndef remove_markers(lyrics):\n    return [w for w in lyrics if w not in markers]\n\nlyrics = []\ntokenizer = RegexpTokenizer(r'\\w+')\n\nlyrics_df['lyrics'] = lyrics_df['lyrics'].apply(lambda x: remove_punc(x))\nlyrics_df['lyrics'] = lyrics_df['lyrics'].apply(lambda x: tokenizer.tokenize(x))\nlyrics_df['lyrics'] = lyrics_df['lyrics'].apply(lambda x: remove_markers(x))\nlyrics_df['lyrics'] = lyrics_df['lyrics'].apply(lambda x: remove_stopwords(x))\nlyrics_df['lyrics'].head(20)","cbd1c859":"lyrics_df['lyrics'] = lyrics_df['lyrics'].apply(lambda x: ' '.join(x))","67402512":"import spacy\nfrom collections import Counter\n\ndef most_freq_words(df, number):\n    sp = spacy.load('en_core_web_sm')\n    complete_doc = sp(' '.join([i for i in df['lyrics']]))\n    words = [token.text for token in complete_doc\n             if not token.is_stop and not token.is_punct]\n    word_freq = Counter(words)\n    common_words = word_freq.most_common(number)\n    print (common_words)","585d3d5e":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud, STOPWORDS\n\ndef word_cloud(df):\n    v = TfidfVectorizer()\n    x = v.fit_transform(df['lyrics'])\n    text = df.lyrics.values\n    wordcloud = WordCloud(\n        width = 3000,\n        height = 2000,\n        background_color = 'white',\n        stopwords = STOPWORDS).generate(str(text))\n    fig = plt.figure(\n        figsize = (40, 30),\n        facecolor = 'k',\n        edgecolor = 'k')\n    plt.imshow(wordcloud, interpolation = 'bilinear')\n    plt.axis('off')\n    plt.tight_layout(pad=0)\n    plt.show()","9f9d2938":"most_freq_words(lyrics_df, 20)\nword_cloud(lyrics_df)","1b8ad9e5":"sias_df = lyrics_df[lyrics_df['album'] == 'Suck It and See']\nmost_freq_words(sias_df, 20)\nword_cloud(sias_df)","5f0e5f2f":"tranqulity_df = lyrics_df[lyrics_df['album'] == 'Tranquility Base Hotel & Casino']\nmost_freq_words(tranqulity_df, 20)\nword_cloud(tranqulity_df)","9bb483ed":"from sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef print_top_words(model, feature_names, n_top_words):\n    topics=[]\n    for topic_idx, topic in enumerate(model.components_):\n        topics.append([feature_names[i]\n        for i in topic.argsort()[:-n_top_words - 1:-1]])    \n    for t in topics:\n        print(t)\n\ndef lda(tags):\n    number_topics = 10\n    no_top_words = 5\n    no_features = 5000\n\n    ct_vectorizer = CountVectorizer(max_features=no_features)\n    tags_ct = ct_vectorizer.fit_transform(tags)\n\n    lda = LatentDirichletAllocation(n_components=number_topics, n_jobs=-1)\n    lda.fit(tags_ct)\n    \n    ct_features_names = ct_vectorizer.get_feature_names()\n    print_top_words(lda, ct_features_names, no_top_words)\n    ","ada797b2":"lda(lyrics_df['lyrics'])","6115fb80":"lda(sias_df['lyrics'])","4faaf03e":"lda(tranqulity_df['lyrics'])","85218377":"Cleaning the text, removing some words that will get in the way of the analysis.","c30918d9":"## Analyzing the monkeys' songs.\nFirst, import a csv containing all of the lyrics","d9585f22":"And we'll generate a wordcloud","04ac20bd":"Using spacy, we'll see the most frequent words in the lyrics.","c8884b4e":"Now, only the 'TBH&C' album.","20e82361":"Using all discography, we get the following:","debe94e7":"Now, only the 'Suck it and see' album.","262ca2d0":"Running it on the whole discography, in the suck it and see and in the tbh&c album","af2aa68a":"What topics are more frequent in the lyrics? For what we'll use Latent Dirichlet Allocation"}}