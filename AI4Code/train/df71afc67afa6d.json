{"cell_type":{"bd8f9d4a":"code","7a7cae48":"code","e38ec0e0":"code","39b388cc":"code","b6c923f3":"code","83f41002":"code","c491bf80":"code","77c94594":"code","5bdcec14":"code","a83922bf":"code","5e68e28a":"code","4a0463b8":"code","6cb12c6b":"code","65cc2561":"code","1a8011b9":"code","fd4cb076":"code","284b14cf":"markdown","61cb7bbc":"markdown","4794e778":"markdown","5348fc99":"markdown"},"source":{"bd8f9d4a":"from pathlib import Path\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Disable Tensorflow debugging information\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport tensorflow as tf","7a7cae48":"# Data train path\ntrain_df_dir = Path(r'..\/input\/cat-and-dog\/training_set\/training_set')\n\n# Get image paths and labels\nimg_dir = list(train_df_dir.glob(r'**\/*.jpg'))\nlabel = list(map(lambda x : os.path.split(os.path.split(x)[0])[1], img_dir))\n\n# Create the paths data\ntrain_df = pd.DataFrame({'img_dir':img_dir, 'label':label}).astype('str')\ntrain_df","e38ec0e0":"# Data test path\ntrain_df_dir = Path(r'..\/input\/cat-and-dog\/test_set\/test_set')\n\n# Get image paths and labels\nimg_dir = list(train_df_dir.glob(r'**\/*.jpg'))\nlabel = list(map(lambda x : os.path.split(os.path.split(x)[0])[1], img_dir))\n\n# Create the paths data\ntest_df = pd.DataFrame({'img_dir':img_dir, 'label':label}).astype('str')\ntest_df","39b388cc":"# Shuffle the data and reset index\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\ntest_df = test_df.sample(frac=1).reset_index(drop=True)\n\ntrain_df","b6c923f3":"# Image sizes\nimage_sizes = train_df['img_dir'].apply(lambda x : plt.imread(x).shape)\nprint(image_sizes.value_counts())","83f41002":"# Count the images for each class\nfor Class in train_df['label'].unique():\n    n = train_df.loc[train_df['label'] == Class, 'label'].count()\n    print(f'{Class} --> {n} image')","c491bf80":"# Show some samples from training data\nplt.figure(figsize=(20, 20))\n\nn_img = (5, 5) # The number of pictures in each row and the number of pictures in each column\nfor i in range(1, (n_img[0] * n_img[1]) +1):\n    plt.subplot(n_img[0], n_img[1], i)\n    plt.axis('off')\n    plt.title(train_df['label'][i])\n    plt.imshow(plt.imread(train_df['img_dir'][i]))","77c94594":"training_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntesting_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","5bdcec14":"train_images = training_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='img_dir',\n    y_col='label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=45,\n    subset='training'\n)\n\nval_images = training_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='img_dir',\n    y_col='label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=45,\n    subset='validation'\n)\n\ntest_images = testing_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='img_dir',\n    y_col='label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False,\n)","a83922bf":"# Load the pretrained model\npretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","5e68e28a":"# Creta new model from pretrained model\ninputs = pretrained_model.input\n\nDense1 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nDense2 = tf.keras.layers.Dense(128, activation='relu')(Dense1)\noutputs = tf.keras.layers.Dense(2, activation='softmax')(Dense2)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n# compiling the model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","4a0463b8":"ep = 20\nEarlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=ep,\n    callbacks=EarlyStopping\n)","6cb12c6b":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()\n\npd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss\")\nplt.show()","65cc2561":"Loss, Accuracy = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(Loss))\nprint(\"Test Accuracy: {:.2f}%\".format(Accuracy * 100))","1a8011b9":"# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nMap = dict((v,k) for k,v in (train_images.class_indices).items())\npred = pd.Series(pred).map(Map).values\n\n# Classification report\nfrom sklearn.metrics import classification_report\ny_test = list(test_df.label)\nprint(classification_report(y_test, pred))","fd4cb076":"# Display 25 picture of the dataset with their labels\nplt.figure(figsize=(20, 20))\nn_img = (5, 5) # The number of pictures in each row and the number of pictures in each column\n\nfor i in range(1, (n_img[0] * n_img[1])+1):\n    plt.subplot(n_img[0], n_img[1], i)\n    plt.axis('off')\n    \n    # Set green title for correct prediction and red for false prediction\n    color='green'\n    if test_df.label.iloc[i] != pred[i]:\n        color='red'\n        \n    # Show pictures\n    plt.title(f\"True: {test_df.label.iloc[i]}\\nPredicted: {pred[i]}\", color=color)\n    plt.imshow(plt.imread(test_df['img_dir'].iloc[i]))","284b14cf":"# **3. Create the model**","61cb7bbc":"# **4. Traing the model**","4794e778":"# **2. Load images with a generator**","5348fc99":"# **1. Load the dataset**"}}