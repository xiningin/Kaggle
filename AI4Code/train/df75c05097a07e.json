{"cell_type":{"57c8e7d5":"code","fca40160":"code","a7d337dc":"code","9e592521":"code","ec58087e":"code","3005bc4a":"code","e16c91bf":"code","8fc08c46":"code","270c3971":"code","3cef30ee":"code","8afc72eb":"code","8b956921":"code","32be9afd":"code","7066f601":"code","67daab85":"code","7d647b3a":"code","9df7d762":"code","276e02fd":"markdown","d19c525c":"markdown","2315ff54":"markdown","0314b137":"markdown","f05de3ed":"markdown","903ac42e":"markdown","a78d0b73":"markdown","6b004b30":"markdown","4f93bd4a":"markdown","30a79cfa":"markdown","9ec8b51d":"markdown","a551e516":"markdown","9d701858":"markdown","9023937c":"markdown","094f51a8":"markdown","6c8963e6":"markdown","c4124a14":"markdown","039fa31f":"markdown","338a251f":"markdown","2d422fd3":"markdown","090b4547":"markdown","d940b42e":"markdown"},"source":{"57c8e7d5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport zipfile\nimport os\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n%matplotlib inline","fca40160":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a7d337dc":"# path to zipped & working directories\npath_zip = '\/kaggle\/input\/denoising-dirty-documents\/'\npath = '\/kaggle\/working\/'","9e592521":"# unzip files first to working directory\n# We could use also unzipped data source, but why not to learn something new?\nwith zipfile.ZipFile(path_zip + 'train.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)\n\nwith zipfile.ZipFile(path_zip + 'test.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'train_cleaned.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'sampleSubmission.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  ","ec58087e":"# store image names in list for later use\ntrain_img = sorted(os.listdir(path + '\/train'))\ntrain_cleaned_img = sorted(os.listdir(path + '\/train_cleaned'))\ntest_img = sorted(os.listdir(path + '\/test'))","3005bc4a":"# prepare function\ndef process_image(path):\n    img = cv2.imread(path)\n    img = np.asarray(img, dtype=\"float32\")\n    img = cv2.resize(img, (540, 420))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = img\/255.0\n    img = np.reshape(img, (420, 540, 1))\n    \n    return img","e16c91bf":"# preprocess images\ntrain = []\ntrain_cleaned = []\ntest = []\n\nfor f in sorted(os.listdir(path + 'train\/')):\n    train.append(process_image(path + 'train\/' + f))\n\nfor f in sorted(os.listdir(path + 'train_cleaned\/')):\n    train_cleaned.append(process_image(path + 'train_cleaned\/' + f))\n   \nfor f in sorted(os.listdir(path + 'test\/')):\n    test.append(process_image(path + 'test\/' + f))","8fc08c46":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train[i][:,:,0], cmap='gray')\n    plt.title('Noise image: {}'.format(train_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train_cleaned[i][:,:,0], cmap='gray')\n    plt.title('Denoised image: {}'.format(train_img[i]))\n\nplt.show()","270c3971":"# convert list to numpy array\nX_train = np.asarray(train)\nY_train = np.asarray(train_cleaned)\nX_test = np.asarray(test)\n\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15)","3cef30ee":"def model():\n    input_layer = Input(shape=(420, 540, 1))  # we might define (None,None,1) here, but in model summary dims would not be visible\n    \n    # encoding\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    \n    x = Dropout(0.5)(x)\n\n    # decoding\n    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x = UpSampling2D((2, 2))(x)\n\n    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n    model = Model(inputs=[input_layer], outputs=[output_layer])\n    model.compile(optimizer='adam' , loss='mean_squared_error', metrics=['mae'])\n\n    return model\n\n\nmodel = model()\nmodel.summary()","8afc72eb":"callback = EarlyStopping(monitor='loss', patience=30)\nhistory = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=600, batch_size=24, verbose=0, callbacks=[callback])","8b956921":"# Check how loss & mae went down\nepoch_loss = history.history['loss']\nepoch_val_loss = history.history['val_loss']\nepoch_mae = history.history['mae']\nepoch_val_mae = history.history['val_mae']\n\nplt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nplt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')\nplt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Val Loss')\nplt.title('Evolution of loss on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2)\nplt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train MAE')\nplt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Val MAE')\nplt.title('Evolution of MAE on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.show()\n","32be9afd":"# predict\/clean test images\nY_test = model.predict(X_test, batch_size=16)","7066f601":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_test[i][:,:,0], cmap='gray')\n    plt.title('Noisy image: {}'.format(test_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(Y_test[i][:,:,0], cmap='gray')\n    plt.title('Denoised by autoencoder: {}'.format(test_img[i]))\n\nplt.show()","67daab85":"# it will take a while!\nids = []\nvals = []\nfor i, f in enumerate(test_img):\n    file = path + 'test\/' + f\n    imgid = int(f[:-4])\n    img = cv2.imread(file, 0)\n    img_shape = img.shape\n    # print('Processing image: {} \\tinto size: {}'.format(f, img_shape))    # uncomment to see progress\n    preds_reshaped = cv2.resize(Y_test[i], (img_shape[1], img_shape[0]))\n\n    for r in range(img_shape[0]):\n        for c in range(img_shape[1]):\n            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n            vals.append(preds_reshaped[r, c])\n\nsubmission = pd.DataFrame({'id': ids, 'value': vals})\nsubmission.to_csv('submission.csv',index = False)\n\nprint('Results saved to submission.csv!')\n\n# quick check if length of IDs is OK\n# we should get there number 14230080\nprint('Length of IDs: {}'.format(len(ids)))","7d647b3a":"# check first few rows of submission\nmy_submission = pd.read_csv('submission.csv')\nmy_submission.head(5)","9df7d762":"# cleanup working directory\nimport shutil\nshutil.rmtree(path + 'train\/')\nshutil.rmtree(path + 'test\/')\nshutil.rmtree(path + 'train_cleaned\/')","276e02fd":"What kind of data\/files we have there?","d19c525c":"I have really enjoyed this task, hope you did as well!","2315ff54":"# Evaluation\nIn this step we will \"predict\", or better say clean test images and check how well model works.","0314b137":"As we have data zipped, we will have to work in \/kaggle\/working\/ directory to unzip images here.","f05de3ed":"# Exploratory data analysis\nNot too much to look there, but just quickly look on train images and their cleaned version. This is what we put into model to learn how to clean noise from background.","903ac42e":"# Data preparation\nNext step is to define function to process images and then store this images in list. As there is not as many data, we do not need to work in batches.","a78d0b73":"# Submission\nIt's time to contest! Let's submit our data.","6b004b30":"Let's store history of model as well, so we can plot loss (rmse) and mae.","4f93bd4a":"## Train model\nVerbose is going to be set to 0 to avoid filling output with hundreds of lines from training. We will run 300 epochs having early stopping set to 20 (if val loss does not drop in 20 epochs, it will stop).","30a79cfa":"# Import libraries and data\nFirst load libraries we need for our work. We need multiple libraries to be able to unzip files, work with directories, sklearn, tensorflow...","9ec8b51d":"# Conclusion\nWe've created autoencoder using tensorflow v2 and keras that can very successfully remove background and noise from documents. Next step could me create algorithm that will be able to extract words out of cleaned sheets ;-)","a551e516":"## If you liked this notebook, please UPVOTE\n## Thanks !","9d701858":"# Remove noisy background from images\/documents using Autoencoders, Tensorflow v2 and Keras","9023937c":"You may notice jump in error after approx. 10 epoch that is pretty important, but enought epochs flatten this to almost 0.","094f51a8":"For later use, we will store image names into list, so we can draw them simply.","6c8963e6":"![](https:\/\/osclasspoint.com\/kaggle\/autoencoder.png)","c4124a14":"I have tested many different models and this one brought me to best results (val_loss < 0.0004). Increasing filters, adding another convolutional layer, batch normalization or drop out did not helped to get better score.","039fa31f":"## Plot error evolution on epochs","338a251f":"Honestly, this way to submit results was really weird for me :-\/","2d422fd3":"Now compare noisy (left) and denoised test images (right). Our model has done great job with denoising!","090b4547":"Reshape images and put them into list.","d940b42e":"# Split data\nIn this step we convert lists to numpy arrays and split dataset into train and validation in ration 85% train, 15% test."}}