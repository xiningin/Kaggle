{"cell_type":{"3ace7bce":"code","de5f2397":"code","d9b0e72c":"code","4e580533":"code","889fc60d":"code","b1516f73":"code","799dcde9":"code","bc377ca9":"code","a82c7cc4":"code","39fe960a":"code","258d3d8c":"code","86dbbdbd":"code","be49b2a5":"code","770facd9":"code","b7a84cc2":"code","e9f8af02":"code","018c8eba":"code","1d1f7686":"code","d561fe1b":"code","0df421b5":"code","96cd9be0":"code","274ecc02":"code","1e412cf1":"code","23d7f822":"code","7ac0e6fe":"code","a4eb759a":"code","15611931":"code","fad9f0d6":"code","20553689":"code","40bad0c2":"code","09605a4b":"code","b7afc753":"code","109984c9":"code","27a77b08":"code","7ac14b00":"markdown","833646ba":"markdown","3accb92d":"markdown","cc414a1b":"markdown","6801afcf":"markdown","b96c7a69":"markdown","ff27fe79":"markdown","b8d54f70":"markdown","73674155":"markdown","df11fbc4":"markdown","7da06dff":"markdown","683b7d70":"markdown","3cb39b6c":"markdown","c4291651":"markdown","34dbbfe1":"markdown","b954cc5b":"markdown","fa41e65f":"markdown","1b50d6e6":"markdown","38d9808b":"markdown"},"source":{"3ace7bce":"import warnings\nwarnings.filterwarnings(\"ignore\")","de5f2397":"!pip install pycaret","d9b0e72c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd  # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pycaret\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e580533":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\nsub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","889fc60d":"train.head()","b1516f73":"train.info()","799dcde9":"def check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)","bc377ca9":"check_df(train)","a82c7cc4":"def cat_summary(dataframe, col_name, plot=False):\n\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()","39fe960a":"cat_summary(train, \"Survived\", plot=True)","258d3d8c":"from pycaret.classification import *","86dbbdbd":"clf1 = setup(data = train, \n             target = 'Survived',\n             numeric_imputation = 'mean',\n             categorical_features = ['Sex','Embarked'], \n             ignore_features = ['Name','Ticket','Cabin'],\n             silent = True\n             )","be49b2a5":"compare_models()","770facd9":"catboost  = create_model('catboost') ","b7a84cc2":"tuned_cat = tune_model(catboost)","e9f8af02":"plot_model(estimator = tuned_cat, plot = 'learning')","018c8eba":"plot_model(estimator = tuned_cat, plot = 'auc')","1d1f7686":"plot_model(estimator = tuned_cat, plot = 'confusion_matrix')","d561fe1b":"plot_model(estimator = tuned_cat, plot = 'feature')","0df421b5":"interpret_model(tuned_cat)","96cd9be0":"clf2 = setup(data = train, \n             target = 'Survived',\n             numeric_imputation = 'mean',\n             categorical_features = ['Sex','Embarked'], \n             ignore_features = ['Name','Ticket','Cabin','SibSp','Parch'],\n             silent = True,\n             remove_outliers=True\n             )","274ecc02":"compare_models()","1e412cf1":"cat2  = create_model('catboost')   ","23d7f822":"tuned_cat2 = tune_model(cat2)","7ac0e6fe":"plot_model(estimator = tuned_cat2, plot = 'learning')","a4eb759a":"plot_model(estimator = tuned_cat2, plot = 'auc')","15611931":"plot_model(estimator = tuned_cat2, plot = 'confusion_matrix')","fad9f0d6":"light  = create_model('lightgbm');\ngbc = create_model('gbc');\nblend = blend_models(estimator_list=[tuned_cat2,light,gbc])","20553689":"tuned_blend = tune_model(blend)","40bad0c2":"plot_model(estimator = blend, plot = 'learning')","09605a4b":"plot_model(estimator = blend, plot = 'auc')","b7afc753":"plot_model(estimator = blend, plot = 'confusion_matrix')","109984c9":"predictions = predict_model(blend, data=test)\npredictions.head()","27a77b08":"sub['Survived'] = round(predictions['Score']).astype(int)\nsub.to_csv('submission.csv',index=False)\nsub.head()","7ac14b00":"Now let's observe which machine learning algorithm will work better with the help of PyCaret. We will examine this problem as part of the classification problem. Therefore, I import PyCaret's classification modules and specify our target column and categorical variables with the setup.","833646ba":"In this part, I conclude that it might be better if we look at the **Feature** graphics above and delete some features. I will remove the SibSp, Parch columns from the model and observe the results again. Additionally, I also change the **remove_outliers** property to True. If there is an outlier, I want it to take action on it as well.","3accb92d":"Looking at the results, it seems that removing the less active features and dealing with outliers did not have a huge impact on our model. We can deduce from these results that we have obtained a usable model in its initial state too.","cc414a1b":"In summary, PyCaret is an easy-to-use library. It helps developers from the beginning of data preparation to model analysis. It has lots of open source algorithms, visualization tools, and preprocessing techniques. In cases where we are undecided about which machine learning algorithm to apply to any data set, we can use the PyCaret library when we want to find the best parameters of the machine learning model we have chosen.\nI hope this post about PyCaret was helpful. Goodbye :)","6801afcf":"Let's see how effective the features that affect this model are on the model. The top-ranked features have more impact on the model.","b96c7a69":"Now I want this model to find **the best parameters** and return a result according to those parameters. I will use the following code snippet for this.","ff27fe79":"There are many settings in the **setup** function. We can use these properties according to the problem. After this process, we can see which model will bring the best results with **compare_model()**. From the results below it clearly appears that the best results come with **catboost**. These results may vary slightly as the code is applied. These differences are normal since we randomly divide the data into pieces and apply algorithms.","b8d54f70":"![indir.png](attachment:c12ec285-7389-42dc-959f-2afa6dea3b18.png)","73674155":"First, I will include the required libraries in the code.","df11fbc4":"The accuracy value increases when the best parameters are set. Now let's observe the values with data visualization tools.","7da06dff":"PyCaret is a Python library that aims to reduce trial and error processes and be more productive of data scientists. It's basically a Python library that surrounds scikit-learn, XGBoost, LightGBM, and many more machine learning libraries and frameworks.\n\nPyCaret includes modules for some Machine Learning tasks given below.\n- Classification\n- Regression\n- Clustering\n- Anomaly Detection\n- Naturel Language Processing\n- Association Rule Mining","683b7d70":"After examining the table, I decided to implement CatBoost Classifier.","3cb39b6c":"Here we will try to predict the Survived column.  In this column, 1 indicates survivors and 0 death ones in Titanic. Let's examine the ratio of these two situations with a graph.","c4291651":"The results in the second graph show that the model's success is satisfying. Let's observe it with the confusion matrix as we understand it.","34dbbfe1":" In addition to all this, PyCaret allows us to apply multiple models to the dataset. I will show this with a short example. We can implement multiple models using the blend_models() function. In this case, the first two or three algorithms that give the best results on the first try are usually chosen. As a result, we see an increase of 1%.","b954cc5b":"Now let's see what the dataset looks like.","fa41e65f":"# **Analysis of Titanic Dataset with PYCARET**\n\n   Today in my notebook, i am going to talk about PYCARET which is an AutoML tool. When applying machine learning models, we usually do data preprocessing, feature extraction, and feature selection. After these steps, we choose the best algorithm and optimize our parameters to achieve the best results. There are many automatic machine learning tools that we call AutoML to reduce this load. Today, I will review PyCaret, one of these tools, and make a classification example with PyCaret.","1b50d6e6":"You can easily download pycaret with the above command.\n> !pip install pycaret","38d9808b":"If you want to see more detail about PyCaret, you can reach it from the link. https:\/\/pycaret.org\/"}}