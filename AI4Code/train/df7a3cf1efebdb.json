{"cell_type":{"1561277d":"code","1b54ec80":"code","57408f1a":"code","3132bdb5":"code","4a0abd4c":"code","f248af62":"code","44d135bc":"code","cacde4fa":"code","8ea8f3d4":"code","33c51a1c":"code","69a48875":"code","4f3eb5cf":"code","c4769b99":"code","3a22f859":"code","06243a8f":"code","2603bb10":"code","595ad34f":"code","3fb82bc1":"markdown","024edd73":"markdown","53bd8f80":"markdown","876aaf40":"markdown","f20256a7":"markdown","9375081f":"markdown","5bcedb00":"markdown","0c7f81c6":"markdown","a0dc8703":"markdown","40d51612":"markdown"},"source":{"1561277d":"! pip install --index-url https:\/\/test.pypi.org\/simple\/ PyARMViz","1b54ec80":"import pandas as pd \nimport numpy as np\nimport networkx as nx \nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport warnings \nimport seaborn as sns \nfrom PyARMViz import PyARMViz\n\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn')\n\ndata = pd.read_csv('..\/input\/the-bread-basket\/bread basket.csv')","57408f1a":"data.head()","3132bdb5":"data.info()","4a0abd4c":"data_vis = data.copy()\ndf_network_first = data_vis.groupby(\"Item\").sum().sort_values(\"Transaction\", ascending=False).reset_index()\ndf_network_first[\"Type\"] = \"Bakery\"\ndf_network_first = df_network_first.truncate(before=-1, after=30) # top 30\nplt.rcParams['figure.figsize']=(15,15)\nj = 0\nfor i, _ in reversed(list(enumerate(df_network_first['Transaction']))):\n    df_network_first['Transaction'][j] = i\n    j+=1\nfirst_choice = nx.from_pandas_edgelist(df_network_first, source='Type', target=\"Item\", edge_attr='Transaction')\nprior = [i['Transaction'] for i in dict(first_choice.edges).values()]\npos = nx.spring_layout(first_choice)\nnx.draw_networkx_nodes(first_choice, pos, node_size=5000, node_color=\"maroon\")\nnx.draw_networkx_edges(first_choice, pos, width=prior, alpha=0.4, edge_color='black')\nnx.draw_networkx_labels(first_choice, pos, font_size=9, font_family='sans-serif', font_color = 'white')\nplt.axis('off')\nplt.grid()\nplt.title('Top 30 Products at The Bread Basket Bakery', fontsize=25)\nplt.show()","f248af62":"from mlxtend.frequent_patterns import association_rules, apriori\n\ndef encoder(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\n\napriori_data = data.groupby(['Transaction','Item'])['Item'].count().reset_index(name ='Count')\napriori_basket = apriori_data.pivot_table(index = 'Transaction', columns = 'Item', values = 'Count', aggfunc = 'sum').fillna(0)\napriori_basket_set = apriori_basket.applymap(encoder)\napriori_basket_set.head()","44d135bc":"f_items = apriori(apriori_basket_set, min_support = 0.05, use_colnames = True)\nf_items","cacde4fa":"apriori_rules = association_rules(f_items, metric = 'lift', min_threshold = 0.05)\napriori_rules.sort_values('confidence', ascending = False, inplace = True)\napriori_rules","8ea8f3d4":"f_items = apriori(apriori_basket_set, min_support = 0.01, use_colnames = True)\nf_items","33c51a1c":"apriori_rules = association_rules(f_items, metric = 'lift', min_threshold = 0.01)\napriori_rules.sort_values('confidence', ascending = False, inplace = True)\napriori_rules","69a48875":"apriori_rules['lhs_items'] = apriori_rules['antecedents'].apply(lambda x:len(x) )\napriori_rules[apriori_rules['lhs_items']>1].sort_values('lift', ascending=False).head()\napriori_rules['antecedents_'] = apriori_rules['antecedents'].apply(lambda a: ','.join(list(a)))\napriori_rules['consequents_'] = apriori_rules['consequents'].apply(lambda a: ','.join(list(a)))\npivot = apriori_rules[apriori_rules['lhs_items']>1].pivot(index = 'antecedents_', columns = 'consequents_', values= 'lift')\nsns.heatmap(pivot, annot = True)\nplt.yticks(rotation=0)\nplt.xticks(rotation=90)\nplt.show()","4f3eb5cf":"from PyARMViz import PyARMViz\nfrom PyARMViz.Rule import generate_rule_from_dict\n\napriori_vis = apriori_rules\n\napriori_vis['uni'] = np.nan\napriori_vis['ant'] = np.nan\napriori_vis['con'] = np.nan\napriori_vis['tot'] = 20507\n\ntransactions = [a[1]['Item'].tolist() for a in list(data.groupby(['Transaction', 'date_time']))]\n\ndef tran():\n    for t in transactions:\n        yield t\ndef antec(x):\n    cnt = 0\n    for t in tran():\n        t = set(t)\n        if x.intersection(t) == x:\n            cnt = cnt + 1\n    return cnt\nvis = apriori_vis.values.tolist()\n\nrules_dict = []\nfor i in vis:\n    i[10] = antec(i[0])\n    i[11] = antec(i[1])\n    i[9] = antec(i[0].union(i[1]))\n    diction = {\n        'lhs': tuple(i[0]), \n        'rhs': tuple(i[1]),\n        'count_full': i[9],\n        'count_lhs': i[10],\n        'count_rhs': i[11],\n        'num_transactions': i[12]\n    }\n    rules_dict.append(diction)","c4769b99":"rules = []\nfor rd in rules_dict:\n    rules.append(generate_rule_from_dict(rd))\n    \nPyARMViz.generate_parallel_category_plot(rules)","3a22f859":"# with 0.001\n\nf_items = apriori(apriori_basket_set, min_support = 0.005, use_colnames = True)\napriori_rules = association_rules(f_items, metric = 'lift', min_threshold = 0.005)\napriori_rules.sort_values('confidence', ascending = False, inplace = True)\n\napriori_vis = apriori_rules\n\napriori_vis['uni'] = np.nan\napriori_vis['ant'] = np.nan\napriori_vis['con'] = np.nan\napriori_vis['tot'] = 20507\n\ntransactions = [a[1]['Item'].tolist() for a in list(data.groupby(['Transaction', 'date_time']))]\n\ndef tran():\n    for t in transactions:\n        yield t\ndef antec(x):\n    cnt = 0\n    for t in tran():\n        t = set(t)\n        if x.intersection(t) == x:\n            cnt = cnt + 1\n    return cnt\nvis = apriori_vis.values.tolist()\n\nrules_dict = []\nfor i in vis:\n    i[10] = antec(i[0])\n    i[11] = antec(i[1])\n    i[9] = antec(i[0].union(i[1]))\n    diction = {\n        'lhs': tuple(i[0]), \n        'rhs': tuple(i[1]),\n        'count_full': i[9],\n        'count_lhs': i[10],\n        'count_rhs': i[11],\n        'num_transactions': i[12]\n    }\n    rules_dict.append(diction)\n    \nrules = []\nfor rd in rules_dict:\n    rules.append(generate_rule_from_dict(rd))","06243a8f":"PyARMViz.generate_parallel_category_plot(rules)","2603bb10":"PyARMViz.generate_rule_graph_plotly(rules)","595ad34f":"PyARMViz.generate_rule_strength_plot(rules)","3fb82bc1":"We would only need Transaction, Item and date time. Let's try and explore which are the top 30 selling products in the bakery using a network diagram.","024edd73":"Its time to model the Apriori algorithm. We should first generate the frequent item set and then generate the association rules using the frequent item set. We need to ensure we generate a matrix with 0\/1 values representating transaction presence of that item.","53bd8f80":"Also the association strength plot which is a scatter plot of support vs confidence with metric as the color dimension.","876aaf40":"Ofcourse this plot is much more useful with larger number of association rules. So let's try using the same analysis this time with 0.5% minimum support threshold","f20256a7":"# Apriori Algorithm Implementation \n\n## Note:\nThis analysis is in conjuction with the medium article I published for Delvify. You can find the link here: \nhttps:\/\/medium.com\/delvify\/a-conceptual-introduction-into-association-rule-mining-part-2-96c73c4ce87b\n\n\n## Data Preprocessing and EDA","9375081f":"Let's first analyze the rules with min_support 5% and then for 1% respectively. Both using the metric lift.","5bcedb00":"## Data Modelling","0c7f81c6":"Now let's take a look at the network graph plot for the rules.","a0dc8703":"Another great visualization library I absolutely love is the PyARMViz library which can work with complex large scale rules. Let's first generate a parallel categories plot","40d51612":"## Data Visualizations for Association Rules\n\nFirst let's take look at a heatmap of the association rules generated for 1% minimum support threshold. "}}