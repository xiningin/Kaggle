{"cell_type":{"e9d1b0a9":"code","f9493d52":"code","7921a69e":"code","234a4f94":"code","00005a44":"code","0d7ec5bc":"code","3cdc6d3f":"code","b4968ce1":"code","fe964589":"code","aedc79c0":"code","0696029e":"code","8df85e82":"code","cbf23356":"code","17bfea53":"code","81f1910a":"code","4a040749":"markdown","d2f99c08":"markdown","a85f664f":"markdown","ca24d261":"markdown","d3327f86":"markdown","524c5829":"markdown","aca9d2a2":"markdown"},"source":{"e9d1b0a9":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nimport torch.optim as optim\nfrom sklearn.utils import shuffle\nfrom PIL import Image\n%matplotlib inline","f9493d52":"# Need to check if cuda is avaiable, to shift tensors and network to GPUs\nif torch.cuda.is_available():\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')","7921a69e":"from glob import glob\nclass BrainMRIDataset(Dataset):\n    \n    def __init__(self,data_dir,reshape=True,height=128,width=128,autoencoder=False):\n        self.dataDirectory = data_dir\n        self.no_class = glob(data_dir+'\/no\/*')\n        self.yes_class = glob(data_dir+'\/yes\/*')\n        self.height = height\n        self.width = width\n        self.reshape=reshape\n        self.autoencoder = autoencoder\n        \n        labels = [0 for i in range(len(self.no_class))]\n        labels += [1 for i in range(len(self.yes_class))]\n        \n        image_links = self.no_class + self.yes_class\n        self.dataframe = pd.DataFrame({\n            'image':image_links,\n            'labels': labels\n        })\n        \n        self.dataframe = shuffle(self.dataframe)\n        self.dataframe.reset_index(inplace=True,drop=True)\n        \n    def __len__(self):\n        return len(self.no_class)+len(self.yes_class)\n    \n    def __getitem__(self,idx):\n        \n        image_list = self.dataframe['image'][idx]\n        label_list = self.dataframe['labels'][idx]\n        \n        if type(image_list) == str:\n            image_list = [image_list]\n\n        if not isinstance(label_list,np.int64):\n            label_list = label_list.values\n\n        image_array = []\n        for image in image_list:\n            image = Image.open(image).convert(\"L\")\n            if self.reshape:\n                image = image.resize((self.height,self.width))\n\n            array = np.asarray(image)\n        \n            if self.autoencoder:\n                array = array.reshape(self.height*self.width)\n            else:\n                array = array.reshape(1,self.height,self.width)\n            \n            image_array.append(array)\n        \n        return [torch.tensor(image_array,device=device),torch.tensor(label_list,device=device)]\n    \n    def __repr__(self):\n        return str(self.dataframe.head())","234a4f94":"dataset = BrainMRIDataset(\"..\/input\/brain-mri-images-for-brain-tumor-detection\")\nprint(dataset)","00005a44":"class BrainTumorModel(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1,256,kernel_size=3),\n            nn.MaxPool2d(2,2),\n            nn.Conv2d(256,32,kernel_size=2)\n        )\n        self.linear1 = nn.Linear(62,128)\n        self.linear2 = nn.Linear(128,64)\n        self.flat = nn.Flatten(1)\n        self.linear3 = nn.Linear(126976,2)\n\n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.linear1(x))\n        x = self.linear2(x)\n        x = self.flat(x)\n        x = self.linear3(x)\n\n        return x","0d7ec5bc":"model = BrainTumorModel()\nmodel.to(device)","3cdc6d3f":"loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())","b4968ce1":"epochs = 200\nbatch_size = 32\nloss_list = []\nfor epoch in range(epochs):\n    total_loss = 0\n    for n in range(len(dataset)\/\/batch_size):\n    \n        data,target = dataset[n*batch_size:(n+1)*batch_size]\n\n        ypred = model.forward(data.float())\n        loss = loss_fn(ypred,target)\n\n        total_loss += loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n  \n    loss_list.append(total_loss\/batch_size)\n    if epoch%10 == 0:\n        print(f'Epochs: {epoch} Loss: {total_loss\/n}')","fe964589":"fig = plt.figure(figsize=(10,10))\nplt.plot(list(range(epochs)),loss_list)\nplt.title(\"Loss v\/s Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()","aedc79c0":"mapping = {0:'no',1:'yes'}\nfig = plt.figure(figsize=(20,20))\nfor i in range(20):\n    data,target = dataset[i]\n    pred = model.forward(data.float())\n    pred = torch.argmax(pred,dim=1)\n    plt.subplot(4,5,i+1)\n    plt.imshow(data[0][0].cpu())\n    plt.title(f'Actual: {mapping[target.cpu().detach().item()]} Predicted: {mapping[pred.cpu().detach().item()]}')\nplt.show()","0696029e":"dataset_autoencoder = BrainMRIDataset(\"..\/input\/brain-mri-images-for-brain-tumor-detection\",autoencoder=True,height=28,width=28)","8df85e82":"class BrainTumorAutoencodes(nn.Module):\n    \n    def __init__(self,dim):\n        \n        super().__init__()\n        self.lin1 = nn.Linear(dim*dim,542)\n        self.lin2 = nn.Linear(542,345)\n        self.lin3 = nn.Linear(345,128)\n        self.lin4 = nn.Linear(128,64)\n        self.lin5 = nn.Linear(64,32)\n        self.lin6 = nn.Linear(32,64)\n        self.lin7 = nn.Linear(64,128)\n        self.lin8 = nn.Linear(128,345)\n        self.lin9 = nn.Linear(345,542)\n        self.lin10 = nn.Linear(542,dim*dim)\n\n    def forward(self,x):\n        x = F.relu(self.lin1(x))\n        x = self.lin2(x)\n        x = F.relu(self.lin3(x))\n        x = F.relu(self.lin4(x))\n        x = self.lin5(x)\n        x = F.relu(self.lin6(x))\n        x = F.relu(self.lin7(x))\n        x = self.lin8(x)\n        x = F.relu(self.lin9(x))\n        x = F.relu(self.lin10(x))\n\n        return x\n        ","cbf23356":"autoencoder = BrainTumorAutoencodes(28)\nautoencoder.to(device)","17bfea53":"loss_fn = nn.MSELoss()\noptimizer = optim.Adam(autoencoder.parameters())","81f1910a":"from IPython.display import clear_output\nepochs = 500\nbatch_size = 32\nloss_list = []\nfor epoch in range(epochs):\n    clear_output(True)\n    total_loss = 0\n    for n in range(len(dataset_autoencoder)\/\/batch_size):\n    \n        data,target = dataset_autoencoder[n*batch_size:(n+1)*batch_size]\n\n        ypred = autoencoder.forward(data.float())\n        loss = loss_fn(ypred,data.float())\n\n        total_loss += loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n  \n    loss_list.append(total_loss\/batch_size)\n    \n    figure = plt.figure(figsize=(20,20))\n    for i in range(20):\n        plt.subplot(4,5,i+1)\n        image = ypred[i].cpu().detach().numpy()# plot the sample\n        image = image.reshape(28,28)\n        fig = plt.figure\n        plt.imshow(image, cmap='gray')\n        plt.title(f'Epochs: {epoch} Loss: {total_loss\/n}')\n    plt.show()","4a040749":"## Results\nUnderlying contains two plots, Loss and Prediction ","d2f99c08":"## Model Training\n\n1. Loss Function: ```torch.nn``` Module having predefined loss functions and you can create your own Loss functions as defined above. Using CrossEntropyLoss for 2 Outputs, for examining the individual probabilities\n\n2. Optimizer: ```torch.nn``` having pre-defined optimizers, with many parameters, using Adam here\n\n3. After defining epochs, need to loop over some steps\n    * Fitting Data with batch of dataset\n    * Compute the Loss\n    * Make Gradient Zero, for previous computations\n    * Compute the backward propogation (Derivate calculation)\n    * Optimizing the weight and biases","a85f664f":"# Brain Tumor Detection\nThis Notebook will go through different libraries, custom dataset generator and Neural Network function along with results\n\n<b><u>Contents<\/u><\/b>\n* Libraries Import\n* Custom Data Generator\n* Custom Network Implementation\n* Model Training\n* Results","ca24d261":"## Custom Data Generator\n\nA lot of effort in solving any machine learning problem goes into preparing the data. PyTorch provides many tools to make data loading easy and hopefully, to make your code more readable. In this tutorial, we will see how to load and preprocess\/augment data from a non trivial dataset.\n\ntorch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n\n```__len__``` so that len(dataset) returns the size of the dataset.<br>\n```__getitem__``` to support the indexing such that dataset[i] can be used to get i<sup>th<\/sup> sample.\n\n**Below Cell Explanation**\n\n```__init__```: In this section, we have created a dataframe, where First column will be having the image path and second column containing labels, along with that shuffled the dataset.<br>\n\n```__len__```: In this section, return the sum of files present in both folder <br>\n```__getitem__```: In this Section, as idx can be single integer or slicing, therefore need to return the images in grayscale (as many of the images are in grayscale and some of them are in RGB Channel, so converted into one), and return the Torch tensor array with labels\n\nLearn More: [Pytorch Data Loading Documentation](https:\/\/pytorch.org\/tutorials\/beginner\/data_loading_tutorial.html)","d3327f86":"## Custom Neural Network Class\n\nThis class will inherit the properties from ```torch.nn.Module``` and should have two functions ```__init__``` for defining neural network and ```forward``` for forward propogation. In General, forward function, will be dealing with output from each layer. We can apply MaxPool, Dropouts and other activation functions.","524c5829":"# Convolutional Neural Network - Classification","aca9d2a2":"# Autoencoder\nIn this section, we will be looking into an Autoencoder Implementation, which will try to understand the underlying distribution of Data, and try to create brain images using Models."}}