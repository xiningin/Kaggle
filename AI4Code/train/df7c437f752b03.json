{"cell_type":{"7a0ee608":"code","cd67292e":"code","e8217884":"code","12cbdf66":"code","4aa9c0b1":"code","7c4a6b2c":"code","882099a6":"code","492beb69":"code","5c72ca56":"code","e3921376":"code","5bba0e20":"code","638c9203":"code","0d5f7b56":"code","85549c4e":"code","f0564172":"code","62fcc3d8":"code","96ea5c2f":"code","2ea88e42":"code","b59f2817":"code","a2495883":"code","c6f95cd6":"code","a18dfd27":"code","2103f1af":"code","217481c3":"code","c116f42d":"code","7534c756":"markdown","35482f3e":"markdown","75855d8d":"markdown","582194c0":"markdown","248d31ec":"markdown","b8a68f42":"markdown","b0cb90b9":"markdown","5a527499":"markdown","f0e9f151":"markdown","09f81172":"markdown","19bb42da":"markdown","c23a8aba":"markdown","89228081":"markdown","f407630e":"markdown","386e6685":"markdown","189fc46c":"markdown","9ae6156d":"markdown","aef6b0d9":"markdown","b00f521a":"markdown","519362a5":"markdown","dff14646":"markdown","ea33f90e":"markdown","74851021":"markdown","bc6aa238":"markdown","d662c005":"markdown"},"source":{"7a0ee608":"import pathlib\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport PIL\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","cd67292e":"# Defining the path for train and test images\ndata_dir_train = pathlib.Path(\"..\/input\/skin-cancer\/Skin cancer ISIC The International Skin Imaging Collaboration\/Train\")\ndata_dir_test = pathlib.Path('..\/input\/skin-cancer\/Skin cancer ISIC The International Skin Imaging Collaboration\/Test')","e8217884":"image_count_train = len(list(data_dir_train.glob('*\/*.jpg')))\nprint(image_count_train)\nimage_count_test = len(list(data_dir_test.glob('*\/*.jpg')))\nprint(image_count_test)","12cbdf66":"batch_size = 32\nimg_height = 180\nimg_width = 180","4aa9c0b1":"## Write your train dataset here\n## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    seed=123,\n    validation_split= 0.2,\n    subset= 'training',\n    image_size=(img_height,img_width),\n    batch_size = batch_size\n)\n","7c4a6b2c":"## Write your validation dataset here\n## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    seed=123,\n    validation_split= 0.2,\n    subset= 'validation',\n    image_size=(img_height,img_width),\n    batch_size = batch_size\n)","882099a6":"# List out all the classes of skin cancer and store them in a list. \n# You can find the class names in the class_names attribute on these datasets. \n# These correspond to the directory names in alphabetical order.\nclass_names = train_ds.class_names\nprint(class_names)","492beb69":"import matplotlib.image as mpimg\nplt.figure(figsize=(10,10))\nfor i in range(9): \n  plt.subplot(3, 3, i + 1)\n  image = mpimg.imread(str(list(data_dir_train.glob(class_names[i]+'\/*.jpg'))[1]))\n  plt.title(class_names[i])\n  plt.imshow(image)","5c72ca56":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","e3921376":"from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nnum_classes = 9\nmodel = Sequential([\n                    layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(img_height, img_width,3))\n])\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (180, 180, 32)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation = \"softmax\"))","5bba0e20":"from tensorflow.keras.optimizers import RMSprop","638c9203":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","0d5f7b56":"# View the summary of all layers\nmodel.summary()","85549c4e":"epochs=30\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","f0564172":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","62fcc3d8":"\ndata_aug = keras.Sequential([\n                             layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\",input_shape=(img_height,img_width,3)),\n                             layers.experimental.preprocessing.RandomRotation(0.2, fill_mode='reflect'),\n                             layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3), fill_mode='reflect')\n])","96ea5c2f":"# visualize how your augmentation strategy works for one instance of training image.\nplt.figure(figsize=(12, 12))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(data_aug(images)[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","2ea88e42":"## You can use Dropout layer if there is an evidence of overfitting in your findings\n\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nnum_classes = 9\nmodel = Sequential([ data_aug,\n                    layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(img_height, img_width,3))\n      \n])\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (180, 180, 32)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation = \"softmax\"))\n","b59f2817":"## Your code goes here\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","a2495883":"## Your code goes here, note: train your model for 100 epochs\nepochs=30\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","c6f95cd6":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","a18dfd27":"path_list=[]\nlesion_list=[]\nfor i in class_names:\n      \n    for j in data_dir_train.glob(i+'\/*.jpg'):\n        path_list.append(str(j))\n        lesion_list.append(i)\ndataframe_dict_original = dict(zip(path_list, lesion_list))\noriginal_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\noriginal_df","2103f1af":"dataframe_dict_original = dict(zip(path_list, lesion_list))\noriginal_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\noriginal_df","217481c3":"count=[]\nfor i in class_names:\n    count.append(len(list(data_dir_train.glob(i+'\/*.jpg'))))\nplt.figure(figsize=(25,10))\nplt.bar(class_names,count)","c116f42d":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","7534c756":"**Problem statement:** To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis.","35482f3e":"### Train the model","75855d8d":"### Create the model\n#### Below is the first base model`we have created:","582194c0":"### Model Creation, compilation and training the model\n","248d31ec":"Use 80% of the images for training, and 20% for validation.","b8a68f42":"### Importing all the important libraries","b0cb90b9":"`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n\n`Dataset.prefetch()` overlaps data preprocessing and model execution while training.","5a527499":"### Create a dataset\n\nDefine some parameters for the loader:","f0e9f151":"### Compiling the model","09f81172":"#### Visualize the model results","19bb42da":"### Visualizing the results","c23a8aba":"### Visualize the data\n#### Below is the code to visualize one instance of all the nine classes present in the dataset","89228081":"### Training the model","f407630e":"### Visualizing training results","386e6685":"### Importing Data","189fc46c":"### Load using keras.preprocessing\n\nLet's load these images off disk using the helpful image_dataset_from_directory utility.","9ae6156d":"#### Findings on the first base model\n\n\n*   Initial findings: The model is overfitting because overfitting is calculated w.r.t loss, and we can also see difference in loss functions in training & test around the 19-20th epoch \n*   The accuracy is just around 50-60% because there are enough features to remember the pattern, and the neural network is very young (just 20 epochs), so the learning has just started\n*   But again, it's too early to comment on the overfitting & underfitting debate\n\n","aef6b0d9":"This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively.","b00f521a":"### Findings\n\n#### - Seborrheic keratosis is having the lowest distribution\n#### - Pigmented Benign keratosis is having the highest distribution of data\n","519362a5":"### As it is a multi class classification, we are using SparseCategoricalCrossEntropy as the loss function, and we are using adam optimizer as a hit & trial, further we can perform hyper parameter optimization and change the optimizer accordingly","dff14646":"The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.","ea33f90e":"### Compile the model\nChoose an appropirate optimiser and loss function for model training ","74851021":"**Submitted by: Satyajit Pattnaik**","bc6aa238":"#### Findings:\n\n\n*   We don't see much improvements with respect to accuracy from the base model, but we can definitely see the overfitting issue fading away due to data augmentation\n*   But again, judging based on just 20 epochs won't give us proper conclusions\n\n","d662c005":"## Finding the distribution of classes in the training dataset.\n"}}