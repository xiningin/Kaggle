{"cell_type":{"e56f6543":"code","46453812":"code","e873a5ea":"code","885082e2":"code","74bd7348":"code","92bec47e":"code","ac7e6db8":"code","25986ab2":"code","280a4680":"code","af29c6e1":"code","da312546":"code","1a055f33":"code","b14ab06a":"code","86256e27":"code","27a44a90":"code","b84f309a":"code","0f2ba324":"code","09b5f549":"code","1205a21b":"code","202ed010":"code","c32d0b04":"code","30940626":"code","a6d55b17":"code","b96a10c8":"code","a291f8dc":"code","c4a918ea":"code","13f0a676":"code","3938c2ba":"code","f2d2f6fb":"code","e36112c7":"code","2af1ab4d":"code","5cc57d7d":"code","8ba462bf":"code","15c40d51":"code","bebec2b0":"code","7a75e64f":"code","0565f4ac":"code","f1c3fd4f":"code","d738f4d8":"code","daaa2f1c":"code","099f53c4":"markdown","72261776":"markdown","f71a078a":"markdown","1a79fb2a":"markdown","fa537a17":"markdown","16ea68b1":"markdown","f0634663":"markdown"},"source":{"e56f6543":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(rc={'figure.figsize': [7, 7]}, font_scale=1.2)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46453812":"dataset_path = '\/kaggle\/input\/dry-beans-classification-iti-ai-pro-intake01\/'\ndf = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\ndftest = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df.shape))\nprint(\"The shape of the dataset is {}.\\n\\n\".format(dftest.shape))\ndf.head()","e873a5ea":"# df = pd.read_csv('train.csv')\n# df","885082e2":"df.info()","74bd7348":"df.describe()","92bec47e":"df['y'].unique()","ac7e6db8":"yData=df['y']","25986ab2":"df = pd.get_dummies(df, columns=['y'])\ndf","280a4680":"df.columns","af29c6e1":"x = df[['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength',\n       'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent',\n       'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2',\n       'ShapeFactor3', 'ShapeFactor4']]\ny = df[['y_BARBUNYA', 'y_BOMBAY', 'y_CALI',\n       'y_DERMASON', 'y_HOROZ', 'y_SEKER', 'y_SIRA']]","da312546":"y ","1a055f33":"x","b14ab06a":"from sklearn.model_selection import train_test_split","86256e27":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.2, random_state=42,stratify =yData)","27a44a90":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nsc.fit(x_train)\nx_train = sc.transform(x_train)\nx_val= sc.transform(x_val)","b84f309a":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","0f2ba324":"x.shape","09b5f549":"x.shape[1]","1205a21b":"y.shape","202ed010":"y.shape[1]","c32d0b04":"model = Sequential()\nmodel.add(Dense(256, input_shape=[x.shape[1]], activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(y.shape[1], activation='softmax'))","30940626":"model.summary()","a6d55b17":"model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])","b96a10c8":"lrd = ReduceLROnPlateau(monitor = 'val_loss',\n                         patience = 10,\n                         verbose = 1,\n                         factor = 0.75,\n                         min_lr = 1e-10)\n\nmcp = ModelCheckpoint('model.h5')\n\nes = EarlyStopping(verbose=1, patience=100)","a291f8dc":"history = model.fit(x=x_train, y=y_train, epochs=500, callbacks=[lrd, mcp, es], batch_size=32, validation_split=0.1)","c4a918ea":"y_pred = np.argmax(model.predict(x_val), axis=-1)\ny_pred ","13f0a676":"y_val","3938c2ba":"np.argmax(model.predict(x_val), axis=-1)[10]","f2d2f6fb":"y_val.iloc[10]","e36112c7":"model.evaluate(x_val, y_val)","2af1ab4d":"y_pred","5cc57d7d":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper right')\nplt.show()\n\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","8ba462bf":"ID=dftest[\"ID\"]","15c40d51":"xtest=dftest.drop(columns=['ID'])\nxtest","bebec2b0":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nsc.fit(xtest)\nxtest = sc.transform(xtest)","7a75e64f":"y_pred2 = np.argmax(model.predict(xtest), axis=-1)\ny_pred2","0565f4ac":"dfyPred = pd.DataFrame(y_pred2, columns = [\"yPred\"])\ndfyPred['yPredNew']      = np.where((dfyPred['yPred']==0), 'y_BARBUNYA',dfyPred['yPred'])\ndfyPred['yPredNew']      = np.where((dfyPred['yPred']==1), 'y_BOMBAY',dfyPred['yPredNew'])\ndfyPred['yPredNew']      = np.where((dfyPred['yPred']==2), 'y_CALI',dfyPred['yPredNew'])\ndfyPred['yPredNew']      = np.where((dfyPred['yPred']==3), 'y_DERMASON',dfyPred['yPredNew'])\ndfyPred['yPredNew']      = np.where((dfyPred['yPred']==4), 'y_HOROZ',dfyPred['yPredNew'])\ndfyPred['yPredNew']      = np.where((dfyPred['yPred']==5), 'y_SEKER',dfyPred['yPredNew'])\ndfyPred['yPredNew']      = np.where((dfyPred['yPred']==6), 'y_SIRA',dfyPred['yPredNew'])\ndfyPred['result'] = dfyPred['yPredNew'].map(lambda x: x.lstrip('y_'))\ndfyPred=dfyPred[\"result\"]\ndfyPred","f1c3fd4f":"dftest['y'] = dfyPred","d738f4d8":"dftest","daaa2f1c":"dftest.drop(columns=\"ID\",inplace=True)\ndfTest=pd.concat([dftest, ID],axis=1)\n\ndfTest[['ID', 'y']].to_csv('\/kaggle\/working\/submission.csv', index=False)\n# dfTest[['ID', 'y']].to_csv('submission.csv', index=False)","099f53c4":"## Visualize Loss","72261776":"# Test Data","f71a078a":"_________________________________________________________","1a79fb2a":"__________________________","fa537a17":"## Testing & evaluating the model","16ea68b1":"## Defining the model structure","f0634663":"## Training the model"}}