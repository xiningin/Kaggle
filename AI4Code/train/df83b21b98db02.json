{"cell_type":{"abbd3c6f":"code","74e4e7a8":"code","41841568":"code","fa79c896":"code","cf06cff5":"code","89cb85b0":"code","0e1104ca":"code","2dbc3fcc":"code","a764ea2a":"code","8e265f03":"code","b207f8c2":"code","2e594955":"code","015ce26d":"code","f5aded10":"code","42a0c7d0":"code","e3c8f210":"markdown","5c6401f4":"markdown","c93f46fd":"markdown","c76471cf":"markdown","c2f336f8":"markdown","a6e22dc6":"markdown","3ff81dfd":"markdown","3c5f73b5":"markdown","481a4d1e":"markdown"},"source":{"abbd3c6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74e4e7a8":"#Code by Ryan Holbrook\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='summer')\n\nimage_path = '..\/input\/ouhands\/OUHANDS_train\/train\/negative_data\/colour\/0033.png'\nimage = tf.io.read_file(image_path)\nimage = tf.io.decode_jpeg(image, channels=1)\nimage = tf.image.resize(image, size=[400, 400])\n\nplt.figure(figsize=(6, 6))\nplt.imshow(tf.squeeze(image), cmap='summer')\nplt.axis('off')\nplt.show();","41841568":"import learntools.computer_vision.visiontools as visiontools\nfrom learntools.computer_vision.visiontools import edge, bottom_sobel, emboss, sharpen\n\nKaggleNotebooks = [edge, bottom_sobel, emboss, sharpen]\nnames = [\"Edge Detect\", \"Bottom Sobel\", \"Emboss\", \"Sharpen\"]\n\nplt.figure(figsize=(12, 12))\nfor i, (KaggleNotebook, name) in enumerate(zip(KaggleNotebooks, names)):\n    plt.subplot(1, 4, i+1)\n    visiontools.show_kernel(KaggleNotebook)\n    plt.title(name)\nplt.tight_layout()","fa79c896":"#Code By Ryan Holbrook\n# Reformat for batch compatibility.\nimage = tf.image.convert_image_dtype(image, dtype=tf.float32)\nimage = tf.expand_dims(image, axis=0)\nKaggleNotebook = tf.reshape(KaggleNotebook, [*KaggleNotebook.shape, 1, 1])\nKaggleNotebook = tf.cast(KaggleNotebook, dtype=tf.float32)","cf06cff5":"conv_fn = tf.nn.conv2d","89cb85b0":"image_filter = conv_fn(\n    input=image,\n    filters=KaggleNotebook,\n    strides=1, # or (1, 1)\n    padding='SAME',\n)\n\nplt.imshow(\n    # Reformat for plotting\n    tf.squeeze(image_filter)\n)\nplt.axis('off')\nplt.show();","0e1104ca":"# Give the TensorFlow ReLU function (without arguments)\nrelu_fn = tf.nn.relu","2dbc3fcc":"#Code By Ryan Holbrook\nimage_detect = relu_fn(image_filter)\n\nplt.imshow(\n    # Reformat for plotting\n    tf.squeeze(image_detect)\n)\nplt.axis('off')\nplt.show();","a764ea2a":"#Code By Ryan Holbrook\n# Sympy is a python library for symbolic mathematics. It has a nice\n# pretty printer for matrices, which is all we'll use it for.\nimport sympy\nsympy.init_printing()\nfrom IPython.display import display\n\nimage = np.array([\n    [0, 1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0, 0],\n    [0, 1, 0, 1, 1, 1],\n    [0, 1, 0, 0, 0, 0],\n])\n\nKaggleNotebook = np.array([\n    [1, -1],\n    [1, -1],\n])\n\ndisplay(sympy.Matrix(image))\ndisplay(sympy.Matrix(KaggleNotebook))\n# Reformat for Tensorflow\nimage = tf.cast(image, dtype=tf.float32)\nimage = tf.reshape(image, [1, *image.shape, 1])\nKaggleNotebook = tf.reshape(KaggleNotebook, [*KaggleNotebook.shape, 1, 1])\nKaggleNotebook = tf.cast(KaggleNotebook, dtype=tf.float32)","8e265f03":"# Read image\nimage_path = '..\/input\/ouhands\/OUHANDS_train\/train\/negative_data\/colour\/0033.png'\nimage = tf.io.read_file(image_path)\nimage = tf.io.decode_jpeg(image, channels=1)\nimage = tf.image.resize(image, size=[400, 400])\n\n# Embossing kernel\nkernel = tf.constant([\n    [-2, -1, 0],\n    [-1, 1, 1],\n    [0, 1, 2],\n])\n\n# Reformat for batch compatibility.\nimage = tf.image.convert_image_dtype(image, dtype=tf.float32)\nimage = tf.expand_dims(image, axis=0)\nkernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\nkernel = tf.cast(kernel, dtype=tf.float32)\n\nimage_filter = tf.nn.conv2d(\n    input=image,\n    filters=kernel,\n    strides=1,\n    padding='VALID',\n)\n\nimage_detect = tf.nn.relu(image_filter)\n\n# Show what we have so far\nplt.figure(figsize=(12, 6))\nplt.subplot(131)\nplt.imshow(tf.squeeze(image), cmap='gray')\nplt.axis('off')\nplt.title('Input')\nplt.subplot(132)\nplt.imshow(tf.squeeze(image_filter))\nplt.axis('off')\nplt.title('Filter')\nplt.subplot(133)\nplt.imshow(tf.squeeze(image_detect))\nplt.axis('off')\nplt.title('Detect')\nplt.show();","b207f8c2":"image_condense = image_condense = tf.nn.pool(\n    input=image_detect,\n    window_shape=(2, 2),\n    pooling_type='MAX',\n    strides=(2, 2),\n    padding='SAME',\n)","2e594955":"plt.figure(figsize=(8, 6))\nplt.subplot(121)\nplt.imshow(tf.squeeze(image_detect))\nplt.axis('off')\nplt.title(\"Detect (ReLU)\")\nplt.subplot(122)\nplt.imshow(tf.squeeze(image_condense))\nplt.axis('off')\nplt.title(\"Condense (MaxPool)\")\nplt.show();","015ce26d":"REPEATS = 4\nSIZE = [64, 64]\n\n# Create a randomly shifted circle\nimage = visiontools.circle(SIZE, r_shrink=4, val=1)\nimage = tf.expand_dims(image, axis=-1)\nimage = visiontools.random_transform(image, jitter=3, fill_method='replicate')\nimage = tf.squeeze(image)\n\nplt.figure(figsize=(16, 4))\nplt.subplot(1, REPEATS+1, 1)\nplt.imshow(image, vmin=0, vmax=1)\nplt.title(\"Original\\nShape: {}x{}\".format(image.shape[0], image.shape[1]))\nplt.axis('off')\n\n# Now condense with maximum pooling several times\nfor i in range(REPEATS):\n    ax = plt.subplot(1, REPEATS+1, i+2)\n    image = tf.reshape(image, [1, *image.shape, 1])\n    image = tf.nn.pool(image, window_shape=(2,2), strides=(2, 2), padding='SAME', pooling_type='MAX')\n    image = tf.squeeze(image)\n    plt.imshow(image, vmin=0, vmax=1)\n    plt.title(\"MaxPool {}\\nShape: {}x{}\".format(i+1, image.shape[0], image.shape[1]))\n    plt.axis('off')","f5aded10":"#Codes by Ryan Holbrook\n\nfrom matplotlib import gridspec\n\nfeature_maps = [visiontools.random_map([5, 5], scale=0.1, decay_power=4) for _ in range(8)]\n\ngs = gridspec.GridSpec(1, 8, wspace=0.01, hspace=0.01)\nplt.figure(figsize=(18, 2))\nfor i, feature_map in enumerate(feature_maps):\n    plt.subplot(gs[i])\n    plt.imshow(feature_map, vmin=0, vmax=1)\n    plt.axis('off')\nplt.suptitle('Feature Maps', size=18, weight='bold', y=1.1)\nplt.show()\n\n# reformat for TensorFlow\nfeature_maps_tf = [tf.reshape(feature_map, [1, *feature_map.shape, 1])\n                   for feature_map in feature_maps]\n\nglobal_avg_pool = tf.keras.layers.GlobalAvgPool2D()\npooled_maps = [global_avg_pool(feature_map) for feature_map in feature_maps_tf]\nimg = np.array(pooled_maps)[:,:,0].T\n\nplt.imshow(img, vmin=0, vmax=1)\nplt.axis('off')\nplt.title('Pooled Feature Maps')\nplt.show();","42a0c7d0":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#32a832','#32a84e','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Mar\u00edlia Prata, @mpwolke was here' )","e3c8f210":"![](https:\/\/d3i71xaburhd42.cloudfront.net\/d58e9c94206b72de545f7720c38f87f1c8b81839\/2-Figure2-1.png)ouhands.oulu.fi","5c6401f4":"Define a simple array to act as an image, and another array to act as the Kaggle Notebook. The following cell show these arrays.","c93f46fd":"#Codes by Ryan Holbrook  https:\/\/www.kaggle.com\/ryanholbrook\/convolution-and-relu","c76471cf":"#Spoiler alert, It's the Hat! ","c2f336f8":"#Apply Pooling to Condense","a6e22dc6":"#The first step of feature extraction, the filtering step. Do some reformatting for TensorFlow","3ff81dfd":"#Apply ReLU","3c5f73b5":"#OUHANDS is a database of static hand pose images captured in a HCI-like setting.\n\nThe camera was hand-held and the hand was kept relatively close to the camera. The database was captured using the RealSense RGB-D camera.\n\nCITATION:\n\nM. Matilainen, P. Sangi, J. Holappa and O. Silven. OUHANDS database for hand detection and pose recognition. Proc. International Conference on Image Processing Theory, Tools and Applications, 2016. http:\/\/www.ouhands.oulu.fi\/","481a4d1e":"#Apply Transformations"}}