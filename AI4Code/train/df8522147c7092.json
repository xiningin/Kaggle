{"cell_type":{"11371a6e":"code","b9af4333":"code","c08300ca":"code","4438f059":"code","9aac2d55":"code","bc89d330":"code","50f1e982":"code","1913df74":"code","046684fb":"code","ff113626":"code","b1ae6bcd":"code","3ebbdbf0":"code","db7a1e15":"code","d636a6b4":"code","9f59901e":"code","76c506c8":"code","af5f1dd0":"code","5f92dbc1":"code","bf674be6":"code","0534b71f":"code","31502e02":"code","abcf3b4e":"code","fac840ac":"code","3a8fda16":"code","e538a589":"code","763563c6":"code","248efecb":"code","f498a330":"code","90e8c53a":"code","08e476f5":"code","1686f48b":"code","a694a947":"code","a3fad753":"code","501e272b":"code","f0eb5df8":"code","f19eb8f5":"code","ca1545f1":"code","725b05f8":"code","eca360ab":"code","6c54cb92":"code","5a5daa1f":"code","b0d07b95":"code","8a0c4403":"code","2b3451b4":"code","795a461c":"code","6b32fab2":"code","803b3d33":"code","8494778e":"code","e191f027":"code","36c304c0":"code","fd7be207":"code","80e2e17c":"code","1cc68714":"markdown","e3646ddb":"markdown","5a0977b5":"markdown","e51928bc":"markdown","69389fee":"markdown","5adf7eae":"markdown","78d66188":"markdown","67178379":"markdown","d853c914":"markdown","39470ebf":"markdown","9bad0f00":"markdown","38401f2b":"markdown","b703cd46":"markdown"},"source":{"11371a6e":"\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b9af4333":"df=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf.head()","c08300ca":"dft=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndft.head()","4438f059":"print(df.shape)\nprint(dft.shape)\n","9aac2d55":"df.describe()","bc89d330":"dft.describe()","50f1e982":"df.info()","1913df74":"dft.info()","046684fb":"df.isnull().sum()","ff113626":"dft.isnull().sum()","b1ae6bcd":"#visualise missing value \nimport missingno as mn\nmn.matrix(df)\nmn.matrix(dft)","3ebbdbf0":"df = df.drop(['Cabin'], axis = 1)\n","db7a1e15":"dft = dft.drop(['Cabin'], axis = 1)","d636a6b4":"df['Embarked'].value_counts()","9f59901e":"#Embarked has 2 missing value fill with S which has highest number\ndf['Embarked'].fillna('S',inplace=True)","76c506c8":"dft['Embarked'].fillna('S',inplace=True)","af5f1dd0":"#replace NaN value in Age with mean value\nmedian=np.round(df['Age'].median(),1)\ndf['Age'].fillna(median,inplace=True)","5f92dbc1":"median=np.round(dft['Age'].median(),1)\ndft['Age'].fillna(median,inplace=True)","bf674be6":"df.isnull().sum()","0534b71f":"dft.isnull().sum()","31502e02":"#replace Sex column with numeric 0,1 with male,female rep\ndf=df.replace({'male': 0,\n            'female' : 1})\ndf.head()","abcf3b4e":"dft=dft.replace({'male': 0,\n            'female' : 1})\ndft.head()","fac840ac":"#find the correlation between data\ndf.corr()","3a8fda16":"#visualise correlation data using heatmap\nplt.figure(figsize=(14,6))\nsns.heatmap(df.corr(),annot=True)\n","e538a589":"#plot graph between pclass and survived\nsns.barplot(x='Pclass',y='Survived',data=df)","763563c6":"#Sex vs Survived\nsns.barplot(x='Sex',y='Survived',data=df)","248efecb":"#Embarked vs Survived\nsns.barplot(x='Embarked',y='Survived',data=df)","f498a330":"#Drop unwanted columns such as Name,Ticket,Fare is decided by Pclass so drop fare also\ndf=df.drop(['Name','Ticket','Fare'],axis=1)","90e8c53a":"dft=dft.drop(['Name','Ticket','Fare'],axis=1)","08e476f5":"#add SibSp and Parch in Family\ndf['Family']=df['SibSp']+df['Parch']+1\ndf=df.drop(['SibSp','Parch'],axis=1)","1686f48b":"dft['Family']=dft['SibSp']+dft['Parch']+1\ndft=dft.drop(['SibSp','Parch'],axis=1)","a694a947":"#Categorise Age\ndef AgeGroup(age):\n    a=''\n    if age<=10:\n        a='Child'\n    elif age<=30:\n        a='Young'\n    elif age<=50:\n        a='Adult'\n    else:\n        a='Old'\n    return a\ndf['AgeGroup']=df['Age'].map(AgeGroup)\ndf=df.drop(['Age'],axis=1)","a3fad753":"dft['AgeGroup']=dft['Age'].map(AgeGroup)\ndft=dft.drop(['Age'],axis=1)","501e272b":"#Categorise Family\ndef FamilyGroup(family):\n    a=''\n    if family<=1:\n        a='Solo'\n    elif family<=4:\n        a='Small'\n    else:\n        a='Large'\n    return a\ndf['FamilyGroup']=df['Family'].map(FamilyGroup)\ndf=df.drop(['Family'],axis=1)    ","f0eb5df8":"dft['FamilyGroup']=dft['Family'].map(FamilyGroup)\ndft=dft.drop(['Family'],axis=1)","f19eb8f5":"#get dummies variable\ndf=pd.get_dummies(df,columns=['Embarked','AgeGroup','FamilyGroup','Sex'])","ca1545f1":"dft=pd.get_dummies(dft,columns=['Embarked','AgeGroup','FamilyGroup','Sex'])","725b05f8":"print(df.shape)\nprint(dft.shape)","eca360ab":"df.head()","6c54cb92":"dft.head()","5a5daa1f":"X=df.drop(['Survived'],axis=1)\nX.head()\ny=df['Survived']\ny.head()","b0d07b95":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=1)","8a0c4403":"#import all lib\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss","2b3451b4":"#KNN CLASSIFIER\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nKs = 15\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)\/np.sqrt(yhat.shape[0])\n\nmean_acc","795a461c":"print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ","6b32fab2":"#LOGISTIC REGRESSION\nfrom sklearn.linear_model import LogisticRegression\nLR = LogisticRegression().fit(X_train,y_train)\ny_pred=LR.predict(X_test)\nprint(\"The best accuracy with LR is\", metrics.accuracy_score(y_test,y_pred))\n","803b3d33":"#SVM\nfrom sklearn import svm\nSVM=svm.SVC().fit(X_train,y_train)\ny_pred=SVM.predict(X_test)\nprint(\"The best accuracy with SVM is\", metrics.accuracy_score(y_test,y_pred))","8494778e":"#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndef getaccuracy(max_leaf,X_train,y_train,X_test,y_test):\n    DT=DecisionTreeClassifier().fit(X_train,y_train)\n    y_pred=DT.predict(X_test)\n    return(metrics.accuracy_score(y_test,y_pred))\n    \n","e191f027":"for max_leaf in [5,50,500]:\n    my_mae = getaccuracy(max_leaf,X_train,y_train,X_test,y_test)\n    print(\"Max leaf : \",max_leaf,'The best accuracy with SVM is',my_mae)","36c304c0":"#define whole train as TrainX and Trainy\nTrainX=df.drop(['Survived'],axis=1)\nTrainy=df['Survived']","fd7be207":"from sklearn import svm\nSVM=svm.SVC().fit(TrainX,Trainy)\ny_pred=SVM.predict(dft)","80e2e17c":"submission = pd.DataFrame({\n        \"PassengerId\": dft[\"PassengerId\"],\n        \"Survived\": y_pred\n    })\nsubmission.to_csv('titanic.csv', index=False)\nprint(\"Submitted Successfully\")","1cc68714":"We will use Logistic regression,SVM,KNN,and desicion tree.","e3646ddb":"So higher class people had higher survived rate","5a0977b5":"# Model Creation and Evaluation","e51928bc":"Female had much more survived rate than male","69389fee":"# Feature Engineering","5adf7eae":"Since only age and cabin feature has missing values with more percentage.Due to percentage is more we can not drop missing value.We may loose some important data.We will drop Cabin row instead of 687 rows.","78d66188":"We conclude that as age increased survived rate is decreasing because of negative correlation and as fare increases survive rate increases due to positive value","67178379":"Take 50 as max leaf node.","d853c914":"Hope you are clear with problem statement and all features.So we have to predict whetaher person will survive or not using our model.We list out steps for our train and test dataset.\nImport useful libraries\nCheck data,check missing values","39470ebf":"We will deal with categorical output so convert numerical variable into categorical i.e Age,Family.","9bad0f00":"# Prediction\nSo best classifier is SVM with high accuracy.","38401f2b":"# EDA\nTill now we were dealing with missing values.It is time for visualising data.Lets do it","b703cd46":"Now visualise each data with survived rate"}}