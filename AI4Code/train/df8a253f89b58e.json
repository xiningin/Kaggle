{"cell_type":{"7f083d56":"code","7bc985c2":"code","6067b8bd":"code","34f4beb0":"code","ccd228f5":"code","60e76d77":"code","25095f81":"code","82e3e002":"code","28c7a6f7":"code","b996225b":"code","1ff9d54e":"code","1a89f473":"code","bcede40b":"code","f0dfe155":"code","5cf8648f":"code","69140183":"code","fb65f052":"code","2f42f9ca":"code","8e2a8226":"code","77dfc827":"code","c35f6f9b":"markdown"},"source":{"7f083d56":"import keras\nfrom keras.datasets import cifar10\nfrom keras import backend as K\nfrom tensorflow.keras.layers import Input, Conv2D, Dense, BatchNormalization, Activation\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, MaxPooling2D, add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import SeparableConv2D\n\nfrom tensorflow.keras import optimizers,regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.initializers import he_normal\nfrom tensorflow.keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n\nnum_classes        = 10\nbatch_size         = 64 \nepochs             = 100\niterations         = 782       \nweight_decay=1e-4","7bc985c2":"def color_preprocessing(x_train,x_test):\n    x_train = x_train.astype('float32')\n    x_test = x_test.astype('float32')\n    mean = [125.307, 122.95, 113.865]\n    std  = [62.9932, 62.0887, 66.7048]\n    for i in range(3):\n        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) \/ std[i]\n        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) \/ std[i]\n    return x_train, x_test","6067b8bd":"def scheduler(epoch):\n    if epoch < 100:\n        return 0.01\n    return 0.001","34f4beb0":"# load data\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test  = keras.utils.to_categorical(y_test, num_classes)\nx_train, x_test = color_preprocessing(x_train, x_test)","ccd228f5":"# 36 convolutional layers are structured into 14 modules\ndef entryflow(x,params,top=False):\n    # modules 2-4,13\n    # params is (3,)\n    # top = true means module 2, don't use relu\n    residual = Conv2D(params[0], (1, 1), strides=(2, 2),padding='same')(x)\n    residual = BatchNormalization()(residual)\n    if top:\n        x = Activation('relu')(x)\n    x = SeparableConv2D(params[1], (3, 3),padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(params[2], (3, 3),padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2),padding='same')(x)\n    x = add([x, residual])\n    return x","60e76d77":"def middleflow(x,params):\n    # modules 5-12, params is int\n    residual = x\n    x = Activation('relu')(x)\n    x = SeparableConv2D(params, (3, 3),padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(params, (3, 3),padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(params, (3, 3),padding='same')(x)\n    x = BatchNormalization()(x)\n    x = add([x, residual])\n    return x","25095f81":"def exitflow(x,params):\n    # modules 14 , params is (2,)\n    x = SeparableConv2D(params[0], (3, 3),padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(params[1], (3, 3),padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)   \n    return x","82e3e002":"def xception(img_input,shallow=False, classes=10):\n    # modules 1\n    x = Conv2D(32,(3, 3),strides=(2, 2),padding='same')(img_input)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(64, (3, 3),strides=(1,1),padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    # module 2\n    x = entryflow(x,(128,128,128),top=True)\n    # module 3-4\n    x = entryflow(x,(256,256,256))\n    x = entryflow(x,(728,728,728))\n    # module 5-12\n    for _ in range(8):\n        x = middleflow(x,728)\n    # module 13\n    x = entryflow(x,(1024,728,1024))\n    # module 14\n    x = exitflow(x,(1536,2048))\n    # output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(classes, activation='softmax')(x)\n    return x","28c7a6f7":"img_input=Input(shape=(32,32,3))\noutput = xception(img_input)\nmodel=Model(img_input,output)\nmodel.summary()","b996225b":"# set optimizer\nsgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n# compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])","1ff9d54e":"# set callback\nlog_filepath  = '.\/xception_1'\ntb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\nchange_lr = LearningRateScheduler(scheduler)\ncbks = [change_lr,tb_cb]","1a89f473":"# set data augmentation\ndatagen = ImageDataGenerator(horizontal_flip=True,\n                             width_shift_range=0.125,\n                             height_shift_range=0.125,\n                             fill_mode='constant',cval=0.)\ndatagen.fit(x_train)","bcede40b":"# start training\nh=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n                    steps_per_epoch=iterations,\n                    epochs=epochs,\n                    callbacks=cbks\n                      ,\n                    validation_data=(x_test, y_test))","f0dfe155":"import matplotlib.pyplot as plt\nepoch_nums = range(1, epochs+1)\ntraining_loss = h.history[\"loss\"]\nvalidation_loss = h.history[\"val_loss\"]\nplt.plot(epoch_nums , training_loss)\nplt.plot(epoch_nums , validation_loss)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['training','validation'], loc='upper right')\nplt.show()","5cf8648f":"model.save('xception_1.h5')","69140183":"scores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","fb65f052":"def testImage(result):\n    print(result) \n    if result[0][0]==1: \n        print(\"Aeroplane\") \n    elif result[0][1]==1: \n        print('Automobile') \n    elif result[0][2]==1: \n        print('Bird') \n    elif result[0][3]==1: \n        print('Cat') \n    elif result[0][4]==1: \n        print('Deer') \n    elif result[0][5]==1: \n        print('Dog') \n    elif result[0][6]==1: \n        print('Frog') \n    elif result[0][7]==1: \n        print('Horse') \n    elif result[0][8]==1: \n        print('Ship') \n    elif result[0][9]==1: \n        print('Truck') \n    else:\n        print('Error')","2f42f9ca":"from keras.preprocessing import image\nimport numpy as np\n\ntest_image1 =image.load_img(\"..\/input\/imagetest\/Image\/horse1.jpg\",target_size =(32,32,3))\ntest_image =image.img_to_array(test_image1) \ntest_image =np.expand_dims(test_image, axis =0) \nresult = model.predict(test_image)\nplt.imshow(test_image1)\ntestImage(result)","8e2a8226":"y_pred_test = model.predict(x_test)\ny_pred_test_classes = np.argmax(y_pred_test, axis=1)\ny_pred_test_max_probas = np.max(y_pred_test, axis=1)","77dfc827":"cols = 8\nrows = 2\nNUM_CLASSES = 10\n# load data\n(x_train2, y_train2), (x_test2, y_test2) = cifar10.load_data()\ncifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\nfig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\nfor i in range(cols):\n    for j in range(rows):\n        random_index = np.random.randint(0, len(y_test2))\n        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n        ax.grid('off')\n        ax.axis('off')\n        ax.imshow(x_test2[random_index, :])\n        pred_label =  cifar10_classes[y_pred_test_classes[random_index]]\n        pred_proba = y_pred_test_max_probas[random_index]\n        true_label = cifar10_classes[y_test2[random_index, 0]]\n        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n               pred_label, pred_proba, true_label\n        ))\nplt.show()\n","c35f6f9b":"# Loss"}}