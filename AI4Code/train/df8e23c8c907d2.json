{"cell_type":{"8b70ba9b":"code","5e4ebd52":"code","c0695d21":"code","d5d91bdf":"code","cb64524d":"code","29603362":"code","4e8a1cb2":"code","d0e07cea":"code","7e23bff3":"code","98262bdd":"code","8a339194":"code","00d5e36d":"code","664178c3":"code","d064ee27":"code","5f2d7345":"code","e4b92f10":"code","a1edc796":"code","5f645d00":"code","be958c29":"code","bec9cbfc":"code","cee63cd0":"code","4a3b4a01":"code","346c2bfd":"code","f94c780d":"code","a69d5288":"code","9512602b":"code","3bd7e8f0":"code","d66bd3e6":"code","6304503e":"code","3262dfde":"code","52effd64":"code","4610a043":"code","fb516974":"code","c4950788":"code","ff94c614":"code","0a3d2481":"code","8a87c4db":"code","2eaf817b":"code","1df5c430":"code","db60ac54":"code","da3464b9":"code","ec2c32c2":"code","2813514b":"code","178a0489":"code","32195f86":"code","213e9e01":"code","1431e1c5":"code","8732a2e5":"code","23d5929a":"code","86c43be3":"code","46a33a9b":"code","935ff864":"code","cab154e3":"code","f8093839":"code","b6b0cd9b":"code","4b99fd58":"code","4b582304":"code","49e9eb8d":"code","8480a574":"code","38a0a499":"code","e570b0e6":"code","d669bff7":"code","118287ca":"code","7be64148":"code","aa183b6d":"code","822ed3b0":"code","9a9e5e67":"code","1b79d36f":"code","8d0c5707":"code","9e45a570":"code","111fef31":"code","d40d5727":"code","383d59be":"code","663b6cdf":"code","0b340aea":"code","9e48943c":"code","445fd2d7":"code","0fa5d04c":"markdown","c68c6c48":"markdown","87cf551c":"markdown","9d843285":"markdown","0bc1b93f":"markdown","91cdcfa1":"markdown","3f890f32":"markdown","31825b3d":"markdown","07aa5f4d":"markdown","59effe4b":"markdown","1a0beeb8":"markdown","a6190753":"markdown","2e10bcbe":"markdown","2c0472a6":"markdown","ca69b960":"markdown","32c93f80":"markdown","5724a4cc":"markdown","8f337aea":"markdown","2a6d7fea":"markdown"},"source":{"8b70ba9b":"import numpy as np\nimport pandas as pd\nimport jieba\nimport re\n\n# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\nfrom gensim.corpora import Dictionary\n\n# Pre-Processing\nimport string\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.stem import PorterStemmer\n\n# Modeling\nimport gensim\nimport statsmodels.api as sm\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nfrom nltk.util import ngrams\nfrom collections import Counter\nfrom gensim.models import word2vec\nfrom nltk.tokenize import word_tokenize\nfrom gensim import corpora, models, similarities\nfrom gensim.models import TfidfModel\nfrom gensim.corpora import Dictionary\nfrom nltk.stem.lancaster import LancasterStemmer\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split as split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\n\n# For the first-time user, you should download these two pre-trained tokenizer\n#nltk.download('punkt') \n#nltk.download('stopwords')\n\nimport numpy as np\nimport pandas as pd\n\n# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\n\nimport nltk\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.corpus import stopwords\nlemmatizer = WordNetLemmatizer()\nstemmer = PorterStemmer() \n#nltk.download('wordnet')\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report","5e4ebd52":"data = pd.read_csv(\"..\/input\/doubanmovieshortcomments\/DMSC.csv\")","c0695d21":"# check whether there are nan values\n\ndata.isna().sum()","d5d91bdf":"# drop the duplicated value and keep the comments which only appear one time \n\ndata = data.drop_duplicates(['Comment'], keep='first')","cb64524d":"# transform to the positive and negative\n\ndef polarity (row):\n  if row['Star'] >= 4: # bigger or equal to 4 stars are positive\n    return '1'\n  if row['Star'] <= 3: # smaller or equal to 3 stars are negative\n    return '0'\n\ndata['Star'] = data.apply(lambda row: polarity(row), axis=1)","29603362":"data['Movie_Name_CN'].value_counts()","4e8a1cb2":"# choose the samples\n\n#data_part = data.groupby(['Movie_Name_CN', 'Star']).apply(\n    #lambda x: x.sample(n=int(2125056\/(28*10)), replace=True, random_state=0))","d0e07cea":"# only use the star and comment columns\n\n#Review = data_part[['Star','Comment']]\ncomment = data[['Star','Comment']]","7e23bff3":"# check the positive and negative distribution\n\ncount = pd.value_counts(comment['Star'])\ncount","98262bdd":"import matplotlib.mlab as mlab  \nimport matplotlib.pyplot as plt  \nlabels=['positive','negative']\nX=[1179936,783088]  \n\nfig = plt.figure()\nplt.pie(X,labels=labels,autopct='%1.2f%%')\n\nplt.show()  \nplt.savefig(\"PieChart.jpg\")","8a339194":"comment","00d5e36d":"# make an back-up copy, if we use sample data\n\n#comment = pd.DataFrame(Review.values,columns=Review.columns)\n#comment","664178c3":"# remove the number, punctuation\n\ndef preprocess(sentence):\n    sentence=str(sentence)\n    #sentence = sentence.lower()\n    sentence=sentence.replace('{html}',\"\") \n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, '', sentence)\n    rem_url=re.sub(r'http\\S+', '',cleantext)\n    rem_num = re.sub('[0-9]+', '', rem_url)\n    tokenizer = RegexpTokenizer(r'\\w+')\n    tokens = tokenizer.tokenize(rem_num)  \n    #filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n    stem_words=[stemmer.stem(w) for w in tokens]\n    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n    return \" \".join(tokens)\n\ncomment['Comment'] = comment['Comment'].apply(preprocess)\ncomment.head()","d064ee27":"# we choose some moive frequent words as the add words to avoid wrong tokenization\n\nimport jieba\nadd_words = pd.read_excel(\"add_words.xlsx\")\n\nfor w in add_words.word:\n   jieba.add_word(w , freq=1000)","5f2d7345":"%%time\n# use jieba to make tokenization, \n\ncomment_s = []\nfor line in comment['Comment']:\n    comment_cut = jieba.lcut(line)\n    comment_s.append(comment_cut)","e4b92f10":"comment_s","a1edc796":"# delete some meaningless stop words\n\ndef get_custom_stopwords(stop_words_file):    \n    with open(stop_words_file) as f:        \n        stopwords = f.read()    \n        stopwords_list = stopwords.split('\\n')    \n        custom_stopwords_list = [i for i in stopwords_list]    \n    return custom_stopwords_list","5f645d00":"#-*- coding : utf-8-*-\n# coding:unicode_escape\nio = \"\u4e2d\u6587\u505c\u7528\u8bcd\u5e93.txt\"\n#data=pd.read_csv(io,encoding='unicode_escape')\nstopwords = pd.read_csv(io,encoding='gbk')","be958c29":"stopwords","bec9cbfc":"stop_words_file = \"\u4e2d\u6587\u505c\u7528\u8bcd\u5e93.txt\"\nstopwords = get_custom_stopwords(stop_words_file)","cee63cd0":"%%time\ncomment_clean = []\nfor line in comment_s:\n    line_clean = []\n    for word in line:\n        if word not in stopwords:\n            line_clean.append(word)\n    comment_clean.append(line_clean)","4a3b4a01":"comment_clean","346c2bfd":"%%time\n\n# drop the duplicated words in one comment\n\ncomment_clean_dist = []\nfor line in comment_clean:   \n   line_dist = []\n   for word in line:\n      if word not in line_dist:\n         line_dist.append(word)\n   comment_clean_dist.append(line_dist)","f94c780d":"comment_clean_dist","a69d5288":"%%time\n\n# calculate the the length of each review\nlen_line = []\nfor line in comment_clean_dist:\n    length = len(line)\n    len_line.append(length)","9512602b":"# put all reviews in one list \n\nallwords_clean_dist = []\nfor line in comment_clean_dist:\n   for word in line:\n      allwords_clean_dist.append(word)","3bd7e8f0":"allwords_clean_dist","d66bd3e6":"# make a dataframe to count the frequency\n\ndf_allwords_clean_dist = pd.DataFrame({'allwords': allwords_clean_dist})\nword_count = df_allwords_clean_dist.allwords.value_counts().reset_index()    \nword_count.columns = ['word','count'] ","6304503e":"word_count","3262dfde":"# use the most frequent words to draw word cloud\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n    \nplt.figure(figsize=(20,10), dpi = 300)\nw_c = WordCloud(font_path=r\"C:\\Users\\87973\\Desktop\\\u9510\u5b57\u903c\u683c\u9510\u7ebf\u7c97\u4f53\u7b802.0.TTF\",background_color=\"white\", \n                max_font_size=60, margin=1)\nwc = w_c.fit_words({x[0]:x[1] for x in word_count.head(150).values})    \n\nplt.imshow(wc, interpolation='bilinear') \nplt.axis(\"off\")\nplt.show()","52effd64":"# transform comment_clean_dist to only one list that using commas fragments each comment\n\nAll_text = []\nfor line in comment_clean_dist:\n    onetext = \" \".join(line)\n    All_text.append(onetext)\nAll_text","4610a043":"# using All_text value make a dataframe\n\ndf_all_text = pd.DataFrame(All_text, columns = ['Comment'])\ndf_all_text","fb516974":"# spilting data to train and test data set\n\ntext = df_all_text['Comment']\nscore = comment['Star']\nX_train1, X_test1, y_train1, y_test1 = train_test_split(text, score, test_size = 0.20, random_state = 0, stratify = score)","c4950788":"# convert corpus to BoW format\n\nfrom sklearn.feature_extraction.text import CountVectorizer \ncount_vect = CountVectorizer(encoding='latin-1')\nX_train_counts = count_vect.fit_transform(X_train1)\nX_train_counts.shape","ff94c614":"#calculate tf-idf and use tf-idfs to represent documents\n\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer(use_idf=True)\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n\nX_train_tfidf.shape","0a3d2481":"# build MultinomialNB model\n\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB().fit(X_train_tfidf, y_train1)","8a87c4db":"# fit MultinomialNB model\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nX_test_counts = count_vect.transform(X_test1)\nX_test_tfidf = tfidf_transformer.transform(X_test_counts)\ny_pre1 = clf.predict(X_test_tfidf)\ngaussian_acc = accuracy_score(y_test1, y_pre1)\nprint(gaussian_acc)","2eaf817b":"# print the classification report and confustion report\n\nprint(\"Classification Report:\\n \", classification_report(y_test1, y_pre1))\nprint(\"Confusion Matrix:\\n \", confusion_matrix(y_test1, y_pre1))","1df5c430":"# draw the ROC plot and calculate AUC score\n\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import roc_curve\n\ny_pred11 = clf.predict_proba(X_test_tfidf)\n(fpr, tpr, thresholds) = roc_curve(y_test1,y_pred11[:,1],pos_label='1')\nroc_auc = auc(fpr,tpr)\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr,lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) \nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","db60ac54":"# cross-validation to find the best parameter\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nrandom_search = {'C':[0.01, 1, 10, 100]}\ngrid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=random_search, cv=4, n_jobs=-1, scoring='roc_auc')\ngrid_result=grid_search.fit(X_train_tfidf, y_train1)\nprint(f'Best:{grid_result.best_score_}using{grid_result.best_params_}','\\n')","da3464b9":"lr = LogisticRegression(C=1)\nlr.fit(X_train_tfidf, y_train1)\ny_pre2 = lr.predict(X_test_tfidf)\nlogistic_acc = accuracy_score(y_test1, y_pre2)\nprint(logistic_acc)","ec2c32c2":"from sklearn.metrics import accuracy_score, confusion_matrix","2813514b":"print(\"Classification Report:\\n \", classification_report(y_test1, y_pre2))\nprint(\"Confusion Matrix:\\n \", confusion_matrix(y_test1, y_pre2))","178a0489":"y_pred11 = lr.predict_proba(X_test_tfidf)\n(fpr, tpr, thresholds) = roc_curve(y_test1,y_pred11[:,1],pos_label='1')\nroc_auc = auc(fpr,tpr)\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr,lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) \nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","32195f86":"svm = LinearSVC()\nsvm.fit(X_train_tfidf, y_train1)\ny_pred4 = svm.predict(X_test_tfidf)\n\nprint(\"Classification Report:\\n \", classification_report(y_test1, y_pred4))\nprint(\"Confusion Matrix:\\n \", confusion_matrix(y_test1, y_pred4))","213e9e01":"from sklearn.linear_model import Perceptron\nmodel5=Perceptron()\nmodel5.fit(X_train_tfidf, y_train1)\ny_pred5 = model5.predict(X_test_tfidf)\n\nprint(\"Classification Report:\\n \", classification_report(y_test1, y_pred5))\nprint(\"Confusion Matrix:\\n \", confusion_matrix(y_test1, y_pred5))","1431e1c5":"from sklearn.neural_network import MLPClassifier\nmodel7 = MLPClassifier(hidden_layer_sizes=(400,100),alpha=0.01,max_iter=1000) \nmodel7.fit(X_train_tfidf, y_train1) \ny_pred7 = model6.predict(X_test_tfidf)\n\nprint(\"Classification Report:\\n \", classification_report(y_test1, y_pred7))","8732a2e5":"from sklearn.ensemble import GradientBoostingClassifier\nmodel6= GradientBoostingClassifier(random_state=1)             \nmodel6.fit(X_train_tfidf, y_train1)           ","23d5929a":"y_pred6 = model6.predict(X_test_tfidf)\n\nprint(\"Classification Report:\\n \", classification_report(y_test1, y_pred6))\nprint(\"Confusion Matrix:\\n \", confusion_matrix(y_test1, y_pred6))","86c43be3":"y_pred11 = model6.predict_proba(X_test_tfidf)\n(fpr, tpr, thresholds) = roc_curve(y_test1,y_pred11[:,1],pos_label='1')\nroc_auc = auc(fpr,tpr)\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr,lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) \nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","46a33a9b":"%%time\nfrom sklearn.ensemble import AdaBoostClassifier\nimport sklearn.tree as st\nimport sklearn.ensemble as se\nmodel10=AdaBoostClassifier(n_estimators=150, random_state=0)\nmodel10.fit(X_train_tfidf, y_train1) \ny_pred10 = model10.predict(X_test_tfidf)\n\nprint(\"Classification Report:\\n \", classification_report(y_test1, y_pred10))\nprint(\"Confusion Matrix:\\n \", confusion_matrix(y_test1, y_pred10))","935ff864":"y_pred11 = model10.predict_proba(X_test_tfidf)\n(fpr, tpr, thresholds) = roc_curve(y_test1,y_pred11[:,1],pos_label='1')\nroc_auc = auc(fpr,tpr)\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr,lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) \nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","cab154e3":"from gensim import corpora, models\nfrom gensim.models.coherencemodel import CoherenceModel\nimport matplotlib.pyplot as plt","f8093839":"dictionary= Dictionary(comment_clean)  # fit dictionary\ndictionary\ncorpus = [dictionary.doc2bow(line) for line in comment_clean]  # convert corpus to BoW format","b6b0cd9b":"%%time\nfrom gensim import corpora, models\nfrom gensim.models.coherencemodel import CoherenceModel\nimport matplotlib.pyplot as plt\n\ndef compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3): #def2\n    coherence_values = []\n    model_list = []\n    for num_of_topics in range(start, stop, step):\n        # generate LDA model\n        print(num_of_topics)\n        model = gensim.models.ldamodel.LdaModel(doc_term_matrix, num_topics=num_of_topics, id2word = dictionary,random_state = 1)  # train model\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=text, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n    print(coherence_values)\n    return model_list, coherence_values\n\ndef plot_graph(doc_clean,start, stop, step): #def3\n    #dictionary\n    model_list, coherence_values = compute_coherence_values(dictionary,corpus,text,stop, start, step) #def2\n    # Show graph\n    x = range(start, stop, step)\n    plt.plot(x, coherence_values)\n    plt.xlabel(\"Number of Topics\")\n    plt.ylabel(\"Coherence score\")\n    plt.legend((\"coherence_values\"), loc='best')\n    plt.show()\n    \ntext = comment_clean\nstart,stop,step=1,6,1\nplot_graph(text,start,stop,step)\n#print()\n# We got 4 is the optimal number for the topic choosen.","4b99fd58":"plt.savefig('lda_best_topics.png')","4b582304":"nt = 4\nlda_model = gensim.models.ldamodel.LdaModel(corpus, num_topics=nt, id2word = dictionary, passes=2) \n\nprint(lda_model.print_topics(num_topics=nt, num_words=5))","49e9eb8d":"for idx, topic in lda_model.print_topics(-1):\n    print('Topic: {} \\nWords: {}'.format(idx, topic))","8480a574":"%%time\nfrom gensim.models import LsiModel\nfrom gensim import corpora, models\nfrom gensim.models.coherencemodel import CoherenceModel\nimport matplotlib.pyplot as plt\n\ndef compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3): #def2\n    coherence_values = []\n    model_list = []\n    for num_of_topics in range(start, stop, step):\n        # generate LSA model\n        print(num_of_topics)\n        model = LsiModel(doc_term_matrix, num_topics=num_of_topics, id2word = dictionary)  # train model\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=text, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n    print(coherence_values)\n    return model_list, coherence_values\n\ndef plot_graph(doc_clean,start, stop, step): #def3\n    #dictionary\n    model_list, coherence_values = compute_coherence_values(dictionary,corpus,text,stop, start, step) #def2\n    # Show graph\n    x = range(start, stop, step)\n    plt.plot(x, coherence_values)\n    plt.xlabel(\"Number of Topics\")\n    plt.ylabel(\"Coherence score\")\n    plt.legend((\"coherence_values\"), loc='best')\n    plt.show()\n    \ntext = comment_clean\nstart,stop,step=1,6,1\nplot_graph(text,start,stop,step)\n#print()\n# We got 3 is the optimal number for the topic choosen.","38a0a499":"nt = 3\nlsa_model = LsiModel(corpus, num_topics=nt, id2word = dictionary) \n\nprint(lsa_model.print_topics(num_topics=nt, num_words=10))","e570b0e6":"for idx, topic in lsa_model.print_topics(-1):\n    print('Topic: {} \\nWords: {}'.format(idx, topic))","d669bff7":"dataset = pd.read_csv(\"\u51b0\u96ea\u5947\u7f18 Frozen.txt\", sep='\\t', header=None)\ndataset","118287ca":"dataset[0]=((dataset[0]+0.5)\/3.5).astype(int)","7be64148":"def preprocess(sentence):\n    sentence=str(sentence)\n    #sentence = sentence.lower()\n    sentence=sentence.replace('{html}',\"\") \n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, '', sentence)\n    rem_url=re.sub(r'http\\S+', '',cleantext)\n    rem_num = re.sub('[0-9]+', '', rem_url)\n    tokenizer = RegexpTokenizer(r'\\w+')\n    tokens = tokenizer.tokenize(rem_num)  \n    #filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n    stem_words=[stemmer.stem(w) for w in tokens]\n    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n    return \" \".join(tokens)","aa183b6d":"comment_s1 = []\nfor line in dataset[1]:\n    comment_cut = jieba.lcut(line)\n    comment_s1.append(comment_cut)","822ed3b0":"comment_clean1 = []\nfor line in comment_s1:\n    line_clean = []\n    for word in line:\n        if word not in stopwords:\n            line_clean.append(word)\n    comment_clean1.append(line_clean)","9a9e5e67":"comment_clean_dist1 = []\nfor line in comment_clean1:   \n   line_dist = []\n   for word in line:\n      if word not in line_dist:\n         line_dist.append(word)\n   comment_clean_dist1.append(line_dist)","1b79d36f":"allwords_clean_dist1 = []\nfor line in comment_clean_dist1:\n   for word in line:\n      allwords_clean_dist1.append(word)","8d0c5707":"All_text1 = []\nfor line in comment_clean_dist1:\n    onetext = \" \".join(line)\n    All_text1.append(onetext)","9e45a570":"df_all_text1 = pd.DataFrame(All_text1, columns = ['Comment'])\ndf_all_text1","111fef31":"X_test_bxqy=df_all_text1.Comment\ny_test_bxqy=dataset[0]\n\ny_test_bxqy=y_test_bxqy.astype(\"str\")","d40d5727":"X_test_bxqy_counts = count_vect.transform(X_test_bxqy)\nX_test_bxqy_tfidf = tfidf_transformer.transform(X_test_bxqy_counts)","383d59be":"%%time\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train_tfidf, y_train1)\ny_predlr_bxqy = lr.predict(X_test_bxqy_tfidf)\n\nprint(\"Classification Report:\\n \", classification_report(y_test_bxqy, y_predlr_bxqy))\nprint(\"\\nConfusion Matrix:\\n\",metrics.confusion_matrix(y_test_bxqy, y_predlr_bxqy))","663b6cdf":"from sklearn.metrics import auc\nfrom sklearn.metrics import roc_curve","0b340aea":"y_pred11 = lr.predict_proba(X_test_bxqy_tfidf)\n(fpr, tpr, thresholds) = roc_curve(y_test_bxqy,y_pred11[:,1],pos_label='1')\nroc_auc = auc(fpr,tpr)\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr,lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) \nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","9e48943c":"X_train_scaled=X_train_tfidf\nX_test_scaled=X_test_bxqy_tfidf\ny_test=y_test_bxqy\ny_train=y_train1\n\nfrom sklearn.naive_bayes import BernoulliNB\nmodel17 = BernoulliNB()\nmodel17.fit(X_train_scaled, y_train)\ny_pred17 = model17.predict(X_test_scaled)\n\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred17))\nprint(\"\\nConfusion Matrix:\\n\",metrics.confusion_matrix(y_test, y_pred17))","445fd2d7":"y_pred11 = model17.predict_proba(X_test_bxqy_tfidf)\n(fpr, tpr, thresholds) = roc_curve(y_test_bxqy,y_pred11[:,1],pos_label='1')\nroc_auc = auc(fpr,tpr)\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr,lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) \nplt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.show()","0fa5d04c":"### AdaBoost","c68c6c48":"### LDA-choose the topic number\nWe first choose the optimal topic number.","87cf551c":"## 2.Using ti-idfs as independent variables to predict the sentiment","9d843285":"* # Douban movie reviews analysis\n","0bc1b93f":"### MLP Classifier","91cdcfa1":"## 3.Build the LSA and LDA topic models for the reviews","3f890f32":"### Logistic Regression","31825b3d":"### GradientBoost","07aa5f4d":"We have added some steps about data preprocessing to make the data cleaner and better processed. We deleted the duplicated comments and made a moive stop-word list.","59effe4b":"### Multinomial NB","1a0beeb8":"### Linear SVM","a6190753":"### LSA-choose the topic number","2e10bcbe":"We use two models LDA and LSA to handle the review documents. For each model, we use the corpus after applying tf-idf and dictionary to fit the model and get several topics. Secondly, we use coherence values to find the optimal topic number.Coherence value help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. So we use that with highest score to decide the number of topic. Then, we print the topics and the score of each topic for the reviews.","2c0472a6":"### LSA-build the model","ca69b960":"## 4.Now, let's use a new film 'Frozen' to test our model!","32c93f80":"### LDA-build the model","5724a4cc":"### Perception","8f337aea":"## 1.Pre-processing","2a6d7fea":"We first tried to build lda and lsa topic models to make prediction(the same as project 3 method), but the result is not ideal. No mather we used either model, the probability of prediction is around the random guess's probability. Therefore, we move our direction to using ti-idfs as dependent variables to build our model after refering to other nlp sentiment prediction projects. We uses several classification models, then print out their classification report and draw ROC plot. We choose the best model according to both the f1-score and AUC score."}}