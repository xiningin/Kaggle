{"cell_type":{"c5ee3bdd":"code","b5801184":"code","b257e6af":"code","c0f1f371":"code","1e9ba1e0":"code","833053b1":"code","9a6de935":"code","48fd244a":"code","a02c36af":"code","b51ea999":"code","21a63d39":"code","c69befdd":"code","ca683dbb":"code","96a6cc57":"code","8885d5d1":"code","bfb5e54e":"markdown","b2f4f2e8":"markdown"},"source":{"c5ee3bdd":"! pip install scikit-learn --upgrade --force-reinstall","b5801184":"! pip install --no-deps autoxgb","b257e6af":"# import gresearch_crypto\nfrom autoxgb import AutoXGB\n\n\n\n\n# required parameters:\ntrain_filename = \"..\/input\/data-for-autoxgb\/train1.csv\"\noutput = \"output1\"\n\n# optional parameters\ntest_filename = \"..\/input\/data-for-autoxgb\/test.csv\"\ntask = 'regression'\nidx = None\ntargets = [\"y\"]\nfeatures = None\ncategorical_features = None\nuse_gpu = True\nnum_folds = 5\nseed = 42\nnum_trials = 100\ntime_limit = 360 # do mentation a time limit other wise it keeps on running\nfast = False\n\n# Now its time to train the model!\naxgb = AutoXGB(\n    train_filename=train_filename,\n    output=output,\n    test_filename=test_filename,\n    task=task,\n    idx=idx,\n    targets=targets,\n#     features=features,\n#     categorical_features=categorical_features,\n    use_gpu=use_gpu,\n    num_folds=num_folds,\n    seed=seed,\n    num_trials=num_trials,\n    time_limit=time_limit,\n    fast=fast,\n)\naxgb.train()","c0f1f371":"import pandas as pd\ntest_pred = pd.read_csv(\".\/output1\/test_predictions.csv\")\nprint(test_pred.shape)\ntest_pred.head()","1e9ba1e0":"actual_y = pd.read_csv(\"..\/input\/data-for-autoxgb\/y_test_split.csv\")\nactual_y.head()","833053b1":"real_test = pd.read_csv(\"..\/input\/data-for-autoxgb\/gresearch_crypto_test.csv\")\nreal_test.shape","9a6de935":"real_test.iloc[[0]]","48fd244a":"test = pd.read_csv(\"..\/input\/data-for-autoxgb\/test.csv\")\n\n# for i in range(test.shape[0]): \n#     if test.iloc[[i]] == real_test.iloc[[i]]:\n        \n# #     df.shape\n\n# test.iloc[[4294617,4294631]].head()\ntest[4294617:4294631]\n# test.shape","a02c36af":"real_test.head()","b51ea999":"test_pred[4294617:4294631]","21a63d39":"sample_df = pd.read_csv(\"..\/input\/data-for-autoxgb\/gresearch_crypto_sample.csv\")\n# sample_df[\"Target\"] = test_pred[4294617:4294631][\"y\"]\nsample_df.head()","c69befdd":"# # sample_df[\"Target\"] = test_pred[4294617:4294631][\"y\"]\n# temp1 = test_pred[4294617:4294631][\"y\"]\n# for i in range(len(temp1)):\n\nsample_df.Target = test_pred[4294617:4294631][\"y\"].values\nsample_df = sample_df.drop([\"Unnamed: 0\"],axis=1)\nsample_df.head()","ca683dbb":"sample_df.to_csv(\"submission.csv\")","96a6cc57":"# out of folde predictions\noof = pd.read_csv(\".\/output1\/oof_predictions.csv\")\noof.head()","8885d5d1":"import numpy as np\ny = actual_y[\"y\"]\ny_pred = test_pred[0:4294617][\"y\"]\n\ndiff = y - y_pred\nmae = np.mean(abs(diff))\nmse = np.mean(diff**2)\nrmse = np.sqrt(mse)\nr_2 = 1 - (sum(diff**2)\/ sum((y - np.mean(y))**2))\n\nprint(\"Results by manual calculation:\")\nprint(\"MAE:\",mae)\nprint(\"MSE:\", mse)\nprint(\"RMSE:\", rmse)\nprint(\"R-Squared:\", r_2)","bfb5e54e":"# About the NB:\nThis is the nb where I try different autoML libraries for this competition. Here, specially I tried the autoML library called **autoXGB** by Abhishek Thakur which recently got published and currently having ~300 stars on github. I have seen some notebook from him, doing some playground kaggle competition with this library. So, I though why not use it in a real kaggle competition, and check how it performs. \n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">\ud83d\ude80AutoXGB preview: <a href=\"https:\/\/t.co\/UH6pKGYTYy\">https:\/\/t.co\/UH6pKGYTYy<\/a><br>(Release hopefully this weekend!)<br>\ud83d\udc49\ud83d\udc49Tasks supported:<br>\u2705 binary classification<br>\u2705 multi-class classification<br>\u2705 single column regression<br>\u2705 multi-column regression<br>\u2705 multi-label classification<br>\ud83d\udcbb GitHub Repo: <a href=\"https:\/\/t.co\/Ro6sqQm2Xl\">https:\/\/t.co\/Ro6sqQm2Xl<\/a><\/p>&mdash; abhishek (@abhi1thakur) <a href=\"https:\/\/twitter.com\/abhi1thakur\/status\/1454483069310808068?ref_src=twsrc%5Etfw\">October 30, 2021<\/a><\/blockquote> <script async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script>\n\n\nTraditional machine learning model development is resource-intensive, requiring significant domain knowledge and time to produce and compare dozens of models. With automated machine learning, you'll accelerate the time it takes to get production-ready ML models with great ease and efficiency. \n\n\n## Features of the library:\n- auto train xgboost directly from CSV files\n- auto tune xgboost using optuna\n- to serve best xgboot model using fastapi\n\n## First impression about this\nLet's unbox shall we,\n\n- Its a low-code library, even the internal code, which makes it a light weight library and easy to use.\n- I like the fact that it only takes the train cv file as a input, you dont even read and split the data for training.\n- I have seen many of his videos, and I think he loves using CLI tools a lot. And you can see the potrail of that love in this library too. It has a CLI feature, using which you can train your **autoXGB** model.\n\n```python\nautoxgb train \\\n --train_filename datasets\/30train.csv \\\n --output outputs\/30days \\\n --test_filename datasets\/30test.csv \\\n --use_gpu\n```\nCheck out more about the cli commands [here](https:\/\/github.com\/abhishekkrthakur\/autoxgb#cli).\n\n- I think people can learn a lot from the library internals. I used to think that the code would be very complecated to implement, but seeing this light weight library makes me think that making one is not much complicated, if someone wants to.\n\n- The **autoXGB** model has some parameters based on which the model gets trained, some of them are num_folds, num_trials, time_limit, fast. having cross validation is a plus point. \n\n- I feel that its a great library, but obviously its not there yet compared to other autoML libraries. He is already working on autoNLP, so making a small side project like this one of the ways of showing love for his followers. If things go right then we might see some other ml models being automated in the library(as a feature).\n\n## What has been covered in this NB:\n\n<p align=\"center\">\n<img width = \"300\" src=\"https:\/\/i.imgur.com\/QJeo1SA.jpg\">\n<\/p>\n\n\n- This NB covers model trining using autoXGB\n- I tried to show the regression metrics for the model\n- created the submission file\n\n\n <font size=\"6\"\n          face=\"verdana\"\n          color=\"green\">\n            Please upvote the NB if you find it interesting.\n        <\/font>","b2f4f2e8":"## "}}