{"cell_type":{"54ef974e":"code","fc7af718":"code","4faefc0e":"code","22592d67":"code","da53536c":"code","50ba9ba1":"code","fd01ae5a":"code","c69c0271":"code","00d9c872":"code","43fd09cd":"code","e5d34b23":"code","ea59687f":"code","7a4d70d0":"code","418e9a62":"code","6e157a2e":"code","890a5513":"code","9c7b6920":"markdown","6a317384":"markdown","ef064bd3":"markdown","c7479311":"markdown","a9bc3206":"markdown","6c09a168":"markdown","a5c07de1":"markdown","39ee0061":"markdown","64c56c19":"markdown","f626ec06":"markdown","93f3ae31":"markdown","283c46a8":"markdown","263be65c":"markdown","055293aa":"markdown"},"source":{"54ef974e":"# Imports\nimport numpy as np\nimport pandas as pd\nfrom subprocess import check_output\nimport matplotlib.pyplot as plt\n%matplotlib inline\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","fc7af718":"data = pd.read_csv('..\/input\/better-donald-trump-tweets\/Donald-Tweets!.csv')","4faefc0e":"print('Rows', data.shape[0])\nprint('Colummns', data.shape[1])\ndata.head()","22592d67":"text = '\\n\\n'.join(data['Tweet_Text'].values)","da53536c":"from collections import Counter\nimport re","50ba9ba1":"cntr = Counter(text)\nrare = list(np.asarray(list(cntr.keys()))[np.asarray(list(cntr.values())) < 300])\nfor c in rare:\n    text = re.sub('[' + c + ']', '', text)","fd01ae5a":"text[:1000]","c69c0271":"print('Total de Caracteres no Corpus:', len(text))\nchars = sorted(list(set(text)))\nprint('Total de Caracteres \u00danicos:', len(chars))\nchar_indices = dict((c, i) for i, c in enumerate(chars))\nindices_char = dict((i, c) for i, c in enumerate(chars))","00d9c872":"maxlen = 50\nstep = 3\nsentences = []\nnext_chars = []\nfor i in range(0, len(text) - maxlen, step):\n    sentences.append(text[i: i + maxlen])\n    next_chars.append(text[i + maxlen])\nprint('N\u00famero de Sequ\u00eancias:', len(sentences))","43fd09cd":"X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\ny = np.zeros((len(sentences), len(chars)), dtype=np.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        X[i, t, char_indices[char]] = 1\n    y[i, char_indices[next_chars[i]]] = 1","e5d34b23":"import random\nimport sys\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers import LSTM\nfrom keras.optimizers import RMSprop","ea59687f":"cntr = Counter(text)\ncntr_sum = sum(cntr.values())\nchar_probs = list(map(lambda c: cntr[c] \/ cntr_sum, chars))","7a4d70d0":"def sample(preds):\n    preds = np.asarray(preds).astype('float64')\n    preds = preds \/ np.sum(preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)","418e9a62":"def generate(model, length, seed=''):\n    \n    if len(seed) != 0:\n        sys.stdout.write(seed)\n    \n    generated = seed\n    sentence = seed\n    \n    for i in range(length):\n        x = np.zeros((1, maxlen, len(chars)))\n\n        padding = maxlen - len(sentence)\n        \n        for i in range(padding):\n            x[0, i] = char_probs # pad usando os anteriores\n            \n        for t, char in enumerate(sentence):\n            x[0, padding + t, char_indices[char]] = 1.\n\n        preds = model.predict(x, verbose=0)[0]\n        next_index = sample(preds)\n        next_char = indices_char[next_index]\n\n        sentence = sentence[1:] + next_char\n        generated += next_char\n        \n        sys.stdout.write(next_char)\n        sys.stdout.flush()\n        \n    return generated","6e157a2e":"from os.path import isfile\nfrom keras.models import load_model\n\nMODEL_PATH = '..\/input\/weights\/stacked-lstm-2-layers-128-hidden.h5'\n\nif isfile(MODEL_PATH):\n    model = load_model(MODEL_PATH)\nelse:\n    N_HIDDEN = 128\n\n    # Modelo\n    model = Sequential()\n    model.add(LSTM(N_HIDDEN, dropout = 0.1, input_shape = (maxlen, len(chars)), return_sequences = True))\n    model.add(LSTM(N_HIDDEN, dropout = 0.1))\n    model.add(Dense(len(chars), activation = 'softmax'))\n\n    # Otimizador\n    optimizer = RMSprop(lr = 0.01)\n    \n    # Compila\u00e7\u00e3o\n    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n\n    # Imprime amostras a cada \u00e9poca\n    for iteration in range(1, 40):\n        print('\\n')\n        print('-' * 4)\n        print('\\nItera\u00e7\u00e3o', iteration)\n        model.fit(X, y, batch_size=3000, epochs=1)\n\n        print('\\n-------------------- Tweet Gerado Pelo Modelo Nesta Itera\u00e7\u00e3o ---------------------\\n')\n\n        rand = np.random.randint(len(text) - maxlen)\n        seed = text[rand:rand + maxlen]\n        generate(model, 400, seed)\n\n    #model.save(MODEL_PATH)","890a5513":"sample_tweet_start = 'Go Republican Senators, Go!'\n_ = generate(model, 250, sample_tweet_start)","9c7b6920":"\nThe corpus has 857177 characters and there are 78 unique characters inside it:","6a317384":"A regular expression is a special sequence of characters that helps you match or find other strings or sets of strings, using a specialized syntax held in a pattern. Regular expressions are widely used in UNIX world.\nThe module re provides full support for Perl-like regular expressions in Python. The re module raises the exception re.error if an error occurs while compiling or using a regular expression.\nWe would cover two important functions, which would be used to handle regular expressions. But a small thing first: There are various characters, which would have special meaning when they are used in regular expression. ","ef064bd3":"### 2. Generative Model","c7479311":"### So, let's vectorize the sentences:","a9bc3206":"## Imagine the possibility of predicting what the President of the United States, Mr. Trump will say .... Okay, I do not expect much good thing .... lol ..\n## But at least we can practice PLN art in LSTM","6c09a168":"Let's create some reusable functions that can generate text for our generative model.","a5c07de1":"### To reduce the size of our feature space and training time, we've removed rare characters:","39ee0061":"\n#### Now let's cut the text into semi-redundant sequences of * maxlen * characters so that it can be fed into an LSTM template:","64c56c19":"### Now let's try the model!\n## Using the first sentence of this tweet as seed, we will try to continue the sentence of Trump and see what interesting things our model can say:","f626ec06":"\n#### We will use US President Tweets, Donald Trump, to train a 2-layer LSTM model and then teach the model to generate tweets ","93f3ae31":"### Now, let's build the graph of our neural network. Then we will train our model and display some samples at all times. At the end of the training, we save the template so that we can reuse it quickly in the future.","283c46a8":"## All we need is the field ** Tweet_Text **. \nLet's combine all the lines to create a text corpus, concatenating tweets, but separating them with two new lines:","263be65c":"#### Here is how the beginning of the corpus looks ... \n### So it is very difficult for humans to read, is not it?","055293aa":"\n###  Feature Engineering\n* Raw text data can not be provided directly in the LSTM model. \n* We must engineer the attributes first before we can move on to the modeling step."}}