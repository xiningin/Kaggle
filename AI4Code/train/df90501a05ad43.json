{"cell_type":{"81944fa5":"code","a9decaee":"code","8acd61fc":"code","1e1b343f":"code","8b9df34e":"code","6d37dc48":"code","83a83c1e":"code","d82473d3":"code","40aac7e7":"code","b82a0b21":"code","0ed5bde9":"code","c8b55af0":"code","23db7b76":"markdown","907d502e":"markdown","7c440b9b":"markdown","8e98a29b":"markdown","440af3dc":"markdown","46c6e8d2":"markdown","b5870bd2":"markdown","fa5effde":"markdown","087036e8":"markdown","ef1995c5":"markdown","693e7cb9":"markdown","baf01607":"markdown","21a523c0":"markdown","82e4c244":"markdown"},"source":{"81944fa5":"import pandas as pd\nimport numpy as np\nimport warnings\nimport matplotlib.pyplot as plt\n\nwarnings.simplefilter('ignore')\n\n# Common code for display result\ndef show_graph(df1,df2,title):\n    data = pd.concat([df1, df2])\n    data.reset_index(inplace=True, drop=True)\n    for col in data.columns:\n        if col.lower().startswith('pred'):\n            data[col].plot(label=col,linestyle=\"dotted\")\n        else:\n            data[col].plot(label=col)\n    plt.title(title)\n    plt.legend()\n    plt.show()","a9decaee":"from statsmodels.tsa.ar_model import AutoReg\nfrom random import random\n\ndef AR_model(train,test):\n    # fit model\n    model = AutoReg(train['Act'], lags=1)\n    model_fit = model.fit()\n    # make prediction\n    yhat=model_fit.predict(len(train), len(train) + len(test) - 1)\n    res=pd.DataFrame({\"Pred\":yhat, \"Act\":test[\"Act\"].values})\n    return res\n \ndf_train = pd.DataFrame([x + random()*10 for x in range(1, 100)],\n                     columns=['Act'])\ndf_test = pd.DataFrame([x + random()*10 for x in range(101, 200)],\n                     columns=['Act'])\ndf_ret = AR_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Autoregression (AR)\")","8acd61fc":"from statsmodels.tsa.arima_model import ARMA\nfrom random import random\n\ndef MA_model(train,test):\n    # fit model\n    model = ARMA(train['Act'], order=(0, 1))\n    model_fit = model.fit(disp=False)\n    # make prediction\n    yhat = model_fit.predict(len(train), len(train) + len(test) - 1)\n    res=pd.DataFrame({\"Pred\":yhat, \"Act\":test[\"Act\"].values})\n    return res\n \ndf_train = pd.DataFrame([x + random()*10 for x in range(0, 100)],\n                     columns=['Act'])\ndf_test = pd.DataFrame([x + random()*10 for x in range(101, 201)],\n                     columns=['Act'])\ndf_ret = MA_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Moving Average (MA)\")","1e1b343f":"from statsmodels.tsa.arima_model import ARMA\nfrom random import random\n\ndef ARMA_model(train,test):\n    # fit model\n    model = ARMA(train['Act'], order=(1,2))\n    model_fit = model.fit(disp=False)\n    # make prediction\n    yhat = model_fit.predict(len(train), len(train) + len(test) - 1)\n    res=pd.DataFrame({\"Pred\":yhat, \"Act\":test[\"Act\"].values})\n    return res\n \ndf_train = pd.DataFrame([x + random()*10 for x in range(0, 100)],\n                     columns=['Act'])\ndf_test = pd.DataFrame([x + random()*10 for x in range(101, 201)],\n                     columns=['Act'])\ndf_ret = ARMA_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Autoregressive Moving Average (ARMA)\")","8b9df34e":"from statsmodels.tsa.arima_model import ARIMA\nfrom random import random\n\ndef ARIMA_model(train,test):\n    # fit model\n    model = ARIMA(train['Act'], order=(1, 1, 1))\n    model_fit = model.fit(disp=False)\n    # make prediction\n    yhat = model_fit.predict(len(train), len(train) + len(test) - 1, typ='levels')\n    res=pd.DataFrame({\"Pred\":yhat, \"Act\":test[\"Act\"].values})\n    return res\n \ndf_train = pd.DataFrame([x + random()*10 for x in range(0, 100)],\n                     columns=['Act'])\ndf_test = pd.DataFrame([x + random()*10 for x in range(101, 201)],\n                     columns=['Act'])\ndf_ret = ARIMA_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Autoregressive Integrated Moving Average (ARIMA)\")","6d37dc48":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom random import random\n\ndef SARIMA_model(train,test):\n    # fit model\n    model = SARIMAX(train['Act'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 2))\n    model_fit = model.fit(disp=False)\n    # make prediction\n    yhat = model_fit.predict(len(train), len(train) + len(test) - 1)\n    res=pd.DataFrame({\"Pred\":yhat, \"Act\":test[\"Act\"].values})\n    return res\n \ndf_train = pd.DataFrame([x + random()*10 for x in range(0, 100)],\n                     columns=['Act'])\ndf_test = pd.DataFrame([x + random()*10 for x in range(101, 201)],\n                     columns=['Act'])\ndf_ret = SARIMA_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Seasonal Autoregressive Integrated Moving-Average (SARIMA)\")","83a83c1e":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom random import random\n\ndef SARIMAX_model(train,test):\n    # fit model\n    model = SARIMAX(train.drop('Exog', axis=1), exog=train['Exog'], order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n    model_fit = model.fit(disp=False)\n    # make prediction\n    yhat = model_fit.predict(len(train), len(train) + len(test) - 1, exog=test[\"Exog\"].values)\n    res=pd.DataFrame({\"Pred\":yhat, \"Act\":test[\"Act\"].values,\"Exog\":test[\"Exog\"].values})\n    return res\n\ndf_train = pd.DataFrame({'Act':[x + random()*10 for x in range(0, 100)],\n                         'Exog':[x + random()*10 for x in range(101, 201)]})\ndf_test = pd.DataFrame({'Act':[x + random()*10 for x in range(101, 201)],\n                         'Exog':[200 + random()*10 for x in range(201, 301)]})\ndf_ret = SARIMAX_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Seasonal Autoregressive Integrated Moving-Average with Exogenous Regressors (SARIMAX)\")","d82473d3":"from statsmodels.tsa.vector_ar.var_model import VAR\nfrom random import random\n\ndef VAR_model(train,test):\n    # fit model\n    model = VAR(train)\n    model_fit = model.fit()\n    # make prediction\n    yhat = model_fit.forecast(model_fit.y, steps=len(test))\n    res=pd.DataFrame({\"Pred1\":[x[0] for x in yhat], \"Pred2\":[x[1] for x in yhat], \n                      \"Act1\":test[\"Act1\"].values, \"Act2\":test[\"Act2\"].values})\n    return res\n\ndf_train = pd.DataFrame({'Act1':[x + random()*10 for x in range(0, 100)],\n                         'Act2':50+np.sin(np.linspace(0, 2*np.pi, 100))*50})\ndf_test = pd.DataFrame({'Act1':[x + random()*10 for x in range(101, 201)],\n                         'Act2':50+np.sin(np.linspace(0, 2*np.pi, 100))*50})\ndf_ret = VAR_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Vector Autoregression (VAR)\")","40aac7e7":"from statsmodels.tsa.statespace.varmax import VARMAX\nfrom random import random\n\ndef VARMA_model(train,test):\n    # fit model\n    model = VARMAX(train, order=(1, 2))\n    model_fit = model.fit(disp=False)\n    # make prediction\n    yhat = model_fit.forecast(steps=len(test))\n    res=pd.DataFrame({\"Pred1\":yhat['Act1'], \"Pred2\":yhat['Act2'], \n                      \"Act1\":test[\"Act1\"].values, \"Act2\":test[\"Act2\"].values})\n    return res\n\ndf_train = pd.DataFrame({'Act1':[x + random()*10 for x in range(0, 100)],\n                         'Act2':50+np.sin(np.linspace(0, 2*np.pi, 100))*50})\ndf_test = pd.DataFrame({'Act1':[x + random()*10 for x in range(101, 201)],\n                         'Act2':50+np.sin(np.linspace(0, 2*np.pi, 100))*50})\ndf_ret = VARMA_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Vector Autoregression Moving-Average (VARMA)\")","b82a0b21":"from statsmodels.tsa.statespace.varmax import VARMAX\nfrom random import random\n\ndef VARMAX_model(train,test):\n    # fit model\n    model = VARMAX(train.drop('Exog', axis=1), exog=train['Exog'], order=(1, 1))\n    model_fit = model.fit(disp=False)\n    # make prediction\n    yhat = model_fit.forecast(steps=len(test),exog=test['Exog'])\n    res=pd.DataFrame({\"Pred1\":yhat['Act1'], \"Pred2\":yhat['Act2'], \n            \"Act1\":test[\"Act1\"].values, \"Act2\":test[\"Act2\"].values, \"Exog\":test[\"Exog\"].values})\n    return res\n\ndf_train = pd.DataFrame({'Act1':[x + random()*10 for x in range(0, 100)],\n                         'Act2':[x*3 + random()*10 for x in range(0, 100)],\n                         'Exog':50+np.sin(np.linspace(0, 2*np.pi, 100))*50})\ndf_test = pd.DataFrame({'Act1':[x + random()*10 for x in range(101, 201)],\n                         'Act2':[x*3 + random()*10 for x in range(101, 201)],\n                         'Exog':50+np.sin(np.linspace(0, 2*np.pi, 100))*50})\ndf_ret = VARMAX_model(df_train, df_test)\nshow_graph(df_train, df_ret,\"Vector Autoregression Moving-Average with Exogenous Regressors (VARMAX)\")","0ed5bde9":"from statsmodels.tsa.holtwinters import SimpleExpSmoothing\nfrom random import random\n\ndef SES_model(train,test):\n    # fit model\n    model = SimpleExpSmoothing(train['Act'])\n    model_fit = model.fit()\n    # make prediction\n    yhat=model_fit.predict(len(train), len(train) + len(test) - 1)\n    res=pd.DataFrame({\"Pred\":yhat, \"Act\":test[\"Act\"].values})\n    return res\n \ndf_train = pd.DataFrame([x + random()*10 for x in range(0, 100)],\n                     columns=['Act'])\ndf_test = pd.DataFrame([x + random()*10 for x in range(101, 201)],\n                     columns=['Act'])\ndf_ret = SES_model(df_train, df_test)\nshow_graph(df_train, df_ret,\"Simple Exponential Smoothing (SES)\")","c8b55af0":"from statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom random import random\n\ndef HWES_model(train,test):\n    # fit model\n    model = ExponentialSmoothing(train['Act'])\n    model_fit = model.fit()\n    # make prediction\n    yhat=model_fit.predict(len(train), len(train) + len(test) - 1)\n    res=pd.DataFrame({\"Pred\":yhat, \"Act\":test[\"Act\"].values})\n    return res\n \ndf_train = pd.DataFrame([x + random()*10 for x in range(0, 100)],\n                     columns=['Act'])\ndf_test = pd.DataFrame([x + random()*10 for x in range(101, 201)],\n                     columns=['Act'])\ndf_ret = HWES_model(df_train, df_test)\nshow_graph(df_train, df_ret, \"Holt Winter\u2019s Exponential Smoothing (HWES)\")","23db7b76":"# Code Example & Description","907d502e":"## 10. Simple Exponential Smoothing (SES)\nThe Simple Exponential Smoothing (SES) method models the next time step as an exponentially weighted linear function of observations at prior time steps.<br>\n\nThe method is suitable for univariate time series without trend and seasonal components.<br>","7c440b9b":"## Reference\nThis section provides more resources on the topic if you are looking to go deeper.\n\nStatsmodels: Time Series analysis API<br>\nhttp:\/\/www.statsmodels.org\/dev\/tsa.html\n\nStatsmodels: Time Series Analysis by State Space Methods<br>\nhttp:\/\/www.statsmodels.org\/dev\/statespace.html\n\nI write this notebook referencing this cheat sheet<br>\nhttps:\/\/machinelearningmastery.com\/time-series-forecasting-methods-in-python-cheat-sheet\/\n\nThank you.","8e98a29b":"## 11. Holt Winter\u2019s Exponential Smoothing (HWES)\nThe Holt Winter\u2019s Exponential Smoothing (HWES) also called the Triple Exponential Smoothing method models the next time step as an exponentially weighted linear function of observations at prior time steps, taking trends and seasonality into account.<br>\n\nThe method is suitable for univariate time series with trend and\/or seasonal components.<br>","440af3dc":"## 4. Autoregressive Integrated Moving Average (ARIMA)\nThe Autoregressive Integrated Moving Average (ARIMA) method models the next step in the sequence as a linear function of the differenced observations and residual errors at prior time steps.<br>\n\nIt combines both Autoregression (AR) and Moving Average (MA) models as well as a differencing pre-processing step of the sequence to make the sequence stationary, called integration (I).<br>\n\nThe notation for the model involves specifying the order for the AR(p), I(d), and MA(q) models as parameters to an ARIMA function, e.g. ARIMA(p, d, q). An ARIMA model can also be used to develop AR, MA, and ARMA models.<br>\n\nThe method is suitable for univariate time series with trend and without seasonal components.<br>","46c6e8d2":"# Classical Time Series Forecasting Methods in Python\n\nMachine learning methods can be used for classification and forecasting on time series problems.\n\nBefore exploring machine learning methods for time series, it is a good idea to ensure you have exhausted classical linear time series forecasting methods. Classical time series forecasting methods may be focused on linear relationships, nevertheless, they are sophisticated and perform well on a wide range of problems, assuming that your data is suitably prepared and the method is well configured.\n\n## Overview\nThis notebook demonstrates 11 different classical time series forecasting methods; they are:\n\n    1. Autoregression (AR)\n    2. Moving Average (MA)\n    3. Autoregressive Moving Average (ARMA)\n    4. Autoregressive Integrated Moving Average (ARIMA)\n    5. Seasonal Autoregressive Integrated Moving-Average (SARIMA)\n    6. Seasonal Autoregressive Integrated Moving-Average with Exogenous Regressors (SARIMAX)\n    7. Vector Autoregression (VAR)\n    8. Vector Autoregression Moving-Average (VARMA)\n    9. Vector Autoregression Moving-Average with Exogenous Regressors (VARMAX)\n    10. Simple Exponential Smoothing (SES)\n    11. Holt Winter\u2019s Exponential Smoothing (HWES)\n\nEach code example is demonstrated on a simple contrived dataset that may or may not be appropriate for the method. Replace the contrived dataset with your data in order to test the method.\n\nEach method will require tuning to your specific problem. In many cases, I have examples of how to configure and even grid search parameters on the blog already, try the search function.","b5870bd2":"## 2. Moving Average (MA)\nThe moving average (MA) method models the next step in the sequence as a linear function of the residual errors from a mean process at prior time steps.<br>\n\nA moving average model is different from calculating the moving average of the time series.<br>\n\nThe notation for the model involves specifying the order of the model q as a parameter to the MA function, e.g. MA(q). For example, MA(1) is a first-order moving average model.<br>\n\nThe method is suitable for univariate time series without trend and seasonal components.<br>","fa5effde":"## 3. Autoregressive Moving Average (ARMA)\nThe Autoregressive Moving Average (ARMA) method models the next step in the sequence as a linear function of the observations and resiudal errors at prior time steps.<br>\n\nIt combines both Autoregression (AR) and Moving Average (MA) models.<br>\n\nThe notation for the model involves specifying the order for the AR(p) and MA(q) models as parameters to an ARMA function, e.g. ARMA(p, q). An ARIMA model can be used to develop AR or MA models.<br>\n\nThe method is suitable for univariate time series without trend and seasonal components.<br>","087036e8":"## 5. Seasonal Autoregressive Integrated Moving-Average (SARIMA)\nThe Seasonal Autoregressive Integrated Moving Average (SARIMA) method models the next step in the sequence as a linear function of the differenced observations, errors, differenced seasonal observations, and seasonal errors at prior time steps.<br>\n\nIt combines the ARIMA model with the ability to perform the same autoregression, differencing, and moving average modeling at the seasonal level.<br>\n\nThe notation for the model involves specifying the order for the AR(p), I(d), and MA(q) models as parameters to an ARIMA function and AR(P), I(D), MA(Q) and m parameters at the seasonal level, e.g. SARIMA(p, d, q)(P, D, Q)m where \u201cm\u201d is the number of time steps in each season (the seasonal period). A SARIMA model can be used to develop AR, MA, ARMA and ARIMA models.<br>\n\nThe method is suitable for univariate time series with trend and\/or seasonal components.<br>","ef1995c5":"## 9. Vector Autoregression Moving-Average with Exogenous Regressors (VARMAX)\nThe Vector Autoregression Moving-Average with Exogenous Regressors (VARMAX) is an extension of the VARMA model that also includes the modeling of exogenous variables. It is a multivariate version of the ARMAX method.<br>\n\nExogenous variables are also called covariates and can be thought of as parallel input sequences that have observations at the same time steps as the original series. The primary series(es) are referred to as endogenous data to contrast it from the exogenous sequence(s). The observations for exogenous variables are included in the model directly at each time step and are not modeled in the same way as the primary endogenous sequence (e.g. as an AR, MA, etc. process).<br>\n\nThe VARMAX method can also be used to model the subsumed models with exogenous variables, such as VARX and VMAX.<br>\n\nThe method is suitable for multivariate time series without trend and seasonal components with exogenous variables.<br>","693e7cb9":"## 1. Autoregression (AR)\nThe autoregression (AR) method models the next step in the sequence as a linear function of the observations at prior time steps.<br>\n\nThe notation for the model involves specifying the order of the model p as a parameter to the AR function, e.g. AR(p). For example, AR(1) is a first-order autoregression model.<br>\n\nThe method is suitable for univariate time series without trend and seasonal components.<br>","baf01607":"## 6. Seasonal Autoregressive Integrated Moving-Average with Exogenous Regressors (SARIMAX)\nThe Seasonal Autoregressive Integrated Moving-Average with Exogenous Regressors (SARIMAX) is an extension of the SARIMA model that also includes the modeling of exogenous variables.<br>\n\nExogenous variables are also called covariates and can be thought of as parallel input sequences that have observations at the same time steps as the original series. The primary series may be referred to as endogenous data to contrast it from the exogenous sequence(s). The observations for exogenous variables are included in the model directly at each time step and are not modeled in the same way as the primary endogenous sequence (e.g. as an AR, MA, etc. process).<br>\n\nThe SARIMAX method can also be used to model the subsumed models with exogenous variables, such as ARX, MAX, ARMAX, and ARIMAX.<br>\n\nThe method is suitable for univariate time series with trend and\/or seasonal components and exogenous variables.<br>","21a523c0":"## 7. Vector Autoregression (VAR)\nThe Vector Autoregression (VAR) method models the next step in each time series using an AR model. It is the generalization of AR to multiple parallel time series, e.g. multivariate time series.<br>\n\nThe notation for the model involves specifying the order for the AR(p) model as parameters to a VAR function, e.g. VAR(p).<br>\n\nThe method is suitable for multivariate time series without trend and seasonal components.<br>","82e4c244":"## 8. Vector Autoregression Moving-Average (VARMA)\nThe Vector Autoregression Moving-Average (VARMA) method models the next step in each time series using an ARMA model. It is the generalization of ARMA to multiple parallel time series, e.g. multivariate time series.<br>\n\nThe notation for the model involves specifying the order for the AR(p) and MA(q) models as parameters to a VARMA function, e.g. VARMA(p, q). A VARMA model can also be used to develop VAR or VMA models.<br>\n\nThe method is suitable for multivariate time series without trend and seasonal components.<br>"}}