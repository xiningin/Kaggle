{"cell_type":{"afacdd2d":"code","5d34eb44":"code","5047762f":"code","a9458be2":"code","87a32ba3":"code","fec226d5":"code","9458b5fe":"code","f0512707":"code","6fb11150":"code","cf47af8d":"code","db6b2b4c":"code","b1f8eda1":"code","00c38517":"code","3a5ee716":"code","4280e8e9":"code","9362869f":"code","090147e6":"code","f12e8e9a":"code","8d8d17ea":"code","0806003e":"code","6143a333":"code","9d9c6384":"code","6ec7392c":"code","e2bf11d1":"code","0b3b6646":"code","fe8e8beb":"code","cc827dae":"code","733b35d5":"code","05419c24":"code","85ef1d36":"code","21aae468":"code","316edc3e":"code","913a8fdc":"code","7450415c":"markdown","a1043c5b":"markdown","58353c07":"markdown","e3a4a907":"markdown","220994cb":"markdown","2b7093be":"markdown","36020e9b":"markdown","dda25320":"markdown","904ec8f0":"markdown","81b3bb0b":"markdown","7ffb5de1":"markdown","46f743e8":"markdown","6260211a":"markdown","d6c4bcc0":"markdown","18c3b42e":"markdown","9de9b405":"markdown","6d6569a2":"markdown","920c0fb2":"markdown","2e067914":"markdown"},"source":{"afacdd2d":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom itertools import product\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\nimport calendar\nfrom datetime import datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","5d34eb44":"test = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\nsales = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cats = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')","5047762f":"sns.boxplot(x=sales.item_cnt_day)","a9458be2":"sns.boxplot(x=sales.item_price)","87a32ba3":"train = sales[(sales.item_price < 100000) & (sales.item_price > 0)]\ntrain = train[sales.item_cnt_day < 1001]","fec226d5":"print(shops[shops.shop_id.isin([0, 57])]['shop_name'])\nprint(shops[shops.shop_id.isin([1, 58])]['shop_name'])\nprint(shops[shops.shop_id.isin([40, 39])]['shop_name'])","9458b5fe":"train.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n\ntrain.loc[train.shop_id == 40, 'shop_id'] = 39\ntest.loc[test.shop_id == 40, 'shop_id'] = 39","f0512707":"index_cols = ['shop_id', 'item_id', 'date_block_num']\n\ndf = [] \nfor block_num in train['date_block_num'].unique():\n    cur_shops = train.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n    cur_items = train.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n    df.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n\ndf = pd.DataFrame(np.vstack(df), columns = index_cols,dtype=np.int32)\n\n#Add month sales\ngroup = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\ndf = pd.merge(df, group, on=index_cols, how='left')\ndf['item_cnt_month'] = (df['item_cnt_month']\n                                .fillna(0)\n                                .clip(0,20)\n                                .astype(np.float16))\ndf.head(5)","6fb11150":"test['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)\ndf = pd.concat([df, test], ignore_index=True, sort=False, keys=index_cols)\ndf.fillna(0, inplace=True)","cf47af8d":"shops['city'] = shops['shop_name'].apply(lambda x: x.split()[0].lower())\nshops.loc[shops.city == '!\u044f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u044f\u043a\u0443\u0442\u0441\u043a'\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n\ncoords = dict()\ncoords['\u044f\u043a\u0443\u0442\u0441\u043a'] = (62.028098, 129.732555, 4)\ncoords['\u0430\u0434\u044b\u0433\u0435\u044f'] = (44.609764, 40.100516, 3)\ncoords['\u0431\u0430\u043b\u0430\u0448\u0438\u0445\u0430'] = (55.8094500, 37.9580600, 1)\ncoords['\u0432\u043e\u043b\u0436\u0441\u043a\u0438\u0439'] = (53.4305800, 50.1190000, 3)\ncoords['\u0432\u043e\u043b\u043e\u0433\u0434\u0430'] = (59.2239000, 39.8839800, 2)\ncoords['\u0432\u043e\u0440\u043e\u043d\u0435\u0436'] = (51.6720400, 39.1843000, 3)\ncoords['\u0432\u044b\u0435\u0437\u0434\u043d\u0430\u044f'] = (0, 0, 0)\ncoords['\u0436\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439'] = (55.5952800, 38.1202800, 1)\ncoords['\u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442-\u043c\u0430\u0433\u0430\u0437\u0438\u043d'] = (0, 0, 0)\ncoords['\u043a\u0430\u0437\u0430\u043d\u044c'] = (55.7887400, 49.1221400, 4)\ncoords['\u043a\u0430\u043b\u0443\u0433\u0430'] = (54.5293000, 36.2754200, 4)\ncoords['\u043a\u043e\u043b\u043e\u043c\u043d\u0430'] = (55.0794400, 38.7783300, 4)\ncoords['\u043a\u0440\u0430\u0441\u043d\u043e\u044f\u0440\u0441\u043a'] = (56.0183900, 92.8671700, 4)\ncoords['\u043a\u0443\u0440\u0441\u043a'] = (51.7373300, 36.1873500, 3)\ncoords['\u043c\u043e\u0441\u043a\u0432\u0430'] = (55.7522200, 37.6155600, 1)\ncoords['\u043c\u044b\u0442\u0438\u0449\u0438'] = (55.9116300, 37.7307600, 1)\ncoords['\u043d.\u043d\u043e\u0432\u0433\u043e\u0440\u043e\u0434'] = (56.3286700, 44.0020500, 4)\ncoords['\u043d\u043e\u0432\u043e\u0441\u0438\u0431\u0438\u0440\u0441\u043a'] = (55.0415000, 82.9346000, 4)\ncoords['\u043e\u043c\u0441\u043a'] = (54.9924400, 73.3685900, 4)\ncoords['\u0440\u043e\u0441\u0442\u043e\u0432\u043d\u0430\u0434\u043e\u043d\u0443'] = (47.2313500, 39.7232800, 3)\ncoords['\u0441\u043f\u0431'] = (59.9386300, 30.3141300, 2)\ncoords['\u0441\u0430\u043c\u0430\u0440\u0430'] = (53.2000700, 50.1500000, 4)\ncoords['\u0441\u0435\u0440\u0433\u0438\u0435\u0432'] = (56.3000000, 38.1333300, 4)\ncoords['\u0441\u0443\u0440\u0433\u0443\u0442'] = (61.2500000, 73.4166700, 4)\ncoords['\u0442\u043e\u043c\u0441\u043a'] = (56.4977100, 84.9743700, 4)\ncoords['\u0442\u044e\u043c\u0435\u043d\u044c'] = (57.1522200, 65.5272200, 4)\ncoords['\u0443\u0444\u0430'] = (54.7430600, 55.9677900, 4)\ncoords['\u0445\u0438\u043c\u043a\u0438'] = (55.8970400, 37.4296900, 1)\ncoords['\u0446\u0438\u0444\u0440\u043e\u0432\u043e\u0439'] = (0, 0, 0)\ncoords['\u0447\u0435\u0445\u043e\u0432'] = (55.1477000, 37.4772800, 4)\ncoords['\u044f\u0440\u043e\u0441\u043b\u0430\u0432\u043b\u044c'] = (57.6298700, 39.8736800, 2) \n\nshops['city_coord_1'] = shops['city'].apply(lambda x: coords[x][0])\nshops['city_coord_2'] = shops['city'].apply(lambda x: coords[x][1])\nshops['country_part'] = shops['city'].apply(lambda x: coords[x][2])\n\nshops = shops[['shop_id', 'city_code', 'city_coord_1', 'city_coord_2', 'country_part']]","db6b2b4c":"df = pd.merge(df, shops, on=['shop_id'], how='left')","b1f8eda1":"map_dict = {\n            '\u0427\u0438\u0441\u0442\u044b\u0435 \u043d\u043e\u0441\u0438\u0442\u0435\u043b\u0438 (\u0448\u0442\u0443\u0447\u043d\u044b\u0435)': '\u0427\u0438\u0441\u0442\u044b\u0435 \u043d\u043e\u0441\u0438\u0442\u0435\u043b\u0438',\n            '\u0427\u0438\u0441\u0442\u044b\u0435 \u043d\u043e\u0441\u0438\u0442\u0435\u043b\u0438 (\u0448\u043f\u0438\u043b\u044c)' : '\u0427\u0438\u0441\u0442\u044b\u0435 \u043d\u043e\u0441\u0438\u0442\u0435\u043b\u0438',\n            'PC ': '\u0410\u043a\u0441\u0435\u0441\u0441\u0443\u0430\u0440\u044b',\n            '\u0421\u043b\u0443\u0436\u0435\u0431\u043d\u044b\u0435': '\u0421\u043b\u0443\u0436\u0435\u0431\u043d\u044b\u0435 '\n            }\n\nitems = pd.merge(items, item_cats, on='item_category_id')\n\nitems['item_category'] = items['item_category_name'].apply(lambda x: x.split('-')[0])\nitems['item_category'] = items['item_category'].apply(lambda x: map_dict[x] if x in map_dict.keys() else x)\nitems['item_category_common'] = LabelEncoder().fit_transform(items['item_category'])\n\nitems['item_category_code'] = LabelEncoder().fit_transform(items['item_category_name'])\nitems = items[['item_id', 'item_category_common', 'item_category_code']]","00c38517":"df = pd.merge(df, items, on=['item_id'], how='left')","3a5ee716":"def count_days(date_block_num):\n    year = 2013 + date_block_num \/\/ 12\n    month = 1 + date_block_num % 12\n    weeknd_count = len([1 for i in calendar.monthcalendar(year, month) if i[6] != 0])\n    days_in_month = calendar.monthrange(year, month)[1]\n    return weeknd_count, days_in_month, month\n\nmap_dict = {i: count_days(i) for i in range(35)}\n\ndf['weeknd_count'] = df['date_block_num'].apply(lambda x: map_dict[x][0])\ndf['days_in_month'] = df['date_block_num'].apply(lambda x: map_dict[x][1])","4280e8e9":"first_item_block = df.groupby(['item_id'])['date_block_num'].min().reset_index()\nfirst_item_block['item_first_interaction'] = 1\n\nfirst_shop_item_buy_block = df[df['date_block_num'] > 0].groupby(['shop_id', 'item_id'])['date_block_num'].min().reset_index()\nfirst_shop_item_buy_block['first_date_block_num'] = first_shop_item_buy_block['date_block_num']","9362869f":"df = pd.merge(df, first_item_block[['item_id', 'date_block_num', 'item_first_interaction']], on=['item_id', 'date_block_num'], how='left')\ndf = pd.merge(df, first_shop_item_buy_block[['item_id', 'shop_id', 'first_date_block_num']], on=['item_id', 'shop_id'], how='left')\n\ndf['first_date_block_num'].fillna(100, inplace=True)\ndf['shop_item_sold_before'] = (df['first_date_block_num'] < df['date_block_num']).astype('int8')\ndf.drop(['first_date_block_num'], axis=1, inplace=True)\n\ndf['item_first_interaction'].fillna(0, inplace=True)\ndf['shop_item_sold_before'].fillna(0, inplace=True)\n \ndf['item_first_interaction'] = df['item_first_interaction'].astype('int8')  \ndf['shop_item_sold_before'] = df['shop_item_sold_before'].astype('int8') ","090147e6":"def lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n        df[col+'_lag_'+str(i)] = df[col+'_lag_'+str(i)].astype('float16')\n    return df","f12e8e9a":"#Add sales lags for last 3 months\ndf = lag_feature(df, [1, 2, 3], 'item_cnt_month')","8d8d17ea":"#Add avg shop\/item price\n\nindex_cols = ['shop_id', 'item_id', 'date_block_num']\ngroup = train.groupby(index_cols)['item_price'].mean().reset_index().rename(columns={\"item_price\": \"avg_shop_price\"}, errors=\"raise\")\ndf = pd.merge(df, group, on=index_cols, how='left')\n\ndf['avg_shop_price'] = (df['avg_shop_price']\n                                .fillna(0)\n                                .astype(np.float16))\n\nindex_cols = ['item_id', 'date_block_num']\ngroup = train.groupby(['date_block_num','item_id'])['item_price'].mean().reset_index().rename(columns={\"item_price\": \"avg_item_price\"}, errors=\"raise\")\n\n\ndf = pd.merge(df, group, on=index_cols, how='left')\ndf['avg_item_price'] = (df['avg_item_price']\n                                .fillna(0)\n                                .astype(np.float16))\n\ndf['item_shop_price_avg'] = (df['avg_shop_price'] - df['avg_item_price']) \/ df['avg_item_price']\ndf['item_shop_price_avg'].fillna(0, inplace=True)\n\ndf = lag_feature(df, [1, 2, 3], 'item_shop_price_avg')\ndf.drop(['avg_shop_price', 'avg_item_price', 'item_shop_price_avg'], axis=1, inplace=True)","0806003e":"#Add target encoding for items for last 3 months \nitem_id_target_mean = df.groupby(['date_block_num','item_id'])['item_cnt_month'].mean().reset_index().rename(columns={\"item_cnt_month\": \"item_target_enc\"}, errors=\"raise\")\ndf = pd.merge(df, item_id_target_mean, on=['date_block_num','item_id'], how='left')\n\ndf['item_target_enc'] = (df['item_target_enc']\n                                .fillna(0)\n                                .astype(np.float16))\n\ndf = lag_feature(df, [1, 2, 3], 'item_target_enc')\ndf.drop(['item_target_enc'], axis=1, inplace=True)","6143a333":"#Add target encoding for item\/city for last 3 months \nitem_id_target_mean = df.groupby(['date_block_num','item_id', 'city_code'])['item_cnt_month'].mean().reset_index().rename(columns={\n    \"item_cnt_month\": \"item_loc_target_enc\"}, errors=\"raise\")\ndf = pd.merge(df, item_id_target_mean, on=['date_block_num','item_id', 'city_code'], how='left')\n\ndf['item_loc_target_enc'] = (df['item_loc_target_enc']\n                                .fillna(0)\n                                .astype(np.float16))\n\ndf = lag_feature(df, [1, 2, 3], 'item_loc_target_enc')\ndf.drop(['item_loc_target_enc'], axis=1, inplace=True)","9d9c6384":"#Add target encoding for item\/shop for last 3 months \nitem_id_target_mean = df.groupby(['date_block_num','item_id', 'shop_id'])['item_cnt_month'].mean().reset_index().rename(columns={\n    \"item_cnt_month\": \"item_shop_target_enc\"}, errors=\"raise\")\n\ndf = pd.merge(df, item_id_target_mean, on=['date_block_num','item_id', 'shop_id'], how='left')\n\ndf['item_shop_target_enc'] = (df['item_shop_target_enc']\n                                .fillna(0)\n                                .astype(np.float16))\n\ndf = lag_feature(df, [1, 2, 3], 'item_shop_target_enc')\ndf.drop(['item_shop_target_enc'], axis=1, inplace=True)","6ec7392c":"#For new items add avg category sales for last 3 months\nitem_id_target_mean = df[df['item_first_interaction'] == 1].groupby(['date_block_num','item_category_code'])['item_cnt_month'].mean().reset_index().rename(columns={\n    \"item_cnt_month\": \"new_item_cat_avg\"}, errors=\"raise\")\n\ndf = pd.merge(df, item_id_target_mean, on=['date_block_num','item_category_code'], how='left')\n\ndf['new_item_cat_avg'] = (df['new_item_cat_avg']\n                                .fillna(0)\n                                .astype(np.float16))\n\ndf = lag_feature(df, [1, 2, 3], 'new_item_cat_avg')\ndf.drop(['new_item_cat_avg'], axis=1, inplace=True)","e2bf11d1":"#For new items add avg category sales in a separate store for last 3 months\nitem_id_target_mean = df[df['item_first_interaction'] == 1].groupby(['date_block_num','item_category_code', 'shop_id'])['item_cnt_month'].mean().reset_index().rename(columns={\n    \"item_cnt_month\": \"new_item_shop_cat_avg\"}, errors=\"raise\")\n\ndf = pd.merge(df, item_id_target_mean, on=['date_block_num','item_category_code', 'shop_id'], how='left')\n\ndf['new_item_shop_cat_avg'] = (df['new_item_shop_cat_avg']\n                                .fillna(0)\n                                .astype(np.float16))\n\ndf = lag_feature(df, [1, 2, 3], 'new_item_shop_cat_avg')\ndf.drop(['new_item_shop_cat_avg'], axis=1, inplace=True)","0b3b6646":"def lag_feature_adv(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)+'_adv']\n        shifted['date_block_num'] += i\n        shifted['item_id'] -= 1\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n        df[col+'_lag_'+str(i)+'_adv'] = df[col+'_lag_'+str(i)+'_adv'].astype('float16')\n    return df\n\ndf = lag_feature_adv(df, [1, 2, 3], 'item_cnt_month')","fe8e8beb":"df.fillna(0, inplace=True)\ndf = df[(df['date_block_num'] > 2)]\ndf.head()","cc827dae":"df.columns","733b35d5":"#Save dataset\ndf.drop(['ID'], axis=1, inplace=True, errors='ignore')\ndf.to_pickle('df.pkl')","05419c24":"df = pd.read_pickle('df.pkl')\ndf.info()","85ef1d36":"X_train = df[df.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = df[df.date_block_num < 33]['item_cnt_month']\nX_valid = df[df.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = df[df.date_block_num == 33]['item_cnt_month']\nX_test = df[df.date_block_num == 34].drop(['item_cnt_month'], axis=1)\ndel df","21aae468":"feature_name = X_train.columns.tolist()\n\nparams = {\n    'objective': 'mse',\n    'metric': 'rmse',\n    'num_leaves': 2 ** 7 - 1,\n    'learning_rate': 0.005,\n    'feature_fraction': 0.75,\n    'bagging_fraction': 0.75,\n    'bagging_freq': 5,\n    'seed': 1,\n    'verbose': 1\n}\n\nfeature_name_indexes = [ \n                        'country_part', \n                        'item_category_common',\n                        'item_category_code', \n                        'city_code',\n]\n\nlgb_train = lgb.Dataset(X_train[feature_name], Y_train)\nlgb_eval = lgb.Dataset(X_valid[feature_name], Y_valid, reference=lgb_train)\n\nevals_result = {}\ngbm = lgb.train(\n        params, \n        lgb_train,\n        num_boost_round=3000,\n        valid_sets=(lgb_train, lgb_eval), \n        feature_name = feature_name,\n        categorical_feature = feature_name_indexes,\n        verbose_eval=5, \n        evals_result = evals_result,\n        early_stopping_rounds = 100)\n","316edc3e":"lgb.plot_importance(\n    gbm, \n    max_num_features=50, \n    importance_type='gain', \n    figsize=(12,8));","913a8fdc":"test = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\nY_test = gbm.predict(X_test[feature_name]).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('gbm_submission.csv', index=False)","7450415c":"**Shop features**\n\n* City of a shop\n* City coords\n* Country part (0-4) based on the map ","a1043c5b":"**Item features**\n\n* Item category\n* More common item category","58353c07":"Add sales for the last three months for similar item (item with id = item_id - 1;\nkinda tricky feature, but increased the metric significantly)","e3a4a907":"# Libraries","220994cb":"**Basic lag features**","2b7093be":"**Date features**\n\n* Weekends count (4 or 5)\n* Number of days in a month","36020e9b":"**Target encoding**","dda25320":"# **Create dataset**","904ec8f0":"Add test","81b3bb0b":"# Feature engineering","7ffb5de1":"# **Load data**","46f743e8":"**Interaction features**\n\n* Item is new\n* Item was bought in this shop before","6260211a":"Remove outliers","d6c4bcc0":"Detect same shops","18c3b42e":"Remove data for the first three months","9de9b405":"Stacking didn't work for me. I'd tried 2 approaches:\n\n1. XGBoost + CatBoost + LightGBM at the first level and LinearRegression\/LightGBM at the second level\n1. LinearRegression + LightGBM + RandomForest at the first level and LinearRegression\/LightGBM at the second level","6d6569a2":"Extra interaction features","920c0fb2":"Simple train dataset","2e067914":"# Train model"}}