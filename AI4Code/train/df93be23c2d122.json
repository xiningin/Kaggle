{"cell_type":{"ff025dd6":"code","3dcf89b8":"code","838c9a78":"code","6cbed71b":"code","ad82c2ea":"code","30b12061":"code","df906b33":"code","e593e97a":"code","2ed50116":"code","056a554f":"code","9492911e":"code","6cdaddb8":"code","3b0a00b9":"code","106e0fdf":"code","44dce2e3":"code","dc1fb99c":"code","1c255dce":"code","9a5c8022":"code","f89a975f":"code","a4d2f49d":"code","eaef7f8b":"code","c29db61c":"code","16c5688b":"code","3ee57139":"code","4bd8a84a":"code","d399f4bd":"code","87007c7c":"code","d95aed3b":"markdown","6a3eba99":"markdown","2cd0f866":"markdown","0e194c11":"markdown","0e434e94":"markdown","e95fbcd5":"markdown","d1e2e57a":"markdown","06b9a210":"markdown","de620f74":"markdown","541f3899":"markdown","b35c9c63":"markdown","1a4d1d52":"markdown","a3f93655":"markdown","5036f665":"markdown","65ca3f28":"markdown"},"source":{"ff025dd6":"#import needed libraries\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom tensorflow import keras\nfrom keras.models import load_model,Sequential\nfrom keras.preprocessing.image import ImageDataGenerator as Imgen\nfrom keras.preprocessing import image\nfrom keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n\nfrom PIL import Image\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nimport os\n\n","3dcf89b8":"pip install split-folders --upgrade --quiet","838c9a78":"import splitfolders\nsplitfolders.ratio(\"..\/input\/flowers-recognition\/flowers\",output=\"Tr-Te-Val\",ratio=(0.8,0.1,0.1))","6cbed71b":"os.removedirs(\".\/Tr-Te-Val\/train\/flowers\")\nos.removedirs(\".\/Tr-Te-Val\/test\/flowers\")\nos.removedirs(\".\/Tr-Te-Val\/val\/flowers\")","ad82c2ea":"train_gen = Imgen(preprocessing_function=keras.applications.densenet.preprocess_input,\n                 zoom_range=0.2,\n                  shear_range=0.2,\n                  vertical_flip=True,\n                  width_shift_range=0.2,\n                  height_shift_range=0.2,\n                  fill_mode='nearest'\n                 )\n\nval_gen = Imgen(preprocessing_function=keras.applications.densenet.preprocess_input,\n                 zoom_range=0.2,\n                  shear_range=0.2,\n                  vertical_flip=True,\n                  width_shift_range=0.2,\n                  height_shift_range=0.2,\n                  fill_mode='nearest'\n                 )\n\ntest_gen = Imgen(preprocessing_function=keras.applications.densenet.preprocess_input\n                 )","30b12061":"train_ds = train_gen.flow_from_directory(\".\/Tr-Te-Val\/train\",\n                                       target_size=(331,331),\n                                        seed = 123,\n                                        batch_size=32\n                                       )\n\nval_ds = val_gen.flow_from_directory(\".\/Tr-Te-Val\/val\",\n                                       target_size=(331,331),\n                                        seed = 123,\n                                        batch_size=32)\n\ntest_ds = test_gen.flow_from_directory(\".\/Tr-Te-Val\/test\",\n                                       target_size=(331,331),\n                                        seed = 123,\n                                        batch_size=32,\n                                      shuffle=False\n                                      )","df906b33":"a = train_ds.class_indices\nclasses = list(a.keys())\nclasses","e593e97a":"#one batch\nX,Y = next(train_ds)","2ed50116":"#plot function\ndef plot_images(img,labels):\n    plt.figure(figsize=(15,10))\n    for i in range(16):\n        plt.subplot(4,4,i+1)\n        plt.imshow(img[i])\n        plt.title(classes[np.argmax(labels[i])])\n        plt.axis('off')","056a554f":"plot_images(X,Y)","9492911e":"from keras.applications.densenet import DenseNet201","6cdaddb8":"base_model = DenseNet201(include_top=False,\n                  input_shape=(331,331,3),\n                   weights = 'imagenet',\n                    pooling='avg'\n                  )\nbase_model.trainable = False","3b0a00b9":"inputs = base_model.input\nl1 = Dense(128,activation='relu')(base_model.output)\noutputs = Dense(5,activation='softmax')(l1)\nmodel = keras.Model(inputs=inputs,outputs=outputs)","106e0fdf":"#compile \nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","44dce2e3":"#callbacks\nmy_calls = [keras.callbacks.EarlyStopping(monitor='val_loss',patience=3),\n            keras.callbacks.ModelCheckpoint(\"Model.h5\",verbose=1,save_best_only=True)]","dc1fb99c":"hist = model.fit(train_ds,epochs=18,validation_data=val_ds,callbacks=my_calls)","1c255dce":"model = load_model(\".\/Model.h5\")","9a5c8022":"#test\nmodel.evaluate(test_ds)","f89a975f":"plt.figure(figsize=(15,6))\n\nplt.subplot(1,2,1)\nplt.plot(hist.epoch,hist.history['accuracy'],label = 'Training')\nplt.plot(hist.epoch,hist.history['val_accuracy'],label = 'validation')\n\nplt.title(\"Accuracy\")\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(hist.epoch,hist.history['loss'],label = 'Training')\nplt.plot(hist.epoch,hist.history['val_loss'],label = 'validation')\n\nplt.title(\"Loss\")\nplt.legend()\nplt.show()","a4d2f49d":"preds = model.predict(test_ds,verbose=1)","eaef7f8b":"pred = [np.argmax(i) for i in preds]\npred[:5]","c29db61c":"actual = test_ds.classes","16c5688b":"print(classification_report(pred,actual))","3ee57139":"plt.figure(figsize=(8,6))\nsns.heatmap(confusion_matrix(pred,actual),annot = True, fmt = 'd', cmap = 'Blues');","4bd8a84a":"def predict_img(path):\n    img = image.load_img(path,target_size=(331,331))\n    img_arr = image.img_to_array(img)\n    img_arr_expnd  = np.expand_dims(img_arr,axis=0)\n    img = keras.applications.densenet.preprocess_input(img_arr_expnd)\n    \n    pred = model.predict(img)\n    result = classes[np.argmax(pred)]\n    \n    return result","d399f4bd":"plt.imshow(Image.open(\"..\/input\/flowers-recognition\/flowers\/rose\/10503217854_e66a804309.jpg\"))\nplt.axis('off');","87007c7c":"print(\"The given image belongs to class:\",predict_img(\"..\/input\/flowers-recognition\/flowers\/rose\/10503217854_e66a804309.jpg\"))","d95aed3b":"**Making Predictions and Verifying**","6a3eba99":"**Getting the name of classes for ease of use**","2cd0f866":"**Extracting one batch from datagen for visualization purposes**","0e194c11":"## **Using Transfer Learning to build the Model**","0e434e94":"**Defining callbacks to get the best model possible**","e95fbcd5":"**Confusion Matrix**","d1e2e57a":"**Training**","06b9a210":"> function to predict","de620f74":"**Individual image Identification**","541f3899":"**Graphs to show loss and accuracy along the training**","b35c9c63":"**To split into train test and validate folders I am going to use this library**","1a4d1d52":"**Image data from the folders using Image Data Generator**","a3f93655":"**Classification Report**","5036f665":"**Prediction**","65ca3f28":"**Getting the saved model**"}}