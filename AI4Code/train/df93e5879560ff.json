{"cell_type":{"f4fbc241":"code","9a431fc4":"code","15c49b66":"code","a3cf9815":"code","cc94ee29":"code","1f119846":"code","48e8d8bd":"code","0f0127e6":"code","4ae8bd42":"code","3f1bcef0":"code","793baf46":"code","06e6cc2a":"code","a0084f46":"code","407f9b28":"code","c73bf437":"code","dd0016ed":"code","073d830c":"code","8bb7f7da":"code","92ee1e81":"code","e56579eb":"code","806e7bae":"code","1d59fcc3":"code","c151f0c1":"code","e75e23ca":"markdown"},"source":{"f4fbc241":"import pandas as pd\nimport numpy as np\n\nmytrainset = pd.read_csv('..\/input\/titanic\/train.csv') \nmytrainset.head()\n# import and view preview of train set","9a431fc4":"mytestset = pd.read_csv('..\/input\/titanic\/test.csv')\nmytestset.head()\n# import and view preview of test set","15c49b66":"mytrainset.info()\nmytestset.info()\n# view info of our datasets to analyze what attributes need preprocessing","a3cf9815":"ages_mean_train = mytrainset['Age'].mean()\nages_mean_train = round(ages_mean_train)\n\nages_mean_test = mytestset['Age'].mean()\nages_mean_test = round(ages_mean_test)\n\n# calculate the means of ages for preprocessing","cc94ee29":"mytrainset['Age'] = mytrainset['Age'].replace(np.nan, ages_mean_train)\nmytrainset['Age'] = mytrainset['Age'].replace(np.nan, ages_mean_train)\nmytrainset = mytrainset.drop([\"Cabin\"], axis=1)\nmytrainset = mytrainset.drop([\"Name\"], axis=1)\nmytrainset = mytrainset.drop([\"Ticket\"], axis=1)\nmytrainset['Embarked'].replace({'C':1, 'Q':2, 'S':3},inplace=True)\nmytrainset['Embarked'] = mytrainset['Embarked'].fillna(0)\nmytrainset['Sex'].replace({'male':0, 'female':1},inplace=True)\n\nmytestset['Age'] = mytestset['Age'].replace(np.nan, ages_mean_test)\nmytestset = mytestset.drop([\"Cabin\"], axis=1)\nmytestset = mytestset.drop([\"Name\"], axis=1)\nmytestset = mytestset.drop([\"Ticket\"], axis=1)\nmytestset['Embarked'].replace({'C':1, 'Q':2, 'S':3},inplace=True)\nmytestset['Sex'].replace({'male':0, 'female':1},inplace=True)\nmytestset['Fare'] = mytestset['Fare'].fillna(mytestset['Fare'].mean())\n\n# Replacing null age values with the mean of ages and dropping features that do not matter.\n# Tranform our embark attribute into numbers to aid in preprocessing\n# Replace our sex values with numbers to also aid in preprocessing\n# Filled the one fare attribute which was null with 0.","1f119846":"mytrainset.info()\nmytestset.info()\n\n# Analyzing the datasets after preprocessing","48e8d8bd":"mytrainset.head()\n\n# previewing after preprocessing","0f0127e6":"mytestset.head()\n\n# previewing after preprocessing","4ae8bd42":"from sklearn.ensemble import RandomForestClassifier \nfrom sklearn.model_selection import train_test_split\n# filtered our prediction attribute\ny = mytrainset['Survived']\n# defined our features \nfeatures = [\"Pclass\", \"Age\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]\nX = mytrainset[features]\n# split our training set into a training set and a validation set 70% 30% split\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=1) ","3f1bcef0":"# Using random forest classifier \nmodel= RandomForestClassifier(n_estimators=200,max_depth=5, random_state=1)\nmodel = model.fit(X_train, Y_train)\npredictions = model.predict(X_test)","793baf46":"from sklearn.metrics import accuracy_score\naccuracy_score(predictions, Y_test)\n# ignore this ","06e6cc2a":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\nNB_model_predictions = gnb.fit(X_train, Y_train).predict(X_test)\naccuracy_score(NB_model_predictions, Y_test)\n# Using Naive Bayses Classsifier","a0084f46":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n\ndecisiontreeModel = DecisionTreeClassifier()\n\ndecisiontreeModel = decisiontreeModel.fit(X_train, Y_train)\n\ndecisiontreePredicition = decisiontreeModel.predict(X_test)\n\naccuracy_score(decisiontreePredicition, Y_test)\n\n# Using decision trees classifier","407f9b28":"from sklearn.metrics import confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n\nknn.fit(X_train, Y_train)\n\nknnPredictions = knn.predict(X_test)\n# confusion_matrix(y, knn.predict(X_train))\n\naccuracy_score(Y_test, knnPredictions)\n\n# Using K nearest neighnour classsifier","c73bf437":"from sklearn.linear_model import LogisticRegression\nLRModel = LogisticRegression(max_iter = 200)\nLRModel.fit(X_train, Y_train)\nLRModel_Prediction = LRModel.predict(X_test)\n\naccuracy_score(Y_test, LRModel_Prediction)\n\n# using logistic regression classifier","dd0016ed":"# Using k fold cross validation to analyse the accuracy of our models\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\ncv = KFold(n_splits=10, random_state=1, shuffle=True)\nscores = cross_val_score(model, X, y,  scoring='accuracy', cv=cv, n_jobs=-1)\nprint(\"%0.2f accuracy\" % (scores.mean()))","073d830c":"scores = cross_val_score(gnb, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nscores\nprint(\"%0.2f accuracy\" % (scores.mean()))","8bb7f7da":"scores = cross_val_score(decisiontreeModel, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nscores\nprint(\"%0.2f accuracy\" % (scores.mean()))","92ee1e81":"scores = cross_val_score(knn, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nscores\nprint(\"%0.2f accuracy\" % (scores.mean()))","e56579eb":"scores = cross_val_score(LRModel, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nscores\nprint(\"%0.2f accuracy\" % (scores.mean()))","806e7bae":"testing = mytestset[features]\ntestPredicitons = model.predict(testing)","1d59fcc3":"testPredicitons","c151f0c1":"testPredicitons = {'PassengerId':mytestset[\"PassengerId\"], \"Survived\": testPredicitons}\npd.DataFrame(testPredicitons).to_csv(\"predictions.csv\", index = False)","e75e23ca":"# DATA MINING PROJECT"}}