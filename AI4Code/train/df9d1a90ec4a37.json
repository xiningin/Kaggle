{"cell_type":{"7ef1cc29":"code","efa48ac5":"code","c8179684":"code","9dac4a3a":"code","eda80cfd":"code","f0ee4407":"code","ce488eb4":"code","9f2d49ce":"code","d44ad062":"code","4ba3be4a":"code","e6b4c42c":"code","5fdbb9c4":"code","981575ce":"code","103185ac":"code","cd5096a9":"code","fd737c31":"code","e2261d26":"code","10c202f5":"markdown","a9cb2895":"markdown","cbf05d34":"markdown","82899302":"markdown","fba973b9":"markdown","2f49a313":"markdown","52594d39":"markdown","dc6eedf8":"markdown"},"source":{"7ef1cc29":"import pandas as pd\nimport numpy as np\n\nimport os\nimport sys\n\nimport librosa\nimport librosa.display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.display import Audio\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","efa48ac5":"Crema = \"\/kaggle\/input\/cremad\/AudioWAV\/\"","c8179684":"crema_directory_list = os.listdir(Crema)\n\nfile_emotion = []\nfile_path = []\n\nfor file in crema_directory_list:\n    # storing file paths\n    file_path.append(Crema + file)\n    # storing file emotions\n    part=file.split('_')\n    if part[2] == 'SAD':\n        file_emotion.append('sad')\n    elif part[2] == 'ANG':\n        file_emotion.append('angry')\n    elif part[2] == 'DIS':\n        file_emotion.append('disgust')\n    elif part[2] == 'FEA':\n        file_emotion.append('fear')\n    elif part[2] == 'HAP':\n        file_emotion.append('happy')\n    elif part[2] == 'NEU':\n        file_emotion.append('neutral')\n    else:\n        file_emotion.append('Unknown')\n        \n# dataframe for emotion of files\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n\n# dataframe for path of files.\npath_df = pd.DataFrame(file_path, columns=['Path'])\nCrema_df = pd.concat([emotion_df, path_df], axis=1)\nCrema_df.head()","9dac4a3a":"plt.title('Count of Emotions', size=16)\nsns.countplot(Crema_df.Emotions)\nplt.ylabel('Count', size=12)\nplt.xlabel('Emotions', size=12)\nsns.despine(top=True, right=True, left=False, bottom=False)\nplt.show()","eda80cfd":"def create_waveplot(data, sr, e):\n    plt.figure(figsize=(10, 3))\n    plt.title('Waveplot for {} emotion'.format(e), size=15)\n    librosa.display.waveplot(data, sr=sr)\n    plt.show()\n\ndef create_spectrogram(data, sr, e):\n    X = librosa.stft(data)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    plt.figure(figsize=(12, 3))\n    plt.title('Spectrogram for {} emotion'.format(e), size=15)\n    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n    plt.colorbar()","f0ee4407":"emotion='angry'\npath = np.array(Crema_df.Path[Crema_df.Emotions==emotion])[0]\ndata, sampling_rate = librosa.load(path)\ncreate_waveplot(data, sampling_rate, emotion)\ncreate_spectrogram(data, sampling_rate, emotion)\nAudio(path)","ce488eb4":"labels = {'disgust':0,'happy':1,'sad':2,'neutral':3,'fear':4,'angry':5}\nCrema_df.replace({'Emotions':labels},inplace=True)","9f2d49ce":"num_mfcc=13\nn_fft=2048\nhop_length=512\nSAMPLE_RATE = 22050\ndata = {\n        \"labels\": [],\n        \"mfcc\": []\n    }\nfor i in range(7442):\n    data['labels'].append(Crema_df.iloc[i,0])\n    signal, sample_rate = librosa.load(Crema_df.iloc[i,1], sr=SAMPLE_RATE)\n    mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=13, n_fft=2048, hop_length=512)\n    mfcc = mfcc.T\n    data[\"mfcc\"].append(np.asarray(mfcc))\n    if i%500==0:\n        print(i)","d44ad062":"X = np.asarray(data['mfcc'])\ny = np.asarray(data[\"labels\"])","4ba3be4a":"X = tf.keras.preprocessing.sequence.pad_sequences(X)\nX.shape","e6b4c42c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)","5fdbb9c4":"print(X_train.shape,y_train.shape,X_validation.shape,y_validation.shape,X_test.shape,y_test.shape)","981575ce":"def build_model(input_shape):\n    model = tf.keras.Sequential()\n\n    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n    model.add(LSTM(64))\n    \n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.3))\n\n    model.add(Dense(6, activation='softmax'))\n\n    return model","103185ac":"# create network\ninput_shape = (None,13)\nmodel = build_model(input_shape)\n\n# compile model\noptimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimiser,\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\nmodel.summary()","cd5096a9":"history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)","fd737c31":"test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Test Accuracy: \",test_acc)","e2261d26":"model.save('Speech-Emotion-Recognition-Model.h5')","10c202f5":"# Dataset","a9cb2895":"# Importing Libraries","cbf05d34":"# Visualization","82899302":"# Evaluation","fba973b9":"# Model","2f49a313":"# Padding MFCC to make them of equal length","52594d39":"# MFCC Extraction","dc6eedf8":"# Training"}}