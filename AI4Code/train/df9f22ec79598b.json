{"cell_type":{"dd34945d":"code","25ea91ce":"code","712e2912":"code","5cde0c37":"code","6a4191fc":"code","08f3b057":"code","ff3f9452":"code","74a965e9":"code","60896c9b":"code","467e22bb":"code","57848e71":"code","a26121bd":"code","fe074936":"code","7079beda":"code","0cb94cbc":"code","b3dc0d16":"code","4498fcc6":"code","62e50535":"code","c3e3a308":"code","f8909adf":"code","31ed6e75":"code","068ab216":"code","ed2b58c0":"code","4b7471cc":"code","e4650f76":"code","caac8b9a":"code","5348feac":"code","2f5b1152":"code","24c7b616":"code","98954315":"code","d68f514a":"code","42604f16":"code","4c897561":"code","7e3bcfa6":"code","32c4348d":"code","c02352f4":"code","027c0f8f":"code","31a1f2ce":"code","525a4e22":"code","37700d72":"code","816842a2":"code","21821c46":"code","09188c07":"code","8a302169":"markdown","06c0458a":"markdown","b5c2f92b":"markdown","d6fc1cc0":"markdown","2558a7fc":"markdown","6600bd43":"markdown","2358ffed":"markdown","cc6e6e62":"markdown","7aa61df8":"markdown","e84d0f4f":"markdown","e5f6ce35":"markdown","4132934d":"markdown","366ee84e":"markdown","950f0db7":"markdown","dd439286":"markdown","7863f449":"markdown","ef21243f":"markdown","8290b79d":"markdown","51c7368c":"markdown","fc0130e2":"markdown","3007c928":"markdown","ae033d93":"markdown","a6640337":"markdown","9db37045":"markdown","a2c3df40":"markdown","14352800":"markdown","94bac8f6":"markdown","66a2295e":"markdown","6aafb5ce":"markdown"},"source":{"dd34945d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","25ea91ce":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\",index_col='PassengerId')\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\", index_col='PassengerId')","712e2912":"train_data.head()","5cde0c37":"train_data['Royalty'] = train_data['Name'].str.split(', ').str[1].str.split('.').str[0]\ntest_data['Royalty'] = test_data['Name'].str.split(', ').str[1].str.split('.').str[0]\ntrain_data['Royalty'].unique()","6a4191fc":"train_data['MarStatus'] = train_data['Royalty']\ntest_data['MarStatus'] = test_data['Royalty']\n\ntrain_data['MarStatus'] = train_data['MarStatus'].replace(['Ms','Mlle'], 'Miss')\ntrain_data['MarStatus'] = train_data['MarStatus'].replace(['Mme','Dona','the Countess','Lady'], 'Mrs')\ntrain_data['MarStatus'] = train_data['MarStatus'].replace(['Rev','Jonkheer','Dr','Capt','Don','Col','Major','Sir'], 'Mr')\n\ntest_data['MarStatus'] = test_data['MarStatus'].replace(['Ms','Mlle'], 'Miss')\ntest_data['MarStatus'] = test_data['MarStatus'].replace(['Mme','Dona','the Countess','Lady'], 'Mrs')\ntest_data['MarStatus'] = test_data['MarStatus'].replace(['Rev','Jonkheer','Dr','Capt','Don','Col','Major','Sir'], 'Mr')","08f3b057":"train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\ntest_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1","ff3f9452":"train_data['isAlone'] = train_data['FamilySize']\ntrain_data['isAlone'].replace({2 : 0, 5 : 0, 3 : 0, 7 : 0, 6 : 0, 4 : 0, 8 : 0, 11 : 0}, inplace = True)   \ntest_data['isAlone'] = test_data['FamilySize']\ntest_data['isAlone'].replace({2 : 0, 5 : 0, 3 : 0, 7 : 0, 6 : 0, 4 : 0, 8 : 0, 11 : 0}, inplace = True)   ","74a965e9":"train_data.isnull().sum()","60896c9b":"test_data.isnull().sum()","467e22bb":"#Categorical Encoding\n\ntrain_data['Sex'].replace({'male':1 , 'female':0},inplace=True)\ntrain_data['Embarked'].replace({'C': 1, 'S': 2 ,'Q': 3},inplace=True)\ntrain_data['MarStatus'].replace({'Miss' : 0, 'Mr' : 1, 'Mrs' : 2, 'Master' : 0}, inplace=True)\ntrain_data['Royalty'].replace({'Mr' : 0, 'Mrs': 0, 'Miss' : 0, 'Master' : 0, \n                               'Don' : 1, 'Rev' : 1, 'Dr' : 1, 'Mme' : 0, 'Ms' : 0,\n                               'Major' : 1, 'Lady' : 1, 'Sir' : 1, 'Mlle' : 0, \n                               'Col' : 1, 'Capt' : 1, 'the Countess' : 1, 'Jonkheer' : 1}, inplace = True)\n\ntest_data['MarStatus'].replace({'Miss' : 0, 'Mr' : 1, 'Mrs' : 2, 'Master' : 0}, inplace = True)\ntest_data['Sex'].replace({'male':1 , 'female':0},inplace=True)\ntest_data['Embarked'].replace({'C': 1, 'S': 2 ,'Q': 3},inplace=True)\ntest_data['Royalty'].replace({'Mr' : 0, 'Mrs': 0, 'Miss' : 0, 'Master' : 0, \n                               'Don' : 1, 'Dona' : 1, 'Rev' : 1, 'Dr' : 1, 'Mme' : 0, 'Ms' : 0,\n                               'Major' : 1, 'Lady' : 1, 'Sir' : 1, 'Mlle' : 0, \n                               'Col' : 1, 'Capt' : 1, 'the Countess' : 1, 'Jonkheer' : 1}, inplace = True)","57848e71":"#Handling the missing values\n\ntrain_data['Age'].fillna(train_data['Age'].median(), inplace = True)\ntrain_data['Embarked'].fillna(1,inplace=True)\ntest_data['Age'].fillna(test_data['Age'].median(),inplace = True )\ntest_data['Fare'].fillna(test_data['Fare'].mean(), inplace = True)","a26121bd":"train_data['Embarked'] = train_data['Embarked'].astype(int)\ntest_data['Embarked'] = test_data['Embarked'].astype(int)","fe074936":"train_data.head()","7079beda":"train_data.isnull().sum()","0cb94cbc":"test_data.isnull().sum()","b3dc0d16":"sns.barplot(x = train_data['Pclass'] , y = 1 - train_data['Survived'])\nplt.title(\"No.of deaths according to Pclass\")\nplt.ylabel('Deaths')\n     \n# It can be observed that as the people from the 3rd class suffered the highest deaths","4498fcc6":"sns.barplot(x = train_data['Sex'] , y = train_data['Survived'])\nplt.title(\"No.of survivals according to Sex\")\n\n#It is observed that most of the survivors were female","62e50535":"sns.barplot(x = train_data['SibSp'] , y = train_data['Survived'])\nplt.title(\"Effect of sibling(s) and spouse on survival\")\n\n# It can be observed that people with 0,1,2 spouse\/sibling(s) had the highest survival rate","c3e3a308":"sns.barplot(x = train_data['Parch'] , y = train_data['Survived'])\nplt.title(\"Effect of parent and children on survival\")\n\n# It can be observed that parents with 0,1,2,3 children had the highest survival rate","f8909adf":"sns.barplot(x = train_data['Embarked'] , y = train_data['Survived'])\nplt.title(\"Ports Embarked and Survival\")\n\n# It can be observed that people who Embarked from Cherbourg had the highest survival rate","31ed6e75":"sns.barplot(x = train_data['Royalty'] , y = train_data['Survived'])\nplt.title(\"Royal Titles and Survival\")\n\n# It can be observed that royal and non royals had a similar fate","068ab216":"sns.barplot(x = train_data['FamilySize'] , y = train_data['Survived'])\nplt.title(\"Effect of Family size on Survival\")\n\n# It can be observed that people with 4 or less membered families survived more","ed2b58c0":"sns.barplot(x = train_data['MarStatus'] , y = train_data['Survived'])\nplt.title(\"Maritial Status and Survival\")\n\n# It can be observed that Unmarried and Married females along with kids had higher chances of Survival","4b7471cc":"plt.figure(figsize=(15,6))\n\n#outlier detection in Age column\nplt.subplot(1, 2, 1)\nfig = train_data.boxplot(column='Age')\nfig.set_title('')\nfig.set_ylabel('Age')\n\n#outlier detection in Fare column\nplt.subplot(1, 2, 2)\nfig = train_data.boxplot(column='Fare')\nfig.set_title('')\nfig.set_ylabel('Fare')","e4650f76":"plt.figure(figsize=(15,6))\n\n#Visualizing the Age columns\nplt.subplot(1, 2, 1)\nfig = train_data.Age.hist(bins=20)\nfig.set_ylabel('Number of passengers')\nfig.set_xlabel('Age')\n\n##Visualizing the Fare columns\nplt.subplot(1, 2, 2)\nfig = train_data.Fare.hist(bins=20)\nfig.set_ylabel('Number of passengers')\nfig.set_xlabel('Fare')","caac8b9a":"#Gaussian Assumption\n#defining upper and lower boundaries\nUpper_boundary = train_data.Age.mean() + 3* train_data.Age.std()\nLower_boundary = train_data.Age.mean() - 3* train_data.Age.std()\nAge_limit = round(Upper_boundary)\n\n#Constraining the upper limit of the data\ntrain_data['Age'] = np.where(train_data['Age'] > Age_limit, Age_limit, train_data['Age'])\ntest_data['Age'] = np.where(test_data['Age'] > Age_limit, Age_limit, test_data['Age'])\ntrain_data['Age'].max()","5348feac":"#Inter-Quartile Range Adjustments\n#defining the upper and lower break limits\nIQR = train_data.Fare.quantile(0.75) - train_data.Fare.quantile(0.25)\nLower_fence = train_data.Fare.quantile(0.25) - (IQR * 3)\nUpper_fence = train_data.Fare.quantile(0.75) + (IQR * 3)\nFare_limit = round(Upper_fence)\n\n#Constraining the lower limits of the data\ntrain_data['Fare'] = np.where(train_data['Fare'] > Fare_limit, Fare_limit, train_data['Fare'])\ntest_data['Fare'] = np.where(test_data['Fare'] > Fare_limit, Fare_limit, test_data['Fare'])\ntrain_data['Fare'].max()","2f5b1152":"#Separating the Age column into 5 different bins \ntrain_data['Age_binned'] = pd.cut(train_data['Age'],5)\ntrain_data['Age_binned'].unique()","24c7b616":"#Applying categorical encoding according to the binned train data\ntrain_data.loc[(train_data['Age'] <= 13.936), 'Age'] = 1\ntrain_data.loc[(train_data['Age'] > 13.936) & (train_data['Age'] <= 27.452), 'Age'] = 2\ntrain_data.loc[(train_data['Age'] > 27.452) & (train_data['Age'] <= 40.968), 'Age'] = 3\ntrain_data.loc[(train_data['Age'] > 40.968) & (train_data['Age'] <= 54.484), 'Age'] = 4\ntrain_data.loc[(train_data['Age'] > 54.484) & (train_data['Age'] <= 68.0), 'Age'] = 5","98954315":"#Applying categorical encoding to the test data\ntest_data.loc[(test_data['Age'] <= 13.936), 'Age'] = 1\ntest_data.loc[(test_data['Age'] > 13.936) & (test_data['Age'] <= 27.452), 'Age'] = 2\ntest_data.loc[(test_data['Age'] > 27.452) & (test_data['Age'] <= 40.968), 'Age'] = 3\ntest_data.loc[(test_data['Age'] > 40.968) & (test_data['Age'] <= 54.484), 'Age'] = 4\ntest_data.loc[(test_data['Age'] > 54.484) & (test_data['Age'] <= 68.0), 'Age'] = 5","d68f514a":"train_data.drop('Age_binned', axis = 1, inplace = True)\ntrain_data['Age'] = train_data['Age'].astype(int)\ntest_data['Age'] = test_data['Age'].astype(int)","42604f16":"#Separating the Fare column into different bins \ntrain_data['Fare_binned'] = pd.cut(train_data['Fare'],4)\ntrain_data['Fare_binned'].unique()","4c897561":"#Applying categorical encoding according to the binned data\ntrain_data.loc[(train_data['Fare'] <= 25.00), 'Fare'] = 1\ntrain_data.loc[(train_data['Fare'] > 25.00) & (train_data['Fare'] <= 50.00), 'Fare'] = 2\ntrain_data.loc[(train_data['Fare'] > 50.00) & (train_data['Fare'] <= 75.00), 'Fare'] = 3\ntrain_data.loc[(train_data['Fare'] > 75.00) & (train_data['Fare'] <= 100.00), 'Fare'] = 4","7e3bcfa6":"#Applying categorical encoding according to the binned test data\ntest_data.loc[(test_data['Fare'] <= 25.00), 'Fare'] = 1\ntest_data.loc[(test_data['Fare'] > 25.00) & (test_data['Fare'] <= 50.00), 'Fare'] = 2\ntest_data.loc[(test_data['Fare'] > 50.00) & (test_data['Fare'] <= 75.00), 'Fare'] = 3\ntest_data.loc[(test_data['Fare'] > 75.00) & (test_data['Fare'] <= 100.00), 'Fare'] = 4","32c4348d":"train_data.drop('Fare_binned', axis = 1, inplace = True)\ntrain_data['Fare'] = train_data['Fare'].astype(int)\ntest_data['Fare'] = test_data['Fare'].astype(int)","c02352f4":"plt.figure(figsize = (12,6))\nsns.heatmap(train_data.corr(), annot = True, linewidth = 3, cmap=\"YlGnBu\")","027c0f8f":"features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Royalty', 'MarStatus', 'FamilySize', 'isAlone']\nX = train_data[features]\ny = train_data.Survived\nX_final = test_data[features]","31a1f2ce":"combine = pd.concat([X,X_final])\ncombine = pd.get_dummies(columns = features, data = combine)\nn_cols = combine.shape[1]\ncombine.head()","525a4e22":"#Sanity check to see if any missing values exist\nprint(combine.isnull().sum().sum())","37700d72":"#Splitting the combined data into train and test set\nX_encoded = combine.iloc[: X.shape[0]]\nX_final_encoded = combine.iloc[X.shape[0] :]","816842a2":"#importing Standard Scaler\nfrom sklearn.preprocessing import StandardScaler\n\n#instanting object and fitting the train data\nscaler = StandardScaler()\nscaler.fit(X_encoded)\n\n#scaling the train and test data\nX_scaled = scaler.transform(X_encoded)\nX_final_scaled = scaler.transform(X_final_encoded)","21821c46":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(n_estimators = 2000, \n                    learning_rate = 0.005,\n                    max_depth = 10,\n                    subsample = 0.85,\n                    colsample_bytree = 0.6,\n                    gamma = 0)\n\nxgb.fit(X_scaled, y, early_stopping_rounds = 5, \n              eval_set=[(X_scaled, y)], \n              verbose = False)\n\nprint(xgb.score(X_scaled,y))\n\ny_pred = xgb.predict(X_final_scaled)","09188c07":"output = pd.DataFrame(columns = ['PassengerId','Survived'])\n\nfor i in range(0, X_final_encoded.shape[0]):\n    output = output.append({'PassengerId': X_final_encoded.index[i], 'Survived': y_pred[i]}, ignore_index = True)\n\noutput.to_csv('Submission_Titanic.csv', index=False)","8a302169":"## Categorical Encoding and Handling Missing Values","06c0458a":"### ----- THANK YOU ! ------ ","b5c2f92b":"Handling the ***Fare*** column","d6fc1cc0":"## EDA and Data Visualization","2558a7fc":"## Feature Selection","6600bd43":"Extracting royal titles and maritial status from the Name column","2358ffed":"Outlier detection via boxplots","cc6e6e62":"Loading the data and checking for missing values","7aa61df8":"## Data Normalization","e84d0f4f":"Creating Family Size feature from SibSp and Parch columns","e5f6ce35":"Visualizaing the data distribution of Age and Fare via histograms","4132934d":"As it can be seen from the histograms, the ***Age*** values have Normal distribution, while the ***Fare*** values are Left Skewed.\nHence we will be using Gaussian Assumption and Interquartile range calculations respectively to correct the outliers.","366ee84e":"Creating a new feature called isAlone ","950f0db7":"Handling the ***Age*** column ","dd439286":"## One Hot Encoding the complete data","7863f449":"## Training the Model","ef21243f":"We will be using all the features, since the number of features are less and training data is also less. \n\nHowever, since FamilySize is very highly corelated with SibSp and Parch, we will be using FamilySize only and not be using the other two","8290b79d":"## Data Binning - Age\n\nSeparating the Age column into different groups and hence applying categorical encoding to the data","51c7368c":"As it can be seen that both the Age and the Fare column has a lot of outliers.\n\nIt is important to note that Outliers can only be present in continous values and hence other columns have been ignored","fc0130e2":"Using co-relation matrix and heatmap to identify important features","3007c928":"## Outlier Handling","ae033d93":"## Outlier Detection\n\n\nFor this section, I referred to this kernel - https:\/\/www.kaggle.com\/anuragnegi\/feature-engineering-outliers-handling-ensembling","a6640337":"## Data Binning - Fare\n\nSeparating the Age column into different groups and hence applying categorical encoding to the data","9db37045":"## DATA GATHERING","a2c3df40":"## Making predictions and saving the output","14352800":"No new missing values were created.\n\nThree new features have been created. We will be converting them to usable values in the Categorical Encoding section","94bac8f6":"Checking for new missing values that could be created","66a2295e":"## Feature Engineering\n\nThe data contains valuable information in the Name column, which could be used to create new features. Similarly, by combining SibSp and Parch, we can estimate the size of the family, which is also another important feature","6aafb5ce":"The Age and Fare values have been handled by constraining the maximum limit of the data. It can be seen that only the upper limit has been constrained and the lower limit hasn't been touched. This is because, in both cases, the lower limit is negative and in practical situations it is not possible to have negative values of Fare and Age and hence they are automatically constrained to be positive."}}