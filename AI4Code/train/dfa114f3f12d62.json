{"cell_type":{"e33e482b":"code","3f800cb5":"code","b09752c0":"code","c4c7dfd2":"code","ca2e2146":"code","70fb4d19":"code","dc36c482":"code","72d922b6":"code","f89c1831":"code","ed3ce547":"code","d936463a":"code","d3fea249":"code","0877d473":"code","1e74a905":"code","6751c8c0":"code","9ea5e4ba":"code","a3c4d970":"code","96aeeb4e":"code","eb5f11a7":"code","b49f17e3":"code","d3b2a77a":"code","ec8afdeb":"code","f3bd6cfc":"code","cc876dc3":"code","a32e3bdd":"code","e43f9596":"code","e24937c7":"code","315e0deb":"markdown","fef477d3":"markdown","9cc5830c":"markdown","a891182c":"markdown","52b7ae09":"markdown","5b29b1b1":"markdown","2c8e5a4b":"markdown","a2869632":"markdown","2f2eaf93":"markdown","aefa481d":"markdown","a2cc8247":"markdown","1efdd32c":"markdown","344f3af3":"markdown","301cd4b4":"markdown","40db9897":"markdown"},"source":{"e33e482b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3f800cb5":"!pip install tf_explain\n\n","b09752c0":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport pandas as pd\n\nimport xml.etree.ElementTree as ET\n#import gdown\nimport time\nimport math\nimport cv2\nfrom PIL import Image\n\nimport matplotlib.image as image\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\n\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\n\nfrom tensorflow.keras import layers\n\nfrom keras.applications.xception import Xception, preprocess_input\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\n\nfrom keras.utils import np_utils\nfrom keras.utils import Sequence\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tf_explain.core.activations import ExtractActivations\n\nfrom tensorflow.keras.applications.xception import decode_predictions\n%matplotlib inline\nfrom sklearn.metrics import classification_report\n\nfrom PIL import Image\nimport matplotlib.image as mpimg\nfrom imgaug import augmenters as iaa\nprint(\"Loaded all libraries\")","c4c7dfd2":"image_path  = r'\/kaggle\/input\/stanford-dogs-dataset\/images\/Images\/'\nimage_size = 299\nbatch_size = 16\nnum_of_categories = 120","ca2e2146":"breed_list = sorted(os.listdir(image_path))\nnum_classes = len(breed_list)\nprint(\"{} breeds\".format(num_classes))","70fb4d19":"# Define a time counter function to test the algorythms performance \n_start_time = time.time()\n\ndef process_time_starts():\n    global _start_time \n    _start_time = time.time()\n\ndef time_elapsed():\n    t_sec = round(time.time() - _start_time)\n    (t_min, t_sec) = divmod(t_sec,60)\n    (t_hour,t_min) = divmod(t_min,60) \n    print('The process took: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))","dc36c482":"# copy from https:\/\/www.kaggle.com\/gabrielloye\/dogs-inception-pytorch-implementation\n# reduce the background noise\n\nos.mkdir('data')\nfor breed in breed_list:\n    os.mkdir('data\/' + breed)\nprint('Created {} folders to store cropped images of the different breeds.'.format(len(os.listdir('data'))))","72d922b6":"%%time\nfor breed in os.listdir('data'):\n    for file in os.listdir('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/{}'.format(breed)):\n        img = Image.open('..\/input\/stanford-dogs-dataset\/images\/Images\/{}\/{}.jpg'.format(breed, file))\n        tree = ET.parse('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/{}\/{}'.format(breed, file))\n        xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n        xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n        ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n        ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n        img = img.crop((xmin, ymin, xmax, ymax))\n        img = img.convert('RGB')\n        img = img.resize((image_size, image_size))\n        img.save('data\/' + breed + '\/' + file + '.jpg')","f89c1831":"plt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(331 + i) # showing 9 random images\n    breed = np.random.choice(breed_list) # random breed\n    dog = np.random.choice(os.listdir('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/' + breed)) # random image \n    img = Image.open('..\/input\/stanford-dogs-dataset\/images\/Images\/' + breed + '\/' + dog + '.jpg') \n    tree = ET.parse('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/' + breed + '\/' + dog) # init parser for file given\n    root = tree.getroot() # idk what's it but it's from documentation\n    objects = root.findall('object') # finding all dogs. An array\n    plt.imshow(img) # displays photo\n    for o in objects:\n        bndbox = o.find('bndbox') # reading border coordinates\n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n        plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin]) # showing border\n        plt.text(xmin, ymin, o.find('name').text, bbox={'ec': None}) # printing breed","ed3ce547":"label_maps = {}\nlabel_maps_rev = {}\nfor i, v in enumerate(breed_list):\n    label_maps.update({v: i})\n    label_maps_rev.update({i : v})","d936463a":"def paths_and_labels():\n    paths = list()\n    labels = list()\n    targets = list()\n    for breed in breed_list:\n        base_name = \".\/data\/{}\/\".format(breed)\n        for img_name in os.listdir(base_name):\n            paths.append(base_name + img_name)\n            labels.append(breed)\n            targets.append(label_maps[breed])\n    return paths, labels, targets\n\npaths, labels, targets = paths_and_labels()\n\nassert len(paths) == len(labels)\nassert len(paths) == len(targets)\n\ntargets = np_utils.to_categorical(targets, num_classes=num_classes)","d3fea249":"class ImageGenerator(Sequence):\n    \n    def __init__(self, paths, targets, batch_size, shape, augment=False):\n        self.paths = paths\n        self.targets = targets\n        self.batch_size = batch_size\n        self.shape = shape\n        self.augment = augment\n        \n    def __len__(self):\n        return int(np.ceil(len(self.paths) \/ float(self.batch_size)))\n    \n    def __getitem__(self, idx):\n        batch_paths = self.paths[idx * self.batch_size : (idx + 1) * self.batch_size]\n        x = np.zeros((len(batch_paths), self.shape[0], self.shape[1], self.shape[2]), dtype=np.float32)\n        y = np.zeros((self.batch_size, num_classes, 1))\n        for i, path in enumerate(batch_paths):\n            x[i] = self.__load_image(path)\n        y = self.targets[idx * self.batch_size : (idx + 1) * self.batch_size]\n        return x, y\n    \n    def __iter__(self):\n        for item in (self[i] for i in range(len(self))):\n            yield item\n            \n    def __load_image(self, path):\n        image = cv2.imread(path)\n        image = preprocess_input(image)\n        if self.augment:\n            seq = iaa.Sequential([\n                iaa.OneOf([\n                    iaa.Fliplr(0.5),\n                    iaa.Flipud(0.5),\n                    iaa.Sometimes(0.5,\n                    \n                    ),\n                    iaa.Affine(\n                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n                        rotate=(-40, 40),\n                        shear=(-8, 8)\n                    )\n                ])\n            ], random_order=True)\n            image = seq.augment_image(image)\n        return image\n","0877d473":"x_train, x_test, y_train, y_test = train_test_split(paths, targets, test_size=0.2, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)\n\ntrain_ds = ImageGenerator(x_train, y_train, batch_size=32, shape=(image_size, image_size,3), augment=True)\nval_ds = ImageGenerator(x_test, y_test, batch_size=32, shape=(image_size, image_size,3), augment=False)\ntest_ds = ImageGenerator(x_test, y_test, batch_size=32, shape=(image_size, image_size,3), augment=False)","1e74a905":"#base line \nbase_model = tf.keras.applications.xception.Xception(weights='imagenet',include_top=False, pooling='avg')#Summary of Xception Model\n\n\nbase_model.trainable = False\n\n#model.summary()\nbase_model.summary()","6751c8c0":"flat_dim = 5 * 5 * 2048\n\nmy_model = Sequential(base_model)\n\nmy_model.add(Flatten())\nmy_model.add(Dropout(0.05)) # dropout added\nmy_model.add(Dense(1032, activation='relu',input_dim=flat_dim))\nmy_model.add(Dense(512, activation='relu'))\nmy_model.add(Dropout(0.05))\nmy_model.add(Dense(256, activation='relu'))\nmy_model.add(Dense(120, activation='softmax'))","9ea5e4ba":"###################\ntotal_epoch = 8\nlearning_rate_init = 0.00001\n###################\n\ndef lr_scheduler(epoch):\n    epoch += 1\n   \n    if epoch == 1:\n        return learning_rate_init\n    \n    elif epoch >= 2 and epoch <= 40:\n        return (0.2*epoch**3)*math.exp(-0.45*epoch)*learning_rate_init\n    \n    else:\n        return lr_scheduler(40-1)\n    \n\nstage = [i for i in range(0,25)]\nlearning_rate = [lr_scheduler(x) for x in stage]\nplt.plot(stage, learning_rate)\nprint(learning_rate)","a3c4d970":"# Callbacks\n\nscheduler = keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\nearly_stop = EarlyStopping(monitor='val_accuracy', patience = 6, mode='max', min_delta=1, verbose=1)","96aeeb4e":"my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","eb5f11a7":"process_time_starts()\n\nhist = my_model.fit_generator(generator=train_ds, steps_per_epoch=400, validation_data=val_ds,  validation_steps=90, epochs=8, callbacks=[scheduler])\n","b49f17e3":"time_elapsed()","d3b2a77a":"plt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1.1])\nplt.show()\n\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n#plt.ylim([0, 1.1])\nplt.show()","ec8afdeb":"my_model.save('my_model.h5', overwrite=True) \nmy_model.save_weights('dog_breed_xcept_weights.h5', overwrite=True)\nprint(\"Saved model to disk\")","f3bd6cfc":"test_loss, test_accuracy = my_model.evaluate_generator(generator=test_ds,steps=int(100))\n\nprint(\"Test results \\n Loss:\",test_loss,'\\n Accuracy',test_accuracy)","cc876dc3":"def download_and_predict(url, filename):\n    # download and save\n    os.system(\"curl -s {} -o {}\".format(url, filename))\n    img = Image.open(filename)\n    img = img.convert('RGB')\n    img = img.resize((299, 299))\n    img.save(filename)\n    # show image\n    plt.figure(figsize=(4, 4))\n    plt.imshow(img)\n    plt.axis('off')\n    # predict\n    img = image.imread(filename)\n    img = preprocess_input(img)\n    probs = my_model.predict(np.expand_dims(img, axis=0))\n    for idx in probs.argsort()[0][::-1][:5]:\n        print(\"{:.2f}%\".format(probs[0][idx]*100), \"\\t\", label_maps_rev[idx].split(\"-\")[-1])","a32e3bdd":"def download_and_predict2(url, filename):\n    # download and save\n    os.system(\"curl -s {} -o {}\".format(url, filename))\n    img = Image.open(filename)\n    \n    \n    img = img.convert('RGB')\n    img = img.resize((299, 299))\n    img.save(filename)\n    # show image\n    plt.figure(figsize=(4, 4))\n    #plt.imshow(img)\n    plt.axis('off')\n    # predict\n    img = image.imread(filename)\n    img = preprocess_input(img)\n    probs = my_model.predict(np.expand_dims(img, axis=0))\n    for idx in probs.argsort()[0][::-1][:5]:\n        print(\"{:.2f}%\".format(probs[0][idx]*100), \"\\t\", label_maps_rev[idx].split(\"-\")[-1])\n    \n    \n    tree = ET.parse('..\/output\/kaggle\/working\/'+filename.rstrip(\".jpg\")) # init parser for file given\n    \n    \n    root = tree.getroot() # idk what's it but it's from documentation\n    objects = root.findall('object') # finding all dogs. An array\n    plt.imshow(img) # displays photo\n    for o in objects:\n        bndbox = o.find('bndbox') # reading border coordinates\n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n        plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin]) # showing border\n        plt.text(xmin, ymin, o.find('name').text, bbox={'ec': None}) # printing breed","e43f9596":"filename=\"test_1.jpg\"\ndownload_and_predict(\"https:\/\/bingvsdevportalprodgbl.blob.core.windows.net\/demo-images\/c5c7398b-850b-4a7d-b0d9-ef5e10d97bc0.jpg\",filename)\n","e24937c7":"download_and_predict(\"https:\/\/bingvsdevportalprodgbl.blob.core.windows.net\/demo-images\/3f827498-4989-4e18-bc86-19fe80292e32.jpeg\",'test_2.jpg')","315e0deb":"1.2.1 Define paths (X) and labels (y)","fef477d3":"2.2 Fully connected layer","9cc5830c":"I dont take all the credit for this assigment.\nthere are people that actually has done a greate work on this area see:\nhttps:\/\/www.kaggle.com\/mclikmb4\/xception-transfer-learning-120-breeds-83-acc","a891182c":"7. Predict new images","52b7ae09":"Print cropped images","5b29b1b1":"6. Test model accuracy","2c8e5a4b":"1.2 Generate a data folder with cropped pictures","a2869632":"# 3. TRAINING THE MODEL","2f2eaf93":"1.4 Split X and y into train, validation and test","aefa481d":"5. Save model and parameters","a2cc8247":"2.1 Importing the Xception CNN\u00b6","1efdd32c":"1.3 Define my own image generator with custom augmentation","344f3af3":"1. # Transfer Learning:","301cd4b4":"# Inicio del Entrenamiento con Checkpoint","40db9897":"# 2. MODEL PREPARATION\u00b6"}}