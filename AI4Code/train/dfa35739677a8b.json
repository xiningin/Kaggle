{"cell_type":{"ca28cb93":"code","881c1b21":"code","b4f1d3a8":"code","75cb8306":"code","b4c3fa53":"code","bbf1bc90":"code","b3306c62":"code","c21f5438":"code","d09fed7e":"code","e9071473":"code","2693c937":"code","cdcf45c2":"code","5f838ef4":"code","5c855aa1":"code","c18af414":"code","276d36ef":"code","111addd7":"code","6ed9da41":"code","3b6db8c1":"code","f11e1943":"code","4fb6595d":"code","454ffc5a":"code","c6cf7795":"code","6a584a24":"code","8884d0bd":"code","5a749201":"code","81725043":"markdown","134a9842":"markdown","e706978d":"markdown","81502a06":"markdown","7d364914":"markdown","f290a90b":"markdown","689f2f34":"markdown","9acb1397":"markdown","bac74c4c":"markdown","e383910b":"markdown"},"source":{"ca28cb93":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","881c1b21":"import pandas as pd\ndf=pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Pclass','Age','Fare','Survived'])\ndf.head()","b4f1d3a8":"#Checking the null values\ndf.isnull().sum()","75cb8306":"#Replacing the null values with median\ndf['Age'].fillna(df.Age.median(),inplace=True)","b4c3fa53":"#### standarisation: We use the Standardscaler from sklearn library\nfrom sklearn.preprocessing import StandardScaler\n#creating an object of StandardScaler\nscalar = StandardScaler()","bbf1bc90":"#Fit vs Fit_transform\n#Fit only fits the model whereas fit_transform tranforms the data during fitting","b3306c62":"#fitting the standardscaler object to the dataset and tranforming it using fit_transform\ndf_scaled = scalar.fit_transform(df)\ndf_scaled","c21f5438":"pd.DataFrame(df_scaled).head()","d09fed7e":"plt.hist(df_scaled[:,2],bins=20)","e9071473":"from sklearn.preprocessing import MinMaxScaler\nminmax = MinMaxScaler()\ndf_minmax = pd.DataFrame(minmax.fit_transform(df),columns=df.columns)\ndf_minmax","2693c937":"plt.hist(df_minmax['Age'],bins=20)","cdcf45c2":"from sklearn.preprocessing import RobustScaler\nrobust = RobustScaler()\ndf_robust = pd.DataFrame(robust.fit_transform(df),columns=df.columns)\ndf_robust","5f838ef4":"plt.hist(df_robust['Age'],bins=20)","5c855aa1":"\ndf=pd.read_csv('..\/input\/titanic\/train.csv',usecols=['Age','Fare','Survived'])\ndf.head()","c18af414":"### fillnan\ndf['Age']=df['Age'].fillna(df['Age'].median())","276d36ef":"df.isnull().sum()","111addd7":"import scipy.stats as stat\nimport pylab","6ed9da41":"#### If you want to check whether feature is guassian or normal distributed\n#### Q-Q plot\ndef plot_data(df,feature):\n    plt.figure(figsize=(10,6))\n    plt.subplot(1,2,1)\n    df[feature].hist()\n    plt.subplot(1,2,2)\n    stat.probplot(df[feature],dist='norm',plot=pylab)\n    plt.show()","3b6db8c1":"plot_data(df,'Age') #To check if the coordinates are following the same line (red line)","f11e1943":"df['Age_log']=np.log(df['Age'])\nplot_data(df,'Age_log')","4fb6595d":"df['Age_reciprocal']=1\/df.Age\nplot_data(df,'Age_reciprocal')","454ffc5a":"df['Age_sqaure']=df.Age**(1\/2)\nplot_data(df,'Age_sqaure')","c6cf7795":"df['Age_exponential']=df.Age**(1\/1.2)\nplot_data(df,'Age_exponential')","6a584a24":"df['Age_Boxcox'],parameters=stat.boxcox(df['Age'])","8884d0bd":"print(parameters)","5a749201":"plot_data(df,'Age_Boxcox')","81725043":"## 1. Standardization\nIt is used more in Machine Learning algos\n\nIf the data is with respect to Standard Normal Distribution it is used\n\nIt is most commonly used as it works with most of the algorithms\n\nWe try to bring all the variables or features to a similar scale. Standardization means centering the variable at zero. z=(x-x_mean)\/std","134a9842":"## Robust Scaler\n\nIt is used to scale the feature to median and quantiles Scaling using median and quantiles consists of substracting the median to all the observations, and then dividing by the interquantile difference. The interquantile difference is the difference between the 75th and 25th quantile:\n\nIQR = 75th quantile - 25th quantile\n\nX_scaled = (X - X.median) \/ IQR\n\n0,1,2,3,4,5,6,7,8,9,10\n\n9-90 percentile---90% of all values in this group is less than 9 1-10 precentile---10% of all values in this group is less than 1 4-40%","e706978d":"## 4. Guassian Transformation \nUsed in KNN etc\n\nSome machine learning algorithms like linear and logistic assume that the features are normally distributed \n\n-Accuracy \n\n-Performance\n\n    a. Logarithmic Transformation \n    \n    b. Reciprocal Transformation \n    \n    c. Square Root Transformation \n    \n    d. Exponential Transformation\n    \n    e. Box Cox Transformation","81502a06":"### Square Root Transformation","7d364914":"### Logarithmic Transformation\nFor right skewed it is better","f290a90b":"# Types Of Transformation\n#### 1. Normalization And Standardization\n#### 2. Scaling to Minimum And Maximum values\n#### 3. Scaling To Median And Quantiles\n#### 4. Guassian Transformation \n\n    a. Logarithmic Transformation \n    \n    b. Reciprocal Transformation \n    \n    c. Square Root Transformation \n    \n    d. Exponential Transformation\n    \n    e. Box Cox Transformation","689f2f34":"### Exponential Transdormation","9acb1397":"### BoxCOx Transformation\nThe Box-Cox transformation is defined as:\n\nT(Y)=(Y exp(\u03bb)\u22121)\/\u03bb\n\nwhere Y is the response variable and \u03bb is the transformation parameter. \u03bb varies from -5 to 5. In the transformation, all values of \u03bb are considered and the optimal value for a given variable is selected.","bac74c4c":"### Reciprocal Transformation","e383910b":"## 2. MixMax Scaling\nIt works well with CNN - (Deeplearing)\n\nIt transforms the values between 0 and 1. X_scaled = (X - X.min \/ (X.max - X.min)"}}