{"cell_type":{"85b1c130":"code","85e21270":"code","cae880a4":"code","c281c92a":"code","d79874ed":"code","f6a32473":"code","3dc72cff":"code","9facdb3d":"code","a7dd18cf":"code","69caa5eb":"markdown"},"source":{"85b1c130":"#-------Import Dependencies-------#\n%matplotlib inline\nimport pandas as pd\nimport os,shutil,math,scipy,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random as rn\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix,roc_curve,auc\n\nfrom PIL import Image\nfrom PIL import Image as pil_image\nfrom PIL import ImageDraw\n\nfrom time import time\nfrom glob import glob\nfrom tqdm import tqdm\nfrom skimage.io import imread\nfrom IPython.display import SVG\n\nfrom scipy import misc,ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\n\n\nfrom keras import backend as K\nfrom keras.utils.np_utils import to_categorical\nfrom keras import layers\nfrom keras.preprocessing.image import save_img\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.applications.xception import Xception\nfrom keras.applications.nasnet import NASNetMobile\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\nfrom keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler","85e21270":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('acc')\n    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","cae880a4":"def visualize_layer_kernels(img, conv_layer, title):\n    weights1 = conv_layer.get_weights()\n    kernels = weights1[0]\n    kernels_num = kernels.shape[3]\n    f, ax = plt.subplots(kernels_num, 3, figsize=(7, kernels_num*2))\n\n    for i in range(0, kernels_num):\n        kernel=kernels[:,:,:3,i]\n        ax[i][0].imshow((kernel * 255).astype(np.uint8), vmin=0, vmax=255)\n        ax[i][0].set_title(\"Kernel %d\" % i, fontsize = 9)\n        ax[i][1].imshow((img * 255).astype(np.uint8), vmin=0, vmax=255)\n        ax[i][1].set_title(\"Before\", fontsize=8)\n        img_filt = scipy.ndimage.filters.convolve(img, kernel)\n        ax[i][2].imshow((img_filt * 255).astype(np.uint8), vmin=0, vmax=255)\n        ax[i][2].set_title(\"After\", fontsize=8)\n        \n    plt.suptitle(title)\n    plt.tight_layout()\n    plt.subplots_adjust(top=0.93)\n    plt.show()   ","c281c92a":"train_dir = '..\/input\/lego brick images\/LEGO brick images\/train'\nval_dir ='..\/input\/lego brick images\/LEGO brick images\/valid'\n\n\naugs_gen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,  \n    zoom_range=0.2,        \n    horizontal_flip=True,validation_split=0.2)  \n\ntrain_gen = augs_gen.flow_from_directory(\n    train_dir,\n    target_size = (150,150),\n    batch_size=16,\n    class_mode = 'categorical',\n    shuffle=True\n)\n\ntest_gen = augs_gen.flow_from_directory(\n    val_dir,\n    target_size=(150,150),\n    batch_size=16,\n    class_mode='categorical',\n    shuffle=False\n)","d79874ed":"def ConvBlock(model, layers, filters):\n    for i in range(layers):\n        model.add(Conv2D(filters,(3,3),activation='selu'))\n        model.add(SeparableConv2D(filters, (3, 3), activation='selu'))\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n    \ndef FCN():\n    model = Sequential()\n    model.add(Lambda(lambda x: x, input_shape=(150, 150, 3)))\n    ConvBlock(model, 1, 32)\n    ConvBlock(model, 1, 64)\n    ConvBlock(model, 1, 128)\n    ConvBlock(model, 1, 256)\n    model.add(Flatten())\n    model.add(Dense(1024,activation='selu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(16,activation='softmax'))\n    return model\n\nmodel = FCN()\nmodel.summary()\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True, expand_nested=True)","f6a32473":"#-------Callbacks-------------#\nbest_model_weights = '.\/base.model'\ncheckpoint = ModelCheckpoint(\n    best_model_weights,\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=10,\n    verbose=1,\n    mode='auto'\n)\ntensorboard = TensorBoard(\n    log_dir = '.\/logs',\n    histogram_freq=0,\n    batch_size=16,\n    write_graph=True,\n    write_grads=True,\n    write_images=False,\n)\n\ncsvlogger = CSVLogger(\n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\n\n#lrsched = LearningRateScheduler(step_decay,verbose=1)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=40,\n    verbose=1, \n    mode='auto',\n    cooldown=1 \n)\n\ncallbacks = [checkpoint,tensorboard,csvlogger,reduce]","3dc72cff":"opt = SGD(lr=1e-4,momentum=0.99)\nopt1 = Adam(lr=2e-4)\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n    \nhistory = model.fit_generator(\n    train_gen, \n    steps_per_epoch  = 100, \n    validation_data  = test_gen,\n    validation_steps = 100,\n    epochs = 20, \n    verbose = 1,\n    callbacks=callbacks\n)","9facdb3d":"show_final_history(history)\nmodel.load_weights(best_model_weights)\nmodel_score = model.evaluate_generator(test_gen)\nprint(\"Model Test Loss:\",model_score[0])\nprint(\"Model Test Accuracy:\",model_score[1])\n\nmodel_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save(\"model.h5\")\nprint(\"Weights Saved\")","a7dd18cf":"!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = '.\/logs' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('.\/ngrok http 8080 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n","69caa5eb":"def model_evaluation(history, model, x_test,y_test, field_name):\n    f, ax = plt.subplots(2,1, figsize=(5,5))\n    ax[0].plot(history.history['loss'], label=\"Loss\")\n    ax[0].plot(history.history['val_loss'], label=\"Validation loss\")\n    ax[0].set_title('%s: loss' % field_name)\n    ax[0].set_xlabel('Epoch')\n    ax[0].set_ylabel('Loss')\n    ax[0].legend()\n    \n    ax[1].plot(history.history['acc'], label=\"Accuracy\")\n    ax[1].plot(history.history['val_acc'], label=\"Validation accuracy\")\n    ax[1].set_title('%s: accuracy' % field_name)\n    ax[1].set_xlabel('Epoch')\n    ax[1].set_ylabel('Accuracy')\n    ax[1].legend()\n    plt.tight_layout()\n    plt.show()\n\n    test_pred = model.predict(x_test)\n    \n    acc_by_subspecies = np.logical_and((test_pred > 0.5), y_test).sum()\/y_test.sum()\n    acc_by_subspecies.plot(kind='bar', title='Accuracy by %s' % field_name)\n    plt.ylabel('Accuracy')\n    plt.show()\n\n    print(\"Classification report\")\n    test_pred = np.argmax(test_pred, axis=1)\n    test_truth = np.argmax(y_test.values, axis=1)\n    print(metrics.classification_report(test_truth, test_pred, target_names=y_test.columns))\n\n    test_result = model.evaluate(x_test, y_test.values, verbose=0)\n    print('Loss function: %s, accuracy:' % test_result[0], test_result[1])"}}