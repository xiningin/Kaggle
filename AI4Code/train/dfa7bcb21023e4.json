{"cell_type":{"443d754b":"code","b9899d7a":"code","513c02d6":"code","8765f1d8":"code","a176ee76":"code","e90ebd8b":"code","7c1772c1":"code","cb8cb98f":"code","5aa2b120":"code","fb1c48cd":"code","490918ba":"code","facb7d41":"code","5bb34773":"code","f1db98a7":"code","96c659a9":"code","3a0fcaed":"code","3be32317":"code","4022cb3d":"code","e6d1ca5f":"code","cb5c9c9e":"code","8ac990f1":"code","c69b09d7":"code","6962584c":"code","9389b7f3":"code","c1b5fa52":"code","6b2e579e":"code","3db452e6":"code","09f6c507":"code","58b528fc":"code","0910ca77":"code","aa737592":"code","7cbc4b86":"code","675d415f":"code","361cb023":"code","d8de13d7":"code","27063acc":"code","1f4dff88":"code","bb16c1f5":"code","b23f8565":"code","40f72a9c":"code","323a04c3":"code","3fd1f417":"code","7846359e":"code","9ce056e7":"code","195d60f5":"code","30984256":"code","4f183fc0":"code","a59637c5":"code","c0f0e771":"code","c2bff72d":"code","4631d3a2":"code","60835bc9":"code","5e0ba274":"code","230b1e35":"code","bb7f2f0b":"code","0eb66c9b":"code","3871b32d":"code","08ccc378":"code","236c417c":"code","a6e93d00":"code","77c43913":"code","bc75ee4e":"code","f75aa873":"code","df822c55":"code","3043da24":"code","e93a4f8a":"code","9e6e8771":"code","9457726e":"code","65fb1bde":"code","2a0c4eee":"code","5c81ebef":"code","acee7a52":"code","787b5c77":"code","004c7a4f":"code","13958ed0":"code","12739eaa":"code","3a86eda8":"code","e4785ec6":"code","7c864ab4":"code","ec8c8d1d":"code","389187d4":"code","7bd52ee7":"code","f73200f1":"code","b263e40f":"code","d3e9aaae":"code","1c4e40dc":"code","e8b60ebb":"code","2e202267":"code","9b6d3c3c":"code","bc960a33":"code","dbaaae8b":"code","9babca21":"code","99c81e38":"code","a9440358":"code","f3b25d79":"code","a129ca47":"code","0923f98d":"code","e24d0a1f":"code","82cfac12":"code","d20735e4":"code","f031c5b4":"code","ff8fa227":"code","176aa834":"code","32751de8":"code","c0a5d7a3":"code","d9f1e88c":"code","712de94d":"code","f1558206":"code","70593a1c":"code","9d84e830":"code","9b17eb9a":"code","ef7a05f1":"code","0344f6a6":"code","1c26bcb0":"code","3ed29d7b":"code","ba219a23":"code","a837f713":"code","6789b771":"code","5fb4bb98":"code","02988ce6":"code","2206240a":"code","8358e11f":"code","306d27dc":"code","6a0b1864":"code","4e1ea2e1":"code","c4d3ec0b":"code","8b26632e":"code","740049c1":"code","33b5ba61":"code","09ef133b":"code","8d9e8311":"code","34db1278":"code","be115dc9":"code","889d1dc6":"code","476d4f38":"code","5450192b":"code","6ddec073":"code","701206a8":"code","66bc2630":"code","0e79d218":"code","9599a030":"code","ff4a6691":"code","7ea1815b":"code","284e7d71":"code","a8eb087d":"code","1c09b215":"code","288a8c45":"code","66628dea":"code","42b7f554":"code","d8dd7cf0":"code","b2c9e4dd":"code","558fccf7":"code","2578004c":"code","570e2baa":"code","26e39516":"code","a40e3f53":"code","102216bc":"code","ffc7c32e":"code","62d0c86a":"code","2a33c8a0":"code","8e51a05a":"code","33ff5bb2":"code","18f5d054":"markdown","5f44bb68":"markdown","1a7dbb0b":"markdown","5db8fc97":"markdown","62b55a61":"markdown","ae8a3c05":"markdown","fdf04238":"markdown","d9d4935e":"markdown","c2ddb46a":"markdown","b74852c7":"markdown","fffa693b":"markdown","807a373a":"markdown","2292732a":"markdown","6888f9d0":"markdown","6688555a":"markdown","a732f66f":"markdown","3b376b86":"markdown","71095393":"markdown","ab0b9cb4":"markdown","0343bac5":"markdown","80ad0962":"markdown","c36c5b69":"markdown","29461e45":"markdown","8ab00372":"markdown","c9083118":"markdown","6490c921":"markdown","4d0bd11b":"markdown","496873c0":"markdown","cc565f32":"markdown","6995fb04":"markdown","6eea1e75":"markdown","e60b9143":"markdown","0653c449":"markdown","e2ea1c02":"markdown","ea538d75":"markdown","342e0fe2":"markdown","5c39912b":"markdown","ffc9722e":"markdown","0e46c414":"markdown","b4f83a01":"markdown","b8ffb300":"markdown","c9edd218":"markdown","488e565f":"markdown","3b5e921d":"markdown","740bfd27":"markdown","3c615a9a":"markdown","633844e3":"markdown","7e5e2ab1":"markdown","4af26658":"markdown","e52bbfe9":"markdown","8b48b1b4":"markdown","a1431fd7":"markdown","c19ee3d8":"markdown","45e73ea2":"markdown","099c909f":"markdown","a1342a1f":"markdown","8b9d95c7":"markdown","099c6c6c":"markdown","a7e4047b":"markdown","9834668f":"markdown","e9e70256":"markdown","9d84877e":"markdown","8c2ac841":"markdown","43bd77b5":"markdown","82a218e9":"markdown","6f5fc12d":"markdown","06bf7938":"markdown","ea779094":"markdown","ab026dd0":"markdown","b95717ce":"markdown","22eba7ae":"markdown","fa189097":"markdown","05f79d7b":"markdown","c12f0bf8":"markdown","27df11e6":"markdown","39daf3d3":"markdown","22f7ab70":"markdown","9480abc8":"markdown","836a5453":"markdown","6d551d73":"markdown","cf76964e":"markdown","af2ac59f":"markdown","b70f8820":"markdown","776bddc1":"markdown","222923d4":"markdown","dd9220f9":"markdown","223e124f":"markdown","807b7624":"markdown","5b567475":"markdown","e673bc5d":"markdown","19343670":"markdown","5bfe05cf":"markdown","e529591c":"markdown","47f51033":"markdown","3dbe70da":"markdown","b64ec235":"markdown","076ad23c":"markdown","b27dcc98":"markdown","3636f548":"markdown","71bde22f":"markdown","170ed95f":"markdown","469a8be9":"markdown","55a3be08":"markdown","b75761be":"markdown","305d763c":"markdown","7635eaaa":"markdown","e3838ee0":"markdown","616caad4":"markdown","d2264952":"markdown","554170b8":"markdown","526f9a4d":"markdown","4bd58ff7":"markdown","aeae317b":"markdown","b173365b":"markdown","279d5bc4":"markdown","f5998183":"markdown","48310c46":"markdown","828f3fe5":"markdown","5509b357":"markdown","f57d8bcd":"markdown","7e0dc630":"markdown"},"source":{"443d754b":"import pandas as pd\nimport numpy as np\nimport warnings\nimport regex as re\nwarnings.filterwarnings('ignore')#to filter all the warnings\nimport seaborn as sns\npd.set_option('float_format', '{:.4f}'.format)# to keep the float values short\n# Import for wordcloud\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\n#import fot plotly\nimport plotly.express as px","b9899d7a":"\nUS_Videos_df = pd.read_csv('..\/input\/youtube-trending-video-dataset\/US_youtube_trending_data.csv')\nUS_Videos_df.head(1)","513c02d6":"CA_Videos_df = pd.read_csv('..\/input\/youtube-trending-video-dataset\/CA_youtube_trending_data.csv')\nCA_Videos_df.head(1)","8765f1d8":"GB_Videos_df = pd.read_csv('..\/input\/youtube-trending-video-dataset\/GB_youtube_trending_data.csv')\nGB_Videos_df.head(1)","a176ee76":"print('Shape of GB File: '+ str(GB_Videos_df.shape))\nprint('Shape of CA File: '+ str(CA_Videos_df.shape))\nprint('Shape of US File: '+ str(US_Videos_df.shape))","e90ebd8b":"import json #import data using python json module\nwith open('..\/input\/youtube-trending-video-dataset\/US_category_id.json','r') as f:\n    category_data_us= json.loads(f.read())","7c1772c1":"with open('..\/input\/youtube-trending-video-dataset\/CA_category_id.json','r') as f:\n    category_data_ca= json.loads(f.read())","cb8cb98f":"with open('..\/input\/youtube-trending-video-dataset\/GB_category_id.json','r') as f:\n    category_data_gb= json.loads(f.read())","5aa2b120":"US_cat = pd.json_normalize(category_data_us,record_path='items')\nCA_cat = pd.json_normalize(category_data_ca,record_path='items')\nGB_cat = pd.json_normalize(category_data_gb,record_path='items')","fb1c48cd":"# Converting the 'id' extracted from the json file to type 'int'\nUS_cat['id']= US_cat['id'].astype(int)\nCA_cat['id']= CA_cat['id'].astype(int)\nGB_cat['id']= GB_cat['id'].astype(int)","490918ba":"US_Videos_df= US_Videos_df.merge(US_cat,how ='left',left_on= 'categoryId',\\\n                                 right_on='id').rename(columns= {'snippet.title':'category_name'})\nCA_Videos_df= CA_Videos_df.merge(CA_cat,how ='left',left_on= 'categoryId',\\\n                                 right_on='id').rename(columns= {'snippet.title':'category_name'})\nGB_Videos_df= GB_Videos_df.merge(GB_cat,how ='left',left_on= 'categoryId',\\\n                                 right_on='id').rename(columns= {'snippet.title':'category_name'})","facb7d41":"print('Shape of GB File: '+ str(GB_Videos_df.shape))\nprint('Shape of CA File: '+ str(CA_Videos_df.shape))\nprint('Shape of US File: '+ str(US_Videos_df.shape))","5bb34773":"US_Videos_df['country']= 'USA'\nCA_Videos_df['country']= 'Canada'\nGB_Videos_df['country']= 'Great Britain'","f1db98a7":"US_Videos_df.head(1)","96c659a9":"df_list= [US_Videos_df,CA_Videos_df,GB_Videos_df]","3a0fcaed":"df= pd.concat(df_list).reset_index(drop=True)","3be32317":"df.groupby('country')['video_id'].count()","4022cb3d":"df.shape","e6d1ca5f":"df.drop(columns=['thumbnail_link','kind','etag','id','snippet.assignable','snippet.channelId','channelId'], axis='columns').shape","cb5c9c9e":"df.drop(columns=['thumbnail_link','kind','etag','id','snippet.assignable',\\\n                 'snippet.channelId','channelId'], axis='columns',inplace=True)","8ac990f1":"df.head(1)","c69b09d7":"df[df.comments_disabled==True]['comment_count'].head()","6962584c":"df[df.ratings_disabled==True][['likes','dislikes']].sample(5)","9389b7f3":"df[df.comments_disabled==True].comment_count.sum()","c1b5fa52":"df[df.ratings_disabled==True][['likes','dislikes']].sum()","6b2e579e":"df.drop(columns=['comments_disabled','ratings_disabled'],axis=1,inplace=True)","3db452e6":"df.shape","09f6c507":"df.isna().sum()","58b528fc":"df[df.category_name.isna()].head()","0910ca77":"df[df.categoryId==29].category_name","aa737592":"df[df.category_name.isna()]['title'].unique()","7cbc4b86":"df.category_name.fillna('Nonprofits & Activism').isna().any()","675d415f":"df.category_name.fillna('Nonprofits & Activism',inplace=True)","361cb023":"df.description.fillna('')","d8de13d7":"df.description.fillna('').isna().any()","27063acc":"df.description.fillna('',inplace=True)","1f4dff88":"df.tags.sample(4)","bb16c1f5":"df.title.sample(4)","b23f8565":"df.channelTitle.sample(4)","40f72a9c":"df.description.sample(4)","323a04c3":"def isEnglish(s):\n    try:\n        s.encode('ascii')\n    except UnicodeEncodeError:\n        return False\n    else:\n        return True","3fd1f417":"isEnglish('slabiky, ale li\u0161\u00ed se podle v\u00fdznamu')","7846359e":"isEnglish('This sentence is in English')","9ce056e7":"def removeNonEnglishWords(text):\n    filteredText = []\n    for word in text.split():\n        if isEnglish(word):\n            filteredText.append(word)\n    \n    return \" \".join(filteredText)\n        ","195d60f5":"text = \"\u2023 what was tekoi:  tekoi commentary:   old version of tekoi:  crowdfundersbob kunz, john buchan, nevin spoljaric, donal botkin, bn-12, chris chapin, richard jenkins, phil gardner, martin, steven grimm, \u0633\u0644\u064a\u0645\u0627\u0646 \u0627\u0644\u0639\u0642\u0644, david f watson, colin millions, saki comandao, ben schwab, jason lewandowski, marco arment, shantanu raj, rictic, emptymachine, george lin, henry ng, thunda plum, awoo, david tyler, fuesu, iulus, jordan earls, joshua jamison, nick fish, nick gibson, tyler bryant, zach whittle, oliver steele, kermit norlund, kevin costello, derek bonner, derek jackson, mikko , orbit_junkie, ron bowes, t\u00f3mas \u00e1rni j\u00f3nasson, bryan mclemore, alex simonides, felix weis, melvin sowah, christopher mutchler, giulio bontadini, paul alom, ryan tripicchio, scot melville, bear, chrysilis, david palomares, emil, erik parasiuk, esteban santana santana, freddi h\u00f8rlyck, john rogers, leon, peter lomax, rhys parry, shiroiyami, tristan watts-willis, veronica peshterianu, dag viggo lok\u00f8en, john lee, maxime zielony, julien dubois, elizabeth keathley, nicholas welna## musicdavid rees:\"\nprint(removeNonEnglishWords(text))","30984256":"df['isEnglish'] = df.description.apply(lambda s: isEnglish(s))","4f183fc0":"df.isEnglish.value_counts()","a59637c5":"df[df.isEnglish==False].description","c0f0e771":"df['des']= df.description.apply(removeNonEnglishWords)","c2bff72d":"df[['description','des']].sample(5)","4631d3a2":"df.drop(columns=['description','isEnglish'],axis=1,inplace=True)","60835bc9":"df['isEnglish'] = df.tags.apply(lambda s: isEnglish(s))\ndf[df.isEnglish==False].tags.count()# finding the number of tags that consists of non english characters","5e0ba274":"df['c_tags']= df.tags.apply(removeNonEnglishWords)","230b1e35":"df.drop(columns=['isEnglish','tags'],axis=1,inplace=True)","bb7f2f0b":"df['isEnglish'] = df.title.apply(lambda s: isEnglish(s))\ndf[df.isEnglish==False].title.count()","0eb66c9b":"df['c_title']= df.title.apply(removeNonEnglishWords)","3871b32d":"df.drop(columns=['isEnglish','title'],axis=1,inplace=True)","08ccc378":"df['isEnglish'] = df.channelTitle.apply(lambda s: isEnglish(s))\ndf[df.isEnglish==False].channelTitle.count()","236c417c":"df['channel_title']= df.channelTitle.apply(removeNonEnglishWords)","a6e93d00":"df.drop(columns=['channelTitle','isEnglish'],axis=1,inplace=True)","77c43913":"#remove links from the description\ndf.des= df.des.str.replace('http\\S+|www.\\S+',''\\\n                                     ,regex=True).str.replace('\\r+',''\\\n                                     ,regex= True).str.lower()\n#removing Punctuation from description\ndf.des = df.des.str.replace(r'[^\\w\\s]+', '')","bc75ee4e":"#replacing | from tags with a space and converting the text to lowercase\ndf.c_tags= df.c_tags.str.replace('|', ' ').str.lower()\n#removing punctuation if any from tags\ndf.c_tags = df.c_tags.str.replace(r'[^\\w\\s]+', '')\n#Replacing None in tags to ''\ndf.c_tags = df.c_tags.str.replace('none','')\ndf[df.c_tags=='none'].head(1)","f75aa873":"#replacing | from title with a space and converting the text to lowercase\ndf.c_title= df.c_title.str.replace('|', ' ').str.lower()\n#remove links from the title\ndf.c_title= df.c_title.str.replace('http\\S+|www.\\S+',''\\\n                                     ,regex=True).str.replace('\\r+',''\\\n                                     ,regex= True).str.lower()\n#removing punctuation if any from title\ndf.c_title = df.c_title.str.replace(r'[^\\w\\s]+', '')","df822c55":"#replacing | from channel_title with a space \ndf.channel_title= df.channel_title.str.replace('|', ' ')\n#removing punctuation if any from title\ndf.channel_title = df.channel_title.str.replace(r'[^\\w\\s]+', '')","3043da24":"df.isna().any().sum()","e93a4f8a":"df.sample(2)","9e6e8771":"df.dtypes","9457726e":"df['publishedAt']=pd.to_datetime(df.publishedAt)\ndf['publishedAt'] = df['publishedAt'].dt.tz_convert(None)\ndf['trending_date']=pd.to_datetime(df.trending_date)\ndf['trending_date'] = df['trending_date'].dt.tz_convert(None)\ndf['country']= df['country'].astype('category')","65fb1bde":"df.dtypes","2a0c4eee":"df.isna().any().sum()","5c81ebef":"df.rename(columns={\"publishedAt\": \"published_at\",\"categoryId\" : \"category_id\"\\\n                   ,'des':'description','c_tags':'tags','c_title':'video_title'}, inplace = True)","acee7a52":"df.head(1)","787b5c77":"df[df.likes>df.view_count].sample(2)","004c7a4f":"df.drop(df[df.likes>df.view_count].index,inplace=True)","13958ed0":"df.reset_index(drop=True, inplace=True)","12739eaa":"df.set_index('video_id',inplace=True)\ndf.to_csv('Clean_Dataset_final.csv.zip')","3a86eda8":"df.shape","e4785ec6":"df.reset_index(inplace = True)","7c864ab4":"df.head(1)","ec8c8d1d":"\ndf_US = df[df.country == 'USA']\ndf_US = df_US.drop_duplicates(subset=['video_id'], keep='last')\ndf_US_category_counts = df_US.groupby(['trending_date', 'category_name'], as_index=False)['view_count'].sum()","389187d4":"df_US_category_counts['trending_date'] = pd.to_datetime(df_US_category_counts['trending_date']).dt.date\ndf_US_news_count = df_US_category_counts[df_US_category_counts.category_name == 'News & Politics']","7bd52ee7":"labels = {'view_count': 'View Count (Millions)', 'trending_date': 'Trending Date'}\nfig = px.line(df_US_news_count, x='trending_date', y='view_count', title='View Count Time Series for category: News & Politics (USA)', labels=labels)\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.update_layout(title_x=0.5)\nfig.show()","f73200f1":"# To increase the figure size\nplt.rcParams['figure.figsize'] = [10, 5]\n\n# Adding unwanted words and social media tags to stopword list:\nstopwords = set(STOPWORDS)\nstopwords.update(['follow', 'twitter', 'social', 'instagram', 'subscribe', 'snapchat', 'youtube', 'videos', 'video'\\\n                  ,'channel', 'share', 'facebook', 'comment', 'like', 'take', 'go', 'got', 'back',\\\n                  'much', 'made', 'keep', 'watch','none', 'check', 'will', 'make'])\ndef generate_wordcloud(text, stop_words):\n    wordcloud = WordCloud(stopwords=stop_words,max_font_size=50, max_words=150, background_color=\"white\").generate(text)\n    plt.figure()\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()","b263e40f":"category = 'News & Politics'\ndateMask = (df_US.trending_date > pd.Timestamp(2020,10,1)) & (df_US.trending_date < pd.Timestamp(2020,12,1))","d3e9aaae":"tag_text = \" \".join(text for text in df_US.tags[(df_US.category_name == category ) & (dateMask)])\ntitle_text = \" \".join(text for text in df_US.video_title[(df_US.category_name == category ) & (dateMask) ])\ntag_title_text = tag_text + ' ' + title_text\ngenerate_wordcloud(tag_title_text, stopwords)","1c4e40dc":"category = 'News & Politics'\ndateMask = (df_US.trending_date > pd.Timestamp(2021,4,30)) & (df_US.trending_date < pd.Timestamp(2021,6,1))","e8b60ebb":"tag_text = \" \".join(text for text in df_US.tags[(df_US.category_name == category ) & (dateMask)])\ntitle_text = \" \".join(text for text in df_US.video_title[(df_US.category_name == category ) & (dateMask) ])\ntag_title_text = tag_text + ' ' + title_text\ngenerate_wordcloud(tag_title_text, stopwords)","2e202267":"sns.countplot(y='category_name',data=df,hue='country',\\\n              order=df.category_name.value_counts().iloc[:10].index,hue_order=['USA','Great Britain','Canada'])","9b6d3c3c":"category_list = ['Entertainment', 'Sports']","bc960a33":"for category in category_list:\n    print(\"Category: \"+category)\n    tag_text = \" \".join(text for text in df.tags[(df.category_name == category )& (df.country == 'USA')])\n    title_text = \" \".join(text for text in df.video_title[(df.category_name == category )& (df.country == 'USA')])\n    tag_title_text = tag_text + ' ' + title_text\n    generate_wordcloud(tag_title_text, stopwords)","dbaaae8b":"for category in category_list:\n    print(\"Category: \"+category)\n    tag_text = \" \".join(text for text in df.tags[(df.category_name == category )& (df.country == 'Great Britain')])\n    title_text = \" \".join(text for text in df.video_title[(df.category_name == category )& (df.country == 'Great Britain')])\n    tag_title_text = tag_text + ' ' + title_text\n    generate_wordcloud(tag_title_text, stopwords)","9babca21":"df = pd.read_csv('Clean_Dataset_final.csv.zip')","99c81e38":"df.info()","a9440358":"df.drop_duplicates(subset=['video_id'], keep='last', inplace = True)","f3b25d79":"df.drop(columns=['channel_title','video_id','published_at', 'category_id','trending_date',\\\n                 'view_count', 'likes', 'dislikes', 'comment_count', 'country'],axis=1,inplace=True)","a129ca47":"df.fillna(value = '', inplace = True)","0923f98d":"# Combining all text data in a single column:\n\ndf['All_text'] = df.description + ' ' + df.tags + ' ' + df.video_title","e24d0a1f":"pd.set_option(\"display.max_colwidth\", -1)","82cfac12":"df.head(1)","d20735e4":"df.drop(columns=['description', 'tags', 'video_title'],axis=1,inplace=True)","f031c5b4":"df.head(1)","ff8fa227":"def preprocessing(text):\n    stemmer = PorterStemmer()\n    processed_text = ''\n    for word in text.split():\n        if not word in stopwords:\n            processed_text += stemmer.stem(word) + \" \"\n\n    return processed_text","176aa834":"test = \"today i show you how to make a curried egg sandwich curried egg sandwiches are my favourite snack they are easy to make and incredibly tasty unfortunately not many people know how to make one correctly that changes today enjoyclick here to eggscribe a video suggestion post it in the comments section contact me through my facebook page or tweet meconnect with mefacebook channel howtobasic shirts and egg plushies someone that likes curried egg sandwiches link this delicious recipe to them how to make a curried egg sandwich curried egg egg sandwich recipe egg recipe how to make a sandwich curried egg sandwich recipe easy recipe curry recipe how to make curry food step by step recipes healthy recipes egg salad sandwich recipe how to make a curried egg sandwich\"","32751de8":"preprocessing(test)","c0a5d7a3":"df['All_text'] = df['All_text'].apply(preprocessing)","d9f1e88c":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier","712de94d":"df.category_name.value_counts()","f1558206":"df_filtered = df[df.category_name.isin(['Entertainment', 'Sports', 'Music', 'Gaming', \\\n                                        'People & Blogs', 'Comedy','News & Politics'])]","70593a1c":"X = df_filtered.All_text","9d84e830":"Y = df_filtered.category_name","9b17eb9a":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state = 0)","ef7a05f1":"# Applying bag of words to features in training and testing data\nbag_of_words_creator = CountVectorizer()\nX_train_bow = bag_of_words_creator.fit_transform(X_train)\nX_test_bow = bag_of_words_creator.transform(X_test)","0344f6a6":"#cl = RandomForestClassifier(random_state = 0, n_estimators=1000)\ncl = RandomForestClassifier(random_state = 0)\ncl.fit(X_train_bow,Y_train)","1c26bcb0":"y_pred = cl.predict(X_test_bow)","3ed29d7b":"from sklearn.metrics import confusion_matrix\nimport sklearn.metrics as met","ba219a23":"confusion_matrix(Y_test,y_pred)","a837f713":"print(met.classification_report(Y_test,y_pred))","6789b771":"tfidf_creator = TfidfVectorizer()\nX_train_tfidf = tfidf_creator.fit_transform(X_train)\nX_test_tfidf = tfidf_creator.transform(X_test)","5fb4bb98":"#cl = RandomForestClassifier(random_state = 0, n_estimators=1000)\ncl = RandomForestClassifier(random_state = 0)\ncl.fit(X_train_tfidf,Y_train)","02988ce6":"y_pred = cl.predict(X_test_tfidf)","2206240a":"confusion_matrix(Y_test,y_pred)","8358e11f":"print(met.classification_report(Y_test,y_pred))","306d27dc":"df = pd.read_csv('Clean_Dataset_final.csv.zip')","6a0b1864":"ML_df= df.groupby(['video_id','trending_date','published_at'],as_index=False).agg({'view_count':\\\n                                                             'max','likes':'max','dislikes':'max','comment_count':'max'})","4e1ea2e1":"ML_df[ML_df.video_id=='9Lhbm87KmOc']","c4d3ec0b":"df1 = ML_df.copy()","8b26632e":"df1.info()","740049c1":"df1['trending_date'] = pd.to_datetime(df1['trending_date'])\ndf1['published_at'] = pd.to_datetime(df1['published_at'])","33b5ba61":"df1['trending_day_no'] = df1.groupby(['video_id'])[\"trending_date\"].rank('first',ascending=True)","09ef133b":"df1_count = df1.groupby('video_id',as_index=False)[\"trending_date\"].count().rename(columns={\\\n                                                                'trending_date':'total_trending_days'})","8d9e8311":"df2 = df1.merge(df1_count, left_on='video_id', right_on='video_id')\ndf2.head()","34db1278":"df2.corr()","be115dc9":"df2[df2['video_id'] == '9Lhbm87KmOc']","889d1dc6":"df2.info()","476d4f38":"df2['published_year'] = df2.published_at.dt.year\ndf2['published_month'] = df2.published_at.dt.month\ndf2['published_day'] = df2.published_at.dt.day\ndf2['published_hour'] = df2.published_at.dt.hour\ndf2['published_minute'] = df2.published_at.dt.minute\ndf2['published_week'] = df2.published_at.dt.week","5450192b":"df2.drop(columns=['video_id', 'trending_date', 'published_at'],inplace=True) ","6ddec073":"df2.head()","701206a8":"X = df2.drop('total_trending_days',axis=1)\nY = df2.total_trending_days","66bc2630":"import sklearn.tree","0e79d218":"dt = sklearn.tree.DecisionTreeRegressor(max_depth = 2)","9599a030":"dt.fit(X,Y)","ff4a6691":"Y.mean()","7ea1815b":"import sklearn.tree as tree\nfrom IPython.display import Image  \nimport pydotplus\n\ndt_feature_names = list(X.columns)\ndt_target_names = np.array(Y.unique(),dtype=np.string_) \ntree.export_graphviz(dt, out_file='tree.dot', \n    feature_names=dt_feature_names, class_names=dt_target_names,\n    filled=True)  \ngraph = pydotplus.graph_from_dot_file('tree.dot')\nImage(graph.create_png())","284e7d71":"Y.value_counts()","a8eb087d":"trending_days_binned = pd.cut(Y, bins= [0,4,9,40])\ntrending_days_binned_count = trending_days_binned.value_counts().rename_axis('Binned_Trending_Days').reset_index(name = 'Count')","1c09b215":"sns.catplot( y='Count',x='Binned_Trending_Days',\\\n            data=trending_days_binned_count,kind='bar', aspect = 2)","288a8c45":"X = df2.drop('total_trending_days',axis=1)\nY = df2.total_trending_days","66628dea":"from sklearn.model_selection import train_test_split","42b7f554":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y,\n                            test_size=0.3,random_state=0)","d8dd7cf0":"from sklearn import linear_model","b2c9e4dd":"regr = linear_model.LinearRegression()","558fccf7":"regr.fit(X_train,Y_train)","2578004c":"y_pred = regr.predict(X_test)","570e2baa":"y_pred","26e39516":"print(\"Coefficients: \\n\", regr.coef_)","a40e3f53":"r2_score=sklearn.metrics.r2_score(Y_test, y_pred)","102216bc":"print(\"Coefficient of determination: %.2f\" % r2_score)","ffc7c32e":"(y_pred-Y_test).abs().mean()","62d0c86a":"((y_pred-Y_test)**2).mean()","2a33c8a0":"from sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import SVR\n\nregs = [Lasso(), ElasticNet(), DecisionTreeRegressor(), GradientBoostingRegressor(), MLPRegressor()]\n ","8e51a05a":"from sklearn.model_selection import KFold","33ff5bb2":"minMAD = 10000000\nnfolds = 3\nbestREG = ''\n\nfor reg in regs:\n    kf = KFold(n_splits=nfolds,random_state=0,shuffle=True)\n    mad = sklearn.model_selection.cross_val_score(reg,X,Y,\\\n             cv=kf,scoring='neg_mean_absolute_error').mean()\n    # need the lowest scoring for mad\n    print (str(reg)[:25] + ' with mad= ' + str(mad) )\n    if mad < minMAD:\n        minMAD = mad\n        bestREG = reg\n        \nprint('***********************************************')\nprint ('Best Regressor is... ' + str(bestREG)[:25] )\nprint('**********************')\nprint ('With MAD Score ' + str(minMAD))","18f5d054":"# YouTube Trending Videos Analysis","5f44bb68":"### Metrics","1a7dbb0b":"#### Defining a function to remove stop words and perform word stemming(which converts word into it's root form)","5db8fc97":"#### For categoryID=29 , USA has a category name NonProfits&Activism whereas CA,GB did not define a categoryname. By taking a look at the Video title of those records,we can come to a conclusion that they represent  NonProfits&Activists category. So, replacing Nan's with NonProfits&Activism.","62b55a61":"#### Confusion Matrix","ae8a3c05":"### The function defined below checks if the text contains non english characters or not","fdf04238":"#### Doing prediction for categories with higher value counts to keep the dataset balanced\n\n-df_filtered - the dataframe only with categories 'Entertainment', 'Sports', 'Music', 'Gaming','People & Blogs', 'Comedy','News & Politics'","d9d4935e":"### FINDING 1: ","c2ddb46a":"##### Tags cleaning:","b74852c7":"### Make X,Y","fffa693b":"#### Finding the coefficients","807a373a":"### FINDING 3: (MACHINE LEARNING)","2292732a":"#### Summary: It can be inferred form the above wordcloud that the May-July 2021 spike was caused due to 2 major happenings:\n#### 1. Hamas attacks on israel\n#### 2. Deadly Covid-19 second wave in India","6888f9d0":"### Rename the columns for easier understanding and uniformity","6688555a":"##### The records with True values in Comments_disabled and ratings_disabled have 0 corresponding values(likes, dislikes,comment_count).Hence the data is coherent and it is safe to drop the above 2 columns","a732f66f":"### Finding the shape of these 3 dataframes","3b376b86":"### INSIGHT: Trending Videos with words on sensational happenings in tags and Titles are tending to be viewed more. We can also say that YouTube is biased towards choosing such videos in its Trending Tab. So, if content creators wants to make it to trending Tab, using such words will give the video higher chances to get to trending.\n","71095393":"### USA","ab0b9cb4":"Train and predict with LinearRegession","0343bac5":"### INSIGHT:\n\n### Knowing what is trending in videos could help businesses target advertisements specific to viewer country and taste. \n","80ad0962":"#### Mean Squared Error\/MSE","c36c5b69":"### Stopword Removal and Word Stemming","29461e45":"### Adding a column 'country' to identify country specific information after appending the 3 countries - USA, Great Britain, Canada","8ab00372":"#### Dropping columns except title description and tags which will help us to predict category","c9083118":"#### 1. Converting published_at, trending_date to datetime and removing time zones\n#### 2. Converting country to category","6490c921":"### Checking for Null values","4d0bd11b":"#### Finding if there are any True values in comments_disabled and ratings_disabled columns, which represents that comment_count is 0 if  comments_disabled is True, and likes ,dislikes should be 0 if ratings_disabled is True","496873c0":"#### --------------------------------------------------------------------------------------------------------------","cc565f32":"#### There are null values in category_name and description\n#### 1. Dealing with Category_name null values \n#### 2. Dealing with description null values","6995fb04":"###  We observed few records with likes and dislikes greater than  view_count, which is practically impossible.\n##### Dropping records with likes > view_count.","6eea1e75":"#### NOVEMBER 2020","e60b9143":"#### Mean Absolute Error and Mean Absolute deviation","0653c449":"##### We observed that Entertainment and Sports are most popular and  anlaysed these two categories to present the contrast.","e2ea1c02":"#### FINDING: There are 2 unusual spikes with significantly more views in the month of November  2020 and between May and July2021 ","ea538d75":"##### adding a new feature c_tags (with cleaned tags ) into the dataframe","342e0fe2":"### TFIDF Concept: It is another form of feature representation of textual data. In simple words, it assigns weight to every word depending on how unique a word is to a given document. Weight of every word is proportional to the frequency of that word in it's own document\/text and inversly proportional to occurence in the other documents\/texts","5c39912b":"# Data Cleaning","ffc9722e":"#### Understanding data in descriptive columns","0e46c414":"### Converting Datatypes for Analysis\n","b4f83a01":"To find the popular categories by country","b8ffb300":"### Importing required libraries:","c9edd218":"**3. Merging videos dataframe and category dataframe for all countries using left join**","488e565f":"#### Checking data for a specific video_id","3b5e921d":"#### MAY-JULY 2021","740bfd27":"### Opening JSON file and loading the required data to match categoryId to its respective category name:\n\nThe dataset we downloaded from Kaggle has two types of files for each country, one is 'video.csv' which contains all the features described before, and the other is 'category.json' which contains mapping for category id to category names.\n\nTo merge this information together, we did the following steps:\n\n**1. Load JSON File for each country**","3c615a9a":"Splitting X and Y for training and test","633844e3":"## Dataset Description","7e5e2ab1":"#### ","4af26658":"#### Since we are predicting multiclass, we cannot calculate AUC acore in our scenario","e52bbfe9":"### File type: csv\n<ol>\n    <li>video_id: Uniquely identifies each video<\/li>\n    <li>published_at: Date and Time of video published<\/li>\n    <li>categoryId: Id of category the video belongs to<\/li>\n    <li>trending_date: Date and time when the video got to Trending<\/li>\n    <li>view_count: Number of views (cumulative)<\/li>\n    <li>likes: Number of Likes(cumulative)<\/li>\n    <li>dislikes: Number of dislikes(cumulative)<\/li>\n    <li>comment_count: Number of comments(cumulative)<\/li>\n    <li>country: Country in which the video was trending<\/li>\n    <li>description: Description of video by the creator<\/li>\n    <li>tags: Tags of the video by the creator<\/li>\n    <li>title: Title of the video<\/li>\n    <li>channelTitle: Channel Title of the video<\/li>\n    <li>thumbnail_link:link for thumbnails<\/li>\n    <li>comments_disabled: boolean value that defines if viewer can comment<\/li>\n    <li>ratings_disabled: boolean value that defines if viewer can rate through likes and dislikes<\/li>\n    <li>channelId: uniquely defines the channel the video is coming from<\/li>\n<\/ol>\n\n### File type: json\n<ol>\n<li>id: Id of category the video belongs to<\/li>\n<li>name: Respective category names of category ids<\/li>  \n<\/ol>\n","8b48b1b4":"## Managerial Insight: \n- From this ML Model, We can find out the missing category of any video, based on the information obtained from title, tag and description\n         \n- A platform like youtube can use this model to recommend the category to the users by doing real time analysis on title, tag and description while they are uploading their videos","a1431fd7":"### Function to remove non english characters from the text:","c19ee3d8":"**2. Since JSON file was in nested format we used json normalize function from pandas to flatten it and read into data frame**\n\n","45e73ea2":"### Data coherency","099c909f":"Resetting index after dropping few rows","a1342a1f":"Visualize the tree","8b9d95c7":"#### Coefficient Determination","099c6c6c":"Build and Train","a7e4047b":"#### For each video_id and trending_date extract the maximun view_count,Likes,Dislikes,Comment_count ","9834668f":"## Cleaned Dataset Description","e9e70256":"#### We analyzed various categories but found interesting insights in category 'News and Politics' so chossing it for further analysis","9d84877e":"### FINDING 2:","8c2ac841":"### Removing links and converting all the relevant text columns to lowercase","43bd77b5":"\n### Now the Dataset looks clean for some exploration","82a218e9":"#### 1. Dealing with null values in category_name","6f5fc12d":"#### False--- indicates the presence of non- English characters in description\n#### True---- indicates all the words in its description are in English","06bf7938":"#### Making a list of all countries and using pd.concat function to append data for all countries in one dataframe","ea779094":"##### Channel_Title","ab026dd0":"#### From the above code, des column has only the words in that are in English .So it is safe to drop Description and isEnglish(flag) column.","b95717ce":"#### Calculating total trending days for each video","22eba7ae":"#### Creating a flag to check if each record in description is in English","fa189097":"#### Classification for Prediction","05f79d7b":"### Data Correctness","c12f0bf8":"#### The above code has cleaned tilte column and stored into c_title column and hence we are dropping isEnglish and tiltle column from df","27df11e6":"#### Each video trends for multiple days so we are creating a new feature 'trending_day_no' which will give us the current trending day number for each record\n- We are adding this feature to retain the metrics like likes, dislikes, view, comment_count for each trending day number\n- To use it for predicting how many more days a video can trend","39daf3d3":"### Importing individual .csv file of USA, Great Britain, Canada from Home directory:","22f7ab70":"### -------------------------------------Verified clean data for analysis---------------------------------------------------------","9480abc8":"#### cross checking the values to see all the days a video was trending","836a5453":"#### The above code is a proof that the columns mentioned are safely dropped without disturbing the rows.So,using inplace= True parameter with drop","6d551d73":"### Bag of Words Model: It is represnetation of text that describes the occurence of words within a document. We use this to convert text into numerical representation and use it in the classification model","cf76964e":"Resetting index back as we set index to Video_id for writing the file to csv","af2ac59f":"#### Calculating best regressor for the dataset","b70f8820":"#### Applying the filter for country = USA and keeping only one unique record for a video. For each trending date and category name perform a groupby and get the view count","776bddc1":"### Goal:To find what tags and titles are mostly used in popular categories? Does Americans prefer certain Tags and titles over the British?","222923d4":"#### Confusion Matrix","dd9220f9":"#### Using classification report which gives us metric like 'precision', 'recall'and 'f1 score' for all the categories taken into consideration","223e124f":"#### Tree Interpretation: If the trending days are less than 11.5, we can predict with higher accuracy total number of trending days for a video since on an average video trends for approximately 6 days. Since the data for videos which trend for more than 12 days is very less we see a high MSE score on the right side of the tree","807b7624":"Goal is to find the predictor which minimized the cross-validated MAD","5b567475":"### With this step all the text columns are cleaned to be in English and lower case without any links or puntuation or special characters in them.","e673bc5d":"#### Prepare the dataset fo Machine learning","19343670":"### Summary: It can be inferred from the wordcloud that the spike in November was caused because of the elections in USA and it overshadowed the coronavirus second wave related news, which was prevalent during the same time period","5bfe05cf":"Now, the c_tags column has just the english words from tags column. hence, it is safe to drop isEnglish and tags columns from df","e529591c":"#### Dropping columns that are irrelevant for analysis:","47f51033":"#### To generate the wordcloud we used the wordcloud library, to filter the data into the time range we used the date mask from october 1 to december 1, and we combined all the tags and title for all videos into a single string which we passed to the wordcloud generator and got the words with maximum frequency in a bigger size\n\n","3dbe70da":"##### Title(video title)","b64ec235":"### Great Britain","076ad23c":"#### Now applying the same logic on tags, title and channel_title  columns to ensure the presence of just English words","b27dcc98":"Now the dataset is ready for Machine learning","3636f548":"### Mangerial Insight: A video that performs well on the trending page will be surfaced to more people and helps in the better the reach of the channel. So, by using this model, channels could estimate their total number of days their video could trend based on the number of views, likes, dislikes and comments the video is receiving.","71bde22f":"#### Using classification report which gives us metric like 'precision', 'recall'and 'f1 score' for all the categories taken into consideration","170ed95f":"### Writing this cleaned file to compressed csv","469a8be9":"#### Validating preprocessing method :","55a3be08":"#### Keeping only one unique record of each video_id","b75761be":"### Regression for Prediction","305d763c":"#### To understand what caused these unusual spikes we generated a wordcloud to see the most popular Tags and Titles in those specific Months","7635eaaa":"#### 2. Dealing with Null values in description\n##### filling missing values in description with ''","e3838ee0":"### --------------------------------------------------------------------------------------------------------------","616caad4":"<ol>\n    <li>video_id-------------------------\t Uniquely identifies each video<\/li>\n    <li>published_at-----------------------    Date and Time of video published<\/li>\n    <li>category_id------------------------    Id of category the video belongs to<\/li>\n    <li>trending_date----------------------    Date and time when the video got to Trending<\/li>\n    <li>view_count-------------------------    Number of views (cumulative)<\/li>\n    <li>likes------------------------------\tNumber of Likes(cumulative)<\/li>\n    <li>dislikes---------------------------    Number of dislikes(cumulative)<\/li>\n    <li>comment_count----------------------   Number of comments(cumulative)<\/li>\n    <li>category_name-----------------------\tName of category corresponding to Id<\/li>\n    <li>country----------------------------------    Country in which the video was trending<\/li>\n    <li>description-----------------------------   Description of video by the creator<\/li>\n    <li>tags---------------------------------------   Tags of the video by the creator<\/li>\n    <li>video_title------------------------------   Title of the video<\/li>\n    <li>channel_title--------------------------\tChannel Title of the video<\/li>\n<\/ol>\n","d2264952":"### Noting the shape again after the merge","554170b8":"#### Validating the function 'removeNonEnglishWords'","526f9a4d":"### Finding: Majority of the trending videos are trending for total 4 to 9 days so the decision tree regressor gives a better prediction for videos in that bin range","4bd58ff7":"## Finding 4","aeae317b":"### Appending Data from 3 countries:","b173365b":"#### GOAL: To plot the Time Series for each trending date over number of videos viewed, in news and politics category during the pandemic(2020-2021) <font color=blue>Using Plotly Time series<\/font>","279d5bc4":"### GOAL: To construct a Machine learning model to predict how many more days a video will trend given views,likes,dislikes,comment_count, published date and trending day number","f5998183":"#### MAD","48310c46":"### YouTube Trending Statistics - Consists of updated daily records of top trending YouTube videos, based on viewership metrics such as likes, dislikes and views and provides interesting parameters such as tag or country for further analysis.\n\n \n","828f3fe5":"#### adding a new feature des (with cleaned description ) into the dataframe","5509b357":"### Does Americans prefer certain Tags and titles over the British? \n\n### Finding: Yes. In USA , people have varied interests in both the categories. Whereas, in Great Britain , The most watched videos are predominantly Football and more exclusively Manchester United in 2020-21.\n","f57d8bcd":"#### Dropping off isEnglish and channelTitle columns and keeping the cleaned channel_title","7e0dc630":"#### -------------------------------------------------------------------------------------------------------------------"}}