{"cell_type":{"27d667bc":"code","1dfeea08":"code","d1b06a47":"code","09fb5f17":"code","d0f6e1bf":"code","87fbd34c":"code","dd8b1951":"code","15cc48f1":"code","892e2ce7":"code","ca869a86":"code","c243ac5e":"code","3304ba3b":"code","6c94edbb":"code","f95d6e72":"code","c00083c6":"code","1df231cf":"code","81f84f22":"code","fc9453c0":"code","678af936":"markdown","530f5bfb":"markdown","49b02b07":"markdown","e7a27c17":"markdown","34b8cbcd":"markdown","990cd9f3":"markdown","f3958057":"markdown","f89440d9":"markdown","1e870e19":"markdown","6a815667":"markdown","578c69ec":"markdown","6bd7f485":"markdown","d46b7cee":"markdown","92d68fcd":"markdown","a852ccf6":"markdown","fe8dde2e":"markdown","168bb594":"markdown","943f442c":"markdown","bad0812a":"markdown","b1b8cb38":"markdown"},"source":{"27d667bc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.callbacks import EarlyStopping","1dfeea08":"df = pd.read_csv('..\/input\/ice-cream-production\/Ice_Cream_Production.csv',index_col='DATE',parse_dates=True)\ndf.columns = ['PRODUCTION']","d1b06a47":"df.head(10)","09fb5f17":"plt.figure(figsize=(15,8))\nplt.plot(df)","d0f6e1bf":"# The test dataset contains 2 years of data\ntest_size = 24\ntest_idx = len(df)- test_size\n\ntrain = df.iloc[:test_idx]\ntest = df.iloc[test_idx:]\n\nprint(\"Train_dataset\")\nprint(train.head())\nprint(\"\\nTest_dataset\")\nprint(test.head())\n","87fbd34c":"scaler = MinMaxScaler()\nscaler.fit(train)\nscaled_train = scaler.transform(train)\nscaled_test = scaler.transform(test)","dd8b1951":"length = 12 # number of elements in 1 time series\nn_features = 1 # Prediction\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=1)\nvalidation_generator = TimeseriesGenerator(scaled_test,scaled_test, length=length, batch_size=1)","15cc48f1":"model = Sequential()\nmodel.add(LSTM(120, activation='relu', input_shape=(length, n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\nmodel.summary()\n\nearly_stop = EarlyStopping(monitor='val_loss',patience=2)\n","892e2ce7":"model.fit_generator(generator, epochs=100, validation_data=validation_generator, callbacks=[early_stop])","ca869a86":"loss = pd.DataFrame(model.history.history)\nloss.plot(figsize = (15, 8))","c243ac5e":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(len(test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","3304ba3b":"# Inverse the scaler\ntrue_predictions = scaler.inverse_transform(test_predictions)\n\n# Save the predictions in the dataframe 'test'\ntest['PREDICTIONS'] = true_predictions\ntest.plot(figsize = (15, 8))\ntest.head()","6c94edbb":"full_scaler = MinMaxScaler()\nscaled_full_data = full_scaler.fit_transform(df)\n\nlength = 24\ngenerator = TimeseriesGenerator(scaled_full_data, scaled_full_data, length=length, batch_size=1)","f95d6e72":"model = Sequential()\nmodel.add(LSTM(100, activation='relu', input_shape=(length, n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\n\nmodel.fit_generator(generator,epochs=6)","c00083c6":"forecast = []\n# The period we want to predict the future\nperiods = 12\n\nfirst_eval_batch = scaled_full_data[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(periods):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    forecast.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","1df231cf":"forecast = full_scaler.inverse_transform(forecast)","81f84f22":"forecast_index = pd.date_range(start='2019-09-01',periods=periods,freq='MS')\nforecast_df = pd.DataFrame(data=forecast,index=forecast_index, columns=['Forecast'])\nforecast_df.head()","fc9453c0":"ax = df.plot()\nforecast_df.plot(figsize = (15, 8), ax = ax)\nplt.xlim('2017-01-01','2020-09-01')","678af936":"## Scale data","530f5bfb":"**Plot the time series**","49b02b07":"**Import the csv and put the column 'DATE' in index**","e7a27c17":"**Inverse the scaler**","34b8cbcd":"# FORECAST ON FUTURE","990cd9f3":"**We take the entire dataset (train + test) to predict the future**","f3958057":"**Evaluate the model :**   \n**Plot the history of the loss that occured during training**","f89440d9":"**Create new index on the dataframe df**","1e870e19":"**Creation of the same model as before**","6a815667":"## Explore the data","578c69ec":"# IMPORT","6bd7f485":"# MODEL","d46b7cee":"# DATASET","92d68fcd":"## Train Test Split","a852ccf6":"# FORECAST ON TEST DATA ","fe8dde2e":"**Plot the predictions**","168bb594":"**Transform the data into a times series genetator object**","943f442c":"**Fit to the data**","bad0812a":"**Create the model**","b1b8cb38":"## Times series generator"}}