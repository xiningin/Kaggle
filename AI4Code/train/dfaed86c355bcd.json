{"cell_type":{"175268d1":"code","9af4f977":"code","ab6f0015":"code","00f07ac8":"code","ab23ec66":"code","8cbc6c83":"code","b025a5e9":"code","5e6c6c6f":"code","8dbacb90":"code","45e95632":"markdown","f341b405":"markdown","079e0b58":"markdown"},"source":{"175268d1":"import lightgbm as lgb\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport seaborn\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom warnings import simplefilter","9af4f977":"!pip install kaggler","ab6f0015":"import kaggler\nfrom kaggler.model import AutoLGB\nprint(kaggler.__version__)","00f07ac8":"plt.style.use('fivethirtyeight')\npd.set_option('max_columns', 100)\nsimplefilter('ignore')","ab23ec66":"data_dir = Path('..\/input\/tabular-playground-series-jun-2021')\ntrain_file = data_dir \/ 'train.csv'\ntest_file = data_dir \/ 'test.csv'\nsample_file = data_dir \/ 'sample_submission.csv'\n\nid_col = 'id'\ntarget_col = 'target'\n\nn_fold = 5\nseed = 42","8cbc6c83":"trn = pd.read_csv(train_file, index_col=id_col)\ntst = pd.read_csv(test_file, index_col=id_col)\nsub = pd.read_csv(sample_file, index_col=id_col)\nprint(trn.shape, tst.shape, sub.shape)","b025a5e9":"n_trn = trn.shape[0]\ndf = pd.concat([trn.drop(target_col, axis=1), tst], axis=0)\nprint(df.shape)","5e6c6c6f":"cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\nX = df\ny = pd.Series(np.concatenate([np.zeros(n_trn,), np.ones(df.shape[0] - n_trn,)]))\np = np.zeros_like(y, dtype=float)\nfor i, (i_trn, i_val) in enumerate(cv.split(X, y)):\n    if i == 0:\n        clf = AutoLGB(objective='binary', metric='auc', random_state=seed, feature_selection=False)\n        clf.tune(X.iloc[i_trn], y[i_trn])\n        features = clf.features\n        params = clf.params\n        n_best = clf.n_best\n        print(f'{n_best}')\n        print(f'{params}')\n        print(f'{features}')\n    \n    trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn])\n    val_data = lgb.Dataset(X.iloc[i_val], y[i_val])\n    clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100)\n    p[i_val] = clf.predict(X.iloc[i_val])\n    print(f'CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}')","8dbacb90":"print(f'CV AUC: {roc_auc_score(y, p):.6f}')","45e95632":"# Conclusion\n\nAdverarial validation AUC is close to 50%. In other words, it confirms that the feature distributions between the training and test data are similar.\n\nLet's have some fun. :)","f341b405":"Adversarial validation is a method to check how different feature distributions between the training and test data. We train a binary classifier with a new target variable indicating whether a sample belongs to the test data (1) or not (0).\n\nFrom the [EDA](https:\/\/www.kaggle.com\/subinium\/tps-jun-this-is-original-eda-viz) by @subinium, we already saw that feature distrubutions across the training and test data are quite similar, but here, let's use adversarial validation to validate the finding.","079e0b58":"# Adversarial Validation - TPS 6"}}