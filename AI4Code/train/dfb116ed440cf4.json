{"cell_type":{"5b137691":"code","cabf7691":"code","f236e1ef":"code","dfa4ab2b":"code","9dbe95ee":"code","c589acc4":"code","7bcaf475":"code","318c38f1":"code","ad6ad476":"code","3c86b8c1":"code","dc9f93c7":"code","d89ddb9e":"code","bb4ba68f":"code","da8af7c7":"code","79115913":"code","f88dbbc3":"code","19b5841d":"code","808561eb":"code","94d8c829":"code","30eed63d":"code","3541d813":"code","1b846f9f":"code","652c51ba":"code","b4df3524":"markdown","85ec0951":"markdown","d5e11f46":"markdown","1c0c1787":"markdown","5551bda6":"markdown"},"source":{"5b137691":"!pip install -q efficientnet_pytorch > \/dev\/null\n!pip install torchcontrib","cabf7691":"import sys\nfrom glob import glob\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nimport cv2\nfrom skimage import io\nimport albumentations as A\nimport torch\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.nn import functional as F\nfrom glob import glob\nimport sklearn\nfrom torch import nn\nimport warnings\nfrom torchvision import models\nimport torch.nn.functional as F\nimport types\nimport torch\nfrom collections import OrderedDict\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nimport pandas as pd\nfrom PIL import Image\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom catalyst.data.sampler import BalanceClassSampler\nimport os\nfrom datetime import datetime\nfrom glob import glob\nimport time\nimport random\nimport sklearn\nimport random\nimport numpy as np\nimport scipy\nfrom scipy import ndimage\nfrom PIL import Image, ImageEnhance, ImageOps\nfrom torchvision import transforms, utils\nfrom torchcontrib.optim import SWA\n\nwarnings.filterwarnings(\"ignore\") \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nSEED = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","f236e1ef":"def get_train_transforms():\n    return A.Compose([\n            A.RandomRotate90(p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.Resize(height=288, width=384, p=1),\n            A.Cutout(num_holes=5, max_h_size=34, max_w_size=64, fill_value=0, p=0.5),\n            ToTensorV2(p=1.0),                  \n        ], p=1.0)\n\ndef get_valid_transforms():\n    return A.Compose([\n            A.Resize(height=288, width=384, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)","dfa4ab2b":"from sklearn import metrics\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\nclass RocAucMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.y_true = np.array([0,1])\n        self.y_pred = np.array([0.5,0.5])\n        self.score = 0\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        # y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred)\n\n    @property\n    def avg(self):\n        return self.score\n\n    \nclass APScoreMeter(RocAucMeter):\n    def __init__(self):\n        super(APScoreMeter, self).__init__()\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = sklearn.metrics.average_precision_score(self.y_true, self.y_pred)","9dbe95ee":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.logits = logits\n        self.reduce = reduce\n\n    def forward(self, inputs, targets):\n        if self.logits:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets)\n        else:\n            BCE_loss = F.binary_cross_entropy(inputs, targets)\n\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss\n        \nclass LabelSmoothing(nn.Module):\n    def __init__(self, smoothing = 0.1):\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        if self.training:\n            x = x.float()\n            target = target.float()\n            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n\n            nll_loss = -logprobs * target\n            nll_loss = nll_loss.sum(-1)\n    \n            smooth_loss = -logprobs.mean(dim=-1)\n\n            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n\n            return loss.mean()\n        else:\n            return torch.nn.functional.cross_entropy(x, target)\n        \nclass DiceBCELoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice_loss = 1 - (2.*intersection + smooth)\/(inputs.sum() + targets.sum() + smooth)  \n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        Dice_BCE = BCE + dice_loss\n        \n        return Dice_BCE        \n    \nclass FocalDiceLoss(nn.Module):\n    def __init__(self,alpha=1, gamma=2, logits=True, reduce=False,weight=None, size_average=True):\n        super(FocalDiceLoss,self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.logits = logits\n        self.reduce = reduce\n   \n    def forward(self, inputs, targets, smooth=1):\n        if self.logits:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets)\n        else:\n            BCE_loss = F.binary_cross_entropy(inputs, targets)\n\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n        \n        \n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice_loss = 1 - (2.*intersection + smooth)\/(inputs.sum() + targets.sum() + smooth)  \n        \n        if self.reduce:\n            return torch.mean(F_loss)+dice_loss\n        else:\n            return F_loss+ dice_loss","c589acc4":"from efficientnet_pytorch import EfficientNet\n","7bcaf475":"def get_net():\n    net = EfficientNet.from_pretrained('efficientnet-b3')\n    net._fc = nn.Linear(in_features=1536, out_features=1000, bias=True)\n    return net","318c38f1":"class MetaNet(nn.Module):\n    def __init__(self):\n        super(MetaNet, self).__init__()\n        self.meta_before = FeedForwardNN()\n        self.mainnet = get_net()\n        self.linear = nn.Linear(1256,2)\n    def forward(self,inputs):\n        x,meta_data = inputs\n        meta_features = self.meta_before(meta_data)\n        cnn_features = self.mainnet(x)\n        features = torch.cat((cnn_features,meta_features),dim=1)\n        output = self.linear(features)\n        return output","ad6ad476":"class FeedForwardNN(nn.Module):\n\n    def __init__(self):\n\n        super().__init__()\n        self.net1 = nn.Sequential(nn.Linear(3,64),nn.BatchNorm1d(64),nn.ReLU())\n        self.net2 = nn.Sequential(nn.Linear(64,128),nn.BatchNorm1d(128),nn.ReLU())\n        self.net3 = nn.Linear(128,256)\n        \n    def forward(self,inputs):\n        output = self.net3(self.net2(self.net1(inputs)))\n        return output","3c86b8c1":"net = MetaNet()","dc9f93c7":"DATA_PATH = '..\/input\/512x384\/'\nTRAIN_ROOT_PATH = f'{DATA_PATH}\/512x384-dataset-melanoma\/'\n\ntrain = pd.read_csv(f'{DATA_PATH}\/marking.csv')\ntrain['sex'] = train['sex'].fillna('na')\ntrain['age_approx'] = train['age_approx'].fillna(0)\ntrain['anatom_site_general_challenge'] = train['anatom_site_general_challenge'].fillna('na')\n\nle = preprocessing.LabelEncoder()\n\ntrain.sex = le.fit_transform(train.sex)\ntrain.anatom_site_general_challenge = le.fit_transform(train.anatom_site_general_challenge)\ntrain['age_approx'] = le.fit_transform(train['age_approx'])\nscaler = StandardScaler()\nx = scaler.fit_transform(train[['sex','age_approx','anatom_site_general_challenge']])\ntrain.sex,train.age_approx,train.anatom_site_general_challenge = x[:,0],x[:,1],x[:,2]","d89ddb9e":"def onehot(size, target):\n    vec = torch.zeros(size, dtype=torch.float32)\n    vec[target] = 1.\n    return vec\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df, image_ids, labels, transforms=None):\n        super().__init__()\n        self.image_ids = image_ids\n        self.labels = labels\n        self.transforms = transforms\n        self.df = df\n\n    def __getitem__(self, idx: int):\n        image_id = self.image_ids[idx]\n#         print(image_id)\n        image = cv2.imread(f'{TRAIN_ROOT_PATH}\/{image_id}.jpg', cv2.IMREAD_COLOR)\n        image = image.astype(np.float32) \/ 255.0\n        record = self.df[self.df.image_id == image_id]\n        meta_data = np.squeeze(record[['sex','age_approx','anatom_site_general_challenge']].values)\n        label = self.labels[idx]\n        meta_data = torch.tensor(meta_data,dtype=torch.float32)\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        target = onehot(2, label)\n        return (image,meta_data), target\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n\n    def get_labels(self):\n        return list(self.labels)","bb4ba68f":"df_folds = pd.read_csv(f'{DATA_PATH}\/folds_13062020.csv', index_col='image_id')","da8af7c7":"class Fitter:\n    \n    def __init__(self, model, device, config, folder):\n        self.config = config\n        self.epoch = 0\n\n        self.base_dir = f'.\/{folder}'\n        if not os.path.exists(self.base_dir):\n            os.makedirs(self.base_dir)\n\n        self.log_path = f'{self.base_dir}\/log.txt'\n        self.best_score = 0\n        self.best_loss = 10**5\n        self.best_ap = 0\n         \n        self.model = model\n        self.device = device\n\n        \n        self.base_optimizer = optim.AdamW(self.model.parameters(), lr=config.lr)\n        self.optimizer = SWA(self.base_optimizer)\n        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n\n        self.criterion = FocalDiceLoss(logits=True).to(self.device)\n        self.log(f'Fitter prepared. Device is {self.device}')\n\n    def fit(self, train_loader, validation_loader):\n        for e in range(self.config.n_epochs):\n            if self.config.verbose:\n                lr = self.optimizer.param_groups[0]['lr']\n                timestamp = datetime.utcnow().isoformat()\n                self.log(f'\\n{timestamp}\\nLR: {lr}')\n\n            t = time.time()\n#             if e >= self.config.lowerLRat-self.config.lowerLRAfter:\n#                 self.scheduler.step()\n                    \n            summary_loss, roc_auc_scores, ap_scores = self.train_one_epoch(train_loader)\n            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n            \n                \n            t = time.time()\n            \n                \n            summary_loss, roc_auc_scores, ap_scores = self.validation(validation_loader) \n            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n            \n            \n            if summary_loss.avg < self.best_loss:\n                self.best_loss = summary_loss.avg\n                self.save_model(f'{self.base_dir}\/best-loss-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob(f'{self.base_dir}\/best-loss-checkpoint-*epoch.bin'))[:-1]:\n                    os.remove(path)\n                    \n            if roc_auc_scores.avg > self.best_score:\n                self.best_score = roc_auc_scores.avg\n                self.save_model(f'{self.base_dir}\/best-score-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob(f'{self.base_dir}\/best-score-checkpoint-*epoch.bin'))[:-4]:\n                    os.remove(path)\n                    \n            if ap_scores.avg > self.best_ap:\n                self.best_ap = ap_scores.avg\n                self.save_model(f'{self.base_dir}\/best-ap-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob(f'{self.base_dir}\/best-ap-checkpoint-*epoch.bin'))[:-1]:\n                    os.remove(path)\n                \n            if self.config.validation_scheduler:\n                self.scheduler.step(metrics=summary_loss.avg)\n            self.epoch += 1\n            if self.epoch > 1:\n                self.optimizer.update_swa()\n            if self.epoch == self.config.n_epochs:\n                self.save_model(f'{self.base_dir}\/last-checkpoint.bin')\n                self.optimizer.swap_swa_sgd()\n                summary_loss, roc_auc_scores, ap_scores = self.validation(validation_loader)\n                self.log(f'[SWA WEIGHTS]: {roc_auc_scores.avg}')\n                self.save_model(f'{self.base_dir}\/last-checkpoint-swa.bin')\n    def validation(self, val_loader):\n        self.model.eval()\n        summary_loss = AverageMeter()\n        roc_auc_scores = RocAucMeter()\n        ap_scores = APScoreMeter()\n        t = time.time()\n        for step, (data, targets) in enumerate(val_loader):\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Val Step {step}\/{len(val_loader)}, ' + \\\n                        f'summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n                        f'time: {(time.time() - t):.5f}', end='\\r'\n                    )\n            with torch.no_grad():\n                targets = targets.to(self.device).float()\n                batch_size = data[0].shape[0]\n                data[0] = data[0].to(self.device).float()\n                data[1] = data[1].to(self.device).float()\n                outputs = self.model(data)\n            \n                loss = self.criterion(outputs, targets)\n                roc_auc_scores.update(targets, outputs)\n                ap_scores.update(targets, outputs)\n                summary_loss.update(loss.detach().item(), batch_size)\n\n        return summary_loss, roc_auc_scores, ap_scores\n\n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = AverageMeter()\n        roc_auc_scores = RocAucMeter()\n        ap_scores = APScoreMeter()\n        t = time.time()\n        for step, (data, targets) in enumerate(train_loader):\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Train Step {step}\/{len(train_loader)}, ' + \\\n                        f'summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n                        f'time: {(time.time() - t):.5f}', end='\\r'\n                    )\n            targets = targets.to(self.device).float()\n            data[0] = data[0].to(self.device).float()\n            data[1] = data[1].to(self.device).float()\n            batch_size = data[0].shape[0]\n\n            self.optimizer.zero_grad()\n            outputs = self.model(data)\n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            \n            roc_auc_scores.update(targets, outputs)\n            ap_scores.update(targets, outputs)\n            summary_loss.update(loss.detach().item(), batch_size)\n\n            self.optimizer.step()\n            \n            if self.config.step_scheduler:\n                self.scheduler.step()\n\n        return summary_loss, roc_auc_scores, ap_scores\n    \n    def save_model(self, path):\n        self.model.eval()\n        torch.save(self.model.state_dict(),path)\n\n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_score': self.best_score,\n            'best_ap': self.best_ap,\n            'best_loss': self.best_loss,\n            'epoch': self.epoch,\n        }, path)\n\n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_score = checkpoint['best_score']\n        self.best_ap = checkpoint['best_ap']\n        self.best_loss = checkpoint['best_loss']\n        self.epoch = checkpoint['epoch']\n        \n    def log(self, message):\n        if self.config.verbose:\n            print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')","79115913":"class TrainGlobalConfig:\n    num_workers = 2\n    batch_size = 32 \n    n_epochs = 20\n    lr = 0.00003\n\n    # -------------------\n    verbose = True\n    verbose_step = 1\n    # -------------------\n\n    # --------------------\n    step_scheduler = False  # do scheduler.step after optimizer.step\n    validation_scheduler = True \n    \n    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n    scheduler_params = dict(\n        mode='min',\n        factor=0.8,\n        patience=1,\n        verbose=False, \n        threshold=0.0001,\n        threshold_mode='abs',\n        cooldown=0, \n        min_lr=1e-8,\n        eps=1e-08\n    )","f88dbbc3":"fitter = Fitter(model=net, device=torch.device('cuda:0'), config=TrainGlobalConfig, folder='base_state')\nBASE_STATE_PATH = f'{fitter.base_dir}\/base_state.bin'\nfitter.save(BASE_STATE_PATH)","19b5841d":"def train_fold(fold_number):\n\n    train_dataset = DatasetRetriever(df = train,\n        image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n        labels=df_folds[df_folds['fold'] != fold_number].target.values,\n        transforms=get_train_transforms(),\n    )\n\n    df_val = df_folds[(df_folds['fold'] == fold_number) & (df_folds['source'] == 'ISIC20')]\n\n    validation_dataset = DatasetRetriever(df= train,\n        image_ids=df_val.index.values,\n        labels=df_val.target.values,\n        transforms=get_valid_transforms(),\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n        batch_size=TrainGlobalConfig.batch_size,\n        pin_memory=False,\n        drop_last=True,\n        num_workers=TrainGlobalConfig.num_workers,\n    )\n    val_loader = torch.utils.data.DataLoader(\n        validation_dataset, \n        batch_size=TrainGlobalConfig.batch_size,\n        num_workers=TrainGlobalConfig.num_workers,\n        shuffle=False,\n        sampler=SequentialSampler(validation_dataset),\n        pin_memory=False,\n    )\n\n    fitter = Fitter(model=net.cuda(), device=torch.device('cuda:0'), config=TrainGlobalConfig, folder=f'{fold_number}')\n    fitter.load(BASE_STATE_PATH)\n    print(\"strat\")\n    fitter.fit(train_loader, val_loader)","808561eb":"import warnings\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","94d8c829":"train_fold(fold_number=2)","30eed63d":"train_fold(fold_number=0)","3541d813":"train_fold(fold_number=3)","1b846f9f":"train_fold(fold_number=4)","652c51ba":"train_fold(fold_number=1)","b4df3524":"# Save all states for \"honest\" training of folds","85ec0951":"# Metrics","d5e11f46":"# Fitter","1c0c1787":"# Loss","5551bda6":"# Net"}}