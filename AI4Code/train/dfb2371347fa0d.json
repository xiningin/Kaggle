{"cell_type":{"6ef4ff2f":"code","4a08e2a8":"code","b65036f7":"code","cb14d230":"code","f6edb0e2":"code","b8fe30d5":"code","e0f82c80":"code","b88ffb27":"code","1a9fe1fb":"code","119295c6":"code","6ade2bd3":"code","37eaf705":"code","b6581eb5":"code","45703b57":"code","78ac6b09":"code","3a15d505":"code","8af07273":"code","4f2349ff":"code","dd6ff551":"code","94230a0a":"code","18af0e75":"code","da5b22a7":"code","039194a2":"code","11c4b8ea":"code","c85f1156":"code","2bd94dc5":"code","9a91dd7d":"code","0820d52c":"code","f5eb1d70":"code","eae77c08":"code","1f139d5e":"code","0f3b7ba5":"code","78fbc353":"code","6b62db2e":"code","cd556a48":"code","c550d90c":"code","e69b0cf0":"code","6543c71e":"code","8e3dd855":"code","2f23a01c":"code","efadbbe2":"code","ed1ca7c9":"code","c9ef1785":"code","f3270c1c":"code","8f28672a":"code","a2135854":"code","f5db5ae3":"code","6c972087":"code","fc7f07e9":"code","f1d2dac9":"code","a7f2c933":"code","f023ac76":"code","98945c7c":"code","f54d6321":"code","e3fd7d04":"code","17167261":"code","46326204":"code","06543301":"code","d0d65738":"markdown","377b093c":"markdown","a0aca01a":"markdown","35d9b563":"markdown","2b0b32dd":"markdown","9543eb39":"markdown","6071d608":"markdown","435ff24a":"markdown","7aabcbbd":"markdown","4d994560":"markdown","62093ec8":"markdown","c8d30dde":"markdown","85a57b4f":"markdown","ee231a45":"markdown"},"source":{"6ef4ff2f":"import seaborn as sns\n# ^^^ pyforest auto-imports - don't write above this line\nimport plotly.express as px\nimport pandas as pd\nimport numpy as np","4a08e2a8":"data = pd.read_csv('\/kaggle\/input\/usa-cers-dataset\/USA_cars_datasets.csv', index_col=0)\n","b65036f7":"data.shape","cb14d230":"for col in data.columns:\n    print(col)\n    print()\n    print(data[col].value_counts())\n    print('= - ='*20)\n    print()","f6edb0e2":"data.head(1)","b8fe30d5":"data.drop(columns=['vin', 'lot'], inplace= True)","e0f82c80":"data.rename(columns={'mileage' : 'miles_driven'}, inplace = True)","b88ffb27":"data['title_status'].replace({'clean vehicle' : 1, 'salvage insurance': 0}, inplace = True)","1a9fe1fb":"data['vehicle_age'] = 2020 - data['year']\ndata.drop(columns=['year'], inplace= True)","119295c6":"# converting day,hours into minutes\n\ndata['condition'] = data['condition'].str.replace('left','')\ndata.loc[data['condition'].str.contains('minutes'), 'condition'] = data.loc[data['condition'].str.contains('minutes'), 'condition'].apply(lambda x : str(x).split()[0])\ndata.loc[data['condition'].str.contains('hours'), 'condition'] = data.loc[data['condition'].str.contains('hours'), 'condition'].apply(lambda x : str(int(str(x).split()[0])*60))\ndata.loc[data['condition'].str.contains('days'), 'condition'] = data.loc[data['condition'].str.contains('days'), 'condition'].apply(lambda x : str(int(str(x).split()[0])*60*24))\ndata.loc[data['condition'].str.contains('Listing Expired'), 'condition'] = 0\ndata['condition'] = data['condition'].astype('int')","6ade2bd3":"data[data.country == ' canada']","37eaf705":"data.drop(columns='country',inplace = True)","b6581eb5":"# Replacing colors having counts less than 10 to other\n\ncolors_less_counts = data.color.value_counts()[data['color'].value_counts() < 10].index\ndata['color'].replace(colors_less_counts, 'other', inplace= True)","45703b57":"pd.set_option('display.max_rows',200)","78ac6b09":"data.groupby('model')['brand'].value_counts()","3a15d505":"data['model'].replace(['doors','d'], 'door', inplace = True)\ndata['model'].replace('vans', 'van', inplace = True)","8af07273":"data['price'].value_counts().sort_index().head(10)","4f2349ff":"data[(data['price'] == 0) | (data['price'] == 25)]","dd6ff551":"data.drop(index=[309,322,349,545], inplace = True)","94230a0a":"data.isnull().sum()","18af0e75":"data_copy = data.copy(deep = True)","da5b22a7":"num_cols = data_copy.select_dtypes(exclude='object').columns\ncat_cols = data_copy.select_dtypes(include='object').columns","039194a2":"from sklearn.ensemble import IsolationForest\n\nclf = IsolationForest(random_state = 1)\npreds = clf.fit_predict(data_copy[num_cols])  # using only numerical columns\nlist(preds).count(-1)","11c4b8ea":"from scipy.stats import zscore","c85f1156":"data_copy_scaled = zscore(pd.get_dummies(data_copy))","2bd94dc5":"clf = IsolationForest(random_state = 1)\npreds = clf.fit_predict(data_copy_scaled) # using total data\nlist(preds).count(-1)","9a91dd7d":"fig = px.box(data,x =  data['title_status'].replace({0:'salvage_insurance',1:'clean_vehicle'}), y ='price', template='plotly_dark')\nfig.show()","0820d52c":"fig = px.box(data, x = 'brand', y ='price', template='plotly_dark' ,color = 'title_status')\nfig.show()","f5eb1d70":"fig = px.box(data, x = 'color', y ='price', template='plotly_dark' ,color = 'title_status')\nfig.show()","eae77c08":"fig = px.box(data, x = 'state', y ='price', template='plotly_dark')\nfig.show()","1f139d5e":"fig = px.scatter(data, x=\"vehicle_age\", y=\"price\", color=\"brand\", size='price',hover_data=['model'], template = 'plotly_dark')\nfig.show()","0f3b7ba5":"# Double click on brand to select one brand at a time to get good understanding\n# In this graph we can observe price variation of different models in a brand.\n\nfig = px.scatter(data, x=\"model\", y=\"price\", color=\"brand\", size='vehicle_age',hover_data=['vehicle_age'], template = 'plotly_dark')\n# fig.update_traces(visible= False, selector=dict(type='scatter'))\nfig.show()","78fbc353":"# Double click on model to select one brand at a time to get good understanding, Select **mpv**\n# In this plot we can observe price variation of each model in different states\n\n\nfig = px.scatter(data, x=\"state\", y=\"price\", color=\"model\", size='vehicle_age',hover_data=['brand','vehicle_age','miles_driven','title_status'], template = 'plotly_dark')\nfig.show()","6b62db2e":"def check_mutlicolinearity(data_x):\n    corr = data_x.corr()\n    corr = pd.DataFrame(np.tril(corr, k=-1),      # gets Lower triangular matrix\n                        columns=data_x.columns,\n                        index=data_x.columns)  \n\n    corr = corr.replace(0.000000, np.NAN)\n    count_of_total_correlation_values = corr.count().sum()\n\n    for i in [0.5, 0.6, 0.7, 0.8, 0.9]:\n        data_corr = corr[abs(corr) > i]\n        count_greater_than_thresh = data_corr.count().sum()\n        print(f'Percent Values Greater than {i} co-relation : {count_greater_than_thresh\/count_of_total_correlation_values}')\n    return corr","cd556a48":"def plot_corr(threshold, corr):\n    data_corr = corr[abs(corr) > threshold]\n    sns.heatmap(data_corr, annot=True, cmap=\"YlGnBu\", center=0)\n    plt.show()","c550d90c":"corr = check_mutlicolinearity(data[num_cols].drop(columns = 'price'))","e69b0cf0":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplot_corr(0, corr)","6543c71e":"data.head()","8e3dd855":"X = data.drop(columns='price')\nX_scaled = zscore(pd.get_dummies(X))\n\nY = data['price']\nY_scaled = zscore(Y)","2f23a01c":"data.corr()['price']","efadbbe2":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_regression,f_regression,f_oneway","ed1ca7c9":"fs = SelectKBest(score_func=f_regression, k='all')\nfs.fit(pd.get_dummies(X[cat_cols]), Y)","c9ef1785":"fig = px.bar(x =pd.get_dummies(X[cat_cols]).columns, y = fs.scores_, template = 'plotly_dark')\nfig.show()","f3270c1c":"fs = SelectKBest(score_func=mutual_info_regression, k='all')\nfs.fit(pd.get_dummies(X), Y)","8f28672a":"fig = px.bar(x = pd.get_dummies(X).columns, y =fs.scores_, template = 'plotly_dark')\nfig.show()","a2135854":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor,RandomForestRegressor,VotingRegressor\nfrom sklearn.model_selection import cross_val_score,GridSearchCV,KFold\n","f5db5ae3":"# GB_bias=[]\n# GB_ve=[]\n# for n in np.arange(1,100):\n#     GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n#     scores=cross_val_score(GB,X_scaled,Y_scaled,cv=3,scoring='neg_mean_squared_error')\n#     rmse=np.sqrt(np.abs(scores))\n#     GB_bias.append(np.mean(rmse))\n#     GB_ve.append((np.std(rmse,ddof=1)))\n\n#np.argmin(GB_bias)","6c972087":"# bias=[]\n# ve=[]\n# for n in np.arange(1,100):\n#     mod=AdaBoostRegressor(base_estimator=LR,n_estimators=n,random_state=0)\n#     scores=cross_val_score(mod,X_scaled,Y_scaled,cv=3,scoring='neg_mean_squared_error')\n#     rmse=np.sqrt(np.abs(scores))\n#     bias.append(np.mean(rmse))\n#     ve.append((np.std(rmse,ddof=1)))\n\n#np.argmin(bias)","fc7f07e9":"LR=LinearRegression()\nLR_AB=AdaBoostRegressor(base_estimator=LR,n_estimators = 94 ,random_state=0)\nDT_AB=AdaBoostRegressor(n_estimators = 8 ,random_state=0)\nLR_GB=GradientBoostingRegressor(n_estimators = 97, random_state=0)\nRF=RandomForestRegressor(criterion='mse',random_state=0)","f1d2dac9":"models = []\n# models.append(('LinearRegression', LR))\n# models.append(('Adaboost',LR_AB))\nmodels.append(('DT_boost',DT_AB))\nmodels.append(('GBoost',LR_GB))\nmodels.append(('RF',RF))\n\n","a7f2c933":"# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(shuffle=True,n_splits=3,random_state=0)\n    cv_results = cross_val_score(model, X_scaled, Y_scaled,cv=kfold, scoring='neg_mean_squared_error', n_jobs = 3)\n    results.append(np.sqrt(np.abs(cv_results)))\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name, np.mean(np.sqrt(np.abs(cv_results))),np.std(np.sqrt(np.abs(cv_results)),ddof=1)))\n    \n#     break\n","f023ac76":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X_scaled,Y_scaled, random_state = 0)","98945c7c":"model = AdaBoostRegressor(n_estimators = 8 ,random_state=0)\nmodel.fit(x_train, y_train)","f54d6321":"from sklearn.metrics import mean_squared_error","e3fd7d04":"y_predict = model.predict(x_train) #train error\nmean_squared_error(y_train, y_predict)","17167261":"y_predict = model.predict(x_test)  # test error\nmean_squared_error(y_test, y_predict)","46326204":"from sklearn import neighbors\nknn=neighbors.KNeighborsRegressor()\n\nparam_grid={\n    'n_neighbors':np.arange(2,5),\n    'weights':['uniform', 'distance']}\n\nkfold= KFold(n_splits=3,shuffle=True,random_state=1)\nmodel= GridSearchCV(estimator=knn,\n                        param_grid=param_grid,\n                        scoring='neg_mean_squared_error',\n                        cv=kfold,\n                        refit=True,\n                        verbose=5,\n                        n_jobs=3)\n                        \nmodel.fit(X_scaled,Y_scaled)\n\nprint()\nprint('Best Scorer{}'.format(model.best_score_))\nprint('Best Parameters{}'.format(model.best_params_))","06543301":"res = pd.DataFrame(model.cv_results_)\nres.sort_values('rank_test_score').head(3)\n","d0d65738":"KNeighborsRegressor gives the least bias error(0.45) and least variance error(0.063)","377b093c":"[Isolation forest paper](https:\/\/cs.nju.edu.cn\/zhouzh\/zhouzh.files\/publication\/icdm08b.pdf)","a0aca01a":"## Feature Selection","35d9b563":"## Pre-Process","2b0b32dd":"##### Using numerical columns only we can find 386 outliers.  -1 is an outlier and 1 is not an outlier","9543eb39":"### We Have cars whose price are zero and less than 100 also. ","6071d608":"## EDA","435ff24a":"##### From above table we can say that most of the cars title_status = 0(Salvage_insurace). **So not changing price**\n\n##### We can also find some anomalies such as indexes 309,322,349,545 whose prices = 0 and miles driven = 0 and age > 10","7aabcbbd":"|Feature\t|Type |Description|\n|--------|---------|--------------|\n|Price|\tInteger|\tThe sale price of the vehicle in the ad\n|Years\t|Integer\t|The vehicle registration year\n|Brand\t|String\t|The brand of car\n|Model\t|String\t|model of the vehicle\n|Color\t|String\t|Color of the vehicle\n|State\/City\t|String\t|The location in which the car is being available for purchase\n|Mileage\t|Float\t|miles traveled by vehicle\n|Vin\t|String\t|The vehicle identification number is a collection of 17 characters (digits and capital letters)\n|Title |Status\t|String\tThis feature included binary classification, which are clean title vehicles and salvage insurance\n|Lot\t|Integer\t|A lot number is an identification number assigned to a particular quantity or lot of material from a single manufacturer.For cars, a lot number is combined with a serial number to form the Vehicle Identification Number.\n|Condition\t|String\t|Time","4d994560":"[Data description link](https:\/\/www.kaggle.com\/doaaalsenani\/usa-cers-dataset)","62093ec8":"We cannot find any outliers using Isolation Forest Method.","c8d30dde":"### OutLier detection","85a57b4f":"##### As Canada has only 7 values and 5 out of 7 have same price(30,000) even they has +\/- 10,000 difference in miles_driven and most of the other attributes are equal. So ***Removing column Country***.      We have ***state*** column so i think that makes sense.","ee231a45":"## Modelling"}}