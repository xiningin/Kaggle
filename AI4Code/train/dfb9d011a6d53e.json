{"cell_type":{"9b2c06d6":"code","076749eb":"code","6c7f4aba":"code","2b46b107":"code","f9c9c3a6":"code","d9c87b64":"code","04891f6c":"code","35604968":"code","132efa57":"code","52788362":"code","2273c2df":"code","b604f664":"code","886908a1":"code","ac387a7a":"code","155e160b":"code","23289593":"code","be75fa7d":"code","11a79162":"code","ea01fe60":"code","92358ba6":"code","ea972cd0":"code","36dd0246":"code","95f53ce2":"code","620c6773":"code","ed546b1d":"code","af98931b":"code","9989c650":"markdown"},"source":{"9b2c06d6":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.linear_model import LogisticRegression as logit\nfrom sklearn.ensemble import RandomForestClassifier as RF\nfrom sklearn.metrics import roc_auc_score\nimport keras as ks\nimport tensorflow as tf\nfrom scipy.special import erfinv\nimport plotly.express as px\nimport seaborn as sns\nimport plotly.figure_factory as ff\nfrom plotly.offline import iplot\nimport math\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","076749eb":"compresion = 3\neps = 100\nbs = 2048\nleRa = 0.02\ndec = 0.0001\n\nrandRatioViz = 0.1\n\n\"Learning rate and decay ok?: \" + str(leRa - dec * eps > 0)","6c7f4aba":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2b46b107":"train = pd.read_csv(\"..\/input\/kaggletheme\/train.csv\")\ntrain_id = train.id\ntest = pd.read_csv(\"..\/input\/kaggletheme\/test.csv\")\ntest_id = test.id","f9c9c3a6":"Xx = pd.concat([train.drop(\"target\", axis = 1), test])\nXx = Xx.set_index(\"id\")","d9c87b64":"Xx.head()","04891f6c":"catVars = [c for c in Xx.columns if \"cat\" in c]\ncontVars = [c for c in Xx.columns if \"cont\" in c]","35604968":"le = preprocessing.LabelEncoder()\nfor c in catVars:\n    Xx[f\"{c}\"] = le.fit_transform(Xx[f\"{c}\"])","132efa57":"#Checking Corelation\nr = list(np.random.random_sample(train.shape[0]) <= randRatioViz)\n\ndf = train.loc[r,contVars]\ndf[\"target\"] = train.loc[r,[\"target\"]]\n\nsns.set_theme(style=\"ticks\")\n\nsns.pairplot(df, \n             hue=\"target\",\n             palette =\"viridis\",\n             kind=\"hist\",\n             height=2,\n             diag_kind=\"kde\",\n             corner=True\n             )","52788362":"#Rank Gauss\ndef rg(df, e, Vars):\n    for i in df.loc[:,Vars]:\n        r = df[i].rank()\n        Range = (r\/r.max()-0.5)*2\n        Range = np.clip(Range, a_max = 1-e, a_min = -1+e)\n        rg = erfinv(Range)\n        df[i] = rg * 2**0.5\n    return df","2273c2df":"Xx_train = rg(Xx, 0.000001, contVars)","b604f664":"#Define the encoder and the decoder\ndef autoencoder(DataSet, comp):\n    \n    \"\"\"This function returns the encoder, the autoencoder, and the names of the embeddings \n    the output-layer as input for the decoder, the inputs, the outputs and the names ot all inputs\"\"\"\n    \n    inputs = []\n    outputs = []\n    names = []\n\n    for c in catVars:\n\n        inputDims = len(DataSet[f\"{c}\"].unique())\n        embedDim = min([math.ceil(inputDims \/ 10), 10])\n\n        INPUT = ks.layers.Input(shape=(1), name=c + \"_emb\")\n        OUTPUT = ks.layers.Embedding(inputDims + 1, embedDim)(INPUT)\n        OUTPUT = ks.layers.Reshape(target_shape=(embedDim, ))(OUTPUT)\n\n        inputs.append(INPUT)\n        outputs.append(OUTPUT)\n        names.append(c + \"_emb\")\n\n    contNum = len(DataSet.columns) - len(catVars) \n\n    INPUT = ks.layers.Input(shape=(contNum,), name=\"Vars\")\n\n    outputs.append(INPUT)\n    inputs.append(INPUT)\n\n    CONCAT = ks.layers.Concatenate()(outputs)\n\n    OUT = ks.layers.Dropout(0.1)(CONCAT)\n    OUT = ks.layers.BatchNormalization()(OUT)\n    OUT = ks.layers.Dense(150, activation='relu')(OUT)\n\n    OUT = ks.layers.Dropout(0.1)(OUT)\n    OUT = ks.layers.BatchNormalization()(OUT)\n    OUT = ks.layers.Dense(15, activation='relu')(OUT)\n\n    OUT = ks.layers.Dropout(0.1)(OUT)\n    OUT = ks.layers.BatchNormalization()(OUT)\n    OUT = ks.layers.Dense(comp, activation='linear')(OUT)\n\n    encoder = ks.Model(inputs=inputs, outputs=OUT)\n\n    OUT = ks.layers.Dropout(0.1)(OUT)\n    OUT = ks.layers.BatchNormalization()(OUT)\n    OUT = ks.layers.Dense(15, activation='relu')(OUT)\n\n    OUT = ks.layers.Dropout(0.1)(OUT)\n    OUT = ks.layers.BatchNormalization()(OUT)\n    OUT = ks.layers.Dense(150, activation='relu')(OUT)\n\n    OUT = ks.layers.Dropout(0.1)(OUT)\n    OUT = ks.layers.BatchNormalization()(OUT)\n    OUT = ks.layers.Dense(30-len(catVars), activation='linear')(OUT)\n\n    AE = ks.Model(inputs=inputs, outputs=OUT)\n    \n    return encoder, AE, names","886908a1":"help(autoencoder)","ac387a7a":"#Combining\nENCODER, AUTOENCODER, names = autoencoder(Xx,compresion)\n\n#Converts a Keras model to dot format and save to a file.\nks.utils.plot_model(AUTOENCODER,\n                    to_file=\"model.png\",\n                    show_shapes=True, \n                    show_layer_names=True,\n                    dpi = 1080\n                    )","155e160b":"def rmse(y_pred, y_true):\n    y_pred = tf.cast(y_pred, dtype=\"float32\")\n    y_true = tf.cast(y_true, dtype=\"float32\")\n    r = tf.sqrt(tf.keras.backend.mean(tf.square(y_pred - y_true)))\n    return r","23289593":"stop = ks.callbacks.EarlyStopping(monitor='AUC', min_delta=0.000001, patience=10, mode='max')","be75fa7d":"optimizer = ks.optimizers.Adam(lr=leRa, decay=dec)\nAUTOENCODER.compile(optimizer = optimizer, loss = rmse)","11a79162":"X_Train = {names[c]: Xx_train.iloc[:,c] for c in range(len(catVars))}\nX_Train.update({\"Vars\": Xx_train.drop(catVars, axis=1)})","ea01fe60":"history = ks.callbacks.History()\n\nAUTOENCODER.fit(X_Train, \n                Xx.drop(catVars, axis=1), \n                epochs = eps, \n                batch_size = bs, \n                shuffle = False,\n                callbacks=[history]\n               )","92358ba6":"Denoised = AUTOENCODER.predict(\n   x=X_Train, \n   workers = 1, \n   use_multiprocessing = True\n)\n\nDenoised = pd.DataFrame(Denoised, columns=contVars)\n\nDenoised = pd.concat([Xx.loc[:,catVars], Denoised], axis=1)\n    \nDenoised.head()","ea972cd0":"X_Compress = {names[c]: Xx_train.iloc[train_id,c] for c in range(len(catVars))}\nX_Compress.update({\"Vars\": Xx_train.iloc[train_id,:].drop(catVars, axis=1)})","36dd0246":"Compressed = ENCODER.predict(\n   x=X_Compress, \n   workers = 1, \n   use_multiprocessing = True\n)\n\nCompressed = pd.DataFrame(Compressed, columns=[\"dim_{0}\".format(i) for i in range(Compressed.shape[1])])\nCompressed[\"target\"] = train.target.astype(\"category\")\nCompressed.head()","95f53ce2":"#Compressed Representation\nr = list(np.random.random_sample(Compressed.shape[0]) <= randRatioViz)\n\nCompressed = Compressed.loc[r,:]\n\nfig = px.scatter_3d(\n     Compressed, \n     x='dim_0', \n     y='dim_1', \n     z='dim_2',\n     color='target',\n     hover_data={'dim_0': False, \n                 'dim_1': False,\n                 'dim_2': False,\n                 'target': True\n             },\n     opacity=1,\n     color_discrete_sequence=px.colors.qualitative.Antique,\n     title=\"Compressed Representation\",\n     template=\"simple_white\"\n     )\n\nfig.update_traces(marker=dict(size=6,\n                              line=dict(width=1,\n                                        color='grey')),\n                  selector=dict(mode='markers'))\n\nfig.update_layout(margin=dict(l=0, r=0, b=0, t=0),\n                 scene=dict(bgcolor='white'))\n\nfig.show()","620c6773":"#Using the denoised data:\nfor c in catVars:\n    Denoised[f\"{c}\"] = Denoised[f\"{c}\"].astype(\"category\")\n\ntr = Denoised.loc[train_id,:]\nprint(tr.shape)\nte = Denoised.loc[test_id,:]\nte.shape","ed546b1d":"cv_size = 0.2\nX_train, X_test, y_train, y_test = tts(tr, train.target, test_size=cv_size, random_state=42)\n\ny_train.describe()","af98931b":"clf = RF(n_estimators=80, \n         min_samples_leaf=5,\n         max_depth=20, \n         min_samples_split=5, \n         random_state=0,\n         n_jobs=-1\n         )\n\nclf.fit(X_train, y_train)\n\nprint(\"AUC is: \" + str(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])))\nprint(\"Accuracy is: \" + str(clf.score(X_test, y_test)))","9989c650":"For this notebook, we will be predicting a binary target based on a number of feature columns given in the data. All of the feature columns, cat0 - cat18 are categorical, and the feature columns cont0 - cont10 are continuous.\n\nFiles\ntrain.csv - the training data with the target column\ntest.csv - the test set; we will be predicting the target for each row in this file (the probability of the binary target)"}}