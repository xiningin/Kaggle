{"cell_type":{"1bf77f55":"code","c7b807e9":"code","a06d63a3":"code","387bf618":"code","07a37b03":"code","f8ac7276":"code","5e19fa1b":"code","05df09e0":"code","fe5cb1c1":"code","c9dda216":"code","0cbf32a7":"markdown","0a25fd9a":"markdown","2f285ab2":"markdown","92eb52ae":"markdown","6130780a":"markdown","ab71f51c":"markdown","bdb01b4f":"markdown","6aef508d":"markdown","3204cdc9":"markdown"},"source":{"1bf77f55":"import pandas as pd\nimport matplotlib.pyplot as plt\n#%matplotlib inline\n\ndata = pd.read_csv(\"..\/input\/petr4.csv\")\ndata = data.dropna()\ndata = data.iloc[:,1].values\nplt.plot(data)","c7b807e9":"periods = 30 # days","a06d63a3":"# separate the records from stock prices excluding the latest 30 days (test data)\ntrain_x = data[0:(len(data) - (len(data) % periods))]\n\ntrain_x_batches = train_x.reshape(-1, periods, 1)  \n# Uses 1 because it's only one independent feature\n# created 41 batches with 30 records with 1 feature\n\n# Using stock price for the \"next day\" of each 30 days batch as the dependent variable.\ntrain_y = data[1:(len(data) - (len(data) % periods)) + 1] # increment 1 to get the \"next day\"\ntrain_y_batches = train_y.reshape(-1, periods, 1)\n\nprint('train_x shape: ', train_x.shape)\nprint('train_y shape: ', train_y.shape)\n\nprint('train_x_batches shape: ', train_x_batches.shape)\nprint('train_y_batches shape: ', train_y_batches.shape)","387bf618":"test_x = data[-(periods + 1):]\ntest_x = test_x[:periods]\ntest_x = test_x.reshape(-1, periods, 1)\nprint('test_x shape: ', test_x.shape)\n\ntest_y = data[-(periods):]\ntest_y = test_y.reshape(-1, periods, 1)\nprint('test_y shape: ', test_y.shape)","07a37b03":"import tensorflow as tf\ntf.reset_default_graph() # memory clean","f8ac7276":"neurons_input = 1 # it's just one independent variable (feature)\nneurons_hidden = 100\nneurons_output = 1 # it's just on dependent variable\n\nxph = tf.placeholder(tf.float32, [None, periods, neurons_input])\nyph = tf.placeholder(tf.float32, [None, periods, neurons_output])\n\ndef create_cell():\n    return tf.contrib.rnn.LSTMCell(num_units = neurons_hidden, activation = tf.nn.relu)\n\ndef create_cells():\n    cells = tf.nn.rnn_cell.MultiRNNCell([create_cell() for i in range(4)]) # ten cells\n    return tf.contrib.rnn.DropoutWrapper(cells, output_keep_prob=0.1) # 10%\n\n#cell = tf.contrib.rnn.BasicRNNCell(num_units = neurons_hidden, activation = tf.nn.relu)\ncell = create_cells()\ncell_output = tf.contrib.rnn.OutputProjectionWrapper(cell, output_size=1) # Dense Neural Network\n\nrnn_output, _ = tf.nn.dynamic_rnn(cell_output, xph, dtype=tf.float32)\n\nerror = tf.losses.mean_squared_error(labels=yph, predictions=rnn_output)\n\noptimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n\ntrain = optimizer.minimize(error)","5e19fa1b":"with tf.Session() as s:\n    s.run(tf.global_variables_initializer())\n    \n    for epoch in range(1000):\n        _, cost = s.run([train, error], feed_dict = { xph: train_x_batches, yph: train_y_batches })\n        if epoch % 100 == 0:\n            print('Epoch: ', epoch + 1, ' - Cost error: ', cost)\n            \n    \n    predictions = s.run(rnn_output, feed_dict = { xph: test_x })\n    ","05df09e0":"import numpy as np\ncheck_y = np.ravel(test_y) # reduction (1,30,1) to (30,)\ncheck_predictions = np.ravel(predictions)","fe5cb1c1":"from sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(check_y, check_predictions)\nmae\n# we got a high error of $5.5 into prices. \n# It's really bad, so we got a bad result using LSTM with Dropout. \n# So, it's a hard work to improve the algortihm changing the parameters, epochs, cells, etc.","c9dda216":"plt.plot(check_y, '*', markersize=10, label = 'Real value')\nplt.plot(check_predictions, 'o', markersize=10, label = 'Predictions')\nplt.legend()\n\nplt.plot(check_y, label = 'Real value')\nplt.plot(check_predictions, label = 'Predictions')\nplt.legend()","0cbf32a7":"# Test data\n\nUsing stock price of latest 30 days as the dependent variable to evaluate the accuracy.","0a25fd9a":"## Neural Network Execution","2f285ab2":"# Evaluate","92eb52ae":"# Introduction\n\nIt's a basic kernel using TensorFlow and Long-short Term Memory Recurrent Neural Network (LSTM RNN) to predict a stock price using 4 cells into hidden layer and 10% of Dropout (discard some input values to avoid overfitting).\n\nUsing 30 days (records) of PETR4 stock prices, we will try to predict the stock price for the next day.\n\nPETR4 is a stock into BOVESPA (Brazil Stock Market).","6130780a":"# Train Data","ab71f51c":"# TensorFlow implementation","bdb01b4f":"### Accuracy\n\nWe got a bad result using LSTM and Dropout technique for this dataset.","6aef508d":"## Neural Network definitions","3204cdc9":"# Definitions\n\nWe will predict stock prices for the next 30 days of PETR4 company.\n"}}