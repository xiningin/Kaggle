{"cell_type":{"048eb600":"code","516359f4":"code","a2da82ee":"code","bbbacb17":"code","d5846dc9":"code","ded92cd1":"code","091b1324":"code","1d59991f":"code","4f893fee":"code","7d43eefd":"code","49a1545c":"code","d6cae122":"code","bfd21a51":"code","73a3f3c2":"code","06cf3694":"code","9246bcba":"code","ddd1b6ca":"code","bcd1421f":"code","bd9919a1":"code","efd4740e":"code","f9c7a58e":"markdown","aa6f62e8":"markdown","03ed1b14":"markdown","9c8265e7":"markdown","a156e3bc":"markdown","f5ff461e":"markdown","aed1b7c9":"markdown","c9249c4b":"markdown","0e9c49fe":"markdown","09b95621":"markdown","efdc984d":"markdown","2da9021d":"markdown"},"source":{"048eb600":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTflG6gYn-XUyauI8rxZTQnWdQr_S2CtnBRfPb4YWvLCRrPa9WG_w&s',width=400,height=400)","516359f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a2da82ee":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSt9TkOMRKELbw4BtywZLt9NyOOhFdEQ0Y2DTj7yLObQjK0IBuv&s',width=400,height=400)","bbbacb17":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('..\/input\/sf-ethics-commission-enforcement-summaries\/ethics-commission-enforcement-summaries.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'ethics-commission-enforcement-summaries.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","d5846dc9":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/sfethics.org\/wp-content\/uploads\/2015\/06\/campaign_consultant_vendor_payments.png',width=400,height=400)","ded92cd1":"df.head()","091b1324":"df.dtypes","1d59991f":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcT0KlNOV30EsYcmruwRjA1J2IoXZWiWPUGklvbfKdY4Qoj2xSETIw&s',width=400,height=400)","4f893fee":"df.loc[df[\"Disposition\"] == 0.0, \"Respondents\"].hist(alpha = 0.5);\ndf.loc[df[\"Disposition\"] == 1.0, \"Respondents\"].hist(alpha = 0.5);","7d43eefd":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTd6EJ10dqtlXzrmHqNKOXm5O_aSIRD4voPrADo1xca52zeh-8Nwg&s',width=400,height=400)","49a1545c":"df.groupby(['Disposition']).size().plot.bar()","d6cae122":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/sfethics.org\/wp-content\/uploads\/2015\/06\/campaign_consultants_client_payments.png',width=400,height=400)","bfd21a51":"# Necessary Functions: \ndef pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label+value\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig","73a3f3c2":"import plotly.offline as py\nvalue_counts = df['Disposition'].value_counts()\nlabels = value_counts.index.tolist()\npy.iplot(pie_plot(labels, value_counts,['#1B9E77', '#7570B3'], \"Type Distribution\"))","06cf3694":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df.Disposition)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200, background_color=\"black\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","9246bcba":"from collections import Counter\nimport json\nfrom IPython.display import HTML\nimport altair as alt\nfrom  altair.vega import v5","ddd1b6ca":"##-----------------------------------------------------------\n# This whole section \nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v5.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n\n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\")))","bcd1421f":"def word_cloud(df, pixwidth=6000, pixheight=350, column=\"index\", counts=\"count\"):\n    data= [dict(name=\"dataset\", values=df.to_dict(orient=\"records\"))]\n    wordcloud = {\n        \"$schema\": \"https:\/\/vega.github.io\/schema\/vega\/v5.json\",\n        \"width\": pixwidth,\n        \"height\": pixheight,\n        \"padding\": 0,\n        \"title\": \"Hover to see number of occureances from all the sequences\",\n        \"data\": data\n    }\n    scale = dict(\n        name=\"color\",\n        type=\"ordinal\",\n        range=[\"cadetblue\", \"royalblue\", \"steelblue\", \"navy\", \"teal\"]\n    )\n    mark = {\n        \"type\":\"text\",\n        \"from\":dict(data=\"dataset\"),\n        \"encode\":dict(\n            enter=dict(\n                text=dict(field=column),\n                align=dict(value=\"center\"),\n                baseline=dict(value=\"alphabetic\"),\n                fill=dict(scale=\"color\", field=column),\n                tooltip=dict(signal=\"datum.count + ' occurrances'\")\n            )\n        ),\n            \"transform\": [{\n            \"type\": \"wordcloud\",\n            \"text\": dict(field=column),\n            \"size\": [pixwidth, pixheight],\n            \"font\": \"Helvetica Neue, Arial\",\n            \"fontSize\": dict(field=\"datum.{}\".format(counts)),\n            \"fontSizeRange\": [10, 60],\n            \"padding\": 2\n        }]\n    }\n    wordcloud[\"scales\"] = [scale]\n    wordcloud[\"marks\"] = [mark]\n    \n    return wordcloud\n\nfrom collections import defaultdict\n\ndef wordcloud_create(df):\n    ult = {}\n    corpus = df.Disposition.values.tolist()\n    final = defaultdict(int) #Declaring an empty dictionary for count (Saves ram usage)\n    for words in corpus:\n        for word in words.split():\n             final[word]+=1\n    temp = Counter(final)\n    for k, v in  temp.most_common(200):\n        ult[k] = v\n    corpus = pd.Series(ult) #Creating a dataframe from the final default dict\n    return render(word_cloud(corpus.to_frame(name=\"count\").reset_index(), pixheight=600, pixwidth=900))","bd9919a1":"wordcloud_create(df)","efd4740e":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcT5M6rbXSfAZcR8Jhdx4sr1NMCzBJf4jojNxC7kIn6ppX7aAqtR&s',width=400,height=400)","f9c7a58e":"#codes from Shivam Ralli @hoshi7","aa6f62e8":"I tried to make some visualization, it seems smth took my Allegations away.Which seems unethical or probably I don't know how to work. ","03ed1b14":"Kaggle Notebook Runner: Mar\u00edlia Prata @mpwolke","9c8265e7":"Image slideserve.com","a156e3bc":"Image sfmagazine.com - DATA ETHICS: DOING THE RIGHT THING WITH DATA by Jim Tadewald, CMA, CFM, CIA, CRISC, CFE. https:\/\/sfmagazine.com\/post-entry\/june-2019-data-ethics-doing-the-right-thing-with-data\/","f5ff461e":"Image yumpu.com - https:\/\/www.yumpu.com\/en\/document\/view\/55791144\/ethics-for-powerful-algorithms","aed1b7c9":"Image sfethics.org - Vendor\/Subvendor Payments \u2013 Dashboards \u2013 Campaign Consultant Disclosure - Annual Total Payments Promised or Received\nhttps:\/\/sfethics.org\/disclosures\/campaign-consultant-disclosure\/campaign-consultant-disclosure-dashboards","c9249c4b":"Image sfethics.org - Client Payments \u2013 Dashboards \u2013 Campaign Consultant Disclosure https:\/\/sfethics.org\/disclosures\/campaign-consultant-disclosure\/campaign-consultant-disclosure-dashboards","0e9c49fe":"Image sftomorrow.org","09b95621":"The Ethics Commission was established by San Francisco voters in November 1993, and serves the public, City employees and officials, and local candidates through education and enforcement of governmental ethics laws, including public information, reports and advice; campaign disclosure and economic interests filings; lobbyist and campaign consultant registration and reporting; public financing for City campaigns; audits, investigations and enforcement. https:\/\/sfethics.org\/\n","efdc984d":"* Image ethicstoolkit.ai \n* Algorithm use in government is inevitable.\n* Data collection is typically a separate effort with different intentions from the analysis and use of it.\n* All data has bias.\n* All algorithms have bias.\n* All people have bias. (#D4GX)","2da9021d":"#codes from Shivam Ralli @hoshi7 "}}