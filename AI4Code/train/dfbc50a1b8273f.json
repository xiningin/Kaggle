{"cell_type":{"bf7b4d5d":"code","63ee6518":"code","992169c1":"code","5f67cfdb":"code","06ddbbcf":"code","bfc658c8":"code","c71f9d69":"code","b64ee278":"code","1c849663":"code","ccb6584b":"code","f3ceade6":"code","b0ebcd79":"code","bbb81678":"code","0b2a6822":"code","ebc1afe4":"code","3f730eb4":"code","634ff4c3":"code","86002c53":"code","a02da0a9":"code","d22b1834":"code","d7e443d4":"code","20ea5e57":"code","0829568c":"markdown","ddfb0482":"markdown","a3185da9":"markdown","b61444cb":"markdown","776b7b59":"markdown","78429759":"markdown","7637a7fc":"markdown","4256bd12":"markdown"},"source":{"bf7b4d5d":"# import libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","63ee6518":"# data doesn't have headers, so let's create headers\n_headers = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'car']","992169c1":"# read in cars dataset\ndf = pd.read_csv('https:\/\/raw.githubusercontent.com\/PacktWorkshops\/The-Data-Science-Workshop\/master\/Chapter06\/Dataset\/car.data', names=_headers, index_col=None)","5f67cfdb":"df.head()","06ddbbcf":"training, evaluation = train_test_split(df, test_size=0.3, random_state=0)","bfc658c8":"validation, test = train_test_split(evaluation, test_size=0.5, random_state=0)","c71f9d69":"# encode categorical variables\n_df = pd.get_dummies(df, columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n_df.head()","b64ee278":"# target column is 'car'\n\nfeatures = _df.drop(['car'], axis=1).values\nlabels = _df[['car']].values\n\n# split 80% for training and 20% into an evaluation set\nX_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.3, random_state=0)\n\n# further split the evaluation set into validation and test sets of 10% each\nX_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, test_size=0.5, random_state=0)","1c849663":"# train a Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)","ccb6584b":"# make predictions for the validation dataset\ny_pred = model.predict(X_val)","f3ceade6":"#import libraries\nfrom sklearn.metrics import confusion_matrix","b0ebcd79":"confusion_matrix(y_val, y_pred)","bbb81678":"#import libraries\nfrom sklearn.metrics import precision_score","0b2a6822":"precision_score(y_val, y_pred, average='macro')","ebc1afe4":"# import libraries\nfrom sklearn.metrics import recall_score","3f730eb4":"recall_score = recall_score(y_val, y_pred, average='macro')\nprint(recall_score)","634ff4c3":"#import libraries\nfrom sklearn.metrics import f1_score","86002c53":"f1_score = f1_score(y_val, y_pred, average='macro')\nprint(f1_score)","a02da0a9":"# import necessary library\nfrom sklearn.metrics import accuracy_score","d22b1834":"_accuracy = accuracy_score(y_val, y_pred)\nprint(_accuracy)","d7e443d4":"# import libraries\nfrom sklearn.metrics import log_loss","20ea5e57":"_loss = log_loss(y_val, model.predict_proba(X_val))\nprint(_loss)","0829568c":"# Creating recall score","ddfb0482":"# Creating confusion matrix","a3185da9":"# Computing Log Loss","b61444cb":"# creating f1 score","776b7b59":"# Creating accuracy score","78429759":"# Creating classification model","7637a7fc":"# My work on car evaluation","4256bd12":"# Creating precision score"}}