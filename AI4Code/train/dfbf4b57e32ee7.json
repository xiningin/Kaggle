{"cell_type":{"5e079607":"code","0cb8aadb":"code","5bafbd4d":"code","a39cda88":"code","5ca63d91":"code","e9c04828":"code","6e0d2aa7":"code","9eaec21f":"code","5eaf405c":"code","402ae215":"code","644a0231":"code","809ddc82":"code","5f2adcbc":"code","3166b2fc":"code","4538c0ca":"code","3ea59e4b":"code","1d49b7f0":"code","481b7a33":"code","ba726078":"code","45dfdcfd":"code","7448dd76":"code","4f1dfdc8":"code","d3612c0b":"code","b87ddfc0":"code","0077105d":"code","22278d65":"code","cced48fb":"code","6cea5a70":"code","c5439466":"code","8ae256b3":"code","7924f254":"code","5da829df":"code","3ad27511":"code","861125ac":"code","477919a2":"code","d9fb15c4":"code","b46a02d1":"code","8b2668a4":"code","c6ae775d":"code","78e23f59":"code","c25595c6":"code","ac0ee143":"code","267d2a4f":"code","e5b3886e":"code","a16ec37b":"code","5a45bf00":"code","e85c6b27":"code","64f54b78":"code","822bb58f":"code","4825dbb5":"code","10c9ea8e":"code","bb9035a6":"code","d0e3a4b1":"code","3ede82c0":"code","a855ca8b":"code","e22e983a":"code","822d6579":"code","6d9b1b89":"code","173e8509":"code","97b28193":"code","dfa6e57b":"code","93a2c423":"code","30de8cbb":"code","0e8559fc":"markdown","fc6b2e29":"markdown","9f8e8939":"markdown","6a877038":"markdown","7c77da85":"markdown","783cadee":"markdown","f9c34b11":"markdown","e4ebeeaa":"markdown","370b578b":"markdown","d54b76aa":"markdown","58d61956":"markdown","6bef8c17":"markdown","d244e42e":"markdown","675dd0d5":"markdown","5fcd78c5":"markdown","5db50151":"markdown","ebad0eb6":"markdown","416ab1bf":"markdown","626d3ba0":"markdown","052b41cb":"markdown","e1e33adb":"markdown","7b85e5b5":"markdown","c61a3876":"markdown","3b6c133f":"markdown","bf5a54cb":"markdown","da99b500":"markdown","e12b7f6d":"markdown","79b3f430":"markdown","48bd4c40":"markdown","cf187da2":"markdown","4008ed75":"markdown","ca5a9ba4":"markdown","b69e7627":"markdown","a573ac8d":"markdown","0038edf8":"markdown","6fe712d6":"markdown"},"source":{"5e079607":"import pandas as pd\nimport numpy as np  \nimport matplotlib.pyplot as plt\nimport seaborn as sns","0cb8aadb":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest  = pd.read_csv('..\/input\/titanic\/test.csv')","5bafbd4d":"train.head()","a39cda88":"test.head()","5ca63d91":"train.info()","e9c04828":"train.describe().T","6e0d2aa7":"train.describe(include=['O']).T","9eaec21f":"# EXplore Missing Values\ntrain.isnull().sum().sort_values(ascending=False)","5eaf405c":"test.isnull().sum().sort_values(ascending=False)","402ae215":"df_num = train[['Age','SibSp','Parch','Fare']]\ndf_cat = train[['Survived' , 'Sex' , 'Pclass' , 'Embarked']]","644a0231":"for col in df_num.columns:\n  plt.hist(df_num[col])\n  plt.title(col)\n  plt.show()","809ddc82":"for col in df_cat.columns:\n  sns.barplot( df_cat[col].value_counts().index,df_cat[col].value_counts() ).set_title(col)\n  plt.show()\n\n    ","5f2adcbc":"sns.countplot(x=\"Survived\" , hue=\"Sex\" , data=train)","3166b2fc":"train[['Sex' , 'Survived']].groupby(['Sex'],as_index=False).mean().sort_values(by='Survived' , ascending=False)","4538c0ca":"sns.countplot(x=\"Survived\" , hue = \"Pclass\" , data=train)","3ea59e4b":"train[['Survived' , 'Pclass']].groupby(['Pclass']).mean().sort_values(by='Survived' , ascending=False)","1d49b7f0":"pd.pivot_table(train,values=\"Name\" , index=[\"Pclass\",\"Sex\"] , columns=\"Survived\",aggfunc=\"count\" )","481b7a33":"train[['Survived' , 'Sex' , 'Pclass']].groupby(['Pclass' , 'Sex']).mean().sort_values(by='Survived' , ascending=False)","ba726078":"sns.countplot(x=\"Survived\", hue=\"Embarked\",data=train)","45dfdcfd":"#pd.pivot_table(train,values=\"Name\", index=['Pclass' , 'Embarked'] , columns=\"Age\",aggfunc=\"count\")\nsns.countplot(x='Embarked' , hue='Pclass',data=train)","7448dd76":"sns.heatmap(train.corr(),annot=True)","4f1dfdc8":"train[['Embarked' , 'Age' ]].groupby(['Embarked' ]).mean().sort_values(by='Age' , ascending=False)","d3612c0b":"train[['Age' , 'Sex']].groupby(['Sex']).mean().sort_values(by='Age' , ascending=False)","b87ddfc0":"train[['SibSp' ,  'Parch','Age']].groupby(['SibSp','Parch']).mean().sort_values(by ='Age' , ascending=False)","0077105d":"train[['Age' , 'Sex' , 'Pclass']].groupby(['Pclass' , 'Sex']).mean().sort_values(by='Age' , ascending=False)","22278d65":"age = pd.cut(train['Age'], [0, 18, 32,48,64,80])\ntrain.pivot_table('Survived', ['Sex', age], 'Pclass').plot.bar()","cced48fb":"dataset = pd.concat((train,test) , sort = False).reset_index(drop=True)\ndataset = dataset.drop(columns =['Survived'], axis =1 )","6cea5a70":"dataset.head()","c5439466":"#columns that have missing values :- \n#Cabin ==>  687 , Age ==> 177 , Embarked === > 2\ndef impute_age(col):\n  Age    = col[0]\n  Pclass = col[1]\n  Sex    = col[2]\n  if pd.isnull(Age):\n    if Pclass==1:\n      if Sex == 'female':\n        return 34\n      else:\n        return 41\n    elif Pclass == 2:\n      if Sex == 'female':\n        return 28\n      else:\n        return 30\n    elif Pclass==3:\n      if Sex =='female':\n        return 21\n      else:\n        return 26\n  else:\n   return Age \n\n","8ae256b3":"dataset['Age']= dataset[['Age','Pclass' , 'Sex']].apply(impute_age,axis=1)","7924f254":"dataset['Embarked'] = dataset['Embarked'].fillna(dataset['Embarked'].mode()[0])","5da829df":"dataset['Cabin_ch'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)\ndataset.drop('Cabin',axis=1 , inplace=True)\ndataset.head()\n#dataset['Cabin'][0]","3ad27511":"# make intiution on Cabin_ch\ndataset['Cabin_ch'].value_counts()","861125ac":"#explore correlation between Fare and Cabin_ch\ndataset.pivot_table('Fare' , 'Cabin_ch' , aggfunc='median').sort_values(by='Fare' , ascending=False)","477919a2":"dataset.pivot_table(values='Cabin_ch' , index='Embarked' , aggfunc='count').sort_values(by='Cabin_ch',ascending=False)","d9fb15c4":"sns.countplot(y='Embarked' , hue='Cabin_ch',data=dataset)","b46a02d1":"dataset['Cabin_ch']= dataset['Cabin_ch'].fillna('C')","8b2668a4":"dataset.head()","c6ae775d":"dataset['Fare']=dataset['Fare'].fillna(dataset['Fare'].median())","78e23f59":"dataset.isnull().sum().sort_values(ascending=False)","c25595c6":"#check for Duplicate values\nduplicate = dataset[dataset.duplicated()]\nprint(duplicate)","ac0ee143":"dataset['Title']= dataset.Name.apply(lambda x : x.split(',')[1].split('.')[0].strip())","267d2a4f":"pd.unique(dataset['Title'])","e5b3886e":"dataset['Title'].value_counts()","a16ec37b":"#train['Title'].replace(['Dr' , 'Rev','Col',''])","5a45bf00":"#train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived' , ascending=False)","e85c6b27":"dataset['Pclass'] = dataset['Pclass'].astype('str')","64f54b78":"dataset.drop(['PassengerId','Name' ,'Ticket'] , axis =1 , inplace=True)","822bb58f":"dataset.head()","4825dbb5":"dataset = pd.get_dummies(dataset , drop_first= True).reset_index(drop=True)\ndataset.head() ","10c9ea8e":"y=train['Survived']\nX = dataset.iloc[:len(y),:]\ndf_test = dataset.iloc[len(y): , : ]","bb9035a6":"from sklearn.preprocessing import MinMaxScaler\nsc_X = MinMaxScaler()\nsc_test = MinMaxScaler()\nX=sc_X.fit_transform(X)\ndf_test=sc_test.fit_transform(df_test)","d0e3a4b1":"from sklearn.model_selection import train_test_split\nX_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.3 , random_state=0)","3ede82c0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nlogReg = LogisticRegression()\nlogReg.fit(X_train,y_train)\nlogReg_pred = logReg.predict(X_test)\n#Evalulate Model\nlogReg_acc_score= round(accuracy_score(y_test,logReg_pred),2)\nprint('Logistic Regression Score :  ',logReg_acc_score)\n## using Cross validation \ncv_logReg = round(cross_val_score(logReg , X , y, cv=5).mean(),2)\nprint('cross_val_score LogReg :  ',cv_logReg, '\\n\\n')","a855ca8b":"from sklearn.metrics import  confusion_matrix\nlogReg_accuracy = confusion_matrix(y_test,logReg_pred)\nprint(logReg_accuracy)","e22e983a":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,logReg_pred))","822d6579":"from sklearn.neighbors import KNeighborsClassifier\nknc = KNeighborsClassifier()\nknc.fit(X_train,y_train)\nknc_pred = knc.predict(X_test)\n# evaluate accuracy \nknc_accuracy = round(accuracy_score(y_test,knc_pred),2)\nprint('KNeighbors Classifier :    ',knc_accuracy)\n## using cross validation\ncv_knc = round(cross_val_score(knc,X,y,cv=5).mean(),2)\nprint('cross_val_score K_Nearest Neighbors :    ',cv_knc , '\\n\\n')","6d9b1b89":"from sklearn.svm import SVC\nsvc = SVC(kernel='rbf' , random_state=0)\nsvc.fit(X_train , y_train)\nsvc_pred = svc.predict(X_test)\n# evaluate accuracy \nsvc_accuracy = round(accuracy_score(y_test,svc_pred),2)\nprint(svc_accuracy)\n## using cross validation\ncv_svc = round(cross_val_score(svc,X,y,cv=5).mean(),2)\nprint('cross_val_score :    ',cv_svc , '\\n\\n')","173e8509":"from sklearn.naive_bayes import GaussianNB\nn_bayes = GaussianNB()\nn_bayes.fit(X_train ,y_train)\nn_bayes_pred = n_bayes.predict(X_test)\n# evaluate accuracy \nn_bayes_acc = round(accuracy_score(y_test,n_bayes_pred),2)\nprint('Naive Bayes:   ',n_bayes_acc )\n## using cross validataion\ncv_n_bayes = round(cross_val_score(n_bayes,X,y,cv=5).mean(),2)\nprint('cross_val_score:   ' , cv_n_bayes,'\\n\\n')","97b28193":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(criterion = 'entropy',random_state=0)\ntree.fit(X_train, y_train)\ntree_pred = tree.predict(X_test)\n#Evaluate Model\ntree_acc = round(accuracy_score(y_test,tree_pred),2)\nprint('Decision Tree Classifier:', tree_acc)\n## using cross validataion\ncv_tree =round(cross_val_score(tree,X,y,cv=5).mean(),2)\nprint('cross_val_score Decision Tree:   ' , cv_tree,'\\n\\n')","dfa6e57b":"from sklearn.ensemble import RandomForestClassifier\nran_forest = RandomForestClassifier(n_estimators=10 , criterion='entropy' , random_state=0)\nran_forest.fit(X_train,y_train)\nran_forest_pred = ran_forest.predict(X_test)\n#Evaluate Model\nran_forest_acc= round(accuracy_score(y_test,ran_forest_pred),2)\nprint('Random Forest :     ',ran_forest_acc)\n## using cross validataion\ncv_ran_forest =round(cross_val_score(ran_forest,X,y,cv=5).mean(),2)\nprint('cross_val_score:   ' , cv_ran_forest,'\\n\\n')","93a2c423":"models = pd.DataFrame({'Model' : ['Logistic Regression' , 'K_Nearest Neighbors', 'SVM' , 'Naive Bayes' , 'Decision Tree','Random Forest'],\n                       'Score' : [logReg_acc_score   ,knc_accuracy     ,svc_accuracy, n_bayes_acc  ,  tree_acc       , ran_forest_acc],\n                       'Cross Validation': [cv_logReg , cv_knc     ,cv_svc ,cv_n_bayes,cv_tree,cv_ran_forest]})\nmodels.sort_values(by='Score' , ascending=False)","30de8cbb":"#prediction for test data\ny_pred = logReg.predict(df_test)\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": y_pred\n    })\nsubmission.to_csv('titanic_model_v1.csv' , index=False) ","0e8559fc":"**SVM**","fc6b2e29":"**<h4>Feature Enginnereing<\/h4>**","9f8e8939":"sibling , parch , Fare ==> need to log transformation","6a877038":"**Naive Bayes**","7c77da85":"**Import Libraries**","783cadee":"most people died board from port 'S'<br>\nmost people survived board from port 'S' also ","f9c34b11":"during Explore Correlation between Cabin_ch and Embarked <br>\nfoud that there is strong correlatin between Embarked and Cabin_ch where most 'Cabin_ch' from 'S' then 'C' then 'Q' BUT 'Q' is rare<br><hr>\nmake visualizatin to show this correlation in more details and found that Cabin_ch ('C') most used either in Embarked'S' OR 'C' OR 'Q'","e4ebeeaa":"**Fill Missing Values**","370b578b":"**<h4>Visualize data <\/h4>**","d54b76aa":"**K_Nearest Neighbors**","58d61956":"**<h4>Evaluate Models<\/h4>**","6bef8c17":"**Combine train and test**","d244e42e":"*Drop Features* ","675dd0d5":"**Random Forest Classification**","5fcd78c5":"**<h4> Feature Scaling <\/h4>**","5db50151":"**<h3>Build Model<\/h3>**","ebad0eb6":"Convert Pclass data type  from number to string","416ab1bf":"**Logistic Regression**","626d3ba0":"there is missing value in :- \n1.   Cabin    686\n2.   Age      177\n3.   Embarked 2","052b41cb":"pclass feature need to convert datatype from int64 to string","e1e33adb":"make title from Name ","7b85e5b5":"Make Feature Engineer on Cabin feature then drop Cabin feature","c61a3876":"Split Data for Independent and dependent Variables","3b6c133f":"#Step 2:- preprocessing data ","bf5a54cb":"fill missing value in Age ","da99b500":"**<h4> Categorical Variables<\/h4>**\n\n","e12b7f6d":"**Submit Model**","79b3f430":"<h1><center>Titanic Problem<\/center><\/h1>\n","48bd4c40":"Split Data to train and test","cf187da2":"**Fill missing values in Cabin_ch**","4008ed75":"**<h3> Explore Data <\/h3>**","ca5a9ba4":"**Decision Tree Classifier**","b69e7627":"Embarked , Age , Pclass , Survived  ====> have strong correlation<br><hr>\nthen we can say that pclass '1' have most survived <br>\nand pclass'1' most of them from Emabrked 'C' <br>\nand Emabrked 'C' have greatest average of Age  <br><hr>\nso distribution passenger on pclass is depend on Age where class'1' has oldest passengers and pclass '3' has youngest passengers","a573ac8d":"there is correlation between : <br><hr>\nPclass with Fare     ===>  (-55%) <br>\nsibSp  with Parch    ===>  (41%) <br>\npclass with Age      ===>  (-37%) <br>\nPclass with Survived ===>  (-34%) <br>\nsibSP  with Age      ===>  (-31%> <br>\nFare with Survived   ===>   26% <br>\nparch  with Fare    ===> 22% <br>\nsibSp  with Fare    ===> 16% <br>\n\n","0038edf8":"fill Embarked missing value","6fe712d6":"**Read Data**"}}