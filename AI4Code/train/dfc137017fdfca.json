{"cell_type":{"17157989":"code","9f05fc90":"code","dc84c5b7":"code","5646c5f2":"code","814d4c85":"code","fab5e3ce":"code","eb9dd9e1":"code","b0f92afe":"code","1921061d":"code","7f9c383c":"code","7b066e9a":"code","b5b8053f":"code","19f02db7":"code","081bff5e":"code","75ec7142":"code","76a5f6d3":"code","4ef00c29":"code","6f61a818":"code","e95e73bb":"code","dece1585":"code","f5cc3c57":"code","bc578a52":"code","8ca9e5c5":"code","0e995f27":"code","7e8196ed":"code","5debf78b":"code","68a712a0":"code","17cdc439":"code","36a6524d":"code","b9172297":"code","e4672baa":"code","60dec81b":"code","582fd839":"code","81326e12":"code","ada2ff26":"code","50db2473":"code","582ce68f":"code","53c37108":"code","a2a9057c":"code","800d66f7":"code","d2be6472":"code","775f8b24":"code","ebf8ddcc":"code","492835fa":"code","de272b79":"code","291d7652":"code","3c878657":"code","a7db745a":"code","356b102b":"code","54de3daf":"code","f75d574b":"code","b3297070":"code","4cbde6fd":"code","d7d29503":"code","7530cbc7":"markdown","57f552e2":"markdown","30669b4e":"markdown","4fe6a05c":"markdown","df20e022":"markdown","d05c0301":"markdown","6dad7753":"markdown","6fb587ff":"markdown","02f43392":"markdown","9b688205":"markdown","24cd3f73":"markdown","75cdc9c2":"markdown","2ab767d0":"markdown","92cb4fd2":"markdown","c2b5aaaa":"markdown","f4dd7f7c":"markdown","a793f5eb":"markdown","770b9af3":"markdown","69e04be3":"markdown","44351f3c":"markdown","7ceaae96":"markdown","a978de53":"markdown","23827076":"markdown","2425cb78":"markdown","8d3502ce":"markdown","12dfa9a8":"markdown","7374d7fa":"markdown","70e162bf":"markdown","f34d66f9":"markdown","51a88103":"markdown","31883108":"markdown","20797a6f":"markdown","12df9acd":"markdown","6385a970":"markdown"},"source":{"17157989":"import os\nimport optuna\nimport numpy as np\nimport pandas as pd\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport sys\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import f1_score, roc_auc_score, precision_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n\n\n# Classifiers\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n\n\nMETRIC = f1_score\nmetric = 'f1_macro'\n\n# METRIC = f1_score\n# metric = 'f1'\n\n# METRIC = roc_auc_score\n# metric = 'roc_auc_ovr'\n\n# METRIC = precision_score\n# metric = 'precision_macro'","9f05fc90":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nlink = '\/kaggle\/input\/in-hospital-mortality-prediction\/data01.csv'\ndf = pd.read_csv(link)\n\ntarget = \"outcome\"\npredictors = list(df.columns)\npredictors.remove(target)\n\ndf","dc84c5b7":"plt.figure(figsize=(15, 15))\nsns.heatmap(df.isnull(), cbar=False)","5646c5f2":"def NaN_info(df):\n    global null_view\n    try:\n        null_view = df[[col for col in df.columns if df[col].isna().sum() > 0]].isna().sum().sort_values(ascending = True)\n        null_view = pd.DataFrame(null_view, columns=['NANs'])\n        null_view['PERCENT'] = null_view.NANs.apply(lambda x: round((x\/len(df))*100, 2))\n        null_view['TYPE'] = df.dtypes\n    except:\n        return null_view\n    return null_view\n\nNaN_info(df)","814d4c85":"def trash_cleaner(df, target=None):\n    '''drop_duplicates, drop rows with nan in target, drop column with 1 unique value'''\n    \n    print(f'Start shape: {df.shape}\\n')\n    print('Drop_duplicates')\n    df.drop_duplicates(inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    print(f'shape: {df.shape}\\n')\n    \n    print('Drop columns with 1 unique value')\n    for col in df.columns:\n        if len(df[col].unique()) == 1:\n            df.drop([col], inplace=True, axis=1)\n            print(f'column \"{col}\" cnontain 1 unique value and has been dropped out')\n    print(f'shape: {df.shape}\\n')\n            \n    \n    if target:\n        print('Drop rows with NaN in target feature')\n        nan = df[df[target].isnull()]\n        indeces = list(nan.index)\n        print(f'number of rows with NaN in target feature:\\\n        {len(indeces)} rows have been dropped out\\n')\n        df = df.drop(df.index[indeces])\n        df.reset_index(drop=True, inplace=True)\n    \n        print(f'Finish shape: {df.shape}\\n')\n    \n    return df","fab5e3ce":"df = trash_cleaner(df, target)","eb9dd9e1":"def recover_data(data_input_0, \n                 target = None,   # For prediction at the end\n                 verbose = 1\n                 ):\n    \n    import random\n    import pandas as pd\n    import numpy as np\n    \n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    %matplotlib inline\n\n    import sys\n    import warnings\n    if not sys.warnoptions:\n        warnings.simplefilter(\"ignore\")\n\n    from lightgbm import LGBMClassifier\n    from lightgbm import LGBMRegressor\n    \n    from sklearn.model_selection import RandomizedSearchCV\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_absolute_error\n    from sklearn.metrics import classification_report\n    from sklearn.preprocessing import LabelEncoder\n    \n\n    \n        \n    encoder_pool = {}\n    decoder_pool = {}\n    encoded_columns = []\n        \n    counter_predicted_values = 0\n    \n    data_input = data_input_0.copy()\n    \n\n    \n    def get_data_info(df):\n        data_info = pd.DataFrame(index=df.columns)\n        try:\n            data_info['NaN_counts'] = df[[col for col in df.columns if df[col].isna().sum() > 0]].isna().sum().sort_values(ascending = True)\n            data_info['NaN_percent'] = data_info['NaN_counts'].apply(lambda x: round((x\/len(df))*100, 2))\n            data_info['col_type'] = df.dtypes\n            data_info = data_info.sort_values(by=['NaN_counts'], ascending=True)\n        except:\n            return data_info\n        return data_info\n    \n    \n    def encode_column(df, enc_pool, dec_pool, column):\n        enc_pool[column] = {}\n        dec_pool[column] = {}\n        not_nan_index=df[df[column].notnull()].index\n        values_set = list(set(list(df.loc[not_nan_index, column])))\n        value = 0.0\n        for el in values_set:\n            enc_pool[column][el] = value\n            dec_pool[column][value] = el\n            value += 1\n        df[column] = df[column].map(enc_pool[column])\n        df[column] = df[column].astype('float64')\n        return df\n    \n    \n    def get_continuous_columns(continuous_columns, target_column):\n        continuous_features_now = continuous_columns[:]\n        if target_now in continuous_features_now:\n            continuous_features_now.remove(target_column)\n        return continuous_features_now\n    \n    \n    def normalize_data(df_in, continuous_columns):\n        for col in continuous_columns:\n            df_in[col] = np.log1p(df_in[col])\n        return df_in\n    \n    \n    def get_class_weight(y):\n        global class_weight\n        class_weight={}\n        unique = []\n        counts = []\n        values_counted = (pd.DataFrame(y)).value_counts().sort_values(ascending=False)\n        for idx, val in values_counted.items():\n            unique.append(idx[0])\n            counts.append(val)\n\n        max_value = max(counts)\n        j = 0\n        for el in unique:\n            class_weight[el] = int(max_value\/counts[j])\n            j += 1\n        return class_weight\n\n    \n    def predict(X__train, y__train, X__pred, algorithm):\n        model = algorithm.fit(X__train, y__train)\n        y_hat = list(model.predict(X__pred))\n        return y_hat\n\n    \n    def imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el):\n        df.loc[miss_indeces, el] = pred_miss[:]\n        if verbose:\n            print(f' __ {len(miss_indeces)} __ values have been imputed\\n')\n        return df\n    \n    \n    def decode_column(df, dec_pool, column):\n        df[column] = df[column].map(dec_pool[column])\n        df[column] = df[column].astype('object')\n        return df\n    \n    \n    \n    \n    # main\n    if verbose:\n        plt.figure(figsize=(20, 5))\n        sns.heatmap(data_input.isnull(), cbar=False)\n\n    \n    data_info = get_data_info(data_input)\n    if verbose:\n        print('\\n\\n\\n')\n        print(data_info)\n        print('\\n\\n\\n')\n    \n    all_features = list(data_input.columns)\n    data_input_indeces = list(data_input.index)\n    data_input.reset_index(drop=True, inplace = True)\n    \n    all_miss_features = list(data_info.index[data_info['NaN_counts'] > 0])\n\n    # move target_feature to end of the prediction\n    if target:\n        if target in all_miss_features:\n            all_miss_features.append(all_miss_features.pop(all_miss_features.index(target)))\n            \n    # a simple encoding\n    for col in data_input.columns:\n        feature_type = data_info.loc[col, 'col_type']\n        if feature_type == 'object' or feature_type == 'bool':            \n            data_input[col] = encode_column(data_input[[col]], encoder_pool, decoder_pool, col)\n            encoded_columns.append(col)\n        else:\n            # object column with NaN sometimes has type float64\n            try:\n                data_input.loc[:, col] = data_input.loc[:, col] + 0\n            except:\n                data_input[col] = data_input[col].astype('object')\n                data_input[col] = encode_column(data_input[[col]], encoder_pool, decoder_pool, col)\n                encoded_columns.append(col)\n    \n    \n    # get continuous features\n    continuous_features = []\n    for col in data_input.columns:\n        count = len(data_input[col].value_counts())\n        if count > 20:\n            continuous_features.append(col)\n\n    \n    # work with each column containing NaNs\n    for target_now in all_miss_features:\n        if verbose:\n            print('='*90,'\\n')\n        # predictors for iteration\n        predictors = all_features[:]\n        predictors.remove(target_now)\n        \n        continuous_features_now = get_continuous_columns(continuous_features, target_now)\n        \n        # indexes of missing data in target_now (data for prediction)\n        miss_indeces = list((data_input[pd.isnull(data_input[target_now])]).index)\n\n        # data without NaN rows (X data for train & evaluation of model)\n        work_indeces = list(set(data_input_indeces) - set(miss_indeces))\n        \n        # X data for predict target NaNs\n        miss_df = data_input.loc[miss_indeces, predictors]\n#         miss_df = normalize_data(miss_df, continuous_features_now)\n        \n        # X data for train and model evaluation \n        work_df = data_input.iloc[work_indeces, : ]\n#         work_df = normalize_data(work_df, continuous_features_now)\n        \n        X = work_df[predictors]\n        y = work_df[target_now]\n\n        target_values_counted = y.value_counts()\n        last_item = target_values_counted.tail(1).item() \n        \n        \n        feature_type_target = data_info.loc[target_now, 'col_type']\n        if len(target_values_counted) < 11 or feature_type_target == 'object':\n            labelencoder = LabelEncoder()\n            y = labelencoder.fit_transform(y).astype('int64')\n            \n            \n        if feature_type_target == 'object' and last_item < 2:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n        elif feature_type_target == 'object' and last_item < 3:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0, stratify=y)\n        elif feature_type_target == 'object' and last_item < 5:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)\n        elif feature_type_target == 'object':\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n        else:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n\n        \n        # Info\n        if verbose:\n            percent_missing_data = data_info.loc[target_now, 'NaN_percent']\n            print(f'Feature: {target_now}, missing values: {percent_missing_data}%\\n')    \n            print(f'Shape for train & test: {(X.shape)}')\n            print('')\n            if len(target_values_counted) < 11:\n                print(f'values_count:')\n                print(target_values_counted)\n                print('')\n\n        \n        # PREDICTIONS\n        if len(target_values_counted) < 11 or feature_type_target == 'object':\n            class_weight = get_class_weight(y_train)\n            alg = LGBMClassifier(n_jobs=-1, random_state=0, class_weight=class_weight)                \n            pred_test = predict(X_train, y_train, X_test, alg)\n\n            if verbose:\n                print('FAST CLASSIFIER:')\n                print(f'Weights transferred to the classifier: {class_weight}')\n                print('\\nEvaluations:')\n                print(f'first 20 y_test: {list(y_test[:20])}')\n                print(f'first 20 y_pred: {pred_test[:20]}\\n')\n                print(f'Classification Report:\\n')\n                print(classification_report(y_test, pred_test), '\\n')\n\n#             ADVANCED  alg = LGBMClassifier(n_jobs=-1, random_state=0, class_weight=class_weight)                \n            pred_miss = predict(X_train, y_train, miss_df, alg)\n\n            pred_miss = [int(i) for i in pred_miss]\n            pred_miss = labelencoder.inverse_transform(pred_miss)\n            imput_missing_value_to_main_df(data_input, miss_indeces, pred_miss, target_now)\n            counter_predicted_values += len(miss_indeces)\n\n        elif feature_type_target == 'float64' or feature_type == 'int64':\n            alg = LGBMRegressor(n_jobs=-1, random_state=0)\n            pred_test = predict(X_train, np.log1p(y_train), X_test, alg)\n            pred_test = np.expm1(pred_test)\n\n            pred_test[pred_test == -np.inf] = 0\n            pred_test[pred_test == np.inf] = 0\n\n            MAE = mean_absolute_error(y_test,pred_test)\n            y_te = list(round(y_test[:10], 1))\n            y_pred = list(np.round(pred_test[:10], 1))\n            \n            if verbose:\n                print('FAST REGRESSOR:')\n                print('\\nEvaluations:')\n                print(f'first 10 y_test: {y_te}')\n                print(f'first 10 y_pred: {y_pred}\\n')\n                print(f'MAE for {target_now}: {MAE}')\n                print(f'min for {target_now}: {data_input[target_now].min()}')\n                print(f'avg for {target_now}: {data_input[target_now].mean()}')\n                print(f'max for {target_now}: {data_input[target_now].max()}\\n')\n\n\n#             ADVANCED  alg = LGBMRegressor(n_jobs=-1, random_state=0)\n            pred_miss = predict(X, np.log1p(y), miss_df, alg)\n            pred_miss = np.expm1(pred_miss)  \n\n            pred_miss[pred_miss == -np.inf] = 0\n            pred_miss[pred_miss == np.inf] = 0\n\n            imput_missing_value_to_main_df(data_input, miss_indeces, pred_miss, target_now)\n            counter_predicted_values += len(miss_indeces)\n\n        else:\n            if verbose:\n                print(f\"unprocessed feature: {target_now} - {feature_type} type\")\n\n\n        \n        del predictors\n        del miss_indeces\n        del miss_df        \n        del work_df\n        del X\n        del y\n        del X_train\n        del X_test\n        del y_train\n        del y_test\n\n    # return states to their initial states    \n    for col in encoded_columns:\n        data_input[col] = decode_column(data_input[[col]], decoder_pool, col)\n        \n    for col in data_input.columns:\n        data_input[col] = data_input[col].astype(data_info.loc[col, 'col_type'])\n                \n    data_input.index = data_input_indeces\n\n    if verbose:\n        plt.figure(figsize=(20, 5))\n        sns.heatmap(data_input.isnull(), cbar=False)\n        print('\\n\\n\\n')\n        data_info = get_data_info(data_input)\n        print(data_info)\n        print('\\n\\n\\n')\n        print(f'{counter_predicted_values} values have been predicted and replaced. \\\n        {(counter_predicted_values*100\/(data_input.shape[0]*data_input.shape[1]))} % of data')\n        print('\\n')\n    \n\n    return data_input","b0f92afe":"df = recover_data(df)","1921061d":"df[target] = df[target].astype('int64')\ndf['group'] = df['group'].map({1:0, 2:1})\ndf['gendera'] = df['gendera'].map({1:0, 2:1})","7f9c383c":"predictors = list(df.columns)\npredictors.remove(target)","7b066e9a":"def encoding(work_df, columns):\n    for col in columns:\n        feature_type = work_df[col].dtype\n        if feature_type == 'object' or feature_type == 'bool':\n            labelencoder = LabelEncoder()\n            work_df.loc[:, col] = labelencoder.fit_transform(work_df.loc[:, col])\n    return work_df\n\n\ndf = encoding(df, predictors)","b5b8053f":"sns.displot(data=df, x=target)","19f02db7":"fig, axes = plt.subplots(nrows=10, ncols=5, figsize=(20,40))\naxes = axes.flatten()\n\nfor idx, axis in enumerate(axes):\n    sns.histplot(data=df, x=df[predictors].iloc[:, idx],\n                 ax=axis, hue=target, legend=True)\n    axis.set_ylabel('')    \n    axis.set_xlabel('')\n    axis.set_title(predictors[idx])","081bff5e":"def evaluate_model(train_X, train_y, test_X, test_y, default_model):\n    values_counted = train_y.value_counts()\n    if len(values_counted) < 11:\n        model = default_model.fit(train_X, train_y)\n        pred = model.predict(test_X)\n        score = METRIC(test_y, pred, average='macro')\n        print(f'{metric}: {score}\\n')\n        print(classification_report(test_y, pred), '\\n')\n\n\n        f, ax = plt.subplots(1, 3, figsize=(13, 4))\n\n        plt.subplot(1, 3, 1)\n        cm = confusion_matrix(test_y, pred)\n        sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.0f',  ax=ax[0])\n        ax[0].set_title(\"Confusion Matrix\")\n        \n        plt.subplot(1, 3, 2)\n        plt.plot([1,0], color='red')\n        plot_precision_recall_curve(model, test_X, test_y, ax=ax[1])\n        ax[1].set_title(\"PR AUC\")\n\n        plt.subplot(1, 3, 3)\n        plt.plot([0,1], color='red')\n        plot_roc_curve(model, test_X, test_y, ax=ax[2])\n        ax[2].set_title(\"ROC AUC\")\n\n        f.tight_layout()\n\n    else:\n        model = default_model.fit(train_X, train_y)\n        pred_test = model.predict(test_X)\n        MAE = mean_absolute_error(test_y, pred_test)\n        MSE = mean_squared_error(test_y, pred_test)\n        print(f'mean_absolute_error: {MAE}')\n        print(f'mean_squared_error: {MSE}')\n\n    return 0","75ec7142":"X = df[predictors]\ny = df[target]\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, stratify=y, test_size=0.1, random_state=42)\n\n\nclassifier = XGBClassifier(verbosity=0, random_state=42, n_jobs=-1)\nevaluate_model(train_X, train_y, test_X, test_y, classifier)","76a5f6d3":"# train_test_split_ordered works correctly with test_size = 0.1, 0.2, 0.25, 0.33, 0.5 \n\ndef train_test_split_balanced(df, target_feature, test_size=0.33, verbose=0, research_iter=0):\n    \n    import matplotlib.pyplot as plt\n    from lightgbm import LGBMRegressor\n    from lightgbm import LGBMClassifier \n    from sklearn.inspection import permutation_importance\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_absolute_error\n    from sklearn.metrics import f1_score\n\n    \n    global df_count\n    global df_work\n    \n    \n    df_work = pd.DataFrame()\n    df_count = pd.DataFrame()\n    \n    \n    CLASSIFIER_FOR_UNIQUE_VALUES_LESS_THAN = 10\n    \n\n\n    \n    \n    def get_predictors(df, target_feature):\n        predictors = list(df.columns)\n        predictors.remove(target_feature)\n        return predictors\n    \n    \n    def get_X(df, predictors):\n        X = df[predictors]\n        return X\n    \n    \n    def get_y(df, target_feature):\n        y = df[[target_feature]]\n        return y\n    \n    \n    def regression_score(train_X, test_X, train_y, test_y):\n        model = LGBMRegressor(random_state=0).fit(train_X, train_y)\n        predict = model.predict(test_X)\n        return mean_absolute_error(predict, test_y)\n    \n    \n    def classification_accuracy(train_X, test_X, train_y, test_y):\n        model = LGBMClassifier(random_state=0).fit(train_X, train_y.values.ravel())\n        predict = model.predict(test_X)\n        return f1_score(predict, test_y.values.ravel(), average='macro')\n    \n    \n    def get_research(X, y, target_feature, test_size, research_iter):\n        RESULTS = pd.DataFrame()\n        print('\\n-----------------------------------')\n        if len(y.value_counts()) > CLASSIFIER_FOR_UNIQUE_VALUES_LESS_THAN:\n            print('Regression research by sklearn.model_selection.train_test_split:\\n')\n            for random_state in range(0,research_iter):\n                train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=test_size, random_state=random_state)\n                RESULTS.loc[random_state, 'score'] = regression_score(train_X, test_X, train_y, test_y)\n            print(f'Regression MAE with random_state from 0 to {research_iter - 1}:')\n        else:\n            print('Classification research by sklearn.model_selection.train_test_split:\\n')\n            print(f'Target function has {len(y.value_counts())} unique values.')\n            for random_state in range(0,research_iter):\n                train_X, test_X, train_y, test_y = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_state)\n                RESULTS.loc[random_state, 'score'] = classification_accuracy(train_X, test_X, train_y, test_y)\n            print(f'classification F1_SCORE(average=\"macro\") with random_state from 0 to {research_iter - 1}:')\n\n        print(f'max:  {RESULTS.score.max()}')\n        print(f'mean: {RESULTS.score.mean()}')\n        print(f'min:  {RESULTS.score.min()}\\n')\n        del RESULTS\n        return 0\n        \n    \n    def order_and_sort_table(df, important_functions):\n        df = df.sort_values(by=important_functions, ascending=True)\n        df = df.reset_index(drop=True)\n        if verbose:\n            print('\\n-----------------------------------')\n            print(f'The Table has been sorted by columns:\\n{important_functions}')\n        return df\n\n\n    \n    # split works correctly with test_size = 0.1, 0.2, 0.25, 0.33, 0.5 \n    def train_test_split_ordered(X, y, test_size=0.33):\n        train_indexes = []\n        test_indexes = []\n        indexes = list(X.index)\n\n        for el in indexes:\n            if el % int(1\/test_size):\n                train_indexes.append(el)\n            else:\n                test_indexes.append(el)\n\n        train_X = X.iloc[train_indexes]\n        test_X = X.iloc[test_indexes]\n        train_y = y.iloc[train_indexes]\n        test_y = y.iloc[test_indexes]\n        return train_X, test_X, train_y, test_y\n    \n    \n\n    \n    predictors = get_predictors(df, target_feature)\n    if research_iter:\n        get_research(get_X(df, predictors), get_y(df, target_feature), target_feature, test_size, research_iter)\n    \n    for el in df.columns:\n        count = len(df[el].value_counts())\n        df_count.loc[el, 'counts'] = count\n    df_count = df_count.sort_values(by='counts', ascending=True)\n    \n    if verbose:\n        print(df_count)\n    \n    ordered_predictors = list(df_count.index)\n    ordered_predictors.remove(target_feature)\n    ordered_columns = [target_feature] + ordered_predictors\n    df = df[ordered_columns]\n    \n    df_work = order_and_sort_table(df, ordered_columns)\n    predictors = get_predictors(df_work, target_feature)\n    \n    if research_iter:\n        get_research(get_X(df_work, predictors), get_y(df_work, target_feature), target_feature, test_size, research_iter)\n\n    train_X, test_X, train_y, test_y = \\\n    train_test_split_ordered(get_X(df_work, predictors), get_y(df_work, target_feature), test_size=test_size)\n\n    if research_iter:\n        print('\\n-----------------------------------')\n        if  len(train_y.value_counts()) > CLASSIFIER_FOR_UNIQUE_VALUES_LESS_THAN:\n            print(f'The final result MAE of the custom split:\\n{regression_score(train_X, test_X, train_y, test_y)}')\n        else:\n            print(f'The final result F1_SCORE(average=\"macro\") of the custom split:\\n{classification_accuracy(train_X, test_X, train_y, test_y)}')\n    if research_iter or verbose:\n        print('\\n-----------------------------------')\n        print('The split has been made.')\n    \n    return train_X, test_X, train_y, test_y","4ef00c29":"train_X, test_X, train_y, test_y = train_test_split_balanced(df, target, test_size=0.1, verbose=1, research_iter=10)","6f61a818":"df = df[list(train_X.columns) + [target]]\ndf","e95e73bb":"classifier = XGBClassifier(verbosity=0, random_state=42, n_jobs=-1)\n\nevaluate_model(train_X, train_y, test_X, test_y, classifier)","dece1585":"predictors = list(train_X.columns)\nX = df[predictors]\ny = df[target]","f5cc3c57":"params = {}\n\n\nLGB_clf = LGBMClassifier(**params)\nXGB_clf = XGBClassifier(verbosity=0, **params)\nCTB_clf = CatBoostClassifier(verbose=0, **params)\nSVM_clf = SVC(kernel='linear', **params)\nRDG_clf = RidgeClassifier(**params)\nNNC_clf = NearestCentroid(metric='mahalanobis', **params)\nSGD_clf = SGDClassifier(loss=\"hinge\", **params)\nGNB_clf = GaussianNB(**params)\nDTC_clf = DecisionTreeClassifier(**params)\nRFC_clf = RandomForestClassifier(**params)\nABC_clf = AdaBoostClassifier(**params)\nGBC_clf = GradientBoostingClassifier(random_state=0, **params)\nLRC_clf = LogisticRegression(solver='liblinear', **params)","bc578a52":"algorithms = [\n              LGB_clf, \n              XGB_clf, \n              CTB_clf, \n              RDG_clf, \n              NNC_clf,\n              SGD_clf, \n              GNB_clf, \n              DTC_clf, \n              RFC_clf, \n              SVM_clf, \n              ABC_clf, \n              GBC_clf, \n              LRC_clf, \n             ]\n\nCV = StratifiedShuffleSplit(n_splits=5, random_state=42)\nfor alg in algorithms:\n    scores = cross_val_score(alg, X, y, scoring=metric, cv=CV)\n    print(\"%s %0.2f (+\/- %0.2f) %s\" % (metric, scores.mean(), scores.std(), alg.__class__.__name__))","8ca9e5c5":"def predict(X__train, y__train, X__pred, all_algorithms):\n    stacked_predicts = pd.DataFrame()\n    stacked_column_names = []\n    for alg in all_algorithms:\n        alg_name = str(alg.__class__.__name__)[:3]\n        model = alg.fit(X__train, y__train)\n        y_hat = model.predict(X__pred)\n        stacked_predicts[alg_name] = y_hat\n        stacked_column_names.append(alg_name)\n    stacked_predicts['y_hat_final'] = stacked_predicts[stacked_column_names].mode(axis=1)[0].astype('int64')\n    y_hat = list(stacked_predicts.loc[:, 'y_hat_final'])\n    print(stacked_predicts[-30:])\n    del stacked_predicts\n    return y_hat","0e995f27":"algorithms = [\n              LGB_clf, \n#                       XGB_clf, \n              RDG_clf, \n              NNC_clf,\n              ABC_clf, \n              GBC_clf, \n#                       LRC_clf, \n             ]\n\n\npred = predict(train_X, train_y, test_X, algorithms)\n\nscore = METRIC(test_y, pred, average='macro')\nprint(f'\\n{metric}: {score}\\n')\nprint(f'last 30 y_test: {list(test_y[target][-30:])}')\nprint(f'last 30 y_pred: {pred[-30:]}\\n')\nprint(f'Classification Report:\\n')\nprint(classification_report(test_y, pred), '\\n')\n\n\ncm = confusion_matrix(test_y, pred)\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.0f')","7e8196ed":"optuna.logging.set_verbosity(optuna.logging.WARNING)\n\ndef evaluate(clf, X, y):\n    CV = StratifiedShuffleSplit(n_splits=5, random_state=42)\n    scores = cross_val_score(clf, X, y, scoring=metric, cv=CV)\n    score = scores.mean()\n    return score","5debf78b":"def objective(trial):\n    params = {\n        'metric': trial.suggest_categorical('metric', ['binary_error',\"binary_logloss\"]),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 105, step=25),\n        'learning_rate' :  trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n        'max_depth' : trial.suggest_int('max_depth', 4, 12, step=2),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n    }\n    \n    LGB_clf = LGBMClassifier(**params)\n    return evaluate(LGB_clf, X, y)\n    \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=3)\nparams = study.best_params\nprint(f'{metric}: {study.best_value}')\nprint(params)","68a712a0":"# # precision_macro: 0.8925418060200668\n# params = {'metric': 'binary_error', \n#          'num_leaves': 60, \n#          'min_child_samples': 5, \n#          'learning_rate': 0.24597341468158593, \n#          'max_depth': 12, \n#          'reg_lambda': 2.870832929582711, \n#          'reg_alpha': 9.838213737499016}\n\n# f1_macro: 0.7437231415036591\nparams = {'metric': 'binary_error', \n          'num_leaves': 245, \n          'min_child_samples': 80, \n          'learning_rate': 0.6334801148415141, \n          'max_depth': 4, \n          'reg_lambda': 3.7849884251302635e-05, \n          'reg_alpha': 0.0017074541107411703}\nLGB_clf = LGBMClassifier(**params)","17cdc439":"def objective(trial):\n    params = {\n        'lambda': trial.suggest_loguniform('lambda', 1e-5, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-5, 10.0),\n        'learning_rate' :  trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]),\n        'colsample_bynode': trial.suggest_categorical('colsample_bynode', [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]),\n        'subsample': trial.suggest_categorical('subsample', [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]),\n        'max_depth':  trial.suggest_int('max_depth', 4, 12, step=2),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n    }\n    XGB_clf = XGBClassifier(verbosity=0, **params)\n    return evaluate(XGB_clf, X, y)\n    \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=3)\nparams = study.best_params\nprint(f'{metric}: {study.best_value}')\nprint(params)","36a6524d":"# # precision_macro: 0.9411844077961021\n# params = {'lambda': 9.99678606682676, \n#           'alpha': 7.936488158358531, \n#           'learning_rate': 0.06465093743454552, \n#           'colsample_bytree': 0.2, \n#           'colsample_bylevel': 1, \n#           'colsample_bynode': 1, \n#           'subsample': 1, \n#           'max_depth': 8, \n#           'min_child_weight': 4}\n\n# f1_macro: 0.7264364974613166\nparams = {'lambda': 0.01133255160723048, \n          'alpha': 1.46890769343035, \n          'learning_rate': 0.8396809234665066, \n          'colsample_bytree': 0.3, \n          'colsample_bylevel': 0.2, \n          'colsample_bynode': 0.9, \n          'subsample': 0.9, \n          'max_depth': 10, \n          'min_child_weight': 4}\nXGB_clf = XGBClassifier(verbosity=0, **params)","b9172297":"def objective(trial):\n    params = {\n        'alpha' : trial.suggest_loguniform('alpha', 1e-5, 1e-3),\n        'tol' : trial.suggest_float('tol', 1e-5, 1),\n        'solver' : trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']),\n        'max_iter' : trial.suggest_int('max_iter', 100, 1000, step=100),    \n    }\n    \n    RDG_clf = RidgeClassifier(**params)\n    return evaluate(RDG_clf, X, y)\n    \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=3)\nparams = study.best_params\nprint(f'{metric}: {study.best_value}')\nprint(params)","e4672baa":"# # precision_macro: 0.84512336584705\n# params = {'alpha': 0.0003147647317690689, \n#           'tol': 0.4943652914691356, \n#           'solver': 'auto', \n#           'max_iter': 1000}\n\n# f1_macro: 0.6642166680569712\nparams = {'alpha': 1.756922286150556e-05, \n         'tol': 0.9371234830838449, \n         'solver': 'cholesky', \n         'max_iter': 1000}\nRDG_clf = RidgeClassifier(**params)","60dec81b":"metrics = ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', \n            'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', \n           'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', \n           'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', \n           'sokalsneath', 'sqeuclidean', 'yule', 'nan_euclidean']\n\nbest_result = []\nfor met in metrics:\n    NNC_clf = NearestCentroid(metric=met)\n    score = evaluate(NNC_clf, X, y)\n    best_result.append([[score],[met]])\n    \nparams = sorted(best_result)\nparams = params[-1][1][0]\nparams","582fd839":"# 0.6258985842456785 seuclidean\nNNC_clf = NearestCentroid(metric=params)","81326e12":"def objective(trial):\n    params = {\n        'learning_rate' :  trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n        'algorithm' : trial.suggest_categorical('algorithm', ['SAMME','SAMME.R']),\n        'n_estimators' : trial.suggest_int('n_estimators', 200, 1000, step=200),\n    }\n    \n    ABC_clf = AdaBoostClassifier(**params)\n    return evaluate(ABC_clf, X, y)\n    \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=3)\nparams = study.best_params\nprint(f'{metric}: {study.best_value}')\nprint(params)","ada2ff26":"# # precision_macro: 0.9062299619421058\n# params = {'learning_rate': 0.040581329808262255, \n#           'algorithm': 'SAMME', \n#           'n_estimators': 400}\n\n# f1_macro: 0.7024505235718082\nparams = {'learning_rate': 0.09024693732857182, \n          'algorithm': 'SAMME.R', \n          'n_estimators': 1000}\nABC_clf = AdaBoostClassifier(**params)","50db2473":"def objective(trial):\n    params = {\n        'loss' : trial.suggest_categorical('loss', ['deviance', 'exponential']),\n        'learning_rate' :  trial.suggest_loguniform('learning_rate', 1e-5, 1.0),\n        'subsample': trial.suggest_categorical('subsample', [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]),\n        'max_depth':  trial.suggest_int('max_depth', 4, 20, step=2),\n        'random_state' : trial.suggest_int('random_state', 0, 500, step=100)\n    }\n    \n    GBC_clf = GradientBoostingClassifier(**params)\n    return evaluate(GBC_clf, X, y)\n    \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=3)\nparams = study.best_params\nprint(f'{metric}: {study.best_value}')\nprint(params)","582ce68f":"# # precision_macro: 0.9054784146388345\n# params = {'loss': 'exponential', \n#           'learning_rate': 0.05269526014338683, \n#           'subsample': 0.3, \n#           'max_depth': 14, \n#           'random_state': 200}\n\n# f1_macro: 0.7110284120162633\nparams = {'loss': 'exponential', \n          'learning_rate': 0.18096022842968976, \n          'subsample': 0.5, \n          'max_depth': 4, \n          'random_state': 300}\nGBC_clf = GradientBoostingClassifier(**params)","53c37108":"def objective(trial):\n    params = {\n        'penalty' : trial.suggest_categorical('penalty', [ 'l2',  \n                                                           'l1',\n#                                                           'none', \n#                                                           'elasticnet', \n                                                         ]),\n        'solver' : trial.suggest_categorical('solver', [ 'liblinear',\n#                                                          'newton-cg', \n#                                                          'lbfgs', \n#                                                          'sag', \n#                                                          'saga'\n                                                        ]),\n        'l1_ratio' :  trial.suggest_loguniform('l1_ratio', 1e-5, 1.0),\n        'tol' :  trial.suggest_loguniform('tol', 1e-5, 1.0),\n        'C' :  trial.suggest_loguniform('C', 1e0, 1e2),\n    }\n    \n    LRC_clf = LogisticRegression(**params)\n    return evaluate(LRC_clf, X, y)\n    \nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=3)\nparams = study.best_params\nprint(f'{metric}: {study.best_value}')\nprint(params)","a2a9057c":"# # precision_macro: 0.8925555764985911\n# params ={'penalty': 'l1', \n#          'solver': 'liblinear', \n#          'l1_ratio': 0.0008776750899154615, \n#          'tol': 0.04780231961745664, \n#          'C': 71.41257156206963}\n\n# f1_macro: 0.7129877603540123\nparams = {'penalty': 'l1', \n          'solver': 'liblinear', \n          'l1_ratio': 0.0030092851573443866, \n          'tol': 0.005971277973744049, \n          'C': 4.8666194188435945}\n\nLRC_clf = LogisticRegression(**params)","800d66f7":"algorithms = [\n              LGB_clf, \n              XGB_clf, \n              RDG_clf, \n              NNC_clf,\n              ABC_clf, \n              GBC_clf, \n              LRC_clf, \n             ]\n\nCV = StratifiedShuffleSplit(n_splits=5, random_state=42)\n\nfor alg in algorithms:\n    scores = cross_val_score(alg, X, y, scoring=metric, cv=CV)\n    print(\"%s %0.2f (+\/- %0.2f) %s\" % (metric, scores.mean(), scores.std(), alg.__class__.__name__))","d2be6472":"algorithms = [\n              LGB_clf, \n#                       XGB_clf, \n              RDG_clf, \n              NNC_clf,\n              ABC_clf, \n#               GBC_clf, \n                      LRC_clf, \n             ]\n\n\n\n\npred = predict(train_X, train_y, test_X, algorithms)\n\nscore = METRIC(test_y, pred, average='macro')\nprint(f'\\n{metric}: {score}\\n')\nprint(f'last 30 y_test: {list(test_y[target][-30:])}')\nprint(f'last 30 y_pred: {pred[-30:]}\\n')\nprint(f'Classification Report:\\n')\nprint(classification_report(test_y, pred), '\\n')\n\n\ncm = confusion_matrix(test_y, pred)\nsns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='.0f')","775f8b24":"algorithms","ebf8ddcc":"for alg in algorithms:\n    alg.fit(X, y)","492835fa":"import pickle","de272b79":"names = []\nfor alg in algorithms:\n    filename = alg.__class__.__name__ + '.sav'\n    pickle.dump(alg, open(filename, 'wb'))\n    names.append(filename)\n    \nnames","291d7652":"for alg_name in names:\n    var_name = 'model_' + alg_name.split('.')[0]\n    vars()[var_name] = pickle.load(open(alg_name, 'rb'))\n    print(var_name)","3c878657":"model_LGBMClassifier","a7db745a":"model_RidgeClassifier","356b102b":"model_NearestCentroid","54de3daf":"model_AdaBoostClassifier","f75d574b":"model_LogisticRegression","b3297070":"train_X, test_X, train_y, test_y = train_test_split_balanced(df, target, test_size=0.5, verbose=0, research_iter=0)","4cbde6fd":"import shap\nfrom xgboost import XGBClassifier\n\n\nmodel = XGBClassifier(random_state=0, verbosity=0).fit(train_X, train_y)\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(test_X)\n\nplt.title(target)\nplt.gcf().subplots_adjust()\nshap.summary_plot(shap_values, test_X, max_display=train_X.shape[1], show=True, plot_size=(10, 12))\n\nplt.savefig(\"shap_\"+target+\"_.png\")\nplt.savefig(\"shap_\"+target+\"_.pdf\")\nplt.close()","d7d29503":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp\nfrom lightgbm import LGBMClassifier\n\n\nmodel = LGBMClassifier(random_state=0).fit(train_X, train_y)\n\nfor feature in list(train_X.columns):\n    print('\\n')\n    pdp_dist = pdp.pdp_isolate(model=model,\n                               dataset=test_X,\n                               model_features=test_X.columns, \n                               feature=feature)\n\n    pdp.pdp_plot(pdp_dist, feature)\n    plt.title(target)  \n    plt.savefig(\"pdp_\"+feature+\"_.png\", dpi=100)\n    plt.show()\n    plt.close()","7530cbc7":"# Load data","57f552e2":"# Some time later...\n# Load the model from disk","30669b4e":"# Import libraries","4fe6a05c":"\ud83d\udc4d\ud83d\udc4d\ud83d\udc4d","df20e022":"# Visualizing the Distributions ","d05c0301":"# Save models to disk","6dad7753":"# Hospital Moratality EDA & Modeling","6fb587ff":"# Looks better )","02f43392":"Target Variable - Outcome   \n0 - Alive   \n1 - Death   ","9b688205":"# LGBMClassifier","24cd3f73":"# Define evaluation function","75cdc9c2":"# RidgeClassifier","2ab767d0":"# AdaBoostClassifier","92cb4fd2":"# We have imbalanced target feature.","c2b5aaaa":"![\u0421\u043d\u0438\u043c\u043e\u043a \u044d\u043a\u0440\u0430\u043d\u0430 2021-11-25 \u0432 13.26.12.png](attachment:cdb6b820-6949-4a8f-9019-b1380361d225.png)","f4dd7f7c":"# Simple trash cleaner\n1) drop out duplicates   \n2) drop out columns with 1 unique value   \n3) drop rows with NaN in the target feature ","a793f5eb":"# evaluation of __custom train_test_split_balanced__","770b9af3":"# Try typical method with stratify=y by sklearn.model_selection.train_test_split()","69e04be3":"\ud83d\ude2d\ud83d\ude2d\ud83d\ude2d","44351f3c":"# Recover data","7ceaae96":"# Custom BALANCED train_test_split   \n# !!! FOR CLASSIFICATION ONLY !!!","a978de53":"# Algorithms were chosen\n","23827076":"# Thank you for your curiosity ;)","2425cb78":"# XGBClassifier","8d3502ce":"# Let's choose some classifiers from this stack","12dfa9a8":"# Define Classifiers","7374d7fa":"# Algorithm Selection","70e162bf":"# LogisticRegression","f34d66f9":"# NaN overview","51a88103":"# Now try hyperparameters tuning","31883108":"# GradientBoostingClassifier","20797a6f":"# EDA","12df9acd":"# Simple encoding","6385a970":"# NearestCentroid"}}