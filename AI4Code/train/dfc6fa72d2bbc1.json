{"cell_type":{"62a87590":"code","299227c0":"code","f3ec91b6":"code","1f85b97d":"code","25c2bf4d":"code","74194afa":"code","aa42258a":"code","383a957a":"code","cd8ad4cb":"code","ee8573a6":"code","15fa4914":"code","b1eb7cd2":"code","ed05ac9d":"code","d8fdd2d3":"code","03b710e9":"code","6b078f59":"code","11c1854e":"code","0cfc33ff":"code","d8a05d66":"code","df9025b1":"markdown","9f0380e3":"markdown","34c610b1":"markdown","6746fd5d":"markdown","4b21372a":"markdown","c104dc66":"markdown","9f5fb366":"markdown","3483b90f":"markdown","8c15ae43":"markdown","9e62096f":"markdown","f46afeeb":"markdown","bb86913e":"markdown","27cc5c5b":"markdown","1cfb33d2":"markdown"},"source":{"62a87590":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","299227c0":"df=pd.read_csv(\"\/kaggle\/input\/oil-spill\/oil-spill.csv\",header=None)","f3ec91b6":"df.head()","1f85b97d":"df.iloc[:,49].value_counts()\/len(df)","25c2bf4d":"df.iloc[:,0].value_counts()","74194afa":"df.isnull().sum().sum()","aa42258a":"from sklearn.model_selection import train_test_split\n\ntrain,val=train_test_split(df)\nX,y=train.drop(49,axis=1),train[49]\nX_train,X_test,y_train,y_test=train_test_split(df.drop(49,axis=1),df[49])","383a957a":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom imblearn.metrics import geometric_mean_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.dummy import DummyClassifier\n\nmodel = DummyClassifier(strategy='uniform')\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\nscores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n\nprint(scores.mean())","cd8ad4cb":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB","ee8573a6":"models = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis())) \nmodels.append(('NB', GaussianNB()))\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf1=pd.DataFrame(mean_scores,index=names,columns=['Baseline'])\ndf1","15fa4914":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis())) \nmodels.append(('NB', GaussianNB()))\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\nscaler=StandardScaler()\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    pipe=Pipeline([('scaler',scaler),('model',model)])\n    scores = cross_val_score(pipe, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf2=pd.DataFrame(mean_scores,index=names,columns=['StandardScaler'])\ndf3=df1.join(df2)\ndf3","b1eb7cd2":"from sklearn.preprocessing import StandardScaler\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import RandomOverSampler\n\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis())) \nmodels.append(('NB', GaussianNB()))\n\nscaler=StandardScaler()\nros=RandomOverSampler()\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    pipe=Pipeline([('scaler',scaler),('ros',ros),('model',model)])\n    scores = cross_val_score(pipe, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf4=pd.DataFrame(mean_scores,index=names,columns=['StandScaler+RandomOverSampler'])\ndf5=df3.join(df4)\ndf5","ed05ac9d":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear',class_weight='balanced')))\nmodels.append(('CART', DecisionTreeClassifier(class_weight='balanced'))) \nmodels.append(('SVM', SVC(gamma='scale',class_weight='balanced')))\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf6=pd.DataFrame(mean_scores,index=names,columns=['Balanced'])\ndf7=df5.join(df6,how='outer')\ndf7","d8fdd2d3":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear',class_weight='balanced')))\nmodels.append(('CART', DecisionTreeClassifier(class_weight='balanced'))) \nmodels.append(('SVM', SVC(gamma='scale',class_weight='balanced')))\n\nscaler=StandardScaler()\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    pipe=Pipeline([('scaler',scaler),('model',model)])\n    scores = cross_val_score(pipe, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf8=pd.DataFrame(mean_scores,index=names,columns=['Balanced+StandardScaler'])\ndf9=df7.join(df8,how='outer')\ndf9","03b710e9":"from sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import RandomOverSampler\n\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis())) \nmodels.append(('NB', GaussianNB()))\n\nscaler=StandardScaler()\nros=RandomOverSampler()\npt=PowerTransformer()\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    pipe=Pipeline([('scaler',scaler),('pt',pt),('ros',ros),('model',model)])\n    scores = cross_val_score(pipe, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf10=pd.DataFrame(mean_scores,index=names,columns=['StandScaler+RandomOverSampler+PowerTransformer'])\ndf11=df9.join(df10)\ndf11\n","6b078f59":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear',class_weight='balanced')))\nmodels.append(('CART', DecisionTreeClassifier(class_weight='balanced'))) \nmodels.append(('SVM', SVC(gamma='scale',class_weight='balanced')))\n\nscaler=StandardScaler()\npt=PowerTransformer()\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    pipe=Pipeline([('scaler',scaler),('pt',pt),('model',model)])\n    scores = cross_val_score(pipe, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf12=pd.DataFrame(mean_scores,index=names,columns=['Balanced+StandardScaler+PowerTransformer'])\ndf13=df11.join(df12,how='outer')\ndf13","11c1854e":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\ntest = SelectKBest(score_func=f_classif, k='all')\nfit = test.fit(X, y)\npd.DataFrame(fit.scores_,index=X.columns).sort_values(by=0).plot(kind='barh',figsize=(12,12))","0cfc33ff":"models = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis())) \nmodels.append(('NB', GaussianNB()))\n\nskb = SelectKBest(score_func=f_classif, k=10)\n\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    pipe=Pipeline([('skb',skb),('model',model)])\n    scores = cross_val_score(pipe, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf14=pd.DataFrame(mean_scores,index=names,columns=['Baseline+SKB'])\ndf15=df13.join(df14,how='outer')\ndf15","d8a05d66":"models = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis())) \nmodels.append(('NB', GaussianNB()))\n\nscaler=StandardScaler()\nros=RandomOverSampler()\npt=PowerTransformer()\nskb = SelectKBest(score_func=f_classif, k=6)\n\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nmetric = make_scorer(geometric_mean_score)\n\nnames=[]\nmean_scores=[]\nfor name,model in models:\n    pipe=Pipeline([('scaler',scaler),('pt',pt),('ros',ros),('skb',skb),('model',model)])\n    scores = cross_val_score(pipe, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    names.append(name)\n    mean_scores.append(scores.mean().round(3))\ndf16=pd.DataFrame(mean_scores,index=names,columns=['StandScaler+RandomOverSampler+PowerTransformer+SKB'])\ndf17=df15.join(df16,how='outer')\ndf17","df9025b1":"# Balanced Model Comparison with StandardScaler and PowerTransformer","9f0380e3":"# Introduction\n#### Dataset created using satelite images of the ocean to identify oil spills. \nhttps:\/\/machinelearningmastery.com\/imbalanced-classification-model-to-detect-oil-spills\/","34c610b1":"# Model Comparison Baseline","6746fd5d":"# Model Comparison with StandardScaler","4b21372a":"# Feature Selection","c104dc66":"# Model Comparison with StandardScaler and RandomOverSampler","9f5fb366":"# Balanced Model Comparison\n#### A new set of classifiers which take class_weight as a parameter","3483b90f":"# Model Comparison Baseline with Feature Selection","8c15ae43":"# Model Comparison with StandardScaler,RandomOverSampler, and PowerTransformer","9e62096f":"# Model Comparison with StandardScaler,RandomOverSampler,PowerTransformer, and SKB","f46afeeb":"#### This dataset is a candidate for imblanced classification techniques since more than 80% of the samples belong to the majority class. ","bb86913e":"# Dummy Classifier\n#### Geometric mean or G-mean combines Sensitivity and Specificity \n#### Since the uniform strategy generates predictions uniformly at random, we expect a G-mean close to 0.5 ","27cc5c5b":"# Balanced Model Comparison with StandardScaler","1cfb33d2":"# View Class Imbalance"}}