{"cell_type":{"5b71bc69":"code","ea30dcd4":"code","c3e07e61":"code","5e1073a7":"code","d4c1b637":"code","840677da":"code","2f89061b":"code","642b8c83":"code","cce8b952":"code","2ff0cc4d":"code","58c85d7e":"code","1df01375":"code","f0b51563":"code","7ecf80e2":"code","a471e098":"code","37f951b6":"code","297443c3":"code","9e997d0b":"code","212ac397":"code","a4c2c77c":"code","a0c5ab52":"code","28034867":"code","90b35be8":"code","afd5a654":"code","ef90b809":"code","db0d24da":"code","bad552fc":"code","d27f8694":"code","04afea62":"code","0711f3eb":"code","416a31e9":"code","1f0efb32":"code","d74ebc21":"code","fa2dde5f":"code","4f8182a9":"code","a4822c84":"code","d47632ea":"code","7778b26f":"code","46e4628e":"code","d891cb74":"code","f99940f8":"code","26fad8e8":"code","3ccd3151":"code","34ade78a":"code","c735af62":"code","44618086":"code","d4b757c4":"code","7a7aa836":"code","ab0b80b5":"code","038ce40d":"code","18cfe0b2":"code","0003cd48":"code","84e47c87":"code","bb757e89":"code","8fe2daef":"code","ad761393":"code","3aa65654":"code","f467474f":"code","274ab56b":"code","ca4bedb9":"code","89f4bcc5":"code","48191f7e":"code","6bb87318":"code","d68f8470":"code","1a218199":"markdown"},"source":{"5b71bc69":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ea30dcd4":"items = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nitem_categories = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ntrain = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","c3e07e61":"train.head()","5e1073a7":"shops.head()","d4c1b637":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x= train.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price)","840677da":"train = train[train.item_price<100000]\ntrain = train[train.item_cnt_day < 1001]","2f89061b":"train.item_price.median()","642b8c83":"train[train.item_price < 0]","cce8b952":"median_value = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)&(train.item_cnt_day==1)].item_price.median()\nmedian_value","2ff0cc4d":"train.loc[train.item_price<0, 'item_price'] = median_value","58c85d7e":"train[train.shop_id==0].head()","1df01375":"shops.head()","f0b51563":"items.head()","7ecf80e2":"train.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","a471e098":"item_categories.head()","37f951b6":"shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops.loc[shops.city == '!\u042f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u042f\u043a\u0443\u0442\u0441\u043a'\nshops\n\n","297443c3":"item_categories['split'] = item_categories['item_category_name'].str.split('-')\nitem_categories['type'] = item_categories['item_category_name'].str.split('-').map(lambda x: x[0])\nitem_categories['sub_type'] = item_categories['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n\nitem_categories.head()","9e997d0b":"test.head()","212ac397":"matrix = []\nfrom itertools import product\ncols = ['date_block_num', 'shop_id', 'item_id']\nfor i in range(34):\n    sales = train[train.date_block_num == i]\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype = 'int16'))\n    \nmatrix = pd.DataFrame(np.vstack(matrix), columns = cols)\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\nmatrix.head()","a4c2c77c":"train.head()","a0c5ab52":"train['revenue'] = train['item_price'] * train['item_cnt_day']\n\ngroup = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']","28034867":"group.head()","90b35be8":"group.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (matrix['item_cnt_month'].fillna(0).clip(0,20).astype(np.float16))","afd5a654":"matrix.head()","ef90b809":"test.head()","db0d24da":"test['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)","bad552fc":"matrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna(0, inplace=True)","d27f8694":"matrix.drop(columns = ['ID'], inplace = True)\nmatrix.head()","04afea62":"shops.head()","0711f3eb":"from sklearn.preprocessing import LabelEncoder\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id','city_code']]","416a31e9":"item_categories['type_code'] = LabelEncoder().fit_transform(item_categories['type'])\nitem_categories['sub_type_code'] = LabelEncoder().fit_transform(item_categories['sub_type'])\nitem_categories = item_categories[['item_category_id', 'type_code', 'sub_type_code']]\nitem_categories.head()","1f0efb32":"items.drop(columns = ['item_name'], inplace = True)\nitems.head()","d74ebc21":"matrix = pd.merge(matrix, shops, on = ['shop_id'], how = 'left')\nmatrix = pd.merge(matrix, items, on = ['item_id'], how = 'left')\nmatrix = pd.merge(matrix, item_categories, on = ['item_category_id'], how = 'left')\nmatrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['type_code'] = matrix['type_code'].astype(np.int8)\nmatrix['sub_type_code'] = matrix['sub_type_code'].astype(np.int8)\nmatrix.head()","fa2dde5f":"def lag_features(df, lags, col):\n    tmp = df[['date_block_num', 'shop_id', 'item_id', col]]\n    \n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num', 'shop_id', 'item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += 1\n        \n        df = pd.merge(df, shifted, on = ['date_block_num','shop_id','item_id'], how='left')\n    return df","4f8182a9":"matrix = lag_features(matrix, [1,2,3,6,12], 'item_cnt_month')\nmatrix.head()","a4822c84":"group = matrix.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_avg_item_cnt' ]\ngroup.reset_index(inplace=True)","d47632ea":"matrix.head()","7778b26f":"matrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\nmatrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\nmatrix = lag_features(matrix, [1], 'date_avg_item_cnt')\nmatrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)","46e4628e":"group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month':['mean']})\ngroup.columns = ['date_item_avg_item_cnt']\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = ['date_block_num', 'item_id'], how = 'left')\nmatrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\nmatrix = lag_features(matrix, [1], 'date_item_avg_item_cnt')\nmatrix.drop(['date_item_avg_item_cnt'], axis = 1, inplace = True)","d891cb74":"group = train.groupby(['item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['item_avg_item_price']\ngroup.reset_index(inplace = True)","f99940f8":"matrix = pd.merge(matrix, group, on = ['item_id'], how = 'left')\nmatrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)","26fad8e8":"group = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['date_item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)","3ccd3151":"lags = [1,2,3,4,5,6]\nmatrix = lag_features(matrix, lags, 'date_item_avg_item_price')","34ade78a":"for i in lags:\n    matrix['delta_price_lag_'+str(i)] = (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price'])\/matrix['item_avg_item_price']","c735af62":"def select_trend(row):\n    for i in lags:\n        if row['delta_price_lag_'+str(i)]:\n            return row['delta_price_lag_'+str(i)]\n    return 0\n\nmatrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\nmatrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\nmatrix['delta_price_lag'].fillna(0, inplace=True)\n\nfetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\nfor i in lags:\n    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n    fetures_to_drop += ['delta_price_lag_'+str(i)]\n\nmatrix.drop(fetures_to_drop, axis=1, inplace=True)","44618086":"matrix.head()","d4b757c4":"matrix = matrix[matrix.date_block_num > 11]","7a7aa836":"matrix.reset_index(inplace = True)","ab0b80b5":"matrix.drop(['index'], axis = 1, inplace = True)\nmatrix.head()","038ce40d":"matrix.isnull().sum()","18cfe0b2":"X_train = matrix[matrix.date_block_num < 33].drop(['item_cnt_month'], axis = 1)\nY_train = matrix[matrix.date_block_num < 33]['item_cnt_month']\nX_Valid = matrix[matrix.date_block_num ==33].drop(['item_cnt_month'], axis = 1)\nY_Valid = matrix[matrix.date_block_num ==33]['item_cnt_month']\nX_test = matrix[matrix.date_block_num == 34].drop(['item_cnt_month'], axis = 1)","0003cd48":"X_train.isnull().sum()","84e47c87":"X_Valid.isnull().sum()","bb757e89":"X_test.isnull().sum()","8fe2daef":"X_train.fillna(0, inplace = True)\nX_Valid.fillna(0, inplace = True)\nX_test.fillna(0, inplace = True)\n","ad761393":"from xgboost import XGBRegressor\nmodel = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_Valid, Y_Valid)], \n    verbose=True, \n    early_stopping_rounds = 10)","3aa65654":"Y_pred = model.predict(X_Valid).clip(0, 20)\nY_test = model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)","f467474f":"X_train.head()","274ab56b":"X_train.shape","ca4bedb9":"from numpy import array\ndef split_sequence(sequence, n_steps):\n\tX, y = list(), list()\n\tfor i in range(len(sequence)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_steps\n\t\t# check if we are beyond the sequence\n\t\tif end_ix > len(sequence)-1:\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn array(X), array(y)","89f4bcc5":"raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\nn_steps = 3\n# split into samples\nX, y = split_sequence(raw_seq, n_steps)\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))","48191f7e":"X_train_numpy = np.array(X_train)","6bb87318":"X_train_numpy = X_train_numpy.reshape((X_train_numpy.shape[0], X_train_numpy.shape[1], n_features))","d68f8470":"Y_train_numpy = np.array(Y_train)","1a218199":"Trend Features"}}