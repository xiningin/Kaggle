{"cell_type":{"49ca1a7f":"code","dc686ff1":"code","0659f85a":"code","cad13f4a":"code","cb7df1bc":"code","c18d47bc":"code","eefedef5":"code","d70f4f20":"code","1987b351":"code","f170a736":"code","9d8aad0c":"code","ff5b18c1":"code","72a9554b":"code","07462046":"code","d8282ec5":"code","c074357e":"code","4c2e61d7":"code","a9f6ce81":"code","550c9f56":"code","3c643b77":"code","fb3a3103":"code","82cd522d":"code","306b7c4a":"code","ad171ada":"code","3e82e6c0":"code","94fc12db":"code","6d081432":"code","3bc7f429":"code","e4491c7b":"code","62c2747d":"code","4f4a4deb":"code","cda079aa":"code","26a2a439":"code","8c909602":"code","6cda608e":"code","6c9a9f50":"code","38be2d7a":"code","b529c9d0":"code","090eb495":"code","a5b3b30d":"code","45642d58":"code","b64efdc9":"code","1b21f350":"code","a0e2a194":"code","20fb2e69":"code","73e8f413":"code","a737ca07":"code","7933f5b0":"code","fdc96225":"code","81547209":"code","64155595":"code","4f3eff4f":"code","8951202c":"code","8c436c32":"code","c9fb60a7":"code","3d8ba692":"code","cb4fa309":"code","2eef1af8":"code","b067b5f3":"code","95be62c9":"code","22348d5d":"markdown","610c61be":"markdown","8807f190":"markdown","b88add60":"markdown","201d5c38":"markdown","2bcd459a":"markdown"},"source":{"49ca1a7f":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport scipy\nimport numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport plotly.express as px\nimport plotly.graph_objects as go\nsns.color_palette('bright')\nsns.set(style='darkgrid',rc = {'figure.figsize':(15,8)})\nfrom plotly.offline import iplot\nfrom sklearn.pipeline import make_pipeline \n%matplotlib inline\nprint(\"Ready,set,go....\")","dc686ff1":"#reading data sets\ndf = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/train.csv')\nprint(df.shape)","0659f85a":"#checking head\ndf.head()","cad13f4a":"#checking info\ndf.info()","cb7df1bc":"#reading data sets\ndftest = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/test.csv')\nprint(dftest.shape)","c18d47bc":"#checking head\ndftest.head()","eefedef5":"#checking info\ndftest.info()","d70f4f20":"df.cat0.dtypes","1987b351":"catgeroical = df.columns[df.dtypes=='object']\nnumber = df.columns[df.dtypes!='object']","f170a736":"number = number.delete(0)\nnumber = number.delete(-1)\nnumber","9d8aad0c":"catgeroical","ff5b18c1":"#!pip install klib","72a9554b":"#import klib","07462046":"#klib.cat_plot(df)","d8282ec5":"#plt.style.use('ggplot')\n#plt.figure(figsize=(16,10))\n#for i in range(10):\n   # ax = plt.subplot(4,3,i+1)\n    #plt.hist(data= df,x=catgeroical[i])\n    #plt.grid('off')\n    #plt.title(\"{}\".format(catgeroical[i]))","c074357e":"#klib.dist_plot(df)","4c2e61d7":"#klib.corr_mat(df)","a9f6ce81":"#klib.corr_plot(df)","550c9f56":"#plt.figure(figsize=(8,8))\n#sns.distplot(df['target'])","3c643b77":"#df.columns","fb3a3103":"X = df.drop(['id','target'],axis=1)\nxtest = dftest.drop('id',axis = 1)","82cd522d":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler,OrdinalEncoder,MinMaxScaler\n\nc_transformer = ColumnTransformer([\n            ('min_max',MinMaxScaler(),number),\n            ('Ord_enc',OrdinalEncoder(),catgeroical)]\n,remainder='passthrough')\n\nx_mi = c_transformer.fit_transform(X)\nxtest_mi = c_transformer.transform(xtest)","306b7c4a":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler,OrdinalEncoder,MinMaxScaler\n\nc_transformer = ColumnTransformer([\n            ('standard',StandardScaler(),number),\n            ('Ord_enc',OrdinalEncoder(),catgeroical)]\n,remainder='passthrough')\n\nx_sc = c_transformer.fit_transform(X)\nxtest_sc = c_transformer.transform(xtest)","ad171ada":"x_mi[0]","3e82e6c0":"x_sc[0]","94fc12db":"y=df['target'].values","6d081432":"y","3bc7f429":"from xgboost import XGBRegressor\nfrom sklearn import metrics,model_selection\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom optuna.visualization import plot_optimization_history,plot_param_importances\nimport optuna\nfrom sklearn.model_selection import KFold","e4491c7b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x_sc, y, test_size = 1\/3, random_state = 69)","62c2747d":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler,OrdinalEncoder,MinMaxScaler\n\nc_transformer = ColumnTransformer([\n            ('standard',StandardScaler(),number),\n            ('Ord_enc',OrdinalEncoder(),catgeroical)]\n,remainder='passthrough')\n\n\ndef objective(trial):\n    li = []\n    \n    paramas = {\n        'n_estimators':trial.suggest_int('n_estimators',100,20000,step=200),\n        'max_depth':trial.suggest_int('max_depth',1,5),\n        'eta': trial.suggest_float('eta',1e-3,1e-2,log = True),\n        'gamma':trial.suggest_float('gamma',0.0,1.0,step=0.1),\n        'min_child_weight': trial.suggest_int('min_child_weight',1,1000),\n        'colsample_bytree':trial.suggest_float('colsample_bytree',0.4,1.0,step=0.1),\n        'subsample':trial.suggest_float('subsample',0.2,0.8,step=0.1),\n        'lambda':trial.suggest_float('lambda',1.0,100.0),\n        'alpha':trial.suggest_float('alpha',1.0,100.0),\n        'random_state':69\n    }\n    kfold = model_selection.KFold(n_splits=5,shuffle=True,random_state=69)\n    \n    for i,j in kfold.split(x_sc,y) :\n        X_train,X_test = X[i],X[j]\n        y_train,y_test = y[i],y[j]\n        \n        x_sc = c_transformer.fit_transform(X_train)\n        xtest_sc = c_transformer.transform(X_test)\n        xb = XGBRegressor(n_jobs=-1,tree_method ='gpu_hist',gpu_id =0,predictor = 'gpu_predictor',\n                      **paramas)\n        xb.fit(x_sc,y_train,verbose= 0,early_stopping_rounds=50,eval_set=[(x_sc[j],y[j])],eval_metrics='RMSE')\n        pred = xb.predict(xtest_sc)\n        li = np.mean(metrics.mean_squared_error(y_test,pred,squared = False))\n       \n    \n    return (li) \n    \n    ","4f4a4deb":"study = optuna.create_study()\nstudy.optimize(objective, n_trials=10)","cda079aa":"xgb_params = {\n    'n_estimators': 5000,\n    'learning_rate': 0.1235,\n    'subsample': 0.95,\n    'colsample_bytree': 0.11,\n    'max_depth': 2,\n    'booster': 'gbtree', \n    'reg_lambda': 66.1,\n    'reg_alpha': 15.9,\n    'random_state':42,\n    'tree_method': 'gpu_hist',\n    'gpu_id': 0,\n    'predictor': 'gpu_predictor'\n}","26a2a439":"train_pred1 = np.zeros(x_sc.shape[0])\ntrain_pred2 = np.zeros(x_sc.shape[0])\ntrain_pred3 = np.zeros(x_sc.shape[0])","8c909602":"from sklearn.model_selection import KFold\n\nbest_params = xgb_params\nfinal_predictions = []\nkfold = KFold(n_splits=5, shuffle=True, random_state=69)\n\nfor i, j in kfold.split(x_sc, y):\n    xgb_final = XGBRegressor(**best_params,n_jobs=-1)\n    \n    xgb_final.fit(x_sc[i], y[i], early_stopping_rounds=300, eval_set=[(x_mi[j], y[j])],verbose=0)\n    \n    final_predictions.append(xgb_final.predict(xtest_sc))\n    \n    train_pred1[j] = xgb_final.predict(x_sc[j])\n\nxgb_preds = np.mean(np.column_stack(final_predictions), axis=1)","6cda608e":"sample = pd.read_csv('..\/input\/30-days-of-ml\/sample_submission.csv')\nsample['target'] = xgb_preds\nsample.to_csv('submission_1.csv',index = False)","6c9a9f50":"def cat_objective(trial):\n    \n    paramas={\n        'iterations':trial.suggest_int('iterations',100,40000,step=150),\n        'max_depth':trial.suggest_int('max_depth',4,10),\n        'eta': trial.suggest_discrete_uniform('eta',1e-3,1e-2,0.001),\n        'l2_leaf_reg':trial.suggest_discrete_uniform('l2_leaf_reg',1.0,20.0,0.50),\n        'grow_policy' : 'Depthwise',\n        'eval_metric' : 'RMSE',\n        'od_type' : 'Iter',\n        'logging_level' :'Silent',\n        'task_type':'GPU'\n        }\n    cb = CatBoostRegressor(early_stopping_rounds=500,\n                          **paramas)\n    cb.fit(X_train,y_train)\n    pred = cb.predict(X_test)\n    li = (metrics.mean_squared_error(y_test,pred,squared = False))\n    \n\n    return (li)\n    \n    ","38be2d7a":"study2 = optuna.create_study()\nstudy2.optimize(cat_objective, n_trials=50)","b529c9d0":"print(study2.best_params)","090eb495":"cat_params = study2.best_params","a5b3b30d":"plot_optimization_history(study2)","45642d58":"plot_param_importances(study2)","b64efdc9":"from sklearn.model_selection import KFold\n\nbest_params = cat_params\nfinal_predictions = []\nkfold = KFold(n_splits=5, shuffle=True, random_state=69)\n\nfor i, j in kfold.split(x_sc, y):\n    cb_final = CatBoostRegressor(**best_params,verbose=0)\n    \n    cb_final.fit(x_sc[i], y[i])\n    \n    final_predictions.append(cb_final.predict(xtest_sc))\n    \n    train_pred2[j] = cb_final.predict(x_sc[j])\n\ncat_preds = np.mean(np.column_stack(final_predictions), axis=1)","1b21f350":"sample = pd.read_csv('..\/input\/30-days-of-ml\/sample_submission.csv')\nsample['target'] = cat_preds\nsample.to_csv('submission_2.csv',index = False)","a0e2a194":"def lbm_objective(trial):\n    \n    \n    paramas = {\n        'n_estimators':trial.suggest_int('n_estimators',100,50000,step=200),\n        'boosting_type':trial.suggest_categorical('boosting_type',['dart','goss','rf']),\n        'reg_lambda':trial.suggest_float('reg_lambda',0.0001,100.0),\n        'reg_alpha':trial.suggest_float('reg_alpha',0.0001,100.0),\n        'colsample_bytree':trial.suggest_float('colsample_bytree',0.2,1.0,step=0.1),\n        'max_depth':trial.suggest_int('max_depth',-5,0),\n        'learning_rate': trial.suggest_float('learning_rate',1e-5,1e-2,log = True),\n        'num_leaves':trial.suggest_int('num_leaves',31,1000),\n        'n_jobs':-1,\n        'silent':True        }\n    lb = LGBMRegressor(**paramas,device_type = 'gpu',metric = 'rmse',\n                       gpu_platform_id= 0,\n                       gpu_device_id= 1)\n    lb.fit(X_train,y_train,verbose=False)\n    pred = lb.predict(X_test)\n    li = metrics.mean_squared_error(y_test,pred,squared = False)\n    \n\n    return (li)\n    \n    ","20fb2e69":"study3 = optuna.create_study()\nstudy3.optimize(lbm_objective, n_trials=100)","73e8f413":"print(study3.best_params)","a737ca07":"lb_params = study3.best_params","7933f5b0":"plot_param_importances(study3)","fdc96225":"plot_optimization_history(study3)","81547209":"from sklearn.model_selection import KFold\nbest_params = lb_params\nfinal_predictions = []\n\nkfold = KFold(n_splits=5, shuffle=True, random_state=69)\n\nfor i, j in kfold.split(x_sc, y):\n    lb_final = LGBMRegressor(**best_params,device_type = 'gpu',metric = 'rmse',\n                       gpu_platform_id= 0,\n                       gpu_device_id= 0)\n    \n    lb_final.fit(x_sc[i], y[i])\n    \n    final_predictions.append(lb_final.predict(xtest_sc))\n    \n    train_pred3[j] = lb_final.predict(x_sc[j])\n\nlb_preds = np.mean(np.column_stack(final_predictions), axis=1)","64155595":"sample = pd.read_csv('..\/input\/30-days-of-ml\/sample_submission.csv')\nsample['target'] = lb_preds\nsample.to_csv('submission_3.csv',index = False)","4f3eff4f":"final_preds = (xgb_preds + cat_preds +lb_preds)\/3","8951202c":"sample = pd.read_csv('..\/input\/30-days-of-ml\/sample_submission.csv')\nsample['target'] = final_preds\nsample.to_csv('submission_4.csv',index = False)","8c436c32":"train_stack = np.column_stack(train_pred1,train_pred2,train_pred3)\ntest_stack = np.column_stack(xgb_preds,cat_preds,lb_preds)","c9fb60a7":"train =  pd.DataFrame(data = {\n            'xgb':train_pred1.tolist(),\n            'cat':train_pred2.tolist(),\n            'lgb':train_pred3.tolist(),\n            'target':df.target})\n\ntest = pd.DataFrame(data = {\n        'xgb':xgb_preds.tolist(),\n        'cat':cat_preds.tolist(),\n        'lgb':lb_preds.tolist()\n})","3d8ba692":"train.head()","cb4fa309":"test.head()","2eef1af8":"from sklearn.linear_model import Lasso","b067b5f3":"from sklearn.model_selection import KFold\n\nfinal_predictions = []\n\nrmse = []\n\nkfold = KFold(n_splits=5, shuffle=True, random_state=69)\n\nfor i, j in kfold.split(train_stack, df['target']):\n    \n    las = Lasso(alpha = 0.00001)\n    \n    las.fit(train_stack[i], df['target'].iloc[i])\n    \n    final_predictions.append(las.predict(test_stack))\n    \n    rmse.append(metrics.mean_squared_error(df['target'].iloc[j],las.predict(test_stack),squared=False))\n    \n\npreds = np.mean(np.column_stack(final_predictions), axis=1)\nprint(\"Rmse: {}\".format(np.mean(rmse)))","95be62c9":"sample = pd.read_csv('..\/input\/30-days-of-ml\/sample_submission.csv')\nsample['target'] = preds\nsample.to_csv('submission_5.csv',index = False)","22348d5d":"<h1> Preparing Data for models <\/h1>","610c61be":"<h1> Stacking <\/h1>","8807f190":"<h1> Models <\/h1>","b88add60":"<h1> Data <\/h1>","201d5c38":"<h1> EDA <\/h1>","2bcd459a":"<h1> simple ensemble <\/h1>"}}