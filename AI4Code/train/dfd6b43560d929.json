{"cell_type":{"ee0c2cde":"code","6585a7c3":"code","a06388de":"code","dd403fd9":"code","b4b6ff1b":"code","57324c9e":"code","7895d508":"code","5137fba8":"code","e7c4a263":"code","9cadee9b":"code","827e5406":"code","cb27947e":"code","a1a35090":"code","f97aef5b":"code","9aefb053":"code","d1414d78":"code","4c8e785a":"code","ae4132a7":"code","2f7474dd":"code","a32a75ef":"code","56211fdf":"code","9473e4e9":"code","0a085eab":"code","d80fa56d":"code","9ff29b29":"code","107653f1":"code","d95c86f3":"code","ebe661fa":"code","b10024e9":"code","1910f8d8":"code","b783f2fe":"code","4eb62e8d":"code","0c56b441":"code","07f7e335":"code","adac07d6":"code","572eeec3":"code","69ab1b65":"code","16bce0b8":"code","ee32bbdb":"code","0d75b5b0":"code","7a340780":"code","ec0f99f1":"code","eb06f88f":"code","2977baa7":"code","8e1ed5d0":"code","694eb032":"code","3580aed7":"markdown","f6d506ab":"markdown","4c761c5b":"markdown","323c6fd1":"markdown","1422e0c6":"markdown","8ff90aeb":"markdown","c95c74f7":"markdown","a31d80fb":"markdown","ad56f326":"markdown","2f662d89":"markdown","bdee69cf":"markdown","7a1c418e":"markdown","2433f5cc":"markdown","42d416d3":"markdown","dd4b7f65":"markdown","3d7eb995":"markdown","a489cb10":"markdown","82e3a011":"markdown","cc57763d":"markdown","312ff6f0":"markdown","928f00ea":"markdown","ccc8e993":"markdown","52acba2d":"markdown","8620750e":"markdown","1df5434b":"markdown","9e3feb86":"markdown","f06c6a0f":"markdown","844236d9":"markdown","8d80b105":"markdown","10a23435":"markdown","422734a2":"markdown","db37e93e":"markdown","898a4e54":"markdown","ac040829":"markdown","eed98f5a":"markdown","032bd9e0":"markdown","bbc7ecc3":"markdown","655081ba":"markdown","bd09e553":"markdown","5fe1a95c":"markdown","90a8c97c":"markdown","cf0b7d38":"markdown","3a1f1589":"markdown"},"source":{"ee0c2cde":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","6585a7c3":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","a06388de":"train.head(10)","dd403fd9":"train.info()","b4b6ff1b":"train[\"Cabin\"].value_counts()","57324c9e":"train.drop(\"PassengerId\",axis=1,inplace=True)","7895d508":"train.describe()","5137fba8":"x = train[\"Age\"]\nsns.distplot(x)","e7c4a263":"print(train[\"Age\"].median())\nprint(train[\"Age\"].mean())\nprint(train[\"Age\"].mode()[0])","9cadee9b":"median = train[\"Age\"].median()\ntrain[\"Age\"].fillna(median,inplace = True)","827e5406":"sns.countplot(train[\"Embarked\"])","cb27947e":"train[\"Embarked\"].fillna(\"S\",inplace = True)","a1a35090":"train.info()","f97aef5b":"#correlation map\nf,ax=plt.subplots(figsize=(25, 25))\nsns.heatmap(train.corr(), annot=True, linewidths=.4, fmt= '.1f',ax=ax)\nplt.show()","9aefb053":"corr_matrix = train.corr()\ncorr_matrix[\"Survived\"].sort_values(ascending = False)","d1414d78":"train.loc[:,[\"Name\",\"Ticket\"]]","4c8e785a":"train[\"Honorific\"] = train[\"Name\"].str.split(\",\",expand = True).iloc[:,1].str.split(\".\",expand = True).iloc[:,0].str.strip()\ntrain[\"Honorific\"].value_counts()","ae4132a7":"train = train.assign(Mr = (train[\"Honorific\"] == \"Mr\").astype(int))\ntrain = train.assign(Miss = (train[\"Honorific\"] == \"Miss\").astype(int))\ntrain = train.assign(Mrs = (train[\"Honorific\"] == \"Mrs\").astype(int))\ntrain = train.assign(Master = (train[\"Honorific\"] == \"Master\").astype(int))","2f7474dd":"train.drop(\"Honorific\",axis=1,inplace=True)","a32a75ef":"train[\"Name\"] = train[\"Name\"].str.split(\",\",expand = True)[0]\n\nfamily = train.loc[:,[\"Name\",\"Ticket\"]]\nfamily[\"new\"] = family[\"Name\"] + family[\"Ticket\"]\n\ntrain[\"new\"] = train[\"Name\"] + train[\"Ticket\"]\nfamily_unique = family[\"new\"].unique().tolist()\nfamily_id = [i for i in range(1,len(family_unique)+1)]\n\nmerge_df = pd.DataFrame(data={\"new\":family_unique,\"FamilyID\":family_id})\n    \ntrain = train.join(merge_df.set_index(\"new\"), on='new')\ntrain.drop(\"new\",axis=1,inplace=True)\ntrain[\"FamilyID\"].fillna(0,inplace = True)\n\n\ntrain.drop([\"Name\",\"Ticket\"],axis=1,inplace=True)","56211fdf":"import plotly.express as px\nfig = px.histogram(train, x=\"Sex\", color='Survived', barmode='group',\n             height=400)\nfig.show()","9473e4e9":"train = train.assign(Female = (lambda x: ((x[\"Sex\"] == \"female\")).astype(int)))\ntrain = train.assign(Male = (lambda x: ((x[\"Sex\"] == \"male\")).astype(int)))\ntrain.drop(\"Sex\",axis=1,inplace=True)","0a085eab":"import plotly.express as px\n\ndf_for_bar = train.loc[:,[\"Pclass\",\"Survived\"]]\ndf_for_bar[\"Survived\"].replace({0:\"No\",1:\"Yes\"},inplace = True)\n\nfig = px.histogram(df_for_bar, x=\"Pclass\", color='Survived')\n\nfig.update_layout(\n    xaxis_title_text='Pclass', \n    yaxis_title_text='Count', \n    bargap = 0.2)\nfig.show()","d80fa56d":"number_rows = train.count()[0]\n\nrates = train[train[\"Survived\"]==1].groupby([\"Pclass\"]).count().iloc[:,0]\n\nprint(rates \/ number_rows)","9ff29b29":"from sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder()\n\nresults = ohe.fit_transform(train[\"Pclass\"].values.reshape(-1,1),).toarray()\n\ntrain[\"PClass_1\"] = 0\ntrain[\"PClass_2\"] = 0\ntrain[\"PClass_3\"] = 0\n\ntrain.iloc[:,[10,11,12]] = results\ntrain.iloc[:,[10,11,12]] = train.iloc[:,[10,11,12]].astype(int)","107653f1":"df_for_pie = train[train[\"Survived\"]==1].groupby([\"Embarked\"]).count()\nfig = px.pie(df_for_pie, values='Survived', names=df_for_pie.index, title='Embarked Distribution Among Survived People')\nfig.show()","d95c86f3":"embarked_three = pd.get_dummies(train[\"Embarked\"])\ntrain = pd.concat([train,embarked_three],axis=1)\n\ntrain.drop(\"Embarked\",axis=1,inplace=True)","ebe661fa":"train[\"NoChild\"] = train[\"Parch\"].loc[train[\"Parch\"]==0]\ntrain[\"NoChild\"] = train[\"NoChild\"].fillna(1).astype(int)\n\ntrain[\"NoSibSp\"] = train[\"SibSp\"].loc[train[\"SibSp\"]==0]\ntrain[\"NoSibSp\"] = train[\"NoSibSp\"].fillna(1).astype(int)","b10024e9":"train[\"FamilySize\"] = train[\"Parch\"] + train[\"SibSp\"]","1910f8d8":"train.head()","b783f2fe":"fig = px.box(train[train[\"Fare\"] != 512.3292], x=\"Pclass\", y=\"Fare\")\nfig.show()","4eb62e8d":"train[\"Pclass\"].replace({1:3,3:1},inplace = True)  \ntrain[\"Fare\"] = train[\"Fare\"] * train[\"Pclass\"]\ntrain[\"Age\"] = train[\"Age\"] * train[\"Pclass\"] \ntrain[\"Pclass\"].replace({1:3,3:1},inplace = True)  ","0c56b441":"fig = px.box(train[train[\"Fare\"] < 700], x=\"Pclass\", y=\"Fare\")\nfig.show()","07f7e335":"train.drop(train.loc[:,[\"Pclass\",\"Parch\",\"SibSp\",\"Cabin\"]],axis=1,inplace=True)","adac07d6":"y = train[\"Survived\"].copy()\ntrain.drop(\"Survived\",axis=1,inplace=True)","572eeec3":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1,test_size=0.13,random_state=42)\nfor train_index,cv_index in split.split(train,y):\n    X_train, X_cv = train.loc[train_index], train.loc[cv_index]\n    y_train, y_cv = y.loc[train_index], y.loc[cv_index]","69ab1b65":"from sklearn.metrics import accuracy_score\ndef predict_model(model,X_train,y_train,X_cv,y_cv):\n    model.fit(X_train,y_train)\n    return accuracy_score(y_train,model.predict(X_train)),accuracy_score(y_cv,model.predict(X_cv))","16bce0b8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\n\nlog_reg = LogisticRegression(max_iter=50000)\nprint(\"Logistic Regression    Train: \"+\"   CV:\".join(map(str,predict_model(log_reg,X_train,y_train,X_cv,y_cv))))\n\nrnd_clf = RandomForestClassifier()\nprint(\"Random Forest Classifier    Train: \"+\"   CV:\".join(map(str,predict_model(rnd_clf,X_train,y_train,X_cv,y_cv))))\n\nsvc = svm.SVC(max_iter=50000)\nprint(\"Support Vector Machine Classifier    Train: \"+\"   CV:\".join(map(str,predict_model(svc,X_train,y_train,X_cv,y_cv))))","ee32bbdb":"train","0d75b5b0":"train2 = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","7a340780":"def all_changes(X):\n    X[\"Honorific\"] = X[\"Name\"].str.split(\",\",expand = True).iloc[:,1].str.split(\".\",expand = True).iloc[:,0].str.strip()\n    X = X.assign(Mr = (X[\"Honorific\"] == \"Mr\").astype(int))\n    X = X.assign(Miss = (X[\"Honorific\"] == \"Miss\").astype(int))\n    X = X.assign(Mrs = (X[\"Honorific\"] == \"Mrs\").astype(int))\n    X = X.assign(Master = (X[\"Honorific\"] == \"Master\").astype(int))\n    X.drop(\"Honorific\",axis=1,inplace=True)\n    \n    X[\"Name\"]=X[\"Name\"].str.split(\",\",expand = True)[0]\n    family = X.loc[:,[\"Name\",\"Ticket\"]]\n    family[\"new\"] = family[\"Name\"] + family[\"Ticket\"]\n    X[\"new\"] = X[\"Name\"] + X[\"Ticket\"]\n    family_unique = family[\"new\"].unique().tolist()\n    family_id = [i for i in range(1,len(family_unique)+1)]\n    merge_df = pd.DataFrame(data={\"new\":family_unique,\"FamilyID\":family_id})\n    \n    X = X.join(merge_df.set_index(\"new\"), on='new')\n    X.drop(\"new\",axis=1,inplace=True)\n    X[\"FamilyID\"].fillna(0,inplace = True)\n    \n    \n    X.drop(X.loc[:,[\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"]],axis=1,inplace=True)\n    \n    X = X.assign(Female = (lambda x: ((x[\"Sex\"] == \"female\")).astype(int)))\n    X = X.assign(Male = (lambda x: ((x[\"Sex\"] == \"male\")).astype(int)))\n    \n    \n    \n    mean = X[\"Age\"].mean()\n    X[\"Age\"].fillna(mean,inplace = True)\n       \n    \n    \n    X = X.assign(P_1 = (X[\"Pclass\"]== 1).astype(int))\n    X = X.assign(P_2 = (X[\"Pclass\"]== 2).astype(int))\n    X = X.assign(P_3 = (X[\"Pclass\"]== 3).astype(int))\n    \n    X[\"Embarked\"].fillna(\"S\",inplace = True)\n    \n    X = X.assign(C = (X[\"Embarked\"]==\"C\").astype(int))\n    X = X.assign(Q = (X[\"Embarked\"]==\"Q\").astype(int))\n    X = X.assign(S = (X[\"Embarked\"]==\"S\").astype(int))\n        \n\n    X[\"NoChild\"] = X[\"Parch\"].loc[X[\"Parch\"]==0]\n    X[\"NoSibSp\"] = X[\"SibSp\"].loc[X[\"SibSp\"]==0]\n    \n    X[\"NoChild\"] = X[\"NoChild\"].fillna(1).astype(int)\n    X[\"NoSibSp\"] = X[\"NoSibSp\"].fillna(1).astype(int)\n    \n\n    X[\"FamilySize\"] = X[\"Parch\"] + X[\"SibSp\"]\n  \n # - - --- - - - - - - -- - - - - - -- - - - -- - - - - -- - - - - - - -- - - - - - -\n    X[\"Pclass\"].replace({1:3,3:1},inplace = True)\n    \n    X[\"Fare\"] = X[\"Fare\"] * X[\"Pclass\"]\n    X[\"Age\"] = X[\"Age\"] * X[\"Pclass\"] \n    \n    X.rename(columns={\"P_1\":\"PClass_1\",\"P_2\":\"PClass_2\",\"P_3\":\"PClass_3\"},inplace=True)\n\n    X.drop(X.loc[:,[\"Sex\",\"Embarked\",\"Pclass\",\"Parch\",\"SibSp\"]],axis=1,inplace=True)\n    return X\n\n\ntrain2 = all_changes(train2)","ec0f99f1":"test.info()","eb06f88f":"test[\"Fare\"].fillna(11,inplace = True)\ntest = all_changes(test)","2977baa7":"test.head()","8e1ed5d0":"X_train.head()","694eb032":"test_result = log_reg.predict(test)\ntest_result = test_result.reshape(-1,1)\n\nresult = pd.DataFrame(data = {\"PassengerId\":np.arange(892,1310,1)})\nresult[\"Survived\"]= test_result\nresult.to_csv(r'result.csv',index = False, header=True)","3580aed7":"What I can get from the name are honorifics and surnames. With surnames and ticket numbers I can create family id","f6d506ab":"For the third outcome, I have to handle Embarked and I can see values of it with countplot.","4c761c5b":"![image.png](attachment:image.png)\n\n\nRMS Titanic, British luxury passenger liner that sank on April 14\u201315, 1912, during its maiden voyage, en route to New York City from Southampton, England, killing about 1,500 passengers and ship personnel. \n\nOne of the most famous tragedies in modern history, it inspired numerous stories, several films, and a musical and has been the subject of much scholarship and scientific speculation.\n\nFirstly, we should import our core libraries that we use to manipulate our data.\n","323c6fd1":"Now we can think about how to use SibSp and and Parch. We can encode 1 if the passenger has any SibSp or Parch value rather than 0. Otherwise, it is zero\n","1422e0c6":"Let's move to first outcome to handle Age's missing values we can use median or mean of the data according to which one will get lower error. \n\nHere the values.","8ff90aeb":"It is the end ! Thanks for your precious comments and feedbacks..","c95c74f7":"Finally, let's drop reduntant features and jump to prediciton part.","a31d80fb":"Firstly, let's handle categorical variables. My first target is Name and Ticket.","ad56f326":"For instance, Fare and Pclass have bigger correlation with Survived than others; however, It is not that massive correlation because the values are still small (0.25 and -0.33).","2f662d89":"147 different values ! It is impossible to complete that much missing data because we can not predict accurately each of them so we just delete the whole column.\n\nAlso we can delete PassengerId becuase we can separate them according to their index column, no need to PassengerId.\n","bdee69cf":"Firstly, I select Pclass. I know that there are 3 different pclass 1,2 and 3; moreover, I want to observe that which one has most number of survived people and survived\/all rate by each class\n\nTo see that I can use a stacked barplot from the plotly library\n","7a1c418e":"Everything looks as expected. However, it seems there are missing values in numerous features such as Age and Cabin so lets check it how many of them is null.","2433f5cc":"Or we can see the correlation just like..","42d416d3":"This is my first notebook that I have ever worked after started to learn machine learning and I am glad for any comment or feedback.","dd4b7f65":"People who survived consist of highly people getting on the ship from S then C and Q come after that\n\nWe can split Embarked like Pclass; however, this time we can use different method instead of OneHotEncoder","3d7eb995":"While I was working on this notebook, I was stuck and I decided to be enlightened about the topic then I watched the Titanic movie and read Titanic's wiki page to acquire knowledge because I had no idea what I'm dealing with.","a489cb10":"Now let's jump to feature engineering before prediction","82e3a011":"To split data I used Stratified sampling","cc57763d":"To see models prediction accuracy I implemented following function\n","312ff6f0":"I chose logistic regression because it gave better result on test data.\n\nWe need to apply same functions to test data that we applied on train data so I just collect functions above in a function.","928f00ea":"We can select any of those values to fill age's missing values. \n\nI'll go with median","ccc8e993":"The biggest part of the survived people have first class ticket then third class and second class come accordingly.\n\n\nTherefore, First class has high probability to survive so our model can predict by just looking whether the passengers possess first class ticket or not. For that reason, It is better to separate Pclass according to their values 1,2 or 3.\n\n\nIn order to make this happen, we can use the famous OneHotEncoder function from sklearn lib.\n","52acba2d":"To get family id I use an algorithm to select families uniquely. After that we don't have any job with ticket and name ; therefore, I delete them.\n","8620750e":"It can be seen that most of the female survived but it is not coincidence because we already know the women and children first rule; therefore, the graph above is the result of that. We can split it up to more accurate prediction.","1df5434b":"We had missing values in Cabin and Age same as train but we have only one row that does not have Fare value unlike train data. We can fill it and then use function we just implemented to finalize.","9e3feb86":"Now I can use correlation map to see correlation between Survived and others. \n\nIf the number is close to 1, then there is a positive correlation ( if x goes up then y goes up ). \n\nIf the number is close to -1 then there is a negative correlation ( if x goes down then y goes up ). \n\nIn the image below, We can see it.\nIn addition, we can only see numerical data not string etc.","f06c6a0f":"After that, I learned the most critical thing about Titanic and I used it to get my final result. It was that while evacuation happening, women and children at higher classes (Pclass1 and Pclass2 mostly) were loaded first to lifeboat. In other words, if you are women or children at first or second class, you are survived with high probability.","844236d9":"Got the data seperately as train and test. \n\nWe will examine train data and build a model on it. After that, We'll try our model on the test data. \n\nLet's take the first look with train data.\n","8d80b105":"# Feature Engineering","10a23435":"How about family size ? It can make a difference\n","422734a2":"Now we can approach Embarked same as Pclass.\n","db37e93e":"There are huge amount of S in the column which means S is the mode and It is slightly reasonable that I prefer S to fill missing values of Embarked because S has high probability rather than others.","898a4e54":"Both dataframe are same according to their column order. ","ac040829":"# Getting Started","eed98f5a":"The Honorific is not needed. Hence, I should just delete it to avoid any kind of redundancy.","032bd9e0":"Table above is our latest form; however, we will delete reduntant features and then I will use my last trick which is multiplying Age and Fare by Pclass because basically a 30 years old passenger in First class is not equal to another 30 years old passenger in Third class. Since,  evacuation of First class is happened firstly and Second class and Third class come later. By doing so, our model can predict better.\n\nIn Fare there are fares that more expensive than prior classes but by multiplacation we can get rid of it in order to expand range between fares for each classes.","bbc7ecc3":"We got it ! No more missing values that probably give us trouble except Cabin (we'll handle it later)","655081ba":"So far, we filled and dropped some columns and we skimed through the correlation map what we should do next is apply some feature engineering stuff and get the data ready for prediction\n\n","bd09e553":"# Prediction\n","5fe1a95c":"Also we can conclude that there are columns that we can use as numerical value instead of string type so that we can get some correlation with survived column. \n\nI mean columns including object type data.","90a8c97c":"What I see from table above is if you are first class passenger then you have high probability to survive but after that we cannot see which one comes next so we can calculate it directly.","cf0b7d38":"We are lucky that the data do not have massive null values for many features, so there are 3 outcomes which are about Age, Cabin and Embarked.\n\n**AGE**\n1. There are approximately 280 missing values in the Age column that we may complete manually e.g. filling with mean values or median values..\n\n**EMBARKED**\n2. For Embarked, it is just 2 so we can either delete or complete them.\n\n**CABIN**\n3. As we can see there are huge amount of data are missing in Cabin column; moreover, I may complete them according to right possible values unless it has various values so lets take a look ","3a1f1589":"Top 4 will be enough for prediction purposes that's why I'll do cut rest of them and use only top 4."}}