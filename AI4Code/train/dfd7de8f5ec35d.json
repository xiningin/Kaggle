{"cell_type":{"1fced8c1":"code","35e09ad4":"code","a6eaa4c0":"code","68fb1704":"code","dbf805cf":"code","464d52db":"code","83e9bbf4":"code","2de51ef9":"code","c2de828f":"code","4402787e":"code","5baf14ff":"code","2bf9ccde":"code","76c0a263":"code","951ecd8a":"code","c1c31774":"code","2c25dcb7":"code","9f6c5ad6":"code","0a590969":"code","6a308b4d":"code","fb152f1a":"code","96bf995f":"code","2a157ffa":"code","ae3ecd30":"code","bcf00e68":"code","3e624666":"code","1bfc2624":"code","d235639a":"code","c724af89":"code","6a3a28c6":"code","908b9b7e":"code","0f9ed11b":"code","53f2d1b9":"code","b3378efc":"code","365ea151":"code","5fa63b3b":"code","baf2f4f1":"code","2068caa4":"code","7cb24d20":"code","1c592862":"code","033f620b":"code","a5c5948d":"code","bab9397e":"code","da79d1c5":"code","b919b7be":"code","d6f3ecaf":"code","bba615f4":"code","bb229978":"code","76536251":"markdown","32b4aae1":"markdown","2f0745ce":"markdown","db744d3c":"markdown","eeb7685e":"markdown","f60ef431":"markdown","51474d85":"markdown","8d4f453b":"markdown","bb939f69":"markdown","3ce324af":"markdown","b1a82a22":"markdown","cd5ccb0a":"markdown"},"source":{"1fced8c1":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\n%matplotlib inline\n\ndf_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_train.head(5)","35e09ad4":"df_train.info()","a6eaa4c0":"age_na = df_train[df_train['Age'].isna()]\nage_na.head(5)","68fb1704":"#Looking up for a 'Sex' in missing data\nsns.countplot(data= age_na, x= 'Sex', hue= 'Survived')","dbf805cf":"print(age_na[age_na['Sex'] == 'male'].describe())\nprint('---------------------------------------------------------------------')\nprint(age_na[age_na['Sex'] == 'female'].describe())","464d52db":"#Filling 'NaN' man values according the 3rd class mean age in dataset\n\nm_mean = df_train[df_train['Pclass'] == 3]['Age'].mean()\nmale_filled = pd.Series(df_train[df_train['Sex'] == 'male']['Age'].fillna(m_mean))","83e9bbf4":"#Filling 'NaN' women values according the 3rd class mean age in dataset\n\nf_mean = df_train[df_train['Pclass'] == 3]['Age'].mean()\nfemale_filled = pd.Series(df_train[df_train['Sex'] == 'female']['Age'].fillna(f_mean))","2de51ef9":"#Concat and write to dataset\ndf_train['Age'] = list(male_filled.values) + list(female_filled.values)\ndf_train.info()","c2de828f":"df_train.isna().sum()","4402787e":"df_train[df_train['Embarked'].isna()]","5baf14ff":"df_train['Embarked'].mode()","2bf9ccde":"df_train['Embarked'].fillna('S', inplace= True)\ndf_train.isna().sum()","76c0a263":"# Creating 'IsAlone' feature ('Parch' + 'SibSp')\ndf_train['NotAlone'] = (df_train['Parch'] + df_train['SibSp'])\ndf_train['NotAlone'].replace(to_replace= range(1,14), value= 1,inplace= True)\ndf_train.head()","951ecd8a":"# Creating 'Male' feature (male= 1, female= 0)\ndf_train['Male'] = (df_train['Sex'].replace({'male': 1, 'female': 0}))\ndf_train.head()","c1c31774":"sns.histplot(data=df_train, x= 'Age', hue= 'Survived')","2c25dcb7":"''' Good idea or bad generalization?! '''\n#df_train['ChildGirl'] = (df_train['Age']<= 3) & (df_train['Sex'] == 'female')\n#df_train[df_train.ChildGirl == True]","9f6c5ad6":"#Transforming 'Age' into 7 bins\ndf_train['Age'] = pd.qcut(df_train['Age'], 7, duplicates= 'drop', labels= False)\ndf_train.head()","0a590969":"sns.histplot(data=df_train, x= 'Age', hue= 'Survived')","6a308b4d":"sns.histplot(np.sort(df_train['Fare']), bins= 50)\n\ndf_train.loc[df_train['Fare'] <= 30, 'Fare'] = 1\ndf_train['Fare'] = np.where((df_train['Fare'] > 30) & (df_train['Fare'] <= 90) , 2, df_train['Fare'])\ndf_train['Fare'] = np.where((df_train['Fare'] > 90) & (df_train['Fare'] <= 170) , 3, df_train['Fare'])\ndf_train['Fare'] = np.where((df_train['Fare'] > 170) & (df_train['Fare'] <= 260) , 4, df_train['Fare'])\ndf_train['Fare'] = np.where((df_train['Fare'] > 260) & (df_train['Fare'] <= df_train['Fare'].max()) , 5, df_train['Fare'])\nnp.sort(df_train['Fare'].unique())\n","fb152f1a":"sns.countplot(data= df_train, x= 'Fare', hue= 'Survived')","96bf995f":"# Transforming embarked to features\ndf_train['emb_C'] = df_train['Embarked'] == 'C'\ndf_train['emb_C'] = df_train['emb_C'].replace(True, 1).replace(False, 0)\n\ndf_train['emb_Q'] = df_train['Embarked'] == 'Q'\ndf_train['emb_Q'] = df_train['emb_Q'].replace(True, 1).replace(False, 0)\n\ndf_train['emb_S'] = df_train['Embarked'] == 'S'\ndf_train['emb_S'] = df_train['emb_S'].replace(True, 1).replace(False, 0)\n\ndf_train.info()","2a157ffa":"df_train.head(5)","ae3ecd30":"#Drop useless columns\ndf_train.drop(columns=['Cabin', 'Ticket', 'Sex', 'Embarked', 'Name'], inplace= True)\ndf_train.head()","bcf00e68":"from matplotlib import pyplot as plt\nplt.figure(figsize= (10,6))\nsns.heatmap(df_train.corr(), annot= True)","3e624666":"sns.countplot(data= df_train, x= 'Age', hue= 'Survived')","1bfc2624":"sns.countplot(data= df_train, x= 'emb_Q', hue= 'Survived')","d235639a":"sns.countplot(data= df_train, x= 'emb_S', hue= 'Survived')","c724af89":"sns.countplot(data= df_train, x= 'emb_C', hue= 'Survived')","6a3a28c6":"sns.countplot(data= df_train, x= 'Male', hue= 'Survived')","908b9b7e":"sns.countplot(data= df_train, x= 'NotAlone', hue= 'Survived')","0f9ed11b":"sns.countplot(data= df_train, x= 'Pclass', hue= 'Survived')","53f2d1b9":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\n\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(random_state= 14),\n    GaussianProcessClassifier(random_state= 14),\n    DecisionTreeClassifier(random_state= 14),\n    RandomForestClassifier(random_state= 14),\n    GradientBoostingClassifier(random_state= 14),\n    AdaBoostClassifier(random_state= 14),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    XGBClassifier()]\n\ny = df_train['Survived']\nX = df_train.drop(columns= ['Survived'])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=17)\n\nfor clf in classifiers:\n        clf.fit(X_train, y_train)\n        print(f'{clf}----{clf.score(X_test, y_test)}')","b3378efc":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\n\nparams_rForest = {'n_estimators': [100,200,300,400,500], 'criterion': ('gini', 'entropy'), 'max_depth': range(1,15),\n                  'n_jobs': [4]}\n\nparams_ada = {'base_estimator': [DecisionTreeClassifier(max_depth=3, random_state= 14)], 'n_estimators': [50, 100, 150, 200], 'learning_rate': [0.1,1,10,15],\n             'algorithm': ('SAMME', 'SAMME.R')}\n\nparams_xgb = {'n_estimators': [100,200,300,400,500], 'use_label_encoder': [False], 'max_depth': range(1,15), \n              'learning_rate': [0.1, 1, 10], 'booster': ('gbtree','gblinear','dart'), 'n_jobs': [4]}\n\nsearch_rFrorest = GridSearchCV(RandomForestClassifier(random_state=14), param_grid= params_rForest, scoring= 'roc_auc')\nsearch_ada = GridSearchCV(AdaBoostClassifier(random_state=14), param_grid= params_ada, scoring= 'roc_auc')\nsearch_xgb = GridSearchCV(XGBClassifier(), param_grid= params_xgb, scoring= 'roc_auc')\n\nsearch_rFrorest.fit(X,y)\nsearch_ada.fit(X,y)\nsearch_xgb.fit(X,y)\n\n","365ea151":"r_forest_best_est = search_rFrorest.best_estimator_\nada_best_est = search_ada.best_estimator_\nxgb_best_est = search_xgb.best_estimator_\n","5fa63b3b":"search_xgb.best_estimator_","baf2f4f1":"search_xgb.best_score_","2068caa4":"search_rFrorest.best_estimator_","7cb24d20":"search_rFrorest.best_score_","1c592862":"search_ada.best_estimator_","033f620b":"search_ada.best_score_","a5c5948d":"from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\nfrom matplotlib import pyplot as plt\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 19)\n\n","bab9397e":"y_score = r_forest_best_est.predict(X_test)\n\n\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfpr, tpr, _ = roc_curve(y_test, y_score)\nroc_auc = auc(fpr, tpr)\n\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC for RandomForest')\nplt.legend(loc=\"lower right\")\nplt.show()","da79d1c5":"cm = confusion_matrix(y_test, y_score, labels=clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=clf.classes_)\ndisp.plot()","b919b7be":"y_score = ada_best_est.predict(X_test)\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfpr, tpr, _ = roc_curve(y_test, y_score)\nroc_auc = auc(fpr, tpr)\n\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC for AdaBoost')\nplt.legend(loc=\"lower right\")\nplt.show()\n","d6f3ecaf":"cm = confusion_matrix(y_test, y_score, labels=clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=clf.classes_)\ndisp.plot()","bba615f4":"y_score = xgb_best_est.predict(X_test)\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfpr, tpr, _ = roc_curve(y_test, y_score)\nroc_auc = auc(fpr, tpr)\n\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC for AdaBoost')\nplt.legend(loc=\"lower right\")\nplt.show()","bb229978":"cm = confusion_matrix(y_test, y_score, labels=clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=clf.classes_)\ndisp.plot()","76536251":"# Reading the data and get some info","32b4aae1":"## Grid search for best params in best classifiries","2f0745ce":"# Preprocessing other data to categorial variables","db744d3c":"# Plotting roc_auc curve and confusion matrix","eeb7685e":"# Taking closer look to 'Embarked' feature","f60ef431":"## AdaBoost  ROC curve and confusion matrix","51474d85":"# Taking closer look  to 'Age' feature","8d4f453b":"# Building model","bb939f69":"## Random forest ROC curve and confusion matrix","3ce324af":"## Choosing best untuned ones","b1a82a22":"# Visual analyze of features","cd5ccb0a":"## XGBoost  ROC curve and confusion matrix"}}