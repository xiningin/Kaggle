{"cell_type":{"f73f5d94":"code","7177e01e":"code","874e8da6":"code","a72506b3":"code","1adbb09e":"code","f70a3a15":"code","39f623ca":"code","6c1efb12":"code","28f72817":"code","cdf3ba7b":"code","9e6d8e95":"code","c07b4fad":"code","9ea4ec74":"code","d8bafbf6":"code","bfc56cda":"code","75e7b834":"code","bfbd1a98":"code","94b70061":"code","02a02c22":"code","805080a7":"code","7d6faddc":"code","5c3c185e":"code","48131b07":"code","522c8764":"code","2f87ef2d":"code","9cd68c4d":"code","5c6c28e3":"code","9d91d415":"code","1f2d13c0":"code","991bac89":"code","e735c1b9":"code","c12babae":"code","913c8cd8":"code","693770c6":"code","cc5be98e":"code","8e6e42a3":"code","fd7881a3":"code","fed8733f":"code","ca648f6c":"code","691c0d57":"code","ee3921fa":"code","70556a09":"code","f4268b90":"code","22e615a2":"code","4c2abe02":"code","57ba5969":"code","a742360e":"code","aef04f60":"code","92bf526c":"code","293faac2":"code","b0cf5425":"code","435b44be":"code","50bbc5bf":"code","2fc98704":"code","702163db":"code","da65f92d":"code","c605e7be":"code","05f43339":"code","5b2e71e8":"code","e8b95afc":"code","36be3544":"code","d78ce598":"code","cc1c3544":"code","0f723084":"code","1a9bee0d":"code","2a9504ca":"code","074ad4e5":"code","047cf40c":"code","7f8b61f6":"code","dd30f8f8":"markdown","7bf3874a":"markdown","9f2dcd01":"markdown","1a65f1b8":"markdown","3e97a582":"markdown","ed02a554":"markdown","a3d658bd":"markdown","0b635206":"markdown","97b5dccd":"markdown","22978735":"markdown","668d3918":"markdown","6f805792":"markdown","c36e7827":"markdown","03b8c7c9":"markdown","80761cd2":"markdown","f6a2668e":"markdown","ac46299a":"markdown","771d937e":"markdown","6bb72aa9":"markdown","44b431c5":"markdown","c443ef42":"markdown","21a16c54":"markdown","3258357e":"markdown","6cb57189":"markdown"},"source":{"f73f5d94":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport pandas as pd","7177e01e":"df=pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/train.csv\")","874e8da6":"df.head()","a72506b3":"print(\"***** Shape of dataset is *****\")\nprint()\ndf.shape   #shape of training data","1adbb09e":"print(\"***** Column names present in dataset *****\")\nprint()\ndf.columns  #Column names","f70a3a15":"print(\"***** Checking if null values present or not *****\")\nprint()\ndf.isnull().sum()   #Checking null values","39f623ca":"print(\"**** Description of data *****\")\nprint()\ndf.describe()   #Description of data","6c1efb12":"print(\"***** Value counts of target feature *****\")\nprint()\ndf['Is_Lead'].value_counts()","28f72817":"columns=[ 'Gender', 'Region_Code', 'Occupation', 'Channel_Code',\n        'Credit_Product', 'Is_Active','Is_Lead']\n\nfor i in columns:\n    print(\"Value counts of\",i,\"is :\")\n    print(df[i].value_counts())\n    print()\n    print(\"Unique values of\",i,\"is :\",df[i].unique()) \n    print()","cdf3ba7b":"df.head()","9e6d8e95":"def with_hue(data,feature,ax):\n    \n    #Numnber of categories\n    num_of_cat=len([x for x in data[feature].unique() if x==x])\n    \n    bars=ax.patches\n    \n    for ind in range(num_of_cat):\n        ##     Get every hue bar\n        ##     ex. 8 X categories, 4 hues =>\n        ##    [0, 8, 16, 24] are hue bars for 1st X category\n        hueBars=bars[ind:][::num_of_cat] \n        # Get the total height (for percentages)\n        total=sum([x.get_height() for x in hueBars])\n        #Printing percentages on bar\n        for bar in hueBars:\n            percentage='{:.1f}%'.format(100 * bar.get_height()\/total)\n            ax.text(bar.get_x()+bar.get_width()\/2.0,\n                   bar.get_height(),\n                   percentage,\n                    ha=\"center\",va=\"bottom\",fontweight='bold',fontsize=14)\n    \n\n    \ndef without_hue(data,feature,ax):\n    \n    total=float(len(data))\n    bars_plot=ax.patches\n    \n    for bars in bars_plot:\n        percentage = '{:.1f}%'.format(100 * bars.get_height()\/total)\n        x = bars.get_x() + bars.get_width()\/2.0\n        y = bars.get_height()\n        ax.text(x, y,(percentage,bars.get_height()),ha='center',fontweight='bold',fontsize=14)\n","c07b4fad":"sns.set_theme(context=\"notebook\",style=\"white\",font_scale=2)\nfig=plt.figure(figsize=(15,7))\n\n#Setting plot and background color\nax = plt.axes() \nax.set_facecolor(\"#F2EDD7FF\") \nfig.patch.set_facecolor(\"#F2EDD7FF\")\n\n#Dealing with spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.grid(linestyle=\"--\",axis='y',color='gray')\n\na=sns.countplot(data=df,x='Is_Lead',palette='rocket_r')\nwithout_hue(df,'Is_Lead',a)","9ea4ec74":"nrows=5\nncols=2\nf,ax=plt.subplots(nrows=nrows,ncols=ncols,figsize=(20,34))\ncolumns=['Gender','Occupation', 'Channel_Code','Credit_Product', 'Is_Active']\n\nf.patch.set_facecolor('#F2EDD7FF')\n\n    #Setting background and foreground color\nfor i in range(0,nrows):\n  for j in range(0,ncols):\n    ax[i][j].set_facecolor('#F2EDD7FF')\n    ax[i][j].spines['top'].set_visible(False)\n    ax[i][j].spines['right'].set_visible(False)\n    ax[i][j].spines['left'].set_visible(False)\n    ax[i][j].grid(linestyle=\"--\",axis='y',color='gray')\n\n\n    if(j==0):\n      a1=sns.countplot(data=df,x=columns[i-1],palette='rocket_r',ax=ax[i][j])\n      without_hue(df,columns[i-1],a1)\n    elif(j==1):\n      a2=sns.countplot(data=df,x=columns[i-1],palette='rocket_r',ax=ax[i][j],hue=\"Is_Lead\")\n      with_hue(df,columns[i-1],a2)\n\n","d8bafbf6":"nrows=3\nncols=2\nf,ax=plt.subplots(nrows=nrows,ncols=ncols,figsize=(25,34))\ncolumns=[\"Age\",\"Vintage\",\"Avg_Account_Balance\"]\n\nf.patch.set_facecolor('#F2EDD7FF')\n\n    #Setting background and foreground color\nfor i in range(0,nrows):\n  for j in range(0,ncols):\n    ax[i][j].set_facecolor('#F2EDD7FF')\n    ax[i][j].spines['top'].set_visible(False)\n    ax[i][j].spines['right'].set_visible(False)\n    ax[i][j].spines['left'].set_visible(False)\n    ax[i][j].grid(linestyle=\"--\",axis='y',color='gray')\n\n\n    if(j==0):\n      a1=sns.boxplot(data=df,x=(df[columns[i-1]]),palette='rocket_r',ax=ax[i][j])\n    elif(j==1):\n      a2=sns.histplot(data=df,x=(df[columns[i-1]]),palette='rocket_r',ax=ax[i][j],hue=\"Is_Lead\",kde=True)","bfc56cda":"sns.set_theme(context=\"notebook\",style=\"white\",font_scale=2)\nfig=plt.figure(figsize=(15,7))\n\n#Setting plot and background color\nax = plt.axes() \nax.set_facecolor(\"#F2EDD7FF\") \nfig.patch.set_facecolor(\"#F2EDD7FF\")\n\n#Dealing with spines\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.grid(linestyle=\"--\",axis='y',color='gray')\n\nplt.text(10,3300,\"Log Distribution of\\nAvg_Account_Balance\",fontweight='bold')\na=sns.histplot(data=df,x=np.log(df['Avg_Account_Balance']),palette='rocket_r',kde=True)\n","75e7b834":"xvars=['Age',\"Vintage\",'Avg_Account_Balance']\nyvars=['Age','Vintage',\"Avg_Account_Balance\"]\ng=sns.pairplot(data=df,x_vars=xvars,y_vars=yvars,palette=\"rocket_r\")\ng.fig.set_size_inches(15,15)\n","bfbd1a98":"#Changing the distribution of 'Avg_Account_Balance' into Log Distribution\ndf['Avg_Account_Balance']=np.log(df['Avg_Account_Balance'])","94b70061":"\n'''df_acc=sorted(df['Avg_Account_Balance'])\nQ1,Q3=np.percentile(df_acc,[25,75])\nIQR= Q3-Q1\nlower_range= Q1-(1.5*IQR)\nupper_range=Q3+(1.5*IQR)\n\nprint(\"Lower range of outliers : \",lower_range)\nprint(\"Upper range of outliers : \",upper_range)\ndf_lower_outliers=df[df['Avg_Account_Balance']<lower_range]\ndf_upper_outliers=df[df['Avg_Account_Balance']>upper_range]\n\nprint(\"***** Lower outliers of acc *****\")\nprint()\ndf_lower_outliers\n\nprint(df_upper_outliers.shape)\nprint()\nprint(\"**** Outer outliers of acc *****\")\nprint()\ndf_upper_outliers\n\ndf1=df.drop(df[df['Avg_Account_Balance']>upper_range].index)\ndf1=df.drop(df[df['Avg_Account_Balance']<lower_range].index)'''","02a02c22":"df1=df.copy()","805080a7":"dropping_columns=['ID']\ndf1=df1.drop(dropping_columns,axis=1)","7d6faddc":"from sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nimport optuna\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import cross_val_score,train_test_split , StratifiedKFold\nfrom sklearn.metrics import roc_auc_score , f1_score , confusion_matrix , classification_report","5c3c185e":"#df1[\"Credit_Product\"]=df1['Credit_Product'].fillna(df1['Credit_Product'].dropna().mode()[0])\ndf1['Credit_Product'].replace(np.nan,'Missing',inplace=True)","48131b07":"#Label Encoding\nlabel_encode=LabelEncoder()\ncolumns1=['Gender', 'Is_Active','Occupation', 'Channel_Code','Credit_Product',\"Region_Code\"]\ndf1[columns1]=df1[columns1].apply(label_encode.fit_transform)\ndf1.head()","522c8764":"#One hot encoding\nlabel_encode=LabelEncoder()\ncolumns1=['Gender', 'Is_Active']\ncolumns2=['Occupation', 'Channel_Code','Credit_Product']\ndf1[columns1]=df1[columns1].apply(label_encode.fit_transform)\ndf1=pd.get_dummies(data=df1,columns=columns2)\ndf1.head()","2f87ef2d":"#Standard Scaling\nss=StandardScaler()\ncolumns3=['Age','Vintage','Avg_Account_Balance']\ndf1[columns3]=ss.fit_transform(df1[columns3])\ndf1.head()","9cd68c4d":"fig=plt.figure(figsize=(20,10))\nax = plt.axes() \nax.set_facecolor(\"#F2EDD7FF\") \nfig.patch.set_facecolor(\"#F2EDD7FF\")\n\nsns.heatmap(data=df1.corr(),annot=True,linewidth=3)","5c6c28e3":"Y=df1['Is_Lead']\nX=df1.drop(\"Is_Lead\",axis=1)","9d91d415":"Y.value_counts()","1f2d13c0":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)","991bac89":"y_train.value_counts()","e735c1b9":"y_test.value_counts()","c12babae":"#Oversampling\nsmt=SMOTE()\nx_samp,y_samp=smt.fit_resample(x_train,y_train)\n\n#UnderSampling\n'''from imblearn.under_sampling import RandomUnderSampler\nus=RandomUnderSampler(random_state=42)\n","913c8cd8":"from sklearn.linear_model import LogisticRegression\nclf=LogisticRegression(solver=\"liblinear\", random_state=42)\ncv=StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\nans=cross_val_score(clf,x_train,y_train,cv=cv,n_jobs=2,scoring='roc_auc').mean()\nprint(\"Logistic Regression :\" , ans)","693770c6":"model_log=clf.fit(x_train,y_train)","cc5be98e":"pred_log=model_log.predict_proba(x_test)[:,1]","8e6e42a3":"print(\"***** roc-auc-score of logistic regression *****\")\nprint()\nprint(roc_auc_score(y_test,pred_log))","fd7881a3":"from sklearn.tree import DecisionTreeClassifier","fed8733f":"def objective(trial):\n    \n    #n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_int('max_depth', 1,100))\n    clf = DecisionTreeClassifier(max_depth=max_depth)\n    cv=StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\n    return cross_val_score(clf, x_train, y_train,n_jobs=2, cv=cv,scoring='roc_auc').mean()","ca648f6c":"study = optuna.create_study(direction='maximize',study_name='Decision Trees')\nstudy.optimize(objective, n_trials=15)","691c0d57":"trial = study.best_trial\nprint('## best_value -->',trial.value)\nprint(\"## best_parameters -->\",trial.params)","ee3921fa":"model_dt=DecisionTreeClassifier(max_depth=10)\n\nmodel_dt.fit(x_train,y_train)","70556a09":"y_pred_dt=model_dt.predict_proba(x_test)[:,1]","f4268b90":"print(\"***** roc_auc_score of decision tree classifier *****\")\nprint()\nprint(roc_auc_score(y_test,y_pred_dt))","22e615a2":"from sklearn.neighbors import KNeighborsClassifier","4c2abe02":"def objective(trial):\n    \n    #n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    n_neighbors = int(trial.suggest_int('n_neighbors', 1,500))\n    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n    cv=StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\n\n    return cross_val_score(clf, x_train, y_train, \n           n_jobs=2, cv=cv,scoring='roc_auc').mean()","57ba5969":"study = optuna.create_study(direction='maximize',study_name='KNN')\nstudy.optimize(objective, n_trials=15)","a742360e":"trial = study.best_trial\nprint('## best_values -->',trial.value)\nprint(\"## best_parameters -->\",trial.params)","aef04f60":"model_k=KNeighborsClassifier(n_neighbors=43)","92bf526c":"model_k.fit(x_train,y_train)","293faac2":"y_pred_k=model_k.predict_proba(x_test)[:,1]","b0cf5425":"print(roc_auc_score(y_test,y_pred_k))","435b44be":"def objective(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_int('max_depth', 1, 40))\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n    cv=StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\n\n    return cross_val_score(clf, x_train, y_train, \n           n_jobs=2, cv=cv,scoring='roc_auc').mean()","50bbc5bf":"study = optuna.create_study(direction='maximize',study_name='Random Forest')\nstudy.optimize(objective, n_trials=10)","2fc98704":"trial = study.best_trial\nprint('## best_values -->',trial.value)\nprint(\"## best_parameters -->\",trial.params)","702163db":"model_rf=RandomForestClassifier(n_estimators=174,max_depth=10)","da65f92d":"model_rf.fit(x_train,y_train)","c605e7be":"pred_train=model_rf.predict_proba(x_test)[:,1]\n","05f43339":"print(roc_auc_score(y_test,pred_train))","5b2e71e8":"feature_importance = np.array(model_rf.feature_importances_)\nfeature_names = np.array(x_train.columns)\ndata={'feature_names':feature_names,'feature_importance':feature_importance}\ndf_plt = pd.DataFrame(data)\ndf_plt.sort_values(by=['feature_importance'], ascending=False,inplace=True)\nplt.figure(figsize=(10,8))\nsns.barplot(x=df_plt['feature_importance'], y=df_plt['feature_names'])\n#plt.style.use(\"ggplot\")\nplt.xlabel('FEATURE IMPORTANCE')\nplt.ylabel('FEATURE NAMES')\nplt.show()","e8b95afc":"import lightgbm as lgb","36be3544":"def objective_lgbm(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 500)\n    max_depth = int(trial.suggest_int('max_depth', 2, 50))\n    learning_rate=trial.suggest_loguniform('learning_rate',0.001,1)\n    colsample_bytree=trial.suggest_loguniform(\"colsample_bytree\",0.1, 1)\n    num_leaves=trial.suggest_int('num_leaves',10,300)\n    reg_alpha= trial.suggest_loguniform('reg_alpha',0.1,10)\n    reg_lambda= trial.suggest_loguniform('reg_lambda',0.1,10)\n    min_split_gain=trial.suggest_loguniform('min_split_gain',0.1,1)\n    subsample=trial.suggest_loguniform('subsample',0.1,1)    \n    clf = lgb.LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth,\n                            learning_rate=learning_rate,colsample_bytree=colsample_bytree,\n                            num_leaves=num_leaves,reg_alpha=reg_alpha,reg_lambda=reg_lambda,\n                            min_split_gain=min_split_gain,subsample=subsample)\n    cv=StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\n    return cross_val_score(clf, x_train, y_train, \n           n_jobs=2, cv=5,scoring='roc_auc').mean()","d78ce598":"study_lgbm= optuna.create_study(direction='maximize',study_name=\"LGBM\")\nstudy_lgbm.optimize(objective_lgbm, n_trials=15)","cc1c3544":"trial_lgbm= study_lgbm.best_trial\nprint(\"## Accuracy --> \",trial_lgbm.value)\nprint(\"## Best parameters --> \",trial_lgbm.params)","0f723084":"#MODEL\nmodel_lgbm=lgb.LGBMClassifier(**trial_lgbm.params)\nmodel_lgbm.fit(x_train,y_train,eval_metric=\"auc\",eval_set=[(x_test,y_test)],early_stopping_rounds=100,verbose=400)","1a9bee0d":"pred_lgbm=model_lgbm.predict_proba(x_test)[:,1]","2a9504ca":"print(\"***** roc_auc_score of LGBM *****\")\nprint()\nprint(roc_auc_score(y_test,pred_lgbm))","074ad4e5":"def cross_val(X, y, model, params, folds=9):\n\n    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=21)\n    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n        x_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        x_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n\n        alg = model(**params)\n        alg.fit(x_train, y_train,\n                eval_set=[(x_test, y_test)],\n                early_stopping_rounds=100,\n                verbose=400)\n\n        pred = alg.predict_proba(x_test)[:, 1]\n        roc_score = roc_auc_score(y_test, pred)\n        print(f\"roc_auc_score: {roc_score}\")\n        #print(\"-\"*50)\n    \n    return alg","047cf40c":" lgbm_params= {'learning_rate': 0.045, \n             'n_estimators': 20000, \n             'max_bin': 94,\n             'num_leaves': 10, \n             'max_depth': 27, \n             'reg_alpha': 8.457, \n             'reg_lambda': 6.853, \n             'subsample': 0.749}","7f8b61f6":"from lightgbm import LGBMClassifier\nlgb_model = cross_val(X,Y,LGBMClassifier, lgbm_params)","dd30f8f8":"# **LOGISTIC REGRESSION**","7bf3874a":"##### **Undersampling and oversampling code but we will move ahead without implementation of these techniques and observe how our models will work**","9f2dcd01":"#### **Removing outliers using quartile method**","1a65f1b8":"* **ID : Unique Identifier for a row** \n\n* **Gender: Gender of the Customer** \n\n* **Age : Age of the Customer (in Years)**\n\n* **Region_Code : Code of the Region for the customers** \n\n* **Occupation : Occupation Type for the customer** \n\n* **Channel_Code : Acquisition Channel Code for the Customer (Encoded)** \n\n* **Vintage : Vintage for the Customer (In Months), Number of Days, Customer has been associated with the company** \n\n* **Credit_Product : If the Customer has any active credit product (Home loan, Personal loan, Credit Card etc.)** \n\n* **Avg_Account_Balance : Average Account Balance for the Customer in last 12 Months**\n\n* **Is_Active : If the Customer is Active in last 3 Months** \n\n* **Is_Lead(Target) : If the Customer is interested for the Credit Card, 0 \/ 1: Customer is not interested \/ interested**\n\n* **Things I have learned from this competition , please visit on this [topic](https:\/\/www.kaggle.com\/discussion\/242986) and provide your feedback**","3e97a582":"# **OVERVIEW**","ed02a554":"##### **Hyperparameter tuning using optuna**","a3d658bd":"# **PREPROCESSING**","0b635206":"##### **Training of Model**","97b5dccd":"# **Decision Tree Classifier**","22978735":"# **DATASET**","668d3918":"##### **Curently going forward without dropping outliers : because removing outliers may cause loss of important data**","6f805792":"### **Don't forget to visit my other notebooks too and your feedback is appreciated**\n\n1. [Crime Against Women in India](https:\/\/www.kaggle.com\/aryanml007\/crime-against-women-in-india-2001-to-2014)\n2. [Stroke Prediction Analysis](https:\/\/www.kaggle.com\/aryanml007\/stroke-prediction-analysis-auc-0-90)\n3. [Heart Attack Analysis](https:\/\/www.kaggle.com\/aryanml007\/heart-attack-analysis-visualizations)\n\n4. [TPS April 2021](https:\/\/www.kaggle.com\/aryanml007\/manual-encoding-optuna-tps-april)\n\n5. [Fetal Health classification](https:\/\/www.kaggle.com\/aryanml007\/fetal-health-classification)\n\n6. [Student performance analysis](https:\/\/www.kaggle.com\/aryanml007\/students-performance-analysis)\n\n7. [Plant Disease detection](https:\/\/www.kaggle.com\/aryanml007\/plant-disease-resnet50)\n\n8. [Vehicle Insurance](https:\/\/www.kaggle.com\/aryanml007\/vehicle-insurance)\n","c36e7827":"##### **Will do label encoding of all categorical columns**","03b8c7c9":"##### **Dropping \"ID\" Column**","80761cd2":"### **As we can see data is imbalanced**","f6a2668e":"##### **Prediction**","ac46299a":"#### **Not any major correlation between two features so we will go ahead with all features and start from basic**","771d937e":"# **LGBM**","6bb72aa9":"##### **We will take \"nan\" value present in \"Credit_Product\" as another class and replace all \"nan\" values with \"Missing\" Keyword**","44b431c5":"### **Out of all classifiers LGBM gives the highest roc_auc_score**\n### **If you have any suggestion please tell me in the comment section**\n### **There are many experiments we can do on this dataset but I build a baseline notebook:)**\n### **Also I have made a topic on things I have learned from this competition link is [Here](https:\/\/www.kaggle.com\/discussion\/242986) , please have a look and share your feedback**\n","c443ef42":"# **K NEAREST NEIGHBOURS**","21a16c54":"#### **Importing necessary libraries**","3258357e":"# **VISUALIZATIONS**","6cb57189":"# **RANDOM FOREST CLASSIFIER**"}}