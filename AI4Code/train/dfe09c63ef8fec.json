{"cell_type":{"b0d2550f":"code","a9da6459":"code","43f79c68":"code","d5b40bcd":"code","ff8e92ee":"code","02e1bb93":"code","152c1787":"code","d70b31e6":"code","b9c0f4b0":"markdown","95514b8c":"markdown","329633a7":"markdown","51c189a6":"markdown","e312b652":"markdown","e9eb98ce":"markdown","8bccec09":"markdown"},"source":{"b0d2550f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\nfrom sklearn.pipeline import Pipeline","a9da6459":"# Initialize the random seed for consistency\nnp.random.seed(23)\n\n# Read in data from csv files\ntrain_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\n# Relabel columns\ntrain_df.columns = ['id', 'survived', 'pclass', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare', 'cabin', 'embarked']\ntest_df.columns = ['id', 'pclass', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare', 'cabin', 'embarked']","43f79c68":"print(train_df.head())\n\ntrain_df.info()\n\n%matplotlib inline\ntrain_df.hist(bins=20, figsize=(16, 9))\nplt.show()","d5b40bcd":"def print_value_counts(data, columns):\n    for col in columns:\n        print(data[col].value_counts())\n        print('')\n\ncol_list = ['sex', 'ticket', 'cabin', 'embarked']\nprint_value_counts(train_df, col_list)","ff8e92ee":"# As the majority of passengers embarked from Southampton, the two empty passengers will be marked as leaving from there\ntrain_df['embarked'].fillna('S', inplace=True)\n\n# One hot encodes sex to column male, where 1 is male and 0 is female\ntrain_df = pd.get_dummies(train_df, columns=['sex'], drop_first=True)\ntrain_df.rename(columns={'sex_male':'male'}, inplace=True)\n\n#Changes embarked from object to int types, with 0 representing Cherbourg, 1 represeting Queenstown, and 2 representing Southampton\nembarked_nums = [0 for i in range(len(train_df['embarked']))]\nfor i, val in enumerate(train_df['embarked']):\n    if val == 'C':\n        embarked_nums[i] = 0\n    if val == 'Q':\n        embarked_nums[i] = 1\n    if val == 'S':\n        embarked_nums[i] = 2\ntrain_df['embarked'] = embarked_nums\n\nprint(train_df.head())\nprint(train_df.info())","02e1bb93":"# Ignoring id, name, ticket, and cabin because the data is either superfluous or too much is missing\nX = train_df[['pclass', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'male']]\ny = train_df['survived']\n\n# The Age data is annoying. I think there is good reason to try a multitude of things. In one case, I will just drop the rows with\n# the age missing, which will be X_drop. In another case I will attempt to impute the age by drawing from the absolute value of the\n# normal distribution for the missing values, denoted as X_imp. In the last case, I will use all of the rows but just ignore the age\n# information, denoted as X_noage.\n\nX_drop = X.dropna()\nmask = X['age'].isna()\ny_drop = y[~mask]\n\n# Imputes missing ages as the absolute value of ages pulled from a normal dist with mean and std equal to those of the original age data\n# Taking the absolute value isn't amazing as it is no longer a normal distribution, but it makes the resulting dist look very similar\n# to the original dist, so I'm taking it\nX_imp = pd.DataFrame.copy(X)\n\ndef impute_normal_dist(data, col):\n    mean = data[col].mean()\n    std = data[col].std()\n\n    rng = np.random.default_rng(seed = 23)\n\n    mask = data[col].isna()\n    imp_age = [0 for i in range(len(data[col]))]\n\n    for i, val in enumerate(data[col]):\n        if mask[i]:\n            imp_age[i] = np.abs(rng.normal(mean, std))\n        else:\n            imp_age[i] = val\n    return imp_age\n\n            \nX_imp['age'] = impute_normal_dist(X, 'age')\n\nX_noage = X.drop(labels = 'age', axis = 1)\n\n# X_imp and X_noage have the same number of rows as y, so a new dataframe is unnecessary\nX_list = [X_drop, X_imp, X_noage]\ny_list = [y_drop, y, y]\n\n\n# Create the Random Forest Classifier and a hyperparameter space to search over\nrfc = RandomForestClassifier(random_state = 23)\nrfc_params = {'n_estimators':[10, 50, 100], 'max_depth':[10, 50]}\n\n# Create the K-Nearest Neighbors Classifier and a hyperparameter space to search over\nknn = KNeighborsClassifier()\nknn_params = {'n_neighbors':[1, 3, 5, 10]}\n\n# Create the SGD Classifier and a hyperparameter space to search over\nsgd = SGDClassifier(max_iter=100000, random_state = 23)\nsgd_params = {'loss':['hinge', 'log'], 'penalty':['l2', 'l1'], 'alpha':[0.1, 1, 10, 100]}\n\n# Lists of estimators and parameter spaces\nestimators = [rfc, knn, sgd]\nparams = [rfc_params, knn_params, sgd_params]\n\n# Number of rows and columns in result space\nnum_rows = len(estimators)\nnum_cols = len(X_list)\n\n# Empty lists used to capture information from GridSearches\nbest_scores = [[None]*num_cols]*num_rows\nbest_params = [[None]*num_cols]*num_rows\ntest_scores = [[None]*num_cols]*num_rows\n\n# Loop through each estimator and the associated parameters and create a GridSearchCV\nfor i, (est, param) in enumerate(zip(estimators, params)):\n    cv = GridSearchCV(est, param, cv=10)\n    print(cv)\n    # Loop through the 3 data sets and fit the Grid Search on it, then extract the best performing model for each model and dataset\n    for j, (X, y) in enumerate(zip(X_list, y_list)):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 23)\n        cv.fit(X_train, y_train)\n        print(str(i)+' '+str(cv.best_score_)+' '+str(cv.best_params_)+' '+str(cv.score(X_test, y_test)))\n","152c1787":"X = train_df[['pclass', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'male']]\ny = train_df['survived']\n\n# Get imputed ages\nX_imp = pd.DataFrame.copy(X)\nX_imp['age'] = impute_normal_dist(X, 'age')\n\nrfc = RandomForestClassifier(random_state = 23)\nparams = rfc_params = {'n_estimators':[20, 30, 40, 50, 60, 70], 'max_depth':[2, 4, 6, 8, 10]}\n\nX_train, X_test, y_train, y_test = train_test_split(X_imp, y, test_size = 0.2, random_state = 23)\n\ncv = GridSearchCV(rfc, params, cv=10)\ncv.fit(X_train, y_train)\nprint(str(cv.best_score_)+' '+str(cv.best_params_)+' '+str(cv.score(X_test, y_test)))","d70b31e6":"X_pred = test_df[['pclass', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'sex']]\n\nX_pred = pd.get_dummies(X_pred, columns=['sex'], drop_first=True)\nX_pred.rename(columns={'sex_male':'male'}, inplace=True)\n\nembarked_nums = [0 for i in range(len(X_pred['embarked']))]\nfor i, val in enumerate(X_pred['embarked']):\n    if val == 'C':\n        embarked_nums[i] = 0\n    if val == 'Q':\n        embarked_nums[i] = 1\n    if val == 'S':\n        embarked_nums[i] = 2\nX_pred['embarked'] = embarked_nums\n\nX_pred['fare'].fillna(value=np.nanmedian(X_pred['fare']))\n\nmean = np.mean(train_df['age'])\nstd = np.mean(train_df['age'])\n\nrng = np.random.default_rng(seed = 23)\nmask = X_pred['age'].isna()\nimp = [0 for i in range(len(X_pred['age']))]\nfor i, val in enumerate(X_pred['age']):\n    if mask[i]:\n        imp[i] = np.abs(rng.normal(mean, std))\n    else:\n        imp[i] = val\nX_pred['age'] = imp\n\nX_pred['fare'].fillna(np.nanmedian(X_pred['fare']), inplace=True)\ny_pred = cv.predict(X_pred)\n\n# Size of submission file\npass_id = [i+892 for i in range(418)]\nsurv = [y_pred[i] for i in range(418)]\n    \nsubmission = pd.DataFrame(zip(pass_id, surv), columns = ['PassengerId', 'Survived'])\nsubmission.to_csv('submission.csv', index=False)","b9c0f4b0":"# Exploratory Data Analysis","95514b8c":"Looking at the results of this GridSearch, the highest test score was a random forest classifier on the data that had imputed age information","329633a7":"# Imports and Data Initialization","51c189a6":"## Generating Submission File","e312b652":"## Feature extraction","e9eb98ce":"## Model Testing and Selection","8bccec09":"## Model Refining\n\nHere I will do more in-depth searching using a random forest classifier on data that has imputed age information to find better hyperparameters"}}