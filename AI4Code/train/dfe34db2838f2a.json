{"cell_type":{"6a4111a1":"code","ad75faee":"code","b7370a40":"code","555f3c95":"code","e631db5d":"code","e340e075":"code","a16365c5":"code","26b42d39":"code","f4d7bbcc":"code","3a3d862f":"code","a8ec79ad":"code","39e52942":"code","c61d9ce1":"code","9b2e0e5f":"code","6bde8557":"code","25cfedff":"code","c9b1810f":"code","3c36d9a6":"code","c59a33c2":"code","c3675019":"code","9e1d3902":"code","9d84f059":"code","da6a270d":"code","2bc8ff87":"code","f13f85d5":"markdown","913774ca":"markdown","7e0b804b":"markdown","6eca1278":"markdown","8d9b64b5":"markdown","726c82ce":"markdown","761ef57d":"markdown","485d7f89":"markdown","6a50da22":"markdown"},"source":{"6a4111a1":"import pandas as pd\nimport numpy as np\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nrawData = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')","ad75faee":"print(rawData.head())","b7370a40":"rawData = rawData.drop('Id', axis=1)","555f3c95":"def showInfo(dataframe, code, target):\n    '''\n     *** for making data underestanding  functions in one line code\n\n     :arg = dataframe of data, code, target value for valuse count\n     :return = results data underestanding  of functions based on their code\n\n      '''\n\n    if (int(code) == 1):\n        print(\"data info: \")\n        print(dataframe.info())\n        print(\"_______________________________________________________________________\")\n\n    if (int(code) == 2):\n        print(\"data shape:\")\n        print(dataframe.shape)\n        print(\"_______________________________________________________________________\")\n        print(\"data info: \")\n        print(dataframe.info())\n        print(\"_______________________________________________________________________\")\n\n    if (int(code) == 3):\n        print(\"data shape:\")\n        print(dataframe.shape)\n        print(\"_______________________________________________________________________\")\n        print(\"data info: \")\n        print(dataframe.info())\n        print(\"_______________________________________________________________________\")\n        print(\"data describe:\")\n        print(dataframe.describe())\n        print(\"_______________________________________________________________________\")\n\n    if (int(code == 4)):\n        print(\"data shape:\")\n        print(dataframe.shape)\n        print(\"_______________________________________________________________________\")\n        print(\"data info: \")\n        print(dataframe.info())\n        print(\"_______________________________________________________________________\")\n        print(\"data describe:\")\n        print(dataframe.describe())\n        print(\"_______________________________________________________________________\")\n        print(\"value counts is:\")\n        print(dataframe[str(target)].value_counts())\n\n\n","e631db5d":"print(showInfo(rawData, 4, 'Species'))","e340e075":"def infoDtype(dataFrame):\n\n    '''\n     *** for making a dataframe of the easy EDA\n\n     :arg = dataframe of data\n     :return = dataframe of EDA informations\n     \n      '''\n    cols = dataFrame.columns\n    informationDataframe = pd.DataFrame(index=cols, columns=['data type'])\n    \n    for i in range(len(cols)):\n        informationDataframe.loc[cols[i], 'data type'] = dataFrame.dtypes[i]\n    return informationDataframe","a16365c5":"infoDF = infoDtype(rawData)\nprint(infoDF)","26b42d39":"rawData.hist()\nplt.show()","f4d7bbcc":"def infoNormality(informationDataFrame, dataFrame, alpha=0.05):\n    '''\n      *** for applying 3 normal hypothesis test on columns and returns the normal\n            if 2 hypothesis tests vote  normal\n\n      :arg = dataframe of data, EDA information dataframe , alpha as p_value that is optional\n      :return = dataframe of EDA informations with column shows normality\n\n       '''\n    \n    from scipy.stats import anderson, shapiro, normaltest\n    cols = dataFrame.columns\n\n    for i in range(len(cols)):\n        result = {}\n        if informationDataFrame.loc[cols[i], 'data type'] == 'float64':\n            shapiro_test = shapiro(dataFrame[cols[i]])\n            if round(shapiro_test[1], 3) > alpha:  # pvalue\n                result['shapiro'] = 1\n            else:\n                result['shapiro'] = 0\n\n            normal = normaltest(dataFrame[cols[i]])\n            if round(normal.pvalue, 3) > alpha:  # pvalue\n                result['normal test'] = 1\n            else:\n                result['normal test'] = 0\n            andrson = anderson(dataFrame[cols[i]], dist='norm')\n            sts = round(andrson.statistic, 3)\n            j = 0\n            result['anderson'] = 0\n            while sts < andrson.critical_values[j]:  # normal limit\n                # sl, cv = round(andrson.significance_level[j], 3), round(andrson.critical_values[j], 3)\n                if j == len(andrson.critical_values) - 1:\n                    break\n                else:\n                    j += 1\n                    result['anderson'] = 1\n\n            if sum(result.values()) >= 2:\n                informationDataFrame.loc[cols[i], 'normality_test'] = 'normal'\n            else:\n                informationDataFrame.loc[cols[i], 'normality_test'] = 'not normal'\n        else:\n            informationDataFrame.loc[cols[i], 'normality_test'] = '___'\n\n    return informationDataFrame","3a3d862f":"infoDF = infoNormality(infoDF, rawData, 0.05)\nprint(infoDF)","a8ec79ad":"def correaltionIndex(dataframe, infoDF, alpha=0.6):\n    '''\n      *** for applying 3 correlation hypothesis test on columns and returns the name of correlated columns\n            if 2 hypothesis tests vote  for existing correlation.\n\n      :arg = dataframe of data, EDA information dataframe , alpha as p_value that is optional\n      :return = dataframe of EDA informations with column shows correlated_columns\n\n       '''\n    \n    cols = dataframe.columns\n    correlators = ['pearson', 'spearman', 'kendall']\n    corDict = {}\n\n    for j in correlators:\n        corr_calculated = dataframe.corr(method=j)\n        dictionary = {}\n        for i in cols[:-1]:\n            x = corr_calculated.loc[i].tolist()\n            dictionary[i] = dict(zip(cols[:-1], x))\n            dictionary[i].pop(i)\n        corDict[j] = dictionary\n\n    correlated_dict = []\n    for i in cols[:-1]:\n        cur_dict = []\n        for n in cols[:-1]:\n            if n != i:\n                for j in correlators:\n                    if (abs(corDict[j][i][n]) >= alpha):\n                        cur_dict.append(n)\n                        break\n\n        correlated_dict.append(cur_dict)\n\n    correlated_dict.append([])\n    infoDF['correlated_to'] = correlated_dict\n    return infoDF\n","39e52942":"infoDF = correaltionIndex(rawData, infoDF)\nprint(infoDF)","c61d9ce1":"sns.pairplot(rawData, kind='reg', hue=\"Species\")\nplt.show()","9b2e0e5f":"from pandas.plotting import parallel_coordinates \nplt.figure(figsize=(15,10))\nparallel_coordinates(rawData, 'Species')\nplt.title(\"Parallel Coordinates Plot\", fontsize=20, fontweight='bold' )\nplt.xlabel(\"features\", fontsize=15)\nplt.ylabel(\"values\", fontsize=15)\nplt.legend(loc=1, prop={'size': 10}, frameon=True,shadow=False, facecolor=\"white\", edgecolor=\"black\")\n\n#reference code: https:\/\/www.kaggle.com\/skalskip\/iris-data-visualization-and-knn-classification","6bde8557":"from pandas.plotting import andrews_curves\nplt.figure(figsize=(15,10))\nandrews_curves(rawData, \"Species\")\nplt.title('Andrews Curves Plot', fontsize=20, fontweight='bold')\nplt.legend(loc=1, prop={'size': 15}, frameon=True,shadow=True, facecolor=\"white\", edgecolor=\"black\")\nplt.show()\n\n#reference code: https:\/\/www.kaggle.com\/skalskip\/iris-data-visualization-and-knn-classification","25cfedff":"def delDup(dataframe, mode):\n    mode = str(mode)\n\n    if mode == 'show':\n        dups = dataframe.duplicated(keep='first')\n        if dups.any() == True:\n            print(dataframe[dups])\n        else:\n            print(\"No duplicates found!\")\n    elif mode == 'del':\n        dataframe = dataframe.drop_duplicates()\n        return dataframe\n  \nprint(rawData.shape)\nrawData = delDup(rawData, 'del')\nprint(rawData.shape)","c9b1810f":"def outlierDetector(dataframe, infoDF, mode):\n    '''\n    *** detects if the data distribution is normal or not and apply suitable approach for the column\n        using IQR, and standard deviation.\n    \n    :param dataframe: dataframe of raw datas.\n    :param infoDF: EDA dataframe.\n    :param mode: show or del.\n    :return: dataframe without outliers\n    '''\n\n    columnList = [dataframe.columns[i] for i in range(len(dataframe.columns)) if\n                  infoDF.loc[dataframe.columns[i]]['normality_test'] == 'normal']\n    for i in columnList:\n        meanValue, stdValue = dataframe[i].mean(), dataframe[i].std()\n        lower, upper = (meanValue - (3 * stdValue)), (meanValue + (3 * stdValue))\n        outliers = dataframe[(dataframe[i] < lower) | (dataframe[i] > upper)]\n\n        if outliers.empty:\n            print(\"for Normals: Congratulations ! There is no Outlier!\")\n        elif mode == \"show\":\n                print(outliers)\n        elif mode == \"del\":\n            dropIndex = outliers.index\n            dataframe = dataframe.drop(dropIndex, axis=0)\n\n\n    columnList1 = [dataframe.columns[i] for i in range(len(dataframe.columns)) if\n                   infoDF.loc[dataframe.columns[i]]['normality_test'] == 'not normal']\n    for i in columnList1:\n        q1, q3 = dataframe[i].quantile(0.25), dataframe[i].quantile(0.75)\n        Q = q3 - q1\n        lower, upper = (q1 - (1.5 * Q)), (q3 + (1.5 * Q))\n        outliers1 = dataframe[(dataframe[i] < lower) | (dataframe[i] > upper)]\n\n    if outliers1.empty:\n        print(\"for nonNormals: Congratulations ! There is no Outlier!\")\n    elif mode == \"show\":\n        print(outliers1)\n    elif mode == \"del\":\n        dropIndex = outliers1.index\n        dataframe = dataframe.drop(dropIndex, axis=0)\n    return dataframe\n","3c36d9a6":"rawData = outlierDetector(rawData, infoDF, 'del')\nprint(rawData.shape)","c59a33c2":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n\ntransformer = MinMaxScaler()\ntransformedData = pd.DataFrame(transformer.fit_transform(rawData.loc[:, ~rawData.columns.isin(['Species'])]))\ntransformedData.columns = rawData.columns[~rawData.columns.isin(['Species'])]\n\n\nle = LabelEncoder()\ntransformedData = pd.concat((transformedData, pd.Series(le.fit_transform(rawData.Species))), axis=1, join='inner')\ntransformedData = transformedData.rename(columns={0:'Species'})\n","c3675019":"inputData = rawData[rawData.columns.difference(['Species'])].to_numpy() \ntargetData = rawData[['Species']].to_numpy() ","9e1d3902":"from sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(inputData, targetData, test_size = 0.3, random_state = 0)\nclassifier = KNN(n_neighbors=5)\nclassifier.fit(X_train, y_train.ravel())\ny_pred = classifier.predict(X_test)","9d84f059":"from sklearn.metrics import accuracy_score\n\n# choose best k \nclassifier = KNN(n_neighbors=5)\nk_values = list(range(1,10))\naccuracy_list = []\nfor k in k_values:\n    classifier = KNN(n_neighbors=k)\n    test_predictions = classifier.fit(X_train, y_train.ravel())\n    y_pred = classifier.predict(X_test)\n    accuracy_list.append(accuracy_score(y_test, y_pred))","da6a270d":"plt.figure(figsize=(10,6))\nplt.plot(k_values,accuracy_list,color='blue', linestyle='dashed', marker='o',\n markerfacecolor='red', markersize=10)\nplt.title('accuracy Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('accuracy Rate')\nplt.show()","2bc8ff87":"best_K = accuracy_list.index(max(accuracy_list))+1\nclassifier = KNN(n_neighbors=best_K)\nclassifier.fit(X_train, y_train.ravel())\ny_pred = classifier.predict(X_test)\nprint(\"The accuracy of a model is {}!\".format(accuracy_score(y_test, y_pred)))","f13f85d5":"### `Data Transformation`","913774ca":"# 4_ Modeling\n","7e0b804b":"# 2_ Data Underestanding\n\n## `Univariate Analysis`","6eca1278":"* We know that in KNN, we do not care about the data distribution. but since the KNN is distance base, so it is sensitive to outliers, for dealing with outliers we should know about the data distribution.","8d9b64b5":"### `Dealing With Outliers`","726c82ce":"# 3_ Data Preprocessing\n### `Basic Processing`","761ef57d":"\n#  1_ Setting\n## `import Libraries`\n*****","485d7f89":"## `Bivariate Analysis`","6a50da22":"* As we can see in the histogram plot, we can guess the 'SepalWidthhCm' has normal distribution, for being sure we can use the hypothesis test."}}