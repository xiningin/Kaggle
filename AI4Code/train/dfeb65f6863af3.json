{"cell_type":{"823a2495":"code","e02e9b0b":"code","300433f0":"code","1a792f64":"code","8bc490a7":"code","3f9c6dc1":"code","ca812d7d":"code","f1546822":"code","c57b6a30":"code","817d2030":"code","377e27b8":"code","b257e658":"code","1d6deba7":"code","52e7d6b6":"code","b4574391":"code","33c89886":"code","959a23a4":"code","6e4dceb9":"code","36f0ab13":"code","d0f815f6":"code","29ae5d31":"code","49c1fc7a":"code","3290f52b":"code","d304349e":"code","e3919adf":"markdown","0471e614":"markdown","2919ecfd":"markdown","3aa24434":"markdown","4c95ad54":"markdown","d6758b5f":"markdown","5fd66d06":"markdown","09cce097":"markdown","ba272ca3":"markdown","df29dcdc":"markdown","c68156dc":"markdown","590a90ba":"markdown","25f31c9f":"markdown","974f9067":"markdown","aa7e3519":"markdown","abb91c76":"markdown","f373a6f3":"markdown","11e7d92d":"markdown","5b402372":"markdown","e7afe39b":"markdown","be7ea4d3":"markdown"},"source":{"823a2495":"#Import libraires\n\nimport tensorflow as tf\n#tf.__version__\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# display all dataframe columns & rows\npd.options.display.max_columns = None\npd.options.display.max_rows = None\n\n# to set the limit to 3 decimals\npd.options.display.float_format = '{:.7f}'.format\n","e02e9b0b":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntrain.head()","300433f0":"test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest.head()","1a792f64":"train.describe()","8bc490a7":"plt.figure(figsize=(10,7))\nsns.countplot(train['label'])\nplt.tight_layout(); #for better visualization","3f9c6dc1":"sns.set_style(\"darkgrid\")\nplt.figure(figsize=(12,6))\n#distribution plot\nsns.distplot(train['label'], axlabel=\"Labels\", color='red')","ca812d7d":"# Extract features\nfeatures = train.drop('label', axis=1)\n\n# Extract label\ny_train = train['label']\n\n# Train images\nX_ = np.array(features)\nX_train = X_.reshape(X_.shape[0], 28, 28)\n\n# Test images\nX_test = np.array(test)","f1546822":"plt.imshow(X_train[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()","c57b6a30":"fig = plt.figure(figsize=(10,5))\n\nfor i in range(16):\n  fig.add_subplot(4,4, i+1)\n  plt.xticks([])\n  plt.yticks([])\n  plt.imshow(X_train[i], cmap='gray')\n  plt.xlabel('Digit: ' + str(y_train[i]))\n  plt.tight_layout(); # to see clear graph\nplt.show();\n","817d2030":"X_train.shape, X_test.shape","377e27b8":"X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)","b257e658":"# lets check the shape again\nX_train.shape, X_test.shape","1d6deba7":"X_train.min(), X_train.max()","52e7d6b6":"X_test.min(), X_train.max()","b4574391":"X_train = X_train\/255.\nX_test = X_test\/255.","33c89886":"X_train.min(), X_train.max()","959a23a4":"# 1. Create the model\n\nmodel = tf.keras.Sequential([\n                             tf.keras.layers.Flatten(input_shape=(28,28)),\n                             tf.keras.layers.Dense(128, activation=\"relu\"),\n                             tf.keras.layers.Dense(10) #10 is the number of classes\n])\n\n#2 Compile the model\n\nmodel.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=[\"accuracy\"])\n\n# 3. Fit the model\n\nhistory = model.fit(X_train, y_train, epochs=50)\n","6e4dceb9":"#ploting the loss and accuracy graph\n\npd.DataFrame(history.history).plot(figsize=(12,7))","36f0ab13":"predictions = np.argmax(model.predict(X_test), axis=1)","d0f815f6":"predictions","29ae5d31":"submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission.head()","49c1fc7a":"submission.shape","3290f52b":"submission['Label']  = predictions","d304349e":"submission.to_csv('submission.csv',index=False)\nsubmission.head()","e3919adf":"**Accuracy & Loss plot:**","0471e614":"Now its time to scale, normalize in other words, our data. \n> To do so we need to divide the train and test dataset with pixel-value as an integer between 0 and 255, inclusive. (In simple words dividing with maximum number to bring them in a format of 0 and 1)","2919ecfd":"## 4. Creating a machine learning model","3aa24434":"## 5: Predictions","4c95ad54":"The from_logits=True attribute inform the loss function that the output values generated by the model are not normalized, a.k.a. logits. In other words, the softmax function has not been applied on them to produce a probability distribution.","d6758b5f":"The MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. ","5fd66d06":"To see the image associated with the index number use ``imshow()``,  with   ``X_train[]``","09cce097":"##2. Preparing the data","ba272ca3":"## 3. Exploratory Data Analysis & Preprocessing","df29dcdc":"Steps in Creating a Data Science Project\n\n* Defining the project\n* Preparing the data\n* Exploratory Data Analysis & Preprocessing\n* Creating a machine learning model\n* Predictions\n* Presenting your findings","c68156dc":"Making a submission file for competition.","590a90ba":"Check the ``min()`` , ``max()`` of data to confirm it is now normalized. ","25f31c9f":"History variable here will be used in the next step to plot a graph of loss and accuracy parameter to see where trend is heading to.","974f9067":"Let's extract the features for train and test to be used while modeling","aa7e3519":"Since we are working on a binary classification problem, So lets create our neural network with tensorflow. Steps in Modeling to classify whether a circle is (Blue or Red)\nThe steps in modeling with Tensorflow are typically:\n\n* Create or import a model\n* Compile a model\n* Fit the model\n* Evaluate the model\n* Tweak\n* Evaluate.","abb91c76":"To verify that the data is in the correct format and that you're ready to build and train the network, let's display the first 16 images from the training set.","f373a6f3":"## 1. Defining the project\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\nIn this problem, our goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.","11e7d92d":"Check the shape of train and test set.","5b402372":"> The first layer in this network, tf.keras.layers.Flatten, transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.","e7afe39b":"Shape has 28000 rows of data, and 2 columns ``ImageId`` , ``Label``","be7ea4d3":"Our data is not in the same shape so here there is a need to reshape our train and test data respectively. \nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels. (28*28 = 784)"}}