{"cell_type":{"dba14272":"code","94ab2614":"code","2c3f4f7d":"code","b6473a00":"code","e02551df":"code","32873d76":"code","fd90c071":"code","6d87396f":"code","68363e15":"code","b4e5c0a9":"code","9b21a05b":"code","5d58421b":"code","cd43087f":"code","2e45dcd4":"code","4bf5fbda":"code","bacec75a":"code","2843c0de":"code","24cfb213":"code","604ac7d5":"code","60dbee46":"code","b138d12b":"code","0462aaf9":"code","1d2ffa38":"code","a7b9a43f":"code","94e560e4":"code","2659a3f2":"code","13026d9a":"code","3c09acdf":"code","5e1652cb":"code","c0b2bc33":"code","c599cddf":"code","9fdc429a":"code","99f00461":"code","aa2b24ce":"code","aca2089d":"code","bb96f395":"code","430639f1":"code","86e2464b":"code","b5ffad92":"code","a5880626":"code","d3f51538":"code","1643a888":"code","2aaeb961":"code","5d896e23":"code","8efedf60":"code","384d8880":"code","e3839f4f":"code","dacb5b03":"code","39b251ee":"code","10714303":"code","71463200":"code","41cf0e60":"code","5d4507bd":"code","9679f545":"code","f9fef6f6":"code","be6ad561":"code","a12abb23":"code","72f199e8":"code","af14b067":"code","0f645715":"code","92458db7":"code","7ab1a2b7":"code","c9a2aca9":"code","246c431a":"code","d305d05d":"code","3d34b9eb":"code","85532725":"code","57bf4aa5":"code","e6c32fad":"code","d2a11ad0":"code","993c86dc":"code","b78cce11":"code","a064a1a4":"code","78d7218e":"code","43a1693c":"code","bd3c31cb":"code","6dd69c0e":"code","cb1e9fd9":"code","9f84f718":"code","3c00e2cb":"code","e36696eb":"code","da10e01c":"code","d17786a8":"code","1bbc3fc1":"code","383121df":"code","48fb0beb":"code","69485dd2":"code","834ee5cf":"code","df120896":"code","f9bc1d93":"code","4ff14036":"code","a3660ea3":"markdown","89d79545":"markdown","6fd631a9":"markdown","594d9825":"markdown","4d85d2ab":"markdown","c4e9ff9b":"markdown","91b07c7b":"markdown","15d7da70":"markdown","e685d875":"markdown","f67583ee":"markdown","03f62c87":"markdown","de8b23d7":"markdown","dc463279":"markdown","4a45ee1b":"markdown","012a6cac":"markdown","89e4771f":"markdown","66de0af7":"markdown","fad0a9db":"markdown","47b6c699":"markdown","2ca815dc":"markdown","3444dd7d":"markdown","05044b8f":"markdown","f76e64ef":"markdown","a0508693":"markdown","8660b931":"markdown","34de2dbc":"markdown","5ce838b0":"markdown","81be4d2a":"markdown","fc7ecfa9":"markdown","836e3a72":"markdown","53f2820d":"markdown","eeafe73e":"markdown","5cacc006":"markdown","8d2bc39a":"markdown","6470a7df":"markdown","36a8cf22":"markdown","a9d52ccc":"markdown","ec442131":"markdown","ee8b8142":"markdown","b8917441":"markdown","d80e5654":"markdown","c9060c03":"markdown","7a5b607f":"markdown","84c1a2f4":"markdown","8988a558":"markdown","b36d5352":"markdown","d36742d7":"markdown","e8980307":"markdown","938cece4":"markdown","fc4512bd":"markdown"},"source":{"dba14272":"import os\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","94ab2614":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","2c3f4f7d":"#Reading Data\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')","b6473a00":"train_df.head()","e02551df":"test_df.head()","32873d76":"def plot_missing_data(dataset, title):\n    fig, ax = plt.subplots(figsize=(5,5))\n    plt.title(title)  \n    sns.heatmap(dataset.isnull(), cbar=False)","fd90c071":"train_df.info()","6d87396f":"plot_missing_data(train_df, \"Training Dataset\")","68363e15":"test_df.info()","b4e5c0a9":"plot_missing_data(test_df, \"Test Dataset\")","9b21a05b":"def bar_chart_stacked(dataset, feature, stacked = True):\n    survived = dataset[dataset['Survived']==1][feature].value_counts()\n    dead = dataset[dataset['Survived']==0][feature].value_counts()\n    df_survived_dead = pd.DataFrame([survived,dead])\n    df_survived_dead.index = ['Passengers Survived','Passengers Died']\n    ax = df_survived_dead.plot(kind='bar',stacked=stacked, figsize=(5,5))","5d58421b":"train_df['Survived'].value_counts()","cd43087f":"train_df['Survived'].value_counts(normalize=True)","2e45dcd4":"bar_chart_stacked(train_df, \"Survived\")","4bf5fbda":"train_df['Sex'].value_counts().to_frame()","bacec75a":"bar_chart_stacked(train_df, \"Sex\")","2843c0de":"train_df.groupby('Sex').Survived.mean()","24cfb213":"bar_chart_stacked(train_df, 'Pclass')","604ac7d5":"pd.pivot_table(train_df, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count')","60dbee46":"train_df.groupby(['Pclass']).Survived.mean().to_frame()","b138d12b":"def bar_chart_compare(dataset, feature1, feature2=None, title = \"Survival rate by sex and class'\"):\n    plt.figure(figsize = [5,5])\n    plt.title(title)\n    g = sns.barplot(x=feature1, y='Survived', hue=feature2, ci=None, data=dataset).set_ylabel('Survival rate')","0462aaf9":"bar_chart_compare(train_df, \"Pclass\", \"Sex\")","1d2ffa38":"pd.pivot_table(train_df, index = 'Survived', columns = ['Pclass', \"Sex\"], values = 'Ticket' ,aggfunc ='count')","a7b9a43f":"train_df.groupby(['Pclass', \"Sex\"]).Survived.mean().to_frame()","94e560e4":"def plot_distribution(dataset, feature, title, bins = 30, hist = True, fsize = (5,5)):\n    fig, ax = plt.subplots(figsize=fsize)\n    ax.set_title(title)\n    sns.distplot(train_df[feature], color='g', bins=bins, ax=ax)","2659a3f2":"def plot_kernel_density_estimate_survivors(dataset, feature1, title, fsize = (5,5)):\n    fig, ax = plt.subplots(figsize=fsize)\n    ax.set_title(title) \n    sns.kdeplot(dataset[feature1].loc[train_df[\"Survived\"] == 1],\n                shade= True, ax=ax, label='Survived').set_xlabel(feature1)\n    sns.kdeplot(dataset[feature1].loc[train_df[\"Survived\"] == 0],\n                shade=True, ax=ax, label=\"Died\")","13026d9a":"plot_distribution(train_df, \"Age\", \"Age Distribution Passengers\")","3c09acdf":"plot_kernel_density_estimate_survivors(train_df, \"Age\", \"Age Distribution Surived vs Died\")","5e1652cb":"def plot_swarm_survivors(dataset, feature1, feature2, title, fize = (155)):\n    fig, ax = plt.subplots(figsize=(18,5))\n    # Turns off grid on the left Axis.\n    ax.grid(True)\n    plt.xticks(list(range(0,100,2)))\n    sns.swarmplot(y=feature1, x=feature2, hue='Survived',data=train_df).set_title(title)","c0b2bc33":"plot_swarm_survivors(train_df, \"Sex\", \"Age\", \"Survivor Swarmplot for Age and Gender\")","c599cddf":"plot_swarm_survivors(train_df, \"Age\", \"Pclass\", \"Survivor Swarmplot for Age and Gender\")","9fdc429a":"train_df.Fare.describe()","99f00461":"plot_distribution(train_df, \"Fare\", \"Fare Distribution Passengers\")","aa2b24ce":"def plot_quartiles(dataset, feature, title, categories):\n    fig, axarr = plt.subplots(figsize=(5,5))\n    fare_ranges = pd.qcut(dataset[feature], len(categories), labels = categories) #. [0, .25, .5, .75, 1.]\n    axarr.set_title(title)\n    sns.barplot(x=fare_ranges, y=dataset.Survived, ci=None, ax=axarr).set_ylabel('Survival rate')","aca2089d":"categories = ['Cheap', 'Standard', 'Expensive', 'Luxury']\n\nplot_quartiles(train_df, \"Fare\", \"Survival Rate by Fare Ranges\/Categories\", categories)","bb96f395":"plot_swarm_survivors(train_df, \"Fare\", \"Sex\",\"Survivor Swarmplot for Age and Gender\")","430639f1":"train_df.loc[train_df.Fare==0] ","86e2464b":"len(train_df.loc[train_df.Fare==0])","b5ffad92":"# Replace Fare == 0 with nan\ntrain_df.loc[train_df['Fare'] == 0, 'Fare'] = np.NaN\ntest_df.loc[train_df['Fare'] == 0, 'Fare'] = np.NaN","a5880626":"def show_countplot(dataset, feature, title, fsize = (5,5)):\n    fig, ax = plt.subplots(figsize=fsize)\n    sns.countplot(dataset[feature], ax=ax).set_title(title)\n    \ndef show_compare_countplot(dataset, feature1, feature2, title):\n    fig, ax = plt.subplots(figsize=(5,5))\n    p = sns.countplot(x = feature1, hue = feature2, data = dataset, ax=ax).set_title(title)   ","d3f51538":"bar_chart_stacked(train_df, 'Embarked') ","1643a888":"show_countplot(train_df, \"Embarked\", 'Passengers count by boarding point')","2aaeb961":"train_df['Embarked'].value_counts().to_frame()","5d896e23":"show_compare_countplot(train_df, \"Embarked\", \"Survived\", \"Survivor count by place of embarktion\")","8efedf60":"pd.pivot_table(train_df, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count')","384d8880":"train_df.groupby(['Embarked']).Survived.mean().to_frame()","e3839f4f":"show_compare_countplot(train_df, \"Embarked\", \"Pclass\", \"Passenger count by place of embarktion and class\")","dacb5b03":"train_df.groupby(['Embarked', 'Pclass']).Survived.sum().to_frame()","39b251ee":"show_compare_countplot(train_df, \"Embarked\", \"Sex\", \"Passenger count by place of embarktion and sex\")","10714303":"train_df['SibSp'].value_counts().to_frame()","71463200":"bar_chart_compare(train_df, \"SibSp\", title = \"Surival rate by siblings \/ spouses aboard the Titanic\")","41cf0e60":"train_df.groupby(['SibSp']).Survived.mean().to_frame()","5d4507bd":"show_countplot(train_df, \"SibSp\", 'SibSp Distribution', (15,3))","9679f545":"show_compare_countplot(train_df, \"SibSp\", \"Survived\", \"Survivor count by number of siblings \/ spouses aboard the Titanic\")","f9fef6f6":"show_countplot(train_df, \"Parch\", 'Parch Distribution', (15,3))","be6ad561":"bar_chart_compare(train_df, \"Parch\", title = \"Survival rate by Parch\")","a12abb23":"train_df.groupby(['Parch']).Survived.mean().to_frame()","72f199e8":"show_compare_countplot(train_df, \"Parch\", \"Survived\", \"Survivor count by Parch\")","af14b067":"pd.unique(train_df['Name'])","0f645715":"train_df['Title'] = train_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntest_df['Title'] = test_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())","92458db7":"train_df.head()","7ab1a2b7":"train_df['Title'].value_counts().to_frame()","c9a2aca9":"show_countplot(train_df, \"Title\", 'Title Distribution', (15,3))","246c431a":"train_df['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntest_df['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntrain_df['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\ntest_df['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)","d305d05d":"show_countplot(train_df, \"Title\", 'Title Distribution after substitution', (15,3))","3d34b9eb":"bar_chart_stacked(train_df, 'Title') ","85532725":"bar_chart_compare(train_df, \"Title\", title = \"Survival rate by Title\")","57bf4aa5":"train_df[['Cabin', 'Ticket']]","e6c32fad":"# Extract Leading Letter:\ntrain_df['Ticket_2letter'] = train_df.Ticket.apply(lambda x: x[:2])\ntest_df['Ticket_2letter'] = test_df.Ticket.apply(lambda x: x[:2])","d2a11ad0":"# Extract Ticket Lenght:\ntrain_df['Ticket_len'] = train_df.Ticket.apply(lambda x: len(x))\ntest_df['Ticket_len'] = test_df.Ticket.apply(lambda x: len(x))","993c86dc":"# Extract Number of Cabins:\ntrain_df['Cabin_num'] = train_df.Ticket.apply(lambda x: len(x.split()))\ntest_df['Cabin_num'] = test_df.Ticket.apply(lambda x: len(x.split()))","b78cce11":"# Extract Leading Letter:\ntrain_df['Cabin_1letter'] = train_df.Ticket.apply(lambda x: x[:1])\ntest_df['Cabin_1letter'] = test_df.Ticket.apply(lambda x: x[:1])","a064a1a4":"len(train_df['Ticket'].value_counts().to_frame())","78d7218e":"len(train_df[\"Ticket_2letter\"].value_counts().to_frame())","43a1693c":"len(train_df[\"Ticket_len\"].value_counts().to_frame())","bd3c31cb":"train_df.head()","6dd69c0e":"len(train_df['Cabin'].value_counts().to_frame())","cb1e9fd9":"len(train_df['Cabin_num'].value_counts().to_frame())","9f84f718":"train_df['Cabin_num'].value_counts().to_frame()","3c00e2cb":"len(train_df['Cabin_1letter'].value_counts().to_frame())","e36696eb":"train_df['Fam_size'] = train_df['SibSp'] + train_df['Parch'] + 1\ntest_df['Fam_size'] = test_df['SibSp'] + test_df['Parch'] + 1","da10e01c":"bar_chart_compare(train_df, \"Fam_size\", title = \"Survival rate by family size\")","d17786a8":"show_compare_countplot(train_df, \"Fam_size\", \"Survived\", \"Survivor count by family size\")","1bbc3fc1":"# Creation of four groups\ntrain_df['Fam_type'] = pd.cut(train_df.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\ntest_df['Fam_type'] = pd.cut(test_df.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])","383121df":"bar_chart_compare(train_df, \"Fam_type\", title = \"Surival rate by family type\")","48fb0beb":"show_compare_countplot(train_df, \"Fam_type\", \"Survived\", \"Survivor count by family type\")","69485dd2":"y = train_df['Survived']\nfeatures = ['Pclass', 'Fare', 'Title', 'Embarked', 'Fam_type', 'Ticket_len', 'Ticket_2letter']\nX = train_df[features]\nX.head()","834ee5cf":"numerical_cols = ['Fare']\ncategorical_cols = ['Pclass', 'Title', 'Embarked', 'Fam_type', 'Ticket_len', 'Ticket_2letter']\n\n# Inputing numerical values with median\nnumerical_transformer = SimpleImputer(strategy='median')\n\n# Inputing missing values with most frequent one for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Bundle preprocessing and modeling code \ntitanic_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestClassifier(random_state=0, n_estimators=500, max_depth=5))\n])\n\n# Training\ntitanic_pipeline.fit(X,y)\n\nprint('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, y, cv=10).mean()))","df120896":"X_test = test_df[features]\nX_test.head()","f9bc1d93":"predictions = titanic_pipeline.predict(X_test)","4ff14036":"output = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint('Your submission was successfully saved!')","a3660ea3":"#### Observarion:\nThe majority traveled alone.\nIt seems that the more Sibling a passenger has the less chance of survival there is.","89d79545":"## 2.12 Analyze Feature SibSp:\nSibSp is the number of siblings or spouses of a person aboard the Titanic","6fd631a9":"#### Observation:\nOnce more we can see the importance of Pclass when it comes to predicting the likelihood of survival.\nOne additional piece of information from the plot above is that the first-class did not have a lot of children.\nMaybe rich people get fewer kids?","594d9825":"# 4. Training a classifier\n\n- We start by selecting the features we will use and isolating the target.\n- We will not consider Cabin and in the end, we also excluded Age as the relevant information which is being a young man is encoded in the Master title.\n- We also did not use Sex as it is not useful given the Title column:<br> \n  adult males and young children have the same sex but are different categories as we saw before, so we don't want to confuse our algorithm.\n","4d85d2ab":"#### Investigate Results:\nCabin:","c4e9ff9b":"#### 1. Let's try to understand how many people survived overall:","91b07c7b":"##2.9 Analyze Feature Embarked","15d7da70":"# 2. Exploratory data analysis","e685d875":"## 3.1 Feature Name:","f67583ee":"##2.2 Analyze Feature Survived:","03f62c87":"## 2.8 Analyze Feature Fare:","de8b23d7":"#### Observation:\nHere, some important observations can be made:\n- Irrespective of gender all passengers with a fare above 500$ survived.\n\n- All male passenger that paid between 200-300$ died\n\n- All female passenger that paid between 200-300$ died\n\nThis could be a feature a classifier might pick up.\n\nOne thing that caught my attention is that the minimum fare paid was 0.0 $.\n\nThis seems highly unlikely. We can investigate who these people were:","dc463279":"#### Observation:\nAs can see the Titles are severely imbalanced. In makes sense ti group less frequent Titles together.\nI will substitute male titles into Mr and female Titles into Mr:","4a45ee1b":"#### Observation:\ntodo","012a6cac":"## 2.1 Check missing values","89e4771f":"#### Observation:\n15 Passengers paid no fare. As this is nonsensical I decide to replace 0 values with nan and then later to think about how to impute these values.","66de0af7":"#### Display train data","fad0a9db":"#### Observation:\nFrom the plots and tables above it becomes clear that the Pclass is an important factor to consider.\n\n- Most passenger had class 3 tickets, yet only 24% of class 3 passengers survived.\n- Almost 63% of the passenger from class 1 survived. \n- Also approx 50% of the class 2 passenger survived.\n\nOne questions that comes into mind is:\n\nIs the class or sex the deciding factor?","47b6c699":"#### Observation:\nFare does not follow a normal distribution and has a huge spike at the price range [0-100$].\n\nThe distribution is skewed to the left with 75% of the fare paid under 31% and a max paid fare of 512$.\nDepending on the model that I'm going to use it might make sense to normalize this feature. However, this aspect will be tackled later in the feature engineering section.\n\nTo better understand how this feature influences the survival rate, we could plot bar plots of Fare vs Survived. However, due to the large range of fares such as plot would not be useful for inferring useful information. \n\nA more suited visualization would be to combine fares into categories and then plot the \ncategories vs Survived. ","2ca815dc":"## 2.4 Analyze Feature Pclass:","3444dd7d":"##  2.12 Analyze Feature Parch\n\nSimilar to the SibSp column, this feature contains the number of parents or children each passenger was traveling with.\n\nHere we draw the same conclusions as SibSp; we see again that small families had more chances to survive than bigger ones and passengers who traveled alone.\n","05044b8f":"## 3.3 Feature Family Size\nBoth features do not seem to be very informative, however, higher abstraction levels trees might pick up certain groups. For faster training, it might be beneficial to combine both features into 1 and create a family size feature.","f76e64ef":"#### Observation:\nThere are three possible values for the Embarked Feature: \n- Southampton, Cherbourg, and Queenstown.\n\nWe can see that the majority of passengers embarked from Southampton.\nHowever, only 33% survived the sinking of the titanic.\n\nThe highest survival rate of 55% is in the group of passengers that embarked from Cherbourg\n\nUsing common sense I would not expect that the place of border changes the likelihood of survival.\n\nWhy is the likelihood of survival higher at Cherbourg?\nAs we know from above a better class increases the survival rate drastically.\nOne indicator may be the percentage of 1. Class passengers that embarked at Cherbourg:","a0508693":"#### Observation:\nAs expected the majority of passengers in the training data died. \nOnly 38% survived the disaster. So the training data suffers from data imbalance but it is not severe which is why I will not cosider techniques like sampling to tackle the imbalance.","8660b931":"# Hint\nYou can find a more detailed explanations in my Medium article:\n\nhttps:\/\/anelmusic13.medium.com\/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1","34de2dbc":"#### Observation:\nHere, we can clearly see that the question was justified. Irrespective of the class the most important factor when it comes to surviving was gender. (At least between Sex and Pclass)\nHowever, men in class 1 had a significantly higher chance of survival when they bought class 1 tickets.\nThis just shows to say that we should keep both features as both yield insightful information that should help our model.\n- Survival Rate females 1. Class: 96,8%\n- Survival Rate females 2. Class: 92,1%\n- Survival Rate females 3. Class: 50% \n\n- Survival Rate male 1. Class: 36.8%\n  <br>(still significantly lower than 3. class females)\n    \n\n","5ce838b0":"#### Observation:\nAs we can see both features are not easy to deal with. Cabin contains a lot of Nans and the ticket seems not to provide any useful information.\n\nWe can try different ideas:\n- Extract two leading letters to create a new feature\n- Extract number of letter in ticket to create a new features\n- Extract number of cabins used\n- Extract Cabin letter","81be4d2a":"## 2.5 Analyze Feature Age:","fc7ecfa9":"## 2.10 Analyze Features Embarked & Pclass together","836e3a72":"#### Display test data","53f2820d":"#### Observation:\nAs we can see the likelihood of survival is definitely influenced by the price paid. \n- Cheap (0-25% of max Price): Surival Rate = 0.2 (aprox)\n- Cheap (25%-50% of max Price): Surival Rate = 0.3 (aprox)\n- Cheap (50%-75% of max Price): Surival Rate = 0.45 (aprox)\n- Cheap (75%-100% of max Price): Surival Rate = 0.55 (aprox)\n\nAdditionally, we can investigate the relationship between fare, sex and survived to further understand the importance of the feature.","eeafe73e":"##2.3 Analyze Feature Sex:","5cacc006":"## 2.11 Analyze Features Embarked & Sex together","8d2bc39a":"# 3. Feature engineering","6470a7df":"#### Observation:\nThe hypothesis seems to be correct. \n- The majority embarked at Cherbourg were 1. class passengers.\n- The majority embarked at Southampton were 3. class passengers.\n\nHowever, it does not explain why the survival rate at Queenstown is slightly higher than at Southampton even though the number of 1. class passenger concerning 3. class passengers is higher at Southampton.\n\nOne hypothesis is that maybe the ratio between male and female passengers differs:","36a8cf22":"## 3.2 Cabin and Ticket","a9d52ccc":"#### Observation:\nAs expected twice as many male passengers embarked from Southam were roughly the same number of male and female passengers embarked from Queenstown. This just shows the importance of the Sex feature.","ec442131":"#### Observation:\nAs the majority of passenger were we could infer that the majority of survivors were men.\n\nWe can check this assumption by looking at the bar chart below:","ee8b8142":"#### Observation:\n- As expected female Titles result in a higher survival rate.\n- Master and Dr are slightly have a surprisingly high survival rate even tough both are male titles\n- Being \"just\" a Mr comes with a compromised survival rate of approx 15%\n- It is interesting that all 6 Revernands died. Maybe they decided to accept their destiny and wanted to die with dignity ","b8917441":"## 3.4 Feature Family Type\nTo further summarize the previous trend, as our final feature, Let's create four groups for family size","d80e5654":"#### Observation:\nFrom the blots above we can see that both training as well as test dataset contain features with missing values. However, the most sparse features are Age as well as Cabin.\n\nAs we do not know the how mich information the features yield, further investigation is needed.","c9060c03":"#### Observation\nTo create a new feature we can extract the Titles from the name.","7a5b607f":"#### Observation:\nSimilar to the SibSp column, this feature contains the number of parents or children each passenger was traveling with.\nHere we draw the same conclusions as SibSp; we see again that small families had more chances to survive than bigger ones and passengers who traveled alone.\n\nBoth features do not seem to be very informative, however, higher abstraction levels trees might pick up certain groups.\nFor faster training, it might be beneficial to combine both features into 1 and create a family size feature.","84c1a2f4":"## 2.7 Analyze Features Age and Pclass together","8988a558":"#### Observation:\nHere, we can see the even though the majority of the passenger were male, the majority of survivors were female. The key observation here is that the survival rate for female passengers is 4 times higher than the survival rate of male passengers.   ","b36d5352":"## 2.6 Analyze FeatureFeature Age & Sex together:","d36742d7":"# 1. Loading the dataset:","e8980307":"#### Observation:\nAs expected age holds valuable information. The swarm plot above shows that a big portion of male survivors are passengers between 0 and 12 years of age.\nIt's also interesting to see that the oldest passenger 80 year old man survived.","938cece4":"#### Observation:\nThe Histogram above shows that age follows a fairly normal distribution.\n\nAlso investigating the kernel density estimate does not provide additional information except a raise in survivors at a very young age.\nHowever, one idea might be to investigate age and sex together.","fc4512bd":"#### Investigate Results:\nTicket:"}}