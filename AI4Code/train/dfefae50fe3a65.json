{"cell_type":{"2fcdc424":"code","47266773":"code","c29edcd7":"code","939f1bde":"code","9a54a0de":"code","5c318251":"code","203f0f6c":"code","3ac92f5a":"code","bef3ce22":"code","48debe31":"code","63630520":"code","332ff66c":"code","279eff8a":"code","db12f00c":"code","d59d89b7":"code","78612d0f":"code","ed34c630":"code","6eb6b235":"code","79136c1f":"code","88cb0f70":"code","249c8078":"code","506eb221":"markdown","65c8ca9b":"markdown","e94ac0f0":"markdown","8967b052":"markdown","f08a3eb0":"markdown","73dbaf46":"markdown","07c88f39":"markdown","b9cd673d":"markdown","b580d7b3":"markdown","589e329e":"markdown","b9bef49b":"markdown","f60fbfd9":"markdown","af05db80":"markdown","8a43747e":"markdown"},"source":{"2fcdc424":"import pandas as pd \nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","47266773":"df = pd.read_csv('..\/input\/ccdata\/CC GENERAL.csv')","c29edcd7":"df.head()","939f1bde":"df.describe()","9a54a0de":"df.shape","5c318251":"df.info()","203f0f6c":"df.nunique()","3ac92f5a":"df.pop('CUST_ID')","bef3ce22":"df.isnull().sum()","48debe31":"x = df.iloc[:,:].values\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(x[:, -5:-2])\nx[:, -5:-2] = imputer.transform(x[:, -5:-2])\ndf = pd.DataFrame(x , columns = df.columns)\ndf.isnull().sum()","63630520":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndf = pd.DataFrame(sc.fit_transform(df.iloc[:,:].values) , columns = df.columns)\ndf","332ff66c":"corelation_matrix = df.corr()\n\nplt.figure(figsize=(15,15))\n\nsns.heatmap(corelation_matrix , xticklabels = corelation_matrix.columns \n            , yticklabels = corelation_matrix.columns , annot = True,cmap='Spectral', fmt='.2f' )","279eff8a":"plt.figure(figsize=(12,55))\nfor ii, columnName in enumerate(df.columns): \n    plt.subplot(len(df.columns), 1, ii+1)\n    plt.hist(df[columnName], alpha=.4, bins=30)\n    plt.title(columnName)\n    \nplt.tight_layout()","db12f00c":"from sklearn.neighbors import NearestNeighbors\nfrom sklearn.cluster import DBSCAN\nfrom math import ceil , log\n\nX = df.iloc[:,:].values\nnbrs = NearestNeighbors(n_neighbors=len(X)).fit(X)\ndistances, indices = nbrs.kneighbors(X)\n\ndbscan = DBSCAN(eps=ceil(distances.mean()),min_samples=ceil(log(df.shape[1])))\ndbscan.fit(X)","d59d89b7":"from sklearn.metrics import silhouette_score , davies_bouldin_score\nprint('silhouette_score:', silhouette_score(X,dbscan.labels_))\nprint('davies_bouldin_score:', davies_bouldin_score(X,dbscan.labels_))","78612d0f":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, df.shape[1]):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, df.shape[1]), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","ed34c630":"kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)","6eb6b235":"print('silhouette_score:', silhouette_score(x,kmeans.labels_))\nprint('davies_bouldin_score:', davies_bouldin_score(x,kmeans.labels_))","79136c1f":"import scipy.cluster.hierarchy as sch\nplt.figure(figsize=(35,35))\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\nplt.show()","88cb0f70":"from sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 4, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)","249c8078":"print('silhouette_score:', silhouette_score(X,hc.labels_))\nprint('davies_bouldin_score:', davies_bouldin_score(X,hc.labels_))","506eb221":"![Credit Card](https:\/\/milesopedia.com\/wp-content\/uploads\/2019\/08\/featured-les-meilleures-cartes-de-credit.jpg)","65c8ca9b":"> 4.2 Kmean++","e94ac0f0":">2.3.feature scalling","8967b052":"> 4.1 DBSCAN","f08a3eb0":"> 2.2.Taking Care Of Missing Data","73dbaf46":"\n> 2.1.Delete Some Columns","07c88f39":"**3.Analysis Of Relationship**","b9cd673d":" **2.Data Perprocessing and feature selection**","b580d7b3":"# **1.2.Feature Details**\n\n\n(I copy this information from [this](https:\/\/www.kaggle.com\/arjunbhasin2013\/ccdata))\n\n\n>1.**CUSTID** : Identification of Credit Card holder (Categorical)\n\n\n>2.**BALANCE** : Balance amount left in their account to make purchases \n\n\n>3.**BALANCEFREQUENCY** : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n\n\n>4.**PURCHASES** : Amount of purchases made from account\n\n\n>5.**ONEOFFPURCHASES** : Maximum purchase amount done in one-go\n\n\n>6.**INSTALLMENTSPURCHASES** : Amount of purchase done in installment\n\n\n>7.**CASHADVANCE** : Cash in advance given by the user\n\n\n>8.**PURCHASESFREQUENCY** : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n\n\n>9.**ONEOFFPURCHASESFREQUENCY** : How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n\n\n>10.**PURCHASESINSTALLMENTSFREQUENCY** : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n\n\n>11.**CASHADVANCEFREQUENCY** : How frequently the cash in advance being paid\n\n\n>12.**CASHADVANCETRX** : Number of Transactions made with \"Cash in Advanced\"\n\n\n>13.**PURCHASESTRX** : Numbe of purchase transactions made\n\n\n>14.**CREDITLIMIT** : Limit of Credit Card for user\n\n\n>15.**PAYMENTS** : Amount of Payment done by user\n\n\n>16.**MINIMUM_PAYMENTS** : Minimum amount of payments made by user\n\n\n>17.**PRCFULLPAYMENT** : Percent of full payment paid by user\n\n\n>18.**TENURE** : Tenure of credit card service for user","589e329e":"\n# **STEPS:** \n\n 1.Understanding Dataset1.Understanding Dataset\n\n 2.Data Perprocessing\n\n > 2.1.Delete Some Columns\n\n>2.2.Taking Care Of Missing Data\n\n>2.3.feature scalling\n\n3.Analysis Of Relationship\n\n4.Create Model\n","b9bef49b":"\n**4.Create Model**","f60fbfd9":"4.3.HC","af05db80":"I think best model is DBSCAN , but after training this ,this model I create Kmean++ and hc","8a43747e":"**1.Understanding Dataset**"}}