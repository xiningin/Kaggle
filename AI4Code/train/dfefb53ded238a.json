{"cell_type":{"4bd1ae08":"code","c08e8241":"code","7ff049bd":"code","015e9895":"code","05411de2":"code","d7538247":"code","63e4d031":"code","67147eee":"markdown","d04c234e":"markdown","95d91702":"markdown","4a0a980c":"markdown","a7391195":"markdown","a108c5d9":"markdown"},"source":{"4bd1ae08":"import warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter(action='ignore', category=FutureWarning)","c08e8241":"import sys\nsys.path.append('..\/input\/iter-strat')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'","7ff049bd":"x_develop = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ny_develop = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')","015e9895":"print('Number of Samples: %d' % y_develop.shape[0])\nkeep_rows_id = x_develop['cp_type']!='ctl_vehicle'\ny_develop = y_develop[keep_rows_id].reset_index(drop=True).drop('sig_id', axis=1)\nprint('Number of Samples without Control Group: %d' % y_develop.shape[0])","05411de2":"def calculate_metric(data, seed, n_splits):\n    diff_mean = []\n    Fold = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    for n, (train_index, val_index) in enumerate(Fold.split(data, data)):\n        train_mean_positivity = data.iloc[train_index, 1:].mean()\n        val_mean_positivity = data.iloc[val_index, 1:].mean()\n        diff = train_mean_positivity - val_mean_positivity\n        diff_mean += [np.sqrt(np.sum(diff**2.))]\n    mn = np.mean(diff_mean)\n    std = np.std(diff_mean)\n    return i, mn, std","d7538247":"a = []\nfor i in tqdm(range(100)):\n    a += [calculate_metric(y_develop, i, 5)]","63e4d031":"pd.DataFrame(a, columns=['Seed', 'mean', 'std']).sort_values(by='std').set_index('Seed')","67147eee":"### Best Seed to Worst Seed","d04c234e":"# Iterative-Stratification: Some seeds are better than others\n\nStratification of multilabel data is a commonly used method in the MoA prediction competition. Randomly selected seeds do not seem to provide the most optimized distributions. This notebook finds the seeds that would split the train data into train and validation sets with the most similar distributions.\n\n- V3: Control Group Excluded\n- V2: Control Group Included","95d91702":"### Read Data","4a0a980c":"### Exclude Control Group","a7391195":"Please let me know if you notice any mistakes or have any suggestions.","a108c5d9":"### Metric for best seed\n\nHere I define an Euclidean distance metric to measure how the validation set's distribution matches with that of the training set.\n\nFor a given seed, this metric does the following:\n1. Group the data into 5-folds.\n2. For each train::val couple:\n    - Calculate the positivity rate of each of the 206 targets in the validation set.\n    - Calculate the positivity rate of each of the 206 targets in the training set.\n3. Calculate the Euclidean distances using the positivity rates in Step 2 for each train::val group.\n4. Calculate the mean and standard deviation of the Euclidean distances.\n\nI consider the seed with the smallest Euclidean distance to be the best seed."}}