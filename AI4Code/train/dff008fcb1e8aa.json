{"cell_type":{"076b8646":"code","c86ef179":"code","1397c15b":"code","49ed1a06":"code","c7387cb0":"code","0e58bf9b":"code","431ef3f3":"code","ff39643c":"code","3bf3ee3a":"code","df2a796e":"code","929e4611":"code","c91b46d4":"code","01e7779d":"code","e8bd66e9":"code","df6cc19b":"code","f7b21cbd":"code","a9452341":"code","1637a36b":"code","61f049a9":"code","9711525f":"code","102d86b5":"code","723f1e1a":"code","c0aa1d08":"code","6a0dfddd":"code","5dbf7c80":"code","f738872a":"code","5f9090ce":"code","65cb44c6":"code","2df92388":"code","77c38008":"code","3dee6e47":"code","875fa337":"code","c6bd33fc":"code","f903b42d":"code","60ba2a7c":"code","b96a07c6":"code","165b67b0":"code","302f6e53":"code","2f76ec4b":"code","3b3fed3e":"code","50529e70":"code","86209761":"code","ec793e86":"code","43d072fa":"code","62d1cc8e":"code","1baaac44":"code","71db8ed2":"code","30036c5b":"code","965976c7":"code","b60ed7cb":"code","7a92882e":"code","3ee0669e":"code","08e4e5b6":"code","07199241":"code","563ad2fc":"code","046c19fe":"code","079859f2":"code","07ebdb86":"code","c2363f1b":"code","cad26f8d":"code","41cc7337":"code","793923c9":"code","9dd3cfbe":"code","9933b55d":"code","0d390474":"code","5f9749d5":"code","d9750148":"code","483d25ce":"code","2edd89e3":"code","352d979b":"code","088157ae":"code","018d403c":"code","2a78ca88":"markdown","71bee2f6":"markdown","99e56e24":"markdown","d5f613c3":"markdown","411dfcae":"markdown","6bc6d02c":"markdown","45646a17":"markdown","641d6b1d":"markdown","63bd38c7":"markdown","675b0222":"markdown","15d01270":"markdown","207c4657":"markdown","d37e736a":"markdown","a6367abe":"markdown","f6ebf88c":"markdown","a3da1409":"markdown","d5cc85ed":"markdown","48822169":"markdown","03170008":"markdown","209b6911":"markdown"},"source":{"076b8646":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch","c86ef179":"x = torch.empty(5,3)\nprint(x)","1397c15b":"x = torch.rand(5, 3)\nprint(x)","49ed1a06":"x = torch.zeros(5, 3, dtype=torch.long)\nprint(x)","c7387cb0":"x = torch.tensor([5.5, 3])\nprint(x)","0e58bf9b":"print(x.size())","431ef3f3":"x = torch.tensor([[5.5, 3], [5.5, 3]])\nprint(x)","ff39643c":"x.size()","3bf3ee3a":"np.zeros((2,2)).shape","df2a796e":"x = torch.rand(5, 3)\ny = torch.rand(5, 3)\nprint(x + y)","929e4611":"print(torch.add(x, y))","c91b46d4":"result = torch.empty(5, 3)\ntorch.add(x, y, out=result)\nprint(result)","01e7779d":"x = torch.randn(4, 4)\ny = x.view(16)\nz = x.view(-1, 8)  # the size -1 is inferred from other dimensions\nprint(x.size(), y.size(), z.size())","e8bd66e9":"np_zeros = np.zeros((4,4))","df6cc19b":"np_zeros.reshape((-1,8))","f7b21cbd":"z[0, 0].item()","a9452341":"x.numpy() + np_zeros","1637a36b":"x = torch.zeros((4,4), dtype = torch.double)","61f049a9":"x + torch.from_numpy(np_zeros)","9711525f":"torch.cuda.is_available()","102d86b5":"y = x.cuda()","723f1e1a":"%%time\ny + y","c0aa1d08":"%%time\nx + x","6a0dfddd":"y = torch.randn(500,200)\nw = torch.randn(200,500)","5dbf7c80":"%%time\ntorch.mm(y,w)","f738872a":"y = y.cuda()\nw = w.cuda()","5f9090ce":"%%time\ntorch.mm(y,w)","65cb44c6":"x = torch.ones(2, 2, requires_grad=True)\nprint(x)","2df92388":"y = x + 2\nprint(y)","77c38008":"z = y * y * 3\nout = z.mean()\n\nprint(z, out)","3dee6e47":"a = torch.randn(2, 2)\na = ((a * 3) \/ (a - 1))\nprint(a.requires_grad)\na.requires_grad_(True)\nprint(a.requires_grad)\nb = (a * a).sum()\nprint(b.grad_fn)","875fa337":"out.backward()","c6bd33fc":"print(x.grad)","f903b42d":"print(x.requires_grad)\nprint((x ** 2).requires_grad)\n\nwith torch.no_grad():\n    print((x ** 2).requires_grad)","60ba2a7c":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels, 3x3 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(1, 6, 3)\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # If the size is a square you can only specify a single number\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n\nnet = Net()\nprint(net)","b96a07c6":"params = list(net.parameters())\nprint(len(params))\nprint(params[0].size())  # conv1's .weight","165b67b0":"input = torch.randn(1, 1, 32, 32)\nout = net(input)\nprint(out)","302f6e53":"net.zero_grad()\nout.backward(torch.randn(1, 10))","2f76ec4b":"output = net(input)\ntarget = torch.randn(10)  # a dummy target, for example\ntarget = target.view(1, -1)  # make it the same shape as output\ncriterion = nn.MSELoss()\n\nloss = criterion(output, target)\nprint(loss)","3b3fed3e":"net.zero_grad()     # zeroes the gradient buffers of all parameters\n\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n\nloss.backward()\n\nprint('conv1.bias.grad after backward')\nprint(net.conv1.bias.grad)","50529e70":"learning_rate = 0.001\nfor f in net.parameters():\n    f.data.sub_(f.grad.data * learning_rate)","86209761":"import torch.optim as optim\n\n# create your optimizer\noptimizer = optim.Adam(net.parameters(), lr=0.01)\n\n# in your training loop:\noptimizer.zero_grad()   # zero the gradient buffers\noutput = net(input)\nloss = criterion(output, target)\nloss.backward()\noptimizer.step()    # Does the update","ec793e86":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","43d072fa":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","62d1cc8e":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))","1baaac44":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()","71db8ed2":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","30036c5b":"%%time\nfor epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","965976c7":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))","b60ed7cb":"outputs = net(images)","7a92882e":"_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))","3ee0669e":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct \/ total))","08e4e5b6":"images.shape","07199241":"class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] \/ class_total[i]))","563ad2fc":"#uncomment to see what the state_dict looks like. All of the weights of the network\n# net.state_dict()","046c19fe":"torch.save(net.state_dict(), \"model.pth\")","079859f2":"model = Net()\nmodel.load_state_dict(torch.load(\"model.pth\"))\nmodel.eval()","07ebdb86":"torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss,\n            }, \"full_model.pth\")\n","c2363f1b":"checkpoint = torch.load(\"full_model.pth\")\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\nmodel.eval()\n# - or -\nmodel.train()","cad26f8d":"torch.save(model, \"standalone_model.pth\")\nmodel = torch.load(\"standalone_model.pth\")","41cc7337":"class SimpleNet(nn.Module):\n\n    def __init__(self):\n        super(SimpleNet, self).__init__()\n        self.fc1 = nn.Linear(32*32, 100)\n\n        # an affine operation: y = Wx + b\n        self.fc2 = nn.Linear(100, 60)\n        self.fc3 = nn.Linear(60, 32)\n        self.fc4 = nn.Linear(32, 10)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.fc3(x)\n        x = F.relu(x)\n        x = self.fc4(x)\n        x = F.relu(x)\n        return x\n\n\nnet = SimpleNet()\nprint(net)","793923c9":"# License: BSD\n# Author: Sasank Chilamkurthy\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nplt.ion()   # interactive mode","9dd3cfbe":"os.listdir(\"..\/input\/hymenoptera-data\/hymenoptera_data\/hymenoptera_data\/\")","9933b55d":"# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = '..\/input\/hymenoptera-data\/hymenoptera_data\/hymenoptera_data\/'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","0d390474":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","5f9749d5":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","d9750148":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","483d25ce":"model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","2edd89e3":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=25)","352d979b":"visualize_model(model_ft)","088157ae":"model_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, 2)\n\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)","018d403c":"model_conv = train_model(model_conv, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=25)","2a78ca88":"Side by side of numpy and pytorch for training neural network\nhttps:\/\/pytorch.org\/tutorials\/beginner\/pytorch_with_examples.html","71bee2f6":"Can extract individual items from tensors","99e56e24":"3 different ways to do addition","d5f613c3":"## Importing data and training","411dfcae":"Comparison to np","6bc6d02c":"# Part 2: Transfer Learning","45646a17":"Model is reloaded and then put into eval mode in order to turn off dropout, bathcnorm and anything else you likely want to turn off during inference","641d6b1d":"## Quick Math\nhttps:\/\/pytorch.org\/tutorials\/beginner\/blitz\/tensor_tutorial.html","63bd38c7":"input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss","675b0222":"Can convert to numpy array on the fly","15d01270":"https:\/\/pytorch.org\/tutorials\/beginner\/saving_loading_models.html","207c4657":"No the model can be loaded back in with all of the additional optimizer states and loss histories and put into eval mode or train mode","d37e736a":"Check if gpu device is available","a6367abe":"First option for saving NN is saving just the weights. Doing it this way means next time the NN graph must be defined again and then weights loaded.","f6ebf88c":"One other way to save the model is just to save the entire thing as one big pickle. This is IMO the easiest and best way to do things but slightly unsupported since they cannot guarantee everything in the environment is the same in the new place the model has been unpickled. ","a3da1409":"Applying SGD\nweight = weight - learning_rate * gradient","d5cc85ed":"NN Tutorial\nhttps:\/\/pytorch.org\/tutorials\/beginner\/blitz\/neural_networks_tutorial.html","48822169":"## Autograd\nhttps:\/\/pytorch.org\/tutorials\/beginner\/blitz\/autograd_tutorial.html","03170008":"Option 2 for saving pytorch models is saving the model weights and all of the other things that are related like the optimizer state and the loss history. This will be better if you are trying to conitnue training later","209b6911":"NN as a feature extractor"}}