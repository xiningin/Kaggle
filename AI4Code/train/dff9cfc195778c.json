{"cell_type":{"5e6a6dc8":"code","a4a385ac":"code","1b711069":"code","64328727":"code","f83028f0":"code","3194bd68":"code","7debf8ea":"code","9743a8e8":"code","b61d8b1a":"code","ee7c6ee4":"code","d83b0b40":"code","6e0fa294":"code","b94e0304":"code","b670b16d":"code","c51c895a":"code","597915bd":"code","36510d88":"code","4eda7303":"code","437eff70":"code","087f8921":"code","7970c69a":"code","a77d1fea":"code","17d1da73":"code","6aa9de61":"markdown","a4e44ec4":"markdown","93606eec":"markdown","8a333291":"markdown","1a98a30b":"markdown","acda3b09":"markdown","dbf499d7":"markdown"},"source":{"5e6a6dc8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a4a385ac":"data = pd.read_csv(\"..\/input\/Pokemon.csv\")","1b711069":"data.head()","64328727":"data.tail()","f83028f0":"data.columns","3194bd68":"data.shape","7debf8ea":"data.info()","9743a8e8":"# For example lets look frequnecy of pokemon types\nprint(data[\"Type 1\"].value_counts(dropna = False)) # if there are nan values that also be counted","b61d8b1a":"# For example max HP is 255 or min defense is 5\ndata.describe() # ignore null entries","ee7c6ee4":"# circles mean outlies value\n\ndata.boxplot(column='Attack', by = 'Legendary')\nplt.show()","d83b0b40":"# Firstly I create new data from pokemons data to explain melt nore easily\ndata_new = data.head()\ndata_new","6e0fa294":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we watn to melt\nmelted = pd.melt(frame=data_new, id_vars = 'Name', value_vars = ['Attack','Defense'])\nmelted","b94e0304":"# PIVOTING DATA\n# Reverse of melting\n\n# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\n\nmelted.pivot(index = 'Name', columns = 'variable', values = 'value')","b670b16d":"# Firstly lets create 2 data frame\n\ndata1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2], axis = 0, ignore_index = True) # axis = 0 : adds dataframes in row\nconc_data_row","c51c895a":"data3 = data['Attack'].head()\ndata4 = data['Defense'].head()\nconc_data_col = pd.concat([data3,data4], axis = 1) # axis = 1 : adds dataframes in column\nconc_data_col","597915bd":"data.dtypes","36510d88":"# Lets convert object(str) to categorical and it to float\ndata['Type 1']= data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')\ndata.dtypes","4eda7303":"data.info()\n# Type 2 has 414 non-null object so it has 386 null object","437eff70":"data['Type 2'].value_counts(dropna = False)","087f8921":"data1 = data\ndata1['Type 2'].dropna(inplace = True)","7970c69a":"assert data1['Type 2'].notnull().all # returns nothing because we drop nan values","a77d1fea":"data['Type 2'].fillna('empty',inplace = True)","17d1da73":"assert data['Type 2'].notnull().all() # returns nothing because we don't have nan values","6aa9de61":"**VISUAL EXPLORATORY DATA ANALYSIS**\n\n Box plots : visualize basic statistics like outliers, min\/max or quartiles","a4e44ec4":"**TIDY DATA**\n\nWe tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it\n","93606eec":"EXPLOTARY DATA ANALYSIS (EDA)\n\nvalue_counts() : Frequency counts\noutliers : the value that is considerably higher or lower from rest of the data\n\n* Lets say value at 75% is Q3 and values at 25% is Q1\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1).\n(Q3-Q1) =IQR\nWe will use describe() method. Describe method includes:\n* count : number of entries\n* mean : average of entries\n* std : standart deviation\n* min : minumun entry\n\nOur series:  1,2,3,4,5,6,7,8,9\n\n* Q1 : 25% : first quartile (The lower quartile is the median in between the smallest number and the median => 3)\n* 50% : median or second quartile (middle of series = 5)\n* Q3 : 75%: third quartile (The higher quartile is the median in between the highest number and the median => 7)\n* max : maximum entry\n","8a333291":"**DATA TYPES**\n\nThere are 5 basic data types: object(string), boolean, integer, float and categorical.\nWe can make conversion data types like from str to categorical or from int to float\nWhy is category important?\n*  Make dataframe smaller in memory\n* can be utilized for analysis especially for sklearn","1a98a30b":"**DIAGNOSE DATA for CLEANING**\nWe need to diagnose and clean data before exploring.\nUnclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\nWe will use head, tail, columns, shape and info methods to diagnose data\n\n","acda3b09":"**MISSING DATA and TESTING WITH ASSERT**\nIf we encounter with missing data, what we can do:\n\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\nAssert statement : check that you can turn on or turn off when you are done with your testing of the program","dbf499d7":"**CONCATENATING DATA**\nWe can concatenate two dataframe"}}