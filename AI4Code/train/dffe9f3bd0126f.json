{"cell_type":{"daed1da1":"code","26a9f16b":"code","c176259a":"code","16ceae1c":"code","008a1f1c":"code","4305593a":"code","dd33083f":"code","0e8ebcf8":"code","e9b3dd8e":"code","b51d3c27":"code","02ffd260":"code","f20516b8":"code","844c5da3":"code","df444308":"code","8f0d3448":"code","f62a1406":"code","c98fdc4a":"code","3be294b1":"code","f9384e5e":"code","af20e101":"code","cf54b3d4":"markdown","095e8970":"markdown","0f06ae7c":"markdown","fbaf0cab":"markdown","cdeab201":"markdown","914215c9":"markdown","ad367d5a":"markdown","090ab2ab":"markdown","b27c1a74":"markdown","743a2b21":"markdown"},"source":{"daed1da1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26a9f16b":"# Importing some of the Library\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px \nimport plotly.graph_objs as go\nfrom plotly.offline import iplot","c176259a":"df = pd.read_csv('\/kaggle\/input\/us-accidents\/US_Accidents_June20.csv')","16ceae1c":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","008a1f1c":"df = reduce_mem_usage(df)","4305593a":"df.head()","dd33083f":"df.isnull().sum()","0e8ebcf8":"# Counting the unique numbers of Source\ndf['Source'].unique()","e9b3dd8e":"# Calculating the Contribution of each unique sources in percentage\n\nlabels = df['Source'].value_counts()[:].index\nvalues = df['Source'].value_counts()[:].values\n\ncolors = df['Source']\n\nfig = go.Figure(data=[go.Pie(labels = labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","b51d3c27":"# Counting the unique numbers of state\n\ndf['State'].unique()","02ffd260":"labels = df['State'].value_counts()[:10].index\nvalues = df['State'].value_counts()[:10].values\n\ncolors = df['State']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","f20516b8":"# Counting the unique time zones\n\ndf['Timezone'].unique()","844c5da3":"labels = df['Timezone'].value_counts()[:].index\nvalues = df['Timezone'].value_counts()[:].values\n\ncolors = df['Timezone']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","df444308":"df['Weather_Timestamp'].unique()","8f0d3448":"labels = df['Weather_Timestamp'].value_counts()[:10].index\nvalues = df['Weather_Timestamp'].value_counts()[:10].values\n\ncolors = df['Weather_Timestamp']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","f62a1406":"labels = df['Traffic_Signal'].value_counts()[:10].index\nvalues = df['Traffic_Signal'].value_counts()[:10].values\n\ncolors = df['Sunrise_Sunset']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","c98fdc4a":"labels = df['Sunrise_Sunset'].value_counts()[:10].index\nvalues = df['Sunrise_Sunset'].value_counts()[:10].values\n\ncolors = df['Sunrise_Sunset']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","3be294b1":"labels = df['Weather_Condition'].value_counts()[:10].index\nvalues = df['Weather_Condition'].value_counts()[:10].values\n\ncolors = df['Weather_Condition']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","f9384e5e":"fig=sns.heatmap(df[['TMC','Severity','Start_Lat','End_Lat','Distance(mi)','Temperature(F)','Wind_Chill(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)']].corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':15})\nfig=plt.gcf()\nfig.set_size_inches(18,15)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","af20e101":"from wordcloud import WordCloud\nplt.style.use('seaborn')\nwrds1 = df[\"Description\"].str.split(\"(\").str[0].value_counts().keys()\n\nwc1 = WordCloud(scale=5,max_words=1000,colormap=\"rainbow\",background_color=\"black\").generate(\" \".join(wrds1))\nplt.figure(figsize=(20,14))\nplt.imshow(wc1,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Key Words in Accident Description\",color='b')\nplt.show()","cf54b3d4":"Key Words in the  Description","095e8970":"We can see that most of the accidents has been occured in the Eastern and Pacific Time Zone","0f06ae7c":"Most of the accidents have occured in the day time","fbaf0cab":"So most of the data has been contributed by MapQuest","cdeab201":"Most of the accidents have occured due to wrong traffic signal ","914215c9":"We have 3 unique sources for the accident information","ad367d5a":"Among the state with highest number of accidents California accounts for the most of the accident","090ab2ab":"## Reading the data","b27c1a74":"All Timestamp contrubutes more or less equally","743a2b21":"If you found this notebook insightful please upvote it\n\nFeel free to comment for any questions or suggestions\n\nI would love to hear back from you All"}}