{"cell_type":{"dbbb11ae":"code","edc2fd74":"code","e907720e":"code","47e035cc":"code","bb7130e5":"code","25fb2898":"code","e3f5d802":"code","5ad6d565":"code","092bc0f2":"code","14345808":"code","1ae2bf14":"code","db092435":"code","1fa6e577":"code","dc74057c":"code","04cebdd2":"code","52a9e402":"code","47f47b92":"code","eaf417ae":"code","663a581c":"code","04088451":"code","114f0621":"code","afb20d99":"code","96640197":"code","9ebda4fb":"code","d0ff6bbf":"code","6a1781af":"code","7a19b24e":"markdown","bbfb3cc7":"markdown","c6ba432a":"markdown","f6a97364":"markdown","4f000b02":"markdown","8d7c6231":"markdown","815a7430":"markdown","adfc3e43":"markdown","eb62173d":"markdown","e1d597d9":"markdown","f06f3b6d":"markdown","0ff538d9":"markdown","0531dfdd":"markdown"},"source":{"dbbb11ae":"import os\nimport time\nimport math\nimport gc\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\n\nfrom transformers import DistilBertTokenizer\nfrom transformers import DistilBertModel\n\nfrom logging import getLogger\nfrom logging import INFO\nfrom logging import FileHandler\nfrom logging import Formatter\nfrom logging import StreamHandler\nfrom pathlib import Path\n\n# text augmentation library\n!cp ..\/input\/nlpaug-114\/nlpaug-1.1.4-py3-none-any.whl \/kaggle\/working\/\n!pip install --no-index --find-links \/kaggle\/working\/ nlpaug\nimport nlpaug.augmenter.word as naw\nimport nlpaug.augmenter.sentence as nas","edc2fd74":"# clean memory\ngc.collect()\ntorch.cuda.empty_cache()","e907720e":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","47e035cc":"OUTPUT_DIR = \".\/\"\nBASE_DATA_PATH = Path(\"..\/input\/commonlitreadabilityprize\/\")\n\n!ls {BASE_DATA_PATH}","bb7130e5":"df_train = pd.read_csv(BASE_DATA_PATH \/ \"train.csv\")\ndisplay(df_train.head(3))\n\n# explore excerpt\ndf_train['nb_words'] = df_train.excerpt.apply(lambda x: len(x.split()))\ndf_train['nb_chars'] = df_train.excerpt.apply(lambda x: len(x))\n\n# plot histograms\nfix, ax = plt.subplots(1, 2, figsize=(15, 5))\nsns.histplot(data=df_train, x=\"nb_chars\", bins=100, ax=ax[0],\n             color='orange', edgecolor=None, stat='density')\nsns.kdeplot(data=df_train, x=\"nb_chars\", color='red', ax=ax[0])\nax[0].axvline(np.median(df_train.nb_chars), 0, np.max(df_train.nb_chars))\nax[0].set_title('Text length', fontsize=10)\n\nsns.histplot(data=df_train, x=\"nb_words\", bins=100, ax=ax[1],\n             color='salmon', edgecolor=None, stat='density')\nsns.kdeplot(data=df_train, x=\"nb_words\", color='red', ax=ax[1])\nax[1].axvline(np.median(df_train.nb_words), 0, np.max(df_train.nb_words))\nax[1].set_title('Number of words', fontsize=10)\n\nplt.show()","25fb2898":"# target labels\nlabels = df_train['target']\nprint(\"Values of the target : {} -> {}\".format(labels.min(), labels.max()))\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 5))\nsns.histplot(data=df_train, x=\"target\", bins=100, ax=ax[0],\n             color='lightgreen', edgecolor=None, stat='density')\nsns.kdeplot(data=df_train, x=\"target\", ax=ax[0], color='forestgreen')\nax[0].axvline(np.median(df_train.target), 0, np.max(df_train.target))\nax[0].set_title('Targets histogram', fontsize=10)\n\nsns.boxplot(x=df_train[\"target\"], ax=ax[1], color='lightgreen')\nax[1].set_title('Targets boxplot', fontsize=10)\nplt.show()","e3f5d802":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\n    of a given object:\n    val is the current value\n    sum is the total sum of all increments\n    count is the number of increments\n    avg is the mean increment\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.cur_val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.cur_val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\nclass Metric:\n    \"\"\"sums the squared residuals (target - excepted) for a period (epoch)\n    and returns the rmse for the whole epoch data\"\"\"\n\n    def __init__(self):\n        self.sse = 0\n        self.num_samples = 0\n\n    def update(self, targets, predictions):\n        predictions = flatten(predictions)\n        self.sse += np.sum(np.square(targets - predictions))\n        self.num_samples += len(targets)\n\n    def get_rmse(self):\n        rmse = np.sqrt(self.sse \/ self.num_samples)\n        return rmse\n\n\ndef flatten(array):\n    \"\"\"takes an output array and flatten it\n    returns a list\"\"\"\n\n    my_list = []\n    for i in range(len(array)):\n        my_list.append(array[i][0])\n    return np.array(my_list)\n\n\ndef asMinutes(s):\n    \"\"\"converts seconds to minutes\"\"\"\n\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    \"\"\"returns the time elapsed from the 'since' point\n    and an estimation of the remaining time\n    percent : current % of progress compared to total length\"\"\"\n\n    now = time.time()\n    elapsed = now - since\n    estimated = elapsed \/ (percent)\n    remaining = estimated - elapsed\n    return '%s (remain %s)' % (asMinutes(elapsed), asMinutes(remaining))\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    \"\"\"initiate logger\"\"\"\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n\n    logger.handlers.clear()\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n\n    return logger\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\ndef get_scheduler(optimizer):\n    \"\"\"instanciate a scheduler to update learning rate\"\"\"\n    if CFG.scheduler == 'CosineAnnealingLR':\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n                                                         T_max=CFG.T_max,\n                                                         eta_min=CFG.min_lr,\n                                                         last_epoch=-1)\n    if CFG.scheduler == 'StepLR':\n        scheduler = optim.lr_scheduler.StepLR(optimizer,\n                                              step_size=30,\n                                              gamma=0.1)\n    return scheduler\n\n\ndef get_optimizer(model):\n    \"\"\"instanciate an optimizer\n    weight_decay is for L2 regularization\"\"\"\n    if CFG.optimizer == 'Adam':\n        optimizer = optim.Adam(model.parameters(), lr=CFG.lr,\n                               weight_decay=CFG.weight_decay)\n    if CFG.optimizer == 'RMSprop':\n        optimizer = optim.RMSprop(model.parameters(), lr=CFG.lr,\n                                  weight_decay=CFG.weight_decay)\n    if CFG.optimizer == 'SGD':\n        optimizer = optim.SGD(model.parameters(), lr=CFG.lr,\n                              weight_decay=CFG.weight_decay)\n    return optimizer","5ad6d565":"class CFG:\n    model_name = \"distilbert-base-uncased\"\n    model_path = \"..\/input\/distilbertbaseuncased\"\n    max_length = 256\n    dropout_p = 0.4\n    batch_size = 32\n    n_epochs = 10\n    weight_decay = 1e-6\n    lr = 3e-4\n    min_lr = 1e-6\n    scheduler = \"CosineAnnealingLR\"\n    optimizer = \"Adam\"\n    T_max = 10\n    seed = 28\n    n_folds = 5\n    print_freq = 50\n    num_workers = 4\n    augment_text = False\n    augment_ratio = 0.1","092bc0f2":"def augment_sentences(text, action='switch'):\n    \"\"\"switches or deletes randomly sentences in the text\n    warning : looses the different ponctuations (only dots)\"\"\"\n    list_replace = ['.', '!', '?', '...']\n    sep = '.'\n    for char in list_replace:\n        text = text.replace(char, sep)\n    sentences = text.split(sep)\n    sentences = [x for x in sentences if x]  # cleans empty sentences\n    nb_sentences = len(sentences)\n\n    if (action == 'switch') & (nb_sentences > 1):\n        sents = random.sample(range(nb_sentences), 2)\n        s0 = sentences[sents[0]]\n        s1 = sentences[sents[1]]\n        sentences[sents[0]] = s1\n        sentences[sents[1]] = s0\n        augmented_text = '. '.join(sentences)\n        del(s0, s1)\n        return augmented_text + '.'\n    elif (action == 'delete') & (nb_sentences > 0):\n        sents = random.sample(range(nb_sentences), 1)\n        del sentences[sents[0]]\n        augmented_text = '. '.join(sentences)\n        return augmented_text + '.'\n    else:\n        return text\n\n\ndef augment_words(text, action='delete'):\n    \"\"\"words random augmentations\n    uses NLPAug library:\n    with \u2018swap\u2019, \u2018delete\u2019 or \u2018crop\u2019 actions\n    insertion with distilbert model \"\"\"\n    augmented_text = ''\n    if action in ['delete', 'crop', 'swap']:\n        aug = naw.RandomWordAug(action=action, aug_p=0.3,\n                                aug_min=5, aug_max=50)\n    elif action in ['insert']:\n        aug = naw.ContextualWordEmbsAug(model_path=CFG.model_path,\n                                        action=action)\n\n    augmented_text = aug.augment(text)\n    return augmented_text\n\n\ndef apply_augment(text):\n    \"\"\"randomly applies 1 augmentation on sentence level\n    and 1 augmentation on word level\"\"\"\n\n    list_aug_sentence = ['switch', 'delete']\n    list_aug_word = ['delete', 'crop', 'swap', 'insert']\n\n    # pick randomly 2 transformations\n    trans_s = random.sample(range(len(list_aug_sentence)), 1)[0]\n    trans_w = random.sample(range(len(list_aug_word)), 1)[0]\n\n    aug_text = augment_sentences(text, action=list_aug_sentence[trans_s])\n    aug_text = augment_words(aug_text, action=list_aug_word[trans_w])\n    return aug_text","14345808":"class CommonLitDataset(Dataset):\n\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        tokenized_input = self.tokenizer(row.excerpt, return_tensors=\"pt\",\n                                         max_length=self.max_length,\n                                         padding=\"max_length\", truncation=True)\n\n        return {\n                \"ids\": tokenized_input[\"input_ids\"][0],\n                \"masks\": tokenized_input[\"attention_mask\"][0],\n                \"targets\": torch.tensor(row.target).float()\n        }","1ae2bf14":"class TextRegressionModel(nn.Module):\n\n    def __init__(self, model_name, dropout_p=0.3):\n        super(TextRegressionModel, self).__init__()\n\n        # load DistilBERT model\n        self.model = DistilBertModel.from_pretrained(CFG.model_path)\n        # and freeze its parameters if wanted\n        # for param in self.model.parameters():\n        # param.requires_grad = False\n\n        # define other layers\n        self.features = nn.Linear(768, 200)\n        self.dropout = nn.Dropout(dropout_p)\n        self.regressor = nn.Linear(200, 1)\n        self.list_layers = [self.model, self.features,\n                            self.dropout, self.regressor]\n        self.list_layers_names = ['DistilBERT', 'Features',\n                                  'Dropout', 'Regressor']\n\n    def forward(self, input_ids, attention_mask):\n        output = self.model(input_ids=input_ids,\n                            attention_mask=attention_mask)\n        output = output.last_hidden_state[:, 0]\n        output = F.relu(self.features(output))\n        output = self.dropout(output)\n        output = self.regressor(output)\n        return output\n\n    def count_parameters(self):\n        \"\"\"counts number of trainable parameters\"\"\"\n        total = 0\n        for layer in self.list_layers:\n            total += sum(p.numel() for p in layer.parameters()\n                         if p.requires_grad)\n        return total\n\n    def details_parameters(self):\n        \"\"\"details the number of trainable parameters by layer\"\"\"\n\n        for i in range(len(self.list_layers)):\n            layer = self.list_layers[i]\n            table = pd.DataFrame(columns=['module', 'parameters'])\n            for name, parameter in layer.named_parameters():\n                if not parameter.requires_grad:\n                    continue\n                param = parameter.numel()\n                new_line = {'module': name, 'parameters': param}\n                table.loc[len(table)] = new_line\n            print(self.list_layers_names[i], 'layer :')\n            display(table)","db092435":"def train_step(model, criterion, optimizer, data_loader, epoch, device=device):\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    train_loss = AverageMeter()\n    metric = Metric()\n    model.train()\n\n    start = end = time.time()\n\n    for step, batch in enumerate(data_loader):\n        # update data loading time\n        data_time.update(time.time() - end)\n\n        # get data for the current batch\n        input_ids = batch[\"ids\"].to(device)\n        attention_masks = batch[\"masks\"].to(device)\n        targets = batch[\"targets\"].to(device)\n        bs = input_ids.size(0)\n\n        # compute output and loss\n        output = model(input_ids, attention_masks)\n        loss = criterion(output.squeeze(1), targets)\n        train_loss.update(loss.item(), bs)\n        # loss.item() is the avg of mse over the batch\n        loss.backward()\n\n        m_targets = targets.detach().cpu().numpy()\n        m_predictions = output.detach().cpu().numpy()\n        metric.update(targets=m_targets, predictions=m_predictions)\n\n        # step optimizer\n        optimizer.step()\n        optimizer.zero_grad()\n\n        # update batch time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # if current step is a multiple of the printing param (or end)\n        if step % CFG.print_freq == 0 or step == (len(data_loader) - 1):\n            print('Epoch {0} [{1}\/{2}]: '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.cur_val:.4f} (avg {loss.avg:.4f}) '\n                  .format(\n                      epoch+1, step, len(data_loader),\n                      loss=train_loss,\n                      remain=timeSince(start,\n                                       float(step + 1) \/ len(data_loader))))\n\n    rmse = metric.get_rmse()\n    return train_loss.avg, rmse\n\n\ndef eval_step(model, criterion, data_loader, epoch, device=device):\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    eval_loss = AverageMeter()\n    metric = Metric()\n    model.eval()\n\n    start = end = time.time()\n\n    for step, batch in enumerate(data_loader):\n        data_time.update(time.time() - end)\n\n        input_ids = batch[\"ids\"].to(device)\n        attention_masks = batch[\"masks\"].to(device)\n        targets = batch[\"targets\"].to(device)\n        bs = input_ids.size(0)\n        with torch.no_grad():\n            output = model(input_ids, attention_masks)\n        loss = criterion(output.squeeze(1), targets)\n        eval_loss.update(loss.item(), bs)\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        m_targets = targets.detach().cpu().numpy()\n        m_predictions = output.detach().cpu().numpy()\n        metric.update(targets=m_targets, predictions=m_predictions)\n\n        if step % CFG.print_freq == 0 or step == (len(data_loader) - 1):\n            print('EVAL - Epoch {0} [{1}\/{2}]: '\n                  'Loss: {loss.cur_val:.4f} (avg {loss.avg:.4f}) '\n                  .format(epoch+1, step, len(data_loader),\n                          loss=eval_loss))\n    rmse = metric.get_rmse()\n    return eval_loss.avg, rmse","1fa6e577":"def train_loop(folds, fold):\n    print('\\n*** FOLD ', fold)\n\n    # get indexes tagged for the current fold\n    train_index = folds[folds[\"fold\"] != fold].index\n    valid_index = folds[folds[\"fold\"] == fold].index\n\n    # get data\n    train_folds = folds.loc[train_index].reset_index(drop=True)\n    valid_folds = folds.loc[valid_index].reset_index(drop=True)\n\n    # create tokenizer and create dataset\n    tokenizer = DistilBertTokenizer.from_pretrained(CFG.model_path)\n    tokenizer.save_pretrained(f\"{CFG.model_name}_tokenizer\")\n\n    # create validation data loader\n    valid_dataset = CommonLitDataset(df=valid_folds, tokenizer=tokenizer,\n                                     max_length=CFG.max_length)\n    valid_data_loader = DataLoader(valid_dataset,\n                                   batch_size=CFG.batch_size,\n                                   shuffle=False,\n                                   num_workers=CFG.num_workers,\n                                   pin_memory=True)\n\n    # define scheduler, model, optimizer, loss\n    model = TextRegressionModel(model_name=CFG.model_name,\n                                dropout_p=CFG.dropout_p)\n    model.to(device)\n    if fold == 0:\n        print('Model instanciated. Number of trainable parameters : {}\\n'\n              .format(model.count_parameters()))\n        model.details_parameters()\n\n    optimizer = get_optimizer(model)\n    scheduler = get_scheduler(optimizer)\n\n    criterion = nn.MSELoss().to(device)\n    best_loss = np.inf  # initiate with positive infinity\n\n    # iterate through epochs\n    for epoch in range(CFG.n_epochs):\n\n        # augment part of the data except for the first epoch\n        if CFG.augment_text & (epoch != 0):\n            print(\"Epoch {} - Augmenting data...\".format(epoch + 1))\n            start = time.time()\n            ratio = CFG.augment_ratio\n            idx_aug = random.sample(range(len(train_folds)),\n                                    int(len(train_folds) * ratio))\n            for idx in idx_aug:\n                cur_excerpt = train_folds.loc[idx, 'excerpt']\n                train_folds.loc[idx, 'excerpt'] = apply_augment(cur_excerpt)\n            print(\"... done ({} sec)\".format(round(time.time() - start)))\n\n        # build train data loader\n        train_dataset = CommonLitDataset(df=train_folds, tokenizer=tokenizer,\n                                         max_length=CFG.max_length)\n        train_data_loader = DataLoader(train_dataset,\n                                       batch_size=CFG.batch_size,\n                                       shuffle=True,\n                                       num_workers=CFG.num_workers,\n                                       pin_memory=True)\n\n        # train and evaluate\n        start_time = time.time()\n        train_loss, train_rmse = train_step(model, criterion, optimizer,\n                                            train_data_loader, epoch)\n        eval_loss, eval_rmse = eval_step(model, criterion,\n                                         valid_data_loader, epoch)\n        scheduler.step()\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {train_loss:.4f}'\n                    ' time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - avg_eval_loss: {eval_loss:.4f} '\n                    '- avg_rmse: {eval_rmse:.4f}')\n        save_training(fold, epoch, train_loss, eval_loss,\n                      train_rmse, eval_rmse)\n\n        # save best loss and model\n        if eval_loss < best_loss:\n            best_loss = eval_loss\n            file_name = f\"{CFG.model_name}_fold_{fold}_best.pth\"\n            print('  -> save model as', file_name)\n            torch.save({\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"scheduler\": scheduler.state_dict()\n            }, file_name)","dc74057c":"def save_training(fold, epoch, train_loss, val_loss, train_rmse, val_rmse):\n    \"\"\"stores the values of loss and rmse during training\"\"\"\n    new_line = {'fold': fold, 'epoch': epoch,\n                'train_loss': train_loss, 'val_loss': val_loss,\n                'train_rmse': train_rmse, 'val_rmse': val_rmse}\n    training_evals.loc[len(training_evals)] = new_line\n    return training_evals","04cebdd2":"# separate the observations in CFG.n_folds folds\n# the fold number is recorded in the 'fold' column of folds df\nfolds = df_train.copy()\nFold = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\nfor n, (train_idx, valid_idx) in enumerate(Fold.split(folds)):\n    folds.loc[valid_idx, \"fold\"] = int(n)\n\nfolds[\"fold\"] = folds[\"fold\"].astype(int)\nprint('Number of observations per fold :\\n')\nprint(folds.groupby([\"fold\"]).size())","52a9e402":"def main():\n    for fold in range(CFG.n_folds):\n        gc.collect()\n        torch.cuda.empty_cache()\n        train_loop(folds, fold)","47f47b92":"# inits\nseed_torch(seed=CFG.seed)\nLOGGER = init_logger()\ntraining_evals = pd.DataFrame(columns=['fold', 'epoch',\n                                       'train_loss', 'val_loss',\n                                       'train_rmse', 'val_rmse'])\n\n# run training\nmain()","eaf417ae":"# print results\nepochs = range(1, CFG.n_epochs + 1)\ncolors = ['mediumpurple', 'deepskyblue', 'mediumseagreen', 'gold', 'tomato']\n\n# loss curve\nfig = plt.figure(figsize=(8, 8))\nmax_y = 0\nfor f in range(CFG.n_folds):\n    loss_train = training_evals.loc[training_evals.fold == f, 'train_loss']\n    loss_val = training_evals.loc[training_evals.fold == f, 'val_loss']\n    curmax = max(max(loss_train), max(loss_val))\n    if curmax > max_y:\n        max_y = curmax\n    plt.plot(epochs, loss_train, c=colors[f], label='Training loss fold {}'.format(f))\n    plt.plot(epochs, loss_val, c=colors[f], linestyle='dashed',\n             label='validation loss fold {}'.format(f))\n\nplt.title('Training and Validation loss')\nplt.xticks(range(0, CFG.n_epochs + 1))\nplt.xlim(0.5, CFG.n_epochs + 0.5)\nplt.ylim(0, max_y)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(bbox_to_anchor=(1, 1, 0, 0))\nplt.show()\n\n# RMSE\nmax_y = 0\nfig = plt.figure(figsize=(8, 8))\nfor f in range(CFG.n_folds):\n    rmse_train = training_evals.loc[training_evals.fold == f, 'train_rmse']\n    rmse_val = training_evals.loc[training_evals.fold == f, 'val_rmse']\n    curmax = max(max(rmse_train), max(rmse_val))\n    if curmax > max_y:\n        max_y = curmax\n    plt.plot(epochs, rmse_train, c=colors[f], label='Training RMSE fold {}'.format(f))\n    plt.plot(epochs, rmse_val, c=colors[f], linestyle='dashed',\n             label='validation RMSE fold {}'.format(f))\nplt.title('Training and Validation RMSE')\nplt.xticks(range(0, CFG.n_epochs + 1))\nplt.xlim(0.5, CFG.n_epochs + 0.5)\nplt.ylim(0, max_y)\nplt.xlabel('Epochs')\nplt.ylabel('RMSE')\nplt.legend(bbox_to_anchor=(1, 1, 0, 0))\nplt.show()","663a581c":"class CommonLitDataset_test(Dataset):\n\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n\n        tokenized_input = self.tokenizer(row.excerpt, return_tensors=\"pt\",\n                                         max_length=self.max_length,\n                                         padding=\"max_length\", truncation=True)\n\n        return {\n                \"ids\": tokenized_input[\"input_ids\"][0],\n                \"masks\": tokenized_input[\"attention_mask\"][0]\n        }","04088451":"def inference(model, states, data_loader, device=device):\n    \"\"\" runs inference for the test set\n    takes each state (cf fold) and computes the mean of the results\"\"\"\n    results = []\n    n_state = 1\n    with torch.no_grad():\n        for state in states:\n            state_results = []\n            print('State {}\/{}'.format(n_state, len(states)))\n            model.load_state_dict(state)\n            model.to(device)\n            model.eval()\n\n            for step, batch in enumerate(data_loader):\n                input_ids = batch[\"ids\"].to(device)\n                attention_masks = batch[\"masks\"].to(device)\n                output = model(input_ids, attention_masks)\n                predictions = flatten(output.detach().cpu().numpy())\n                state_results.extend(predictions)\n\n            results.append(state_results)\n            n_state += 1\n\n    mean_results = np.mean(results, axis=0)\n    return results, mean_results","114f0621":"# get previous states from k fold\nstates = [torch.load(f\"distilbert-base-uncased_fold_{f}_best.pth\")[\"model\"]\n          for f in range(CFG.n_folds)]\n\n# build model\nmodel_inf = TextRegressionModel(CFG.model_name, CFG.dropout_p)","afb20d99":"# build dataset with no target\ntokenizer = DistilBertTokenizer.from_pretrained(CFG.model_path)\n\ndf_train = pd.read_csv(BASE_DATA_PATH \/ \"train.csv\")\ntest_dataset = CommonLitDataset_test(df_train, tokenizer, CFG.max_length)\n\ndata_loader_test = DataLoader(test_dataset,\n                              batch_size=CFG.batch_size, shuffle=False)","96640197":"# predict outputs\nres_states, mean_res = inference(model_inf, states, data_loader_test, device)","9ebda4fb":"y_pred = mean_res\ny_true = df_train.target\n\n# compute RMSE on training set\nrmse = np.sqrt(metrics.mean_squared_error(y_true, y_pred))\nprint('RMSE on train dataset :', round(rmse, 4))\n\n# plot results\nfig, axes = plt.subplots(figsize=(12, 6), nrows=1, ncols=2)\nxmin = np.min(y_true) - 1\nxmax = np.max(y_true) + 1\naxes[0].scatter(y_true, y_pred, color='yellowgreen', s=1)\naxes[0].plot([xmin, xmax], [xmin, xmax],\n             color='darkolivegreen', linewidth=1)\naxes[0].set_xlabel('True target')\naxes[0].set_ylabel('Predicted target')\naxes[0].set_title('Predicted vs true targets')\n\nresiduals = y_true - y_pred\nmoy_residuals = np.mean(residuals)\nlab = 'Mean residuals({})'.format(np.round(moy_residuals, decimals=2))\n\nxmin = np.min(y_pred) - 1\nxmax = np.max(y_pred) + 1\naxes[1].scatter(y_pred, residuals, color='burlywood', s=1.5)\naxes[1].plot([xmin, xmax], [0, 0], color='grey', alpha=0.5, linewidth=0.5)\naxes[1].plot([xmin, xmax], [moy_residuals, moy_residuals],\n             color='saddlebrown', linewidth=1, label=lab)\naxes[1].set_xlabel('Predicted target')\naxes[1].set_ylabel('Residuals')\naxes[1].legend()\naxes[1].set_title('Residuals')\n\nplt.show()","d0ff6bbf":"# build test dataset\ntokenizer = DistilBertTokenizer.from_pretrained(CFG.model_path)\n\ndf_test = pd.read_csv(BASE_DATA_PATH \/ \"test.csv\")\ntest_dataset = CommonLitDataset_test(df_test, tokenizer, CFG.max_length)\n\ndata_loader_test = DataLoader(test_dataset,\n                              batch_size=CFG.batch_size, shuffle=False)\n\n# predict outputs\nout_states, out_mean = inference(model_inf, states, data_loader_test, device)","6a1781af":"# build submission file\ndf_sub = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/sample_submission.csv\")\ndf_sub[\"target\"] = out_mean\ndf_sub.to_csv(\"submission.csv\",index=False)\ndf_sub","7a19b24e":"# Model","bbfb3cc7":"### On full dataset \n(**Warning** : this should give great RMSE as the data has been used for training)","c6ba432a":"# Inference","f6a97364":"# Configuration","4f000b02":"# Main","8d7c6231":"# Train and eval Functions","815a7430":"# Utils","adfc3e43":"### On test set (7 entries)","eb62173d":"# Data Loading","e1d597d9":"\n# Dataset","f06f3b6d":"# Imports","0ff538d9":"# CommonLit Readability - DistilBERT fine tuning and data augmentation\nThis notebook is using DistilBert fine tuning for the CommonLit readability competition, with kfold validation.\n\nMost of the code comes from S Canisir's notebooks : https:\/\/www.kaggle.com\/snnclsr\/commonlit-pytorch-distilbert-training  \nWith the help of V Baskaran's work as well : https:\/\/www.kaggle.com\/vigneshbaskaran\/commonlit-easy-transformer-finetuner  \n\nMy first attempts concentrated on using DistilBERT with some linear and dropout layers, not freezing any parameter. The global model was then built with around 66 millions parameters to update. With the small number of data available, it turned out to overfit a lot, even with the dropout layer : loss curve decreasing a lot on training set but not on validation set.   \n  \nI tried to freeze the 66 million parameters of the DistilBERT model (see Model class), to make it possible to train the model with the amount of data provided.    \n  \nI also tried to generate data augmentation on the texts (see parameter in CFG class).   \nBe aware that it takes a long time to generate the augmented data, that's why I only augmented 10% of the data at each epoch.   \nNote : to use NLPaug library offline, one should import it as a dataset.\n","0531dfdd":"#### CV split"}}