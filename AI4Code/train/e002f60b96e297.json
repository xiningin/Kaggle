{"cell_type":{"7300bed4":"code","cf4b9678":"code","56c3e39f":"code","e1525a3b":"code","a40b153f":"code","ca7bfc05":"code","31da7cd2":"code","df9135e9":"code","8e91251b":"code","460e01d1":"code","302e1830":"code","2a8369e4":"code","b414b47f":"code","a9549a9b":"code","43d64f6d":"code","4726e7c0":"code","5bf1b62e":"code","09f6ed17":"code","04dcc20c":"code","5d75fd06":"code","2ece39eb":"code","d22831ab":"code","28797d7e":"code","fb92ccc2":"code","15a3b373":"code","6198c30f":"markdown","d2ca2062":"markdown","413856ae":"markdown","f07ed378":"markdown","102bdbf8":"markdown","5ce28231":"markdown","9f07c5b9":"markdown","d8e4cbdd":"markdown","3a6e4f60":"markdown","e639e19a":"markdown"},"source":{"7300bed4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf4b9678":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #show data in draph\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler","56c3e39f":"cols=['A','B','C','D','E','F','G','H','I','J',\n      'K','L','M','N','O','P','Q','R','S','T',\n      'U','V','W','X','Y','Z','AA','AB','AC','AD',\n     'AE','AF','AG','AH','AI','AJ','AK','AL','AM','AN']\ntrain_data=pd.read_csv(\"..\/input\/data-science-london-scikit-learn\/train.csv\",names=cols)\ntest_data=pd.read_csv(\"..\/input\/data-science-london-scikit-learn\/test.csv\",names=cols)\ntrain_label=pd.read_csv(\"..\/input\/data-science-london-scikit-learn\/trainLabels.csv\",names=['result'])","e1525a3b":"train_data.shape","a40b153f":"test_data.shape","ca7bfc05":"train_label.shape","31da7cd2":"train_data.head()","df9135e9":"test_data.head()","8e91251b":"train_label.head()","460e01d1":"train_data.describe()","302e1830":"train_data.info()","2a8369e4":"train_data.isna().sum()","b414b47f":"train_data=pd.DataFrame(MinMaxScaler().fit_transform(train_data),columns=cols)\ntest_data=pd.DataFrame(MinMaxScaler().fit_transform(test_data),columns=cols)","a9549a9b":"x_train=train_data\ny_train=train_label\nx_test=test_data","43d64f6d":"lgmodel=LogisticRegression().fit(x_train,y_train)\nprint(\"the score of train data is : \",lgmodel.score(x_train,y_train))\ny_pred=lgmodel.predict(x_train)\nconf1= confusion_matrix(y_train,y_pred)","4726e7c0":"conf1","5bf1b62e":"sns.heatmap(conf1,annot=True)","09f6ed17":"svcmodel=SVC(C=2).fit(x_train,y_train)\nprint(\"the score of train data is : \",svcmodel.score(x_train,y_train))\ny_pred1=svcmodel.predict(x_train)\ny_pred_test=pd.DataFrame(svcmodel.predict(x_test),columns=['Solution'])\nconf2= confusion_matrix(y_train,y_pred1)","04dcc20c":"conf2\n","5d75fd06":"sns.heatmap(conf2,annot=True)","2ece39eb":"treemodel=DecisionTreeClassifier().fit(x_train,y_train)\nprint(\"the score of train data is : \",treemodel.score(x_train,y_train))\ny_pred2=treemodel.predict(x_train)\nconf3= confusion_matrix(y_train,y_pred2)","d22831ab":"conf3","28797d7e":"sns.heatmap(conf3,annot=True)","fb92ccc2":"\nsubmission = pd.DataFrame(np.arange(1,len(x_test)+1),columns=['id'])\n#submission = submission[['Id', 'Solution']]\n#submission\n#y_pred_test\nsubmission=pd.concat([submission['id'],y_pred_test['Solution']], axis=1)\nsubmission","15a3b373":"submission.to_csv('submission.csv', index=False)","6198c30f":"**Here we import the tool we need**","d2ca2062":"**split data**","413856ae":"**In DecisionTreeClassifier the score of train data reach to 1.0 ,This indicates that there is overfitting**","f07ed378":"**Here we get the data**","102bdbf8":"**DecisionTreeClassifier algorithim**","5ce28231":"**Discover scikit_learn library* ","9f07c5b9":"**LogisticRegression**","d8e4cbdd":"**SVC algorithim**\n","3a6e4f60":"**Wonderful the score of train data reach .983 by using the SVC algorithim**","e639e19a":"**In LogisticRegression the score reach to .386 ,This is pretty good**"}}