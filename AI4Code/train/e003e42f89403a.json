{"cell_type":{"3058f806":"code","bdc85d97":"code","bca7cac7":"code","f60c896d":"code","ed9b9c2f":"code","65b1293d":"code","7fa1e303":"code","34f0b6d9":"code","c3500858":"code","bae4c2de":"code","5acab932":"code","2c7065a4":"code","0ffe5d90":"code","c6fcb4b8":"code","97b64f17":"code","f350d660":"code","0f954a5d":"code","586baf18":"code","f57117b9":"code","d8503647":"code","02337fb2":"code","1cd19d3d":"code","2baf11ea":"code","9ea8e183":"markdown","ae4b43c2":"markdown","cecbb705":"markdown","da0c7972":"markdown","2959e584":"markdown","6d27c23a":"markdown","9e8a820e":"markdown","0c0c7d5e":"markdown","a2e4982d":"markdown","26d07f6f":"markdown","2986f5a1":"markdown","22a62e04":"markdown","5ab72941":"markdown","54e9e065":"markdown","125e45c1":"markdown","5c0d4f10":"markdown","4fd5a90d":"markdown","bdfd62d4":"markdown"},"source":{"3058f806":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn import metrics \nimport matplotlib.pyplot as plt\nimport seaborn as sns","bdc85d97":"sales = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest  = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\nsubmission=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')","bca7cac7":"test.info()","f60c896d":"test.head()","ed9b9c2f":"sales.info()","65b1293d":"sales.head()","7fa1e303":"sales['item_price'].max()\nplt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sales.item_cnt_day)\nplt.figure(figsize=(10,4))\nplt.xlim(sales.item_price.min(), sales.item_price.max()*1.1)\nsns.boxplot(x=sales.item_price)\n","34f0b6d9":"sales.drop(sales[sales['item_cnt_day']<0].index,axis=0,inplace=True)\n\nsubset  = ['date','date_block_num','shop_id','item_id', 'item_cnt_day']\nsales.drop_duplicates(subset=subset , inplace=True)\n\nmax_price=sales['item_price'].max()\nmost_expensive_item=sales.loc[sales['item_price']==max_price,'item_id'].values[0]\nsales.drop(sales['item_price'].idxmax(),axis=0,inplace=True)\ndel max_price, most_expensive_item\nsales.drop(sales['item_price'].idxmin(),axis=0,inplace=True)\nsales=sales.iloc[:,0:7]\nsales = sales[sales.item_price<100000]\nsales = sales[sales.item_cnt_day<1001]","c3500858":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sales.item_cnt_day)\nplt.figure(figsize=(10,4))\nplt.xlim(sales.item_price.min(), sales.item_price.max()*1.1)\nsns.boxplot(x=sales.item_price)","bae4c2de":"sales.head()","5acab932":"agg_df = sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\"item_cnt_day\"].agg('sum').reset_index()\nagg_df.columns = ['date_block_num','shop_id','item_id','item_cnt_day']\nagg_df['item_cnt_day'].clip(0,20,inplace=True)\n\nexc_item_cnt=agg_df.iloc[:,:-1]\nitem_cnt=agg_df.iloc[:,-1:]","2c7065a4":"exc_item_cnt","0ffe5d90":"item_cnt","c6fcb4b8":"x_train, x_test,y_train,y_test = train_test_split(exc_item_cnt,item_cnt,test_size=0.33, random_state=14)","97b64f17":"from xgboost import XGBRegressor\nxgb_model = XGBRegressor(random_state=14, colsample_bylevel=1,\n                         colsample_bytree=0.5, learning_rate=0.2, seed=42, max_depth=5,\n                         n_estimators=250, min_child_weight=250, subsample=0.8)\nxgb_model.fit(x_train,y_train,eval_metric=\"rmse\", \n              eval_set=[(x_train, y_train), (x_test, y_test)], \n              verbose=True, \n              early_stopping_rounds=15)\n\ny_pred = xgb_model.predict(x_test)\ny_pred = y_pred.tolist()\nxgb_r2=r2_score(y_test,y_pred)\nxgb_rmse=np.sqrt(mean_squared_error(y_test,y_pred))\nprint(\"R2 Score:\",r2_score(y_test,y_pred))","f350d660":"AdaBoostRegressor","0f954a5d":"ada_model = AdaBoostRegressor(random_state=14,n_estimators=250,learning_rate=0.3)\n\nada_model.fit(x_train,y_train)\ny_pred = ada_model.predict(x_test)\nada_rmse=np.sqrt(mean_squared_error(y_test,y_pred))\nada_r2=r2_score(y_test,y_pred)\nprint(\"R2 Score:\",r2_score(y_test,y_pred))\nprint('Root Mean Squared Error :', np.sqrt(mean_squared_error(y_test,y_pred)))","586baf18":"rf = RandomForestRegressor(n_estimators = 50,random_state=14)\n\nrf.fit(x_train,y_train)\ny_pred = rf.predict(x_test)\nrf_rmse=np.sqrt(mean_squared_error(y_test,y_pred))\nrf_r2=r2_score(y_test,y_pred)\nprint(\"R2 Score:\",r2_score(y_test,y_pred))\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Root Mean Squared Error :', np.sqrt(mean_squared_error(y_test,y_pred)))","f57117b9":"import lightgbm as lgb\nparams = {\n    'task': 'train','boosting_type': 'gbdt','objective': 'regression','metric': 'rmse',\n    'learning_rate': 0.005,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 10,\n    'verbose': 10,\n    \"max_depth\": 8,\n    \"num_leaves\": 128,  \n    \"max_bin\": 512,\n    \"num_iterations\": 40,\n    \"n_estimators\": 250\n}\n\nlgb_model = lgb.LGBMRegressor(**params)\n\nlgb_model.fit(x_train, y_train,\n        eval_set=[(x_test, y_test)],\n        eval_metric='l1',\n        early_stopping_rounds=1000)\ny_pred = lgb_model.predict(x_test)\nlight_r2=r2_score(y_test,y_pred)\nlight_rmse=np.sqrt(mean_squared_error(y_test,y_pred))\nprint(\"R2 Score:\",r2_score(y_test,y_pred))","d8503647":"RMSE = [xgb_rmse, ada_rmse, rf_rmse, light_rmse]\nimport seaborn as sns \nimport matplotlib.pyplot as plt\ny_ax = ['XGBoost' ,'AdaBoost', 'Random Forest Regression','Lightgbm']\nx_ax = RMSE\n\nsns.barplot(x=x_ax,y=y_ax,linewidth=1.5,edgecolor=\"0.1\")\nplt.xlabel('RMSE')","02337fb2":"R2 = [xgb_r2, ada_r2, rf_r2, light_r2]\nimport seaborn as sns \nimport matplotlib.pyplot as plt\ny_ax = ['XGBoost' ,'AdaBoost', 'Random Forest Regression','Lightgbm']\nx_ax = R2\n\nsns.barplot(x=x_ax,y=y_ax,linewidth=1.5,edgecolor=\"0.1\")\nplt.xlabel('R2')","1cd19d3d":"t_p=rf.predict(test)\np_df=pd.DataFrame(t_p,columns=['item_cnt_month',])\np_df=p_df.clip(0,20)\nsubmission.drop(columns =\"item_cnt_month\",inplace = True)\nresult=pd.concat([submission,p_df],axis=1)\nresult.head(6)","2baf11ea":"result.to_csv('submission.csv', index=False)\n","9ea8e183":"# Model Selection","ae4b43c2":"* Handling Outliers, Noisy Datas and Duplicates","cecbb705":"* Analyzing the Data","da0c7972":"* Comparations Between the R2","2959e584":"LightGBM","6d27c23a":"* Detection of Outliers","9e8a820e":"* Splitting the data to Train and Test","0c0c7d5e":"After the compare I choosed RF for prediction.","a2e4982d":"* Grouping the Data","26d07f6f":"# Submit","2986f5a1":"* Comparations Between the RMSE","22a62e04":"# Serkan Yava\u015f\n# 160202063","5ab72941":"* Prediction","54e9e065":"* Load Data","125e45c1":"****XGBoost Regressor****","5c0d4f10":"Random Forest","4fd5a90d":"# Preprocessing ","bdfd62d4":"* After Handling Outliers"}}