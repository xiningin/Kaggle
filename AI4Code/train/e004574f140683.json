{"cell_type":{"310ee98c":"code","da96920c":"code","1eaa3e5c":"code","6b3365eb":"code","b780a0ee":"code","f0dbaf83":"code","c4cb0df3":"code","14734176":"code","a3a96136":"code","c3695705":"code","897f4074":"code","d79a2cbd":"code","a3d4837a":"code","b9197da4":"code","47119139":"code","5832ff81":"code","9058e544":"markdown","c9c7b7ad":"markdown","1bd0c888":"markdown","8a21b5c2":"markdown","4d5aa8ed":"markdown","8428122d":"markdown","11d6003b":"markdown","956f836a":"markdown","0da2d36c":"markdown"},"source":{"310ee98c":"#!pip install ..\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4\/ > \/dev\/null # no output\npackage_path = '..\/input\/underscripts\/' # add unet script dataset\nimport sys\nsys.path.append(package_path)\nfrom model import Unet # import Unet model from the script\nfrom upp_model import UPPnet","da96920c":"import os\nimport cv2\nimport pdb\nimport time\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom matplotlib import pyplot as plt\nfrom  albumentations  import (\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, Flip, OneOf, Compose,NoOp,Normalize\n) # \u56fe\u50cf\u53d8\u6362\u51fd\u6570\nfrom albumentations.torch import ToTensor\nwarnings.filterwarnings(\"ignore\")\nseed = 69\nrandom.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\nnp.random.seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","1eaa3e5c":"from sklearn.model_selection import StratifiedKFold","6b3365eb":"# some preprocessing\n# https:\/\/www.kaggle.com\/amanooo\/defect-detection-starter-u-net\ntrain = pd.read_csv('..\/input\/severstal-steel-defect-detection\/train.csv')\ntrain['ImageId'], train['ClassId'] = zip(*train['ImageId_ClassId'].str.split('_'))\ntrain['ClassId'] = train['ClassId'].astype(int)\ntrain = train.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\ntrain['defects'] = train.count(axis=1)\ntrain = train.reset_index()","b780a0ee":"skf = StratifiedKFold(n_splits=5,random_state=42)\nfor i,(trn_idx,val_idx)in enumerate(skf.split(train,train[\"defects\"])):\n    train_fold = train.iloc[trn_idx]\n    valid_fold = train.iloc[val_idx]\n    train_fold.to_csv(\".\/train_fold_{}.csv\".format(i),index=False)\n    valid_fold.to_csv(\".\/valid_fold_{}.csv\".format(i),index=False)","f0dbaf83":"#https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef make_mask(row_id, df):\n    '''Given a row index, return image_id and mask (256, 1600, 4)'''\n    fname = df.iloc[row_id][\"ImageId\"]\n    labels = df.iloc[row_id][1:5]\n    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n    # 4:class 1\uff5e4 (ch:0\uff5e3)\n\n    for idx, label in enumerate(labels.values):\n        if label is not np.nan:\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            mask = np.zeros(256 * 1600, dtype=np.uint8)\n            for pos, le in zip(positions, length):\n                mask[pos:(pos + le)] = 1\n            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n    return fname, masks","c4cb0df3":"class SteelDataset(Dataset):\n    def __init__(self, df, data_folder, mean, std, phase):\n        self.df = df\n        self.root = data_folder\n        self.mean = mean\n        self.std = std\n        self.phase = phase\n        self.transforms = get_transforms(phase, mean, std)\n        self.fnames = self.df.index.tolist()\n\n    def __getitem__(self, idx):\n        image_id, mask = make_mask(idx, self.df)\n        image_path = os.path.join(self.root, \"train_images\",  image_id)\n        img = cv2.imread(image_path)\n        augmented = self.transforms(image=img, mask=mask)\n        img = augmented['image']\n        mask = augmented['mask'] # 1x256x1600x4\n        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n        return img, mask\n\n    def __len__(self):\n        return len(self.fnames)\n\n\ndef get_transforms(phase, mean, std):\n    list_transforms = []\n    if phase == \"train\":\n        list_transforms.extend(\n            [OneOf([\n                HorizontalFlip(),\n                ShiftScaleRotate(p=1),\n                NoOp(),\n            ]),\n            OneOf([\n                Blur(blur_limit=2,p=0.1),\n                GaussNoise(),\n                NoOp(),\n            ]),\n            OneOf([\n                CLAHE(clip_limit=0.8),\n                NoOp(),\n            ])\n            ]\n        )\n    list_transforms.extend(\n        [\n            Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    )\n    list_trfms = Compose(list_transforms)\n    return list_trfms\n\ndef provider(\n    data_folder,\n    df_path,\n    phase,\n    mean=None,\n    std=None,\n    batch_size=8,\n    num_workers=4,\n):\n    '''Returns dataloader for the model training'''\n    df = pd.read_csv(df_path)\n    \n    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n    if phase==\"train\":\n        dataloader = DataLoader(\n            image_dataset,\n            batch_size=batch_size,\n            num_workers=num_workers,\n            pin_memory=False,\n            shuffle=True,   \n        )\n    else:\n        dataloader = DataLoader(\n            image_dataset,\n            batch_size=batch_size,\n            num_workers=num_workers,\n            pin_memory=False,\n            shuffle=False\n        )\n    return dataloader\n","14734176":"def predict(X, threshold):\n    '''X is sigmoid output of the model'''\n    X_p = np.copy(X)\n    preds = (X_p > threshold).astype('uint8')\n    return preds\n\ndef metric(probability, truth, threshold=0.5, reduction='none'):\n    '''Calculates dice of positive and negative images seperately'''\n    '''probability and truth must be torch tensors'''\n    batch_size = len(truth)\n    with torch.no_grad():\n        probability = probability.view(batch_size, -1)\n        truth = truth.view(batch_size, -1)\n        assert(probability.shape == truth.shape)\n\n        p = (probability > threshold).float()\n        t = (truth > 0.5).float()\n\n        t_sum = t.sum(-1)\n        p_sum = p.sum(-1)\n        neg_index = torch.nonzero(t_sum == 0)\n        pos_index = torch.nonzero(t_sum >= 1)\n\n        dice_neg = (p_sum == 0).float()\n        dice_pos = 2 * (p*t).sum(-1)\/((p+t).sum(-1))\n\n        dice_neg = dice_neg[neg_index]\n        dice_pos = dice_pos[pos_index]\n        dice = torch.cat([dice_pos, dice_neg])\n\n        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n        dice = dice.mean().item()\n\n        num_neg = len(neg_index)\n        num_pos = len(pos_index)\n\n    return dice, dice_neg, dice_pos, num_neg, num_pos\n\nclass Meter:\n    '''A meter to keep track of iou and dice scores throughout an epoch'''\n    def __init__(self, phase, epoch):\n        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n        self.base_dice_scores = []\n        self.dice_neg_scores = []\n        self.dice_pos_scores = []\n        self.iou_scores = []\n\n    def update(self, targets, outputs):\n        probs = torch.sigmoid(outputs)\n        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n        self.base_dice_scores.append(dice)\n        self.dice_pos_scores.append(dice_pos)\n        self.dice_neg_scores.append(dice_neg)\n        preds = predict(probs, self.base_threshold)\n        iou = compute_iou_batch(preds, targets, classes=[1])\n        self.iou_scores.append(iou)\n\n    def get_metrics(self):\n        dice = np.mean(self.base_dice_scores)\n        dice_neg = np.mean(self.dice_neg_scores)\n        dice_pos = np.mean(self.dice_pos_scores)\n        dices = [dice, dice_neg, dice_pos]\n        iou = np.nanmean(self.iou_scores)\n        return dices, iou\n\ndef epoch_log(phase, epoch, epoch_loss, meter, start):\n    '''logging the metrics at the end of an epoch'''\n    dices, iou = meter.get_metrics()\n    dice, dice_neg, dice_pos = dices\n    print(\"Loss: %0.4f | IoU: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f\" % (epoch_loss, iou, dice, dice_neg, dice_pos))\n    return dice, iou\n\ndef compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n    '''computes iou for one ground truth mask and predicted mask'''\n    pred[label == ignore_index] = 0\n    ious = []\n    for c in classes:\n        label_c = label == c\n        if only_present and np.sum(label_c) == 0:\n            ious.append(np.nan)\n            continue\n        pred_c = pred == c\n        intersection = np.logical_and(pred_c, label_c).sum()\n        union = np.logical_or(pred_c, label_c).sum()\n        if union != 0:\n            ious.append(intersection \/ union)\n    return ious if ious else [1]\n\ndef compute_iou_batch(outputs, labels, classes=None):\n    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n    ious = []\n    preds = np.copy(outputs) # copy is imp\n    labels = np.array(labels) # tensor to np\n    for pred, label in zip(preds, labels):\n        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n    iou = np.nanmean(ious)\n    return iou\n","a3a96136":"# code inspired from: https:\/\/github.com\/anandsaha\/pytorch.cyclic.learning.rate\/blob\/master\/cls.py\nfrom torch.optim.optimizer import Optimizer\nclass CyclicLR(object):\n    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n                 step_size=2000, mode='triangular', gamma=1.,\n                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n\n        if not isinstance(optimizer, Optimizer):\n            raise TypeError('{} is not an Optimizer'.format(\n                type(optimizer).__name__))\n        self.optimizer = optimizer\n        self.lr_history = []\n        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n            if len(base_lr) != len(optimizer.param_groups):\n                raise ValueError(\"expected {} base_lr, got {}\".format(\n                    len(optimizer.param_groups), len(base_lr)))\n            self.base_lrs = list(base_lr)\n        else:\n            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n\n        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n            if len(max_lr) != len(optimizer.param_groups):\n                raise ValueError(\"expected {} max_lr, got {}\".format(\n                    len(optimizer.param_groups), len(max_lr)))\n            self.max_lrs = list(max_lr)\n        else:\n            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n\n        self.step_size = step_size\n\n        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n                and scale_fn is None:\n            raise ValueError('mode is invalid and scale_fn is None')\n\n        self.mode = mode\n        self.gamma = gamma\n        \n        #scheduler althorighms\n        if scale_fn is None:\n            if self.mode == 'triangular':\n                self.scale_fn = self._triangular_scale_fn\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = self._triangular2_scale_fn\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = self._exp_range_scale_fn\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n        \n        self.batch_step(last_batch_iteration + 1)\n        self.last_batch_iteration = last_batch_iteration\n\n    def batch_step(self, batch_iteration=None):\n        if batch_iteration is None:\n            batch_iteration = self.last_batch_iteration + 1\n        self.last_batch_iteration = batch_iteration\n        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n            param_group['lr'] = lr\n\n    def _triangular_scale_fn(self, x):\n        return 1.\n\n    def _triangular2_scale_fn(self, x):\n        return 1 \/ (2. ** (x - 1))\n\n    def _exp_range_scale_fn(self, x):\n        return self.gamma**(x)\n\n    def get_lr(self):\n        step_size = float(self.step_size)\n        #why 2* step_size?\n        cycle = np.floor(1 + self.last_batch_iteration \/ (2 * step_size))\n        x = np.abs(self.last_batch_iteration \/ step_size - 2 * cycle + 1)\n\n        lrs = []\n        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n        for param_group, base_lr, max_lr in param_lrs:\n            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n            if self.scale_mode == 'cycle':\n                lr = base_lr + base_height * self.scale_fn(cycle)\n            else:\n                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n            lrs.append(lr)\n        self.lr_history.append(lrs)\n        return lrs","c3695705":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\ntry:\n    from itertools import  ifilterfalse\nexcept ImportError: # py3k\n    from itertools import  filterfalse as ifilterfalse\n    \n\"\"\"\n===================================\nDice Loss\n\"\"\"\ndef make_one_hot(input,num_classes):\n    \"\"\"Convert class index tensor to one hot encoding tensor.\n    Args:\n         input: A tensor of shape [N, 1, *]\n         num_classes: An int of number of class\n    Returns:\n        A tensor of shape [N, num_classes, *]\n    \"\"\"\n    shape = np.array(input.shape)\n    shape[1] = num_classes\n    shape = tuple(shape)\n    result = torch.zeros(shape)\n    result = result.scatter_(1,input.cpu(),1)\n    return result\n\nclass BinaryDiceLoss(nn.Module):\n    \"\"\"Dice loss of binary class\n    Args:\n        smooth: A float number to smooth loss, and avoid NaN error, default: 1\n        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n        predict: A tensor of shape [N, *]\n        target: A tensor of shape same with predict\n        reduction: Reduction method to apply, return mean over batch if 'mean',\n            return sum if 'sum', return a tensor of shape [N,] if 'none'\n    Returns:\n        Loss tensor according to arg reduction\n    Raise:\n        Exception if unexpected reduction\n    \"\"\"\n    def __init__(self, smooth=1, p=1, reduction='mean'):\n        super(BinaryDiceLoss, self).__init__()\n        self.smooth = smooth\n        self.p = p\n        self.reduction = reduction\n        \n    def forward(self, predict, target):\n        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n        predict = predict.contiguous().view(predict.shape[0], -1)\n        target = target.contiguous().view(target.shape[0], -1)\n        \n        if torch.sum(target)>0:\n            num = torch.sum(torch.mul(F.sigmoid(predict),target),dim=1)+self.smooth\n            den = torch.sum(F.sigmoid(predict)+target,dim=1)+self.smooth\n\n            num_ = torch.sum(torch.mul(F.sigmoid(-predict),1-target),dim=1)+self.smooth\n            den_ = torch.sum(F.sigmoid(-predict)+(1-target),dim=1)+self.smooth\n\n            loss_1 = 1-num\/den\n            loss_2 = 1-num_\/den_\n            return (loss_1.sum()+loss_2.sum())\/2\n        else:#no loss for no signals samples\n            return Variable(torch.FloatTensor([0]),requires_grad=True).cuda()[0]\n\nclass DiceLoss(nn.Module):\n    \"\"\"Dice loss, need one hot encode input\n    Args:\n        weight: An array of shape [num_classes,]\n        ignore_index: class index to ignore\n        predict: A tensor of shape [N, C, *]\n        target: A tensor of same shape with predict\n        other args pass to BinaryDiceLoss\n    Return:\n        same as BinaryDiceLoss\n    \"\"\"\n    def __init__(self,weight=None,ignore_index=None,**kwargs):\n        super(DiceLoss, self).__init__()\n        self.kwargs = kwargs\n        self.weight = weight\n        self.ignore_index = ignore_index\n        \n    def forward(self,predict,target):\n        assert predict.shape == target.shape, 'predict & target shape do not match'\n        dice = BinaryDiceLoss(**self.kwargs)\n        total_loss = 0\n        #predict = F.softmax(predict,dim=1)\n        for i in range(target.shape[1]):\n            if i != self.ignore_index:\n                dice_loss = dice(predict[:, i], target[:, i])\n                if self.weight is not None:\n                    assert self.weight.shape[0] == target.shape[1], \\\n                        'Expect weight shape [{}], get[{}]'.format(target.shape[1], self.weight.shape[0])\n                    dice_loss *= self.weights[i]\n                total_loss += dice_loss\n        return total_loss\/target.shape[1]","897f4074":"#model = Unet(encoder_type=\"resnet\",encoder_name=\"resnet50\",classes=4,activation=None)\nmodel = UPPnet(encoder_type=\"resnet\",encoder_name=\"resnet18\",classes=4,activation=None)","d79a2cbd":"model # a *deeper* look","a3d4837a":"class SingleFoldTrainer(object):\n    '''This class takes care of training and validation of our model'''\n    def __init__(self, model,fold_num=0,batch_size ={\"train\": 4, \"valid\": 4},accumulation_step=32,lr=5e-4,num_epochs=20,\\\n                 criterion=None,optim = \"Adam\",scheduler=None):\n        self.fold_num = fold_num\n        self.batch_size = batch_size\n        self.accumulation_steps = accumulation_step \/\/ self.batch_size['train']\n        self.lr = lr\n        self.num_epochs = num_epochs\n        self.best_loss = float(\"inf\")\n        self.phases = [\"train\", \"valid\"]\n        self.device = torch.device(\"cuda:0\")\n        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n        self.net = model\n        self.base_criterion=torch.nn.BCEWithLogitsLoss()\n        self.criterion = criterion\n        if optim==\"Adam\":\n            self.optimizer = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n        elif optim==\"SGD\":\n            self.optimizer = torch.optim.SGD(self.net.parameters(),lr=self.lr)\n        if scheduler:\n            self.scheduler = CyclicLR(self.optimizer,base_lr = self.lr*0.1,max_lr = self.lr,\n                                 step_size=int(len(pd.read_csv(\".\/train_fold_{}.csv\".format(fold_num)))\/self.accumulation_steps),\\\n                                  mode=\"triangular\",gamma=0.994)\n        else:\n            self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n        \n        self.net = self.net.to(self.device)\n        cudnn.benchmark = True\n        self.dataloaders = {\n            phase: provider(\n                data_folder=data_folder,\n                df_path=\".\/{}_fold_{}.csv\".format(phase,fold_num),\n                phase=phase,\n                mean=(0.485, 0.456, 0.406),\n                std=(0.229, 0.224, 0.225),\n                batch_size=self.batch_size[phase],\n            )\n            for phase in self.phases\n        }\n        self.losses = {phase: [] for phase in self.phases}\n        self.iou_scores = {phase: [] for phase in self.phases}\n        self.dice_scores = {phase: [] for phase in self.phases}\n        \n    def forward(self, images, targets):\n        images = images.to(self.device)\n        masks = targets.to(self.device)\n        outputs = self.net(images)\n        if self.criterion is None:\n            loss = 0.5*self.base_criterion(outputs[0], masks)+self.base_criterion(outputs[1], masks)\n        else:\n            loss = 0.5*self.base_criterion(outputs[0], masks)+self.base_criterion(outputs[1], masks)+\\\n             0.5*(self.criterion(outputs[0],masks))+self.criterion(outputs[1],masks)\n        return loss, outputs\n\n    def iterate(self, epoch, phase):\n        meter_1 = Meter(phase, epoch)\n        meter_2 = Meter(phase, epoch)\n        start = time.strftime(\"%H:%M:%S\")\n        print(f\"Starting epoch: {epoch} | phase: {phase} | \u23f0: {start}\")\n        batch_size = self.batch_size[phase]\n        self.net.train(phase == \"train\")\n        dataloader = self.dataloaders[phase]\n        running_loss = 0.0\n        total_batches = len(dataloader)\n        self.optimizer.zero_grad()\n        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n            images, targets = batch\n            loss, outputs = self.forward(images, targets)\n            loss = loss \/ self.accumulation_steps\n            if phase == \"train\":\n                loss.backward()\n                if (itr + 1 ) % self.accumulation_steps == 0:\n                    #self.scheduler.batch_step()\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n            running_loss += loss.item()\n            outputs = [output.detach().cpu() for output in outputs]\n            meter_1.update(targets, outputs[0])\n            meter_2.update(targets, outputs[1])\n        epoch_loss = (running_loss * self.accumulation_steps) \/ total_batches\n        dice, iou = epoch_log(phase, epoch, epoch_loss, meter_1, start)\n        dice, iou = epoch_log(phase, epoch, epoch_loss, meter_2, start)\n        self.losses[phase].append(epoch_loss)\n        self.dice_scores[phase].append(dice)\n        self.iou_scores[phase].append(iou)\n        torch.cuda.empty_cache()\n        return epoch_loss\n\n    def start(self):\n        for epoch in range(self.num_epochs):\n            self.iterate(epoch, \"train\")\n            state = {\n                \"epoch\": epoch,\n                \"best_loss\": self.best_loss,\n                \"state_dict\": self.net.state_dict(),\n                \"optimizer\": self.optimizer.state_dict(),\n            }\n            val_loss = self.iterate(epoch, \"valid\")\n            self.scheduler.step(val_loss)\n            if val_loss < self.best_loss:\n                print(\"******** New optimal found, saving state ********\")\n                state[\"best_loss\"] = self.best_loss = val_loss\n                torch.save(state, \".\/{}_fold_{}.pth\".format(self.net.name,self.fold_num))\n            print()","b9197da4":"sample_submission_path = '..\/input\/severstal-steel-defect-detection\/sample_submission.csv'\ntrain_df_path = '..\/input\/severstal-steel-defect-detection\/train.csv'\ndata_folder = \"..\/input\/severstal-steel-defect-detection\/\"\ntest_data_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"","47119139":"model_trainer = SingleFoldTrainer(model,fold_num=1,num_epochs=16,criterion=None,scheduler=None)\nmodel_trainer.start()","5832ff81":"# PLOT TRAINING\nlosses = model_trainer.losses\ndice_scores = model_trainer.dice_scores # overall dice\niou_scores = model_trainer.iou_scores\n\ndef plot(scores, name):\n    plt.figure(figsize=(15,5))\n    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n    plt.plot(range(len(scores[\"train\"])), scores[\"valid\"], label=f'val {name}')\n    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n    plt.legend(); \n    plt.show()\n\nplot(losses, \"BCE loss\")\nplot(dice_scores, \"Dice score\")\nplot(iou_scores, \"IoU score\")","9058e544":"**## CyClic LR","c9c7b7ad":"**As internet is not allowed for this competition, I tried installing `segmentation_models.pytorch` by source using pip but due to some reasons it didn't work. So, as a [Jugaad](https:\/\/en.wikipedia.org\/wiki\/Jugaad) I took all of `segmentation_models.pytorch`'s UNet code and wrote it in a single file and added it as a dataset so as to use it for this kernel, its dependency [pretrained-models.pytorch](https:\/\/github.com\/Cadene\/pretrained-models.pytorch) is also added as a dataset.","1bd0c888":"## RLE-Mask utility functions","8a21b5c2":"## UNet starter for Steel defect detection challenge\n\n\nThis kernel uses a UNet model with pretrained resnet18 encoder for this challenge, with simple augmentations using albumentations library, uses BCE loss, metrics like Dice and IoU. I've used [segmentation_models.pytorch](https:\/\/github.com\/qubvel\/segmentation_models.pytorch) which comes with a lot pre-implemented segmentation architectures. This is a modified version of my previous [kernel](https:\/\/www.kaggle.com\/rishabhiitbhu\/unet-with-resnet34-encoder-pytorch) for [siim-acr-pneumothorax-segmentation](https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/) competition.","4d5aa8ed":"### Training and Validation","8428122d":"## Imports","11d6003b":"## Some more utility functions\n\nDice and IoU metric implementations, metric logger for training and validation.","956f836a":"**## Dice Loss","0da2d36c":"## Dataloader"}}