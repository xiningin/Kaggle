{"cell_type":{"27a15720":"code","3fc7b852":"code","950d37fd":"code","49e93f60":"code","87f43e8f":"code","ac2cdd28":"code","2937c8c4":"code","a610cb30":"code","e9c55eb9":"code","2ffa6d46":"code","f1be6073":"code","fd20d91d":"code","6d2cabd9":"code","9c9a51ba":"code","78b25c04":"code","f2cd7187":"code","a9526ea9":"code","f3001e6b":"code","d960793b":"code","1eb04b87":"code","ce7e79c2":"code","5e8d7bae":"code","f8062ebb":"markdown","7806f6ff":"markdown","4137b6a6":"markdown","6184a9f2":"markdown","07a1e006":"markdown"},"source":{"27a15720":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import cross_val_score\n\nimport optuna.integration.lightgbm as lgb\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\nfrom optuna.integration import LightGBMPruningCallback\n\nfrom tqdm import tqdm","3fc7b852":"train=pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntest=pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')\nsub=pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')","950d37fd":"conditions = [\n    (train.target == \"Class_1\"),\n    (train.target == \"Class_2\"),\n    (train.target == \"Class_3\"),\n    (train.target == \"Class_4\")\n]\nchoices = [0, 1, 2, 3]\ntrain[\"target\"] = np.select(conditions, choices)","49e93f60":"X_test = test.drop(['id'], axis=1)\nX = train.drop(['id', 'target'], axis=1)\ny = train.target","87f43e8f":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=42)","ac2cdd28":"dtrain = lgb.Dataset(X_train, label=y_train)\ndval = lgb.Dataset(X_val, label=y_val)","2937c8c4":"params = {\n    \"objective\": \"multiclass\",\n    \"num_class\": 4,\n    \"metric\": \"multi_logloss\",\n    \"verbosity\": -1,\n    \"boosting_type\": \"gbdt\",\n    'learning_rate': 0.02,\n    'random_state': 314\n    }","a610cb30":"booster = lgb.train(params, \n                    dtrain, valid_sets=dval,\n                    verbose_eval=0,\n                    early_stopping_rounds=70\n                   )","e9c55eb9":"booster.params","2ffa6d46":"y_pred = booster.predict(X_test, num_iteration=booster.best_iteration)","f1be6073":"sub=pd.concat([\n    test.id,\n    pd.DataFrame(y_pred, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4'])\n], axis=1)\n\nsub.to_csv('lgbm_tuner.csv', index=False)","fd20d91d":"dae_train=pd.read_csv('..\/input\/tps-may2021-r-dae-keras\/daeta_train.csv')\ndae_test=pd.read_csv('..\/input\/tps-may2021-r-dae-keras\/daeta_test.csv')","6d2cabd9":"dae_train[\"target\"] = dae_train.target.str.extract(\"(\\d)\").astype(\"int64\") - 1","9c9a51ba":"X_test = dae_test.drop(['id'], axis=1)\nX = dae_train.drop(['id', 'target'], axis=1)\ny = dae_train.target","78b25c04":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=42)","f2cd7187":"dtrain = lgb.Dataset(X_train, label=y_train)\ndval = lgb.Dataset(X_val, label=y_val)","a9526ea9":"booster = lgb.train(params, \n                    dtrain, valid_sets=dval,\n                    verbose_eval=0,\n                    early_stopping_rounds=70\n                   )","f3001e6b":"booster.params","d960793b":"y_pred_dae = booster.predict(X_test.drop('target', axis=1), num_iteration=booster.best_iteration)","1eb04b87":"sub=pd.concat([\n    test.id,\n    pd.DataFrame(y_pred_dae, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4'])\n], axis=1)\n\nsub.to_csv('lgbm_tuner_dae.csv', index=False)","ce7e79c2":"y_blend = np.zeros([sub.shape[0], 4])\n\nfor j in [0,1, 2, 3]:\n    y_blend[:,j] = (y_pred[:,j] + y_pred_dae[:,j] ) \/ 2","5e8d7bae":"sub=pd.concat([\n    test.id,\n    pd.DataFrame(y_blend, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4'])\n], axis=1)\n\nsub.to_csv('lgbm_tuner_blend.csv', index=False)","f8062ebb":"# Blending","7806f6ff":"# Prepare data","4137b6a6":"# Dependencies","6184a9f2":"# Problem definition\n\nFrom description:\n\n\"The dataset is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Although the features are anonymized, they have properties relating to real-world features.\"\n\n\nSee notebooks using R:\n\n1. [Finding the best pre-processing configuration and predictive models based on the original data](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-r-eda-tidymodels-workflowsets\/)\n2. [Create DAE dataset and fit models in DAE data](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-r-dae-keras) \n4. [Stacking all](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-r-tidymodels-stacks\/)\n\nNotebooks using Python:\n\n1. **LightGbm sequencial tuning with Optuna Step-wise by LightGBM Tuner**\n2. [LightGbm tuning with Optuna TPE (Tree-structured Parzen Estimator)](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-optuna-lightgbm-tpe\/)\n3. [LightGbm tuning one vs rest with Optuna Step-wise by LightGBM Tuner](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-optuna-tuner-one-x-rest\/)\n4. [LightGbm tuning pseudo label with Optuna Tuner](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-lightgbm-pseudolabel\/)\n5. [Stacking All](https:\/\/www.kaggle.com\/gomes555\/tps-may2021-stacking)\n\nAll notebooks will be public and suggestions and criticism are very welcome!\n\n\n<br>\n\n<p align=\"right\"><span style=\"color:firebrick\">Dont forget the upvote if you liked the notebook! <i class=\"fas fa-hand-peace\"><\/i><\/span> <\/p>","07a1e006":"# DAE \n\nData obtained from the notebook developed using the keras library in R: <https:\/\/www.kaggle.com\/gomes555\/tps-may2021-r-dae-keras>"}}