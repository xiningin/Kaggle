{"cell_type":{"c28d03e3":"code","9762e245":"code","c24327c9":"code","6fbe5e0e":"code","fb8d3b41":"code","3581d756":"code","b1810b22":"code","8ce4cc97":"code","f3792990":"code","7079cc6a":"code","0f30fa0c":"code","338afbb1":"code","61a1c9eb":"code","b8a818aa":"code","1b1c07d6":"code","5c800730":"code","b269137f":"code","05a7d322":"code","203bfc13":"code","c6d72918":"code","68d4b4b9":"code","0893351c":"code","9d36e276":"code","e24800d8":"code","4d609a03":"code","6234963e":"code","e556ed71":"code","6981d982":"code","480368ba":"code","774805af":"code","a3860c87":"code","07fc4afe":"markdown","a03b9353":"markdown","cb7b755e":"markdown","6aceef92":"markdown","5995be19":"markdown","1e5bd31f":"markdown","a0c0267b":"markdown","7dbe1d44":"markdown","ff39bed7":"markdown","f12e8744":"markdown","23b81d81":"markdown","ac575a45":"markdown","b72be173":"markdown","4e6deaa0":"markdown","8b8ebc20":"markdown","b91b2579":"markdown","1fe6a3cf":"markdown"},"source":{"c28d03e3":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport logging\nimport datetime\n\nfrom sklearn.preprocessing import OneHotEncoder,MinMaxScaler, Normalizer, LabelEncoder\nfrom sklearn.feature_selection import SelectKBest,chi2,SelectFromModel\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import SimpleImputer\nfrom xgboost import plot_importance\nfrom mlxtend.preprocessing import DenseTransformer\nfrom mlxtend.feature_selection import ColumnSelector\nfrom itertools import product\n\nsns.set(color_codes=True)","9762e245":"def _transfer_type(df, cols, dtype):\n    for v in cols:\n        df[v] = df[v].astype(dtype)\n    \n    return df","c24327c9":"dateparse = lambda x: pd.datetime.strptime(x, '%d.%m.%Y')\nsales_df = pd.read_csv('..\/input\/sales_train.csv', parse_dates = ['date'], date_parser=dateparse)\n\nitem_df = pd.read_csv('..\/input\/items.csv')\nshop_df = pd.read_csv('..\/input\/shops.csv')\ncategory_df = pd.read_csv('..\/input\/item_categories.csv')\n\ntest_df = pd.read_csv('..\/input\/test.csv').set_index('ID')","6fbe5e0e":"sales_df = _transfer_type(sales_df, ['date_block_num', 'shop_id', 'item_id', 'item_cnt_day'], np.int16)\nsales_df = _transfer_type(sales_df, ['item_price'], np.float16)\n\nitem_df = _transfer_type(item_df, ['item_id', 'item_category_id'], np.int16)\nitem_df['item_name'] = item_df['item_name'].astype(str)\n\nshop_df['shop_name'] = shop_df['shop_name'].astype(str)\nshop_df['shop_id'] = shop_df['shop_id'].astype(np.int16)\n\ncategory_df['item_category_name'] = category_df['item_category_name'].astype(str)\ncategory_df['item_category_id'] = category_df['item_category_id'].astype(np.int16)","fb8d3b41":"sales_df = sales_df[sales_df.item_price<100000]\nsales_df = sales_df[sales_df.item_cnt_day<1000]","3581d756":"sales_df[sales_df.item_price < 0]","b1810b22":"sales_df.at[484683, 'item_price'] = sales_df[(sales_df.item_id == 2973) & (sales_df.item_price > 0)].item_price.mean()","8ce4cc97":"shop_df[shop_df.shop_id == 0]","f3792990":"shop_df[shop_df.shop_id == 57]","7079cc6a":"# \u042f\u043a\u0443\u0442\u0441\u043a \u041e\u0440\u0434\u0436\u043e\u043d\u0438\u043a\u0438\u0434\u0437\u0435, 56\nsales_df.at[sales_df.shop_id == 0, 'shop_id'] = 57\n# \u042f\u043a\u0443\u0442\u0441\u043a \u0422\u0426 \"\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u044b\u0439\"\nsales_df.at[sales_df.shop_id == 1, 'shop_id'] = 58\n# \u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439 \u0443\u043b. \u0427\u043a\u0430\u043b\u043e\u0432\u0430 39\u043c\u00b2\nsales_df.at[sales_df.shop_id == 10, 'shop_id'] = 11","0f30fa0c":"def _rename(prefix):\n    cols = ['2013-01', '2013-02', '2013-03', '2013-04','2013-05','2013-06','2013-07','2013-08','2013-09','2013-10','2013-11','2013-12','2014-01','2014-02','2014-03','2014-04','2014-05','2014-06','2014-07','2014-08','2014-09','2014-10','2014-11','2014-12','2015-01','2015-02','2015-03','2015-04','2015-05','2015-06','2015-07','2015-08', '2015-09','2015-10']\n    \n    result = {}\n    for i in range(1, len(cols) + 1, 1):\n        result[cols[i-1]] = prefix + str(i)\n    \n    return result","338afbb1":"import gc\nt = sales_df.groupby([sales_df.date.apply(lambda x: x.strftime('%Y-%m')),'item_id','shop_id']).agg({'item_cnt_day': 'sum'}).reset_index()\n\nt = t[['date','item_id','shop_id','item_cnt_day']]\nt = t.pivot_table(index=['item_id','shop_id'], columns='date',values='item_cnt_day',fill_value=0).reset_index()\nt = t.rename(index=str, columns=_rename('r'))\nsales_detail_df = t.copy()\n\ndel t\ngc.collect()","61a1c9eb":"leak_df = test_df[['item_id', 'shop_id']].drop_duplicates()\nsales_detail_df = pd.merge(sales_detail_df, leak_df, on=['item_id', 'shop_id'], how='outer')\nsales_detail_df = sales_detail_df.fillna(0)\nsales_detail_df.info()","b8a818aa":"def _extract(df, i, is_test=False):\n    arr = ['item_id','shop_id']\n    for j in range(1, 13, 1):\n        arr = arr + ['r' + str(i-j)]\n    \n    if not is_test:\n        arr = arr + ['r' + str(i)]\n    \n    tdf = df[arr]\n    tdf['date_block_num'] = i - 1\n    \n    return tdf","1b1c07d6":"cols = ['item_id','shop_id', 'r1', 'r2', 'r3', 'r4',  'r5', 'r6','r7', 'r8',  'r9', 'r10',  'r11',  'r12', 'item_cnt_month', 'date_block_num']\nsales_record_df = pd.DataFrame(columns=cols)\nfor i in range(13, 35, 1):\n    tdf = _extract(sales_detail_df, i)\n    sales_record_df = sales_record_df.append(pd.DataFrame(columns=cols, data=tdf.values))\n\nsales_record_df['month'] = sales_record_df['date_block_num'].apply(lambda x: (x % 12) + 1)\n\nfor i in range(1, 13, 1):\n    sales_record_df['r'+str(i)] = sales_record_df['r'+str(i)].astype(np.float16)\n\nsales_record_df = _transfer_type(sales_record_df, ['item_id', 'shop_id', 'date_block_num', 'month'], np.int16)\nsales_record_df = _transfer_type(sales_record_df, ['item_cnt_month'], np.float16)\nsales_record_df = sales_record_df.fillna(0)","5c800730":"shop_df.loc[shop_df.shop_name == '\u0421\u0435\u0440\u0433\u0438\u0435\u0432 \u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"', 'shop_name'] = '\u0421\u0435\u0440\u0433\u0438\u0435\u0432\u041f\u043e\u0441\u0430\u0434 \u0422\u0426 \"7\u042f\"'\nshop_df['shop_name'] = shop_df['shop_name'].astype(str)\nshop_df['city'] = shop_df['shop_name'].str.split(' ').map(lambda x: x[0])\nshop_df.loc[shop_df.city == '!\u042f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u042f\u043a\u0443\u0442\u0441\u043a'\n\nencoder = LabelEncoder()\nencoder.fit(shop_df['city'])\nshop_df['city_code'] = encoder.transform(shop_df['city'])","b269137f":"category_df['item_category_name'] = category_df['item_category_name'].astype(str)\ncategory_df['type'] = category_df['item_category_name'].map(lambda x: x.split('-')[0].strip())\n\nencoder = LabelEncoder()\nencoder.fit(category_df['type'])\ncategory_df['type_code'] = encoder.transform(category_df['type'])","05a7d322":"category_df['subtype'] = category_df['item_category_name'].map(lambda x: x.split('-')[1].strip() if len(x.split('-')) > 1 else x.split('-')[0].strip())\n\nencoder = LabelEncoder()\nencoder.fit(category_df['subtype'])\ncategory_df['subtype_code'] = encoder.transform(category_df['subtype'])","203bfc13":"sales_record_df = pd.merge(sales_record_df, item_df, on=['item_id'], how='left')\nsales_record_df = pd.merge(sales_record_df, shop_df, on=['shop_id'], how='left')\nsales_record_df = pd.merge(sales_record_df, category_df, on=['item_category_id'], how='left')\nsales_record_df = sales_record_df.fillna(0)\n\nsales_record_df = sales_record_df.drop(['city', 'type', 'subtype', 'item_name', 'shop_name', 'item_category_name'], axis=1)\nsales_record_df = _transfer_type(sales_record_df, ['item_category_id', 'city_code', 'type_code', 'subtype_code'], np.int16)\n\nsales_record_df.info()","c6d72918":"def _agg(df, cols, prefix):\n    \n    result = df[cols].drop_duplicates()\n    \n    for i in range(1, 13, 1):\n        t = df.groupby(cols)['r'+str(i)].mean().fillna(0).astype(np.float16).reset_index(name=prefix+str(i))\n        result = pd.merge(result, t, on=cols, how='left')\n    \n#     result = _mean(result, prefix)\n    return result","68d4b4b9":"sc_df = _agg(sales_record_df, ['shop_id', 'item_category_id'], 'sc')\ni_df = _agg(sales_record_df, ['item_id'], 'i')\nit_df = _agg(sales_record_df, ['item_category_id'], 'it')\ns_df = _agg(sales_record_df, ['shop_id'], 's')\n\nsales_record_df = pd.merge(sales_record_df, sc_df, on=['shop_id', 'item_category_id'], how='left')\nsales_record_df = pd.merge(sales_record_df, i_df, on=['item_id'], how='left')\nsales_record_df = pd.merge(sales_record_df, it_df, on=['item_category_id'], how='left')\nsales_record_df = pd.merge(sales_record_df, s_df, on=['shop_id'], how='left')","0893351c":"dataset = sales_record_df.copy()\ndataset.columns.values","9d36e276":"dataset_beta = dataset[dataset.date_block_num < 33]\ndataset_alpha = dataset[dataset.date_block_num == 33]","e24800d8":"features = [\n    'item_id', 'shop_id', 'r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7',\n    'r8', 'r9', 'r10', 'r11', 'r12',\n    'date_block_num', 'month', 'item_category_id', 'city_code',\n    'type_code', 'subtype_code',\n    \n    'sc1', 'sc2', 'sc3', 'sc4', 'sc5', 'sc6', 'sc7', 'sc8', 'sc9', 'sc10', 'sc11', 'sc12',\n    'i1', 'i2', 'i3', 'i4', 'i5', 'i6', 'i7', 'i8', 'i9', 'i10', 'i11', 'i12',\n#     'it1', 'it2', 'it3', 'it4', 'it5', 'it6', 'it7', 'it8', 'it9', 'it10', 'it11', 'it12',\n#     's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12',\n]\nlabel = 'item_cnt_month'","4d609a03":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(dataset_beta[features], dataset_beta[label], test_size=0.3, random_state=2019)\n\n# dataset_beta = dataset[(dataset.date_block_num < 24) & (dataset.date_block_num > 17)]\n# train_dataset_x = dataset_beta[features]\n# train_dataset_y = dataset_beta[label].values.ravel()\ntrain_dmatrix = xgb.DMatrix(X_train, label=y_train)\n\ntest_dataset_x = dataset_alpha[features]\ntest_dataset_y = dataset_alpha[label]\ntest_dmatrix = xgb.DMatrix(test_dataset_x, label=test_dataset_y)\n\n# dataset_valid = dataset[(dataset.date_block_num == 32)]\n# valid_dataset_x = dataset_valid[features]\n# valid_dataset_y = dataset_valid[label].values.ravel()\nvalid_dmatrix = xgb.DMatrix(X_test, label=y_test)","6234963e":"from xgboost import XGBRegressor\n\nwatchlist = [(train_dmatrix, 'train'), (valid_dmatrix, 'validate')] \n\nparams = {\n  'booster': 'gbtree',\n  'objective': 'reg:linear',\n  'eta': 0.1,\n  'gamma': 0.7,\n  'min_child_weight': 7,\n  'max_depth': 4,\n  'subsample': 0.5,\n  'colsample_bytree': 0.1,\n  'nthread': 2,\n  'silent': 0,\n  'seed': 2019,\n  \"max_evals\": 200,\n}\n\nwatchlist = [(train_dmatrix, 'train'), (valid_dmatrix, 'validate')] \nbst = xgb.train(params, train_dmatrix, evals=watchlist, early_stopping_rounds=10, num_boost_round=190)","e556ed71":"model = xgb.train(params, train_dmatrix, num_boost_round=bst.best_iteration)","6981d982":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n# t = pd.merge(test_df, dataset_test, on=['shop_id', 'item_id'], how='left')\ntest_dmatrix = xgb.DMatrix(dataset_test[features], label=dataset_test[label])\n\npred = model.predict(test_dmatrix)\nsqrt(mean_squared_error(dataset_test[label], pred))","480368ba":"tdf = _extract(sales_detail_df, 35, is_test=True)\ncols = ['item_id','shop_id', 'r1', 'r2', 'r3', 'r4',  'r5', 'r6','r7', 'r8',  'r9', 'r10',  'r11',  'r12', 'date_block_num']\ndataset_predict_df = pd.DataFrame(columns=cols, data=tdf.values)\ndataset_predict_df = dataset_predict_df.drop_duplicates(['item_id','shop_id'])\n\ndataset_predict_df = pd.merge(test_df, dataset_predict_df, on=['item_id', 'shop_id'], how='left')\ndataset_predict_df = dataset_predict_df.fillna(0)\n\ndataset_predict_df = pd.merge(dataset_predict_df, item_df, on=['item_id'], how='left')\ndataset_predict_df = pd.merge(dataset_predict_df, shop_df, on=['shop_id'], how='left')\ndataset_predict_df = pd.merge(dataset_predict_df, category_df, on=['item_category_id'], how='left')\n\ndataset_predict_df['month'] = dataset_predict_df['date_block_num'].apply(lambda x: (x % 12) + 1)\n\nsc_df = _agg(dataset_predict_df, ['shop_id', 'item_category_id'], 'sc')\ni_df = _agg(dataset_predict_df, ['item_id'], 'i')\nit_df = _agg(dataset_predict_df, ['item_category_id'], 'it')\ns_df = _agg(dataset_predict_df, ['shop_id'], 's')\n\ndataset_predict_df = pd.merge(dataset_predict_df, sc_df, on=['shop_id', 'item_category_id'], how='left')\ndataset_predict_df = pd.merge(dataset_predict_df, i_df, on=['item_id'], how='left')\ndataset_predict_df = pd.merge(dataset_predict_df, it_df, on=['item_category_id'], how='left')\ndataset_predict_df = pd.merge(dataset_predict_df, s_df, on=['shop_id'], how='left')\n\ndataset_predict_df = dataset_predict_df.drop(['city', 'type', 'subtype', 'item_name', 'shop_name', 'item_category_name'], axis=1)\ndataset_predict_df = _transfer_type(dataset_predict_df, ['item_category_id', 'city_code', 'type_code', 'subtype_code', 'month'], np.int16)","774805af":"predict_dmatrix = xgb.DMatrix(dataset_predict_df[features])\npred = model.predict(predict_dmatrix)","a3860c87":"submission = pd.DataFrame({\n    \"ID\": test_df.index, \n    \"item_cnt_month\": pred.clip(0, 20)\n})\n\nsubmission.to_csv('submission.csv', index=False)","07fc4afe":"+ **Feature 'type'**: Each category contains type and subtype in its name.\n+ **Feature 'subtype'**: Each category contains type and subtype in its name.","a03b9353":"## outliers","cb7b755e":"### Correct the negative item price","6aceef92":"## Predict","5995be19":"+ **Feature 'r' series**: Sales record","1e5bd31f":"## Extract Features","a0c0267b":"The shop_id 0 and 57 are the same shop. And other pairs are 1 and 58, 10 and 11.","7dbe1d44":"### Clear the data out of range","ff39bed7":"## Train","f12e8744":"### Adjust duplicates by shop name\n\nAccording to the reference, some shops are duplicates. This feature found is based on the language background.","23b81d81":"## Normal ML Analysis\n\n+ [Feature engineering, xgboost](https:\/\/www.kaggle.com\/dlarionov\/feature-engineering-xgboost)\n+ [Predicting sales using Lightgbm](https:\/\/www.kaggle.com\/sanket30\/predicting-sales-using-lightgbm)","ac575a45":"## Feature Selection","b72be173":"## Merge Data into one entity","4e6deaa0":"+ **Feature 'city'**: Each shop_name starts with the city name.","8b8ebc20":"## Time Series\n\n\u5bf9\u4e8erevenge\u7684\u9884\u6d4b\u5f88\u6709\u5e2e\u52a9\uff0c\u4f46\u662f\u5bf9\u4e8e\u5355\u4e2a\u5e97\u7684\u5355\u4e2a\u5546\u54c1\u800c\u8a00\u6ca1\u6709\u5b9e\u9645\u7684\u610f\u4e49\uff0c\u8fd9\u79cd\u9884\u6d4b\u65b9\u5f0f\u7684\u5b66\u4e60\u975e\u5e38\u6709\u76ca\u5904\n\n+ [AR(I)MA\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u8fc7\u7a0b\u2014\u2014\u6b65\u9aa4\u548cpython\u4ee3\u7801](https:\/\/www.jianshu.com\/p\/cced6617b423)\n+ [python\u65f6\u95f4\u5e8f\u5217\u5206\u6790](http:\/\/www.cnblogs.com\/foley\/p\/5582358.html)\n+ [AR\u3001MA\u53caARMA\u6a21\u578b](https:\/\/zhuanlan.zhihu.com\/p\/22248464)\n+ [Time Series with Python (ODSC) STA.ipynb](https:\/\/github.com\/ultimatist\/ODSC17\/blob\/master\/Time%20Series%20with%20Python%20(ODSC)%20STA.ipynb)\n+ [Getting Started with Time Series](https:\/\/pyflux.readthedocs.io\/en\/latest\/getting_started.html)\n+ [Welcome to Statsmodels\u2019s Documentation](http:\/\/www.statsmodels.org\/devel\/index.html)","b91b2579":"# Reference","1fe6a3cf":"# Features Engineering"}}