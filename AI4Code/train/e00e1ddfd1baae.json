{"cell_type":{"ebffd42d":"code","b52a9d9d":"code","e60bcaa5":"code","d6e79753":"code","5b27f2dc":"code","17501638":"code","6db1fce3":"code","d4841c22":"code","7d076f69":"code","8dff2c4d":"code","afb6add2":"code","a0246eb3":"code","0fa2ac2c":"code","cda4c8fe":"code","595e2b9f":"code","b44271c0":"code","c907b498":"code","0662b456":"code","dc844ad7":"code","b699c5de":"code","1aa4252e":"code","05d22fc7":"markdown","fdfa68b1":"markdown","a31460e8":"markdown","c352284f":"markdown","7c72f843":"markdown","e4765179":"markdown","8ffc29c6":"markdown","c3e562c3":"markdown","3c1bb127":"markdown"},"source":{"ebffd42d":"import seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport gc\npd.set_option('display.max_columns', 200)\n\ntrain_csv = pd.read_csv(\"..\/input\/sf-crime\/train.csv.zip\")\ntest_csv  = pd.read_csv(\"..\/input\/sf-crime\/test.csv.zip\")\nsample_csv  = pd.read_csv(\"..\/input\/sf-crime\/sampleSubmission.csv.zip\")\n# col = ['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict','Resolution', 'Address', 'X', 'Y']\n# train.shape = (878049, 9)\ntrain_csv.head(3)","b52a9d9d":"#@function_define\n# \u30c7\u30fc\u30bf\u5909\u63db\u306b\u3088\u3063\u3066\u30ec\u30b3\u30fc\u30c9\u6570\u304c\u8aa4\u3063\u3066\u5897\u6e1b\u3057\u3066\u3044\u306a\u3044\u304b\u78ba\u8a8d\u3059\u308b\ndef check(pre, new, columns=False):\n    print(\"---------- check ----------\")\n    print(\"pre.shape = \", pre.shape)\n    print(\"new.shape = \", new.shape)\n    if columns:\n        print(\"new.columns = \", new.columns)\n    print(\"---------------------------\")","e60bcaa5":"# train\u30c7\u30fc\u30bf\u306e\u5916\u308c\u5024\u306e\u5206\u5272\ntrain_raw = train_csv[train_csv[\"Y\"] < 60]\ntrain_raw_outlier = train_csv[train_csv[\"Y\"] >= 60]\n\nagg_pddistrict = train_raw[[\"PdDistrict\", \"X\", \"Y\"]].groupby(\n    [\"PdDistrict\"],\n    as_index=False\n).agg(\n    {\"X\": np.mean, \"Y\": np.mean}\n)\ntrain_raw_outlier = train_raw_outlier.drop([\"X\", \"Y\"],axis=1).merge(agg_pddistrict, on=\"PdDistrict\")\ntrain_raw = pd.concat([train_raw, train_raw_outlier], axis=0)\n\ncheck(train_csv, train_raw)\ntrain_raw.head(3)","d6e79753":"# train\u30c7\u30fc\u30bf\u306e\u5916\u308c\u5024\u306e\u5206\u5272\ntest_raw = test_csv[test_csv[\"Y\"] < 60]\ntest_raw_outlier = test_csv[test_csv[\"Y\"] >= 60]\n\nagg_pddistrict = test_raw[[\"PdDistrict\", \"X\", \"Y\"]].groupby(\n    [\"PdDistrict\"],\n    as_index=False\n).agg(\n    {\"X\": np.mean, \"Y\": np.mean}\n)\ntest_raw_outlier = test_raw_outlier.drop([\"X\", \"Y\"],axis=1).merge(agg_pddistrict, on=\"PdDistrict\")\ntest_raw = pd.concat([test_raw, test_raw_outlier], axis=0)\n\nall = pd.concat([train_raw, test_raw], axis=0)[[\"X\", \"Y\"]]\n\ncheck(test_csv, test_raw)\ntest_raw.head(3)","5b27f2dc":"category = train_raw[\"Category\"].drop_duplicates().to_list()","17501638":"#@function_define\n# \u4ea4\u5dee\u70b9\u3067\u8d77\u304d\u305f\u4e8b\u6545\u3001\u4e8b\u4ef6(=Address\u306b\"\/\"\u304c\u5165\u3063\u3066\u3044\u308b)\u3082\u306e\u306f\u3001\u305d\u3046\u3067\u306a\u3044\u3082\u306e\u3068\u5206\u3051\u308b\n\ndef add_intersection(data):\n    data[\"Intersection\"] = data[\"Address\"].str.contains(\"\/\")\n    return data","6db1fce3":"#@function_define\n# \u30b5\u30f3\u30d5\u30e9\u30f3\u30b7\u30b9\u30b3\u3067\u72af\u7f6a\u4ef6\u6570\u304c\u591a\u3044\u901a\u308a\u306e\u540d\u524d\nstreet_name = [\"SAN JOSE AV\", \"DOLORES ST\", \"VALENCIA ST\", \"MISSION ST\"]\ndef add_street_flag(data):\n    def get_st_name(x):\n        st_flag = [(st in x) for st in street_name]\n        if np.any(st_flag):\n            return street_name[st_flag.index(True)]\n        else:\n            return \"\"\n    data[\"Street_flag\"] = data[\"Address\"].map(get_st_name)\n    return data","d4841c22":"#@function_define\n# \u65e5\u4ed8\u304b\u3089\u6708\u3001\u6642\u523b\u3001TimeGroup(\u671d\u663c\u6669\u533a\u5206)\u3092\u8ffd\u52a0\u3059\u308b\u95a2\u6570\n\ndef add_timegroup(data):\n    data[\"Dates\"] = pd.to_datetime(data[\"Dates\"])\n    data[\"Year\"] = data[\"Dates\"].dt.year\n    data[\"Month\"] = data[\"Dates\"].dt.month\n    data[\"Hour\"] = data[\"Dates\"].dt.hour\n    # \u5b9a\u7fa9\u306f\u9069\u5f53\u306bPanasonic\u306e\u30b9\u30de\u30fc\u30c8\u5bb6\u96fb\u304b\u3089https:\/\/panasonic.jp\/pss\/qa\/answer167.html\n    def func_cate(x):\n        if  x >= 3 and x < 11:  # \u671d\u306f\u30013\u6642\u304b\u308910\u664259\u5206\u307e\u3067\n            return \"morning\"\n        elif x >= 11 and x < 18: # \u663c\u306f\u300111\u6642\u304b\u308917\u664259\u5206\u307e\u3067\n            return \"daytime\"\n        else:  # \u591c\u306f18\u6642\u304b\u308926\u664259\u5206\u307e\u3067\n            return \"evening\"\n    data['TimeGroup'] = data[\"Hour\"].apply(func_cate)\n    return data","7d076f69":"#@function_define\n# \u6307\u5b9a\u3057\u305f\u6587\u5b57\u5217\u30ab\u30e9\u30e0\u3092\u6570\u5b57\u306b\u5909\u63db\u3059\u308b(LabelEncode)\nfrom sklearn.preprocessing import LabelEncoder\n\ndef label_encode(data, columns):\n    label_masters = {}\n    for column in columns:\n        le = LabelEncoder()\n        le.fit(data[column])\n        data[column+\"_id\"] = le.transform(data[column])\n        label_masters.update({\n            column: le.classes_\n        })\n    return data, label_masters","8dff2c4d":"#@function_define\n# \u5468\u8fba\u306e\u30ab\u30c6\u30b4\u30ea\u5225\u306e\u72af\u7f6a\u4ef6\u6570\u306e\u5206\u5e03\u3092\u4ed8\u4e0e\u3059\u308b\ndef add_category_distribution(data, x_range, y_range, n_splits):\n    # \u6307\u5b9a\u3057\u305f\u7def\u5ea6\u7d4c\u5ea6\u306e\u7bc4\u56f2\u3092\u3067n_split\u7b49\u5206\u3059\u308b\n    x_div = (x_range[1]-x_range[0])\/n_splits\n    y_div = (y_range[1]-y_range[0])\/n_splits\n    def to_left(v):\n        if type(v) is float:\n            return v\n        else:\n            return v.left\n    data[\"x_group\"] = [to_left(x) for x in pd.cut(\n        data[\"X\"], np.arange(x_range[0], x_range[1]+x_div, x_div), right=False)]\n    data[\"y_group\"] = [to_left(y) for y in pd.cut(\n        data[\"Y\"], np.arange(y_range[0], y_range[1]+x_div, y_div), right=False)]\n    \n    # \u5404\u7bc4\u56f2\u6bce\u306e\u72af\u7f6a\u4ef6\u6570\u3092\u96c6\u8a08\u3059\u308b\n    agg = data.copy()\n    agg[\"count\"] = 1\n    agg = agg.groupby(\n        [\n            \"Category\",\n            \"x_group\",\n            \"y_group\"\n        ],\n        as_index = False\n    ).agg(\n        {\"count\": np.sum}\n    )\n    agg=agg.pivot(\n        index=['x_group', 'y_group'], columns='Category', values='count'\n    ).fillna(0).reset_index()\n    \n    # \u5404\u884c\u3054\u3068\u306b\u72af\u7f6a\u306e\u4ef6\u6570\u304b\u3089\u5272\u5408\u306b\u5909\u63db\u3059\u308b\n    agg_category = agg.drop([\"x_group\", \"y_group\"], axis=1)\n    agg[\"sum\"] = agg_category.sum(axis=1)\n    for col in agg_category.columns:\n        agg[col] = agg[col]\/agg[\"sum\"]\n    agg = agg.drop(\"sum\", axis=1)\n    \n    # data\u306e\u53d6\u308a\u65b9\u306b\u3088\u3063\u3066\u306f\u72af\u7f6a\u4ef6\u6570\u304c0\u4ef6\u306e\u30ab\u30c6\u30b4\u30ea\u304c\u751f\u3058\u308b\n    # \u305d\u306e\u5834\u5408\u306f0\u3067\u57cb\u3081\u308b\n    for col in category:\n        if not col in agg.columns:\n            agg[col] = 0\n\n    return pd.merge(data, agg, on=['x_group', 'y_group'],how='left'), agg","afb6add2":"# \u4e0a\u8a18\u95a2\u6570\u3092\u5229\u7528\u3057\u3066\u7279\u5fb4\u91cf\u751f\u6210\ntrain = train_raw.copy()\ntrain = add_intersection(train)\ntrain = add_street_flag(train)\ntrain = add_timegroup(train)\ntrain, masters = label_encode(train, [\"Street_flag\", \"Category\"])\ncheck(train_raw, train, columns = True)\ntrain.head(3)","a0246eb3":"#@function_define\nfrom sklearn.model_selection import StratifiedKFold\ndef cross_validation():\n    skf = StratifiedKFold(n_splits=config.n_splits)\n    return [v for v in skf.split(train, train[\"Category_id\"])]","0fa2ac2c":"#@function_define\nimport xgboost as xgb\n\ndef run_single_xgboost(dtrain, dvalid, params):\n    evals = [(dtrain, 'train'), (dvalid, 'eval')]\n    \n    # \u5b66\u7fd2\u904e\u7a0b\u3092\u8a18\u9332\u3059\u308b\u305f\u3081\u306e\u8f9e\u66f8\n    evals_result = {}\n\n    # \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u306e\u5b9f\u884c\n    bst = xgb.train(\n        params,\n        dtrain,\n        config.num_round,\n        evals = evals,\n        evals_result = evals_result,\n    )\n\n    return bst, evals_result","cda4c8fe":"#@function_define\n# \u5b66\u7fd2\u7d50\u679c\u306e\u63cf\u753b\nimport operator\nimport datetime\n\ndef visualize(bst, evals_result):\n    train_metric = evals_result['train']['mlogloss']\n    plt.plot(train_metric, label='train mlogloss')\n    eval_metric = evals_result['eval']['mlogloss']\n    plt.plot(eval_metric, label='eval mlogloss')\n    plt.grid()\n    plt.legend()\n    plt.xlabel('rounds')\n    plt.ylabel('mlogloss')\n    plt.show()","595e2b9f":"#@function_define\n\ndef run_fold_xgboost(hyperparams):\n    config.trial_count += 1\n    eta = hyperparams.suggest_uniform('eta', 0.0, 1.0) # \u30c7\u30d5\u30a9\u30eb\u30c8\u306f0.3\n    gamma = hyperparams.suggest_uniform('gamma', 0.0, 100.0) # \u30c7\u30d5\u30a9\u30eb\u30c8\u306f0\n    n_splits_xy = hyperparams.suggest_int('n_splits_xy', 100, 1000)\n    print(\"eta: \", eta)\n    print(\"gamma: \", gamma)\n    print(\"n_splits_xy: \", n_splits_xy)\n    \n    metric = []\n    fold = 0\n    for train_t_iloc, train_v_iloc in config.cross_validation:\n        fold += 1\n        print(\"---- fold \" + str(fold) + \"\/\" + str(config.n_splits) + \" ----\")\n        train_t = train.iloc[train_t_iloc].copy()\n        train_v = train.iloc[train_v_iloc].copy()\n        \n        # \u25a0 \u5468\u8fba\u306e\u30ab\u30c6\u30b4\u30ea\u5225\u306e\u72af\u7f6a\u4ef6\u6570\u3092\u4ed8\u4e0e\u3059\u308b\n        # validation\u30c7\u30fc\u30bf\u306b\u3064\u3051\u305f\u72af\u7f6a\u6570\u5206\u5e03\u306f\u672c\u6765\u4e88\u6e2c\u3057\u3066\u5f97\u3089\u308c\u308b\u3082\u306e\u306a\u306e\u3067\u5916\u3057\u3001\u4ee3\u308f\u308a\u306b\u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u304b\u3089\u4f5c\u6210\u3057\u305f\u72af\u7f6a\u4ef6\u6570\u3092\u4ed8\u4e0e\u3059\u308b\u3002\n        x_range = [min(all[\"X\"]), max(all[\"X\"])]\n        y_range = [min(all[\"Y\"]), max(all[\"Y\"])]\n        train_t, crime_hist = add_category_distribution(train_t, x_range, y_range, n_splits_xy)\n        train_v, _ = add_category_distribution(train_v, x_range, y_range, n_splits_xy)\n        train_v = train_v.drop(category, axis=1)\n        train_v = train_v.merge(crime_hist, on=['x_group','y_group'], how=\"left\")\n        \n        # \u25a0 \u5fc5\u8981\u306a\u30ab\u30e9\u30e0\u3060\u3051\u9078\u629e\n        train_t_select = train_t[[\n            'DayOfWeek',\n            'PdDistrict',\n            'Month',\n            'TimeGroup',\n            'Intersection',\n            'Street_flag_id',\n            'Category_id',\n            *crime_hist.columns\n        ]]\n        train_v_select = train_v[[\n            'DayOfWeek',\n            'PdDistrict',\n            'Month',\n            'TimeGroup',\n            'Intersection',\n            'Street_flag_id',\n            'Category_id',\n            *crime_hist.columns\n        ]]\n\n        # \u25a0 \u6c7a\u5b9a\u6728\u7528\u306b\u30c7\u30fc\u30bf\u3092\u51e6\u7406\n        # One-hot Encoding\u3092\u884c\u3046\n        train_dummies_t = pd.get_dummies(train_t_select)\n        train_dummies_v = pd.get_dummies(train_v_select)\n        # \u7279\u5fb4\u91cf\u3068\u76ee\u7684\u5909\u6570\u3092xgboost\u306e\u30c7\u30fc\u30bf\u69cb\u9020\u306b\u5909\u63db\u3059\u308b\n        dtrain = xgb.DMatrix(train_dummies_t.drop(\"Category_id\", axis=1), label=train_dummies_t[\"Category_id\"])\n        dvalid = xgb.DMatrix(train_dummies_v.drop(\"Category_id\", axis=1), label=train_dummies_v[\"Category_id\"])\n        \n        gc.collect()\n        \n        # \u25a0 \u5b66\u7fd2\u5b9f\u884c\n        # \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8a2d\u5b9a\n        params = {\n            # GPU\n            # \"tree_method\": 'gpu_hist',\n            # 'n_gpus': 1,\n            # Learning Parameters\n            \"objective\": 'multi:softprob',\n            'num_class': 39,\n            'eval_metric':'mlogloss',\n            # Booster Parameters(\u30d9\u30a4\u30ba\u6700\u9069\u5316\u306e\u5bfe\u8c61)\n            # \u56fa\u5b9a\u5024\u306f\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u5b9a\u3081\u3089\u308c\u305f\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u3092\u305d\u306e\u307e\u307e\u5229\u7528\u3057\u3066\u3044\u308b\u3002\n            \"eta\": eta,\n            \"gamma\": gamma,\n            \"max_depth\": 6,\n            \"min_child_weight\": 1,\n            \"max_delta_step\": 0,\n            \"subsample\": 1,\n            \"colsample_bytree\": 1,\n            \"colsample_bylevel\": 1,\n            \"lambda\": 1,\n            \"alpha\": 0\n        }\n        # \u5b66\u7fd2\u3092\u5b9f\u884c\n        bst, evals_result = run_single_xgboost(dtrain, dvalid, params)\n        # \u5b66\u7fd2\u7d50\u679c\u3092\u4fdd\u5b58\n        config.storage_model(bst, fold)\n        config.storage_importance(bst, fold)\n        # \u8a08\u7b97\u7d50\u679c\u3092\u53ef\u8996\u5316\n        # visualize(bst, evals_result)\n        \n        metric.append({\n            \"train_metric\": evals_result['train']['mlogloss'][-1],\n            \"eval_metric\": evals_result['eval']['mlogloss'][-1]\n        })\n    \n    print(\"---- fold finish ----\")\n    # \u8a08\u7b97\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u4fdd\u5b58\n    result = {\n        \"metric\": metric,\n        \"train_ave\": np.mean([m[\"train_metric\"] for m in metric]),\n        \"eval_ave\": np.mean([m[\"eval_metric\"] for m in metric])\n    }\n    config.result.append(result)\n    config.storage_result(result)\n    \n    return result[\"eval_ave\"]","b44271c0":"#@function_define\n# \u5b66\u7fd2\u5168\u822c\u306b\u95a2\u3059\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7ba1\u7406\nimport os\nimport json\nimport pickle\nclass Config(object):\n    def __init__(self):\n        self.n_splits = 4   # Fold\u306e\u6570\n        self.n_trials = 50   # Optuna(\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0)\u306e\u8a66\u884c\u56de\u6570\n        self.num_round = 50   # xgboost\u306e\u8a66\u884c\u56de\u6570\n        \n        self.trial_count = 0\n        self.cross_validation = []\n        self.result = []\n        \n        # model\u306e\u8a08\u7b97\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3059\u308b\u305f\u3081\u306e\u30d5\u30a9\u30eb\u30c0\u3092\u4f5c\u6210\n        dt_now = dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n        self.dir_name = \"model_\" + dt_now\n        os.makedirs(self.dir_name)\n    \n    def storage_model(self, bst, fold):\n        file_name = self.dir_name + \"\/model_trial-\" + str(self.trial_count) + \"_fold-\" + str(fold) + \".bst\"\n        bst.save_model(file_name)\n\n    def storage_importance(self, bst, fold):\n        file_name = self.dir_name + \"\/importance_trial-\" + str(self.trial_count) + \"_fold-\" + str(fold) + \".json\"\n        with open(file_name, 'w') as f:\n            json.dump(bst.get_fscore(), f, indent=2)\n\n    def storage_result(self, result):\n        file_name = self.dir_name + \"\/result_trial-\" + str(self.trial_count) + \".json\"\n        with open(file_name, 'w') as f:\n            json.dump(result, f, indent=2)\n\n    def storage_best_params(self, study):\n        file_name = self.dir_name + \"\/best_params.json\"\n        with open(file_name, 'w') as f:\n            json.dump({\n                \"best_params\": study.best_params,\n                \"best_value\": study.best_value\n            }, f, indent=2)\n    \n    def storage_study(self, study):\n        file_name = self.dir_name + \"\/study.pickle\"\n        with open(file_name, mode=\"wb\") as f:\n            pickle.dump(study, f)\n        \n    def storage_submission(self, submission):\n        file_name = self.dir_name + \"\/submission.csv\"\n        submission.to_csv(file_name, index = False)","c907b498":"import optuna\n\nfolder_name = None\nif folder_name:\n    print(\"----- load \"+folder_name+\" -----\")\n    with open(\".\/\"+folder_name+\"\/study.pickle\", mode=\"rb\") as f:\n        study = pickle.load(f)\nelse:\n    study = optuna.create_study()\n    # hyperparams\u306e\u521d\u671f\u5024\u3092\u8a2d\u5b9a\n    study.enqueue_trial({\n        'eta': 0.14504447778508744,\n        'gamma': 41.441405792041834,\n        'n_splits_xy': 100\n    })\n\n# \u5b66\u7fd2\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\nconfig = Config()\nconfig.n_splits = 3  # Fold\u306e\u6570\nconfig.n_trials = 15   # Optuna(\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0)\u306e\u8a66\u884c\u56de\u6570\nconfig.num_round = 50   # xgboost\u306e\u8a66\u884c\u56de\u6570\n\n# \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\nconfig.cross_validation = cross_validation()\n\n# \u6700\u9069\u306ahyperparams\u63a2\u7d22\u3092\u5b9f\u884c\nstudy.optimize(run_fold_xgboost, n_trials=config.n_trials)","0662b456":"config.storage_best_params(study)\nconfig.storage_study(study)\n\n# \u6700\u9069\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8868\u793a\nprint(study.best_params)\n# \u6700\u5c0f\u5316\u3055\u308c\u305f\u76ee\u7684\u95a2\u6570\u3092\u8868\u793a\nprint(study.best_value)","dc844ad7":"# \u25a0 \u5468\u8fba\u306e\u30ab\u30c6\u30b4\u30ea\u5225\u306e\u72af\u7f6a\u4ef6\u6570\u3092\u4ed8\u4e0e\u3059\u308b\nx_range = [min(all[\"X\"]), max(all[\"X\"])]\ny_range = [min(all[\"Y\"]), max(all[\"Y\"])]\ntrain_all, _ = add_category_distribution(train, x_range, y_range, study.best_params[\"n_splits_xy\"])\n\n# \u25a0 \u5fc5\u8981\u306a\u30ab\u30e9\u30e0\u3060\u3051\u9078\u629e\ntrain_all_select = train_all[[\n    'DayOfWeek',\n    'PdDistrict',\n    'Month',\n    'TimeGroup',\n    'Intersection',\n    'Street_flag_id',\n    'Category_id',\n    *_.columns\n]]\n\n# \u25a0 \u6c7a\u5b9a\u6728\u7528\u306b\u30c7\u30fc\u30bf\u3092\u51e6\u7406\n# One-hot Encoding\u3092\u884c\u3046\ntrain_dummies_all = pd.get_dummies(train_all_select)\n\n# \u7279\u5fb4\u91cf\u3068\u76ee\u7684\u5909\u6570\u3092xgboost\u306e\u30c7\u30fc\u30bf\u69cb\u9020\u306b\u5909\u63db\u3059\u308b\ndtrain_all = xgb.DMatrix(train_dummies_all.drop(\"Category_id\", axis=1), label=train_dummies_all[\"Category_id\"])\n\ngc.collect()\n# \u25a0 \u5b66\u7fd2\u5b9f\u884c\n# \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8a2d\u5b9a\nconfig.num_round = 100   # xgboost\u306e\u8a66\u884c\u56de\u6570\nparams = {\n    # Learning Parameters\n    \"objective\": 'multi:softprob',\n    'num_class': 39,\n    'eval_metric':'mlogloss',\n    # Booster Parameters(\u30d9\u30a4\u30ba\u6700\u9069\u5316\u306e\u5bfe\u8c61)\n    # \u56fa\u5b9a\u5024\u306f\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u5b9a\u3081\u3089\u308c\u305f\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u3092\u305d\u306e\u307e\u307e\u5229\u7528\u3057\u3066\u3044\u308b\u3002\n    \"eta\": study.best_params[\"eta\"],\n    \"gamma\": study.best_params[\"gamma\"],\n    \"max_depth\": 6,\n    \"min_child_weight\": 1,\n    \"max_delta_step\": 0,\n    \"subsample\": 1,\n    \"colsample_bytree\": 1,\n    \"colsample_bylevel\": 1,\n    \"lambda\": 1,\n    \"alpha\": 0\n}\n# \u5b66\u7fd2\u3092\u5b9f\u884c\nbst, evals_result = run_single_xgboost(dtrain_all, dtrain_all, params)\n# \u5b66\u7fd2\u7d50\u679c\u3092\u4fdd\u5b58\nconfig.trial_count = \"finish\"\nconfig.storage_model(bst, 0)\nconfig.storage_importance(bst, 0)\n# \u8a08\u7b97\u7d50\u679c\u3092\u53ef\u8996\u5316\nvisualize(bst, evals_result)","b699c5de":"test = test_raw.copy()\ntest = add_intersection(test)\ntest = add_street_flag(test)\ntest = add_timegroup(test)\ntest, _ = label_encode(test, [\"Street_flag\"])\n\ntmp = test.copy()\ntmp[\"Category\"] = \"-\"\nx_range = [min(all[\"X\"]), max(all[\"X\"])]\ny_range = [min(all[\"Y\"]), max(all[\"Y\"])]\n_, master_all = add_category_distribution(train_raw, x_range, y_range, study.best_params[\"n_splits_xy\"])\ntmp, _ = add_category_distribution(tmp, x_range, y_range, study.best_params[\"n_splits_xy\"])\ntest = tmp.drop([\"-\"]+category, axis=1).merge(master_all, on=['x_group', 'y_group'], how=\"left\")\n\ntest_select = test[[\n    'DayOfWeek',\n    'PdDistrict',\n    'Month',\n    'TimeGroup',\n    'Street_flag',\n    'Street_flag_id',\n    'Intersection',\n    *master_all.columns\n]]\n\n\ntest_dummies = pd.get_dummies(test_select)\nprint(test.shape)\ntest_dummies.head(3)","1aa4252e":"test_dummies_select = test_dummies[[*train_dummies_all.drop(\"Category_id\", axis=1).columns]]\n\ndtest = xgb.DMatrix(test_dummies_select)\npred_test = bst.predict(dtest)\n\n# \u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\nsubmisson = pd.DataFrame(pred_test, columns = masters[\"Category\"])\nsubmisson[\"Id\"] = test_raw[\"Id\"].to_list()\n\nconfig.storage_submission(submisson)\n\nsubmisson.head(3)","05d22fc7":"## XGBoost\nxgboost\u30e9\u30a4\u30d6\u30e9\u30ea\u306exgb.train\u3092\u5229\u7528\u3059\u308b","fdfa68b1":"## \u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\nOptuna\u3092\u5229\u7528\u3057\u3066\u3001xgboost\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u3002  \nxgboost\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u3064\u3044\u3066\u306f[\u3053\u3061\u3089\u306eQiita\u8a18\u4e8b](https:\/\/qiita.com\/FJyusk56\/items\/0649f4362587261bd57a)\u3092\u53c2\u8003\u306b\u3057\u305f\u3002  \noptuna\u306e\u4f7f\u3044\u65b9\u306b\u95a2\u3057\u3066\u306f[\u3053\u3061\u3089\u306eQiita\u8a18\u4e8b](https:\/\/qiita.com\/mamorous3578\/items\/912f1a2be0e9da7e9140)\u3092\u53c2\u8003\u306b\u3057\u305f\u3002","a31460e8":"# train\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u3066\u5b66\u7fd2\u3059\u308b","c352284f":"# \u30de\u30b9\u30bf\u3092\u4f5c\u6210","7c72f843":"## \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\nStratifiedKFold\u306f\u6307\u5b9a\u3057\u305f\u30ab\u30c6\u30b4\u30ea\u30fc\u304c\u5404fold\u306b\u5747\u7b49\u306b\u914d\u5206\u3055\u308c\u308b\u3088\u3046\u306b\u5206\u5272\u3057\u3066\u304f\u308c\u308b\u3002  \n\u4eca\u56de\u306fCategory\u6bce\u306b\u30ec\u30b3\u30fc\u30c9\u6570\u306b\u5927\u304d\u306a\u5dee\u304c\u3042\u308a\u3001\u666e\u901a\u306eKFold\u3092\u4f7f\u3046\u3068Category\u306b\u504f\u308a\u304c\u751f\u3058\u3066\u3057\u307e\u3046\u305f\u3081\u3001StratifiedKFold\u3092\u5229\u7528\u3057\u3066\u3044\u308b","e4765179":"# \u7279\u5fb4\u91cf\u751f\u6210\u306b\u5229\u7528\u3059\u308b\u95a2\u6570\u306e\u5b9a\u7fa9","8ffc29c6":"# \u30ab\u30c6\u30b4\u30ea\u3092\u4e88\u6e2c\n## \u7279\u5fb4\u91cf\n\n## \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\nXGBoost\n\n## \u7d50\u679c","c3e562c3":"# \u5916\u308c\u5024\u306e\u51e6\u7406\nX=-120.5, Y=90\u306b\u306a\u3063\u3066\u3044\u308b\u30ec\u30b3\u30fc\u30c9\u3092\u5916\u308c\u5024\u3068\u3057\u3066\u6271\u3046\u3002\u304a\u305d\u3089\u304f\u4f55\u304b\u3057\u3089\u306e\u4e0d\u5177\u5408\uff1f\n\n\u975e\u5916\u308c\u5024\u5074\u306ePdDistrict\u6bce\u306eX\u3068Y\u306e\u5e73\u5747\u3092\u8a08\u7b97\u3057\u3001\u5916\u308c\u5024\u5074\u306eX,Y\u3092\u305d\u308c\u306b\u7f6e\u304d\u63db\u3048\u308b","3c1bb127":"# Submit"}}