{"cell_type":{"2689ea87":"code","5707b79d":"code","3ce8339e":"code","22d57a4d":"code","c9bf5a17":"code","e2bc00d3":"code","17b16fd8":"code","18d2a66a":"code","752c52b8":"code","4588aafa":"code","a758dd8f":"code","4c2147e8":"code","de967134":"code","d5b80445":"code","5fa3c30e":"code","8516ad13":"code","43fa2044":"code","f362441f":"code","3186bb59":"code","cf8c6007":"code","a24508d1":"code","06096a4d":"code","88a64070":"code","b83bf20e":"code","ae352293":"code","c9160d72":"code","9982eb0c":"code","f667b024":"code","ad6d108b":"code","e68606b7":"code","2c806aeb":"code","073ade8b":"code","f6a8ea6c":"code","697707fa":"code","170cd7f3":"markdown","53c07389":"markdown","99e16100":"markdown"},"source":{"2689ea87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5707b79d":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","3ce8339e":"train.head()","22d57a4d":"test.info()","c9bf5a17":"train.isnull().sum()","e2bc00d3":"test.isnull().sum()","17b16fd8":"#Treat Age\ntrain['Age'] = train['Age'].fillna(value=train['Age'].median())\ntest['Age'] = test['Age'].fillna(value=test['Age'].median())","18d2a66a":"#Treat Fare\ntrain['Fare'] = train['Fare'].fillna(value=train['Fare'].median())\ntest['Fare'] = test['Fare'].fillna(value=test['Fare'].median())","752c52b8":"train['Embarked'].mode()[0]","4588aafa":"#Treat Embarked\ntrain['Embarked'] = train['Embarked'].fillna(value=train['Embarked'].mode()[0])\ntest['Embarked'] = test['Embarked'].fillna(value=test['Embarked'].mode()[0])","a758dd8f":"#Treat Cabin\ntrain['Cabin'] = train['Cabin'].fillna('Missing')\ntrain['Cabin'] = train['Cabin'].str[0]\ntrain['Cabin'].value_counts()","4c2147e8":"#Treat Cabin\ntest['Cabin'] = test['Cabin'].fillna('Missing')\ntest['Cabin'] = test['Cabin'].str[0]\ntest['Cabin'].value_counts()","de967134":"#Extract Title from Name\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","d5b80445":"#We will combine a few categories, since few of them are unique \ntrain['Title'] = train['Title'].replace(['Capt', 'Dr', 'Major', 'Rev'], 'Officer')\ntrain['Title'] = train['Title'].replace(['Lady', 'Countess', 'Don', 'Sir', 'Jonkheer', 'Dona'], 'Royal')\ntrain['Title'] = train['Title'].replace(['Mlle', 'Ms'], 'Miss')\ntrain['Title'] = train['Title'].replace(['Mme'], 'Mrs')\ntrain['Title'].value_counts()","5fa3c30e":"#We will combine a few categories, since few of them are unique \ntest['Title'] = test['Title'].replace(['Capt', 'Dr', 'Major', 'Rev'], 'Officer')\ntest['Title'] = test['Title'].replace(['Lady', 'Countess', 'Don', 'Sir', 'Jonkheer', 'Dona'], 'Royal')\ntest['Title'] = test['Title'].replace(['Mlle', 'Ms'], 'Miss')\ntest['Title'] = test['Title'].replace(['Mme'], 'Mrs')\ntest['Title'].value_counts()","8516ad13":"#Family Size & Alone \ntrain['Family_Size'] = train['SibSp'] + train['Parch'] + 1\ntrain['IsAlone'] = 0\ntrain.loc[train['Family_Size']==1, 'IsAlone'] = 1","43fa2044":"#Family Size & Alone \ntest['Family_Size'] = test['SibSp'] + test['Parch'] + 1\ntest['IsAlone'] = 0\ntest.loc[train['Family_Size']==1, 'IsAlone'] = 1","f362441f":"train.head()","3186bb59":"all = pd.concat([train, test], sort = False)\nall.info()","cf8c6007":"all_dummies = pd.get_dummies(all.drop(['Name', 'Ticket'], axis = 1), drop_first = True)\nall_dummies.head()","a24508d1":"all_train = all_dummies[all_dummies['Survived'].notna()]","06096a4d":"all_test = all_dummies[all_dummies['Survived'].isna()]","88a64070":"y = all_train['Survived']\nX = all_train.drop(['Survived', 'PassengerId'], axis = 1)","b83bf20e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=101)","ae352293":"from sklearn.linear_model import LogisticRegression","c9160d72":"logModel = LogisticRegression(max_iter = 5000)\nlogModel.fit(X_train, y_train)","9982eb0c":"predictions = logModel.predict(X_test)\npredictions","f667b024":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predictions))","ad6d108b":"logModel.score(X_train, y_train)","e68606b7":"logModel.score(X_test, y_test)","2c806aeb":"X_Submission = all_test.drop(['PassengerId', 'Survived'], axis = 1)","073ade8b":"pred_for_submission = logModel.predict(X_Submission).astype(int)","f6a8ea6c":"logSub = pd.DataFrame({'PassengerId': all_test['PassengerId'], 'Survived':pred_for_submission })\nlogSub.head(1)","697707fa":"logSub.to_csv(\"1_Logistics_Regression_Submission.csv\", index = False)","170cd7f3":"# Process Data for Modelling","53c07389":"# Log Model","99e16100":"# Make Submission"}}