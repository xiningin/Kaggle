{"cell_type":{"2902074c":"code","d8e93924":"code","bf32f2c4":"code","e1b2004d":"code","09ef56f2":"code","0029b790":"code","cfbfc33d":"code","35992388":"code","a5c57b26":"code","a502f078":"code","3a7a0bee":"code","89472d89":"code","93f02ce5":"code","ffbea995":"code","0caf3ef5":"code","db3a89cb":"markdown","428f29ff":"markdown"},"source":{"2902074c":"from keras.datasets.mnist import load_data\n\nmnist = load_data()","d8e93924":"X_train, y_train, X_test, y_test = mnist[0][0], mnist[0][1], mnist[1][0], mnist[1][1]","bf32f2c4":"import matplotlib.pyplot as plt\n\nsome_digit = X_train[36000]\nplt.imshow(some_digit, cmap=plt.cm.binary)\nplt.show()","e1b2004d":"X_train, X_valid = X_train[:50000] \/ 255., X_train[50000:] \/ 255.\ny_train, y_valid = y_train[:50000], y_train[50000:]\nX_test = X_test \/ 255.","09ef56f2":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras","0029b790":"keras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)","cfbfc33d":"K = keras.backend\n\nclass ExponentialLearningRate(keras.callbacks.Callback):\n    def __init__(self, factor):\n        self.factor = factor\n        self.rates = []\n        self.losses = []\n    def on_batch_end(self, batch, logs):\n        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n        self.losses.append(logs[\"loss\"])\n        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)","35992388":"model = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(300, activation=\"relu\"),\n    keras.layers.Dense(100, activation=\"relu\"),\n    keras.layers.Dense(10, activation=\"softmax\")\n])\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n                optimizer=keras.optimizers.SGD(lr=1e-5),\n                metrics=[\"accuracy\"])\nexpon_lr = ExponentialLearningRate(factor=1.005)\nhistory = model.fit(X_train, y_train, epochs=2, validation_data=(X_valid, y_valid),\n          callbacks=[expon_lr])","a5c57b26":"import plotly.graph_objects as go\n\nfig = go.Figure(data=[go.Scatter(x=expon_lr.rates, y=expon_lr.losses, mode=\"markers\", marker=dict(size=3))])\nfig.update_layout(title=\"Exponential Learning Rate\", xaxis_title=\"Learning Rate\", yaxis_title=\"Loss\")\nfig.update_yaxes(type=\"log\")\nfig.show()","a502f078":"keras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)","3a7a0bee":"import os\nroot_logdir = os.path.join(os.curdir, \"my_logs\")","89472d89":"def get_run_logdir():\n    import time\n    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n    return os.path.join(root_logdir, run_id)\n\nrun_logdir = get_run_logdir()\nrun_logdir","93f02ce5":"lr = 0.2\nmodel = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(300, activation=\"relu\"),\n    keras.layers.Dense(100, activation=\"relu\"),\n    keras.layers.Dense(10, activation=\"softmax\")\n])\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n                optimizer=keras.optimizers.SGD(learning_rate=lr),\n                metrics=[\"accuracy\"])\n\ncheckpoint_cb = keras.callbacks.ModelCheckpoint('MNIST\/my_model.h5', save_best_only=True)\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n                                                  restore_best_weights=True)\ntensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n\nhistory = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])","ffbea995":"import pandas as pd\nfrom plotly.subplots import make_subplots\n\nhist_df = pd.DataFrame(history.history)\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Loss\", \"Accuracy\"))\nfig.add_trace(go.Scatter(x=hist_df.index, y=hist_df[\"loss\"], name=\"Train\"), 1, 1)\nfig.add_trace(go.Scatter(x=hist_df.index, y=hist_df[\"val_loss\"], name=\"Validation\"), 1, 1)\nfig.add_trace(go.Scatter(x=hist_df.index, y=hist_df[\"accuracy\"], name=\"Train\"), 1, 2)\nfig.add_trace(go.Scatter(x=hist_df.index, y=hist_df[\"val_accuracy\"], name=\"Validation\"), 1, 2)\nfig.update_layout(title=\"Training History\", xaxis_title=\"Epoch\")\nfig.show()","0caf3ef5":"best_model = keras.models.load_model('MNIST\/my_model.h5')\nbest_model.evaluate(X_test, y_test)","db3a89cb":"## Hyperparameter tuning","428f29ff":"### Improve Learning rate"}}