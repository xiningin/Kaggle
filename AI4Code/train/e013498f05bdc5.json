{"cell_type":{"46e3fef3":"code","25237c28":"code","7d1bb6f1":"code","da5ad004":"code","40b48458":"code","ba699265":"code","5ac214e9":"code","787215db":"code","37b3c4b5":"code","26ead33f":"code","82d25ce0":"code","0cabb406":"code","365e033b":"code","bcf912c5":"code","e6fdc59d":"code","44721427":"code","3cb96894":"code","8c404532":"markdown","145fed56":"markdown","557b5894":"markdown","d4fcd691":"markdown","43a51512":"markdown","ae203d32":"markdown","cbb84a49":"markdown"},"source":{"46e3fef3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport tensorflow as tf\nimport pathlib\nimport pickle","25237c28":"def load_images(source_dir):\n    images = pathlib.Path(source_dir).glob(\"**\/*.jpg\")\n    images = list(images)\n    images = [str(x) for x in images]\n    df = pd.DataFrame()\n    df[\"Path\"] = images\n    df['Label'] = df['Path'].apply(lambda x: 1 if '1' in x else 0)\n    return df.sample(df.shape[0],random_state=1)\ndf_images = load_images(\"..\/input\/facemask-dataset\/dataset\")\n\ndf_images.head()","7d1bb6f1":"df_images['Label'].value_counts()","da5ad004":"def replicate(df,label,minority_class,majority_class):\n    df_res = df.copy()\n    while (df_res[df_res[label] == majority_class].shape[0] - df_res[df_res[label] == minority_class].shape[0]) > df_res[df_res[label] == minority_class].shape[0]:\n        #print('i')\n        df_res = pd.concat([df,df[df[label] == minority_class]],axis=0)\n    \n    x = df_res[df_res[label] == majority_class].shape[0] - df_res[df_res[label] == minority_class].shape[0]\n    if x > df_res[df_res[label] == minority_class].shape[0]:\n        df_res = pd.concat([df_res,df[df[label] == minority_class].sample(x,random_state=5)])\n    return df_res","40b48458":"final_images = replicate(df_images,'Label',0,1)\nfinal_images.shape","ba699265":"from skimage.io import imread\nfrom skimage.transform import rescale,resize\n\n\n\n\ndef scale_image(img):\n    img[:,:,0] = (img[:,:,0] - np.min(img[:,:,0]))\/(np.max(img[:,:,0]) - np.min(img[:,:,0]))\n    img[:,:,1] = (img[:,:,1] - np.min(img[:,:,1]))\/(np.max(img[:,:,1]) - np.min(img[:,:,1]))\n    img[:,:,2] = (img[:,:,2] - np.min(img[:,:,2]))\/(np.max(img[:,:,2]) - np.min(img[:,:,2]))\n    return img\n\n\n\n\n\ndef get_num_batches(total_imgs,batch_size):\n    if total_imgs % batch_size == 0:\n        return total_imgs \/\/ batch_size\n    else:\n        return total_imgs \/\/ batch_size + 1\n    \n    \n\n### Data Generator Labels have to be 0,1,...n-1 where n is the number of classes\ndef prepare_data(dataset,img_path_col,target_label_col,num_classes, batch_size, input_shape=(256,256,3)):\n    num_images = dataset.shape[0]\n    batches = get_num_batches(num_images,batch_size)\n    while True:\n        for batch in range(batches):\n            if num_images % batch_size == 0 or batch < batches - 1:\n                images = np.zeros((batch_size, input_shape[0],input_shape[1],input_shape[2]))\n                labels = np.zeros((batch_size,num_classes))\n                for b in range(batch_size):\n                    image = imread(dataset.iloc[batch*batch_size + b].loc[img_path_col])\n                    image = resize(image,input_shape)\n                    image = scale_image(image)\n\n                    images[b,:,:,:] = image\n                    cat = dataset.iloc[batch*batch_size + b].loc[target_label_col]\n                    labels[b,cat] = 1\n                yield images,labels\n\n            else:\n                images = np.zeros((num_images % batch_size, input_shape[0],input_shape[1],input_shape[2]))\n                labels = np.zeros((num_images % batch_size,num_classes))\n                for b in range(num_images % batch_size):\n\n                    image = imread(dataset.iloc[batch*batch_size + b].loc[img_path_col])\n\n                    image = resize(image,input_shape)\n                    image = scale_image(image)\n                    images[b,:,:,:] = image\n                    cat = dataset.iloc[batch*batch_size + b].loc[target_label_col]\n                    labels[b,cat] = 1\n                yield images,labels\n","5ac214e9":"img = imread(\"..\/input\/facemask-dataset\/dataset\/dataset\/0\/12.jpg\")\nplt.imshow(resize(img,(256,256,3)))\n","787215db":"from sklearn.model_selection import train_test_split\n\ntrain_img,val_imgs = train_test_split(final_images,random_state=10)","37b3c4b5":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,GlobalAveragePooling2D\nfrom tensorflow.keras.applications import MobileNet,ResNet50,VGG19\nfrom tensorflow.keras.layers import Dense, Dropout","26ead33f":"model_1 = Sequential()\nmodel_1.add(Conv2D(64,(3,3),activation='relu',input_shape=(256,256,3)))\nmodel_1.add(MaxPool2D())\nmodel_1.add(Conv2D(128,(3,3),activation='relu'))\nmodel_1.add(MaxPool2D())\nmodel_1.add(Flatten())\nmodel_1.add(Dropout(0.2))\nmodel_1.add(Dense(2,activation='softmax'))\n\n### Compile the model\n\nmodel_1.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n\n\n","82d25ce0":"model_1.summary()\n","0cabb406":"train_data = prepare_data(train_img,'Path','Label',2,32)\nval_data = prepare_data(val_imgs,'Path','Label',2,32)\n\nhistory = model_1.fit_generator(train_data,validation_data=val_data,steps_per_epoch=33,validation_steps=11,epochs=10)","365e033b":"obs = history.history\n\nplt.figure(figsize=(10,8))\nplt.subplot(1,2,1)\nplt.plot(range(1,11),obs['loss'])\nplt.plot(range(1,11),obs['val_loss'])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\n\n\nplt.subplot(1,2,2)\nplt.plot(range(1,11),obs['accuracy'])\nplt.plot(range(1,11),obs['val_accuracy'])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")","bcf912c5":"m1 = MobileNet(include_top=False,input_shape=(256,256,3))\nm1.trainable = False\nmodel = Sequential()\nmodel.add(m1)\nmodel.add(Flatten())\nmodel.add(Dropout(0.15))\nmodel.add(Dense(2,activation='softmax'))\n\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics='categorical_accuracy')\n\nmodel.summary()","e6fdc59d":"model.fit_generator(train_data,steps_per_epoch=33,validation_data=val_data,validation_steps=11,epochs=5)","44721427":"model.save(\"model.pkl\")","3cb96894":"model_1.save('cnn.pkl')","8c404532":"## Let us prepare the data","145fed56":"### Now let us prepare data for training and validation","557b5894":"### Let us build a model","d4fcd691":"### Observation:\n- After 5 Epochs model overfitted\n\n- Let us try Transfer Learning","43a51512":"### Due to the class imbalance we will duplicate some images","ae203d32":"### Let us check the class distribution ","cbb84a49":"### Let us not generate data"}}