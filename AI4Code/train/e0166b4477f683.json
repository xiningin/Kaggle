{"cell_type":{"ab047c24":"code","7b2110f1":"code","f9f1374a":"code","6d11f9cb":"code","c19cdafa":"code","6666dfd2":"code","0ca73132":"code","864c8570":"code","e8915dc4":"code","03166b8e":"code","8b36a43c":"code","f628dead":"code","913c7f01":"code","d7711178":"code","a56e3901":"code","b59cc62a":"code","2679d993":"code","1c7b0077":"code","894629ff":"code","4b041908":"code","ddae7d8f":"code","b2c91816":"code","0a2932c8":"code","1f44a804":"code","f1f67be9":"markdown","08bfe631":"markdown","84d11ab5":"markdown","6998ad72":"markdown","1173c816":"markdown","40c02d79":"markdown","91bfadf0":"markdown","2ec36636":"markdown","8cfc98b1":"markdown"},"source":{"ab047c24":"#import libraries\nimport numpy as np                                                      #for fast operations on arrays    \nimport pandas as pd                                                     #for read & manipulate dataset\nimport matplotlib.pyplot as plt                                         #for Data visualization\nimport seaborn as sns                                                   #for Data visualization\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","7b2110f1":"#load dataset\ndf = pd.read_csv('..\/input\/samplesuperstore\/SampleSuperstore.csv')\ndataset = df.copy()\ndataset.head()","f9f1374a":"dataset.columns","6d11f9cb":"dataset.info()","c19cdafa":"print(\"Nimber of rows : {}\".format(dataset.shape[0]))","6666dfd2":"#Check Missing Values\ndef check_missing(data):\n    total = data.isnull().sum().sort_values(ascending=False)\n    percent = (data.isnull().sum()\/data.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data.head()\n\ncheck_missing(dataset)","0ca73132":"#check duplicate rows\ndef check_duplicate(data):\n    duplicate = data.duplicated()\n    unique_data  = pd.Series(data.shape[0] - duplicate.value_counts()[1])\n    duplicate_data = pd.Series(data.shape[0] - duplicate.value_counts()[0])\n    unique_data_percent = pd.Series((unique_data\/data.shape[0])*100)\n    duplicate_data_percent = pd.Series((duplicate_data\/data.shape[0])*100)\n    dub = pd.concat([unique_data, duplicate_data,unique_data_percent,duplicate_data_percent], axis=1, keys=['Unique Count', 'Duplicate Count','Unique percent','Duplicate Percent'])\n    return dub\n\ncheck_duplicate(dataset)","864c8570":"#Drop duplicates\ndataset.drop_duplicates(inplace=True)","e8915dc4":"dataset['Ship Mode'].value_counts().plot(kind='pie',figsize=[8,8],autopct='%1.1f%%')","03166b8e":"dataset['Region'].value_counts().plot(kind='pie',figsize=[8,8],autopct='%1.1f%%')","8b36a43c":"dataset['Category'].value_counts().plot(kind='pie',figsize=[8,8],autopct='%1.1f%%')","f628dead":"dataset['Sub-Category'].value_counts().plot(kind='barh',figsize=[8,8])","913c7f01":"dataset[['Ship Mode','Sales']].groupby(['Ship Mode']).sum().plot(kind='pie',subplots=True,figsize=[10,10],autopct='%1.1f%%')","d7711178":"dataset[['Ship Mode','Profit']].groupby(['Ship Mode']).sum().plot(kind='barh',figsize=[8,8])","a56e3901":"dataset[['Segment','Sales']].groupby(['Segment']).sum().plot(kind='pie',subplots=True,figsize=[10,10],autopct='%1.1f%%')","b59cc62a":"fig, axs = plt.subplots(ncols=2,  figsize = (20,15))\nsns.countplot(x=\"Ship Mode\", hue ='Category', data = dataset,  ax = axs[0])\nsns.countplot(x=\"Ship Mode\", hue ='Sub-Category', data = dataset,  ax = axs[1])\naxs[0].set_title('Category Wise', fontsize = 20)\naxs[1].set_title('Sub-category Wise', fontsize = 20)\nplt.show()","2679d993":"plt.subplots(figsize = (20,15))\nsns.countplot(x=\"Category\", hue ='Sub-Category', data = dataset)\nplt.title('Category Vs. Sub-category', fontsize = 30)\nplt.show()","1c7b0077":"dataset['State'].value_counts().plot(kind='barh',figsize=[10,10])","894629ff":"dataset[['Segment','Profit']].groupby(['Segment']).sum().plot(kind='barh',figsize=[8,8])","4b041908":"dataset[['State','Profit']].groupby(['State']).sum().sort_values(by = ['Profit']).plot(kind='barh',figsize=[10,10])","ddae7d8f":"dataset[['Category','Sales']].groupby(['Category']).sum().plot(kind='pie',figsize=[10,10],subplots=True,autopct='%1.1f%%')","b2c91816":"dataset[['Category','Profit']].groupby(['Category']).sum().plot(kind='barh',figsize=[8,8])","0a2932c8":"dataset[['Sub-Category','Sales']].groupby(['Sub-Category']).sum().sort_values(by = ['Sales']).plot(kind='barh',figsize=[8,8])","1f44a804":"dataset[['Sub-Category','Profit']].groupby(['Sub-Category']).sum().sort_values(by = ['Profit']).plot(kind='barh',figsize=[8,8])","f1f67be9":"### Exploratory Data Analysis on SuperStore dataset\n\n**As a bussines manager, try to find out the weak areas where you can work to make more profit**\n\n**What all business problems you can derive by exploring the data?**\n\n**Create the dashboard\/storyboard with explanation the charts and interpretations**\n","08bfe631":"**although the sales of all categories is equal to each other the profit which come from furniture is very low**","84d11ab5":"**the most profit come from New york, California States**\n\n**but on the other side States such as Taxas, Colorado, ...... has negative earning**","6998ad72":"**the most sales is come from California state**\n\n**the lowest sales is come from wyoming**","1173c816":"### High Demand Products in Different Categories\n**Funiture: Furnishings and Chairs**\n\n**Office Supplies: Binders and Papers**\n\n**Technology: Phones and Accessories**\n\n### Low Demand Products in Different Categories\n**Furniture: Bookcases and Tables**\n\n**Office Supplies: Fasteners and Supplies**\n\n**Technology: Machines and Copiers**","40c02d79":"**Consumer is the most profit segment**","91bfadf0":"**We can say the sales of all categories is equal to each other**","2ec36636":"**Ship Mode**: Maximum Dealings:- Category **(Office Supplies)** and Sub-Category **(Binders)** on Standard Class Mode\n\n**Ship Mode**: Minimum Dealings:- Category **(Technology)** and Sub-Category **(Copiers)** on Same Day Mode","8cfc98b1":"**the profit from Tables, Bookcases is negative earning which make furniture has low profit**"}}