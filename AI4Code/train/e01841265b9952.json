{"cell_type":{"22f97c96":"code","8b301dc9":"code","eb22933c":"code","79913167":"code","256e3106":"code","38c05429":"code","5f53c75e":"code","d29fb527":"code","7013dbbe":"code","0a9d78e6":"code","d5bdb0d6":"code","4b193869":"code","c43805c3":"code","f21a18cf":"code","a0247d0d":"code","70c222cf":"code","b945fd56":"code","3c900993":"code","e939e545":"code","31bbf309":"code","ba258fe4":"code","43aadca6":"code","49e3e92d":"code","ed43a864":"code","3c20748c":"code","397fdc6b":"code","8e542e8c":"code","74c69c54":"code","48692aee":"code","42ced541":"code","4116360b":"code","7931facd":"code","67b15c98":"code","20e3578a":"code","1ca63373":"code","38c15b82":"code","f5189634":"code","2fe7496e":"code","05dfb170":"code","473a9acc":"code","720f949d":"code","7d8ba0d9":"code","2afde89b":"code","bc624d86":"code","acf63f1a":"code","a8b3ecf3":"code","4d30a4c2":"code","d051a227":"code","a8ab4817":"code","0436ec3d":"code","d9106237":"code","c1288039":"code","ab3bbf4a":"code","c1655fdb":"code","b86b061c":"code","7445044f":"code","b750bee2":"code","38b9509e":"code","c969fa8b":"code","f3ad9bcb":"code","1cc0c5d5":"code","ebcaf8e0":"code","e3e84197":"code","b7e2810f":"markdown","067b4afd":"markdown","220f6c67":"markdown","a8130914":"markdown","32f14262":"markdown"},"source":{"22f97c96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8b301dc9":"#Importing reqd libraries \nimport numpy              as np\nimport pandas             as pd\nimport matplotlib.pyplot  as plt\nimport seaborn            as sns\n%matplotlib inline\n\nimport cufflinks          as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n\nfrom sklearn.preprocessing import MinMaxScaler","eb22933c":"#Importing the dataset \ndf_countries = pd.read_csv(r'..\/input\/country-data-test-2020\/Country-data.csv')\ndf_countries.head()","79913167":"#Checking the dataframe \ndf_countries.info()\n\n#We can observe that there are no null values in the dataset ","256e3106":"#Describing the dataframe\ndf_countries.describe()","38c05429":"#Function to display the distribution of different columns\ndef histogram(df,col_name,title):\n    temp           = pd.DataFrame()\n    temp[col_name] = df[col_name]\n\n    return temp[col_name].iplot(kind='hist',\n                       subplots=True,\n                       fill=True,\n                       subplot_titles=True,\n                       title=title)","5f53c75e":"#Function to display the distribution of different columns\ndef boxplot(df,col_name,title):\n    temp           = pd.DataFrame()\n    temp[col_name] = df[col_name]\n\n    return temp[col_name].iplot(kind='box',\n                       subplots=True,\n                       fill=True,\n                       subplot_titles=True,\n                       title=title)","d29fb527":"#Function to display a scatter plot\ndef scatter(df,col1_name,col2_name,title):\n    return df.iplot(kind='scatter',x=col1_name,y=col2_name,mode='markers',title=title,xTitle=col1_name,\n               yTitle=col2_name)","7013dbbe":"#Scatter plot between exports and gdpp\nscatter(df_countries,'gdpp','exports','Plot between GDP and exports')","0a9d78e6":"#Scatter plot between health and child_mort\nscatter(df_countries,'health','child_mort','Plot between health expenditure & child mortality')","d5bdb0d6":"#Scatter plot between child_mort and gdpp\nscatter(df_countries,'gdpp','child_mort','Plot between child mortality & GDP')","4b193869":"#Scatter plot between health and gdpp\nscatter(df_countries,'gdpp','health','Plot between health expenditure & GDP')","c43805c3":"#Scatter plot between income and gdpp\nscatter(df_countries,'income','gdpp','Plot between Income & GDP')","f21a18cf":"#Scatter plot between inflation and gdpp\nscatter(df_countries,'gdpp','inflation','Plot between Income & gdpp')","a0247d0d":"#Analysing the GDP column \nhistogram(df_countries,'gdpp','GDP distribution')","70c222cf":"#Analysing the GDP column \nboxplot(df_countries,'gdpp','GDP distribution')","b945fd56":"#Analysing the child mortalibity\nhistogram(df_countries,'child_mort','Child mortatlity distribution')","3c900993":"#Analysing the exports\nhistogram(df_countries,'exports','Export distribution')","e939e545":"#Analysing the imports\nhistogram(df_countries,'imports','Imports distribution')","31bbf309":"#Analysing the inflation\nhistogram(df_countries,'inflation','inflation distribution')","ba258fe4":"#Function to clean the outliers \ndef outlier_removal(grouped_df,col_name):\n    Q1 = grouped_df[col_name].quantile(0.05)\n    Q3 = grouped_df[col_name].quantile(0.95)\n    IQR = Q3 - Q1\n    grouped_df = grouped_df[(grouped_df[col_name] >= Q1 - 1.5*IQR) & (grouped_df[col_name] <= Q3 + 1.5*IQR)]","43aadca6":"list_ss = ['child_mort', 'exports', 'health', 'imports', 'income','inflation', 'life_expec', 'total_fer', 'gdpp']","49e3e92d":"df_wo_ot = df_countries.copy()\nprint('The shape of df before removing outliers:{}'.format(df_wo_ot.shape))\nfor i in list_ss:\n    outlier_removal(df_wo_ot,i)\nprint('The shape of df after removing outliers:{}'.format(df_wo_ot.shape))","ed43a864":"#Standardizing the values in the dataframe\nfrom sklearn.preprocessing import StandardScaler\nSS             = StandardScaler()\ndf_ss          = df_countries.copy()\ndf_ss[list_ss] = SS.fit_transform(df_countries[list_ss])\ndf_ss.head()","3c20748c":"#Model building and clustering \nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","397fdc6b":"#Checking the hopkins statistics to checj if custer tendency exits\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nimport numpy as np\nfrom math import isnan\n\ndef hopkins(X):\n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    H = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","8e542e8c":"#Use the Hopkins Statistic function by passing the above dataframe as a paramter\nhopkins(df_ss[list_ss])\n\n#We can observe that the hopkins stats is near to 1 so there is a good cluster tendency ","74c69c54":"#Checking the silhoutte score\n# silhouette analysis\ndef silhouette(df):\n    range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n\n    for num_clusters in range_n_clusters:\n\n        # intialise kmeans\n        kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n        kmeans.fit(df)\n\n        cluster_labels = kmeans.labels_\n\n        # silhouette score\n        silhouette_avg = silhouette_score(df, cluster_labels)\n        print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))","48692aee":"silhouette(df_ss[list_ss])","42ced541":"#Drawing the elbow curve\n# elbow-curve\/SSD\ndef elbow_cover(df):\n    ssd = []\n    range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n    for num_clusters in range_n_clusters:\n        kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n        kmeans.fit(df)\n\n        ssd.append(kmeans.inertia_)\n\n    # plot the SSDs for each n_clusters\n    # ssd\n    plt.plot(ssd)","4116360b":"elbow_cover(df_ss[list_ss])","7931facd":"#Initially we will build a model with 4 clusters \nkmeans = KMeans(n_clusters=4, max_iter=50)\nkmeans.fit(df_ss[list_ss])","67b15c98":"#Lets analyse the cluster with k =4\n#Allocating the lables to the df\ndf_ss['labels'] = kmeans.labels_\nsns.catplot(x=\"labels\", y=\"gdpp\", kind=\"box\", data=df_ss)","20e3578a":"sns.catplot(x=\"labels\", y=\"inflation\", kind=\"box\", data=df_ss)","1ca63373":"#Analysing how health expenditure is spread across labels\nsns.catplot(x=\"labels\", y=\"health\", kind=\"box\", data=df_ss)","38c15b82":"sns.catplot(x=\"labels\", y=\"income\", kind=\"box\", data=df_ss)","f5189634":"sns.catplot(x=\"labels\", y=\"child_mort\", kind=\"box\", data=df_ss)","2fe7496e":"df_ss.columns","05dfb170":"sns.catplot(x=\"labels\", y=\"exports\", kind=\"box\", data=df_ss)","473a9acc":"sns.catplot(x=\"labels\", y='imports', kind=\"box\", data=df_ss)","720f949d":"sns.countplot(df_ss['labels'])","7d8ba0d9":"#Lets build a model with K=3 and check out the results \nkmeans = KMeans(n_clusters=3, max_iter=50)\nkmeans.fit(df_ss[list_ss])","2afde89b":"#Lets analyse the cluster with k =4\n#Allocating the lables to the df\ndf_ss.drop(columns='labels',axis=1,inplace=True)\ndf_ss['labels'] = kmeans.labels_\nsns.catplot(x=\"labels\", y=\"gdpp\", kind=\"box\", data=df_ss)","bc624d86":"#fig   = plt.subplots(1,2,figsize=(10,7))\nfig1 = sns.catplot(x=\"labels\", y=\"exports\", kind=\"box\", data=df_ss)\nfig2 = sns.catplot(x=\"labels\", y=\"imports\", kind=\"box\", data=df_ss)","acf63f1a":"#Lets analyse the countries in label 2 \ndf_ss[df_ss['labels'] == 2]","a8b3ecf3":"df_ss.columns","4d30a4c2":"#Removing some lables to form better clusters \ndf_new = df_ss[['child_mort', 'health','income','inflation', 'life_expec', 'gdpp']].copy()\nkmeans = KMeans(n_clusters=3, max_iter=50)\nkmeans.fit(df_ss[list_ss])","d051a227":"#checking the silhouttee score\n#df_new.drop(columns=['country','labels'],axis=1,inplace=True)\nsilhouette_score(df_new,kmeans.labels_ )","a8ab4817":"df_new['labels'] = kmeans.labels_\ndf_new['country']  = df_ss['country']\nsns.catplot(x=\"labels\", y=\"gdpp\", kind=\"box\", data=df_new)\n#df_new[df_new['labels'] == 1]","0436ec3d":"df_new[df_new['labels'] == 1].count()","d9106237":"df_ss.columns","c1288039":"#Trying the hierrachial approach \ndf_hc = df_ss[['child_mort', 'exports', 'health', 'imports', 'income',\n       'inflation', 'life_expec', 'total_fer', 'gdpp']].copy()\n#df_hc.apply(pd.to_numeric())\nmergings = linkage(df_hc, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","ab3bbf4a":"mergings = linkage(df_hc, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","c1655fdb":"cluster_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )\ncluster_labels","b86b061c":"df_hc['cluster_labels'] = cluster_labels\ndf_hc['country']        = df_ss['country'] \ndf_hc.head()","7445044f":"sns.catplot(x=\"cluster_labels\", y=\"gdpp\", kind=\"box\", data=df_hc)","b750bee2":"df_hc[df_hc['cluster_labels'] == 2].count()","38b9509e":"df_hc[df_hc['cluster_labels'] == 0].describe()","c969fa8b":"df_hc = df_ss[['child_mort', 'health', 'income',\n       'inflation', 'life_expec', 'gdpp']].copy()\n#df_hc.apply(pd.to_numeric())\nmergings = linkage(df_hc, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","f3ad9bcb":"cluster_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )\ncluster_labels","1cc0c5d5":"df_hc['cluster_labels'] = cluster_labels\ndf_hc['country']        = df_ss['country'] \ndf_hc.head()","ebcaf8e0":"sns.catplot(x=\"cluster_labels\", y=\"gdpp\", kind=\"box\", data=df_hc)","e3e84197":"df_hc[df_hc['cluster_labels'] == 2]","b7e2810f":"### 4. DATA PREPROCESSING","067b4afd":"### 2. EXPLORATORY DATA ANALYSIS AND OUTLIER REMOVAL TREATMENT","220f6c67":"### 3. DATA CLEANING ","a8130914":"### 1. IMPORTING THE DATA AND ANALYZING","32f14262":"### 5. MODEL BUILDING & EVALUATING THE MODEL"}}