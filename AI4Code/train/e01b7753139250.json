{"cell_type":{"46d1f50d":"code","d2a5cc50":"code","b5f37b0a":"code","98aed6fc":"code","9815ded0":"code","95835e71":"code","649354f8":"code","7b505651":"code","76d10333":"code","0361c0f9":"code","c7f63895":"code","e8b393a9":"code","151d2566":"code","581448f4":"code","80728d73":"code","284a1729":"code","59896e0b":"markdown","3ff8dbce":"markdown"},"source":{"46d1f50d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nvirus_csv_file = '..\/input\/genome-information-for-sequenced-organisms\/viruses.csv'\nviruses_df = pd.read_csv(virus_csv_file)\nviruses_df.head(5)\n\n","d2a5cc50":"# clean up column names i.e. remove the erroneous characters from the column names (spaces, percent sign, etc.)\n\n# clean up column names https:\/\/stackoverflow.com\/a\/11346337\/6542644 \nviruses_df.columns = ['organism_name', 'organism_groups', 'BioSample', 'Bioproject', 'Assembly', 'Level', 'size_mb', 'gc_percent', 'replicons', 'host', 'cds', 'neighbours', 'release_date', 'genbank_ftp', 'refseq_ftp', 'replicons1']\n\n# verify column names have been changed\nviruses_df.head(1)","b5f37b0a":"#Explore the data\n\n# .shape[0] gives the number of rows in the dataframe, which is the number of viral species in the dataset\nprint('Number of viruses: ', viruses_df.shape[0])\n\n# .unique gives the number of unique items in a specified column, in this case the number of viral hosts\nprint('Number of unique viral host types: ', (len(viruses_df['host'].unique())))\n\nviruses_df['host'].unique()","98aed6fc":"ohe_df = pd.get_dummies(viruses_df['host'], prefix='host')\nohe_df.head(5)","9815ded0":"# drop columns we don't need \nvirus_feats_only = viruses_df.drop(['organism_name', 'organism_groups', 'BioSample', \n                                    'Bioproject', 'Assembly', 'Level', 'replicons', \n                                    'neighbours', 'release_date', 'genbank_ftp', 'refseq_ftp',\n                                   'replicons1'], axis=1)\n\n\n# create dict to map strings to numerical values, also combines overlapping hosts: vertebrates\/human and human\nviruses_host_dict = {'bacteria': 0, 'fungi': 1, 'plants': 2, 'vertebrates': 3,\n                    'invertebrates': 4, 'protozoa': 5, 'vertebrates, invertebrates, human': 6,\n                    'invertebrates, plants': 7, 'algae': 8, 'vertebrates, invertebrates': 9,\n                    'vertebrates, human': 10, 'archaea': 11, 'human': 10}\n\n# replace method use cited from: https:\/\/stackoverflow.com\/a\/20250996\/6542644 \nvirus_feats_cleanhost = virus_feats_only.replace({'host':viruses_host_dict})\n\nfirst_col = virus_feats_cleanhost.pop('host')\nvirus_feats_cleanhost.insert(0, 'host', first_col)\nvirus_feats_cleanhost.head(5)","95835e71":"# check for NaN values in data\n\nprint(\"Count of NaN in host: \", virus_feats_cleanhost['host'].isnull().sum())\nprint(\"Count of NaN in Size_Mb: \", virus_feats_cleanhost['size_mb'].isnull().sum())\nprint(\"Count of NaN in GC_percent: \", virus_feats_cleanhost['gc_percent'].isnull().sum())\nprint(\"Count of NaN in cds: \", virus_feats_cleanhost['cds'].isnull().sum())\n\nviruses_dropped_nan = virus_feats_cleanhost.dropna()\n\n# count of NaN values in a column cited from: https:\/\/datatofish.com\/check-nan-pandas-dataframe\/\n\nprint(\"Count of NaN after dropna(): \", viruses_dropped_nan['host'].isnull().sum())\n\nviruses_dropped_nan.head(5)\ndisplay(viruses_dropped_nan)","649354f8":"# Check distribution of viral hosts\ncounts_host2 = viruses_dropped_nan.copy()\ncounts_host_unique = counts_host2.groupby(['host']).size().reset_index(name='Counts')\n\ncounts_host_unique","7b505651":"# Plot distribution of viral hosts\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ngroup = ['host']\ncounts = viruses_dropped_nan.groupby(group).size().reset_index(name=\"Counts\")\n\n# use of plt cited from: https:\/\/python-graph-gallery.com\/4-add-title-and-axis-label\/\nbars = ('bact', 'fungi', 'plants', 'verts', 'inverts',\n        'pro', 'v\/i\/hum',\n        'i\/plants', 'algae', 'v\/i',\n        'v\/hum', 'archaea')\ny_pos = np.arange(len(bars))\n\n#plt.title('Distribution of Unique Host Types')\nplt.figure(figsize=(10,8))\nplt.bar(range(len(counts)), counts['Counts'], color = 'blue')\nplt.title('Distribution of Viral Hosts')\nplt.xlabel('Viral Hosts')\nplt.ylabel('Count')\nplt.xticks(y_pos, bars)","76d10333":"# Get stats for viral genome size (size_mb) and plot distribution\n\nprint('Number of unique size values: ', (len(viruses_dropped_nan['size_mb'].unique())))\n\nprint(viruses_dropped_nan.size_mb.describe())\n\nprint(\"mode of Size_Mb is: \", viruses_dropped_nan['size_mb'].mode())\n\n# replace values of 0 with the mean cited from: https:\/\/stackoverflow.com\/a\/11455375\/6542644\nfrom sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=0, strategy = 'mean')\n\ncleaned_sizemb_df = viruses_dropped_nan['size_mb']\n\ndrop_host = viruses_dropped_nan.drop(['host'], axis=1)\n\nimp.fit(drop_host)\n\ncleaned_df = imp.transform(drop_host)\n\ncleaned_df = pd.DataFrame(data=cleaned_df, columns=[\"size_mb\", \"gc_percent\", \"cds\"])\n\ncleaned_size = cleaned_df['size_mb']\n\nprint(\"count zeroes is: \", cleaned_size.isin([0]).sum())\n\ncleaned_size = cleaned_size.sort_values()\ncleaned_size.hist(bins = 100)\nplt.title('Distribution of Size of Genome Mb')\nplt.xlabel('Size of genome in Mb')\nplt.ylabel('Count')","0361c0f9":"# Get stats for GC% (gc_percent) and plot distribution\n\nprint('Number of unique GC% values: ', (len(viruses_df['gc_percent'].unique())))\n\nprint(viruses_df.gc_percent.describe())\n\ngc_sorted_df = viruses_df['gc_percent']\ngc_sorted_df = gc_sorted_df.sort_values()\n\nprint('Most frequent value is ', gc_sorted_df.mode() )\ngc_sorted_df.hist(bins = 50)\nplt.title('Distribution of GC% of Viral Genomes')\nplt.xlabel('GC% of Viral Genomes')\nplt.ylabel('Count')","c7f63895":"# Get stats for CDS (cds) and plot distribution\n\nprint('Number of unique CDS values: ', (len(viruses_df['cds'].unique())))\n\nprint(viruses_df.cds.describe())\n\ncds_sorted_df = viruses_df['cds']\ncds_sorted_df = cds_sorted_df.sort_values()\n\nprint('Most frequent value is ', cds_sorted_df.mode() )\n\nprint('count zeroes is ', cds_sorted_df.isin([0]).sum() )\n\ncds_sorted_df.hist(bins = 50)\nplt.title('Distribution of CDS of Viral Genomes')\nplt.xlabel('CDS of Viral Genomes')\nplt.ylabel('Count')","e8b393a9":"# Pre-process Data\n\nfrom sklearn import preprocessing\n\nnew_viral_df = viruses_dropped_nan.copy()\n\ntargets_host = new_viral_df.pop('host')\n\nx = new_viral_df.values\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\n\nunclean_viral_df = pd.DataFrame(x_scaled)\n\nunclean_viral_df.insert(0, 'host', targets_host)\n\n# remove the NaN values!\nnew_df_clean = unclean_viral_df.dropna()\n\nnew_df_clean.columns = ['host', 'size_mb', 'gc_percent', 'cds']\nnew_df_clean.head(5)","151d2566":"# Prep the data: generate X and y\n\n# create features and labels\ny = new_df_clean['host']\nX = new_df_clean.drop(['host'], axis=1)\ny.columns = ['host']\n\n# X.head(5)","581448f4":"# SVM usage cited from: https:\/\/towardsdatascience.com\/multiclass-classification-with-support-vector-machines-svm-kernel-trick-kernel-functions-f9d5377d6f02\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm, datasets\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n\n# start with linear kernel\n\nlinear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n                                            \nlinear_pred = linear.predict(X_test)\n\n# retrieve accuracy\naccuracy_lin = linear.score(X_test, y_test)\n\nprint(\"acc linear kernel: \", accuracy_lin)\n\ncm_lin = confusion_matrix(y_test, linear_pred)\nprint(cm_lin)","80728d73":"# now try rbf kernel\n\nrbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo', probability=True).fit(X_train, y_train)\nrbf_pred = rbf.predict(X_test)\n\naccuracy_rbf = rbf.score(X_test, y_test)\nprint(\"acc rbf kernel: \", accuracy_rbf)\n\ncm_rbf = confusion_matrix(y_test, linear_pred)\nprint(cm_rbf)","284a1729":"# now try with cross validation!\n\nfrom sklearn.model_selection import cross_val_score\n\nclf_cross_val = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo')\n\n# use of cross_val_score cited from: https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html\n\nscores = cross_val_score(clf_cross_val, X, y, cv=10)\nprint(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))","59896e0b":"### Distribution of Data\n\nWe will look at the distribution of our viral hosts (target) and our features. Class imbalances may affect our results. Here we ask: **How evenly is our data distributed among different meta-genomic features and viral hosts?**","3ff8dbce":"### Predicting Viral Host based on Metagenomic Features\n\nIn this notebook, metagenomic features taken from a viral genome are used to predict the type of virus host. The efficacy of these features is then evaluated. Genome size, GC%, and count of CDS from viral genomes are used as features to predict the viral host (target). SVM techniques are used to create a classifier that achieves 86% accuracy across this dataset. This notebook was created by Jeffrey Jeyachandren (github: JeffinWithYa) as the capstone project for the Udacity Machine Learning Engineer nanodegree. \n\nYou should note two things:\n* The dataset is taken from the viruses.csv file, please make sure it is in your directory.\n* The data contains metagenomic info from 7362 unique viral genomes and their known characteristics"}}