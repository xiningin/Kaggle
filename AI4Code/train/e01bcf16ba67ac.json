{"cell_type":{"00590d53":"code","cfc8fc3a":"code","e6727bd3":"code","90e65b2d":"code","467ebcb5":"code","7996e73a":"code","51aa089a":"code","908dc062":"code","de1660dd":"code","acf5922b":"code","759f285e":"code","f737e1e0":"markdown","cff67283":"markdown","226f05f5":"markdown","7eaec745":"markdown"},"source":{"00590d53":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimage\nimport numpy as np\nimport cv2\nimport os\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n\nfrom sklearn.metrics import confusion_matrix","cfc8fc3a":"TRAIN_DIR='..\/input\/cat-and-dog\/training_set\/training_set\/'\nTEST_DIR='..\/input\/cat-and-dog\/test_set\/test_set\/'\n\n\ntrain_cat_dir=TRAIN_DIR+'cats'\ntrain_dog_dir=TEST_DIR+'dogs'\n\ntrain_cat_fnames=os.listdir(train_cat_dir)\ntrain_dog_fnames=os.listdir(train_dog_dir)\n\n# test_cat_fnames=os.listdir(test_dir+'cats')\n# test_dog_fnames=os.listdir(test_dir+'dogs')","e6727bd3":"num_rows=4\nnum_cols=4\npic_index=0","90e65b2d":"fig=plt.gcf()\nfig.set_size_inches(num_rows*4,num_cols*4)\n\npic_index+=8\n\nnext_cat_pix=[os.path.join(train_cat_dir,fname) for fname in train_cat_fnames[pic_index-8:pic_index]]\nnext_dog_pix=[os.path.join(train_dog_dir,fname) for fname in train_dog_fnames[pic_index-8:pic_index]]\n\nfor i,img_path in enumerate(next_cat_pix+next_dog_pix):\n    sp=plt.subplot(num_rows,num_cols,i+1)\n    sp.axis('off')\n    \n    img=mpimage.imread(img_path)\n    plt.imshow(img)","467ebcb5":"# Initialising the CNN\ncnn_model = Sequential();\n# step 1 convolution layer\n# 64,64 means number of the channel in row and columns.\n# 32 is the number of detactores, 3X3 cross matrix(filter size) we can also increas depend on gpu\/cpu\ncnn_model.add(Conv2D(32, (3, 3), input_shape=(64,64,3), activation='relu')) \n# step 2 Pooling\ncnn_model.add(MaxPool2D(pool_size=(2,2)))\n# Adding a second convolutional layer\ncnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n# step 2 Pooling\ncnn_model.add(MaxPool2D(pool_size=(2,2)))\ncnn_model.add(Conv2D(128, (3, 3), activation='relu'))\ncnn_model.add(MaxPool2D(pool_size=(2,2)))\ncnn_model.add(Conv2D(128,(3,3),activation='relu'))\ncnn_model.add(MaxPool2D(pool_size=(2,2)))\n\n# step 3 Flattening creating a long vector\ncnn_model.add(Flatten())\n# step 4 Full connection\ncnn_model.add(Dense(units=512, activation='relu'))\ncnn_model.add(Dense(units=1, activation='sigmoid'))","7996e73a":"# Compleate CNN\ncnn_model.compile(optimizer='adam',loss=\"binary_crossentropy\", metrics=['accuracy'])","51aa089a":"#Data augmentation\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, #Rescaling factor\n                                   shear_range=0.2, # float shear intensity \n                                   zoom_range=0.2, #Range for random zoom float(lower\/upper)\n                                   horizontal_flip=True) # Random flip inputs horizontally\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntraining_set = train_datagen.flow_from_directory(TRAIN_DIR,\n                                                 target_size=(64, 64),\n                                                 batch_size=32,\n                                                 class_mode='binary')\ntest_set = test_datagen.flow_from_directory(TEST_DIR,\n                                            target_size=(64, 64),\n                                            batch_size=32,\n                                            class_mode='binary')","908dc062":"history=cnn_model.fit(training_set,\n              steps_per_epoch=200,\n              epochs=25,\n              validation_data=test_set,\n              validation_steps=50)","de1660dd":"# plot accuracy and loss\n\n\nacc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(1, len(acc) + 1)\n\n# accuracy\n\nplt.plot(epochs, acc, \"b\", label=\"Training accuracy\")\nplt.plot(epochs, val_acc, \"b--\", label=\"Validation accuracy\")\nplt.title(\"Training and validation accuracy\")\nplt.legend()\nplt.show()\n\n# loss\n\nplt.plot(epochs, loss, \"r\", label=\"Training loss\")\nplt.plot(epochs, val_loss, \"r--\", label=\"Validation loss\")\nplt.title(\"Training and validation loss\")\nplt.legend()\nplt.show()","acf5922b":"# Predictions for Dog image using train model\n\n# from keras.preprocessing import image\n# test_image = image.load_img('\/content\/training_set\/training_set\/cats\/cat.1.jpg',target_size=(64,64))\n# test_image = image.img_to_array(test_image)\n# test_image = np.expand_dims(test_image, axis=0)\n\n\ntest_image = cv2.imread(\"\/kaggle\/input\/cat-and-dog\/training_set\/training_set\/cats\/cat.1903.jpg\")\nplt.imshow(test_image)\n\ntest_image = cv2.resize(test_image,None, fx = 0.5, fy=0.5)\ntest_image = test_image.reshape()\n\nresult = cnn_model.predict(test_image)\ntraining_set.class_indices\nif result[0][0]==1:\n  prediction = 'dog'\n  print(prediction)\nelse:\n  prediction = 'cat'\n  print(prediction)","759f285e":"# Predictions for Dog image using train model\ntest_image = cv2.imread(\"\/kaggle\/input\/cat-and-dog\/training_set\/training_set\/dogs\/dog.1903.jpg\")\nplt.imshow(test_image)\n\ntest_image = cv2.resize(test_image,None, fx = 0.5, fy=0.5)\ntest_image = test_image.reshape()\n\nresult = cnn_model.predict(test_image)\ntraining_set.class_indices\nif result[0][0]==1:\n  prediction = 'dog'\n  print(prediction)\nelse:\n  prediction = 'cat'\n  print(prediction)","f737e1e0":"Note that when we have only two classes, we could instead configure our output layer to have only one output, rather than two, and use **binary_crossentropy** as our loss, rather than ***categorical_crossentropy***. Both options work equally well and achieve the exact same result.\n\nWith ***binary_crossentropy***, however, the last layer would need to use ***sigmoid***, rather than ***softmax***, as its activation function.","cff67283":"#### Convolutional Neural Network Dogs and Cats -keras\n\n##### Before understanding the CNN, lets understand first about these two core subject\n![image.png](attachment:image.png)\n**Image processing** is a method to perform some operations on an image, in order to get an enhanced image or to extract some useful information from it. It is a type of signal processing in which input is an image and output may be image or characteristics\/features associated with that image.\n\n**Computer vision** is a field of computer science that works on enabling computers to see, identify and process images in the same way that human vision does, and then provide appropriate output. It is like imparting human intelligence and instincts to a computer. In reality though, it is a difficult task to enable computers to recognize images of different objects.\n\n### Content:\n#### Explanation\n* Convolution operation\n* ReLU\n* Max Pooling\n* Flattening\n* Full-connection Softmax & Cross entropy\n\n#### IMPLEMENTATION\n* Data preprocessing\n* Build the Keras model\n* Compile and fit the model\n* Make predictions and determine accuracy","226f05f5":"##### Now that we have a general understanding for how to build and work with a CNN using Keras","7eaec745":"### Model Building in CNN"}}