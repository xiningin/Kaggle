{"cell_type":{"9f873544":"code","98a67b8a":"code","1b21d2c2":"code","8d5abd9d":"code","a9fe8161":"code","3c6ba15d":"code","e058ce0d":"code","a1cba4c8":"code","bb2f0b99":"code","87c7313e":"code","1bdc5824":"code","b58e71b4":"code","87402add":"code","f7db30dc":"code","90e3ae2b":"code","d14a2205":"code","f22c8c63":"code","d11259a9":"code","9db220af":"code","ed9a5f15":"code","79d6056c":"code","8dbad249":"code","59f4cc4c":"code","e96e2582":"code","d89ed6ef":"markdown","0fb1e87e":"markdown","eac32f0a":"markdown","df50ed30":"markdown","8f36bd19":"markdown","50d0646e":"markdown","c30a1e20":"markdown","7b7dc1c8":"markdown","815777f3":"markdown","5693a3cd":"markdown","e9bb0f80":"markdown","57403367":"markdown","a8c32a7d":"markdown","957364e0":"markdown","6fbb406d":"markdown"},"source":{"9f873544":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Activation, Dropout,Dense, Flatten, BatchNormalization, Conv2D, AveragePooling2D, MaxPooling2D, Lambda, Input, ZeroPadding2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\nimport itertools\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelBinarizer\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\nfrom itertools import cycle\nfrom scipy import interp\nfrom sklearn import metrics\n#from imutils import paths\nfrom keras.models import load_model\nimport os\nimport cv2\nimport shutil\nfrom keras import backend as K\nimport random\nimport glob\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","98a67b8a":"img_width, img_height = 64, 64\ntrain_data_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\n#validation_data_dir = '..\/input\/binary-wbc\/binary_data\/val'\ntest_data_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nnb_train_samples = 5216\nnb_validation_samples = 624\n#epochs = 10\nbatch_size = 64\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)","1b21d2c2":"train_datagen = ImageDataGenerator(\n    rescale=1. \/ 255, #rescales each images (normalization)\n    shear_range=0.2,  #shears each images by 0.2%\n    zoom_range=0.2, # zoom each image by 0.2%\n    width_shift_range=0.2,  #shifts width\n    height_shift_range=0.2,  #shifts height\n    horizontal_flip=False,  #horizontally flips the images\n    vertical_flip=False)\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)  #no augmentation is performed for test set except for the normalization.\n","8d5abd9d":"train_batches = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    #classes=['MONONUCLEAR', 'POLYNUCLEAR'])\n    class_mode='categorical')  #class mode is set to binary as we are performing binary classification.","a9fe8161":"#valid_batches = test_datagen.flow_from_directory(\n    #validation_data_dir,\n    #target_size=(img_width, img_height),\n    #batch_size=batch_size,\n    #classes=['MONONUCLEAR', 'POLYNUCLEAR'])\n    #color_mode=\"grayscale\")","3c6ba15d":"test_batches = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=624,\n    #classes=['MONONUCLEAR', 'POLYNUCLEAR'])\n    class_mode='categorical')   #class mode is set to binary as we are performing binary classification.","e058ce0d":"epochs = 25\nINIT_LR = 0.0001\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ epochs)","a1cba4c8":"# BUILD CONVOLUTIONAL NEURAL NETWORKS\nnets = 5\nmodel = [0] *nets\nfor j in range(nets):\n    model[j] = Sequential()\n    model[j].add(BatchNormalization(input_shape=input_shape))\n    model[j].add(Conv2D(32, (3, 3), padding='valid'))\n    #model[j].add(BatchNormalization())\n    model[j].add(Activation('relu'))\n    #model[j].add(Dropout(0.4))\n    model[j].add(MaxPooling2D(pool_size=(2, 2)))\n    model[j].add(Dropout(0.5))\n    \n    model[j].add(Conv2D(32, (5, 5), padding='same'))\n    #model[j].add(BatchNormalization())\n    model[j].add(Activation('relu'))\n    model[j].add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model[j].add(Conv2D(64, (5, 5), padding='same'))\n    #model[j].add(BatchNormalization())\n    model[j].add(Activation('relu'))\n    model[j].add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model[j].add(Conv2D(128, (5, 5), padding='same'))\n    #model[j].add(BatchNormalization())\n    model[j].add(Activation('relu'))\n    model[j].add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model[j].add(Flatten())\n    #model[j].add(Dense(128))\n    #model[j].add(Activation('relu'))\n    model[j].add(Dense(256))\n    model[j].add(Activation('relu'))\n    model[j].add(Dropout(0.5))\n    #model[j].add(Dense(32))\n    #model[j].add(Activation('relu'))\n\n    model[j].add(Dense(2))\n    model[j].add(Activation('softmax'))\n    model[j].summary()\n\n    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n    model[j].compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","bb2f0b99":"# DECREASE LEARNING RATE EACH EPOCH\n#annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n# TRAIN NETWORKS\nhistory = [0] * nets\nfor j in range(nets):\n    #X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n    history[j] = model[j].fit_generator(train_batches,\n        epochs = epochs, steps_per_epoch = nb_train_samples \/\/ batch_size,\n        validation_data = test_batches,\n        validation_steps = nb_validation_samples \/\/ batch_size,\n        callbacks=[#annealer,\n        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4),\n        tf.keras.callbacks.ModelCheckpoint(filepath = '\/kaggle\/working\/model_{val_accuracy:.3f}.h5', save_best_only=True,\n                                          save_weights_only=False, monitor='val_accuracy')\n        ])  #, callbacks=[annealer]\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n        j+1,epochs,max(history[j].history['accuracy']),max(history[j].history['val_accuracy']) ))","87c7313e":"test_imgs, test_labels = next(test_batches)","1bdc5824":"# ENSEMBLE PREDICTIONS AND SUBMIT\nresults = np.zeros( (624,2) ) \nfor j in range(nets):\n    results = results + model[j].predict_generator(test_imgs, steps=1, verbose=0)\nresults = np.argmax(results,axis = -1)\n#results = pd.Series(results,name=\"Label\")\n#submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n#submission.to_csv(\"MNIST-CNN-ENSEMBLE.csv\",index=False)","b58e71b4":"results","87402add":"test_labels = np.argmax(test_labels,axis = -1)\ntest_labels","f7db30dc":"#test_model = load_model('..\/input\/acc-9330\/model_0.933.h5')","90e3ae2b":"cm = confusion_matrix(y_true=test_labels, y_pred=results)","d14a2205":"acc = accuracy_score(test_labels, results)*100\ntn, fp, fn, tp = cm.ravel()\nprecision = tp\/(tp+fp)*100\nrecall = tp\/(tp+fn)*100\nprint('Accuracy: {0:0.2f}%'.format(acc))\nprint('Precision: {0:0.2f}%'.format(precision))\nprint('Recall: {0:0.2f}%'.format(recall))\nprint('F1-score: {0:0.2f}'.format(2*precision*recall\/(precision+recall)))\n#print('Train acc: {0:0.2f}'.format(np.round((h.history['accuracy'][-1])*100, 2)))","f22c8c63":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    #plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","d11259a9":"cm_plot_labels = ['NORMAL', 'PNEUMONIA']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='')","9db220af":"#confusion matrix-->correct identification = 202+380= 582\n#                -->wrong identification = 32+10 = 42\n#                --> accuracy = 582\/(582 + 42) = 0.9326 or (93.26% accuracy)","ed9a5f15":"from sklearn.metrics import classification_report","79d6056c":"print(classification_report(y_true=test_labels, y_pred=results))","8dbad249":"# Plot linewidth.\nlw = 2\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(2):\n    fpr[i], tpr[i], _ = roc_curve(results,test_labels)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_labels.ravel(), results.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n# Compute macro-average ROC curve and ROC area\n\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(2)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(2):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr \/= 2\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure(1)\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'cornflowerblue'])\nfor i, color in zip(range(2), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n#plt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","59f4cc4c":"for j in range(nets):\n    accs = history[j].history['accuracy']\n    val_accs = history[j].history['val_accuracy']\n\n    plt.title(\"For CNN: \"+ str(j+1))\n    plt.plot(range(len(accs)),accs, label = 'Training_accuracy')\n    plt.plot(range(len(accs)),val_accs, label = 'Validation_accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epochs')\n    plt.legend()\n    plt.show()","e96e2582":"for j in range(nets):\n    loss = history[j].history['loss']\n    val_loss = history[j].history['val_loss']\n\n    plt.title(\"For CNN: \"+ str(j+1))\n    plt.plot(range(len(loss)),loss, label = 'Training_loss')\n    plt.plot(range(len(loss)),val_loss, label = 'Validation_loss')\n    plt.ylabel('loss')\n    plt.xlabel('epochs')\n    plt.legend()\n    plt.show()","d89ed6ef":"# Introduction\n\n**In this notebook, I tried to differentiate the Normal and Pneumonia affected patients using chest X-ray images using a Lightweight Convolutional Neural Network. As a beginner myself, I searched a lot to perform prediction with higher acccuracy but less number of parameters thus know the difficulties and misunderstanding in the way. That's why, Here I will try my best to explain every steps for the sake of better understanding. Hope this will help the beginners like me to learn the basic image classification using CNN.**","0fb1e87e":"***Check version: 10 for notebook with AUC score 0.94. Here I've tried to implement a new ensemble method. More tuning is being performed currently to achieve a better result. You can have some idea about ensemble method in binary or multiclass classification from here if you want and some upvotes would really be appreciated if you get any help from here.That will keep me motivated. Thank you***","eac32f0a":"# Data Augmentation\n\n**To perform the data augmentation, here the [ImageDataGenerator](https:\/\/keras.io\/api\/preprocessing\/image\/) class provided by Keras has been initialized. You can learn more about it from the provided link.**","df50ed30":"**Here, I have initialized the image width and height for efficient training. You can change it as per your will. Then the image dirctories of training and testing images were set. I skipped the val directory but you can use it for your validation task. The parameters can be tuned as per your desire.**","8f36bd19":"**Here the Accuracy is of the imported pre-trained model and the Train acc is of the recently trained model.**","50d0646e":"# Avoid Overfitting\n\n**To avoid the famous over-fitting problem, I used the dropout regularization method. Dropout means it disables a percentage of neurons from extracting unneccessary features. You can add dropout layer after each conv layer with your needed value. You need to figure out which value suits your model better.**","c30a1e20":"![pneu.jpg](attachment:pneu.jpg)","7b7dc1c8":"**Here I used a pre-trained model from previous version to perform the prediction. You can use any model you want from your training. The model I used (trained in the previous versions) outperforms all the recently trained models. You can modify your model and use the best performing model to perform the prediction after training the model. Just import the model in following way.**","815777f3":"# Dataset Description\n\n**The dataset was collected from the [Chest X-ray pneumonia dataset](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia). It contains three folders named train (for training), val (for validation), and test (for testing). Each of them has two sub-folders with label \"NORMAL\" and \"PENUMONIA\".**\n\n* train\n     * NORMAL\n     * PNEUMONIA\n\n\n* val\n     * NORMAL\n     * PNEUMONIA\n   \n   \n* test\n     * NORMAL\n     * PNEUMONIA","5693a3cd":"**A pneumonia infection is no joke. In fact, UNICEF reports that pneumonia kills more children than any other illness. Even if you combined the deal toll of AIDS, measles, and malaria, you would still not have a number high enough to match that of the deaths pneumonia has caused. This dangerous infection should not be taken lightly. It is good to be acquainted with the four stages of pneumonia. The sooner you recognize the illness, the better for your recovery.**\n   1. Congestion: This stage occurs within the first 24 hours of contracting pneumonia. During congestion, the body will experience vascular engorgement, intra-alveolar fluid, and multiple bacteria. The lungs will be very heavy and red. Capillaries in the alveolar walls become congested and the infection will spread to the hilum and pleura. During this stage, a person will experience coughing and deep breathing. \n   \n   2. Red Hepatization: This stage occurs two to three days after congestion. At this point, the lungs will be red, firm, and airless with a resemblance to the liver. Alveolar capillaries will be engorged with blood and vascular congestion will persist. During the red hepatization stage, the alveoli will contain many erythrocytes, neutrophils, desquamated epithelial cells, and fibrin.\n\n   3. Grey Hepatization: This stage will occur two to three days after red hepatization and is an avascular stage. The lungs will appear to be a grayish brown or yellow color because of the disintegration of red cells. Your lungs will also appear to be paler and drier than usual. There will be a persistence of fibrin exudate during this stage.\n   \n   4. Resolution: The resolution, or complete recovery, occurs when the exudate experiences progressive enzymatic digestion. This will produce debris that is eventually reabsorbed, ingested by macrophages, coughed up, or reorganized by fibroblasts.\n   \n  \n  Courtesy: [Four Stages of Pneumonia](http:\/\/www.bassadvancedurgentcare.com\/post\/four-stages-of-pneumonia)","e9bb0f80":"**Creates batches for training, validation and testing**","57403367":"# Import Libraries\n\n**First, we need to import the necessary libraries for this task.**","a8c32a7d":"# Model\n\n**Now, the Convolutional Neural Network model is to be built. Here I have implemented a Sequential model with 7 layers (excluding output layer). The first 5 layers are convolutional layer and the last two are dense layers also known as fully connected layers. The number of filters in each layer is chosen through experimentation. You can try tuning the value for better result and clearer cocept. You can also add layers as per your need.**\n\n**The convolutional(Conv) layers have parameters filters, kernel size, input shape, and padding. Kernel size value should be chosen carefully. If you need to extract very fine details, you should use a small kernel size and for larger features, larger kernel size should be chosen. There is no limitation of using same kernel size in each layer. It can vary. All you have to do is experiment.**\n\n**Only for the first Conv layer, you need to define the input shape. The later layers take the previous layer's output as it's input. padding is used to add extra pixel values of zero to the image. One thing to note that *I got error initially while tried to add more number of layers. The dimensionality didn't match. Then switched the padding value from valid to same which solved my problem***\n\n**I used the relu activation function in each layer except for the output layer, where i have used the sigmoid activation function for binary classification. The MaxPooling layer extracts the pixels with max values and use it for next steps. The Adam optimizer and binary crossentropy loss function is applied for training. The EarlyStopping monitors the training process and stops it when no more improvement occurs. The models are saved in the defined output directory from where i used the best model to perform prediction on test set.**\n\n","957364e0":"**Pneumonia is an infection that inflames your lungs' air sacs (alveoli). The air sacs may fill up with fluid or pus, causing symptoms such as a cough, fever, chills and trouble breathing. Bacteria and viruses are the main causes of pneumonia. Pneumonia-causing germs can settle in the alveoli and multiply after a person breathes them in. Pneumonia can be contagious. The bacteria and viruses that cause pneumonia are usually inhaled.**","6fbb406d":"# Pneumonia Detection"}}