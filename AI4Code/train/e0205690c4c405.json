{"cell_type":{"88a08fd7":"code","0fdd3e20":"code","e5e75c9b":"code","61fbcefd":"code","302cca98":"markdown","d253b579":"markdown","9704f905":"markdown","0b8683b7":"markdown","1cabc4bc":"markdown","9d8eef5e":"markdown","32fefcc9":"markdown","5ec0a70a":"markdown","465c7d68":"markdown","610e11ca":"markdown","c3d3d01a":"markdown"},"source":{"88a08fd7":"# generating a normal density distribution\nfrom matplotlib import pyplot\nfrom numpy.random import normal\nfrom numpy import mean\nfrom numpy import std\n\n# generate a sample\nsample = normal(loc=50, scale=5, size=1000)\n# calculate parameters\nsample_mean = mean(sample)\nsample_std = std(sample)\nprint('Mean=%.3f, Standard Deviation=%.3f' % (sample_mean, sample_std))\n\n\"\"\"\nNow we have a mean and sample from our sample space, let's see \nwhat the histogram of our sample looks like\n\n\"\"\"\n\n# plot the histogram of the sample points\npyplot.hist(sample, bins=10, density=True)\npyplot.show()","0fdd3e20":"\"\"\"\nAs we can clearly see that the distribution of the sample space shows a single peak and resembles\nthe normal distribution.\n\"\"\"\n\nfrom scipy.stats import norm\n\n# define the distribution\ndist = norm(sample_mean, sample_std)\n\n# sample probabilities for a range of outcomes\nvalues = [value for value in range(30, 70)]\n\n# take the probability \nprobabilities = [dist.pdf(value) for value in values]\n\n# Use estimated probabilities to generate distribution of the population\npyplot.hist(sample, bins=10, density=True)\npyplot.plot(values, probabilities)\npyplot.show()","e5e75c9b":"# example of a bimodal data sample\nfrom matplotlib import pyplot\nfrom numpy.random import normal\nfrom numpy import hstack\n\n# generate a sample\nsample1 = normal(loc=20, scale=5, size=300)\nsample2 = normal(loc=40, scale=5, size=700)\nsample = hstack((sample1, sample2))\n# plot the histogram\npyplot.hist(sample, bins=50)\npyplot.show()","61fbcefd":"\"\"\"\nAs we can see that the distribution doesn't follow the gaussian norm and its bimodal in  nature\n\"\"\"\n\nfrom sklearn.neighbors import KernelDensity\nfrom numpy.random import normal\nfrom numpy import asarray\nfrom numpy import exp\n\n# fit density\nmodel = KernelDensity(bandwidth=2, kernel='gaussian')\nsample = sample.reshape((len(sample), 1))\nmodel.fit(sample)\n\n# sample probabilities for a range of outcomes\nvalues = asarray([value for value in range(1, 60)])\nvalues = values.reshape((len(values), 1))\n\nprobabilities = model.score_samples(values)\nprobabilities = exp(probabilities)\n# plot the histogram and pdf\npyplot.hist(sample, bins=50, density=True)\npyplot.plot(values[:], probabilities)\npyplot.show()","302cca98":"## 7. Why do we take negative log of probabilities in the entropy formula ?\n\nAns- To understand we need to look again to the likelihood function.\n\nAs we already know, likelihood equation can be framed according to problem. In case of classification, suppose we already have the model, input features and labels or classes, now we want to find the parameters of the model which correctly maps the input to their labels. So here it can be framed as\n\n`Likelihood` is the conditional probability, given the input features and parameters, what is the probability of observing any class variable .\n\n    Likelihood = P ( Y; (x1,x2,...xM ), theta )\n    \n    where x1,x2,...xn are the features(columns) , Y is the class or label and theta are the parameters.\n    \nSuppose we need to find out whether a fruit is apple ,orange or banana. So here `apple`, `orange` and `banana` are our classes. Now given any sample or input,  we might have features for `apple` like `red peel`, `non-spherical shape`, `white flesh`, `black seeds`. So likelihood would be given all these features , what is the probability that our model would categorise the fruit as `apple`.\n\n        likelihood for class apple = p (apple; features, theta)\n        likelihood for class orange  = p (orange; features, theta)\n        likelihood for class banana = p (banana; features, theta)\n\n                  \n    Total likelihood = p (apple; features, theta) * p (orange; features, theta) * p (banana; features, theta)\n    \nIn general likelihood,\n\n                     = product i to C Probability( class_i ; (x1,x2,...xM), theta )\n\nWe always want to **maximise this total likelihood (joint probability), higher the probability , higher the assurity that the fruit is apple and hence better classification**. \n\nNow suppose we are one hot encoding the target labels or classes as  `apple:[1,0,0], orange:[0,1,0] and banana:[0,0,1]`, we have a sample (row) which is `apple` i.e. our \n    \n    target distribution =  [t1,t2,t3] = [1,0,0] \n    \n    Suppose , predicted distribution = [p1, p2, p3] , where p1, p2, p3 are probabilities\n    \nWhile training the model, we want our **target to be apple**, then the model should give `p1` as its output. Then our likelihood equation converts to\n\n    Likelihood  = p1^t1 * p2^t2 * p3^t3  \n    \n    Lets say,\n    \n    Predicted distribution = [ 0.6, 0.3, 0.1] \n    \n    Likelihood = 0.6^1 * 0.3^0 * 0.1^0\n               = 0.6 * 1 * 1\n               = 0.6\n               \nThus whenever we have two distribution ( target and prediction) and we want to maximise the likelihood , our equation is\n\n     Likelihood one distribution given another distribution = p1^t1 * p2^t2 * p3^t3  \n\nHere the definition of likelihood can be understood as \n\n    How likely is our model to produce predicted distributions similar to the target distributions or\n    \n    What is the probability that our predictions would be similar to the target values\n    \n**Multiplying many small probabilities together can be numerically unstable in practice, therefore, it is common to restate this problem as the sum of the log conditional probabilities of observing each example given the model parameters.**\n\nTaking log of the product of probabilities becomes the sum of log of the probabilities.\n\n    Total Likelihood = t1 log p1 + t2 log p2 + t3 log p3 \n    \nAs we take the log here, it is also known as `log-likelihood estimation`. \n\nAs we know that **probabilities lie between 0 to 1 and log of these numbers are negative. So we put negative in front of the equation to make the overall value positive. Therefore, the negative of the log-likelihood function** is used, referred to generally as a `Negative Log-Likelihood (NLL)` function. \n    \n    - sum i to C  t_i log p_i\n    \nNegative log likelihood is also known as `Cross-Entropy`\n\n*************************************","d253b579":"## 3. Is minimizing least square in linear regression equivalent to maximum likelihood estimation ?\n\nAns- The answer would be yes, if **the distribution of the input data follows the gaussian distribution**. \n\nFor `least square minimization`, we want to find a line that minimises the total squared distance between the data points and the regression line. \n\nIn `maximum likelihood estimation` we want to maximise the total probability of the data. \n\nWhen a Gaussian distribution is assumed, the maximum probability is found when the data points get closer to the mean value. That means by minimising the distance between the data points and the mean value, we will maximize the total probability of the data.\n\nHence performing `OLS (Ordinary Least Squares)` is equivalent to performing `MLE (Maximum Likelihood Estimation)`\n\n***********************************","9704f905":"     Non-parametric Methods\n     \n         - In some cases, a data sample may not resemble a common probability distribution or cannot be easily made to fit the distribution. This is often the case when the data has two peaks (bimodal distribution) or many peaks (multimodal distribution).This doesn't make any assumption about the population's distribution. It just finds out the distrbution using all the sample.\n        \n `Kernel Density Estimation` - KDE is a non-parametric method to estimate density function of data generating distribution. KDE allocates high density to certain x if sample data has many datapoints around it. A datapoint\u2019s contribution to certain x depends on its distance to x and bandwidth. As the sample size increases, KDE approximation under certain conditions approaches true pdf. \n\nThe kernel function weights the contribution of observations from a data sample based on their relationship or distance to a given query sample for which the probability is requested.","0b8683b7":"## 4. What is probability density estimation or density estimation?\n\nAns- Density estimation is estimating the probability distribution of the population from the sample. \n\nEvery sample or set of data belongs to a population and since we don't know anything about population, we want to find out the population's nature using the sample data we have. So population is like a `domain` , we have some data (sample) from that domain and we want to find out about that domain. A distribution will let us know various things about the population or domain, like its \n\n    mean, median, variance, skewness, kurtosis\n    \nYou can think density estimation as an extrapolation method where we are trying to draw an inference about the population from its sample. Its similar to tasting a soup and telling about its ingredients. Its like testing a person's DNA to know about its ancestory. Its like a taking a leaf and finding about the whole tree.\n\nTypically, estimating the entire distribution is intractable, and hence we try to find the parameters that define them like mean, mode or variance. Density estimation techniques involve finding these parameters that will help in extrapolating the population distribution.\n\n**Why is it necessary ?**\n\nKnowing the probability distribution for a random variable can help to calculate moments of the distribution, like the mean and variance, but can also be useful for other more general considerations, like determining whether an observation is unlikely or very unlikely and might be an outlier or anomaly.\n\n**Techniques to determine density estimation** -\n\n    Parametric Methods\n    \n        - This method makes an assumption about the population's distribution. Gaussian (normal) distribution is the common distribution observed in most of the real life scenarios. So if we plot a histogram of a given sample and it resembles like normal distribution we assume that the population distribution might follow this pattern. ","1cabc4bc":"     Explicit Density Estimation\n     \n         - These techniques will produce a PDF (Probability density function) from the sample space. It can be parametric or non paramteric.\n         For example ; MLE (parametric) , KDE (non parametric) etc.\n         \n\n`Maximum Likelihood Estimation` - given by the formula \n    \n                    product i to n P( x_i; theta) \n                                                    \n                    where x_{} denotes the individual datapoints and theta are the parameters like mean and standard deviation.\n                                    \n\n\n`Maximum a Posteriori Estimation` - which is similar to Bayes theorem. It involves calculating the conditional probability of one outcome given another outcome, using the inverse of this relationship, stated as follows:\n\n    P(A | B) = (P(B | A) * P(A)) \/ P(B)\n\nThe quantity that we are calculating is typically referred to as the posterior probability of A given B and P(A) is referred to as the prior probability of A.\n\nThe normalizing constant of P(B) can be removed, and the posterior can be shown to be proportional to the probability of B given A multiplied by the prior.\n\n    P(A | B) is proportional to P(B | A) * P(A)\n\nOr, simply:\n\n    P(A | B) = P(B | A) * P(A)\n\nThis is a helpful simplification as we are not interested in estimating a probability, but instead in optimizing a quantity. A proportional quantity is good enough for this purpose.\n\nWe can now relate this calculation to our desire to estimate a distribution and parameters (theta) that best explains our dataset (X), as we described in the previous section. This can be stated as:\n\n    P(theta | X) = P(X | theta) * P(theta)\n\nMaximizing this quantity over a range of theta solves an optimization problem for estimating the central tendency of the posterior probability (e.g. the model of the distribution). As such, this technique is referred to as \u201cmaximum a posteriori estimation,\u201d or MAP estimation for short, and sometimes simply `maximum posterior estimation`\n\n    maximize P(X | theta) * P(theta)\n\nwe are calculating a point estimation such as a moment of the distribution, like the mode, the most common value, which is the same as the mean for the normal distribution.","9d8eef5e":"## 2. What is the difference between a probability and likelihood and what is maximum likelihood estimation ?\n\nAns - If we have a **fair** coin (parameter value), `Probability` of coming **heads** is `0.5`. If we toss a coin 100 times and it comes up with head 52 times, then it has high `Likelihood` of being **fair**. Probability quantifies anticipation (of outcome), likelihood quantifies trust (in model). \n\n*--------from StackOverflow*\n\nAs we can see, **probability will help us to know the chances of the outcome (heads or tails) whereas likelihood will help us to know whether coin is fair enough to give those probabilities**. In the view of machine learning, suppose we have a classification problem, `probability (P)`, is,  given the input **x** what is the chance that it will fall under a particular **class (C)**, \n    \n    P (C;x) \nwhereas `likelihood (L)` will tell us whether the **classifier or model is strong enough** to distinguish the inputs into their particular category i.e. \n    \n    L ( P(C;x) ; model )\n    \nA model is defined by any function `F`, like sigmoid or softmax function in case of logistic regression and these functions are defined by various parameters `theta` that we tune while optimization (Hyperparameter Tuning) , hence `likelihood` can be written as \n\n    L ( P(C;x) ; F(theta) )\n\nIn classification, we usually have inputs ,x,  with their labels ,C, from here we can find out the probability P (C\/x) , so our objective becomes to find a mathematical function to assure this probability. Hence we can say, classification is a process of finding likelihood. Now usually in the classification, mathematical function is known to us, like sigmoid, softmax or tanh, hence our objective becomes to mold these functions in a way that correctly maps the inputs to their outputs. These functions can be mold using different parameters values , like coefficients or weights associated with the inputs, so our objective now becomes that \n\n    Using any set of parameters what is the probability that the input will give a particular outcome or\n    \n    Given a set of hyperparameters in the model ,what is the possibility that a particular set of input will fall under its lablled class or\n    \n    How likely is our model to correctly classify the input x to its respective class C\n    \n    L ( P (C;x) ; F(theta) )\n    \n    The only value which is unknown to us are parameters that is theta\n    \nWe always want to **maximise this likelihood** in order to get a strong model, hence it is known as `Maximum Likelihood Estimation`. Hence we can say that maximum likelihood estimation is the process of maximizing the probability of seeing a bunch of data in any category for any set of parameters. \n\n### In order to understand it more correctly, lets take a classification scenario.\n\nIn case of classification, suppose we already have the model, input features and labels or classes, now we want to find the parameters of the model which correctly maps the input to their labels. So here it can be framed as\n\n`Likelihood` is the conditional probability, given the input features and parameters, what is the probability of observing any class variable .\n\n        Likelihood = P ( Y; (x1,x2,...xM ), theta )\n\n        where x1,x2,...xn are the features(columns) , Y is the class or label and theta are the parameters.\n\nSuppose we need to find out whether a fruit is apple ,orange or banana. So here `apple`, `orange` and `banana` are our classes. Now given any sample or input,  we might have features for `apple` like `red peel`, `non-spherical shape`, `white flesh`, `black seeds`. So likelihood would be given all these features , what is the probability that our model would categorise the fruit as `apple`.\n\n        likelihood for class apple = p (apple; features, theta)\n        likelihood for class orange  = p (orange; features, theta)\n        likelihood for class banana = p (banana; features, theta)\n\n        Total likelihood = p (apple; features, theta) * p (orange; features, theta) * p (banana; features, theta)\n\nIn general likelihood,\n\n                         = product i to C Probability( class_i ; (x1,x2,...xM), theta )\n\nWe always want to **maximise this total likelihood (joint probability), higher the probability , higher the assurity that the fruit is apple and hence better classification**. Hence the name `Maximum Likelihood Estimation`.\n\nYou can think it as an optimization function also and parameters can be anything according to the different scenario. For example, at the time of \n\n    MODEL SELECTION, our parameters (theta) will be different machine learning models ( KNN, Random Forest, Gradient Boosting etc.), so here we want to maximise the probability of observing accurate results given any model. How likely a particular model is to give accurate results.\n    \n    L (Training Dataset; model) \n    \n    PROBABILITY DENSITY ESTIMATION, our paramters will be mean and standard deviation, so here our objective is to maximize the probability of seeing a data (x), with the given mean and standard deviation.\n    \n    L ( x ; mean, standard deviation ) \n******************************************************************************","32fefcc9":"# Advanced Machine Learning Concepts\n**************************\n\nThis notebook contains answer to some of the advanced questions related to the machine learning. This notebook also assumes that you are aware of the basic machine learning algorithms and concepts. The answers written here are totally based on my understanding and research. If I am mistaken somewhere, please let me know in the comment section.","5ec0a70a":"## 5. How are Maximum Likelihood Function (MLE) and Maximum a Posteriori (MAP) related to each other ?\n\nAns - `MAP` is very similar to `MLE`, with the addition of the prior probability over the distribution and parameters. In fact, if we assume that all parameters (theta) are equally likely because we don\u2019t have any prior information (e.g. a uniform prior), then both calculations are equivalent.\n\nBecause of this equivalence, both MLE and MAP often converge to the same optimization problem for many machine learning algorithms. This is not always the case; if the calculation of the MLE and MAP optimization problem differ, the MLE and MAP solution found for an algorithm may also differ.\n\nIn machine learning, Maximum a Posteriori optimization provides a Bayesian probability framework for fitting model parameters to training data and an alternative and sibling to the perhaps more common Maximum Likelihood Estimation framework. One framework is not better than another and in many cases, both frameworks frame the same optimization problem from different perspectives.\n\nInstead, **MAP is appropriate for those problems where there is some prior information**, e.g. where a meaningful prior can be set to weigh the choice of different distributions and parameters or model parameters. \n\n**MLE is more appropriate where there is no such prior**.\n\nIn fact, the **addition of the prior to the MLE can be thought of as a type of regularization of the MLE calculation**. This insight allows other regularization methods (e.g. L2 norm in models that use a weighted sum of inputs) to be interpreted under a framework of MAP Bayesian inference. For example, L2 is a bias or prior that assumes that a set of coefficients or weights have a small sum squared value.\n\nFrom Model Selection point of view\n\n    MAP = maximize P(Training Dataset | model) * P(model)\n    \n    MLE = maximize P(Training Dataset | model)\n    ","465c7d68":"## 1. Does introducing polynomial features while polynomial regression bring multicollinearity to the model ? If it is, then what are the other options ?\n\nAns - This question was asked by a user on stackoverflow to which I have answered it there and I am writing the same answer here.\n\nMulti-collinearity isn't always a hindrance. It depends from data to data. If your model isn't giving you the best results(high accuracy or low loss), you then remove the outliers or highly correlated features to improve it but if everything is hunky-dory, you don't bother about them.\n\nSame goes with `polynomial regression`. In polynomial regression, we introduce higher order polynomials i.e., adding quadratic and cubic terms. Indirectly we add more features to our dataset. As these features are a linear transformation of the feature already present in the dataset, it adds multi-collinearity in your model by introducing x^2, x^3 features into the model. There are other issues as well. As we increase the complexity of the formula, the number of features also increases which is sometimes difficult to handle. Also, polynomial regression has a tendency to drastically over-fit, even on a simple one dimensional data set\n\nTo overcome that, we can use `orthogonal polynomial regression` which introduces polynomials that are orthogonal to each other.\n\nBut it will still introduce higher degree polynomials.\n\nTo overcome this issue, we can use `Regression Splines` in which it divides the distribution of the data into separate portions and fit linear or low degree polynomial functions on each of these portions. The points where the division occurs are called `Knots`. Functions which we can use for modelling each piece\/bin are known as `Piecewise functions`. This function has a constraint , suppose, if it is introducing 3 degree of polynomials or cubic features and then the function should be second-order differentiable. Such a piecewise polynomial of degree m with m-1 continuous derivatives is called a `Spline`.\n\n**For more details, [please refer to this article](https:\/\/www.analyticsvidhya.com\/blog\/2018\/03\/introduction-regression-splines-python-codes\/).**\n******************************************************","610e11ca":"     Implicit Density Estimation\n     \n         - It will not produce any PDF, but it will generate a function for the population from which you can draw samples.\n         \n\n### Implicit Density Estimation \n\nmethods are\n\n`Variational AutoEncoders` - VAE consists of an encoder and a decoder. `Encoder` compresses the sample point space to two values depicting its `mean` and `standard deviation`. This mean and standard deviation are the parameters of the population.`Decoder` then uses that mean and standard deviation to create new datapoints that follows the original distribution.\n\n**For Reference - [look into this notebook](https:\/\/www.kaggle.com\/shweta2407\/variational-autoencoders-for-synthetic-data)**\n\n`Generative Adversial Network`  - This technique involves two models `generator` and `discriminator`, where a generator creates a random sample space and passes it through the discriminator. Discriminator takes that random space and compares it with original sample space and detects whether the random sample is equal to the original sample space or not. Generator keeps on improving itself until Discriminator stops discriminating between the random space and the original space. Once the discriminator stops that means generator has been successful to generate sample spaces equivalent to the original one. Then this generator function can be used to create new sample points.\n\n********************************************************************","c3d3d01a":"## 6. What is a cross-entropy ?\n\nAns- **Entropy** is the measure of uncertainty associated with any distribution. By distribution here means the distribution of the class variables in the classification problem. By uncertainty, how sure are we that a class variable belongs to the class distribution.\n\nThis might sound boggling now, but would make sense later.\n\nLet's say there are two classes `a` and `b`. Probability of class `a` is `p(a)` and `p(b)` for `b`. So the entropy of `a` and `b` would be \n\n    entropy(a) = - p(a) log p(a) \n\n    entropy(b) = - p(b) log p(b)\n\nSo the total entropy is : \n    \n    -[ entropy(a) + entropy(b) ]\n    \nSuppose we know that all of our datapoints falls into `a` category that means \n\n    total entropy = entropy(a)\n                  = - p(a) * log p(a)\n                  = - 1 * log(1)\n                  = - 1 * 0 \n                  = 0\nWe have `0` entropy i.e. there is uncertainty of `0` regarding the datapoint into which category it falls or we are very certain. Hence **Entropy** is the measure of uncertainty.\n\n**Cross-entropy** is the measure of uncertainty between two distributions given by the following formula.\n\n    cross-entropy of a class x = - t(x) log p(x)  \n\nIn classification scenario, we have two distributions, the target distribution `t(x)` and the predicted distribution `p(x)`. \n\nSuppose we have a dataset of 10 samples and `target labels = [ a, b, a, a, b, a, a, b, a, a]`. Now the probabilities are\n\n    p(a) = 0.7\n    p(b) = 0.3\n    \n    target probability distribution, t(a,b) = [0.7, 0.3]\n    \nNow we trained a model on the dataset and it predicted the distribution as `[0.6, 0.4]`. Now cross-entropy would be\n\n    t(a,b) = [0.7, 0.3]\n    \n    p(a,b) = [0.6, 0.4]\n    \n    cross-entropy = - [ 0.7 * log(0.6) + 0.3 * log(0.4) ] \n                  = - [-0.3575 + ( - 0.2748) ]\n                  = 0.6323 (aaprox.)\n                  \nThis `0.623` tells the uncertainty present in the model. Hence we need to reduce it. This is main objective of the classification problems to minimize the cross-entropy value i.e., `loss function`.\n\nYou see even if you do your predicted probability distribution as `[0.7, 0.3]` , you will get the entropy as `0.357`. This is the minimum and it tells that there is 0.357 uncertainty in the model. \n\n**Why it is 0.357 why not 0 when we have correctly predicted the target distribution ?**\n\nBecause this is cross entropy, this is the uncertainty between two distributions rather than entropy where the uncertainty is measured within a single distribution. We can never be sure that the one distribution comes from the second distribution.\n\n*************************************"}}