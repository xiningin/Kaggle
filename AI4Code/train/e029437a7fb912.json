{"cell_type":{"37c76563":"code","f1cf017c":"code","1b5111df":"code","977aad7b":"code","9ea130bd":"code","ab5b1444":"code","31d8cfae":"code","45574cf6":"code","1037dc45":"code","fd60a166":"code","cb1daeae":"code","e2f5bb35":"code","57c9ead6":"code","fcc5eb2b":"code","d92d9c84":"code","cccdc1e1":"code","eefa6b77":"code","8e9de008":"code","56e5770f":"code","c658702f":"code","1b68fab4":"code","4312ddc6":"code","ef36ceee":"code","36fe2a4d":"code","e1951310":"code","5b685a2b":"code","42e497dc":"code","8aa4795e":"code","4a73fcc1":"code","80ed4b5e":"code","e339c038":"markdown","9125ce07":"markdown","11496335":"markdown"},"source":{"37c76563":"!pip install pandarallel\n!python -m spacy download pt","f1cf017c":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nimport spacy\nimport pickle\nimport os\nimport matplotlib.pyplot as plt\n\nfrom scipy.sparse import hstack\nfrom nltk.corpus import stopwords\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer,RSLPStemmer\nfrom pandarallel import pandarallel\n\npandarallel.initialize(shm_size_mb=2000, progress_bar=True, nb_workers=3)\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.max_rows', 200)\n%matplotlib inline","1b5111df":"import nltk\nnltk.download('stopwords')\nnltk.download('rslp')\nnltk.download('punkt')\nnltk.download('wordnet')\n\nstemmer=RSLPStemmer()\nlemma=WordNetLemmatizer()","977aad7b":"#Load data\ntrain = pd.read_csv('\/kaggle\/input\/nlp-deeplearningbrasil-ml-challenge\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-deeplearningbrasil-ml-challenge\/test.csv')","9ea130bd":"# Count words occurrence on title column\npd.Series(' '.join(train['title']).lower().split()).value_counts()[:100]","ab5b1444":"# Search for word on title column\nteste  = pd.read_csv('\/kaggle\/input\/nlp-deeplearningbrasil-ml-challenge\/train.csv', encoding=\"utf-8\").title.str.count('Prote\u00e7ao')\nteste.sum(axis = 0, skipna = True) ","31d8cfae":"# List rows filter by category\nengine = pd.read_csv('\/kaggle\/input\/nlp-deeplearningbrasil-ml-challenge\/train.csv', encoding=\"utf-8\")[train['category'] == 'CELLPHONE_REPAIR_TOOL_KITS']","45574cf6":"engine[0:50]","1037dc45":"# Words with incorrect spelling\n#misspeling = {\n    #\"und\": \"unidade\", \n    #\"seg\": \"segundos\", \n    #\"lamp\": \"l\u00e2mpada\",\n    #\"dobradica\": \"dobradi\u00e7a\", \n    #\"profisional\": \"profissional\", \n    #\"recpetor\": \"receptor\"\n#}","fd60a166":"# Custom stop words list\n#remove_words = ['balada', 'segundos', 'profissional', 'golf']","cb1daeae":"#Category count\ntrain['category'].value_counts()","e2f5bb35":"#Add new features\n#train['title_size'] = train['title'].progress_map(lambda s: len(s))\n#train['title_upper'] = train['title'].progress_map(lambda s: sum(1 for c in s if c.isupper()))\n#train['word_count'] = train['title'].progress_map(lambda s: len(s.split()))\n#train['root_element'] = train['title'].progress_map(lambda s: ' '.join(token.lemma_ for token in nlp(s) if token.dep_ == 'ROOT'))","57c9ead6":"# Pre processing data\n\nimport unidecode\nimport unicodedata\n\nnlp = spacy.load('pt', parser=False, entity=False)\n\ndef preProcessing(x):\n    \n    #has = False\n    \n    # Converting to Lowercase\n    x = x.lower()\n            \n    #Remove stop words spacy\n    x = ' '.join(token.text for token in nlp(x) if not token.is_stop)\n    \n    # Remove links\n    x = re.sub(r'http\\S+', ' ', x)\n    \n    # Remove all the special characters\n    x = re.sub(r'\\W', ' ', x)\n    \n    # Remove punct\n    x = x.translate(str.maketrans(\"\",\"\", string.punctuation))\n    \n    # Remove Numbers\n    x = re.sub(r'\\d+', ' ', x)\n    \n    # Remove accents\n    x = unicodedata.normalize('NFD', x)\n    x = x.encode('ascii', 'ignore')\n    x = x.decode(\"utf-8\")\n    \n    # Stemmer\n    result = []\n    for item in x.split():\n        result.append(stemmer.stem(item))\n    \n    x = ' '.join(result)    \n    \n    return x","fcc5eb2b":"train.head()","d92d9c84":"# Executing text pre processing on train dataframe\ntrain['title'] = train['title'].parallel_map(preProcessing)","cccdc1e1":"# Executing text pre processing on test dataframe\ntest['title'] = test['title'].parallel_map(preProcessing)","eefa6b77":"#After pre processing\ntrain.head(100)","8e9de008":"# List of imports\n\nfrom sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV, train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn import preprocessing\nfrom imblearn.over_sampling import SMOTE\nfrom matplotlib import pyplot as plt\nfrom sklearn.svm import SVC","56e5770f":"# Define y value\ny = train['category'].values","c658702f":"# TEST PARAMS\n\nfrom imblearn.pipeline import Pipeline\n\nX_train, X_test, y_train, y_test = train_test_split(train['title'], y, test_size=0.15, random_state=0)\n\ntext_clf_red = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n                       ('tfidf', TfidfTransformer(smooth_idf=False)),\n                       ('clf', LinearSVC())\n                       ])\n\ntext_clf_red.fit(X_train, y_train)\ny_test_pred = text_clf_red.predict(X_test)\naccuracy_score(y_test, y_test_pred)","1b68fab4":"#pipeline = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n#                       ('tfidf', TfidfTransformer()),\n#                       ('clf', LinearSVC())\n#                       ])\n\n#parameters = {\n#    'vect__max_df': (0.5, 0.75, 0.9),\n#    'vect__min_df':(2 , 3),\n#    'vect__max_features': (25000, 35000, 40000),\n    #'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n#    'tfidf__use_idf': (True, False),\n#    'tfidf__smooth_idf': (True, False),\n#    'tfidf__sublinear_tf': (True, False),\n    #'tfidf__norm': ('l1', 'l2'),\n#    'clf__class_weight': (None, 'balanced'),\n#    'clf__C': (1, 100, 500),\n    #'clf__max_iter': (10, 50, 80, 150),\n#}","4312ddc6":"#grid_search = GridSearchCV(pipeline, parameters, cv=6,\n#                           n_jobs=-1, verbose=1)\n\n#grid_search.fit(X_train, y_train)","ef36ceee":"#grid_search.best_params_","36fe2a4d":"# Vectorizer\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html\n\n# Value of max_feature is not the same, decrease to run on kaggle, original was 36500\nvectorizer = CountVectorizer(max_features=5000, ngram_range=(1, 2))\ncon = pd.concat([train, test], sort=False)\nX = vectorizer.fit(con['title'])\n\n# Transform with train and test title\nX_comp = vectorizer.transform(con['title'])\nX = vectorizer.transform(train['title'])","e1951310":"# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.TfidfTransformer.html\ntfidfconverter = TfidfTransformer(smooth_idf=False)\nX_comp = tfidfconverter.fit(X_comp)\nX = tfidfconverter.transform(X).toarray()","5b685a2b":"# Train test split on data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)","42e497dc":"#OVERSAMPLE\n\nsmote = SMOTE(ratio='minority')\nX_res, y_res = smote.fit_sample(X, y)","8aa4795e":"%%time\n# LINEAR SVC\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.LinearSVC.html\nlinf = LinearSVC()\nlinf.fit(X_res, y_res)\n\n# predict and evaluate predictions\npredictions = linf.predict(X_test)\n\n#linf_score = cross_val_score(linf, X_res, y_res, cv=5, scoring='accuracy')\n#print(linf_score)\n#print(linf_score.mean())\n\nprint('accuracy %s' % accuracy_score(predictions, y_test))\nprint(classification_report(y_test, predictions,target_names=train['category'].unique()))","4a73fcc1":"simple_data = vectorizer.transform(test['title'])\nsimple_data = tfidfconverter.transform(simple_data).toarray()\n\nsimple_result = linf.predict(simple_data)\n#y_test_pred = text_clf_red.predict(test['title'])\n\n# Submission\nsubmission = pd.DataFrame({\n    \"id\": test.index.values,\n    \"category\": simple_result\n})\n\n# Create file\nsubmission.to_csv('submission.csv', index=False)","80ed4b5e":"submission.head(10)","e339c038":"# SIMPLE PREDICT AND SUBMISSION","9125ce07":"# PIPELINE FOR TESTS","11496335":"# LINEAR SVC"}}