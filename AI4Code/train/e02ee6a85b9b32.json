{"cell_type":{"89baa7fe":"code","b2c9f377":"code","0c564eb4":"code","0b16a777":"code","91a61449":"code","0a08aed6":"code","d5be8cba":"code","b4868d72":"code","86e3e62e":"code","fd62dd20":"code","b6cfd720":"code","fe6d7949":"code","3301ea72":"code","d1c17887":"code","172b5896":"code","71a29c39":"code","ab68418f":"code","17b8acde":"code","534997b0":"code","923a0978":"code","8ccef650":"code","f9fc69f3":"code","224cb9c3":"code","0c677cd2":"code","1e9c4702":"markdown","8fe1a10b":"markdown","ffd0363b":"markdown","ce5eb6d2":"markdown","b17eccd8":"markdown","0cbe5866":"markdown","46b68526":"markdown","9e6cd2df":"markdown","1fd2e6e1":"markdown","8ce3617e":"markdown"},"source":{"89baa7fe":"import numpy as np\nimport pandas as pd\n\nimport os\nprint(os.listdir('..\/input\/digit-recognizer'))\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n\nfrom sklearn.model_selection import train_test_split\n\n# OpenCV Image Library\nimport cv2 # Image provessing library\n\n# Import PyTorch\nimport torchvision.transforms as transforms # Useful to make transformation on images easily\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch\nimport torch.nn as nn # To build neural network on PyTorch\nimport torch.nn.functional as F # Useful to get specific layers for the nn\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset # To create torch datasets\nimport torchvision # Very large package that contains datasets, models etc...\nimport torch.optim as optim # To get the optimizer of our model","b2c9f377":"# Data paths\ntrain_path = '..\/input\/digit-recognizer\/train.csv'\ntest_path = '..\/input\/digit-recognizer\/test.csv'\nsample_sub_path = '..\/input\/digit-recognizer\/sample_submission.csv'","0c564eb4":"df_train = pd.read_csv(train_path, dtype=np.float32)\ndf_test = pd.read_csv(test_path, dtype=np.float32)\ndf_sample_sub = pd.read_csv(sample_sub_path)","0b16a777":"print(df_train.shape)\nprint(df_test.shape)\nprint(df_sample_sub.shape)","91a61449":"y_train_full = df_train['label'].to_numpy() # We need to convert pd.DataFrame to numpy array to then, convert it to PyTorch tensor\nX_train_full = df_train.loc[:,df_train.columns != 'label']","0a08aed6":"X_train_full = X_train_full.values.reshape(-1,1,28,28) # (nbr of samples, height, width, channel) Since these are not colored images, there's only one channel\ndf_test = df_test.values.reshape(-1,1,28,28) # It's different from keras where the channel is usualy the last dimension.\n\nX_train_full \/= 255.0\ndf_test \/= 255.0\n\n# Split into training and test set\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42) # As usual","d5be8cba":"# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\nX_train_pyt = torch.from_numpy(X_train)\ny_train_pyt = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for validation set.\nX_val_pyt = torch.from_numpy(X_val)\ny_val_pyt = torch.from_numpy(y_val).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for the final set that will be used to train the final model.\nX_train_full_pyt = torch.from_numpy(X_train_full)\ny_train_full_pyt = torch.from_numpy(y_train_full).type(torch.LongTensor) # data type is long\n\n# Data for submission\nX_test_pyt = torch.from_numpy(df_test)\n#y_test_pyt = torch.from_numpy(y_test).type(torch.LongTensor)","b4868d72":"print(X_train_pyt.shape) # These are now pytorch tensors\nprint(X_val_pyt.shape)\nprint(X_train_full_pyt.shape)\nprint(X_test_pyt.shape)","86e3e62e":"# Set batch size\nbatch_size = 64\n\n# We now create PyTorch dataframess\ndf_train_pyt = torch.utils.data.TensorDataset(X_train_pyt,y_train_pyt)\ndf_val_pyt = torch.utils.data.TensorDataset(X_val_pyt,y_val_pyt)\ndf_train_full_pyt = torch.utils.data.TensorDataset(X_train_full_pyt,y_train_full_pyt)\ndf_test_pyt = torch.utils.data.TensorDataset(X_test_pyt)\n\n# and load the dataframes with batch of images\ntrain_loader = torch.utils.data.DataLoader(df_train_pyt, batch_size = batch_size, shuffle = True)\nvalid_loader = torch.utils.data.DataLoader(df_val_pyt, batch_size = batch_size, shuffle = True)\nsubmission_loader = torch.utils.data.DataLoader(df_train_full_pyt, batch_size = batch_size, shuffle = True)\ntest_loader = torch.utils.data.DataLoader(df_test_pyt, batch_size = batch_size, shuffle = False)","fd62dd20":"one_batch_images, one_batch_labels = next(iter(train_loader))\n\none_image = one_batch_images[0,0,:,:]\none_label = one_batch_labels[0]\n\nplt.imshow(one_image)\nplt.title(one_label)\nplt.axis('off')\nplt.show()","b6cfd720":"class Net(nn.Module): # In PyTorch, models are made through a class\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(in_features = 320,  out_features = 50)\n        self.fc2 = nn.Linear(in_features = 50, out_features = 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)","fe6d7949":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","3301ea72":"# create a complete CNN\nmodel = Net()\nprint(model)\n\n# Move model to GPU if available\nif train_on_gpu: model.cuda()","d1c17887":"criterion = nn.NLLLoss()\n\n# Define the optimier\noptimizer = optim.Adam(model.parameters(), lr=0.0015)","172b5896":"# number of epochs to train the model\nn_epochs = 30\n\nvalid_loss_min = np.Inf # track change in validation loss\n\n# keeping track of losses as it happen\ntrain_losses = []\nvalid_losses = []\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n        \n    # print training\/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'best_model.pt')\n        valid_loss_min = valid_loss","71a29c39":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(valid_losses, label='Validation loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend(frameon=False)","ab68418f":"# Load Best parameters learned from training into our model to make predictions later\n#best_model = model.load_state_dict(torch.load('best_model.pt'))\n#model.load_state_dict(torch.load('best_model.pt'))\n\n#model.load_state_dict(torch.load('best_model.pt'))\ncheckpoint = torch.load('best_model.pt')\nmodel.load_state_dict(torch.load('best_model.pt'))","17b8acde":"for keys in checkpoint:\n    print(keys)","534997b0":"#final_test_np = final_test.values\/255\ntest_tn = torch.from_numpy(df_test)","923a0978":"# Creating fake labels for convenience of passing into DataLoader\n## CAUTION: There are other ways of doing this, I just did it this way\nfake_labels = np.zeros(df_test.shape)\nfake_labels = torch.from_numpy(fake_labels)","8ccef650":"submission_tn_data = torch.utils.data.TensorDataset(test_tn, fake_labels)\n\nsubmission_loader = torch.utils.data.DataLoader(submission_tn_data, batch_size = batch_size, shuffle = False)","f9fc69f3":"# Making it submission ready\nsubmission = [['ImageId', 'Label']]\n\n        \n\n# Turn off gradients for validation\nwith torch.no_grad():\n    #best_model.eval()\n    model.eval()\n    image_id = 1\n    for images, _ in submission_loader:\n        if train_on_gpu:\n            images = images.cuda()\n        log_ps = model(images)\n        ps = torch.exp(log_ps)\n        top_p, top_class = ps.topk(1, dim=1)\n        \n        for prediction in top_class:\n            submission.append([image_id, prediction.item()])\n            image_id += 1","224cb9c3":"submission_df = pd.DataFrame(submission)\nsubmission_df.columns = submission_df.iloc[0]\nsubmission_df = submission_df.drop(0, axis=0)","0c677cd2":"submission_df.to_csv(\"submission.csv\", index=False)","1e9c4702":"## Display results","8fe1a10b":"# Running the model","ffd0363b":"# Import the relevant libraries","ce5eb6d2":"# Introduction to PyTorch on the MNIST Digit classification","b17eccd8":"# Display one image","0cbe5866":"## Convert the data","46b68526":"## Load the training data","9e6cd2df":"!This aim of the notebook is to show on a basic exemple how to use PyTorch for an image classification task. PyTorch is an alternative to TensorFlow to develop machine learning and deep learning models. It was developped by Facebook and in my opinion, it is a nice way to go deeper in deep learning after an introduction with Keras.","1fd2e6e1":"# Submission","8ce3617e":"# Define the model"}}