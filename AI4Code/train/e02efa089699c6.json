{"cell_type":{"e8d9316b":"code","ac557139":"code","0217c4b9":"code","0c670dba":"code","d9692279":"code","7ac57ddd":"code","b2dd92c9":"code","8cec0b26":"code","3cda8f35":"code","3827155c":"code","11124562":"code","f6abc474":"code","e9f580ed":"code","7de24143":"code","42bfd79d":"code","b8f36994":"code","d1f4f051":"code","4ec0911b":"code","4eeeab07":"code","01f8b48b":"code","667a5b99":"code","f560c100":"code","b23e04b0":"code","f0011502":"code","47b0d739":"code","19c81553":"code","e133fb99":"code","8f5421a9":"markdown","d343685c":"markdown","a210f2cf":"markdown","b86d1a3e":"markdown","d4d3437b":"markdown","0e7fdaf3":"markdown","8d97a456":"markdown","12dd863c":"markdown","0ec9c36c":"markdown","36eb8f1b":"markdown","80f620d9":"markdown","1a4db1de":"markdown","3e1463bf":"markdown","45b57cac":"markdown","a374df19":"markdown","70bc2b07":"markdown","83edb2ae":"markdown","e73ca03b":"markdown","a1b79fa8":"markdown","f850ebce":"markdown","4f3a09de":"markdown","719261b4":"markdown","e8cb885c":"markdown","f5dab80d":"markdown","0d02ecaf":"markdown","1064a94d":"markdown","64a0954d":"markdown","f504d000":"markdown","4323cc07":"markdown","5adf0dd5":"markdown","2545cc61":"markdown","f932488c":"markdown","e6203e64":"markdown","8224e648":"markdown","430eb03f":"markdown","67248636":"markdown","0c0633ad":"markdown","d47449bd":"markdown","a5cb338a":"markdown","2a14ab00":"markdown","d3b258b9":"markdown","224cd5d9":"markdown","d3627415":"markdown"},"source":{"e8d9316b":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","ac557139":"import pandas as pd\nimport numpy as np","0217c4b9":"import sklearn.metrics\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","0c670dba":"sns.set(rc={'figure.figsize':(10, 7)})","d9692279":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')","7ac57ddd":"train_df.head()","b2dd92c9":"test_df.head()","8cec0b26":"train_df.describe()","3cda8f35":"test_df.describe()","3827155c":"train_df.isnull().sum()","11124562":"test_df.isnull().sum()","f6abc474":"sns.displot(train_df, x='Age', hue='Survived', kde=True, col='Pclass', row='Sex')","e9f580ed":"train_df.groupby(['Pclass', 'Sex'])['Age'].median().to_frame()","7de24143":"train_df.loc[train_df['Embarked'].isnull()]","42bfd79d":"name_prefixes = train_df['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0].to_frame().rename({0: 'prefix'}, axis=1)\nsns.catplot(data=name_prefixes, x='prefix', kind='count', height=5, aspect=2.9)","b8f36994":"train_df.corr()['Survived'][['SibSp', 'Parch']]","d1f4f051":"sns.displot(train_df, x='Fare', hue='Survived', kde=True, aspect=2.5, height=10)","4ec0911b":"sns.displot(x=train_df.loc[train_df['Fare'] <= 100, 'Fare'], hue=train_df['Survived'], kde=True, aspect=2.5, height=10)","4eeeab07":"def prepare_features(df, drop_id=True):\n    # 1. Fill NaN values\n    df.Age = df.groupby(['Sex', 'Pclass']).Age.apply(lambda x: x.fillna(x.median())).astype(int)\n    df.Embarked = df.Embarked.fillna('S')\n    df.Fare.fillna(df.Fare.median(), inplace=True)\n    # 2. String values converting\n    df['Male'] = df['Sex'].map({'male': 1, 'female': 0}).astype(int)\n    df.Embarked = df.Embarked.map({'C': 0, 'Q': 1, 'S': 2})\n    # 3. Name\n    df['NameTitle'] = df['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    df['NameTitle'] = df['NameTitle'].replace(['Lady', 'the Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    df['NameTitle'] = df['NameTitle'].replace(['Mlle', 'Ms'], 'Miss')\n    df['NameTitle'] = df['NameTitle'].replace(['Mme'], 'Mrs')\n    df['NameTitle'] = df['NameTitle'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}).astype(int)\n    # 4. Family\n    df['FamilySize'] = df.SibSp + df.Parch + 1\n    df['IsAlone'] = 0\n    df.loc[df.FamilySize == 1, 'IsAlone'] = 1\n    # 5. Fare\n    df['FareCategory'] = 0\n    df.loc[(df['Fare'] <= 6), 'FareCategory'] = 0\n    df.loc[(df['Fare'] > 6) & (df['Fare'] <= 16), 'FareCategory'] = 1\n    df.loc[(df['Fare'] > 16) & (df['Fare'] <= 40), 'FareCategory'] = 2\n    df.loc[(df['Fare'] > 40), 'FareCategory'] = 3\n    # 6. Another columns\n    if drop_id:\n        df = df.drop(['PassengerId'], axis=1)\n    df = df.drop(['Sex', 'Name', 'Ticket', 'SibSp', 'Parch', 'FamilySize', 'Fare', 'Cabin'], axis=1)\n    return df","01f8b48b":"train_df = prepare_features(train_df)\ntest_df = prepare_features(test_df, drop_id=False)\ntrain_df.head()","667a5b99":"sns.heatmap(train_df.corr(), annot=True, vmin=-1)","f560c100":"sns.catplot(data=train_df, x='Survived', hue='NameTitle', kind='count')","b23e04b0":"X = train_df.drop('Survived', axis=1)\ny = train_df.Survived","f0011502":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)","47b0d739":"rf = RandomForestClassifier(n_estimators=100, max_depth=5)\nrf.fit(X_train, y_train)","19c81553":"print(\"Train score: \" + str(rf.score(X_train, y_train)))\nprint(\"Test score: \" + str(rf.score(X_test, y_test)))\nprint(\"Global score: \" + str(rf.score(X, y)))","e133fb99":"predictions = rf.predict(test_df.drop('PassengerId', axis=1))\npd.concat([test_df['PassengerId'].to_frame(), pd.DataFrame(predictions)], axis=1).rename({0: 'Survived'}, axis=1).to_csv('predictions.csv', index=False)","8f5421a9":"**4. Family**","d343685c":"Not bad! Let's predict for the test dataset and save the result","a210f2cf":"Let's divide the prefixes into 5 categories: 4 of them are the most popular, the fifth is all other.","b86d1a3e":"I will use Random Forest model.","d4d3437b":"Here the fare distribution:","0e7fdaf3":"# 2. Feature engineering","8d97a456":"**1.3 Embarked**","12dd863c":"# 3. Model","0ec9c36c":"Let's see how good it is","36eb8f1b":"There are 177 NaN values in train dataset and 86 in test. Let's look at the distribution of age according to class and gender.","80f620d9":"Importing:\n1. matplotlib and seaborn for visualization\n2. pandas and numpy to work with data\n3. sklearn for machine learning","1a4db1de":"**Function:**","3e1463bf":"**Data preparation**","45b57cac":"We have two columns that store the number of relatives and servants. Let's look at their correlation with the target.","a374df19":"The correlation is not that high. We can try to combine them into a 'Family Size' column this way: SibSp + Parch + 1, and then, leave only the 'IsAlone' column, which shows whether the person traveled alone.","70bc2b07":"As we can see, they are quite different. It would be logical to fill in the missing age values based on the information about class and sex.","83edb2ae":"**2.2 Loading the data**","e73ca03b":"**1.1 Importing Libraries**","a1b79fa8":"As we can see, there are missing values in the data. We will need to fix it.","f850ebce":"A quick overview of the data","4f3a09de":"Loading train and test datasets","719261b4":"**1.1 Age**","e8cb885c":"**2. String values converting**\n\nFor convenience, we will encode the gender and port with numerical values.","f5dab80d":"It is difficult to see any clear boundaries here, so I categorized it this way:\n1 category - from 0 to 6\n2 category - from 6 to 16\n3 category - from 16 to 40\n4 category - over 40","0d02ecaf":"# 1. Some preparations","1064a94d":"There is one missing fare value. It doesn't have a big impact on accuracy if we fill it in with the median.","64a0954d":"I wrote the features preparation in one function so that it would be convenient to apply it to train and test datasets. I tried to add as many comments as possible to make it clear.","f504d000":"We have a name column, and all we can get out of it are name prefixes like 'Mr', 'Mrs', 'Miss' and so on. Let's take a look at the number of such prefixes and their distribution.","4323cc07":"My solution to the classic Titanic problem.","5adf0dd5":"**6. Another columns**","2545cc61":"Creating X and y","f932488c":"**1.2 Fare**","e6203e64":"And medians are:","8224e648":"**1. Fill NaN values**","430eb03f":"Embarked have 3 unique values: \"S\", \"C\", \"Q\". These letters designate the ports in which passengers boarded. Let's take a look at the names of people who have missed embarked values.","67248636":"**3. Name**","0c0633ad":"Now, let's apply the function to datasets and see what we have.","d47449bd":"I googled some inforamtion about they, and found that they both boarded in the port of Southampton, that is, both missing values can be filled in with the 'S'.\nLinks: [Amelina Icard](https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/amelia-icard.html), [Martha Evelyn Stone](https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/martha-evelyn-stone.html)","a5cb338a":"So what we need to do:","2a14ab00":"Splitting to train and test","d3b258b9":"Okay, let's take a look at the charts.","224cd5d9":"**5. Fare**","d3627415":"We also have columns that store the ticket and cabin numbers. We could actually use the cabin number for the classification, but there are too many missing values. Therefore, let's just drop them."}}