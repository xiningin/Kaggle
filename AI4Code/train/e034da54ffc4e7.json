{"cell_type":{"a1a44b9b":"code","bf1f2a9e":"code","4381cd65":"code","b8cdf1e2":"code","ddd5a7dd":"code","599d7e7e":"code","baf847f7":"code","731ec03b":"code","a1461564":"code","a3d56585":"code","5e2527ab":"code","db0061b5":"code","e75856c9":"code","64b12a9a":"code","ab6b89f2":"code","3e4816b3":"code","ab7b4f76":"code","b5642b9f":"code","5597fb04":"code","2be179a5":"code","072a8d2f":"code","745d36d2":"code","fd364253":"code","56c9ffd5":"code","6484349a":"code","f6f8592b":"code","07df2811":"code","6c198aa1":"code","dcc14d05":"code","9e77cae5":"code","67368a28":"code","7cfff28f":"markdown","9a60048b":"markdown","695e995e":"markdown","5a9cb79d":"markdown","b246ddff":"markdown","1e2b9577":"markdown","7dff1b91":"markdown","7c0379e9":"markdown","0480c7c1":"markdown"},"source":{"a1a44b9b":"import pandas as pd \nimport numpy as np\n\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nfrom wordcloud import WordCloud,STOPWORDS\n\n#libraries for visualization \nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport seaborn as sns\n%matplotlib inline\n\n#Cufflinks is another library that connects the Pandas data frame with \n#Plotly enabling users to create visualizations directly from Pandas. \nimport cufflinks as cf\nfrom pandas import DataFrame\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode,iplot,plot\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom PIL import Image\n","bf1f2a9e":"cf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)","4381cd65":"food_reviews_df=pd.read_csv('..\/input\/amazon-fine-food-reviews\/Reviews.csv')\nfood_reviews_df.shape","b8cdf1e2":"food_reviews_df.head().T","ddd5a7dd":"corpus_df=food_reviews_df[['Score','Summary','Text']].dropna()\ncorpus_df.shape","599d7e7e":"corpus_df.head()","baf847f7":"corpus_df.iloc[3].Text","731ec03b":"corpus_df.iloc[1].Text","a1461564":"corpus_df.tail()","a3d56585":"\nplt.figure(figsize=(16, 6))\nax=sns.countplot(y=\"Score\", data=corpus_df, palette=\"Blues\")\n\nplt.title(\"User Ratings for food reviews\", fontsize=16)\nplt.ylabel(\"Scores\", fontsize=14)\nplt.xlabel(\"Frequency\");","5e2527ab":"corpus_df=corpus_df[corpus_df['Score']<4]\ncorpus_df.shape","db0061b5":"\nplt.figure(figsize=(16, 6))\nax=sns.countplot(y=\"Score\", data=corpus_df, palette=\"viridis\")\n\nplt.title(\"User Ratings for food reviews\", fontsize=16)\nplt.ylabel(\"Scores\", fontsize=14)\nplt.xlabel(\"Frequency\");","e75856c9":"#creating the pipeline for text preprocessing \nwpt = nltk.WordPunctTokenizer()\nstop_words = nltk.corpus.stopwords.words('english')\n\ndef normalize_document(doc):\n    # lower case and remove special characters\\whitespaces\n    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n    doc = doc.lower()\n    doc = doc.strip()\n    # tokenize document\n    tokens = wpt.tokenize(doc)\n    # filter stopwords out of document\n    filtered_tokens = [token for token in tokens if token not in stop_words]\n    # re-create document from filtered tokens\n    doc = ' '.join(filtered_tokens)\n    return doc\n\nnormalize_corpus = np.vectorize(normalize_document) # doc appects string byte object ","64b12a9a":"\ncorpus_df['normalized_Text']=normalize_corpus(corpus_df.Text)\ncorpus_df['normalized_Text'].head()\n","ab6b89f2":"wc = WordCloud(stopwords=STOPWORDS,max_words=2000,\n               width=1600,height=800).generate(' '.join(corpus_df['normalized_Text']))\n              \n# Open a plot of the generated image.\n\nplt.figure( figsize=(20,10), facecolor='k')\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.savefig('wordcloud.png', facecolor='k', bbox_inches='tight')   \n","3e4816b3":"corpus_df['normalized_Summary']=normalize_corpus(corpus_df.Summary)\ncorpus_df['normalized_Summary'].head()\n","ab7b4f76":"corpus_df.head().T","b5642b9f":"#generate word cloud for suppmary for bigrams (two words) instead of single word \nwc = WordCloud(background_color=\"white\",stopwords=STOPWORDS,max_words=2000,\n               width=1600,height=800).generate(' '.join(corpus_df['normalized_Summary']))\n              \n# Open a plot of the generated image.\n\nplt.figure( figsize=(20,10), facecolor='k')\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.savefig('wordcloud.png', facecolor='k', bbox_inches='tight')   \n\n\n","5597fb04":"Score_one=[]\nScore_two=[]\nScore_three=[]\n\nfor row in corpus_df.itertuples(): #execution faster than iterrows \n    val = getattr(row,'normalized_Text')\n    if getattr(row,'Score') ==1:\n        Score_one.append(val)\n    elif getattr(row,'Score') ==2:\n        Score_two.append(val)\n    elif getattr(row,'Score') ==3:\n        Score_three.append(val)\n\n  ","2be179a5":"#one list value \nScore_one[0]  ","072a8d2f":"Score_two[0]","745d36d2":"pattern = r'\\b(?:{})\\b'.format('|'.join(stop))\ndef text_cleaning(val_list):\n    df1 = DataFrame (val_list,columns =['normalized_text']).dropna()\n    df1[\"normalized_text\"] = df1[\"normalized_text\"].str.replace(pattern, '')\n    df1[\"normalized_text\"] = df1[\"normalized_text\"].str.replace(r'\\s+', ' ')\n    return df1","fd364253":"#create 3 different data frames for 1,2 and 3 rating separately \none_star=text_cleaning(Score_one)\ntwo_star=text_cleaning(Score_two)\nthree_star=text_cleaning(Score_three)\n\n","56c9ffd5":"print(\"\",one_star.shape)\nprint(\"\",two_star.shape)\nprint(\"\",three_star.shape)","6484349a":"#creating a biagram for one rating and see top 20 comments \ndef get_top_n_bigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\n","f6f8592b":"#plot it for score one review \ncommon_words = get_top_n_bigram(one_star['normalized_text'], 30)\ndf1 = pd.DataFrame(common_words, columns = ['words' ,'count'])\ndf1.groupby('words').sum()['count'].sort_values(ascending=False).iplot(\n    kind='bar', yTitle='Count', linecolor='black', title='Top 30 bigrams from one star reviews')","07df2811":"#plot it for score one review \ncommon_words = get_top_n_bigram(two_star['normalized_text'], 30)\ndf2 = pd.DataFrame(common_words, columns = ['words' ,'count'])\ndf2.groupby('words').sum()['count'].sort_values(ascending=False).iplot(\n    kind='bar', yTitle='Count', linecolor='black', title='Top 30 bigrams from two star reviews')","6c198aa1":"#plot it for score one review \ncommon_words = get_top_n_bigram(three_star['normalized_text'], 30)\ndf3 = pd.DataFrame(common_words, columns = ['words' ,'count'])\ndf3.groupby('words').sum()['count'].sort_values(ascending=False).iplot(\n    kind='bar', yTitle='Count', linecolor='black', title='Top 30 bigrams from three star reviews')","dcc14d05":"def get_top_n_trigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(3, 3)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","9e77cae5":"\ncommon_words = get_top_n_trigram(one_star['normalized_text'], 30)\ndf4 = pd.DataFrame(common_words, columns = ['words' , 'count'])\ndf4.groupby('words').sum()['count'].sort_values(ascending=False).iplot(\n    kind='bar', yTitle='Count', linecolor='black', title='Top 30 trigrams from one star reviews')","67368a28":"#word cloud for onr star bigrams \n#df1 = pd.DataFrame(common_words, columns = ['words' ,'count'])\n\n#generate word cloud for suppmary for bigrams (two words) instead of single word \nwc = WordCloud(background_color=\"white\",stopwords=STOPWORDS,max_words=2000,\n               width=1600,height=800).generate('_'.join(df1['words']))\n              \n# Open a plot of the generated image.\n\nplt.figure( figsize=(20,10), facecolor='k')\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.savefig('wordcloud.png', facecolor='k', bbox_inches='tight') ","7cfff28f":"Now I thick its better to analysise by deviding into 3 rating categories differently to understand each of them better but will also see this time with N grams ","9a60048b":"HERE score represents the 1 to 5 rating. summary gives a brief on positive or negative sentiment and Text have the reviews. we will subset these 3 columns into our dataset. ","695e995e":"#Amazon fine food reviews with N gram and skip gram generators \n\nThis dataset consists of reviews of fine foods from amazon.  \nwe will explore the N grams here to understand what users are actually saying about the products. \n\n Here we have classified our positive and negative reviews into two parts. based on 1 to 5 rating \n we have considered 4 and 5 as positive reviews and 1 to 3 as negative reviews.\n \n thses negative reviews are more important as we need to improvement in this category of product or deleivery services. \n \n In this current version i have taken 1 to 3 rating reviews for analysis, even if you see positive words in word cloud it definitely refers to a negative review. \n \n for exmple: \"I dont like this food taste\". after removing stop words we may see like and taste in word cloud but it says of they did not like food tase. \n \n I am working on to present more contextual meaning in word cloud in future version with skp grams. currently I have created on bigrams.\n \n \n **IF YOU FIND THESE WORD CLOUDS USEFUL PLZ GIVE AN UPVOTE.ITS MY VERY FIRST NOTEBOOK. THANKS**","5a9cb79d":"we have more 5 reviews 6 times more than 1 rating. but we are going to focus on 1 to 3 ratings. ","b246ddff":"here we can see the text is clean but what we have lost here ? \nrow 1 says summary \"Not as Advertised\" becomes \"advertised\" and \"My Cats Are Not Fans of the New Food\" is transformed to \"cats fans new food\". Both of them sounds neutral after removal of not. This is challenging for us as we get a different sentiment here. instaed of bad when some one writes not good. \n\nwe will deal with it later. for now we have like \"poor taste\" and nasty flavor. lets check them out from our verbs what people have expressed the most. \n\nOne thing that we need to note here that we have not selected reviews with 5 scores only 3,2 and 1. so yes they are negative already. \n","1e2b9577":"If we look at this reviews and they way reviews given. in first one one product she liked but the second one was medicine taste. \n\nwe need to find the best keywords to understand them at a glance ","7dff1b91":"creating 3 different list for 3 ratings ","7c0379e9":"almost same things lets find tri gram for 1 and 2 ","0480c7c1":"this is word cloud of bigram. we still need a lot of improvement as this does not give an contexual meaning. work in progress."}}