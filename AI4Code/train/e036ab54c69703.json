{"cell_type":{"4eaa57d0":"code","9961e760":"code","8af1cfce":"code","06349d94":"code","1d3254ae":"code","6287adfa":"code","d962c1a1":"code","b75796c0":"code","74418cac":"code","923a6727":"code","f4dbe2af":"code","101c63b9":"code","23ccecd3":"markdown","7c00475c":"markdown","1fbff730":"markdown","d9a2db7b":"markdown","28b30a6c":"markdown","a597e71f":"markdown","880a4131":"markdown","2dfddf51":"markdown","0200e0f7":"markdown","a71cda35":"markdown","fab7289a":"markdown"},"source":{"4eaa57d0":"import os\nimport skimage\nimport numpy as np\nimport pandas as pd\nimport skimage.segmentation\nimport matplotlib.pyplot as plt","9961e760":"def rles_to_mask(encs, shape):\n    \"\"\"\n    Decodes a rle.\n\n    Args:\n        encs (list of str): Rles for each class.\n        shape (tuple [2]): Mask size.\n\n    Returns:\n        np array [shape]: Mask.\n    \"\"\"\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint)\n    for m, enc in enumerate(encs):\n        if isinstance(enc, np.float) and np.isnan(enc):\n            continue\n        enc_split = enc.split()\n        for i in range(len(enc_split) \/\/ 2):\n            start = int(enc_split[2 * i]) - 1\n            length = int(enc_split[2 * i + 1])\n            img[start: start + length] = 1 + m\n    return img.reshape(shape)","8af1cfce":"df = pd.read_csv('..\/input\/sartorius-cell-instance-segmentation\/train.csv')\ndf = df.groupby('id').agg(list).reset_index()\n\nfor col in df.columns[2:]:\n    df[col] = df[col].apply(\n        lambda x: np.unique(x)[0] if len(np.unique(x)) == 1 else np.unique(x)\n    )","06349d94":"i = 0  # feel free to change that\n\nshape = df[['height', 'width']].values[i]\n\nrles = df['annotation'][i]\n\nmasks = rles_to_mask(rles, shape).astype(np.uint16)","1d3254ae":"plt.figure(figsize=(15, 10))\nplt.imshow(masks)\nplt.axis(False)\nplt.show()","6287adfa":"# offset pixels\noffset = 1\ny_pred = masks[offset:, offset:]\ny_pred = np.pad(y_pred, ((0, offset), (0, offset)), mode=\"constant\")\n\n# Remove a bunch of cells\ny_pred[y_pred > 300] = 0 \n\n# Relabel objects\ny_pred, _, _ = skimage.segmentation.relabel_sequential(y_pred) ","d962c1a1":"plt.figure(figsize=(15, 10))\nplt.imshow(y_pred)\nplt.axis(False)\nplt.show()","b75796c0":"def compute_iou(labels, y_pred):\n    \"\"\"\n    Computes the IoU for instance labels and predictions.\n\n    Args:\n        labels (np array): Labels.\n        y_pred (np array): predictions\n\n    Returns:\n        np array: IoU matrix, of size true_objects x pred_objects.\n    \"\"\"\n\n    true_objects = len(np.unique(labels))\n    pred_objects = len(np.unique(y_pred))\n\n    # Compute intersection between all objects\n    intersection = np.histogram2d(\n        labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects)\n    )[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins=true_objects)[0]\n    area_pred = np.histogram(y_pred, bins=pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n    iou = intersection \/ union\n    \n    return iou[1:, 1:]  # exclude background","74418cac":"def precision_at(threshold, iou):\n    \"\"\"\n    Computes the precision at a given threshold.\n\n    Args:\n        threshold (float): Threshold.\n        iou (np array [n_truths x n_preds]): IoU matrix.\n\n    Returns:\n        int: Number of true positives,\n        int: Number of false positives,\n        int: Number of false negatives.\n    \"\"\"\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) >= 1  # Correct objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Missed objects\n    false_positives = np.sum(matches, axis=0) == 0  # Extra objects\n    tp, fp, fn = (\n        np.sum(true_positives),\n        np.sum(false_positives),\n        np.sum(false_negatives),\n    )\n    return tp, fp, fn","923a6727":"def iou_map(truths, preds, verbose=0):\n    \"\"\"\n    Computes the metric for the competition.\n    Masks contain the segmented pixels where each object has one value associated,\n    and 0 is the background.\n\n    Args:\n        truths (list of masks): Ground truths.\n        preds (list of masks): Predictions.\n        verbose (int, optional): Whether to print infos. Defaults to 0.\n\n    Returns:\n        float: mAP.\n    \"\"\"\n    ious = [compute_iou(truth, pred) for truth, pred in zip(truths, preds)]\n    \n    print(ious[0].shape)\n\n    if verbose:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tps, fps, fns = 0, 0, 0\n        for iou in ious:\n            tp, fp, fn = precision_at(t, iou)\n            tps += tp\n            fps += fp\n            fns += fn\n\n        p = tps \/ (tps + fps + fns)\n        prec.append(p)\n\n        if verbose:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tps, fps, fns, p))\n\n    if verbose:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n\n    return np.mean(prec)","f4dbe2af":"iou_map([masks] * 5, [masks] * 5, verbose=1)  # This should score 1","101c63b9":"iou_map([masks] , [y_pred], verbose=1)","23ccecd3":"## Precision","7c00475c":"Hope this helps !\n\nNote that the averaging is made at cell level here.\nTo compute the evaluation metric as intended, use the previous cell and loop over all the ground truths and predictions.\n\nPlease let me know if I made any mistakes.","1fbff730":"## Compute","d9a2db7b":"## IoU","28b30a6c":"### IoU","a597e71f":"# Implementation of the mean Average Precision (mAP) at different intersection over union (IoU)\n\nAs described [here](https:\/\/www.kaggle.com\/c\/sartorius-cell-instance-segmentation\/overview\/evaluation)\n\nCode adapted from [here](https:\/\/www.kaggle.com\/wcukierski\/example-metric-implementation) (please upvote this kernel as well), as the metric should be the same as the 2018 DSB one.\n\n- FIX v4 : Removed background from the analysis\n- EDIT v5 : Metric should be computed at image level, I updated comments regarding this.\n- EDIT v6, v7 : Variables `false_negatives` and `false_positives` were inverted (?).","880a4131":"## Overall Metric","2dfddf51":"## Simulated prediction","0200e0f7":"# Load Example","a71cda35":"## Ground truth","fab7289a":"# Metric"}}