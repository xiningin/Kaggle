{"cell_type":{"289ed597":"code","0222ec0e":"code","5326a245":"code","c4e4b8f7":"code","f3d33c55":"markdown","335c6614":"markdown"},"source":{"289ed597":"import numpy as np\nimport pandas as pd","0222ec0e":"print('float\\t\\t bytes')\nprint(np.float64(-0.622475), '\\t', np.float64(-0.622475).nbytes)\nprint(np.float32(-0.622475), '\\t', np.float32(-0.622475).nbytes)\nprint(np.float16(-0.622475), '\\t', np.float16(-0.622475).nbytes)","5326a245":"df = pd.read_csv('..\/input\/jane-street-market-prediction\/train.csv')\ndf.info()","c4e4b8f7":"float64_cols = df.select_dtypes(include='float64').columns\nmapper = {col_name: np.float32 for col_name in float64_cols}\ndf = df.astype(mapper)\ndf.info()","f3d33c55":"So when `pandas` loads `.csv` files and encounters floats, it automatically makes them of data type `float64`.\n\nSince the data we are given only has a precision of six digits, `float64` is overkill. Using `float32` would still maintain *all* precision but saves half the memory size!","335c6614":"That's half the memory usage *without any loss of precision*!\n\nAs a bonus, here it is as a one-liner after loading `train.csv` into `df` using `.read_csv`:\n```\ndf = df.astype({c: np.float32 for c in df.select_dtypes(include='float64').columns})\n```"}}