{"cell_type":{"c14fc696":"code","1f442fd8":"code","c9ec3676":"code","cb81ec9e":"code","280f6501":"code","3aeab2e5":"code","04324a3e":"code","d8f80c8b":"code","4fae4ca7":"code","8f41ac61":"code","f6ae5d08":"markdown","c733adc6":"markdown"},"source":{"c14fc696":"# General imports\nimport numpy as np\nimport pandas as pd\nimport os","1f442fd8":"# Specify lang\nLANG = \"ru\"\nDIR = f\"..\/input\/{LANG}-changed-subs\/\"\nWEIGHT = 1 # we kept WEIGHT between 1-2","c9ec3676":"submission = pd.read_csv(\"..\/input\/jigsaw-multilingual-toxic-comment-classification\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/jigsaw-multilingual-toxic-comment-classification\/test.csv\")\nsub_best = pd.read_csv(os.path.join(DIR, \"sub-LB-9549.csv\"))","cb81ec9e":"files_sub = os.listdir(DIR)\nfiles_sub = sorted(files_sub)\nprint(len(files_sub))\nfiles_sub","280f6501":"for file in files_sub:\n    test[file.replace(\".csv\", \"\")] = pd.read_csv(os.path.join(DIR, file))[\"toxic\"]","3aeab2e5":"test = test.loc[test[\"lang\"]==LANG].reset_index(drop=True)\ntest.head(1)","04324a3e":"# Derive the given sub increases or decreases in score\ntest[\"diff_good1\"] = test[f\"{LANG}-9397\"] - test[f\"{LANG}-9373\"]\ntest[\"diff_good2\"] = test[f\"{LANG}-9476\"] - test[f\"{LANG}-9475\"]\ntest[\"diff_good3\"] = test[f\"{LANG}-9529\"] - test[f\"{LANG}-9510\"]\ntest[\"diff_good4\"] = test[f\"{LANG}-9544\"] - test[f\"{LANG}-9543\"]\n\ntest[\"diff_bad1\"] = test[f\"{LANG}-9545\"] - test[f\"{LANG}-9543-from-9545\"]","d8f80c8b":"test[\"sub_best\"] = test[\"sub-LB-9549\"]\ncol_comment = [\"id\", \"content\", \"sub_best\"]\ncol_diff = [column for column in test.columns if \"diff\" in column]\ntest_diff = test[col_comment + col_diff].reset_index(drop=True)\n\ntest_diff[\"diff_avg\"] = test_diff[col_diff].mean(axis=1) # the mean trend","4fae4ca7":"# Apply the post-processing technique in one line (as explained in the pseudo-code of my post.\ntest_diff[\"sub_new\"] = test_diff.apply(lambda x: (1+WEIGHT*x[\"diff_avg\"])*x[\"sub_best\"] if x[\"diff_avg\"]<0 else (1-WEIGHT*x[\"diff_avg\"])*x[\"sub_best\"] + WEIGHT*x[\"diff_avg\"] , axis=1)","8f41ac61":"submission[\"toxic\"] = sub_best[\"toxic\"]\nsubmission.loc[test[\"id\"], \"toxic\"] = test_diff[\"sub_new\"].values\nsubmission.to_csv(\"submission.csv\", index=False)","f6ae5d08":"## Introduction\n\nIn this notebook, one of the last techniques that we applied is shown. A simple post-processing technique, as described in the associated [post](https:\/\/www.kaggle.com\/c\/jigsaw-multilingual-toxic-comment-classification\/discussion\/160986). The score gain is relatively low compared to other techniques we applied. However, it gave a steady increase (~0.0001) for each of languages es\/tr\/fr\/ru both in public LB as private LB. This also secured our first place.\n\n\nHere, I present an example of how to use our earlier Russian subs to achieve the gain in score: going from public LB 9549 to 9550, and private LB 9532 to 9533. This be done in similar fashion with the other languages.","c733adc6":"# Imports"}}