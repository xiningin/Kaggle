{"cell_type":{"905349ab":"code","9fc6a4d4":"code","816856f7":"code","dc380a78":"code","686fb640":"code","b5dc188c":"code","6379085b":"code","ef9bdbbc":"code","379c243e":"code","1adcb15b":"code","9a9f779b":"code","ca4597b5":"code","14363340":"code","fc642143":"code","82a18508":"code","90a8878f":"code","8dce4fbf":"code","512c0cec":"code","4d34abd4":"code","fa4d588b":"code","078b7c43":"code","498dd882":"code","cdd5623d":"code","78801791":"code","bad27015":"code","425f72b9":"code","bfd20f69":"code","777fdeee":"code","5d540420":"code","f5a58943":"code","7fa7dee1":"code","401dfe2e":"code","eefbd878":"code","9f146684":"code","56f13015":"code","b9ace06b":"code","6035abe3":"code","886c758c":"code","cf6a9af9":"code","6d332eb5":"code","6183e8cf":"code","73bc4132":"code","b314bf4c":"code","81b29e8b":"code","90c929b0":"code","c6cb586f":"code","aa1e9813":"code","02530ac3":"code","7e3dba3d":"code","63f0d639":"code","d551adb3":"markdown","da988e4d":"markdown","4e4c615d":"markdown","1b59f172":"markdown","53fb387e":"markdown","d1ccce1c":"markdown","e10b446c":"markdown","c20eba46":"markdown","bf1680ec":"markdown","121c3412":"markdown","dba6e9e7":"markdown","18cbb34e":"markdown","71858c48":"markdown","3d33cf2d":"markdown","9fd52726":"markdown","8d085303":"markdown","8403c979":"markdown","f5329bc0":"markdown","d3e02c92":"markdown","8db2083d":"markdown","c8de0dec":"markdown","d753933c":"markdown","4060240c":"markdown","6278b29f":"markdown","fcd9f190":"markdown","935be9f4":"markdown","73bba1d2":"markdown","da0bfb35":"markdown","929dbb21":"markdown","0545b8f0":"markdown","01ed3dd8":"markdown"},"source":{"905349ab":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","9fc6a4d4":"df = pd.read_csv('..\/input\/heart-disease-dataset\/heart.csv')","816856f7":"df.head(10)","dc380a78":"df.info()","686fb640":"df.isnull().sum()","b5dc188c":"df.head(10)","6379085b":"X = df[list(df.columns)[0:-1]]\ny = df[list(df.columns)[-1]]","ef9bdbbc":"X.head(5)","379c243e":"y","1adcb15b":"from sklearn.preprocessing import StandardScaler","9a9f779b":"X = StandardScaler().fit_transform(X)\nX = pd.DataFrame(X)","ca4597b5":"X","14363340":"from sklearn.decomposition import PCA","fc642143":"pca = PCA(0.9)\npca.fit_transform(X)\npca_variance = pca.explained_variance_ratio_\n\nplt.figure(figsize=(8, 6))\nplt.plot( np.cumsum(pca_variance), alpha=0.5, label='individual variance')\nplt.legend()\nplt.ylabel('Variance ratio')\nplt.xlabel('Principal components')\nplt.show()","82a18508":"pca = PCA(n_components = 10)\nX = pca.fit_transform(X)\nX = pd.DataFrame(X)","90a8878f":"X","8dce4fbf":"from sklearn.model_selection import train_test_split","512c0cec":"x_train, x_test, y_train, y_test=train_test_split(X,y,test_size=0.20,random_state=1)","4d34abd4":"x_train.shape","fa4d588b":"x_test.shape","078b7c43":"import keras\nfrom tensorflow.keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense","498dd882":"model = Sequential()\nmodel.add(Dense(12, input_dim=10, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","cdd5623d":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","78801791":"history = model.fit(x_train, y_train, epochs=150, batch_size=10, validation_split=0.2, shuffle=True)","bad27015":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","425f72b9":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","bfd20f69":"_, accuracy = model.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))","777fdeee":"from sklearn import metrics","5d540420":"y_pred = model.predict(x_test)\ny_pred[y_pred>=0.5] = 1\ny_pred[y_pred<0.5] = 0\nprint(metrics.accuracy_score(y_test, y_pred))","f5a58943":"from keras.layers import Dropout","7fa7dee1":"model = keras.Sequential()\nmodel.add(Dense(16, activation='relu', input_dim=10))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1, activation='sigmoid'))","401dfe2e":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","eefbd878":"history = model.fit(x_train, y_train, epochs=150, batch_size=10, validation_split=0.2, shuffle=True)","9f146684":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","56f13015":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","b9ace06b":"_, accuracy = model.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))","6035abe3":"y_pred = model.predict(x_test)\ny_pred[y_pred>=0.5] = 1\ny_pred[y_pred<0.5] = 0\nprint(metrics.accuracy_score(y_test, y_pred))","886c758c":"from keras.layers import Conv1D, Flatten, MaxPooling1D, GlobalAveragePooling1D, Input","cf6a9af9":"x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\ny_train = np.array(y_train).reshape(y_train.shape[0], 1)\nx_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\ny_test = np.array(y_test).reshape(y_test.shape[0], 1)","6d332eb5":"n_timesteps, n_features = x_train.shape[1], x_train.shape[2]","6183e8cf":"model = Sequential()\nmodel.add(Input(shape=(x_train.shape[1], 1)))\nmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\nmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","73bc4132":"optimizer = optimizers.RMSprop(0.001)\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","b314bf4c":"history = model.fit(x_train, y_train, epochs=150, batch_size=15, verbose=1, validation_split=0.2)","81b29e8b":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('mae')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","90c929b0":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c6cb586f":"model = Sequential()\nmodel.add(Input(shape=(x_train.shape[1], 1)))\nmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\nmodel.add(keras.layers.Dropout(0.2))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\nmodel.add(keras.layers.Dropout(0.2))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","aa1e9813":"optimizer = optimizers.RMSprop(0.001)\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","02530ac3":"history = model.fit(x_train, y_train, epochs=200, validation_split=0.2, verbose=1)","7e3dba3d":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","63f0d639":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","d551adb3":"### Load Dataset ","da988e4d":"### Fit Model ","4e4c615d":"### Convert Number of Features to 10  ","1b59f172":"### Find & Fix Missing Values ","53fb387e":"### Calculate Model Score ","d1ccce1c":"### Fix Overfitting  ","e10b446c":"### Config Model ","c20eba46":"### Plot Loss History ","bf1680ec":"### Dataset Infography ","121c3412":"### Preprocessing Dataset ","dba6e9e7":"### Fix Overfitting ","18cbb34e":"### Reshape Dataset ","71858c48":"### Plot Accuracy History ","3d33cf2d":"### Split Data to Train & Test ","9fd52726":"### Compile Model ","8d085303":"### Fit Model ","8403c979":"### Split Features & Class ","f5329bc0":"### Create Model ","d3e02c92":"### Show Dataset ","8db2083d":"### Fit Model ","c8de0dec":"### Plot Accuracy History","d753933c":"### Calculate Model Score ","4060240c":"### Create Simple Dense Model ","6278b29f":"### Dimensionality Reduction - Use PCA Algorithm ","fcd9f190":"### Import Raw Libraries","935be9f4":"### Prepare Classes  ","73bba1d2":"### Create Dense Model with Dropout Layer ","da0bfb35":"### Plot Loss History ","929dbb21":"### Create 1D Convolutional Model ","0545b8f0":"### Compile Model ","01ed3dd8":"## Keras Classification Project "}}