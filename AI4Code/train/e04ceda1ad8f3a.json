{"cell_type":{"470fdf81":"code","10d0926a":"code","4a807644":"code","64d71bb5":"code","aef67df0":"code","eeceecac":"code","914baba8":"code","0fc268fb":"code","d1736a41":"code","de5eaaab":"code","a10193df":"code","8e7f17f5":"code","8b3cf285":"code","c57c3928":"code","fc4855cd":"code","c6be268f":"code","59929d71":"code","7b75b617":"code","95f8dbdd":"code","aa2fb884":"code","e6d608dd":"code","faeafb05":"code","2a7fea8d":"code","58313a7a":"code","aeacdbf3":"markdown","d141ea44":"markdown","bb123a92":"markdown","9a744e30":"markdown","3b7309af":"markdown"},"source":{"470fdf81":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport random\nimport cv2","10d0926a":"## Declare Directory\ntrain_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\"\nval_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\"\ntest_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\"\n\nclasses = [\"With Mask\", \"Without Mask\"]","4a807644":"n = 5\n## Check Image\nplt.figure(figsize=(15, n))\nfor i in range(n):\n    # read image\n    sample = random.choice(os.listdir(train_dir + \"\/WithMask\"))\n    # print(\"filename:\", sample)\n    img_dir = train_dir + \"\/WithMask\/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # plot image\n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"With Mask\")\nplt.show()   \n\nplt.figure(figsize=(15, n))\nfor i in range(n):\n    # read image\n    sample = random.choice(os.listdir(train_dir + \"\/WithoutMask\"))\n    # print(\"filename:\", sample)\n    img_dir = train_dir + \"\/WithoutMask\/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # plot image\n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"Without Mask\")\nplt.show()   ","64d71bb5":"## Data Augmentation \nfrom keras.preprocessing.image import ImageDataGenerator","aef67df0":"# Dataset Loader\ntrain_datagen = ImageDataGenerator(\n                                rescale=1.\/255,\n                                rotation_range=0.2,\n                                #width_shift_range=0.1,\n                                #height_shift_range=0.1,\n                                shear_range=0.2,\n                                #zoom_range=0.09,\n                                horizontal_flip=True,\n                                vertical_flip=False,\n                                #validation_split=0.1\n                                )\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)","eeceecac":"# Image Generator Config\ntarget_size = (150, 150)\nbatch_size = 16\n\n# Load Dataset\ntrain_dataset = train_datagen.flow_from_directory(train_dir,\n                                                  target_size=target_size,\n                                                  batch_size=batch_size,\n                                                  class_mode=\"categorical\",\n                                                  shuffle=True)\n\nval_dataset = val_datagen.flow_from_directory(val_dir,\n                                              target_size=target_size,\n                                              batch_size=batch_size,\n                                              class_mode=\"categorical\",\n                                              shuffle=False)","914baba8":"# Import\nimport keras\nfrom keras import layers\nfrom keras.applications import MobileNetV2\n\n# Initiate Baseline Model\nbase_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))","0fc268fb":"# Freezing Layer\nfor layer in base_model.layers:\n    layer.trainable = False","d1736a41":"model = keras.Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2, activation=\"softmax\"))","de5eaaab":"model.summary()","a10193df":"## Setting backprop of model (how this model learning)\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics =\"accuracy\")","8e7f17f5":"# Training\nEPOCHS = 10\nhistory = model.fit_generator(train_dataset,\n                               steps_per_epoch=len(train_dataset)\/\/train_dataset.batch_size,\n                               validation_data=val_dataset, \n                               validation_steps=len(val_dataset)\/\/val_dataset.batch_size,\n                               epochs=EPOCHS, \n                               )","8b3cf285":"## Review Our Model\nimport matplotlib.gridspec as gridspec\n\nfig = plt.figure(figsize=(14,5))\ngrid = gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\nfig.add_subplot(grid[0])\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nfig.add_subplot(grid[1])\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n\n#plt.savefig(\"Training_result.jpg\",dpi=300)","c57c3928":"# Load Test Dataset\ntest_dataset = val_datagen.flow_from_directory(test_dir,\n                                            target_size=target_size,\n                                            batch_size=1,\n                                            class_mode=None,\n                                            shuffle=False)","fc4855cd":"probabilities = model.predict_generator(test_dataset)","c6be268f":"y_pred = probabilities.argmax(axis=-1)\ny_test = test_dataset.classes","59929d71":"from sklearn.metrics import confusion_matrix, accuracy_score\nimport seaborn as sns","7b75b617":"print(\"Accuracy Score of Model:\", accuracy_score(y_pred,y_test))","95f8dbdd":"labels = [\"No Mask\",\"Mask\"]\n\nfig, ax = plt.subplots(figsize=(8,7))\nsns.heatmap(confusion_matrix(y_test,y_pred),xticklabels=labels, ax=ax,\n                                       yticklabels=labels, annot=True,fmt=\"1.0f\",cbar=False,annot_kws={\"size\": 20})\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nplt.title(\"Confusion matrix\",fontsize=30)","aa2fb884":"import glob\nimport random","e6d608dd":"def preprocessing_img(img):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (150, 150))\n    img = np.array(img)\n    img = np.expand_dims(img, axis=0)\n    img = img\/255\n    return img\n","faeafb05":"random_test_img = random.choice(glob.glob(test_dir+\"\/*\/*\"))\nprint(random_test_img)\nimg_test = cv2.imread(random_test_img)\nimg_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\nplt.imshow(img_test)\nplt.show()","2a7fea8d":"img_test = preprocessing_img(img_test)\nresult = model.predict(img_test)\nscore = np.max(result)\npredicted_class = classes[np.argmax(result)]\nprint(predicted_class)\nprint(\"Confident: \", score)","58313a7a":"model.save(\"face-masked-detection.h5\")","aeacdbf3":"# 1. Preparation","d141ea44":"# Test with Visualization","bb123a92":"# 3. Reviewing Model","9a744e30":"# 2. Deep Learning Model","3b7309af":"# Save Model"}}