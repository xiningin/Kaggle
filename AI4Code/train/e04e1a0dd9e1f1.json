{"cell_type":{"39ec5c24":"code","0e6b2115":"code","77eb5775":"code","060d60d4":"code","54c3490c":"code","ad8ff2b0":"code","0137e510":"code","e9e6f17b":"code","8540c0bf":"code","602f453b":"code","b5aeacb7":"code","dd077201":"code","c82304ad":"code","21955cf5":"code","495c8301":"code","9c9e1e86":"code","dd4fb29f":"code","20c83bf3":"code","32c7d066":"code","c694da7e":"markdown","875931d1":"markdown","651f6907":"markdown","a119bffb":"markdown","450f3f41":"markdown","1018aeda":"markdown","723ce28f":"markdown","0f1a0a9a":"markdown","ad958ec5":"markdown","7ba514be":"markdown","3eb94fea":"markdown","9a87fea3":"markdown"},"source":{"39ec5c24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e6b2115":"import seaborn as sns\nimport matplotlib.pyplot as plt","77eb5775":"sub = pd.read_csv(\"..\/input\/mercedes-benz-greener-manufacturing\/sample_submission.csv.zip\")\ntest = pd.read_csv(\"..\/input\/mercedes-benz-greener-manufacturing\/test.csv.zip\")\ntrain = pd.read_csv(\"..\/input\/mercedes-benz-greener-manufacturing\/train.csv.zip\")","060d60d4":"train[\"set\"] = \"train\"\ntrain.loc[(train['ID'] > 6000), 'set'] = 'va'\ntrain","54c3490c":"plt.style.use('default')\nsns.set()\nsns.set_style('whitegrid')\nsns.set_palette('Dark2')\n\nsns.distplot(train.y)","ad8ff2b0":"test[\"set\"] = \"test\"\ntest_id = test.ID","0137e510":"data_all = pd.DataFrame()\ndata_all = pd.concat([train,test])\ndata_all = data_all.sort_values(by='ID', ascending=True)\n#data_all = data_all.drop(columns = \"ID\")\ndata_all = data_all.reset_index(drop=True)\ndata_all","e9e6f17b":"enc = data_all[['X0','X1','X2','X3','X4','X5','X6','X8']]\nenc","8540c0bf":"from sklearn.preprocessing import LabelEncoder #Library for LabelEncoding\n\nfor c in enc:\n    le = LabelEncoder()\n    le.fit(enc[c])\n    enc[c] = le.transform(enc[c])\n    \nenc","602f453b":"data_all = data_all.drop(['X0','X1','X2','X3','X4','X5','X6','X8'], axis=1)\ndata_all = data_all.join(enc)\ndata_all","b5aeacb7":"n_tr = (data_all.set == 'train').sum()\nn_va = (data_all.set == 'va').sum()\nn_te = (data_all.set == 'test').sum()\nn = [n_tr, n_va, n_te]\nn","dd077201":"label = [\"train\",\"va\",\"test\"]\n\nplt.pie(n, labels=label)\nplt.gca().add_artist(plt.Circle((0, 0), 0.65, color='white'))\nplt.axis('equal')","c82304ad":"train_fit = pd.DataFrame()\ntrain_fit = data_all.loc[data_all.set == \"train\"]\n\ntrain_fit_x = train_fit.drop(columns = \"y\")\ntrain_fit_x = train_fit_x.drop(columns = \"set\")\ntrain_fit_y = train_fit.y\n\n\nva_fit = pd.DataFrame()\nva_fit = data_all.loc[data_all.set == \"va\"]\n\nva_fit_x = va_fit.drop(columns = \"y\")\nva_fit_x = va_fit_x.drop(columns = \"set\")\nva_fit_y = va_fit.y\n\n\ntest_fit = pd.DataFrame()\ntest_fit = data_all.loc[data_all.set == \"test\"]\n\ntest_fit_x = test_fit.drop(['y', 'set'], axis=1)","21955cf5":"%%time\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import r2_score\n\ncategorical_features = ['X0','X1','X2','X3','X4','X5','X6','X8']\n\n# Parameter setting\nparams = {\n    \"objective\" : \"regression\",\n    \"metric\" : \"rmse\",\n    \"num_leaves\" : 40,\n    \"learning_rate\" : 0.01,\n    \"bagging_fraction\" : 0.8,\n    \"feature_fraction\" : 0.8, # Use only \u3007% of features\n    \"bagging_frequency\" : 6,\n    \"bagging_seed\" : 42,\n    \"verbosity\" : -1, # Whether to display the progress during learning\n    \"seed\": 42\n}\n\ntrain_lgb = lgb.Dataset(train_fit_x,\n                        label=train_fit_y,\n                        categorical_feature=categorical_features)\n\nva_lgb = lgb.Dataset(va_fit_x,\n                     label=va_fit_y,\n                     categorical_feature=categorical_features)\n\nevals_result = {}\n\nmodel_lgb = lgb.train(params, train_set = train_lgb,\n                  num_boost_round = 10000,\n                  valid_sets=[train_lgb, va_lgb], \n                  early_stopping_rounds=200, \n                  verbose_eval=1000,\n                  evals_result=evals_result)","495c8301":"va_y = va_fit_y\n\npred = model_lgb.predict(va_fit_x, num_iteration=model_lgb.best_iteration)\n\ncolumns = [\"y\"]\npred_d = pd.DataFrame(data=pred, columns = columns)\n\n# RSMLE score\nscore_RMSLE = np.sqrt(mean_squared_log_error(va_y, pred_d[\"y\"]))\nprint(\"---------------RMSLE-score----------------\")\nprint(score_RMSLE)\n\n# RSMLE score\nscore_R2 = r2_score(va_y, pred_d[\"y\"])\nprint(\"---------------R2-score----------------\")\nscore_R2","9c9e1e86":"columns = [\"y\"]\nva_fit_d = pd.DataFrame(data=va_y, columns = columns)\nva_fit_d = va_fit_d.reset_index(drop=True)\n\nsns.scatterplot(x=va_fit_d['y'], y=pred_d['y'])\nsns.scatterplot(x=va_fit_d['y'], y=va_fit_d['y']) #perfect fitting line","dd4fb29f":"# predict\npred = model_lgb.predict(test_fit_x)\n\npred_df = pd.DataFrame()\npred_df[\"y\"] = pred\nsns.distplot(pred_df.y)","20c83bf3":"submission = pd.DataFrame()\nsubmission[\"id\"] = test_id\nsubmission[\"y\"] = pred\n\n# Export to csv file\nsubmission.to_csv(\"submission.csv\", index=False)","32c7d066":"columns_ck = [[\"y\"]]\nsubmission_ck = pd.DataFrame(data=pred, columns = columns_ck)\ntest_id_df = pd.DataFrame(data=test_id)\ntest_id_df = test_id_df.reset_index(drop=True)\ntest_id_df.columns = [\"id\"]\n\ntest_reindex = test_fit_x.reset_index(drop=True)","c694da7e":"# Mercedes-Benz Greener Manufacturing\nRecent competitions are complicated and difficult for beginners.<br>\nI'm a beginner, so I'm trying to do past competitions.<br>\nIt's a very simple code, but please comment if there are any improvements to this code! !!\n\n<br>\nPrivate Score 0.51903<br>\nPublic Score 0.53255<br>\n","875931d1":"# import data","651f6907":"# LabelEncoding","a119bffb":"# join and see the all data","450f3f41":"Thank you for reading<br>\nPlease let me know anythin to imporve this code!!!<br>\n## Also, I would be grateful if you could upvote to keep my motivation.\n","1018aeda":"# validation data visualization","723ce28f":"# make column named \"set\" to separate train, test and validation later","0f1a0a9a":"# Predict and Submission","ad958ec5":"# Split the data","7ba514be":"# check \"y\" destribution","3eb94fea":"# check the ratio of data","9a87fea3":"# LightGBM"}}