{"cell_type":{"f0f38bca":"code","3aaef8c5":"code","3a8a7227":"code","c306aa8e":"code","2013061f":"code","ecf9ce1f":"code","faa8b09b":"code","ffba2303":"code","a1b6b9cb":"code","9758cb12":"code","38121e12":"code","f7cdfa69":"code","bfc64a2b":"code","a27be484":"code","1622838e":"markdown","9912f972":"markdown","8749b158":"markdown","f73df99c":"markdown","1e13af61":"markdown","4fd3d039":"markdown","7169ef97":"markdown"},"source":{"f0f38bca":"import numpy as np\nimport pandas as pd\nimport os\nimport time\nfrom keras.applications.vgg19 import VGG19, preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.utils import np_utils\nfrom keras import backend as k\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt","3aaef8c5":"img_path = '..\/input\/sheep-breed-classification\/SheepFaceImages\/Marino\/00.jpgMA8.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nplt.imshow(img)\n\n# Convert the images to numpy array\nx = image.img_to_array(img)\nprint (x.shape)\nx = np.expand_dims(x, axis=0)\nprint (x.shape)\nx = preprocess_input(x)\nprint('Input image shape:', x.shape)","3a8a7227":"PATH = '..\/input\/sheep-breed-classification'\n# Define data path\ndata_path = PATH + '\/SheepFaceImages'\ndata_dir_list = os.listdir(data_path) # List containing names of sheep breeds","c306aa8e":"img_data_list = []\nimg_list_lengths = []\nnames = []\n\n# labels = np.ones((num_of_samples,),dtype='int64')\n\nfor dataset in data_dir_list:\n    # Load images in dataset\n    img_list = os.listdir(data_path+'\/'+ dataset)\n    img_list_lengths.append(len(img_list))\n    \n    # Save the name of the dataset\n    names.append(dataset) \n\n    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n    for img in img_list:\n        img_path = data_path + '\/'+ dataset + '\/'+ img \n        img = image.load_img(img_path, target_size=(224, 224))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        x = preprocess_input(x)\n        #print('Input image shape:', x.shape)\n        img_data_list.append(x)","2013061f":"img_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nprint (img_data.shape)\nimg_data=np.rollaxis(img_data,1,0)\nprint (img_data.shape)\nimg_data=img_data[0]\nprint (img_data.shape)","ecf9ce1f":"num_classes = 4\nnum_of_samples = img_data.shape[0]\nlabels = np.ones((num_of_samples,),dtype='int64')","faa8b09b":"# Assign correct label to the list of images\nstart = 0\nfor label in range(num_classes):\n    end = start + img_list_lengths[label]\n    labels[start : end] = label\n    start = end","ffba2303":"Y = np_utils.to_categorical(labels, num_classes)","a1b6b9cb":"#Shuffle the dataset\nx, y = shuffle(img_data, Y, random_state=777)\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=777)","9758cb12":"print('X_train shape: ', X_train.shape)\nprint('X_test shape: ', X_test.shape)\nprint('y_train shape: ', y_train.shape)\nprint('y_test shape: ', y_test.shape)","38121e12":"inputs = np.concatenate((X_train, X_test), axis=0)\ntargets = np.concatenate((y_train, y_test), axis=0)\n\ndel X_train, X_test, y_train, y_test, Y","f7cdfa69":"folds = 10\n\n# Lists for storing training metrics per fold \ntrain_acc_per_fold = []\nloss_per_fold = []\n\n# Lists for storing test metrics per fold\nval_acc_per_fold = []\nval_prec_per_fold = []\nval_rec_per_fold = []\nval_f1_per_fold = []\n\nkfold = KFold(n_splits=folds, shuffle=True)\n\ncallback = EarlyStopping(monitor='accuracy', patience=10)\n\nimage_input = Input(shape=(224, 224, 3))\n\nfold_no = 1\nfor train, test in kfold.split(inputs, targets):\n    \n    y_test = targets[test]\n    test_labels = np.argmax(y_test, axis=1)\n    \n    # Save the labels in a file\n    pd.DataFrame(y_test).to_csv('vgg19_y_test_fold' + str(fold_no) + '.csv', index=False)\n    \n    # Load the ResNet50 model with imagenet weights\n    model = VGG19(input_tensor = image_input, include_top = False, weights = 'imagenet')\n\n    # Add some more layers to accomodate to our needs of classifying the sheep\n    last_layer = model.get_layer('block5_pool').output\n    x = BatchNormalization()(last_layer)\n    x = Flatten(name='flatten')(x)\n    out = Dense(num_classes, activation='softmax', name='output_layer')(x)\n    custom_vgg19_model = Model(inputs=image_input, outputs=out)\n    #custom_vgg19_model.summary()\n    \n    for layer in model.layers:\n        layer.trainable = False\n    \n    # Compile the model\n    custom_vgg19_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    print(f'Training for fold {fold_no} ...')\n    \n    t=time.time()\n    hist = custom_vgg19_model.fit(inputs[train], targets[train], batch_size=32, epochs=200, verbose=0, callbacks=[callback])\n    print('Training time: %s' % (t - time.time()))\n    \n    # Evaluate the trained model\n    scores = custom_vgg19_model.evaluate(inputs[test], targets[test], batch_size=10, verbose=0)\n    \n    # Make predictions on the validation set and flatten\n    preds = custom_vgg19_model.predict(inputs[test], batch_size=10, verbose=0)\n    preds_flat = np.argmax(preds, axis=1)\n    \n    # Calculate validation metrics\n    val_acc = accuracy_score(test_labels, preds_flat)\n    val_prec = precision_score(test_labels, preds_flat, average='weighted')\n    val_rec = recall_score(test_labels, preds_flat, average='weighted')\n    val_f1 = f1_score(test_labels, preds_flat, average='weighted')\n    \n    val_acc_per_fold.append(val_acc*100)\n    val_prec_per_fold.append(val_prec*100)\n    val_rec_per_fold.append(val_rec*100)\n    val_f1_per_fold.append(val_f1*100)\n    \n    # Save the scores and the validation predictions foldwise (if needed)\n    pd.DataFrame(preds).to_csv('vgg19_preds_fold' + str(fold_no) + '.csv', index=False)\n    pd.DataFrame(scores).to_csv('vgg19_history_fold' + str(fold_no) + '.csv', index=False)\n    \n    print(f'Training score for fold {fold_no}: {custom_vgg19_model.metrics_names[0]} of {scores[0]}; {custom_vgg19_model.metrics_names[1]} of {scores[1]*100}%')\n    train_acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    \n    fold_no += 1","bfc64a2b":"# Average Scores for training and validation\nprint('------------------------------------------------------------------------')\nprint('Training score per fold')\nfor i in range(0, len(train_acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {train_acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\n\nprint('Validation score per fold')\nfor i in range(0, len(val_acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Accuracy: {val_acc_per_fold[i]}% - Precision: {val_prec_per_fold[i]}% - Recall: {val_rec_per_fold[i]}% - F1 Score: {val_f1_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\n\nprint('Average training scores for all folds:')\nprint(f'> Accuracy: {np.mean(train_acc_per_fold)}% (+- {np.std(train_acc_per_fold)}%)')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')\n\nprint('Average validation scores for all folds:')\nprint(f'> Accuracy: {np.mean(val_acc_per_fold)}% (+- {np.std(val_acc_per_fold)}%)')\nprint(f'> Precision: {np.mean(val_prec_per_fold)}% (+- {np.std(val_prec_per_fold)}%)')\nprint(f'> Recall: {np.mean(val_rec_per_fold)}% (+- {np.std(val_rec_per_fold)}%)')\nprint(f'> F1 Score: {np.mean(val_f1_per_fold)}% (+- {np.std(val_f1_per_fold)}%)')\nprint('------------------------------------------------------------------------')","a27be484":"# vgg19_df = pd.DataFrame({'0': preds[:, 0], '1': preds[:, 1], '2': preds[:, 2], '3': preds[:, 3]})\n# vgg19_df.to_csv('vgg19_predictions.csv', index=False)","1622838e":"#### *A lots of wool!! Certainly this one is not meant for meat!! This is the Merino sheep, wool of which is one of the most expensive in the world!!!*\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/a\/a1\/Merino_sheep.png)","9912f972":"### *Assign the labels to the images. Don't you think it's important to let the farmer know not to butcher a high paying sheep?!*","8749b158":"### *The sheep looks slick, ain't they?!* ","f73df99c":"### Boss: I want results, not how you trained and validated the model!! All I care about is ***Classification metrics***\n### Me: Alright, *se\u00f1or*...\ud83d\ude11","1e13af61":"### Here shoot up the most important tasks of the notebook \ud83d\ude0e... ***Training and Validation***","4fd3d039":"### *Necessary Imports*","7169ef97":"#### It is one of the code script implementations used in the paper:\n[Ensemble Algorithm using Transfer Learning for Sheep Breed Classification](http:\/\/https:\/\/ieeexplore.ieee.org\/document\/9465609)"}}