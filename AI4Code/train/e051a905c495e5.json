{"cell_type":{"ef392620":"code","d8e3ccd9":"code","ea11113b":"code","5020904b":"code","a4690347":"code","9f4f60c3":"code","8eeeec5f":"code","95e7c437":"code","8af3bc21":"code","93c9775e":"code","4972db2e":"code","e26fdea7":"code","1af3f082":"code","8adb99df":"code","bd56932e":"markdown"},"source":{"ef392620":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8e3ccd9":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.core.display import HTML # permet d'afficher du code html dans jupyter","ea11113b":"df_test = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\ndf_train = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\n\ndf_train.head()\ndf_test.head()","5020904b":"X_train, X_test, y_train, y_test = df_train.drop([\"label\"], axis=1), df_test.drop([\"label\"], axis=1), df_train[\"label\"], df_test[\"label\"]","a4690347":"X = np.array(df_train.drop([\"label\"],axis=1))\nprint(X[0])","9f4f60c3":"plt.imshow(X[5].reshape(28,28), cmap=\"gray_r\") # sqrt(784)=28","8eeeec5f":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","95e7c437":"acc_score = accuracy_score(y_test, y_rf)\ncm = confusion_matrix(y_test, y_rf)\nprint(acc_score,'\\n', cm)","8af3bc21":"#Deep Learning","93c9775e":"X_train =X_train.values\ny_train = y_train.values\nX_test = X_test.values\ny_test = y_test.values","4972db2e":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nmodel = Sequential()\n\nmodel.add(Dense(20, activation=\"relu\"))\nmodel.add(Dense(10, activation=\"softmax\"))\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\ntrain = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs=100, verbose=1)","e26fdea7":"y_ann = model.predict_classes(X_test).flatten()\ny_ann\nprint(accuracy_score(y_test, y_ann)) # 0.68\nconfusion_matrix(y_test, y_ann)","1af3f082":"model = Sequential()\n\nmodel.add(Dense(10, activation=\"relu\"))\nmodel.add(Dense(15, activation=\"relu\"))\nmodel.add(Dense(20, activation=\"relu\"))\nmodel.add(Dense(10, activation=\"softmax\"))\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\ntrain = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs=50, verbose=1)","8adb99df":"y_ann = model.predict_classes(X_test).flatten()\ny_ann\nprint(accuracy_score(y_test, y_ann)) # 0.747\nconfusion_matrix(y_test, y_ann)","bd56932e":"#Random Forest"}}