{"cell_type":{"9638c2ef":"code","f454532b":"code","6217b006":"code","3b3bb3aa":"code","89958391":"code","edd6a134":"code","fe4d80ef":"code","5215846a":"code","1cca8910":"code","56230c85":"code","a09d5d6e":"code","996ffa41":"code","9add973c":"code","9b8c86a6":"code","7cb8d9c3":"code","92a02182":"code","2304d175":"code","bf07dd04":"code","727093bb":"code","b2de40f9":"code","f95797a7":"code","798eb3fa":"code","3b70ff15":"code","6b35d1f4":"code","cece566b":"code","9bd3dfa1":"code","e158aaf6":"code","0d9f9e37":"code","68cc534a":"code","04a06534":"code","55073fe1":"code","247fdc77":"code","4d5c3022":"code","67d794ef":"markdown","b22df288":"markdown","a70b9f16":"markdown","995d9bd2":"markdown"},"source":{"9638c2ef":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","f454532b":"# Data loading\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6217b006":"df = pd.read_csv(r\"\/kaggle\/input\/fake-news\/train.csv\")","3b3bb3aa":"df\n# 0 means not fake and 1 means fake","89958391":"percentage_null_values = (df.isnull().sum()\/df.isnull().count())*100\npercentage_null_values","edd6a134":"# as we have to work only with title so its better to remove null values\ndf = df.dropna()","fe4d80ef":"df.isnull().sum()\n# null values removed","5215846a":"x = df.drop(\"label\" , axis = 1)","1cca8910":"y = df['label']","56230c85":"print(\"x_shape:\",x.shape)\nprint(\"y_shape:\",y.shape)","a09d5d6e":"import tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","996ffa41":"vocab_size = 5000          # dictionary of words","9add973c":"data = x.copy()\ndata.head(2)","9b8c86a6":"data.reset_index(inplace = True)   # as we removed null values so have to reset index ","7cb8d9c3":"import nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nnltk.download('stopwords')","92a02182":"stop = stopwords.words('english')","2304d175":"ps = PorterStemmer()\ncorpus = []\n\nfor i in range(len(data)):\n    final = re.sub('[^a-zA-Z]',' ',data['title'][i])\n    final = final.lower()\n    final = final.split()\n    final = [ps.stem(word) for word in final if not word in stop]\n    final = ' '.join(final)\n    corpus.append(final)","bf07dd04":"corpus","727093bb":"voc_size = 5000\n\none_hot = [one_hot(words ,voc_size) for words in corpus] # to get index of all words","b2de40f9":"one_hot","f95797a7":"# we will do padding to make all lengths same \n\nembedded_rep = pad_sequences(one_hot , padding = 'pre' , maxlen = 20)\nembedded_rep","798eb3fa":"embedded_rep[0]","3b70ff15":"embedded_rep.shape","6b35d1f4":"# making model\nfrom keras.layers import Dropout\n\nembedding_vector_features = 40\nmodel = Sequential()\nmodel.add(Embedding(voc_size , embedding_vector_features , input_length = 20))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1 , activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])","cece566b":"model.summary()","9bd3dfa1":"# now we will train model and for that we will make our x and y\n\nx_final = np.array(embedded_rep)\ny_final = np.array(y)","e158aaf6":"# splitting data for train and test\n\nfrom sklearn.model_selection import train_test_split\n\nx_train , x_test , y_train , y_test = train_test_split(x_final , y_final , random_state = 0 , test_size = 0.30)\n\nprint(\"shape of x_train:\",x_train.shape)\nprint(\"shape of x_test:\",x_test.shape)\nprint(\"shape of y_train:\",y_train.shape)\nprint(\"shape of y_test:\",y_test.shape)","0d9f9e37":"# model training\n\nmodel.fit(x = x_train , y = y_train , validation_data = (x_test , y_test) , epochs = 10 , batch_size = 64)","68cc534a":"y_pred = model.predict_classes(x_test)","04a06534":"y_pred","55073fe1":"y_test","247fdc77":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test,y_pred)","4d5c3022":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test,y_pred)","67d794ef":"## one-hot","b22df288":"## Embedding layer","a70b9f16":"### Step:\n### text data--->>preprocessing(removing stop words etc)--->>onhot(to get index)--->>embedding layer(to get setiment vectors)    ","995d9bd2":"## Preprocessing data"}}