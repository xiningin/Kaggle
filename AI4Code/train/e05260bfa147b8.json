{"cell_type":{"085a86a2":"code","d36ed861":"code","23f95fe7":"code","e99ce59b":"code","1fc00ae6":"code","ce890def":"code","a7cd555e":"code","3bf8a786":"code","08b32881":"code","cadf1c0d":"code","eea7441f":"code","59a4cbcf":"code","b576c8c2":"code","9b662dfa":"markdown","9367d076":"markdown","6c7d1fb1":"markdown","f2305254":"markdown","3da43b56":"markdown","08a71ef3":"markdown","b5489753":"markdown","b206a0a7":"markdown","e6cc4b20":"markdown"},"source":{"085a86a2":"%matplotlib inline\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom torch import autograd\nfrom torch.autograd import Variable\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt","d36ed861":"device = ('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","23f95fe7":"class FashionMNIST(Dataset):\n    def __init__(self, transform=None):\n        self.transform = transform\n        fashion_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\n        self.labels = fashion_df.label.values\n        self.images = fashion_df.iloc[:, 1:].values.astype('uint8').reshape(-1, 28, 28)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        label = self.labels[idx]\n        img = Image.fromarray(self.images[idx])\n        \n        if self.transform:\n            img = self.transform(img)\n\n        return img, label","e99ce59b":"dataset = FashionMNIST()\ndataset[0][0]","1fc00ae6":"transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5), std=(0.5))\n])\ndataset = FashionMNIST(transform=transform)\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)","ce890def":"class Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.label_emb = nn.Embedding(10, 10)\n        \n        self.model = nn.Sequential(\n            nn.Linear(794, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x, labels):\n        x = x.view(x.size(0), 784) # batch_size x 784\n        c = self.label_emb(labels) # batch_size x 10\n        x = torch.cat([x, c], 1)   # batch_size x 794\n        out = self.model(x)        # batch_size x 1\n        return out.squeeze()       # batch_size","a7cd555e":"class Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.label_emb = nn.Embedding(10, 10)\n        \n        self.model = nn.Sequential(\n            nn.Linear(110, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(1024, 784),\n            nn.Tanh()\n        )\n    \n    def forward(self, z, labels):\n        z = z.view(z.size(0), 100)      # batch_size x 100\n        c = self.label_emb(labels)      \n        x = torch.cat([z, c], 1)        # batch_size x 110\n        out = self.model(x)             # batch_size x 784\n        return out.view(x.size(0), 28, 28) # batch_size x 28 x 28","3bf8a786":"generator = Generator().to(device)\ndiscriminator = Discriminator().to(device)","08b32881":"criterion = nn.BCELoss()\nd_optimizer = torch.optim.Adam(discriminator.parameters() , lr=1e-4)\ng_optimizer = torch.optim.Adam(generator.parameters() , lr=1e-4)","cadf1c0d":"def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n    g_optimizer.zero_grad()\n    z = Variable(torch.randn(batch_size, 100)).to(device)\n    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 10, batch_size))).to(device)\n    fake_images = generator(z, fake_labels)\n    validity = discriminator(fake_images, fake_labels)\n    g_loss = criterion(validity, Variable(torch.ones(batch_size)).to(device))\n    g_loss.backward()\n    g_optimizer.step()\n    return g_loss.data","eea7441f":"def discriminator_train_step(batch_size , discriminator , generator , d_optimizer , criterion , real_image , labels):\n    d_optimizer.zero_grad()\n    \n    # train with real images\n    real_validity = discriminator(real_images , labels)\n    real_loss = criterion(real_validity , Variable(torch.ones(batch_size).to(device)))\n    \n    # train with fake images\n    z = Variable(torch.randn(batch_size ,100)).to(device)\n    fake_labels = Variable(torch.LongTensor(np.random.randint(0,10,batch_size))).to(device)\n    fake_images = generator(z , fake_labels)\n    fake_validity = discriminator(fake_images , fake_labels)\n    fake_loss = criterion(fake_validity , Variable(torch.zeros(batch_size)).to(device))\n    \n    d_loss = real_loss + fake_loss\n    d_loss.backward()\n    d_optimizer.step()\n    return d_loss.data","59a4cbcf":"num_epochs = 30\nn_critic = 5\ndisplay_step = 300\nfor epoch in range(num_epochs):\n    print(\"Starting epoch {}...\".format(epoch))\n    for i , (images , labels) in enumerate(data_loader):\n        real_images = Variable(images).to(device)\n        labels = Variable(labels).to(device)\n        generator.train()\n        batch_size = real_images.size(0)\n        d_loss = discriminator_train_step(batch_size , discriminator , generator , d_optimizer , criterion , real_images , labels)\n        g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n    generator.eval()\n    print('g_loss: {} , d_loss: {} '.format(g_loss , d_loss))\n    z = Variable(torch.randn(9,100)).to(device)\n    labels = Variable(torch.LongTensor(np.arange(9))).to(device)\n    sample_images = generator(z , labels).unsqueeze(1).data.cpu()\n    grid = make_grid(sample_images, nrow=3, normalize=True).permute(1,2,0).numpy()\n    print(grid.shape)\n    plt.imshow(grid)\n    plt.show()","b576c8c2":"z = Variable(torch.randn(100,100)).to(device)\nlabels = Variable(torch.LongTensor([i for _ in range(10) for i in range(10)])).to(device)\nsample_images = generator(z , labels).unsqueeze(1).data.cpu()\nprint(sample_images.shape)\nprint(make_grid(sample_images, nrow=10, normalize=True).shape)\ngrid = make_grid(sample_images, nrow=10, normalize=True).permute(1,2,0).numpy()\nprint(grid.shape)\nfig, ax = plt.subplots(figsize=(15,15))\nax.imshow(grid)\n","9b662dfa":"**** Create Discriminator Model ****","9367d076":"Create optimizer for both Discriminator and Generator","6c7d1fb1":"Define dataset","f2305254":"## Import Libraries ","3da43b56":"Training function of generater model","08a71ef3":"## Set The device\nUse cuda if available otherwise use cpu","b5489753":"**Create Generator Model**","b206a0a7":"Train the model","e6cc4b20":"Training function of generater model"}}