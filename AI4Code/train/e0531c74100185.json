{"cell_type":{"09b53e20":"code","253d9e12":"code","81978bf3":"code","72f73d03":"code","0c6a23b7":"code","5e1cfbdb":"code","8425089d":"code","4d778a10":"code","f4dd1005":"code","32ca961d":"code","069a8557":"code","b3ce56d6":"code","3c749f75":"code","9d12d447":"code","86254fec":"code","9aabd559":"code","e48e689c":"code","d2805dfe":"code","11cf83c7":"code","415c6937":"code","2ff8c89c":"code","45ee5ac9":"code","c5b312cd":"code","e3ac99cb":"code","382f0871":"code","e15d0b6e":"code","e0b8d71c":"code","7c735bba":"code","ce56bcb7":"code","e48f8ed5":"code","5bc8085e":"code","14c6edbb":"code","6100bcd8":"code","aa3b4792":"code","b48beed9":"code","210a8a21":"code","5cfe6891":"code","9c715ea6":"code","5e0f1266":"code","c956509a":"markdown","0489c9de":"markdown","7012072d":"markdown","8c7b5ac8":"markdown","ff99eda9":"markdown","7488eb18":"markdown","3ba1dc3e":"markdown","2377a391":"markdown","94915d31":"markdown","1d2ab1c1":"markdown","b306f67e":"markdown","6497c059":"markdown","232b45ca":"markdown","9a38e5c4":"markdown","67b9a52e":"markdown","da9556fa":"markdown","2fadb644":"markdown","71652243":"markdown","acc5e80e":"markdown","3eedafdf":"markdown","8f8bb9db":"markdown","e9fa448f":"markdown","ee1c377d":"markdown","26123f69":"markdown","1db8a319":"markdown","a0c1f95c":"markdown","4f07b01a":"markdown","2a032adb":"markdown","6b00f8bb":"markdown","ecebe3a4":"markdown","6bec8ee9":"markdown","9787053e":"markdown","52ce1681":"markdown","2280cafe":"markdown","5d0ef88b":"markdown","14d6b0fc":"markdown","5466a62b":"markdown","f292ad27":"markdown","1a0e0ea5":"markdown","b6141584":"markdown","cec9f8ee":"markdown","033376bc":"markdown","738f5511":"markdown","3496dc2c":"markdown","fdb8e4b7":"markdown","ba440b07":"markdown","0e8604be":"markdown","5fa8581f":"markdown","2c44a517":"markdown"},"source":{"09b53e20":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom scipy import stats\n%matplotlib inline","253d9e12":"sns.set(color_codes=True)\npd.set_option('display.max_columns', None)","81978bf3":"file_path = '..\/input\/housesalesprediction\/kc_house_data.csv'\ndf = pd.read_csv(file_path)","72f73d03":"df.head()","0c6a23b7":"df.dtypes","5e1cfbdb":"df.shape","8425089d":"df.describe()","4d778a10":"# The columns\ncategorical = ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade']\ncontinous = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']","f4dd1005":"# Pearson coefficient\ncontinous_df = df[continous]\ncontinous_df.corrwith(df['price'])","32ca961d":"for column_name in continous:\n    plt.figure(figsize=(10,8))\n    sns.scatterplot(x=column_name, y='price', data=df)","069a8557":"pearson_coeff, p_value = stats.pearsonr(df['sqft_living'], df['price'])\nprint(\"sqft_living -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)\n\npearson_coeff, p_value = stats.pearsonr(df['sqft_living15'], df['price'])\nprint(\"sqft_living15 -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)\n\npearson_coeff, p_value = stats.pearsonr(df['sqft_above'], df['price'])\nprint(\"sqft_above -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)\n\npearson_coeff, p_value = stats.pearsonr(df['sqft_basement'], df['price'])\nprint(\"sqft_basement -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)\n\npearson_coeff, p_value = stats.pearsonr(df['lat'], df['price'])\nprint(\"lat -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)","b3ce56d6":"# Categorical\nfor column_name in categorical:\n    plt.figure(figsize=(10,8))\n    sns.boxplot(x=column_name, y='price', data=df)","3c749f75":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","9d12d447":"%matplotlib inline\nsns.set(color_codes=True)\npd.set_option('display.max_columns', None)","86254fec":"X = df[['sqft_above', 'sqft_living15', 'sqft_living', 'sqft_basement', 'bedrooms', 'bathrooms', 'waterfront', 'floors', 'lat', 'view' , 'grade']]\ny = df[['price']]","9aabd559":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","e48e689c":"lm = LinearRegression()\nlm.fit(X_train, y_train)","d2805dfe":"yhat_test = lm.predict(X_test)\nyhat_test_df = pd.DataFrame(yhat_test, columns=['predicted_price'])","11cf83c7":"plt.figure(figsize=(12,10))\nax = sns.kdeplot(y_test['price'])\nax = sns.kdeplot(yhat_test_df['predicted_price'], ax=ax)\nax.legend(['y', 'y_hat'], fontsize=13);","415c6937":"lm.score(X_test, y_test)","2ff8c89c":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures","45ee5ac9":"pipe_info = [('Normalize', StandardScaler()), ('Polynomial Features', PolynomialFeatures(include_bias=False)), ('Linear Model', LinearRegression())]\npipe = Pipeline(pipe_info)","c5b312cd":"pipe.fit(X_train, y_train)","e3ac99cb":"yhat_test_pipe = pipe.predict(X_test)\nyhat_test_pipe_df = pd.DataFrame(yhat_test_pipe, columns=['predicted_price'])","382f0871":"plt.figure(figsize=(12,10))\nax = sns.kdeplot(y_test['price'])\nax = sns.kdeplot(yhat_test_pipe_df['predicted_price'], ax=ax)\nax.legend(['y', 'y_hat'], fontsize=13);","e15d0b6e":"pipe.score(X_test, y_test)","e0b8d71c":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge","7c735bba":"pipe_info_ridge = [('Normalize', StandardScaler()), ('Polynomial Features', PolynomialFeatures(include_bias=False)), ('Regression', Ridge())]\nridge_pipe = Pipeline(pipe_info_ridge)","ce56bcb7":"ridge_pipe.get_params().keys()","e48f8ed5":"hyper_params_dict = {'Regression__alpha': [0.0001, 0.001, 0.01, 0.1, 0, 1, 10, 100, 1000, 10000]}","5bc8085e":"grid = GridSearchCV(estimator=ridge_pipe, param_grid=hyper_params_dict, scoring='r2', n_jobs=-1, cv=4)","14c6edbb":"grid.fit(X_train, y_train)","6100bcd8":"grid.best_params_","aa3b4792":"best_ridge = grid.best_estimator_\nbest_ridge","b48beed9":"yhat_ridge = best_ridge.predict(X_test)\nyhat_ridge_df = pd.DataFrame(yhat_ridge, columns=['predicted_price'])\nplt.figure(figsize=(12,10))\nax = sns.kdeplot(y_test['price'])\nax = sns.kdeplot(yhat_test_pipe_df['predicted_price'], ax=ax)\nax.legend(['y', 'y_hat'], fontsize=13);","210a8a21":"grid.best_score_","5cfe6891":"from sklearn.model_selection import cross_val_score","9c715ea6":"cv_scores = cross_val_score(estimator=best_ridge, X=X, y=y, cv=5)\ncv_scores","5e0f1266":"pd.Series(cv_scores).describe()","c956509a":"# Exploratory Analysis <a id='2'><\/a>\n----------------------","0489c9de":"For ridge regression, we would be optimizing the hyper-parameter $\\alpha$ by grid search. Let's get the parameters.","7012072d":"Although we did take Cross-validation into account when doing the Grid Search for Regression, let's do a k-fold cross-validation with 5 folds regardless. We would getting the R-squared values.\n\nLet's get started. \n\nMandatory Imports.","8c7b5ac8":"So, we would be using the `Regression__alpha` parameter then. Let's create the dict with parameters.","ff99eda9":"It seems that everything except condition would be a good predictor. ","7488eb18":"Time to use the grid search","3ba1dc3e":"That seems like a decent result. ","2377a391":"We will create a pipeline that will first normalize the values (using standard scalar), create polynomial features (with degree of 2) and then use linear model to predict the data. \n\nLet's create the pipeline","94915d31":"# Predicting House Prices\n----------------------------------------------\n\nIn this notebook, I will be creating a model to predict house prices in the King County based on the dataset.","1d2ab1c1":"## Creating a pipeline <a id='17'><\/a>","b306f67e":"### Conclusion: Continous <a id='7'><\/a>","6497c059":"# Cross-validation <a id='19'><\/a>","232b45ca":"# Table of Contents\n\n* [Setup](#1)\n* [Exploratory Analysis](#2)\n    - [Summary](#3)\n    - [Finding categorical and continous variables](#4)\n    - [Continous](#5)\n        + [Statistical Significance](#6)\n        + [Conclusion: Continous](#7)\n    - [Categorical](#8)\n        + [Conclusion: Categorical](#9)\n    - [Exploratory Conclusion](#10)\n* [Model Development and Evaluation](#11)\n* [Setup](#12)\n* [Multiple Linear Regression Model](#13)\n    - [Building the model](#14)\n    - [Teseting and evaluating the model](#15)\n* [Polynomial Regression and Normalization](#16)\n    - [Creating a pipeline](#17)\n* [Ridge Regression](#18)\n* [Cross-validation](#19)\n* [Conclusion](#20)\n* [Author](#21)","9a38e5c4":"## Continous <a id='5'><\/a>\n\nLet's explore the relationship of continous variables and price.\n\nWe would be using two methods:\n* The Pearson coefficient\n* Scatter plot","67b9a52e":"The features that can predict price are _sqft_living, sqft_living15, sqft_above, sqft_basement and lat_","da9556fa":"## Categorical <a id='8'><\/a>\n\nLet's figure out the relationship between categorical variables and price. We will first plot them. ","2fadb644":"Summary of the data","71652243":"# Model Development and Evaluation <a id='11'><\/a>\n----------------------------------\n\nNow, let's move onto creating a model.\n\nI will be making a linear regression since we are trying to predict a continous variable that has some linear relationship with its 'dependent' variables. ","acc5e80e":"# Polynomial Regression and Normalization <a id='16'><\/a>","3eedafdf":"### Statistical Significance <a id='6'><\/a>\n\nLet's find whether they are statistically significant or not. We would be using p-value for that.","8f8bb9db":"## Building the model <a id='14'><\/a>\n\nWe would first be building a MLR model. From the exploratory analysis, we know that the important features are:\n* sqft_above\n* sqft_living15\n* sqft_living\n* sqft_basement\n* bedrooms\n* bathrooms\n* waterfront\n* floors\n* lat\n* view \n* grade\n\nThe first step would be to create X and y. ","e9fa448f":"# Setup <a id='1'><\/a>\n\nImporting the libraries and getting the data.","ee1c377d":"# Ridge Regression <a id='18'><\/a>","26123f69":"# Conclusion <a id='20'><\/a>\n\nThere we go. A linear regression model to predict houseprices.\n\nThe best model we achieved had a mean cv score of 0.73 and was a Ridge Regression model with $\\alpha$ as 1000.  ","1db8a319":"## Summary <a id='3'><\/a>\n\nNow let's see the columns types in the dataframe. ","a0c1f95c":"Let's test the model by getting prediction values and making a distribution plot.","4f07b01a":"Finally, we need to get summary of the array.","2a032adb":"Without further ado, let's get started.","6b00f8bb":"## Finding categorical and continous variables <a id='4'><\/a>\n\nWe can see that the columns _floors, waterfront, view, condition,_ and _grade_ have few values and could be seen as categorical. Thus we should use a boxplot to explore the relationship between them.\n\nAs of the rest, a scatterplot would be a good idea.","ecebe3a4":"Let's find the best estimator and the param","6bec8ee9":"Finally, the R-squared score we got.","9787053e":"A better score. But there's further room for improvement. \n\nLet's try Ridge Regression because the parameters could be correlated (such as having more bedrooms is likely to imply more bathrooms).","52ce1681":"Now, let's create the model.","2280cafe":"That looks a really good estimate. We should also get some numeric values. Let's get the R-squared value.","5d0ef88b":"Now let's use the pipeline","14d6b0fc":"# Setup <a id='12'><\/a>\n\nFirst, we need to get started by importing the libraries, setting some options and importing the data.","5466a62b":"Then, we need to split the data. ","f292ad27":"# Author <a id='21'><\/a>\nBy Abhinav Garg","1a0e0ea5":"# Multiple Linear Regression Model <a id='13'><\/a>","b6141584":"We would be creating a pipe to first normalize, polynomial features and then ridge regression. \n\nMandatory Imports:","cec9f8ee":"## Exploratory Conclusion <a id='10'><\/a>\n\nThe features that we found that we can use to predict the house price are:\n* sqft_above\n* sqft_living15\n* sqft_living\n* sqft_basement\n* bedrooms\n* bathrooms\n* waterfront\n* floors\n* lat\n* view \n* grade","033376bc":"So, there's room for improvement. \n\nIf we take a look at the graphs in the exploratory analysis, we can see them some features (say grade) have a non-linear relationship. So, we need to make a polynomial linear regression model to take those into account properly.\n\nFurthermore, it would be helpfult to normalize the variables, so that few variables might not dominate the model","738f5511":"## Testing and evaluating the model <a id='15'><\/a>","3496dc2c":"We can see that the ones that might have correlation with price are _sqft_living, sqft_above, sqft_living15._ _lat,_ and _sqft_basement_ also have moderate correlation too.","fdb8e4b7":"The best way to go at it would be to create a pipeline.\n\nLet's import the modules first.","ba440b07":"Now let's plot it and see what we get.","0e8604be":"The p-value is extremely low to the point that it seems like 0.\n\nNow, we can confidently say that these variables have correlation with price.","5fa8581f":"The distribution plot:","2c44a517":"### Conclusion: Categorical <a id='9'><\/a>\n\nWe concluded that the variables of interest are _bedrooms, bathrooms, waterfront, view,_ and _grade_"}}