{"cell_type":{"b5d85369":"code","438f3262":"code","f416ed91":"code","012e94a6":"code","05df7ee6":"code","5fab2c3d":"code","29eaf833":"code","c4b3ec8b":"code","fe3dbaf9":"code","0fad6cf5":"code","378d521b":"code","4cb2422f":"code","39a2e5cb":"code","c281b0a6":"code","34d748d3":"code","d88fc126":"code","26b27c89":"code","8f38770e":"code","9455a795":"code","bfb67316":"code","cfcf2986":"markdown","ae1f0b16":"markdown","3c071e03":"markdown","f6f76ce2":"markdown","16204a4c":"markdown","0cb8a7a2":"markdown","c4d75bbb":"markdown","e705a18b":"markdown"},"source":{"b5d85369":"import os\nimport shutil\nimport  joblib\nimport numpy as np\nimport pandas as pd\nimport librosa as lb\nimport librosa.display\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm","438f3262":"DATA_ROOT = Path(\"..\/input\/rfcx-species-audio-detection\")\nTRAIN_AUDIO_ROOT = Path(\"..\/input\/rfcx-species-audio-detection\/train\")\nTEST_AUDIO_ROOT = Path(\"..\/input\/rfcx-species-audio-detection\/test\")","f416ed91":"df_train = pd.DataFrame({\n    \"recording_id\": [path.stem for path in Path(TRAIN_AUDIO_ROOT).glob(\"*.flac\")],\n})\n\ndf_test = pd.DataFrame({\n    \"recording_id\": [path.stem for path in Path(TEST_AUDIO_ROOT).glob(\"*.flac\")],\n})","012e94a6":"class params:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = 32000\n\n    # Melspectrogram\n    n_mels = 128\n    fmin = 20\n    fmax = sr \/\/ 2  # Shannon theorem","05df7ee6":"def load_audio(record, sr=16000, root=\"\"):\n    y, _ = lb.load(\n        root.joinpath(record).with_suffix(\".flac\").as_posix(),\n        sr=sr, \n    )\n    return y","5fab2c3d":"def compute_melspec(y, params):\n    \"\"\"\n    Computes a mel-spectrogram and puts it at decibel scale\n    Arguments:\n        y {np array} -- signal\n        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n    Returns:\n        np array -- Mel-spectrogram\n    \"\"\"\n    melspec = lb.feature.melspectrogram(\n        y, sr=params.sr, n_mels=params.n_mels, fmin=params.fmin, fmax=params.fmax,\n    )\n\n    melspec = lb.power_to_db(melspec).astype(np.float32)\n    return melspec","29eaf833":"y = load_audio(df_train[\"recording_id\"][0], params.sr, TRAIN_AUDIO_ROOT)","c4b3ec8b":"melspec = compute_melspec(y, params)","fe3dbaf9":"fig, ax = plt.subplots(figsize=(15, 5))\nimg = librosa.display.specshow(\n    melspec[:, :512], \n    sr=params.sr,\n    x_axis='time', \n    y_axis='linear', \n    ax=ax)\nfig.colorbar(img, ax=ax, format=\"%+2.f dB\")\nplt.show()","0fad6cf5":"np.save(\"melspec.npy\", melspec)","378d521b":"%%timeit \n\nspec = np.load(\"melspec.npy\")","4cb2422f":"%%timeit \n\ny = load_audio(df_train[\"recording_id\"][0], params.sr, TRAIN_AUDIO_ROOT)\nmelspec = compute_melspec(y, params)","39a2e5cb":"def load_and_save_train(record):\n    y = load_audio(record, params.sr, TRAIN_AUDIO_ROOT)\n    melspec = compute_melspec(y, params)\n\n    np.save(OUT_TRAIN + record + \".npy\", melspec)","c281b0a6":"# OUT_TRAIN = 'train\/'\n# os.mkdir(OUT_TRAIN)","34d748d3":"# _ = joblib.Parallel(n_jobs=8)(\n#     joblib.delayed(load_and_save_train)(record) for record in tqdm(df_train['recording_id'].values)\n# )","d88fc126":"# shutil.make_archive(OUT_TRAIN, 'zip', OUT_TRAIN)\n# shutil.rmtree(OUT_TRAIN)","26b27c89":"def load_and_save_test(record):\n    y = load_audio(record, params.sr, TEST_AUDIO_ROOT)\n    melspec = compute_melspec(y, params)\n\n    np.save(OUT_TEST + record + \".npy\", melspec)","8f38770e":"OUT_TEST = 'test\/'\nos.mkdir(OUT_TEST)","9455a795":"_ = joblib.Parallel(n_jobs=8)(\n    joblib.delayed(load_and_save_test)(record) for record in tqdm(df_test['recording_id'].values)\n)","bfb67316":"shutil.make_archive(OUT_TEST, 'zip', OUT_TEST)\nshutil.rmtree(OUT_TEST)","cfcf2986":"# Data","ae1f0b16":"## Train","3c071e03":"# Main","f6f76ce2":"# Time comparison","16204a4c":"x 3000 improvement ! ","0cb8a7a2":"# Tools","c4d75bbb":"# Example","e705a18b":"## Test"}}