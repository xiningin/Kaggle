{"cell_type":{"a2358298":"code","421be7d7":"code","9d5e88fe":"code","361dad7d":"code","54e4a4a3":"code","4fadc822":"code","8d2d90ba":"code","97545b1b":"code","16ff4568":"code","cbfe45b7":"code","57fb30db":"markdown"},"source":{"a2358298":"import torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch import nn\nimport pathlib\nfrom torch.utils.data import DataLoader\nfrom torchvision import *","421be7d7":"device = torch.device(\"cpu\")\ntransformtrain = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(9),\n    transforms.ToTensor(),\n    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n])","9d5e88fe":"transformtest = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n])","361dad7d":"trainds = datasets.ImageFolder('..\/input\/fruits-360_dataset\/fruits-360\/Training\/', transform=transformtrain)\ntestds = datasets.ImageFolder('..\/input\/fruits-360_dataset\/fruits-360\/Test\/', transform=transformtest)","54e4a4a3":"trainloader = DataLoader(trainds, batch_size=64, shuffle=True)\ntestloader = DataLoader(testds, batch_size=32, shuffle=False)","4fadc822":"root = pathlib.Path('..\/input\/fruits-360_dataset\/fruits-360\/Training\/')\nclasses = sorted([j.name.split('\/')[-1] for j in root.iterdir()])","8d2d90ba":"class ConvNet(nn.Module):\n\n    def __init__(self, epoch, learningrate):\n        super().__init__()\n        self.epoch = epoch\n        self.lr = learningrate\n        self.conv1 = nn.Conv2d(3, 8, 5, 1, 2)\n        self.conv2 = nn.Conv2d(8, 16, 5, 1, 2)\n        self.fc1 = nn.Linear(8*8*16, 300)\n        self.fc2 = nn.Linear(300, len(classes))\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 8*8*16)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","97545b1b":"model = ConvNet(10, 0.0001).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), model.lr, weight_decay=0.0001)\ntrainlosses = []\ntestlosses = []","16ff4568":"for e in range(model.epoch):\n    trainloss = 0.0\n    traintotal = 0\n    trainsuccessful = 0\n    for traininputs, trainlabels in trainloader:\n        inputs, labels = traininputs.to(device), trainlabels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        _, trainpredict = torch.max(outputs.data, 1)\n        loss.backward()\n        optimizer.step()\n        trainloss += loss.item()\n        traintotal += labels.size(0)\n        trainsuccessful += (trainpredict == labels).sum().item()\n\n    else:\n        testloss = 0.0\n        testtotal = 0\n        testsuccessful = 0\n        with torch.no_grad():\n            for testimages, testlabels in testloader:\n                inputs_, labels_ = testimages.to(device), testlabels.to(device)\n                predictions = model(inputs_)\n                tloss = criterion(predictions, labels_)\n                testloss += tloss.item()\n                _, predict = torch.max(predictions.data, 1)\n                testtotal += labels_.size(0)\n                testsuccessful += (predict == labels_).sum().item()\n        trainlosses.append(trainloss\/len(trainloader))\n        testlosses.append(testloss\/len(testloader))\n        print('Train Accuracy %{:.2f}'.format(100*trainsuccessful\/traintotal))\n        print('Test Accuracy %{:.2f}'.format(100*testsuccessful\/testtotal))","cbfe45b7":"plt.plot(trainlosses, label='Training loss', color='green')\nplt.plot(testlosses, label='Validation loss', color='black')\nplt.legend(frameon=False)\nplt.show()","57fb30db":"Could rise weight decay or dropout to pretend overfitting(~%5). And use gpu for faster training. With more training, it will approach to %100."}}