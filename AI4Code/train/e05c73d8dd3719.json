{"cell_type":{"b130e502":"code","d5a52e27":"code","9f7b842e":"code","9782f2a1":"code","f94ffacf":"code","8a69daae":"code","b819f5c7":"code","d59f5875":"code","72afef61":"code","0bbdf2f3":"code","8a797972":"code","665563a7":"code","40aa0e2a":"code","6da775ca":"code","bb4ab8ee":"code","54f40dbb":"code","e2bd46c9":"code","388dbdfe":"code","adb4dbc7":"code","20bd13df":"code","25f2fd4a":"code","e449adb7":"code","aff26181":"code","9b4ea3ee":"code","db20c1e6":"code","5e0a72fc":"code","6e1cfcf6":"code","53de15d2":"code","c1b6e325":"code","ce1930e6":"code","baf72df4":"code","7039bb42":"code","0b01b695":"code","c8e2516a":"code","29d9605c":"code","d1ef49d2":"code","5de44de4":"code","2ab62d30":"code","979b9a34":"code","88e20ae2":"markdown","f4a998cc":"markdown","a1e77a4e":"markdown","4b75e314":"markdown","ce075421":"markdown","1cef4e52":"markdown","75faf793":"markdown","3d53f86a":"markdown"},"source":{"b130e502":"import numpy as np # matrix tools\nimport matplotlib.pyplot as plt # for basic plots\nimport seaborn as sns # for nicer plots\nimport pandas as pd\nfrom glob import glob\nimport re\nfrom skimage.io import imread\n\nimport keras","d5a52e27":"overview_df = pd.read_csv('..\/input\/overview.csv')\noverview_df.columns = ['idx']+list(overview_df.columns[1:])\noverview_df['Contrast'] = overview_df['Contrast'].map(lambda x: 'Contrast' if x else 'No Contrast')\noverview_df.sample(3)","9f7b842e":"%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname,\"______\")\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9782f2a1":"IS_LOCAL = False\nif(IS_LOCAL):\n    PATH=\"..\/input\/siim-medical-image\/\"\nelse:\n    PATH=\"..\/input\/\"\nprint(os.listdir(PATH))\noverview = pd.read_csv(os.path.join(PATH,\"overview.csv\"))\noverview.head()","f94ffacf":"len(overview)","8a69daae":"overview['Contrast'] = overview['Contrast'].map(lambda x: 1 if x else 0)","b819f5c7":"plt.figure(figsize=(10,5))\nsns.distplot(overview['Age'])","d59f5875":"g = sns.FacetGrid(overview, col=\"Contrast\", size=8)\ng = g.map(sns.distplot, \"Age\")","72afef61":"g = sns.FacetGrid(overview, hue=\"Contrast\",size=6, legend_out=True)\ng = g.map(sns.distplot, \"Age\").add_legend()","0bbdf2f3":"#if(IS_LOCAL):\n   #PATH=\"\/input\/siim-medical-image\/\"\n#else:\n    #PATH=\"\/input\/\"\n\n\nBASE_IMG_PATH='..\/input'\n#print(os.listdir(BASE_IMG_PATH))\n#print(os.path.join(BASE_IMG_PATH,'tiff_images','*.tif'))\nall_images_list = glob(os.path.join(BASE_IMG_PATH,'tiff_images','*.tif'))\nall_images_list[:5]\nprint(all_images_list)","8a797972":"imread(all_images_list[0]).shape","665563a7":"np.array(np.arange(81)).reshape(9,9)","40aa0e2a":"np.array(np.arange(81)).reshape(9,9)[::3,::3]","6da775ca":"np.expand_dims(imread(all_images_list[0])[::4,::4],0).shape","bb4ab8ee":"jimread = lambda x: np.expand_dims(imread(x)[::2,::2],0)","54f40dbb":"test_image = jimread(all_images_list[0])\nplt.imshow(test_image[0])","e2bd46c9":"check_contrast = re.compile(r'ID_([\\d]+)_AGE_[\\d]+_CONTRAST_([\\d]+)_CT')\nlabel = []\nid_list = []\nfor image in all_images_list:\n    id_list.append(check_contrast.findall(image)[0][0])\n    label.append(check_contrast.findall(image)[0][1])","388dbdfe":"label_list = pd.DataFrame(label,id_list)","adb4dbc7":"label_list.head()","20bd13df":"images = np.stack([jimread(i) for i in all_images_list],0)","25f2fd4a":"len(images)","e449adb7":"from sklearn.model_selection import train_test_split","aff26181":"X_train, X_test, y_train, y_test = train_test_split(images, label_list, test_size=0.1, random_state=0)","9b4ea3ee":"n_train, depth, width, height = X_train.shape\nn_test,_,_,_ = X_test.shape","db20c1e6":"n_train,depth, width, height","5e0a72fc":"input_shape = (width,height,depth)","6e1cfcf6":"input_shape","53de15d2":"input_train = X_train.reshape((n_train, width,height,depth))\ninput_train.shape\ninput_train.astype('float32')\ninput_train = input_train \/ np.max(input_train)\ninput_train.max()","c1b6e325":"input_test = X_test.reshape(n_test, *input_shape)\ninput_test.astype('float32')\ninput_test = input_test \/ np.max(input_test)","ce1930e6":"output_train = keras.utils.to_categorical(y_train, 2)\noutput_test = keras.utils.to_categorical(y_test, 2)\noutput_train[5]","baf72df4":"input_train.shape","7039bb42":"from keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.layers import Conv2D, MaxPooling2D","0b01b695":"batch_size = 20\nepochs = 40","c8e2516a":"model2 = Sequential()\nmodel2.add(Conv2D(50, (5, 5), activation='relu', input_shape=input_shape))\n # 32 4x4 Filter  Convolutional Network\nmodel2.add(MaxPooling2D(pool_size=(3, 3))) # 3x3 Maxpooling \nmodel2.add(Conv2D(30, (4, 4), activation='relu', input_shape=input_shape))\nmodel2.add(MaxPooling2D(pool_size=(2, 2))) # 2x2 Maxpooling \nmodel2.add(Flatten()) #Fully Connected Neural Network \nmodel2.add(Dense(2, activation='softmax'))","29d9605c":"model2.summary()","d1ef49d2":"model2.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","5de44de4":"history = model2.fit(input_train, output_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(input_test, output_test))","2ab62d30":"score = model2.evaluate(input_test, output_test, verbose=0)\nscore","979b9a34":"model2.predict(input_test)","88e20ae2":"## Read Image Files ","f4a998cc":"## Split Data to Train, Test","a1e77a4e":"## Network","4b75e314":"## Exploratory data analysis","ce075421":"## Reshape image Data ","1cef4e52":"## Model 2","75faf793":"# Constrast Cancer Classification","3d53f86a":" - np.expand_dims -> Expand the shape of an array.\n  - Insert a new axis, corresponding to a given position in the array shape."}}