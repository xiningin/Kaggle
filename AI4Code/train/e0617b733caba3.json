{"cell_type":{"16b6b243":"code","f9369c4b":"code","9e87df46":"code","a84e0131":"code","bc5e04f2":"code","ffd3e91b":"code","afadbe75":"code","6f5cb07c":"code","871b0982":"code","ec406e59":"code","2aa60a78":"code","c489ee42":"code","3eab1a44":"code","f75583e1":"code","db83ed78":"code","ee23a571":"code","1a55c3e9":"code","d1540434":"code","4160cef6":"code","4bc0c656":"code","f3ca6067":"code","7fb3970f":"code","a1d6b32a":"code","c392ed69":"code","57354da6":"code","572d9864":"code","f31bac59":"code","a3be8961":"code","54582be6":"code","a7f6e208":"code","f1f40fc4":"code","a8eb9cdb":"code","ab7d0845":"code","e5feb958":"code","527ad8c0":"code","63a004dd":"code","683d3dd1":"code","a5d0e6b3":"code","2999ddaf":"code","ee1e3af6":"code","c0e2c5c9":"code","134da481":"code","9d42ab23":"code","9800427e":"code","293becec":"code","cebdf301":"code","d9c56a8f":"code","9c1551c1":"code","f666e66b":"code","915fbfc2":"code","d49d4333":"code","ad37f513":"code","75641998":"code","248b25f3":"code","86495d8b":"code","528981ee":"code","b79f5e79":"code","64e3b1f5":"code","171fbdd0":"code","59c450fb":"code","a13384c7":"code","381b783b":"code","272a2020":"code","75d776a8":"code","2d1303a5":"code","4a98ad1c":"code","a10af1d7":"code","cb8538a5":"code","efcc081e":"code","e338cb0b":"code","4e1b8030":"code","71782b3f":"code","9c649e98":"code","353ad02c":"code","762eda54":"code","6fcb40dd":"code","65de4dc8":"code","205bca79":"code","2be55736":"code","06d97498":"code","1683d91f":"code","5f17e457":"code","99522a98":"code","de8d83bc":"code","6e4bdec8":"code","a9691950":"code","63436253":"code","bb4a1644":"code","d7bdfec0":"code","4efc8d95":"code","b321fdfc":"code","8876a2bc":"code","2a1de96c":"code","0e38d912":"code","19a602ed":"markdown","21c8d601":"markdown","a39b7622":"markdown","a9ef35c0":"markdown","43671e6d":"markdown","4a75d64a":"markdown","c431b5d3":"markdown","b2097d5d":"markdown","92c2c8d1":"markdown","7eb7b414":"markdown","7871e6c0":"markdown","bfe2ebaf":"markdown","c50dbdbe":"markdown","198129d9":"markdown","280c85e3":"markdown","2e945f8c":"markdown","efda2759":"markdown","dbce54ed":"markdown","4879214c":"markdown","c8874364":"markdown","0a3620a0":"markdown","a0ad4fca":"markdown","e1566ee1":"markdown","ade12347":"markdown","f0ef907a":"markdown","0b9a6b27":"markdown","c97d1f83":"markdown","81e35486":"markdown","ea73d979":"markdown","b11cf2bf":"markdown","8ed025db":"markdown","2a49fde2":"markdown","7ce00982":"markdown"},"source":{"16b6b243":"import re\nimport gc\nimport string\nfrom tqdm import tqdm\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet, stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nimport seaborn as sns\ncolor = sns.color_palette()\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec \n\nimport numpy as np \nimport pandas as pd\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport spacy\nfrom collections import Counter, defaultdict\nimport en_core_web_sm\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.linear_model import LogisticRegression\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.layers import Dropout, SpatialDropout1D, Embedding, add, concatenate, Concatenate, Input\nfrom tensorflow.keras.layers import LSTM, Dense, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPool1D\nfrom tensorflow.compat.v1.keras.layers import CuDNNLSTM","f9369c4b":"train_data = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip')\ntest_data = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip')","9e87df46":"train_data.head()","a84e0131":"test_data.head()","bc5e04f2":"train_data.info()","ffd3e91b":"train_data.isna().sum()","afadbe75":"train_data.shape, test_data.shape","6f5cb07c":"comments = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ncomments_count = [train_data.toxic.sum(), train_data.severe_toxic.sum(), \n         train_data.obscene.sum(), train_data.threat.sum(), \n         train_data.insult.sum(), train_data.identity_hate.sum() ]\n\nplt.bar(comments, comments_count, width=0.6)","871b0982":"sum(comments_count)","ec406e59":"normal_comments = train_data.loc[ \n    (train_data[\"severe_toxic\"]==0)\n   &(train_data[\"toxic\"]==0)\n   &(train_data[\"obscene\"]==0)\n   &(train_data[\"threat\"]==0)\n   &(train_data[\"insult\"]==0)\n   &(train_data[\"identity_hate\"]==0)\n]","2aa60a78":"pd.set_option('display.max_colwidth', None)\nnormal_comments","c489ee42":"print(\"There are {0} comments which are not toxic in the given categories\".format(len(normal_comments)))","3eab1a44":"print(\"Summation of normal comments and toxic comments exceed the total number of comments we have {0}\".format(len(normal_comments) + sum(comments_count)))","f75583e1":"row_sum = train_data.iloc[:, 2:].sum(axis=1)\nplt.bar(row_sum.value_counts().index, row_sum.value_counts().values)","db83ed78":"df = pd.DataFrame()","ee23a571":"#where three category overlaps \ndf[\"unique\"] = (row_sum==1)\nprint(\"no of comments which lie in unique category\/tagged with unique category\", df.loc[df[\"unique\"]].shape[0])\n\ndf[\"two_cat\"] = (row_sum==2)\nprint(\"no of comments which lie in two category\/tagged with two category\", df.loc[df[\"two_cat\"]].shape[0])\n\ndf[\"three_cat\"] = (row_sum==3)\nprint(\"no of comments which lie in three category\/tagged with three category\", df.loc[df[\"three_cat\"]].shape[0])\n\ndf[\"four_cat\"] = (row_sum==4)\nprint(\"no of comments which lie in four category\/tagged with four category\", df.loc[df[\"four_cat\"]].shape[0])\n\ndf[\"five_cat\"] = (row_sum==5)\nprint(\"no of comments which lie in five category\/tagged with five category\", df.loc[df[\"five_cat\"]].shape[0])\n\ndf[\"six_cat\"] = (row_sum==6)\nprint(\"no of comments which lie in six category\/tagged with six category\", df.loc[df[\"six_cat\"]].shape[0])","1a55c3e9":"del df\ngc.collect()","d1540434":"pd.crosstab(train_data.loc[row_sum==3][\"toxic\"], \n[\n    train_data.loc[row_sum==3][\"threat\"],\n    train_data.loc[row_sum==3][\"severe_toxic\"],\n    train_data.loc[row_sum==3][\"identity_hate\"],\n    train_data.loc[row_sum==3][\"obscene\"], \n    train_data.loc[row_sum==3][\"insult\"],   \n],\n            rownames=[\"toxic\"], \n            colnames=[\"threat\", \"severe_toxic\", \"identity_hate\", \"obscene\", \"insult\"]\n)","4160cef6":"threat_comments = train_data.loc[ (train_data[\"threat\"]==1) ]","4bc0c656":"threat_comments","f3ca6067":"pd.set_option('display.max_colwidth', None)\npd.crosstab(threat_comments[\"threat\"]==1, \n[\n    threat_comments[\"toxic\"]==1,\n    threat_comments[\"severe_toxic\"]==1,\n    threat_comments[\"identity_hate\"]==1,\n    threat_comments[\"obscene\"]==1, \n    threat_comments[\"insult\"]==1,   \n],\n            rownames=[\"threat\"], \n            colnames=[\"toxic\", \"severe_toxic\", \"identity_hate\", \"obscene\", \"insult\"]\n)","7fb3970f":"del threat_comments\ngc.collect()","a1d6b32a":"wc_stopwords=set(STOPWORDS)","c392ed69":"normal_comments[\"comment_text\"].values","57354da6":"normal_mask=np.array(Image.open(\"..\/input\/wordcloud-mask\/flower.png\"))\nwc_normal = WordCloud(max_words=4000, min_font_size=5,\n                      mask=normal_mask, \n                      stopwords=wc_stopwords, background_color=\"black\", \n                      margin=10, random_state=1).generate(\" \".join(normal_comments[\"comment_text\"].values))\nplt.figure(figsize=(12, 15))\nplt.title(\"Word cloud for normal\/clean comments\")\nplt.axis(\"off\")\nplt.imshow(wc_normal, interpolation = 'bilinear')","572d9864":"normal_mask=np.array(Image.open(\"..\/input\/wordcloud-mask\/flower.png\"))\nplt.figure(figsize=(20, 18))\n\nfor i, category in enumerate([\"toxic\", \"severe_toxic\", \"threat\", \"obscene\", \"insult\", \"identity_hate\"]):\n    plt.subplot(3,2,i+1)\n    wc_normal = WordCloud(max_words=4000, min_font_size=5,\n                          mask=normal_mask, \n                          stopwords=wc_stopwords, background_color=\"black\", \n                          margin=10, random_state=1).generate(\" \".join(train_data[train_data[category]==1].comment_text.values))\n    plt.title(\"Word cloud for {0} comments\".format(category).upper(), fontsize=22)\n    plt.axis(\"off\")\n    plt.imshow(wc_normal, interpolation = 'bilinear')","f31bac59":"nlp = en_core_web_sm.load()\nprint(nlp.entity.labels)\nprint(nlp.entity.cfg)","a3be8961":"%%time\n\n#\n#Named entities for  comments\n#list which are in ORG,\n#NORP Nationalities or religious or political group\n#\n\ntexts = train_data[\"comment_text\"].values\norgs = []\n\nfor doc in nlp.pipe(texts, disable=[\"tagger\", \"parser\"]):\n    orgs.extend([ent.text for ent in doc.ents if not ent.text.isspace() and ent.label_==\"ORG\"])","54582be6":"#now list out the most frequent ORG used in the data\nCounter(orgs).most_common(50)","a7f6e208":"#Lemmatize Words\n\n\ndef get_pos_tag(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        # As default pos in lemmatization is Noun\n        return wordnet.NOUN\n\nlemmatizer = WordNetLemmatizer()","f1f40fc4":"APPO = {\n\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"that's\" : \"that is\",\n\"there's\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"\n}","a8eb9cdb":"\nREPLACE_URLS = re.compile(r'http[s]?:\/\/(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+')\nREPLACE_HASH = re.compile(r'#(\\w+)')\nREPLACE_AT = re.compile(r'@(\\w+)')\nREPLACE_HTML_TAGS = re.compile(r'<[^>]+>')\nREPLACE_DIGITS = re.compile(r'\\d+')\nREPLACE_PUNCTUATION = re.compile(r'!\\\"#+$%&\\)*,-.\/:;<=>?@[\\\\]^_`{|}~\\t\\(\\\\n\u201c\u201d\u2019\\'\u221e\u03b8\u00f7\u03b1\u2022\u00e0\u2212\u03b2\u2205\u00b3\u03c0\u2018\u20b9\u00b4\u00b0\u00a3\u20ac\\\u00d7\u2122\u221a\u00b2\u2014')     #[,!@\\'\\\"?\\.$%_&#*+-:;]\")       #[!\\\"#$%&\\'()*+,-\\.\/:;<=>?@[\\\\]^_`{|}~]\")\nLEAKY_FEATURE = re.compile(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\") \n\nSTOPWORDS = set(stopwords.words('english'))\n\nsentences = [] #for Word2Vec model\n\ndef clean_text(text):\n    text = text.lower()\n    text = REPLACE_HTML_TAGS.sub(' ', text)\n    \n    text = re.sub(r'&amp;', '&', text)\n    \n    text = REPLACE_URLS.sub('', text)\n    #text = REPLACE_HASH.sub('', text)\n    text = REPLACE_AT.sub('', text)\n    text = REPLACE_DIGITS.sub('', text)\n    text = REPLACE_PUNCTUATION.sub(' ' , text)\n    text = LEAKY_FEATURE.sub('', text)\n    \n    text = [APPO[word] if word in APPO else word for word in text.split()]\n    \n    text = \" \".join(lemmatizer.lemmatize(word.strip(), get_pos_tag(pos_tag([word.strip()])[0][1])) for word in text if word not in STOPWORDS)\n    \n    #sentences.append(text.split())\n    return text","ab7d0845":"%%time\ntrain_data[\"comment\"] = train_data[\"comment_text\"].apply(clean_text)\n","e5feb958":"#train_data.to_csv(\"clean_jigsaw.csv\")","527ad8c0":"%%time\ntest_data[\"comment\"] = test_data[\"comment_text\"].apply(clean_text)","63a004dd":"df_count = train_data.loc[:, [\"id\", \"comment_text\", \"comment\"]]\ndf_count[\"word_count\"] = df_count[\"comment_text\"].apply(lambda x: len(str(x).split()))\ndf_count[\"sent_count\"] = df_count[\"comment_text\"].apply(lambda x: len(re.findall(\"\\n\", str(x))) +1)\ndf_count[\"unique_words\"] = df_count[\"comment_text\"].apply(lambda x : len(set(str(x).split())))","683d3dd1":"#count in comments after data cleaning\ndf_count[\"word_count_clean\"] = df_count[\"comment\"].apply(lambda x: len(str(x).split()))\n#df_count[\"sent_count_clean\"] = df_count[\"comment\"].apply(lambda x: len(re.findall(\"\\n\", str(x))) +1)\ndf_count[\"unique_words_clean\"] = df_count[\"comment\"].apply(lambda x : len(set(str(x).split())))","a5d0e6b3":"print( \"min and max word count in comment before cleaning >> \", min(df_count[\"word_count\"]), max(df_count[\"word_count\"]) )\nprint( \"min and max unique words in comment before cleaning >> \", min(df_count[\"unique_words\"]), max(df_count[\"unique_words\"]) )\nprint( \"min and max  word count in comment after cleaning >> \", min(df_count[\"word_count_clean\"]), max(df_count[\"word_count_clean\"]) )\nprint( \"min and max  unique word in comment after cleaning >> \", min(df_count[\"unique_words_clean\"]), max(df_count[\"unique_words_clean\"]) )","2999ddaf":"toxic_index = train_data[train_data[\"toxic\"]==1][\"id\"]\nsevere_toxic_index = train_data[train_data[\"severe_toxic\"]==1][\"id\"]\nthreat_index = train_data[train_data[\"threat\"]==1][\"id\"]\nobscene_index = train_data[train_data[\"obscene\"]==1][\"id\"]\ninsult_index = train_data[train_data[\"insult\"]==1][\"id\"]\nidentity_hate_index = train_data[train_data[\"identity_hate\"]==1][\"id\"]","ee1e3af6":"category_list = [\"toxic\", \"severe_toxic\", \"threat\", \"obscene\", \"insult\", \"identity_hate\"]\navg_count = []\navg_unique_count = []\nunique_to_all = []\n\nfor i, category in enumerate([toxic_index, severe_toxic_index, threat_index, obscene_index, insult_index, identity_hate_index]):\n    avg_count.append(df_count[df_count.id.isin(category)][\"word_count\"].mean())\n    avg_unique_count.append(df_count[df_count.id.isin(category)][\"unique_words\"].mean())\n    \navg_count.append(df_count[df_count.id.isin(normal_comments.id)][\"word_count\"].mean())\navg_unique_count.append(df_count[df_count.id.isin(normal_comments.id)][\"unique_words\"].mean())\n\n\nfor i, category in enumerate([toxic_index, severe_toxic_index, threat_index, obscene_index, insult_index, identity_hate_index]):\n    ratio = df_count[df_count.id.isin(category)][\"unique_words\"]\/df_count[df_count.id.isin(category)][\"word_count\"] \n    unique_to_all.append(ratio.mean()*100)\n    \nunique_to_all.append( (df_count[df_count.id.isin(normal_comments.id)][\"unique_words\"]\/df_count[df_count.id.isin(normal_comments.id)][\"word_count\"] ).mean()*100)\n\ncategory_list.append(\"normal\")\n","c0e2c5c9":"x = np.arange(len(category_list))\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(15,6))\ncount_bar = ax.bar(x - width\/2, avg_count, width, label='avg word count')\nunique_count_bar = ax.bar(x + width\/2, avg_unique_count, width, label='avg unique word count')\nax.set_ylabel('Counts')\nax.set_title(\"Avg word count by total and unique\")\nax.set_xticks(x)\nax.set_xticklabels(category_list)\nax.legend()\n\nplt.figure(figsize=(15,6))\nplt.bar(category_list, unique_to_all, width=0.8)\nplt.title(\"% of unique counts\")\nplt.show()\n    ","134da481":"import seaborn as sns\nf, (ax_wc, ax_uwc) = plt.subplots(1,2, figsize=(22,10))\n\nmean_wc = df_count[df_count.id.isin(normal_comments[\"id\"])][\"word_count\"].mean()\nmedian_wc = df_count[df_count.id.isin(normal_comments[\"id\"])][\"word_count\"].median()\nmode_wc = df_count[df_count.id.isin(normal_comments[\"id\"])][\"word_count\"].mode()\n\nsns.distplot(df_count[df_count.id.isin(normal_comments[\"id\"])][\"word_count\"], ax=ax_wc)\nax_wc.axvline(mean_wc, color='r', linestyle='--')\nax_wc.axvline(median_wc, color='g', linestyle='-')\n\nmean_uwc = df_count[df_count.id.isin(normal_comments[\"id\"])][\"unique_words\"].mean()\nmedian_uwc = df_count[df_count.id.isin(normal_comments[\"id\"])][\"unique_words\"].median()\nmode_uwc = df_count[df_count.id.isin(normal_comments[\"id\"])][\"unique_words\"].mode()\n\nsns.distplot(df_count[df_count.id.isin(normal_comments[\"id\"])][\"unique_words\"], ax=ax_uwc)\nax_uwc.axvline(mean_uwc, color='r', linestyle='--')\nax_uwc.axvline(median_uwc, color='g', linestyle='-')\n\nplt.legend({'Mean':mean_wc,'Median':median_wc})\nplt.show()","9d42ab23":"del df_count\ndel toxic_index\ndel severe_toxic_index\ndel threat_index\ndel obscene_index\ndel insult_index\ndel identity_hate_index\ngc.collect()","9800427e":"#input_list = ['all', 'this', 'happened', 'more', 'or', 'less']\n\ndef find_ngrams(input_list, n):\n   return zip(*[input_list[i:] for i in range(n)])","293becec":"train_tags = train_data.loc[:, [\"id\", \"toxic\", \"severe_toxic\", \"threat\", \"obscene\", \"insult\", \"identity_hate\"]]","cebdf301":"train_data.loc[:, [\"id\", \"toxic\", \"severe_toxic\", \"threat\", \"obscene\", \"insult\", \"identity_hate\"]].columns[1:]","d9c56a8f":"train_data.iloc[12235][\"comment_text\"]","9c1551c1":"train_data.iloc[12235][\"comment\"]","f666e66b":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectorizer_bi = TfidfVectorizer(min_df=100,  max_features=80000, \n                                   strip_accents='unicode', analyzer='word',ngram_range=(2,2),\n                                   use_idf=1,smooth_idf=1,sublinear_tf=1,\n                                   stop_words = 'english')\n\ntfidf_vectorizer_bi.fit(pd.concat([train_data[\"comment\"], test_data[\"comment\"] ]))\nfeatures = np.array(tfidf_vectorizer_bi.get_feature_names())\n\ntrain_bigrams =  tfidf_vectorizer_bi.transform(train_data[\"comment\"])\ntest_bigrams = tfidf_vectorizer_bi.transform(test_data[\"comment\"])","915fbfc2":"##https:\/\/buhrmann.github.io\/tfidf-analysis.html\n##https:\/\/www.kaggle.com\/jagangupta\/stop-the-s-toxic-comments-eda#Feature-engineering:\n\ndef top_tfidf_feats(row, features, top_n=25):\n    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n    topn_ids = np.argsort(row)[::-1][:top_n]\n    top_feats = [(features[i], row[i]) for i in topn_ids]\n    df = pd.DataFrame(top_feats)\n    df.columns = ['feature', 'tfidf']\n    return df\n\ndef top_feats_in_doc(Xtr, features, row_id, top_n=25):\n    ''' Top tfidf features in specific document (matrix row) '''\n    row = np.squeeze(Xtr[row_id].toarray())\n    return top_tfidf_feats(row, features, top_n)\n\ndef top_mean_feats(Xtr, features, grp_ids, min_tfidf=0.1, top_n=25):\n    ''' Return the top n features that on average are most important amongst documents in rows\n        indentified by indices in grp_ids. '''\n    \n    D = Xtr[grp_ids].toarray()\n\n    D[D < min_tfidf] = 0\n    tfidf_means = np.mean(D, axis=0)\n    return top_tfidf_feats(tfidf_means, features, top_n)\n\n# modified for multilabel milticlass\ndef top_feats_by_class(Xtr, features, min_tfidf=0.1, top_n=20):\n    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n        calculated across documents with the same class label. '''\n    dfs = []\n    cols=train_tags.columns[1:]\n    for col in cols:\n        ids = train_tags.index[train_tags[col]==1]\n        feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n        feats_df.label = comments\n        dfs.append(feats_df)\n    ids = train_tags.index[train_tags.id.isin(normal_comments.id)]\n    feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n    feats_df.label = \"clean\"\n    dfs.append(feats_df)\n    return dfs","d49d4333":"%%time\ntfidf_top_n_per_lass=top_feats_by_class(train_bigrams,features)","ad37f513":"plt.figure(figsize=(16,22))\nplt.suptitle(\"TF_IDF Top words per class(Bigrams)\",fontsize=20)\ngridspec.GridSpec(4,2)\nplt.subplot2grid((4,2),(0,0))\nsns.barplot(tfidf_top_n_per_lass[0].feature.iloc[0:5],tfidf_top_n_per_lass[0].tfidf.iloc[0:5],color=color[0])\nplt.title(\"class : Toxic\",fontsize=15)\n#plt.xlabel('Word', fontsize=12)\nplt.ylabel('TF-IDF score', fontsize=12)\n\nplt.subplot2grid((4,2),(0,1))\nsns.barplot(tfidf_top_n_per_lass[1].feature.iloc[0:5],tfidf_top_n_per_lass[1].tfidf.iloc[0:5],color=color[1])\nplt.title(\"class : Severe toxic\",fontsize=15)\n#plt.xlabel('Word', fontsize=12)\nplt.ylabel('TF-IDF score', fontsize=12)\n\n\nplt.subplot2grid((4,2),(1,0))\nsns.barplot(tfidf_top_n_per_lass[2].feature.iloc[0:5],tfidf_top_n_per_lass[2].tfidf.iloc[0:5],color=color[2])\nplt.title(\"class : Obscene\",fontsize=15)\n#plt.xlabel('Word', fontsize=12)\nplt.ylabel('TF-IDF score', fontsize=12)\n\n\nplt.subplot2grid((4,2),(1,1))\nsns.barplot(tfidf_top_n_per_lass[3].feature.iloc[0:5],tfidf_top_n_per_lass[3].tfidf.iloc[0:5],color=color[3])\nplt.title(\"class : Threat\",fontsize=15)\n#plt.xlabel('Word', fontsize=12)\nplt.ylabel('TF-IDF score', fontsize=12)\n\n\nplt.subplot2grid((4,2),(2,0))\nsns.barplot(tfidf_top_n_per_lass[4].feature.iloc[0:5],tfidf_top_n_per_lass[4].tfidf.iloc[0:5],color=color[4])\nplt.title(\"class : Insult\",fontsize=15)\n#plt.xlabel('Word', fontsize=12)\nplt.ylabel('TF-IDF score', fontsize=12)\n\n\nplt.subplot2grid((4,2),(2,1))\nsns.barplot(tfidf_top_n_per_lass[5].feature.iloc[0:5],tfidf_top_n_per_lass[5].tfidf.iloc[0:5],color=color[5])\nplt.title(\"class : Identity hate\",fontsize=15)\n#plt.xlabel('Word', fontsize=12)\nplt.ylabel('TF-IDF score', fontsize=12)\n\nplt.subplot2grid((4,2),(3,0),colspan=2)\nsns.barplot(tfidf_top_n_per_lass[6].feature.iloc[0:9],tfidf_top_n_per_lass[6].tfidf.iloc[0:9])\nplt.title(\"class : Clean\",fontsize=15)\n#plt.xlabel('Word', fontsize=12)\nplt.ylabel('TF-IDF score', fontsize=12)\n\nplt.show()","75641998":"del normal_comments\ndel tfidf_vectorizer_bi\ndel train_bigrams\ndel test_bigrams\ngc.collect()","248b25f3":"#over sample the minority class by 10% and under sample the majority class by 50%\n#as the original paper suggest to combine combining SMOTE with randome undersampling of the majority class \ndef apply_SMOTE(X_vec, y_vec):\n    over = SMOTE(sampling_strategy=0.2, random_state=777)#, k_neighbors=1)\n    under = RandomUnderSampler(sampling_strategy=0.5, random_state=777)#, k_neighbors=1)\n    steps = [('o', over), ('u', under)]\n    pipeline = Pipeline(steps=steps)\n    # transform the dataset\n    X_smote, y_smote = pipeline.fit_resample(X_vec, y_vec)\n    return (X_smote, y_smote)","86495d8b":"#all_text = pd.concat([train_data[\"comment\"], test_data[\"comment\"] ])\n\ntfidf_vectorizer = TfidfVectorizer(min_df=100,  max_features=80000, \n                                   strip_accents='unicode', analyzer='word',ngram_range=(1,3),\n                                   use_idf=1,smooth_idf=1,sublinear_tf=1,\n                                   stop_words = 'english')\n\ntfidf_vectorizer.fit(pd.concat([train_data[\"comment\"], test_data[\"comment\"] ]))\nfeatures = np.array(tfidf_vectorizer.get_feature_names())\n\ntrain_tfidf =  tfidf_vectorizer.transform(train_data[\"comment\"])\ntest_tfidf = tfidf_vectorizer.transform(test_data[\"comment\"])","528981ee":"def apply_model(splits, X, y, model, average_method): #average_method='macro'\n    \n    kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=777)\n    accuracy = []\n    precision = []\n    recall = []\n    f1 = []\n    for train, test in kfold.split(X, y):\n        \n        lr_fit = model.fit(X[train], y[train])\n        prediction = model.predict(X[test])\n        scores = model.score(X[test],y[test])\n        \n        accuracy.append(scores * 100)\n        precision.append(precision_score(y[test], prediction, average=average_method)*100)\n        \n        recall.append(recall_score(y[test], prediction, average=average_method)*100)\n        \n        f1.append(f1_score(y[test], prediction, average=average_method)*100)\n    \n    result = {\n        \"accuracy\": [\" %.2f%% (+\/- %.2f%%)\"% (np.mean(accuracy), np.std(accuracy))],\n        \"precision\": [\"%.2f%% (+\/- %.2f%%)\"% (np.mean(precision), np.std(precision))],\n        \"recall\": [\"%.2f%% (+\/- %.2f%%)\" % (np.mean(recall), np.std(recall))],\n        \"f1 score\": [\"%.2f%% (+\/- %.2f%%)\" % (np.mean(f1), np.std(f1))]\n    }\n    \n    return pd.DataFrame(result)","b79f5e79":"#apply SMOTE after cross validation split only \n#what has been seen, can not not be unseen  --> overfitting \n\ndef apply_model_with_smote(splits, X, y, model, average_method): #average_method='macro'\n    \n    kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=777)\n    accuracy = []\n    precision = []\n    recall = []\n    f1 = []\n    for train, test in kfold.split(X, y):\n        \n        X_smote, y_smote = apply_SMOTE(X[train], y[train])\n        \n        lr_fit = model.fit(X_smote, y_smote)\n        prediction = model.predict(X[test])\n        scores = model.score(X[test],y[test])\n        \n        accuracy.append(scores * 100)\n        precision.append(precision_score(y[test], prediction, average=average_method)*100)\n        \n        recall.append(recall_score(y[test], prediction, average=average_method)*100)\n        \n        f1.append(f1_score(y[test], prediction, average=average_method)*100)\n        \n    result = {\n        \"accuracy\": [\" %.2f%% (+\/- %.2f%%)\"% (np.mean(accuracy), np.std(accuracy))],\n        \"precision\": [\"%.2f%% (+\/- %.2f%%)\"% (np.mean(precision), np.std(precision))],\n        \"recall\": [\"%.2f%% (+\/- %.2f%%)\" % (np.mean(recall), np.std(recall))],\n        \"f1 score\": [\"%.2f%% (+\/- %.2f%%)\" % (np.mean(f1), np.std(f1))]\n    }        \n  \n    return pd.DataFrame(result)","64e3b1f5":"lr_model = LogisticRegression(C=0.1, solver='sag')\nprint(\"~~~~~~~~~~~~ Logistic Regression ~~~~~~~~~~~~\")\nfor class_name in category_list[:-1]:\n    y = train_data[class_name]\n    print(\"------RESULT FOR  {0}---------\".format(class_name))\n    model_metrics = apply_model(5, train_tfidf, y, lr_model, 'macro')\n    model_metrics[\"model\"] = [\"Logistic Regression\"]","171fbdd0":"#from sklearn.utils.class_weight import compute_class_weight\n#class_weights = compute_class_weight('balanced', np.unique(y), y)","59c450fb":"lr_model_weights = LogisticRegression(C=0.1, solver='lbfgs', \n                                      class_weight={1:0.8, 0:0.2}\n                                       #class_weight={\"toxic\":2, \"severe_toxic\":8, \"threat\":10, \"obscene\":5, \"insult\":5, \"identity_hate\":8}\n                                      )\nprint(\"~~~~~~~~~~~~ Logistic Regression with weights ~~~~~~~~~~~~\")\nfor class_name in category_list[:-1]:\n    y = train_data[class_name]\n    print(\"------RESULT FOR  {0}---------\".format(class_name))\n    weights_metrics = apply_model(5, train_tfidf, y, lr_model_weights, 'macro')\n    weights_metrics[\"model\"] = [\"LR with weights\"]","a13384c7":"#Cross check this approach i.e. applying SMOTE for every class one by one \nlr_model_smote = LogisticRegression(C=0.1, solver='sag')\nprint(\"~~~~~~~~~~~~ Logistic Regression with SMOTE~~~~~~~~~~~~\")\nfor class_name in category_list[:-1]:\n    y = train_data[class_name]\n    print(\"------RESULT FOR  {0}---------\".format(class_name))\n    smote_metrics = apply_model_with_smote(5, train_tfidf, y, lr_model_smote, 'macro')\n    smote_metrics[\"model\"] = [\"LR with smote\"]","381b783b":"#Comparsion \nlr_metrics = pd.concat([model_metrics, weights_metrics, smote_metrics])\nlr_metrics","272a2020":"del tfidf_vectorizer\ndel train_tfidf\ndel test_tfidf\ngc.collect()","75d776a8":"train_data = pd.read_csv(\"clean_jigsaw.csv\")","2d1303a5":"train_data.info()","4a98ad1c":"max_len = np.max(train_data[\"comment\"].apply(lambda x: len(x)))\nmax_len","a10af1d7":"REMOVE_CHARS = '!\"#$%&()*+,-.\/:;<=>?@[\\\\]^_`{|}~\\t\\n\u201c\u201d\u2019\\'\u221e\u03b8\u00f7\u03b1\u2022\u00e0\u2212\u03b2\u2205\u00b3\u03c0\u2018\u20b9\u00b4\u00b0\u00a3\u20ac\\\u00d7\u2122\u221a\u00b2\u2014'\nmax_features = 100000","cb8538a5":"tokenizer = Tokenizer(filters=REMOVE_CHARS, num_words=100000)\n\ntokenizer.fit_on_texts(list(train_data[\"comment\"].astype(str)))\n\nvocab_size = len(tokenizer.word_index) + 1\nX_tokenized = tokenizer.texts_to_sequences(train_data[\"comment\"].astype(str))\nX_tokenized = pad_sequences(X_tokenized, maxlen=5000, padding='post')","efcc081e":"#pre process test data with param of train data\n#X_test_tokenize = tokenizer.texts_to_sequences(test_data[\"comment\"].values)\n#X_test_tokenize = pad_sequences(X_test_tokenize, maxlen=max_len, padding='post')","e338cb0b":"embeddings_index = {}\nglovefile = open('..\/input\/glove42b300dtxt\/glove.42B.300d.txt','r',encoding='utf-8')\nfor line in tqdm(glovefile):\n    values = line.split(\" \")\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nglovefile.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","4e1b8030":"# create an embedding matrix for the words we have in the dataset\nnum_words = min(max_features, len(tokenizer.word_index) + 1)\nembedding_matrix = np.zeros((num_words, 300))\nfor word, index in tqdm(tokenizer.word_index.items()):\n    try:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[index] = embedding_vector\n    except IndexError:\n        pass","71782b3f":"del embeddings_index\ngc.collect()","9c649e98":"LSTM_UNITS = 128\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS","353ad02c":"y_train = train_data[[\"toxic\", \"severe_toxic\",\"threat\",\"obscene\", \"insult\", \"identity_hate\"]].values","762eda54":"embedding_matrix.shape","6fcb40dd":"X_tokenized.shape, y_train.shape","65de4dc8":"# def build_model(embedding_matrix):\n#     words = Input(shape=(5000,))\n    \n#     x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n#     x = SpatialDropout1D(0.2)(x)\n#     x1 = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n#     x2 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x1)\n    \n#     #avg_pool = GlobalAveragePooling1D()(x)\n#     max_pool1 = GlobalMaxPooling1D()(x1)\n#     max_pool2 = GlobalMaxPooling1D()(x2)\n#     conc = Concatenate()([max_pool1, max_pool2])\n    \n# #     hidden = add([conc, Dense(DENSE_HIDDEN_UNITS, activation='relu')(conc)])\n# #     hidden = Dropout(0.2)(hidden)\n# #     hidden = add([conc, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n    \n#     result = Dense(6, activation='softmax')(conc)\n    \n#     model = Model(inputs=words, outputs=result)\n#     model.compile(loss='binary_crossentropy', optimizer='adam')\n    \n#     return model\n\n\n","205bca79":"def build_model(embedding_matrix):\n    inp = Input(shape=(max_len,))\n    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix])(inp)\n    x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n    x = GlobalMaxPool1D()(x)\n    x = Dense(50, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","2be55736":"model_lstm = build_model(embedding_matrix)\nmodel_lstm.summary()","06d97498":"epochs = 100\nbatch_size = 512","1683d91f":"#  \"toxic\":train_data.toxic,\n#  \"severe_toxic\":train_data.severe_toxic,\n#  \"threat\":train_data.threat,\n#  \"obscene\":train_data.obscene,\n#  \"insult\":train_data.insult,\n#  \"identity_hate\":train_data.identity_hate\n    ","5f17e457":"history_lstm = model_lstm.fit(\n    X_tokenized, \n    y_train,\n    validation_split=0.2,\n    epochs=3,\n    batch_size=512,\n    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])","99522a98":"del model_lstm\n#del history_lstm\ngc.collect()","de8d83bc":"del embedding_matrix\ndel tokenizer\ndel X_tokenized\n#del X_test_tokenize\ngc.collect()","6e4bdec8":"#https:\/\/www.kaggle.com\/user123454321\/bert-starter-inference\n#https:\/\/tfhub.dev\/s?q=bert\n\n","a9691950":"#Get the tokenization script from the officical repo\n!wget --quiet https:\/\/raw.githubusercontent.com\/tensorflow\/models\/master\/official\/nlp\/bert\/tokenization.py\n    \nimport tokenization","63436253":"def bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","bb4a1644":"def build_model(bert_layer, max_len=512):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n    \n    inputs = {\"word_ids\":input_word_ids, \"mask\":input_mask, \"segment_ids\":segment_ids}\n\n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    clf_output = sequence_output[:, 0, :]\n    \n    toxic = Dense(1, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='toxic')(clf_output)\n    severe_toxic = Dense(1, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='severe_toxic')(clf_output)\n    threat = Dense(1, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='threat')(clf_output)\n    obscene = Dense(1, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='obscene')(clf_output)\n    insult = Dense(1, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='insult')(clf_output)\n    identity_hate = Dense(1, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='identity_hate')(clf_output)\n    \n    out = {\"toxic\":toxic, \"severe_toxic\":severe_toxic, \"threat\":threat, \"obscene\":obscene, \"insult\":insult, \"identity_hate\":identity_hate}\n    \n    #model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[toxic, severe_toxic, threat, obscene, insult, identity_hate])\n    model = Model(inputs=inputs, outputs=out, name=\"Toxic_BERT_model\")\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","d7bdfec0":"%%time\n#Load BERT from TF\n\nmodule_url = \"https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-24_H-1024_A-16\/1\"\nbert_layer = hub.KerasLayer(module_url, trainable=True)\n\n","4efc8d95":"#load tokenizer from BERT layer\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","b321fdfc":"#encode text into token, mask and segments \ntrain_input = bert_encode(train_data.comment.values, tokenizer, max_len=160)\ntest_input = bert_encode(test_data.comment.values, tokenizer, max_len=160)\n\n#train_labels = train_data.toxic.values","8876a2bc":"model = build_model(bert_layer, max_len=160)\nmodel.summary()","2a1de96c":"checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n\n# train_history = model.fit(\n#     train_input, train_labels,\n#     validation_split=0.2,\n#     epochs=3,\n#     callbacks=[checkpoint],\n#     batch_size=16\n# )\n\n# train_history = model.fit(\n#     x = train_input,\n#      y = {\n#          \"toxic\":train_data[toxic],\n#          \"severe_toxic\":train_data[severe_toxic],\n#          \"threat\":train_data[threat],\n#          \"obscene\":train_data[obscene],\n#          \"insult\":train_data[insult],\n#          \"identity_hate\":train_data[identity_hate]\n#      }\n#     validation_split=0.2,\n#     epochs=3,\n#     callbacks=[checkpoint],\n#     batch_size=16\n# )","0e38d912":"# model.load_weights('model.h5')\n# test_pred = model.predict(test_input)","19a602ed":"<a id=\"word_cloud\"><\/a>\n# Word Cloud","21c8d601":"Word Count per category ","a39b7622":"**** Hi, Thank you for visiting this notebook. If you like any part of this notebook, please upvote :)* ","a9ef35c0":"<a id=eda ><\/a>\n# EDA","43671e6d":"<a id=\"lstm\" ><\/a>\n# LSTM","4a75d64a":"Check which category has most of comments and which has least,\nbasically check category counts","c431b5d3":"* > Tokenize the data\n* > Text to sequence \n* > padding --> all seq have same shape\n* > build embedding matrix\n* > build model with CuDNNLSTM\n\n","b2097d5d":"Now let's check which of the category overlaps most\nOne thing is that a comment which lie in severe toxic category should belong to toxic also. ","92c2c8d1":"Most of the threat comments have (insult, obsence, toxic) category tagged. \nThere are also 22 comments which are only tagged as threat.","7eb7b414":"* Tfidf --> Logistic Regresion\n* Tfidf --> SMOTE --> Logistic Regresion\n* Tfidf --> Weights --> Logistic Regresion","7871e6c0":"Now Let's check for those alerts which have lie in mutiple category","bfe2ebaf":"<a id=n-gram><\/a>\n# N-gram Analysis","c50dbdbe":"* It comes out that dataset is imbalanced. Most of the comments are in toxic category and threat, identity_hate and severe_toxic has less.\n* One thing is that comment which is in severe_toxic will be in toxic category too. ","198129d9":"Let's see where none of the (toxic, severe toxic, obsence, threat, insult, identity_hate) exists for the given tweet. Basically see how many comments are clean from toxic\/hate and all.","280c85e3":"* Not able to fit the above model due to memory constraint here. \n* * \"Your notebook tried to allocate more memory than is available. It has restarted\"","2e945f8c":"<a id=\"lr_model\"><\/a>\n# Logistic Regression","efda2759":"Now let's load train and test data to start with EDA and all.","dbce54ed":"There are normal_comments 143346 and sumamtion of toxic comments is 35098; which means that there are some toxic comments which may lie in mutiple category.","4879214c":"how the Average count and average unique count of each category (\"toxic\", \"severe_toxic\", \"threat\", \"obscene\", \"insult\", \"identity_hate\", \"normal\") AND unique count percentage. ","c8874364":"<a id=\"bert\"> <\/a>\n# BERT ","0a3620a0":"Let's explore the comments which belong only to the threat category ","a0ad4fca":"word_count is spread till 1200 while unique_count is limited to 800","e1566ee1":"* Highest number of comments which are tagged in three category belongs to group (Obscene, insult, toxic)\n* Lowest number of comments which are tagged in three category belongs to group (Threat, obscene, insult","ade12347":"Most of the gap is in severe_toxic category ","f0ef907a":"**Note:**\n> you can use the techniques to calculate the weights using GridSerachCV and \n> compute_class_weight from sklearn.utils.class_weight ","0b9a6b27":"Check if there is any null values or not","c97d1f83":"> Precision = true positive\/predicted positive --> TP\/(TP+FP) --> measure of relevant data points\n> Recall = true positive\/ actual positive --> TP\/(TP+FN) --> how accuractely the model identify the relevant data\n\nFrom the above compariosnof f1 score it is visible that aftetreating the data imbalance the model performed well ","81e35486":"<a id=\"word_count\"> <\/a>\n# Word Count Analysis","ea73d979":"<a id=\"data_clean\"><\/a>\n# Data Cleaning","b11cf2bf":"<a id=\"smote\"><\/a>\n> SMOTE --> Synthetic Minority Oversampling Technique","8ed025db":"Now let's clean tthe data in train and test dataset","2a49fde2":"Check the distribution of comments with word_count and unique words ","7ce00982":"There are no such no null values :)"}}