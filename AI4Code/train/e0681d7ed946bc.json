{"cell_type":{"2a0ad782":"code","5196cb2b":"code","f89c1b78":"code","fa708643":"code","10b699de":"code","a0826c67":"code","5e6e09d6":"code","c80fa76d":"code","85f7f86a":"code","10a4d93a":"code","90faf786":"code","c9df7529":"code","f8a5dead":"code","42bf11c4":"code","dda76cc1":"code","41d4ac57":"code","3c5d612f":"code","35704a70":"code","7f911d55":"code","54ade462":"code","b12b81d9":"code","7c79e2c6":"code","6c6b94ba":"code","070a913b":"code","0d81c77f":"code","bfd32f85":"code","2e5876e1":"code","4ce32c5a":"code","fa1c016f":"code","cafdf76f":"code","6884e32c":"code","10986650":"code","e8f1da77":"code","fe401eb3":"code","ae593158":"code","73c211b9":"code","1fe949c6":"code","c5f7f4c9":"code","aa5cee4f":"code","41280720":"code","7c83da78":"code","83502df2":"code","59f04542":"code","5a8978c7":"code","0847a690":"code","2588aa01":"code","18d170a9":"code","a22c4f13":"code","e6c43a7a":"code","187df954":"code","4fc192b1":"code","58db27ae":"code","b8841159":"code","0c60649e":"code","81a7c4df":"code","1aa29a89":"code","f742d91c":"code","41b874a0":"markdown","b2399a4c":"markdown","cbc8bbdb":"markdown","80f9fb6d":"markdown","6f17c801":"markdown","9072f1a4":"markdown","9cb2c10d":"markdown","414a6ba1":"markdown","459967d0":"markdown","7b8a0132":"markdown","ceac6067":"markdown","e5e1d489":"markdown","c9678649":"markdown","d3f978ef":"markdown","b88951cd":"markdown","ef514a36":"markdown","e9b4d37f":"markdown"},"source":{"2a0ad782":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5196cb2b":"## Import library\nimport numpy as np\nfrom numpy import mean\nimport pandas as pd\n##from pandas_profiling import ProfileReport\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n%matplotlib inline\nfrom operator import itemgetter\nimport ast\nfrom ast import literal_eval\n\n## Plotly Packages\nfrom plotly import tools\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)","f89c1b78":"all_trails= pd.read_csv('..\/input\/national-park-trails\/AllTrails data - nationalpark.csv')\nall_trails.head()","fa708643":"all_trails.info()","10b699de":"#Split _geoloc to two columns 1) latitude and longtitude\n## Create two new columns\nall_trails[['lat','lng']] = all_trails['_geoloc'].apply(lambda x: pd.Series(str(x).split(\",\")))\nall_trails['lat'] = all_trails['lat'].apply(lambda x: (x.split(':')[1].split()[-1])).astype(float)\nall_trails['lng'] = all_trails['lng'].apply(lambda x: (x.split(':')[1].split()[-1][:-1])).astype(float)","a0826c67":"#Calcuate numbers of features and actitivies based on feature and activities feature\n## Create two new columns with calculation \nall_trails['features_count'] = all_trails['features'].apply(lambda x: len(x.split(',')))\nall_trails['activities_count'] = all_trails['activities'].apply(lambda x: len(x.split(',')))","5e6e09d6":"#Create difficulty_rating definition\ndef definition(difficulty_rate):\n    '''To clarify trail's difficulty rating \n    >>>Input: -> Output\n    1 -> easy\n    3-> moderate\n    5 -> hard\n    7 -> hard\n    '''\n    if difficulty_rate == 1:\n        return 'easy'\n    elif difficulty_rate == 3:\n        return 'moderate'\n    elif difficulty_rate == 5:\n        return 'hard'\n    else:\n        return 'hard'","c80fa76d":"#New column of difficulty rating definition\nall_trails['difficulty'] = all_trails.apply(lambda x: definition(difficulty_rate = x['difficulty_rating']), axis = 1)","85f7f86a":"#Correct data\nall_trails['country_name'] = all_trails['country_name'].apply(lambda x: x.replace(\"Hawaii\", \"United States\"))\nall_trails['state_name'] = all_trails['state_name'].apply(lambda x: x.replace(\"Maui\", \"Hawaii\"))","10a4d93a":"#Convert meters to inches for trails in Hawaii\ndef convert (units, length):\n    \"\"\" Convert meters to inches\n        Input: 1 meter\n        Output: 39.3701 inches\n    \"\"\"\n    if units == 'm':\n        return length * 39.3701\n    else:\n        return length","90faf786":"#Create new length column\nall_trails['length_inches'] = all_trails.apply(lambda x: convert(units = x['units'], length = x['length']), axis = 1)\n#drop original length column\nall_trails.drop(['length'], axis = 1, inplace = True)","c9df7529":"all_trails.head()","f8a5dead":"#replace null value as zero\nall_trails.fillna({'visitor_usage':0}, inplace=True)","42bf11c4":"#remove geoloc variables\nall_trails.drop(['_geoloc'],axis = 1, inplace = True)\n\n#Review and check the dataset\nall_trails.isnull().sum()","dda76cc1":"#Summarize each attribution \nall_trails.describe().T","41d4ac57":"#creating plots on dataset\n# Each attribution Histagram \nall_trails.hist(bins=20,figsize=(20,15))\nplt.show()","3c5d612f":"#Skewness - measure of symmetry\/assymetry of distribution. \n## If the distribution is perfectly symmetrical, the value of skewness is equal to 0. \n## If skewness > 0 : positive, if skewness < 0 : negative\nprint('Skewness: {}'.format(all_trails['popularity'].skew()))\n\n#Kurtosis - measure of flattening distribution of a feature.\nprint('Kurtosis: {}'.format(all_trails['popularity'].kurt()))","35704a70":"#Heamp map on correlation - check all the variables linearly related\ncorr = all_trails.corr().round(2)\nsns.set(rc={\"figure.figsize\":(12,8)})\nheatmap = sns.heatmap(corr, annot = True, vmin=-1, vmax=1, center= 0, cmap=sns.diverging_palette(20, 220, n=200),linewidths=.5)\nplt.show()","7f911d55":"# States count\nall_trails['state_name'].unique()\n\n#Total summary of trails by state\nTotal_count = all_trails[['trail_id','state_name','route_type']].groupby(['state_name', 'route_type']).count().reset_index()\nTotal_count","54ade462":"#Bar Chart of total summary of trails by state\nfig_sumtrails_group= px.bar(Total_count, x= 'state_name', y='trail_id', text= 'trail_id', color = 'route_type', title = 'Total Trails count by States')\nfig_sumtrails_group.show()","b12b81d9":"#Boxplot for trails count by state\nfig_boxplot_avaiableday = px.box(all_trails, x='state_name', y='popularity', color = 'state_name')\nfig_boxplot_avaiableday.update_traces(quartilemethod=\"linear\") \nfig_boxplot_avaiableday.show()","7c79e2c6":"#All trails by Geography\nfig = go.Figure(data=go.Scattergeo(\n        lon = all_trails['lng'],\n        lat = all_trails['lat'],\n        text = all_trails['state_name'],\n        mode = 'markers',\n        marker = dict(\n            size = 8,\n            opacity = 0.8,\n            reversescale = True,\n            autocolorscale = False,\n            symbol = 'square',\n            line = dict(\n                width=1,\n                color='rgba(102, 102, 102)'\n            ),\n            colorscale = 'Blues',\n            cmin = 0,\n            color = all_trails['trail_id']\n        )))\n\nfig.update_layout(\n        title = 'Tails of NP in the US',\n        geo = dict(\n            scope='usa',\n            projection_type='albers usa',\n            showland = True,\n            landcolor = \"rgb(250, 250, 250)\",\n            subunitcolor = \"rgb(217, 217, 217)\",\n            countrycolor = \"rgb(217, 217, 217)\",\n            countrywidth = 0.5,\n            subunitwidth = 0.5\n        ),\n    )\nfig.show()","6c6b94ba":"#Top N function\ndef top(df, n, column):\n    \"\"\" return top N  records\"\"\"\n    return df.sort_values(by=column)[-n:]","070a913b":"#New data frame\nNO_reviews = all_trails[['area_name','name','route_type','num_reviews','popularity']]\n# Top 10 Number of Reviews of National Parks and trails\nTop_10_NP = top(NO_reviews, n=10, column = 'num_reviews').sort_values(by = 'num_reviews', ascending=True)\nTop_10_NP","0d81c77f":"#Top Trials by number of reviews\nfig = px.bar(Top_10_NP, x=\"name\", y=\"num_reviews\", text = 'num_reviews',color=\"route_type\",title=\"Top 10 Trails in National Parks by Number of Reviews\",\n            labels={\n                     \"name\": \"Trail Name\",\n                     \"num_reviews\": \"Number of Reviews\",\n                     \"route_type\": \"Route Type\"\n                 },)\nfig.update_layout(xaxis={'categoryorder':'total descending'})\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.show()","bfd32f85":"# Top 10 Popular National Parks by number of trails\navg_pop_df = all_trails[['area_name','name','route_type','popularity']].groupby(['area_name']).agg({'popularity':'mean','name':'count'}).reset_index()\navg_pop_df.rename(columns = {'name': 'Total Number of trails'}, \n          inplace=True)\nTop_10_pop = top(avg_pop_df, n=10, column = 'popularity').sort_values(by = 'popularity', ascending=False)\nTop_10_pop","2e5876e1":"#Bar Chart of Top 10 National Parks\nTop_NPs_pop= go.Figure(\n    data=[\n    go.Bar(name='popularity', x=Top_10_pop['area_name'], y=Top_10_pop['popularity'], yaxis='y', offsetgroup=1),\n    go.Bar(name='Total Number of trails', x=Top_10_pop['area_name'], y=Top_10_pop['Total Number of trails'], yaxis='y2', offsetgroup=2)\n    ],\nlayout={'xaxis': {'title': ' National Parks'},\n        'yaxis': {'title': 'Average of popularity'},\n        'yaxis2': {'title': 'Total number of trails', 'overlaying': 'y', 'side': 'right'}\n})\n\nTop_NPs_pop.update_layout(barmode='group', title = \"Top 10 Popular National Parks by number of trails\")\nTop_NPs_pop.show()","4ce32c5a":"#Top 10 Activities for all the trails\nmega_act_list = []\n\nfor index, row in all_trails.iterrows():\n    for item in ast.literal_eval(row['activities']):\n        mega_act_list.append(item)\n        \n#print(mega_act_list)\nmega_act_df = pd.DataFrame(mega_act_list, columns = [\"activity\"])\n#print(mega_act_df)\n\nact_count = mega_act_df.groupby(\"activity\")[\"activity\"].agg(Total = 'count')","fa1c016f":"#Top 10 Activities of trails\nTop_10_activities = top(act_count, n=10, column = 'Total').sort_values(by = 'Total', ascending=False)\nTop_10_activities","cafdf76f":"#Top 10 feeatures for all the trails\n#Features of trails Calulation \nmega_feat_list = []\n\nfor index, row in all_trails.iterrows():\n    for item in ast.literal_eval(row['features']):\n        mega_feat_list.append(item)\n\nmega_feat_df = pd.DataFrame(mega_feat_list, columns = [\"features\"])\n#print(mega_act_df)\n\nfeat_count = mega_feat_df.groupby(\"features\")[\"features\"].agg(Total = 'count')","6884e32c":"#Top 10 Features for trails\nTop_10_features = top(feat_count, n=10, column = 'Total').sort_values(by = 'Total', ascending=False)\nTop_10_features","10986650":"### import Model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score #Cross valication\nfrom sklearn.preprocessing import StandardScaler #standard dataset\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression #muLtilnear Regression\nfrom sklearn.linear_model import Lasso #Lasso Regression\nfrom sklearn.linear_model import Ridge #Ridge Regression\nfrom sklearn.ensemble import RandomForestRegressor #Random Forest\nfrom sklearn.svm import SVR #Support Vector Machine\nfrom sklearn.metrics import r2_score #R_square\nfrom sklearn.metrics import mean_absolute_error #MAE\nfrom sklearn.metrics import mean_squared_error #MSE\nfrom sklearn.model_selection import GridSearchCV #Find best premeters and cross validation ","e8f1da77":"df = all_trails.drop(['trail_id','city_name','country_name','features','activities','lat','lng','units','difficulty','visitor_usage'], axis=1)\ndf.info()","fe401eb3":"s = df.pop('popularity')\nnew_df = pd.concat([df, s],1)\ndataset = pd.DataFrame(data=new_df)\ndataset.head()","ae593158":"sns.pairplot(dataset,x_vars=['length_inches','elevation_gain','difficulty_rating','avg_rating','num_reviews','features_count','activities_count'], y_vars='popularity')","73c211b9":"#Encode the input Variables\ndef Encode(data):\n    for column in dataset.columns[dataset.columns.isin(['name', 'area_name','state_name','route_type'])]:\n        dataset[column] = dataset[column].factorize()[0]\n    return dataset\n\ndataset_en = Encode(dataset.copy())","1fe949c6":"#prepare the dataset for training\n## set input and output dataset\nX = dataset_en.iloc[:,:-1].values\ny = dataset_en.iloc[:,-1].values","c5f7f4c9":"#split the dataset (80% train;20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state = 0)\nprint(X_train.shape, y_test.shape)","aa5cee4f":"#Cross Validation Function\ndef cross_val(model):\n    pred = cross_val_score(model, X, y, cv=10)\n    return pred.mean()\n\ndef print_evaluate(true, predicted):  \n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)\n    \ndef evaluate(true, predicted):\n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    return mae, mse, rmse, r2_square","41280720":"pipeline = Pipeline([\n    ('std_scalar', StandardScaler())\n])\n\nX_train = pipeline.fit_transform(X_train)\nX_test = pipeline.transform(X_test)","7c83da78":"#Create linear regression model\nlin_reg = LinearRegression()\n#Train\/fit lm on the training data\nlin_reg.fit(X_train,y_train)\n#The coefficients of the model\nlin_reg.intercept_, lin_reg.coef_, \n#Predicting Test Data\npred = lin_reg.predict(X_test)\nplt.scatter(y_test, pred)\ntest_pred = lin_reg.predict(X_test)\ntrain_pred = lin_reg.predict(X_train)","83502df2":"#Train set evaluation\nprint_evaluate(y_train, train_pred)","59f04542":"#Test set evaluation\nprint_evaluate(y_test, test_pred)","5a8978c7":"results_CV = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_CV","0847a690":"#Create Ridge model\nmodel =Ridge(alpha=.5,random_state=0)\nmodel.fit(X_train, y_train)\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)","2588aa01":"#Train set evaluation\nprint_evaluate(y_train, train_pred)","18d170a9":"#Test set evaluation\nprint_evaluate(y_test, test_pred)","a22c4f13":"results_CV2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_CV = results_CV.append(results_CV2, ignore_index=True)\nresults_CV","e6c43a7a":"#Create Lasso model\nmodel = Lasso(alpha=0.1,random_state=0)\nmodel.fit(X_train, y_train)\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)","187df954":"#Train set evaluation\nprint_evaluate(y_train, train_pred)","4fc192b1":"#Test set evaluation\nprint_evaluate(y_test, test_pred)","58db27ae":"results_CV3 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_CV = results_CV.append(results_CV3, ignore_index=True)\nresults_CV","b8841159":"#Random Forest\n##Define model\nrf_reg = RandomForestRegressor(random_state=0)","0c60649e":"# Using GridSearch to find the best parameters\ngrid_value = {\n              \"max_depth\": [3,4,5,6,7,8],\n              \"min_samples_leaf\": [2, 4, 6],\n              \"n_estimators\" :[100],\n              \"ccp_alpha\":[0.0,0.5,1.0]}\n\nrnd_cv =  GridSearchCV (rf_reg, grid_value, cv=10, scoring='accuracy', n_jobs=2)\n","81a7c4df":"##Fit model\nrnd_cv.fit(X_train, y_train)\n\nprint(\"best parameters) \",rnd_cv.best_params_)\nprint(rnd_cv.best_estimator_)","1aa29a89":"svm_reg = SVR()\n\n# Using GridSearch to find the best parameters\n#rbf: Radial basis function\ntuned_parameters = [{'kernel': ['rbf','linear','sigmoid','poly'],'degree':[1,2,3],'epsilon':[0.1,0.2,0.3],\n                     'C': [1.0,1.5,2.0]}]\nsvm_cv = GridSearchCV(SVR(), tuned_parameters, cv=10, scoring='precision')\n##Fit model\nsvm_cv.fit(X_train, y_train)\nprint(\"best parameters) \", svm_cv.best_params_)\nprint(svm_cv.best_estimator_)","f742d91c":"results_CV.set_index('Model', inplace=True)\nresults_CV['R2 Square'].plot(kind='barh', figsize=(12, 8))","41b874a0":"1) Number of Trails in the National Parks by States","b2399a4c":"**DATA MODELING**","cbc8bbdb":"**EXPLORATORY DATA ANALYSIS (EDA)**","80f9fb6d":"2) Top 10 trails in National Parks by number of reviews and \n3) Top 10 populiar trails in National Parks by number of trails","6f17c801":"**I find that the number of reviews, average rating, and features count is positively correlated to popularity from the correlation heat map.**","9072f1a4":"**Lasso Regression**","9cb2c10d":"**Models Comparion and Conclusion**","414a6ba1":"**DATA CLEANING**","459967d0":"**LINEAR REGRESSION**","7b8a0132":"**DATA PROFILING**","ceac6067":"**Support Vector Machine**","e5e1d489":"**From this list, I found lots of trails in the National Parks do not allow tourists to bring dogs**","c9678649":"**Random Forest**","d3f978ef":"**Ridge Regression**","b88951cd":"![](https:\/\/farm6.staticflickr.com\/5516\/14549322414_74b3a76a63.jpg)\n\n**--- Business Problem ---**\n1. Which trails have highest number of reviews on the All_trials website\n2. Which state have the most popular trails\n3. Most popular trails by number of reviews \n4. Most popular trails by number of trails\n\n**--- Data Profiling ---** \n\n**--- Data Cleaning ---** \n\n**-- Exploratory Data Analysis (EDA) ---**\n\n**--- Modeling ---**","ef514a36":"*Based on my research, I didn't find the metedata of visitor usage, I would suspect that this might be the old features. Since the data set was extracted from All-Trials API, it might not be maintained anymore. Thus, so many trails have null value. In addition, this feature is not important enought that I would replace null value as zero.*","e9b4d37f":"**Hiking, Nature-trips, and birding are frequently show on the trails' activity**"}}