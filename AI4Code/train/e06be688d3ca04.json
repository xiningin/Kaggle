{"cell_type":{"baff63cf":"code","56c62cbe":"code","b7400bc6":"code","4c2a3f7f":"code","cd9e2060":"code","b3302a72":"code","53707f83":"code","3287a4db":"code","5bcb3967":"code","88c4b825":"code","9b10ec97":"code","53569e91":"code","63911ded":"code","b317f22f":"code","15033b62":"code","1c110c24":"code","e3693a0b":"code","36845343":"code","e4f0acdc":"code","3102c2e3":"code","264d7745":"code","1100b7ec":"code","58fa55bf":"markdown","d4f8eca4":"markdown","0b354761":"markdown","3b58468c":"markdown","0893e853":"markdown"},"source":{"baff63cf":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nfrom tqdm import tqdm\n!pip install tqdm\nimport csv\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dropout, Dense, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization","56c62cbe":"train_dir= '..\/input\/plant-pathology-2021-fgvc8\/train_images'\ntest_dir =  '..\/input\/plant-pathology-2021-fgvc8\/test_images'\ntrain = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')\ntrain.head","b7400bc6":"train = pd.DataFrame(train,columns = ['image','labels'])\ntrain['labels'].value_counts()","4c2a3f7f":"train['labels'] = train['labels'].apply(lambda s: s.split(' '))\ntrain[:10]","cd9e2060":"# Use the Image Data Generator to import the images from the dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rescale = 1\/255.,\n    rotation_range = 10,#Performing Rotation\n    zoom_range = 0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split= 0.2)\n\n\n","b3302a72":"HEIGHT = 384\nWIDTH=384\nSEED = 98\nBATCH_SIZE=64\n","53707f83":"train_ds = datagen.flow_from_dataframe(\n    train,\n    directory = '..\/input\/resized-plant2021\/img_sz_384',# We are using the resized images otherwise it will take a lot of time to train \n    x_col = 'image',\n    y_col = 'labels',\n    subset=\"training\",\n    color_mode=\"rgb\",\n    target_size = (HEIGHT,WIDTH),\n    class_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=SEED,\n)\n\n\nval_ds = datagen.flow_from_dataframe(\n    train,\n    directory = '..\/input\/resized-plant2021\/img_sz_384',# We are using the resized images otherwise it will take a lot of time to train \n    x_col = 'image',\n    y_col = 'labels',\n    subset=\"validation\",\n    color_mode=\"rgb\",\n    target_size = (HEIGHT,WIDTH),\n    class_mode=\"categorical\",\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=SEED,\n)","3287a4db":"example = next(train_ds)\nprint(example[0].shape)\nplt.imshow(example[0][0,:,:,:])\nplt.show()","5bcb3967":"model=Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu', input_shape=(HEIGHT, WIDTH,3)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(BatchNormalization(axis=1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(6))\nmodel.add(Activation(\"softmax\"))\n\nmodel.summary()","88c4b825":"# Compile the Model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, decay=0.01\/30),\n    loss='binary_crossentropy',\n    metrics=['accuracy'])\n","9b10ec97":"checkpoint=ModelCheckpoint(r'Models\\model-x.h5',\n                          monitor='val_loss',\n                          mode='min',\n                          save_best_only=True,\n                          verbose=1)\ncallbacks=[checkpoint]","53569e91":"cnn_model=model.fit(train_ds,\n                    validation_data=val_ds,\n                    epochs=25,\n                    shuffle=True,\n                    verbose=1,\n                    batch_size=BATCH_SIZE,\n#                     steps_per_epoch=train_ds.samples\/\/64,\n#                     validation_steps=val_ds.samples\/\/64,\n                    callbacks=callbacks)","63911ded":"# cnn_model.save('model-cnn.h5')\nmodel.save('model.h5')","b317f22f":"model_history = cnn_model.history\n\nplt.figure()\nplt.plot(model_history['accuracy'])\nplt.plot(model_history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'])\nplt.savefig('accuracy')\nplt.show()","15033b62":"plt.figure()\nplt.plot(model_history['loss'])\nplt.plot(model_history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'])\nplt.savefig('loss')\nplt.show()","1c110c24":"submission = pd.read_csv('\/kaggle\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')\nsubmission.head()","e3693a0b":"test_datagen = ImageDataGenerator(\n    rescale = 1.\/255\n)\nINPUT_SIZE = (HEIGHT,WIDTH,3)\ntest_generator =  test_datagen.flow_from_dataframe(\n    submission,\n    directory=\"..\/input\/plant-pathology-2021-fgvc8\/test_images\",\n    x_col='image',\n    y_col=None,\n    class_mode=None,\n    target_size=INPUT_SIZE[:2]\n)","36845343":"preds = model.predict(test_generator)\nprint(preds)","e4f0acdc":"preds = preds.tolist()\nindices = []\nfor pred in preds:\n    temp = []\n    for category in pred:\n        if category>=0.23:\n            temp.append(pred.index(category))\n    if temp!=[]:\n        indices.append(temp)\n    else:\n        temp.append(np.argmax(pred))\n        indices.append(temp)\n    \nprint(indices)","3102c2e3":"labels = (train_ds.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nprint(labels)\ntestlabels = []\nfor image in indices:\n    temp = []\n    for i in image:\n        temp.append(str(labels[i]))\n    testlabels.append(' '.join(temp))\nprint(testlabels)","264d7745":"submission['labels'] = testlabels\nsubmission.head()","1100b7ec":"submission.to_csv('submission.csv', index=False)","58fa55bf":"# **Resources**\n\nDetails and background information on the dataset and Kaggle competition \u2018Plant Pathology 2020 Challenge\u2019 were published as a peer-reviewed research article. If you use the dataset for your project, please cite the following\n\nhttps:\/\/bsapubs.onlinelibrary.wiley.com\/doi\/10.1002\/aps3.11390","d4f8eca4":"# **Objectives**\n\nThe main objective of the competition is to develop machine learning-based models to accurately classify a given leaf image from the test dataset to a particular disease category, and to identify an individual disease from multiple disease symptoms on a single leaf image.","0b354761":"# Submission Format\nFor every author in the dataset, submission files should contain two columns: image and labels. labels should be a space-delimited list.\n\nThe file should contain a header and have the following format:\n\n* image, labels\n* 85f8cb619c66b863.jpg,healthy\n* ad8770db05586b59.jpg,healthy\n* c7b03e718489f3ca.jpg,healthy","3b58468c":"### Reading data","0893e853":"### Prerequisites"}}