{"cell_type":{"4812b645":"code","4330dc3e":"code","63f3de73":"code","dca272cb":"code","5f57f055":"code","ab63ac55":"code","6b825451":"code","90602598":"code","da794cc0":"code","d65699fa":"code","979e22a2":"code","a082c2d0":"code","1ba422c1":"code","a6f77968":"code","df510069":"code","87e0a856":"code","4a7ec7b2":"code","3a44533d":"code","776974d9":"code","9ba49272":"code","746769ac":"code","0e412aa0":"markdown","647602e1":"markdown","9b49c81d":"markdown","957bd825":"markdown","53c9f6d3":"markdown","3575ce4b":"markdown","71605aed":"markdown","c0e1790f":"markdown","a582d08e":"markdown","ee93779b":"markdown","0ca6ccda":"markdown"},"source":{"4812b645":"import pandas as pd \nimport numpy as np\n","4330dc3e":"train = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\n\ntest = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')","63f3de73":"test['is_train'] = 0\ntrain['is_train'] = 1","dca272cb":"train.drop(['id'], axis = 1, inplace = True)\ntest.drop(['id'], axis = 1, inplace = True)","5f57f055":"df_combine = pd.concat([train, test], axis=0, ignore_index=True)\n#dropping \u2018target\u2019 column as it is not present in the test\ndf_combine = df_combine.drop('target', axis =1)\ny = df_combine['is_train'].values #labels\nx = df_combine.drop('is_train', axis=1).values #covariates or our independent variables\ntst, trn = test.values, train.values","ab63ac55":"from sklearn.ensemble import RandomForestClassifier\n\nm = RandomForestClassifier(n_jobs=-1, max_depth=5, min_samples_leaf = 5)\npredictions = np.zeros(y.shape)","6b825451":"from sklearn.model_selection import StratifiedKFold as SKF\nskf = SKF(n_splits=20, shuffle=True, random_state=100)\nfor fold, (train_idx, test_idx) in enumerate(skf.split(x, y)):\n    X_train, X_test = x[train_idx], x[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n    m.fit(X_train, y_train)\n    probs = m.predict_proba(X_test)[:, 1] #calculating the probability\n    predictions[test_idx] = probs","90602598":"from sklearn.metrics import roc_auc_score as AUC\nprint(\"ROC-AUC for train and test distributions:\", AUC(y, predictions))","da794cc0":"df_dae = pd.read_csv('..\/input\/dae-te-le-tps0521\/df_dae.csv')\n\n\ny = pd.read_csv('..\/input\/dae-te-le-tps0521\/y.csv')\n\n\ndf_dae.head()\n\n","d65699fa":"x_dae = df_dae[:len(y)]\n\nx_tst_dae = df_dae[len(y):]","979e22a2":"x_tst_dae['is_train'] = 0\nx_dae['is_train'] = 1","a082c2d0":"\ndf_combine = pd.concat([x_dae, x_tst_dae], axis=0, ignore_index=True)\n#dropping \u2018target\u2019 column as it is not present in the test\n#df_combine = df_combine.drop('target', axis =1)\ny_ = df_combine['is_train'].values #labels\nx = df_combine.drop('is_train', axis=1).values #covariates or our independent variables\ntst, trn = test.values, train.values\n\n\nm = RandomForestClassifier(n_jobs=-1, max_depth=5, min_samples_leaf = 5)\npredictions = np.zeros(y_.shape)\n\n\nskf = SKF(n_splits=20, shuffle=True, random_state=100)\nfor fold, (train_idx, test_idx) in enumerate(skf.split(x, y_)):\n    X_train, X_test = x[train_idx], x[test_idx]\n    y_train, y_test = y_[train_idx], y_[test_idx]\n    m.fit(X_train, y_train)\n    probs = m.predict_proba(X_test)[:, 1] #calculating the probability\n    predictions[test_idx] = probs\n    \n    \nfrom sklearn.metrics import roc_auc_score as AUC\nprint(\"ROC-AUC for train and test distributions:\", AUC(y_, predictions))","1ba422c1":"df_te = pd.read_csv('..\/input\/dae-te-le-tps0521\/df_te.csv')\n\nx_te = df_te[:len(y)]\n\nx_tst_te = df_te[len(y):]\n\ndf_te.head()","a6f77968":"x_tst_te['is_train'] = 0\nx_te['is_train'] = 1","df510069":"\ndf_combine = pd.concat([x_te, x_tst_te], axis=0, ignore_index=True)\n#dropping \u2018target\u2019 column as it is not present in the test\n#df_combine = df_combine.drop('target', axis =1)\ny_ = df_combine['is_train'].values #labels\nx = df_combine.drop('is_train', axis=1).values #covariates or our independent variables\ntst, trn = test.values, train.values\n\n\nm = RandomForestClassifier(n_jobs=-1, max_depth=5, min_samples_leaf = 5)\npredictions = np.zeros(y_.shape)\n\n\nskf = SKF(n_splits=20, shuffle=True, random_state=100)\nfor fold, (train_idx, test_idx) in enumerate(skf.split(x, y_)):\n    X_train, X_test = x[train_idx], x[test_idx]\n    y_train, y_test = y_[train_idx], y_[test_idx]\n    m.fit(X_train, y_train)\n    probs = m.predict_proba(X_test)[:, 1] #calculating the probability\n    predictions[test_idx] = probs\n    \n    \nfrom sklearn.metrics import roc_auc_score as AUC\nprint(\"ROC-AUC for train and test distributions:\", AUC(y_, predictions))","87e0a856":"df_le = pd.read_csv('..\/input\/dae-te-le-tps0521\/df_le.csv')\n\nx_le = df_le[:len(y)]\n\nx_tst_le = df_le[len(y):]\n\ndf_le.head()","4a7ec7b2":"x_tst_le['is_train'] = 0\nx_le['is_train'] = 1","3a44533d":"\ndf_combine = pd.concat([x_le, x_tst_le], axis=0, ignore_index=True)\n#dropping \u2018target\u2019 column as it is not present in the test\n#df_combine = df_combine.drop('target', axis =1)\ny_ = df_combine['is_train'].values #labels\nx = df_combine.drop('is_train', axis=1).values #covariates or our independent variables\ntst, trn = test.values, train.values\n\n\nm = RandomForestClassifier(n_jobs=-1, max_depth=5, min_samples_leaf = 5)\npredictions = np.zeros(y_.shape)\n\n\nskf = SKF(n_splits=20, shuffle=True, random_state=100)\nfor fold, (train_idx, test_idx) in enumerate(skf.split(x, y_)):\n    X_train, X_test = x[train_idx], x[test_idx]\n    y_train, y_test = y_[train_idx], y_[test_idx]\n    m.fit(X_train, y_train)\n    probs = m.predict_proba(X_test)[:, 1] #calculating the probability\n    predictions[test_idx] = probs\n    \n    \nfrom sklearn.metrics import roc_auc_score as AUC\nprint(\"ROC-AUC for train and test distributions:\", AUC(y_, predictions))","776974d9":"df_combined = pd.concat([df_dae, df_le, df_te], axis = 1)\n\ndf_x = df_combined[:len(y)]\n\ndf_x_tst = df_combined[len(y):]\n\ndf_combined.head()","9ba49272":"df_x_tst['is_train'] = 0\ndf_x['is_train'] = 1","746769ac":"\ndf_combine = pd.concat([df_x, df_x_tst], axis=0, ignore_index=True)\n#dropping \u2018target\u2019 column as it is not present in the test\n#df_combine = df_combine.drop('target', axis =1)\ny_ = df_combine['is_train'].values #labels\nx = df_combine.drop('is_train', axis=1).values #covariates or our independent variables\ntst, trn = test.values, train.values\n\n\nm = RandomForestClassifier(n_jobs=-1, max_depth=5, min_samples_leaf = 5)\npredictions = np.zeros(y_.shape)\n\n\nskf = SKF(n_splits=20, shuffle=True, random_state=100)\nfor fold, (train_idx, test_idx) in enumerate(skf.split(x, y_)):\n    X_train, X_test = x[train_idx], x[test_idx]\n    y_train, y_test = y_[train_idx], y_[test_idx]\n    m.fit(X_train, y_train)\n    probs = m.predict_proba(X_test)[:, 1] #calculating the probability\n    predictions[test_idx] = probs\n    \n    \nfrom sklearn.metrics import roc_auc_score as AUC\nprint(\"ROC-AUC for train and test distributions:\", AUC(y_, predictions))","0e412aa0":"Checking for TE features obtained","647602e1":"## This notebook analyzes the (dis)similarity between the train.csv & test.csv","9b49c81d":"Finding relevant features","957bd825":"![img](https:\/\/cdn-images-1.medium.com\/max\/800\/1*BY-0dhr8UTgJRsmdt3bpgQ.png)\n![img2](https:\/\/miro.medium.com\/max\/847\/1*L8Ua86qfwVRJAnaH_KZdFQ.png)","53c9f6d3":"Checking for concatenated feature set","3575ce4b":"![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*THOmXNUuCs92HZWTNJYaDw.png)","71605aed":"Checking for LE features","c0e1790f":"Conclusion : DAE + TE + LE features have similar distribution in the training and test set.<br>\n### Meaning trust your Cross-Validation score for LB.","a582d08e":"No evidence of strong covariance shift. Majority of observations come from a feature space not specific to train or test set.","ee93779b":"#### Checking for Original Dataset...","0ca6ccda":"#### Checking for DAE extracted features, TE extracted features, LE features."}}