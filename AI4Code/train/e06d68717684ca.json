{"cell_type":{"eada5ec0":"code","d8448c92":"code","c9605c38":"code","7317320c":"code","c008b95c":"code","93109354":"code","9b5d1568":"code","40e8c719":"code","02c54df5":"code","c86f2897":"code","93b7b015":"code","b047c4d5":"code","df84f3ea":"code","3c408370":"code","9ae265e3":"code","70a038ca":"code","b011a8eb":"code","b9af84ec":"code","b7ecce96":"code","f1939a84":"code","bb82d79a":"code","a33c64f3":"code","3af64f77":"code","e64ac8d3":"code","81bd90b8":"code","8f054360":"code","31592e5b":"code","c506b3e9":"markdown","1b3b8065":"markdown","490f86bd":"markdown","f300c1ba":"markdown","88a84086":"markdown","6c8727aa":"markdown","bf82c6d1":"markdown","e95d93be":"markdown","65ad76bb":"markdown","36073f1e":"markdown","c286fb00":"markdown","798854e4":"markdown","fc9c66ee":"markdown","e065e416":"markdown","ac4f55fa":"markdown","5c8a6763":"markdown","2be57269":"markdown","6b45abc2":"markdown","1a3ed10d":"markdown","1c91138c":"markdown","b6d9694c":"markdown","8e425cd5":"markdown","8cd92f9f":"markdown","15b2709b":"markdown","2d9583e9":"markdown","7c219f2c":"markdown"},"source":{"eada5ec0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"white\") \nsns.set(style=\"whitegrid\", color_codes=True)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8448c92":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n\ntest_pid = test_data['PassengerId']","c9605c38":"# Training data\n\ntrain_data.head(5)","7317320c":"train_data.info()\nprint(\"------------------\")\ntest_data.info()","c008b95c":"from pandas_profiling import ProfileReport\nreport = ProfileReport(train_data)\nreport","93109354":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ntrain_data.plot(kind='box')\nplt.show()\n","9b5d1568":"#train_df = pd.Series(np.random.normal(size=200))\n#train_df = train_data[train_data.between(train_data.quantile(.25), train_data.quantile(.75))]\n#train_data = train_df\n#train_df.plot(kind='box')\n#plt.show()\ndef drop_outliers(df, field_name):\n    iqr = 1.5 * (np.percentile(df[field_name], 75) - np.percentile(df[field_name], 25))\n    df.drop(df[df[field_name] > (iqr + np.percentile(df[field_name], 75))].index, inplace=True)\n    df.drop(df[df[field_name] < (np.percentile(df[field_name], 25) - iqr)].index, inplace=True)\n\ndrop_outliers(train_data,'Age')\ndrop_outliers(train_data,'SibSp')\ndrop_outliers(train_data,'Parch')\ndrop_outliers(train_data,'Fare')\n\ntrain_data.plot(kind='box')\nplt.show()\n\n\n\n\n\n","40e8c719":"missing_column = (train_data.isnull().sum())\nmissing_column","02c54df5":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\ntrain_data['Age'] = imputer.fit_transform(train_data[['Age']])\ntrain_data['Cabin'] = train_data['Cabin'].fillna('N')\nmissing_column = (train_data.isnull().sum())\nmissing_column","c86f2897":"\n#corr_df = pd.DataFrame(abs(train_data.corr()['Survived']).sort_values(ascending = False))\n#corr_df \ncorr_df = abs(train_data.corr()['Survived']).sort_values(ascending = False)\ncorr_df\n","93b7b015":"\n\nplt.figure(figsize=(12,8))\n\nsns.barplot('Pclass', 'Survived', data=train_data, color=\"#fabf37\")\nplt.show()","b047c4d5":"plt.figure(figsize=(15,8))\nsns.kdeplot(train_data['Fare'][train_data.Survived==1], color=\"aqua\", shade=True)\nsns.kdeplot(train_data['Fare'][train_data.Survived==0], color=\"#ffb3b3\", shade=True)\n\nplt.legend(['Survived', 'Died'])\nplt.title('Density plot of Fare for surviving population and decreased population')\nplt.show()\n","df84f3ea":"plt.figure(figsize=(12,8))\n\nsns.barplot('Embarked', 'Survived', data=train_data, color=\"aqua\")\nplt.show()","3c408370":"plt.figure(figsize=(15,8))\nsns.kdeplot(train_data['Age'][train_data.Survived==1], color=\"aqua\", shade=True)\nsns.kdeplot(train_data['Age'][train_data.Survived==0], color=\"#ffb3b3\", shade=True)\n\nplt.legend(['Survived', 'Died'])\nplt.title('Density plot of Age for surviving population and decreased population')\nplt.show()\n","9ae265e3":"plt.figure(figsize=(12,8))\n\nsns.barplot('Sex', 'Survived', data=train_data, color=\"#fabf37\")\nplt.show()\n","70a038ca":"plt.figure(figsize=(15,8))\nsns.kdeplot(train_data['SibSp'][train_data.Survived==1], color=\"aqua\", shade=True)\nsns.kdeplot(train_data['SibSp'][train_data.Survived==0], color=\"#ffb3b3\", shade=True)\n\nplt.legend(['Survived', 'Died'])\nplt.title('Density plot of SibSp for surviving population and decreased population')\nplt.show()\n","b011a8eb":"final_train_data= pd.get_dummies(train_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\nfinal_train_data['Alone']=np.where((train_data[\"SibSp\"]+train_data[\"Parch\"])>0, 0, 1)\nfinal_train_data.drop('Name',axis=1, inplace=True)\nfinal_train_data.drop('SibSp',axis=1, inplace=True)\nfinal_train_data.drop('Parch',axis=1, inplace=True)\nfinal_train_data.drop('Ticket',axis=1, inplace=True)\nfinal_train_data.drop('Cabin',axis=1, inplace=True)\nfinal_train_data.head()","b9af84ec":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\ntest_data['Age'] = imputer.fit_transform(test_data[['Age']])\ntest_data['Fare'] = imputer.fit_transform(test_data[['Fare']])\n\ntest_data['Cabin'] = test_data['Cabin'].fillna('N')\n\n\nmissing_column = (test_data.isnull().sum())\nmissing_column","b7ecce96":"final_test_data= pd.get_dummies(test_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\nfinal_test_data['Alone']=np.where((test_data[\"SibSp\"]+test_data[\"Parch\"])>0, 0, 1)\nfinal_test_data.drop('Name',axis=1, inplace=True)\nfinal_test_data.drop('SibSp',axis=1, inplace=True)\nfinal_test_data.drop('Parch',axis=1, inplace=True)\nfinal_test_data.drop('Ticket',axis=1, inplace=True)\nfinal_test_data.drop('Cabin',axis=1, inplace=True)\nfinal_test_data.head()","f1939a84":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\n\nattr = [\"Age\",\"Fare\",\"Pclass_1\",\"Pclass_2\",\"Embarked_C\",\"Embarked_S\",\"Embarked_Q\",\"Sex_male\",\"Sex_female\",\"Alone\"] \nX = final_train_data[attr]\ny = final_train_data['Survived']\n\nmodel = LogisticRegression()\nrfe = RFE(model, 8)\nrfe = rfe.fit(X, y)\nprint('Selected features: %s' % list(X.columns[rfe.support_]))","bb82d79a":"selected_attr = ['Pclass_1', 'Pclass_2', 'Embarked_C', 'Embarked_S', 'Embarked_Q', 'Sex_male', 'Sex_female', 'Alone']\nX = final_train_data[selected_attr]\n\nplt.subplots(figsize=(8, 8))\nsns.heatmap(X.corr(), annot=True, cmap=\"RdYlGn\")\nplt.show()","a33c64f3":"#import libraries\n!pip install pycaret\nfrom pycaret.classification import *\n","3af64f77":"#exp1 = setup(final_train_data, target = 'Survived', feature_selection = True)\nexp1 = setup(final_train_data, target = 'Survived', feature_selection = True,silent = True)\n","e64ac8d3":"compare_models(fold = 5, turbo = True)\n","81bd90b8":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(random_state=0, max_iter=2500)\nmodel.fit(X,y)","8f054360":"X_test = final_test_data[selected_attr]\npred = model.predict(X_test)","31592e5b":"final = pd.DataFrame({'PassengerId':test_pid,'Survived':pred})\nfinal.to_csv('submission.csv',index=False)\nfinal.head()","c506b3e9":"#  Load Testing and Training DataSet","1b3b8065":"# Exploratory Data Analysis","490f86bd":"# Feature Engineering","f300c1ba":"# Feature Selection","88a84086":"> Persons travelled alone are less likely to survive than the persons travelling with siblings.","6c8727aa":"### Fare vs Survived","bf82c6d1":"### Pclass vs survived","e95d93be":"#  Analyze Data","65ad76bb":"# Handle Missing Values","36073f1e":"#  Outliers Detection","c286fb00":"> Passengers who paid lower fare appear to have been less likely to survive.","798854e4":"# Model Selection","fc9c66ee":"# Remove Outliers","e065e416":"### Age vs Survived","ac4f55fa":"> ","5c8a6763":"> From above 1st class passenger is more likely to survive.","2be57269":"> Lets modify test data also to add above features","6b45abc2":"### Embarked vs Survived","1a3ed10d":"> C = Cherbourg, Q = Queenstown, S = Southampton. Persons embarked from Q and C are more likely to survive.","1c91138c":"##### We will use imputation to fill the missing values.","b6d9694c":"> Females are more likely to survive than males.","8e425cd5":"##### Now we can see that in train dataset Age,Cabin,Embarked contain missing values and in test data set Cabin and Age contain missing values.","8cd92f9f":"### SibSp vs Survived","15b2709b":"### Gender vs Survived","2d9583e9":"# Pandas profiling for Data Analyses","7c219f2c":">  Lets add and select the best features by considering above EDA."}}