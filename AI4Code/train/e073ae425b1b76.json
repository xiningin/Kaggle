{"cell_type":{"7ca0c7cd":"code","104c95bc":"code","277f2ec1":"code","9abea22e":"code","e21a7caa":"code","d2d1b50d":"code","95156131":"code","039dc8a9":"code","3a93daa4":"code","b6bc7d47":"code","936fac9e":"markdown","99363f48":"markdown","be82139d":"markdown"},"source":{"7ca0c7cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","104c95bc":"path = '\/kaggle\/input\/quora-insincere-questions-classification\/train.csv'\ntrain = pd.read_csv(path, nrows=1000)\ntrain.head()","277f2ec1":"# converting every character to lowercase\ndocs = train['question_text'].str.lower()\ndocs.head()","9abea22e":"# Remove non alphabets\ndocs = docs.str.replace('[^a-z ]','')\ndocs.head()","e21a7caa":"import nltk\nstopwords = nltk.corpus.stopwords.words('english')\nstemmer = nltk.stem.PorterStemmer()\n\n# other way to do using lambda.\n# docs.apply(lambda v:v.split(' ')).head() \ndef clean_sentence(doc):\n    words = doc.split(' ')\n    words_clean = [stemmer.stem(word) for word in words if word not in stopwords]\n    return ' '.join(words_clean)\n    \ndocs = docs.apply(clean_sentence)","d2d1b50d":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\ndtm_vectorizer = CountVectorizer()\n\n\ntrain_x,validate_x, train_y,validate_y = train_test_split(docs, train['target'],test_size = 0.2,random_state = 1)\ndtm_vectorizer.fit(train_x)\ndtm_train = dtm_vectorizer.transform(train_x)\ndtm_validate = dtm_vectorizer.transform(validate_x)\n\n","95156131":"df_dtm_train=pd.DataFrame(dtm_train.toarray(),columns=dtm_vectorizer.get_feature_names(),index=train_x.index)\ndf_dtm_train","039dc8a9":"df_dtm_train = pd.DataFrame(dtm_train.toarray(),columns=dtm_vectorizer.get_feature_names(),index=train_x.index)\ndf_dtm_train.sum().sort_values(ascending=False).head(20).plot.bar()","3a93daa4":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB().fit(dtm_train,train_y)\ntrain_y_pred=model.predict(dtm_validate)\n\nfrom sklearn.metrics import accuracy_score,f1_score\nprint(accuracy_score(validate_y,train_y_pred))\nprint(f1_score(validate_y,train_y_pred))","b6bc7d47":"from nltk.sentiment import SentimentIntensityAnalyzer\nsentiment_analyzer=SentimentIntensityAnalyzer()\nsentiment_analyzer.polarity_scores('i like india')","936fac9e":"# method to convert text to numerical values\n - Doccument term matrix\n - using word2vec\/Doc2vec\n \n# Text cleaning for classification\n- convert every character to lower case\n- using regular expression retain only alphabets(sometime numbers, # and @)\n- remove commonly used words\n- identify root form of the word (stemming, lemmatization)","99363f48":"> Here we can see the  worrld ' I  Like India' has a positive sentiment of 0.714.","be82139d":"![](http:\/\/)# converting alphabets into numbers - doccument trm matrix\nto normalize in text mining.\nTerm frquency(TF)\nInverse doccumnet Frequency(IDF)"}}