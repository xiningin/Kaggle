{"cell_type":{"3faec56e":"code","84dfcdf9":"code","cfd36e97":"code","7d6882a8":"code","988d68d4":"code","8be3caef":"code","1f7b4b1e":"code","b23d4073":"code","ffbe2c3c":"code","681579cb":"code","1da49fb7":"code","f3574218":"code","336d5d7b":"code","eb9ed793":"code","7a78fa08":"code","d98418e5":"code","f9b36bde":"code","6ea1d668":"code","9cfeb1cc":"code","78966ae3":"code","afd67ae7":"code","589ad779":"markdown","c4f08845":"markdown","fb737a5e":"markdown","b7d7e879":"markdown","d9602802":"markdown","dd2e1b34":"markdown","16738bfc":"markdown","8c33e6c2":"markdown","d0866b6e":"markdown","f432f557":"markdown","9f833713":"markdown","e848006a":"markdown","3903729d":"markdown","589d32bd":"markdown","55d57bff":"markdown","ea481856":"markdown"},"source":{"3faec56e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n","84dfcdf9":"x_train = pd.read_csv('..\/input\/titanic\/train.csv')\n\nnull_columns=x_train.columns[x_train.isnull().any()]\nprint(\"NULL COLUMNS OF YOUR DATAFRAME : \" , null_columns , '\\n\\n')\n\n\ny_train = x_train.iloc[: , 1].values\nprint(y_train)\n\n\nx_train = x_train.drop([\"PassengerId\" , \"Survived\" , \"Name\" , \"Ticket\" , \"Cabin\"] , axis = 1)\nprint(x_train)\n\n","cfd36e97":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nx_train = np.array(ct.fit_transform(x_train))\n\nprint(\"Column Number = 0 : \" , x_train[: , 0])\nprint(\"Column Number = 1 : \" , x_train[: , 1])\nprint(\"Column Number = 2 : \" , x_train[: , 2])\n","7d6882a8":"\n# FILLING MISSING VALUES USING MODE STRATEGY\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nx_train[: , 3] = imputer.fit_transform(x_train[: , 3].reshape(- 1 , 1)).reshape(-1)\n\n\n# LABEL ENCODING\nfrom sklearn.preprocessing import LabelEncoder , OneHotEncoder\nlabel_encoder_x = LabelEncoder()\nx_train[: , 3] = label_encoder_x.fit_transform(x_train[: , 3])\n\n# ONE HOT ENCODING\nfrom sklearn.compose import ColumnTransformer\nct = ColumnTransformer(transformers = [ ('encoder' , OneHotEncoder() , [3]) ] , remainder = 'passthrough')\nx_train = np.array(  ct.fit_transform(x_train)  )\n\n\nprint(\"Column Number = 3 : \" , x_train[: , 3])\nprint(\"Column Number = 4 : \" , x_train[: , 4])\n\n","988d68d4":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan , strategy = 'mean')\nx_train[: , 5] = imputer.fit_transform(x_train[: , 5].reshape(-1 , 1)).reshape(-1)\n\nprint(x_train[: , 5])\n\n\n","8be3caef":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan , strategy = 'most_frequent')\nx_train[: , -1] = imputer.fit_transform(x_train[: , -1].reshape(-1 , 1)).reshape(891)\n\nfrom sklearn.preprocessing import LabelEncoder , OneHotEncoder\nlabel_encoder_x = LabelEncoder()\nx_train[: , -1] = label_encoder_x.fit_transform(x_train[: , -1])\n\n\n\nfrom sklearn.compose import ColumnTransformer\nct = ColumnTransformer(transformers = [ ('encoder' , OneHotEncoder() , [-1] ) ] , remainder = 'passthrough')\nx_train = np.array(ct.fit_transform(x_train))\n\n\n","1f7b4b1e":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nx_train = sc_x.fit_transform(x_train)","b23d4073":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 15, metric = 'minkowski', p = 2)\nclassifier.fit(x_train, y_train)\n","ffbe2c3c":"x_test = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# PassengerId columns\npassenger_id_col = np.array(x_test['PassengerId']).reshape(-1 , 1)\n\n\n\n\nnull_columns=x_test.columns[x_test.isnull().any()]\nprint(\"NULL COLUMNS OF YOUR DATAFRAME : \" , null_columns , '\\n\\n')\n\nx_test = x_test.drop([\"PassengerId\" , \"Name\" , \"Ticket\" , \"Cabin\"] , axis = 1)\n\n\n# PassengerId columns\n\n\n\nprint(type(x_test))\n\n","681579cb":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n\nct = ColumnTransformer(transformers = [ ('encoder' , OneHotEncoder() , [0]) ] , remainder = \"passthrough\")\nx_test = np.array(ct.fit_transform(x_test))\nprint(x_test[: , 0])","1da49fb7":"from sklearn.preprocessing import LabelEncoder , OneHotEncoder\nlabel_encoder_x = LabelEncoder()\nx_test[: , 3] = label_encoder_x.fit_transform(x_test[: , 3])\n\n\nfrom sklearn.compose import ColumnTransformer\nct = ColumnTransformer(transformers = [ ('encoder' , OneHotEncoder() , [3]) ] , remainder = 'passthrough')\nx_test = np.array(ct.fit_transform(x_test))\n\nprint(x_test[: , 3])","f3574218":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer()\nx_test[: , 5] = imputer.fit_transform(x_test[: , 5].reshape(-1 , 1)).reshape(-1)","336d5d7b":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan , strategy = 'mean')\nx_test[: , -2] = imputer.fit_transform(x_test[: , -2].reshape(-1 , 1)).reshape(-1)\n\nprint(x_test[ : , -2])","eb9ed793":"from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n\nlabel_encoder_x = LabelEncoder()\nx_test[: , -1] = label_encoder_x.fit_transform(x_test[: , -1])\n\nfrom sklearn.compose import ColumnTransformer\nct = ColumnTransformer(transformers = [ ('encoder' , OneHotEncoder() , [-1]) ] , remainder = 'passthrough')\nx_test = np.array(ct.fit_transform(x_test))\n\n\n","7a78fa08":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nx_test = sc_x.fit_transform(x_test)","d98418e5":"y_pred = classifier.predict(x_test)\ny_pred = y_pred.reshape(-1 , 1).astype(int)\nprint(y_pred)\n\nfinal = np.concatenate( (passenger_id_col,y_pred), axis=1)\nprint(final)","f9b36bde":"print(final)","6ea1d668":"print(final.shape)","9cfeb1cc":"print(type(final))","78966ae3":"data_to_be_submitted = pd.DataFrame(final , columns=['PassengerId' , 'Survived'])\nprint(data_to_be_submitted)","afd67ae7":"data_to_be_submitted = data_to_be_submitted.to_csv('data_to_be_submitted_csv_file.csv' , index = False)","589ad779":"# Preprocessing of \"Fare\" Column :\n### 1. Filling the missing values using mean strategy of imputer\n","c4f08845":"# Preprocessing of \"Sex\" column :\n### 1. Filling the Nan values using IMPUTER using mode strategy\n### 2. Label Encoding as it has Categorical data\n### 3. One Hot Encoding after Label Encoding as no category will get mathematical advantage\n\n---\n\n","fb737a5e":"# Applying Feature Scaling to x_train :","b7d7e879":"# Importing necessary libraries","d9602802":"# Preprocessing of \"Embarked\" Column :\n### 1. Filling missing values using MODE strategy of IMPUTER\n### 2. LABEL ENCODING \n### 3. ONE HOT ENODING ","dd2e1b34":"# Importing the TRAINING DATA and also finding the columns with Nan values in our dataframe i.e. x_train ,, also droping the unnecassary columns = [\"PassengerId\" , \"Survived\" , \"Name\" , \"Ticket\" , \"Cabin\"]","16738bfc":"# Preprocessing of \"Age\" Column :\n### 1. Filling missing values using mean strategy of imputer","8c33e6c2":"# Importing the TEST dataset , checking for Nan value Columns , making passengerId column form test file and removing unnecessary columns = [\"PassengerId\"  , \"Name\" , \"Ticket\" , \"Cabin\"]:","d0866b6e":"# Preprocessing of \"Age\" Column :\n### 1. Filling missing values using mean strategy of imputer","f432f557":"# Applying Feature Scaling to x_test :","9f833713":"# Model Training :","e848006a":"# Predicting the test set values","3903729d":"# Preprocessing of \"Embarked\" Column :\n### 1. LABEL ENCODING \n### 2. ONE HOT ENODING","589d32bd":"# Preprocessing of \"Pclass\" Column :\n### Here the data is categorical but label encoding is not required  because data is already in numerical form.\n### 1. One Hot Encoding as no category will get mathematical advantage\n","55d57bff":"# Preprocessing of \"Pclass\" Column :\n### Here the data is categorical but label encoding is not required  because data is already in numerical form.\n### 1. One Hot Encoding as no category will get mathematical advantage","ea481856":"# Preprocessing of \"Sex\" column :\n### 1. Label Encoding as it has Categorical data\n### 2. One Hot Encoding after Label Encoding as no category will get mathematical advantage"}}