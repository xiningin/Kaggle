{"cell_type":{"a14c54ec":"code","1803076b":"code","4ee5ce74":"code","a38de2ac":"code","41cce348":"code","02657681":"code","0e985b60":"code","4f7efba0":"code","4ef62f84":"code","1b333f60":"code","832164ad":"code","acc5b7d8":"code","a1b4ed98":"code","dd3e0b7c":"code","f2998892":"code","3134432d":"code","0028f5cf":"code","65417d6b":"code","b993ee45":"code","1483eed3":"code","d8dc17cd":"code","862ac41c":"code","2eda268a":"markdown","b7e9b6d9":"markdown"},"source":{"a14c54ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport umap\nfrom PIL import Image\nfrom scipy import misc\nfrom os import listdir\nfrom os.path import isfile, join\nimport numpy as np\nfrom scipy import misc\nfrom random import shuffle\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.utils.np_utils import to_categorical\n","1803076b":"\nos.chdir('..\/input\/utkface_aligned_cropped')\nos.chdir('UTKFace')\n","4ee5ce74":"im =Image.open('1_0_0_20161219140623097.jpg.chip.jpg').resize((128,128))\nim","a38de2ac":"onlyfiles = os.listdir()","41cce348":"len(onlyfiles)","02657681":"shuffle(onlyfiles)\ngender = [i.split('_')[1] for i in onlyfiles]","0e985b60":"classes = []\nfor i in gender:\n    i = int(i)\n    classes.append(i)\n\n","4f7efba0":"X_data =[]\nfor file in onlyfiles:\n    face = misc.imread(file)\n    face = cv2.resize(face, (32, 32) )\n    X_data.append(face)\n","4ef62f84":"X = np.squeeze(X_data)","1b333f60":"X.shape","832164ad":"# normalize data\nX = X.astype('float32')\nX \/= 255\n","acc5b7d8":"classes[:10]\n","a1b4ed98":"categorical_labels = to_categorical(classes, num_classes=2)\n","dd3e0b7c":"categorical_labels[:10]\n","f2998892":"(x_train, y_train), (x_test, y_test) = (X[:15008],categorical_labels[:15008]) , (X[15008:] , categorical_labels[15008:])\n(x_valid , y_valid) = (x_test[:7000], y_test[:7000])\n(x_test, y_test) = (x_test[7000:], y_test[7000:])\n","3134432d":"len(x_train)+len(x_test) + len(x_valid) == len(X)\n","0028f5cf":"model = tf.keras.Sequential()\n\n# Must define the input shape in the first layer of the neural network\nmodel.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(32,32,3))) \nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=2))\nmodel.add(tf.keras.layers.Dropout(0.3))\n\nmodel.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=2))\nmodel.add(tf.keras.layers.Dropout(0.3))\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n\n# Take a look at the model summary\nmodel.summary()\n","65417d6b":"model.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])\n","b993ee45":"model.fit(x_train,\n         y_train,\n         batch_size=64,\n         epochs=35,\n         validation_data=(x_valid, y_valid),)","1483eed3":"# Evaluate the model on test set\nscore = model.evaluate(x_test, y_test, verbose=0)\n\n# Print test accuracy\nprint('\\n', 'Test accuracy:', score[1])","d8dc17cd":"labels =[\"Male\",  # index 0\n        \"Female\",      # index 1\n        ]","862ac41c":"y_hat = model.predict(x_test)\n\n# Plot a random sample of 10 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = np.argmax(y_hat[index])\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(labels[predict_index], \n                                  labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\nplt.show()\n","2eda268a":"1. I would like to make clear that the image data is in its name means the first box of the second cell, the second gender, the second one, so the first step is that we are trying to separate the labels from the images so that they are stored in the classes as much as we need them\n2. We can split the data into Gender Classes - 0 Male 1 Female\n","b7e9b6d9":"**CONVERT IMAGES TO VECTORS**"}}