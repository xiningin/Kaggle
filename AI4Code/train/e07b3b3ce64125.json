{"cell_type":{"d8c7f85e":"code","83167e9c":"code","c1e6c453":"code","257f9480":"code","1838a408":"code","f889068c":"code","4953b80a":"code","aea1b63f":"code","e7e7770b":"code","2881f220":"code","836db28f":"code","48a596c9":"markdown","948a6d17":"markdown","6d6c8ba5":"markdown","5b2b3376":"markdown","85b9f77c":"markdown","e016c219":"markdown","658453d8":"markdown","03d6b539":"markdown","b421d3d9":"markdown","f1878547":"markdown","3fd2fd09":"markdown","8dda9186":"markdown","7011973a":"markdown","7f5ab162":"markdown"},"source":{"d8c7f85e":"# import modules\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom datetime import timedelta\nimport os\n\nimport random\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\nsns.set()","83167e9c":"# load data\nfiles_csv=[]\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        files_csv.append(os.path.join(dirname, filename))\n        \n# create Pandas dataframes and add the column \"month\"\nframe=[]\nfor i in range(len(files_csv)):\n    df_i=pd.read_csv(files_csv[i])\n    df_i['month']=files_csv[i][-7:-4]\n    frame.append(df_i)\ndf=pd.concat(frame,ignore_index=True,sort=False)\n\n# a quick examination of the dataframe\nprint(\"The dataframe has {} rows and {} columns.\\n\".format(df.shape[0],df.shape[1]))\nprint(\"Shown below are the first 3 rows of the dataframe:\\n\")\npd.set_option('display.max_columns', 100)\ndisplay(df.head(3))","c1e6c453":"# data preparation\n\n# step 1: select customers who purchased\ndf_sales=df.loc[df.event_type=='purchase',:]\n\n# step 2: drop \"category_code\", \"brand\", \"product_id\", \"category_id\", and \"user_session\"\ndf_sales=df_sales.drop(columns=['category_code','brand','product_id','category_id','user_session'])\n\n# step 3: drop duplicates\ndf_sales=df_sales.drop_duplicates()\n\n# step 4: convert \"event_time\" to DateTime format\ndf_sales['event_time']=pd.to_datetime(df_sales['event_time'],infer_datetime_format=True)\n\nnullcolumns=df_sales.isnull().sum()\nnullnumbers=len(nullcolumns[nullcolumns!=0])\nprint(\"After data selection and cleansing, the dataframe has {} rows, {} columns, and {} null value.\\n\".format(df_sales.shape[0],df_sales.shape[1],nullnumbers))\nprint(\"Shown below are the first 3 rows of the cleaned dataframe:\\n\")\ndisplay(df_sales.head(3))","257f9480":"# initial data exploration\n\nplt.figure(figsize=(10,8))\n\n# plot the number of customers each day \nplt.axes([0.08, 0.4, 0.87, 0.4])\ndf_sales_n_user=df_sales.resample(\"D\",on='event_time')['user_id'].nunique()\ndf_sales_n_user.plot(kind='line')\nplt.xlabel('')\nplt.ylabel('customer #')\n\n# plot total sales\/month \nplt.axes([0.08,0,0.4,0.32])\na=df_sales.resample('M',on='event_time')['price'].sum().to_frame()\na['month']=['Oct','Nov','Dec',\"Jan\\n2020\", \"Feb\"]\na['price']=a['price']\/1000000\nsns.barplot(x='month',y='price',data=a,color=\"lightsteelblue\")\nplt.xlabel('month')\nplt.ylabel('total sales (million $)')\n\n# plot average spend\/customer\nplt.axes([0.55,0,0.4,0.32])\ndf_sales_p_day=df_sales.resample('D',on='event_time')['price'].sum()\ndf_sales_spent=df_sales_p_day\/df_sales_n_user\ndf_sales_spent.plot(kind='area',color=\"lightsteelblue\")\nplt.xlabel('date')\nplt.ylabel('average spend\/customer ($)');","1838a408":"# group the data by \"user_id\", and calcualte each customer's recency, frequency, and monetary value\n\n# step 1: calculate \"Recency\", set Feb 2020 as the reference month, and use \"month\" as the unit\nd={\"Oct\":4,\"Nov\":3,\"Dec\":2,\"Jan\":1,\"Feb\":0}\ndf_sales.loc[:,'Recency']=df_sales['month'].map(d)\ndf_R=df_sales.groupby('user_id')['Recency'].min().reset_index().rename(columns={\"0\":\"Recency\"})\n\n# step 2: calculate \"Frequency\"\ndf_F=df_sales.groupby('user_id')['event_type'].count().reset_index().rename(columns={\"event_type\":\"Frequency\"})\n\n# step 3: calculate \"Monetary\"\ndf_M=df_sales.groupby('user_id')['price'].sum().reset_index().rename(columns={\"price\":\"Monetary\"})\n\n# step 4: merge \"Recency\", \"Frequency\", and \"Monetary\"\ndf_RF=pd.merge(df_R,df_F,on='user_id')\ndf_RFM=pd.merge(df_RF,df_M,on='user_id')\n\n# step 5: remove outliers before K-Means clustering\nconditions=np.abs(stats.zscore(df_RFM.loc[:,['Recency','Frequency','Monetary']]) < 3).all(axis=1)\ndf_RFM2=df_RFM.loc[conditions,:]\n\ndf_RFM2.head(3)","f889068c":"# visualize the distribution of \"Recency\", \"Frequency\", and \"Monetary\"\nfig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(10,4))\n\n# plot \"Recency\"\nax1.hist(df_RFM2['Recency'],bins=5,color='lightsteelblue')\nax1.set_xticks(np.arange(0,5,1))\nax1.set_xlabel('recency (month)')\nax1.set_ylabel('customer #')\n\n# plot \"Frequency\"\nax2.hist(df_RFM2['Frequency'],bins=5,color='lightsteelblue')\nax2.set_xlabel('frequency')\nax2.set_ylabel('customer#')\n\n# plot \"Monetary\"\nax3.hist(df_RFM2['Monetary'],bins=5,color='lightsteelblue')\nax3.set_xlabel('monetary value ($)')\nax3.set_ylabel('customer#')\n\nplt.tight_layout()","4953b80a":"# k-means clustering: using recency, frequency, and monetary as clustering varaibles\n\n# step 1: standardize data\ndf_RFM3=df_RFM2.drop(columns=['user_id'])\nX = StandardScaler().fit_transform(df_RFM3)\n\n# step 2: find the optimal number of clusters\nSSE=[]\nfor i in range(1,8,1):\n    kmeans=KMeans(n_clusters=i)\n    kmeans.fit(X)\n    SSE.append(kmeans.inertia_)\nsns.set()\nplt.plot(range(1,8,1),SSE,marker='o')\nplt.xlabel('number of clusters')\nplt.ylabel('squared error');","aea1b63f":"# k-means clustering: using recency, frequency, and monetary as clustering varaibles\n\n# step 3: group customers into 4 clusters\nrandom.seed(8)\nkm=KMeans(n_clusters=4,random_state=0)\nkm.fit(X)\nrandom.seed(8)\npred=km.predict(X)\ndf_RFM2=df_RFM2.assign(clusters=pred)\n\n# step 4: visualize the 4 clusters\n\n# step 4_1: data preparation\nR=[]\nF=[]\nM=[]\nmycolors=['navajowhite','lightsteelblue','mediumaquamarine','thistle']\ncluster_orders=[3,2,0,1]\nfor i in [0,1,2,3]:\n    R.append(df_RFM2.loc[df_RFM2.clusters==cluster_orders[i],'Recency'].values.tolist())\n    F.append(df_RFM2.loc[df_RFM2.clusters==cluster_orders[i],'Frequency'].values.tolist())\n    M.append(df_RFM2.loc[df_RFM2.clusters==cluster_orders[i],'Monetary'].values.tolist())\n    \n# step 4_2: 3D scatter plot\nfig=plt.figure(figsize=(8,5))\nax=Axes3D(fig)\nfor i in [0,1,2,3]:\n    ax.scatter(R[i], F[i], M[i], c=mycolors[i], marker='o',alpha=0.5,label='cluster '+str(cluster_orders[i]))\nax.set_xlabel('Recency (month)')\nax.set_ylabel('Frequency')\nax.set_zlabel('Monetary Value($)')\nax.set_xlim(0,4)\nax.set_xticks(list(range(5)))\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()","e7e7770b":"# replace k-means cluster names with more meaningful names\nd1={0:\"New Customers\", 2:\"Potential Loyalist\", 1: \"At-Risk\", 3:\"Loyal Customers\"}\ndf_RFM2.loc[:,\"segments\"]=df_RFM2.loc[:,\"clusters\"].map(d1)\n\n# calculate the number of customers, median recency, median frequency, \n# and average customer spend in each customer segment\ndf_RFM3=df_RFM2.groupby('segments').agg(Recency=('Recency',np.median),Frequency=('Frequency',np.median),MonetarySum=('Monetary',np.sum),size=(\"clusters\",'size'))\ndf_RFM3.loc[:,'Sales\/Customer']=round(df_RFM3.loc[:,'MonetarySum']\/df_RFM3.loc[:,'size'])\ndf_RFM3=df_RFM3.astype({'Sales\/Customer':int}).reset_index()\n\n# visualize\nplt.figure(figsize=(10,4))\nseg_names=['Loyal Customers','Potential Loyalist','New Customers','At-Risk']\n\n# plot the number of customers in each segment\nsns.set_style(\"white\")\nplt.axes([0, 0, 0.38, 0.9])\nseg=df_RFM2.groupby('segments').size().to_frame().rename(columns={0:'number of customers'}).reset_index()\nsns.barplot(x='number of customers',y='segments',data=seg,order=seg_names,palette=mycolors)\nfor i in [0,1,2,3]:\n    number=int(seg.loc[seg.segments==seg_names[i],'number of customers'])\n    x_pos=round(number,-2)\n    plt.text(x_pos,i,number)\nplt.ylabel(\"\")\nsns.despine()\n\n# plot recency, frequency, and average spend\/customer of the 4 segments\nplt.axes([0.5,0,0.42,0.9])\nsns.scatterplot(x='Recency',y='Frequency',hue='segments',hue_order=seg_names,palette=mycolors,size='Sales\/Customer',sizes=(200,1000),legend=False,data=df_RFM3)\nplt.ylim(0,35)\nplt.xticks(list(range(5)))\nplt.text(1,29,'average \"Loyal Customer\": $146')\nplt.text(2,16,'average \"Potential Loyalist\": $72')\nplt.text(0,6,'average \"New Customer\": $24')\nplt.text(3,6,'average \"At-Risk\": $24')\nplt.xlabel('Median Recency (month)')\nplt.ylabel('Median Frequency')\nsns.despine()","2881f220":"# explore the relationship between customers' purchase probability in Feb 2020 and their Recency,Frequency,\n# and Monetary in previous months\n\n# step 1: calculate recency, Frequency, and Monetary in Oct 2019-Jan 2020\ndf_sales1=df_sales.loc[df_sales.month!='Feb',:].copy()\nd={\"Oct\":3,\"Nov\":2,\"Dec\":1,\"Jan\":0}\ndf_sales1.loc[:,'Recency']=df_sales1.loc[:,'month'].map(d)\ndf_sales1_R=df_sales1.groupby('user_id')['Recency'].min().reset_index()\ndf_sales1_F=df_sales1.groupby('user_id')['event_type'].count().reset_index().rename(columns={'event_type':'Frequency'})\ndf_sales1_RF=pd.merge(df_sales1_R,df_sales1_F,on='user_id')\ndf_sales1_M=df_sales1.groupby('user_id')['price'].sum().reset_index().rename(columns={'price':\"Monetary\"})\ndf_sales2=pd.merge(df_sales1_RF,df_sales1_M,on='user_id')\n                   \n# step 2_1: find out customers who made purchases in Feb 2020\ndf_sales_feb_buyers=df_sales.loc[df_sales.month=='Feb','user_id'].unique().tolist()\n\n# step 2_2: combine step 1 and step 2 results and remove outliers\ndf_sales2.loc[:,'Buy']=np.where(df_sales2['user_id'].isin(df_sales_feb_buyers),1,0)\nconditions=np.abs(stats.zscore(df_sales2[['Recency','Frequency','Monetary']]) < 3).all(axis=1)\ndf_sales2=df_sales2.loc[conditions,:]\nprint(\"Shown below are the first 3 rows of the cleaned dataframe:\\n\")\ndisplay(df_sales2.head(3))","836db28f":"# Step 3 and 4: calculate and visualize the relationship between the probability of purchasing and RFM \nsns.set()\nplt.figure(figsize=(12,4))\n\n# plot purchase probability and Recency \nplt.axes([0,0,0.25,0.8])\ndf_Buy_R=df_sales2.groupby('Recency').agg(Number=('Buy','count'),Buy=('Buy','sum'))\ndf_Buy_R['Probability']=df_Buy_R['Buy']\/df_Buy_R['Number']\nplt.scatter(x=df_Buy_R.index,y=df_Buy_R.Probability)\nplt.xlim(-0.1,4)\nplt.xticks(np.arange(0,4,1))\nplt.xlabel('Recency(month)')\nplt.ylabel('probability of purchase')\n\n# plot purchase probability and Frequency\nplt.axes([0.32,0,0.25,0.8])\ndf_Buy_F=df_sales2.groupby('Frequency').agg(Number=('Buy','count'),Buy=('Buy','sum'))\ndf_Buy_F['Probability']=df_Buy_F['Buy']\/df_Buy_F['Number']\nplt.scatter(x=df_Buy_F.index,y=df_Buy_F.Probability,alpha=0.5)\nplt.xlabel('Frequency')\nplt.ylabel('probability of purchase')\n\n# plot purchase probability and Monetary\nplt.axes([0.63,0,0.25,0.8])\ndf_Buy_M=df_sales2.groupby('Monetary').agg(Number=('Buy','count'),Buy=('Buy','sum'))\ndf_Buy_M['Probability']=df_Buy_M['Buy']\/df_Buy_M['Number']\nplt.scatter(x=df_Buy_M.index,y=df_Buy_M.Probability,alpha=0.5)\nplt.xlabel('Monetary Value ($)')\nplt.ylabel(\"probability of purchase\");","48a596c9":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Since the goal was to segment customers to help with marketing campaigns, I decided to start with the simple but very effective RFM model. Briefly, the RFM analysis is based on 3 factors \u2013 how recently (Recency), how often (Frequency), and how much (Monetary Value) did the customer buy. Next, I selected the rows and columns needed, deleted duplicate records, and performed some data type conversion.","948a6d17":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initial examination of the RFM data revealed: (1) customers were somewhat evenly distributed along the recency curve; (2) most customers made purchases fewer than 10 times; (3) most customers spent less than 100 dollars.","6d6c8ba5":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Taken together, our customers were grouped into 4 segments:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)\tLoyal Customers: These customers purchased very often and spent the highest amount of money. They shopped from Oct 2019 to Feb 2020 with a median recency of 1 month. \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)\tPotential Loyalist: This group shopped quite often (though not as frequent as the loyal customers) and spent reasonable amount of money (though not as high as the loyal customers). \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3)\tNew Customers: I was so surprised that we had such a large group of new customers. They started shopping very recently and as a result, they didn\u2019t make purchases often nor spend much money.\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4)\tAt-Risk: This is the largest-sized group!!! These customers have high recency, low frequency, and low monetary.","5b2b3376":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The probability of repurchasing in Feb 2020 increased as the customers\u2019 recency decreased. For example, customers who were active in Jan 2020 (Recency=0) had about 4 times as high probability of repurchasing as those who made their last order in Oct 2019 (Recency=3). There was somewhat of a linear relationship between the probability of purchase and frequency. Customers with higher number of transactions were more likely to repurchase. However, how much a customer spent over the past 4 months didn\u2019t seem to have any obvious relationships with his or her purchase probability.\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In summary, using the RFM-based K-Means clustering method, I grouped customers into 4 segments: (1) Loyal Customers; (2) Potential Loyalist; (3) New Customers; (4) At-Risk. Additionally, I found that there is a negative association between recency and purchase probability, and a positive relationship between frequency and purchase probability. I hope my work could help our marketing team design effective campaigns.\n\n\n\n\n\n__References__\n\nChen Daqing (2012). Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining. Database Marketing & Customer Strategy Management 19, 197-208\n","85b9f77c":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I must admit that I\u2019ve never liked 3D graphs. I don\u2019t want to call my customer segments neither \u201ccluster 1\u201d nor \u201ccluster 2\u201d. So, I replaced the old cluster names with more meaning segment names and re-plotted the data.","e016c219":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Though the distribution of the number of customers indicated that other unrecorded factors had influenced our customer behavior, I decided to ignore them for now and continue my analysis before I obtain more details from our marketing team. \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Next, I grouped the data by user_id, and calculated each customer\u2019s Recency (how many months until Feb 29, 2020 had it been since the customer\u2019s last purchase), Frequency (how often had the customer made a purchase from Oct 2019 to Feb 2020), and Monetary Value(how much did the customer spend from Oct 2019 to Feb 2020). Furthermore, I removed outliers before clustering. I got this:","658453d8":"### Part II: Customer Segmentation by RFM-Based K-Means Clustering","03d6b539":"## Customer Segmentation by RFM model and K-Means\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It was my first day as a data analyst in a cosmetics online store. My supervisor sent me a link to a shared folder that contained 5 medium-sized csv files. \u201cWe may launch a marketing campaign soon, take a look at these files and see if you can group our customers in a meaningful way,\u201d he said to me a few minutes before he left for a business trip.\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After taking a deep breath, I glanced through the files. Each file contained customer behavior data for a month. The data were collected from Oct 2019 to Feb 2020.  Next, I combined these files using python and added a column \u201cmonth\u201d.","b421d3d9":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I was curious about the number of customers and sales over time. After more data manipulation (see codes below for details), the time series analysis showed that\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1) the number of customers spiked in Nov 2019 (Thanksgiving?) and the end of Jan 2020 (sales event?). There was a big drop in customer numbers on New Year\u2019s Eve (system downtime?); \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2) sales went up from ~0.95 million dollars in Oct 2019 to ~1.3 million dollars in Nov 2019, fell to ~0.85 million dollars in Dec 2019, and then remained ~1 million dollars\/month in the following 2 months;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3) the average spend per customer didn\u2019t change much over the 5 months.","f1878547":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As a very curious data analyst, I always like to dig a little deeper. I wanted to find out how a customer\u2019s recency, frequency, and monetary value would affect his or her repurchase probability. To address my own question, I did the following things:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1) I calculated the Recency, Frequency, and Monetary Value of each customer using data from Oct 2019 to Jan 2020. Jan 2020 was used as the reference month; \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)\nI assigned the customers who made >=1 purchase in Feb 2020 to the \u201cbuy\u201d (1) group, and those who didn\u2019t buy in Feb 2020 to the \u201cno-buy\u201d (0) group; \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3) I grouped the data by recency, frequency, and monetary, respectively, and calculated the percentage of the \u201cbuy\u201d group in each recency\/frequency\/monetary bin; \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4) I plotted the percentage (purchase probability in Feb 2020) against recency\/frequency\/monetary.","3fd2fd09":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Based on the graph above, I decided to group our customers into 4 clusters by K-Means. The 3D scatter plot showed that the 4 groups were well separated.","8dda9186":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traditionally, in RFM models, each customer is assigned a score for each RFM factor. These scores are then combined and used for segmentation. Inspired by Chen (2012), I decided to do RFM analysis by K-Means clustering. The first two things I did were to standardize the data and then find the optimal number of clusters by the elbow method.","7011973a":"### Part III: Examine the Relationship between the Probability of Purchasing and RFM","7f5ab162":"### Part I: Initial Data Preparation and Exploration"}}