{"cell_type":{"c1112c42":"code","c826f261":"code","0634d8dd":"code","d85ec985":"code","0a9492dd":"code","e6b66f7b":"code","7c2cde1b":"code","d622f831":"code","c5de8851":"code","64315934":"code","d76809fa":"code","c9e11241":"code","0fa65282":"code","eab1e667":"code","55a449b7":"code","702ab527":"markdown","2652a40f":"markdown","b38935d0":"markdown","eb370c71":"markdown","4e32b683":"markdown","4f28380b":"markdown","c8c12187":"markdown","47fcfc4c":"markdown","9e2c106f":"markdown","16747166":"markdown"},"source":{"c1112c42":"#Using the standard python 3 kernel set up.  Added matplotlib, pandas plotting and date\/datetime\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\nfrom datetime import datetime\nfrom datetime import date\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c826f261":"#Read in the data\n\nfile = '\/kaggle\/input\/novel-corona-virus-2019-dataset\/2019_nCoV_data.csv'\ndf = pd.read_csv(file)\nprint(df.head())\nprint(df.tail())\n","0634d8dd":"#Create a data frame grouped by Date for confirmed, deaths, recovered\nmort_df = df.groupby('Date').Confirmed.sum()\nmort_df = pd.concat([mort_df, df.groupby('Date').Deaths.sum(), df.groupby('Date').Recovered.sum()], axis=1)\nmort_df = mort_df.sort_values(by='Date').reset_index()\n\n#convert Date do datetime\nmort_df.Date =  [datetime.strptime(x, \"%m\/%d\/%Y %H:%M:%S\").date() for x in mort_df.Date]\n#create a variable that keeps track of how many days ago the data is from\nmort_df[\"daysago\"] = [-(date.today() - x).days for x in mort_df.Date]\nmort_df\n","d85ec985":"mort_df[\"fc\"] = [100.0*int(x)\/(int(x)+int(y)) if int(x)>0 else 0 for (x, y) in zip(mort_df.Deaths, mort_df.Recovered)]\nmort_df[\"cfr\"] = [100.0*int(x)\/int(y) if int(x)>0 else 0 for (x, y) in zip(mort_df.Deaths, mort_df.Confirmed)]\n\nplt.plot(mort_df.daysago[1:], mort_df.fc[1:], 'o') #using [1:] to skip the first day which had zeros\nplt.xlabel(\"time delta from today\")\nplt.title('Final count and CFR vs time')\nplt.ylabel('%')\nplt.ylim([0, 65])\nplt.plot(mort_df.daysago[1:], mort_df.cfr[1:], 'o')\nplt.show()","0a9492dd":"def fc_add_delay(dead, recovered, daysago, delay):\n    \"\"\"function to add a delay to the recovered number before comparing to dead\"\"\"\n    mort_fc = []\n    timestep = []\n    for i in range(1, len(dead) - delay):\n        mort_fc.append(100*dead[i]\/(dead[i] + recovered[delay+i]))\n        timestep.append(daysago[i]+delay)\n    return(mort_fc, timestep)\n        ","e6b66f7b":"(mort_fc, timestep) = fc_add_delay(mort_df.Deaths, mort_df.Recovered, mort_df.daysago, 5)","7c2cde1b":"plt.plot(timestep, mort_fc)\nplt.xlabel(\"time delta from today\")\nplt.title('Final count vs time with 5 day delay for recovered')\nplt.ylabel('%')","d622f831":"(mort_fc, timestep) = fc_add_delay(mort_df.Deaths, mort_df.Recovered, mort_df.daysago, 3)\nplt.plot(timestep, mort_fc)\nplt.xlabel(\"time delta from today\")\n\nplt.title('Final count vs time with 3 day delay for recovered')\nplt.ylabel('%')","c5de8851":"(mort_fc, timestep) = fc_add_delay(mort_df.Deaths, mort_df.Recovered, mort_df.daysago, 7)\nplt.plot(timestep, mort_fc)\nplt.xlabel(\"time delta from today\")\nplt.title('Final count vs time with 7 day delay for recovered')\nplt.ylabel('%')","64315934":"for i in range(10):\n    (mort_fc, timestep) = fc_add_delay(mort_df.Deaths, mort_df.Recovered, mort_df.daysago, i)\n    plt.plot(timestep, mort_fc)","d76809fa":"def cfr_add_delay(confirmed, dead, daysago, delay):\n    mort_cfr = []\n    timestep = []\n\n    for i in range(1, len(confirmed) - delay):\n\n        mort_cfr.append(100*dead[i+delay]\/confirmed[i])\n        timestep.append(daysago[i]+delay)\n    return(mort_cfr, timestep)\n        ","c9e11241":"(mort_cfr, timestep) = cfr_add_delay(mort_df.Confirmed, mort_df.Deaths, mort_df.daysago, 0)\nplt.plot(timestep, mort_cfr)\nplt.xlabel(\"time delta from today\")\nplt.title('CFR vs time with death count with no delay')\nplt.ylabel('%')","0fa65282":"(mort_cfr, timestep) = cfr_add_delay(mort_df.Confirmed, mort_df.Deaths, mort_df.daysago, 3)\nplt.plot(timestep, mort_cfr)\nplt.xlabel(\"time delta from today\")\nplt.title('CFR vs time with death count delayed by 3 days')\nplt.ylabel('%')\n    \n","eab1e667":"(mort_cfr, timestep) = cfr_add_delay(mort_df.Confirmed, mort_df.Deaths, mort_df.daysago, 7)\nplt.plot(timestep, mort_cfr)\nplt.xlabel(\"time delta from today\")\nplt.title('Final count vs time with death count delayed by 7 days')\nplt.ylabel('%')","55a449b7":"for i in range(10):\n    (mort_cfr, timestep) = cfr_add_delay(mort_df.Confirmed, mort_df.Deaths, mort_df.daysago, i)\n    plt.plot(timestep, mort_cfr)","702ab527":"Caveat number 2 -- this is the first kernel I've created and submitted, so apologies if it's a bit amateurish.  ","2652a40f":"We can do the same thing with confirmed vs deaths, though in this case we delay the deaths relative to confirmed cases (someone who has just died was probable confirmed several days ago) -- also, given that it must take several days to get sick enough to die, our time series isn't really long enough yet.  But we do find that assuming longer times increases the mortality rate.  We also see that (at least with this length of time series), the delayed CFR is not stable but decreasing strongly with time, though the 3 day delay may be flatting at the end.","b38935d0":"I want to start with a HUGE caveat -- I\"m a data scientist with a background in Physics. I know nothing about biology or diseases. What I have put in this kernel is to satisfy my own curiousity and I'm making the kernal public in case others are interested.  I'd love feedback from pythonistas or disease experts on the code and\/or the assumptions.  ","eb370c71":"In any case, it was very interesting to use this data and answer some questions I've had. Thanks for uploading it!","4e32b683":"Now I create a couple columns for CFR (case fatality rate -- the official mortality rate) and what I'm calling FC or \"final count\" where final means that the person has either recovered or died -- so no more change is possible.  \n\nAnd now we plot those two columns vs time delta from current day.","4f28380b":"So this has  the same shape as above, but only peaks at 24%\n\nPlaying with different delays (below), we shorter delays causes a sharper peak\/drop, but longer delays causes a flattening. This will be interesting to revisit as time goes on","c8c12187":"Looking at a range of delays from 1 to 10 we see some flattening for longer delays and a 9 or 10 day delay has a positive slope. Something around 7 or 8 days may make the most sense.  ","47fcfc4c":"So, the actually \"death rate\" is somewhere between the above two curves, and we can see that the dead + recovered curve has a nice, reassuring negative slope and will most likely asymptotically approach the lower line as time goes on (important note -- these numbers are only for those sick enough to be tested!  Mild, unreported cases would reduce both numbers considerably!!)\n\nNow, if someone gets really sick, but doesn't die, it will take them a few days to be in the \"recovered\" category, so we should assume some number of days delay between the \"dead\" and \"recovered\" curves.  Let's start with assuming 5 days delay.","9e2c106f":"I have been curious about the mortality rate for the coronavirus.  I know the official rate is the number of deaths divided by the number of confirmed cases. But I keep thinking that since people who are still sick may yet die, it seems like # deaths\/# cases would be an underestimate of the true death rate -- someone who was just confirmed with the virus has awhile to go before they're safe. However, if you look at the number of deaths vs the number of recoveries, that is frightening close to even, though the number of recovered patients is growing much faster than the number of deaths.  So I wanted to play a bit with delays between the different variables.  ","16747166":"Plotting delays from 0 to 10 days shows a that the 0 day delay is significantly flatter and longer delays leads to a sharp slope with time. This gives some support to using the current CFR method of # deaths \/ # confirmed (in short -- listen to the experts). "}}