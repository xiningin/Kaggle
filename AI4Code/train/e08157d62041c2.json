{"cell_type":{"85c9e800":"code","260504ff":"code","8bc1b8e7":"code","c062bd0e":"code","630caa9a":"code","a20d11da":"code","b127d111":"code","f33fe2fe":"code","eda135d2":"code","d2a76aab":"code","ddddedc3":"code","d70c9140":"code","6fc19aa1":"code","ae3f3cf2":"code","5eab93ef":"code","d0d656ee":"markdown","4dd50f41":"markdown","7479f15a":"markdown","63f08f22":"markdown","2a9da7f3":"markdown","bb4c5a76":"markdown","10a6e938":"markdown","ae68ad85":"markdown","be54686a":"markdown"},"source":{"85c9e800":"import os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom sklearn.metrics import classification_report, confusion_matrix","260504ff":"BATCH_SIZE = 500\nEPOCHS = 50\nLEARNING_RATE = 0.0001","8bc1b8e7":"test_dir = '..\/input\/dogs-cats-images\/dataset\/test_set\/'\ntrain_dir = '..\/input\/dogs-cats-images\/dataset\/training_set\/'","c062bd0e":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Resize((128, 128)),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n)","630caa9a":"train_folder = ImageFolder(root=train_dir,transform=transform)\ntest_folder = ImageFolder(root=test_dir,transform=transform)","a20d11da":"train_folder.classes","b127d111":"train_loader = DataLoader(train_folder,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True)\ntest_loader = DataLoader(test_folder,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True)","f33fe2fe":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net,self).__init__()\n        self.main = nn.Sequential(\n                        nn.Conv2d(3, 16, 4, 2, 1, bias = False),                       \n                        nn.LeakyReLU(0.2, inplace = True),\n                        nn.Conv2d(16, 32, 4, 2, 1, bias = False),\n                        nn.BatchNorm2d(32),                        \n                        nn.LeakyReLU(0.2, inplace = True),\n                        nn.Conv2d(32, 64, 4, 2, 1, bias = False),\n                        nn.BatchNorm2d(64),\n                        nn.LeakyReLU(0.2, inplace = True),\n                        nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n                        nn.BatchNorm2d(128),\n                        nn.LeakyReLU(0.2, inplace = True),\n                        nn.Conv2d(128, 1, 8, 1, 0, bias = False),                        \n                        nn.Sigmoid()\n                        )\n    \n    def forward(self, x):          \n        return self.main(x).view(-1)\nnet = Net()","eda135d2":"for p in net.parameters():\n    print(p.shape)","d2a76aab":"device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nprint('Using: ',device)\nif not (device == 'cpu'):\n    net.to(device)","ddddedc3":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.9)","d70c9140":"epoch_loss = []\nfor epoch in range(EPOCHS):  \n    print('Epochs: [%d\/%d]' % (epoch+1,EPOCHS))\n    running_loss = 0.0\n    \n    for i, data in enumerate(train_loader, 0):        \n        if not (device == 'cpu'):\n            inputs, labels = data[0].to(device),data[1].to(device)\n        else:            \n            inputs, labels = data\n        \n        optimizer.zero_grad()\n        \n        outputs = net(inputs)\n        \n        outputs= outputs.unsqueeze(1)\n        labels = labels.unsqueeze(1).type_as(outputs)        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n    # print every epoch\n    epoch_loss.append((running_loss \/ (i+1)))\n    print('loss: %.3f' % (running_loss \/ (i+1))) #Average loss per batch in epoch\n        \n\nprint('Finished Training')","6fc19aa1":"plt.plot(epoch_loss)","ae3f3cf2":"y_pred_list = []\ny_true_list = []\nwith torch.no_grad():\n    for x_batch, y_batch in test_loader:\n        if not (device == 'cpu'):\n            x_batch, y_batch = x_batch.to(device), y_batch.to(device)  \n            \n        y_test_pred = net(x_batch)      \n           \n        y_test_pred[y_test_pred<0.5] = 0\n        y_test_pred[y_test_pred>=0.5] = 1\n        \n        y_pred_list.append(y_test_pred.cpu().numpy())\n        y_true_list.append(y_batch.cpu().numpy()) ","5eab93ef":"y_pred_list = np.hstack(np.asarray(y_pred_list))\ny_true_list = np.hstack(np.asarray(y_true_list))\n\nprint(confusion_matrix(y_true_list,y_pred_list))\nprint(classification_report(y_true_list,y_pred_list))","d0d656ee":"# 3. Load and transform","4dd50f41":"It's simple classifier that achieves ~ 60% accuracy right now. ","7479f15a":"# 5. Training","63f08f22":"# 7. Results","2a9da7f3":"# 4. Network architecture","bb4c5a76":"# 1. Imports","10a6e938":"# Dogs vs Cats binary classifier using PyTorch","ae68ad85":"# 2. Settable Parameters","be54686a":"# 6. Testing"}}