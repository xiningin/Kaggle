{"cell_type":{"13d11a68":"code","f759c680":"code","f1a77f7c":"code","6a709305":"code","457600a8":"code","e064e23a":"code","e5c9872f":"code","d09c0337":"code","cd02f958":"code","e17deec9":"code","dc57e56d":"code","3723787c":"code","14024e54":"code","9354c322":"code","bf033783":"code","bf060e90":"code","ed303a70":"code","25aad3df":"code","6570b539":"code","a6f6d1f2":"code","4f0da13f":"code","f04d8ed1":"code","7fdb11b0":"code","37ca629c":"code","5764f9c8":"code","9bf5ab56":"code","b8b0c214":"code","6cfa50d8":"code","bb23715d":"code","9097ac70":"code","e8fd42a4":"code","9198f02d":"code","e6e3e8cd":"code","d6d8b089":"code","8b402e55":"code","dd6d547f":"code","31e17f17":"code","31f9bd56":"code","32b07363":"code","78102662":"code","8ece9c65":"markdown","2875cb71":"markdown","fada91a9":"markdown","3d9963dc":"markdown","68bf5565":"markdown","53d3735d":"markdown","47eadded":"markdown","a64d035f":"markdown","be10b1f0":"markdown","cf49f5e1":"markdown"},"source":{"13d11a68":"import numpy as np \nimport pandas as pd \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nfrom sklearn.metrics import precision_score, accuracy_score,  confusion_matrix, classification_report, auc, roc_curve\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f759c680":"add = pd.read_csv('..\/input\/advertsuccess\/Train.csv')","f1a77f7c":"# print the size of the data\nadd.shape","6a709305":"# checking the first 5 row of data set\nadd.head()","457600a8":"# get the brief information about dataset\nadd.info()","e064e23a":"# get the aggregation\nadd.describe()","e5c9872f":"# make id as index\nadd.set_index('id', inplace=True)\n\n# sort index\nadd.sort_index(ascending=True, inplace=True)","d09c0337":"# check missing values\nadd.isnull().sum()","cd02f958":"# check the number of unique value in each column\nfor cols in add.columns:\n    print(cols, '--> ',add[cols].nunique())","e17deec9":"#Understanding the target variable netgain.\n# We can see that the count of unsuccessful ads are higher.\n\nsns.countplot('netgain',data = add)\nplt.show()","dc57e56d":"# method to add percentage on the plot\ndef add_percentage(ax, total):\n    for i in ax.patches:\n        height = i.get_height()\n        ax.text(i.get_x()+i.get_width()\/2.,height + 5,'{:1.2f}'.format(height\/total*100) + '%')","3723787c":"# Around 76% of the ad campaigns are not successful.\n# 0 - False = ad campaign not successful.\n# 1 - True = ad campaign successful.\n\ntotal = float(len(add))\nplt.title('Netgain sucess and failure percentage')\nax = sns.countplot(x=\"netgain\", data=add)\n\nadd_percentage(ax, total)","14024e54":"for cols in add.columns:\n    if add[cols].dtype == 'O':\n        total = float(len(add))\n        plt.figure(figsize=(15,4.5))\n        plt.title('Netgain success based on '+ cols, fontsize=24)\n        ax = sns.countplot(x=cols, data=add, hue='netgain')\n\n        add_percentage(ax, total)\n        plt.show()","9354c322":"# As suspected above, yes Pharma industry dominates the other sectors and has the highest count of more than 10000 observations\n# realted to it.Around 40% of the industry sector is contributed to Pharma industry and it also has high count of successful ads.\n\ntotal = float(len(add))\nplt.figure(figsize=(15,4.5))\nplt.title('Netgain sucess and failure percentage')\nax = sns.countplot(x=\"industry\", data=add)\n\nadd_percentage(ax, total)","bf033783":"# We can see that the average run time of the ads per week is around 40 mins \n# i.e the ads were aired around 40 mins per week.\n\nplt.figure(figsize=(15,6))\nsns.distplot(add['average_runtime(minutes_per_week)'])\nplt.show()","bf060e90":"plt.figure(figsize=(25,20))\nsns.factorplot(data=add,x='netgain',y='ratings',hue='genre')\nplt.show()","ed303a70":"# Daytime ads are run more amount of time compared to the other airtimes. \n\nsns.catplot(x='airtime', y='average_runtime(minutes_per_week)', data=add, kind='boxen', aspect=2)\nplt.title('Boxen Plot', weight='bold', fontsize=16)\nplt.show()","25aad3df":"# Ads from pharma industry are aired more compared to others.\n\nplt.figure(figsize=(200,400))\nsns.factorplot(data=add,x='industry',y='average_runtime(minutes_per_week)')\nplt.title('Factor Plot', weight='bold', fontsize=16)\nplt.show()","6570b539":"# Splitting the independent and target variables.\nx = add.iloc[:, :-1]\ny = add.iloc[:, -1]","a6f6d1f2":"# convert categorical variable to numerical\nfrom sklearn.preprocessing import LabelEncoder\n\ny = LabelEncoder().fit_transform(y)\nx = x.apply(LabelEncoder().fit_transform)","4f0da13f":"# print the size of x and y\ny.shape, x.shape","f04d8ed1":"# train and test split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n\nprint('X train size: ', x_train.shape)\nprint('y train size: ', y_train.shape)\nprint('X test size: ', x_test.shape)\nprint('y test size: ', y_test.shape)","7fdb11b0":"# Decision tree classifier with grid seacrh CV and model evaluation using accuracy score, precision score and AUC\/ROC curve.\n\nparm = {'max_features': [0.5,0.6,0.7,0.8,0.9,1.0], 'max_depth': [2,3,4,5,6,7,8,9],'min_samples_leaf':[1,10,15,20,25,100],'random_state':[14]}\n\ndtc_grid = GridSearchCV(DecisionTreeClassifier(), parm, cv=5, scoring='roc_auc')\ndtc_grid.fit(x_train, y_train)","37ca629c":"print('The best parameters are: ', dtc_grid.best_params_)\nprint('best mean cross-validated score (auc) : ', dtc_grid.best_score_)","5764f9c8":"y_pred = dtc_grid.predict(x_test)\nprecision_score_DT_test =  precision_score(y_test, y_pred)\naccuracy_score_DT_test = accuracy_score(y_test, y_pred)\nprint('The precision score of decision tree on TEST is : ',round(precision_score_DT_test * 100,2), '%')\nprint('The accuracy score of decision tree on TEST is : ',round(accuracy_score_DT_test * 100,2), '%')","9bf5ab56":"adsu = dtc_grid.predict_proba(x_test)[:,1]\nplt.subplots(figsize=(8,6))\nfpr, tpr, thresholds = roc_curve(y_test, adsu)\nplt.plot(fpr, tpr, label=\"ROC Curve\")\nx = np.linspace(0,1,num=50)\nplt.plot(x,x,linestyle='--',marker='',lw=2,label='random guess')\nplt.legend(fontsize = 14)\nplt.xlabel('False positive rate', fontsize = 18)\nplt.ylabel('True positive rate', fontsize = 18)\nplt.xlim(0,1,4)\nplt.ylim(0,1,4)\nplt.show()\n\nAUC_DT = auc(fpr,tpr)\nprint('DT AUC is: ', round(AUC_DT * 100,2), '%')","b8b0c214":"print ('\\nClassification Report TEST:\\n', classification_report(y_test,y_pred))","6cfa50d8":"from sklearn.ensemble import RandomForestClassifier\n\nparam = {'n_estimators':[700],'n_jobs':[-1], 'max_features': [0.5,0.7,0.9], 'max_depth': [3,5,7],'min_samples_leaf':[1,10],'random_state':[14]}\n\nrfc_grid = GridSearchCV(RandomForestClassifier(), param, cv=5, scoring='roc_auc')\nrfc_grid.fit(x_train, y_train)","bb23715d":"print('The best parameters are: ', rfc_grid.best_params_)\nprint('best mean cross-validated score (auc) : ', rfc_grid.best_score_)","9097ac70":"y_pred = rfc_grid.predict(x_test)\nprecision_score_RF_test =  precision_score(y_test, y_pred)\naccuracy_score_RF_test = accuracy_score(y_test, y_pred)\nprint('The precision score on TEST is : ',round(precision_score_RF_test * 100,2), '%')\nprint('The accuracy score on TEST is : ',round(accuracy_score_RF_test * 100,2), '%')","e8fd42a4":"# Now let's plot the ROC curve and calculate AUC on the test set\n\nadsu = rfc_grid.predict_proba(x_test)[:,1]\nplt.subplots(figsize=(8,6))\nfpr, tpr, thresholds = roc_curve(y_test, adsu)\nplt.plot(fpr, tpr, label='ROC Curve')\nx = np.linspace(0,1,num=50)\nplt.plot(x,x,linestyle='--',marker='',lw=2,label='random guess')\nplt.legend(fontsize = 14)\nplt.xlabel('False positive rate', fontsize = 18)\nplt.ylabel('True positive rate', fontsize = 18)\nplt.xlim(0,1)\nplt.ylim(0,1)\nplt.show()\n\nAUC_RF = auc(fpr,tpr)\nprint('RF AUC is: ', round(AUC_RF * 100,2), '%')","9198f02d":"print ('\\nClassification Report TEST:\\n', classification_report(y_test,y_pred))","e6e3e8cd":"from sklearn.neighbors import KNeighborsClassifier\n\nknc = KNeighborsClassifier(n_neighbors=3)\n\nknc_bc = BaggingClassifier(base_estimator=knc, n_estimators=30, max_samples=0.8, max_features=0.8)\n\nknc_bc.fit(x_train, y_train)","d6d8b089":"y_pred = knc_bc.predict(x_test)\nprecision_score_RF_test =  precision_score(y_test, y_pred)\naccuracy_score_RF_test = accuracy_score(y_test, y_pred)\nprint('The precision score  on TEST is : ',round(precision_score_RF_test * 100,2), '%')\nprint('The accuracy score  on TEST is : ',round(accuracy_score_RF_test * 100,2), '%')","8b402e55":"# Now let's plot the ROC curve and calculate AUC on the test set\n\nadsu = rfc_grid.predict_proba(x_test)[:,1]\nplt.subplots(figsize=(8,6))\nfpr, tpr, thresholds = roc_curve(y_test, adsu)\nplt.plot(fpr, tpr, label='ROC Curve')\nx = np.linspace(0,1,num=50)\nplt.plot(x,x,linestyle='--',marker='',lw=2,label='random guess')\nplt.legend(fontsize = 14)\nplt.xlabel('False positive rate', fontsize = 18)\nplt.ylabel('True positive rate', fontsize = 18)\nplt.show()\n\nAUC_RF = auc(fpr,tpr)\nprint('RF AUC is: ', round(AUC_RF * 100,2), '%')","dd6d547f":"print ('\\nClassification Report TEST:\\n', classification_report(y_test,y_pred))","31e17f17":"from sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n\nrfClf = RandomForestClassifier(n_estimators=500, random_state=0) # 500 trees. \nsvmClf = SVC(probability=True, random_state=0) # probability calculation\nlogClf = LogisticRegression(random_state=0)\n\nvc = VotingClassifier(estimators= [('rf',rfClf), ('svm',svmClf), ('log', logClf)], voting='soft')\n\nvc.fit(x_train, y_train)","31f9bd56":"y_pred = vc.predict(x_test)\nprecision_score_RF_test =  precision_score(y_test, y_pred)\naccuracy_score_RF_test = accuracy_score(y_test, y_pred)\nprint('The precision score  on TEST is : ',round(precision_score_RF_test * 100,2), '%')\nprint('The accuracy score  on TEST is : ',round(accuracy_score_RF_test * 100,2), '%')","32b07363":"# Now let's plot the ROC curve and calculate AUC on the test set\n\nadsu = vc.predict_proba(x_test)[:,1]\nplt.subplots(figsize=(8,6))\nfpr, tpr, thresholds = roc_curve(y_test, adsu)\nplt.plot(fpr, tpr, label='ROC Curve')\nx = np.linspace(0,1,num=50)\nplt.plot(x,x,linestyle='--',marker='',lw=2,label='random guess')\nplt.legend(fontsize = 14)\nplt.xlabel('False positive rate', fontsize = 18)\nplt.ylabel('True positive rate', fontsize = 18)\nplt.show()\n\nAUC_RF = auc(fpr,tpr)\nprint('RF AUC is: ', round(AUC_RF * 100,2), '%')","78102662":"print ('\\nClassification Report TEST:\\n', classification_report(y_test,y_pred))","8ece9c65":"\nAmong all predictions for ad to be successful, 68.92% are successful.\n\n82.48 % of the succcessful ads were predicted correctly.","2875cb71":"# Bagging\n\n## Bagging using Random Forest","fada91a9":"# Load Library","3d9963dc":"## Decision Tree Classifier","68bf5565":"# Load Dataset","53d3735d":"## Bagging using BaggingClassifier\n\n## We will use -> k-nearest neighbor ","47eadded":"## We will try to find out if add campaign is successfully or not","a64d035f":"\nAmong all predictions for add, 64.16% are successful.\n\n81.67 % of the succcessful ads were predicted correctly.","be10b1f0":"## Bagging using Voting Classifier\n## We will use -> support vector machine, Random Forest, Logistic Regression","cf49f5e1":"# Exploratory data analysis "}}