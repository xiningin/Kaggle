{"cell_type":{"3b568939":"code","14f68938":"code","f227f17b":"code","1d862b3b":"code","c78c93d0":"code","912417d5":"code","a2e9a252":"code","6574f5df":"code","ae432177":"code","47b62a13":"code","e59a9d7e":"code","bfade387":"code","88e60f6e":"code","5c555fe0":"markdown","0929e3bf":"markdown","aca0ba71":"markdown","8f5863c7":"markdown"},"source":{"3b568939":"%matplotlib inline\n\nimport pandas as pd\nimport os\nimport sys\n\n# check the current directory\ncwd = os.getcwd()\nprint ('Current directory: {}'.format(cwd))\n\n# create new directories\nnew_folder_paths = ['Train',\n                    os.path.join('Train','Beauty'),\n                    os.path.join('Train','Fashion'),\n                    os.path.join('Train','Mobile'),\n                    'Test',\n                    os.path.join('Test','Beauty'),\n                    os.path.join('Test','Fashion'),\n                    os.path.join('Test','Mobile')]\n\nfor folder_path in new_folder_paths:\n    if (os.path.isdir(folder_path) is False):\n        os.mkdir(folder_path)\n\n'''\nWe now reorganize image files in training set\n'''\n\ntrain_data = pd.read_csv('train.csv')\nn_labels = 58\nfolder_path_dict = {i:'Beauty' for i in range(17)}\nfolder_path_dict.update({i:'Fashion' for i in range(17, 31, 1)})\nfolder_path_dict.update({i:'Mobile' for i in range(31, 58, 1)})\n\n\nfor category in range(n_labels):\n        \n    category_img_paths = train_data[train_data['Category']==category]['image_path'].values.tolist()\n    folder_path = os.path.join('Train', folder_path_dict[category], str(category))\n\n    if (os.path.isdir(folder_path) is False):\n        os.mkdir(folder_path)\n\n    for img_path in category_img_paths:\n        img_name = img_path.split('\/')[1]\n        \n        # some image paths does not contain file extension\n        if (img_name[-4:] != '.jpg'):\n            img_name += '.jpg'\n            img_path += '.jpg'\n            \n        # if there is no image found, just pass and we will have a look later on\n        try:\n            os.rename(img_path, os.path.join(folder_path, img_name))\n        except FileNotFoundError:\n            pass\n\ntest_data = pd.read_csv('test.csv')\ncategory_img_paths = test_data['image_path'].values.tolist()\nfor img_path in category_img_paths:\n    img_master_label, img_name = img_path.split('\/')\n    \n    if (img_master_label == 'beauty_image'):\n        folder_path = os.path.join('Test', 'Beauty')\n    elif (img_master_label == 'fashion_image'):\n        folder_path = os.path.join('Test', 'Fashion')\n    else:\n        folder_path = os.path.join('Test', 'Mobile')\n        \n    if (img_name[-4:] != '.jpg'):\n            img_name += '.jpg'\n            img_path += '.jpg'\n      \n    try:\n        os.rename(img_path, os.path.join(folder_path, img_name))\n    except FileNotFoundError:\n        pass","14f68938":"import json\n\nwith open('categories.json') as json_file:\n    labels = json.load(json_file)\nnumerical2label = {}\n\nfor master_label in labels.keys():\n    master_dict = labels[master_label]\n    for item_name, item_idx in master_dict.items():\n        numerical2label[item_idx] = item_name\n        \nlabel2numerical = {}\nfor item_idx, item_name in numerical2label.items():\n    label2numerical[item_name] = item_idx","f227f17b":"# Source: https:\/\/github.com\/fchollet\/deep-learning-with-python-notebooks\/blob\/master\/5.2-using-convnets-with-small-datasets.ipynb\nimport os, shutil\n\n\n# Directories for our training,\n# validation and test splits\nbase_dir = os.path.join(os.getcwd(), 'Train', 'Beauty')\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nvalidation_dir = os.path.join(base_dir, 'validate')\nos.mkdir(validation_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\n# Directory with our training categories\nn_labels = 17\nfor category_id in range(n_labels):\n    category_name = numerical2label[category_id]\n    train_category_dir = os.path.join(train_dir, category_name)\n    if (os.path.isdir(train_category_dir) is False):\n        os.mkdir(train_category_dir)\n\n# Directory with our validation categories\nfor category_id in range(n_labels):\n    category_name = numerical2label[category_id]\n    validation_category_dir = os.path.join(validation_dir, category_name)\n    if (os.path.isdir(validation_category_dir) is False):\n        os.mkdir(validation_category_dir)\n\n# Directory with our test categories\nfor category_id in range(n_labels):\n    category_name = numerical2label[category_id]\n    test_category_dir = os.path.join(test_dir, category_name)\n    if (os.path.isdir(test_category_dir) is False):\n        os.mkdir(test_category_dir)","1d862b3b":"for category in range(n_labels):\n    print('Category {0}|{1} \\t has {2} images.'.format(numerical2label[category],\n                                                    category,\n                                                    len(os.listdir(os.path.join(base_dir, str(category))))))","c78c93d0":"train_ratio = 0.7; validation_ratio = 0.1; test_ratio = 0.2\n\nfor category in range(n_labels):\n    category_size = len(os.listdir(os.path.join(base_dir, str(category))))\n    train_size = int(train_ratio * category_size)\n    validation_size = int(validation_ratio * category_size)\n    test_size = category_size - (train_size + validation_size)\n    \n    # Copy data from category_dir to create train set for category\n    category_dir = os.path.join(base_dir, str(category))\n    train_category_dir = os.path.join(train_dir, numerical2label[category])\n    fnames = os.listdir(category_dir)[0:train_size]\n    for fname in fnames:\n        src = os.path.join(category_dir, fname)\n        dst = os.path.join(train_category_dir, fname)\n        shutil.copyfile(src, dst)\n        \n    # Copy data from category_dir to create validation set for category\n    validation_category_dir = os.path.join(validation_dir, numerical2label[category])\n    fnames = os.listdir(category_dir)[train_size:train_size+validation_size]\n    for fname in fnames:\n        src = os.path.join(category_dir, fname)\n        dst = os.path.join(validation_category_dir, fname)\n        shutil.copyfile(src, dst)\n\n    # Copy data from category_dir to create test set for category\n    test_category_dir = os.path.join(test_dir, numerical2label[category])\n    fnames = os.listdir(category_dir)[train_size+validation_size:]\n    for fname in fnames:\n        src = os.path.join(category_dir, fname)\n        dst = os.path.join(test_category_dir, fname)\n        shutil.copyfile(src, dst)","912417d5":"from keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size=(150, 150),\n        batch_size=20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='categorical')\n\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='categorical')","a2e9a252":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',\n                        input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(17, activation='softmax'))","6574f5df":"model.summary()","ae432177":"from keras import optimizers\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.adam(),\n              metrics=['acc'])","47b62a13":"history = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=30,\n      validation_data=validation_generator,\n      validation_steps=50)","e59a9d7e":"model.save('cnn_baseline_beauty.h5')","bfade387":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","88e60f6e":"test_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='categorical')\n\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc:', test_acc)","5c555fe0":"# 2. Train a CNN for beauty images.","0929e3bf":"It may take up to 40 minutes to finish copying files. The goal of the script is to re-organize the whole image dataset in such a way that it is easy to load and train. You can find 2 news folders:\n```\nNDSC_project    \n|-- Train\n|   |-- Beauty\n|   |   |-- 0\n|   |   |-- 1 \n|   |   |-- ...\n|   |-- Fashion\n|   |   |-- 17\n|   |   |-- 18 \n|   |   |-- ...\n|   |-- Mobile\n|   |   |-- 31\n|   |   |-- 32\n|   |   |-- ...\n|-- Test\n|   |-- Beauty\n|   |-- Fashion\n|   |-- Mobile\n```","aca0ba71":"# 1. Reorganize directory tree\n\nYou should have directory tree with following structure:\n```\nNDSC_project    \n|-- train.csv\n|-- test.csv\n|-- this_jupyter_notebook.ipynb\n|-- categories.json\n|-- beauty_image\n|   |-- 000004d60c92af4390399d71a305f64b.jpg\n|   |-- 0000113904d1bc15232ee3b8a5432254.jpg\n|   |-- ...\n|-- fashion_image\n|   |-- 000006831bfaf0e3b5ce3564a10e6dd4.jpg\n|   |-- 6819bac64db6f99d6dc37a897c0e9651.jpg\n|   |-- ...\n|-- mobile_image\n|   |-- 0000456f97a4805ba4960084ffc8c058.jpg\n|   |-- 454bdaf9438c099583957964914ffbe5.jpg\n|   |-- ...\n```","8f5863c7":"# Instruction to set up a baseline CNN to train an image classifier\n\nIn this tutorial, I will show you how to train a simple CNN on the beauty image subset. Here are what you need:\n- `keras` installed, with GPU.\n-  enough space to extract the dataset; ideally, it should be at least 90GB. FYI, the format `.tar.gz`, as in `beauty_image.tar.gz`, is in fact a file name extension indicating this is a compressed file, similar to `.zip`.  I used Hamster Zip Archiver software (Windows) to extract, even though it is easier to do so in Linux, i.e. type in the terminal\n```sh\ntar -zxvf yourfile.tar.gz\n```\n\nYou can then set up a simple CNN as following steps:\n1. Reorganize directory tree\n2. Train a CNN for beauty images.\n\n> **NOTE**: ignore the warning error here and run it on your local machine. \n"}}