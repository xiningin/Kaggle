{"cell_type":{"d213e174":"code","91d4771a":"code","7060e10a":"code","52c9badd":"code","36a24d28":"code","843ff168":"code","df804bff":"code","39db1a65":"code","6abb7e94":"code","21aa49e7":"code","52ce5f29":"code","c859e39c":"code","4709d84a":"code","ed457810":"code","0f709cf2":"code","43c5a884":"code","2b3320ad":"code","96dec898":"code","a9bca24e":"code","14b55192":"code","165d7dc0":"code","b13d9531":"code","3d1ec0dc":"code","7f499ba7":"code","aac05f2b":"code","db5414e4":"code","90cee736":"code","365cba85":"markdown","c8074fe8":"markdown","5fb31a8c":"markdown","fdde7aa7":"markdown","0341c67d":"markdown","d757cf6e":"markdown","860bfdf0":"markdown","1247eeb0":"markdown","1a394a5e":"markdown","ef9fcf69":"markdown","d98865b6":"markdown","6e7a9178":"markdown","10c96be4":"markdown","22f58684":"markdown"},"source":{"d213e174":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","91d4771a":"!pip install pycaret","7060e10a":"data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata.head()","52c9badd":"from pycaret.regression import *","36a24d28":"exp_reg = setup(data, target='SalePrice', log_experiment = True, experiment_name = 'exp_reg')","843ff168":"compare_models(sort=\"RMSE\",\n               exclude = ['tr','xgboost','catboost'],\n              )","df804bff":"OMP = create_model('omp', verbose=False)\nLIGHTGBM = create_model('lightgbm', verbose=False)","39db1a65":"tuned_OMP = tune_model(OMP, optimize='MAE')\ntuned_LIGHTGBM = tune_model(LIGHTGBM, optimize='RMSE')","6abb7e94":"plot_model(tuned_OMP, plot='error')","21aa49e7":"plot_model(tuned_LIGHTGBM, plot='error')","52ce5f29":"plot_model(tuned_OMP, plot='feature')","c859e39c":"plot_model(tuned_LIGHTGBM, plot='feature')","4709d84a":"predict_model(tuned_OMP)","ed457810":"predict_model(tuned_LIGHTGBM)","0f709cf2":"evaluate_model(tuned_OMP)","43c5a884":"evaluate_model(tuned_LIGHTGBM)","2b3320ad":"final_OMP = finalize_model(tuned_OMP)","96dec898":"test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","a9bca24e":"test.head()","14b55192":"predictions = predict_model(final_OMP, data = test)","165d7dc0":"predictions.head(2000)","b13d9531":"prediction = pd.DataFrame(predictions, columns=['Id','Label']).to_csv('prediction.csv')","3d1ec0dc":"save_model(final_OMP , model_name = 'abc')","7f499ba7":"l = load_model('abc')","aac05f2b":"from pycaret.regression import load_model,predict_model\nl = load_model('abc')\np = predict_model(l, data=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv'))\np.head()","db5414e4":"from sklearn import set_config\nset_config(display ='diagram')","90cee736":"l","365cba85":"![image.png](attachment:3e1f3808-189d-422b-8a36-17402a06ed4a.png)","c8074fe8":"**Without doing any transformations let\u2019s initialise PyCaret where target column being SalePrice right at the end.**","5fb31a8c":"**Lets first import the regression libraries for PyCaret as well and pandas to read in the data.**","fdde7aa7":"**Now let\u2019s read in the data and take a look at the top 5 rows.**","0341c67d":"**Let's test the performance of our model on the test data.**","d757cf6e":"**Finalize the model, I will go with OMP model given it's RMSE value and correctness compared to the other model.**","860bfdf0":"**Checking Important Features**","1247eeb0":"**Let's have a look at all the available models and sort them by the RMSE (Root Mean Squared Error) to review their performance, Also, within the code snipped I have used exclude option to ignore TheilSen Regressor and Extreme Gradient Boosting models as they were taking way too long time, like >10 hrs :(**","1a394a5e":"**Let's Predict**","ef9fcf69":"Want to deploy your model on to the AWS bucket\n\n#deploy_model(OMP. 'abc', platform = 'aws',\n#authentication = {'bucket' : 'name of your aws bucket'})","d98865b6":"**Picked two best performing models based on their RMSE and MAE metrics**","6e7a9178":"# **Lets install the all mighty PyCaret Library!**","10c96be4":"**Let\u2019s take the top 2 models, tune them and work with those for the remainder of this analysis. This means we need to create models from them. We can do this using create_models() as follows.**","22f58684":"**Let's see how they are performing post tuning compared to the best fit values.**"}}