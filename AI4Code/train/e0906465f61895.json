{"cell_type":{"dc6aa2a6":"code","75519154":"code","9b32c9df":"code","2e5917b0":"code","c05acec4":"code","1154ab55":"code","2076f594":"code","8d2b1ff6":"code","9a03e53b":"code","88a501bb":"code","041458e4":"code","b6a616d8":"code","5e50fdc2":"code","17f4381c":"code","e51b0327":"code","80350457":"markdown"},"source":{"dc6aa2a6":"import base64\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os, glob, time, copy\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms, models\nfrom PIL import Image\nfrom sklearn.metrics import classification_report\nfrom IPython.display import HTML","75519154":"###Training Phase 1###\n###A Classifier to identify the manufacturer of the car###\nINDIVIDUAL_CLASSES = [x.split(' ')[0] for x in os.listdir('..\/input\/car_data\/car_data\/train\/')]\nCOMPANIES = list(set(INDIVIDUAL_CLASSES))\nNUM_CLASSES = len(COMPANIES)\nROOT_DIR = '..\/input\/car_data\/car_data'\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nDATA_TRANSFORMS = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n    ]),\n    'test': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n    ]),\n}","9b32c9df":"###Analyzing the dataset###\nc = 0\nfor company in COMPANIES:\n    models_count = INDIVIDUAL_CLASSES.count(company)\n    print (\"{0}: {1}\".format(company, models_count))\n    if (models_count != 1): c += 1\nprint (\"Companies with more than 1 model: {0}\".format(c))","2e5917b0":"class CarDS(Dataset):\n    def __init__(self, root, phase, transforms):\n        self.filenames = []\n        self.root = root\n        self.phase = phase\n        self.transform = transforms\n        self.classes = os.listdir(root)\n        self.labels = []\n        for dir in os.listdir(root):\n            path = os.path.join(self.root, dir)\n            filenames = glob.glob(os.path.join(path, '*'))\n            for fn in filenames:\n                self.filenames.append(fn)\n                self.labels.append(COMPANIES.index(dir.split(' ')[0]))\n        self.labels = np.array(self.labels)\n        self.len = len(self.filenames)\n        \n    def __getitem__(self, index):\n        image = Image.open(self.filenames[index])\n        image = image.convert('RGB')\n        image = self.transform(image)\n        return image, self.labels[index]\n\n    def __len__(self):\n        return self.len","c05acec4":"def plot_xy(x, y, title=\"\", xlabel=\"\", ylabel=\"\"):\n    plt.figure()\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    for i in range(len(y)):\n        plt.plot(x, y[i], label = str(i))\n    plt.show()\n\ndef get_count_per_class(data_dir, phase = 'train'):\n    train_labels_count = [0]*NUM_CLASSES\n    phase_path = os.path.join(data_dir, phase)\n    for ind, dir in enumerate(os.listdir(phase_path)):\n        path, dirs, files = next(os.walk(os.path.join(phase_path, dir)))\n        file_count = len(files)\n        act_ind = COMPANIES.index(dir.split(' ')[0])\n        train_labels_count[act_ind] += file_count\n    return train_labels_count\n\ndef plot_images_per_class(labels_count=None, phase = 'train'):\n    if (labels_count is None):\n        labels_count = get_count_per_class(phase)\n    plt.figure()\n    f, ax = plt.subplots(figsize=(25,10))\n    plt.bar(COMPANIES, labels_count)\n    plt.xticks(rotation=90)\n    #plt.xticks(np.arange(102), np.arange(102))\n    plt.ylabel(\"No. of samples\")\n    plt.xlabel(\"Classes\")\n    plt.title(phase)\n    plt.show()\n    \ndef train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    losses = {'train': [], 'valid':[]}\n    acc = {'train': [], 'valid': []}\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(DEVICE)\n                labels = labels.to(DEVICE)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            losses[phase].append(epoch_loss)\n            acc[phase].append(epoch_acc)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n            if (phase == 'valid' and epoch + 1 == num_epochs):\n                print (\"-\" * 15)\n                print (\"Final Classification Report\")\n                print (\"-\" * 15)\n                print (classification_report(preds.cpu(), labels.cpu()))\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    plot_xy(np.arange(num_epochs), [losses['train'], losses['valid']], xlabel = 'Epochs', ylabel = 'Loss', title = 'Loss Plot')\n    plot_xy(np.arange(num_epochs), [acc['train'], acc['valid']], xlabel = 'Epochs', ylabel = 'Accuracy', title = 'Accuracy Plot')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","1154ab55":"dataset = CarDS(os.path.join(ROOT_DIR, 'train'), phase = 'train', transforms = DATA_TRANSFORMS['train'])\ntrain_size = int(0.90 * len(dataset))\nvalid_size = len(dataset) - train_size\nprint (\"Train Size: {0}\".format(train_size))\nprint (\"Validation Size: {0}\".format(valid_size))\nlabels_count = get_count_per_class('..\/input\/car_data\/car_data', phase='train')\nplot_images_per_class(labels_count)\ndataset_sizes = {'train': train_size, 'valid': valid_size}\ntrain_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\ndataloaders = {'train': DataLoader(train_dataset, batch_size = 64, shuffle = True),\n              'valid': DataLoader(valid_dataset, batch_size = 64, shuffle = False)}","2076f594":"model = models.resnet101(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, NUM_CLASSES)\nmodel = model.to(DEVICE)\nclass_weights = [1-(float(labels_count[class_id])\/(len(dataset))) for class_id in range(NUM_CLASSES)]\ncriterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(DEVICE))\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","8d2b1ff6":"model = train_model(dataloaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)","9a03e53b":"###Training Phase 2###\n###Retraining the classfier to identify the model of the car###\nINDIVIDUAL_CLASSES = os.listdir('..\/input\/car_data\/car_data\/train\/')\nNUM_CLASSES = len(INDIVIDUAL_CLASSES)\nROOT_DIR = '..\/input\/car_data\/car_data'\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nDATA_TRANSFORMS = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n    ]),\n    'test': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n    ]),\n}","88a501bb":"class CarDS(Dataset):\n    def __init__(self, root, phase, transforms):\n        self.filenames = []\n        self.root = root\n        self.phase = phase\n        self.transform = transforms\n        self.classes = os.listdir(root)\n        self.labels = []\n        for dir in os.listdir(root):\n            path = os.path.join(self.root, dir)\n            filenames = glob.glob(os.path.join(path, '*'))\n            for fn in filenames:\n                self.filenames.append(fn)\n                self.labels.append(INDIVIDUAL_CLASSES.index(dir))\n        self.labels = np.array(self.labels)\n        self.len = len(self.filenames)\n        \n    def __getitem__(self, index):\n        image = Image.open(self.filenames[index])\n        image = image.convert('RGB')\n        image = self.transform(image)\n        if (self.phase == 'test'):\n            return image\n        return image, self.labels[index]\n\n    def __len__(self):\n        return self.len","041458e4":"dataset = CarDS(os.path.join(ROOT_DIR, 'train'), phase = 'train', transforms = DATA_TRANSFORMS['train'])\ntrain_size = int(0.9 * len(dataset))\nvalid_size = len(dataset) - train_size\ndataset_sizes = {'train': train_size, 'valid': valid_size}\ntrain_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\ndataloaders = {'train': DataLoader(train_dataset, batch_size = 64, shuffle = True),\n              'valid': DataLoader(valid_dataset, batch_size = 64, shuffle = False)}","b6a616d8":"num_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, NUM_CLASSES)\nmodel = model.to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","5e50fdc2":"model = train_model(dataloaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)","17f4381c":"###Testing the model with test samples###\npd.set_option('display.max_rows', 9000)\nnames = pd.read_csv(\"..\/input\/names.csv\", header=None)\nnames = names.rename(columns={0: 'Model'})\nnames.Model = names.Model.replace({\"Ram C\/V Cargo Van Minivan 2012\": \"Ram C-V Cargo Van Minivan 2012\"})\nLOAD_MODEL = False\nwith torch.no_grad():\n    model.eval()\n    print (\"Test set prediction results:\")\n    test_set = CarDS('..\/input\/car_data\/car_data\/test', transforms=DATA_TRANSFORMS['test'], phase='test')\n    test_loader = DataLoader(test_set, batch_size = 64, shuffle=False)\n    index = 0\n    results = []\n    for inputs in test_loader:\n        outputs = model(inputs.to(DEVICE))\n        _, pred = torch.max(outputs, 1)\n        for i in range(len(inputs)):\n            Id = str(test_set.filenames[index].split(\"\/\")[-1].split(\".\")[0])\n            Predicted_cls = INDIVIDUAL_CLASSES[int(pred[i])]\n            Predicted_index = names.loc[names['Model'] == Predicted_cls].index[0]+1\n            results.append((Id,Predicted_index))\n            index += 1\n    result_df = pd.DataFrame(results, columns=['Id', 'Predicted'])\n    #result_df = result_df.sort_values(by=['Filename'])\n    print (result_df)\n    result_df.to_csv('..\/working\/test_results.csv')","e51b0327":"###Downloading the results file###\ndef create_download_link(df, title = \"Download Result file\", filename = \"results.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(result_df)","80350457":"**Stanford Car Classification - My Approach**\n1. The transfer learning approach is adopted to solve this classification problem. Fine tuning a model which is already trained on a larger set in the same domain (i.e. image classification) gives an upperhand in solving the problem rather than training a model from zero knowledge.\n2.  The pretrained model that has been choosen here is Resnet-101 as this model has the least top-5 error on Imagenet 1-crop dataset. The advantage of Resnet (introduced by Microsoft) is that the model has a deeper architecture than a wider one. The number of parameters to be trained in Resnet is comparatively smaller than its variants due to its shortcut connections. This helps in training the model faster than the others.\n3.  The car classification is executed in two stages.  The inital model pre-trained on Imagenet  knows to classify the given image as car.  Each car manufacturer keeps some unique features in the car which will be present in all the models released by that manufacturer.  So, the pre-trained model is first fine-tuned to classify the car into different manufacturers alone.  This will help the model in learning the common features that a manufacturer keeps in every model.  Now, this fine-tuned model is further trained to perform the actual classification of the cars into the corresponding models.  In the second stage, the model just has to find the features which makes a car model distinct from the other models of the same manufacturer.  This two-stage execution is more intuitive and helps in robust learning of the model.\n4.  The dataset given for training is found to be unbalanced for the first stage i.e., there are certain manufacturers for whom there are many models available and thus many training samples.  This has been clearly shown in the results obtained through analyzing a dataset where the difference between the manufacturer with highest number of samples and the one with the lowest is 10 fold.  To mitigate this bias, the following steps have been taken.\n    * Transforms - One way of mitigating the unbalanced dataset problem is to do possible and suitable transformations at each iteration. The standard transformations that include randomized cropping, and flipping were carried out to augment the dataset\n    * Weighted Criterion - Even with the data augmentation approach, there is a high possibility of repetitive images for a class with minimum number of samples. To overcome this, while penalizing the model for giving wrong prediction, the class with lesser no. of samples are given more weightage and are penalized more than the one with many samples to rectify the bias in the dataset.  This weighted criterion is used only in the first stage of training whereas in the second stage, each model has almost equal number of samples which nullifies the need of this weighted criterion.\n4.  The optimizer chosen is Adam and the learning rate is fixed to 0.0001 empirically. The weight decay parameter is set to 1e-5 to decay the hyperparameters along with the learning rate. The learning Rate Scheduler has been used to gradually change the learning rate over the training phase. The step size is empirically set to 7 and gamma value is set to default. The number of epochs is empirically set to 25 for each of the two stages.\n5.  The model which gave the best validation accuracy is saved for further testing.\n6.  In addition to accuracy and loss, the model's performance is also evaluated by finding the precision, recall, and f1-score for each of the class in the validation phase."}}