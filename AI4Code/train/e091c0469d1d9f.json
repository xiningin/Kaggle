{"cell_type":{"c99d7274":"code","abc6ea3a":"code","d6810140":"code","b91e4799":"code","0b76847f":"code","1abfa0b5":"code","f3e6fbf2":"code","b62f2b9b":"code","2473bb01":"code","af6e8f15":"code","5d2da829":"code","55854495":"code","4c861d21":"code","2d7c9cea":"code","d26d492d":"code","63f1978d":"code","a97894f4":"code","48ab595c":"code","eff96d49":"code","6c52d348":"code","0742cb3b":"code","4edf8e76":"code","a70957b2":"code","76e1924c":"code","9ead8963":"code","ec0f8755":"code","ece366cc":"code","94260913":"code","5dbd369d":"code","92d90200":"code","e18e5d52":"markdown","25f2af09":"markdown","93483924":"markdown","c21222b3":"markdown","6f29d8a3":"markdown","8958b0d8":"markdown","80d19dc5":"markdown","2783d040":"markdown","f3200966":"markdown","1f9e8b10":"markdown","9b2897f0":"markdown","bba4c441":"markdown","1d183187":"markdown","6c0dfb44":"markdown","83e2006b":"markdown","aa9a4bdb":"markdown","288f0538":"markdown","7474345e":"markdown","6f83e7ec":"markdown","ed141f16":"markdown","33bea170":"markdown","d868c107":"markdown","35648f58":"markdown","92169c2c":"markdown","0a447df1":"markdown","187970fa":"markdown","7732c6a6":"markdown","9dde8d1c":"markdown","7f461206":"markdown"},"source":{"c99d7274":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom PIL import Image\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","abc6ea3a":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","d6810140":"base_dir = os.path.join(os.path.dirname('\/kaggle\/input\/dogs-cats-images\/'), 'dataset')\ntrain_dir = os.path.join(base_dir, 'training_set')\nvalidation_dir = os.path.join(base_dir, 'test_set')\n\ntrain_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures","b91e4799":"cat = Image.open(\"\/kaggle\/input\/dogs-cats-images\/dataset\/test_set\/cats\/cat.4796.jpg\")\ndog = Image.open(\"\/kaggle\/input\/dogs-cats-images\/dataset\/test_set\/dogs\/dog.4323.jpg\")","0b76847f":"print(cat.format, cat.size, cat.mode)\nprint(dog.format, dog.size, dog.mode)","1abfa0b5":"num_cats_tr = len(os.listdir(train_cats_dir))\nnum_dogs_tr = len(os.listdir(train_dogs_dir))\n\nnum_cats_val = len(os.listdir(validation_cats_dir))\nnum_dogs_val = len(os.listdir(validation_dogs_dir))\n\ntotal_train = num_cats_tr + num_dogs_tr\ntotal_val = num_cats_val + num_dogs_val","f3e6fbf2":"print('total training cat images:', num_cats_tr)\nprint('total training dog images:', num_dogs_tr)\n\nprint('total validation cat images:', num_cats_val)\nprint('total validation dog images:', num_dogs_val)\nprint(\"--\")\nprint(\"Total training images:\", total_train)\nprint(\"Total validation images:\", total_val)","b62f2b9b":"BATCH_SIZE = 128  # Number of training examples to process before updating our models variables\nIMG_SHAPE  = 224  # Our training data consists of images with width of 150 pixels and height of 150 pixels","2473bb01":"# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\ndef plot_images(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n    plt.tight_layout()\n    plt.show()","af6e8f15":"image_gen = ImageDataGenerator(rescale=1.\/255, horizontal_flip=True)\n\ntrain_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size=(IMG_SHAPE,IMG_SHAPE))","5d2da829":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]\nplot_images(augmented_images)","55854495":"image_gen = ImageDataGenerator(rescale=1.\/255, rotation_range=45)\n\ntrain_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size=(IMG_SHAPE, IMG_SHAPE))","4c861d21":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]\nplot_images(augmented_images)","2d7c9cea":"image_gen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.5)\n\ntrain_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n                                               directory=train_dir,\n                                               shuffle=True,\n                                               target_size=(IMG_SHAPE, IMG_SHAPE))","d26d492d":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]\nplot_images(augmented_images)","63f1978d":"image_gen_train = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntrain_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n                                                     directory=train_dir,\n                                                     shuffle=True,\n                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n                                                     class_mode='binary')","a97894f4":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]\nplot_images(augmented_images)","48ab595c":"image_gen_val = ImageDataGenerator(rescale=1.\/255)\n\nval_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n                                                 directory=validation_dir,\n                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n                                                 class_mode='binary')","eff96d49":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SHAPE, IMG_SHAPE, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])","6c52d348":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","0742cb3b":"model.summary()","4edf8e76":"!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5","a70957b2":"weights1=\"inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"","76e1924c":"pre_trained_model = InceptionV3(input_shape = (IMG_SHAPE, IMG_SHAPE, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(weights1)\n\nfor layer in pre_trained_model.layers:\n    layer.trainable = False\n\npre_trained_model.summary()","9ead8963":"last_7_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_7_layer.output_shape)\nlast_output = last_7_layer.output","ec0f8755":"x = layers.Flatten()(last_output)\n\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel_incept = Model( pre_trained_model.input, x) \n\nmodel_incept.compile(optimizer = tf.keras.optimizers.Adam(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['accuracy'])","ece366cc":"epochs=1\n# history = model.fit_generator(\n#     train_data_gen,\n#     steps_per_epoch=int(np.ceil(total_train \/ float(BATCH_SIZE))),\n#     epochs=epochs,\n#     validation_data=val_data_gen,\n#     validation_steps=int(np.ceil(total_val \/ float(BATCH_SIZE)))\n# )\n\nhistory = model_incept.fit_generator(\n            train_data_gen,\n            steps_per_epoch=int(np.ceil(total_train \/ float(BATCH_SIZE))),\n            epochs=epochs,\n            validation_data=val_data_gen,\n            validation_steps=int(np.ceil(total_val \/ float(BATCH_SIZE))),\n            verbose = 2)","94260913":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n# plt.savefig('.\/acc_fig.png')\nplt.show()","5dbd369d":"\n\ndef testing_image(image_directory): #testing out our model\n    test_image = image.load_img(image_directory, target_size = (IMG_SHAPE, IMG_SHAPE))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n    result = model.predict(x = test_image)\n    print(result)\n#     if result[0][0]  == 1:\n#         prediction = 'Dog'\n#     else:\n#         prediction = 'Cat'\n    return prediction","92d90200":"#making prediction\n# print(testing_image(\"\/kaggle\/input\/dogs-cats-images\/dataset\/test_set\/dogs\/dog.4323.jpg\"))","e18e5d52":"## Transfer Learning:`Inceptionv3`","25f2af09":"## Data Loading","93483924":"## Data Augmentation","c21222b3":"This Kernel for someone want to deep dive into image classification. I use CNN for classification model. If you found this Kernel helpful please up vote it. If you have some feedback and question don't forget to comment below.","6f29d8a3":"### Visualizing results of the training","8958b0d8":"Generally, we only apply data augmentation to our training examples, since the original images should be representative of what our model needs to manage. So, in this case we are only rescaling our validation images and converting them into batches using ImageDataGenerator.","80d19dc5":"Let's look at how many cats and dogs images we have in our training and validation directory","2783d040":"Let's visualize how a single image would look like five different times, when we pass these augmentations randomly to our dataset. ","f3200966":"### Applying Zoom\nWe can also apply Zoom augmentation to our dataset, zooming images up to 50% randomly.","1f9e8b10":"### Model Summary\n\nLet's look at all the layers of our network using **summary** method.","9b2897f0":"### Train the model","bba4c441":"# Dogs vs Cats Image Classification","1d183187":"### Putting it all together","6c0dfb44":"Images must be formatted into appropriately pre-processed floating point tensors before being fed into the network. The steps involved in preparing these images are:\n\n1. Read images from the disk\n2. Decode contents of these images and convert it into proper grid format as per their RGB content\n3. Convert them into floating point tensors\n4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.","83e2006b":"Overfitting often occurs when we have a small number of training examples. One way to fix this problem is to augment our dataset so that it has sufficient number and variety of training examples. Data augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples through random transformations that yield believable-looking images. The goal is that at training time, your model will never see the exact same picture twice. This exposes the model to more aspects of the data, allowing it to generalize better.","aa9a4bdb":"## Setting Model Parameters\nLet's set up variables that will be used later while pre-processing dataset and training network.","288f0538":"![Cat-vs-dogs-v4_27Nov.jpg](attachment:Cat-vs-dogs-v4_27Nov.jpg)","7474345e":"It's time we train our network.\n\nSince our batches are coming from a generator (`ImageDataGenerator`), we'll use `fit_generator` instead of `fit`.","6f83e7ec":"## Contents\n\n- Using Image Data Generator\n- Using Augmentation to increase variety in Dataset\n- Transfer Learning (Inceptionv3 model)\n- Plotting Accuracy and Loss for Training and Validation\n","ed141f16":"## Model Creation","33bea170":"### Understanding our data","d868c107":"### Compiling the model\n\nAs usual, we will use the `adam` optimizer. Since we output a softmax categorization, we'll use `sparse_categorical_crossentropy` as the loss function. We would also like to look at training and validation accuracy on each epoch as we train our network, so we are passing in the metrics argument.","35648f58":"## Importing packages","92169c2c":"### Flipping the image horizontally\nThis is achieved by passing `horizontal_flip=True` as an argument to the `ImageDataGenerator` class.","0a447df1":"## Data Preparation ","187970fa":"We'll now visualize the results we get after training our network.","7732c6a6":"### Define the model\n\nThe model consists of four convolution blocks with a max pool layer in each of them.\n\nBefore the final Dense layers, we're also applying a Dropout probability of 0.5. It means that 50% of the values coming into the Dropout layer will be set to zero. This helps to prevent overfitting.\n\nThen we have a fully connected layer with 512 units, with a `relu` activation function. The model will output class probabilities for two classes \u2014 dogs and cats \u2014 using `softmax`. ","9dde8d1c":"### Rotating the image","7f461206":"Let's apply rescale, rotation of 45 degrees, width shift, height shift, horizontal flip, and zoom augmentation to our training images."}}