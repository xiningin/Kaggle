{"cell_type":{"47b128f8":"code","9d0c6eda":"code","60b97168":"code","2f8f002a":"code","1cccd5ab":"code","b11ab462":"code","21f99c3d":"code","74ad5c8d":"code","679b9701":"code","17fccd21":"code","090ea853":"code","a282fc79":"code","af4ac8c0":"code","54faa0e3":"code","025e0e4c":"markdown","8bf70b1c":"markdown","7e5cfeec":"markdown","465300eb":"markdown","037b1867":"markdown","e3e51d42":"markdown","66ef4da2":"markdown","a14a11c8":"markdown","3cd4e155":"markdown","c3c260fb":"markdown","4e729778":"markdown","609c8ecb":"markdown"},"source":{"47b128f8":"import numpy as np\nimport pandas as pd\nimport re\nimport sklearn\nimport nltk\nimport bs4\nnltk.download('stopwords')\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import LinearSVC\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9d0c6eda":"!pip install beautifulsoup4","60b97168":"imdb_data=pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv',names=['review', 'sentiment'],header=0)\nprint(imdb_data.shape)","2f8f002a":"imdb_data.head(20)","1cccd5ab":"imdb_data.describe()","b11ab462":"imdb_data['sentiment'].value_counts()","21f99c3d":"sentiment_values=pd.get_dummies(imdb_data['sentiment'])\nsentiment_values=sentiment_values.iloc[:,1].values","74ad5c8d":"lemmatizer=WordNetLemmatizer()\ncorpus=[]\nfor i in range (0,len(imdb_data)):\n    soup = bs4.BeautifulSoup(imdb_data ['review'][i], \"html.parser\")\n    review=re.sub('\\[[^]]*\\]',' ',imdb_data['review'][i])\n    review=re.sub('[^a-zA-Z]',' ',imdb_data['review'][i])\n    review=review.lower()\n    review= review. split()\n    review=[word for word in review if not word in set(stopwords.words('english'))]\n    review = [lemmatizer.lemmatize(word) for word in review]\n    review=' '.join (review)\n    corpus.append(review)","679b9701":"cv = TfidfVectorizer(ngram_range=(1, 3))\ntfidf = cv.fit_transform(corpus)","17fccd21":"tfidf_train,tfidf_test,sentiment_values_train,sentiment_values_test=train_test_split(tfidf,sentiment_values,test_size=0.20,random_state=0)","090ea853":"linear_svc = LinearSVC(C=0.5, random_state=42)\nlinear_svc.fit(tfidf_train, sentiment_values_train)\n\npredict = linear_svc.predict(tfidf_test)","a282fc79":"report=classification_report(sentiment_values_test, predict,target_names=['Negative','Positive'])\nprint(\"Classification Report: \\n\",report)","af4ac8c0":"matrix=confusion_matrix(sentiment_values_test, predict)\nprint(\"Confusion Matrix: \\n\",matrix)","54faa0e3":"accuracy=accuracy_score(sentiment_values_test, predict)\nprint(\"Accuracy: \\n\", accuracy)","025e0e4c":"IMPORTING NECESSARY LIBRARIES","8bf70b1c":"SENTIMENT COUNT","7e5cfeec":"TRAINING AND TESTING DATA","465300eb":"CONFUSION MATRIX","037b1867":"IMPORTING THE DATASET","e3e51d42":"VIEWING DATASET","66ef4da2":"DATA ANALYSIS","a14a11c8":"SVC MODEL","3cd4e155":"ACCURACY","c3c260fb":"Term Frequency-Inverse Document Frequency(TFIDF)","4e729778":"DATA CLEANING","609c8ecb":"CLASSIFICATION REPORT"}}