{"cell_type":{"a267492a":"code","bb238b24":"code","170a5fa8":"code","5ea6a46c":"code","b39be5dd":"code","4aac3d2f":"code","2531be72":"code","eb9e5aee":"code","b05afe17":"code","af326449":"code","a0a16f60":"code","100906c5":"code","22e46fa4":"code","a945b686":"code","a3878b6c":"code","85d10bbd":"code","5be77733":"code","5fa8c604":"markdown","55b734b0":"markdown","be2c7887":"markdown","3bc02379":"markdown","ccd3cd87":"markdown","3b522711":"markdown","b0119282":"markdown","8de96e52":"markdown","e15b7a83":"markdown","1605fb1d":"markdown","9fe39486":"markdown","85e17cf6":"markdown","9dd05ed1":"markdown","ff6c4c59":"markdown","0757aa32":"markdown"},"source":{"a267492a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb238b24":"df = pd.read_csv(\"\/kaggle\/input\/ai4all-project\/data\/viral_calls\/sample_overviews.csv\")\ndf.head()","170a5fa8":"print(f\"data shape: {df.shape}\")","5ea6a46c":"df.describe()","b39be5dd":"df.isnull().sum()","4aac3d2f":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()","2531be72":"plot_count(\"total_reads\", \"total_reads\", df,4)","eb9e5aee":"plot_count(\"nonhost_reads_percent\", \"nonhost_reads_percent\", df,4)","b05afe17":"# Distribution of different type of amount\nfig , ax = plt.subplots(1,3,figsize = (12,5))\n\ntotal_reads = df.total_reads.values\nnonhost_reads = df.nonhost_reads.values\ntotal_ercc_reads = df.total_ercc_reads.values\n\nsns.distplot(total_reads , ax = ax[0] , color = 'blue').set_title('Viral Samples Total Reads' , fontsize = 14)\nsns.distplot(nonhost_reads , ax = ax[1] , color = 'cyan').set_title('Viral Samples Nonhost Reads' , fontsize = 14)\nsns.distplot(total_ercc_reads , ax = ax[2] , color = 'purple').set_title('Viral Samples Total ERCC Reads' , fontsize = 14)\n\nplt.show()","af326449":"df['water_control'].value_counts()","a0a16f60":"f,ax = plt.subplots(1,2,figsize = (16,8))\n\ncolors = ['blue','red']\nlabels = ['Yes', 'No']\nplt.suptitle('Water Condition & Reads after Trimmomatic',fontsize = 20)\n\ndf['water_control'].value_counts().plot.pie(explode = [0,0.25], autopct = \"%1.2f%%\" , ax = ax[0],\n                                                 labels = labels , colors = colors ,fontsize = 12 , startangle = 70)\n\nax[0].set_ylabel('% of condition of Water')\n\npalette = [\"Blue\", \"Red\"]\n\nsns.barplot(x = 'upload_date', y = 'reads_after_trimmomatic',hue = 'quality_control',data = df,palette = palette,\n           estimator = lambda x: len(x)\/len(df) * 100)\n\nax[1].set(ylabel='%')","100906c5":"cmap = plt.cm.Set2\ndf.groupby(['insert_size_standard_deviation','subsampled_fraction'])['total_ercc_reads'].sum().unstack().plot(figsize = (15,6))\nplt.title('Subsampled Fraction Standard Deviation by Total ERCC Reads')","22e46fa4":"f , ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\nsns.set_style('whitegrid')\ncmap = plt.cm.inferno\ntotal_reads = df.groupby(['upload_date','insert_size_mean']).total_reads.mean()\ntotal_reads.unstack().plot(kind = 'area',ax = ax1 , figsize = (16,12) , colormap = cmap , grid = False)\nax1.set_title('Average Total Reads by Insert Size Mean')\nax1.set_xlabel('Upload Date')\n\nnonhost_reads = df.groupby(['upload_date','insert_size_mean']).nonhost_reads.mean().unstack().plot(kind = 'area',ax = ax2 ,colormap = cmap, figsize = (16,12),grid = False)\nax2.set_title('Average Nonhost Reads by Insert Size Mean')\nax2.set_xlabel('Upload Date')\ninsert_size_read_pairs = df.groupby(['upload_date','insert_size_mean'])['insert_size_read_pairs'].mean().unstack().plot(kind = 'area',ax = ax3 , figsize = (16,12) ,colormap = cmap, grid = False)\nax3.set_title('Average Size Read Pairs by Insert Size Mean ')\nax3.set_xlabel('Upload Date')\n\ntotal_ercc_reads = df.groupby(['upload_date','insert_size_mean']).total_ercc_reads.mean().unstack().plot(kind = 'area',ax = ax4 , figsize = (16,12),colormap = cmap,grid = False)\nax4.set_title('Total ERCC Reads by Insert Size Mean')\nax4.set_xlabel('Upload Date')\nplt.show()","a945b686":"fig , ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows = 2, ncols = 2, figsize = (14,6))\n\nsns.violinplot(x = 'compression_ratio' , y = 'reads_after_star' , data = df , ax = ax1 , palette = 'Set2')\nsns.violinplot(x = 'compression_ratio' , y = 'reads_after_trimmomatic' , data = df , ax = ax2 , palette = 'Set2')\nsns.boxplot(x = 'compression_ratio' , y = 'reads_after_priceseq', data = df, ax = ax3 , palette = 'Set2')\nsns.boxplot(x = 'compression_ratio',y = 'reads_after_cdhitdup', data = df, ax = ax4, palette = 'Set2')","a3878b6c":"f , (ax1,ax2) = plt.subplots(1,2,figsize = (15,6))\ncmap = plt.cm.coolwarm\n\nby_subsampled_fraction = df.groupby(['upload_date','insert_size_mode']).subsampled_fraction.mean()\nby_subsampled_fraction.unstack().plot(ax = ax1 , colormap = cmap)\nax1.set_title('Subsampled Fraction Insert Size Mode')\n\nby_insert_size_standard_deviation = df.groupby(['upload_date','insert_size_mode']).insert_size_standard_deviation.mean()\nby_insert_size_standard_deviation.unstack().plot( ax = ax2 , colormap = cmap)\nax2.set_title('Insert Size Standard Deviation & Mode')\n#ax2.legend(bbox_to_anchor=(-1.0, -0.3, 1.7, 0.1), loc=5, prop={'size':12},\n #          ncol=7, mode=\"expand\", borderaxespad=0.)","85d10bbd":"fig = plt.figure(figsize = (16,12))\n\nax1 = fig.add_subplot(221)\nax2 = fig.add_subplot(222)\nax3 = fig.add_subplot(212)\n\ncmap = plt.cm.coolwarm_r\n\nreads_after_trimmomatic = df.groupby(['insert_size_mode','reads_after_trimmomatic']).size()\nreads_after_trimmomatic.unstack().plot(kind = 'bar', ax = ax1 , stacked = True , colormap = cmap , grid = False)\nax1.set_title('Reads After Trimmomatic Insert Size Mode',fontsize = 14)\n\nreads_after_priceseq = df.groupby(['insert_size_standard_deviation','reads_after_priceseq']).size().unstack().plot(kind = 'bar',ax = ax2, stacked = True, colormap = cmap, grid = False)\nax2.set_title('Reads After Priceseq Insert Standard Deviation', fontsize = 14)\n\ntotal_ercc_reads = df.groupby(['upload_date', 'reads_after_cdhitdup']).total_ercc_reads.mean().unstack().plot(ax = ax3, colormap = cmap)\nax3.set_title('Reads After Cdhitdup', fontsize = 14)\nax3.set_ylabel('Total ERCC Reads',fontsize = 12)","5be77733":"fig = plt.figure(figsize = (20,10))\nax1 = fig.add_subplot(221)\nax2 = fig.add_subplot(222)\nax3 = fig.add_subplot(212)\nsns.countplot(x = 'quality_control', hue = 'subsampled_fraction',data = df , ax = ax1 )\nax1.set_title('Quality control of Subsampled Fraction')\n\nsns.countplot(x = 'quality_control', hue = 'insert_size_min',data = df , ax = ax2 )\nax2.set_title('Quality Control of Insert Size Min')\n\nsns.distplot(df[df.compression_ratio], ax = ax3 , label = 'Compression Ration',color = 'blue')\nsns.distplot(df[df.reads_after_trimmomatic] , ax = ax3 , label = 'Reads After Trimmomatic' , color = 'red')\n\nplt.legend()\nplt.show()","5fa8c604":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQoHym_GdZIbnApW9lrzRrbAD8F-PTTu88F0Q&usqp=CAU)slideshare.net","55b734b0":"![]()","be2c7887":"Das War's kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","3bc02379":"#Features of the Computational Tools in Our Workflow \n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTwbPU29SGILLuCSW_kjrMdz48Q2pOCnd95RQ&usqp=CAU)researchgate.net","ccd3cd87":"#CD-HIT\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcR5PkkLCU2Z2DDpiP9RxcLWUjeSUKgAbttScQ&usqp=CAU)sourceforge.net","3b522711":"#CD-HIT-DUP identifies duplicates from single or paired Illumina reads\n\nCD-HIT is a very widely used program for clustering and comparing protein or nucleotide sequences. CD-HIT was originally developed by Dr. Weizhong Li at Dr. Adam Godzik's Lab at the Burnham Institute (now Sanford-Burnham Medical Research Institute)http:\/\/weizhongli-lab.org\/cd-hit\/","b0119282":"It's on Fire! ","8de96e52":"#Codes from Niwanshu Maheshwari https:\/\/www.kaggle.com\/niwanshu29\/lending-club","e15b7a83":"#Codes from Niwanshu Maheshwari  https:\/\/www.kaggle.com\/niwanshu29\/lending-club","1605fb1d":"#Trimmomatic\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRLHN7X1jC_631LWPqxrlvCUZaiP4ciXTVvmA&usqp=CAU)codenong.com","9fe39486":"![](https:\/\/www.ekfdiagnostics.com\/res\/PrimeStore%20Molecular%20transport%20media-2.jpg)ekfdiagnostics.com","85e17cf6":"#Summary of the trimming results with Trimmomatic for each cDNA library sequenced.\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTxRM6iIr7Zd1BP1vdKObYD9OqMyTbRwvdkzg&usqp=CAU)researchgate.net","9dd05ed1":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcSjWnqm4SqGC0aYt3QUSDv-xMKuZ3NOZULgdA&usqp=CAU)slideshare.net","ff6c4c59":"#External RNA Controls Consortium (ERCC) ","0757aa32":"Evaluation of Seven Different RNA-Seq Alignment Tools Based on Experimental Data from the Model Plant Arabidopsis thaliana. By Stephanie Schaarschmidt,Axel Fischer,Ellen Zuther andDirk K. Hincha\nInt. J. Mol. Sci. 2020, 21(5), 1720; https:\/\/doi.org\/10.3390\/ijms21051720\n\n![](https:\/\/www.mdpi.com\/ijms\/ijms-21-01720\/article_deploy\/html\/images\/ijms-21-01720-g006-550.jpg)\nFigure . Number of reads mapping on the same genomic position comparing HISAT2, RSEM and STAR for Col-0. Venn diagrams are based on 24,989,667 reads mapped by all three mappers and represent the overlap of mapped reads on the same genomic position for sample A (see Table A3 for sample information). A high number of the uniquely mapped reads in RSEM was based on soft-clipping by one bp performed by HISAT2 and STAR (a). The reads in HISAT2 and STAR were corrected by adding the soft-clipped bp back and the overlap with RSEM increased strongly (b).https:\/\/www.mdpi.com\/1422-0067\/21\/5\/1720\/htm"}}