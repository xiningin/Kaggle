{"cell_type":{"eb1509ad":"code","5b2debd4":"code","6b9a6551":"code","b93c5d9f":"code","c00e78a4":"code","1f92288e":"code","bf9277b9":"code","77e21a48":"code","19d4cba2":"code","301e71d0":"code","14fe7200":"code","977b4097":"code","0aefeff9":"code","bcaa20c1":"code","285f6ab6":"code","052985f6":"code","1d25bba2":"code","e2e5376b":"code","dd77d306":"code","c2735252":"code","34900ec1":"code","b044f68a":"code","1eb4bacd":"code","67c12ec7":"code","3f9b25d4":"code","34559bb1":"code","da743eaf":"code","71597bd6":"code","17b0f366":"code","e1673c78":"code","1fcdc106":"code","68dc15a0":"code","38b295ba":"code","9ddc8cd4":"code","e322f820":"code","953135b0":"code","5c718520":"code","4141580f":"code","be0852b0":"code","d578bab4":"code","0f807cc5":"code","45f54f28":"code","64f06ef9":"code","d91bc905":"code","106ce568":"code","465048e3":"code","b15fa658":"code","d655a6f6":"code","f0dacd92":"code","dffe237d":"code","63df68cb":"code","bcc41937":"code","2b874127":"code","d2cc7284":"code","b199e942":"code","ffe4ff4a":"code","c4ea9360":"code","08c2eeff":"code","24e74e3b":"code","75e5a740":"code","f4c44f43":"code","9802f130":"code","4e20ff34":"code","fc98bd0e":"code","1711890d":"code","e63d4d16":"code","0b710030":"code","ed09c23d":"code","49f6f822":"code","8f8cd036":"code","3b55a582":"code","0a950553":"code","74495521":"code","5359ae27":"code","c685b973":"code","00d4c01a":"code","c920f46e":"code","beb0c0e1":"code","93230425":"code","5e907ebb":"code","5186d17f":"code","58811c69":"code","174ba3ce":"code","17679d22":"code","83fe8752":"code","e6dc6b2d":"code","6d383772":"code","6233062d":"code","625b6d80":"code","a8dec810":"code","ab3a97d7":"code","bcdf8a95":"code","a9a883d6":"code","e8c33049":"code","86c195ff":"code","2ae43cbc":"code","34d1be77":"code","209680e7":"code","a6e45999":"code","c032d5db":"code","c52748dd":"code","fe03bac3":"code","75c33089":"code","a835f00a":"code","e755c1ff":"code","93fdfc55":"code","c110c210":"markdown","4f548e1a":"markdown","f34ad921":"markdown","54fc9b18":"markdown","5523419c":"markdown","58156322":"markdown","f0274727":"markdown","8f3f5489":"markdown","e1680281":"markdown","3ba5ee30":"markdown","fc811b17":"markdown","888801f2":"markdown","8535284d":"markdown","47d60c88":"markdown","a7bcb976":"markdown","f75c437c":"markdown","54ca0852":"markdown","cb52af6b":"markdown","90adf732":"markdown","2c19c8b6":"markdown","b5cfc9cf":"markdown","11e1b93c":"markdown","2a437e4e":"markdown","2cebab51":"markdown","8d6390fe":"markdown","6af94301":"markdown","ef05efd1":"markdown","d2ab33f1":"markdown","2206bde1":"markdown","82992d94":"markdown","e2e58597":"markdown","e4b18cbb":"markdown","2adfe9ad":"markdown","da3777e1":"markdown","16984d44":"markdown","0c439666":"markdown","2263e0bc":"markdown","fc68c662":"markdown","0be73847":"markdown","75af14d3":"markdown","c10dd57f":"markdown"},"source":{"eb1509ad":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","5b2debd4":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","6b9a6551":"# copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","b93c5d9f":"train.head()","c00e78a4":"test.head()","1f92288e":"train.info()","bf9277b9":"train.describe().T","77e21a48":"train['Pclass'].value_counts()","19d4cba2":"train['Sex'].value_counts()","301e71d0":"train['SibSp'].value_counts()","14fe7200":"train['Parch'].value_counts()","977b4097":"train['Ticket'].value_counts()","0aefeff9":"train['Cabin'].value_counts()","bcaa20c1":"train['Embarked'].value_counts()","285f6ab6":"sns.barplot(x = 'Pclass', y = 'Survived', data = train);","052985f6":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","1d25bba2":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","e2e5376b":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","dd77d306":"train.head()","c2735252":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","34900ec1":"train.describe().T","b044f68a":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","1eb4bacd":"Q1 = train['Fare'].quantile(0.25)\nQ3 = train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","67c12ec7":"# observations with Fare data higher than the upper limit:\n\ntrain['Fare'] > (upper_limit)","3f9b25d4":"train.sort_values(\"Fare\", ascending=False).head()","34559bb1":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \ntrain['Fare'] = train['Fare'].replace(512.3292, 300)","da743eaf":"train.sort_values(\"Fare\", ascending=False).head()","71597bd6":"test.sort_values(\"Fare\", ascending=False)","17b0f366":"test['Fare'] = test['Fare'].replace(512.3292, 300)","e1673c78":"test.sort_values(\"Fare\", ascending=False)","1fcdc106":"train.isnull().sum()","68dc15a0":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","38b295ba":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","9ddc8cd4":"train.isnull().sum()","e322f820":"test.isnull().sum()","953135b0":"train.isnull().sum()","5c718520":"test.isnull().sum()","4141580f":"train[\"Embarked\"].value_counts()","be0852b0":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","d578bab4":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","0f807cc5":"train.isnull().sum()","45f54f28":"test.isnull().sum()","64f06ef9":"test[test[\"Fare\"].isnull()]","d91bc905":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","106ce568":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","465048e3":"test[\"Fare\"].isnull().sum()","b15fa658":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ntrain[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\ntrain.head()","d655a6f6":"train.isnull().sum()","f0dacd92":"test.isnull().sum()","dffe237d":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","63df68cb":"train.head()","bcc41937":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","2b874127":"train.head()","d2cc7284":"train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","b199e942":"train.head()","ffe4ff4a":"train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')","c4ea9360":"test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","08c2eeff":"train.head()","24e74e3b":"test.head()","75e5a740":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","f4c44f43":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","9802f130":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","4e20ff34":"train.isnull().sum()","fc98bd0e":"test['Title'] = test['Title'].map(title_mapping)","1711890d":"test.head()","e63d4d16":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","0b710030":"train.head()","ed09c23d":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)","49f6f822":"# Map each Age value to a numerical value:\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)","8f8cd036":"train.head()","3b55a582":"#dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","0a950553":"train.head()","74495521":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])","5359ae27":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","c685b973":"train.head()","00d4c01a":"train.head()","c920f46e":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","beb0c0e1":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","93230425":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","5e907ebb":"train.head()","5186d17f":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","58811c69":"test.head()","174ba3ce":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")","17679d22":"train.head()","83fe8752":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")","e6dc6b2d":"test.head()","6d383772":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")","6233062d":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","625b6d80":"train.head()","a8dec810":"test.head()","ab3a97d7":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","bcdf8a95":"x_train.shape","a9a883d6":"x_test.shape","e8c33049":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","86c195ff":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","2ae43cbc":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","34d1be77":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","209680e7":"xgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","a6e45999":"xgb_cv_model.fit(x_train, y_train)","c032d5db":"xgb_cv_model.best_params_","c52748dd":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","fe03bac3":"xgb_tuned =  xgb.fit(x_train,y_train)","75c33089":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","a835f00a":"test","e755c1ff":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = xgb_tuned.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","93fdfc55":"output.head()","c110c210":"## Variable Transformation","4f548e1a":"## Missing Value Treatment","f34ad921":"**## Loading Data","54fc9b18":"## Spliting the train data","5523419c":"#### Parch vs survived:","58156322":"### Embarked","f0274727":"### Name - Title","8f3f5489":"**Variable Notes:**\n\nPclass: A proxy for socio-economic status (SES)\n- 1st = Upper\n- 2nd = Middle\n- 3rd = Lower\n\nAge: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nSibSp: The dataset defines family relations in this way...\n- Sibling = brother, sister, stepbrother, stepsister\n- Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nParch: The dataset defines family relations in this way...\n- Parent = mother, father\n- Child = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","e1680281":"### Age","3ba5ee30":"## Analysis and Visualization of Numeric and Categorical Variables","fc811b17":"## Logistic Regression","888801f2":"## Random Forest","8535284d":"### Fare","47d60c88":"### Pclass","a7bcb976":"## Deleting Unnecessary Variables","f75c437c":"### Sex","54ca0852":"#### Sex vs survived:","cb52af6b":"#### Pclass vs survived:","90adf732":"### Basic summary statistics about the numerical data","2c19c8b6":"### Visualization","b5cfc9cf":"### AgeGroup","11e1b93c":"# Deployment","2a437e4e":"**Titanic Survival Prediction:**\n\nUse machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","2cebab51":"### Embarked & Title","8d6390fe":"### Classes of some categorical variables","6af94301":"## Importing Librarires","ef05efd1":"### Family Size","d2ab33f1":"### Ticket","2206bde1":"#### SibSp vs survived:","82992d94":"### Cabin","e2e58597":"# Data Preparation","e4b18cbb":"## Outlier Treatment","2adfe9ad":"# Business Understanding \/ Problem Definition","da3777e1":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","16984d44":"**Variables and Their Types:**\n\nSurvival: Survival -> 0 = No, 1 = Yes\n\nPclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n\nSex: Sex\n\nAge: Age in years\n\nSibSp: # of siblings \/ spouses aboard the Titanic\n\nParch: # of parents \/ children aboard the Titanic\n\nTicket: Ticket number\n\nFare: Passenger fare\n\nCabin: Cabin number\n\nEmbarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton","0c439666":"### Fare","2263e0bc":"## Feature Engineering","fc68c662":"## Gradient Boosting Classifier","0be73847":"# Modeling, Evaluation and Model Tuning","75af14d3":"# Data Understanding (Exploratory Data Analysis)","c10dd57f":"### Embarked"}}