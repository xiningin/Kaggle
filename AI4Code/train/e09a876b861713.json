{"cell_type":{"678e7f3b":"code","2f0303d3":"code","63c564e4":"code","1a7bfb94":"code","e70a5109":"code","457643be":"code","dace1056":"code","41b07064":"code","5622e4e5":"code","3ab23e30":"code","706db29d":"code","d54fc1bb":"code","44d1858e":"code","174c06f2":"code","a0677e5c":"code","d6455de2":"code","1404ea85":"code","97710f4c":"code","6864f8ea":"code","1ac2b344":"code","138dccdb":"code","1bc4d384":"code","aedebe6c":"code","190c8018":"code","ba6e58e7":"code","83e518fc":"code","41bb9870":"code","19b25f6c":"code","22aa20c4":"code","315d3626":"code","23cfa015":"code","158e392e":"code","0d85181b":"code","5f944dd8":"markdown","094bc689":"markdown"},"source":{"678e7f3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2f0303d3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nsns.set()","63c564e4":"pd.options.display.max_columns = None #Display all columns","1a7bfb94":"df = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.tail()","e70a5109":"df.describe()","457643be":"def show_info(data):\n    data_info = data.info()\n    data_shape = data.shape\n    data_null = data.isna().sum()\n    return data_info,data_null, print('Data shape:', data_shape)","dace1056":"show_info(df)","41b07064":"cat_data = df['diagnosis']\narray = np.array(cat_data)\nfull_list = list(array)","5622e4e5":"# A counter function. Similar to .value_counts()\ndef counter(data):\n    data_map = {}\n    \n    for element in data:\n        if element not in data_map:\n            data_map[element] = 1\n        else:\n            data_map[element] += 1\n        \n    return data_map","3ab23e30":"data_counter = counter(full_list)\nprint(data_counter['M'], ';',  data_counter['B'])","706db29d":"sns.countplot(cat_data)","d54fc1bb":"# Map Malignant to 0 and Benign to 1 (Targets)\ndiagnosis = df['diagnosis'] = df['diagnosis'].map({'M': 0, 'B':1})","44d1858e":"df.hist(bins = 50, figsize=(30,20))\nplt.show()","174c06f2":"train_set, test_set = train_test_split(df, test_size = 0.2, random_state = 42)","a0677e5c":"def train_test_size_ratio(train_set, test_set):\n    train_rows = train_set.shape[0]\n    test_rows = test_set.shape[0]\n    test_percentage = int((test_rows\/train_rows)*100)\n    train_percentage = 100 - test_percentage\n    return test_percentage, train_percentage","d6455de2":"print('Test-Train ratio:', train_test_size_ratio(train_set,test_set))","1404ea85":"correlation_matrix = df.corr().round(1)","97710f4c":"#We search for the correlation between attributes and diagnosis\ncorrelation_matrix['diagnosis'].sort_values(ascending = False) ","6864f8ea":"mask = np.triu(np.ones_like(correlation_matrix, dtype= bool))\n\nsns.set_style(style = 'white')\nf, ax = plt.subplots(figsize=(70, 20))\nplt.title('Attributes Correlation',fontsize = 20)\ncmap = sns.diverging_palette(10, 250, as_cmap=True)\n\nsns.heatmap(correlation_matrix, mask=mask, cmap='Blues', annot = True,\n            square=True, vmin = 0, vmax = 1,linewidths=.5, ax=ax)","1ac2b344":"# Strong linear correlation with diagnosis attributes\nattributes = ['radius_worst','diagnosis','concave points_mean',\n              'perimeter_worst','concave points_worst']","138dccdb":"# Plotting those promising attributes\nplot = sns.pairplot(data = df[attributes])","1bc4d384":"df.columns","aedebe6c":"targets = df.diagnosis","190c8018":"drop_columns = ['id','Unnamed: 32','diagnosis']\nattributes = df.drop(labels = drop_columns, axis = 1) #Drop information\nattributes.head()","ba6e58e7":"scaler = StandardScaler()\nscaler.fit(attributes) #We scale the attributes of the model","83e518fc":"scaled_numerical = scaler.transform(attributes)","41bb9870":"df_scaled_numerical = pd.DataFrame(data = scaled_numerical,\n                  columns = [ 'radius_mean','texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst'] )\ndf_scaled_numerical.head()","19b25f6c":"log_reg = LogisticRegression() ","22aa20c4":"log_reg.fit(df_scaled_numerical, targets) #We train the model","315d3626":"predictions = log_reg.predict(scaled_numerical)\npredictions","23cfa015":"score = log_reg.score(df_scaled_numerical, targets)*100\nscore.round(3)","158e392e":"from sklearn.metrics import confusion_matrix","0d85181b":"conf = confusion_matrix(targets,predictions)\nconf","5f944dd8":"# Logistic Regression","094bc689":"# Confusion Matrix"}}