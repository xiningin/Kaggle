{"cell_type":{"420824b8":"code","7259c696":"code","e3456f23":"code","61f2f654":"code","39a7d915":"code","09f9d34f":"code","6f7eec72":"markdown","67ffd94a":"markdown","812a8517":"markdown","d7958b39":"markdown","da0d0f2d":"markdown","ce62fb8f":"markdown","55848bda":"markdown","f8480bd2":"markdown","2ab427dc":"markdown","0556d64f":"markdown","4111c7d6":"markdown","0609e530":"markdown","ef699f45":"markdown","62330bbc":"markdown","eda2c7a4":"markdown","47cc20db":"markdown"},"source":{"420824b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7259c696":"df = pd.read_csv('\/kaggle\/input\/students-performance-in-exams\/StudentsPerformance.csv')","e3456f23":"rs = df['reading score']\nws = df['writing score']","61f2f654":"def SamplingDistributions(df, iters = 101):\n    t = []\n    \n    for _ in range(iters):\n        sample = ResampleRows(df)\n        rscore = sample['reading score']\n        wscore = sample['writing score']\n        estimates = LeastSquares(wscore, rscore)\n        t.append(estimates)\n        \n    iters, slopes = zip(*t)\n    return iters, slopes\n\ndef LeastSquares(xs, ys):\n    meanx, varx = np.mean(xs), np.var(xs)\n    meany = np.mean(ys)\n    \n    slope = covariance(xs, ys) \/ varx\n    inter = meany - slope * meanx\n    \n    return inter, slope\n\ndef de_mean(x):\n    x_bar = np.mean(x)\n    return [x_i - x_bar for x_i in x]\n\ndef covariance(x, y):\n    n = len(x)\n    return np.dot(de_mean(x), de_mean(y)) \/ (n - 1)\n\ndef ResampleRows(df):\n    return SampleRows(df, len(df), replace = True)\n\ndef SampleRows(df, nrows, replace=False):\n    indices = np.random.choice(df.index, nrows, replace=replace)\n    sample = df.loc[indices]\n    return sample","39a7d915":"def RMSE(estimates, actual):\n    e2 = [(estimate - actual) ** 2 for estimate in estimates]\n    mse = np.mean(e2)\n    return mse ** (1\/2)","09f9d34f":"inters = SamplingDistributions(df)[0]\nslopes = SamplingDistributions(df)[1]\n\nprint('Mean of intercepts is: ', np.mean(inters))\nprint('90% confidence interval of intercepts is: ', np.percentile(inters, 5), '-', np.percentile(inters, 95))\nprint('Standard error of intercepts is: ', RMSE(inters, 6.688023759635257))\nprint('\\n')\nprint('Mean of slopes is: ', np.mean(slopes))\nprint('90% confidence interval of slopes is: ', np.percentile(slopes, 5), '-', np.percentile(slopes, 95))\nprint('Standard error of slopes is: ', RMSE(slopes, 0.9181087994881232))","6f7eec72":"# ***I'll use the same intecept ans slope to predict the results***","67ffd94a":"1. [Elemental approach to finding correlation](https:\/\/www.kaggle.com\/ritikpnayak\/elemental-approach-to-finding-correlation)\n\n2. [Computing the magnitude of skewness in Maths score](https:\/\/www.kaggle.com\/ritikpnayak\/computing-the-magnitude-of-skewness-in-maths-score)","812a8517":"# Disclaimer","d7958b39":"# 3. Conclusion","da0d0f2d":"1. The SE for the itercept and the slope is 0.5 and 0.0075 respectively.\n2. This means that we expect the intercept and slope are expected to be off by 0.5 and 0.0075 respectively.\n3. The difference between the extremes of the confidence intervals of intercepts (7.61 - 5.98) and slopes (0.92 - 0.90) is quite less.\n4. This means that if we run the sample 101 times, we expect 90% of the values to fall between the respective range. The 90% CI for both the intercept and slope is very near to the mean of the estimates which indicates the validity\/accuracy of the mean of the estimates.","ce62fb8f":"# Previous notebooks on the same dataset:","55848bda":"***What is standard error?***\n\n1. standard error or SE  is a measure of how far we expect the estimate to be off, on average.\n2. We find it using the Root Mean Square Error or RMSE.\n3. It is NOT EQUAL to standard deviation.\n\n***Whats is confidence interval?***\n\n1. A confidence interval (CI) is a range that includes a given fraction of the sampling distribution.\n2. For instance, if we say that a certain number of values fall in the 90 percent confidence interval, we mean that if we take 90 out of 100 values, we would expect those values to fall in that range.","f8480bd2":"1. [Introduction to Hypothesis Testing and Estimation](https:\/\/www.kaggle.com\/ritikpnayak\/introduction-to-hypothesis-testing-and-estimation)","2ab427dc":"# 2. Sampling Distributions","0556d64f":"1. In the first part, I found that the fit line for our data. \n2. The R square for out line was as big as 0.9.\n3. In this notebook, I analyze the errors associated with the intercept and slope of the line.\n4. I'll specifically look for standard error and the confidence interval for both intercept and slope.","4111c7d6":"To assess the SE, I'll answer the question; \n\n***\"If we run this experiment again, how much variability do we expect in the estimates?\"***","0609e530":"# Previous notebooks on the same subject:","ef699f45":"# 1. What I am going to do in this notebook?","62330bbc":"In the code;\n\n**print('Standard error of intercepts is: ', RMSE(inters, 6.688023759635257))**,\n\nthe number 6.6880... is the value of the intercept of the line that I draw in my previous notebook (which is the fit line for our data). \n\nSimilarly, in the code;\n\n**print('Standard error of slopes is: ', RMSE(slopes, 0.9181087994881232))**,\n\nthe number is the value of the slope that I found in the previous notebook.","eda2c7a4":"***The code is self-explanatory***","47cc20db":"***This is the second part of the series of notebook meant to do a regression analysis on this dataset. The first notebook of this series: [Regression model-1: The best fit line with R2>0.9](https:\/\/www.kaggle.com\/ritikpnayak\/regression-model-1-the-best-fit-line-with-r2-0-9)***"}}