{"cell_type":{"e6a17297":"code","bc0d11ee":"code","3321b093":"code","77b97bb2":"code","d6a61a38":"code","595878e1":"code","1ef794df":"code","90519384":"code","4da0ec95":"code","f175c9b7":"code","2a9eef54":"code","49673f9a":"code","8200d4a2":"code","7f69a3d5":"code","5070bcec":"code","321fb292":"code","032391e3":"code","70210b62":"code","b0597227":"code","85230387":"code","d476a045":"code","11d892b5":"code","e557851c":"code","40e457a6":"code","7ce58d30":"code","af1a1ca5":"code","324d380a":"code","5fadb1e3":"code","7f6cbbd2":"code","86f34847":"code","21f175ce":"code","53736d3f":"code","4d938dd6":"code","ae620da3":"code","727a128e":"code","53acdb56":"code","28e7b059":"code","7d763102":"code","6accc274":"code","e58d8ca0":"code","637c961c":"code","5a00bb64":"code","050a05d5":"markdown","64b751cc":"markdown","35380436":"markdown","a7ca9b42":"markdown","dd91d095":"markdown","d71fa5f7":"markdown","0af51423":"markdown","576e399f":"markdown","ddbf53c8":"markdown","a7e36fe9":"markdown","89813c8b":"markdown","e0e27831":"markdown","149a4799":"markdown","44c35b44":"markdown","1e073a5b":"markdown"},"source":{"e6a17297":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bc0d11ee":"raw_train = pd.read_csv('\/kaggle\/input\/seoul-bike-rental-ai-pro-iti\/train.csv' , index_col='ID')\nraw_test = pd.read_csv('\/kaggle\/input\/seoul-bike-rental-ai-pro-iti\/test.csv'  , index_col='ID')\nprint(f\"train set size : {raw_train.shape} \\ntest set size : {raw_test.shape}\")","3321b093":"raw_train.head(5)","77b97bb2":"raw_train.info()","d6a61a38":"from sklearn.base import TransformerMixin , BaseEstimator\nfrom datetime import datetime\nclass TSSplit(BaseEstimator , TransformerMixin):\n    def __init__(self , format_str , out_col = ['year' , 'month' , 'day' , 'hour' , 'minute' , 'sec' , 'dayname' , 'dayNUM' , 'isweekend' , 'DayNight' , 'week_num'] , weed_end_days = ['Saturday' ,'Sunday'] , morning_interval = (6 , 17)):\n        self.format_str    = format_str\n        self.out_col       = out_col\n        self.weed_end_days = weed_end_days\n        self.morning_interval = morning_interval\n    \n    def fit(self , X , y=None):\n        return self\n    \n    def columns(self):\n        return self.out_col\n    \n    def transform(self , X):\n        col = X.copy().values\n        dict = {}\n        \n        for i in self.out_col:\n            if i == 'day'      : dict['day'       ] = np.array([datetime.strptime(i[0], self.format_str).day                                  for i in col] ).reshape(-1,1)\n            if i == 'year'     : dict['year'      ] = np.array([datetime.strptime(i[0], self.format_str).year                                 for i in col] ).reshape(-1,1)\n            if i == 'month'    : dict['month'     ] = np.array([datetime.strptime(i[0], self.format_str).month                                for i in col] ).reshape(-1,1)\n            if i == 'hour'     : dict['hour'      ] = np.array([datetime.strptime(i[0], self.format_str).hour                                 for i in col] ).reshape(-1,1)\n            if i == 'minute'   : dict['minute'    ] = np.array([datetime.strptime(i[0], self.format_str).minute                               for i in col] ).reshape(-1,1)\n            if i == 'sec'      : dict['sec'       ] = np.array([datetime.strptime(i[0], self.format_str).second                               for i in col] ).reshape(-1,1)\n            if i == 'dayname'  : dict['dayname'   ] = np.array([datetime.strptime(i[0], self.format_str).strftime(\"%A\")                       for i in col] ).reshape(-1,1)\n            if i == 'dayNUM'   : dict['dayNUM'    ] = np.array([datetime.strptime(i[0], self.format_str).isoweekday()                         for i in col] ).reshape(-1,1)\n            if i == 'isweekend': dict['isweekend' ] = np.array([datetime.strptime(i[0], self.format_str).strftime(\"%A\") in self.weed_end_days for i in col] ).astype(int).reshape(-1,1)\n            if i == 'DayNight' : dict['DayNight'  ] = np.array(\n                [\n                    (datetime.strptime(i[0], self.format_str).hour > self.morning_interval[0]) and\n                    (datetime.strptime(i[0], self.format_str).hour < self.morning_interval[1]) for i in col\n                ] \n            ).astype(int).reshape(-1,1)\n            if i == 'week_num'      : dict['week_num'       ] = np.array([datetime.strptime(i[0], self.format_str).strftime(\"%V\")                       for i in col] ).astype(int).reshape(-1,1)\n        \n        out_list = []\n        \n        for i in self.out_col:\n            out_list.append(dict[i])\n        return np.concatenate(out_list , axis=1)","595878e1":"# exmple\nfrom sklearn.compose import ColumnTransformer\n\nobj = TSSplit(format_str='%d\/%m\/%Y' , out_col = ['month','year' , 'day' , 'dayNUM' , 'isweekend' ,  'week_num'] , weed_end_days = ['Saturday' ,'Sunday'] , morning_interval = (6 , 17))\n\ntrain_out = obj.fit_transform(raw_train)\ndate_transformation_train = pd.DataFrame(train_out , columns=obj.columns())\n\ntest_out = obj.fit_transform(raw_test)\ndate_transformation_test = pd.DataFrame(test_out , columns=obj.columns())\ndate_transformation_test = date_transformation_test.set_index(raw_test.index)\n\ntrain = pd.concat( [raw_train.drop(['Date'] , axis = 1) , date_transformation_train] , axis = 1)\ntest = pd.concat( [raw_test.drop(['Date'] , axis = 1) , date_transformation_test] , axis = 1 )","1ef794df":"train['DayNight'] = np.array([( i > 11) and (i < 20)  for i in train.Hour]).astype(int).reshape(-1,1) \ntest['DayNight'] = np.array([( i > 11) and (i < 20)  for i in test.Hour]).astype(int).reshape(-1,1) \nsns.histplot(train['DayNight'] , binwidth = 0.5 ,  color = 'r')","90519384":"train.head(5)","4da0ec95":"plt.figure(figsize=(15,5))\n# sns.set_style(\"darkgrid\")\nsns.scatterplot(data=train, x=\"month\", y='Temperature(\ufffdC)' , hue='y' , size='y');\nsns.lineplot(data = train , x = 'month' , y = 'Temperature(\ufffdC)' , color='red')\nplt.show()","f175c9b7":"plt.figure(figsize=(15,5));\nsns.relplot(data = train , x = 'Hour' , y = 'y' ,  hue='DayNight' , palette = 'Reds');","2a9eef54":"# Plot for Temperature & Humidity by Summary\nplt.figure(figsize=(12,12))\nplt.title('Temperature vs Humidity')\nsns.scatterplot(\n    data    = train ,\n    x       = 'Temperature(\ufffdC)',\n    y       = 'Humidity(%)',\n    hue     = 'y', \n    palette = 'Reds',\n    s       = 75 , \n    alpha   = 0.6)\nplt.show()","49673f9a":"train['Solar Radiation (MJ\/m2)'] = np.log(train['Solar Radiation (MJ\/m2)']+1)\ntest['Solar Radiation (MJ\/m2)'] = np.log(test['Solar Radiation (MJ\/m2)']+1)\n\ntrain['Visibility (10m)'] = train['Visibility (10m)'] \/2000\ntest['Visibility (10m)'] = test['Visibility (10m)'] \/ 2000\n\ndata = train['Humidity(%)'] ; train['Humidity(%)'] = (data - data.min()) \/ (data.max() - data.min())\ndata = test['Humidity(%)']  ; test['Humidity(%)'] = (data - data.min()) \/ (data.max() - data.min())\n\ndata = train['Rainfall(mm)'] ; train['Rainfall(mm)'] = (data - data.min()) \/ (data.max() - data.min())\ndata = test['Rainfall(mm)'] ; test['Rainfall(mm)'] = (data - data.min()) \/ (data.max() - data.min())\n\ndata = train['Snowfall (cm)'] ; train['Snowfall (cm)'] = (data - data.min()) \/ (data.max() - data.min())\ndata = test['Snowfall (cm)'] ; test['Snowfall (cm)'] = (data - data.min()) \/ (data.max() - data.min())\n","8200d4a2":"fig , ax  = plt.subplots(2 , 3)\nfig.set_size_inches(18.5, 10.5)\nsns.histplot(train['Solar Radiation (MJ\/m2)'] , color = 'r' , kde = True , ax = ax[0,0])\nsns.histplot(train['Visibility (10m)'] , color = 'r' , kde = True , ax = ax[0,1])\nsns.histplot(train['Humidity(%)'] , color = 'r' , kde = True , ax = ax[0,2])\nsns.histplot(train['Rainfall(mm)'] , color = 'r' , kde = True , ax = ax[1,0])\nsns.histplot(train['Snowfall (cm)'] , color = 'r' , kde = True , ax = ax[1,1])","7f69a3d5":"from sklearn.base import TransformerMixin , BaseEstimator\nfrom sklearn.cluster import DBSCAN , KMeans \n\nfrom datetime import datetime\n\nclass LablizeGroup(BaseEstimator , TransformerMixin):\n    def __init__(self  , df , columns , K = 5 ):\n        self.K    = K\n        self.df  = df\n        self.columns = columns\n    \n    def fit(self , X=None , y=None):\n        self.clustrer = KMeans(n_clusters = self.K , random_state=42)\n        return self\n        \n    def getLablesFromTest(self , test_df):\n        data_to_get_label = test_df[self.columns]\n        labels = self.clustrer.predict(data_to_get_label)\n        return pd.DataFrame(labels , columns=['lables'])\n    \n    def transform(self , X):\n        data_to_cluster = self.df[self.columns]\n        labels          = self.clustrer.fit_predict(data_to_cluster)\n        return pd.DataFrame(self.clustrer.labels_ , columns=['lables'])","5070bcec":"LablizeGroup_obj = LablizeGroup(\n    train , \n    ['Temperature(\ufffdC)', 'Humidity(%)', 'Wind speed (m\/s)', 'Visibility (10m)','Solar Radiation (MJ\/m2)', 'Rainfall(mm)', 'Snowfall (cm)'] , \n    K = 7\n)\nres2 = LablizeGroup_obj.fit_transform(train)\nlabels = pd.DataFrame(res2)\nlabled_train = pd.concat([train , labels] , axis  = 1)","321fb292":"LablizeGroup_obj \nres2 = LablizeGroup_obj.getLablesFromTest(test)\nlabels = pd.DataFrame(res2 )\nlabels = labels.set_index(test.index)\nlabled_test = pd.concat([test , labels] , axis  = 1)","032391e3":"sns.histplot(labled_train.lables , binwidth = 0.5 ,  color = 'r')","70210b62":"modified = labled_train.copy()\n\nmodified['Temperature(\ufffdC)'          ] = np.abs  (np.round(np.log(modified['Temperature(\ufffdC)' ] +20 ))).astype(int)\nmodified['Humidity(%)'              ] = np.round(np.log(modified['Humidity(%)'              ] +1  )).astype(int)\nmodified['Wind speed (m\/s)'         ] = np.round(np.log(modified['Wind speed (m\/s)'         ] +1  )).astype(int)\nmodified['Visibility (10m)'         ] = np.round(np.log(modified['Visibility (10m)'         ] +1  )).astype(int)\nmodified['Dew point temperature(\ufffdC)'] = np.round(np.log(modified['Dew point temperature(\ufffdC)'] +28 )).astype(int)\nmodified['Solar Radiation (MJ\/m2)'  ] = np.round(np.log(modified['Solar Radiation (MJ\/m2)'  ] +1  )).astype(int)\nmodified['Rainfall(mm)'             ] = np.round(np.log(modified['Rainfall(mm)'             ] +1  )).astype(int)\nmodified['Snowfall (cm)'            ] = np.round(np.log(modified['Snowfall (cm)'            ] +1  )).astype(int)\n\nmodified['count'] = modified['y']\nmodified\n\ng = modified.groupby(\n    ['Temperature(\ufffdC)','Humidity(%)',\n     'Visibility (10m)','Dew point temperature(\ufffdC)',\n     'Solar Radiation (MJ\/m2)','Rainfall(mm)',\n     'Snowfall (cm)','month'\n    ])['y'].agg(np.mean)\n\ng = pd.DataFrame(g).reset_index()\ng['y'] = g['y'].astype(int)\n\nmodified = modified.merge(g , \n               on = ['Temperature(\ufffdC)','Humidity(%)',\n                     'Visibility (10m)','Dew point temperature(\ufffdC)',\n                     'Solar Radiation (MJ\/m2)','Rainfall(mm)',\n                     'Snowfall (cm)','month'] ,\n               suffixes=('', '_modified') ,how='left')\n\ngrouped_train = pd.concat([labled_train , modified['y_modified']] , axis = 1)","b0597227":"\nmodified_t = labled_test.copy()\n\nmodified_t['Temperature(\ufffdC)'          ] = np.abs  (np.round(np.log(modified_t['Temperature(\ufffdC)' ] +20 ) )).astype(int)\nmodified_t['Humidity(%)'              ] = np.round(np.log(modified_t['Humidity(%)'              ] +1  ) ).astype(int)\nmodified_t['Wind speed (m\/s)'         ] = np.round(np.log(modified_t['Wind speed (m\/s)'         ] +1  ) ).astype(int)\nmodified_t['Visibility (10m)'         ] = np.round(np.log(modified_t['Visibility (10m)'         ] +1  ) ).astype(int)\nmodified_t['Dew point temperature(\ufffdC)'] = np.round(np.log(modified_t['Dew point temperature(\ufffdC)'] +40 ) ).astype(int)\nmodified_t['Solar Radiation (MJ\/m2)'  ] = np.round(np.log(modified_t['Solar Radiation (MJ\/m2)'  ] +1  ) ).astype(int)\nmodified_t['Rainfall(mm)'             ] = np.round(np.log(modified_t['Rainfall(mm)'             ] +1  ) ).astype(int)\nmodified_t['Snowfall (cm)'            ] = np.round(np.log(modified_t['Snowfall (cm)'            ] +1  ) ).astype(int)\n\n\nmodified_t = modified_t.merge(g , \n               on = ['Temperature(\ufffdC)','Humidity(%)',\n                     'Visibility (10m)','Dew point temperature(\ufffdC)',\n                     'Solar Radiation (MJ\/m2)','Rainfall(mm)',\n                     'Snowfall (cm)','month'] ,\n               suffixes=('', '_modified') ,how='left')\n\nmodified_t['y'] = modified_t['y'].fillna(modified_t['y'].mean())\n\ntemp         = pd.DataFrame(modified_t['y']).set_index(labled_test.index)\ngrouped_test = pd.concat([labled_test , temp] , axis = 1)\ngrouped_test = grouped_test.rename(columns={\"y\": \"y_modified\"})","85230387":"from sklearn.base import TransformerMixin , BaseEstimator\nfrom datetime import datetime\nimport numpy as np\nclass Window(BaseEstimator , TransformerMixin):\n    def __init__(self , on , window_size = 12 , function = np.median , del_original = True):\n        self.window_size = window_size\n        self.on = on\n        self.function = function\n        self.del_original = del_original\n        self.res = None\n    \n    def fit(self , X , y=None):\n        return self\n    \n    def transorm_for_test(self , X):\n        col = X.copy().values.reshape(-1 , 1)\n        a = np.concatenate([self.on.copy().values.reshape(-1 , 1) , self.res] , axis = 1)\n        x = pd.DataFrame(a).groupby(0).agg({1:self.function})\n        out = pd.DataFrame(col).merge(x , how = 'left' , on = 0)\n        return np.round(out[1])\n    \n    def transform(self , X):\n        on_col = self.on.copy().values.reshape(-1 , 1)\n        col = X.copy().values.reshape(-1 , 1)\n        self.res = np.zeros(col.shape)\n        for i in range(len(col)):\n            if i < self.window_size :\n                self.res[i,0] = col[i,0]\n            else :\n                avg = self.function(col[i-self.window_size:i , 0])\n                self.res[i,0] = np.round(avg , 2)\n        print(on_col.shape , col.shape , self.res.shape)\n        if self.del_original == True:\n            return self.res\n        if self.del_original == False:\n            return np.concatenate([col , self.res] , axis = 1)","d476a045":"obj = Window(on = grouped_train.Hour, window_size = 5 , function = np.mean , del_original = True)\nout = obj.fit_transform(train['y'])\nwindowed_train = pd.concat([grouped_train , pd.DataFrame(out , columns = ['window'])] , axis  = 1)","11d892b5":"out = pd.DataFrame(obj.transorm_for_test(X = grouped_test.Hour) )\nout = out.rename(columns = {1: 'window'})\nout = out.set_index(grouped_test.index)\nwindowed_test = pd.concat([grouped_test , out] , axis = 1)","e557851c":"plt.figure(figsize=(15,15))\nsns.heatmap(data=windowed_train.corr(), annot=True, cmap='Blues' ,  fmt='.1')\nplt.show()","40e457a6":"enc_train = pd.get_dummies(data = windowed_train)\nenc_test = pd.get_dummies(data = windowed_test)","7ce58d30":"# from sklearn.decomposition import PCA\n\n\n# pca = PCA(n_components=4)\n# pca.fit(enc_train.drop(['y'] , axis = 1))\n\n# pca_train = pca.transform(enc_train.drop(['y'] , axis = 1))\n# pca_test = pca.transform(enc_test)\n\n# pca_train = pd.concat([enc_train , pd.DataFrame(pca_train)] , axis = 1)\n# pca_test = pd.concat([enc_test , pd.DataFrame(pca_test).set_index(enc_test.index)] , axis = 1)\n","af1a1ca5":"# import numpy as np\n# from sklearn.manifold import TSNE\n\n# tsen = TSNE(n_components=3)\n# tsen_train = tsen.fit_transform(enc_train.drop(['y'] , axis = 1))\n# tsen_test = tsen.fit_transform(enc_test)\n\n# tsen_train = pd.concat([enc_train , pd.DataFrame(tsen_train)] , axis = 1)\n# tsen_test = pd.concat([enc_test , pd.DataFrame(tsen_test).set_index(enc_test.index)] , axis = 1)\n","324d380a":"\n# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n# clf = LinearDiscriminantAnalysis()\n# clf.fit( enc_train.drop(['y'] , axis = 1), np.round(enc_train['y']).astype(int))\n\n# LDA_train = clf.predict(enc_train.drop(['y'] , axis = 1))\n# LDA_test  = clf.predict(enc_test)\n\n# LDA_train = pd.concat([enc_train , pd.DataFrame(LDA_train)] , axis = 1)\n# LDA_test = pd.concat([enc_test , pd.DataFrame(LDA_test).set_index(enc_test.index)] , axis = 1)","5fadb1e3":"# from sklearn.decomposition import TruncatedSVD\n\n# svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n# svd.fit( enc_train.drop(['y'] , axis = 1))\n\n# svd_train = svd.transform(enc_train.drop(['y'] , axis = 1))\n# svd_test  = svd.transform(enc_test)\n\n# svd_train = pd.concat([enc_train , pd.DataFrame(svd_train)] , axis = 1)\n# svd_test  = pd.concat([enc_test , pd.DataFrame(svd_test).set_index(enc_test.index)] , axis = 1)","7f6cbbd2":"droped = ['isweekend' ,'DayNight','Dew point temperature(\ufffdC)','day','Wind speed (m\/s)','Seasons_Spring','Seasons_Summer','Seasons_Winter','lables','window','y_modified']","86f34847":"# final_train , final_test = svd_train  , svd_test\n# final_train , final_test = LDA_train  , LDA_test\n# final_train , final_test = tsen_train , tsen_test\n# final_train , final_test = pca_train  , pca_test\nfinal_train , final_test = enc_train  , enc_test","21f175ce":"final_train['all'] = final_train['Holiday_Holiday']+final_train['Holiday_No Holiday']+final_train['Functioning Day_No']+final_train['Functioning Day_Yes']\nfinal_test ['all'] = final_test ['Holiday_Holiday']+final_test ['Holiday_No Holiday']+final_test ['Functioning Day_No']+final_test ['Functioning Day_Yes']\n\nfinal_train['weather'] = (0.65*final_train['Solar Radiation (MJ\/m2)']+0.66*final_train['Rainfall(mm)']+final_train['Snowfall (cm)'])\nfinal_test ['weather'] = (0.63*final_test ['Solar Radiation (MJ\/m2)']+0.64*final_test ['Rainfall(mm)']+final_test ['Snowfall (cm)'])","53736d3f":"final_train['Shifted_temp']=final_train['Temperature(\ufffdC)'].shift(-1)\nfinal_train['Rainfall(mm)']=final_train['Rainfall(mm)'].shift(-1)\n\nfinal_test['Shifted_temp']=final_test['Temperature(\ufffdC)'].shift(-1)\nfinal_test['Rainfall(mm)']=final_test['Rainfall(mm)'].shift(-1)","4d938dd6":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import make_scorer\n\ndef my_custom_loss_func(y_true, y_pred):\n    diff = np.sqrt(mean_squared_log_error(y_true , abs(y_pred)))\n    return diff\n\nscore = make_scorer(my_custom_loss_func, greater_is_better=False)","ae620da3":"X = final_train.drop(['y'] + droped , axis = 1)\ny = np.log(final_train['y'] + 1)","727a128e":"lt     = final_test.drop(droped , axis = 1)","53acdb56":"from sklearn.preprocessing import QuantileTransformer\nqt = QuantileTransformer(random_state=0)\nX=qt.fit_transform(X)\nX_test=qt.fit_transform(lt)\n","28e7b059":"from catboost import CatBoostRegressor\ncatbmodel = CatBoostRegressor(\n    iterations          = 6575,\n    learning_rate       = 0.05,\n    loss_function       = \"RMSE\",\n    random_state        = 42,\n    verbose             = 0,\n    bootstrap_type      = \"Bayesian\",\n    bagging_temperature = 0.2,\n    depth               = 2,\n    l2_leaf_reg         = 1,\n).fit( X , y )","7d763102":"scores = -1 * cross_val_score(catbmodel, X, y, cv=5, scoring = score)\nscores.mean()","6accc274":"import xgboost as xgb\nfrom sklearn.ensemble import BaggingRegressor\nxg_reg = BaggingRegressor(\n    base_estimator = xgb.XGBRegressor(colsample_bytree = 0.9, learning_rate = 0.15, max_depth = 3,  n_estimators =500),                    \n    n_estimators = 4, \n    random_state = 0\n).fit(X , y)","e58d8ca0":"scores = -1 * cross_val_score(xg_reg, X, y, cv=5, scoring = score)\nscores.mean()","637c961c":"y_out3 = np.fix(np.exp(xg_reg.predict(X_test)) - 1)","5a00bb64":"output = pd.DataFrame({'ID': raw_test.index,'y': y_out3})\noutput.to_csv('submission.csv', index=False)\noutput","050a05d5":"# <center> transform categorical columns","64b751cc":"# <center> fit with xgboost regression model","35380436":"# <center> split X , y from train set","a7ca9b42":"# <center> make custom scoring function to use with cross validation","dd91d095":"# <center> fit with cat boost regression model","d71fa5f7":"# <center> drop columns that make score worse","0af51423":"# <center> transform some columns","576e399f":"# <center>reading datasets","ddbf53c8":"# <center> check features coreleation","a7e36fe9":"# <center> extracting data from date time col","89813c8b":"# <center> try diffrent decomposition technique","e0e27831":"# <center> get the mean number of bikes for the last 12 hour","149a4799":"# <center> generate calculated column from existing one","44c35b44":"# <center> group similar weather conditions togeather","1e073a5b":"# <center> get mean number of bikes for diffrent weather condition"}}