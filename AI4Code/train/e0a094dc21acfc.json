{"cell_type":{"e41d0b30":"code","159093a7":"code","85612aca":"code","efda458c":"code","c0b9a15d":"code","62527305":"code","5baa2974":"code","5a9485ba":"code","0eed1097":"code","6c5b8afa":"code","9a9f1fa0":"code","861d7f96":"code","207c5bf7":"markdown","bab910a6":"markdown","00bc904f":"markdown","9f046ce2":"markdown","8b1e746d":"markdown","29f8957e":"markdown","9211099d":"markdown","90d4a8ad":"markdown"},"source":{"e41d0b30":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib as ml\nimport matplotlib.pyplot as plt\n%matplotlib inline\nml.style.use('fivethirtyeight')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","159093a7":"data = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\ndata.head(60)","85612aca":"data.drop(columns=['Id'],inplace=True)\ndata","efda458c":"plt.figure(figsize=(20,10))\nsns.boxplot(data=data,palette='Set2')\nplt.title('Checking for the feature with least outliers')\nplt.show()","c0b9a15d":"sns.heatmap(data.corr(),annot=True,linewidth=0.1,linecolor='white')\nplt.title(\"Checking for the most correlated features\")\nplt.show()","62527305":"X = data['PetalLengthCm'].values\nY = data['PetalWidthCm'].values\nX.shape,Y.shape","5baa2974":"sns.scatterplot(x=X,y=Y,hue=data.Species)\nplt.xlabel('PetalLengthCm')\nplt.ylabel('PetalWidthCm')\nplt.title(\"Raw plotting of the data\")\nplt.show()","5a9485ba":"# Mean X and Y\nmn_x = np.mean(X)\nmn_y = np.mean(Y)\ntotal = len(X)    # Total number of values","0eed1097":"# Using the formula to calculate b0 and b1\nn = 0\nd = 0\nfor i in range(total):\n    n = n + ((X[i] - mn_x) * (Y[i] - mn_y))\n    d = d + ((X[i] - mn_x) ** 2)\nb1 = n \/ d                               # B1 = (summation([x[i] - x_mean]*(y[i] - y_mean)))\/((summation(x[i] - x_mean))^2)\nb0 = mn_y - (b1 * mn_x)                  # B0 = y_mean - (B1*x_mean)\n\n# Print coefficients\nprint(b1, b0)","6c5b8afa":"# Y = B0 + B1*X\n# PetalWidthCm = 325.573421049 + (0.263429339489 * PetalLengthCm)         \n\n# This is our linear model\n\n# Now plotting it to obtain best fit curve\n\nmax_x = np.max(X)\nmin_x = np.min(X)","9a9f1fa0":"# Generating unseen data\n# Calculating line values x and y\nx = np.linspace(min_x, max_x, 1000)\ny = b0 + b1 * x","861d7f96":"# Plotting\n\nplt.figure(figsize=(10,5))\n# Ploting Line based on linear model made from scratch : The unseen data\nplt.plot(x, y, color='blue', label='Regression Line')\n\n# Ploting Scatter Points of our actual dataset to see how well the model performs : The predefined data\nplt.scatter(X, Y, c='red', label='Scatter Plot')\nplt.xlabel('Petal Length in cm')\nplt.ylabel('Petal Width in cm')\nplt.title(\"Implentation of Linear Regression from scratch visualized\")\nplt.legend()\nplt.show()","207c5bf7":"## Calculation of Coefficients","bab910a6":"## Separating X and Y","00bc904f":"## Final comparative plot : Visualizing the best fit curve","9f046ce2":"**Clearly, PetalLengthCm and PetalWidthCm are the most related.**","8b1e746d":"# Implementing Linear Regression from scratch","29f8957e":"## Getting the equation","9211099d":"## Generating unseen data for analyzing best fit curve","90d4a8ad":"## So, by visually analyzing the distances of the data points from the best fit curve, we can say this is a fairly good fit."}}