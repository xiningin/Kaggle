{"cell_type":{"1d0cc4c2":"code","24c39fee":"code","5715cb39":"code","7d475936":"code","06ba21af":"code","466d0fbc":"code","68daf93f":"code","47e8bcc9":"code","204c6bee":"code","91b660b9":"markdown","80c73f55":"markdown","01e06c84":"markdown"},"source":{"1d0cc4c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","24c39fee":"train = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/test.csv')\n","5715cb39":"train.head()","7d475936":"train['power per wt'] = train['battery_power']\/train['mobile_wt']\ntrain['wt per vol'] = train.apply(lambda x: x['mobile_wt']\/(x['sc_h']*x['sc_w']*x['m_dep']) if x['sc_w']!=0 else 0 , axis = 1)\ntrain['power per core'] = train['battery_power']\/train['n_cores']\ntrain['pixels'] = train['px_height']*train['px_width']\ntrain['area'] = train['sc_h']*train['sc_w']\ntrain['px_density'] = train.apply(lambda x:x['pixels']\/x['area'] if x['area']!=0 else 0 , axis = 1)\ntrain['sc_size'] = np.sqrt(train['sc_h']**2 + train['sc_w']**2)\ntrain['time'] = train['battery_power']\/train['talk_time']\ntrain['power per clock'] = train['battery_power']\/train['clock_speed']","06ba21af":"train.isna().sum()","466d0fbc":"cols = ['battery_power','clock_speed','mobile_wt','n_cores','px_height','px_width','ram','sc_w','talk_time','power per wt','wt per vol', 'power per core','pixels','area','px_density','sc_size','time','power per clock',\"price_range\"] ","68daf93f":"train2 = train[cols]\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\ntrain , test = train_test_split(train2, test_size = 0.25)\n\nx_train = train.drop('price_range', axis=1)\ny_train = train['price_range']\n\nx_test = test.drop('price_range', axis = 1)\ny_test = test['price_range']\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nparam_grid = {'n_estimators':range(10,110,10) , 'criterion':['gini', 'entropy'],\n             'max_depth' : [1,2,3,4,5,6,7,8,9,10],'max_features':['auto', 'sqrt', 'log2']}\n\nclf = RandomizedSearchCV(RandomForestClassifier(),param_grid,cv = 10,n_iter = 30)\nclf = clf.fit(x_train, y_train)","47e8bcc9":"from sklearn.metrics import classification_report,accuracy_score\naccuracy_score(y_test , clf.predict(x_test))","204c6bee":"from sklearn.metrics import classification_report,accuracy_score\naccuracy_score(y_train , clf.predict(x_train))","91b660b9":"I am using a Random Forest Model with hyperparameter tuning ","80c73f55":"Feature Engineering ","01e06c84":"From the training and testing accuracies we can say that the model is kind of overfit but does the job "}}