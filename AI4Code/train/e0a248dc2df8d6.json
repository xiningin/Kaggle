{"cell_type":{"32148d56":"code","efad55a1":"code","206fd005":"code","4cd164f3":"code","faa769d0":"code","c79d9eca":"code","4ff14f7a":"code","829109b3":"code","d25ed93e":"code","78e24338":"code","b65b5131":"code","b9324590":"code","323cccb7":"code","c89ee163":"code","66f9e6ea":"code","dde7042c":"markdown","154fe5f5":"markdown","85236482":"markdown","22e3b9ed":"markdown","5e9dd401":"markdown","f9ee6182":"markdown","403455b8":"markdown","9babb564":"markdown","a1009e86":"markdown","f25103a2":"markdown","22385663":"markdown","98183304":"markdown","f3a70a38":"markdown","68e93d6e":"markdown","68fd53cd":"markdown","b90f79b1":"markdown","faab0dd6":"markdown"},"source":{"32148d56":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator","efad55a1":"tf.__version__","206fd005":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntraining_set = train_datagen.flow_from_directory('dataset\/training_set',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')","4cd164f3":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_set = test_datagen.flow_from_directory('dataset\/test_set',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","faa769d0":"cnn = tf.keras.models.Sequential()","c79d9eca":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))","4ff14f7a":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","829109b3":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","d25ed93e":"cnn.add(tf.keras.layers.Flatten())","78e24338":"cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))","b65b5131":"cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","b9324590":"cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","323cccb7":"cnn.fit(x = training_set, validation_data = test_set, epochs = 25)","c89ee163":"import numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('dataset\/single_prediction\/cat_or_dog_1.jpg', target_size = (64, 64))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n  prediction = 'dog'\nelse:\n  prediction = 'cat'","66f9e6ea":"print(prediction)","dde7042c":"### Preprocessing the Training set","154fe5f5":"# Convolutional Neural Network","85236482":"### Step 2 - Pooling","22e3b9ed":"## Part 1 - Data Preprocessing","5e9dd401":"### Step 3 - Flattening","f9ee6182":"## Part 4 - Making a single prediction","403455b8":"### Importing the libraries","9babb564":"### Training the CNN on the Training set and evaluating it on the Test set","a1009e86":"### Step 5 - Output Layer","f25103a2":"### Adding a second convolutional layer","22385663":"### Step 4 - Full Connection","98183304":"## Part 3 - Training the CNN","f3a70a38":"### Initialising the CNN","68e93d6e":"### Step 1 - Convolution","68fd53cd":"### Compiling the CNN","b90f79b1":"### Preprocessing the Test set","faab0dd6":"## Part 2 - Building the CNN"}}