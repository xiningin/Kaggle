{"cell_type":{"692affbe":"code","170deec3":"code","c53ce984":"code","3b877bc8":"code","7e955d6e":"code","bda54ee9":"code","80b4ac63":"code","afa46690":"markdown","90854093":"markdown","5123aed6":"markdown","5c535414":"markdown","f9eb6725":"markdown","4be8c244":"markdown","563429aa":"markdown","27649e8c":"markdown"},"source":{"692affbe":"import pandas as pd\nimport numpy as np","170deec3":"df_train = pd.read_csv('..\/input\/X_train.csv', encoding='cp949')\ndf_test = pd.read_csv('..\/input\/X_test.csv', encoding='cp949')\ny_train = pd.read_csv('..\/input\/y_train.csv').gender\nIDtest = df_test.custid.unique()\n\ndf_train.head()","c53ce984":"p_level = 'corner_nm'  # \uc0c1\ud488 \ubd84\ub958 \uc218\uc900\n\n# W2V \ud559\uc2b5\uc744 \ud558\uae30\uc5d0\ub294 \ub370\uc774\ud130(\uc989 corpus)\uac00 \ubd80\uc871\ud558\uc5ec \n# \uace0\uac1d\ubcc4\ub85c \uad6c\ub9e4\ud55c \uc0c1\ud488 \ubaa9\ub85d\uc73c\ub85c\ubd80\ud130 n\ubc30 oversampling\uc744 \uc218\ud589\ndef oversample(x, n):\n    if n == 0:\n        return list(x)\n    uw = np.unique(x)\n    bs = np.array([])\n    for j in range(n):\n        bs = np.append(bs, np.random.choice(uw, len(uw), replace=False))\n    return list(bs)\n\nX_train = list(df_train.groupby('custid')[p_level].agg(oversample, 20))\nX_test = list(df_test.groupby('custid')[p_level].agg(oversample, 20))","3b877bc8":"num_features = 100 # \ub2e8\uc5b4 \ubca1\ud130 \ucc28\uc6d0 \uc218\nmin_word_count = 1 # \ucd5c\uc18c \ub2e8\uc5b4 \uc218\ncontext = 5 # \ud559\uc2b5 \uc708\ub3c4\uc6b0(\uc778\uc811\ud55c \ub2e8\uc5b4 \ub9ac\uc2a4\ud2b8) \ud06c\uae30\n\n# \ucd08\uae30\ud654 \ubc0f \ubaa8\ub378 \ud559\uc2b5\nfrom gensim.models import word2vec\n\n# \ubaa8\ub378 \ud559\uc2b5\nmodel = word2vec.Word2Vec(X_train, \n                          size=num_features, \n                          min_count=min_word_count,\n                          window=context,)\n# \ud544\uc694\uc5c6\ub294 \uba54\ubaa8\ub9ac unload\nmodel.init_sims(replace=True)\n#model.wv.most_similar('\uc5ec\uc790',topn=20)","7e955d6e":"# \uad6c\ub9e4\uc0c1\ud488\uc5d0 \ud574\ub2f9\ud558\ub294 \ubca1\ud130\uc758 \ud3c9\uade0\/\ucd5c\uc18c\/\ucd5c\ub300 \ubca1\ud130\ub97c feature\ub85c \ub9cc\ub4dc\ub294 \uc804\ucc98\ub9ac\uae30(pipeline\uc5d0\uc11c \uc0ac\uc6a9 \uac00\ub2a5)\nclass EmbeddingVectorizer(object):\n    def __init__(self, word2vec):\n        self.word2vec = word2vec\n        self.dim = num_features\n    def fit(self, X, y):\n        return self\n    def transform(self, X):\n        return np.array([\n            np.hstack([\n                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n            ]) \n            for words in X\n        ])  ","bda54ee9":"from sklearn.pipeline import Pipeline\nfrom xgboost import XGBClassifier\n\nmodel = Pipeline([\n    (\"W2V vectorizer\", EmbeddingVectorizer(model.wv)),\n    (\"xgboost\", XGBClassifier())])\n\nmodel.fit(X_train, y_train)","80b4ac63":"pred = model.predict_proba(X_test)[:,1]\nfname = 'submissions.csv'\nsubmissions = pd.concat([pd.Series(IDtest, name=\"custid\"), pd.Series(pred, name=\"gender\")] ,axis=1)\nsubmissions.to_csv(fname, index=False)\nprint(\"'{}' is ready to submit.\" .format(fname))","afa46690":"### Make features","90854093":"### Make corpus","5123aed6":"### Build models","5c535414":"### Training the Word2Vec model","f9eb6725":"### Make submissions","4be8c244":"### Read data","563429aa":"### Imports","27649e8c":"## End"}}