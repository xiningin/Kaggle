{"cell_type":{"1cf3ad38":"code","d96ce5db":"code","69698c46":"code","65f50e60":"code","7321d409":"code","cdc80317":"code","e925a70e":"code","415c7d20":"code","9d723b7b":"code","92ea2019":"code","0d426e04":"code","006819ff":"code","1b2716f5":"code","d0fd8a3d":"code","f8e18694":"code","ab43de30":"code","959ffc68":"code","58600adc":"markdown","f80b7839":"markdown","5138085f":"markdown","30bdf5b0":"markdown","efb9f984":"markdown","fb1b78fd":"markdown","fd5ddd9e":"markdown","75e75846":"markdown","43c3a802":"markdown","9d0f76bc":"markdown","412520a6":"markdown","4e6c6c7b":"markdown"},"source":{"1cf3ad38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d96ce5db":"# Need to install apyori first\n!pip install apyori","69698c46":"# Import the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom apyori import apriori\nfrom wordcloud import WordCloud","65f50e60":"#Import dataset\ndataset = pd.read_csv('\/kaggle\/input\/market-basket-optimization\/Market_Basket_Optimisation.csv', header = None)","7321d409":"dataset.shape","cdc80317":"dataset.sample(5)","e925a70e":"plt.figure(figsize=(15,15))\nwc = WordCloud(background_color = 'black', width = 1500,  height = 1500, max_words = 100).generate(str(dataset[0]))\nplt.imshow(wc)\nplt.axis('off')\nplt.title('Popular Items in Market Basket')\nplt.show()","415c7d20":"plt.figure(figsize=(20,10))\ncolor = plt.cm.cool(np.linspace(0, 1, 40))\ndataset[0].value_counts().head(40).plot.bar(color = color)\nplt.title('Market Analysis:Most sold products', fontsize = 30)\nplt.xticks(rotation = 90 )\nplt.show()","9d723b7b":"# Data preprocessing\ntransactions = []\nfor i in range(0, 7501):\n  transactions.append([str(dataset.values[i,j]) for j in range(0, 20)])","92ea2019":"# Training the Apriori model on the dataset\nrules_1 = apriori(transactions = transactions, min_support = 0.003, min_confidence = 0.2, min_lift = 3, min_length = 2, max_length = 2)","0d426e04":"# Make a list of the rules\nresults_1 = list(rules_1)","006819ff":"# Put the results well organised into a Pandas DataFrame\ndef inspect_apriori(results):\n    lhs         = [tuple(result[2][0][0])[0] for result in results]\n    rhs         = [tuple(result[2][0][1])[0] for result in results]\n    supports    = [result[1] for result in results]\n    confidences = [result[2][0][2] for result in results]\n    lifts       = [result[2][0][3] for result in results]\n    return list(zip(lhs, rhs, supports, confidences, lifts))\nresultsinDataFrame_1 = pd.DataFrame(inspect_apriori(results_1), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])","1b2716f5":"## Displaying the results sorted by descending lifts\nresultsinDataFrame_1.nlargest(n = 5, columns = 'Lift')","d0fd8a3d":"# Training the Eclat model on the dataset\nrules_2 = apriori(transactions = transactions, min_support = 0.003, min_confidence = 0.2, min_lift = 3, min_length = 2, max_length = 2)","f8e18694":"# Make a list of the rules\nresults_2 = list(rules_2)","ab43de30":"# Put the results well organised into a Pandas DataFrame\ndef inspect_eclat(results):\n    lhs         = [tuple(result[2][0][0])[0] for result in results]\n    rhs         = [tuple(result[2][0][1])[0] for result in results]\n    supports    = [result[1] for result in results]\n    return list(zip(lhs, rhs, supports))\nresultsinDataFrame_2 = pd.DataFrame(inspect_eclat(results_2), columns = ['Product 1', 'Product 2', 'Support'])","959ffc68":"## Displaying the results sorted by descending supports\nresultsinDataFrame_2.nlargest(n = 5, columns = 'Support')","58600adc":"Most of the customers like burgers!Why don't they like yogurt cake??!I love them anyways..","f80b7839":"**We have to import few libraries and also the dataset we want to work with :)**","5138085f":"Let us play with words ;)","30bdf5b0":"**Data Preprocessing**","efb9f984":"**First of all we need to install apyori library!**","fb1b78fd":"What is the shape of our dataset??","fd5ddd9e":"**Visualization: Let us have some fun**","75e75846":"**Thank you very much for giving my notebook a look!If you like it please upvote it :)**","43c3a802":"**Apriori Model**","9d0f76bc":"Have a nice day:)","412520a6":"Let us check few random data sample :)","4e6c6c7b":"So it has total 7501 rows and 20 columns.In each row we have food items purchased by a particular customer."}}