{"cell_type":{"690d1c40":"code","57f54603":"code","dc1585ca":"code","bed5e854":"code","a4170aab":"code","0b324bf0":"code","681cb848":"code","8b25fb0f":"code","89d556af":"code","cea123de":"code","9cacd926":"code","980ef329":"code","885e2bbc":"code","81203a48":"code","32ac6a73":"code","49db1d54":"code","99e044fc":"code","d1e14218":"markdown","84d6583c":"markdown","3db0483d":"markdown","d4ccd982":"markdown","dfc64e23":"markdown","454f5b44":"markdown"},"source":{"690d1c40":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","57f54603":"# Tensorflow builds NN\nimport tensorflow as tf\nprint('tensorflow version : ', tf.__version__)\n\n# default libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\n# for data preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","dc1585ca":"income = pd.read_csv(\"\/kaggle\/input\/adult-income-dataset\/adult.csv\")\nincome.head()","bed5e854":"income['income'] = income['income'].map({'<=50K':0, '>50K':1})","a4170aab":"income['income'].value_counts()","0b324bf0":"def init_check(df):\n    \"\"\"\n    A function to make initial check for the dataset including the name, data type, \n    number of null values and number of unique varialbes for each feature.\n    \n    Parameter: dataset(DataFrame)\n    Output : DataFrame\n    \"\"\"\n    columns = df.columns    \n    lst = []\n    for feature in columns : \n        dtype = df[feature].dtypes\n        num_null = df[feature].isnull().sum()\n        num_unique = df[feature].nunique()\n        lst.append([feature, dtype, num_null, num_unique])\n    \n    check_df = pd.DataFrame(lst)\n    check_df.columns = ['feature','dtype','num_null','num_unique']\n    check_df = check_df.sort_values(by='dtype', axis=0, ascending=True)\n    \n    return check_df","681cb848":"init_check(income)","8b25fb0f":"def categorical_encoding(df, categorical_cloumns, encoding_method):\n    \"\"\"\n    A function to encode categorical features to a one-hot numeric array (one-hot encoding) or \n    an array with value between 0 and n_classes-1 (label encoding).\n    \n    Parameters:\n        df (pd.DataFrame) : dataset\n        categorical_cloumns  (string) : list of features \n        encoding_method (string) : 'one-hot' or 'label'\n    Output : pd.DataFrame\n    \"\"\"\n    \n    if encoding_method == 'label':\n        print('You choose label encoding for your categorical features')\n        encoder = LabelEncoder()\n        encoded = df[categorical_cloumns].apply(encoder.fit_transform)\n        return encoded\n    \n    elif encoding_method == 'one-hot':\n        print('You choose one-hot encoding for your categorical features') \n        encoded = pd.DataFrame()\n        for feature in categorical_cloumns:\n            dummies = pd.get_dummies(df[feature], prefix=feature)\n            encoded = pd.concat([encoded, dummies], axis=1)\n        return encoded","89d556af":"def data_preprocessing(df, features, target, encoding_method, test_size, random_state):\n    \n    \n    y = df[target]\n    \n    X = df[features]\n    \n    categorical_columns = X.select_dtypes(include=['object']).columns\n    \n    if len(categorical_columns) != 0 :\n        encoded = categorical_encoding(X, categorical_cloumns=categorical_columns, encoding_method=encoding_method)\n        X = X.drop(columns=categorical_columns, axis=1)\n        X = pd.concat([X, encoded], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    \n    scaler=MinMaxScaler()\n    X_train= pd.DataFrame(scaler.fit_transform(X_train))\n    X_test = pd.DataFrame(scaler.transform(X_test))\n    \n    return X_train, X_test, y_train, y_test","cea123de":"features = income.columns.drop('income')\nX_train, X_test, y_train, y_test = data_preprocessing(df=income, features=features, \n                                                      target='income', encoding_method = 'label',\n                                                      test_size=0.2, random_state=0)\n\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","9cacd926":"model = tf.keras.models.Sequential([\n  tf.keras.layers.Dense(64, activation='relu', input_shape = [X_train.shape[1]]),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(32, activation='relu'),  \n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(2, activation='softmax')                     \n])\n\noptimizer = tf.keras.optimizers.RMSprop(0.001)\n\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","980ef329":"print(model.summary())","885e2bbc":"tf.keras.utils.plot_model(\n    model,\n    to_file='model.png',\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir='TB',\n)","81203a48":"history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))","32ac6a73":"test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)","49db1d54":"plt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')","99e044fc":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.8,0.9])\nplt.legend(loc='upper right')","d1e14218":"## Step 4. Build Neural Networks Model","84d6583c":"## Step 1. Import Python Libraries","3db0483d":"## Step 2. Load the Data","d4ccd982":"## Step 3. Data exploration and preprocessing","dfc64e23":"## Step 5. Train the Model","454f5b44":"## Step 6. Evaluate the Model"}}