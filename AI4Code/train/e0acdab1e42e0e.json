{"cell_type":{"c5f3564d":"code","67cf9122":"code","4340a0d3":"code","01645b0f":"code","d75787ec":"code","b2adbc7f":"code","cfeebd34":"code","ae84d640":"code","d379dfa2":"code","f7ae660a":"code","5e7f7033":"code","7ab672c1":"code","99430677":"code","8ca843c8":"code","9a9a085d":"code","01b604ef":"code","dc104316":"code","f803554d":"code","f9e7a957":"code","3f32968f":"code","2716ac48":"code","0d9671c2":"code","8af7b12a":"code","6691a6cb":"code","39a75780":"markdown","af96e2e0":"markdown","2f47bfe5":"markdown","f67aac3c":"markdown","f36fd29d":"markdown"},"source":{"c5f3564d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","67cf9122":"import numpy as np\nimport pandas as pd\n# Scikit-Learn for fitting models\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# For plotting \nimport matplotlib\nimport matplotlib.pyplot as plt","4340a0d3":"# We define a curve, in this case a sine curve to serve as our process that generates the data. As the real-world is never perfectly clean however, we also need to add some noise into the observations. This is done by adding a small random number to each value.\n\n#Set the random seed for reproducible results\nnp.random.seed(42)\n\n#generating function representing a process in real life\ndef true_gen(x):\n    y = np.sin(1.2 * x * np.pi) \n    return(y)\n\n# x values and y value with a small amount of random noise\nx = np.sort(np.random.rand(120))\ny = true_gen(x) + 0.1 * np.random.randn(len(x))#basicallyfor each value of pure sin(x), we are adding a small random value ","01645b0f":"# Training and Testing\n\n# Random indices for creating training and testing sets\nrandom_ind = np.random.choice(list(range(120)), size = 120, replace=False)\nx_t = x[random_ind]#for the elements in the array x, random elements are chosen based on the index deterimined by random_ind\ny_t = y[random_ind]\n\n# Training and testing observations\ntrain = x_t[:int(0.7 * len(x))] #we are now choosing 70% of data as training and the remaining below as test.\ntest = x_t[int(0.7 * len(x)):]\n\ny_train = y_t[:int(0.7 * len(y))]\ny_test = y_t[int(0.7 * len(y)):]\n\n# Model the true curve. As you might have noticed, here too we are calling the true_gen method. But here the difference is..\n#...the input is a continuous values of x (determined by np.linspace, we gives uniformly spaced values) for we are getting\n#..the sin(x) value, and thus fit_poly(train, y_train, test, y_test, degrees = 1, plot='test')this time plotting the sine curve itself. (above we just created 'points' following sine curve)\nx_linspace = np.linspace(0, 1, 1000)\ny_true = true_gen(x_linspace)","d75787ec":"# Visualization\n\n# Visualize observations and true curve\nplt.plot(train, y_train, 'ko', label = 'Train'); \nplt.plot(test, y_test, 'ro', label = 'Test')\nplt.plot(x_linspace, y_true, 'b-', linewidth = 2, label = 'True function')\nplt.legend()\nplt.xlabel('x'); plt.ylabel('y'); plt.title('Data');","b2adbc7f":"# Visualization\n\n# Visualize observations and true curve\nplt.plot(train, y_train, 'ko', label = 'Train'); \nplt.plot(test, y_test, 'ro', label = 'Test')\nplt.plot(x_linspace, y_true, 'b-', linewidth = 4, label = 'True function')\nplt.legend()\nplt.xlabel('x'); plt.ylabel('y'); plt.title('Data');","cfeebd34":"def fit_poly(train, y_train, test, y_test, degrees, plot='train', return_scores=False):\n    \n    # Create a polynomial transformation of features.For example for degree 2, (x,x**2) i.e. 2,2**2 => (2,4)\n    # so a point in 1-D is converted to a point in 2-D, and so on for even higher degree. \n    features = PolynomialFeatures(degree=degrees, include_bias=False)\n    \n    # Reshape training features for use in scikit-learn and transform features\n    train = train.reshape((-1, 1))\n    train_trans = features.fit_transform(train)\n    \n    # Create the linear regression model and train\n    model = LinearRegression()\n    model.fit(train_trans, y_train) \n    \n    # Train set predictions and error\n    train_predictions = model.predict(train_trans)\n    training_error = mean_squared_error(y_train, train_predictions) # Format test features\n    test = test.reshape((-1, 1))\n    test_trans = features.fit_transform(test)\n    \n    # Test set predictions and error\n    test_predictions = model.predict(test_trans)\n    testing_error = mean_squared_error(y_test, test_predictions)\n    \n    # Find the model curve and the true curve\n    x_curve = np.linspace(0, 1, 100)\n    x_curve = x_curve.reshape((-1, 1))\n    x_curve_trans = features.fit_transform(x_curve)\n    \n    # Model curve\n    model_curve = model.predict(x_curve_trans)\n    \n    # True curve\n    y_true_curve = true_gen(x_curve[:, 0])\n    \n    # Plot observations, true function, and model predicted function\n    if plot == 'train':\n        plt.plot(train[:, 0], y_train, 'ko', label = 'Observations')\n        plt.plot(x_curve[:, 0], y_true_curve, linewidth = 4, label = 'True Function')\n        plt.plot(x_curve[:, 0], model_curve, linewidth = 4, label = 'Model Function')\n        plt.xlabel('x'); plt.ylabel('y')\n        plt.legend()\n        plt.ylim(-1, 1.5); plt.xlim(0, 1)\n        plt.title('{} Degree Model on Training Data'.format(degrees))\n        plt.show()\n        \n    elif plot == 'test':\n        # Plot the test observations and test predictions\n        plt.plot(test, y_test, 'o', label = 'Test Observations')\n        plt.plot(x_curve[:, 0], y_true_curve, 'b-', linewidth = 2, label = 'True Function')\n        plt.plot(test, test_predictions, 'ro', label = 'Test Predictions')\n        plt.ylim(-1, 1.5); plt.xlim(0, 1)\n        plt.legend(), plt.xlabel('x'), plt.ylabel('y'); plt.title('{} Degree Model on Testing Data'.format(degrees)), plt.show();\n    \n     # Return the metrics\n    if return_scores:\n        return training_error, testing_error\n","ae84d640":"fit_poly(train, y_train, test, y_test, degrees = 1, plot='train')","d379dfa2":"# The model predictions for the testing data are shown compared to the true function and testing data points\n\nfit_poly(train, y_train, test, y_test, degrees = 1, plot='test')","f7ae660a":"fit_poly(train, y_train, test, y_test, degrees = 25, plot='train')","5e7f7033":"fit_poly(train, y_train, test, y_test, degrees = 25, plot='test')","7ab672c1":"fit_poly(train, y_train, test, y_test, degrees = 8, plot='train')","99430677":"fit_poly(train, y_train, test, y_test, degrees = 8, plot='test')","8ca843c8":"fit_poly(train, y_train, test, y_test, degrees = 22, plot='train')","9a9a085d":"fit_poly(train, y_train, test, y_test, degrees = 22, plot='test')","01b604ef":"fit_poly(train, y_train, test, y_test, degrees = 190, plot='train')","dc104316":"fit_poly(train, y_train, test, y_test, degrees = 190, plot='test')","f803554d":"# Range of model degrees to evaluate\ndegrees = [int(x) for x in np.linspace(1, 40, 40)]\n\n# Results dataframe\nresults = pd.DataFrame(0, columns = ['train_error', 'test_error'], index = degrees)\n\n# Try each value of degrees for the model and record results\nfor degree in degrees:\n    degree_results = fit_poly(train, y_train, test, y_test, degree, plot=False, return_scores=True)\n    results.loc[degree, 'train_error'] = degree_results[0]\n    results.loc[degree, 'test_error'] = degree_results[1]","f9e7a957":"print('Training Errors\\n')\ntrain_eval = results.sort_values('train_error').reset_index(level=0).rename(columns={'index': 'degrees'})\ntrain_eval.loc[:,['degrees', 'train_error']] .head(10)","3f32968f":"print('Testing Errors\\n')\ntrain_eval = results.sort_values('test_error').reset_index(level=0).rename(columns={'index': 'degrees'})\ntrain_eval.loc[:,['degrees', 'test_error']] .head(10)","2716ac48":"print('Testing Errors\\n')\ntrain_eval = results.sort_values('test_error').reset_index(level=0).rename(columns={'index': 'degrees'})\ntrain_eval.loc[:,['degrees', 'test_error']] .head(40)","0d9671c2":"#plotting both the train and test against the model complexity\nplt.plot(results.index, results['train_error'], 'b', ms=6, label = 'Training Error')\nplt.plot(results.index, results['test_error'], 'r', ms=6, label = 'Testing Error')\nplt.legend(loc=2)\nplt.xlabel('Degrees')\nplt.ylabel('Mean Square Error')\nplt.title('Training and Testing Curves');\nplt.ylim(0, 0.05) \nplt.show()\n\nprint('\\nMinimum Training Error occurs at {} degrees.'.format(int(np.argmin(results['train_error'].values))))\nprint('Minimum Testing Error occurs at {} degrees.\\n'.format(int(np.argmin(results['test_error'].values))))","8af7b12a":"#plotting both the train and test against the model complexity\nplt.plot(results.index, results['train_error'], 'b', ms=10, label = 'Training Error')\nplt.plot(results.index, results['test_error'], 'r', ms=10, label = 'Testing Error')\nplt.legend(loc=2)\nplt.xlabel('Degrees')\nplt.ylabel('Mean Square Error')\nplt.title('Training and Testing Curves');\nplt.ylim(0, 0.10) \nplt.show()\n\nprint('\\nMinimum Training Error occurs at {} degrees.'.format(int(np.argmin(results['train_error'].values))))\nprint('Minimum Testing Error occurs at {} degrees.\\n'.format(int(np.argmin(results['test_error'].values))))","6691a6cb":"#plotting both the train and test against the model complexity\nplt.plot(results.index, results['train_error'], 'b', ms=100, label = 'Training Error')\nplt.plot(results.index, results['test_error'], 'r', ms=100, label = 'Testing Error')\nplt.legend(loc=5)\nplt.xlabel('Degrees')\nplt.ylabel('Mean Square Error')\nplt.title('Training and Testing Curves');\nplt.ylim(0, 0.10) \nplt.show()\n\nprint('\\nMinimum Training Error occurs at {} degrees.'.format(int(np.argmin(results['train_error'].values))))\nprint('Minimum Testing Error occurs at {} degrees.\\n'.format(int(np.argmin(results['test_error'].values))))","39a75780":"Degrees = 25 -> Overfitting An overfit model will have extremely low training error but a high testing error.\n\nWe can go in the completely opposite direction and create a model that overfits the data. This model has too much flexibility and learns the training data too closely. As the training data has some amount of noise, it will end up capturing that noise and will be misled by that noise when it tries to make predictions on the test data.\n\nThis is a model with a high variance, because it will change significantly depending on the training data.","af96e2e0":"Model with Different Degrees\n\nDegrees = 1 -> Underfitting\n\nFor example, a degree-1 polynomial fits a straight line to the data. In this case a linear model cannot accurately learn the relationship between x and y so it will underfit the data. This is because an underfit model has low variance and high bias. Variance refers to how much the model is dependent on the training data.","2f47bfe5":"Polynomial Model\n\nWe want to try and capture the data using a polynomial function. A polynomial is defined by the degree, or the highest power for the x-values. A line has a degree of 1 because it is of the form y=m1\u2217x+c where m is the slope and c is the intercept. A third degree polynomial would have the form y=m3\u2217x3+m2\u2217x2+m1\u2217x+c and so on. The higher the degree of the polynomial, the more flexible the model.\n\nThe following function creates a polynomial with the specified number of degrees and plots the results. We can use these results to determine the optimal degrees to achieve the right balance between over and underfitting.","f67aac3c":"Degrees = 5 -> Balanced Model\n\nNow that we have seen the two extremes, we can take a look at a model that does a good job of both accounting for the data while not following it too closely.","f36fd29d":"Evaluate Models\n\nWe will use a range of values to see how the performance on the training and testing set compares. A model with much lower errors on the training data than the testing data is overfit. A model with high error on the training data (which will lead to high testing error as well) is underfitting because it does not even learn the training data."}}