{"cell_type":{"82f5f4cd":"code","cd5c6058":"code","271715f5":"code","c871c5a8":"code","3a161aa5":"code","3c9e84de":"code","e1f738b1":"code","6be4e7c9":"code","43725bff":"code","353cf80f":"code","405961a4":"code","bc000bdd":"code","ee3fbecd":"code","c81f5065":"code","33806b4c":"code","b2928624":"code","737f9457":"code","fec8988f":"code","36d4833e":"code","9cf018d8":"code","9d37e083":"code","5cff27cf":"code","4657dde8":"code","eac5f777":"code","927fe5d3":"code","73035729":"code","51db26b0":"markdown","2cbd9953":"markdown","54eace0c":"markdown","674c615d":"markdown","01eae41d":"markdown","5c159c93":"markdown","68734ca2":"markdown","d2843050":"markdown","5fde7836":"markdown","c605e475":"markdown","a6da6707":"markdown"},"source":{"82f5f4cd":"#Numerical python, multidimensional array\n#Useful for linear algebra operations\nimport numpy as np \n#pyplot collection of functions in the popular visualization \n#package Matplotlib\nimport matplotlib.pyplot as plt \n#The \"layer call\" action is like drawing an \n#arrow from inputs\/previous layer output \n#to the layer we'll create in the defining model section\n#Functional API\nfrom keras.layers import  Input,Conv2D,MaxPool2D, UpSampling2D,Dense, Dropout \n\n#Model groups layers into an object with training and \n#inference features\nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras.datasets import mnist, cifar10\n#displays output inline\n%matplotlib inline ","cd5c6058":"#presprocess the images for grey and color types\ndef preprocess(array1, array2, channel):\n    \"\"\"\n    Normalizes\/scales [0,1], divinding by the supplied array and reshapes \n    it into the appropriate format.\n    \"\"\"\n\n    \n    if channel==1:\n        #here -1 refers to the number of rows(n), n*784\n        #on this array\n        ar1 = array1.astype('float32').reshape([-1,28,28,1]) \/ 255.\n        ar2 = array2.astype('float32').reshape([-1,28,28,1]) \/ 255.\n    else:\n        ar1 = array1.astype('float32').reshape([-1,32,32,3]) \/ 255\n        ar2 = array2.astype('float32').reshape([-1,32,32,3]) \/ 255\n    return ar1, ar2","271715f5":"def noise(a1,a2, channel):\n    \"\"\"\n    Adds random noise to each image in the supplied array.\n    \"\"\"\n    if channel==1:\n        # Adding noise by multiplication of noise factor and \n        #gaussian distribution\n        noise_factor = 0.2\n        noisy_arr1 = a1 + noise_factor * np.random.normal(\n        0.0, 1.0, size=a1.shape)\n        noisy_arr2 = a2 + noise_factor * np.random.normal(\n        0.0, 1.0, size=a2.shape)\n    else:\n        \n        noi = 0.1\n        noisy_arr1 = a1 + noi * np.random.normal(\n        0.0, 1.0, size=a1.shape)\n        noisy_arr2 = a2 + noi * np.random.normal(\n        0.0, 1.0, size=a2.shape) \n        \n    #pixel value not in ranged [0,1] cliped \n    ab1 = np.clip(noisy_arr1, 0, 1)\n    ab2 = np.clip(noisy_arr2, 0, 1)\n    return ab1, ab2","c871c5a8":"# Visualization for mnist, cifar10, noisy, denoised\/predictions data\ndef display(rows, cols, a, b, check=False ):\n    '''rows: defining no. of rows in figure\n      cols: defining no. of colums in figure\n      a: train images without noise or noisy_image while test\n      prediction\n      b: train images with noise or denoised_image based while test \n      prediction\n      check: default False for 32*32 cifar10, true for 28*28\n      mnist dataset and any predictions\n    '''\n    # defining a figure \n    f = plt.figure(figsize=(2*cols,2*rows*2)) \n    for i in range(rows):\n        for j in range(cols):\n            # adding subplot to figure on each iteration\n            f.add_subplot(rows*2,cols, (2*i*cols)+(j+1))\n            if check:\n                plt.imshow(a[i*cols + j].reshape([28,28]),cmap=\"Blues\")\n            else:\n                plt.imshow(a[i*cols + j])\n            plt.axis(\"off\")\n        for j in range(cols):\n            # adding subplot to figure on each iteration\n            f.add_subplot(rows*2,cols,((2*i+1)*cols)+(j+1)) \n            if check:\n                plt.imshow(b[i*cols + j].reshape([28,28]),cmap=\"Blues\")\n            else:\n                plt.imshow(b[i*cols + j])\n            plt.axis(\"off\")\n            plt.axis(\"off\")\n        \n    #f.suptitle(\"Sample Training Data\",fontsize=18)\n    plt.savefig(\"ss.png\")\n    plt.show()","3a161aa5":"# Since we only need images from the dataset to encode and decode, we\n# won't use the labels, 50k for train, 10k for test\n(train_data, _), (test_data, _) = mnist.load_data()\nchannel=1\n# Normalize and reshape the data\ntrain_data, test_data = preprocess(train_data,test_data,channel)\n\n# Create a copy of the data with added noise\nnoisy_train_data, noisy_test_data = noise(train_data,test_data,channel)\n\n\n# Display the train data and a version of it with added noise\ndisplay(2,3,train_data, noisy_train_data, check=True)","3c9e84de":"#same as befor 50k for train and 10k test\n(cifar_train, _), (cifar_test, _) = cifar10.load_data()\nrows=2\ncols=3\nchannel = 3\n\n# Normalize and reshape the data\ncifar_train, cifar_test = preprocess(cifar_train,cifar_test, channel)\n\n# Create a copy of the data with added noise\ncifar_train_noise, cifar_test_noise = noise(cifar_train,cifar_test, channel)\n\n#display train image with and without noise\ndisplay(rows, cols, cifar_train,cifar_train_noise )\n\n\n","e1f738b1":"# Encoder \ninputs = Input(shape=(28,28,1))\n#padding same, as if conv fit with the image\nx = Conv2D(32, 3, activation='relu', padding='same')(inputs)\nx = MaxPool2D()(x)\nx = Dropout(0.2)(x)\n#relu removes any negative value after transformation\nx = Conv2D(32, 3, activation='relu', padding='same')(x)\nencoded = MaxPool2D()(x)\n\n#Decoder\nx = Conv2D(32, 3, activation='relu', padding='same')(encoded)\n\n#upsampling has no parameter or model weights to learn\n#simpy double the size of inputs\nx = UpSampling2D()(x) \n#used to prevent overfitting\n#actuallay we drop 40% of our neuron\/unit in backpropagation \n#updating parameters for other 70% of the unit\nx = Dropout(0.2)(x) #l1 & l2 modify cost function but\n                    #dropout modify the network itself\nx = Conv2D(32, 3, activation='relu', padding='same')(x)\nx = UpSampling2D()(x)\ndecoded = Conv2D(1, 3, activation='sigmoid', padding='same')(x)","6be4e7c9":"\n#create a model by specifying inputs and output\nfrom tensorflow.keras import losses\n\nautoencoder1 = Model(inputs, decoded)\n#binary cross entropy how close or far from the actual value\n#logloss\nautoencoder1.compile(optimizer='adam', loss=losses.binary_crossentropy) \n\nautoencoder1.summary()\n#autoencoder.summary()","43725bff":"\nhistory1=autoencoder1.fit(noisy_train_data, train_data,\n                epochs=50,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(noisy_test_data, test_data)\n               )\n","353cf80f":"def plot_diag(history):\n    f = plt.figure(figsize=(10,7))\n    f.add_subplot()\n    #Adding Subplot\n    plt.plot(history.epoch, history.history['loss'], label = \"loss\") # Loss curve for training set\n    plt.plot(history.epoch, history.history['val_loss'], label = \"val_loss\") # Loss curve for validation set\n\n    plt.title(\"Loss Curve\",fontsize=18)\n    plt.xlabel(\"Epochs\",fontsize=15)\n    plt.ylabel(\"Loss\",fontsize=15)\n    plt.grid(alpha=0.3)\n    plt.legend()\n    plt.savefig(\"Loss_curve.png\")\n    plt.show()\nplot_diag(history1)","405961a4":"# saving whole model\nautoencoder1.save('autoencoder_model1.h5')\n \n# loading whole model\nfrom keras.models import load_model\nmodel1 = load_model('autoencoder_model1.h5')","bc000bdd":"# Select few random test images\nnum_imgs = 45\nrand = np.random.randint(1, 100)\ntest_images = noisy_test_data[rand:rand+num_imgs] # slicing\ntest_denoised = model1.predict(test_images) # predict","ee3fbecd":"display(2, 6, test_images,test_denoised, check=True )","c81f5065":"from tensorflow.keras import layers, losses\n\nclass Denoise(Model):\n    '''__init__ constructor in OOP\n    This method called when an object is created from the class and \n    it allow the class to initialize the attributes of a class.\n    \n    super()function used to give access to \n    methods and properties of a parent or sibling class\n    \n    '''\n    def __init__(self): \n        super(Denoise, self).__init__() \n        #encoder\n        self.encoder = tf.keras.Sequential([\n        layers.Input(shape=(28, 28, 1)),\n        layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n        layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n        #decoder\n        self.decoder = tf.keras.Sequential([\n        layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n        layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n        layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n\n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nautoencoder = Denoise()","33806b4c":"autoencoder.compile(optimizer='rmsprop', loss=losses.MeanSquaredError())\n","b2928624":"history=autoencoder.fit(noisy_train_data,train_data,\n                epochs=10,\n                batch_size=256,\n                shuffle=True,\n                validation_data= (noisy_test_data, test_data))","737f9457":"plot_diag(history)","fec8988f":"# Select few random test images\nnum_imgs = 45\nrand = np.random.randint(1, 100)\ntest_images = noisy_test_data[rand:rand+num_imgs] # slicing\ntest_denoised = autoencoder.predict(test_images) # predict\ndisplay(2, 4, test_images, test_denoised, check=True)","36d4833e":"#LeakyRelu allow small gradient when any unit is deactive\n#usefull for generative models\n#Takes input as list of tensors, all of the same shape, and returns a \n#single tensor with same shape\nfrom keras.layers import  Conv2DTranspose, BatchNormalization, add, LeakyReLU\nfrom keras.optimizers import Adam","9cf018d8":"#print(cifar_train.shape)\nsize=32\nchannel=3","9d37e083":"# Encoder \n\ninputs = Input(shape=(size,size,channel))\n\nx = Conv2D(32, 3, activation='relu', padding='same')(inputs)\nx = BatchNormalization()(x) #standarized the inputs\nx = MaxPool2D()(x)\nx = Dropout(0.5)(x)\n# skip connection for decoder\n#convey info, mitigate exploding and and vanishing\n#gradient problem\n# make activations\/output of units\/layer not equal 0\nskip = Conv2D(32, 3, padding='same')(x) \nx = LeakyReLU()(skip)  \nx = BatchNormalization()(x)\nx = MaxPool2D()(x)\nx = Dropout(0.5)(x)\nx = Conv2D(64, 3, activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nencoded = MaxPool2D()(x)\n\n# Decoder\n#Conv2DTranspose, the layer will be initialized with \n#random weights that will learn \n#how to effectively upsample with detail during training.\nx = Conv2DTranspose(64, 3,activation='relu',strides=(2,2), padding='same')(encoded)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Conv2DTranspose(32, 3, activation='relu',strides=(2,2), padding='same')(x)\nx = BatchNormalization()(x) #normalize x into 0 to 1\nx = Dropout(0.5)(x)\n#Upsampling and Convolution in one layer\n#a crude understanding\nx = Conv2DTranspose(32, 3, padding='same')(x) \nx = add([x,skip]) # adding skip connection\nx = LeakyReLU()(x)\nx = BatchNormalization()(x)\ndecoded = Conv2DTranspose(3, 3, activation='sigmoid',strides=(2,2), padding='same')(x)\n\nautoencoder2 = Model(inputs, decoded)\nautoencoder2.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy')\nautoencoder2.summary()","5cff27cf":"# Training\nepochs = 25\nbatch_size = 256\n\nhistory2 = autoencoder2.fit(cifar_train_noise,\n                cifar_train,\n                epochs=epochs,\n                batch_size=batch_size,\n                shuffle=True,\n                validation_data=(cifar_test_noise, cifar_test))","4657dde8":"\n#store both architechture and weights in hierarchical dataformat\n#contains multidimensional arrays\n# saving whole model\nautoencoder2.save('autoencoder_model.h5')\n \n# loading whole model\nfrom keras.models import load_model\nmodel2 = load_model('autoencoder_model.h5')","eac5f777":"plot_diag(history2)","927fe5d3":"# Select few random test images\nnum_imgs = 48\nrand = np.random.randint(1, cifar_test_noise.shape[0]-48) \n\ncifar_test_images = cifar_test_noise[rand:rand+num_imgs] # slicing\ncifar_test_denoised = autoencoder2.predict(cifar_test_images) # predict","73035729":"# Visualize test images with their denoised images\ndisplay(3, 4, cifar_test_images,cifar_test_denoised)","51db26b0":"***Image denoising work better with MSE loss Deconvolution Work better rather than UpSampling except checkerboard artifacts problem***\n\n***Here another model incorporating OOP concept***\n","2cbd9953":"# Performance\/ Visualise Results\nTraining seems to be great. Loss and validation loss has decreased as expected.","54eace0c":"**How UpSampling2D works:**\nThe input image of shape 2x2 will be 4x4, like the example below.\n```\nInput = [\n         [1, 2],\n         [3, 4]\n        ]\n\nOutput =  [\n           [1, 1, 2, 2],\n           [1, 1, 2, 2],\n           [3, 3, 4, 4],\n           [3, 3, 4, 4]\n          ]\n```\nThis is Functional API of Keras. Deep learning model is usually a directed acyclic graph (DAG) of layers. Functional API is a way to build graphs of layers. \nFor more details:\n* [Functioanl API](https:\/\/keras.io\/guides\/functional_api\/)\n* [UpSampling2D](#https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/UpSampling2D)","674c615d":"## Model\nMore complicated architecture. What's different from last Model Architecture:\n* Conv2DTranspose layer\n* No UpSampling2D layer\n* Skip connection for the last model\n* BatchNormalization and MaxPool2D\n\n## Deconvolution (Conv2DTranspose)\n![TransposeConvolution](https:\/\/classic.d2l.ai\/_images\/trans_conv.svg)\n\n**Conv2DTranspose** layer performs the inverse of that of **Conv2D**. It performs deconvolution, and it is much better than **UpSampling**. **UpSampling** layer copies the values to the upscaled dimension. But deconvolution layer can combine the upsampling and convolution in one layer.\n\n**Cons:**\n[Checkerboard Artifacts](https:\/\/distill.pub\/2016\/deconv-checkerboard\/). <br>\n**Skip connection in resnet**\n![SKIP CONNECTION](https:\/\/cdn-images-1.medium.com\/max\/800\/1*SP6KSRdom6hu4kUxpdXgiQ.png)\n\nResearch paper: [Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections](https:\/\/arxiv.org\/pdf\/1606.08921.pdf).\n\n","01eae41d":"**Define a convolutional autoencoder**\nA convolutional autoencoder using Conv2D layers in the encoder, and Conv2DTranspose layers in the decoder","5c159c93":"### Sample few test images","68734ca2":"Adding Noise\nTo add noise we can generate array with same dimension of our images with random values between [0,1] using normal distribution with mean = 0 and standard deviation = 1.\n\nTo generate normal distribution, we can use [np.random.normal(loc,scale,size)](https:\/\/numpy.org\/doc\/stable\/reference\/random\/generated\/numpy.random.normal.html). Then scale the noise by some factor, here I am using 0.3. After adding noise, pixel values can be out of range [0,1], so we need to clip the values using [np.clip(arr, arr_min, arr_max )](https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.clip.html).","d2843050":"# [Autoencoder Model](https:\/\/afagarap.works\/2019\/03\/20\/implementing-autoencoder-in-tensorflow-2.0.html)\nThe process of choosing the important parts of the data is known as feature selection, which is among the number of use cases for an autoencoder.\nA neural network is a computational model that is used for finding a function describing the relationship between data features x and its values (a regression task) or labels (a classification task) y, i.e. y=f(x). \n\nNow, an autoencoder is also a neural network. But instead of finding the function mapping the features x to their corresponding values or labels y, it aims to find the function mapping the features \nx to itself x <br>\n![image](https:\/\/afagarap.works\/images\/autoencoder.png)\n\nAutoencoder consists of two parts:\n1. **Encoder:**  Similar to a conventional feed-forward network, Which learns the data representation, i.e. the important features z of the data instead of label.\n2. **Decoder:**  Similar to a feed-forward network. However, instead of reducing data to a lower dimension like encoder, it reconstructs the data from its lower dimension representation z to its original dimension x. Which reconstructs the data based on its idea z of how it is structured.\n\nMathematically,\nz=f(he(x))<br>\nx'=f(hd(z))\n\n**Loss Function**,\nlike other neural networks, an autoencoder learns through backpropagation. However, instead of comparing the values or labels of the model, we compare the reconstructed data \nx' and the original data x. Let\u2019s call this comparison the reconstruction error function. And it's Mean Squred Error! \n\n\n \n\n\n\n","5fde7836":"### Training\n","c605e475":"### Encoder & Decoder","a6da6707":"### Create and compile model"}}