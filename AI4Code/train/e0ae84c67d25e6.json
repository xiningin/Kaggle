{"cell_type":{"a5a22afd":"code","4bf2ec1a":"code","f65520d7":"code","9eb70623":"code","53a5b2bc":"code","8a7266ba":"code","d0f16c71":"code","2ccab4d8":"code","1ab10d73":"code","08fc1a1d":"code","6699164b":"code","2e49374d":"code","3b68972f":"code","b9ba7ab7":"code","aa46bbba":"code","348f5d92":"code","36ec7be8":"code","7715b0f2":"code","3e9fc8ef":"code","30ad42bb":"code","6c207a95":"code","9283fe41":"code","11d59a1c":"code","b1aa9e43":"code","e9bd4000":"code","bc9213dd":"code","083b10c9":"code","2df71f64":"code","7d7f52b2":"code","fd7c94ae":"code","891b7d17":"code","90532485":"code","f5b57cba":"code","69fb28eb":"code","7da5e7d9":"code","d8e4bd0a":"code","f3903a1c":"code","2756d0f5":"code","2734f80b":"code","215a50de":"code","65b10f56":"code","5e410f1d":"code","286edd04":"code","e99492d3":"code","1b85a634":"code","5a101f16":"code","5de2a6b9":"code","8c23f52a":"code","a3ea6e27":"code","8eddc895":"code","881ab44f":"code","ae42d0f6":"code","48849df6":"code","ede203e8":"code","0dbe8753":"code","3d0a3820":"code","fca32292":"code","f0bf1554":"code","ec51ac12":"code","19b824e4":"code","ea0bc470":"code","e4f1f3d8":"code","48c37adf":"code","f511ca92":"code","4b23a094":"code","ed26a1e6":"code","24511395":"code","efa24383":"code","3b9a32de":"code","ec125ebf":"code","89976d87":"code","0004aaa9":"code","1f46458e":"code","fd064d14":"code","140c7190":"code","edd0a5e3":"code","59356839":"code","dff61494":"code","dc109599":"code","82fe1b3e":"markdown","b8fbac5b":"markdown","3739d306":"markdown","5569d7f2":"markdown","41ed6606":"markdown","7f029bc2":"markdown","3ab3f32d":"markdown","d4c497f1":"markdown"},"source":{"a5a22afd":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom keras import regularizers","4bf2ec1a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n","f65520d7":"train_data=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\")\ntest_data=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\")","9eb70623":"submissions_index = test_data.Id # this will be used as index for submission csv file, ignore it now","53a5b2bc":"test_data.info()","8a7266ba":"print(train_data.shape)\nprint(test_data.shape)","d0f16c71":"target_label=train_data[\"SalePrice\"]","2ccab4d8":"train_data.drop([\"SalePrice\",\"Id\"],1,inplace=True)","1ab10d73":"\ntest_data.drop(\"Id\",1,inplace=True)","08fc1a1d":"print(train_data.shape)\nprint(test_data.shape)","6699164b":"train_data[\"PoolArea\"].unique()","2e49374d":"train_data.drop(\"PoolArea\",1,inplace=True)\ntest_data.drop(\"PoolArea\",1,inplace=True)\nprint(train_data.shape)\nprint(test_data.shape)","3b68972f":"# missing values\nmissing=train_data.isnull().mean()*100\nmissing_train=missing[missing>0].sort_values(ascending=False)\nmissing_train","b9ba7ab7":"# missing values\nmissing=test_data.isnull().mean()*100\nmissing_test=missing[missing>0].sort_values(ascending=False)\nmissing_test","aa46bbba":"# plot the missing values\nplt.figure(figsize=(20,25))\nax=sns.barplot(missing_train.index,missing_train)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","348f5d92":"# plot the missing values\nplt.figure(figsize=(20,25))\nax=sns.barplot(missing_test.index,missing_test)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","36ec7be8":"train_data.drop(['PoolQC','MiscFeature',\"Alley\"],1,inplace=True)\ntest_data.drop(['PoolQC','MiscFeature',\"Alley\"],1,inplace=True)","7715b0f2":"train_cat=train_data.select_dtypes(include=\"object\")\ntrain_num=train_data.select_dtypes(exclude=\"object\")\ntest_cat=test_data.select_dtypes(include=\"object\")\ntest_num=test_data.select_dtypes(exclude=\"object\")","3e9fc8ef":"print(train_cat.shape)\nprint(train_num.shape)\nprint(test_cat.shape)\nprint(test_num.shape)","30ad42bb":"# # bivariate anlysis  between each feature and SalePrice(target_label\n# plt.figure(figsize=(20,25))\n# for i,col in enumerate(train_data.select_dtypes(exclude=\"object\")):\n#     plt.subplot(9,4,i+1)\n#     sns.scatterplot(train_data[col],target_label)\n# plt.tight_layout()\n    ","6c207a95":"train_data.drop([\"LowQualFinSF\",\"3SsnPorch\",\"MiscVal\"],1,inplace=True)\ntest_data.drop([\"LowQualFinSF\",\"3SsnPorch\",\"MiscVal\"],1,inplace=True)","9283fe41":"train_data.info()","11d59a1c":"test_data.columns","b1aa9e43":"drop=[\"MSSubClass\",\"OverallQual\",\"OverallCond\",\n      \"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\n      \"KitchenAbvGr\",\"TotRmsAbvGrd\",\"Fireplaces\",\"GarageCars\",\"MoSold\",\"YrSold\"]\ntrain_cont=[] #continues numercal data (not dicrete data)\nfor i in train_data.select_dtypes(exclude=\"object\"):\n    if i not in drop:\n        train_cont.append(i)","e9bd4000":"for i in train_cont:\n    print(i)","bc9213dd":"# train_num[\"2ndFlrSF\"].describe()","083b10c9":"# IQR method is used to remove outliners in data\nlval=[]\nhval=[]\nfor i in train_cont:\n    q3=train_data[i].quantile(0.75)\n    q1=train_data[i].quantile(0.25)\n    iqr=q3-q1\n    # lower value\n    lv=q1-iqr*1.5\n    lval.append(lv)\n    # higher value\n    hv=q3+iqr*1.5\n    hval.append(hv)\n    ","2df71f64":"print(lval)\nprint(hval)","7d7f52b2":"# test_data[\"\"]","fd7c94ae":"# according to IQR method we drop outliners (Q1-1.5*IQR(least value in a col))\n# and (Q3+1.5*IQR (highest val in a col)) all other data below least val and \n# highest val(accourding to IQR method) will be dropped\nlcount=0\nhcount=0\nfor i in train_cont:\n    train_data.drop(train_data[(train_data[train_cont[lcount]] < lval[lcount]) & train_data[train_cont[lcount]] > hval[hcount]].index, inplace = True)\n    lcount+=1\n    hcount+=1\n    ","891b7d17":"# according to IQR method we drop outliners (Q1-1.5*IQR(least value in a col))\n# and (Q3+1.5*IQR (highest val in a col)) all other data below least val and \n# highest val(accourding to IQR method) will be dropped\nlcount=0\nhcount=0\nfor i in train_cont:\n    test_data.drop(test_data[(test_data[train_cont[lcount]] < lval[lcount]) & test_data[train_cont[lcount]] > hval[hcount]].index, inplace = True)\n    lcount+=1\n    hcount+=1\n    ","90532485":"print(train_data.shape)\nprint(test_data.shape)","f5b57cba":"corelation=train_data.corr()","69fb28eb":"threshold=0.8\nplt.figure(figsize=(20,25))\nsns.heatmap(corelation>threshold,square=True,annot=True)","7da5e7d9":"train_data.drop([\"GarageYrBlt\",\"TotRmsAbvGrd\",\"GarageCars\",\"TotalBsmtSF\"],1,inplace=True)","d8e4bd0a":"test_data.drop([\"GarageYrBlt\",\"TotRmsAbvGrd\",\"GarageCars\",\"TotalBsmtSF\"],1,inplace=True)","f3903a1c":"#heatmap to chect the missing value in numerical and categorical data in test train data\n","2756d0f5":"# heatmap of missing values\nplt.figure(figsize=(10,15))\nsns.heatmap(train_data.select_dtypes(exclude=\"object\").isnull(),yticklabels=False,cbar=False)\nplt.tight_layout()","2734f80b":"# heatmap of missing values\nplt.figure(figsize=(10,15))\nsns.heatmap(test_data.select_dtypes(exclude=\"object\").isnull(),yticklabels=False,cbar=False)\nplt.tight_layout()","215a50de":"print(train_data.shape)\nprint(test_data.shape)","65b10f56":"test_data[\"MasVnrArea\"]=test_data[\"MasVnrArea\"].fillna(test_data[\"MasVnrArea\"].mean(),inplace=True)","5e410f1d":"train_data[\"MasVnrArea\"]=train_data[\"MasVnrArea\"].fillna(train_data[\"MasVnrArea\"].mean(),inplace=True)","286edd04":"train_data[\"LotFrontage\"]=train_data[\"LotFrontage\"].fillna(train_data[\"LotFrontage\"].mean())\ntest_data[\"LotFrontage\"]=test_data[\"LotFrontage\"].fillna(test_data[\"LotFrontage\"].mean())","e99492d3":"test_data[\"BsmtFullBath\"]=test_data[\"BsmtFullBath\"].fillna(test_data[\"BsmtFullBath\"].mean())\ntest_data[\"BsmtHalfBath\"]=test_data[\"BsmtHalfBath\"].fillna(test_data[\"BsmtHalfBath\"].mean())\ntest_data[\"GarageArea\"]=test_data[\"GarageArea\"].fillna(test_data[\"GarageArea\"].mean())","1b85a634":"# heatmap of missing values\nplt.figure(figsize=(10,15))\nsns.heatmap(train_data.select_dtypes(include=\"object\").isnull(),yticklabels=False,cbar=False)\nplt.tight_layout()","5a101f16":"# heatmap of missing values\nplt.figure(figsize=(10,15))\nsns.heatmap(test_data.select_dtypes(include=\"object\").isnull(),yticklabels=False,cbar=False)\nplt.tight_layout()","5de2a6b9":"train_data.drop(\"MasVnrArea\",1,inplace=True)\n","8c23f52a":"test_data.drop(\"MasVnrArea\",1,inplace=True)","a3ea6e27":"train_data.drop(\"MasVnrType\",1,inplace=True)\ntest_data.drop(\"MasVnrType\",1,inplace=True)","8eddc895":"train_data.drop(\"GarageFinish\",1,inplace=True)\ntest_data.drop(\"GarageFinish\",1,inplace=True)","881ab44f":"train_data.drop(\"GarageType\",1,inplace=True)\ntest_data.drop(\"GarageType\",1,inplace=True)","ae42d0f6":"train_data.drop(\"GarageCond\",1,inplace=True)\ntest_data.drop(\"GarageCond\",1,inplace=True)","48849df6":"train_data.drop(\"FireplaceQu\",1,inplace=True)\ntest_data.drop(\"FireplaceQu\",1,inplace=True)","ede203e8":"train_data.drop(\"Fence\",1,inplace=True)\ntest_data.drop(\"Fence\",1,inplace=True)","0dbe8753":"train_data[\"BsmtQual\"]=train_data[\"BsmtQual\"].fillna(train_data[\"BsmtQual\"].mode()[0])\ntest_data[\"BsmtQual\"]=test_data[\"BsmtQual\"].fillna(test_data[\"BsmtQual\"].mode()[0])\ntrain_data[\"BsmtCond\"]=train_data[\"BsmtCond\"].fillna(train_data[\"BsmtCond\"].mode()[0])\ntest_data[\"BsmtCond\"]=test_data[\"BsmtCond\"].fillna(test_data[\"BsmtCond\"].mode()[0])\ntrain_data[\"BsmtExposure\"]=train_data[\"BsmtExposure\"].fillna(train_data[\"BsmtExposure\"].mode()[0])\ntest_data[\"BsmtExposure\"]=test_data[\"BsmtExposure\"].fillna(test_data[\"BsmtExposure\"].mode()[0])\ntrain_data[\"BsmtFinType1\"]=train_data[\"BsmtFinType1\"].fillna(train_data[\"BsmtFinType1\"].mode()[0])\ntest_data[\"BsmtFinType1\"]=test_data[\"BsmtFinType1\"].fillna(test_data[\"BsmtFinType1\"].mode()[0])\ntrain_data[\"BsmtFinType2\"]=train_data[\"BsmtFinType2\"].fillna(train_data[\"BsmtFinType2\"].mode()[0])\ntest_data[\"BsmtFinType2\"]=test_data[\"BsmtFinType2\"].fillna(test_data[\"BsmtFinType2\"].mode()[0])\ntrain_data[\"Electrical\"]=train_data[\"Electrical\"].fillna(train_data[\"Electrical\"].mode()[0])\ntest_data[\"Electrical\"]=test_data[\"Electrical\"].fillna(test_data[\"Electrical\"].mode()[0])\ntrain_data[\"GarageQual\"]=train_data[\"GarageQual\"].fillna(train_data[\"GarageQual\"].mode()[0])\ntest_data[\"GarageQual\"]=test_data[\"GarageQual\"].fillna(test_data[\"GarageQual\"].mode()[0])\n","3d0a3820":"print(train_data.shape)\nprint(test_data.shape)","fca32292":"# seperating the categorical and numericl data to nomarlize numerical data\ntrain_num=train_data.select_dtypes(exclude=\"object\")\ntrain_cat=train_data.select_dtypes(include=\"object\")\ntest_num=test_data.select_dtypes(exclude=\"object\")\ntest_cat=test_data.select_dtypes(include=\"object\")","f0bf1554":"# normalization\nmean=np.mean(train_num)\ntrain_num-=mean\nstd=np.std(train_num)\ntrain_num\/=std\n\ntest_num-=mean\ntest_num\/=std","ec51ac12":"# concationation of normalize data and categorical data\ntrain_data=pd.concat([train_num,train_cat],axis=1)\ntest_data=pd.concat([test_num,test_cat],axis=1)","19b824e4":"print(train_data.shape)\nprint(test_data.shape)","ea0bc470":"cat=train_data.select_dtypes(include=\"object\")\ncat.columns","e4f1f3d8":"cat_columns=['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating',\n       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n       'GarageQual', 'PavedDrive', 'SaleType', 'SaleCondition']","48c37adf":"# here we put the catagorical  to one hot encode the data \ndef category_onehot_multcols(multcolumns):\n    df_final=final_df\n    i=0\n    for fields in multcolumns:\n        \n        print(fields)\n        df1=pd.get_dummies(final_df[fields],drop_first=True)\n        \n        final_df.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:\n            \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n       \n        \n    df_final=pd.concat([final_df,df_final],axis=1)\n        \n    return df_final\n","f511ca92":"final_df=pd.concat([train_data,test_data],axis=0)","4b23a094":"final_df.shape","ed26a1e6":"final_df=category_onehot_multcols(cat_columns)","24511395":"final_df.shape","efa24383":"#remove duplicate columns\nfinal_df =final_df.loc[:,~final_df.columns.duplicated()]","3b9a32de":"final_df.shape","ec125ebf":"train_final=final_df[:1460]\ntest_final=final_df[1460:]","89976d87":"print(train_final.shape)\nprint(test_final.shape)","0004aaa9":"test_final[\"BsmtUnfSF\"]=test_final[\"BsmtUnfSF\"].fillna(test_final[\"BsmtUnfSF\"].mean())\ntest_final[\"BsmtFinSF2\"]=test_final[\"BsmtFinSF2\"].fillna(test_final[\"BsmtFinSF2\"].mean())\ntest_final[\"BsmtFinSF1\"]=test_final[\"BsmtFinSF1\"].fillna(test_final[\"BsmtFinSF1\"].mean())\n","1f46458e":"import keras\nfrom keras import layers\nfrom keras import models\nfrom keras.optimizers import Adam","fd064d14":"model = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu',input_shape=(160,), kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dense(32, activation='relu' ,kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=Adam(learning_rate=0.004), loss='mse', metrics=['mae'])","140c7190":"# early stop when model stops improving to avoid overfitting\nfrom keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor='val_mae', verbose=1, patience=20)\n\n# fitting_value\nhistory=model.fit(x=train_final,y=target_label, epochs=500,\n                  batch_size=32,validation_split=0.1, callbacks=[es])","edd0a5e3":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,10))\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'b--', label='Training loss', linewidth=2)\nplt.plot(epochs, val_loss, 'r', label='Validation loss', linewidth=5)\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","59356839":"preds = model.predict(test_final)","dff61494":"preds = preds.reshape(1459) # ValueError: Data must be 1-dimensional","dc109599":"test_data.index = submissions_index\n\n# Save predictions in format used for competition scoring\noutput = pd.DataFrame({'Id': test_data.index,\n                       'SalePrice': preds})\noutput.to_csv('submission.csv', index=False)","82fe1b3e":"# corelation is features remove high corelation features","b8fbac5b":"# drop those col for which lval and hval is 0","3739d306":"# drop columns having missing value >90 %","5569d7f2":"# removing outliers from the data by graphical analysis on numerical data (training)","41ed6606":"# by looking there graphs we remove outliners in the continuous data col (not dicrete data col) ","7f029bc2":"# Seperate all categorical columns","3ab3f32d":"# seprate catagorical and numerical data","d4c497f1":"# removing outliers from the data by graphical analysis on numerical data (test_data)"}}