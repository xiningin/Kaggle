{"cell_type":{"f33f0237":"code","ed4b204f":"code","0a1c719c":"code","ea9d9812":"code","485e827d":"code","a18a10e7":"code","8a204542":"code","7b616d50":"code","03656eb0":"code","c23af583":"code","e7fcc8ab":"code","3f909b1b":"code","a88662e9":"code","f506fad6":"code","a27bef12":"code","158a834e":"code","76c03eb7":"code","aba69608":"code","c9334561":"code","79b92f23":"code","37262672":"code","d1444166":"code","b4586783":"code","3d748ae1":"code","7a68f3ac":"code","51763e33":"code","a7ece5e7":"code","9b699535":"code","314b9869":"code","1c3678ec":"code","512a4bc9":"code","9303d1e9":"code","d86e96f0":"code","ee747bcb":"code","7c8b5895":"code","2f69263d":"code","b9c3acf6":"code","53b8edf3":"code","f55194b4":"code","3d24069d":"code","8c597248":"code","6143e1d2":"code","b418dc70":"code","0888f966":"code","893154bf":"markdown","6c213580":"markdown","463bd544":"markdown","65dc1eff":"markdown","f58cad75":"markdown","04025b71":"markdown","65feac96":"markdown","4bb228e9":"markdown","b4704e39":"markdown","18f2d4c4":"markdown","1e36794e":"markdown","039332e3":"markdown","ae68eaab":"markdown"},"source":{"f33f0237":"from fastai.conv_learner import *\nfrom fastai.dataset import *\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split","ed4b204f":"PATH = '.\/'\nTRAIN = '..\/input\/airbus-ship-detection\/train_v2\/'\nTEST = '..\/input\/airbus-ship-detection\/test_v2\/'\nSEGMENTATION = '..\/input\/airbus-ship-detection\/train_ship_segmentations_v2.csv'\n# PRETRAINED = '..\/input\/fine-tuning-resnet34-on-ship-detection\/models\/Resnet34_lable_256_1.h5'\nexclude_list = ['6384c3e78.jpg','13703f040.jpg', '14715c06d.jpg',  '33e0ff2d5.jpg',\n                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', \n                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg'] #corrupted images","0a1c719c":"tr_arr = np.array(pd.read_csv('..\/input\/traintestval-airbus\/train_df.csv')['0'].reset_index(drop=True))\nval_arr = np.array(pd.read_csv('..\/input\/traintestval-airbus\/val_df.csv')['0'].reset_index(drop=True))\ntest_arr = np.array(pd.read_csv('..\/input\/traintestval-airbus\/test_df.csv')['0'].reset_index(drop=True))","ea9d9812":"nw = 2   #number of workers for data loader\narch = resnet34 #specify target architecture","485e827d":"for el in exclude_list:\n    if(el in tr_arr): tr_arr.remove(el)\n    if(el in val_arr): val_arr.remove(el)\n    if(el in test_arr): test_arr.remove(el)\nsegmentation_df = pd.read_csv(os.path.join(PATH, SEGMENTATION)).set_index('ImageId')","a18a10e7":"tr_n = tr_arr\nval_n = val_arr\ntest_n = test_arr","8a204542":"def cut_empty(names):\n    return [name for name in names \n            if(type(segmentation_df.loc[name]['EncodedPixels']) != float)]\n\ntr_n = cut_empty(tr_n)\nval_n = cut_empty(val_n)\ntest_n = cut_empty(test_n)","7b616d50":"total_n = tr_n + val_n","03656eb0":"def get_mask(img_id, df):\n    shape = (768,768)\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    masks = df.loc[img_id]['EncodedPixels']\n    if(type(masks) == float): return img.reshape(shape)\n    if(type(masks) == str): masks = [masks]\n    for mask in masks:\n        s = mask.split()\n        for i in range(len(s)\/\/2):\n            start = int(s[2*i]) - 1\n            length = int(s[2*i+1])\n            img[start:start+length] = 1\n    return img.reshape(shape).T\n\ndef Show_images(x,yp,yt):\n    columns = 3\n    rows = min(bs,8)\n    fig=plt.figure(figsize=(columns*4, rows*4))\n    for i in range(rows):\n        fig.add_subplot(rows, columns, 3*i+1)\n        plt.axis('off')\n        plt.imshow(x[i])\n        fig.add_subplot(rows, columns, 3*i+2)\n        plt.axis('off')\n        plt.imshow(yp[i])\n        fig.add_subplot(rows, columns, 3*i+3)\n        plt.axis('off')\n        plt.imshow(yt[i])\n    plt.show()","c23af583":"class pdFilesDataset(FilesDataset):\n    def __init__(self, fnames, path, transform):\n        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n        super().__init__(fnames, transform, path)\n    \n    def get_x(self, i):\n        img = open_image(os.path.join(self.path, self.fnames[i]))\n        if self.sz == 768: return img \n        else: return cv2.resize(img, (self.sz, self.sz))\n    \n    def get_y(self, i):\n        mask = np.zeros((768,768), dtype=np.uint8) if (self.path == TEST) \\\n            else get_mask(self.fnames[i], self.segmentation_df)\n        img = Image.fromarray(mask).resize((self.sz, self.sz)).convert('RGB')\n        return np.array(img).astype(np.float32)\n    \n    def get_c(self): return 0\n     \n\ndef get_data(sz,bs):\n    #data augmentation\n    aug_tfms = [RandomRotate(45,p=0.75, tfm_y=TfmType.CLASS)]\n    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS,aug_tfms=aug_tfms)\n    tr_names = tr_n if (len(tr_n)%bs == 0) else tr_n[:-(len(tr_n)%bs)] #cut incomplete batch\n    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), (val_n,TRAIN), tfms, test=(test_n,TRAIN))\n    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n    #md.is_multi = False\n    return md\n\ndef get_data_no_aug(sz,bs):\n    #data augmentation\n    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS)\n    tr_names = tr_n if (len(tr_n)%bs == 0) else tr_n[:-(len(tr_n)%bs)] #cut incomplete batch\n    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), (val_n,TRAIN), tfms, test=(test_n,TRAIN))\n    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n    #md.is_multi = False\n    return md\n\n# Use test set as val\ndef get_data_test_no_aug(sz,bs):\n    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS)\n    tr_names = tr_n if (len(tr_n)%bs == 0) else tr_n[:-(len(tr_n)%bs)] #cut incomplete batch\n    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), (test_n,TRAIN), tfms, test=(test_n,TRAIN))\n    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n    #md.is_multi = False\n    return md","e7fcc8ab":"cut,lr_cut = model_meta[arch]","3f909b1b":"def get_base():                   #load ResNet34 model\n    layers = cut_model(arch(True), cut)\n    return nn.Sequential(*layers)\n\ndef get_base(pre=True):              #load ResNet34 model\n    layers = cut_model(arch(pre), cut)\n    return nn.Sequential(*layers)","a88662e9":"class UnetBlock(nn.Module):\n    def __init__(self, up_in, x_in, n_out):\n        super().__init__()\n        up_out = x_out = n_out\/\/2\n        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n        self.bn = nn.BatchNorm2d(n_out)\n        \n    def forward(self, up_p, x_p):\n        up_p = self.tr_conv(up_p)\n        x_p = self.x_conv(x_p)\n        cat_p = torch.cat([up_p,x_p], dim=1)\n        return self.bn(F.relu(cat_p))\n\nclass SaveFeatures():\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()\n    \nclass Unet34(nn.Module):\n    def __init__(self, rn):\n        super().__init__()\n        self.rn = rn\n        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n        self.up1 = UnetBlock(512,256,256)\n        self.up2 = UnetBlock(256,128,256)\n        self.up3 = UnetBlock(256,64,256)\n        self.up4 = UnetBlock(256,64,256)\n        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n        \n    def forward(self,x):\n        x = F.relu(self.rn(x))\n        x = self.up1(x, self.sfs[3].features)\n        x = self.up2(x, self.sfs[2].features)\n        x = self.up3(x, self.sfs[1].features)\n        x = self.up4(x, self.sfs[0].features)\n        x = self.up5(x)\n        return x[:,0]\n    \n    def close(self):\n        for sf in self.sfs: sf.remove()\n            \nclass UnetModel():\n    def __init__(self,model,name='Unet'):\n        self.model,self.name = model,name\n\n    def get_layer_groups(self, precompute):\n        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n        return lgs + [children(self.model)[1:]]","f506fad6":"def dice_loss(input, target):\n    input = torch.sigmoid(input)\n    smooth = 1.0\n\n    iflat = input.view(-1)\n    tflat = target.view(-1)\n    intersection = (iflat * tflat).sum()\n    \n    return ((2.0 * intersection + smooth) \/ (iflat.sum() + tflat.sum() + smooth))","a27bef12":"class FocalLoss(nn.Module):\n    def __init__(self, gamma):\n        super().__init__()\n        self.gamma = gamma\n        \n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n            ((-max_val).exp() + (-input - max_val).exp()).log()\n\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        \n        return loss.mean()","158a834e":"class MixedLoss(nn.Module):\n    def __init__(self, alpha, gamma):\n        super().__init__()\n        self.alpha = alpha\n        self.focal = FocalLoss(gamma)\n        \n    def forward(self, input, target):\n        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n        return loss.mean()","76c03eb7":"def dice(pred, targs):\n    pred = (pred>0).float()\n    return 2.0 * (pred*targs).sum() \/ ((pred+targs).sum() + 1.0)\n\ndef IoU(pred, targs):\n    pred = (pred>0).float()\n    intersection = (pred*targs).sum()\n    return intersection \/ ((pred+targs).sum() - intersection + 1.0)","aba69608":"sz = 768 #image size\nbs = 8  #batch size\n\nmd = get_data(sz,bs)\nno_aug_md = get_data_no_aug(sz,bs)","c9334561":"m_base = get_base()\nstate = torch.load('..\/input\/traintestval-airbus\/Unet34_768_aug_0.h5')\nm_base.load_state_dict(state, strict=False)\n\nm = to_gpu(Unet34(m_base))\nmodels = UnetModel(m)","79b92f23":"learn = ConvLearner(md, models)\nlearn.opt_fn=optim.Adam\nlearn.crit = MixedLoss(10.0, 2.0)\nlearn.metrics=[accuracy_thresh(0.5),dice,IoU]\nwd=1e-7\nlr = 1e-2","37262672":"learn.freeze_to(1)\nlearn.fit(lr,1,wds=wd,cycle_len=1,use_clr=(5,8))","d1444166":"learn.save('Unet34_768_aug_0')","b4586783":"# Unfreeze and train with differential learning rate\nlrs = np.array([lr\/100,lr\/10,lr])\nlearn.unfreeze() #unfreeze the encoder\nlearn.bn_freeze(True)\n\nlearn.fit(lrs,2,wds=wd,cycle_len=1,use_clr=(20,8))","3d748ae1":"learn.sched.plot_lr()","7a68f3ac":"learn.save('Unet34_768_aug_1')","51763e33":"sz = 768 #image size\nbs = 8  #batch size\n\nno_aug_md = get_data_no_aug(sz,bs)\n\nm_base = get_base()\nstate_na = torch.load('..\/input\/traintestval-airbus\/Unet34_768_no_aug_0.h5')\nm_base.load_state_dict(state_na, strict=False)\nm = to_gpu(Unet34(m_base))\n\nlearn_na = ConvLearner(no_aug_md, models)\nlearn_na.opt_fn=optim.Adam\nlearn_na.crit = MixedLoss(10.0, 2.0)\nlearn_na.metrics=[accuracy_thresh(0.5),dice,IoU]\nwd=1e-7\nlr = 1e-2","a7ece5e7":"# Deprecated\nlearn_na.freeze_to(1)\nlearn_na.fit(lr,1,wds=wd,cycle_len=1,use_clr=(5,8))\nlearn_na.save('Unet34_768_no_aug_0')","9b699535":"# Unfreeze and train with differential learning rate\nlrs = np.array([lr\/100,lr\/10,lr])\nlearn_na.unfreeze() #unfreeze the encoder\nlearn_na.bn_freeze(True)\n\nlearn_na.fit(lrs,2,wds=wd,cycle_len=1,use_clr=(20,8))\n\nlearn_na.save('Unet34_768_no_aug_1')","314b9869":"def Show_images(x,yp,yt):\n    columns = 3\n    rows = min(bs,8)\n    fig=plt.figure(figsize=(columns*4, rows*4))\n    for i in range(rows):\n        fig.add_subplot(rows, columns, 3*i+1)\n        plt.axis('off')\n        plt.imshow(x[i])\n        fig.add_subplot(rows, columns, 3*i+2)\n        plt.axis('off')\n        plt.imshow(yp[i])\n        fig.add_subplot(rows, columns, 3*i+3)\n        plt.axis('off')\n        plt.imshow(yt[i])\n    plt.show()\n    \n    \ndef Show_images(x,y,x1,y1):\n    columns = 4\n    rows = min(bs,8)\n    fig=plt.figure(figsize=(columns*4, rows*4))\n    for i in range(rows):\n        fig.add_subplot(rows, columns, 4*i+1)\n        plt.axis('off')\n        plt.imshow(x[i])\n        fig.add_subplot(rows, columns, 4*i+2)\n        plt.axis('off')\n        plt.imshow(y[i])\n        fig.add_subplot(rows, columns, 4*i+3)\n        plt.axis('off')\n        plt.imshow(x1[i])\n        fig.add_subplot(rows, columns, 4*i+4)\n        plt.axis('off')\n        plt.imshow(y1[i])\n    plt.show()","1c3678ec":"sz = 768 #image size\nbs = 8  #batch size\n\nmd = get_data(sz,bs)\nno_aug_md = get_data_no_aug(sz,bs)","512a4bc9":"x,y= md[0].trn_ds[2]\nox,oy = md[1].trn_ds[2]","9303d1e9":"plt.imshow(md[0].trn_ds.denorm(x)[0])","d86e96f0":"plt.imshow(y)","ee747bcb":"plt.imshow(md[1].trn_ds.denorm(ox)[0])","7c8b5895":"plt.imshow(oy)","2f69263d":"from scipy import ndimage","b9c3acf6":"def IoU(pred, targs):\n    pred = (pred > 0.5).astype(float)\n    intersection = (pred*targs).sum()\n    return intersection \/ ((pred+targs).sum() - intersection + 1.0)\n\ndef get_iou(pred, true):\n    n_masks = len(true)\n    n_pred = len(pred)\n    tot_iou = []\n    \n    for mask in true:\n        for p in pred: \n            temp_iou = IoU(p,mask)\n            tot_iou.append(temp_iou)\n    \n    return np.mean(np.array(tot_iou))\n\ndef get_score(pred, true):\n    n_th = 10\n    b = 4\n    thresholds = [0.5 + 0.05*i for i in range(n_th)]\n    n_masks = len(true)\n    n_pred = len(pred)\n    \n    ious = []\n    score = 0\n    for mask in true:\n        buf = []\n        for p in pred: \n            buf.append(IoU(p,mask))\n        ious.append(buf)\n        \n    for t in thresholds:   \n        tp, fp, fn = 0, 0, 0\n        for i in range(n_masks):\n            match = False\n            for j in range(n_pred):\n                if ious[i][j] > t: match = True\n            if not match: fn += 1\n        \n        for j in range(n_pred):\n            match = False\n            for i in range(n_masks):\n                if ious[i][j] > t: match = True\n            if match: tp += 1\n            else: fp += 1\n        score += ((b+1)*tp)\/((b+1)*tp + b*fn + fp)\n    \n    return score\/n_th\n\ndef split_mask(mask):\n    threshold = 0.5\n    threshold_obj = 30 #ignor predictions composed of \"threshold_obj\" pixels or less\n    labled,n_objs = ndimage.label(mask > threshold)\n    result = []\n    for i in range(n_objs):\n        obj = (labled == i + 1).astype(int)\n        if(obj.sum() > threshold_obj): result.append(obj)\n    return result\n\ndef get_mask_ind(img_id, df, shape = (768,768)): #return mask for each ship\n    masks = df.loc[img_id]['EncodedPixels']\n    if(type(masks) == float): return []\n    if(type(masks) == str): masks = [masks]\n    result = []\n    for mask in masks:\n        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n        s = mask.split()\n        for i in range(len(s)\/\/2):\n            start = int(s[2*i]) - 1\n            length = int(s[2*i+1])\n            img[start:start+length] = 1\n        result.append(img.reshape(shape).T)\n    return result\n\nclass IoU_eval():\n    def __init__(self):\n        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n        self.count = 0\n        self.iou = 0.0\n        \n    def put(self,pred,name):\n        true = get_mask_ind(name, self.segmentation_df)\n        self.iou += get_iou(pred,true)        \n        self.count += 1\n        \n    def evaluate(self):\n        return (self.iou \/ self.count)\n\nclass Score_eval():\n    def __init__(self):\n        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n        self.score, self.count = 0.0, 0\n        \n    def put(self,pred,name):\n        true = get_mask_ind(name, self.segmentation_df)\n        self.score +=  get_score(pred,true)\n        self.count += 1\n        \n    def evaluate(self):\n        return (self.score\/self.count)","53b8edf3":"def aug_unit(x,fwd=True,mask=False):\n    return x\n\ndef aug_flipV(x,fwd=True,mask=False):\n    return x.flip(2) if mask else x.flip(3)\n\ndef aug_flipH(x,fwd=True,mask=False):\n    return x.flip(1) if mask else x.flip(2)\n\ndef aug_T(x,fwd=True,mask=False):\n    return torch.transpose(x,1,2) if mask else torch.transpose(x,2,3)\n\ndef aug_rot_2(x,fwd=True,mask=False): #rotate pi\/2\n    return aug_flipV(aug_flipH(x,fwd,mask),fwd,mask)\n\ndef aug_rot_4cr(x,fwd=True,mask=False): #rotate pi\/4 counterclockwise\n    return aug_flipV(aug_T(x,fwd,mask),fwd,mask) if fwd else \\\n        aug_T(aug_flipV(x,fwd,mask),fwd,mask)\n\ndef aug_rot_4cw(x,fwd=True,mask=False): #rotate pi\/4 clockwise\n    return aug_flipH(aug_T(x,fwd,mask),fwd,mask) if fwd else \\\n        aug_T(aug_flipH(x,fwd,mask),fwd,mask)\n\ndef aug_rot_2T(x,fwd=True,mask=False): #transpose and rotate pi\/2\n    return aug_rot_2(aug_T(x,fwd,mask),fwd,mask)\n\ntrms_side_on = [aug_unit,aug_flipH]\ntrms_top_down = [aug_unit,aug_flipV]\ntrms_dihedral = [aug_unit,aug_flipH,aug_flipV,aug_T,aug_rot_2,aug_rot_2T,\n                 aug_rot_4cw,aug_rot_4cr]\ndef enc_img(img):\n    return torch.transpose(torch.tensor(img),0,2).unsqueeze(0)\n\ndef dec_img(img):\n    return to_np(torch.transpose(img.squeeze(0),0,2))\n\ndef display_augs(x,augs=aug_unit):\n    columns = 4\n    n = len(augs)\n    rows = n\/\/4 + 1\n    fig=plt.figure(figsize=(columns*4, rows*4))\n    img = enc_img(x)\n    for i in range(rows):\n        for j in range(columns):\n            idx = j+i*columns\n            if idx >= n: break\n            fig.add_subplot(rows, columns, idx+1)\n            plt.axis('off')\n            plt.imshow(dec_img(augs[idx](img)))\n    plt.show()","f55194b4":"def model_pred(learner, dl, F_save): #if use train dl, disable shuffling\n    learner.model.eval();\n    name_list = dl.dataset.fnames\n    num_batchs = len(dl)\n    t = tqdm(iter(dl), leave=False, total=num_batchs)\n    count = 0\n    for x,y in t:\n        py = to_np(torch.sigmoid(learn.model(V(x))))\n        batch_size = len(py)\n        for i in range(batch_size):\n            F_save(py[i],to_np(y[i]),name_list[count])\n            count += 1","3d24069d":"sz = 768 #image size\nbs = 8  #batch size\ntest_md = get_data_test_no_aug(sz,bs)","8c597248":"!cp ..\/input\/traintestval-airbus\/Unet34_768_no_aug_1.h5 .\/models\/Unet34_768_no_aug_1.h5","6143e1d2":"# Test Aug on no aug\n\nm = to_gpu(Unet34(get_base(False)))\nmodels = UnetModel(m)\n\nlearn = ConvLearner(test_md, models)\n\nlearn.load('Unet34_768_no_aug_1')","b418dc70":"score = Score_eval()\nprocess_pred = lambda yp, y, name : score.put(split_mask(yp),name)\n\niou_score = IoU_eval()\nprocess_iou_pred = lambda yp, y, name : iou_score.put(split_mask(yp),name)","0888f966":"model_pred(learn, test_md.val_dl, process_pred)\nprint('\\n',score.evaluate())","893154bf":"### Evaluate scoring","6c213580":"### Loss function","463bd544":"## Test Model","65dc1eff":"### TTA","f58cad75":"Build model","04025b71":"### Data + Pretrained code","65feac96":"## Overview","4bb228e9":"## Training non-augmented learner","b4704e39":"### Train Augmented Learner","18f2d4c4":"### Visualization","1e36794e":"### Model","039332e3":"### Test augmented model","ae68eaab":" The lr of the head part is still 1e-3, while the middle layers of the model are trained with 1e-4 lr, and the base is trained with even smaller lr, 1e-5, since low level detectors do not vary much from one image data set to another."}}