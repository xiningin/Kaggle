{"cell_type":{"f1f7b56b":"code","bca61cc5":"code","803c6694":"code","d5173f4d":"code","1f35b845":"code","b30dac1c":"code","2bd1f2a2":"code","deb017a0":"code","7758a7dd":"code","cf6fa9fe":"code","bd712667":"code","0d83e876":"code","5331a48a":"code","d9b1cadf":"code","d6220b22":"code","0dd9acfe":"code","70f86ef6":"code","3591e92f":"code","d1d78afd":"code","adfdea99":"code","d2408f68":"code","46bf9eef":"code","c9954b40":"code","efab2a21":"code","cf81f1a5":"code","e41598d8":"code","5ac80480":"code","ae509061":"code","dcbaa774":"code","cd215ad6":"code","b603a8e6":"code","5b11ddf6":"code","b6bd1bab":"code","c23d6bd0":"code","2083547a":"code","8fb28e04":"code","b7204c06":"code","afaa4bcc":"code","cf494b3c":"code","5e4353cf":"code","7b505788":"code","6aedf2a2":"code","71292220":"code","dd1944d6":"code","48bfba9c":"code","f874c21c":"code","b39131da":"code","3650d8f2":"code","ce47a824":"code","5130c756":"code","961bc465":"code","663bb4a0":"code","3d948a56":"code","292acdaa":"code","55794894":"code","a4e27470":"code","9761a632":"code","27296301":"code","531cace4":"code","586135fd":"code","08017701":"code","a0da0b91":"code","0c4f76ea":"code","7710c231":"code","30677d7b":"code","b84f58db":"code","aea5688e":"code","501db0e4":"code","3d97d155":"code","4f445b28":"code","5a591c75":"code","a64e83c8":"code","a1c17564":"code","247acc81":"code","521cf036":"code","24d45f50":"code","6a74ab61":"code","ec500401":"code","0ddb9807":"code","23619231":"code","5eb475c3":"markdown","dc39ba83":"markdown","845ca1c2":"markdown","47aee6ca":"markdown","0d42b604":"markdown","461584c6":"markdown","cf49cd1a":"markdown","c1e964ee":"markdown","3292d59f":"markdown","961a274b":"markdown","c5b116e4":"markdown","5638ab6d":"markdown","91a619bf":"markdown","c30a863f":"markdown","beebab0e":"markdown","cc693f8a":"markdown","cc4cc9aa":"markdown","22f859a4":"markdown","989a4f54":"markdown","516f4003":"markdown","5cceb1f2":"markdown","daec3c3d":"markdown","4db220b2":"markdown","34ba525e":"markdown","35b4519b":"markdown","64c5f51d":"markdown","b6254ff0":"markdown","366e2e33":"markdown","2fa5055b":"markdown","bfe41125":"markdown","3c1cb0b9":"markdown","07a5c716":"markdown","64ee873d":"markdown","1829489a":"markdown","bdb49bd1":"markdown","78e447a4":"markdown","51212b9a":"markdown","dcf2132d":"markdown","4b78cedc":"markdown","7376fcd3":"markdown","d2894ef2":"markdown","9f884a1f":"markdown","b025e1a6":"markdown","f82fabd1":"markdown","cfbb6c56":"markdown","3c841edb":"markdown","75a439bf":"markdown","0ce3ff6c":"markdown","03a76923":"markdown","d47f113c":"markdown","e5c5d83a":"markdown","97a4684f":"markdown","9ea66ab8":"markdown","f27da2df":"markdown","134de04d":"markdown","8085f145":"markdown","fa6d2dbc":"markdown","a1ba4748":"markdown","538090aa":"markdown","ae49ebab":"markdown"},"source":{"f1f7b56b":"# Loading packages\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn\nfrom datetime import datetime","bca61cc5":"# Loading data:\ntweets = pd.read_csv('https:\/\/transfer.sh\/bJEJT\/twcs.csv')","803c6694":"# Let's see what does the dataset contain\ntweets.head()","d5173f4d":"# Pick only inbound tweets that aren't in reply to anything\nfirst_inbound = tweets[pd.isnull(tweets.in_response_to_tweet_id) & tweets.inbound]\nprint('Found {} first inbound messages.'.format(len(first_inbound)))\n\n# Merge in all tweets in response\ntweet_data = pd.merge(first_inbound, tweets, left_on='tweet_id', \n                                  right_on='in_response_to_tweet_id')\nprint(\"Found {} responses.\".format(len(tweet_data)))\n\n# Filter out cases where reply tweet isn't from company\ntweet_data = tweet_data[tweet_data.inbound_y ^ True]\n\n# Let's see what happened\nprint(\"Found {} responses from companies.\".format(len(tweet_data)))\nprint(\"Tweets Preview:\")","1f35b845":"# Let's check what's inside our dataset\ntweet_data.info() ","b30dac1c":"# Seems that the column 'in_response_to_tweet_id_x' includes only missing values, let's check how many of them do we have in the whole dataset\ntweet_data.isnull().sum()","2bd1f2a2":"# Let's drop this column\ntweet_data.drop(['in_response_to_tweet_id_x'], axis='columns', inplace=True)","deb017a0":"#Changing timestamp format\ntweet_data['outbound_time_'] = pd.to_datetime(tweet_data['created_at_x'], format='%a %b %d %H:%M:%S +0000 %Y')\ntweet_data['inbound_time'] = pd.to_datetime(tweet_data['created_at_y'], format='%a %b %d %H:%M:%S +0000 %Y')\n\n#Calculating time between between outbound response and inbound message\ntweet_data['response_time'] = tweet_data['inbound_time'] - tweet_data['outbound_time_']\n\n# And how does it look like after the changes:\ntweet_data.head()","7758a7dd":"# Let's change the variables we'll be using for networks to floats, as they have numeric values\ntweet_data['tweet_id_x'] = pd.to_numeric(tweet_data['tweet_id_x'])\ntweet_data['tweet_id_y'] = pd.to_numeric(tweet_data['tweet_id_y'])\ntweet_data['author_id_x'] = pd.to_numeric(tweet_data['author_id_x'])","cf6fa9fe":"#Making sure the data type is a timedelta\/duration\nprint('from ' + str(tweet_data['response_time'].dtype))\n\n#Making it easier to later do averages by converting to a float datatype\ntweet_data['converted_time'] = tweet_data['response_time'].astype('timedelta64[s]') \/ 60\n\nprint('to ' + str(tweet_data['converted_time'].dtype))","bd712667":"# Getting the average response time per company.\ntweet_data.groupby('author_id_y')['converted_time'].mean()","0d83e876":"# Getting the average response time per company.\nauthor_grouped = tweet_data.groupby('author_id_y')","5331a48a":"# Let's see the top 20 support providers \ntop_support_providers = set(author_grouped.agg('count')\n                                .sort_values(['tweet_id_x'], ascending=[0])\n                                .index[:20]\n                                .values)","d9b1cadf":"tweet_data \\\n    .loc[tweet_data.author_id_y.isin(top_support_providers)] \\\n    .groupby('author_id_y') \\\n    .tweet_id_x.count() \\\n    .sort_values() \\\n    .plot('barh', title='Top 20 Brands by Volume')","d6220b22":"# To select rows whose column value is in an iterable array, which we'll define as array, you can use isin:\narray = ['Delta', 'AmericanAir', 'SouthwestAir', 'British_Airways']\n# tweet_data_airline will now be the new dataframe only containing the 4 biggest airlines in support\ntweet_data_airline = tweet_data.loc[tweet_data['author_id_y'].isin(array)]","0dd9acfe":"# Viewing the dataframe\ntweet_data_airline.head()","70f86ef6":"# Getting the shape of the new defined df. \ntweet_data_airline.shape","3591e92f":"#I saw it says 94 mins is the average time it takes for a response. This does not seem realistic.\n#Focusing in on the airlines and taking out outliers.\n\n# Delta Airline\ndelta = tweet_data_airline[tweet_data_airline['author_id_y'] == 'Delta']\ndelta_times = delta['converted_time']\n\ndelta_times.dropna()\n\ndef remove_outlier(delta_times):\n    q1 = delta_times.quantile(0.25)\n    q3 = delta_times.quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out = delta_times.loc[(delta_times > fence_low) & (delta_times < fence_high)]\n    return df_out\n\nno_outliers = remove_outlier(delta_times)\n\nimport matplotlib.pyplot as plt\nhist_plot = no_outliers.plot.hist(bins=50)\nhist_plot.set_title('Delta Support Response Time')\nhist_plot.set_xlabel('Mins to Response')\nhist_plot.set_ylabel('Frequency')\nplt.show()\n\nprint('Delta\\'s average response time is ' + str(round(no_outliers.mean(),2)) + ' minutes.' )\n\n# AmericanAir\namericanair = tweet_data_airline[tweet_data_airline['author_id_y'] == 'AmericanAir']\namericanair_times = americanair['converted_time']\n\namericanair_times.dropna()\n\ndef remove_outlier(americanair_times):\n    q1 = americanair_times.quantile(0.25)\n    q3 = americanair_times.quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out1 = americanair_times.loc[(americanair_times > fence_low) & (americanair_times < fence_high)]\n    return df_out1\n\nno_outliers1 = remove_outlier(americanair_times)\n\nimport matplotlib.pyplot as plt\nhist_plot = no_outliers1.plot.hist(bins=50)\nhist_plot.set_title('AmericanAir Support Response Time')\nhist_plot.set_xlabel('Mins to Response')\nhist_plot.set_ylabel('Frequency')\nplt.show()\n\nprint('AmericanAir\\'s average response time is ' + str(round(no_outliers1.mean(),2)) + ' minutes.' )\n\n# SouthwestAir\nsouthwestair = tweet_data_airline[tweet_data_airline['author_id_y'] == 'SouthwestAir']\nsouthwestair_times = southwestair['converted_time']\n\nsouthwestair_times.dropna()\n\ndef remove_outlier(southwestair_times):\n    q1 = southwestair_times.quantile(0.25)\n    q3 = southwestair_times.quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out2 = southwestair_times.loc[(southwestair_times > fence_low) & (southwestair_times < fence_high)]\n    return df_out2\n\nno_outliers2 = remove_outlier(southwestair_times)\n\nimport matplotlib.pyplot as plt\nhist_plot = no_outliers2.plot.hist(bins=50)\nhist_plot.set_title('SouthwestAir Support Response Time')\nhist_plot.set_xlabel('Mins to Response')\nhist_plot.set_ylabel('Frequency')\nplt.show()\n\nprint('SouthwestAir\\'s average response time is ' + str(round(no_outliers2.mean(),2)) + ' minutes.' )\n\n# British_Airways\nbritish_airways = tweet_data_airline[tweet_data_airline['author_id_y'] == 'British_Airways']\nbritish_airways_times = british_airways['converted_time']\n\nbritish_airways_times.dropna()\n\ndef remove_outlier(british_airways_times):\n    q1 = british_airways_times.quantile(0.25)\n    q3 = british_airways_times.quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out3 = british_airways_times.loc[(british_airways_times > fence_low) & (british_airways_times < fence_high)]\n    return df_out3\n\nno_outliers3 = remove_outlier(british_airways_times)\n\nimport matplotlib.pyplot as plt\nhist_plot = no_outliers3.plot.hist(bins=50)\nhist_plot.set_title('British Airways Support Response Time')\nhist_plot.set_xlabel('Mins to Response')\nhist_plot.set_ylabel('Frequency')\nplt.show()\n\nprint('British Airways\\'s average response time is ' + str(round(no_outliers3.mean(),2)) + ' minutes.' )\n","d1d78afd":"# Tokenizing sentences\nfrom nltk.tokenize import sent_tokenize\n\n# Tokenizing words\nfrom nltk.tokenize import word_tokenize\n\n# Tokenizing Tweets!\nfrom nltk.tokenize import TweetTokenizer","adfdea99":"!pip install gensim\n\nimport nltk\nnltk.download('stopwords')\nnltk.download('wordnet')","d2408f68":"from nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.preprocessing import LabelEncoder #labelencoder for crosstab\nimport collections   # when calling Counter I would then use collections.Counter()\nimport collections as collect # collect.Counter\nfrom collections import Counter\nfrom gensim.corpora.dictionary import Dictionary #corpora dicionary for later analysis\nfrom gensim.models.tfidfmodel import TfidfModel ","46bf9eef":"tknzr = TweetTokenizer(preserve_case=False)\n\n# Parsing the tweets using the tweet column\ntext_tokenized = [tknzr.tokenize(text) for text in tweet_data_airline['text_x']]","c9954b40":"# Lemmarize and remove stopwords\nenglish_stopwords = stopwords.words('english')\nenglish_stopwords.append('rt') #we also want to remove the retweet sign from the tweets. It's easyer just to add it to the list of english stopwords\n\n# Instantiate the WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\ntweet_data_airline['tokenized'] = [tknzr.tokenize(text) for text in tweet_data_airline['text_x']]\ntweet_data_airline['tokenized'] = tweet_data_airline['tokenized'].map(lambda t: [word.lower().strip() for word in t if word.isalpha()])\ntweet_data_airline['tokenized'] = tweet_data_airline['tokenized'].map(lambda t: [wordnet_lemmatizer.lemmatize(word) for word in t if word not in english_stopwords])","efab2a21":"# Viewing the data\ntweet_data_airline['tokenized'].head()","cf81f1a5":"# Figuring out frequently used words\ndef tokenize_tweets_for_counter(tweets):\n    \"\"\"Get all of the tokens in a set of tweets\"\"\"\n    twt = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=False) #makes lowercase\n    tokens = [token for tweet in tweets for token in twt.tokenize(tweet)]\n    return(tokens)","e41598d8":"# Figuring out frequently used words\nmy_temp_tweet_tokens = tokenize_tweets_for_counter(tweet_data_airline['text_x'])\nfrom nltk.corpus import stopwords\n\n# lowercasing\ncleaned_word_tokenized = [word.lower().strip() for word in my_temp_tweet_tokens]\n# replacing some unwanted things\ncleaned_word_tokenized = [word.replace('(','').replace(')','') for word in cleaned_word_tokenized if word.isalpha()]\n# removing stopwords\ncleaned_word_tokenized = [word for word in cleaned_word_tokenized if word not in english_stopwords]\n# removing RT\n\npos_count = Counter(cleaned_word_tokenized)\npos_count.most_common(10)","5ac80480":"# We start by creating a Dictionary from the tweets\ndictionary = Dictionary(tweet_data_airline['tokenized'])","ae509061":"# Create a Corpus: corpus\ncorpus = [dictionary.doc2bow(mytweet) for mytweet in tweet_data_airline['tokenized']]","dcbaa774":"# Create and fit a new TfidfModel using the corpus: tfidf\ntfidf = TfidfModel(corpus)","cd215ad6":"tfidf_corpus = tfidf[corpus]","b603a8e6":"# We import the model\nfrom gensim.models.lsimodel import LsiModel\n\n# And we fit it on the tfidf_corpus pointing to the dictionary as reference and the number of topics.\nlsi = LsiModel(tfidf_corpus, id2word=dictionary, num_topics=100)","5b11ddf6":"# Inspecting the topics\nlsi.show_topics(num_topics=10)","b6bd1bab":"# We can use the trained model to transform the corpus\nlsi_corpus = lsi[tfidf_corpus]","c23d6bd0":"# Load the MatrixSimilarity\nfrom gensim.similarities import MatrixSimilarity\n\n# Create the document-topic-matrix\ndocument_topic_matrix = MatrixSimilarity(lsi_corpus)\ndocument_topic_matrix = document_topic_matrix.index","2083547a":"pd.DataFrame(document_topic_matrix.dot(document_topic_matrix.T))","8fb28e04":"!pip install basemap","b7204c06":"import nltk\nnltk.download('vader_lexicon')","afaa4bcc":"# We borrowed this code from: https:\/\/datascienceplus.com\/twitter-analysis-with-python\/?fbclid=IwAR3JrPUK6iaU8IOdD4-Sdsf3XTc4g71BhHU5y6xiv99dnhQKcvTNCcLu-Zw\nimport re\nimport warnings\n\n#Visualisation\n\nimport matplotlib\nimport seaborn as sns\nfrom IPython.display import display\n#from mpl_toolkits.basemap import Basemap\n#from wordcloud import WordCloud, STOPWORDS\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nfrom nltk import tokenize\n\nmatplotlib.style.use('ggplot')\npd.options.mode.chained_assignment = None\nwarnings.filterwarnings(\"ignore\")","cf494b3c":"# Lemmatizing tweets\/preprocessing them  \ntweet_data_airline['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in tweet_data_airline['text_x']]       \nvectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\nX = vectorizer.fit_transform(tweet_data_airline['text_lem'].str.upper())\nsid = SentimentIntensityAnalyzer()\ntweet_data_airline['sentiment_compound_polarity']=tweet_data_airline.text_lem.apply(lambda x:sid.polarity_scores(x)['compound'])\ntweet_data_airline['sentiment_neutral']=tweet_data_airline.text_lem.apply(lambda x:sid.polarity_scores(x)['neu'])\ntweet_data_airline['sentiment_negative']=tweet_data_airline.text_lem.apply(lambda x:sid.polarity_scores(x)['neg'])\ntweet_data_airline['sentiment_pos']=tweet_data_airline.text_lem.apply(lambda x:sid.polarity_scores(x)['pos'])\ntweet_data_airline['sentiment_type']=''\ntweet_data_airline.loc[tweet_data_airline.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\ntweet_data_airline.loc[tweet_data_airline.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\ntweet_data_airline.loc[tweet_data_airline.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'","5e4353cf":"tweets_sentiment = tweet_data_airline.groupby(['sentiment_type'])['sentiment_neutral'].count()\ntweets_sentiment.rename(\"\",inplace=True)\nexplode = (1, 0, 0)\nplt.subplot(221)\ntweets_sentiment.transpose().plot(kind='barh',figsize=(20, 20))\nplt.title('Sentiment Analysis: All airlines 1', bbox={'facecolor':'0.8', 'pad':0})\nplt.subplot(222)\ntweets_sentiment.plot(kind='pie',figsize=(20, 20),autopct='%1.1f%%',shadow=True,explode=explode)\nplt.legend(bbox_to_anchor=(1, 1), loc=3, borderaxespad=0.)\nplt.title('Sentiment Analysis: All airlines 2', bbox={'facecolor':'0.8', 'pad':0})\nplt.show()","7b505788":"# To select rows whose column value is in an iterable array, which we'll define as array, you can use isin:\narray1 = ['Delta']\n# tweet_data_airline will now be the new dataframe only containing delta airlines in support\ntweet_data_delta = tweet_data_airline.loc[tweet_data_airline['author_id_y'].isin(array1)]\n\n# To select rows whose column value is in an iterable array, which we'll define as array, you can use isin:\narray2 = ['AmericanAir']\n# tweet_data_airline will now be the new dataframe only containing american airlines in support\ntweet_data_americanair = tweet_data_airline.loc[tweet_data_airline['author_id_y'].isin(array2)]\n\n# To select rows whose column value is in an iterable array, which we'll define as array, you can use isin:\narray3 = ['SouthwestAir']\n# tweet_data_airline will now be the new dataframe only containing southwest airlines in support\ntweet_data_southwestair = tweet_data_airline.loc[tweet_data_airline['author_id_y'].isin(array3)]\n\n# To select rows whose column value is in an iterable array, which we'll define as array, you can use isin:\narray4 = ['British_Airways']\n# tweet_data_airline will now be the new dataframe only containing british airways in support\ntweet_data_britishairways = tweet_data_airline.loc[tweet_data_airline['author_id_y'].isin(array4)]","6aedf2a2":"tweet_data_delta['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in tweet_data_delta['text_x']]       \nvectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\nX = vectorizer.fit_transform(tweet_data_delta['text_lem'].str.upper())\nsid = SentimentIntensityAnalyzer()\ntweet_data_delta['sentiment_compound_polarity']=tweet_data_delta.text_lem.apply(lambda x:sid.polarity_scores(x)['compound'])\ntweet_data_delta['sentiment_neutral']=tweet_data_delta.text_lem.apply(lambda x:sid.polarity_scores(x)['neu'])\ntweet_data_delta['sentiment_negative']=tweet_data_delta.text_lem.apply(lambda x:sid.polarity_scores(x)['neg'])\ntweet_data_delta['sentiment_pos']=tweet_data_delta.text_lem.apply(lambda x:sid.polarity_scores(x)['pos'])\ntweet_data_delta['sentiment_type']=''\ntweet_data_delta.loc[tweet_data_delta.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\ntweet_data_delta.loc[tweet_data_delta.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\ntweet_data_delta.loc[tweet_data_delta.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'","71292220":"tweets_sentiment1 = tweet_data_delta.groupby(['sentiment_type'])['sentiment_neutral'].count()\ntweets_sentiment1.rename(\"\",inplace=True)\nexplode = (1, 0, 0)\nplt.subplot(221)\ntweets_sentiment1.transpose().plot(kind='barh',figsize=(20, 20))\nplt.title('Sentiment Analysis 1 for Delta', bbox={'facecolor':'0.8', 'pad':0})\nplt.subplot(222)\ntweets_sentiment1.plot(kind='pie',figsize=(20, 20),autopct='%1.1f%%',shadow=True,explode=explode)\nplt.legend(bbox_to_anchor=(1, 1), loc=3, borderaxespad=0.)\nplt.title('Sentiment Analysis 2 for Delta', bbox={'facecolor':'0.8', 'pad':0})\nplt.show()","dd1944d6":"tweet_data_americanair['text_lem1'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in tweet_data_americanair['text_x']]       \nvectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\nX = vectorizer.fit_transform(tweet_data_americanair['text_lem1'].str.upper())\nsid = SentimentIntensityAnalyzer()\ntweet_data_americanair['sentiment_compound_polarity']=tweet_data_americanair.text_lem1.apply(lambda x:sid.polarity_scores(x)['compound'])\ntweet_data_americanair['sentiment_neutral']=tweet_data_americanair.text_lem1.apply(lambda x:sid.polarity_scores(x)['neu'])\ntweet_data_americanair['sentiment_negative']=tweet_data_americanair.text_lem1.apply(lambda x:sid.polarity_scores(x)['neg'])\ntweet_data_americanair['sentiment_pos']=tweet_data_americanair.text_lem1.apply(lambda x:sid.polarity_scores(x)['pos'])\ntweet_data_americanair['sentiment_type']=''\ntweet_data_americanair.loc[tweet_data_americanair.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\ntweet_data_americanair.loc[tweet_data_americanair.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\ntweet_data_americanair.loc[tweet_data_americanair.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'","48bfba9c":"tweets_sentiment1 = tweet_data_americanair.groupby(['sentiment_type'])['sentiment_neutral'].count()\ntweets_sentiment1.rename(\"\",inplace=True)\nexplode = (1, 0, 0)\nplt.subplot(221)\ntweets_sentiment1.transpose().plot(kind='barh',figsize=(20, 20))\nplt.title('Sentiment Analysis 1 for AmericanAir', bbox={'facecolor':'0.8', 'pad':0})\nplt.subplot(222)\ntweets_sentiment1.plot(kind='pie',figsize=(20, 20),autopct='%1.1f%%',shadow=True,explode=explode)\nplt.legend(bbox_to_anchor=(1, 1), loc=3, borderaxespad=0.)\nplt.title('Sentiment Analysis 2 for AmericanAir', bbox={'facecolor':'0.8', 'pad':0})\nplt.show()","f874c21c":"tweet_data_southwestair['text_lem3'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in tweet_data_southwestair['text_x']]       \nvectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\nX = vectorizer.fit_transform(tweet_data_southwestair['text_lem3'].str.upper())\nsid = SentimentIntensityAnalyzer()\ntweet_data_southwestair['sentiment_compound_polarity']=tweet_data_southwestair.text_lem3.apply(lambda x:sid.polarity_scores(x)['compound'])\ntweet_data_southwestair['sentiment_neutral']=tweet_data_southwestair.text_lem3.apply(lambda x:sid.polarity_scores(x)['neu'])\ntweet_data_southwestair['sentiment_negative']=tweet_data_southwestair.text_lem3.apply(lambda x:sid.polarity_scores(x)['neg'])\ntweet_data_southwestair['sentiment_pos']=tweet_data_southwestair.text_lem3.apply(lambda x:sid.polarity_scores(x)['pos'])\ntweet_data_southwestair['sentiment_type']=''\ntweet_data_southwestair.loc[tweet_data_southwestair.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\ntweet_data_southwestair.loc[tweet_data_southwestair.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\ntweet_data_southwestair.loc[tweet_data_southwestair.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'","b39131da":"tweets_sentiment3 = tweet_data_southwestair.groupby(['sentiment_type'])['sentiment_neutral'].count()\ntweets_sentiment3.rename(\"\",inplace=True)\nexplode = (1, 0, 0)\nplt.subplot(221)\ntweets_sentiment3.transpose().plot(kind='barh',figsize=(20, 20))\nplt.title('Sentiment Analysis 1 for SouthwestAir', bbox={'facecolor':'0.8', 'pad':0})\nplt.subplot(222)\ntweets_sentiment3.plot(kind='pie',figsize=(20, 20),autopct='%1.1f%%',shadow=True,explode=explode)\nplt.legend(bbox_to_anchor=(1, 1), loc=3, borderaxespad=0.)\nplt.title('Sentiment Analysis 2 for SouthwestAir', bbox={'facecolor':'0.8', 'pad':0})\nplt.show()","3650d8f2":"tweet_data_britishairways['text_lem2'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in tweet_data_britishairways['text_x']]       \nvectorizer = TfidfVectorizer(max_df=0.5,max_features=10000,min_df=10,stop_words='english',use_idf=True)\nX = vectorizer.fit_transform(tweet_data_britishairways['text_lem2'].str.upper())\nsid = SentimentIntensityAnalyzer()\ntweet_data_britishairways['sentiment_compound_polarity']=tweet_data_britishairways.text_lem2.apply(lambda x:sid.polarity_scores(x)['compound'])\ntweet_data_britishairways['sentiment_neutral']=tweet_data_britishairways.text_lem2.apply(lambda x:sid.polarity_scores(x)['neu'])\ntweet_data_britishairways['sentiment_negative']=tweet_data_britishairways.text_lem2.apply(lambda x:sid.polarity_scores(x)['neg'])\ntweet_data_britishairways['sentiment_pos']=tweet_data_britishairways.text_lem2.apply(lambda x:sid.polarity_scores(x)['pos'])\ntweet_data_britishairways['sentiment_type']=''\ntweet_data_britishairways.loc[tweet_data_britishairways.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\ntweet_data_britishairways.loc[tweet_data_britishairways.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\ntweet_data_britishairways.loc[tweet_data_britishairways.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'","ce47a824":"tweets_sentiment2 = tweet_data_britishairways.groupby(['sentiment_type'])['sentiment_neutral'].count()\ntweets_sentiment2.rename(\"\",inplace=True)\nexplode = (1, 0, 0)\nplt.subplot(221)\ntweets_sentiment2.transpose().plot(kind='barh',figsize=(20, 20))\nplt.title('Sentiment Analysis 1 for British Airways', bbox={'facecolor':'0.8', 'pad':0})\nplt.subplot(222)\ntweets_sentiment2.plot(kind='pie',figsize=(20, 20),autopct='%1.1f%%',shadow=True,explode=explode)\nplt.legend(bbox_to_anchor=(1, 1), loc=3, borderaxespad=0.)\nplt.title('Sentiment Analysis 2 for British Airways', bbox={'facecolor':'0.8', 'pad':0})\nplt.show()","5130c756":"# Grouping tweets by class to see the amoung of each class denotation\nt_class = tweet_data_airline.groupby(['sentiment_type'], as_index=False).count()","961bc465":"# Print results of t_class\nprint(t_class)","663bb4a0":"# Creating a array to save results\nnegative_tweets = []\n\n# Take negative tweets and tokenized words and add it to our negative_tweets\nfor x in tweet_data_airline[tweet_data_airline['sentiment_type'] == 'NEGATIVE']['tokenized']:\n    negative_tweets.extend(x)\n    \nnegative_tweets_tfidf = tfidf[dictionary.doc2bow(negative_tweets)]\n\nnegative_tweets_tfidf = sorted(negative_tweets_tfidf, key=lambda w: w[1], reverse=True)\n\n# Print the top 10 weighted words\nfor term_id, weight in negative_tweets_tfidf[:10]:\n    print(dictionary.get(term_id), weight)","3d948a56":"positive_tweets = []\n\nfor x in tweet_data_airline[tweet_data_airline['sentiment_type'] == 'POSITIVE']['tokenized']:\n    positive_tweets.extend(x)\n    \npositive_tweets_tfidf = tfidf[dictionary.doc2bow(positive_tweets)]\n\npositive_tweets_tfidf = sorted(positive_tweets_tfidf, key=lambda w: w[1], reverse=True)\n\n# Print the top 10 weighted words\nfor term_id, weight in positive_tweets_tfidf[:10]:\n    print(dictionary.get(term_id), weight)","292acdaa":"neutral_tweets = []\n\nfor x in tweet_data_airline[tweet_data_airline['sentiment_type'] == 'NEUTRAL']['tokenized']:\n    negative_tweets.extend(x)\n    \nneutral_tweets_tfidf = tfidf[dictionary.doc2bow(negative_tweets)]\n\nneutral_tweets_tfidf = sorted(negative_tweets_tfidf, key=lambda w: w[1], reverse=True)\n\n# Print the top 10 weighted words\nfor term_id, weight in neutral_tweets_tfidf[:10]:\n    print(dictionary.get(term_id), weight)","55794894":"# Let's recode our labels to numeric values\nmapping = {'NEGATIVE': 0, 'POSITIVE': 1, 'NEUTRAL': 2}","a4e27470":"# We use our mapping to change the value in our dataframe\/column\ntweet_data_airline['sentiment_type'] = tweet_data_airline['sentiment_type'].map(mapping)","9761a632":"# Let's make a quick view of change is complete before moving on to ML\ntweet_data_airline.sentiment_type.unique()","27296301":"# Creating a list to save results from the three classifier models\nclassifier_results = [0,0,0]","531cace4":"# define y and X \ny = tweet_data_airline['sentiment_type']\n\nX = document_topic_matrix\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)","586135fd":"# Let's fit a simple linear regression model\n\nfrom sklearn.linear_model import LogisticRegression\n\nregressor = LogisticRegression()\n\nregressor.fit(X_train, y_train)\n\ny_pred = regressor.predict(X_test)\n\nfrom sklearn.model_selection import cross_val_score\n\naccuracies = cross_val_score(estimator = regressor, X = X_train, y = y_train, cv = 5)\n\nprint(\"Score on train set \" + str(accuracies.mean()))\nprint(\"Std deviation \" + str(accuracies.std()))\nclassifier_results[0] = regressor.score(X_test, y_test)\nprint(\"Score on test set \" + str(classifier_results[0]))","08017701":"from sklearn.preprocessing import LabelEncoder #labelencoder for crosstab\n# Encode the labels to numbers\nlabelencoder_y = LabelEncoder()\ny = labelencoder_y.fit_transform(y)\n\n# Creating a pandas DataFrame and cross-tabulation\nreal_tweets = labelencoder_y.inverse_transform(y_test)\npredicted_tweets = labelencoder_y.inverse_transform(y_pred)\ndf = pd.DataFrame({'real_tweets': real_tweets, 'predicted_tweets': predicted_tweets}) ","a0da0b91":"# Let's create a crosstab with results comparing classified tweets to train set\npd.crosstab(df.real_tweets, df.predicted_tweets)","0c4f76ea":"# Let's see how does it look like with accuracies for each class\nfrom sklearn.metrics import classification_report\ny_true = df.real_tweets\ny_pred = df.predicted_tweets\ntarget_names = ['Negative', 'Positive', 'Neutral']\nprint(classification_report(y_true, y_pred, target_names=target_names))","7710c231":"# Let's fit a simple linear gradient boosting classifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nregressor = GradientBoostingClassifier()\n\nregressor.fit(X_train, y_train)\n\ny_pred = regressor.predict(X_test)\n\nfrom sklearn.model_selection import cross_val_score\n\naccuracies = cross_val_score(estimator = regressor, X = X_train, y = y_train, cv = 5)\n\nprint(\"Score on train set \" + str(accuracies.mean()))\nprint(\"Std deviation \" + str(accuracies.std()))\nclassifier_results[1] = regressor.score(X_test, y_test)\nprint(\"Score on test set \" + str(classifier_results[1]))","30677d7b":"# Encode the labels to numbers\nlabelencoder_y = LabelEncoder()\ny = labelencoder_y.fit_transform(y)\n\n# Creating a pandas DataFrame and cross-tabulation\nreal_tweets = labelencoder_y.inverse_transform(y_test)\npredicted_tweets = labelencoder_y.inverse_transform(y_pred)\ndf = pd.DataFrame({'real_tweets': real_tweets, 'predicted_tweets': predicted_tweets}) ","b84f58db":"pd.crosstab(df.real_tweets, df.predicted_tweets)","aea5688e":"# Let's see how does it look like with accuracies for each class\nfrom sklearn.metrics import classification_report\ny_true = df.real_tweets\ny_pred = df.predicted_tweets\ntarget_names = ['Negative', 'Positive', 'Neutral']\nprint(classification_report(y_true, y_pred, target_names=target_names))","501db0e4":"#  Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy', random_state = 22)\nclassifier.fit(X_train, y_train)\n\n# Predicting the test set results from the test-set inputs\ny_pred = classifier.predict(X_test)\n\n# Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 5)\n\nprint(\"Score on train set \" + str(accuracies.mean()))\nprint(\"Std deviation \" + str(accuracies.std()))\nclassifier_results[2] = regressor.score(X_test, y_test)\nprint(\"Score on test set \" + str(classifier_results[2]))","3d97d155":"# Encode the labels to numbers\nlabelencoder_y = LabelEncoder()\ny = labelencoder_y.fit_transform(y)\n\n# Creating a pandas DataFrame and cross-tabulation\nreal_tweets = labelencoder_y.inverse_transform(y_test)\npredicted_tweets = labelencoder_y.inverse_transform(y_pred)\ndf = pd.DataFrame({'real_tweets': real_tweets, 'predicted_tweets': predicted_tweets}) ","4f445b28":"pd.crosstab(df.real_tweets, df.predicted_tweets)","5a591c75":"# Let's see how does it look like with accuracies for each class\nfrom sklearn.metrics import classification_report\ny_true = df.real_tweets\ny_pred = df.predicted_tweets\ntarget_names = ['Negative', 'Positive', 'Neutral']\nprint(classification_report(y_true, y_pred, target_names=target_names))","a64e83c8":"final_data = pd.DataFrame({'cat': ['Logistic Regresion', 'Gradient Boosting', 'Random Forest'], 'val': [classifier_results[0], classifier_results[1], classifier_results[2]]})\nax = sns.barplot(x = 'val', y = 'cat', \n              data = final_data)\nax.set(xlabel='Performance of classifying models in procentage', ylabel='models')\nplt.show()","a1c17564":"import networkx as nx\nimport itertools\nimport copy","247acc81":"edgelist = tweet_data_airline[['tweet_id_x','tweet_id_y']]\nnodelist = tweet_data_airline[['tweet_id_y',\t'author_id_x']]","521cf036":"# Creating empty graph\ng = nx.Graph()\n# Add edges and edge attributes\nfor i, elrow in edgelist.iterrows():\n    g.add_edge(elrow[0], elrow[1])","24d45f50":"# Let's check what's inside edge list\nelrow.head()","6a74ab61":"# Adding node attributes\nfor i, nlrow in nodelist.iterrows():\n      g.node[nlrow['tweet_id_y']].update(nlrow[1:].to_dict())","ec500401":"# Node list example\nprint(nlrow)","0ddb9807":"# Let's check the number of nodes and edges\nprint('number of edges: {}'.format(g.number_of_edges()))\nprint('number of nodes: {}'.format(g.number_of_nodes()))","23619231":"# Let's download our modified dataset:\nfrom google.colab import files\n\ntweet_data_airline.to_csv('airlines.csv')\nfiles.download('airlines.csv')","5eb475c3":"What we found of words in the Negative tweets doesn't really seem \"negative\". There is some delayed and delay, but the words does not seem so harsh and we remenber from the hate speed dataset. What is interesting is the references to negative situations, which is something with bags, seat, flight, hour and service. So if we had all the more negative words it would be about these situations. Like, delayed flight, bad seat, worst bag service and so on. So the context makes sense. ","dc39ba83":"## Data preprocessing\n\nHere we'll try to see what's inside our dataset and do our first cleaning, although it's not final, as we'll be preparing our data for network analysis and natural language processing in each section accordingly.","845ca1c2":"#### Sentiment analysis for AmericanAir","47aee6ca":"Based on this quick look at the topics, we are not going to be able to conclude much more than we did with the most frequently used words. So let's instead try with some other metods.","0d42b604":"It takes so much time to run but...\n\n![alt text](https:\/\/media.giphy.com\/media\/2vZElmmiXALa8\/giphy.gif)","461584c6":"## Network analysis","cf49cd1a":"**Answer**\n\nWe tried shedding a light on the problem from different angles with different methods: We found that SouthWest Air had the fastest answering rate, which is a good quality of a costumer support. Furthermore the tone of their recived tweets is much more postitive than for example Delta. So it seems costumers are both happy AND get the needed help fast. Good job, SouthWest Air! \n\nHowever... There might be a slight problem with our analysis and therefore our results. From the sentiment analysis we can see that a lot of the same words show up as both positive, negative and neutral. The explanation for this might be that people don't tend to use as strong language in an airline costumer support as in a politic or religious context for instance. We asume this is the same reason that our predictive models weren't able to reach a high percentage of accuracy. A solution could be removing the \"neutral\" part of the sentiment analysis because this seems to have caused quite a disturbance in our results.\n\nWhat we learned from the analysis is that we can't say from this dataset, that customers writes negative or positive tweets because of the fast or slow response time from the airlines customer support on Twitter. Because the tweets are from the customers directed to the support, which then will be replied of the airline support. So the positive or negative tweets comes from the expirience of their flight or service with the airline, but still if the airlines see if they could improve flight expirence, service or support, this data definitly tell us something about how fast are our competition on replying on twitter and what are our own level of customer service compared to our competitors. By the nlp we can detect what areas of our organisation we could improve. Like, do we have a lot delay which makes customers unsatisfied or is our seats bad or do we in general have a bad service. So from knowing how many negative, neutral and positive tweets the airline recieve to going deeper into the context of the sentiment. \n\n\n**Network analysis**\n\nThis was actually the most challenging part for us - firstly we've spent a lot of time trying to create nodes and edge list from dataframe and figuring out what should be included in both. When we got it to work we met the reality - our dataset was too big and neither Google Colab nor R Studio could manage to plot the graphs from such a big dataset. We got one big blue ball! \n\nThe values for graph charactistics also didn't leave us much room for interpretation as tweets are directed and the edge density is very low because there are no interactions between users, which also makes it impossible to have closed triplets in the graph. We know we could try doing the analysis on aggregated level but with time constrains, we have chosen to focus on other parts instead of waiting for very long time to show a plot that cannot even be interpreted.","c1e964ee":"## Natural language processing","3292d59f":"#### Logistic Regression Model ","961a274b":"This code that will be used for all four airlines will seem the same when we begin analyse the sentiment analysis for the individual airline. \n\nBut to explain a little bit about what we will do in this code: we're starting with lemmatizing the tweets to analyse the sentiment of them. Meaning we can categorize each word in the test set into a positive, neutral or negative tweet. We can use this information to analyse customers experience passing through the different customer supports and draw parallels from the nature of their tone to how satisfied they are with the service - i.e. how good is the costumer support at dealing with client issues.","c5b116e4":"#### Sentiment analysis for Delta","5638ab6d":"We can see that **tweet_id_x** is connected to **tweet_id_y** and the information about response from company to user is stored in **response_tweet_id_x** which will be useful for our network analysis","91a619bf":"In order to find out which airline has the best customer support we need to do a more qualitative analysis of the nature of the tweets. We have chosen a sentiment analysis approach by which we categorize the tweets into one of three types: Positive, neutral or negative.\n\n![confused](https:\/\/media.giphy.com\/media\/l3V0o7QyRb08irLag\/giphy.gif)","c30a863f":"**Creating a Corpus and TF-IDF**","beebab0e":"**Problem formulation:**\n\n\"For this project we want to explore the quality of different companies customer support on twitter. More precisly we are looking at four of the biggest airline companies to find out which one provides the best service.\"","cc693f8a":"### Let's find the sentiment for each Airline individualy \nWe have four airlines and we know some of the airlines are faster at replying customers on Twitter than other. \n\nWe will create four new dataframes each involving the data from the  individual airline. \n\nJust to make it clear, then results for each of the airlines will be presented in the end when taking all four airlines in consideration.\n\n**** WE KNOW this could have been done in a different way, but we choose to loc the data the same way as when we selected the four airlines. ","cc4cc9aa":"## Machine learning\nWe'll try to label tweets into one of three categories:\n* Positive\n* Negative\n* Neutral\n\nIt is a classification problem - we're not trying to predict anything, just get labels on tweets and classify them, so we'll be using classifiers not regression models\n\n![classified](https:\/\/media.giphy.com\/media\/TGtuSGteYWhX2\/giphy.gif)","22f859a4":"#### Random Forest Classification","989a4f54":"Exploring the most common topics of the customer service tweets using Latent Semantic Indexing (lsi)","516f4003":"Alright so with the tokenizing done, let's try to learn some more about our data. First: What words are frequently used in twitter users inquiries to airline companies.","5cceb1f2":"So, in answering our problemformulation, a good place to start exploring the response rate of the airlines in questing - we asume the minimun expectations of a good costumer support is to get a (quick) response - so lets check it out!","daec3c3d":"#### Sentiment analysis for British Airways ","4db220b2":"### Results from exploring the four Airlines \n\n| Airline                   | Average response time in min.         |\n| -------------                |:-------------:|\n| Delta                      |20.08          |\n| AmericanAir         |14.93         |\n| SouthwestAir       |9.56         |\n| British Airways    |244.51         |\n\nWe found that the Airline with the fastest twitter support is SouthwestAir with an average response time of 9 minutes and 56 seconds AND longest possible response time is under 40 minutes. While the Airline with the slowest twitter support is British Airways with an average response time of 244 minuts and 51 seconds which is almost 5 hours. The longest waiting time is almost 800 minutes. \n\nHowever, we don't believe that speed is what necessarily constitutes a high quality customer support. Therefore we now move on to natual language processing to see if we can extract some more descriptive results with some different methods.   ","34ba525e":"### Creating a new dataframe\n\nSince we wish to analyze the customer support of the four biggest airline companies, we select these by volume and combine them in a new dataframe: tweet_data_airline.\n\n![airline](https:\/\/media.giphy.com\/media\/xT5LMRTvSUEAQEXjr2\/giphy.gif)","35b4519b":"The results from all four airlines is that we from the crossbar graph can clearly see that there is a majority of positive tweet among the four airlines. Eventhough there is a high number of positive tweets there is still a 31,7 % of the tweets that is negative.\n\nThe neutral tweets is 19,4% of the tweets and later on it would be interesting to explore this some more. Right now we don't really know what classify tweets as neutral and what neutral means in this context. ","64c5f51d":"What we have created from the corpus is as topic matrix from the words in our tweets. So if you had printed the document_topic_matrix you would have seen a matrix with the same amount of columns and rows showing the frequence of the words in tweets. \n\nFor now we gonna leave be till we get to our ml models where document_topic_matrix is gonna be used to predict the tweets.","b6254ff0":"#### Collection of only words in Neutral tweets","366e2e33":"## Exploratory data analysis\nNow that we have preprocessed and cleaned some of our data, we can use it and make some simple explorations and visualizations to get to know the data better. ","2fa5055b":"# Preparation","bfe41125":"For the words in positive tweets it is more obvious whats classify the tweets as possitive. The context is the same, because of flight, service and seat, but now there is words like thanks, help, great and LOVE, which makes them positive. ","3c1cb0b9":"Not surprisingly, words like \"flight\" and \"help\" are among the most frequently used. The most interesting observation to take away from these results is probably that \"thanks\" and \"please\" are that frequently accuring combined with the fact that there are no negative words among the top frequently accuring word. It seems we are dealing with some very polite costumers. To varify this observation, let's move on to chek out some topics.","07a5c716":"Now let's create a corpus (ID'd map of each tweets tokens) that is weighted according to the TF-IDF (*Term Frequency - Inverse Document Frequency*) method so that the most accuring words are not identified as key words. The words are then weighed according to these when we later compare them against each other.","64ee873d":"# Conclusion","1829489a":"### Results from the exploration \nWe found that positive tweets are quite obvious to classify, but  it was difficult to find any differences between negative and neutral ones. We talked about that the reason it is hard to find the words is because people aren't that harsh when it comes to customer support as if it was something political. Furthermore, the most common words are more common... because most of the tweets refer to the same context, so we won't find a word like stupid in the top 10 most common words.","bdb49bd1":"#### Collection of only words in Negative tweets","78e447a4":"We can see that overall precision of Logistic Regression is around 66% and the model had the most trouble with classifying neutral tweets, while positive tweets are the most accurate with 73 %.","51212b9a":"#### Sentiment analysis for Southwest Air","dcf2132d":"We started with a dataframe of 794299 rows, which we learned was way too big to use in network analysis and nlp. We decided to focus on one support group, in this case airlines. This concluded in 93588 rows and a smaller\/scoped dataset to work with. ","4b78cedc":"#### Collection of only words in Positive tweets","7376fcd3":"#### Quick overview of how many tweets we got in each category: Negative, Neutral & Positive","d2894ef2":"#### Renaming values in column sentiment_type","9f884a1f":"### Loading needed packages\nOf course, these are not all of the packages we'll be using. Stay tuned...","b025e1a6":"What we can see is that 29.655 of the tweets are classified as negative tweets, while 18.168 is classified as neutral and 45.765 is classified as positive tweets. This match well to the overall procentage from the sentiment analysis we did above.\n\nThe results from Overall can be seen here:\n\n| Airline                   | Positive   | Neutral | Negative|\n| -------------                |:-------------:| :-------------:|:-------------:|\n| Overall                  |48,9         |19,4     |31,7      |","f82fabd1":"### Results from the sentiment analysis \nWhat we found in the sentiment analysis is that the airline with the most positive tweets received is Southwest Air with 56,3 % positive and only 23,7 % negative. On the other hand the airline with the most negative tweets received from customers is American Air with 44,8 % positive and 37,8 % negative tweets. \n\nSo this is a quite interesting finding in our analysis of the data. When we explored for the average time of airlines responding tweets American Air was the second fastest, but eventhough they are fast doesn't mean they are \"better\". On the other hand British Airways was the slowest using hours before responding and the among negative tweets received is 3 procentage point from American Air. \n\n\n\n| Airline                   | Positive   | Neutral | Negative|\n| -------------                |:-------------:| :-------------:|:-------------:|\n| Delta                      |50,3 %         |19,7 %    |30 %    |\n| American Air         |44,8 %        |17,3 %    |37,8 %     |\n| Southwest Air       |56,3 %        |20,9 %    |23,7 %     |\n| British Airways    |45,2 %       |19,9 %     |34,9 %     |\n| Overall                  |48,9 %        |19,4 %    |31,7 %     |\n\n\nFrom this we can conclude that having a good twitter support doesn't mean they have a better general service flying with them. In the end negative tweets can come from the general expirience of the flight and not the customer service on Twitter. ","cfbb6c56":"#### Gradient Boosting Classifier","3c841edb":"### Sentiment Analysis","75a439bf":"We can see that the results are quite similar and our best model have accuracy of only 70%, but we came up with some explanation what is the reason for that.\n\nFirstly, the tweets were not classified previously by humans and we have seen some examples from the dataset like *\"great\" service\"* which might be recognized by machine as positive tweet, while we would say that the meaning was sarcastic.\n\nSecondly, all categories include the same words like \"flight\" and many words are classified to both positive and neural or negative and neutral, which makes it difficult to differentiate. The model would work much better if we tried to identify only either positive or negative customers tweets.\n","0ce3ff6c":"For words in neutral tweets we got the same most common words as in negative tweets, which is really interesting, because what words then classify them as the one or the other? ","03a76923":"### Problem formulation\nFor this project we want to explore the quality of different companies customer support on Twitter. More precisly we are looking at four of the biggest airline companies to find out which one provides the best service.\n\n### Data\nWe have found the dataset about *Customer Support on Twitter* on Kaggle. It consists of over 3 million tweets and replies from the biggest brands and customers on Twitter.\n\nThe data has seven columns that need a little further explaination (at least it did for us):\n\n*   tweet_id: Anonymous referal to the tweet\n*   author_id: Anonymous referal to the person posting the tweet\n*   inbound: The tweet rife inside the company doing the customer support\n*   created_at: Date and time the tweet was posted\n*   text: The content of the tweet\n*   response_tweet_id: ID's of responding tweets\n*   in_response_to_tweet_id: If the tweet is in response to another tweet, that ID is indicated in this column\n\n\n\n\n\n\n\n","d47f113c":"### Explore and compare the sentiment types - \"Positive vs. Negative\"\nWe know have many procentage negative, neutral and positive tweets the airlines have received from customers. Now we want to get deeper into what words makes tweets classify as negative, neutral and positive. \n\n![positive_negative](https:\/\/media.giphy.com\/media\/dJGYFScvBjfRabiH7m\/giphy.gif)\n\nWe collect all the words from each class\/type and create a list of 10 most common words in each category. This might tell us some more which can be used as knowledge later on.","e5c5d83a":"### Results","97a4684f":"**Topic modeling**","9ea66ab8":"### Sentiment analysis for all four airlines","f27da2df":"#### First let's import the packages needed for this part:","134de04d":"#### Let's start the ml ","8085f145":"We can see that Random Forest has the best results in classifying our tweets both in each category and with the overall accuracy of 70%. This also gets the best result for the neutral tweets with 69 %.","fa6d2dbc":"Sorry, we got excited way too fast...\nWe can't create the simple graph from our nodes and edges because the dataset is just too big and it would take too much time to compute (trust us, we've tried in both Python and R)\n\n![alt text](https:\/\/media.giphy.com\/media\/39gIrKpwKes3C\/giphy.gif)\n\nBut for your entertainment we'll present our beautiful network analysis in R at the end","a1ba4748":"We can see that the accuracy for this model is 64% which is even worse than simple logistic regression. Although this model is better at predicting neutral tweets, the precision for both other classes is lower than in logistic regression.","538090aa":"Looks like after a lot of struggle we finally managed to get working graph object! \nIn addition the number of edges matches the number of responses from companiesis, which looks very promising for our analysis\n\n![alt text](https:\/\/media.giphy.com\/media\/TdfyKrN7HGTIY\/giphy.gif)","ae49ebab":"# Module 2 - group assignment\n\nAuthors: Mille Kathrine S\u00f8rensen, Jakob Knudsen, Karolina Grodzi\u0144ska\n\n![alt text](https:\/\/media.giphy.com\/media\/xT5LMHxhOfscxPfIfm\/giphy.gif)"}}