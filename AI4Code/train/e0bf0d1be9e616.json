{"cell_type":{"6a183045":"code","359e7498":"code","5b6dd829":"code","66e880f7":"code","a5c27e48":"code","c99f98b2":"code","72f2b9f4":"code","7fac864f":"code","a2ca309a":"code","383fe4e7":"code","73bbb2e6":"code","52fb6db3":"code","e82376fd":"code","9d9063af":"code","70e89a7b":"code","d8818526":"code","fe72de7c":"code","b9c85350":"code","34555df1":"code","f52776ec":"code","8a463848":"code","2dff9fe7":"markdown","661209f8":"markdown","ff7bc287":"markdown","7a4242f1":"markdown","7fc3ab6c":"markdown","b76605ff":"markdown","6a7610b4":"markdown","e745919b":"markdown","b9ffb23d":"markdown","ec0d924a":"markdown","a23ac269":"markdown","5c975a30":"markdown","b508bbde":"markdown","2ca90af7":"markdown","6d9351de":"markdown","487e7db8":"markdown"},"source":{"6a183045":"import os\nimport pandas as pd\nimport numpy as np\nimport random\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error as mse\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.autograd import Variable as V","359e7498":"df = pd.read_csv(\"\/kaggle\/input\/top50spotify2019\/top50.csv\", encoding=\"ISO-8859-1\", index_col= [\"Unnamed: 0\"])\ndf.head()","5b6dd829":"df.info()","66e880f7":"Genre_Enc= LabelEncoder().fit_transform(df[\"Genre\"])\ndf.insert(3,'Genre_Enc',Genre_Enc)","a5c27e48":"plt.figure(figsize=(10,6))\n\nheatmap = sns.heatmap(df.corr(), vmin=-1,vmax=1, annot=True, cmap='viridis')\n\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\nplt.show()","c99f98b2":"Y = df.Popularity\nX = df.drop(['Popularity','Track.Name','Artist.Name','Genre'],axis=1)","72f2b9f4":"fig = px.line(df, x= range(0,df.shape[0]), y = sorted(Y),\n             hover_name = \"Track.Name\",hover_data= ['Artist.Name', 'Genre'])\n\nfig.update_layout(title= 'Popularity sorted', \n                  xaxis =dict(title='Song index'),\n                  yaxis =dict(title='Popularity'))\nfig.show()","7fac864f":"RFR = RandomForestRegressor(random_state=42,n_jobs=2)\n\nRFR_error = -1*cross_val_score(RFR,X,Y,cv=10, scoring='neg_mean_squared_error')\nRFR.fit(X,Y)\n\nprint('RFR max error by CV is: {:.3f} \\nRFR min error by CV is: {:.3f} \\nRFR mean error by CV is: {:.3f}'.\n      format(RFR_error.max(),RFR_error.min(),RFR_error.mean()))\n\nfig= plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),sorted(Y), label='Actual Value',lw=2, alpha= 0.7)\nplt.plot(sorted(RFR.predict(X)), label='Random Forest Prediction')\n\nplt.title(\"Random Forest prediction\")\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nfig.legend(loc='lower right',bbox_to_anchor=(0.85,0.15))\nplt.show()\n\nRFR_mse = mse(RFR.predict(X), Y)\nprint(\"RFR mean squared error is: {:.4f}\".format(RFR_mse))","a2ca309a":"GBR = GradientBoostingRegressor(random_state=42)\n\nGBR_error = -1*cross_val_score(GBR,X,Y,cv=10, scoring='neg_mean_squared_error')\nGBR.fit(X,Y)\n\nprint('GBR max error by CV is: {:.3f} \\nGBR min error by CV is: {:.3f} \\nGBR mean error by CV is: {:.3f}'.\n      format(GBR_error.max(),GBR_error.min(),GBR_error.mean()))\nfig= plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),sorted(Y), label='Actual Value',lw=2, alpha= 0.7)\nplt.plot(sorted(GBR.predict(X)), label='Gradien Boosting Prediction')\n\nplt.title(\"Gradient Boosting prediction\")\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nfig.legend(loc='lower right',bbox_to_anchor=(0.85,0.15))\nplt.show()\n\nGBR_mse = mse(GBR.predict(X), Y)\nprint(\"GBR mean squared error is: {:.4f}\".format(GBR_mse))","383fe4e7":"KNR = KNeighborsRegressor(n_jobs=2)\n\nKNR_error = -1*cross_val_score(KNR,X,Y,cv=10, scoring='neg_mean_squared_error')\nKNR.fit(X,Y)\n\nprint('KNR max error by CV is: {:.3f} \\nKNR min error by CV is: {:.3f} \\nKNR mean error by CV is: {:.3f}'.\n      format(KNR_error.max(),KNR_error.min(),KNR_error.mean()))\n\nfig= plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),sorted(Y), label='Actual Value',lw=2, alpha= 0.7)\nplt.plot(sorted(KNR.predict(X)), label='K Neighbors Prediction')\n\nplt.title(\"K Neighbors prediction\")\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nfig.legend(loc='lower right',bbox_to_anchor=(0.85,0.15))\nplt.show()\n\nKNR_mse = mse(KNR.predict(X), Y)\nprint(\"KNR mean squared error is: {:.4f}\".format(KNR_mse))","73bbb2e6":"SVRR = SVR(kernel='linear')\n\nSVRR_error = -1*cross_val_score(SVRR,X,Y,cv=10, scoring='neg_mean_squared_error')\nSVRR.fit(X,Y)\n\nprint('SVR max error by CV is: {:.3f} \\nSVR min error by CV is: {:.3f} \\nSVR mean error by CV is: {:.3f}'.\n      format(SVRR_error.max(),SVRR_error.min(),SVRR_error.mean()))\n\nfig= plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),sorted(Y), label='Actual Value',lw=2, alpha= 0.7)\nplt.plot(sorted(SVRR.predict(X)), label='Support Vector Prediction')\n\nplt.title(\"Support Vector prediction\")\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nfig.legend(loc='lower right',bbox_to_anchor=(0.85,0.15))\nplt.show()\n\nSVRR_mse = mse(SVRR.predict(X), Y)\nprint(\"SVR mean squared error is: {:.4f}\".format(SVRR_mse))","52fb6db3":"LR = LinearRegression()\n\nLR_error = -1*cross_val_score(LR,X,Y,cv=10, scoring='neg_mean_squared_error')\nLR.fit(X,Y)\n\nprint('LR min error by CV is: {:.3f} \\nLR min error by CV is: {:.3f} \\nLR mean error by CV is: {:.3f}'.\n      format(LR_error.max(),LR_error.min(),LR_error.mean()))\n\nfig= plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),sorted(Y), label='Actual Value',lw=2, alpha= 0.7)\nplt.plot(sorted(LR.predict(X)), label='Linear Prediction')\n\nplt.title(\"Linear prediction\")\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nfig.legend(loc='lower right',bbox_to_anchor=(0.75,0.15))\nplt.show()\n\nLR_mse = mse(LR.predict(X), Y)\nprint(\"RFR mean squared error is: {:.4f}\".format(LR_mse))","e82376fd":"fig= plt.figure(figsize=(16,9))\n\nplt.plot(RFR_error, label='Random Forest')\nplt.plot(GBR_error, label='Gradient Boosting')\nplt.plot(KNR_error, label='K Neighbours')\nplt.plot(SVRR_error, label= 'Support Vector')\nplt.plot(LR_error, label= 'Linear')\n\n\nfig.suptitle(\"Cross Validation Error\")\nfig.legend(loc='upper right',bbox_to_anchor=(0.8,0.75))\nplt.show()","9d9063af":"# Giving weights to prediction models based on their accuracy\nmean_errors = np.array([RFR_error.mean(),GBR_error.mean(),KNR_error.mean(),SVRR_error.mean(),LR_error.mean()])\nmin_errors = np.array([RFR_error.min(),GBR_error.min(),KNR_error.min(),SVRR_error.min(),LR_error.min()])\nmax_errors = np.array([RFR_error.max(),GBR_error.max(),KNR_error.max(),SVRR_error.max(),LR_error.max()])\n\nRFR_w0,GBR_w0,KNR_w0,SVRR_w0,LR_w0 = mean_errors\/(mean_errors.sum())\nRFR_w1,GBR_w1,KNR_w1,SVRR_w1,LR_w1 = min_errors\/(min_errors.sum())\nRFR_w2,GBR_w2,KNR_w2,SVRR_w2,LR_w2 = max_errors\/(max_errors.sum())\n\nRFR_w = (RFR_w0+RFR_w1+RFR_w2)\/3\nGBR_w = (GBR_w0+GBR_w1+GBR_w2)\/3\nKNR_w = (KNR_w0+KNR_w1+KNR_w2)\/3\nSVRR_w = (SVRR_w0+SVRR_w1+SVRR_w2)\/3\nLR_w = (LR_w0+LR_w1+LR_w2)\/3","70e89a7b":"RGKSL0_Ypred = RFR_w0*RFR.predict(X)+GBR_w0*GBR.predict(X)+KNR_w0*KNR.predict(X)+SVRR_w0*SVRR.predict(X)+LR_w0*LR.predict(X)\nRGKSL0_mse = mse(RGKSL0_Ypred,Y)\n\nRGKSL1_Ypred = RFR_w1*RFR.predict(X)+GBR_w1*GBR.predict(X)+KNR_w1*KNR.predict(X)+SVRR_w1*SVRR.predict(X)+LR_w1*LR.predict(X)\nRGKSL1_mse = mse(RGKSL1_Ypred,Y)\n\nRGKSL2_Ypred = RFR_w2*RFR.predict(X)+GBR_w2*GBR.predict(X)+KNR_w2*KNR.predict(X)+SVRR_w2*SVRR.predict(X)+LR_w2*LR.predict(X)\nRGKSL2_mse = mse(RGKSL2_Ypred,Y)\n\nRGKSL_Ypred = RFR_w*RFR.predict(X)+GBR_w*GBR.predict(X)+KNR_w*KNR.predict(X)+SVRR_w*SVRR.predict(X)+LR_w*LR.predict(X)\nRGKSL_mse = mse(RGKSL_Ypred,Y)\n\n\nprint('RGKSL0 model has a mean squared error of : {:.3f}'.format(RGKSL0_mse) )\nprint('RGKSL1 model has a mean squared error of : {:.3f}'.format(RGKSL1_mse) )\nprint('RGKSL2 model has a mean squared error of : {:.3f}'.format(RGKSL2_mse) )\nprint('RGKSL model has a mean squared error of : {:.3f}'.format(RGKSL_mse) )","d8818526":"fig= plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),sorted(Y), label='Actual Value')\nplt.plot(sorted(RGKSL0_Ypred), label='w with Mean Error')\nplt.plot(sorted(RGKSL1_Ypred), label='w with Min Error')\nplt.plot(sorted(RGKSL2_Ypred), label='w with Max Error')\nplt.plot(sorted(RGKSL_Ypred), label= 'w with Mean(Min,Max,Mean) Error')\n\n\nfig.suptitle(\"Comparison between weights choosing method\")\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nfig.legend(loc='lower right',bbox_to_anchor=(0.85,0.15))\nplt.show()\n","fe72de7c":"# Giving weights to prediction models based on their mse\nmse_errors = np.array([RFR_mse,GBR_mse,KNR_mse,SVRR_mse,LR_mse])\n\nRFR_wmse,GBR_wmse,KNR_wmse,SVRR_wmse,LR_wmse = (1\/mse_errors)\/((1\/mse_errors).sum())\n\n# Building the model\n\nRGKSL_mse_Ypred = RFR_wmse*RFR.predict(X)+GBR_wmse*GBR.predict(X)+KNR_wmse*KNR.predict(X)+SVRR_wmse*SVRR.predict(X)+LR_wmse*LR.predict(X)\nRGKSL_mse_MSE = mse(RGKSL_mse_Ypred,Y)","b9c85350":"fig= plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),sorted(Y), label='Actual Value',lw=2, alpha= 0.7)\nplt.plot(sorted(RGKSL_mse_Ypred), label='w with previous mse')\n\nplt.title(\"Model of models with MSE prediction\")\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nfig.legend(loc='lower right',bbox_to_anchor=(0.85,0.15))\nplt.show()\nprint('RGKSL_mse model has a mean squared error of : {:.3f}'.format(RGKSL_mse_MSE) )","34555df1":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nx = torch.from_numpy(X.values.astype(np.float32)).reshape(-1,10).to(device)\ny = torch.from_numpy(np.array(Y).astype(np.float32)).reshape(-1,1).to(device)\n\ninput_shape, hidden_shape1, hidden_shape2, output_shape, EPOCH = 10, 500, 10, 1, 3001\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(input_shape, hidden_shape1),\n    torch.nn.ReLU(),\n    torch.nn.Linear(hidden_shape1, hidden_shape2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(hidden_shape2, output_shape),\n).to(device)\nlearning_rate = 1e-3\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\nloss_fn = torch.nn.MSELoss()\n\n\nfor epoch in range(EPOCH):\n\n    pred = model(x)\n    loss = loss_fn(pred, y)\n    \n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    if epoch % 500 == 0:\n        print('EPOCH: {}. Training loss: {:.4f}'.format(epoch,loss_fn(model(x), y)))\n\nNNR_Ypred = model(x).detach().numpy()\n\nfig= plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),sorted(Y), label='Actual Value')\nplt.plot(sorted(NNR_Ypred), '+-',label='Neural Network')\n\nfig.suptitle(\"Neural Network Regression\")\nfig.legend(loc='lower right',bbox_to_anchor=(0.85,0.15))\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nplt.show()\nNNR_mse = mse(NNR_Ypred,Y)\nprint(\"NNR has a mean squared error of: {:.4f}\".format(NNR_mse))\nprint(\"Applying a Neural Network of two hidden layers seems to be the best option but may suffer from overfitting.\\nThe error is clearly the best, dropping from 0.034 to {:.4f}.\".format(NNR_mse))","f52776ec":"plt.figure(figsize=(16,9))\n\nplt.plot(range(0,50),Y, label='Actual Value',lw=10,alpha= 0.5,color='black')\nplt.plot(NNR_Ypred,label='Neural Network',color='green')\nplt.plot(RGKSL0_Ypred, label='Regressor of CV error',color='orange')\nplt.plot(RGKSL_mse_Ypred, label='Regressor of MSE error',color='magenta')\nplt.plot(RFR.predict(X), label='Random Forest',color= 'blue')\nplt.plot(GBR.predict(X), label='Gradient Boosting',color='red')\nplt.plot(KNR.predict(X), label='K Neighbors',color='pink')\nplt.plot(SVRR.predict(X), label='Support Vector', color='yellow')\nplt.plot(LR.predict(X), label='Linear')\n\nplt.title(\"Model predicted values\")\nplt.legend(loc='best')\nplt.xlabel(\"Items\")\nplt.ylabel(\"Popularity\")\nplt.show()\n","8a463848":"plt.figure(figsize=(16,9))\n\nheight=np.array([RFR_mse,GBR_mse,KNR_mse,SVRR_mse,LR_mse,RGKSL0_mse,RGKSL_mse_MSE,NNR_mse])\nx_mse = ['Random_Forest', 'Gradient_Boosting','K_Neighbours','Support_Vector','Linear',\n        'Reg_of_CV','Reg_of_MSE','Neural_Network']\n\ndf_sns = pd.DataFrame({'Model':x_mse,\n                      'Mean Squared Error':height})\ndf_sns.sort_values(by=['Mean Squared Error'],inplace=True)\nsns.barplot(data=df_sns,y='Model',x='Mean Squared Error')\n\nplt.title('Model ranking by MSE')\nplt.show()","2dff9fe7":"I'm starting with neural networks. If you have any advice please comment it so I can improve.\n\nThank you for reading. ","661209f8":"### Gradient Boosting Regressor","ff7bc287":"Popularity is:\nCorrelated directly with:\n* Genre\n* Speechiness\n* Beats.Per.Minute\n\nInverse correlated with:\n* Valence\n\nNon correlated to others.","7a4242f1":"### Support Vector Regressor","7fc3ab6c":"# Spotify song popularity prediction\n\nBased on the notebook:\n\nhttps:\/\/www.kaggle.com\/thomaskonstantin\/top-spotify-songs-analysis-modeling-and-prediction\n\nI tried to elaborate multiple models to predict the data.","b76605ff":"The best option for building a linear model of previous models is to choose the weights based on the mean error or min error of the *mean_squared_error* function from cross validation.","6a7610b4":"## Neural Network","e745919b":"## Model Popularity ","b9ffb23d":"### Model of models by MSE error","ec0d924a":"### Random Forest Regressor","a23ac269":"### K Neighbours Regressor","5c975a30":"### Linear Regressor","b508bbde":"## Data","2ca90af7":"## Correlation","6d9351de":"## Obtaining a model\n### Model of models by Cross Validation error","487e7db8":"## Summary"}}