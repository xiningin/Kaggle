{"cell_type":{"6ec6c6db":"code","121afaa6":"code","3e347338":"code","f8356a0d":"code","fd02b5b4":"code","eeb04c10":"code","45dafdf0":"code","bf91defe":"code","51d17704":"code","a7c9d985":"code","e837a9c1":"code","46eee851":"code","b84b852d":"code","ccdd2ee7":"code","6e005adc":"markdown","597edb72":"markdown","d523863d":"markdown","de0c2543":"markdown","488bd146":"markdown","6d430fc5":"markdown","0e02437e":"markdown","2b91dfc8":"markdown","7c2d9f36":"markdown","3d9791d9":"markdown","c725c2d6":"markdown","6ae918f6":"markdown","a999e73d":"markdown","55fb2346":"markdown"},"source":{"6ec6c6db":"import math\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom IPython.display import clear_output","121afaa6":"path = '..\/input\/50-startups\/50_Startups.csv'\ndf = pd.read_csv(path)\ndf = shuffle(df)\ndf.head()","3e347338":"# group into one feature\ndf['Spent'] = df['R&D Spend'] + df['Administration'] + df['Marketing Spend']\n\n# standardization of the features spent and profit\nscaler = StandardScaler()\ndf[['Spent', 'Profit']] = scaler.fit_transform(df[['Spent', 'Profit']])","f8356a0d":"plt.figure(figsize=(14,8))\nplt.title(\"Spent vs Profit\")\nplt.xlabel(\"Spent\")\nplt.ylabel(\"Profit\")\nplt.plot(df['Spent'], df['Profit'], 'bo')","fd02b5b4":"def forward(gamma, X):\n    w, b = gamma\n    z = X * w + b\n    return z","eeb04c10":"def loss_fn(y, y_hat):\n    return 1\/2 * (y_hat - y) ** 2","45dafdf0":"def dloss(y, y_hat):\n    return y_hat - y","bf91defe":"def gradients(gamma, X, y, y_hat):\n    dl = dloss(y, y_hat)\n    dw = dl * X\n    db = dl\n    return dw, db","51d17704":"np.random.seed(343242)\nscale = 1\/max(1., (2+2)\/2.)\nlimit = math.sqrt(3.0 * scale)\n\nw = np.random.uniform(-limit, limit, size=1)\nb = np.random.uniform(-limit, limit, size=1)\n\ngamma = [w, b]","a7c9d985":"X, y = df['Spent'].values, df['Profit'].values\ntest = np.arange(y.min(), y.max() + 0.5, 0.02)\n\n# split into batches of 4\nbatches = np.array_split(np.arange(len(X)), len(X) \/ 4)","e837a9c1":"alpha = 0.1\nbeta1 = 0.9\nbeta2 = 0.999\n\nm = np.zeros(len(gamma))\nu = np.zeros(len(gamma))","46eee851":"for e in range(100):\n\n    for t, batch in enumerate(batches):\n        y_hat = forward(gamma, X[batch])\n        loss = loss_fn(y_hat, y[batch]).mean()\n\n        dw, db = gradients(gamma, X[batch], y[batch], y_hat)\n        g = dw.mean(), db.mean()\n\n        # adamax\n        for i in range(len(g)):\n            m[i] = (beta1 * m[i] + (1 - beta1)) * g[i]\n            u[i] = max(beta2 * u[i], abs(g[i]))\n            gamma[i] -= (alpha \/ ( 1 - beta1)) * m[i] \/ u[i]\n\n    if((e+1) % 10 == 0):\n        clear_output(wait=True)\n        plt.figure(figsize=(14,8))\n        plt.plot(X, y, 'bo')\n        plt.plot(test, forward(gamma, test), 'r-')\n        plt.show()","b84b852d":"def predict(gamma, X, scaler):\n    X = scaler.transform([[X, 0.]])[0]\n    z = forward(gamma, X)[0]\n    z = scaler.inverse_transform([[0., z]])[0][0]\n    return z","ccdd2ee7":"# the lowest value for the prediction is the df['Spent'].min()\nmoney_spent = df['Spent'].min()\n# have to reverse it with the scaler\nmoney_spent = scaler.inverse_transform([[money_spent, 0.]])[0][0]\n\n\nprofit_made = predict(gamma, money_spent, scaler)\nprint(\"Money Spent:%6.2f$ - Profit:%6.2f$\" % (money_spent, profit_made))","6e005adc":"<h1 id=\"parameters\" style=\"color:black; background:white; border:0.5px dotted black;\"> \n    <center>Hyperparameters\n        <a class=\"anchor-link\" href=\"#parameters\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","597edb72":"<h1 id=\"dataset\" style=\"color:black; background:white; border:0.5px dotted black;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","d523863d":"<div width=\"100%\">\n    <img width=\"100%\" src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/418397\/799497\/8f5cf74367e40c83b8828f9950a803e8\/dataset-cover.jpg\" \/>\n<\/div>","de0c2543":"<h1 id=\"back\" style=\"color:black; background:white; border:0.5px dotted black;\"> \n    <center>Backward propagation\n        <a class=\"anchor-link\" href=\"#back\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","488bd146":"<h1 id=\"training\" style=\"color:black; background:white; border:0.5px dotted black;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","6d430fc5":"## Load dataset","0e02437e":"## Features and labels + test dataset","2b91dfc8":"<h1 id=\"forward\" style=\"color:black; background:white; border:0.5px dotted black;\"> \n    <center>Forward propagation\n        <a class=\"anchor-link\" href=\"#forward\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","7c2d9f36":"<h1 id=\"prediction\" style=\"color:black; background:white; border:0.5px dotted black;\"> \n    <center>Prediction\n        <a class=\"anchor-link\" href=\"#prediction\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","3d9791d9":"<h1 id=\"loss\" style=\"color:black; background:white; border:0.5px dotted black;\"> \n    <center>Loss function\n        <a class=\"anchor-link\" href=\"#loss\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","c725c2d6":"## Weights and bias with Xavier initialization","6ae918f6":"## Adamax hyperparameters","a999e73d":"## Plot the Spent\/Profit","55fb2346":"## Features engineering"}}