{"cell_type":{"d71212c3":"code","7a7d3108":"code","79c9df72":"code","acd9acbe":"code","aa11e54a":"code","c23d9b43":"code","249282b3":"code","ffb37cc2":"code","08465511":"code","675623e4":"code","75f69bb1":"code","7d2a921e":"code","e2348b04":"code","522c76cc":"code","ff1f0ed7":"code","57e821ed":"code","c12765ff":"code","1a8ab546":"code","8fbbe6e2":"markdown","fe0a3edb":"markdown","4420f147":"markdown","1003eb48":"markdown","d40def36":"markdown","e9fd50f9":"markdown","d3986ce4":"markdown","d8f355bc":"markdown","2acd0648":"markdown","a59c7152":"markdown","cee60eb5":"markdown","3c8409a4":"markdown","a14a4a7c":"markdown"},"source":{"d71212c3":"# Packages required:\nimport os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\nfrom keras.metrics import BinaryAccuracy, Precision, Recall, AUC\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, precision_recall_curve, classification_report\n\nnp.random.seed(0)\n\n## Build in Python 3.8.2\n!python --version ","7a7d3108":"# Identify the parent folder where all folders and files are contained \nbase_dir = os.path.join(os.getcwd(), '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray')\ntotal_number = len(glob(os.path.join(base_dir,'*','*','*.jpeg')))\n\nprint(os.listdir(base_dir))\n# Checking the folder structure\nprint(\"Data composition in folder chest_xray\\n\")\nfor folder in ['train', 'val', 'test']:\n    num_of_jpeg = len(glob(os.path.join(base_dir, folder, \"*\", '*.jpeg')))\n    print(\"{}:\\t\\t{} ({:.2f}% of total)\".format(folder, num_of_jpeg, num_of_jpeg\/total_number*100))\n    for subfolder in os.listdir(os.path.join(base_dir, folder)):\n        num_in_subfolder = len(glob(os.path.join(base_dir, folder, subfolder,'*.jpeg')))\n        print(\" - {}:\\t  {} ({:.2f}%)\".format(subfolder, num_in_subfolder, num_in_subfolder\/num_of_jpeg*100))\n        \nprint(\"\\n For a total of {} .jpeg files.\".format(total_number))","79c9df72":"# Let's proceed with the analysis of the database that I've downloaded from keggle\n\n# First let's check that the number of files matches the description in the webpage. So to check that all images are accounted for.\ntotal_number = len(glob(os.path.join(base_dir,'*','*','*.jpeg')))\n    \n# Checking the folder structure\nprint(\"Data composition in folder chest_xray\\n\")\nfor folder in ['train', 'val', 'test']:\n    num_of_jpeg = len(glob(os.path.join(base_dir, folder, \"*\", '*.jpeg')))\n    print(\"{}:\\t\\t{} ({:.2f}% of total)\".format(folder, num_of_jpeg, num_of_jpeg\/total_number*100))\n    for subfolder in os.listdir(os.path.join(base_dir, folder)):\n        num_in_subfolder = len(glob(os.path.join(base_dir, folder, subfolder,'*.jpeg')))\n        print(\" - {}:\\t  {} ({:.2f}%)\".format(subfolder, num_in_subfolder, num_in_subfolder\/num_of_jpeg*100))\n        \nprint(\"\\n For a total of {} .jpeg files.\".format(total_number))","acd9acbe":"NORMAL = glob(os.path.join(base_dir,'*','NORMAL','*.jpeg'))\nPNEUMONIA = glob(os.path.join(base_dir,'*','PNEUMONIA','*.jpeg'))\n\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(9, 4))\nfor i in range(3):\n    axes[0,i].set_xlabel('Normal')\n    axes[0,i].imshow(mpimg.imread(NORMAL[i]), cmap='gray')\n    axes[0,i].set_xticks([])\n    axes[0,i].set_yticks([])\n    axes[1,i].set_xlabel('Pneumonia')\n    axes[1,i].imshow(mpimg.imread(PNEUMONIA[i]), cmap='gray')\n    axes[1,i].set_xticks([])\n    axes[1,i].set_yticks([])\nplt.show()","aa11e54a":"# Dataframe with all images manually classified as healhy patients \ndf_normal = pd.DataFrame({'Path': NORMAL, 'Class': 'NORMAL' })\n\n# Dataframe with all images manually classified as patients wiht pneumonia\ndf_pneumonia = pd.DataFrame({'Path': PNEUMONIA, 'Class': 'PNEUMONIA' })\n\n# The entire dataset of images\ndf = pd.concat([df_normal, df_pneumonia])\n\ndf.head()","c23d9b43":"df.describe()","249282b3":"train_split = 0.4 # Majority of images for the train subset (60%)\nX_train, X_val, y_train, y_val = train_test_split(\n    df['Path'], df['Class'], \n    test_size = train_split, \n    stratify = df['Class'], # This parameter establishes a proportional split of values in the sample\n    random_state=42)\n\nval_test_split = 0.5 # Equal division for test and validation\nX_test, X_val, y_test, y_val = train_test_split(\n    X_val, y_val,  test_size = val_test_split, stratify = y_val, random_state=42)\n\ntrain_set = pd.DataFrame({'Path': X_train, 'Class' : y_train})\nval_set = pd.DataFrame({'Path': X_val, 'Class': y_val})\ntest_set = pd.DataFrame({'Path': X_test,'Class' : y_test})\n\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 3))\nsns.countplot(x=\"Class\", data=test_set, ax=axes[0])\nsns.countplot(x=\"Class\", data=val_set, ax=axes[1])\nsns.countplot(x=\"Class\", data=train_set, ax=axes[2])\n\naxes[0].set_title(\"Test Set\")\naxes[1].set_title(\"Validation Set\")\naxes[2].set_title(\"Train Set\")\nplt.show()","ffb37cc2":"# Checking the folder structure\nprint(\"Data composition in rearranged sets\\n\")\nfor set_name, set_ in zip(['train_set', 'val_set', 'test_set'], [train_set, val_set, test_set]):\n    print(\"{}:\\t{} ({:.2f}% of total)\".format(set_name, set_.shape[0], set_.shape[0]\/total_number*100)) #\n    for label in ['PNEUMONIA', 'NORMAL']:\n        print(\" - {}:\\t  {} ({:.2f}%)\".format(label, sum(set_.Class==label), set_[set_['Class']==label].shape[0]\/set_.shape[0]*100))","08465511":"pneumo_in_test = sum(train_set.Class=='PNEUMONIA')\nnormal_in_test = sum(train_set.Class=='NORMAL')\n\nprint(\"Pneumonia images count in training set: {}\".format(pneumo_in_test))\nprint(\"Normal images count in training set: {}\\n\".format(normal_in_test))\nprint(\"Total number of images: {}\\n\".format(train_set.shape[0]))\nprint(\"Initial bias: {:.5f}\\n\".format(np.log([pneumo_in_test \/ normal_in_test])[0]))\n\nweight_for_normal = (1 \/ normal_in_test) * (train_set.shape[0]) \/ 2.0\nweight_for_pneumo = (1 \/ pneumo_in_test) * (train_set.shape[0]) \/ 2.0\n\nprint(\"Weight for class 0 (Normal): {:.2f}\".format(weight_for_normal))\nprint(\"Weight for class 1 (Pneuom): {:.2f}\".format(weight_for_pneumo))\n\nclass_weight = {0: weight_for_normal, 1: weight_for_pneumo}\n\n# Alternativly we could have used sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(train_generator), train_generator)","675623e4":"rescale = 1.\/255 #  To get all the scaled data in the range [0, 1]\ntarget_size = (150, 150) # The dimensions to which all images found will be resized. In this dataset, we have images of different size\nbatch_size = 32 # is the number of training instances observed before the optimizer performs a weight update.\nclass_mode = \"binary\"\n\n## Data Augmentation\n# We can artificially expand our training set with multiple types of transformation, including rotation, rescaling, horizontal or vertical flip, zooming, etch.\n# This also contributes to avoid overfitting issues\ntrain_datagen = ImageDataGenerator(\n    rescale = rescale,\n    rotation_range = 30, # Randomly rotating pictures, it takes values between 0-180\n    shear_range = 0.2, # Shear Intensity\n    zoom_range = 0.2, # Randomly zooming pictures\n    horizontal_flip = True # Randomly flipping half of the images horizontally\n)\ntrain_generator = train_datagen.flow_from_dataframe( #Takes the dataframe and the path to a directory plus generates batches.\n        dataframe = train_set, x_col = \"Path\", y_col = \"Class\", batch_size = batch_size,seed = 42,\n        shuffle = True, # Randomly shuffles the input dataset\n        class_mode = class_mode,target_size = target_size)\n\nvalidation_datagen = ImageDataGenerator(rescale=rescale) # Data augmentation only for train set\nvalidation_generator = validation_datagen.flow_from_dataframe(\n        dataframe = val_set, x_col = \"Path\", y_col = \"Class\", batch_size = batch_size,\n        seed = 42, shuffle = False, class_mode = class_mode, target_size = target_size)\n\ntest_datagen = ImageDataGenerator(rescale=rescale)\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe = test_set, x_col = \"Path\", y_col = \"Class\", target_size=target_size,\n    class_mode=class_mode, batch_size=batch_size, shuffle = False)","75f69bb1":"model= Sequential() # It initializes the neural network\nmodel.add(Conv2D( # It makes a convolutional layer\n    32, # The number of output filters in the convolution\n    (3,3), # The feature detector\n    input_shape=(150, 150, 3),\n    activation='relu' # Rectified Linear Unit, the most comnly used activation function\n                ))\nmodel.add(MaxPooling2D(2,2)) # This enables the CNN to detect features irrespective of the difference in lighting and angles\n    \nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.2)) # Randomly \"switch-off\" of neurons to avoid overfitting\n    \nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.2))\n    \nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n    \nmodel.add(Flatten()) # Flattening transforms the entire pooled feature map matrix into a single column\nmodel.add(Dropout(0.2))\nmodel.add(Dense(256,activation='relu')) # The fully connected layer as in a hidden layer in ANNs\nmodel.add(Dense(1,activation='sigmoid'))\nprint(model.summary())","7d2a921e":"metrics_ = [ # Choosing the metrics of evaluation for our model\n    AUC(name='auc'), \n    BinaryAccuracy(name='accuracy'), \n    Precision(name=\"precision\"),\n    Recall(name=\"recall\"), \n           ]\n\nmodel.compile(\n    optimizer = 'adam', # This optimizer uses a stochastic gradient descent method\n    loss = 'binary_crossentropy', # For a binary classification problem\n    metrics = metrics_)","e2348b04":"# This feature is used to save checkpoints of your model at regular intervals and recover in case of problems.\nmetric = 'auc'\ncheckpoint = ModelCheckpoint(\n    filepath = 'chestxray_model.hdf5', \n    monitor = metric, \n    save_best_only = True)\n\n# This feature is used to interrupt training when validation performance has stopped improving after a while.\nearly_stopping = EarlyStopping(\n    monitor='val_auc', \n    verbose=1,\n    patience=10,\n    mode='max',\n    restore_best_weights=True)","522c76cc":"steps_per_epoch=len(train_generator)\nvalidation_steps=len(validation_generator)\nepochs = 10 # Number of times the training vectors are used to update weights\n\nhistory_model = model.fit(\n    train_generator,\n    validation_data = validation_generator,\n    \n    steps_per_epoch = steps_per_epoch,\n    validation_steps = validation_steps,\n    \n    epochs = epochs,\n    verbose = 1,\n    callbacks = [checkpoint, early_stopping],\n    \n    class_weight=class_weight)","ff1f0ed7":"result  = model.evaluate(test_generator, steps=len(test_generator), \n                         verbose=False, return_dict=True)\n\nprint(\"The model trained has a result for:\\nArea Under the Curve of {:.3f}\\n\\\n\\nAn Accuracy of {:.2f}%\\nPrecison {:.2f}% and \\nRecall of {:.2f}%\".format(\n    result['auc'],\n    result['accuracy']*100,\n    result['precision']*100,\n    result['recall']*100\n))","57e821ed":"fig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate([\"auc\",  \"accuracy\", \"precision\", \"recall\"]):\n    ax[i].plot(history_model.history[met])\n    ax[i].plot(history_model.history[\"val_\" + met])\n    ax[i].set_title(\"Model {}\".format(met))\n    ax[i].set_xlabel(\"epochs\")\n    ax[i].set_ylabel(met)\n    ax[i].legend([\"train\", \"val\"])","c12765ff":"predictions = model.predict(test_generator, batch_size = batch_size, steps=len(test_generator), verbose=0)\npred_classes =  (model.predict(test_generator, batch_size = batch_size) > 0.5).astype(\"int32\")\n\nprint(classification_report(test_generator.labels, pred_classes))","1a8ab546":"fpr, tpr, _ = roc_curve(test_generator.labels, predictions)\npre, rec, _ = precision_recall_curve(test_generator.labels, predictions)\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 3))\n\nax[0].plot(fpr, tpr, 'b')\nax[0].set_xlabel('False Positives Rate')\nax[0].set_ylabel('True positives Rate')\nax[0].set_title('ROC Curve')\n\nax[1].plot(pre, rec, 'b') \nax[1].set_xlabel('Recall')\nax[1].set_ylabel('Precision')\nax[1].set_title('Precision-Recall Curve')\n\nplt.show()","8fbbe6e2":"### Model Performance","fe0a3edb":"From the output above, we can see that the folder Train has got almost 90% of all images (89.07%) with the 3\/4 of images being Pneumonia. While in the folder Test we have only 10% of all images, with 2\/3 being labelled as pneumonia. And in the folder Val, there are present only 16 images in total.\n\nIn a normal machine learning analysis, it is good practice not to use the entire database to train our model but to split into subgroups and use only one of them at the time to train and the remaining for testing and validation.\n\nIn general, for small databases I prefer to create a k-cross-validation system, in which, iteratively, the whole dataset is used as part of train and test sets. While, for very large datasets, or those requiring great computational time, I prefer  to split the database into a training, testing and validation set.\n\nFor this exercise I choose to use a train\/test\/validation system. At this moment, with low computing power to perform a cross validation in a timely manner. Plus, given the nature of composition of the folders I have decided to rearrange the data and divide into a different ratio.","4420f147":"## Correct for data imbalance\nIn the now rearranged sets we have an equal ratio of Pneumonia\/Normal images in each subsets. However, the dataset is indeed still imbalanced with a different number of Pneumonia\/Normal images within each of the sets. \n\nThis can be a potential problem, indeed with our current ratio, a model could reach 73% accuracy just by classifying everything as Pneumonia. To solve this problem, I compute the class weights to indicate an imbalance in our data to our model using the parameter `CLASS_WEIGHTS`.","1003eb48":"### Fitting the model","d40def36":"### Selecting the metrics ","e9fd50f9":"# Exploratory Data Analysis\nBefore any attempt of creating a ML\/DL model is good practice to start with an Exploratory Data Analysis (EDA) of the database. During this stage, we analyse the data set to summarise its main characteristics and gain major insight into its features using numerical analysis and visual methods.\n\nIn my experience in the healthcare and in the bioinformatics sectors, databases are usually particularly messy and noisy. Experimental and clinical data might come from many different sources (public or company databases), different laboratories following different protocols. It is imperative to be very careful with the data, check if the data provided are correct in the input phase and have multiple checks along the pipeline.\n\nFor this particular challenge, we are close to an idea scenario. We have got a manually curated dataset of high quality black-and-white pictures that do not require data cleaning, analysis of missing value, feature scaling, correlation analysis, etch. But I will proceed to the analysis of the data folder, and the images contained in it.","d3986ce4":"### Creating the CNN Model","d8f355bc":"### Train\/test\/validation split\nContinue by dividing the dataset again in a determined ratio.\nI will use 60% of the data as a training set, 20% for the validation and test sets.","2acd0648":"### Pre processing","a59c7152":"# Challenge: Chest X-Ray Images (Pneumonia)\n## General Project Overview\nIn this [Kaggle competion](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia?) a set of 5,863 chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients, between the age of one to five years old, in Guangzhou. All chest X-ray imaging was performed as part of the patient's routine clinical care. \n\nAll chest radiographs were screened  by two expert physicians for quality control and removing all low quality or unreadable scans.\n\nIn the picture below are show the three type of chest X-ray present in the database: \n![alt](https:\/\/mattiacinelli.com\/wp-content\/uploads\/2020\/10\/output_5_0.png)\n\nOn the left-hand side it is present an image of a __healthy indivudal__ with clear lungs and no areas of abnormal opacification. In the middle and right-hand side images are present a patient affected by __bacterial__ and __viral__ pneumonia respectively. The latter, presents a more diffuse \u2018\u2018interstitial\u2019\u2019 pattern in both lungs. while the first typically exhibits a focal lobar consolidation, in this case in the right upper lobe (white arrows). \n\nFor this particular challenge we are requested to discern only healthy vs pneumonia affected chest X-ray.\n\n# Pneumonia\n\n> Pneumonia is a form of acute respiratory infection that affects the lungs. When an individual has pneumonia, the lungs\u2019 alveoli are filled with pus and fluid, which makes breathing painful and limits oxygen intake.\n>\n> Pneumonia is the single largest infectious cause of death in children worldwide. Pneumonia killed 808 694 children under the age of 5 in 2017, accounting for 15% of all deaths of children under five years old. [[Pneumonia - WHO]](https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/pneumonia)\n>\n> More recently, the novel Covid-19 virus and the consequent pandemic has seen a dramatic increase in pneumonia cases all over the world and it is considered one of the most serious consequences of this new virus. [[George et al. (2020)]](https:\/\/thorax.bmj.com\/content\/early\/2020\/08\/24\/thoraxjnl-2020-215314) [[Pneumonia - NHS]](https:\/\/www.nhs.uk\/conditions\/pneumonia\/)\n\n\n## The dataset\nThis is a _manually cureted_ dataset of 5,863 X-Ray images, in JPEG format. \nThe images are organized into __3 folders: (train, test, val)__. In each folder are two subfolders for each image category: `PNEUMONIA`, the pneumonia affected individual and `NORMAL` healthy patients. \n\n### Objectives\nThe objective of this kaggle challenge is a binary classification of images. Being a computer vision problem, I have chosen to use Convolutional Neural Network as a Deep Learning model for this challenge.","cee60eb5":"In the top row of the images above, we can see three examples of NORMAL images, those representing healthy individuals with clear lungs and no opacity. While the bottom row shows three PNEUMONIA individuals with infected and more opaque lungs.\n\nAlso we can notice that now all images have the same length\/width ratio.\n\n## Data preparation\nFirst, I create a pandas dataframe that will contain the path to each of the imanges and the label associated with them.","3c8409a4":"The numerical values of AUC and binary accuracy and the ROC curve plot shows that the image classification task was performed with high level of success, even with low number of convolutional layers and epochs.\n\n# Source \n- Deep learning with Tensorflow 2 and Keras. Gulli, Kapoor, Pal. Second Edition\n- [Keras code examples](https:\/\/keras.io\/examples\/vision\/xray_classification_with_tpus\/)\n- [Keras documentation](https:\/\/keras.io\/api\/preprocessing\/image\/)\n- [Kaggles' discussion board and notebooks](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia\/discussion)","a14a4a7c":"### Callbacks"}}