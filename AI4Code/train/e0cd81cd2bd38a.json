{"cell_type":{"84542060":"code","0bb466b2":"code","a9cf5fe4":"code","71705bda":"code","02b89d71":"code","1d6ccbce":"code","68bd8b5b":"code","b0db22be":"code","2e8ee834":"code","a37a08ee":"code","f3f8ac60":"code","c6a3fb2a":"code","ba961268":"code","8387df89":"code","ec2a06c1":"code","35cc74ac":"code","6e713d4a":"code","f9dc7077":"code","cb8a2f56":"markdown","b9b1bda1":"markdown","40e782bb":"markdown","48b7c62c":"markdown","3b020fad":"markdown","b449ea6e":"markdown"},"source":{"84542060":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","0bb466b2":"train_data = pd.read_csv('..\/input\/training\/training.csv')\nprint(train_data.shape)\ntrain_data.isna().sum()\n# train_data.isnull().any().value_counts()","a9cf5fe4":"# Using ffill to fill the na values:\ntrain_data.fillna(method='ffill', inplace=True)","71705bda":"img_dt = []\n\nfor i in range(len(train_data)):\n  img_dt.append(train_data['Image'][i].split(' '))\n  \nX = np.array(img_dt, dtype='float')","02b89d71":"# Visualizing one of the images:\nplt.imshow(X[1].reshape(96,96), cmap='gray')","1d6ccbce":"facial_pts_data = train_data.drop(['Image'], axis=1)\nfacial_pts = []\n\nfor i in range(len(facial_pts_data)):\n  facial_pts.append(facial_pts_data.iloc[i])\n  \ny = np.array(facial_pts, dtype='float')","68bd8b5b":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n\n# class Basic_CNN(nn.Module):\n#     def __init__(self):\n#         super(Basic_CNN, self).__init__()\n#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5) # (1,1,96,96) to (1,4,92,92)\n# #         self.conv1_bn = nn.BatchNorm2d(16)\n#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5) # (1,4,46,46) to (1,8,42,42)\n# #         self.conv2_bn = nn.BatchNorm2d(32)\n#         self.fc1 = nn.Linear(32*21*21, 250)\n#         self.fc2 = nn.Linear(250, 30)\n#         self.dp1 = nn.Dropout(p=0.4)\n    \n        \n    \n#     def forward(self, x, verbose=False):\n# #         x = self.conv1_bn(self.conv1(x))\n#         x = self.conv1(x)\n#         x = F.relu(x)\n#         x = F.max_pool2d(x, kernel_size=2)\n#         x = self.dp1(x)\n# #         x = self.conv2_bn(self.conv2(x))\n#         x = self.conv2(x)\n#         x = F.relu(x)\n#         x = F.max_pool2d(x, kernel_size=2)\n#         x = self.dp1(x)\n#         x = x.view(-1, 32*21*21)\n#         x = self.fc1(x)\n#         x = F.relu(x)\n#         x = self.dp1(x)\n#         x = self.fc2(x)\n#         return x\n      \nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5) # (b,1,96,96) to (b,4,92,92)\n        self.conv1_bn = nn.BatchNorm2d(4)\n        self.conv2 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=3) # (b,4,46,46) to (b,64,44,44)\n        self.conv2_bn = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3) # (b,64,22,22) to (b,128,20,20)\n        self.conv3_bn = nn.BatchNorm2d(128)\n        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3) # (b,128,10,10) to (b,256,8,8)\n        self.conv4_bn = nn.BatchNorm2d(256)\n        self.fc1 = nn.Linear(256*4*4, 1024)\n        self.fc2 = nn.Linear(1024, 256)\n        self.fc3 = nn.Linear(256, 30)\n        self.dp1 = nn.Dropout(p=0.4)\n    \n        \n    \n    def forward(self, x, verbose=False):\n        # apply conv1, relu and maxpool2d\n        x = self.conv1_bn(self.conv1(x))\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n        x = self.dp1(x)\n        \n        # apply conv2, relu and maxpool2d\n        x = self.conv2_bn(self.conv2(x))\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n        x = self.dp1(x)\n        \n        # apply conv3, relu and maxpool2d\n        x = self.conv3_bn(self.conv3(x))\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n        x = self.dp1(x)\n        \n        # apply conv4, relu and maxpool2d\n        x = self.conv4_bn(self.conv4(x))\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n        \n        # apply dropout\n        x = self.dp1(x)\n        \n        x = x.view(-1, 256*4*4)\n        \n        # now use FC layer with relu\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dp1(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.dp1(x)\n        x = self.fc3(x)\n        return x","b0db22be":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndef testing(model, device, valid_loader):\n  model.eval()\n  test_loss = 0\n  for data, target in valid_loader:\n    data, target = data.to(device), target.to(device)\n    data = data.view(-1, 96*96)\n    data = data.view(-1, 1, 96, 96)\n    output = model(data)\n    loss = criterion(output, target)\n    test_loss += loss.item()\n    \n  test_loss \/= len(valid_loader.dataset)\n  return test_loss\n\ndef training(epochs, model, criterion, device, train_loader, valid_loader, optimizer):\n  train_error_list = []\n  val_error_list = []\n  for epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    for batch_idx, (data, target) in enumerate(train_loader):\n      data, target = data.to(device), target.to(device)\n      data = data.view(-1, 96*96)\n      data = data.view(-1, 1, 96, 96)\n      optimizer.zero_grad()\n      output = model(data)\n      loss = criterion(output, target)\n      train_loss += loss.item()\n      loss.backward()\n      optimizer.step()\n    \n    train_loss \/= len(train_loader.dataset)\n    eval_loss = testing(model, device, valid_loader)\n    train_error_list.append(train_loss)\n    val_error_list.append(eval_loss)\n    if (epoch+1) % 25 == 0:\n      print(\"End of epoch {}: \\nTraining error = [{}]\\tValidation error = [{}]\".format(epoch+1, train_loss, eval_loss))\n  return train_error_list, val_error_list\n","2e8ee834":"def train_test_split(X, validation_split):\n  dataset_size = len(X)\n  indices = list(range(dataset_size))\n  val_num = int(np.floor(validation_split*dataset_size))\n  np.random.shuffle(indices)\n  train_indices, val_indices = indices[val_num:], indices[:val_num]\n\n  train_sampler = SubsetRandomSampler(train_indices)\n  valid_sampler = SubsetRandomSampler(val_indices)\n\n  loader_object = data_utils.TensorDataset(torch.from_numpy(X).float(), torch.from_numpy(y).float())\n  train_loader = data_utils.DataLoader(loader_object, batch_size=32, sampler=train_sampler)\n  valid_loader = data_utils.DataLoader(loader_object, batch_size=32, sampler=valid_sampler)\n  return train_loader, valid_loader","a37a08ee":"def get_n_params(model):\n    np=0\n    for p in list(model.parameters()):\n        np += p.nelement()\n    return np\n\nn_hidden = 128 # number of hidden units\noutput_size = 30\ntrain_loader, valid_loader = train_test_split(X, 0.2)\n\nmodel = CNN()\nmodel.to(device)\ncriterion = torch.nn.MSELoss() \noptimizer = optim.Adam(model.parameters())\n\nprint('Number of parameters: {}'.format(get_n_params(model)))\n\ntrain_error_list, valid_error_list = training(500, model, criterion, device, train_loader, valid_loader, optimizer)","f3f8ac60":"def plot_samples(X, y, model, num_samples):\n  fig, axes = plt.subplots(nrows=num_samples, ncols=2, figsize=(12,12))\n  \n  for row in range(num_samples):\n    sample_idx = np.random.choice(len(X))\n    x = X[sample_idx]\n    x = torch.from_numpy(x).float().view(1,1,96,96).to(device)\n    actual_y = y[sample_idx]\n    pred_y = model(x)\n    img = X[sample_idx].reshape(96,96)\n    \n    actual_y = np.vstack(np.split(actual_y, 15)).T\n    pred_y = pred_y.cpu().data.numpy()[0]\n    pred_y = np.vstack(np.split(pred_y, 15)).T\n    \n    axes[row, 0].imshow(img, cmap='gray')\n    axes[row, 0].plot(actual_y[0], actual_y[1], 'o', color='red', label='actual')\n    axes[row, 0].legend()\n    axes[row, 1].imshow(img, cmap='gray')\n    axes[row, 1].plot(actual_y[0], actual_y[1], 'o', color='red', label='actual')\n    axes[row, 1].plot(pred_y[0], pred_y[1], 'o', color='green', label='predicted')\n    axes[row, 1].legend()\n\n  \nplot_samples(X, y, model, 3)","c6a3fb2a":"test_data = pd.read_csv('..\/input\/test\/test.csv')\n\nimg_dt = []\n\nfor i in range(len(test_data)):\n  img_dt.append(test_data['Image'][i].split(' '))\n  \ntest_X = np.array(img_dt, dtype='float')","ba961268":"test_X_torch = torch.from_numpy(test_X).float().view(len(test_X),1,96,96).to(device)\ntest_predictions = model(test_X_torch)\ntest_predictions = test_predictions.cpu().data.numpy()\n\nkeypts_labels = train_data.columns.tolist()","8387df89":"# Visualizing the outputs:\n\ndef plot_samples_test(X, y, num_samples):\n  fig, axes = plt.subplots(nrows=1, ncols=num_samples, figsize=(20,12))\n  \n  for row in range(num_samples):\n    sample_idx = np.random.choice(len(X))\n    img = X[sample_idx].reshape(96,96)\n    predicted = y[sample_idx]\n    \n    predicted = np.vstack(np.split(predicted, 15)).T\n#     print(img, predicted)\n    axes[row].imshow(img, cmap='gray')\n    axes[row].plot(predicted[0], predicted[1], 'o', color='green', label='predicted')\n    axes[row].legend()\n  \nplot_samples_test(test_X, test_predictions, 6)","ec2a06c1":"id_lookup = pd.read_csv('..\/input\/IdLookupTable.csv')\nid_lookup_features = list(id_lookup['FeatureName'])\nid_lookup_image = list(id_lookup['ImageId'])\n\nfor i in range(len(id_lookup_features)):\n  id_lookup_features[i] = keypts_labels.index(id_lookup_features[i])\n\nlocation = []\nfor i in range(len(id_lookup_features)):\n  location.append(test_predictions[id_lookup_image[i]-1][id_lookup_features[i]])","35cc74ac":"id_lookup['Location'] = location","6e713d4a":"submission = id_lookup[['RowId', 'Location']]\nsubmission.head(5)","f9dc7077":"submission.to_csv('..\/input\/SubmissionFile.csv')","cb8a2f56":"# Prediction on test set:","b9b1bda1":"# Visualizing the test predictions","40e782bb":"# Visualizing the outputs:","48b7c62c":"# Reading the test dataset:\n","3b020fad":"Now, there are no missing values in the dataset. We now need to segregate the data into two parts: X and y. Here X is the Image feature values and y are all the other feature values","b449ea6e":"# Creating the submission file"}}