{"cell_type":{"1cdb2c08":"code","009f8ac4":"code","a7428675":"code","be484614":"code","3eccc876":"code","6680bd8f":"code","c19f15d9":"markdown"},"source":{"1cdb2c08":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport spacy\n\nimport nltk\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","009f8ac4":"test_df  = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\ntrain_df = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\n# train_df","a7428675":"# Source: https:\/\/www.kaggle.com\/bryanb\/first-approach-using-xgboost-with-hyperopt\n\nsp        = spacy.load('en_core_web_sm')\nstopwords = stopwords.words('english')\nsnowball  = SnowballStemmer(language='english')\n\ndef preprocessing_excerpt(text):\n    text = text.lower()\n    text = word_tokenize(text)\n    text = [ x for x in text if x not in stopwords ]\n    text = [ snowball.stem(x) for x in text ]\n    text = \" \".join(text)\n    return str(sp(text))\n\n\ntrain_df['excerpt_clean'] = train_df['excerpt'].apply(preprocessing_excerpt)\ntest_df[ 'excerpt_clean'] = test_df[ 'excerpt'].apply(preprocessing_excerpt)\ntrain_df","be484614":"# vectorizer       = TfidfVectorizer()\nvectorizer         = CountVectorizer()\nvectorizer.fit(np.concatenate([ train_df['excerpt_clean'].values, test_df['excerpt_clean'].values ]))\ntrain_vectors      = vectorizer.transform(train_df['excerpt_clean'].values)\ntest_vectors       = vectorizer.transform( test_df['excerpt_clean'].values)\n# feature_names      = vectorizer.get_feature_names()\n# test_feature_names = vectorizer.get_feature_names()\n\nX_train = pd.DataFrame(train_vectors.todense())\ny_train = train_df['target'].values\nX_test  = pd.DataFrame(test_vectors.todense()) ","3eccc876":"regressor = xgb.XGBRegressor()\nregressor.fit(X_train, y_train)\ny_pred    = regressor.predict(X_test)    \ny_pred","6680bd8f":"submission_df = pd.read_csv('..\/input\/commonlitreadabilityprize\/sample_submission.csv')\nsubmission_df['target'] = y_pred\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","c19f15d9":"# CommonLit - XGBooost  \n\nThis notebook uses CountVectorizer and XGBooost to make predictions"}}