{"cell_type":{"89764847":"code","e33e0096":"code","53bf36c1":"code","4fcfdf53":"code","14f3b71c":"code","b8e592a9":"code","10307a6d":"code","e7db8db9":"code","5a130d71":"code","8e8a9959":"code","81de1faa":"code","eeb0badd":"code","4d343f6e":"code","219d2396":"code","1bb2705a":"code","c60af688":"code","40e612a6":"code","3eb41092":"code","bff8468f":"code","200dbef0":"code","4536c1d0":"code","d5491d81":"code","a41e85af":"code","35c66060":"code","a61da3d4":"code","39bb39bc":"code","7750e2d7":"code","ee8518c9":"code","9af1c7d5":"code","4c855a92":"code","6188df94":"code","fb1e211e":"code","577931bd":"code","b65d747f":"code","2a0a919b":"code","1bf69854":"code","725d89e2":"code","3d749675":"code","e2010e84":"code","168ad971":"code","20535b0a":"code","e3053936":"code","c540de1f":"code","caf5c791":"code","31d7f6b0":"code","5fd099ce":"code","f7a75e46":"code","8be03fa0":"code","cd974c8e":"markdown","0e88a3ee":"markdown","69039c6c":"markdown","ea7543ec":"markdown","4034db30":"markdown","40bbedfb":"markdown","6d0c1740":"markdown","1413df20":"markdown","10dffb39":"markdown","21e8c6f3":"markdown","eff25896":"markdown","98ad2589":"markdown","9bd0af7a":"markdown","6dfe8310":"markdown","a1fce821":"markdown","a89d41a1":"markdown","6b40532f":"markdown","d6c83853":"markdown","efa23aaa":"markdown","409c9ea6":"markdown","efd64cc5":"markdown"},"source":{"89764847":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import mean_squared_error","e33e0096":"path = \"..\/input\/frozen-dessert-production\/Frozen_Dessert_Production.csv\"","53bf36c1":"df = pd.read_csv(path, parse_dates = [\"DATE\"])","4fcfdf53":"df.head(5)","14f3b71c":"df.info()","b8e592a9":"df.columns","10307a6d":"df = df.set_index('DATE')","e7db8db9":"df.columns = ['Production']","5a130d71":"df.head(5)","8e8a9959":"df.plot(figsize = (12, 6))\nplt.show()","81de1faa":"len(df)","eeb0badd":"test_size = 24","4d343f6e":"test_index  = len(df)-test_size\ntest_index","219d2396":"train = df.iloc[:test_index]\ntest = df.iloc[test_index:]","1bb2705a":"len(train)","c60af688":"len(test)","40e612a6":"train.head(5)","3eb41092":"test.head(5)","bff8468f":"scaler = MinMaxScaler()","200dbef0":"# IGNORE WARNING ITS JUST CONVERTING TO FLOATS\n# WE ONLY FIT TO TRAININ DATA, OTHERWISE WE ARE CHEATING ASSUMING INFO ABOUT TEST SET\nscaler.fit(train)","4536c1d0":"scaled_train = scaler.fit_transform(train)\nscaled_test = scaler.transform(test)","d5491d81":"length = 18 #one shorter to the length of test data\nbatch_size = 1\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length = length, batch_size = batch_size)","a41e85af":"validation_generator = TimeseriesGenerator(scaled_test, scaled_test, length = length, batch_size = batch_size)","35c66060":"n_features = 1","a61da3d4":"# define model\nmodel = Sequential()\n\n# Simple RNN layer\n#model.add(SimpleRNN(50,input_shape=(length, n_features))) #50 neurons\n\n# LSTM \nmodel.add(LSTM(100, activation = 'relu', input_shape = (length, n_features)))\n\n# Final Prediction\nmodel.add(Dense(1))\n\nmodel.compile(optimizer = 'adam', loss = 'mse')\n\n# Model Summary\nmodel.summary()","39bb39bc":"early_stop = EarlyStopping(monitor = 'val_loss', patience = 3)","7750e2d7":"model.fit_generator(generator, \n                    epochs = 25, \n                    validation_data = validation_generator, \n                    callbacks = [early_stop])","ee8518c9":"losses = pd.DataFrame(model.history.history)\nlosses.plot()\nplt.show()","9af1c7d5":"losses","4c855a92":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(len(test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:], [[current_pred]], axis = 1)","6188df94":"true_predictions = scaler.inverse_transform(test_predictions)","fb1e211e":"test['Predictions'] = true_predictions","577931bd":"test.head()","b65d747f":"test.plot(figsize = (10, 4))\nplt.show()","2a0a919b":"np.sqrt(mean_squared_error(test['Production'],test['Predictions']))","1bf69854":"full_scaler = MinMaxScaler()\nscaled_full_data = full_scaler.fit_transform(df)","725d89e2":"length = 12 # Length of the output sequences (in number of timesteps)\ngenerator = TimeseriesGenerator(scaled_full_data, scaled_full_data, length = length, batch_size = 1)","3d749675":"model = Sequential()\nmodel.add(LSTM(100, activation = 'relu', input_shape = (length, n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer = 'adam', loss = 'mse')\n\n\n# fit model\nmodel.fit_generator(generator, epochs = 8)","e2010e84":"forecast = []\n# Replace periods with whatever forecast length you want\nperiods = 12\n\nfirst_eval_batch = scaled_full_data[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(periods):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    forecast.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:], [[current_pred]], axis = 1)","168ad971":"forecast = scaler.inverse_transform(forecast)","20535b0a":"df","e3053936":"forecast_index = pd.date_range(start = '2019-10-01', periods = periods, freq = 'MS') #freq = 'MS' --> pandas frequency stings\n# https:\/\/stackoverflow.com\/questions\/35339139\/what-values-are-valid-in-pandas-freq-tags","c540de1f":"forecast_index","caf5c791":"forecast_df = pd.DataFrame(data = forecast,\n                           index = forecast_index,\n                           columns = ['Forecast'])","31d7f6b0":"forecast_df","5fd099ce":"fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 7))\n\naxes[0].plot(df, 'b')\n\naxes[1].plot(forecast_df, 'r')\n\n#labels\naxes[0].set_xlabel('Date')\naxes[0].set_title('Production')\n\naxes[1].set_xlabel('Date')\naxes[1].set_title('Forecast')\n\nplt.show()","f7a75e46":"ax = df.plot()\nforecast_df.plot(figsize = (15, 8), ax = ax)\nplt.show()","8be03fa0":"ax = df.plot()\nforecast_df.plot(figsize = (10, 6), ax = ax)\nplt.xlim('2018-01-01','2020-12-01\t')\nplt.show()","cd974c8e":"**Figure out the length of the data set**","0e88a3ee":"## Scale Data","69039c6c":"**Change the column name to Production**","ea7543ec":"**Creating new timestamp index with pandas**","4034db30":"**Joining Pandas Plot**","40bbedfb":"**Calculate your RMSE.**","6d0c1740":"**Plot your predictions versus the True test values. (Your plot may look different than ours).**","1413df20":"## Evaluate on Test Data\n\n**Forecast predictions for your test data range (the last 12 months of the entire dataset). Remember to inverse your scaling transformations. Your final result should be a DataFrame with two columns, the true test values and the predictions.**","10dffb39":"**Retrain & Forecasting**","21e8c6f3":"**IMPORT THE BASIC LIBRARIES YOU THINK YOU WILL USE**","eff25896":"### Create the Model\n\n**Create a Keras Sequential Model with as many LSTM units you want and a final Dense Layer.**","98ad2589":"**Create a generator for the scaled test\/validation set. NOTE: Double check that your batch length makes sense for the size of the test set**","9bd0af7a":"## Train Test Split","6dfe8310":"**Split the data into a train\/test split where the test set is the last 24 months of data.**","a1fce821":"## Data\n\nInfo about this data set: https:\/\/fred.stlouisfed.org\/series\/IPN31152N\n\n\nUnits:  Index 2012=100, Not Seasonally Adjusted\n\nFrequency:  Monthly\n\nThe industrial production (IP) index measures the real output of all relevant establishments located in the United States, regardless of their ownership, but not those located in U.S. territories.\n\nNAICS = 31152\n\nSource Code: IP.N31152.N\n\nSuggested Citation:\nBoard of Governors of the Federal Reserve System (US), Industrial Production: Nondurable Goods: Ice cream and frozen dessert [IPN31152N], retrieved from FRED, Federal Reserve Bank of St. Louis; https:\/\/fred.stlouisfed.org\/series\/IPN31152N, November 16, 2019.\n\n# Project Tasks\n\n**Read in the data set \"Frozen_Dessert_Production.csv\" from the Data folder. Figure out how to set the date to a datetime index columns**","a89d41a1":"**Fit the model to the generator, let the EarlyStopping dictate the amount of epochs, so feel free to set the parameter high.**","6b40532f":"**Use a MinMaxScaler to scale the train and test sets into scaled versions.**","d6c83853":"# Time Series Generator\n\n**Create a TimeSeriesGenerator object based off the scaled_train data. The batch length is up to you, but at a minimum it should be at least 18 to capture a full year seasonality.**","efa23aaa":"**Plot out the time series**","409c9ea6":"**Create an EarlyStopping callback based on val_loss.**","efd64cc5":"**Plot the history of the loss that occured during training.**"}}