{"cell_type":{"61d6386a":"code","c4bdb442":"code","64cc09d0":"code","0fa927f0":"code","a7809519":"code","38bb9d30":"code","132ea429":"code","f081179a":"code","1ab68861":"code","0b8eb8e9":"code","4b8a198f":"code","36c8ae2f":"code","59336f29":"code","0c319cc7":"code","cc5fe43f":"code","1346a164":"code","6ec26ad8":"code","7f72cdb8":"code","96fda945":"code","6cc63ab0":"code","196fa67b":"code","65231c13":"code","dca68393":"code","7b4aa5f1":"code","06b9656c":"code","a36f2afb":"markdown","fbd76273":"markdown","da7605c5":"markdown","db91c9b5":"markdown","ece0a211":"markdown","3cc00cb5":"markdown","9f45069e":"markdown","065bbd44":"markdown","e90f0fba":"markdown","a4ed7180":"markdown","351914c6":"markdown","f8f6e5d3":"markdown","6ff58af8":"markdown","508f8e43":"markdown","d50bfca7":"markdown"},"source":{"61d6386a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4bdb442":"! pip uninstall --y kaggle\n! pip install --upgrade pip\n! pip install kaggle==1.5.6\n\n","64cc09d0":"! mkdir -p ~\/.kaggle\n!cp kaggle.json ~\/.kaggle\/\n! chmod 600 ~\/.kaggle\/kaggle.json\n!kaggle -v","0fa927f0":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nfrom sklearn import preprocessing","a7809519":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","38bb9d30":"!kaggle competitions download -c solarenergy-meteorologicalphenomenon2","132ea429":"!unzip solarenergy-meteorologicalphenomenon2.zip","f081179a":"learning_rate = 1e-4\ntraining_epoches = 700\nbatch_size = 50\nScaler = preprocessing.StandardScaler()","1ab68861":"#train=pd.read_csv('\/kaggle\/input\/carclassification\/car5_train.csv')\ntrain = pd.read_csv('\/kaggle\/input\/solarenergy-meteorologicalphenomenon2\/Solar_TrainData_3.csv', header=None, skiprows=1, usecols=range(0,9))\ntrain = train.dropna()\ntrain","0b8eb8e9":"#\/kaggle\/input\/solarenergy-meteorologicalphenomenon2\/\ntest = pd.read_csv('\/kaggle\/input\/solarenergy-meteorologicalphenomenon2\/Solar_TestData_2.csv', header = None, skiprows=1,usecols=range(0,8))\n\ntest","4b8a198f":"x_train=train.loc[:,[i for i in train.keys()[1:-1]]]\ny_train=train[train.keys()[-1]]","36c8ae2f":"x_train","59336f29":"#x_train = train.loc[:,1:7]\n#y_train = train.loc[:,:8]\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\n\nx_train = torch.FloatTensor(x_train)\ny_train = torch.FloatTensor(y_train)","0c319cc7":"train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\ndata_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                          batch_size = batch_size,\n                                          shuffle = True,\n                                          drop_last=True)","cc5fe43f":"linear1 = torch.nn.Linear(7,32, bias = True) # feature\nlinear2 = torch.nn.Linear(32,32, bias = True)\nlinear3 = torch.nn.Linear(32,32, bias = True)\nlinear4 = torch.nn.Linear(32,16, bias = True)\nlinear5 = torch.nn.Linear(16,16, bias = True)\nlinear6 = torch.nn.Linear(16,16, bias = True)\nlinear7 = torch.nn.Linear(16,8, bias = True)\nlinear8 = torch.nn.Linear(8,8, bias = True)\nlinear9 = torch.nn.Linear(8,8, bias = True)\nlinear10 = torch.nn.Linear(8,1, bias = True)","1346a164":"torch.nn.init.kaiming_uniform_(linear1.weight)\ntorch.nn.init.kaiming_uniform_(linear2.weight)\ntorch.nn.init.kaiming_uniform_(linear3.weight)\ntorch.nn.init.kaiming_uniform_(linear4.weight)\ntorch.nn.init.kaiming_uniform_(linear5.weight)\ntorch.nn.init.kaiming_uniform_(linear6.weight)\ntorch.nn.init.kaiming_uniform_(linear7.weight)\ntorch.nn.init.kaiming_uniform_(linear8.weight)\ntorch.nn.init.kaiming_uniform_(linear9.weight)\ntorch.nn.init.kaiming_uniform_(linear10.weight)\nrelu=torch.nn.LeakyReLU()","6ec26ad8":"model = torch.nn.Sequential(linear1,relu,\n                            linear2,relu,\n                            linear3,relu,\n                            linear4,relu,\n                            linear5,relu,\n                            linear6,relu,\n                            linear7,relu,\n                            linear8,relu,\n                            linear9,relu,\n                            linear10).to(device)","7f72cdb8":"loss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","96fda945":"total_batch = len(data_loader)\n\nfor epoch in range(training_epoches):\n  avg_cost = 0\n\n  for X, Y in data_loader:\n\n    X = X.to(device)\n    Y = Y.to(device)\n\n    optimizer.zero_grad()\n    hypothesis = model(X)\n    cost = loss(hypothesis, Y)\n    cost.backward()\n    optimizer.step()\n\n    avg_cost += cost \/ total_batch\n  \n  print('Epoch:','%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\nprint('Learning finshed')","6cc63ab0":"with torch.no_grad():\n  x_test = test.loc[:,1:7]\n  x_test = np.array(x_test)\n\n  x_test = torch.from_numpy(x_test).float().to(device)\n\n  prediction = model(x_test)","196fa67b":"correct_prediction = prediction.cpu().numpy().reshape(-1,1)","65231c13":"submit = pd.read_csv('\/kaggle\/input\/solarenergy-meteorologicalphenomenon2\/Solar_SubmitForm_2.csv')\nsubmit","dca68393":"for i in range(len(correct_prediction)):\n  submit['Predict'][i] = correct_prediction[i].item()\n\nsubmit['YYYY\/MM\/DD'] = submit[0]\nsubmit","7b4aa5f1":"submit.to_csv('Sejeong.csv', mode='w', index = False)","06b9656c":"!kaggle competitions submit -c solarenergy-meteorologicalphenomenon2 -f Sejeong.csv -m \"Message\"","a36f2afb":"\ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c import\ud574\uc8fc\uc5c8\ub2e4.","fbd76273":"\ud544\uc694\ud55c \ud30c\ub77c\ubbf8\ud130\ub97c \uc124\uc815\ud574\uc8fc\uace0, \uc815\uaddc\ud654 scaler\ub97c \ub123\uc5b4\uc8fc\uc5c8\ub2e4. ","da7605c5":"\ubca0\uc774\uc2a4\ub77c\uc778\uc5d0 \ud65c\uc131\ud654\ud568\uc218\uac00 \ucca8\ubd80\ub418\uc5b4\uc788\uc9c0 \uc54a\uc544 \ud65c\uc131\ud654\ud568\uc218\ub97c \ub123\uc5b4\uc8fc\uc5b4 \uc815\ud655\ub3c4\ub97c \ub192\uc600\ub2e4.","db91c9b5":"cpu\ub97c gpu\ub85c \ubcc0\uacbd\ud574\uc8fc\uc5c8\ub2e4. ","ece0a211":"\ubca0\uc774\uc2a4\ub77c\uc778 \ucf54\ub4dc\uc5d0\uc11c\ub294 xavier\ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uc600\ub294\ub370 kaiming_unform\uc744 \uc0ac\uc6a9\ud588\ub2e4. ","3cc00cb5":"\uce90\uae00\uc5d0\uc11c data\ub97c \ub2e4\uc6b4\ubc1b\uace0 \uc555\ucd95\uc744 \ud480\uc5b4\uc92c\ub2e4. ","9f45069e":"\uc190\uc2e4\ud568\uc218\uc640 \ucd5c\uc801\ud654 \ud568\uc218\ub97c \ubd88\ub7ec\uc654\ub2e4. ","065bbd44":"\ud2b8\ub808\uc778\uacfc \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc654\ub2e4. ","e90f0fba":"\ub808\uc774\uc5b4\ub294 \ubcf8 \ubca0\uc774\uc2a4\ub77c\uc778\ucf54\ub4dc\uc640 \uac19\uc774 10\uac1c\ub85c \uc124\uc815\ud574\uc8fc\uc5c8\ub2e4. ","a4ed7180":"\ub370\uc774\ud130\ub97c \ud559\uc2b5\uc2dc\ud0a8\ub2e4.","351914c6":"\ud2b8\ub808\uc778\uacfc \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \ubc94\uc704\ub97c \uc124\uc815\ud574\uc8fc\uace0 pd->numpy-> torch\ub85c data\ub97c \ubcc0\uacbd\ud574\uc8fc\uc5c8\ub2e4. ","f8f6e5d3":"submit \ud30c\uc77c\uc744 \ubd88\ub7ec\uc628\ub2e4. ","6ff58af8":"\uce90\uae00\uc744 \uc7ac\uc124\uce58\ud574\uc8fc\uace0 kaggle.json\uc744 \ubd88\ub7ec\uc654\ub2e4. ","508f8e43":"\ud14c\uc2a4\ud2b8\ub370\uc774\ud130\ub97c \ub3cc\ub824\uc900\ub2e4. ","d50bfca7":"\uc815\ud655\ub3d9\ub97c \ub354 \ub192\uc774\uae30 \uc704\ud574 \ubcf8 \ubca0\uc774\uc2a4\ub77c\uc778\uc5d0\ub294 \ud65c\uc131\ud568\uc218\uac00 \uc5c6\uc5c8\ub294\ub370 \nLeaky ReLu\ub97c \uc124\uc815\ud574\uc8fc\uc5c8\ub2e4. "}}