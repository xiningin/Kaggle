{"cell_type":{"e3ed497f":"code","ded7f6f8":"code","f849ebe8":"code","3cc4b76c":"code","455ff567":"code","b9171617":"code","38c247f2":"code","c624f4d7":"code","aef526bf":"code","78a9c436":"code","73285968":"code","c3634407":"code","029762c5":"markdown","3304c0dc":"markdown","c266a25c":"markdown","264df479":"markdown","2ea4309e":"markdown","f0c87513":"markdown","fc797816":"markdown","c530a329":"markdown","1b8f8736":"markdown","a839b8a1":"markdown","75f95c7d":"markdown","a162d44f":"markdown","c57417a9":"markdown","1e5b7bb4":"markdown","5c59cb3e":"markdown","09133d45":"markdown"},"source":{"e3ed497f":"!pip install pydotplus\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom IPython.display import Image, display_png\nfrom pydotplus import graph_from_dot_data\nfrom sklearn.tree import export_graphviz\nfrom sklearn import manifold\nimport folium\nfrom pyproj import Proj, transform","ded7f6f8":"df = pd.read_csv('..\/input\/whisky.csv')\ndf.head()","f849ebe8":"df.info()","3cc4b76c":"df.describe()","455ff567":"dist = []\n\nfor i in range(2,20):\n    km = KMeans(n_clusters = i, n_init=10, max_iter = 500, random_state =0)\n    km.fit(df.iloc[:, 2:-3])\n    dist.append(km.inertia_)\n    \nplt.plot(range(2,20),dist)\nplt.show()","b9171617":"km = KMeans(n_clusters = 5, n_init=10, max_iter = 300, random_state =0)\ndf['class'] = km.fit_predict(df.iloc[:, 2:-3])\ndf['class'].values","38c247f2":"mds = manifold.MDS(n_components=2, dissimilarity=\"euclidean\", random_state=0)\npos = mds.fit_transform(df.iloc[:, 2:-4])\n\ncol =['orange','green', 'blue', 'purple', 'red']\nchars = \"^<>vo+d\"\nc_flag = 0\nlabels = df['Distillery']\n\nplt.figure(figsize=(20, 20), dpi=50)\nplt.rcParams[\"font.size\"] = 15\n\nfor label, x, y, c in zip(labels, pos[:, 0], pos[:, 1],df['class']):\n\n    if(c == c_flag):\n        c_flag = c_flag+1\n        plt.scatter(x,y, c=col[c], marker=chars[c], s=100, label = \"Class \"+ str(c+1))\n    else:\n        plt.scatter(x,y, c=col[c], marker=chars[c], s=100)\n        \n    plt.annotate(label,xy = (x, y))\nplt.legend(loc='upper right')\nplt.show()","c624f4d7":"df.query('Distillery == \"GlenSpey\" or Distillery == \"Miltonduff\"')","aef526bf":"df.query('Distillery == \"GlenSpey\" or Distillery == \"Glendronach\"')","78a9c436":"tree = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state =1, min_samples_leaf=5)\n\nX_train = df.iloc[:, 2:-4]\ny_train = df['class']\n\ntree.fit(X_train, y_train)","73285968":"dot_data = export_graphviz(tree, filled = True, rounded = True, class_names = ['Class 1','Class 2', 'Class 3', 'Class 4', 'Class 5'],\n                          feature_names = df.columns[2:-4].values, out_file = None)\n\ngraph = graph_from_dot_data(dot_data)\ngraph.write_png('tree.png')\ndisplay_png(Image('tree.png'))","c3634407":"map_whisky = folium.Map(location=[57.499520,  -2.776390], zoom_start = 9)\n\ninProj = Proj(init='epsg:27700')\noutProj = Proj(init='epsg:4326')\n\nfor label, lon, lat, c in zip(labels, df['Latitude'], df['Longitude'], df['class']):\n    \n    lat2,lon2 = transform(inProj,outProj,lon,lat)\n    folium.Marker([lon2, lat2], popup= label, icon=folium.Icon(color=col[c])).add_to(map_whisky)\n\nmap_whisky","029762c5":"The difference in absolute values between the attributes of these two distilleries is 7. It seems that Miltonduff is a bit more sweet, honey and fruity than GlenSpey.\n\nThen let's compare the tastes in different class. Here we see GlenSpey in class 1 and Glendronach in class 4.","3304c0dc":"Here we can see that the distilleries within the same class position closely.\n\nLet's see how close the whisky tastes within the same class. Here we compare GlenSpey and Miltonduff in Class 1.","c266a25c":"## 3. Identify the characteristics of tastes using decision tree\n\nHere we use decision tree to identy the characteristics of whisky tastes in each class using decision tree.\n\n#### Calculate decision tree","264df479":"Here we do not have any outstanding elbows. Maybe we can use k=5.\n\n#### Conduct k-means classification\n\nHere we conduct k-means classification with k=5.","2ea4309e":"#### Map the distilleries onto 2D plane\n\nHere we map the distilleries with their class information onto 2D plane taking into account their \"distance\" in flavors. We use MDS (Multidimensional Scaling) library in scikit-learn.","f0c87513":"#### Check the statistics","fc797816":"We can see that we can use the attributes related to taste (body, sweetness, smoky, medicinal, tabacco, honey, picy, winey, nutty, malty, fruity, floral) to find out the similarity of whisky.","c530a329":"## Similar taste? Different taste?\n\nI love whisky. I want to enjoy a variety of whisky tastes. But it is dissapointing if I order several kinds of whisky and all of them taste almost the same. So, I decided to identify the difference between whisky distilleries before getting tipsy.\n\n#### Strategy\n- Classify distilleries based on flavor of their whisky using k-means clustering.\n- Identify the characteristics of whisky (distilleries) using decision tree.\n- Map the location of distilleries in each class.\n\n#### Reference\nSebastian Raschka and Vahid Mirjalili, Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow, 2nd Edition. (Capter 3: A Tour of Machine Learning Classifiers Using scikit-learn, Capter 11: Working with Unlabeled Data - Clustering Analyis)\n\n## 1. Data preparation\n\n#### Load libraries.","1b8f8736":"## 4. Map the locations of distilleries\n\nHere we mark the the locations of distilleries onto a map. Here we use position infomation (latitude and longitude) in the dataset. We also change the color of marker by their class.\n\nNote that the values of latitude and longitude in the data are not in degree. They are in United Kingdom Coordinate System (EPSG 27700). Therefore, we need to transform them into World Coordinate System (WGS84 (EPSG4326)).","a839b8a1":"## 2. k-means clustering\n\nHere we classify distilleries based on the flavors of their whisky using k-means clustering.\n\n#### Determine the number of cluster\n\nFirst, we identify appropriate number of clusters by using elbow method. Here we perform k-means clustering with changing the number of clusters (k). Then we find the optimal k where the inertia of k-means decreases rapidly.","75f95c7d":"#### Visualize the derived decision tree","a162d44f":"## 5. Conlcusion\n\nWe identified the similarity\/difference of whisky tastes derived by k-means clustering and decision tree analysis. I think this result is quite helpful for you to choose the whisky you will like. But my analysis might have some flaws. The only way to make sure my analysis is correct must be visiting Scotland and tasting all of them by myself ;-).","c57417a9":"The difference in absolute values between the attributes of these two distilleries is 15. It is quite larger than the comparison between GlenSpey and Miltonduff. So I believe that Glendronarch tastes much body, honey, winey and fruity than GlenSpey.","1e5b7bb4":"#### Interpretation of the tree\n\nFrom the above decision tree, we can see the characteristics of whisky tastes in each class.\n\n- Class 1: Most of them are floral and less winey.\n- Class 2: Less floral, more body.\n- Class 3: Floral, winey and body (strong tastes?).\n- Class 4: There are only five of them. Three of them are less floral, more body and less medicinal. The remainings are close to Class 3. \n- Class 5: Most of them are less floral and less body (lighter tastes?).\n","5c59cb3e":"Now we can see the location of distilleries for each class. By clicking the markers, you can see the name of distilleries.","09133d45":"#### Load data and check the attributes."}}