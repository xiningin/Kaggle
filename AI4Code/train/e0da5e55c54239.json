{"cell_type":{"04dec589":"code","ebc80522":"code","787871f9":"code","a9a63b1e":"code","f14288cf":"code","9478efc8":"code","ef8e3783":"code","37ccdb70":"code","955aa94b":"code","4b9efc28":"code","06057eb4":"code","68201501":"code","274c6625":"code","071b9b7e":"code","00d622df":"code","8edad1e9":"code","a4a993bc":"code","c7acfe9c":"code","dc95e308":"code","1134c614":"code","17b27362":"code","9dba31e0":"code","c25f55f0":"code","106adb3c":"code","da60fbdc":"code","2fafad67":"code","37ca200b":"code","ca2a1fe6":"code","9703a7e0":"code","f6b2ff76":"code","f8453c1a":"markdown","73c5f8b3":"markdown","fe5fd444":"markdown","a9c0622e":"markdown","927a3f9f":"markdown","ce14bd97":"markdown","ca1fbf7a":"markdown","794b7c54":"markdown","988c6e1e":"markdown","b0f267ab":"markdown","c3a814ad":"markdown","34e61788":"markdown","30b9e2e7":"markdown","610bad68":"markdown","7bcddafd":"markdown","5457fc70":"markdown","b0c38e66":"markdown","42d5a58f":"markdown","d296a095":"markdown","a4c205d9":"markdown","6b16051b":"markdown","a74ac40a":"markdown","7d837100":"markdown","e5cd58a1":"markdown","ee17863a":"markdown","320f830f":"markdown","38bafb61":"markdown","0f8381b4":"markdown","8349f64b":"markdown","235b39d9":"markdown","bbdcb5b5":"markdown","2309e206":"markdown","ac2a94fa":"markdown","216d3ad0":"markdown","9e031010":"markdown","9e869985":"markdown","3815ab46":"markdown","09b6b0c1":"markdown","32541b99":"markdown","9730a6a6":"markdown","2c03856d":"markdown","a0ecd047":"markdown","776301a8":"markdown","bce49eef":"markdown","0fdeb51c":"markdown","daac83d0":"markdown","40762776":"markdown"},"source":{"04dec589":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\n","ebc80522":"from fastai import *\nfrom fastai.vision import *\n\n# useful paths\ninput_path = Path('\/kaggle\/input') \ncovid_xray_path = input_path\/'xray-covid'\npneumonia_path = input_path\/'chest-xray-pneumonia\/chest_xray'\n\ncovid_df = pd.read_csv(covid_xray_path\/'metadata.csv')\ncovid_df.head()","787871f9":"covid_df.dropna(axis=1,inplace=True)\ncovid_df","a9a63b1e":"covid_df.groupby('view').count()","f14288cf":"covid_df.groupby('finding').count()","9478efc8":"covid_df = covid_df[lambda x: x['view'] == 'PA']\ncovid_df","ef8e3783":"covid_df['finding'] = covid_df['finding'].apply(lambda x:'positive' if x == 'COVID-19' else 'negative')\ncovid_df","37ccdb70":"def makeFilename(x = ''):\n    return input_path\/f'xray-covid\/images\/{x}'\n\ncovid_df['filename'] = covid_df['filename'].apply(makeFilename)\ncovid_df = covid_df[['finding', 'filename']]\ncovid_df","955aa94b":"\npneumonia_df = pd.DataFrame([], columns=['finding', 'filename'])\nfolders = ['train\/NORMAL', 'val\/NORMAL', 'test\/NORMAL']\nfor folder in folders:\n    fnames = get_image_files(pneumonia_path\/folder)\n    fnames = map(lambda x: ['negative', x], fnames)\n    df = pd.DataFrame(fnames, columns=['finding', 'filename'])\n    pneumonia_df = pneumonia_df.append(df, ignore_index = True)\n\n\n\nfolders = ['train\/PNEUMONIA', 'val\/PNEUMONIA', 'test\/PNEUMONIA']\nfor folder in folders:\n    fnames = get_image_files(pneumonia_path\/folder)\n    fnames = map(lambda x: ['negative', x], fnames)\n    df = pd.DataFrame(fnames, columns=['finding', 'filename'])\n    pneumonia_df = pneumonia_df.append(df, ignore_index = True)\n\npneumonia_df.info()","4b9efc28":"\nhealthy_df = pd.DataFrame([], columns=['finding', 'filename'])\nfolders = ['train\/NORMAL', 'val\/NORMAL', 'test\/NORMAL']\nfor folder in folders:\n    fnames = get_image_files(pneumonia_path\/folder)\n    fnames = map(lambda x: ['negative', x], fnames)\n    df = pd.DataFrame(fnames, columns=['finding', 'filename'])\n    healthy_df = healthy_df.append(df, ignore_index = True)\n    \npneumonia_df = pd.DataFrame([], columns=['finding', 'filename'])\nfolders = ['train\/PNEUMONIA', 'val\/PNEUMONIA', 'test\/PNEUMONIA']\nfor folder in folders:\n    fnames = get_image_files(pneumonia_path\/folder)\n    fnames = map(lambda x: ['negative', x], fnames)\n    df = pd.DataFrame(fnames, columns=['finding', 'filename'])\n    pneumonia_df = pneumonia_df.append(df, ignore_index = True)\n\npneumonia_df = pneumonia_df.sample(covid_df.shape[0]).reset_index(drop=True)\n\nhealthy_df = healthy_df.sample(covid_df.shape[0]).reset_index(drop=True)\n\nnegative_df = healthy_df.append(pneumonia_df, ignore_index = True)\n\nnegative_df.head()","06057eb4":"df = covid_df.append(healthy_df, ignore_index = True)\ndf = df.sample(frac=1).reset_index(drop=True)\ndf.sample(20)\n","68201501":"np.random.seed(42)\ndata = ImageDataBunch.from_df(\n        '\/', \n        df, \n        fn_col='filename',\n        label_col='finding',\n        ds_tfms=get_transforms(), ## data augmentation: flip horizozntally\n        size=224, \n        num_workers=4\n    ).normalize(imagenet_stats)\n\ndata\n","274c6625":"data.show_batch(rows=80, figsize=(21,21))","071b9b7e":"learn = cnn_learner(data, models.resnet50, metrics=error_rate)","00d622df":"learn.fit_one_cycle(10)","8edad1e9":"learn.fit_one_cycle(10)","a4a993bc":"learn.save('stage-1')","c7acfe9c":"df2 = covid_df.append(pneumonia_df, ignore_index = True)\ndf2 = df2.sample(frac=1).reset_index(drop=True)\nnp.random.seed(42)\ndata2 = ImageDataBunch.from_df(\n        '\/', \n        df2, \n        fn_col='filename',\n        label_col='finding',\n        ds_tfms=get_transforms(), ## data augmentation: flip horizozntally\n        size=224, \n        num_workers=4\n    ).normalize(imagenet_stats)\n\nlearn2 = cnn_learner(data2, models.resnet50, metrics=error_rate)\nlearn2.fit_one_cycle(10)","dc95e308":"learn2.fit_one_cycle(10)","1134c614":"learn2.fit_one_cycle(10)","17b27362":"learn2.save('learn2-stage-1')\n","9dba31e0":"learn.load('stage-1')\nlearn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot()","c25f55f0":"learn.fit_one_cycle(10, max_lr=slice(7e-5,2e-4))","106adb3c":"learn.save('stage-2')","da60fbdc":"learn.fit_one_cycle(2, max_lr=slice(7e-5,2e-4))","2fafad67":"learn.load('stage-2')\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","37ca200b":"learn2.load('learn2-stage-1')\nlearn2.unfreeze()\nlearn2.lr_find()\nlearn2.recorder.plot()\n","ca2a1fe6":"learn2.load('learn2-stage-1')\nlearn2.unfreeze()\nlearn2.fit_one_cycle(4, max_lr=slice(7e-5,1e-4))","9703a7e0":"learn2.save('learn2-stage-2')","f6b2ff76":"# learn = cnn_learner(data, models.resnet50, metrics=error_rate)\n# learn.load('stage-3')\n# interp = ClassificationInterpretation.from_learner(learn)\nimg = open_image(input_path\/'test-img\/df1053d3e8896b53ef140773e10e26_gallery.jpeg')\nlearn.predict(img)","f8453c1a":"To my untrained eyes, it looks like the images look consistent. We are going to use a resnet50 and leverage Kaggle free GPU Quota. Let's start training ten cycles.","73c5f8b3":"But first let's import necessary libraries","fe5fd444":"As you can see we have 5856 pictures which is about 60 times larger than our covid_df.  \n\nSince we have 92 pictures in our covid_df, I decided to take an equal number of pictures of healthy patients and an equal number of picture of pneumonia patients. In other words, 92 covid_df images, 92 healthy patient images, and 92 pneumonia affected patients. As far as our analysis goes, we are really only interested in covid positive and covid negative. Therefore, both the healthy and pneumonia patients will be labeled as ```negative```","a9c0622e":"## Second case: COVID-19 patients and pneumonia patients","927a3f9f":"It looks good. We are going to keep the 5.5% error for now and try the next data frame\n","ce14bd97":"## First case: COVID-19 patients and healthy patients","ca1fbf7a":"Let's import Fastai, create useful paths and create covid_df","794b7c54":"## COVID-19-xray\n","988c6e1e":"The standard COVID-19 tests are called PCR (Polymerase chain reaction) tests. This family of tests looks for the existence of antibodies of a given infection. Two main issues with this test are:\n\n1. a shortage a tests available worldwide\n2. a patient might be carring the virus without having symptoms. In this case the test fails to identify infected patients","b0f267ab":"[Dr. Joseph Paul Cohen, Postdoctoral Fellow at University of Montreal](https:\/\/josephpcohen.com\/w\/), recently open sourced a [database](https:\/\/github.com\/ieee8023\/covid-chestxray-dataset) containing chest x-ray pictures of patients suffering from the COVID-19 disease. \nAs soon as I found this out, I decided to put in practice what I have learned during the first two weeks of the [Fastai's DL course](https:\/\/course.fast.ai\/) and to build a classifier to predict from a chest x-ray scan wether or not a patient has the virus.","c3a814ad":"## Second case: COVID-19 patients and pneumonia patients","34e61788":"We now need to create a dataframe of the same format using the pictures from the other database. Once we have that dataframe, we can use the mighty [ImageDataBunch](https:\/\/docs.fast.ai\/vision.data.html) methods to create a dataset that we can feed to our convolutional network.  \n\nSince our second database is made up of pictures of both healthy patients and pneumonia suffering patients, we are going to take an equal mix of both. I tried using only images of healthy people from this database but I reflected that since COVID-19 and pneumonia are linked somehow then it might give our network an edge to also contain pneumonia x-rays.\n\nThis is what our ```pneumonia_df``` looks like:","30b9e2e7":"# 1. Data Preparation","610bad68":"NB: Following great suggestions, I received, I am gonna run the Convolutional Net on two dataBunch:\n\n- The first will have covid_df and healthy_df\n- The second one will have covid_df and pneumonia_df\n\nWe will then compare the perfomances and, hopefully, we will get comparable results so that we can have more confidence in our results.\n","7bcddafd":"Disclaimer: I am not a doctor nor a medical researcher. This work is only intended as a source of inspiration for further studies.","5457fc70":"That looks better. We are mainly interested in two columns: ```finding``` and ```filename```. The former tells us wether or not a patient is suffering from the virus whereas the latter tells us the finename. The other interesting column is ```view```. It turns out the view is the angle used when the scan is taken and the most frequently used is PA. PA view stands for Posteroanterior view.","b0c38e66":"Since the error rate is 0, the confusion matrix shows we have no errors.","42d5a58f":"Let's first fit 10 cycles and see how it improves","d296a095":"# Test","a4c205d9":"# Using Deep Learning to detect COVID-19 presence from x-ray scans","6b16051b":"# What's next?","a74ac40a":"Let's run some more cycles","7d837100":"# 3. Optmize","e5cd58a1":"That image is taken from https:\/\/radiopaedia.org\/images\/52197348 and it is an image of a positive patient.","ee17863a":"For simplicity, let's also rename the elements in column ```finding``` to be ```positive``` if the patient is suffering from COVID-19 and negative otherwise.","320f830f":"Now, we can finally merge our dataframes to get the dataframe needed to build our [ImageDataBunch](https:\/\/docs.fast.ai\/vision.data.html).","38bafb61":"## First case: COVID-19 patients and healthy patients","0f8381b4":"We notice straight away that we have a large number of NaN, let's remove them and see what we are left with","8349f64b":"That's a nice error rate. Let's save ```learn2``` and starti optimizing","235b39d9":"Looks like we can do better, let's run ten cycles more.","bbdcb5b5":"First of all, I would like to incorporate scans from other sources and see if accuracy and generalization might increase.\nToday, while I was about to pusblish this article, I found out that [MIT](https:\/\/www.technologyreview.com\/s\/615399\/coronavirus-neural-network-can-help-spot-covid-19-in-chest-x-ray-pneumonia\/) has released a database containing xrays images of covid patients. Next, I am going to incorporate MIT's database and see where we get.","2309e206":"Both cases have an error rate < 3%. Given the scarsity of data, this is a promising first result. Since using both models, covid-19 prediction seems to be consistent, we can be confident enough in its predictions.","ac2a94fa":"I obtained the 0% error rate after a updated my notebook on kaggle and used a balanced dataset. This error rate though, is probably due to the fact that I am still collecting data and would require much more images to have an more stable error rate.","216d3ad0":"Looks like the error rate is not really moving. With 3.6% error rate we might be satisfied with this first results. We are going to save and plot the confusion matrix.","9e031010":"I am going to run the Convolutional Net using two training sets.\nThe first will have  covid_df and healthy_df\nThe second one will have covid_df and pneumonia_df\n\nWe will then compare the perfomances and, hopefully, we will get comparable results so that we can have more confidence in our results.","9e869985":"The more the pandemic crisis progresses, the more it gets important that countries perform tests to help understand and stop the spread of COVID-19.\nUnfortunately, the capacity for COVID-19 testing is still low in many countries. ","3815ab46":"Let's take random images from ```data``` to see if they look consistent.","09b6b0c1":"The database only contains pictures of patients suffering from COVID-19. In order to build a classifier for xray images we first need to find similar x-ray images of people who are not suffering from the disease.\nIt turns out Kaggle has a database with chest x-ray images of patients suffering of pneumonia and healthy patients. Hence, we are going to use both sources images in our dataset.\n","32541b99":"### How are tests performed?","9730a6a6":"# 2. Train Network using Fastai","2c03856d":"We are now ready to create the ImageDataBunch.","a0ecd047":"The notebook is organized as follows:\n\n1. Data Preparation  \n\n2. Train Network using Fastai\n\n3. Optimize Network\n\n4. Test\n\n5. What's Next","776301a8":"PA makes up the majority of the datapoints. Let's keep them and remove the rest.","bce49eef":"Results for the first case were already pretty solid in **Part 2**. We are going to first optimize the results for the first case and then optimize results for the second case. Then, if the two cases accuracy do not differ too much, we will be confident in our result and try to predict random images online.","0fdeb51c":"Finally, let's replace the ```filename``` column by the entire system path and keep only the two columns we are more interested in","daac83d0":" The longest downward shape is found in the region around ```1e-4``` let's use that as our starting point","40762776":" The longest downward shape is found in the region around ???????????```1e-4``` let's use that as our starting point"}}