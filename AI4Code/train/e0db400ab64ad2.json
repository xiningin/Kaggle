{"cell_type":{"06d01c6c":"code","322babcd":"code","c3eff430":"code","80ac3a0a":"code","1d7d0656":"code","867b9fd8":"code","736aaf4b":"code","467096e3":"code","6eababce":"code","05acefcd":"code","0481033a":"code","2712db96":"code","cd79fc2d":"code","0cf7fb11":"markdown","3453b239":"markdown","e236964c":"markdown","e6071337":"markdown","14aa8d75":"markdown","346a3b60":"markdown","033ca4bc":"markdown"},"source":{"06d01c6c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","322babcd":"from sklearn.datasets import load_iris","c3eff430":"iris = load_iris()\n#print('Printing iris dataset',iris)","80ac3a0a":"data = iris.data\nfeature = iris.feature_names\ndf = pd.DataFrame(data,columns = feature)\nprint(df.head())\ntarget = iris.target\nprint('\\n\\n target',target)\ntarget_names = iris.target_names\nprint('\\n\\ntarget names',target_names)","1d7d0656":"import seaborn as sns\n%matplotlib inline","867b9fd8":"df['target']  = target\ndf['Species'] = target_names[target]\ndf.head()\n# now we can visualize data ","736aaf4b":"sns.pairplot(df,hue = 'Species',height = 2)","467096e3":"from sklearn.model_selection import train_test_split\n\ntrain_data,test_data,train_target,test_target = train_test_split(data,target,test_size = 0.3,random_state = 1)\nprint('train data shape',train_data.shape)\nprint('test data shape',test_data.shape)\nprint('train target data',train_target.shape)\nprint('test target data',test_target.shape)\nprint(test_data[:3])","6eababce":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nclassifier  =  KNeighborsClassifier(n_neighbors=3)\nkn_model = classifier.fit(train_data,train_target)\nspecies_pred = kn_model.predict(train_data)\nprint(species_pred)\n\n## checking accuracy score\naccuracy_score = metrics.accuracy_score(train_target,species_pred)\nprint('Accuracy score =',accuracy_score)","05acefcd":"## now we give sample to the model\nsample = [[1,5,6,3],[4,2,8,9],[2,8,9,3]]\nsample_pred = kn_model.predict(sample)\nfor i in sample_pred:\n    print(f'Species name for given sample is ',target_names[i] )\n","0481033a":"test_pred = kn_model.predict(test_data)\naccuracy = metrics.accuracy_score(test_target,test_pred)\nprint('Accuracy score =',accuracy)","2712db96":"new_data = [[1,2,1,2],[4.7,3.2,1.3,0.2],[1,2,5,1],[3,2,6,3],[4,2,5,4],[5,3,6,2.1]]\ndf1 = pd.DataFrame(new_data,columns = feature)\nnew_pred = kn_model.predict(new_data)\nprint(new_data)\nprint(target_names[new_pred])\ndf1['species'] = target_names[new_pred]\ndf1","cd79fc2d":"sns.pairplot(df1,hue='species')","0cf7fb11":"## Visualization of data for species","3453b239":"### Spliting Data For Training and Testing ","e236964c":"### Converting iris dataset to dataframe","e6071337":"## Training the model ","14aa8d75":"## Testing the model","346a3b60":"## For visualizing we have to join species to dataframe ","033ca4bc":"### Loading iris dataset"}}