{"cell_type":{"c1dd1196":"code","c46e7841":"code","d36677a1":"code","65d60326":"code","f6762bef":"code","504b0a1c":"code","8d8cdaae":"code","78a50dff":"code","4c66267b":"code","a9be6ca3":"code","051a4b5b":"code","14cb6f39":"code","8a222694":"code","99e56297":"code","14ba629f":"code","7c23af4e":"code","14a97f52":"code","98e486e1":"code","4806e10e":"code","bcf0408b":"code","8b742d93":"code","68ea3bdf":"code","f353d08c":"code","b16e0a4a":"code","befc8e8d":"code","91d9f395":"code","5cdd4778":"code","1089c022":"code","0042c332":"code","606bcd1a":"code","4cf3b18e":"code","e302808b":"code","3e4595c3":"code","cd259d7a":"code","eea971d3":"code","5e24b68a":"code","f89c25a6":"code","db082cca":"code","a8a79da1":"code","5faf1661":"code","2943dad9":"code","40b7ecf2":"code","d1ffa4e3":"code","df895cc7":"code","ca4c7c34":"code","8d55f60e":"code","dfd50f70":"code","5da786d9":"markdown","35448637":"markdown","ce6a2ff1":"markdown","132816dc":"markdown"},"source":{"c1dd1196":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nplt.style.use(\"ggplot\") # to make the plots to look nicer","c46e7841":"train_df = pd.read_csv(\"..\/input\/rossmann-data\/train.csv\")\n#test_df = pd.read_csv(\"..\/input\/prayasys\/test.csv\")\nstore_df = pd.read_csv(\"..\/input\/rossmann-data\/store.csv\")","d36677a1":"train_df.info()","65d60326":"store_df.info()","f6762bef":"opened_sales = (train_df[(train_df.Open == 1) & (train_df.Sales)]) #if the stores are opend\nopened_sales.Sales.describe()","504b0a1c":"opened_sales","8d8cdaae":"f, ax = plt.subplots(1,2, figsize = (20, 5))\n\nopened_sales.Sales.plot(kind = \"hist\", title = \"Sales Histogram\", bins = 25, ax = ax[0])\nopened_sales.Sales.plot.box(title = \"Sales Boxplot\", ax = ax[1])","78a50dff":"print(\"Rossmann has\", round(opened_sales.Sales[(opened_sales.Sales > 10000)].count() \/ opened_sales.shape[0] * 100, 4), \n      \"% of the time big sales, over 10,000 Euros\")\nprint(\"Rossmann has\", round(opened_sales.Sales[(opened_sales.Sales < 1000)].count() \/ opened_sales.shape[0] * 100, 4), \n      \"% of the time low sales, under 1000 Euros\")","4c66267b":"train_df.Customers.describe()\n","a9be6ca3":"f, ax = plt.subplots(1,2, figsize = (20, 5))\n\ntrain_df.Customers.plot(kind = \"hist\", title = \"Customers Histogram\", bins = 20, ax = ax[0])\ntrain_df.Customers.plot.box(title = \"Sales Boxplot\", ax = ax[1])","051a4b5b":"print(\"In 3 years, different stores were\", train_df[(train_df.Open == 0)].count()[0], \"times closed out of\", train_df.shape[0], \"times.\")\n\nprint(\"From these days,\", train_df[(train_df.Open == 0) & \n         ((train_df.StateHoliday == \"a\") | \n         (train_df.StateHoliday == \"b\") | \n         (train_df.StateHoliday == \"c\"))].count()[0], \"times the stores were closed because of holidays\")\n\nprint(train_df[(train_df.Open == 0) & (train_df.SchoolHoliday == 1)].count()[0], \"times, some stores were closed because of school holiday\")\nprint(\"The stores which were open on sundays ->\", train_df[(train_df.Open == 1) & (train_df.DayOfWeek == 7)].count()[0], \"times\")\nprint(\"However,\", train_df[(train_df.Open == 0) & ((train_df.StateHoliday == \"0\") | (train_df.StateHoliday == 0)) & (train_df.SchoolHoliday == 0)].count()[0], \"times, the stores were closed for no reason (No Holidays or Sunday)\")","14cb6f39":"print(round((train_df.Promo[train_df.Promo == 1].count() \/ train_df.shape[0] * 100), 3), \"% of the time, promotions have been made\")\n","8a222694":"# StateHoliday is not a continous number. \ntrain_df.StateHoliday.value_counts()","99e56297":"# StateHoliday is a string and for us it is not so important to know what kind of holiday (a, b or c). We will convert it into 0 and 1, by creating a new variable\ntrain_df[\"StateHoliday_cat\"] = train_df[\"StateHoliday\"].map({0:0, \"0\": 0, \"a\": 1, \"b\": 1, \"c\": 1})\ntrain_df.StateHoliday_cat.count()","14ba629f":"# lets get rid of the StateHoliday column and use only the new one\ntrain_df = train_df.drop(\"StateHoliday\", axis = 1)\ntrain_df.tail()","7c23af4e":"#lets delete the times, where the stores were opened with no sales because of days in inventory.\ntrain_df = train_df.drop(train_df[(train_df.Open == 0) & (train_df.Sales == 0)].index)\ntrain_df = train_df.reset_index(drop = True) # to get the indexes back to 0, 1, 2,etc.\n\ntrain_df.isnull().all() #to check for NaNs","14a97f52":"store_df.head().append(store_df.tail())","98e486e1":"#how may missing data do we have in %:\n100- (store_df.count() \/ store_df.shape[0] * 100)","4806e10e":"store_df.info()\n","bcf0408b":"store_df.CompetitionDistance.plot.box() #let me see the outliers, so we can choose between mean and median to fill the NaNs\nprint(\"the median is\", store_df.CompetitionDistance.median(), \"and mean is\", store_df.CompetitionDistance.mean())","8b742d93":"print(\"Since we have here some outlier, its better to input the median value to those few missing values.\")\nstore_df[\"CompetitionDistance\"].fillna(store_df[\"CompetitionDistance\"].median(), inplace = True)","68ea3bdf":"#The missing values, are not there, because the stores had no competition. So I would suggest to fill the missing values with zeros.\nstore_df[\"CompetitionOpenSinceMonth\"].fillna(0, inplace = True)\nstore_df[\"CompetitionOpenSinceYear\"].fillna(0, inplace = True)\n\n#both the columns are categorical","f353d08c":"store_df.groupby(by = \"Promo2\", axis = 0).count()\n","b16e0a4a":"print(\"Promo2 was running in {} stores\".format(len(store_df[store_df['Promo2']==1])))","befc8e8d":"# so if no promo has been made, then we should replace the NaN from Promo since Week and Year with zero\nstore_df[\"Promo2SinceWeek\"].fillna(0, inplace = True)\nstore_df[\"Promo2SinceYear\"].fillna(0, inplace = True)\nstore_df[\"PromoInterval\"].fillna(0, inplace = True)\n\nstore_df.info()","91d9f395":"#Now there are no null values in our store dataframe as well. Let us join these 2 to get better information.\n\ntrain_store_df = pd.merge(train_df, store_df, how = \"left\", on = \"Store\")\ntrain_store_df.info()","5cdd4778":"train_store_df[\"Avg_Customer_Sales\"] = train_store_df.Sales \/ train_store_df.Customers\ntrain_store_df.to_csv('train_store_df.csv', index = False)","1089c022":"f, ax = plt.subplots(2, 3, figsize = (20,10))\n\nstore_df.groupby(\"StoreType\")[\"Store\"].count().plot(kind = \"bar\", ax = ax[0, 0], title = \"Total StoreTypes in the Dataset\")\ntrain_store_df.groupby(\"StoreType\")[\"Sales\"].sum().plot(kind = \"bar\", ax = ax[0,1], title = \"Total Sales of the StoreTypes\")\ntrain_store_df.groupby(\"StoreType\")[\"Customers\"].sum().plot(kind = \"bar\", ax = ax[0,2], title = \"Total nr Customers of the StoreTypes\")\ntrain_store_df.groupby(\"StoreType\")[\"Sales\"].mean().plot(kind = \"bar\", ax = ax[1,0], title = \"Average Sales of StoreTypes\")\ntrain_store_df.groupby(\"StoreType\")[\"Avg_Customer_Sales\"].mean().plot(kind = \"bar\", ax = ax[1,1], title = \"Average Spending per Customer\")\ntrain_store_df.groupby(\"StoreType\")[\"Customers\"].mean().plot(kind = \"bar\", ax = ax[1,2], title = \"Average Customers per StoreType\")\n\nplt.subplots_adjust(hspace = 0.3)\nplt.show()","0042c332":"sns.countplot(data = train_store_df, x = \"StoreType\", hue = \"Assortment\", order=[\"a\",\"b\",\"c\",\"d\"]) \nprint(\"\"\"So only the StoreType B has all assortments. Thats why they are performing so good. Maybe this StoreType has more sales area.\n      The assortment C is a good one, because the StoreType D has the best average customer spending.\"\"\")\n\nplt.show()","606bcd1a":"train_store_df.Date = train_store_df.Date.astype(\"datetime64[ns]\")\n\ntrain_store_df[\"Month\"] = train_store_df.Date.dt.month\ntrain_store_df[\"Year\"] = train_store_df.Date.dt.year\ntrain_store_df[\"Day\"] = train_store_df.Date.dt.day","4cf3b18e":"sns.factorplot(data = train_store_df, x =\"Month\", y = \"Sales\", \n               col = 'Promo', # per store type in cols\n               hue = 'Promo2',\n               row = \"Year\")\n# So, of course, if the stores are having promotion the sales are higher.\n# Overall the store promotions sellings are also higher than the seasionality promotions (Promo2). However we can't see any yearly trend.","e302808b":"sns.factorplot(data = train_store_df, x = \"DayOfWeek\", y = \"Sales\", hue = \"Promo\")","3e4595c3":"print(\"\"\"So, no promotion in the weekend. However, the sales are very high, if the stores have promotion. \nThe Sales are going crazy on Sunday.\"\"\")\nprint(\"There are\", train_store_df[(train_store_df.Open == 1) & (train_store_df.DayOfWeek == 7)].Store.unique().shape[0], \"stores opened on sundays\") ","cd259d7a":"sns.factorplot(data = train_store_df, x = \"Month\", y = \"Sales\", col = \"Year\", hue = \"StoreType\")\n# Yes, we can see a seasonalities, but not trends. The sales stays constantly yearly. ","eea971d3":"train_store_df.CompetitionDistance.describe()\n# The obsverations are continous numbers, so we need to convert them into a categories. Lets a create a new variable.\ntrain_store_df[\"CompetitionDistance_Cat\"] = pd.cut(train_store_df[\"CompetitionDistance\"], 5)","5e24b68a":"f, ax = plt.subplots(1,2, figsize = (15,5))\n\ntrain_store_df.groupby(by = \"CompetitionDistance_Cat\").Sales.mean().plot(kind = \"bar\", title = \"Average Total Sales by Competition Distance\", ax = ax[0])\ntrain_store_df.groupby(by = \"CompetitionDistance_Cat\").Customers.mean().plot(kind = \"bar\", title = \"Average Total Customers by Competition Distance\", ax = ax[1])\n\n# It is pretty clear. If the competition is very far away, the stores are performing better (sales and customers)","f89c25a6":"# first we have to convert the variables to categories, before we convert them to codes.\n\n# train_store_df[\"SchoolHoliday\"] = train_store_df[\"SchoolHoliday\"].astype(\"category\") # it's already numerical\ntrain_store_df[\"StoreType\"] = train_store_df[\"StoreType\"].astype(\"category\")\ntrain_store_df[\"Assortment\"] = train_store_df[\"Assortment\"].astype(\"category\")\n# train_store_df[\"Promo2\"] = train_store_df[\"Promo2\"].astype(\"category\") # it's already numerical\ntrain_store_df[\"PromoInterval\"] = train_store_df[\"PromoInterval\"].astype(\"category\")\n\ntrain_store_df[\"StoreType_cat\"] = train_store_df[\"StoreType\"].cat.codes\ntrain_store_df[\"Assortment_cat\"] = train_store_df[\"Assortment\"].cat.codes\ntrain_store_df[\"PromoInterval_cat\"] = train_store_df[\"PromoInterval\"].cat.codes \n\ntrain_store_df[\"StateHoliday_cat\"] = train_store_df[\"StateHoliday_cat\"].astype(\"float\")\ntrain_store_df[\"StoreType_cat\"] = train_store_df[\"StoreType_cat\"].astype(\"float\")\ntrain_store_df[\"Assortment_cat\"] = train_store_df[\"Assortment_cat\"].astype(\"float\")\ntrain_store_df[\"PromoInterval_cat\"] = train_store_df[\"PromoInterval_cat\"].astype(\"float\")","db082cca":"train_store_df.info()","a8a79da1":"df_correlation = train_store_df[[\"Store\", \"DayOfWeek\", \"Sales\", \"Customers\", \"Promo\", \"SchoolHoliday\", \"CompetitionDistance\",  \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \"Promo2\", \"Promo2SinceWeek\",  \"Avg_Customer_Sales\", \"Month\", \"Year\", \"Day\", \"StateHoliday_cat\", \"Assortment_cat\", \"StoreType_cat\", \"PromoInterval_cat\"]]\n\n\nf, ax = plt.subplots(figsize = (15, 10))\nsns.heatmap(df_correlation.corr(),ax = ax, annot=True, cmap=sns.diverging_palette(10, 133, as_cmap=True), linewidths=0.5)","5faf1661":"types = {'CompetitionOpenSinceYear': np.dtype(int),\n         'CompetitionOpenSinceMonth': np.dtype(int),\n         'StateHoliday': np.dtype(str),\n         'Promo2SinceWeek': np.dtype(int),\n         'SchoolHoliday': np.dtype(float),\n         'PromoInterval': np.dtype(str)}\ntrain = pd.read_csv(\"..\/input\/rossmann-data\/train.csv\", parse_dates=[2], dtype=types)\nstore = pd.read_csv(\"..\/input\/rossmann-data\/store.csv\")","2943dad9":"def build_features(features, data):\n    # remove NaNs\n    data.fillna(0, inplace=True)\n    data.loc[data.Open.isnull(), 'Open'] = 1\n    # Use some properties directly\n    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n\n    # Label encode some features\n    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n    data.StoreType.replace(mappings, inplace=True)\n    data.Assortment.replace(mappings, inplace=True)\n    data.StateHoliday.replace(mappings, inplace=True)\n\n    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n    data['Year'] = data.Date.dt.year\n    data['Month'] = data.Date.dt.month\n    data['Day'] = data.Date.dt.day\n    data['DayOfWeek'] = data.Date.dt.dayofweek\n    data['WeekOfYear'] = data.Date.dt.weekofyear\n\n    # CompetionOpen en PromoOpen from https:\/\/www.kaggle.com\/ananya77041\/rossmann-store-sales\/randomforestpython\/code\n    # Calculate time competition open time in months\n    features.append('CompetitionOpen')\n    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n        (data.Month - data.CompetitionOpenSinceMonth)\n    # Promo open time in months\n    features.append('PromoOpen')\n    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n        (data.WeekOfYear - data.Promo2SinceWeek) \/ 4.0\n    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n\n    # Indicate that sales on that day are in promo interval\n    features.append('IsPromoMonth')\n    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n    data['monthStr'] = data.Month.map(month2str)\n    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n    data['IsPromoMonth'] = 0\n    for interval in data.PromoInterval.unique():\n        if interval != '':\n            for month in interval.split(','):\n                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n\n    return data","40b7ecf2":"def rmspe(y, yhat):\n    return np.sqrt(np.mean((yhat\/y-1) ** 2))\n\ndef rmspe_xg(yhat, y):\n    y = np.expm1(y.get_label())\n    yhat = np.expm1(yhat)\n    return \"rmspe\", rmspe(y,yhat)\n","d1ffa4e3":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb","df895cc7":"train.fillna(1, inplace=True)\ntrain = train[train[\"Open\"] != 0]\ntrain = train[train[\"Sales\"] > 0]\ntrain = pd.merge(train, store, on='Store')\nfeatures = []\ndata=build_features(features, train)","ca4c7c34":"params = {\"objective\": \"reg:linear\",\n          \"booster\" : \"gbtree\",\n          \"eta\": 0.3,\n          \"max_depth\": 10,\n          \"subsample\": 0.9,\n          \"colsample_bytree\": 0.7,\n          \"silent\": 1,\n          \"seed\": 1301\n          }\n\n# max_depth is kept 10 to avoid overfitting. By default it is 6.\nnum_boost_round = 300","8d55f60e":"X_train, X_valid = train_test_split(train, test_size=0.012, random_state=10)\ny_train = np.log1p(X_train.Sales)\ny_valid = np.log1p(X_valid.Sales)\ndtrain = xgb.DMatrix(X_train[features], y_train)\ndvalid = xgb.DMatrix(X_valid[features], y_valid)\n\nwatchlist = [(dtrain, 'train'), (dvalid, 'eval')]\ngbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n  early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)","dfd50f70":"yhat = gbm.predict(xgb.DMatrix(X_valid[features]))\nerror = rmspe(X_valid.Sales.values, np.expm1(yhat))\nprint('RMSPE: {:.6f}'.format(error))","5da786d9":"**Lets go with the correlation graph.**","35448637":"# Problem Statement:\n\nTo predict sales for 1115 Rossmann Stores. Rossmann is the second largest drug store in Germany. \n\n# Business Stakeholders:\n\nRossmann stores or as a matter of fact any store\/organisation wishing to predict their sales on the basis of various parameters like seasonality, regionality etc. \n\n# Business Metric:\n\nTo understand what factors cause sales of a particular commodity store to vary.\n\n\n# Data Science Metric:\n\nRMSPE : With Root Mean Squared Percent Error (RMSPE), you have somewhat more of an idea of the magnitude of the error in relation to the actual values.\n\n","ce6a2ff1":"As we can see from the graphs, the StoreType A has the most stores, sales and customers. However the StoreType D has the best averages spendings per customers. StoreType B, with only 17 stores has the most average customers.","132816dc":"# **Conclusion:**\n- StoreType A has the most sales and customers.\n- StoreType B has the lowest Average Sales per Customer. \n- StoreType D had the highest buyer cart.\n- Promo runs only in weekdays.\n- Promo2 does not seems to be correlated to any significant change in the sales amount.\n- Customers tend to buy more on Monday, when there's promotion running (Promo) and on Sundays, when there is no promotion at all.\n- No yearly trends recognized. Only seasonal patterns.\n"}}