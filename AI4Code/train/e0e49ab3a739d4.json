{"cell_type":{"ef0f2439":"code","d964ab8d":"code","8232e2d8":"code","1418d919":"code","1dff261d":"code","3a93ba89":"code","03a59d34":"code","2ccd8ef8":"code","3b3b63d3":"code","9cbf1b21":"code","3538fd51":"code","0d9d0460":"code","b5a015cb":"code","31631b8a":"code","725ecaec":"code","e28233f4":"code","cd64354a":"code","a8a82ede":"code","eba977c4":"code","542046bb":"code","a313d0a2":"code","7eb3ed56":"code","5f488e52":"code","87bf1e49":"code","68f06be3":"code","cf26f058":"code","ca8f988e":"code","38cb0e22":"code","a3115d6d":"code","0e3ddeef":"code","0dbd3dda":"code","21a29970":"code","2f749970":"code","0cca1858":"code","0618e1d0":"code","bfefbd6f":"code","13ad3dae":"code","035e7b58":"code","76be6d41":"code","6b903f23":"code","dbf875e8":"code","b9a69367":"code","f83196da":"code","c0c7d877":"code","0b05dbaa":"code","e4e0b385":"code","7bc90da5":"code","894acbda":"code","cffa881d":"code","ee699143":"code","8b27ba29":"code","dce93055":"code","77a4a537":"code","a820947a":"code","aab6a25b":"code","bd14dbaf":"code","ef6e3f45":"code","9d605887":"code","89dda36a":"code","63acf06c":"code","d7092541":"code","5b4f5f67":"code","61e1daad":"code","f4b0d683":"code","9b6a211b":"code","7bf21767":"code","ee2c2dcc":"code","590059ee":"code","70be8895":"code","91d59795":"code","41bc02f7":"code","0e5e8fbb":"code","4481637c":"code","a516f1bd":"code","0d42cb00":"code","b323c666":"code","1beea6d9":"code","135ce7f8":"code","26766593":"code","031e8989":"code","e448444b":"code","37abf14f":"code","e6b614ec":"code","1ab4f99d":"code","c47375e9":"code","5a5ec9ee":"code","62eeb34a":"code","2a713ff3":"code","368a6f0e":"code","69e351cf":"code","706cedd8":"markdown","8da51eed":"markdown","a4b8fa95":"markdown","c0b976b3":"markdown","fa3a678c":"markdown","7948b6e9":"markdown"},"source":{"ef0f2439":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.api as sm\nimport warnings\nwarnings.filterwarnings('ignore')","d964ab8d":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\")","8232e2d8":"df.head()","1418d919":"df.shape","1dff261d":"df.info()","3a93ba89":"df.describe()","03a59d34":"df.isnull().sum()","2ccd8ef8":"687\/891\n#lots of null rows","3b3b63d3":"df.drop(\"Cabin\", axis=1, inplace=True)\ndf.head()","9cbf1b21":"df.shape","3538fd51":"177\/891\n#less than 20%","0d9d0460":"#age seems to be an important variable here to be saved\nplt.figure(figsize=(20, 12))\nsns.boxplot(x = 'Survived', y = 'Age', data = df)","b5a015cb":"df.Age.mean()","31631b8a":"df.Age.median()","725ecaec":"df['Age'] = df['Age'].fillna(df['Age'].median())","e28233f4":"df.Age.isnull()","cd64354a":"df.Age.isnull().sum()","a8a82ede":"df.isnull().sum()","eba977c4":"#Drop the rows of embarked having null values\ndf1 = df[~df.Embarked.isnull()]","542046bb":"df1.isnull().sum()","a313d0a2":"dummy1 = pd.get_dummies(df1['Sex'], drop_first = True)\ndummy1.head()","7eb3ed56":"df1 = pd.concat([df1, dummy1], axis = 1)\ndf1.head()\n","5f488e52":"df1.drop(['Sex'], axis = 1, inplace = True)\ndf1.head()","87bf1e49":"# we will also drop name for now and deal with only numbers leading to the survival \n#(I am sure they wouldn't have asked for names in the time of their emergency)\n\ndf1.drop(['Name'], axis = 1, inplace = True)\ndf1.head()\n\n","68f06be3":"#proabably even ticket's contents are capture by its fare we gon drop even that\\\ndf1. drop([\"Ticket\"], axis = 1, inplace = True)\ndf1.head()","cf26f058":"dummy2 = pd.get_dummies(df1['Embarked'], drop_first = True)\ndummy2.head()","ca8f988e":"df1 = pd.concat([df1, dummy2], axis = 1)\ndf1.head()","38cb0e22":"df1.drop(['Embarked'], axis = 1, inplace = True)\ndf1.head()","a3115d6d":"df1.drop([\"PassengerId\"], axis = 1, inplace = True)\ndf1.head()","0e3ddeef":"dummy3 = pd.get_dummies(df1['Pclass'], drop_first = True)\ndummy3.rename(columns = {2:'Pclass_2', 3:'Pclass_3'}, inplace = True)\ndummy3.head()","0dbd3dda":"df1 = pd.concat([df1, dummy3], axis = 1)\n\ndf1.drop([\"Pclass\"], axis = 1, inplace = True)\n\ndf1.head()","21a29970":"from sklearn.model_selection import train_test_split\n","2f749970":"X = df1.drop(['Survived'], axis=1)\n\nX.head()","0cca1858":"y = df1['Survived']\n\ny.head()","0618e1d0":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","bfefbd6f":"from sklearn.preprocessing import StandardScaler","13ad3dae":"scaler = StandardScaler()\n\nX_train[['Age','Fare']] = scaler.fit_transform(X_train[['Age','Fare']])\n\nX_train.head()","035e7b58":"import statsmodels.api as sm","76be6d41":"X_train_sm = sm.add_constant(X_train)\nlogm1 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm1.fit()\nres.summary()","6b903f23":"col = X_train_sm.columns\ncol = col.drop('Parch', 1)\ncol = col.drop('Fare', 1)\ncol = col.drop('Q', 1)\ncol = col.drop('const', 1)\ncol = col.drop('Pclass_2', 1)","dbf875e8":"X_train_sm = sm.add_constant(X_train[col])\nlogm1 = sm.GLM(y_train,X_train_sm[col], family = sm.families.Binomial())\nres = logm1.fit()\nres.summary()","b9a69367":"X_train_sm.shape","f83196da":"y_train_pred = res.predict(X_train_sm[col])\ny_train_pred[:10]","c0c7d877":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred[:10]","0b05dbaa":"y_train_pred_final = pd.DataFrame({'Survived':y_train.values, 'Survival_Prob':y_train_pred})\ny_train_pred_final['PassengerId'] = y_train.index\ny_train_pred_final.head()","e4e0b385":"y_train_pred_final['predicted'] = y_train_pred_final.Survival_Prob.map(lambda x: 1 if x > 0.5 else 0)\n\n# Let's see the head\ny_train_pred_final.head()","7bc90da5":"from sklearn import metrics","894acbda":"confusion = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final.predicted )\nprint(confusion)","cffa881d":"print(metrics.accuracy_score(y_train_pred_final.Survived, y_train_pred_final.predicted))","ee699143":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","8b27ba29":"TP \/ float(TP+FN)","dce93055":"TN \/ float(TN+FP)","77a4a537":"print(FP\/ float(TN+FP))","a820947a":"print (TP \/ float(TP+FP))","aab6a25b":"print (TN \/ float(TN+ FN))","bd14dbaf":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","ef6e3f45":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Survived, y_train_pred_final.Survival_Prob, drop_intermediate = False )","9d605887":"draw_roc(y_train_pred_final.Survived, y_train_pred_final.Survival_Prob)","89dda36a":"y_train_pred_final['predicted'] = y_train_pred_final.Survival_Prob.map(lambda x: 1 if x > 0.5 else 0)\n\n# Let's see the head\ny_train_pred_final.head()","63acf06c":"confusion = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final.predicted )\nprint(confusion)","d7092541":"print(metrics.accuracy_score(y_train_pred_final.Survived, y_train_pred_final.predicted))","5b4f5f67":"#X_test_sm = sm.add_constant(X_test[col])\ny_test_pred = res.predict(X_test[col])\ny_test_pred[:10]","61e1daad":"y_test_pred = y_test_pred.values.reshape(-1)\ny_test_pred[:10]","f4b0d683":"y_test_pred_final = pd.DataFrame({'Survived':y_test.values, 'Survival_Prob':y_test_pred})\ny_test_pred_final['PassengerId'] = y_test.index\ny_test_pred_final.head()\n","9b6a211b":"y_test_pred_final['predicted'] = y_test_pred_final.Survival_Prob.map(lambda x: 1 if x > 0.3 else 0)\n\n# Let's see the head\ny_test_pred_final.head()","7bf21767":"confusion = metrics.confusion_matrix(y_test_pred_final.Survived, y_test_pred_final.predicted )\nprint(confusion)","ee2c2dcc":"print(metrics.accuracy_score(y_test_pred_final.Survived, y_test_pred_final.predicted))","590059ee":"y_test_pred_final.predicted.value_counts()","70be8895":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nfrom sklearn.feature_selection import RFE\nrfe = RFE(logreg, 9)             # running RFE with 5 variables as output\nrfe = rfe.fit(X_train, y_train)","91d59795":"col = X_train.columns[rfe.support_]\nfeatures = [\"Pclass_2\", \"male\", \"SibSp\", \"Parch\"]","41bc02f7":"#model = svc.fit(X_train[col], y_train)\n#y_pred = model.predict(X_test[col])","0e5e8fbb":"#from sklearn.metrics import accuracy_score, confusion_matrix\n#accuracy = accuracy_score(y_pred, y_test)\n#print(accuracy)\n\n#confusion_matrix(y_pred, y_test)","4481637c":"from sklearn.svm import SVC\n\nsvc = SVC(C= 1.0, gamma= 0.5)\n\nmodel = svc.fit(X_train[col], y_train)\ny_pred = model.predict(X_test[col])\n\n","a516f1bd":"from sklearn.metrics import accuracy_score, confusion_matrix\naccuracy = accuracy_score(y_pred, y_test)\nprint(accuracy)\n\nconfusion_matrix(y_pred, y_test)","0d42cb00":"from sklearn.model_selection import GridSearchCV","b323c666":"# Create the parameter grid based on the results of random search \nparams = {\n    'n_estimators': [1, 5, 10, 50, 100, 200],\n    'max_depth': [1, 2, 3, 5, 10],\n    'min_samples_leaf': [1, 2, 5, 10, 20],\n    'criterion': [\"gini\", \"entropy\"]\n}\n\n","1beea6d9":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\n\n\ngrid_search = GridSearchCV(estimator=rf, \n                           param_grid=params, \n                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n\ngrid_search.fit(X_train[col], y_train)\n\n\n\ngrid_search.best_estimator_\n#y_pred = model.predict(X_test[col])","135ce7f8":"rf_best = grid_search.best_estimator_\nmodel = rf_best.fit(X_train[col], y_train)\ny_pred = model.predict(X_test[col])","26766593":"from sklearn.metrics import accuracy_score, confusion_matrix\naccuracy = accuracy_score(y_pred, y_test)\nprint(accuracy)\n\nconfusion_matrix(y_pred, y_test)","031e8989":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV","e448444b":"params = {\n    'n_estimators': [1, 5, 10, 50, 100, 200],\n    'learning_rate': [1, 2, 3, 5, 10],\n    'max_depth': [1, 2, 5, 10, 20],\n    'max_features': [\"auto\"]\n    \n}\n","37abf14f":"gb = GradientBoostingClassifier(random_state=0)","e6b614ec":"grid_search = GridSearchCV(estimator=gb, \n                           param_grid=params, \n                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n\ngrid_search.fit(X_train, y_train)\ngrid_search.best_estimator_","1ab4f99d":"gb_best = grid_search.best_estimator_\nclf = gb_best.fit(X_train, y_train)","c47375e9":"clf.score(X_test, y_test)","5a5ec9ee":"import xgboost as xgb\nfrom sklearn import metrics\n\nxgclf = xgb.XGBClassifier()\nxgb_model = xgb.XGBClassifier()","62eeb34a":"# 1st-Run for best hyperparameters\nparameters = {'learning_rate': [0.1, 0.2, 0.3, 0.4],\n              'max_depth': [2, 4, 6, 8],\n              'min_child_weight': [3, 7, 11, 19],\n              'n_estimators': [50, 100, 150, 200]}\n\nscorer = metrics.make_scorer(metrics.roc_auc_score,\n                             greater_is_better=True,\n                             needs_proba=True,\n                             needs_threshold=False)\n\nclf_xgb = GridSearchCV(estimator=xgb_model,\n                                       param_grid=parameters,\n                                       n_jobs=-1,\n                                       cv=3,\n                                       scoring=scorer,\n                                       verbose = 1,\n                                       refit=True)\n\nclf_xgb.fit(X_train[features], y_train)","2a713ff3":"print(clf_xgb.best_params_)\nprint(clf_xgb.best_score_)\nprint(clf_xgb.best_estimator_)","368a6f0e":"clf_xgb_best = grid_search.best_estimator_\nmodel = clf_xgb_best.fit(X_train[features], y_train)\ny_pred = model.predict(X_test[features]) ","69e351cf":"accuracy = accuracy_score(y_pred, y_test)\nprint(accuracy)\n\nconfusion_matrix(y_pred, y_test)","706cedd8":"### Random Forest","8da51eed":"### GRAD boost","a4b8fa95":"### XG Boost","c0b976b3":"### SVM ","fa3a678c":"------------------\n","7948b6e9":"-----------------------\n"}}