{"cell_type":{"5d9a5e9d":"code","5cba3656":"code","0afd4b11":"code","4cbf23ab":"code","af869f47":"code","cad6a0f2":"code","daa3ac9c":"code","fe680d62":"code","5e2d2cc9":"code","fdce32db":"code","2ad866ae":"code","d3b33e3a":"code","f3ebcc82":"code","8cd88e08":"code","be680f2d":"code","10e9774b":"code","da5655d8":"code","745488eb":"code","ac116817":"code","08d7de0f":"code","99827a3d":"code","95778e55":"markdown","f2b3c145":"markdown","16d2c3b2":"markdown"},"source":{"5d9a5e9d":"\n#Libraries for data manipulation\nimport numpy as np #Linear Algebra\nimport pandas as pd #Data Processing\n\n#for cnn\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.optimizers import Adam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\nfrom keras.layers.advanced_activations import LeakyReLU \nfrom keras.preprocessing.image import ImageDataGenerator\n\n#for data visulization\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n","5cba3656":"\ntrain_data=pd.read_csv('..\/input\/training\/training.csv')\ntest_data=pd.read_csv(\"..\/input\/test\/test.csv\")\nlookid_data = pd.read_csv(\"..\/input\/IdLookupTable.csv\")","0afd4b11":"#Number of rows and columns in the training data\ntrain_data.shape","4cbf23ab":"#Name of the columns in the training data\ntrain_data.columns","af869f47":"#Number of rows and columns in the test data\ntest_data.shape","cad6a0f2":"#Name of the columns in the test data\ntest_data.columns","daa3ac9c":"train_data.head().T","fe680d62":"#checking for missing values\ntrain_data.isnull().sum()","5e2d2cc9":"train_data.fillna(method='ffill',inplace=True)","fdce32db":"\n#Converting image into an 1D list of pixels\nimages=[]\nfor i in range(train_data.shape[0]):\n    image=['0'if x=='' else x for x in train_data['Image'][i].split(' ')]\n    images.append(image)\n\ntest_images=[]\nfor i in test_data['Image']:\n    test_images.append(['0' if x==' ' else x for x in i.split(' ') ])\n\ntrain_data.drop(['Image'],axis=1,inplace=True)    ","2ad866ae":"#convert 1d array of images to 2d array\nimages=np.array(images,dtype=float)\nimages=images.reshape(-1,96,96)\ntest_images=np.array(test_images,dtype=float)\ntest_images=test_images.reshape(-1,96,96)","d3b33e3a":"print(images[0])","f3ebcc82":"\n#Let's visualize some columns\nf,((ax1,ax2),(ax3,ax4))=plt.subplots(2,2,sharex='col',sharey='row')\nax1.imshow(images[0])\nax2.imshow(images[1])\nax3.imshow(images[2])\nax4.imshow(images[3])\n#plt.show()","8cd88e08":"#for our cnn,we need to convert 2d array into 3d array.\nimages=images.reshape(-1,96,96,1)","be680f2d":"model=Sequential()\nmodel.add(Conv2D(32,(3,3),input_shape=(96,96,1)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32,(3,3)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(30))\n","10e9774b":"#compile the model\nmodel.compile(loss='mse', optimizer='adam', metrics=['accuracy'])","da5655d8":"model.fit(images,train_data,epochs=1000,batch_size=128,validation_split=0.2)","745488eb":"#some images of test data.\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nf,((ax1,ax2),(ax3,ax4))=plt.subplots(2,2,sharex='col',sharey='row')\nax1.imshow(test_images[0])\nax2.imshow(test_images[1])\nax3.imshow(test_images[2])\nax4.imshow(test_images[3])","ac116817":"test_images=test_images.reshape(-1,96,96,1)\nresult=model.predict(test_images)","08d7de0f":"lookup=pd.read_csv('..\/input\/IdLookupTable.csv')\nlookup.head(5)","99827a3d":"#code for preparation of submission file\na=list(train_data.columns)\n\nindexes=[]\nfor i in lookup['FeatureName']:\n    indexes.append(a.index(i))\nimageid=[]\nfor i in lookup['ImageId']:\n        imageid.append(i-1)\nanswer=[]\nfor image,feature in zip(imageid,indexes):\n    answer.append(result[image][feature])\n\nrowid=range(1,len(answer)+1)\nanswer=pd.Series(answer,name='RowId')\nrowid=pd.Series(rowid,name='Location')\nsubmission=pd.concat([rowid,answer],axis=1)\nsubmission.to_csv('final.csv',index=False)\n","95778e55":"Get the datasets","f2b3c145":"every column contains some missing values. So Instead of removing the rows which contains missing values, I filled missing values with the values of previous row.","16d2c3b2":"Let's see some data of training dataset."}}