{"cell_type":{"184b1f2c":"code","71f6c69c":"code","1a86119d":"code","62e6e682":"code","3d2498bd":"code","4f9b730b":"code","8f4c37f0":"code","9adda57c":"code","5b439abb":"code","da589f3c":"code","cd6648a3":"code","a6c593cc":"code","4fb2940f":"code","6d42dd1f":"code","8ad971d3":"code","bb255cdc":"code","aa4388fa":"code","4d050d7b":"code","4be677d9":"code","b0f8ac8a":"code","6f087f54":"code","1f6f5239":"code","dcd74f15":"code","03b083cf":"code","e589a904":"code","92a7c7f4":"code","9f061205":"code","d4674cb4":"code","57b5d59b":"code","a996e2f0":"code","23bb8762":"code","6f11f0a7":"code","90c0413a":"code","dcd0322c":"code","bf4415bd":"code","ed49bff6":"code","b3bf4a6e":"code","373fa567":"code","770c7131":"code","d4f5a6e4":"code","26b923c8":"code","6fc52c9f":"code","8fcfd649":"code","d0aaf41c":"code","5f2647c7":"code","12ea9eb9":"code","2b7eb02c":"code","084095dd":"code","72340d81":"code","8f232e5e":"code","92e2ce18":"code","c8aadf4b":"code","e9b0df87":"code","fbc67df5":"code","119812fb":"code","3717e60d":"code","c300a193":"code","82595498":"code","d5af4057":"code","87e72501":"code","8b7aa2ee":"code","aa6b1c99":"code","d4fda56c":"code","b2c6f7ff":"code","79298c28":"code","3b12ca0e":"code","0cd2ed65":"code","dee03a81":"code","3e645d21":"code","a0689c3b":"code","8e52c91b":"code","65afa148":"code","276a59f7":"code","9d76a8be":"code","fc7e5289":"code","b5d4d7af":"code","3b4b3b50":"code","43118d5b":"code","419e3acf":"code","385fb960":"code","ec3195d4":"code","eb4833a5":"code","da989b10":"code","2b73285f":"code","8aa49848":"code","d9184ad5":"code","ba3c92c8":"code","43438af2":"code","08312c57":"code","a6666c7e":"code","fc4955a0":"markdown","3dc39bcf":"markdown","36c5c5a8":"markdown","8ba6107b":"markdown","fb1b17b6":"markdown","6ef63512":"markdown","7e5f2cfc":"markdown","3aa492d9":"markdown","e8687259":"markdown","d577a9af":"markdown","0410a225":"markdown","8b56936a":"markdown","28b2a91c":"markdown","78db1398":"markdown","f9c18d47":"markdown","2403c70c":"markdown","235d51ac":"markdown","e2f09442":"markdown","2128dbba":"markdown","984faca2":"markdown","17eba730":"markdown","fb7df4d5":"markdown","1f310a47":"markdown","a4ea2ec1":"markdown","57bddaf2":"markdown","71591d98":"markdown","5733c7e7":"markdown","73c598bf":"markdown","dc841e0e":"markdown","58d99a95":"markdown"},"source":{"184b1f2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","71f6c69c":"import seaborn as sns\nfrom sklearn import linear_model","1a86119d":"path_to_file=\"..\/input\/googleplaystore.csv\"","62e6e682":"data=pd.read_csv(path_to_file,encoding='utf-8')","3d2498bd":"##checking for all null values in dataset\nmissing_data_results =data.isnull().sum()\nprint(missing_data_results)\n","4f9b730b":"#loops through dataset and delete rows where column values is null\ndata =data.dropna()\ndata.isnull().sum()","8f4c37f0":"#Below we are using the regex \\D to remove any non-digit characters\ndata['Installs']=data['Installs'].replace(regex=True,inplace=False,to_replace=r'\\D',value=r'')\n#data['Installs']=data['Installs'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n#data.Installs\n","9adda57c":"data['Installs']","5b439abb":"np.sort(data.Installs)\n#for col in data.columns:\n  #  data[col]=np.sort(data[col].values)","da589f3c":"data.shape","cd6648a3":"dupes=data.duplicated()\nsum(dupes)\n","a6c593cc":"data=data.drop_duplicates()","4fb2940f":"data.shape","6d42dd1f":"data.dtypes\n    ","8ad971d3":"data['Price']=data['Price'].replace(regex=True,inplace=False,to_replace=r'\\D',value=r'')","bb255cdc":"#converting installs and Price to appropriate data types\ndata[\"Installs\"] = pd.to_numeric(data[\"Installs\"])\ndata[\"Reviews\"] = pd.to_numeric(data[\"Reviews\"])\ndata[\"Price\"] = pd.Float64Index(data[\"Price\"])\ndata.dtypes","aa4388fa":"data.columns =data.columns.str.replace(' ', '_')","4d050d7b":"#Apps available based on Content rating\nplt.figure(figsize=(10,10))\nsns.countplot(x='Content_Rating',data=data,)\nplt.xticks(rotation=45)\nplt.title(\"Number of Apps available based on Content rating\")\n","4be677d9":"\n#data['Category'].value_counts()\nplt.figure(figsize=(12,12))\ndata['Category'].value_counts().plot(kind='bar',title='Distribution of Categories')\nplt.xlabel('Categories')\nplt.ylabel('Number of Apps')\n\n","b0f8ac8a":"\nplt.figure(figsize=(12,12))\nsns.barplot(x='Installs',y='Category',data=data,ci=None)\nplt.title(\"Number of Apps installed based on Category\")\n","6f087f54":"data['Type'].value_counts().plot(kind='bar',title='Distribution App Types')\nplt.xlabel('Type of Apps')\nplt.ylabel('Count')","1f6f5239":"\nfind=((data.Installs.values >=10000)& (data.Installs.values <=10000000))\ndata1 = data[find]\ndata1","dcd74f15":"#Viewing install column after dividing dataset\ndata1.hist(column= 'Installs')","03b083cf":"len(data1.Installs.values)","e589a904":"data1.Reviews","92a7c7f4":"#qcut tries to divide up the underlying data into equal sized bins.\ndata1.Reviews=pd.qcut(data1.Reviews,20)","9f061205":"tree_data = data1[['Installs','Category','Type','Reviews']]\ntree_data","d4674cb4":"data1.Installs.value_counts()","57b5d59b":"tree_data['Installs'] = pd.cut(tree_data['Installs'], [9999\n,50000\n,100000\n,500000\n,1000000\n,5000000\n,10000000\n                                              ])\ntree_data.Installs.value_counts()","a996e2f0":"tree_data.Installs.value_counts()","23bb8762":"# Encoder function.....transforming","6f11f0a7":"def encoder(dataset):\n    from sklearn.preprocessing import LabelEncoder\n    #dictionary to store values\n    encoder = {}\n    for column in dataset.columns:\n        # Only creating encoder for categorical data types\n      #  if not np.issubdtype(dataset[column].dtype, np.number) and column != 'Installs':\n            encoder[column]= LabelEncoder().fit(dataset[column])\n            #returning the dictionary with values\n    return encoder","90c0413a":"tree_data","dcd0322c":"#transforming tree data\nencoded_labels = encoder(tree_data)\nprint(\"Encoded Values for each Label\")\nprint(\"=\"*32)\nfor column in encoded_labels:\n    print(\"=\"*32)\n    print('Encoder(%s) = %s' % (column, encoded_labels[column].classes_ ))\n    print(pd.DataFrame([range(0,len(encoded_labels[column].classes_))], columns=encoded_labels[column].classes_, index=['Encoded Values']  ).T)","bf4415bd":"data1.Installs.value_counts()","ed49bff6":"transformed_data= tree_data.copy()\nfor col in transformed_data.columns:\n    if col in encoded_labels:\n       transformed_data[col] = encoded_labels[col].transform(transformed_data[col])\nprint(\"Transformed data set with category and type encoded\")\nprint(\"=\"*32)\ntransformed_data","b3bf4a6e":"from sklearn.model_selection import train_test_split\n#Seperate our data into independent X and dependent Y \nX_data = transformed_data[['Category','Type']]\nY_data= transformed_data['Installs']\nX_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.30)","373fa567":"from sklearn import linear_model\nfrom sklearn.naive_bayes import GaussianNB","770c7131":"# creating multinomial model since we have more than one predictor then fit training data.\nregr = linear_model.LogisticRegression(solver='newton-cg')\n#regr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(pd.DataFrame(X_train),Y_train)\n#regr = GaussianNB()\nregr.fit(pd.DataFrame(X_train),Y_train)","d4f5a6e4":"#given a trained model, we are predicting the label of a new set of X test data.\nPrediction = regr.predict(pd.DataFrame(X_test))","26b923c8":"transformed_data['Installs'].value_counts()","6fc52c9f":"print(Prediction)","8fcfd649":"# The coefficient of our determinant(x)\nprint('Coefficients: \\n', regr.coef_)","d0aaf41c":"regr.intercept_","5f2647c7":"from sklearn.metrics import r2_score\n# Use score method to get accuracy of model\nprint('Variance score:%2f'% r2_score(Y_test,Prediction)) ","12ea9eb9":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\ncm = metrics.confusion_matrix(Y_test,Prediction)\nprint(cm)\ncm.shape","2b7eb02c":"plt.figure(figsize=(5,5))\nplt.imshow(cm, interpolation='nearest', cmap='Pastel1')\nplt.title('Confusion matrix', size = 15)\nplt.colorbar()\nplt.xticks(Prediction)\nplt.yticks(Y_test)\nplt.tight_layout()\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nwidth,height = cm.shape\nfor x in range(width):\n for y in range(height):\n  plt.annotate(str(cm[x][y]), xy=(y, x), \n  horizontalalignment='center',\n  verticalalignment='center')","084095dd":"data1","72340d81":"plt.scatter(transformed_data.Category,transformed_data.Installs)\nplt.show()","8f232e5e":"np.corrcoef(transformed_data.Type,transformed_data.Installs)\n","92e2ce18":"plt.scatter(transformed_data.Type,transformed_data.Installs)\nplt.show()","c8aadf4b":"np.corrcoef(transformed_data.Type,transformed_data.Installs)","e9b0df87":"from sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn import tree","fbc67df5":"# Create the classifier with a maximum depth of 2 using entropy as the criterion for choosing most significant nodes\n# to build the tree\nclf = DecisionTreeClassifier(criterion='entropy',min_samples_split=2)\n# Hint : Change the max_depth to 10 or another number to see how this affects the tree","119812fb":"clf.fit(X_train, Y_train)","3717e60d":"pd.DataFrame([ \"%.2f%%\" % perc for perc in (clf.feature_importances_ * 100)\n], index = X_data.columns, columns = ['Feature Significance in Decision Tree'])","c300a193":"import graphviz","82595498":"Y_data","d5af4057":"dot_data = tree.export_graphviz(clf,out_file=None,\n\nfeature_names=X_data.columns,\nclass_names= None,\nfilled=True, rounded=True, proportion=True,\nnode_ids=True, #impurity=False,\nspecial_characters=True)","87e72501":"graph = graphviz.Source(dot_data)\n\ngraph\ntree.export_graphviz(clf,out_file='tree.dot') ","8b7aa2ee":"corrmat = transformed_data.corr()\n#f, ax = plt.subplots()\np =sns.heatmap(corrmat, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))","aa6b1c99":"transformed_data['Reviews'].corr(transformed_data['Installs'])","d4fda56c":"X_data1 = transformed_data['Reviews']\nY_data1 = transformed_data['Installs']","b2c6f7ff":"from sklearn.model_selection import train_test_split\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X_data1, Y_data1, test_size=0.30)","79298c28":"reg1 = linear_model.LinearRegression()","3b12ca0e":"reg1.fit(pd.DataFrame(X_train1),y_train1)","0cd2ed65":"Prediction1 = reg1.predict(pd.DataFrame(X_test1))","dee03a81":"y_test1.index","3e645d21":"Prediction1[:12]","a0689c3b":"reg1.coef_","8e52c91b":"reg1.intercept_","65afa148":"reg1.score(pd.DataFrame(X_test1),y_test1)","276a59f7":"plt.scatter(X_test1,y_test1,  color='black')\nplt.plot(X_test1,Prediction1,color='blue', linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()","9d76a8be":"import seaborn as sns\nsns.set(style=\"whitegrid\")\n# Plot the residuals after fitting a linear model\nsns.residplot(X_train1, y_train1, lowess=True, color=\"b\")","fc7e5289":"install = 0.2*4 -0.354\ninstall","b5d4d7af":"cluster_data = transformed_data[['Reviews','Installs']]\ncluster_data.head(50)","3b4b3b50":"cluster_data.plot(kind='scatter',x='Reviews',y='Installs')","43118d5b":"# Is there any missing data\nmissing_data_results = cluster_data.isnull().sum()\nprint(missing_data_results)","419e3acf":"data_values = cluster_data.iloc[ :, :].values\ndata_values","385fb960":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cluster import KMeans","ec3195d4":"mms = MinMaxScaler()\nmms.fit(data_values)\ndata_transformed = mms.transform(data_values)","eb4833a5":"Sum_of_squared_distances = []\nK = range(1,15)\nfor i in K:\n    km = KMeans(n_clusters=i)\n    km = km.fit(data_transformed)\n    Sum_of_squared_distances.append(km.inertia_)","da989b10":"plt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('WCSS')\nplt.title('Computing WCSS for KMeans++')\nplt.xlabel(\"Number of clusters\")\nplt.show()","2b73285f":"kmeans = KMeans(n_clusters=3, init=\"k-means++\", n_init=10, max_iter=300)\ncluster_data[\"cluster\"] = kmeans.fit_predict( data_values )\ncluster_data","8aa49848":"#viewing amount of elements in clusters\ncluster_data['cluster'].value_counts()\n","d9184ad5":"import seaborn as sns\nsns.set(color_codes=True)\n","ba3c92c8":"cluster_data['cluster'].value_counts().plot(kind='bar',title='Distribution of Apps')","43438af2":"grouped_cluster_data = cluster_data.groupby('cluster')\ngrouped_cluster_data","08312c57":"grouped_cluster_data.plot(subplots=True)","a6666c7e":"sns.pairplot(cluster_data,hue=\"cluster\")","fc4955a0":"# Transformation step in KDD process","3dc39bcf":"# Aim: Does the amount of installs go up with increase in reviews?","36c5c5a8":"**VISUALIZATIONS**","8ba6107b":"Application of knowledge from dataset.....\nSelect all apps where there downloads are between 10000 and 10000000\n________________________________________________________________________________","fb1b17b6":"# Output of linear regression\n**install = 0.2review -0.354**","6ef63512":"# We attempted to use decision tree to give a better visual of the question above but had some problem......*not one of our algorithm!* ","7e5f2cfc":"In observing the dataset we realied that some of the apps listed were not even released as yet.\nWe also spotted the pattern that these apps all contained some NULL values and would not be important \nfor our analysis so we decided to get rid of them.","3aa492d9":"Checking to see if we are working with ligit data types","e8687259":"# **********************Linear Regression************************\nType of algorithm ?\n    -supervised machine learning algorithm\nType ofsupervised machine learning?\n    - Classification since dependent variable is categorical and dealing with current behavior\n        ","d577a9af":"*************************************k-Nearest Neighbors Method************************\nType of algorithm ?\n    -supervised machine learning algorithm\nType ofsupervised machine learning?\n    - Classification since dependent variable is categorical and dealing with current behavior","0410a225":"# Interpretation\/ Evaluation of K-Mean","8b56936a":"*************************************Multinomial LogisticRegression************************\n# Aim: Does the numbr of Installs for an app incrof installs go up with increase in reviews?\nType of algorithm ?\n    -supervised machine learning algorithm\nType ofsupervised machine learning?\n    - Classification since dependent variable is categorical and dealing with current behavior\n        \n    ","28b2a91c":"Complete case analysis, Complete case analysis followed by nearest-neighbor assignment for partial data, Partial data cluster analysis, Replacing missing values or incomplete data with means Imputation are all ways to deals with missing data. However we decided to delete all rows where  column values is null","78db1398":"### check correlation between Category and Installs variables\nnp.corrcoef(transformed_data.Category,transformed_data.Installs)\n","f9c18d47":"1. Number of Apps available basedon content ratings","2403c70c":"  **CLUSTERING******\n  Aim: Can we identify groups based on Review and Installs?\nIf that is the case, developers could develop Apps of a certain category based on the reviews","235d51ac":"Observing the install columns we realized that it contains string characters and as such we remove those charaters in order to work with integer values.\n                   BEFORE:                                    \n![image.png](attachment:image.png)\n","e2f09442":"AFTER:\n![image.png](attachment:image.png)","2128dbba":"# Data Mining  in KDD process","984faca2":"# Preprossesing  data in KDD PROCESS","17eba730":"# Interpretation\/ Evaluation of Linear model\nThe linear regression module was considered better than the multinomial regression as the coefficient of determination had a higher value. The R^2 value for this module was 0.85 which means that Installs have an 85 percent chance of being predicted from Reviews.\n","fb7df4d5":"**Regression Explanation**\nThe score above indicates that our model is extreamly bad!! We considered many solutions such as using different models and allocating  a larger training sample, none of which worked. We then observed the relationship between our two independent variables and dependent variable. There are of no relation and as such contributing to our bad model. So in conclusion, we went wrong in selecting our independent variables!! :(","1f310a47":"        *Most installed apps based on Category*","a4ea2ec1":" #   Selection of data in KDD process","57bddaf2":"3. In the series of steps to determine what appp to develop we would like to identify whether there are more downloads for \"Paid\" or \"Free\" apps","71591d98":"With the clustering algorithm, we used the elbow method to deduce the number of groups we could possible obtain. After trying the various K values, we decided that K =3 give the most suitable results. With K= 3 we deduce that apps each group has at least 2000 apps which are group together based on their Installs and Reviews. The values for installs show the different bins in which apps bring for the 3 groups. It can be deduced that apps in group 0 are apps received more installs than review, while group 1 on shows that the apps in that group received.","5733c7e7":"2. Plot to show the distribution of apps from each category in the data set. ","73c598bf":"# Interpretation\/ Evaluation of our Regression Model","dc841e0e":"# K-MEANS","58d99a95":"        **Check for duplicate records**"}}