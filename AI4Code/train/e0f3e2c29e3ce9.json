{"cell_type":{"12b6f16d":"code","7b0f3683":"code","5bb9d606":"code","2a7f2255":"code","2a7b9ceb":"code","19720c61":"code","349ac39c":"code","6a318473":"code","b83afdfc":"code","ffabc382":"code","f8457da9":"code","6f2f862d":"markdown","75ea06b6":"markdown","d20ee8d8":"markdown","29e8504c":"markdown","eebe1d5e":"markdown"},"source":{"12b6f16d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport glob\nimport shutil\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","7b0f3683":"#create new folder structure usable by keras image processor\nDATA_DIR = \"data\"\nTRAIN_DIR = \"train\"\nTEST_DIR = \"test\"\nOWL = \"OWL\"\nFROGMOUTH = \"FROGMOUTH\"\n\nGENERATED_DIR = \"GEN\"\n\nos.makedirs(os.path.join(os.getcwd(),DATA_DIR, TRAIN_DIR,OWL), exist_ok=True)\nos.makedirs(os.path.join(os.getcwd(),DATA_DIR, TRAIN_DIR,FROGMOUTH), exist_ok=True)\n\nos.makedirs(os.path.join(os.getcwd(),DATA_DIR, TEST_DIR,OWL), exist_ok=True)\nos.makedirs(os.path.join(os.getcwd(),DATA_DIR, TEST_DIR,FROGMOUTH), exist_ok=True)\n\n\nos.makedirs(os.path.join(os.getcwd(),DATA_DIR, GENERATED_DIR), exist_ok=True)\n\n\n#copy existing data images into new directory\n#copy training frogmouth\nfiles = glob.iglob('..\/input\/owl-and-frogmouth\/owl_and_frogmouth\/train\/frogmouth*.*')\n\nfor path in files:\n    if(path.endswith('csv')):\n        continue\n    shutil.copy(path,os.path.join(os.getcwd(),DATA_DIR, TRAIN_DIR,FROGMOUTH))\n \n#copy test frogmouth\nfiles = glob.iglob('..\/input\/owl-and-frogmouth\/owl_and_frogmouth\/test\/frogmouth*.*')\nfor path in files:\n    if(path.endswith('csv')):\n        continue\n    shutil.copy(path,os.path.join(os.getcwd(),DATA_DIR, TEST_DIR,FROGMOUTH))\n    \n#copy training owl\nfiles = glob.iglob('..\/input\/owl-and-frogmouth\/owl_and_frogmouth\/train\/owl*.*')\nfor path in files:\n    if(path.endswith('csv')):\n        continue\n    \n    shutil.copy(path,os.path.join(os.getcwd(),DATA_DIR, TRAIN_DIR,OWL))\n    \n#copy test owl\nfiles = glob.iglob('..\/input\/owl-and-frogmouth\/owl_and_frogmouth\/test\/owl*.*')\nfor path in files:\n    if(path.endswith('csv')):\n        continue\n    \n    shutil.copy(path,os.path.join(os.getcwd(),DATA_DIR, TEST_DIR,OWL))\n\nplt.show()","5bb9d606":"#our set image size\nIMAGE_SHAPE = [150,150]\n\n\n#instantiate pre trained VGG16 model with imagenet weights prefilled\npre_t_model = VGG16(\n                input_shape= IMAGE_SHAPE + [3],\n                weights='imagenet',\n                include_top = False)\n\n#we don't want to retrain the conv layers\npre_t_model.trainable = False\n\nK = 2 #two classes\nx = Flatten() (pre_t_model.output)\nx = Dense(2048, activation='relu') (x)\nx = Dropout(0.2) (x)\nx = Dense(K, activation='softmax') (x)\n\n#create our model\nmodel = Model(inputs=pre_t_model.input, outputs=x)\n\nmodel.summary()","2a7f2255":"#creating image data generators\ngen = ImageDataGenerator(\n        rescale=1.\/255,\n        rotation_range=10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        preprocessing_function=preprocess_input)\n\nbatch_size = 8\n\n#training generator\ntrain_generator = gen.flow_from_directory(\n                os.path.join(os.getcwd(),DATA_DIR, TRAIN_DIR),\n                shuffle=True,\n                target_size=IMAGE_SHAPE,\n                batch_size=batch_size,\n                save_to_dir=os.path.join(os.getcwd(),DATA_DIR,GENERATED_DIR),\n                save_prefix='train_gen')\n\nval_generator = gen.flow_from_directory(\n                os.path.join(os.getcwd(),DATA_DIR, TEST_DIR),\n                shuffle=True,\n                target_size=IMAGE_SHAPE,\n                batch_size=batch_size,\n                save_to_dir=os.path.join(os.getcwd(),DATA_DIR,GENERATED_DIR),\n                save_prefix='test_gen')\n\n","2a7b9ceb":"#compile and train model\n\nopti = SGD(lr=0.0001, momentum=0.8)\n#opti = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=opti,\n        metrics=['accuracy'])\n\nr = model.fit_generator(\n        train_generator,\n        validation_data=val_generator,\n        steps_per_epoch=3,\n        epochs=30,\n        validation_steps=3)","19720c61":"plt.plot(r.history['accuracy'], label='accuracy')\nplt.plot(r.history['val_accuracy'], label='val accuracy')\n\nplt.legend()","349ac39c":"plt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()","6a318473":"pre_t_model.trainable = True\n\nset_trainable = False\nfor layer in pre_t_model.layers:\n    if layer.name == \"block5_conv1\":\n        set_trainable = True\n    layer.trainable = set_trainable\n    \nmodel.summary()\n\n","b83afdfc":"#compile and train model\n\nopti = SGD(lr=0.000001)\n#opti = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=opti,\n        metrics=['accuracy'])\n\n\n#now train the model\nr = model.fit_generator(\n        train_generator,\n        validation_data=val_generator,\n        steps_per_epoch=3,\n        epochs=100,\n        validation_steps=3)","ffabc382":"plt.plot(r.history['accuracy'], label='accuracy')\nplt.plot(r.history['val_accuracy'], label='val accuracy')\n\nplt.legend()","f8457da9":"plt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()","6f2f862d":"# I tried to demonstrate few things in this notebook.\n1. how to make use of the owl and frogmouth dataset\n2. How to use VGG16 to try and classify these two birds\n","75ea06b6":"Now we will unfreeze the VGG16 last conv block and train it along with our dense categorization block","d20ee8d8":"Now we will compile it again with SGD optimizer having a very low learning rate\n","29e8504c":"As you can see from the plots, although the model could get proper accuracy and loss on the training data, it fails on the validation data.\nThis could be primarily due to the fact that these two species of birds look a lot similar.","eebe1d5e":"Plotting accuracy and loss again"}}