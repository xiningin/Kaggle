{"cell_type":{"f4594beb":"code","03e016f0":"code","22aed446":"code","05e45581":"code","9ea53164":"code","602833f0":"code","59d50784":"code","94ec0469":"code","a69890f1":"markdown","21141039":"markdown","6c1125c5":"markdown","0e3aed06":"markdown"},"source":{"f4594beb":"from google.cloud import bigquery\nimport pandas as pd\n\nclient = bigquery.Client()\n\n# Query by Allen Day, GooglCloud Developer Advocate (https:\/\/medium.com\/@allenday)\nquery = \"\"\"\nSELECT \n  SUM(value\/POWER(10,18)) AS sum_tx_ether,\n  AVG(gas_price*(receipt_gas_used\/POWER(10,18))) AS avg_tx_gas_cost,\n  DATE(timestamp) AS tx_date\nFROM\n  `bigquery-public-data.crypto_ethereum.transactions` AS transactions,\n  `bigquery-public-data.crypto_ethereum.blocks` AS blocks\nWHERE TRUE\n  AND transactions.block_number = blocks.number\n  AND receipt_status = 1\n  AND value > 0\nGROUP BY tx_date\nHAVING tx_date >= '2018-01-01' AND tx_date <= '2018-12-31'\nORDER BY tx_date\n\"\"\"","03e016f0":"query_job = client.query(query)\n\niterator = query_job.result(timeout=30)\nrows = list(iterator)\n\n# Transform the rows into a nice pandas dataframe\ndf = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n\n# Look at the first 10\ndf.head(10)","22aed446":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n\nf, g = plt.subplots(figsize=(12, 9))\ng = sns.lineplot(x=\"tx_date\", y=\"avg_tx_gas_cost\", data=df, palette=\"Blues_d\")\nplt.title(\"Average Ether transaction cost over time\")\nplt.show(g)","05e45581":"# https:\/\/github.com\/SohierDane\/BigQuery_Helper\nfrom bq_helper import BigQueryHelper\n\n# This establishes an authenticated session and prepares a reference to the dataset that lives in BigQuery.\nbq_assistant = BigQueryHelper(\"bigquery-public-data\", \"crypto_ethereum\")","9ea53164":"df = bq_assistant.query_to_pandas_safe(query)","602833f0":"df = bq_assistant.query_to_pandas_safe(query, max_gb_scanned=18)","59d50784":"print('Size of dataframe: {} Bytes'.format(int(df.memory_usage(index=True, deep=True).sum())))","94ec0469":"f, g = plt.subplots(figsize=(12, 9))\ng = sns.lineplot(x=\"tx_date\", y=\"avg_tx_gas_cost\", data=df, palette=\"Blues_d\")\nplt.title(\"Average Ether transaction cost over time\")\nplt.show(g)","a69890f1":"Voil\u00e0. Same results. We have done a deep dive on the BigQueryHelper functions in [this kernel](https:\/\/www.kaggle.com\/mrisdal\/safely-analyzing-github-projects-popular-licenses).","21141039":"To make querying BigQuery datasets even easier on Kaggle, we have also written some helper functions that are packaged in the [BigQueryHelper module](https:\/\/github.com\/SohierDane\/BigQuery_Helper\/blob\/master\/bq_helper.py) available in Kernels. I'll replicate the code above using the wrapper functions below. Because our query results are cached by default, we don't need to worry about spending more quota by executing the query twice.","6c1125c5":"In this starter kernel, I'll show you how to use the BigQuery Python client library in Kernels to query data from the Ethereum Blockchain. We'll examine average Ether transaction costs over time. In the second half of this kernel, I'll show you how you can better manage your free 5TB 30-day quota by using the BigQueryHelper module.\n\nFor general resources about working with BigQuery datasets on Kaggle, check out [this forum post](https:\/\/www.kaggle.com\/product-feedback\/48573).","0e3aed06":"Conveniently, it will cancel any queries that are estimated to scan more than 1GB of data. This helps with managing resources and gives you more control in staying below your 5TB 30-day quota. This makes Kernels a safe sandbox for learning to work with BigQuery data."}}