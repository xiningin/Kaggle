{"cell_type":{"01947960":"code","05790ce9":"code","347c208b":"code","1f8076c8":"code","cb990713":"code","890dd013":"code","8b8a68c1":"code","c03da62a":"code","8f8d7341":"code","bb50084d":"code","25dac474":"code","abdb886e":"code","8728bdaf":"code","faf0c7cc":"code","dbb4bf6a":"code","207f40b5":"code","ebe9cf26":"code","9e24e60b":"code","baa53f3f":"code","6fccf013":"code","86b086f1":"code","ce31649f":"code","9f114a33":"code","fc9e9eac":"code","65a05b60":"code","601fc696":"code","982412bc":"code","2230ffda":"code","cb4c6136":"code","77f32833":"code","84d88ace":"code","c5bfc1b3":"code","1866470d":"code","2e28ff8f":"markdown","33f27701":"markdown","f30ee259":"markdown","f0877fb4":"markdown","1f7d51b7":"markdown","6575715a":"markdown","0670087e":"markdown","9e670567":"markdown","905e9c09":"markdown","1df32bed":"markdown","0f9f457c":"markdown","0f7a2563":"markdown","1dfd99b0":"markdown","7db5ffa6":"markdown","015cccb3":"markdown","82f59ea7":"markdown","48a86c3a":"markdown","aea07252":"markdown","27456a81":"markdown","a6994288":"markdown","7ec19bb6":"markdown","8189f932":"markdown","7407f2ef":"markdown","16646d02":"markdown","498d14c8":"markdown","64d3c125":"markdown","7fac4646":"markdown","79864577":"markdown","4b0e575e":"markdown","4e04c3d1":"markdown"},"source":{"01947960":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\n\nsns.set_style('darkgrid')","05790ce9":"#create an empty DataFrame\ndf = pd.DataFrame(columns=['path','label'])\n\n#loop over fire images and label them 1\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/fire-dataset\/fire_dataset\/fire_images'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        df = df.append(pd.DataFrame([[os.path.join(dirname, filename),'fire']],columns=['path','label']))\n\n#loop over non fire images and label them 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/fire-dataset\/fire_dataset\/non_fire_images'):\n    for filename in filenames:\n        df = df.append(pd.DataFrame([[os.path.join(dirname, filename),'non_fire']],columns=['path','label']))\n        #print(os.path.join(dirname, filename))\n\n#shuffle the dataset for redistribute the labels\ndf = df.sample(frac=1).reset_index(drop=True)\ndf.head(10)","347c208b":"fig = px.scatter(data_frame = df,x=df.index,y='label',color='label',title='Distribution of fire and non-fire images along the length of the dataframe')\nfig.update_traces(marker_size=2)","1f8076c8":"fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"xy\"}, {\"type\": \"pie\"}]])\n\n\nfig.add_trace(go.Bar(x =df['label'].value_counts().index,y=df['label'].value_counts().to_numpy(),marker_color=['darkorange','green'],showlegend=False),row=1,col=1)\n\nfig.add_trace(go.Pie(\n     values=df['label'].value_counts().to_numpy(),\n     labels=df['label'].value_counts().index,\n    marker=dict(colors=['darkorange','green'])),\n    row=1, col=2)\n","cb990713":"label = 'fire' #label for images with fire\ndata = df[df['label'] == label]\nsns.set_style('dark')\n\n\npics = 6 #set the number of pics\nfig,ax = plt.subplots(int(pics\/\/2),2,figsize=(15,15))\nplt.suptitle('Images with Fire')\nax = ax.ravel()\nfor i in range((pics\/\/2)*2):\n    path = data.sample(1).loc[:,'path'].to_numpy()[0]\n    img = image.load_img(path)\n    img = image.img_to_array(img)\/255\n    ax[i].imshow(img)\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","890dd013":"label = 'non_fire' #label for images without fire\ndata = df[df['label'] == label]\nsns.set_style('dark')\n\n\npics = 6 #set the number of pics\nfig,ax = plt.subplots(int(pics\/\/2),2,figsize=(15,15))\nplt.suptitle('Images with Fire')\nax = ax.ravel()\nfor i in range((pics\/\/2)*2):\n    path = data.sample(1).loc[:,'path'].to_numpy()[0]\n    img = image.load_img(path)\n    img = image.img_to_array(img)\/255\n    ax[i].imshow(img)\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","8b8a68c1":"def shaper(row):\n    shape = image.load_img(row['path']).size\n    row['height'] = shape[1]\n    row['width'] = shape[0]\n    return row\ndf = df.apply(shaper,axis=1)\ndf.head(5)","c03da62a":"sns.set_style('darkgrid')\nfig,(ax1,ax2,ax3) = plt.subplots(1,3,gridspec_kw={'width_ratios': [3,0.5,0.5]},figsize=(15,10))\nsns.kdeplot(data=df.drop(columns=['path','label']),ax=ax1,legend=True)\nsns.boxplot(data=df,y='height',ax=ax2,color='skyblue')\nsns.boxplot(data=df,y='width',ax=ax3,color='orange')\nplt.suptitle('Distribution of image shapes')\nax3.set_ylim(0,7000)\nax2.set_ylim(0,7000)\nplt.tight_layout()","8f8d7341":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","bb50084d":"generator = ImageDataGenerator(\n    rotation_range= 20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range = 2,\n    zoom_range=0.2,\n    rescale = 1\/255,\n    validation_split=0.2,\n)","25dac474":"train_gen = generator.flow_from_dataframe(df,x_col='path',y_col='label',images_size=(256,256),class_mode='binary',subset='training')\nval_gen = generator.flow_from_dataframe(df,x_col='path',y_col='label',images_size=(256,256),class_mode='binary',subset='validation')","abdb886e":"class_indices = {}\nfor key in train_gen.class_indices.keys():\n    class_indices[train_gen.class_indices[key]] = key\n    \nprint(class_indices)","8728bdaf":"sns.set_style('dark')\npics = 6 #set the number of pics\nfig,ax = plt.subplots(int(pics\/\/2),2,figsize=(15,15))\nplt.suptitle('Generated images in training set')\nax = ax.ravel()\nfor i in range((pics\/\/2)*2):\n    ax[i].imshow(train_gen[0][0][i])\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","faf0c7cc":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense","dbb4bf6a":"model = Sequential()\nmodel.add(Conv2D(filters=32,kernel_size = (2,2),activation='relu',input_shape = (256,256,3)))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(filters=64,kernel_size=(2,2),activation='relu'))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(filters=128,kernel_size=(2,2),activation='relu'))\nmodel.add(MaxPool2D())\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(32,activation = 'relu'))\nmodel.add(Dense(1,activation = 'sigmoid'))","207f40b5":"model.summary()","ebe9cf26":"from tensorflow.keras.metrics import Recall,AUC\nfrom tensorflow.keras.utils import plot_model","9e24e60b":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy',Recall(),AUC()])","baa53f3f":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","6fccf013":"early_stoppping = EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\nreduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=5)","86b086f1":"model.fit(x=train_gen,batch_size=32,epochs=15,validation_data=val_gen,callbacks=[early_stoppping,reduce_lr_on_plateau])","ce31649f":"history= model.history.history\npx.line(history,title = \"Metrics Plot\")","9f114a33":"eval_list = model.evaluate(val_gen,return_dict=True)\nfor metric in eval_list.keys():\n    print(metric+f\": {eval_list[metric]:.2f}\")","fc9e9eac":"from tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dropout","65a05b60":"xception = Xception(include_top = False,input_shape = (256,256,3))\ninput_to_model = xception.input\n#turn off training\nxception.trainable = False\n\nx = Flatten()(xception.output)\nx = Dense(64,activation = 'relu')(x)\noutput_to_model = Dense(1,activation = 'sigmoid')(x)\nmodel2 = Model(inputs = input_to_model,outputs = output_to_model)","601fc696":"model2.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy',Recall(),AUC()])","982412bc":"history2 = model2.fit(x = train_gen,batch_size=32,epochs=15,callbacks = [early_stoppping,reduce_lr_on_plateau],validation_data = val_gen)","2230ffda":"px.line(history,title='Metrics Plot')","cb4c6136":"eval_list = model.evaluate(val_gen,return_dict=True)\nfor metric in eval_list.keys():\n    print(metric+f\": {eval_list[metric]:.2f}\")","77f32833":"#Downloading the image\n!curl https:\/\/static01.nyt.com\/images\/2021\/02\/19\/world\/19storm-briefing-texas-fire\/19storm-briefing-texas-fire-articleLarge.jpg --output predict.jpg","84d88ace":"#loading the image\nimg = image.load_img('predict.jpg')\nimg","c5bfc1b3":"img = image.img_to_array(img)\/255\nimg = tf.image.resize(img,(256,256))\nimg = tf.expand_dims(img,axis=0)\n\nprint(\"Image Shape\",img.shape)","1866470d":"prediction = int(tf.round(model2.predict(x=img)).numpy()[0][0])\nprint(\"The predicted value is: \",prediction,\"and the predicted label is:\",class_indices[prediction])","2e28ff8f":"### Model Summary","33f27701":"#### Class indices assigned by the Image generator","f30ee259":"**The shuffling has taken place well.**\n\n**Let's visualize the countplot of the data**","f0877fb4":"### Model Evaluation","1f7d51b7":"**Creating the training and test generator**\n\n**We will use the flow_from_dataframe method of the ImageDataGenerator class. It will take the path of the images from the dataframe along with their labels. We construct two generators, one for training and the other for validation.**\n\n**Note: Our labels are strings 'fire ' and 'non_fire'. Image generator will automatically encode them to integer labels.**","6575715a":"# Thank You","0670087e":"## Visualizing the images with fire","9e670567":"# Fire Detection in Images\n\n**Description about the dataset:**\n\nData was collected to train a model to distinguish between the images that contain fire (fire images) and regular images (non-fire images). Data is divided into 2 folders, fireimages folder contains 755 outdoor-fire images some of them contains heavy smoke, the other one is non-fireimages which contain 244 nature images (eg: forest, tree, grass, river, people, foggy forest, lake, animal, road, and waterfall).\n\n**Objective: To create a classification model that can detect fire in images**\n\n**Models used: Sequential CNN from scratch, Pretrained Xception with modifications**","905e9c09":"**Great! the dataset has been created. Let's see how well the data is shuffled.**","1df32bed":"**Let's first create a dataframe that contains the path to each picture and its corresponding label (fire or non fire).**\n\n**Reading Paths**","0f9f457c":"**Compiling the model**","0f7a2563":"**As you can see, the sizes of the images are different. Let's visualize the distribution of their shapes**","1dfd99b0":"**Hence an image predicted 0 will contain fire and 1 won't.**","7db5ffa6":"**Fitting the model**","015cccb3":"## Example Prediction\n\n**Let's use an image of the apartment complex in Texas that caught fire in February 2021.**\n\nNews link : https:\/\/www.nytimes.com\/2021\/02\/19\/us\/san-antonio-fire-hydrants-water.html","82f59ea7":"**Resizing the image and expanding its dimension to include the batch size - 1**","48a86c3a":"## Creating the model","aea07252":"### Model Evaluation\n\n**Plotting metrics**","27456a81":"**Defining Callbacks**\n","a6994288":"**Printing the image**","7ec19bb6":"**Compiling the model**","8189f932":"## Visualizing the generated images in training set","7407f2ef":"### Model Fitting","16646d02":"**The height and width of images vary too much. We have to reshape them to a fixed shape before training**\n\n## Image Generation or Augmentation","498d14c8":"**Prediction**","64d3c125":"**Non fire label has less number of images. The dataset is imbalanced**","7fac4646":"**We increase the number of filters as we add more layers because initially there will be a lot of noise present in the input and we only need to capture the important information. Later as we progress through the layers, the feature maps become nuanced and we try to capture them with more filters**  ","79864577":"## Model creation by transfer learning","4b0e575e":"## Exploratory Data Analysis","4e04c3d1":"## Visualizing Shape Distribution"}}