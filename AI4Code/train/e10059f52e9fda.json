{"cell_type":{"4614f57d":"code","6059f3e3":"code","b5ed39f1":"code","4b80b294":"code","94238da0":"code","80d543e9":"code","c3614fc1":"code","2af1398b":"code","7b1978a1":"code","6f418957":"code","fa560af5":"code","7df29973":"code","8b9fc806":"code","25e183ac":"code","1efebe77":"code","4b2e66ac":"code","df570471":"code","38431abb":"code","2ecbb81d":"code","98ea1ab9":"code","465555c1":"code","329045c8":"code","045071f6":"code","a79ae385":"code","b314fab2":"code","37cfecba":"code","7aa55174":"code","b61e8da7":"code","db7cb351":"code","845ecbd2":"code","b3de4b53":"code","edc04fe0":"code","59badebe":"code","534f0e33":"code","900b8c74":"code","c92012af":"code","c186044e":"code","3dffb428":"code","f80de5b4":"code","e07db2de":"code","139dc45a":"code","c33265c9":"code","55baf682":"code","0029919e":"code","21af6d79":"code","4eb898b4":"code","60309404":"code","3ad6c3ae":"code","100e7713":"code","97d67c32":"code","3151422c":"code","2c044919":"code","cb69e89f":"markdown","37e1ab41":"markdown","300fbd4c":"markdown","2fa2f733":"markdown","57e67046":"markdown","be30ed3a":"markdown","d40b824e":"markdown","d5f5419b":"markdown","043999f7":"markdown","a631f229":"markdown","5cea48a2":"markdown","af8b19d9":"markdown","10c279dd":"markdown","d3ded276":"markdown","b5f56bcb":"markdown","d919bdcb":"markdown","2d544f5e":"markdown"},"source":{"4614f57d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost.sklearn import XGBClassifier\nfrom datetime import datetime\nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6059f3e3":"train=pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/train_users_2.csv.zip')\ntest = pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/test_users.csv.zip')\n#sessions=pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/sessions.csv.zip')\n#countries=pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/countries.csv.zip')\n#age_gender=pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/age_gender_bkts.csv.zip')","b5ed39f1":"Id = 'id' # Submission'da kullanmak \u00fczere id k\u0131sm\u0131n\u0131 de\u011fi\u015fkene atayarak datamdan silece\u011fm.\n\nmysubmission_ID = test.loc[:,Id]\n\ntrain.drop(Id, axis=1, inplace=True)\ntest.drop(Id, axis=1, inplace=True)\n\n# Test ve Train datas\u0131n\u0131 i\u015faretleyebilmek i\u00e7in Train kolonu olu\u015fturdum.\ntrain.loc[:,'Train'] = 1\ntest.loc[:,'Train'] = 0\n\n# Tek bir df \u00fczerinden gitmek i\u00e7in birle\u015ftiriyorum.\n\ndf = pd.concat([train,test], ignore_index=True)\ndf = df.drop(['date_first_booking'], axis=1)","4b80b294":"df.info() # Bo\u015f de\u011feri olan s\u00fctunlar\u0131 belirlemek ve data tiplerini anlamak i\u00e7in info'ya bak\u0131yorum. ","94238da0":"train.info() ","80d543e9":"test.info()","c3614fc1":"train.describe()","2af1398b":"dft=df[df['Train']==1]","7b1978a1":"df.drop(dft[(dft['age']<=17) & (dft['country_destination']=='NDF')].sort_values(by=['age']).index, inplace=True)#18 ya\u015f\u0131ndan k\u00fc\u00e7\u00fck ve bir yere gitmemi\u015f ki\u015fileri kald\u0131rd\u0131m ","6f418957":"df.loc[df['age']<=17, 'age']=18 # 18 ya\u015f\u0131ndan k\u00fc\u00e7\u00fck ve bir yere gidebilmi\u015f ki\u015filer kald\u0131, gitmeyen herkesi datamdan kald\u0131rd\u0131\u011f\u0131m i\u00e7in. \n                                #K\u00fc\u00e7\u00fck g\u00f6r\u00fcnen ki\u015fileri 18 ya\u015f\u0131na getirdim.","fa560af5":"def ageconverter(age):\n    if (age<1997) & (age>1000):\n        return (2014-age)\n    else:\n        return age","7df29973":"df['aged'] =df['age'].apply(ageconverter) #yeni bir s\u00fctuna ald\u0131m 'age' \u00f6zelli\u011fini\n","8b9fc806":"df.loc[df['aged']>=1000, 'aged']=np.nan # geride kalan ve ya\u015f\u0131 1997'den b\u00fcy\u00fck ki\u015filerin ya\u015flar\u0131n\u0131 NaN yapt\u0131m.","25e183ac":"df['aged'].describe() ","1efebe77":"plt.figure(figsize=(30,15))\nsns.countplot(x='aged', data=df)","4b2e66ac":"df.loc[df['aged']>=85, 'aged']=np.nan #grafi\u011fe bak\u0131nca 85'ten sonras\u0131n\u0131 almamaya karar verdim, onlar\u0131 da NaN ile doldurdum.","df570471":"df['aged'].describe()","38431abb":"dft=df[df['Train']==1]\ndft.groupby('affiliate_channel')['aged'].mean()","2ecbb81d":"def agefiller(param):\n    age = param[0]\n    ac = param[1]\n    if pd.isnull(age)==True:\n        if ac == 'api':\n            return 33\n        elif ac== 'content':\n            return 41\n        elif ac== 'direct':\n            return 36\n        elif ac=='other':\n            return 37\n        elif ac== 'remarketing':\n            return 40\n        elif ac== 'sem-brand':\n            return 39\n        elif ac== 'sem-non-brand':\n            return 40\n        elif ac== 'seo':\n            return 35\n    else:\n        return param[0]\n      ","98ea1ab9":"df['aged'] =df[['aged', 'affiliate_channel']].apply(agefiller, axis=1)","465555c1":"df['aged'].describe()","329045c8":"df['aged']=df['aged'].astype(int) # say\u0131lar\u0131 integer'a \u00e7evirdim daha okunabilir olmas\u0131 i\u00e7in.\ndf = df.drop(['age'], axis=1)","045071f6":"df.isnull().sum() # test datas\u0131 d\u0131\u015f\u0131nda hala bo\u015f h\u00fccresi olan 'first_affiliate_tracked' g\u00f6r\u00fcn\u00fcyor.","a79ae385":"dft=df[df['Train']==1]\ndft.pivot_table(values='gender',index='affiliate_channel', columns='first_affiliate_tracked',aggfunc='count')","b314fab2":"def fatfiller(param):\n    fat= param[0]\n    ac = param[1]\n    if pd.isnull(fat)==True:\n        if ac == 'seo':\n            return 'linked'\n        elif ac== 'sem-non-brand':\n            return 'omg'\n        else:\n            return 'untracked'\n    else:\n        return param[0]","37cfecba":"df['first_affiliate_tracked'] =df[['first_affiliate_tracked', 'affiliate_channel']].apply(fatfiller, axis=1)","7aa55174":"df['first_browser'].replace('-unknown-',np.nan,inplace=True)","b61e8da7":"dft.pivot_table(values='language',index='first_browser', columns='first_device_type',aggfunc='count')","db7cb351":"def fbfiller(param):\n    fb= param[0]\n    fdt = param[1]\n    if pd.isnull(fb)==True:\n        if fdt == 'Android Phone':\n            return 'Android Browser'\n        elif fdt =='Android Tablet':\n            return 'IE'\n        elif fdt =='SmartPhone (Other)':\n            return 'BlackBerry Browser'\n        elif fdt =='iPad':\n            return 'Mobile Safari'\n        elif fdt =='iPhone':\n            return 'Mobile Safari'\n        elif fdt =='Mac Desktop':\n            return 'Safari'\n        else:\n            return 'Chrome'\n    else:\n        return param[0]","845ecbd2":"df['first_browser'] =df[['first_browser', 'first_device_type']].apply(fbfiller, axis=1) # fonksiyona g\u00f6re datam\u0131 doldurdum.","b3de4b53":"first_active_date =[]\nfor i in df['timestamp_first_active']:\n    d = datetime.strptime(str(i),'%Y%m%d%H%M%S')\n    day_string = d.strftime('%Y-%m-%d')\n    first_active_date.append(day_string)","edc04fe0":"first_active_time =[]\nfor i in df['timestamp_first_active']:\n    d = datetime.strptime(str(i),'%Y%m%d%H%M%S')\n    time_string = d.strftime('%H:%M:%S')\n    first_active_time.append(time_string)\n    ","59badebe":"df['first_active_date']=first_active_date # timestamp_first_active'den first active date ve time'\u0131 ay\u0131rarak ayr\u0131 iki s\u00fctun olu\u015fturdum\ndf['first_active_time']=first_active_time\ndf=df.drop(['timestamp_first_active'], axis=1)","534f0e33":"fad = np.vstack(df['first_active_date'].astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\ndf['fad_year'] = fad[:, 0] # Y\u0131l - ay - g\u00fcn olarak ay\u0131r\u0131yorum\ndf['fad_month'] = fad[:, 1]\ndf['fad_day'] = fad[:, 2]\ndf = df.drop(['first_active_date'], axis=1)","900b8c74":"fad = np.vstack(df['first_active_time'].astype(str).apply(lambda x: list(map(int, x.split(':')))).values)\ndf['fad_hour'] = fad[:, 0] # saati ayr\u0131 bir s\u00fctuna ald\u0131m\ndf = df.drop(['first_active_time'], axis=1)","c92012af":"dac = np.vstack(df['date_account_created'].astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\ndf['dac_year'] = dac[:, 0] #airbng hesab\u0131n\u0131n ilk olu\u015fturdu\u011fu y\u0131l-ay-g\u00fcn s\u00fctunlar\u0131 olu\u015fturuyorum.\ndf['dac_month'] = dac[:, 1]\ndf['dac_day'] = dac[:, 2]\ndf = df.drop(['date_account_created'], axis=1)","c186044e":"df.select_dtypes(\"object\").columns","3dffb428":"\nle = LabelEncoder() \ndf['signup_method']= le.fit_transform(df['signup_method']) \ndf['language']= le.fit_transform(df['language'])\ndf['affiliate_channel']= le.fit_transform(df['affiliate_channel'])\ndf['affiliate_provider']= le.fit_transform(df['affiliate_provider'])\ndf['signup_app']= le.fit_transform(df['signup_app'])\ndf['first_device_type']= le.fit_transform(df['first_device_type'])\ndf['gender']= le.fit_transform(df['gender'])\ndf['first_browser']= le.fit_transform(df['first_browser'])\ndf['first_affiliate_tracked']= le.fit_transform(df['first_affiliate_tracked'])","f80de5b4":"df['country_destination'].replace('NDF',0, inplace=True)\ndf['country_destination'].replace('US',1, inplace=True)\ndf['country_destination'].replace('other',2, inplace=True)\ndf['country_destination'].replace('FR',3, inplace=True)\ndf['country_destination'].replace('CA',4, inplace=True)\ndf['country_destination'].replace('GB',5, inplace=True)\ndf['country_destination'].replace('ES',6, inplace=True)\ndf['country_destination'].replace('IT',7, inplace=True)\ndf['country_destination'].replace('PT',8, inplace=True)\ndf['country_destination'].replace('DE',9, inplace=True)\ndf['country_destination'].replace('NL',10, inplace=True)\ndf['country_destination'].replace('AU',11, inplace=True)","e07db2de":"dft=df[df['Train']==1] #train datas\u0131n\u0131 olu\u015fturmak i\u00e7in train olanlar\u0131 al\u0131yorum\nX=dft.drop(['country_destination','Train'], axis=1) #feature tan\u0131mlama\nY = dft['country_destination'] # target tan\u0131mlama","139dc45a":"x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.3, random_state = 42)  #data ay\u0131rma","c33265c9":"from sklearn.tree import DecisionTreeClassifier","55baf682":"dtree=DecisionTreeClassifier()\ndtree.fit(x_train,y_train)\npredictions=dtree.predict(x_test)\nprint(confusion_matrix(y_test, predictions))\nprint(classification_report(y_test, predictions))","0029919e":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(criterion='entropy', max_depth= 8, max_leaf_nodes=30, min_samples_leaf=30, n_estimators= 100, random_state=0)\n\nrfc.fit(x_train, y_train)\nprediction = pd.DataFrame(data=rfc.predict(x_test), index = x_test.index)\nprint(classification_report(y_test, prediction))\n","21af6d79":"xgb = XGBClassifier(max_depth=5, learning_rate=0.2, n_estimators=50,\n                    objective='multi:softprob', subsample=0.6, colsample_bytree=0.6, seed=0, silent=0)                  \n\nxgb.fit(x_train, y_train)","4eb898b4":"y_predicted=xgb.predict(x_test)\nprint(confusion_matrix(y_test, y_predicted))\nprint(classification_report(y_test, y_predicted))","60309404":"pred_country={0:'NDF' ,1:\"US\", 2:\"other\", 3:\"FR\", 4:\"CA\", 5:\"GB\", 6:\"ES\", 7:\"IT\", 8:\"PT\", 9:\"DE\", 10:\"NL\", 11:\"AU\"}","3ad6c3ae":"dftest=df[df['Train']==0]# submission yapmak i\u00e7in haz\u0131rl\u0131k\ntestX=dftest.drop(['country_destination','Train'],axis=1) # submission yapmak i\u00e7in haz\u0131rl\u0131k\ntested = xgb.predict(testX)# submission yapmak i\u00e7in haz\u0131rl\u0131k","100e7713":"results=[]\nfor i in tested:\n    results.append(pred_country[i])\nprint(results)","97d67c32":"len(tested) #Kontrol\nlen(mysubmission_ID)","3151422c":"len(mysubmission_ID)","2c044919":"my_submission = pd.DataFrame({'id': mysubmission_ID, 'country':results})\nmy_submission.to_csv('submission.csv', index=False)","cb69e89f":"Random forest ile:","37e1ab41":"Ya\u015fta hala NaN de\u011ferlerim vard\u0131,di\u011fer hangi \u00f6zelliklerle yak\u0131n ili\u015fkisi var diye bakt\u0131m, en anlaml\u0131 farkl\u0131l\u0131k affiliate_channel'da vard\u0131. Bu \u00f6zelli\u011fe g\u00f6re doldurmak i\u00e7in bir fonksiyon yazd\u0131m ve b\u00f6yle doldurdum. Sadece train datas\u0131n\u0131n de\u011ferlerine bakabilmek i\u00e7in dft dataframe'i olu\u015fturdum.","300fbd4c":"---> \u015eimdi tarih i\u00e7eren kolonlar\u0131 d\u00fczenlemeye ge\u00e7iyorum.","2fa2f733":"\u00dclke adlar\u0131n\u0131 da manuel olarak kendim encode ettim.","57e67046":"Kategorik verileri modelimde kullanabilmek i\u00e7in label encoder kulland\u0131m.","be30ed3a":"#  **4. Model \u00e7al\u0131\u015ft\u0131rma**","d40b824e":"# 3. Encoding","d5f5419b":"---> Ya\u015f datas\u0131nda hatal\u0131 giri\u015fler oldu\u011funu g\u00f6rd\u00fcm. Max=2014 ve min=1 idi. Ya\u015f datas\u0131n\u0131 gidilen \u00fclke ve cinsiyet ile ili\u015fkilendirebilir miyim diye bakt\u0131m. Fark yaratan bir \u015fey yoktu. Airbnb'in kurallar\u0131na g\u00f6re 18 ya\u015f\u0131ndan k\u00fc\u00e7\u00fck ki\u015filer airbnb arac\u0131l\u0131\u011f\u0131 ile bir yerde konaklayamaz. Bu nedenle 18 ya\u015f\u0131ndan k\u00fc\u00e7\u00fck olup, bir yere gitmeyen ki\u015fileri datadan kald\u0131rd\u0131m. Bir yere giden ki\u015filerin ya\u015f\u0131n\u0131 ise 18'e getirdim.\n\n4 basamakl\u0131 girilen ya\u015flar\u0131n yan\u0131s\u0131ra 100-116 aras\u0131nda ya\u015flar da vard\u0131. Train datas\u0131nda 105 ya\u015f\u0131nda bariz bir fazlal\u0131k oldu\u011funu g\u00f6rd\u00fcm. E\u011fer bo\u015f de\u011fer olmasayd\u0131, ya\u015f girmeyenleri sistem otomatik 2015-1910 gibi sabit bir de\u011ferle doldurmu\u015f diye d\u00fc\u015f\u00fcnecektim. Ya\u015f de\u011ferli bir bilgi olaca\u011f\u0131 i\u00e7in outlier yaratabilecek bu de\u011ferleri kald\u0131rd\u0131m. Bir sonraki a\u015famada bu ya\u015f civar\u0131nda olanlar\u0131n ortak bir \u00f6zelli\u011fi var m\u0131 diye bakmay\u0131 planl\u0131yorum.","043999f7":"first_browser'\u0131n first_device_type ile ili\u015fkisine bakt\u0131\u011f\u0131mda ay\u0131rtedici farklar vard\u0131, datam\u0131 buna g\u00f6re dolduraca\u011f\u0131m bir fonksiyon yazd\u0131m.","a631f229":"# 2. Datay\u0131 Anlama","5cea48a2":"** Decision Tree Algoritmas\u0131 ile","af8b19d9":"affiliate_channel'a g\u00f6re bak\u0131nca, NaN de\u011ferleri doldururken seo ise linked, omg ise sem-non-brand, di\u011ferlerini de 'untracked' olarak doldurmaya kadar verdim.","10c279dd":"Date_first_booking =NaN olanlar Country_destination'da \"NDF\" olan ki\u015filer ile ayn\u0131. Bu da airbnb'ye kay\u0131t olup, hen\u00fcz herhangi bir yere gitmeyenleri g\u00f6steriyor. Test datas\u0131nda da bu de\u011ferler bo\u015f; ama\u00e7 test datas\u0131ndaki ki\u015filerin gidecekleri ilk yer bulmak oldu\u011fu i\u00e7in bu da beklenebilecek bir durum. Dolay\u0131s\u0131 ile asl\u0131nda modelde \"Date_first_booking\" kolonunu kullanmak anlaml\u0131 de\u011fil. Yap\u0131labilecek bir \u015fey, sadece bir yere gidenler \u00fczerinden model kurmak. Herhangi ba\u015fka bir \u015feyi de\u011fi\u015ftirmeden, bir de \"NDF\" olanlar\u0131 \u00e7\u0131karmadan ayn\u0131 modeli \u00e7al\u0131\u015ft\u0131rarak sonucun nas\u0131l de\u011fi\u015fti\u011fi g\u00f6zlemlenebilir. Bu modelde NDF olanlar\u0131 dahil ettim. Ayr\u0131ca data_first_booking kullan\u0131labilecek bir feature haline getirilerek de model kurulabilir. \u00d6rn; uygulamada aktif oldu\u011fu tarih ile ilk booking'ini yapt\u0131\u011f\u0131 tarih aras\u0131nda benzerlik olan ki\u015filer benzer davran\u0131\u015flar g\u00f6steriyor mu? sorusunun cevab\u0131 aranabilir.\n\ndate_first_booking haricinde, age ve first_affiliate_tracked kolonlar\u0131nda eksik data g\u00f6r\u00fcl\u00fcyor. Di\u011fer s\u00fctunlar\u0131n unique de\u011ferlerine bakt\u0131\u011f\u0131m\u0131zda, gender'da da \"unknown\" girilen, eksik veri olarak de\u011ferlendirilebilece\u011fimiz data oldu\u011funu g\u00f6rebiliriz.","d3ded276":"1000 - 1996 aras\u0131nda olan ya\u015f de\u011ferlerinde ki\u015filerin do\u011fum tarihlerini ya\u015f olarak girdi\u011fini kabul ettim. 2014 y\u0131l\u0131na ait daha fazla de\u011fer oldu\u011fu i\u00e7in 2014 y\u0131l\u0131nda 18 ya\u015f\u0131nda olmay\u0131 seyahat \u015fart\u0131 gibi ald\u0131m.","b5f56bcb":"# 1. K\u00fct\u00fcphanelerin ve Datan\u0131n Y\u00fcklenmesi","d919bdcb":"Bir de bo\u015f g\u00f6r\u00fcnmese de i\u00e7indeki verilere bak\u0131nca first_browser'da da unknown de\u011ferler oldu\u011funu g\u00f6rd\u00fcm.","2d544f5e":"XGBoosting"}}