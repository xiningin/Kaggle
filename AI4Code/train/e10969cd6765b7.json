{"cell_type":{"e96cae76":"code","4b3cff2b":"code","62db3ca0":"code","ea4fbcb2":"code","0e946274":"code","2b0a10e8":"code","d56b3df8":"code","1a5182d8":"code","4b3ad5d3":"code","9b0ee433":"code","36c12987":"code","c23cdfca":"code","f534541d":"code","f452aaa0":"code","622f0f34":"code","80ab33e7":"code","5aca9149":"code","7f4b6146":"code","a3c6e33c":"code","086e29e4":"code","f04c2167":"code","a8d81f5a":"code","a78bde2e":"code","8a1a9cfc":"code","21cbf188":"code","986da0c8":"code","701ff13f":"code","c4ade924":"code","e143b365":"code","254e89c1":"code","e7148146":"code","2d0ce079":"code","18ce41e1":"markdown","3b7a5afc":"markdown","fae0f2fd":"markdown","b0664d63":"markdown","ff6d503b":"markdown","4e48d769":"markdown","451d2f58":"markdown","591eb85d":"markdown","7f5821a9":"markdown","630ce92b":"markdown","f972120b":"markdown","a35223d1":"markdown","53442785":"markdown","1185d84a":"markdown","18e151f9":"markdown","d1158dc7":"markdown","04388e94":"markdown","aff4eb32":"markdown","a3391b3c":"markdown","7581ddaf":"markdown","2cf01630":"markdown","9a8d203b":"markdown","3de6a017":"markdown","3f3469bf":"markdown","9befd1f6":"markdown","5415e0e3":"markdown","0a8b7486":"markdown","53e5b4e6":"markdown","62a01e1c":"markdown","5398c746":"markdown","65938b9a":"markdown","f6832a84":"markdown","107ac036":"markdown","c15ad391":"markdown","882586fd":"markdown","1089e05d":"markdown","edf1bdf6":"markdown","c129e53d":"markdown","300df176":"markdown","b925e4ce":"markdown","9513b753":"markdown","c70e81bc":"markdown","7fff9312":"markdown","1b3a8833":"markdown"},"source":{"e96cae76":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport itertools\nfrom wordcloud import WordCloud, STOPWORDS","4b3cff2b":"PATH = \"..\/input\/udemy-courses\/\"\n\ndf = pd.read_csv(PATH + 'udemy_courses.csv')","62db3ca0":"print(\"There are {} rows and {} columns in the dataset.\".format(df.shape[0], df.shape[1]))","ea4fbcb2":"df.head(10)","0e946274":"df.tail(10)","2b0a10e8":"df.info()","d56b3df8":"df['course_id'] = df['course_id'].astype(str)","1a5182d8":"df['published_timestamp'] = pd.to_datetime(df['published_timestamp'])\ndf['date_published'] = df.loc[:, 'published_timestamp'].apply(lambda s: s.date())\ndf['year_published'] = df.loc[:, 'published_timestamp'].apply(lambda s: s.year)\ndf['month_published'] = df.loc[:, 'published_timestamp'].apply(lambda s: s.month_name())","4b3ad5d3":"subject = df['subject'].value_counts().reset_index()","9b0ee433":"subject.columns = ['subject', 'counts']","36c12987":"fig = px.bar(\n        subject, \n        x = 'subject', \n        y='counts', \n        color='subject',\n        title='Subject Counts')\nfig.update_layout(showlegend=False, width=600)\nfig.show()","c23cdfca":"subjects = df['subject'].unique()\n\nsubset = df[['date_published','subject']]\nsubset = subset.sort_values('date_published')\ntime_series = subset['date_published'].value_counts().reset_index()\ntime_series.columns = ['Date', 'Counts']\ntime_series = time_series.sort_values('Date')\ntime_series['Cum Count'] = time_series['Counts'].cumsum()\ndummies = pd.get_dummies(subset['subject'])\n\nsubset = subset.join(dummies)\nsubset['Cum Business'] = subset['Business Finance'].cumsum()\nsubset['Cum Software'] = subset['Web Development'].cumsum()\nsubset['Cum Music'] = subset['Musical Instruments'].cumsum()\nsubset['Cum Design'] = subset['Graphic Design'].cumsum()\nsubset_melt = subset.melt(id_vars='date_published', value_vars=['Cum Business', 'Cum Software', 'Cum Design', 'Cum Music'])\n\nfig = make_subplots(\n    rows=2, \n    cols=1,\n    subplot_titles=(\"Time series plot of number of courses\",\n                    \"Time series plot of number of courses by subject\"))\ndf.sort_values('date_published', inplace=True)\nfig.append_trace(go.Scatter(\n    x=time_series['Date'],\n    y=time_series['Cum Count'],\n    name=\"All\",\n    mode='lines'),\n    row=1, col=1)\n\nfig.append_trace(go.Scatter(\n    x=subset['date_published'], \n    y=subset['Cum Business'], \n    mode=\"lines\",\n    name=\"Business\",\n    line=dict(color=\"#617C58\")\n),\n    row=2, col=1)\nfig.append_trace(go.Scatter(\n    x=subset['date_published'], \n    y=subset['Cum Software'], \n    mode=\"lines\",\n    name=\"Software\",\n    line=dict(color=\"#74597D\", dash=\"longdashdot\"),\n),\n    row=2, col=1)\nfig.append_trace(go.Scatter(\n    x=subset['date_published'], \n    y=subset['Cum Design'], \n    \n    mode=\"lines\",\n    name=\"Design\",\n    line=dict(color=\"#C85A17\", dash=\"dash\")\n),\n    row=2, col=1)\nfig.append_trace(go.Scatter(\n    x=subset['date_published'], \n    y=subset['Cum Music'], \n    \n    mode=\"lines\",\n    name=\"Music\",\n  \n    line=dict(color=\"#1884C7\", dash=\"dashdot\")\n),\n    row=2, col=1)\nfig.update_layout(width=700, height=800)\nfig.show()","f534541d":"fig = px.box(\n    df,\n    x='level',\n    y='num_lectures',\n    color='level',\n    title='Boxplot of Level vs Number of Lectures')\nfig.update_yaxes(range=[0,200])\nfig.update_layout(showlegend=False)\nfig.show()","f452aaa0":"fig = px.violin(\n    df,\n    x='level',\n    y='content_duration',\n    color='level',\n    title='Violin plot of Level vs Course Duration')\nfig.update_yaxes(range=[0,40])\nfig.update_layout(showlegend=False)\nfig.show()","622f0f34":"pf_split = df['is_paid'].value_counts().reset_index()\npf_split.columns = ['Is Paid', 'Counts']\nfig = px.pie(pf_split, names='Is Paid', values='Counts', color=['009933','#980000 '], width=500)\nfig.update_layout(title=\"Paid Vs Free Courses\")","80ab33e7":"free_df = df[df['is_paid'] == False]","5aca9149":"top_rated_free = free_df.groupby('subject') \\\n.apply(lambda x: x.sort_values(['num_subscribers'], ascending=False)) \\\n.reset_index(drop=True) \\\n.groupby('subject') \\\n.head(1)\n\ntop_rated_free = top_rated_free[['course_title',\n                                 'content_duration',\n                                 'published_timestamp',\n                                 'num_subscribers',\n                                'subject']]\ntop_rated_free","7f4b6146":"top_subs = df.sort_values(by='num_subscribers', ascending=False).head(5)\ntop_reviews = df.sort_values(by='num_reviews', ascending=False).head(5)\n\nfig = make_subplots(\n    rows=2, \n    cols=1,\n    subplot_titles=(\"Top 5 courses by subscriber count\",\"Top 5 courses by review count\")\n)\nfig.append_trace(go.Bar(\n    y=top_subs['course_title'].values,\n    x=top_subs['num_subscribers'].values,\n    texttemplate = \"%{value:,s}\",\n    marker=dict(color=top_subs['num_subscribers'].values, coloraxis=\"coloraxis\"),\n    textposition = \"inside\",\n    orientation='h'\n), row=1, col=1)\nfig.append_trace(go.Bar(\n    x=top_reviews['course_title'].values,\n    y=top_reviews['num_reviews'].values,\n     marker=dict(color=top_subs['num_reviews'].values, coloraxis=\"coloraxis\"),\n    texttemplate = \"%{value:,s}\",\n    textposition = \"outside\",\n), row=2, col=1)\nfig.update_layout(coloraxis=dict(colorscale='emrld'),height=1200, width=900, showlegend=False)\nfig.show()","a3c6e33c":"fig = make_subplots(\n    rows=4, \n    cols=1,\n    subplot_titles=(\"Price distribution (Skew: {:2f})\".format(df['price'].skew()),\n                    \"Subscriber distribution (Skew: {:2f})\".format(df['num_subscribers'].skew()),\n                    \"Lecture distribution (Skew: {:2f})\".format(df['num_lectures'].skew()),\n                    \"Reviews distribution (Skew: {:2f})\".format(df['num_reviews'].skew())\n))\n\nfig.append_trace(go.Histogram(\nx=df['price'],\nmarker_color='#2B65EC',\nopacity=0.75,\n)\n, row=1, col=1)\n\nfig.append_trace(go.Histogram(\nx=df['num_subscribers'],\nmarker_color='#1589FF',\nopacity=0.75),row=2, col=1)\n\nfig.append_trace(go.Histogram(\nx=df['num_lectures'],\nmarker_color='#6698FF',\nopacity=0.75),row=3, col=1)\n\nfig.append_trace(go.Histogram(\nx=df['num_reviews'],\nmarker_color='#38ACEC',\nopacity=0.75),row=4, col=1)\n\nfig.update_xaxes(title_text=\"Price\", row=1, col=1)\nfig.update_xaxes(title_text=\"Count\", range=[0,30000], row=2, col=1)\nfig.update_xaxes(title_text=\"Count\", range=[0, 200], row=3, col=1)\nfig.update_xaxes(title_text=\"Count\", range=[0, 1000], row=4, col=1)\n\nfig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\nfig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\nfig.update_yaxes(title_text=\"Frequency\", row=3, col=1)\nfig.update_yaxes(title_text=\"Frequency\", row=4, col=1)\n\nfig.update_layout(height=1000, width=1000,showlegend=False)\n\nfig.show(title='Distribution of numerical columns')\n\n\n","086e29e4":"fig = make_subplots(\n    rows=3,\n    cols=1,\n    )\n\nfig.append_trace(go.Scatter(\n    x=df['price'],\n    y=df['num_subscribers'],\n    mode='markers',\n    opacity=0.75,\n    marker_color='#43BFC7',\n), row=1, col=1)\n\nfig.append_trace(go.Scatter(\n    x=df['num_reviews'],\n    y=df['num_subscribers'],\n    mode='markers',\n    opacity=0.75,\n    marker_color='#C74C44',\n), row=2, col=1)\n\nfig.append_trace(go.Scatter(\n    x=df['num_subscribers'],\n    y=df['content_duration'],\n    mode='markers',\n    opacity=0.75,\n    marker_color='#A8C744',\n), row=3, col=1)\n\nfig.update_xaxes(title_text=\"Price\", row=1, col=1)\nfig.update_xaxes(title_text=\"Reviews\", row=2, col=1)\nfig.update_xaxes(title_text=\"Subscribers\", row=3, col=1)\n\nfig.update_yaxes(title_text=\"Subscribers\", row=1, col=1)\nfig.update_yaxes(title_text=\"Subscribers\", row=2, col=1)\nfig.update_yaxes(title_text=\"Duration (hrs)\", row=3, col=1)\n\nfig.update_layout(width=800, height=800, title=\"Graphs plotting relationship between numerical variables\", showlegend=False)\nfig.show()","f04c2167":"comment_words = ''\nstopwords = set(STOPWORDS)\n\nfor s in df.course_title:\n    s = str(s)\n    tokens = s.split()\n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\nwordcloud = WordCloud(width = 800, height = 800, \n            background_color ='black', \n            stopwords = stopwords, \n            min_font_size = 10).generate(comment_words)\nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","a8d81f5a":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler","a78bde2e":"num_cols = ['price', 'num_reviews', 'num_lectures', 'content_duration']\ncat_cols = ['is_paid', 'level', 'subject']\nX_data, y_data = df[num_cols].merge(pd.get_dummies(df[cat_cols]), left_index=True, right_index=True), df['num_subscribers']","8a1a9cfc":"X_train, X_test,  y_train, y_test = train_test_split(\n                                    X_data, y_data, test_size=0.2, random_state=42)\ncol_names = X_train.columns","21cbf188":"scaler = StandardScaler()\nscaler = scaler.fit(X_train) \nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","986da0c8":"model = RandomForestRegressor(n_estimators=500, random_state=42)","701ff13f":"model.fit(X_train, y_train)","c4ade924":"y_train_preds = model.predict(X_train)","e143b365":"print(\"Mean Squared Error on training data is: {:.2f}\".format(mean_squared_error(y_train_preds, y_train)))","254e89c1":"y_pred = model.predict(X_test)","e7148146":"print(\"Mean Squared Error on testing data is: {:.2f}\".format(mean_squared_error(y_pred, y_test)))","2d0ce079":"imp_features = pd.Series(model.feature_importances_, index=col_names).nlargest(5)\npx.bar(x=imp_features.index, y=imp_features.values,\n       labels={'x':\"Features\", 'y':\"Importance Criterion\"},\n       color=imp_features.index,\n       color_discrete_sequence=px.colors.qualitative.T10,\n       title=\"Feature Importance\")","18ce41e1":"## Wordcloud","3b7a5afc":"Again, the median seems to be the same over all levels. However, for expert level courses, we see that there are again fewer data points towards the higher end of the boxplot as compared to the others. This goes against our initial hypothesis. Maybe these were deemed to be expert level courses because of the degree of toughness of the material as well as the smaller duration of lectures?","fae0f2fd":"Since we do not have information regarding reviews, a decent measure of 'goodness' could be the number of people subscribed to a course. Let's have a look at the top free course per subject based on subscriber count.","b0664d63":"There is heavy positive skew for 3 out of the 4 numeric columns. This tells us that the mode is far away from the mean. A reason for this could be the fact that there are outliers which have extreme values. ","ff6d503b":"### Model Building","4e48d769":"In this part of the notebook, we will try to predict subscriber count using the data we have.","451d2f58":"## Distribution of numeric values","591eb85d":"We see that the number of reviews plays a massive role in predicting subscriber count. Interestingly, price does not seem to be a big factor. One reason for this could be the fact that most courses on Udemy are quite cheap. \n\nI feel that having information on course ratings could have been another major factor in subsriber count. It would be interesting to see how much the model can be improved. I've left that as an exercise.\n\nI hope all of you enjoyed this notebook. Do tell me if you are able to find out more data and are able to build better models. \ud83d\ude01","7f5821a9":"## Predicting subscriber count","630ce92b":"## Importing libraries","f972120b":"## Check for null values and data type","a35223d1":"A few useful relationships to look at between numeric columns are price vs num_subscribers, num_reviews vs num_subscribers and num_subscribers vs course_duration.\n","53442785":"We see that courses are dominated by Web Dev and Business. Not too many surprises there as Information Technology and Business\/Management are two of the most lucrative industries to be working for.","1185d84a":"The most popular words seems to be trigger words like \"learn\", \"beginner\", \"complete\" to get customers hooked onto coruses. \"trading\", \"javascript\", \"guitar\", \"photoshop\" seem to be a few more popular non trigger words.","18e151f9":"### Importing libraries","d1158dc7":"Standard scaler is applied only on the numerical features.","04388e94":"## Free vs Paid split","aff4eb32":"### Splitting into train and test data","a3391b3c":"## Best free courses","7581ddaf":"The median among the groups seems to be very close to each other. However, expert level courses seems to have fewer number of lectures towards the higher quantiles.","2cf01630":"## Popular\/Engaging Courses","9a8d203b":"### Applying standard scaler","3de6a017":"## Relationship between numeric columns","3f3469bf":"Let's try to look at the most popular and engaging courses over all the subject areas. We will use subscriber count as well as reviews as measurements to plot this.","9befd1f6":"Udemy is one of the most popular E-learning platforms in the world. As mentioned on their website, the platform has over 75,000 instructors, **150,000 courses**, **250 million enrollments** and **33 million minutes** worth of content. This notebook takes an in-depth look into records of the MOOC platform.","5415e0e3":"We pick a random forest regressor of 500 trees to predict subscriber count.","0a8b7486":"## Plotting level vs number of lectures\n\nLet's try to capture the relationship between the level of difficultly of a course versus the number of lectures. Ideally, for beginner courses there should be slightly higher number of lectures so as to help develop intuition about the subject matter.","53e5b4e6":"## Overview","62a01e1c":"## Feature Importance","5398c746":"No surprises that all 10 entries are programming courses. Programming is considered one of the most important skills to learn in the 21st century.","65938b9a":"Let us look at the distribution of numeric values present in our data.","f6832a84":"### Choosing our columns of interest","107ac036":"The onset of 2016 saw a rise in the number of software\/programming courses. So much so that, it overtook Business just before 2017. Overall, all four categories seem to have had a good rise post 2016.","c15ad391":"Here we try to remove some errors in our data. There were a few misplaced values, wrong data types and unsatisfactory data formats.\n\nEDIT: According to a more recent version of the data, a lot of the issues have been fixed. Hence, a lot of code present in this section in an earlier version has been removed.","882586fd":"## Plotting level vs course duration\n\nIntuitively,course duration for expert level courses should be higher due to the difficulty of the course material.","1089e05d":"There seems to be a slight positive trend for reviews vs subscribers. One hypothesis to test out is whether number of reviews influences a prospective customer's decision to by the course. This hypothesis would be more tailored if we also had data about ratings. Unfortunately the dataset does not provide us with it so we have to make do with what we have.","edf1bdf6":"Some cool things to note about the above table:\n* All courses have a difficulty level of either beginner or all.\n* All courses were pubished during the earlier days of the platform (Udemy Series B funding happened in 2012).\n* All courses have relatively less content duration (HTML 5 is higher but still relatively low compared to other technical courses)\n","c129e53d":"## Head and Tail","300df176":"## Time Series of growth of courses by subject","b925e4ce":"There is no such thing as a free lunch. 8.43% of our data disagrees. Moving on,","9513b753":"We subset our data and derive dummy data for the categorical variables.","c70e81bc":"While our MSE is quite high, it seems that we haven't really overfit the data. It is likely that we will need better features in order to build predictive power.","7fff9312":"## Exploring subjects","1b3a8833":"## Data Cleaning"}}