{"cell_type":{"04a8b446":"code","ea480a78":"code","a6d0708e":"code","2f7e79f9":"code","80f0aade":"code","823854eb":"code","340e93db":"code","1ddb4534":"code","67a6526e":"code","b4713eed":"code","fd21f6ba":"code","62e87ce9":"code","e5a07199":"code","5f1e6c7b":"code","bbc7c43a":"code","e85bc539":"code","d326e68b":"code","6abe6275":"code","b0cb22d4":"code","56f0fb3d":"code","bab69e98":"markdown","0e37ac03":"markdown","36e347bf":"markdown","9570740f":"markdown","b6f945e3":"markdown","e760f125":"markdown"},"source":{"04a8b446":"#Install Cellpose, configure dependencies and check GPU access\n!pip install cellpose\n\n#disabled installation and import of mxnet as pytorch is the default neural net\nimport numpy as np\nimport time, os, sys, random\nfrom urllib.parse import urlparse\nimport skimage.io\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\nmpl.rcParams['figure.dpi'] = 300\n\nfrom urllib.parse import urlparse\nimport shutil\n\n\nprint (\"Downloading Models\")\nfrom cellpose import models\n\n#https:\/\/stackoverflow.com\/questions\/8924173\/how-do-i-print-bold-text-in-python\nBOLD = '\\033[1m'\nUNDERLINE = '\\033[4m'\nEND = '\\033[0m'\n\n#Check if colab notebook instance has GPU access\nif models.use_gpu()==False: \n  #Warnings from the ZeroCost StarDist notebook\n  print(BOLD+UNDERLINE+'You do not have GPU access.'+END)\n  print('Did you change your runtime ?') \n  print('If the runtime setting is correct then Google did not allocate a GPU for your session')\n  print('Expect slow performance. To access GPU try reconnecting later')\n  use_GPU=False\nelse:\n  print(BOLD+UNDERLINE+\"You have access to the GPU.\"+END+\"\\nDetails are:\")\n  print(\"*************************************************\")\n  !nvidia-smi\n  use_GPU=True\n\nprint(\"*************************************************\")\nprint(\"Libraries imported and configured\")","ea480a78":"#specify training directories\n\ntrain_input_dir = \"..\/input\/labeled-images\/labeled_images\" \ntrain_save_dir = \"\/kaggle\/working\"","a6d0708e":"#Load images from training input directory\n\ntrain_images=[]\ntrain_masks=[]\ncount=0\nfor _, _, files in os.walk(train_input_dir):\n    files.sort()\n    for f in files:\n        dat = np.load(train_input_dir + '\/' + f, allow_pickle=True).item()\n        train_images.append(dat['img'])\n        train_masks.append(dat['masks'])\n        count+=1\nprint('Loaded', count, 'images.')","2f7e79f9":"# show an example mask\n\nplt.imshow(train_masks[2]); plt.axis('off')","80f0aade":"#and the corresponding image\n\nimage = dat['img']\nplt.imshow(image[:,:]); plt.axis('off')","823854eb":"#use cyto model provided by cellpose as a start\n\nimport pathlib\nmodel_type=\"cyto\"\ncp_dir = pathlib.Path.home().joinpath('.cellpose')\nmodel_dir = cp_dir.joinpath('models')\n\ntorch=True\ntorch_str = ['','torch'][torch]\n\nold_pretrained_model=[os.fspath(model_dir.joinpath('%s%s_%d'%(model_type,torch_str,j))) for j in range(4)]","340e93db":"#use a beforehand created model as a start\n\nold_pretrained_model='..\/input\/old-weights-cellpose\/cellpose_residual_on_style_on_concatenation_off_working_2021_03_07_08_07_33.837598'","1ddb4534":"#training based on old_pretrained_model and training data as defined above\n#here alos hyperparameters such as learning_rate, number of epoch etc. can be specified\n\nmodel=models.CellposeModel(pretrained_model=old_pretrained_model, diam_mean=50)\nmodel.train(train_data=train_images, train_labels=train_masks, train_files=None, \n              test_data=None, test_labels=None, test_files=None,\n              channels=[1,2], normalize=True, pretrained_model=old_pretrained_model, \n              save_path=train_save_dir, save_every=50,\n              learning_rate=0.1, n_epochs=1, momentum=0.9, weight_decay=0.00001, batch_size=8, rescale=True)","67a6526e":"#Directory path containing the images \n#Existing Masks directory will be deleted. (Does not read images in subfolders)\nInput_Directory = \"..\/input\/cell-images\/HEK_merg\/HEK_merg\" \ninput_dir = os.path.join(Input_Directory, \"\") #adds separator to the end regardless if path has it or not\n\n#Enter image extension here to read only files\/images of specified extension (.tif,.jpg..) \nimage_format = \".png\"\n\nsave_dir = \"\/kaggle\/working\/annotations\"\n\n#Save Directory will be created in the input path under Masks\n\n\n# r=root, d=directories, f = files\nfiles=[]\n\nfor r, d, f in os.walk(input_dir):\n    for fil in f:\n      if (image_format):\n        \n        if fil.endswith(image_format):\n          files.append(os.path.join(r, fil))\n      else:\n        files.append(os.path.join(r, fil))\n    break #only read the root directory; can change this to include levels\nfiles.sort()\nif(len(files)==0):\n  print(\"Number of images loaded: %d.\" %(len(files)))\n  print(\"Cannot read image files. Check if folder has images\")\nelse:\n  print(\"Number of images loaded: %d.\" %(len(files)))","b4713eed":"#Read and Load all the images\n#Show a random image as an example\n\nimgs=[] #store all images\n#Read images\nfor f in files:\n  im=skimage.io.imread(f)\n  n_dim=len(im.shape) #shape of image\n  dim=im.shape #dimensions of image\n  channel=min(dim) #channel will be dimension with min value usually\n  channel_position=dim.index(channel)\n  #if no of dim is 3 and channel is first index, swap channel to last index\n  if n_dim==3 and channel_position==0: \n    #print(dim)\n    im=im.transpose(1,2,0)\n    dim=im.shape\n    #print(\"Shape changed\")\n  #print(dim)\n  imgs.append(im)\n\nnimg = len(imgs)\nprint(\"No of images loaded are: \", nimg)\n\nprint(\"Example Image:\")\n\nrandom_idx = random.choice(range(len(imgs)))\nx=imgs[random_idx]\nn_dim=len(x.shape)\nfile_name=os.path.basename(files[random_idx])\nprint(file_name+\" has \"+str(n_dim)+\" dimensions\/s\")\nif n_dim==3:\n  channel_image=x.shape[2]\n  fig, axs = plt.subplots(1, channel_image,figsize=(3,3))\n  print(\"Image: %s\" %(file_name))\n  for channel in range(channel_image):\n      axs[channel].imshow(x[:,:,channel])\n      axs[channel].set_title('Channel '+str(channel+1),size=5)\n      axs[channel].axis('off')\n  fig.tight_layout()\nelif n_dim==2:\n  print(\"One Channel\")\n  plt.imshow(x)\nelse:\n  print(\"Channel number invalid or dimensions wrong. Image shape is: \"+str(x.shape))","fd21f6ba":"#Use this if the original cellpose model has to be used instead of the pretrained one for the pretrained model skip this step\n\n#If the image has only one channel, leave it as 0\nsegment_channel=0\n\nmodel_type=\"cyto\"\n\n# Diameter of cell (pixels):\n# Enter 0 if you don't know and cellpose will estimate it automatically. Can define this later as well.\ndiameter=0\n\n# channels = [cytoplasm, nucleus]\nchannels=[segment_channel,0]\n\n# DEFINE CELLPOSE MODEL\nmodel = models.Cellpose(gpu=use_GPU, model_type=model_type)\n\n# if diameter is set to None, the size of the cells is estimated on a per image basis\n# you can set the average cell `diameter` in pixels yourself (recommended) \n# diameter can be a list or a single number for all images\nif diameter is 0:\n  diameter = None\n  print(\"Diameter is set to None. The size of the cells will be estimated on a per image basis\")","62e87ce9":"# provide path for the pretrained model or use an old model instead\npretrained_model='.\/models\/cellpose_residual_on_style_on_concatenation_off_working_2021_03_04_09_11_32.494127'","e5a07199":"# create model to perform the inference\nmodel2=models.CellposeModel(pretrained_model=old_pretrained_model, gpu=use_GPU, diam_mean=50)","5f1e6c7b":"#test model an an example image\n#this can also be used to test the parameters of the model i.e. flow_threshold and cellprob_threshold\n\nfrom skimage.util import img_as_ubyte\n\nImage_Number =  3 #note that this starts at zero (duh)\ndiameter = 50\n\nflow_threshold = 0.75\ncellprob_threshold = 0.0\n\nif diameter is 0:\n  diameter = None\n\ntry:\n    image = imgs[Image_Number]\nexcept IndexError as i:\n   print(\"Image number does not exist\",i)\n   print(\"Actual no of images in folder: \",len(imgs))\nprint(\"Image: %s\" %(os.path.splitext(os.path.basename(files[Image_Number]))[0]))\nimg1=imgs[Image_Number]\n\nimport cv2\n\nmasks, flows, styles = model2.eval(img1, diameter=diameter, flow_threshold=flow_threshold, cellprob_threshold=cellprob_threshold, channels=[2,3])\n\n# DISPLAY RESULTS\nfrom cellpose import plot\nmaski = masks\nflowi = flows[0]\n\n#convert to 8-bit if not so it can display properly in the graph\nif img1.dtype!='uint8':\n  img1=img_as_ubyte(img1)\n\nfig = plt.figure(figsize=(12,5))\nplot.show_segmentation(fig, img1, maski, flowi, channels=[2,3])\nplt.tight_layout()\nplt.show()","bbc7c43a":"#define channels (again if not done above)\nsegment_channel = 2\nnucleus_channel = 3\n\nchannels = [2,3]","e85bc539":"#create output directories\nos.makedirs('..\/working\/annotations')\nos.makedirs('..\/working\/annotations\/mergeMasks')","d326e68b":"#Run Cellpose on folder of images\nfrom cellpose import utils\nfrom skimage.util import img_as_ubyte\nfrom tqdm import tqdm\nimport time\n\nprint(\"Running segmentation on channel %s\" %(segment_channel))\nif diameter is None:\n  print(\"Diameter will be estimated from the image\/s\")\nelse:\n  print(f\"Cellpose will use a diameter of {diameter}\")\n\nprint(f\"Using a flow threshold of: {flow_threshold} and a cell probability threshold of: {cellprob_threshold}\")\n\nbatch_size = 20\n\n#evaluation has to be done in batches due to RAM restrictions\n#the commented bound in the line below is used if all images have to be annotated\nfor i in range(1): #(len(imgs)\/\/batch_size + 1):\n  print(\"\\n**********\",\"BATCH NUMBER:\",i+1,'\/',len(imgs)\/\/batch_size + 1,\"**********\")\n  if (i+1)*batch_size > len(imgs):\n      imgs_batch = imgs[i*batch_size:]  \n      masks, _, _ = model2.eval(imgs_batch, diameter=diameter, flow_threshold=flow_threshold, cellprob_threshold=cellprob_threshold, channels=channels)   \n  else:\n      imgs_batch = imgs[i*batch_size:(i+1)*batch_size]\n      masks, _, _ = model2.eval(imgs_batch, diameter=diameter, flow_threshold=flow_threshold, cellprob_threshold=cellprob_threshold, channels=channels)\n\n\n  #save images in folder with the diameter value used in cellpose\n  print(\"Segmentation Done. Saving Masks now\")\n\n  with tqdm(total=len(masks)) as pbar:\n    start = time.time()\n    for idx,mask in enumerate(masks):\n\n      img = imgs[i*batch_size+idx]\n\n      if img.ndim>2:\n            img = img.astype(np.float32).mean(axis=-1)\n      else:\n          img = img.astype(np.float32)\n      img = utils.normalize99(img)\n      img -= img.min()\n      img \/= img.max()\n\n      mergeMasks = np.zeros((img.shape[0], img.shape[1], 3), dtype=int)\n\n      file_name=os.path.splitext(os.path.basename(files[i*batch_size+idx]))[0]\n        \n      j = 0\n      for n in range(int(mask.max())):\n          singleMask = np.zeros((img.shape[0], img.shape[1], 3), dtype=int)\n          ipix = (mask==n+1).nonzero()\n          mergeMasks[ipix[0],ipix[1],:] = 255.0  \n          singleMask[ipix[0],ipix[1],:] = 255.0  \n          j+=1\n          \n          mask_output_name=save_dir+\"\/\"+file_name+\"_mask_out_\"+str(j)+\".png\"\n          skimage.io.imsave(mask_output_name, img_as_ubyte(singleMask), check_contrast=False)\n\n      mask_output_name=save_dir+\"\/mergeMasks\/\"+file_name+\"_mergeMasks\"+\".png\"\n      #skimage.io.imsave(mask_output_name, img_as_ubyte(mergeMasks), check_contrast=False) #pure white\n      mask=mask.astype(np.uint16)\n      skimage.io.imsave(mask_output_name, mask, check_contrast=False)\n      pbar.update(1)\n  end = time.time()\n  print('Saving', len(masks), 'masks took', round(end - start,2), 'seconds.')","6abe6275":"# check the output of the above step\n\nimport pylab\npylab.rcParams['figure.figsize'] = (2.0, 2.0)\n\nfile_name = \"HEK_0019_merged\"\n\nmergeMasks=skimage.io.imread(save_dir + \"\/mergeMasks\/\" + file_name + \"_mergeMasks\"+\".png\")\nplt.imshow(mergeMasks); plt.axis('off')","b0cb22d4":"#compare to image\n\nimage=skimage.io.imread(input_dir + file_name + \".png\")\nplt.imshow(image); plt.axis('off')","56f0fb3d":"# create zip file to download a large chunk of data from kaggle (if needed)\n\n!zip -r annotations_HEK.zip \"..\/working\"","bab69e98":"Define the model to start from:","0e37ac03":"Run cellpose on the images loaded above and save the annotations created in this way.","36e347bf":"# Train Cellpose\n\n1. Train the cellpose algorithm on segmented data created using e.g. the cellpose GUI. The cellpose algorithm was already trained on a general dataset containing various cells. Here, it was trained additionally on our specific celldata. This was found to enhance the performance, although it was already okay before.\n\n2. After the training the cellpose algorithm can be run on a folder of input images to create annotation files that then be used for e.g. the Mask RCNN model. In this notebook also the option to run the cellpose algorithm without pretraining is implemented.\n\nThis code is based on https:\/\/colab.research.google.com\/github\/MouseLand\/cellpose\/blob\/master\/notebooks\/Cellpose_2D_v0_1.ipynb","9570740f":"# Training","b6f945e3":"# Run on input images\n\nRun the cellpose algorithm on the images loaded above to create annotation files. These consist of a binary mask for every detected cell and merged image containing all binary images. ","e760f125":"# Inference\n\nBased on the above trained model check the performance and create the annotations used as input for the mask RCNN model.\n\nFor that first of all load the images."}}