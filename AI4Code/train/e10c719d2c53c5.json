{"cell_type":{"427b82a2":"code","e5f34ff9":"code","e9b542db":"code","e2b07097":"code","7319a9eb":"code","ffcc9293":"code","d4f10e51":"code","b9edc925":"code","6eac3919":"code","61ff44e7":"code","b2d5a1f3":"code","69490b59":"code","222e031a":"code","2bbcdc2b":"code","0e8c4e38":"code","82cb9262":"code","38e6fa36":"code","08afde9c":"code","f0d91b13":"code","96e71c00":"code","a6606faa":"code","388601a7":"code","11da0442":"code","1f803be7":"code","175e5a5f":"code","979db146":"code","f90eeaf4":"code","6fa1de91":"markdown","576b3c0f":"markdown","64347a86":"markdown","25709a57":"markdown","515d7f40":"markdown","71bdfdfa":"markdown","1548b04e":"markdown","3923902d":"markdown","3d6e6ced":"markdown","b3231753":"markdown","cb159703":"markdown","cd271a23":"markdown"},"source":{"427b82a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e5f34ff9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\nimport matplotlib.image as implt\nfrom PIL import Image \nimport seaborn as sns\nimport cv2 as cs2\nimport os\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nimport scipy.ndimage\nimport pandas as pd\nimport tensorflow as tf\nfrom keras_preprocessing.image import ImageDataGenerator\n\nimport warnings\nwarnings.filterwarnings('ignore')","e9b542db":"train_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\"\ntest_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\"\n\ntrain_horses = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\/horses\"\ntest_horses = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/horses\"\n\ntrain_humans = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\/humans\"\ntest_humans = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/humans\"","e2b07097":"#Paramters that are important in this notebook.\nimg_size = 28","7319a9eb":"\n\nhumans_train = []\nhorses_train = []\nlabel = []\n\nfor i in os.listdir(train_humans): # all train human images\n    if os.path.isfile(train_path + \"\/humans\/\" + i): # check image in file\n        humans = Image.open(train_path + \"\/humans\/\" + i).convert(\"L\") # converting grey scale \n        humans = humans.resize((img_size,img_size), Image.ANTIALIAS) # resizing to image suze agree before\n        humans = np.asarray(humans)\/255 # bit format\n        humans_train.append(humans)\n        label.append(1)\n        \nfor i in os.listdir(train_horses): # all train horse images\n    if os.path.isfile(train_path + \"\/horses\/\" + i): # check image in file\n        horses = Image.open(train_path + \"\/horses\/\" + i).convert(\"L\") # converting grey scale \n        horses = horses.resize((img_size,img_size), Image.ANTIALIAS) # resizing to image suze agree before\n        horses = np.asarray(horses)\/255 # bit format\n        horses_train.append(horses)\n        label.append(0)","ffcc9293":"x_train = np.concatenate((humans_train,horses_train),axis=0) # training dataset\nx_train_label = np.asarray(label) # label array containing 0 and 1\nx_train_label = x_train_label.reshape(x_train_label.shape[0],1)\n\nprint(\"humans:\",np.shape(humans_train) , \"horses:\",np.shape(horses_train))\nprint(\"train_dataset:\",np.shape(x_train), \"train_values:\",np.shape(x_train_label))","d4f10e51":"#x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]) # flatten 3D image array to 2D, count: 50*50 = 2500\ny_train=x_train_label","b9edc925":"humans_test = []\nhorses_test = []\nlabel = []\n\nfor i in os.listdir(test_humans): # all train human images\n    if os.path.isfile(test_path + \"\/humans\/\" + i): # check image in file\n        humans = Image.open(test_path + \"\/humans\/\" + i).convert(\"L\") # converting grey scale \n        humans = humans.resize((img_size,img_size), Image.ANTIALIAS) # resizing to 50,50\n        humans = np.asarray(humans)\/255 # bit format\n        humans_test.append(humans)\n        label.append(1)\n        \nfor i in os.listdir(test_horses): # all train horse images\n    if os.path.isfile(test_path + \"\/horses\/\" + i): # check image in file\n        horses = Image.open(test_path + \"\/horses\/\" + i).convert(\"L\") # converting grey scale \n        horses = horses.resize((img_size,img_size), Image.ANTIALIAS) # resizing to 50,50\n        horses = np.asarray(horses)\/255 # bit format\n        horses_test.append(horses)\n        label.append(0)","6eac3919":"x_test = np.concatenate((humans_test,horses_test),axis=0) # training dataset\nx_test_label = np.asarray(label) # label array containing 0 and 1\nx_test_label = x_test_label.reshape(x_test_label.shape[0],1)\n\nprint(\"humans:\",np.shape(humans_test) , \"horses:\",np.shape(horses_test))\nprint(\"test_dataset:\",np.shape(x_test), \"test_values:\",np.shape(x_test_label))","61ff44e7":"y_test=x_test_label","b2d5a1f3":"#what is the shape of all these tensors.\nprint(\"x train: \",x_train.shape)\nprint(\"x test: \",x_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","69490b59":"x = np.concatenate((x_train,x_test),axis=0) # count: 1027+256= 1283  | train_data\n# x.shape: \n#   output = (1283,50,50)\ny = np.concatenate((x_train_label,x_test_label),axis=0) # count: 1027+256= 1283 | test_data\n#x = x.reshape(x.shape[0],x.shape[1]*x.shape[2]) # flatten 3D image array to 2D, count: 50*50 = 2500\nprint(\"images:\",np.shape(x), \"labels:\",np.shape(y))","222e031a":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\nnumber_of_train = X_train.shape[0]\nnumber_of_test = X_test.shape[0]\n\nprint(\"Train Number: \", number_of_train)\nprint(\"Test Number: \", number_of_test)","2bbcdc2b":"#here we confirm the shape of the tensors mix and splited.\nx_train = X_train\nx_test = X_test\ny_train = y_train\ny_test = y_test\nprint(\"x train: \",x_train.shape)\nprint(\"x test: \",x_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","0e8c4e38":"y_test[3,0]","82cb9262":"#En este caso selecionamos una sola neurona de regresion logistica.\n# Cargamos bibliotecas importantes\nfrom sklearn.linear_model import LogisticRegression\n# Creamos nuestro objeto de modelo de regresi\u00f3n log\u00edstica\nreg_log = LogisticRegression()\n# y lo entrenamos con los datos\n#X_train=x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]) # flatten 3D image array to 2D, count: 50*50 = 2500\n\nreg_log.fit(x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]), y_train.reshape(y_train.shape[0]))\n","38e6fa36":"print((reg_log.predict(x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])) == y_train.reshape(y_train.shape[0])).sum(), ' \/ ', y_train.reshape(y_train.shape[0]).shape[0], ' clasificados correctamente en aprendizaje')\n\nprint((reg_log.predict(x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])) == y_train.reshape(y_train.shape[0])).sum()\/ y_train.reshape(y_train.shape[0]).shape[0], '%')","08afde9c":"print((reg_log.predict(x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])) == y_test.reshape(y_test.shape[0])).sum(), ' \/ ', y_test.reshape(y_test.shape[0]).shape[0], ' clasificados correctamente en la prueba')\n\nprint((reg_log.predict(x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])) == y_test.reshape(y_test.shape[0])).sum()\/ y_test.reshape(y_test.shape[0]).shape[0], '%')","f0d91b13":"# tamano de la imagen de entrada\n\n# definicion del modelo Perceptron\nmodel = keras.Sequential(\n    [\n        layers.Flatten(input_shape=(img_size,img_size)),\n        layers.Dense(img_size*img_size\/2, activation=\"relu\"),\n        layers.Dense(100, activation=\"relu\"),\n        layers.Dense(10, activation=\"softmax\"),\n    ]\n)\n\n# Construir el modelo y ver la arquitectura\nmodel.build((img_size,img_size))\nmodel.summary()","96e71c00":"# Definir los parametros de optimizacion y perdida del modelo (con CrossValidation)\noptimizer = keras.optimizers.Adam(learning_rate=0.01)\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n# ejecutar training\nhistory = model.fit(x_train, y_train, epochs=70, batch_size=100, verbose=1, validation_split=0.2, shuffle=True)","a6606faa":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1.1])\nplt.show()\n\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1.1])\nplt.show()","388601a7":"\n#train_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\"\n#test_path = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\"\n\n\n\n# configuracion de entrenamiento\ntrain_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\n\n\n\n# generador\ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=(img_size,img_size),\n    class_mode='categorical')\n\n# configuacion de pruebas (test set)\ntest_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    #rotation_range=10,\n    #width_shift_range=0.2,\n    #height_shift_range=0.2\n)\n\n# generador\ntest_generator = test_datagen.flow_from_directory(\n        test_path,\n        target_size=(img_size,img_size),\n        class_mode='categorical')","11da0442":"print(x_test.shape,' tama\u00f1o de x test set')\nprint(x_train.shape,' tama\u00f1o de x traing set')","1f803be7":"\n\n\nmodelo = keras.Sequential(\n    [\n        keras.Input(shape=(img_size,img_size, 3)),\n        # =============================\n        # ...CAPAS CONVOLUCIONALES...\n        # =============================\n        layers.Flatten(),\n        layers.BatchNormalization(),\n        layers.Dense(2048, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dense(1024, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dense(200, activation=\"relu\"),\n        layers.Dense(7, activation=\"softmax\"),\n    ]\n)\n\nmodelo.build((img_size,img_size))\nmodelo.summary()\n","175e5a5f":"# Definir los parametros de optimizacion y perdida del modelo (con CrossValidation)\nmodelo.compile(loss = 'categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\n\n# ejecutar training\n# se usan los datagens como parametros.\nhistory = model.fit(\n                    train_generator, \n                    steps_per_epoch = 100,\n                    epochs=100,\n                    verbose=1, \n                    #shuffle=True,\n                    validation_data=test_generator,\n                    validation_steps=100\n                   )","979db146":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1.1])\nplt.show()\n\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n#plt.ylim([0, 1.1])\nplt.show()","f90eeaf4":"# tamano de la imagen de entrada\n\n# definicion del modelo Perceptron\nmodel = keras.Sequential(\n    [\n        layers.Flatten(input_shape=(img_size,img_size,1)),\n        layers.Dropout(0.2),\n        layers.Dense(500, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dense(100, activation=\"relu\"),\n        layers.Dense(10, activation=\"softmax\"),\n        layers.Dense(300, activation=\"relu\"),\n        layers.Dense(100, activation=\"relu\"),\n        layers.Dense(10, activation=\"softmax\"),\n    ]\n)\n\n# Construir el modelo y ver la arquitectura\nmodel.build((img_size,img_size,1))\nmodel.summary()","6fa1de91":"# Entregable 1: Considere una arquitectura neuronal simple primero.","576b3c0f":"Lets mix the 2 controls groups to prevent vias.","64347a86":"and re split the samples of the pictures","25709a57":"# Exploring the Dataset","515d7f40":"# Considere utilizar BatchNormalization y Dropout","71bdfdfa":"# Evaluacion de red neuronal ","1548b04e":"# Arquitetura Perceptron","3923902d":"# Deben utilizar Image Augmentation (ImageDataGenerator de Keras).","3d6e6ced":"Now we need to modify images.\n\n* The dataset contains different sizes of RGB color images.\n* First we should resize all the images, second sonvert images to grayscale.\n* Depending on purpose, you can go for RGB images.\n* But grey scale has just one dimension while RGB image has 3, and helps you to avoid false classification and complexities.","b3231753":"# Processing Dataset","cb159703":"# Entrenar la Red Neuronal","cd271a23":"# Creemos una red neuronal sensilla"}}