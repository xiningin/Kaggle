{"cell_type":{"c54d5695":"code","68ddd835":"code","be20c834":"code","844bd208":"code","bcab72d6":"code","85a02152":"code","9a214e3e":"code","e88ce2f8":"code","def40cb0":"code","9d2ea4a6":"code","e0b96fad":"code","2e086150":"code","5283c5c0":"code","c6ae4347":"code","6ee13ede":"code","eea878c4":"code","aed6fa0e":"code","79351886":"code","0e387af6":"code","88d7cd0e":"code","f4e1134d":"code","aa58891d":"code","c454d04c":"code","c67161b3":"code","890b1b1c":"code","dae2984b":"code","a2215955":"code","1a5a48ad":"code","9d3ee576":"code","e0575216":"code","51585ea6":"code","0cccb539":"code","bc72bf4b":"code","aab81f2b":"code","f87ea179":"code","db4e78d4":"markdown","d73169ca":"markdown","914979e1":"markdown","623760a8":"markdown","e986394a":"markdown","aead4fc9":"markdown","b8ba52e3":"markdown","b96acc45":"markdown","33db91bb":"markdown","a3cb8ca9":"markdown","bdf3dc3f":"markdown","ce17db1c":"markdown","eb544ba7":"markdown","de004982":"markdown","2b4265a5":"markdown"},"source":{"c54d5695":"from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https:\/\/www.who.int\/malaria\/map-pbo-nets-hompepage.jpg\")","68ddd835":"import seaborn as sns\n# PyTorch\nfrom torchvision import transforms, datasets, models\nimport torch\nfrom torch import optim, cuda\nfrom torch.utils.data import DataLoader, sampler\nimport torch.nn as nn\n\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\n# Data science tools\nimport numpy as np\nimport pandas as pd\nimport os\n\n# Image manipulations\nfrom PIL import Image\n# Useful for examining network\n# Timing utility\nfrom timeit import default_timer as timer\n\n\n# Visualizations\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['font.size'] = 14","be20c834":"import os\nprint(os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/\"))","844bd208":"traindir_parasitized = \"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized\/\"\ntraindir_uninfected = \"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected\/\"","bcab72d6":"def imshow(image):\n    \"\"\"Display Infected image\"\"\"\n    plt.figure(figsize=(6, 6))\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n\n# Example image\nx = Image.open(traindir_parasitized + '\/C136P97ThinF_IMG_20151005_140538_cell_96.png')\nnp.array(x).shape\nimshow(x)","85a02152":"# Uninfected image\nx = Image.open(traindir_uninfected + '\/C128P89ThinF_IMG_20151004_131632_cell_18.png')\nnp.array(x).shape\nimshow(x)","9a214e3e":"def imshow_tensor(image, ax=None, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    # Set the color channel as the third dimension\n    image = image.numpy().transpose((1, 2, 0))\n\n    # Reverse the preprocessing steps\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n\n    # Clip the image pixel values\n    image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    plt.axis('off')\n\n    return ax, image","e88ce2f8":"save_file_name = 'resnet50-transfer-4.pt'\ncheckpoint_path = 'resnet50-transfer-4.pth'\n\n# Change to fit hardware\nbatch_size = 128\n\n# Whether to train on a gpu\ntrain_on_gpu = cuda.is_available()\nprint(f'Train on gpu: {train_on_gpu}')\n\n# Number of gpus\nif train_on_gpu:\n    gpu_count = cuda.device_count()\n    print(f'{gpu_count} gpus detected.')","def40cb0":"image_transformers = {'train':\n    transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomVerticalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406], \n                                                            [0.229, 0.224, 0.225])]),\n\n'test':transforms.Compose([transforms.Resize(256),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], \n                                                           [0.229, 0.224, 0.225])]),\n\n'val':transforms.Compose([transforms.Resize(256),\n                                            transforms.CenterCrop(224),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize([0.485, 0.456, 0.406], \n                                                                 [0.229, 0.224, 0.225])])}","9d2ea4a6":"data = {'train':datasets.ImageFolder(root ='..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/',transform=image_transformers['train']),\n        'val':datasets.ImageFolder(root ='..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/',transform=image_transformers['val']),\n        'test':datasets.ImageFolder(root ='..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/',transform=image_transformers['test'])}\n\n# Dataloader iterators\ndataloaders = {\n    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n    'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n}","e0b96fad":"trainiter = iter(dataloaders['train'])\nfeatures, labels = next(trainiter)\nfeatures.shape, labels.shape","2e086150":"model = models.resnet50(pretrained=True)\nmodel","5283c5c0":"for param in model.parameters():\n    param.requires_grad = False","c6ae4347":"n_inputs = model.fc.in_features\n\n# Add on classifier\nmodel.fc = nn.Sequential(\n    nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.4),\n    nn.Linear(256, 2), nn.LogSoftmax(dim=1))\n\nmodel.fc","6ee13ede":"total_params = sum(p.numel() for p in model.parameters())\nprint(f'{total_params:,} total parameters.')\ntotal_trainable_params = sum(\n    p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'{total_trainable_params:,} training parameters.')","eea878c4":"if train_on_gpu:\n    model = model.to('cuda')","aed6fa0e":"model.class_to_idx = data['train'].class_to_idx\nmodel.idx_to_class = {\n    idx: class_\n    for class_, idx in model.class_to_idx.items()}\n\nlist(model.idx_to_class.items())","79351886":"criterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters())","0e387af6":"for p in optimizer.param_groups[0]['params']:\n    if p.requires_grad:\n        print(p.shape)","88d7cd0e":"def train(model,criterion,optimizer,train_loader,\n          valid_loader,save_file_name,max_epochs_stop=3,\n          n_epochs=20,print_every=1):\n    \n    \"\"\"Train a PyTorch Model\n\n    Params\n    --------\n        model (PyTorch model): cnn to train\n        criterion (PyTorch loss): objective to minimize\n        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n        train_loader (PyTorch dataloader): training dataloader to iterate through\n        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n        save_file_name (str ending in '.pt'): file path to save the model state dict\n        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n        n_epochs (int): maximum number of training epochs\n        print_every (int): frequency of epochs to print training stats\n\n    Returns\n    --------\n        model (PyTorch model): trained cnn with best weights\n        history (DataFrame): history of train and validation loss and accuracy\n    \"\"\"\n\n    # Early stopping intialization\n    epochs_no_improve = 0\n    valid_loss_min = np.Inf\n\n    valid_max_acc = 0\n    history = []\n\n    # Number of epochs already trained (if using loaded in model weights)\n    try:\n        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n    except:\n        model.epochs = 0\n        print(f'Starting Training from Scratch.\\n')\n\n    overall_start = timer()\n\n    # Main loop\n    for epoch in range(n_epochs):\n\n        # keep track of training and validation loss each epoch\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        train_acc = 0\n        valid_acc = 0\n\n        # Set to training\n        model.train()\n        start = timer()\n\n        # Training loop\n        for ii, (data, target) in enumerate(train_loader):\n            # Tensors to gpu\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n\n            # Clear gradients\n            optimizer.zero_grad()\n            # Predicted outputs are log probabilities\n            output = model(data)\n\n            # Loss and backpropagation of gradients\n            loss = criterion(output, target)\n            loss.backward()\n\n            # Update the parameters\n            optimizer.step()\n\n            # Track train loss by multiplying average loss by number of examples in batch\n            train_loss += loss.item() * data.size(0)\n\n            # Calculate accuracy by finding max log probability\n            _, pred = torch.max(output, dim=1)\n            correct_tensor = pred.eq(target.data.view_as(pred))\n            # Need to convert correct tensor from int to float to average\n            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n            # Multiply average accuracy times the number of examples in batch\n            train_acc += accuracy.item() * data.size(0)\n\n            # Track training progress\n            print(\n                f'Epoch: {epoch}\\t{100 * (ii + 1) \/ len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n                end='\\r')\n\n        # After training loops ends, start validation\n        else:\n            model.epochs += 1\n\n            # Don't need to keep track of gradients\n            with torch.no_grad():\n                # Set to evaluation mode\n                model.eval()\n\n                # Validation loop\n                for data, target in valid_loader:\n                    # Tensors to gpu\n                    if train_on_gpu:\n                        data, target = data.cuda(), target.cuda()\n\n                    # Forward pass\n                    output = model(data)\n\n                    # Validation loss\n                    loss = criterion(output, target)\n                    # Multiply average loss times the number of examples in batch\n                    valid_loss += loss.item() * data.size(0)\n\n                    # Calculate validation accuracy\n                    _, pred = torch.max(output, dim=1)\n                    correct_tensor = pred.eq(target.data.view_as(pred))\n                    accuracy = torch.mean(\n                        correct_tensor.type(torch.FloatTensor))\n                    # Multiply average accuracy times the number of examples\n                    valid_acc += accuracy.item() * data.size(0)\n\n                # Calculate average losses\n                train_loss = train_loss \/ len(train_loader.dataset)\n                valid_loss = valid_loss \/ len(valid_loader.dataset)\n\n                # Calculate average accuracy\n                train_acc = train_acc \/ len(train_loader.dataset)\n                valid_acc = valid_acc \/ len(valid_loader.dataset)\n\n                history.append([train_loss, valid_loss, train_acc, valid_acc])\n\n                # Print training and validation results\n                if (epoch + 1) % print_every == 0:\n                    print(\n                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n                    )\n                    print(\n                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n                    )\n\n                # Save the model if validation loss decreases\n                if valid_loss < valid_loss_min:\n                    # Save model\n                    torch.save(model.state_dict(), save_file_name)\n                    # Track improvement\n                    epochs_no_improve = 0\n                    valid_loss_min = valid_loss\n                    valid_best_acc = valid_acc\n                    best_epoch = epoch\n\n                # Otherwise increment count of epochs with no improvement\n                else:\n                    epochs_no_improve += 1\n                    # Trigger early stopping\n                    if epochs_no_improve >= max_epochs_stop:\n                        print(\n                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n                        )\n                        total_time = timer() - overall_start\n                        print(\n                            f'{total_time:.2f} total seconds elapsed. {total_time \/ (epoch+1):.2f} seconds per epoch.'\n                        )\n\n                        # Load the best state dict\n                        model.load_state_dict(torch.load(save_file_name))\n                        # Attach the optimizer\n                        model.optimizer = optimizer\n\n                        # Format history\n                        history = pd.DataFrame(\n                            history,\n                            columns=[\n                                'train_loss', 'valid_loss', 'train_acc',\n                                'valid_acc'\n                            ])\n                        return model, history\n\n    # Attach the optimizer\n    model.optimizer = optimizer\n    # Record overall time and print out stats\n    total_time = timer() - overall_start\n    print(\n        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n    )\n    print(\n        f'{total_time:.2f} total seconds elapsed. {total_time \/ (epoch):.2f} seconds per epoch.'\n    )\n    # Format history\n    history = pd.DataFrame(\n        history,\n        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n    return model, history","f4e1134d":"model, history = train(model,criterion,optimizer,dataloaders['train'],\n                       dataloaders['val'],save_file_name=save_file_name,\n                       max_epochs_stop=3,n_epochs=2,print_every=1)","aa58891d":"plt.figure(figsize=(8, 6))\nfor c in ['train_loss', 'valid_loss']:\n    plt.plot(\n        history[c], label=c)\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Average Negative Log Likelihood')\nplt.title('Training and Validation Losses')","c454d04c":"plt.figure(figsize=(8, 6))\nfor c in ['train_acc', 'valid_acc']:\n    plt.plot(\n        100 * history[c], label=c)\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Average Accuracy')\nplt.title('Training and Validation Accuracy')","c67161b3":"def save_checkpoint(model, path):\n    \"\"\"Save a PyTorch model checkpoint\n\n    Params\n    --------\n        model (PyTorch model): model to save\n        path (str): location to save model. Must start with `model_name-` and end in '.pth'\n\n    Returns\n    --------\n        None, save the `model` to `path`\n\n    \"\"\"\n\n    model_name = path.split('-')[0]\n    assert (model_name in ['vgg16', 'resnet50'\n                           ]), \"Path must have the correct model name\"\n\n    # Basic details\n    checkpoint = {'class_to_idx': model.class_to_idx,\n                  'idx_to_class': model.idx_to_class,\n                  'epochs': model.epochs}\n\n    # Extract the final classifier and the state dictionary\n    if model_name == 'resnet50':\n        checkpoint['fc'] = model.fc\n        checkpoint['state_dict'] = model.state_dict()\n\n    # Add the optimizer\n    checkpoint['optimizer'] = model.optimizer\n    checkpoint['optimizer_state_dict'] = model.optimizer.state_dict()\n\n    # Save the data to the path\n    torch.save(checkpoint, path)","890b1b1c":"save_checkpoint(model, path=checkpoint_path)","dae2984b":"def load_checkpoint(path):\n    \"\"\"Load a PyTorch model checkpoint\n\n    Params\n    --------\n        path (str): saved model checkpoint. Must start with `model_name-` and end in '.pth'\n\n    Returns\n    --------\n        None, save the `model` to `path`\n\n    \"\"\"\n\n    # Get the model name\n    model_name = 'resnet50'\n\n    # Load in checkpoint\n    checkpoint = torch.load(path)\n\n    if model_name == 'resnet50':\n        model = models.resnet50(pretrained=True)\n        # Make sure to set parameters as not trainable\n        for param in model.parameters():\n            param.requires_grad = False\n        model.fc = checkpoint['fc']\n        \n    # Load in the state dict\n    model.load_state_dict(checkpoint['state_dict'])\n\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f'{total_params:,} total parameters.')\n    total_trainable_params = sum(\n        p.numel() for p in model.parameters() if p.requires_grad)\n    print(f'{total_trainable_params:,} total gradient parameters.')\n\n    # Move to gpu\n    if train_on_gpu:\n        model = model.to('cuda')\n\n    # Model basics\n    model.class_to_idx = checkpoint['class_to_idx']\n    model.idx_to_class = checkpoint['idx_to_class']\n    model.epochs = checkpoint['epochs']\n\n    # Optimizer\n    optimizer = checkpoint['optimizer']\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n    return model, optimizer","a2215955":"!pip install torchsummary\nfrom torchsummary import summary","1a5a48ad":"model, optimizer = load_checkpoint(path=checkpoint_path)\nsummary(model, input_size=(3, 224, 224), batch_size=batch_size)","9d3ee576":"model, history = train(model,criterion,optimizer,dataloaders['train'],dataloaders['val'],\n                       save_file_name=save_file_name,max_epochs_stop=3,n_epochs=20,print_every=1)","e0575216":"def process_image(image_path):\n    \"\"\"Process an image path into a PyTorch tensor\"\"\"\n\n    image = Image.open(image_path)\n    # Resize\n    img = image.resize((224, 224))\n\n    # Center crop\n    width = 256\n    height = 256\n    new_width = 224\n    new_height = 224\n\n    left = (width - new_width) \/ 2\n    top = (height - new_height) \/ 2\n    right = (width + new_width) \/ 2\n    bottom = (height + new_height) \/ 2\n    img = img.crop((left, top, right, bottom))\n\n    # Convert to numpy, transpose color dimension and normalize\n    img = np.array(img)\/ 256\n\n    # Standardization\n    means = np.array([0.485, 0.456, 0.406]).reshape((3,))\n    stds = np.array([0.229, 0.224, 0.225]).reshape((3,))\n\n    img = img - means\n    img = img \/ stds\n\n    img_tensor = torch.Tensor(img)\n\n    return img_tensor","51585ea6":"x = process_image(traindir_uninfected + '\/C100P61ThinF_IMG_20150918_144348_cell_71.png')\nx.shape","0cccb539":"def predict(image_path, model, topk=2):\n    \"\"\"Make a prediction for an image using a trained model\n\n    Params\n    --------\n        image_path (str): filename of the image\n        model (PyTorch model): trained model for inference\n        topk (int): number of top predictions to return\n\n    Returns\n\n    \"\"\"\n    real_class = image_path.split('\/')[-2]\n\n    # Convert to pytorch tensor\n    img_tensor = process_image(image_path)\n\n    # Resize\n    if train_on_gpu:\n        img_tensor = img_tensor.view(1, 3, 224, 224).cuda()\n\n    # Set to evaluation\n    with torch.no_grad():\n        model.eval()\n        # Model outputs log probabilities\n        out = model(img_tensor)\n        ps = torch.exp(out)\n\n        # Find the topk predictions\n        topk, topclass = ps.topk(topk, dim=1)\n\n        # Extract the actual classes and probabilities\n        top_classes = [model.idx_to_class[class_] for class_ in topclass.cpu().numpy()[0]]\n        top_p = topk.cpu().numpy()[0]\n\n        return img_tensor.cpu().squeeze(), top_p, top_classes, real_class","bc72bf4b":"img, top_p, top_classes, real_class = predict(traindir_uninfected + '\/C100P61ThinF_IMG_20150918_144348_cell_71.png', model)\nimg.shape","aab81f2b":"def display_prediction(image_path, model, topk):\n    \"\"\"Display image and preditions from model\"\"\"\n\n    # Get predictions\n    img, ps, classes, y_obs = predict(image_path, model, topk)\n    # Convert results to dataframe for plotting\n    result = pd.DataFrame({'p': ps}, index=classes)\n\n    # Show the image\n    plt.figure(figsize=(16, 5))\n    ax = plt.subplot(1, 2, 1)\n    # Uninfected image\n    #x = Image.open(image_path)\n    #np.array(x).shape\n    #imshow(x)\n    ax, img = imshow_tensor(img, ax=ax)\n\n    # Set title to be the actual class\n    ax.set_title(y_obs, size=20)\n\n    ax = plt.subplot(1, 2, 2)\n    # Plot a bar plot of predictions\n    result.sort_values('p')['p'].plot.barh(color='blue', edgecolor='k', ax=ax)\n    plt.xlabel('Predicted Probability')\n    plt.tight_layout()","f87ea179":"display_prediction(traindir_uninfected + '\/C100P61ThinF_IMG_20150918_144348_cell_71.png', model,2)","db4e78d4":"# 6. Model Evaluation\n#### Save Model Checkpoint\n#### Loading Model Checkpoint\n#### Reinitialise training from last epoch ","d73169ca":"##### Class Check","914979e1":"# 4. Transfer Learning\n##### Fetch Restnet50 Weights from Pytorch Torchvision models\n[Source](https:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html)\n","623760a8":"<font color='blue'>If you find this kernel awesome and useful please hit upvote \ud83d\ude0a .<\/font> <br> <br>\n\n\n<font color='blue'>Cheers!!!! <\/font>","e986394a":"##### Model Training Begins Here.....","aead4fc9":"# 7. Prediction on Test Image","b8ba52e3":"#####  Freeze early layers\n","b96acc45":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content:<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#one_\" role=\"tab\" aria-controls=\"profile\">1. Importing Libraries<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#two_\" role=\"tab\" aria-controls=\"messages\">2. Exploratory Data Analysis<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#three_\" role=\"tab\" aria-controls=\"settings\">3. Image Data Preprocessing<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n   <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#four_\" role=\"tab\" aria-controls=\"settings\">4. Transfer Learning -RESNET50<span class=\"badge badge-primary badge-pill\">4<\/span><\/a>\n   <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#five_\" role=\"tab\" aria-controls=\"settings\">5. Model Training<span class=\"badge badge-primary badge-pill\">5<\/span><\/a>\n   <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#five_\" role=\"tab\" aria-controls=\"settings\">6. Model Evaluation<span class=\"badge badge-primary badge-pill\">6<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#six_\" role=\"tab\" aria-controls=\"settings\">7. Prediction on Test Images<span class=\"badge badge-primary badge-pill\">7<\/span><\/a>","33db91bb":"# 2.Exploratory Data Analysis","a3cb8ca9":"# 1. Import Libraries","bdf3dc3f":"### References\n - [Retinal Image Classification](https:\/\/www.kaggle.com\/dude431\/retinal-images-classification)\n - [Pytorch Doc](https:\/\/pytorch.org\/tutorials\/)\n - [Torchvision Models](https:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html)\n - [Image Classification using PyTorch](https:\/\/www.analyticsvidhya.com\/blog\/2019\/10\/building-image-classification-models-cnn-pytorch)","ce17db1c":"# 5. Model Training\n###### Function to initialise grads for torch tensors","eb544ba7":"# Malaria Cell Images Dataset\n### Detecting Malaria through AI\n##### Malaria is a mosquito-borne infectious disease that affects humans and other animals. Malaria causes symptoms that typically include fever, tiredness, vomiting, and headaches.\n* Prevention: Mosquito nets, insect repellent etc\n* Specialty: Infectious disease\n* Symptoms: Fever, vomiting, headache\n* Causes: Plasmodium spread by mosquitos","de004982":"##### Model Transfer to CUDA","2b4265a5":"# 3. Image Data Preprocessing\n#### Building Transformers for Model Training and Validation\n#### Defining Data Iterators"}}