{"cell_type":{"be8009d4":"code","fae015dd":"code","f834a276":"code","bd5245f4":"code","559058aa":"code","744151dc":"code","dc4914f8":"code","fab80767":"code","aaaf012e":"code","75dbfcdf":"code","fac80047":"code","654239bb":"code","6aef77c1":"code","469997fe":"code","96e698b3":"code","b79ec7ab":"code","7d0d13f9":"code","a702b644":"code","bfc17c31":"code","f5eac344":"code","2fb44873":"code","744cea15":"code","1aad21d0":"code","69f6ccdf":"code","61c2cd86":"code","9f0e3df1":"code","0f80417b":"code","efdcfe62":"code","44725bd0":"code","3297b994":"code","f10772db":"code","a87e32f5":"markdown","4af45e06":"markdown","cdf0f69f":"markdown","1c5357a9":"markdown","e7f9c8eb":"markdown","16cb24cc":"markdown","af901940":"markdown","c2bd8bee":"markdown","15f60014":"markdown","83557db5":"markdown","4bb85fa8":"markdown"},"source":{"be8009d4":"!pip install flair\n!pip install transformers\n!pip install node2vec\n!pip install wordcloud #https:\/\/github.com\/amueller\/word_cloud","fae015dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom flair.models import SequenceTagger\nfrom flair.data import Sentence\nfrom transformers import pipeline\npd.set_option('display.max_columns', 30)\nfrom collections import Counter \nimport nltk\nimport matplotlib.pyplot as plt\nimport re\nfrom tqdm.autonotebook import tqdm\nimport networkx as nx\nfrom wordcloud import WordCloud\nfrom sklearn.cluster import DBSCAN\n\nimport plotly.graph_objects as go\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f834a276":"def tokenizer(text):\n    text = text.split(',')\n    res = []\n    for t in text:\n        res.extend(nltk.word_tokenize(t))\n        \n    return res","bd5245f4":"data = pd.read_csv(\"\/kaggle\/input\/novel-corona-virus-2019-dataset\/COVID19_line_list_data.csv\")\ndata.head()","559058aa":"text = data.summary.dropna().values\nprint(f\"Text lenght: {len(text)}\")","744151dc":"symptoms = data.symptom.dropna().tolist()\nprint(len(symptoms))","dc4914f8":"print(f\"Total dataset len: {len(data)}\")\nprint(f\"Death: {len(data.loc[data.death == '1'])}\")\nprint(f\"Recovered: {len(data.loc[data.recovered == '1'])}\")","fab80767":"ner_tagger = SequenceTagger.load('ner')\n\nnlp_qa = pipeline('question-answering')","aaaf012e":"match = re.findall(r'(\\d+\/\\d+\/\\d+)',text[1])\nprint(match)","75dbfcdf":"sentence = Sentence(text[1])\nner_tagger.predict(sentence)\nprint(sentence.to_tagged_string())","fac80047":"questions = [\n    'How old?',\n    'Gender?',\n    'Where from?',\n    'When symptoms onset?',\n    'When Hospitalized?',\n    'When quarantined?',\n]","654239bb":"print(text[0])\nfor q in questions:\n    print(f\"Question: {q}, answer: {nlp_qa(context = text[0], question=q)}\")","6aef77c1":"wordcloud = WordCloud().generate(' '.join(symptoms))\n\nplt.figure(figsize=[10, 6])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")","469997fe":"from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n\nglove_embedding = WordEmbeddings('glove')\n\ndocument_embeddings = DocumentRNNEmbeddings([glove_embedding])","96e698b3":"embeddings = np.empty((len(text), 128))\nfor idx, t in tqdm(enumerate(text)):\n    sentence = Sentence(t)\n    document_embeddings.embed(sentence)\n    embeddings[idx, :] = (sentence.get_embedding().detach().numpy())","b79ec7ab":"dbscan=DBSCAN(eps=0.08, min_samples=2,metric='cosine' ).fit(embeddings)\n\ndf_cluster = pd.DataFrame({\"text\":text, \"cluster\":dbscan.labels_})","7d0d13f9":"df_cluster.cluster.value_counts()","a702b644":"df_cluster.loc[df_cluster['cluster'] == 31].head()","bfc17c31":"from sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\ndef plot_pca(train,y, text=\"Plot\", algo = 'TSNE', size = 2):\n    \"\"\"Function visualizating PCA\/TSNE\"\"\"\n\n    plt.figure(figsize=(20,8))\n    if algo == 'PCA':\n        pca = PCA(n_components = 2,copy=False)\n    elif algo == 'TSNE':\n        pca = TSNE(n_components = 2)\n    else:\n        print('Unknown algo, using PCA...')\n        pca = PCA(n_components = 2, copy=False)\n        \n    train_pca = pca.fit_transform(train)\n\n    plt.scatter(train_pca[:,0], train_pca[:,1],c=y, edgecolor='none', alpha=0.9,\n            cmap=plt.cm.get_cmap('seismic', size))\n    plt.title(text)\n    plt.xlabel('component 1')\n    plt.ylabel('component 2')\n    plt.colorbar()","f5eac344":"np.unique(dbscan.labels_)","2fb44873":"plot_pca(embeddings, dbscan.labels_, size = len(np.unique(dbscan.labels_)))","744cea15":"'''plt.figure(figsize=[10, 8])\nplt.title(\"Text embedding\")\nplt.scatter(transformed[:,0], transformed[:,1], edgecolor='none', alpha=0.9,)\nplt.xlabel('X-comp')\nplt.ylabel('Y-comp')\nplt.show()'''","1aad21d0":"symptoms[:10]","69f6ccdf":"counter = Counter()\nlinks = dict(dict())\n\nfor row in symptoms:\n    \n    row = tokenizer(row)    \n    \n    for symptome in row:\n        counter[symptome] += 1\n        \n    for subsymptome in row:\n        if not(symptome in links.keys()):\n            links[symptome] = dict()\n            \n        if not(subsymptome in links[symptome].keys()):\n            links[symptome][subsymptome] = 0\n            \n        if symptome != subsymptome:    \n            links[symptome][subsymptome] += 1\n            \nfor key1 in links.keys():\n    for key2 in links[key1].keys():\n        links[key1][key2] \/= counter[key1]\n        \nlinks_dict = dict()\nfor key1, val1 in links.items():\n    for key2, val2 in links[key1].items():\n        #if val2 >= 0.5:\n        if key1 != key2:\n            links_dict[(key1, key2)] = val2\n        ","61c2cd86":"counter.most_common(10)","9f0e3df1":"size_df = pd.DataFrame.from_dict(counter, orient='index').reset_index()\nsize_df.columns = ['label', 'size']\n\nlinks_df = pd.DataFrame([[list(key)[0], val, list(key)[1]] for key, val in links_dict.items() if list(key)[0] != list(key)[1]], columns = ['source', 'weight', 'target'])","0f80417b":"G = nx.Graph()\nfor idx, row in size_df.iterrows():\n    G.add_node(row['label'], size = float(row['size']))\n\nfor idx, row in links_df.iterrows():\n    G.add_edge(row['source'], row['target'], weight=float(row['weight']))","efdcfe62":"print(f\"Nodes len: {len(list(G.nodes()))}\")\nprint(f\"Edges len: {len(list(G.edges()))}\")\n# %%\nplt.figure(figsize=[20, 8])\n\nparams = {\n    'edge_color'    : '#FFDEA2',\n    'width'         : 1,\n    'with_label'    : True,\n    'font_weight'   : 'regular'\n}\n\nnode_list = [i*10 for i in size_df['label'].values]\nnode_size = [i*10 for i in size_df['size'].values]\nnx.draw_networkx(G,node_list = node_list,node_size=node_size, **params)","44725bd0":"from node2vec import Node2Vec\n\nn2v = Node2Vec(G, dimensions=15, num_walks=100, workers=4)\nnode_model = n2v.fit(size=3, window=2, seed=42, iter=1, sg=1)","3297b994":"node_model.most_similar(['fever'], topn=15)","f10772db":"node_model.most_similar(['fever', 'cough'], topn=15)","a87e32f5":"We can collect some data using NLP question answering. Adding more questions, and filtering by confidesce score we can fill some missing walues","4af45e06":"Look like we have some clusters at document embedding space","cdf0f69f":"Create node2vec for symptomes prediction.","1c5357a9":"Try to use question answering. \nSome sample questions","e7f9c8eb":"## Question answering","16cb24cc":"Create symptoms graph and Node2Vec model for finding similar symptom and get a probability of next potential symptoms","af901940":"Look like NER is not useful for us, if we want parse dates its better to use regular expressions.","c2bd8bee":"## Clustering","15f60014":"Wordcloud basic","83557db5":"# Symptoms Node2Vec","4bb85fa8":"# NLP"}}