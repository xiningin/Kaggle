{"cell_type":{"1bb0c03a":"code","558f6606":"code","3e64e994":"code","c7fdc5fe":"code","036214ab":"code","72b6bfe3":"code","0ca77d9f":"code","b149c045":"code","0fdc9741":"code","d7dc5781":"code","8ecfdafc":"code","c7ece195":"code","eee5031b":"code","ad8692e1":"code","feb9cf38":"code","d88cd89b":"markdown","7c4e6b0e":"markdown","4ede3ead":"markdown","f08c61ce":"markdown","a2e15742":"markdown","222058a2":"markdown","40374905":"markdown","f93adb50":"markdown","bba13aab":"markdown","7412856a":"markdown","ec96a366":"markdown","3bedb12c":"markdown","7d020530":"markdown","a07dacab":"markdown","979e5df3":"markdown","d95a77c0":"markdown"},"source":{"1bb0c03a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import skew\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb","558f6606":"submission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsubmission.head()","3e64e994":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain.head()","c7fdc5fe":"test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest.head()","036214ab":"print('=========== train infomation ===========')\ntrain.info()\nprint('\\n\\n=========== test infomation ===========')\ntest.info()","72b6bfe3":"data = pd.concat([train, test])\ndata.shape","0ca77d9f":"# current numeric data\nnumerics = data.loc[:,data.dtypes != 'object'].drop('Id', axis=1)\nnumerics.head()","b149c045":"# numeric data after conversion to logarithm\nlog_numerics = np.log1p(numerics)\nlog_numerics.head()","0fdc9741":"# compare skewnesses before with after of logarithmization\nskewness = pd.concat([numerics.apply(lambda x: skew(x.dropna())),\n                      log_numerics.apply(lambda x: skew(x.dropna()))],\n                     axis=1).rename(columns={0:'original', 1:'logarithmization'}).sort_values('original')\nskewness.plot.barh(figsize=(12,10), title='Comparison of skewness of original and logarithmized', width=0.8);","d7dc5781":"cat_cols = data.loc[:,data.dtypes == 'object'].columns\ndata.loc[:,cat_cols].head()","8ecfdafc":"# categorical data after conversion to one-hot vector\n# cat_data = pd.get_dummies(data.loc[:, cat_cols], drop_first=True, dummy_na=True)\ncat_data = pd.get_dummies(data.loc[:, cat_cols], drop_first=True)\ncat_data.head()","c7ece195":"# merge categorical and numeric columns\noptimized_data = pd.concat([data['Id'], cat_data, log_numerics], axis=1)\noptimized_data.head()","eee5031b":"# split data into X_train, y_train and test\ntrain = optimized_data[:train.shape[0]]\ntest = optimized_data[train.shape[0]:].drop(['Id', 'SalePrice'], axis=1)\nX_train = train.drop(['Id', 'SalePrice'], axis=1)\ny_train = train['SalePrice']","ad8692e1":"# train\nlgb_train = lgb.Dataset(X_train, y_train)\nparams = {\n        'objective' : 'regression',\n        'metric' : {'rmse'}\n}\ngbm = lgb.train(params, lgb_train)\n# predict\npred = gbm.predict(test)","feb9cf38":"# convert logarithms into exponent\npred = np.expm1(pred)\n# create submission file\nresults = pd.Series(pred, name='SalePrice')\nsubmission = pd.concat([submission['Id'], results], axis=1)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","d88cd89b":"## 1.1 Import libraries<a id=\"1.1\"><\/a>\n**Import all required libraries**","7c4e6b0e":"## 2.1 Transform numeric into logarithms<a id=\"2.1\"><\/a>\n**transform all numeric columns of the data frame into logarithms to reduce skewness**<br><br>\nApproximating to a normal distribution often improves the accuracy of machine learning.<br>Logarithmic conversion reduces the range when the feature scale is large and expands it when the feature scale is small.<br>This often allows you to get closer to a mountainous distribution as if you were crushing a long-tailed distribution.","4ede3ead":"<a id=\"1\"><\/a><h1 style='background:slateblue; border:.; color:white'><center>1. Preparations<\/center><\/h1>","f08c61ce":"## 1.4 Combine train and test<a id=\"1.4\"><\/a>\n**Combine train and test so that you can do each future operation once**","a2e15742":"## 1.3 Check data<a id=\"1.3\"><\/a>\n**check data shape, count and dtype of each column**","222058a2":"## 3.3 Create submission<a id=\"3.3\"><\/a>\n**convert prediction into exponent and export CSV file**","40374905":"## 2.2 Transform categorical into one-hot vector<a id=\"2.2\"><\/a>\n**transform all categorical columns of the data frame into one-hot vector**<br><br>\nSince GBDT treats features as numerical data, it is necessary to convert categorical data to numerical values. Label encoding is fine, but one-hot encoding often has better performance.","f93adb50":"## 3.2 Prediction<a id=\"3.2\"><\/a>\n**fit and predict using lightGBM**","bba13aab":"The skewnesses of many features are reduced by logarithmic conversion. Some skewnesses have increased, but overall it has decreased.","7412856a":"## 3.1 Format data<a id=\"3.1\"><\/a>\n**Format data for training**","ec96a366":"This notebook has a score of 0.13086 and is in the top 30%.<br>Based on this notebook, Feature engineering, Hyper-parameter tuning and ensemble will give you a better score.","3bedb12c":"<a id=\"2\"><\/a><h1 style='background:slateblue; border:.; color:white'><center>2. Feature Engineering<\/center><\/h1>","7d020530":"## 1.2 Load dataset<a id=\"1.2\"><\/a>\n**Load each data as a Pandas DataFrame**","a07dacab":"<a id=\"3\"><\/a>\n<h1 style='background:slateblue; border:.; color:white'><center>3. Prediction and submission<\/center><\/h1>","979e5df3":"* [1. Preparations](#1)\n    * [1.1 Import libraries](#1.1)\n    * [1.2 Load dataset](#1.2)\n    * [1.3 Check data](#1.3)\n    * [1.4 Combine train and test](#1.4)\n* [2. Feature Engineering](#2)\n    * [2.1 Transform numeric into logarithms](#2.1)\n    * [2.2 Transform categorical into one-hot vector](#2.2)\n* [3. Prediction and submission](#3)\n    * [3.1 Format data](#3.1)\n    * [3.2 Prediction](#3.2)\n    * [3.3 Create submission](#3.3)","d95a77c0":"# <u>House Prices: Simple and easy 3 steps to submit<\/u>\nThis notebook will guide you through three simple and effective steps to submit."}}