{"cell_type":{"3bdd5d70":"code","17f59c01":"code","2bb6df89":"code","4af7ba1b":"code","497a87d2":"code","617c44c6":"code","c633d158":"code","a2202d8b":"code","8a7492fe":"code","54a8cc74":"code","ee4b0d35":"code","1d9fd6c7":"code","cc1791e5":"code","ba9f7d43":"code","858abd72":"code","3b3062df":"code","722647a9":"code","3effa82a":"code","0c9e2b9d":"code","e95b248a":"code","83cad8a4":"code","73b679bf":"code","99398d79":"code","c6ab893a":"code","192f50a5":"code","a94713eb":"code","19c8ab03":"code","6a2895e6":"code","09f49284":"code","294fb69f":"code","2e3ec689":"code","55420e36":"code","aa11f9bc":"code","b49e2c5d":"code","090e5123":"code","9c819062":"code","938f6e77":"code","c8103433":"code","c3e6bcb3":"code","0892fa54":"code","4f017464":"code","8a5cc024":"code","646e9060":"code","6f7fc8c7":"code","c782f7d8":"code","ccafa609":"code","773e5094":"code","c9bdc93f":"code","b749a596":"code","6cb902ca":"code","73421ded":"code","c8052f16":"code","9b03d866":"code","f3c228d0":"code","27f9c8b5":"code","dd18ee01":"code","159a0eb1":"code","69e01e43":"code","122203ec":"code","346ee4d9":"code","73f21504":"markdown","0f0b019c":"markdown","91483e48":"markdown","e8b2f32f":"markdown","b3d83522":"markdown","ea184db0":"markdown","1a0c2a92":"markdown","b068a06c":"markdown","8b4b3b77":"markdown","fa17f63f":"markdown","e26ccdb4":"markdown","f685ac0c":"markdown","06830f69":"markdown","679e01c4":"markdown"},"source":{"3bdd5d70":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17f59c01":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","2bb6df89":"train = pd.read_csv(\"..\/input\/predicting-pulsar-starintermediate\/pulsar_data_train.csv\")\ntest = pd.read_csv(\"..\/input\/predicting-pulsar-starintermediate\/pulsar_data_test.csv\")","4af7ba1b":"train.head() #sample of train data","497a87d2":"test.head() # sample of test data","617c44c6":"train.columns","c633d158":"test.columns","a2202d8b":"train.info() #get information about the data(data types, null)","8a7492fe":"test.info() #get information about the test data","54a8cc74":"#rename the columns of the data frame so that it can be easil\ntrain.columns = ['IP_mean', 'IP_std', 'IP_kurtosis', 'IP_skewness','DM-SNR_mean','DM-SNR_std', 'DM-SNR_kurtosis','DM-SNR_skewness', 'target']","ee4b0d35":"test.columns = ['IP_mean', 'IP_std', 'IP_kurtosis', 'IP_skewness','DM-SNR_mean','DM-SNR_std', 'DM-SNR_kurtosis','DM-SNR_skewness', 'target']","1d9fd6c7":"#check the changes\ntrain.info()","cc1791e5":"test.info()","ba9f7d43":" #count number of duplicated rows in train data\nprint('there is: ' + str(train.duplicated().sum()) + \" duplicated rows in this dataset\")","858abd72":"train.hist(bins = 120, figsize=(14,16)) #present the distribution of each column \nplt.show()","3b3062df":"train.isnull().sum() #count null in each column","722647a9":"sns.heatmap(train.isnull()) #heat map for null values","3effa82a":"sns.heatmap(test.isnull()) #heat map for null values","0c9e2b9d":"train['IP_kurtosis'].fillna(method = \"ffill\", inplace = True) #fill nulls uing forward fill\ntest['IP_kurtosis'].fillna(method = \"ffill\", inplace = True) #fill nulls uing forward fill","e95b248a":"train['DM-SNR_std'].fillna(method = \"ffill\", inplace = True)\ntest['DM-SNR_std'].fillna(method = \"ffill\", inplace = True)","83cad8a4":"train['DM-SNR_skewness'].fillna(method = \"ffill\", inplace = True)\ntest['DM-SNR_skewness'].fillna(method = \"ffill\", inplace = True)","73b679bf":"sns.heatmap(train.isnull()) #heat map for null values","99398d79":"sns.heatmap(test.isnull()) #heat map for null values","c6ab893a":"train.hist(bins = 120, figsize=(14,18)) #present the distribution of each column \nplt.show()","192f50a5":"train['target'].value_counts()","a94713eb":"#show the difference between pulsar and non pulasr stars\nsns.countplot(x=\"target\", palette=\"ch:.25\", data=train)","19c8ab03":"plt.pie(train['target'].value_counts(), labels = [\"not pulsar\", 'pulsar'], colors = ['red', 'green'], autopct = '%1.1f%%', shadow = True, explode = [0.2, 0.1])\nplt.show()","6a2895e6":"train.drop('target', axis = 1).plot(kind = \"box\" , subplots = True , figsize = (20,15) ,  layout = (3,3))\nplt.show()","09f49284":"sns.pairplot(train, hue=\"target\", markers=[\"o\", \"D\"])","294fb69f":"from sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn import metrics","2e3ec689":"#splitting data to train and test (we use train data file only as we will use SVM which is supervised algorithm \n#so we need Y column)\n\nfeatures = train.drop('target', axis = 1)\ntarget = train['target']\n\nX_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)","55420e36":"clf_1 = SVC(kernel = 'linear')\nclf_1.fit(X_train, Y_train)","aa11f9bc":"y_predict_1 = clf_1.predict(X_test)","b49e2c5d":"print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_predict_1))\n","090e5123":"conf = metrics.confusion_matrix(Y_test, y_predict_1)\nconf","9c819062":"f, ax=plt.subplots(figsize=(10,10))\nsns.heatmap(conf, annot=True, linewidths=0.5, linecolor=\"black\", fmt=\".0f\", ax=ax, cmap=\"magma\")\nplt.xlabel(\"y_prediction\")\nplt.ylabel(\"y_test\")\nplt.show()","938f6e77":"print(\"percision: \", metrics.precision_score(Y_test, y_predict_1))\nprint(\"recall: \", metrics.recall_score(Y_test, y_predict_1))","c8103433":"FPR, TPR, cutoffs = metrics.roc_curve(Y_test,y_predict_1,pos_label=1) ","c3e6bcb3":"# Visualize.\nplt.plot(FPR,TPR,c='red',linewidth=1.0)\nplt.xlabel('False Positive')\nplt.ylabel('True Positive')\nplt.title('ROC Curve')\nplt.show()","0892fa54":"auc = metrics.roc_auc_score(Y_test, y_predict_1)\n\nfp_rate, tp_rate, thresolds = metrics.roc_curve(Y_test, y_predict_1)\n\nplt.figure(figsize=(10, 8), dpi=60)\nplt.axis('scaled')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.title(\"AUC Curve\")\nplt.plot(fp_rate, tp_rate, 'g')\nplt.fill_between(fp_rate, tp_rate, facecolor='purple', alpha=0.6)\nplt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=19, weight='bold', color='red')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.show()","4f017464":"clf_2 = SVC(kernel = 'rbf')\nclf_2.fit(X_train, Y_train)","8a5cc024":"y_predict_2 = clf_2.predict(X_test)","646e9060":"print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_predict_2))","6f7fc8c7":"conf = metrics.confusion_matrix(Y_test, y_predict_2)\nconf","c782f7d8":"f, ax=plt.subplots(figsize=(10,10))\nsns.heatmap(conf, annot=True, linewidths=0.5, linecolor=\"black\", fmt=\".0f\", ax=ax, cmap=\"magma\")\nplt.xlabel(\"y_prediction\")\nplt.ylabel(\"y_test\")\nplt.show()","ccafa609":"print(\"percision: \", metrics.precision_score(Y_test, y_predict_2))\nprint(\"recall: \", metrics.recall_score(Y_test, y_predict_2))\nprint(\"f1-score: \", metrics.f1_score(Y_test, y_predict_2, average='macro'))","773e5094":"FPR, TPR, cutoffs = metrics.roc_curve(Y_test,y_predict_2,pos_label = 1) ","c9bdc93f":"# Visualize.\nplt.plot(FPR,TPR,c='green',linewidth=1.5)\nplt.xlabel('False Positive')\nplt.ylabel('True Positive')\nplt.title('ROC Curve')\nplt.show()","b749a596":"auc = metrics.roc_auc_score(Y_test, y_predict_2)\n\nfp_rate, tp_rate, thresolds = metrics.roc_curve(Y_test, y_predict_2)\n\nplt.figure(figsize=(10, 8), dpi=70)\nplt.axis('scaled')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.title(\"AUC Curve\")\nplt.plot(fp_rate, tp_rate, 'g')\nplt.fill_between(fp_rate, tp_rate, facecolor='blue', alpha=0.7)\nplt.text(0.95, 0.05, 'AUC = %0.4f' % auc, ha='right', fontsize=19, weight='bold', color='red')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.show()","6cb902ca":"from sklearn.cluster import DBSCAN\nfrom sklearn.metrics import silhouette_score","73421ded":"X = train.drop('target', axis = 1)","c8052f16":"# Defining the list of hyperparameters to try\neps_list = np.arange(start = 0.1, stop = 0.9, step = 0.01)\nmin_sample_list = np.arange(start = 2, stop = 10, step = 1)\neps = 0\nmin_sample = 0\nfor eps_trial in eps_list:\n    for min_sample_trial in min_sample_list:\n        \n        # Generating DBSAN clusters\n        model = DBSCAN(eps=eps_trial, min_samples = min_sample_trial).fit(test.drop('target', axis = 1))\n        print(\"with eps: \", str(eps_trial), \" and min_samples: \", str(min_sample_trial), \" we have:\", str(len(np.unique(model.labels_))), \"clusters\")\n        if len(np.unique(model.labels_)) == 3:\n            eps = eps_trial\n            min_sample = min_sample_trial\n            break\n","9b03d866":"model = DBSCAN(eps=eps, min_samples = min_sample).fit(test.drop('target', axis = 1))","f3c228d0":"print(model.labels_)","27f9c8b5":"core_samples_mask = np.zeros_like(model.labels_, dtype=bool)\ncore_samples_mask","dd18ee01":"model.core_sample_indices_","159a0eb1":"core_samples_mask[model.core_sample_indices_] = True\ncore_samples_mask","69e01e43":"labels = model.labels_\nlen(labels)","122203ec":"n_noise = list(labels).count(-1)\nn_noise","346ee4d9":"percentage_of_Outlaiers=n_noise\/len(test)\npercentage_of_Outlaiers*100","73f21504":"### there is only 9.2% form the sample are pulsar stars and the rest of the data for the not pulsar stars","0f0b019c":"### as shown in the heat map, each columns have distributed null values across all the column so we can use the *forward fillna* or *backword fillna*","91483e48":"# Read Data\nthe data contains 2 subsets <br\/>\n> 1- pulsar_data_train : to use it to train the model \n\n> 2- pulsar_data_test : to use it to test the model","e8b2f32f":"### remove outliers","b3d83522":"### as the accuracy matrices all are high then we don't need to try gridsearch to find the paramaters to get the best SVM","ea184db0":"columns names is very hard and can be simplified so will change it later","1a0c2a92":"from the previous figures we can find that filling the null did't affect the distribution of any features in the data","b068a06c":"# prepare train data for modeling <br\/>\n>## 1- correct columns names\n\n>## 2- remove duplicates\n\n>## 3- remove null\n\n>## 4- remove outliers","8b4b3b77":"## 2. RBF kernel SVM(with default parameters)","fa17f63f":"## Model the data with DBscan ","e26ccdb4":"# import necessary libraries ","f685ac0c":"# Start Modeling","06830f69":"### the percentage of noise is so big which mean it is totally incorrect parameters for the model so we need to change eps and min_sample in the future","679e01c4":"## 1. Linear Kenral SVM(using default paramaters)"}}