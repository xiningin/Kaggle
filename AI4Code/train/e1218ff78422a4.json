{"cell_type":{"c7070c24":"code","66e06402":"code","bd4101b2":"code","14134e2f":"code","33f2bd40":"code","a649f5a9":"code","0560094b":"code","91c6284c":"code","81afe2c2":"code","8a7f233c":"code","0f09ff03":"code","cb6ada8f":"code","14e78f12":"code","5dbdae12":"code","2c160eb0":"code","aabee2c6":"code","a6e13f89":"code","6f0950a4":"code","e6f0a2c0":"code","bd8e9670":"code","0479ab69":"code","7d8ae098":"code","f007be99":"code","6e7615e8":"code","761558ae":"code","54329c1b":"code","fa65ef7c":"code","f3a1e724":"code","ba2995c1":"code","dec524c5":"code","30a8f5ec":"code","8ef4260e":"code","8701c90a":"code","da3fb7d7":"code","ea8153c5":"code","530bcae6":"code","8fff6968":"code","101d5896":"code","cfa94450":"code","c7c73a37":"code","0f83297c":"code","53ed0b35":"code","aa4cfd5e":"code","e27c6d8d":"code","a7e34c4b":"code","3c6df36b":"code","b52fc120":"code","ab9b58e3":"code","df2e7dfb":"code","ff073058":"code","aff3a638":"code","4496fc83":"code","48d6d7dd":"code","dc67f3d0":"code","4352be94":"code","6bf3e5df":"code","6efd8e44":"code","dffb6dcb":"code","9e0c31b2":"code","6a0cb367":"code","f3cac683":"code","27c9727f":"code","b9d60786":"code","cda2ff49":"code","b7c5209e":"code","9550c550":"code","27bbb859":"code","acda762c":"code","cb29d1e2":"code","ca1475f3":"code","04913c76":"code","9e8d426e":"code","9ec3d219":"code","4f6faa35":"markdown","a0aeb669":"markdown","3738b296":"markdown","2aae9510":"markdown","4080af90":"markdown","f715675a":"markdown","300e7621":"markdown","1d7c9beb":"markdown","89fd7085":"markdown","a807d695":"markdown","1e0e1d56":"markdown","2ab2ed80":"markdown","0f8b9f86":"markdown","41cac191":"markdown","c8a6c0fd":"markdown","e00cedb1":"markdown","727de944":"markdown","4718d736":"markdown","29c28b90":"markdown","e22efd0e":"markdown","60971fcf":"markdown","1c79de0f":"markdown","faa989e7":"markdown","ef67b1a4":"markdown","446f7ab9":"markdown","253e4340":"markdown","c6e9a56f":"markdown","276efce5":"markdown","47d0fed0":"markdown","4bbf62f2":"markdown","cddfc871":"markdown","51002f4a":"markdown","f4a33709":"markdown","288ced5a":"markdown","6cbdd856":"markdown","a5bb3a72":"markdown","ff5974f7":"markdown","288bcf97":"markdown","53866720":"markdown","0b4dc496":"markdown","e6103f35":"markdown","428e0469":"markdown","1a775475":"markdown","a8d855f0":"markdown","d6e57ea5":"markdown","79f25336":"markdown","4f349290":"markdown","85591c29":"markdown","70effeb1":"markdown","0d82b4cb":"markdown","207729b6":"markdown","9beb8ba1":"markdown","5e9818dd":"markdown","2fdec2d5":"markdown","cbb950cc":"markdown","4208e8af":"markdown","7e61bc99":"markdown","e0a4ccbd":"markdown","b7814692":"markdown","fab826fe":"markdown"},"source":{"c7070c24":"!pip install kaggle --upgrade","66e06402":"def init_on_kaggle(username, api_key):\n    KAGGLE_CONFIG_DIR = os.path.join(os.path.expandvars('$HOME'), '.kaggle')\n    os.makedirs(KAGGLE_CONFIG_DIR, exist_ok = True)\n    api_dict = {\"username\":username, \"key\":api_key}\n    with open(f\"{KAGGLE_CONFIG_DIR}\/kaggle.json\", \"w\", encoding='utf-8') as f:\n        json.dump(api_dict, f)\n    cmd = f\"chmod 600 {KAGGLE_CONFIG_DIR}\/kaggle.json\"\n    output = subprocess.check_output(cmd.split(\" \"))\n    output = output.decode(encoding='UTF-8')\n    print(output)\n","bd4101b2":"from kaggle_secrets import UserSecretsClient\nimport os, json, subprocess\n\nuser_secrets = UserSecretsClient()\napi_secret = user_secrets.get_secret(\"kaggle api key\")\n\ninit_on_kaggle(\"donkeys\", api_secret)\n","14134e2f":"import kaggle\n\n#The API is simplest to access via kaggle.api object. \n#I will do that for the rest of this notebook, but you could just as well assign it to something shorter if you like\n#For example:\n\napi = kaggle.api\napi.get_config_value(\"username\")","33f2bd40":"\nddir = kaggle.api.get_default_download_dir()\nprint(ddir)\n","a649f5a9":"kaggle.api.get_default_download_dir(\"titanic\", \"bob\")","0560094b":"kaggle.api.get_config_value(\"username\")","91c6284c":"kaggle.api.print_config_value(\"username\", prefix=\"-\", separator=\": \")","81afe2c2":"kaggle.api.print_config_values(prefix=\"- \")","8a7f233c":"#this would show the API key as well, so I am not executing it\n#kaggle.api.config_values","0f09ff03":"#kaggle.api.print_config_value(\"key\", prefix=\"-\", separator=\": \")\n#kaggle.api.get_config_value(\"key\")","cb6ada8f":"\n#this crashes if there is a dataset with no files (size=None). for example search=\"us\"\ndatasets = kaggle.api.dataset_list(search=\"covid\")\nprint(datasets)","14e78f12":"ds = datasets[0]\nds_vars = vars(ds)\nfor var in ds_vars:\n    print(f\"{var} = {ds_vars[var]}\")","5dbdae12":"ds.tags","2c160eb0":"ds.licenseName","aabee2c6":"meta = kaggle.api.dataset_view(ds.ref)\nmeta.usabilityRating","a6e13f89":"kaggle.api.dataset_status(ds.ref)","6f0950a4":"kaggle.api.dataset_view(ds.ref)","e6f0a2c0":"file_result = kaggle.api.dataset_list_files(ds.ref)\nfile_result.files","bd8e9670":"kaggle.api.dataset_status(ds.ref)","0479ab69":"!mkdir example_init","7d8ae098":"kaggle.api.dataset_initialize(\"example_init\")","f007be99":"!cat example_init\/dataset-metadata.json","6e7615e8":"!mkdir dataset_download","761558ae":"kaggle.api.dataset_download_files(ds.ref, path=\"dataset_download\")","54329c1b":"!ls dataset_download","fa65ef7c":"kaggle.api.dataset_download_file(\"donkeys\/covid-nlp-preprocess\/\", \"output\/unknown.txt\")","f3a1e724":"!ls","ba2995c1":"!unzip unknown.txt.zip","dec524c5":"!head unknown.txt","30a8f5ec":"dataset_create_version(self,\n#                           folder,\n#                           version_notes,\n#                           quiet=False,\n#                           convert_to_csv=True,\n#                           delete_old_versions=False,\n#                           dir_mode='skip'):","8ef4260e":"#dataset_create_new(self,\n#                       folder,\n#                       public=False,\n#                       quiet=False,\n#                       convert_to_csv=True,\n#                       dir_mode='skip'):\n","8701c90a":"kernel_list = kaggle.api.kernels_list(search=\"covid\")\nkernel_list","da3fb7d7":"kernel = kernel_list[0]\nkernel_vars = vars(kernel)\nfor var in kernel_vars:\n    print(f\"{var} = {kernel_vars[var]}\")","ea8153c5":"kernel.ref","530bcae6":"!mkdir kernel_example","8fff6968":"kaggle.api.kernels_pull(kernel.ref, \"kernel_example\", metadata=True)\n","101d5896":"!ls -l kernel_example","cfa94450":"!cat kernel_example\/kernel-metadata.json","c7c73a37":"#kaggle.api.kernels_push(\"kernel_example\")\n","0f83297c":"!mkdir kernel_output","53ed0b35":"kaggle.api.kernels_output(kernel.ref, \"kernel_output\")","aa4cfd5e":"!ls -l kernel_output","e27c6d8d":"!cat kernel_output\/covid-19-analysis-visualization-comparisons.log","a7e34c4b":"kaggle.api.kernels_status(kernel.ref)\n","3c6df36b":"kaggle.api.competitions_list()","b52fc120":"!kaggle competitions list","ab9b58e3":"kaggle.api.competition_download_files(\"titanic\", path=\"download\")\n\n!ls -l download","df2e7dfb":"kaggle.api.competition_download_file(\"titanic\", \"train.csv\", path=\"download\")\n!ls -l download","ff073058":"kaggle.api.competition_submissions(\"titanic\")","aff3a638":"!ls -l","4496fc83":"kaggle.api.competition_leaderboard_download(\"titanic\", \"download_leaderboard\/leaderboard\")\n!ls -l download_leaderboard","48d6d7dd":"!ls download_leaderboard\/leaderboard","dc67f3d0":"!unzip download_leaderboard\/leaderboard\/titanic.zip","4352be94":"!ls","6bf3e5df":"!head titanic-publicleaderboard.csv","6efd8e44":"!wget https:\/\/repo1.maven.org\/maven2\/io\/swagger\/codegen\/v3\/swagger-codegen-cli\/3.0.19\/swagger-codegen-cli-3.0.19.jar -O swagger-codegen-cli.jar\n","dffb6dcb":"!ls","9e0c31b2":"!java -jar swagger-codegen-cli.jar --help","6a0cb367":"!git clone https:\/\/github.com\/Kaggle\/kaggle-api.git","f3cac683":"!ls kaggle-api","27c9727f":"%cd kaggle-api\n!pwd","b9d60786":"!java -jar ..\/swagger-codegen-cli.jar generate -l html2 -i KaggleSwagger.yaml -o SwaggerOutput","cda2ff49":"!java -jar ..\/swagger-codegen-cli.jar generate -l python -i KaggleSwagger.yaml -o SwaggerOutput\/python_client","b7c5209e":"!ls SwaggerOutput\/python_client","9550c550":"!java -jar ..\/swagger-codegen-cli.jar langs","27bbb859":"!ls -l SwaggerOutput","acda762c":"!ls","cb29d1e2":"!mv SwaggerOutput ..","ca1475f3":"%cd ..","04913c76":"!ls","9e8d426e":"!rm -rf dataset_download\n!rm -rf download_leaderboard\n!rm -rf example_init\n!rm -rf kaggle-api\n!rm swagger-codegen-cli.jar\n!rm *.txt*\n!rm *.csv\n","9ec3d219":"!ls SwaggerOutput","4f6faa35":"## kernels_push()\n\n- kernels_push(folder):\n\n        \"\"\" read the metadata file and kernel files from a notebook, validate\n            both, and use Kernel API to push to Kaggle if all is valid.\n             Parameters\n            ==========\n            folder: the path of the folder\n        \"\"\"\n","a0aeb669":"I believe the values you get back are identifiers for your own submissions made to the given competition. Or the versions of the submission.. Which is effectively the same as a submission.","3738b296":"We can list the values similar to the dataset object:","2aae9510":"## print_config_value()\n\n- kaggle.api.print_config_value(name, prefix='- ', separator=': '):\n\n        \"\"\"print a single configuration value, based on a prefix and separator\n\n           Parameters\n           ==========\n           name: the key of the config valur in self.config_values to print\n           prefix: the prefix to print\n           separator: the separator to use (default is : )\n        \"\"\"\n\nThis seems to be just a convenience method to print a value, same as getting it first, then calling print() on it.\n","4080af90":"The above would now upload the notebook from the \"kernel_example\" directory. Except it likely would not work since the current metadata file is generated from someone elses kernel, with their user info. So I would need to change the metadata.json to use my credentials instead.\n\nI find the simplest way to create the metadata file would be to create the notebook manually using the Kaggle website UI, downloading the kernel to also get the metadata file, along with the notebook file. Then use that as a template to upload the notebook again later (as an update).","f715675a":"## dataset_status()\n\n- kaggle.api.dataset_status(dataset):\n\n        \"\"\" call to get the status of a dataset from the API\n             Parameters\n            ==========\n            dataset: the string identified of the dataset\n                     should be in format [owner]\/[dataset-name]\n        \"\"\"\n","300e7621":"# Configuration\n\nAPI functions related to Kaggle configuration.","1d7c9beb":"This generates the HTML2 format documentation.I will be saved under \"SwaggerOutput\" directory, from where you can download it from this notebooks output files.","89fd7085":"The [metadata](https:\/\/github.com\/Kaggle\/kaggle-api\/wiki\/Dataset-Metadata) page actually shows a much more extensive example. Which is why I don't really see much point in generating this minimal template vs copying the metadata page example template..","a807d695":"From my experiments, I believe this does not actually list all files if your dataset has up to thousands of files. Rather it seems to list 20 first files under each directory. It also seems to list files inside zip files. So if your dataset has a single .zip file, this will actually list files inside that zip file, not the zip file itself. But I haven't really experimented in a lot of detail.","1e0e1d56":"I am not submitting to a competition in this notebook, but this function should allow you to do it..","2ab2ed80":"## competition_download_file()\n\n- kaggle.api.competition_download_file(competition, file_name, path=None, force=False, quiet=False):\n\n        \"\"\" download a competition file to a designated location, or use\n            a default location\n\n            Paramters\n            =========\n            competition: the name of the competition\n            file_name: the configuration file name\n            path: a path to download the file to\n            force: force the download if the file already exists (default False)\n            quiet: suppress verbose output (default is False)\n        \"\"\"","0f8b9f86":"When not running inside Kaggle kernel, just write the kaggle.json file yourself, based on the info from Kaggle. Or use my scripts if you want it automated.\n\nPractical use:","41cac191":"Clone the [Kaggle API from Github](https:\/\/github.com\/Kaggle\/kaggle-api):","c8a6c0fd":"First [install the Swagger jar](https:\/\/github.com\/swagger-api\/swagger-codegen):","e00cedb1":"You could generate the Kaggle API client code for many platforms using the following style. Just replace \"python\" with your favourite programming language. The HTML docs generated above might actually better suit that generated client than the repo code.. But as noted, I did not try it.","727de944":"I don't know what are all the options for values in the \"status\" columns, or what kind of error messages you might get in different situations. In a real use you would see, or read the code, I guess.","4718d736":"Thats all..","29c28b90":"If you just want to see all the config values at once, you can directly access the dict:","e22efd0e":"## dataset_initialize()\n\n- kaggle.api.dataset_initialize(folder):\n\n        \"\"\" initialize a folder with a a dataset configuration (metadata) file\n\n            Parameters\n            ==========\n            folder: the folder to initialize the metadata file in\n        \"\"\"\n\nInitialize a dataset with the [metadata file](https:\/\/github.com\/Kaggle\/kaggle-api\/wiki\/Dataset-Metadata). This seems a bit pointless to me, since you could just copy-paste the template from the [metadata page](https:\/\/github.com\/Kaggle\/kaggle-api\/wiki\/Dataset-Metadata) but whatever goes, I guess...\n","60971fcf":"## print_config_values()\n\n- kaggle.api.print_config_values(prefix='- '):\n\n        \"\"\"a wrapper to print_config_value to print all configuration values\n            Parameters\n           ==========\n           prefix: the character prefix to put before the printed config value\n                   defaults to \"- \"\n        \"\"\"","1c79de0f":"## kernels_status()\n- kernels_status(kernel):\n    \n        \"\"\" call to the api to get the status of a kernel.\n             Parameters\n            ==========\n            kernel: the kernel to get the status for\n        \"\"\"\n","faa989e7":"# Competitions","ef67b1a4":"# dataset_view()\n\n- kaggle.api.dataset_view(dataset):\n\n        \"\"\" view metadata for a dataset.\n\n            Parameters\n            ==========\n            dataset: the string identified of the dataset\n                     should be in format [owner]\/[dataset-name]\n        \"\"\"\n\nThis just gets the metadata same as above but for a specific dataset.","446f7ab9":"Since in the above (*kernel_pull()* section) we already downloaded a kernel, along with its metadata, we should now have everything we need in the \"kernel_example\" directory. To upload the same notebook, we could now just give the directory name as parameter:","253e4340":"You could download the index.html for the Swagger docs, and the python_client folder contains the generated Python client code for the Swagger API. Haven't tried it..","c6e9a56f":"## dataset_list_files()\n\n- kaggle.api.dataset_list_files(dataset):\n\n        \"\"\" list files for a dataset\n             Parameters\n            ==========\n            dataset: the string identified of the dataset\n                     should be in format [owner]\/[dataset-name]\n        \"\"\"\n","276efce5":"The returned values are actually metadata objects containing a number of different fields. We can list them all with vars():","47d0fed0":"the get and print functions still work for all configuration keys as well","4bbf62f2":"# get_default_download_dir()\n\n- kaggle.api.get_default_download_dir(*subdirs):\n\n        \"\"\" Get the download path for a file. If not defined, return default\n            from config.\n\n            Parameters\n            ==========\n            subdirs: a single (or list of) subfolders under the basepath\n        \"\"\"","cddfc871":"## dataset_create_version()\n\n- dataset_create_version(folder, version_notes, quiet=False, convert_to_csv=True, delete_old_versions=False, dir_mode='skip'):\n\n        \"\"\" create a version of a dataset\n\n            Parameters\n            ==========\n            folder: the folder with the dataset configuration \/ data files\n            version_notes: notes to add for the version\n            quiet: suppress verbose output (default is False)\n            convert_to_csv: on upload, if data should be converted to csv\n            delete_old_versions: if True, do that (default False)\n            dir_mode: What to do with directories: \"skip\" - ignore; \"zip\" - compress and upload\n        \"\"\"\n\nthis creates a dataset new version, much like the update_dataset() function in my [kaggle_uploader utility script](). I am not updating any dataset in this notebook so leaving the call commented..\n","51002f4a":"# Install\n\nKaggle Python API is already on PyPi, so install is simple:","f4a33709":"Set of supported languages to generate clients for:","288ced5a":"## dataset_download_file()\n\n- kaggle.api.dataset_download_file(dataset, file_name, path=None, force=False, quiet=True):\n\n        \"\"\" download a single file for a dataset\n\n            Parameters\n            ==========\n            dataset: the string identified of the dataset\n                     should be in format [owner]\/[dataset-name]\n            file_name: the dataset configuration file\n            path: if defined, download to this location\n            force: force the download if the file already exists (default False)\n            quiet: suppress verbose output (default is True)\n        \"\"\"","6cbdd856":"## dataset_create_new() \n\n- kaggle.api.dataset_create_new(folder, public=False, quiet=False, convert_to_csv=True, dir_mode='skip'):  \n\n        \"\"\" create a new dataset, meaning the same as creating a version but\n            with extra metadata like license and user\/owner.\n             Parameters\n            ==========\n            folder: the folder to initialize the metadata file in\n            public: should the dataset be public?\n            quiet: suppress verbose output (default is False)\n            convert_to_csv: if True, convert data to comma separated value\n            dir_mode: What to do with directories: \"skip\" - ignore; \"zip\" - compress and upload\n        \"\"\"\n\nthis creates a new dataset, much like the create_dataset() function in my [kaggle_uploader utility script](). I am not creating any dataset in this notebook so leaving the call commented..","a5bb3a72":"## Accessing all configuration values","ff5974f7":"There you see the \"index.html\" file, which is the generated docs for the Swagger API.","288bcf97":"# dataset_status()\n\n- kaggle.api.dataset_status(dataset):\n\n        \"\"\" call to get the status of a dataset from the API\n             Parameters\n            ==========\n            dataset: the string identified of the dataset\n                     should be in format [owner]\/[dataset-name]\n        \"\"\"\n        ","53866720":"The API needs a configuration to use. The simplest one is perhaps to write a *kaggle.json* file under the \".kaggle\" folder in your home directory. In Kaggle notebooks, I use this helper method I made.\n\nYou also need a Kaggle API key, which you can create under your profile. And add it to your notebook using the Kaggle secrets system. So under your notebook, look into \"Add-ons\/Secrets\". The following illustrates this:\n\n","0b4dc496":"## kernels_output()\n\n- kernels_output(kernel, path, force=False, quiet=True):\n\n        \"\"\" retrieve output for a specified kernel\n            Parameters\n            ==========\n            kernel: the kernel to output\n            path: the path to pull files to on the filesystem\n            force: if output already exists, force overwrite (default False)\n            quiet: suppress verbosity (default is True)\n        \"\"\"","e6103f35":"## dataset_download_files()\n\n- kaggle.api.dataset_download_files(dataset, path=None, force=False, quiet=True, unzip=False):\n\n        \"\"\" download all files for a dataset\n\n            Parameters\n            ==========\n            dataset: the string identified of the dataset\n                     should be in format [owner]\/[dataset-name]\n            path: the path to download the dataset to\n            force: force the download if the file already exists (default False)\n            quiet: suppress verbose output (default is True)\n            unzip: if True, unzip files upon download (default is False)\n        \"\"\"","428e0469":"There is also the CLI version of competitions list, as for most of the commands here. Besides the functions I list in this notebook, there are some others that are used as helpers for the CLI implementation. For example, [print_table()](https:\/\/github.com\/Kaggle\/kaggle-api\/blob\/master\/kaggle\/api\/kaggle_api_extended.py) formats tables such as below:","1a775475":"See the file KaggleSwagger.yaml? That is the top level spec for Swagger in this repo..","a8d855f0":"## kernels_list():\n- kernels_list(page=1, page_size=20, dataset=None, competition=None, parent_kernel=None, search=None, mine=False, user=None, language=None, kernel_type=None, output_type=None, sort_by=None):\n\n        \"\"\" list kernels based on a set of search criteria\n\n            Parameters\n            ==========\n            page: the page of results to return (default is 1)\n            page_size: results per page (default is 20)\n            dataset: if defined, filter to this dataset (default None)\n            competition: if defined, filter to this competition (default None)\n            parent_kernel: if defined, filter to those with specified parent\n            search: a custom search string to pass to the list query\n            mine: if true, group is specified as \"my\" to return personal kernels\n            user: filter results to a specific user\n            language: the programming language of the kernel\n            kernel_type: the type of kernel, one of valid_list_kernel_types (str)\n            output_type: the output type, one of valid_list_output_types (str)\n            sort_by: if defined, sort results by this string (valid_list_sort_by)\n        \"\"\"","d6e57ea5":"The *dataset_download_file()* function downloads a single file, in this case from inside a zip file. Because my COVID NLP preprocessed dataset consists of a single ZIP file that has thousands of files inside the ZIP file, including one named \"output\/unknown.txt\". But it seems to return the requested single file zipped itself. A bit weird but OK, lets go with that:","79f25336":"# Kaggle Python API\n\nThe Kaggle Python API is rather poorly documented. Or actually not really documented at all.\nThere are [pages]((https:\/\/www.kaggle.com\/docs\/api)) for the command line interface (CLI), that seems to be named the \"Kaggle API\".\nThe implementation of these CLI tools is available on [Github](https:\/\/github.com\/Kaggle\/kaggle-api),\nagain named \"Kaggle API\" but with no real API documentation.\n\nThis notebook is to document the Python API as it implements the CLI tools.\nFor this, I cloned the Kaggle API Github reposiroty, set it up as a project in PyCharm,\nand browsed through the API implementation, mainly the [kaggle_api_extended.py](https:\/\/github.com\/Kaggle\/kaggle-api\/blob\/master\/kaggle\/api\/kaggle_api_extended.py) class, along with others. \nTried some code in practice at the same time, used the debugger to figure it out.\n\nNow you should all upvote so I get one of those kernel medals, yes sir (and madam) :)","4f349290":"## competition_submissions()\n\n- kaggle.api.competition_submissions(competition)\n\n        \"\"\" get the list of Submission for a particular competition\n\n            Parameters\n            ==========\n            competition: the name of the competition\n        \"\"\"","85591c29":"## competition_submit()\n\n- kaggle.api.competition_submit()\n\n        \"\"\" submit a competition!\n\n            Parameters\n            ==========\n            file_name: the competition metadata file\n            message: the submission description\n            competition: the competition name\n            quiet: suppress verbose output (default is False)\n        \"\"\"\n\n","70effeb1":"## competition_leaderboard_download()\n\n- kaggle.api.competition_leaderboard_download(competition, path, quiet=True):\n\n        \"\"\" Download competition leaderboards\n\n            Parameters\n            =========\n            competition: the name of the competition\n            path: a path to download the file to\n            quiet: suppress verbose output (default is True)\n        \"\"\"","0d82b4cb":"# Swagger API documentation\n\nThe Kaggle Github reposiroty actually contains files to generate API documents and API clients for different programming languages using [Swagger](https:\/\/swagger.io\/). I personally found it weird, since the API documentations that it generates does not seem to match the code that is in the Github repo. Maybe you are supposed to use the Swagger client separately? I just went with the actual code in the repo as I documented above. But here is how to generate API clients and HTML documentation for Kaggle API using Swagger.","207729b6":"## get_config_value()\n\n- kaggle.api.get_config_value(name):\n\n        \"\"\" return a config value (with key name) if it's in the config_values,\n            otherwise return None\n\n            Parameters\n            ==========\n            name: the config value key to get\n\n        \"\"\"","9beb8ba1":"# Datasets","5e9818dd":"*print_config_values()* sounds like it would print every configuration value defined. But the implementation is\/was actually this:\n\n        print('Configuration values from ' + self.config_dir)\n        self.print_config_value(self.CONFIG_NAME_USER, prefix=prefix)\n        self.print_config_value(self.CONFIG_NAME_PATH, prefix=prefix)\n        self.print_config_value(self.CONFIG_NAME_PROXY, prefix=prefix)\n        self.print_config_value(self.CONFIG_NAME_COMPETITION, prefix=prefix)\n\nSo it doesn't really print everything. For example, the \"key\" value is not printed.\n\nHere is a snippet from the API code that defines a few more configuration options:\n\n    CONFIG_NAME_PROXY = 'proxy'\n    CONFIG_NAME_COMPETITION = 'competition'\n    CONFIG_NAME_PATH = 'path'\n    CONFIG_NAME_USER = 'username'\n    CONFIG_NAME_KEY = 'key'\n    CONFIG_NAME_SSL_CA_CERT = 'ssl_ca_cert'","2fdec2d5":"## competitions_list()\n\n- kaggle.api.competitions_list(group=None, category=None, sort_by=None, page=1, search=None)\n\n        \"\"\" make call to list competitions, format the response, and return\n            a list of Competition instances\n\n            Parameters\n            ==========\n\n            page: the page to return (default is 1)\n            search: a search term to use (default is empty string)\n            sort_by: how to sort the result, see valid_competition_sort_by for options\n            category: category to filter result to\n            group: group to filter result to\n        \"\"\"","cbb950cc":"# Kernels (called Notebooks these days but the API is classic)","4208e8af":"## dataset_list()\n\n- kaggle.api.dataset_list(sort_by=None, size=None, file_type=None, license_name=None, tag_ids=None, search=None, user=None, mine=False, page=1, max_size=None, min_size=None):\n\n        \"\"\" return a list of datasets!\n\n            Parameters\n            ==========\n            sort_by: how to sort the result, see valid_dataset_sort_bys for options\n            size: Deprecated\n            file_type: the format, see valid_dataset_file_types for string options\n            license_name: string descriptor for license, see valid_dataset_license_names\n            tag_ids: tag identifiers to filter the search\n            search: a search term to use (default is empty string)\n            user: username to filter the search to\n            mine: boolean if True, group is changed to \"my\" to return personal\n            page: the page to return (default is 1)\n            max_size: the maximum size of the dataset to return (bytes)\n            min_size: the minimum size of the dataset to return (bytes)\n        \"\"\"\n","7e61bc99":"As the above illustrates, this Kaggle API overall seems a bit of a sideproject with not too much effort put into it from the programmatic API perspective. If there is no \"path\" value in the kaggle.json configuration file, *get_default_download_dir()* just prints the current working directory. Even if you give it some subdir parameters.\n\nsnippet from the API code that does this:\n        # If not set in config, default to present working directory\n        if path is None:\n            return os.getcwd()\n            \nI currently do not have a \"path\" set in kaggle.json, so this illustrates how it just gives the working directory regardless of parameters:","e0a4ccbd":"## competition_download_files()\n\n- kaggle.api.competition_download_files(\n\n        \"\"\" downloads all competition files.\n\n            Parameters\n            =========\n            competition: the name of the competition\n            path: a path to download the file to\n            force: force the download if the file already exists (default False)\n            quiet: suppress verbose output (default is True)\n        \"\"\"\n\n","b7814692":"You can access each field by *objectname.fieldname*, such as:","fab826fe":"## kernels_pull()\n\n- kernels_pull(kernel, path, metadata=False, quiet=True):\n\n        \"\"\" pull a kernel, including a metadata file (if metadata is True)\n            and associated files to a specified path.\n             Parameters\n            ==========\n            kernel: the kernel to pull\n            path: the path to pull files to on the filesystem\n            metadata: if True, also pull metadata\n            quiet: suppress verbosity (default is True)\n        \"\"\""}}