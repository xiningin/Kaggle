{"cell_type":{"61bd0721":"code","f0885ab9":"code","c4b8c8cc":"code","7daa338a":"code","b2f244c1":"code","6b84d077":"code","f04dcfa4":"code","ef5d34dc":"code","1893fbe9":"code","2851c63c":"code","e08b1328":"code","9274d694":"code","80ae3383":"code","741112ef":"code","30227a99":"code","18efe261":"code","9fff89b5":"code","1d330f02":"code","928071bb":"code","7c2eb6aa":"code","05f8debb":"code","51c4a95c":"code","91c9066e":"code","b4492611":"code","3af79f18":"code","80840d38":"code","e7528073":"code","b83c62fd":"code","95c62d4c":"markdown","35e15062":"markdown","17c05491":"markdown","2bedb49f":"markdown","9fe4c5ee":"markdown","3c4b654c":"markdown","7327fd26":"markdown","4a9f30e3":"markdown","6068f49f":"markdown","895c3365":"markdown"},"source":{"61bd0721":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f0885ab9":"res_aluno = pd.read_csv('..\/input\/TS_RESULTADO_ALUNO.csv', sep=';', decimal=',')","c4b8c8cc":"quest_aluno = pd.read_csv('..\/input\/TS_QUEST_ALUNO.csv', sep=';', decimal=',')","7daa338a":"res_aluno.shape, quest_aluno.shape","b2f244c1":"res_aluno.info()","6b84d077":"res_aluno.head(10)","f04dcfa4":"quest_aluno.sample(10)","ef5d34dc":"import seaborn as sns\n\n# sns.heatmap(res_aluno, dropna=True)\n# sns.pairplot(res_aluno, dropna=True)  # demora muito","1893fbe9":"# Filtrando dados \u00fateis\nres_aluno = res_aluno[res_aluno['IN_PROFICIENCIA']==1]  # Somente as que cont\u00e9m o m\u00ednimo de respostas\n\n# Removendo peso\nremover = 2000000\ndrop_indices = np.random.choice(res_aluno.index, remover, replace=False)\nres_aluno = res_aluno.drop(drop_indices)","2851c63c":"# Limpeza ALUNO\n\ncolunas = ['PESO', 'PROFICIENCIA_LP', 'DESVIO_PADRAO_LP', 'PROFICIENCIA_LP_SAEB', 'DESVIO_PADRAO_LP_SAEB',\n           'PROFICIENCIA_MT', 'DESVIO_PADRAO_MT', 'PROFICIENCIA_MT_SAEB', 'DESVIO_PADRAO_MT_SAEB', 'ID_TURNO']\nres_aluno[colunas] = res_aluno[colunas].applymap(lambda x: str(x).replace(',', '.'))  # applymap funcionou outros map, apply nops\nres_aluno.replace(r'^\\s*$', np.nan, regex=True, inplace=True)  # limpa campos que s\u00f3 tem espa\u00e7o em branco\nres_aluno.replace('nan', np.nan, regex=True, inplace=True)  # limpa campos que tem escrito 'nan'\nres_aluno[colunas] = res_aluno[colunas].apply(pd.to_numeric)\nres_aluno.info()","e08b1328":"res_aluno.isna().sum()","9274d694":"# A fun\u00e7\u00e3o abaixo foi obtida em https:\/\/www.kaggle.com\/arjanso\/reducing-dataframe-memory-size-by-65\ndef reduce_mem_usage(props):\n    \"\"\"Fun\u00e7\u00e3o para reduzir a mem\u00f3ria dos Dataframes\"\"\"\n    start_mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",props[col].dtype)\n            print(\"******************************\")\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return props, NAlist","80ae3383":"res_aluno, _ = reduce_mem_usage(res_aluno)\nquest_aluno, _ = reduce_mem_usage(quest_aluno)","741112ef":"# Criando a coluna alvo\nmediana = res_aluno['PROFICIENCIA_LP'].median()\nprint(mediana)\n\nres_aluno['mediana_lp'] = res_aluno['PROFICIENCIA_LP'] >= mediana","30227a99":"# Criandos os dummies do res_aluno\ndummies_res = ['ID_UF', 'ID_DEPENDENCIA_ADM', 'ID_LOCALIZACAO', 'ID_SERIE', 'ID_TURNO']\nres_aluno = pd.get_dummies(data=res_aluno, columns=dummies_res)","18efe261":"# Juntando os dummies ao dataframe\n# res_aluno = res_aluno[['ID_ALUNO', 'IN_SITUACAO_CENSO', 'IN_PROFICIENCIA', 'PROFICIENCIA_MT', 'PROFICIENCIA_LP']]\n# res_aluno = pd.concat([res_aluno, dummies_res], axis=1)\n# res_aluno.info()","9fff89b5":"# Criando os dummies do quest_aluno\ncolunas_quest = ['ID_ALUNO', 'TX_RESP_Q001', 'TX_RESP_Q002', 'TX_RESP_Q004', 'TX_RESP_Q005', 'TX_RESP_Q012', 'TX_RESP_Q013', 'TX_RESP_Q017',\n                 'TX_RESP_Q018', 'TX_RESP_Q020', 'TX_RESP_Q022', 'TX_RESP_Q024', 'TX_RESP_Q027', 'TX_RESP_Q033', 'TX_RESP_Q038',\n                 'TX_RESP_Q039', 'TX_RESP_Q044', 'TX_RESP_Q045', 'TX_RESP_Q046', 'TX_RESP_Q047', 'TX_RESP_Q049', 'TX_RESP_Q050',\n                 'TX_RESP_Q051', 'TX_RESP_Q052']\nquest_aluno = quest_aluno[colunas_quest]","1d330f02":"# Juntando os dataframes\ncolunas_quest.remove('ID_ALUNO')\nquest_aluno = pd.get_dummies(data=quest_aluno, columns=colunas_quest)","928071bb":"alunos = res_aluno.merge(quest_aluno, on='ID_ALUNO', how='left')","7c2eb6aa":"alunos.info()","05f8debb":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ntrain, test = train_test_split(alunos, random_state=42, test_size=0.3)\n\ncols = [c for c in train.columns if c not in ['mediana_lp', 'PROFICIENCIA_LP', 'PROFICIENCIA_LP_SAEB', \n                                              'DESVIO_PADRAO_LP_SAEB', 'ID_MUNICIPIO', 'ID_PROVA_BRASIL', \n                                              'ID_TURMA','ID_ALUNO', 'IN_SITUACAO_CENSO', 'IN_PREENCHIMENTO', \n                                              'PESO', 'IN_PROFICIENCIA', 'DESVIO_PADRAO_MT', 'DESVIO_PADRAO_LP',\n                                             'PROFICIENCIA_MT_SAEB', 'DESVIO_PADRAO_MT_SAEB', 'ID_ESCOLA']]","51c4a95c":"print(cols)","91c9066e":"from sklearn.linear_model import LogisticRegression\n\nlg = LogisticRegression(n_jobs=-1)\nlg.fit(train[cols], train['mediana_lp'])","b4492611":"preds2 = lg.predict(test[cols])\naccuracy_score(test['mediana_lp'], preds2)","3af79f18":"rf = RandomForestClassifier(n_jobs=-1, n_estimators=25)\nrf.fit(train[cols], train['mediana_lp'])","80840d38":"preds = rf.predict(test[cols])\naccuracy_score(test['mediana_lp'], preds)","e7528073":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(10, 10))\npd.Series(rf.feature_importances_[:10], index=cols[:10]).sort_values().plot.barh()","b83c62fd":"# fig = plt.figure(figsize=(10, 10))\n# pd.Series(lg.feature_importances_, index=cols).sort_values().plot.barh()","95c62d4c":"# Engenharia de Dados\n\nPara obtermos mais dados para utilizar nos algoritmos de classifica\u00e7\u00e3o da vari\u00e1vel alvo, foram criadas diversas vari\u00e1veis dummies a partir das vari\u00e1veis classificat\u00f3rias dos dados originais. Isso ajuda a normalizar os dados, removendo comparativos de tamanho entre vari\u00e1veis classificat\u00f3rias.\n\n## Dummies\n\nPara gera\u00e7\u00e3o dos dummies, foram selecionadas algumas colunas do dataframe original, a fim de termos colunas mais significativas para o trabalho.","35e15062":"# Resultados\n\nTivemos um indice de acur\u00e1cia de aproximadamente 80% utilizando o RandomForest. O gr\u00e1fico apresentado, verifica-se que a var\u00ed\u00e1vel PROEFICIENCIA_MT tem muito influ\u00eancia em rela\u00e7\u00e3o a vari\u00e1vel predita(PROEFICIENCIA_LP).\n","17c05491":"# Carga dos Dados\n","2bedb49f":"# Modelos, Predi\u00e7\u00e3o e C\u00e1lculo\n\nSer\u00e3o utilizados o modelo de regress\u00e3o logistica e random forest. Pretende-se com esses m\u00e9todos obter a vari\u00e1vel alvo. \n\n## Verifica\u00e7\u00e3o dos Modelos\n\nSer\u00e1 utilizada a acur\u00e1cia como m\u00e9trica para verificar os modelos.\n","9fe4c5ee":"Por causa do tamanho dos dataframes, o Kaggle estava apresentando diversos erros ao rodar o script. Desta forma, utilizamos uma fun\u00e7\u00e3o que converte o tipo de dado para o menor tipo poss\u00edvel, que possa ser representado sem que se perca a informa\u00e7\u00e3o do mesmo. Ex: se um n\u00famero varia de -10 a +10 n\u00e3o \u00e9 necess\u00e1rio usar um inteiro de 64 bits para armazenar, 8 bits bastam (2<sup>8<\/sup> = 256).\n","3c4b654c":"# Limpeza dos Dados\n\nAntes de podermos trabalhar nos dados \u00e9 necess\u00e1rio que estes estejam padronizados, ou seja, n\u00fameros serem n\u00fameros, textos como strings, e somente um tipo de indicador de nulos, no caso o np.nan. \n\nNo caso dos n\u00fameros, apesar de terem sido carregados com decimal = ',', isso n\u00e3o foi suficiente para eliminar erros, pois o pandas detectou outros dados diferente de n\u00fameros em outras linhas (espa\u00e7o em branco, 'nan', etc). Portanto \u00e9 necess\u00e1rio converter manualmente esses dados.\n\nO Dataframe res_aluno \u00e9 o que tinha os piores casos a serem tradados em rela\u00e7\u00e3o ao quest_aluno.\n\n**Por motivos de restri\u00e7\u00f5es de mem\u00f3ria do Kaggle, tivemos que remover 2 milh\u00f5es de linhas aleat\u00f3rias.**","7327fd26":"# Criando a coluna alvo\n\nEscolhemos como coluna alvo para classifica\u00e7\u00e3o dos algoritmos a classifica\u00e7\u00e3o do aluno quanto a mediana da nota de proficiencia em lingua portuguesa.","4a9f30e3":"# Cruzamento dos dados\n\nTexto sobre cruzamento dos dados. Talvez fazer cruzamento antes das demais tarefas!?","6068f49f":"## Avalia\u00e7\u00e3o das features utilizadas","895c3365":"# Dados do INEP 2011\n\nO banco de dados escolhido refere-se a aplica\u00e7\u00e3o da Prova Brasil e Saeb. Esses dois exames comp\u00f5e o Sistema de Avalia\u00e7\u00e3o da Educa\u00e7\u00e3o B\u00e1sica, ou seja, essas provas tem o objetivo de avaliar a qualidade da educa\u00e7\u00e3o b\u00e1sica. A prova do Saeb foi aplicada a primeira vez em 1990, j\u00e1 a Prova Brasil foi aplicada a primeira vez em 2005. Os dois conceitos avaliados s\u00e3o as habilidades em L\u00edngua Portuguesa (foco em leitura) e Matem\u00e1tica (foco na resolu\u00e7\u00e3o de problemas).\n\nFonte dos dados: \nhttp:\/\/smeduquedecaxias.rj.gov.br\/nead\/Biblioteca\/Gest%C3%A3o\/IDEB\/portal.inep.gov.br\/web\/saeb-e-prova-brasil\/prova-brasil-e-saeb.html\n"}}