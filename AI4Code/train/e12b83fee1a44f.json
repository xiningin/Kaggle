{"cell_type":{"cacf1fa2":"code","cde27b28":"code","f576bb33":"code","d22f9230":"code","122a85bc":"code","65e2453b":"code","977903c6":"code","9653abc5":"code","4137de31":"code","729c51e1":"code","f174b2da":"code","8f29632f":"code","2da8f859":"code","a4a55a72":"code","8e89bbdc":"code","df68784b":"code","92568077":"code","b2f376a9":"code","78fc7e74":"code","57326cd0":"code","b2fe707a":"code","b7ef710f":"markdown","403eeca5":"markdown"},"source":{"cacf1fa2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cde27b28":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f576bb33":"#Loading the Dataset\nurl = (\"..\/input\/creditcardfraud\/creditcard.csv\")\ncredit_card_data = pd.read_csv(url)","d22f9230":"#Looking at the first four rows of the data\ncredit_card_data.head()\n\n#Columns in the data\ncolumn_names = credit_card_data.columns\nprint(column_names)","122a85bc":"#Getting the number of classes in the data\ncredit_card_data[\"Class\"].value_counts()\n\ncredit_card_data[\"Class\"].describe()","65e2453b":"credit_card_data.describe()","977903c6":"credit_card_data.hist(bins=50,figsize=(20,15))\nplt.show()","9653abc5":"#Plotting a scatter matrix\nfrom pandas.plotting import scatter_matrix\nattributes = ['Class','Time', 'V1', 'V2', 'V3', 'V4']\nscatter_matrix(credit_card_data[attributes],figsize=(20,10))\nplt.show()","4137de31":"#Visualing the correlation between attributes\ncorr_mat = credit_card_data.corr()\ncorr_mat[\"Class\"].sort_values(ascending = True)","729c51e1":"#V4 and V11 tends to have some positive correlation with class. To see the same, lets plot a scatter between the two\nattributes = [\"Class\",\"V11\"]\nscatter_matrix(credit_card_data[attributes], figsize=(20,10))\nplt.show()","f174b2da":"X = credit_card_data.drop([\"Class\"],axis=1)\nY = credit_card_data[\"Class\"]\ncredit_card_data.shape","8f29632f":"print(X.shape)\nprint(Y.shape)","2da8f859":"#Getting the number of positive and negative instances\noutliers = Y[Y==1]\nnum_outliers = len(outliers)\nnum_normal = len(Y)-num_outliers\noutlier_frac = num_outliers\/num_normal\nprint(len(Y))\nprint(num_outliers, num_normal)\nprint(outlier_frac)","a4a55a72":"#Outlier detection using LOF\nfrom sklearn.neighbors import LocalOutlierFactor\nlof = LocalOutlierFactor(n_neighbors=15,contamination=0.005)\nY_predict = lof.fit_predict(X)\n","8e89bbdc":"#Having a look at the predictions\nprint(Y_predict[:20])\nprint(Y[:20])","df68784b":"#Reshaping the prediction values as per the desired output i.e. 0 for normal 1 for outlier\nY_predict[Y_predict==1]=0\nY_predict[Y_predict==-1]=1\nprint(Y_predict[4920])\nprint(Y[4920])\n#Getting the negative outlier factor\n#Inliers tend to have a LOF score close to 1 (negative_outlier_factor_ close to -1), \n#while outliers tend to have a larger LOF score.\n\nlof_score = lof.negative_outlier_factor_\nprint(lof_score)","92568077":"#Getting the number of errors\nlof_n_error = (Y_predict!=Y).sum()\nprint(outliers)\nprint(lof_n_error)","b2f376a9":"#Getting the accuracy and classification report\nfrom sklearn.metrics import accuracy_score, classification_report\nprint(\"Accuracy:{}\",format(accuracy_score(Y_predict,Y)))\nprint(\"Classification Report:\",classification_report(Y_predict,Y))","78fc7e74":"#Using the isolation forest \nfrom sklearn.ensemble import IsolationForest\n\nisf = IsolationForest(max_samples=len(X),contamination=outlier_frac,random_state=1)\ny_pred = isf.fit_predict(X)","57326cd0":"y_pred[y_pred==1]=0\ny_pred[y_pred==-1]=1\nprint(Y_predict[4920])\nprint(Y[4920])\nisf_n_error = (y_pred!=Y).sum()\nprint(isf_n_error)","b2fe707a":"print(\"Accuracy:{}\",format(accuracy_score(y_pred,Y)))\nprint(\"Classification Report:\",classification_report(y_pred,Y))","b7ef710f":"There seems to be no linear correlation between the target attribute and the features. Further the number of positive examples are far more greater than the number of negative examples. Hence, the problem is a clear case of anomally detection.","403eeca5":"We will be experimenting with two algorithms for anomally detection:\n1. Outlier detection with Local Outlier Factor (LOF)\n2. Isolation Forest Algorithm\nWe will then compare the performance of the true."}}