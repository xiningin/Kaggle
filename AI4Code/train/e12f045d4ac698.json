{"cell_type":{"518b2de0":"code","880413a0":"code","02698754":"code","3d929f14":"code","317788d3":"code","17ef6388":"code","f481b90f":"code","2f82c95a":"code","0ada1b68":"code","ee7c62ee":"code","09831d11":"code","636e88fd":"code","50625d49":"code","3c8d8061":"code","506773cf":"code","57dbd7d8":"code","9a412dce":"code","902990f2":"code","aea6f6f7":"code","cf2a83f1":"code","1513ed92":"code","ebbbf8b3":"code","93a2e96e":"code","7dd91b04":"code","e7b63f1b":"code","f1ca4fb3":"code","b2b1e7d2":"code","5a91bca8":"code","fb9a39ec":"code","67e5d0f0":"code","071b67f5":"code","ec494fc6":"code","f9ea0130":"code","8f87a3a4":"code","301caffc":"code","e27c67b6":"code","33aad3dd":"code","5966a17b":"code","1891a20a":"code","c6834c55":"code","9b08a2e2":"code","02c63e0d":"code","fe389469":"code","11da3a29":"code","4dfc3bc7":"code","3082acfd":"code","04532a21":"code","df6a2900":"code","95b7bffa":"code","991ad171":"code","c184e221":"code","8913704a":"code","7fdef4f1":"code","311852be":"code","cbc20c82":"code","334956fe":"code","c3c56bd0":"code","9fa4ac86":"code","9956e192":"code","5d4d7427":"code","148fb17c":"code","22bf68a8":"code","d3055d25":"code","8b2bc133":"code","4f6bbb30":"code","d43b70d7":"code","ca9727ff":"code","5ae4c5ba":"code","595966dc":"code","5cf3afe9":"code","0071c985":"code","c3ac3550":"code","e0b3dc1e":"code","2e1520bf":"code","919e109a":"code","946e7fe0":"code","6e61b80a":"code","df2e057a":"code","3e5e2f53":"code","4c52d31f":"code","c264466b":"code","f4ac4a2e":"code","01ca3898":"code","562cdc0b":"code","4d702429":"code","bb3b70b7":"code","a14f4221":"code","cc5ae948":"code","bb374c27":"code","3077b2d7":"code","896c101a":"code","ada8d60a":"code","97294b38":"code","ea54db78":"code","a0e12186":"code","d9af2ba9":"code","ff378a3c":"code","0f8375cb":"code","40a7476a":"code","937ba30c":"code","16976d88":"code","42878222":"code","caba1ef2":"code","ac97eed3":"code","890aa072":"code","d5ef10cb":"code","98d7e402":"code","ed704f11":"code","c1a5b0c4":"code","1ce43a80":"code","412e0f2f":"code","5a3beab6":"code","2f79b641":"code","dd8e38d7":"code","bb1872d7":"code","0c49cd34":"markdown","62ad666b":"markdown","3a4114b3":"markdown","129bed2e":"markdown","83690eb7":"markdown","7d8c17e3":"markdown","7b4fb6a7":"markdown","888316b4":"markdown","385c3420":"markdown","43e44ca5":"markdown","29c2629a":"markdown","da58c04a":"markdown","55ac5e71":"markdown","f8534d20":"markdown","047a31f0":"markdown","1f12d079":"markdown","09d487a5":"markdown","0111a696":"markdown","74aa028a":"markdown","50f7494a":"markdown","01bfd2d8":"markdown","5da29f2a":"markdown","5a5eb51b":"markdown","859d03e2":"markdown","d7c79d78":"markdown","2c297405":"markdown","6a7e779e":"markdown","1ee3949d":"markdown","9df7aa63":"markdown","25a129f5":"markdown","4f3b1cec":"markdown","0e8c815f":"markdown","3e926eba":"markdown","52687f84":"markdown","ec0030f7":"markdown","9a59343b":"markdown","762ff382":"markdown","8635cf40":"markdown","07c89f16":"markdown","36cdab75":"markdown","64b6f631":"markdown","c6c9601b":"markdown","89e277bb":"markdown"},"source":{"518b2de0":"# Imports\n##################################################\n\nimport numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport emoji\nimport seaborn as sns\n\nimport pyLDAvis\nimport pyLDAvis.gensim as gensimvis\n\n# To preprocess the data \nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom collections import Counter\nfrom nltk.corpus import stopwords\n\nimport gensim\nfrom gensim.corpora.dictionary import Dictionary\n\nfrom itertools import cycle\n\n#For the machine laerning part\n\nfrom sklearn import svm\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.model_selection import learning_curve\n\n##################################################\n# Params\n##################################################\n\n\n##################################################\n# Utils\n##################################################","880413a0":"def label_to_emoji(label):\n    \"\"\"\n    Converts a label (int or string) into the corresponding emoji code (string) ready to be printed\n    \"\"\"\n    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)","02698754":"def plot_pie_chart(df_, labels,ax,title_,colors):\n    \n    proportion=df_.groupby('class').size()\n    class_proportion_train=[]\n    for class_ in range(5):\n        class_proportion_train.append(proportion[class_]\/len(df_))\n    \n    ax.pie(class_proportion_train,  labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90, colors=colors)\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    ax.set_title(title_)","3d929f14":"def count_words(df):\n    lenght=[]\n    for text in df['phrase']:\n        lenght.append(len(text.split()))\n    return lenght","317788d3":"def tokenize_phrase(df):\n    lower_token=[]\n    token_phrases=[word_tokenize(phrase) for phrase in df['phrase']]\n    for phrase in token_phrases:\n        lower_token.append([t.lower() for t in phrase])\n        \n    return lower_token","17ef6388":"def tokenize_tot_phrase(df):\n    lower_token=[]\n    token_phrases=[word_tokenize(phrase) for phrase in df['phrase']]\n    for phrase in token_phrases:\n        for t in phrase:    \n            lower_token.append(t.lower())\n    return lower_token","f481b90f":"def calculate_plot_cv_NB(X_train,Y_train,X_cv,Y_cv,values):\n  train_scores=[]\n  cv_scores=[]\n\n  for value in values: #train and evaluate the score for every value in the list values \n  \n    model=MultinomialNB(alpha=value)\n    model.fit(X_train, Y_train)\n    Y_train_predict_proba = model.predict(X_train)[:]\n    Y_cv_predict_proba = model.predict(X_cv)[:]\n\n    train_scores.append(metrics.accuracy_score(Y_train, Y_train_predict_proba))\n    cv_scores.append(metrics.accuracy_score(Y_cv, Y_cv_predict_proba))\n\n  \n  plt.figure(figsize=(10,5))\n\n  plt.plot(values, train_scores, label='Training', marker='o', lw=0, ms=10)\n  plt.plot(values, cv_scores, label='Cross-Validation', marker='*', lw=0, ms=12)\n\n  plt.xlabel(\"Alpha\", fontsize=20)\n  plt.ylabel(\"average precision\", fontsize=20)\n  #plt.xlim(1e-9, 1e9)\n\n  plt.xscale('log')\n\n  plt.grid()\n  plt.legend(loc='best',fontsize=20)\n  plt.tick_params( length=2, width=2, grid_alpha=1, labelsize=20)\n\n  return (train_scores,cv_scores)","2f82c95a":"def print_metrics(model,y_,x_,accuracy=True,f1=True,precision=True,recall=True):\n  print(\"| {:25} | {} |\".format(\"Metrics\", \" Validation Score  \"))\n  print(\"| {} | {} |\".format(\"-\"*25, \"-\"*17))\n\n  if accuracy:\n    print('Accuracy :                        '+str(round(metrics.accuracy_score(y_,model.predict(x_)),3)))\n  if f1:\n    print('F1 score:                         '+str(round(metrics.f1_score(y_,model.predict(x_),  average='macro'),3)))\n  if precision:\n    print('Precision :                       '+str(round(metrics.precision_score(y_, model.predict(x_), average='macro'),3)))\n  if recall:\n    print('Recall :                          '+str(round(metrics.recall_score(y_, model.predict(x_), average='macro'),3))+'\\n')","0ada1b68":"def evaluate_model(model,x_t,y_t,x_v,y_v):\n  model.fit(x_t, y_t)\n  pred = model.predict(x_v)\n\n  print(classification_report(y_v, model.predict(x_v)))\n\n  print_metrics(model,y_v,x_v)\n\n  return pred","ee7c62ee":"def accuracy(y_pred, y_true):\n    '''\n    input y_pred: ndarray of shape (N,)\n    input y_true: ndarray of shape (N,)\n    '''\n    return (1.0 * (y_pred == y_true)).mean()","09831d11":"def lemmatize_phrase(df):\n    lemm_token=[]\n    token_phrases=[word_tokenize(phrase) for phrase in df['phrase']]\n    for phrase in token_phrases:\n        lemm_token.append([WordNetLemmatizer().lemmatize(t) for t in phrase])\n        \n    return lemm_token","636e88fd":"def print_table_emoji(pred, title):\n  print('########   '+str(title)+'   ########')\n  print('          '+ label_to_emoji(0)+ ' ' + label_to_emoji(1) + ' ' +  label_to_emoji(2)+ ' ' + label_to_emoji(3)+' ' + label_to_emoji(4))\n  print(pd.crosstab(y_validation,pred.reshape(len(df_pred),),  rownames=['Actual'], colnames=['Predicted'], margins=True))\n  print('\\n')","50625d49":"def plot_confusion_matrix_classifier(classifier,title_):\n\n  fig,ax=plt.subplots(1,2, figsize=(20,6))\n  titles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\n  class_names=[0,1,2,3,4]\n  #class_names=[label_to_emoji(0),label_to_emoji(1),label_to_emoji(2),label_to_emoji(3),label_to_emoji(4)]\n  i=0\n  for title, normalize in titles_options:\n      plot_confusion_matrix(classifier, x_val, y_validation, display_labels=class_names, cmap=plt.cm.Blues, normalize=normalize, ax=ax[i])\n      ax[i].set_title(title)\n      i+=1\n\n  fig.suptitle(title_)","3c8d8061":"def plot_learning_curves(model,title,ax,multi_label=''):\n  train_size,train_scores,val_scores=learning_curve(model,x_train,y_train,cv=5)\n\n  train_scores_plot=np.mean(train_scores,axis=1)\n  val_scores_plot=np.mean(val_scores,axis=1)\n\n  ax.plot(train_size,train_scores_plot,marker='*',label='Train '+ multi_label)\n  ax.plot(train_size,val_scores_plot,marker='.',label='Validation '+multi_label)\n  ax.set_xlabel('Size training sample')\n  ax.set_ylabel('Accuracy of the model')\n  ax.grid()\n  ax.legend()\n  ax.set_title('Learning Curves '+str(title))","506773cf":"def plot_word_importance(class_, vect,proba,n, most, less ):\n  print('#########   '+ label_to_emoji(class_) +'   #########\\n')\n  if less==True:\n    print('Less important words:')\n    print(str(np.take(vect.get_feature_names(), proba[:n]))+'\\n')\n  if most==True:\n    print('Most important words:')\n    print(str(np.take(vect.get_feature_names(), proba[-n:]))+'\\n')","57dbd7d8":"def multiclass_precision_recall_curve(y_score,ax_micro, micro_average=True,label_='Micro Averaged'):\n\n  #binarize y_validation\n  y_validation_binar = np.zeros(y_score.shape)\n  nrows = y_score.shape[0]\n  for i in range(nrows) :\n      y_validation_binar[i][y_validation[i]] = 1\n\n\n  n_classes=5\n  precision = dict()\n  recall = dict()\n  average_precision = dict()\n  accuracy=dict()\n  for i in range(n_classes):\n      precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i], y_score[:, i])                                                \n      average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\n      #accuracy[i] = metrics.accuracy_score(y_validation_binar[:, i], y_score[:, i])\n      print('Average Precision Class '+str(i)+': {0:0.2f}'.format(average_precision[i]))\n      #print('Accuracy Class '+str(i)+': {0:0.2f}'.format(accuracy[i]))\n\n  if micro_average==True:\n\n    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_validation_binar.ravel(),y_score.ravel())\n    average_precision[\"micro\"] = average_precision_score(y_validation_binar, y_score,average=\"micro\")                                             \n    print('Average precision score, micro-averaged over all classes: {0:0.2f}'.format(average_precision[\"micro\"]))\n\n  else: \n    average_precision[\"micro\"]=0\n          \n  if ax_micro and micro_average==True:\n    \n    ax_micro.step( precision['micro'],recall['micro'], where='post', label=label_)\n\n    ax_micro.set_xlabel('Recall')\n    ax_micro.set_ylabel('Precision')\n    ax_micro.set_ylim([0.0, 1.05])\n    ax_micro.set_xlim([0.0, 1.0])\n    ax_micro.set_title('Average precision score, micro-averaged over all classes: AP={0:0.2f}'.format(average_precision[\"micro\"]))\n    ax_micro.grid()\n    ax_micro.legend() \n\n\n    return (precision, recall, average_precision, average_precision[\"micro\"])\n","9a412dce":"def plot_multiclass_precision_recall(precision,recall,average_precision,ax,fig):\n\n  colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n  lines = []\n  labels = []\n\n  l, = ax.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n  lines.append(l)\n  labels.append('micro-average Precision-recall (area = {0:0.2f})'''.format(average_precision[\"micro\"]))\n              \n  for i, color in zip(range(n_classes), colors):\n    l, = ax.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'''.format(i, average_precision[i]))\n                  \n  fig.subplots_adjust(bottom=0.25)\n  ax.set_xlim([0.0, 1.0])\n  ax.set_ylim([0.0, 1.05])\n  ax.set_xlabel('Recall')\n  ax.set_ylabel('Precision')\n  ax.set_title('Precision-Recall curve per class')\n  ax.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n  ax.grid()","902990f2":"def plot_precision_recall_class(precision,recall,class_,ax,color,label_):\n\n  ax.plot(recall[class_], precision[class_], color=color, lw=2,label=str(label_)+' Classifier')\n  ax.set_xlim([0.0, 1.0])\n  ax.set_ylim([0.0, 1.05])\n  ax.set_xlabel('Recall')\n  ax.set_ylabel('Precision')\n  ax.set_title('Precision-Recall curve class '+str(class_))\n  ax.legend()\n  ax.grid()\n","aea6f6f7":"def plot_roc_curves(y_score,ax):\n\n  y_validation_binar = np.zeros(y_score.shape)\n  nrows = y_score.shape[0]\n  for i in range(nrows) :\n      y_validation_binar[i][y_validation[i]] = 1\n\n\n  fpr = dict()\n  tpr = dict()\n\n  for i in range(n_classes):\n      fpr[i], tpr[i], _ = roc_curve(y_validation_binar[:, i],\n                                  y_score[:, i])\n      plt.plot(fpr[i], tpr[i], lw=2, label='class {}'.format(i))\n\n  ax.set_xlabel(\"false positive rate\")\n  ax.set_ylabel(\"true positive rate\")\n  ax.legend(loc=\"best\")\n  ax.set_title(\"ROC curve\")\n  ax.grid()","cf2a83f1":"def train_test_performance(model,x_t,x_v,y_t,y_v):\n  model.fit(x_t,y_t)\n  train_acc=metrics.accuracy_score(y_t,model.predict(x_t))\n  val_acc=metrics.accuracy_score(y_v,model.predict(x_v))\n\n  return (train_acc,val_acc)","1513ed92":"# Load dataset\n##################################################\n\nDATA_BASE_FOLDER = '\/kaggle\/input\/emojify-challenge'\n\n\ndf_train =  pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'train.csv'))\ny_train = df_train['class']\n\ndf_validation = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'validation.csv'))\ny_validation = df_validation['class']\n\nemoji_dictionary = {\n    '0': '\\u2764\\uFE0F',\n    '1': ':baseball:',\n    '2': ':smile:',\n    '3': ':disappointed:',\n    '4': ':fork_and_knife:'\n}\n\n# See some data examples\nprint('EXAMPLES:\\n####################')\nfor idx in range(10):\n    print(f'{df_train[\"phrase\"][idx]} -> {label_to_emoji(y_train[idx])}')","ebbbf8b3":"df_train_copy=df_train\ndf_train_copy['emoji']=''\nfor i,number in enumerate(df_train_copy['class']):\n  df_train_copy['emoji'][i]=label_to_emoji(number)\n\ndf_train_copy[14:19]","93a2e96e":"print('Class:          Emoji:')\nfor idx in range(len(emoji_dictionary)):\n    print(str(int(list(emoji_dictionary.keys())[idx]))+'                '+label_to_emoji(idx))","7dd91b04":"print('Number of events in the training dataset:  '+str(len(df_train)))\nprint('Number of events in the validation dataset:  '+str(len(df_validation)))","e7b63f1b":"class_emoji=[label_to_emoji(0),label_to_emoji(1),label_to_emoji(2),label_to_emoji(3),label_to_emoji(4)]","f1ca4fb3":"fig, ax = plt.subplots(2,2,figsize=(14,8))\nplt.suptitle('Number of the classes in the datasets')\nsns.countplot(x='class',data=df_train,ax=ax[0][0]).set_title('Training')\nsns.countplot(x='class',data=df_validation,ax=ax[0][1]).set_title('Validation')\n\nlabels=[i for i in range(5)]\ncolors=['blue','orange','green','darkred','purple']\n\nplt.suptitle('Proportion of the classes in the datasets', fontsize=20)\n\nplot_pie_chart(df_train, labels, ax[1][0], 'Training',colors)\nplot_pie_chart(df_validation, labels, ax[1][1],'Validation',colors)    \n\nplt.show()","b2b1e7d2":"fig,ax=plt.subplots(figsize=(10,6))\n\nlenght_train=count_words(df_train)\nlenght_cv=count_words(df_validation)\n\nax.hist(lenght_train, density=1,alpha=0.5, color='blue', label='Training', histtype='step')\nax.hist(lenght_cv, density=1, alpha=0.5, color='red', label='Validation', histtype='step')\n\nax.set_title('Lenght of the phrase in the training and validation sample')\nax.legend()\nax.set_xlabel('Number of words')\nax.set_ylabel('Normalized counts')\nax.grid()","5a91bca8":"print('Mean number of word training sample: '+str(np.mean(lenght_train)))\nprint('Mean number of word validation sample: '+str(np.mean(lenght_cv)))","fb9a39ec":"#Select the tokens in lower case letters and not in stopwords\ntk_train=[]\nfor phrase in tokenize_phrase(df_train):\n    tk_train.append([t for t in phrase if t not in stopwords.words('english')])\n        \ntk_val=[]\nfor phrase in  tokenize_phrase(df_validation):\n    tk_val.append([t for t in phrase if t not in stopwords.words('english')])","67e5d0f0":"# Analize all the phrases\ntk_train_tot=tokenize_tot_phrase(df_train)\ntk_tot=[t for t in tk_train_tot if t not in stopwords.words('english')]\n\ncount_train_tot=Counter(tk_tot)\n\ncount_train_tot.most_common(10)\nlab=[ n[0] for lab,n in enumerate(count_train_tot.most_common(10))]\nfreq=[n[1] for lab,n in enumerate(count_train_tot.most_common(10))]","071b67f5":"fig,ax=plt.subplots(figsize=(15,6))\n\nax.barh(lab,freq,color='green')\nax.set_xlabel('Number of words')\nax.set_title('Frequency of the words in all the phrases')\nax.grid()","ec494fc6":"from nltk.stem import WordNetLemmatizer \nfrom nltk.stem import PorterStemmer\n# Training sample\ntk_lemm=[]\nfor phrase in tk_train:\n    tk_lemm.append([WordNetLemmatizer().lemmatize(t) for t in phrase])\n\ntk_stemm=[]\nfor phrase in tk_lemm:\n    tk_stemm.append([PorterStemmer().stem(t) for t in phrase])\n\ntk_train=tk_stemm\n\n#Validation sample\ntk_lemm_v=[]\nfor phrase in tk_val:\n    tk_lemm_v.append([WordNetLemmatizer().lemmatize(t) for t in phrase])\n\ntk_stemm_v=[]\nfor phrase in tk_lemm_v:\n    tk_stemm_v.append([PorterStemmer().stem(t) for t in phrase])\n\ntk_val=tk_stemm_v\n","f9ea0130":"# Here I am using all the prepocessing part to create the dictionary for the LdaModel \n\ndictionary=Dictionary(tk_train)\ndictionary_v=Dictionary(tk_val)\n\ncorpus = [dictionary.doc2bow(phrase) for phrase in tk_train]","8f87a3a4":"from gensim.models.ldamodel import LdaModel\nphrases_topics = LdaModel(corpus=corpus,\n                          id2word=dictionary,\n                          num_topics=5,\n                         \n                          per_word_topics=True)","301caffc":"len(dictionary)","e27c67b6":"phrases_topics.show_topics(num_words=20)\n","33aad3dd":"pyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(phrases_topics, corpus, dictionary=phrases_topics.id2word)\nvis","5966a17b":"from matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.colors as mcolors","1891a20a":"count_vectorizer = CountVectorizer(stop_words='english',lowercase=True)","c6834c55":"cols = [color for name, color in mcolors.TABLEAU_COLORS.items()] \n\ncloud = WordCloud(stopwords=count_vectorizer.get_stop_words(),\n                  background_color='white',\n                  width=2500,\n                  height=1800,\n                  max_words=20,\n                  colormap='tab10',\n                  color_func=lambda *args, **kwargs: cols[i],\n                  prefer_horizontal=1.0)\n\ntopics = phrases_topics.show_topics(formatted=False, num_words=20)\n\nfig, axes = plt.subplots(1,5, figsize=(20,10), sharex=True, sharey=True)\n\nfor i, ax in enumerate(axes.flatten()):\n    fig.add_subplot(ax)\n    topic_words = dict(topics[i][1])\n    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n    plt.gca().imshow(cloud)\n    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n    plt.gca().axis('off')\n\n\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.axis('off')\nplt.margins(x=0, y=0)\nplt.tight_layout()\nplt.show()","9b08a2e2":"X_train=df_train['phrase']\nX_val=df_validation['phrase']","02c63e0d":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ncount_vectorizer = CountVectorizer(stop_words='english',lowercase=True)\n\ntfidf_vectorizer = TfidfVectorizer(stop_words='english',lowercase=True)","fe389469":"x_train = count_vectorizer.fit_transform(X_train.values)\nx_val = count_vectorizer.transform(X_val.values)\n\nx_train_tfid=tfidf_vectorizer.fit_transform(X_train.values)\nx_val_tfid=tfidf_vectorizer.transform(X_val.values)","11da3a29":"from sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler(with_mean=False)\nscaler_tfid=StandardScaler(with_mean=False)\n\nx_train=scaler.fit_transform(x_train)\nx_val=scaler.transform(x_val)\n\nx_train_tfid=scaler_tfid.fit_transform(x_train_tfid)\nx_val_tfid=scaler_tfid.transform(x_val_tfid)","4dfc3bc7":"LR=LogisticRegression(solver='newton-cg', multi_class='multinomial')\npred_LR=evaluate_model(LR,x_train,y_train,x_val,y_validation)","3082acfd":"LR=LogisticRegression(solver='newton-cg')\npred_LR_tfid=evaluate_model(LR,x_train_tfid,y_train,x_val_tfid,y_validation)","04532a21":"C_values=[1e-3,1e-2,0.05,1e-1,0.5,1e0,5,1e1,1e2,1e3]\nparam={'C':C_values}\nLR=LogisticRegression()\ngrid_search_C=GridSearchCV(LR,param, scoring='accuracy',n_jobs=-1, return_train_score=True,cv=5)\ngrid_search_C.fit(x_train,y_train)\ncv_results_C=pd.DataFrame(grid_search_C.cv_results_)","df6a2900":"plt.figure(figsize=(10,6))\n\nplt.plot(C_values,cv_results_C['mean_train_score'],marker='.',label='Train')\nplt.plot(C_values,cv_results_C['mean_test_score'],marker='*',label='test')\nplt.legend()\nplt.grid()\nplt.title('Cross Validation C')\nplt.xlabel('C value')\nplt.ylabel('Accuracy')\nplt.xscale('log')\nplt.show()","95b7bffa":"param_LR={'C':C_values,\n          'penalty':['l1','l2'],\n          'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag']}\nlr=LogisticRegression()\ngrid_search_LR=GridSearchCV(estimator=lr, param_grid=param_LR, cv=5, n_jobs=-1)\ngrid_search_LR.fit(x_train,y_train)","991ad171":"df_gs_LR=pd.DataFrame(grid_search_LR.cv_results_)\ndf_gs_LR.sort_values('rank_test_score').head()","c184e221":"fig=plt.figure(figsize=(10,6))\n\nplt.hist(grid_search_LR.cv_results_['mean_test_score'],alpha=0.5)\nplt.grid()\nplt.title('Distribution of the validation accuracy among the models')\nplt.xlabel('Accuracy')\nplt.ylabel('Counts')\nplt.show()","8913704a":"data_box={}\nlab=[]\ndata_plot=[]\nfor cr in ['newton-cg', 'lbfgs', 'liblinear', 'sag']:\n  data_box[str(cr)]=(list(df_gs_LR[df_gs_LR['param_solver']==cr]['mean_fit_time']))\n  lab.append(str(cr))\n  data_plot.append(data_box[str(cr)])\n\nplt.boxplot(data_plot,labels=lab)\nplt.xlabel('Solver')\nplt.ylabel('Mean fit time')\nplt.grid()\nplt.title('Solver and mean fit time')\nplt.show()\n","7fdef4f1":"# I select the best estimator from the grid search \nprint('Best Logistic Regression classifier:')\nprint(grid_search_LR.best_estimator_)\nLR=grid_search_LR.best_estimator_\nevaluate_model(LR,x_train,y_train,x_val,y_validation)","311852be":"df_pred=pd.DataFrame(X_val)\ndf_pred['class']=y_validation\ndf_pred['pred_LR']=pred_LR","cbc20c82":"print_table_emoji(pred_LR, 'Logistic Regression')","334956fe":"plot_confusion_matrix_classifier(LR,'Logistic Regression Classifier')","c3c56bd0":"n_classes=5","9fa4ac86":"y_score_LR=LR.predict_proba(x_val)","9956e192":"fig,ax=plt.subplots(1,3,figsize=(20,6))\n\nprecision_LR,recall_LR, average_precision_LR, average_precision_LR['micro']=multiclass_precision_recall_curve(y_score_LR,ax[0], micro_average=True)\nplot_multiclass_precision_recall(precision_LR,recall_LR,average_precision_LR,ax[1],fig)\nplot_roc_curves(y_score_LR,ax[2])","5d4d7427":"fig,ax=plt.subplots(figsize=(10,6))\n\nplot_learning_curves(LR,'Logistic Regression classifier',ax)","148fb17c":"y_test_pred = None\n\n# Create submission\nsubmission = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'sample_submission.csv'))\nx_test=count_vectorizer.transform(submission['phrase'].values)\n\nx_test=scaler.fit_transform(x_test)\n\ny_test_pred=LR.predict(x_test)\n\n\nif y_test_pred is not None:\n    submission['class'] = y_test_pred\n    submission = submission[['Unnamed: 0', 'class']]\n\n    submission = submission.rename(columns={'Unnamed: 0': 'id'})\n    \n    submission.to_csv('my_submission_LR.csv', index=False)\n","22bf68a8":"nb_classifier = MultinomialNB()\npred_NB=evaluate_model(nb_classifier,x_train,y_train,x_val,y_validation)","d3055d25":"nb_classifier_tfid = MultinomialNB()\npred_NB_tfid=evaluate_model(nb_classifier_tfid,x_train_tfid,y_train,x_val_tfid,y_validation)","8b2bc133":"alpha_values=[1e-9,1e-6,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,1e6,1e9]\nparam_NB={'alpha':alpha_values}\nnb=MultinomialNB()\ngrid_search_NB=GridSearchCV(estimator=nb, param_grid=param_NB, cv=3, n_jobs=-1, return_train_score=True)\ngrid_search_NB.fit(x_train,y_train)\ncv_results_alpha=pd.DataFrame(grid_search_NB.cv_results_)","4f6bbb30":"plt.figure(figsize=(10,6))\n\nplt.plot(alpha_values,cv_results_alpha['mean_train_score'],marker='.',label='Train')\nplt.plot(alpha_values,cv_results_alpha['mean_test_score'],marker='*',label='test')\nplt.legend()\nplt.grid()\nplt.title('Cross Validation alpha')\nplt.xlabel('Alpha value')\nplt.ylabel('Accuracy')\nplt.xscale('log')","d43b70d7":"print_table_emoji(pred_NB, 'Naive Bayes Model')\nprint_table_emoji(pred_NB_tfid, 'Naive Bayes Model TfidfVectorizer ')","ca9727ff":"plot_confusion_matrix_classifier(nb_classifier,'Naive Bayes Classifier')\n#plot_confusion_matrix_classifier(nb_classifier_tfid,'Naive Bayes Classifier')","5ae4c5ba":"print('Best Naive Bayes estimator:\\n')\nprint(grid_search_NB.best_estimator_)\nNB=grid_search_NB.best_estimator_\nevaluate_model(NB,x_train,y_train,x_val,y_validation)","595966dc":"df_pred['pred_NB_tfid']=NB.predict(x_val_tfid)\ndf_pred['pred_NB']=NB.predict(x_val)","5cf3afe9":"y_score_NB=NB.predict_proba(x_val)","0071c985":"fig,ax=plt.subplots(1,3,figsize=(20,6))\n\nprecision_NB,recall_NB, average_precision_NB, average_precision_NB['micro']=multiclass_precision_recall_curve(y_score_NB,ax[0], micro_average=True)\nplot_multiclass_precision_recall(precision_NB,recall_NB,average_precision_NB,ax[1],fig)\nplot_roc_curves(y_score_NB,ax[2])","c3ac3550":"fig,ax=plt.subplots(1,2,figsize=(20,10))\nplot_learning_curves(nb_classifier_tfid,'Naive Bayes TFID',ax[0])\nplot_learning_curves(NB,'Naive Bayes',ax[1])\n","e0b3dc1e":"y_test_pred = None\n\n# Create submission\nsubmission = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'sample_submission.csv'))\nx_test=count_vectorizer.transform(submission['phrase'].values)\n\nx_test=scaler.fit_transform(x_test)\n\ny_test_pred=NB.predict(x_test)\n\n\nif y_test_pred is not None:\n    submission['class'] = y_test_pred\n    submission = submission[['Unnamed: 0', 'class']]\n\n    submission = submission.rename(columns={'Unnamed: 0': 'id'})\n    \n    submission.to_csv('my_submission_NB.csv', index=False)\n","2e1520bf":"DTC=DecisionTreeClassifier(random_state=42)","919e109a":"evaluate_model(DTC,x_train,y_train,x_val,y_validation)","946e7fe0":"depths=[1,2,3,4,5,10,20,50,100]\nparam={'max_depth':depths}\nDTC=DecisionTreeClassifier(random_state=42)\ngrid_search_depth=GridSearchCV(DTC,param, scoring='accuracy',n_jobs=-1, return_train_score=True)\ngrid_search_depth.fit(x_train,y_train)\ncv_results_depths=pd.DataFrame(grid_search_depth.cv_results_)","6e61b80a":"plt.figure(figsize=(10,6))\n\nplt.plot(depths,cv_results_depths['mean_train_score'],marker='.',label='Train')\nplt.plot(depths,cv_results_depths['mean_test_score'],marker='*',label='test')\nplt.legend()\nplt.grid()\nplt.title('Cross Validation depths')\nplt.xlabel('Depth')\nplt.ylabel('Accuracy')\n\nplt.figure(figsize=(10,6))\nplt.plot(depths,cv_results_depths['mean_fit_time'],marker='.',label='Train')\n#plt.plot(depths,cv_results_depths['mean_score_time'],marker='*',label='test')\nplt.legend()\nplt.grid()\nplt.title('Cross Validation depths')\nplt.xlabel('Depth')\nplt.ylabel('Mean fit time')\nplt.show()\n","df2e057a":"param_DTC={'criterion':['gini','entropy'],\n           'max_depth':depths,\n           'max_features':['auto','None'],\n           'random_state':[1,2,3,5,42,100,200]\n           }\n\n\ndtc=DecisionTreeClassifier(random_state=42)\n\ngrid_search_DTC=GridSearchCV(estimator=dtc, param_grid=param_DTC, cv=5, n_jobs=-1, scoring='accuracy')\ngrid_search_DTC.fit(x_train,y_train)","3e5e2f53":"df_dtc=pd.DataFrame(grid_search_DTC.cv_results_)\ndf_dtc.sort_values('rank_test_score').head()","4c52d31f":"grid_search_DTC.best_params_","c264466b":"\ndepth=df_dtc['param_max_depth']\nmean_time=df_dtc['mean_fit_time']\nstate=df_dtc['param_random_state']\n\ndata_box={}\nlab=[]\ndata_plot=[]\nfor depth in depths:\n  data_box[str(depth)]=(list(df_dtc[df_dtc['param_max_depth']==depth]['mean_fit_time']))\n  lab.append(str(depth))\n  data_plot.append(data_box[str(depth)])\n\nplt.boxplot(data_plot,labels=lab)\nplt.xlabel('Depth')\nplt.ylabel('Mean fit time')\nplt.grid()\nplt.title('Depth and mean fit time')\nplt.show()\n\n\ndata_box2={}\nlab=[]\ndata_plot2=[]\nfor depth in depths:\n  data_box2[str(depth)]=(list(df_dtc[df_dtc['param_max_depth']==depth]['mean_score_time']))\n  lab.append(str(depth))\n  data_plot2.append(data_box2[str(depth)])\n\nplt.boxplot(data_plot2,labels=lab)\nplt.xlabel('Depth')\nplt.ylabel('Mean score time')\nplt.grid()\nplt.title('Depth and mean score time')\nplt.show()\n\ndata_box3={}\nlab3=[]\ndata_plot3=[]\nfor cr in ['gini','entropy']:\n  data_box3[str(cr)]=(list(df_dtc[df_dtc['param_criterion']==cr]['mean_fit_time']))\n  lab3.append(str(cr))\n  data_plot3.append(data_box3[str(cr)])\n\nplt.boxplot(data_plot3,labels=lab3)\nplt.xlabel('Criterion')\nplt.ylabel('Mean fit time')\nplt.grid()\nplt.title('Criterion and mean fit time')\nplt.show()\n","f4ac4a2e":"# I select the best estimator from the grid search \nprint('Best Decision Tree classifier:')\nprint(grid_search_DTC.best_estimator_)\nDTC=grid_search_DTC.best_estimator_\npred_DTC=evaluate_model(DTC,x_train,y_train,x_val,y_validation)","01ca3898":"plot_confusion_matrix_classifier(DTC,'Decision Tree Classifier')\n","562cdc0b":"df_pred['pred_DTC']=pred_DTC","4d702429":"y_score_DTC=DTC.predict_proba(x_val)","bb3b70b7":"fig,ax=plt.subplots(1,3,figsize=(20,6))\n\nprecision_DTC,recall_DTC, average_precision_DTC, average_precision_DTC['micro']=multiclass_precision_recall_curve(y_score_DTC,ax[0], micro_average=True)\nplot_multiclass_precision_recall(precision_DTC,recall_DTC,average_precision_DTC,ax[1],fig)\nplot_roc_curves(y_score_DTC,ax[2])","a14f4221":"fig,ax=plt.subplots(figsize=(10,6))\n\nplot_learning_curves(DTC,'Decision Tree classifier',ax)","cc5ae948":"y_test_pred = None\n\n# Create submission\nsubmission = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'sample_submission.csv'))\nx_test=count_vectorizer.transform(submission['phrase'].values)\n\nx_test=scaler.fit_transform(x_test)\n\ny_test_pred=DTC.predict(x_test)\n\n\nif y_test_pred is not None:\n    submission['class'] = y_test_pred\n    submission = submission[['Unnamed: 0', 'class']]\n\n    submission = submission.rename(columns={'Unnamed: 0': 'id'})\n    \n    submission.to_csv('my_submission_DTC.csv', index=False)\n","bb374c27":"from sklearn.neural_network import MLPClassifier","3077b2d7":"MLP = MLPClassifier()\nevaluate_model(MLP,x_train,y_train,x_val,y_validation)\n","896c101a":"MLP","ada8d60a":"# If have time compile this \n\n# alpha_=[0.0001, 0.01, 1, 10, 100, 1000]\n# param_MLP={\n#     'hidden_layer_sizes': [(50,50),(50,50,50), (50,100,50), (100,),(100,100,100)],\n#     'activation': ['tanh', 'relu'],\n#     'solver': ['sgd', 'adam'],\n#     'alpha':alpha_ ,\n#     'learning_rate': ['constant','adaptive'],\n#     'max_iter':[200,300,500]\n# }\n\n\n# MLP = MLPClassifier(random_state=42)\n\n# grid_search_MLP=GridSearchCV(estimator=MLP, param_grid=param_MLP, cv=3, n_jobs=-1, scoring='accuracy')\n# grid_search_MLP.fit(x_train,y_train)\n\n# df_mlp=pd.DataFrame(grid_search_MLP.cv_results_)\n# df_mlp.sort_values('rank_test_score').head()\n\n# print('Best MLP classifier:')\n# MLP=grid_search_MLP.best_estimator_\n# print(MLP)\n\n","97294b38":"DATA_BASE_FOLDER_MLP = '\/kaggle\/input\/grid-search-mlp\/'\n\ndf_mlp =  pd.read_csv(os.path.join(DATA_BASE_FOLDER_MLP, 'df_mlp.csv'))\n\n\ndf_mlp.sort_values('rank_test_score').head()","ea54db78":"data_box={}\nlab=[]\ndata_plot=[]\n\ndata_box2={}\ndata_plot2=[]\n\ndata_box3={}\nlab3=[]\ndata_plot3=[]\n\ndata_box4={}\ndata_plot4=[]\n\nlayers=['(50, 50)','(50, 50, 50)', '(50, 100, 50)', '(100,)','(100, 100, 100)']\nfor layer in layers:\n    data_box[str(layer)]=(list(df_mlp[df_mlp['param_hidden_layer_sizes']==layer]['mean_fit_time']))\n    data_box2[str(layer)]=(list(df_mlp[df_mlp['param_hidden_layer_sizes']==layer]['mean_score_time']))\n    data_box4[str(layer)]=(list(df_mlp[df_mlp['param_hidden_layer_sizes']==layer]['mean_test_score']))\n\n    lab.append(str(layer))\n    data_plot.append(data_box[str(layer)])\n    data_plot2.append(data_box2[str(layer)])\n    data_plot4.append(data_box4[str(layer)])\n\nfor solver in  ['sgd', 'adam']:\n    data_box3[str(solver)]=(list(df_mlp[df_mlp['param_solver']==solver]['mean_fit_time']))\n    lab3.append(str(solver))\n    data_plot3.append(data_box3[str(solver)])\n\nfig,ax=plt.subplots(1,4,figsize=(25,6))\n\nax[0].boxplot(data_plot,labels=lab)\nax[0].set_xlabel('Layers')\nax[0].set_ylabel('Mean fit time')\nax[0].grid()\nax[0].set_title('Layer and mean fit time')\n\nax[1].boxplot(data_plot2,labels=lab)\nax[1].set_xlabel('Layers')\nax[1].set_ylabel('Mean score time')\nax[1].grid()\nax[1].set_title('Layer and mean score time')\n\nax[2].boxplot(data_plot3,labels=lab3)\nax[2].set_xlabel('Solver')\nax[2].set_ylabel('Mean fit time')\nax[2].grid()\nax[2].set_title('Solver and mean fit time')\n\nax[3].boxplot(data_plot4,labels=lab)\nax[3].set_xlabel('Layers')\nax[3].set_ylabel('Mean test score')\nax[3].grid()\nax[3].set_title('Layer and mean test score')\n\n\nplt.show()\n\n","a0e12186":"df_mlp.columns","d9af2ba9":"#Best model previous grid search:\nMLP=MLPClassifier(activation='tanh', alpha=10, batch_size='auto', beta_1=0.9,\n              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n              hidden_layer_sizes=(50, 100, 50), learning_rate='constant',\n              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n              power_t=0.5, random_state=42, shuffle=True, solver='adam',\n              tol=0.0001, validation_fraction=0.1, verbose=False,\n              warm_start=False)","ff378a3c":"pred_MLP=evaluate_model(MLP,x_train,y_train,x_val,y_validation)","0f8375cb":"plot_confusion_matrix_classifier(MLP,'Multi Layer Perceptron Classifier')","40a7476a":"y_score_MLP=MLP.predict_proba(x_val)","937ba30c":"fig,ax=plt.subplots(1,3,figsize=(20,6))\n\nprecision_MLP,recall_MLP, average_precision_MLP, average_precision_MLP['micro']=multiclass_precision_recall_curve(y_score_MLP,ax[0], micro_average=True)\nplot_multiclass_precision_recall(precision_MLP,recall_MLP,average_precision_MLP,ax[1],fig)\nplot_roc_curves(y_score_MLP,ax[2])\nplt.show()","16976d88":"fig,ax=plt.subplots(figsize=(10,6))\n\nplot_learning_curves(MLP,'Multi Layer Perceptron classifier',ax)","42878222":"DATA_BASE_FOLDER\n","caba1ef2":"y_test_pred = None\n\n# Create submission\nsubmission = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'sample_submission.csv'))\nx_test=count_vectorizer.transform(submission['phrase'].values)\n\nx_test=scaler.fit_transform(x_test)\n\ny_test_pred=MLP.predict(x_test)\n\n\nif y_test_pred is not None:\n    submission['class'] = y_test_pred\n    submission = submission[['Unnamed: 0', 'class']]\n\n    submission = submission.rename(columns={'Unnamed: 0': 'id'})\n    \n    submission.to_csv('\/kaggle\/working\/my_submission_MLP.csv', index=False)","ac97eed3":"fig,ax=plt.subplots(1,5,figsize=(20,6))\n\nfor i in range(5):\n  plot_precision_recall_class(precision_LR,recall_LR, i, ax[i],color='red',label_='LR')\n  plot_precision_recall_class(precision_NB,recall_NB, i, ax[i],color='blue',label_='NB')\n  plot_precision_recall_class(precision_DTC,recall_DTC, i, ax[i],color='green',label_='DTC')\n  plot_precision_recall_class(precision_MLP,recall_MLP, i, ax[i],color='orange',label_='MLP')\n  ax[i].grid(True)","890aa072":"fig,ax=plt.subplots(figsize=(10,6))\n\nprecision_LR,recall_LR, average_precision_LR, average_precision_LR['micro']=multiclass_precision_recall_curve(y_score_LR,ax, micro_average=True,label_='LR')\nprecision_NB,recall_NB, average_precision_NB, average_precision_NB['micro']=multiclass_precision_recall_curve(y_score_NB,ax, micro_average=True, label_='NB')\nprecision_DTC,recall_DTC, average_precision_DTC, average_precision_DTC['micro']=multiclass_precision_recall_curve(y_score_DTC,ax, micro_average=True,label_='DT')\nprecision_MLP,recall_MLP, average_precision_MLP, average_precision_MLP['micro']=multiclass_precision_recall_curve(y_score_MLP,ax, micro_average=True,label_='MLP')\n\nplt.title('Averaged precision-recall curves')\nplt.grid()\n","d5ef10cb":"dic_LR={}\nfor label,value in average_precision_LR.items():\n  dic_LR[str(label)]=value\n\ndic_NB={}\nfor label,value in average_precision_NB.items():\n  dic_NB[str(label)]=value\n\ndic_DTC={}\nfor label,value in average_precision_DTC.items():\n  dic_DTC[str(label)]=value\n\ndic_MLP={}\nfor label,value in average_precision_MLP.items():\n  dic_MLP[str(label)]=value","98d7e402":"labels=('0','1','2','3','4','micro')\nx = np.arange(len(labels))\nbarWidth = 0.2 \n\nfig=plt.figure(figsize=(10,6))\n\nbr1 = np.arange(len(labels)) \nbr2 = [x + barWidth for x in br1] \nbr3 = [x + barWidth for x in br2] \nbr4 = [x + barWidth for x in br3] \n#br4 = [x + barWidth for x in br4] \n\nplt.bar(br1,dic_LR.values(),label='LR', width = barWidth, alpha=0.8)\nplt.bar(br2,dic_NB.values(),label='NB', width = barWidth, alpha=0.8)\nplt.bar(br3,dic_DTC.values(),label='DTC', width = barWidth, alpha=0.8)\nplt.bar(br4,dic_MLP.values(),label='MLP', width = barWidth, alpha=0.8)\n\nplt.legend()\nplt.grid()\nplt.xticks(np.arange(6),labels=labels)\nplt.xlabel('Class')\nplt.ylabel('Average Precision')\nplt.title('Performances by Class')\nplt.show()","ed704f11":"df_pred['pred_MLP']=MLP.predict(x_val)","c1a5b0c4":"fig,ax=plt.subplots(figsize=(10,6))\n\nplot_learning_curves(LR,'Logistic Regression',ax, multi_label='LR')\nplot_learning_curves(NB,'Naive Bayes',ax, multi_label='NB')\nplot_learning_curves(DTC,'Decision Tree',ax, multi_label='DT')\nplot_learning_curves(MLP,'Multi Layer Perceptron',ax, multi_label='MLP')\n\nplt.title('Learning Curves models studied')\nplt.grid()\n","1ce43a80":"best_classifiers=[LR,NB,DTC,MLP]","412e0f2f":"print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Validation Accuracy\"))\nprint(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*19))\nfor clf in best_classifiers: \n    clf_name = clf.__class__.__name__\n    train_acc, val_acc = train_test_performance(clf, x_train, x_val, y_train, y_validation)\n    print(\"| {:25} | {:17.3f} | {:13.3f}       |\".format(clf_name, train_acc, val_acc))","5a3beab6":"df_pred['emoji']=''\ndf_pred['emoji_LR']=''\ndf_pred['emoji_NB']=''\ndf_pred['emoji_DTC']=''\ndf_pred['emoji_MLP']=''\n\ndf_pred['Phrase']=df_pred['phrase']\n\nfor i,number in enumerate(df_pred['class']):\n  df_pred['emoji'][i]=label_to_emoji(number)\n\nfor i,number in enumerate(df_pred['pred_LR']):\n  df_pred['emoji_LR'][i]=label_to_emoji(number)\n\nfor i,number in enumerate(df_pred['pred_NB']):\n  df_pred['emoji_NB'][i]=label_to_emoji(number)\n\nfor i,number in enumerate(df_pred['pred_DTC']):\n  df_pred['emoji_DTC'][i]=label_to_emoji(number)\n\nfor i,number in enumerate(df_pred['pred_MLP']):\n  df_pred['emoji_MLP'][i]=label_to_emoji(number)\n\ndf_pred\n","2f79b641":"#print(df_pred[:10])\nprint('EXAMPLES:\\n####################')\nfor idx in range(len(df_pred)):#len(df_pred)\n  print(f'{df_pred[\"phrase\"][idx]} \\n {label_to_emoji(df_pred[\"class\"][idx])}          predicted NB-> {label_to_emoji(df_pred[\"pred_NB\"][idx])}   predicted LR-> {label_to_emoji(df_pred[\"pred_LR\"][idx])}  predicted DTC-> {label_to_emoji(df_pred[\"pred_DTC\"][idx])}  predicted MLP-> {label_to_emoji(df_pred[\"pred_MLP\"][idx])}\\n')","dd8e38d7":"class_proba_0=(nb_classifier.feature_log_prob_[0, :]).argsort()\nclass_proba_1=(nb_classifier.feature_log_prob_[1, :]).argsort()\nclass_proba_2=(nb_classifier.feature_log_prob_[2, :]).argsort()\nclass_proba_3=(nb_classifier.feature_log_prob_[3, :]).argsort()\nclass_proba_4=(nb_classifier.feature_log_prob_[4, :]).argsort()","bb1872d7":"n_words=5\n\nplot_word_importance(0, count_vectorizer,class_proba_0, n_words, most=True,less=False)\nplot_word_importance(1, count_vectorizer,class_proba_1, n_words, most=True,less=False)\nplot_word_importance(2, count_vectorizer,class_proba_2, n_words, most=True,less=False)\nplot_word_importance(3, count_vectorizer,class_proba_3, n_words, most=True,less=False)\nplot_word_importance(4, count_vectorizer,class_proba_4, n_words, most=True,less=False)","0c49cd34":"### Neural Network","62ad666b":"#### Evaluation","3a4114b3":"## Prediction","129bed2e":"#### Learning Curves","83690eb7":"#### Learning Curves","7d8c17e3":"### Logistic Regression\n\nThe first method studied is a logistic regression classificator it can be implemented using an extended version of binary logistic regression know as Multinomial Logistic Regression.","7b4fb6a7":"### Precision Recall Curves","888316b4":"#### Cross Validation","385c3420":"### Emoji prediction","43e44ca5":"### Performances","29c2629a":"#### Evaluation","da58c04a":"In this section I want to better undertand how is composed the dataset or the number of events in one particular class, the proportion of these related to the all classes. The number of words in each phrase and the most commond words in the dataset. ","55ac5e71":"#### Precision Recall Curves","f8534d20":"#### Evaluation","047a31f0":"### Most important words","1f12d079":"In this section I convert the phrases in such a way that can be used by the classification methods, it can be done in serveral ways. The most commont and is the Bag of Words method, I also tried to use the TF-IDF Scheme but in a short text like this one (max 10 words per phrase) the word embadding method doesn't afflict the performance so much.","09d487a5":"#### Precision Recall Curves","0111a696":"#### Cross Validation","74aa028a":"#### Evaluation","50f7494a":"## Loading Functions\n","01bfd2d8":"## Loading Libraries","5da29f2a":"### Learning Curves","5a5eb51b":"The goal of this project is to predict one emoji from a phrase. \n\nIt will be done throught some multiclass classifiction methods like Naive Bayes and Logistic Regression. Each method will be analize and studied to maximize the performance in terms of 'accuracy'. There is a firs part of preprocessing and NPL analisis, when you can see the characteristics of the phrases and the main topics. Then for each model will be studied the learning curves, the confusion matrix, and made a simple cross validation on the main hyperparameter and a grid-search cross validation to better understand the potential of each method in terms of performance.\n\nThen all the methods studied are compared in terms of performance and prediction of the classes. \n\nAll the machine learninig analysis will be done throught the scikit-learn library. ","859d03e2":"## Loading the Datasets ","d7c79d78":"## Classification models","2c297405":"In this section I preprocess the text data to further analisis with the following steps, both for trainind and validation sets.\n\n- **Tokenization**: divide each phrase in a list of single word\n\n- **Removig stop words**: remove from the phrases all the non-fundamentals words like article, all the most frequent words in english\n\n- **Stemming**: reduct each word to their root form, like 'walking'->'walk'\n\n- **Lemmatitation**: like stemming is used to reduct words in their common base form\n\nIn this case the phrases analized are very short and simple so the part of stemming and lemmatitation doesen't afflict the set so much. ","6a7e779e":"#### Grid Search","1ee3949d":"## Preprocessing the Data","9df7aa63":"#### Precision Recall Curves\n","25a129f5":"#### Learning Curves","4f3b1cec":"## Comparison among the models\n\n","0e8c815f":"### Decision Tree","3e926eba":"To make the notebook more slender I wrote some functions that will help me during the analysis. For example a general function to evaluate the performance of a general model or to plot the relative learning curves. All the functions used are implemented as follows. ","52687f84":"#### Grid Search","ec0030f7":"## Exploring the Datasets","9a59343b":"### Naive Bayes\n\nIn this section will be studied the Naive Bayes mehod \n","762ff382":"#### Cross Validation\nI studied a cross validation only for the regularitation hyperparameter C and then a complete grid seacrh cv also to test the solver or the type of penalty. ","8635cf40":"#### Learning Curves","07c89f16":"#### Precision Recall Curves","36cdab75":"In this section I use some gensim methods to analize the phrases of our datasetm, in particular create a dictionary and a corpus, these will be used by the ldaModel to make inference about the topics of these phrases. I set the nuber of topics equal to 5, like the number of classes available in the dataset. ","64b6f631":"#### Grid Search","c6c9601b":"\n![Emoji.jpg](attachment:Emoji.jpg)\n\n# EMOJIFY PROJECT:\n\n###### Luca Pessina \n###### University of Padua\n###### a.a. 2020\/2021","89e277bb":"## Topics Analysis"}}