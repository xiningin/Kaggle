{"cell_type":{"c564c6f3":"code","e325a66e":"code","d171a6c6":"code","1161068d":"code","5e43f02b":"code","a18107ad":"code","8623b76a":"code","c3e78edf":"code","6c4aaadc":"code","6e54f076":"code","9f22fd9e":"code","6e0d56ed":"code","b5368b02":"code","e6f98f71":"code","8f3cbec3":"code","b5fb4588":"code","fac86b01":"code","52c9fc18":"code","78b0b7fd":"code","e7ea6a7b":"code","7a600d1a":"code","db6d79b9":"code","11420fee":"code","e489b2f9":"markdown","e37669e4":"markdown","92ae7fe8":"markdown","e3727ae2":"markdown","5862bd47":"markdown","2ef7227a":"markdown","d1ebc02f":"markdown"},"source":{"c564c6f3":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport gc\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e325a66e":"%%time\n\ntrain_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv', index_col='TransactionID')\ntrain_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv', index_col='TransactionID')\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ndel train_transaction, train_identity\ngc.collect()","d171a6c6":"train = train.fillna(-999)","1161068d":"many_same_values_columns_train = [c for c in train.columns if train[c].value_counts(normalize=True).values[0] > 0.9]\ncolumns_to_drop = many_same_values_columns_train\ncolumns_to_drop.remove('isFraud')\ntrain = train.drop(columns_to_drop, axis=1)\ngc.collect()","5e43f02b":"# From https:\/\/www.kaggle.com\/pavelvpster\/ieee-fraud-eda-lightgbm-baseline\n\nfrom sklearn.preprocessing import LabelEncoder\n\ndef encode_categorial_features_fit(df, columns_to_encode):\n    encoders = {}\n    for c in columns_to_encode:\n        if c in df.columns:\n            encoder = LabelEncoder()\n            encoder.fit(df[c].astype(str).values)\n            encoders[c] = encoder\n    return encoders\n\ndef encode_categorial_features_transform(df, encoders):\n    out = pd.DataFrame(index=df.index)\n    for c in encoders.keys():\n        if c in df.columns:\n            out[c] = encoders[c].transform(df[c].astype(str).values)\n    return out\n\ncategorial_features_columns = [\n    'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21',\n    'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31',\n    'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n    'DeviceType', 'DeviceInfo', 'ProductCD', 'P_emaildomain', 'R_emaildomain',\n    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n    'addr1', 'addr2',\n    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9',\n    'P_emaildomain_vendor', 'P_emaildomain_suffix', 'P_emaildomain_us',\n    'R_emaildomain_vendor', 'R_emaildomain_suffix', 'R_emaildomain_us'\n]\n\ncategorial_features_encoders = encode_categorial_features_fit(train, categorial_features_columns)\ntemp = encode_categorial_features_transform(train, categorial_features_encoders)\ncolumns_to_drop = list(set(categorial_features_columns) & set(train.columns))\ntrain = train.drop(columns_to_drop, axis=1).merge(temp, how='left', left_index=True, right_index=True)\ndel temp\ngc.collect()","a18107ad":"# From https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n#        else:\n#            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\ntrain = reduce_mem_usage(train)","8623b76a":"y_train = train['isFraud'].copy()\nx_train = train.drop('isFraud', axis=1)\n\ndel train\n\ngc.collect()","c3e78edf":"x_train.shape","6c4aaadc":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFECV\nimport lightgbm as lgb","6e54f076":"percent = 25 # percent of dataset to use for feature selection\n\nx_train_train, x_train_valid, y_train_train, y_train_valid = train_test_split(x_train, y_train, test_size=1.0-percent\/100.0, random_state=42)\n\ndel x_train\ndel y_train\n\ngc.collect()","9f22fd9e":"params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'is_unbalance': False,\n    'boost_from_average': True,\n    'num_threads': 4,\n    \n    'num_leaves': 500,\n    # 'min_data_in_leaf': 25,\n    'max_depth': -1,\n    'learning_rate': 0.01\n}\n\n# n_jobs=-1 causes out of memory\nfeature_selector = RFECV(lgb.LGBMClassifier(**params), step=10, scoring='roc_auc', cv=5, verbose=1)\nfeature_selector.fit(x_train_train, y_train_train)\nprint('Features selected:', feature_selector.n_features_)","6e0d56ed":"selected_features = [f for f in x_train_train.columns[feature_selector.ranking_ == 1]]\n\nselected_features","b5368b02":"from sklearn.metrics import roc_auc_score","e6f98f71":"percent = 25 # percent of dataset to use for validation\n\n_, x_train_valid_part, _, y_train_valid_part = train_test_split(x_train_valid, y_train_valid, test_size=percent\/100.0, random_state=42)","8f3cbec3":"lgb_model = lgb.LGBMClassifier(**params).fit(x_train_train, y_train_train)\ny_all_features = lgb_model.predict_proba(x_train_valid_part)[:,1]\nscore_all_features = roc_auc_score(y_train_valid_part, y_all_features)\nprint('Score \/ all features:', score_all_features)","b5fb4588":"y_selected_features = feature_selector.estimator_.predict_proba(x_train_valid_part[selected_features])[:,1]\nscore_selected_features = roc_auc_score(y_train_valid_part, y_selected_features)\nprint('Score \/ selected features:', score_selected_features)","fac86b01":"print('Score change:', score_selected_features-score_all_features)","52c9fc18":"feature_importance_df = pd.concat([\n    pd.Series(x_train_train.columns),\n    pd.Series(lgb_model.feature_importances_)], axis=1)\nfeature_importance_df.columns = ['featureName', 'importance']\n\nfeature_importance_df['selected'] = feature_importance_df['featureName'].map(lambda x: x in selected_features)","78b0b7fd":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(feature_importance_df.sort_values(by=['importance'], ascending=False))","e7ea6a7b":"# From https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","7a600d1a":"classes = pd.Series([0,1])\n\nplot_confusion_matrix(y_train_valid_part, y_all_features.round(), classes=classes, normalize=True,\n                      title='Confusion matrix \/ all features')\n\nplt.show()","db6d79b9":"plot_confusion_matrix(y_train_valid_part, y_selected_features.round(), classes=classes, normalize=True,\n                      title='Confusion matrix \/ selected features')\n\nplt.show()","11420fee":"# From https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_roc.html\n#  and https:\/\/stackoverflow.com\/questions\/25009284\/how-to-plot-roc-curve-in-python\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\nfpr_all_features, tpr_all_features, _ = roc_curve(y_train_valid_part, y_all_features.round())\nroc_auc_all_features = auc(fpr_all_features, tpr_all_features)\n\nfpr_selected_features, tpr_selected_features, _ = roc_curve(y_train_valid_part, y_selected_features.round())\nroc_auc_selected_features = auc(fpr_selected_features, tpr_selected_features)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr_all_features, tpr_all_features, 'g', label = 'AUC (all features) = %0.2f' % roc_auc_all_features)\nplt.plot(fpr_selected_features, tpr_selected_features, 'b', label = 'AUC (selected features) = %0.2f' % roc_auc_selected_features)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","e489b2f9":"## Confusion matrix","e37669e4":"## Compare feature importance and feature selection results","92ae7fe8":"## Load and prepare data","e3727ae2":"## Compare score (all features vs selected features)","5862bd47":"*) Lower values for 1-0 and 0-1 mean better performance","2ef7227a":"## ROC curve","d1ebc02f":"## Feature selection"}}