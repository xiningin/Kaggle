{"cell_type":{"cf5642cf":"code","08c24caa":"code","cb99a3db":"code","0726dbec":"code","7f071d74":"code","dfe3f47f":"code","c4bb0f5c":"code","462e5cc9":"code","a376fcb6":"code","6dc18fdf":"code","05a3c175":"code","a76dbbbb":"code","c4c40cd4":"code","95849a0d":"code","bda742e5":"code","614a1b09":"code","19e8cd6f":"code","2c51e156":"code","08abf2c4":"code","6100703d":"code","70be93ea":"code","41cb6078":"code","92d22919":"code","53c75e1c":"code","e7be9e6c":"code","b4bd1c5a":"code","d452b520":"code","6d2c7a9d":"code","11171a82":"code","28ade5e4":"code","4f915264":"code","0d788329":"code","22f28ae1":"code","890befac":"markdown","8f45559f":"markdown","41d046ab":"markdown","707423cb":"markdown","d7223532":"markdown","9461d73c":"markdown","401e528b":"markdown","85381150":"markdown","bae8136a":"markdown","ff90660a":"markdown","c4e319a5":"markdown","8f443c3e":"markdown","d5dca82e":"markdown","4359e28b":"markdown","9fb0b56e":"markdown","299a1442":"markdown","8431ad04":"markdown","12105779":"markdown","b4491d6d":"markdown","61fd5ba9":"markdown","36d29df4":"markdown","4bc827b0":"markdown","e107eef0":"markdown","fd763e6c":"markdown","403c1257":"markdown","b13f6619":"markdown","2042270c":"markdown","16d024ca":"markdown","332bfaee":"markdown","c599f98d":"markdown","26110bd1":"markdown","0a2f6188":"markdown","5ad4edea":"markdown","152d9e31":"markdown","d93c9e9b":"markdown"},"source":{"cf5642cf":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport seaborn as sns\nimport random\nimport cv2\nimport copy\nimport os\nfrom sklearn.model_selection import train_test_split\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.models as models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nimport torchvision.transforms as transform\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom PIL import Image\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","08c24caa":"path = '..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray'","cb99a3db":"train_samplesize = pd.DataFrame.from_dict(\n    {'Normal': [len([os.path.join(path+'\/train\/NORMAL', filename) \n                     for filename in os.listdir(path+'\/train\/NORMAL')])], \n     'Pneumonia': [len([os.path.join(path+'\/train\/PNEUMONIA', filename) \n                        for filename in os.listdir(path+'\/train\/PNEUMONIA')])]})\n\n\nsns.barplot(data=train_samplesize).set_title('Training Set Data Inbalance', fontsize=20)\nplt.show()","0726dbec":"transformer = {\n    'dataset1': transform.Compose([transform.Resize(255),\n                                            transform.CenterCrop(224),\n                                            transform.RandomHorizontalFlip(),\n                                            transform.RandomRotation(10),\n                                            transform.RandomGrayscale(),\n                                            transform.RandomAffine(translate=(0.05,0.05), degrees=0),\n                                            transform.ToTensor()\n                                           ]),\n    \n    'dataset2' : transform.Compose([transform.Resize(255),\n                                            transform.CenterCrop(224),\n                                            transform.RandomHorizontalFlip(p=1),\n                                            transform.RandomGrayscale(),\n                                            transform.RandomAffine(translate=(0.1,0.05), degrees=10),\n                                            transform.ToTensor()\n                                    \n                                           ]),\n    'dataset3' : transform.Compose([transform.Resize(255),\n                                            transform.CenterCrop(224),\n                                            transform.RandomHorizontalFlip(p=0.5),\n                                            transform.RandomRotation(15),\n                                            transform.RandomGrayscale(p=1),\n                                            transform.RandomAffine(translate=(0.08,0.1), degrees=15),\n                                            transform.ToTensor()\n                                           ]),\n}","7f071d74":"dataset1 = ImageFolder(path+'\/train', \n                      transform=transformer['dataset1'])\n\ndataset2 = ImageFolder(path+'\/train', \n                      transform=transformer['dataset2'])\n\ndataset3 = ImageFolder(path+'\/train', \n                      transform=transformer['dataset3'])\n\nnorm1, _ = train_test_split(dataset2, test_size= 3875\/(1341+3875), shuffle=False)\nnorm2, _ = train_test_split(dataset3, test_size= 4023\/(1341+3875), shuffle=False)\n\ndataset = ConcatDataset([dataset1, norm1, norm2])\n\nlen(dataset)","dfe3f47f":"print(dataset1.classes)","c4bb0f5c":"# Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,8))\n    for i in range(len(samples)):\n        image = cv2.cvtColor(imread(samples[i]), cv2.COLOR_BGR2RGB)\n        ax[i\/\/5][i%5].imshow(image)\n        if i<5:\n            ax[i\/\/5][i%5].set_title(\"Normal\", fontsize=20)\n        else:\n            ax[i\/\/5][i%5].set_title(\"Pneumonia\", fontsize=20)\n        ax[i\/\/5][i%5].axis('off')","462e5cc9":"rand_samples = random.sample([os.path.join(path+'\/train\/NORMAL', filename) \n                              for filename in os.listdir(path+'\/train\/NORMAL')], 5) + \\\n    random.sample([os.path.join(path+'\/train\/PNEUMONIA', filename) \n                   for filename in os.listdir(path+'\/train\/PNEUMONIA')], 5)\n\nplot_samples(rand_samples)\nplt.suptitle('Training Set Samples', fontsize=30)\nplt.show()","a376fcb6":"# set random seed so we get the same sampling every time for reproducibility\n\nrandom_seed = 2020\ntorch.manual_seed(random_seed);","6dc18fdf":"train_ds, val_ds = train_test_split(dataset, test_size=0.3, random_state=random_seed)\nlen(train_ds), len(val_ds)","05a3c175":"batch_size=50\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\nloaders = {'train':train_dl, 'val':val_dl}\ndataset_sizes = {'train':len(train_ds), 'val':len(val_ds)}","a76dbbbb":"def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:60], nrow=10).permute(1, 2, 0))\n        break\n        \nshow_batch(train_dl)","c4c40cd4":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1) \n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds)), preds","95849a0d":"model = torchvision.models.densenet161(pretrained=True)","bda742e5":"for param in model.parameters():\n    param.requires_grad = False\n    \nin_features = model.classifier.in_features\n\nmodel.classifier = nn.Linear(in_features, 2)","614a1b09":"#save the losses for further visualization\nlosses = {'train':[], 'val':[]}\naccuracies = {'train':[], 'val':[]}","19e8cd6f":"def train(model, criterion, optimizer, scheduler, epochs):\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  for epoch in range(epochs):\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()\n      else:\n        model.eval()\n      \n      running_loss = 0.0\n      running_corrects = 0.0\n\n      for inputs, labels in loaders[phase]:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(phase=='train'):\n          outp = model(inputs)\n          _, pred = torch.max(outp, 1)\n          loss = criterion(outp, labels)\n        \n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n        \n        running_loss += loss.item()*inputs.size(0)\n        running_corrects += torch.sum(pred == labels.data)\n\n\n      epoch_loss = running_loss \/ dataset_sizes[phase]\n      epoch_acc = running_corrects.double()\/dataset_sizes[phase]\n      losses[phase].append(epoch_loss)\n      accuracies[phase].append(epoch_acc)\n      if phase == 'train':\n        print('Epoch: {}\/{}'.format(epoch+1, epochs))\n      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n    \n      if phase == 'val':\n        print('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n            \n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model = copy.deepcopy(model.state_dict())\n    scheduler.step()  \n  time_elapsed = time.time() - since\n  print('Training Time {}m {}s'.format(time_elapsed\/\/60, time_elapsed%60)) \n  print('Best accuracy {}'.format(best_acc))\n\n  model.load_state_dict(best_model)\n  return model   ","2c51e156":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.classifier.parameters(), lr = 0.001)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)","08abf2c4":"model.to(device)\nepochs = 10\nmodel = train(model, criterion, optimizer, scheduler, epochs)","6100703d":"for param in model.parameters():\n    param.requires_grad = True\n    \noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n\nmodel.to(device)\ngrad_clip = None\nweight_decay = 1e-4\n# weighted loss for data class imbalance\nepochs = 10\nmodel = train(model, criterion, optimizer, scheduler, epochs)","70be93ea":"# Save Model\n# bestmodel = {'model': PneumoniaResnet(),\n#               'state_dict': model.state_dict(),\n#               'optimizer' : optimizer.state_dict()}\n\n# torch.save(bestmodel, 'PneumoniaResnet.pth')","41cb6078":"# this is for loading the model from a previously saved one\n\n# def load_checkpoint(filepath):\n#     checkpoint = torch.load(filepath)\n#     model = checkpoint['model']\n#     model.load_state_dict(checkpoint['state_dict'])\n#     for parameter in model.parameters():\n#         parameter.requires_grad = False\n\n#     model.eval()\n#     return model\n\n#model = load_checkpoint('.\/PneumoniaResnet.pth')","92d22919":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,epochs*2+1))\nax1.plot(epoch_list, accuracies['train'], label='Train Accuracy')\nax1.plot(epoch_list, accuracies['val'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, epochs*2+1, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, losses['train'], label='Train Loss')\nax2.plot(epoch_list, losses['val'], label='Validation Loss')\nax2.set_xticks(np.arange(0, epochs*2+1, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","53c75e1c":"test_samplesize = pd.DataFrame.from_dict(\n    {'Normal': [len([os.path.join(path+'\/test\/NORMAL', filename) \n                     for filename in os.listdir(path+'\/test\/NORMAL')])], \n     'Pneumonia': [len([os.path.join(path+'\/test\/PNEUMONIA', filename) \n                        for filename in os.listdir(path+'\/test\/PNEUMONIA')])]})\n\nsns.barplot(data=test_samplesize).set_title('Test Set Data Inbalance', fontsize=20)\nplt.show()","e7be9e6c":"def validation_step(batch):\n        images,labels = batch\n        images,labels = images.to(device),labels.to(device)\n        out = model(images)                                      \n        loss = F.cross_entropy(out, labels)                    \n        acc,preds = accuracy(out, labels)                       \n        \n        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n                'preds':preds.detach(), 'labels':labels.detach()}","b4bd1c5a":" def test_prediction(outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()           \n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()             \n        # combine predictions\n        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n        # combine labels\n        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n        \n        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n                'test_preds': batch_preds, 'test_labels': batch_labels}  ","d452b520":"@torch.no_grad()\ndef test_predict(model, test_loader):\n    model.eval()\n    # perform testing for each batch\n    outputs = [validation_step(batch) for batch in test_loader] \n    results = test_prediction(outputs)                          \n    print('test_loss: {:.4f}, test_acc: {:.4f}'\n          .format(results['test_loss'], results['test_acc']))\n    \n    return results['test_preds'], results['test_labels']","6d2c7a9d":"testset = ImageFolder(path+'\/test', \n                           transform=transform.Compose([transform.Resize(255),\n                                                 transform.CenterCrop(224),                                                              \n                                                 transform.ToTensor(),\n                                                ]))","11171a82":"test_dl = DataLoader(testset, batch_size=256)\nmodel.to(device)\npreds,labels = test_predict(model, test_dl)","28ade5e4":"# Plot confusion matrix\ncm  = confusion_matrix(labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.xlabel('Predicted Label',fontsize=18)\nplt.ylabel('True Label',fontsize=18)\nplt.show()","4f915264":"# Compute Performance Metrics\ntn, fp, fn, tp = cm.ravel()\n\naccuracy = (np.array(preds) == np.array(labels)).sum() \/ len(preds)\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\nf1 = 2*((precision*recall)\/(precision+recall))\n\nprint(\"Accuracy of the model is {:.2f}\".format(accuracy))\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))\nprint(\"F1 Score of the model is {:.2f}\".format(f1))","0d788329":"# select 5 normal and 5 pneumonia images indices\nidxs = torch.tensor(np.append(np.arange(start=0, stop=5, step=1), \n                             np.arange(start=500, stop=505, step=1))) \n\nfig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,14))\n\nfor c,i in enumerate(idxs):\n    img_tensor, label = testset[i]\n    ax[c\/\/5][c%5].imshow(img_tensor[0,:,:], cmap='gray')\n    ax[c\/\/5][c%5].set_title('Label: {}\\nPrediction: {}'\n                            .format(testset.classes[label], \n                                    testset.classes[preds[i]]),\n                            fontsize=25)\n    ax[c\/\/5][c%5].axis('off')","22f28ae1":"fig, ax = plt.subplots(figsize=(8,12), ncols=2, nrows=4)\n\nfor row in range(4):\n    img,label = testset[row]\n    pred = torch.exp(model(img.to(device).unsqueeze(0)))\n    class_name = ['NORMAL', 'PNEUMONIA']\n    classes = np.array(class_name)\n    pred = pred.cpu().data.numpy().squeeze()\n    ax[row][0].imshow(img.permute(1, 2, 0))\n    ax[row][0].set_title('Real : {}'.format(class_name[label]))\n    ax[row][0].axis('off')\n    ax[row][1].barh(classes, pred)\n    ax[row][1].set_aspect(0.1)\n    ax[row][1].set_yticks(classes)\n    ax[row][1].set_yticklabels(classes)\n    ax[row][1].set_title('Predicted Class')\n    ax[row][1].set_xlim(0, 1.)\n    plt.tight_layout()","890befac":"The test data also shows an imbalance","8f45559f":"We know in advance what classes there are, but sometimes it is useful to be able to view classes from the dataset","41d046ab":"# 1. Data Loading\n\nLet's look at the data and the possible imbalance ","707423cb":"I would like to draw your attention to the fact that in the optimizer we specify only the classifier","d7223532":"The upper (first) layers of the network are frozen, the lower ones are retrained. The upper layers highlight low-level information, and they've learned to do this well in pre-training. The lower layers are separated from the information obtained from the upper layers, information specific to the task, so they need to be retrained.\n\nHow many layers to freeze depends on the difference between the datasets, the complexity of the task and the size of the dataset for additional training. DenseNet has only one fully connected layer, so we'll only train it, and freeze the rest of the network. We will also change the last layer, since it was originally trained in 1000 classes, and we have only 2","9461d73c":"Let's look at the data distribution. As we can see, there is a strong imbalance in the data (there are many times more X-rays with pneumonia than normal ones), there are many solutions to the imbalance problem. I offer my solution below.","401e528b":"Importing the required libraries","85381150":"![350px-Precisionrecall.png](attachment:f8611e24-666c-4112-9cba-e1bd59db5591.png)","bae8136a":"# 5. Test\n\nNow look at the X-ray-trained network on data it has never seen.","ff90660a":"# 6. Calculation of some more metrics and visualization of predictions","c4e319a5":"# 3. Creating Model\n\nIn the third part, we will create the model. We will take a ready-made densenet network and work with it","8f443c3e":"Here are the augmentations for datasets","d5dca82e":"Let's see what the data with augmentation looks like.","4359e28b":"![\u0411\u0435\u0437\u044b\u043c\u044f\u043d\u043d\u044b\u0439 \u0440\u0438\u0441\u0443\u043d\u043e\u043a.jpg](attachment:95a64a99-179f-48d5-a87d-8a716d491de4.jpg)","9fb0b56e":"Let's create a dataset with training x-rays","299a1442":"# 4. Plots Accuracy and Loss\n\nLet's display our results to see how the idea worked with additional training of the entire network, whether we selected the learning rate correctly and whether the network is being retrained. As you can see from the graph, the idea worked and we really increased productivity. (attention to the network after the 10th epoch)","8431ad04":"Here I would like to stop and explain the idea in more detail.\nOften, a dataset for a task for training a network contains few objects. And if you train the network on this dataset from scratch, the network will be retrained.\nIdea: to use the knowledge gained by other networks on similar tasks.\nI will be using DenseNet. DenseNet has many advantages: strong gradient flow, the number of layers and parameters is not very large, conv layers highlight more diverse features, the lower conv layers take into account the low, complex patterns from the upper layers, which can be useful for detecting some low-level patterns. It also helps DenseNet learn better on small datasets.\n","12105779":"Next, let's calculate recall, precision and f1 score. This is one of the most key metrics for classification problems.","b4491d6d":"Let's create a pre-trained network","61fd5ba9":"![\u0411\u0435\u0437\u044b\u043c\u044f\u043d\u043d\u044b\u0439 \u0440\u0438\u0441\u0443\u043d\u043e\u043a.jpg](attachment:21463cf1-d745-4aa7-adbf-1e9b0f419540.jpg)","36d29df4":"![Vanishing.jpg](attachment:a8b0fbfe-11ca-4f00-9e55-f4dbd4d2ac93.jpg)\n![\u0411\u0435\u0437\u044b\u043c\u044f\u043d\u043d\u044b\u0439 \u0440\u0438\u0441\u0443\u043d\u043e\u043a.jpg](attachment:dd50c131-9924-4641-b780-ebff95590870.jpg)","4bc827b0":"let's designate the path as a variable so as not to write a long path","e107eef0":"We can also see how strongly the neural network is confident in certain decisions.","fd763e6c":"# 2. Preparing Train, Validation\n\nIn this part, we will split the 'train' folder into validation and training parts. It seems strange, because there is a separate folder with validation, but the fact is that there are only 16 images and this is clearly not enough to adequately evaluate the model, so you have to sacrifice part of the data for validation. We will split the data in a ratio of 3\/10, of course, in favor of the training data.","403c1257":"Since we will have to calculate the accuracy several times, we will write in advance the function for calculating the accuracy","b13f6619":"Let's create datasets and concatenate them","2042270c":"I suggest increasing the dataset with normal x-rays. The difference between the pneumonia renegens and the normal ones is 2534, that is, in order to level, we need to add 2534 normal X-rays. Since there are only 1341 normal images in the 'train' folder, we will take the missing 1193 images from the third dataset. To prevent duplicate objects in the final dataset, I applied unique augmentation for each dataset.","16d024ca":"Look at X-rays and predictions","332bfaee":"The following three functions are needed to calculate metrics","c599f98d":"Evaluate test set","26110bd1":"Let's display X-rays with diagnoses. To be honest, I don't see any difference between a pneumonia X-ray and a normal X-ray)","0a2f6188":"Training function","5ad4edea":"DenseNet is good for dealing with vanishing gradients. If you do not know what it is, I will add a rather short but complete description at the bottom. DenseNet is good for dealing with vanishing gradients. If you do not know what it is, I will add a fairly short but complete description at the bottom. In short, the longer the network, the smaller the change in weight to reaches the first layers, because the number of multipliers less than 1 increases.","152d9e31":"Let's wrap the data into dataloaders. We will also create a dictionary with dataloggers in order to have quick access to them and a dictionary with their sizes, this will be useful to us for evaluating the model","d93c9e9b":"It is good practice to retrain the rest of the network after we have trained the last layer. In most cases, this leads to an increase in performance, but in my practice there have been cases when, due to a small dataset, this led to a performance degradation, so my advice is to check two options. Learning rate can be reduced by 10 times"}}