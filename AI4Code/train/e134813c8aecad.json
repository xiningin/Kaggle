{"cell_type":{"483cfed3":"code","b68241be":"code","5fd637a1":"code","b7b5854c":"code","d10aa60f":"code","7072c113":"code","5e3560e9":"code","7b80453a":"code","545dee21":"code","18f871a2":"code","7a9ce0e1":"code","ceb75ec7":"markdown","9a815ee6":"markdown","a5fb00b4":"markdown","ff5a00c1":"markdown","b94d1a52":"markdown","15ec978c":"markdown","7c63fc3b":"markdown"},"source":{"483cfed3":"!pip install kaggle-environments --upgrade -q","b68241be":"%%writefile epsilon_greedy.py\n\nimport math\nimport random\n\nepsilon = 0.1\n\nlast_bandit = -1\ntotal_reward = 0\n\nsums_of_reward = None\nnumbers_of_selections = None\nrandom.seed(42)\n\ndef agent(observation, configuration):    \n    global sums_of_reward, numbers_of_selections, last_bandit, total_reward\n\n    if observation.step == 0:\n        numbers_of_selections = [0] * configuration.banditCount\n        sums_of_reward = [0] * configuration.banditCount\n\n    if last_bandit > -1:\n        reward = observation.reward - total_reward\n        sums_of_reward[last_bandit] += reward\n        total_reward += reward\n\n    if random.random() < epsilon:\n        bandit = random.randint(0, configuration.banditCount-1)\n        last_bandit = bandit\n    else:\n        bandit = 0\n        max_upper_bound = 0\n\n        for i in range(0, configuration.banditCount):\n            if numbers_of_selections[i] > 0:\n                upper_bound = sums_of_reward[i] \/ numbers_of_selections[i]\n            else:\n                upper_bound = 1e400\n            if upper_bound > max_upper_bound and last_bandit != i:\n                max_upper_bound = upper_bound\n                bandit = i\n                last_bandit = bandit\n\n    numbers_of_selections[bandit] += 1\n\n    if bandit is None:\n        bandit = 0\n\n    return bandit","5fd637a1":"%%writefile epsilon_greedy_decay.py\n\nimport math\nimport random\n\nepsilon = 0.1\n\nlast_bandit = -1\ntotal_reward = 0\n\nsums_of_reward = None\nnumbers_of_selections = None\nrandom.seed(42)\n\ndef agent(observation, configuration):    \n    global sums_of_reward, numbers_of_selections, last_bandit, total_reward    \n\n    if observation.step == 0:\n        numbers_of_selections = [0] * configuration.banditCount\n        sums_of_reward = [0] * configuration.banditCount\n\n    if last_bandit > -1:\n        reward = observation.reward - total_reward\n        sums_of_reward[last_bandit] += reward\n        total_reward += reward\n\n    if random.random() < epsilon:\n        bandit = random.randint(0, configuration.banditCount-1)\n        last_bandit = bandit\n    else:\n        bandit = 0\n        max_upper_bound = 0\n\n        for i in range(0, configuration.banditCount):\n            if numbers_of_selections[i] > 0:\n                decay = 0.97 ** numbers_of_selections[i]\n                upper_bound = decay * sums_of_reward[i] \/ numbers_of_selections[i]\n            else:\n                upper_bound = 1e400\n            if upper_bound > max_upper_bound and last_bandit != i:\n                max_upper_bound = upper_bound\n                bandit = i\n                last_bandit = bandit\n\n    numbers_of_selections[bandit] += 1\n\n    if bandit is None:\n        bandit = 0\n\n    return bandit","b7b5854c":"from kaggle_environments import make\nenv = make(\"mab\", debug=True)","d10aa60f":"env.reset()\nenv.run([\"..\/input\/santa-2020\/submission.py\", \"epsilon_greedy_decay.py\"])\nenv.render(mode=\"ipython\", width=800, height=500)","7072c113":"env.reset()\nenv.run([\"..\/input\/santa-2020\/submission.py\", \"epsilon_greedy.py\"])\nenv.render(mode=\"ipython\", width=800, height=500)","5e3560e9":"env.reset()\nenv.run([\"epsilon_greedy_decay.py\", \"epsilon_greedy.py\"])\nenv.render(mode=\"ipython\", width=800, height=500)","7b80453a":"def bo5(file1, file2):\n    env = make(\"mab\", debug=True)\n\n    for i in range(5):\n        env.run([file1, file2])\n        p1_score = env.steps[-1][0]['reward']\n        p2_score = env.steps[-1][1]['reward']\n        env.reset()\n        print(f\"Round {i+1}: {p1_score} - {p2_score}\")","545dee21":"print('Default vs epsilon-greedy')\nbo5(\"..\/input\/santa-2020\/submission.py\", \"epsilon_greedy.py\")","18f871a2":"print('Default vs epsilon-greedy+decay')\nbo5(\"..\/input\/santa-2020\/submission.py\", \"epsilon_greedy_decay.py\")","7a9ce0e1":"print('epsilon-greedy vs epsilon-greedy+decay')\nbo5(\"epsilon_greedy.py\", \"epsilon_greedy_decay.py\")","ceb75ec7":"References:\n* [Santa 2020 starter](https:\/\/www.kaggle.com\/isaienkov\/santa-2020-starter\/comments): Re-used `writefile` magic command and `make_env` function for creating a simulation.","9a815ee6":"## Simulation: Default vs $\\epsilon$-greedy without decay","a5fb00b4":"## Best of 5's","ff5a00c1":"## $\\epsilon$-greedy with decay\n\nSame as above with a 0.97 decay factor.","b94d1a52":"## Simulation: Default vs $\\epsilon$-greedy with decay","15ec978c":"## $\\epsilon$-greedy without decay\n\nThis modifies the default `submission.py` provided by the competition along by using the $\\epsilon$-greedy algorithm ","7c63fc3b":"## Simulation: $\\epsilon$-greedy with decay vs $\\epsilon$-greedy without decay"}}