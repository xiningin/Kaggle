{"cell_type":{"a8a9b6aa":"code","29722989":"code","d5e80be1":"code","841c8cd0":"code","a0710849":"code","9f516dd5":"code","a24f1e73":"code","5a4610ff":"code","a4ab2a18":"code","b575bf28":"code","70d0843f":"code","ce00f1bc":"code","67a4f546":"code","a9fbb787":"code","c1eaa9ab":"code","e29cc95e":"code","3a01ebbf":"code","2a069232":"code","2da3c298":"code","31b3b332":"code","ebe36916":"code","71a50273":"code","42b1681b":"code","a850ac16":"code","e762cf4e":"code","77d90eed":"code","e712abbb":"code","0b9a126f":"code","c22275e6":"code","315404ff":"code","2bcf4914":"code","2feae14e":"code","042e2595":"code","721774ff":"code","122187ad":"code","c03d8748":"code","51b7dced":"code","5db65ec8":"code","f03ff075":"code","ba1f35d3":"code","308806e6":"code","388e25fa":"code","388368ac":"code","17f4e76a":"code","0aa48fc4":"code","209d0e93":"code","e4b32e26":"code","acb04ec8":"code","57136f36":"code","ff9e76b9":"code","0416b88d":"code","462c7bdc":"code","ae90cac5":"code","0a850cb0":"code","548cacc3":"code","b2dd4783":"code","7614e05a":"code","609a88c5":"code","19a768fb":"code","faacbdbe":"code","e37e56df":"code","91378a1a":"code","d39dbc5c":"code","f3bbc05d":"code","c3511400":"code","0afca481":"code","a37cba91":"code","966e4096":"code","a01bd08b":"code","f6d9c0ee":"code","0a33ce73":"code","8956e12f":"code","8cb34606":"code","4852452e":"code","a8d53656":"code","3194510a":"code","410c7692":"code","9e91b6b1":"code","8afcfec8":"code","f5c924ec":"code","cf90bdc3":"code","caa11653":"code","6c8b7cbf":"code","bff83d91":"code","904ff910":"code","1c1b7b51":"code","7a3bb2a8":"code","3c23f665":"markdown","5db654f8":"markdown","d0dc2791":"markdown","49d5eac2":"markdown","dbae4c8c":"markdown","88c7665a":"markdown","e3e69897":"markdown","b04e0a7b":"markdown","ed732b09":"markdown","0d1b4df9":"markdown","dc195c49":"markdown","b4e08823":"markdown","da9e8d10":"markdown","1ef1180d":"markdown","a146e405":"markdown","2e1f4a68":"markdown"},"source":{"a8a9b6aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","29722989":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","d5e80be1":"train_df.columns","841c8cd0":"train_df.head()","a0710849":"train_df.describe()","9f516dd5":"train_df.info()","a24f1e73":"def bar_plot(variable):\n    \"\"\"\n        input: variable ex: \"Sex\"\n        output: bar plot & value count\n    \"\"\"\n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","5a4610ff":"category1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\", \"Parch\"]\nfor c in category1:\n    bar_plot(c)","a4ab2a18":"category2 = [\"Cabin\", \"Name\", \"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","b575bf28":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","70d0843f":"numericVar = [\"Fare\", \"Age\",\"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","ce00f1bc":"# Plcass vs Survived\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","67a4f546":"# Sex vs Survived\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","a9fbb787":"# Sibsp vs Survived\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","c1eaa9ab":"# Parch vs Survived\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","e29cc95e":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","3a01ebbf":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","2a069232":"# drop outliers\ntrain_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)","2da3c298":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop = True)","31b3b332":"train_df.head()","ebe36916":"train_df.columns[train_df.isnull().any()]","71a50273":"train_df.isnull().sum()","42b1681b":"train_df[train_df[\"Embarked\"].isnull()]","a850ac16":"train_df.boxplot(column=\"Fare\",by = \"Embarked\")\nplt.show()","e762cf4e":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","77d90eed":"train_df[train_df[\"Fare\"].isnull()]","e712abbb":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","0b9a126f":"train_df[train_df[\"Fare\"].isnull()]","c22275e6":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\nplt.show()","315404ff":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","2bcf4914":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", kind = \"bar\", data = train_df, size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","2feae14e":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","042e2595":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","721774ff":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 2)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","122187ad":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","c03d8748":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","51b7dced":"train_df[train_df[\"Age\"].isnull()]","5db65ec8":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","f03ff075":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\",data = train_df, kind = \"box\")\nplt.show()","ba1f35d3":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","308806e6":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","388e25fa":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","388368ac":"train_df[train_df[\"Age\"].isnull()]","17f4e76a":"train_df[\"Name\"].head(10)","0aa48fc4":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","209d0e93":"train_df[\"Title\"].head(10)","e4b32e26":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","acb04ec8":"# convert to categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)","57136f36":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","ff9e76b9":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","0416b88d":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","462c7bdc":"train_df.head()","ae90cac5":"train_df = pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","0a850cb0":"train_df.head()","548cacc3":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","b2dd4783":"train_df.head()","7614e05a":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","609a88c5":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","19a768fb":"train_df.head(10)","faacbdbe":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","e37e56df":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","91378a1a":"train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\ntrain_df.head()","d39dbc5c":"train_df[\"Embarked\"].head()","f3bbc05d":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","c3511400":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","0afca481":"train_df[\"Ticket\"].head(20)","a37cba91":"a = \"A\/5. 2151\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","966e4096":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","a01bd08b":"train_df[\"Ticket\"].head(20)","f6d9c0ee":"train_df.head()","0a33ce73":"train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\")\ntrain_df.head(10)","8956e12f":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","8cb34606":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns= [\"Pclass\"])\ntrain_df.head()","4852452e":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns=[\"Sex\"])\ntrain_df.head()","a8d53656":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","3194510a":"train_df.columns","410c7692":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","9e91b6b1":"train_df_len","8afcfec8":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)","f5c924ec":"test.head()","cf90bdc3":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","caa11653":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2) \nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","6c8b7cbf":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","bff83d91":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","904ff910":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","1c1b7b51":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","7a3bb2a8":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","3c23f665":"## Data Analysis","5db654f8":"## Missing Value","d0dc2791":"## Ensemble Modeling\n","49d5eac2":"## Numerical Variable","dbae4c8c":"## Prediction and Submission","88c7665a":"## Outlier Detection","e3e69897":"## Train Test Split","b04e0a7b":"## Hyperparameter Tuning - Grid Search - Cross Validation\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","ed732b09":"## Modeling","0d1b4df9":"## Load Data","dc195c49":"# Titanic Case\n\nThe sinking of Titanic is one of the most notorious shipwrecks in the history. In 1912, during her voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.\n","b4e08823":"## Visualization","da9e8d10":"## Variable Description\n* PassengerId: unique id number to each passenger\n* Survived: passenger survive(1) or died(0)\n* Pclass: passenger class\n* Name: name\n* Sex: gender of passenger\n* Age: age of passenger\n* SibSp: number of siblings\/spouses\n* Parch: number of parents\/children\n* Ticket: ticket number\n* Fare: amount of money spent on ticket\n* Cabin: cabin category\n* Embarked: port where passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton)","1ef1180d":"## Logistic Regression","a146e405":"## Feature Engineering","2e1f4a68":"## Categorical Variable"}}