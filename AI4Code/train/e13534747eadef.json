{"cell_type":{"45bea12a":"code","5aeb2297":"code","7104884a":"code","790ecdaf":"code","a311a017":"code","22fa58f2":"code","df313244":"code","f5946c89":"code","03099725":"code","b07b9b8f":"code","ac3c26e1":"code","f170214c":"code","43d3ceac":"code","636fdad2":"code","bc7150dd":"code","ed155912":"code","e49d9222":"code","927ae0b7":"code","da4db6f3":"code","121b1fe5":"code","519db87c":"code","63cbb608":"code","c8f6e31f":"code","1bec9e88":"code","26f21fe4":"code","58e71629":"code","15248030":"code","3f3072c8":"code","b65ef9f2":"code","c932642c":"code","af46df16":"code","9e291a44":"code","2f949156":"code","36ad285f":"code","35a82aee":"code","b739663d":"code","772f9962":"code","e74c727a":"code","2cf981ad":"code","4f91a7b2":"code","d0e8d1d2":"code","356d48a3":"code","b60510da":"code","37657933":"markdown","6c366692":"markdown","e48b31cf":"markdown","167cf27c":"markdown","acabadcb":"markdown","12a05f2d":"markdown","0516f38e":"markdown","77a38ca9":"markdown","c7edef8e":"markdown","9014346c":"markdown","598cc002":"markdown","5baad38e":"markdown"},"source":{"45bea12a":"\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \n\nimport os\nfrom PIL import Image\n\n\nimport IPython.display \nfrom keras.preprocessing.image import array_to_img \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n\nfrom keras.callbacks import TensorBoard \nfrom time import strftime ","5aeb2297":"IMAGES_PATH = '..\/input\/plant-pathology-2020-fgvc7\/images' \nTRAIN_PATH =  '..\/input\/plant-pathology-2020-fgvc7\/train.csv'\nTEST_PATH =  '..\/input\/plant-pathology-2020-fgvc7\/test.csv' \n\n\nIMG_WIDTH = IMG_HEIGHT = 300 \nNR_CHANNELS = 3\nTOTAL_INPUTS = NR_CHANNELS * IMG_HEIGHT * IMG_WIDTH\n\nLOG_DIR = '\/kaggle\/working\/tensorboard_plant_logs\/'\n\nCOLUMNS = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\nLABEL_ENCODE = np.array([0,1,2,3])","7104884a":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH) ","790ecdaf":"train.shape","a311a017":"train.head()","22fa58f2":"train.tail()","df313244":"train.info() ","f5946c89":"train['healthy'].value_counts()","03099725":"train['multiple_diseases'].value_counts()","b07b9b8f":"train['rust'].value_counts()","ac3c26e1":"train['scab'].value_counts()","f170214c":"ex_image = os.path.join(IMAGES_PATH, train.image_id[0] + '.jpg')\nex_image = np.asanyarray(Image.open(ex_image)) \nex_image.shape","43d3ceac":"def load_images(dataset, folder): \n    arr = [] \n    for imageName in dataset:\n        path = os.path.join(folder, imageName + '.jpg') \n        img = Image.open(path) \n        img = img.resize((300, 300)) \n        arr.append(np.asanyarray(img)) \n        img.close() \n    \n    return arr ","636fdad2":"train_images_all = np.array(load_images(train.image_id, IMAGES_PATH)) \ntrain_images_all.shape","bc7150dd":"test_images_all = np.array(load_images(test.image_id, IMAGES_PATH))\ntest_images_all.shape","ed155912":"# get target from train \ntrain_all_y = train.iloc[:, 1:5]","e49d9222":"# Split data for validation set and flatten data \nx_train = train_images_all[:1638] \nx_train = x_train.reshape(x_train.shape[0], -1)\ny_train = train_all_y[:1638] \ny_train = np.dot(y_train, LABEL_ENCODE.T) # to label encoding\n\nx_val = train_images_all[1638:] # %10 for validation set \nx_val = x_val.reshape(x_val.shape[0], -1)\ny_val = train_all_y[1638:]\ny_val = np.dot(y_val, LABEL_ENCODE.T) # to label encoding\n\nprint(\"x_val shape: \" , x_val.shape) \nprint(\"x_train shape: \",x_train.shape)","927ae0b7":"plt.figure(figsize=(15,7)) \nfor i in range(1,10): \n    plt.subplot(1, 10, i) \n    plt.yticks([])\n    plt.xticks([]) \n    plt.imshow(train_images_all[i]) ","da4db6f3":"type(train_images_all[0][0][0][0])","121b1fe5":"train_images_all, test_images_all = train_images_all \/ 255.0, test_images_all \/ 255.0","519db87c":"print(type(train_images_all[0][0][0][0])) \nprint(train_images_all[0][0][0][0])","63cbb608":"# Flat Images to one single vector \ntrain_images_all = train_images_all.reshape(len(train_images_all), TOTAL_INPUTS)\ntest_images_all = test_images_all.reshape(len(test_images_all), TOTAL_INPUTS)","c8f6e31f":"train_images_all.shape","1bec9e88":"model_1 = Sequential([\n    Dense(units=32, input_dim=TOTAL_INPUTS, activation='relu'),  \n    Dense(units=16, activation='relu'), \n    Dense(units=4, activation='softmax') \n])","26f21fe4":"type(model_1)","58e71629":"model_1.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \nmodel_1.summary() ","15248030":"def get_tensorboard(model_name): \n    folder_name = f'{model_name} at {strftime(\"%H %M\")}'\n    dir_paths = os.path.join(LOG_DIR, folder_name) \n    \n    try: \n        os.makedirs(dir_paths) \n    except OSError as err:\n        print(err.strerror)\n    else: \n        print('Succesfully created.') \n    \n    return TensorBoard(log_dir=dir_paths), dir_paths ","3f3072c8":"samples_per_batch = 200 \nnr_epoch = 100","b65ef9f2":"%%time \ntensorboard, logdir = get_tensorboard('model_1') \nhistory_model_1 = model_1.fit(x_train, y_train, batch_size=samples_per_batch, validation_data=(x_val, y_val), epochs= nr_epoch, \n           callbacks=[tensorboard], verbose=0)","c932642c":"def display_model_hist(train_loss, train_accuracy, val_loss, val_accuracy): \n    \n    fig, axs = plt.subplots(2, 2)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n    \n    axs[0,0].set_xlabel('Nr of Epochs', fontsize=18)\n    axs[0,0].set_ylabel('Train Loss', fontsize=18)\n    axs[0,0].plot(train_loss,color='green')\n\n    axs[0,1].set_xlabel('Nr of Epochs', fontsize=18)\n    axs[0,1].set_ylabel('Train Accuracy', fontsize=18)\n    axs[0,1].plot(train_accuracy, color='green') \n    \n    axs[1,0].set_xlabel('Nr of Epochs', fontsize=18)\n    axs[1,0].set_ylabel('Val Loss', fontsize=18)\n    axs[1,0].plot(val_loss,color='magenta')\n\n    axs[1,1].set_xlabel('Nr of Epochs', fontsize=18)\n    axs[1,1].set_ylabel('Val Accuracy', fontsize=18)\n    axs[1,1].plot(val_accuracy, color='magenta') \n    \n\n    plt.show()","af46df16":"loss = history_model_1.history['loss'] \naccs = history_model_1.history['accuracy'] \n\nval_loss = history_model_1.history['val_loss']\nval_accuracy = history_model_1.history['val_accuracy']\n\ndisplay_model_hist(loss, accs, val_loss, val_accuracy) ","9e291a44":"nr_epoch = 200","2f949156":"%%time \ntensorboard, logdir = get_tensorboard('model_2') \nhistory_model_2 = model_1.fit(x_train, y_train, batch_size=samples_per_batch, validation_data=(x_val, y_val), epochs= nr_epoch, \n           callbacks=[tensorboard], verbose=0)","36ad285f":"loss = history_model_2.history['loss'] \naccs = history_model_2.history['accuracy'] \n\nval_loss = history_model_2.history['val_loss']\nval_accuracy = history_model_2.history['val_accuracy']\n\ndisplay_model_hist(loss, accs, val_loss, val_accuracy) ","35a82aee":"model_3 = Sequential([\n    Dropout(0.2, seed=42, input_shape=(TOTAL_INPUTS,)),\n    Dense(units=64, activation='relu'),  \n    Dense(units=32, activation='relu'),\n    Dense(units=16, activation='relu'), \n    Dense(units=4, activation='softmax') \n])\n\nmodel_3.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \nmodel_3.summary()","b739663d":"%%time \ntensorboard, logdir = get_tensorboard('model_3') \nhistory_model_3 = model_3.fit(x_train, y_train, batch_size=samples_per_batch, validation_data=(x_val, y_val), epochs= nr_epoch, \n           callbacks=[tensorboard], verbose=0)","772f9962":"loss = history_model_3.history['loss'] \naccs = history_model_3.history['accuracy'] \n\nval_loss = history_model_3.history['val_loss']\nval_accuracy = history_model_3.history['val_accuracy']\n\ndisplay_model_hist(loss, accs, val_loss, val_accuracy) ","e74c727a":"test_ph = np.expand_dims(test_images_all[0], axis=0)\ntest_ph.shape","2cf981ad":"model_3.predict(test_ph)","4f91a7b2":"test_images_all.shape","d0e8d1d2":"%%time\nresult = model_3.predict(test_images_all)","356d48a3":"submission = pd.DataFrame(columns=train.columns[1:], data=result)\nsubmission = pd.concat([test, submission], axis=1)","b60510da":"submission.head() ","37657933":"* Try early stopping, because we have obtained high accuracy and low loss previous epoch.  ","6c366692":"* As you can see, we have large images. \n* We can't load all of them in main memory. \n* There is several ways to handle this problem but we just resize it. \n* For now its size is going to be fixed, at the end we can arrange it again. ","e48b31cf":"# Constants","167cf27c":"# Imports","acabadcb":"### In train set; \n* image_id: the foreign key for the parquet files\n* combinations: one of the target labels\n* healthy: one of the target labels\n* rust: one of the target labels\n* scab: one of the target labels","12a05f2d":"# Get the Data","0516f38e":"# Prediction and Evaluate Model","77a38ca9":"# Pre-process Data ","c7edef8e":"## Get the imgs","9014346c":"# Fit the Model ","598cc002":"# Tensorboard","5baad38e":"# Define the Neural Network Using Keras "}}