{"cell_type":{"b8887ffa":"code","3cdf0a6e":"code","fbd9892f":"code","993b4e46":"code","e12c82f4":"code","c63db22f":"code","e3cbb316":"code","110a2c40":"code","198662d5":"markdown","39f47472":"markdown","6d620c8b":"markdown","5f3269de":"markdown","6648076c":"markdown","2e23e25a":"markdown","2ae46649":"markdown","84c4ca65":"markdown","8e3faf00":"markdown"},"source":{"b8887ffa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical","3cdf0a6e":"img_rows, img_cols = 28, 28\n\nraw_train = np.array(pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\"), dtype='float32')\nraw_test = np.array(pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\"), dtype='float32')\n\nx_train = raw_train[:, 1:]\/255.0\ny_train = raw_train[:,0]\n\nx_test = raw_test[:, 1:]\/255.0\ny_test = raw_test[:,0]\n\nx_train = x_train.reshape(y_train.shape[0], img_rows, img_cols,1)\nx_test = x_test.reshape(y_test.shape[0], img_rows, img_cols,1)\n\nprint(x_train.shape)\nprint(x_test.shape)\n\nK = len(set(y_train))\nprint (K)\n\nplt.imshow(x_train[4500].reshape(28,28))","fbd9892f":"i = Input(shape=x_test[0].shape)\n\nx = Conv2D(32, (3,3), activation='relu', padding='same') (i)\nx = BatchNormalization() (x)\nx = Conv2D(32, (3,3), activation='relu', padding='same') (x)\nx = BatchNormalization() (x)\nx = MaxPooling2D((2,2))(x)\n\nx = Conv2D(64, (3,3), activation='relu', padding='same') (i)\nx = BatchNormalization() (x)\nx = Conv2D(64, (3,3), activation='relu', padding='same') (x)\nx = BatchNormalization() (x)\nx = MaxPooling2D((2,2))(x)\n\nx = Conv2D(128, (3,3), activation='relu', padding='same') (i)\nx = BatchNormalization() (x)\nx = Conv2D(128, (3,3), activation='relu', padding='same') (x)\nx = BatchNormalization() (x)\nx = MaxPooling2D((2,2))(x)\n\nx = Flatten() (x)\n\nx = Dense(1024, activation='relu') (x)\nx = Dropout(0.2) (x)\nx = Dense(128, activation = 'relu') (x)\nx = Dropout(0.2) (x)\nx = Dense(K, activation='softmax') (x)\n\nmodel = Model(i,x)","993b4e46":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","e12c82f4":"\nr = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 20)","c63db22f":"plt.plot(r.history['loss'], label=\"loss\")\nplt.plot(r.history['val_loss'], label=\"val_loss\")\n\nplt.plot(r.history['accuracy'], label=\"accuracy\")\nplt.plot(r.history['val_accuracy'], label=\"val_accuracy\")\n\nplt.legend()","e3cbb316":"batch_size = 32\nbatch_generator = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)\ntrain_generator = batch_generator.flow(x_train, y_train, batch_size)\nr = model.fit_generator(train_generator, validation_data=(x_test, y_test), steps_per_epoch=x_train.shape[0]\/\/batch_size, epochs=20)","110a2c40":"plt.plot(r.history['loss'], label=\"loss\")\nplt.plot(r.history['val_loss'], label=\"val_loss\")\n\nplt.plot(r.history['accuracy'], label=\"accuracy\")\nplt.plot(r.history['val_accuracy'], label=\"val_accuracy\")\n\nplt.legend()","198662d5":"**Do some plotting of accuracy and loss**","39f47472":"**Plot Loss and Accuracy Again**","6d620c8b":"**Train**","5f3269de":"**Compile Model**","6648076c":"**Imports**","2e23e25a":"**Prep data******","2ae46649":"**Now we will try to add a generator and use data augmentation to see if the result improves**","84c4ca65":"**Make model**","8e3faf00":"****For whosoever is viewing this notebook, this is a convnet model (basically two models) that I used to get better results with fashion mnist dataset.\nOne of the main challenge with fashion mnist is the overlapping labels and also the tiny little blob of images that those are.\nSo, in the first model, I used only batch normalization and maxpooling to see if I could get some good result with the dataset over normal conv->Dense model.\n\nHowever, that didn't do much, and I was still overfitting. \nSo, I used augmentation with horizontal and vertical shift with horizontal flip as properties. That did however, made the curves converge much more, i.e., loss and accuracy.\n\nYou should ideally run both models individually. Running those sequentially would build up on one another (not a bad thing, but won't show the advantage of augmentation).****"}}