{"cell_type":{"bd5ca290":"code","c4308ed8":"code","85fa709d":"code","f7125ceb":"code","becbf0cd":"code","ba2fd733":"code","8859fe01":"code","91866b9f":"code","33899f99":"code","ce3e9ed4":"code","13c4c08d":"code","d65d572d":"code","4fdd43f3":"code","66f201f7":"code","8bec44d5":"code","142558d4":"code","ebf6f2b2":"code","16e57c32":"code","1408081b":"code","64fc4640":"code","c1d378be":"code","ee3171c0":"code","366b71ce":"code","65762aee":"code","4582aeb3":"code","0caad4f4":"code","cdadb2e2":"code","759beb05":"code","a49f924b":"code","17b94663":"code","f7d01af1":"code","c14c2da9":"code","178492a8":"code","edcc1f32":"code","0bc01ded":"code","b0a6bd86":"code","08365228":"code","f26ed121":"code","c59cc626":"code","9236a671":"markdown","ef029350":"markdown","be1f5474":"markdown"},"source":{"bd5ca290":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c4308ed8":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import Model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\nimport os\nimport gc\nimport joblib\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import utils\nimport tensorflow as tf","85fa709d":"train=pd.read_csv('..\/input\/cat-in-the-dat-ii\/train.csv')\ntest=pd.read_csv('..\/input\/cat-in-the-dat-ii\/test.csv')","f7125ceb":"print(\"training data size: \", train.shape)\nprint(\"training data size: \", test.shape)","becbf0cd":"def create_model(data, features):\n    inputs=[]\n    output=[]\n    \n    for c in features:\n        num_unique_values = int(data[c].nunique())\n        embed_dim = int(min(np.ceil((num_unique_values)\/2), 50))\n        inp = layers.Input(shape=(1,))\n        out = layers.Embedding(num_unique_values + 1, embed_dim, name=c)(inp)\n        out = layers.SpatialDropout1D(0.3)(out)\n        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n        inputs.append(inp)\n        output.append(out)\n        \n    x=layers.Concatenate()(output)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Dense(300, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Dense(300, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.BatchNormalization()(x)\n    \n    y = layers.Dense(2, activation=\"softmax\")(x)\n\n    model = Model(inputs=inputs, outputs=y)\n    return model","ba2fd733":"def auc(y_true, y_pred):\n    def fallback_auc(y_true, y_pred):\n        try:\n            return metrics.roc_auc_score(y_true, y_pred)\n        except:\n            return 0.5\n    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)","8859fe01":"test[\"target\"] = -1\ndata = pd.concat([train, test]).reset_index(drop=True)\nfeatures = [x for x in train.columns if x not in [\"id\", \"target\"]]\nfor feat in features:\n    lbl_enc = LabelEncoder()\n    data[feat] = lbl_enc.fit_transform(data[feat].fillna(\"-1\").astype(str).values)\ntrain = data[data.target != -1].reset_index(drop=True)\ntest = data[data.target == -1].reset_index(drop=True)\ntest_data = [test.loc[:, features].values[:, k] for k in range(test.loc[:, features].values.shape[1])]\noof_preds = np.zeros((len(train)))\ntest_preds = np.zeros((len(test)))\n\nskf = StratifiedKFold(n_splits=50)\nfor train_index, test_index in skf.split(train, train.target.values):\n    X_train, X_test = train.iloc[train_index, :], train.iloc[test_index, :]\n    X_train = X_train.reset_index(drop=True)\n    X_test = X_test.reset_index(drop=True)\n    y_train, y_test = X_train.target.values, X_test.target.values\n    model = create_model(data, features)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])\n    X_train = [X_train.loc[:, features].values[:, k] for k in range(X_train.loc[:, features].values.shape[1])]\n    X_test = [X_test.loc[:, features].values[:, k] for k in range(X_test.loc[:, features].values.shape[1])]\n    \n    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=5,\n                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n\n    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n                                      patience=3, min_lr=1e-6, mode='max', verbose=1)\n    \n    model.fit(X_train,\n              utils.to_categorical(y_train),\n              validation_data=(X_test, utils.to_categorical(y_test)),\n              verbose=1,\n              batch_size=1024,\n              callbacks=[es, rlr],\n              epochs=100\n             )\n    valid_fold_preds = model.predict(X_test)[:, 1]\n    test_fold_preds = model.predict(test_data)[:, 1]\n    oof_preds[test_index] = valid_fold_preds.ravel()\n    test_preds += test_fold_preds.ravel()\n    print(metrics.roc_auc_score(y_test, valid_fold_preds))\n    K.clear_session()","91866b9f":"tf.keras.models.save_model(model, '..\/output\/kaggle\/working\/', overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)","33899f99":"print(\"Overall AUC={}\".format(metrics.roc_auc_score(train.target.values, oof_preds)))","ce3e9ed4":"test_preds \/= 50\ntest_ids = test.id.values\nprint(\"Saving submission file\")\nsubmission = pd.DataFrame.from_dict({\n    'id': test_ids,\n    'target': test_preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","13c4c08d":"train_df['target'].value_counts()","d65d572d":"target=train_df['target']\ndel train_df['target']","4fdd43f3":"train_df['nom_0'].value_counts()","66f201f7":"train_df['nom_1'].value_counts()","8bec44d5":"train_df['nom_2'].value_counts()","142558d4":"train_df['nom_3'].value_counts()","ebf6f2b2":"for i in range(10):\n    print(train_df['nom_{}'.format(i)].value_counts())\n    print('\\n')","16e57c32":"data=pd.concat([train_df, test_df])","1408081b":"cols=['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\n","64fc4640":"mode = data.filter(cols).mode()\ndata[cols]=data[cols].fillna(mode.iloc[0])","c1d378be":"data['bin_3']=data['bin_3'].map({'F': 0, 'T':1})\ndata['bin_4']=data['bin_4'].map({'Y':1, 'N':0})","ee3171c0":"data[['bin_0', 'bin_1', 'bin_2']]=data[['bin_0', 'bin_1', 'bin_2']].astype('int8')","366b71ce":"cols=[]\nfor i in range(10):\n    cols.append(\"nom_{}\".format(i))","65762aee":"data=data.fillna(-1)","4582aeb3":"data.reset_index(inplace=True)","0caad4f4":"data=data.drop('id', axis=1)","cdadb2e2":"data=data.drop('index', axis=1)","759beb05":"from sklearn.preprocessing import LabelEncoder\n\nfeatures=[i for i in data.columns]","a49f924b":"le=LabelEncoder()\nfor i in features:\n    data[i]=le.fit_transform(data[i].astype(str))","17b94663":"train_data=data[:600000]\ntest_data=data[600000:]","f7d01af1":"X_train, X_test, y_train, y_test=train_test_split(train_data, target, test_size=.20)","c14c2da9":"classifier=RandomForestClassifier(n_estimators=1200, max_depth=100, n_jobs=-1, verbose=2, max_features='sqrt')","178492a8":"classifier.fit(X_train, y_train, )","edcc1f32":"pred=classifier.predict(X_test)","0bc01ded":"from sklearn.metrics import f1_score","b0a6bd86":"fs=f1_score(y_test, pred)","08365228":"fs","f26ed121":"import lightgbm as lgb","c59cc626":"param = {\n    'num_leaves': 31,\n    'objective': 'binary'\n    'metric': ''}\nparam['metric'] = ['auc', 'binary_logloss']","9236a671":"## CH-SQAURE TEST","ef029350":"## Encoding","be1f5474":"## Lightgbm"}}