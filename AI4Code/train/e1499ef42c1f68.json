{"cell_type":{"45abff51":"code","ca6e6d49":"code","b88a341d":"code","cfde85ee":"code","71ffcdd7":"code","52d39bf3":"code","35155e90":"code","4d39c9ca":"code","c2315757":"code","93a5366a":"code","d93b1161":"code","e7064e98":"code","76c964b2":"code","59c65e77":"code","48abd612":"code","fa04bf7c":"code","cc776463":"code","e40a935d":"code","6e457b40":"code","390ec639":"code","fe0a2c86":"code","800da0d7":"code","33d96ea4":"code","c5504ecd":"code","d6e9fe2f":"code","565f3286":"code","f5ea4e29":"code","33269306":"code","4f4c4afc":"code","4dd29e89":"code","870f7bc1":"code","b509690b":"code","197b67a4":"code","5881d270":"code","e343d29c":"code","acea1f88":"code","d9b3074a":"code","c015f3ec":"code","1499dcfc":"code","ea2588e7":"code","2bba3793":"code","cd15b1cf":"code","495552a8":"code","26e8b40f":"code","a3c4dc9c":"code","6b658ae6":"code","647fc0c7":"code","32a17a46":"markdown","ab7508d0":"markdown","16406041":"markdown"},"source":{"45abff51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# data mining libaries\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, learning_curve\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\n# Import tools needed for visualization\nfrom sklearn.tree import export_graphviz\nimport pydot\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\n#plot libaries\nimport plotly\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True) # to show plots in notebook\n\n# online plotly\n#from plotly.plotly import plot, iplot\n#plotly.tools.set_credentials_file(username='XXXXXXXXXXXXXXX', api_key='XXXXXXXXXXXXXXX')\n\n# offline plotly\nfrom plotly.offline import plot, iplot\n\n# do not show any warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nSEED = 17 # specify seed for reproducable results\npd.set_option('display.max_columns', None) # prevents abbreviation (with '...') of columns in prints","ca6e6d49":"# load the dataset\ndf = pd.read_csv('..\/input\/datasetremovenan\/S10e-6pm-20191122(kaggle).csv')\nprint(\"The dataset has %d rows and %d columns.\" % df.shape)","b88a341d":"count_nan = df.isna().sum().sum()\nprint ('Count of NaN\/NULL values: ' + str(count_nan))","cfde85ee":"df.head(15)","71ffcdd7":"def preprocess_data(df):\n    pre_df = df.copy()\n    pre_df = pre_df.drop(['Timestamp'], axis=1)\n    pre_df = pre_df.drop(['GEOMETRY'], axis=1)\n    pre_df = pre_df.drop(['UL-bitrate'], axis=1)\n    return pre_df","52d39bf3":"pre_df = preprocess_data(df)\npre_df.head(3)","35155e90":"print(\"The dataset has %d rows and %d columns.\" % pre_df.shape)","4d39c9ca":"pre_df.describe()","c2315757":"sn.boxplot(x=pre_df['DL-bitrate'])","93a5366a":"from scipy import stats\nimport numpy as np\nz = np.abs(stats.zscore(pre_df))\nprint(z)","d93b1161":"threshold = 3\nprint(np.where(z > 3))","e7064e98":"print(z[149][7])","76c964b2":"pre_df = pre_df[(z < 3).all(axis=1)]","59c65e77":"print(\"The dataset has %d rows and %d columns.\" % pre_df.shape)","48abd612":"pre_df.describe()","fa04bf7c":"sn.boxplot(x=pre_df['DL-bitrate'])","cc776463":"import matplotlib.pyplot as plt\n\n# pandas plot histogram\npre_df.hist(column='DL-bitrate')\npre_df.hist(column='Speed')\npre_df.hist(column='RSRP')\npre_df.hist(column='RSRQ')\npre_df.hist(column='SNR')\npre_df.hist(column='LTE RSSI')\n","e40a935d":"fig_size = plt.rcParams[\"figure.figsize\"]\nfig_size[0] = 10\nfig_size[1] = 7\nplt.rcParams[\"figure.figsize\"] = fig_size","6e457b40":"ax = sn.scatterplot(x=pre_df['LTE RSSI'], y=pre_df['SNR'], s=100,alpha=0.1, palette=\"icefire\", hue=pre_df['DL-bitrate'])\nplt.title('DL-bitrate relationship between SNR and LTE RSSI')\n# Remove the legend and add a colorbar\nplt.show()","390ec639":"ax = sn.scatterplot(x=pre_df['Longitude'], y=pre_df['Latitude'], s=100,alpha=0.1, palette=\"Spectral\", hue=pre_df['DL-bitrate'])\nplt.title('DL-bitrate in each geometry coordinates (kbps)')\n# Remove the legend and add a colorbar\nplt.show()","fe0a2c86":"ax = sn.scatterplot(x=pre_df['Longitude'], y=pre_df['Latitude'], s=100,alpha=0.1, palette=\"Spectral\", hue=pre_df['Speed'])\nplt.title('Speed in each geometry coordinates (km\/h)')\n# Remove the legend and add a colorbar\nplt.show()","800da0d7":"ax = sn.scatterplot(x=pre_df['Longitude'], y=pre_df['Latitude'], s=100,alpha=0.1, palette=\"Spectral\", hue=pre_df['RSRP'])\nplt.title('RSRP in each geometry coordinates (dBm)')\n# Remove the legend and add a colorbar\nplt.show()","33d96ea4":"ax = sn.scatterplot(x=pre_df['Longitude'], y=pre_df['Latitude'], s=100,alpha=0.1, palette=\"Spectral\", hue=pre_df['RSRQ'])\nplt.title('RSRQ in each geometry coordinates (dBm)')\n# Remove the legend and add a colorbar\nplt.show()","c5504ecd":"ax = sn.scatterplot(x=pre_df['Longitude'], y=pre_df['Latitude'], s=100,alpha=0.1, palette=\"Spectral\", hue=pre_df['SNR'])\nplt.title('SNR in each geometry coordinates (dBm)')\n# Remove the legend and add a colorbar\nplt.show()","d6e9fe2f":"ax = sn.scatterplot(x=pre_df['Longitude'], y=pre_df['Latitude'], s=100,alpha=0.1, palette=\"Spectral\", hue=pre_df['LTE RSSI'])\nplt.title('RSSI in each geometry coordinates (dBm)')\n# Remove the legend and add a colorbar\nplt.show()","565f3286":"# Labels are the values we want to predict\nlabels = np.array(pre_df['DL-bitrate'])\n# Remove the labels from the features\n# axis 1 refers to the columns\nfeatures= pre_df.drop('DL-bitrate', axis = 1)\n# Saving feature names for later use\nfeature_list = list(features.columns)\n# Convert to numpy array\nfeatures = np.array(features)","f5ea4e29":"# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n# Split the data into training and testing sets\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)","33269306":"print('Training Features Shape:', train_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Features Shape:', test_features.shape)\nprint('Testing Labels Shape:', test_labels.shape)","4f4c4afc":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\n# Instantiate model with 1000 decision trees\nrf = RandomForestRegressor(n_estimators = 2000, random_state = 42)\n# Train the model on training data\nrf.fit(train_features, train_labels);","4dd29e89":"# Use the forest's predict method on the test data\npredictions = rf.predict(test_features)\n# Calculate the absolute errors\nerrors = abs(predictions - test_labels)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'kbps.')","870f7bc1":"# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors \/ test_labels)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","b509690b":"# Pull out one tree from the forest\ntree = rf.estimators_[5]\n# Export the image to a dot file\nexport_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n# Use dot file to create a graph\n(graph, ) = pydot.graph_from_dot_file('tree.dot')\n# Write graph to a png file\ngraph.write_png('tree.png')","197b67a4":"# Limit depth of tree to 3 levels\nrf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\nrf_small.fit(train_features, train_labels)\n# Extract the small tree\ntree_small = rf_small.estimators_[5]\n# Save the tree as a png image\nexport_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\ngraph.write_png('small_tree.png');","5881d270":"# Get numerical feature importances\nimportances = list(rf.feature_importances_)\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","e343d29c":"# Import matplotlib for plotting and use magic command for Jupyter Notebooks\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Set the style\nplt.style.use('fivethirtyeight')\n# list of x locations for plotting\nx_values = list(range(len(importances)))\n# Make a bar chart\nplt.bar(x_values, importances, orientation = 'vertical')\n# Tick labels for x axis\nplt.xticks(x_values, feature_list, rotation='vertical')\n# Axis labels and title\nplt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');","acea1f88":"sn.regplot(x = \"DL-bitrate\", y=\"LTE RSSI\", data=pre_df, fit_reg = True, scatter_kws={\"alpha\": 0.5})","d9b3074a":"sn.regplot(x = \"DL-bitrate\", y=\"SNR\", data=pre_df, fit_reg = True, scatter_kws={\"alpha\": 0.5})","c015f3ec":"g = sn.relplot(x =\"LTE RSSI\", y=\"DL-bitrate\", kind=\"line\", data=pre_df)\ng.fig.autofmt_xdate()","1499dcfc":"g = sn.relplot(x =\"SNR\", y=\"DL-bitrate\", kind=\"line\", data=pre_df)\ng.fig.autofmt_xdate()","ea2588e7":"# Evaluating the Algorithm\nfrom sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(test_labels, predictions),'dBm')\nprint('Mean Squared Error:', metrics.mean_squared_error(test_labels, predictions), 'dBm')\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_labels, predictions)),'dBm')","2bba3793":"from sklearn.metrics import r2_score\nr2 = r2_score(test_labels, predictions)\nprint('R2 score for random forest model is', r2)","cd15b1cf":"print('actuals', test_labels)","495552a8":"print('actuals', predictions)","26e8b40f":"# Relative error\ndef mean_relative_error(test_labels, predictions):\n    relative_error = np.average(np.abs(test_labels - predictions) \/ test_labels, axis=0)\n    print('RE', relative_error)","a3c4dc9c":"df=pd.DataFrame({'Actual':test_labels, 'Predicted':predictions})\ndf","6b658ae6":"df1 = df.head(40)\ndf1.plot(kind='line',figsize=(20,10))\nplt.grid(which='major', linestyle='--', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle='--', linewidth='0.5', color='black')\nplt.show()","647fc0c7":"plt.figure(figsize=(8, 8))\nax = sn.distplot(test_labels, hist=False, color=\"r\", label=\"Actual Value\")\nsn.distplot(predictions, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax)\n\n\nplt.title('Actual vs Fitted Values')\n\n\nplt.show()\nplt.close()","32a17a46":"**DATA VISUALIZATION**","ab7508d0":"**RANDOM FOREST**","16406041":"**DATASET ANALYSIS**"}}