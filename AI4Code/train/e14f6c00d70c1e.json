{"cell_type":{"aafa7a65":"code","a51ba61a":"code","86cd3f0e":"code","a1e52608":"code","baa2d2a0":"code","90a63f89":"code","55ee33bd":"code","943b4015":"code","ac6d47b9":"code","aea7492e":"code","d6b25fc9":"code","7326a8dc":"code","b302e31a":"code","cac4bc9f":"code","95096276":"code","4f999748":"code","fc917b73":"code","66b5d8be":"code","115616a3":"code","a92f0a7d":"code","c61c1190":"code","619072dc":"code","c37cf98a":"code","f6f58b69":"code","3235a969":"code","cf68c126":"code","2c70ba17":"code","27d5637b":"code","7c2ee796":"markdown","2bafeac0":"markdown","cccc9d70":"markdown","7277285b":"markdown","7ce937a8":"markdown","9187e1f8":"markdown","7699e1ed":"markdown","65e92122":"markdown","4bc51887":"markdown","85da6a6f":"markdown"},"source":{"aafa7a65":"#Importing Preprocessing libraries\nimport numpy as np\nimport pandas as pd \n\nfrom sklearn import preprocessing\nimport pandas_profiling as pp\nfrom sklearn.impute import KNNImputer\n\n\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\n\n#Importing visualize libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Importing Machine learning models library used for classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as knn\nfrom sklearn.naive_bayes import GaussianNB as GB\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score , recall_score\nfrom sklearn.model_selection import GridSearchCV \n","a51ba61a":"#Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","86cd3f0e":"#read data \ndf = pd.read_csv('..\/input\/churn-prediction\/Churn.csv')\ndf.head()","a1e52608":"#check info and Describe  total data\ndf.info()\ndf.describe().T","baa2d2a0":"#drop id\ndf = df.drop(\"customerID\",axis = 1)\ndf.head()","90a63f89":"pp.ProfileReport(df)","55ee33bd":"#Encoding\n\ndf['gender'] = df['gender'].map({'Male': 0,'Female': 1})\n\ndf['MultipleLines'] = df['MultipleLines'].map({'No phone service': -1 ,'No': 0 ,'Yes' : 1 })\n\n\ncolumns_to_dummy = ['Partner', \n                    'Dependents', \n                    'PhoneService', \n                    'PaperlessBilling', \n                    'Churn']\n\nfor col in columns_to_dummy:\n      df[col] = df[col].map({'No': 0,'Yes': 1})\n        \ncolumns_to_lable = ['OnlineSecurity',\n                    'OnlineBackup',\n                    'DeviceProtection',\n                    'TechSupport',\n                    'StreamingTV',\n                    'StreamingMovies']\n\nfor i in columns_to_lable:\n    df[i] = df[i].map({'No internet service': -1 ,'No': 0 ,'Yes' : 1 })\n\ndf =pd.get_dummies(data = df, columns =\n                          ['InternetService', 'Contract', 'PaymentMethod'],drop_first = True )\n\ndf.head()\n","943b4015":"# Outlier detection & Management and Correlation\ndf.skew()","ac6d47b9":"df.isnull().sum()","aea7492e":"# Missing Value detection & Management\n\ndf['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan, regex=True)\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n\n\ndf.isnull().sum(axis = 0)\n\nimputer = KNNImputer()\ndf['TotalCharges'] = imputer.fit_transform(df[['TotalCharges']])\ndf.isna().sum()","d6b25fc9":"#Scaling\nmm_scaler = preprocessing.MinMaxScaler()\ndata_scaled = pd.DataFrame(mm_scaler.fit_transform(df),columns = df.columns)\n\ndata_scaled","7326a8dc":"data_scaled.var()","b302e31a":"X = data_scaled.drop(['Churn'], axis=1)\ny = data_scaled['Churn']","cac4bc9f":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    return(vif)\n\nvifList = calc_vif(X).sort_values( by = 'VIF' , ascending = False)\nvifList. reset_index(drop=True, inplace=True)\nvifList","95096276":"#Feature importance for modeling\ndata_scaled = data_scaled.drop(['MonthlyCharges','StreamingMovies','StreamingTV', 'tenure' , 'PhoneService','TechSupport'], axis=1)\n\nvifList = calc_vif(data_scaled).sort_values( by = 'VIF' , ascending = False)\nvifList. reset_index(drop=True, inplace=True)\nvifList","4f999748":"data = data_scaled.copy()","fc917b73":"X = data.drop('Churn' , axis = 1)\ny = data['Churn']","66b5d8be":"# check target is balance or not\ng = sns.countplot(data['Churn'])\ng.set_xticklabels([1,0])\nplt.show()\n\n# class count\ny_count_0, y_count_1 = data['Churn'].value_counts()\n\n# Separate class\nclass_0 = data[data['Churn'] == 0]\nclass_1 = data[data['Churn'] == 1]\n\n# print the shape of the class\nprint('class 0:', class_0.shape)\nprint('class 1:', class_1.shape)","115616a3":"#Balancing target by over sampling\nsmote = SMOTE(k_neighbors = 10)\nX, y = smote.fit_resample(X, y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","a92f0a7d":"# check target is balance or not\ng = sns.countplot(y)\ng.set_xticklabels([1,0])\nplt.show()\n\n# class count\ny_count_0, y_count_1 = y.value_counts()\n\n# Separate class\nclass_0 = y == 0\nclass_1 = y == 1\n\n# print the shape of the class\nprint('class 0:', class_0.shape)\nprint('class 1:', class_1.shape)","c61c1190":"#def func for multiple modleing\n\ndef Cls_model_GrdSrch_Tune(model, Data, X, y, params):\n    \n    clf = GridSearchCV(model, params, scoring ='accuracy', cv = 5)\n    clf.fit(X, y)\n    \n    print(\"best score is :\" , clf.best_score_)\n    print(\"best estimator is :\" , clf.best_estimator_)\n    print(\"best Params is :\" , clf.best_params_)\n    \n    return (clf.best_score_)","619072dc":"models_lables = [\"RandomForestClassifier\",\"Gaussian Naive Bays\",\"KNN\",\"Logistic_Regression\",\"Support_Vector\"]\nmodels = [RandomForestClassifier(),GB(),knn(),LogisticRegression(),SVC()]\nModel_Accuracy_default = []\n\nfor models_lable, model in zip(models_lables, models):\n    print('*****************************************')\n    print(models_lable)\n    Accuracy = Cls_model_GrdSrch_Tune(model, data, X_train, y_train, {})\n    Model_Accuracy_default.append(Accuracy)","c37cf98a":"AccuracyList_default = pd.DataFrame({ \n     \"Classification Model\" :models,\n     \"Accuracy\":Model_Accuracy_default\n    })\nAccuracyList_default.sort_values( by = 'Accuracy' , ascending = False)","f6f58b69":"models_lables = [\"RandomForestClassifier\",\"Gaussian Naive Bays\",\"KNN\",\"Logistic_Regression\",\"Support_Vector\"]\n\nmodels = [RandomForestClassifier(),GB(),knn(),LogisticRegression(),SVC()]\n\nparams_RFC = {   \n                'n_estimators': [5, 10, 15, 19, 20, 21, 25, 30, 35, 40],\n                'min_samples_split': [2, 3, 4, 5, 6],\n                'criterion' : [\"gini\", \"entropy\"]\n            }\nparams_GB = {\n        \n            }  \nparams_KNN = {\n               'n_neighbors':[3, 4, 5, 10, 15, 20],\n               'weights':('uniform','distance'),\n               'p':[1,5]\n             }  \nparams_LR = {\n             'C': [0.01,0.1,1,10],'penalty':('l1','l2'),\n             'penalty': ('l1', 'l2', 'elasticnet')\n            }    \nparams_SVC = {\n    \n              'C': [0.1, 1, 10, 20, 100],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001,10], \n              'kernel': ['rbf']\n             } \n\nparams = [params_RFC, params_GB, params_KNN, params_LR, params_SVC]\n\nModel_Accuracy_tunned = []\n\n# lst = zip(models_lables, models, params)\n# list(lst)\n\nfor models_lable, model, param in zip(models_lables, models, params):\n    print('*****************************************')\n    print(models_lable)\n    \n    Accuracy = Cls_model_GrdSrch_Tune(model, data, X_train, y_train, param)\n    Model_Accuracy_tunned.append(Accuracy)\n    ","3235a969":"AccuracyList_tunned = pd.DataFrame({ \n     \"Classification Model\" :models,\n     \"Accuracy\":Model_Accuracy_tunned\n    })\nAccuracyList_tunned.sort_values( by = 'Accuracy' , ascending = False)","cf68c126":"AccuracyList_final = pd.DataFrame({ \n     \"Classification Model\" :models,\n     \"Accuracy_with_default_config\":Model_Accuracy_default,\n     \"Accuracy_with_tunned_params\": Model_Accuracy_tunned\n    })\nAccuracyList_final.sort_values(by = 'Accuracy_with_tunned_params' , ascending = False)","2c70ba17":"# selected model up on accuracy score is RandomForestClassifier with Tunned HyperParams\nparams = {'n_estimators' : [35],\n          'min_samples_split' : [5],\n          'criterion': [\"entropy\"]\n         }\n\nRFC = GridSearchCV(RandomForestClassifier(), params)\nRFC.fit(X_train, y_train)\ny_predicted = RFC.predict(X_test)\n\nRFDT_model = RFC.best_estimator_\nprint (RFC.best_score_, RFC.best_params_)","27d5637b":"conf_matrix = confusion_matrix(y_test, y_predicted)\n\nacc_score = accuracy_score(y_test, y_predicted)\npre_score = precision_score(y_test, y_predicted)\nre_score = recall_score(y_test, y_predicted)\n\nprint('accuracy_score : ', acc_score)\nprint('precision_score : ', pre_score)\nprint('recall_score : ', re_score, '\\n')\n\nprint('Accuracy of RandomForestClassifier is: ', acc_score * 100)\nprint('Precision of RandomForestClassifier is: ', pre_score * 100)\nprint('Recall of KRandomForestClassifier is: ', re_score * 100, '\\n')\n\nprint('Confusion_Matrix : ',\"\\n\" , conf_matrix,  '\\n')","7c2ee796":"### This notebook contains:\n* Read data\n* Exploratory Data Analysis\n* Data Encoding\n* Checking Missing Values\n 1. Imputation KNN\n* Outlier Detection\n* Data Scaling\n* Feature Selection and Feature Engineering\n  1. Checking Variance_Inflation_Factor\n  2. Backward Feature Selection\n* Modeling\n 1. Splitting the dataset\n 2. Balancing Target by Over Sampling Technique\n 3. Building Model Pipeline\n 4. Performing Hyperparameters Tuning\n 5. Creating Table Compression of the Results\n* Confusion Matrix\n","2bafeac0":"### Cheking Variance of the features ","cccc9d70":"### Compare Result Accuracy","7277285b":"## Selected Best Model","7ce937a8":"### Modeling by Default values Hyperparameters","9187e1f8":"## Feature selection and Feature Engineering","7699e1ed":"### Cheking Variance_Inflation_Factor ","65e92122":"## Modeling","4bc51887":"# Telco Churn Analysis\n* Dataset Info: Sample Data Set containing Telco customer data and showing customers left last month","85da6a6f":"### Modeling with tunning Hyperparameters"}}