{"cell_type":{"fe9ac730":"code","3afab222":"code","f4f32ab4":"code","2265d41b":"code","91fac85a":"code","ffeb8d2d":"code","b15ad574":"code","dd1846c6":"code","7bef62fb":"code","8f6eecb7":"code","1d6c0300":"code","38a98493":"code","2e4b53e3":"code","afd1348c":"code","2067812e":"code","665e56bd":"code","1ff61a56":"code","5702693a":"markdown","846dda5b":"markdown","d60f7fb7":"markdown","d713c2d5":"markdown","d1b02018":"markdown","4cc8eb79":"markdown","a7b5c15b":"markdown","5a2b267d":"markdown","4973c2c6":"markdown","397c2e1f":"markdown","688b7ad1":"markdown"},"source":{"fe9ac730":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns","3afab222":"data = pd.read_csv(\"\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv\")\ndata.head()","f4f32ab4":"data.shape","2265d41b":"data.isnull().sum()","91fac85a":"data.salary.fillna(0,inplace = True)","ffeb8d2d":"dataStringVals = []\nfor i in data.columns:\n    dataStringVals.append(len(data[i].unique()))\nprint(f\"column: {data.columns} values: {dataStringVals}\")","b15ad574":"le = LabelEncoder()\nfor i in [\"gender\",\"ssc_b\",\"hsc_b\",\"workex\",\"specialisation\",\"status\"]: #label encoding\n    data[i] = le.fit_transform(data[i])\ndata","dd1846c6":"for i in [\"hsc_s\", \"degree_t\"]: # Onehot encoding\n    temp = pd.get_dummies(data[i])\n    data = pd.concat((data,temp),axis = 1)\n    data.drop(columns = [i],inplace = True)\ndata","7bef62fb":"listofunscaledcolumns = [\"ssc_p\",\"hsc_p\",\"degree_p\",\"etest_p\",\"mba_p\",\"salary\"]\nmms = MinMaxScaler()\nfor i in listofunscaledcolumns:\n    data[i] = mms.fit_transform(np.expand_dims(data[i].to_numpy(),axis = 1))\ndata","8f6eecb7":"data.corr()[\"status\"]","1d6c0300":"plt.figure(figsize=(10,8))\nsns.barplot(y=data.corr()[\"status\"].index,x=abs(data.corr()[\"status\"]),palette='CMRmap')","38a98493":"listofpickedcolumns = [\"ssc_p\",\"hsc_p\",\"degree_p\",\"workex\",\"specialisation\",\"salary\",\"status\"]","2e4b53e3":"data = data[listofpickedcolumns]\nX = data.drop(columns = [\"status\"])\ny = data.status","afd1348c":"X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 44, test_size = 0.2)","2067812e":"from xgboost import XGBClassifier\nXGBC = XGBClassifier()\nmodelParams = {\"max_depth\": [2,5,15,30],\n              \"subsample\": [0.5,0.75,1],\n              \"colsample_bytree\":[0.5,0.75,1],\n              \"colsample_bylevel\":[0.5,0.75,1],\n              \"min_child_weight\": [1,5,25,100],\n              \"n_estimators\": [10,50,100,250,500],\n              \"learning_rate\":[0.01,0.1,0.25]} \nXGBGridSearch = GridSearchCV(XGBC, modelParams,verbose = 2,n_jobs = -1,cv = 10) #n_jobs = -1 means use all cores for training\nXGBGridSearch.fit(X_train,y_train)\nXGBGridSearch.best_params_","665e56bd":"XGBR2 = XGBClassifier(colsample_bylevel= 0.5,colsample_bytree= 0.5,learning_rate= 0.25,max_depth= 2,min_child_weight= 1,n_estimators= 100,subsample= 0.75)\nXGBR2.fit(X_train,y_train)\ny_pred = XGBR2.predict(X_test)\ny_predtrain = XGBR2.predict(X_train)","1ff61a56":"from sklearn.metrics import confusion_matrix, accuracy_score\nprint(f\"train set confusion matrix:{confusion_matrix(y_train, y_predtrain)} train set accuracy:{accuracy_score(y_train,y_predtrain)}\")\nprint(f\"test set confusion matrix:{confusion_matrix(y_test, y_pred)} test set accuracy:{accuracy_score(y_test,y_pred)}\")","5702693a":"<a id=\"part5\"><\/a>\n# 5.GridSearch and Training:\n\nTo find best hyperparameters for XGBoostClassifier i am going to apply gridsearch.","846dda5b":"<a id=\"part4\"><\/a>\n# 4.Feature Selection:\n\nSome columns in data can affect training negatively. What we're going to do in this section is check correlations between columns and drop unnecessary ones.","d60f7fb7":"<a id=\"part6\"><\/a>\n# 6.Evaluation:\n\nLets see how model predicted.","d713c2d5":"Now, you exactly now what recruiters want.We predicted both sets(training and test) correctly. If you have any question about notebook, i am here to answer it. Thanks for your time.\n\n![](https:\/\/blog-c7ff.kxcdn.com\/blog\/wp-content\/uploads\/2013\/09\/top_5_recruit-01.jpg)","d1b02018":"<a id=\"part1\"><\/a>\n# 1.Quickpeek to Data:","4cc8eb79":"<a id=\"part3\"><\/a>\n# 3.Scaling:\n\nWe have to scale data for faster and better training.","a7b5c15b":"Dataset has 215 unique rows but salary column has 67 missing values. Lets Change their values to zero. Because we need all features as numerical value.","5a2b267d":"Seems like ssc_p, hsc_p, degree_p, workex, specialisation and salary columns more correlated with status column. Lets pick these columns for training","4973c2c6":"<a id=\"part2\"><\/a>\n# 2.Encoding:","397c2e1f":"<a id=\"part0\"><\/a>\n# 0.Campus Recruitment\n\nIn this dataset we can reach %100 accuracy with simple couple lines of code. I'am going to apply XGBClassifier to dataset and optimize it with GridSearch. Lets dive into notebook.\n\n![](https:\/\/gregsavage.com.au\/wp-content\/uploads\/2017\/05\/worstrecruiter-600x340.png)\n\n**Table of Contents **\n\n* [0.Campus Recruitment:](#part0)\n* [1.Quickpeek to Data:](#part1)\n* [2.Encoding:](#part2)\n* [3.Scaling:](#part3)\n* [4.Feature Selection:](#part4)\n* [5.GridSearch and Training:](#part5)\n* [6.Evaluation:](#part6)\n\n**DATA DICTIONARY:**\n\n1. sl_no : Serial Number(we dont need this for training)\n\n2. gender: Male='M', Female='F'\n\n3. ssc_p : Secondary Education percentage- 10th Grade\n \n4. ssc_b : Board of Education- Central\/ Others\n\n5. hsc_b : Higher Secondary Education percentage- 12th Grade\n \n6. hsc_s : Specialization in Higher Secondary Education\n \n7. degree_p: Degree Percentage\n\n8. degree_t: Under Graduation(Degree type)- Field of degree education\n \n9. workex : Work Experience\n \n10. etest_p: Entrance Test Percentage\n \n11. mba_p: MBA Percentage\n \n12. status : Placed or not\n \n13. salary : Salary offered\n","688b7ad1":"Gender, ssc_b, hsc_b, workex, specialisation and status columns have 2 different value. I am going to label encode these columns. Then i am going to apply OneHotEncoding to hsc_s and degree_t columns because these columns have 3 different values."}}