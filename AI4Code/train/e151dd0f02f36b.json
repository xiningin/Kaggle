{"cell_type":{"11b5cfbc":"code","8662586b":"code","c69e5896":"code","0570841f":"code","fee84cc0":"code","d6c7f9a9":"code","71965894":"code","03f0e6c7":"code","e5577a80":"code","d39de959":"code","f9ffc1d6":"code","c3844d04":"code","e15bf3ea":"code","07a70af1":"code","65283042":"code","acecfab9":"code","c4c6cbc9":"code","318afd0e":"code","90cbc11f":"code","4a7804b7":"code","76c06bc0":"code","2d07c4d2":"code","9fb16129":"code","98546948":"code","2e41b910":"code","f290756f":"code","ff6b071a":"code","6d6ee485":"code","3fbc2eef":"code","d1796276":"code","41d44eee":"code","4b445fa7":"code","dcd09cab":"code","f64de155":"code","df4f8098":"code","0dde5423":"code","80727b59":"code","39720528":"code","6c90953e":"code","e1319fa2":"code","61ee15be":"code","ca49509e":"code","6f12a51f":"code","16cda399":"code","93e20b21":"code","913b7f27":"code","86413644":"code","de199c46":"code","166bb05f":"code","2075fcbf":"code","a106435a":"code","ebe8494f":"code","c94ace8d":"code","400ac9cc":"code","12c99282":"code","c668ca8e":"code","af90abc2":"code","562f4a69":"code","04bdb969":"markdown","c951ccaa":"markdown","5edd3c30":"markdown","b5a1e117":"markdown","8b2f475f":"markdown","6616208f":"markdown","d58d08e9":"markdown","4591c358":"markdown","bfeefe68":"markdown","0f6b802e":"markdown","eeecd677":"markdown","fb343462":"markdown","c6ae47c4":"markdown","c25da356":"markdown","26cb8104":"markdown","31d46f45":"markdown","77dc8644":"markdown","00b26363":"markdown","75e2436c":"markdown","2493adc5":"markdown","28a0f8c9":"markdown","b98087f7":"markdown","198f43de":"markdown","c756c2a9":"markdown","e348e86e":"markdown","c8a4a259":"markdown","0c247e4c":"markdown","8afcb867":"markdown","802e09d9":"markdown","32647de7":"markdown","3e5d9409":"markdown","5f2ccc72":"markdown","66d1e28f":"markdown","173d3fd9":"markdown","1aba06ee":"markdown","9e4e7b5d":"markdown","8b8c0151":"markdown","b76f1b67":"markdown","a722cfae":"markdown","6676145e":"markdown","35a9a664":"markdown","25819ef9":"markdown","de7a5870":"markdown","5c6832cc":"markdown","0394f20d":"markdown","891f8c83":"markdown","2ab0524c":"markdown","50e534ec":"markdown","b2ebdecd":"markdown","98e17b6a":"markdown","9046f4d4":"markdown","6e3c494f":"markdown","5b228e0d":"markdown","0105d227":"markdown","ea66780f":"markdown","6bbf4b52":"markdown","e7ead3e7":"markdown","8e8372bf":"markdown","264b86ce":"markdown","be5d24d3":"markdown"},"source":{"11b5cfbc":"import numpy as np\nimport pandas as pd \nimport random as rn\n\n# tensorflow\nimport tensorflow.random as tfr\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# Chart\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport seaborn as sns\nimport glob\n\nfrom skimage import color, exposure\nfrom sklearn.metrics import classification_report\n\nimport os\nimport cv2\n\n# Setting the same seed for repeatability\n\nseed = 0\n\nnp.random.seed(seed) \nrn.seed(seed)\ntfr.set_seed(seed)\n\n# Display graphs in a Jupyter\n%matplotlib inline\n\nprint(\"Imported\")","8662586b":"data_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/'\ndata_path\n\ntrain_path = data_path + 'train\/'\ntest_path = data_path + 'test\/'\nval_path = data_path + 'val\/'","c69e5896":"img_size = 200","0570841f":"def read_data(data_paths):\n    for data_path in data_paths:\n        labels = ['PNEUMONIA', 'NORMAL']\n        images = []\n        y = []\n        for label in labels:\n            curr_path = data_path + label\n            for img in os.listdir(curr_path):\n                if ('DS' not in img):\n                    image_path = os.path.join(curr_path, img)\n                    image =  cv2.resize(cv2.imread(image_path), (img_size, img_size))\n                    if image is not None:\n                        images.append([image, label])\n                \n    images = np.asarray(images)\n    return images","fee84cc0":"train = read_data([train_path])\ntest = read_data([val_path, test_path])","d6c7f9a9":"for i in range(10):\n    np.random.shuffle(train)\n    np.random.shuffle(test)","71965894":"train_df = pd.DataFrame(train, columns=['image', 'label'])\ntest_df = pd.DataFrame(test, columns = ['image', 'label'])","03f0e6c7":"train_df['label'].head()","e5577a80":"plt.figure(figsize=(18, 8))\nsns.set_style(\"darkgrid\")\n\nplt.subplot(1,2,1)\nsns.countplot(train_df['label'], palette = 'coolwarm')\nplt.title('Train data')\n\nplt.subplot(1,2,2)\nsns.countplot(test_df['label'], palette = \"hls\")\nplt.title('Test data')\n\nplt.show()","d39de959":"def Show_example_image():\n    fig = plt.figure(figsize = (16, 16))\n    for idx in range(15):\n        plt.subplot(5, 5, idx+1)\n        plt.imshow(train_df.iloc[idx]['image'])\n        plt.title(\"{}\".format(train_df.iloc[idx]['label']))\n        \n    plt.tight_layout()\n    \nShow_example_image()","f9ffc1d6":"def lung_condition(label):\n    if label == 'NORMAL':\n        return 0\n    else:\n        return 1","c3844d04":"def splitdata(data):\n    X = []\n    y = []\n    for i, (val, label) in enumerate(data):\n        X.append(val)\n        y.append(lung_condition(label))\n    return np.array(X), np.array(y)","e15bf3ea":"np.random.shuffle(train)\nnp.random.shuffle(test)\nX_train, y_train = splitdata(train)\nX_test, y_test = splitdata(test)","07a70af1":"def preprocesing_to_mlp(data):\n    data1 = color.rgb2gray(data).reshape(-1, img_size * img_size).astype('float32')\n    \n    # Data Normalization [0, 1]\n    data1 \/= 255\n    \n    return data1","65283042":"X_train = preprocesing_to_mlp(X_train)\nX_test = preprocesing_to_mlp(X_test)","acecfab9":"num_pixels = X_train.shape[1] \n\n# one-hot encoding for target column\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\nnum_classes = y_train.shape[1]","c4c6cbc9":"def draw_learning_curve(history, keys=['accuracy', 'loss']):\n    plt.figure(figsize=(20,8))\n    for i, key in enumerate(keys):\n        plt.subplot(1, 2, i + 1)\n        sns.lineplot(x = history.epoch, y = history.history[key])\n        sns.lineplot(x = history.epoch, y = history.history['val_' + key])\n        plt.title('Learning Curve')\n        plt.ylabel(key.title())\n        plt.xlabel('Epoch')\n#         plt.ylim(ylim)\n        plt.legend(['train', 'test'], loc='best')\n    plt.show()","318afd0e":"callbacks1 = [ \n    EarlyStopping(monitor = 'loss', patience = 6), \n    ReduceLROnPlateau(monitor = 'loss', patience = 3), \n    ModelCheckpoint('..\/working\/model.best1.hdf5',monitor='loss', save_best_only=True) # saving the best model\n]","90cbc11f":"def get_mlp():\n    \n    return Sequential([\n        #input layer is automatic generation by keras\n        \n        #hidden layer\n        Dense(1024, input_dim = num_pixels, activation='relu'),\n        \n        #output layer\n        Dense(num_classes, activation='softmax')\n    ])","4a7804b7":"model = get_mlp()\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nmodel.summary()","76c06bc0":"learning_history = model.fit(X_train, y_train,\n          batch_size = 64, epochs = 40, verbose = 2,\n          callbacks = callbacks1,\n          validation_data=(X_test, y_test));","2d07c4d2":"model = load_model('model.best1.hdf5')","9fb16129":"score = model.evaluate(X_test, y_test, verbose = 0)\nprint('Test loss: {}%'.format(score[0] * 100))\nprint('Test accuracy: {}%'.format(score[1] * 100))\n\nprint(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))","98546948":"draw_learning_curve(learning_history)","2e41b910":"callbacks2 = [ \n    EarlyStopping(monitor = 'loss', patience = 6), \n    ReduceLROnPlateau(monitor = 'loss', patience = 3), \n    ModelCheckpoint('..\/working\/model.best2.hdf5', monitor='loss' , save_best_only=True) # saving the best model\n]","f290756f":"def get_mlpv2():\n    \n    return Sequential([\n        Dense(1024, input_dim=num_pixels, activation='relu'),\n        Dropout(0.4),\n        Dense(512, activation='relu'),\n        Dropout(0.3),\n        Dense(128, activation='relu'),\n        Dropout(0.3),\n        Dense(num_classes, activation='softmax')\n    ])","ff6b071a":"model = get_mlpv2()\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nmodel.summary()","6d6ee485":"learning_history = model.fit(X_train, y_train,\n          batch_size = 64, epochs = 100, verbose = 1,\n          callbacks = callbacks2,\n          validation_data=(X_test, y_test));","3fbc2eef":"model = load_model('model.best2.hdf5')","d1796276":"score = model.evaluate(X_test, y_test, verbose = 0)\nprint('Test loss: {}%'.format(score[0] * 100))\nprint('Test accuracy: {}%'.format(score[1] * 100))\n\nprint(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))","41d44eee":"draw_learning_curve(learning_history)","4b445fa7":"X_train, y_train = splitdata(train)\nX_test, y_test = splitdata(test)","dcd09cab":"def preprocesing_to_cnn(data):\n    data1 = color.rgb2gray(data).reshape(-1, img_size, img_size, 1).astype('float32')\n    data1 \/= 255\n    return data1","f64de155":"X_train = preprocesing_to_cnn(X_train)\nX_test = preprocesing_to_cnn(X_test)\n\n# one-hot encoding for target column\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","df4f8098":"num_classes = y_train.shape[1]","0dde5423":"input_shape = (img_size, img_size, 1)","80727b59":"callbacks3 = [ \n    EarlyStopping(monitor = 'loss', patience = 6), \n    ReduceLROnPlateau(monitor = 'loss', patience = 3), \n    ModelCheckpoint('..\/working\/model.best3.hdf5', monitor='loss' , save_best_only=True) # saving the best model\n]","39720528":"num_pixels ","6c90953e":"def get_modelcnn():\n    return Sequential([\n        \n        Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', input_shape = input_shape),\n        Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same' ),\n        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same' ),\n        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        \n        Flatten(),\n        \n        Dense(512, activation='relu'),\n        Dropout(0.5),\n        \n        Dense(256, activation='relu'),\n        Dropout(0.5),\n        \n        Dense(64, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation = \"softmax\")\n        \n    ])","e1319fa2":"model = get_modelcnn()\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\nmodel.summary()","61ee15be":"learning_history = model.fit(X_train, y_train,\n          batch_size = 64,\n          epochs = 100,\n          verbose = 1,\n          callbacks = callbacks3,\n          validation_data = (X_test, y_test))","ca49509e":"model = load_model('model.best3.hdf5')","6f12a51f":"score = model.evaluate(X_test, y_test, verbose = 0)\nprint('Test loss: {}%'.format(score[0] * 100))\nprint('Test accuracy: {}%'.format(score[1] * 100))\n\nprint(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))","16cda399":"draw_learning_curve(learning_history)","93e20b21":"datagen = ImageDataGenerator(\n        featurewise_center = False,\n        samplewise_center = False,\n        featurewise_std_normalization = False, \n        samplewise_std_normalization = False,\n        zca_whitening = False,\n        horizontal_flip = False,\n        vertical_flip = False,\n        rotation_range = 10,  \n        zoom_range = 0.1, \n        width_shift_range = 0.1, \n        height_shift_range = 0.1)\n\ndatagen.fit(X_train)\ntrain_gen = datagen.flow(X_train, y_train, batch_size = 32)","913b7f27":"callbacks4 = [ \n    EarlyStopping(monitor = 'loss', patience = 7), \n    ReduceLROnPlateau(monitor = 'loss', patience = 4), \n    ModelCheckpoint('..\/working\/model.best4.hdf5', monitor='loss' , save_best_only=True) # saving the best model\n]","86413644":"def get_modelcnn_v2():\n    return Sequential([\n        Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', input_shape = input_shape),\n        Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.2),\n        \n        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.2),\n        \n        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.2),\n        \n        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.2),\n        \n        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.2),\n        \n        Flatten(),\n       \n        Dense(1024, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.3),\n        \n        Dense(64, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.2),\n        \n        Dense(num_classes, activation = \"softmax\")\n        \n    ])","de199c46":"model = get_modelcnn_v2()\nmodel.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\nmodel.summary()","166bb05f":"learning_history = model.fit_generator((train_gen), \n                               epochs = 100, \n                               steps_per_epoch = X_train.shape[0] \/\/ 32,\n                               validation_data = (X_test, y_test),\n                               callbacks = callbacks4,\n                        )","2075fcbf":"model = load_model('model.best4.hdf5')","a106435a":"score = model.evaluate(X_test, y_test, verbose = 0)\nprint('Test loss: {}%'.format(score[0] * 100))\nprint('Test accuracy: {}%'.format(score[1] * 100))\n\nprint(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))","ebe8494f":"draw_learning_curve(learning_history)","c94ace8d":"y_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis = 1)","400ac9cc":"y_pre_test = np.argmax(y_test, axis = 1)","12c99282":"def show_condition(num):\n    if num == 0:\n        return 'NORMAL'\n    return 'PNEUMONIA'","c668ca8e":"cnt_error = []\nfor idx, (a, b) in enumerate(zip(y_pre_test, y_pred)):\n    if a == b: continue\n    cnt_error.append(a)# test\n\ncnt_error = np.unique(cnt_error, return_counts = True)\nsns.set_style(\"darkgrid\")\nplt.figure(figsize = (15, 7))\nsns.barplot([show_condition(x) for x in cnt_error[0]], cnt_error[1], palette=\"muted\")\nplt.show()","af90abc2":"cnt_ind = 1\nlist_idx = []\nfig = plt.figure(figsize=(14, 14))\nX_test_plot = X_test.reshape(-1, img_size, img_size)\nfor idx, (a, b) in enumerate(zip(y_pre_test, y_pred)):\n    if(cnt_ind > 16):break\n    if a == b: continue\n    plt.subplot(4, 4, cnt_ind)\n    plt.imshow(X_test_plot[idx], cmap='gray', interpolation='none')\n    plt.title('y_true = {0}\\ny_pred = {1}\\n ind = {2}'.format(show_condition(a), show_condition(b), idx))\n    plt.tight_layout()\n    list_idx.append(idx)\n    cnt_ind += 1","562f4a69":"print(classification_report(y_pre_test, y_pred))","04bdb969":"Grayscale conversion, normalization and table reshaping function for MLP","c951ccaa":"![](https:\/\/austingwalters.com\/wp-content\/uploads\/2018\/12\/mlp.png)","5edd3c30":"Fitting the model","b5a1e117":"#### I'm going to make the next notebook soon. ","8b2f475f":"#### Structure","6616208f":"#### Second Model","d58d08e9":"### I recommend running this notebook with a GPU accelerator!","4591c358":"# About Dataset","bfeefe68":"#### First model CNN","0f6b802e":"I'm creating a data frame for visualization","eeecd677":"# Data preprocessing","fb343462":"#### First model","c6ae47c4":"# The Purpose of notebook","c25da356":"# Reading data","26cb8104":"Function to drawing learning curve history learning neural network","31d46f45":"Test dataset contains val and test folders","77dc8644":"#### Fitting the model","00b26363":"I create a data_path to the root folder and path to a specific folder","75e2436c":"![](https:\/\/www.mdpi.com\/diagnostics\/diagnostics-10-00417\/article_deploy\/html\/images\/diagnostics-10-00417-g001.png)","2493adc5":"# MLP ([Multilayer perceptron](https:\/\/en.wikipedia.org\/wiki\/Multilayer_perceptron))","28a0f8c9":"The photos are of high resolution, on average above 1000x1000.\n\nProcessing them is not optimal.\n\nI chose the size 200x200 because the size is not too big and you can see the most important elements on them.","b98087f7":"# Exploratory Data Analysis","198f43de":"<font size=\"5\">\n    <div style=\"text-align: center\"> <b> Author <\/b> <\/div>\n<\/font>\n\n<font size=\"3\">\n    <div style=\"text-align: center\"> J\u0119drzej <\/div>\n    <div style=\"text-align: center\"> Dudzicz <\/div>\n<\/font>","c756c2a9":"Fitting the model","e348e86e":"Function for reading data from folders.\n\nReturns numpy array [img, label]","c8a4a259":"# Data preparing for CNN","0c247e4c":"The model is wrong when the patient has pneumonia and is diagnosed as healthy.\n\nThis is not good, but it occurs in less than 10% of the patients studied. \n\nIt is quite possible that the doctor would not be sure of these cases either. \n\nBy collecting more data from different people in different hospitals, from different parts of the world, we can generalize the data and increase the accuracy of diagnosis. \n\nIn addition, this model can serve as a screening test for patients because, as shown in the graph, when the model recognizes a person with pneumonia is almost certain.","8afcb867":"Let's see where the model was invalid","802e09d9":"# Summary","32647de7":"# CNN ([Convolutional_neural_network](https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network))","3e5d9409":"Function for dividing data into arrays X_ and y_","5f2ccc72":"Evaluation","66d1e28f":"Evaluation","173d3fd9":"### It is important to shuffle the data because it is loaded in batches.","1aba06ee":"It is very similar to first model, I'm changing only weight in dropout and add layer","9e4e7b5d":"This is my second notebook. I would love to know your comments and note about this.\n\nIf you liked it, make sure to vote :)","8b8c0151":"#### Fitting the model","b76f1b67":"### Let's see the images","a722cfae":"I will try to improve the result by expanding the data.\n\n#### Data augmentation:\n* Randomly shift images horizontally by 10% of the width\n\n* Randomly shift images vertically by 10% of the height\n\n* Randomly rotate images by 10 degrees\n\n* Randomly Zoom by 10% some images","6676145e":"# Pneumonia detection on chest X-ray","35a9a664":"We need to rehaspe data again","25819ef9":"* The models have been saved in the output directory, if you don't want to run this notebook, you can download it from there.","de7a5870":"### Achievements in the notebook","5c6832cc":"Evaluation","0394f20d":"Firstly, let's think how the network should look like. It will have three layers:\n\n1. Input Layer\n1. Hidden Layer\n1. Output Layer\n\nInput layer has 200 * 200 pixels reshape to vector\n\nHidden layer has a lot of neurons\n\nOutput layer has 2 neurons: pneumonia \/ normal","891f8c83":"Loading the best model in terms of the loss metric","2ab0524c":"We can see disproportions in the data distribution, but it is similar in the test and training data.","50e534ec":"Split data","b2ebdecd":"Grayscale conversion, normalization and table reshaping function for CNN","98e17b6a":"## Importing libraries","9046f4d4":"Let's show images","6e3c494f":"The dataset contains 5,863 x-rays (JPEG) divided into two categories (pneumonia \/ normal).\n\nThe dataset contains 3 subsets: train, value, test.\nDue to the fact that the validation kit only consists of 16 photos, we will include it in the test kit.\n\nWe will train the model only on the training set.\n\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\u2019s Medical Center, Guangzhou. \n\nAll chest x-rays were taken as part of routine clinical care.","5b228e0d":"#### Second model CNN","0105d227":"#### Technical matters","ea66780f":"Let's see the graph with the error amount for each label.","6bbf4b52":"# Data Augmentation","e7ead3e7":"I will try to maximize the accuracy in recognizing (above 90%) whether a person is healthy or has pneumonia\n\nTo do this, create a pair of neural networks based on the MLP and CNN classes.","8e8372bf":"Simple sequential model is used, starting with 5 double convolutional networks of kernel size **(3, 3)** and max pooling with pool size **(2, 2)**. \n\nAdditionally has batch normalization and dropout","264b86ce":"Evaluation","be5d24d3":"### Callbacks\n* EarlyStopping (Stop training when a monitored metric has stopped improving)\n\n* ReduceLROnPlateau (Reduce learning rate when a metric has stopped improving)\n\n* ModelCheckpoint (Callback to save the Keras model or model weights at some frequency)"}}