{"cell_type":{"2aaf5a3e":"code","3e802888":"code","8445fb07":"code","37bcbc2c":"code","dff9f2c6":"code","0c63d137":"code","571e85ef":"code","02092393":"code","4d91f5b4":"code","c260b2a6":"code","990d71bd":"code","6829379a":"code","fd23d8d2":"code","f8031a51":"code","a6f47a42":"code","d03382ce":"code","bc5393ab":"code","bc03fd69":"code","be18f77a":"code","442b41ea":"code","66933ee4":"code","3942f6a7":"code","bed50596":"code","0c490c83":"markdown","50eb6fc2":"markdown","b0ef7a04":"markdown","2412cb5c":"markdown","46be8168":"markdown","24d375e2":"markdown"},"source":{"2aaf5a3e":"%matplotlib inline\nimport os\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nimport keras\nimport keras.backend as K\nfrom skimage.util.montage import montage2d\ndata_dir = os.path.join('..', 'input')\nnorm_stack = lambda x: np.clip((x-127.0)\/127.0, -1, 1)\ndef norm_stack(x):\n    # calculate statistics on first 20 points\n    mean = np.mean(x[:20])\n    std = np.std(x[:20])\n    return (1.0*x-mean)\/(2*std)","3e802888":"# load the data file and extract dimensions\nwith h5py.File(os.path.join(data_dir,'real_gaze.h5'),'r') as t_file:\n    print(list(t_file.keys()))\n    assert 'image' in t_file, \"Images are missing\"\n    print('Images found:',len(t_file['image']))\n    for _, (ikey, ival) in zip(range(1), t_file['image'].items()):\n        print('image',ikey,'shape:',ival.shape)\n        img_width, img_height = ival.shape\n    real_image_stack = norm_stack(np.expand_dims(np.stack([a for a in t_file['image'].values()],0), -1))\n    print(real_image_stack.shape, 'loaded')\nplt.matshow(montage2d(real_image_stack[0:9, :, :, 0]), cmap = 'gray')","8445fb07":"# load the data file and extract dimensions\nwith h5py.File(os.path.join(data_dir,'gaze.h5'),'r') as t_file:\n    print(list(t_file.keys()))\n    assert 'image' in t_file, \"Images are missing\"\n    assert 'look_vec' in t_file, \"Look vector is missing\"\n    look_vec = t_file['look_vec'].value\n    assert 'path' in t_file, \"Paths are missing\"\n    print('Images found:',len(t_file['image']))\n    for _, (ikey, ival) in zip(range(1), t_file['image'].items()):\n        print('image',ikey,'shape:',ival.shape)\n        img_width, img_height = ival.shape\n    syn_image_stack = norm_stack(np.expand_dims(np.stack([a for a in t_file['image'].values()],0), -1))\n    print(syn_image_stack.shape, 'loaded')\nplt.matshow(montage2d(syn_image_stack[0:9, :, :, 0]), cmap = 'gray')","37bcbc2c":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.hist(syn_image_stack[::10].ravel());\nax1.set_title('Synthetic Data')\nax2.hist(real_image_stack[::10].ravel());\nax2.set_title('Real Data')","dff9f2c6":"from sklearn.model_selection import train_test_split\ntrain_X, test_X = train_test_split(syn_image_stack, \n                                   test_size = 0.25, \n                                   random_state = 2018)\ntrain_Y, test_Y = train_test_split(real_image_stack,\n                                   test_size = 0.25,\n                                   random_state = 2018)\nprint('Fake Images', train_X.shape, test_X.shape, train_X.max(), train_X.min(), train_X.mean(), train_X.std())\nprint('Real Images', train_Y.shape, test_Y.shape, train_Y.max(), train_Y.min(), train_Y.mean(), train_Y.std())","0c63d137":"from keras.layers import Input, concatenate, Conv2D, MaxPool2D, UpSampling2D, Flatten, Dense, Dropout, GaussianNoise, add, ZeroPadding2D, Cropping2D, Conv2DTranspose\nfrom keras import models, layers\nfrom collections import defaultdict\ngauss_noise_level = 1e-3\nleakiness = 0.1\ndef make_gen(depth=16, layer_count=2, use_dilation=False, use_add=False):\n    in_lay = Input(shape = (train_X.shape[1:4]), name = 'Generator_Input')\n    padding_size = ((2, 3), (2,3))\n    padding_size = ((6, 7), (4, 5))\n    gn = ZeroPadding2D(padding_size)(in_lay)\n    gn = GaussianNoise(gauss_noise_level)(gn)\n    \n    c1 = Conv2D(depth, (3,3), padding = 'same')(gn)\n    out_layers = []\n    # dilation\n    if use_dilation:\n        for i in range(layer_count):\n            out_layers += [Conv2D(depth, (3,3), padding = 'same', dilation_rate=(2**i, 2**i))(c1)]\n            out_layers += [Conv2D(depth, (1,3), padding = 'same', dilation_rate=(1, 2**i))(c1)]\n        c2 = concatenate(out_layers)\n    else:\n        layer_db = defaultdict(lambda : [])\n        x = c1\n        layer_db[c1._keras_shape[1:3]] += [c1]\n        for i in range(layer_count):\n            x = Conv2D(depth*2**i, (3,3), padding = 'same', activation='linear')(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.LeakyReLU(leakiness)(x)\n            x = MaxPool2D((2, 2))(x)\n            layer_db[x._keras_shape[1:3]] += [x]\n        for idx, i in enumerate(reversed(range(layer_count))):\n            if idx>0:\n                x = Conv2D(depth*2**i, (1,1), padding = 'same', activation='linear')(x)\n                x = layers.BatchNormalization()(x)\n                x = layers.LeakyReLU(leakiness)(x)\n            x = Conv2DTranspose(depth, (2, 2), strides = (2,2), padding = 'same')(x)\n            x = concatenate([x] + layer_db.get(x._keras_shape[1:3]))\n        c2 = x\n    \n    if use_add:\n        c_out = Conv2D(1, (1,1), padding = 'same', activation = 'tanh')(c2)\n        c_out = add([gn, c_out])\n    else:\n        c_out = Conv2D(1, (1,1), padding = 'same', activation = 'tanh')(c2)\n    c_out = Cropping2D(padding_size)(c_out)\n    return models.Model(inputs = [in_lay], outputs = [c_out], name = 'Generator')\n\ndef make_disc(depth=4, layer_count=3):\n    in_lay = Input(shape = (train_X.shape[1:4]), name = 'Disc_Input')\n    gn = GaussianNoise(gauss_noise_level)(in_lay)\n    x = Conv2D(depth, (3,3), padding = 'valid', activation='linear')(gn)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU(leakiness)(x)\n    for i in range(layer_count):\n        x = Conv2D(depth*2**i, (3,3), strides=(1, 1), padding = 'same', activation='linear')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.LeakyReLU(leakiness)(x)\n        x = Conv2D(depth*2**i, (3,3), strides=(2, 2), padding = 'same', activation='linear')(x)\n        x = layers.LeakyReLU(leakiness)(x)\n    \n    c_out = layers.concatenate([layers.GlobalMaxPool2D()(x), layers.GlobalAvgPool2D()(x)])\n    c_out = Dropout(0.5)(c_out)\n    c_out = Dense(2, activation = 'softmax')(c_out)\n    return models.Model(inputs = [in_lay], outputs = [c_out], name = 'Discriminator')","571e85ef":"simple_gen = make_gen(32, layer_count=3)\nsimple_disc = make_disc(32)\ndef make_full(gen_mod, disc_model):\n    raw_img_in = Input(shape = (train_X.shape[1:4]), name = 'Image_In')\n    ref_img_out = simple_gen(raw_img_in)\n    ref_disc_score = simple_disc(ref_img_out)\n    return models.Model(inputs=[raw_img_in], outputs=[ref_disc_score, ref_img_out])\nfull_gen_model = make_full(simple_gen, simple_disc)","02092393":"from IPython.display import SVG, Image\nfrom keras.utils.vis_utils import model_to_dot\nd = model_to_dot(simple_gen, show_shapes=True)\nd.set_rankdir('UD')\n#SVG(d.create_svg())\nImage(d.create_png())","4d91f5b4":"# show the discriminator\nImage(model_to_dot(simple_disc, show_shapes=True).create_png())","c260b2a6":"from keras.optimizers import Adam\nGLOBAL_LR = 1e-3\ndef compile_generator(lr = 4e-3): \n    simple_disc.trainable = False\n    full_gen_model.compile(optimizer=Adam(lr=lr), \n                           loss = ['categorical_crossentropy', 'mean_absolute_error'], \n                           loss_weights = [1.0, 0.3],\n                           metrics = ['accuracy'])\n\ndef compile_discriminator(lr = 1e-4): \n    simple_disc.trainable = True\n    simple_disc.compile(optimizer=Adam(lr=lr), \n                           loss = 'categorical_crossentropy', \n                           metrics = ['accuracy'])","990d71bd":"compile_generator(GLOBAL_LR)\nassert all([x in simple_gen.trainable_weights \n            for x in full_gen_model.trainable_weights]), \"Only generator should be trainable\"\nfull_gen_model.summary()","6829379a":"compile_discriminator(GLOBAL_LR)\nsimple_disc.summary()","fd23d8d2":"fake_score, fake_images = full_gen_model.predict(train_X[0:2])\nprint(fake_score)\nplt.imshow(fake_images[0, :, :, 0], cmap='gray')","f8031a51":"from keras.preprocessing.image import ImageDataGenerator\ndg_args = dict(featurewise_center = False, \n                  samplewise_center = False,\n                  rotation_range = 5, \n                  width_shift_range = 0.1, \n                  height_shift_range = 0.1, \n                  shear_range = 0.01,\n                  zoom_range = [0.8, 1.2],  \n                  horizontal_flip = True, \n                  vertical_flip = False,\n                  fill_mode = 'reflect',\n               data_format = 'channels_last')\n\nimage_gen = ImageDataGenerator(**dg_args)\ndef make_train_gen_batch(in_X, batch_size = 512):\n    # improve generator\n    for x in image_gen.flow(in_X, batch_size=batch_size):\n        out_vec = np.zeros((x.shape[0], 2))\n        out_vec[:, 1] = 1.0\n        yield x, [out_vec, x]","a6f47a42":"gen_train = make_train_gen_batch(train_X)\ngen_valid = make_train_gen_batch(test_X)\na, (b, c) = next(gen_train)\nprint(a.shape, b.shape, c.shape)\nfig, (ax1) = plt.subplots(1, 1, figsize = (20, 10))\nax1.imshow(montage2d(a[:, :, :, 0]), cmap = 'bone')\nax1.set_title('Synth Images')","d03382ce":"def show_status(seed = None, img_cnt = 9):\n    if seed is not None:\n        np.random.seed(seed)\n    syn_block = np.random.permutation(syn_image_stack)[0:img_cnt]\n    real_block = np.random.permutation(real_image_stack)[0:img_cnt]\n    bins = np.linspace(-1, 1, 30)\n    fig, ((ax1, ax2, ax3), (ax1h, ax2h, ax3h))  = plt.subplots(2, 3, figsize = (24, 12))\n    ax1.imshow(montage2d(syn_block[:, :, :, 0]), cmap = 'gray')\n    ax1h.hist(syn_block[:, :, :, 0].flatten(), bins)\n    ax1.set_title('Simulated Images\\nReal: %2.2f%%' % (np.mean(simple_disc.predict(syn_block)[:, 1])*100))\n    gen_stack = simple_gen.predict(syn_block)\n    ax2.imshow(montage2d(gen_stack[: , :, :, 0]), cmap = 'gray')\n    ax2h.hist(gen_stack[:, :, :, 0].flatten(), bins)\n    ax2.set_title('Generated Images\\nReal: %2.2f%%' % (np.mean(simple_disc.predict(gen_stack)[:, 1])*100))\n    realness = np.mean(simple_disc.predict(syn_block)[:, 1])\n    ax3.imshow(montage2d(real_block[:, :, :, 0]), cmap = 'gray')\n    ax3h.hist(real_block[:, :, :, 0].flatten(), bins)\n    ax3.set_title('Real Images\\nReal: %2.2f%%' % (np.mean(simple_disc.predict(real_block)[:, 1])*100))\n    return fig\nshow_status();","bc5393ab":"def make_train_disc_batch(in_fake, in_real, batch_size = 256, refine_images=True):\n    \"\"\"we create batches consisting of a 50\/50 split between\n    fake and real images. The fake images are processed using the refiner (refine_images=True), but\n    in future we plan to provide fake images from many different generations of\n    the generator model to 'stabilize training'  \"\"\"\n    while True:\n        real_img = image_gen.flow(in_real, batch_size=batch_size)\n        fake_img = image_gen.flow(in_fake, batch_size=batch_size)\n        for (c_real, c_fake) in zip(real_img, fake_img):\n            real_cat = np.zeros((c_real.shape[0], 2))\n            real_cat[:, 1] = 1.0 # real\n            refined_cat = np.zeros((c_fake.shape[0], 2))\n            refined_cat[:, 0] = 1.0 # learn that they are fake\n\n            if refine_images:\n                c_refined = simple_gen.predict(c_fake)\n            else:\n                c_fake = c_fake\n            yield np.concatenate([c_real, c_refined], 0), np.concatenate([real_cat, refined_cat])\ndisc_train = make_train_disc_batch(train_X, train_Y)\ndisc_valid = make_train_disc_batch(test_X, test_Y)","bc03fd69":"compile_discriminator(GLOBAL_LR)\nprint('Improving Discriminator')\nsimple_disc.fit_generator(disc_train, steps_per_epoch=100)","be18f77a":"compile_generator(GLOBAL_LR)\nprint('Improving Generator')\nfull_gen_model.fit_generator(gen_train,\n                             steps_per_epoch=200)","442b41ea":"show_status(2002, 25).savefig('pretraining_image_gen.png', dpi = 300)","66933ee4":"from IPython.display import clear_output, display\nt_steps = 200\nv_steps = 0\nepochs = 20\nfrom keras.callbacks import EarlyStopping\nes_callback = lambda : EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)\nfor i in range(epochs):\n    cur_lr = GLOBAL_LR*(0.8**(i))\n    print('Improving Generator ({:2.2g})'.format(cur_lr))\n    compile_generator(cur_lr)\n    if v_steps>0:\n        v_args = dict(validation_data=gen_valid, validation_steps=v_steps)\n    else:\n        v_args = {}\n    full_gen_model.fit_generator(gen_train, steps_per_epoch=t_steps,**v_args)\n    \n    plt.close('all')\n    clear_output()\n    display(show_status(2018, 4))\n    \n    # we might be required to precompute images at some point here\n    disc_train = make_train_disc_batch(train_X, train_Y)\n    disc_valid = make_train_disc_batch(test_X, test_Y)\n    compile_discriminator(cur_lr)\n    print('Improving Discriminator')\n    if v_steps>0:\n        v_args = dict(validation_data=disc_valid, validation_steps=v_steps)\n    else:\n        v_args = {}\n    simple_disc.fit_generator(disc_train, steps_per_epoch=t_steps, **v_args)\n    display(show_status(2018, 4))","3942f6a7":"show_status(2002, 25).savefig('image_gen.png', dpi = 300)","bed50596":"show_status(2003, 25);","0c490c83":"# Prepare Training Data","50eb6fc2":"# Big Training\nHere we run a number of loops \n- improve the generator\n- improve the discriminator\n- decrease the learning rate of both\n- show results on fixed images\n- repeat","b0ef7a04":"# Load Real Data","2412cb5c":"# Overview\nThe notebook implements a simpler version of the model discussed in [Learning from Simulated and Unsupervised Images through Adversarial Training](https:\/\/arxiv.org\/abs\/1612.07828). \n### The initial focus is to \n- load the datasets correctly\n- create the refiner and discriminator models\n- use data augmentation on the real and fake images\n- train for a few epochs\n- use the simpler training approach\n\n### Training\n- Unity Images - $x$\n- Real images $y$\n- Refiner Model $\\mathcal{R}$\n- Discriminator Model $\\mathcal{D}$\n### Training Loop (one epoch)\n1. Improve Generator: minimize $-\\log(\\mathcal{D}(\\mathcal{R}(x)))+||\\mathcal{R}(x)-x||_1$ by updating parameters in $\\mathcal{R}$\n1. Improve Discriminator: maximize $-\\log(\\mathcal{D}(y)+\\log(1-\\mathcal{D}(\\mathcal{R}(x)))$ by updating parameters in $\\mathcal{D}$","46be8168":"# Build Models","24d375e2":"# Load Synthetic Data\nGenerated using Unity and UnityEyes Tools"}}