{"cell_type":{"ead131f7":"code","26902bb6":"code","b764f12e":"code","1a7ca93f":"code","760cfe86":"code","7a597e05":"code","f082e3f2":"code","329b0e24":"code","398beabe":"code","137436b6":"code","dcee8c14":"code","e9eb69b3":"code","cf47ba45":"code","d7de4e70":"code","5de22f83":"code","5c7111f4":"code","ac68a6d4":"code","9b4d9e10":"code","b9ce2cd9":"code","7b2f0578":"code","e09cf80d":"code","c67da14f":"code","f1a0427a":"code","3da180e8":"code","240d9658":"code","7a8bb0ef":"code","792b93d5":"code","fe7c6b55":"code","f61275ff":"code","16156c2b":"code","cd69e570":"code","b0bee033":"code","1a52c959":"markdown","28d05139":"markdown","8b54a0d7":"markdown","658181a6":"markdown","702c20c7":"markdown","31024e49":"markdown","4fc7fbe2":"markdown","37d1634c":"markdown","4380d18a":"markdown","8fbc28a8":"markdown","0eaacd5d":"markdown","4de448be":"markdown"},"source":{"ead131f7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom tensorflow import keras\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import LeakyReLU, ReLU\nfrom tensorflow.keras import models\nfrom tensorflow.keras.layers import BatchNormalization, Dropout\nfrom tensorflow.keras.optimizers import Adam, Adagrad, RMSprop, SGD\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D","26902bb6":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","b764f12e":"Y_train = train[\"label\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\n# free some space\ndel train \n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()","1a7ca93f":"X_train.isnull().any().describe()","760cfe86":"test.isnull().any().describe()","7a597e05":"X_train = X_train \/ 255.0\ntest = test \/ 255.0","f082e3f2":"X_train_r = X_train.values.reshape(-1,28,28,1)\ntest_r = test.values.reshape(-1,28,28,1)","329b0e24":"X_train = X_train.values\nY_train = Y_train.values\ntest = test.values","398beabe":"Y_train_keras = tf.keras.utils.to_categorical(Y_train, num_classes = 10)","137436b6":"# This data will be used for deep learning.\nX_train_keras, X_val_keras, Y_train_keras, Y_val_keras = train_test_split(X_train_r, Y_train_keras, test_size = 0.1, random_state=0)","dcee8c14":"# This data is used for random forests, etc.\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=0)","e9eb69b3":"plt.imshow(X_train_keras[2])","cf47ba45":"# model = models.Sequential()\n\n# model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n#                  activation ='relu', input_shape = (28,28,1)))\n# model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n#                  activation ='relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n\n# model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n#                  activation ='relu'))\n# model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n#                  activation ='relu'))\n# model.add(MaxPool2D(pool_size=(2,2)))\n\n# model.add(Flatten())\n# model.add(Dense(512, activation = \"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dense(256, activation = \"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.1))\n# model.add(Dense(10, activation = \"softmax\"))","d7de4e70":"# I referred to the model below\u3000\u3000\uff1a\u3000\u3000https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\n\nmodel = models.Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","5de22f83":"# Define the optimizer\noptimizer = Adam(lr=0.001)","5c7111f4":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","ac68a6d4":"model.summary()","9b4d9e10":"tf.random.set_seed(0)\n\nhistory = model.fit(X_train_keras,\n                    Y_train_keras,\n                    epochs=10,\n                    batch_size=128,\n                    validation_data=(X_val_keras, Y_val_keras),\n                   )","b9ce2cd9":"def plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.plot(hist['epoch'], hist['accuracy'],\n           label='Train Accuracy')\n  plt.plot(hist['epoch'], hist['val_accuracy'],\n           label = 'Val Accuracy')\n  plt.ylim([0.7,1.0])\n  plt.legend()\n  plt.show()\n    \n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.plot(hist['epoch'], hist['loss'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_loss'],\n           label = 'Val Error')\n  plt.ylim([0.0,0.3])\n  plt.legend()\n  plt.show()\n\n\nplot_history(history)","7b2f0578":"pred = model.predict_classes(test_r)","e09cf80d":"submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")","c67da14f":"submission[\"Label\"] = pred","f1a0427a":"submission.to_csv(\"submission_keras.csv\",index=False)","3da180e8":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import accuracy_score","240d9658":"rf = RandomForestClassifier(min_samples_leaf = 2, n_estimators = 1000, random_state = 0, verbose = 1)","7a8bb0ef":"rf.fit(X_train, Y_train)","792b93d5":"rf_pred = rf.predict(X_val)","fe7c6b55":"print('RandomForest : ' + str(accuracy_score(rf_pred, Y_val)))","f61275ff":"pred_rf = rf.predict(test)","16156c2b":"submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")","cd69e570":"submission[\"Label\"] = pred_rf","b0bee033":"submission.to_csv(\"submission_rf.csv\",index=False)","1a52c959":"# Normalization","28d05139":"# Predict_Keras","8b54a0d7":" ### RandomForest : accuracy 96%","658181a6":"# Data preparation","702c20c7":"# Reshape","31024e49":"# Predict_RandomForest","4fc7fbe2":"# Deep Learning by Tensorflow(Keras)","37d1634c":"# To NumPy","4380d18a":"# To Categorical","8fbc28a8":"# Random Forest","0eaacd5d":"# Split training and valdiation","4de448be":"# Check for null and missing values"}}