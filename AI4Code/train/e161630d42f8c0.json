{"cell_type":{"a81342c8":"code","fc320f21":"code","b03428cd":"code","ec21e82d":"code","3a642bbc":"code","8507c9d1":"code","b82ffb64":"code","3603be02":"code","69e01e4d":"code","97d85c54":"code","f38578f5":"code","f5bddbc7":"code","fc026f42":"code","3f58d4ec":"code","58f7c962":"code","3ae843ff":"code","69d8dc1f":"code","324e4dc1":"code","5b443674":"code","7c6c808a":"code","fadbd884":"code","5f3692da":"code","12d91995":"code","b2d5450d":"code","2863ab8c":"code","18159ad8":"code","fdc1c7ee":"markdown","dc70805c":"markdown","ba194dfd":"markdown","5b25e58b":"markdown","61f7a954":"markdown","2d2a59a7":"markdown","9ee0f850":"markdown","1b6cee50":"markdown","25bd2cc1":"markdown","d3cb5530":"markdown","7d33565c":"markdown","2a782ffa":"markdown","bba8b512":"markdown","04297a9f":"markdown","de7a99f8":"markdown","c4cea7d1":"markdown"},"source":{"a81342c8":"# import packages\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import skew\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import Ridge,RidgeCV, Lasso, ElasticNet, LassoCV, LassoLarsCV, ElasticNetCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# define plot styles\nplt.style.use(['dark_background'])\nparams = {'legend.fontsize': 'x-large',\n        'figure.figsize': (15, 5),\n        'axes.labelsize': 'small',\n        'axes.titlesize':'small',\n        'xtick.labelsize':'small',\n        'ytick.labelsize':'small'}\nplt.rcParams.update(params)","fc320f21":"# read train and test data\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","b03428cd":"train_shape = train.shape\ntest_shape = test.shape\nprint(f\"Train data: rows {train_shape[0]} | columns {train_shape[1]}\")\nprint(f\"Test data: rows {test_shape[0]} | columns {test_shape[1]}\")","ec21e82d":"diff_columns = [col for col in train.columns if col not in test.columns]\ninters_columns = [col for col in train.columns if col in test.columns]\nprint(f\"Differents columns between train and test ({len(diff_columns)}) {diff_columns}\", end=\"\\n\"*2)\nprint(f\"Intersect columns between train and test ({len(inters_columns)}) {inters_columns}\")","3a642bbc":"# transform data type of MSSubClass, YrSold and MoSold to object in train and test\n\ntrain['MSSubClass'] = train['MSSubClass'].apply(str)\ntrain['YrSold'] = train['YrSold'].astype(str)\ntrain['MoSold'] = train['MoSold'].astype(str)\ntrain['GarageYrBlt'] = train['GarageYrBlt'].astype(str)\n\n\ntest['MSSubClass'] = test['MSSubClass'].apply(str)\ntest['YrSold'] = test['YrSold'].astype(str)\ntest['MoSold'] = test['MoSold'].astype(str)\ntest['GarageYrBlt'] = test['GarageYrBlt'].astype(str)","8507c9d1":"# remove outliers with percentile technique\ndef outliers_box_plot(data):\n    q1, q3= np.percentile(data,[25,75])\n    iqr = q3 - q1\n    lower_bound = q1 -(1.5 * iqr) \n    upper_bound = q3 +(1.5 * iqr) \n    return lower_bound, upper_bound","b82ffb64":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nax = sns.boxplot(x=\"OverallQual\", y=\"SalePrice\", data=train);\nax = sns.swarmplot(x=\"OverallQual\", y=\"SalePrice\", data=train, color=\".15\")\n\n\n# remove outliers in SalePrice for each group conditioned on OverallQual\ndrop_index = []\nfor g in train.groupby(\"OverallQual\")[\"SalePrice\"]:\n    serie_group = g[1]\n    l,u = outliers_box_plot(serie_group)\n    if len(serie_group)>10: # arbitrarily defined        \n        drop_index = drop_index + (serie_group[(serie_group<l) |( serie_group>u)].index.values.tolist())\n\nprint(f\"Eliminated outlier rows: {len(drop_index)}\")\ntrain.drop(drop_index,inplace=True)\n\n\nplt.subplot(1,2,2)\nax = sns.boxplot(x=\"OverallQual\", y=\"SalePrice\", data=train);\nax = sns.swarmplot(x=\"OverallQual\", y=\"SalePrice\", data=train, color=\".15\")","3603be02":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nax = sns.boxplot(x=\"MSZoning\", y=\"SalePrice\", data=train);\nax = sns.swarmplot(x=\"MSZoning\", y=\"SalePrice\", data=train, color=\".15\")\n\n\n# remove outliers in SalePrice for each group conditioned on OverallQual\ndrop_index = []\nfor g in train.groupby(\"MSZoning\")[\"SalePrice\"]:\n    serie_group = g[1]\n    l,u = outliers_box_plot(serie_group)\n    if len(serie_group)>10: # arbitrarily defined        \n        drop_index = drop_index + (serie_group[(serie_group<l) |( serie_group>u)].index.values.tolist())\n\nprint(f\"Eliminated outlier rows: {len(drop_index)}\")\ntrain.drop(drop_index,inplace=True)\n\n\nplt.subplot(1,2,2)\nax = sns.boxplot(x=\"MSZoning\", y=\"SalePrice\", data=train);\nax = sns.swarmplot(x=\"MSZoning\", y=\"SalePrice\", data=train, color=\".15\")","69e01e4d":"# remove outliers with Density technique\ndef dbscan_outliers(var1,var2,dbscan_eps,dbscan_minsample,get_cluster_num):\n    plt.figure(figsize=(8,8))\n    scaler = RobustScaler()\n    scale_var1 = scaler.fit_transform(pd.DataFrame((train[var1]))).reshape(1,-1)[0]\n    scale_var2 = scaler.fit_transform(pd.DataFrame((train[var2]))).reshape(1,-1)[0]\n    df_temp = pd.DataFrame({\"var1\":scale_var1 , \"var2\":scale_var2})\n    clustering = DBSCAN(eps=dbscan_eps, min_samples=dbscan_minsample).fit(df_temp.values) # parameters iteratively defined \n    df_temp[\"c\"] = clustering.labels_\n    df_temp.index = train.index\n    sns.scatterplot(scale_var1,scale_var2, hue=clustering.labels_)\n    return df_temp[df_temp[\"c\"]==get_cluster_num].index\n    ","97d85c54":"dropindex = dbscan_outliers(\"GrLivArea\",\"SalePrice\",dbscan_eps=.7,dbscan_minsample=10,get_cluster_num=-1)\nprint(f\"Outliers droped {len(dropindex)}\")\ntrain.drop(dropindex,inplace=True)","f38578f5":"# get quantitative and qualitative columns\n\nquantitative_cols = [col for col in train.columns if train.dtypes[col] != 'object']\n\n# remove SalePrice and Id from quantitative columns\nquantitative_cols.remove('SalePrice')\nquantitative_cols.remove('Id')\nqualitative_cols = [col for col in train.columns if train.dtypes[col] == 'object']\n\nprint(f\"Quantitative columns ({len(quantitative_cols)}): {quantitative_cols}\", end=\"\\n\"*2)\nprint(f\"Quanlitative columns ({len(qualitative_cols)}): {qualitative_cols}\")\n","f5bddbc7":"# concat train and test for preprocessing\nall_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n                      test.loc[:,'MSSubClass':'SaleCondition']))\n\n\n","fc026f42":"# get percent of missing values by columns\nmissing_serie = all_data.isna().sum().sort_values(ascending=False)\n\nmissing_serie[missing_serie>0].plot.bar(rot=90);\nprint(\"Missing percent\")\nprint(missing_serie[missing_serie>0]\/all_data.shape[0])","3f58d4ec":"# case when null represent \"No prescence\" according to data description\nall_data[\"PoolQC\"].fillna(\"NoPool\", inplace=True)\nall_data[\"MiscFeature\"].fillna(\"NOMiscFeature\", inplace=True)\nall_data[\"Alley\"].fillna(\"NOAlley\", inplace=True)\nall_data[\"Fence\"].fillna(\"NOFence\", inplace=True)\nall_data[\"FireplaceQu\"].fillna(\"NOFireplaceQu\", inplace=True)\nall_data[\"GarageCond\"].fillna(\"NOGarageCond\", inplace=True) \nall_data[\"GarageQual\"].fillna(\"NOGarageQual\", inplace=True)\nall_data[\"GarageYrBlt\"].fillna(\"NOGarageYrBlt\", inplace=True)\nall_data[\"GarageFinish\"].fillna(\"NOGarageFinish\", inplace=True)\nall_data[\"GarageType\"].fillna(\"NOGarageType\", inplace=True)\nall_data[\"BsmtCond\"].fillna(\"NOBsmtCond\", inplace=True)\nall_data[\"BsmtExposure\"].fillna(\"NOBsmtExposure\", inplace=True)\nall_data[\"BsmtQual\"].fillna(\"NOBsmtQual\", inplace=True)\nall_data[\"BsmtFinType2\"].fillna(\"NOBsmtFinType2\", inplace=True)\nall_data[\"BsmtFinType1\"].fillna(\"NOBsmtFinType1\", inplace=True)\n\n\n# Imputed with mean in numerical variables or mode (by neighborhood) in categorical\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\nall_data[\"BsmtFinSF2\"] = all_data.groupby(\"Neighborhood\")[\"BsmtFinSF2\"].transform(lambda x: x.fillna(x.median()))\nall_data[\"BsmtFinSF1\"] = all_data.groupby(\"Neighborhood\")[\"BsmtFinSF1\"].transform(lambda x: x.fillna(x.median()))\nall_data[\"MasVnrType\"] = all_data.groupby(\"Neighborhood\")[\"MasVnrType\"].transform(lambda x: x.fillna(x.mode().values[0]))\nall_data[\"MasVnrArea\"] = all_data.groupby(\"Neighborhood\")[\"MasVnrArea\"].transform(lambda x: x.fillna(x.mean()))\nall_data[\"MSZoning\"] = all_data.groupby(\"Neighborhood\")[\"MSZoning\"].transform(lambda x: x.fillna(x.mode().values[0]))\nall_data[\"Exterior2nd\"] = all_data.groupby(\"Neighborhood\")[\"Exterior2nd\"].transform(lambda x: x.fillna(x.mode().values[0]))\nall_data[\"BsmtUnfSF\"] = all_data.groupby(\"Neighborhood\")[\"BsmtUnfSF\"].transform(lambda x: x.fillna(x.median()))\nall_data[\"TotalBsmtSF\"] = all_data.groupby(\"Neighborhood\")[\"TotalBsmtSF\"].transform(lambda x: x.fillna(x.median()))\nall_data[\"Exterior1st\"] = all_data.groupby(\"Neighborhood\")[\"Exterior1st\"].transform(lambda x: x.fillna(x.mode().values[0]))\nall_data[\"SaleType\"] = all_data.groupby(\"Neighborhood\")[\"SaleType\"].transform(lambda x: x.fillna(x.mode().values[0]))\nall_data[\"Electrical\"] = all_data.groupby(\"Neighborhood\")[\"Electrical\"].transform(lambda x: x.fillna(x.mode().values[0]))\nall_data[\"KitchenQual\"] = all_data.groupby(\"Neighborhood\")[\"KitchenQual\"].transform(lambda x: x.fillna(x.mode().values[0]))\nall_data[\"GarageArea\"] = all_data.groupby(\"Neighborhood\")[\"GarageArea\"].transform(lambda x: x.fillna(x.median()))\nall_data[\"GarageCars\"] = all_data.groupby(\"Neighborhood\")[\"GarageCars\"].transform(lambda x: x.fillna(x.mode().values[0]))\n\n\n# according to data description\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\nall_data[\"BsmtHalfBath\"].fillna(0, inplace=True)\nall_data[\"BsmtFullBath\"].fillna(0, inplace=True)\n\n\nall_data = all_data.drop(['Utilities'], axis=1) # no relevant according to value_counts\n","58f7c962":"# apply logtransform to SalePrice\nprint(\"Skew before log transform:\",train[\"SalePrice\"].skew())\nplt.subplot(1,2,1)\nplt.title(\"SalePrice\")\nsns.distplot(train[\"SalePrice\"])\nplt.subplot(1,2,2)\nplt.title(\"SalePrice Log\")\nsns.distplot(np.log1p(train[\"SalePrice\"]));\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\nprint(\"Skew after log transform:\",train[\"SalePrice\"].skew())","3ae843ff":"# apply boxcox1p_transform in columns with abs(skew) >.7\n\nskewed_cols = all_data[quantitative_cols].apply(lambda x: abs(skew(x.dropna())))\nboxcox_transf_cols = skewed_cols[skewed_cols > 0.7].index\n\nfor col_box in boxcox_transf_cols:\n    plt.subplot(1,2,1)\n    plt.title(col_box)\n    sns.distplot(all_data[col_box].dropna(), kde=False, axlabel=col_box)\n    plt.subplot(1,2,2)\n    plt.title(col_box + \"_boxcox1p\")\n    sns.distplot(boxcox1p(all_data[col_box].dropna(), boxcox_normmax(all_data[col_box].dropna() + 1)), kde=False, axlabel= col_box+\"_boxcox1p\")\n    all_data[col_box] = boxcox1p(all_data[col_box].dropna(), boxcox_normmax(all_data[col_box].dropna() + 1))\n    plt.show()\n    ","69d8dc1f":"# generate dummies\nall_data = pd.get_dummies(all_data)","324e4dc1":"# regenerate train\/test data\nX_train = all_data[:train.shape[0]]\nX_test = all_data[train.shape[0]:]\ny = train.SalePrice","5b443674":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\n","7c6c808a":"# Setup cross validation folds\nkf = KFold(n_splits=12, random_state=42, shuffle=True)\n\n# ridge alphas\nridge_alphas = [1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\nparam_grid = {'model__alpha':ridge_alphas}\n\n# define pipeline model\nridge = Pipeline(steps=[('standardscaler', RobustScaler()),\n                        ('model', Ridge(max_iter=1e7))])\n\n\nsearch_ridge = GridSearchCV(ridge, param_grid,cv=kf,scoring=\"neg_mean_squared_error\")\nsearch_ridge.fit(X_train, y)\n\n# get score of best estimator\nnp.sqrt(search_ridge.best_score_*-1)","fadbd884":"cv_result = pd.DataFrame(search_ridge.cv_results_[\"params\"])\ncv_result[\"score\"] = np.sqrt(search_ridge.cv_results_[\"mean_test_score\"]*-1)\ncv_result.plot(x=\"model__alpha\",y=\"score\");","5f3692da":"alphas = np.array([ 0.01,0.005,0.001,0.0001,0.00001])\n\nparam_grid = {'model__alpha':alphas}\n\nlasso = Pipeline(steps=[('standardscaler', RobustScaler()),\n                    ('model', Lasso(max_iter=1e5))])\n\n\nsearch_lasso = GridSearchCV(lasso, param_grid,cv=10,scoring=\"neg_mean_squared_error\")\nsearch_lasso.fit(X_train, y)\nnp.sqrt(search_lasso.best_score_*-1)","12d91995":"cv_result = pd.DataFrame(search_lasso.cv_results_[\"params\"])\ncv_result[\"score\"] = np.sqrt(search_lasso.cv_results_[\"mean_test_score\"]*-1)\ncv_result.plot(x=\"model__alpha\",y=\"score\")","b2d5450d":"lasso_coef = pd.DataFrame(search_lasso.best_estimator_[\"model\"].coef_,columns=[\"coef\"])\nlasso_coef[\"col\"] = X_train.columns","2863ab8c":"coef_0 = (lasso_coef[\"coef\"]==0).value_counts().get(True)\nprint(f\"Lasso (coef==0) = {coef_0}\")\nlasso_coef[abs(lasso_coef[\"coef\"])>0].sort_values(by=\"coef\").plot(kind=\"bar\",x=\"col\",rot=80)","18159ad8":"pred = search_lasso.best_estimator_.predict(X_test)\ndf_result = pd.DataFrame(np.expm1(pred),columns=[\"SalePrice\"])\ndf_result[\"Id\"] = test.Id\ndf_result.to_csv(\"submit.csv\",index=False)\n","fdc1c7ee":"### 1. Ridge","dc70805c":"##### **GrLivArea**","ba194dfd":"### 3.  Transform datatype columns","5b25e58b":"##### **OverallQual**","61f7a954":"### Submit file","2d2a59a7":" ### 4.  Remove Outliers","9ee0f850":"Remove ouliers in the three most important columns, OverallQual, MSZoning and GrLivArea, according to Lasso model shown below. \nThis process can be applied to the rest of the columns but I decided for now to work only with the three most relevant according to Lasso.","1b6cee50":"### 2. Lasso","25bd2cc1":"##### ***MSZoning***","d3cb5530":"## Modeling","7d33565c":"#### Transform data","2a782ffa":"## Data Preparation with Python","bba8b512":"### 2. Read csv train\/test","04297a9f":"##### Imputed missing values","de7a99f8":"### 1. Import packages and define plot styles","c4cea7d1":"### 5. Missing Values"}}