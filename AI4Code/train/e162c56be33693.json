{"cell_type":{"7adcbe6b":"code","2effb410":"code","37de52b9":"code","8849d032":"code","c29102a9":"code","b32c3549":"code","d13a43c0":"code","99c95a24":"code","a2a9b417":"code","d32688c3":"code","f8311dad":"code","7ec60c78":"code","61c8a35f":"code","b4ce00f6":"code","19584c22":"code","ad3b2597":"code","1dd92e56":"code","b28d5092":"code","90e7e6bf":"code","007fd04f":"code","43f31707":"code","511a17cb":"markdown","e8ebc242":"markdown","7aeff3d1":"markdown","630ec27e":"markdown","6b07b1bb":"markdown","ecc0fe16":"markdown","37f695bd":"markdown","39410e1f":"markdown"},"source":{"7adcbe6b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2effb410":"import pandas as pd\ncreditcard = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\",index_col=0)","37de52b9":"\n# summarize the shape of the dataset\nprint(creditcard.shape)","8849d032":"from collections import Counter\n# summarize the class distribution\ntarget = creditcard.values[:,-1]\ncounter = Counter(target)\nfor k,v in counter.items():\n    per = v \/ len(target) * 100\n    print('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))","c29102a9":"creditcard.head()","b32c3549":"creditcard['Amount'].describe()","d13a43c0":"from matplotlib import pyplot\n# drop the target variable\ndf = creditcard.drop('Class', axis=1)\n# create a histogram plot of each numeric variable\nax = df.hist(bins=100)\n# disable axis labels to avoid the clutter\nfor axis in ax.flatten():\n    axis.set_xticklabels([])\n    axis.set_yticklabels([])\n# show the plot\npyplot.show()","99c95a24":"#get correlations of each features in dataset\ncorrmat = df.corr()\ntop_corr_features = corrmat.index\n","a2a9b417":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(15,15))\n#plot heat map\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n","d32688c3":"# load the dataset\ndef load_dataset(full_path):\n    # load the dataset as a numpy array\n    data = pd.read_csv(full_path,index_col=0,low_memory=False)\n    # retrieve numpy array\n    data = data.values\n    # split into input and output elements\n    X, y = data[:, :-1], data[:, -1]\n    return X, y\n ","f8311dad":"from numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import make_scorer\nfrom sklearn.dummy import DummyClassifier\n\n# calculate precision-recall area under curve\ndef pr_auc(y_true, probas_pred):\n    # calculate precision-recall curve\n    p, r, _ = precision_recall_curve(y_true, probas_pred)\n    # calculate area under curve\n    return auc(r, p)","7ec60c78":"# evaluate a model\ndef evaluate_model(X, y, model):\n    # define evaluation procedure\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    # define the model evaluation the metric\n    metric = make_scorer(pr_auc, needs_proba=True)\n    # evaluate model\n    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    return scores","61c8a35f":"\n# define the reference model\nmodel = DummyClassifier(strategy='constant', constant=1)","b4ce00f6":"# define the location of the dataset\nfull_path = \"..\/input\/creditcardfraud\/creditcard.csv\"\n# load the dataset\nX, y = load_dataset(full_path)","19584c22":"print(X)","ad3b2597":"print(y)","1dd92e56":"# evaluate the model\nscores = evaluate_model(X, y, model)\n","b28d5092":"# summarize performance\nprint('Mean PR AUC: %.3f (%.3f)' % (mean(scores), std(scores)))","90e7e6bf":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import make_scorer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\n# define models to test\ndef get_models():\n    models, names = list(), list()\n    # CART\n    models.append(DecisionTreeClassifier())\n    names.append('CART')\n    # KNN\n    steps = [('s',StandardScaler()),('m',KNeighborsClassifier())]\n    models.append(Pipeline(steps=steps))\n    names.append('KNN')\n    # Bagging\n    models.append(BaggingClassifier(n_estimators=100))\n    names.append('BAG')\n    # RF\n    models.append(RandomForestClassifier(n_estimators=100))\n    names.append('RF')\n    # ET\n    models.append(ExtraTreesClassifier(n_estimators=100))\n    names.append('ET')\n    return models, names","007fd04f":"# define models\nmodels, names = get_models()\nresults = list()\n# evaluate each model\nfor i in range(len(models)):\n    # evaluate the model and store results\n    scores = evaluate_model(X, y, models[i])\n    results.append(scores)\n    # summarize performance\n    print('>%s %.3f (%.3f)' % (names[i], mean(scores), std(scores)))","43f31707":"pyplot.boxplot(results, labels=names, showmeans=True)\npyplot.show()","511a17cb":"## Model Test and Baseline Result","e8ebc242":"## Exploratory Data Analysis","7aeff3d1":"## Evaluate Machine Learning Algorithms","630ec27e":"Some publications use the ROC area under curve metric, although the website for the dataset recommends using the precision-recall area under curve metric, given the severe class imbalance.\n\nGiven the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC).","6b07b1bb":"> ## References\n\nhttps:\/\/machinelearningmastery.com\/imbalanced-classification-with-the-fraudulent-credit-card-transactions-dataset\/\n\n","ecc0fe16":"## Note\n### Your participation in discussion, and UPVOTES would be highly appreciated","37f695bd":"## Correlations between Features and Target","39410e1f":"## Introduction\n\nThe data represents credit card transactions that occurred over two days in September 2013 by European cardholders.\n\nThe dataset is credited to the Machine Learning Group at the Free University of Brussels (Universit\u00e9 Libre de Bruxelles) and a suite of publications by Andrea Dal Pozzolo, et al.\n\nAll details of the cardholders have been anonymized via a principal component analysis (PCA) transform. Instead, a total of 28 principal components of these anonymized features is provided. In addition, the time in seconds between transactions is provided, as is the purchase amount (presumably in Euros).\n\nEach record is classified as normal (class \u201c0\u201d) or fraudulent (class \u201c1\u201d ) and the transactions are heavily skewed towards normal. Specifically, there are 492 fraudulent credit card transactions out of a total of 284,807 transactions, which is a total of about 0.172% of all transactions."}}