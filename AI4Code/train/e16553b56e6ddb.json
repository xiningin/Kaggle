{"cell_type":{"6e398f8c":"code","001d47ed":"code","09609f88":"code","060006a1":"code","98f5d062":"code","b646dc18":"code","0ae70422":"code","693e899b":"code","b3001265":"code","6506aa48":"markdown","1de8d46c":"markdown"},"source":{"6e398f8c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.","001d47ed":"# load data set\nx_l = np.load('..\/input\/Sign-language-digits-dataset\/X.npy')\nY_l = np.load('..\/input\/Sign-language-digits-dataset\/Y.npy')\nimg_size = 64\nplt.subplot(1, 2, 1)\nplt.imshow(x_l[260].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(x_l[900].reshape(img_size, img_size))\nplt.axis('off')","09609f88":"# splitting tool for the validation set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_l,Y_l,test_size=0.2,random_state=42)\n#reshape\nx_train = x_train.reshape(-1,64,64,1)\nx_test = x_test.reshape(-1,64,64,1)","060006a1":"print(\"x train shape :\",x_train.shape)\nprint(\"y train shape :\",y_train.shape)\nprint(\"x test shape :\",x_test.shape)\nprint(\"y test shape :\",y_test.shape)","98f5d062":"# \nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel=Sequential()\nmodel.add(Conv2D(filters=16,kernel_size=(5,5),activation=\"relu\",padding=\"same\",input_shape=(64,64,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n#\nmodel.add(Conv2D(filters=8,kernel_size=(4,4),activation=\"relu\",padding=\"same\"))\nmodel.add(Conv2D(filters=8,kernel_size=(4,4),activation=\"relu\",padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2)))#!!!dersi tekrar izle bu k\u0131sm\u0131n\u0131\nmodel.add(Dropout(0.25))   \nmodel.add(Flatten())\n          \n#full connected layer\n#hidden layers\nmodel.add(Dense(64,activation=\"relu\"))\nmodel.add(Dense(32,activation=\"relu\"))\n#output layers\nmodel.add(Dense(10,activation=\"softmax\"))\n\n","b646dc18":"model.summary()","0ae70422":"#compile model\nmodel.compile(optimizer = Adam(lr=0.0003) , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","693e899b":"#Train\nhistory = model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))","b3001265":"plt.figure(figsize=(24,8))\nplt.subplot(1,2,1)\nplt.plot(history.history[\"val_acc\"],label=\"validation_accuracy\",c=\"blue\",linewidth=4)\nplt.plot(history.history[\"acc\"],label=\"training_accuracy\",c=\"red\",linewidth=4)\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1,2,2)\nplt.plot(history.history[\"val_loss\"],label=\"validation_loss\",c=\"red\",linewidth=4)\nplt.plot(history.history[\"loss\"],label=\"training_loss\",c=\"green\",linewidth=4)\nplt.legend()\nplt.grid(True)\n\nplt.suptitle(\"ACC \/ LOSS\",fontsize=18)\n\nplt.show()","6506aa48":"## Train Test and Split\n","1de8d46c":"## Implementing with Keras"}}