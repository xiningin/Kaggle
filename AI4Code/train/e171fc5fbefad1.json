{"cell_type":{"983813d0":"code","bd3f775b":"code","1a04f02c":"code","6bdd258c":"code","743c16d0":"code","d878d829":"code","83968ec6":"code","bda8b90d":"code","303b35b4":"code","60ed61b7":"code","f668bb63":"code","c4df1cc7":"code","2871a29f":"code","f2e9c84c":"code","56541b84":"code","853ceb6e":"code","d95b21d0":"code","31d2b82b":"markdown","943005ff":"markdown","82d44af8":"markdown","e9706e02":"markdown","11a63ece":"markdown","2e7cb28d":"markdown"},"source":{"983813d0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nsns.set_style('dark')\nimport sklearn\nimport tensorflow as tf\nfrom tensorflow import keras","bd3f775b":"import os\n\ntrain = pd.read_csv('..\/input\/Kannada-MNIST\/train.csv')\ntest = pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')\ndig_mnist = pd.read_csv('..\/input\/Kannada-MNIST\/Dig-MNIST.csv')","1a04f02c":"print(train.shape)\nprint(dig_mnist.shape)\nprint(test.shape)","6bdd258c":"train.columns","743c16d0":"train_labels = train['label'].values\ntrain_data = train.drop('label',axis=1).values\n\nval_labels = dig_mnist['label'].values\nval_data = dig_mnist.drop('label',axis=1).values\n\ntest_data = test.drop('id', axis=1).values\n\nprint(train_labels)\nprint(train_data)","d878d829":"train_data = (train_data - np.mean(train_data)) \/ 255.\nval_data = (val_data - np.mean(val_data)) \/ 255.\ntest_data = (test_data - np.mean(test_data)) \/ 255.\n\ntrain_data","83968ec6":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\n# Let's reshape our 2d arrays because input to datagen.fit() should have rank 4.\n\ntrain_data = train_data.reshape(-1,28,28,1)\nval_data = val_data.reshape(-1,28,28,1)\ntest_data = test_data.reshape(-1,28,28,1)\n\ndatagen.fit(train_data)","bda8b90d":"model = keras.models.Sequential([\n    keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n    keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    keras.layers.LeakyReLU(alpha=0.1),\n    \n    keras.layers.Conv2D(64, (3,3), padding='same'),\n    keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    keras.layers.LeakyReLU(alpha=0.1),\n    \n    keras.layers.Conv2D(64, (3,3), padding='same'),\n    keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    keras.layers.LeakyReLU(alpha=0.1),\n    \n    keras.layers.MaxPooling2D(2, 2),\n    keras.layers.Dropout(0.2),\n    \n    keras.layers.Conv2D(128, (3,3), padding='same', input_shape=(28, 28, 1)),\n    keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    keras.layers.LeakyReLU(alpha=0.1),\n    \n    keras.layers.Conv2D(128, (3,3), padding='same', input_shape=(28, 28, 1)),\n    keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    keras.layers.LeakyReLU(alpha=0.1),\n    \n    keras.layers.Conv2D(128, (3,3), padding='same', input_shape=(28, 28, 1)),\n    keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    keras.layers.LeakyReLU(alpha=0.1),\n    \n    keras.layers.MaxPooling2D(2, 2),\n    keras.layers.Dropout(0.2),\n    \n    \n    keras.layers.Conv2D(256, (3,3), padding='same', input_shape=(28, 28, 1)),\n    keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    keras.layers.LeakyReLU(alpha=0.1),\n    \n    keras.layers.Conv2D(256, (3,3), padding='same', input_shape=(28, 28, 1)),\n    keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    keras.layers.LeakyReLU(alpha=0.1),\n    \n    keras.layers.MaxPooling2D(2, 2),\n    keras.layers.Dropout(0.2),\n    \n    keras.layers.Flatten(),\n    \n    keras.layers.Dense(256),\n    keras.layers.LeakyReLU(alpha=0.1),\n    keras.layers.BatchNormalization(),\n    \n    keras.layers.Dense(256),\n    keras.layers.LeakyReLU(alpha=0.1),\n    keras.layers.BatchNormalization(),\n    \n    keras.layers.Dense(10, activation='softmax')\n    \n])\n\n\noptimizer = keras.optimizers.RMSprop(learning_rate=0.002,rho=0.9)\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","303b35b4":"learning_rate_reduction = keras.callbacks.ReduceLROnPlateau( \n    monitor='loss',    \n    factor=0.2,       \n    patience=2,        \n    verbose=1,         \n    mode=\"min\",       \n    min_delta=0.0001,  \n    cooldown=0, \n    min_lr=0.00001)\n\nes = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=3, restore_best_weights=True)\n\nhistory = model.fit(datagen.flow(train_data, train_labels, batch_size=1024),\n                              steps_per_epoch = len(train_data) \/\/ 1024,\n                              epochs = 100,\n                              validation_data = (np.array(val_data),np.array(val_labels)),\n                              validation_steps = 50,\n                              callbacks = [learning_rate_reduction, es])","60ed61b7":"print(history.history.keys())\nepochs = len(history.history['loss'])","f668bb63":"y1 = history.history['loss']\ny2 = history.history['val_loss']\nx = np.arange(1, epochs+1)\n\nplt.plot(x, y1, y2)\nplt.legend(['loss', 'val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.tight_layout()","c4df1cc7":"y1 = history.history['accuracy']\ny2 = history.history['val_accuracy']\nx = np.arange(1, epochs+1)\n\nplt.plot(x, y1, y2)\nplt.legend(['accuracy', 'val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.tight_layout()","2871a29f":"score = model.evaluate( np.array(val_data), np.array(val_labels),batch_size = 1024)","f2e9c84c":"predictions = model.predict(test_data)","56541b84":"pred = np.argmax(predictions, axis=1)\npred","853ceb6e":"# test_id = test_data['Id']\ntest_id = np.arange(pred.shape[0])\ntest_id","d95b21d0":"submission = pd.DataFrame({'id': test_id, 'label': pred})\nsubmission.to_csv('submission.csv', index = False)","31d2b82b":"# Making predictions","943005ff":"# Building and compiling the model","82d44af8":"# Training our model","e9706e02":"# Data Preparation and Preprocessing","11a63ece":"# Evaluating our model","2e7cb28d":"# Let's bring in the imports and the data"}}