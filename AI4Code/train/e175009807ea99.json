{"cell_type":{"4d6c7faf":"code","3a778e91":"code","b7c13861":"code","add2dd82":"code","da9d5c3b":"code","dadff48e":"code","1e825ea2":"code","73985dfd":"code","7168949c":"code","be2d3a98":"code","b63391d5":"code","9b8c9a27":"code","4f1d6d69":"code","4a00d85e":"code","77807c56":"code","9a2d28e4":"code","531d812a":"code","083bfb4c":"code","b97d68df":"code","2ff21e5e":"code","864f46e0":"code","6f9300f8":"code","4a806b28":"code","dddd4ece":"code","24f0aba8":"code","34c19b18":"code","068bdaff":"code","97d573b4":"code","5829aa6a":"code","fa0ca150":"code","00e9808a":"code","909fa5c3":"code","3a7ca596":"code","480594a4":"code","6bd8e187":"code","7d1f16e6":"code","71060170":"code","9f0586bf":"markdown","3085986a":"markdown","904cb960":"markdown","8b4d955b":"markdown","40fab1da":"markdown","d1280060":"markdown"},"source":{"4d6c7faf":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","3a778e91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn as sk\nfrom sklearn.impute import KNNImputer\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7c13861":"df_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","add2dd82":"df_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","da9d5c3b":"df_train.info()","dadff48e":"df_train[\"Sex\"].replace(\"female\",0, inplace = True)\ndf_train[\"Sex\"].replace(\"male\",1, inplace = True)","1e825ea2":"df_test[\"Sex\"].replace(\"female\",0, inplace = True)\ndf_test[\"Sex\"].replace(\"male\",1, inplace = True)","73985dfd":"df_train.head()","7168949c":"df_train.nunique()","be2d3a98":"df_train[\"Survived\"] = df_train[\"Survived\"].astype(\"category\")\ndf_train[\"Pclass\"] = df_train[\"Pclass\"].astype(\"category\")\ndf_train[\"Sex\"] = df_train[\"Sex\"].astype(\"category\")\ndf_train[\"SibSp\"] = df_train[\"SibSp\"].astype(\"category\")\ndf_train[\"Parch\"] = df_train[\"Parch\"].astype(\"category\")\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].astype(\"category\")\ndf_train[\"Ticket\"] = df_train[\"Ticket\"].astype(\"category\")\ndf_train[\"Cabin\"] = df_train[\"Cabin\"].astype(\"category\")","b63391d5":"df_test[\"Pclass\"] = df_test[\"Pclass\"].astype(\"category\")\ndf_test[\"Sex\"] = df_test[\"Sex\"].astype(\"category\")\ndf_test[\"SibSp\"] = df_test[\"SibSp\"].astype(\"category\")\ndf_test[\"Parch\"] = df_test[\"Parch\"].astype(\"category\")\ndf_test[\"Embarked\"] = df_test[\"Embarked\"].astype(\"category\")","9b8c9a27":"df_train.info()","4f1d6d69":"df_train.isna().sum()","4a00d85e":"df_train.drop([\"Name\", \"Ticket\", \"Cabin\", \"Fare\",\"Embarked\"], axis =1, inplace = True)\ndf_test.drop([\"Name\", \"Ticket\", \"Cabin\", \"Fare\",\"Embarked\"], axis =1, inplace = True)","77807c56":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf_train = pd.DataFrame(scaler.fit_transform(df_train), columns = df_train.columns)\ndf_test = pd.DataFrame(scaler.fit_transform(df_test), columns = df_test.columns)","9a2d28e4":"imputer = KNNImputer(n_neighbors = 5)\ndf_train = pd.DataFrame(imputer.fit_transform(df_train), columns = df_train.columns)","531d812a":"df_train.isnull().sum()","083bfb4c":"df_test.info()","b97d68df":"df_test.isna().sum()","2ff21e5e":"df_test = pd.DataFrame(imputer.fit_transform(df_test), columns =df_test.columns)","864f46e0":"x_train = np.array(df_train.drop(['Survived'], axis =1))\ny_train = np.array(df_train['Survived'])","6f9300f8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix","4a806b28":"model1 = LogisticRegression(solver='liblinear', random_state=0, max_iter = 1000).fit(x_train,y_train)","dddd4ece":"model1.coef_","24f0aba8":"pd.DataFrame(confusion_matrix(y_train, model1.predict(x_train)))\nconf1 = confusion_matrix(y_train, model1.predict(x_train))\nSensitivity = round(conf1[1,1]\/(conf1[1,1]+conf1[0,1]),2)\nSpecificity = round(conf1[0,0]\/(conf1[0,0]+conf1[1,0]),2)\nPrecision = round(conf1[1,1]\/(conf1[1,1]+conf1[1,0]),2)\naccuracy = round((conf1[1,1]+conf1[0,0])\/(conf1[1,1]+conf1[0,0] + conf1[1,0]+conf1[0,1]),2)\nSensitivity, Specificity, Precision, accuracy","34c19b18":"##AUC ROC \nfrom sklearn.metrics import roc_auc_score\nround(roc_auc_score(y_train, model1.predict_proba(x_train)[:,1]),2)","068bdaff":"from sklearn.tree import DecisionTreeClassifier\n\nmodel2= DecisionTreeClassifier(max_depth = 4, min_samples_leaf = 10).fit(x_train, y_train)\n","97d573b4":"model2.score(x_train, y_train)","5829aa6a":"pd.DataFrame(confusion_matrix(y_train, model2.predict(x_train)))\nconf2 = confusion_matrix(y_train, model2.predict(x_train))\nSensitivity = round(conf2[1,1]\/(conf2[1,1]+conf2[0,1]),2)\nSpecificity = round(conf2[0,0]\/(conf2[0,0]+conf2[1,0]),2)\nPrecision = round(conf2[1,1]\/(conf2[1,1]+conf2[1,0]),2)\naccuracy = round((conf2[1,1]+conf2[0,0])\/(conf2[1,1]+conf2[0,0] + conf2[1,0]+conf2[0,1]),2)\nSensitivity, Specificity, Precision, accuracy","fa0ca150":"##AUC ROC \nfrom sklearn.metrics import roc_auc_score\nround(roc_auc_score(y_train, model2.predict_proba(x_train)[:,1]),2)","00e9808a":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestClassifier\n# Instantiate model with 1000 decision trees\nmodel3 = RandomForestClassifier(n_estimators = 100, random_state = 1, max_depth =5).fit(x_train,y_train)\n","909fa5c3":"round(model3.score(x_train,y_train),2)","3a7ca596":"pd.DataFrame(confusion_matrix(y_train, model3.predict(x_train)))\nconf3 = confusion_matrix(y_train,model3.predict(x_train))\nSensitivity = round(conf3[1,1]\/(conf3[1,1]+conf3[0,1]),2)\nSpecificity = round(conf3[0,0]\/(conf3[0,0]+conf3[1,0]),2)\nPrecision = round(conf3[1,1]\/(conf3[1,1]+conf3[1,0]),2)\naccuracy = round((conf3[1,1]+conf3[0,0])\/(conf3[1,1]+conf3[0,0] + conf3[1,0]+conf3[0,1]),2)\nSensitivity, Specificity, Precision, accuracy","480594a4":"##AUC ROC \nfrom sklearn.metrics import roc_auc_score\nround(roc_auc_score(y_train, model3.predict_proba(x_train)[:,1]),2)","6bd8e187":"pred = (model3.predict(df_test))","7d1f16e6":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': pred})","71060170":"output.to_csv('submission1.csv')\n","9f0586bf":"# DECISION TREE","3085986a":"# Final Submission","904cb960":"# Data Pre-processing","8b4d955b":"# Random Forest","40fab1da":"# Logistic Regression","d1280060":"# KNN Imputation"}}