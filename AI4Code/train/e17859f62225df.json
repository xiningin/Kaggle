{"cell_type":{"e2fd9c48":"code","ecd7d81a":"code","1041807f":"code","2e607f8b":"code","2fa7ce73":"code","050e96b6":"code","89aa2217":"code","8f53b06b":"code","21319bed":"code","e6d18e4a":"code","c8143491":"code","64057c78":"code","0b3b198f":"code","238b0e6b":"code","7bb69897":"code","316df30e":"code","f0a7a7e8":"code","c22aa7ff":"markdown","25b9e0de":"markdown","99a1d99d":"markdown","c1281a5c":"markdown","8e73c70d":"markdown","e5fe054e":"markdown","fc457f52":"markdown","0d8c6004":"markdown","c5ae3f9c":"markdown","de46a61c":"markdown","e0c7976f":"markdown","5317899b":"markdown","b7c2c79d":"markdown","c3f5eafd":"markdown","b569feee":"markdown","8dbbe4d1":"markdown","3a4dbb27":"markdown","decc570b":"markdown","14bd3be1":"markdown","86a54bd0":"markdown","dd5b2619":"markdown","cc00b6b5":"markdown","a5ed7554":"markdown","8fc2e603":"markdown","320fcec5":"markdown"},"source":{"e2fd9c48":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","ecd7d81a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\nfrom sklearn.cluster import KMeans \nfrom sklearn.preprocessing import StandardScaler\n\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn.metrics import silhouette_samples, silhouette_score\n\n%matplotlib inline","1041807f":"data = pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")","2e607f8b":"#Let's see how our data looks like!\n\ndata.head(5)","2fa7ce73":"# Let's get some more information about our dataset.\n\ndata.info()","050e96b6":"import missingno as mn\nmn.matrix(data)","89aa2217":"plt.figure(figsize=(8,5))\nplt.scatter('Annual Income (k$)','Spending Score (1-100)',data=data, s=30, color=\"red\", alpha = 0.8)\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')","8f53b06b":"x= data.iloc[:,3:5]\n\nx_array =  np.array(x)\nprint(x_array)","21319bed":"scaler = StandardScaler() \n\nx_scaled = scaler.fit_transform(x_array)\nx_scaled","e6d18e4a":"# Fitting the model for values in range(1,11)\n\nSSD =[]\nK = range(1,11)\n\nfor k in K:\n    km = KMeans(n_clusters = k)\n    km = km.fit(x_scaled)\n    SSD.append(km.inertia_)","c8143491":"#plotting Elbow\nplt.figure(figsize=(8,5))\nplt.plot(K, SSD, 'bx-')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Sum of squared distances')\nplt.title('Elbow Method For Optimal K')\nplt.show()","64057c78":"KMean= KMeans(n_clusters=5)\nKMean.fit(x_scaled)\nlabel=KMean.predict(x_scaled)\n\nprint(\"Silhouette Score(n=5):\",silhouette_score(x_scaled, label))","0b3b198f":"model = KMeans(random_state=123)\n\n# Instantiate the KElbowVisualizer with the number of clusters and the metric \nVisualizer = KElbowVisualizer(model, k=(2,6), metric='silhouette', timings=False)\nplt.figure(figsize=(8,5))\n# Fit the data and visualize\nVisualizer.fit(x_scaled)    \nVisualizer.poof()","238b0e6b":"print(KMean.cluster_centers_)","7bb69897":"print(KMean.labels_)","316df30e":"#Add cluster results columns to the dataset dataframe\n\ndata[\"cluster\"] = KMean.labels_\ndata.head()","f0a7a7e8":"plt.figure(figsize=(8,5))\n\nplt.scatter(x_scaled[label==0, 0], x_scaled[label==0, 1], s=100, c='red', label ='Careless')\nplt.scatter(x_scaled[label==1, 0], x_scaled[label==1, 1], s=100, c='blue', label ='Target')\nplt.scatter(x_scaled[label==2, 0], x_scaled[label==2, 1], s=100, c='green', label ='Planner')\nplt.scatter(x_scaled[label==3, 0], x_scaled[label==3, 1], s=100, c='cyan', label ='Sensible')\nplt.scatter(x_scaled[label==4, 0], x_scaled[label==4, 1], s=100, c='magenta', label ='Moderate')\n\nplt.title('Cluster of Clients')\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.legend()\nplt.show","c22aa7ff":"## For more read on KElbowVisualizer:\n\nhttps:\/\/heartbeat.fritz.ai\/analyzing-machine-learning-models-with-yellowbrick-37795733f3ee","25b9e0de":"### Our labels are from 0-4.","99a1d99d":"## Properties of Clusters:\n\n1. All the data points in a cluster should be similar to each other. \n2. The data points from different clusters should be as different as possible. ","c1281a5c":"## When to use Cluster Analysis?\n\nIf we are using a labeled data we can use classification technique whereas in case when the data is not labeled we can cluster the data based on certain feature and try to label it on our own.So when we use cluster analysis we don\u2019t have labels(ie..data is not labeled)in the context of machine learning this is called as unsupervised learning.","8e73c70d":"We can see the behaviour of Customers with Annual Income and their Spending Score. \nThe plot shows segments of Customers with following behaviours :\n\n* Less Income- Less Spending Score\n* High Income- Less Spending Score\n* Low Income- High Spending Score\n* High Income- High Spending Score\n* Moderate Income- Moderate Spending Score","e5fe054e":"## 2) Silhouette Coefficient Method:\n\nThe silhouette coefficient of a data measures how well data are assigned to its own cluster and how far they are from other clusters. \n* A silhouette close to 1 means the data points are in an appropriate cluster \n* A silhouette coefficient close to \u22121 implies out data is in the wrong cluster.\n\n**Silhouette Coefficient = (x-y)\/ max(x,y)**","fc457f52":"## Stopping Criteria for K-Means Clustering\n\nThere are essentially three stopping criteria that can be adopted to stop the K-means algorithm:\n\n* Centroids of newly formed clusters do not change\n* Points remain in the same cluster\n* Maximum number of iterations are reached","0d8c6004":"### 1)  Elbow-Method using WCSS(Within Cluster Sum of Squares):\n \nThe Elbow method is a very popular technique and the idea is to run k-means clustering for a range of clusters k (let's say from 1 to 10) and for each value, we are calculating the sum of squared distances from each point to its assigned center.","c5ae3f9c":"# Mall Customer Segmentation","de46a61c":"## Step 1: Importing Libraries","e0c7976f":"## Rescaling","5317899b":"## Plotting the data:\nNow we will simply plot the scatter plot of the given data using. ","b7c2c79d":"### There are no missing values in our dataset","c3f5eafd":"## Problem Statement:\n\nYou own the mall and want to understand the customers like who can be easily converge (Target customers) so that the sense can be given to marketing team and plan the strategy accordingly.","b569feee":"## The approach Kmeans follows to solve the problem is called Expectation Maximization:\n\n1. Specify number of clusters K.\n2. Initialize centroids by first shuffling the dataset and then randomly selecting K data points for the centroids without       replacement.\n3. Keep iterating until there is no change to the centroids. i.e assignment of data points to clusters isn\u2019t changing.\n4. Compute the sum of the squared distance between data points and all centroids.\n5. Assign each data point to the closest cluster (centroid).\n6. Compute the centroids for the clusters by taking the average of the all data points that belong to each cluster.","8dbbe4d1":"## Steps:\n* Importing Libraries\n* Importing Data\n* Data Visualization\n* Clustering using K-Means\n* Selection of Clusters\n* Plotting the Cluster Boundary and Clusters\n* Visualization of Cluster Result","3a4dbb27":"## Description Variables:\n* **CustomerID**:             Unique ID assigned to the customer\n* **Gender**:                 Gender of the customer\n* **Age**:                    Age of the customer\n* **Annual Income (k$)**:     Annual Income of the customee\n* **Spending Score (1\u2013100)**: Score assigned by the mall based on customer behavior and spending nature.","decc570b":"### Now if we observe the point after which there isn\u2019t a sudden change in WCSS in K=5. So we will choose K=5 as an appropriate number of clusters which matched the clusters we had before applying the algorithm.","14bd3be1":"## Definition:\n\nKmeans algorithm is an iterative algorithm that tries to partition the dataset into Kpre-defined distinct non-overlapping subgroups (clusters) where each data point belongs to only one group. In the realm of machine learning, k-means clustering can be used to segment customers (or other data) efficiently.\n","86a54bd0":"Now we know customers behaviour depending upon their Annual Income and Spending Score. \nThere can be many marketing strategies applied for Customers on these Cluster Analysis.\nHigh income and High spending score customers are our target customers and we would always want to retain them as they give the most profit margin.\nHigh Income and Less spending score customers can be attracted with wide range of products their life style demands and it might attract them towards the Mall Supermarket.\nLess Income Less Spending Score can be given extra offers and constantly sending them the offers and discounts will attract them towards spending.We can also have a cluster anaysis done on what kind of products customers tend to buy and can make other marketing strategies accordingly.","dd5b2619":"## Determine K-value","cc00b6b5":"## Final Goal:\nThe goal of clustering is to maximize the similarity of observation within the cluster and maximize the dissimilarity between the clusters.","a5ed7554":"## Closing comments: ","8fc2e603":"### Inertia: It is defined as the mean squared distance between each instance and its closest centroid. Logically, as per the definition lower the inertia better the model.","320fcec5":"![thank-you-message-person-using-laptop-computer-thank-you-message-person-using-laptop-computer-165172636.jpg](attachment:thank-you-message-person-using-laptop-computer-thank-you-message-person-using-laptop-computer-165172636.jpg)"}}