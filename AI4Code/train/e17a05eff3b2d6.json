{"cell_type":{"627406d1":"code","a364cb69":"code","c14bf642":"code","c52eeea8":"code","4cb80891":"code","f8e86836":"markdown","c56d96a2":"markdown","0b6269f4":"markdown","638e2454":"markdown","276faecf":"markdown","79940423":"markdown","c73f6d60":"markdown","1587c38e":"markdown","de1d54d3":"markdown","6235e414":"markdown","30ed90c3":"markdown","cd048912":"markdown"},"source":{"627406d1":"import pandas as pd\nimport seaborn as sns\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n#combining train and test\ndataset =  pd.concat(objs=[train, test], axis=0,ignore_index=True)\ndataset[\"Fare\"].fillna(dataset[\"Fare\"].median(),inplace=True)\n#dataset.Fare.isnull().sum()","a364cb69":"t=sns.distplot(dataset[\"Fare\"],label=\"Skewness: %.2f\"%(dataset[\"Fare\"].skew()) )\nt.legend()","c14bf642":"import numpy as np\nLog_Fare = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\nt=sns.distplot(Log_Fare,label=\"Skewness: %.2f\"%(Log_Fare.skew()) )\nt.legend()","c52eeea8":"from scipy import stats\nBoxcox_Fare = dataset[\"Fare\"].map(lambda i: np.abs(i) if i < 0 else (i+1 if i==0 else i))\nBoxcox_Fare= stats.boxcox(Boxcox_Fare)\nBoxcox_Fare= pd.Series(Boxcox_Fare[0])\nt=sns.distplot(Boxcox_Fare,label=\"Skewness: %.2f\"%(Boxcox_Fare.skew()) )\nt.legend()","4cb80891":"Sqrt_Fare = dataset[\"Fare\"].map(lambda i: np.sqrt(i))\nt=sns.distplot(Sqrt_Fare,label=\"Skewness: %.2f\"%(Sqrt_Fare.skew()) )\nt.legend()","f8e86836":"## Conclusion\nModels such as ones baseed on linear regression makes reliable predictions if the fetaures are normally distributed. However we, must remember on which feature we perfromed the transform as we have to reverse it before making predictions","c56d96a2":"So as we can see Fare distribution is very skewed. Such data can be handled by following ways:\n* Log Transform\n* Box Cox Transform\n* Square Root Transform\n","0b6269f4":"## Square Root Transform\n* Not generally used as taking square root shortens the range of variables\n* Can be applied via np.sqrt()\n\nLets try it on \"Fare\" column","638e2454":"## Skewed Data","276faecf":"Skewness is reduced from 4.37 to 0.57","79940423":"This is notebook is part of snippet series that I am documenting to for my own references on daily basis. I am keeping them public,so that other beginners can refer to them as well. I hope you find it useful. ","c73f6d60":"**What is Skewed Data?**\n* A data is called as skewed when curve appears distorted either to the left or to the right, in a statistical distribution.I.e one tail is longer than the other.\n\nLets take an example from Titanic dataset only. Yeah the same old boring one cause I am still exploring it!\n\n","1587c38e":"Lets plot Fare from train and test dataset combined.","de1d54d3":"Not too much reduction in skewness but still the change is noticable as skewness decreased from 4.37 to 2.09","6235e414":"## Box Cox Transform\n* Data must be positive\n* Imported from scipy (expand the code below to see)\n\nSince data we have in \"Fare\" is not postive so we cannot apply this functions. However, to have a jist of how function is applied lets convert fare values to postive. (Note: This is not to be done when solving a real problem, doing this just so that we can see how function is applied)","30ed90c3":"We will not compare the skewness as we have heavily manipulated data but in general when dealing with positive data it will reduce to great extent","cd048912":"## Log Transform\n* This is most commonly used\n* Easily done by np.log()\n* Data should not have null values\n* Handle values at 0 (np.log(0) encounters divide by zero)\n\nLets apply it on our dataset and plot it."}}