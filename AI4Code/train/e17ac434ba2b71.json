{"cell_type":{"18817380":"code","93c3d7fb":"code","394525f5":"code","46109055":"code","de70bb8a":"code","fe0fc06c":"code","c14d502a":"code","35bb2ef9":"code","6ae6e1d4":"code","06d39e96":"code","f9f0f17c":"code","ae04be91":"code","d33029d1":"code","8175e936":"code","34c019b2":"code","8f669c03":"code","209f9fae":"code","72e89246":"markdown","37c3862c":"markdown","b6a84172":"markdown","e6460e3c":"markdown","8d34a728":"markdown","da16b671":"markdown","e8622a51":"markdown","5c4e2994":"markdown","46abf7eb":"markdown","637d547e":"markdown"},"source":{"18817380":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93c3d7fb":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier","394525f5":"df=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","46109055":"df.head()","de70bb8a":"df.info()","fe0fc06c":"df.describe()","c14d502a":"fig, axs = plt.subplots(4,2, figsize=(15,15))\n\nsns.countplot(ax=axs[0,0], x=\"Survived\",hue=\"Pclass\",data=df)\nsns.countplot(ax=axs[0,1], x=\"Survived\",hue=\"Sex\",data=df)\nsns.countplot(ax=axs[1,0], x=\"Survived\",hue=\"Embarked\",data=df)\nsns.countplot(ax=axs[1,1], x=\"Survived\",hue=\"Parch\",data=df)\nsns.countplot(ax=axs[2,0], x=\"Survived\",hue=\"SibSp\",data=df)\nsns.histplot(ax=axs[2,1], x=\"Age\", hue=\"Survived\", data=df)\n\nax1=plt.subplot(414)\nsns.histplot(ax=ax1, x=\"Fare\", data=df)\n\nplt.show()","35bb2ef9":"fig, axs = plt.subplots(1,2, figsize=(18,5))\n\nmask = np.triu(np.ones_like(df.drop(columns=[\"PassengerId\",\"Name\"]).corr(), dtype=np.bool))\nsns.heatmap(df.drop(columns=[\"PassengerId\",\"Name\"]).corr(), annot=True, mask=mask, ax=axs[0])\nsns.heatmap(df.drop(columns=[\"PassengerId\",\"Name\"]).corr()[['Survived']].sort_values(by='Survived', ascending=False), annot=True, ax=axs[1])\n\nplt.show()","6ae6e1d4":"df['Age'].fillna(df['Age'].median(), inplace=True)\ndf['Embarked'].fillna('S', inplace=True)\n\ndf_test['Age'].fillna(df_test['Age'].median(), inplace=True)\ndf_test['Embarked'].fillna('S', inplace=True)\ndf_test['Fare'].fillna(df_test['Fare'].median(), inplace=True)\n\nX_train=df.drop(columns=['Survived','Name','Cabin','Ticket'])\ndf_test.drop(columns=['Name','Cabin','Ticket'], inplace=True)\nY_train=df['Survived']\nX_train","06d39e96":"le=preprocessing.LabelEncoder()\n\nX_train[['Sex']]=le.fit_transform(X_train[['Sex']])\ndf_test[['Sex']]=le.transform(df_test[['Sex']])\n\nX_train['Embarked'][X_train['Embarked'].notnull()]=le.fit_transform(X_train[['Embarked']][X_train['Embarked'].notnull()])\ndf_test['Embarked'][df_test['Embarked'].notnull()]=le.transform(df_test[['Embarked']][df_test['Embarked'].notnull()])\n\nX_train","f9f0f17c":"df_test","ae04be91":"train_x, test_x, train_y, test_y = train_test_split(X_train, Y_train, test_size=0.3)\n\nclf=DecisionTreeClassifier()\nclf.fit(train_x,train_y)\npred_y=clf.predict(test_x)\n\nprint(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))\nprint(\"F1:\",metrics.f1_score(test_y, pred_y))\n\npred_y=clf.predict(df_test)\nresult=pd.DataFrame()\nresult['PassengerId']=df_test['PassengerId']\nresult['Survived']=pred_y\n\n# result.to_csv('decisiontree.csv',index=False)","d33029d1":"train_x, test_x, train_y, test_y = train_test_split(X_train, Y_train, test_size=0.3)\n\nclf=RandomForestClassifier(n_estimators=30)\nclf.fit(train_x,train_y)\npred_y=clf.predict(test_x)\n\nprint(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))\nprint(\"F1:\",metrics.f1_score(test_y, pred_y))\n\npred_y=clf.predict(df_test)\nresult=pd.DataFrame()\nresult['PassengerId']=df_test['PassengerId']\nresult['Survived']=pred_y\n\n# result.to_csv('randomforest.csv',index=False)","8175e936":"train_x, test_x, train_y, test_y = train_test_split(X_train, Y_train, test_size=0.3)\n\nclf=GaussianNB()\nclf.fit(train_x,train_y)\npred_y=clf.predict(test_x)\n\nprint(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))\nprint(\"F1:\",metrics.f1_score(test_y, pred_y))\n\npred_y=clf.predict(df_test)\nresult=pd.DataFrame()\nresult['PassengerId']=df_test['PassengerId']\nresult['Survived']=pred_y\n\n# result.to_csv('naivebaye.csv',index=False)","34c019b2":"train_x, test_x, train_y, test_y = train_test_split(X_train, Y_train, test_size=0.3)\n\nclf=LogisticRegression(penalty=\"l1\",solver='liblinear', random_state=1)\nclf.fit(train_x,train_y)\npred_y=clf.predict(test_x)\n\nprint(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))\nprint(\"F1:\",metrics.f1_score(test_y, pred_y))\n\npred_y=clf.predict(df_test)\nresult=pd.DataFrame()\nresult['PassengerId']=df_test['PassengerId']\nresult['Survived']=pred_y\n\n# result.to_csv('logisticregression_lasso.csv',index=False)","8f669c03":"train_x, test_x, train_y, test_y = train_test_split(X_train, Y_train, test_size=0.3)\n\nclf=LogisticRegression(penalty=\"l2\",solver='liblinear', random_state=1)\nclf.fit(train_x,train_y)\npred_y=clf.predict(test_x)\n\nprint(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))\nprint(\"F1:\",metrics.f1_score(test_y, pred_y))\n\npred_y=clf.predict(df_test)\nresult=pd.DataFrame()\nresult['PassengerId']=df_test['PassengerId']\nresult['Survived']=pred_y\n\n# result.to_csv('logisticregression_ridge.csv',index=False)","209f9fae":"train_x, test_x, train_y, test_y = train_test_split(X_train, Y_train, test_size=0.3)\n\nclf=GradientBoostingClassifier()\nclf.fit(train_x,train_y)\npred_y=clf.predict(test_x)\n\nprint(\"Accuracy:\",metrics.accuracy_score(test_y, pred_y))\nprint(\"F1:\",metrics.f1_score(test_y, pred_y))\n\npred_y=clf.predict(df_test)\nresult=pd.DataFrame()\nresult['PassengerId']=df_test['PassengerId']\nresult['Survived']=pred_y\n\nresult.to_csv('GradientBoosting.csv',index=False)","72e89246":"# Random Forest","37c3862c":"# LogisticRegression with lasso","b6a84172":"# Decision Tree","e6460e3c":"# Import libraries","8d34a728":"# Data overview","da16b671":"# Gradient Boosting","e8622a51":"# naive bayes gaussian","5c4e2994":"# Replacing missing data and encoding","46abf7eb":"# LogisticRegression with ridge","637d547e":"# Import data set"}}