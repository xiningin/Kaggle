{"cell_type":{"055cf8ee":"code","a0fcadfc":"code","91877f96":"code","c9a61c59":"markdown","40bafa83":"markdown","353fb383":"markdown","d9216c8e":"markdown","715c2b53":"markdown","f03026dc":"markdown"},"source":{"055cf8ee":"from sklearn.model_selection import KFold\nX = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\ny = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]\nkf = KFold(n_splits=3, shuffle=True)\nfor train_index, test_index in kf.split(X):\n     print(\"%s %s\" % (train_index, test_index))","a0fcadfc":"from sklearn.model_selection import StratifiedKFold\nX = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\ny = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\nskf = StratifiedKFold(n_splits=4, shuffle=True)\nfor train_index, test_index in skf.split(X, y):\n    print(\"%s %s\" % (train_index, test_index))","91877f96":"from sklearn.model_selection import GroupKFold\nX = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\ny = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]\ngroups = ['a','a', 'a', 'b', 'b', 'b', 'c', 'c', 'c', 'c', 'd', 'd', 'd', 'd', 'd', 'd']\ngkf = GroupKFold(n_splits=4)\nfor train_index, test_index in gkf.split(X, y, groups=groups):\n     print(\"%s %s\" % (train_index, test_index))","c9a61c59":"## Stratified KFold\nIf we use the KFold for unbalanced dataset, we might endup in a training data that conatins no or very few minority classes. To avoid this problem, we use the stratified KFold. StratifiedKFold is a variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.","40bafa83":"## KFold\nKFold divides all the samples in k groups of samples, called folds ( if k=n this is equivalent to the Leave One Out strategy), of equal sizes (if possible). The prediction function is learned using k - 1 folds, and the fold left out is used for test.","353fb383":"## GroupKFold\nThere could me one more situation where we are collecting data from individuals that belong to multile groups. Suppose we want to train on some individuals belonging to a set groups and test on remaining set of groups. In this situation, we can use GroupKfold. The GroupKFold need groups also as an input.","d9216c8e":"Here if you carefully observe you can see that the test split has atleast one y which has value 1","715c2b53":"Here if you carefully observe, you can see that the test_index belongs to one group. For the first case its the group `d`, second case its group `c`, third case its the group `b` and in the fourth case its the group `a`.","f03026dc":"The most common ways to overfit data is to train and test in the same data. One solution to solve this problem is to use the cross validation.\n\nCommonly used cross validation strategies are `KFold`, `Stratified KFold` and `GroupKFold`."}}