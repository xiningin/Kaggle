{"cell_type":{"03621260":"code","4219f2d6":"code","3641f2f7":"code","92518afa":"code","7c2ae463":"code","b35d39ab":"code","2084ad84":"code","49917708":"code","3992517a":"code","dac10700":"code","2efd9b7d":"code","d5697054":"code","c2af8a4c":"code","bfe6b8aa":"code","13569a8a":"markdown","9a7cacf2":"markdown","23e76380":"markdown","f7282583":"markdown","75c4eead":"markdown","398ae510":"markdown","d43f8ed5":"markdown","215a9b20":"markdown"},"source":{"03621260":"from collections import defaultdict\nimport random\nimport numpy as np\nfrom enum import Enum\nfrom typing import List,Tuple,Optional\nimport multiprocessing\n","4219f2d6":"class Action(Enum):\n    NORTH = \"NORTH\"\n    SOUTH = \"SOUTH\"\n    EAST  = \"EAST\"\n    WEST  = \"WEST\"\n    def __str__(self):\n        return self.value\n    def __repr__(self):\n        return self.value\n    \n    def opposite(self):\n        return _ACTION_TO_OPPOSITE[self]\n\n    def to_tuple(self):\n        return _ACTION_TO_TUPLE[self]\n    \n    @classmethod\n    def from_tuple(cls,t:Tuple[int,int]):\n        if t[0] == 0:\n            if t[1] == 1:\n                return cls.NORTH\n            if t[1] == -1:\n                return cls.SOUTH\n        if t[1] == 0:\n            if t[0] == 1:\n                return cls.EAST\n            if t[0] == -1:\n                return cls.WEST\n        raise ValueError(f\"Can't convert tuple {t}\")\n        \n        \n_ACTION_TO_OPPOSITE = {\n    Action.NORTH:Action.SOUTH,\n    Action.SOUTH:Action.NORTH,\n    Action.EAST:Action.WEST,\n    Action.WEST:Action.EAST\n}\n\n_ACTION_TO_TUPLE = {\n    Action.NORTH:(0,1),\n    Action.SOUTH:(0,-1),\n    Action.EAST:(1,0),\n    Action.WEST:(-1,0)\n}","3641f2f7":"NUM_ROWS = 7\nNUM_COLUMNS = 11\nHUNGER_RATE = 40\n_PREVIOUS_STATES = []\n","92518afa":"class Board:\n    def __init__(self):\n        self._ps = np.zeros((NUM_COLUMNS,NUM_ROWS),dtype=Point)\n        for x in range(NUM_COLUMNS):\n            for y in range(NUM_ROWS):\n                self._ps[x,y] = Point(x,y,board=self)\n        self._food = []\n    def __repr__(self):\n            return f\"Board {NUM_ROWS}X{NUM_COLUMNS}\"\n    def __getitem__(self,item):\n            x,y = item\n            return self._ps[x % NUM_COLUMNS,y % NUM_ROWS]\n    def add_food(self,x: int,y:int):\n            p = self[x, y]\n            p.food = True\n            self._food.append(p)\n    def food_positions(self):\n            return self._food\n            ","7c2ae463":"class Point:\n    def __init__(self,x:int,y:int,board:Board):\n        self.x = x\n        self.y = y\n        self.board = board\n        \n        self.goose: Optional[Goose] = None\n        self.food: bool = False\n    \n    def __repr__(self):\n        return f\"[{self.x},{self.y}]\"\n    def __hash__(self):\n        return self.y * NUM_COLUMNS + self.x\n    def __sub__(self,other:\"Point\"):\n        return self.board[self.x - other.x,self.y - other.y]\n    def __add__(self,other:\"Point\"):\n        return self.board[self.x + other.x,self.y + other.y]\n    def apply(self,action:\"Action\"):\n        return _transform(self,action)\n    def to_tuple(self):\n        return self.x,self.y\n    def to_flat(self):\n        return (NUM_ROWS - self.y - 1) * NUM_COLUMNS + self.x\n    def distance_from(self,other:\"Point\"):\n        _, d = self.dirs_to(other)\n        return d\n    def dirs_to(self,other:\"Point\"):\n        return _dirs_to(dx=self.x - other.x,dy = self.y - other.y)\n    def nearby_points(self,radius:int = 1):\n        return _nearby_points(self,radius)\n    def food_distance(self):\n        food_positions = self.board.food_positions()\n        if not food_positions:\n            return np.inf\n        return min(self.distance_from(x) for x in food_positions)\n","b35d39ab":"from functools import lru_cache\nimport itertools\n@lru_cache(256)\ndef _nearby_points(p:Point,radius: int = 1):\n    if radius <= 0:\n        return []\n    points = []\n    for actions in itertools.product(Action,repeat=radius):\n        _p = p\n        for a in actions:\n            _p = _p.apply(a)\n        if (_p.x,_p.y) != (p.x,p.y) and _p not in points:\n            points.append(_p)\n    return points\n                        \n@lru_cache(128)\ndef _dirs_to(dx:int,dy:int):\n    if dx == 0 and dy == 0:\n        return [],0\n    if abs(dx) > NUM_COLUMNS \/ 2:\n        dx -= np.sign(dx) * NUM_COLUMNS\n    if abs(dy) > NUM_ROWS \/ 2:\n        dy -= np.sign(dy) * NUM_ROWS\n    \n    ret = []\n    if dx > 0:\n        ret.append(Action.WEST)\n    elif dx < 0:\n        ret.append(Action.EAST)\n    if dy > 0:\n        ret.append(Action.SOUTH)\n    elif dy < 0:\n        ret.append(Action.NORTH)\n    return ret,abs(dx) + abs(dy)\n\ndef _transform(p:Point,a:Action):\n    x ,y = a.to_tuple()\n    return p.board[p.x + x,p.y + y]\n\ndef is_starving_step(step: int):\n    return (step + 1) % HUNGER_RATE == 0\n\ndef find_opponent_allowed_actions(goose:\"Goose\",opponents:List[\"Goose\"],starving:bool = False):\n    allowed_actions = goose.self_collision_free_actions\n    if not allowed_actions:\n        return allowed_actions\n    forbidden_actions = []\n    for op in opponents:\n        if not op.is_active or not op.self_collision_free_actions:\n            continue\n        \n        op_points = op.positions[:-1]\n        if starving:\n            op_points = op_points[:-1]\n        \n        for a in allowed_actions:\n            if a not in forbidden_actions:\n                next_head_position = goose.head.apply(a)\n                if next_head_position in op_points:\n                    forbidden_actions.append(a)\n    allowed_actions = [x for x in allowed_actions if x not in forbidden_actions]\n    return allowed_actions","2084ad84":"class Goose:\n    def __init__(\n        self,\n        id: int,\n        step: int,\n        positions:List[Point],\n        last_action: Optional[Action],\n        reward: Optional[int] = None):\n        self.id = id\n        self.step = step\n        self.positions = positions\n        self.last_action = last_action\n        \n        self.reward = (\n            reward if reward is not None else (self.step + 1) * 100 + self.length\n        )\n        self.is_active = bool(positions)\n        if self.is_active:\n            self.head = positions[0]\n            self.self_opposite_free_actions = self.__get_self_opposite_free_actions()\n            self.self_collision_free_actions = self.__get_self_collision_free_actions()\n     ########       \n        else:\n            self.head = None\n            self.self_opposite_free_actions = []\n            self.self_collision_free_actions = [] \n            \n    ########\n    def __get_self_opposite_free_actions(self):\n        if not self.last_action:\n            return list(Action)\n        not_allowed_action = self.last_action.opposite()\n        return [a for a in Action if a != not_allowed_action]\n    \n    def __get_self_collision_free_actions(self):\n        new_body_positions = self.positions[:-1]\n        allowed_actions = []\n        for a in self.self_opposite_free_actions:\n            head_point = self.head.apply(a)\n            for n,body_point in  enumerate(new_body_positions):\n                if ([head_point.x,head_point.y] == [body_point.x,body_point.y]):\n                    break\n                elif(n+1==len(new_body_positions)):\n                    allowed_actions.append(a)\n                    break\n        return allowed_actions\n    def __repr__(self):\n        return f\"Goose(id={self.id},positions={self.positions})\"\n    def __iter__(self):\n        return iter(self.positions)    \n    def __len__(self):\n        return self.length\n    def __bool__(self):\n        return self.is_active\n    def to_flat(self):\n        return [x.to_flat() for x in self.positions]\n    \n    @property\n    def tail(self):\n        return self.positions[-1]\n    def distance_from(self,point:\"Point\"):\n        _, d = self.dirs_to(point) \n    def dirs_to(self,point:\"Point\"):\n        p = self.head\n        return _dirs_to(dx=p.x - point.x,dy=p.y - point.y)\n    \n    @property    \n    def length(self):\n        return len(self.positions)\n    @property\n    def length(self):\n        return len(self.positions)\n\n    def can_move(self):\n        return bool(self.self_collision_free_actions)\n\n    def __get_self_opposite_free_actions(self):\n        if not self.last_action:\n            return list(Action)\n\n        not_allowed_action = self.last_action.opposite()\n        return [a for a in Action if a != not_allowed_action]\n\n    def __get_self_collision_free_actions(self):\n        new_body_positions = self.positions[:-1]\n        allowed_actions = []\n        for a in self.self_opposite_free_actions:\n            head_point = self.head.apply(a)\n            for n,body_point in  enumerate(new_body_positions):\n                if ([head_point.x,head_point.y] == [body_point.x,body_point.y]):\n                    break\n                elif(n+1==len(new_body_positions)):\n                    allowed_actions.append(a)\n                    break\n        return allowed_actions\n\n    def kick(self, last_action: Optional[Action] = None):\n        return self.__class__(\n            id=self.id,\n            step=self.step,\n            positions=[],\n            last_action=last_action,\n            reward=self.reward,\n        )\n\n    def apply(self, action: Action, food: List[\"Point\"]):\n        assert self.is_active\n\n        if self.last_action and action == self.last_action.opposite():\n            return self.kick(action)\n\n        head_position = self.head.apply(action)\n\n        body_positions = self.positions\n        if head_position not in food:\n            body_positions = body_positions[:-1]\n\n        if head_position in body_positions:\n            return self.kick(action)\n\n        new_goose = self.__class__(\n            id=self.id,\n            step=self.step + 1,\n            positions=[head_position] + body_positions,\n            last_action=action,\n        )\n\n        if is_starving_step(self.step):\n            new_goose.positions = new_goose.positions[:-1]\n            if not new_goose.positions:\n                return self.kick(action)\n\n        return new_goose\n","49917708":"class _Node:\n    def __init__(\n       self,\n       g1:Goose,\n       op_geese:List[Goose],\n       food:List[Point],\n       step:int,\n       remaining_steps:int,\n       max_sub_nodes:float=500\n    ):\n        self.g1 = g1\n        self.op_geese = op_geese\n        self.food = food\n        self.step = step\n        self.remaining_steps = remaining_steps\n        self.max_sub_nodes = max_sub_nodes\n        self.sub_nodes = [] # [(node,score),(node,score),...]\n        self.action_to_score = {}\n        self.score = self._calculate_score()\n        \n    def __repr__(self):\n        return f\"Node step={self.step}\"\n    \n    def best_actions(self):\n        if not self.action_to_score:\n            return []\n        max_score = max(self.action_to_score.values())\n        return [a for a, s in self.action_to_score.items() if s == max_score]\n\n    @staticmethod\n    def _reward_score(my,ops:List[Goose]):\n        my_reward = []\n        for op in ops:\n            if my.reward >= op.reward:\n                my_reward.append([1])\n            else:\n                my_reward.append([0])\n        return np.sum(my_reward)\/len(my_reward)\n\n    @staticmethod\n    def __estimate_space_score(g1:Goose,ops:List[Goose]):\n        head = g1.head\n        if g1.length > 1:\n            exp = [g1.positions[1]]\n        elif g1.last_action:\n            exp = [g1.head.apply(g1.last_action.opposite())]\n        else:\n            exp = []\n        occupied_points =  g1.positions\n        \n        for op in ops:\n            occupied_points += op.positions\n                \n        space ,total = 0,0\n        for x in head.nearby_points(radius=1):\n            if x not in exp:\n                total += 1\n                if x not in occupied_points:\n                    space += 1\n        return 0.5 * (space + 1)\/(total + 1)\n            \n    def _calculate_score(self):\n\n        my = self.g1\n        ops = self.op_geese\n        if self.remaining_steps <= 0:\n            return self._reward_score(my,ops)\n        \n        starving = is_starving_step(self.step)\n        my_actions = find_opponent_allowed_actions(my,ops,starving=starving)\n        ops_actions = []\n        for op in ops:\n            ops_actions.append(find_opponent_allowed_actions(op,[ x for x in ops if x.id != op.id] + [my] ,starving=starving)) \n        if not ops_actions:\n            if my_actions:\n                return 1\n            \n        my_reward = []\n            \n        if not my_actions:\n            for n,op_actions in enumerate(ops_actions):\n                if not op_actions:\n                    if self._reward_score(my,[ops[n]]):\n                        my_reward.append(1)\n                    else:\n                        my_reward.append(0)  \n                else:\n                    my_reward.append(0)                     \n                return np.sum(my_reward)\/len(my_reward)\n            \n            \n        num_sub_nodes = 1\n        for actions in  ops_actions:\n            if actions != []:\n                num_sub_nodes = num_sub_nodes * len(actions)\n                \n        num_nodes_per_sub_node = self.max_sub_nodes \/ num_sub_nodes\n        if num_nodes_per_sub_node < 1:\n            return self.__estimate_space_score(my,ops)\n        \n        food = self.food\n        my_action_to_scores = defaultdict(list)\n        ops_actions_after_modification = []\n        for op_actions in ops_actions:\n            if op_actions == []:\n                ops_actions_after_modification.append(['no_actions'])\n            else:\n                ops_actions_after_modification.append(op_actions)\n        \n        for a in itertools.product(my_actions,*ops_actions_after_modification):\n            next_my = my.apply(a[0],food)\n            next_heads = []\n            next_heads.append(next_my.head)\n            next_ops = []\n            for n,op in enumerate(ops):\n                if a[n+1] != 'no_actions':\n                    op.apply(a[n+1],food)\n                else:\n                    op.apply(a[0],food)\n                next_ops.append(op)\n                \n            for next_op in next_ops:\n                if next_op.is_active:\n                    next_heads.append(next_op.head)\n            next_food = [f for f in food if f not in next_heads]\n            \n            next_node = _Node(\n                g1=next_my,\n                op_geese = next_ops,\n                food=next_food,\n                step=self.step + 1,\n                remaining_steps=self.remaining_steps - 1,\n                max_sub_nodes=num_nodes_per_sub_node,\n            )\n            \n            score = next_node.score\n            self.sub_nodes.append((next_node, score))\n            my_action_to_scores[a[0]].append(score)\n         \n        for action, scores in my_action_to_scores.items():\n                self.action_to_score[action] = min(scores)\n        del next_node\n        return max(self.action_to_score.values())","3992517a":"\ndef find_last_action(goose_id: int, current_positions: List[Point]):\n    if not _PREVIOUS_STATES or not current_positions:\n        return\n\n    head = current_positions[0]\n    previous_state = _PREVIOUS_STATES[-1]\n    previous_goose = previous_state.geese[goose_id]\n    previous_head = previous_goose.head\n    if not previous_head:\n        return\n\n    a, d = previous_head.dirs_to(head)\n    assert d == 1\n    return a[0]\n","dac10700":"class State:\n    def __init__(self,obs,conf):\n        self.step = obs['step']\n        self.my_id = obs['index']\n        self.remaining_overage_time = obs[\"remainingOverageTime\"]\n        self.remaining_steps = conf[\"episodeSteps\"] - self.step - 1  \n        \n        assert conf[\"columns\"] == NUM_COLUMNS\n        assert conf[\"rows\"] == NUM_ROWS\n        assert conf[\"hunger_rate\"] == HUNGER_RATE\n        \n        self.board = Board()\n        def __flat_to_point(_x:int):\n            assert 0 <= _x < NUM_COLUMNS * NUM_ROWS\n            return _x % NUM_COLUMNS, NUM_ROWS - _x \/\/ NUM_COLUMNS - 1\n        \n        # FOOD\n        for p in obs[\"food\"]:\n            x, y = __flat_to_point(p)\n            self.board.add_food(x, y)\n        self.food = self.board.food_positions()\n        \n        # GEESE\n        self.geese = {}\n        for i, pp in enumerate(obs[\"geese\"]):\n            goose_positions = []\n            for p in pp:\n                x, y = __flat_to_point(p)\n                point = self.board[x, y]\n                goose_positions.append(point)\n            last_action = find_last_action(\n                goose_id=i, current_positions=goose_positions\n            )\n            goose = Goose(\n                id=i, positions=goose_positions, step=self.step, last_action=last_action\n            )\n            self.geese[i] = goose\n\n        self.my_goose = self.geese[self.my_id]\n        self.opponents = [\n            x for x in self.geese.values() if x.id != self.my_id and x.is_active\n        ]               \n    def __repr__(self):\n        return f\"State(step={self.step})\"\n\n    def next_action(self):\n        self_allowed_actions = self.my_goose.self_collision_free_actions\n        if not self_allowed_actions:\n            return random.choice(list(Action))\n        elif len(self_allowed_actions) == 1:\n            return self_allowed_actions[0]    \n\n        opponent_allowed_actions = find_opponent_allowed_actions(\n            self.my_goose, self.opponents, starving=is_starving_step(self.step)\n        )\n        \n        if not opponent_allowed_actions:\n            return random.choice(list(self_allowed_actions))\n        elif len(opponent_allowed_actions) == 1:\n            return opponent_allowed_actions[0]\n        \n        node = _Node(\n            self.my_goose,\n            self.opponents,\n            self.food,\n            step=self.step,\n            remaining_steps=self.remaining_steps,\n        )     \n        actions = node.best_actions()\n        if not actions:\n            return random.choice(list(opponent_allowed_actions))\n\n        action = sorted(\n            actions, key=lambda a: self.my_goose.head.apply(a).food_distance()\n        )[0]\n        del node\n        return action\n    \ndef create_state(obs, conf):\n    global _PREVIOUS_STATES\n\n    if _PREVIOUS_STATES and obs[\"step\"] != _PREVIOUS_STATES[-1].step + 1:\n        _PREVIOUS_STATES = []\n\n    state = State(obs, conf)\n\n    _PREVIOUS_STATES.append(state)\n    return state\n\n\ndef min_max_agent(obs, conf):\n    return str(create_state(obs, conf).next_action())\n\n        \n        ","2efd9b7d":"class Agent:\n    def __init__(self,engine,positions):\n        self.engine = engine\n        self.positions = positions\n    @property\n    def name(self):\n        if isinstance(self.engine,str):\n            return self.engine\n        elif callable(self.engine):\n            print('callable')\n            return self.engine.__module__+'-'+self.engine.__name__\n        else:\n            return \"Unknown\"\n        ","d5697054":"class Game:\n    def __init__(\n        self,\n        geese,\n        food,\n        episode_steps = 200,\n        act_timeout = 1000,\n        run_timeout = 120000,\n        columns = 11,\n        rows = 7,\n        hunger_rate = 40,\n        max_length = 99,\n        debug = True,\n    ):    \n        self.geese = geese\n        self.food = food\n        self.episode_steps = episode_steps\n        self.act_timeout = act_timeout\n        self.run_timeout = run_timeout\n        self.columns = columns\n        self.rows = rows\n        self.hunger_rate = hunger_rate\n        self.max_length = max_length\n        self.debug = debug\n\n        self.__post_init__()\n        \n    def __post_init__(self):\n        import kaggle_environments \n        self.min_food = len(self.food)\n        \n        env = kaggle_environments.make(\n            \"hungry_geese\",configuration=self.config,debug=self.debug\n        )\n        env.reset(num_agents=len(self.geese))\n        setattr(env, \"reset\", lambda _: None)\n        geese_data = env.state[0][\"observation\"][\"geese\"]\n        food_data = env.state[0][\"observation\"][\"food\"]\n        \n        for i, x in enumerate(self.geese):\n            geese_data[i] = x.positions\n\n        for i, x in enumerate(self.food):\n            food_data[i] = x\n        env.run([x.engine for x in self.geese])\n        self.env = env\n        \n    def show(self, width=400, height=600):\n        render = self.env.render(**{\"mode\": \"ipython\", \"width\": width, \"height\": height})\n    @property\n    def rewards(self):\n        return [g[\"reward\"] for g in self.env.steps[-1]]\n    \n    @property\n    def config(self):\n        return {\n            \"episodeSteps\": self.episode_steps,\n            \"actTimeout\": self.act_timeout,\n            \"runTimeout\": self.run_timeout,\n            \"columns\": self.columns,\n            \"rows\": self.rows,\n            \"hunger_rate\": self.hunger_rate,\n            \"min_food\": self.min_food,\n            \"max_length\": self.max_length,\n        }\n    ","c2af8a4c":"TestAgent = min_max_agent\ng1 = [49, 60, 61]\ng2 = [12, 11, 22]\ng3 = [40, 41, 42]\ng4 = [50, 51, 52]\n\ngame = Game(\n      geese=[\n          Agent(engine=TestAgent,positions=g1),\n          Agent(engine='greedy',positions=g2),\n          Agent(engine='greedy',positions=g3),\n          Agent(engine='greedy',positions=g3),\n\n      ],\n    food = [47,0],\n    episode_steps=30,\n)\ngame.show()","bfe6b8aa":"\"\"\"\"\"import kaggle_environments \nenv = kaggle_environments.make(\"hungry_geese\",debug=True)\nenv.run([min_max_agent,'greedy','greedy','greedy'])\"\"\"\"\"\n","13569a8a":"# Goose class","9a7cacf2":"# Board class","23e76380":"# Point class","f7282583":"# Agent & Game class","75c4eead":"# State class","398ae510":"# Node class","d43f8ed5":"# Action class","215a9b20":"**This kernel was copied from [MinMax.Goose Go kernel](http:\/\/https:\/\/www.kaggle.com\/egrehbbt\/minmax-goose-go) so please give it upvoit.**\n\n**In the previous kernel, the agent used to play against one opponent, now it plays against more than one opponent**\n**The only problem here is that the minimax algorithm takes time to get the action out**"}}