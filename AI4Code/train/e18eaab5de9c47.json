{"cell_type":{"2f17ee22":"code","b8a8fee0":"code","7fad2f81":"code","ec2fa526":"code","5c033e4d":"code","6638581b":"code","9cfefede":"code","39722330":"code","b3c77876":"code","1096a00c":"code","6a604c92":"code","5ca60333":"code","46e02a70":"code","71bf8dd9":"code","5bd8bbe3":"code","2b5244a8":"code","1a643699":"code","d9317e54":"code","d4e65b6a":"code","4a354ee4":"code","cae6d818":"code","da034152":"code","9961786c":"code","c69c4db5":"code","dcfa5495":"code","fd20e111":"markdown","4d2b9b31":"markdown","ca745fd2":"markdown"},"source":{"2f17ee22":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b8a8fee0":"import numpy as np\nimport pandas as pd\n\n# Visualization\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nimport seaborn as sns\n\n# sklearn for feature extraction & modeling\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.externals import joblib\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n# Iteratively read files\nimport glob\nimport os\n\n# For displaying images in ipython\nimport seaborn as sns\nsns.set(color_codes = True)\n%matplotlib inline","7fad2f81":"df = pd.read_csv(\"\/kaggle\/input\/food-com-recipes-and-user-interactions\/RAW_interactions.csv\")","ec2fa526":"print(df.shape)\ndf.head()","5c033e4d":"df[\"count\"] = [1] * len(df)\ndf.head()","6638581b":"# pivot_table = df.pivot_table(values = \"count\" , index = \"recipe_id\" , columns = \"rating\", aggfunc= np.sum,\n#                             fill_value = 0)","9cfefede":"# pivot_table.head(n=4)","39722330":"# pivot_table[\"Total Rating\"] = pivot_table.apply(lambda x : np.sum(x),axis = 1)","b3c77876":"# pivot_table.head()","1096a00c":"df[\"rating\"].value_counts()","6a604c92":"df = df.dropna()\ndf = df[df[\"rating\"] !=0]\ndf.shape","5ca60333":"df[\"rating\"].value_counts()","46e02a70":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","71bf8dd9":"def create_wordcloud(dframe):\n    unique_ratings = dframe[\"rating\"].unique()\n    # Create stopword list:\n    stopwords = set(STOPWORDS)\n    for rating in unique_ratings:\n        temp_text = dframe[dframe[\"rating\"]== rating][\"review\"]\n        collapsed_temp_text = temp_text.str.cat(sep=' ')\n        \n        print(\"Word Cloud for Rating: %s\"%(rating))\n\n        # Generate a word cloud image\n        wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\",max_words=50).generate(collapsed_temp_text)\n\n        # Display the generated image:\n        # the matplotlib way:1\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis(\"off\")\n        plt.show()","5bd8bbe3":"create_wordcloud(dframe = df.iloc[0:1000,:])","2b5244a8":"# Building Pipeline for raw text transformation\nclf = Pipeline([\n    ('vect', CountVectorizer(stop_words= \"english\")),\n    ('tfidf', TfidfTransformer()),\n    ('classifier', MultinomialNB(\n                    fit_prior=True, class_prior=None)),\n    ])","1a643699":"X_train, X_test, y_train, y_test = train_test_split(df[\"review\"][0:100000]\n                                                    , df[\"rating\"][0:100000],random_state = 42,\n                                                   test_size = 0.20)\nX_train.shape,X_test.shape,y_train.shape","d9317e54":"model = clf.fit(X_train , y_train)","d4e65b6a":"print(\"Accuracy of Prediction on Test Data: %s\"%model.score(X_test,y_test))","4a354ee4":"# Building Pipeline for raw text transformation\nclf = Pipeline([\n    ('vect', CountVectorizer(stop_words= \"english\")),\n    ('tfidf', TfidfTransformer()),\n    ('classifier', RandomForestClassifier()),\n    ])","cae6d818":"X_train, X_test, y_train, y_test = train_test_split(df[\"review\"][0:100000]\n                                                    , df[\"rating\"][0:100000],random_state = 42,\n                                                   test_size = 0.20)\nX_train.shape,X_test.shape,y_train.shape","da034152":"model = clf.fit(X_train , y_train)","9961786c":"print(\"Accuracy of Prediction on Test Data: %s\"%model.score(X_test,y_test))","c69c4db5":"param_grid = {\n    'classifier__criterion': [\"gini\",\"entropy\"],\n    #'classifier__max_features': [\"auto\",\"sqrt\",\"log2\"],\n    'classifier__max_depth':[4,6],\n    'classifier__n_estimators':[100,150,200]\n}\n\ngrid_search = GridSearchCV(clf, param_grid, cv=3, iid=False,verbose = 1,n_jobs= -1)\ngrid_search.fit(X_train, y_train)","dcfa5495":"print(\"Accuracy of Prediction on Test Data: %s\"%grid_search.score(X_test,y_test))","fd20e111":"**Predict Rating of recipe basis the Review given by User**","4d2b9b31":"**Using Random Forest Classifier**","ca745fd2":"**Hyper Parameter Tuning**"}}