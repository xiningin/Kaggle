{"cell_type":{"5cdf0059":"code","22c11b16":"code","2c7a081e":"code","622840fa":"code","0cca64b0":"code","5cdde245":"code","d81e0ab3":"code","403dd8b0":"code","1544fd5d":"code","3d9b3f07":"code","21e65dc0":"code","80a10db4":"code","bbbc19bf":"code","5eee5149":"code","791066ef":"code","be9892e6":"code","a2bea81f":"code","8405c261":"code","5ef6d1d1":"code","c3f5ee2b":"code","845d7f99":"code","0ceba7d0":"code","92295c81":"code","0f56dad3":"code","015e9f35":"code","78eea611":"code","5a5e52c9":"code","e078ba9e":"code","ed06c8dc":"code","fdd9721f":"code","c42ec944":"code","86bbe901":"code","36d763c3":"code","9d59ad08":"code","8b1a3330":"code","4d822121":"code","f1eacbd2":"code","ded50d1b":"code","57fdc120":"code","efffc1a2":"code","df527612":"code","a629904e":"code","c5ac59b9":"code","bf4bf329":"code","1383c64d":"code","53d4cd75":"code","7318c3c0":"code","435b8be0":"code","8dece6c3":"code","9a45f0a7":"code","1426d432":"code","54fb7703":"code","0d88f17a":"code","3fb37092":"code","da7b947c":"code","72a5c8ed":"code","97019fcb":"code","1a0436be":"code","430df347":"code","9c29dfee":"code","9e8ebdb2":"code","383ae084":"code","6d313d53":"code","af73c47e":"code","06ece6f8":"code","6825c978":"code","8d37a91d":"code","d9550622":"code","f913a7be":"code","b3e30321":"code","e4eaab68":"code","8bcf7c1d":"code","049d281d":"code","7f3c8941":"code","d9c6bc2e":"code","05e13c37":"code","8ac09c8f":"code","9186cd9b":"code","dc69a92d":"code","daaa1bc8":"code","7c4fe8c8":"code","33059c18":"code","576068ac":"code","4dde0096":"code","deda2744":"code","a839393b":"code","f4618b90":"code","71d81e02":"code","9114808a":"code","ef98b4c8":"code","f4a4e36c":"code","77c90266":"code","d511b6e6":"code","7163df6b":"markdown","3d76e194":"markdown","6c3d11c4":"markdown","03a57ef8":"markdown","2c044093":"markdown","e4edda88":"markdown","0808c1c0":"markdown","da30c39d":"markdown","72e6cf39":"markdown","cc8c612f":"markdown","6ef8ccf5":"markdown","a0dcb015":"markdown","577778a8":"markdown","48580f1c":"markdown","2e0fcfa9":"markdown","63577e62":"markdown","ff71b3c7":"markdown","de052b31":"markdown","4d3fdf83":"markdown","33894b79":"markdown","feab026a":"markdown","437ea160":"markdown","01c02df0":"markdown","b5c01774":"markdown"},"source":{"5cdf0059":"#importing necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import  DecisionTreeClassifier\nfrom scipy.stats import zscore\n\n%matplotlib inline","22c11b16":"#reading the data-pandas dataframe\nbankdata=pd.read_csv(\"\/kaggle\/input\/portuguese-bank-marketing-data-set\/bank-full.csv\",sep=';')\nbankdata.head() #first 5 records of file for sample","2c7a081e":"print(\"Shape\",bankdata.shape) #Shape- no of rows and columns\nprint(\"Size\",bankdata.size) #Size- number of elements in the data file","622840fa":"bankdata.info() #file attributes and metadata details","0cca64b0":"for col in bankdata.columns:\n    if bankdata[col].dtype=='object':\n        bankdata[col]= pd.Categorical(bankdata[col])\nbankdata =bankdata.rename(columns={'y': 'Target'})","5cdde245":"bankdata.info()","d81e0ab3":"# checking for null values in the files\nbankdata.isna().sum()","403dd8b0":"bankdata.describe() # Summary of numerical attributes of the file","1544fd5d":"bankdata.head(20) #check data for anamolies","3d9b3f07":"# Missing values and categorical data treatment with convenient data for analysis\n\nreplace_struct={\"marital\": {\"single\":0 ,\"married\":1,\"divorced\":2},\n                \"contact\": {\"unknown\":0,\"telephone\":1,\"cellular\":2},\n                \"poutcome\":{\"other\":-1,\"unknown\":0,\"success\":1,\"failure\":2},\n                \"month\": {\"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\"jul\":7,\"aug\":8,\"sep\":9,\"oct\":10,\"nov\":11,\"dec\":12},\n                \"default\":{\"yes\":1, \"no\":0},\n                \"loan\":{\"yes\":1, \"no\":0},\n                \"housing\":{\"yes\":1, \"no\":0},\n                \"Target\": {\"no\":0,\"yes\":1}\n                }\n                \ndf1=bankdata.replace(replace_struct)\ndf1","21e65dc0":"#checking the correlation between few columns of interest\ncorr_data= bankdata[['age','balance','day','duration','campaign','pdays','previous','Target']]\ncorr_data.corr()","80a10db4":"df1.corr() # checking correlation between data on missing values and relevant data replacement","bbbc19bf":"# checking the correlation \ncorr_data= df1[['age','balance','duration','campaign','month','previous','Target']]\ncorr_data.corr()","5eee5149":"# correlation matrix\/ graph\nplt.figure(figsize=(10,8))\nsns.heatmap(corr_data.corr(), annot=True, fmt='0.3f', center=0,linewidths=.5)","791066ef":"#checking for outliers\nplt.figure(figsize=(20,6))\nplt.subplot(1,2,1) \nplt.title('age')\nplt.boxplot(df1['age'])\nplt.subplot(1,2,2)\nplt.title('balance')\nplt.boxplot(df1['balance'])","be9892e6":"plt.figure(figsize=(20,6))\nplt.subplot(1,2,1) \nplt.title('duration')\nplt.boxplot(df1['duration'])\nplt.subplot(1,2,2)\nplt.title('campaign')\nplt.boxplot(df1['campaign'])","a2bea81f":"df1['balance_zscore']=df1['balance']","8405c261":"df1","5ef6d1d1":"df1['balance_zscore']=zscore(df1['balance_zscore'])","c3f5ee2b":"df1.sample(12)","845d7f99":"df1=df1.drop(df1[(df1['balance_zscore']>3)|(df1['balance_zscore']<-3)].index, axis=0, inplace=False)","0ceba7d0":"print(df1.shape)","92295c81":"corr_data= df1[['age','balance','duration','campaign','month','previous','Target']]\nprint(corr_data.corr())\nplt.figure(figsize=(10,8))\nsns.heatmap(corr_data.corr(), annot=True, fmt='0.3f', center=0,linewidths=.5)","0f56dad3":"plt.style.use('ggplot')\nplt.figure(figsize=(20,6))\nplt.subplot(1,2,1) \nplt.title('age')\nplt.hist(df1['age'],bins=8)\nplt.subplot(1,2,2)\nplt.title('balance')\nplt.hist(df1['balance'],bins=8)","015e9f35":"plt.figure(figsize=(20,6))\nplt.subplot(1,2,1) \nplt.title('duration')\nplt.hist(df1['duration'])\nplt.subplot(1,2,2)\nplt.title('campaign')\nplt.hist(df1['campaign'])","78eea611":"df1['campaign'].describe()","5a5e52c9":"df1['duration'].describe()","e078ba9e":"sns.distplot(df1['month'])","ed06c8dc":"sns.scatterplot(x='age',y='balance',data=df1)","fdd9721f":"plt.figure(figsize=(8,8))\nsns.scatterplot(x='age',y='balance', data=df1, hue='Target')","c42ec944":"plt.figure(figsize=(8,8))\n \nsns.countplot(x='poutcome', hue='Target' , data=df1)","86bbe901":"df2=df1.drop('balance_zscore',axis=1 )","36d763c3":"df2","9d59ad08":"sns.countplot(x='default', hue='Target' , data=df2) #drop default","8b1a3330":"df2=df2.drop('default',axis=1)","4d822121":"df2","f1eacbd2":"sns.countplot(x='loan', hue='Target' , data=df2)","ded50d1b":"sns.countplot(x='housing', hue='Target' , data=df2)","57fdc120":"sns.countplot(x='contact', hue='Target' , data=df2)","efffc1a2":"plt.figure(figsize=(6,8))\nsns.countplot(x='month', hue='Target' , data=df2)","df527612":"plt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nsns.barplot(x='month',y='duration' , data=df1)\nplt.subplot(1,2,2)\nsns.barplot(x='month',y='duration', hue='Target', data=df1)","a629904e":"plt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nsns.barplot(x='month',y='campaign' , data=df1)\nplt.subplot(1,2,2)\nsns.barplot(x='month',y='campaign', hue='Target', data=df1)","c5ac59b9":"print(df2.shape)\ndf2=df2.drop(df2[df2['education']=='unknown'].index, axis=0)\nprint(df2.shape)","bf4bf329":"df2['education'].unique()","1383c64d":"plt.figure(figsize=(16,8))\nsns.countplot(x='job', hue='Target' , data=df2) # can drop unknown values","53d4cd75":"print(df2.shape)\ndf2=df2.drop(df2[df2['job']=='unknown'].index, axis=0)\nprint(df2.shape)\ndf2['job'].unique()","7318c3c0":"plt.figure(figsize=(10,5))\nsns.countplot(x='marital', hue='Target' , data=df2)","435b8be0":"plt.figure(figsize=(20,5))\nsns.barplot(x='day', y='duration' ,hue='Target' , data=df2)","8dece6c3":"plt.figure(figsize=(8,8))\nsns.scatterplot(x='campaign',y='duration', data=df1, hue='Target')","9a45f0a7":"df2","1426d432":"df2=df2.drop(['pdays','poutcome'],axis=1) #not significant in classifying the customer","54fb7703":"df2.shape","0d88f17a":"oneHotcode =['job','education']\ndf2=pd.get_dummies(df2,columns=oneHotcode)","3fb37092":"df2.shape","da7b947c":"bankdataset=df2.drop(['job_unknown','education_unknown'],axis=1) \nbankdataset.shape","72a5c8ed":"bankdataset.columns","97019fcb":"x=bankdataset.drop(['Target'], axis=1)\nY=bankdataset['Target']\nx_train, x_test, Y_train, Y_test = train_test_split(x,Y, train_size = 0.7, test_size = 0.3, random_state = 1)","1a0436be":"LogRegModel= LogisticRegression(solver='sag',max_iter=10000)\nLogRegModel.fit(x_train,Y_train)\nprint(LogRegModel.score(x_train, Y_train))\nprint(LogRegModel.score(x_test, Y_test))","430df347":"LogRegModel= LogisticRegression(solver='lbfgs', max_iter=10000)\nLogRegModel.fit(x_train,Y_train)\nprint(LogRegModel.score(x_train, Y_train))\nprint(LogRegModel.score(x_test, Y_test))","9c29dfee":"LogRegModel= LogisticRegression(solver='liblinear')\nLogRegModel.fit(x_train,Y_train)\nprint(LogRegModel.score(x_train, Y_train))\nprint(LogRegModel.score(x_test, Y_test))","9e8ebdb2":"pred=LogRegModel.predict(x_test)\nprint(LogRegModel.intercept_)\nprint(LogRegModel.coef_)\nConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(ConfMat_DF, annot=True )","383ae084":"#AUC ROC curve\nlogit_roc_auc = roc_auc_score(Y_test,pred)\nfpr, tpr, thresholds = roc_curve(Y_test, LogRegModel.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()\nauc_score = metrics.roc_auc_score(Y_test, LogRegModel.predict_proba(x_test)[:,1])\nprint(\"Logistic Regression AUC Score:\",auc_score)\n","6d313d53":"myList = list(range(1,200))\n\n# subsetting just the odd ones\nneighbors = list(filter(lambda x: x % 2 != 0, myList))\n# empty list that will hold accuracy scores\nac_scores = []\nrl_scores =[]\n\n# perform accuracy metrics for values from 1,3,5....19\nfor k in neighbors:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train, Y_train)\n    # predict the response\n    Y_pred = knn.predict(x_test)\n    # evaluate accuracy\n    scores = accuracy_score(Y_test, Y_pred)\n    ac_scores.append(scores)\n   # changing to misclassification error\nMSE = [1 - x for x in ac_scores]\n\n# determining best k\noptimal_k = neighbors[MSE.index(min(MSE))]\nprint(\"The optimal number of neighbors is %d\" % optimal_k)","af73c47e":"KNNModel = KNeighborsClassifier(n_neighbors = 9)\n\n# fitting the model\nKNNModel.fit(x_train,Y_train)\n\n# predict the response\npred = KNNModel.predict(x_test)\n\n# evaluate accuracy\n \nprint(KNNModel.score(x_test, Y_test))\n","06ece6f8":"KNNModel = KNeighborsClassifier(n_neighbors = 23)\n\n# fitting the model\nKNNModel.fit(x_train,Y_train)\n\n# predict the response\npred = KNNModel.predict(x_test)\n\n# evaluate accuracy\n \nprint(KNNModel.score(x_test, Y_test))","6825c978":"KNNModel = KNeighborsClassifier(n_neighbors = 41)\n\n# fitting the model\nKNNModel.fit(x_train,Y_train)\n\n# predict the response\npred = KNNModel.predict(x_test)\n\n# evaluate accuracy\n \nprint(KNNModel.score(x_test, Y_test))","8d37a91d":"KNNModel = KNeighborsClassifier(n_neighbors =95)\n\n# fitting the model\nKNNModel.fit(x_train,Y_train)\n\n# predict the response\npred = KNNModel.predict(x_test)\n\n# evaluate accuracy\n \nprint(KNNModel.score(x_test, Y_test))","d9550622":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True )","f913a7be":"knn_roc_auc = roc_auc_score(Y_test,pred)\nfpr, tpr, thresholds = roc_curve(Y_test, KNNModel.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='KNN (area = %0.2f)' % knn_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.savefig('KNN_ROC')\nplt.show()\nauc_score = metrics.roc_auc_score(Y_test, KNNModel.predict_proba(x_test)[:,1])\nprint(\"KNN AUC Score:\",auc_score)","b3e30321":"NBModel = GaussianNB()\nNBModel.fit(x_train, Y_train)\npred= NBModel.predict(x_test)\nprint(NBModel.score(x_train, Y_train))\nprint(NBModel.score(x_test, Y_test))","e4eaab68":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )","8bcf7c1d":"roc_auc = roc_auc_score(Y_test,pred)\nfpr, tpr, thresholds = roc_curve(Y_test, NBModel.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Naive Baye''s (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.savefig('Naive_ROC')\nplt.show()\nauc_score = metrics.roc_auc_score(Y_test, NBModel.predict_proba(x_test)[:,1])\nprint(\"Naive Bayes AUC Score:\",auc_score)\n","049d281d":"# Building a Support Vector Machine on train data\nSVCModel = SVC(C= .1, kernel='rbf', gamma= 'auto')\nSVCModel.fit(x_train, Y_train)\n\npred= SVCModel.predict(x_test)\n# check the accuracy on the training set\nprint(SVCModel.score(x_train, Y_train))\n# check the accuracy on the test set\nprint(SVCModel.score(x_test, Y_test))","7f3c8941":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )\n\n","d9c6bc2e":"dTree = DecisionTreeClassifier(criterion = 'gini', random_state=1)\ndTree.fit(x_train, Y_train)","05e13c37":"print(dTree.score(x_train, Y_train))\nprint(dTree.score(x_test, Y_test))","8ac09c8f":"dTreeR = DecisionTreeClassifier(criterion = 'gini', max_depth = 5, random_state=1)\n#(The importance of a feature is computed as the normalized total reduction of the criterion brought by that feature. \n#It is also known as the Gini importance )\n\ndTreeR.fit(x_train, Y_train)\nprint(dTreeR.score(x_train, Y_train))\nprint(dTreeR.score(x_test, Y_test))","9186cd9b":"# importance of features in the tree building \nprint (pd.DataFrame(dTreeR.feature_importances_, columns = [\"Imp\"], index = x_train.columns))","dc69a92d":"print(dTreeR.score(x_test , Y_test))\npred = dTreeR.predict(x_test)\n\nConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )\n","daaa1bc8":"# Ensemble Techniques\n\nbgcl = BaggingClassifier(base_estimator=dTree, n_estimators=50,random_state=1)\n#bgcl = BaggingClassifier(n_estimators=50,random_state=1)\n\nbgcl = bgcl.fit(x_train, Y_train)\npred = bgcl.predict(x_test)\nprint(bgcl.score(x_test , Y_test))\n\n","7c4fe8c8":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )","33059c18":"bgcl = BaggingClassifier(base_estimator=dTreeR, n_estimators=50,random_state=1)\n#bgcl = BaggingClassifier(n_estimators=50,random_state=1)\n\nbgcl = bgcl.fit(x_train, Y_train)\npred = bgcl.predict(x_test)\nprint(bgcl.score(x_test , Y_test))\n","576068ac":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )","4dde0096":"bgcl = BaggingClassifier(base_estimator=LogRegModel, n_estimators=50,random_state=1)\n#bgcl = BaggingClassifier(n_estimators=50,random_state=1)\n\nbgcl = bgcl.fit(x_train, Y_train)\npred = bgcl.predict(x_test)\nprint(bgcl.score(x_test , Y_test))\n","deda2744":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )","a839393b":"abcl = AdaBoostClassifier(base_estimator=dTree,n_estimators=30, random_state=1)\nabcl = abcl.fit(x_train, Y_train)\npred = abcl.predict(x_test)\nprint(abcl.score(x_test , Y_test))","f4618b90":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )","71d81e02":"abcl = AdaBoostClassifier(base_estimator=dTreeR,n_estimators=30, random_state=1)\nabcl = abcl.fit(x_train, Y_train)\npred = abcl.predict(x_test)\nprint(abcl.score(x_test , Y_test))","9114808a":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )","ef98b4c8":"abcl = AdaBoostClassifier(base_estimator=LogRegModel,n_estimators=30, random_state=1)\nabcl = abcl.fit(x_train, Y_train)\npred = abcl.predict(x_test)\nprint(abcl.score(x_test , Y_test))","f4a4e36c":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )","77c90266":"rfcl = RandomForestClassifier(n_estimators = 50, random_state=1,max_depth=5)\nrfcl = rfcl.fit(x_train, Y_train)\npred= rfcl.predict(x_test)\nprint(rfcl.score(x_test , Y_test))","d511b6e6":"ConfMat=metrics.confusion_matrix(Y_test, pred, labels=[1, 0])\nprint (ConfMat)\n\nConfMat_DF = pd.DataFrame(ConfMat, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,4))\nsns.heatmap(ConfMat_DF, annot=True, cmap='GnBu',center=0 )","7163df6b":"Outlier treatment","3d76e194":"#### File Attributes\n1. age - Numerical Variable - Customers' Age\n2. job - Categorical Variable - Customer's Job Type\n3. marital - Categorical Variable - Customer's Marital Status\n4. education - Categorical Variable - Customer's Education Level\n5. default  - Categorical Variable - Customer's credit default status\n6. balance  - Numerical Variable - Customer's average yearly balance in Euros (numeric)\n7. housing - Categorical Variable - Customer's housing loan status \n8. loan - Categorical Variable - Customer's housing personal loan status   loan?\n9. contact - Categorical Variable - Customer's prferbale communication mode\n10. day - Numerical Variable -  last contact day of the month \n11. month  - Numerical Variable -  last contact month of year\n12. duration - Numerical Variable -  last call duration, in seconds\n13. campaign - Numerical Variable - number of calls performed during the campaign \n14. pdays - Numerical Variable - number of days that passed by after the client was last contacted from a previous campaign\n15. previous - Numerical Variable -  number of calls performed before this campaign and for this client\n16. poutcome - Categorical Variable - outcome of the previous marketing campaign\n17. target - Binary Variable - has the client subscribed a term deposit? (binary: \"yes\",\"no\") \n ","6c3d11c4":"The above DTree model is overfitting, and hence we regularize it by setting the maximum depth of DTree for model","03a57ef8":"![](http:\/\/)By applying logistic regression or Decision Tree algorithms, classification and estimation model were built with 89.5% score. With either of these models, the bank will be able to predict if the customer would subscribe to the product as a response to the Bank's telemarketing campaign before calling this customer. ","2c044093":"From the scatter plot, we could infer that the customers who subscribed to products were contacted between 2-10 times, and almost call duration ranged between some 60 sec to 2000 seconds","e4edda88":"Age is normally distributed, customers range between age of 18 and 90.However, a majority of customers are in the age group of 30-45.\n\nBalance is skewed, after dropping outliers in balance, the range of balance is negative, giving a range from -2500 to 12000 euros. ","0808c1c0":"From the plot, we can see that most of the contact were made in month of may","da30c39d":"According to the correlation heatmap, we see that there are no great correlation between dependent variables and a Target variable, however, we see that there is some good correlation between Target and duration of contact, also previous contact variable and balance have some visible impact on the target variable.","72e6cf39":"From the above graph, we see that there existed customers among all age groups, however. we see that most concentrated with age between 25-65.\nAlso, the balance were more for customers of age group between 30-60, and above 60 held low balance, probably because they retired from work","cc8c612f":"#### Univariate Analysis","6ef8ccf5":"#### Data Description\nThe data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. ","a0dcb015":"#### Support Vector Machine\nSVM is an supervised learning model that analyzes the linearly spearable planes and helps resolve the classification problems and regression problems.\nhey are widely used for Classification problems.","577778a8":"### Objective: To classify the customers who may subscribe to the products on telemarketing campaign","48580f1c":"#### Decision Trees\nDecision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.","2e0fcfa9":"Though there are no null values or NaN values in the file, we see that are some fields with 'unknown' value, that needs to be treated","63577e62":"#### Bi-variate and Multivariate Analysis ","ff71b3c7":"#### KNN Model\nKNN stands for K Nearest Neighbour ALogorithm, its one of the classification methods that predicts the output variable based on the nearest dependent variables","de052b31":"We see that few variables are of type object and we change them to categorical for further analysis","4d3fdf83":"We see that there are many outlieres in balance, and we need to normalize the data.","33894b79":"### EDA, Outliers Treatment and Modelling","feab026a":"As observed from the box plot and summary, the duration of contact has a median of around 180 seconds, the left-skewed boxplot indicates that most calls are relatively short.\n\nThe distribution of campagin, most of the customers have been reached by the bank for one to three times,some clients have been contacted by as high as 63 times, which is not normal. ","437ea160":"##                          Bank Telemarketing Campaign Case Study","01c02df0":"From the Scatterplot, there is no clear relationship between age and balance.\nNevertheless, over the age of 60, customers tend to have a significantly lower balance.","b5c01774":"#### Logistic Regression Model\nLogistic Regression is a supervised learning model that predicts a non linear relationship between the dependent and independent variables. It is classification technique"}}