{"cell_type":{"fb100e2d":"code","b42e6bc8":"code","b791e2ef":"code","a7abf306":"code","5c0281f1":"code","92d83b67":"code","5d63fa08":"code","ecfb51ae":"code","04b42b79":"code","23f95ed1":"code","f1daefb4":"code","fb05597c":"code","356f2373":"code","e6145dca":"code","acf0b2b0":"code","ff62a821":"code","a0c5954d":"code","1621bd8c":"code","22e8f137":"markdown","511d858c":"markdown","8dc6c2e0":"markdown","f958f04d":"markdown","b5461c15":"markdown"},"source":{"fb100e2d":"import cv2\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom tensorflow.keras.callbacks import *","b42e6bc8":"imagePaths = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/'):\n    for filename in filenames:\n        if (filename[-3:] == 'png'):\n            imagePaths.append(os.path.join(dirname, filename))","b791e2ef":"imgSize = 224","a7abf306":"X = []\nY = []\nhmap = {'Viral Pneumonia': 'Pneumonia', 'NORMAL': 'Normal', 'COVID-19': 'Covid-19'}\nfor imagePath in tqdm(imagePaths):\n    label = imagePath.split(os.path.sep)[-2]\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (imgSize, imgSize))\n\n    X.append(image)\n    Y.append(hmap[label])\n    ","5c0281f1":"print('Covid-19:',Y.count('Covid-19'))\nprint('Normal:',Y.count('Normal'))\nprint('Pneumonia: ',Y.count('Pneumonia'))","92d83b67":"le = LabelEncoder()\nY = le.fit_transform(Y)\nY = to_categorical(Y)","5d63fa08":"(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size=0.20, stratify=Y, random_state=42)","ecfb51ae":"del X\ndel Y","04b42b79":"print(len(trainY))\nntimes = 6\ntrainY = trainY.tolist()\nfor i in tqdm(range(len(trainX))):\n    if (trainY[i][0] == 1):\n        trainX += [trainX[i]]*ntimes\n        trainY += [trainY[i]]*ntimes\n        \ntrainY = np.array(trainY)\n\nprint(len(trainY))","23f95ed1":"trainX = np.array(trainX).astype('float16')\/255\n\ntestX = np.array(testX).astype('float16')\/255","f1daefb4":"trainAug = ImageDataGenerator(rotation_range=20, horizontal_flip = True,fill_mode=\"nearest\")","fb05597c":"best_val_acc = 0\nbest_train_acc = 0\ndef saveModel(epoch,logs):\n    val_acc = logs['val_accuracy']\n    train_acc = logs['accuracy']\n    global best_val_acc\n    global best_train_acc\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        model.save('model.h5')\n    elif val_acc == best_val_acc:\n        if train_acc > best_train_acc:\n            best_train_acc= train_acc\n            model.save('model.h5')","356f2373":"baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(imgSize, imgSize, 3)))\nheadModel = baseModel.output\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(64, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(3, activation=\"softmax\")(headModel)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\nfor layer in baseModel.layers:\n    layer.trainable = False","e6145dca":"INIT_LR = 3e-4\nEPOCHS = 50\nBS = 32\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\nH = model.fit_generator(\n    trainAug.flow(trainX, trainY, batch_size=BS),\n    steps_per_epoch=len(trainX) \/\/ BS,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) \/\/ BS,\n    callbacks= [LambdaCallback(on_epoch_end=saveModel),\n#              EarlyStopping(monitor='val_accuracy', patience=3),\n#              ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,patience=2),\n              ],\n    epochs=EPOCHS)","acf0b2b0":"N = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\")","ff62a821":"model= load_model('model.h5')","a0c5954d":"predIdxs = model.predict(trainX, batch_size=BS)\npredIdxs = np.argmax(predIdxs, axis=1)\nprint(classification_report(trainY.argmax(axis=1), predIdxs, target_names=le.classes_, digits = 5))","1621bd8c":"predIdxs = model.predict(testX, batch_size=BS)\npredIdxs = np.argmax(predIdxs, axis=1)\nprint(classification_report(testY.argmax(axis=1), predIdxs, target_names=le.classes_, digits = 5))","22e8f137":"# Result on train","511d858c":"# Result on test","8dc6c2e0":"# Train model","f958f04d":"# MODEL","b5461c15":"# Load best model"}}