{"cell_type":{"22764883":"code","a43687e4":"code","1d09356f":"code","145329b2":"code","9c24132d":"code","f45431ed":"code","a983a2dc":"code","cd306a20":"code","3e56cc03":"code","a59fee3d":"code","8fa2304a":"code","7b4305ea":"code","da1d327f":"code","c94997fa":"code","5d762caf":"code","e95731b6":"code","e1c46444":"code","3305a8aa":"code","47bfa760":"code","88a9f18b":"code","b364b9a2":"code","d8cdb4be":"code","d0e38ed9":"code","06ad4df1":"code","233473cb":"code","263de4ab":"code","22cf9a2e":"code","f5c7991e":"code","38e9e255":"code","3e1b6b8d":"code","c8a5284a":"code","31b86c50":"markdown","db5c402f":"markdown","e09d4dfe":"markdown","189bd572":"markdown","4aa3bac4":"markdown","49ab6aa4":"markdown","8ebf28a3":"markdown","6ffe9d40":"markdown","002af9a1":"markdown","a4a600dc":"markdown","30ba7e50":"markdown","7a5d5f77":"markdown","66436d6d":"markdown"},"source":{"22764883":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a43687e4":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","1d09356f":"titanic_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntitanic_test = pd.read_csv('..\/input\/titanic\/test.csv')","145329b2":"titanic_df.info()","9c24132d":"titanic_df.head()","f45431ed":"titanic_df.isnull().sum()","a983a2dc":"titanic_df.drop(columns=['Name', 'Cabin', 'Ticket'], inplace=True)","cd306a20":"titanic_df.fillna(titanic_df.median(), inplace=True)","3e56cc03":"titanic_df['Family'] = titanic_df['SibSp'] + titanic_df['Parch']\ntitanic_df.drop(columns=['SibSp', 'Parch'], inplace=True)","a59fee3d":"titanic_df.describe().transpose()","8fa2304a":"sns.pairplot(data=titanic_df);","7b4305ea":"sns.countplot(data=titanic_df, x='Survived');","da1d327f":"sns.countplot(data=titanic_df, hue='Survived', x='Sex');","c94997fa":"sns.displot(data=titanic_df, x='Age', kind='kde', hue='Survived');","5d762caf":"sns.countplot(data=titanic_df, x='Pclass', hue='Survived');","e95731b6":"sns.countplot(data=titanic_df, x='Family', hue='Survived');","e1c46444":"sns.countplot(data=titanic_df, x='Embarked', hue='Survived');","3305a8aa":"from sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","47bfa760":"X = titanic_df.drop(columns=['Survived'])\ny = titanic_df['Survived']","88a9f18b":"#Creating dummy columns for category columns\ncateg_col = ['Sex', 'Pclass', 'Family', 'Embarked']\nX = pd.get_dummies(data=X, columns=categ_col, drop_first=True)","b364b9a2":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)","d8cdb4be":"# Fit the model on train\nmodel = LogisticRegression(solver=\"liblinear\")\nmodel.fit(X_train, y_train)\n#predict on test\ny_predict = model.predict(X_test)","d0e38ed9":"conf_matrix = metrics.confusion_matrix(y_test, y_predict, labels=[0,1])\nsns.heatmap(data=conf_matrix, cmap='coolwarm', annot=True);","06ad4df1":"#dropping the columns that are not required\ntitanic_test.drop(columns=['Name', 'Cabin', 'Ticket'], inplace=True)","233473cb":"#Creating the composite column\ntitanic_test['Family'] = titanic_test['SibSp'] + titanic_test['Parch']\ntitanic_test.drop(columns=['SibSp', 'Parch'], inplace=True)","263de4ab":"#Creating dummy columns for categorical data\ntitanic_test = pd.get_dummies(data=titanic_test, columns=categ_col, drop_first=True)","22cf9a2e":"# Checking for missing records\ntitanic_test.isnull().values.any()","f5c7991e":"#Filling the missing records\ntitanic_test.fillna(titanic_df.median(), inplace=True)","38e9e255":"#Fittng the model by taking the complete training data for training and predicting the output for test data\nmodel.fit(X,y)\npredection = model.predict(titanic_test)","3e1b6b8d":"#Creating the output dataframe and checking the format\noutput = pd.DataFrame({'PassengerId': titanic_test.PassengerId, 'Survived': predection})\noutput.head()","c8a5284a":"#Creating the csv for submission\noutput.to_csv('submission.csv', index=False)","31b86c50":"Visualizing the Sirvival distribution with respect to other metrices","db5c402f":"### Importing data","e09d4dfe":"Checking the null records in the dataframe.","189bd572":"### EDA and Preprossing","4aa3bac4":"## Final Prediction on Test Data","49ab6aa4":"### Bivariate analysis","8ebf28a3":"Assuming 'Parch' and 'SibSp' count are mutually exclusive. We can create a composite column 'Family' to represent the number of family members from 'SibSp' and 'Parch'.","6ffe9d40":"Checking the basic info of the dataframe.","002af9a1":"### Importing required libraries","a4a600dc":"### Building a logistic regression model","30ba7e50":"Let's check the first few records.","7a5d5f77":"We can drop the Cabin, Ticket and Name from Dataset as Name and Ticket is a PII and Cabin data is mostly missing (687 out of 891 missing). We will need to fill the missing data for age (177 out of 891 missing)","66436d6d":"Splitting the train data into train and test set"}}