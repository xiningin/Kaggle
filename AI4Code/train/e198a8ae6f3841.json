{"cell_type":{"a6d3d0cd":"code","f363079e":"code","e31db2ac":"code","70b2b5bd":"code","57455406":"code","56331cad":"code","cf9c2113":"code","ee928bd2":"code","d3c7b0e7":"code","f54314ac":"code","72c8c8f9":"code","a4d46379":"code","ed0212ec":"code","e684d06d":"code","9bcdb6bf":"code","bd8d8c22":"code","c7a039de":"code","5ed28d95":"code","d182c4ba":"code","d2b6883e":"code","d7fecaa5":"code","63728e55":"code","6a0b931b":"code","3c3b5ed6":"code","c86f3cc9":"code","57b21b78":"code","4308d2bd":"code","4d65eec2":"code","cf42131e":"code","ea47fb88":"code","d3aeb921":"code","30af3d00":"code","b465118e":"code","cbc4e798":"code","d0ddf474":"code","ef43a8d5":"code","00e98ee4":"code","1e8cac2f":"code","864a3c23":"code","93ccdcb9":"code","fbabcc70":"code","2c167d7d":"code","6d4dce1d":"code","61207fb3":"markdown","172acf5d":"markdown","6a64e860":"markdown","cbce17f4":"markdown","a80ea5b7":"markdown","07f1c62e":"markdown","fb4e978e":"markdown","4cdebeba":"markdown","8838542b":"markdown","078c5c7d":"markdown","f604e8c4":"markdown","ac26f2ce":"markdown","bf5bc2d2":"markdown","be47cdac":"markdown","e452a9e8":"markdown","90fad661":"markdown","9a98b67b":"markdown","f04792d7":"markdown","64e19889":"markdown","85bcc830":"markdown","1f3155a5":"markdown","3c0a2aa9":"markdown","4f9b4f6d":"markdown","5892f908":"markdown","750ca20c":"markdown","56e45308":"markdown","203164c1":"markdown","4af3e284":"markdown","40fdd99a":"markdown","9a6ac2c2":"markdown","c4bf4508":"markdown","0f58d29e":"markdown","bb043096":"markdown","728824de":"markdown"},"source":{"a6d3d0cd":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline\n\n# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import datasets","f363079e":"from tensorflow.keras.models import Sequential, load_model\n\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\n\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n\nfrom tensorflow.keras.utils import to_categorical","e31db2ac":"import cv2\nimport os\nimport glob\nimport gc\n\ndef lire_images(img_dir, xdim, ydim, nmax=5000) :\n    \"\"\" \n    Lit les images dans les sous r\u00e9pertoires de img_dir\n    nmax images lues dans chaque r\u00e9pertoire au maximum\n    Renvoie :\n    X : liste des images lues, matrices xdim*ydim\n    y : liste des labels num\u00e9riques\n    label : nombre de labels\n    label_names : liste des noms des r\u00e9pertoires lus\n    \"\"\"\n    label = 0\n    label_names = []\n    X = []\n    y=[]\n    for dirname in os.listdir(img_dir):\n        print(dirname)\n        label_names.append(dirname)\n        data_path = os.path.join(img_dir + \"\/\" + dirname,'*g')\n        files = glob.glob(data_path)\n        n=0\n        for f1 in files:\n            if n>nmax : break\n            img = cv2.imread(f1) # Lecture de l'image dans le repertoire\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Conversion couleur RGB\n            img = cv2.resize(img, (xdim,ydim)) # Redimensionnement de l'image\n            X.append(np.array(img)) # Conversion en tableau et ajout a la liste des images\n            y.append(label) # Ajout de l'etiquette de l'image a la liste des etiquettes\n            n=n+1\n        print(n,' images lues')\n        label = label+1\n    X = np.array(X)\n    y = np.array(y)\n    gc.collect() # R\u00e9cup\u00e9ration de m\u00e9moire\n    return X,y, label, label_names","70b2b5bd":"X,y,Nombre_classes,Classes = lire_images(\"..\/input\/cat-and-dog\/training_set\/training_set\", 224, 224, 1000)","57455406":"Nombre_classes","56331cad":"Classes","cf9c2113":"import random\nplt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    j = random.randint(0,len(X))\n    plt.axis('off')\n    plt.imshow(X[j])\n    plt.title(Classes[y[j]])","ee928bd2":"y = to_categorical(y)","d3c7b0e7":"y","f54314ac":"X.shape","72c8c8f9":"# Normalisation entre 0 et 1\nX = X \/ 255\nprint(X[0][0])","a4d46379":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","ed0212ec":"del X,y","e684d06d":"# R\u00e9seau convolutionnel simple\nmodel = Sequential()\nmodel.add(Conv2D(32, (5, 5), input_shape=(224, 224, 3), activation='relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\n#model.add(Dense(128, activation='relu'))\nmodel.add(Dense(Nombre_classes, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","9bcdb6bf":"model.summary()","bd8d8c22":"# Apprentissage\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, verbose=1)","c7a039de":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","5ed28d95":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","d182c4ba":"plot_scores(train)","d2b6883e":"# Prediction\ny_cnn = model.predict_classes(X_test)","d7fecaa5":"plt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        plt.title('%s \/ %s' % (Classes[y_cnn[j]], Classes[y_test[j].argmax(axis=-1)]))\n        i+=1","63728e55":"# Mod\u00e8le CNN plus profond\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(Nombre_classes, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","6a0b931b":"model.summary()","3c3b5ed6":"# Apprentissage\ntrain = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=1)\n\n# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","c86f3cc9":"plot_scores(train)","57b21b78":"model.save('mnist_cnn2.h5')","4308d2bd":"new_model = load_model('mnist_cnn2.h5')\nnew_model.summary()","4d65eec2":"scores = new_model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","cf42131e":"from tensorflow.keras.applications import VGG16","ea47fb88":"vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\nvgg16.trainable = False","d3aeb921":"vgg16.summary()","30af3d00":"model = Sequential()\nmodel.add(vgg16)\nmodel.add(Flatten())\nmodel.add(Dense(Nombre_classes, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","b465118e":"model.summary()","cbc4e798":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, verbose=1)","d0ddf474":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","ef43a8d5":"for i in range (len(vgg16.layers)):\n    print (i,vgg16.layers[i])","00e98ee4":"for layer in vgg16.layers[15:]:\n    layer.trainable=True\nfor layer in vgg16.layers[0:15]:\n    layer.trainable=False","1e8cac2f":"model = Sequential()\nmodel.add(vgg16)\nmodel.add(Flatten())\nmodel.add(Dense(Nombre_classes, activation='softmax'))\n\n# Compilation du mod\u00e8le\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","864a3c23":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, verbose=1)","93ccdcb9":"plot_scores(train)","fbabcc70":"y_cnn = model.predict_classes(X_test)","2c167d7d":"plt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j].argmax(axis=-1)) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        plt.title('%s \/ %s' % (Classes[y_cnn[j]], Classes[y_test[j].argmax(axis=-1)]))\n        i+=1","6d4dce1d":"from tensorflow.keras.applications import InceptionV3, ResNet50V2","61207fb3":"Pour installer Keras et Tensorflow sans GPU :","172acf5d":"On peut afficher la structure du mod\u00e8le :","6a64e860":"## Lecture des images","cbce17f4":"## Transfer learning","a80ea5b7":"Il existe plusieurs autres mod\u00e8les plus complexes :\nhttps:\/\/keras.io\/applications\/","07f1c62e":"On va utiliser un mod\u00e8le pr\u00e9d\u00e9fini dans Keras (VGG16) :","fb4e978e":"On ajoute des couches pour entra\u00eener le mod\u00e8le \u00e0 partir du dataset, sans modifier les poids existants du VGG16 :","4cdebeba":"On d\u00e9compose en ensemble d'apprentissage et de validation :","8838542b":"On peut ensuite utiliser le mod\u00e8le sans recommencer l'entra\u00eenement :","078c5c7d":"On utilise le dataset *Cat and Dog* : https:\/\/www.kaggle.com\/tongpython\/cat-and-dog","f604e8c4":"## Keras et Tensorflow","ac26f2ce":"## Exercices","bf5bc2d2":"On utilise les poids pr\u00e9-entra\u00een\u00e9s sur ImageNet (un million d'images)\nOn \"fige\" le r\u00e9seau VGG16, de mani\u00e8re \u00e0 ne pas refaire l'entra\u00eenement sur le dataset particulier","be47cdac":"Le mod\u00e8le entrain\u00e9 peut \u00eatre sauvegard\u00e9 :","e452a9e8":"L'apprentissage peut \u00eatre un peu long sans GPU ...","90fad661":"## Exercice : Tester le transfer learning avec des mod\u00e8les avanc\u00e9s","9a98b67b":"\nD\u00e9tection de cellules infect\u00e9es par la malaria :  \nhttps:\/\/www.kaggle.com\/iarunava\/cell-images-for-detecting-malaria\n\nCOVID (radiographies) : https:\/\/www.kaggle.com\/khoongweihao\/covid19-xray-dataset-train-test-sets\n\nCOVID (scanner) : https:\/\/www.kaggle.com\/drsurabhithorat\/covid-19-ct-scan-dataset\n\nD\u00e9tection de l'autisme : https:\/\/www.kaggle.com\/cihan063\/autism-image-data\n\nD\u00e9tection Alzheimer : https:\/\/www.kaggle.com\/legendahmed\/alzheimermridataset\n\nD\u00e9tection glaucome : https:\/\/www.kaggle.com\/sshikamaru\/glaucoma-detection\n\n\nLes Simpsons  \nhttps:\/\/www.kaggle.com\/alexattia\/the-simpsons-characters-dataset","f04792d7":"On d\u00e9finit une fonction pour afficher un graphique des scores :","64e19889":"Pour une installation locale :\npip install opencv-python\n","85bcc830":"On \"binarise\" la cible :","1f3155a5":"conda install -c conda-forge keras\nconda install -c conda-forge tensorflow ","3c0a2aa9":"## Initialisations","4f9b4f6d":"On va utiliser utiliser une couche convolutionnelle pour l'extraction des caract\u00e9ristiques, et une couche dense pour la classification :","5892f908":"## Mod\u00e8le CNN plus profond","750ca20c":"## Exercice d\u00e9geler tout le mod\u00e8le VGG16 sauf la premi\u00e8re couche (0)","56e45308":"On teste un mod\u00e8le avec deux couches convolutionnelles :","203164c1":"On affiche 50 images o\u00f9 l'algorithme s'est tromp\u00e9 :","4af3e284":"Pour installer la version GPU sous windows, cf https:\/\/medium.com\/@raza.shahzad\/setting-up-tensorflow-gpu-keras-in-conda-on-windows-10-75d4fd498198  \nSous Linux : http:\/\/deeplearning.lipingyang.org\/2017\/08\/01\/install-keras-with-tensorflow-backend\/  \nSous MacOS (avec GPU Nvidia) : https:\/\/blog.wenhaolee.com\/run-keras-on-mac-os-with-gpu\/","40fdd99a":"## Une couche convolutionnelle","9a6ac2c2":"On peut \"d\u00e9geler\" les derni\u00e8res couches :","c4bf4508":"Fonction permettant de lire des images dans des sous-r\u00e9pertoires :","0f58d29e":"On affiche des images al\u00e9atoirement :","bb043096":"On va lire toutes les images dans les sous r\u00e9pertoires du *training_set* :","728824de":"On observe un fort surapprentissage : la pertinence sur l'ensemble d'apprentissage est \u00e0 100%, mais beaucoup moins bonne sur l'ensemble de test ..."}}