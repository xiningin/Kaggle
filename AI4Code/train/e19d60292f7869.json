{"cell_type":{"fdfbfc6f":"code","fdecf168":"code","51bc1b14":"code","54a63837":"code","085d3eeb":"code","0210b3d8":"code","8abdcbf3":"code","35c6bf6f":"code","2b50db2a":"code","6f15ddd4":"code","e4e8a41a":"code","fbb9d33f":"code","b54c0493":"code","65d6a93b":"code","4d4d2cb5":"code","06da551e":"code","f8f1d197":"code","ef1b0060":"code","2c7be628":"code","3f8eb415":"code","86741a50":"code","31d81b20":"markdown","a6cd49fa":"markdown","10013173":"markdown","73e851dd":"markdown"},"source":{"fdfbfc6f":"import os\nimport numpy\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nimport statsmodels.api as sm \nfrom scipy.interpolate import interp1d\nimport datetime as dt\n\npd.set_option('max_columns', 50)\nplt.style.use('bmh')\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","fdecf168":"osj = os.path.join\nINPUT_DIR = '..\/input\/m5-forecasting-accuracy\/'\ntrain = pd.read_csv(osj(INPUT_DIR, 'sales_train_validation.csv'))\nprice = pd.read_csv(osj(INPUT_DIR, 'sell_prices.csv'))\ncalender = pd.read_csv(osj(INPUT_DIR, 'calendar.csv'))\n\nsample_submit = pd.read_csv(osj(INPUT_DIR, 'sample_submission.csv'))","51bc1b14":"calender['date'] = pd.to_datetime(calender['date'])","54a63837":"d_cols = [c for c in train.columns if 'd_' in c] # d_\u3067\u59cb\u307e\u308b\u65e5\u4ed8\u5217\u306e\u30ea\u30b9\u30c8","085d3eeb":"past_sales = train.set_index('id')[d_cols].T.merge(calender.set_index('d')['date'],\n                                                   left_index=True,\n                                                   right_index=True,\n                                                   validate='1:1').set_index('date')","0210b3d8":"def make_total_sales_lowess( p ):\n    total_sales = pd.DataFrame(p.sum(axis=1), columns=['total sales'])\n    \n    # \u30af\u30ea\u30b9\u30de\u30b9\u524a\u9664\n    total_sales_noXmas = total_sales.drop(index=[dt.datetime(2011,12,25), \n                                                 dt.datetime(2012,12,25), \n                                                 dt.datetime(2013,12,25), \n                                                 dt.datetime(2014,12,25), \n                                                 dt.datetime(2015,12,25)])\n\n    df = total_sales_noXmas\n    lowess = sm.nonparametric.lowess(df['total sales'], df.index, frac=.3) \n    lowess_x = list(zip(*lowess))[0] \n    lowess_y = list(zip(*lowess))[1] \n    \n    f = interp1d(lowess_x, lowess_y, bounds_error=False)\n    new_lowess_x = df.index\n    new_lowess_y = f(new_lowess_x)\n    \n    total_sales_lowess = total_sales_noXmas\n    total_sales_lowess['lowess'] = new_lowess_y\n    total_sales_lowess['total sales-lowess'] = total_sales_lowess['total sales'] - total_sales_lowess['lowess']\n    \n    return total_sales_lowess","8abdcbf3":"total_sales_lowess = make_total_sales_lowess( past_sales )","35c6bf6f":"y_bt = -5000\ny_up = 10000\nstore_list = price['store_id'].unique()\nfor store in store_list :\n    total_sales_lowess_tmp = make_total_sales_lowess( past_sales.loc[:, past_sales.columns.str.contains(store)] )\n    total_sales_lowess_tmp.plot(figsize=(15, 5), alpha=0.8, ylim=[y_bt, y_up],title=store)","2b50db2a":"########################### Read base submission\n############################################################################\nsubmission = pd.read_csv('..\/input\/m5-three-shades-of-dark-darker-magic\/submission_v1.csv')","6f15ddd4":"########################### Day 1\n############################################################################\n\n# Current number of teams       3,215 (day 2 of May)\n# Number of teams 2 days before 3,186 \nteams_now = 3215\nteams_before = 3186\n#submission['F1'] *= teams_now\/teams_before\nsubmission.loc[submission['id'].str.contains('CA_1'), 'F1'] *= 1.009\nsubmission.loc[submission['id'].str.contains('CA_2'), 'F1'] *= 1.02\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F1'] *= 1.009\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F1'] *= 1.011\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F1'] *= 1.01\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F1'] *= 1.011\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F1'] *= 1.011\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F1'] *= 1.015\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F1'] *= 1.02\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F1'] *= 1.015\nsubmission['F1'].sum()","e4e8a41a":"########################### Day 2\n############################################################################\n\n# In case you'll get a heart attack \n# because of all the MAGIC in this kernel -\n# here is South Korean emergency number - 119\nmagic = submission['F2'].sum()\njapan_emergency = 119\n#submission['F2'] *= magic \/ (magic + japan_emergency)\n                             \nsubmission.loc[submission['id'].str.contains('CA_1'), 'F2'] *= 0.994\nsubmission.loc[submission['id'].str.contains('CA_2'), 'F2'] *= 0.998\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F2'] *= 0.994\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F2'] *= 0.996\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F2'] *= 0.995\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F2'] *= 0.996\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F2'] *= 0.996\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F2'] *= 0.998\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F2'] *= 1\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F2'] *= 0.998\n\nsubmission['F2'].sum()","fbb9d33f":"########################### Day 3\n############################################################################\n\n# 1913 - The Woman suffrage parade of 1913 takes place in Washington, D.C.\n# 1923 - Ankara replaces Istanbul (Constantinople), as the capital of Turkey.\n#submission['F3'] *= 1913\/1923\nsubmission.loc[submission['id'].str.contains('CA_1'), 'F3'] *= 0.994\nsubmission.loc[submission['id'].str.contains('CA_2'), 'F3'] *= 0.998\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F3'] *= 0.994\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F3'] *= 0.996\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F3'] *= 0.995\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F3'] *= 0.996\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F3'] *= 0.996\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F3'] *= 1\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F3'] *= 1.005\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F3'] *= 1\nsubmission['F3'].sum()","b54c0493":"########################### Day 4\n############################################################################\n\n# I love statistics.\n# When you dig in data you can \n# find VERY interesting \"facts\".\n# Did you know that the mean \n# number of sexual partners \n# per person is 1.0073\nsex_constant = 1.0073\n#submission['F4'] \/= sex_constant\nsubmission.loc[submission['id'].str.contains('CA_1'), 'F4'] *= 0.98\nsubmission.loc[submission['id'].str.contains('CA_2'), 'F4'] *= 1.02\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F4'] *= 0.98\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F4'] *= 1\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F4'] *= 0.99\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F4'] *= 1\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F4'] *= 1\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F4'] *= 1.00\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F4'] *= 1.02\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F4'] *= 1.00\nsubmission['F4'].sum()","65d6a93b":"########################### Day 5\n############################################################################\n\n# It's Friday  \n# Friday night is a mix (colors)\n# of girls #ffb0e8 and boys #330000\n# Resulted mix HEX color code is #995874\ncolor_of_the_night = 995874\n\n# There are millions \"Stories\"\n# We need to make it Mean, really mean\ncolor_of_the_night \/= 1000000\n#submission['F5'] *= color_of_the_night\nsubmission.loc[submission['id'].str.contains('CA_1'), 'F5'] *= 0.995\nsubmission.loc[submission['id'].str.contains('CA_2'), 'F5'] *= 1\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F5'] *= 0.995\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F5'] *= 0.998\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F5'] *= 0.996\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F5'] *= 0.998\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F5'] *= 0.998\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F5'] *= 1\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F5'] *= 1.01\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F5'] *= 1\nsubmission['F5'].sum()","4d4d2cb5":"########################### Day 6\n############################################################################\n\n# Fridays not always pass without \"consequences\"\n# BE CAREFUL - DRINK MODERATELY\n# https:\/\/www.ncbi.nlm.nih.gov\/pubmed\/25701909\n# Traumatic brain injury and cognition.\n# PMID: 25701909 DOI: 10.1016\/B978-0-444-63521-1.00037-6\n\n# 1.00037-6 - it can't be just a coincidence\ninjury = 1.000376\n#submission['F6'] *= injury\nsubmission.loc[submission['id'].str.contains('CA_1'), 'F6'] *= 1.0002\nsubmission.loc[submission['id'].str.contains('CA_2'), 'F6'] *= 1.001\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F6'] *= 1.0002\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F6'] *= 1.001\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F6'] *= 1.000\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F6'] *= 1.001\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F6'] *= 1.001\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F6'] *= 1.001\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F6'] *= 1.01\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F6'] *= 1.001\nsubmission['F6'].sum()","06da551e":"########################### Day 7\n############################################################################\n\n# Let's make it aaaall random\n# We will need NumPy\n\n# We will divide the COMPLETELY random number\n# from range >1000000 by 1000000\n# to have some float number from 0 to 1 \n\nimport numpy as np\nnp.random.seed(198505)\ncorrection = np.random.randint(1000000)\/1000000\n#submission['F7'] *= correction\nsubmission.loc[submission['id'].str.contains('CA_1'), 'F7'] *= 0.994\nsubmission.loc[submission['id'].str.contains('CA_2'), 'F7'] *= 1\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F7'] *= 0.994\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F7'] *= 0.998\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F7'] *= 0.995635\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F7'] *= 0.998\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F7'] *= 0.998\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F7'] *= 1\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F7'] *= 1.01\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F7'] *= 1\nsubmission['F7'].sum()","f8f1d197":"########################### Day 8\n############################################################################\n#submission['F8'] *= (100-1)\/100 + (100-12)\/10000\nsubmission.loc[submission['id'].str.contains('CA_1'), 'F8'] *= 0.996\nsubmission.loc[submission['id'].str.contains('CA_2'), 'F8'] *= 1\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F8'] *= 0.996\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F8'] *= 0.998\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F8'] *= 0.9988\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F8'] *= 1\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F8'] *= 1\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F8'] *= 1\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F8'] *= 1.01\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F8'] *= 1\nsubmission['F8'].sum()","ef1b0060":"########################### Day 11\n############################################################################\n\n# Let's not change anything here\n# I have a feeling that we should \n# keep origical prediction\n#submission['F11'] = submission['F11']\nsubmission.loc[submission['id'].str.contains('CA_1'), 'F11'] *= 1 \nsubmission.loc[submission['id'].str.contains('CA_2'), 'F11'] *= 1\nsubmission.loc[submission['id'].str.contains('CA_3'), 'F11'] *= 1\nsubmission.loc[submission['id'].str.contains('CA_4'), 'F11'] *= 1\n\nsubmission.loc[submission['id'].str.contains('TX_1'), 'F11'] *= 1\nsubmission.loc[submission['id'].str.contains('TX_2'), 'F11'] *= 1\nsubmission.loc[submission['id'].str.contains('TX_3'), 'F11'] *= 1\n\nsubmission.loc[submission['id'].str.contains('WI_1'), 'F11'] *= 1\nsubmission.loc[submission['id'].str.contains('WI_2'), 'F11'] *= 1\nsubmission.loc[submission['id'].str.contains('WI_3'), 'F11'] *= 1\nsubmission['F11'].sum()","2c7be628":"########################### Days 9-19\n############################################################################\n\n# Just 1% of his fortune is equivalent to the whole health budget for Ethiopia\nfor i in range(9,20):\n    if i!=11:\n        #submission['F'+str(i)] *= 1.01 \n        submission.loc[submission['id'].str.contains('CA_1'), 'F'+str(i)] *= 1\n        submission.loc[submission['id'].str.contains('CA_2'), 'F'+str(i)] *= 1.015\n        submission.loc[submission['id'].str.contains('CA_3'), 'F'+str(i)] *= 1\n        submission.loc[submission['id'].str.contains('CA_4'), 'F'+str(i)] *= 1.013\n\n        submission.loc[submission['id'].str.contains('TX_1'), 'F'+str(i)] *= 1\n        submission.loc[submission['id'].str.contains('TX_2'), 'F'+str(i)] *= 1.013\n        submission.loc[submission['id'].str.contains('TX_3'), 'F'+str(i)] *= 1.013\n\n        submission.loc[submission['id'].str.contains('WI_1'), 'F'+str(i)] *= 1.015\n        submission.loc[submission['id'].str.contains('WI_2'), 'F'+str(i)] *= 1.02\n        submission.loc[submission['id'].str.contains('WI_3'), 'F'+str(i)] *= 1.015\n        print(submission['F'+str(i)].sum())","3f8eb415":"########################### Days 20-28\n############################################################################\n\n# Of all the people earning A$100,000 a year under the age of 50, 2% are women. Just 2% are women.\nfor i in range(20,29):\n    #submission['F'+str(i)] *= 1.02\n    submission.loc[submission['id'].str.contains('CA_1'), 'F'+str(i)] *= 1.015\n    submission.loc[submission['id'].str.contains('CA_2'), 'F'+str(i)] *= 1.03\n    submission.loc[submission['id'].str.contains('CA_3'), 'F'+str(i)] *= 1.015\n    submission.loc[submission['id'].str.contains('CA_4'), 'F'+str(i)] *= 1.025\n\n    submission.loc[submission['id'].str.contains('TX_1'), 'F'+str(i)] *= 1.02\n    submission.loc[submission['id'].str.contains('TX_2'), 'F'+str(i)] *= 1.025\n    submission.loc[submission['id'].str.contains('TX_3'), 'F'+str(i)] *= 1.025\n\n    submission.loc[submission['id'].str.contains('WI_1'), 'F'+str(i)] *= 1.03\n    submission.loc[submission['id'].str.contains('WI_2'), 'F'+str(i)] *= 1.04\n    submission.loc[submission['id'].str.contains('WI_3'), 'F'+str(i)] *= 1.03\n    print(submission['F'+str(i)].sum())","86741a50":"########################### Export\n############################################################################\nsubmission.to_csv('submission.csv', index=False)","31d81b20":"# Charts by store","a6cd49fa":"We can found following chart trends in recently:\n\nCA_1 : small -\n\nCA_2 : +\n\nCA_3 : small -\n\nCA_4 : small +\n\nTX_1 : stable\n\nTX_2 : small +\n\nTX_3 : small +\n\nWI_1 : +\n\nWI_2 : ++\n\nWI_3 : +\n\nLet's adjust!","10013173":"# Adjust submission","73e851dd":"# Charts trends"}}