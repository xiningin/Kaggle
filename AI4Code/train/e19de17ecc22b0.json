{"cell_type":{"a600abad":"code","94042d4f":"code","e0752ea7":"code","16c998a4":"code","6387d45b":"code","8ffaba98":"code","e364cf83":"code","a7b9b429":"code","3d1e4d47":"code","7b13d857":"code","1ef4e37b":"code","6bcb8a5e":"code","cb26d7de":"code","4b234a63":"code","e3003af8":"code","39ffb215":"code","56a07e56":"code","04218926":"code","928c940a":"code","14faf4df":"code","3504b01d":"code","124f7cb5":"code","2c8e8f14":"code","666164bd":"code","558d4ff8":"code","cfff381f":"code","9e2f3b4a":"code","41774171":"code","8eca4a1d":"code","5e706ba6":"code","b51e90f5":"code","ed1f39e4":"code","e19df71e":"code","a2461d96":"markdown","3f23fbbe":"markdown","3f84e97b":"markdown","fc0d68d8":"markdown","f3d1bc88":"markdown","f9018611":"markdown","c51e7794":"markdown","b0aea0cb":"markdown","13a3f249":"markdown","1345900f":"markdown","38077e43":"markdown","bcfb9fd2":"markdown","bc5cbe18":"markdown","afac7713":"markdown","2501ae17":"markdown","39f92eec":"markdown","003f7511":"markdown","6e590728":"markdown"},"source":{"a600abad":"# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Helper libraries\nimport numpy as np #Algebra Lineare\nimport matplotlib.pyplot as plt #grafici\nimport pandas as pd\nimport itertools\n%matplotlib inline\n","94042d4f":"#loading the dataset and labels.......(Train)\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\n\n#loading the dataset.......(Test)\ntest_images= pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nprint(test_images.shape)","e0752ea7":"class_names = ['0', '1', '2', '3', '4','5', '6', '7', '8', '9']","16c998a4":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(data.iloc[i,1:].values.reshape((28,28)),cmap=plt.cm.binary)\n    plt.xlabel(class_names[data.iloc[i,0]])\nplt.show()","6387d45b":"#loading the dataset and labels.......(Train)\ntrain = pd.read_csv(\"..\/input\/mnist-in-csv\/mnist_train.csv\")\nprint(train.shape)\n\n#loading the dataset.......(Test)\ntest= pd.read_csv(\"..\/input\/mnist-in-csv\/mnist_test.csv\")\nprint(test.shape)","8ffaba98":"data = pd.concat([train,test])\ndata.shape","e364cf83":"data.head(8)","a7b9b429":"class_names = ['0', '1', '2', '3', '4','5', '6', '7', '8', '9']","3d1e4d47":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(data.iloc[i,1:].values.reshape((28,28)),cmap=plt.cm.binary)\n    plt.xlabel(class_names[data.iloc[i,0]])\nplt.show()","7b13d857":"#loading the dataset and labels.......(Train)\ntrain = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\nprint(train.shape)\n\n#loading the dataset.......(Test)\ntest = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\nprint(test.shape)","1ef4e37b":"data = pd.concat([train,test])\ndata.shape","6bcb8a5e":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","cb26d7de":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(data.iloc[i,1:].values.reshape((28,28)),cmap=plt.cm.binary)\n    plt.xlabel(class_names[data.iloc[i,0]])\nplt.show()","4b234a63":"from sklearn.model_selection import train_test_split\n\n# Separate in train and test data seconda opzione solo per la competition Digit-Recognizer\ntrain_df, test_df = train_test_split(data, train_size=0.6, shuffle=False, random_state=42)","e3003af8":"from sklearn.model_selection import train_test_split\n\n# Separate in train and test data\ntrain_df, test_df = train_test_split(data, train_size=0.6, shuffle=True, random_state=42)","39ffb215":"train_images = train_df.iloc[:,1:].values.astype('float32')# only labels i.e targets digits\ntrain_labels = train_df.iloc[:,0].values.astype('int32')# only labels i.e targets digits\n\nprint(train_images.shape,train_labels.shape)\n\ntest_images = test_df.iloc[:,1:].values.astype('float32')# only labels i.e targets digits\ntest_labels = test_df.iloc[:,0].values.astype('int32')# only labels i.e targets digits\n\nprint(test_images.shape,test_labels.shape)","56a07e56":"train_images = train_images \/ 255.0\ntest_images = test_images \/ 255.0","04218926":"# Funzione ausiliaria per visualizzare in blocco alcune immagini dei dati\ndef plot_image(i, predictions_array, true_label, img):\n  predictions_array, true_label, img = predictions_array, true_label[i], img[i].reshape((28,28))\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n\n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n  predictions_array, true_label = predictions_array, true_label[i]\n  plt.grid(False)\n  plt.xticks(range(10))\n  plt.yticks([])\n  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1])\n  predicted_label = np.argmax(predictions_array)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('blue')","928c940a":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28, 28)), #livello degli input\n    keras.layers.Dense(128, activation='relu'), #primo livello interno\n    keras.layers.Dense(10, activation='softmax') #livello degli output\n])","14faf4df":"model.summary()","3504b01d":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","124f7cb5":"predictions = model.predict(test_images)","2c8e8f14":"# Plot the first X test images, their predicted labels, and the true labels.\n# Color correct predictions in blue and incorrect predictions in red.\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i, predictions[i], test_labels, test_images)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions[i], test_labels)\nplt.tight_layout()\nplt.show()","666164bd":"model_log = model.fit(train_images,train_labels,\n                      batch_size=32,\n                      epochs =10,\n                      validation_split=0.05,\n                      verbose=1)","558d4ff8":"# plotting the metrics\nfig = plt.figure(figsize=(15, 5))\nplt.subplot(1,2,1)\nplt.plot(model_log.history['accuracy'])\nplt.plot(model_log.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='lower right')\nplt.subplot(1,2,2)\nplt.plot(model_log.history['loss'])\nplt.plot(model_log.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper right')\nplt.tight_layout()\n\nfig.show()","cfff381f":"test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","9e2f3b4a":"predictions = model.predict(test_images)","41774171":"predictions[0]","8eca4a1d":"np.argmax(predictions[0])","5e706ba6":"# Plot the first X test images, their predicted labels, and the true labels.\n# Color correct predictions in blue and incorrect predictions in red.\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i, predictions[i], test_labels, test_images)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions[i], test_labels)\nplt.tight_layout()\nplt.show()","b51e90f5":"pred = []\n\nfor i in range(0,len(predictions)):\n    pred.append(np.argmax(predictions[i]))","ed1f39e4":"#Questa parte serve solo per la competition Digit-Recognizer per generare il file da inviare\nimageid = []\npred = []\n\nfor i in range(0,len(predictions)):\n    pred.append(np.argmax(predictions[i]))\n    imageid.append(i+1)\n    \npred_df = pd.DataFrame(pred,imageid)\npred_df.index.name='ImageId'\npred_df.head(8)\n\npred_df.columns=['Label']\npred_df.head()\n\npred_df.to_csv('submission.csv')","e19df71e":"# Calcola e visualizza la matrice di confusione tra predizioni e valori veri\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(test_labels, pred, normalize='true')\nplt.figure(figsize = (10,6))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(class_names)), yticklabels = sorted(set(class_names)))\nplt.title('Normalized Confusion Matrix')\nplt.show()","a2461d96":"Il primo livello in questa rete, `tf.keras.layers.Flatten`, trasforma il formato delle immagini da un array bi-dimensionale (di 28 per 28 pixel) in un array uni-dimensionale (di 28 * 28 = 784 pixel). Pensate a questi livelli come righe non impilate di pixel dell'immagine. Questo livello non ha parametri da imparare; esso si limita a rifirmattare i dati.\n\nhttps:\/\/keras.io\/api\/layers\/activations\/\n\nDopo la normalizzazione dei pixel, la rete consiste di due livelli `tf.keras.layers.Dense`. Questi sono livelli neurali strettamente connessi, o completamente connessi. Il primo livello `Denso` ha 128 nodi (o neuroni). Il secondo (ed ultimo) livello \u00e8 un livello *softmax* a 10 nodi che restituisce un vettore di 10 valori di probabilit\u00e0 la cui somma \u00e8 1. Ogni nodo contiene un valore che indica la probabilit\u00e0 che l'immagine corrente appartenga ad una delle 10 classi.\n\n### Compilare il modello\n\nPrima che il modello sia pronto per l'apprendimento, \u00e8 necessaria qualche impostazione in pi\u00f9. Queste sono aggiunte durante i passi di *compilazione* del modello:\n\n* *Funzione perdita* \u2014Misura quanto \u00e8 accurato il modello durante l'apprendimento. La volont\u00e0 \u00e8 di minimizzare questa funzione per \"dirigere\" il modello nella giusta direzione.\n\n  https:\/\/keras.io\/api\/losses\/\n\n* *Ottimizzatore* \u2014Indica com'\u00e8 aggiornato il modello sulla base dei dati che tratta e della sua funzione perdita.\n\n  https:\/\/keras.io\/api\/optimizers\/adam\/\n\n* *Metriche* \u2014Usate per monitorare i passi di addestramento e verifica. L'esempio seguente usa come *accuratezza*, la frazione delle immagini che sono classificate correttamente.\n\n  https:\/\/keras.io\/api\/metrics\/","3f23fbbe":"Mentre il modello si allena, vengono visualizzate le metriche di perdita e accuratezza. Questo modello raggiunge un'accuratezza di circa 0.9 (il risultato cambia ogni volta) sui dati di addestramento.","3f84e97b":"Per scoprire che l'accuratezza sul datase di test \u00e8 leggermente inferiore rispetto a quella sul dataset di addestramento. Questa differenza tra l'accuratezza in addestramento e l'accuratezza in test rappresenta l' *overfitting*. L'overfitting \u00e8 quando un modello di machine learning ha prestazioni peggiori su input nuovi, mai visti prima, che sui dati di addestramento.","fc0d68d8":"## Addestrare il modello\n\nL'addestramento del modello di rete neurale richiede i seguenti passi:\n\n1. Alimentare il modello con i dati di addestramento. In questo esempio, i dati di addestramento sono nei vettori `train_images` e `train_labels`.\n2. Il modello impara ad associare immagini ed etichette.\n3. Chiedere al modello di fare previsioni su un insieme di prova\u2014in questo esempio, il vettore `test_images`.\n4. Verificare che le previsioni corrispondano alle etichette del vettore `test_labels`.\nPer iniziare l'addestramento, chiamare il metodo `model.fit`\u2014chiamato cos\u00ec perch\u00e8 \"allena\" il modello sui dati di addestramento:","f3d1bc88":"Rappresentiamo diverse immagini con le rispettive previsioni. Notiamo che il modello pu\u00f2 sbagliare anche quando \u00e8 molto confidente.","f9018611":"## Valutare l'accuratezza\n\nSuccessivamente, valutare come si comporta il modello sul dataset di test:","c51e7794":"## Importare il dataset MNIST (solo per la competition Digit-Recognizer)","b0aea0cb":"### Inizializzare i livelli\n\nL'elemento costruttivo di base di una rete neurale \u00e8 il *livello*. I livelli estraggono rappresentazioni dai dati con cui vengono alimentati. Sperabilmente, queste rappresentazioni sono significative per il problema che si sta trattando.\n\nLa maggior parte del deep learning consiste nel collegare tra loro livelli semplici. La maggior parte dei livelli, come `tf.keras.layers.Dense`, hanno parametri che sono imparati durante l'allenamento.","13a3f249":"## Pre-elaborare i dati\n\nPrima di allenare la rete, i dati devono essere pre-elaborati. Osservando la prima immagine  dell'insieme di addestramento, si noter\u00e0 che i valori dei pixel cadono nell'intervallo da 0 a 255 (variare il numero 0 contenuto in train_images[0] per vedere come cambia il risultato; plt \u00e8 il nome con cui \u00e8 stato creato un oggetto tipo matplotlib.pyplot):","1345900f":"Qui, il modello ha previsto l'etichetta per ciascuna immagine nell'insieme di test. Diamo un'ochiata alla prima previsione:","38077e43":"Una prevsione \u00e8 un vettore di 10 numeri. Essi rappresentano la \"confidenza\" del modello che l'immagine corrisponda a ciascuno dei 10 diversi articoli di abbigliamento. E si pu\u00f2 vedere quale etichetta ha il valore pi\u00f9 alto di confidenza:","bcfb9fd2":"Questi valori vanno scalati in un intervallo tra 0 e 1 prima di darli in pasto al modello della rete. Per fare ci\u00f2, si dividono i valori per 255. E' importante che l'*insieme di addestramento* e l'*insieme di verifica* siano pre-elaborati nello stesso modo:","bc5cbe18":"## Fare previsioni\n\nUna volta addestrato il modello, puoi usarlo per fare previsioni su altre immagini.","afac7713":"## Importare il dataset MNIST","2501ae17":"# Classificazione base: dai numeri ai di capi d'abbigliamento","39f92eec":"## Importare il dataset Fashion MNIST","003f7511":"Infine, usiamo il modello addestrato per fare una previsione su una singola immagine.","6e590728":"## Costruire il modello\n\nLa costruzione della rete neurale richiede di configurare i livelli del modello, quindi la compilazione del modello."}}