{"cell_type":{"8f746b67":"code","c92bc2a8":"code","c312cfb8":"code","ba859f11":"code","abda5be4":"code","f711dc1e":"code","c405192f":"code","7965ab2f":"code","5550a24e":"code","3a95ae42":"code","830ec1f9":"code","a0d64a48":"code","eb9beb6d":"code","7f32ea75":"code","32f9e238":"code","0e382d0f":"code","f870ef25":"code","4f0eb7ba":"code","05904759":"code","282aa478":"code","ac5d48b4":"code","0d54b3d6":"code","bb34470e":"code","b4f37170":"code","fcc3690f":"code","917ee2cc":"code","80378905":"code","aed0ee3e":"code","09af54d2":"code","9b6b1834":"code","adc4de9d":"code","8c8e2b16":"code","d6228ec6":"code","fe76179c":"code","03b766f9":"code","26e00493":"markdown","0f6e437c":"markdown","167d2ada":"markdown","5914f544":"markdown","77615bb8":"markdown","5e2dcb17":"markdown","9a3b197e":"markdown"},"source":{"8f746b67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c92bc2a8":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","c312cfb8":"df.head()","ba859f11":"df_test.head()","abda5be4":"df.info()","f711dc1e":"df.describe()","c405192f":"df_test.describe()","7965ab2f":"df.isnull().sum()","5550a24e":"df_test.isnull().sum()","3a95ae42":"df.duplicated().sum()","830ec1f9":"df_test.duplicated().sum()","a0d64a48":"df['Embarked'].value_counts()","eb9beb6d":"df['Embarked'] = df['Embarked'].fillna('S')","7f32ea75":"df = df.drop(columns=['PassengerId','Name','Ticket', 'Cabin'])\ndf_test = df_test.drop(columns=['PassengerId','Name','Ticket', 'Cabin'])","32f9e238":"df_encoded = pd.get_dummies(df, drop_first=True)\ndf_test_encoded = pd.get_dummies(df_test, drop_first=True)\ndf_encoded.head()","0e382d0f":"df_test_encoded.head()","f870ef25":"data = [df_encoded,df_test_encoded]\nfor dataset in data:\n    mean = df_encoded[\"Age\"].mean()\n    std = df_test_encoded[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    # compute random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    # fill NaN values in Age column with random values generated\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = df_encoded[\"Age\"].astype(int)\n    \ndf_encoded[\"Age\"].isnull().sum()","4f0eb7ba":"df_test_encoded[\"Age\"].isnull().sum()","05904759":"df_test_encoded[\"Fare\"] = df_test_encoded[\"Fare\"].fillna(df_test_encoded[\"Fare\"].median())","282aa478":"correlation = df_encoded.corr()\ncorrelation[\"Survived\"].sort_values()","ac5d48b4":"mask = np.array(correlation)\nmask[np.tril_indices_from(mask)] = False\nfig, ax = plt.subplots(figsize = (12,12))\nsns.heatmap(correlation, mask = mask, vmax = 0.9, square = True, annot = True)","0d54b3d6":"X = df_encoded.drop(columns=['Survived'])\ny = df_encoded['Survived']\nX_test = df_test_encoded.copy()","bb34470e":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)","b4f37170":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\nY_prediction = random_forest.predict(X_val)\nprint(random_forest.score(X_train, y_train))","fcc3690f":"from sklearn.model_selection import cross_val_score\nrf = RandomForestClassifier(n_estimators=100, oob_score = True)\nscores = cross_val_score(rf, X_train, y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","917ee2cc":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\npredictions = cross_val_predict(random_forest, X_train, y_train, cv=3)\nconfusion_matrix(y_train, predictions)","80378905":"from sklearn.metrics import precision_score, recall_score\n\nprint(\"Precision:\", precision_score(y_train, predictions))\nprint(\"Recall:\",recall_score(y_train, predictions))","aed0ee3e":"from sklearn.metrics import precision_recall_curve\n\ny_scores = random_forest.predict_proba(X_train)\ny_scores = y_scores[:,1]\n\nfrom sklearn.metrics import roc_auc_score\nr_a_score = roc_auc_score(y_train, y_scores)\nprint(\"ROC-AUC-Score:\", r_a_score)","09af54d2":"from sklearn.model_selection import cross_val_score\nxgb = XGBClassifier( max_depth= 100, n_estimators= 500, learning_rate=0.29, random_state= 0, n_jobs=5, eval_metric='logloss')\nscores = cross_val_score(xgb, X_train, y_train, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","9b6b1834":"xgb = XGBClassifier( max_depth= 100, n_estimators= 500, learning_rate=0.29, random_state= 0, n_jobs=5)\nxgb.fit(X_train, y_train)\nY_pred = xgb.predict(X_val)\nprint(xgb.score(X_train, y_train))","adc4de9d":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\npredictions = cross_val_predict(xgb, X_train, y_train, cv=3)\nconfusion_matrix(y_train, predictions)","8c8e2b16":"from sklearn.metrics import precision_score, recall_score\n\nprint(\"Precision:\", precision_score(y_train, predictions))\nprint(\"Recall:\",recall_score(y_train, predictions))","d6228ec6":"from sklearn.metrics import precision_recall_curve\n\n# getting the probabilities of our predictions\ny_scores = xgb.predict_proba(X_train)\ny_scores = y_scores[:,1]\n\nfrom sklearn.metrics import roc_auc_score\nr_a_score = roc_auc_score(y_train, y_scores)\nprint(\"ROC-AUC-Score:\", r_a_score)","fe76179c":"y_XGB = xgb.predict(X_test)","03b766f9":"titanic_test_original = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\noutput = pd.DataFrame({'PassengerId' : titanic_test_original.PassengerId, 'Survived': y_XGB})\noutput.to_csv('submission.csv', index=False)","26e00493":"# Models","0f6e437c":"# Imports","167d2ada":"# Data preprocessing","5914f544":"# Reading the Data","77615bb8":"## XGBoost","5e2dcb17":"## Random Forest","9a3b197e":"# Data Exploration"}}