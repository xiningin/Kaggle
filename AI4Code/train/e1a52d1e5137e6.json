{"cell_type":{"0b89bfc9":"code","797dc0e9":"code","2ce55949":"code","997eb0f7":"code","c45323f7":"code","58bd2d3a":"code","bb74aa9a":"code","3d806034":"code","587e2373":"code","84f10862":"code","8bb71363":"code","d301e8da":"code","9f30cbc2":"code","05c00f76":"code","dc234585":"code","e27fc0d1":"code","e560e364":"code","f6fa4d79":"code","c3c20ac6":"code","e5ff80d5":"code","c5578adf":"code","fea84d0f":"code","67bf56db":"code","49e2a780":"code","ae441f2b":"code","fb380642":"code","7f905236":"code","148359a2":"code","3dcb0f83":"code","a269f2da":"code","ea3e39a9":"code","ae6fb682":"markdown","65f4b477":"markdown","c0026df9":"markdown","4525d0c3":"markdown","8f4bcd2f":"markdown"},"source":{"0b89bfc9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport time\nfrom keras import layers\nfrom keras.layers import Dense, Dropout, GlobalMaxPooling2D, Flatten\nfrom keras.preprocessing.image import load_img\nfrom keras.applications import VGG16\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","797dc0e9":"# Data preparation.\n# \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\u3092\u3057\u307e\u3059\u3002\nprint(os.listdir(\"..\/input\"))","2ce55949":"# Check the data.\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf10\u4ef6\u3092\u30ea\u30b9\u30c8\u3057\u307e\u3059\u3002\nprint(os.listdir(\"..\/input\/train\/train\")[:10])\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf10\u4ef6\u3092\u30ea\u30b9\u30c8\u3057\u307e\u3059\u3002\nprint(os.listdir(\"..\/input\/test1\/test1\")[:10])","997eb0f7":"# Get category from file name.Because there is no correct \n# answer label, get the label from the file name and make \n# it a classification class.\n# First, get a list of file names.\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u304b\u3089dog, cat\u3092\u53d6\u5f97\u3057\u5206\u985e\u3059\u308b\u30ab\u30c6\u30b4\u30ea\u3068\u3057\u307e\u3059\u3002\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u4e00\u89a7\u3092\u53d6\u5f97\u3002\nfilenames = os.listdir(\"..\/input\/train\/train\")\n# Variable to store categories.\n# \u30af\u30e9\u30b9\u3092\u683c\u7d0d\u3059\u308b\u5909\u6570\u3002\ncategories = []\n# Perform processing for the number of acquired files.\n# \u53d6\u5f97\u3057\u305f\u30d5\u30a1\u30a4\u30eb\u6570\u5206\u51e6\u7406\u3092\u7e70\u308a\u8fd4\u3057\u307e\u3059\u3002\nfor filename in filenames:\n    # Cut out label from file name.\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u304b\u3089\u6b63\u89e3\u30e9\u30d9\u30eb\u3092\u5207\u308a\u53d6\u308b\u3002\n    category = filename.split('.')[0]\n    # If the file name contains Dog, set the class to 1, \n    # otherwise set it to 0.\n    # \u30d5\u30a1\u30a4\u30eb\u540d\u306bDog\u304c\u542b\u307e\u308c\u3066\u3044\u308c\u3070\u3001\u30af\u30e9\u30b9\u306b1\u3092\u8a2d\u5b9a\u3057\u3001\n    # \u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306f0\u3092\u8a2d\u5b9a\u3059\u308b\u3002\n    whichCategorys = '1' if category == 'dog' else '0'\n    # Add label.\n    # \u30e9\u30d9\u30eb\u3092\u5909\u6570\u306b\u683c\u7d0d\u3057\u307e\u3059\u3002\n    categories.append(whichCategorys)\n\n# Create a data frame with file name and class, \n# and use it as supervised learning data.\n# \u30d5\u30a1\u30a4\u30eb\u540d\u3068\u30af\u30e9\u30b9\u3092\u6301\u3064\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\u3057\u3001\u6559\u5e2b\u3042\u308a\u306e\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u3057\u307e\u3059\u3002\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\n\n# display the beginning.\n# \u5148\u982d\u3092\u8868\u793a\u3057\u3066\u307f\u307e\u3059\u3002\ndf.head()\n","c45323f7":"# We have the same amount of images of dogs and cats.\n# \u72ac\u732b\u306f\u540c\u6570\u3042\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002\n#df['class'].value_counts()\ndf['category'].value_counts()","58bd2d3a":"# See sample image.\n# \u753b\u50cf\u3092\u8868\u793a\u3057\u3066\u307f\u307e\u3059\u3002\nplt.figure(figsize=(12, 12))\nfor i in range(0, 9):\n    plt.subplot(3, 3, i+1)\n    image = load_img('..\/input\/train\/train\/'+df.filename[i])\n    plt.imshow(image)\nplt.tight_layout()\nplt.show()","bb74aa9a":"# Input data is a color image (3 channels) with an image size of 224x224.(Same as VGG 16 input layer)\n# \u5165\u529b\u30c7\u30fc\u30bf\u306f\u3001\u753b\u50cf\u30b5\u30a4\u30ba\u3092224x224\u306e\u30ab\u30e9\u30fc\u753b\u50cf(3\u30c1\u30e3\u30f3\u30cd\u30eb)\u3068\u3059\u308b\u3002(VGG16\u306e\u5165\u529b\u5c64\u306b\u5408\u308f\u305b\u305f)\nimage_size = 224\ninput_shape = (image_size, image_size, 3)","3d806034":"# \u30a8\u30dd\u30c3\u30af\u65707\u3001\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u309216\u306b\u8a2d\u5b9a\u3002\nepochs = 7\nbatch_size = 16","587e2373":"# VGG16 model download(Set up Internet connection from Kernel beforehand)\n# The output layer of the VGG 16 is 1,000 classes, and this time the output \n# layer is replaced for 2-class classification. \n# VGG16\u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9(\u4e8b\u524d\u306bKernel\u304b\u3089Internet\u63a5\u7d9a\u304c\u3067\u304d\u308b\u3088\u3046\u8a2d\u5b9a\u3057\u3066\u304a\u304d\u307e\u3059)\n# VGG16\u306f1,000\u30af\u30e9\u30b9\u306e\u51fa\u529b\u5c64\u3068\u306a\u3063\u3066\u304a\u308a\u3001\u4eca\u56de\u306f\u72ac\u3001\u732b\u306e\uff12\u30af\u30e9\u30b9\u5206\u985e\u3068\u306a\u308b\u305f\u3081\u51fa\u529b\u5c64\u306e\u53d6\u308a\u66ff\u3048\u3092\u884c\u3044\u307e\u3059\u3002\n# \u3053\u306e\u305f\u3081include_top=False\u3068\u3057\u3001\u51fa\u529b\u5c64\u306e\u524d\u306e\u5c64\u3092\u5229\u7528\u3057\u307e\u3059\u3002\nVGG16model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")","84f10862":"# Display model summary.\n# \u30e2\u30c7\u30eb\u306e\u30b5\u30de\u30ea\u3092\u8868\u793a\u3057\u307e\u3059\u3002\n# \u5165\u529b\u5c64\u3068\u7573\u307f\u8fbc\u307f\u5c64\u3001\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u304b\u3089\u306a\u308b\u30d6\u30ed\u30c3\u30af\u304c\uff15\u3064\u3042\u308b\u4e8b\u304c\u308f\u304b\u308a\u307e\u3059\u3002\nVGG16model.summary()","8bb71363":"# \u6700\u5f8c\u306e\u7573\u307f\u8fbc\u307f\u5c64\u306e\u76f4\u524d\u307e\u3067\u306e\u5c64\u306f\u3001\u5b66\u7fd2\u3055\u308c\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u305d\u306e\u307e\u307e\u5229\u7528\u3059\u308b\u305f\u3081\n# \u4eca\u5f8c\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306b\u3088\u3063\u3066\u5909\u66f4\u3055\u308c\u306a\u3044\u3088\u3046\u306b\u3057\u307e\u3059\u3002\u4eca\u56de\u6700\u5f8c\u306e\u5c64\u3060\u3051\u5b66\u7fd2\u3055\u305b\u307e\u3059\u3002\n# Freeze the layer just before the last convolutional layer.\nfor layer in VGG16model.layers[:15]:\n    layer.trainable = False","d301e8da":"# \uff15\u30d6\u30ed\u30c3\u30af\u76ee\u306e\u7573\u307f\u8fbc\u307f\u5c64\u3060\u3051\u5b66\u7fd2\u3067\u304d\u308b\u72b6\u614b\u306b\u306a\u3063\u3066\u3044\u308b\u4e8b\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002\n# Only the 5th block can learn.\nfor layer in VGG16model.layers[:-1]:\n    print(layer.trainable)","9f30cbc2":"# Set the 5th block of the VGG16 model as the last output layer.\n# VGG16\u30e2\u30c7\u30eb\u306e5\u30d6\u30ed\u30c3\u30af\u76ee\u3092\u6700\u5f8c\u306e\u51fa\u529b\u5c64\u3068\u3059\u308b\u3002\nlast_layer = VGG16model.get_layer('block5_pool')\nlast_output = last_layer.output","05c00f76":"# Create a new output layer for 2 class classification.\n# \u5206\u985e\u306f\u72ac\u732b\u306e\uff12\u30af\u30e9\u30b9\u306e\u5206\u985e\u3092\u51fa\u529b\u3059\u308b\u5c64\u3092\u65b0\u898f\u306b\u4f5c\u6210\u3059\u308b\u3002\n# \u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3092\u7f6e\u304d\u3001\u5165\u529b\u306fVGG16\u306e\u51fa\u529b\u3092\u53d7\u3051\u53d6\u308b\u3088\u3046\u306b\u3059\u308b\u3002\nnew_last_layers = GlobalMaxPooling2D()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\n# 512\u30ce\u30fc\u30c9\u306e\u5168\u7d50\u5408\u5c64\u3092\u8ffd\u52a0\u3001\u6d3b\u6027\u5316\u95a2\u6570\u306fReLU\nnew_last_layers = Dense(512, activation='relu')(new_last_layers)\n# Add a dropout rate of 0.5\n# \u30c9\u30ed\u30c3\u30d7\u30a2\u30a6\u30c8\u3092\u8ffd\u52a0\u3001\u30ec\u30fc\u30c8\u306f0.5\nnew_last_layers = Dropout(0.5)(new_last_layers)\n# Add a final sigmoid layer for classification\n# \u6700\u5f8c\u306b\u72ac\u732b\u306e\u30af\u30e9\u30b9\u3092\u793a\u3059\u30ce\u30fc\u30c9\uff12\u3064\u306e\u51fa\u529b\u5c64\u3092\u4f5c\u308a\u3001\u30b7\u30b0\u30e2\u30a4\u30c9\u95a2\u6570\u3092\u9069\u7528\u3059\u308b\nnew_last_layers = layers.Dense(2, activation='sigmoid')(new_last_layers)","dc234585":"# Combine the VGG 16 with the output layer.\n# VGG16\u3068\u51fa\u529b\u5c64\u3092\u7d50\u5408\u3059\u308b\u3002\nmodel = Model(VGG16model.input, new_last_layers)\n# complile.\n# \u30e2\u30c7\u30eb\u306e\u30b3\u30f3\u30d1\u30a4\u30eb\u3002\nmodel.compile(loss = \"categorical_crossentropy\",\n              optimizer=SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n# Display model summary.\n# \u30b5\u30de\u30ea\u8868\u793a\nmodel.summary()","e27fc0d1":"# Prepare training data and validation data.\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf(train_df)\u3068\u691c\u8a3c\u30c7\u30fc\u30bf(validate_df)\u3092\u6e96\u5099\u3059\u308b\u3002\ntrain_df, validate_df = train_test_split(df, test_size=0.1)\n# index\u306e\u30ea\u30bb\u30c3\u30c8\ntrain_df = train_df.reset_index()\nvalidate_df = validate_df.reset_index()\n# \u30c7\u30fc\u30bf\u6570\u306e\u53d6\u5f97\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nprint('Total amount of data={}, Total train={}, Total validate={}'.format(len(df), total_train, total_validate))","e560e364":"train_df.head()","f6fa4d79":"validate_df.head()","c3c20ac6":"# Traning Generator\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u62e1\u5f35\u3092\u884c\u3046\ntrain_datagen = ImageDataGenerator(\n    # \u753b\u50cf\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u56de\u8ee2\u7bc4\u56f2\n    rotation_range=15,\n    # \u753b\u7d20\u5024\u306e\u30ea\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u4fc2\u6570\n    rescale=1.\/255,\n    # \u30b7\u30a2\u30fc\u5f37\u5ea6\uff08\u53cd\u6642\u8a08\u56de\u308a\u306e\u30b7\u30a2\u30fc\u89d2\u5ea6\uff09\n    shear_range=0.2,\n    # \u30e9\u30f3\u30c0\u30e0\u306b\u30ba\u30fc\u30e0\u3059\u308b\u7bc4\u56f2\n    zoom_range=0.2,\n    # \u6c34\u5e73\u65b9\u5411\u306b\u753b\u50cf\u53cd\u8ee2\n    horizontal_flip=True,\n    # \u5165\u529b\u753b\u50cf\u306e\u5883\u754c\u5468\u308a\u3092\u57cb\u3081\u308b\u6307\u5b9a\n    fill_mode='nearest',\n    # \u6c34\u5e73\u30b7\u30d5\u30c8\u3059\u308b\u7bc4\u56f2\n    width_shift_range=0.1,\n    # \u5782\u76f4\u30b7\u30d5\u30c8\u3059\u308b\u7bc4\u56f2\n    height_shift_range=0.1\n)","e5ff80d5":"# Generate a batch of expanded data from data frames and directory.\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\n# \u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3068\u30d1\u30b9\u304b\u3089\u30c7\u30fc\u30bf\u3092\u62e1\u5f35\u3057\u305f\u30d0\u30c3\u30c1\u3092\u751f\u6210\u3059\u308b\ntrain_generator = train_datagen.flow_from_dataframe(\n    # \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\n    train_df, \n    # \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u30d1\u30b9\n    \"..\/input\/train\/train\/\",\n    # \u30d5\u30a1\u30a4\u30eb\u540d\n    x_col='filename',\n    # \u6b63\u89e3\u30e9\u30d9\u30eb(\u30ab\u30c6\u30b4\u30ea)\n    y_col='category',\n    # '\u72ac(1)'\u3001'\u732b(0)'\u306e\u30ab\u30c6\u30b4\u30ea\u5206\u985e\u3068\u3057\u3066\u6271\u3046\n    class_mode='categorical',\n    # \u5bfe\u8c61\u306e\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba\n    target_size=(image_size, image_size),\n    # \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\n    batch_size=batch_size\n)","c5578adf":"# Validation Generator\n# \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"..\/input\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='categorical',\n    target_size=(image_size, image_size),\n    batch_size=batch_size\n)","fea84d0f":"# Prepare a generator for sample display of extended image\n# \u62e1\u5f35\u753b\u50cf\u306e\u30b5\u30f3\u30d7\u30eb\u8868\u793a\u3092\u884c\u3046\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u3092\u6e96\u5099\nexample_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"..\/input\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='categorical'\n)\n# Display a sample of expanded image data\n# \u62e1\u5f35\u3057\u305f\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u8868\u793a\u3059\u308b\nplt.figure(figsize=(12, 12))\nfor i in range(0, 9):\n    plt.subplot(3, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()\n","67bf56db":"# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u6642\u9593\u6e2c\u5b9a\u306e\u305f\u3081\u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u3092\u53d6\u5f97\nstart = time.time()\n\n# Fit Model\n# fine-tune the model\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306e\u5b9f\u65bd\nhistory = model.fit_generator(\n    train_generator,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size)\n\n# Display of learning time\n# \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u6642\u9593\u306e\u8868\u793a\nelapsed_time = time.time() - start\nprint (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")","49e2a780":"# evaluation\n# \u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\nloss, accuracy = model.evaluate_generator(validation_generator, total_validate\/\/batch_size, workers=12)\nprint(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))","ae441f2b":"# loss and accuracy graph\n# \u640d\u5931\u95a2\u6570\u306e\u5024\u3068\u5206\u985e\u7cbe\u5ea6\u306e\u30b0\u30e9\u30d5\ndef plot_model_history(model_history, acc='acc', val_acc='val_acc'):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    axs[0].plot(range(1,len(model_history.history[acc])+1),model_history.history[acc])\n    axs[0].plot(range(1,len(model_history.history[val_acc])+1),model_history.history[val_acc])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history[acc])+1),len(model_history.history[acc])\/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])\/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n    \nplot_model_history(history)","fb380642":"# Try image recognition.\n# Run this cell several times and try out various images.\n# \u8a66\u3057\u306b\u3001\u30e9\u30f3\u30c0\u30e0\u306b\uff11\u679a\u753b\u50cf\u3092\u9078\u3093\u3067\u8868\u793a\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n# \u3053\u306e\u30bb\u30eb\u306f\u4f55\u5ea6\u304b\u5b9f\u884c\u3057\u3001\u8272\u3005\u306a\u753b\u50cf\u3067\u8a66\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\nfilenames = os.listdir(\"..\/input\/test1\/test1\")\nsample = random.choice(filenames)\nimg = load_img(\"..\/input\/test1\/test1\/\"+sample,target_size=(224,224))\nplt.imshow(img)\nimg = np.asarray(img)\nimg = np.expand_dims(img, axis=0)\n\npredict =  model.predict(img)\ndog_vs_cat= np.argmax(predict,axis=1)\nprint('The animals in the picture are \"', end='')\nif dog_vs_cat == 1:\n    print('dog\".')\nelse:\n    print('cat\".')\n","7f905236":"# Preparation of test data.\n# \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\u306e\u6e96\u5099\u3002\ntest_filenames = os.listdir(\"..\/input\/test1\/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","148359a2":"# Create Testing Generator.\n# \u30c6\u30b9\u30c8\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u3092\u4f5c\u6210\u3002\ntest_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"..\/input\/test1\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    batch_size=batch_size,\n    target_size=(image_size, image_size),\n    shuffle=False\n)\n","3dcb0f83":"# Predict\n# \u4e88\u6e2c\u3059\u308b\npredict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","a269f2da":"# Display some of the prediction results.\n# \u4e88\u6e2c\u7d50\u679c\u306e\u4e00\u90e8\u3092\u8868\u793a\u3002\ndog_vs_cat= np.argmax(predict,axis=1)\nplt.figure(figsize=(12, 12))\nfor i in range(0, 9):\n    ax= plt.subplot(3, 3, i+1, xticks=[], yticks=[])\n    image = load_img('..\/input\/test1\/test1\/'+test_df.filename[i])\n    plt.imshow(image)\n    ax.set_title(\"predict={}\".format(('dog' if dog_vs_cat[i]==1 else 'cat')))\nplt.tight_layout()\nplt.show()","ea3e39a9":"# Submission file output\n# \u30b5\u30d6\u30df\u30c3\u30b7\u30e7\u30f3\u7528\u306eDF\u3092\u6e96\u5099\nsubmission_df = test_df.copy()\n#id\u3092\u8a2d\u5b9a\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\n#label\u3092\u8a2d\u5b9a\nsubmission_df['label'] = dog_vs_cat\n#filename\u306f\u4e0d\u8981\u306a\u306e\u3067\u524a\u9664\nsubmission_df.drop(['filename'], axis=1, inplace=True)\n# \u30b5\u30d6\u30df\u30c3\u30b7\u30e7\u30f3\u30d5\u30a1\u30a4\u30eb\u306e\u51fa\u529b\nsubmission_df.to_csv('submission.csv', index=False)","ae6fb682":"# Prediction and submission","65f4b477":"# Data preparation","c0026df9":"# Introduction\nThis model is a fine-tuned model of VGG16 by Keras.\n\nAlso, this Kernel has written a detailed explanation for beginners.\n\nPlease set in advance that Internet can be used from Kernel.","4525d0c3":"# Fine-tuned model of VGG16","8f4bcd2f":"# Evaluate the model"}}