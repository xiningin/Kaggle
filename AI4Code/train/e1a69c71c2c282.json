{"cell_type":{"4dd2f5f6":"code","ab351ffb":"code","45071747":"code","8f01ccac":"code","a6d304e1":"code","d04e2486":"code","ecdb412d":"code","7aa0c8e4":"code","d4acc403":"code","7b5c2369":"code","a4d75b82":"code","c1be40e7":"code","3ff8fa7c":"code","c6ebc13a":"code","fe17b879":"code","06939c26":"code","7c793ff3":"code","533f328e":"code","c49a3087":"code","d8cd1ad8":"code","689f7eb6":"code","ca5ee310":"markdown","3147037b":"markdown","0e1b9675":"markdown","795fad7a":"markdown","86241703":"markdown"},"source":{"4dd2f5f6":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntrain=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest=pd.read_csv(\"..\/input\/titanic\/test.csv\")","ab351ffb":"#do the basic exploration things and find the number of null values\n#train.describe()\n#train.info()\n#train.isnull().any()\ntrain.isnull().sum()","45071747":"#Dropping the columns which we dont need and that dont effect much\ntrain.drop(columns=[\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1,inplace=True)","8f01ccac":"#plotting null values\nplt.figure(figsize=(5,5))\nsns.heatmap(train.isnull(),yticklabels=False,cbar=False)","a6d304e1":"#dropping only the rows with null values in embarked column, can also use the below methods\n#train[train['Embarked'].isnull()].index.tolist()\n#train = train[train['Embarked'].notna()]\n\ntrain.dropna(subset=['Embarked'],inplace=True)\ntrain.Age.fillna(train.Age.mean(),inplace=True)","d04e2486":"train.isnull().sum()","ecdb412d":"train.hist(figsize=(10,10),bins = 29, color=\"#107009AA\")\nplt.title(\"Features Distribution\")\nplt.show()","7aa0c8e4":"g = sns.FacetGrid(train, col='Survived')\ng = g.map(sns.distplot, \"Age\")","d4acc403":"print(train.Sex.unique())\nprint(train.Embarked.unique())","7b5c2369":"train['Sex']=train['Sex'].map({'male':0,'female':1})\ntrain['Embarked']=train['Embarked'].map({'S':0,'C':1,'Q':2})","a4d75b82":"#oulier analysis using zscore\nfrom scipy import stats\nimport numpy as np\na=np.mean(train.Fare)\nprint(a)\nb=np.std(train.Fare)\nprint(b)\n\nz = np.abs(stats.zscore(train))\nprint(z)\nthreshold = 3","c1be40e7":"train = train[(z < 3).all(axis=1)]","3ff8fa7c":"#oulier analysis using inter quartile range IQR\nfrom collections import Counter\ndef detect_outliers(df,n,features):\n    outlier_indices = []\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    return multiple_outliers   \nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])","c6ebc13a":"train = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","fe17b879":"test.isnull().sum()","06939c26":"test.drop(columns=[\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1,inplace=True)","7c793ff3":"test['Sex']=test['Sex'].map({'male':0,'female':1})\ntest['Embarked']=test['Embarked'].map({'S':0,'C':1,'Q':2})","533f328e":"test.Fare.fillna(test.Fare.mean(),inplace=True)\ntest.Age.fillna(train.Age.mean(),inplace=True)","c49a3087":"xtrain=train.iloc[:,1:]\nytrain=train.iloc[:,0]\nxtest=test","d8cd1ad8":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(booster = 'gbtree', gamma=5,learning_rate = 0.1, max_depth = 5, n_estimators = 100,colsample_bytree=1)\nxgb.fit(xtrain, ytrain)\nxgbpred=xgb.predict(xtest)","689f7eb6":"prediction = pd.DataFrame(xgbpred)\nsubmission= pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = prediction\nsubmission.to_csv('xgbpred21%.csv', index = False)","ca5ee310":"# feature analysis","3147037b":"# Test data","0e1b9675":"# EDA","795fad7a":"# Train Data","86241703":"# Split and Model"}}