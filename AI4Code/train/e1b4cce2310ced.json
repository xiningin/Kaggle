{"cell_type":{"e42da4e2":"code","cf18550b":"code","0b8067c7":"code","10a60f6d":"code","f5ebdeb6":"code","2040e2cf":"code","0bca1c04":"code","ab77de70":"code","64a3645f":"code","687e32b6":"code","cb730f64":"code","0d0728d7":"code","fc070103":"code","457bc83a":"code","a8da3c05":"code","ca8d4692":"code","2d3ded87":"code","7697b60b":"code","a18efd4b":"code","016a0e0c":"code","1350c40c":"code","fdf3ecbf":"code","965ada5e":"code","7e274ecd":"code","b8c7ccab":"code","ca251728":"code","b8ace19e":"markdown","d8987412":"markdown","aa36ee45":"markdown","a33eb80a":"markdown"},"source":{"e42da4e2":"# RNN\nimport pandas as pd\nimport random\nimport os\nimport copy\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nprint(__version__) \nimport cufflinks as cf\n# For Notebooks\ninit_notebook_mode(connected=True)\n# For offline use\ncf.go_offline()","cf18550b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","0b8067c7":"dataset = pd.read_csv('..\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/aaxn.us.txt')\ndataset.head()","10a60f6d":"# Creating an numpy arrray of dataset\ntraining_set = dataset.iloc[:,0:2]","f5ebdeb6":"training_set","2040e2cf":"training_set.iplot(kind='line',y='Open',x='Date')","0bca1c04":"training_set = dataset.iloc[2000:-20,0:2]","ab77de70":"training_set.iplot(kind='line',y='Open',x='Date')","64a3645f":"# feature scaling\ntraining_set = dataset.iloc[2000:-20,1:2].values\nfrom sklearn.preprocessing import MinMaxScaler\nmms = MinMaxScaler()\ntraining_set = mms.fit_transform(training_set)","687e32b6":"X_train = []\ny_train = []\n\n# creating a time series:     use timesteps --> 100 \ntime_step = 100;\nfor i in range(time_step,len(training_set)):\n    X_train.append(training_set[i-time_step:i,0])\n    y_train.append(training_set[i,0])\n\n#converting list into array\nX_train = np.array(X_train);y_train = np.array(y_train)\n\n# We know that LSTM layer takes 3 dimentional array\n#The LSTM input layer must be 3D.\n#The meaning of the 3 input dimensions are: samples, time steps, and features.\nX_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n","cb730f64":"X_train.shape","0d0728d7":"#Building an rnn\n\n#importing the keras libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dropout,Dense,LSTM\n","fc070103":"#adding layers\nregressor = Sequential()\nregressor.add(LSTM(units=200,return_sequences = True,input_shape=(X_train.shape[1],1)))\nregressor.add(Dropout(0.2))\nregressor.add(LSTM(units=200,return_sequences = True))\nregressor.add(Dropout(0.2))\nregressor.add(LSTM(units=200,return_sequences = True))\nregressor.add(Dropout(0.2))\nregressor.add(LSTM(units=200,return_sequences = True))\nregressor.add(Dropout(0.2))\nregressor.add(LSTM(units=100))\nregressor.add(Dropout(0.2))\n\n#output layer\nregressor.add(Dense(units=1))\n\nregressor.compile(optimizer = 'adam',loss = 'mean_squared_error')","457bc83a":"regressor.fit(X_train,y_train,epochs=100,batch_size=80)","a8da3c05":"losses = regressor.history.history\nlosses = pd.DataFrame(losses)\nlosses['loss'].plot()","ca8d4692":"dataset_test  = dataset.iloc[-20:,1:2]","2d3ded87":"real_stocks = dataset_test['Open'].values","7697b60b":"dataset_total =dataset.iloc[:,1:2].values","a18efd4b":"dataset_total = mms.transform(dataset_total)","016a0e0c":"time_step=100\nprediction_stocks = []\n# creating a time series:     use timesteps --> 80 \nfor i in range(len(dataset_total)-20,len(dataset_total)):\n    prediction_stocks.append(dataset_total[i-time_step:i])","1350c40c":"prediction_stocks = np.array(prediction_stocks)","fdf3ecbf":"prediction_stocks = np.reshape(prediction_stocks,(prediction_stocks.shape[0],prediction_stocks.shape[1],1))\npredictions = regressor.predict(prediction_stocks)\npredictions = mms.inverse_transform(predictions)","965ada5e":"#visulising the results\n\nplt.plot(real_stocks, color = 'red', label = 'Real Stock Price')\nplt.plot(predictions, color = 'blue', label = 'Predicted Stock Price')\nplt.title('Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Stock Price')\nplt.legend()\nplt.show()","7e274ecd":"R = pd.DataFrame(real_stocks)\nP = pd.DataFrame(predictions)\nData = pd.concat([R,P],axis=1)","b8c7ccab":"Data.columns=['RealStocks','PredictedStocks']","ca251728":"Data[['RealStocks','PredictedStocks']].iplot(kind='spread')","b8ace19e":"## Improving the performance of your RNN \n- Getting more training data: we trained our model on the past few years, but it would be even better to train it on more data.\n- Increasing the number of timesteps: the model remembered the stock prices from the x previous financial days to predict the stock price of the next day. That\u2019s because we chose a number of x timesteps. You could try to increase the number of timesteps, by choosing for example 120 timesteps (6 months).\n- Adding some other indicators: if you have the financial instinct that the stock price of some other companies might be correlated to the one that is used in above notebook, you could add this other stock price as a new indicator in the training data.\n- Adding more LSTM layers: we built a RNN with four LSTM layers but you could try with even more.\n- Adding more neurones in the LSTM layers: we highlighted the fact that we needed a high number of neurones in the LSTM layers to respond better to the complexity of the problem and we chose to include 200 neurones in each of our 4 LSTM layers. You could try an architecture with even more neurones in each of the 4 (or more) LSTM layers.","d8987412":"In this notebook, an generalized code has been given that could run on each and every stock*. \n\nThe only changes you have to do :\n- Choose the dataset you want\n- Change the length of the dataset according to your system performance\n\n\nIn the end, some important points for imroving the performance of your RNN is also given","aa36ee45":"Interactive plot of complete dataset","a33eb80a":"We have to choose the training set accordingly where we can find significant shift in the stock prices. If your system has high computational power, take the whole dataset"}}