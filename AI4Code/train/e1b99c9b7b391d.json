{"cell_type":{"fb59d135":"code","58832588":"code","ec7c1539":"code","0790c0b0":"code","4794347e":"code","2998b222":"code","4dd53dd5":"code","1ec57372":"code","8cbc160e":"code","22c8c2e3":"code","a2284bfb":"code","39cf5eee":"code","6bfe3559":"code","d3521e80":"code","d343f51b":"code","24a258b7":"code","a1a348ff":"code","06e19c43":"code","eff41bee":"code","0d45b5f1":"code","4107df75":"code","1b9d9b75":"markdown","ae784b78":"markdown","3c4895d7":"markdown","bc09e5b1":"markdown","d6c725ed":"markdown","598979c9":"markdown","0927ddf2":"markdown","c9873d6c":"markdown","a2c57d24":"markdown","831218bd":"markdown","4c1727f3":"markdown","aa67c853":"markdown","5dd7ea52":"markdown","8849ee8c":"markdown","386004dd":"markdown","3086232a":"markdown","3e2e62f8":"markdown","f02005b6":"markdown","5c810d5f":"markdown"},"source":{"fb59d135":"\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\nimport zipfile\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport shutil\nfrom tensorflow.keras.applications import VGG19\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport seaborn as sns\n\n","58832588":"base_dir = \"..\/input\/yoga-posture-data\/DATA\"\ntrain_dir= \"..\/input\/yoga-posture-data\/DATA\/train\"\nval_dir  = \"..\/input\/yoga-posture-data\/DATA\/val\"\ntest_dir = \"..\/input\/yoga-posture-data\/DATA\/test\/TEST\"","ec7c1539":"labels = []\ntrain_counts = []\nfor dirname in os.listdir(train_dir):\n    labels.append(dirname)\n    image_count = 0\n    for img in os.listdir(os.path.join(train_dir,dirname)):\n        image_count +=1\n    train_counts.append(image_count)","0790c0b0":"print(labels)\nprint(train_counts)","4794347e":"train_datagen = ImageDataGenerator(rescale=1.\/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n\nvalid_datagen = ImageDataGenerator(rescale=1. \/ 255)","2998b222":"train_generator = train_datagen.flow_from_directory(train_dir,\n                                                   batch_size=16,\n                                            class_mode='categorical',\n                                            target_size=(150, 150),\n                                                    shuffle=True)\n\n\nvalid_generator = valid_datagen.flow_from_directory(val_dir,\n                                                    batch_size=16,\n                                            class_mode='categorical',\n                                                target_size=(150, 150),\n                                                    shuffle=False)","4dd53dd5":"test_datagen=ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                  batch_size=1,\n                                            class_mode='categorical',\n                                                target_size=(150, 150),\n                                                    shuffle=False)","1ec57372":"class_weights = []\ntotal_samples = train_generator.samples\ntotal_classes = len(train_generator.class_indices)\nfor ele in train_counts:\n    result = round(total_samples \/ (total_classes * ele),2)\n    class_weights.append(result)\n\nclass_weights = dict(zip(train_generator.class_indices.values(),class_weights))\nprint(class_weights)","8cbc160e":"tf.keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)","22c8c2e3":"def custom_model():\n    \n    \n    cus_model = VGG19(input_shape = (150,150,3),        \n                         weights='imagenet', \n                         include_top= False,)\n    \n   #Using pre-trained weights from imagenet \n    for layer in cus_model.layers:\n        layer.trainable = False\n\n    # Adding layers in a sequential manner\n    x = layers.Flatten()(cus_model.output)\n\n    x = layers.Dense(512, activation='relu')(x)\n    \n    x = layers.Dropout(0.2)(x)\n \n    x = layers.Dense(5, activation='softmax')(x)\n\n    model = Model(cus_model.input,x)\n    \n    return model","a2284bfb":"model = custom_model()\nmodel.summary()","39cf5eee":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 ** (epoch \/ s)\n\n    return exponential_decay_fn\n\n\nexponential_decay_fn = exponential_decay(lr0=0.0009, s=5)\n\nlr_scheduler_ed = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n\n# Checkpoint callback\n# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"yoga_model.h5\", save_best_only=True)\n\n# Early stopping callback\nearly_stopping_m = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)","6bfe3559":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","d3521e80":"history = model.fit(train_generator,\n                    validation_data=valid_generator,\n                    epochs=30,\n                    batch_size=32,\n                    callbacks=[lr_scheduler_ed, early_stopping_m],\n                    verbose=1\n                    )","d343f51b":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(history.epoch, acc, 'r', label='Training accuracy')\nplt.plot(history.epoch, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.grid(True)\nplt.figure()\n","24a258b7":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(history.epoch, loss, 'r', label='Training Loss')\nplt.plot(history.epoch, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.grid(True)\nplt.show()","a1a348ff":"plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Learning Rate\")\nplt.title(\" exponential_decay\", fontsize=14)\nplt.grid(True)\nplt.show()","06e19c43":"pd.DataFrame(history.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1)","eff41bee":"model.evaluate(test_generator, batch_size=1)","0d45b5f1":"y_pred = model.predict(test_generator)\ny_pred = np.argmax(y_pred, axis=1)\nprint(classification_report(test_generator.classes, y_pred))","4107df75":"cf_matrix = confusion_matrix(test_generator.classes, y_pred)\nLabels = ['downdog', 'tree', 'warrior2', 'goddess', 'plank']\nplt.figure(figsize=(20, 8))\nheatmap = sns.heatmap(cf_matrix, xticklabels=Labels, yticklabels=Labels, annot=True, fmt='d', color='blue')\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')\nplt.title('Confusion Matrix')\nplt.show()","1b9d9b75":"### **Fitting the model:**","ae784b78":"### Intializing directiores:","3c4895d7":"### **Plotting Graphs:**","bc09e5b1":"### Graph for learning rate ~ Exponential Decay","d6c725ed":"### **Callbacks:**","598979c9":"###  **Understanding the dataset:**","0927ddf2":"### Importing necessary modules:","c9873d6c":"### Confusion Matrix:","a2c57d24":"#### Various classes with number of images in training data:","831218bd":"### **VGG19-Model**","4c1727f3":"### Plotting all the metrics in one graph","aa67c853":"# Introduction\n\nYoga is a very well-known practice to curb anxiety and relieve stress. There are many yoga poses but the very well-known ones are the downward dog pose, goddess pose, tree pose, plank pose and the warrior pose. Smart technology can be used to classify between them.","5dd7ea52":"### **Compiling the model:**","8849ee8c":"### **Structure of the model:**","386004dd":"### **Assigning weights to classes:**","3086232a":"### **Evaluate model with test dataset**","3e2e62f8":"### Graph between training loss and validation Loss:","f02005b6":"### Data Augmentation:","5c810d5f":"### Graph betweeen training accuracy and validation accuracy:"}}