{"cell_type":{"fa585f12":"code","2df144bf":"code","1cf829e1":"code","02026232":"code","d993c6c9":"code","0f9b7f67":"code","74f0657b":"code","dc880284":"code","40eec445":"code","87bdadfb":"code","59d6cb09":"code","08631520":"code","85d6cc45":"code","6603cc5b":"code","55ad0101":"code","f945d8c1":"code","aa96cf34":"code","d37cb9ae":"markdown","58644541":"markdown","d9ef0fdb":"markdown","ef3e6ab5":"markdown","91e0f1e7":"markdown","97a3a049":"markdown","2d4c562b":"markdown","5f142fd5":"markdown","073ff6d6":"markdown","79fe7cc7":"markdown","14d50f28":"markdown","b1b3bdcd":"markdown","b84c411b":"markdown","695a09f5":"markdown"},"source":{"fa585f12":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2df144bf":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix, f1_score, accuracy_score\n\nimport warnings\nwarnings.simplefilter(\"ignore\")","1cf829e1":"strokedf = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\n\n# Check the initial rows\nstrokedf.head()","02026232":"# Lets check the datastructure\nstrokedf.info()","d993c6c9":"# Check for missing values\n\nstrokedf.isna().sum()","0f9b7f67":"strokedf['bmi'] = strokedf['bmi'].fillna(strokedf.groupby('stroke')['bmi'].transform('mean'))\n\n# Check whether imputations are done\nstrokedf.isna().sum()\n\n# Another alternate approach\n\n# strokedf[\"bmi\"] = strokedf.groupby(\"stroke\").transform(lambda x: x.fillna(x.mean()))","74f0657b":"# Explore the target variable\n\nsns.countplot(strokedf['stroke'])\n\nstrokedf['stroke'].value_counts()","dc880284":"print(\"Gender by the target variable\")\nprint(strokedf.groupby('stroke')['gender'].value_counts())\nprint(\"\\n\")\nprint(\"hypertension by the target variable\")\nprint(strokedf.groupby('stroke')['hypertension'].value_counts())\nprint(\"\\n\")\nprint(\"heart_disease by the target variable\")\nprint(strokedf.groupby('stroke')['heart_disease'].value_counts())\n\n\n# Doing the visualizations\n\nfig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(16,6))\nsns.countplot(x='gender', hue='stroke', data=strokedf, ax=ax1);\nsns.countplot(x='hypertension', hue='stroke', data=strokedf, ax=ax2);\nax2.set_ylabel(\"\")\nsns.countplot(x='heart_disease', hue='stroke', data=strokedf, ax=ax3);\nax3.set_ylabel(\"\")\nplt.show()","40eec445":"# Explore Age attribute\n\nprint(strokedf.groupby('stroke')['age'].mean())\n\n# Explore Age variable with respect to the stroke attribute\nsns.catplot(x=\"stroke\", y=\"age\", kind=\"box\", data=strokedf);\n\ng = sns.FacetGrid(data=strokedf, col='stroke', height=5)\ng.map(sns.distplot, 'age')\nplt.show()","87bdadfb":"# Explore gender and age with respect to stroke and establish any conclusion\n\nsns.catplot(x=\"gender\", y=\"age\", hue='stroke', kind=\"box\", data=strokedf);","59d6cb09":"print(\"ever_married by the target variable\")\nprint(strokedf.groupby('stroke')['ever_married'].value_counts())\nprint(\"\\n\")\nprint(\"work_type by the target variable\")\nprint(strokedf.groupby('stroke')['work_type'].value_counts())\nprint(\"\\n\")\nprint(\"Residence_type by the target variable\")\nprint(strokedf.groupby('stroke')['Residence_type'].value_counts())\nprint(\"\\n\")\nprint(\"smoking_status by the target variable\")\nprint(strokedf.groupby('stroke')['smoking_status'].value_counts())\n\n\n# Doing the visualizations\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4,figsize=(20,6))\nsns.countplot(x='ever_married', hue='stroke', data=strokedf, ax=ax1);\nsns.countplot(x='work_type', hue='stroke', data=strokedf, ax=ax2);\nax2.set_ylabel(\"\")\nsns.countplot(x='Residence_type', hue='stroke', data=strokedf, ax=ax3);\nax3.set_ylabel(\"\")\nsns.countplot(x='smoking_status', hue='stroke', data=strokedf, ax=ax4);\nax4.set_ylabel(\"\")\nplt.show()","08631520":"\n# Explore avg_glucose_level variable with respect to the stroke attribute\n\nprint(strokedf.groupby('stroke')['avg_glucose_level'].mean())\n\nsns.catplot(x=\"stroke\", y=\"avg_glucose_level\", kind=\"box\", data=strokedf);\n\ng = sns.FacetGrid(data=strokedf, col='stroke', height=5)\ng.map(sns.distplot, 'avg_glucose_level')\nplt.show()","85d6cc45":"# Explore bmi variable with respect to the stroke attribute\n\nprint(strokedf.groupby('stroke')['bmi'].mean())\n\nsns.catplot(x=\"stroke\", y=\"bmi\", kind=\"box\", data=strokedf);\n\ng = sns.FacetGrid(data=strokedf, col='stroke', height=5)\ng.map(sns.distplot, 'bmi')\nplt.show()","6603cc5b":"# Initialize the label encoder\nlabel_encoder = LabelEncoder() \n\n# Encode labels \nstrokedf['gender'] = label_encoder.fit_transform(strokedf['gender'])\nstrokedf['ever_married'] = label_encoder.fit_transform(strokedf['ever_married'])\nstrokedf['work_type'] = label_encoder.fit_transform(strokedf['work_type'])\nstrokedf['Residence_type'] = label_encoder.fit_transform(strokedf['Residence_type'])\nstrokedf['smoking_status'] = label_encoder.fit_transform(strokedf['smoking_status'])","55ad0101":"features = strokedf.drop('stroke', axis=1)\ntarget = strokedf['stroke']\n\nfeatures_train, features_test, target_train, target_test = train_test_split(features, \n                                                                            target, \n                                                                            test_size=0.3, random_state=101,\n                                                                           stratify = target)","f945d8c1":"# Training the Random Forest model\nfrom sklearn.ensemble import RandomForestClassifier\n\n# we will build the random forest classifier both using entropy and gini index\nrfc = RandomForestClassifier(n_estimators=100, criterion='entropy')\nrfc.fit(features_train, target_train)","aa96cf34":"predictions = rfc.predict(features_test)\n\nprint(\"Confusion Matrix - Random Forest Using Gini Index\\n\")\nprint(confusion_matrix(target_test,predictions))\nprint(\"\\n\")\nprint(\"Classification Report \\n\")\nprint(classification_report(target_test,predictions))\nprint(\"\\n\")\nprint(\"Accuracy Score \\n\")\nprint(accuracy_score(target_test, predictions))\nprint(\"\\n\")\nprint(\"F1 Score \\n\")\nprint(f1_score(target_test, predictions))","d37cb9ae":"#### exploration Age attribute","58644541":"### Building the Model","d9ef0fdb":"## Load the dataset and verify the dataload","ef3e6ab5":"#### exploration - ever_married, work_type, Residence_type, smoking_status attributes","91e0f1e7":"#### exploration avg_glucose level","97a3a049":"#### exploration bmi attribute","2d4c562b":"### Predictions and Evaluations","5f142fd5":"## Modelling - Random Forest","073ff6d6":"## Library imports","79fe7cc7":"### Perform Train , Test Split of the data\n\nSince proportion of the stroke data is less, we will perform a stratified sampling","14d50f28":"### Peform Label Encoder Transformations","b1b3bdcd":"#### exploration  - gender, hypertension and heart_disease attributes","b84c411b":"## Exploratory Data Analysis","695a09f5":"### Missing value treatment for 'bmi' attribute\n\nThe approach is to substitue mean of the bmi by the target variable - stroke"}}