{"cell_type":{"40bc5695":"code","ea1d8017":"code","887386da":"code","6e7c8ed5":"code","589013ad":"code","0ebaadf1":"code","cd5bbb75":"code","471258ce":"code","26a52d44":"code","24cef263":"code","84810aa9":"code","8390fa1b":"code","8dc1a896":"code","6e4128fd":"code","4151e5eb":"code","5ab5dcff":"code","6d378c35":"code","0068522c":"code","eb00ec08":"code","07719f67":"code","d4ae5012":"markdown","2fef5291":"markdown","5a12f0ce":"markdown","9ae3f5b1":"markdown","60dd055d":"markdown","22528df8":"markdown","6a06ffa7":"markdown","cf3ba27c":"markdown","8371ccb5":"markdown","c55bfc13":"markdown","f44c9834":"markdown"},"source":{"40bc5695":"import pandas as pd\nimport numpy as np\nimport warnings \nwarnings.filterwarnings('ignore')","ea1d8017":"train_df=pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_df","887386da":"test_df=pd.read_csv('..\/input\/titanic\/test.csv')","6e7c8ed5":"train_df.isnull().sum()","589013ad":"# Drop the Cabin column as it has close to 80% missing data. Will not make sense to Impute it.\ntrain_df.drop('Cabin', axis=1, inplace=True)\ntest_df.drop('Cabin', axis=1, inplace=True)\n\ntrain_df.isnull().sum()","0ebaadf1":"#Missing value imputation\ncolumns=['Age','Embarked']\nfor i in columns:\n    train_df[i].fillna(value=np.nan,inplace=True)","cd5bbb75":"#Replacing np.nan with average\ntrain_df['Age'].fillna(train_df['Age'].mean(),inplace=True)\n#Replacing np.nan with mode for Embarked\ntrain_df['Embarked'].fillna(train_df['Embarked'].mode()[0],inplace=True)","471258ce":"test_df.isnull().sum()","26a52d44":"columns=['Age','Fare']\nfor i in columns:\n    test_df[i].fillna(value=np.nan,inplace=True)","24cef263":"#Replacing np.nan with average\ntest_df['Age'].fillna(test_df['Age'].mean(),inplace=True)\ntest_df['Fare'].fillna(test_df['Fare'].mean(),inplace=True)","84810aa9":"# Dropping irrelaveant features from test and train sets. Also alloting dependent var \"y\" and independent vars \"X\".\n\ny = train_df['Survived'].astype(int)\nX = train_df.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1)\nd2=test_df[\"PassengerId\"]\nn_test_df = test_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)","8390fa1b":"cat_col=['object']\ndf_catcols_only=X.select_dtypes(include=cat_col)\ndf_catcols_only1=n_test_df.select_dtypes(include=cat_col)","8dc1a896":"df_catcols_only.columns","6e4128fd":"df_catcols_only1.columns","4151e5eb":"X=pd.get_dummies(data=X,columns=['Sex', 'Embarked'],drop_first=True)\nn_test_df=pd.get_dummies(data=n_test_df,columns=['Sex', 'Embarked'],drop_first=True)","5ab5dcff":"from sklearn.model_selection import train_test_split\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=1)\n\nprint(Xtrain.shape)\nprint(Xtest.shape)\nprint(ytrain.shape)\nprint(ytest.shape)","6d378c35":"from sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBClassifier\n\nparameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n               \"max_depth\": [2, 4, 7, 10],\n               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n               \"reg_alpha\": [0, 0.5, 1],\n               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n               \"min_child_weight\": [1, 3, 5, 7],\n               \"n_estimators\": [100, 250, 500, 1000]}\n\nxgb_rscv = RandomizedSearchCV(XGBClassifier(), param_distributions = parameters, cv = 7,  random_state = 40)\n\nmodel_rscv = xgb_rscv.fit(Xtrain, ytrain)\nmodel_rscv.best_params_","0068522c":"# Best parameter values\ntuned_model = XGBClassifier(booster='gbtree', subsample= 0.6,\n reg_lambda= 1,\n reg_alpha= 0,\n n_estimators= 100,\n min_child_weight= 5,\n max_depth= 2,\n learning_rate = 0.1,\n gamma= 1.5,\n colsample_bytree= 1.0)\n\ntuned_model.fit(Xtrain, ytrain)","eb00ec08":"tuned_model.score(Xtest, ytest)","07719f67":"predictions = tuned_model.predict(n_test_df)\n\noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","d4ae5012":"## Missing value Analysis : Age & Embarked have a few missing values, Cabin has a lot of missing values.","2fef5291":"## Dummifying Categorical variables.","5a12f0ce":"* pid - Index. Will remove it.\n* Survival - Its a target variable, so its gonna go anyways.\n* pclass - It will be relevant, remmember in the movie how the first class passengers were being taken to the boat first. Hell they   took the dog too.\n* Sex - 70% of survivors were women. So its relevant. Remmember - Ladies first.\n* Age - The old and mothers were lifted first. So will keep it too.\n* sibsp\/parch - will keep them. Later we will do feature engineering with them.\n* ticket - Looks to me like a alphanumeric random set. Cut it.\n* fare - Will keep it.\n* cabin - Already removed. Too many missing values.\n* embarked - Will keep it.","9ae3f5b1":"## Feature Selection\/Rejection","60dd055d":"## Model Training & Prediction.","22528df8":"# Categorical Train Columns","6a06ffa7":"## Submission## ","cf3ba27c":"Analysis and Preprocessing.\n* Look for missing values, drop them or fix them.\n* Feature Selection\/Rejection\n* Dummify the categorical variables.","8371ccb5":"# Categorical Test Columns","c55bfc13":"# Modelling with hyperparameter tunining for best results.","f44c9834":"### Before we start, we need to divide the training data into a training set and a testing set. This will ensure that our model predict on data it has never seen before, which will give its true sense of strength."}}