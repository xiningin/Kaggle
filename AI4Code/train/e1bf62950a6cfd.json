{"cell_type":{"284a21ac":"code","52196757":"code","d2c55ab7":"code","0f1b68a7":"code","ae57c6f1":"code","06fc76d1":"code","fa70635f":"code","215348a6":"code","9dcad988":"code","6170d993":"code","11bf8ce8":"code","cfd88ce7":"code","718fbfef":"markdown","852273c8":"markdown","0bac7ab4":"markdown","47917f88":"markdown","455069a6":"markdown"},"source":{"284a21ac":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n# Image processing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\nfrom imageio import imread\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n\nprint(os.listdir('..\/input\/nonsegmentedv2\/'))\ndirectory=os.listdir('..\/input\/nonsegmentedv2\/')\n# Any results you write to the current directory are saved as output.","52196757":"\n\nf, ax = plt.subplots(nrows=1,ncols=12, figsize=(20,5))\ni=0\nfor d in directory:\n    file='..\/input\/nonsegmentedv2\/'+d+'\/1.png'\n    im=imageio.imread(file)\n    #print(im,imread(img_file).shape)\n    #f, ax = plt.subplots(figsize=(12,5))\n    ax[i].imshow(im,resample=True)\n    ax[i].set_title(d, fontsize=8)\n    i+=1\n    \nplt.suptitle(\"Plants\")\nplt.tight_layout()\nplt.show()","d2c55ab7":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        validation_split=0.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/nonsegmentedv2\/',\n        target_size=(64,64),\n        batch_size=32,\n        class_mode='categorical',\n        subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n        '..\/input\/nonsegmentedv2\/',\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='categorical',\n        subset='validation')\n\ninput_shape=(64,64,3)\nnum_classes=12","0f1b68a7":"model = Sequential()\nmodel.add(Conv2D(32,(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\n#model.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","ae57c6f1":"# We'll stop training if no improvement after some epochs\nearlystopper1 = EarlyStopping(monitor='loss', patience=10, verbose=1)\n\n# Save the best model during the traning\ncheckpointer1 = ModelCheckpoint('best_model1.h1'\n                                ,monitor='val_acc'\n                                ,verbose=1\n                                ,save_best_only=True\n                                ,save_weights_only=True)","06fc76d1":"training=model.fit_generator(\n        train_generator,\n        steps_per_epoch=100,\n        epochs=30,\n        validation_data = validation_generator, \n        callbacks=[earlystopper1, checkpointer1]\n       )","fa70635f":"# Get the best saved weights\nmodel1.load_weights('best_model1.h5')","215348a6":"train_generator1 = train_datagen.flow_from_directory(\n        '..\/input\/nonsegmentedv2\/',\n        target_size=(16,16),\n        batch_size=32,\n        class_mode='categorical',\n        subset='training')\n\nvalidation_generator1 = train_datagen.flow_from_directory(\n        '..\/input\/nonsegmentedv2\/',\n        target_size=(16, 16),\n        batch_size=32,\n        class_mode='categorical',\n        subset='validation')\n\ninput_shape=(16,16,3)\nnum_classes=12","9dcad988":"checkpointer1 = ModelCheckpoint('best_model1.h2'\n                                ,monitor='val_acc'\n                                ,verbose=1\n                                ,save_best_only=True\n                                ,save_weights_only=True)","6170d993":"model1 = Sequential()\nmodel1.add(Conv2D(16,(3, 3),\n                 activation='relu',\n                 input_shape=input_shape, padding='same'))\n#model.add(MaxPooling2D(pool_size=(3, 3)))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.25))\n\nmodel1.add(Conv2D(16, (3, 3), activation='relu',padding='same'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPooling2D(pool_size=(3, 3)))\nmodel1.add(Dropout(0.25))\n\nmodel1.add(Flatten())\n\nmodel1.add(Dense(128, activation='relu'))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.25))\nmodel1.add(Dense(num_classes, activation='softmax'))\n\nmodel1.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","11bf8ce8":"training1=model1.fit_generator(\n        train_generator1,\n        steps_per_epoch=100,\n        epochs=30,\n        validation_data = validation_generator1, \n        validation_steps =30,\n        callbacks=[earlystopper1, checkpointer1]\n       )\nmodel1.load_weights('best_model1.h2')","cfd88ce7":"f, ax = plt.subplots(2,1, figsize=(5,5))\nax[0].plot(training.history['loss'], label=\"Loss\")\nax[0].plot(training.history['val_loss'], label=\"Validation loss\")\nax[0].set_title('%s: loss')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\nax[0].legend()\n    \n    # Accuracy\nax[1].plot(training1.history['acc'], label=\"Accuracy\")\nax[1].plot(training1.history['val_acc'], label=\"Validation accuracy\")\nax[1].set_title('%s: accuracy')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nax[1].legend()\nplt.tight_layout()\nplt.show()","718fbfef":"##Second model- starting from different reshaping","852273c8":"##For each folder show one exaple","0bac7ab4":"##Importing libraries, listing directories","47917f88":"##Building first model","455069a6":"##Specify train and validation series"}}