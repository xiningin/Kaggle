{"cell_type":{"101bc9cb":"code","4322c5ab":"code","c8ee4d9a":"code","75f4b95b":"code","0a2e20a1":"code","e1da54e3":"code","b35106be":"code","159e7111":"code","ea96686e":"code","b9a65e19":"code","adbfa037":"code","e2054160":"code","11bb0109":"code","099fcd82":"code","146f7647":"code","d455c1d9":"code","2b01efab":"code","c38165d7":"code","25aede6b":"code","7a7da768":"code","a98059e9":"code","70fb6be1":"code","4757c37d":"code","ae312783":"code","ead10d59":"code","c3f21e28":"code","997835b5":"code","3d1d95a4":"code","9ae1f56a":"code","b6568e66":"code","6739089e":"code","b4280bfd":"code","3788e83a":"code","7afda5ec":"code","c79512c9":"code","4936edd4":"code","cb1087ca":"code","b054c04d":"code","7e208c4d":"markdown","4451f7c1":"markdown","453679bf":"markdown","bb56022a":"markdown","27953cba":"markdown","506a140b":"markdown"},"source":{"101bc9cb":"#import library\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport nltk\nnltk.download('stopwords')\nfrom wordcloud import WordCloud\nimport re\nimport string\nstring.punctuation\nimport matplotlib.pyplot as plt\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import metrics","4322c5ab":"tweet = pd.read_csv('..\/input\/tweet-sentiment-and-emotion-analysis\/all_tweets.csv')","c8ee4d9a":"tweet.shape","75f4b95b":"tweet.head()","0a2e20a1":"#drop unnamed: 0\ntweet = tweet.drop('Unnamed: 0', 1)\ntweet.head()","e1da54e3":"tweet.info()","b35106be":"#selection data\ndf1 = tweet[['text', 'sentiment']]\ndf1.head()","159e7111":"#defining function for remove rt\ndef remove_rt(text):\n    rt = re.sub(r'^RT[\\s]+', '', text)\n    return rt\n\n#applying function to the column\ndf1['text_no_rt'] = df1['text'].apply(lambda x: remove_rt(x))\ndf1.head()","ea96686e":"#defining the function to remove punctuation\ndef remove_punctuation(text):\n    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree\n\n#storing the puntuation free text\ndf1['clean_text'] = df1['text_no_rt'].apply(lambda x:remove_punctuation(x))\ndf1.head()","b9a65e19":"#setting lower case\ndf1['text_lower'] = df1['clean_text'].apply(lambda x: x.lower())\ndf1.head()","adbfa037":"#defining function for tokenization\ndef tokenization(text):\n    tokens = re.split('W+', text)\n    return tokens\n\n#applying function to the column\ndf1['text_tokenied'] = df1['text_lower'].apply(lambda x: tokenization(x))\ndf1.head()","e2054160":"#stop words present in the library\nstopwords = nltk.corpus.stopwords.words('english')\nstopwords[0:10]","11bb0109":"#defining the function to remove stopwords from tokenized text\ndef remove_stopwords(text):\n    output= [i for i in text if i not in stopwords]\n    return output","099fcd82":"#applying the function\ndf1['no_stopwords'] = df1['text_tokenied'].apply(lambda x:remove_stopwords(x))\ndf1.head()","146f7647":"#defining the object for stemming\nporter_stemmer = PorterStemmer()","d455c1d9":"#defining a function for stemming\ndef stemming(text):\n    stem_text = [porter_stemmer.stem(word) for word in text]\n    return stem_text\n\ndf1['text_stemmed'] = df1['no_stopwords'].apply(lambda x: stemming(x))\ndf1.head()","2b01efab":"df2 = df1[['clean_text', 'sentiment']]\ndf2.head()","c38165d7":"positive = \" \".join(df2[df2.sentiment == 'positive']['clean_text'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(positive)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Positive Text\")\nplt.axis('off')\nplt.show()","25aede6b":"neutral = \" \".join(df2[df2.sentiment == 'neutral']['clean_text'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(neutral)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Neutral Text\")\nplt.axis('off')\nplt.show()","7a7da768":"negative = \" \".join(df2[df2.sentiment == 'negative']['clean_text'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(negative)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Negative Text\")\nplt.axis('off')\nplt.show()","a98059e9":"#visualize sentiment\ndf2['sentiment'].value_counts()\n\nplt.figure(figsize = (10,6))\nplt.title(\"Sentiment Analysis of Tweets\")\nplt.xlabel(\"Sentiment\")\nplt.ylabel(\"Count\")\n\ndf2['sentiment'].value_counts().plot(kind = 'bar')\nplt.show()","70fb6be1":"plt.figure(figsize = (10,6))\nsns.countplot(tweet['label'])\nplt.title(\"Type of Tweets\")\nplt.show()","4757c37d":"#selection data\ndf3 = df1[['text_lower', 'sentiment']]\ndf3.head()","ae312783":"#transform data\ndf3.sentiment[df3.sentiment == 'negative'] = 0\ndf3.sentiment[df3.sentiment == 'neutral'] = 1\ndf3.sentiment[df3.sentiment == 'positive'] = 2","ead10d59":"df3['sentiment'] = df3['sentiment'].astype(int)\ndf3.head()","c3f21e28":"#split data\ntweet = df3['text_lower']\nsentiment = df3['sentiment']\nX_train, X_test, y_train, y_test = train_test_split(tweet, sentiment, test_size = 0.3, random_state = 1)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","997835b5":"cv = CountVectorizer()\nvector_x_train = cv.fit_transform(X_train) \nvector_x_test = cv.transform(X_test)","3d1d95a4":"nb = MultinomialNB()\nnb.fit(vector_x_train, y_train)\n%time nb.fit(vector_x_train, y_train)","9ae1f56a":"#prediction\ny_pred = nb.predict(vector_x_test)\nprint(y_pred)","b6568e66":"#result\nprediction = pd.DataFrame({'prediction' : y_pred})\nprediction.head()","6739089e":"#take the result to dataset\njoin = [df3, prediction]\nresult = pd.concat(join, axis = True)\nresult.head()","b4280bfd":"#accuracy score\naccuracy = metrics.accuracy_score(y_test, y_pred)\nprint('Accuracy Score : ', accuracy)","3788e83a":"tfid = TfidfVectorizer()\nvector_x_train_2 = tfid.fit_transform(X_train) \nvector_x_test_2 = tfid.transform(X_test)","7afda5ec":"nb = MultinomialNB()\nnb.fit(vector_x_train_2, y_train)\n%time nb.fit(vector_x_train_2, y_train)","c79512c9":"#prediction\ny_pred_2 = nb.predict(vector_x_test_2)\nprint(y_pred_2)","4936edd4":"#result\nprediction = pd.DataFrame({'prediction' : y_pred_2})\nprediction.head()","cb1087ca":"#take the result to dataset\njoin = [df3, prediction]\nresult = pd.concat(join, axis = True)\nresult.head()","b054c04d":"#accuracy score\naccuracy = metrics.accuracy_score(y_test, y_pred_2)\nprint('Accuracy Score : ', accuracy)","7e208c4d":"## Text Processing","4451f7c1":"### CountVectorizer Method","453679bf":"## Data Extraction","bb56022a":"## Naive Bayes Model","27953cba":"# Sentiment Analysis of Tweet","506a140b":"### TFIDFVectorizer"}}