{"cell_type":{"b73c9c23":"code","f928a174":"code","609685f1":"code","59e00147":"code","b36f30ad":"code","0032afeb":"code","c3e292cb":"code","18d21326":"code","09995d4f":"code","ea311278":"code","a3262b4a":"code","4b2e50dc":"code","df14d1d3":"code","c8dce9fa":"code","695340d0":"code","810c21bc":"code","0a27ac0c":"code","6a23ed2b":"code","af721a0c":"code","68d931a5":"code","ea4cb0fc":"code","7798785f":"code","e58a8d6d":"markdown","cdcfb5c3":"markdown","3911225c":"markdown","14d49155":"markdown","3a665375":"markdown","c94c2a3b":"markdown","a0c047c5":"markdown","a8afbfc4":"markdown","dd2ab3ae":"markdown","08520f09":"markdown"},"source":{"b73c9c23":"import os, glob\nimport random\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport multiprocessing\nfrom copy import deepcopy\nfrom sklearn.metrics import precision_recall_curve, auc\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.densenet import DenseNet201\nfrom tensorflow.keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import optimizers, applications\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nfrom tensorflow.keras.utils import Sequence\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\nfrom tqdm import tqdm_notebook as tqdm\nimport json\nimport os\nimport gc\nfrom numpy.random import seed\nseed(10)\n\n%matplotlib inline","f928a174":"!pip install git+https:\/\/github.com\/qubvel\/efficientnet -q","609685f1":"os.listdir('..\/input')","59e00147":"\nAUTO = tf.data.experimental.AUTOTUNE\ntry:\n    # Create strategy from tpu\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print('tpu:',tpu)\nexcept:\n    print('no tpu.....')\n    strategy=None\n    tpu=None\n\n\n\n# Data access\nif tpu:\n    GCS_DS_PATH = KaggleDatasets().get_gcs_path('iwildcam-2020-fgvc7')\n    tf_records_path= KaggleDatasets().get_gcs_path('iwildcam2020-64-tf-records')\n    tf_records_path2=KaggleDatasets().get_gcs_path('iwildcam2020-64-tf-records')\n    test_tf_records_path=KaggleDatasets().get_gcs_path('iwildcam2020-64-tf-records')\n    #If you want to use the best speed of TPU,then the batch_size should be times of 16. \n    #Since TPU V3-8 has 8 cores,so 16*8\n    BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\n# Configuration\nEPOCHS = 8#3\nimg_size = 64#96\n","b36f30ad":"TRAINING_FILENAMES = tf.io.gfile.glob(tf_records_path + '\/*train.rec')\nTRAINING_FILENAMES.extend(tf.io.gfile.glob(tf_records_path2 + '\/*zero.rec'))\nTRAINING_FILENAMES","0032afeb":"TEST_FILENAMES=tf.io.gfile.glob(test_tf_records_path + '\/*test.rec')","c3e292cb":"\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [img_size,img_size, 3]) # explicit size needed for TPU\n    return image\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n#     image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n    \n    \ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset","18d21326":"train_dataset=get_training_dataset()\n","09995d4f":"sub_df = pd.read_csv('..\/input\/iwildcam-2020-fgvc7\/sample_submission.csv')\nsub_df.head()","ea311278":"test_dataset=get_test_dataset()\n","a3262b4a":"# import efficientnet.keras as efn \nimport  efficientnet.tfkeras as efn \n\n\nwith strategy.scope():\n    model = tf.keras.Sequential([\n        efn.EfficientNetB7(\n            input_shape=(img_size, img_size, 3),\n            weights='imagenet',\n            include_top=False\n        ),\n        L.GlobalAveragePooling2D(),\n        L.Dense(216, activation='softmax')#573\n    ])\n\n    model.compile(\n        optimizer='adam',\n         loss = 'sparse_categorical_crossentropy',\n        metrics=['sparse_categorical_accuracy']\n    )\n    model.summary()\n","4b2e50dc":"# Callbacks\n\nearly = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\nbest_checkpoint='model.h5'\ncheckpoint = ModelCheckpoint(\n    best_checkpoint, \n    monitor='val_accuracy', \n    verbose=1, \n#     save_best_only=True, \n    save_weights_only=True,\n    mode='auto'\n)","df14d1d3":"%%time\n# STEPS_PER_EPOCH = train_x.shape[0] \/\/ BATCH_SIZE\nSTEPS_PER_EPOCH=(143736+3709) \/\/ BATCH_SIZE\nhistory = model.fit(\n    train_dataset, \n    epochs=EPOCHS, \n    verbose=2,\n    callbacks=[early,checkpoint],\n    steps_per_epoch=STEPS_PER_EPOCH,\n#     validation_data=valid_dataset\n)","c8dce9fa":"import gc\n\ngc.collect()","695340d0":"sam_sub_df=sub_df.copy()\nsam_sub_df[\"file_name\"] = sam_sub_df[\"Id\"].map(lambda str : str + \".jpg\")","810c21bc":"%%time\nmodel.load_weights(best_checkpoint)\n\npredict=model.predict(test_dataset, verbose=1).astype(float)","0a27ac0c":"print(len(predict))\n","6a23ed2b":"predicted_class_indices=np.argmax(predict,axis=1)","af721a0c":"predicted_class_indices","68d931a5":"import pickle\nwith open('..\/input\/iwildcam2020-classes-dict\/cid_invert_dict.pkl', mode='rb') as fin:\n    cid_invert_dict=pickle.load(fin)","ea4cb0fc":"def transform(x):\n    return cid_invert_dict[str(x)]","7798785f":"sam_sub_df[\"Category\"] = predicted_class_indices\nsam_sub_df[\"Category\"]=sam_sub_df[\"Category\"].apply(transform)\n\n\n         \nsam_sub_df = sam_sub_df.loc[:,[\"Id\", \"Category\"]]\nsam_sub_df.to_csv(\"submission.csv\",index=False)\nsam_sub_df.head()","e58a8d6d":"# Train","cdcfb5c3":"## About this kernel\n\nCredited to @Nayu's kernel. \n\nI changed it with tf2.x codes and support TPU. For fast training, I resized the images into 64*64. <br>\nLet your TPU burn...","3911225c":"### Model","14d49155":"# TPU setup","3a665375":"I refered following kernels, thank you!\n\nhttps:\/\/www.kaggle.com\/ateplyuk\/inat2019-starter-keras-efficientnet\/data\n\nhttps:\/\/www.kaggle.com\/mobassir\/keras-efficientnetb2-for-classifying-cloud\n\nhttps:\/\/www.kaggle.com\/mgornergoogle\/getting-started-with-100-flowers-on-tpu\n","c94c2a3b":"### Test data","a0c047c5":"**Example of Fine-tuning from pretrained model using Keras  and Efficientnet (https:\/\/pypi.org\/project\/efficientnet\/).**","a8afbfc4":"# Train data","dd2ab3ae":"## Data processing functions:","08520f09":"### Prediction"}}