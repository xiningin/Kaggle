{"cell_type":{"be92f209":"code","8c638fea":"code","eb276d89":"code","be3bacd9":"code","89b0d4cd":"code","da78b350":"code","987f7162":"code","e00546cd":"code","66c877d3":"code","9a9773cb":"code","e5872cb9":"code","450b3e19":"code","3a51dddc":"code","bc4eb6e4":"code","f00b028d":"code","2ae9b2b6":"code","4a6e1a09":"code","2d7359cd":"code","65bee4a1":"code","2a6f6c23":"code","73f25d57":"code","11ba67ce":"code","186ec968":"code","8e1b470f":"code","151d7376":"code","bcec7725":"code","fa8e37c0":"code","9275635d":"code","469b7199":"code","dfd5bbed":"code","e18e60b0":"code","99e1d8bd":"code","cd63fe5c":"code","9993bd31":"code","3bffd6e2":"code","bcbf6cf1":"code","e51a4af9":"code","3a873668":"code","18215888":"code","1422feec":"code","3b13e39c":"markdown","7ae701dc":"markdown","c4d04f4b":"markdown","44c899d3":"markdown","45cb40cb":"markdown","ae9885ce":"markdown","8f148969":"markdown","dc1a08be":"markdown","572e0fb7":"markdown","66cab046":"markdown","56f66a62":"markdown","b8292f96":"markdown","fd4a4819":"markdown","b4e3e21a":"markdown","e246f472":"markdown","b1e19ef5":"markdown","4f434d83":"markdown","7aef86a1":"markdown","51eb5e9c":"markdown","57d3e87f":"markdown","c8626a40":"markdown","3b15a416":"markdown","bb66301a":"markdown","a3e4995f":"markdown","bd2014dc":"markdown","360dfb33":"markdown","2a39ad83":"markdown","364d55d7":"markdown","a6693679":"markdown","8a39cd3b":"markdown","40146fc2":"markdown","1ce1205d":"markdown"},"source":{"be92f209":"# Import lib. for data analysis\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom scipy.stats import ttest_ind\n","8c638fea":"loan = pd.read_csv('..\/input\/loan.csv')","eb276d89":"# delete column having 80% of missing values\nmissing_columns = loan.columns[loan.isnull().sum()\/len(loan.index)*100 > 80]\nprint(missing_columns)","be3bacd9":"# Dropping all the columns with null values\nloan = loan.drop(missing_columns, axis=1)\nprint(loan.shape)","89b0d4cd":"# All urls are unique. Not required for the analysis. Dropping this column\nprint(loan['url'].head())\nloan = loan.drop('url', axis=1)","da78b350":"# It is string var. Does not seem like it can be used untill key words can be extracted. \nprint(loan['desc'].head())\nloan = loan.drop('desc', axis=1)","987f7162":"# Removing these columns as they have single value\nprint(loan['initial_list_status'].unique())\nprint(loan['collections_12_mths_ex_med'].unique())\nprint(loan['policy_code'].unique())\nprint(loan['application_type'].unique())\nprint(loan['acc_now_delinq'].unique())\nprint(loan['chargeoff_within_12_mths'].unique())\nprint(loan['delinq_amnt'].unique())\nprint(loan['tax_liens'].unique())\nprint(loan['pymnt_plan'].unique())\n\nloan = loan.drop(['initial_list_status',\n                  'collections_12_mths_ex_med',\n                  'policy_code',\n                  'application_type',\n                  'acc_now_delinq',\n                  'chargeoff_within_12_mths',\n                  'delinq_amnt',\n                  'tax_liens',\n                  'pymnt_plan'], axis=1)","e00546cd":"# Removing member_id column\nloan = loan.drop('member_id', axis=1)","66c877d3":"loan.shape","9a9773cb":"# Convert term column to int\nprint(loan['term'].unique())\nloan['term'] = loan['term'].apply(lambda x : 36 if x==' 36 months' else 60)\nprint(loan['term'].unique())","e5872cb9":"# convert int_rate to float\nprint(loan['int_rate'].head(2))\nloan['int_rate'] = loan['int_rate'].apply(lambda x : float(x[0:-1]))\nprint(loan['int_rate'].head(2))","450b3e19":"# Convert emp_length to int\nloan['emp_length'].unique()\nemp_replace_dict = {'10+ years':10, '< 1 year':0, '1 year':1, \n                    '3 years':3, '8 years':8, '9 years':9,'4 years':4,\n                    '5 years':5, '6 years':6, '2 years':2, '7 years':7}\n\nloan['emp_length'].replace(emp_replace_dict, inplace=True)\nloan['emp_length'].head()","3a51dddc":"# Convert revol_util into int\nloan['revol_util'] = loan['revol_util'].replace(np.nan, '', regex=True)\nloan['revol_util'] = loan['revol_util'].apply(lambda x : float(x[0:-1]) if len(x) > 0 else np.nan )","bc4eb6e4":"# One hot encoding for loan status\nloan_status_dummies = pd.get_dummies(loan['loan_status'])\nprint(loan_status_dummies.head())\n\nloan = pd.concat([loan, loan_status_dummies], axis=1)","f00b028d":"# Analyze correlation between numeric data types\nnumerics = ['uint8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nloan_numeric = loan.select_dtypes(include=numerics)\ncorr = loan_numeric.corr()\n\n# Plot the heat map\nfig, ax = plt.subplots(figsize=(22,22))       \nsns.heatmap(corr, \n            xticklabels=corr.columns,\n            yticklabels=corr.columns,\n            fmt=\".1f\",\n            annot=True,\n            ax = ax)","2ae9b2b6":"# We conclude from above heapmap that these columns have positive correlation.\n# 1. loan_amt\n# 2. funded_amnt\n# 3. funded_amnt_inv\n# 4. installment\n# 5. total_pymnt\n# 6. total_pymnt_inv\n# 7. total_rec_prncp\n# 8. total_rec_int\n\ncorr = loan_numeric.loc[:, ['loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n             'installment', 'total_pymnt', 'total_pymnt_inv',\n             'total_rec_prncp', 'total_rec_int']].corr()\n\nfig, ax = plt.subplots(figsize=(6,6))       \n\nsns.heatmap(corr, \n            xticklabels=corr.columns,\n            yticklabels=corr.columns,\n            annot=True,\n            ax = ax)","4a6e1a09":"# out_prncp and out_prncp_inv have corr value. They are related.\nprint(loan_numeric['out_prncp'].corr(loan_numeric['out_prncp_inv']))","2d7359cd":"# pub_rec and pub_rec_bankruptcies have corr value. They are related.\nloan_numeric['pub_rec'].corr(loan_numeric['pub_rec_bankruptcies'])","65bee4a1":"# recoveries and collection_recovery_fee have corr value. They are related.\nloan_numeric['recoveries'].corr(loan_numeric['collection_recovery_fee'])","2a6f6c23":"# delinq_2yrs and mths_since_last_delinq have negative corr value. They are related.\nloan_numeric['delinq_2yrs'].corr(loan['mths_since_last_delinq'])","73f25d57":"# Remove the 'Current' loan status as it is not relevant in the current context\nloan_subset_df = loan.loc[loan['loan_status'] != 'Current']\n","11ba67ce":"# Helper function to draw plots for numerical data\nclass color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n\ndef showPlots(tips, colname, scale, lq, rq, title):\n    tips_copy = tips.loc[(tips.loc[:, colname] > 0) & \n                         (tips.loc[:,colname] <= tips.loc[:, colname].quantile(rq)) &\n                         (tips.loc[:,colname] >= tips.loc[:, colname].quantile(lq))]\n        \n    if scale == \"log\":\n        tips_copy.loc[:, colname] = np.log(tips_copy.loc[:, colname])\n    fig, axs = plt.subplots(ncols=2, figsize=(20, 6))\n    ax1 = sns.distplot(tips_copy[colname], ax=axs[0]);\n    ax1.set(xlabel=title, ylabel='Fraction', title=title + \" distribution\")\n    ax2=sns.boxplot(x=\"loan_status\", y=colname, data=tips_copy, ax=axs[1])\n    ax2.set(xlabel=\"Loan Status\", ylabel=title, title=title + \" v\/s Loan Status\")\n    \ndef showNumericalPlots(**kwargs):  \n    showPlots(kwargs['data'],\n              kwargs['colname'],\n              kwargs['scale'],\n              kwargs['left_quantile'],\n              kwargs['right_quantile'],\n              kwargs['title']\n             )\n    \ndef compareLoanStatus(data, colname):\n    print(color.BLUE + color.BOLD + 'Charged Off data' + color.END)\n    print(data.loc[data['loan_status'] == 'Charged Off'][colname].describe())\n    print('')\n    print(color.RED + color.BOLD + 'Fully paid data' + color.END)\n    print(data.loc[data['loan_status'] == 'Fully Paid'][colname].describe())\n    \ndef performTTest(data, colname):\n    print('')\n    print(color.GREEN + color.BOLD + 't-score' + color.END)\n    print(ttest_ind(data.loc[data['loan_status'] == 'Charged Off'][colname], \n          data.loc[data['loan_status'] == 'Fully Paid'][colname]))","186ec968":"# Helper function to draw plots for categorical data\ndef showCategoricalPlots(tips, colname, width, xlabel):\n    tips_copy = tips.groupby([colname, 'loan_status'])[colname].count().unstack()\n    tips_copy['Charged Off %'] = (tips_copy['Charged Off'] \/ (tips_copy['Charged Off'] + tips_copy['Fully Paid'])) * 100\n    tips_copy.sort_values(by=\"Charged Off %\", ascending=False, inplace=True)\n    plot = tips_copy.loc[:, ['Charged Off %']].plot.bar(figsize=(width, 4))\n    plot.set(xlabel=xlabel, ylabel=\"Charged Off %\", title=xlabel + \" v\/s Loan Status\")\n    plot.spines['top'].set_visible(False)\n    plot.spines['right'].set_visible(False)\n    print(tips_copy.head(10))\n    \n# Helper function to draw plots for categorical data\ndef showCategoricalPlotsStacked(tips, colname, width, xlabel):\n    tips_copy = tips.groupby([colname, 'loan_status'])[colname].count().unstack().reset_index()\n    tips_copy['Fully Paid %'] = (tips_copy['Fully Paid'] \/ (tips_copy['Charged Off'] + tips_copy['Fully Paid'])) * 100\n    tips_copy['Charged Off %'] = (tips_copy['Charged Off'] \/ (tips_copy['Charged Off'] + tips_copy['Fully Paid'])) * 100\n    tips_copy.sort_values(by=\"Charged Off %\", ascending=False, inplace=True)\n    ax = tips_copy.loc[:, [colname, 'Fully Paid %', 'Charged Off %']].set_index(colname).plot(kind='bar', stacked=True, figsize=(width, 4))\n    ax.set(xlabel=xlabel, ylabel='Loan Status %', title=xlabel + \" v\/s Loan Status\")\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    print(tips_copy.loc[:,[colname, 'Charged Off', 'Fully Paid',  'Charged Off %']].set_index(colname).head(10))\n","8e1b470f":"# Draw dist plot for int_rate and compare the boxplot for Fully paid and Charged off\nshowNumericalPlots(data=loan_subset_df,\n                   colname='int_rate',\n                   left_quantile=0.0,\n                   right_quantile=1.0,\n                   scale='linear',\n                   title='Interest Rate')\n\n\n# Hypothesis : The int_rate variable has higher median for charged_off loan status\ncompareLoanStatus(loan_subset_df, 'int_rate')\n\n# median [charged off] = 13.61%\n# median [fully paid] = 11.49%\n\nperformTTest(loan_subset_df, 'int_rate')\n\n# t-score = 42.48\n# Large t-score confirms that the int_rate for defaulters [Fully Paid] and \n# non-defaulters [Charged Off] are different.\n\n# Inference :  In int_rate is higher, then probability of default is higher.\n","151d7376":"# Draw dist plot for annual_inc and compare the boxplot for Fully paid and Charged off\n# Remove outlier and scale to log\nshowNumericalPlots(data=loan_subset_df,\n                   colname='annual_inc',\n                   left_quantile=0.1,\n                   right_quantile=0.9,\n                   scale='log',\n                   title='Annual Income')\n\n# Hypothesis : The annual_inc variable has higher median for charged_off loan status\ncompareLoanStatus(loan_subset_df, 'annual_inc')\n\n# median [charged off] = $53,000\n# median [fully paid] = $60,000\n\n# Inference :  If annual_inc is lower, then probability of default is higher.\n\n","bcec7725":"# Calculate mean of total_rec_late_fee  \n# Remove outliers whose fees > $50\nloan_subset_df_late_fee = loan_subset_df.loc[(loan_subset_df['total_rec_late_fee'] < 50)]\nprint(loan_subset_df_late_fee.groupby(['loan_status'])['total_rec_late_fee'].mean())\n\nfig, axs = plt.subplots(ncols=2, figsize=(15, 6))\n\nax0 = sns.distplot(loan_subset_df_late_fee.loc[loan_subset_df_late_fee['loan_status'] == 'Fully Paid']['total_rec_late_fee'],\n             ax=axs[0],\n             color=\"blue\",\n             hist=False);\nax0.set(xlabel='Received Late Fees', ylabel='%', title='Late free distribution for Fully paid burrowers')\n\nax1 = sns.distplot(loan_subset_df_late_fee.loc[loan_subset_df_late_fee['loan_status'] == 'Charged Off']['total_rec_late_fee'],\n             ax=axs[1], \n             color='red',\n             hist=False);\n\nax1.set(xlabel='Received Late Fees', ylabel='%', title='Late free distribution for Charged off burrowers')\n\n\n# Calclate number of defaulters with fees > $0\nprint(loan_subset_df.loc[(loan_subset_df['total_rec_late_fee'] > 0) & \n                   (loan_subset_df_late_fee['loan_status'] == 'Charged Off')].shape)\n\n# Calclate number of defaulters with fees >= $15\nprint(loan_subset_df.loc[(loan_subset_df['total_rec_late_fee'] >= 15) & \n                   (loan_subset_df_late_fee['loan_status'] == 'Charged Off')].shape)\n\n# Calclate number of non-defaulters with fees > $0\nprint(loan_subset_df.loc[(loan_subset_df['total_rec_late_fee'] > 0) & \n                   (loan_subset_df_late_fee['loan_status'] == 'Fully Paid')].shape)\n\n# Calclate number of non-defaulters with fees >= $15\nprint(loan_subset_df.loc[(loan_subset_df['total_rec_late_fee'] >= 15) & \n                   (loan_subset_df_late_fee['loan_status'] == 'Fully Paid')].shape)\n\n\n# Observation :  The mean total late fee recieved for fully paid burrowers is sigficantly less that those\n#                who were charged off. \n#\n#                1. In the below graph, atleast 23% of defaulters have paid $15 or more while only 6%\n#                   non-defaulters have paid $15.\n#                2. Mean for Charged Off is $3.15 while mean for Fully Paid is $0.68.\n#                3. There are 13% Defaulters with late fees > $0 in comparison to 3% such non-defaulters.\n#                4. There are 9% defaulters with late fess > $15 in comarison to 2.5% such non-defaulters.\n\n# Inference   : Those who have high late fee sum (>= $15) will have high rate of default.\n","fa8e37c0":"# Scatter plot between loan_amnt and total_pymnt\nax = sns.scatterplot(x=\"loan_amnt\", \n                y=\"total_pymnt\",\n                data=loan_subset_df,\n                hue='loan_status')\n\nax.set(xlabel='Loan Amount', ylabel='Total Payment', title='Loan Amount v\/s Total Payment')\n\n# Draw dist plot for loan_amnt and compare the boxplot for Fully paid and Charged off\n# Remove outlier and scale to log\nshowNumericalPlots(data=loan_subset_df,\n                   colname='loan_amnt',\n                   left_quantile=0.1,\n                   right_quantile=0.9,\n                   scale='log',\n                   title='Loan Amount')\n\n# Draw dist plot for total_pymnt and compare the boxplot for Fully paid and Charged off\n# Remove outlier and scale to log\nshowNumericalPlots(data=loan_subset_df,\n                   colname='total_pymnt',\n                   left_quantile=0.1,\n                   right_quantile=0.9,\n                   scale='log',\n                   title='Total Payment')\n\n# Calculate median\nprint(loan_subset_df.groupby(['loan_status'])['loan_amnt'].median())\nprint(loan_subset_df.groupby(['loan_status'])['total_pymnt'].median())\n\n\n# Observation :  The mean total payment recieved for charged paid burrowers is sigficantly less that those\n#                whofully paid. \n#\n#                1. In the below scatter plot, despite having same loan amount, the total payment for\n#                   the defaulters is lesser than the non-defaulters.\n#                2. The median for loan_amnt is almost same for Charged Off ($9,600) and Fully Paid ($10,000) but \n#                   total_pymnt median for Charged Off is only $4842 compared to $10687 for Fully Paid\n\n# Inference   : Those who have less total_pymnt for the same loan_amnt will have high possibility of being\n#               Charged Off.\n","9275635d":"# Scatter plot between loan_amnt and total_rec_prncp\nax = sns.scatterplot(y=\"total_rec_prncp\", \n                     x=\"loan_amnt\",\n                     data=loan_subset_df,\n                     hue='loan_status')\n\nax.set(xlabel='Loan Amount', ylabel='Total Principle Recieved', title='Loan Amount v\/s Total Principle Recieved')\n\n# Draw dist plot for total_rec_prncp and compare the boxplot for Fully paid and Charged off\n# Remove outlier and scale to log\nshowNumericalPlots(data=loan_subset_df,\n                   colname='total_rec_prncp',\n                   left_quantile=0.1,\n                   right_quantile=0.9,\n                   scale='linear',\n                   title='Principle Recieved')\n\n# Calculate median\nprint(loan_subset_df.groupby(['loan_status'])['total_rec_prncp'].median())\n\n# median [charged off] = $2,730\n# median [fully paid] = $9,200\n\n# Observation :  The median total principle recieved for charged paid burrowers is sigficantly less that those\n#                whofully paid. \n#\n#                1. In the below scatter plot, despite having same loan amount, the total principle recieved\n#                   from the defaulters is lesser than the non-defaulters.\n#                2. The median for loan_amnt is almost same for Charged Off ($9,600) and Fully Paid ($10,000) but \n#                   total_rec_prncp median for Charged Off is only $2730 compared to $9200 for Fully Paid\n\n# Inference :  Those who have less total_rec_prncp for the same loan_amnt will have high possibility of being\n#              Charged Off.","469b7199":"# Create a derived column last_pymnt_d_year\nloan_subset_df.loc[:, 'last_pymnt_d'] = loan_subset_df['last_pymnt_d'].replace(np.nan, '', regex=True)\nloan_subset_df.loc[:, 'last_pymnt_d_year'] = loan_subset_df['last_pymnt_d'].apply(lambda x : (x[-2:]) if len(x) > 0 else np.nan )\nshowCategoricalPlotsStacked(loan_subset_df, 'last_pymnt_d_year', 10, 'Last payment year')\n\n# Observation : The Charged off % is higher as the last payment date are earlier.\n# Inference :   If the last payment date of a loan is older, then there is a high probability\n#               that it will be charged off.\n","dfd5bbed":"showCategoricalPlots(loan_subset_df, 'verification_status', 5, 'Verification Status')\n\n# Observation : The Charged off % is higher if the customer is Verified by LC.\n# Inference :   If the customer is Verified, the probability of him defaulting is high.\n","e18e60b0":"plot_df = showCategoricalPlotsStacked(loan_subset_df, 'purpose', 6, 'Purpose of the loan')\n\n# Observation : The Charged off % is dependent on the purpose of the loan. There is a significantly high \n#               default rate for small_business\n# Inference :   If the burrower is taking the loan for Small Business, then changes of default are high \n#               than any other purpose.\n","99e1d8bd":"# Removing NE state (outlier) due to it's unusual high % of Charged Off.\nloan_subset_df = loan_subset_df.loc[loan_subset_df['addr_state'] != 'NE']\nshowCategoricalPlotsStacked(loan_subset_df, 'addr_state', 11, 'Address State')\n\n# Observation : The Charged off % is also dependent on the state of the burrower. There is a high \n#               default rate for NV state.\n# Inference :   If the burrower is taking the loan belongs to NV the he has 22% change of defaulting.\n","cd63fe5c":"df_grp = loan.groupby('loan_status')['loan_status'].count()\nprint(df_grp)\n\n# Charged off (default) % = 14.60\n\ndf_grp.plot.bar()","9993bd31":"# Analyse grade and sub_grade vs loan_status\n\ndf_grp = loan_subset_df.groupby(['grade', 'loan_status'])['loan_status'].count().unstack().reset_index('grade')\ndf_grp['Charged Off%'] = df_grp['Charged Off'] \/ (df_grp['Charged Off'] + df_grp['Fully Paid']) * 100\ndf_grp['Fully Paid%'] = df_grp['Fully Paid'] \/ (df_grp['Charged Off'] + df_grp['Fully Paid']) * 100\nax1 = df_grp.loc[:, ['grade', 'Fully Paid%', 'Charged Off%']].set_index('grade').plot(kind='bar', stacked=True, figsize=(8, 4))\nax1.set(xlabel='Grade', ylabel='Loan Status %', title='Influence of Grade on Loan Status')\nax1.patch.set_facecolor('white')\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\ndf_grp = loan_subset_df.groupby(['sub_grade', 'loan_status'])['loan_status'].count().unstack().reset_index('sub_grade')\ndf_grp['Charged Off%'] = df_grp['Charged Off'] \/ (df_grp['Charged Off'] + df_grp['Fully Paid']) * 100\ndf_grp['Fully Paid%'] = df_grp['Fully Paid'] \/ (df_grp['Charged Off'] + df_grp['Fully Paid']) * 100\nax2 = df_grp.loc[:, ['sub_grade', 'Fully Paid%', 'Charged Off%']].set_index('sub_grade').plot(kind='bar', stacked=True, figsize=(12, 4))\nax2.set(xlabel='Sub-Grade', ylabel='Loan Status %', title='Influence of Sub-Grade on Loan Status')\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\n# Observation : The Charged off % is also dependent on the grade and sub-grade of the burrower. There is a high \n#               default rate if grade or sub_grade are lower.\n#               Grade: Here A is better than B better than C and so on\n#               Sub-grade: Here A1 is better than A2 better than A3 and so on.\n\n# Inference :   If the burrower is taking the loan belongs to the lower grade then he has high change of defaulting.\n","3bffd6e2":"showCategoricalPlots(loan_subset_df, 'term', 6, 'Loan term')\n\n# Observation : The Charged off % is also dependent on the term. There is a high \n#               default rate if term is 60.\n\n# Inference :   If the burrower is taking the loan for 60 months, there is 25% chance of defaulting.\n","bcbf6cf1":"showCategoricalPlots(loan_subset_df, 'emp_length', 8, 'Loan term')\n\n# Observation : The Charged off % is increasing as the emp_length is increading, with a few exceptions\n\n# Inference :   If the burrower is taking the loan whose emp_length is higher, there may be high chance of defaulting.","e51a4af9":"# Created 4 installment bins with 25% data in each\n# Low        => [0, 165]\n# Medium     => [166, 275]\n# High       => [276, 420]\n# Very High  => > 420\ndef createInstallmentBins(n):\n    if n <= 165:\n        return 'Low'\n    elif n > 165 and n <=275:\n        return 'Medium'\n    elif n > 275 and n <=420:\n        return 'High'\n    else:\n        return 'Very high'\n    \nloan_subset_df['installment_bin'] = loan_subset_df['installment'].apply(lambda x: createInstallmentBins(x))\nshowCategoricalPlots(loan_subset_df, 'installment_bin', 8, 'Installments')\n\n# Inference :   If the burrower is taking the loan whose installment is higher ( > $420), \n#               there may be high chance of defaulting.","3a873668":"# Created 4 loan amount bins with 25% data in each\n# Low        => [0, 5500)\n# Medium     => [5500, 9600)\n# High       => [9600, 15000)\n# Very High  => > 15000\ndef createLoanAmountBins(n):\n    if n < 5500:\n        return 'Low'\n    elif n >=5500 and n < 9600:\n        return 'Medium'\n    elif n >= 9600 and n < 15000:\n        return 'High'\n    else:\n        return 'Very high'\n    \nloan_subset_df['loan_amnt_bin'] = loan_subset_df['loan_amnt'].apply(lambda x: createLoanAmountBins(x))\nshowCategoricalPlots(loan_subset_df, 'loan_amnt_bin', 8, 'Loan amount')\n\n# Inference :   If the burrower is taking the loan whose loan amount is higher ( > $15000), \n#               there may be high chance of defaulting.","18215888":"# Created 4 annual income bins with 25% data in each\n# Low        => [0, 41000)\n# Medium     => [41000, 60000)\n# High       => [60000, 83500)\n# Very High  => > 83500\ndef createAnnualIncomeBin(n):\n    if n < 41000:\n        return 'Low'\n    elif n >= 41000 and n < 60000:\n        return 'Medium'\n    elif n >= 60000 and n < 83500:\n        return 'High'\n    else:\n        return 'Very high'\n    \nloan_subset_df['annual_inc_bin'] = loan_subset_df['annual_inc'].apply(lambda x: createAnnualIncomeBin(x))\nshowCategoricalPlots(loan_subset_df, 'annual_inc_bin', 8, 'Annual income')\n\n# Inference :   If the burrower is taking the loan whose annual income is lower ( < $41000), \n#               there may be high chance of defaulting.","1422feec":"# Debt to income ratio\n# Created 4 dti bins with 25% data in each\n# Low        => [0, 8)\n# Medium     => [8, 13.2)\n# High       => [13.2, 18.5)\n# Very High  => > 18.5\ndef createDTIBin(n):\n    if n < 8:\n        return 'Low'\n    elif n >= 8 and n < 13.2:\n        return 'Medium'\n    elif n >= 13.2 and n < 18.5:\n        return 'High'\n    else:\n        return 'Very high'\n \nloan_subset_df['dti_bin'] = loan_subset_df['dti'].apply(lambda x: createDTIBin(x))\nshowCategoricalPlots(loan_subset_df, 'dti_bin', 8, 'DTI')\n\n# Inference :   If the burrower is taking the loan whose dti is higher ( >= 18.5), \n#               there may be high chance of defaulting.","3b13e39c":"## 3.1 loan_status analysis\n**Desc : Current status of the loan** ","7ae701dc":"### 3.2.4 Segmenting loan_status by `installment`","c4d04f4b":"# Data Cleaning","44c899d3":"### 2.1.3 total_rec_late_fee\n**Desc : Late fees received to date**","45cb40cb":"### 3.2.3 Segmenting loan_status by `emp_length`","ae9885ce":"### 2.1 Numerical data v\/s Loan status","8f148969":"### 1. Remove columns with missing values","dc1a08be":"### 2.2.4 addr_state\n**Desc : The state provided by the borrower in the loan application**","572e0fb7":"### 3.2.7 Segmenting loan_status by ` dti`","66cab046":"## 3.2 Segmented Univariate analysis","56f66a62":"# Lending Club Loan Analysis","b8292f96":"#### Objective:-  To find which burrower is more likely to default","fd4a4819":"### 2.1.2 annual_inc\n**Desc : The self-reported annual income provided by the borrower during registration.**","b4e3e21a":"## Analysis Result :\n\n- #### Based on the data analysis performed,`Recommendations` are:-\n     1. Stop \u2013  approving loans of lower grades `(G & F)`.\n     2. Start \u2013 Charging higher interest rates for loans with DTI `(>=18)`. \n     3. More Verification required \u2013 Before approving  loan whose loan amount is higher `(> $15000)`. \n     4. Reduce \u2013 number of approvals where purpose  is `Small Business`.\n     5. Stop \u2013 approving loans whose annual income is lower `(< $41,000)`.\n","e246f472":"### 2.2.1 last_paymnt_d\n**Desc : Last month payment was received**","b1e19ef5":"# Bivariate Analysis","4f434d83":"### 2.2 Categorical data v\/s Loan status","7aef86a1":"### 3.2.5 Segmenting loan_status by `loan amount`","51eb5e9c":"## 1. Numerical Data Correlation","57d3e87f":"### 2.2.3 purpose\n**Desc : A category provided by the borrower for the loan request.**","c8626a40":"### 3.2.1 Segmenting loan_status by `grade and sub_grade`","3b15a416":"### 2.1.4 loan_amnt v\/s total_pymnt\n**Desc : Comparison of Loan amount and the Total payment made till now**","bb66301a":"### Conclusion\nIn the above heat map we found out the correlation between various features. But any **strong** correlation between **Charged Off** and other features **could not be found out**. We need to dig deeper.","a3e4995f":"## 2. Finding the relation of features with defaulters using plots","bd2014dc":"### 3.2.6 Segmenting loan_status by `annual income`","360dfb33":"### 2. Convert non-numeric ordinal data to numeric","2a39ad83":"### 2.1.5 total_rec_prncp\n**Desc : Principle received to date**","364d55d7":"### 3.2.2 Segmenting loan_status by `term`","a6693679":"## Business Objectives\nThis company is the largest online loan marketplace, facilitating personal loans, business loans, and financing of medical procedures. Borrowers can easily access lower interest rate loans through a fast online interface. \n\n \n\nLike most other lending companies, lending loans to \u2018risky\u2019 applicants is the largest source of financial loss (called credit loss). The credit loss is the amount of money lost by the lender when the borrower refuses to pay or runs away with the money owed. In other words, borrowers who default cause the largest amount of loss to the lenders. In this case, the customers labelled as 'charged-off' are the 'defaulters'. \n\n \n\nIf one is able to identify these risky loan applicants, then such loans can be reduced thereby cutting down the amount of credit loss. Identification of such applicants using EDA is the aim of this case study.\n\n \n\nIn other words, the company wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default.  The company can utilise this knowledge for its portfolio and risk assessment. ","8a39cd3b":"### 2.1.1 int_rate\n**Desc : Interest Rate on the loan**","40146fc2":"### 2.2.2 verification_status\n**Desc : Indicates if income was verified by LC, not verified, or if the income source was verified**","1ce1205d":"# 3. Univariate Analysis"}}