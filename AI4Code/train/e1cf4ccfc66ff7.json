{"cell_type":{"46aaffd7":"code","266edc95":"code","e54eeec0":"code","d3d617ac":"code","27e2c836":"code","4dc165f2":"code","43a664cc":"code","2ac857d0":"code","5476403b":"code","6139d1e2":"code","488bd696":"code","221f02d4":"code","a54dd6c6":"code","dfd0feb1":"code","98f99ead":"code","00e88d44":"code","9639787d":"code","09e4a011":"code","52cb4450":"code","f7fb2e35":"code","ed2f4abd":"code","5664d8d1":"code","82c1232e":"code","2955e3f2":"code","f1ca8d0a":"code","02d6e21c":"code","2ecb98b2":"code","6f78e33e":"code","3c4e33b8":"markdown"},"source":{"46aaffd7":"import numpy as np\nimport pandas as pd\npd.options.display.max_columns = 200\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor, Pool, cv\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","266edc95":"df = pd.read_csv(\"\/kaggle\/input\/real-time-advertisers-auction\/Dataset.csv\")","e54eeec0":"df.head()","d3d617ac":"# Making label\n\ndef weird_division(n, d):\n    return n \/ d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),\n                                              x['measurable_impressions'])*1000 , axis=1)","27e2c836":"df.nunique()","4dc165f2":"# Let's drop columns that are used in CPM formula and useless ones\n\ndf.drop(['total_revenue', 'measurable_impressions', 'integration_type_id', 'revenue_share_percent'], \\\n        axis=1, inplace=True)","43a664cc":"df['date'] = pd.to_datetime(df.date)\ndf = df.sort_values('date')","2ac857d0":"df = df[df.CPM < df.CPM.quantile(.95)]\ndf = df[df.CPM >= 0]","5476403b":"df.CPM.hist();","6139d1e2":"corr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","488bd696":"# Make some features\n\ndf['weekday'] = df.date.apply(lambda x: x.weekday())","221f02d4":"dates = df.date.sort_values().unique()\ndate_df = pd.DataFrame({'date': dates, 'date_num': np.arange(len(dates)).astype(float)})","a54dd6c6":"df = df.merge(date_df, left_on='date', right_on='date', how='inner')","dfd0feb1":"df[['total_impressions', 'viewable_impressions']] = df[['total_impressions', 'viewable_impressions']].astype(float)","98f99ead":"# Making two datasets to compare how big 'order_id' and 'line_item_type_id' improve score (they may contain leaks)\n\ndata1 = pd.get_dummies(df[[col for col in df.columns if col not in ['order_id' , 'line_item_type_id']]])\ndata2 = pd.get_dummies(df)","00e88d44":"train = data1[data1.date <= pd.Timestamp(2019,6,21)]\ny_train = train.pop('CPM')\ntest = data1[data1.date > pd.Timestamp(2019,6,21)]\ny_test = test.pop('CPM')","9639787d":"del train['date']\ndel test['date']","09e4a011":"X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.3, random_state=42)","52cb4450":"cat_feat = np.where(X_train.dtypes != np.float)[0]\nparams = {\n    'iterations': 300,\n    #'logging_level': 'Silent',\n    'loss_function': 'RMSE',\n    'use_best_model': True,\n}\ntrain_pool = Pool(X_train, y_train, cat_features=cat_feat)\nvalidate_pool = Pool(X_val, y_val, cat_features=cat_feat)\n\nmodel = CatBoostRegressor(**params, cat_features=cat_feat)\nmodel.fit(train_pool, eval_set=validate_pool)","f7fb2e35":"model.get_feature_importance(data=None,\n                       #type=EFstrType.FeatureImportance,\n                       prettified=True,\n                       thread_count=-1,\n                       verbose=False).head(20)","ed2f4abd":"# Turning negative CPM values to zeros\n\ny_pred = pd.Series(model.predict(test)).apply(lambda x: 0 if x < 0 else x).values","5664d8d1":"print(f'MSE = {mean_squared_error(y_pred, y_test)}')","82c1232e":"# Checking second dataset","2955e3f2":"train = data2[data2.date <= pd.Timestamp(2019,6,21)]\ny_train = train.pop('CPM')\ntest = data2[data2.date > pd.Timestamp(2019,6,21)]\ny_test = test.pop('CPM')\n\ndel train['date']\ndel test['date']\n\nX_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.3, random_state=42)","f1ca8d0a":"cat_feat = np.where(X_train.dtypes != np.float)[0]\nparams = {\n    #'iterations': 300,\n    #'logging_level': 'Silent',\n    'loss_function': 'RMSE',\n    'use_best_model': True,\n}\ntrain_pool = Pool(X_train, y_train, cat_features=cat_feat)\nvalidate_pool = Pool(X_val, y_val, cat_features=cat_feat)\n\nmodel = CatBoostRegressor(**params, cat_features=cat_feat)\nmodel.fit(train_pool, eval_set=validate_pool)","02d6e21c":"model.get_feature_importance(data=None,\n                       #type=EFstrType.FeatureImportance,\n                       prettified=True,\n                       thread_count=-1,\n                       verbose=False).head(20)","2ecb98b2":"y_pred = pd.Series(model.predict(test)).apply(lambda x: 0 if x < 0 else x).values","6f78e33e":"print(f'MSE = {mean_squared_error(y_pred, y_test)}')","3c4e33b8":"#### We see, that in the second case considered features influence the model much better than others, so they can contain leak info\n\n#### But stil we have obtain acceptable MSE under 4850 in both methods"}}