{"cell_type":{"61729688":"code","5844eaf2":"code","0b79de4d":"code","5fb38f04":"code","d7e308df":"code","e3088f91":"code","6f096124":"code","01240dbb":"code","f9a52112":"code","747db0e4":"code","09082735":"code","139e5ce7":"code","bf4152d3":"code","5129a739":"code","b26fe1f1":"code","1868d28a":"code","a88e4813":"code","87a1250c":"code","c32c626a":"code","c0aa94dd":"code","ee82188b":"code","f86f936c":"code","104a8800":"code","1c1b0981":"code","e9047e7a":"code","22a1797c":"code","8253171e":"code","19a4a504":"code","822ff970":"markdown","9be62b7c":"markdown","eebcdd6d":"markdown","7951dfff":"markdown","bc7ddd4f":"markdown","ef9eecf6":"markdown","3bf6fcf3":"markdown","618c5d1d":"markdown","cb13f3b2":"markdown","d6a5d931":"markdown","86ff5d5e":"markdown"},"source":{"61729688":"# Setting package umum \nimport pandas as pd\nimport pandas_profiling as pp\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nfrom tqdm import tqdm_notebook as tqdm\n%matplotlib inline\n\nfrom matplotlib.pylab import rcParams\n# For every plotting cell use this\n# grid = gridspec.GridSpec(n_row,n_col)\n# ax = plt.subplot(grid[i])\n# fig, axes = plt.subplots()\nrcParams['figure.figsize'] = [10,5]\nplt.style.use('fivethirtyeight') \nsns.set_style('whitegrid')\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom tqdm import tqdm\n\npd.set_option('display.max_rows', 50)\npd.set_option('display.max_columns', 150)\npd.options.display.float_format = '{:.4f}'.format\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5844eaf2":"### Load dataset\ndf_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","0b79de4d":"### Overview dataset\ndf_train.head(11)","5fb38f04":"#Function to give quick general information about the dataset\ndef dataset_summary(df) :\n    # Make summary dataframe\n    summary_df = pd.DataFrame()\n\n    # Input the characteristic of the dataset\n    summary_df['Var'] = df.columns\n    summary_df['Dtypes'] = df.dtypes.values\n    summary_df['Total Missing'] = df.isnull().sum().values\n    summary_df['Missing%'] = summary_df['Total Missing'] \/ len(df) * 100\n    summary_df['Total Unique'] = df.nunique().values\n    summary_df['Unique%'] = summary_df['Total Unique'] \/ len(df) * 100\n\n    # Dataset dimension\n    print('Dataset dimension :',df.shape)\n\n    return summary_df","d7e308df":"### Summary of dataset\ndataset_summary(df_train)","e3088f91":"### Summary of dataset test\ndataset_summary(df_test)","6f096124":"### Proportion of target variables\ndf_train['Survived'].value_counts() \/ len(df_train)","01240dbb":"### Check distribution of age\nrcParams['figure.figsize'] = [10,5]\nplt.style.use('fivethirtyeight') \nsns.set_style('whitegrid')\n\n# Plot\nsns.distplot(df_train['Age']) ;","f9a52112":"### Impute missing value of age using median\ndf_train['Age'] = df_train['Age'].fillna(np.median(df_train['Age'].dropna()))\ndf_test['Age'] = df_test['Age'].fillna(np.median(df_train['Age'].dropna()))","747db0e4":"### Check proportion of embarked\ndf_train['Embarked'].value_counts() \/ len(df_train)","09082735":"### Impute missing value of embarked using modus\ndf_train['Embarked'] = df_train['Embarked'].fillna('S')","139e5ce7":"### Check distribution of fare\nrcParams['figure.figsize'] = [10,5]\nplt.style.use('fivethirtyeight') \nsns.set_style('whitegrid')\n\n# Plot\nsns.distplot(df_train['Fare']) ;","bf4152d3":"### Impute missing value of fare using Q1\ndf_test['Fare'] = df_test['Fare'].fillna(np.percentile(df_train['Fare'], 25))","5129a739":"### Feature engineering\ndef feature_engineering(df) :\n    # Creating a categorical variable for Ages\n    df['AgeCat'] = ''\n    df['AgeCat'].loc[(df['Age'] < 18)] = 'young'\n    df['AgeCat'].loc[(df['Age'] >= 18) & (df['Age'] < 56)] = 'mature'\n    df['AgeCat'].loc[(df['Age'] >= 56)] = 'senior'\n\n\n    # Creating a categorical variable for Family Sizes\n    df['FamilySize'] = ''\n    df['FamilySize'].loc[(df['SibSp'] <= 2)] = 'small'\n    df['FamilySize'].loc[(df['SibSp'] > 2) & (df['SibSp'] <= 5 )] = 'medium'\n    df['FamilySize'].loc[(df['SibSp'] > 5)] = 'large'\n\n\n    # Creating a categorical variable to tell if the passenger is alone\n    df['IsAlone'] = ''\n    df['IsAlone'].loc[((df['SibSp'] + df['Parch']) > 0)] = 'no'\n    df['IsAlone'].loc[((df['SibSp'] + df['Parch']) == 0)] = 'yes'\n\n\n    # Creating a categorical variable to tell if the passenger is a Young\/Mature\/Senior male or a Young\/Mature\/Senior female\n    df['SexCat'] = ''\n    df['SexCat'].loc[(df['Sex'] == 'male') & (df['Age'] <= 21)] = 'youngmale'\n    df['SexCat'].loc[(df['Sex'] == 'male') & (df['Age'] > 21) & (df['Age']) < 50] = 'maturemale'\n    df['SexCat'].loc[(df['Sex'] == 'male') & (df['Age'] > 50)] = 'maturemale'\n    df['SexCat'].loc[(df['Sex'] == 'female') & (df['Age'] <= 21)] = 'youngfemale'\n    df['SexCat'].loc[(df['Sex'] == 'female') & (df['Age'] > 21) & (df['Age']) < 50] = 'maturefemale'\n    df['SexCat'].loc[(df['Sex'] == 'female') & (df['Age'] > 50)] = 'maturefemale'\n    \n    return df\n\ndf_train = feature_engineering(df_train)\ndf_test = feature_engineering(df_test)","b26fe1f1":"### Drop unnecessary columns and get the list of col\ndef get_feature_names(df):\n\n    # Dropping unused columns from the feature set\n    df.drop(['PassengerId', 'Ticket', 'Name', 'Cabin'], axis=1, inplace=True)\n\n    # Splitting categorical and numerical column dataframes\n    categorical_df = df.select_dtypes(include=['object'])\n    numeric_df = df.select_dtypes(exclude=['object'])\n\n    # And then, storing the names of categorical and numerical columns.\n    categorical_columns = list(categorical_df.columns)\n    numeric_columns = list(numeric_df.columns)\n    \n    print(\"Categorical columns:\\n\", categorical_columns)\n    print(\"\\nNumeric columns:\\n\", numeric_columns)\n\n    return categorical_columns, numeric_columns\n\ncat_var, cont_var = get_feature_names(df_train)\n_, _ = get_feature_names(df_test)","1868d28a":"### Overview of dataset\ndf_train.head()","a88e4813":"### Use to close H2O\n# Type \"Y\"\nh2o.cluster().shutdown(prompt=True)","87a1250c":"### Initialize h2o\nimport h2o\nh2o.init()\nh2o.no_progress()","c32c626a":"### Class to do Bayesian Encoding\nclass mmotokiBetaEncoder(object):\n        \n    def __init__(self, group):\n        \n        self.group = group\n        self.stats = None\n        \n    # get counts from df\n    def fit(self, df, target_col):\n        self.prior_mean = np.mean(df[target_col])\n        stats = df[[target_col, self.group]].groupby(self.group)\n        stats = stats.agg(['sum', 'count'])[target_col]    \n        stats.rename(columns={'sum': 'n', 'count': 'N'}, inplace=True)\n        stats.reset_index(level=0, inplace=True)           \n        self.stats = stats\n        \n    # extract posterior statistics\n    def transform(self, df, stat_type, N_min=1):\n        \n        df_stats = pd.merge(df[[self.group]], self.stats, how='left')\n        n = df_stats['n'].copy()\n        N = df_stats['N'].copy()\n        \n        # fill in missing\n        nan_indexs = np.isnan(n)\n        n[nan_indexs] = self.prior_mean\n        N[nan_indexs] = 1.0\n        \n        # prior parameters\n        N_prior = np.maximum(N_min-N, 0)\n        alpha_prior = self.prior_mean*N_prior\n        beta_prior = (1-self.prior_mean)*N_prior\n        \n        # posterior parameters\n        alpha = alpha_prior + n\n        beta =  beta_prior + N-n\n        \n        # calculate statistics\n        if stat_type=='mean':\n            num = alpha\n            dem = alpha+beta\n                    \n        elif stat_type=='mode':\n            num = alpha-1\n            dem = alpha+beta-2\n            \n        elif stat_type=='median':\n            num = alpha-1\/3\n            dem = alpha+beta-2\/3\n        \n        elif stat_type=='var':\n            num = alpha*beta\n            dem = (alpha+beta)**2*(alpha+beta+1)\n                    \n        elif stat_type=='skewness':\n            num = 2*(beta-alpha)*np.sqrt(alpha+beta+1)\n            dem = (alpha+beta+2)*np.sqrt(alpha*beta)\n\n        elif stat_type=='kurtosis':\n            num = 6*(alpha-beta)**2*(alpha+beta+1) - alpha*beta*(alpha+beta+2)\n            dem = alpha*beta*(alpha+beta+2)*(alpha+beta+3)\n\n        else:\n            num = self.prior_mean\n            dem = np.ones_like(N_prior)\n            \n        # replace missing\n        value = num\/dem\n        value[np.isnan(value)] = np.nanmedian(value)\n        return value","c0aa94dd":"### Make all H2O baseline model\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.estimators import H2OXGBoostEstimator\nimport time\n\ndef h2o_compare_models(train_data, val_data, X, Y, random_state, cv=5) :\n    '''\n    Function to compare H2O model\n    Note that if you want to change the metrics you have to do it manually change the code\n    In this notebook I use accuracy\n    \n    PARAMS\n    train_data : H2OFrame, that contains the training dataset\n    val_data : H2OFrame, that contains the validation dataset\n    X : list, that contains the predictors used\n    Y : string, the target variable\n    random_state : int, for model seeding\n    cv : int, for CV metrics\n    \n    OUTPUT\n    result : pd.DataFrame, that contains the score for each model\n    \n    '''\n    \n    # Preprocess dataframe to H2O Dataset\n    h2o_train = h2o.H2OFrame(train_data[X+[Y]])\n    h2o_val = h2o.H2OFrame(val_data[X+[Y]])\n    \n    h2o_train[Y] = h2o_train[Y].asfactor()\n    h2o_val[Y] = h2o_val[Y].asfactor()\n    \n    # Initialize all model (Ganti family\/distributionnya)\n    glm = H2OGeneralizedLinearEstimator(seed=random_state, family='binomial', nfolds=cv, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    gbm = H2OGradientBoostingEstimator(seed=random_state, distribution='bernoulli', nfolds=cv, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    xgb = H2OXGBoostEstimator(seed=random_state, distribution='bernoulli', nfolds=cv, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    lgbm = H2OXGBoostEstimator(seed=random_state, distribution='bernoulli', tree_method=\"hist\", grow_policy=\"lossguide\",\n                              nfolds=cv, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    rf = H2ORandomForestEstimator(seed=random_state, distribution='bernoulli', nfolds=cv, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    ext = H2ORandomForestEstimator(seed=random_state, distribution='bernoulli', histogram_type=\"Random\",\n                                  nfolds=cv, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    \n    # Train model\n    glm.train(x=X, y=Y, training_frame=h2o_train)\n    gbm.train(x=X, y=Y, training_frame=h2o_train)\n    xgb.train(x=X, y=Y, training_frame=h2o_train)\n    lgbm.train(x=X, y=Y, training_frame=h2o_train)\n    rf.train(x=X, y=Y, training_frame=h2o_train)\n    ext.train(x=X, y=Y, training_frame=h2o_train)\n    \n    # Calculate train metrics (Bisa diganti)\n    from sklearn.metrics import accuracy_score\n    train_glm = accuracy_score(h2o_train[Y].as_data_frame(), glm.predict(h2o_train)['predict'].as_data_frame())\n    train_gbm = accuracy_score(h2o_train[Y].as_data_frame(), gbm.predict(h2o_train)['predict'].as_data_frame())\n    train_xgb = accuracy_score(h2o_train[Y].as_data_frame(), xgb.predict(h2o_train)['predict'].as_data_frame())\n    train_lgbm = accuracy_score(h2o_train[Y].as_data_frame(), lgbm.predict(h2o_train)['predict'].as_data_frame())\n    train_rf = accuracy_score(h2o_train[Y].as_data_frame(), rf.predict(h2o_train)['predict'].as_data_frame())\n    train_ext = accuracy_score(h2o_train[Y].as_data_frame(), ext.predict(h2o_train)['predict'].as_data_frame())\n\n    # Calculate CV metrics for all model (Bisa diganti)\n    met_glm = accuracy_score(h2o_train[Y].as_data_frame(), glm.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_gbm = accuracy_score(h2o_train[Y].as_data_frame(), gbm.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_xgb = accuracy_score(h2o_train[Y].as_data_frame(), xgb.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_lgbm = accuracy_score(h2o_train[Y].as_data_frame(), lgbm.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_rf = accuracy_score(h2o_train[Y].as_data_frame(), rf.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_ext = accuracy_score(h2o_train[Y].as_data_frame(), ext.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    \n    # Calculate holdout metrics\n    from sklearn.metrics import accuracy_score\n    hold_glm = accuracy_score(h2o_val[Y].as_data_frame(), glm.predict(h2o_val)['predict'].as_data_frame())\n    hold_gbm = accuracy_score(h2o_val[Y].as_data_frame(), gbm.predict(h2o_val)['predict'].as_data_frame())\n    hold_xgb = accuracy_score(h2o_val[Y].as_data_frame(), xgb.predict(h2o_val)['predict'].as_data_frame())\n    hold_lgbm = accuracy_score(h2o_val[Y].as_data_frame(), lgbm.predict(h2o_val)['predict'].as_data_frame())\n    hold_rf = accuracy_score(h2o_val[Y].as_data_frame(), rf.predict(h2o_val)['predict'].as_data_frame())\n    hold_ext = accuracy_score(h2o_val[Y].as_data_frame(), ext.predict(h2o_val)['predict'].as_data_frame())\n    \n    # Make result dataframe\n    result = pd.DataFrame({'Model':['GLM','GBM','XGB','LGBM','RF','ExtraTree'],\n                          'Train Metrics':[train_glm,train_gbm,train_xgb,train_lgbm,train_rf,train_ext],\n                          'CV Metrics':[met_glm,met_gbm,met_xgb,met_lgbm,met_rf,met_ext],\n                          'Holdout Metrics':[hold_glm,hold_gbm,hold_xgb,hold_lgbm,hold_rf,hold_ext]})\n    \n    return result.sort_values('CV Metrics') ","ee82188b":"# Define dict to store encoder\nfrom category_encoders import JamesSteinEncoder, BackwardDifferenceEncoder, BaseNEncoder, BinaryEncoder\nfrom category_encoders import CatBoostEncoder, CountEncoder, GLMMEncoder, HashingEncoder, HelmertEncoder\nfrom category_encoders import LeaveOneOutEncoder, MEstimateEncoder, OneHotEncoder, OrdinalEncoder, SumEncoder\nfrom category_encoders import PolynomialEncoder, TargetEncoder, WOEEncoder\n\ndict_encoder = {'js':JamesSteinEncoder,\n                'backd':BackwardDifferenceEncoder,\n                'basen':BaseNEncoder,\n                'bin':BinaryEncoder,\n                'cat':CatBoostEncoder,\n                'count':CountEncoder,\n                'glm':GLMMEncoder,\n                'hash':HashingEncoder,\n                'helmert':HelmertEncoder,\n                'leaveone':LeaveOneOutEncoder,\n                'mest':MEstimateEncoder,\n                'ohe':OneHotEncoder,\n                'ord':OrdinalEncoder,\n                'sum':SumEncoder,\n                'poly':PolynomialEncoder,\n                'target':TargetEncoder,\n                'woe':WOEEncoder,\n                \n                # Additional\n                'bayes':mmotokiBetaEncoder}","f86f936c":"### Make function to benchmark encoder in category encoder package\ndef ce_benchmark_wrapper(dataset, repetition, list_enc, cat_var, Y) :\n    '''\n    Function to benchmark encoder using repetitive stratified split\n    \n    PARAMS\n    dataset : pd.DataFrame, that contains the full dataset\n    repetition : int, how many repetitive split should be used to benchmark\n    list_enc : list, that contains the key names of encoder to benchmark\n    cat_var : list, that contains the categorical variable to encode\n    Y : string, the target variable\n    \n    RETURN\n    final_result : pd.DataFrame, that contains the avg and std metric score for each encoder\n    \n    '''\n    \n    import random\n    global dict_encoder\n    import gc\n    \n    metric = []\n    metric_std = []\n    start = time.time()\n    random_state = [random.choice(range(999999999)) for i in range(repetition)]\n    \n    print('There are',len(list_enc),'encoder for benchmark')\n    print('Using',repetition,'repetition')\n    \n    for i_enc, enc_name in enumerate(list_enc) :\n        \n        print('')\n        print('#'*33)\n        print(i_enc+1,':',dict_encoder[enc_name].__name__)\n        print('')\n        enc_metric = []\n        \n        for i in range(repetition) :\n            \n            # Split dataframe\n            from sklearn.model_selection import train_test_split\n            train_data, val_data = train_test_split(dataset, stratify=dataset[Y], test_size = 0.2, random_state=random_state[i])\n            \n            train_data = train_data.reset_index(drop=True)\n            val_data = val_data.reset_index(drop=True)\n            \n            # Encoding\n            if enc_name != 'bayes' :\n                enc = dict_encoder[enc_name](cols=cat_var)\n                list_col = list(train_data.drop(columns=[Y]).columns)\n\n                enc_train_data = enc.fit_transform(train_data[list_col], train_data[Y])\n                enc_train_data[Y] = train_data[Y]\n\n                enc_val_data = enc.transform(val_data[list_col])\n                enc_val_data[Y] = val_data[Y]\n                \n            else :\n                enc_train_data = train_data.copy().reset_index(drop=True)\n                enc_val_data = val_data.copy().reset_index(drop=True)\n                N_min = 11\n\n                for var in cat_var :\n\n                    # Fit\n                    enc = dict_encoder[enc_name](var)\n                    enc.fit(enc_train_data, Y)\n\n                    # Transform\n                    enc_train_data[var]  = enc.transform(enc_train_data,  'mean', N_min)\n                    enc_val_data[var]  = enc.transform(enc_val_data,  'mean', N_min)\n                \n            \n            # Make model\n            list_col = list(enc_train_data.drop(columns=[Y]).columns)\n            result = h2o_compare_models(enc_train_data, enc_val_data, list_col, Y, random_state=random_state[i])\n            \n            # Save metric score\n            enc_metric.append(np.mean(result['Holdout Metrics']))\n            \n            print('Repetition',i+1,'completed')\n            \n        # Save encoder metric score\n        metric.append(np.mean(enc_metric))\n        metric_std.append(np.std(enc_metric))\n        print('Score :',np.mean(enc_metric),'+-',np.std(enc_metric))\n                      \n        end = time.time()\n        print('\\nTime Used :',(end-start)\/60)\n        \n        g = gc.collect()\n        \n    # Make final result dataframe\n    final_result = pd.DataFrame({'Encoder':list_enc, 'Score':metric, 'Std':metric_std})\n    \n    return final_result.sort_values('Score')","104a8800":"### Try benchmark encoder\nlist_enc = list(dict_encoder.keys())\nlist_enc.remove('ohe')\nresult = ce_benchmark_wrapper(df_train, 5, list_enc, cat_var, 'Survived')","1c1b0981":"### See the result\nresult","e9047e7a":"### Encoding \nY = 'Survived'\nenc_name = 'basen'\n\nenc = dict_encoder[enc_name](cols=cat_var)\nlist_col = list(df_train.drop(columns=[Y]).columns)\n\nenc_train_data = enc.fit_transform(df_train[list_col], df_train[Y])\nenc_train_data[Y] = df_train[Y]\n\nenc_test_data = enc.transform(df_test[list_col])","22a1797c":"### Build the model\nX = list(enc_train_data.drop(columns=[Y]).columns)\nrandom_state = 11\ncv = 5\n\n# Make H2OFrame\nh2o_train = h2o.H2OFrame(enc_train_data[X+[Y]])\nh2o_test = h2o.H2OFrame(enc_test_data[X])\n\nh2o_train[Y] = h2o_train[Y].asfactor()\n\n# Build LGBM\nlgbm = H2OXGBoostEstimator(seed=random_state, distribution='bernoulli', tree_method=\"hist\", grow_policy=\"lossguide\",\n                      nfolds=cv, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n\n# Fit LGBM\nlgbm.train(x=X, y=Y, training_frame=h2o_train)","8253171e":"### Make prediction \npred = lgbm.predict(h2o_test)['predict'].as_data_frame()","19a4a504":"### Make submission\nsub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsub['Survived'] = pred\n\nsub.to_csv('ce_benchmark_sub.csv', index=False)","822ff970":"'S' is the most frequent value on Embarked, so I will use it to impute the missing value","9be62b7c":"Because the Age distribution is slightly skewed I will use median to impute missing value","eebcdd6d":"# Preprocessing\nFor quick feature engineering I use the code present on this notebook https:\/\/www.kaggle.com\/pedrodematos\/titanic-eda-pipelines-auto-model-selection. The notebook itself explain the data pretty extensively using many cool package that you guys should try out","7951dfff":"There are 1 more encoder that are not available in category_encoder package. It called Bayesian Encoder and to do that I use the code that I stumble in this notebook https:\/\/www.kaggle.com\/mmotoki\/avito-target-encoding","bc7ddd4f":"# Benchmark\nI will use H2O to make the predictive model. For you who doesn't know this package, its basically the same as sklearn but I like it more because it can set the categorical variable as factor like in R. I make two function called **h2o_compare_models** to build ML model and calculate the preferred metrics, and **ce_benchmark_wrapper** to benchmark categorical encoder\n\nIn total there are 18 encoder that will be used for benchmark. The function run in approx 1 hour","ef9eecf6":"# Encoder benchmark on Titanic\nHello and welcome to this humble notebook. This notebook is a small playground for me to see the capability of **category_encoders** package for quick way to encode categorical variable. Before I stumble into this notebook the method I frequently used to encode is either **One Hot Encoding** or **Target Encoding**. Turns out there a more way to encode and I am gonna benchmark it using Titanic dataset since it is a small dataset so I can benchmark efficiently.\n\nNote that I will not explain the theory behind each encoder method, to do that you can check this article and notebook that I read :\n- Stop One Hot Encoding You Categorical Variable (https:\/\/towardsdatascience.com\/stop-one-hot-encoding-your-categorical-variables-bbb0fba89809)\n- 11 Categorical Encoder and Benchmark (https:\/\/www.kaggle.com\/subinium\/11-categorical-encoders-and-benchmark)","3bf6fcf3":"# Submission","618c5d1d":"Here we can see that the BaseNEncoder have the best validation accuracy among other encoder. Its pretty simple yet sometimes all we need is the simple method. So I will use it with LGBM to make submission","cb13f3b2":"Based on the overview of the dataset we know that :\n- There exist some missing value in train and test dataset. Since the goal of this notebook is just to benchmark categorical encoder I will just do some quick EDA to impute the missing value\n- Based on the proportion of the target variable it safe to say that this is not a imbalance classification task so no need to sampled the dataset","d6a5d931":"The distribution of Fare is pretty skewed, so I will use the 25th percentile to impute missing value. Note that this is just my preference, to impute the missing value more accurately we need to do more extensive EDA","86ff5d5e":"## Feel free to ask below and upvote if this notebook help you :)"}}