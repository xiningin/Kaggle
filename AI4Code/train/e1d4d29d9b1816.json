{"cell_type":{"5270343e":"code","8027de03":"code","e2e9978c":"code","59b7998f":"code","0f071e01":"code","463a1317":"code","0bb8a6b7":"code","23e7d761":"code","0345913a":"code","a7479e4e":"code","9bbc65bf":"code","48b997df":"code","045a0b16":"code","1e63044c":"code","776fe26c":"code","457888d0":"code","f6e89cd3":"code","9a649427":"code","f96ee133":"code","6d616ef1":"code","932d95fc":"code","425acabe":"code","b6fe8786":"code","3f7cdf77":"code","17ac9107":"code","2a1e258b":"code","356f2567":"code","c4c25fb6":"code","610d531d":"code","c329addf":"code","ebba7c03":"code","31cc21e1":"code","1b1e5e5a":"code","2fdefa21":"code","8dc0e86b":"code","aaf10514":"code","e45de71c":"code","90254bfc":"code","1c9188ca":"code","c74f22a4":"code","9e1295c3":"code","149fca2d":"code","3dbc5aef":"code","1724e1b6":"code","3b41abef":"code","8a0133a6":"code","40c83866":"code","716c909a":"code","c81a8c2d":"code","6b734d1a":"code","396fae8b":"code","872bdcf2":"code","3ccae097":"code","633d2000":"code","c679042b":"code","9a1ec37e":"code","ac36fceb":"markdown","8c78a9d5":"markdown","fac227bc":"markdown","6c4f57d3":"markdown","6d7aacc7":"markdown","40ee999e":"markdown","bdb187c1":"markdown","ec0250c5":"markdown","a37d3519":"markdown","f43ff1e4":"markdown","6d4447bd":"markdown","ec14e423":"markdown","51f14ea3":"markdown","4917ef35":"markdown","a97d3f68":"markdown","02292a31":"markdown","792cbea1":"markdown","a26ac35e":"markdown","5dec4319":"markdown","3e9fd735":"markdown","e0726d20":"markdown","79c62220":"markdown","5cf27993":"markdown","ef439839":"markdown","2742173c":"markdown","aaf68df6":"markdown","e917a2ec":"markdown","bca20826":"markdown","6ddf201d":"markdown","7f55806f":"markdown","86517741":"markdown","f5cc8249":"markdown","62ba986a":"markdown","7c033f7f":"markdown","6921d842":"markdown","f5522965":"markdown","2badb472":"markdown","9207ac66":"markdown","5e9d7e32":"markdown","26c044f7":"markdown"},"source":{"5270343e":"#imports\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","8027de03":"df= pd.read_csv('C:\/Users\/uknow\/Desktop\/bank_final2.csv')\n\ndf.head()","e2e9978c":"df.dtypes","59b7998f":"df.rename(columns = {\"['y']_yes\":'y'}, inplace = True) ","0f071e01":"X= pd.read_csv('C:\/Users\/uknow\/Desktop\/bank_final.csv')\n","463a1317":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, df.y, test_size=0.2, random_state=2019)","0bb8a6b7":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","23e7d761":"from sklearn.model_selection import KFold\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","0345913a":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","a7479e4e":"from sklearn.linear_model import Perceptron\nppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)\nppn.fit(X_train, y_train)","9bbc65bf":"#ppnprep=y_pred are the class labels that we predicted\nppnpred = ppn.predict(X_test)","48b997df":"print(ppn.score(X_train, y_train), ppn.score(X_test, y_test))","045a0b16":"# Calculate the classification accuracy of the perceptron\n\n# Here y_test are the true class labels \n\nfrom sklearn import metrics\n\nfrom sklearn.metrics import accuracy_score\n\nprint('Accuracy: %.2f' % accuracy_score(y_test, ppnpred))","1e63044c":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_test, ppnpred))","776fe26c":"from sklearn.model_selection import cross_val_score\n\nPPNCV = (cross_val_score(ppn, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())\nPPNCV","457888d0":"from sklearn.metrics import recall_score\n\nprint(round(metrics.recall_score(y_test, ppnpred),2))\n","f6e89cd3":"from sklearn.metrics import precision_score\n\nprint(round(metrics.precision_score(y_test, ppnpred),2))","9a649427":"from sklearn.metrics import classification_report\n\nprint(' Performance Metrics Reports\\n',classification_report(y_test, ppnpred))","f96ee133":"fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, ppnpred)\n\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nplt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('ROC curve for Perceptron model ',fontsize=10)\nplt.ylabel('True Positive Rate',fontsize=20)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 16})\n\nplt.show()","6d616ef1":"def sigmoid(z):\n    return 1.0 \/ (1.0 + np.exp(-z))\n\nz = np.arange(-7, 7, 0.1)\nplt.plot(z, sigmoid(z))\nplt.axvline(0.0, color='k')\nplt.axhspan(0.0, 1.0, facecolor='1.0', alpha=1.0, ls='dotted')\nplt.axhline(y=0.5, ls='dotted', color='k')\nplt.yticks([0.0, 0.5, 1.0])\nplt.ylim(-0.1, 1.1)\nplt.xlabel('z= the net input ')\nplt.title('$sigmoid (z)$')\nplt.ylabel(\"y=responses\")\nplt.show()","932d95fc":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.get_params()","425acabe":"logreg.fit(X_train, y_train)","b6fe8786":"# logistic regression is a linear model, so you have coefficients and intercepts:\nlogreg.coef_","3f7cdf77":"logreg.intercept_","17ac9107":"coeffs = pd.DataFrame({\n    'features X': X_train.columns,\n    'weights w'  : logreg.coef_[0]\n})\n\ncoeffs","2a1e258b":"\nY = X_train.dot(logreg.coef_.T) + logreg.intercept_\n# and this gives us our predictions\nsigmoid(Y)","356f2567":"# you can then use the predict method to predic out of sample data\nlogpred= logreg.predict(X_test)\nlogpred","c4c25fb6":"print(logreg.score(X_train, y_train), logreg.score(X_test, y_test))","610d531d":"logreg.predict_proba(X_test)","c329addf":"print(confusion_matrix(y_test, logpred))\n\nprint(round(accuracy_score(y_test, logpred),2)*100)\n\nprint(round(metrics.recall_score(y_test, logpred),2))\n\nprint(round(metrics.precision_score(y_test, logpred),2))\n\nLOGCV = (cross_val_score(logreg, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())\n\n","ebba7c03":"print(' Performance Metrics Reports\\n',classification_report(y_test, logpred))","31cc21e1":"fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, logpred)\n\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nplt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('ROC curve for LogReg model ',fontsize=10)\nplt.ylabel('True Positive Rate',fontsize=20)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 16})\n\nplt.show()","1b1e5e5a":"from sklearn.model_selection import GridSearchCV\n\n# set up the parameters of the model you'd like to fit\nparam_grid = {\n    'penalty': ['l1', 'l2'],\n    'C'      : [.0001, .001, .01, .1, 1, 10, 100, 1000, 10000],\n}","2fdefa21":"# load it into the grid\ngrid = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=10)\n\n# fit it on your training data\ngrid.fit(X_train, y_train)\n\n# get the version that gave you the best fit\ngrid.best_params_\n\n# Note that tunning parameter is 1\/C is small","8dc0e86b":"params_lg = {'C': 10000, 'penalty': 'l1'}\n\nlogreg.set_params(**params_lg)","aaf10514":"logreg.fit(X_train, y_train)","e45de71c":"logreg.predict_proba(X_test)","90254bfc":"fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, logpred)\n\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nplt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('ROC curve for LogReg model ',fontsize=10)\nplt.ylabel('True Positive Rate',fontsize=20)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 16})\n\nplt.show()","1c9188ca":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini\ndtree.fit(X_train, y_train)\ndtreepred = dtree.predict(X_test)","c74f22a4":"\nprint(confusion_matrix(y_test, dtreepred))\nprint(round(accuracy_score(y_test, dtreepred),2)*100)\nDTREECV = (cross_val_score(dtree, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","9e1295c3":"print(' Performance Metrics Reports\\n',classification_report(y_test, logpred))","149fca2d":"fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, logpred)\n\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nplt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('ROC curve for Decision Tree model ',fontsize=10)\nplt.ylabel('True Positive Rate',fontsize=20)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 16})\n\nplt.show()","3dbc5aef":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 200)#criterion = entopy,gini\nrf.fit(X_train, y_train)\nrfpred = rf.predict(X_test)\n","1724e1b6":"print(confusion_matrix(y_test, rfpred ))\nprint(round(accuracy_score(y_test, rfpred),2)*100)\nRFCV = (cross_val_score(rf, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","3b41abef":"print(' Performance Metrics Reports\\n',classification_report(y_test, rfpred))","8a0133a6":"fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, logpred)\n\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nplt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('ROC curve for Random Forest model ',fontsize=10)\nplt.ylabel('True Positive Rate',fontsize=20)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 16})\n\nplt.show()","40c83866":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)\ngbpred = gb.predict(X_test)\n","716c909a":"print(confusion_matrix(y_test, gbpred ))\nprint(round(accuracy_score(y_test, gbpred),2)*100)\nGBCV = (cross_val_score(gb, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","c81a8c2d":"fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, gbpred)\n\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nplt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('ROC curve for Gradient Boosting model ',fontsize=10)\nplt.ylabel('True Positive Rate',fontsize=20)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 16})\n\nplt.show()","6b734d1a":"from sklearn.svm import SVC\nsv= SVC(kernel = 'sigmoid')\nsv.fit(X_train, y_train)\nsvpred = sv.predict(X_test)\n","396fae8b":"print(confusion_matrix(y_test, svpred))\nprint(round(accuracy_score(y_test, svpred),2)*100)\nSVCV = (cross_val_score(sv, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","872bdcf2":"print(' Performance Metrics Reports\\n',classification_report(y_test, svpred))","3ccae097":"fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, svpred)\n\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nplt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('ROC curve for SVM model ',fontsize=10)\nplt.ylabel('True Positive Rate',fontsize=20)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 16})\n\nplt.show()","633d2000":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=22)\nknn.fit(X_train, y_train)\nknnpred = knn.predict(X_test)","c679042b":"print(confusion_matrix(y_test, knnpred))\nprint(round(accuracy_score(y_test, knnpred),2)*100)\nKNNCV = (cross_val_score(knn, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","9a1ec37e":"fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, knnpred)\n\nroc_aucgbk = metrics.auc(fprgbk, tprgbk)\n\nplt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('ROC curve for KNN model ',fontsize=10)\nplt.ylabel('True Positive Rate',fontsize=20)\nplt.xlabel('False Positive Rate',fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 16})\n\nplt.show()","ac36fceb":"#### Overfitting is a common problem in machine learning\n\nthe model performs well on training data but does not generalize well to test data","8c78a9d5":"#### Confusion_matrix: \n\nor error matrix allows a more detailed analysis than the accuracy_score which can yield to misleading results if the data set is unbalanced \n\n(when the numbers of observations in different classes vary greatly)","fac227bc":"##  Logistic Regression \n\n - one of the most widely used algorithms for classification","6c4f57d3":"#### ROC curve plot and Area Under the Curve (AUC)\n\n\n - a model that randomly guesses the label will result in the red interrupted line \n \n - our model has the ROC curve is above the red line (good\n \n - Many data scientists prefer to use the AUC to analyze a model\u2019s performance:\n \nAccuracy is measured by the area under the ROC curve. An area of 1 represents a perfect test; an area of .5 represents a worthless test.**\n\n\n.90-1 = excellent (A)\n\n.80-.90 = good (B)\n\n.70-.80 = fair (C)\n\n.60-.70 = poor (D)\n\n.50-.60 = fail (F)\n","6d7aacc7":"## Decision Tree Model\n\nThis identification can be quite useful when we try to understand what is driving market behavior. \n\nIt also has an advantage over regression in its ability to detect nonlinear relationships.","40ee999e":"### Predict also the class-membership probability of the samples\n\nvia the predict_proba method.","bdb187c1":"## Standardize the features \n\n\n- Many machine learning and optimization algorithms also require feature scaling\nfor optimal performance","ec0250c5":"#### The output that recreates the predictions","a37d3519":"## K-Nearest Neighbors Model","f43ff1e4":"#### The output of the sigmoid(z) is interpreted as prob(y=1 | X, w)\n\nthe probability of particular sample belonging to class y= 1 given its features X parameterized by the weights w:","6d4447bd":"\n###  AUC = 68% \n\nis a slight improvement.\n\n- We can do a Grid Search","ec14e423":"### Peformance metrics available in Scikit-learn via the metrics module:\n\n#### Accuracy_score:\n\nthe proportion of correct classifications\n\nTP+TN \/ TP+TN+FP+FN","51f14ea3":"#### Summary using classification_report","4917ef35":"## Random Forest Model\n\nClassify the data set by taking a majority vote of each leaf value","a97d3f68":"## Modeling class probabilities using Logistic Regression","02292a31":"### Performance Metrics","792cbea1":"\n###  AUC = 60% \n\n\nThe reason for the perceptron algorithm perfomance is that it doesn't converge if the classes are not perfectly linearly separable.\n\n\n\n- Next we will look at other classifiers:\n ","a26ac35e":"### Peformance metrics in scikit-learn :","5dec4319":"## Support Vector Machine","3e9fd735":"## Gradient Boosting","e0726d20":"####   Cross-validation:\n\n\nEstimatorCV has built-in cross-validation capabilities to automatically select the best hyper-parameters.\n\n\"The advantage of using a cross-validation estimator over the canonical Estimator class along with grid search is that they can take advantage of warm-starting by reusing precomputed results in the previous steps of the cross-validation process. This generally leads to speed improvements.\" (scikit-learn.org)","79c62220":"\n\n#### f1-score:\n\n- F1-score is the harmonic mean of precision and sensitivity \n\nF1 = 2*PPV * TPR \/(PPV+TPR)","5cf27993":"### Performance Metrics","ef439839":"\n### R2 score:","2742173c":"### Predict","aaf68df6":"#### Precision_score:\n\nor positive predictive value (PPV) is another performance metric used in predictive analytics\n\nTP \/ (TP + FP) \n\n- For all positive how much the model predicts correctly","e917a2ec":"\n###  AUC = 75% \n\nis a slight improvement.","bca20826":"## Perceptron model\n\nHaving standardized the training data, we can now train a perceptron model","6ddf201d":"- it is similar to linear regression where we use the sigmoid function instead of linear function to fit the data\n\nThe output of the sigmoid function is interpreted as the probability of particular sample belonging to class y=1 given its features X_train parameterized by the weights (the coefficients are obtained by maximizing the log-likelihood function)\n\n\n####  p the probability of a positive event (y=1)\np =prob(y=1 |X)\n\n#### Odds ratio: \np\/(1-p) = odds in favor of the positive event\n\n#### z is the net input \n=the linear combination of weights and sample features X\n\n z = log(p\/1-p) \n\n#### y = response variable\n\ny = sigmoid (z)\n","7f55806f":"## Selecting the best Machine Learning algorithm\n\n\n- Data Source available at:\n\n http:\/\/archive.ics.uci.edu\/ml\/datasets\/Bank+Marketing# \n\n\nThis data is related with a bank marketing campaign (phone calls).\n\nThe bank's business goal is to attract new clients to open a Certificate of Deposit i.e., to predict if a prospect will open a CD.\n\n\n- We've cleaned the data and performed EDA.\n\n- Loading the data:","86517741":"\n- \"How to acquire new clients?\"\n\n- \"How to improve the efficiency of a marketing campaign?\"\n\n","f5cc8249":"### Predict\nHaving trained a model in scikit-learn, we can make predictions","62ba986a":"## Applications","7c033f7f":"### Performance Metrics","6921d842":"#### Recall_score:\n\nor recognition rate is another performance metric used in predictive analytics\n\nRecall (or sensitivity) is the fraction of positives predicted correctly:\n\nTP\/(TP + FN) \n\n\n","f5522965":"## train_test_split: 80\/20","2badb472":"### Performance Metrics","9207ac66":"## k fold cross-validation","5e9d7e32":"You may use this code to help implement and choose the best Machine Learning algorithm to solve the following business problems:","26c044f7":"### Interpretation\n\nFirst code performs a logistic regression using default options.\n\nThen I performed a grid search on logistic regression and selected the best_params for logistic regression with Lasso using ('penalty=l1') and tunning parameter 1\/C ('C': 10000) on the same variable. I fitted on the entire training data.\n\nAs I expect, the results are similar, giving me confidence that the logistic regression model is stable."}}