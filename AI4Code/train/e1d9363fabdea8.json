{"cell_type":{"6e572392":"code","05cee196":"code","ec4a2c99":"code","a7c28c47":"code","7e8c7a18":"code","e69a5fc6":"code","1775aae3":"code","c84a2266":"code","69c25da3":"code","a4d0d52d":"code","0f2b74c2":"code","0e7c9daf":"code","f4c0fe7a":"code","b6340c40":"code","981ed324":"code","0ac69a25":"code","bc49aa76":"code","3ec06ab4":"code","ff12f6b5":"code","213691ca":"markdown","11ec8e86":"markdown","ad683e88":"markdown","3a3bace8":"markdown","696b7524":"markdown","a9ba880d":"markdown","f32ce97e":"markdown","0e7817ef":"markdown","4267f409":"markdown"},"source":{"6e572392":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05cee196":"# import libaries \n\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nimport cv2 as cv\nimport random\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow.keras \nfrom tensorflow.keras.models import Sequential, load_model, Model\nfrom tensorflow.keras import layers \nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n","ec4a2c99":"# import the data\ntrain_df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain_df.head()","a7c28c47":"num_instances = train_df.groupby('label').size()\n\nplt.figure(figsize = (10,5))\nplt.bar(np.unique(train_df.label),num_instances)\nplt.title('Number of labels within the training set', fontweight = 'bold')\nplt.xlabel('labels')\nplt.ylabel('instances')","7e8c7a18":"%%time\nsamples, columns = train_df.shape\n\n# empty tensors \nX = np.zeros((samples,28,28,1))\ny_true = np.zeros((samples,1))\n\nfor sample in tqdm(range(samples)):\n    X[sample,:,:,:] = train_df.iloc[sample,1:columns].values.reshape(28,28,1).astype('float32') # convert vectors into 2D tensors with (28,28,1)\n    y_true[sample,0] = train_df.iloc[sample,0] # read the the corresponding output labels","e69a5fc6":"values = train_df.label\n# integer encode\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(values)\n\nprint('The original output labels', values)\n# binary encode\nonehot_encoder = OneHotEncoder(sparse=False)\n\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded) # corresponding loss function is the \"categorical cross entropy\" and the neural network output should be a layer with 9 neurons\nsamples, classes = onehot_encoded.shape\nprint(\"Number of vectors:\", samples, \"\\nNumber of neurons \/ length of vector:\", classes)","1775aae3":"y = onehot_encoded # corresponding ground truth vector for X","c84a2266":"%%time\n# normalize the input features\ndef standard_norm(img):\n    return (img - np.mean(img))\/np.std(img)\n\n# empty tensor \nnorm_X = np.zeros((samples,28,28,1))\nfor sample in tqdm(range(samples)):\n    norm_X[sample,:,:,:] = standard_norm(X[sample,:,:,:]).reshape(28,28,1) \n    ","69c25da3":"def METRICS():\n    metrics = ['accuracy', \n              Precision(name='precision'), \n              Recall(name='recall'),\n              AUC(name='AUC')]\n    return metrics\n\n\nmodel = Sequential()\nmodel.add(layers.Input(shape=(28, 28, 1))) \nmodel.add(layers.Conv2D(32, (3,3), padding = 'same', activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2)))\nmodel.add(layers.Conv2D(64, (3,3), padding = 'same', activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2)))\nmodel.add(layers.Conv2D(128, (3,3), padding = 'same', activation='relu'))\nmodel.add(layers.BatchNormalization())\n\n\nmodel.add(layers.GlobalAveragePooling2D()) \nmodel.add(layers.Dense(classes,activation='softmax', name = 'output_layer'))\nmodel.compile(Adam(lr = 0.00100005134), metrics= METRICS(), loss = 'categorical_crossentropy') \nmodel.summary()","a4d0d52d":"# functions to help split our data and train our model ...\n\ndef split_data(X,Y):\n    return train_test_split(X, Y, test_size=0.2, random_state=42)\n\ndef train_model(model, X, Y, epochs, bs):\n    X_train, X_val, y_train, y_val = split_data(X,Y)\n    \n    STEP_SIZE_TRAIN = X_train.shape[0]\/\/bs + 1\n    STEP_SIZE_VAL = X_val.shape[0]\/\/bs + 1\n    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n    \n    train_history = model.fit(X_train, y_train, \n                             steps_per_epoch = STEP_SIZE_TRAIN,\n                             validation_data = (X_val,y_val),\n                             validation_steps = STEP_SIZE_VAL, \n                            epochs = epochs, shuffle = True,\n                             )\n    return train_history, model\n","0f2b74c2":"# train model .. \nepochs, bs = 20, 32 # choosen hyperparameters\ntrain_hist, final_model = train_model(model, norm_X, y, epochs, bs)","0e7c9daf":"%%time\n\nsamples, columns = test_df.shape\nX_test = np.zeros((samples,28,28,1)) # empty tensor\nX_norm_test = np.zeros((samples,28,28,1))\nfor sample in tqdm(range(samples)):\n    X_test[sample,:,:,:] = test_df.iloc[sample,:].values.reshape(28,28,1).astype('float32') # convert vector into 2D tensor\n    X_norm_test[sample,:,:,:] = standard_norm(X_test[sample,:,:].reshape(28,28,1))","f4c0fe7a":"\"\"\"\n    Implementing class activation maps for architectures with Global Average Pooling 2D before the final dense layer \n\"\"\"\nclass MNIST_CAM:\n    \n    def __init__(self, img):\n        self.resize_width, self.resize_height, _ = img.shape    \n    \n    # zero-center normalization \n    def standard_norm(self, img):\n        return ((img - np.mean(img))\/np.std(img))\n    \n    # final layer should be (7,7,2048)\n    def feature_model(self, model):  \n        return Model(inputs = model.layers[0].input, outputs = model.layers[-3].output)\n    \n    # final weight tensor before classification layer is 3*2048\n    def weight_tensor(self, model):\n        final_outputs = model.layers[-1]\n        return final_outputs.get_weights()[0]\n    \n    # output prediction class of the image of interest\n    def predict_class(self, model, X):\n        prob_vec = model.predict(X)\n        return np.argmax(prob_vec[0])\n        \n    # generate class activation maps (CAMs)    \n    def generate_CAM(self, model, img):\n        norm_img = self.standard_norm(img)\n        Fmap_model = self.feature_model(model)\n        Wtensor = self.weight_tensor(model)\n        feature_map = Fmap_model.predict(norm_img.reshape(1,28,28,1))\n        label = self.predict_class(model, norm_img.reshape(1,28,28,1))\n        CAM = feature_map.dot(Wtensor[:,label])[0,:,:]\n        return cv.resize(CAM, \n                         (self.resize_width, self.resize_height),\n                         interpolation = cv.INTER_CUBIC), label\n    \n    # generate probability vector \n    def generate_probvec(self, model, img):\n        X = self.standard_norm(img)\n        prob_vec = model.predict(X.reshape(1,28,28,1))\n        return prob_vec","b6340c40":"# example image \nimg = X_test[102,:,:,:]\nCAM_generator = MNIST_CAM(img)\nplt.imshow(img.reshape(28,28), cmap='gray')\nactivation_map, label = CAM_generator.generate_CAM(final_model, img)\nplt.imshow(activation_map,'jet', alpha = 0.3)\nplt.title(\"Predicted Class: \" + str(label))\nplt.show()","981ed324":"# Here is an interactive loop that asks if you want to continue to generate random input digit images \n#through the CAM_generator ...\n\n\n# Generate and plot class activation map along with the original image ... \nwhile True:\n    sample = random.randint(0, len(X_test))\n    img = X[sample,:,:,:] \n    CAM_generator = MNIST_CAM(img)\n    plt.imshow(img.reshape(28,28), cmap='gray')\n    activation_map, label = CAM_generator.generate_CAM(final_model, img) # generate activation map and output label\n    plt.imshow(activation_map,'jet', alpha = 0.3)\n    plt.title(\"Predicted Class: \" + str(label))\n    plt.show()\n    request = input(\"Next Image? (y\/n)\")\n    if request and request[0] == 'n':\n        break","0ac69a25":"final_model.predict(X_norm_test[0,:,:,:].reshape(1,28,28,1))","bc49aa76":"y_test,test_Ids = np.zeros((samples,1)), np.zeros((samples,1))\n\n\nfor sample in tqdm(range(samples)):\n    y_test[sample,0] = np.argmax(final_model.predict(X_norm_test[sample,:,:,:].reshape(1,28,28,1)))\n    test_Ids[sample,0] = int(sample+1)          ","3ec06ab4":"label_df, pred_df = pd.DataFrame(test_Ids), pd.DataFrame(y_test)\nsub_df = pd.concat([label_df, pred_df], axis = 1)\nsub_df.iloc[:,:] = sub_df.iloc[:,:].astype('int')\nsub_df.columns = ['ImageId', 'Label']\nsub_df.head()","ff12f6b5":"sub_df.to_csv('sample_submission.csv', index=False)","213691ca":"## Class Activation Maps:\n\nIf you are interested in more detail about CAMs, here is the following link that takes you to the authors website: [Learning Deep Features for Discriminative Localization](http:\/\/cnnlocalization.csail.mit.edu\/). Here, I will create a object that creates a subset model of our trained model on the MNIST dataset that inputs images with size 28x28 and outputs 128 feature maps with size 7x7. This feature map in particular is the convolutional block before the Global Average Pooling layer. Then for the image of interest, we let the originally trained model predict the label, that way, we can extract the weight vector from the weight tensor that corresponds to the final output dense layer. This weight vector will then have a size of (128,1). Next, we generate the 128 feature maps for the image of interest and compute the dot product of these feature maps with weight vector that corresponds the model's predicted output neuron. So the dot product will be the following: (7,7,128)$\\cdot$(128,1) = (7,7,1). This output with size (7,7,1) is the class activation map, where we then resize the image into (28,28,1) and overlap the original input image and activation map. Finally, by overlapping the activation map and image, we can find which features of the image the neural network focuses onto so that the model can successfully predict the label. ","11ec8e86":"The above graph tells us that the data is not as imbalanced as most datasets. However, it does seem that exists couple labels (e.g., 4 and 5) that are under counted, while the above figure also shows few labels (e.g., 1, 3, and 7) are abundant. Overall, the imbalances are not too dramatic, so we will avoid including any sort of class balancing methods into our pipeline.","ad683e88":"## Baseline model:\n\nHere, we will construct a Convolutional Neural Network with batch normalization layers after each conv. In addition, we included a GlobalAveragePooling, so that we can implement a Class Activation Map into our pipeline. Important to note, CAMs require a Global Average Pooling before the output layer, while Grad-CAMs can be implemented on any Convolutional Neural Network architecture. ","3a3bace8":"## Prepare the training data: \n\nHere, the dataframes contain the images as 28*28 columns as integer values, so we have to reshape from (1,28x28) into (28,28,1) and convert the data into float32.","696b7524":"## Exploring Data Analysis:\n\nHere, we will quickly check if class imabalances exist within our training dataset. ","a9ba880d":"## Load Test Data:\n\nBefore implementing CAMs, we will load test images to demonstrate our neural networks ability to focus on imperative features that correspond to accurately classify digits.  ","f32ce97e":"We successfully normalized our image pixels from [0,255] to [-I_lower, I_upper], where I means intensity pixel value, and the normalized image pixels are binned into a range such that the mean and standard deviation of the whole image is equal to 0 and 1.","0e7817ef":"## Submitted Test Set: ","4267f409":"One hot encode the output labels ... "}}