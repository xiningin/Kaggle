{"cell_type":{"d1e9409b":"code","3cfa5452":"code","8268ab31":"code","d3fe9f86":"code","9fd8b14b":"code","bec1a52d":"code","92642d1b":"code","e9d3f401":"code","80a776ab":"code","85e1456e":"code","f84c47ce":"code","5a5297ae":"code","6e8d682d":"code","7f58d222":"code","20ec9c52":"code","caf1c7d7":"code","b8a6d38a":"code","fc2fbeab":"code","68d7e72d":"code","4e523474":"code","4b743d8b":"code","144ca80e":"code","d3418e05":"code","a61c88c1":"code","542ae4a4":"markdown","e2292e3b":"markdown","54a1ac3f":"markdown","df7eacb3":"markdown","cae69fe4":"markdown","41429a45":"markdown","0a06f1b7":"markdown","c5f7024f":"markdown"},"source":{"d1e9409b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3cfa5452":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier # Model 1 or Base Model\nfrom sklearn.ensemble import RandomForestClassifier # Model 2\nfrom sklearn.tree import DecisionTreeClassifier # Model 3\nfrom sklearn.model_selection import RandomizedSearchCV # Model 4\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.preprocessing import StandardScaler","8268ab31":"df = pd.read_csv(\"\/kaggle\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv\")\n\ndf.info()","d3fe9f86":"# We can not see any null values but we will still look for null values just in case\nprint('Number of Null values')\nprint(df.isnull().sum())\nprint()\nprint('Number of ? values')\nprint((df == '?').sum())","9fd8b14b":"categorical_cols = ['SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','default.payment.next.month']\nnumerical_cols = df.drop(['ID','SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','default.payment.next.month'], axis=1)","bec1a52d":"print('Describing numerical columns')\nprint(df[numerical_cols.columns].describe())","92642d1b":"# From df.info we can see that there is no PAY_1 between PAY_0 and PAY_2\n# We can rename PAY_0 to PAY_1 becasue BILL_AMT and PAY_AMT are also starting from 1\n\ndf = df.rename(columns={'PAY_0':'PAY_1'})\n\nprint(f'Column names are :', list(df.columns))","e9d3f401":"# From the Data Description given, we know that in df.EDUCATION, 5 and 6 represents \"unknown\"\n# Changing 6 to 5 to keep it under 1 category\n\ndf['EDUCATION'] = df['EDUCATION'].replace(6,5)\n\nprint(f'Unique values of Education columns are:',np.unique(df['EDUCATION']))","80a776ab":"# We can drop the 'ID' column as it is irrelevant to our target column\ndf.drop(['ID'], axis=1, inplace=True)\nprint(df.columns)","85e1456e":"# Percentage of people who have Deafulted and not Defaulted\n\ntarget_count = df.groupby('default.payment.next.month').size().reset_index(name='counts')\n\nplt.figure(figsize=(6,6))\nplt.bar(target_count['default.payment.next.month'], target_count.counts)\nplt.xticks([0,1], labels=[\"Not Deafaulted\", \"Defaulted\"])\nplt.title(\"Target Distribution\")\n\ntotal = len(df['default.payment.next.month'])\nnot_def = len(df[df['default.payment.next.month']==0])\/total *100\nyes_def = len(df[df['default.payment.next.month']==1])\/total *100\n\nplt.text(x=0, y=not_def,s=str(\"%.2f\"%not_def+'%'), fontsize=12, position=(0,len(df[df['default.payment.next.month']==0])*1.006), horizontalalignment='center')\nplt.text(x=1, y=yes_def,s=str(\"%.2f\"%yes_def+'%'), fontsize=12, position=(1,len(df[df['default.payment.next.month']==1])*1.02), horizontalalignment='center')\n\nplt.show()","f84c47ce":"df['Age_category'] = pd.cut(df.AGE, bins=[20,35,50,80])\n\ntarget_count = df.groupby(['Age_category','SEX']).AGE.count().unstack()\n\n# print(target_count)\nplt.figure(figsize=(6,6))\ntarget_count.plot(kind='bar', stacked=False)\nplt.xticks(rotation=0)\nplt.ylabel('Count')\nplt.legend(['Male', 'Female'])\nplt.title(\"Age and Sex counts\")\nplt.show()","5a5297ae":"target_count = df.groupby(['Age_category','default.payment.next.month']).AGE.count().unstack()\n\n# print(target_count)\nplt.figure(figsize=(6,6))\ntarget_count.plot(kind='bar', stacked=True)\nplt.xticks(rotation=0)\nplt.ylabel('Count')\nplt.legend(['Not defaulted', 'Defaulted'])\nplt.title(\"Age and People deafulted counts\")\nplt.show()","6e8d682d":"target_count = df.groupby(['SEX','default.payment.next.month']).SEX.count().unstack()\n\n# print(target_count)\nplt.figure(figsize=(6,6))\ntarget_count.plot(kind='bar', stacked=False)\nplt.xticks([0,1],labels=['Male','Female'],rotation=0)\nplt.ylabel('Count')\nplt.legend(['Not defaulted', 'Defaulted'])\nplt.title(\"Sex and People deafulted counts\")\nplt.show()","7f58d222":"plt.subplots(figsize=(10,5))\n# plt.subplot(121)\nsns.distplot(df.LIMIT_BAL)\nplt.show()","20ec9c52":"plt.subplots(figsize=(20,10))\nplt.subplot(231)\nplt.scatter(x=df.PAY_AMT1, y=df.BILL_AMT1, c='r', s=1)\nplt.xlabel('PAY_AMT1')\nplt.ylabel('BILL_AMT1')\n\nplt.subplot(232)\nplt.scatter(x=df.PAY_AMT2, y=df.BILL_AMT2, c='g', s=1)\nplt.xlabel('PAY_AMT2')\nplt.ylabel('BILL_AMT2')\nplt.title('Payment structure vs Bill amount in the last 6 months', fontsize=15)\n\nplt.subplot(233)\nplt.scatter(x=df.PAY_AMT3, y=df.BILL_AMT3, c='b', s=1)\nplt.xlabel('PAY_AMT3')\nplt.ylabel('BILL_AMT3')\n\nplt.subplot(234)\nplt.scatter(x=df.PAY_AMT4, y=df.BILL_AMT4, c='y', s=1)\nplt.xlabel('PAY_AMT4')\nplt.ylabel('BILL_AMT4')\n\nplt.subplot(235)\nplt.scatter(x=df.PAY_AMT5, y=df.BILL_AMT5, c='black', s=1)\nplt.xlabel('PAY_AMT5')\nplt.ylabel('BILL_AMT5')\n\nplt.subplot(236)\nplt.scatter(x=df.PAY_AMT6, y=df.BILL_AMT6, c='m', s=1)\nplt.xlabel('PAY_AMT6')\nplt.ylabel('BILL_AMT6')\n\n\nplt.show()","caf1c7d7":"X = df.drop(['default.payment.next.month','Age_category'], axis=1)\ny = df['default.payment.next.month']\nX.head()","b8a6d38a":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","fc2fbeab":"model1 = RidgeClassifier()\n\nmodel1.fit(X_train, y_train)\n\nmodel1_acc = model1.score(X_test, y_test)*100\n\nprint('Model1 Accuracy score is :', model1_acc)\n\nprint( classification_report(y_test, model1.predict(X_test)) )\n\nplot_confusion_matrix(model1, X_test, y_test, cmap=\"Blues_r\")\n\nplt.show()","68d7e72d":"model2 = DecisionTreeClassifier(criterion='entropy', max_depth=10)\n\nmodel2.fit(X_train, y_train)\n\nmodel2_acc = model2.score(X_test, y_test)*100\n\nprint('Model2 Accuracy score is :', model2_acc)\n\nprint( classification_report(y_test, model2.predict(X_test)) )\n\nplot_confusion_matrix(model2, X_test, y_test, cmap=\"Blues_r\")\n\nplt.show()","4e523474":"model3 = RandomForestClassifier(max_depth=10)\n\nmodel3.fit(X_train, y_train)\n\nmodel3_acc = model3.score(X_test, y_test)*100\n\nprint('Model3 Accuracy score is :', model3_acc)\n\nprint( classification_report(y_test, model3.predict(X_test)) )\n\nplot_confusion_matrix(model3, X_test, y_test, cmap=\"Blues_r\")\n\nplt.show()","4b743d8b":"# Creating parameters for RandomSearch\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","144ca80e":"rf = RandomizedSearchCV(model3, param_distributions=random_grid, verbose=1, random_state=10, cv=5, n_iter=10)\nrf.fit(X_train, y_train)","d3418e05":"model4 = rf.best_estimator_\nmodel4_acc = model4.score(X_test,y_test)*100\n\nprint('Model4 Accuracy score is :', model4_acc)\n\nprint( classification_report(y_test, model4.predict(X_test)) )\n\nplot_confusion_matrix(model4, X_test, y_test, cmap=\"Blues_r\")\n\nplt.show()","a61c88c1":"models = ['RidgeClassifier', 'DecisionTree', 'RandomTree', 'RandomizedSearch']\n\nacc = [model1_acc, model2_acc, model3_acc, model4_acc]\n\nplt.figure(figsize=(15,5))\nplt.barh(models, acc)\n  \nfor index, value in enumerate(acc):\n    plt.text(value, index,\n             str(\"%.2f\"%value))\nplt.title(\"Model Accuracy\")\nplt.show()","542ae4a4":"# Splitting the data into Train and Test","e2292e3b":"### RandomTree and RandomizedSearch models have almost same values of 82%\n\n### But RandomizedSearch have better confusion matrix and better recall for 'defaulted' \n\n\n### In conclusion RandomizedSearch is the best Model out of the above four","54a1ac3f":"# Visualizing Model Accuracy","df7eacb3":"# Conclusion","cae69fe4":"# Data cleaning","41429a45":"# Data importing and Basic Data Analysis","0a06f1b7":"# Building Model  ","c5f7024f":"# Visualization"}}