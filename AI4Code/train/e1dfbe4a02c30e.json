{"cell_type":{"f49a9ff5":"code","7a5880bf":"code","db5eef10":"code","7d0a7b06":"code","5a55e90e":"code","0bf04788":"code","05f07711":"code","025710cd":"code","da6e82f4":"code","c65d7afb":"code","f8e8c8e9":"code","dafbd71d":"code","2a32f4eb":"code","5789fe6d":"code","619be0ca":"code","995156f0":"code","16b3409c":"code","6d281e49":"code","84ce0b03":"code","c5d867fb":"code","04f193ae":"code","4d448620":"code","5c9b379c":"code","d5f02b40":"code","3a64678d":"code","88c2c393":"code","b649367e":"code","2fceffb9":"code","37380cb4":"code","83b9da4c":"code","19cba639":"code","4e0b22d4":"code","4a30897c":"code","b312b30a":"code","74f8bb4c":"code","0ad9fb46":"code","7f200bf8":"code","018f0b80":"code","72cbd042":"code","51f85acf":"code","af20674a":"code","f870a895":"code","0eae97ce":"code","75a4ad0e":"code","520c7a81":"code","aec3746e":"code","d1170c20":"code","3fc1401c":"code","99a47f6c":"code","f150a1c1":"code","ee829f21":"code","5b08ef0b":"code","e747fd36":"code","4305f2a8":"code","a967ec27":"code","a32f9cd7":"code","ff233ed8":"markdown","1256a175":"markdown","d1409eeb":"markdown","4d6744ba":"markdown","80ea5e2c":"markdown","7c002301":"markdown","25de51c5":"markdown","417887ea":"markdown","c487dbc4":"markdown"},"source":{"f49a9ff5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.figure_factory as ff\nfrom matplotlib import gridspec \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot","7a5880bf":"%matplotlib inline","db5eef10":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d0a7b06":"df = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","5a55e90e":"df.head()","0bf04788":"df.describe()","05f07711":"df.info","025710cd":"from pandas_profiling import ProfileReport","da6e82f4":"df.shape","c65d7afb":"print('Proportion of the classes in the data:')\nprint(df['Class'].value_counts() \/ len(df))","f8e8c8e9":"print(df.isnull().sum().max()) #there are no Null Values so we dont need to worry about them","dafbd71d":"df.columns","2a32f4eb":"print(\"Frauds in imbalanced dataset are\",round(sum(df['Class']==1)\/len(df)*100,2),\"%\")\nprint(\"Valid Transactions in imbalanced dataset are\",round(sum(df['Class']==0)\/len(df)*100,2),\"%\")","5789fe6d":"plt.figure(figsize=(20,2))\nsns.countplot(y=df['Class'])\nplt.savefig('countofdata.png')\nplt.show()","619be0ca":"class_0 = df.loc[df['Class'] == 0][\"Time\"]\nclass_1 = df.loc[df['Class'] == 1][\"Time\"]\nplt.figure(figsize = (14,4))\nplt.title('Credit Card Transactions Time Density Plot')\nsns.distplot(class_0,kde=True,bins=480,color = 'red')\nsns.distplot(class_1,kde=True,bins=480,color = 'blue')\nplt.show()","995156f0":"timedelta = pd.to_timedelta(df['Time'], unit='s')\ndf['Time_min'] = (timedelta.dt.components.minutes).astype(int)\ndf['Time_hour'] = (timedelta.dt.components.hours).astype(int)","16b3409c":"plt.figure(figsize=(12,5))\nsns.distplot(df[df['Class'] == 0][\"Time_hour\"], \n             color='g')\nsns.distplot(df[df['Class'] == 1][\"Time_hour\"], \n             color='r')\nplt.title('Fraud x Normal Transactions by Hours', fontsize=17)\nplt.xlim([-1,25])","6d281e49":"plt.figure(figsize=(12,5))\nsns.distplot(df[df['Class'] == 0][\"Time_min\"], \n             color='g')\nsns.distplot(df[df['Class'] == 1][\"Time_min\"], \n             color='r')\nplt.title('Fraud x Normal Transactions by Minutes', fontsize=17)\nplt.xlim([-1,60])","84ce0b03":"fig,ax = plt.subplots(1, 2, figsize=(18,4))\n\namount_val = df['Amount'].values\ntime_val = df['Time'].values\n\nsns.distplot(amount_val, ax=ax[0], color='r')\nax[0].set_title('Distribution of Transaction Amount', fontsize=14)\nax[0].set_xlim([min(amount_val), max(amount_val)])\n\nsns.distplot(time_val, ax=ax[1], color='b')\nax[1].set_title('Distribution of Transaction Time', fontsize=14)\nax[1].set_xlim([min(time_val), max(time_val)])","c5d867fb":"pip install mlxtend  ","04f193ae":"from sklearn.model_selection import train_test_split","4d448620":"plt.figure(figsize=(10,6))\ncorr_mat = df.corr()\ncorr_mat\nsns.heatmap(corr_mat,cmap = 'coolwarm')","5c9b379c":"df = df.drop(['Time','Time_hour','Time_min'], axis = 1)\nX = np.array(df.loc[:, df.columns != 'Class'])\ny = np.array(df.loc[:, df.columns == 'Class']).reshape(-1, 1)\n# standardize the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","d5f02b40":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 2, shuffle = True, stratify = y)\nprint(\"Number transactions X_train dataset: \", X_train.shape) \nprint(\"Number transactions y_train dataset: \", y_train.shape) \nprint(\"Number transactions X_test dataset: \", X_test.shape) \nprint(\"Number transactions y_test dataset: \", y_test.shape) ","3a64678d":"from sklearn.linear_model import LogisticRegression","88c2c393":"lr = LogisticRegression(solver = 'lbfgs')","b649367e":"lr.fit(X_train,y_train.ravel())","2fceffb9":"train_pred = lr.predict(X_train)\ny_pred=lr.predict(X_test)","37380cb4":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score,roc_auc_score, precision_recall_curve, roc_curve, auc, average_precision_score","83b9da4c":"print(classification_report(y_test, y_pred)) \nprint(accuracy_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","19cba639":"print('Confusion Matrix - Training Dataset')\nprint(pd.crosstab(y_train.ravel(), train_pred, rownames = ['True'], colnames = ['Predicted'], margins = True))","4e0b22d4":"average_precision = average_precision_score(y_test, y_pred)","4a30897c":"print(\"Area under the curve : %f\" % (roc_auc_score(y_test, y_pred)))","b312b30a":"from mlxtend.plotting import plot_confusion_matrix\ncon_mat=confusion_matrix(y_test, y_pred)\ndef confus_matrix(CM):\n    fig, ax = plot_confusion_matrix(conf_mat= CM)\n    plt.title(\"The Confusion Matrix of full dataset using best_parameters\")\n    plt.ylabel(\"Actual\")\n    plt.xlabel(\"Predicted\")\n    plt.show()\n    print(\"The accuracy is \"+str((CM[1,1]+CM[0,0])\/(CM[0,0] + CM[0,1]+CM[1,0] + CM[1,1])*100) + \" %\")\n    print(\"The recall from the confusion matrix is \"+ str(CM[1,1]\/(CM[1,0] + CM[1,1])*100) +\" %\")\nconfus_matrix(con_mat)","74f8bb4c":"precision, recall, _ = precision_recall_curve(y_test, y_pred)\nplt.step(recall, precision, color='b', alpha=0.2, where='post')\nplt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))","0ad9fb46":"fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred)\nroc_auc_rf = auc(fpr_rf, tpr_rf)\nplt.figure(figsize=(8,8))\nplt.xlim([-0.01, 1.00])\nplt.ylim([-0.01, 1.01])\nplt.plot(fpr_rf, tpr_rf, lw=1, label='{} curve (AUC = {:0.2f})'.format('RF',roc_auc_rf))\n\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curve', fontsize=16)\nplt.legend(loc='lower right', fontsize=13)\nplt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\nplt.axes().set_aspect('equal')\nplt.show()","7f200bf8":"print('Accuracy score for Training Dataset = ', accuracy_score(train_pred, y_train))\nprint('Accuracy score for Testing Dataset = ', accuracy_score(y_pred, y_test))","018f0b80":"134\/330","72cbd042":"#Now, we will apply different imbalanced data handling techniques and see their accuracy and recall results.","51f85acf":"#Using SMOTE Algorithm","af20674a":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n\n# import SMOTE module from imblearn library \n# pip install imblearn (if you don't have imblearn in your system) \nfrom imblearn.over_sampling import SMOTE \nsm = SMOTE(random_state = 2) \nX_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel()) \n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) \n","f870a895":"smote_logistic = LogisticRegression()\nsmote_logistic.fit(X_train_res,y_train_res)","0eae97ce":"train_pred_sm = smote_logistic.predict(X_train_res)\ny_smote= smote_logistic.predict(X_test)","75a4ad0e":"# Checking accuracy\naccuracy_score(y_test,y_smote)","520c7a81":"# f1 score\nf1_score(y_test, y_smote)","aec3746e":"pd.Series(y_train_res).value_counts().plot.bar()","d1170c20":"print('Accuracy score for Training Dataset = ', accuracy_score(train_pred_sm,y_train_res))\nprint('Accuracy score for Testing Dataset = ', accuracy_score(y_smote, y_test))","3fc1401c":"average_precision = average_precision_score(y_test, y_pred)","99a47f6c":"print(\"Area under the curve : %f\" % (roc_auc_score(y_test, y_pred)))","f150a1c1":"from mlxtend.plotting import plot_confusion_matrix\ncon_mat=confusion_matrix(y_test, y_smote)\ndef confus_matrix(CM):\n    fig, ax = plot_confusion_matrix(conf_mat= CM)\n    plt.title(\"The Confusion Matrix of full dataset using best_parameters\")\n    plt.ylabel(\"Actual\")\n    plt.xlabel(\"Predicted\")\n    plt.show()\n    print(\"The accuracy is \"+str((CM[1,1]+CM[0,0])\/(CM[0,0] + CM[0,1]+CM[1,0] + CM[1,1])*100) + \" %\")\n    print(\"The recall from the confusion matrix is \"+ str(CM[1,1]\/(CM[1,0] + CM[1,1])*100) +\" %\")\nconfus_matrix(con_mat)","ee829f21":"precision, recall, _ = precision_recall_curve(y_test, y_smote)\nplt.step(recall, precision, color='b', alpha=0.2, where='post')\nplt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))","5b08ef0b":"fpr_rf, tpr_rf, _ = roc_curve(y_test, y_smote)\nroc_auc_rf = auc(fpr_rf, tpr_rf)\nplt.figure(figsize=(8,8))\nplt.xlim([-0.01, 1.00])\nplt.ylim([-0.01, 1.01])\nplt.plot(fpr_rf, tpr_rf, lw=1, label='{} curve (AUC = {:0.2f})'.format('RF',roc_auc_rf))\n\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curve', fontsize=16)\nplt.legend(loc='lower right', fontsize=13)\nplt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\nplt.axes().set_aspect('equal')\nplt.show()","e747fd36":"print('Confusion Matrix - Training Dataset')\nprint(pd.crosstab(y_train_res, train_pred_sm, rownames = ['True'], colnames = ['Predicted'], margins = True))","4305f2a8":"16685\/190490","a967ec27":"print('Confusion Matrix - Testing Dataset')\nprint(pd.crosstab(y_test.ravel(), y_smote, rownames = ['True'], colnames = ['Predicted'], margins = True))","a32f9cd7":"12\/162","ff233ed8":"Roughly 7.4% of the fraud classes have been classified as not fraud.","1256a175":"16685 out of 190490 fraud cases have been classified as not fraud. This is a mere 8.7% compared to the previous 41%.\n\nA vast improvement!\n\nSame is the case with the Testing Dataset.","d1409eeb":"design_report = ProfileReport(df)\ndesign_report.to_file(output_file='credit card detection.html') #for making a pandas profile report","4d6744ba":"That is a whopping 41%! We are classifying 41% of the fraud cases as not fraud. This is going to cost some serious losses to the credit card company. You can observe this similarly in the confusion matrix of the Testing Dataset.\n\nThe higher accuracy is not due to correct classification. The model has predicted the majority class for almost all the examples. And since about 99.8% of the examples actually belong to this class, it leads to such high accuracy scores.","80ea5e2c":"We have obtained great accuracy and prediction, But this is hypothetical, as there was lot of imbalanced data.\nImbalanced classes are a common problem in machine learning classification where there are a disproportionate ratio \nof observations in each class. Class imbalance can be found in many different areas including medical diagnosis, spam filtering, and fraud detection.","7c002301":"Look! that SMOTE Algorithm has oversampled the minority instances and made it equal to majority class.\nBoth categories have equal amount of records. More specifically, the minority class \nhas been increased to the total number of majority class.\nNow see the accuracy and recall results after applying SMOTE algorithm (Oversampling).","25de51c5":"Also, in our undersample data our model is unable to detect for a large number of cases non fraud transactions correctly and instead, \nmisclassifies those non fraud transactions as fraud cases. Imagine that people that were making regular purchases got their card blocked due to the reason that our model classified that transaction as a fraud transaction, this will be a huge disadvantage for the financial institution. The number of customer complaints and customer disatisfaction will increase. \nThe next step of this analysis will be to do an outlier removal on our oversample dataset and see if our accuracy in the test set improves.","417887ea":"Implementing SMOTE on our imbalanced dataset helped us with the imbalance of our labels (more no fraud than fraud transactions).","c487dbc4":"CONCLUSION"}}