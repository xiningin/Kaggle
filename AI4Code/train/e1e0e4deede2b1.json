{"cell_type":{"c5a8b3a4":"code","c6dbc45d":"code","1a29d1d3":"code","0a1a6fe9":"code","42d4909f":"code","f12a7f3d":"code","cc687ee3":"code","0c3dea21":"code","c8c1569e":"code","2c68c951":"code","3a53c6bb":"code","44391a62":"code","4b248a32":"code","1bea1109":"code","ca84a70c":"code","241e172c":"code","3f57a764":"code","c9fcd1cb":"code","6f2b9d56":"code","ddb0155b":"code","f00f0fef":"code","32311004":"code","ad85962e":"code","8de74940":"code","543b48db":"code","2107a262":"code","9d904a84":"code","b5b7851e":"code","32b9ad04":"code","a65b40bc":"code","8cfe36d8":"code","2148251a":"code","0d52544e":"code","fdba2be2":"code","2341892c":"code","9083c79c":"code","fdad27d0":"code","946752c4":"code","fdeb710d":"code","793f3d35":"code","da5132a9":"code","13ce271c":"code","9754c169":"code","f5dcc6fe":"code","9328abfd":"code","af657185":"code","abbe81de":"code","62700bb1":"code","3cfd1da5":"code","9bdbe30c":"code","d3bfa863":"code","ee97ddc9":"code","b6f09d35":"code","14393eaf":"code","f1f6a4d0":"code","0bf60f82":"markdown","5af3316c":"markdown","7449f233":"markdown","a2b21c71":"markdown","54b59ea3":"markdown","1343dd0e":"markdown","5e111ff3":"markdown","7f483570":"markdown","8b96f5ec":"markdown","6dff3ab6":"markdown","3a3a3873":"markdown","10dfccc5":"markdown","a7a99d8e":"markdown","77f00262":"markdown","7270191b":"markdown","57307650":"markdown","09d61708":"markdown","afb707a1":"markdown","ad96308a":"markdown","53eed767":"markdown","57fb68df":"markdown","ff0af2ba":"markdown","7c6277f1":"markdown","1a3065e8":"markdown","2cbfc2ee":"markdown","c87466ce":"markdown","5d2bca6f":"markdown","0d9f5e88":"markdown"},"source":{"c5a8b3a4":"# import the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","c6dbc45d":"# import the dataset\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_data","1a29d1d3":"train_data.shape","0a1a6fe9":"test_data = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_data","42d4909f":"test_data.shape","f12a7f3d":"train_data.info()","cc687ee3":"test_data.info()","0c3dea21":"train_data.duplicated().sum()","c8c1569e":"test_data.duplicated().sum()","2c68c951":"train_data['Survived'].value_counts(normalize=True)","3a53c6bb":"import seaborn as sns\nsns.countplot(x='Survived', data=train_data)","44391a62":"train_data['Sex'].value_counts().to_frame()","4b248a32":"train_data.groupby('Sex').Survived.mean().to_frame()","1bea1109":"sns.countplot(x='Survived', hue='Sex', data=train_data)\nplt.title('Survival by Sex')","ca84a70c":"train_data['Pclass'].value_counts().to_frame()","241e172c":"# train_data['Pclass'].value_counts(normalize=True)\ntrain_data.groupby('Pclass').Survived.mean().to_frame()","3f57a764":"sns.countplot(x='Pclass', data=train_data)","c9fcd1cb":"sns.countplot(x='Pclass', hue='Survived', data=train_data)\nplt.title('Survival according to the Pclass')","6f2b9d56":"train_data['Pclass'].value_counts().to_frame()","ddb0155b":"sns.barplot(x='Pclass', y='Survived', hue='Sex', data=train_data)\nplt.title('Survival rate according to Pclass & Sex')","f00f0fef":"train_data.groupby(['Pclass','Sex']).Survived.mean().to_frame()","32311004":"sns.boxplot(x='Pclass', y='Age', hue='Survived', data=train_data)","ad85962e":"sns.boxplot(x='Pclass', y='Fare', data=train_data)","8de74940":"sns.boxplot(x='Survived', y='Fare',data=train_data)","543b48db":"train_data[train_data['Fare']==0]","2107a262":"def remove_zero_fares(row):\n    if row.Fare == 0:\n        row.Fare = np.NaN\n    return row","9d904a84":"train_data = train_data.apply(remove_zero_fares, axis=1)\ntest_data = test_data.apply(remove_zero_fares, axis=1)","b5b7851e":"train_data[train_data['Fare'] == 0]\ntest_data[test_data['Fare'] == 0]","32b9ad04":"train_data['Embarked'].value_counts()","a65b40bc":"sns.countplot(x='Embarked', hue='Pclass', data=train_data)","8cfe36d8":"sns.barplot(x='Embarked', y='Survived', hue='Pclass', data=train_data)","2148251a":"train_data['Title'] = train_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntest_data['Title'] = test_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())","0d52544e":"train_data['Title'].value_counts()","fdba2be2":"test_data['Title'].value_counts()","2341892c":"train_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntest_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntrain_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\ntest_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)","9083c79c":"train_data['Title'].value_counts()","fdad27d0":"sns.barplot(x='Title', y='Survived', data=train_data)","946752c4":"# Extract the first two letters\ntrain_data['Ticket_lett'] = train_data.Ticket.apply(lambda x: x[:2])\ntest_data['Ticket_lett'] = test_data.Ticket.apply(lambda x: x[:2])","fdeb710d":"# Calculate ticket length\ntrain_data['Ticket_len'] = train_data.Ticket.apply(lambda x: len(x))\ntest_data['Ticket_len'] = test_data.Ticket.apply(lambda x: len(x))","793f3d35":"train_data['Fam_size'] = train_data['SibSp'] + train_data['Parch'] + 1\ntest_data['Fam_size'] = test_data['SibSp'] + test_data['Parch'] + 1","da5132a9":"sns.barplot(x='Fam_size', y='Survived', data=train_data)","13ce271c":"# Creation of four groups\ntrain_data['Fam_type'] = pd.cut(train_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\ntest_data['Fam_type'] = pd.cut(test_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])","9754c169":"sns.barplot(x='Fam_type', y='Survived', data=train_data)","f5dcc6fe":"sns.countplot(x='Fam_type', hue='Survived', data=train_data)","9328abfd":"Y=train_data['Survived']\nfeatures = ['Pclass', 'Fare', 'Title', 'Embarked', 'Fam_type', 'Ticket_len', 'Ticket_lett']\nX=train_data[features]\nX.head()","af657185":"numerical_cols = ['Fare']\ncategorical_cols = ['Pclass', 'Title', 'Embarked', 'Fam_type', 'Ticket_len', 'Ticket_lett']","abbe81de":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='median')","62700bb1":"# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])","3cfd1da5":"# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","9bdbe30c":"# Bundle preprocessing and modeling code \ntitanic_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', LogisticRegression(solver='liblinear'))\n])","d3bfa863":"# Preprocessing of training data, fit model \ntitanic_pipeline.fit(X,Y)","ee97ddc9":"print('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, Y, cv=10).mean()))","b6f09d35":"X_test = test_data[features]\nX_test.head()","14393eaf":"# Preprocessing of test data, get predictions\npredictions = titanic_pipeline.predict(X_test)","f1f6a4d0":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint('Your submission was successfully saved!')","0bf60f82":"We can see that that in our data 74% of females survived where as only 18% of males survived.","5af3316c":"### Cabin and Ticket\n\n1. The Cabin feature is somewhat problematic as there are many missing values.\n2. We can not expect it to help our model too much.\n3. On the other side, a correctly engineered Ticket column is the best way to find family groups.\n4. Since it is a pity to delete it knowing its full potential, we can create two new columns; one for the ticket first two letters and the second one for the ticket length.","7449f233":"Now we will clear the missing values","a2b21c71":"Lets check the missing values in the dataset","54b59ea3":"1. We can also see the survival rate by Sex and Pclass, which is quite impressive. First class and second class women who were rescued were respectively 97% and 92%, while the percentage drops to 50% for third-class women.\n2. Despite that, this is still more than the 37% survival rate for first-class men.","1343dd0e":"### Modeling\n1. We start by selecting the features we will use and isolating the target.\n2. We will not consider Cabin and in the end, we also excluded Age as the relevant information which is being a young man is encoded in the Master title.\n3. We also did not use Sex as it is not useful given the Title column: adult males and young children have the same sex but are really different categories as we saw before, so we don't want to confuse our algorithm.\n4. If you don't extract the Title column, remember to put Sex in your models as it is pretty important!","5e111ff3":"## Name\n\n1. The Name column contains useful information as for example we could identify family groups using surnames.\n2. In this notebook, however, we extracted only the passengers' title from it, creating a new feature for both train and test data.","7f483570":"1. We see that around 65% of the passengers were male while the remaining 35% were female.\n2. The important thing to notice here is that the survival rate for women was four times the survival rate for men and this makes Sex one of the most informative features.\n\n### Pclass","8b96f5ec":"1. Looking at the distribution of the titles, it might be convenient to move the really low-frequency ones into bigger groups.\n2. After analyzing them, we can substitute all rare female titles with Miss and all rare male titles with Mr","6dff3ab6":"Here is the final result. We have relatively high hopes for this new feature since the survival rate in most cases appears to be either significantly above or below the average survival rate, which should help our model.","3a3a3873":"1. Another interesting thing to look at is the relation between Age, Pclass and Survived.\n2. We see the influence of Pclass is the important one as there are no super clear horizontal patterns.\n3. Also, we note that there were not many children in the first class.","10dfccc5":"## Age,Pclass,Survived","a7a99d8e":"We can see that we have made the rows with Fare as 0 to NULL","77f00262":"1. There were three classes on the ship and from the plot we see that the number of passengers in the third class was higher than the number of passengers in the first and second classes combined.\n2. However, the survival rate by class is not the same, more than 60% of first-class passengers and around half of the second class passengers were rescued, whereas 75% of third class passengers were not able to survive the disaster.\n3. For this reason, this is definitely an important aspect to consider\n\n### Pclass & Sex","7270191b":"1. From the description, we see that the Fare distribution is positively skewed, with 75% of data under 31 and a goes to 500.\n2. At a first look, we notice that the higher the fare, the higher the possibility of surviving.","57307650":"### Embarked ,Pclass\n\nEmbarked tells us where a passenger boarded from.\n\nThere are three possible values for it: Southampton, Cherbourg and Queenstown.","09d61708":"We can see from the above that the no of Class 1 category people survived the most compared to the no of Class 2 category people.","afb707a1":"There are almost 15 such passengers are present. Since some of them are 1st or 2nd class passengers, we should remove zero-Fares that might confuse our model.\nWith the help of this function, we are going to set null values every time we encounter a zero value for Fare.","ad96308a":"We can see there are no duplicate values in our dataset\n\nLet us see how many passangers survived.","53eed767":"we can see that in our data there are missing values in 'Age' , 'Fare' and 'Cabin' columns\n\nWe will check for duplicated values as well","57fb68df":"### Family Type\nTo further summarize the previous trend, as our final feature, Let's create four groups for family size.","ff0af2ba":"Now we will test our model on test data","7c6277f1":"we can see that in our training data only 38% of people survived.\n\n### Feature Analysis\nHere we'll see how our data used to perform a more precise feature selection in the modeling part.\nWe will thus explore one feature at a time in order to determine its importance in predicting if a passenger survived or not.\n\n### Sex","1a3065e8":"We will input the training and testing data","2cbfc2ee":"### Family Size\nSince we have two seemingly weak predictors, one thing we can do is combine them to get a stronger one.\nIn the case of SibSp and Parch, we can join the two variables to get a family size feature, which is the sum of SibSp, Parch and 1 (who is the passenger himself).\nCreation of a new Fam_size column","c87466ce":"Plotting the survival rate by family size it is clear that people who were alone had a lower chance of surviving than families up to 4 components, while the survival rate drops for bigger families and ultimately becomes zero for very large ones.\n\n","5d2bca6f":"### Fare\n","0d9f5e88":"Submission File"}}