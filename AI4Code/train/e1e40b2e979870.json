{"cell_type":{"d9172a5f":"code","1ea3988d":"code","f4bde6ed":"code","dd71ad1b":"code","8a373656":"code","2ff128dc":"code","dd23b899":"code","ac93444e":"code","2fedbe0d":"code","2e7b34af":"code","080b520a":"code","60387759":"code","f1ec2cf7":"code","90400179":"code","1e5b569d":"code","092c99ef":"code","4e02acc1":"code","6383f22c":"code","f74cf2bf":"code","616fed9f":"code","1ad95e64":"markdown","2fc6e3da":"markdown","fc3024a1":"markdown","9121e223":"markdown","aa3b2739":"markdown","726d1616":"markdown"},"source":{"d9172a5f":"%config IPCompleter.greedy=True\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport re\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport matplotlib as matplot\n%matplotlib inline\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nfrom sklearn.model_selection import train_test_split","1ea3988d":"train = pd.read_csv('https:\/\/raw.githubusercontent.com\/defcom17\/NSL_KDD\/master\/KDDTrain%2B.csv')\ntest = pd.read_csv('https:\/\/raw.githubusercontent.com\/defcom17\/NSL_KDD\/master\/KDDTest%2B.csv')\ntrain.shape\ntest.shape \ntrain.columns = range(train.shape[1])\ntest.columns = range(test.shape[1])\nlabels = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n'num_access_files', 'num_outbound_cmds', 'is_host_login',\n'is_guest_login', 'count', 'srv_count', 'serror_rate',\n'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n'dst_host_srv_rerror_rate', 'attack_type', 'difficulty_level']# subclass - > attack_type\ncombined_data = pd.concat([train, test])\ncombined_data.shape\ncombined_data.head(5)","f4bde6ed":"combined_data.columns = labels\ncombined_data = combined_data.drop('difficulty_level', 1)\ncombined_data.head(3)","dd71ad1b":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nprint(set(list(combined_data['attack_type']))) # use print to make it print on single line \ncombined_data['attack_type'] = le.fit_transform(combined_data['attack_type'])\ncombined_data['protocol_type'] = le.fit_transform(combined_data['protocol_type'])\ncombined_data['service'] = le.fit_transform(combined_data['service'])\ncombined_data['flag'] = le.fit_transform(combined_data['flag'])\n\nprint('\\nDescribing attack_type: ')\ncombined_data['attack_type'].describe()","8a373656":"# select least correlated\ncorr_matrix = combined_data.corr().abs().sort_values('attack_type')\n# tmp.head(10) # to view CORR matrix \nleastCorrelated = corr_matrix['attack_type'].nsmallest(10)\nleastCorrelated = list(leastCorrelated.index)\n\n# select least correlated\nleastSTD =  combined_data.std().to_frame().nsmallest(5, columns=0)\nleastSTD = list(leastSTD.transpose().columns)  #fuckin pandas.core.indexes.base.Index   -_-\n#tmp = tmp.append('num_outbound_cmds')  # might not work...\nfeatureElimination = set(leastCorrelated + leastSTD)\nlen(featureElimination)\nfeatureElimination","2ff128dc":"combined_data=combined_data.drop(featureElimination,axis=1)\ndata_x = combined_data.drop('attack_type', axis=1)\ndata_y = combined_data.loc[:,['attack_type']]\ndel combined_data # free mem\nX_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.5, random_state=42) # TODO","dd23b899":"print(\"Thats how to rid rid of {0} dimentions of data, from the 10 lowest STD and 5 lowest correlation\".format(len(featureElimination)))\n\nX_train.shape\nX_test.shape","ac93444e":"from sklearn import linear_model\n\nfrom sklearn.ensemble import VotingClassifier\n\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import IsolationForest\n\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport gc \ngc.collect()","2fedbe0d":"x = X_train\ny = y_train['attack_type'].ravel()\n\nclf1 = DecisionTreeClassifier() \nclf2 = RandomForestClassifier(n_estimators=25, random_state=1)\nclf3 = GradientBoostingClassifier()\nET = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False) # .76 # without this lil fucker, Acc: 0.75 [Ensemble], 0.78 with \n\neclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),('et',ET)], voting='hard') \n\nfor clf, label in zip([clf1, clf2, clf3,ET, eclf], ['DecisionTreeClassifier', 'Random Forest', 'GradientBoostingClassifier','ExtraTreesClassifier', 'Ensemble']): \n    tmp = clf.fit(x,y)\n    pred = clf.score(X_test,y_test)\n    print(\"Acc: %0.2f [%s]\" % (pred,label))","2e7b34af":"LR = linear_model.LinearRegression()\nLR.fit(X_train, y_train)\nlr_score = LR.score(X_test, y_test)\nprint('Linear regression processing')\nprint('Linear regression Score: %.2f %%' % lr_score)","080b520a":"AB = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, learning_rate=1.0)\nRF = RandomForestClassifier(n_estimators=10, criterion='entropy', max_features='auto', bootstrap=True)\nET = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False)\nGB = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, max_features='auto')","60387759":"# y_train = Y_train['attack_type'].ravel()\n# x_train = X_train.values\n# x_test = X_test.values","f1ec2cf7":"AB.fit(X_train, y_train)\nAB_feature = AB.feature_importances_\n#AB_feature\nab_score = AB.score(X_test, y_test)\n\nprint('AdaBoostClassifier processing ,,,')\nprint('AdaBoostClassifier Score: %.3f %%' % ab_score)","90400179":"RF.fit(X_train, y_train)\nRF_feature = RF.feature_importances_\n#RF_feature\n\nrf_score = RF.score(X_test, y_test)\n\nprint('RandomForestClassifier processing ,,,')\nprint('RandomForestClassifier Score: %.3f %%' % rf_score)","1e5b569d":"ET.fit(X_train, y_train)\nET_feature = ET.feature_importances_\n#ET_feature\n\net_score = ET.score(X_test, y_test)\n\nprint('ExtraTreesClassifier processing ,,,')\nprint('ExtraTreeClassifier: %.3f %%' % et_score)","092c99ef":"GB.fit(X_train, y_train)\n\nGB_feature = GB.feature_importances_\n#GB_feature\n\ngb_score = GB.score(X_test, y_test)\n\nprint('GradientBoostingClassifier processing ,,,')\nprint('GradientBoostingClassifier Score: %.3f %%' % gb_score)","4e02acc1":"feature_df = pd.DataFrame({'features': X_train.columns.values, # names\n                           'AdaBoost' : AB_feature,\n                           'RandomForest' : RF_feature,\n                           'ExtraTree' : ET_feature,\n                           'GradientBoost' : GB_feature\n                          })\n#feature_df.features\nfeature_df.head(5)","6383f22c":"n = 10\na_f = feature_df.nlargest(n, 'AdaBoost')\ne_f = feature_df.nlargest(n, 'ExtraTree')\ng_f = feature_df.nlargest(n, 'GradientBoost')\nr_f = feature_df.nlargest(n, 'RandomForest')\n\nresult = pd.concat([a_f, e_f, g_f, r_f]).drop_duplicates() \nresult.index\nresult","f74cf2bf":"# X_train_SF = X_train[result.index]\n# X_test_SF = X_test[result.index]\n\n\n\nselected_features = result['features'].values.tolist()\nX_train_SF = X_train[selected_features]\nX_test_SF = X_test[selected_features]\n\n\nx = X_train_SF#.reshape(-1, 26)  # 31\ny = y_train['attack_type'].ravel()\n\n\n# x=x[:20000]\n# y=y[:20000]\n\n\nx.shape\ny.size","616fed9f":"clf1 = DecisionTreeClassifier() \nclf2 = RandomForestClassifier(n_estimators=25, random_state=1)# .77\nclf3 = GradientBoostingClassifier() # .76\nET = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False) # .76 # without this lil fucker, Acc: 0.75 [Ensemble], 0.78 with \n\neclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),('et',ET)], voting='hard') \n# n =7 with better selection; .79\n# n =7 ; .77\n# n =10 ; .78\n# n =14 ; .77\n\nfor clf, label in zip([clf1, clf2, clf3,ET, eclf], ['DecisionTreeClassifier', 'Random Forest', 'GradientBoostingClassifier','ExtraTreesClassifier', 'Ensemble']): \n    # scores = cross_val_score(clf, x, y, cv=2, scoring='accuracy') # cv= 5 \n    # print(\"Accuracy: %0.2f (+\/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n\n    tmp = clf.fit(x,y)\n    pred = clf.score(X_test_SF,y_test)\n    print(\"Acc: %0.2f [%s]\" % (pred,label))","1ad95e64":"###### Intrusion Detection \n\n### Dataset from https:\/\/github.com\/defcom17\/NSL_KDD\/\n* [more info](https:\/\/docs.google.com\/spreadsheets\/d\/1oAx320Vo9Z6HrBrL6BcfLH6sh2zIk9EKCv2OlaMGmwY\/edit#gid=0)\n\n### Sample code used: https:\/\/www.kaggle.com\/meesterwaffles\/nicholas-brougher-neb5211-project4\n","2fc6e3da":"# Done! > 99% acc ","fc3024a1":"### 45mins wasted on numpy....","9121e223":"## Drop features with lowest STD","aa3b2739":"### The following few cells are taken from the 'sample code'","726d1616":"### Reduce train size for faster trainin, remove when in production"}}