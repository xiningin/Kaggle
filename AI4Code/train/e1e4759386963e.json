{"cell_type":{"94a05ac5":"code","ae2ce646":"code","6c74ea2d":"code","8d89d58a":"code","69866fc5":"code","f5bfb372":"code","449861b7":"code","d2735e71":"code","4e5d321f":"code","1b29bd00":"code","7e9717f2":"code","d35ca235":"code","83d94261":"code","92295247":"markdown","edc3a5db":"markdown","7a6529c4":"markdown","261a0edb":"markdown","da5533db":"markdown","be0d5692":"markdown"},"source":{"94a05ac5":"import os\nimport glob\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom sklearn.model_selection import train_test_split","ae2ce646":"image_path = list(Path('..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset').glob(r'**\/*.png'))\nimage_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], image_path))","6c74ea2d":"image_path = pd.Series(image_path, name='path').astype(str)\nimage_labels = pd.Series(image_labels, name='label')\ndf_image = pd.concat([image_path, image_labels], axis=1)\ndf_image.head()","8d89d58a":"df_image = df_image.sample(frac=1).reset_index(drop = True)\nfig, axes = plt.subplots(3, 4, figsize=(12, 7), subplot_kw={'xticks': [], 'yticks': []})\nfor idx, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_image.path[idx]))\n    ax.set_title(df_image.label[idx])\nplt.tight_layout()\nplt.show()","69866fc5":"df_image = df_image[~df_image.label.str.contains(\"GT\")]","f5bfb372":"df_image = df_image.sample(frac=1).reset_index(drop = True)\ndf_train, df_test = train_test_split(df_image, test_size=0.1, random_state=42)","449861b7":"print('Training size: {} images\\nTest size: {} images'.format(len(df_train), len(df_test)))","d2735e71":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2 # 20% of the training data will be used for validation\n)\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","4e5d321f":"train_images = train_generator.flow_from_dataframe(\n    dataframe=df_train,\n    x_col='path',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle=True,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=df_train,\n    x_col='path',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle=True,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=df_test,\n    x_col='path',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle=False\n)","1b29bd00":"input_shape=(224,224,3)\ninputs = tf.keras.layers.Input(input_shape)\n    \nbase_model = tf.keras.applications.MobileNetV2(\n        input_shape=(224, 224, 3), # the images are 224 x 224 with 3 channels (RGB)\n        weights='imagenet',\n        pooling='avg',\n        include_top=False # we discard the last layer of the original net and replace it with 2 layers defined in the following\n        )\n    \nbase_model.trainable = False # We won't re-train all the base model parameters, but just those of the layers we will add.\n    \nx = base_model(inputs)\nx = tf.keras.layers.Dense(64, activation='relu')(x) # additional hidden layer\noutputs =  tf.keras.layers.Dense(9, activation='softmax')(x) #output layer for the 9 classes\n    \n    \nmodel = tf.keras.models.Model(inputs, outputs)","7e9717f2":"model.compile(\n            optimizer='adam',\n            loss='categorical_crossentropy',\n            metrics=['accuracy']\n        )","d35ca235":"\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=5, #since it's transfer earnings we can achieve higher accuracy with less epochs\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping( # we apply earlystopping to prevent overfitting\n            monitor='val_loss',\n            patience=1, # we choose patience=1 to stop the model fit if val_loss won't decrease for an epoch\n            restore_best_weights=True # choose the best weights when early-stopping\n        )\n    ]\n)","83d94261":"plt.plot(history.history[\"loss\"], label=\"train_loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.title('Loss Plot')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.show()","92295247":"## Data preprocessing","edc3a5db":"## Notebook for better understanding :- https:\/\/www.kaggle.com\/ludovicocuoghi\/transfer-learning-with-cnns-test-acc-100\/notebook","7a6529c4":"## Importing the libraries","261a0edb":"## Plotting the loss","da5533db":"# Data Augmentation","be0d5692":"## Model Building"}}