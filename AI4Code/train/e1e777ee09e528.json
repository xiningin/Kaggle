{"cell_type":{"7fc959ca":"code","20f48123":"code","4a493c35":"code","21d84597":"code","71c10ceb":"code","0be2490e":"code","16190498":"code","2e9bbd9d":"code","ef7b7b54":"code","972f0404":"code","96392be1":"code","a0356a12":"code","3b5b2fd2":"code","63ec4db5":"code","56e714eb":"code","02c995fb":"code","c7036cad":"code","6d915b1b":"code","55420d07":"code","032d9df8":"code","c2fc1d8d":"code","2d74a96a":"code","55a859b9":"code","a302db3a":"code","a9ae4167":"code","a5cd48ca":"code","c6f8307e":"code","9fb61aa5":"code","ffc7f655":"code","0c7ab91e":"code","950d224d":"code","3e40e3bb":"code","2286197b":"code","4aa870c1":"code","0d4e9d14":"code","9244b647":"code","0e332bf1":"code","88774e23":"code","ee74d8c8":"code","faf8944b":"code","5d0a8f2c":"code","8ec32f52":"code","f13d5fd2":"code","cb5cc748":"code","cdf8514d":"code","298e256d":"code","9b81b4dd":"code","83e3e9f2":"code","5107c302":"code","c8e0caa7":"code","b33c253c":"code","53170cf5":"code","a8ee5d03":"code","bcc57ad2":"code","9afd51a9":"code","088b075a":"markdown","ce9283e6":"markdown"},"source":{"7fc959ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20f48123":"df=pd.read_csv('\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","4a493c35":"df.head()","21d84597":"# One review\ndf['review'][0]","71c10ceb":"#1\n#df=df.sample(10000)","0be2490e":"df.shape","16190498":"df.info()\n#Clearly seem that here is no missing data","2e9bbd9d":"df['sentiment'].replace({'positive': 1, 'negative': 0}, inplace= True)","ef7b7b54":"df.head()","972f0404":"#2\n# Using regex library to remove html tags\nimport re\nclean=re.compile('<.*?>')\nprint(df.iloc[2].review)\n# Test After Cleaning of one data\nre.sub(clean,'',df.iloc[2].review)","96392be1":"#Function to clean html tags\ndef clean_html(text):\n    clean=re.compile('<.*?>')\n    return re.sub(clean,'',text)","a0356a12":"df['review']=df['review'].apply(clean_html)","3b5b2fd2":"#3\n#converting everything to lower\ndef convert_lower(text):\n    return text.lower()","63ec4db5":"df['review']=df['review'].apply(convert_lower)","56e714eb":"#4\n#function to remove special characters\ndef remove_special(text):\n    x=''\n    \n    for i in text:\n        #checking is the character in the given string is alphanumeric or not\n        if i.isalnum(): \n            x+=i\n        else:\n            x+=' '\n    return x","02c995fb":"df['review']=df['review'].apply(remove_special)","c7036cad":"# 5\n# Remove the stop words\n# using natural language tool kit and stopwords class\nimport nltk \nfrom nltk.corpus import stopwords","6d915b1b":"stopwords.words('english')","55420d07":"\ndef remove_stopwords(text):\n    x=[]\n    for i in text.split():\n        if i not in stopwords.words('english'):\n            x.append(i)\n    y=x[:]\n    x.clear()\n    return y\n            ","032d9df8":"df['review']=df['review'].apply(remove_stopwords)","c2fc1d8d":"df","2d74a96a":"# 6\n# Perform stemming\nfrom nltk.stem.porter import PorterStemmer\nps=PorterStemmer()","55a859b9":"def stem_words(text):\n    y=[]\n    for i in text:\n        y.append(ps.stem(i))\n    z=y[:]\n    y.clear()\n    return z","a302db3a":"stem_words(['I','Loved','Loving','it'])","a9ae4167":"df['review']=df['review'].apply(stem_words)","a5cd48ca":"df","c6f8307e":"#join back\ndef join_back(list_input):\n    return \" \".join(list_input)","9fb61aa5":"df['review']=df['review'].apply(join_back)","ffc7f655":"df","0c7ab91e":"# Creating the input features\n# Using CountVectorizer class\nX=df.iloc[:,0:-1].values","950d224d":"X.shape","3e40e3bb":"from sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer(max_features=500)","2286197b":"X=cv.fit_transform(df['review']).toarray()","4aa870c1":"X.shape","0d4e9d14":"#taking the output\ny=df.iloc[:,-1].values","9244b647":"y.shape","0e332bf1":"# Next step: Split the data in two parts\n# X,y\n# training set\n# test set(Already know the result)","88774e23":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)","ee74d8c8":"X_train.shape","faf8944b":"X_test.shape","5d0a8f2c":"y_train.shape","8ec32f52":"y_test.shape","f13d5fd2":"from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\nclf1=GaussianNB()\nclf2=MultinomialNB()\nclf3=BernoulliNB()","cb5cc748":"clf1.fit(X_train,y_train)\nclf2.fit(X_train,y_train)\nclf3.fit(X_train,y_train)","cdf8514d":"y_pred1=clf1.predict(X_test)\ny_pred2=clf2.predict(X_test)\ny_pred3=clf3.predict(X_test)","298e256d":"y_pred3.shape","9b81b4dd":"y_test.shape","83e3e9f2":"from sklearn.metrics import accuracy_score","5107c302":"print('Gaussian:',accuracy_score(y_test,y_pred1)*100,'%')\nprint('Multinomial:',accuracy_score(y_test,y_pred2)*100,'%')\nprint('Bernoulli:',accuracy_score(y_test,y_pred3)*100,'%')","c8e0caa7":"#Calculating accurary of GaussianNB manually\nprint(np.sum(y_test==y_pred1)\/y_pred1.shape[0]*100)","b33c253c":"#Visualizing the reviews\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud","53170cf5":"# All positive reviews\nnorm_text_pos=\"\"\nfor i in range(0,df.shape[0]):\n    if(df.iloc[i].sentiment==1):\n        norm_text_pos+=df.iloc[i].review\nlen(norm_text_pos)","a8ee5d03":"#word cloud for positive review words\nplt.figure(figsize=(10,10))\npositive_text=norm_text_pos\nWC=WordCloud(width=1000,height=500,max_words=500,min_font_size=5)\npositive_words=WC.generate(positive_text)\nplt.imshow(positive_words,interpolation='bilinear')\nplt.show()","bcc57ad2":"# All negative reviews\nnorm_text_neg=\"\"\nfor i in range(0,df.shape[0]):\n    if(df.iloc[i].sentiment==0):\n        norm_text_neg+=df.iloc[i].review\nlen(norm_text_neg)","9afd51a9":"#Word cloud for negative review words\nplt.figure(figsize=(10,10))\nnegative_text=norm_text_neg\nWC=WordCloud(width=1000,height=500,max_words=500,min_font_size=5)\nnegative_words=WC.generate(negative_text)\nplt.imshow(negative_words,interpolation='bilinear')\nplt.show()","088b075a":"## Conclusion:\n\n### 1. We can observed that both Bernoulli naive bayes and Multinomial naive bayes model performing well compared to Gaussian naive bayes.\n\n### 2. We can also use other different classification algorithms to see which one predicts best.","ce9283e6":"# **Text Cleaning**\n\n1. Sample 10,000 rows\n2. Remove html tags\n3. Converting every thing to lower case\n4. Remove special characters\n5. Removing Stop words\n6. Stemming"}}