{"cell_type":{"8ac295e0":"code","0ed2a85f":"code","44edf884":"code","0d4ca16d":"code","2300374d":"code","6bf5c7a4":"code","55048fce":"code","ab4cc9ab":"code","9382cb12":"code","9ce8fc9b":"code","fbfb6d1e":"code","0d9af937":"code","4eea2f03":"code","c3fb1dcb":"code","bac6ded5":"code","c63a0a2a":"code","c593940d":"code","a738d2e2":"code","b0a8c1c8":"code","e898a7a4":"code","63e1b42e":"code","334fb788":"code","03620a3c":"code","eb167992":"code","b2df0541":"code","8ff279f1":"code","5b71e14b":"code","05e7de0d":"markdown"},"source":{"8ac295e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ed2a85f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nimport cv2\n\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2\nfrom keras import regularizers\nfrom tensorflow.keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')","44edf884":"train_dir = '..\/input\/fer2013\/train\/'\ntest_dir = '..\/input\/fer2013\/test\/' #passing the path with testing images","0d4ca16d":"row, col = 48, 48\nclasses = 7\n\n#make a count of the different classes\ndef count_exp(path, set_):\n    dict_ = {}\n    for expression in os.listdir(path):\n        dir_ = path + expression\n        dict_[expression] = len(os.listdir(dir_))\n    df = pd.DataFrame(dict_, index=[set_])\n    return df\ntrain_count = count_exp(train_dir, 'train')\ntest_count = count_exp(test_dir, 'test')\nprint(train_count)\nprint(test_count)","2300374d":"#define a function to plot some images from different classes\n\ndef plot_images(img_dir, top=10):\n    all_img_dirs = os.listdir(img_dir)\n    img_files = [os.path.join(img_dir, file) for file in all_img_dirs][:5]\n  \n    plt.figure(figsize=(10, 10))\n  \n    for idx, img_path in enumerate(img_files):\n        plt.subplot(5, 5, idx+1)\n    \n        img = plt.imread(img_path)\n        plt.tight_layout()         \n        plt.imshow(img, cmap='Blues_r') ","6bf5c7a4":"#angry class\nplot_images(train_dir+'\/angry')","55048fce":"#disgust class\nplot_images(train_dir+'\/disgust')","ab4cc9ab":"#fear class\nplot_images(train_dir+'\/fear')","9382cb12":"#happy class\nplot_images(train_dir+'\/happy')","9ce8fc9b":"#neutral class\nplot_images(train_dir+'\/neutral')","fbfb6d1e":"#sad class\nplot_images(train_dir+'\/sad')","0d9af937":"#surprise class\nplot_images(train_dir+'\/surprise')","4eea2f03":"#plot some from the test set\n\n\nplt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(train_dir):\n    img = load_img((test_dir + expression +'\/'+ os.listdir(test_dir + expression)[1]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()","c3fb1dcb":"\"\"\"\nData Augmentation\n--------------------------\nrotation_range = rotates the image with the amount of degrees we provide\nwidth_shift_range = shifts the image randomly to the right or left along the width of the image\nheight_shift range = shifts image randomly to up or below along the height of the image\nhorizontal_flip = flips the image horizontally\nrescale = to scale down the pizel values in our image between 0 and 1\nzoom_range = applies random zoom to our object\nvalidation_split = reserves some images to be used for validation purpose\n\"\"\"\n\ntrain_datagen = ImageDataGenerator(#rotation_range = 180,\n                                         width_shift_range = 0.1,\n                                         height_shift_range = 0.1,\n                                         horizontal_flip = True,\n                                         rescale = 1.\/255,\n                                         zoom_range = 0.2,\n                                         validation_split = 0.2\n                                        )\ntest_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                         validation_split = 0.2)","bac6ded5":"\"\"\"\nApplying data augmentation to the images as we read \nthem from their respectivve directories\n\"\"\"\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (48,48),\n                                                    batch_size = 32,\n                                                    color_mode ='rgb',\n                                                    class_mode = \"categorical\"\n                                                   )\ntest_generator = test_datagen.flow_from_directory( directory = test_dir,\n                                                              target_size = (48,48),\n                                                              batch_size = 32,\n                                                               color_mode ='rgb',\n                                                              class_mode = \"categorical\"\n                                                             )","c63a0a2a":"#using pretrained model, RESNET50 architecture\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\nbase_model = ResNet50(input_shape=(48,48,3),include_top = False, weights = 'imagenet')\n\n\nbase_model.summary()","c593940d":"# Freezing layers \nfor layer in base_model.layers[:-4]:\n    layer.trainable = False","a738d2e2":"# Build model on the top of base model\nmodel = Sequential()\n\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\n\n#add fully connected layers\nmodel.add(Dense(512,activation ='relu', kernel_regularizer = tf.keras.regularizers.l2(0.01)))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(rate = 0.2))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(7, activation='softmax')) #output layer","b0a8c1c8":"# model Summary\nmodel.summary()","e898a7a4":"#import modules that will wnable early stopping for optimization during model training\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping\nfrom datetime import datetime\n\n#tensorboard\nlogdir = \"logs\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = TensorBoard(log_dir=logdir)\n\n#define the early stopping\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)","63e1b42e":"# compile model\nmodel.compile(optimizer='adam', # optimize the model with adam optimizer\n              loss=\"categorical_crossentropy\", #for svm classification\n              metrics=['accuracy']) #to get accuracy of the model in each run","334fb788":"#fit the model on train data and add val data fro validation\nhistory = model.fit(train_generator,\n    batch_size = 32,\n    verbose = 1, # Suppress chatty output; use Tensorboard instead\n    epochs = 50, #add the validation set to evaluate the performance in each run\n    validation_data = test_generator\n)","03620a3c":"acc = history.history['accuracy'] # get history report of the model\n\nval_acc = history.history['val_accuracy'] # get history of the validation set\n\nloss = history.history['loss'] #get the history of the lossses recorded on the train set\nval_loss = history.history['val_loss'] #get the history of the lossses recorded on the validation set\n\nplt.figure(figsize=(8, 8)) # set figure size for the plot generated\n\n\nplt.plot(acc, label='Training Accuracy') #plot accuracy curve for each train run\nplt.plot(val_acc, label='Validation Accuracy') #plot accuracy curve for each validation run\n\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy') #label name for y axis\nplt.ylim([min(plt.ylim()),0.9]) #set limit for y axis\nplt.title('Training and Validation Accuracy') #set title for the plot","eb167992":"# Unfreeze the base model\nbase_model.trainable = True\n\n# It's important to recompile your model after you make any changes\n# to the `trainable` attribute of any inner layer, so that your changes\n# are take into account\nmodel.compile(optimizer= Adam(1e-5),  # Very low learning rate\n              loss=\"categorical_crossentropy\", #for svm classification\n              metrics=['accuracy'])\n\n# Train end-to-end. Be careful to stop before you overfit!\nhistory1 = model.fit(train_generator,\n    batch_size = 32,\n    verbose = 1, # Suppress chatty output; use Tensorboard instead\n    epochs = 25, #add the validation set to evaluate the performance in each run\n    callbacks = [tensorboard_callback, es],\n    validation_data = test_generator\n)","b2df0541":"acc = history1.history['accuracy'] # get history report of the model\n\nval_acc = history1.history['val_accuracy'] # get history of the validation set\n\nloss = history1.history['loss'] #get the history of the lossses recorded on the train set\nval_loss = history1.history['val_loss'] #get the history of the lossses recorded on the validation set\n\nplt.figure(figsize=(8, 8)) # set figure size for the plot generated\n\n\nplt.plot(acc, label='Training Accuracy') #plot accuracy curve for each train run\nplt.plot(val_acc, label='Validation Accuracy') #plot accuracy curve for each validation run\n\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy') #label name for y axis\nplt.ylim([min(plt.ylim()),0.9]) #set limit for y axis\nplt.title('Training and Validation Accuracy') #set title for the plot","8ff279f1":"test_img = image.load_img('..\/input\/fer2013\/test\/surprise\/PrivateTest_11501834.jpg',target_size = (48,48))\nplt.imshow(test_img)","5b71e14b":"label_dict = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\n\ntest_img = np.expand_dims(test_img,axis = 0)\ntest_img = test_img.reshape(1,48, 48,3)\nresult = model.predict(test_img)\nresult = list(result[0])\n\nimg_index = result.index(max(result))\nprint(label_dict[img_index])","05e7de0d":"### Fine tuning"}}