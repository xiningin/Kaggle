{"cell_type":{"6197a835":"code","846cb977":"code","edd3cbe3":"code","9c603de2":"code","85afc4d1":"code","5180040c":"code","a7a67197":"code","5c92684d":"markdown"},"source":{"6197a835":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","846cb977":"import time\nimport pandas as pd\nimport os,shutil,math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,roc_curve,auc\n\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom glob import glob\n\n\nfrom IPython.display import SVG\n\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.applications.vgg19 import VGG19,preprocess_input\nfrom keras.applications.xception import Xception\nfrom keras.applications.nasnet import NASNetMobile\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,BatchNormalization,Activation\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.callbacks import EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau, ModelCheckpoint\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input, decode_predictions","edd3cbe3":"train_data_dir = '..\/input\/flowers\/flowers'\nimg_width, img_height = 299, 299 \nbatch_size = 32\n# Bilder haben unterschiedliche Dimensionen.","9c603de2":"\nimage_datagen = ImageDataGenerator(\n    rescale=1.\/255, \n    vertical_flip = True,\n    horizontal_flip = True,\n    rotation_range=20,\n    shear_range=0.05,\n    zoom_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=0.2\n    #channel_shift_range=0.1\n)\ntrain_gen = image_datagen.flow_from_directory(\n        train_data_dir, \n        target_size=(img_height, img_width), \n        batch_size=batch_size, \n        class_mode=\"categorical\", \n        subset=\"training\")\nvalid_gen = image_datagen.flow_from_directory(\n        train_data_dir, \n        target_size=(img_height, img_width), \n        batch_size=batch_size, \n        class_mode=\"categorical\", \n        subset=\"validation\")","85afc4d1":"# In the summary above of our base model, trainable params is 2,565\n\n# Callbacks\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=10,\n    verbose=1,\n    mode='auto' \n)\ncsvlogger = CSVLogger( \n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\nreduce = ReduceLROnPlateau( \n    monitor='val_loss',\n    factor=0.1, \n    patience=3, #kac epoch iyilesmezse learning rate d\u00fcss\u00fcn\n    verbose=1, \n    mode='auto',\n)    \n","5180040c":"\n# Hyperparameters\nsecond_dense_512 = [0, 1]\ndropout = [0, 1]\n\nbase_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\nprint('Loaded model!')","a7a67197":"\n# Freeze the layers in base_model \nfor layer in base_model.layers:\n    layer.trainable = False \n        \nfor dense2 in second_dense_512:\n    for drop in dropout:\n        \n        NAME = \"flowers-inception-dense{}-drop{}-{}\".format(dense2, drop, int(time.time()))\n        print(NAME)\n        logdir = \"logs\/flowers-inception\/{}\/\".format(NAME)\n        \n        # Callbacks\n        checkpoint = ModelCheckpoint(\n            '{}base.model'.format(logdir),\n            monitor='val_loss',\n            mode='min',\n            save_weights_only=True,\n            save_best_only = True,\n            verbose = 1)\n        tensorboard = TensorBoard(\n            log_dir = logdir,\n            histogram_freq=0,\n            batch_size=batch_size,\n            write_graph=True,\n            write_grads=True,\n            write_images=False,\n        )\n\n        x = base_model.output\n        x = GlobalAveragePooling2D()(x)\n        x = Dense(1024)(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        if drop == 1 : x = Dropout(0.3)(x)\n        if dense2 == 1 : \n            x = Dense(512)(x)\n            x = BatchNormalization()(x)\n            x = Activation(\"relu\")(x)\n            if drop == 1 : x = Dropout(0.3)(x)\n        \n        predictions = Dense(5, activation='softmax')(x)\n        \n        model = Model(base_model.input, predictions)\n        \n        \n        model.compile(loss='categorical_crossentropy',\n                      optimizer='Adam',\n                      metrics=['accuracy'])\n        \n        # Take a look at layers of model\n        '''\n        pd.set_option('max_colwidth', -1)\n        layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n        print(pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) )\n        '''\n    \n        history = model.fit_generator(\n            train_gen,\n            steps_per_epoch = train_gen.n \/\/ train_gen.batch_size, #normalde len(X_train) \/ batch_size,\n            epochs= 100,\n            validation_data = valid_gen,\n            validation_steps=valid_gen.n \/\/ valid_gen.batch_size, # normalde len(X_valid) \/ batch_size,\n            verbose=1,\n            callbacks=[checkpoint,tensorboard,csvlogger,reduce,earlystop])\n       \n        \n\n'''\nmodel.load_weights(best_model_finetuned_path)  \n   \n(eval_loss, eval_accuracy) = model.evaluate(  \n     X_test, y_test, batch_size=batch_size, verbose=1)\n\nprint(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100))  \nprint(\"Loss: {}\".format(eval_loss)) \n'''\n","5c92684d":"Inception V3"}}