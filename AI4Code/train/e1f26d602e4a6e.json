{"cell_type":{"ed88c54e":"code","1c155073":"code","472c7774":"code","a2580c56":"code","efe9f2f9":"code","1726e1a5":"code","c81e99d3":"code","7d497dd3":"code","540c270e":"code","289e26bc":"code","6198b1cd":"code","4c4013c2":"code","60c6be4a":"code","9f0561c9":"code","fe4251b0":"code","532933ef":"code","86159763":"code","22140189":"markdown","8900c03b":"markdown","92d9d936":"markdown","2ce6a6c7":"markdown","e5588f0b":"markdown","cc631a9b":"markdown","ee144e4d":"markdown","562eff76":"markdown","f5ad0a09":"markdown","0f6e7f43":"markdown","31caf0f9":"markdown","51a403e6":"markdown","158f288a":"markdown","497d591c":"markdown","237b0bf2":"markdown","6eddcff6":"markdown","ce6b5208":"markdown","8fc802b8":"markdown","d6c32815":"markdown","39517d6e":"markdown","ad8cde3a":"markdown","adaeb69f":"markdown","5df473c7":"markdown","83ee2f46":"markdown"},"source":{"ed88c54e":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\n\nimport scipy.stats as stats\nimport statsmodels.api as sm\nfrom statsmodels.stats.proportion import proportions_ztest\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\n%matplotlib inline","1c155073":"# Read the data\npath ='..\/input\/ad-ab-testing\/AdSmartABdata - AdSmartABdata.csv'\n\ndf = pd.read_csv(path)","472c7774":"# Set up the format and styles for plots globally\nsns.set_style('white')\nplt.rc('axes', titlesize=13)\nplt.rc('axes', labelsize=12)\nplt.rc('xtick', labelsize=11)\nplt.rc('ytick', labelsize=11)\nplt.rc('legend', fontsize=11)\nplt.rc('font', size=10)","a2580c56":"df.head(10)","efe9f2f9":"df.info()","1726e1a5":"# Check for duplicates\nif df.iloc[: ,0].nunique() == df.shape[0]:\n    print('There are no duplicates in the dataset')\nelse:\n    print('There are some duplicates in the dataset')\n\nif df.isnull().sum().sum() == 0:\n    print('There are no null values')\nelse:\n    print('There are some null values')\n","c81e99d3":"# Filter out users that were not interacting\nrelevant_rows = df.query('yes == 1 | no == 1')\n\n# Divide a dataframe by exposed and control group\nexposed = relevant_rows.query('experiment == \"exposed\"')\ncontrol = relevant_rows.query('experiment == \"control\"')\n\n# Calculate a number of observation in both groups\nprint('The exposed group dataframe has {} observations'. format(exposed.shape[0]))\nprint('The control group dataframe has {} observations'. format(control.shape[0]))\n\ncontr_d1 = '{0:.2f}%'.format(exposed.yes.mean()*100)\ntrtm_d1 = '{0:.2f}%'.format(control.yes.mean()*100)\nprint('The conversion rate in the exposed group is equal to {}'.format(contr_d1))\nprint('The conversion rate in the exposed group is equal to {}'.format(trtm_d1))","7d497dd3":"obs_diff = exposed.yes.mean() - control.yes.mean()\nobs_diff_form = '{0:.2f}%'.format(obs_diff*100)\nprint('The observed difference in the conversion rate between the exposed and the control group is {}'.format(obs_diff_form))","540c270e":"exposed_converted = exposed.query('yes == 1')\ncontrol_converted = control.query('yes == 1')\nprint('The sample sizes of the exposed group and control group are {} and {} respectively'.format(exposed.shape[0], control.shape[0]))\nprint('The number of conversions in the exposed group and control group is {} and {} respectively'.format(exposed_converted.shape[0],\n                                                                                          control_converted.shape[0]))","289e26bc":"#storing number of conversions for exposed and control groups as numpy arrays\ncount = np.array([exposed_converted.shape[0], control_converted.shape[0]])\n#storing sample sizes of exposed and control group as numpy arrays\nnobs = np.array([exposed.shape[0], control.shape[0]])\n#storing results of z test in variables\nstat, p_val = proportions_ztest(count, nobs, alternative = 'larger')\np_form = '{0:.2f}%'.format(p_val*100)\nprint('P-value is equal to {}'.format(p_form))","6198b1cd":"# Draw 100000 samples from binominal distribution\nexposed_simulation = np.random.binomial(exposed.shape[0], exposed.yes.mean(), 100000)\/exposed.shape[0]\ncontrol_simulation = np.random.binomial(control.shape[0], control.yes.mean(), 100000)\/control.shape[0]\np_diffs = exposed_simulation - control_simulation\ndiffs = np.array(p_diffs)\n\n#Creation of normal distribution centered at zero\nnull_vals = np.random.normal(0, np.std(diffs), len(diffs))","4c4013c2":"def statplot(data, lim, obs_stat, title):\n    \"\"\"\n    This function creates a plot, that represents sampling distribution. \n    This plot is formatted and has main statistics on it\n    Arguments:\n    data = array\n    lim = height of the plot\n    obs_stat = observed statistic\n    title = chart title\n    \"\"\"\n    \n    #Create a kdeplot\n    plt.figure(figsize=(12,4), tight_layout=True)\n    ax = sns.kdeplot(data, linewidth = 0.8, color = 'black')\n    \n    # Simple formatting\n    frame = ['right', 'left', 'top']\n    for i in frame:\n        ax.spines[i].set_visible(False)\n\n    plt.title(title)\n    plt.ylabel('')\n    plt.yticks([], [])\n    \n    # Legend\n    line = Line2D([0], [0], color='red', linestyle = '-', label='observed statistic')\n    line_dashed = Line2D([0], [0], color='black', linestyle = '--', label='mean and standard deviation')\n    plt.legend(handles=[line, line_dashed], loc='upper left');\n    \n    # Create a list of 3 standard deviation to the left and to the right and mean\n    std_list = []\n    std_list_format = []\n    for i in range(-3,4):\n        std_dev = np.std(data) * i + np.mean(data)\n        std_list.append(std_dev)\n        std_list_format.append('{0:.3f}'.format(std_dev) + '\\n {} std'.format(i))\n        \n    # Create a list of corresponding y values\n    data_x, data_y = ax.lines[0].get_data()\n    height = []\n    for i in std_list:\n        height.append(np.interp(i, data_x, data_y))\n        \n    # Plotting vertical lines representing std deviations \n    for a, b in zip(std_list, height):\n        plt.axvline(a, 0, b\/lim, color = 'black', alpha = 1, linewidth = 0.8, linestyle = '--')\n        plt.plot(a, b, marker = 'o', color = 'blue')\n    \n    # Plotting observed statistic\n    obs_line_height = np.interp(obs_stat, data_x, data_y)\n    plt.axvline(obs_stat, 0, obs_line_height\/lim, color = 'red', alpha = 1, linewidth = 0.8, linestyle = '-')\n    plt.plot(obs_stat, obs_line_height, marker = 'o', color = 'red')\n            \n    # Plotting x ticks\n    x_ticks = std_list\n    x_labels = std_list_format\n    plt.xticks(x_ticks, x_labels)\n    plt.ylim(0,lim)","60c6be4a":"def shading(data, left, right, color):\n    \n    \"\"\"\n    This function shades areas of the kde plot.\n    Arguments:\n    data = array\n    left = left boundary of the area to be shaded\n    right = right boundary of the area to be shaded\n    color = color\n    \"\"\"\n    \n    #Shading areas\n    kde = stats.gaussian_kde(data)\n    shade = np.linspace(left, right, 100)\n    plt.fill_between(shade, kde(shade), color = color, alpha = 0.5);","9f0561c9":"# Plotting the sampling distribution\nstatplot(null_vals, 15, obs_diff, 'Sampling Distribution of the difference in sample proportions under the null hypothesis')\nshading(null_vals, obs_diff, null_vals.max(),'#aaffb5')\nshading(null_vals, null_vals.min(), obs_diff,'#cceefb')\nplt.text(0.075, 12, \"P-value = {}\".format(p_form), color = 'black', size = 15);","fe4251b0":"# Calculate z statistic\nzscore = stats.norm.ppf(1 - .05)\n\n# Calculate mean proportion for exposed group\np1 = exposed.yes.mean()\n# Calculate mean proportion for control group\np2 = control.yes.mean()\n# Calculate distance from the mean\ndistance_from_mean = ((p1*(1-p1)\/exposed.yes.shape[0]) + (p2*(1-p2)\/control.yes.shape[0])) ** 0.5 * zscore\n\n# Lower boarder of the interval\nlow = obs_diff - distance_from_mean\n# Higher boarder of the interval\nhigh = obs_diff + distance_from_mean\n\nprint('The 90% confidence interval falls between {} and {}.'.format(low, high))","532933ef":"# Plotting the confidence interval\nstatplot(diffs, 15, np.mean(null_vals), '90% confidence interval')\nshading(diffs, diffs.min(), low, '#aaffb5')\nshading(diffs, low, high, '#cceefb')\nshading(diffs, high, diffs.max(), '#aaffb5')","86159763":"# Create dummy variables for experiment variable\nrelevant_rows[['control', 'exposed']] = pd.get_dummies(relevant_rows.loc[:, 'experiment'])\nrelevant_rows = relevant_rows.drop(['control'], axis = 1)\n# Add intercept\nrelevant_rows['intercept'] = 1\n\n#set up logistic regression model\nlogit_mod = sm.Logit(relevant_rows['yes'], relevant_rows[['intercept', 'exposed']])\n#fitting logistic regression model\nresults = logit_mod.fit()\n#display summary results\nresults.summary()","22140189":"We can see here that our null hypothesis falls within the confidence interval. We can expect that 90% of confidence intervals would overlap with zero. Under the null hypothesis, our true difference in proportions is zero. Therefore, the P-value is higher than the significance level of 10%. (for the one-tailed test it would be 5%). Therefore, I do not have enough evidence to reject the null and suggest the alternative hypothesis.","8900c03b":"<a id='Table'><\/a>\n# <center> Three ways of doing A\/B Tests","92d9d936":"<a id='Dataset'><\/a>\n## Reading the dataset\n[to the top](#Table)","2ce6a6c7":"Here I will be formulating a null and an alternative hypothesis. The null hypothesis will state that there are no changes in conversion either with the new creative ad or with the dummy ad. The alternative hypothesis is what we wanted to confirm, ie the conversion rate is higher with the new creative ad than with the dummy one. \n\n$$Null\\ (H_0) \\ and \\ Alternative \\ (H_1) \\ Hypothesis$$  \n\n$$H_0: \\ Y_{new} - \\ Y_{old} = 0$$\n\n\n$$H_1: \\ Y_{new} - \\ Y_{old} > 0$$    \n  \nAhead of time, we need to set up the level of significance for the A\/B test. Let's say our alpha is 5%. That means we will reject the null hypothesis only when the probability of observing the difference in sample proportion given the null hypothesis is true is less than 5%. Since I am curious whether the new creative ad facilitates a better conversion rate, I will be using a one-tailed hypothesis test","e5588f0b":"<a id='Preprocessing'><\/a>\n## Data preprocessing\n[to the top](#Table)","cc631a9b":"The plot above is the sampling distribution of the difference in sample proportions under the null hypothesis. The observed difference in conversion rates falls between the mean and the first standard deviation. The area shaded in green starts with the observed difference in conversion rate and goes up to the right end, which represents differences more extreme than the observed. The probability that the observed difference falls into the sampling distribution of the null hypothesis is equal to 25.92%. Given that our level of significance is 5%, we fail to reject the null hypothesis, ie we do not have enough evidence to conclude that the conversion rate with the new creative ad is higher than with the dummy one.","ee144e4d":"<a id='Introduction'><\/a>\n## Introduction\n[to the top](#Table)","562eff76":"In logistic regression significance of a variable can be described by the P-value. If the P-value is high, then the variable is not significant and wise versa. Here, the P-value is 51.9%. Since logistic regression assumes that the test is two-sided and I conduct my test as one-sided, I will divide the P-value by 2 which will give me approx. 26%. Since 26% is higher than the level of significance, I fail to reject the null hypothesis in favor of the alternative.","f5ad0a09":"<a id='Assessment'><\/a>\n## Data assessment\n[to the top](#Table)","0f6e7f43":"A\/B test can be conducted using confidence intervals. Hypothesis testing using confidence intervals assumes that a two-tailed hypothesis test is conducted. However, according to my alternative hypothesis where I want to prove that the conversion rate with the new creative ad is better than with the dummy ad, we want to conduct a one-tailed hypothesis test. Therefore, I will multiply my significance level by two, which will give me 5% x 2 = 10%. Thus I want to prove that mean from the hull hypothesis falls outside of the sampling distribution of the difference in sample proportion under the alternative hypothesis with a 90% confidence.","31caf0f9":"## Table of contents\n- [Introduction](#Introduction)  \n- [Import packages](#Packages)\n- [Description of variables](#Variables)\n- [Reading the dataset](#Dataset)\n- [Data assessment](#Assessment)\n- [Data preprocessing](#Preprocessing)\n- [Formulation of Null and Alternative Hypothesis](#Formulation)\n- [Sampling distribution under the null](#Sampling)  \n- [Confidence intervals](#Intervals)\n- [Logistic Regression](#Logistic)\n- [Conclusions](#Conclusions)","51a403e6":"<a id='Variables'><\/a>\n## Description of variables\n[to the top](#Table)\n\n\n| VariableName | Description |\n|:--|:--|\n| auction_id |the unique id of the online user who has been presented the BIO. In standard terminologies this is called an impression id. The user may see the BIO questionnaire but choose not to respond. In that case both the yes and no columns are zero. |\n| experiment |which group the user belongs to - control or exposed. Control: users who have been shown a dummy ad. Exposed: users who have been shown a creative, an online interactive ad, with the SmartAd brand. |\n| date |the date in YYYY-MM-DD format |\n| hour |the hour of the day in HH format |\n| device_make |the name of the type of device the user has e.g. Samsung |\n| platform_os |the id of the OS the user has. |\n| browser |the name of the browser the user uses to see the BIO questionnaire. |\n| yes |1 if the user chooses the \u201cYes\u201d radio button for the BIO questionnaire. |\n| no |1 if the user chooses the \u201cNo\u201d radio button for the BIO questionnaire. |","158f288a":"<a id='Logistic'><\/a>\n## Logistic Regression\n[to the top](#Table)","497d591c":"In this notebook, I conducted A\/B tests in three different ways. All versions suggest that the P-value is greater than the significance level and we do not have enough evidence to reject the null hypothesis.","237b0bf2":"<a id='Packages'><\/a>\n## Import packages\n[to the top](#Table)","6eddcff6":"In this activity, I will be interested in a conversion rate. I will filter out the impressions where users neither clicked the *yes* button nor the *no* button. In other words, I will be doing multiple A\/B tests to figure out whether the conversion rate with a new creative ad is higher than with a dummy ad.","ce6b5208":"I am sure that there are more ways of doing A\/B tests. I will investigate this topic further in the future. As for now, that is all. Thank you for reading this notebook :)","8fc802b8":"<a id='Sampling'><\/a>\n## Sampling distribution under the null\n[to the top](#Table)","d6c32815":"<center><img src=\"https:\/\/cdn.technologyadvice.com\/wp-content\/uploads\/2015\/02\/compare-crms-like-a-pro-01-700x400.png\">","39517d6e":"<a id='Intervals'><\/a>\n## Confidence intervals\n[to the top](#Table)","ad8cde3a":"<a id='Conclusions'><\/a>\n## Conclusions\n[to the top](#Table)","adaeb69f":"In this notebook, I will conduct A\/B tests in three different ways.  \n- Sampling distribution under the null hypothesis  \n- Confidence intervals  \n- Logistic Regression","5df473c7":"Another way of conducting A\/B test is to use the logistic regression to calculate P-value to see if there is a significant difference in conversion based on which ad a user receives","83ee2f46":"<a id='Formulation'><\/a>\n## Formulation of Null and Alternative Hypothesis\n[to the top](#Table)"}}