{"cell_type":{"b15197de":"code","a4ff9094":"code","e721d57e":"code","516092fd":"code","fee58e97":"code","0c89c866":"code","4f463d42":"code","7ad900e6":"code","05a6ecc5":"code","1202587f":"code","051e6481":"markdown"},"source":{"b15197de":"%%writefile submission.py\nimport pickle\nimport bz2\nimport base64\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport time\nimport functools, collections\nfrom copy import deepcopy\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Action, translate\nfrom kaggle_environments.helpers import histogram\n\nsigmoid = lambda x: 1 \/ (1 + np.exp(-x))\neps = 10**(-6)\nDEBUG = True","a4ff9094":"%%writefile -a submission.py\n# The model\u2019s parameters from https:\/\/www.kaggle.com\/yuricat\/smart-geese-trained-by-reinforcement-learning\nPARAM = b'XXXXX'\nPARAM_SELF = b'YYYYY'","e721d57e":"%%writefile -a submission.py\nclass MCTS():\n    def __init__(self, game, nn_agent_self, nn_agent_pubhrl, eps=1e-8, cpuct_self=1.0, cpuct_other=1.0):\n        self.game = game\n        self.nn_agent_self = nn_agent_self\n        self.nn_agent_pubhrl = nn_agent_pubhrl\n        self.eps = eps\n        self.cpuct_self = cpuct_self\n        self.cpuct_other = cpuct_other\n        \n        self.Qsa = {}  # stores Q values for s,a (as defined in the paper)\n        self.Nsa = {}  # stores #times edge s,a was visited\n        self.Ns = {}  # stores #times board s was visited\n        self.Ps = {}  # stores initial policy (returned by neural net)\n        self.Pm = {}  # masked initial policy (returned by neural net times masking)\n\n        self.Vs = {}  # stores game.getValidMoves for board s\n        \n        self.last_obs = None\n\n    def getActionProb(self, obs, timelimit=1.0):\n        extra_time = obs.remainingOverageTime\n        obs_step = obs.step\n        remaining_steps = 220 - obs.step\n        print(obs)\n        print(len(obs.geese[obs.index]), [len(goose) for goose in obs.geese])\n        \n        s = self.game.stringRepresentation(obs)\n        i = obs.index\n\n        start_time = time.time()\n        while time.time() - start_time < timelimit + extra_time\/(remaining_steps\/4):\n            self.search(obs, self.last_obs)\n\n            counts = [\n                self.Nsa[(s, i, a)] if (s, i, a) in self.Nsa else 0\n                for a in range(self.game.getActionSize())\n            ]\n            prob = counts \/ (np.sum(counts)+eps)\n            \n            target_prob = max(self.Ps[s, i])\n            if time.time() - start_time > timelimit and (extra_time < 10 or max(prob) >= target_prob):\n                break\n                        \n        self.last_obs = obs\n        \n        a = np.argmax(prob)\n        \n        if DEBUG:\n            print(s,i,a)\n            print(len(self.Qsa), len(self.Nsa), len(self.Ns), len(self.Ps), len(self.Vs))\n            print(\"self.Qsa\", self.Qsa[s,i,a])\n            print(\"self.Nsa\", self.Nsa[s,i,a])\n            print(\"self.Ns\",  self.Ns[s])\n            print(\"self.Ps\",  \" \".join(f\"{x:.4f}\" for x in self.Ps[s,i]))\n            print(\"self.Vs\",  self.Vs[s,i])\n            print(\"prob   \",  \" \".join(f\"{x:.4f}\" for x in prob))\n            print()\n        \n        return prob\n\n    def search(self, obs, last_obs, prev_v=0):\n        s = self.game.stringRepresentation(obs)\n        \n        if obs.step >= 200:\n            lengths = sorted(len(goose) for goose in obs.geese)[::-1]\n            position = lengths.index(len(obs.geese[obs.index]))\n            scores = {0:1, 1:0.5, 2:-0.5, 3:-1}\n            return [scores[position]]*4\n\n        if s not in self.Ns:\n            values = [-10] * 4\n            for i in range(4):\n                if len(obs.geese[i]) == 0:\n                    continue\n                    \n                valids = self.game.getValidMoves(obs, last_obs, i)\n                # leaf node\n                if sum(v == 0 for v in valids) >= 3:\n                    self.Ps[(s, i)], values[i] = valids, prev_v\n                elif obs.step >= 192:  # random rollouts\n                    self.Ps[(s, i)], values[i] = [0.25, 0.25, 0.25, 0.25], prev_v\n                elif i == obs.index:\n                    self.Ps[(s, i)], values[i] = self.nn_agent_self.predict(obs, last_obs, i)\n                else:\n                    self.Ps[(s, i)], values[i] = self.nn_agent_pubhrl.predict(obs, last_obs, i)                    \n                \n                self.Pm[s, i] = (valids + self.Ps[s, i]) * valids  # masking invalid moves\n                sum_Ps_s = np.sum(self.Pm[s, i])\n                if sum_Ps_s > 0:\n                    self.Pm[(s, i)] \/= sum_Ps_s  # renormalize\n\n                self.Vs[(s, i)] = valids\n                self.Ns[s] = 0\n            return values\n\n        best_acts = [None] * 4\n        for i in range(4):\n            if len(obs.geese[i]) == 0:\n                continue\n            \n            valids = self.Vs[(s, i)]\n            cur_best = -float('inf')\n            best_act = self.game.actions[-1]\n\n            # pick the action with the highest upper confidence bound\n            for a in range(self.game.getActionSize()):\n                if i == obs.index:\n                    cpuct = self.cpuct_self\n                else:\n                    cpuct = self.cpuct_other\n                if valids[a]:\n                    if (s, i, a) in self.Qsa:\n                        u = self.Qsa[(s, i, a)] + cpuct * self.Ps[(s, i)][a] * math.sqrt(\n                                self.Ns[s]) \/ (1 + self.Nsa[(s, i, a)])\n                    else:\n                        u = cpuct * self.Ps[(s, i)][a] * math.sqrt(\n                            self.Ns[s] + self.eps)  # Q = 0 ?\n\n                    if u > cur_best:\n                        cur_best = u\n                        best_act = self.game.actions[a]\n                        \n            best_acts[i] = best_act\n        \n        next_obs = self.game.getNextState(obs, last_obs, best_acts)\n        values = self.search(next_obs, obs)\n\n        for i in range(4):\n            if len(obs.geese[i]) == 0:\n                continue\n                \n            a = self.game.actions.index(best_acts[i])\n            v = values[i]\n            if (s, i, a) in self.Qsa:\n                self.Qsa[(s, i, a)] = (self.Nsa[(s, i, a)] * self.Qsa[\n                    (s, i, a)] + v) \/ (self.Nsa[(s, i, a)] + 1)\n                self.Nsa[(s, i, a)] += 1\n\n            else:\n                self.Qsa[(s, i, a)] = v\n                self.Nsa[(s, i, a)] = 1 + sigmoid(v)  # to tie break when needed\n\n        self.Ns[s] += 1\n        return values","516092fd":"%%writefile -a submission.py\nclass HungryGeese(object):\n    def __init__(self,\n                 rows=7,\n                 columns=11,\n                 actions=[Action.NORTH, Action.SOUTH, Action.WEST, Action.EAST],\n                 hunger_rate=40):\n        self.rows = rows\n        self.columns = columns\n        self.actions = actions\n        self.hunger_rate = hunger_rate\n\n    def getActionSize(self):\n        return len(self.actions)\n\n    def getNextState(self, obs, last_obs, directions):\n        next_obs = deepcopy(obs)\n        next_obs.step += 1\n        geese = next_obs.geese\n        food = next_obs.food\n                \n        for i in range(4):\n            goose = geese[i]\n            \n            if len(goose) == 0: \n                continue\n            \n            head = translate(goose[0], directions[i], self.columns, self.rows)\n            \n            # Check action direction\n            if last_obs is not None and head == last_obs.geese[i][0]:\n                geese[i] = []\n                continue\n\n            # Consume food or drop a tail piece.\n            if head in food:\n                food.remove(head)\n            else:\n                goose.pop()\n            \n            # Add New Head to the Goose.\n            goose.insert(0, head)\n\n            # If hunger strikes remove from the tail.\n            if next_obs.step % self.hunger_rate == 0:\n                if len(goose) > 0:\n                    goose.pop()\n\n        goose_positions = histogram(\n            position\n            for goose in geese\n            for position in goose\n        )\n\n        # Check for collisions.\n        for i in range(4):\n            if len(geese[i]) > 0:\n                head = geese[i][0]\n                if goose_positions[head] > 1:\n                    geese[i] = []\n        \n        return next_obs\n\n    def getValidMoves(self, obs, last_obs, index):        \n        foods = obs.food        \n        geese = deepcopy(obs.geese)        \n        pos = geese[index][0]\n        \n        maxlen_goose = max(len(goose) for goose in geese)\n        num_goose = sum(len(goose) > 0 for goose in geese)\n        \n        potential_tail_strike = collections.defaultdict(lambda: 1)\n        potential_head_collision = collections.defaultdict(lambda: 1)\n        for goose_idx, goose in enumerate(geese):\n            if goose_idx == index or not goose:\n                continue\n            for action in self.actions:\n                nex_loc = translate(goose[0], action, self.columns, self.rows)\n                head_collision_factor = 1\n                if len(geese[index]) < len(goose):\n                    potential_head_collision[nex_loc] = 0.111  # avoid because of definite loss\n                elif num_goose == 2 and len(geese[index]) >= maxlen_goose:\n                    potential_head_collision[nex_loc] = 3.333  # secure first place\n                else:\n                    potential_head_collision[nex_loc] = 0.888  # would prefer higher placing\n                if nex_loc in foods:\n                    potential_tail_strike[goose[-1]] = 0.101\n        \n        next_poss = [translate(pos, action, self.columns, self.rows) for action in self.actions]\n        \n        mask_head_collision = np.array([potential_head_collision[next_pos] for next_pos in next_poss])\n        mask_tail_strike    = np.array([potential_tail_strike[next_pos] for next_pos in next_poss])\n\n        obstacles = {position for goose in geese for position in goose[:-1]}\n        if last_obs:\n            obstacles.add(last_obs.geese[index][0])            \n    \n        mask_valid = np.array([1.0 if next_pos not in obstacles else 0 \n                               for next_pos in next_poss])\n    \n        return mask_valid * mask_tail_strike * mask_head_collision\n\n    def stringRepresentation(self, obs):      \n        return str(obs.geese + obs.food)","fee58e97":"%%writefile -a submission.py\n# Neural Network for Hungry Geese\nclass TorusConv2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        self.edge_size = (kernel_size[0] \/\/ 2, kernel_size[1] \/\/ 2)\n        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=kernel_size)\n        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n\n    def forward(self, x):\n        h = torch.cat([x[:,:,:,-self.edge_size[1]:], x, x[:,:,:,:self.edge_size[1]]], dim=3)\n        h = torch.cat([h[:,:,-self.edge_size[0]:], h, h[:,:,:self.edge_size[0]]], dim=2)\n        h = self.conv(h)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\nclass GeeseNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        layers, filters = 12, 32\n        self.conv0 = TorusConv2d(17, filters, (3, 3), True)\n        self.blocks = nn.ModuleList([TorusConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n        self.head_p = nn.Linear(filters, 4, bias=False)\n        self.head_v = nn.Linear(filters * 2, 1, bias=False)\n\n    def forward(self, x):\n        h = F.relu_(self.conv0(x))\n        for block in self.blocks:\n            h = F.relu_(h + block(h))\n        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n        h_avg = h.view(h.size(0), h.size(1), -1).mean(-1)\n        p = torch.softmax(self.head_p(h_head), 1)\n        v = torch.tanh(self.head_v(torch.cat([h_head, h_avg], 1)))\n\n        return p, v\n\nclass NNAgent():\n    def __init__(self, state_dict):\n        self.model = GeeseNet()\n        self.model.load_state_dict(state_dict)\n        self.model.eval()\n        \n    def predict(self, obs, last_obs, index):\n        x = self._make_input(obs, last_obs, index)\n        with torch.no_grad():\n            xt = torch.from_numpy(x).unsqueeze(0)\n            p, v = self.model(xt)\n            \n        return p.squeeze(0).detach().numpy(), v.item()\n        \n    # Input for Neural Network\n    def _make_input(self, obs, last_obs, index):\n        b = np.zeros((17, 7 * 11), dtype=np.float32)\n        \n        for p, pos_list in enumerate(obs.geese):\n            # head position\n            for pos in pos_list[:1]:\n                b[0 + (p - index) % 4, pos] = 1\n            # tip position\n            for pos in pos_list[-1:]:\n                b[4 + (p - index) % 4, pos] = 1\n            # whole position\n            for pos in pos_list:\n                b[8 + (p - index) % 4, pos] = 1\n\n        # previous head position\n        if last_obs is not None:\n            for p, pos_list in enumerate(last_obs.geese):\n                for pos in pos_list[:1]:\n                    b[12 + (p - index) % 4, pos] = 1\n\n        # food\n        for pos in obs.food:\n            b[16, pos] = 1\n\n        return b.reshape(-1, 7, 11)","0c89c866":"%%writefile -a submission.py\ngame = HungryGeese()\n\nstate_dict_self = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\nagent_self = NNAgent(state_dict_self)\n\nstate_dict_pubhrl = pickle.loads(bz2.decompress(base64.b64decode(PARAM)))\nagent_pubhrl = NNAgent(state_dict_pubhrl)\n\nmcts = MCTS(game, agent_self, agent_pubhrl)\n\ndef alphageese_agent(obs, config):\n    action = game.actions[np.argmax(\n        mcts.getActionProb(obs, timelimit=config.actTimeout))]\n    return action.name","4f463d42":"%%writefile -a submission.py\n\n# class Struct(object):\n#     # convert dictionary into object to allow instance.attribute notation\n#     def __init__(self, data):\n#         for name, value in data.items():\n#             setattr(self, name, self._wrap(value))\n\n#     def _wrap(self, value):\n#         if isinstance(value, (tuple, list, set, frozenset)): \n#             return type(value)([self._wrap(v) for v in value])\n#         else:\n#             return Struct(value) if isinstance(value, dict) else value\n\n# ## test code\n# config = {'episodeSteps': 200, 'actTimeout': 1, 'runTimeout': 1200, \n#           'columns': 11, 'rows': 7, 'hunger_rate': 40, 'min_food': 2, 'max_length': 99}\n\n# # [????] better to get stuck because game is ending\n# obs = {'remainingOverageTime': 60, 'index': 1, 'step': 197, 'geese': [[], \n#     [36,35,24,25,14,3,4,15,16,27,38,39,40,29,28,17,18,7,6,5], \n#     [56,45,46,57,68,2,13,12,23,34,33,43,42,31,20,21,10,9,75,64,65], \n#     [30,41,52,63,62,51,50,49,48,59,60,61,72,73,74,8,19]], 'food': [26, 69]}  \n\n# alphageese_agent(Struct(obs), Struct(config))\n\n# # [0100] https:\/\/www.kaggle.com\/c\/hungry-geese\/submissions?dialog=episodes-episode-24354313\n# obs = {'remainingOverageTime': 36.25855599999999, 'index': 3, 'step': 195, 'geese': [\n#     [76, 75, 74, 73, 72, 6, 7, 8, 9, 20, 21, 10], \n#     [3, 2, 13, 14, 25, 24, 23, 22, 11, 0, 66, 67, 68, 69, 70, 71, 5], \n#     [65, 64, 63, 52, 53, 42, 31, 32, 43, 54, 44, 45, 46, 57, 56], \n#     [36, 37, 38, 27, 26, 15, 16, 17, 28, 29, 18, 19, 30, 41, 40, 51, 62, 61, 50, 49, 48, 47]], 'food': [34, 39]}\n\n# alphageese_agent(Struct(obs), Struct(config))\n\n# # [0001] https:\/\/www.kaggle.com\/c\/hungry-geese\/submissions?dialog=episodes-episode-24354751\n# obs = {'remainingOverageTime': 8.744749000000029, 'index': 3, 'step': 159, 'geese': [\n#     [28, 17, 18, 7, 6, 5, 71, 70, 59, 48, 49, 38, 37], \n#     [57, 46, 47, 58, 69, 3, 14, 25, 36, 35, 24, 23, 12, 13, 2], \n#     [29, 30, 19, 20, 9, 8, 74, 73, 62, 61, 50, 51, 52, 63, 64, 53, 42, 41], \n#     [21, 32, 22, 33, 44, 45, 56, 67, 66, 76, 10, 0]], 'food': [60, 54]}\n\n# alphageese_agent(Struct(obs), Struct(config))","7ad900e6":"url = \"https:\/\/tonghuikang.github.io\/analysis_HandyRL\/strings\/pubhrl.txt\"\nurl_self = \"https:\/\/tonghuikang.github.io\/analysis_HandyRL\/strings\/pubhrl-trained-on-boiler-adverse.txt\"\n\nimport urllib\nparams = next(urllib.request.urlopen(url)).decode(\"utf-8\")\nparams_self = next(urllib.request.urlopen(url_self)).decode(\"utf-8\")\n\nwith open(\"submission.py\", \"r\") as f:\n    s = f.read()\ns = s.replace(\"YYYYY\", params)\ns = s.replace(\"XXXXX\", params_self)\nwith open(\"submission.py\", \"w\") as f:\n    f.write(s)","05a6ecc5":"# check if the code runs\n!python3 submission.py","1202587f":"from kaggle_environments import make\nenv = make(\"hungry_geese\", debug=True)\nenv.reset()\nenv.run(['submission.py', \"greedy\", \"greedy\", \"greedy\"])\nenv.render(mode=\"ipython\", width=700, height=600)","051e6481":"### Reference\n- [Smart Geese Trained by Reinforcement Learning](https:\/\/www.kaggle.com\/yuricat\/smart-geese-trained-by-reinforcement-learning)\n- [Alpha Zero General](https:\/\/github.com\/suragnair\/alpha-zero-general)"}}