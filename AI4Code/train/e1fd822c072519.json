{"cell_type":{"5d931b72":"code","57495fe7":"code","2de37dde":"code","8f9db164":"code","60dc2a74":"code","6bf3ef8c":"code","f5255ec6":"code","ad600ef4":"code","25f3cba6":"code","72b9b721":"code","633eda34":"code","d7106997":"code","673234c7":"code","6522f0ae":"code","43d4f6a5":"code","bc939932":"code","88f1a3f7":"code","2bb5fe19":"code","18956e6b":"code","92a03310":"code","4cec76a4":"code","5dbcb63b":"code","73ddfe7d":"code","7a1437e7":"code","020b0a60":"code","c3f41bf3":"code","80aaef1d":"markdown","dba3ce82":"markdown","fea3d049":"markdown","99e54d0d":"markdown","d98ba970":"markdown","912742dd":"markdown","38887701":"markdown","37397e04":"markdown","52f578ef":"markdown"},"source":{"5d931b72":"import tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder,LabelBinarizer\nfrom sklearn.model_selection import train_test_split,KFold\nfrom tensorflow.keras import *\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import *\nfrom kaggle_datasets import KaggleDatasets\nimport numpy as np\nimport pandas as pd\ngcs_path=KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\nBATCH_SIZE=128","57495fe7":"train_csv=pd.read_csv(gcs_path+'\/train.csv')\ntest_csv=pd.read_csv(gcs_path+'\/test.csv')","2de37dde":"train_csv['age_approx']=train_csv['age_approx'].fillna(0)\ntrain_csv['sex']=train_csv['sex'].fillna('na')\ntrain_csv['anatom_site_general_challenge']=train_csv['anatom_site_general_challenge'].fillna('na')","8f9db164":"train_csv.isna().any()","60dc2a74":"le=LabelEncoder()\nbi=LabelBinarizer()","6bf3ef8c":"train_csv['sex']=bi.fit_transform(train_csv['sex'])\ntrain_csv['anatom_site_general_challenge']=le.fit_transform(train_csv['anatom_site_general_challenge'])","f5255ec6":"train_csv.anatom_site_general_challenge.value_counts().plot(kind='barh')","ad600ef4":"test_csv['sex']=bi.fit_transform(test_csv['sex'])\ntest_csv['anatom_site_general_challenge']=test_csv['anatom_site_general_challenge'].fillna('na')\ntest_csv['anatom_site_general_challenge']=le.fit_transform(test_csv['anatom_site_general_challenge'])","25f3cba6":"feat=['age_approx','sex','anatom_site_general_challenge']","72b9b721":"X=train_csv[feat]\ny=train_csv['target']","633eda34":"#X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.25,random_state=5)","d7106997":"def get_dataset(features,target,shuffle=False):\n   X=tf.data.Dataset.from_tensor_slices(tf.stack(features))\n   y=tf.data.Dataset.from_tensor_slices(target)\n   ds=tf.data.Dataset.zip((X,y))\n   ds=ds.repeat()\n   ds=ds.batch(BATCH_SIZE)\n   if shuffle:\n     ds=ds.shuffle(1234,reshuffle_each_iteration=True) #reshuffle_each_iteration=True\n   ds=ds.cache()\n   return ds","673234c7":"\"\"\"train_X,train_y=X.iloc[train],y[train]\nvalid_X,valid_y=X.iloc[valid],y[valid]\ntrain_ds=get_dataset(X_train,y_train,shuffle=True)\nval_ds=get_dataset(X_val,y_val,shuffle=False)\"\"\"","6522f0ae":"test_ds=tf.data.Dataset.from_tensor_slices(tf.stack(test_csv[feat]))\ntest_ds=test_ds.batch(BATCH_SIZE)\ntest_ds=test_ds.cache()","43d4f6a5":"def binary_focal_loss(gamma=2., alpha=.25):\n    \"\"\"\n    Binary form of focal loss.\n      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n    References:\n        https:\/\/arxiv.org\/pdf\/1708.02002.pdf\n    Usage:\n     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n    \"\"\"\n    def binary_focal_loss_fixed(y_true, y_pred):\n        \"\"\"\n        :param y_true: A tensor of the same shape as `y_pred`\n        :param y_pred:  A tensor resulting from a sigmoid\n        :return: Output tensor.\n        \"\"\"\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n\n        epsilon = K.epsilon()\n        # clip to prevent NaN's and Inf's\n        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n\n        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n\n    return binary_focal_loss_fixed","bc939932":"def create_model():\n  model=Sequential([\n                    Dense(256,activation='relu',input_shape=(3,),\n                          kernel_regularizer=regularizers.l2(0.001)),\n                    Dropout(0.2),\n                    BatchNormalization(),\n                    Dense(108,activation='relu',\n                          kernel_regularizer=regularizers.l2(0.001)),\n                    Dropout(0.2),\n                    Dense(182,activation='relu',\n                          kernel_regularizer=regularizers.l2(0.001)),\n                    Dropout(0.2),\n                    Dense(108,activation='relu',\n                         kernel_regularizer=regularizers.l2(0.001)),\n                    Dropout(0.2),\n                    Dense(108,activation='relu',\n                          kernel_regularizer=regularizers.l2(0.001)),\n                    Dense(1024,activation='relu',\n                          kernel_regularizer=regularizers.l2(0.001)),\n                    BatchNormalization(),\n                    Dropout(0.2),\n                    Dense(1,activation='sigmoid')\n  ])\n  model.compile(optimizer='sgd',\n                      loss=[binary_focal_loss(gamma = 2.2, alpha = 0.82)],\n                      metrics=[metrics.BinaryAccuracy(),metrics.AUC()]\n                )\n  return model","88f1a3f7":"# Learning rate schedule for TPU, GPU and CPU.\n# Using an LR ramp up because fine-tuning a pre-trained model.\n# Starting with a high LR would break the pre-trained weights.\n\nLR_START = 0.004\nLR_MAX = 0.00005 * 16\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 4\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr","2bb5fe19":"models=[]\noof_predictions=[]\noof_target=[]\nkf=KFold(n_splits=15,shuffle=True,random_state=1234)\n\nfor folds,(train,valid) in enumerate(kf.split(X,y)):\n  print('\\n')\n  print('-'*50)\n  print(f'Training fold {folds + 1}')\n  train_X,train_y=X.iloc[train],y[train]\n  valid_X,valid_y=X.iloc[valid],y[valid]\n  train_ds=get_dataset(train_X,train_y,True)\n  valid_ds=get_dataset(valid_X,valid_y,False)\n  K.clear_session()\n  model=create_model()\n  STEPS_PER_EPOCH=len(train_X)\/\/BATCH_SIZE\n  VALIDATION_STEPS=len(valid_X)\/\/BATCH_SIZE\n  es=tf.keras.callbacks.EarlyStopping(monitor = 'val_auc', mode = 'max', patience = 8, \n                                      verbose = 1, min_delta = 0.0001, restore_best_weights = True)\n  cb_schd=tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n  tb=tf.keras.callbacks.TensorBoard(log_dir=f'logs\/{folds +1}')\n  history=model.fit(train_ds,\n          epochs=50,\n          steps_per_epoch=STEPS_PER_EPOCH,\n          validation_data=valid_ds,\n          validation_steps=VALIDATION_STEPS,\n          callbacks=[es,cb_schd,tb]\n          )\n  models.append(model)\n  probabilities = model.predict(valid_X)\n  oof_target.extend(list(valid_y))\n  oof_predictions.extend(list(np.concatenate(probabilities)))","18956e6b":"from sklearn.metrics import roc_curve,auc\nact,pred,threshold=roc_curve(oof_target,oof_predictions)\nprint(\"AUC SCORE : \",auc(act,pred))","92a03310":"sample_sub=pd.read_csv(gcs_path+'\/sample_submission.csv')","4cec76a4":"sample_sub.head(5)","5dbcb63b":"df=sample_sub.copy()","73ddfe7d":"preds = np.average([np.concatenate(models[i].predict(test_ds)) for i in range(folds)], axis = 0)","7a1437e7":"df.target=preds","020b0a60":"df.head(5)","c3f41bf3":"df.to_csv('sub.csv',index=False)","80aaef1d":"**Predictions**","dba3ce82":"# Training ","fea3d049":"**Making the Dataset**","99e54d0d":"**References**\n[https:\/\/www.kaggle.com\/ragnar123\/efficientnet-x-384](http:\/\/)","d98ba970":"**Model Building**","912742dd":"**Data Preprocessing**","38887701":"**Imports**","37397e04":"> **Binary Focal Loss Function**","52f578ef":"**KFOLD Cross Validation**"}}