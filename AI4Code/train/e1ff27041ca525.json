{"cell_type":{"5c24b2ba":"code","ba8db672":"code","2753f631":"code","fa70566a":"code","5790f84d":"code","bcb95ac8":"code","f53f7dfc":"code","fd362967":"code","573a36af":"code","0571a861":"code","70eedf90":"code","53f5d10f":"code","8be6ef7e":"code","7d76c137":"code","c111255b":"code","d7832b60":"code","4a26dbfc":"code","327081eb":"code","4f24639c":"code","4e0c740f":"code","a40e80d7":"code","ab576895":"code","d3285a50":"code","28cb348a":"code","900e87f2":"code","8b29ef2f":"code","ebe31e02":"code","fd4d6441":"code","f318f04f":"code","cc9d6034":"code","6b33a946":"code","934ad062":"code","5f929a01":"code","323ab7f5":"code","41386621":"code","3235fde9":"code","01224cd8":"code","d541754d":"code","0df1ea7e":"code","79a2095d":"code","30fd649d":"code","8106ad15":"code","ce07fcbe":"code","f2538a79":"code","b2b55bae":"code","5574810b":"code","de01e05f":"markdown","b5618eeb":"markdown","451a23ac":"markdown","5b099d09":"markdown","dba574f5":"markdown","4c306852":"markdown","2baa3ca9":"markdown","defc70ce":"markdown","fe43d972":"markdown","22a41879":"markdown","44919f95":"markdown","870bff5a":"markdown","aade195f":"markdown","0742000b":"markdown","18fb2542":"markdown","63d9efcf":"markdown","118ff204":"markdown","cea36123":"markdown","726edc53":"markdown","ce15ab43":"markdown","0f45c22c":"markdown"},"source":{"5c24b2ba":"\nimport pandas as pd\nimport numpy as np\nimport math\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression  \nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\n\nfrom sklearn.metrics import make_scorer\n\nfrom pandas import DataFrame\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import GridSearchCV ","ba8db672":"# Reading the data from dataframe\ndata_frame = pd.read_csv('..\/input\/bike-sharing\/Bike_sharing.csv')","2753f631":"# displaying the few rows of dataset\ndata_frame.head()","fa70566a":"# displaying the info about the train data set\ndata_frame.info()","5790f84d":"# finding the null values in the data set\ndata_frame.isna().sum()","bcb95ac8":"# function to handle the date column in the data frame\ndef Handling_time_feature(df,column):\n    # splitting the time feature into seperate features\n    df['year'] = pd.DatetimeIndex(df[column]).year\n    df['month'] = pd.DatetimeIndex(df[column]).month\n    df['day'] = pd.DatetimeIndex(df[column]).day\n    df['hour'] = pd.DatetimeIndex(df[column]).hour\n    df= df.drop(columns=[column], axis=0) # dropping the date column \n    return df\n\n\n# calling the Handling_time_feature() to split the timestamp feature into seperate features\ndata_frame = Handling_time_feature(data_frame, 'timestamp')","f53f7dfc":"plt.figure(figsize=(18, 12))\nheatmap = sns.heatmap(data_frame.corr(), vmin=-1, vmax=1, annot=True, cmap= 'YlGnBu')\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':25}, pad=25);","fd362967":"# plots for Bike share count VS Temparature, Temparature feels like, Humidity, Windspeed\nfig,ax = plt.subplots(2,2, figsize=(15,15))\nplot = sns.scatterplot(x=\"cnt\", y=\"t1\",hue = 'season',data=data_frame,ax= ax[0,0])\nplot.set_title(\"Bike Share count VS Temparature\")\nplot = sns.scatterplot(x=\"cnt\", y=\"t2\",hue = 'season', palette=\"ch:r=-.5,l=.75\",data=data_frame,ax= ax[0,1])\nplot.set_title(\"Bike Share count VS Temparature feels like\")\nplot = sns.scatterplot(x=\"cnt\", y=\"hum\",hue = 'season', palette=\"ch:r=-.5,l=.75\",data=data_frame,ax= ax[1,0])\nplot.set_title(\"Bike Share count VS Humidity\")\nplot = sns.scatterplot(x=\"cnt\", y=\"wind_speed\",hue = 'season',data=data_frame,ax= ax[1,1])\nplot.set_title(\"Bike Share count VS Windspeed\")","573a36af":"# Bike share based on season and temparature\nplt.figure(figsize=(15, 10))\nplot= sns.relplot(data=data_frame, x='cnt', y='t1', col=\"season\", hue=\"t1\", height=5, aspect=.65)","0571a861":"# Bike share based on season and temparature feels like\nplot= sns.relplot(data=data_frame, x='cnt', y='t2', col=\"season\", hue=\"t2\", height=5, aspect=0.65)","70eedf90":"# Bike share based on season and Humidity\nplot= sns.relplot(data=data_frame, x='cnt', y='hum', col=\"season\", hue=\"t2\", height=5, aspect=0.65)","53f5d10f":"# Bike share based on season and Wind speed\nplot= sns.relplot(data=data_frame, x='cnt', y='wind_speed', col=\"season\", hue=\"t2\", height=5, aspect=0.65)","8be6ef7e":"# Bike share based on weekend and Holiday\nfig, ax = plt.subplots(3,2, figsize=(12,12))\nsns.boxplot(x=\"is_weekend\", y=\"cnt\", data=data_frame, ax=ax[0,0]) \nsns.boxplot(x=\"month\", y=\"cnt\", data=data_frame, ax=ax[0,1]) \nsns.boxplot(x=\"hour\", y=\"cnt\", data=data_frame, ax=ax[1,0]) \nsns.boxplot(x=\"is_holiday\", y=\"cnt\", data=data_frame, ax=ax[1,1]) \nsns.boxplot(x=\"season\", y=\"cnt\", data=data_frame, ax=ax[2,0]) \nsns.boxplot(x=\"weather_code\", y=\"cnt\", data=data_frame, ax=ax[2,1])\nplt.close(2)\nplt.close(3)\nplt.close(4)\nplt.close(5)\nplt.close(6)\nplt.close(7)\nfig.tight_layout()","7d76c137":"# function to normalize the features\ndef Normalize_Function(df, column_list):\n    # apply standardization on numerical features\n    for column in column_list:\n        # fit on training data column\n        scale = MinMaxScaler().fit(df[[column]])    \n        # transform the training data column\n        df[column] = scale.transform(df[[column]])\n    \n    return df        \n \n\n# columns required to scale\ncolumns_to_scale = ['t1', 't2','hum', 'wind_speed']\n\n# calling the  Normalize_Function to scale the features\ndata_frame = Normalize_Function(data_frame, columns_to_scale)\n\n\n# function for onehot encoder\ndef oneHot_Encoder(data_frame,column,prefix):\n    holiday_df = pd.DataFrame(data_frame, columns=[column])\n    temp_df = pd.get_dummies(holiday_df,columns= [column],prefix=[prefix] )\n    data_frame=data_frame.join(temp_df)\n    data_frame= data_frame.drop(columns=[column], axis=0)\n\n    return data_frame\n\n# converting the features into encoded features based on each category\ndata_frame= oneHot_Encoder(data_frame,'weather_code','W')\ndata_frame = oneHot_Encoder(data_frame,'season','season')\ndata_frame = oneHot_Encoder(data_frame,'is_weekend','Weekend')\ndata_frame = oneHot_Encoder(data_frame,'is_holiday','Holiday')\ndata_frame.head(5)","c111255b":"# splitting the data frame into Features and Target varibale for Testing  and Training the model \nX = data_frame.drop(columns=['cnt'], axis=0)\ny = data_frame['cnt']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\nprint(data_frame.shape)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","d7832b60":"# Function to Generate the MSE, RMSE\ndef mse_rmse(trues, preds):\n    '''\n    Compute MSE and rMSE for each column separately.\n    '''\n    mse = np.sum(np.square(trues - preds), axis=0) \/ trues.shape[0]\n    rmse = np.sqrt(mse)\n    return mse, rmse\n\n\ndef rmse_scorer(trues, preds):\n    '''\n    Compute rMSE\n    '''\n    mse, rmse = mse_rmse(trues, preds)\n    return rmse\n# Make the scoring function for GridSearch\nrmse_scoring = make_scorer(rmse_scorer, greater_is_better=False)","4a26dbfc":"# Creating the dataframe for model evaluation metric results\nModels_Performance = pd.DataFrame(columns=['Model', 'Train RMSE','Tuning Parameters', 'Test RMSE'])","327081eb":"def Alpha_Generator(RangeMin, RangeMax):\n    base = 2 \n    steps =20\n    bottom =math.log(RangeMin,base)\n    top = math.log(RangeMax,base)\n    exps = np.arange(bottom, top, (top-bottom)\/steps)\n    alphas = [np.power(base, ex) for ex in exps]\n    alphas\n    return alphas","4f24639c":"# Linear Regression Model\n\nlm = LinearRegression().fit(X_train, y_train)\n\n# appling the Linear model on train data\nlm_pred_train=lm.predict(X_train)\nLinear_Train_MSE, Linear_Train_RMSE=  mse_rmse(y_train, lm_pred_train)\n\n# appling the Linear model on test data\nlm_pred=lm.predict(X_test)\nLinear_MSE, Linear_RMSE=  mse_rmse(y_test, lm_pred)\n\ndata =[{'Model': 'Linear_Regression','Train RMSE':Linear_Train_RMSE,'Tuning Parameters':'none','Test RMSE': Linear_RMSE }]\nModels_Performance= Models_Performance.append(data, ignore_index=True,sort=False)\n\nModels_Performance","4e0c740f":"lasso = Lasso()\nlasso.fit(X_train, y_train)\n\n# appling the lasso model on train data\nlasso_pred_train=lasso.predict(X_train)\nlasso_Train_MSE, lasso_Train_RMSE=  mse_rmse(y_train, lasso_pred_train)\n\n# appling the lasso model on test data\nlasso_pred=lasso.predict(X_test)\nlasso_MSE, lasso_RMSE=  mse_rmse(y_test, lasso_pred)\n\n\ndata =[{'Model': 'Lasso','Train RMSE':lasso_Train_RMSE,'Tuning Parameters':'none','Test RMSE': lasso_RMSE }]\nModels_Performance=Models_Performance.append(data, ignore_index=True,sort=False)\nModels_Performance","a40e80d7":"# generating alpha values for lasso\nalphas=Alpha_Generator(1e-4, 1)\nalphas","ab576895":"# Applying the GridsearchCV with alpha and CrossValidation\nparam_grid = [{'alpha':alphas}]\nlasso_grid_search = GridSearchCV(estimator=lasso,\n                           param_grid=param_grid,\n                           scoring=rmse_scoring,\n                           n_jobs=-1,\n                           verbose= 1,cv=10)\n\nlasso_grid_search.fit(X_train, y_train)","d3285a50":"# retriving the stats from gridsearchcv\nstats = lasso_grid_search.cv_results_","28cb348a":"Lasso_df = DataFrame(stats)\nLasso_df","900e87f2":"# plot for RMSE vs Alpha for Lasso\nscores = (-stats[\"mean_test_score\"])\nalpha = stats[\"param_alpha\"]\n\nplt.figure(figsize=(8, 5))\nsns.lineplot(alpha, scores)\nplt.xlabel('Alpha value')\nplt.ylabel('RMSE')\nplt.title(\"RMSE vs Alpha for LASSO\")","8b29ef2f":"print(\"Best Tuning Parameter:\",lasso_grid_search.best_params_)\nprint(\"Best RMSEscore\",-lasso_grid_search.best_score_)","ebe31e02":"lasso_bestmodel = lasso_grid_search.best_estimator_\nlasso_bestmodel.fit(X_train, y_train)","fd4d6441":"data =[{'Model': 'Lasso_with_GridsearchCV','Train RMSE':lasso_Train_RMSE,'Tuning Parameters':lasso_grid_search.best_params_ ,'Test RMSE': -lasso_grid_search.best_score_ }]\nModels_Performance=Models_Performance.append(data, ignore_index=True,sort=False)\nModels_Performance","f318f04f":"ridge = Ridge()\nridge.fit(X_train, y_train)\n\n# appling the ridge model on train data\nRidge_pred_train=ridge.predict(X_train)\nRidge_Train_MSE, Ridge_Train_RMSE=  mse_rmse(y_train, Ridge_pred_train)\n\n\n# appling the ridge model on test data\nRidge_pred=ridge.predict(X_test)\nRidge_MSE, Ridge_RMSE=  mse_rmse(y_test, Ridge_pred)\n\n\ndata =[{'Model': 'Ridge','Train RMSE':Ridge_Train_RMSE,'Tuning Parameters':'none','Test RMSE': Ridge_RMSE }]\nModels_Performance=Models_Performance.append(data, ignore_index=True,sort=False)\nModels_Performance","cc9d6034":"# generating alpha values\nalphas=Alpha_Generator(1, 1e-6)\nalphas","6b33a946":"# Applying the GridsearchCV with alpha and CrossValidation\n\nparam_grid = [{'alpha':alphas}]\nridge_grid_search = GridSearchCV(estimator=ridge,\n                           param_grid=param_grid,\n                           scoring=rmse_scoring,\n                           n_jobs=-1,\n                           verbose= 1,cv=10)\n\nridge_grid_search.fit(X_train, y_train)","934ad062":"# retriving the stats from gridsearchcv\nstats = ridge_grid_search.cv_results_","5f929a01":"Ridge_df = DataFrame(stats)\nRidge_df","323ab7f5":"# plot for RMSE vs Alpha for Lasso\nscores = (-stats[\"mean_test_score\"])\nalpha = stats[\"param_alpha\"]\n\nplt.figure(figsize=(8, 5))\nsns.lineplot(alpha, scores)\nplt.xlabel('Alpha value')\nplt.ylabel('RMSE')\nplt.title(\"RMSE vs Alpha for Ridge\")","41386621":"print(\"Best Tuning Parameter:\",ridge_grid_search.best_params_)\nprint(\"Best RMSEscore\",-ridge_grid_search.best_score_)","3235fde9":"ridge_bestmodel = ridge_grid_search.best_estimator_\nridge_bestmodel.fit(X_train, y_train)","01224cd8":"data =[{'Model': 'Ridge_with_GridsearchCV','Train RMSE':Ridge_Train_RMSE,'Tuning Parameters':ridge_grid_search.best_params_ ,'Test RMSE': -ridge_grid_search.best_score_ }]\nModels_Performance=Models_Performance.append(data, ignore_index=True,sort=False)\nModels_Performance","d541754d":"elastic = ElasticNet(alpha=0.002, l1_ratio= 0.5)\nelastic.fit(X_train, y_train)\n\n# appling the elastic model on train data\nelastic_pred_train=elastic.predict(X_train)\nelastic_Train_MSE, elastic_Train_RMSE=  mse_rmse(y_train, elastic_pred_train)\n\n# appling the elastic model on test data\nelastic_pred=elastic.predict(X_test)\nelastic_MSE, elastic_RMSE=  mse_rmse(y_test, elastic_pred)\n\n\ndata =[{'Model': 'Elastic','Train RMSE':elastic_Train_RMSE,'Tuning Parameters':'none','Test RMSE': elastic_RMSE }]\nModels_Performance=Models_Performance.append(data, ignore_index=True,sort=False)\nModels_Performance","0df1ea7e":"# Generating the alphas and L1 Ratios\nalphas =Alpha_Generator(1, 1e-6)\nprint(alphas)\nl1_ratios = np.arange(0, 1.2, .2)\nprint(l1_ratios)","79a2095d":"# Applying the GridsearchCV with alpha and CrossValidation\nparam_grid = [{'alpha':alphas, 'l1_ratio': l1_ratios}]\nelastic_grid_search = GridSearchCV(estimator=elastic,\n                           param_grid=param_grid,\n                           scoring=rmse_scoring,\n                           n_jobs=-1,\n                           verbose= 1,cv=10)\n\nelastic_grid_search.fit(X_train, y_train)","30fd649d":"# retriving the stats from gridsearchcv\nstats = elastic_grid_search.cv_results_\n\nelastic_bestmodel = elastic_grid_search.best_estimator_\nelastic_bestmodel.fit(X_train, y_train)\n","8106ad15":"elastic_bestmodel.predict(X_test)","ce07fcbe":"elastic_df = DataFrame(stats)\nelastic_df","f2538a79":"print(\"Best Tuning Parameter:\",elastic_grid_search.best_params_)\nprint(\"Best RMSEscore\",-elastic_grid_search.best_score_)","b2b55bae":"data =[{'Model': 'Elastic_with_GridsearchCV','Train RMSE':elastic_Train_RMSE,'Tuning Parameters':elastic_grid_search.best_params_ ,'Test RMSE': -elastic_grid_search.best_score_ }]\nModels_Performance=Models_Performance.append(data, ignore_index=True,sort=False)\nModels_Performance","5574810b":"# displaying the Evaluation metrics table\nwith pd.option_context('display.max_colwidth', -1):\n    display(Models_Performance)","de01e05f":"#### Elastic Net","b5618eeb":"## Data Preparation","451a23ac":"# Bike Sharing Demand Prediction With Regression Models and GridsearchCV\n\n## Business Understanding\n#### Project Goal:\nThe goal of the project is to work on the Bike share Dataset and predict the demand of Bikes sharing on daily basis by building the Regression Models and GridsearchCV.\n#### Practical use:\n* The project will help the Bike Sharing Companies to solve the realtime problems such as:\n    * By knowing the demand the companies can plan in better way to meet the demand.\n    * Better planning on seasons when there is high demand.\n    * Better planning on the days\/hours have high demand.\n    * Increase the profit by managing the bikes based on demand.\n  \n Data Source: Https:\/\/cycling.data.tfl.gov.uk\/\n","5b099d09":"#### Lasso With GridsearchCV","dba574f5":"\n#### weekend VS count:\n* from the above boxplot we can say that the median of bike sharing is higher in weekdays which is **0** and low during weekend which is **1**.\n\n#### Month VS count:\n* from the above boxplot we can say that the median of bike sharing is higher in Months like 7,6,8,5,9 and moderate in 4,10 and low in remaning months.\n\n#### hour VS count:\n* from the above boxplot we can say that the median of bike sharing is higher during the hours 7,8,9,17,18,19.\n\n#### Holiday VS count:\n* from the above boxplot we can say that the median of bike sharing is higher in Non Holidays which is **0** low during holidays which is **1**.\n\n#### Season VS count:\n* from the above boxplot we can say that the median of bike sharing is higher in season **1** summer.\n\n#### Weather VS count:\n* from the above boxplot we can say that the median of bike sharing is higher in weather_code **1,2,3**.","4c306852":"#### Linear Regression Model","2baa3ca9":"#### Temparature VS count in different seasons:\n* From the above plots we can see that the bike sharing is high in season1,2(**Summer,Fall**) and low in season4(**Winter**) and Moderate in season0(**Spring**) \n#### Temparature Feelslike VS count in different seasons:\n* From the above plots we can see that the bike sharing is high in season1,2(**Summer,Fall**) and low in season4(**Winter**) and Moderate in season0(**Spring**) ","defc70ce":"#### Normalization with MinMaxScalar:\n MinMaxScalar scales each input variable separately to the range 0-1, in the above data frame the features 't1','t2','hum','wind_speed' are in high scale compare to the other features to normalize the data we applied the MinMaxScalar on the above features.\n\n#### Onehotencoding with pandas:\nA one hot encoding is a representation of categorical variables as binary vectors, A one hot encoding allows the representation of categorical data to be more expressive.\nwe applied the onehot encoding on the categorical features 'Weather_code','season','weekend','holiday'.","fe43d972":"## Data Understanding\n\nThe Dataframe has below features :\n**timestamp** :timestamp field for grouping the data\\\n**cnt** :the count of a new bike shares\\\n**t1** :real temperature in C\\\n**t2** :temperature in C \"feels like\"\\\n**hum** :humidity in percentage\\\n**windspeed** :wind speed in km\/h\\\n**weathercode** :category of the weather\\\n**isholiday** :boolean field - 1 holiday \/ 0 non holiday\\\n**isweekend** :boolean field - 1 if the day is weekend\\\n**season** :category field meteorological seasons:\n   > 0-spring\\\n   > 1-summer\\\n   > 2-fall\\\n   > 3-winter.\n   \n**weathe_code** :category description:\n   > 1 = Clear mostly clear but have some values with haze or fog or patches of fog or fog in vicinity.\\\n   > 2 = scattered clouds or few clouds.\\\n   > 3 = Broken clouds.\\\n   > 4 = Cloudy.\\\n   > 7 = Rain or light Rain shower or Light rain.\\\n   > 10 = rain with thunderstorm.\\\n   > 26 = snowfall.\\\n   > 94 = Freezing Fog.\n    \n","22a41879":"## Modeling and Performance Tuning\n#### Regression Models\n\n* By predicting the Bike sharing demand on daily basis using the Linear regression models and error evaluation metric as Root Mean Square Error i got errors for each model as     below.\n* Without tuning the performance metrics we got the best results with Linear Regression model with Test_RMSE as 905.633076  where as the Train RMSE is 885.999083.\n\t\t\n|     Model          | Train RMSE         | Tuning Parameters  |      Test RMSE     |\n| :------------------| :------------------| :------------------| :------------------|\n| Linear_Regression  | 885.999083         | none               | 905.633076         |\n| Lasso              | 886.790976         | none               | 906.141956         |\n| Ridge              | 886.086497         | none               | 905.764295         |\n| Elastic            | 886.944678         | none               | 906.506568         |\n\n#### Regression Models With GridSearchCV\n* **Lasso With GridsearchCV**\n\n\t* By using the GridsearchCV with CV as 10 and different alpha values we got the RMSE error as above plot.\n\t* We can see that the RMSE value increases as the alpha value increases from 0.0\n\t* The Optimal alpha value where the RMSE value is low is 'alpha': 0.0010000000000000024.\n\n* **Ridge With GridsearchCV**\n\n\t* By using the GridsearchCV with CV as 10 and different alpha values we got the RMSE error as above plot.\n\t* We can see that the RMSE value increases as the alpha value increases from 0.0\n\t* The Optimal alpha value where the RMSE value is low is 'alpha': 0.03162277660168379.\n\t\n* **Elastic With GridsearchCV**\n\t* By using the GridsearchCV with CV as 10 and different alpha values and l1 norm  we got the RMSE  error as 886.851187.\n\t* We got the optimal solution at 'alpha': 1.5848931924611134e-05, 'l1_ratio': 0.8.\n\t\n|     Model                            | Train RMSE         | Tuning Parameters                                  |      Test RMSE     |\n| :----------------------------------- | :------------------| :------------------------------------------------- | :------------------|\n| Linear_Regression                    | 885.999083         | none                                               | 905.633076         |\n| Lasso_with_GridsearchCV              | 886.790976         | {'alpha': 0.0010000000000000024}                   | 886.851327         |\n| Ridge_with_GridsearchCV              | 886.086497         | {'alpha': 0.03162277660168379}                     | 886.851185         |\n| Elastic_with_GridsearchCV            | 886.944678         | {'alpha': 1.5848931924611134e-05, 'l1_ratio': 0.8} | 886.851187         |","44919f95":"#### Ridge with GridsearchCV","870bff5a":"* from the above correlation matrix we can see that there is a positive linear relationship between the features t1, t2, hour, windspeed and cnt.\n* we can also see that there is negative linear relationship between hum and cnt.\n* there is no linear relationship with cnt and other features.","aade195f":"#### Lasso","0742000b":"#### Ridge","18fb2542":"## Model Evaulation Metrics","63d9efcf":"#### Elasticnet with GridsearchCV","118ff204":"From the below table we can see that we got the best results by parameter tuning and we got the least RMSE value for Ridge_with_GridsearchCV and Elastic_with_GridsearchCV models.","cea36123":"#### Performance evaluation metrics MSE, RMSE","726edc53":"## Exploratory Data Analysis","ce15ab43":"## Modeling and Performance Tuning","0f45c22c":"## Conclusion\n\nBy this project we are able to predict the Bike sharing demand on daily basis with more accuracy. the Bike sharing companies can use this project for predicting the demand of bike sharing which helps them in managing the bikes in correct manner which helps in increase of profits."}}