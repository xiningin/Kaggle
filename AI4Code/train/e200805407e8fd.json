{"cell_type":{"c9fc1e5b":"code","a5706d82":"code","36972c12":"code","b9a71c3a":"code","bbe2b730":"code","dae98155":"code","231c26dc":"code","0706f1f0":"code","2a9c8e79":"code","b5714ce1":"code","c7378ac5":"code","12f1e190":"code","07bc6dff":"code","fa27cd23":"code","6bbf68a2":"code","25d36afc":"code","ee8c22e3":"code","1b07b546":"code","5c1c4afd":"markdown"},"source":{"c9fc1e5b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import Normalizer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error\nimport catboost as cb\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a5706d82":"train = pd.read_csv(\"\/kaggle\/input\/ventilator-pressure-prediction\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/ventilator-pressure-prediction\/test.csv\")\nprint(train.shape)\ntrain.head()","36972c12":"print(train.isnull().sum())\nprint(\"____________________\")\nprint(test.isnull().sum())","b9a71c3a":"plt.figure(figsize=(10,8))\nsns.heatmap(data = train.corr(), annot = True, cmap = 'Blues')\nplt.show()","bbe2b730":"train['u_in_cumsum'] = (train['u_in']).groupby(train['breath_id']).cumsum()\n\ntest['u_in_cumsum'] = (test['u_in']).groupby(test['breath_id']).cumsum()\ntrain['u_in_lag'] = train['u_in'].shift(2)\ntrain = train.fillna(0)\n\ntest['u_in_lag'] = test['u_in'].shift(2)\ntest = test.fillna(0)\n","dae98155":"\ntrain_fin = train.drop(\"id\",axis=1)\ntrain_fin.shape","231c26dc":"train_fin.isnull().sum()","0706f1f0":"train_fin = train_fin.sample(frac =.003,random_state = 90, replace = False)\ntrain_fin.shape","2a9c8e79":"x = train_fin.drop(\"pressure\",axis=1)\ny = train_fin[\"pressure\"]\nfrom sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor().fit(x, y)\npred_gbr = gbr.predict(x)\nmean_absolute_error(y, pred_gbr)","b5714ce1":"x.shape","c7378ac5":"from tensorflow import keras\nfrom tensorflow.keras import layers,callbacks\nfrom tensorflow.keras.callbacks import EarlyStopping","12f1e190":"# early_stopping = callbacks.EarlyStopping(\n#     min_delta=0.001, \n#     patience=20, \n#     restore_best_weights=True,\n# )\n# neuralnet = keras.Sequential([\n#     layers.Dense(300,activation=\"relu\",input_shape = [8]),\n#     layers.Dense(512,activation=\"relu\"),\n#     layers.Dense(387,activation=\"relu\"),\n#     layers.Dense(234,activation=\"relu\"),\n#     layers.Dense(104,activation=\"relu\"),\n#     layers.Dense(56,activation=\"relu\"),\n#     layers.Dense(20,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(11,activation=\"relu\"),\n#     layers.Dense(1),\n# ])","07bc6dff":"# neuralnet.compile(\n#     optimizer='adam',\n#     loss='cross-entropy',\n# )","fa27cd23":"# history = neuralnet.fit(\n#     x, y,\n#     validation_data=(x, y),\n#     batch_size=32,\n#     epochs=50\n# )","6bbf68a2":"x_test = test.drop(\"id\",axis=1)\n# test_pred = neuralnet.predict(\n#     x_test,\n#     batch_size=32,\n#     verbose = 1\n# )","25d36afc":"train_dataset = cb.Pool(x, y) ","ee8c22e3":"cbmodel = cb.CatBoostRegressor(loss_function='RMSE')\ngrid = {'iterations': [100, 150, 200],\n        'learning_rate': [0.03, 0.1],\n        'depth': [2, 4, 6, 8],\n        'l2_leaf_reg': [0.2, 0.5, 1, 3]}\ncbmodel.grid_search(grid, train_dataset)\npred = cbmodel.predict(x_test)","1b07b546":"# print(test_pred)\n# result = test_pred.flatten()\n\ntest_gbr = gbr.predict(x_test)\noutput = pd.DataFrame({'id': test.id, 'pressure': pred})\noutput.to_csv('submission.csv', index=False)","5c1c4afd":"# Modelling"}}