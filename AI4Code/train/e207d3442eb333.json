{"cell_type":{"0df83767":"code","aa066a55":"code","73102349":"code","7aec4697":"code","0d94e2fb":"code","a73df163":"code","1cc8eb00":"code","98d8feee":"code","3dedffed":"code","2b864517":"code","34108246":"code","1df31d0a":"code","fad3f252":"code","dda36b88":"code","93972895":"code","aec66da8":"code","fe465403":"code","a1b312ae":"code","2b2aefd6":"code","3acd67fa":"code","5ce9f469":"code","35984baf":"code","89aaa7ab":"code","bceaa143":"code","94d3c1ba":"code","3e4544df":"code","963bd62c":"code","fcde21a8":"code","ae6da085":"code","3f764de2":"code","ef838bf3":"code","b5f616f4":"code","725bb213":"code","bdc53e52":"code","0a42f0d4":"code","77f1d9ce":"code","099a2c85":"code","e1e946d5":"code","0b218ccf":"code","d9f0d50c":"code","4b2e84f2":"code","945e5a81":"code","e36f3d7d":"code","9a5d930f":"code","092e1bab":"code","bdfee0da":"code","3213d153":"code","d2e820f9":"code","9020ee65":"code","e3915b92":"code","73d97863":"code","0a880ba8":"code","9ce0927e":"code","6a7a38cd":"code","43e574a4":"code","483ad2c4":"code","ccc4bbc6":"code","4bd9795e":"code","82444ccf":"code","5f84db55":"code","6a43de26":"code","e8d20f80":"code","ee08818d":"code","2dc0fcca":"code","344120e6":"code","ce5fd806":"code","4715b21a":"code","15379f24":"code","ca4c8a2a":"code","33dd3495":"code","7c00123c":"code","30394b40":"code","c37cebe7":"code","4f1f1d8c":"code","53ba6906":"code","f12b6afa":"code","fa46b98e":"code","4d6c9f18":"code","9434cc93":"code","a3c58558":"code","fa8169df":"markdown","d36dbc3f":"markdown","46c51a7c":"markdown","b561839e":"markdown","460c15b3":"markdown","cf7e6c55":"markdown","7c080a85":"markdown","00548d7a":"markdown","e3a39d90":"markdown","6526aaa9":"markdown","05103cd8":"markdown","1f1e1c57":"markdown","fbdecbfe":"markdown","3a1ddb60":"markdown","9b2e3973":"markdown","cdd699e4":"markdown","541b0b58":"markdown","8e1d2063":"markdown","82d7acd3":"markdown","6fe4d1d5":"markdown"},"source":{"0df83767":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_c\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa066a55":"import pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nprint(\"Setup Complete\")","73102349":"from sklearn.model_selection import train_test_split\n#Read Train and Test Data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ny=train_data[\"Survived\"]","7aec4697":"train_data.info()\ntest_data.info()","0d94e2fb":"print(\"The shape of train_data:\", train_data.shape)\nprint(\"The shape of test_data:\", test_data.shape)","a73df163":"train_data.head()","1cc8eb00":"train_data.tail()","98d8feee":"columns = train_data.columns\nfor col in columns:\n    print(\"unique values in {} column is: {}\". format(col, train_data[col].value_counts().size))","3dedffed":"print(\"Total number of male passengers:\")\nprint(train_data.loc[train_data.Sex==\"male\"].Sex.size)\nprint(\"Total number of female passengers:\")\nprint(train_data.loc[train_data.Sex==\"female\"].Sex.size)","2b864517":"print(\"The percentage of survived with respect to Sex:\")\nprint(100 * train_data.groupby(\"Sex\").Survived.mean())","34108246":"print(\"The percentage of survived with respect to Pclass:\")\nprint(100 * train_data.groupby(\"Pclass\").Survived.mean())","1df31d0a":"print(\"The percentage of survived with respect to Age:\")\nprint(100 * train_data.groupby(\"Age\").Survived.mean())","fad3f252":"g = sns.FacetGrid(col=\"Survived\", data=train_data, height = 2, aspect=3)\ng.map(sns.distplot, \"Age\", kde=False, bins=80)","dda36b88":"def cut_age(df, cut_values, label_names):\n    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n    df[\"Age\"]=pd.cut(df[\"Age\"], bins=cut_values, labels=label_names)\n    return df\n    \ncut_values=[-1, 0, 3, 12, 19, 35, 60, 80]\nlabel_names=[\"Missing\", \"Infants\", \"Children\", \"Teenagers\", \"Young Adults\", \"Middle-Age Adults\", \"Seniors\"]\ntrain_data=cut_age(train_data, cut_values, label_names)\ntest_data=cut_age(test_data, cut_values, label_names)","93972895":"sns.catplot(x=\"Age\", row=\"Survived\", kind=\"count\", height=3, aspect=4, data=train_data)","aec66da8":"print(100 * train_data.groupby(\"Age\").Survived.mean())","fe465403":"print(\"The percentage of survived with respect to SibSp:\")\nprint(100 * train_data.groupby(\"SibSp\").Survived.mean())","a1b312ae":"print(\"The percentage of survived with respect to Parch:\")\nprint(100 * train_data.groupby(\"Parch\").Survived.mean())","2b2aefd6":"def Cr_fam_membs(df):\n    df[\"FamMembs\"]= df[\"Parch\"] + df[\"SibSp\"]\n    df=df.drop([\"SibSp\", \"Parch\"], axis=1)\n    return df\n\ntrain_data=Cr_fam_membs(train_data)\ntest_data=Cr_fam_membs(test_data)","3acd67fa":"print(100 * train_data.groupby(\"FamMembs\").Survived.mean())","5ce9f469":"train_data[\"FamMembs\"].unique()","35984baf":"test_data[\"FamMembs\"].unique()","89aaa7ab":"train_data[\"FamMembs\"]=train_data[\"FamMembs\"].apply(lambda s: \"IsAlone\" if s==0 else s)\ntrain_data[\"FamMembs\"]=train_data[\"FamMembs\"].apply(lambda s: \"Small family\" if (s==1 or s==2 or s==3) else s)\ntrain_data[\"FamMembs\"]=train_data[\"FamMembs\"].apply(lambda s: \"Meduim family\" if (s==4 or s==5 or s==6) else s)\ntrain_data[\"FamMembs\"]=train_data[\"FamMembs\"].apply(lambda s: \"Large family\" if (s==7 or s==10) else s)","bceaa143":"test_data[\"FamMembs\"]=test_data[\"FamMembs\"].apply(lambda s: \"IsAlone\" if s==0 else s)\ntest_data[\"FamMembs\"]=test_data[\"FamMembs\"].apply(lambda s: \"Small family\" if (s==1 or s==2 or s==3) else s)\ntest_data[\"FamMembs\"]=test_data[\"FamMembs\"].apply(lambda s: \"Meduim family\" if (s==4 or s==5 or s==6) else s)\ntest_data[\"FamMembs\"]=test_data[\"FamMembs\"].apply(lambda s: \"Large family\" if (s==7 or s==10) else s)","94d3c1ba":"train_data[\"FamMembs\"].value_counts()","3e4544df":"test_data[\"FamMembs\"].value_counts()","963bd62c":"print(\"The percentage of survived with respect to Fam_membs:\")\nprint(100 * train_data.groupby(\"FamMembs\").Survived.mean())","fcde21a8":"sns.catplot(x=\"FamMembs\", row=\"Survived\", kind=\"count\", height=3, aspect=4, data=train_data)","ae6da085":"print(\"The percentage of survived with respect to Embarked:\")\nprint(100 * train_data.groupby(\"Embarked\").Survived.mean())","3f764de2":"train_data[\"Embarked\"]=train_data[\"Embarked\"].fillna(train_data[\"Embarked\"].mode()[0])\ntest_data[\"Embarked\"]=test_data[\"Embarked\"].fillna(test_data[\"Embarked\"].mode()[0])","ef838bf3":"g = sns.FacetGrid(col=\"Survived\", data=train_data, height = 2, aspect=3)\ng.map(sns.distplot, \"Fare\", kde=False, bins=100)","b5f616f4":"sns.catplot(x=\"Pclass\", y=\"Fare\", kind=\"bar\", data=train_data)","725bb213":"bins=np.arange(0, 600, 50)\ng=sns.FacetGrid(row=\"Pclass\", data=train_data, height = 3, aspect=5)\ng.map(sns.distplot, \"Fare\", kde=False, bins=bins, color=\"b\")","bdc53e52":"bins=np.arange(0, 600, 50)\ng=sns.FacetGrid(col=\"Embarked\", data=train_data, height = 3, aspect=2)\ng.map(sns.distplot, \"Fare\", kde=False, bins=bins, color=\"b\")","0a42f0d4":"sns.catplot(x=\"Pclass\", hue=\"Embarked\", kind=\"count\", data=train_data)","77f1d9ce":"#Check number of passengers who embarked at each port\nprint(train_data.loc[train_data[\"Embarked\"]==\"S\"].PassengerId.value_counts().sum())\nprint(train_data.loc[train_data[\"Embarked\"]==\"Q\"].PassengerId.value_counts().sum())\nprint(train_data.loc[train_data[\"Embarked\"]==\"C\"].PassengerId.value_counts().sum())","099a2c85":"test_data[\"Fare\"] = test_data[\"Fare\"].fillna(-1)","e1e946d5":"train_data[\"Fare\"].describe()","0b218ccf":"test_data[\"Fare\"].describe()","d9f0d50c":"def qcut_fare(df, q, labels):\n    df[\"Fare\"]=pd.qcut(df[\"Fare\"], q, labels=labels)\n    return df\n\nlabels=[\"range1\", \"range2\", \"range3\", \"range4\"]\ntrain_data=qcut_fare(train_data, 4, labels)\ntest_data=qcut_fare(test_data, 4, labels)","4b2e84f2":"sns.catplot(x=\"Fare\", data=train_data, kind=\"count\", height=2, aspect=3)","945e5a81":"sns.catplot(x=\"Fare\", data=test_data, kind=\"count\", height=2, aspect=3)","e36f3d7d":"train_data[\"Name\"]","9a5d930f":"train_data[\"Name\"]=train_data[\"Name\"].apply(lambda s: s.split(', ')[1].split('.')[0])\ntest_data[\"Name\"]=test_data[\"Name\"].apply(lambda s: s.split(', ')[1].split('.')[0])","092e1bab":"train_data[\"Name\"].unique()","bdfee0da":"test_data[\"Name\"].unique()","3213d153":"train_data[\"Name\"].value_counts()","d2e820f9":"test_data[\"Name\"].value_counts()","9020ee65":"train_data[\"Name\"]=train_data[\"Name\"].replace([\"Ms\", \"Mlle\"], \"Miss\")\ntrain_data[\"Name\"]=train_data[\"Name\"].replace([\"Sir\"], \"Mr\")\ntrain_data[\"Name\"]=train_data[\"Name\"].replace([\"Mme\"], \"Mrs\")\ntrain_data[\"Name\"]=train_data[\"Name\"].replace([\"Dr\", \"Rev\", \"Col\", \"Major\", \"Capt\", \"Master\", \n                                             \"Lady\", \"the Countess\", \"Don\", \"Dona\", \"Jonkheer\"], \"Other\")","e3915b92":"test_data[\"Name\"]=test_data[\"Name\"].replace([\"Ms\", \"Mlle\"], \"Miss\")\ntest_data[\"Name\"]=test_data[\"Name\"].replace([\"Sir\"], \"Mr\")\ntest_data[\"Name\"]=test_data[\"Name\"].replace([\"Mme\"], \"Mrs\")\ntest_data[\"Name\"]=test_data[\"Name\"].replace([\"Dr\", \"Rev\", \"Col\", \"Major\", \"Capt\", \"Master\", \n                                             \"Lady\", \"the Countess\", \"Don\", \"Dona\", \"Jonkheer\"], \"Other\")","73d97863":"train_data[\"Name\"].unique()","0a880ba8":"train_data[\"Name\"].value_counts()","9ce0927e":"test_data[\"Name\"].value_counts()","6a7a38cd":"sns.catplot(x=\"Name\", hue=\"Survived\", kind=\"count\", data=train_data)","43e574a4":"train_data.Cabin.describe()","483ad2c4":"train_data.Cabin.unique()","ccc4bbc6":"train_data[\"Cabin\"]=train_data[\"Cabin\"].fillna(\"Unknown\")","4bd9795e":"test_data[\"Cabin\"]=test_data[\"Cabin\"].fillna(\"Unknown\")","82444ccf":"train_data[\"Cabin\"].unique()","5f84db55":"test_data[\"Cabin\"].unique()","6a43de26":"train_data[\"Deck\"]=train_data[\"Cabin\"].str.replace(\"([0-9\\s])+\",\"\")","e8d20f80":"test_data[\"Deck\"]=test_data[\"Cabin\"].str.replace(\"([0-9\\s])+\",\"\")","ee08818d":"test_data[\"Deck\"].value_counts()","2dc0fcca":"train_data[\"Deck\"].value_counts()","344120e6":"def total_cabins(row):\n    if row.Deck == \"Unknown\":\n        row[\"TotalCab\"] = 0\n    elif len(row.Deck) > 1:\n        row[\"TotalCab\"] = len(row.Deck)\n    else:\n        row[\"TotalCab\"] = 1\n    return row\n\ntrain_data=train_data.apply(total_cabins, axis=1)\ntest_data=test_data.apply(total_cabins,axis=1)\n        ","ce5fd806":"train_data[\"TotalCab\"].value_counts()","4715b21a":"test_data[\"TotalCab\"].value_counts()","15379f24":"train_data[\"Deck\"]=train_data[\"Deck\"].apply(lambda s: s[0] if s != \"Unknown\" else s)","ca4c8a2a":"test_data[\"Deck\"]=test_data[\"Deck\"].apply(lambda s: s[0] if s != \"Unknown\" else s)","33dd3495":"test_data[\"Deck\"].value_counts()","7c00123c":"train_data[\"Deck\"].value_counts()","30394b40":"train_data=train_data.drop([\"Survived\", \"Cabin\", \"Ticket\"], axis=1)\ntest_data=test_data.drop([\"Cabin\", \"Ticket\"], axis=1)","c37cebe7":"train_data.info()","4f1f1d8c":"test_data.info()","53ba6906":"\nfrom sklearn.preprocessing import OneHotEncoder\n\nOHE = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\nfeatures = [\"Pclass\", \"Name\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamMembs\", \"Deck\", \"TotalCab\"]\nOHE_train_cols = pd.DataFrame(OHE.fit_transform(train_data[features]))\nOHE_test_cols = pd.DataFrame(OHE.transform(test_data[features]))\n\nOHE_train_cols.index = train_data.index\nOHE_test_cols.index = test_data.index\n\nnum_train=train_data.drop(features, axis=1)\nnum_test=test_data.drop(features, axis=1)\n\ntrain_data = pd.concat([num_train, OHE_train_cols], axis=1)\ntest_data = pd.concat([num_test, OHE_test_cols], axis=1)\n","f12b6afa":"print(train_data.shape, test_data.shape)","fa46b98e":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nxgb=XGBClassifier(objective='reg:logistic')\n\nparams={\n    'n_estimators': [200, 500, 1000],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'max_depth': [5, 7, 9],\n    'colsample_bytree': [ 0.4, 0.6, 0.8],\n    'subsample': [0.8, 0.9, 1],\n    'gamma': [0, 0.5, 1]\n}\n\nclf=RandomizedSearchCV(xgb, param_distributions=params, n_iter=50, n_jobs=-1, verbose=1)\nclf.fit(train_data, y)\n\n","4d6c9f18":"score=clf.best_score_\nparams=clf.best_params_\nprint(\"Best score: \",score)\nprint(\"Best parameters: \", params)","9434cc93":"final_predictions = clf.predict(test_data)","a3c58558":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': final_predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","fa8169df":"At the beginning I started with the assumption that the Name feature does not serve useful since every individual has a unique name. What is interesting here is that names have titles. These titles can be useful for the predictions.","d36dbc3f":"The results prove that infants and children had survived more than other age groups.","46c51a7c":"pandas.qcut() will be used to divide the Fare into four categories with equal distributions. pandas.cut() was not used since it is not clear how the fare was assigned and how it relates with other features. ","b561839e":"To limit the number of categories in Fam_membs features, it will be divided into 4 categories as following:\n* IsAlone: 0 fam_membs\n* Small family: 1-3 fam_membs\n* Meduim family: 4-6 fam_membs\n* Large family: 7-10 fam_membs","460c15b3":"This explains why a high number of passengers who embarked from port S paid the low fares, as this port is mostly used by Pclass 3. It also showed the lowest survival mean. Port C showed passengers who paid higher fares, as it is mostly used by Pclass 1. Also, port C showed the highest survival mean. Port Q was embarked by individuals who paid low fares and mainly belonged to Pclass 3. But why did Port S show less survival mean than Port Q? This might be because Port S was used by most of the passengers (higher number of passengers embarked through this port).","cf7e6c55":"As you can see it is difficult to grasp an idea about the relation between survived and age features. In this case, data visualization will be used.","7c080a85":"In the test_data there is 1 empty value in the Fare feature. I will fill it with -1. ","00548d7a":"The above graph tells us that children had a higher survival chance. To get a more clear prediction, one way is to divide the age feature into categories. pandas.cut() function will be used to achieve this goal. Since xgboost will be used, missing values will not be imputed instead they will be categorized as missing.","e3a39d90":"# Deal with categorical values","6526aaa9":"The data reveals that some passangers had more than one cabin. Some of them were on the same deck and some were on different decks. To deal with this, a new feature will be created that indicates the total number of cabins per passenger. If the passenger's cabin is unknown it will give 0. For decks which consitute of more than one letter, the first letter will be taken.","05103cd8":"# Acquiring Data","1f1e1c57":"Here we face the same issue as the age feature. To be more clear pandas.cut() or pandas.qcut() will be used to divide the fare into categories. Further study will be done on the Fare feature to decide which to use  pandas.cut() or pandas.qcut().","fbdecbfe":"Since there is only two missing values in the train_data Embarked feature, they will be filled with the most frequent value.","3a1ddb60":"The reason q=4 was used is becaused the data will be divided according to the values that .desctibe() show you (min, 25%, 50%, 75%, max)","9b2e3973":"# Exploration, Analysis and Feature Engineering","cdd699e4":"Individuals who embarked through port S paid the lowest fare.[](http:\/\/)","541b0b58":"What is interesting in these findings is that it seems that individuals who are alone (no family members) had less chance of survival than if they had 1 to 3 family members on board. But when the family members are more than 3 the survival chance drops. To be more precise, Parch and SibSp featurs will be combined into one feature to indicate the number of family members of each passengers on board. The new feature will be called Fam_membs, and Parch and SibSp features will be dropped.","8e1d2063":"At first I began with the idea of dropping the Cabin feature, as it has a lot of missing values. However, since I will be using Xgboost in my model, which is known to be good with dealing with missing values, I will make use of this feature. \n\nInstead of having a Cabin feature, a Deck feature will be created. Cabins were located on different decks on the ship. These decks were: A, B, C, D, E, F, G, T.\n\n\"Unknown\" will designate NaN values.","82d7acd3":"The values differ from what is expected, as there are people who are in Pclass 1 but paid low to no fare. This can be due to several reasons such as if the passenger is an employee or not.\nBefore dividing the fare, its relation with embarked port will be checked. And the relation of Embarked port with Pclass will also be checked.","6fe4d1d5":"# XGBoost Parameter Tuning & RandomizedSearchCV"}}