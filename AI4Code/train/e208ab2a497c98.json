{"cell_type":{"940a50d3":"code","952e143e":"code","6b129817":"code","8f033a23":"code","fde0a79f":"code","ea66cf7e":"code","1cca0e11":"code","d541defe":"code","4110ff37":"code","b2fcbf4b":"code","6514d7ba":"code","13403361":"code","04005f5f":"code","d0c99286":"code","e953d868":"code","d53cc3ea":"code","3605732c":"code","33aa5049":"code","e40678ea":"code","1daf4a16":"code","ee8d1d8c":"code","41ca8399":"code","e385817b":"code","47701678":"code","1e36bf9f":"code","8f3b614b":"code","be33e6cd":"code","aa295cc9":"code","7e65915f":"markdown","5f41118f":"markdown","77f6072f":"markdown","354ffb47":"markdown","2a5b3b42":"markdown","34d35ede":"markdown","e39f52da":"markdown","e9a38d76":"markdown","38b110cb":"markdown","057dceda":"markdown","b0294cf7":"markdown","af855f3f":"markdown","fe26cdcc":"markdown","b17b58df":"markdown","8629c31a":"markdown"},"source":{"940a50d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","952e143e":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.model_selection import train_test_split\nfrom pylab import plot, show, subplot, specgram, imshow, savefig\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score,f1_score, confusion_matrix\n%matplotlib inline","6b129817":"FILEPATH = '\/kaggle\/input\/loan-data-set\/loan_data_set.csv'","8f033a23":"df = pd.read_csv(FILEPATH)\ndf.head()","fde0a79f":"df.shape","ea66cf7e":"df.describe(include='all')","1cca0e11":"df.info()","d541defe":"df.isnull().any()","4110ff37":"df.isna().sum()","b2fcbf4b":"df.Credit_History.fillna(df.Credit_History.mean(), inplace=True)\ndf.Loan_Amount_Term.fillna(df.Loan_Amount_Term.mean(), inplace=True)","6514d7ba":"df.dropna(how=\"any\",inplace=True)","13403361":"df.isnull().any()","04005f5f":"df.drop(\"Loan_ID\", axis=1, inplace=True)","d0c99286":"le = LabelEncoder()\ncols = df.columns.tolist()\nfor column in cols:\n    if df[column].dtype == 'object':\n        df[column] = le.fit_transform(df[column])","e953d868":"df.dtypes","d53cc3ea":"fig, ax = plt.subplots(figsize=(20, 15))\nsns.heatmap(data=df.corr().round(2), annot=True, linewidths=0.7, cmap='YlGnBu')\nplt.show()","3605732c":"def plot_feature_importance(importance,names,model_type):\n\n    #Create arrays from feature importance and feature names\n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n\n    #Create a DataFrame using a Dictionary\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n\n    #Sort the DataFrame in order decreasing feature importance\n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n\n    #Define size of bar plot\n    plt.figure(figsize=(10,8))\n    #Plot Searborn bar chart\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n    #Add chart labels\n    plt.title(model_type + ' FEATURE IMPORTANCE')\n    plt.xlabel('FEATURE IMPORTANCE')\n    plt.ylabel('FEATURE NAMES')","33aa5049":"X = df.drop(\"Loan_Status\", axis=1)\ny = df[\"Loan_Status\"]\n\nrand_f = RandomForestClassifier().fit(X, y)\n\nplot_feature_importance(rand_f.feature_importances_, X.columns, 'RANDOM FOREST')","e40678ea":"gb_m = GradientBoostingClassifier().fit(X, y)\n\nplot_feature_importance(gb_m.feature_importances_, X.columns, 'GRADIENT BOOSTING')","1daf4a16":"ada = AdaBoostClassifier().fit(X, y)\n\nplot_feature_importance(ada.feature_importances_, X.columns, 'ADA BOOST')","ee8d1d8c":"parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n\nsvc = SVC()\n\ngrid = GridSearchCV(svc, parameters)","41ca8399":"Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=30) ","e385817b":"grid.fit(Xtrain, ytrain)","47701678":"grid.best_params_","1e36bf9f":"pred = grid.best_estimator_.predict(Xtest)","8f3b614b":"confusion_matrix(ytest,pred)","be33e6cd":"print(\"Accuracy score: {0}%\".format((accuracy_score(ytest,pred)*100).round(2)))","aa295cc9":"fig,ax=plt.subplots(figsize=(15,8))\nsns.regplot(x=ytest,y=pred,marker=\"*\")\nplt.show()","7e65915f":"# **DS Toolkit for Classification**","5f41118f":"This is a function to plot feature importance for a model","77f6072f":"It is hard to replace values like Gender, Married since they're categorical.\n\nOther columns are not numerical so we can mostly drop them for the lack of a better strategy.\n\nFor the columns that are numerical, let's fill 'em shall we??","354ffb47":"Null values are there but,\n\nHow many values are null exactly??","2a5b3b42":"Property Area sneaks ahead of Credit History in Ada Boosting which is interesting","34d35ede":"# **DataFrame Analysis**\n\n* Size\n* Description\n* Info\n* Null values in any columns","e39f52da":"Ok null values are handled \n\nLoan ID is good but not that important so we drop it","e9a38d76":"# **Gradient Boosting Classifier**","38b110cb":"We need numeric values for a classifier so we need to encode it. Label Encoder is used in this notebook","057dceda":"Alright on to,\n\n# The Heatmap of Correlation","b0294cf7":"**Random Forest Classifier**","af855f3f":"# Top 5\n\n* Credit_History\n* Applicant_Income\n* Loan_Amount\n* Copplicant_Income\n* Loan_Amount_Term\n\nWhich makes sense since these are the parameters on which a bank decides whether to give a loan or not","fe26cdcc":"# **Ada Boosting Classifier**","b17b58df":"Same Top 5 as Random Forest","8629c31a":"**Sources**:\n\nhttps:\/\/www.kaggle.com\/kamalkhumar\/loan-status-prediction\n\nhttps:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.describe.html\n\nhttps:\/\/seaborn.pydata.org\/generated\/seaborn.heatmap.html"}}