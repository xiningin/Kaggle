{"cell_type":{"07df8aeb":"code","a51c6a7e":"code","0fed5613":"code","3af72732":"code","4b4b663e":"code","df091448":"code","839bdfbc":"code","932994b7":"code","44b189c3":"code","33e32752":"code","3a512516":"code","ff810de5":"code","8620c7d1":"code","3642be20":"code","df31f8a7":"code","3e6f3b8b":"code","cf3c0e71":"code","aed2a521":"code","29929414":"code","14215610":"code","93e0152d":"code","fa96fa08":"markdown","95468b40":"markdown","b84f5fd9":"markdown"},"source":{"07df8aeb":"# https:\/\/www.youtube.com\/watch?v=1fBx2laX9pg\n\n# import libraries.\nimport os\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm #jet colors\nfrom PIL import Image\n\nfrom sklearn.preprocessing import OneHotEncoder \nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\n\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import plot_confusion_matrix\n\n","a51c6a7e":"paths = [] # to store images path\n\nfor r, d, f in os.walk(r'..\/input\/brain-mri-images-for-brain-tumor-detection\/yes'):\n    for file in f:\n#         if '.jpg' in file:\n            paths.append(os.path.join(r, file))         \n            \nprint('Number of MRI images with Brain Tumor: ', len(paths))","0fed5613":"# Visualization of MRI images.\nc = 1\nplt.figure(figsize=(12,13))\n# Random selection of MRI images to visualize\nfor i in np.random.choice(np.arange(len(paths)), size=25, replace=False):\n    plt.subplot(5,5,c) \n    plt.tight_layout() # no overlap\n    plt.xticks([])\n    plt.xlabel('Dim '+str(Image.open(paths[i]).size))\n    plt.yticks([])\n    plt.title(paths[i].split('\/')[-1])\n    plt.grid(False)\n    plt.imshow(Image.open(paths[i]))\n    \n    c += 1\nplt.show()","3af72732":"encoder = OneHotEncoder()\nencoder.fit([[0], [1]])\n\ndata = [] # Store np.array images\nresult = [] # Store labels.\n\npath1 = []\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[0]]).toarray())\n        path1.append(path)\n    else:\n        plt.imshow(img)\n        plt.xticks([])\n        plt.xlabel('Dim '+str(Image.open(path).size))\n        plt.yticks([])\n        plt.title(path.split('\/')[-1])\n        print(path)\n\n","4b4b663e":"print('len paths: ',len(paths))\nprint('len data: ',len(data))\nprint('len resul: ', len(result))","df091448":"# This cell updates result list for images without tumor\npaths = []\nfor r, d, f in os.walk(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\"):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r, file))\n\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[1]]).toarray()) ","839bdfbc":"print('len paths: ',len(paths))\nprint('len data: ',len(data))\nprint('len resul: ', len(result))","932994b7":"data = np.array(data)\nprint('Data shape: ', data.shape)","44b189c3":"result = np.array(result)\nprint('Result shape: ', result.shape)\nresult = result.reshape(len(data),2)\nprint('Result shape: ', result.shape)\npd.DataFrame(result)","33e32752":"# Split the data\nx_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)","3a512516":"x_train.shape\nx_test.shape\ny_test.shape","ff810de5":"model = keras.models.Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))\nmodel.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\nmodel.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same', name='conv2d_last'))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(loss = \"categorical_crossentropy\", optimizer='Adamax',metrics=['accuracy'])\nprint(model.summary())","8620c7d1":"history = model.fit(x_train, \n                    y_train, \n                    epochs = 30, \n                    batch_size = 40,\n#                     validation_split=0.20, # defining train_set % to held out for validation\n                    validation_data = (x_test, y_test),\n                    verbose=1)","3642be20":"history.history.keys()","df31f8a7":"fig = plt.figure(constrained_layout=True, \n                 figsize=(12, 3), dpi = 80)\n\ngs = fig.add_gridspec(1,2)\n\nax1 = fig.add_subplot(gs[0, 0])\nax1.plot(history.history['accuracy'])\nax1.plot(history.history['val_accuracy'], color=\"olivedrab\")\nax1.set_xlabel(\"epoch\")\nax1.set_ylabel(\"accuracy\")\nax1.set_title('model accuracy')\nax1.legend(['train', 'val'], loc='upper right',  bbox_to_anchor=(1.25, 1))\n\nax2 = fig.add_subplot(gs[0, 1])\nax2.plot(history.history['loss'])\nax2.plot(history.history['val_loss'], color=\"olivedrab\")\nax2.set_xlabel(\"epoch\")\nax2.set_ylabel(\"loss\")\nax2.set_title('model loss')\nax2.legend(['train', 'val'], loc='upper right',  bbox_to_anchor=(1.25, 1))\n\nfig.suptitle('Metrics train - validation set', fontsize=16)\nplt.show()","3e6f3b8b":"#Check this..\ny_pred = model.predict_on_batch(x_test)\ntf.math.confusion_matrix(y_test,y_pred)\n","cf3c0e71":"def names(number):\n    if number==0:\n        return 'Its a Tumor'\n    else:\n        return 'No, Its not a tumor'\n# ______________\n# label = 1 >> no a tumor, \n# label = 0 >> it's a tumor\nimg = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/N26.JPG\") #yes\/Y109.JPG\")\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres = model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nplt.imshow(img)\nplt.show()\nprint(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))","aed2a521":"res","29929414":"\ndef img_pred(img_path, model):\n    img = Image.open(img_path)\n    model = model\n    \n    x = np.array(img.resize((128,128)))\n    x = x.reshape(1,128,128,3)\n    res = model.predict_on_batch(x)\n    classification = np.where(res == np.amax(res))[1][0]\n    plt.imshow(img)\n    plt.show()\n    print(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))","14215610":"def get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) \/ tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\n\n\n\n\ndef plot_gradcam(img_path, heatmap, alpha=0.4):\n    img = keras.preprocessing.image.load_img(img_path)\n    img = img.resize((128,128))\n    img = keras.preprocessing.image.img_to_array(img)\n\n\n    # Rescale heatmap to a range 0-255\n    heatmap1 = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap1]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n\n    plt.figure(figsize=(6,6))\n    plt.imshow(superimposed_img)\n    plt.show()","93e0152d":"# Initial parameters\nlast_conv_layer_name = 'conv2d_last'\nimg_size = (128,128)\nimg_path = r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/17 no.jpg\"\nimg_path = r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/28 no.jpg\"\nimg_path = r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/N6.jpg\"\nimg_path = r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y100.JPG\"\nimg_path = r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y109.JPG\"\nimg_path = r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y112.JPG\"\nimg_path = r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y182.JPG\"\nimg_array = get_img_array(img_path, img_size)\n\n# ORIGINAL\nimg_pred(img_path, model)\n\n# WHERE CovNet pay attention || Generate class activation heatmap\nheatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\n# plt.figure(figsize=(6,6))\nplt.matshow(heatmap)\nplt.show()\n\n# SuperImpose visualization\nplot_gradcam(img_path, heatmap, alpha=0.4)","fa96fa08":"# MODEL\nBatch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.\n\n**BachNormalization works differently for training and during inference (evaluate or predict)** [ref](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/BatchNormalization)","95468b40":"# Check Prediction","b84f5fd9":"* MRI images with different sizes (width and height)"}}