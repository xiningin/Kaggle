{"cell_type":{"a385857d":"code","1a17e329":"code","4afb1302":"code","2cca19e5":"code","fb7a612f":"code","f1a79528":"code","920531a7":"code","a28393c1":"code","e09a55a6":"code","5497c11c":"code","b636e2fc":"code","1f2cd7c9":"code","9585ac1d":"code","69f833c9":"code","50b9a903":"code","4a7637dd":"code","6fff8db5":"code","a873713d":"code","1679968e":"code","8ec31160":"code","13640a33":"code","fd263322":"code","6989b834":"code","bda8c299":"code","c0f2f81b":"code","5af1be80":"code","e449dd8a":"code","a3d3e7b7":"code","bbfdd627":"code","3481208b":"code","55150fda":"code","6ed82daf":"code","52f282a6":"code","1ff18264":"code","9b3f802f":"code","4711cc7b":"markdown","a79390e3":"markdown","d93c4b22":"markdown","2ff9296a":"markdown","dc71008a":"markdown","fb3ed1ab":"markdown","92f682fd":"markdown","1d7d0b74":"markdown","4d9ee587":"markdown","d02e37b0":"markdown","9a55b6e3":"markdown","6cdd22a1":"markdown"},"source":{"a385857d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a17e329":"data = pd.read_csv('\/kaggle\/input\/supermarket-sales\/supermarket_sales - Sheet1.csv')\ndata = data.drop(['Invoice ID'],axis=1)","4afb1302":"data.head()","2cca19e5":"data.describe()","fb7a612f":"data.info()","f1a79528":"df = data.copy()","920531a7":"data[[i for i in data.columns if data[i].dtypes == 'object']]","a28393c1":"data[[i for i in data.columns if data[i].dtypes != 'object']]","e09a55a6":" data['DateTime'] = data['Date']+\" \"+ data['Time']\ndata['DateTime'] = pd.to_datetime(data['DateTime'])","5497c11c":"data['Branch'].value_counts()","b636e2fc":"sns.catplot(x=\"Branch\", kind=\"count\", palette=\"ch:.25\", data=data)","1f2cd7c9":"data['City'].value_counts()","9585ac1d":"data = data.drop(['City'],axis=1)\ndata = data.drop(['Date','Time'],axis=1)","69f833c9":"data['Customer type'].value_counts()","50b9a903":"sns.catplot(x=\"Customer type\", kind=\"count\", palette=\"ch:.25\", data=data)","4a7637dd":"data['Gender'].value_counts()","6fff8db5":"size = data['Customer type'].value_counts(sort=True)\ncolors = ['Red','Yellow']\nlabels = ['Member','Normal']\nexplode = (0,0.1)\nplt.figure(figsize=(10 , 8))\nplt.pie(size,colors=colors,autopct='%1.1f%%',shadow=True,startangle = 270 ,explode= explode, labels=labels)\n\nplt.show()\n\n","a873713d":"plt.figure(figsize=(8,4))\nsns.countplot(x='Customer type', data= data, palette= \"rocket\",hue = \"Gender\")","1679968e":"data['Product line'].value_counts()","8ec31160":"plt.figure(figsize=(16,8))\nsns.countplot(x='Product line',data=data,palette='coolwarm',hue='Gender')","13640a33":"sns.countplot(x=data['Payment'],data=data,palette='BuPu')","fd263322":"plt.figure(figsize=(20,8))\nsns.countplot(x='Product line',data=data,palette='ocean',hue='Branch')","6989b834":"plt.figure(figsize=(16,8))\nsns.heatmap(data.corr(),annot=True)","bda8c299":"# categorical data\n[i for i in data.columns if data[i].dtype == 'object']\ndata = pd.get_dummies(data,drop_first=True)","c0f2f81b":"#Feature Engineering \n\ndata['TotalbyQuantity'] = data['Total'] \/ data['Quantity']\n","5af1be80":"# Standardizing the numerical variables\nnum = data[['Unit price','Quantity','Tax 5%','Total','cogs','gross margin percentage','gross income','Rating','TotalbyQuantity']]\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nnum = scaler.fit_transform(num)\nnum = pd.DataFrame(num,columns=['Unit price','Quantity','Tax 5%','Total','cogs','gross margin percentage','gross income','Rating','TotalbyQuantity'])\nnum","e449dd8a":"data=data.drop(['Unit price','Quantity','Tax 5%','Total','cogs','gross margin percentage','gross income','Rating','TotalbyQuantity'],axis=1)\ndata = pd.concat([data,num],axis=1)\ndata.head()","a3d3e7b7":"data = data.drop(['DateTime'],axis=1)\n#Splitting Datas\nX = data.drop(['Total'],axis=1)\ny = data['Total']","bbfdd627":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.45,random_state=42)","3481208b":"X_train.shape","55150fda":"#Supporting functions\nfrom sklearn.preprocessing import PolynomialFeatures\n#Fit Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\n#Scoring function\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score","6ed82daf":"model1 = LinearRegression()\nmodel1.fit(X_train,y_train)\ny_pred = model1.predict(X_test)\nprint(mean_absolute_error(y_test,y_pred))\nprint(np.sqrt(mean_squared_error(y_test,y_pred)))\nprint(model1.score(X_train,y_train))\nprint(model1.score(X_test,y_test))\n","52f282a6":"model2 = Ridge(alpha=1.0,\n    fit_intercept=True,\n    normalize=False,\n    copy_X=True,\n    max_iter=None,\n    tol=0.001,\n    solver='auto',\n    random_state=None,)\nmodel2.fit(X_train,y_train)\ny_pred = model2.predict(X_test)\nprint(mean_absolute_error(y_test,y_pred))\nprint(np.sqrt(mean_squared_error(y_test,y_pred)))\nprint(model1.score(X_train,y_train))\nprint(model1.score(X_test,y_test))","1ff18264":"model3 = Lasso(alpha=1.0,\n    fit_intercept=True,\n    normalize=False,\n    precompute=False,\n    copy_X=True,\n    max_iter=1000,\n    tol=0.0001,\n    warm_start=False,\n    positive=False,\n    random_state=None,\n    selection='cyclic',)\nmodel3.fit(X_train,y_train)\ny_pred = model2.predict(X_test)\nprint(mean_absolute_error(y_test,y_pred))\nprint(np.sqrt(mean_squared_error(y_test,y_pred)))\nprint(model1.score(X_train,y_train))\nprint(model1.score(X_test,y_test))","9b3f802f":"model4 = ElasticNet(alpha=1.0,\n    l1_ratio=0.5,\n    fit_intercept=True,\n    normalize=False,\n    precompute=False,\n    max_iter=1000,\n    copy_X=True,\n    tol=0.0001,\n    warm_start=False,\n    positive=False,\n    random_state=None,\n    selection='cyclic',)\nmodel4.fit(X_train,y_train)\ny_pred = model4.predict(X_test)\nprint(mean_absolute_error(y_test,y_pred))\nprint(np.sqrt(mean_squared_error(y_test,y_pred)))\nprint(model1.score(X_train,y_train))\nprint(model1.score(X_test,y_test))","4711cc7b":"# Elastic Net\nElastic acts life a buffer between Ridge and Lasso Regression,The regularization term is a simple mix of both ridge and lasso ","a79390e3":"# Linear Regression\nLinear Regression is a simple supervised machine model which uses linear function on input features to obtain the output","d93c4b22":"# Splitting the data into Train and Test","2ff9296a":"\nIt is surprising to know that men are buying beauty and health product, women buying sports and travel products more.","dc71008a":"There is no missing values in this dataset","fb3ed1ab":"# Ridge Regression\nRidge Regression(Tikhonov regularization) is a regularized version of Linear Regression,The regularization term forces the learning algorithm to not only fit the data but also keep the model weights as small as possible","92f682fd":"First I concat the two features that is date and time into DateTime and then convert that string to datetime","1d7d0b74":"# Lasso Regression\nLasso Regression is similar to ridge regression except that it uses L1 regularization,It automatically performs feature selection","4d9ee587":"# Modelling","d02e37b0":"# Data Analysis and Data Cleaning","9a55b6e3":"# Importing dataset\n# Importing Libraries","6cdd22a1":"I will drop any of the feature (Branch or City) because both represent same I will drop for City bacuse it will easy for me to use Branch instead"}}