{"cell_type":{"b53ae4a3":"code","ebd5e2e6":"code","9b5f1473":"code","32263972":"code","7467858b":"code","930bd51d":"code","2e2c2ea4":"code","40f6ab76":"code","a1140944":"code","43f4f751":"code","6df309ac":"code","3a41b2dd":"code","dab515e5":"code","680d9de8":"code","4821231d":"code","d6540100":"code","e458fbf6":"code","8d339563":"code","2152c81b":"code","d941b6d5":"code","701ea992":"code","34f8f59a":"code","db5c230e":"code","f0e2d32e":"code","5eb442aa":"code","49932214":"code","04c744e1":"code","63dc52b1":"code","bf3e504e":"code","53c9b300":"code","e087bd45":"code","8cae4fa8":"code","7f289bf8":"code","c95180dd":"code","b9ffe25d":"code","dac440b4":"code","2c4966a1":"code","98b73d4a":"code","c3e578b9":"code","ce01c499":"code","449f79f5":"code","feff83b0":"code","b5937aeb":"code","91fb375a":"code","a78feeb6":"code","9d8215dd":"code","aaebc053":"code","d6e9acee":"code","a7a36c37":"code","3ca9d547":"code","412c559d":"code","acc6cfc2":"code","779e95bb":"code","49085492":"code","16cd2695":"code","4bba5b3b":"code","f1f7a8b3":"code","fffb8d19":"code","0e06f4cd":"code","c209425d":"code","9c885235":"code","46493232":"code","0859d157":"code","7b574905":"code","f17a3173":"code","c78b7bad":"markdown","92a49639":"markdown","51b43a35":"markdown","0e98eaaa":"markdown","5eb9b324":"markdown","5b52e845":"markdown","5a37affb":"markdown","d02bf1f6":"markdown","d0a05682":"markdown","2eeb5e4c":"markdown","125ad357":"markdown","37da0fa7":"markdown","2615ee74":"markdown","9180682b":"markdown","3b46c764":"markdown","172fe180":"markdown","78ca673e":"markdown","1f719a8b":"markdown","ab77ef6c":"markdown","3fcb9fa5":"markdown","1b139fe2":"markdown","36cfde0b":"markdown","374feec2":"markdown","0056af8d":"markdown","03d9834b":"markdown","afe8e468":"markdown","919b3100":"markdown","e6496f51":"markdown","85f83942":"markdown","2fa94d6f":"markdown","991a497b":"markdown","67e1a3ac":"markdown","39cc8980":"markdown","3c7694c4":"markdown","9de4490d":"markdown","02c90190":"markdown","aa1a3b4b":"markdown","e177b15b":"markdown","c5202280":"markdown","a7555fa2":"markdown","532d0cbc":"markdown","8edeab00":"markdown","e29618d6":"markdown","93af825c":"markdown","d9d8353a":"markdown","f40e2b71":"markdown","648eff6c":"markdown"},"source":{"b53ae4a3":"import pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMRegressor\npd.pandas.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n","ebd5e2e6":"train = pd.read_csv(\"..\/input\/titanic-machine-learning-from-disaster\/train.csv\")","9b5f1473":"df = train.copy()","32263972":"df.head(10)","7467858b":"df.columns","930bd51d":"df.info()","2e2c2ea4":"df.size","40f6ab76":"df.shape","a1140944":"df.describe().T","43f4f751":"df.describe(include=['O'])","6df309ac":"df.Survived.unique()","3a41b2dd":"df.Survived.value_counts()","dab515e5":"cat_cols = [col for col in df.columns if df[col].dtypes == 'O']\nprint('Number of Categorical Variables : ', len(cat_cols))","680d9de8":"more_cat_cols = [col for col in df.columns if len(df[col].unique()) < 10]\nprint('Number of Categorical Variables : ', len(more_cat_cols))\nprint(more_cat_cols)","4821231d":"df[cat_cols].nunique()","d6540100":"def cats_summary(data):\n    cats_names = [col for col in data.columns if len(data[col].unique()) < 10 and data[col].dtypes == 'O']\n    for var in cats_names:\n        print(pd.DataFrame({var: data[var].value_counts(),\n                            \"Ratio\": 100 * data[var].value_counts() \/ len(data)}), end=\"\\n\\n\\n\")\n        sns.countplot(x=var, data=data)\n        plt.show()\ncats_summary(df)","e458fbf6":"df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","8d339563":"sns.barplot(x='Pclass', y=\"Survived\", data=df); plt.show()","2152c81b":"sns.countplot(x=\"Survived\", hue=\"Pclass\",data=df); plt.show()","d941b6d5":"df['Pclass'].value_counts().plot.pie(autopct=\"%1.1f%%\",figsize=(10,7)) ; plt.show()","701ea992":"df[[\"Sex\" , \"Survived\"]].groupby([\"Sex\"] , as_index = False).mean().sort_values(by=\"Survived\" , ascending = False)","34f8f59a":"sns.barplot(x='Sex', y=\"Survived\", data=df); plt.show()","db5c230e":"sns.countplot(x=\"Survived\", hue=\"Sex\",data=df); plt.show()","f0e2d32e":"df[[\"Parch\" , \"Survived\"]].groupby([\"Parch\"] , as_index = False) .mean().sort_values(by=\"Survived\" , ascending = False)","5eb442aa":"sns.barplot(x='Parch', y=\"Survived\", data=df); plt.show()","49932214":"sns.countplot(x=\"Survived\", hue=\"Parch\",data=df); plt.show()","04c744e1":"df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","63dc52b1":"sns.barplot(x='Embarked', y=\"Survived\", data=df); plt.show()\nsns.countplot(x=\"Survived\", hue=\"Embarked\",data=df); plt.show()","bf3e504e":"df[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","53c9b300":"sns.barplot(x='SibSp', y=\"Survived\", data=df); plt.show()\nsns.countplot(x=\"Survived\", hue=\"SibSp\",data=df); plt.show()","e087bd45":"df.describe().T","8cae4fa8":"df.describe([0.05, 0.10, 0.25, 0.50, 0.75, 0.80, 0.90, 0.95, 0.99]).T","7f289bf8":"num_cols = [col for col in df.columns if df[col].dtypes != 'O' and col not in \"Id\"]\nprint('Number of Numerical Variables: ', len(num_cols))","c95180dd":"num_cols","b9ffe25d":"def hist_for_nums(data, numeric_cols):\n    col_counter = 0\n    data = data.copy()\n    for col in numeric_cols:\n        data[col].hist(bins=20)\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n        col_counter += 1\n    print(col_counter, \"variables have been plotted\")\n\nhist_for_nums(df, num_cols)\n","dac440b4":"df[\"Survived\"].value_counts()","2c4966a1":"fig1, ax1 = plt.subplots()\nax1.pie(df[\"Survived\"].value_counts(),  labels=['survive','not survive'], autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.show()","98b73d4a":"df.isnull().values.any()","c3e578b9":"df.isnull().sum()","ce01c499":"df['Age'].fillna(df['Age'].median(), inplace=True)\ndf['Fare'].fillna(df['Fare'].mean(), inplace=True)","449f79f5":"df['Embarked'].fillna('S', inplace=True)","feff83b0":"df.drop(['Cabin', 'PassengerId', 'Ticket'], axis=1, inplace=True)\n","b5937aeb":"df.isnull().sum()","91fb375a":"df = df.reset_index(drop=True)","a78feeb6":"df['title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ndf['title'] = df['title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\ndf['title'] = df['title'].replace('Mlle', 'Miss')\ndf['title'] = df['title'].replace('Ms', 'Miss')\ndf['title'] = df['title'].replace('Mme', 'Mrs')\ndf[['title', 'Survived']].groupby(['title'], as_index=False).mean()\nmyCoding = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5}\ndf['title'] = df['title'].map(myCoding)\ndf['title'] = df['title'].fillna(0)\n","9d8215dd":"df.head()","aaebc053":"df.info()\n","d6e9acee":"df.drop(['Name'], axis=1, inplace=True)","a7a36c37":"df.head()","3ca9d547":"df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\ndf['FamilySize'].value_counts()","412c559d":"sns.heatmap(df.isnull()); plt.show()","acc6cfc2":"df['Age*Class'] = df.Age * df.Pclass","779e95bb":"df.head()","49085492":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf[\"Sex\"]= le.fit_transform(df[\"Sex\"])","16cd2695":"def one_hot_encoder(dataframe):\n    dataframe = pd.get_dummies(dataframe, columns=[\"Embarked\",'title', 'Fare'], drop_first=True)\n    new_columns = [c for c in dataframe.columns if c not in original_columns]\n    return dataframe, new_columns\n","4bba5b3b":"df.drop(['Embarked', 'title', 'Fare'], axis=1 , inplace=True)","f1f7a8b3":"X = df.drop('Survived', axis=1)\ny = df[[\"Survived\"]]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=66)","fffb8d19":"knn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train,y_train) * 100, 2)\nacc_knn","0e06f4cd":"gaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\ny_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\nacc_gaussian","c209425d":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\ny_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\nacc_decision_tree","9c885235":"random_forest = RandomForestClassifier(n_estimators=46)\nrandom_forest.fit(X_train, y_train)\ny_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, y_train)\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\nacc_random_forest\n","46493232":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nacc_logreg = round(logreg.score(X_train, y_train) * 100, 2)\nacc_logreg\n","0859d157":"gbkk = GradientBoostingClassifier()\ngbkk.fit(X_train, y_train)\ngbk_pred = gbkk.predict(X_test)\nacc_gbkk = round(gbkk.score(X_train, y_train) * 100, 2)\nacc_gbkk","7b574905":"lgbm = LGBMClassifier(random_state=46)\nlgbm.fit(X_train, y_train)\nLgbm_pred = lgbm.predict(X_test)\nacc_lgbm = round(lgbm.score(X_train, y_train) * 100, 2)\nacc_lgbm","f17a3173":"models = pd.DataFrame({\n    'Model': [ 'KNN', \"LightGBM\",'Logistic Regression',\n              'Random Forest', 'Naive Bayes',\n              'Decision Tree', \"Gradient Boosting Classifier\"],\n    'Score': [ acc_knn, acc_logreg,\n              acc_random_forest, acc_gaussian,\n              acc_decision_tree, acc_gbkk, acc_lgbm]})\nmodels.sort_values(by='Score', ascending=False)\n","c78b7bad":"**6.1. Missing Values\n* Checking  missing value","92a49639":"# 8. MODELING","51b43a35":"**LightGBM**\n","0e98eaaa":"**Decision Tree\n**","5eb9b324":"For categorical columns (string columns), the missing values can be filled with mode. For numerical columns (float columns), the missing values can be filled with with mean.","5b52e845":"# 4. ANALYSIS of NUMERICAL VARIABLE","5a37affb":"# **Objective**\n\nThe primary aim of this study is to develop a machine learning model that predicts which passengers survived the Titanic shipwreck.","d02bf1f6":"# 1. IMPORT SOME NECESSARY LIBRARIES","d0a05682":"List of Variable: 'PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age',SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'","2eeb5e4c":"Passengers who embarked the ship in Cherbourg are more likely to survive.","125ad357":"One hot encoding was applied to categorical variables (two or more).\n","37da0fa7":"![](http:\/\/)![image.png](attachment:image.png)\nsource: Photo: Universal Images Group\/Getty Images","2615ee74":"\n**Visualization of variables**","9180682b":"**Survived**","3b46c764":"**Embarked**","172fe180":"**How many numeric variables are in the data set?\n**","78ca673e":"The Pclass type is related to the likelihood  of survival.","1f719a8b":"**Pclass**","ab77ef6c":"# **Introduction**\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew. While there was some element of luck involved in surviving,it seems some groups of people were more likely to survive than others.","3fcb9fa5":"In this section, first of all, categorical variables should be determined. Which variables in the data set are categorical?","1b139fe2":"Finding the number of values in the target column","36cfde0b":"**KNeighborsClassifier**\n","374feec2":"# 3. EXPLORATORY DATA ANALYSIS ON CATEGORICAL DATA","0056af8d":"# 2. Load Data","03d9834b":"Label encoding was applied to categorical variables.\n","afe8e468":"**SibSp**","919b3100":"After creating \"title\" feature, no necessary to keep \"Name\" feature in datasets.","e6496f51":"**LogisticRegression\n**","85f83942":"**Random Forest**\n","2fa94d6f":"**Visualization of numeric variables\n**","991a497b":"**Gaussian Naive Bayes**","67e1a3ac":"Parch type is related to the likelihood  of survival.","39cc8980":"SibSp is related to the probability of survival.","3c7694c4":"**Creating 'FamilySize' feature**","9de4490d":"# 3. UNDERSTANDING THE DATA-SET\n","02c90190":"**Creating new feature\n**","aa1a3b4b":"**Data Summary**\n\nThis dataset  is obtained from from https:\/\/www.kaggle.com\/c\/titanic\/data. The data-set has 1309 examples in which \n891 are from train data set, and 418 are from test data set. In this dataset,there is one dependent variable (survived) and twelve independent or predictor variables ('PassengerId','Survived', 'Pclass', 'Name', 'Sex', 'Age','SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked').","e177b15b":"Females are more likely to survive than males.","c5202280":"**Sex**","a7555fa2":"# 5. ANALYSIS of DEPENDENT VARIABLE (TARGET ANALYSIS)","532d0cbc":"# 6. DATA PREPROCESSING & FEATURE ENGINEERING\n","8edeab00":"**Parch**","e29618d6":"***The description of  variables in this data as follows:***\n\n**Dependent Variable**\n\nsurvival: Survival\t0 = No, 1 = Yes\"\"\"\n\n**Independent Variable**\n* pclass:\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n* sex:\tSex (Male\/Female)\n* Age:\tAge in years\n* sibsp:\t# of siblings \/ spouses aboard the Titanic\n* parch:\t# of parents \/ children aboard the Titanic\n* ticket:\tTicket number\n* fare:\tPassenger fare\n* cabin:\tCabin number\n* embarked:\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton","93af825c":"The index has been reorganized.\n","d9d8353a":"**Replacing missing data with its mean\n**","f40e2b71":"**Gradient Boosting Classifier\n**","648eff6c":"# 8. LABEL ENCODING & ONE-HOT ENCODING\n"}}