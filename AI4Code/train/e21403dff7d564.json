{"cell_type":{"26e75066":"code","51573c9b":"code","bbd2e647":"code","33920f0b":"code","28b6d0a9":"code","76b02447":"code","5fb37aad":"code","b5fa5c00":"code","b0c02235":"code","e194b475":"code","2c76a0eb":"code","d477d322":"code","255a523e":"code","7962d4c6":"code","a5d237e6":"code","27b35dd8":"code","701076d7":"code","71332ea5":"code","b6621b23":"code","6f1c4118":"code","50c5be56":"code","0463c955":"code","3aa30e47":"code","347485e4":"code","7fed79a5":"code","eefc4e89":"code","01f81307":"code","4973c85d":"code","35babfa8":"code","f6337d69":"code","009add7b":"code","e9c6bb81":"markdown","b295728c":"markdown","b2c76d5d":"markdown","bbb90df9":"markdown","eacff8e3":"markdown","a79b75f8":"markdown","6c34643e":"markdown","0e25c0b3":"markdown","87b0af70":"markdown","9b56d4a0":"markdown","0953d2fd":"markdown","fe241628":"markdown","358ffedc":"markdown","67b6e38c":"markdown","0b8536dd":"markdown","ea5282e3":"markdown","568000d9":"markdown","26dacb96":"markdown","00346770":"markdown","6642e743":"markdown","9d9a65a1":"markdown","c36a6db4":"markdown","d5816eae":"markdown","35ba736a":"markdown","5ffeebaf":"markdown","c579d916":"markdown","5d66db9b":"markdown","dfaf7dae":"markdown","ff8261d2":"markdown","c7d7bfde":"markdown","8c327143":"markdown","6cd4dd1a":"markdown","a4e231e2":"markdown","ec12f002":"markdown","ac6af4fa":"markdown","63ff40cf":"markdown","efd0a092":"markdown","fd928df0":"markdown","49e68bee":"markdown","c61300c8":"markdown","a7aa661d":"markdown","0e82ed54":"markdown","d9e01448":"markdown","a768fe7c":"markdown"},"source":{"26e75066":"!pip install --upgrade pip\n!pip install pymap3d==2.1.0\n!pip install -U l5kit","51573c9b":"from IPython.display import HTML\nHTML('<center><iframe width=\"700\" height=\"400\" src=\"https:\/\/www.youtube.com\/embed\/tlThdr3O5Qo?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen><\/iframe><\/center>')","bbd2e647":"import l5kit, os\nfrom l5kit.rasterization import build_rasterizer\nfrom l5kit.configs import load_config_data\nfrom l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR\nfrom l5kit.geometry import transform_points\nfrom tqdm import tqdm\nfrom collections import Counter\nfrom l5kit.data import PERCEPTION_LABELS\nfrom prettytable import PrettyTable\n# \u30c7\u30fc\u30bf\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\u3059\u308b\nos.environ[\"L5KIT_DATA_FOLDER\"] = \"..\/input\/lyft-motion-prediction-autonomous-vehicles\"\n# \u53d6\u5f97\u8a2d\u5b9a\ncfg = load_config_data(\"..\/input\/lyft-config-files\/visualisation_config.yaml\")\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","33920f0b":"from l5kit.data import ChunkedDataset, LocalDataManager\nfrom l5kit.dataset import EgoDataset, AgentDataset\ndm = LocalDataManager()\ndataset_path = dm.require(cfg[\"val_data_loader\"][\"key\"])\nzarr_dataset = ChunkedDataset(dataset_path)\nzarr_dataset.open()\nprint(zarr_dataset)","28b6d0a9":"import numpy as np\nfrom IPython.display import display, clear_output\nimport PIL\n \ncfg[\"raster_params\"][\"map_type\"] = \"py_semantic\"\nrast = build_rasterizer(cfg, dm)\ndataset = EgoDataset(cfg, zarr_dataset, rast)\nscene_idx = 2\nindexes = dataset.get_scene_indices(scene_idx)\nimages = []\n\nfor idx in indexes:\n    \n    data = dataset[idx]\n    im = data[\"image\"].transpose(1, 2, 0)\n    im = dataset.rasterizer.to_rgb(im)\n    target_positions_pixels = transform_points(data[\"target_positions\"] + data[\"centroid\"][:2], data[\"world_to_image\"])\n    center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n    draw_trajectory(im, target_positions_pixels, data[\"target_yaws\"], TARGET_POINTS_COLOR)\n    clear_output(wait=True)\n    display(PIL.Image.fromarray(im[::-1]))","76b02447":"import numpy as np\nfrom IPython.display import display, clear_output\nimport PIL\n \ncfg[\"raster_params\"][\"map_type\"] = \"py_satellite\"\nrast = build_rasterizer(cfg, dm)\ndataset = EgoDataset(cfg, zarr_dataset, rast)\nscene_idx = 2\nindexes = dataset.get_scene_indices(scene_idx)\nimages = []\n\nfor idx in indexes:\n    \n    data = dataset[idx]\n    im = data[\"image\"].transpose(1, 2, 0)\n    im = dataset.rasterizer.to_rgb(im)\n    target_positions_pixels = transform_points(data[\"target_positions\"] + data[\"centroid\"][:2], data[\"world_to_image\"])\n    center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n    draw_trajectory(im, target_positions_pixels, data[\"target_yaws\"], TARGET_POINTS_COLOR)\n    clear_output(wait=True)\n    display(PIL.Image.fromarray(im[::-1]))","5fb37aad":"from IPython.display import display, clear_output\nfrom IPython.display import HTML\n\nimport PIL\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation, rc\ndef animate_solution(images):\n\n    def animate(i):\n        im.set_data(images[i])\n \n    fig, ax = plt.subplots()\n    im = ax.imshow(images[0])\n    \n    return animation.FuncAnimation(fig, animate, frames=len(images), interval=60)\ncfg[\"raster_params\"][\"map_type\"] = \"py_satellite\"\nrast = build_rasterizer(cfg, dm)\ndataset = EgoDataset(cfg, zarr_dataset, rast)\nscene_idx = 34\nindexes = dataset.get_scene_indices(scene_idx)\nimages = []\n\nfor idx in indexes:\n    \n    data = dataset[idx]\n    im = data[\"image\"].transpose(1, 2, 0)\n    im = dataset.rasterizer.to_rgb(im)\n    target_positions_pixels = transform_points(data[\"target_positions\"] + data[\"centroid\"][:2], data[\"world_to_image\"])\n    center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n    draw_trajectory(im, target_positions_pixels, data[\"target_yaws\"], TARGET_POINTS_COLOR)\n    clear_output(wait=True)\n    images.append(PIL.Image.fromarray(im[::-1]))\nanim = animate_solution(images)\nHTML(anim.to_jshtml())","b5fa5c00":"from IPython.display import display, clear_output\nfrom IPython.display import HTML\n\nimport PIL\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation, rc\ndef animate_solution(images):\n\n    def animate(i):\n        im.set_data(images[i])\n \n    fig, ax = plt.subplots()\n    im = ax.imshow(images[0])\n    \n    return animation.FuncAnimation(fig, animate, frames=len(images), interval=60)\ncfg[\"raster_params\"][\"map_type\"] = \"py_semantic\"\nrast = build_rasterizer(cfg, dm)\ndataset = EgoDataset(cfg, zarr_dataset, rast)\nscene_idx = 34\nindexes = dataset.get_scene_indices(scene_idx)\nimages = []\n\nfor idx in indexes:\n    \n    data = dataset[idx]\n    im = data[\"image\"].transpose(1, 2, 0)\n    im = dataset.rasterizer.to_rgb(im)\n    target_positions_pixels = transform_points(data[\"target_positions\"] + data[\"centroid\"][:2], data[\"world_to_image\"])\n    center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n    draw_trajectory(im, target_positions_pixels, data[\"target_yaws\"], TARGET_POINTS_COLOR)\n    clear_output(wait=True)\n    images.append(PIL.Image.fromarray(im[::-1]))\nanim = animate_solution(images)\nHTML(anim.to_jshtml())","b0c02235":"from IPython.display import display, clear_output\nimport PIL\n \ncfg[\"raster_params\"][\"map_type\"] = \"py_semantic\"\nrast = build_rasterizer(cfg, dm)\ndataset = EgoDataset(cfg, zarr_dataset, rast)\nscene_idx = 34\nindexes = dataset.get_scene_indices(scene_idx)\nimages = []\n\nfor idx in indexes:\n    \n    data = dataset[idx]\n    im = data[\"image\"].transpose(1, 2, 0)\n    im = dataset.rasterizer.to_rgb(im)\n    target_positions_pixels = transform_points(data[\"target_positions\"] + data[\"centroid\"][:2], data[\"world_to_image\"])\n    center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n    draw_trajectory(im, target_positions_pixels, data[\"target_yaws\"], TARGET_POINTS_COLOR)\n    clear_output(wait=True)\n    images.append(PIL.Image.fromarray(im[::-1]))\n    \nanim = animate_solution(images)\nHTML(anim.to_jshtml())","e194b475":"import numpy as np\nfrom IPython.display import display, clear_output\nimport PIL\n \ncfg[\"raster_params\"][\"map_type\"] = \"py_satellite\"\nrast = build_rasterizer(cfg, dm)\ndataset = AgentDataset(cfg, zarr_dataset, rast)\nscene_idx = 2\nindexes = dataset.get_scene_indices(scene_idx)\nimages = []\n\nfor idx in indexes:\n    \n    data = dataset[idx]\n    im = data[\"image\"].transpose(1, 2, 0)\n    im = dataset.rasterizer.to_rgb(im)\n    target_positions_pixels = transform_points(data[\"target_positions\"] + data[\"centroid\"][:2], data[\"world_to_image\"])\n    center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n    draw_trajectory(im, target_positions_pixels, data[\"target_yaws\"], TARGET_POINTS_COLOR)\n    clear_output(wait=True)\n    display(PIL.Image.fromarray(im[::-1]))","2c76a0eb":"import numpy as np\nfrom IPython.display import display, clear_output\nimport PIL\n \ncfg[\"raster_params\"][\"map_type\"] = \"py_semantic\"\nrast = build_rasterizer(cfg, dm)\ndataset = AgentDataset(cfg, zarr_dataset, rast)\nscene_idx = 2\nindexes = dataset.get_scene_indices(scene_idx)\nimages = []\n\nfor idx in indexes:\n    \n    data = dataset[idx]\n    im = data[\"image\"].transpose(1, 2, 0)\n    im = dataset.rasterizer.to_rgb(im)\n    target_positions_pixels = transform_points(data[\"target_positions\"] + data[\"centroid\"][:2], data[\"world_to_image\"])\n    center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n    draw_trajectory(im, target_positions_pixels, data[\"target_yaws\"], TARGET_POINTS_COLOR)\n    clear_output(wait=True)\n    display(PIL.Image.fromarray(im[::-1]))","d477d322":"from l5kit.data.map_api import MapAPI\nfrom l5kit.rasterization.rasterizer_builder import _load_metadata\n\nsemantic_map_filepath = dm.require(cfg[\"raster_params\"][\"semantic_map_key\"])\ndataset_meta = _load_metadata(cfg[\"raster_params\"][\"dataset_meta_key\"], dm)\nworld_to_ecef = np.array(dataset_meta[\"world_to_ecef\"], dtype=np.float64)\n\nmap_api = MapAPI(semantic_map_filepath, world_to_ecef)\nMAP_LAYERS = [\"junction\", \"node\", \"segment\", \"lane\"]\n\n\ndef element_of_type(elem, layer_name):\n    return elem.element.HasField(layer_name)\n\n\ndef get_elements_from_layer(map_api, layer_name):\n    return [elem for elem in map_api.elements if element_of_type(elem, layer_name)]\n\n\nclass MapRenderer:\n    \n    def __init__(self, map_api):\n        self._color_map = dict(drivable_area='#a6cee3',\n                               road_segment='#1f78b4',\n                               road_block='#b2df8a',\n                               lane='#474747')\n        self._map_api = map_api\n    \n    def render_layer(self, layer_name):\n        fig = plt.figure(figsize=(10, 10))\n        ax = fig.add_axes([0, 0, 1, 1])\n        \n    def render_lanes(self):\n        all_lanes = get_elements_from_layer(self._map_api, \"lane\")\n        fig = plt.figure(figsize=(10, 10))\n        ax = fig.add_axes([0, 0, 1, 1])\n        for lane in all_lanes:\n            self.render_lane(ax, lane)\n        return fig, ax\n        \n    def render_lane(self, ax, lane):\n        coords = self._map_api.get_lane_coords(MapAPI.id_as_str(lane.id))\n        self.render_boundary(ax, coords[\"xyz_left\"])\n        self.render_boundary(ax, coords[\"xyz_right\"])\n        \n    def render_boundary(self, ax, boundary):\n        xs = boundary[:, 0]\n        ys = boundary[:, 1] \n        ax.plot(xs, ys, color=self._color_map[\"lane\"], label=\"lane\")\n        \n        \nrenderer = MapRenderer(map_api)\nfig, ax = renderer.render_lanes()","255a523e":"def visualize_rgb_image(dataset, index, title=\"\", ax=None):\n    \"\"\"Visualizes Rasterizer's RGB image\"\"\"\n    data = dataset[index]\n    im = data[\"image\"].transpose(1, 2, 0)\n    im = dataset.rasterizer.to_rgb(im)\n\n    if ax is None:\n        fig, ax = plt.subplots()\n    if title:\n        ax.set_title(title)\n    ax.imshow(im[::-1])\n# Prepare all rasterizer and EgoDataset for each rasterizer\nrasterizer_dict = {}\ndataset_dict = {}","7962d4c6":"\n\nrasterizer_type_list = [\"py_satellite\", \"satellite_debug\", \"py_semantic\", \"semantic_debug\", \"box_debug\", \"stub_debug\"]\n\nfor i, key in enumerate(rasterizer_type_list):\n    # print(\"key\", key)\n    cfg[\"raster_params\"][\"map_type\"] = key\n    rasterizer_dict[key] = build_rasterizer(cfg, dm)\n    dataset_dict[key] = EgoDataset(cfg, zarr_dataset, rasterizer_dict[key])\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\naxes = axes.flatten()\nfor i, key in enumerate([\"stub_debug\", \"satellite_debug\", \"semantic_debug\", \"box_debug\", \"py_satellite\", \"py_semantic\"]):\n    visualize_rgb_image(dataset_dict[key], index=0, title=f\"{key}: {type(rasterizer_dict[key]).__name__}\", ax=axes[i])\nfig.show()","a5d237e6":"print(\"scenes\", zarr_dataset.scenes)\nprint(\"scenes[0]\", zarr_dataset.scenes[0])","27b35dd8":"import pandas as pd\nscenes = zarr_dataset.scenes\nscenes_df = pd.DataFrame(scenes)\nscenes_df.columns = [\"data\"]; features = ['frame_index_interval', 'host', 'start_time', 'end_time']\nfor i, feature in enumerate(features):\n    scenes_df[feature] = scenes_df['data'].apply(lambda x: x[i])\nscenes_df.drop(columns=[\"data\"],inplace=True)\nprint(f\"scenes dataset: {scenes_df.shape}\")\nscenes_df.head()","701076d7":"agents = pd.read_csv('..\/input\/lyft-motion-prediction-autonomous-vehicles-as-csv\/agents_0_10019001_10019001.csv')\nagents","71332ea5":"import seaborn as sns\ncolormap = plt.cm.magma\ncont_feats = [\"centroid_x\", \"centroid_y\", \"extent_x\", \"extent_y\", \"extent_z\", \"yaw\"]\nplt.figure(figsize=(16,12));\nplt.title('Pearson correlation of features', y=1.05, size=15);\nsns.heatmap(agents[cont_feats].corr(),linewidths=0.1,vmax=1.0, square=True, \n            cmap=colormap, linecolor='white', annot=True);\n","b6621b23":"import seaborn as sns\nplot = sns.jointplot(x=agents['centroid_x'][:1000], y=agents['centroid_y'][:1000], kind='hexbin', color='blueviolet')\nplot.set_axis_labels('center_x', 'center_y', fontsize=16)\n\nplt.show()","6f1c4118":"fig = plt.figure(figsize=(15, 15));\nsns.distplot(agents['centroid_x'], color='steelblue');\nsns.distplot(agents['centroid_y'], color='purple');\nplt.title(\"Distributions of Centroid X and Y\");","50c5be56":"fig = plt.figure(figsize=(15, 15));\nsns.distplot(agents['extent_x'], color='steelblue');\nsns.distplot(agents['extent_y'], color='purple');\n\nplt.title(\"Distributions of Extents X and Y\");","0463c955":"fig = plt.figure(figsize=(15, 15));\nsns.distplot(agents['extent_z'], color='steelblue');\n\nplt.title(\"Distributions of Extents z\");","3aa30e47":"fig = plt.figure(figsize=(15, 15));\nsns.distplot(agents['yaw'], color='steelblue');\n\nplt.title(\"Distributions of Extents z\");","347485e4":"frms = pd.read_csv(\"..\/input\/lyft-motion-prediction-autonomous-vehicles-as-csv\/frames_0_124167_124167.csv\")\nfrms.head()","7fed79a5":"import seaborn as sns\ncolormap = plt.cm.magma\ncont_feats = [\"ego_rotation_xx\", \"ego_rotation_xy\", \"ego_rotation_xz\", \"ego_rotation_yx\", \"ego_rotation_yy\", \"ego_rotation_yz\", \"ego_rotation_zx\", \"ego_rotation_zy\", \"ego_rotation_zz\"]\nplt.figure(figsize=(16,12));\nplt.title('Pearson correlation of features', y=1.05, size=15);\nsns.heatmap(frms[cont_feats].corr(),linewidths=0.1,vmax=1.0, square=True, \n            cmap=colormap, linecolor='white', annot=True);\n","eefc4e89":"import numpy as np\nzero_count_list, one_count_list = [], []\ncols_list = [\"label_probabilities_PERCEPTION_LABEL_UNKNOWN\",\"label_probabilities_PERCEPTION_LABEL_CAR\",\"label_probabilities_PERCEPTION_LABEL_CYCLIST\",\"label_probabilities_PERCEPTION_LABEL_PEDESTRIAN\"]\nfor col in cols_list:\n    zero_count_list.append((agents[col]==0).sum())\n    one_count_list.append((agents[col]==1).sum())\n\nN = len(cols_list)\nind = np.arange(N)\nwidth = 0.35\n\nplt.figure(figsize=(6,10))\np1 = plt.barh(ind, zero_count_list, width, color='purple')\np2 = plt.barh(ind, one_count_list, width, left=zero_count_list, color=\"steelblue\")\nplt.yticks(ind, cols_list)\nplt.legend((p1[0], p2[0]), ('Zero count', 'One Count'))\nplt.show()","01f81307":"\"\"\"\"\"\"\nimport json, random\ndef parse_demo(col):\n    bigtxt = \";\".join(df[col].dropna())\n    wrds = bigtxt.split(\";\")\n    wrds = Counter(wrds).most_common()\n    return wrds \n\nstrr = \"id,value,color\\nAudience Demographics,\\n\"\ndemographics = ['Gender', 'Age', 'SexualOrientation', 'RaceEthnicity', 'EducationParents', 'Dependents']\n#demographics = ['Gender', 'Age', 'SexualOrientation', 'RaceEthnicity', 'EducationParents']\ncolors = ['#5b9aff', '#ff77bd', '#82ff8a', '#9b9493', '#5b9aff', '#ff77bd', '#82ff8a', '#9b9493']\nfor i,col in enumerate(demographics):\n    strr += \"Audience Demographics.\" + col + \",\\n\"\n    \n    response = parse_demo(col)\n    total = sum([x[1] for x in response])\n    for term in response:\n        cent = float(term[1])*100 \/ total\n        strr += \"Audience Demographics.\" + col +\".\"+ term[0].split(\"(\")[0].replace(\",\",\"\") +\",\"+ str(cent) + \",\"+colors[i]+\"\\n\"\n\nfout = open(\"tomdata.csv\", \"w\")\n\nfout.write(strr)\n\n\n\nhtml2 =\"\"\" <style>\n.link {\n        fill: none;\n        stroke: #555;\n        stroke-opacity: 0.4;\n        stroke-width: 1px;\n    }\n    text {\n        font-family: \"Arial Black\", Gadget, sans-serif;\n        fill: black;\n        font-weight: bold;\n        font-size: 14px\n    }\n\n    .xAxis .tick text{\n        fill: black;\n    }\n    \n    .grid .tick line{\n        stroke: grey;\n        stroke-dasharray: 5, 10;\n        opacity: 0.7;\n    }\n    .grid path{\n        stroke-width: 0;\n    }\n\n    .node1 circle {\n        fill: #999;\n    }\n    .node1--internal circle {\n        fill: #555;\n    }\n    .node1--internal text {\n        font-size: 16px;\n        text-shadow: 0 2px 0 #fff, 0 -2px 0 #fff, 2px 0 0 #fff, -2px 0 0 #fff;\n    }\n    .node1--leaf text {\n        fill: white;\n    }\n    .ballG text {\n        fill: white;\n    }\n\n    .shadow {\n        -webkit-filter: drop-shadow( -1.5px -1.5px 1.5px #000 );\n        filter: drop-shadow( -1.5px -1.5px 1.5px #000 );\n    }<\/style>\n    <body>\n    <br><br>\n    <svg id=\"five\" width=\"900\" height=\"1200\"><\/svg>\n    <br><br><br>\n<\/body>\n\"\"\"\n\n\njs2 = \"\"\"\n \n require([\"d3\"], function(d3) {\n  \n    var svg1 = d3.select(\"#five\"),\n            width = +svg1.attr(\"width\"),\n            height = +svg1.attr(\"height\"),\n            g1 = svg1.append(\"g\").attr(\"transform\", \"translate(20,10)\");       \/\/ move right 20px.\n            \n    var xScale =  d3.scaleLinear()\n            .domain([0,100])\n            .range([0, 400]);\n\n    var xAxis = d3.axisTop()\n            .scale(xScale);\n\n    \/\/ Setting up a way to handle the data\n    var tree1 = d3.cluster()                 \/\/ This D3 API method setup the Dendrogram datum position.\n            .size([height, width - 550])    \/\/ Total width - bar chart width = Dendrogram chart width\n            .separation(function separate(a, b) {\n                return a.parent == b.parent            \/\/ 2 levels tree1 grouping for category\n                || a.parent.parent == b.parent\n                || a.parent == b.parent.parent ? 0.4 : 0.8;\n            });\n\n    var stratify = d3.stratify()            \/\/ This D3 API method gives cvs file flat data array dimensions.\n            .parentId(function(d) { return d.id.substring(0, d.id.lastIndexOf(\".\")); });","4973c85d":"from typing import Dict\n!pip install pytorch-lightning\n\nfrom tempfile import gettempdir\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.models.resnet import resnet18\nfrom tqdm import tqdm\nfrom l5kit.configs import load_config_data\nfrom l5kit.data import LocalDataManager, ChunkedDataset\nfrom l5kit.dataset import AgentDataset, EgoDataset\nfrom l5kit.rasterization import build_rasterizer\nfrom l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\nfrom l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\nfrom l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\nfrom l5kit.geometry import transform_points\nfrom l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\nfrom prettytable import PrettyTable\nfrom pathlib import Path\nimport pytorch_lightning as pl\nimport os\ncfg = load_config_data('..\/input\/lyft-config-files\/agent_motion_config.yaml')\nclass Mod(torch.nn.Module):\n    def __init__(self, cfg: Dict):\n        super(Mod, self).__init__()\n        self.backbone = resnet18(pretrained=False)\n        \n        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n        num_in_channels = 3 + num_history_channels\n\n        self.backbone.conv1 = nn.Conv2d(\n            num_in_channels,\n            self.backbone.conv1.out_channels,\n            kernel_size=self.backbone.conv1.kernel_size,\n            stride=self.backbone.conv1.stride,\n            padding=self.backbone.conv1.padding,\n            bias=False,\n        )\n        \n        # This is 512 for resnet18 and resnet34;\n        # And it is 2048 for the other resnets\n        backbone_out_features = 512\n\n        # X, Y coords for the future positions (output shape: Bx50x2)\n        num_targets = 2 * cfg[\"model_params\"][\"future_num_frames\"]\n\n        # You can add more layers here.\n        self.head = nn.Sequential(\n            # nn.Dropout(0.2),\n            nn.Linear(in_features=backbone_out_features, out_features=4096),\n        )\n\n        self.logit = nn.Linear(4096, out_features=num_targets)\n    def forward(self):\n        x = self.backbone.conv1(x)\n        x = self.backbone.bn1(x)\n        x = self.backbone.relu(x)\n        x = self.backbone.maxpool(x)\n\n        x = self.backbone.layer1(x)\n        x = self.backbone.layer2(x)\n        x = self.backbone.layer3(x)\n        x = self.backbone.layer4(x)\n\n        x = self.backbone.avgpool(x)\n        x = torch.flatten(x, 1)\n        \n        x = self.head(x)\n        x = self.logit(x)\n        \n        return x        \n\ndef forward(data, model, device, criterion):\n    inputs = data[\"image\"].to(device)\n    target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n    targets = data[\"target_positions\"].to(device)\n    # Forward pass\n    outputs = model(inputs).reshape(targets.shape)\n    loss = criterion(outputs, targets)\n    # not all the output steps are valid, but we can filter them out from the loss using availabilities\n    loss = loss * target_availabilities\n    loss = loss.mean()\n    return loss, outputs\n\nclass LightningLyft(pl.LightningModule):\n    def __init__(self, model):\n        super(LightningLyft, self).__init__()\n        self.model = model\n        \n    def forward(self, x, *args, **kwargs):\n        return self.model(x)\n    \n    def prepare_train_data(self):\n        train_cfg = cfg[\"train_data_loader\"]\n        rasterizer = build_rasterizer(cfg, dm)\n        train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n        train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n        train_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"], batch_size=train_cfg[\"batch_size\"], \n                             num_workers=train_cfg[\"num_workers\"])\n        return train_dataloader\n            \n    def training_step(self, batch, batch_idx):\n        tr_it = iter(train_dataloader)\n        progress_bar = tqdm(range(cfg[\"train_params\"][\"max_num_steps\"]))\n        losses_train = []\n        model = self.model\n        for n in [0, 1, 2 , 3, 4]:\n            try:\n                data = next(tr_it)\n            except StopIteration:\n                tr_it = iter(train_dataloader)\n                data = next(tr_it)\n            model.train()\n            torch.set_grad_enabled(True)\n            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n            optimizer = optim.Adam(model.parameters(), lr=1e-3)\n            criterion = nn.MSELoss(reduction=\"none\")\n            loss, _ = forward(data, model, device, criterion)\n\n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            losses_train.append(loss.item())\n            print(f\"LOSS FOR EPOCH {n}: {loss.item()}\")\n            \n    def configure_optimizers(self):\n        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n        return optimizer","35babfa8":"# ===== INIT DATASET\ntrain_cfg = cfg[\"train_data_loader\"]\nrasterizer = build_rasterizer(cfg, dm)\ntrain_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\ntrain_dataset = AgentDataset(cfg, train_zarr, rasterizer)\ntrain_dataloader = DataLoader(train_dataset, shuffle=train_cfg[\"shuffle\"], batch_size=train_cfg[\"batch_size\"], \n                             num_workers=train_cfg[\"num_workers\"])","f6337d69":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = Mod(cfg).to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.MSELoss(reduction=\"none\")","009add7b":"# ==== TRAIN LOOP\nres = []\ntr_it = iter(train_dataloader)\nmodel = LightningLyft(build_model(cfg))\nprogress_bar = tqdm(range(cfg[\"train_params\"][\"max_num_steps\"]))\nlosses_train = []\nfor _ in progress_bar:\n    try:\n        data = next(tr_it)\n    except StopIteration:\n        tr_it = iter(train_dataloader)\n        data = next(tr_it)\n    model.train()\n    torch.set_grad_enabled(True)\n    loss, _ = forward(data, model, device, criterion)\n    res.append(_)\n    # Backward pass\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    losses_train.append(loss.item())\n    progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")","e9c6bb81":"\u3057\u304b\u3057\u73fe\u5728\u306f\u3001\u30b7\u30fc\u30f3\u3092\u898b\u3066\u6df1\u304f\u5206\u6790\u3059\u308b\u6642\u3067\u3059\u3002\u7406\u8ad6\u7684\u306b\u306f\u79c1\u305f\u3061\u306e\u305f\u3081\u306b\u91cd\u52b4\u50cd\u3092\u3057\u3066\u304f\u308c\u308b\u6c17\u306e\u5229\u3044\u305f\u5c0f\u3055\u306a\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u3092\u4f5c\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002","b295728c":"\u3068\u3044\u3046\u308f\u3051\u3067\u3001\u3053\u306e\u4e00\u679a\u306e\u753b\u50cf\u306b\u306f\u305f\u304f\u3055\u3093\u306e\u60c5\u5831\u304c\u8a70\u307e\u3063\u3066\u3044\u307e\u3059\u3002\u9811\u5f35\u3063\u3066\u6307\u6458\u3057\u3066\u3044\u304d\u307e\u3059\u304c\u3001\u4f55\u304b\u9593\u9055\u3044\u304c\u3042\u3063\u305f\u3089\u77e5\u3089\u305b\u3066\u304f\u3060\u3055\u3044\u3002\u3067\u306f\u3001\u753b\u50cf\u3092\u5206\u89e3\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n+ \u3053\u3053\u306b4\u3064\u306e\u9053\u8def\u304c\u4ea4\u5dee\u3057\u3066\u3044\u307e\u3059\u3002\n+ \u7dd1\u306e\u30d6\u30ed\u30d6\u306f\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u52d5\u304d\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u304c\u3001\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u3053\u306e\u3088\u3046\u306a\u4ea4\u901a\u72b6\u6cc1\u3067\u306e\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u52d5\u304d\u3092\u4e88\u6e2c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002","b2c76d5d":"\u3053\u3053\u306b\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u304a\u306a\u3058\u307f\u306e\u6a5f\u80fd\u3092\u542b\u3080\u3001\u79c1\u305f\u3061\u306e\u305f\u3081\u306b\u4f7f\u7528\u3067\u304d\u308b\u8c4a\u5bcc\u306a\u60c5\u5831\u304c\u3042\u308a\u307e\u3059\u3002\n1. x, y, \u304a\u3088\u3073 z \u306e\u5171\u7dda\u6027\n2. \u504f\u8d70\n3. \u305d\u306e\u4ed6\u306e\u5916\u90e8\u8981\u56e0\u306e\u78ba\u7387","bbb90df9":"\u753b\u50cf\u3092\u63a2\u7d22\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u305f\u306e\u3067\u3001ZARR\u30d5\u30a1\u30a4\u30eb\u306b\u3064\u3044\u3066\u3082\u5c11\u3057\u8a73\u3057\u304f\u8abf\u3079\u3066\u307f\u307e\u3057\u3087\u3046\u3002Python\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u4f7f\u3063\u3066\u63a2\u7d22\u3059\u308b\u306e\u306f\u304b\u306a\u308a\u7c21\u5358\u3067\u3001\u7279\u306bNumPy\u3068\u306e\u76f8\u4e92\u904b\u7528\u6027\u304c\u3042\u308b\u3068\u3044\u3046\u70b9\u3067\u306f\u3001\u3068\u3066\u3082\u4fbf\u5229\u3067\u3059\u3002","eacff8e3":"\u307e\u305a\u7b2c\u4e00\u306b\u3001\u305d\u308c\u305e\u308c\u306b\u5bfe\u5fdc\u3059\u308b9\u3064\u306e\u81ea\u5df1\u56de\u8ee2\u5217\u304c\u3042\u308a\u307e\u3059\u3002\u305d\u3053\u3067\u3001\u3088\u308a\u9ad8\u5ea6\u306a\u5206\u6790\u306b\u79fb\u308b\u524d\u306b\u3001\u3053\u308c\u3089\u306e\u5909\u6570\u306e\u76f8\u95a2\u95a2\u4fc2\u3092\u7c21\u5358\u306b\u30c1\u30a7\u30c3\u30af\u3057\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002","a79b75f8":"# \u30e1\u30bf\u30c7\u30fc\u30bf\u306e\u63a2\u7d22","6c34643e":"\u3053\u3053\u3067\u306f\u3001 **centroid_x** \u3068 **centroid_y** \u3068\u3044\u3046\u5909\u6570\u306b\u306f\u5f37\u3044\u8ca0\u306e\u76f8\u95a2\u304c\u3042\u308a\u3001\u6700\u3082\u5f37\u3044\u76f8\u95a2\u306f **extent_z** \u3068 **extent_x** \u306e\u9593\u306e\u3082\u306e\u3067\u30010.4 \u3068\u306a\u3063\u3066\u3044\u307e\u3059\u3002\u307e\u305f\u3001\u3053\u306e\u554f\u984c\u306e\u4ee3\u66ff\u7684\u306a\u30a2\u30d7\u30ed\u30fc\u30c1\u3068\u3057\u3066\u3001kkiller\u6c0f\u304c\u5f7c\u306e\u7d20\u6674\u3089\u3057\u3044\u30ab\u30fc\u30cd\u30eb\u3067\u5b9f\u8a3c\u3057\u305f\u3088\u3046\u306b\u3001XGBoost\/LightGBM\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u3066\u307f\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002","0e25c0b3":"\u307e\u305f\u3001matplotlib\u578b\u306e\u8996\u70b9\u304b\u3089\u5168\u4f53\u50cf\u3092\u6349\u3048\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002 [\u3053\u306e\u7d20\u6674\u3089\u3057\u3044\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3092\u5f15\u7528\u3044\u305f\u3057\u307e\u3059\u3002](https:\/\/www.kaggle.com\/t3nyks\/lyft-working-with-map-api)","87b0af70":"centroid_x\u306e\u53f3\u306b\u6b6a\u3093\u3060\u5206\u5e03\u306f\u3001 centroid_y\u306e\u305d\u308c\u3088\u308a\u3082\u304b\u306a\u308a\u6975\u7aef\u306a\u3088\u3046\u3067\u3059\u3002\u3069\u3061\u3089\u306e\u5206\u5e03\u3082\u975e\u5e38\u306b\u4f3c\u3066\u3044\u307e\u305b\u3093\u3002","9b56d4a0":"\u3053\u306e\u76f8\u95a2\u5206\u6790\u304b\u3089\u6ce8\u610f\u3059\u3079\u304d\u3053\u3068\n1. y` \u3068 `z` \u306e\u56de\u8ee2\u5ea7\u6a19\u306f\u307b\u3068\u3093\u3069\u306e\u5834\u5408\u3001\u76f8\u95a2\u304c\u306a\u3044\u3088\u3046\u306b\u898b\u3048\u308b\u3002\n2. `x` \u3092\u6301\u3064\u5ea7\u6a19\u306f z \u6b21\u5143\u306e\u56de\u8ee2\u3068\u5f37\u304f\u76f8\u95a2\u3057\u3066\u3044\u308b (\u3053\u308c\u306f\u4f55\u304b\u3092\u793a\u3057\u3066\u3044\u308b\u306e\u3060\u308d\u3046\u304b\uff1f)","0953d2fd":"### \u504f\u8d70","fe241628":"\u3053\u308c\u3089\u3092GIF\u3068\u3057\u3066\u4fdd\u5b58\u3057\u3066\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u52d5\u304d\u3092\u53ef\u8996\u5316\u3057\u305f\u65b9\u304c\u3044\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\u3053\u308c\u3092\u3082\u3063\u3068\u30b7\u30f3\u30d7\u30eb\u306a\u5f62\u3067\u8a66\u3057\u3066\u307f\u3066\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d3\u30e5\u30fc\u3092\u4f7f\u3063\u3066\u307f\u307e\u3057\u3087\u3046\u3002","358ffedc":"d3.js\u3092\u4f7f\u3063\u305f\u30d0\u30a4\u30ca\u30ea\u6a5f\u80fd\u306e\u30af\u30a4\u30c3\u30af\u30c1\u30a7\u30c3\u30af - \u30b0\u30e9\u30d5\u30a3\u30c3\u30af\u306e\u30ec\u30f3\u30c0\u30ea\u30f3\u30b0\u306b\u6642\u9593\u304c\u304b\u304b\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002","67b6e38c":"\u3053\u308c\u306f\u4e3b\u306b\u79c1\u304cLyft\u306e\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u3066\u3001\u63d0\u4f9b\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067PyTorch\u30e2\u30c7\u30eb\u306b\u3069\u306e\u3088\u3046\u306b\u30d5\u30a3\u30c3\u30c8\u3059\u308b\u304b\u3092\u5b9f\u6f14\u3059\u308b\u305f\u3081\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3057\u3066\u3044\u308b\u3082\u306e\u3067\u3059\u3002\n\n\u307e\u305f\u3001PyTorch Lightning\u3068\u305d\u308c\u306b\u4ed8\u968f\u3059\u308b\u3059\u3079\u3066\u306e\u5229\u70b9\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002PL-Lightning\u306b\u3064\u3044\u3066\u306f\u3001\u5f8c\u3067\u8a73\u3057\u304f\u8aac\u660e\u3057\u307e\u3059\u3002","0b8536dd":"\u30ea\u30d5\u30c8\u306e\u30ec\u30d9\u30eb5\u30ad\u30c3\u30c8\u3068\u305d\u308c\u306b\u4ed8\u5c5e\u3059\u308b\u3059\u3079\u3066\u306e\u3082\u306e\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002","ea5282e3":"### \u4e8c\u5024\u7279\u5fb4","568000d9":"2\u3064\u306e\u30bb\u30f3\u30c8\u30ed\u30a4\u30c9\u304c\u3084\u3084\u5f37\u3044\u8ca0\u306e\u76f8\u95a2\u3068\u3001\u4e00\u898b\u4f3c\u305f\u3088\u3046\u306a\u5909\u6570\u5206\u5e03\u3092\u6301\u3063\u3066\u3044\u308b\u3088\u3046\u306b\u898b\u3048\u307e\u3059\u3002\u4e21\u65b9\u306e\u5909\u6570\u306e\u9593\u306b\u8ca0\u306e\u76f8\u95a2\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u3002","26dacb96":"\u3082\u3046\u4e00\u5ea6\u8a00\u3044\u307e\u3059\u304c\u3001\u3059\u3079\u3066\u306e `extent` \u5909\u6570\u3068\u540c\u3058\u3088\u3046\u306b\u3001\u53f3\u306b\u6b6a\u3093\u3060\u5206\u5e03\u3092\u6301\u3063\u3066\u3044\u307e\u3059\u3002","00346770":"\u3057\u304b\u3057\u3001\u79c1\u305f\u3061\u306f\u3053\u308c\u3067\u5341\u5206\u306a\u306e\u3067\u3057\u3087\u3046\u304b\uff1f\u3044\u3044\u3048\u3001\u305d\u3046\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\u4eca\u5f8c\u306fKkkiller\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u3063\u3066\u3001\u3055\u3089\u306b\u8868\u5f62\u5f0f\u306e\u30c7\u30fc\u30bf\u3092\u63a2\u3063\u3066\u3044\u3053\u3046\u3068\u601d\u3044\u307e\u3059\u3002","6642e743":"\u3053\u306e\u8eca\u306f\u3001\u30c9\u30e9\u30a4\u30d0\u30fc\u304c\u76f4\u9762\u3059\u308b\u901a\u5e38\u306e\u8ab2\u984c\u3092\u3055\u308a\u3052\u306a\u304f\u3053\u306a\u3057\u3066\u3044\u308b\u3088\u3046\u306b\u898b\u3048\u307e\u3059\u3002\u305d\u308c\u3082\u9a5a\u304f\u307b\u3069\u306e\u7cbe\u5ea6\u3067\u3059\u3002\u3053\u3053\u3067\u306f\u3001\u3053\u306e\u3088\u3046\u306a\u3053\u3068\u3092\u5b9f\u73fe\u3059\u308b\u305f\u3081\u306b\u3001\u5916\u90e8\u8981\u56e0\u306e\u52d5\u304d\u3092\u4e88\u6e2c\u3057\u3001\u305d\u308c\u306b\u57fa\u3065\u3044\u3066\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u52d5\u304d\u306e\u7d4c\u8def\u3092\u4e88\u6e2c\u3059\u308b\u3053\u3068\u304c\u8ab2\u984c\u3068\u306a\u3063\u3066\u3044\u307e\u3059***\u3053\u306e\u3088\u3046\u306a\u5916\u90e8\u8981\u56e0\u306e\u52d5\u304d\u3092\u4e88\u6e2c\u3059\u308b\u305f\u3081\u306b\u306f\u3001\u5f8c\u8ff0\u3059\u308b\u3088\u3046\u306b\u69d8\u3005\u306a\u30a2\u30d7\u30ed\u30fc\u30c1\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u3068\u308a\u3042\u3048\u305a\u98db\u3073\u8fbc\u3093\u3067\u307f\u307e\u3057\u3087\u3046\u3002\n\n\u3053\u3053\u3067\u306f\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u305d\u306e\u5185\u5bb9\u306b\u3064\u3044\u3066\u306e\u7c21\u5358\u306aFAQ\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002\n\n**\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u69cb\u9020\u306f\uff1f**<br>\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u69cb\u6210\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n```\naerial_map\nscenes\nsemantic_map\n```\n\n\u3053\u3053\u3067\u306f\u3001\u5404\u30b7\u30fc\u30f3\u306b\u306f\u3001\u8907\u6570\u306e\u5916\u90e8\u8eca\u4e21\u306e\u52d5\u304d\u3068\u305d\u308c\u306b\u5bfe\u5fdc\u3059\u308b\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u52d5\u304d\u306b\u95a2\u3059\u308b\u60c5\u5831\u304c\u7d041\u5206\u7a0b\u5ea6\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002\n\n\u30c7\u30fc\u30bf\u4e00\u89a7:\n```\nsample.zarr\ntest.zarr\ntrain.zarr\nvalidate.zarr\n```\n\n\u4eca\u3001\u3053\u306eZARR\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306f\u3001\u79c1\u306f\u53c2\u52a0\u8005\u306e\u307b\u3068\u3093\u3069\u304c\u3053\u308c\u3089\u3092\u4f7f\u7528\u3057\u305f\u3053\u3068\u304c\u306a\u3044\u3068\u601d\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u5c11\u3057\u8208\u5473\u6df1\u3044\u3067\u3059\u3002\u3053\u308c\u3089\u306fNumPy\u3068\u975e\u5e38\u306b\u591a\u304f\u306e\u76f8\u4e92\u904b\u7528\u6027\u304c\u3042\u308a\u3001Lyft\u30ec\u30d9\u30eb5\u30ad\u30c3\u30c8\u306f\u307e\u305f\u3001\u30c7\u30fc\u30bf\u306e\u51e6\u7406\u3092\u51e6\u7406\u3059\u308b\u305f\u3081\u306e\u7c21\u5358\u306a\u65b9\u6cd5\u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u5fc3\u914d\u3057\u306a\u3044\u3067\u304f\u3060\u3055\u3044\u3002\u3082\u3061\u308d\u3093\u3001\u305d\u306e\u904e\u7a0b\u3067Pandas DataFrame\u3092\u4f7f\u7528\u3059\u308b\u65b9\u6cd5\u3082\u3044\u304f\u3064\u304b\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u304c\u3001\u3053\u3053\u3067\u306fLightGBM\u3092\u7528\u3044\u307e\u3059\u3002\n\ntrain.zarr\u306b\u306f\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u7528\u306e\u30de\u30b9\u30af\u3001\u30d5\u30ec\u30fc\u30e0\u3001\u30b7\u30fc\u30f3\u3001\u4fe1\u53f7\u6a5f\u306e\u9854\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u3053\u308c\u306b\u3064\u3044\u3066\u306f\u5f8c\u307b\u3069\u8a73\u3057\u304f\u8aac\u660e\u3057\u307e\u3059\u3002","9d9a65a1":"\u5f85\u3063\u3066\u304f\u3060\u3055\u3044\uff01\u53ef\u8996\u5316\u3068\u305d\u308c\u306b\u4f34\u3046\u3059\u3079\u3066\u306e\u51e6\u7406\u306b\u5165\u308b\u524d\u306b\u3001\u77ed\u3044YouTube\u306e\u30d3\u30c7\u30aa\u3092\u898b\u3066\u3001\u81ea\u5f8b\u8d70\u884c\u8eca\u306e\u64cd\u4f5c\u306e\u4e3b\u984c\u306b\u3064\u3044\u3066\u77e5\u308a\u307e\u305b\u3093\u304b\uff1f","c36a6db4":"\u30bd\u30fc\u30b9: https:\/\/github.com\/lyft\/l5kit\/blob\/master\/examples\/visualisation\/visualise_data.ipynb","d5816eae":"\u3042\u307e\u308a\u30af\u30e9\u30b9\u30bf\u5316\u3055\u308c\u3066\u3044\u306a\u3044\u30d3\u30e5\u30fc\u3068\u3057\u3066\u306f\u826f\u3044\u306e\u3067\u3059\u304c\u3001\u3088\u308a\u8a73\u7d30\u3067\u9ad8\u30ec\u30d9\u30eb\u306a\u30c7\u30fc\u30bf\u306e\u6982\u8981\u3092\u77e5\u308a\u305f\u3044\u5834\u5408\u306f\u3001\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d3\u30e5\u30fc\u3092\u4f7f\u7528\u3057\u3066\u307f\u308b\u3068\u826f\u3044\u3067\u3057\u3087\u3046\u3002","35ba736a":"\u3055\u3066\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u89b3\u70b9\u304b\u3089\u306f\u3069\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\u3053\u308c\u307e\u3067\u306e\u3068\u3053\u308d\u3001\u307b\u3068\u3093\u3069\u306e\u516c\u958b\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001\u4e3b\u306b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u8996\u70b9\u304b\u3089\u30e2\u30c7\u30ea\u30f3\u30b0\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u3053\u308c\u3092\u691c\u8a0e\u3059\u308b\u306e\u306f\u975e\u5e38\u306b\u8208\u5473\u6df1\u3044\u3053\u3068\u3067\u3057\u3087\u3046\u3002","5ffeebaf":"\u3067\u306f\u3001\u8a2d\u5b9a\u30c7\u30fc\u30bf\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u3053\u308c\u306b\u306f\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306b\u95a2\u3059\u308b\u30e1\u30bf\u30c7\u30fc\u30bf\u3001\u5408\u8a08\u6642\u9593\u30011\u30b7\u30fc\u30f3\u3042\u305f\u308a\u306e\u30d5\u30ec\u30fc\u30e0\u6570\u3001\u30b7\u30fc\u30f3\u6642\u9593\u3001\u30d5\u30ec\u30fc\u30e0\u6570\u304c\u542b\u307e\u308c\u307e\u3059\u3002","c579d916":"\u3053\u306e\u5206\u5e03\u306f\u3001\u79c1\u304c\u305d\u308c\u3089\u3092\u547c\u3076\u3088\u3046\u306b\u3001\u3044\u304f\u3064\u304b\u306e \"\u7a81\u8d77 \"\u3092\u6301\u3063\u3066\u3044\u308b\u3088\u3046\u306b\u898b\u3048\u307e\u3059\u3002\u3053\u308c\u3067\u3001\u6211\u3005\u306e\u76ee\u7684\u304c\u3069\u308c\u3060\u3051\u5b9f\u73fe\u53ef\u80fd\u304b\u3092\u78ba\u8a8d\u3059\u308b\u305f\u3081\u306b\u3001\u30d5\u30ec\u30fc\u30e0\u30c7\u30fc\u30bf\u306e\u63a2\u7d22\u306b\u79fb\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002","5d66db9b":"\u3053\u306e\u30c7\u30fc\u30bf\u306e\u8a73\u7d30\u304c\u308f\u304b\u3089\u306a\u3044\u3068\u3001\u4ed6\u306b\u3069\u3093\u306a\u63a8\u8ad6\u304c\u3067\u304d\u308b\u306e\u304b\u3088\u304f\u308f\u304b\u308a\u307e\u305b\u3093\u306e\u3067\u3001\u3053\u308c\u3089\u306e\u753b\u50cf\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002","dfaf7dae":"PyTorch lightning\u3092\u4f7f\u3063\u305f\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u306f\u521d\u3081\u3066\u306a\u306e\u3067\u3001\u304b\u306a\u308a\u6e80\u8db3\u3057\u3066\u3044\u307e\u3059\u3002\u3057\u304b\u3057\u4eca\u306f\u3001\u3053\u306e\u30e2\u30c7\u30eb\u304c\u5177\u4f53\u7684\u306b\u4f55\u3092\u5b66\u7fd2\u3057\u305f\u306e\u304b\u3092\u898b\u3066\u307f\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002<br>\u4e88\u6e2c\u5024\u3092\u7d50\u679c\u7528\u306e\u914d\u5217 `res` \u306b\u4fdd\u5b58\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3057\u305f\u3002\u5b66\u7fd2\u3057\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u306e\u306f\u5f8c\u306b\u306a\u308a\u307e\u3059\u304c\u3001\u4eca\u5f8c\u306f\u4e88\u6e2c\u3092\u9032\u3081\u3066\u3044\u304d\u307e\u3059\u3002","ff8261d2":"# Lyft: \u30c7\u30fc\u30bf\u306e\u7406\u89e3\u3068EDA","c7d7bfde":"# \u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u30fb\u30e2\u30c7\u30eb (\u30bd\u30fc\u30b9: [\u3053\u3061\u3089](https:\/\/github.com\/lyft\/l5kit\/blob\/master\/examples\/agent_motion_prediction\/agent_motion_prediction.ipynb) \u3068 [\u3053\u3061\u3089](https:\/\/www.kaggle.com\/pestipeti\/pytorch-baseline-inference))","8c327143":"### \u81ea\u5df1\u56de\u8ee2","6cd4dd1a":"\u3053\u3053\u306b\u306f\u3001\u30bb\u30f3\u30c8\u30ed\u30a4\u30c9\u306b\u95a2\u3059\u308b\u56de\u8ee2\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u3053\u308c\u306f\u975e\u5e38\u306b\u8208\u5473\u6df1\u3044\u8003\u5bdf\u306b\u306a\u308b\u3067\u3057\u3087\u3046\u3002\u3053\u308c\u3089\u306e\u5909\u6570\u3092\u4e00\u5ea6\u306b\u8907\u6570\u30c1\u30a7\u30c3\u30af\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u305d\u3046\u3067\u3059\u3002","a4e231e2":"### extent_x, extent_y \u3068 extent_z","ec12f002":"\u6ce8\u91c8\uff1a\n\u672c\u8a18\u4e8b\u306f https:\/\/www.kaggle.com\/nxrprime\/lyft-understanding-the-data-baseline-model \u3092\u65e5\u672c\u8a9e\u306b\u8a33\u3057\u305f\u3082\u306e\u306b\u306a\u308a\u307e\u3059\u3002\n\u5185\u5bb9\u306e\u8aa4\u308a\u3084\u8aa4\u8a33\u306b\u3064\u3044\u3066\u306f\u4e88\u3081\u3054\u5bb9\u8d66\u304f\u3060\u3055\u3044\u3002\n\n\u3053\u306e\u65b0\u3057\u3044Lyft\u306e\u30b3\u30f3\u30da\u306f\u3001\u53c2\u52a0\u8005\u3067\u3042\u308b\u79c1\u305f\u3061\u306b\u3001\u81ea\u52d5\u8eca\u3084\u81ea\u8ee2\u8eca\u3001\u6b69\u884c\u8005\u306a\u3069\u306e\u52d5\u304d\u3092\u4e88\u6e2c\u3057\u3066\u3001\u81ea\u52d5\u904b\u8ee2\u8eca\u3092\u652f\u63f4\u3059\u308b\u3053\u3068\u3092\u8ab2\u984c\u3068\u3057\u3066\u3044\u307e\u3059\u3002\u6628\u5e74\u306e\u30b3\u30f3\u30da\u3067\u306f\u3001\u30b9\u30c8\u30c3\u30d7\u30b5\u30a4\u30f3\u306a\u3069\u306e\u7acb\u4f53\u7269\u3092\u691c\u77e5\u3057\u3066\u81ea\u52d5\u904b\u8ee2\u8eca\u306b\u8a8d\u8b58\u65b9\u6cd5\u3092\u6559\u3048\u308b\u3068\u3044\u3046\u8ab2\u984c\u304c\u3042\u308a\u307e\u3057\u305f\u304c\u3001\u3053\u308c\u306f\u4e00\u6b69\u524d\u9032\u3057\u3066\u3044\u307e\u3059\u3002","ac6af4fa":"\u307e\u305f\u3001\u4e57\u308a\u7269\u306e\u5168\u4f53\u7684\u306a\u52d5\u304d\u3082\u898b\u3066\u307f\u305f\u3044\u3082\u306e\u3067\u3059\u3002","63ff40cf":"\u307e\u305f\u3001ChunkedDataset\u3092\u4f7f\u3063\u3066\u30b7\u30fc\u30f3\u306eCSV\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002","efd0a092":"\u3068\u3044\u3046\u3053\u3068\u3067\u3001\u4ed6\u306e\u8eca\u4e21\u306e\u52d5\u304d\u3068\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u52d5\u304d\u306e\u30c7\u30e2\u3067\u3059\u3002\u81ea\u52d5\u904b\u8ee2\u8eca\u306f\u73fe\u5728\u3001\u305d\u306e\u52d5\u304d\u306e\u4e2d\u3067\u306f\u76f4\u7dda\u7684\u306a\u9053\u3057\u304b\u53d6\u3063\u3066\u304a\u3089\u305a\u3001\u76f4\u7dda\u7684\u306a\u9053\u306f\u4ed6\u306e\u8eca\u4e21\u306e\u52d5\u304d\u3068\u914d\u7f6e\u3068\u306e\u95a2\u4fc2\u3067\u8ad6\u7406\u7684\u306b\u898b\u3048\u307e\u3059\u3002","fd928df0":"\u307e\u305f\u3001Lyft\u306e\u30ec\u30d9\u30eb5\u30ad\u30c3\u30c8\u306e\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4f7f\u3046\u3053\u3068\u3067\u3001\u3088\u308a\u7c21\u6613\u306a\u52d5\u304d\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002","49e68bee":"### \u30af\u30ec\u30b8\u30c3\u30c8:\n\n**https:\/\/www.kaggle.com\/t3nyks\/lyft-working-with-map-api**<br>\n**https:\/\/www.kaggle.com\/jpbremer\/lyft-scene-visualisations**<br>\n**https:\/\/www.kaggle.com\/pestipeti\/pytorch-baseline-train**","c61300c8":"## \u30c7\u30fc\u30bf\u306e\u5229\u7528\u3092\u958b\u59cb\u3059\u308b","a7aa661d":"\u30a8\u30af\u30b9\u30c6\u30f3\u30c8X\u3068\u30a8\u30af\u30b9\u30c6\u30f3\u30c8Y\u306e\u5206\u5e03\u306f\u3001\u30bb\u30f3\u30c8\u30ed\u30a4\u30c9X\u3068\u540c\u69d8\u306b\u5927\u304d\u304f\u53f3\u306b\u50be\u3044\u3066\u3044\u308b\u3088\u3046\u306b\u898b\u3048\u307e\u3059\u304c\u3001\u30d7\u30ed\u30c3\u30c8\u306e\u8aad\u307f\u3084\u3059\u3055\u306e\u305f\u3081\u306b\u30a8\u30af\u30b9\u30c6\u30f3\u30c8Z\u3092\u7701\u3044\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u305d\u308c\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n\u30c7\u30fc\u30bf\u3092\u6ed1\u3089\u304b\u306b\u3057\u307e\u3059\u3002","0e82ed54":"\u5358\u7d14\u306a\u30d7\u30ed\u30c3\u30c8\u3088\u308a\u3082\u306f\u308b\u304b\u306b\u8a73\u7d30\u306a\u5206\u6790\u3092\u53ef\u80fd\u306b\u3057\u307e\u3059\u3002\u79c1\u306f\u6b21\u306e\u3088\u3046\u306a\u63a8\u8ad6\u3092\u3059\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n+ \u7dd1\u306f\u81ea\u52d5\u904b\u8ee2\u8eca\u3092\u8868\u3057\u3001\u9752\u306f\u4e3b\u306b\u6211\u3005\u304c\u4e88\u6e2c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u4ed6\u306e\u3059\u3079\u3066\u306e\u8eca\/\u8eca\u4e21\/\u5916\u56e0\u6027\u56e0\u5b50\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\n+ \u79c1\u306e\u4eee\u8aac\u3067\u306f\u3001\u9752\u306f\u8eca\u4e21\u304c\u901a\u904e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u7d4c\u8def\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\n+ \u8eca\u4e21\u304c\u901a\u904e\u3059\u308b\u7d4c\u8def\u3092\u6b63\u78ba\u306b\u4e88\u6e2c\u3067\u304d\u308c\u3070\u3001\u81ea\u52d5\u904b\u8ee2\u8eca\u304c\u305d\u306e\u5834\u3067\u8ecc\u9053\u3092\u8a08\u7b97\u3059\u308b\u306e\u304c\u5bb9\u6613\u306b\u306a\u308a\u307e\u3059\u3002","d9e01448":"\u3053\u308c\u306f\u660e\u3089\u304b\u306b**\u6700\u5927\u306e\u4ea4\u901a\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u30e2\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306e\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u3067\u3059\u3002**\u30d5\u30a1\u30a4\u30eb\u306fPython\u3067.zarr\u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u3067\u4fdd\u5b58\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0ZARR\u306e\u4e2d\u306b\u306f\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u7528\u30de\u30b9\u30af\u3001\u30d5\u30ec\u30fc\u30e0\u3068\u30b7\u30fc\u30f3\u3001\u4fe1\u53f7\u6a5f\u304c\u3042\u308a\u307e\u3059\u3002\n\n\u30c6\u30b9\u30c8\u7528ZARR\u306f\u307b\u307c\u540c\u3058\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u3059\u304c\u3001\u30c7\u30fc\u30bf\u30de\u30b9\u30af\u304c\u9664\u5916\u3055\u308c\u3066\u3044\u308b\u3060\u3051\u3067\u3059\u3002","a768fe7c":"### centroid_x \u3068 centroid_y"}}