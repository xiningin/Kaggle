{"cell_type":{"0e1c06f3":"code","c21b9dc6":"code","37e1b0c4":"code","f8250596":"code","e7383edd":"code","a8163991":"code","a8b79c82":"code","dfa9ef76":"code","5dafea33":"code","2a9bb6ac":"code","d2f42496":"code","c2b2e152":"code","0b4bea7c":"markdown","161fe0a4":"markdown","59455aa8":"markdown","422cbea2":"markdown","d42b15e9":"markdown","6bcd3423":"markdown","7cadc822":"markdown","d19354d3":"markdown"},"source":{"0e1c06f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c21b9dc6":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX_full = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# To keep things simple, we'll use only numerical predictors\nX = X_full.select_dtypes(exclude=['object'])\nX_test = X_test_full.select_dtypes(exclude=['object'])\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","37e1b0c4":"parameters = [{\n    'n_estimators': list(range(100, 1001, 100)), \n    'learning_rate': [x \/ 100 for x in range(5, 100, 10)], \n    'max_depth': list(range(6, 70, 10))\n}]\nprint(parameters)","f8250596":"from sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBRegressor\ngsearch = GridSearchCV(estimator=XGBRegressor(),\n                       param_grid = parameters, \n                       scoring='neg_mean_absolute_error',\n                       n_jobs=4,cv=5, verbose=7)","e7383edd":"gsearch.fit(X, y)","a8163991":"best_n_estimators = gsearch.best_params_.get('n_estimators')\nbest_n_estimators","a8b79c82":"best_learning_rate = gsearch.best_params_.get('learning_rate')\nbest_learning_rate","dfa9ef76":"best_max_depth = gsearch.best_params_.get('max_depth')\nbest_max_depth","5dafea33":"final_model = XGBRegressor(n_estimators=best_n_estimators, \n                          learning_rate=best_learning_rate, \n                          max_depth=best_max_depth)","2a9bb6ac":"final_model.fit(X, y)","d2f42496":"preds_test = final_model.predict(X_test)","c2b2e152":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","0b4bea7c":"# Get the best parameters ","161fe0a4":"# Load data ","59455aa8":"# Define hyper-parameters","422cbea2":"# Define GridSearchCV for hypter-parameter tuning ","d42b15e9":"# Fit the model ","6bcd3423":"# Predict the test data ","7cadc822":"# Write predictions to submit it","d19354d3":"# Build the final model with the best parameters "}}