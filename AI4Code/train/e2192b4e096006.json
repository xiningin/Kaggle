{"cell_type":{"7bf0035e":"code","3dee9787":"code","b18076d6":"code","33da0f4b":"code","485bd7a5":"code","616c8912":"code","07be6bc2":"code","33c3d83c":"code","e63a52dd":"code","74a81ef1":"code","4b55ea43":"code","d6d9abcb":"code","70a8c7f2":"code","2c8fcfb0":"code","d008b734":"code","81dc5838":"code","1964f659":"code","7b00762b":"code","d11fb078":"code","bfb69def":"code","92d9ef60":"markdown","be44e010":"markdown","52095d89":"markdown","540358d7":"markdown","016b2334":"markdown","9a75c963":"markdown","068a9d31":"markdown","53a047a0":"markdown","053c4d9a":"markdown","7546eb4e":"markdown","d1f30455":"markdown","535fcb0b":"markdown"},"source":{"7bf0035e":"%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom keras.models import model_from_json\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# My seed\n\nseed = 42","3dee9787":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test  = pd.read_csv('..\/input\/test.csv')","b18076d6":"df_train.info()","33da0f4b":"df_test.info()","485bd7a5":"X_train = df_train.drop(['label'], axis=1)\ny_train = df_train['label']\nX_test = df_test\n\n# Free memory space\n\ndel df_train\ndel df_test\n\nprint('Shape of X_train:', X_train.shape)\nprint('Shape of y_train:', y_train.shape)\nprint('Shape of X_test :', X_test.shape)\n","616c8912":"counter = Counter(y_train)\ncounter","07be6bc2":"X_train = X_train \/ 255\nX_test = X_test \/ 255","33c3d83c":"X_train = X_train.values.reshape(-1,28,28,1) # (height = 28px, width = 28px , canal = 1)\nX_test = X_test.values.reshape(-1,28,28,1)\n\nprint('Shape of X_train:', X_train.shape)\nprint('Shape of X_test :', X_test.shape)","e63a52dd":"# One Hot Categories\n\ny_train = to_categorical(y_train, num_classes = 10)\ny_train.shape","74a81ef1":"def baseline_model():\n    \n    # Create baseline\n    \n    baseline = Sequential()\n\n    #------------------------------------------------------------\n    \n    # Parameters tunned by GridSearchCV    \n    # 32 filters for the three firsts conv2D layers\n    \n    baseline.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu', \n                     input_shape = (28, 28, 1)))\n    baseline.add(BatchNormalization())\n    baseline.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu'))\n    baseline.add(BatchNormalization())\n    baseline.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu'))\n    baseline.add(BatchNormalization())\n    \n    # This layer simply acts as a downsampling filter. \n    # It looks at the 2 neighboring pixels and picks the maximal value, reducing computational cost, \n    # and to some extent also reduce overfitting.\n    \n    # IMPORTANT: Combining convolutional and pooling layers, CNN are able to combine local features and \n    # learn more global features of the image.\n    \n    baseline.add(MaxPool2D(pool_size=(2,2)))\n    \n    # Dropout is a regularization method, where a proportion of nodes (25%) in the layer are randomly ignored \n    # for each training sample. This dropout forces the network to learn features in a distributed way \n    # and improves generalization and reduces the overfitting.\n    \n    baseline.add(Dropout(0.25))\n    #------------------------------------------------------------\n    \n    # 64 filters for the three last conv2D layers\n    \n    baseline.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n    baseline.add(BatchNormalization())\n    baseline.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n    baseline.add(BatchNormalization())\n    baseline.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n    baseline.add(BatchNormalization())\n    \n    baseline.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    baseline.add(Dropout(0.25))\n    #------------------------------------------------------------\n\n    # The Flatten layer is use to convert the final feature maps into a one single 1D vector. \n    # IMPORTANT: It combines all the found local features of the previous convolutional layers.\n    \n    baseline.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'Same', activation ='sigmoid'))\n    baseline.add(BatchNormalization())\n    \n    baseline.add(Flatten())\n    baseline.add(Dense(128, activation = \"relu\"))\n    baseline.add(Dropout(0.4))\n    \n    # The net outputs distribution of probability of each class --> In our case, 10 output classes\n    \n    baseline.add(Dense(10, activation = \"softmax\"))\n    \n    # The optimizer will iteratively improve parameters in order to minimize the loss.\n    # Compile the baseline including the optimizer and evaluating the performance of the baseline by accuracy\n    \n    baseline.compile(optimizer = 'Adamax' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    return baseline","4b55ea43":"# If after the third epoch we didn't have an improvement of accuracy, the learning rate will be \n# reduced by 50% (factor).\n\nlr_reduction = ReduceLROnPlateau(monitor='val_acc',\n                                 patience=3, \n                                 verbose=0, \n                                 factor=0.5, \n                                 min_lr=0.00001)","d6d9abcb":"# The idea is to alter the training data with small transformations to reproduce the variations \n# occuring when someone is writing a digit. It's a way to minimize the overfitting of the model.\n\ngenerator = ImageDataGenerator(featurewise_center = False,\n                               samplewise_center = False, \n                               featurewise_std_normalization = False,\n                               samplewise_std_normalization = False,\n                               zca_whitening = False,\n                               rotation_range = 10, # Rotate image in 10 degrees\n                               zoom_range = 0.10, # Zoom image (10% zoom) \n                               width_shift_range = 0.10, # Shift image horizontally (10% of width)\n                               height_shift_range = 0.10, # Shift image vertically (10% of height)\n                               horizontal_flip = False,\n                               vertical_flip = False)\n\ngenerator.fit(X_train)","70a8c7f2":"nets = 10\ndigits = [0] * nets\nhistory = [0] * nets\n\nepochs = 40\nbatch_size = 90","2c8fcfb0":"print('Creating {0} CNNs...'.format(nets))\nfor model in range(nets):\n    digits[model] = baseline_model()\n    \n    # Splitting train and test datasets\n    \n    X_train_aux, X_test_aux, y_train_aux, y_test_aux = train_test_split(X_train, y_train, test_size = 0.1)\n    \n    history[model] = digits[model].fit_generator(generator.flow(X_train_aux,\n                                                              y_train_aux, \n                                                              batch_size = batch_size),\n                                                 epochs = epochs, \n                                                 steps_per_epoch = X_train_aux.shape[0] \/\/ batch_size, \n                                                 validation_data = (X_test_aux, y_test_aux), \n                                                 callbacks=[lr_reduction],\n                                                 verbose=0)\n    \n    print(\"CNN {0:>2d}: Epochs = {1:d}, Max. Train accuracy = {2:.5f}, Max. Validation accuracy = {3:.5f}\".format(\n        model + 1, # Number of the CNN model\n        epochs, # Total of epochs\n        max(history[model].history['acc']), # Maximum Accuracy from Training\n        max(history[model].history['val_acc']))) # Maximum Accuracy from Test (validation)","d008b734":"label_predicted = np.zeros( (X_test.shape[0], 10) )\nlabel_predicted","81dc5838":"for model in range(nets):\n    label_predicted = label_predicted + digits[model].predict(X_test)","1964f659":"# Get the index with the maximum probability\n\nlabel_predicted = np.argmax(label_predicted, axis = 1)\nlabel_predicted = pd.Series(label_predicted, name = \"Label\")","7b00762b":"solution = pd.concat([pd.Series(range(1, 28001), name = \"ImageId\"), label_predicted], axis = 1)\nsolution.to_csv(\"solution_cnn_opt.csv\", index=False)","d11fb078":"solution.head(10)","bfb69def":"for model in range(nets):\n    model_saved = digits[model].to_json()\n    name = 'model_' + str(model) + '.json'\n    with open(name, 'w') as json_file:\n        json_file.write(model_saved)\n    name = 'model_' + str(model) + '.h5'\n    digits[model].save_weights(name)","92d9ef60":"### Creating 10 nets and training every ones","be44e010":"### Reshape the images in 4 dimensions to use with Keras","52095d89":"### Define the baseline neural network model","540358d7":"### Saving the models","016b2334":"### Converting y values (labels) to categorical values","9a75c963":"### Counting the labels","068a9d31":"### Learning Rate","53a047a0":"### Spliting the dataset","053c4d9a":"### Normalizing the values of training and test","7546eb4e":"### Data augmentation","d1f30455":"### Loading the training and test dataset","535fcb0b":"### Getting the predictions with more probabilities to be correct"}}