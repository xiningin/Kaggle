{"cell_type":{"3123c58a":"code","3eef2fed":"code","e93af668":"code","089b0208":"code","0c99c7e4":"code","2c7e7943":"code","79071eb0":"code","4748565f":"code","27b96dba":"code","717d2bd0":"code","5b6e3c21":"code","0e8fc3d1":"code","2704d042":"code","ae4e280d":"markdown","0f6e798e":"markdown","922b47ea":"markdown","41af7631":"markdown","11b1a185":"markdown","05eb0523":"markdown","23bf6bf6":"markdown","5bd17093":"markdown","f91f6fb3":"markdown","56ffa26e":"markdown","a171850e":"markdown","ca312a26":"markdown","139762b4":"markdown"},"source":{"3123c58a":"# --- Set up the environment with imports and function definitions ---\n\n# This Python 3 environment comes with many helpful analytics libraries installed!\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os # Working with filesystems\n\nimport matplotlib # visualizations\nimport matplotlib.pyplot as plt # plotting and styling\nimport seaborn as sns # more data visualizations\nimport matplotlib.font_manager as fm # for using custom fonts\nfrom math import pi # Used when drawing \"radar\" plots\n\n# Input data files get stored the read-only \"..\/input\/\" directory.\n# This function will load a CSV file into a pandas dataframe\ndef load_csv(file_path):\n    \"\"\"Load the specified file into a pandas dataframe.\n       The file_path should be the entire path, including\n       the '\/kaggle\/input' directory and any subdirectories.\n       Returns a dataframe.\"\"\"\n    df = pd.read_csv(file_path,low_memory=False,encoding='UTF-8')\n    return df\n\n# --- Set up fonts and constants ---\n\n# Set default fonts and sizes for matplotlib and seaborn\nmatplotlib.rc('font', family='sans-serif') \nmatplotlib.rc('font', serif='Helvetica') \nmatplotlib.rc('text', usetex='false') \nmatplotlib.rcParams.update({'font.size': 12})\nsns.set(rc={'figure.figsize':(8,6)})\n# Use a custom font for showing special symbols as xlabels\nSYMBOL_FONT = fm.FontProperties(fname='..\/input\/notoemojifont\/noto-emoji.regular.ttf', size=20)    \n\n# Set some constants we'll be referring to regularly\nINDUSTRY_COLUMN = 'Q20'\n\n# These are the industries that we're interested in drilling into more closely,\n# and the symbols we're using to represent them in the charts\nfrom collections import OrderedDict\nINDUSTRIES_OF_INTEREST = OrderedDict([\n    ('Accounting\/Finance', '\ud83d\udcb2'),\n    ('Broadcasting\/Communications', '\ud83d\udce1'),\n    ('Energy\/Mining', '\u2600'),\n    ('Government\/Public Service', '\ud83c\udfe2'),\n    ('Hospitality\/Entertainment\/Sports', '\u26bd'),\n    ('Insurance\/Risk Assessment', '\u2614'),\n    ('Marketing\/CRM', '\ud83c\udf20'),\n    ('Manufacturing\/Fabrication', '\ud83d\udea7'),\n    ('Medical\/Pharmaceutical', '\ud83d\udd2c'),\n    ('Military\/Security\/Defense', '\ud83d\udec2'),\n    ('Non-profit\/Service', '\ud83d\udc6b'),\n    ('Retail\/Sales', '\ud83d\udc5c'),\n    ('Shipping\/Transportation', '\ud83d\udea2'),\n    ('Other', '\u2754')\n])\n\n# These are the specific questions (and their user-friendly labels) that\n# we want to drill into more closely\nQUESTIONS_OF_INTEREST = {\n    'Q7': 'What programming languages does each industry use on a regular basis?',\n    'Q9': 'Which IDEs do the different industries use?',\n    'Q17': 'Which ML algorithms do you use on a regular basis?',\n    'Q18': 'Which computer vision methods do you use on a regular basis?',\n    'Q19': 'Which NLP methods do you use on a regular basis?',\n    'Q27a': 'Which cloud computing platforms does each industry use?',\n    'Q32a': 'Which big data products are used by the different industries? ',\n    'Q39': 'Where do you publicly share or deploy your data analysis or machine learning applications?',\n    'Q40': 'On which platforms have you begun or completed data science courses?',\n    'Q42': 'Who\/what are your favorite media sources that report on data science topics?'\n}\n\n# --- Set up charting functions ---\n\n# Because of the wacky font being used for the symbols, we get some runtime warnings\n# about missing glyphs; set these to be ignored, since the symbols render properly\nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\"Glyph 108 missing from current font.\")\nwarnings.filterwarnings(\"ignore\", message=\"Glyph 112 missing from current font.\")\n\n# A function that will allow us to draw a heatmap for the results of a given question\ndef draw_heatmap(dataframe, label, cmap, industry_colors=None):\n    # The dataframe has three pieces of information that we want to visualize\n    # the relationships between: Answers, Industry, and Percent of respondents.\n    # Some questions we might want to know the answers to are:\n    # - Which of the answers were the most popular overall (e.g. 'Recurrent Neural Networks'\n    #   vs. 'Generative Adversarial Networks'),\n    # - Which answers were popular for which industry (e.g. does 'Military\/Security\/Defense'\n    #   use 'Decision Trees or Random Forests' more or less than 'Academics\/Education' does?)\n    #\n    # One useful way to visualize this information is with heatmaps; the answers will be on\n    # the Y-axis, and the industries are on the X-axis. Color\/intensity indicates what\n    # percentage of respondents from each industry chose that answer.\n    \n    # Sort the result in order by most popular to least popular (arbitrarily based on\n    # the first industry; they'll be close enough that this is a useful way to look at them for all)\n    sorted_df = dataframe.sort_values(dataframe.columns[0], inplace = False, ascending=False)\n\n    # Set up for the heatmap\n    fig, ax = plt.subplots(figsize=(10, 7))\n    sns.heatmap(sorted_df, cmap=cmap, square=True, linewidth=0.1, cbar_kws={'shrink':0.75})\n\n    # Make the Y-axis labels a little larger\n    ax.tick_params(axis=\"y\", direction=\"out\", grid_color=\"gray\", left=True,\n                  labelleft=True, labelsize=13)\n    \n    # Use the symbols as labels\n    ax.set_xticklabels(INDUSTRIES_OF_INTEREST.values(), fontproperties=SYMBOL_FONT)\n    # Rotate them to be vertical and put them at the top\n    plt.xticks(rotation=0)\n    ax.xaxis.tick_top() # x axis on top\n    ax.xaxis.set_label_position('top')\n    # And set symbol colors if specified\n    if industry_colors:\n        for tick, color in zip(ax.get_xticklabels(), industry_colors):\n            tick.set_color(color)\n\n    # Display the title\n    plt.title(label, loc='center', fontname='Helvetica', size=16)\n    # Show the full plot\n    plt.show()\n\n    \n# A function that will draw a bubble plot for the results of a question\ndef draw_bubble_plot(dataframe, label, cmap, industry_colors=None):\n    # Since we're plotting categorical variables, the bubble\n    # plot is effectively the same as a heatmap, only with different\n    # styling. Similarly, there will be three different variables we want\n    # to visualize: answer, industry, and percentage of respondents.\n    sorted_df = dataframe.sort_values(dataframe.columns[0], inplace = False, ascending=False)\n\n    # Turn the one-column-per-industry format into a single column containing\n    # the industry as a string, with multiple rows per answer; this makes it\n    # easier to plot on a bubble\/scatter plot\n    sorted_df['Answer'] = sorted_df.index\n    sorted_df = sorted_df.melt(id_vars=[\"Answer\"],\n                               var_name=\"Industry\",\n                               value_name=\"Responses\", ignore_index=True)\n    \n    # use the scatterplot function to build the plot; it's too hard to distinguish\n    # different sizes to communicate number of responses, so we're relying soley\n    # on color (and thus it effectively becomes another form of heatmap)\n    g = sns.scatterplot(data=sorted_df, x='Industry', y='Answer', size=\"Responses\",\n                        palette=cmap, hue=\"Responses\",\n                        legend='brief', sizes=(500, 500))\n    \n    g.set_xticks(g.get_xticks()) # Avoids a warning about FixedFormatter+FixedLocator\n\n    # Styling\n    g.tick_params(axis=\"x\", direction=\"out\", grid_color=\"gray\", top=True, bottom=False, \n                  labeltop=True, labelbottom=False)\n    g.tick_params(axis=\"y\", direction=\"out\", grid_color=\"gray\", left=True,\n                  labelleft=True, labelsize=13)\n    g.set(xlabel=None, ylabel=None)\n    \n    # Use the symbols as labels\n    g.set_xticklabels(INDUSTRIES_OF_INTEREST.values(), fontproperties=SYMBOL_FONT)\n    # And set symbol colors if specified\n    if industry_colors:\n        for tick, color in zip(g.get_xticklabels(), industry_colors):\n            tick.set_color(color)\n\n    # Reverse the order of the legend to match how the values are plotted,\n    # and put it outside of the plot\n    h, l = g.get_legend_handles_labels()\n    h.reverse()\n    l.reverse()\n    g.legend(h, l, bbox_to_anchor=(1, 1), loc='upper left', fontsize=12)\n    \n    # Display the title\n    plt.title(label, loc='center', fontname='Helvetica', size=16)\n\n    # Finally, show the plot\n    plt.show()\n        \n# A function that will draw a radar plot for the results of a question\n# Thanks to https:\/\/www.python-graph-gallery.com\/392-use-faceting-for-radar-chart for\n# some of this code\ndef draw_radar_chart(dataframe, label, cmap):\n    # The radar chart is fairly messy when we have lots of variables (e.g. 14\n    # industries), but we do use it occasionally for a little variation. It's\n    # basically a line chart, except it wraps around into a circle. When there\n    # happen to be 12 choices (e.g. media sources from the final question), the\n    # resultant clock-like distribution is fairly pleasing.\n    original_columns = dataframe.columns\n    sorted_df = dataframe.sort_values(original_columns[0], inplace = False, ascending=False)\n    transposed_df = sorted_df.transpose()\n\n    def draw_line_for_industry(row, title, colors, location=1, fill_polygons=False):\n        # For each industry, initialize the plot and draw\n        # out the answer labels. Even though the current usage of\n        # lines for all the industries on a single plot means that\n        # we could do this initialization just once, there's another use case\n        # here where we might want to draw a different plot for\n        # each industry to make it easier to see the difference,\n        # and this would support that (and doesn't harm the current\n        # use case, apart from slowing it down a little).\n        \n        # Get the answer labels and how many of them there are\n        categories = row.index\n        N = len(categories)\n        # Determine the angle for each answer on the plot (i.e.\n        # how to arrange the answers around the plot evenly)\n        angles = [n \/ float(N) * 2 * pi for n in range(N)]\n        angles += angles[:1] # Wrap the plot back around to form an enclosing polygon\n\n        # Initialise the plot; \"location\" could be varied per\n        # industry to show a plot for each industry, if desired\n        ax = plt.subplot(2, 2, location, polar=True)\n\n        # Put the first answer at the top\n        ax.set_theta_offset(pi \/ 2)\n        ax.set_theta_direction(-1)\n\n        # Draw one tick per answer, and add labels\n        plt.xticks(angles[:-1], categories, color='black', size=13)\n\n        # Draw the labels for the percentages of responses (the \"Y\" axis);\n        # assume there won't be more than 60 per answer\n        ax.set_rlabel_position(0)\n        plt.yticks([10,20,30,40,50], [\"10\",\"20\",\"30\",\"40\", \"50\"], color=\"grey\", size=7)\n        plt.ylim(0,60)\n\n        # Get the values for this industry\n        values = row.values\n        # Add the first value to the end of the array, so that the line loops\n        # back around to the starting point (enclosing polygon)\n        values = np.append(values, values[:1])\n        \n        # Plot the values\n        ax.plot(angles, values, color=colors[row.name], linewidth=3, linestyle='solid')\n        # Fill them if desired\n        if fill_polygons:\n            ax.fill(angles, values, color=colors[row.name], alpha=0.4)\n\n        # Display the title\n        plt.title(title, loc='center', fontname='Helvetica', size=16)\n\n    # Now, draw the plot for each row in the dataset\n    plt.figure(figsize=(15, 15))\n    # Set a color for each industry\n    industry_colors = {}\n    for index, industry in enumerate(original_columns):\n        color = cmap(index\/len(original_columns))\n        industry_colors[industry] = color\n\n    transposed_df.apply(draw_line_for_industry, args=(label, industry_colors), axis=1)\n    industries_for_legend = [symbol for (industry, symbol) in INDUSTRIES_OF_INTEREST.items() if industry in original_columns]\n    plt.legend(industries_for_legend, bbox_to_anchor=(1.2, 1), loc='upper left', prop=SYMBOL_FONT)\n\n\n\n# --- OK, let's get started! Load in the primary response dataframe ---\n\n# Load all the 2021 survey responses into a pandas dataframe\nfile_name_2021 = '\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv'\nsurvey_df_2021 = load_csv(file_name_2021)\nresponses_df_2021 = survey_df_2021[1:] # The first row is labels; trim that off\n","3eef2fed":"# For the first plot, we're just showing a basic plot of the percentage of respondents\n# from each industry. Determine these percentages using \"value_counts\" on the full dataset.\nindustry_percents = responses_df_2021[INDUSTRY_COLUMN].value_counts(normalize=True).mul(100).round(1)\n# Turn that information into a dataframe for easy plotting\nindustry_percents_df = pd.DataFrame({'Percent of Respondents': industry_percents})\nindustry_percents_df.sort_values(by=['Percent of Respondents'], ascending=True, inplace=True)\ncolor = \"#006699\"\n\n# Use the hlines function of matplotlib.pyplot to draw the lines for a horizontal \"lollipop\" chart.\n# Note: In order to get rid of the left margin but still allow a little bit of a right-hand\n# margin so that the \"bubble\" is fully visible, we're drawing an extra white line at the top and bottom\n# of the chart to make it wider than it would normally be. (Since we're drawing those extra lines, we\n# also don't need top and bottom margins, so those are turned off.)\nplt.margins(0)\nplt.hlines(y=[' '], xmin=0, xmax=30, color='white')\nplt.hlines(y=industry_percents_df.index, xmin=0,\n           xmax=industry_percents_df['Percent of Respondents'],\n           color=color)\nplt.hlines(y=['  '], xmin=0, xmax=30, color='white')\n\n# Plot the \"bubble\" part of the lollipops\nplt.plot(industry_percents_df['Percent of Respondents'], industry_percents_df.index,\n         linestyle='None', markersize=10, marker='o', color=color)\n# Add titles and axis names\nplt.yticks(industry_percents_df.index, industry_percents_df.index, size=13)\nplt.title(\"Industries that Use Data Science \/ Machine Learning\", loc='center', size=16)\nplt.xlabel('Percent of Total Respondents')\n\n# Show the plot\nplt.show()","e93af668":"\n# --- Set up relevant lookups for questions\/answers ---\n\n# Questions where respondents can select more than one answer choice have been split into multiple columns.\n# Ultimately, we'll be wanting to do counts of each answer choice for various subsets of the data. Here,\n# we set up dicts that map each user-friendly answer choice name over to the column that holds it. When we\n# go to do counts, we can use this column lookup to find the appropriate column to count for each answer.\n# Once we've defined these dictionaries, the rest of the computations are easy to make dynamic.\n# (Thanks to https:\/\/www.kaggle.com\/paultimothymooney\/2021-kaggle-data-science-machine-learning-survey\/notebook\n# for inspiration for this code; it has been modified to be more dynamically accessible per industry.)\ndictionary_of_columns = {}\ndictionary_of_columns['Q7'] = {\n    'Python' : 'Q7_Part_1',\n    'R': 'Q7_Part_2',\n    'SQL' : 'Q7_Part_3',\n    'C' : 'Q7_Part_4',\n    'C++' : 'Q7_Part_5',\n    'Java' : 'Q7_Part_6',\n    'Javascript' : 'Q7_Part_7',\n    'Julia' : 'Q7_Part_8',\n    'Swift' : 'Q7_Part_9',\n    'Bash' : 'Q7_Part_10',\n    'MATLAB' : 'Q7_Part_11',\n    'None' : 'Q7_Part_12',\n    'Other' : 'Q7_OTHER'\n}\n\ndictionary_of_columns['Q9'] = {\n    'JupyterLab' : 'Q9_Part_1',\n    'RStudio': 'Q9_Part_2',\n    'Visual Studio' : 'Q9_Part_3',\n    'Visual Studio Code (VSCode)' : 'Q9_Part_4',\n    'PyCharm' : 'Q9_Part_5',\n    'Spyder' : 'Q9_Part_6',\n    'Notepad++' : 'Q9_Part_7',\n    'Sublime Text' : 'Q9_Part_8',\n    'Vim, Emacs, or similar' : 'Q9_Part_9',\n    'MATLAB' : 'Q9_Part_10',\n    'Jupyter Notebook' : 'Q9_Part_11',    \n    'None' : 'Q9_Part_12',\n    'Other' : 'Q9_OTHER'\n}\n\ndictionary_of_columns['Q10'] = {\n    'Kaggle Notebooks' : 'Q10_Part_1',\n    'Colab Notebooks': 'Q10_Part_2',\n    'Azure Notebooks' : 'Q10_Part_3',\n    'Paperspace \/ Gradient' : 'Q10_Part_4',\n    'Binder \/ JupyterHub' : 'Q10_Part_5',\n    'Code Ocean' : 'Q10_Part_6',\n    'IBM Watson Studio' : 'Q10_Part_7',\n    'Amazon Sagemaker Studio Notebooks' : 'Q10_Part_8',\n    'Amazon EMR Notebooks' : 'Q10_Part_9',\n    'Google Cloud Notebooks (AI Platform \/ Vertex AI)' : 'Q10_Part_10',\n    'Google Cloud Datalab' : 'Q10_Part_11',\n    'Databricks Collaborative Notebooks' : 'Q10_Part_12',\n    'Zeppelin \/ Zepl Notebooks' : 'Q10_Part_13',\n    'Deepnote Notebooks' : 'Q10_Part_14',\n    'Observable Notebooks' : 'Q10_Part_15',\n    'None' : 'Q10_Part_16',\n    'Other' : 'Q10_OTHER'\n}\n\ndictionary_of_columns['Q12'] = {\n    'NVIDIA GPUs' : 'Q12_Part_1',\n    'Google Cloud TPUs': 'Q12_Part_2',\n    'AWS Trainium Chips': 'Q12_Part_3',\n    'AWS Inferentia Chips': 'Q12_Part_4',\n    'None' : 'Q12_Part_5',\n    'Other' : 'Q12_OTHER'\n}\n\ndictionary_of_columns['Q14'] = {\n    'Matplotlib' : 'Q14_Part_1',\n    'Seaborn': 'Q14_Part_2',\n    'Plotly \/ Plotly Express' : 'Q14_Part_3',\n    'Ggplot \/ ggplot2' : 'Q14_Part_4',\n    'Shiny' : 'Q14_Part_5',\n    'D3.js' : 'Q14_Part_6',\n    'Altair' : 'Q14_Part_7',\n    'Bokeh' : 'Q14_Part_8',\n    'Geoplotlib' : 'Q14_Part_9',\n    'Leaflet \/ Folium' : 'Q14_Part_10',\n    'None' : 'Q14_Part_11',\n    'Other' : 'Q14_OTHER'\n}\n\ndictionary_of_columns['Q16'] = {\n    'Scikit-learn' : 'Q16_Part_1',\n    'TensorFlow': 'Q16_Part_2',\n    'Keras' : 'Q16_Part_3',\n    'PyTorch' : 'Q16_Part_4',\n    'Fast.ai' : 'Q16_Part_5',\n    'MXNet' : 'Q16_Part_6',\n    'Xgboost' : 'Q16_Part_7',\n    'LightGBM' : 'Q16_Part_8',\n    'CatBoost' : 'Q16_Part_9',\n    'Prophet' : 'Q16_Part_10',\n    'H20-3' : 'Q16_Part_11',\n    'Caret' : 'Q16_Part_12',\n    'Tidymodels' : 'Q16_Part_13',\n    'JAX' : 'Q16_Part_14',\n    'PyTorch Lightning' : 'Q16_Part_15',\\\n    'Huggingface' : 'Q16_Part_16',\n    'None' : 'Q16_Part_17',\n    'Other' : 'Q16_OTHER'\n}\n\ndictionary_of_columns['Q17'] = {\n    'Linear or Logistic Regression' : 'Q17_Part_1',\n    'Decision Trees or Random Forests': 'Q17_Part_2',\n    'Gradient Boosting Machines' : 'Q17_Part_3',\n    'Bayesian Approaches' : 'Q17_Part_4',\n    'Evolutionary Approaches' : 'Q17_Part_5',\n    'Dense Neural Networks (MLPs, etc)' : 'Q17_Part_6',\n    'Convolutional Neural Networks' : 'Q17_Part_7',\n    'Generative Adversarial Networks' : 'Q17_Part_8',\n    'Recurrent Neural Networks' : 'Q17_Part_9',\n    'Transformer Networks (BERT, gpt-3, etc)' : 'Q17_Part_10',\n    'None' : 'Q17_Part_11',\n    'Other' : 'Q17_OTHER'\n}\n\ndictionary_of_columns['Q18'] = {\n    'General purpose image\/video tools' : 'Q18_Part_1',\n    'Image segmentation methods': 'Q18_Part_2',\n    'Object detection methods' : 'Q18_Part_3',\n    'Image classification' : 'Q18_Part_4',\n    'Generative Networks' : 'Q18_Part_5',\n    'None' : 'Q18_Part_6',\n    'Other' : 'Q18_OTHER'\n}\n\ndictionary_of_columns['Q19'] = {\n    'Word embeddings\/vectors' : 'Q19_Part_1',\n    'Encoder-decoder models': 'Q19_Part_2',\n    'Contextualized embeddings' : 'Q19_Part_3',\n    'Transformer language models' : 'Q19_Part_4',\n    'None' : 'Q19_Part_5',\n    'Other' : 'Q19_OTHER'\n}\n\ndictionary_of_columns['Q24'] = {\n    'Analyze and understand data to influence product or business decisions' : 'Q24_Part_1',\n    'Build and\/or run the data infrastructure for storing, analyzing, and operationalizing data': 'Q24_Part_2',\n    'Build prototypes to explore applying machine learning to new areas' : 'Q24_Part_3',\n    'Build and\/or run a machine learning service that operationally improves my product or workflows' : 'Q24_Part_4',\n    'Experimentation and iteration to improve existing ML models' : 'Q24_Part_5',\n    'Do research that advances the state of the art of machine learning' : 'Q24_Part_6',\n    'None of these activities are an important part of my role at work' : 'Q24_Part_7',\n    'Other' : 'Q24_OTHER'\n}\n\ndictionary_of_columns['Q27a'] = {\n    'Amazon Web Services (AWS)' : 'Q27_A_Part_1',\n    'Microsoft Azure': 'Q27_A_Part_2',\n    'Google Cloud Platform (GCP)' : 'Q27_A_Part_3',\n    'IBM Cloud \/ Red Hat' : 'Q27_A_Part_4',\n    'Oracle Cloud' : 'Q27_A_Part_5',\n    'SAP Cloud' : 'Q27_A_Part_6',\n    'Salesforce Cloud' : 'Q27_A_Part_7',\n    'VMware Cloud' : 'Q27_A_Part_8',\n    'Alibaba Cloud' : 'Q27_A_Part_9',\n    'Tencent Cloud' : 'Q27_A_Part_10',\n    'None' : 'Q27_A_Part_11',\n    'Other' : 'Q27_A_OTHER'\n}\n\ndictionary_of_columns['Q27b'] = {\n    'Amazon Web Services (AWS)' : 'Q27_B_Part_1',\n    'Microsoft Azure': 'Q27_B_Part_2',\n    'Google Cloud Platform (GCP)' : 'Q27_B_Part_3',\n    'IBM Cloud \/ Red Hat' : 'Q27_B_Part_4',\n    'Oracle Cloud' : 'Q27_B_Part_5',\n    'SAP Cloud' : 'Q27_B_Part_6',\n    'Salesforce Cloud' : 'Q27_B_Part_7',\n    'VMware Cloud' : 'Q27_B_Part_8',\n    'Alibaba Cloud' : 'Q27_B_Part_9',\n    'Tencent Cloud' : 'Q27_B_Part_10',\n    'None' : 'Q27_B_Part_11',\n    'Other' : 'Q27_B_OTHER'\n}\n\ndictionary_of_columns['Q29a'] = {\n    'Amazon Elastic Compute Cloud (EC2)' : 'Q29_A_Part_1',\n    'Microsoft Azure Virtual Machines' : 'Q29_A_Part_2',\n    'Google Cloud Compute Engine' : 'Q29_A_Part_3',\n    'No \/ None' : 'Q29_A_Part_4',\n    'Other' : 'Q29_A_OTHER'\n}\n\ndictionary_of_columns['Q29b'] = {\n    'Amazon Elastic Compute Cloud (EC2)' : 'Q29_B_Part_1',\n    'Microsoft Azure Virtual Machines' : 'Q29_B_Part_2',\n    'Google Cloud Compute Engine' : 'Q29_B_Part_3',\n    'No \/ None' : 'Q29_B_Part_4',\n    'Other' : 'Q29_B_OTHER'\n}\n\ndictionary_of_columns['Q30a'] = {\n    'Microsoft Azure Data Lake Storage' : 'Q30_A_Part_1',\n    'Microsoft Azure Disk Storage': 'Q30_A_Part_2',\n    'Amazon Simple Storage Service (S3) ' : 'Q30_A_Part_3',\n    'Amazon Elastic File System (EFS) ' : 'Q30_A_Part_4',\n    'Google Cloud Storage (GCS) ' : 'Q30_A_Part_5',\n    'Google Cloud Filestore' : 'Q30_A_Part_6',\n    'No \/ None' : 'Q30_A_Part_7',\n    'Other' : 'Q30_A_OTHER'\n}\n\ndictionary_of_columns['Q30b'] = {\n    'Microsoft Azure Data Lake Storage' : 'Q30_B_Part_1',\n    'Microsoft Azure Disk Storage': 'Q30_B_Part_2',\n    'Amazon Simple Storage Service (S3) ' : 'Q30_B_Part_3',\n    'Amazon Elastic File System (EFS) ' : 'Q30_B_Part_4',\n    'Google Cloud Storage (GCS) ' : 'Q30_B_Part_5',\n    'Google Cloud Filestore' : 'Q30_B_Part_6',\n    'No \/ None' : 'Q30_B_Part_7',\n    'Other' : 'Q30_B_OTHER'\n}\n\ndictionary_of_columns['Q31a'] = {\n    'Amazon SageMaker' : 'Q31_A_Part_1',\n    'Azure Machine Learning Studio': 'Q31_A_Part_2',\n    'Google Cloud Vertex AI' : 'Q31_A_Part_3',\n    'DataRobot' : 'Q31_A_Part_4',\n    'Databricks' : 'Q31_A_Part_5',\n    'Dataiku' : 'Q31_A_Part_6',\n    'Alteryx' : 'Q31_A_Part_7',\n    'Rapidminer' : 'Q31_A_Part_8',\n    'No \/ None' : 'Q31_A_Part_9',\n    'Other' : 'Q31_A_OTHER'\n}\n\ndictionary_of_columns['Q31b'] = {\n    'Amazon SageMaker' : 'Q31_B_Part_1',\n    'Azure Machine Learning Studio': 'Q31_B_Part_2',\n    'Google Cloud Vertex AI' : 'Q31_B_Part_3',\n    'DataRobot' : 'Q31_B_Part_4',\n    'Databricks' : 'Q31_B_Part_5',\n    'Dataiku' : 'Q31_B_Part_6',\n    'Alteryx' : 'Q31_B_Part_7',\n    'Rapidminer' : 'Q31_B_Part_8',\n    'No \/ None' : 'Q31_B_Part_9',\n    'Other' : 'Q31_B_OTHER'\n}\n\ndictionary_of_columns['Q32a'] = {\n    'MySQL' : 'Q32_A_Part_1',\n    'PostgreSQL': 'Q32_A_Part_2',\n    'SQLite' : 'Q32_A_Part_3',\n    'Oracle Database' : 'Q32_A_Part_4',\n    'MongoDB' : 'Q32_A_Part_5',\n    'Snowflake' : 'Q32_A_Part_6',\n    'IBM Db2' : 'Q32_A_Part_7',\n    'Microsoft SQL Server' : 'Q32_A_Part_8',\n    'Microsoft Azure SQL Database' : 'Q32_A_Part_9', \n    'Microsoft Azure Cosmos DB' : 'Q32_A_Part_10',\n    'Amazon Redshift' : 'Q32_A_Part_11', \n    'Amazon Aurora' : 'Q32_A_Part_12',\n    'Amazon RDS' : 'Q32_A_Part_13',\n    'Amazon DynamoDB' : 'Q32_A_Part_14',\n    'Google Cloud BigQuery' : 'Q32_A_Part_15',\n    'Google Cloud SQL' : 'Q32_A_Part_16',\n    'Google Cloud Firestore' : 'Q32_A_Part_17',\n    'Google Cloud BigTable' : 'Q32_A_Part_18',\n    'Google Cloud Spanner' : 'Q32_A_Part_19',\n    'None' : 'Q32_A_Part_20',\n    'Other' : 'Q32_A_OTHER'\n}\n\ndictionary_of_columns['Q32b'] = {\n    'MySQL' : 'Q32_B_Part_1',\n    'PostgreSQL': 'Q32_B_Part_2',\n    'SQLite' : 'Q32_B_Part_3',\n    'Oracle Database' : 'Q32_B_Part_4',\n    'MongoDB' : 'Q32_B_Part_5',\n    'Snowflake' : 'Q32_B_Part_6',\n    'IBM Db2' : 'Q32_B_Part_7',\n    'Microsoft SQL Server' : 'Q32_B_Part_8',\n    'Microsoft Azure SQL Database' : 'Q32_B_Part_9', \n    'Microsoft Azure Cosmos DB' : 'Q32_B_Part_10',\n    'Amazon Redshift' : 'Q32_B_Part_11', \n    'Amazon Aurora' : 'Q32_B_Part_12',\n    'Amazon RDS' : 'Q32_B_Part_13',\n    'Amazon DynamoDB' : 'Q32_B_Part_14',\n    'Google Cloud BigQuery' : 'Q32_B_Part_15',\n    'Google Cloud SQL' : 'Q32_B_Part_16',\n    'Google Cloud Firestore' : 'Q32_B_Part_17',\n    'Google Cloud BigTable' : 'Q32_B_Part_18',\n    'Google Cloud Spanner' : 'Q32_B_Part_19',\n    'None' : 'Q32_B_Part_20',\n    'Other' : 'Q32_B_OTHER'\n}\n\ndictionary_of_columns['Q34a'] = {\n    'Amazon QuickSight' : 'Q34_A_Part_1',\n    'Microsoft Power BI': 'Q34_A_Part_2',\n    'Google Data Studio' : 'Q34_A_Part_3',\n    'Looker' : 'Q34_A_Part_4',\n    'Tableau' : 'Q34_A_Part_5',\n    'Salesforce' : 'Q34_A_Part_6',\n    'Tableau CRM' : 'Q34_A_Part_7',\n    'Qlik' : 'Q34_A_Part_8',\n    'Domo' : 'Q34_A_Part_9',\n    'TIBCO Spotfire' : 'Q34_A_Part_10',\n    'Alteryx' : 'Q34_A_Part_11',\n    'Sisense' : 'Q34_A_Part_12',\n    'SAP Analytics Cloud' : 'Q34_A_Part_13',\n    'Microsoft Azure Synapse' : 'Q34_A_Part_14',\n    'Thoughtspot' : 'Q34_A_Part_15',\n    'None' : 'Q34_A_Part_16',\n    'Other' : 'Q34_A_OTHER'\n}\n\ndictionary_of_columns['Q34b'] = {\n    'Amazon QuickSight' : 'Q34_B_Part_1',\n    'Microsoft Power BI': 'Q34_B_Part_2',\n    'Google Data Studio' : 'Q34_B_Part_3',\n    'Looker' : 'Q34_B_Part_4',\n    'Tableau' : 'Q34_B_Part_5',\n    'Salesforce' : 'Q34_B_Part_6',\n    'Tableau CRM' : 'Q34_B_Part_7',\n    'Qlik' : 'Q34_B_Part_8',\n    'Domo' : 'Q34_B_Part_9',\n    'TIBCO Spotfire' : 'Q34_B_Part_10',\n    'Alteryx' : 'Q34_B_Part_11',\n    'Sisense' : 'Q34_B_Part_12',\n    'SAP Analytics Cloud' : 'Q34_B_Part_13',\n    'Microsoft Azure Synapse' : 'Q34_B_Part_14',\n    'Thoughtspot' : 'Q34_B_Part_15',\n    'None' : 'Q34_B_Part_16',\n    'Other' : 'Q34_B_OTHER'\n}\n\ndictionary_of_columns['Q36a'] = {\n    'Automated data augmentation' : 'Q36_A_Part_1',\n    'Automated feature engineering\/selection': 'Q36_A_Part_2',\n    'Automated model selection' : 'Q36_A_Part_3',\n    'Automated model architecture searches' : 'Q36_A_Part_4',\n    'Automated hyperparameter tuning' : 'Q36_A_Part_5',\n    'Automation of full ML pipelines' : 'Q36_A_Part_6',\n    'No \/ None' : 'Q36_A_Part_7',\n    'Other' : 'Q36_A_OTHER'\n}\n\ndictionary_of_columns['Q36b'] = {\n    'Automated data augmentation' : 'Q36_B_Part_1',\n    'Automated feature engineering\/selection': 'Q36_B_Part_2',\n    'Automated model selection' : 'Q36_B_Part_3',\n    'Automated model architecture searches' : 'Q36_B_Part_4',\n    'Automated hyperparameter tuning' : 'Q36_B_Part_5',\n    'Automation of full ML pipelines' : 'Q36_B_Part_6',\n    'No \/ None' : 'Q36_B_Part_7',\n    'Other' : 'Q36_B_OTHER'\n}\n\ndictionary_of_columns['Q37a'] = {\n    'Google Cloud AutoML' : 'Q37_A_Part_1',\n    'H20 Driverless AI': 'Q37_A_Part_2',\n    'Databricks AutoML' : 'Q37_A_Part_3',\n    'DataRobot AutoML' : 'Q37_A_Part_4',\n    'Amazon Sagemaker Autopilot' : 'Q37_A_Part_5',\n    'Azure Automated Machine Learning' : 'Q37_A_Part_6',\n    'No \/ None' : 'Q37_A_Part_7',\n    'Other' : 'Q37_A_OTHER'\n}\n\ndictionary_of_columns['Q37b'] = {\n    'Google Cloud AutoML' : 'Q37_B_Part_1',\n    'H20 Driverless AI': 'Q37_B_Part_2',\n    'Databricks AutoML' : 'Q37_B_Part_3',\n    'DataRobot AutoML' : 'Q37_B_Part_4',\n    'Amazon Sagemaker Autopilot' : 'Q37_B_Part_5',\n    'Azure Automated Machine Learning' : 'Q37_B_Part_6',\n    'No \/ None' : 'Q37_B_Part_7',\n    'Other' : 'Q37_B_OTHER'\n}\n\ndictionary_of_columns['Q38a'] = {\n    'Neptune.ai' : 'Q38_A_Part_1',\n    'Weights & Biases': 'Q38_A_Part_2',\n    'Comet.ml' : 'Q38_A_Part_3',\n    'Sacred + Omniboard' : 'Q38_A_Part_4',\n    'TensorBoard' : 'Q38_A_Part_5',\n    'Guild.ai' : 'Q38_A_Part_6',\n    'Polyaxon' : 'Q38_A_Part_7',\n    'ClearML' : 'Q38_A_Part_8',\n    'Domino Model Monitor' : 'Q38_A_Part_9',\n    'MLflow' : 'Q38_A_Part_10',\n    'No \/ None' : 'Q38_A_Part_11',\n    'Other' : 'Q38_A_OTHER'\n}\n\ndictionary_of_columns['Q38b'] = {\n    'Neptune.ai' : 'Q38_B_Part_1',\n    'Weights & Biases': 'Q38_B_Part_2',\n    'Comet.ml' : 'Q38_B_Part_3',\n    'Sacred + Omniboard' : 'Q38_B_Part_4',\n    'TensorBoard' : 'Q38_B_Part_5',\n    'Guild.ai' : 'Q38_B_Part_6',\n    'Polyaxon' : 'Q38_B_Part_7',\n    'ClearML' : 'Q38_B_Part_8',\n    'Domino Model Monitor' : 'Q38_B_Part_9',\n    'MLflow' : 'Q38_B_Part_10',\n    'No \/ None' : 'Q38_B_Part_11',\n    'Other' : 'Q38_B_OTHER'\n}\n\ndictionary_of_columns['Q39'] = {\n    'Plotly Dash' : 'Q39_Part_1',\n    'Streamlit': 'Q39_Part_2',\n    'NBViewer' : 'Q39_Part_3',\n    'GitHub' : 'Q39_Part_4',\n    'Personal Blog' : 'Q39_Part_5',\n    'Kaggle' : 'Q39_Part_6',\n    'Colab' : 'Q39_Part_7',\n    'Shiny' : 'Q39_Part_8',\n    'None \/ I do not share my work publicly' : 'Q39_Part_9',\n    'Other' : 'Q39_OTHER'\n}\n\ndictionary_of_columns['Q40'] = {\n    'Coursera' : 'Q40_Part_1',\n    'EdX': 'Q40_Part_2',\n    'Kaggle Learn Courses' : 'Q40_Part_3',\n    'DataCamp' : 'Q40_Part_4',\n    'Fast.ai' : 'Q40_Part_5',\n    'Udacity' : 'Q40_Part_6',\n    'Udemy' : 'Q40_Part_7',\n    'LinkedIn Learning' : 'Q40_Part_8',\n    'Cloud-certification programs' : 'Q40_Part_9',\n    'University Courses' : 'Q40_Part_10',\n    'None' : 'Q40_Part_11',\n    'Other' : 'Q40_OTHER'\n}\n\ndictionary_of_columns['Q42'] = {\n    'Twitter' : 'Q42_Part_1',\n    'Email newsletters': 'Q42_Part_2',\n    'Reddit' : 'Q42_Part_3',\n    'Kaggle' : 'Q42_Part_4',\n    'Course Forums' : 'Q42_Part_5',\n    'YouTube' : 'Q42_Part_6',\n    'Podcasts' : 'Q42_Part_7',\n    'Blogs' : 'Q42_Part_8',\n    'Journal Publications' : 'Q42_Part_9',\n    'Slack Communities' : 'Q42_Part_10',\n    'None' : 'Q42_Part_11',\n    'Other' : 'Q42_OTHER'\n}\n\n# --- Drill down by industry for relevant questions ---\n\n# Now we can dig into creating \"answer dataframes\" for each\n# of the questions. These dataframes will contain information\n# needed for plotting the answers based on industry. To start\n# with, create a dataframe containing all the responses from\n# each of the industries; this makes working with them easier.\nindustry_specific_dataframes = {}\nfor industry in INDUSTRIES_OF_INTEREST.keys():\n    industry_specific_dataframes[industry] = responses_df_2021.loc[responses_df_2021[INDUSTRY_COLUMN] == industry]\n\n# Now, for each of the questions that we're interested in, set up a dataframe that looks like this:\n# - Each row represents an \"answer\" (with the user-friendly answer as the index label)\n# - There is a column for each of the \"industries of interest\"\n# - The values for each row are the percent (as an int) of respondents from each of the industries\n# that chose that answer. (Note that a lot of these answers are multiple-choice, and\n# so those percentages won't add up to \"100\". That's OK and expected; we're just looking\n# for relative popularity of the answers across the industries.)\n#\n# These dataframes end up looking something like this:\n#\n# answer_dataframes['Q7']\n# Index   Academics\/Education   Accounting\/Finance ...\n# Python  17                    20\n# R       25                    12\n# SQL     9                     2\n# ...\nanswer_dataframes = {} # This dict will hold all of these \"answer dataframes\", keyed by question (e.g. 'Q7')\nfor question in QUESTIONS_OF_INTEREST:\n    # Create an empty dataframe for the answer_dataframes dict, with all the answers as row labels,\n    # and all the industries as columns (the values at this point will be 'NA')\n    answer_dataframes[question] = pd.DataFrame(columns = INDUSTRIES_OF_INTEREST.keys(), \n                                               index = dictionary_of_columns[question].keys())\n    # Now, for each industry, calculate the percentage of respondents for each answer and store\n    # that as the \"value\" in the df\n    for industry in INDUSTRIES_OF_INTEREST.keys():\n        dict_of_percents = {} # Use this to temporarily store the percentages for each answer\n        total_respondents = len(industry_specific_dataframes[industry].index) # Number of respondents from this industry\n        for (answer, column) in dictionary_of_columns[question].items():\n            count = industry_specific_dataframes[industry][column].count() # How many people chose this answer?\n            dict_of_percents[answer] = int(round(count\/total_respondents*100)) # What was that as a percentage of the total?\n        # Finally, assign that value to the master \"answer dataframe\" for this particular question\/industry combination\n        answer_dataframes[question][industry] = answer_dataframes[question].index.map(dict_of_percents)\n        \n","089b0208":"question = 'Q7'\ndraw_heatmap(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n             cmap = sns.color_palette(\"terrain\", as_cmap=True))","0c99c7e4":"question = 'Q9'\ndraw_heatmap(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n             cmap = sns.color_palette(\"gist_earth\", as_cmap=True))","2c7e7943":"question = 'Q27a'\ndraw_bubble_plot(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n             cmap = sns.color_palette(\"RdYlBu_r\", as_cmap=True))\n\nquestion = 'Q32a'\ndraw_bubble_plot(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n             cmap = sns.color_palette(\"RdYlBu_r\", as_cmap=True))","79071eb0":"question = 'Q17'\ndraw_heatmap(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n             sns.color_palette(\"spring\", as_cmap=True))","4748565f":"question = 'Q18'\ndraw_heatmap(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n             sns.color_palette(\"summer\", as_cmap=True))","27b96dba":"question = 'Q19'\ndraw_heatmap(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n             sns.color_palette(\"autumn\", as_cmap=True))","717d2bd0":"question = 'Q39'\ndraw_bubble_plot(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n                cmap = sns.color_palette(\"plasma\", as_cmap=True))\n","5b6e3c21":"question = 'Q40'\ndraw_bubble_plot(answer_dataframes[question], QUESTIONS_OF_INTEREST[question],\n                cmap = sns.color_palette(\"ocean\", as_cmap=True))","0e8fc3d1":"question = 'Q42'\noutlier_industries = ['Government\/Public Service', 'Shipping\/Transportation', 'Marketing\/CRM',\n                      'Medical\/Pharmaceutical', 'Military\/Security\/Defense', 'Non-profit\/Service', 'Other']\nsimilar_industries = INDUSTRIES_OF_INTEREST.keys() - outlier_industries\n\ntitle = 'Commonalities: ' + QUESTIONS_OF_INTEREST[question]\ndraw_radar_chart(answer_dataframes[question][similar_industries], title,\n             cmap = sns.color_palette(\"Accent\", as_cmap=True))","2704d042":"title = 'Outliers: ' + QUESTIONS_OF_INTEREST[question]\ndraw_radar_chart(answer_dataframes[question][outlier_industries], QUESTIONS_OF_INTEREST[question],\n             cmap = sns.color_palette(\"Accent\", as_cmap=True))","ae4e280d":"There's still a lot of overlap here across the industries, again with Kaggle in the lead. However, there are some notable takeaways from this plot.\n\n**Military\/Security\/Defense** and **Non-profit\/Service** pay more attention to journal publications than do other industries, which represents a potential opportunity for reaching those users.\n\nThe **Marketing\/CRM** industry is a heavy consumer of YouTube, but significantly less so for email newsletters.\n\n<a id=\"community-takeaways\"><\/a>\n## Highlights\n\n* Many industries tend not to share their work publicly, especially **Shipping\/Transportation**, **Manufacturing\/Fabrication**, and **Insurance\/Risk Assessment**\n* Sources of information vary across the industries; YouTube is most likely to reach **Marketing\/CRM** and **Energy\/Mining**, whereas journal publications appeal to **Military\/Security\/Defense** and **Non-profit\/Service**\n* University courses are most popular with the **Military\/Security\/Defense** industry\n\n--------------------\n\n# Conclusion\n\nA full understanding of the ways in which different industries use Data Science and Machine Learning can help Kaggle and other communities to more effectively support a wider variety of users. Additionally, users from one industry can use this information to identify new opportunities to leverage DS\/ML techniques, by examining the data from other industries that are similar to their own.\n\nIn particular, the **Military\/Security\/Defense** industry is an outlier in many different areas, and looking at their specific uses of DS & ML provides clues as to how to most effectively reach that user group. Additionally, the **Hospitality\/Entertainment\/Sports** industry seems already to be broadly engaged with sharing their work, and has the potential to serve as ambassadors to other similar industries that are less involved.\n\nAnd of course, overall, respondents from all industries clearly appreciate the tools and services provided by Kaggle!\n\n-----------------------","0f6e798e":"These industries all responded fairly similarly to this question, with Kaggle a firm leader (again, unsurprising given the source of the data). YouTube and blogs are also popular sources of information, with a few respondents interested in Twitter or other sources.\n\nOne small outlier is the **Energy\/Mining** industry, which listens to podcasts more than other industries do. Additionally, **Retail\/Sales** and **Insurance\/Risk Assessment** are lighter consumers of blogs.\n\nThe remaining industries have a little more variation, but are still fairly similar.","922b47ea":"There's some interesting information here. In general, we see that Jupyter Notebooks are very popular across the board, with a much higher percentage of users than the runner-up (VSCode).\n\nAnd, again, we see that the **Military\/Security\/Defense** industry is a bit unusual. It seems to be less fond of RStudio than other industries, but Spyder, Vim\/Emacs, and MATLAB are all more popular. We start to see some variation here in some of the other industries as well:\n* **Government\/Public Service** doesn't use JupyterLab or Jupyter Notebook as much as some of the others\n* RStudio is much more popular with the **Insurance\/Risk Assessment** industry than it is with other industries\n\nNow, let's examine cloud computing platforms and big data.\n","41af7631":"# Introduction\nThis notebook will specifically examine survey responses from users who have reported being members of non-computer-related fields and industries. It seeks to provide insight into questions such as:\n\n* For what sorts of tasks are Data Science and Machine Learning being used in non-CS industries?\n* Are certain platforms or languages used more commonly by different industries?\n* Do certain industries favor different types of algorithms? \n* Are different industries getting information from different sources? Are they participating in different online communities?\n\n## Industry Legend\nAs we visualize the data, we'll be using icons to represent the various industries. This makes the charts a little less unwieldy, since some of these industry names are long!\n\n![image.png](attachment:4d281fec-df53-4e97-8b02-4ce017aac66a.png)\n\n-------------\n\n# Tools and Platforms\n\n<a id=\"tools-analysis\"><\/a>\n## Analysis\nTo begin, we'll dig into the tools and platforms being used by the different industries. (This section looks at the responses to questions 7, 9, 27, and 32 from the Kaggle survey.)","11b1a185":"GitHub is a clear winner here, and Kaggle is also fairly popular (unsurprisingly, given the source of the survey data). However, we see that a lot of users don't share their work publicly at all, especially in the **Shipping\/Transportation**, **Manufacturing\/Fabrication**, and **Insurance\/Risk Assessment** industries.\n\nWe also see that the **Hospitality\/Entertainment\/Sports** industry tends to share their work more than do other industries. Interestingly, the **Government\/Public Service** industry does not, despite programs such as the United States's [Open Data Policy](https:\/\/digital.gov\/open-data-policy-m-13-13\/) that are designed to encourage sharing.","05eb0523":"The absolute numbers for Natural Language Processing usage aren't as high as they are for Computer Vision, regardless of industry. However, look at the high usage of word embedding NLP methods by the **Hospitality\/Entertainment\/Sports** industry! Are they maybe doing sentiment analysis there?\n\n<a id=\"algorithms-takeaways\"><\/a>\n## Highlights\n\n* The **Military\/Defense** industry reports heavy use of convolutional neural nets and object detection. They're also big into image classification and general purpose image tools. There's definitely a lot of image analysis going on in this industry!\n* There are notable similarities across some of these industries -- in particular, the **Shipping\/Transportation** and **Retail\/Sales** show fairly similar responses. However, **Shipping\/Transportation** is using very little NLP processing compared to **Retail\/Sales** or some of the others. Does that indicate an opportunity for that industry? Are there ways in which the **Shipping\/Transportation** industry could learn from the usage patterns of **Retail\/Sales**?\n\n----------------------\n\n# Community\n\n<a id=\"community-analysis\"><\/a>\n## Analysis\nFinally, let's take a look at how the various industries interact with the broader Data Science and Machine Learning community. Are there ways in which we, as a community, could be better supporting some of these users? (This section looks at the responses to questions 39, 40, and 42 from the Kaggle survey.)","23bf6bf6":"Across the board, we see that most of the industries are using Python, which isn't much of a surprise. However, something interesting pops up in this heatmap in the **Military\/Security\/Defense** industry! These users are more likely to use C++ than are other industries, and they're less likely to use SQL. Let's take a look at other related questions and see if this particular industry stands out in other ways.","5bd17093":"Linear\/Logistic Regression and Decision Trees\/Random Forests are popular with most industries, with Gradient Boosting Machines popping up in use especially by the **Insurance\/Risk Assessment** industry.\n\nOf special interest here is that the **Military\/Defense** industry seems to be leveraging a wider variety of ML algorithms than some of the other industries, and they're particularly using Convolutional Neural Networks. What else are they up to?","f91f6fb3":"# Industry Usage of Data Science and Machine Learning\n\nThe disciplines of Data Science and Machine Learning have their roots in mathematics, statistics, and computer science. Perhaps it is to be expected, then, that most users of DS & ML (and related tools) work in computer-dominated fields and industries such as internet businesses and computer services, as well as in academia and research.\n\nBut Data Science and Machine Learning are also being used in more \"mainstream\" industries, and they're being used in interesting and unconventional ways. This notebook digs into the specifics of that non-traditional usage. Its primary goals are to find ways in which Kaggle and the community can best support industry users, and to identify potential missed opportunities for broader industry usage of DS & ML.\n\n\n## Survey Responses by Industry\n\nIn the 2021 Kaggle Machine Learning and Data Science survey, respondents were asked to specify the industry of their current or most recent employer. Unsurprisingly, respondents who specified their industry overwhelmingly reported being in the fields of **Computers\/Technology** (`25%`) or **Academics\/Education** (`19.7%`). However, that means that over half of the responses were from other industries, and this dataset provides a rich field for further analysis.","56ffa26e":"    \n# Data Science and Machine Learning Go Mainstream\n<div style=\"margin-left: 125px; margin-bottom:50px; border:1px dotted #660033; padding:5px 10px; background-color:#ffffff; width:375px; text-align:center\"><span style=\"color:#660033; font-style: italic; font-size:1.25em\">It's not just for computer scientists anymore!\u2122<\/span><\/div>\n\n-----------\n\n#### Table of Contents\n* **[Industry Usage of DS & ML](#Industry-Usage-of-Data-Science-and-Machine-Learning)**\n    - [Survey Responses by Industry](#Survey-Responses-by-Industry)\n* **[Introduction](#Introduction)**\n    - [Industry Legend](#Industry-Legend)\n* **[Tools and Platforms](#Tools-and-Platforms)**\n    - [Analysis](#tools-analysis)\n    - [Highlights](#tools-takeaways)\n* **[Algorithms](#Algorithms)**\n    - [Analysis](#algorithms-analysis)\n    - [Highlights](#algorithms-takeaways)\n* **[Community](#Community)**\n    - [Analysis](#community-analysis)\n    - [Highlights](#community-takeaways)\n* **[Conclusion](#Conclusion)**\n-----------","a171850e":"There's a lot to unpack here! One of the first takeaways from these heatmaps is that there's a lot of variability in the top few answers, indicating that the various industries aren't closely aligned in terms of their usage of cloud services.\n\n### Cloud Services\nThe **Government\/Public Service** and **Non-profit\/Service** industries shy away from AWS (perhaps due to perceptions of cost or lack of security), whereas **Hospitality\/Entertainment\/Sports**, **Insurance\/Risk Assessment**, and **Broadcasting\/Communications** rely heavily on Amazon services.\n\nInterestingly, Google Cloud Platform is especially popular with the **Marketing\/CRM** and **Hospitality\/Entertainment\/Sports** industries.\n\nAnd, regardless of industry, services other than the \"big three\" of AWS, Azure, and GCP are not very popular at all.\n\n### Big Data Products\nAs far as big data products are concerned, MySQL is the leader for most industries. However, the **Insurance\/Risk Assessment** industry is a big user of Microsoft SQL Server; is there some legacy code there? Additionally, **Marketing\/CRM** uses Google Cloud BigQuery, but not as much as **Hospitality\/Entertainment\/Sports** does!\n\n<a id=\"tools-takeaways\"><\/a>\n## Highlights\n\n* **Military\/Defense** is using more established tools, with C++ and Vim\/Emacs being more popular than in other industries\n* The **Government\/Public Service** industry is very hesitant in its use of cloud platforms; AWS is less popular there than it is in other industries, and \"None\" is a popular choice for Government\/Public Service\n* **Hospitality\/Entertainment\/Sports** and **Marketing\/CRM** are fairly similar overall in terms of tools used; notably, these are two of the main users of Google Cloud Platform\n\n\n-------------------\n\n# Algorithms\n    \n<a id=\"algorithms-analysis\"><\/a>\n## Analysis\nNow, we'll look more closely at the algorithms being used by each of these industries. This information should start to give us an idea of the sorts of tasks for which different industries are using data science and machine learning. (This section looks at the responses to questions 17, 18, and 19 from the Kaggle survey.)\n","ca312a26":"Coursera is a very popular learning platform, especially among respondents in the **Broadcasting\/Communications** and **Shipping\/Transportation** industries! Kaggle Learn is also popular, although some of that may be due to selection bias given the nature of the survey.\n\nOnce again the **Military\/Defense** industry stands out, with a higher percentage of these respondents learning about data science from university courses. This may be due in part to the US Military's sponsorship of college learning through [ROTC](https:\/\/www.todaysmilitary.com\/education-training\/rotc-programs).\n\nFinally, let's take a look at media sources. For this section, there's a lot of overlap, so we'll break them down into two groups: industries that have very similar responses, and then a set of outliers. This allows us to clearly see overlap in specific industries.","139762b4":"Wow, that really jumps right out at us! It seems that image classification is heavily used by **Military\/Defense**, especially as compared to other industries. That industry is also using object detection methods and general purpose image tools pretty heavily.\n\nMeanwhile, when it comes to computer vision, other industries are primarily using image classification. In particular, usage by the **Medical\/Pharmaceutical** industry may indicate efforts to identify clinical malignancies or other visual patterns in patient data."}}