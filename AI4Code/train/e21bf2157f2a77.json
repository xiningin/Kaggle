{"cell_type":{"8fe623ff":"code","96463e86":"code","2fb47a5e":"code","18fe111e":"code","0d100128":"code","7d30ebda":"code","1efeaf0c":"code","5a6ec0c5":"code","269014bd":"code","ffe3336a":"code","207a364f":"code","44827c9e":"code","90e3f746":"code","6a46d5bb":"code","ad549d52":"code","5336e0bc":"code","2151b684":"code","eb3c61e7":"code","95d091af":"code","a579867f":"code","1c3e6a10":"code","4c4f5aca":"code","003535e6":"code","dad0e559":"code","da6d0fdb":"code","a15e2db2":"code","f3f968e8":"code","676d54ec":"code","c43b729e":"code","9691bb18":"code","2e37fd8e":"code","8f2e9628":"code","e24eb0cc":"code","6fcec10e":"code","962dd4f4":"code","f9c912b7":"code","6309a0f3":"code","36df7f52":"code","a09af6b3":"code","e332f8ff":"code","82b9692e":"code","8a11a574":"code","89499ad0":"code","1aa4b5c7":"code","920b265a":"code","6037f134":"code","d5e61449":"code","5ef5b693":"code","b5e3c83e":"code","03dacccb":"code","1ff2068f":"code","c82cc440":"code","3809b64c":"code","9b04d237":"code","115026ef":"code","703eaa1a":"code","1d36e035":"code","662e20eb":"code","54bfea25":"code","7f44aae6":"code","1b643f2e":"code","f05e238e":"code","62494230":"code","8f4710d3":"code","641eb614":"code","94924615":"code","1e035d14":"code","5c09f0d6":"code","19ddd01a":"code","3e992d94":"code","160e24a4":"code","646f7b1b":"code","a7aed67d":"code","60c1df2f":"code","4bc664b2":"code","522ee3ce":"code","adc97b13":"code","092ee184":"code","390c049c":"code","6f6eac1c":"code","d1d06671":"code","0d20b000":"code","f9c51bcc":"code","40d9cc13":"code","07a66c14":"code","43172126":"code","6147179c":"code","6e1ea1a6":"code","9fdc8f48":"code","f3337447":"code","7c249705":"code","1a28b30e":"code","594c8a1d":"code","33e008bf":"code","eef85b9e":"code","26d4c2ea":"code","1017eed2":"code","1eb76b98":"code","aa4346d0":"code","e32439c2":"code","a810d218":"code","91257960":"code","7fd0660b":"code","098ef22f":"code","b2fc106d":"code","92a4c120":"code","c37abd54":"code","29a09856":"code","994aa5bb":"code","c3eee994":"code","08eda367":"code","ab43ef7f":"code","67e086b6":"code","a9d0d895":"markdown","c923d319":"markdown","2f80e4a4":"markdown","b4a41d3f":"markdown","248cbc8e":"markdown","011e5525":"markdown","8da3136c":"markdown","5fd81b98":"markdown","e19cb59c":"markdown","c5dc6233":"markdown","5190a77e":"markdown","f5200420":"markdown","eef86122":"markdown","4a18f96c":"markdown","10162e2c":"markdown","f5001780":"markdown","89ce2cbf":"markdown","ad4b6572":"markdown","d71cced4":"markdown","efa7f65e":"markdown","e96565f4":"markdown","24426efa":"markdown","81f298ff":"markdown","e2ddb2f5":"markdown","1e8f4521":"markdown","a2a3816b":"markdown","410e749c":"markdown","e603f546":"markdown","2c912bf4":"markdown","59123a82":"markdown","13a145d9":"markdown","97e3f028":"markdown","f13fb7db":"markdown","17674ca2":"markdown","2f78e86d":"markdown","91397e03":"markdown","f61294ec":"markdown","691b1dbc":"markdown","4bd22679":"markdown","6d845cae":"markdown","152d905c":"markdown","d57a21fd":"markdown","cd8cd2e6":"markdown","19b372e8":"markdown","8df3fe6b":"markdown","babb66f0":"markdown","84793d44":"markdown","d064b68c":"markdown","d22ed04b":"markdown","3f9999bb":"markdown","40a9ff06":"markdown","c6ff6720":"markdown","8b4bd943":"markdown","d1748611":"markdown","1799e556":"markdown","75dab2e7":"markdown","0cd51bc8":"markdown","7218e85e":"markdown","4c950e30":"markdown","831416d6":"markdown","4e2d7697":"markdown","98241d74":"markdown","197df1fb":"markdown","c15a364c":"markdown","29c43fd3":"markdown"},"source":{"8fe623ff":"# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport missingno as missing\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\nimport random\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import learning_curve, validation_curve\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.metrics import roc_curve, roc_auc_score ,auc, plot_roc_curve\nfrom sklearn import svm\nimport sklearn.metrics\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n","96463e86":"# input\/studentperformancebig\/StudentsPerformanceBig.csv\n# input\/students-performance-in-exams\/StudentsPerformance.csv\ndf = pd.read_csv(\"..\/input\/studentperformancebig\/StudentsPerformanceBig.csv\")\n\n# preview the data\ndf.head()","2fb47a5e":"df.info()","18fe111e":"df.describe()","0d100128":"# lets check the no. of unique items present in the categorical column\n\ndf.select_dtypes('object').nunique()","7d30ebda":"plt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.distplot(df['math score'])\n\nplt.subplot(1, 3, 2)\nsns.distplot(df['reading score'])\n\nplt.subplot(1, 3, 3)\nsns.distplot(df['writing score'])\n\nplt.suptitle('Checking for Skewness', fontsize = 15)\nplt.show()\n\n","1efeaf0c":"\nplt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.boxplot(x=\"race\/ethnicity\", y=\"math score\", hue=\"gender\", data=df)\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.boxplot(x=\"race\/ethnicity\", y=\"reading score\", hue=\"gender\", data=df)\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.boxplot(x=\"race\/ethnicity\", y=\"writing score\", hue=\"gender\", data=df)\nplt.title('WRITING SCORES')\nplt.show()","5a6ec0c5":"plt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.boxplot(x=\"lunch\", y=\"math score\", hue=\"gender\", data=df)\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.boxplot(x=\"lunch\", y=\"reading score\", hue=\"gender\", data=df)\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.boxplot(x=\"lunch\", y=\"writing score\", hue=\"gender\", data=df)\nplt.title('WRITING SCORES')\nplt.show()","269014bd":"plt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.boxplot(x=\"parental level of education\", y=\"math score\", hue=\"gender\", data=df)\nplt.title('MATH SCORES')\nplt.xticks(rotation = 90)\nplt.subplot(1, 3, 2)\nsns.boxplot(x=\"parental level of education\", y=\"reading score\", hue=\"gender\", data=df)\nplt.title('READING SCORES')\nplt.xticks(rotation = 90)\nplt.subplot(1, 3, 3)\nsns.boxplot(x=\"parental level of education\", y=\"writing score\", hue=\"gender\", data=df)\nplt.title('WRITING SCORES')\nplt.xticks(rotation = 90)\nplt.show()\n","ffe3336a":"plt.figure(figsize=(25,6))\nplt.subplot(1, 3, 1)\nsns.boxplot(x=\"test preparation course\", y=\"math score\", hue=\"gender\", data=df)\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.boxplot(x=\"test preparation course\", y=\"reading score\", hue=\"gender\", data=df)\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.boxplot(x=\"test preparation course\", y=\"writing score\", hue=\"gender\", data=df)\nplt.title('WRITING SCORES')\nplt.show()","207a364f":"plt.figure(figsize=(25,6))\nsns.pairplot(data=df,hue='gender',plot_kws={'alpha':0.2})\nplt.show()","44827c9e":"df['math_pass']=np.where(df['math score'] >= 65,'P','F')\ndf['reading_pass']=np.where(df['reading score'] >= 65,'P','F')\ndf['writing_pass']=np.where(df['writing score'] >= 65,'P','F')\ndf['Pass'] = df.apply(lambda x :1 if x['math score'] >= 65 and \n                      x['reading score'] >= 65 and \n                      x['writing score'] >= 65 \n                      else 0, axis =1)\ndf.head()\ndf.Pass.value_counts()","90e3f746":"plt.figure(figsize=(20,15))\n\nplt.subplot(4,3,1)\nsns.countplot(x='parental level of education', hue='writing_pass', data=df)\nplt.xticks(rotation=45)\nplt.subplot(4,3,2)\nsns.countplot(x='parental level of education', hue='math_pass', data=df)\nplt.xticks(rotation=45)\nplt.subplot(4,3,3)\nsns.countplot(x='parental level of education', hue='reading_pass', data=df)\nplt.xticks(rotation=45)\n\nplt.subplot(4,3,4)\nsns.countplot(x='gender', hue='writing_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Gender - Writing Pass\")\nplt.subplot(4,3,5)\nsns.countplot(x='gender', hue='math_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Gender - Math Pass\")\nplt.subplot(4,3,6)\nsns.countplot(x='gender', hue='reading_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Gender - Reading Pass\")\n\nplt.subplot(4,3,7)\nsns.countplot(x='test preparation course', hue='writing_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Preparation - Writing Pass\")\nplt.subplot(4,3,8)\nsns.countplot(x='test preparation course', hue='math_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Preparation - Math Pass\")\nplt.subplot(4,3,9)\nsns.countplot(x='test preparation course', hue='reading_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Preparation - Reading Pass\")\n\nplt.subplot(4,3,10)\nsns.countplot(x='race\/ethnicity', hue='writing_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Race - Writing Pass\")\nplt.subplot(4,3,11)\nsns.countplot(x='race\/ethnicity', hue='math_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Race - Math Pass\")\nplt.subplot(4,3,12)\nsns.countplot(x='race\/ethnicity', hue='reading_pass', data=df)\nplt.xticks(rotation=45)\nplt.title(\"Race - Reading Pass\")\n\nplt.tight_layout()\nplt.show()\n","6a46d5bb":"map1 = {\"high school\": 1, \"some high school\": 1,\n        \"associate's degree\": 2,\n        \"some college\": 3,\n        \"bachelor's degree\": 4,\n        \"master's degree\": 5}\ndf['parental level of education']  = df['parental level of education'].map(map1)\n\nmap2 = {\"free\/reduced\": 0,\n        \"standard\": 1}\ndf['lunch']  = df['lunch'].map(map2)\n\nmap3 = {\"none\": 0,\n        \"completed\": 1}\ndf['test preparation course']  = df['test preparation course'].map(map3)\n\nmap4 = {\"female\": 0,\n        \"male\": 1}\ndf['gender']  = df['gender'].map(map4)\n\nmap5 = {\"group A\": 1,\n        \"group B\": 2,\n        \"group C\": 3,\n        \"group D\": 4,\n        \"group E\": 5}\ndf['race\/ethnicity']  = df['race\/ethnicity'].map(map5)\n","ad549d52":"plt.figure(figsize=(13,10))\n\nplt.subplot(4,3,1)\nsns.barplot(x = \"parental level of education\" , y=\"writing score\" , data=df)\nplt.title(\"Parental level - Writing Scores\")\nplt.subplot(4,3,2)\nsns.barplot(x = \"parental level of education\" , y=\"math score\" , data=df)\nplt.title(\"Parental level - Math Scores\")\nplt.subplot(4,3,3)\nsns.barplot(x = \"parental level of education\" , y=\"reading score\" , data=df)\nplt.title(\"Parental level - Reading Scores\")\n\nplt.subplot(4,3,4)\nsns.barplot(x = \"gender\" , y=\"writing score\" , data=df)\nplt.title(\"Gender - Writing Scores\")\nplt.subplot(4,3,5)\nsns.barplot(x = \"gender\" , y=\"math score\" , data=df)\nplt.title(\"Gender - Math Scores\")\nplt.subplot(4,3,6)\nsns.barplot(x = \"gender\" , y=\"reading score\" , data=df)\nplt.title(\"Gender - Reading Scores\")\n\nplt.subplot(4,3,7)\nsns.barplot(x = \"test preparation course\" , y=\"writing score\" , data=df)\nplt.title(\"Preparation - Writing Scores\")\nplt.subplot(4,3,8)\nsns.barplot(x = \"test preparation course\" , y=\"math score\" , data=df)\nplt.title(\"Preparation - Math Scores\")\nplt.subplot(4,3,9)\nsns.barplot(x = \"test preparation course\" , y=\"reading score\" , data=df)\nplt.title(\"Preparation - Reading Scores\")\n\nplt.subplot(4,3,10)\nsns.barplot(x = \"race\/ethnicity\" , y=\"writing score\" , data=df)\nplt.title(\"Race - Writing Scores\")\nplt.subplot(4,3,11)\nsns.barplot(x = \"race\/ethnicity\" , y=\"math score\" , data=df)\nplt.title(\"Race - Math Scores\")\nplt.subplot(4,3,12)\nsns.barplot(x = \"race\/ethnicity\" , y=\"reading score\" , data=df)\nplt.title(\"Race - Reading Scores\")\n\nplt.tight_layout()\nplt.show()","5336e0bc":"plt.subplots(figsize=(15,10)) \nsns.heatmap(df.corr(), annot = True, fmt = \".2f\")\nplt.show()","2151b684":"dfDrop = df.drop(['math score','reading score','writing score', 'math_pass', 'reading_pass','writing_pass'], axis=1)\ndfDrop.head()\n","eb3c61e7":"dfDrop.info()","95d091af":"plt.subplots(figsize=(15,10)) \nsns.heatmap(dfDrop.corr(), annot = True, fmt = \".2f\")\nplt.show()","a579867f":"def plotLearningCurves(X_train, y_train, classifier, title):\n    train_sizes, train_scores, test_scores = learning_curve(\n            classifier, X_train, y_train, cv=5, scoring=\"accuracy\")\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\" ,label=\"Training Error\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\" ,label=\"Cross Validation Error\")\n    \n    plt.legend()\n    plt.grid()\n    plt.title(title, fontsize = 18, y = 1.03)\n    plt.xlabel('Data Size', fontsize = 14)\n    plt.ylabel('Error', fontsize = 14)\n    plt.tight_layout()","1c3e6a10":"def plotValidationCurves(X_train, y_train, classifier, param_name, param_range, title):\n    train_scores, test_scores = validation_curve(\n        classifier, X_train, y_train, param_name = param_name, param_range = param_range,\n        cv=5, scoring=\"accuracy\")\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.plot(param_range, train_scores_mean, 'o-', color=\"b\" ,label=\"Training Error\")\n    plt.plot(param_range, test_scores_mean, 'o-', color=\"r\" ,label=\"Cross Validation Error\")\n\n    plt.legend()\n    plt.grid()\n    plt.title(title, fontsize = 18, y = 1.03)\n    plt.xlabel('Complexity', fontsize = 14)\n    plt.ylabel('Error', fontsize = 14)\n    plt.tight_layout()","4c4f5aca":"def printConfusionMatrix(y_train, pred):\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_test, pred))\n    print(\"Classification Report:\",)\n    print (classification_report(y_test, pred))\n    print(\"Accuracy:\", accuracy_score(y_test, pred))","003535e6":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","dad0e559":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=3,\n                                    min_samples_split=9,\n                                    min_samples_leaf=5\n                                   )\nrf.fit(X_train, y_train)\nrf_pred1 = rf.predict(X_test)","da6d0fdb":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 1'\nplotLearningCurves(X_train, y_train, rf, title)","a15e2db2":"title = 'Random Forest Validation Curve 1'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)","f3f968e8":"printConfusionMatrix(y_test, rf_pred1)","676d54ec":"plot_roc_curve(rf, X_test, y_test)\nplt.show()\n","c43b729e":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=3,\n                                    criterion='entropy',\n                                    min_samples_split=9,\n                                    min_samples_leaf=5\n                                   )\nrf.fit(X_train, y_train)\nrf_pred2 = rf.predict(X_test)","9691bb18":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 2'\nplotLearningCurves(X_train, y_train, rf, title)","2e37fd8e":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Validation Curve 2'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)","8f2e9628":"printConfusionMatrix(y_test, rf_pred2)","e24eb0cc":"plot_roc_curve(rf, X_test, y_test)\nplt.show()","6fcec10e":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=3,\n                                    criterion='entropy',\n                                    min_samples_split=10,\n                                    min_samples_leaf=5\n                                   )\nrf.fit(X_train, y_train)\nrf_pred3 = rf.predict(X_test)","962dd4f4":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 3'\nplotLearningCurves(X_train, y_train, rf, title)","f9c912b7":"title = 'Random Forest Validation Curve 3'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)","6309a0f3":"printConfusionMatrix(y_test, rf_pred3)","36df7f52":"plot_roc_curve(rf, X_test, y_test)\nplt.show()","a09af6b3":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=5,\n                                    criterion='entropy',\n                                    min_samples_split=9,\n                                    min_samples_leaf=10\n                                   )\nrf.fit(X_train, y_train)\nrf_pred4 = rf.predict(X_test)","e332f8ff":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 4'\nplotLearningCurves(X_train, y_train, rf, title)","82b9692e":"title = 'Random Forest Validation Curve 4'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)","8a11a574":"printConfusionMatrix(y_test, rf_pred4)","89499ad0":"plot_roc_curve(rf, X_test, y_test)\nplt.show()","1aa4b5c7":"rf = RandomForestClassifier(n_estimators = 9,\n                                    max_depth=5,\n                                    criterion='entropy',\n                                    max_features='sqrt',\n                                    min_samples_split=9,\n                                    min_samples_leaf=5\n                                   )\nrf.fit(X_train, y_train)\nrf_pred5 = rf.predict(X_test)","920b265a":"plt.figure(figsize = (16,5))\ntitle = 'Random Forest Learning Curve 5'\nplotLearningCurves(X_train, y_train, rf, title)\n","6037f134":"title = 'Random Forest Validation Curve 5'\nparam_name = 'n_estimators'\nparam_range = [4, 6, 9]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, rf, param_name, param_range, title)\n","d5e61449":"\nprintConfusionMatrix(y_test, rf_pred5)\n","5ef5b693":"plot_roc_curve(rf, X_test, y_test)\nplt.show()","b5e3c83e":"Classifier = RandomForestClassifier()\ngrid_obj = GridSearchCV(Classifier,\n                        {'n_estimators': [4, 6, 9],\n                         'max_features': ['log2', 'sqrt','auto'],\n                         'criterion': ['entropy', 'gini'],\n                         'max_depth': [2, 3, 5, 8],\n                         'min_samples_split': [2, 5, 8, 10],\n                         'min_samples_leaf': [1, 3, 5]\n                        },\n                        scoring=make_scorer(accuracy_score))\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nClassifier = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nClassifier.fit(X_train, y_train)\n\npredictions = Classifier.predict(X_test)\n\nprint(\"Best Params: \" , grid_obj.best_estimator_)\nprint(\"Best Score: \" , grid_obj.best_score_)","03dacccb":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n","1ff2068f":"svmC=svm.SVC(kernel = 'linear' , gamma=0.01, C=0.05)\nsvmC.fit(X_train,y_train)\n\nsvm_pred1=svmC.predict(X_test)","c82cc440":"plt.figure(figsize=(16,5))\ntitle='Support Vector Machine Learning Curve 1'\nplotLearningCurves(X_train,y_train,svmC,title)","3809b64c":"title = 'Support Vector Machine Validation Curve 1'\nparam_name = 'C'\nparam_range = [0.1,1, 10]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, svmC, param_name, param_range, title)","9b04d237":"printConfusionMatrix(y_test, svm_pred1)","115026ef":"plot_roc_curve(svmC, X_test, y_test)\nplt.show()","703eaa1a":"svmC=svm.SVC(kernel = 'rbf' , gamma=0.05, C=1)\nsvmC.fit(X_train,y_train)\n\nsvm_pred2=svmC.predict(X_test)","1d36e035":"plt.figure(figsize=(16,5))\ntitle='Support Vector Machine Learning Curve 2'\nplotLearningCurves(X_train,y_train,svmC,title)","662e20eb":"title = 'Support Vector Machine Validation Curve 2'\nparam_name = 'C'\nparam_range = [0.1,1, 10]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, svmC, param_name, param_range, title)","54bfea25":"printConfusionMatrix(y_test, svm_pred2)\n","7f44aae6":"plot_roc_curve(svmC, X_test, y_test)\nplt.show()","1b643f2e":"svmC=svm.SVC(kernel = 'sigmoid' , gamma=1, C=100)\nsvmC.fit(X_train,y_train)\n\nsvm_pred3=svmC.predict(X_test)\n","f05e238e":"plt.figure(figsize=(16,5))\ntitle='Support Vector Machine Learning Curve 3'\nplotLearningCurves(X_train,y_train,svmC,title)","62494230":"title = 'Support Vector Machine Validation Curve 3' \nparam_name = 'C'\nparam_range = [0.1,1, 10]\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, svmC, param_name, param_range, title)","8f4710d3":"printConfusionMatrix(y_test, svm_pred3)\n","641eb614":"plot_roc_curve(svmC, X_test, y_test)\nplt.show()","94924615":"param_grid = {'C': [0.05, 1,10, 20, 50, 100], 'gamma': [0.01,0.1,0.2,1],'kernel': ['sigmoid', 'rbf','linear']}\ngrid = GridSearchCV(svm.SVC(),param_grid,refit=True,verbose=2)\nsvclassifier = grid.fit(X_train,y_train)\nSvcPredictions = svclassifier.predict(X_test)\n\nprint(\"Best Params: \" , grid.best_estimator_)\nprint(\"Best Score: \" , grid.best_score_)","1e035d14":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","5c09f0d6":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=3)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred1=knn.predict(X_test)","19ddd01a":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 1'\nplotLearningCurves(X_train,y_train,knn,title)","3e992d94":"title = 'KNN Validation Curve 1' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","160e24a4":"printConfusionMatrix(y_test, knn_pred1)","646f7b1b":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","a7aed67d":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=7)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred2=knn.predict(X_test)","60c1df2f":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 2'\nplotLearningCurves(X_train,y_train,knn,title)","4bc664b2":"title = 'KNN Validation Curve 2' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","522ee3ce":"printConfusionMatrix(y_test, knn_pred2)","adc97b13":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","092ee184":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=10)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred3=knn.predict(X_test)","390c049c":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 3'\nplotLearningCurves(X_train,y_train,knn,title)","6f6eac1c":"title = 'KNN Validation Curve 3' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","d1d06671":"printConfusionMatrix(y_test, knn_pred3)","0d20b000":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","f9c51bcc":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=20)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred4=knn.predict(X_test)","40d9cc13":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 4'\nplotLearningCurves(X_train,y_train,knn,title)","07a66c14":"title = 'KNN Validation Curve 4' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","43172126":"printConfusionMatrix(y_test, knn_pred4)","6147179c":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","6e1ea1a6":"# Create KNN classifier\nknn=KNeighborsClassifier(n_neighbors=17)\n# Fit the classifier to the data\nknn.fit(X_train,y_train)\n#show first 5 model predictions on the test data\nknn_pred5=knn.predict(X_test)","9fdc8f48":"plt.figure(figsize=(16,5))\ntitle='KNN Learning Curve 5'\nplotLearningCurves(X_train,y_train,knn,title)","f3337447":"title = 'KNN Validation Curve 5' \nparam_name = 'n_neighbors'\nparam_range = np.arange(1,9,2)\nplt.figure(figsize = (16,5))\nplotValidationCurves(X_train, y_train, knn, param_name, param_range, title)","7c249705":"printConfusionMatrix(y_test, knn_pred5)","1a28b30e":"plot_roc_curve(knn, X_test, y_test)\nplt.show()","594c8a1d":"#create new a knn model\nknn2=KNeighborsClassifier()\n#create a dictionary of all values we want to test for n_neighbors\nparam_grid= {'n_neighbors': np.arange(1, 20)}\n#use gridsearch to test all values for n_neighbors\nknn_gscv=GridSearchCV(knn2, param_grid, cv=5)\n#fit model to data\nknn_gscv.fit(X, y)\n\nprint(\"Best Params: \" , knn_gscv.best_estimator_)\nprint(\"Best Score: \" , knn_gscv.best_score_)","33e008bf":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values","eef85b9e":"# Encoding categorical inputs\nencoder = OneHotEncoder(handle_unknown=\"ignore\")\nencoder.fit(X)\nX = encoder.transform(X)\n\n# 80\/20 train split ratio\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=1)","26d4c2ea":"mlp = MLPClassifier(\n    max_iter=3000,\n    hidden_layer_sizes=[17, 13, 7], \n    solver=\"sgd\", \n    random_state=1,\n    verbose=False\n).fit(X_train, y_train)\n\nmlp_pred1 = mlp.predict(X_test)","1017eed2":"def format_scores_as_dataframe(labels, train_scores, test_scores):\n    learning_data = {\"labels\": [], \"type\": [], \"score\": []}\n\n    for i in range(len(train_sizes)):\n        for j in range(len(train_scores)):\n            learning_data[\"labels\"].append(labels[i])\n            learning_data[\"type\"].append(\"train\")\n            learning_data[\"score\"].append(train_scores[i][j])\n            learning_data[\"labels\"].append(labels[i])\n            learning_data[\"type\"].append(\"test\")\n            learning_data[\"score\"].append(test_scores[i][j])\n            \n    return pd.DataFrame.from_dict(learning_data)","1eb76b98":"train_sizes, train_scores, test_scores = learning_curve(mlp, X, y)\n\nlearning_curve_df = format_scores_as_dataframe(train_sizes, train_scores, test_scores)\n\n# train and test learning scores results\nax = sns.lineplot(x=\"labels\", y=\"score\", hue=\"type\", data=learning_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Learning Curve for MLP Algorithm\")\ndev_null = ax.set(xlabel=\"Samples\", ylabel=\"Error\")","aa4346d0":"scores = cross_val_score(mlp, X, y)\n\nscores, scores.mean(), scores.std()\n\ndev_null = sns.lineplot(x=[1,2,3,4,5], y=scores)\ndev_null.set_title(\"Cross Score Distribution\")\ndev_null = dev_null.set(xlabel=\"# of runs\", ylabel=\"Accuracy\")","e32439c2":"\ncross_val_result = cross_validate(mlp, X, y, return_train_score=True)\n\n\n#validation_curve(mlp, X, y, param_name=\"alpha\", param_range=[0.0001, 0.001, 0.05])\ntrain_scores, test_scores = validation_curve(mlp, X, y, param_name=\"hidden_layer_sizes\", param_range=([5], [10], [10,5], [15, 10], [25,10,5]))\n\nval_curve_data = {\"labels\": [], \"type\": [], \"scores\": []}\nparam_ranges = [\"[5]\", \"[10]\", \"[10,5]\", \"[15,10]\", \"[25,10,5]\"]\n\nfor i in range(len(train_scores)):\n    for j in range(len(train_scores[i])):\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"train\")\n        val_curve_data[\"scores\"].append(train_scores[i][j])\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"test\")\n        val_curve_data[\"scores\"].append(test_scores[i][j])\n        \nval_curve_df = pd.DataFrame.from_dict(val_curve_data)\n\nax = sns.lineplot(x=\"labels\", y=\"scores\", hue=\"type\", data = val_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Validation Curve for our MLP model\")\ndev_null = ax.set(xlabel=\"Layers\/Neurons\", ylabel=\"Accuracy Score\")","a810d218":"\nprintConfusionMatrix(y_test, mlp_pred1)","91257960":"plot_roc_curve(mlp, X_test, y_test)\nplt.show()","7fd0660b":"mlp = MLPClassifier(\n    max_iter=3000,\n    hidden_layer_sizes=[17, 13, 7], \n    solver=\"sgd\",\n    activation=\"logistic\",\n    random_state=1,\n    verbose=False\n).fit(X_train, y_train)\n\nmlp_pred2 = mlp.predict(X_test)","098ef22f":"train_sizes, train_scores, test_scores = learning_curve(mlp, X, y)\n\nlearning_curve_df = format_scores_as_dataframe(train_sizes, train_scores, test_scores)\n\n# train and test learning scores results\nax = sns.lineplot(x=\"labels\", y=\"score\", hue=\"type\", data=learning_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Learning Curve for MLP Algorithm\")\ndev_null = ax.set(xlabel=\"Samples\", ylabel=\"Error\")","b2fc106d":"scores = cross_val_score(mlp, X, y)\n\nscores, scores.mean(), scores.std()\n\ndev_null = sns.lineplot(x=[1,2,3,4,5], y=scores)\ndev_null.set_title(\"Cross Score Distribution\")\ndev_null = dev_null.set(xlabel=\"# of runs\", ylabel=\"Accuracy\")","92a4c120":"cross_val_result = cross_validate(mlp, X, y, return_train_score=True)\n\n#validation_curve(mlp, X, y, param_name=\"alpha\", param_range=[0.0001, 0.001, 0.05])\ntrain_scores, test_scores = validation_curve(mlp, X, y, param_name=\"hidden_layer_sizes\", param_range=([5], [10], [10,5], [15, 10], [25,10,5]))\n\nval_curve_data = {\"labels\": [], \"type\": [], \"scores\": []}\nparam_ranges = [\"[5]\", \"[10]\", \"[10,5]\", \"[15,10]\", \"[25,10,5]\"]\n\nfor i in range(len(train_scores)):\n    for j in range(len(train_scores[i])):\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"train\")\n        val_curve_data[\"scores\"].append(train_scores[i][j])\n        val_curve_data[\"labels\"].append(param_ranges[i])\n        val_curve_data[\"type\"].append(\"test\")\n        val_curve_data[\"scores\"].append(test_scores[i][j])\n        \nval_curve_df = pd.DataFrame.from_dict(val_curve_data)\n\nax = sns.lineplot(x=\"labels\", y=\"scores\", hue=\"type\", data = val_curve_df, marker=\"o\", ci=None)\nax.set_title(\"Validation Curve for our MLP model\")\ndev_null = ax.set(xlabel=\"Layers\/Neurons\", ylabel=\"Accuracy Score\")","c37abd54":"printConfusionMatrix(y_test, mlp_pred2)\n","29a09856":"plot_roc_curve(mlp, X_test, y_test)\nplt.show()","994aa5bb":"parameters = {\n    \"hidden_layer_sizes\": [[8], [5]], #, [2], [8,8], [8,5], [5,8], [5,2], [2,2], [8,5,2], [8,5,5], [13,8,4], [17,13,7]\n    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"], \n    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"], \n    \"max_iter\": [200, 500, ] #1000, 2000, 3000, 5000\n}\n\n# Brace yourself, this will take a while\nmlp = MLPClassifier()\ngs = GridSearchCV(mlp, parameters)\ngs.fit(X_train, y_train)\ngs.predict(X_test)\n\nprint(\"Best Params: \" , gs.best_estimator_)\nprint(\"Best Score: \" , gs.best_score_)","c3eee994":"\n# Instantiate the classfiers and make a list\nclassifiers = [RandomForestClassifier(),\n                MLPClassifier(), \n               svm.SVC(),\n               KNeighborsClassifier()]\n\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n\n\n# print('auc =', auc)\nlr_fpr1, lr_tpr1, _ = roc_curve(y_test, rf_pred5)\nlr_fpr2, lr_tpr2, _ = roc_curve(y_test,  mlp_pred1)\nlr_fpr3, lr_tpr3, _ = roc_curve(y_test, svm_pred1)\nlr_fpr4, lr_tpr4, _ = roc_curve(y_test, knn_pred5)\n\n# fpr , tpr, _= roc_curve(X_test, predict6_test)\nauc1 = roc_auc_score(y_test, rf_pred5)\nauc2 = roc_auc_score(y_test,  mlp_pred1)\nauc3 = roc_auc_score(y_test, svm_pred1)\nauc4 = roc_auc_score(y_test, knn_pred5)\n \n    \nresult_table = result_table.append({'classifiers':RandomForestClassifier.__class__.__name__,\n                                     'fpr':lr_fpr1, \n                                     'tpr':lr_tpr1, \n                                     'auc':auc1}, ignore_index=True)\n\nresult_table = result_table.append({'classifiers':MLPClassifier.__class__.__name__,\n                                     'fpr':lr_fpr2, \n                                     'tpr':lr_tpr2, \n                                     'auc':auc2}, ignore_index=True)\n\nresult_table = result_table.append({'classifiers':svm.SVC.__class__.__name__,\n                                     'fpr':lr_fpr3, \n                                     'tpr':lr_tpr3, \n                                     'auc':auc3}, ignore_index=True)\n\nresult_table = result_table.append({'classifiers':KNeighborsClassifier.__class__.__name__,\n                                     'fpr':lr_fpr4, \n                                     'tpr':lr_tpr4, \n                                     'auc':auc4}, ignore_index=True)\n\nfig = plt.figure(figsize=(8,6))\n\nplt.plot(result_table.loc[0]['fpr'], \n         result_table.loc[0]['tpr'], \n         label=\"RandomForestClassifier, AUC={:.3f}\".format( result_table.loc[0]['auc']))\n\nplt.plot(result_table.loc[1]['fpr'], \n         result_table.loc[1]['tpr'], \n         label=\"MLPClassifier, AUC={:.3f}\".format( result_table.loc[1]['auc']))\n\nplt.plot(result_table.loc[2]['fpr'], \n         result_table.loc[2]['tpr'], \n         label=\"SVM, AUC={:.3f}\".format( result_table.loc[2]['auc']))\n\nplt.plot(result_table.loc[3]['fpr'], \n         result_table.loc[3]['tpr'], \n         label=\"KNeighborsClassifier, AUC={:.3f}\".format( result_table.loc[3]['auc']))\n\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()\n    ","08eda367":"!apt-get remove swig \n!apt-get install swig3.0 build-essential -y\n!ln -s \/usr\/bin\/swig3.0 \/usr\/bin\/swig\n!apt-get install build-essential\n!pip install --upgrade setuptools\n!pip install auto-sklearn","ab43ef7f":"X = dfDrop.iloc[:, :-1].values\ny = dfDrop.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","67e086b6":"import autosklearn.classification\nimport sklearn.model_selection\nimport sklearn.datasets\nimport sklearn.metrics\nimport os  \nimport autosklearn.regression\n\n\nautoml = autosklearn.classification.AutoSklearnClassifier(\n    time_left_for_this_task=120,\n    per_run_time_limit=30,\n    tmp_folder='\/tmp\/autosklearn_cv_example_tmp6',\n    output_folder='\/tmp\/autosklearn_cv_example_out6',\n    delete_tmp_folder_after_terminate=False,\n    resampling_strategy='cv',\n    resampling_strategy_arguments={'folds': 5},\n)\n\n# fit() changes the data in place, but refit needs the original data. We\n# therefore copy the data. In practice, one should reload the data\nautoml.fit(X_train.copy(), y_train.copy(), dataset_name='Students')\n# During fit(), models are fit on individual cross-validation folds. To use\n# all available data, we call refit() which trains all models in the\n# final ensemble on the whole dataset.\nautoml.refit(X_train.copy(), y_train.copy())\n\nprint(automl.show_models())\n\npredictions = automl.predict(X_test)\nprint(\"Accuracy as per AutoML: \", sklearn.metrics.accuracy_score(y_test, predictions))","a9d0d895":"### Grid Search Results","c923d319":"## 1.4 Training Data Info","2f80e4a4":"## 1.3 Data Dictionary\n1. **gender** -- Male or Female\n1. **race\/ethnicity** -- group A,B, ...\n1. **Parental Level of education** --\tMaster, Bachelor, ... \n1. **lunch** -- standared or free\t\n1. **test preparation course**\t-- complete, none\n1. **math score** -- score of math course\n1. **reading score** -- score of reading course\t\n1. **writing score** -- score of writing course","b4a41d3f":"## 4.1 AUC curve over all models","248cbc8e":"### Compute learning curve for MLP","011e5525":"### 2.2.9 Drop unneccessary columns\nNow we can drop math score, reading score and writing score, as we will use the pass column instead.","8da3136c":"*The grid search result gives us result that very close to run #5. *","5fd81b98":"Cross validation is a measure of how well our model can generalize from what it learns. How well will it perform with data it has neven seen before. This is done by saving part of the data to later predict and measure the accuracy. The training data is split with differing testing folds to be used. Default in this case is k=5 folds.","e19cb59c":"### 2.2.4 Test preparation course vs Score","c5dc6233":"# ML Project 1\n## Introduction\nThe objective of this project is to train several classification models, and practice model tuning (bias\/varience) tradeoff. \n\n## Agenda\n1. Data Set Selection \n1. EDA\n1. Models\n1. AutoML\n\n## Team members\n1. Eden Zere\n1. Essey Abraham Tezare\n1. Hussien Mohamed Bayoumy Mohamed Elgabry\n1. Mario Arismendi Matos\n1. Moustafa Ahmed Galal Bahnasawy\n1. Youssef Samy Mounir\n","5190a77e":"# 1. Data Set Selection\n\nObjective is to understand the influence of various factors like economic, personal and social on the students performance\nInferences would be :\n* How to imporve the students performance in each test ?\n* What are the major factors influencing the test scores ?\n* Effectiveness of test preparation course?","f5200420":"### Grid Search Results","eef86122":"## 1.2 Reading the data","4a18f96c":"# 4. Best Model (Over All AUC) and AutoML","10162e2c":"> Overall AUC observed that MLP gives us the best results.","f5001780":"> While tweaking our model to produce meaningful predictions we found that using logistic activation function produced results that were interesting. The learning curve test learning score stays flat and doesn\u2019t improve, while the training score degrades. The cross validation curve shows both training and testing scores overlapping and oscillating between 0.54 and 0.66 for each configuration we tried. The confusion matrix show very poor results with just above 50% precision, 100% recall and 70% f1-score when predicting 0 and 0 for each of those scores when predicting 1. The ROC curve is almost a linear one with AUC=0.54. We decided to use a better configuration, but upon investigation of this model we found that all predictions were 0. The logistic activation is in every neuron to determine if activates or not. We that this could be caused by not having sufficient data and iterations for the model to build impactful bias. The sigmoid equation is meant to act as a threshold to activate a neuron or not, we think that threshold is not being reached currently. ","89ce2cbf":"### GridSearch Results","ad4b6572":"## 3. Models","d71cced4":"### This function is for drawing the learning curve.","efa7f65e":"Back to 9 splits and increasing min leaves","e96565f4":"The curve above shows the cross-validation scores for the default 5 runs in the cross-validation process for the MLP model.","24426efa":"## 2.2 Relation between features and Score","81f298ff":"## 1.6 Distict values","e2ddb2f5":"## 3.1 Random Forest ","1e8f4521":"### 2.2.7 Correclation Matrix between features","a2a3816b":"### 2.2.6 Overall Comparison by mapping","410e749c":"### 2.2.3 Parental level of education vs Score","e603f546":"## 2.1 Checking for Skewness","2c912bf4":">Math and writing scores have the highest correlation among exams with other variables (more than reading and total pass\/fail)\n\n>Other features are not correlated with each other","59123a82":"### Grid Search Results","13a145d9":"> In the KNN model the closer we got to the k = 17 (the final result and the grid search result) we found it more accurate and less variation in the learning curve\n","97e3f028":"**Increasing min samples split**","f13fb7db":"## 1.5 Data description","17674ca2":"> AutoML gives us the most accuracy we can get 0.6778","2f78e86d":"> Our data seems to be clean of missing values.","91397e03":"## 3.4 MLP","f61294ec":"> Group E is performing better in all exams","691b1dbc":"> we used kernel=linear, C=0.05, gamma=0.01 it showed us in the learning curve as the data size increased the training error\u00a0is increasing. In the validation curve we can see that\u00a0the learning error is not changing but the cross-validation error is decreasing as C increases.\u00a0And in AUC we\u00a0have\u00a073%,\u00a0let us\u00a0try\u00a0another\u00a0kernel with some hyper parameter.\u00a0Let us\u00a0try other hyper-parameter and see our result\u00a0","4bd22679":">  Remember that precision is the number of true positives divided by true positives summed with false positive. Recall is true positive divided by true positive summed with false negative.  F1-score is the rate of both these measurements.  \n\n>Looking at the ROC curve, with an AUC value of 0.73, we can see that it has a concave shape towards the True Positive Rate axis. This indicates a model that produces more accurate results by having a greater True Positive Rate of predictions. ","6d845cae":"> we used kernel=rbf, C=1, gamma=0.05 it showed us in the learning curve we can see\u00a0that increasing the data\u00a0will not\u00a0change our model.\u00a0In Validation curve as the complexity increase the training error increased and the\u00a0cross-validation error decreased slowly.\u00a0And we got 73% AUC which is okay,\u00a0let us\u00a0try\u00a0another\u00a0kernel with some hyper parameter.\u00a0Let us\u00a0try other hyper-parameter and see our result.\u00a0","152d905c":"# References: \n\n* http:\/\/roycekimmons.com\/tools\/generated_data\/exams\n* https:\/\/www.kaggle.com\/jeffd23\/scikit-learn-ml-from-start-to-finish\n* https:\/\/www.kaggle.com\/roshansharma\/student-performance-analysis\n* https:\/\/www.kaggle.com\/spscientist\/student-performance-in-exams\n* https:\/\/www.kaggle.com\/nitindatta\/eda-in-depth\n* http:\/\/scikit-learn.sourceforge.net\/stable\/auto_examples\/model_selection\/plot_validation_curve.html#example-model-selection-plot-validation-curve-py\n* https:\/\/chrisalbon.com\/machine_learning\/model_evaluation\/plot_the_validation_curve\/\n* https:\/\/datascience.stackexchange.com\/questions\/76304\/gridsearchcv-with-random-forest-classifier\n* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html#:~:text=A%20random%20forest%20classifier.%20A%20random%20forest%20is,to%20improve%20the%20predictive%20accuracy%20and%20control%20over-fitting.\n* https:\/\/scikit-learn.org\/stable\/modules\/multiclass.html#multioutput-regression\n* https:\/\/www.datacamp.com\/community\/tutorials\/random-forests-classifier-python\n* https:\/\/www.tutorialspoint.com\/machine_learning_with_python\/machine_learning_with_python_classification_algorithms_random_forest.htm\n* https:\/\/florianhartl.com\/thoughts-on-machine-learning-dealing-with-skewed-classes.html\n* https:\/\/www.kaggle.com\/ahmedengu\/lanl-master-s-features-autosklearn","d57a21fd":"## 1.1 Import libraries","cd8cd2e6":"## 4.2 AutoML","19b372e8":"> Students having standard lunch are always performing better","8df3fe6b":"> SVM\u00a0uses three hyper-parameters kernel,\u00a0Cost,\u00a0gamma.\u00a0From Kernel we used linear, sigmoid and\u00a0RBF, with some hyper-parameter. They\u00a0gave us different results based on the hyper-parameter. With grid search we put different values hyper-parameter and the best it gave us is with C=1 gamma=1\u00a0and\u00a0the best score is\u00a067%.\u00a0","babb66f0":"### This function is for printing the confusion matrix","84793d44":"# 2. EDA","d064b68c":"### Compute cross-validation curve","d22ed04b":"\n> Data needs to be arranged (with mapping), but as seems that as parental level of education increases the students performance also increases","3f9999bb":">Exams are very correlated with each other (people who are good are generally good among all exams)\n\n>We can try to combine all in one pass\/fail feature and see if we still maintain good relations with other variables","40a9ff06":"## 3.2 SVM ","c6ff6720":"## 3.3 KNN","8b4bd943":"> The data is nicely distributed (no high skewness noticed)","d1748611":"### 2.2.6 Mapping score to Pass or Fail\nTo be passed in a course, you have to get 60 or more. and to be marked as \"Passed\" you have to pass the 3 courses.","1799e556":"> Students who have taken the test preparation course perform better than students who have not (among all exams)","75dab2e7":">we used kernel=sigmoid, C=100, gamma=1 it showed us in the learning curve as the data size increased and the variance is decreasing, there is low variance,\u00a0the error started to decrease as data increased\u00a0and the model will not learn by adding more data. In the validation curve we can see that they are\u00a0overlapping,\u00a0and the error is decreasing. And we\u00a0have\u00a036% AUC which is bad.\u00a0Let us\u00a0try other hyper-parameter and see our result with grid search.\u00a0","0cd51bc8":"Learning curve is a measurement to check how well the model learns. This is measured by taking a reading of the accuracy of the algorithm as it trains and also while it is testing. This are plotting to see the convergence.","7218e85e":"### 2.2.1 Race\/ethnicity VS Score","4c950e30":"oneHotEncoder is used to encode categiorical columns into values that can be digested by the used algorithm implementation, in our case it.\n\nThe MLP configured above will iterate 3000 times, use hidden layers and 17, 13, 7, solver stochastic gradient descent. Our data was devided into a 80\/20 train\/set splits to train and evaluate your classifier.","831416d6":"### 2.2.2 Lunch vs Score","4e2d7697":"### 2.2.5 Relation between scores","98241d74":"Decreasing the min leaves","197df1fb":"The confusion matrix shows the frequency for True Positives, True Negatives, False Positives, and False Negative. Also a summary of the different properties can be presented here, along with the accuracy for predicted values.","c15a364c":"### This function is for drawing the validation curve.","29c43fd3":"**Using Entropy instead of default (gini)**"}}