{"cell_type":{"ac872067":"code","77ef6f29":"code","9a22be15":"code","7216d394":"code","4ff926c7":"code","ec80cd82":"code","cc05e478":"code","cc459bc7":"code","5f369cc6":"code","a91c6698":"code","f77e1c98":"code","0530fe11":"code","c49e2c18":"code","8738730b":"code","13edec10":"code","19d3abe4":"code","25f4acc9":"code","7f5d267b":"markdown","2f0cd49a":"markdown","f9fdb469":"markdown","cb6584cb":"markdown","8fb258ba":"markdown","70deaa20":"markdown","97b53ec6":"markdown","98d5abab":"markdown"},"source":{"ac872067":"%%capture\nimport os\nimport sys\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom keras.preprocessing.image import img_to_array\ntry:\n    from imutils import paths\nexcept ImportError:\n    !pip install imutils\n    from imutils import paths\n    \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# dataset download api command\n# kaggle datasets download -d paultimothymooney\/chest-xray-pneumonia","77ef6f29":"pneumonia_train = list(paths.list_images(\"..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/PNEUMONIA\/\"))\nnormal_train = list(paths.list_images(\"..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/NORMAL\/\"))\nprint(len(pneumonia_train))\nprint(len(normal_train))","9a22be15":"# define classes\ncolumns = 3\nclasses = {\n    \"Pneumonia\":[cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB) for img in random.sample(pneumonia_train, columns)], \n    \"Normal\": [cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB) for img in random.sample(normal_train, columns)]\n}\n\n# this method displays images for two classes above and below\ndef display(classes, columns, read_as_rgb=True, cmap=None):\n    for _class in classes:\n        #print(random_images)\n        fig, axes = plt.subplots(nrows=1, ncols=columns, figsize=(14, 10), squeeze=False)\n        fig.tight_layout()\n        for l in range(1):\n            for m, img in enumerate(classes[_class]):\n                axes[l][m].imshow(img, cmap=cmap)\n                axes[l][m].axis(\"off\")\n                axes[l][m].set_title(_class)\n    # done displaying\n    \n# display images\ndisplay(classes, columns)","7216d394":"def preprocess(image, input_mode=\"grayscale\", reshape=True):\n    # convert to uint8 watch out after new definition\n    img = image.astype(np.uint8)\n    # if the image is of bgr then equalize each channel and join back\n    if input_mode == \"bgr\":\n        B, G, R = cv2.split(img)\n        B = cv2.equalizeHist(B)\n        G = cv2.equalizeHist(G)\n        R = cv2.equalizeHist(R)\n        img = cv2.merge([B, G, R])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # if grayscale image\n    elif input_mode == \"grayscale\":\n        img = cv2.equalizeHist(img)\n        if reshape:\n            img = img.reshape(224, 224, 1)\n    img = img\/255.\n    return img","4ff926c7":"# get some random positive images\nsample_positive = random.sample(pneumonia_train, 3)\n\n# make a dictionary regular samples and preprocessed ones\nclasses = {\n    \"Original\": [cv2.imread(img, 0) for img in sample_positive],\n    \"Preprocessed\": [preprocess(cv2.imread(img, 0), input_mode=\"grayscale\", reshape=False) for img in sample_positive]\n} \n\n# display the images \ndisplay(classes, 3, cmap=\"gray\")","ec80cd82":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\n\nIM_WIDTH = 224\nIM_HEIGHT = 224\nBATCH_SIZE = 32\n\ntry:\n    from imutils import paths\nexcept ModuleNotFoundError:\n    !pip install imutils\n    from imutils import paths\n\n_generator = ImageDataGenerator(\n    width_shift_range=0.01,\n    height_shift_range=0.01,\n    zoom_range=0.01,\n    horizontal_flip=False,\n    rotation_range=2.99,\n)","cc05e478":"from keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nnp.random.seed(255)\nimport os\nos.environ[\"PYTHONHASHSEED\"] = str(255)\nimport random\nrandom.seed(255)\nimport tensorflow as tf\ntf.set_random_seed(255)\n\nfrom keras import backend as K\ntf_config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\nsess = tf.Session(graph=tf.get_default_graph(), config=tf_config)\nK.set_session(sess)\n\nCOLOR_MODE = \"grayscale\"\n\n# generator for train and validation\n_image_generator = ImageDataGenerator(\n    # rescale=1.\/255,\n    width_shift_range=0.01,\n    height_shift_range=0.01,\n    zoom_range=0.01,\n    horizontal_flip=False,\n    rotation_range=2.99,\n    preprocessing_function=preprocess\n)\n\n# train\n_train = _image_generator.flow_from_directory(\n    directory=\"..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/\",\n    target_size=(IM_WIDTH, IM_HEIGHT),\n    shuffle=True,\n    seed=255,\n    color_mode=COLOR_MODE,\n    class_mode=\"categorical\",\n    batch_size=BATCH_SIZE\n)\n\n# we don't need augumentation for validation and test, so we define a new generator\n_test_generator = ImageDataGenerator(\n    preprocessing_function=preprocess\n)\n# validation\n_valid = _test_generator.flow_from_directory(\n    directory=\"..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val\/\",\n    target_size=(IM_WIDTH, IM_HEIGHT),\n    shuffle=True,\n    seed=255,\n    color_mode=COLOR_MODE,\n    class_mode=\"categorical\",\n    batch_size=16\n)","cc459bc7":"from keras import callbacks\nfrom keras.layers import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler","5f369cc6":"class CustomNet(object):\n\n    def __init__(self, height, width, channels, classes, parameter_scaling):\n        self.height = height\n        self.width = width\n        self.channels = channels\n        self.output_classes = classes\n        self.scale = parameter_scaling\n    \n    def model(self):\n        input_shape = (self.height, self.width, self.channels)\n        chan_dim = -1\n        scale = self.scale\n        \n        # model architecture\n        _model = Sequential()\n    \n        # 224x224\n        # convolution 1\n        _model.add(Conv2D(scale, (3, 3), input_shape=input_shape))\n        _model.add(LeakyReLU(alpha=0.1))\n        # convolution 2\n        _model.add(Conv2D(2*scale, (3, 3)))\n        _model.add(LeakyReLU(alpha=0.1))\n        _model.add(MaxPooling2D(pool_size=(2, 2)))\n        _model.add(Dropout(0.1))\n        \n        # 112x112\n        # convolution 3\n        _model.add(Conv2D(3*scale, (3, 3)))\n        _model.add(LeakyReLU(alpha=0.1))\n        # convolution 4\n        _model.add(Conv2D(4*scale, (3, 3)))\n        _model.add(LeakyReLU(alpha=0.1))\n        _model.add(MaxPooling2D(pool_size=(2, 2)))\n        _model.add(Dropout(0.1))\n        \n        # 56x56\n        # convolution 5\n        _model.add(Conv2D(5*scale, (3, 3)))\n        _model.add(LeakyReLU(alpha=0.1))\n        # convolution 6\n        _model.add(Conv2D(3*scale, (3, 3)))\n        _model.add(LeakyReLU(alpha=0.1))\n        _model.add(MaxPooling2D(pool_size=(2, 2)))\n        _model.add(Dropout(0.1))\n        \n        # 28x28\n        # convolution 7\n        _model.add(Conv2D(6*scale, (3, 3)))\n        _model.add(LeakyReLU(alpha=0.1))\n        _model.add(MaxPooling2D(pool_size=(2, 2)))\n        _model.add(Dropout(0.1))\n        \n        # 14x14\n        # convolution 8\n        _model.add(Conv2D(7*scale, (3, 3)))\n        _model.add(LeakyReLU(alpha=0.1))\n        _model.add(MaxPooling2D(pool_size=(2, 2)))\n        _model.add(Dropout(0.1))\n\n        # flattening layer\n        _model.add(Flatten())\n\n        # first dense layer\n        _model.add(Dense(units=15*scale))\n        _model.add(LeakyReLU(alpha=0.1))\n        _model.add(Dropout(0.5))\n\n        # second dense layer\n        _model.add(Dense(units=15*scale))\n        _model.add(LeakyReLU(alpha=0.1))\n        _model.add(Dropout(0.5))\n\n        # third dense layer\n        _model.add(Dense(units=15*scale))\n        _model.add(LeakyReLU(alpha=0.1))\n        _model.add(Dropout(0.5))\n\n        # output layer\n        _model.add(Dense(self.output_classes, activation=\"softmax\"))\n\n        # print(model.summary()) \n        return _model","a91c6698":"LR = 1e-4\nSCALE = 32\nBATCH_SIZE = 32\nEPOCHS = 30\n\ndef lr_scheduler(epoch, lr):\n    if 20 < epoch <= 40:\n        return (1e-4)*0.25\n    elif 40 < epoch <= 50:\n        return 1e-5\n    else:\n        return lr\n    \n# define callbacks\n_callbacks = [\n    callbacks.TensorBoard(\n        log_dir=\"tensorboard\", write_graph=True, write_images=False    \n    ),\n    LearningRateScheduler(lr_scheduler)\n]\n\n# initiate model\nmodel = CustomNet(\n    height=IM_HEIGHT, width=IM_WIDTH, channels=1, \n    classes=2, parameter_scaling=SCALE\n).model()\n\n# compile\nmodel.compile(\n    loss=\"binary_crossentropy\",optimizer=Adam(lr=LR), metrics=[\"accuracy\"]\n)\nprint(_train.class_indices)","f77e1c98":"%%time\n# start training\nhistory = model.fit_generator(\n    generator=_train,\n    steps_per_epoch=_train.samples\/\/BATCH_SIZE,\n    validation_data=_valid,\n    validation_steps=_valid.samples,\n    callbacks=_callbacks,\n    class_weight={\n        0:3.5,\n        1:1.0\n    },\n    epochs=EPOCHS\n)","0530fe11":"# Let's define test data from the test generator that we used for validation also\n# validation\n_test = _test_generator.flow_from_directory(\n    directory=\"..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test\/\",\n    target_size=(IM_WIDTH, IM_HEIGHT),\n    shuffle=False,\n    seed=255,\n    color_mode=COLOR_MODE,\n    class_mode=\"categorical\",\n    batch_size=1\n)\nprint(_test.class_indices)","c49e2c18":"test_loss, test_acc = model.evaluate_generator(_test, steps=_test.samples, verbose=1)\n\nprint('val_loss:', test_loss)\nprint('val_cat_acc:', test_acc)","8738730b":"# PREDICT\npredictions = model.predict_generator(_test, steps=_test.samples, verbose=1)\nprint(predictions.shape)\ny_pred = np.argmax(predictions, axis=1)\ny_test = _test.classes","13edec10":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nreport = classification_report(y_test, y_pred, target_names=['NORMAL', 'PNEUMONIA'])\nprint(report)","19d3abe4":"# heatmap\nsns.heatmap(\n    confusion_matrix(y_test, y_pred), \n    annot=True, \n    fmt=\"d\", \n    cbar = False, \n    cmap = plt.cm.Blues\n)","25f4acc9":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\n# accuracy score\nprint(\"Accuracy score of the model: {:.2f}\".format(accuracy_score(y_test, y_pred)))\n\n# f1 score\nprint(\"F1 score of the model: {:.2f}\".format(f1_score(y_test, y_pred)))\n\n# precision\nprint(\"Precision score of the model: {:.2f}\".format(precision_score(y_test, y_pred)))\n\n# recall\nprint(\"Recall score of the model: {:.2f}\".format(recall_score(y_test, y_pred)))","7f5d267b":"Define the generators required for Training and Validation ","2f0cd49a":"### 2. Data Preprocessing and Augumentation\n\nIn this section we will generate and standardize data to address class imbalance problem that we saw above (images of one class are less than each other)","f9fdb469":"## References\n\n- https:\/\/towardsdatascience.com\/histogram-equalization-5d1013626e64\n- https:\/\/hypjudy.github.io\/2017\/03\/19\/dip-histogram-equalization\/","cb6584cb":"### 1. Explanatory Analysis\nLet's go into each class and randomly display some images to get an idea of how they look. But first lets make a function to do this for us.","8fb258ba":"### Image Preprocessing\n\n\nAs we can see from the above images, some have low contrast and for some chest cavity is little blurry. Let us do some preprocessing that will bring up the contrast in the images. The preferred approach for this is to histogram equalize the images in the Value channel of HSV color space. See the below images before and after histogram equalization to see the differnce in the information.\n\n                                        Before Histogram Equalization\n![alt text](notebook_images\/hist_eq_before.png)\n                                        \n\n\n\n                                        After Histogram Equalization\n![alt text](notebook_images\/hist_eq_after.png )\n                                 \nWe can clrealy see how histogram equalization has brought up the contrast in the grayscale image and is much clearer to see. So we will perform histogram equalization as one of the preprocessing steps to our current images.\n\nLet's make a fucntion for the preprocessing of images and display them together to see if we have any improvement after preprocessing.","70deaa20":"Lets start by analyzing the number of images in each class for the training set","97b53ec6":"### Model Definition and Training\n\nLet us construct a CNN and train with above data","98d5abab":"From now on we will be converting all the images to grayscale and will do all preprocessing on them as there is not much information in the R,G,B channels."}}