{"cell_type":{"a9e40e0a":"code","df421c07":"code","b799f2c4":"code","70bf76a2":"code","81746cca":"code","1922d2c5":"code","c15f6b90":"code","980a2045":"code","9883889a":"code","09747274":"code","d942ebe7":"code","c89716db":"code","6ef4b48f":"code","5ed23161":"code","3a79f963":"code","7b1086c6":"code","b6be29bf":"code","99696e27":"code","4e75b58d":"markdown","5c7b85b2":"markdown","d6d24093":"markdown","aba51567":"markdown","1401d8a8":"markdown","224b5afe":"markdown","8643cf89":"markdown","b3f99c3b":"markdown","d3592560":"markdown","82ada50b":"markdown","f93f954c":"markdown","f8c1c5eb":"markdown","9285910c":"markdown"},"source":{"a9e40e0a":"'''import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n'''","df421c07":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nfrom cv2 import imread, createCLAHE \nimport cv2\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\n","b799f2c4":"\nimage_path = os.path.join(\"..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\/\")\nmask_path = os.path.join(\"..\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/masks\/\")\nimages = os.listdir(image_path)\nmask = os.listdir(mask_path)\n\nmask = [fName.split(\".png\")[0] for fName in mask] # name of the mask or segment \nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask] # name of the image file ","70bf76a2":"check = [i for i in mask if \"mask\" in i]\nprint(\"Total mask that has modified name:\",len(check))","81746cca":"testing_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\ntraining_files = check","1922d2c5":"# define the function to get data \n\ndef getData(X_shape, flag = \"test\"):\n    im_array = []\n    mask_array = []\n    \n    if flag == \"test\":\n        for i in tqdm(testing_files): \n            im = cv2.resize(cv2.imread(os.path.join(image_path,i)),(X_shape,X_shape))[:,:,0]\n            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i)),(X_shape,X_shape))[:,:,0]\n            \n            im_array.append(im)\n            mask_array.append(mask)\n        \n        return im_array,mask_array\n    \n    if flag == \"train\":\n        for i in tqdm(training_files): \n            im = cv2.resize(cv2.imread(os.path.join(image_path,i.split(\"_mask\")[0]+\".png\")),(X_shape,X_shape))[:,:,0]\n            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i+\".png\")),(X_shape,X_shape))[:,:,0]\n\n            im_array.append(im)\n            mask_array.append(mask)\n\n        return im_array,mask_array","c15f6b90":"#perform sanity check\n\ndef plotMask(X,y):\n    sample = []\n    \n    for i in range(6):\n        left = X[i]\n        right = y[i]\n        combined = np.hstack((left,right))\n        sample.append(combined)\n        \n        \n    for i in range(0,6,3):\n\n        plt.figure(figsize=(25,10))\n        \n        plt.subplot(2,3,1+i)\n        plt.imshow(sample[i])\n        \n        plt.subplot(2,3,2+i)\n        plt.imshow(sample[i+1])\n        \n        \n        plt.subplot(2,3,3+i)\n        plt.imshow(sample[i+2])\n        \n        plt.show()","980a2045":"# Load training and testing data\ndim = 256*2\nX_train,y_train = getData(dim,flag=\"train\")\nX_test, y_test = getData(dim)","9883889a":"print(\"training set\")\nplotMask(X_train,y_train)\nprint(\"testing set\")\nplotMask(X_test,y_test)","09747274":"X_train = np.array(X_train).reshape(len(X_train),dim,dim,1)\ny_train = np.array(y_train).reshape(len(y_train),dim,dim,1)\nX_test = np.array(X_test).reshape(len(X_test),dim,dim,1)\ny_test = np.array(y_test).reshape(len(y_test),dim,dim,1)\nassert X_train.shape == y_train.shape\nassert X_test.shape == y_test.shape\nimages = np.concatenate((X_train,X_test),axis=0)\nmask  = np.concatenate((y_train,y_test),axis=0)","d942ebe7":"from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras import backend as keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","c89716db":"model = unet(input_size=(512,512,1))\nmodel.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss,\n                  metrics=[dice_coef, 'binary_accuracy'])\nmodel.summary()","6ef4b48f":"tf.keras.utils.plot_model(model, to_file='model.png')","5ed23161":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                                   patience=3, \n                                   verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","3a79f963":"from IPython.display import clear_output\nfrom keras.optimizers import Adam \nfrom sklearn.model_selection import train_test_split\n\nmodel.compile(optimizer=Adam(lr=2e-4), \n              loss=[dice_coef_loss], \n           metrics = [dice_coef, 'binary_accuracy'])\n\ntrain_vol, validation_vol, train_seg, validation_seg = train_test_split((images-127.0)\/127.0, \n                                                            (mask>127).astype(np.float32), \n                                                            test_size = 0.1,random_state = 2018)\n\ntrain_vol, test_vol, train_seg, test_seg = train_test_split(train_vol,train_seg, \n                                                            test_size = 0.1, \n                                                            random_state = 2018)\n\nloss_history = model.fit(x = train_vol,\n                       y = train_seg,\n                         batch_size = 16,\n                  epochs = 50,\n                  validation_data =(test_vol,test_seg) ,\n                  callbacks=callbacks_list)\n\nmodel.save('my_model.h5') \n#clear_output()","7b1086c6":"model.save('my_model.h5') ","b6be29bf":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.plot(loss_history.history['loss'], '-', label = 'Loss')\nax1.plot(loss_history.history['val_loss'], '-', label = 'Validation Loss')\nax1.legend()\n\nax2.plot(100*np.array(loss_history.history['binary_accuracy']), '-', \n         label = 'Accuracy')\nax2.plot(100*np.array(loss_history.history['val_binary_accuracy']), '-',\n         label = 'Validation Accuracy')\nax2.legend()","99696e27":"pred_candidates = np.random.randint(1,validation_vol.shape[0],10)\npreds = model.predict(validation_vol)\n\nplt.figure(figsize=(20,10))\n\nfor i in range(0,9,3):\n    plt.subplot(3,3,i+1)\n    \n    plt.imshow(np.squeeze(validation_vol[pred_candidates[i]]))\n    plt.xlabel(\"Base Image\")\n    \n    \n    plt.subplot(3,3,i+2)\n    plt.imshow(np.squeeze(validation_seg[pred_candidates[i]]))\n    plt.xlabel(\"Mask\")\n    \n    plt.subplot(3,3,i+3)\n    plt.imshow(np.squeeze(preds[pred_candidates[i]]))\n    plt.xlabel(\"Pridiction\")","4e75b58d":"## Callbacks, Early Stopping and Reduced LR\n","5c7b85b2":"## Plot the metric and evaluate ","d6d24093":"## Define  the network and callbacks\n\nI am going to use my favourite segmentation network - U-Nets. You can read about them [here](https:\/\/arxiv.org\/abs\/1505.04597).","aba51567":"## I have commented out these lines because there are lots of images","1401d8a8":"## Test the model","224b5afe":"### let us import all the libraries ","8643cf89":"# Perform Sanity Check\n\nIt is prudent to perform sanity check of the data correspondance. It become a routine check-up after a while but it is very crucial to check if we had made a mistake in loading the data.","b3f99c3b":"#### Train the model\n\nI intially used a 60-40 train-test spit and got a loss of -0.97. However, the better way to do it is 80-10-10 train-test-validation spit. Below I am roughly doing the later.","d3592560":"# Lung segmentation from Chest X-Ray dataset\n\n**About the data**:\n- The dataset is made up of images and segmentated mask from two diffrent sources.\n- There is a slight abnormality in naming convention of masks.\n- Some images don't have their corresponding masks.\n- Images from the Shenzhen dataset has apparently smaller lungs as compared to the Montgomery dataset.\n\n### the data set and code used in this worked is taken from [here](https:\/\/www.kaggle.com\/nikhilpandey360\/chest-xray-masks-and-labels) \n\n## Take a look at the dataset","82ada50b":"#### Compile and train the Unet Model","f93f954c":"## plot the model ","f8c1c5eb":"Both the sets looks correct. Let's combine them and further use them as a unified dataset.","9285910c":"### we have 704 masks but 800 images. Hence we are going to\n### make a 1-1 correspondance from mask to images, not the usual other way."}}