{"cell_type":{"e0ed9b5b":"code","e0aacf94":"code","47af8ca5":"code","05e1c5e8":"code","761e376b":"code","71245e89":"code","6a79694a":"code","f05dcf31":"code","f45b7123":"code","013b49b2":"code","013138fd":"code","b362aa62":"code","99bd30a2":"code","88f0bcee":"code","f3b7f45d":"markdown","7fe66820":"markdown","85e101d7":"markdown","4cb34081":"markdown","ba32a3e0":"markdown","63b091a7":"markdown","990d36ff":"markdown"},"source":{"e0ed9b5b":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","e0aacf94":"data = pd.read_csv('..\/input\/supermarket-sales\/supermarket_sales - Sheet1.csv')","47af8ca5":"data","05e1c5e8":"data.info()","761e376b":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop ID column\n    df = df.drop('Invoice ID', axis=1)\n    \n    # Split df into X and y\n    y = df['Rating']\n    X = df.drop('Rating', axis=1)\n    \n    return X, y","71245e89":"X, y = preprocess_inputs(data)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)","6a79694a":"X_train","f05dcf31":"y_train","f45b7123":"# Categorize our features\n\nbinary_features = [\n    'Customer type',\n    'Gender'\n]\n\ndate_features = [\n    'Date'\n]\n\ntime_features = [\n    'Time'\n]\n\nnominal_features = [\n    'Branch',\n    'City',\n    'Product line',\n    'Payment',\n]","013b49b2":"# Create custom transformers for date and time features\n\nclass DateEncoder:\n    \n    def fit(self, X, y):\n        return self\n    \n    def transform(self, X):\n        for column in X.columns:\n            X[column] = pd.to_datetime(X[column])\n            X[column + '_year'] = X[column].apply(lambda x: x.year)\n            X[column + '_month'] = X[column].apply(lambda x: x.month)\n            X[column + '_day'] = X[column].apply(lambda x: x.day)\n            X = X.drop(column, axis=1)\n        return X\n    \n\nclass TimeEncoder:\n    \n    def fit(self, X, y):\n        return self\n        \n    def transform(self, X):\n        for column in X.columns:\n            X[column] = pd.to_datetime(X[column])\n            X[column + '_hour'] = X[column].apply(lambda x: x.hour)\n            X[column + '_minute'] = X[column].apply(lambda x: x.minute)\n            X = X.drop(column, axis=1)\n        return X","013138fd":"# Construct transformer pipelines for each feature type\n\nbinary_transformer = Pipeline(steps=[\n    ('ordinal', OrdinalEncoder())\n])\n\ndate_transformer = Pipeline(steps=[\n    ('date', DateEncoder())\n])\n\ntime_transformer = Pipeline(steps=[\n    ('time', TimeEncoder())\n])\n\nnominal_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder())\n])","b362aa62":"# Combine transformers with ColumnTransformer\n\npreprocessor = ColumnTransformer(transformers=[\n    ('binary', binary_transformer, binary_features),\n    ('date', date_transformer, date_features),\n    ('time', time_transformer, time_features),\n    ('nomnal', nominal_transformer, nominal_features),\n])","99bd30a2":"# Define models\nmodels = {\n    \"                     Linear Regression\": LinearRegression(),\n    \" Linear Regression (L2 Regularization)\": Ridge(),\n    \" Linear Regression (L1 Regularization)\": Lasso(),\n    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n    \"                        Neural Network\": MLPRegressor(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n    \"                         Decision Tree\": DecisionTreeRegressor(),\n    \"                         Random Forest\": RandomForestRegressor(),\n    \"                     Gradient Boosting\": GradientBoostingRegressor(),\n    \"                               XGBoost\": XGBRegressor(),\n    \"                              LightGBM\": LGBMRegressor(),\n    \"                              CatBoost\": CatBoostRegressor(verbose=0)\n}\n\n# Make a scaler\nscaler = StandardScaler()\n\nfor name, model in models.items():\n    # Construct the final pipeline\n    pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('scaler', scaler),\n        ('regressor', model)\n    ])\n    # Fit the pipeline\n    pipeline.fit(X_train, y_train)\n    print(name + \" trained.\")","88f0bcee":"for name, model in models.items():\n    pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('scaler', scaler),\n        ('regressor', model)\n    ])\n    print(name + \" R^2 Score: {:.5f}\".format(pipeline.score(X_test, y_test)))","f3b7f45d":"# Training","7fe66820":"# Initial Preprocessing","85e101d7":"# Getting Started","4cb34081":"# Task for Today  \n\n***\n\n## Supermarket Customer Satisfaction Prediction  \n\nGiven *data about purchases made at three supermarkets*, let's try to predict the **satisfaction level** of a given customer.\n\nWe will use a variety of regression models to make our predictions.","ba32a3e0":"# Constructing Pipeline","63b091a7":"# Results","990d36ff":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/Q6ra1asM4sw"}}