{"cell_type":{"75907647":"code","4c04441c":"code","e908c4f9":"code","cdcb4903":"code","fdfb562e":"code","6f05f8f8":"code","e5dbe2f9":"code","ae88b9b8":"code","59eae33d":"code","8f1015c3":"code","0f0231ec":"code","2b3d9e92":"code","beda86b5":"code","bb8348b3":"code","239d4272":"code","eb7ab8b8":"code","0ac086fd":"code","8edfbbd7":"code","bb9d6475":"code","c490eba8":"code","a01f162e":"code","5eca7f19":"code","53967fa4":"code","553d354d":"code","4551fcaf":"code","05d93cc1":"code","26ce7306":"code","dde70287":"code","2c7245af":"code","c6b391ef":"code","7e055ef8":"code","e77dd90f":"code","5e765e3d":"code","5a6940e0":"code","8ee49ec0":"code","32423069":"code","7960741a":"code","21eef4db":"code","548011de":"code","cb3e17ff":"code","b0ec4fb9":"code","9b70c4a7":"code","39549353":"markdown","3cd55949":"markdown","f444f20a":"markdown","1bc55002":"markdown","7ebdbb25":"markdown","8a927677":"markdown","39a1f21c":"markdown","6d42d151":"markdown","3d4b2db5":"markdown","ddb24d23":"markdown","79572446":"markdown","000ff330":"markdown","5ce894c0":"markdown","5b8659b0":"markdown","90e328e8":"markdown","59e60267":"markdown","86c8d626":"markdown","5698b642":"markdown"},"source":{"75907647":"import os\nfrom os.path import join\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport keras\nfrom keras import layers, Input, models\nfrom keras.utils import to_categorical\nfrom keras.wrappers.scikit_learn import KerasClassifier \nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\ndatapath = join('data', 'wafer')\n\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4c04441c":"df=pd.read_pickle(\"..\/input\/LSWMD.pkl\")\ndf.info()","e908c4f9":"df.head()","cdcb4903":"df.tail()","fdfb562e":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\nuni_Index=np.unique(df.waferIndex, return_counts=True)\nplt.bar(uni_Index[0],uni_Index[1], color='gold', align='center', alpha=0.5)\nplt.title(\" wafer Index distribution\")\nplt.xlabel(\"index #\")\nplt.ylabel(\"frequency\")\nplt.xlim(0,26)\nplt.ylim(30000,34000)\nplt.show()","6f05f8f8":"df = df.drop(['waferIndex'], axis = 1)","e5dbe2f9":"def find_dim(x):\n    dim0=np.size(x,axis=0)\n    dim1=np.size(x,axis=1)\n    return dim0,dim1\ndf['waferMapDim']=df.waferMap.apply(find_dim)\ndf.sample(5)","ae88b9b8":"sub_df = df.loc[df['waferMapDim'] == (26, 26)]\nsub_wafer = sub_df['waferMap'].values\n\nsw = np.ones((1, 26, 26))\nlabel = list()\n\nfor i in range(len(sub_df)):\n    # skip null label\n    if len(sub_df.iloc[i,:]['failureType']) == 0:\n        continue\n    sw = np.concatenate((sw, sub_df.iloc[i,:]['waferMap'].reshape(1, 26, 26)))\n    label.append(sub_df.iloc[i,:]['failureType'][0][0])","59eae33d":"x = sw[1:]\ny = np.array(label).reshape((-1,1))","8f1015c3":"# check dimension\nprint('x shape : {}, y shape : {}'.format(x.shape, y.shape))","0f0231ec":"# plot 1st data\nplt.imshow(x[0])\nplt.show()\n\n# check faulty case\nprint('Faulty case : {} '.format(y[0]))","2b3d9e92":"#add channel\nx = x.reshape((-1, 26, 26, 1))","beda86b5":"faulty_case = np.unique(y)\nprint('Faulty case list : {}'.format(faulty_case))","bb8348b3":"for f in faulty_case :\n    print('{} : {}'.format(f, len(y[y==f])))","239d4272":"# One-hot-Encoding faulty categorical variable as channel\nnew_x = np.zeros((len(x), 26, 26, 3))\n\nfor w in range(len(x)):\n    for i in range(26):\n        for j in range(26):\n            new_x[w, i, j, int(x[w, i, j])] = 1","eb7ab8b8":"#check new x dimension\nnew_x.shape","0ac086fd":"# parameter\nepoch=15\nbatch_size=1024","8edfbbd7":"# Encoder\ninput_shape = (26, 26, 3)\ninput_tensor = Input(input_shape)\nencode = layers.Conv2D(64, (3,3), padding='same', activation='relu')(input_tensor)\n\nlatent_vector = layers.MaxPool2D()(encode)\n\n# Decoder\ndecode_layer_1 = layers.Conv2DTranspose(64, (3,3), padding='same', activation='relu')\ndecode_layer_2 = layers.UpSampling2D()\noutput_tensor = layers.Conv2DTranspose(3, (3,3), padding='same', activation='sigmoid')\n\n# connect decoder layers\ndecode = decode_layer_1(latent_vector)\ndecode = decode_layer_2(decode)\n\nae = models.Model(input_tensor, output_tensor(decode))\nae.compile(optimizer = 'Adam',\n              loss = 'mse',\n             )","bb9d6475":"ae.summary()","c490eba8":"# start train\nae.fit(new_x, new_x,\n       batch_size=batch_size,\n       epochs=epoch,\n       verbose=2)","a01f162e":"# Make encoder model with part of autoencoder model layers\nencoder = models.Model(input_tensor, latent_vector)","5eca7f19":"# Make decoder model with part of autoencoder model layers\ndecoder_input = Input((13, 13, 64))\ndecode = decode_layer_1(decoder_input)\ndecode = decode_layer_2(decode)\n\ndecoder = models.Model(decoder_input, output_tensor(decode))","53967fa4":"# Encode original faulty wafer\nencoded_x = encoder.predict(new_x)","553d354d":"# Add noise to encoded latent faulty wafers vector.\nnoised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 13, 13, 64))","4551fcaf":"# check original faulty wafer data\nplt.imshow(np.argmax(new_x[3], axis=2))","05d93cc1":"# check new noised faulty wafer data\nnoised_gen_x = np.argmax(decoder.predict(noised_encoded_x), axis=3)\nplt.imshow(noised_gen_x[3])","26ce7306":"# check reconstructed original faulty wafer data\ngen_x = np.argmax(ae.predict(new_x), axis=3)\nplt.imshow(gen_x[3])","dde70287":"# augment function define\ndef gen_data(wafer, label):\n    # Encode input wafer\n    encoded_x = encoder.predict(wafer)\n    \n    # dummy array for collecting noised wafer\n    gen_x = np.zeros((1, 26, 26, 3))\n    \n    # Make wafer until total # of wafer to 2000\n    for i in range((2000\/\/len(wafer)) + 1):\n        noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 13, 13, 64)) \n        noised_gen_x = decoder.predict(noised_encoded_x)\n        gen_x = np.concatenate((gen_x, noised_gen_x), axis=0)\n    # also make label vector with same length\n    gen_y = np.full((len(gen_x), 1), label)\n    \n    # return date without 1st dummy data.\n    return gen_x[1:], gen_y[1:]","2c7245af":"# Augmentation for all faulty case.\nfor f in faulty_case : \n    # skip none case\n    if f == 'none' : \n        continue\n    \n    gen_x, gen_y = gen_data(new_x[np.where(y==f)[0]], f)\n    new_x = np.concatenate((new_x, gen_x), axis=0)\n    y = np.concatenate((y, gen_y))","c6b391ef":"print('After Generate new_x shape : {}, new_y shape : {}'.format(new_x.shape, y.shape))","7e055ef8":"for f in faulty_case :\n    print('{} : {}'.format(f, len(y[y==f])))","e77dd90f":"# choice index without replace.\nnone_idx = np.where(y=='none')[0][np.random.choice(len(np.where(y=='none')[0]), size=11000, replace=False)]","5e765e3d":"# delete choiced index data.\nnew_x = np.delete(new_x, none_idx, axis=0)\nnew_y = np.delete(y, none_idx, axis=0)","5a6940e0":"print('After Delete \"none\" class new_x shape : {}, new_y shape : {}'.format(new_x.shape, new_y.shape))","8ee49ec0":"for f in faulty_case :\n    print('{} : {}'.format(f, len(new_y[new_y==f])))","32423069":"# make string label data to numerical data\nfor i, l in enumerate(faulty_case):\n    new_y[new_y==l] = i\n    \n# one-hot-encoding\nnew_y = to_categorical(new_y)","7960741a":"# split data train, test\nx_train, x_test, y_train, y_test = train_test_split(new_x, new_y,\n                                                    test_size=0.33,\n                                                    random_state=2019)","21eef4db":"print('Train x : {}, y : {}'.format(x_train.shape, y_train.shape))\nprint('Test x: {}, y : {}'.format(x_test.shape, y_test.shape))","548011de":"def create_model():\n    input_shape = (26, 26, 3)\n    input_tensor = Input(input_shape)\n\n    conv_1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(input_tensor)\n    conv_2 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(conv_1)\n    conv_3 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(conv_2)\n\n    flat = layers.Flatten()(conv_3)\n\n    dense_1 = layers.Dense(512, activation='relu')(flat)\n    dense_2 = layers.Dense(128, activation='relu')(dense_1)\n    output_tensor = layers.Dense(9, activation='softmax')(dense_2)\n\n    model = models.Model(input_tensor, output_tensor)\n    model.compile(optimizer='Adam',\n                 loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n\n    return model","cb3e17ff":"# Make keras model to sklearn classifier.\nmodel = KerasClassifier(build_fn=create_model, epochs=10, batch_size=1024, verbose=2) \n# 3-Fold Crossvalidation\nkfold = KFold(n_splits=3, shuffle=True, random_state=2019) \nresults = cross_val_score(model, x_train, y_train, cv=kfold)\n# Check 3-fold model's mean accuracy\nprint('Simple CNN Cross validation score : {:.4f}'.format(np.mean(results)))","b0ec4fb9":"history = model.fit(x_train, y_train,\n         validation_data=[x_test, y_test],\n         epochs=epoch,\n         batch_size=batch_size,\n         )","9b70c4a7":"# accuracy plot \nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","39549353":"## Get sub wafer with specific resolution.\nget wafers have (26, 26) resolution. rarrange wafer nd-array with fautly case label.<br>\nsome wafer has null label, skip it.","3cd55949":"* The dataset were collected from **47,543 lots** in real-world fab. However, **47,543 lots x 25 wafer\/lot =1,157,325 wafer maps ** is larger than **811,457 wafer maps**. \n\n* Let's see what happened. ","f444f20a":"### Read data","1bc55002":"* The figure shows that not all lots have perfect 25 wafer maps and it may caused by **sensor failure** or other unknown problems.\n\n* Fortunately, we do not need wafer index feature in our classification so we can just drop the variable. ","7ebdbb25":"## Introduction\nHi, It's my first dataset kernel. <br>\nThis kernel forked from WM-811k Wafermap[https:\/\/www.kaggle.com\/ashishpatel26\/wm-811k-wafermap].<br>\nThis dataset has various wafer resolution with class imbalanced. so I just consider specific subset wafer that has 26x26 resolution.<br> \nand solve imbalance problem using 2D convolutional autoencoder. then, classfy faulty case labels.","8a927677":"## Data augmentation\nWe made convolutional autoencoder model for data augmentation.<br>\nI just want data has 2000 samples for each case. Let's augment data for all faulty case.","39a1f21c":"Check summary","6d42d151":"* The dataset comprises **811,457 wafer maps**, along with additional information such as **wafer die size**, **lot name** and **wafer index**. \n\n* The training \/ test set were already split by domain experts, but in this kernel we ignore this info and we re-divided the dataset into training set and test set by hold-out mehtod which will be introduced in later section.","3d4b2db5":"## Simple 2D CNN Model\nThe data is ready. As wafer data is image. simply use cnn for classification.<br>\n### Make model\ndefine create model function, because we will validate model with sklearn kfold cross validation.","ddb24d23":"We will use 2D Convolutional Autoencoder, extend dimension for channel.","79572446":"## Convolutional Autoencoder for augmentation.\nAs solving class imbalanced problem, we need for data augmentation. <br>\nThe wafer data is image data. so we use convolutional autoencoder.","000ff330":"### Cross validate model\nUsing sklearn KFold Cross validation, we validate our simple cnn.","5ce894c0":"plot 1st data for check.","5b8659b0":"Our model seems quite a good model.","90e328e8":"Make faulty case list, and check how classes imbalanced.","59e60267":">Target distribution","86c8d626":"* We can not get much information from the wafer map column but we can see the die size for each instance is different. \n\n* We create a new variable **'waferMapDim'** for wafer map dim checking.\n","5698b642":"Wafer data's each pixels have a categorical variable that express 0 : not wafer, 1 : normal, 2 : faulty. <br>\nExtend extra dimension with one-hot-encoded categorical data as channel. <br>\n**that idea from Data Science & Business Analytics Lab, School of Industrial Management Engineering, College of Engineering, Korea University**[http:\/\/dsba.korea.ac.kr\/main]"}}