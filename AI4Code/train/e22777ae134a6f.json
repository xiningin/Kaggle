{"cell_type":{"0faf4780":"code","d249ec21":"code","6dc36356":"code","3efa6908":"code","fb0933bc":"markdown"},"source":{"0faf4780":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom kaggle.competitions import twosigmanews\n\nenv = twosigmanews.make_env()\n(marketdf, newsdf) = env.get_training_data()\n\nprint('Preparation:')\ndef prepare_data(marketdf, newsdf):\n    #feature engineering\n    marketdf['time'] = marketdf.time.dt.strftime(\"%Y%m%d\").astype(int)\n    marketdf['bartrend'] = marketdf['close'] \/ marketdf['open']\n    marketdf['average'] = (marketdf['close'] + marketdf['open'])\/2\n    marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']\n    \n    newsdf['time'] = newsdf.time.dt.strftime(\"%Y%m%d\").astype(int)\n    newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0])\n    newsdf['position'] = newsdf['firstMentionSentence'] \/ newsdf['sentenceCount']\n    newsdf['coverage'] = newsdf['sentimentWordCount'] \/ newsdf['wordCount']\n\n    # filter post 2010 data, huge crisis is not representative\n    marketdf = marketdf.loc[marketdf['time'] > 20100000]\n    \n    # columns that i tought are not necessary\n    droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence',\n                'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass',\n                'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount']\n    newsdf.drop(droplist, axis=1, inplace=True)\n    marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)\n    \n    # combine multiple news reports for same assets on same day\n    newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()\n    \n    # join news reports to market data, note many assets will have many days without news data\n    return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])\n\ncdf = prepare_data(marketdf, newsdf)    \ndel marketdf, newsdf  # save the precious memory\n","d249ec21":"\nprint('building training set...')\ntargetcols = ['returnsOpenNextMktres10']\ntraincols = [col for col in cdf.columns if col not in ['time', 'assetCode', 'universe'] + targetcols]\n\ndates = cdf['time'].unique()\ntrain = range(len(dates))[:int(0.85*len(dates))]\nval = range(len(dates))[int(0.85*len(dates)):]\n\n# we be classifyin\ncdf[targetcols[0]] = (cdf[targetcols[0]] > 0).astype(int)\n\n# train data\nXt = cdf[traincols].fillna(0).loc[cdf['time'].isin(dates[train])].values\nYt = cdf[targetcols].fillna(0).loc[cdf['time'].isin(dates[train])].values\n\n# validation data\nXv = cdf[traincols].fillna(0).loc[cdf['time'].isin(dates[val])].values\nYv = cdf[targetcols].fillna(0).loc[cdf['time'].isin(dates[val])].values\n\nprint(Xt.shape, Xv.shape)\n\n\n","6dc36356":"\n## LightGBM\n\nimport lightgbm as lgb\n\n# money\nparams = {\"objective\" : 'binary',\n          \"metric\" : \"binary_logloss\",\n          \"num_leaves\" : 130,\n          \"max_depth\": -1,\n          \"learning_rate\" : 0.01,\n          \"bagging_fraction\" : 0.75,  \n          \"feature_fraction\" : 0.9, \n          \"bagging_freq\" : 2,        \n          \"bagging_seed\" : 2018,\n         \n          \"verbosity\" : -1 }\n\n\nlgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0])\nlgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)\n\n\n\n","3efa6908":"\nprint(\"generating predictions...\")\npreddays = env.get_prediction_days()\nfor marketdf, newsdf, predtemplatedf in preddays:\n    cdf = prepare_data(marketdf, newsdf)\n    Xp = cdf[traincols].fillna(0).values\n    preds = lgbmodel.predict(Xp, num_iteration=lgbmodel.best_iteration) * 2 - 1\n    predsdf = pd.DataFrame({'ast':cdf['assetCode'],'conf':preds})\n    predtemplatedf['confidenceValue'][predtemplatedf['assetCode'].isin(predsdf.ast)] = predsdf['conf'].values\n    env.predict(predtemplatedf)\n\nenv.write_submission_file()","fb0933bc":"**Very easy LGBM 2sigma kernel, with market and news data**"}}