{"cell_type":{"feed949d":"code","86ea6c40":"code","b78166c5":"code","e15a9418":"code","21475d3c":"code","2c1917ff":"code","6b9a051a":"code","2cfa2583":"code","14309a71":"markdown","c0784373":"markdown","2de2193b":"markdown","a0871c1a":"markdown","7ee2bdb3":"markdown","007a4ce3":"markdown","d88b68d5":"markdown","2e93ad4d":"markdown","f11f2339":"markdown","502d6f23":"markdown","318c8a6c":"markdown","b6728726":"markdown","edfa9ffd":"markdown","4c7a1fb2":"markdown","1dcea00d":"markdown","85fc7476":"markdown","dc6b6cb7":"markdown"},"source":{"feed949d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86ea6c40":"import pandas as pd\ndf=pd.read_csv('..\/input\/salary-data-simple-linear-regression\/Salary_Data.csv')\n#view the first 5 rows of dataset\ndf.head()","b78166c5":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,6))\nplt.scatter(x= 'YearsExperience', y='Salary', data=df, marker='*',color='red')\nplt.title('YearsExperience vs Salary')\nplt.xlabel('Salary')\nplt.ylabel('YearsExperience')\nplt.show()","e15a9418":"#boxplot of salary \ndf.boxplot(column=['Salary'])","21475d3c":"#plot histogram of Salary\nimport seaborn as sns\nplt.figure(figsize=(10,6))\nsns.distplot(df['Salary'], \n             hist=True,\n             kde=True, \n             bins=30, color = 'darkblue', \n             )\nplt.show()","2c1917ff":"# import statsmodel library :\nimport statsmodels.api as sm\n# define response variable: \ny=df['Salary']\n#define explanatory variale:\nx= df['YearsExperience']\n# add constant to predictor variables\nx=sm.add_constant(x)\n#fit linear regression model\nmodel= sm.OLS(y,x).fit()\n#view model summary\nprint(model.summary())","6b9a051a":"# Residual vs. fitted values plot\nfig = plt.figure(figsize=(10, 6))\nsm.graphics.plot_regress_exog(model, 'YearsExperience',fig=fig)\nplt.show()","2cfa2583":"#Q-Q plot:\nres = model.resid\nfig = sm.qqplot(res, fit=True, line=\"45\")\nplt.show() ","14309a71":"From the plot we can see that the relationship does appear to be linear. As experience increases, salary tends to increase in a linear fashion.","c0784373":"Next, we can create a boxplot to visualize the distribution of salary and check for outliers. \n\nWe also can plot the histogram to understand the distribution ","2de2193b":"Our model is not homogeneous and is normally distributed. Thus, the output from our model is reliable!","a0871c1a":"# I. Load the data:","7ee2bdb3":"There are no outlier in our dataset ","007a4ce3":"# IV. INTERPRET THE RESULT","d88b68d5":"From the model summary we can see that the fitted regression equation is:\n\nSalary = 25790 + 9449.96*(YearsExperiance)\n\n\nEach additional Years Experiance is associated with an average increase in annual salary of $9449.96.\n\nThe intercept value of 25790 tells us the average expected anual salary for an employee may receive\n\n\n","2e93ad4d":"# THE END","f11f2339":"We can see in our Q-Q plot above that the data values tend to closely follow the 45-degree, which means the data is likely normally distributed.","502d6f23":"Simple linear regression is a technique that we can use to understand the relationship between a single explanatory variable and a single response variable.\n\nThis technique finds a line that best \u201cfits\u201d the data and takes on the following form:\n\n\u0177 = b0 + b1x\n\nwhere:\n\n\u0177: The estimated response value\n\nb0: The intercept of the regression line\n\nb1: The slope of the regression line\n\nThis tutorial provides a step-by-step explanation of how to perform simple linear regression in Machine Learning\n","318c8a6c":"# II. VISUALIZE THE DATA:\nTo gain an understanding of our datas, we should visualize the data first.\n\nWe want to understand the relationship between years experience and salary whether it's linear or not because that is an underlying assumption of simple regression.\n\nWe create a scatterplot to vire the relationsship between two avarible:\n\n","b6728726":"# III. PERFORM SIMPLE LINEAR REGRESSION\n\nOnce we\u2019ve confirmed that the relationship between our variables is linear and that there are no outliers present, we can proceed to fit a simple linear regression model using Year of experience as the explanatory variable and Salary as the response variable:","edfa9ffd":"One of the key assumptions of linear regression is that the residuals of a regression model are roughly normally distributed and are homoscedastic.\n\nTo verify that thE assumptions IS met, we can create the following residual plots:\n\n* Residual vs. fitted values plot: test homoscedastic\n\n* Q-Q plot: test the normal distribution","4c7a1fb2":"Reference: \n\nhttps:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.graphics.regressionplots.plot_regress_exog.html\n\nhttps:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.graphics.gofplots.qqplot.html\n\nhttps:\/\/www.statology.org\/linear-regression\/","1dcea00d":"# V. RESIDUAL PLOT","85fc7476":"The residuals appear to be randomly scattered around zero, therefore heteroscedasticity is not a problem with the explanatory variable.\n\n","dc6b6cb7":"How to interpret the rest of the model summary:\n\nP>|t|:  p-value for YearsExperiance  (0.000) is significantly less than .05, we can say that there is a statistically significant association between YearsExperiance and Salary.\n\nR-squared: In general, the larger the R-squared value of a regression model the better the explanatory variables are able to predict the value of the response variable. In this case, 95.7% of the variation in scores can be explained by hours studied.\n\nF-statistic & p-value: The F-statistic (622.5) and the corresponding p-value (1.14e-20) tell us the overall significance of the regression model \nSince the p-value in this example is less than .05, our model is statistically significant."}}