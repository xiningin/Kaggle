{"cell_type":{"24dd0bbc":"code","13b4d7b4":"code","c6d5d945":"code","1545a12e":"code","41a952ad":"code","63a57fc0":"code","4855032a":"code","a6f9fcbc":"code","62fc3bcb":"code","4851964d":"code","72ae3ca6":"code","534fb59d":"code","b3781bb7":"code","ae9d0b5a":"code","bac9c1dc":"code","9658a459":"code","8d50f1b9":"markdown","6ba935c0":"markdown","eadf3cc6":"markdown","fb77f668":"markdown"},"source":{"24dd0bbc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","13b4d7b4":"train=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')\ntest_id=test.ID\nprint(train.shape)\nprint(test.shape)\n#train.head()\ny=train.target\ny=np.log(y+1)\n#y.head()\ntrain=train.drop(['ID'],axis=1)\ntrain=train.drop(['target'],axis=1)\ntest=test.drop(['ID'],axis=1)","c6d5d945":"unique_df=train.nunique().reset_index()\nunique_df.columns=[\"column\",\"unique_count\"]\nconstant_df=unique_df[unique_df[\"unique_count\"]==1]\n#constant_df.shape\ntrain=train.drop(constant_df['column'],axis=1)\ntest=test.drop(constant_df['column'],axis=1)\nprint(train.shape)\nprint(test.shape)","1545a12e":"total=(train==0).sum().sort_values(ascending=True)\npercent=((train==0).sum()\/((train==0).count())*100).sort_values(ascending=False)\ntrain_data=pd.concat([total,percent],axis=1,keys=['total','percent'],sort=False)\n#train_data.head(50)\ncols_used=train_data[train_data.percent<79]\n#cols_used.shape\ncols_used=cols_used.index\n#cols_used.shape\nprint(cols_used)\ntrain=train[cols_used]\ntest=test[cols_used]\nprint(train.shape)\nprint(test.shape)","41a952ad":"from sklearn.decomposition import PCA\npca=PCA(n_components=2)\nb=pca.fit_transform(train)\npca.transform(test)\n#print(train.shape)\nb","63a57fc0":"def rmsle(x,y):\n    return np.sqrt(np.square(np.log(x+1)-np.log(y+1)).mean())","4855032a":"'''from sklearn.model_selection import GridSearchCV\nmodel=RandomForestRegressor()\nmax_features=[0.5,0.75,0.85,0.95]\nmin_samples_leaf=np.arange(1,15)\nmin_samples_split=np.arange(2,15)\nn_estimators=np.arange(1,11)*10\nparams={'max_features':max_features,'min_samples_leaf':min_samples_leaf,'min_samples_split':min_samples_split,'n_estimators':n_estimators}\ngrid_search=GridSearchCV(model,param_grid=params)\ngrid_search.fit(train,y)'''\nmodel=RandomForestRegressor(max_features=0.75,n_estimators=100,min_samples_leaf=11,min_samples_split=13)\nmodel.fit(train,y)\nprint(model.score(train,y))\ny_pred=model.predict(X_test)\nprint(rmsle(np.exp(y_pred)-1,np.exp(y_test)-1))","a6f9fcbc":"out_test=model.predict(test)\nout_test=np.exp(out_test)-1\nout_df=pd.DataFrame(out_test)\nout_df.columns = ['target']\nout_df.insert(0, 'ID', test_id)\n#out_df\nout_df.to_csv('santander_submission.csv',index=False)","62fc3bcb":"train=pd.read_csv('..\/input\/train.csv')\n","4851964d":"train=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')\nfeatures=['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', 'd6bb78916', 'b43a7cfd5', '58232a6fb']\ny_train=train.target\nX_train=train[features]","72ae3ca6":"print(y_train.head())","534fb59d":"print(X_train.head())","b3781bb7":"model=RandomForestRegressor(max_features=0.75,n_estimators=100,min_samples_leaf=11,min_samples_split=13)\nmodel.fit(X_train,y_train)","ae9d0b5a":"model.score(X_train,y_train)","bac9c1dc":"X_test=test.drop(['ID'],axis=1)\nX_test.head()","9658a459":"X_test=X_test[features]\ntest_id=test.ID\nout_test=model.predict(X_test)\nout_test=np.exp(out_test)-1\nout_df=pd.DataFrame(out_test)\nout_df.columns = ['target']\nout_df.insert(0, 'ID', test_id)\n#out_df\nout_df.to_csv('santander_submission2.csv',index=False)\n","8d50f1b9":"**Removing features which have more than 79 percent of zeroes.**","6ba935c0":"**Removing Columns which have only 1 unique value**","eadf3cc6":"**Grid Search CV on Random Forest Regressor**","fb77f668":"**Output CSV**"}}