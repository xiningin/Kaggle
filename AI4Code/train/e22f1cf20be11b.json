{"cell_type":{"9aebd7db":"code","4be78961":"code","7a2defb7":"code","f66f91dd":"code","e48c2413":"code","7edfcf46":"code","3185df4c":"code","29d83c25":"code","84052a49":"code","f3cc9124":"code","44768b4d":"code","a983afb5":"code","b1a0fd7e":"code","fab96d13":"code","9ce01a28":"code","28dfe040":"code","ad8f51d6":"code","7c4e75e0":"code","d7099317":"code","03607ddd":"code","b89172ce":"code","d59d5d36":"code","9ab15fee":"code","c7289bee":"code","c496a3d1":"code","99ed5ead":"code","f2ab73b4":"code","31cd0f66":"code","0c1fec77":"code","0cd80655":"code","93952139":"markdown","ce42f140":"markdown","b045e1b6":"markdown","e411bbf3":"markdown","ab096281":"markdown","4ba6b32d":"markdown","218829b7":"markdown","c306e9d5":"markdown","e12ba711":"markdown","48175ec8":"markdown","0cab34fb":"markdown","65739fc0":"markdown","13ed1e16":"markdown","60342ab1":"markdown","eab7498b":"markdown","590a3b0d":"markdown"},"source":{"9aebd7db":"# Importando bibliotecas necess\u00e1rias para as an\u00e1lises e predi\u00e7\u00f5es\n\n# Bibliotecas de modelagem de dados\nimport numpy as np\nimport pandas as pd\n\n# Visualiza\u00e7\u00e3o de dados\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Pr\u00e9-processamento dos dados\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\n# Modelos de Aprendizado de M\u00e1quina\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# M\u00f3dulo para avalia\u00e7\u00e3o dos modelos\nfrom sklearn import metrics\n\nsns.set_theme(style=\"whitegrid\")","4be78961":"# Definindo a fun\u00e7\u00e3o para avaliar os modelos\ndef model_evaluation(test, prediction):\n    print('Confusion Matrix\\n', metrics.confusion_matrix(test, prediction)) \n    print(f'\\nAccuracy\\n {np.round(metrics.accuracy_score(test, prediction), 2)}%') \n    print('\\nClass Balanced Accuracy\\n', metrics.balanced_accuracy_score(test, prediction)) \n    print('\\nPrecision\\n', metrics.precision_score(test, prediction)) \n    print('\\nRecall\\n', metrics.recall_score(test, prediction)) \n    print('\\nF1\\n', metrics.f1_score(test, prediction))\n    print('\\nClassification Report\\n', metrics.classification_report(test, prediction))","7a2defb7":"# Carrega o arquivo csv como DataFrame\ndf = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndf2 = df.copy()","f66f91dd":"m = lambda x: 'Sim' if x == 1 else 'N\u00e3o'\ndf2['sex'] = df2.sex.map({1: 'Masculino', 0: 'Feminino'})\ndf2['diabetes'] = df2['diabetes'].map(m)\ndf2['anaemia'] = df2['anaemia'].map(m)\ndf2['high_blood_pressure'] = df2['high_blood_pressure'].map(m)\ndf2['smoking'] = df2['smoking'].map(m)\ndf2['DEATH_EVENT'] = df2['DEATH_EVENT'].map(m)","e48c2413":"# Exibe as 5 primeiras linhas\ndf2.head()","7edfcf46":"# Exibe algumas informa\u00e7\u00f5es sobre as colunas do DataFrame\ndf2.info()","3185df4c":"# Exibe informa\u00e7\u00f5es estat\u00edsticas sobre o conjunto de dados\ndf.describe()","29d83c25":"plt.title('Contagem dos Eventos de Morte por Insufici\u00eancia Card\u00edaca')\nplt.xlabel('-')\nax = sns.countplot(data=df2, x='DEATH_EVENT')\nax.set(xlabel='Evento de Morte', ylabel='');","84052a49":"plt.title('Distribui\u00e7\u00e3o das Idades')\nax = sns.histplot(df.age)\nax.set(xlabel='Idade', ylabel='');","f3cc9124":"plt.title('Distribui\u00e7\u00e3o por G\u00eanero dos Eventos de Morte')\nax = sns.countplot(x='sex', data=df2 , hue='DEATH_EVENT')\nax.legend(title='Evento de Morte')\nax.set(xlabel='G\u00eanero', ylabel='');","44768b4d":"plt.title('Distribui\u00e7\u00e3o de Idade por G\u00eanero')\nax = sns.kdeplot(x='age',hue='sex',data=df2, fill=True)\nax.set(xlabel='Idade', ylabel='Densidade');","a983afb5":"fig = px.box(df2, y='age',x='sex',)\nfig.update_layout(title_text='Boxplot das Idades por G\u00eanero')\nfig.show()","b1a0fd7e":"sns.pairplot(df2.drop(['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'ejection_fraction'], axis=1), hue='DEATH_EVENT', corner=True);","fab96d13":"plt.figure(figsize=(8,7))\n# df2['smoking'] = df2['smoking'].map({1: 'Fumante', 0: 'N\u00e3o Fumante'})\nax=sns.countplot(\n    x='smoking',\n    data=df2 ,\n    hue='DEATH_EVENT'\n)\nax.legend(title='Evento de Morte')\nax.set(xlabel='Fumante', ylabel='');","9ce01a28":"# Exibe um mapa de calor de correla\u00e7\u00e3o entre vari\u00e1veis\n# \u00c9 utilizada a correla\u00e7\u00e3o de Spearman por conter vari\u00e1veis categ\u00f3ricas \nplt.figure(figsize=(15,8))\ncorr = df.corr('spearman')\nsns.heatmap(corr, annot=True, vmin=-1, vmax=1);","28dfe040":"# Salva o nome das colunas em uma lista\ncolumns = list(df.columns)\n\n# Labels\ny = df.iloc[:,-1]\n\n# Guarda os valores do dataset sem a coluna de r\u00f3tulos (vari\u00e1vel alvo)\nX = np.array(df.drop('DEATH_EVENT', axis=1))\n\nprint(columns)\nprint(X.shape)\nprint(y.shape)","ad8f51d6":"# Normaliza\u00e7\u00e3o dos dados\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","7c4e75e0":"rskf = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=42)\nfor train_index, test_index in rskf.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]","d7099317":"# Instanciando o modelo\nlr = LogisticRegression( penalty='l2', solver='liblinear', random_state=42)\n\n# Treinando o modelo com os dados de treino\nlr.fit(X_train, y_train)\n\n# Realizando as predi\u00e7\u00f5es com os dados de teste\ny_predict = lr.predict(X_test)","03607ddd":"# Avaliando o resultado do modelo de Regress\u00e3o Log\u00edstica\nmodel_evaluation(test=y_test, prediction=y_predict)","b89172ce":"matrix = metrics.confusion_matrix(y_test, y_predict)\nplt.title('Matriz de Confus\u00e3o da Regress\u00e3o Log\u00edstica')\nsns.heatmap(matrix, annot=True, cmap=\"YlGnBu\");","d59d5d36":"svc = SVC(\n    kernel='linear',\n    random_state=42)\nsvc.fit(X_train, y_train)\ny_predict = svc.predict(X_test)","9ab15fee":"# Avaliando o resultado do modelo do SVM\nmodel_evaluation(test=y_test, prediction=y_predict)","c7289bee":"matrix = metrics.confusion_matrix(y_test, y_predict)\nplt.title('Matriz de Confus\u00e3o do SVC')\nsns.heatmap(matrix, annot=True, cmap=\"YlGnBu\");","c496a3d1":"# Treinando o modelo do RF\nrf = RandomForestClassifier(\n    criterion = 'entropy',\n    bootstrap=True,\n    max_depth=5,\n    random_state=42)\nrf.fit(X_train, y_train)\n# Realizando as primeiras previs\u00f5es\ny_predict = rf.predict(X_test)","99ed5ead":"# Avaliando o resultado do modelo do RF\nmodel_evaluation(test=y_test, prediction=y_predict)","f2ab73b4":"matrix = metrics.confusion_matrix(y_test, y_predict)\nplt.title('Matriz de Confus\u00e3o do Random Forest')\nsns.heatmap(matrix, annot=True, cmap=\"YlGnBu\");","31cd0f66":"rfc = RandomForestClassifier(\n    n_estimators=100,\n    min_impurity_decrease=0.001,\n    min_samples_leaf=6,\n    max_depth=7,\n    random_state=42\n)\nabc = AdaBoostClassifier(\n    base_estimator=rfc,\n    random_state=42\n).fit(X_train, y_train)\n\ny_predict = abc.predict(X_test)","0c1fec77":"model_evaluation(y_test, y_predict)","0cd80655":"matrix = metrics.confusion_matrix(y_test, y_predict)\nplt.title('Matriz de Confus\u00e3o do AdaBoost')\nsns.heatmap(matrix, annot=True, cmap=\"YlGnBu\");","93952139":"* #### Exibe um mapa de calor de correla\u00e7\u00e3o entre vari\u00e1veis\n* #### \u00c9 utilizada a correla\u00e7\u00e3o de Spearman por conter vari\u00e1veis categ\u00f3ricas ","ce42f140":"# Explorando os dados\n-----","b045e1b6":"## **AdaBoost**\n### Classificador AdaBoost\n\n* Um classificador AdaBoost \u00e9 um metaestimador que come\u00e7a ajustando um classificador no conjunto de dados original e, em seguida, ajusta c\u00f3pias adicionais do classificador no mesmo conjunto de dados, mas onde os pesos das inst\u00e2ncias classificadas incorretamente s\u00e3o ajustados de modo que os classificadores subsequentes se concentrem mais em casos dif\u00edceis.\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.AdaBoostClassifier.html?highlight=adaboost#sklearn.ensemble.AdaBoostClassifier","e411bbf3":"* Exibe as 5 primeiras linhas do conjuto de dados","ab096281":"* Exibe algumas informa\u00e7\u00f5es sobre as colunas do DataFrame","4ba6b32d":"## **Random Forest Classifiers**\n### Classificador Floresta Aleat\u00f3ria\n\n* Uma floresta aleat\u00f3ria \u00e9 um metaestimador que ajusta v\u00e1rios classificadores de \u00e1rvore de decis\u00e3o em v\u00e1rias subamostras do conjunto de dados e usa a m\u00e9dia para melhorar a precis\u00e3o preditiva e o sobreajuste de controle.\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html?highlight=random#sklearn.ensemble.RandomForestClassifier","218829b7":"# **Pr\u00e9 Processamento**","c306e9d5":"## **SVC**\n###  Classificador M\u00e1quina de Vetores de Suporte\n\n* No algoritmo SVM, plotamos cada item de dados como um ponto no espa\u00e7o n-dimensional (onde n \u00e9 um n\u00famero de recursos que voc\u00ea possui) com o valor de cada recurso sendo o valor de uma coordenada espec\u00edfica. Em seguida, realizamos a classifica\u00e7\u00e3o encontrando o hiperplano que diferencia muito bem as duas classes.\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2017\/09\/understaing-support-vector-machine-example-code\/","e12ba711":"* Com o objetivo de avaliar e garantir a capacidade de generaliza\u00e7\u00e3o dos modelos e evitar o sobreajuste (overfiting), \u00e9 realizada uma Valida\u00e7\u00e3o Cruzada juntamente com uma Divis\u00e3o Estratificada, visto que os dados da vari\u00e1vel destino n\u00e3o s\u00e3o equilibradas. Ainda \u00e9 feita uma randomiza\u00e7\u00e3o diferente em cada repeti\u00e7\u00e3o. ","48175ec8":"### Visualizando os dados","0cab34fb":"### Exibe um resumo estat\u00edstico sobre o conjunto de dados","65739fc0":"# **Treinando e Avaliando os Modelos de Aprendizado de M\u00e1quina**\n---\n\n* Primeiro, \u00e9 realizada a instancia\u00e7\u00e3o do modelo com alguns hiperpar\u00e2metros ajustados\n\n* Depois, \u00e9 realizado o treinamento dos modelos com os dados de treino atrav\u00e9s da fun\u00e7\u00e3o \"fit\"\n\n* Ap\u00f3s o treinamento, s\u00e3o realizadas as predi\u00e7\u00f5es com os dados de teste com a fun\u00e7\u00e3o \"predict\"\n\n* Por fim, o modelo \u00e9 avaliado utilizando algumas das principais m\u00e9tricas de avalia\u00e7\u00e3o, como a _Matriz de Confus\u00e3o_ , _Acur\u00e1cia_ , _Acur\u00e1cia Balanceada por Classe_ , _Precis\u00e3o_ , etc.","13ed1e16":"# Explorando os dados","60342ab1":"* \u00c9 realizada uma normaliza\u00e7\u00e3o nos dados removendo a m\u00e9dia e escalonando para a vari\u00e2ncia da unidade","eab7498b":"# Introdu\u00e7\u00e3o\n## Previs\u00e3o de Insufici\u00eancia Card\u00edaca - 12 caracter\u00edsticas cl\u00ednicas para prever eventos de morte.\n----\n\n### Sobre o Conjunto de Dados\n\n*As doen\u00e7as cardiovasculares (DCVs) s\u00e3o a **causa n\u00famero 1** de morte em todo o mundo, levando cerca de **17,9 milh\u00f5es de vidas** a cada ano, o que representa 31% de todas as mortes em todo o mundo.*\n\nA insufici\u00eancia card\u00edaca \u00e9 um evento comum causado por DCVs e este \nconjunto de dados cont\u00e9m 12 recursos que podem ser usados \npara prever a mortalidade por insufici\u00eancia card\u00edaca.\n\n\nA maioria das doen\u00e7as cardiovasculares pode ser prevenida abordando \nos fatores de risco comportamentais, como uso de tabaco, \ndieta n\u00e3o saud\u00e1vel e obesidade, sedentarismo e uso nocivo de \u00e1lcool, \nusando estrat\u00e9gias para toda a popula\u00e7\u00e3o.\n\n\nPessoas com doen\u00e7as cardiovasculares ou que apresentam alto risco cardiovascular \n(devido \u00e0 presen\u00e7a de um ou mais fatores de risco, como hipertens\u00e3o, \ndiabetes, hiperlipidemia ou doen\u00e7a j\u00e1 estabelecida) precisam de detec\u00e7\u00e3o e \ngerenciamento precoces , em que um modelo de aprendizado de m\u00e1quina pode ser de grande ajuda.*\n\n### **Dicion\u00e1rio de dados**\n\n* ***age*** - Idade do Paciente\n* ***anaemia*** - Diminui\u00e7\u00e3o de gl\u00f3bulos vermelhos ou hemoglobina (booleano - 0 = N\u00e3o, 1 = Sim)\n* ***creatinine_phosphokinase*** - N\u00edvel da enzima CPK no sangue (mcg \/ L)\n* ***diabetes*** - Se o paciente tem diabetes (booleano - 0 = N\u00e3o, 1 = Sim)\n* ***ejection_fraction*** - Porcentagem de sangue saindo do cora\u00e7\u00e3o a cada contra\u00e7\u00e3o (porcentagem)\n* ***high_blood_pressure*** - Se o paciente tem hipertens\u00e3o (booleano - 0 = N\u00e3o, 1 = Sim)\n* ***platelets*** - Plaquetas no sangue (quiloplacas \/ mL)\n* ***serum_creatinine*** - N\u00edvel de creatinina s\u00e9rica no sangue (mg \/ dL)\n* ***serum_sodium*** - N\u00edvel de s\u00f3dio s\u00e9rico no sangue (mEq \/ L)\n* **smoking** - Se o paciente fuma ou n\u00e3o (booleano - 0 = N\u00e3o, 1 = Sim)\n* ***sex*** - Mulher ou homem (bin\u00e1rio - 1 = Masculino, 0 = Feminino)\n* ***time*** - Per\u00edodo de acompanhamento (dias)\n* ***DEATH_EVENT*** - Se o paciente faleceu durante o per\u00edodo de acompanhamento (booleano - 0 = N\u00e3o, 1 = Sim)","590a3b0d":"## **Logistic Regression**\n\n### Classificador de Regress\u00e3o Log\u00edstica\nA regress\u00e3o log\u00edstica bin\u00e1ria \u00e9 uma forma de regress\u00e3o usada quando o dependente \u00e9 uma dicotomia e os independentes s\u00e3o de qualquer tipo.\n\nhttps:\/\/faculty.chass.ncsu.edu\/garson\/PA765\/logistic.htm"}}