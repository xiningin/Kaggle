{"cell_type":{"77a82dfb":"code","bfba5e47":"code","f4c157ff":"code","85703de3":"code","ee757e68":"code","46a56f1f":"code","f30684db":"code","069fe3c7":"code","d8a5c1a4":"code","553b69ad":"code","e88d04b7":"code","ad4039df":"code","4e14876b":"code","f0ead280":"code","6d3e41ac":"code","b6c159f9":"code","425e4894":"code","0d6d69bb":"code","2f7163d1":"code","bd276895":"markdown","ef27855c":"markdown","443ea69d":"markdown","1be3e0fd":"markdown","b5ff4c7c":"markdown"},"source":{"77a82dfb":"!pip install feature_engine","bfba5e47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4c157ff":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\npd.options.display.max_columns = None\n\nimport seaborn as sns\nimport feature_engine.transformation as vt #Please install #!pip install feature_engine\n","85703de3":"df_train =  pd.read_csv('\/kaggle\/input\/hackerearth-machine-learning-exhibit-art\/dataset\/train.csv')","ee757e68":"float_var_list = ['Artist Reputation',\n 'Height',\n 'Width',\n 'Weight',\n 'Price Of Sculpture',\n 'Base Shipping Price']\n\nArtist_Reputation_mean = df_train['Artist Reputation'].mean()\nHeight_mean = df_train['Height'].mean()\nWidth_mean = df_train['Width'].mean()\nWeight_median = df_train['Weight'].mean()\n\ndf_train_copy = df_train.copy(deep=True)\ndf_train_copy['State_code'] = df_train_copy['Customer Location'].str.split(',', expand=True)[1].str.slice(0, 3)\n\n\ndef create_dummies_columns(df, column_name, prefix_str):\n    temp_df  =  pd.get_dummies(df[column_name], prefix=prefix_str, drop_first=True)\n    df.drop([column_name],  axis = 1, inplace=True)\n    df = pd.concat([df, temp_df], axis = 1)\n    return df\n\ndef prepare_data(df):\n    df.drop(['Customer Id', 'Artist Name'], axis = 1, inplace=True)\n    df['Artist Reputation_NA'] = np.where(df['Artist Reputation'].isnull(), 1, 0)\n    df['Artist Reputation'].fillna(Artist_Reputation_mean, inplace = True)\n    \n    df['Transport_NA'] = np.where(df['Transport'].isnull(), 1, 0)\n    df['Transport'].fillna(df['Transport'].mode()[0], inplace = True)\n    \n    df['Remote_Location_NA'] = np.where(df['Remote Location'].isnull(), 1, 0)\n    df['Remote Location'].fillna(df['Remote Location'].mode()[0], inplace = True)\n    \n    df['Height_NA'] = np.where(df['Height'].isnull(), 1, 0)\n    df['Height'].fillna(Height_mean, inplace = True)\n    df['Height'] = np.exp(df['Height'])\n    \n    \n    df['Width_NA'] = np.where(df['Width'].isnull(), 1, 0)\n    df['Width'].fillna(Width_mean, inplace = True)\n    df['Width'] = np.log(df['Width'])\n    \n    df['Weight_NA'] = np.where(df['Weight'].isnull(),1,0)\n    df['Weight'].fillna(Weight_median, inplace = True)\n    df['Weight'] = np.log(df['Weight'])\n    \n    df['Material_NA'] = np.where(df['Material'].isnull(), 1, 0)\n    df['Material'].fillna('NA', inplace = True)\n    #Below code is to fill Random in Material\n    #random_sample_Material = df_train_copy['Material'].dropna().sample(df['Material'].isnull().sum(),\n    #                                                                   random_state=\n    #                                                                   np.log(np.abs(df_train_copy['Cost'])).astype(int))\n    \n    #random_sample_Material.index = df[df['Material'].isnull()].index\n    #df.loc[df['Material'].isnull(), 'Material'] = random_sample_Material\n    \n    df['Price Of Sculpture'] = np.log(df['Price Of Sculpture'])\n\n    df['Delivery Date'] = pd.to_datetime(df['Delivery Date'], format='%m\/%d\/%y')\n    df['Scheduled Date'] = pd.to_datetime(df['Scheduled Date'], format='%m\/%d\/%y')\n    df['del_date_sch_date_diff'] = (df['Delivery Date'] - df['Scheduled Date']).dt.days\n    df['del_date_sch_date_diff'] = np.abs(df['del_date_sch_date_diff'])\n    \n    df.drop(['Delivery Date', 'Scheduled Date'], axis = 1, inplace=True)\n    \n    df['city'] = df['Customer Location'].str.split(',', expand=True)[0]\n    df['State_code'] = df['Customer Location'].str.split(',', expand=True)[1].str.slice(0, 3)\n    df['pin'] = df['Customer Location'].str.split(',', expand=True)[1].str.split(' ', expand=True)[2]\n    \n    city_others = df[df['State_code'].isna()]['Customer Location'].str.split(' ', expand=True)[0]\n    city_others.index = df[df['State_code'].isnull()].index\n    \n    State_code_others = df[df['State_code'].isna()]['Customer Location'].str.split(' ', expand=True)[1]\n    State_code_others.index = df[df['State_code'].isnull()].index\n    \n    pin_others = df[df['pin'].isna()]['Customer Location'].str.split(' ', expand=True)[2]\n    pin_others.index = df[df['pin'].isnull()].index\n    \n    \n    df.loc[df['State_code'].isnull(), 'city'] = city_others\n    df.loc[df['State_code'].isnull(), 'State_code'] = State_code_others\n    df.loc[df['pin'].isnull(), 'pin'] = pin_others\n    \n    #df['pin'] = df['pin'].astype(int)\n    \n    df.drop(['Customer Location'], axis = 1, inplace=True)\n    df.drop(['city', 'pin'], axis = 1, inplace=True)    \n    return df\n\n# function to create histogram, Q-Q plot and\n# boxplot\n\nimport scipy.stats as stats\n\n\ndef diagnostic_plots(df, variable):\n    # function takes a dataframe (df) and\n    # the variable of interest as arguments\n\n    # define figure size\n    plt.figure(figsize=(16, 4))\n\n    # histogram\n    plt.subplot(1, 3, 1)\n    sns.histplot(df[variable], bins=30)\n    plt.title('Histogram')\n\n    # Q-Q plot\n    plt.subplot(1, 3, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.ylabel('RM quantiles')\n\n    # boxplot\n    plt.subplot(1, 3, 3)\n    sns.boxplot(y=df[variable])\n    plt.title('Boxplot')\n\n    plt.show()","46a56f1f":"df_train.head(3)","f30684db":"for x in float_var_list:\n   diagnostic_plots(df_train, x)","069fe3c7":"df_train = prepare_data(df_train)","d8a5c1a4":"df_train.head(3)","553b69ad":"for x in float_var_list:\n    diagnostic_plots(df_train, x)","e88d04b7":"df_train_X = df_train.drop(['Cost'], axis = 1)\ndf_train_y = np.log(np.abs(df_train['Cost']))\n\nfrom feature_engine.encoding import OrdinalEncoder\nordinal_enc = OrdinalEncoder(\n    # NOTE that we indicate ordered in the encoding_method, otherwise it assings numbers arbitrarily\n    #encoding_method='ordered',\n    encoding_method='arbitrary',\n    variables=['Material', 'State_code'])\n#ordinal_enc.fit(df_train_X, df_train_y)\nordinal_enc.fit(df_train_X)\ndf_train_X = ordinal_enc.transform(df_train_X)\n\nfrom feature_engine.encoding import OneHotEncoder\nohe_enc = OneHotEncoder(top_categories=None) \nohe_enc.fit(df_train_X)\ndf_train_X = ohe_enc.transform(df_train_X)\n","ad4039df":"df_train_X.head(3)","4e14876b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_train_X, df_train_y, test_size=0.2)\n","f0ead280":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor \n\nfrom sklearn.ensemble import GradientBoostingRegressor\nreg = GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, max_depth=8, random_state=42\n                                ,loss='ls', min_samples_split=5\n                               )\n# train the model\nreg.fit(X_train, y_train)\n\nprint(reg.score(X_train, y_train))\nprint(reg.score(X_test, y_test))","6d3e41ac":"param_grid = [\n{'n_estimators':  [x for x in range(50,500, 20)], \n 'learning_rate' : [0.1, 0.2, 0.3, 0.4, 0.5],\n 'max_depth': [x for x in range(5,20)], \n 'min_samples_split': [x for x in range(2,10)]}\n]","b6c159f9":"reg.fit(df_train_X, df_train_y)","425e4894":"df_test =  pd.read_csv('\/kaggle\/input\/hackerearth-machine-learning-exhibit-art\/dataset\/test.csv')\nsample_submission = df_test[['Customer Id']]\ndf_test = prepare_data(df_test)\n","0d6d69bb":"df_test = ordinal_enc.transform(df_test)\ndf_test = ohe_enc.transform(df_test)\nprint(df_train_X.shape)\nprint(df_test.shape)\nX_test = df_test\ny_predicted = reg.predict(X_test)","2f7163d1":"sample_submission['Cost'] = np.exp(y_predicted)\nsample_submission.to_csv('sample_submission.csv', index=False)","bd276895":"# Function Definitions","ef27855c":"# HackerEarth Machine Learning Challenge: Exhibit A(rt) ","443ea69d":"# Float columns Graph","1be3e0fd":"# Float columns graph after preparing data","b5ff4c7c":"**Points:**\n* Trying to learn Machine Learning by participating in the competitions.\n* Achieved accuracy of 94%, and trying to further improve it.\n* Beginner in Machine Leraning, so may be there will be naive mistake, **feedbacks are most welcome**.\n* Used feature_engine library. Install it on kaggle using `!pip install feature_engine`"}}