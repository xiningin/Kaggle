{"cell_type":{"03788a8e":"code","bec40380":"code","bb75ea11":"code","71253046":"code","9a0dee61":"code","bc909ab5":"code","108c9674":"code","653a7faa":"code","364faa1a":"code","4dc337f7":"code","e7a8a783":"code","ac6c64a6":"code","1d910990":"code","a500ea71":"code","9a973f2b":"code","b08a79db":"code","19f5bd47":"code","d854cc76":"code","f24c6112":"code","1e6536a3":"code","05af5860":"code","e4152abb":"code","65a1a2ed":"code","03f2599a":"code","7b41c9e4":"code","1f548556":"code","e6eca562":"code","4c6b3238":"code","8fab4055":"code","f171467e":"code","5a70000a":"code","aa695fff":"code","1bb5b6fa":"code","449b7dfe":"code","97bc9468":"code","9267416e":"code","898368e6":"code","ff3711e1":"code","9cf181c3":"code","6667e12e":"code","27b9afa5":"code","b2219755":"code","530f82cd":"code","82d99ab5":"markdown","bd3be9b9":"markdown","71c4b6c0":"markdown","a94ee652":"markdown","93cd2547":"markdown","f763951e":"markdown","36c843e5":"markdown","677e2b06":"markdown","4e783aab":"markdown","2b894f05":"markdown","86ecf878":"markdown","9c227d90":"markdown","08d58ebd":"markdown","292a3f7c":"markdown","9ba168ba":"markdown"},"source":{"03788a8e":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\npd.set_option('display.max_columns', None)","bec40380":"y_test = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nX_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","bb75ea11":"train.head()","71253046":"train.info()","9a0dee61":"train[train.duplicated()]","bc909ab5":"train.duplicated().any()","108c9674":"round(train.isnull().sum()\/train.shape[0]*100, 2)","653a7faa":"#drop Cabin\ntrain.drop(columns=['Cabin'], inplace=True)","364faa1a":"sns.distplot(train['Age'])","4dc337f7":"print('avg :', train['Age'].mean())\nprint('Median :', train['Age'].median())","e7a8a783":"#replace null data with mean (columns Age)\nmean_age = train['Age'].mean()\ntrain['Age'] = train['Age'].fillna(mean_age)","ac6c64a6":"#replace embarked with Modus\ntrain['Embarked'].value_counts().plot.bar()","1d910990":"modus_emb = train['Embarked'].mode()[0]\nprint(modus_emb)","a500ea71":"train['Embarked'] = train['Embarked'].fillna(modus_emb)","9a973f2b":"train.isnull().sum()","b08a79db":"train.isnull().any()","19f5bd47":"#drop Cabin\nX_test.drop(columns=['Cabin'], inplace=True)","d854cc76":"#replace null data with mean (columns Age)\nmean_age = X_test['Age'].mean()\nX_test['Age'] = X_test['Age'].fillna(mean_age)","f24c6112":"sns.boxplot(y=train['Age'])","1e6536a3":"sns.boxplot(y=train['Fare'])","05af5860":"train[train['Fare']>500]","e4152abb":"train['Survived'].value_counts().plot.bar()","65a1a2ed":"sns.countplot(train['Survived'], hue=train['Pclass'])","03f2599a":"sns.countplot(train['Survived'], hue=train['Sex'])","7b41c9e4":"train.head()","1f548556":"#drop columns PassenggeID, Name and Ticket\ntrain.drop(columns=['PassengerId', 'Name', 'Ticket'], inplace=True)\nX_test.drop(columns=['PassengerId', 'Name', 'Ticket'], inplace=True)\ny_test.drop(columns=['PassengerId'], inplace=True)","e6eca562":"train.head()","4c6b3238":"from sklearn.preprocessing import LabelEncoder","8fab4055":"#encode kolom Sex\nlE = LabelEncoder()\ntrain['Sex'] = lE.fit_transform(train['Sex'])","f171467e":"#encode embarked\ntrain = pd.get_dummies(train, columns=['Embarked'], prefix=['Emb'], drop_first=True)","5a70000a":"y_train = train['Survived']\nX_train = train.drop(columns=['Survived'])","aa695fff":"X_train","1bb5b6fa":"y_train","449b7dfe":"#encode kolom Sex\nlE = LabelEncoder()\nX_test['Sex'] = lE.fit_transform(X_test['Sex'])","97bc9468":"#encode embarked\nX_test = pd.get_dummies(X_test, columns=['Embarked'], prefix=['Emb'], drop_first=True)","9267416e":"import xgboost as xgb\na=xgb.XGBClassifier()\nparam_grid=  { \n    \"max_depth\":range(5,10),\n    \"n_estimator\":(100,500,1000),\n    \"booster\":[\"gbtree\", \"gblinear\",\"dart\"],\n    \"learning_rate\":(0.1,0.5,1)\n}\nfrom sklearn.model_selection import GridSearchCV\nCV_tree = GridSearchCV(estimator=a, param_grid=param_grid,\n                       n_jobs=-1, cv= 2, verbose=1, \n                       return_train_score=True)\nCV_tree.fit(X_train, y_train)","898368e6":"# best model\nCV_tree.best_params_","ff3711e1":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score","9cf181c3":"pred = CV_tree.predict(X_test)","6667e12e":"CF = confusion_matrix(y_test, pred)\nsns.heatmap(CF, annot=True, fmt=\"d\")","27b9afa5":"target_names = ['Dead','Survival']\nprint(classification_report(y_test,pred, target_names=target_names))","b2219755":"print(\"Accuration for XGboost on test data: \", accuracy_score(y_test, pred))\nprint(\"Precision for XGboost on test data: \", precision_score(y_test, pred))\nprint(\"Recall for XGboost on test data: \", recall_score(y_test, pred))\nprint(\"ROC for XGboost on test data: \", roc_auc_score(y_test, pred))","530f82cd":"# Generate ROC Curve value, fpr, tpr, thresholds\nfpr, tpr, thresholds = roc_curve(y_test, pred)\n# Plot ROC curve\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')","82d99ab5":"**Check for duplicates**","bd3be9b9":"#### Initial Check","71c4b6c0":"Some Visualization from Feature","a94ee652":"Check for Outliers","93cd2547":"### Data Cleansing","f763951e":"**Check for missing values**","36c843e5":"### Data Preparation","677e2b06":"# The Final Result\n\n## the results from the XGBoost model show that the model can predict with an accuracy value of 83.49%, then the Precision value is 81.67%, while the recall value is 70.39% and the ROC value is 80.68%. These results show that the model is quite good at predicting passengers who survived the titanic tragedy","4e783aab":"### Load Dataset Titanic","2b894f05":"### Encode Data","86ecf878":"# Model evaluation","9c227d90":"# Machine Learning Classification - Use Case : Titanic\n\n##### Data taken from [titanic](https:\/\/www.kaggle.com\/c\/titanic)\n\n#### In this problem or use case, the goal is to predict which passengers are safe and which are not safe using passenger data","08d58ebd":"**For binary categorical data, we will use a Label Encoder, while for more than 2 category columns, we will use one hot encoding**","292a3f7c":"### Check missing value for data test","9ba168ba":"## Modeling using XGBoost Hyperparameter Tunning"}}