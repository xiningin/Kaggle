{"cell_type":{"cbe365d4":"code","654e6b94":"code","4cc057a4":"code","e9d483a9":"code","f31a4a02":"code","67e6475f":"code","6422fba4":"code","91a7fe2b":"code","9ddaa654":"code","20f55958":"code","a857dc07":"code","f1b529cb":"code","03c8a884":"code","8ca7f495":"code","19d55373":"code","31486e70":"code","ffe4bfdc":"code","10465ca4":"code","b4882a07":"code","e49e3427":"code","62e64f53":"code","858ef556":"code","61f3ee7b":"code","c4ac418a":"code","f6864b42":"code","b9a636b1":"code","fde14c31":"code","c8deedab":"code","34fb90c4":"code","968735a9":"code","48459feb":"code","ed7248ee":"code","177d8499":"code","c1d56f40":"code","767520b8":"code","db666251":"code","535c4283":"code","06bb7a6d":"code","59f476d5":"code","cffe788d":"code","924d5f2f":"code","58faed6e":"code","f1001be2":"code","2ad686c1":"code","02039aa0":"markdown","454d7a0c":"markdown","22e7f5c7":"markdown","a7458570":"markdown","7af119f9":"markdown","28aadd80":"markdown","81ef5dc1":"markdown","0d62688f":"markdown","32612b5f":"markdown","26eb2ff6":"markdown","1997c0b8":"markdown","67cb77d1":"markdown","2237de5b":"markdown","73df610a":"markdown","2d947602":"markdown","971eaffe":"markdown","a448db05":"markdown","5226e788":"markdown","73ca8345":"markdown","d6162a26":"markdown","9902b164":"markdown","8ba9d259":"markdown","59578f59":"markdown","9460c87b":"markdown","5e528f0e":"markdown","02d9f753":"markdown","ca18ef37":"markdown","1dafa760":"markdown","ef3f7fa0":"markdown"},"source":{"cbe365d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","654e6b94":"#import libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","4cc057a4":"#loading the dataset\n\nfrom sklearn.datasets import load_boston\ndf = load_boston()","e9d483a9":"#displaying the dataset\n\ndf ","f31a4a02":"#extracting only the independent variables (FEATURES)\n\npd.DataFrame(df.data)","67e6475f":"#storing the independent variables into a dataframe\n\ndataset = pd.DataFrame(df.data)","6422fba4":"dataset.columns = df.feature_names","91a7fe2b":"#displaying the final dataset with column names\n\ndataset","9ddaa654":"#displaying only the first 5 records of the dataset\n\ndataset.head()","20f55958":"#creating label (dependent variable) -- price \n\ndataset['price'] = df.target","a857dc07":"#displaying the first 5 records of the dataset\n\ndataset.head()","f1b529cb":"#splitting the dataset into dependent features (LABEL) - 'price' and independent features (all columns except 'price')\n\nx = dataset.drop(columns=['price'])\ny = dataset['price']","03c8a884":"#displaying the dependent feature\n\ny","8ca7f495":"#displaying the independent feature\n\nx","19d55373":"#Importing Linear Regression and Cross Validation from sklearn library\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score","31486e70":"#model \n\nlr = LinearRegression()","ffe4bfdc":"#Performing Cross Validation on the dataset\n\nmse = cross_val_score(lr,x,y,scoring='neg_mean_squared_error',cv=5)","10465ca4":"#5 cross validations performed\n\nmse","b4882a07":"#calculating mean of the mse\n\nmean_mse = np.mean(mse)\nmean_mse","e49e3427":"#Importing Ridge Regression from sklearn library and GridSearchCV for Hyper Parameter Tuning\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV  #hyperparameter tuning","62e64f53":"#model\n\nridge = Ridge()","858ef556":"#creating parameter for Hyper Paramater Tuning\n\nparams={'alpha' :[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]}","61f3ee7b":"#object creation\n\nridge_regressor = GridSearchCV(ridge,params,scoring='neg_mean_squared_error',cv=10)","c4ac418a":"#fitting our model \n\nridge_regressor.fit(x,y)","f6864b42":"ridge_regressor.best_params_","b9a636b1":"ridge_regressor.best_score_","fde14c31":"#Importing Lasso Regression from sklearn library and GridSearchCV for Hyper Parameter Tuning\n\nfrom sklearn.linear_model import Lasso","c8deedab":"#MODEL\n\nlasso = Lasso()","34fb90c4":"#creating parameter for Hyper Paramater Tuning\n\nparams={'alpha' :[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]}","968735a9":"#object creation\n\nlasso_regressor = GridSearchCV(lasso,params,scoring='neg_mean_squared_error',cv=10)","48459feb":"#fitting our model \n\nlasso_regressor.fit(x,y)","ed7248ee":"ridge_regressor.best_params_","177d8499":"ridge_regressor.best_score_","c1d56f40":"#Importing train test split from sklearn library\n\nfrom sklearn.model_selection import train_test_split","767520b8":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.33,random_state=42)","db666251":"#MODEL TRAINING\n\nridge_regressor.fit(x_train,y_train)","535c4283":"#accuracy score\n\nridge_regressor.best_score_","06bb7a6d":"#MODEL TRAINING\n\nlasso_regressor.fit(x_train,y_train)","59f476d5":"#accuracy score\n\nlasso_regressor.best_score_","cffe788d":"# importing R2 score from sklearn library\n\nfrom sklearn.metrics import r2_score","924d5f2f":"#Fitting the model\n\nridge_regressor.fit(x_train,y_train)","58faed6e":"y_pred = ridge_regressor.predict(x_test)","f1001be2":"r2_score1 = r2_score(y_pred,y_test)","2ad686c1":"r2_score1","02039aa0":"**MODEL CREATION**","454d7a0c":"# **LASSO REGRESSION**","22e7f5c7":"# **R2 SCORE**","a7458570":"# **TRAIN TEST SPLIT**","7af119f9":"> **We got -26 score for the Ridge Regression model that we have created**","28aadd80":"LASSO REGRESSION","81ef5dc1":"# **IMPORTING LIBRARIES**","0d62688f":"> Cross Validation takes different combination of the dataset to train the model , let us take 5 as cv for our model","32612b5f":"> **Both Ridge Regression and Lasso Regression have same accuracy score which is -25, So let us improve our score using R2 score**","26eb2ff6":"**CROSS VALIDATION**","1997c0b8":"> **Splitting the dataset into dependent features (LABEL) - 'price' and independent features (all columns except 'price')**","67cb77d1":"# **DISPLAYING THE DATASET**","2237de5b":"**MODEL TRAINING**","73df610a":"**BEST PARAMETER AND SCORE OF THE MODEL**","2d947602":"> **Let us split our model into a 30% test set and rest(70%) train set for our model training**","971eaffe":"# **LINEAR REGRESSION**","a448db05":"# Finally, Our Regression model has a good accuracy of 67% score ","5226e788":"> Let us now create a column ' price' for the independent feature (LABEL)","73ca8345":"**MODEL CREATION**","d6162a26":"> **We got -29 score for the Ridge Regression model that we have created**","9902b164":"# **READING THE DATASET**","8ba9d259":"# **SPLITTING DATASET INTO FEATURES AND LABELS**","59578f59":"**MODEL CREATION**","9460c87b":"RIDGE REGRESSION","5e528f0e":"# **RIDGE REGRESSION**","02d9f753":"**BEST PARAMETER AND SCORE OF THE MODEL**","ca18ef37":"> **We got -37 score for the Linear Regression model that we have created**","1dafa760":"Splitting our dataset into Train set and Test Set ","ef3f7fa0":"> The dataset is in the  form of key,value pairs - like a dictionary"}}