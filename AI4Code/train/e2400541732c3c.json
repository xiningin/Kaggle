{"cell_type":{"d76d2aab":"code","a4060135":"code","fe7e27e3":"code","0d5933b7":"code","29f7be60":"code","74a44976":"code","f72501ff":"code","5cb6f1fa":"code","2f62f73e":"code","80347e46":"code","08bcc55a":"code","aa276cb9":"code","7bb5d56b":"code","9b7d0f86":"code","e0f0bfd0":"code","25e93203":"code","8a2574f9":"code","a97953be":"code","6c424d78":"code","1ba00e95":"code","734036c5":"code","91533b79":"code","9c67072b":"code","f3a93679":"code","014460d5":"code","cacbdc58":"code","617455b8":"code","3f3337e0":"code","30986cb8":"code","e37876af":"code","f8aeb696":"code","10d9c59c":"code","c1d80ed4":"code","51421278":"code","84f1fd2d":"code","523b02a0":"code","dfdbb482":"code","c474e67f":"code","1fb207a8":"code","5739bb11":"code","bbab834a":"code","ebca8211":"code","84f8ed8e":"code","ab2f03f0":"code","01b1df67":"code","7f00766f":"code","884a5602":"code","8397f9a6":"code","3a9cf22c":"code","9facd8d7":"code","5f0bea64":"code","4cbe402a":"code","c9e7dce2":"code","4ce3edf8":"code","77a20e2b":"code","08635e47":"code","2deb3556":"code","9796e632":"code","e2af14db":"code","43550b21":"code","c2e03c22":"code","6ff73c42":"code","e3cfca1d":"code","47db545b":"markdown","37287cea":"markdown","7b56923c":"markdown","1b8c66eb":"markdown","09028e7f":"markdown","af2e134e":"markdown","5ae67588":"markdown","89b068ef":"markdown","f80d7f6f":"markdown","34ccaceb":"markdown","be1bd885":"markdown","2d7d370b":"markdown","96bf2ac5":"markdown","7fd7e54f":"markdown","f6ce9086":"markdown","fa326a57":"markdown","9a921fd4":"markdown","d8facfc2":"markdown","b14df63d":"markdown","784623ed":"markdown","6ff4d93b":"markdown","b01c9a6f":"markdown","25a06b31":"markdown","58bd3429":"markdown","30c79882":"markdown","a8e50739":"markdown","1e6ce3f9":"markdown","da653341":"markdown","8abe884a":"markdown","c4d02edd":"markdown","7c34fd54":"markdown","481f85bc":"markdown","2009b9f9":"markdown"},"source":{"d76d2aab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a4060135":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use(\"fivethirtyeight\")\nsns.set_style(\"darkgrid\")","fe7e27e3":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, auc, roc_curve, f1_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n\nimport torch","0d5933b7":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv\")","29f7be60":"train.head()","74a44976":"test.head()","f72501ff":"sub.head()","5cb6f1fa":"print('Rows and Columns in train dataset:', train.shape)\nprint('Rows and Columns in test dataset:', test.shape)","2f62f73e":"trainoriginal = train.copy()\ntestoriginal = test.copy()","80347e46":"display(train.info())\ndisplay(test.info())","08bcc55a":"print('Missing values in train dataset:', sum(train.isnull().sum()))\nprint('Missing values in test dataset:', sum(test.isnull().sum()))","aa276cb9":"print('Missing values per columns in train dataset')\nfor col in train.columns:\n    train_col = train[col].isnull().sum()\n    print(f'{col}: {train_col}')","7bb5d56b":"print('Missing values per columns in test dataset')\nfor col in test.columns:\n    test_col = test[col].isnull().sum()\n    print(f'{col}: {test_col}')","9b7d0f86":"primary_blue = \"#496595\"\nprimary_blue2 = \"#85a1c1\"\nprimary_grey = \"#c6ccd8\"\nprimary_black = \"#202022\"","e0f0bfd0":"missing = (train.isna().sum().sort_values(ascending=False) \/ len(train) * 100)[:6]\nfig, ax = plt.subplots(1,1,figsize=(9, 8))\n\nax.bar(missing.index, 100, color=primary_grey, width=0.8)\n\nbar = ax.bar(missing.index, missing, color=primary_black, width=0.6)\nax.bar_label(bar, fmt='%.01f %%')\nax.spines.left.set_visible(False)\nax.set_yticks([])\nax.set_title('Missing Values Ratio', fontweight='bold')\n\nplt.show()","25e93203":"train['Survived'].value_counts().to_frame()","8a2574f9":"plt.figure(figsize=(8,6))\nsns.countplot(train['Survived'])\nplt.show()","a97953be":"def categorical(cat, train=train):\n    ax = plt.subplots(figsize=(8,6))\n    sns.countplot(x=cat, data=train)\n    plt.xticks(size=16)\n    plt.yticks(size=16)\n    plt.xlabel(cat+' :Count', fontweight='bold', size=17)\n    plt.ylabel('Count', fontweight='bold', size=17)\n    plt.show()\n    \ndef hue(cat, train=train):\n    ax = plt.subplots(figsize=(8,6))\n    sns.countplot(x=cat, hue='Survived', data=train)\n    plt.show()","6c424d78":"categorical('Sex')","1ba00e95":"hue('Sex')","734036c5":"categorical('Embarked')","91533b79":"hue('Embarked')","9c67072b":"categorical('Pclass')","f3a93679":"hue('Pclass')","014460d5":"categorical('SibSp')","cacbdc58":"hue('SibSp')","617455b8":"categorical('Parch')","3f3337e0":"hue('Parch')","30986cb8":"fig = go.Figure()\n\nfig.add_trace(go.Histogram(x=train['Age'],\n                           name='train', \n                           histnorm='probability density',\n                           xbins=dict(\n                               start=0,\n                               end=100,\n                               size=2\n                           ),\n                           marker_color='lightsalmon',\n                           opacity=0.75\n                          )\n             ) \nfig.add_trace(go.Histogram(x=test['Age'],\n                           name='test', \n                           histnorm='probability density',\n                           xbins=dict(\n                               start=0,\n                               end=100,\n                               size=2\n                           ),\n                           marker_color='lightseagreen',\n                           opacity=0.75\n                          )\n             ) \nfig.update_layout(title='Passengers Age Distribution (train-test)',\n                  xaxis_title='Age [years]', \n                  yaxis_title='Probability Density [-]',\n                  titlefont={'size': 24},\n                  font_family = 'San Serif',\n                  width=1000,height=800,\n                  template=\"plotly_dark\",\n                  showlegend=True,\n                  paper_bgcolor=\"black\",\n                  font=dict(\n                      color ='white',\n                      ),\n                  legend=dict(\n                      orientation=\"v\",\n                      y=1, \n                      yanchor=\"top\", \n                      x=1.0, \n                      xanchor=\"right\",)   \n )\nfig.show()\n","e37876af":"train.drop(['PassengerId'], axis=1, inplace=True)\ntest.drop(['PassengerId'], axis=1, inplace=True)","f8aeb696":"# Pearson Correlation\nplt.figure(figsize=(10,8))\nsns.heatmap(train.corr(method='pearson'), cbar=False, annot=True, fmt='.1', linewidth=0.2);","10d9c59c":"# Spearman Correlation\nplt.figure(figsize=(10,8))\nsns.heatmap(train.corr(method='spearman'), cbar=False, annot=True, fmt='.1', linewidth=0.2);","c1d80ed4":"# kendall\nfig, ax = plt.subplots(1, 3, figsize=(17 , 5))\n\nfeature_lst = ['Pclass', 'Age', 'SibSp','Parch','Fare']\n\ncorr = train[feature_lst].corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nfor idx, method in enumerate(['pearson', 'kendall', 'spearman']):\n    sns.heatmap(train[feature_lst].corr(method=method), ax=ax[idx],\n            square=True, annot=True, fmt='.2f', center=0, linewidth=2,\n            cbar=False, cmap=sns.diverging_palette(240, 10, as_cmap=True),\n            mask=mask\n           ) \n    ax[idx].set_title(f'{method.capitalize()} Correlation', loc='left', fontweight='bold')     \n\nplt.show()","51421278":"train.corr()['Survived']","84f1fd2d":"a = train.drop('Survived', axis=1)\na.corrwith(train['Survived']).plot(kind='bar', grid=True, figsize=(10,8), color='salmon')\nplt.title(\"Correlation with target\", fontweight='bold', size=20)\nplt.xticks(size=15, rotation=90)\nplt.yticks(size=15)\nplt.show()","523b02a0":"plt.figure(figsize=(10,8))\nsns.boxplot(data=train, orient='h', palette='Set2');","dfdbb482":"plt.figure(figsize=(10,8))\nsns.boxplot(data=test, orient='h', palette='Set2');","c474e67f":"train.skew().sort_values(ascending=True)","1fb207a8":"test.skew().sort_values(ascending=True)","5739bb11":"sns.pairplot(data=train);","bbab834a":"sns.pairplot(data=test);","ebca8211":"train = train.drop(['Name', 'Cabin'], axis=1)\ntest = test.drop(['Name', 'Cabin'], axis=1)","84f8ed8e":"display(train.head(2))\ndisplay(test.head(2))","ab2f03f0":"# Fill Missing values in train and test\ntrain['Age'] = train['Age'].fillna(train['Age'].mean())\ntest['Age'] = test['Age'].fillna(test['Age'].mean())\n\ntrain['Fare'] = train['Fare'].fillna(train['Fare'].mean())\ntest['Fare'] = test['Fare'].fillna(test['Fare'].mean())","01b1df67":"le = LabelEncoder()\n\ntrain['Sex'] = le.fit_transform(train['Sex'])\ntrain['Embarked'] = le.fit_transform(train['Embarked'])\n\ntest['Sex'] = le.fit_transform(test['Sex'])\ntest['Embarked'] = le.fit_transform(test['Embarked'])","7f00766f":"tickets = train['Ticket'].str.split()\ntickets = [\n    ticket[-1] if len(ticket) > 1 else ticket[0] \n    for ticket in [\n        ['9999999999'] if ticket is np.nan else ticket \n    for ticket in tickets]\n]\ntickets = [int(elem) if elem.isdigit() else 9999999999 for elem in tickets]\ntrain['Ticket'] = tickets\n\ntickets = test['Ticket'].str.split()\ntickets = [\n    ticket[-1] if len(ticket) > 1 else ticket[0] \n    for ticket in [\n        ['9999999999'] if ticket is np.nan else ticket \n    for ticket in tickets]\n]\ntickets = [int(elem) if elem.isdigit() else 9999999999 for elem in tickets]\ntest['Ticket'] = tickets","884a5602":"y = train.loc[:, ['Survived']]\nX = train.drop(axis=1, columns=['Survived'])","8397f9a6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","3a9cf22c":"# Defining base learners\nmyclf1 = KNeighborsClassifier(n_neighbors=1)\nmyclf2 = RandomForestClassifier(random_state=1)\nmyclf3 = GaussianNB()","9facd8d7":"# Defining meta model\nmylr = LogisticRegression()","5f0bea64":"# creating stacking classifier with above models\nstackingclf = StackingClassifier(estimators=[myclf1, myclf2, myclf3], final_estimator=mylr)","4cbe402a":"print('Doing 3-fold cross validation here:\\n')\n\nfor iterclf, iterlabel in zip([myclf1, myclf2, myclf3, stackingclf],\n                              ['K-Nearest Neighbors Model',\n                               'Random Forest Model',\n                               'Naive Bayes Model',\n                               'StackingClassifier Model']):\n    scores = cross_val_score(iterclf, X_train,y_train, cv=3, scoring='accuracy')\n    print(\"Accuracy: %0.3f (+\/- %0.3f) [%s]\"\n         % (scores.mean(), scores.std(), iterlabel))","c9e7dce2":"estimators = [\n    ('rfc', RandomForestClassifier(max_depth=70, \n                                   n_estimators=58, \n                                   min_samples_split=2,\n                                   n_jobs=-1,\n                                   random_state=3)),\n    ('lgbm', LGBMClassifier(max_depth=123,\n                            n_estimators=95,\n                            n_jobs=-1,\n                            num_leaves=65,\n                            random_state=95),\n    ('xgb', XGBClassifier(max_depth=150, \n                          n_estimators=95, \n                          random_state=45, \n                          n_jobs=-1)))\n]","4ce3edf8":"stack_clfs = StackingClassifier(estimators = estimators, \n                                final_estimator = LGBMClassifier())","77a20e2b":"stack_clfs.fit(X_train, y_train)","08635e47":"Y_pred = stack_clfs.predict(X_test)\naccuracy_score(Y_pred, y_test)","2deb3556":"y_pred_stack_clfs = stack_clfs.predict(test)","9796e632":"lgbm_parameters = {\n    'reg_alpha': 0.00388218567052311,\n    'reg_lambda': 8.972335390951376e-05,\n    'colsample_bytree': 0.18375780999902297,\n    'subsample': 0.013352256062576087,\n    'learning_rate': 0.002597839272059483,\n    'max_depth': 44,\n    'num_leaves': 15,\n    'min_child_samples': 89,\n    'cat_smooth': 56, \n    'cat_l2': 22.375773634793603,\n    'max_bin': 33, \n    'min_data_per_group': 89\n}","e2af14db":"lgbm_parameters['metric'] = 'binary_logloss'\nlgbm_parameters['objective'] = 'binary'\nlgbm_parameters['n_estimators'] = 15000","43550b21":"lgbm_model = LGBMClassifier(**lgbm_parameters)","c2e03c22":"lgbm_model.fit(X_train, y_train)","6ff73c42":"plt.rcParams[\"figure.figsize\"] = (6, 5)\nlightgbm.plot_importance(lgbm_model, max_num_features = 16, height=.9)","e3cfca1d":"submission = pd.DataFrame({\"PassengerId\": testoriginal[\"PassengerId\"], \"Survived\": y_pred_stack_clfs})\nsubmission.to_csv('submission.csv', index=False)","47db545b":"### First 5 rows\n- **Print First 5 rows in the train dataset**","37287cea":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:130%; text-align:center; border-radius: 15px 50px;\">f) Data Visualisation<\/p>","7b56923c":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:120%; text-align:center; border-radius: 15px 50px;\">2. Sex<\/p>","1b8c66eb":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:130%; text-align:center; border-radius: 15px 50px;\">b) Droping Unwanted Columns<\/p>","09028e7f":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:120%; text-align:center; border-radius: 15px 50px;\">3. Embarked<\/p>","af2e134e":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\"> Stacking <\/p>","5ae67588":"## <p style=\"background-color:Yellow; font-family:newtimeroman; font-size:160%; text-align:center; border-radius: 15px 50px;\">5. Model Building and Validation<\/p>","89b068ef":"## <p style=\"background-color:Yellow; font-family:newtimeroman; font-size:160%; text-align:center; border-radius: 15px 50px;\">2. Import Data<\/p>","f80d7f6f":"## <p style=\"background-color:Salmon; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">Table of Content<\/p>\n\n* [1. Import Required Libraries](#1)\n* [2. Import Data](#1)    \n* [3. EDA(Exploratory Data Analysis)](#2)\n    * [3.1 Missing Values](#2.1)\n    * [3.2 Droping Unwanted Columns](#2.2)\n    * [3.3 Correlation between Features](#2.3)\n       * [3.3.1 The correlation between the continuos variables](#2.4)\n       * [3.3.2 The correlation between this continuos features and the target](#2.4)\n    * [3.4 Outliers](#2.4)\n    * [3.5 Skewness and Kurtsis](#2.4)\n    * [3.6 Data Visualisation](#2.4)\n* [4. Feature Engineering \ud83d\udee0](#3)\n* [5. Stacking](#4)\n* [6. Model Building and Validation](#4)","34ccaceb":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:130%; text-align:center; border-radius: 15px 50px;\">a) Missing Values<\/p>","be1bd885":"## <p style=\"background-color:Blue; font-family:newtimeroman; font-size:120%; text-align:left; border-radius: 5px 5px;\"> iii) Multivariate Analysis<\/p>","2d7d370b":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">7. Age<\/p>","96bf2ac5":"- **Print First 5 rows in the test dataset**","7fd7e54f":"|Feature          |Description                                                                      |\n|-----------------|---------------------------------------------------------------------------------|\n|Pclass           |A proxy for socio-economic status (SES) where 1st = Upper, 2nd = Middle and 3rd = Lower.|\n|Sex              |male and female.|\n|Age              |fractional if it less than 1 and age estimation in the form of xx.5.|\n|SibSp            |number of siblings \/ spouses aboard the Synthanic; siblings are brother, sister, stepbrother and stepsister and spouses are husband and wife (mistresses and fianc\u00e9s were ignored).|\n|Parch            |# of parents \/ children aboard the Synthanic; parents are mother and father; child are daughter, son, stepdaughter and stepson. Some children travelled only with a nanny, therefore Parch is 0 for them.|\n|Fare             |the paassenger fare.|\n|Cabin            |the cabin number.|\n|Emarked          |port of embarkation where C is Cherbourg, Q is Queenstown and S is Southampton.|\n|Ticket           |ticket number.|\n|Name             |passengers name.|\n|Survived         |target variable where 0 is not survived and 1 is survived.|","f6ce9086":"## <p style=\"background-color:Yellow; font-family:newtimeroman; font-size:160%; text-align:center; border-radius: 15px 50px;\">4. Feature Engineering<\/p>","fa326a57":"## <p style=\"background-color:Yellow; font-family:newtimeroman; font-size:160%; text-align:center; border-radius: 15px 50px;\">3. EDA(Exploratory Data Analysis)<\/p>","9a921fd4":"### Numbers of rows and columns","d8facfc2":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:120%; text-align:center; border-radius: 15px 50px;\">6. Parch<\/p>","b14df63d":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:120%; text-align:center; border-radius: 15px 50px;\">4. Pclass<\/p>","784623ed":"- For different background colors : http:\/\/www.htmlcodes.ws\/color\/html-color-code-generator.cfm?colorName=SkyBlue","6ff4d93b":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\"> Submission <\/p>","b01c9a6f":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:130%; text-align:center; border-radius: 15px 50px;\">e) Skewness and Kurtsis<\/p>","25a06b31":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:120%; text-align:center; border-radius: 15px 50px;\">1. Survived<\/p>","58bd3429":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\"> Feature Importance <\/p>","30c79882":"## <p style=\"background-color:GreenYellow; font-family:newtimeroman; font-size:120%; text-align:left; \">ii) The correlation between this continuos features and the target<\/p>  ","a8e50739":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:130%; text-align:center; border-radius: 15px 50px;\">d) Outliers<\/p>","1e6ce3f9":"## <p style=\"background-color:Salmon; font-family:newtimeroman; font-size:160%; text-align:center; border-radius: 15px 50px;\">Features description<\/p>","da653341":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:130%; text-align:center; border-radius: 15px 50px;\">c) Correlation between Features<\/p>","8abe884a":"## <p style=\"background-color:GreenYellow; font-family:newtimeroman; font-size:120%; text-align:left; \">i) The correlation between the continuos variables<\/p>  \n\n - a. Pearson Correlation\n - b. Spearman Correlation\n - c. kendall","c4d02edd":"- **Print First 5 rows in the submission dataset**","7c34fd54":"## <p style=\"background-color:magenta; font-family:newtimeroman; font-size:120%; text-align:center; border-radius: 15px 50px;\">5. SibSp<\/p>","481f85bc":"## <p style=\"background-color:Yellow; font-family:newtimeroman; font-size:160%; text-align:center; border-radius: 15px 50px;\">1. Import Required Libraries<\/p>","2009b9f9":"### Kendral Correlation\n- With reference to subin : https:\/\/www.kaggle.com\/subinium\/tps-apr-highlighting-the-data"}}