{"cell_type":{"96bf25b0":"code","24baf2e1":"code","15a0a0ec":"code","d494da2c":"code","c8cec708":"code","7ebd34eb":"code","b9ad6186":"code","8f7d7ee9":"code","2ee83f6e":"code","7f353236":"code","413bc62b":"code","10596cf6":"code","9d35738c":"code","0d456a6e":"code","002a13cd":"code","82748017":"code","a63b4c1a":"code","e8f2a6ba":"code","bd0fabf1":"markdown","3c2cdcd7":"markdown","c821d880":"markdown","af1f1056":"markdown","570de335":"markdown","50e0032b":"markdown","f3caeb63":"markdown","1b80170a":"markdown","d247185b":"markdown","84b9cd01":"markdown","9ae08fcf":"markdown","3f973a03":"markdown","50d19fe3":"markdown","b220e496":"markdown","4b9bd987":"markdown","ded854b4":"markdown","399f187c":"markdown","3b3ccf6c":"markdown"},"source":{"96bf25b0":"# Array Manipulation\nimport numpy as np\n\n# Tensorflow and Keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Reading and Showing Images\nfrom glob import glob\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Tensorflow Addons | For InstanceNormalization\nimport tensorflow_addons as tfa","24baf2e1":"train_horse_path = glob(\"..\/input\/horse2zebra\/horse2zebra\/trainA\"+\"\/*\")\ntrain_zebra_path = glob(\"..\/input\/horse2zebra\/horse2zebra\/trainB\"+\"\/*\")\n\ntest_horse_path = glob(\"..\/input\/horse2zebra\/horse2zebra\/testA\"+\"\/*\")\ntest_zebra_path = glob(\"..\/input\/horse2zebra\/horse2zebra\/testB\"+\"\/*\")","15a0a0ec":"train_horse = []\ntrain_zebra = []\n\ntest_horse = []\ntest_zebra = []\n\nfor path in train_horse_path:\n    img = cv2.imread(path)\n    img = cv2.resize(img,(256,256))\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    \n    train_horse.append(img)\n    \nfor path in train_zebra_path:\n    img = cv2.imread(path)\n    img = cv2.resize(img,(256,256))\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    \n    train_zebra.append(img)\n\nfor path in test_horse_path:\n    img = cv2.imread(path)\n    img = cv2.resize(img,(256,256))\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    \n    test_horse.append(img)\n    \nfor path in test_zebra_path:\n    img = cv2.imread(path)\n    img = cv2.resize(img,(256,256))\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    \n    test_zebra.append(img)\n\ntrain_horse = np.array(train_horse).astype(np.float32) \/ 127.5 - 1\ntest_horse = np.array(test_horse).astype(np.float32) \/ 127.5 -1 \n\ntrain_zebra = np.array(train_zebra).astype(np.float32) \/ 127.5 - 1\ntest_zebra = np.array(test_zebra).astype(np.float32) \/ 127.5 - 1\n\nhorse_ds = tf.data.Dataset.from_tensor_slices(train_horse).batch(1)\nzebra_ds = tf.data.Dataset.from_tensor_slices(train_zebra).batch(1)\n","d494da2c":"OUT_CHANNELS = 3\n# Red Green and Blue\n\ndef downsample(filters,filter_size,apply_instancenorm=True):\n    initializer = tf.random_normal_initializer(0.,0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.,stddev=0.02)\n    \n    model = keras.Sequential()\n    model.add(layers.Conv2D(filters,filter_size,strides=2,padding=\"same\",kernel_initializer=initializer,use_bias=False))\n    \n    if apply_instancenorm:\n        model.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n    \n    model.add(layers.LeakyReLU())\n    \n    return model","c8cec708":"def upsample(filters,filter_size,apply_dropout=False):\n    initializer = tf.random_normal_initializer(0.,0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0,stddev=0.02)\n    \n    model = keras.Sequential()\n    model.add(layers.Conv2DTranspose(filters,\n                                     filter_size,\n                                     strides=2,\n                                     padding=\"same\",\n                                     kernel_initializer=initializer,\n                                     use_bias=False\n                                    ))\n    \n    \n    model.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n    \n    if apply_dropout:\n        model.add(layers.Dropout(0.5))\n        \n    model.add(layers.ReLU())\n    return model","7ebd34eb":"def Generator():\n    inputs = layers.Input([256,256,3])\n    \n    downstack = [\n        downsample(64,4,apply_instancenorm=False), # 128x128\n        downsample(128,4), # 64x64\n        downsample(256,4), # 32x32\n        downsample(512,4), # 16x16\n        downsample(512,4), # 8x8\n        downsample(512,4), # 4x4\n        downsample(512,4), # 2x2\n        downsample(512,4) # 1x1\n    ]\n    \n    upstack = [\n        upsample(512,4,apply_dropout=True), # 2x2\n        upsample(512,4,apply_dropout=True), # 4x4\n        upsample(512,4,apply_dropout=True), # 8x8\n        upsample(512,4), # 16x16\n        upsample(256,4), # 32x32\n        upsample(128,4), # 64x64\n        upsample(64,4) # 128x128\n        \n        # We'll add last layer to gain a 256x256 image\n    ]\n    \n    initializer = tf.random_normal_initializer(0.,0.02)\n    \n    last = layers.Conv2DTranspose(OUT_CHANNELS,\n                                  4,\n                                  strides=2,\n                                  padding=\"same\",\n                                  activation=\"tanh\",\n                                  kernel_initializer=initializer)\n    \n    \n    # Now in order to solve vanishing gradient problem, we'll connect layers using skip connections\n    \n    x = inputs\n    \n    skips = []\n    for down in downstack:\n        x = down(x)\n        skips.append(x)\n        \n    skips = reversed(skips[:-1])\n    \n    for up,skip in zip(upstack,skips):\n        x = up(x)\n        x = layers.Concatenate()([x,skip])\n        \n    x = last(x)\n    \n    return tf.keras.Model(inputs=inputs,outputs=x)\n    ","b9ad6186":"def Discriminator():\n    initializer = tf.random_normal_initializer(0.,0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.,stddev=0.02)\n    \n    inputs = layers.Input(shape=(256,256,3),name=\"input_layer\")\n    \n    x = inputs\n    \n    down1 = downsample(64,4,False)(x)\n    down2 = downsample(128,4)(down1)\n    down3 = downsample(256,4)(down2)\n    \n    zero_pad = layers.ZeroPadding2D()(down3)\n    \n    conv = layers.Conv2D(512,4,strides=1,kernel_initializer=initializer,use_bias=False)(zero_pad)\n    \n    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n    \n    leaky_relu = layers.LeakyReLU()(norm1)\n    \n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)\n    \n    last = layers.Conv2D(1,4,strides=1,kernel_initializer=initializer)(zero_pad2)\n    \n    return tf.keras.Model(inputs=inputs,outputs=last)\n\n    \n    ","8f7d7ee9":"zebra_generator = Generator()\nhorse_generator = Generator()\n\nzebra_discriminator = Discriminator()\nhorse_discriminator = Discriminator()\n\n","2ee83f6e":"class CycleGAN(keras.Model):\n    \n    def __init__(self,\n                 zebra_generator,\n                 horse_generator,\n                 zebra_discriminator,\n                 horse_discriminator,\n                 lambda_cycle=10\n                ):\n        \n        \"\"\"\n        Lambda Cycle is a hyperparameter, we won't change it\n        \"\"\"\n        \n        super(CycleGAN,self).__init__()\n        self.z_gen = zebra_generator\n        self.h_gen = horse_generator\n        self.z_disc = zebra_discriminator\n        self.h_disc = horse_discriminator\n        self.lambda_cycle = lambda_cycle\n        \n    \n    def compile(self,\n                z_gen_optimizer,\n                h_gen_optimizer,\n                z_disc_optimizer,\n                h_disc_optimizer,\n                gen_loss_fn,\n                disc_loss_fn,\n                cycle_loss_fn,\n                identity_loss_fn\n               ):\n        \n        super(CycleGAN,self).compile()\n        self.z_gen_optimizer = z_gen_optimizer\n        self.h_gen_optimizer = h_gen_optimizer\n        self.z_disc_optimizer = z_disc_optimizer\n        self.h_disc_optimizer = h_disc_optimizer\n        \n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n        \n        \"\"\"\n        We've created attributes\n        \"\"\"\n        \n    def train_step(self,batch_data):\n        real_zebra,real_horse = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n            # horse to zebra back to horse\n            fake_zebra = self.z_gen(real_horse,training=True)\n            cycled_horse = self.h_gen(fake_zebra,training=True)\n            \n            # zebra to horse back to zebra\n            fake_horse = self.h_gen(real_zebra,training=True)\n            cycled_zebra = self.z_gen(fake_horse,training=True)\n            \n            # zebra to zebra, horse to horse\n            same_zebra = self.z_gen(real_zebra,training=True)\n            same_horse = self.h_gen(real_horse,training=True)\n            \n            # discriminator detects whether zebras are real or not\n            disc_real_zebra = self.z_disc(real_zebra,training=True)\n            disc_fake_zebra = self.z_disc(fake_zebra,training=True)\n            \n            # discriminator detects whether horses are real or not\n            disc_real_horse = self.h_disc(real_horse,training=True)\n            disc_fake_horse = self.h_disc(fake_horse,training=True)\n            \n            # computing generator loss\n            zebra_gen_loss = self.gen_loss_fn(disc_fake_zebra)\n            horse_gen_loss = self.gen_loss_fn(disc_fake_horse)\n            \n            # computing cycle loss\n            total_cycle_loss = self.cycle_loss_fn(real_zebra,\n                                                  cycled_zebra,\n                                                  self.lambda_cycle\n                                                 ) + self.cycle_loss_fn(real_horse,\n                                                                        cycled_horse,\n                                                                        self.lambda_cycle\n                                                                       )\n            \n            # computing total generator loss\n            total_zebra_gen_loss = zebra_gen_loss + total_cycle_loss + self.identity_loss_fn(real_zebra,\n                                                                                             same_zebra,\n                                                                                             self.lambda_cycle\n                                                                                            )\n            \n            total_horse_gen_loss = horse_gen_loss + total_cycle_loss + self.identity_loss_fn(real_horse,\n                                                                                             same_horse,\n                                                                                             self.lambda_cycle\n                                                                                            )\n            \n            # computing discriminator loss\n            zebra_disc_loss = self.disc_loss_fn(disc_real_zebra,disc_fake_zebra)\n            horse_disc_loss = self.disc_loss_fn(disc_real_horse,disc_fake_horse)\n            \n            \"\"\"\n            Now let's use these losses in order to compute gradients and update parameters\n            \"\"\"\n        \n        # computing gradients of generators\n        zebra_generator_gradients = tape.gradient(total_zebra_gen_loss,\n                                                  self.z_gen.trainable_variables\n                                                 )\n        \n        horse_generator_gradients = tape.gradient(total_horse_gen_loss,\n                                                  self.h_gen.trainable_variables\n                                                 )\n        \n        # computing gradients of discriminator\n        zebra_discriminator_gradients = tape.gradient(zebra_disc_loss,\n                                                      self.z_disc.trainable_variables\n                                                     )\n        \n        horse_discriminator_gradients = tape.gradient(horse_disc_loss,\n                                                      self.h_disc.trainable_variables\n                                                     )\n        \n        # applying gradients \n        \n        self.z_gen_optimizer.apply_gradients(zip(zebra_generator_gradients,\n                                                 self.z_gen.trainable_variables\n                                                ))\n        \n        self.h_gen_optimizer.apply_gradients(zip(horse_generator_gradients,\n                                                 self.h_gen.trainable_variables\n                                                ))\n        \n        \n        self.z_disc_optimizer.apply_gradients(zip(zebra_discriminator_gradients,\n                                                  self.z_disc.trainable_variables\n                                                 ))\n        \n        self.h_disc_optimizer.apply_gradients(zip(horse_discriminator_gradients,\n                                                  self.h_disc.trainable_variables\n                                                 ))\n        \n        # returning stats\n        \n        return {\"zebra_gen_loss\":total_zebra_gen_loss,\n                \"horse_gen_loss\":total_horse_gen_loss,\n                \"zebra_discriminator_loss\":zebra_disc_loss,\n                \"horse_discriminator_loss\":horse_disc_loss\n               }\n            \n            ","7f353236":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\n\ndef discriminator_loss(real,generated):\n    \n    real_loss = cross_entropy(tf.ones_like(real),real)\n    fake_loss = cross_entropy(tf.zeros_like(generated),generated)\n    \n    total_loss = real_loss + fake_loss\n    \n    return total_loss * 0.5\n\n","413bc62b":"def generator_loss(generated):\n    # We've used ones-like becuase generator will try to fool discriminator\n    return cross_entropy(tf.ones_like(generated),generated)","10596cf6":"def calc_cycle_loss(real_image,cycled_image,LAMBDA):\n    \n    cycle_loss = tf.reduce_mean(tf.abs(real_image-cycled_image))\n    \n    return LAMBDA * cycle_loss\n\n","9d35738c":"def identity_loss(real_image,same_image,LAMBDA):\n    \n    id_loss = tf.reduce_mean(tf.abs(real_image-same_image))\n    \n    return LAMBDA * id_loss","0d456a6e":"zebra_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nhorse_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\nzebra_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nhorse_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","002a13cd":"cycle_gan_model = CycleGAN(zebra_generator,\n                           horse_generator,\n                           zebra_discriminator,\n                           horse_discriminator\n                          )\n                           ","82748017":"cycle_gan_model.compile(zebra_generator_optimizer,\n                        horse_generator_optimizer,\n                        zebra_discriminator_optimizer,\n                        horse_discriminator_optimizer,\n                        generator_loss,\n                        discriminator_loss,\n                        calc_cycle_loss,\n                        identity_loss\n                       )","a63b4c1a":"final_dataset = tf.data.Dataset.zip((zebra_ds,horse_ds))\n\ncycle_gan_model.fit(final_dataset,\n                    epochs=10,\n                   )\n\n","e8f2a6ba":"_, ax = plt.subplots(10, 2, figsize=(24,24))\nfor i, img in enumerate(horse_ds.take(10)):\n    prediction = zebra_generator(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Input Horse\")\n    ax[i, 1].set_title(\"Zebra Horse\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","bd0fabf1":"# Building CycleGAN Model\n\nEverything is ready, but still we don't have a collective model, let's concatenate everything in a CycleGAN class.","3c2cdcd7":"**Now let's build our discriminator model.**","c821d880":"# Defining Loss Functions And Optimizers\nIn this section I am going to define loss functions and declare optimizers.","af1f1056":"# Importing Libraries and The Data\nIn this section I am going to import libraries that I need and load the data.","570de335":"# But How AI Can Convert Horse to Zebra\nHello people, welcome to this kernel. In this kernel I am going to convert horses to zebras, it will be very impressive. Let's start!!!\n\n","50e0032b":"# Building and Training Cycle GAN Model\nIn this section I am going to build and train our CycleGAN model.","f3caeb63":"* A CycleGAN model contains 4 networks, let's take a look at them:\n    1. Zebra Generator: This network will convert horse images to zebra images.\n    1. Horse Generator: This network will convert zebra images to horse images.\n    \n    1. Zebra Discriminator: This network will detect whether zebra image is real or not\n    1. Horse Discriminator: This network will detect whether horse image is real or not","1b80170a":"* This function may look easy, but it will be a lifesaver.\n* Let's define upsample function","d247185b":"* Discriminator is a CNN based classifier. It detects whether image is real or generated. Our generator will try to fool discriminator and discriminator will try to detect fake images.\n\n* When our generator succeded to fool discriminator, it will be able to generate real-like images","84b9cd01":"# Conclusion\nThansk for your attention, if you have any question in your mind, please ask, I will definetely return.\n\nHave a great day.","9ae08fcf":"# Building Generator and Discriminator Networks\nIn this section I am going to build generator and discriminator networks, I'll use upsampling and downsampling functions.","3f973a03":"* This function will be the heart of our generator. Let's move on to the next section: building generator.","50d19fe3":"* We've read images as 128x128 and converted them to RGB.\n","b220e496":"* Now let's take a look at the generator.\n\n    1. First, generator downsample the input image to 1x1 \n    2. Then, generator upsample the image to 256x256\n    3. We concatenated layers becuase if we don't do it, we may encounter with vanishing gradient.","4b9bd987":"# Upsampling and Downsampling\nIn this section I am going to define two functions, first function, upsampling function will return a upsampling model (convolutional transpose, normalization, dropout and activation) and downsample function will return a downsampling model (convolutional operator, normalization and activation) Let's create our function.","ded854b4":"# Converting Some Horses :)\n\nIn this section I am going to convert some horses to zebras ","399f187c":"* What a zebra ha! ","3b3ccf6c":"**Now let's create our network objects**"}}