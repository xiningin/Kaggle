{"cell_type":{"1be35ca9":"code","ce08daf6":"code","c6c2fdb1":"code","58aa6572":"code","a32a605b":"code","7ba89e40":"code","9adc9d54":"code","52e686b4":"code","6b820e3d":"code","71974aae":"code","8b772562":"code","c83f7a5d":"code","d6c58de2":"code","3099cf4a":"code","39975a06":"code","84fc51f9":"code","f981385b":"markdown","f7f4b4f9":"markdown","96fcc330":"markdown","b5ff732f":"markdown"},"source":{"1be35ca9":"import os\nimport sys","ce08daf6":"os.listdir(\"\/kaggle\/input\/kaggle-monk-pytorch-efficientdet\/kaggle_monk_pytorch_efficientdet\")","c6c2fdb1":"os.listdir(\"\/kaggle\/input\/global-wheat-detection\")","58aa6572":"! cp -r \/kaggle\/input\/kaggle-monk-pytorch-efficientdet\/kaggle_monk_pytorch_efficientdet .","a32a605b":"! cd kaggle_monk_pytorch_efficientdet\/cocoapi\/PythonAPI\/ && pip install -e .","7ba89e40":"sys.path.append(\"kaggle_monk_pytorch_efficientdet\/cocoapi\/PythonAPI\/\")","9adc9d54":"! pip install kaggle_monk_pytorch_efficientdet\/webcolors-1.11.1-py3-none-any.whl","52e686b4":"## Import\n\nimport os\nimport sys\nsys.path.append(\"kaggle_monk_pytorch_efficientdet\/Monk_Object_Detection\/10_pytorch_efficientdet\/lib\/\");\n\nfrom infer_detector import Infer\n\ngtf = Infer();","6b820e3d":"## Load model\n\nmodel_path = \"kaggle_monk_pytorch_efficientdet\/trained_weights\/custom\/efficientdet-d4_trained.pth\";\nclasses_list = [\"wheat\"];\ngtf.load_model(model_path, classes_list, use_gpu=True);","71974aae":"img_list = os.listdir(\"\/kaggle\/input\/global-wheat-detection\/test\/\")","8b772562":"img_path = \"\/kaggle\/input\/global-wheat-detection\/test\/\" + img_list[0];\nscores, labels, boxes = gtf.predict(img_path, threshold=0.3);\nfrom IPython.display import Image\nImage(filename='output.jpg') ","c83f7a5d":"# Run in loop for for submission\n\nfrom tqdm import tqdm\ncombined = [];\nfor i in tqdm(range(len(img_list))):\n    img_id = img_list[i].split(\".\")[0];\n    img_path = \"\/kaggle\/input\/global-wheat-detection\/test\/\" + img_list[i];\n    scores, labels, boxes = gtf.predict(img_path, threshold=0.3);\n    \n    wr = \"\";\n    \n    for j in range(len(scores)):\n        score = float(scores[j])\n        x1 = int(boxes[j][0]);\n        y1 = int(boxes[j][1]);\n        x2 = int(boxes[j][2]);\n        y2 = int(boxes[j][3]);\n        w = x2-x1;\n        h = y2-y1;\n        #print(type(score), type(x1), type(y1), type(w), type(h))\n        wr += str(score) + \" \" + str(x1) + \" \" + str(y1) + \" \" + str(w) + \" \" + str(h) + \" \";\n    wr = wr[:len(wr)-1];\n    combined.append([img_id, wr]);","d6c58de2":"import pandas as pd\n\ndf = pd.DataFrame(combined, columns = ['image_id', 'PredictionString']);\ndf.to_csv(\"submission.csv\", index=False)","3099cf4a":"! rm -r kaggle_monk_pytorch_efficientdet","39975a06":"df.iloc[0]","84fc51f9":"os.listdir(\".\/\")","f981385b":"## Library details - https:\/\/github.com\/Tessellate-Imaging\/Monk_Object_Detection","f7f4b4f9":"## Installation \n## Individual files to be installed since kernel cannot use internet","96fcc330":"## Training code - https:\/\/github.com\/Tessellate-Imaging\/Monk_Object_Detection\/tree\/master\/application_model_zoo\n    \n### - See Example 18","b5ff732f":"## Inference"}}