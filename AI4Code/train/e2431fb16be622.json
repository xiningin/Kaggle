{"cell_type":{"e619d33b":"code","6ff7f273":"code","e1e5d5ce":"code","104e47f8":"code","526a5296":"code","1a6eb7ce":"code","357b2723":"code","bfa2a151":"markdown","aafabefb":"markdown","f59c4440":"markdown","2c27af1e":"markdown","01911e8f":"markdown","de090108":"markdown"},"source":{"e619d33b":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import roc_auc_score\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback\nfrom lightgbm import LGBMClassifier","6ff7f273":"df_train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nsample_solution = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","e1e5d5ce":"features = [c for c in df_test.columns if 'f' in c]\n\ndf_train['kfold'] = -1\n\ndf_train['missing'] = df_train.isnull().sum(axis=1)\ndf_test['missing']  = df_test.isnull().sum(axis=1)\n\nfeatures.append('missing')\n\ny_train = df_train.claim\nX_train = df_train.drop('claim', axis=1)\n\ndf_train[features] = df_train[features].fillna(df_train[features].median())\ndf_test[features] = df_test[features].fillna(df_test[features].median())\n\nscaler = preprocessing.RobustScaler()\ndf_train[features] = scaler.fit_transform(df_train[features])\ndf_test[features] = scaler.transform(df_test[features])","104e47f8":"skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (i_train, i_valid) in enumerate (skf.split(X_train, y_train)):\n    df_train.loc[i_valid, 'kfold'] = fold","526a5296":"# seed = 0\n\n# def objective(trial):\n#     fold = 0\n#     params = {\n#         'num_leaves': trial.suggest_int('num_leaves', 21, 30),\n#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1000, 20000),\n#         'max_depth': trial.suggest_int('max_depth', 0, 0),\n#         'max_bin': trial.suggest_int('max_bin', 200, 400),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.01),\n#         'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.00001, 5),\n#         'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.00001, 1),\n#         'min_gain_to_split': trial.suggest_float('min_gain_to_split', 1, 3),\n#         'feature_fraction': trial.suggest_float('feature_fraction', 0.05, 0.75),\n#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.78, 0.9),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 1)        \n#     }\n\n#     X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n#     X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n        \n#     y_train = X_train.claim\n#     y_valid = X_valid.claim\n    \n#     X_train = X_train[features]\n#     X_valid = X_valid[features]\n    \n#     model = LGBMClassifier(\n#             objective='binary',\n#             tree_learner='serial',\n#             seed=seed,\n#             n_estimators=50000,\n#             **params)\n    \n#     model.fit(X_train,\n#               y_train,\n#               early_stopping_rounds=500,\n#               eval_set=[(X_valid, y_valid)],\n#               eval_metric='auc',\n#               callbacks=[LightGBMPruningCallback(trial, 'auc')],\n#               verbose=1000)\n    \n#     valid_pred = model.predict_proba(X_valid)[:,1]\n        \n#     auc = roc_auc_score(y_valid, valid_pred)\n#     return auc\n\n# for i in range(3):\n#     study = optuna.create_study(direction=\"maximize\")\n#     study.optimize(objective, n_trials=40)","1a6eb7ce":"%%time\n\nm = 7\ns = 26\n\ntest_preds = []\nvalid_preds = {}\nscores = []\n    \nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n\n    params = {'num_leaves': 15,\n              'min_data_in_leaf': 2200,\n              'max_depth': 4,\n              'max_bin': 220,\n              'learning_rate': 0.010799862652877246,\n              'lambda_l1': 1.8358777923407985,\n              'lambda_l2': 0.0003751344396869442,\n              'min_gain_to_split': 2.850800313709466,\n              'feature_fraction': 0.44543603862631437,\n              'bagging_fraction': 0.7701524274455008,\n              'bagging_freq': 1}\n\n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split', #default=split. try gain\n        boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=s,\n        n_estimators=50000,\n        **params)\n\n    model.fit(X_train,\n              y_train,\n              early_stopping_rounds=500,\n              eval_set=[(X_valid, y_valid)],\n              eval_metric='auc',\n              verbose=1000)\n\n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n    \nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\nvalid_preds.columns = ['id', f'm{m}s{s}_pred']\nvalid_preds.to_csv(f'm{m}s{s}_valid_pred.csv', index=False)\n\nsample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\nsample_solution.columns = ['id', f'm{m}s{s}_pred']\nsample_solution.to_csv(f'm{m}s{s}_test_pred.csv', index=False)","357b2723":"# %%time\n\n# m = 7\n# s = 35\n\n# test_preds = []\n# valid_preds = {}\n# scores = []\n    \n# for fold in range(5):\n#     X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n#     X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n#     X_test = df_test[features].copy()\n\n#     valid_ids = X_valid.id.values.tolist()\n\n#     y_train = X_train.claim\n#     y_valid = X_valid.claim\n\n#     X_train = X_train[features]\n#     X_valid = X_valid[features]\n\n#     params = {'num_leaves': 15,\n#               'min_data_in_leaf': 2200,\n#               'max_depth': 4,\n#               'max_bin': 220,\n#               'learning_rate': 0.010799862652877246,\n#               'lambda_l1': 1.8358777923407985,\n#               'lambda_l2': 0.0003751344396869442,\n#               'min_gain_to_split': 2.850800313709466,\n#               'feature_fraction': 0.44543603862631437,\n#               'bagging_fraction': 0.7701524274455008,\n#               'bagging_freq': 1}\n\n#     model = LGBMClassifier(\n#         objective='binary',\n#         importance_type='split', #default=split. try gain\n#         boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n#         tree_learner='serial',\n#         num_threads=-1,\n#         random_state=s,\n#         n_estimators=50000,\n#         **params)\n\n#     model.fit(X_train,\n#               y_train,\n#               early_stopping_rounds=500,\n#               eval_set=[(X_valid, y_valid)],\n#               eval_metric='auc',\n#               verbose=1000)\n\n#     valid_pred = model.predict_proba(X_valid)[:,1]\n#     test_pred = model.predict_proba(X_test)[:,1]\n\n#     valid_preds.update(dict(zip(valid_ids, valid_pred)))\n#     test_preds.append(test_pred)\n    \n#     score = roc_auc_score(y_valid, valid_pred)    \n#     scores.append(score)\n    \n# print(f'Mean auc{np.mean(scores)}, std {np.std(scores)}')\n\n# valid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\n# valid_preds.columns = ['id', f'm{m}s{s}_pred']\n# valid_preds.to_csv(f'm{m}s{s}_valid_pred.csv', index=False)\n\n# sample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\n# sample_solution.columns = ['id', f'm{m}s{s}_pred']\n# sample_solution.to_csv(f'm{m}s{s}_test_pred.csv', index=False)","bfa2a151":"# Creating folds","aafabefb":"# Loading the data","f59c4440":"# Hyperparameter tuning with Optuna","2c27af1e":"# Model training","01911e8f":"# Importing libraries","de090108":"# Preprocessing"}}