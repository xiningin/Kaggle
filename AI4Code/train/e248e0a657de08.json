{"cell_type":{"9b9b90a5":"code","00ec94c6":"code","c564aba5":"code","4a8be172":"code","ecd09eca":"code","92cbcc46":"code","f815d987":"code","1595e53b":"code","41175b7c":"code","fdb2bbff":"code","05f891fd":"code","640ce6e9":"code","c3b4275d":"code","5173149b":"code","e11aa149":"code","39eb81c8":"code","6adc0f02":"code","d2c30f4c":"code","3ccfde0d":"code","889fa847":"code","4f3a0914":"code","2c376be3":"code","cf244625":"code","9e6c4e56":"code","0285612e":"code","4b37e7dc":"code","a40ef8f1":"code","5523fb1d":"code","32aa85d1":"code","3d7d0584":"code","4f0dfd63":"code","b34cec8b":"code","ec9e6a20":"code","51e05482":"code","323f1231":"code","ef7c48ee":"code","64752675":"code","0e3b2ab1":"code","6322f6b2":"code","e0cdc04e":"code","8bd8cfd1":"code","9366e64b":"code","43f2c591":"code","1935d0ed":"code","dedfc5c1":"code","94982354":"code","8662b816":"code","ee3c22ca":"code","3433aa95":"code","4d9c24fb":"code","8c4af025":"code","c226d152":"code","af23f7d4":"code","0073d5f2":"code","73883d11":"code","7dab0637":"code","b055a940":"markdown","dd402695":"markdown","6d27208c":"markdown","20036470":"markdown","ee2a728a":"markdown","d4ab8f07":"markdown","5393b3c8":"markdown","282098a2":"markdown","256b9c4f":"markdown","dd87ecf1":"markdown","b84f8ec4":"markdown","5cdcf4b4":"markdown","ce82459a":"markdown","8ec69505":"markdown","5ad3466c":"markdown","64194cef":"markdown","31a77538":"markdown"},"source":{"9b9b90a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00ec94c6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","c564aba5":"train=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain","4a8be172":"test=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest","ecd09eca":"#let's have information about datasets\ntrain.info()\ntest.info()","92cbcc46":"#Distribution of null values for training data\nprint(train.isnull().sum())\ntrain.isnull().mean()","f815d987":"#Distribution of null values for test data\nprint(test.isnull().sum())\ntest.isnull().mean()","1595e53b":"train.nunique()#@unique values for training data","41175b7c":"test.nunique()#unique values for testing data","fdb2bbff":"train.Sex.value_counts()","05f891fd":"train.groupby(\"Sex\")[\"Survived\"].mean()#it seems gender is going to be  very interesting for our predictions","640ce6e9":"pd.crosstab(train[\"Sex\"],train[\"Survived\"])","c3b4275d":"train.Pclass.value_counts()# the distribution for classes of trip","5173149b":"train.groupby(\"Pclass\")[\"Survived\"].mean()#people in 1st class had more chances to survive","e11aa149":"pd.crosstab(train[\"Pclass\"],train[\"Survived\"])","39eb81c8":"train.SibSp.value_counts()#most of people were alone or withouth siblings or spouses","6adc0f02":"train.groupby(\"SibSp\")[\"Survived\"].mean()#People with 1 or 2 siblings had more chances to survive","d2c30f4c":"pd.crosstab(train[\"SibSp\"],train[\"Survived\"])","3ccfde0d":"train.Parch.value_counts()","889fa847":"pd.crosstab(train[\"Parch\"],train[\"Survived\"])#Similar to Sibsp. We have the maximum of chance to survive for a low value of Parch","4f3a0914":"pd.crosstab(train[\"Parch\"],train[\"Survived\"])","2c376be3":"\ntrain.Embarked.value_counts()","cf244625":"pd.crosstab(train[\"Embarked\"],train[\"Survived\"])#Values for Embarked in Cherbourg seems better. Let's look at the correlation with Pclass","9e6c4e56":"pd.crosstab(train[\"Embarked\"],train[\"Pclass\"])#As we can see the most of Embarked in Cherbourg were in 1st class. They are not equally distributed for this variable","0285612e":"train.groupby(\"Embarked\")[\"Survived\"].mean()","4b37e7dc":"train.describe()#Some variable are more skewed, like Fare","a40ef8f1":"test.describe()","5523fb1d":"train.corr()# Pclass(negatively) and Fare(positively) seems the more correlated with Age. Sibsp and Parch are correlated as well","32aa85d1":"import seaborn as sns\nplt.figure(figsize=(8,6))\nsns.heatmap(train.corr())# we can see it better with the heatmap","3d7d0584":"sns.pairplot(train)#let's take a look at the distributions. Many variables looks like categorical even they are numeric\nplt.show()","4f0dfd63":"train_b=train.copy()\ntrain_b","b34cec8b":"train[\"log_Fare\"]=np.log1p(train[\"Fare\"])\ntrain.head()","ec9e6a20":"test[\"log_Fare\"]=np.log1p(test[\"Fare\"])\ntest.head()","51e05482":"train.skew()#As we can see the skewness is reduced with the new variable","323f1231":"data = [train, test]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n    dataset['not_alone'] = dataset['not_alone'].astype(int)\ntrain['not_alone'].value_counts()","ef7c48ee":"test[\"not_alone\"].value_counts()","64752675":"train.Cabin=train.Cabin.fillna(\"Missing\")#We operate on Cabin variable to deal with missings. \ntrain.Cabin","0e3b2ab1":"test.Cabin=test.Cabin.fillna(\"Missing\")\ntest.Cabin","6322f6b2":"#i create a function for finding the first letter of the cabin\ndef desk (string):\n    prima=string[0]\n    return prima","e0cdc04e":"train[\"deck\"]=train[\"Cabin\"].apply(desk)\ntrain","8bd8cfd1":"test[\"deck\"]=test[\"Cabin\"].apply(desk)\ntest","9366e64b":"pd.crosstab(train[\"deck\"],train[\"Survived\"])#We can clearly see that who doesn't have a deck had less chances to survive. We can modify Deck in a binary variable ","43f2c591":"train.groupby(\"deck\")[\"Survived\"].mean()","1935d0ed":"def ponte (string):\n    if string==\"M\":\n        return 0\n    else:\n        return 1\n    \ntrain[\"Ponte\"]=train.deck.apply(ponte)\ntrain.Ponte","dedfc5c1":"test[\"Ponte\"]=test.deck.apply(ponte)\ntest.Ponte","94982354":"pd.crosstab(train.Ponte,train.Survived)#We can see the influence of this variable","8662b816":"train.info()#We have now more variable ... we have to cut some of them to make a good choice for the model(\"Occam's Razor\"). Except for Deck they are all numeric","ee3c22ca":"train.corr#Finally we can see that the new variables are correlated with \"Survived\" we can take them and delete other original variables","3433aa95":"train.isnull().mean()# We will impute the median for  Age because is more robust to outliers.. and we will impute the mode for Embarked","4d9c24fb":"test.isnull().mean()# like below we will impute the median for age and for the few missings for log_Fare( Fare doesn't interest us we will exclude it)","8c4af025":"train[\"Age\"]=train[\"Age\"].fillna(train[\"Age\"].median())#Imputation for Age in the train set\ntrain.isnull().mean()","c226d152":"train[\"Embarked\"]=train[\"Embarked\"].fillna(\"S\") # Southampton is the mode for the distribution \ntrain.isnull().mean()","af23f7d4":"test[\"Age\"]=test[\"Age\"].fillna(test[\"Age\"].median()) # imputation for the median of Age in test set \ntest.isnull().mean()","0073d5f2":"test[\"log_Fare\"]=test[\"log_Fare\"].fillna(test[\"log_Fare\"].median()) # Imputation for log_Fare in test set\ntest.isnull().mean()","73883d11":"from sklearn.ensemble import RandomForestClassifier\n\ny = train[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\",\"log_Fare\", \"Age\",\"Embarked\",\"Ponte\",'relatives','not_alone']\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","7dab0637":"test","b055a940":"Reading the data","dd402695":"Log Fare\nWe prefer to use the logarithm of Fare because of the high skewness","6d27208c":"The aim of this work is to involve as lot as possible of people in a space to talk about modelling and predictions with  the kaggle competitions. I think that exchange of ideas can improve us in our process of learning and growth as data scientist so feel free to comment if you find some insights in this notebook.\nIn the first part i'll explain  who i proceeded to got a score of almost 80% that could be used as a baseline.\nYou can use my notebook as inspiration and in the same time suggest me some modification.\nOne ","20036470":"Pclass","ee2a728a":"Deck\n\nDistinguishes who has the Deck from others","d4ab8f07":"Before to proceed... we have still to manage some missing values","5393b3c8":"Quantitative Variable","282098a2":"Ponte\n\nBinary variable who distinguish who was withouth deck","256b9c4f":"Creation of new Variables","dd87ecf1":"Not Alone.\n\nA Variable who distinguuishes who is alone from others","b84f8ec4":"Parch","5cdcf4b4":"Age","ce82459a":"Analizing Categorical data","8ec69505":"SibSp","5ad3466c":"Embarked","64194cef":"Relatives.\n\nWe count the number of people nearest to the passenger ( Sibsp + Parch)","31a77538":"EDA"}}