{"cell_type":{"66d61238":"code","4b990100":"code","1a385a28":"code","cb453597":"code","2e8139c2":"code","2926807c":"code","aa3f3ce5":"code","f24e63e1":"code","390d469b":"code","88759a8a":"code","2927b724":"code","15efa449":"markdown","9cffb139":"markdown","20865302":"markdown","5df0ddec":"markdown","d7050aa2":"markdown","549cad72":"markdown","20d24b64":"markdown","60248195":"markdown","c4bf5693":"markdown"},"source":{"66d61238":"#Load data\nimport pandas as pd\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\n#Drop features we are not going to use\ntrain = train.drop(['Name','SibSp','Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],axis=1)\ntest = test.drop(['Name','SibSp','Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],axis=1)\n\n#Look at the first 3 rows of our training data\ntrain.head(3)","4b990100":"#Convert ['male','female'] to [1,0] so that our decision tree can be built\nfor df in [train,test]:\n    df['Sex_binary']=df['Sex'].map({'male':1,'female':0})\n    \n#Fill in missing age values with 0 (presuming they are a baby if they do not have a listed age)\ntrain['Age'] = train['Age'].fillna(0)\ntest['Age'] = test['Age'].fillna(0)\n\n#Select feature column names and target variable we are going to use for training\nfeatures = ['Pclass','Age','Sex_binary']\ntarget = 'Survived'\n\n#Look at the first 3 rows (we have over 800 total rows) of our training data.; \n#This is input which our classifier will use as an input.\ntrain[features].head(3)","1a385a28":"#Display first 3 target variables\ntrain[target].head(3).values","cb453597":"from sklearn.tree import DecisionTreeClassifier\n\n#Create classifier object with default hyperparameters\nclf = DecisionTreeClassifier(max_depth=3,min_samples_leaf=2)  \n\n#Fit our classifier using the training features and the training target values\nclf.fit(train[features],train[target]) ","2e8139c2":"#Create decision tree \".dot\" file\n\n#Remove each '#' below to uncomment the two lines and export the file.\n#from sklearn.tree import export_graphviz\n#export_graphviz(clf,out_file='titanic_tree.dot',feature_names=features,rounded=True,filled=True,class_names=['Survived','Did not Survive'])","2926807c":"#Display decision tree\n\n#Blue on a node or leaf means the tree thinks the person did not survive\n#Orange on a node or leaf means that tree thinks that the person did survive\n\n#In Chrome, to zoom in press control +. To zoom out, press control -. If you are on a Mac, use Command.\n\n#Remove each '#' below to run the two lines below.\n#from IPython.core.display import Image, display\n#display(Image('titanic_tree.png', width=1900, unconfined=True))","aa3f3ce5":"#Make predictions using the features from the test data set\npredictions = clf.predict(test[features])\n\n#Display our predictions - they are either 0 or 1 for each training instance \n#depending on whether our algorithm believes the person survived or not.\npredictions","f24e63e1":"X_train = train[features]\nY_train = train[target]\nX_test = test[features]\nX_train\n","390d469b":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)","88759a8a":"#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\nsubmission = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':predictions})\n\n#Visualize the first 5 rows\nsubmission.head()","2927b724":"#Convert DataFrame to a csv file that can be uploaded\n#This is saved in the same directory as your notebook\nfilename = 'Titanic_Predictions_1.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","15efa449":"# 4. Create csv to upload to Kaggle","9cffb139":"# 3. Make Predictions","20865302":"Let's look at the first 3 corresponding target variables. This is the measure of whether the passenger survived or not (i.e. the first passenger (22 year-old male) did not survive, but the second passenger (38 year-old female did survive).\n<br><br>\nOur classifier will use this to know what the output should be for each of the training instances.","5df0ddec":"### Visualize default tree (optional)\nThis is not a necessary step, but it shows you how complex the tree is when you don't restrict it. To complete this visualization section you must be going through the code on your computer.","d7050aa2":"# 2. Create and fit the decision tree\n\nThis tree is definitely going to overfit our data. When you get to the challenge stage, you can return here and tune hyperparameters in this cell. For example, you could reduce the maximum depth of the tree to 3 by setting max_depth=3 with the following command:\n>clf = DecisionTreeClassifier(max_depth=3)\n\nTo change multiple hyperparameters, seperate out the parameters with a comma. For example, to change the learning rate and minimum samples per leaf and the maximum depth fill in the parentheses with the following:\n>clf = DecisionTreeClassifier(max_depth=3,min_samples_leaf=2)\n\nThe other parameters are listed below.\nYou can also access the list of parameters by reading the [documentation](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) for decision tree classifiers. Another way to access the parameters is to place your cursor in between the parentheses and then press shift-tab.\n","549cad72":"### Prepare the data to be read by our algorithm","20d24b64":"## 1. Process the data\n\n### Load data","60248195":"Note, if you want to generate a new tree png, you need to open terminal (or command prompt) after running the cell above. Navigate to the directory where you have this notebook and the type the following command.\n>dot -Tpng titanic_tree.dot -o titanic_tree.png<br><br>","c4bf5693":"Our data has the following columns:\n- PassengerId - Each passenger's id\n- Survived - Whether the passenger survived or not (1 - yes, 0 - no)\n- Pclass - The passenger class: (1st class - 1, 2nd class - 2, third class - 3)\n- Sex - Each passenger's sex\n- Age - Each passenger's age"}}