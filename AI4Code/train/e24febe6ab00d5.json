{"cell_type":{"ca962f53":"code","cab58cb1":"code","aecc715a":"code","f9a2f740":"code","8aec03b4":"code","7a561525":"code","bcabadd0":"code","74b28190":"code","bd412820":"code","82bc832d":"code","3546677a":"code","56ef69ab":"code","917b9190":"code","8229b983":"code","1cb874a0":"code","afc46fee":"code","73996ad7":"code","6d5844fc":"code","033e400e":"code","f9700521":"code","16b5c04c":"code","f8855354":"code","5cc7ab53":"code","0219528a":"code","94c43e9b":"code","a3631859":"code","706f6f99":"markdown","ddc0714e":"markdown","d9bdd68d":"markdown","3a60d528":"markdown","22b53235":"markdown","3665abda":"markdown","d9dfb29b":"markdown","1c9e8165":"markdown","a33cc81b":"markdown","ad4b6d7b":"markdown"},"source":{"ca962f53":"import pandas as pd\nimport numpy as np","cab58cb1":"import scipy\nimport scipy.io\nimport cv2\n\nfrom matplotlib import pyplot as plt\n\nfrom scipy.ndimage import gaussian_filter\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom PIL import Image\n\nfrom pytorch_lightning import LightningModule, Trainer\nfrom pytorch_lightning import seed_everything\n\nimport os","aecc715a":"def show(im):\n    plt.figure(figsize=(10, 10))\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))","f9a2f740":"im = cv2.imread('..\/input\/shanghaitech\/ShanghaiTech\/part_B\/train_data\/images\/IMG_1.jpg', cv2.IMREAD_COLOR)\nshow(im)","8aec03b4":"m = scipy.io.loadmat('..\/input\/shanghaitech\/ShanghaiTech\/part_B\/train_data\/ground-truth\/GT_IMG_1.mat')\nps = m['image_info'][0][0][0][0][0]\n\nfor x, y in ps:\n    x = int(x)\n    y = int(y)\n    cv2.drawMarker(im, (x, y), (0, 255, 0))\n    \nshow(im)","7a561525":"from sklearn.model_selection import train_test_split\n\ntrain = [p.path for p in os.scandir('..\/input\/shanghaitech\/ShanghaiTech\/part_B\/train_data\/images\/')]\nvalid_full = [p.path for p in os.scandir('..\/input\/shanghaitech\/ShanghaiTech\/part_B\/test_data\/images\/')]\n\n## use a small subset for validation\n_, valid = train_test_split(valid_full, test_size=64, random_state=42)\n\nlen(train), len(valid)","bcabadd0":"from torchvision import transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","74b28190":"im_size = 512\naug_train = A.Compose([\n    A.RandomCrop(im_size, im_size),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(),\n    A.Normalize((0.5), (0.5)),\n], keypoint_params=A.KeypointParams(format='xy', angle_in_degrees=False))\n\naug_val = A.Compose([\n    A.Resize(768, 1024),\n    A.Normalize((0.5), (0.5)),\n], keypoint_params=A.KeypointParams(format='xy', angle_in_degrees=False))\n\nclass MyDataset(Dataset):\n    def __init__(self, files, aug):\n        self.files = files\n        self.aug = aug\n        \n    def __len__(self):\n        return len(self.files)\n    \n    def __getitem__(self, idx):\n        fn = self.files[idx]\n        \n        im = cv2.imread(fn, cv2.IMREAD_COLOR)\n        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n        \n        m = scipy.io.loadmat(fn.replace('images', 'ground-truth').replace('IMG', 'GT_IMG').replace('.jpg', '.mat'))\n        ps = m['image_info'][0][0][0][0][0]\n        \n        rst = self.aug(image=im, keypoints=ps)\n        im = rst['image']\n        ps = rst['keypoints']\n        \n        dm = np.zeros((im.shape[0], im.shape[1]), dtype=np.float32)\n        for x, y in ps:\n            x = int(x)\n            y = int(y)\n            dm[y, x] = 1\n\n        sigma = 4\n        dm = gaussian_filter(dm, sigma=sigma, truncate=4*sigma)\n        \n        dm = cv2.resize(dm, (im.shape[1] \/\/ 4, im.shape[0] \/\/ 4), interpolation=cv2.INTER_LINEAR)\n        dm *= 16\n        \n        im = torch.from_numpy(im)\n        dm = torch.from_numpy(dm)\n        \n        return im, dm","bd412820":"ds = MyDataset(train, aug_train)\nim, dm = ds[0]\nplt.imshow(im, cmap='gray')","82bc832d":"plt.imshow(dm)","3546677a":"ds = MyDataset(valid, aug_val)\nim, dm = ds[0]\nplt.imshow(im, cmap='gray')","56ef69ab":"plt.imshow(dm)","917b9190":"dm.sum()","8229b983":"class Conv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, relu=True, same_padding=False, bn=False):\n        super(Conv2d, self).__init__()\n        padding = int((kernel_size - 1) \/ 2) if same_padding else 0\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else None\n        self.relu = nn.ReLU(inplace=True) if relu else None\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.bn is not None:\n            x = self.bn(x)\n        if self.relu is not None:\n            x = self.relu(x)\n        return x\n","1cb874a0":"class MCNN(LightningModule):\n    '''\n    Multi-column CNN \n        -Implementation of Single Image Crowd Counting via Multi-column CNN (Zhang et al.)\n    '''\n    \n    def __init__(self, lr, batch_size, max_steps, bn=False):\n        super(MCNN, self).__init__()\n        \n        self.lr = lr\n        self.save_hyperparameters()\n        \n        self.use = 0\n        \n        self.branch1 = nn.Sequential(Conv2d( 1, 16, 9, same_padding=True, bn=bn),\n                                     nn.MaxPool2d(2),\n                                     Conv2d(16, 32, 7, same_padding=True, bn=bn),\n                                     nn.MaxPool2d(2),\n                                     Conv2d(32, 16, 7, same_padding=True, bn=bn),\n                                     Conv2d(16,  8, 7, same_padding=True, bn=bn))\n        \n        self.branch2 = nn.Sequential(Conv2d( 1, 20, 7, same_padding=True, bn=bn),\n                                     nn.MaxPool2d(2),\n                                     Conv2d(20, 40, 5, same_padding=True, bn=bn),\n                                     nn.MaxPool2d(2),\n                                     Conv2d(40, 20, 5, same_padding=True, bn=bn),\n                                     Conv2d(20, 10, 5, same_padding=True, bn=bn))\n        \n        self.branch3 = nn.Sequential(Conv2d( 1, 24, 5, same_padding=True, bn=bn),\n                                     nn.MaxPool2d(2),\n                                     Conv2d(24, 48, 3, same_padding=True, bn=bn),\n                                     nn.MaxPool2d(2),\n                                     Conv2d(48, 24, 3, same_padding=True, bn=bn),\n                                     Conv2d(24, 12, 3, same_padding=True, bn=bn))\n        \n        self.fuse = nn.Sequential(Conv2d( 30, 1, 1, same_padding=True, bn=bn))\n        \n        self.out1 = nn.Sequential(Conv2d( 8, 1, 1, same_padding=True, bn=bn))\n        self.out2 = nn.Sequential(Conv2d( 10, 1, 1, same_padding=True, bn=bn))\n        self.out3 = nn.Sequential(Conv2d( 12, 1, 1, same_padding=True, bn=bn))\n        \n        self.crit = nn.MSELoss()\n        \n    def forward(self, im_data):\n        im_data = im_data.unsqueeze(1)\n        x1 = self.branch1(im_data)\n        x2 = self.branch2(im_data)\n        x3 = self.branch3(im_data)\n        \n        \n        if self.use == 0:\n            x = torch.cat((x1,x2,x3),1)\n            x = self.fuse(x)\n        elif self.use == 1:\n            x = self.out1(x1)\n        elif self.use == 2:\n            x = self.out2(x2)\n        elif self.use == 3:\n            x = self.out3(x3)\n        \n        return x.squeeze(1)\n    \n    \n    def training_step(self, batch, batch_idx):\n        self.train()\n        x, y = batch\n        \n        pred = self(x)\n        loss = self.crit(pred, y)\n        \n        pred_sum = torch.round(pred.sum(dim=(1,2))).int()\n        gt_sum = torch.round(y.sum(dim=(1,2))).int()\n        acc = (pred_sum == gt_sum).float().mean()\n        \n        mae = torch.abs(pred_sum - gt_sum).float().mean()\n        \n        self.log('train_loss', loss)\n        self.log('train_acc', acc)\n        self.log('train_mae', mae)\n        \n        return loss\n        \n    def validation_step(self, batch, batch_idx):\n        with torch.no_grad():\n            self.eval()\n            x, y = batch\n            \n            pred = self(x)\n            loss = self.crit(pred, y)\n        \n            pred_sum = torch.round(pred.sum(dim=(1,2))).int()\n            gt_sum = torch.round(y.sum(dim=(1,2))).int()\n            acc = (pred_sum == gt_sum).float().mean()\n\n            mae = torch.abs(pred_sum - gt_sum).float().mean()\n            \n            self.log('val_loss', loss)\n            self.log('val_acc', acc)\n            self.log('val_mae', mae)\n            \n            \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=1e-4)\n        \n        scheduler = {\n            'scheduler': torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=self.lr, total_steps=self.hparams.max_steps, pct_start=0.1, cycle_momentum=False),\n            'interval': 'step',\n            'frequency': 1\n        }\n        \n        return [optimizer], [scheduler]","afc46fee":"def weights_normal_init(model, dev=0.01):\n    if isinstance(model, list):\n        for m in model:\n            weights_normal_init(m, dev)\n    else:\n        for n, m in model.named_modules():\n            if isinstance(m, nn.Conv2d):\n                m.weight.data.normal_(0.0, dev)\n                if m.bias is not None:\n                    m.bias.data.fill_(0.0)\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0.0, dev)","73996ad7":"batch_size = 32\nepochs = 300\nmax_steps = epochs * len(train) \/\/ batch_size","6d5844fc":"train_loader = DataLoader(MyDataset(train, aug_train), batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\nval_loader = DataLoader(MyDataset(valid, aug_val), batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=4)","033e400e":"from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\nseed_everything(42)\n\ncheckpoint_cb = ModelCheckpoint(\n    save_top_k=1,\n    save_last=True,\n    verbose=True,\n    monitor='val_mae',\n    mode='min',\n    prefix=''\n)\n\ntrainer = Trainer(gpus=1, max_steps=max_steps, precision=16, benchmark=True, callbacks=[checkpoint_cb, LearningRateMonitor()])\n\nlr = 3e-4\n\nmodel = MCNN(lr, batch_size, max_steps)\nweights_normal_init(model, dev=0.01)\n\nmodel.use = 0\n\ntrainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)","f9700521":"# from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n# seed_everything(42)\n\n# checkpoint_cb = ModelCheckpoint(\n#     save_top_k=1,\n#     save_last=True,\n#     verbose=True,\n#     monitor='val_mae',\n#     mode='min',\n#     prefix=''\n# )\n\n# trainer = Trainer(gpus=1, max_steps=max_steps, precision=32, callbacks=[checkpoint_cb, LearningRateMonitor()])\n\n# lr = 3e-4\n\n# model = MCNN(lr, batch_size, max_steps)\n# weights_normal_init(model, dev=0.01)\n\n# model.use = 1\n\n# trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)","16b5c04c":"# checkpoint_cb = ModelCheckpoint(\n#     save_top_k=1,\n#     save_last=True,\n#     verbose=True,\n#     monitor='val_mae',\n#     mode='min',\n#     prefix=''\n# )\n\n# trainer = Trainer(gpus=1, max_steps=max_steps, precision=32, callbacks=[checkpoint_cb, LearningRateMonitor()])\n\n# model.use = 2\n\n# trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)","f8855354":"# checkpoint_cb = ModelCheckpoint(\n#     save_top_k=1,\n#     save_last=True,\n#     verbose=True,\n#     monitor='val_mae',\n#     mode='min',\n#     prefix=''\n# )\n\n# trainer = Trainer(gpus=1, max_steps=max_steps, precision=32, callbacks=[checkpoint_cb, LearningRateMonitor()])\n\n# model.use = 3\n\n# trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)","5cc7ab53":"# checkpoint_cb = ModelCheckpoint(\n#     save_top_k=1,\n#     save_last=True,\n#     verbose=True,\n#     monitor='val_mae',\n#     mode='min',\n#     prefix=''\n# )\n\n# trainer = Trainer(gpus=1, max_steps=max_steps, precision=32, callbacks=[checkpoint_cb, LearningRateMonitor()])\n\n# model.use = 0\n\n# trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)","0219528a":"ds = MyDataset(valid, aug_val)\nd = ds[0][0]\nplt.imshow(d, cmap='gray')","94c43e9b":"plt.imshow(model(d.unsqueeze(0)).detach()[0])","a3631859":"model(d.unsqueeze(0)).detach()[0].sum()","706f6f99":"## Imports","ddc0714e":"## Building Model","d9bdd68d":"## Visualize the result\nWe can see that the recognition results highlight the human body","3a60d528":"## Separate column training","22b53235":"## Prepare dataset","3665abda":"## Training","d9dfb29b":"## visualize","1c9e8165":"# An unoffical demo for training MCNN on Shanghai tech dataset (Part-B)","a33cc81b":"### weight init is crucial for the model to converge","ad4b6d7b":"### training"}}