{"cell_type":{"a5687435":"code","0b3df786":"code","1d4f22f9":"code","e9165159":"code","dbd2c70d":"code","17434d30":"code","b3d36749":"code","f981ff55":"code","555d5f0e":"code","4d1340d6":"code","b116c399":"code","de76f1e6":"code","b865f90a":"code","80b5aa7f":"code","6262578e":"code","8d4b9850":"code","fa54ada2":"code","ee561f64":"code","73ad1910":"code","66745b5c":"code","8984cb30":"code","57aa386d":"code","18de2d4b":"code","db09bf80":"code","9a32b573":"code","6aabf69a":"code","77971dbb":"code","694d9493":"code","43788b26":"code","e946fd04":"code","55b99383":"code","a2e564f7":"markdown","f57003cc":"markdown","a7f1a1d3":"markdown","71890cd6":"markdown","a15e25d7":"markdown","1dabbdc0":"markdown","17df1919":"markdown","e70d97ee":"markdown","0e16ce57":"markdown","2d81c9d7":"markdown","0da64335":"markdown","9ebdc754":"markdown","f88b982b":"markdown","880bc046":"markdown"},"source":{"a5687435":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n%matplotlib inline \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\npd.set_option('display.width', 200)\npd.set_option('display.max_columns', None)\npd.options.display.float_format = '{:11,.2f}'.format","0b3df786":"df_train = pd.read_csv('..\/input\/titanic\/train.csv',index_col=0)\ndf_train.head(2)","1d4f22f9":"df_test = pd.read_csv('..\/input\/titanic\/test.csv',index_col=0)\ndf_test.head(2)","e9165159":"df_combined = pd.concat([df_train,df_test])","dbd2c70d":"df_combined.info()","17434d30":"title = df_combined.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ntitle.value_counts()","b3d36749":"title_dict = {'Mr':'Mr',  'Mrs':'Mrs',  'Miss':'Miss',  'Master':'Master',  'Don':'Mr',  'Rev':'Mr',  'Dr':'Mr','Mme':'Mrs', 'Ms':'Miss', \n              'Major':'Mr', 'Lady':'Mrs', 'Sir':'Mr', 'Mlle':'Miss', 'Col':'Mr', 'Capt':'Mr', 'the Countess':'Mrs', 'Jonkheer':'Mr', 'Dona':'Mrs'}\ndf_combined['Title'] = title.map(title_dict)","f981ff55":"df_combined.groupby(['Title','Pclass'])['Age'].mean()","555d5f0e":"df_combined['Age'] = df_combined['Age'].fillna(df_combined.groupby(['Title', 'Pclass'])['Age'].transform('mean'))","4d1340d6":"print(df_combined['Embarked'].value_counts())\ndf_combined.Embarked.fillna(value='S',inplace=True) # replace by 'S' since it is the most frequent","b116c399":"sns.kdeplot(df_combined.loc[(df_combined['Pclass']==1), 'Age'], color='r', shade=True, Label='Class=1')  \nsns.kdeplot(df_combined.loc[(df_combined['Pclass']==2), 'Age'], color='b', shade=True, Label='Class=2') \nsns.kdeplot(df_combined.loc[(df_combined['Pclass']==3), 'Age'], color='g', shade=True, Label='Class=3') \nplt.xlabel('Age');\nplt.ylabel('Probability Density');","de76f1e6":"plt.hist(df_combined['Age'], color = 'blue', edgecolor = 'black', bins = int(20));","b865f90a":"df_combined['age_group'] = pd.cut(df_combined['Age'], bins=[i for i in range(0,81,5)], right=False) #,labels=[i for i in range(1,81,5)])\ndf_combined[df_combined['Sex']=='male'].groupby('age_group').agg({'Survived': ['count', 'sum', 'mean']}).head(5)","80b5aa7f":"df_combined['is_child'] = np.where(df_combined['Age'] < 10, 1, 0)","6262578e":"df_combined['family_size'] = df_combined.SibSp + df_combined.Parch\ndf_combined[df_combined['Sex']=='male'].groupby('family_size').agg({'Survived': ['count', 'sum', 'mean']})","8d4b9850":"df_combined.describe(include='all')","fa54ada2":"df_combined.drop(columns=['Name', 'SibSp', 'Parch', 'Ticket', 'Fare','Cabin', 'Title', 'Age', 'age_group'],inplace=True)\n","ee561f64":"df_combined.head()","73ad1910":"combined = pd.get_dummies(df_combined, columns=['Pclass','Sex', 'Embarked', 'family_size'], drop_first=True)","66745b5c":"combined.head()","8984cb30":"train = combined[:df_train.shape[0]].copy()\ntest = combined[df_train.shape[0]:].copy()\ntest.drop('Survived',axis=1,inplace=True)","57aa386d":"def split_data(df_train):\n  _df_train, df_valid = train_test_split(df_train, test_size=0.6, random_state=12345)\n  features_train = _df_train.drop(['Survived'], axis=1)\n  target_train = _df_train['Survived']\n  features_valid = df_valid.drop(['Survived'], axis=1)\n  target_valid = df_valid['Survived']\n  return features_train, target_train, features_valid, target_valid","18de2d4b":"features_train, target_train, features_valid, target_valid = split_data(train)","db09bf80":"features_train.describe(include='all')","9a32b573":"model = LogisticRegression(random_state=12345, class_weight=None)\nmodel.fit(features_train, target_train)\npredictions_valid = model.predict(features_valid)\nprint(\"LogisticRegression:\", accuracy_score(target_valid, predictions_valid))","6aabf69a":"def learning_curve(train, valid, steps, target):\n    plt.figure(figsize=(9, 9))\n    targets = [target]* len(train)\n    plt.plot(steps, train, 'o-', color=\"r\", label=\"Training\")\n    plt.plot(steps, valid, 'o-', color=\"b\", label=\"Validation\")\n    plt.plot(steps, targets,'-', color=\"g\", label=\"Target\")\n    plt.ylabel('Score') \n    plt.title('Learning Curve')\n    plt.legend()\n    plt.show()","77971dbb":"score_train = []\nscore_valid = []\nsteps = []\nfor depth in range(2,20):\n    model = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced')\n    model.fit(features_train, target_train)\n    steps.append(depth)\n    score_train.append(accuracy_score(target_train, model.predict(features_train)))\n    score_valid.append(accuracy_score(target_valid, model.predict(features_valid)))\nlearning_curve(score_train, score_valid, steps, 0.59)","694d9493":"score_train = []\nscore_valid = []\nsteps = []\nfor depth in range(2,10):\n    model = RandomForestClassifier(random_state=12345, max_depth=depth, class_weight='balanced')\n    model.fit(features_train, target_train)\n    steps.append(depth)\n    score_train.append(accuracy_score(target_train, model.predict(features_train)))\n    score_valid.append(accuracy_score(target_valid, model.predict(features_valid)))\n\nlearning_curve(score_train, score_valid, steps, 0.59)","43788b26":"model = RandomForestClassifier(random_state=12345, max_depth=5, class_weight='balanced')\nmodel.fit(features_train, target_train)\nprint(\n    accuracy_score(target_train, model.predict(features_train)),\n    accuracy_score(target_valid, model.predict(features_valid)),\n    )","e946fd04":"predicted_test = model.predict(test)\npredicted_test = predicted_test.astype(int)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test.index,\n        \"Survived\": predicted_test\n    })\n\nsubmission.to_csv(\"titanic_submission.csv\", index=False)","55b99383":"!ls","a2e564f7":"The above is the winner model - lets use it for prection on the test set","f57003cc":"<a href=\"https:\/\/colab.research.google.com\/github\/dnevo\/Titanic\/blob\/master\/Titanic.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","a7f1a1d3":"encode `Sex` to `is_male`\nencode `Pclass`\nencode embarked","71890cd6":"# Regression Models (using One Hot Encoding)","a15e25d7":"As above, 4 titles are the most frequent ones - we will later convert the other titles to these 4. Mr: adult male, Miss: young female, Mrs: adult female, Master: child male","1dabbdc0":"As above, there are few columns with missing values:\n- `Age`: 263 missing values. Must be handled as it may have big impact on survival\n- `Fare`: 1 missing value\n- `Cabin`: mostly missing values - we will drop it.\n- `Embarked`: 2 missing values","17df1919":"### Decompose into Test and Train","e70d97ee":"### Combine Test and Validation for easier pre-processing","0e16ce57":"Handling missing values in `Embarked`:","2d81c9d7":"Handling missing values in `Age`. As can be noticed, `Age` has correlation to `Pclass` (higher ages in Pclass=1), and to `title` (Mrs > Mr > Miss > Master)","0da64335":"Following above, create new `is_child` feature, since survival rate below 10 is higher.","9ebdc754":"#### Extract the title from the `Name` column - this is the part which can have meaning","f88b982b":"Train set split\ntest model LR\ncheck metrics - train, valid and test\nrepeat for decision - including validation curve\nrepeat for random forest - including validation curve","880bc046":"create `family_size` - as can be seen, high correlation to survival rate:"}}