{"cell_type":{"cab5277d":"code","c5a82f49":"code","86815cab":"code","0483dad0":"code","dcd2ce2d":"code","75ac07e0":"code","25a147f8":"code","06bb8f82":"code","0f8a84cf":"code","893f027e":"code","2ccde140":"code","0d02e653":"code","7ace7492":"code","3b954bf1":"code","7595a341":"code","45d70f79":"code","ec73844d":"code","203344ff":"code","86373276":"code","1846d040":"code","2c14a979":"code","5ad103e0":"code","94e4b6a4":"code","214d4b5b":"code","b9c8617a":"code","52554539":"code","72df6e39":"code","0862d36f":"code","c6abfaae":"code","4e4044c3":"code","5f71ad16":"markdown","07cb027f":"markdown","013f5e76":"markdown","e2334861":"markdown","ba8fff18":"markdown","cd7a9c5c":"markdown","dc845d92":"markdown","ec979f2b":"markdown","e352aa57":"markdown","b0cc34f4":"markdown","3397d4ca":"markdown"},"source":{"cab5277d":"import pandas as pd\nimport numpy as np\n#from catboost import CatBoostClassifier\n#from sklearn.model_selection import StratifiedKFold,KFold,GroupKFold\n#from sklearn.metrics import accuracy_score\n\n#Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\n\n#For Missing Value and Feature Engineering\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif, VarianceThreshold\nfrom sklearn.impute import SimpleImputer, KNNImputer, MissingIndicator\nfrom sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n\nimport time\n","c5a82f49":"train = pd.read_csv(\"..\/input\/DontGetKicked\/training.csv\")\ntest = pd.read_csv(\"..\/input\/DontGetKicked\/test.csv\")","86815cab":"train.head()","0483dad0":"#insert code","dcd2ce2d":"# Date\n#PurchDate","75ac07e0":"train['mean_MMRAcquisitionAuctionAveragePrice_Make']=train.groupby(['Make'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_Model']=train.groupby(['Model'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_Trim']=train.groupby(['Trim'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_SubModel']=train.groupby(['SubModel'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_Color']=train.groupby(['Color'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntrain['mean_MMRAcquisitionAuctionAveragePrice_Transmission']=train.groupby(['Transmission'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')","25a147f8":"test['mean_MMRAcquisitionAuctionAveragePrice_Make']=test.groupby(['Make'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_Model']=test.groupby(['Model'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_Trim']=test.groupby(['Trim'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_SubModel']=test.groupby(['SubModel'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_Color']=test.groupby(['Color'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')\ntest['mean_MMRAcquisitionAuctionAveragePrice_Transmission']=test.groupby(['Transmission'])['MMRAcquisitionAuctionAveragePrice'].transform('mean')","06bb8f82":"#create X and y datasets for splitting \nX = train.drop(['RefId', 'IsBadBuy'], axis=1)\ny = train['IsBadBuy']","0f8a84cf":"all_features = X.columns","893f027e":"all_features = all_features.tolist()","2ccde140":"numerical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind in ['i','f'] and c !='PassengerId']\ncategorical_features = [c for c, dtype in zip(X.columns, X.dtypes)\n                     if dtype.kind not in ['i','f']]","0d02e653":"numerical_features","7ace7492":"categorical_features","3b954bf1":"#import train_test_split library\nfrom sklearn.model_selection import train_test_split\n\n# create train test split\nX_train, X_test, y_train, y_test = train_test_split( X,  y, test_size=0.3, random_state=0)  ","7595a341":"preprocessor = make_column_transformer(\n    \n    (make_pipeline(\n    #SimpleImputer(strategy = 'median'),\n    KNNImputer(n_neighbors=2, weights=\"uniform\"),\n    MinMaxScaler()), numerical_features),\n    \n    (make_pipeline(\n    SimpleImputer(strategy = 'constant', fill_value = 'missing'),\n    OneHotEncoder(categories = 'auto', handle_unknown = 'ignore')), categorical_features),\n    \n)","45d70f79":"preprocessor_best = make_pipeline(preprocessor, \n                                  VarianceThreshold(), \n                                  SelectKBest(f_classif, k = 50)\n                                 )","ec73844d":"RF_Model = make_pipeline(preprocessor_best, RandomForestClassifier(n_estimators = 100))","203344ff":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 50)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n#Maximum number of levels in tree\nmax_depth = [2,4,6,8]\n# Minimum number of samples required to split a node\n#min_samples_split = [2, 5]\n# Minimum number of samples required at each leaf node\n#min_samples_leaf = [1, 2]\n# Method of selecting samples for training each tree\n#bootstrap = [True, False]","86373276":"# Create the param grid\nparam_grid = {'randomforestclassifier__n_estimators': n_estimators,\n               'randomforestclassifier__max_features': max_features,\n               'randomforestclassifier__max_depth': max_depth\n               #'randomforestclassifier__min_samples_split': min_samples_split,\n               #'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n               #'randomforestclassifier__bootstrap': bootstrap\n             }\nprint(param_grid)","1846d040":"from sklearn.model_selection import RandomizedSearchCV\nrf_RandomGrid = RandomizedSearchCV(estimator = RF_Model, param_distributions = param_grid, cv = 3, verbose=1, n_jobs = -1, n_iter = 5, scoring = 'f1')","2c14a979":"rf_RandomGrid.fit(X_train, y_train)","5ad103e0":"rf_RandomGrid.best_estimator_","94e4b6a4":"print(f'Train : {rf_RandomGrid.score(X_train, y_train):.3f}')\nprint(f'Test : {rf_RandomGrid.score(X_test, y_test):.3f}')","214d4b5b":"def gini(actual, pred):\n    assert (len(actual) == len(pred))\n    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n    totalLosses = all[:, 0].sum()\n    giniSum = all[:, 0].cumsum().sum() \/ totalLosses\n\n    giniSum -= (len(actual) + 1) \/ 2.\n    return giniSum \/ len(actual)\n\n\ndef gini_normalized(actual, pred):\n    return gini(actual, pred) \/ gini(actual, actual)","b9c8617a":"actual_train = y_train\npred_train = rf_RandomGrid.predict(X_train)\nactual_test = y_test\npred_test = rf_RandomGrid.predict(X_test)","52554539":"print(f'Gini Train : {gini(actual_train,pred_train):.3f}')\nprint(f'Gini Test : {gini(actual_test,pred_test):.3f}')","72df6e39":"test_pred = rf_RandomGrid.predict_proba(test[X.columns])[:,1]","0862d36f":"AllSub = pd.DataFrame({ 'RefId': test['RefId'],\n                       'IsBadBuy' : test_pred\n    \n})","c6abfaae":"AllSub['IsBadBuy'] = AllSub['IsBadBuy'].apply(lambda x: 1 if x > 0.09 else 0)","4e4044c3":"AllSub.to_csv('DGK_RF_Pipe_BetterPipe1.csv', index = False)","5f71ad16":"## Import Data","07cb027f":"Ref Articles \n- https:\/\/towardsdatascience.com\/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\n- https:\/\/machinelearningmastery.com\/smote-oversampling-for-imbalanced-classification\/\n- https:\/\/discuss.analyticsvidhya.com\/t\/what-is-the-difference-between-predict-and-predict-proba\/67376\n- https:\/\/github.com\/AnilBetta\/AV-Janata-Hack-healh-Care-2\/blob\/master\/av-jh-hca2-cat.ipynb\n- https:\/\/github.com\/gcspkmdr\/HA-Hackathon","013f5e76":"## SMOTE","e2334861":"## Grid Search","ba8fff18":"## Gini Index","cd7a9c5c":"## Feat Engineering","dc845d92":"## Setup Pipeline ","ec979f2b":"## Accuracy","e352aa57":"## Divide Dataset into X and Y","b0cc34f4":"## Import Libraries","3397d4ca":"## Submission "}}