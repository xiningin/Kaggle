{"cell_type":{"88957447":"code","6dfbfe95":"code","e4601f4c":"code","cd5a9be1":"code","3e7d5242":"code","185702a7":"code","1f95de67":"code","40b7162d":"code","b082172c":"code","8b2c3278":"code","c444119a":"code","d47efcd9":"code","8d2626da":"code","a1cdc516":"code","c057990d":"code","ffef125a":"code","5b0f2101":"code","69c9220b":"code","67ef9a27":"code","240ec2d5":"code","b61f524e":"code","03fc676e":"code","45cdd2f3":"code","08399c64":"code","3aec61d2":"code","f681d453":"code","a7b8c86d":"code","4cc1f46b":"code","22d933ec":"code","96af58ce":"code","123e596b":"code","80c1c24c":"code","07e5b538":"code","7be24c26":"code","d62b3bce":"code","f0f0c999":"code","931877a0":"code","4f31373b":"code","a1b2712e":"code","649d0f0b":"code","e67052d8":"code","0cd57a83":"code","5c87cd09":"code","12023dab":"code","0c8dc20a":"markdown","a3cd33a3":"markdown","a71ed123":"markdown","cc204c54":"markdown","19678c32":"markdown","b6afb725":"markdown","329a0faf":"markdown","6a036bb3":"markdown","d4adf9e9":"markdown","5569be67":"markdown","0cad6c81":"markdown","762a3454":"markdown","38f56835":"markdown","4708206a":"markdown","7a0dc40d":"markdown"},"source":{"88957447":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6dfbfe95":"import numpy as np\nimport pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","e4601f4c":"data = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","cd5a9be1":"data.head()","3e7d5242":"data.dtypes","185702a7":"data.isnull().sum()","1f95de67":"data.shape","40b7162d":"data.describe()","b082172c":"print('The mean of the transaction amount: {} '.format(data['Amount'].mean()))","8b2c3278":"data.columns","c444119a":"data['Class'].value_counts()","d47efcd9":"plt.title('Countplot of Fraud or Not Fraud',fontsize=14)\nsns.countplot('Class',data=data)","8d2626da":"X = data.drop('Class',axis=1)","a1cdc516":"y = data['Class']","c057990d":"fraud = data[data['Class']==1]\nNormal = data[data['Class']==0]","ffef125a":"fraud['Amount'].describe()","5b0f2101":"Normal['Amount'].describe()","69c9220b":"def plot(col):\n    plt.title('Amount per transaction by Fraud')\n    plt.xlabel('Amount($)')\n    plt.ylabel('Number of transaction')\n    plt.xlim((0,20000))\n    sns.boxplot(col)\n    ","67ef9a27":"plot(fraud['Amount'])","240ec2d5":"plot(Normal['Amount'])","b61f524e":"data.hist(figsize = (20,20))\nplt.show()\n#Histogram of each classifier ","03fc676e":"corr = data.corr()","45cdd2f3":"plt.figure(figsize=(20,20))\ncorr_graph = sns.heatmap(data[corr.index].corr(),annot = True,cmap ='RdYlGn')","08399c64":"from sklearn.preprocessing import StandardScaler, RobustScaler\n","3aec61d2":"std_scaler = StandardScaler()\n","f681d453":"rob_scaler = RobustScaler()\n","a7b8c86d":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state = 0)","4cc1f46b":"print('X_train shape is {}'.format(X_train.shape))\nprint('X_test shape is {}'.format(X_test.shape))\nprint('y_train shape is {}'.format(y_train.shape))\nprint('y_test shape is {}'.format(y_test.shape))\n","22d933ec":"X_train = std_scaler.fit_transform(X_train)\nX_test = std_scaler.fit_transform(X_test)","96af58ce":"print('Training Set after Standardised: {}'.format(X_train[0]))","123e596b":"from sklearn.tree import DecisionTreeClassifier","80c1c24c":"from sklearn import metrics\n\ndef predict(ml_model):\n    \n    model=ml_model.fit(X_train,y_train)\n    \n    print('Training score : {}'.format(model.score(X_train,y_train)))\n    \n    y_prediction=model.predict(X_test)\n    \n    print('predictions are: \\n {}'.format(y_prediction))\n    \n    print('\\n')\n    \n    \n    com_decision = confusion_matrix(y_test,y_prediction)\n    \n    print('confusion matrix {}'.format(com_decision))\n    \n    Accuracy_model = ((com_decision[0][0] + com_decision[1][1]) \/ com_decision.sum()) *100\n    \n    print('Accuracy Decision : ',Accuracy_model)\n    \n    Error_rate_model = ((com_decision[0][1] + com_decision[1][0]) \/ com_decision.sum()) *100\n    \n    print('Error Rate Decision : ',Error_rate_model)\n    \n    Specificity_model = (com_decision[1][1] \/ (com_decision[1][1] + com_decision[0][1])) *100\n    \n    print('Specificity Decision : ',Specificity_model)\n    \n    Sensitivity_model = (com_decision[0][0] \/ (com_decision[0][0] + com_decision[1][0])) *100\n    \n    print('Sensitivity Decision : ',Sensitivity_model)","07e5b538":"# predict(DecisionTreeClassifier())\n# Gives Acuracy of 99.90%","7be24c26":"from sklearn.svm import SVC","d62b3bce":"# predict(SVC(kernel = 'rbf' , random_state = 0))\n# Gives Accuracy of 99.93%","f0f0c999":"from sklearn.ensemble import RandomForestClassifier","931877a0":"predict(RandomForestClassifier())","4f31373b":"model = RandomForestClassifier().fit(X_train, y_train)","a1b2712e":"y_prediction = model.predict(X_test)","649d0f0b":"y_prediction","e67052d8":"y_test_array = y_test.to_numpy()","0cd57a83":"y_test_array","5c87cd09":"y_prediction[25000]","12023dab":"y_test_array[25000]","0c8dc20a":"[](http:\/\/)**VISULIZATIONS**","a3cd33a3":"Above graphs shows that amount of fraud transations are very less than the normal ones","a71ed123":"**Lets Do Some Prediction**","cc204c54":"**INTRODUCTION** \n\nIn this notebook we will use many predictive models depending on their accuracy in detencting whether a transaction is fraud or not.In dataset name of several features are not shown due to privacy concerns.Lets Start.","19678c32":"> So, there are no null values in our data","b6afb725":"> So, out of 284807 transactions, there are 492 fraud ones.","329a0faf":"**SCALING and Sample Making**","6a036bb3":"Decision Tree Classifier ","d4adf9e9":"**MODEL**","5569be67":"Since the dataset has no categorical data, So we don't need any encoding technique to convert it in numerical format for applying algorithums.","0cad6c81":"**Summary**\n* There are no Null values in dataset which is a good thing.\n* Mean of transactions amount is approx 88 , which suggest that transaction amount is relatively small.\n* Percentage of fraud case is 0.173 %","762a3454":"**BASICS OF DATA**","38f56835":"**DECISION TREE**","4708206a":"**SUPPORT VECTOR CLASSIFIER**","7a0dc40d":"**CORRELATION**"}}