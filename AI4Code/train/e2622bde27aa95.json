{"cell_type":{"d305a5dd":"code","33081941":"code","9d0b12cb":"code","ece9ecae":"code","f2331f7b":"code","f72672ed":"code","557f5bd9":"code","848ef20f":"code","a34efcd6":"code","77d2c3ce":"code","a639060e":"code","6f6e7f68":"code","f5d6cd85":"code","33540aab":"code","06b53132":"code","ede81a45":"code","152ff7e0":"code","e1657218":"markdown","ac6e9873":"markdown","b94cfc4e":"markdown","ac841d67":"markdown","f5a487bf":"markdown","314bcbbd":"markdown","78718f11":"markdown","2c75efc2":"markdown","448e8427":"markdown","9ec7588e":"markdown","a229e2aa":"markdown","c7202e62":"markdown"},"source":{"d305a5dd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","33081941":"data = pd.read_csv('..\/input\/boston-house-prices\/housing.csv', header = None, delim_whitespace=True)\ndata.columns = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B', 'LSTAT','MEDV']\ndata.head()","9d0b12cb":"data.info()","ece9ecae":"data.describe()","f2331f7b":"for column in data.columns:\n    sns.distplot(data[column])\n    plt.show()","f72672ed":"plt.figure(figsize = (20, 10))\nsns.heatmap(data.corr(), annot = True, cmap = plt.cm.CMRmap_r)","557f5bd9":"data.drop(['RAD'], axis = 1, inplace = True)\n","848ef20f":"columns_to_transform = ['CRIM', 'NOX', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'LSTAT', 'B']\nfor col in columns_to_transform:\n    data[col] = np.log1p(data[col])\n    sns.distplot(data[column])\n    plt.show()","a34efcd6":"X = data.drop(['MEDV'], axis = 1)\ny = data['MEDV']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 51)","77d2c3ce":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","a639060e":"from sklearn.ensemble import RandomForestRegressor\nmodel2 = RandomForestRegressor()\nmodel2.fit(X_train, y_train)\nmodel2.score(X_test, y_test)","6f6e7f68":"from sklearn import svm\nmodel3 = svm.SVR()\nmodel3.fit(X_train, y_train)\nmodel3.score(X_test, y_test)","f5d6cd85":"from  sklearn.neighbors import KNeighborsRegressor\nmodel5 = KNeighborsRegressor()\nmodel5.fit(X_train, y_train)\nmodel5.score(X_test, y_test)","33540aab":"from sklearn.tree import DecisionTreeRegressor\nmodel6 = DecisionTreeRegressor()\nmodel6.fit(X_train, y_train)\nmodel6.score(X_test, y_test)","06b53132":"from sklearn.ensemble import ExtraTreesRegressor\nmodel7 = ExtraTreesRegressor()\nmodel7.fit(X_train, y_train)\nmodel7.score(X_test, y_test)","ede81a45":"from sklearn.linear_model import Lasso\nmodel8 = Lasso()\nmodel8.fit(X_train, y_train)\nmodel8.score(X_test, y_test)","152ff7e0":"from sklearn.ensemble import GradientBoostingRegressor\nmodel9 = GradientBoostingRegressor()\nmodel9.fit(X_train, y_train)\nmodel9.score(X_test, y_test)","e1657218":"I am using log transformation here to normalize the data points since most the columns are right skewed. I haven't the column 'CHAS' since it only unique values are either 0 or 1.","ac6e9873":"Since all of our data is numerical we can quickly iterate over them without checking if they are categorical or not to visualize their distribution.","b94cfc4e":"# Exploratory Data Analysis","ac841d67":"Lets begin with importing the required libraries for this notebook.","f5a487bf":"**Overall the most accurate model with this dataset is GradientBoostingRegressor with 0.88~ and the worse one is SVR with 0.21~ accuracy. Low performance of this model may be attributed the chosen measure accuracy metric since default score metric of the regression models in the scikit-learn library returns the R^2 value.\n\nAny feedback is highly appreciated!**","314bcbbd":"Seems like all of our data is numerical and we have 0 null values! Lets have a quick look at the our central tendency measures.","78718f11":"According to correlation matrix 'TAX' and 'RAD' values are highly correlated. This can have a bad effect in our model, so we are dropping one of the columns to reduce multicollinearity. I want 'TAX' column to sTay since its distribution is more normal than the 'RAD' column's.","2c75efc2":"Seems like the distribution of the some values follow bimodal or left\/right skewed distributions. We may need to normalize them so our distance based models(such as Linear Regression) can fit the data better.","448e8427":"#     Description of the columns are given below:\n    CRIM - per capita crime rate by town\n    ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n    INDUS - proportion of non-retail business acres per town.\n    CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n    NOX - nitric oxides concentration (parts per 10 million)\n    RM - average number of rooms per dwelling\n    AGE - proportion of owner-occupied units built prior to 1940\n    DIS - weighted distances to five Boston employment centres\n    RAD - index of accessibility to radial highways\n    TAX - full-value property-tax rate per 10,000 USD\n    PTRATIO - pupil-teacher ratio by town\n    B - 1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n    LSTAT - % lower status of the population\n    MEDV - Median value of owner-occupied homes in $1000's\n","9ec7588e":"# Model Fitting","a229e2aa":"# Data Preprocessing","c7202e62":"# Feature Scaling"}}