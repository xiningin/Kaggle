{"cell_type":{"71c0c774":"code","20655a6d":"code","d62dfc9a":"code","d9148338":"code","57ae9c90":"code","eab1a1d8":"code","99516187":"code","25b85a18":"code","d210a2f7":"code","1e85380f":"code","8e69d5a8":"code","c4fb17f4":"code","5014cd96":"code","7225bbee":"markdown","386b8817":"markdown","4c626468":"markdown","718f83db":"markdown","93c355ec":"markdown","97853142":"markdown","e7a30b99":"markdown","bb7b6ffb":"markdown","1893b079":"markdown","2a7596ce":"markdown","96abdb3c":"markdown","3c2ddf07":"markdown","44cdc340":"markdown","65cf3091":"markdown"},"source":{"71c0c774":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Read training data\ndf_train_raw = pd.read_csv('..\/input\/train.csv')","20655a6d":"df_train_raw.sample(5)","d62dfc9a":"df_train_raw.describe()","d9148338":"print(('{m:d} unique matches').format(m=len(df_train_raw['matchId'].unique())))\n\nprint(('{tk:d} data entries in {m:d} different matches with exactly 3 team kills').format(\n    tk=len(df_train_raw[df_train_raw['teamKills']==3]),\n    m=len(df_train_raw[df_train_raw['teamKills']==3]['matchId'].unique())))\n\nprint(('{tk:d} data entries in {m:d} different matches with more than 3 team kills').format(\n    tk=len(df_train_raw[df_train_raw['teamKills']>3]),\n    m=len(df_train_raw[df_train_raw['teamKills']>3]['matchId'].unique())))\n    \nprint(('{g:d} data entries in {m:d} different matches with exactly 1 group').format(\n    g=len(df_train_raw[df_train_raw['numGroups']==1]),\n    m=len(df_train_raw[df_train_raw['numGroups']==1]['matchId'].unique())))\n\nn_group = 10\nprint(('{g:d} data entries in {m:d} different matches with less than {n:d} groups').format(\n    g=len(df_train_raw[df_train_raw['numGroups']<n_group]),\n    m=len(df_train_raw[df_train_raw['numGroups']<n_group]['matchId'].unique()),\n    n=n_group))","57ae9c90":"df_train = df_train_raw#.iloc[0:100000]\n\ndel df_train_raw","eab1a1d8":"f, ax = plt.subplots(figsize=(20, 15))\nsns.heatmap(df_train.corr(), annot=True, fmt='.2f', linewidths=.5, ax=ax)","99516187":"# Reference: https:\/\/www.kaggle.com\/anycode\/simple-nn-baseline\/code\ndef FeatureEngineering(df):\n    df_size = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n        \n    df_mean = df.groupby(['matchId','groupId']).mean().reset_index()\n    \n    df_sum = df.groupby(['matchId','groupId']).sum().reset_index()\n    \n    df_max = df.groupby(['matchId','groupId']).max().reset_index()\n    \n    df_min = df.groupby(['matchId','groupId']).min().reset_index()\n    \n    df_match_mean = df.groupby(['matchId']).mean().reset_index()\n    \n    df = pd.merge(df, df_size, how='left', on=['matchId', 'groupId'])\n    del df_size\n    df = pd.merge(df, df_mean, suffixes=[\"\", \"_mean\"], how='left', on=['matchId', 'groupId'])\n    del df_mean\n    df = pd.merge(df, df_sum, suffixes=[\"\", \"_sum\"], how='left', on=['matchId', 'groupId'])\n    del df_sum\n    df = pd.merge(df, df_max, suffixes=[\"\", \"_max\"], how='left', on=['matchId', 'groupId'])\n    del df_max\n    df = pd.merge(df, df_min, suffixes=[\"\", \"_min\"], how='left', on=['matchId', 'groupId'])\n    del df_min\n    df = pd.merge(df, df_match_mean, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    del df_match_mean\n        \n    columns = list(df.columns)\n    columns.remove(\"Id\")\n    columns.remove(\"matchId\")\n    columns.remove(\"groupId\")\n    columns.remove(\"Id_mean\")\n    columns.remove(\"Id_sum\")\n    columns.remove(\"Id_max\")\n    columns.remove(\"Id_min\")\n    columns.remove(\"Id_match_mean\")\n\n    df = df[columns]\n    return df\n","25b85a18":"def MAE(y_estimate, y_true):\n    return sum(abs(y_estimate-y_true))\/len(y_estimate)","d210a2f7":"from sklearn.model_selection import train_test_split\n\nmatchId = df_train['matchId'].unique()\nmatchIdTrain = np.random.choice(matchId, int(0.80*len(matchId)))\n\ndf_train2 = df_train[df_train['matchId'].isin(matchIdTrain)]\ndf_test = df_train[~df_train['matchId'].isin(matchIdTrain)]\n\ny_train = df_train2['winPlacePerc']\nX_train = df_train2.drop(columns=['winPlacePerc'])\ny_test = df_test['winPlacePerc']\nX_test = df_test.drop(columns=['winPlacePerc'])\n\nX_train = FeatureEngineering(X_train)\nX_test = FeatureEngineering(X_test)\n\n# This commented out section is the train\/test split without keeping the matches intact\n#X = df_train.drop(columns=['winPlacePerc'])\n#y = df_train['winPlacePerc']\n#X = FeatureEngineering(X)\n#X_train, X_test, y_train, y_test = train_test_split(X, y)\n\nprint(('Training set size: {train:d}, test set size: {test:d}').format(train=len(X_train), test=len(X_test)))\nprint(X_train.describe())\n\ndel df_train2, df_test, df_train#, X, y","1e85380f":"def RandomForestModel():\n    print('\\nCreating and training random forest regressor')\n    from sklearn.ensemble import RandomForestRegressor\n    rfr = RandomForestRegressor(n_jobs=4, n_estimators=10)\n    rfr.fit(X_train, y_train)\n\n    y_rfr = rfr.predict(X_test)\n    score_rfr = MAE(y_rfr, y_test)\n    print(('Random Forest training testset score: {s:.3f}').format(s=score_rfr))\n    \n    # Read the test set data and make predictions\n    X_submit = pd.read_csv('..\/input\/test.csv')\n    df_submit = X_submit[['Id', 'matchId', 'groupId']]\n    X_submit = FeatureEngineering(X_submit)\n    y_submit = rfr.predict(X_submit)\n    df_submit['prediction'] = y_submit\n    \n    # Return a dataframe with ID's and the prediction\n    return df_submit    ","8e69d5a8":"df_submit = RandomForestModel()\n\ndf_submit.head()","c4fb17f4":"print('Correcting predictions')\n        \ndf_submit['prediction_mod'] = -1.0\nmatchId = df_submit['matchId'].unique()\n\nfor match in matchId:\n    df_match = df_submit[df_submit['matchId']==match]\n\n    df_max = df_match.groupby(['groupId']).max()\n    pred_sort = sorted(df_max['prediction'])\n\n    for i in df_max.index:\n        groupPlace = pred_sort.index(df_max.loc[i]['prediction'])\n        if len(pred_sort) > 1:\n            df_max.at[i,'prediction_mod'] = groupPlace\/(len(pred_sort)-1)\n        else:\n            df_max.at[i,'prediction_mod'] = 1.0\n\n    for i in df_match.index:\n        df_submit.at[i, 'prediction_mod'] = df_max['prediction_mod'].loc[df_match['groupId'].loc[i]]\n\ny_submit_cor = df_submit['prediction_mod']\nprint('Submission scores corrected')\n\ndf_submit.head()","5014cd96":"df_test = pd.read_csv('..\/input\/sample_submission.csv')\ndf_test['winPlacePerc'] = df_submit['prediction_mod'].copy()\n\ndf_test.to_csv('submission_rfr.csv', index=False) \nprint('Random Forest submission file made\\n')","7225bbee":"In 707 matches someone made exactly 3 team kills. He or she did not make any friends that match, but it is possible that it happened in regular games. Also, there are 92 games with more than 3 team kills, which must have been custom matches.\n\nOnly 3 matches had one group, with an average of ~30 players per group. Definitely exceeds the 4 player squad limit. Besides that, there were 593 matches with less than groups. My personal experience is that there were always 80+ players in a games, but I have heard that in the Oceania servers the player count could be much lower.\n\nBased on these stats, up to 2% of the matches may be unreliable, but for now I am ignoring this and will continue with the complete dataset.\n\nThe line blow where df_train is defined is obsolete. For quick testing it was nice to use a smaller dataset. Now it is only used to rename the dataset.","386b8817":"# Feature engineering","4c626468":"# Make submission file","718f83db":"PUBG, the game where you fight with up to 99 others for a chicken dinner. I spent a couple hundred hours in this game while only winning the chicken dinner <50 times. Going to KFC would have been more efficient... Let's find out how we can predict the winner of the chicken dinner.","93c355ec":"# Split the data in a train and test set\nHere y is defined as the output and X are all the features. As mentioned before, all features are included and none of the data entries are removed. The data is split in a training and test set.","97853142":"For the model we will use a Random Forest Regressor with 10 trees. ","e7a30b99":"Let's see if we can get a first look of the important features and which features are correlated with each other.","bb7b6ffb":"# Model: Random Forest","1893b079":"# Scoring function\nThe model performance will be judged by its mean absolute error which is defined in the function below.\n\n[https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_error](https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_error)\n\nThe values can range between 0 (perfect) and 1 (worst possible), give that all predictions are in the interval [0-1].","2a7596ce":"# Call model","96abdb3c":"Starting off with the most important:\n\n**winPlacePerc**  is our to be predicted value. The features with the highest linear correlation are\n1.  walkDistance (0.81)\n2. killPlace (-0.71)\n3. boosts (0.62)\n4. weaponsAcquired (0.57)\n5. damageDealt (0.44)\n\nSo you win by walking? Actually, my view point is that walking distance is a measure for the amount of time you have been alive. Survive longer and you have a higher chance on a higher ranking. Same explanation for the number of weapons acquired. Kill place is negatively correlated because a lower number means more kills. More kills probably means a higher win place, although the number of kills actually does not make the top 5! I think the kill place generalizes better than the actual number of kills. In 1 game the winner may have had 20 kills, while in another game the winner may only have 10 kills, which results in a large spread on a linear fit. For both the 20 and 10 kills the winners may have achieved killPlace = 1.\n\n**Kills** correlates quite well with anything kill related:\n1. damageDealt (0.89)\n2. killStreak (0.80)\n3. DBNOs (0.75)\n4. killPlace (-0.73)\n5. headshotKills (0.68)\n6. longestKill (0.59)\n\nWe may be able to drop some of these features, but for now we continue with all features.","3c2ddf07":"# Exploring the data\nLet's see which features we have and what range of values they have.","44cdc340":"The maxima for DBNO (63), heals (59), kills (60), revives (41), ride distance (48390m), road kills (42), swim distance (5286m), team kills (6), walking distance (17300m) and weapons acquired (76) are really odd.\n\nThe game as intended consists of 100 players playing solo, in duo's (2 players per team) or squads (4 players per team). Having 6 team kills is therefore impossible in the normal game. Achieving 60 kills is theoretically possible, but very unlikely. Same goes for the DBNO's, heals, revives and weapons acquired. It looks like the dataset contains some custom games or zombie mode games, where a few players fights against a horde of unarmed zombies.\n\nThe maximum ride, swim and walking distances are also huge. I thought this was a shooter, not a racing sim? ","65cf3091":"# Make corrections to the predictions\nBefore submitting the predictions, we will correct them. What this correction means is best shown by an example:\nSay, we have 3 teams in 1 match with predicted scores of [0.83, 0.14, 0.56]. We know these scores should be [1.0, 0.0, 0.5] because of the way the scoring is defined. If there is only 1 team we will default the score to be 1.0."}}