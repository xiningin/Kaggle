{"cell_type":{"3488f2f2":"code","2a3d362e":"code","ee31419d":"code","7bf53a4b":"code","013ec976":"code","b38ba3e8":"code","35833f2d":"code","e2416b88":"code","8c692cc9":"code","0a2d0aec":"code","646b11bd":"code","33ba9f56":"code","9219943a":"code","d9a6251a":"code","1123690e":"code","b07d3373":"code","c5033868":"code","614e0ba1":"code","9e4c4194":"code","d705e3a8":"code","cb954cc7":"code","0b2e2520":"code","5321edb5":"code","4a4ab03e":"code","62ab9f7f":"code","bf36e3b3":"code","56ffe28d":"code","2ef18c10":"code","de94ca7c":"code","229b44e0":"code","0469dc9f":"code","94ef1959":"code","2b819393":"code","51189143":"code","17080f43":"code","4d1cfd8b":"code","45fbd537":"code","e296f073":"code","9b0d848a":"code","04de4b42":"code","ab0ca898":"code","928766aa":"code","6194f7a0":"code","2b7d34ff":"code","5281efef":"markdown","d454fb27":"markdown","3ee8c244":"markdown","c9762a06":"markdown","883177c9":"markdown","d891a1eb":"markdown","e4250990":"markdown","d54b2f43":"markdown","cf3044e3":"markdown","b3edadc9":"markdown","1e6c4569":"markdown","3511656d":"markdown","5104c4ba":"markdown","2976ac58":"markdown","32e31d6a":"markdown","134d1172":"markdown","ebe7e673":"markdown","6c98ac71":"markdown","c1f161cf":"markdown"},"source":{"3488f2f2":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2a3d362e":"train=pd.read_csv(\"\/kaggle\/input\/hackerearth-ml-challenge-pet-adoption\/train.csv\")\ntrain.head()","ee31419d":"train.info()","7bf53a4b":"train.shape","013ec976":"for col in train.columns:\n    print(col,':',len(train[col].unique()))","b38ba3e8":"#removing unwanted text in pet_id\ntrain['pet_id']=train['pet_id'].str.replace('[^0-9]',\"\")\n\n#converting into int data type\ntrain['pet_id'] = train.pet_id.astype(int)\n                                      ","35833f2d":"#converting both the columns into datetime format\ntrain['issue_date']=pd.to_datetime(train['issue_date'])\ntrain['listing_date']=pd.to_datetime(train['listing_date'])\n\n","e2416b88":"#taking duration\ntrain['duration']=train['listing_date']-train['issue_date']\ntrain['duration']","8c692cc9":"#considering only no of days ---duration of days\ntrain['duration'] = train['duration'].dt.days\ntrain['duration']","0a2d0aec":"#drop issue_date and listing date columns\n\ntrain.drop(['issue_date','listing_date'],axis=1,inplace=True)","646b11bd":"#Checking for missing values\ntrain.isna().sum()","33ba9f56":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nsns.countplot(x=train['condition'],data=train)\nplt.title(\"Condition values composition\")\nplt.show()","9219943a":"train=train.fillna(2.0)","d9a6251a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nsns.countplot(x=train['condition'],data=train)\nplt.title(\"Condition values composition\")\nplt.show()","1123690e":"train.isna().sum()","b07d3373":"#frequency Encoding\nfeq_encode = train.groupby('color_type').size()\/len(train)\nprint(feq_encode)\n\ntrain.loc[:,'color_type'] = train['color_type'].map(feq_encode)","c5033868":"plt.figure(figsize=(10,8))\nsns.distplot(train['length(m)'])\nplt.title(\"Length data Distribution\")\nplt.show()\n\nplt.figure(figsize=(10,8))\nsns.distplot(train['height(cm)'])\nplt.title(\"Height data Distribution\")\nplt.show()","614e0ba1":"sns.set_style('darkgrid')\nplt.figure(figsize=(10,8))\nsns.countplot(\"condition\",hue=\"pet_category\",data=train)\nplt.show()","9e4c4194":"plt.figure(figsize=(10,8))\nsns.countplot(\"condition\",hue=\"breed_category\",data=train)\nplt.show()","d705e3a8":"plt.figure(figsize=(18,10))\nsns.heatmap(train.corr(),annot=True)","cb954cc7":"plt.figure(figsize=(10,8))\nsns.regplot(x=\"X1\",y=\"X2\",data=train)\nplt.title(\"realtion between X1 and X2\")\nplt.show()","0b2e2520":"import xgboost as xgb","5321edb5":"x=train.drop(['pet_category','breed_category'],axis=1)\ny=train.breed_category #target label","4a4ab03e":"x.head(5)","62ab9f7f":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,accuracy_score","bf36e3b3":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)","56ffe28d":"## Hyper Parameters\n\nparams={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30,0.50 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n    \n}","2ef18c10":"from sklearn.model_selection import RandomizedSearchCV\nxgb_model = xgb.XGBClassifier()\n\nrandom_search=RandomizedSearchCV(xgb_model,param_distributions=params,n_iter=5,n_jobs=-1,cv=5,verbose=3)\nrandom_search.fit(x_train,y_train)","de94ca7c":"random_search.best_params_ #printing best parameters","229b44e0":"random_search.best_estimator_  #best estimator ","0469dc9f":"first_model=xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.3, gamma=0.0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.15, max_delta_step=0, max_depth=10,\n              min_child_weight=1,  monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)","94ef1959":"first_model.fit(x_train,y_train)","2b819393":"y_pred=first_model.predict(x_test)","51189143":"print(\"Accuracy score:\",accuracy_score(y_test,y_pred))\ncm=confusion_matrix(y_pred,y_test)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm,annot=True)\nplt.show()","17080f43":"y=train.pet_category #target label\nsns.countplot('pet_category',data=train)","4d1cfd8b":"x.head(5)","45fbd537":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)","e296f073":"xgb_model = xgb.XGBClassifier()\n\nrandom_search=RandomizedSearchCV(xgb_model,param_distributions=params,n_iter=5,n_jobs=-1,cv=5,verbose=3)\nrandom_search.fit(x_train,y_train)","9b0d848a":"random_search.best_estimator_","04de4b42":"random_search.best_params_","ab0ca898":"second_model = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.2, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=10,\n              min_child_weight=3,monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)","928766aa":"second_model.fit(x_train,y_train)","6194f7a0":"ypred=second_model.predict(x_test)","2b7d34ff":"print(\"Accuracy score:\",accuracy_score(y_test,y_pred))","5281efef":"## Handling text id","d454fb27":"<h1 style=\"color:green;\"> Feature Engineering <\/h1>","3ee8c244":"#### Unique Values  ","c9762a06":"<h1 style=\"color:blue;\"> I hope you learned something New , Thanking You<\/h1>","883177c9":"The most obvious way to do this is to split a multioutput classification problem into multiple single-output classification problems.\n\nFor example, if a multioutput classification problem required the prediction of three values y1, y2 and y3 given an input X, then this could be partitioned into two single-output classification problems:\n\nProblem 1: Given X, predict y1.\n<br>\nProblem 2: Given X, predict y2.\n<br>\nThere are two main approaches to implementing this technique.\n\nThe first approach involves developing a separate classification model for each output value to be predicted. We can think of this as a direct approach, as each target value is modeled directly.\n\nThe second approach is an extension of the first method except the models are organized into a chain. The prediction from the first model is taken as part of the input to the second model, and the process of output-to-input dependency repeats along the chain of models.\n\n<b>Direct Multioutput:<\/b> Develop an independent model for each numerical value to be predicted.\n<b>Chained Multioutput:<\/b> Develop a sequence of dependent models to match the number of labels to be predicted.","d891a1eb":"we have <b>1477<\/b> missing values in condition feature","e4250990":"# Model II","d54b2f43":"### Model I","cf3044e3":"<h2> Handling Categorical Variables<\/h2>","b3edadc9":" # Table of Contents\n \n <ol>\n    <li><h3> Understanding Data<\/h3><\/li>\n    <li> <h3>Feature Engineering<\/h3><\/li>\n    <ul>\n        <li><h4> Handling Text id<\/h4><\/li>\n        <li><h4> Handling Date columns<\/h4><\/li>\n        <li><h4> Handling missing values<\/h4><\/li>\n        <li><h4> Handling Categorical values<\/h4><\/li>\n    <\/ul>\n    <li> <h3>Exploratory Data Analysis<\/h3> <\/li>\n    <li><h3> MultiOutput Classification<\/h3><\/li>\n    <ul>\n        <li> <h4>Model I creation<\/h4><\/li>\n        <li><h4>Model II creation<\/h4><\/li>\n    <\/ul>\n    <\/ol>\n        ","1e6c4569":"## Handling Missing Values","3511656d":" <h4>Frequency Encoding<\/h4>\n It is a way to utilize the frequency of the categories as labels. In the cases where the frequency is related somewhat with the target variable, it helps the model to understand and assign the weight in direct and inverse proportion, depending on the nature of the data.\n <br><br>\n <b>Three-step for this : <\/b>\n <ul>\n    <li>Select a categorical variable you would like to transform<\/li>\n    <li>Group by the categorical variable and obtain counts of each category<\/li>\n    <li>Join it back with the training dataset<\/li>\n <\/ul>","5104c4ba":"## Problem Statement\n<h4> A leading pet domain Agency is planning to create a virtual tour experience for their customers showcasing all the animals that are available in the shelter. You are required to build Machine Learning Model that determines type and breed of the animal based on its physical attributes and other factors<\/h4>\n<br>\n<h4>Target Variables : <b>breed_category<\/b> ,<b>pet_category<\/b><\/h4>","2976ac58":" <h1 style=\"color:blue;\">Exploratory Data Analysis<\/h1>","32e31d6a":"## Handling Date columns","134d1172":"<img src=\"https:\/\/sterlingshelter-animalshelterinc.netdna-ssl.com\/wp-content\/uploads\/2017\/09\/adoption.jpg\" \/>","ebe7e673":"# Understanding Data","6c98ac71":"### Correlation","c1f161cf":"# Multi Output Classification"}}