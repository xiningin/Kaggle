{"cell_type":{"4ee0d525":"code","fe193fba":"code","b6fa8a0e":"code","f969c55d":"code","fbaef92b":"code","e39bf10b":"code","9d55eb57":"code","d66e99ad":"code","7e7a2854":"code","8b531fb5":"code","4a2b28d4":"code","46b9f72f":"code","460328ac":"code","34994a6a":"code","da5cc0f6":"code","f0de6c83":"code","1966c6cb":"code","1a85b2f1":"code","a6d7e60b":"code","b6fcd261":"code","1ace7ad6":"code","c66b0b5f":"code","424a0a2c":"code","25bead34":"code","8382f77e":"code","8a5b7093":"code","cfdc52c4":"code","0a34621c":"code","c90409bc":"code","063e961a":"code","a0030968":"code","8b5f86bf":"code","6ed5a47f":"code","78673437":"code","98b19095":"markdown","8552ccf4":"markdown","2c737a75":"markdown","9d509cf9":"markdown","980c3a16":"markdown","176d3ed7":"markdown","4f06f9c7":"markdown","2ad0111f":"markdown","84334859":"markdown","7e3af2b9":"markdown","d56609f0":"markdown","b624d148":"markdown","683c9f74":"markdown","d74a59ef":"markdown","45247636":"markdown","b8cfd61d":"markdown","1e4aebf1":"markdown","7f19f5ee":"markdown","3c9322b7":"markdown","94eb1742":"markdown","9e974e75":"markdown","2b865952":"markdown"},"source":{"4ee0d525":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fe193fba":"from datetime import datetime\nimport os\nimport random\nimport matplotlib\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nfrom scipy import sparse\nfrom scipy.sparse import csc_matrix\n\nfrom sklearn.decomposition import TruncatedSVD\n#from sklearn.metrics.pariwise import cosine_similarity","b6fa8a0e":"start = datetime.now()\nif not os.path.isfile('data.csv'):\n    #read all txt file and store them in one big file\n    data = open('data.csv', mode='w')\n    \n    row = list()\n    files = ['..\/input\/netflix-prize-data\/combined_data_1.txt', '..\/input\/netflix-prize-data\/combined_data_2.txt',\n            '..\/input\/netflix-prize-data\/combined_data_3.txt', '..\/input\/netflix-prize-data\/combined_data_4.txt']\n    for file in files:\n        print('reading ratings from {}...'.format(file))\n        with open(file) as f:\n            for line in f:\n                del row[:]\n                line = line.strip()\n                if line.endswith(':'):\n                    #all are rating\n                    movid_id = line.replace(':', '')\n                else:\n                    row = [x for x in line.split(',')]\n                    row.insert(0, movid_id)\n                    data.write(','.join(row))\n                    data.write('\\n')\n        print('Done.\\n')\n    data.close()\nprint('time taken:', datetime.now() - start)","f969c55d":"print('creating the dataframe from data.csv file..')\ndf = pd.read_csv('data.csv', sep=',', names=['movie','user','rating','date'])\n\ndf.date = pd.to_datetime(df.date)\nprint('Done.\\n')\n\n#arranging the rating according to time\nprint('sorting the dataframe by date..')\ndf.sort_values(by='date', inplace=True)\nprint('sorting done.')","fbaef92b":"df.head()","e39bf10b":"df.describe()","9d55eb57":"df.describe()['rating']","d66e99ad":"print('number of NaN values in our dataset:', sum(df.isnull().any()))","7e7a2854":"dup = df.duplicated(['movie','user','rating'])\ndups = sum(dup) #considering by column\nprint('there are {} duplicate rating entries in the data.....'.format(dups))","8b531fb5":"print('Total Data')\nprint(\"-\"*60)\nprint('\\nTotal number of rating:', df.shape[0])\nprint('Total number of users:', len(np.unique(df.user)))\nprint('total number of movie:', len(np.unique(df.movie)))","4a2b28d4":"if not os.path.isfile('train.csv'):\n    #create a dataframe and store it\n    df.iloc[:int(df.shape[0]*0.80)].to_csv(\"train.csv\", index=False)\nif not os.path.isfile('test.csv'):\n    #create a dataframe and store it\n    df.iloc[int(df.shape[0]*0.80)].to_csv(\"test.csv\", index=False)\n\ntrain_df = pd.read_csv('train.csv', parse_dates=['date'])\ntest_df = pd.read_csv('test.csv')","46b9f72f":"test_df.shape","460328ac":"print('Total number of rating:',train_df.shape[0])\nprint('Total number of users:', len(np.unique(train_df.user)))\nprint('Total number of movies:', len(np.unique(train_df.movie)))","34994a6a":"test_df.head()","da5cc0f6":"print('Total number of rating:',test_df.shape[0])\n#print('Total number of users:', len(np.unique(test_df.user)))\n#print('Total number of movies:', len(np.unique(test_df.movie)))","f0de6c83":"def human(num, units='M'):\n    units = units.lower()\n    num = float(num)\n    if units == 'k':\n        return str(num\/10**3) + \"K\"\n    elif units == 'm':\n        return str(num\/10**6) + \"M\"\n    elif units == 'b':\n        return str(num\/10**9) + \"B\"\n","1966c6cb":"fig, ax = plt.subplots()\nplt.title('Distribution if rating over training dataset', fontsize=10)\nsns.countplot(train_df.rating)\nax.set_yticklabels([human(item,'M') for item in ax.get_yticks()])\nax.set_ylabel('No. of Ratings (Million)')\n \nplt.show()","1a85b2f1":"#It is used to skip the warnings\n#pd.options.mode.chained_assignment = None\n#train_df['day_of_week'] = train_df.date.dt.weekday_name\n\n#train_df.head()","a6d7e60b":"ax = train_df.resample('m', on='date')['rating'].count().plot()\nax.set_title('No. of ratings per month (Training Data)')\nplt.xlabel('Month')\nplt.ylabel('No. of Rating per Month')\nax.set_yticklabels([human(item,'M') for item in ax.get_yticks()])\n\nplt.show()","b6fcd261":"no_of_rated_movie_per_user = train_df.groupby(by='user')['rating'].count().sort_values(ascending=False)","1ace7ad6":"fig = plt.figure(figsize=plt.figaspect(.5))\n\nax1 = plt.subplot(121)\nsns.kdeplot(no_of_rated_movie_per_user, ax=ax1, shade=True)\nplt.xlabel('No of ratings by user')\nplt.ylabel('PDF')\n\n\n\nax2 = plt.subplot(122)\nsns.kdeplot(no_of_rated_movie_per_user, ax=ax2, shade=True, cumulative=True)\nplt.xlabel('No of ratings by user')\nplt.ylabel('CDF')\n\nplt.show()","c66b0b5f":"no_of_rated_movie_per_user.describe()","424a0a2c":"no_of_ratings_per_movie = train_df.groupby(by='movie')['rating'].count().sort_values(ascending=True)\n\nfig = plt.figure(figsize=plt.figaspect(.5))\nax = plt.gca()\nplt.plot(no_of_ratings_per_movie.values)\nplt.title('Rating Per Movie')\nplt.xlabel('Movie')\nplt.ylabel('No. of Users who rated a Movie')\nax.set_xticklabels([])\n\nplt.show()","25bead34":"start = datetime.now()\nif os.path.isfile('train_sparse_matrix.npz'):\n    train_sparse_matrix = sparse.load_npz('train_sparse_matrix.npz')\nelse:\n    train_sparse_matrix = sparse.csr_matrix((train_df.rating.values, (train_df.user.values, train_df.movie.values)),)\n    print('It is shape is:(user, movie):', train_sparse_matrix.shape)\n    \nprint(datetime.now() - start)","8382f77e":"us, mv = train_sparse_matrix.shape\nelem = train_sparse_matrix.count_nonzero()\n\nprint(elem)","8a5b7093":"print('sparsity of train matrix:{}%'.format((1-(elem\/us*mv)))*100)","cfdc52c4":"def get_average_ratings(sparse_matrix, of_users):\n    #avg rating from user\n    ax = 1 if of_users else 0\n    \n    #'.A1' is for converting column_matrix to 1-D numpy array\n    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n    \n    #boolean matrix of ratings (user raed or not)\n    is_rated = sparse_matrix!=0\n    \n    #no.of ratings that each user\n    no_of_ratings = is_rated.sum(axis=ax).A1\n    \n    u,m = sparse_matrix.shape\n    \n    #create a dictionary of users and their avg \n    average_ratings = {i : sum_of_ratings[i]\/no_of_ratings[i] for i in range(u if of_users else m) if no_of_ratings[i]!=0}\n    \n    return average_ratings","0a34621c":"train_averages = dict()\n\n#get global average \ntrain_global_average = train_sparse_matrix.sum()\/train_sparse_matrix.count_nonzero()\ntrain_averages['global'] = train_global_average\ntrain_averages","c90409bc":"train_averages['movie'] = get_average_ratings(train_sparse_matrix, of_users=False)\nprint('\\n Average rating of movie 15:', train_averages['movie'][15])","063e961a":"start = datetime.now()\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=plt.figaspect(.5))\nfig.suptitle('Avg Ratings per users and per Movie', fontsize=15)\n\nax1.set_title('users-avg-ratings')\n\n#getting a list of avg user rating from the avg dictionary\nuser_avg = [rat for rat in train_averages['user'].values()]\n\nsns.distplot(user_avg, ax=ax1, hint=False, kde_kws = dict(cumulative=True), label='Cdf')\n\nsns.distplot(user_avg, ax=ax1, hint=False,label='Pdf')\nax2.set_title('Movies-Avg-Rating')\n\n#getting a list of movie_avg user rating from the avg dictionary\n\nmovie_average = [rat for rat in train_averages['movie'].values()]\n\nsns.distplot(movie_average, ax=ax2, hint=False, kde_kws = dict(cumulative=True), label='Cdf')\n\nsns.distplot(movie_average, ax=ax2, hint=False,label='Pdf')\n\nplt.show()\nprint(datetime.now() - start)","a0030968":"from sklearn.metrics.pairwise import cosine_similarity","8b5f86bf":"start = datetime.now()\nif not os.path.isfile('m_m_sparse.npz'):\n    print('It seems dont have a file. computing movie_movie smimilarity...')\n    start = datetime.now()\n    m_m_sim_sparse = cosine_similarity(X=train_sparse_matrix.T, dense_output = False)\n    \n    #store this sparse matrix in disk \n    #print('saving it to disk without the need of re-computing it again')\n    #sparse.save_npz(\"m_m_sim_sparse.npz\", m_m_sim_sparse)\nelse:\n    print('it is there.')\n    m_m_sim_sparse = sparse.load_npz(\"m_m_sim_sparse\")\n    \nprint(\"it is a \", m_m_sim_sparse.shape, \"dimensional matrix\")\n\nprint(datetime.now() - start)","6ed5a47f":"movie_ids = np.unique(m_m_sim_sparse.nonzero()[1])\n\nstart  = datetime.now()\nsimilaer_movies = dict()\nfor movie in movie_ids:\n    sim_movies = m_m_sim_sparse[movie].toarry().ravel().argsort()[::-1][1:]\n    similar_movies[movie] = sim_movie[:100]\nprint(datetime.now() - start)\n\n#testing similar movies for movie_15\nsimilar_movies[15]\n","78673437":"movie_titles = pd.read_csv(\"..\/input\/netflix-prize-data\/movie_titles.csv\", sep=',', header=None, names=['movie_id', 'year_of_release', 'title'], verbose=True, index_col='movie_id', encoding='ISO-8859-1')\n\nmovie_titles.head()\n\n","98b19095":"In Training Data********","8552ccf4":"**EDA on Train Data**","2c737a75":"Basic Stats","9d509cf9":"Computing Movie-Movie similarity Matrix","980c3a16":"No. of Rating per Month","176d3ed7":"**PDF & CDF of Avg Ratings of Users and Movies**","4f06f9c7":"> Avg Rating per Movie","2ad0111f":"**Plot PDF(Probability Distribution Function) and CDF(Cumulative Distribution Function)**","84334859":"We can see that there is a massive growth of Netflix during the period 2003\u20132006. There are about 4.5 million ratings given by the users in 2005.","7e3af2b9":"Now add a 'week day' column for Data Analysis ","d56609f0":"Creating sparse matrix from data frame","b624d148":"We take only those top similar movie ratings and store them in a separate dictionary.","683c9f74":"Global average of all movie ratings","d74a59ef":"Finding Most Similar Movie","45247636":"**Distribution**","b8cfd61d":"Basic Statistics on Train and Test Data","1e4aebf1":"From the above distribution we see that most people give a rating of 4 and few people gave a rating of 1 .","7f19f5ee":"Sparsity of Train Sparse Matrix","3c9322b7":"**Checking NaN values**","94eb1742":"Check and Remove Duplicate","9e974e75":"**Split the Dataset**","2b865952":"Find Average of all movie ratings, average rating per user, average rating per movie"}}