{"cell_type":{"5222251e":"code","0124e18c":"code","e43fd046":"code","820c58db":"code","d21e3800":"code","0f3d996a":"code","0261a970":"code","df79c8e2":"code","33f3b9de":"code","7fe24d6b":"code","22d93745":"code","3bef215c":"code","85f1de3f":"code","3968ceae":"code","3273ab26":"code","78d51ff5":"code","dddb2ef0":"code","38d20a6e":"code","e4a29554":"code","a3b7c36a":"code","d964bbbd":"code","b3ca73da":"code","b457294a":"code","a2d598fc":"code","c1b8f69c":"code","7ce2faa9":"code","00348bdb":"code","e55114a9":"code","8b4f294f":"markdown","b5bae651":"markdown","098f71fe":"markdown","7fc4890a":"markdown","82b3f308":"markdown","2bb5b9e1":"markdown"},"source":{"5222251e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","0124e18c":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","e43fd046":"train_data.head()","820c58db":"X = train_data.drop([\"label\"],axis = 1).values\nY = train_data[\"label\"].values","d21e3800":"plt.figure(figsize = (12,6))\nsns.countplot(Y)","0f3d996a":"plt.imshow(X[0].reshape([28,28]))","0261a970":"plt.imshow(X[14].reshape([28,28]))","df79c8e2":"X = X.reshape([42000,28,28,1])\nY = Y.reshape([42000,1])","33f3b9de":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY = to_categorical(Y, num_classes = 10)","7fe24d6b":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 14)","22d93745":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","3bef215c":"x_train = x_train\/255\nx_test = x_test\/255","85f1de3f":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), padding = 'same', activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(64, (3,3), padding = 'same', activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(128, (3,3), padding = 'same', activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(128, (3,3), padding = 'same', activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n","3968ceae":"model.summary()","3273ab26":"from keras.optimizers import Adam\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer = optimizer,\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])","78d51ff5":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.6, \n                                            min_lr=0.00001)","dddb2ef0":"batch_size = 64\nepochs = 30","38d20a6e":"train_datagen = ImageDataGenerator( \n        rotation_range=10,  \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,\n        shear_range = 0.1,\n        horizontal_flip=False,  \n        vertical_flip=False\n        )\ntrain_datagen.fit(x_train)","e4a29554":"history = model.fit(\n            train_datagen.flow(x_train,y_train,batch_size = batch_size),\n            validation_data = (x_test,y_test),\n            batch_size = batch_size,\n            steps_per_epoch = x_train.shape[0]\/\/batch_size,\n            epochs = epochs,\n            verbose = 1,\n            callbacks=[learning_rate_reduction]\n            )","a3b7c36a":"model.evaluate(x_test,y_test)","d964bbbd":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","b3ca73da":"plt.figure()\nplt.plot(acc,color = 'green',label = 'Training Acuracy')\nplt.plot(val_acc,color = 'red',label = 'Validation Accuracy')\nplt.legend()","b457294a":"plt.figure()\nplt.plot(loss,color = 'green',label = 'Training Loss')\nplt.plot(val_loss,color = 'red',label = 'Validation Loss')\nplt.legend()\n","a2d598fc":"data = test_data.values\ndata = data.reshape([28000,28,28,1])\nprint(data.shape)\ndata = data\/255","c1b8f69c":"test_pred = model.predict(data)\ntest_pred = np.argmax(test_pred,axis=1)\nprint(test_pred.shape)","7ce2faa9":"sample_submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsample_submission","00348bdb":"index = sample_submission.ImageId\ndata = {'ImageId' : index,'Label': test_pred}\ndf = pd.DataFrame(data)\ndf.head","e55114a9":"df.to_csv('submission2.csv', index=False)","8b4f294f":"# Evaluation and","b5bae651":"# Learning rate reduction","098f71fe":"# Data Agumentation","7fc4890a":"# defining the cnn architecture","82b3f308":"# compiling the model(optimizer=adam)","2bb5b9e1":"# fitting the model"}}