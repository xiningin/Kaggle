{"cell_type":{"d4f2ccec":"code","da621e25":"code","50b0343f":"code","bc29a3d8":"code","7b7a2677":"code","d6152f8e":"code","732f24c9":"code","a1d43a73":"code","15883be3":"code","bfa25d3f":"code","9b186985":"code","cd16de44":"code","708a428c":"code","09a78e7a":"code","5af93c9c":"code","7a909632":"code","29919acd":"code","43e7f0d0":"code","aef68e59":"code","dc2e29d7":"code","d33f0c4d":"code","4ea5723a":"code","462b765e":"code","e9100ceb":"markdown","4fd1739e":"markdown","d4b0648c":"markdown","dc4f3816":"markdown","af19f6ce":"markdown"},"source":{"d4f2ccec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da621e25":"# importing required modules\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error","50b0343f":"insurance = pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')\ninsurance.head()","bc29a3d8":"insurance.shape","7b7a2677":"for i in ['sex','smoker','region']:\n    print(insurance[i].unique())","d6152f8e":"insurance.describe()","732f24c9":"sns.pairplot(insurance);","a1d43a73":"# vizualising the relation of categorical features with the dependent variable\n\nsns.scatterplot(x=insurance['sex'], y=insurance['charges']);","15883be3":"sns.scatterplot(x=insurance['smoker'], y=insurance['charges']);","bfa25d3f":"sns.scatterplot(x=insurance['region'], y=insurance['charges']);","9b186985":"# checking missing values\n\ninsurance.isnull().sum()","cd16de44":"# abstraction of label and features\n\nX, y = insurance.drop('charges', axis=1), insurance.charges\nprint(X.shape, y.shape)","708a428c":"X.head()","09a78e7a":"# encoding categorical values\n\ncolumnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [1,4,5])], remainder='passthrough') \nX = columnTransformer.fit_transform(X)\nX[0:5]","5af93c9c":"#avoiding the dummy variable trap (reduces the dimensionality of the data) with negligible difference in R2-Score\n\nX = np.delete(X, [1,3,4], 1)\nX[0:5]","7a909632":"# splitting the dataset into training and testing data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(y_train.shape, y_test.shape)","29919acd":"# feature scaling\n\nst = StandardScaler()\nX_train = st.fit_transform(X_train)\nX_test = st.transform(X_test)","43e7f0d0":"# finding the best model parameters\n\nscores = []\nfor i in range(2,15):\n    reg = RandomForestRegressor(max_depth=i).fit(X_train, y_train)\n    scores.append(r2_score(y_test, reg.predict(X_test)))\nplt.plot(list(range(2,15)), scores)","aef68e59":"# making the model with the best parameters\n\nreg = RandomForestRegressor(max_depth=4)","dc2e29d7":"# cross validation scores\n\nscores = cross_val_score(reg, X, y, cv=5)\nprint('Cross Validation Scores: {:.3f} {:.3f} {:.3f} {:.3f} {:.3f}'.format(*scores))","d33f0c4d":"# fitting the training data into the model\n\nreg.fit(X_train, y_train)\nprint('Training Data Score: {:.2f}'.format(reg.score(X_train, y_train)))\nprint('Testing Data Score: {:.2f}'.format(reg.score(X_test, y_test)))","4ea5723a":"# most influential features\n\nreg.feature_importances_","462b765e":"# R2-Score of the model and mean_squared_error\n\nprint('R2 Score: {}'.format(r2_score(y_test, reg.predict(X_test))))\nprint('Mean Squared Error: {}'.format(mean_squared_error(reg.predict(X_test),y_test)))","e9100ceb":"# Applying RandomForest Regression and fitting training data to model","4fd1739e":"# Loading the dataset and analysing the values","d4b0648c":"### Applying scatter plots for all the categorical features individually","dc4f3816":"# Visualizing the relation of various features\n\n### Applying pairplot for all the numerical data since it provides a lot of insights about the relation is a single plot which is easy to analyse and compare","af19f6ce":"# Feature Engineering"}}