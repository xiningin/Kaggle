{"cell_type":{"8b8d04ee":"code","42209873":"code","85439bfd":"code","f9f668bf":"code","f9983c05":"code","9bfb453b":"code","36307fbf":"code","4aa0328d":"code","c24a45e8":"code","bfb762fa":"code","4ffb1036":"code","14525ac0":"code","f8d1613c":"code","e4f15df0":"code","d59196fb":"code","fd36aa84":"code","1d8aafd9":"code","b9cdab04":"code","38aa52d2":"code","d08ebe4e":"code","1119c29d":"code","b4a22f2e":"code","1d341d91":"code","2b958cdc":"markdown","5dde8c80":"markdown","f87e668a":"markdown","5f48ac5a":"markdown","7a6dc824":"markdown","5df0304a":"markdown","049e8834":"markdown","d4fa5880":"markdown","08ad0ca8":"markdown","ede33ce9":"markdown","6e213742":"markdown","d929a925":"markdown","7cbbabce":"markdown","066dd38b":"markdown","17a56bcd":"markdown"},"source":{"8b8d04ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import train_test_split\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42209873":"df = pd.read_csv('\/kaggle\/input\/weight-height\/weight-height.csv')\n\ndf.head()","85439bfd":"df['Gender'].value_counts()","f9f668bf":"plt.figure(figsize=(16,10))\nsns.scatterplot(x = df['Height'], y = df['Weight'], hue = df['Gender']);\n#Looks like there is linear relationship between height and weight","f9983c05":"plt.figure(figsize=(16,10))\nsns.kdeplot(x = df['Height'], hue = df['Gender'])","9bfb453b":"plt.figure(figsize=(16,10))\nsns.kdeplot(x = df['Weight'], hue = df['Gender']);","36307fbf":"##One hot encoding\n\ndf_encode = pd.get_dummies(df)\n\ndf_encode.head()","4aa0328d":"#Taking weight Data\nX = df_encode.drop('Weight', axis=1)\ny = df_encode['Weight']","c24a45e8":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=100)","bfb762fa":"def metrics(y_true, y_pred):\n    print('MAE:',mean_absolute_error(y_true, y_pred),'\\n')\n    print('MSE:', mean_squared_error(y_true, y_pred),'\\n')\n    print('RMSE:', np.sqrt(mean_squared_error(y_true, y_pred)),'\\n')\n    \ndef predictions(model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n    model.fit(X_train, y_train)\n    train_pred = model.predict(X_train)\n    test_pred = model.predict(X_test)\n    actual = [ y_train, y_test]\n    pred = [train_pred, test_pred]\n    data = ['Train', 'Test']\n    \n    for i in range(2):\n        print(data[i])\n        metrics(actual[i], pred[i])\n    sns.scatterplot(x=y_test, y=test_pred)\n    plt.show()","4ffb1036":"lr = LinearRegression()\n\ntest_pred=predictions(lr)","14525ac0":"knn = KNeighborsRegressor()\n\npredictions(knn)","f8d1613c":"dtree = DecisionTreeRegressor()\n\npredictions(dtree)","e4f15df0":"rf = RandomForestRegressor()\n\npredictions(rf)","d59196fb":"grad = GradientBoostingRegressor()\n\npredictions(grad)","fd36aa84":"ada = AdaBoostRegressor()\n\npredictions(ada)","1d8aafd9":"li = LGBMRegressor()\npredictions(li)","b9cdab04":"xgb = XGBRegressor()\n\npredictions(xgb)","38aa52d2":"cat = CatBoostRegressor()\n\npredictions(cat)","d08ebe4e":"#Height Data predictions\n\nX_h = df_encode.drop('Height', axis=1)\n\ny_h = df_encode['Height']\n","1119c29d":"X_train, X_test, y_train, y_test = train_test_split(X_h, y_h, test_size = 0.3, random_state=100)","b4a22f2e":"model_list = [lr, knn, dtree, rf, grad, ada, li, xgb, cat]","1d341d91":"for i in model_list:\n    print('----',i,'-----')\n    predictions(i)","2b958cdc":"#### Decision Tree","5dde8c80":"#### KNN","f87e668a":"### Import Data","5f48ac5a":"#### Linear Regression","7a6dc824":"#### Spliting","5df0304a":"**Observation**:\n* Female's weight falls mostly in 140 - 150 range and follows normal distribution.\n* Male's height falls mostly in  190 - 200 range and follows normal distribution.","049e8834":"#### XGBoost","d4fa5880":"#### Modelling","08ad0ca8":"**Observation**:\n* Female's height falls mostly in 60 - 65 range.\n* Male's height falls mostly in 70 - 75 range.","ede33ce9":"#### Gradient Boosting","6e213742":"#### Light GBM","d929a925":"#### CAT Boost","7cbbabce":"#### ","066dd38b":"#### ADA Boost","17a56bcd":"#### Random Forest"}}