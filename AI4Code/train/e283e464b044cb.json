{"cell_type":{"82d1c574":"code","a54c670c":"code","9e700ad1":"code","351786ae":"code","43fc5c46":"code","3ce5b62a":"code","2e63773a":"code","4eb07401":"code","2a447485":"code","7203ed02":"code","bdbfc761":"code","05b12bd8":"code","b25b2115":"code","081930ab":"code","d72e143b":"code","376f8168":"code","b0b41899":"code","a8064acc":"code","3e6d4f8e":"code","f69f52d7":"code","32996e03":"code","d9e63769":"code","ea26e71c":"code","1128e533":"code","de59bc4e":"markdown","9a010fe5":"markdown","1a36c91a":"markdown","f039c743":"markdown","c10ae116":"markdown","b083fc27":"markdown","db7ffb2a":"markdown","5f14e202":"markdown","6babc3dd":"markdown","2cc72b25":"markdown","7687c7a8":"markdown","9073c3a8":"markdown","54dc6efd":"markdown","6b7579af":"markdown","7b05ce6a":"markdown","5938390b":"markdown","98e607f8":"markdown","44a2a51f":"markdown","d284eaf1":"markdown","bbe2489b":"markdown","4b2ff61e":"markdown","89e57df6":"markdown","b904e7cd":"markdown","5df4f7d1":"markdown"},"source":{"82d1c574":"## Data and Visualization\nimport pandas as pd \npd.options.mode.chained_assignment = None  # default='warn'\nimport numpy as np\n%config InlineBackend.figure_format = 'retina'\n## Pre processing \nimport re\nimport nltk\nfrom nltk.stem.porter import *\nfrom utils_data import prepare_data, downsample_2, downsample_num_2, review_to_words, Rating_augment,CustomStop\nfrom utils_ml import ML_PipeLine, PrepareBinaryClassificationResults, BinaryClassificationResults\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport random","a54c670c":"data_all = pd.read_csv('..\/input\/consumer-reviews-of-amazon-products\/1429_1.csv', dtype = {'name': object, 'reviews.didPurchase': np.float})\ndata_all.head(2)","9e700ad1":"data = prepare_data(filename = '..\/input\/consumer-reviews-of-amazon-products\/1429_1.csv', label_map = {1: 'Neg', 2: 'Neg', 3: 'Neg', 4:'Pos', 5:'Pos'})\ndata.head(5)","351786ae":"data_review_clean = data['Reviews'].apply(lambda x: review_to_words(x))\ndata_cleaned = pd.concat([data_review_clean, data['Label']], axis = 1)\ndata_cleaned.head(5)","43fc5c46":"data_cleaned['Label'].hist();","3ce5b62a":"implance_ratio = data_cleaned.Label.value_counts()['Pos']\/data_cleaned.Label.value_counts()['Neg']\nprint('Implance ratio = {:.2f}'.format(implance_ratio))","2e63773a":"CustomStopWords = CustomStop(data_all, columns = ['categories', 'brand', 'name'])\nrandom.sample(CustomStopWords, 5)","4eb07401":"vocabulary_size = 10000\nvectorizer = CountVectorizer(max_features = vocabulary_size, \n                             preprocessor = lambda x: x, \n                             tokenizer = lambda x:x)","2a447485":"clf1 = GaussianNB()\nn_estimators = 100\nclf2 = GradientBoostingClassifier(n_estimators = n_estimators, learning_rate = 1.0, max_depth = 1, random_state=0)","7203ed02":"data_review_clean_ML = data['Reviews'].apply(lambda x: review_to_words(x, CustomStop = CustomStopWords))\nlabel_map = {'Neg': 0, 'Pos': 1}\ndata_cleaned_ML = pd.concat([data_review_clean_ML, data['Label'].map(label_map)], axis = 1)\ndata_cleaned_ML.head(5)","bdbfc761":"embedding1_trained, clf1_trained, Results1, Data1 = ML_PipeLine(data_cleaned_ML, \n                                                                embedding = vectorizer, \n                                                                clf =  clf1)","05b12bd8":"BinaryClassificationResults(Results1)","b25b2115":"embedding2_trained, clf2_trained, Results2, Data2 = ML_PipeLine( data_cleaned_ML,\n                                                                 embedding = vectorizer,\n                                                                 clf =  clf2)","081930ab":"BinaryClassificationResults(Results2)","d72e143b":"data_cleaned_undersampled_ML = downsample_num_2(data_cleaned_ML)\ndata_cleaned_undersampled_ML['Label'].hist();","376f8168":"embedding3_trained, clf3_trained, Results3, Data3 = ML_PipeLine(data_cleaned_undersampled_ML, \n                                                                embedding = vectorizer, \n                                                                clf =  clf1)","b0b41899":"BinaryClassificationResults(Results3)","a8064acc":"embedding4_trained, clf4_trained, Results4, Data4 = ML_PipeLine(data_cleaned_undersampled_ML, \n                                                                embedding = vectorizer, \n                                                                clf =  clf2)","3e6d4f8e":"BinaryClassificationResults(Results4)","f69f52d7":"import pickle as pk","32996e03":"pk.dump([clf1_trained, clf2_trained, clf3_trained, clf4_trained], open('Model_Training_Models.p', \"wb\"))","d9e63769":"pk.dump([embedding1_trained.vocabulary_, embedding2_trained.vocabulary_, embedding3_trained.vocabulary_, embedding4_trained.vocabulary_], open('Model_Training_Vectorizers.p', \"wb\"))\n","ea26e71c":"pk.dump([Results1, Results2, Results3, Results4], open('Model_Training_Results.p', \"wb\"))","1128e533":"pk.dump([Data1, Data2, Data3, Data4], open('Model_Training_Data.p', \"wb\"))","de59bc4e":"<a id='ml_data'><\/a>\n## Machine Learning Data With Custom Stop Words","9a010fe5":"<a id='binary_prep'><\/a>\n## Read and prepare the data for a binary classification problem","1a36c91a":"# <u>Made by<\/u> :  <center> Omar Khater <\/center>","f039c743":"<a id ='imb_NB'><\/a>\n## Evaluating Imbalanced Data Set With Naive Bayes Classifier","c10ae116":"This is the second part of the project [Sentiment Analysis With Consumer Reviews of Amazon Products](https:\/\/www.kaggle.com\/omarayman67\/basic-machine-learning-pipeline) which covers the basic machine learning pipeline on both imbalanced and down sampled datasets.\n\nThe next stage is to [combine upsampling and down sampling](https:\/\/www.kaggle.com\/omarayman67\/machine-learning-with-more-data)","b083fc27":"<a id ='cleansing'><\/a>\n\n---\n# <center> Data Cleansing <\/center>\n---","db7ffb2a":"<a id='label_dist'><\/a>\n## Label Distribution And Implance Ratio","5f14e202":"## Table of Contents\n<ul>\n<li><a href=\"#intro\">Introduction<\/a><\/li>\n    \n<li><a href=\"#cleansing\">Data Cleansing<\/a><\/li>\n    - <a href=\"#binary_prep\">Read and prepare the data for a binary classification problem <\/a><br>\n    - <a href=\"#clean_raw\">Clean raw reviews string <\/a><br>\n    - <a href=\"#label_dist\">Label Distribution And Implance Ratio<\/a><br>\n    - <a href=\"#custom_stop\">Derive Custom Stop Words <\/a><br>\n    \n  \n<li><a href=\"#ml_pipe\">Basic Machine Learning Pipeline <\/a><\/li>\n    - <a href=\"#initialize\"> Count Vectorizer And 2 Different Classifiers <\/a><br>\n    - <a href=\"#ml_data\"> Machine Learning Data With Custom Stop Words <\/a><br>\n    - <a href=\"#imb_NB\">Evaluating Imbalanced Data Set With Naive Bayes Classifier <\/a><br>\n    - <a href=\"#imb_boost\">Evaluating Imbalanced Data Set With Boosting Trees Classifier <\/a><br>\n\n<li><a href=\"#improve\">Improving Results <\/a><\/li>    \n    - <a href=\"#downsampling\">Down Sampling <\/a><br>\n<\/ul>","6babc3dd":"This step performs basic processing such as HTML tags as well as non-letters removal. In addition, it performs text normalization (i.e. convert uper case chars to lower case) as well as removing stop words. Finally, it performs word stemming to avoid dealing with multiple versions of the same word. The review after this process still not read for the machine learning pipeline it is still continuous string (i.e. it is not tokenized).  ","2cc72b25":"### Evaluating Down Sampled Data Set With Naive Bayes Classifier","7687c7a8":"# <center>Sentiment Analysis With Consumer Reviews of Amazon Products<\/center>\n## <center> 2- Model Training \n    \n<figure class=\"image\">\n    <table><tr>\n    <td> <img src=\"https:\/\/i.ibb.co\/Jtjh90Y\/model-training.png\" alt=\"model_training\" style=\"width: 800px;\"\/> <\/td>   \n    <\/tr><\/table>\n<\/figure>","9073c3a8":"<a id ='intro'><\/a>\n\n---\n# <center> Introduction <\/center>\n---","54dc6efd":"<a id='custom_stop'><\/a>\n## Derive Custom Stop Words","6b7579af":"The original data set contains a lot of information about the given reviews such as the categories of the reviewed products as well as the brands and names involved in the data set. However, these words will not be of a great value to the required classifier since it is irrelevant to the semantic of the reviwer,yet they affect the words distribution in. Thus, it would be beneficial for the model to remove them in addition to normal stop words in the English language. ","7b05ce6a":"<a id='ml_pipe'><\/a>\n\n---\n# <center> Basic Machine Learning Pipeline <\/center>\n---","5938390b":"<a id='initialize'><\/a>\n## Count Vectorizer And 2 Different Classifiers","98e607f8":"<a id='imb_boost'><\/a>\n## Evaluating Imbalanced Data Set With Boosting Trees Classifier","44a2a51f":"<a id='improve'><\/a>\n\n---\n# <center> Improving Results <\/center>\n---","d284eaf1":"## Importing ","bbe2489b":"<a id='downsampling'><\/a>\n## Down Sampling ","4b2ff61e":"<a id='clean_raw'><\/a>\n## Clean raw reviews string","89e57df6":"### Evaluating Down Sampled Data Set With Boosting Trees Classifier","b904e7cd":"### Classes Distribution","5df4f7d1":"### Saving Results"}}