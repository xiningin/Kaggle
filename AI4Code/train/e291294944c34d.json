{"cell_type":{"efbfea93":"code","815cb03a":"code","ca736a9c":"code","4a154f52":"code","da5941a9":"code","54965586":"code","99d2d5a2":"code","293ec5e7":"code","a7a5bc8b":"code","46e9bb77":"code","95ef987b":"code","bbc6ff86":"code","46ecc4a4":"code","00e18eec":"code","5edf2942":"code","8b02a5f8":"code","8e9558a4":"code","4ffa7cf1":"markdown","3e8e8e09":"markdown","91d04ba6":"markdown","5a37a03e":"markdown","88bed8a0":"markdown","88d5e787":"markdown","fda40b39":"markdown","19528aee":"markdown"},"source":{"efbfea93":"!pip install pytorch-transformers","815cb03a":"import torch\nfrom pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n\ndef load_pretrained(model='bert-base-uncased'):\n    # Load pre-trained model tokenizer (vocabulary)\n    tokenizer = BertTokenizer.from_pretrained(model)\n    # Load pre-trained model (weights)\n    model = BertForMaskedLM.from_pretrained(model)\n    model.eval()\n    return tokenizer, model\n\nen_tokenizer, en_model = load_pretrained('bert-base-uncased')\n\ndef predict(text, tokenizer=en_tokenizer, model=en_model):\n    text = \"[CLS] \" + text + \" [SEP]\"\n    tokenized_text = tokenizer.tokenize(text)\n    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n\n    # Create the segments tensors.\n    segments_ids = [0] * len(tokenized_text)\n\n    # Convert inputs to PyTorch tensors\n    tokens_tensor = torch.tensor([indexed_tokens])\n    segments_tensors = torch.tensor([segments_ids])\n\n    # If you have a GPU, put everything on cuda\n    tokens_tensor = tokens_tensor.to('cuda')\n    segments_tensors = segments_tensors.to('cuda')\n    model.to('cuda')\n\n    # Predict all tokens\n    with torch.no_grad():\n        predictions = model(tokens_tensor, segments_tensors)\n\n    masked_index = tokenized_text.index('[MASK]') \n\n    predicted_index = torch.argmax(predictions[0][0][masked_index]).item()\n    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n\n    return predicted_token","ca736a9c":"predict('I want to [MASK] the car')","4a154f52":"predict('I want to [MASK] the car because it is cheap')","da5941a9":"predict('I want to [MASK] the car because it is cheap.')","54965586":"multilingual_tokenizer, multilingual_model = load_pretrained('bert-base-multilingual-cased')\ndef multilingual_predict(text):\n    return predict(text, multilingual_tokenizer, multilingual_model)","99d2d5a2":"multilingual_predict(\"\u5b89\u3044\u304b\u3089\u3053\u306e\u8eca\u3092[MASK]\u3044\u305f\u3044\")","293ec5e7":"multilingual_predict(\"\u5f7c\u306f\u65e5\u672c[MASK]\u3092\u6bcd\u56fd\u8a9e\u3068\u3057\u3066\u8a71\u3059\")","a7a5bc8b":"multilingual_predict(\"\u5f7c\u306f\u512a\u3057\u304f\u3066\u53ef\u611b\u3044\u5f7c\u5973\u3092\u3068\u3066\u3082[MASK]\u304d\u306b\u306a\u308a\u307e\u3057\u305f\u3002\")","46e9bb77":"multilingual_predict(\"\u5f7c\u306f\u919c\u304f\u3066\u308f\u304c\u307e\u307e\u306a\u5f7c\u5973\u3092\u3068\u3066\u3082[MASK]\u3044\u306b\u306a\u308a\u307e\u3057\u305f\u3002\")","95ef987b":"multilingual_predict('I want to [MASK] the car because it is cheap.')","bbc6ff86":"multilingual_predict(\"T\u00f4i mu\u1ed1n [MASK] c\u00e1i \u00f4 t\u00f4 v\u00ec n\u00f3 r\u1ea5t r\u1ebb.\")","46ecc4a4":"multilingual_predict(\"T\u00f4i y\u00eau ti\u1ebfng [MASK] v\u00ec t\u00f4i l\u00e0 ng\u01b0\u1eddi Vi\u1ec7t.\")","00e18eec":"multilingual_predict(\"T\u00f4i r\u1ea5t [MASK] m\u1ebfn c\u00f4 g\u00e1i \u1ea5y.\")","5edf2942":"cn_tokenizer, cn_model = load_pretrained('bert-base-chinese')\n\ndef cn_predict(text):\n    return predict(text, cn_tokenizer, cn_model)","8b02a5f8":"cn_predict(\"\u6211[MASK]\u4f60\uff0c\u56e0\u4e3a\u4f60\u5f88\u6f02\u4eae\") # \u7231","8e9558a4":"cn_predict(\"\u6211[MASK]\u4f60\")","4ffa7cf1":"# \u82f1\u5358\u8a9e\u306e\u4e88\u6e2c","3e8e8e09":"# \u7d50\u8ad6\n\n- \u82f1\u8a9eOK\n- \u30d9\u30c8\u30ca\u30e0\u8a9e\u307e\u3042\u307e\u3042\n- \u65e5\u672c\u8a9e\u3044\u307e\u3044\u3061\n- \u4e2d\u56fd\u8a9e\u3044\u307e\u3044\u3061","91d04ba6":"# \u65e5\u672c\u8a9e\u6587\u5b57\u306e\u4e88\u6e2c","5a37a03e":"# \u30d9\u30c8\u30ca\u30e0\u8a9e\u306e\u4e88\u6e2c","88bed8a0":"# Google\u672c\u5bb6\u306eBERT\u3067\u65e5\u672c\u8a9e\u6587\u5b57\u3092\u4e88\u6e2c\n\n\u9053\u5177\n\n- https:\/\/github.com\/huggingface\/pytorch-transformers\n- https:\/\/github.com\/google-research\/bert\/blob\/master\/multilingual.md\n\n\u53c2\u8003\n\n- https:\/\/stackoverflow.com\/questions\/54978443\/predicting-missing-words-in-a-sentence-natural-language-processing-model","88d5e787":"# \u4e2d\u56fd\u8a9e\u306e\u4e88\u6e2c","fda40b39":"\u6f22\u5b57\u304c\u51fa\u3066\u304d\u305f\u306e\u3067\u3059\u304c\u3001\u671f\u5f85\u3057\u3066\u3044\u305f\u300c\u7231\u300d\u307e\u305f\u306f\u300c\u611b\u300d\u3067\u306f\u306a\u3044\u3067\u3059\u3002","19528aee":"multilingual model \u3067\u82f1\u8a9e\u306e\u8a00\u8449\u3092\u4e88\u6e2c\u3057\u3066\u307f\u305f\u3089\u3001\u82f1\u8a9e\u30e2\u30c7\u30eb\u3068\u306f\u7570\u306a\u308b\u7d50\u679c\u306b\u306a\u308a\u307e\u3057\u305f\u3002"}}