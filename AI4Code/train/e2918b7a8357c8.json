{"cell_type":{"16e2c889":"code","6d0fc6ca":"code","55e1018f":"code","ab323c55":"code","863efe5a":"code","9b580155":"code","2da39897":"code","b889c99e":"code","41bdc6db":"code","6a83e65b":"code","499439d8":"code","f4d656af":"code","66f96418":"code","73ccb622":"code","a16f6480":"markdown","cf898e60":"markdown","80f06510":"markdown","b817add5":"markdown"},"source":{"16e2c889":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d0fc6ca":"eff_b0_path = \"..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth\"\npackage_path = \"..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\/\"\nimport sys \nsys.path.append(package_path)\nimport sys \nimport os \nimport glob \nimport time \nimport random \nimport numpy as np \nimport pandas as pd \nimport pydicom \nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2 \n\nimport torch \nfrom torch import nn \nfrom torch.utils import data as torch_data \nfrom torch.nn import functional as F \n\nimport efficientnet_pytorch\n\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom tqdm import tqdm ","55e1018f":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","ab323c55":"img_size = 256 \nn_frames = 10 \ncnn_features = 256 \nlstm_hidden = 32 \nn_fold = 5 \nn_epochs = 10 ","863efe5a":"device","9b580155":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.map = nn.Conv2d(in_channels = 4 , out_channels = 3 , kernel_size = 1 )\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n        checkpoint = torch.load('..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth')\n        self.net.load_state_dict(checkpoint)\n        n_features = self.net._fc.in_features \n        self.net._fc = nn.Linear(in_features = n_features , out_features = cnn_features)\n    \n    def forward(self, x ):\n        x = F.relu(self.map(x))\n        out = self.net(x)\n        return out \n\n    \nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.cnn = CNN()\n        self.rnn = nn.LSTM(cnn_features , lstm_hidden , 2, batch_first = True)\n        self.fc = nn.Linear(lstm_hidden, 1, bias = True)\n        \n    def forward(self, x):\n        batch_size , timesteps, C, H, W = x.size() \n        c_in = x.view(batch_size* timesteps , C, H, W)\n        c_out = self.cnn(c_in)\n        r_in = c_out.view(batch_size, timesteps, -1)\n        output , (hn,cn) = self.rnn(r_in)\n        out = self.fc(hn[-1])\n        return out","2da39897":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n        \n    data = np.float32(cv2.resize(data, (CFG.img_size, CFG.img_size)))\n    return torch.tensor(data)\n\ndef load_dicom_line(path):\n    t_paths = sorted(\n        glob.glob(os.path.join(path, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    images = []\n    for filename in t_paths:\n        data = load_dicom(filename)\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images","b889c99e":"class DataRetrival(Dataset):\n    def __init__(self, paths,targets , transform = None):\n        self.paths = paths \n        self.transform = transform\n        self.targets = targets\n    \n    def __len__(self):\n        return len(self.paths)\n    \n    def read_in(self,image_paths):\n        total_img = [load_dicom(path) for path in image_paths]\n        \n        if len(total_img) == 0 :\n            total_img = torch.zeros(n_frames , img_size , img_size)\n        \n        else: \n            total_img = torch.stack(total_img)\n        \n        return total_img\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/{str(_id).zfill(5)}\/\"\n        channels = [] \n        for t in [\"FLAIR\",\"T1w\", \"T1wCE\", \"T2w\"]:\n            t_paths = sorted(\n                glob.glob(os.path.join(patient_path, t, \"*\")), \n                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n            )\n            \n            num_samples = n_frames \n            if len(t_paths) < num_samples:\n                in_frames_path = t_paths \n            else:\n                in_frames_paths = uniform_temporal_subsample(t_paths , num_samples)\n            \n            channel = self.read_in(in_frames_path)\n            if channel.shape[0] == 0 :\n                print('1 channel empty')\n                channel = torch.zeros(num_samples , img_size, img_size)\n            \n            channels.append(channel)\n        channels = torch.stack(channels).transpose(0,1)\n        \n        y = torch.tensor(self.targets[index] , dtype = torch.float)\n        return {\"X\" : channels.float(), \"y\": y}","41bdc6db":"df = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\")","6a83e65b":"df","499439d8":"train_loader = torch_data.DataLoader(\n    DataRetrival(df['BraTS21ID'].values,\n                df['MGMT_value'].values\n                ),\n    batch_size = 8 , \n    num_workers = 4, \n    shuffle= True\n)","f4d656af":"def train_loop(epochs , model , optimizer , dataloader , loss):\n    model = model.to(device)\n    if optimizer == \"adam\":\n        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n    model.train()\n    \n    for epoch in tqdm(range(epochs)):\n        for step, data in enumerate(dataloader):\n            X = data['X'].to(device)\n            targets = data['y'].to(device)\n            optimizer.zero_grad()\n            outputs = model(X).squeeze(1)\n            data_loss = loss(outputs, targets)\n            data_loss.backward()\n            \n            optimizer.step()\n        \n        if (epoch%3 == 0):\n            print(f'epoch no {epoch+1} completed at {time.time()}')","66f96418":"model = Model()\ntrain_loop(epochs = n_epochs ,\n           model = model ,\n           optimizer = \"adam\" ,\n           dataloader = train_loader,\n           loss = F.binary_cross_entropy_with_logits)\n","73ccb622":"torch.save(model,\".\/efficient_net_b0_model.pth\" )","a16f6480":"# Importing required libraries ","cf898e60":"# creating the training loop \n","80f06510":"# device selection ","b817add5":"# creating the model "}}