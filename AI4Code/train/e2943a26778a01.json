{"cell_type":{"e0302bf1":"code","e4fb0baf":"code","844307fb":"code","51c2bf95":"code","45445bab":"code","7e00a254":"code","08b9024e":"code","96f7a3ff":"code","1061cabd":"code","44a5e342":"code","52f8b309":"code","acfce00c":"code","cd2beb0c":"code","d06fd7dd":"code","de839e7d":"code","546fdafb":"code","f555ea87":"code","cf92e5fb":"code","9cb4a487":"code","1cfc756c":"code","e46ddac0":"code","421e1062":"code","a88ffe3e":"code","2c9f2cc1":"code","f6146b8e":"code","fa7e3189":"code","e8599c3b":"code","5e559326":"code","15934b21":"code","7850dddc":"code","4c4429f3":"code","4a8abddd":"code","4ec3e9c4":"code","54055bec":"code","401acf0b":"code","151bfbad":"code","d8dc5d5e":"code","79ca58ec":"code","88f69e2d":"code","372fa6ae":"code","bdb97670":"code","37235df6":"code","e6598e42":"code","10ebccae":"code","bdc2f335":"code","4f497479":"code","1ee39d15":"code","da9bc3cc":"code","ada83068":"code","49df3361":"code","8c26b45e":"code","acff7b77":"code","1bfada20":"code","06736836":"code","66a12a62":"code","2965079b":"code","13ac2abe":"code","6a2386a1":"code","d198183d":"code","236785a3":"code","d77b1279":"code","9a38df28":"code","3472f758":"code","3878b641":"code","ce4f7e82":"code","8dbd0ccb":"code","0fc1b6e0":"code","b497e6d7":"code","2f952a2e":"code","e3b7a7da":"code","3ad7c69b":"code","7b7702f5":"code","4252dcd0":"code","b607ade3":"code","ccd71cdf":"code","19abf0d4":"code","01d7004f":"code","fdeae118":"code","2855f111":"code","ee9fb901":"markdown","bff52c98":"markdown","f31a0dc0":"markdown","87522790":"markdown","fea3cf70":"markdown","3097e143":"markdown","e573652e":"markdown","eac6aa38":"markdown","747bfe3d":"markdown"},"source":{"e0302bf1":"import pandas as pd","e4fb0baf":"import numpy as np\nimport pandas as pd","844307fb":"# importing Train data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.head(5)","51c2bf95":"# importing Test data\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntest.head(5)","45445bab":"# Checking number of row and column of train dataset in (r x c)\ntrain.shape","7e00a254":"# Checking number of row and column of test dataset in (r x c)\ntest.shape","08b9024e":"# Show all column names of train dataset\ntrain.columns.tolist()","96f7a3ff":"# Show all column names of test dataset\ntest.columns.tolist()","1061cabd":"# Informations about the train dataset columns\ntrain.info()","44a5e342":"# Informations about the train dataset columns\ntest.info()","52f8b309":"# Checking for missing value\ntrain.isnull().sum()","acfce00c":"# Checking for missing value\ntest.isnull().sum()","cd2beb0c":"# Some more library funtions\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()","d06fd7dd":"# I am now creating a function which will return a barchart with survived columns data\ndef bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived, dead])\n    df.index = (['Survived', 'Dead'])\n    df.plot(kind='bar', stacked=True, figsize=(10,5))","de839e7d":"bar_chart('Sex')","546fdafb":"bar_chart('Pclass')","f555ea87":"bar_chart('SibSp')","cf92e5fb":"bar_chart('Parch')","9cb4a487":"bar_chart('Embarked')","1cfc756c":"# Creating a new dataset having all the data from train and test dataset\ntrain_test_data = [train, test]\n\n# Creating another cell 'Title' to keep track of peoples title from their name and can be used later\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.', expand=False)","e46ddac0":"# Counting title from train dataset\ntrain['Title'].value_counts()","421e1062":"# Counting title from test dataset\ntest['Title'].value_counts()","a88ffe3e":"# putting titles as numbers. because numbers are easy to process\ntitle_mapping = {\"Mr\": 0, \"Miss\":1, \"Mrs\": 2, \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \n                 \"Major\": 3, \"Mlle\": 3, \"Col\": 3, \"Jonkheer\": 3, \"Capt\": 3, \n                 \"Mme\": 3, \"Ms\": 3, \"Sir\": 3, \"Countess\": 3, \"Lady\": 3, \n                 \"Don\": 3, \"Dona\": 3}\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","2c9f2cc1":"train.head()","f6146b8e":"test.head()","fa7e3189":"bar_chart('Title')","e8599c3b":"# Dropping 'Name' column as it may not be needed in processing data\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","5e559326":"# Checking again\ntrain.head()","15934b21":"test.head()","7850dddc":"# replacing 'Sex' column with male = 0 and female = 1\nsex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","4c4429f3":"bar_chart('Sex')","4a8abddd":"# Filling missing age data with median value\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","4ec3e9c4":"train.head(10)","54055bec":"train.groupby(\"Title\")[\"Age\"].transform(\"median\")\ntrain.head(10)","401acf0b":"# Age\nfacet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n\nplt.show()","151bfbad":"# Age but this time changing limit on X axis\nfacet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, 20))\nfacet.add_legend()\n\nplt.show()","d8dc5d5e":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, 30))\nfacet.add_legend()\n\nplt.show()","79ca58ec":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, 40))\nfacet.add_legend()\n\nplt.show()","88f69e2d":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(20, 30))\nfacet.add_legend()\n\nplt.show()","372fa6ae":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","bdb97670":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, 30))\nfacet.add_legend()\n\nplt.show()","37235df6":"train.info()","e6598e42":"test.info()","10ebccae":"# Grouping 'Age' in 5 groups\nfor dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","bdc2f335":"train.head()","4f497479":"bar_chart('Age')","1ee39d15":"# Barchart according to embarked port and class\nPclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st Class', '2nd Class', '3rd Class']\ndf.plot(kind = 'bar', stacked=True, figsize=(10,5))\nplt.show()","da9bc3cc":"# Filling missing ports with S \nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","ada83068":"train.head()","49df3361":"train.info()","8c26b45e":"# REplacing embarked ports with numbers\nembarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","acff7b77":"train.head()","1bfada20":"# Filling missing 'Fare' values with median of the same group\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head()","06736836":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot,'Fare', shade = True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n\nplt.show()","66a12a62":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","2965079b":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","13ac2abe":"# Grouping customers by their paid 'Fare'\nfor dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","6a2386a1":"train.head()","d198183d":"# Counting Cabins\ntrain.Cabin.value_counts()","236785a3":"# Only taking the cabin code elemeniting the numbers(C23, C25, C27 == C)\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","d77b1279":"# Plotting cabin numbers in a barchart\nPclass1 = train[train['Pclass'] == 1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass'] == 2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass'] == 3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))\nplt.show()","9a38df28":"# Replacing cabin codes with numbers again\ncabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","3472f758":"# Filling missing cabin numbers\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","3878b641":"# Counting family size by adding 'SibSp'and 'Parch' columns\ntrain[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","ce4f7e82":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","8dbd0ccb":"# replacing family size with more usuable values\nfamily_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping) ","0fc1b6e0":"train.head()","b497e6d7":"# Dropping unnecesary columns\nfeatures_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)\ntest = test.drop(features_drop, axis=1)","2f952a2e":"# 'train_data' will serve as new test data and 'target' as output\ntrain_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","e3b7a7da":"train_data.head()","3ad7c69b":"# Importing Classifier Modules\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\ntrain.info()","7b7702f5":"# Importing modules\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n'''Splitting total dataset into 10 sections (row wise) \nand using 9 of them as training and 1 of them as test \ndataset serially'''\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","4252dcd0":"# Initializing DecisionTreeClassifier model\nclf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","b607ade3":"round(np.mean(score)*100, 2)","ccd71cdf":"# Initializing RandomForestClassifier model\nclf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","19abf0d4":"round(np.mean(score)*100, 2)","01d7004f":"# Fitting RandomForestClassifier model\nclf = RandomForestClassifier(n_estimators=13)\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","fdeae118":"# Creating submission file\nsubmission = pd.DataFrame({\n    \"PassengerId\": test[\"PassengerId\"],\n    \"Survived\": prediction\n})\n\nsubmission.to_csv('submission.csv', index=False)","2855f111":"# Checking submission file\nsubmission = pd.read_csv('submission.csv')\nsubmission.head()","ee9fb901":"## **Model utilisation**","bff52c98":"## **Again visualisation**","f31a0dc0":"## **5. Data preprocessing**","87522790":"## **2. Libraries**\n\nAt first I will import some commonly used and most frequently needer library functions. If I need something other than these libraries I'll import them later","fea3cf70":"## **1. Introduction**\nThis is the legendary Titanic ML competition \u2013 the best, first challenge for a kaggle user to dive into ML competitions and familiarize oneself with how the Kaggle platform works.\n\nThe competition is simple: user have to use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n","3097e143":"**All the bar charts**","e573652e":"### 1.2. Data Dictionary\n* 'Survival': 0 = No, 1 = Yes\n* 'Pclass': Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n* 'Sex': Sex\n* 'Age': Age in years\n* 'SibSp': # of siblings \/ spouses aboard the Titanic\n* 'Parch': # of parents \/ children aboard the Titanic\n* 'Ticket': Ticket number\n* 'Fare': Passenger fare\n* 'Cabin': Cabin number\n* 'Embarked': Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton","eac6aa38":"## **4. Data visualisation**","747bfe3d":"## **3. Loading and observing data**"}}