{"cell_type":{"cc9119b0":"code","e3690a17":"code","dd8475c5":"code","5d166e70":"code","c170b97e":"code","4d2796d1":"code","9aaf2c35":"code","82b1a341":"code","e8a590da":"code","dc408a27":"code","e2e5995e":"code","0e798738":"code","cc764a9f":"markdown","7083741f":"markdown","35b33b55":"markdown","b3d09894":"markdown","2a99eb3a":"markdown","225cce45":"markdown","c0a4e982":"markdown","e4d73faf":"markdown"},"source":{"cc9119b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e3690a17":"train_data = pd.read_csv(r'..\/input\/nlp-getting-started\/train.csv')\ntest_data = pd.read_csv(r'..\/input\/nlp-getting-started\/test.csv')\ntrain_data.head()","dd8475c5":"test_data.head()","5d166e70":"#   Sentence length in \ntext = train_data['text']\ntext.str.len().hist()","c170b97e":"# Word length Analysis\nimport matplotlib.pyplot as plt\narr = [ ]\nfor i in text:\n    \n    tmp = i.split(' ')\n    arr.append(len(tmp))\nplt.grid()\nplt.hist(arr)","4d2796d1":"!pip install nltk\nimport nltk \nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nstop = set(stopwords.words('english'))","9aaf2c35":"import numpy as np\ncorpus = []\ntmp = []\nfor i in text : \n    tmp.append(i.split())\n    \nfor i in tmp:\n    for words in i :\n        corpus.append(words)\nfrom collections import defaultdict\ndic = defaultdict(int)\nfor i in corpus: \n    if i in stop :\n        dic[i] = dic[i] + 1\nval = dic.values()\nval = sorted(val,reverse = True)\nval = val[0:11]\nd = {}\nfor i in list(dic.keys()):\n    if dic[i] in val: \n        d[i] = dic[i]\n# Top 10 Stopwords in corpus\nplt.bar(list(d.keys()), list(d.values()))","82b1a341":"#bigrams, trigrams\nfrom nltk.util import ngrams\nimport collections\ntex = ''\n#word_tokenize = nltk.download('word_tokenize')\nfor i in text : \n    tex = tex + str(i.strip('[]'))\ntok = tex.split()\nb_grams = ngrams(tok, 2) \nt_grams = ngrams(tok,3)\nbigrams = collections.Counter(b_grams)\ntrigrams = collections.Counter(t_grams)\nbi= bigrams.most_common(10)\nti= trigrams.most_common(10)\n#biti\n","e8a590da":"def plot_ngrams(bi):\n    word = []\n    idx = []\n    for i in range(len(bi)):\n        word.append(str(bi[i][0]))\n        idx.append(bi[i][1])\n    plt.figure(figsize = (10,8))\n    plt.bar(word,idx)\n    plt.xticks(word, word, rotation = 'vertical')\n    plt.xlabel('Ngrams')\n    plt.ylabel('Frequency')\n    plt.title('Ngram with Frequency')\n    plt.show()\nplot_ngrams(bi)\n","dc408a27":"plot_ngrams(ti)","e2e5995e":"# Hastags from Tweets \nimport re  \na = ''\nfor i in range(len(text)):\n    tmp = re.search(r'#[a-zA-Z0-9]*', text[i])\n    #print(tmp)\n    if tmp is not None :  \n        tm = re.sub(r'#','' ,tmp.group())\n        a = a + str(tm)+ ' '\n    else: \n        a = a + ''\nfrom wordcloud import WordCloud, STOPWORDS\nstopwords = train_data['keyword'].unique()\nwordcloud = WordCloud()\nwordcloud=wordcloud.generate(a)\n\nfig = plt.figure(1, figsize=(12, 12))\nplt.axis('off')\n\nplt.imshow(wordcloud)\nplt.show()","0e798738":"from textblob import TextBlob\npo = []\nfor i in text : \n    analysis = TextBlob(i)\n    po.append(analysis.sentiment.polarity)\ndic = { 'polarity': po, 'Tweets': text }\nplt.plot(po[:20])","cc764a9f":"## <a id='5' >Trigrams <\/a>","7083741f":"## <a id = '6'> Hastags from Tweets <\/a>","35b33b55":"## <a id='8'> Sentiment Analysis <\/a>","b3d09894":"## **Table of Contents :** \n\n*      <a href=\"#1\">1. Tweets Length Analysis <\/a>\n\n*      <a href=\"#2\">2. Word Length Analysis <\/a>\n\n*      <a href=\"#3\">3. Top 10 Stopwords in Corpus <\/a>\n\n*      <a href=\"#4\">4. Bigrams <\/a>\n\n*      <a href=\"#5\">5. Trigrams <\/a>\n\n*      <a href=\"#6\">6. Hastags from Tweets <\/a>\n\n*      <a href=\"#7\">7. Wordcloud <\/a>\n\n*      <a href=\"#8\">8. Sentiment Analysis <\/a>\n","2a99eb3a":"## <a id = '4'> Bigrams <\/a>","225cce45":"##  <a id = '1' > Tweets Length Analysis<\/a>","c0a4e982":"## <a id ='3' >Top 10 Stopwords in Corpus <\/a>","e4d73faf":"## <a id= '2' >Word Length Analysis <\/a>"}}