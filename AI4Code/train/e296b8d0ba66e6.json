{"cell_type":{"a717e3d9":"code","786434d2":"code","6b15384d":"code","d7f9a1a2":"code","89191f83":"code","97b7d3b8":"code","073b05a0":"code","fa33a007":"code","1263e83d":"code","a39a5070":"code","e7339cc6":"code","f27b3790":"code","fa6d0574":"code","3ca85e93":"code","76c15cc7":"code","22b6994c":"code","6f61ba9d":"code","e299c079":"code","d6b29f96":"code","e1511b96":"code","3e800393":"code","4f21b924":"markdown","1f1696cd":"markdown","6a9a7a2d":"markdown","2e61429e":"markdown","ed25d560":"markdown","7028af2c":"markdown","e2c1ab3c":"markdown","bb05d806":"markdown","5b07e0d4":"markdown","b947e1b6":"markdown","f700cc8a":"markdown","0ac88ef3":"markdown","4e2ce30e":"markdown","79f21bf0":"markdown","7dd8f966":"markdown","bd73fe2b":"markdown","bb2ade37":"markdown","f57aa3c3":"markdown"},"source":{"a717e3d9":"!pip install numerapi\nimport numerapi","786434d2":"import numpy as np\nimport pandas as pd\nimport os, sys\nimport gc\nimport pathlib\nfrom typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, QuantileTransformer\nfrom sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit\nfrom sklearn.metrics import accuracy_score, roc_auc_score, log_loss, mean_squared_error, mean_absolute_error, f1_score\nfrom scipy.stats import spearmanr\nimport joblib\n\n# model\nimport lightgbm as lgb\nimport xgboost as xgb\nimport operator\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('seaborn-colorblind')\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6b15384d":"def get_int(x):\n    try:\n        return int(x[3:])\n    except:\n        return 1000\n    \ndef read_data(data='train'):\n    # get data \n    if data == 'train':\n        df = pd.read_csv('https:\/\/numerai-public-datasets.s3-us-west-2.amazonaws.com\/latest_numerai_training_data.csv.xz')\n    elif data == 'test':\n        df = pd.read_csv('https:\/\/numerai-public-datasets.s3-us-west-2.amazonaws.com\/latest_numerai_tournament_data.csv.xz')\n    \n    # features\n    feature_cols = df.columns[df.columns.str.startswith('feature')]\n    \n    # map to int, to reduce the memory demand\n    mapping = {0.0 : 0, 0.25 : 1, 0.5 : 2, 0.75 : 3, 1.0 : 4}\n    for c in feature_cols:\n        df[c] = df[c].map(mapping).astype(np.uint8)\n        \n    # also cast era to int\n    df[\"era\"] = df[\"era\"].apply(get_int)\n    return df","d7f9a1a2":"%%time\n\n# load train\u3000(\u534a\u5e74\u9593\u56fa\u5b9a)\ntrain = read_data('train')\nprint(train.shape)\ntrain.head()","89191f83":"%%time\n\n# load test (\u6bce\u9031Round\u3054\u3068\u306b\u66f4\u65b0)\ntest = read_data('test')","97b7d3b8":"valid = test[test[\"data_type\"] == \"validation\"].reset_index(drop = True)\n\n# validation split\nvalid.loc[valid[\"era\"] > 180, \"valid2\"] = True # \u3080\u305a\u3044\u3084\u3064\nvalid.loc[valid[\"era\"] <= 180, \"valid2\"] = False # \u7c21\u5358\u306a\u3084\u3064","073b05a0":"# remove data_type to save memory\ntrain.drop(columns=[\"data_type\"], inplace=True)\nvalid.drop(columns=[\"data_type\"], inplace=True)\ntest.drop(columns=[\"data_type\"], inplace=True)\n\nprint('The number of records: train {:,}, valid {:,}, test {:,}'.format(train.shape[0], valid.shape[0], test.shape[0]))","fa33a007":"# features (\u7279\u5fb4\u91cf)\nfeatures = [f for f in train.columns.values.tolist() if 'feature' in f]\nprint('There are {} features.'.format(len(features)))\nprint(features)","1263e83d":"# target\ntarget = train.columns[train.columns.str.startswith('target')].values.tolist()[0]\nprint(f'Taget name = {target}')","a39a5070":"train[target].hist()","e7339cc6":"# # create a model and fit (\u516c\u5f0fexample)\n# model = xgb.XGBRegressor(max_depth=5, learning_rate=0.01, n_estimators=2000, n_jobs=-1, colsample_bytree=0.1)\n# model.fit(train[features], train[target])","f27b3790":"%%time\n\n# create a model and fit\uff08LGB\u306e\u30cf\u30a4\u30d1\u30e9\u306f\u2191\u306e\u516c\u5f0fXGB\u306b\u5bc4\u305b\u3066\u307f\u307e\u3057\u305f\uff09\nparams = {\n            'n_estimators': 2000,\n            'objective': 'regression',\n            'boosting_type': 'gbdt',\n            'max_depth': 5,\n            'learning_rate': 0.01, \n            'feature_fraction': 0.1,\n            'seed': 42\n            }    \nmodel = lgb.LGBMRegressor(**params)\nmodel.fit(train[features], train[target])","fa6d0574":"# save model\uff08\u3042\u3068\u3067\u30ed\u30fc\u30c9\u3057\u3066\u4e88\u6e2c\u3067\u304d\u308b\u3088\u3046\u306b\u4fdd\u5b58\u3057\u307e\u3059\uff09\njoblib.dump(model, 'my_lightgbm.joblib') \nprint('model saved!')","3ca85e93":"pd.DataFrame(model.feature_importances_, index=features, columns=['importance']).sort_values(by='importance', ascending=False).style.background_gradient(cmap='viridis')","76c15cc7":"# naming conventions\nPREDICTION_NAME = 'prediction'\nTARGET_NAME = target\n# EXAMPLE_PRED = 'example_prediction'\n\n# ---------------------------\n# Functions\n# ---------------------------\ndef valid4score(valid : pd.DataFrame, pred : np.ndarray, load_example: bool=True, save : bool=False) -> pd.DataFrame:\n    \"\"\"\n    Generate new valid pandas dataframe for computing scores\n    \n    :INPUT:\n    - valid : pd.DataFrame extracted from tournament data (data_type='validation')\n    \n    \"\"\"\n    valid_df = valid.copy()\n    valid_df['prediction'] = pd.Series(pred).rank(pct=True, method=\"first\")\n    valid_df.rename(columns={target: 'target'}, inplace=True)\n    \n    if load_example:\n        valid_df[EXAMPLE_PRED] = pd.read_csv(EXP_DIR + 'valid_df.csv')['prediction'].values\n    \n    if save==True:\n        valid_df.to_csv(OUTPUT_DIR + 'valid_df.csv', index=False)\n        print('Validation dataframe saved!')\n    \n    return valid_df\n\ndef compute_corr(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute rank correlation\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \n    \"\"\"\n    \n    return np.corrcoef(valid_df[\"target\"], valid_df['prediction'])[0, 1]\n\ndef compute_max_drawdown(validation_correlations : pd.Series):\n    \"\"\"\n    Compute max drawdown\n    \n    :INPUT:\n    - validation_correaltions : pd.Series\n    \"\"\"\n    \n    rolling_max = (validation_correlations + 1).cumprod().rolling(window=100, min_periods=1).max()\n    daily_value = (validation_correlations + 1).cumprod()\n    max_drawdown = -(rolling_max - daily_value).max()\n    \n    return max_drawdown\n\ndef compute_val_corr(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute rank correlation for valid periods\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \"\"\"\n    \n    # all validation\n    correlation = compute_corr(valid_df)\n    print(\"rank corr = {:.4f}\".format(correlation))\n    return correlation\n    \ndef compute_val_sharpe(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute sharpe ratio for valid periods\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \"\"\"\n    # all validation\n    d = valid_df.groupby('era')[['target', 'prediction']].corr().iloc[0::2,-1].reset_index()\n    me = d['prediction'].mean()\n    sd = d['prediction'].std()\n    max_drawdown = compute_max_drawdown(d['prediction'])\n    print('sharpe ratio = {:.4f}, corr mean = {:.4f}, corr std = {:.4f}, max drawdown = {:.4f}'.format(me \/ sd, me, sd, max_drawdown))\n    \n    return me \/ sd, me, sd, max_drawdown\n    \ndef feature_exposures(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute feature exposure\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \"\"\"\n    feature_names = [f for f in valid_df.columns\n                     if f.startswith(\"feature\")]\n    exposures = []\n    for f in feature_names:\n        fe = spearmanr(valid_df['prediction'], valid_df[f])[0]\n        exposures.append(fe)\n    return np.array(exposures)\n\ndef max_feature_exposure(fe : np.ndarray):\n    return np.max(np.abs(fe))\n\ndef feature_exposure(fe : np.ndarray):\n    return np.sqrt(np.mean(np.square(fe)))\n\ndef compute_val_feature_exposure(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute feature exposure for valid periods\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \"\"\"\n    # all validation\n    fe = feature_exposures(valid_df)\n    fe1, fe2 = feature_exposure(fe), max_feature_exposure(fe)\n    print('feature exposure = {:.4f}, max feature exposure = {:.4f}'.format(fe1, fe2))\n     \n    return fe1, fe2\n\n# to neutralize a column in a df by many other columns\ndef neutralize(df, columns, by, proportion=1.0):\n    scores = df.loc[:, columns]\n    exposures = df[by].values\n\n    # constant column to make sure the series is completely neutral to exposures\n    exposures = np.hstack(\n        (exposures,\n         np.asarray(np.mean(scores)) * np.ones(len(exposures)).reshape(-1, 1)))\n\n    scores = scores - proportion * exposures.dot(\n        np.linalg.pinv(exposures).dot(scores))\n    return scores \/ scores.std()\n\n\n# to neutralize any series by any other series\ndef neutralize_series(series, by, proportion=1.0):\n    scores = series.values.reshape(-1, 1)\n    exposures = by.values.reshape(-1, 1)\n\n    # this line makes series neutral to a constant column so that it's centered and for sure gets corr 0 with exposures\n    exposures = np.hstack(\n        (exposures,\n         np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n\n    correction = proportion * (exposures.dot(\n        np.linalg.lstsq(exposures, scores, rcond=None)[0]))\n    corrected_scores = scores - correction\n    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n    return neutralized\n\n\ndef unif(df):\n    x = (df.rank(method=\"first\") - 0.5) \/ len(df)\n    return pd.Series(x, index=df.index)\n\ndef get_feature_neutral_mean(df):\n    feature_cols = [c for c in df.columns if c.startswith(\"feature\")]\n    df.loc[:, \"neutral_sub\"] = neutralize(df, [PREDICTION_NAME],\n                                          feature_cols)[PREDICTION_NAME]\n    scores = df.groupby(\"era\").apply(\n        lambda x: np.corrcoef(x[\"neutral_sub\"].rank(pct=True, method=\"first\"), x[TARGET_NAME])).mean()\n    return np.mean(scores)\n\ndef compute_val_mmc(valid_df : pd.DataFrame):    \n    # MMC over validation\n    mmc_scores = []\n    corr_scores = []\n    for _, x in valid_df.groupby(\"era\"):\n        series = neutralize_series(pd.Series(unif(x[PREDICTION_NAME])),\n                                   pd.Series(unif(x[EXAMPLE_PRED])))\n        mmc_scores.append(np.cov(series, x[TARGET_NAME])[0, 1] \/ (0.29 ** 2))\n        corr_scores.append(np.corrcoef(unif(x[PREDICTION_NAME]).rank(pct=True, method=\"first\"), x[TARGET_NAME]))\n\n    val_mmc_mean = np.mean(mmc_scores)\n    val_mmc_std = np.std(mmc_scores)\n    val_mmc_sharpe = val_mmc_mean \/ val_mmc_std\n    corr_plus_mmcs = [c + m for c, m in zip(corr_scores, mmc_scores)]\n    corr_plus_mmc_sharpe = np.mean(corr_plus_mmcs) \/ np.std(corr_plus_mmcs)\n    corr_plus_mmc_mean = np.mean(corr_plus_mmcs)\n\n    print(\"MMC Mean = {:.6f}, MMC Std = {:.6f}, CORR+MMC Sharpe = {:.4f}\".format(val_mmc_mean, val_mmc_std, corr_plus_mmc_sharpe))\n\n    # Check correlation with example predictions\n    corr_with_example_preds = np.corrcoef(valid_df[EXAMPLE_PRED].rank(pct=True, method=\"first\"),\n                                          valid_df[PREDICTION_NAME].rank(pct=True, method=\"first\"))[0, 1]\n    print(\"Corr with example preds: {:.4f}\".format(corr_with_example_preds))\n    \n    return val_mmc_mean, val_mmc_std, corr_plus_mmc_sharpe, corr_with_example_preds\n    \ndef score_summary(valid_df : pd.DataFrame):\n    score_df = {}\n    \n    try:\n        score_df['correlation'] = compute_val_corr(valid_df)\n    except:\n        print('ERR: computing correlation')\n    try:\n        score_df['corr_sharpe'], score_df['corr_mean'], score_df['corr_std'], score_df['max_drawdown'] = compute_val_sharpe(valid_df)\n    except:\n        print('ERR: computing sharpe')\n    try:\n        score_df['feature_exposure'], score_df['max_feature_exposure'] = compute_val_feature_exposure(valid_df)\n    except:\n        print('ERR: computing feature exposure')\n    try:\n        score_df['mmc_mean'], score_df['mmc_std'], score_df['corr_mmc_sharpe'], score_df['corr_with_example_xgb'] = compute_val_mmc(valid_df)\n    except:\n        print('ERR: computing MMC')\n    \n    return pd.DataFrame.from_dict(score_df, orient='index')","22b6994c":"# prediction for valid periods   \npred = model.predict(valid[features])","6f61ba9d":"# scores\nvalid_df = valid4score(valid, pred, load_example=False, save=False)\n\nscore_df = pd.DataFrame()\nprint('------------------')\nprint('ALL:')\nprint('------------------')\nall_ = score_summary(valid_df).rename(columns={0: 'all'})\n\nprint('------------------')\nprint('VALID 1:')\nprint('------------------')\nval1_ = score_summary(valid_df.query('era < 150')).rename(columns={0: 'val1'})\n\nprint('------------------')\nprint('VALID 2:')\nprint('------------------')\nval2_ = score_summary(valid_df.query('era > 150')).rename(columns={0: 'val2'})","e299c079":"# scores\nscore_df = pd.concat([all_, val1_, val2_], axis=1)\nscore_df.style.background_gradient(cmap='viridis', axis=0)","d6b29f96":"public_id = \"NYANNYAN\" # replace with yours\nsecret_key = \"WANWAN\" # replace with yours\nmodel_id = \"KOKEKOKKOOOO\" # replace with yours\nPREDICTION_NAME = \"prediction_kazutsugi\" # \u73fe\u5728\u306f\u3053\u308c\uff08\u3044\u305a\u308cprediction_nomi\u306b\u306a\u308b\u3089\u3057\u3044\uff09\nOUTPUT_DIR = '' # prediction dataframe\u3092\u4fdd\u5b58\u3059\u308bpath\n\ndef submit(tournament : pd.DataFrame, pred : np.ndarray, model_id='abcde'):\n    predictions_df = tournament[\"id\"].to_frame()\n    predictions_df[PREDICTION_NAME] = pred\n    \n    # to rank\n    predictions_df[PREDICTION_NAME] = predictions_df[PREDICTION_NAME].rank(pct=True, method=\"first\")\n    \n    # save\n    predictions_df.to_csv(pathlib.Path(OUTPUT_DIR + f\"predictions_{model_id}.csv\"), index=False)\n    \n    # Upload your predictions using API\n    napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n    submission_id = napi.upload_predictions(pathlib.Path(OUTPUT_DIR + f\"predictions_{model_id}.csv\"), model_id=model_id)\n    print('submitted to {model_id}', model_id=model_id)\n    \n    return predictions_df","e1511b96":"# prediction\npred = model.predict(test[features])\nplt.hist(pred);","3e800393":"# submit!\uff08\u672c\u5f53\u306b\u63d0\u51fa\u3059\u308b\u4eba\u306f\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3057\u3066\u304f\u3060\u3055\u3044\uff09\n# predictions_df = submit(tournament, pred, model_id=model_id)","4f21b924":"\u660e\u3089\u304b\u306bVALID2\uff08\u4e88\u6e2c\u304c\u96e3\u3057\u3044Validation\u671f\u9593\uff09\u306e\u65b9\u304c\u3001CORR\u304c\u5c0f\u3055\u304b\u3063\u305f\u308a\u3068\u96e3\u3057\u3044\u3067\u3059\u306d\u3002\n\n\u305f\u3060\u3001valid 2\u306e\u4e88\u6e2c\u304c\u96e3\u3057\u3044\u671f\u9593\u3067\u3082CORR = 0.015\u3042\u305f\u308a\u306e\u30b9\u30b3\u30a2\u306a\u306e\u3067\u3001**Round\u3067CORR\u306e\u307f\u306bBet\u3059\u308c\u3070\uff08\u9031\u6b21\uff091.5%\u306e\u30ea\u30bf\u30fc\u30f3\u304c\u671f\u5f85\u3067\u304d\u305d\u3046**\u3060\u3068\u3044\u3046\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002CORR+MMC\u306bBet\u3059\u308c\u3070\u3001\uff08MMC\u304c\u30d7\u30e9\u30b9\u306a\u3089\uff09\u66f4\u306a\u308b\u30ea\u30bf\u30fc\u30f3\u304c\u898b\u8fbc\u3081\u308b\u30e2\u30c7\u30eb\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u3082\u3061\u308d\u3093\u76f8\u5834\u306e\u52d5\u304d\u306f\u6c17\u307e\u3050\u308c\u3067\u3059\u3002\u3053\u308c\u3067\u300c\u7d76\u5bfe\u306b\u5132\u304b\u308b...!\u300d\u3068\u3044\u3046\u3082\u306e\u3067\u306f\u306a\u3044\u306e\u3067\u3001\u5404\u81ea\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8\u3068\u3057\u3066\u8155\u306e\u898b\u305b\u6240\u3067\u3059\u3002","1f1696cd":"XGBoost\u3082LightGBM\u3082GBDT (Gradient Boosting Decision Tree)\u3068\u547c\u3070\u308c\u308b\u985e\u306e\u30e2\u30c7\u30eb\u3067\u3001\u30c6\u30fc\u30d6\u30eb\u5f62\u5f0f\u306e\u30c7\u30fc\u30bf\u306b\u5927\u3057\u3066\u975e\u5e38\u306b\u5f37\u529b\u3067\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u8907\u6570\u3042\u3063\u3066\u3069\u3046\u3057\u305f\u3089\u3044\u3044\u304b\u308f\u304b\u3089\u306a\u3044\u65b9\u306f\u3001\u3053\u3061\u3089\u306e\u30d6\u30ed\u30b0\u306b\u975e\u5e38\u306b\u7c21\u6f54\u306b\u308f\u304b\u308a\u3084\u3059\u304f\u307e\u3068\u307e\u3063\u3066\u3044\u307e\u3059\u306e\u3067\u30aa\u30b9\u30b9\u30e1\u3067\u3059\u3002\n\n[\u52fe\u914d\u30d6\u30fc\u30b9\u30c6\u30a3\u30f3\u30b0\u3067\u5927\u4e8b\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6c17\u6301\u3061](https:\/\/nykergoto.hatenablog.jp\/entry\/2019\/03\/29\/%E5%8B%BE%E9%85%8D%E3%83%96%E3%83%BC%E3%82%B9%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E5%A4%A7%E4%BA%8B%E3%81%AA%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%81%AE%E6%B0%97%E6%8C%81%E3%81%A1)","6a9a7a2d":"# Feature importance\n\u305b\u3063\u304b\u304fGBDT\u3092\u4f7f\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u3069\u306e\u7279\u5fb4\u91cf\u304c\u5927\u4e8b\u304b\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002","2e61429e":"\u7279\u5fb4\u91cf\u306f\u5168\u3066\u533f\u540d\u306a\u306e\u3067\u3001\u305d\u308c\u305e\u308c\u5177\u4f53\u7684\u306b\u4f55\u3092\u610f\u5473\u3057\u3066\u3044\u308b\u304b\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u3001\u5c11\u306a\u304f\u3068\u3082\u7279\u5225\u5f37\u3044\u3001\u3042\u308b\u3044\u306f\u7279\u5225\u5f31\u3044\u7279\u5fb4\u91cf\u3068\u3044\u3046\u306e\u306f\u306a\u3055\u305d\u3046\u3067\u3059\u3002","ed25d560":"## \u7279\u5fb4\u91cf","7028af2c":"# Submission\n\u4ee5\u4e0b\u63d0\u51fa\u306e\u5f62\u5f0f\u3067\u3059\u3002\u5b9f\u969b\u306b\u63d0\u51fa\u3059\u308b\u306b\u306f\u3001[Numerai tournament](https:\/\/numer.ai\/tournament)\u3067\u30e6\u30fc\u30b6\u767b\u9332\u3092\u884c\u3044\u3001API\u30ad\u30fc\u3068\u30e2\u30c7\u30ebID\u3092\u53d6\u5f97\u3057\u3066\u304f\u3060\u3055\u3044\u3002Rank correlation\u3067\u8a55\u4fa1\u3055\u308c\u308b\u305f\u3081\u3001\u3053\u3061\u3089\u3067rank\u5316\u3057\u3066\u63d0\u51fa\u3057\u307e\u3059\u3002","e2c1ab3c":"# Tournament\u30c7\u30fc\u30bf\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\nAWS\u306b\u516c\u958b\u3055\u308c\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u8ab0\u3067\u3082\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u53ef\u80fd\u3067\u3059\u3002\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\u306f\u96e2\u6563\u5024\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u30e1\u30e2\u30ea\u7bc0\u7d04\u306e\u305f\u3081\u6574\u6570\u5024\u306b\u30ad\u30e3\u30b9\u30c8\u3057\u3066\u3044\u307e\u3059\u3002Round\u671f\u9593\u3092\u8868\u3059'Era'\u3082\u6574\u6570\u306b\u3057\u307e\u3059\u3002","bb05d806":"![](https:\/\/numer.ai\/img\/Numerai-Logo-Side-Black.8393ed16.png)\n\n\uff08\u5c65\u6b74\uff09\n- version 3: \u516c\u958b\n- version 4: \u30bf\u30a4\u30dd\u306a\u3069\u4fee\u6b63\n- version 5: target nomi\u3078\u5909\u66f4\u3002\u52a0\u7b46\u3002\n\n\u300cNumerai\u306f\u3058\u3081\u3066\u307f\u305f\u3044\u3051\u3069\u3001\u82f1\u8a9e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304c\u591a\u304f\u3066\u3061\u3087\u3063\u3068...\u300d\u3068\u3044\u3046\u65b9\u3082\u591a\u3044\u3068\u601d\u3044\u307e\u3059\u306e\u3067\u3001\u65e5\u672c\u8a9e\u3067\u300c\u30c7\u30fc\u30bf\u306e\u30ed\u30fc\u30c9\u2192\u30e2\u30c7\u30ea\u30f3\u30b0\u2192\u8a55\u4fa1\u2192\u63d0\u51fa\u300d\u306e\u4e00\u9023\u306e\u6d41\u308c\u3092\u307e\u3068\u3081\u3066\u307f\u307e\u3057\u305f\u3002\n\n\u305f\u3060\u3001\u6700\u8fd1Numerai\u95a2\u9023\u306e\u65e5\u672c\u8a9e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304c\u5145\u5b9f\u3057\u3066\u304d\u307e\u3057\u3066\u3001\u516c\u5f0f\u3067\u307e\u3068\u307e\u3063\u3066\u308b\u306e\u3067\u4e00\u5ea6\u3054\u89a7\u306b\u306a\u308b\u3068\u826f\u3044\u304b\u3082\u77e5\u308c\u306a\u3044\u3067\u3059\u3002\n\n[Numerai\u65e5\u672c\u8a9e\u516c\u5f0f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8](https:\/\/jp.docs.numer.ai\/numerai-tournament\/new-users)\n\n\u305d\u308c\u3067\u306f\u3084\u3063\u3066\u3044\u304d\u307e\u3057\u3087\u3046\u3002\n\n\u307e\u305a\u3001Numerai\u306b\u306fAPI\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u5229\u7528\u3059\u308b\u305f\u3081\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002","5b07e0d4":"# \u53c2\u8003\n\n- [Kaggler\u3078\u306eNumerai\u306e\u30b9\u30b9\u30e1](https:\/\/zenn.dev\/katsu1110\/articles\/bb2b5cba9b04c9e30bfe)\n- [Numerai\u516c\u5f0fGithub](https:\/\/github.com\/numerai)","b947e1b6":"# Modeling\u306e\u5b9f\u884c\n\u30c7\u30fc\u30bf\u306e\u6574\u7406\u304c\u3067\u304d\u305f\u306e\u3067\u3001[\u516c\u5f0fExample](https:\/\/github.com\/numerai\/example-scripts\/blob\/master\/example_model.py)\u306b\u306a\u3089\u3044\u30e2\u30c7\u30ea\u30f3\u30b0\u3092\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n\n[\u516c\u5f0f\u3067\u306fXGBoost\u3092\u4f7f\u7528](https:\/\/jp.docs.numer.ai\/numerai-tournament\/tournament-overview)\u3057\u3066\u3044\u307e\u3059\u304c\u3001\u6642\u77ed\u306e\u305f\u3081\u3053\u3053\u3067\u306fLightGBM\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002","f700cc8a":"# EDA (Exploratory Data Analysis)\u306e\u5b9f\u884c\n\u7c21\u5358\u306b\u3067\u3059\u304c\u3001\u3069\u3093\u306a\u30c7\u30fc\u30bf\u306a\u306e\u304b\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002","0ac88ef3":"Tournament\u30c7\u30fc\u30bf\u306b\u306f\u3001\u30e9\u30d9\u30eb\u304c\u4e0e\u3048\u3089\u308c\u3066\u3044\u308bValidation\u30c7\u30fc\u30bf\u3068\u3001\u30e9\u30d9\u30eb\u304c\u3042\u305f\u3048\u3089\u308c\u3066\u3044\u306a\u3044Test\u30c7\u30fc\u30bf\u304c\u5165\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u5206\u96e2\u3057\u307e\u3059\u3002\u307e\u305f\u3001Validation\u30c7\u30fc\u30bf\u306f\u4e3b\u306b2\u671f\u9593\u306b\u5206\u304b\u308c\u3066\u3044\u308b\uff08\u524d\u306e\u671f\u9593\u306f\u4e88\u6e2c\u304c\u7c21\u5358\u3067\u3001\u5f8c\u306e\u65b9\u304c\u4e88\u6e2c\u304c\u96e3\u3057\u3044\uff09\u305f\u3081\u3001\u3053\u3053\u3092\u533a\u5225\u3057\u305f\u30e9\u30d9\u30eb\u3092\u4ed8\u4e0e\u3057\u307e\u3059\u3002","4e2ce30e":"## Target\ntarget\u306f\u3069\u3046\u3067\u3057\u3087\u3046\u304b\u3002","79f21bf0":"# \u7d42\u308f\u308a\u306b\nNumerai\u306f\u82f1\u8a9e\u306e\u60c5\u5831\u304c\u591a\u304f\u3001\u3068\u3063\u3064\u304d\u306b\u304f\u304b\u3063\u305f\u4eba\u3082\u591a\u3044\u3068\u306f\u601d\u3044\u307e\u3059\u304c\u3001\u3053\u306eNotebook\u304c\u307f\u306a\u3055\u3093\u306eNumerai life\u306e\u53c2\u8003\u306b\u306a\u308c\u3070\u5e78\u3044\u3067\u3059\u3002","7dd8f966":"\u6b63\u898f\u5206\u5e03\u3063\u307d\u30445\u3064\u306e\u96e2\u6563\u5024\u3067\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\u3002","bd73fe2b":"# Validation Score\nValidation\u30c7\u30fc\u30bf\u304c\u4e0e\u3048\u3089\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u8a13\u7df4\u3057\u305f\u30e2\u30c7\u30eb\u304c\u3069\u306e\u7a0b\u5ea6\u306e\u3082\u306e\u304b\u3001\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u91d1\u878d\u30e2\u30c7\u30eb\u306a\u306e\u3067\u3001\u305f\u3060\u7cbe\u5ea6 (target\u3068\u306erank correlation)\u3060\u3051\u3067\u306a\u304f\u3001\u904b\u7528\u671f\u9593\u3067\u5b89\u5b9a\u3057\u305f\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u51fa\u305b\u3066\u3044\u308b\u304b\u30c1\u30a7\u30c3\u30af\u3057\u307e\u3059\u3002\u591a\u304f\u306e\u95a2\u6570\u306fNumerai\u306e[\u516c\u5f0fGithub](https:\/\/github.com\/numerai\/example-scripts\/blob\/master\/example_model.py)\u306b\u3042\u308b\u306e\u3067\u3001\u62fe\u3063\u3066\u6539\u5909\u3057\u4f7f\u3063\u3066\u3044\u304d\u307e\u3059\u3002\n\nMMC\uff08meta model correlation\uff09\u306f\u3001\u904b\u55b6\u306e\u30e1\u30bf\u30e2\u30c7\u30eb\u304c\u624b\u306b\u5165\u3089\u306a\u3044\u305f\u3081\u8a08\u7b97\u3067\u304d\u307e\u305b\u3093\u304c\u3001\u7cbe\u5ea6 (rank correlation)\u3068\u3001\u7cbe\u5ea6\u3068\u5b89\u5b9a\u6027\u306e\u30d0\u30e9\u30f3\u30b9\u3092\u8a55\u4fa1\u3059\u308b**correlation sharpe**\u306a\u3069\u306f\u3001\u81ea\u5206\u3067\u8a08\u7b97\u3067\u304d\u307e\u3059\u306e\u3067\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002\u4ee5\u4e0b\u306e\u6307\u6a19\u3092\u3001Validation\u671f\u9593\u3092\u5168\u3066\u3001\u524d\u534a\uff08\u7c21\u5358\u306a\u3084\u3064\uff09\u3001\u5f8c\u534a\uff08\u96e3\u3057\u3044\u3084\u3064\uff09\u306b\u5206\u3051\u3066\u8a08\u7b97\u3057\u3066\u3044\u307e\u3059\u3002\n\n- rank correlation (Numerai\u3067CORR\u3068\u547c\u3070\u308c\u3066\u3044\u308b\u3082\u306e\u3002\u9ad8\u3044\u307b\u3069\u826f\u3044)\n- sharpe ratio\uff08\u671f\u9593\u30d9\u30fc\u30b9\u3067\u306eCORR\u5e73\u5747\u3092\u6a19\u6e96\u504f\u5dee\u3067\u5272\u3063\u305f\u3082\u306e\u3002\u9ad8\u3044\u307b\u3069\u826f\u3044\uff09\n- max drawdown (\u3042\u308b1\u30e9\u30a6\u30f3\u30c9\u3067\u306e\u6700\u5927\u306e\u640d\u5931CORR\u30020\u306b\u8fd1\u3044\u307b\u3069\u826f\u3044)\n- feature exposure (\u30e2\u30c7\u30eb\u4e88\u6e2c\u5024\u304c\u4e00\u90e8\u306e\u7279\u5fb4\u91cf\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u5ea6\u5408\u3002\u4f4e\u3044\u307b\u3069\u826f\u3044)\n\n\u5b9f\u306f\u63d0\u51fa\u3059\u308b\u3068\u3001Numerai\u5074\u3067\u5168\u90e8\u8a08\u7b97\u3057\u3066\u81ea\u5206\u306e\u30da\u30fc\u30b8\u3067\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u306e\u3067\u3059\u304c\u3001\u5168validation\u671f\u9593\u3092\u4f7f\u7528\u3057\u305f\u30b9\u30b3\u30a2\u306e\u307f\u304c\u8fd4\u3063\u3066\u304f\u308b\u305f\u3081\u3001\u300c\u4e88\u6e2c\u304c\u96e3\u3057\u3044\u6642\u671f\u3067\u3082\u3044\u3044\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u51fa\u3066\u3044\u308b\u304b\uff1f\u300d\u3068\u3044\u3046\u809d\u5fc3\u306e\u7591\u554f\u306b\u306f\u7b54\u3048\u3066\u304f\u308c\u307e\u305b\u3093\u3002\u306a\u306e\u3067\u3001\u81ea\u5206\u3067\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046...^^","bb2ade37":"\u4ed6\u306e\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002","f57aa3c3":"310\u500b\u306e\u533f\u540d\u7279\u5fb4\u91cf\u304c\u3042\u308a\u307e\u3059\u306d\u3002\n\n- intelligence (1 ~ 12)\n- charisma (1 ~ 86)\n- strength (1 ~ 38)\n- dexterity (1 ~ 14)\n- constitution (1 ~ 114)\n- wisdom (1 ~ 46)\n\n\u30686\u7a2e\u985e\u306b\u5927\u5225\u3067\u304d\u305d\u3046\u3067\u3059\u304c\u3001\u305d\u308c\u305e\u308c\u3069\u3046\u3044\u3063\u305f\u7279\u5fb4\u91cf\u306a\u306e\u304b\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u3002"}}