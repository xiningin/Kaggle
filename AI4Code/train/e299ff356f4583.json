{"cell_type":{"13a31ac0":"code","61aa9957":"code","24d3e14a":"code","5d76867b":"code","c217e3a3":"code","04ec5dc0":"code","00fa8325":"code","8cf594b9":"code","6eb42c1e":"code","0a47130c":"code","e9382594":"code","ca5557a9":"code","ea2c22b2":"code","f4ca8851":"code","5951b12a":"code","ffc92493":"code","5045e247":"code","58fbe16e":"code","399db00e":"code","bb1c8dd1":"code","2940a320":"code","40d7cb81":"code","3dc9d183":"code","792ebc39":"code","6483e575":"code","806002e1":"code","04dbf6ac":"code","9cebba48":"code","820938fd":"code","307ff962":"code","6ca5d713":"code","166d3e6f":"code","518ca54c":"code","63d1e133":"code","3559ba06":"code","97c910e2":"code","98249543":"code","bd573277":"code","588ed058":"code","1541d721":"code","3826aea7":"code","dcf25691":"code","511a6317":"code","89d601ea":"code","61e952e3":"code","59bb1723":"code","5f9ac85d":"code","a6aa6706":"markdown","c123ea41":"markdown","f493f2bc":"markdown","b97ffc82":"markdown","56aed564":"markdown","0a5e3d20":"markdown","788c8c6c":"markdown","00b6ee9c":"markdown","d49ef165":"markdown","9248a5ce":"markdown","c60e5047":"markdown","17839de5":"markdown","1e806a5f":"markdown","67328e03":"markdown","cfbb86f9":"markdown","ed671f59":"markdown","ec8adc7c":"markdown","8bb762a2":"markdown","6f5b60a5":"markdown","c77652f0":"markdown","577e1ea6":"markdown","0bda3e65":"markdown","aa1b128c":"markdown","54dd22cb":"markdown","d9ccd64f":"markdown","e2d5d2d1":"markdown","385e5ae1":"markdown"},"source":{"13a31ac0":"import warnings\nimport itertools\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, log_loss\nimport dask.dataframe as dd\nimport dask\nimport gc\n\nfrom yellowbrick.text import TSNEVisualizer\n\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nwarnings.simplefilter(action='ignore')\nsns.set_style('whitegrid')","61aa9957":"def gc():\n    print(gc.collect())\n\ndtypes = {\"crew\": \"int8\",\n          \"experiment\": \"category\",\n          \"time\": \"float32\",\n          \"seat\": \"int8\",\n          \"eeg_fp1\": \"float32\",\n          \"eeg_f7\": \"float32\",\n          \"eeg_f8\": \"float32\",\n          \"eeg_t4\": \"float32\",\n          \"eeg_t6\": \"float32\",\n          \"eeg_t5\": \"float32\",\n          \"eeg_t3\": \"float32\",\n          \"eeg_fp2\": \"float32\",\n          \"eeg_o1\": \"float32\",\n          \"eeg_p3\": \"float32\",\n          \"eeg_pz\": \"float32\",\n          \"eeg_f3\": \"float32\",\n          \"eeg_fz\": \"float32\",\n          \"eeg_f4\": \"float32\",\n          \"eeg_c4\": \"float32\",\n          \"eeg_p4\": \"float32\",\n          \"eeg_poz\": \"float32\",\n          \"eeg_c3\": \"float32\",\n          \"eeg_cz\": \"float32\",\n          \"eeg_o2\": \"float32\",\n          \"ecg\": \"float32\",\n          \"r\": \"float32\",\n          \"gsr\": \"float32\",\n          \"event\": \"category\",\n         }\n\nimport matplotlib.pyplot as plt\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","24d3e14a":"%%time\ntrain = dd.read_csv(\"..\/input\/train.csv\", blocksize=  64000000, dtype = dtypes)","5d76867b":"%%time\ntest = dd.read_csv(\"..\/input\/test.csv\", dtype = dtypes)\n# test_df = pd.read_csv(\"..\/input\/test.csv\", dtype=dtypes)","c217e3a3":"%%time\ntrain  = train.compute()\nprint(\"Training shape : \", train.shape)","04ec5dc0":"%%time\ntest = test.compute()\nprint(\"Testing shape : \", test.shape)\n# print(gc.collect())","00fa8325":"train_df = train.copy()\ntest_df = test.copy()","8cf594b9":"import gc\ngc.collect()","6eb42c1e":"import lightgbm as lgb\n\ntest_id = test_df['id']\n\n\ndic = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\ndic1 = {'CA':0,'DA':1,'SS':3,'LOFT':4}\ntrain_df[\"event\"] = train_df[\"event\"].apply(lambda x: dic[x])\ntrain_df[\"event\"] = train_df[\"event\"].astype('int8')\ntrain_df['experiment'] = train_df['experiment'].apply(lambda x: dic1[x])\ntest_df['experiment'] = test_df['experiment'].apply(lambda x: dic1[x])\n\ntrain_df['experiment'] = train_df['experiment'].astype('int8')\ntest_df['experiment'] = test_df['experiment'].astype('int8')\n\ny = train_df['event']","0a47130c":"tr_col = train_df.columns","e9382594":"test_df.head()","ca5557a9":"train_df.shape,test.shape","ea2c22b2":"plt.figure(figsize=(15,10))\nsns.countplot(train_df['event'])\nplt.xlabel(\"State of the pilot\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.title(\"Target repartition\", fontsize=15)\nplt.show()","f4ca8851":"plt.figure(figsize=(15,10))\nsns.countplot('experiment', hue='event', data=train_df)\nplt.xlabel(\"Experiment and state of the pilot\", fontsize=12)\nplt.ylabel(\"Count (log)\", fontsize=12)\nplt.yscale('log')\nplt.title(\"Target repartition for different experiments\", fontsize=15)\nplt.show()","5951b12a":"plt.figure(figsize=(15,10))\nsns.countplot('event', hue='seat', data=train_df)\nplt.xlabel(\"Seat and state of the pilot\", fontsize=12)\nplt.ylabel(\"Count (log)\", fontsize=12)\nplt.yscale('log')\nplt.title(\"Left seat or right seat ?\", fontsize=15)\nplt.show()","ffc92493":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='time', data=train_df.sample(50000))\nplt.ylabel(\"Time (s)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Which time do events occur at ?\", fontsize=15)\nplt.show()","5045e247":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['time'], label='Test set')\nsns.distplot(train_df['time'], label='Train set')\nplt.legend()\nplt.xlabel(\"Time (s)\", fontsize=12)\nplt.title(\"Reparition of the time feature\", fontsize=15)\nplt.show()","58fbe16e":"eeg_features = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\"]","399db00e":"plt.figure(figsize=(20,25))\ni = 0\n\nfor egg in eeg_features:\n    i += 1\n    plt.subplot(5, 4, i)\n    sns.boxplot(x='event', y=egg, data=train_df.sample(50000), showfliers=False)\n\nplt.show()","bb1c8dd1":"plt.figure(figsize=(20,25))\nplt.title('Eeg features distributions')\ni = 0\n\nfor eeg in eeg_features:\n    i += 1\n    plt.subplot(5, 4, i)\n    sns.distplot(test_df.sample(10000)[eeg], label='Test set', hist=False)\n    sns.distplot(train_df.sample(10000)[eeg], label='Train set', hist=False)\n    plt.xlim((-500, 500))\n    plt.legend()\n    plt.xlabel(eeg, fontsize=12)\n\nplt.show()","2940a320":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='ecg', data=train_df.sample(50000))\nplt.ylabel(\"Electrocardiogram Signal (\u00b5V)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Electrocardiogram signal influence\", fontsize=15)\nplt.show()","40d7cb81":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['ecg'], label='Test set')\nsns.distplot(train_df['ecg'], label='Train set')\nplt.legend()\nplt.xlabel(\"Electrocardiogram Signal (\u00b5V)\", fontsize=12)\nplt.title(\"Electrocardiogram Signal Distribution\", fontsize=15)\nplt.show()","3dc9d183":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='r', data=train_df.sample(50000))\nplt.ylabel(\"Respiration Signal (\u00b5V)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Respiration influence\", fontsize=15)\nplt.show()","792ebc39":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['r'], label='Test set')\nsns.distplot(train_df['r'], label='Train set')\nplt.legend()\nplt.xlabel(\"Respiration Signal (\u00b5V)\", fontsize=12)\nplt.title(\"Respiration Signal Distribution\", fontsize=15)\nplt.show()","6483e575":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='gsr', data=train_df.sample(50000))\nplt.ylabel(\"Electrodermal activity measure (\u00b5V)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Electrodermal activity influence\", fontsize=15)\nplt.show()","806002e1":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['gsr'], label='Test set')\nsns.distplot(train_df['gsr'], label='Train set')\nplt.legend()\nplt.xlabel(\"Electrodermal activity measure (\u00b5V)\", fontsize=12)\nplt.title(\"Electrodermal activity Distribution\", fontsize=15)\nplt.show()","04dbf6ac":"train_df.shape,test.shape","9cebba48":"features_n = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\", \"ecg\", \"r\", \"gsr\"]","820938fd":"train_df['pilot'] = 100 * train_df['seat'] + train_df['crew']\ntest_df['pilot'] = 100 * test_df['seat'] + test_df['crew']\n\nprint(\"Number of pilots : \", len(train_df['pilot'].unique()))","307ff962":"train_df.shape,test.shape","6ca5d713":"tr_col = train_df.columns","166d3e6f":"# scaler = MinMaxScaler()\n# train_df = scaler.fit_transform(train_df)\n# train_df = pd.DataFrame(train_df)\n# train_df.columns = tr_col\n# train_df","518ca54c":"# # train_df = normalize_by_pilots(train_df)\n# # test_df = normalize_by_pilots(test_df)\nfrom imblearn.over_sampling import SMOTE\ntrain_df, y = SMOTE().fit_resample(train_df, y.ravel())","63d1e133":"train_df.shape","3559ba06":"train_df = pd.DataFrame(train_df)\ntrain_df.columns = tr_col\ntrain_df.head()","97c910e2":"print(train_df.shape,test.shape)\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=32)\nprint(f\"Training on {train_df.shape[0]} samples.\")","98249543":"features = [\"crew\", \"seat\"] + features_n\n      \ndef run_lgb(df_train, df_test):\n    # Classes as integers\n    dic = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n    try:\n        df_train[\"event\"] = df_train[\"event\"].apply(lambda x: dic[x])\n        df_test[\"event\"] = df_test[\"event\"].apply(lambda x: dic[x])\n    except: \n        pass\n    \n    params = {\"objective\" : \"multiclass\",\n              \"num_class\": 4,\n              \"metric\" : \"multi_error\",\n              \"num_leaves\" : 30,\n              \"min_child_weight\" : 50,\n              \"learning_rate\" : 0.1,\n              \"bagging_fraction\" : 0.7,\n              \"feature_fraction\" : 0.7,\n              \"reg_alpha\": 0.15,\n              \"reg_lambda\": 0.15,\n              \"min_child_weight\": 50,\n              \"bagging_seed\" : 420,\n              \"verbosity\" : -1\n             }\n#         params =  {\n# #             'task': 'train',\n#             'boosting_type': 'gbdt',\n#             'objective': 'multiclass',\n#             'num_class': 4,\n#             'metric': ['multi_error'],\n#             \"learning_rate\": 0.05,\n#              \"num_leaves\": 60,\n#              \"max_depth\": 9,\n#              \"feature_fraction\": 0.45,\n#              \"bagging_fraction\": 0.3,\n#              \"reg_alpha\": 0.15,\n#              \"reg_lambda\": 0.15,\n#         #      \"min_split_gain\": 0,\n#               \"min_child_weight\": 50\n#                         }\n    \n    lg_train = lgb.Dataset(df_train[features], label=(df_train[\"event\"]))\n    lg_test = lgb.Dataset(df_test[features], label=(df_test[\"event\"]))\n    model = lgb.train(params, lg_train, 1000, valid_sets=[lg_test], early_stopping_rounds=50, verbose_eval=100)\n    \n    return model","bd573277":"model = run_lgb(train_df, val_df)","588ed058":"fig, ax = plt.subplots(figsize=(12,10))\nlgb.plot_importance(model, height=0.8, ax=ax)\nax.grid(False)\nplt.ylabel('Feature', size=12)\nplt.xlabel('Importance', size=12)\nplt.title(\"Importance of the Features of our LightGBM Model\", fontsize=15)\nplt.show()","1541d721":"pred_val = model.predict(val_df[features], num_iteration=model.best_iteration)\n#pred_train = model.predict(train_df[features], num_iteration=model.best_iteration)","3826aea7":"print(\"Log loss on validation data :\", round(log_loss(np.array(val_df[\"event\"].values), pred_val), 3))","dcf25691":"def plot_confusion_matrix(cm, classes, title='Confusion matrix', normalize=False, cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    fmt = '.2f' if normalize else 'd'\n\n    fig, ax = plt.subplots(figsize=(15, 10))\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, size=15)\n    plt.colorbar()\n    plt.grid(False)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = (cm.max()+cm.min()) \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', size=12)\n    plt.xlabel('Predicted label', size=12)","511a6317":"conf_mat_val = confusion_matrix(np.argmax(pred_val, axis=1), val_df[\"event\"].values)\nplot_confusion_matrix(conf_mat_val, [\"A\", \"B\", \"C\", \"D\"], title='Confusion matrix on Validation data', normalize=True)","89d601ea":"pred_test = model.predict(test_df[features], num_iteration=model.best_iteration)","61e952e3":"submission = pd.DataFrame(np.concatenate((np.arange(len(test_df))[:, np.newaxis], pred_test), axis=1), columns=['id', 'A', 'B', 'C', 'D'])\nsubmission['id'] = submission['id'].astype(int)","59bb1723":"submission.head()","5f9ac85d":"submission.to_csv(\"submission.csv\", index=False)","a6aa6706":"### Model\nNote that I did not bother tweaking the parameters yet.","c123ea41":"We Also check if features have the same distribution on the test and train set","f493f2bc":"## **Solve Class Imbalance Problem Using SMOTE**","b97ffc82":"### Confusion Matrix","56aed564":"No missing values.","0a5e3d20":"Again, quite similar.","788c8c6c":"### Galvanic Skin Response\n - A measure of electrodermal activity. The sensor had a resolution\/bit of .2384186 \u00b5V and a range of -2.0V to +2.0V. The data are provided in microvolts.\n > \"The galvanic skin response (GSR, which falls under the umbrella term of electrodermal activity, or EDA) refers to changes in sweat gland activity that are reflective of the intensity of our emotional state, otherwise known as emotional arousal.\"","00b6ee9c":"### Seat\nWhich seat the pilot is sitting in.\n- 0 : left seat\n- 1 : right seat\n\nThis probably has nothing to do with the outcome of the experiment though.","d49ef165":"## 2 - EDA","9248a5ce":"### Electrocardiogram\n- 3-point Electrocardiogram signal. The sensor had a resolution\/bit of .012215 \u00b5V and a range of -100mV to +100mV. The data are provided in microvolts.","c60e5047":"### Submission","17839de5":"### Feature importance","1e806a5f":"# Starter Code : EDA and LGBM Baseline ","67328e03":"Except foir the >20000-ish samples, train\/test repartitions are similar.","cfbb86f9":"### Respiration \n- A measure of the rise and fall of the chest. The sensor had a resolution\/bit of .2384186 \u00b5V and a range of -2.0V to +2.0V. The data are provided in microvolts.","ed671f59":"Any feedback is always appreciated ! \n\n### *Thanks for reading !*\n","ec8adc7c":"Nothing much to say here, the test set has a bunch of sample with lower values though.","8bb762a2":"### Normalizing \n\nBecause of earlier remarks, we normalize our features. \n\nI do believe the following features depend a lot of the person, therefore I apply a Min\/Max Scaler for each pilot.","6f5b60a5":"Reparitions seem consistent :  Gaussians with a sinuso\u00efdal noise centered at 0. Note that the variance is larger on the test set.","c77652f0":"### Train \/ Test split","577e1ea6":"### Time of the experiment","0bda3e65":"### Target & Experiment\n\nThe pilots experienced distractions intended to induce one of the following three cognitive states:\n\n- Channelized Attention (CA) is, roughly speaking, the state of being focused on one task to the exclusion of all others. This is induced in benchmarking by having the subjects play an engaging puzzle-based video game.\n- Diverted Attention (DA) is the state of having one\u2019s attention diverted by actions or thought processes associated with a decision. This is induced by having the subjects perform a display monitoring task. Periodically, a math problem showed up which had to be solved before returning to the monitoring task.\n- Startle\/Surprise (SS) is induced by having the subjects watch movie clips with jump scares.\n\nSamples are labelled the following way : \n- A = baseline\n- B = SS\n- C = CA\n- D = DA","aa1b128c":"### Electroencephalogram recordings","54dd22cb":"The repartition of events is interesting. However, we can't use this feature because time in the flight simulator has nothing to do with time in the experiments. \nIt's a shame because take-off and landing could have been exploited.","d9ccd64f":"## 1 - Loading the Data","e2d5d2d1":"The experiment of the test set is LOFT (Line Oriented Flight Training), which is a full flight (take off, flight, and landing) in a flight simulator. ","385e5ae1":"## 3 - Gradient Boosting"}}