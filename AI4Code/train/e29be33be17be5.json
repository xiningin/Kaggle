{"cell_type":{"2c4d619c":"code","54d87e8e":"code","7c8b37f7":"code","49316452":"code","df75507a":"code","91b73292":"code","dee39948":"code","bc11c400":"code","ffb4d391":"code","0a8a71ff":"code","7b7c5575":"code","28373e1b":"code","8985359c":"code","fcb01ca4":"code","1aa2a621":"code","00b9119e":"code","faa62e99":"code","99c9a714":"code","1a67eb3a":"code","52e0b501":"code","45cee0a2":"code","a67440a7":"markdown","d2c9f8e0":"markdown","42ffcc33":"markdown","311236cc":"markdown","deb1d152":"markdown","52ea2278":"markdown","621ac1e0":"markdown","c9fdb893":"markdown","eefd5b80":"markdown","e550773e":"markdown","ae2741c0":"markdown","c86d0633":"markdown","98881fc7":"markdown","1ad438a2":"markdown","a0feb7b2":"markdown","101fd854":"markdown","04d1d01f":"markdown","2136ee4c":"markdown","5ce3a185":"markdown","2ce87556":"markdown","1e568c53":"markdown","9b7b0f43":"markdown","2cd27678":"markdown","1548bc6b":"markdown","039e9e65":"markdown"},"source":{"2c4d619c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np  \nimport seaborn as sns \npal = sns.color_palette()\nfrom wordcloud import WordCloud\nimport plotly.express as px\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nmatplotlib.style.use('ggplot')\nfrom sklearn import preprocessing\nimport glob\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport datetime as dt","54d87e8e":"districts_data=pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")","7c8b37f7":"districts_data.head()","49316452":"# plotting missing data information\n\nmissing_district_data = pd.DataFrame(districts_data.isnull().sum()\/len(districts_data)).reset_index().sort_values(by=0)\n\nplt.figure(figsize=(8,6))\nplt.bar(missing_district_data['index'],missing_district_data[0],alpha=0.75)\nplt.xticks(rotation=90)\n\nplt.rc('ytick', labelsize=10)\nplt.title('Percetage of missing data')","df75507a":"# To undertsand t\nobject_columns = ['state', 'locale', 'pct_black\/hispanic','pct_free\/reduced', 'county_connections_ratio', 'pp_total_raw']\n\nfor col in object_columns:\n    bold_start = '\\033[1m'\n    bold_end   = '\\033[0m'\n    print(bold_start,'\\nUnique values for ' + col + ' :',bold_end)\n    unique_values = districts_data[col].dropna().unique()\n    print(unique_values)\n    print('Number of unique values is:' + str(len(unique_values)))","91b73292":"state_codes = {\n    'District of Columbia' : 'dc','Mississippi': 'MS', 'Oklahoma': 'OK', \n    'Delaware': 'DE', 'Minnesota': 'MN', 'Illinois': 'IL', 'Arkansas': 'AR', \n    'New Mexico': 'NM', 'Indiana': 'IN', 'Maryland': 'MD', 'Louisiana': 'LA', \n    'Idaho': 'ID', 'Wyoming': 'WY', 'Tennessee': 'TN', 'Arizona': 'AZ', \n    'Iowa': 'IA', 'Michigan': 'MI', 'Kansas': 'KS', 'Utah': 'UT', \n    'Virginia': 'VA', 'Oregon': 'OR', 'Connecticut': 'CT', 'Montana': 'MT', \n    'California': 'CA', 'Massachusetts': 'MA', 'West Virginia': 'WV', \n    'South Carolina': 'SC', 'New Hampshire': 'NH', 'Wisconsin': 'WI',\n    'Vermont': 'VT', 'Georgia': 'GA', 'North Dakota': 'ND', \n    'Pennsylvania': 'PA', 'Florida': 'FL', 'Alaska': 'AK', 'Kentucky': 'KY', \n    'Hawaii': 'HI', 'Nebraska': 'NE', 'Missouri': 'MO', 'Ohio': 'OH', \n    'Alabama': 'AL', 'Rhode Island': 'RI', 'South Dakota': 'SD', \n    'Colorado': 'CO', 'New Jersey': 'NJ', 'Washington': 'WA', \n    'North Carolina': 'NC', 'New York': 'NY', 'Texas': 'TX', \n    'Nevada': 'NV', 'Maine': 'ME',np.nan:np.nan}\n\ndistricts_data['state_code'] =districts_data['state'].map(state_codes)\n\nmap_plot = districts_data.dropna(subset=['state'])","dee39948":"district_count = map_plot.groupby(['state','state_code'],as_index=False)['district_id'].count()\n\nfig = go.Figure(data=go.Choropleth(\n    locations=district_count['state_code'], # Spatial coordinates\n    z = district_count['district_id'].astype(float), # Data to be color-coded\n    locationmode = 'USA-states', # set of locations match entries in `locations`\n    text = district_count['state'],\n    colorscale = 'Reds',\n    colorbar_title = \"Number of school districts\",\n))\n\nfig.update_layout(\n    title_text = 'Number of school district in a state',\n    geo_scope='usa',width=800, height=600 # limite map scope to USA\n)\n\nfig.show()","bc11c400":"#Distribution of localities \n\nlocale_count = map_plot.groupby(['locale'],as_index=False)['district_id'].count()\nlocale_count =locale_count.rename(columns={'district_id':'Number of districts'})\n\nfig1 = px.pie(locale_count, values='Number of districts', names='locale', color='locale',hover_name='locale',\n             color_discrete_map={'City':'lightcyan',\n                                 'Rural':'cyan',\n                                 'Suburb':'royalblue',\n                                 'Town':'darkblue'},title='Distribution districts in different localities')\nfig1.show()","ffb4d391":"# distribution of black and hispanic population as per locality\n\nblc_hisp_count = map_plot.groupby(['locale','pct_black\/hispanic'],as_index=False)['district_id'].count()\npct_blk_hisp = {'[0, 0.2[':'0-20%', '[0.2, 0.4[':'20-40%' ,'[0.4, 0.6[':'40-60%', '[0.8, 1[':'80-100%', '[0.6, 0.8[':'60-80%'}\nblc_hisp_count['Percentage of black and hipanic population']=blc_hisp_count['pct_black\/hispanic'].map(pct_blk_hisp)\nblc_hisp_count = blc_hisp_count.rename(columns={'district_id':'Number of districts'})\ncity_b = blc_hisp_count[blc_hisp_count.locale=='City']\ntown_b = blc_hisp_count[blc_hisp_count.locale=='Town']\nsuburb_b = blc_hisp_count[blc_hisp_count.locale=='Rural']\nrural_b = blc_hisp_count[blc_hisp_count.locale=='Suburb']\nfrom plotly.subplots import make_subplots\n\n\nfig3 = make_subplots(rows=2, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}],[{'type':'domain'},{'type':'domain'}]])\n\nfig3.add_trace(go.Pie(labels=suburb_b['Percentage of black and hipanic population'], values=suburb_b['Number of districts'], name=\"Suburb\"),\n              1, 1)\nfig3.add_trace(go.Pie(labels=city_b['Percentage of black and hipanic population'], values=city_b['Number of districts'], name=\"City\"),\n              1, 2)\nfig3.add_trace(go.Pie(labels=rural_b['Percentage of black and hipanic population'], values=rural_b['Number of districts'], name=\"Rural\"),\n              2, 1)\nfig3.add_trace(go.Pie(labels=town_b['Percentage of black and hipanic population'], values=town_b['Number of districts'], name=\"Town\"),\n              2, 2)\n# Use `hole` to create a donut-like pie chart\nfig3.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig3.update_layout(\n    title_text=\"Distibution of black and hispanic population in different locality\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Suburb', x=0.17, y=.8, font_size=20, showarrow=False),\n                 dict(text='City', x=0.8, y=.8, font_size=20, showarrow=False),\n                 dict(text='Rural', x=0.18, y=0.175, font_size=20, showarrow=False),\n                dict(text='Town', x=0.82, y=0.175, font_size=20, showarrow=False)], width=900, height=800)\n\nfig3.show()","0a8a71ff":"CSV_files=pd.DataFrame()\naddress = glob.glob('..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/*.csv')\ncount=0\nfor i in address:\n    with open(i, \"rb\") as data_of_files:\n        data=pd.read_csv(data_of_files)\n        data['district_id'] = (i.split('\/')[4]).split('.')[0]\n        CSV_files=pd.concat([CSV_files,data], axis=0)\n        count=count+1\n        if count==233:\n            break  \nCSV_files","7b7c5575":"# Percentage of missing values in each column\nmissing_engegement_data= pd.DataFrame(CSV_files.isnull().sum()*100\/len(CSV_files)).reset_index()\nmissing_engegement_data = missing_engegement_data.rename(columns={'index':'Column Name', 0:'Percentage of missing data'})\nmissing_engegement_data","28373e1b":"CSV_files['date'] = pd.to_datetime(CSV_files['time']).dt.date\nCSV_files['month']= pd.to_datetime(CSV_files['time']).dt.month_name()\nCSV_files['weekday']= pd.to_datetime(CSV_files['time']).dt.day_name()\nCSV_files","8985359c":"sns.set_style(\"dark\")\nsns.set(rc={'figure.figsize':(15,8.27)})\nsns.boxplot(x=CSV_files['month'], y = CSV_files['pct_access'], linewidth=5).set_title('Variation in percentage of students accessing the digital product over months ')","fcb01ca4":"order = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\nsns.set_style(\"dark\")\nsns.set(rc={'figure.figsize':(15,8.27)})\nsns.boxplot(x=CSV_files['weekday'], y = CSV_files['pct_access'],order=order, linewidth=5).set_title('Variation in percentage of students accessing the digital product over days of a week ')","1aa2a621":"engmnt_dist=CSV_files.groupby('district_id',as_index=False)['engagement_index','pct_access'].mean()","00b9119e":"engmnt_dist['district_id'] = engmnt_dist['district_id'].astype('str')\nengmnt_dist =engmnt_dist.sort_values(by='engagement_index')\nfig, axes = plt.subplots(ncols=2, sharey=True, figsize=(12,26),squeeze=True,)\naxes[0].barh(engmnt_dist['district_id'],engmnt_dist['engagement_index'], \n             color='red',align='center')\naxes[0].invert_xaxis()\naxes[0].yaxis.set_visible(False)\naxes[0].set(title='Mean engagement index')\naxes[1].barh( engmnt_dist['district_id'],engmnt_dist['pct_access'],\n             color='blue',align='center')\naxes[1].set(title='Mean percent access')\naxes[0].yaxis.set_visible(True)\nplt.rc('ytick', labelsize=6)\nplt.subplots_adjust(top=.95)\nfig.suptitle('Comparing engagement idex and percent access district wise')","faa62e99":"products_data = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")","99c9a714":"# Percentage of missing values in each column\nmissing_products_data= pd.DataFrame(products_data.isnull().sum()*100\/len(products_data)).reset_index()\nmissing_products_data = missing_products_data.rename(columns={'index':'Column Name', 0:'Percentage of missing data'})\nmissing_products_data","1a67eb3a":"sector_group = products_data.groupby('Sector(s)')['LP ID'].count()\nsector_group","52e0b501":"products_data['Primary Essential Function'] = products_data['Primary Essential Function'].astype('str')\nproducts_data[['Main Function','Sub Category']] = products_data['Primary Essential Function'].str.split('-', 1, expand=True)\nproduct_distribution = products_data.groupby(['Main Function','Sub Category'], as_index=False)['LP ID'].count()\nproduct_distribution = product_distribution.rename(columns={'LP ID':'Number of products'})","45cee0a2":"fig5 = px.sunburst(product_distribution, path=['Main Function', 'Sub Category'], values='Number of products',\n                  color='Number of products', \n                  color_continuous_scale='RdBu')\n                 \nfig5.update_layout(title='Number of products under each category of essential function')\nfig5.show()","a67440a7":"# Products Dataset","d2c9f8e0":"**How many products lie under a particular product function?**\n\nPrimary Essential Function gives basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled.\n\nLet's see distibution of products under each category","42ffcc33":"**Observations from the plot:**\n* For all months exclusing june and july there are some days when percenntage of students accessing the digital products is greater than 80%. This decrease in June and July can be due to the summer break during this time in most states.\n* Majority of the days percentage of students accessing the digital products is less than 1 %","311236cc":"# Engagement Dataset","deb1d152":"**What is the percentage of districts in different localities**\n\nFollowing plot shows percentage of districts that fall in each locatlity.\n\nThere are four localities in the data:\n* Suburb\n* City\n* Town \n* Rural","52ea2278":"**Observations from plot**\n* 272 products lie under Learning and Curiculum category\n* 30 products lie under School and districts operations\n* 34 products lie under Classroom Management","621ac1e0":"**States and districts**\n\nHow many districts are mentioned per state?\nWhat are the states which have highest numbr of school distrcits in the data?","c9fdb893":"District data includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab.","eefd5b80":"**Missing values in engagement data**","e550773e":"**Problem Statement**\n\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow.","ae2741c0":"**Unique values in distirict data**\n\nTo understand district data let us see what are the unqiue values in each of the columns","c86d0633":"# Variation in percentage of students accessing the digital product over week days\nPct_access gives the percentage of students in the district have at least one page-load event of a given product and on a given day.\n\nLet's see if the distibution of this vaiables changes over the week days.","98881fc7":"**Missing values in products data**","1ad438a2":"**Missing values in district data**\n* About 50% of values are missing from pp_total_raw columns\n* More than 24% of data is missing from columns other than district id and pp_total_raw ","a0feb7b2":"# Variation in percentage of students accessing the digital product over months\nPct_access gives the percentage of students in the district have at least one page-load event of a given product and on a given day.\n\nLet's see if the distibution of this vaiables changes over the months.","101fd854":"Products data includes information about the characteristics of the top 372 products with most users in 2020.","04d1d01f":"**How the black and hispanic population is distributed in different localities**\n\nEach disttict under a locality has different percentage of black and hispanic population. Let us see what percetage of districts under a locality :\n* has highest black and hispanic population\n* has lowest black and hispani population","2136ee4c":"**Observation from plot**\n* General trend of engagement index and percet access is same accross the districts. The districts with hight engagement index seem to hvae hight percentage access.\n* There are some districts where engagement index is low but percent access is high.","5ce3a185":"**Observations from the plot**\n* Majority of the districts mentioned in the data fall in Suburb locatlity\n* Least number of dictricts fall in Town locality","2ce87556":"# Engagement index and Pct_access\nLet's see if varitaion in pct_access across districts and across days follows the same trend as the engagement index or not","1e568c53":"## **Districts data**","9b7b0f43":"**Missing data in district dataset**","2cd27678":"**Observations from the plot**\n* 93.9% of districts in Suburd locality have black and hispanic population of 0-20%. That means more than 90% of disticts in Suburb locality have low population of black and hispanics\n* Districts in City locality have differnt number of black and hispanic populations. We can see eqaul proportion of disctricts with different percentage of population.\n* Majority of the districts under town and rural localities have 0-20% of black and hispanic population","1548bc6b":"**Missing data in Engagment dataframe**\n* 24% of engagement_index values are missing.\n* .06% of pct_access values are missing\n* .002% of Ip_id values are missing","039e9e65":"**Observations from the plot:**\n* There is a decrease in percentage of students loading the page on weekends\n* Trend across the working days remains same"}}