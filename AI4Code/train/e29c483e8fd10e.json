{"cell_type":{"6ea57755":"code","6f19ec46":"code","26b2fa38":"code","8909bab8":"code","7ab4c9fb":"code","9beee5bb":"code","614cf146":"code","91e52cd1":"code","f4639091":"code","d90a1be1":"code","9f4dae9e":"code","147b505b":"code","def75bfe":"code","b1ed2fa9":"code","9b4313bd":"code","ee239a34":"code","5812794f":"code","259c3c5b":"code","d76f093e":"code","b668655b":"code","a5c84d6b":"code","ffa9d446":"code","2f1b7480":"code","9a706c9f":"code","de6ee14b":"code","9b6402f4":"code","b54e48eb":"code","9d3a3aa3":"code","d4bc462d":"code","f8b59fe5":"code","667667fb":"code","e7e08d81":"code","a704d7ae":"code","9a583e6d":"code","6d18b2f5":"code","b4d9d913":"code","04ff5f31":"code","a468821d":"code","18f32311":"code","d2798b42":"code","35a16f3e":"code","015ec2e9":"code","c2bb0c6c":"code","5c605f8e":"code","d7e65ac8":"code","4fa29f86":"code","6fab6bcd":"code","00e618cd":"code","b9a95291":"code","3c6281c9":"code","cf487ba8":"code","a34250c4":"markdown","ae2bd904":"markdown","11762476":"markdown","55b3a48b":"markdown","0a5e6000":"markdown","7f7a2d83":"markdown","7d88cc70":"markdown","737ac78d":"markdown","78403e5d":"markdown","91ba849c":"markdown","84c668de":"markdown","74870fa5":"markdown","2a4006a8":"markdown","9c8beac3":"markdown","303a111c":"markdown","d6775a8b":"markdown","094f62f5":"markdown","e454e09c":"markdown","84402647":"markdown","fd74167a":"markdown","ea5332a1":"markdown","9c887557":"markdown","4d005c55":"markdown","35735a1f":"markdown","bbeaa898":"markdown","79e0cae8":"markdown","ae9c3cf7":"markdown","084468c0":"markdown","5332af50":"markdown","e47c6ea0":"markdown","c1bba3e9":"markdown","9aad77f0":"markdown","7de9af70":"markdown","1ada76fa":"markdown","0e708131":"markdown","9233436c":"markdown","f5c4f347":"markdown","e82eeead":"markdown","97d85361":"markdown","bf3bfa37":"markdown"},"source":{"6ea57755":"import pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\nplt.style.use('fivethirtyeight')","6f19ec46":"data = pd.read_csv('..\/input\/loan.csv', low_memory=False)","26b2fa38":"data.drop(484446, inplace = True)\ndata.drop(531886, inplace = True)\ndata.drop(475046, inplace = True)\ndata.drop(532701, inplace = True)\ndata.drop(540456, inplace = True)","8909bab8":"sns.set(font_scale=1.5)\nfig, ax = plt.subplots()\nfig.set_size_inches(12, 6)\nsns.regplot(x='dti', y='annual_inc', data= data, line_kws={'color':'red'}, ax=ax)","7ab4c9fb":"data.boxplot(column='int_rate', by='grade', figsize=(12,6))","9beee5bb":"data.home_ownership.value_counts()","614cf146":"data=data.drop(data[data.home_ownership=='OTHER'].index)\ndata=data.drop(data[data.home_ownership=='ANY'].index)\ndata=data.drop(data[data.home_ownership=='NONE'].index)\ndata.home_ownership.replace('OWN','MORTGAGE', inplace=True)\ndata.home_ownership.value_counts()","91e52cd1":"data.loan_status.value_counts().plot(kind='barh', figsize=(7,5), title = \"Loan Status\", fontsize = 15)","f4639091":"matureLoan = data[(data.loan_status=='Fully Paid') | (data.loan_status=='Charged Off')].copy()","d90a1be1":"matureLoan.loan_status.value_counts()","9f4dae9e":"possibleFeatures=matureLoan[['emp_length', 'home_ownership', 'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths',\n                                'mths_since_last_delinq','mths_since_last_record', 'open_acc', 'pub_rec',\n                                'revol_bal', 'revol_util', 'total_acc', 'collections_12_mths_ex_med',\n                                'mths_since_last_delinq', 'open_acc_6m', 'open_il_6m','open_il_12m',\n                                'open_il_24m', 'mths_since_rcnt_il', 'il_util','open_rv_12m', 'open_rv_24m','max_bal_bc',\n                                'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m','tot_coll_amt','tot_cur_bal','loan_status']]","147b505b":"possibleFeatures.isnull().sum()","def75bfe":"matureLoan.emp_length.replace({'10+ years':10, '< 1 year':1, '1 year':1, '3 years':3, '8 years':8, '9 years':9, '4 years':4, '5 years':5, '6 years':6, '2 years':2, '7 years':7}, inplace=True)","b1ed2fa9":"matureLoan.emp_length.value_counts(dropna=False)","9b4313bd":"features = pd.get_dummies(matureLoan[['emp_length', 'home_ownership', 'annual_inc', 'dti', 'delinq_2yrs', \n                                       'inq_last_6mths', 'open_acc', 'pub_rec','revol_bal', 'revol_util', 'total_acc',\n                                       'collections_12_mths_ex_med','tot_coll_amt','tot_cur_bal','loan_status']],\n                                    drop_first = True)","ee239a34":"features.isnull().sum()","5812794f":"features.dropna(inplace=True)","259c3c5b":"features.isnull().sum()","d76f093e":"features.describe()","b668655b":"X=features.drop('loan_status_Fully Paid', axis=1)","a5c84d6b":"y=features['loan_status_Fully Paid']","ffa9d446":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","2f1b7480":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","9a706c9f":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","de6ee14b":"logreg = LogisticRegression()\nlogreg.fit(X_train,y_train)","9b6402f4":"name = features.columns\n\ncoef = logreg.coef_[0]\n\npd.DataFrame([name,coef],index = ['Name','Coef']).transpose()","b54e48eb":"features1 = pd.get_dummies(matureLoan[['annual_inc', 'dti','inq_last_6mths', 'revol_util', 'total_acc','tot_cur_bal','loan_status']],\n                                    drop_first = True)","9d3a3aa3":"features1.dropna(inplace=True)\nfeatures1.isnull().sum()","d4bc462d":"X1=features1.drop('loan_status_Fully Paid', axis=1)\ny1=features1['loan_status_Fully Paid']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)","f8b59fe5":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX1_train = scaler.fit_transform(X1_train)\nX1_test = scaler.transform(X1_test)","667667fb":"logreg1= LogisticRegression()\nlogreg1.fit(X1_train,y1_train)","e7e08d81":"name = features1.columns\n\ncoef = logreg1.coef_[0]\n\npd.DataFrame([name,coef],index = ['Name','Coef']).transpose()","a704d7ae":"y_pred1 = logreg1.predict(X1_test)","9a583e6d":"metrics.accuracy_score(y1_test,y_pred1)","6d18b2f5":"y1_test.mean()","b4d9d913":"from sklearn.tree import DecisionTreeClassifier\n\ntreeclf = DecisionTreeClassifier(max_depth=4, random_state=42)\ntreeclf.fit(X, y)","04ff5f31":"pd.DataFrame({'feature':X.columns, 'importance':treeclf.feature_importances_})","a468821d":"cm = metrics.confusion_matrix(y1_test,y_pred1)\nplt.clf()\nplt.rcParams[\"figure.figsize\"] = [6,6]\nplt.imshow(cm, cmap=plt.cm.Wistia)\nclassNames = ['Negative','Positive']\nplt.title('Loan Status Fully Paid')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\ns = [['TN','FP'], ['FN', 'TP']]\nfor i in range(2):\n    for j in range(2):\n        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\nplt.show()","18f32311":"y_pred_prob = logreg1.predict_proba(X1_test)[:, 1]","d2798b42":"plt.rcParams['font.size'] = 14\nplt.rcParams[\"figure.figsize\"] = [7,7]\nplt.hist(y_pred_prob)\nplt.xlim(0, 1)\nplt.title('Histogram of predicted probabilities')\nplt.xlabel('Predicted probability')\nplt.ylabel('Frequency')","35a16f3e":"plt.rcParams[\"figure.figsize\"] = [7,7]\nplt.hist(y_pred_prob, label='prediction')\nplt.hist(y1_test, label='test')\nplt.xlim(0, 1)\nplt.title('Histogram of test data vs. prediction')\nplt.xlabel('Actual data vs. predicted probability')\nplt.ylabel('Frequency')\nplt.legend()","015ec2e9":"y_pred_class6 = np.where(y_pred_prob > 0.6, 1, 0)\nmetrics.confusion_matrix(y1_test,y_pred_class6)","c2bb0c6c":"y_pred_class7 = np.where(y_pred_prob > 0.7, 1, 0)\nmetrics.confusion_matrix(y1_test,y_pred_class7)","5c605f8e":"y_pred_class8 = np.where(y_pred_prob > 0.8, 1, 0)\nmetrics.confusion_matrix(y1_test,y_pred_class8)","d7e65ac8":"y_pred_class9 = np.where(y_pred_prob > 0.9, 1, 0)\nmetrics.confusion_matrix(y1_test,y_pred_class9)","4fa29f86":"matureLoan['costChargeOff'] = matureLoan.loan_amnt - matureLoan.total_pymnt","6fab6bcd":"cost=matureLoan.costChargeOff[matureLoan.loan_status=='Charged Off']\ncost.mean()","00e618cd":"benefit = matureLoan.total_rec_int[matureLoan.loan_status=='Fully Paid']\nbenefit.mean()","b9a95291":"# Benefit of a True Positive = $1902\nBTP = 1902\n# Benefit of a True Negative = $0 since they don't qualify for the loan\nBTN = 0\n# Cost of a False Positive = $8188\nCFP = -8188\n# Cost of a False Negative = $0 since they don't qualify for the loan\nCFN = 0\n\n# Calculate the probabilities for each confusion matrix entry\nTP = 46168\/56718\nTN = 3\/56718\nFP = 10537\/56718\nFN = 10\/56718\n\nTP, TN, FP, FN","3c6281c9":"EV = BTP * TP + BTN * TN + CFP * FP + CFN * FN\nEV","cf487ba8":"thresholds=[0.5, 0.6, 0.7, 0.75, 0.8, 0.9]\nMSE=[27, 37, 127, 229, 308, 113]\n\nplt.plot(thresholds, MSE)\nplt.xlabel('Threshold')\nplt.ylabel('Expected Value ($)')","a34250c4":"Looks like we have class imbalance, plot histogram","ae2bd904":"**Lets use a different classification technique just to confirm that we chose the right features**","11762476":"Threshold = 0.8","55b3a48b":"Multiply Cost-Benefit Matrix & Confusion Matrix<br>\n\nCost Benefit Matrix * Confusion Matrix probabilities<br>\n\n|0     8188|             |pTN    pFP|<br>\n|0     1902|             |pFN    pTP|<br><br>\nExpected Value = BTP * pTP + BTN * pTN + CFP * pFP + CFN * pFN","0a5e6000":"When looking at a business use case for Lending Club loans:<br><br>\n\nBenefit of a True Positive = 1902 dollars<br>\nBenefit of a True Negative = 0 since they don't qualify for the loan<br>\nCost of a False Positive = 8188 dollars<br>\nCost of a False Negative = 0 since they don't qualify for the loan<br>\n\nCost Benefit Matrix=\n\n   |0   8188|<br>\n   |0   1902|","7f7a2d83":"Since we have class imbalance, we have to change the model's threshold","7d88cc70":"Output the coefficients to help prioritize which features are important","737ac78d":"Here is the features list after clean up & applying get_dummies","78403e5d":"Threshold = 0.6","91ba849c":"What important loan metric is missing?  <font color='red'>FICO Score<\/font> ","84c668de":"Keep the high coefficient values for our model and drop the rest","74870fa5":"Debt-to-Income vs. Annual Income relationship makes sense","2a4006a8":"Scale the dataset","9c8beac3":"Re-run logistic regression using the new features list","303a111c":"If we use our 0.5 threshold model to predict which loans to give out, we'll make $27\/customer","d6775a8b":"Threshold = 0.9","094f62f5":"Calculate the accuracy of the model","e454e09c":"Look at all potential features that are relevant to the applicant","84402647":"Clean up home ownership into two categories as it is a relevant applicant feature","fd74167a":"Compared to our test data, our model only predicts 1.0 (Loan fully paid) and almost never predicts 0.0 (loan defaul).","ea5332a1":"Use classification technique to create a model to predict loan default or payoff and maximize expected value for Lending Club","9c887557":"Drop some outliers","4d005c55":"Assume the Benefit of a fully paid loan (average) = Total interest received","35735a1f":"There is a strong corellation between the grade given and the interest rate given, but since this is assigned after the bank has performed their own prediction of risk, we can't use them as pre-application features.","bbeaa898":"Let's do the same calculation for the other confusion matrices if we change the thresholds","79e0cae8":"Compare to the Null Accuracy<br>\nNull Accuracy = the proportion of the majority class in the testing set (aka, baseline)","ae9c3cf7":"Drop all columns that have large NaN's<br>\nUse a dictionary to digitize emp_length column","084468c0":"Let's take a look at our logistic regression confusion matrix","5332af50":"Use the model to predict on x1_test","e47c6ea0":"Split my training & test data using 70\/30 split","c1bba3e9":"Threshold= 0.7","9aad77f0":"Decision Tree method confirms we have the right features in our model","7de9af70":"Look at 74 columns with 2 sample rows to get a glimpse of the data.<br>\nloan_status will serve as our target<br>\n<font color='green'>Possible applicant features listed below:<\/font> <br>\nemp_length, home_ownership, annual_inc<br>\nopen_acc = number of open credit lines in the borrower's credit file<br>\nrevol_bal = portion of CC spending thats unpaid at end of billing cycle<br>\nrevol_util = amount of credit the borrower is using relative to all available revolving credit.<br>\ndti=debt to income & inq_last_6mths= credit inquiries<br>\nhome_ownership","1ada76fa":"Assume the Cost of a charge-off (average)= Loan amount - Total payment received","0e708131":"Drop all rows for loan_status types except 'Fully Paid' and 'Charged Off' as they are the only categories that have matured.","9233436c":"If a dummy model were to predict the predominant class 100% of the time, it would be 81% correct, no difference from my model","f5c4f347":"**Conclusion:  Using a threshold of 0.8 allows our model to balance the loan qualifying\/denying decision while maximizing expected value.**","e82eeead":"**How do we apply the different confusion matrices to the real world?**<br>\nWe need to look at the business use case\n\nApply the Cost-Benefit Matrix","97d85361":"Threshold = 0.5, Expected Value = 27 dollars<br>\nThreshold = 0.6, Expected Value = 37 dollars<br>\nThreshold = 0.7, Expected Value = 127 dollars<br>\nThreshold = 0.75, Expected Value = 229 dollars<br>\nThreshold = 0.8, Expected Value = 308 dollars<br>\nThreshold = 0.9, Expected Value = 113 dollars<br>","bf3bfa37":"Perform logistic regression using loan_status as my target"}}