{"cell_type":{"504ace09":"code","e2e6aa10":"code","7d5518b3":"code","9bac02ef":"code","e55fe04a":"code","84918efb":"code","add2ddcc":"code","13236df8":"code","020aebc2":"code","26a22cde":"code","1d088aa9":"code","b24a5256":"code","dbd618c9":"code","265e2ced":"code","7ff50fea":"code","b53cfd58":"code","a443c309":"code","358ae066":"code","44a4f2c0":"code","5fad990c":"code","e61476f2":"code","1b65e873":"code","9231430b":"code","e9f238c1":"code","0663b681":"code","3152daa6":"code","59938c2c":"code","ee63b272":"code","69fbeff8":"code","c7eb5f63":"code","c3343fc4":"code","a06c224d":"code","86f3e76b":"code","25fe3780":"code","7bb11479":"code","0704b201":"code","759a3e2f":"code","c7908463":"code","d72881f9":"code","727e4b60":"code","2b01d2b4":"code","2a630ab8":"code","1eef893a":"code","59d9140b":"code","b9054f19":"code","92191d11":"code","0c41e823":"code","b928dbdc":"code","d6e4cec3":"code","407f77e1":"code","c4e031cb":"code","a24b17fa":"code","458edd2f":"code","d7e413f3":"code","ce23c32c":"code","9df87bd3":"code","0495099e":"code","c30f53cc":"code","af235109":"code","55e3ffe3":"code","2e2f3f09":"code","f909c4a8":"code","9ecf66c9":"code","93dc47c8":"code","2d9c1d09":"code","e3265275":"code","a8a6b3d6":"code","78c8f8a7":"code","8ab89872":"code","2ab1e742":"code","8436a121":"code","a56c4ada":"code","7b3865f9":"code","8a7d51d7":"code","079793eb":"code","0faa31d7":"code","913d2ebb":"code","5c71f56c":"code","12d90d60":"code","1ac86f58":"code","d2e330f5":"code","e6ef214e":"code","ea81c968":"code","8177e990":"code","3da336b1":"code","45ff841d":"code","70a9b258":"code","d681fd54":"code","37f9c990":"code","df035c16":"code","318c5893":"code","cb86e610":"code","35edf445":"code","89f605b0":"code","59bf4201":"code","849cbd60":"code","c0407632":"code","27434904":"code","a059a964":"code","02a20cce":"code","99c20ea0":"code","934e920d":"code","4f2f6999":"code","6c5d130b":"code","bbda141e":"code","c47804a6":"code","5309a1f7":"code","a614b35f":"code","305911e4":"code","d3a4be61":"code","a0908c90":"code","8126146c":"code","1fdebc29":"code","07f14a8c":"code","7d3a1452":"code","ca1e490f":"code","b062e6c8":"markdown","c6832c75":"markdown","1fa8f520":"markdown","73f9a7c1":"markdown","f64a45b3":"markdown","c5535249":"markdown","9e91d3c3":"markdown","19fdf00e":"markdown","6987d628":"markdown","a3dcf407":"markdown","1b171d8e":"markdown","2a052fac":"markdown","fbd1f1c2":"markdown","84eaff16":"markdown","0e3f5b85":"markdown","00bcb438":"markdown","a941716e":"markdown","8ee3b709":"markdown","25ef46d8":"markdown","496bcc29":"markdown","7b382bce":"markdown","6e29482e":"markdown","39879c22":"markdown","04b83840":"markdown","3dcec023":"markdown","80038111":"markdown","e57051af":"markdown","4b14bc65":"markdown","e50a13d7":"markdown","3515e37f":"markdown","b6c22336":"markdown","c3715657":"markdown","0de35e47":"markdown","0058f6e9":"markdown","d182e153":"markdown","d3dbaea1":"markdown","009634fc":"markdown","9d0a2b5f":"markdown","079e82b3":"markdown","53dea3b4":"markdown","5bc3f0a7":"markdown","33659c64":"markdown","67204f24":"markdown","d839c498":"markdown","c8da927e":"markdown","1028f5e1":"markdown","3032d991":"markdown","27391b14":"markdown","95fdfe6d":"markdown","014de3be":"markdown","1a33e173":"markdown","2360e3c7":"markdown","7301568f":"markdown","1ad87639":"markdown","7d1c71dd":"markdown","1e24f0ce":"markdown","7282252a":"markdown","ab4f52c8":"markdown","0c43d8d7":"markdown","eded3fb4":"markdown","393fffb6":"markdown","3e5fd02f":"markdown","90e7b6f8":"markdown","f72f8fbf":"markdown","fd28d156":"markdown","e9490072":"markdown","213a40d7":"markdown","8caff1d1":"markdown","bc3c8e57":"markdown","3731bc69":"markdown","afaa6916":"markdown","3b4f7e29":"markdown","99456472":"markdown","74105d96":"markdown","3e093548":"markdown","46272337":"markdown","9fcffede":"markdown","6c0a5b35":"markdown","4c0be77f":"markdown","ec319878":"markdown","bc318a4c":"markdown","808c23cc":"markdown","83c4d34d":"markdown","d4f39a78":"markdown","2504431d":"markdown","66e5d5ad":"markdown","54484326":"markdown","09a880d5":"markdown","afb8e7d6":"markdown","4bdf720f":"markdown","da0d1d13":"markdown","98c81820":"markdown","4d6aec81":"markdown","babca2a3":"markdown","8b019f04":"markdown","8928ae14":"markdown","1de68081":"markdown","5639d822":"markdown","f1a7b7f7":"markdown","9d753261":"markdown","2f9d2487":"markdown","d9b1b8e8":"markdown","e53c3c52":"markdown","e74c90b3":"markdown","5e01dad3":"markdown","dbd588e7":"markdown","b6e91b3e":"markdown","d646bb5d":"markdown","caf875ba":"markdown","1500b588":"markdown","2000d2aa":"markdown","412f75de":"markdown","f82b043d":"markdown","c056fc36":"markdown","72b44c60":"markdown","f39b9e87":"markdown","e2c59f16":"markdown"},"source":{"504ace09":"import pandas as pd\nimport plotly.express as px\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport joblib","e2e6aa10":"raw_df = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","7d5518b3":"raw_df","9bac02ef":"raw_df.info()","e55fe04a":"raw_df.dropna(subset=['RainToday','RainTomorrow'], inplace=True)","84918efb":"raw_df.info()","add2ddcc":"#configure matplotlib for visulaisation style\nsns.set_style('darkgrid')\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10, 6)\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'","13236df8":"fig = px.histogram(raw_df, x='Location', title='Distribution of Location', marginal='box',color='RainToday' )\nfig.update_layout(bargap=0.1)\nfig.show()","020aebc2":"fig = px.histogram(raw_df, x='MinTemp', title='Minimum Temperature Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","26a22cde":"fig = px.histogram(raw_df, x='MaxTemp', title='Maximum Temperature Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","1d088aa9":"fig = px.histogram(raw_df, x='RainTomorrow', title='Rain Tomorrow Vs Rain Today', marginal='box', color='RainToday')\nfig.update_layout(bargap=0.1)\nfig.show()","b24a5256":"fig = px.histogram(raw_df, x='Evaporation', title='Evaporation Distribution', color='RainTomorrow', marginal='box')\n#fig = px.histogram(raw_df[raw_df.Evaporation < 10], x='Evaporation', title='Evaporation Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.01)\nfig.show()","dbd618c9":"fig = px.histogram(raw_df, x='Sunshine', title='Sunshine Distribution', color='RainTomorrow', marginal='box')\n#fig = px.histogram(raw_df[raw_df.Sunshine <8], x='Sunshine', title='Sunshine Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","265e2ced":"fig = px.histogram(raw_df, x='WindGustDir', title='Wind Gust Direction Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","7ff50fea":"fig = px.histogram(raw_df, x='WindGustSpeed', title='Wind Gust Speed Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","b53cfd58":"fig = px.histogram(raw_df, x='WindDir9am', title='Wind Direction@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","a443c309":"fig = px.histogram(raw_df, x='WindDir3pm', title='Wind Direction@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","358ae066":"fig = px.histogram(raw_df, x='WindSpeed9am', title='WindSpeed@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","44a4f2c0":"fig = px.histogram(raw_df, x='WindSpeed3pm', title='WindSpeed@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","5fad990c":"fig = px.histogram(raw_df, x='Humidity9am', title='Humidity@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","e61476f2":"fig = px.histogram(raw_df, x='Humidity3pm', title='Humidity@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","1b65e873":"fig = px.histogram(raw_df, x='Pressure9am', title='Pressure@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","9231430b":"fig = px.histogram(raw_df, x='Pressure3pm', title='Pressure@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","e9f238c1":"fig = px.histogram(raw_df, x='Cloud9am', title='Cloud@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","0663b681":"fig = px.histogram(raw_df, x='Cloud3pm', title='Cloud@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","3152daa6":"fig = px.histogram(raw_df, x='Temp9am', title='Temperature@9AM Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","59938c2c":"fig = px.histogram(raw_df, x='Temp3pm', title='Temperature@3PM Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","ee63b272":"px.scatter(raw_df.sample(2000), x='MinTemp', y='MaxTemp', title='MinTemp Vs MaxTemp', color='RainToday')","69fbeff8":"px.scatter(raw_df.sample(2000), x='Rainfall', y='Evaporation', title='Rainfall Vs Evaporation', color='RainToday')","c7eb5f63":"px.scatter(raw_df.sample(2000), x='Sunshine', y='Evaporation', title='Sunshine Vs Evaporation', color='RainToday')","c3343fc4":"px.strip(raw_df.sample(2000), x='Temp9am', y='Humidity9am', title='Temp@9AM Vs Humidity@9AM', color='RainTomorrow')","a06c224d":"px.strip(raw_df.sample(2000), x='Temp3pm', y='Humidity3pm', title='Temp@3PM Vs Humidity@3PM', color='RainTomorrow')","86f3e76b":"px.strip(raw_df.sample(2000), x='Pressure9am', y='Humidity9am', title='Pressure@9AM Vs Humidity@9AM', color='RainTomorrow')","25fe3780":"px.strip(raw_df.sample(2000), x='Pressure3pm', y='Humidity3pm', title='Pressure@3PM Vs Humidity@3PM', color='RainTomorrow')","7bb11479":"px.strip(raw_df.sample(2000), x='Temp9am', y='Pressure9am', title='Temp@9AM Vs Pressure@9AM', color='RainTomorrow')","0704b201":"px.strip(raw_df.sample(2000), x='Temp3pm', y='Pressure3pm', title='Temp@3PM Vs Pressure@3PM', color='RainTomorrow')","759a3e2f":"use_sample = False\nsample_fraction = 0.1\nif use_sample:\n    raw_df = raw_df.sample(sample_fraction).copy()","c7908463":"train_val_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=42)\ntrain_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)","d72881f9":"print('train_df shape :',train_df.shape)\nprint('val_df shape :',val_df.shape)\nprint('test_df shape :',test_df.shape)","727e4b60":"plt.title('No. of Rows per year')\nsns.countplot(x=pd.to_datetime(raw_df.Date).dt.year);","2b01d2b4":"year = pd.to_datetime(raw_df.Date).dt.year\nyear","2a630ab8":"train_df = raw_df[year < 2015]\nval_df = raw_df[year == 2015]\ntest_df = raw_df[year > 2015]","1eef893a":"print('train_df shape :',train_df.shape)\nprint('val_df shape :',val_df.shape)\nprint('test_df shape :',test_df.shape)","59d9140b":"raw_df","b9054f19":"cols = list(train_df.columns)\ninput_cols = cols[1:-1]\ntarget_cols = cols[-1]","92191d11":"X_train = train_df[input_cols].copy()\nY_train = train_df[target_cols].copy()","0c41e823":"X_val = val_df[input_cols].copy()\nY_val = val_df[target_cols].copy()","b928dbdc":"X_test = test_df[input_cols].copy()\nY_test = test_df[target_cols].copy()","d6e4cec3":"numeric_cols = list(X_train.select_dtypes(include=np.number).columns)\ncategorical_cols = list(X_train.select_dtypes('object').columns)","407f77e1":"numeric_cols,categorical_cols","c4e031cb":"X_train.describe()","a24b17fa":"X_train[categorical_cols].nunique()","458edd2f":"raw_df[numeric_cols].isna().sum()","d7e413f3":"imputer = SimpleImputer(strategy='mean')","ce23c32c":"imputer.fit(raw_df[numeric_cols])   #fitting in raw_df not in X_train, X_val ","9df87bd3":"imputer.statistics_","0495099e":"X_train[numeric_cols] = imputer.transform(X_train[numeric_cols])\nX_val[numeric_cols] = imputer.transform(X_val[numeric_cols])\nX_test[numeric_cols] = imputer.transform(X_test[numeric_cols])","c30f53cc":"X_train[numeric_cols].isna().sum()","af235109":"scaler = MinMaxScaler()","55e3ffe3":"scaler.fit(raw_df[numeric_cols])  #not splitted data set","2e2f3f09":"X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])\nX_train[numeric_cols]","f909c4a8":"X_train[numeric_cols].describe()","9ecf66c9":"X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\nX_val","93dc47c8":"X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\nX_test","2d9c1d09":"raw_df[categorical_cols].nunique()","e3265275":"raw_df.Location.unique()","a8a6b3d6":"encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')","78c8f8a7":"encoder.fit(raw_df[categorical_cols])    #fit with entire dataset","8ab89872":"categorical_cols","2ab1e742":"encoder.categories_","8436a121":"encoded_cols = list(encoder.get_feature_names(categorical_cols))\nencoded_cols","a56c4ada":"X_train[encoded_cols] = encoder.transform(X_train[categorical_cols])","7b3865f9":"X_val[encoded_cols] = encoder.transform(X_val[categorical_cols])","8a7d51d7":"X_test[encoded_cols] = encoder.transform(X_test[categorical_cols])","079793eb":"print('X_train:', X_train.shape)\nprint('Y_train:', Y_train.shape)\nprint('X_val:', X_val.shape)\nprint('Y_val:', Y_val.shape)\nprint('X_test:', X_test.shape)\nprint('Y_test:', Y_test.shape)","0faa31d7":"X_train.to_parquet('X_train.parquet')\nX_val.to_parquet('X_val.parquet')\nX_test.to_parquet('X_test.parquet')","913d2ebb":"pd.DataFrame(Y_train).to_parquet('Y_train.parquet')\npd.DataFrame(Y_val).to_parquet('Y_val.parquet')\npd.DataFrame(Y_test).to_parquet('Y_test.parquet')","5c71f56c":"X_train = pd.read_parquet('X_train.parquet')\nX_val = pd.read_parquet('X_val.parquet')\nX_test = pd.read_parquet('X_test.parquet')","12d90d60":"Y_train = pd.read_parquet('Y_train.parquet')[target_cols]\nY_val = pd.read_parquet('Y_val.parquet')[target_cols]\nY_test = pd.read_parquet('Y_test.parquet')[target_cols]","1ac86f58":"print('X_train:', X_train.shape)\nprint('Y_train:', Y_train.shape)\nprint('X_val:', X_val.shape)\nprint('Y_val:', Y_val.shape)\nprint('X_test:', X_test.shape)\nprint('Y_test:', Y_test.shape)","d2e330f5":"model = LogisticRegression(solver ='liblinear') #liblinear optimization","e6ef214e":"%%time\nmodel.fit(X_train[numeric_cols + encoded_cols], Y_train)","ea81c968":"weight_df = pd.DataFrame({\n    'feature' : (numeric_cols + encoded_cols),\n    'weight' : model.coef_.tolist()[0]\n})","8177e990":"plt.figure(figsize=(10,50))\nsns.barplot(data=weight_df, x='weight', y='feature');","3da336b1":"sns.barplot(data=weight_df.sort_values('weight', ascending=False).head(10), x='weight', y='feature');","45ff841d":"X_train = X_train[numeric_cols + encoded_cols]\nX_val = X_val[numeric_cols + encoded_cols]\nX_test = X_test[numeric_cols + encoded_cols]","70a9b258":"train_pred = model.predict(X_train)\ntrain_probs = model.predict_proba(X_train)","d681fd54":"train_pred","37f9c990":"train_probs","df035c16":"Y_train","318c5893":"print('Accuracy =',accuracy_score(Y_train, train_pred))","cb86e610":"cf = confusion_matrix(Y_train, train_pred, normalize='true')","35edf445":"print('Accuracy =',accuracy_score(Y_train, train_pred)*100)\nplt.figure();\nsns.heatmap(cf, annot=True);\nplt.title('Training Confusion Matrix');\nplt.xlabel('Prediction');\nplt.ylabel('Target');","89f605b0":"X_val","59bf4201":"val_pred = model.predict(X_val)\ncf = confusion_matrix(Y_val, val_pred, normalize='true')\ncf","849cbd60":"print('Accuracy =',accuracy_score(Y_val, val_pred)*100)\nplt.figure();\nsns.heatmap(cf, annot=True);\nplt.title('Validation Confusion Matrix');\nplt.xlabel('Prediction');\nplt.ylabel('Target');","c0407632":"test_pred = model.predict(X_test)\ncf = confusion_matrix(Y_test, test_pred, normalize='true')","27434904":"print('Accuracy =', accuracy_score(Y_test, test_pred))\nplt.figure()\nsns.heatmap(cf, annot = True);\nplt.title('Testing Confusion Matrix');\nplt.xlabel('Prediction');\nplt.ylabel('Targer');","a059a964":"def random_model(inputs):\n    return np.random.choice(['No', 'Yes'], len(inputs))\nprint('Accuracy on Random Model on Validation Data Set =',accuracy_score(random_model(X_val), Y_val))","02a20cce":"def all_no(inputs):\n    return np.full(len(inputs), ['No'])\nprint('Accuracy on All_No Model on Test Data Set =',accuracy_score(all_no(X_test), Y_test))","99c20ea0":"Y_test.value_counts()","934e920d":"new_input = {'Date': '2021-06-19',\n             'Location': 'Katherine',\n             'MinTemp': 23.2,\n             'MaxTemp': 33.2,\n             'Rainfall': 10.2,\n             'Evaporation': 4.2,\n             'Sunshine': np.nan,\n             'WindGustDir': 'NNW',\n             'WindGustSpeed': 52.0,\n             'WindDir9am': 'NW',\n             'WindDir3pm': 'NNE',\n             'WindSpeed9am': 13.0,\n             'WindSpeed3pm': 20.0,\n             'Humidity9am': 89.0,\n             'Humidity3pm': 58.0,\n             'Pressure9am': 1004.8,\n             'Pressure3pm': 1001.5,\n             'Cloud9am': 8.0,\n             'Cloud3pm': 5.0,\n             'Temp9am': 25.7,\n             'Temp3pm': 33.0,\n             'RainToday': 'Yes'}","4f2f6999":"new_input = pd.DataFrame([new_input])","6c5d130b":"new_input","bbda141e":"new_input[numeric_cols] = imputer.transform(new_input[numeric_cols])\nnew_input[numeric_cols] = scaler.transform(new_input[numeric_cols])\nnew_input[encoded_cols] = encoder.transform(new_input[categorical_cols])","c47804a6":"X_inp = new_input[numeric_cols + encoded_cols]","5309a1f7":"print(model.predict(X_inp))","a614b35f":"model.predict_proba(X_inp)","305911e4":"new_input = {'Date': '2021-06-19',\n             'Location': 'Launceston',\n             'MinTemp': 23.2,\n             'MaxTemp': 33.2,\n             'Rainfall': 10.2,\n             'Evaporation': 4.2,\n             'Sunshine': np.nan,\n             'WindGustDir': 'NNW',\n             'WindGustSpeed': 52.0,\n             'WindDir9am': 'NW',\n             'WindDir3pm': 'NNE',\n             'WindSpeed9am': 13.0,\n             'WindSpeed3pm': 20.0,\n             'Humidity9am': 89.0,\n             'Humidity3pm': 58.0,\n             'Pressure9am': 1004.8,\n             'Pressure3pm': 1001.5,\n             'Cloud9am': 8.0,\n             'Cloud3pm': 5.0,\n             'Temp9am': 25.7,\n             'Temp3pm': 33.0,\n             'RainToday': 'Yes'}","d3a4be61":"def predict_input(single_input):\n    input_df = pd.DataFrame([single_input])\n    input_df[numeric_cols] = imputer.transform(input_df[numeric_cols])\n    input_df[numeric_cols] = scaler.transform(input_df[numeric_cols])\n    input_df[encoded_cols] = encoder.transform(input_df[categorical_cols])\n    X_input = input_df[numeric_cols + encoded_cols]\n    pred = model.predict(X_input)[0]\n    prob = model.predict_proba(X_input)[0][list(model.classes_).index(pred)]\n    return pred, prob","a0908c90":"predict_input(new_input)","8126146c":"aussie_rain = {\n    'model': model,\n    'imputer': imputer,\n    'scaler': scaler,\n    'encoder': encoder,\n    'input_cols': input_cols,\n    'target_col': target_cols,\n    'numeric_cols': numeric_cols,\n    'categorical_cols': categorical_cols,\n    'encoded_cols': encoded_cols\n}","1fdebc29":"joblib.dump(aussie_rain,'aussie_rain.joblib')","07f14a8c":"aussie_rain = joblib.load('aussie_rain.joblib')","7d3a1452":"aussie_rain","ca1e490f":"accuracy_score(aussie_rain['model'].predict(X_test), Y_test)","b062e6c8":"# Problem Statement\n\nPredict whether it is going to rain tomorrow or not based on todays's weather report","c6832c75":"## Pressure@3PM Vs Humidity@3PM","1fa8f520":"## Temp@3PM Vs Humidity@3PM","73f9a7c1":"#### Validation Data Set","f64a45b3":"# Making Predictions & Evaluations","c5535249":"#### Scale Training Data Set","9e91d3c3":"Whatever the cloud at 3pm, there is more possibility of ***no rain*** on the next day.<br>\nAs cloud at 3pm increases probability of raining on the next day increases.<br>\nFor cloud at 3pm = 8, there is more probability ofraining on the next day","19fdf00e":"## Wind Gust Direction\nThis is a categorical value with 16 categories of direction","6987d628":"#### Validation Set","a3dcf407":"# Saving & Loading Model\n\nWe can save the parameters (weights and biases) of our trained model to disk, so that we needn't retrain the model from scratch each time we wish to use it. Along with the model, it's also important to save imputers, scalers, encoders and even column names. Anything that will be required while generating predictions using the model should be saved.\n\nWe can use the `joblib` module to save and load Python objects on the disk. ","1b171d8e":"## Temperature@9AM Distribution","2a052fac":"***Note :***<br>\nIn these data frames, both categorical columns and corresponding encoded columns are also present","fbd1f1c2":"## Evaporation Distribution","84eaff16":"Whatever the evaporation rate, there is more possibility of ***no rain*** on the next day<br>\nAlso most commonly evaporation rate in which there is a low probability to rain on the next day is in the range is 0.6 - 8.","0e3f5b85":"Most of the samples for which the next day will rain have humidity > 30<br>\nMost of the samples for which the next day will not rain have humidity > 0<br>","00bcb438":"# Save Processed Data","a941716e":"The accuracy of the model on the test and validation set are above 84%, which suggests that our model generalizes well to data it hasn't seen before. \n\nBut how good is 84% accuracy? While this depends on the nature of the problem and on business requirements, a good way to verify whether a model has actually learned something useful is to compare its results to a \"random\" or \"dumb\" model.\n\nLet's create two models: one that guesses randomly and another that always return \"No\". Both of these models completely ignore the inputs given to them.","8ee3b709":"## Pressure@9AM Distribution","25ef46d8":"> **EXERCISE**: Initialize the `LogisticRegression` model with different arguments and try to achieve a higher accuracy. The arguments used for initializing the model are called hyperparameters (to differentiate them from weights and biases - parameters that are learned by the model during training). You can find the full list of arguments here: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html ","496bcc29":"## Minimum Temperature","7b382bce":"## Cloud@3PM Distribution","6e29482e":"## Sunshine Distribution","39879c22":"***Note***<br>\nFor RainToday=Yes, Minimum temperature and maximum temperature are nearer.<br>\nFor RainToday=No, Minimum temperature and maximum temperature are not nearer.<br>\n\nWhen there is rain, variation in temperature is small (i.e,maximum temperature is nearer to minimum temperature)","04b83840":"#### Identify Numerical & Categorical Columns","3dcec023":"Out of 140787 sample cases,around 110k there were rain the next day<br>\nbut around 30k there were no rain the next day.<br>\nThis is class imbalance i.e, no imbalance of each classes of target variable which may lead to bias towards not raining on tomorrow.\n\nThere were 92.728k cases with no rain today and tomorrow<br>\nThere were 16.858k cases with rain today and no rain tomorrow<br>\nThere were 16.604k cases with no rain today and rain tomorrow<br>\nThere were 14.597k cases with rain today and tomorrow<br>\n\nSo, there is a high chance that it will not rain tomorrow if it didn't rain today<br>\nBut it is not the case that it will rain tomorrow if it did rain today<br>\ni.e, there is equal chance of raining tomorrow if it either rains today or not.<br>\n\n<b>So it is easy to predict rain tomorrow as No but not easy to predict rain tomorrow as Yes (when rain today is no)","80038111":"Gaussian \/ Normal Distibution<br>\nIt seems for Lower the temperature, more cases of rain the next day<br>\nAlso there are some cases when temperature is high and there was rain the next day","e57051af":"Uniform Distribution<br>\nAbove 20% there were rain in all cities<br>\nNhil, Katherine, Uluru has lesser values than other cities.<br>\nThis might be probably due to no weather stations or data lost, or any other factors<br>\n\nTherefore, Location is a factor for rainfall","4b14bc65":"## Rainfall Distribution - Rain Tomorrow Vs Rain Today\nWe assumed a hypothesis that if there is rain on a day it is more likely to rain on the next day too<br>","e50a13d7":"When temperature@9am increases Humidity@9am decreases for both rainTomorrow=Yes or No<br>\nFor higher temperature and lower humidity it is more probable that it will not rain the next day","3515e37f":"#### Training Data Set","b6c22336":"## Humidity@9AM Distribution","c3715657":"#### Test Data Set","0de35e47":"#### Test Set","0058f6e9":"As rainfall increases, evaporation decreases<br>\nWhen rainfall in a day is less than or equal to 1, there is no rain on the next day<br>\nWhen rainfall in a day is more than 1, there is rain on the next day<br>","d182e153":"# Feature Scaling","d3dbaea1":"#### Confusion Matrix - Validation Data Set","009634fc":"Values Replaced by Average ","9d0a2b5f":"***Note :***\nThe date column is 2018 everywhere due to the split we have done. So, during testing our model won't<br> see any date as 2018 so it is useless to use date column as an input column.<br>\n\nRainTomorrow is target.<br>\nAll other than these are input columns.","079e82b3":"Whenever the humidity at 3pm is in the range 0 - 78, there is more possibility of ***no rain*** on the next day.<br>\nWhenever the humidity at 3pm is above 78, there is more possibility of ***raining*** on the next day.<br>","53dea3b4":"## Rainfall Vs Evaporation","5bc3f0a7":"#### Read those stored data","33659c64":"Whatever the wind speed at 3pm, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly wind speed at 3pm is in the range is 7 - 31 for which there is low probability to rain on the next day","67204f24":"Total Columns = 23<br>\nDate is irrelevant feature<br>\nRainTomorrow is taget feature<br>\nSo, 21 features and one taget feature<br>\nIn the dataset, there are missing values for some rows which can be preprocessed.<br>\n\n<b>Note :<\/b>There are also missing values in the target column 'RainTomorrow', <br>\nso those rows for which there are null values in target column 'RainTomorrow' are to be removed.<br>\n\nAlso, the feature 'RainToday' is a feature is likely to be very closely related to the target variable.<br>\nSo, we consider this hypothesis and remove rows with null values","d839c498":"#### Scaling Test Data Set","c8da927e":"#### Find Total Number of Nan in Numeric Coumns","1028f5e1":"# Imputing Missing Numeric Data\n\nSince there are some missing values, we'll get error when performing some steps in ML.\n\n<img src=\"https:\/\/i.imgur.com\/W7cfyOp.png\" width=\"480\">\n\nSo, we'll replace those values with average value from the column.<br>\n\nWe'll compute average from the entire set and fill it in train, val, test set individually","3032d991":"# Working With Sample","27391b14":"#### Confusion Matrix - Training Data Set","95fdfe6d":"## Maximum Temperature","014de3be":"Seems our model is not  confident with its prediction","1a33e173":"#### Load","2360e3c7":"# Making Prediction on Single Input","7301568f":"#### Training Set","1ad87639":"## Wind Direction@9AM\nThis is a categorical value with 16 categories of direction","7d1c71dd":"Let's first create a dictionary containing all the required objects.","1e24f0ce":"When Pressure@9am increases Humidity@9am increases<br>\nMost samples for which there will be no rain the next day have humidity > 20<br>\nMost samples for which there will be no rain the next day have humidity > 50<br>","7282252a":"The number of rows are reduced from 145460 to 140787 <br>\nAlso, no null values in the columns RainToday, RainTomorrow","ab4f52c8":"***Note :*** While working with dates (time-series data), it's often a better idea to separate the training, validation and test sets<br> with time, so that the model is trained on data from the past and evaluated on data from the future.<br>\n\nLet us analyse the years from which the dataset are from.","0c43d8d7":"#### Save All","eded3fb4":"Whatever the cloud at 9am, there is more possibility of ***no rain*** on the next day.<br>\nAs cloud at 9am(6-8) increases probability of raining on the next day increases","393fffb6":"# Import Libraries","3e5fd02f":"## Temp@9AM Vs Humidity@9AM","90e7b6f8":"The model achieves an accuracy of 85.1% on the training set. We can visualize the breakdown of correctly and incorrectly classified inputs using a confusion matrix.\n\n<img src=\"https:\/\/i.imgur.com\/UM28BCN.png\" width=\"480\">","f72f8fbf":"# Data Visualization & Analysis","fd28d156":"## Top 10 Important Features","e9490072":"Whatever the wind gust direction is, there is more possibility of ***no rain*** on the next day<br>\nAlso for every of the 16 directions, there is lower probability that there will be rain on the next day.","213a40d7":"Whatever the wind gust direction is, there is more possibility of ***no rain*** on the next day<br>\nAlso for every of the 16 directions, there is lower probability that there will be rain on the next day.","8caff1d1":"Whatever the minimum temperature is, there is more possible of ***no rain*** on the next day.<br>\nThere is less possibility to rain on the next day if the minimum temperature on the previous day is around 5 to 25<br>","bc3c8e57":"Whatever the wind speed at 9am, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly wind speed at 9am is in the range is 0 - 28 for which there is low probability to rain on the next day","3731bc69":"Therefore, just by predicting all as 'No' gives accuracy as 77 %.<br>\n***Note : *** Accuracy for All_No model is 77% and our model has accuracy as 84% for test data set<br>\n\nThis is because the validation data set is skewed towards 'No' as see below:","afaa6916":"#### Confusion Matrix - Test Data Set","3b4f7e29":"## Sunshine Vs Evaporation","99456472":"Whatever the wind gust direction is, there is more possibility of ***no rain*** on the next day<br>\nAlso for every of the 16 directions, there is lower probability that there will be rain on the next day.","74105d96":"## Pressure@9AM Vs Humidity@9AM","3e093548":"#### Accuracy","46272337":"## Wind Direction@3PM\nThis is a categorical value with 16 categories of direction","9fcffede":"## Location Distribution","6c0a5b35":"Whatever the pressure at 3pm, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly pressure at 3pm is in the range is 1000 - 1030 for which there is low probability to rain on the next day","4c0be77f":"With increase in temperature@3pm pressure@3pm decreases slightly<br>\nFor lesser temperature and pressure it is more likely to rain the next day<br>\nFor higher temperature and lower pressure it is not likely to rain on the next day","ec319878":"Whatever the maximum temperature is, there is more possible of ***no rain*** on the next day.<br>\nThere are rain on the next day if the maximum temperature on the previous day is around 10 to 35 <br>","bc318a4c":"## WindSpeed@3PM Distribution","808c23cc":"## Temp@9AM Vs Pressure@9AM","83c4d34d":"# Identify Input & Target Columns","d4f39a78":"#### Get Feature Names for the Encoded Columns","2504431d":"## Cloud@9AM Distribution","66e5d5ad":"We must now apply the same transformations applied while training the model:\n\n1. Imputation of missing values using the `imputer` created earlier (Average values for numeric columns only)\n2. Scaling numerical features using the `scaler` created earlier\n3. Encoding categorical features using the `encoder` created earlier","54484326":"Whatever the wind gust speed, there is more possibility of ***no rain*** on the next day<br>\nAlso most commonly wind gust speed is in the range is 24 - 65 for which there is low probability to rain on the next day.","09a880d5":"When temperature@3pm increases Humidity@3pm decreases for both rainTomorrow=Yes or No<br>\nBut during rainTomorrow=Yes, Humidity is more compared to rainTomorrow=No<br>\n\nWhen temperature@3pm is low & humidity@3pm is high, there is high chance that it will rain tomorrow","afb8e7d6":"> **EXERCISE**: Train a logistic regression model using just the numeric columns from the dataset. Does it perform better or worse than the model trained above?","4bdf720f":"## Pressure@3PM Distribution","da0d1d13":"From the histogram, as the luminuous intensity of sun increases it is more probably that it will ***not rain*** on the next day.<br>\nAnd when the luminuous intensity of sun is low it is more probably ***to rain*** on the next day","98c81820":"# Import Dataset","4d6aec81":"#### Encoding Location Column","babca2a3":"## Wind Gust Speed Distribution\nA sudden burst in wind speed is called the wind gusts","8b019f04":"With increase in sunshine, the evaporation rate is almost constant<br>\nWith increase in sunshine, there is a more possibility to rain on the next day as<br>\nthe number of samples where it rained the next day increases with increase in sunshine<br>","8928ae14":"## Min Temp Vs Max Temp","1de68081":"#### Store DataFrames as parquet format","5639d822":"#### Unique Categories of Categorical Data in Training Set","f1a7b7f7":"> **EXERCISE**: Train a logistic regression model using just the categorical columns from the dataset. Does it perform better or worse than the model trained above?","9d753261":"With increase in temperature@9am pressure@9am decreases slightly<br>\nFor less temperature and high pressure, it is more probable that it will not rain the next day","2f9d2487":"## Humidity@3PM Distribution","d9b1b8e8":"#### Scaling Validation Data Set","e53c3c52":"Therefore, just by predicting randomly accuracy is 50 %","e74c90b3":"Whatever the Temperature at 9am, there is more possibility of no rain on the next day.<br>\nAlso most commonly temperature at 9am is in the range is 10 - 30 for which there is low probability to rain on the next day.","5e01dad3":"# Encoding Categorical Values\n\nSince machine learning models can only be trained with numeric data, we need to convert categorical data to numbers by using techniques like one-hot encoding for categorical columns.\n\n<img src=\"https:\/\/i.imgur.com\/n8GuiOO.png\" width=\"640\">\n\nOne hot encoding involves adding a new binary (0\/1) column for each unique category of a categorical column. ","dbd588e7":"***Note : ***There is Nan value also","b6e91b3e":"We'll use datas till 2014 (inclusive) for training, 2015 for validation and 2016 & 2017 for testing<br>\neven there is no 60-20-20 ratio maintained.\n\nData from 2018, 2019 can be used for deployment (future).","d646bb5d":"## WindSpeed@9am Distribution","caf875ba":"Whatever the pressure at 9am, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly pressure at 9am is in the range is 1000 - 1030 for which there is low probability to rain on the next day","1500b588":"> **EXERCISE**: Apply some other imputation techniques and observe how they change the results of the model. You can learn more about other imputation techniques here: https:\/\/scikit-learn.org\/stable\/modules\/impute.html","2000d2aa":"Whatever the humidity at 9am, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly humidity at 9am is in the range is 60 - 100 for which there is low probability to rain on the next day","412f75de":"> **EXERCISE**: Train a logistic regression model without feature scaling. Also try a different strategy for missing data imputation. Does it perform better or worse than the model trained above?","f82b043d":"#### Statistics of Numerical Data in Training Set","c056fc36":"## Temperature@3PM Distribution","72b44c60":"# Training a Logistic Regression Model","f39b9e87":"# Training, Validation, Test Sets","e2c59f16":"## Temp@3PM Vs Pressure@3PM"}}