{"cell_type":{"f238f948":"code","a45a2b5f":"code","5db0d75e":"code","ee9dff11":"code","1e4a393e":"code","ff62f239":"code","dcf2dfa1":"code","9cafdfc5":"code","64dc7b8d":"code","99a0345e":"code","c8cc05a1":"code","8933fda0":"code","3ff6342e":"code","273b81e9":"code","832561fe":"code","ac064c66":"code","41a6933e":"code","5841a5d7":"markdown","35a1797b":"markdown","397dfbd1":"markdown"},"source":{"f238f948":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt","a45a2b5f":"label = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/labels.csv')","5db0d75e":"train_dir = '\/kaggle\/input\/dog-breed-identification\/train\/'\ntest_dir  = '\/kaggle\/input\/dog-breed-identification\/test\/'","ee9dff11":"train_img = os.listdir(train_dir)\ntest_img  = os.listdir(test_dir)\n\nprint('Number of train_img',len(train_img))\nprint('Number of test_img' ,len(test_img))\nprint(len(set(train_img)))\nprint(len(set(test_img)))","1e4a393e":"label['path'] = train_dir+label.id+'.jpg'\n\nfig,axes = plt.subplots(2,5,figsize = (30,10))\n\nfor ax in axes.reshape(-1,):\n    rnd_idx = np.random.randint(label.index[0],label.index[-1])\n    arr = plt.imread(label.loc[rnd_idx,'path'])\n    ax.imshow(arr)\n    ax.set_title(label.loc[rnd_idx,'breed']+'\\n'+str(arr.shape))\n    ax.axis('off')\n\n# as we can see pictures have different size.\n# lets extract this feature and write to label frame","ff62f239":"# there should be more straitforward way\n\nsizes_info = label.path.apply(lambda x: plt.imread(x).shape).values.tolist()\nmeta_df    = pd.DataFrame(sizes_info,columns = ['height','width','channels'])\nlabel      = pd.merge(label,meta_df,how = 'left',left_index = True,right_index=True)","dcf2dfa1":"import seaborn as sns\n\nfig,axes = plt.subplots(1,3,figsize = (20,5))\n\nfor ax,col in zip(axes,['height','width','channels']):\n    label[[col]].hist(bins = 100,ax = ax)\n\n# most of the pictures have height = 300 and width 500\n# make sense to rescale pictures","9cafdfc5":"label['id1'] = label.id+'.jpg'\nbreed = label.breed.unique()","64dc7b8d":"rnd_row = np.random.randint(label.index[0],label.index[-1],2000)\nshorter_df = label.loc[rnd_row,:].reset_index(drop = True)","99a0345e":"import tensorflow as tf\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale          =1.\/255,\n    #rotation_range   = 45,\n    #horizontal_flip  = True,\n    #shear_range      = 0.2,\n    validation_split = 0.25\n)\n\ntrain_generator=datagen.flow_from_dataframe(\n    dataframe = label,\n    directory=\"\/kaggle\/input\/dog-breed-identification\/train\/\",\n    x_col=\"id1\",\n    y_col=\"breed\",\n    color_mode = 'rgb',\n    subset = 'training',\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=\"categorical\",\n    target_size=(300,300)\n)\n\nval_generator=datagen.flow_from_dataframe(\n    dataframe = label,\n    directory=\"\/kaggle\/input\/dog-breed-identification\/train\/\",\n    x_col=\"id1\",\n    y_col=\"breed\",\n    color_mode = 'rgb',\n    subset = 'validation',\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=\"categorical\",\n    target_size=(300,300)\n)\n\n","c8cc05a1":"classes = train_generator.class_indices","8933fda0":"classes = {x:y for x,y in classes.items()}","3ff6342e":"mnv = tf.keras.applications.inception_v3.InceptionV3(include_top = False,\n                                           weights      = 'imagenet',\n                                           input_shape = (300,300,3))\n\nmnv.trainbale = False\nfor layer in mnv.layers:\n    layer.trainable = False\n    \n\nmodel = tf.keras.Sequential([\n    mnv,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation ='relu'),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(256,activation ='relu'),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(120,activation = 'softmax')\n])","273b81e9":"model.compile(loss = 'categorical_crossentropy',\n              optimizer = tf.keras.optimizers.Adam(),\n              metrics   = ['accuracy'])\n\nhist = model.fit_generator(generator = train_generator,\n                           epochs = 3,\n                           steps_per_epoch  = train_generator.n\/\/train_generator.batch_size,\n                           validation_data  = val_generator,\n                           validation_steps = val_generator.n\/\/val_generator.batch_size)\n","832561fe":"fig, ax = plt.subplots(figsize = (5,5))\nax.plot(range(1,len(hist.history['accuracy'])+1),hist.history['accuracy'])\nax.plot(range(1,len(hist.history['val_accuracy'])+1),hist.history['val_accuracy'])","ac064c66":"val_pred = np.argmax(model.predict(val_generator),axis=-1)\nclasses = {x:y for y,x in classes.items()}\n\nfig,axes = plt.subplots(2,5,figsize = (30,10))\n\nfor ax in axes.reshape(-1,):\n    rnd_idx = np.random.randint(0,len(val_generator.filepaths))\n    arr = plt.imread(val_generator.filepaths[rnd_idx])\n    ax.imshow(arr)\n    breed_true = classes[val_generator.classes[rnd_idx]]\n    breed_pred = classes[val_pred[rnd_idx]]\n    \n    if breed_true != classes[val_pred[rnd_idx]]:\n        ax.set_title(breed_true+'\\n'+ breed_pred,color = 'red',fontsize = 15)\n    else:\n        ax.set_title(breed_true+'\\n'+ breed_pred,color = 'black',fontsize = 15)\n\n    ax.axis('off')","41a6933e":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(val_generator.classes,val_pred)","5841a5d7":"# Check images","35a1797b":"# Check model performance","397dfbd1":"# Initiate transfer learning"}}