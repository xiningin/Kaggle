{"cell_type":{"b9e85f4a":"code","095c5d45":"code","3c84fcc8":"code","fb2f5d0f":"code","09cb91bc":"code","ba7b2c20":"code","e7553550":"code","cb6f0b8c":"code","a9dd584a":"code","fe93d397":"code","01921b27":"code","b2c5641f":"code","ee9a64f4":"code","51c34345":"code","f220eb05":"code","a5edec55":"code","7a55dc7e":"code","f2378a7d":"code","d2b408e1":"code","634e6d75":"markdown","66ad7126":"markdown","5ad4dcd5":"markdown","260d9760":"markdown","7c75772b":"markdown","ec7358a0":"markdown","a8dea4cb":"markdown","d8a14373":"markdown","7e47d6ed":"markdown","ed858dde":"markdown","0cc32663":"markdown","5df67358":"markdown","55b652f1":"markdown","046f7778":"markdown"},"source":{"b9e85f4a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\n\n\n# from sklearn.cluster import KMeans\n# from sklearn.cluster import MiniBatchKMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport os\n\nfiles = [ os.path.join(dirname, filename) for dirname, _, filenames in os.walk('\/kaggle\/input') for filename in filenames   ]         \nfiles","095c5d45":"data = pd.read_csv(files[1])\ndata.set_index('Id', inplace = True )\ny =  data.iloc[:,-1:]","3c84fcc8":"plt.hist(y, bins=8)\nplt.title(\"Distribuitions of Cover_Types in train-set\")\nplt.xlabel(\"Cover Type\")","fb2f5d0f":"# cols = data.iloc[:,:14].columns\ncols_geo  = data.iloc[:,:10].columns     # Columns with Geographic information\ncols_wild = data.iloc[:,10:14].columns  # Wilderness columns\ncols_soil = data.iloc[:,-41:-1].columns   # Soil Types columns","09cb91bc":"rows = 2\ncols = len(cols_geo)\/\/rows\n\nfig, ax = plt.subplots(rows,cols, figsize=(20,8))\n\nfor cover in [1,2,3]:\n    for item in range(len(cols_geo)):\n        if cover ==3:\n            ax[item\/\/cols, item%cols].hist(data[data.Cover_Type.isin(range(3,8))][cols_geo[item]], \n                                           alpha=0.5, \n                                           label='Cover'+str(cover),\n                                          bins = 100)\n        else:\n            ax[item\/\/cols, item%cols].hist(data[data.Cover_Type.isin([cover])][cols_geo[item]], \n                                           alpha=0.5, \n                                           label='Cover'+str(cover),\n                                          bins=100)\n        ax[item\/\/cols, item%cols].set_title(cols_geo[item])\n        \nax[0,0].legend()\n","ba7b2c20":"fig, ax = plt.subplots(figsize=(10,5))\nfor item in range(1,8):\n    ax.hist(data[data.Cover_Type.isin([item])][cols_geo[0]], alpha=0.5, label='Cover'+str(item), bins= 100)\n    ax.set_title(cols_geo[0])\nax.legend()","e7553550":"import pandas as pd\n\ndata = pd.read_csv(files[1])\ndata.set_index('Id', inplace = True )\n\ncols_wild = data.iloc[:,10:14].columns  # Wilderness columns","cb6f0b8c":"# This cell take a while\n\nfrom tqdm.notebook import tqdm_notebook\n\ndata['join_Wilder'] = [\"\"]*len(data)\n\nfor n, col in enumerate(cols_wild):\n    print(col)\n    data['join_Wilder'] += [ str(n+1) if data[col][i]==1 else \"\" for i in tqdm_notebook(range(len(data[col])) )]\ndata","a9dd584a":"fig, ax = plt.subplots(figsize=(20,7))\nax.hist(sorted(data['join_Wilder']))","fe93d397":"cols = ['Cover_Type', 'join_Wilder']\nwilder_gb = data.groupby(cols)['Elevation'].count()\nwilder_gb","01921b27":"ax = wilder_gb.unstack(level=0).plot(kind='bar', \n#                                      subplots=True, \n                                     layout =(7,1), \n                                     figsize=(20,5), \n#                                      sharey=True,\n                                     sharex=True)","b2c5641f":"ax = wilder_gb.unstack(level=1).plot(kind='bar', \n#                                      subplots=True, \n                                     layout =(7,1), \n                                     figsize=(20,5), \n#                                      sharey=True,\n                                     sharex=True)","ee9a64f4":"# Now without the Covers 1 and 2\n\nwilder_gb.unstack(level=0)[[3,4,5,6,7]]","51c34345":"ax = wilder_gb.unstack(level=0)[[3,4,5,6,7]].plot(kind='bar', \n                                     layout =(7,1), \n                                     figsize=(20,5), \n                                     sharex=True)","f220eb05":"data[cols_soil].sum(axis=0)\n# Just Soils 7 and 15 has not occurence","a5edec55":"def prepare_tables(file = 'train'):\n    \n    if file == 'train':\n        data = pd.read_csv(files[1])\n        data.set_index('Id', inplace = True)\n        data, y = data.iloc[:,:-1], data.iloc[:,-1:]\n        \n    elif file =='test':\n        data = pd.read_csv(files[2])\n        data.set_index('Id', inplace = True)\n        y = 0\n        \n    cols_wild = data.iloc[:,10:14].columns  # Wilderness columns\n    cols_soil = data.iloc[:,-40:].columns   # Soil Types columns\n\n    cols =[]\n    cols.append( [i for i in cols_wild ] )\n    cols.append( [i for i in cols_soil ] )\n    all_columns =  [ i for item in cols for i in item ]\n\n    train = data[all_columns].astype(np.uint8)      # Change the type to reduce memory usage\n    train['Elevation'] = data['Elevation']\/1000\n    \n    return train, y","7a55dc7e":"train, target = prepare_tables('train')\ntest , y = prepare_tables('test')","f2378a7d":"import xgboost as xgb\n\nX_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=0.2, random_state=13)\n\n# xg_train = xgb.DMatrix( X_train, y_train.Cover_Type,  enable_categorical = True)\nxg_train = xgb.DMatrix( X_train, y_train)\nxg_valid = xgb.DMatrix( X_valid, y_valid)\nxg_test = xgb.DMatrix( test)\nprint(\"Matrixes - Loaded\\n\")\n\nparams = {\n    'booster': 'gbtree',    \n    'eta': 0.03,\n    'max_depth': 5,     \n    'learning_rate': 0.05,\n    'objective': 'multi:softprob', # 'multi:softmax',\n    'num_class' : 4\n}\n\nclassifier = xgb.XGBClassifier(params, tree_method='gpu_hist'  )  ## HERE YOU ACTIVATE YOUR GPU\n\nmodel =  classifier.fit(X_train, y_train)\npred_xg_geo = model.predict(X_valid)\nprint('Accuracy on validation = ', np.round(accuracy_score(y_valid, pred_xg_geo)*100, 2), '%')","d2b408e1":"test_xg_geo = model.predict(test)\n\nsubm = pd.DataFrame( test_xg_geo, index= test.index, columns = ['Cover_Type'])\nsubm.to_csv('Submission.csv')","634e6d75":"To begin, we tried a simple classifier below with fixed parameters for the model.","66ad7126":"This model is going to use 'Elevation', and all the 'WildernessAreas' and 'Soil_Types'","5ad4dcd5":"## 3. Now we check the Soil Type\n\nWe could not find any pattern from SoilType besides de 40 different types. Then we used it as it was delivered.","260d9760":"Here we can see the best result obtained above and its parameter. Using the best_params_, just predict using the test-set and submit.","7c75772b":"Grab a cup of coffe. The cell below take a while to run. (10 min)","ec7358a0":"## 1. Geographic features\n\nFirstly, we are going to verify which geographic features impacts in the \"Cover Type\" \n\nWhen a histogram is plotted for Cover_Types(target), we can see that 'Elevation' is clear different ","a8dea4cb":"## 4. XGBoost - Classifier","d8a14373":"From the histogram below, WildernessArea = 3 is the most usual in the dataset. The second most frequent is 1.","7e47d6ed":"From this chart it is possible to predict that:\n- Elevation < 2500 --> Cover Type = 3\n- 2500 < Elevation < 3000 --> Cover Type = 2\n- Elevation > 3000 --> Cover Type =1 \n\n### --> This submission results in 0.8724 in public leaderboard.","ed858dde":"Using a histogram, we can see that CoverTypes 2 and 1 are the most frequent in dataset.","0cc32663":"## 2. Now we check the WildernessAreas\n\nWe joined the 4 columns of Wilderness areas into one conjugated columns. Then, if a row has [0,1,1,0] in respective Wilderness Areas, the conjugated columns became '23'.","5df67358":"Then we split the features in 3 different fields:\n- Geographical (10 first columns)\n- Wilderness Area (4 columns in the middle)\n- Soil Type (40 last columns)\n","55b652f1":"### Exploratory and XGBoostClassifier\n\nIn this notebook we made a simple EDA to get --> 0.87\n\nThen a simples XGBoost Classifier to get --> 0.91. \n\nNOTE:You can go further just adjusting the parameters.\n\n### --> Did you like this notebook?  **PLEASE UPVOTE**\n","046f7778":"### Using this model above, we got --> 0.91199 in publig leaderboard. An improvement from the \"Just Elevation model\"\n\n#### --> Did you like this notebook?  **PLEASE UPVOTE**"}}