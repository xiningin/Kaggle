{"cell_type":{"5e8059c7":"code","f0cde467":"code","bc3df538":"code","f195deec":"code","5e6397bd":"code","dd72e509":"code","5626be68":"code","223604f6":"code","6c1ec430":"code","dac73693":"code","8fe73f77":"code","db60270d":"code","01b1d374":"code","33f12d73":"code","adde9f1a":"code","9964812e":"markdown","98cf1bc4":"markdown","02ee5418":"markdown","a41429f4":"markdown","23860055":"markdown","3285e523":"markdown","e887f5e6":"markdown","c7f4617d":"markdown","9afeaf35":"markdown","c592a0c2":"markdown","292d3698":"markdown","46d268d6":"markdown","45c05639":"markdown","537eff15":"markdown","6d4e5eff":"markdown","a614632c":"markdown","c9166c48":"markdown","057ae4f9":"markdown"},"source":{"5e8059c7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pickle\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('..\/input'))\n\n# Any results we write to the current directory are saved as output\n","f0cde467":"# Opening file for reading in binary mode\nwith open('..\/input\/traffic-signs-preprocessed\/data2.pickle', 'rb') as f:\n    data = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Preparing y_train and y_validation for using in Keras\ndata['y_train'] = to_categorical(data['y_train'], num_classes=43)\ndata['y_validation'] = to_categorical(data['y_validation'], num_classes=43)\n\n# Making channels come at the end\ndata['x_train'] = data['x_train'].transpose(0, 2, 3, 1)\ndata['x_validation'] = data['x_validation'].transpose(0, 2, 3, 1)\ndata['x_test'] = data['x_test'].transpose(0, 2, 3, 1)\n\n# Showing loaded data from file\nfor i, j in data.items():\n    if i == 'labels':\n        print(i + ':', len(j))\n    else: \n        print(i + ':', j.shape)\n\n# x_train: (86989, 32, 32, 3)\n# y_train: (86989, 43)\n# x_test: (12630, 32, 32, 3)\n# y_test: (12630,)\n# x_validation: (4410, 32, 32, 3)\n# y_validation: (4410, 43)\n# labels: 43\n","bc3df538":"%matplotlib inline\n\n# Preparing function for ploting set of examples\n# As input it will take 4D tensor and convert it to the grid\n# Values will be scaled to the range [0, 255]\ndef convert_to_grid(x_input):\n    N, H, W, C = x_input.shape\n    grid_size = int(np.ceil(np.sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width, C)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) \/ (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid\n\n\n# Visualizing some examples of training data\nexamples = data['x_train'][:81, :, :, :]\nprint(examples.shape)  # (81, 32, 32, 3)\n\n# Plotting some examples\nfig = plt.figure()\ngrid = convert_to_grid(examples)\nplt.imshow(grid.astype('uint8'), cmap='gray')\nplt.axis('off')\nplt.gcf().set_size_inches(15, 15)\nplt.title('Some examples of training data', fontsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('training_examples.png')\nplt.close()\n","f195deec":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPool2D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(43, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","5e6397bd":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 15\n\nh = model.fit(data['x_train'][:10], data['y_train'][:10],\n              batch_size=5, epochs = epochs,\n              validation_data = (data['x_validation'], data['y_validation']),\n              callbacks=[annealer], verbose=1)\n","dd72e509":"print('Epochs={0:d}, training accuracy={1:.5f}, validation accuracy={2:.5f}'.\\\n      format(epochs, max(h.history['acc']), max(h.history['val_acc'])))\n","5626be68":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 5.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['font.family'] = 'Times New Roman'\n\nfig = plt.figure()\nplt.plot(h.history['acc'], '-o', linewidth=3.0)\nplt.plot(h.history['val_acc'], '-o', linewidth=3.0)\nplt.title('Overfitting small data', fontsize=22)\nplt.legend(['train', 'validation'], loc='upper left', fontsize='xx-large')\nplt.xlabel('Epoch', fontsize=20)\nplt.ylabel('Accuracy', fontsize=20)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('overfitting_small_data.png')\nplt.close()\n","223604f6":"filters = [3, 5, 9, 13, 15, 19, 23, 25, 31]\nmodel = [0] * len(filters)\n\nfor i in range(len(model)):\n    model[i] = Sequential()\n    model[i].add(Conv2D(32, kernel_size=filters[i], padding='same', activation='relu', input_shape=(32, 32, 3)))\n    model[i].add(MaxPool2D(pool_size=2))\n    model[i].add(Flatten())\n    model[i].add(Dense(500, activation='relu'))\n    model[i].add(Dense(43, activation='softmax'))\n    model[i].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","6c1ec430":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 5\n\nh = [0] * len(model)\n\nfor i in range(len(h)):\n    h[i] = model[i].fit(data['x_train'], data['y_train'],\n                        batch_size=5, epochs = epochs,\n                        validation_data = (data['x_validation'], data['y_validation']),\n                        callbacks=[annealer], verbose=0)\n    \n    print('Model with filters {0:d}x{0:d}, epochs={1:d}, training accuracy={2:.5f}, validation accuracy={3:.5f}'.\\\n      format(filters[i], epochs, max(h[i].history['acc']), max(h[i].history['val_acc'])))\n","dac73693":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 15.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['font.family'] = 'Times New Roman'\n\n# Plotting history of training accuracy\nfig = plt.figure()\nplt.subplot(2, 1, 1)\nplt.plot(h[8].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[7].history['acc'], '-s', linewidth=3.0)\nplt.plot(h[6].history['acc'], '-D', linewidth=3.0)\nplt.plot(h[5].history['acc'], '-D', linewidth=3.0)\nplt.plot(h[4].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[3].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[2].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[1].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[0].history['acc'], '-o', linewidth=3.0)\nplt.legend(['filter 31', 'filter 25', 'filter 23', 'filter 19', 'filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='lower right', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\nplt.ylabel('Training Accuracy', fontsize=20, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.85, 1.0)\nplt.xlim(0.5, 5.3) \nplt.title('Accuracy for different sizes of filters', fontsize=22)\nplt.tick_params(labelsize=18)\n\nplt.subplot(2, 1, 2)\n# plt.gca().set_title('Validation accuracy')\nplt.plot(h[8].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[7].history['val_acc'], '-s', linewidth=3.0)\nplt.plot(h[6].history['val_acc'], '-D', linewidth=3.0)\nplt.plot(h[5].history['val_acc'], '-D', linewidth=3.0)\nplt.plot(h[4].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[3].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[2].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[1].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[0].history['val_acc'], '-o', linewidth=3.0)\nplt.legend(['filter 31', 'filter 25', 'filter 23', 'filter 19', 'filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='lower right', fontsize='xx-large', borderpad=2)\nplt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\nplt.ylabel('Validation Accuracy', fontsize=20, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.75, 0.9)\nplt.xlim(0.5, 5.3)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('models_accuracy.png')\nplt.close()\n\n\n# Showing values of accuracy for different filters\nfor i in range(len(h)):\n    print('data2 filter {0:d} training accuracy = {1:.5f}'.\\\n          format(filters[i], np.max(h[i].history['acc'])))\n\nprint()\n\nfor i in range(len(h)):\n    print('data2 filter {0:d} validation accuracy = {1:.5f}'.\\\n          format(filters[i], np.max(h[i].history['val_acc'])))\n","8fe73f77":"for i in range(len(model)):\n    temp = model[i].predict(data['x_test'])\n    temp = np.argmax(temp, axis=1)\n\n    # We compare predicted class with correct class for all input images\n    # And calculating mean value among all values of following numpy array\n    # By saying 'testing_accuracy == data['y_test']' we create numpy array with True and False values\n    # 'np.mean' function will return average of the array elements\n    # The average is taken over the flattened array by default\n    temp = np.mean(temp == data['y_test'])\n    \n    print('data2 filter {0:d} testing accuracy = {1:.5f}'.format(filters[i], temp))\n","db60270d":"# Getting scores from forward pass of one input image\n# Scores are given for each image with 43 numbers of predictions for each class\n# Measuring at the same time execution time\n\nfor i in range(len(model)):\n    start = timer()\n    temp = model[i].predict(data['x_test'][:1, :, :, :])\n    end = timer()\n    \n    print('data2 filter {0:d} classification time = {1:.5f}'.format(filters[i], end - start))\n","01b1d374":"for i in range(len(model)):\n    w = model[i].get_weights()\n    print(w[0].shape)\n    # print(model[i].get_config())\n    # l = model[i].layers\n    # print(l[0].get_weights()[0].shape)\n\n    # Visualizing filters\n    temp = w[0].transpose(3, 0, 1, 2)\n    print(temp.shape)  # (81, 32, 32, 3)\n\n    # Plotting\n    fig = plt.figure()\n    grid = convert_to_grid(temp)\n    plt.imshow(grid.astype('uint8'), cmap='gray')\n    plt.axis('off')\n    plt.gcf().set_size_inches(10, 10)\n    name = 'Trained filters ' + str(filters[i]) + 'x' + str(filters[i])\n    plt.title(name, fontsize=18)\n    \n    # Showing the plot\n    plt.show()\n\n    # Saving the plot\n    name = 'filters-' + str(filters[i]) + 'x' + str(filters[i]) + '.png'\n    fig.savefig(name)\n    plt.close()\n","33f12d73":"%matplotlib inline\n\n# Preparing image for predicting from test dataset\nx_input = data['x_test'][100:101]\nprint(x_input.shape)\ny_input = data['y_test'][100:101]\nprint(y_input)\n\nplt.rcParams['figure.figsize'] = (2.5, 2.5) # Setting default size of plots\nplt.imshow(x_input[0, :, :, :])\nplt.axis('off')\n\n# Showing the plot\nplt.show()\n\n# Getting scores from forward pass of input image\nscores = model[0].predict(x_input)\nprint(scores[0].shape) # (43,)\n\n# Scores is given for image with 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\nprint('ClassId:', prediction)\n\n# Defining function for getting texts for every class - labels\ndef label_text(file):\n    # Defining list for saving label in order from 0 to 42\n    label_list = []\n    \n    # Reading 'csv' file and getting image's labels\n    r = pd.read_csv(file)\n    # Going through all names\n    for name in r['SignName']:\n        # Adding from every row second column with name of the label\n        label_list.append(name)\n    \n    # Returning resulted list with labels\n    return label_list\n\n\n# Getting labels\nlabels = label_text('..\/input\/traffic-signs-preprocessed\/label_names.csv')\n\n# Printing label for classified Traffic Sign\nprint('Label:', labels[prediction])\n","adde9f1a":"for i in range(len(model)):\n    name = 'model-' + str(filters[i]) + 'x' + str(filters[i]) + '.h5'\n    model[i].save(name)\n\n# # Saving model locally without committing\n# from IPython.display import FileLink\n\n# FileLink('model-3x3.h5')\n","9964812e":"**Design**, **Train** & **Test** deep CNN for Image Classification.\n\n**Join** the course & enjoy new opportunities to get deep learning skills:\n\n\n[https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/](https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/?referralCode=12EE0D74A405BF4DDE9B)\n\n\n![](https:\/\/github.com\/sichkar-valentyn\/1-million-images-for-Traffic-Signs-Classification-tasks\/blob\/main\/images\/slideshow_classification.gif?raw=true)","98cf1bc4":"# \ud83e\uddee Calculating accuracy with testing dataset","02ee5418":"## \ud83d\udcf0 Related Paper\nSichkar V. N. Effect of various dimension convolutional layer filters on traffic sign classification accuracy. *Scientific and Technical Journal of Information Technologies, Mechanics and Optics*, 2019, vol. 19, no. 3, pp. DOI: 10.17586\/2226-1494-2019-19-3-546-552 (Full-text available on ResearchGate here: [Effect of various dimension convolutional layer filters on traffic sign classification accuracy](https:\/\/www.researchgate.net\/publication\/334074308_Effect_of_various_dimension_convolutional_layer_filters_on_traffic_sign_classification_accuracy))\n\n$\\displaystyle ^*$ Experiments in the paper were done with pure numpy library and in different machine. Some results might be different. But main concept is implemented in this Notebook with Keras and can be repeated with ease or used for further research.\n\n$\\displaystyle ^*$ Test online with custom Traffic Sign here: https:\/\/valentynsichkar.name\/traffic_signs.html","a41429f4":"# \ud83d\udcc8 Plotting comparison results for accuracy","23860055":"# \ud83d\udc41\ufe0f Visualizing filters of convolutional layer","3285e523":"# \ud83d\udcc8 Plotting history results for overfitting small data","e887f5e6":"# \ud83c\udf93 Related course for classification tasks","c7f4617d":"# \ud83d\udcab Showing some examples","9afeaf35":"# \u26d4\ufe0f Traffic Signs Classification with CNN","c592a0c2":"# \ud83c\udfd7\ufe0f Building model of CNN with Keras\n## Trying one model with filters of size 3x3","292d3698":"# \u231b Time for classification","46d268d6":"# \ud83d\udca1 Training set of models of CNN with Keras\n## And with different dimensions of filters","45c05639":"# \ud83d\udce5 Importing needed libraries","537eff15":"# \ud83d\uddbc\ufe0f Predicting with one image from test dataset","6d4e5eff":"# \ud83c\udfd7\ufe0f Building set of models of CNN with Keras\n## Trying different models with different dimensions of filters","a614632c":"# \ud83d\udcbe Saving models","c9166c48":"# \ud83d\udcc2 Loading dataset data2.pickle with RGB examples","057ae4f9":"# \ud83e\udd0f Overfitting the 3x3 model with small amount of data"}}