{"cell_type":{"25f4c87c":"code","e8f9090b":"code","fb3544aa":"code","96e50419":"code","97e8026a":"code","82b4104f":"code","b71deed8":"code","7c813c06":"code","29e1195a":"code","6f763d51":"code","8826fcca":"code","d48fdae2":"code","eb72e8c1":"code","2f053569":"code","ee4716b8":"code","d1411993":"code","f373f081":"code","a0f9ca20":"code","60780a78":"code","50d09156":"code","221625e5":"code","ed157bc5":"code","3bceef4c":"code","3a3e3d2e":"code","1c57151b":"code","270443e6":"code","4f325636":"code","6aed34ad":"code","be2da3e5":"code","ab16754b":"code","93a47877":"code","5bc6821f":"code","acd0376a":"code","816d9d1f":"code","34757b8e":"code","d477e2fb":"code","ae36cfcf":"code","85f5b6b4":"code","975fbfb5":"code","7b74357a":"code","e53a4b26":"code","891415ef":"code","0204bef1":"code","0c900fa2":"code","6b757569":"code","3497b8a7":"code","b79d7797":"code","674e5ca2":"code","e1e42f38":"code","709db218":"code","9d52dbde":"code","b0304e16":"code","370fbe6a":"code","240fd9d0":"code","f98b1389":"code","6f2272a9":"code","90b16c70":"code","81c813f8":"code","e8e25e77":"code","a1dc13b1":"code","6bd443e7":"code","8bfe95b4":"code","cc774d71":"code","89674b3e":"code","4a8d1662":"code","29f887a4":"code","75dd18ce":"code","8fabb00e":"code","e88ea468":"code","ff2e3d89":"code","94a61584":"code","fa1a1ace":"code","ab26ce5e":"code","4204d309":"code","40e677ac":"code","219ac0d1":"code","a11846f3":"code","e01356ca":"code","1aa7c834":"code","679e35e0":"code","3c3b6652":"code","c4f2ca41":"code","105a83db":"code","f2ab4f7c":"code","0f9015d6":"code","ec72af22":"code","7090deb3":"code","74dfc05f":"markdown","0f5c9d35":"markdown","d0f64460":"markdown","92f0bda6":"markdown","53741bd1":"markdown","301d2dfe":"markdown","c40b5cfa":"markdown","04b9baf8":"markdown","4d1087fd":"markdown","568694dc":"markdown","0cb43bb0":"markdown","04915022":"markdown","b4c36000":"markdown","0bd8150f":"markdown","7ac1f9fc":"markdown","dfc2b3c8":"markdown","d753b32c":"markdown","f03d0e43":"markdown","ed55ea58":"markdown","a3753cad":"markdown","334bae9e":"markdown","61b154f7":"markdown","8a864a22":"markdown","ebd21620":"markdown","633796d6":"markdown","cef2dc6f":"markdown","fd2e5f32":"markdown","f9d2b1d4":"markdown","45da2807":"markdown","f9cfba22":"markdown","e98484d4":"markdown","163fc90d":"markdown"},"source":{"25f4c87c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfrom mpl_toolkits.mplot3d import Axes3D\nimport statsmodels.api as sm\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom scipy.stats import levene\nfrom scipy.stats import shapiro\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import ShuffleSplit, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import tree\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf","e8f9090b":"filterwarnings(\"ignore\", category=DeprecationWarning) \nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","fb3544aa":"Train = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\") # main train data\ndataTrain = Train.copy() # to protect main data, it is same as main data","96e50419":"Test = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\") # main test data\nTest = Test.drop(\"label\",axis=1)\ndataTest = Test.copy() # to protect main data, it is same as main data","97e8026a":"print(dataTrain.shape)","82b4104f":"print(dataTrain.columns)","b71deed8":"print(dataTrain.columns.value_counts().sum())","7c813c06":"print(dataTrain.info())","29e1195a":"print(dataTrain.index)","6f763d51":"print(type(dataTrain))","8826fcca":"print(dataTrain.isnull().sum().sum())","d48fdae2":"print(dataTrain.duplicated().sum())\n# since we are dealing with pixels, this section should be noted, duplicated values can be important for data, so we will not do anything","eb72e8c1":"print(dataTest.shape)","2f053569":"print(dataTest.columns)","ee4716b8":"print(dataTest.info())","d1411993":"print(dataTest.index)","f373f081":"print(type(dataTest))","a0f9ca20":"print(dataTest.isnull().sum().sum())","60780a78":"print(dataTest.duplicated().sum())\n# since we are dealing with pixels, this section should be noted, duplicated values can be important for data, so we will not do anything","50d09156":"x = dataTrain.drop(\"label\",axis=1)\ny = dataTrain[\"label\"]","221625e5":"xTrain,xTest,yTrain,yTest = train_test_split(x,y,test_size=0.2,random_state=42)","ed157bc5":"print(xTrain.shape)","3bceef4c":"print(xTest.shape)","3a3e3d2e":"print(yTrain.shape)","1c57151b":"print(yTest.shape)","270443e6":"scaler = StandardScaler()","4f325636":"xTrain = scaler.fit_transform(xTrain)\nxTest = scaler.fit_transform(xTest)\n# you can use other scalers\n# as the classifier models accept two-dimensional data, the data remain two-dimensional\n# for ANN, we will make data 3-dimensional","6aed34ad":"xTrain = xTrain.astype(\"float32\") \/ 255\n# to reduce processing time and make models more understand the data","be2da3e5":"print(xTrain.shape) # checking shape","ab16754b":"print(xTrain.ndim) # checking dimensions","93a47877":"print(xTrain.dtype) # checking type","5bc6821f":"xTest = xTest.astype(\"float32\") \/ 255\n# to reduce processing time and make models more understand the data","acd0376a":"print(xTest.shape) # checking shape","816d9d1f":"print(xTest.ndim) # checking dimensions","34757b8e":"print(xTest.dtype) # checking type","d477e2fb":"figure = plt.figure(figsize=(15,8))\nsns.countplot(dataTrain[\"label\"],color=\"red\")\nplt.show()","ae36cfcf":"figure = plt.figure(figsize=(15,8))\nsns.countplot(dataTest[\"label\"],color=\"black\")\nplt.show()","85f5b6b4":"figure = plt.figure(figsize=(15,8))\ndigitTrain1 = xTrain[4]\ndigitTrain1 = np.array(digitTrain1)\ndigitTrain1 = digitTrain1.reshape((28,28))\nplt.imshow(digitTrain1,cmap=plt.cm.binary)\nplt.show()","975fbfb5":"figure = plt.figure(figsize=(15,8))\ndigitTrain2 = xTrain[10]\ndigitTrain2 = np.array(digitTrain2)\ndigitTrain2 = digitTrain2.reshape((28,28))\nplt.imshow(digitTrain2,cmap=plt.cm.binary)\nplt.show()","7b74357a":"figure = plt.figure(figsize=(15,8))\ndigitTrain3 = xTrain[100]\ndigitTrain3 = np.array(digitTrain3)\ndigitTrain3 = digitTrain3.reshape((28,28))\nplt.imshow(digitTrain3,cmap=plt.cm.binary)\nplt.show()","e53a4b26":"figure = plt.figure(figsize=(15,8))\ndigitTrain4 = xTrain[400]\ndigitTrain4 = np.array(digitTrain4)\ndigitTrain4 = digitTrain4.reshape((28,28))\nplt.imshow(digitTrain4,cmap=plt.cm.binary)\nplt.show()","891415ef":"figure = plt.figure(figsize=(15,8))\ndigitTest1 = xTest[4]\ndigitTest1 = np.array(digitTest1)\ndigitTest1 = digitTest1.reshape((28,28))\nplt.imshow(digitTest1,cmap=plt.cm.binary)\nplt.show()","0204bef1":"figure = plt.figure(figsize=(15,8))\ndigitTest2 = xTest[40]\ndigitTest2 = np.array(digitTest1)\ndigitTest2 = digitTest2.reshape((28,28))\nplt.imshow(digitTest2,cmap=plt.cm.binary)\nplt.show()","0c900fa2":"figure = plt.figure(figsize=(15,8))\ndigitTest3 = xTest[5]\ndigitTest3 = np.array(digitTest3)\ndigitTest3 = digitTest3.reshape((28,28))\nplt.imshow(digitTest3,cmap=plt.cm.binary)\nplt.show()","6b757569":"figure = plt.figure(figsize=(15,8))\ndigitTest4 = xTest[500]\ndigitTest4 = np.array(digitTest4)\ndigitTest4 = digitTest4.reshape((28,28))\nplt.imshow(digitTest4,cmap=plt.cm.binary)\nplt.show()","3497b8a7":"# model training\n\nlj = LogisticRegression(solver=\"liblinear\").fit(xTrain,yTrain)\ngnb = GaussianNB().fit(xTrain,yTrain)\nknnc = KNeighborsClassifier().fit(xTrain,yTrain)\ncartc = DecisionTreeClassifier(random_state=42).fit(xTrain,yTrain)\nrfc = RandomForestClassifier(random_state=42,verbose=False).fit(xTrain,yTrain)","b79d7797":"# model list for loop, you can do it one by one if you want\n\nmodelsc = [lj,gnb,knnc,cartc,rfc]","674e5ca2":"for model in modelsc:\n    name = model.__class__.__name__\n    predict = model.predict(xTest)\n    R2CV = cross_val_score(model,xTest,yTest,cv=10,verbose=False).mean()\n    error = -cross_val_score(model,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\",verbose=False).mean()\n    print(name + \": \")\n    print(\"-\" * 10)\n    print(\"ACC-->\",accuracy_score(yTest,predict))\n    print(\"-\" * 10)\n    print(\"R2CV-->\",R2CV)\n    print(\"-\" * 10)\n    print(\"MEAN SQUARED ERROR-->\",np.sqrt(error))\n    print(\"-\" * 30)","e1e42f38":"params = {\"max_depth\": [2, 5, 8, 10],\n          \"max_features\": [2, 5, 8],\n          \"n_estimators\": [10, 500, 1000],\n          \"min_samples_split\": [2, 5, 10]}\n# you can try different parameters\n# it is for example","709db218":"cv = GridSearchCV(rfc,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\nprint(cv.best_params_)\nprint(cv.best_score_)\n\n# report --> {\"max_depth\": 5, \"max_features\": 5, \"n_estimators\": 500, \"min_samples_split\":10}","9d52dbde":"rfcmodel = RandomForestClassifier(max_depth=5,\n                                 max_features=5,\n                                 n_estimators=500,\n                                 min_samples_split=10,\n                                 verbose=False,\n                                 random_state=42).fit(xTrain,yTrain)","b0304e16":"predictrfcmodel = rfcmodel.predict(xTest)","370fbe6a":"R2CVtuned = cross_val_score(rfcmodel,xTest,yTest,cv=10,verbose=False).mean()\nprint(R2CVtuned)","240fd9d0":"conf = confusion_matrix(yTest,predictrfcmodel)\n# \u0131t is for visualization of confusion matrix ","f98b1389":"figure = plt.figure(figsize=(15,8))\nsns.heatmap(conf,annot=True,cmap=\"PiYG\",linewidths=2, linecolor='black')\nplt.show()","6f2272a9":"testLabel = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\ntestLabel = testLabel.drop(\"label\",axis=1)","90b16c70":"predictionRandom = rfc.predict(testLabel)","81c813f8":"print(predictionRandom[1])","e8e25e77":"figure = plt.figure(figsize=(15,8))\nTestPic = testLabel.iloc[1]\nTestPic = np.array(TestPic)\nTestPic = TestPic.reshape((28,28))\nplt.imshow(TestPic,cmap=plt.cm.binary)\nplt.show()","a1dc13b1":"xN = dataTrain.drop(\"label\",axis=1)\nyN = dataTrain[\"label\"]","6bd443e7":"print(xN.shape)","8bfe95b4":"xN = np.array(xN)\nxN = xN.reshape(60000, 28, 28)","cc774d71":"xNTrain,xNTest,yNTrain,yNTest = train_test_split(xN,yN,test_size=0.2,random_state=42)","89674b3e":"print(xNTrain.shape)","4a8d1662":"print(dataTrain[\"label\"].value_counts())","29f887a4":"ANNmodel = tf.keras.models.Sequential([\n  # inputs \n  tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255),\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  # hiddens layers\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  # output layer\n  tf.keras.layers.Dense(10)\n])\n\nlossfunc = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nANNmodel.compile(optimizer='adam', loss=lossfunc, metrics=['accuracy'])","75dd18ce":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)","8fabb00e":"MainModel = ANNmodel.fit(xNTrain, yNTrain, validation_split=0.2, epochs=30, callbacks=[callback],validation_data=(xNTest,yNTest))","e88ea468":"print(ANNmodel.summary())","ff2e3d89":"HistoryData = pd.DataFrame(ANNmodel.history.history)","94a61584":"print(HistoryData.head())","fa1a1ace":"HistoryData.plot()","ab26ce5e":"plt.plot(MainModel.history[\"accuracy\"])\nplt.plot(MainModel.history[\"val_accuracy\"])\nplt.ylabel(\"ACC\")\nplt.legend()\nplt.show()","4204d309":"HistoryDict = MainModel.history","40e677ac":"print(HistoryDict.keys())","219ac0d1":"val_losses = HistoryDict[\"val_loss\"]\nval_acc = HistoryDict[\"val_accuracy\"]\nacc = HistoryDict[\"accuracy\"]\nlosses = HistoryDict[\"loss\"]\nepochs = range(1,len(val_losses)+1)","a11846f3":"plt.plot(epochs,val_losses,\"bo\",label=\"LOSS\")\nplt.plot(epochs,val_acc,\"r\",label=\"ACCURACY\")\nplt.title(\"LOSS & ACCURACY\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"Loss & Acc\")\nplt.legend()\nplt.show()","e01356ca":"plt.plot(epochs,acc,\"bo\",label=\"ACCURACY\")\nplt.plot(epochs,val_acc,\"r\",label=\"ACCURACY VAL\")\nplt.title(\"ACCURACY & ACCURACY VAL\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"ACCURACY & ACCURACY VAL\")\nplt.legend()\nplt.show()","1aa7c834":"plt.plot(epochs,losses,\"bo\",label=\"LOSS\")\nplt.plot(epochs,val_losses,\"r\",label=\"LOSS VAL\")\nplt.title(\"LOSS & LOSS VAL\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"LOSS & LOSS VAL\")\nplt.legend()\nplt.show()","679e35e0":"print(dataTest.shape)","3c3b6652":"dataTest = np.array(dataTest)","c4f2ca41":"dataTest = dataTest.reshape(10000,28,28)","105a83db":"print(dataTest.shape)","f2ab4f7c":"predictANN = ANNmodel.predict(dataTest)","0f9015d6":"plt.imshow(dataTest[10])\nplt.show()","ec72af22":"p = [np.argmax(i) for i in predictANN]","7090deb3":"print(p[10])","74dfc05f":"# MODEL","0f5c9d35":"#### WARNINGS","d0f64460":"#### PREDICTION FOR MAIN RANDOM FOREST","92f0bda6":"#### CONTROLLING ACCURACY","53741bd1":"#### SEPARATION","301d2dfe":"#### PREDICTION","c40b5cfa":"# VISUALIZATION","04b9baf8":"# ANN - ARTIFICIAL NEURAL NETWORK","4d1087fd":"#### PARAMETERS","568694dc":"# PACKAGES AND LIBRARIES","0cb43bb0":"#### 3 means dress, prediction is true, check content again","04915022":"#### as we see, the best is Random Forest \/ R2 - %85\n\nwe need to be tuning","b4c36000":"#### TEST","0bd8150f":"# TRAIN AND TEST FOR TRAINING","7ac1f9fc":"#### STANDARDIZATION","dfc2b3c8":"#### CREATING NEW RANDOM FOREST MODEL","d753b32c":"#### CONTROLLING","f03d0e43":"#### TRAIN","ed55ea58":"#### TRAIN","a3753cad":"#### if you want to, you can use these models too\n\n* gbmc = GradientBoostingClassifier(verbose=False).fit(xTrain,yTrain)\n* xgbc = XGBClassifier().fit(xTrain,yTrain)\n* lgbmc = LGBMClassifier().fit(xTrain,yTrain)\n* catbc = CatBoostClassifier(verbose=False).fit(xTrain,yTrain)","334bae9e":"#### ACCURACY CHECKING","61b154f7":"# RANDOM FOREST PROCESS","8a864a22":"#### DEFINITION","ebd21620":"# DATA","633796d6":"#### TUNING","cef2dc6f":"#### TEST","fd2e5f32":"# EXPLORATORY DATA ANALYSIS","f9d2b1d4":"#### 2 means Pullover, but prediction is not true\n\nit is for example","45da2807":"#### MODEL PROCESS","f9cfba22":"# CONTENT\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n\nTo locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix\n\n* Each row is a separate image\n* Column 1 is the class label.\n* Remaining columns are pixel numbers (784 total).\n* Each value is the darkness of the pixel (1 to 255)\n\n\n#### Labels\n\n\n* 0 T-shirt\/top\n* 1 Trouser\n* 2 Pullover\n* 3 Dress\n* 4 Coat\n* 5 Sandal\n* 6 Shirt\n* 7 Sneaker\n* 8 Bag\n* 9 Ankle boot","e98484d4":"#### PREDICTION FOR TUNED MODEL","163fc90d":"#### CONTROLLING CONFUSION MATRIX"}}