{"cell_type":{"a5cb93cf":"code","087f00d0":"code","c1963166":"code","654488de":"code","f4e330b2":"code","f7c1dfd6":"code","bf86814f":"code","4b41b910":"code","a4e27a9e":"code","d39b4188":"code","e49485d8":"code","2fe58575":"code","e6df76aa":"code","1ffdf9d0":"code","b5c372e1":"code","87493f4e":"code","8683cfbb":"code","5a29af14":"code","1f5972e3":"code","01d9507e":"code","4ddace1b":"code","72b0fd67":"code","86f4635d":"code","a80de3ed":"code","c3087658":"code","645f5f57":"code","89871b96":"code","cb687341":"code","95fa881e":"code","5539f73e":"code","92af7c7b":"code","1bf3d865":"code","da4e3465":"code","e51962a6":"code","00180180":"code","2d881c1f":"code","4703b16b":"code","3afc330f":"code","bfd6dcfb":"code","de1c8fbe":"code","5275779f":"code","40c2842e":"code","d6e80f78":"code","bb359775":"code","0e17740b":"code","8091574d":"code","d736dfc9":"markdown","1d39a961":"markdown","87232988":"markdown","5873508f":"markdown","5003f080":"markdown","2792cb67":"markdown","8b7c3d3e":"markdown","d233eb5e":"markdown","c5993238":"markdown","0d9ab575":"markdown"},"source":{"a5cb93cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","087f00d0":"import numpy as np\nimport seaborn as sb\nimport pandas as pd","c1963166":"df = pd.read_csv('..\/input\/heights-and-weights\/data.csv')","654488de":"df","f4e330b2":"df.describe()","f7c1dfd6":"df.corr()","bf86814f":"import matplotlib.pyplot as plt\nplt.figure(figsize = (10,5))\nplt.title(\"Height Vs. Weight\")\nplt.xlabel(\"Height\")\nplt.ylabel(\"Weight\")\nplt.scatter(df.Height, df.Weight)\nplt.show()","4b41b910":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","a4e27a9e":"X = df.iloc[:,:-1].values\ny = df.iloc[:,-1].values","d39b4188":"X","e49485d8":"y","2fe58575":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","e6df76aa":"lreg = LinearRegression()\nlreg.fit(X_train, y_train)","1ffdf9d0":"print(f'Coefficient: {lreg.coef_}')\nprint(f'Intercept: {lreg.intercept_}')","b5c372e1":"plt.figure(figsize = (10,5))\nplt.title('Regression Line on Training Set')\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.scatter(X_train, y_train)\nplt.plot(X_train, lreg.predict(X_train), color = 'red')\nplt.show()","87493f4e":"X_test","8683cfbb":"y_pred = lreg.predict(X_test)","5a29af14":"print(f'Height: {X_test}'), print(f'Actual Weight: {y_test}'), print(f'Predicted Weight: {y_pred}') ","1f5972e3":"pd.DataFrame({'Height': X_test[:,0], 'Actual Weight': y_test, 'Predicted Weight': y_pred})","01d9507e":"plt.figure(figsize = (10,5))\nplt.title(\"Regression line on Test Set\")\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.scatter(X_test, y_test)\nplt.plot(X_test, y_pred, color = \"red\")\nplt.show()","4ddace1b":"print(f'Mean Squared Error: {metrics.mean_squared_error(y_test, y_pred)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, y_pred)}')\nprint(f'R2 Score: {metrics.r2_score(y_test, y_pred)}')\nprint(f'RMSE Score: {np.sqrt(metrics.mean_squared_error(y_test, y_pred))}')","72b0fd67":"sb.pairplot(df)","86f4635d":"from sklearn.linear_model import RANSACRegressor\n\nmodel = RANSACRegressor (base_estimator = LinearRegression(), max_trials = 100)\nmodel.fit(X_train, y_train)\n\ny_test_pred_rr = model.predict(X_test)\ny_train_pred_rr = model.predict(X_train)","a80de3ed":"print(\"Training Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_train, y_train_pred_rr)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_train, y_train_pred_rr)}')\nprint(f'R2 Score: {metrics.r2_score(y_train, y_train_pred_rr)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_train, y_train_pred_rr))}')\nprint(\"-----------------------------------\")\nprint(\"Test Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_test, y_test_pred_rr)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, y_test_pred_rr)}')\nprint(f'R2 Score: {metrics.r2_score(y_test, y_test_pred_rr)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_rr))}')","c3087658":"from sklearn.linear_model import Ridge","645f5f57":"model = Ridge(alpha = 0.01, solver = \"cholesky\", tol = 0.0001, random_state = 40)\nmodel.fit(X_train, y_train)\ny_test_pred_r = model.predict(X_test)\ny_train_pred_r = model.predict(X_train)","89871b96":"print(\"Training Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_train, y_train_pred_r)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_train, y_train_pred_r)}')\nprint(f'R2 Score: {metrics.r2_score(y_train, y_train_pred_r)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_train, y_train_pred_r))}')\nprint(\"-----------------------------------\")\nprint(\"Test Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_test, y_test_pred_r)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, y_test_pred_r)}')\nprint(f'R2 Score: {metrics.r2_score(y_test, y_test_pred_r)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_r))}')","cb687341":"plt.figure(figsize = (10,5))\nplt.title(\"Regression line on Test Set\")\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.scatter(X_test, y_test)\nplt.plot(X_test, y_test_pred_r, color = \"red\")\nplt.show()","95fa881e":"from sklearn.linear_model import Lasso","5539f73e":"model = Lasso(alpha = 0.1, precompute = True, positive = True, selection = \"random\", random_state = 40)","92af7c7b":"model.fit(X_train, y_train)\ny_test_pred_lar = model.predict(X_test)\ny_train_pred_lar = model.predict(X_train)","1bf3d865":"print(\"Training Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_train, y_train_pred_lar)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_train, y_train_pred_lar)}')\nprint(f'R2 Score: {metrics.r2_score(y_train, y_train_pred_lar)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_train, y_train_pred_lar))}')\nprint(\"-----------------------------------\")\nprint(\"Test Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_test, y_test_pred_lar)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, y_test_pred_lar)}')\nprint(f'R2 Score: {metrics.r2_score(y_test, y_test_pred_lar)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_lar))}')","da4e3465":"plt.figure(figsize = (10,5))\nplt.title(\"Regression line on Test Set\")\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.scatter(X_test, y_test)\nplt.plot(X_test, y_test_pred_lar, color = \"red\")\nplt.show()","e51962a6":"from sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree=2)\n\nX_train_2_d = poly_reg.fit_transform(X_train)\nX_test_2_d = poly_reg.fit_transform(X_test)\n\nlin_reg = LinearRegression(normalize = True)\nlin_reg.fit(X_train_2_d, y_train)\n\ny_test_pred_pr = lin_reg.predict(X_test_2_d)\ny_train_pred_pr = lin_reg.predict(X_train_2_d)","00180180":"plt.figure(figsize = (10,5))\nplt.title(\"Regression line on Test Set\")\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.scatter(X_test, y_test)\nplt.plot(X_test, y_test_pred_pr, color = \"red\")\nplt.show()","2d881c1f":"print(\"Training Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_train, y_train_pred_pr)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_train, y_train_pred_pr)}')\nprint(f'R2 Score: {metrics.r2_score(y_train, y_train_pred_pr)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_train, y_train_pred_pr))}')\nprint(\"-----------------------------------\")\nprint(\"Test Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_test, y_test_pred_pr)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, y_test_pred_pr)}')\nprint(f'R2 Score: {metrics.r2_score(y_test, y_test_pred_pr)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_pr))}')","4703b16b":"from sklearn.svm import SVR","3afc330f":"svm_reg = SVR(kernel = \"rbf\", C = 1000000, epsilon = 0.001)\nsvm_reg.fit(X_train, y_train)\n\ny_test_pred_svm = svm_reg.predict(X_test)\ny_train_pred_svm = svm_reg.predict(X_train)","bfd6dcfb":"plt.figure(figsize=(10,5))\nplt.title(\"SVM Regression Line on Test Data\")\nplt.xlabel(\"Height\")\nplt.ylabel(\"Weight\")\nplt.scatter(X_test, y_test)\nplt.plot(X_test, y_test_pred_svm, color = \"red\")\nplt.show()","de1c8fbe":"print(\"Training Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_train, y_train_pred_svm)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_train, y_train_pred_svm)}')\nprint(f'R2 Score: {metrics.r2_score(y_train, y_train_pred_svm)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_train, y_train_pred_svm))}')\nprint(\"-----------------------------------\")\nprint(\"Test Data Evaluation\")\nprint(f'Mean Squared Error: {metrics.mean_squared_error(y_test, y_test_pred_svm)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, y_test_pred_svm)}')\nprint(f'R2 Score: {metrics.r2_score(y_test, y_test_pred_svm)}')\nprint(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_svm))}')","5275779f":"lr_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))","40c2842e":"rr_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_rr))\nr_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_r))\nlar_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_lar))\npr_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_pr))\nsvm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_svm))","d6e80f78":"results_df = {\n    \"Model\": [\"Linear Regression\", \"Robust Regression\", \"Ridge Regression\", \"Lasso Regression\", \"Polynomial Regression\", \"SVM\"], \n    \"RMSE\": [lr_rmse, rr_rmse, r_rmse, lar_rmse, pr_rmse, svm_rmse]}","bb359775":"results = pd.DataFrame(data = results_df)","0e17740b":"results","8091574d":"results[\"RMSE\"].plot(kind = \"barh\", figsize = (12,8))","d736dfc9":"# Ridge Regression","1d39a961":"# Support Vector Machine","87232988":"# Comparison of Models","5873508f":"# \ud83d\udcff LASSO Regression","5003f080":"# \ud83d\udd0e EDA","2792cb67":"# \u2307Polynomial Regression","8b7c3d3e":"# \ud83d\udcaa Robust Regression","d233eb5e":"# \ud83d\udcc8 Linear Regression","c5993238":"> ***RMSE is a measure of how well the regression model is able to predict the value in aboslute terms. In general, the less the RMSE, more accurately will the model predict the weight. Hence, Polynomial Regression clearly is the best choice for this scenario.***","0d9ab575":"# \ud83e\uddd0 What do the results tell us? (Conclusion)"}}