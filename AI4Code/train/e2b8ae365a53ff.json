{"cell_type":{"a3c67197":"code","b57b8377":"code","2f1dd775":"code","c18d99c8":"code","5a32dd21":"code","5168003c":"code","bf672b08":"code","7778a7e8":"code","daa9d6cb":"code","02edef17":"code","e0fde3ad":"code","1b1b9dfa":"code","fc2cef0a":"code","b2c50e1c":"code","fb2927f8":"code","c1b78bd8":"code","384f7027":"code","d229f888":"code","7d3f64c9":"code","c11c66bf":"code","13853e62":"code","b87115d7":"code","eab71f67":"markdown","f06d5fc9":"markdown","bd9959b4":"markdown","92ccafcf":"markdown"},"source":{"a3c67197":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b57b8377":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom warnings import filterwarnings\nRANDOM_STATE = 12345\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.model_selection import train_test_split, cross_validate, cross_val_score,cross_val_predict, GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nimport lightgbm as lgbm\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","2f1dd775":"filterwarnings('ignore')","c18d99c8":"def open_file_info(filepath):\n    file = pd.read_csv(filepath)\n    display(file.head(5))\n    print('Shape = ',file.shape)\n    print(file.info())\n    return file\n","5a32dd21":"heart = open_file_info('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\n","5168003c":"saturation = open_file_info('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/o2Saturation.csv')","bf672b08":"cat_features = []\nfor i in heart.columns:\n    heart[i].hist()\n    name=heart[i].name\n    plt.title('Hist for column '+name)\n    plt.ylabel('amount')\n    plt.xlabel(name)\n    plt.show()\n    if heart[i].nunique() > 5:\n        sns.boxplot(x='output',y=name,data = heart)\n        plt.title('Boxplot for '+name)\n        plt.xlabel('output')\n        plt.show()\n        display(heart[i].describe())\n        print('Check the null hypotysys data taken from normal distribution:')\n        alpha = 0.05\n        print(stats.shapiro(heart[i]))\n    else:\n        if name != 'output':\n            cat_features.append(name)\n            sns.barplot(x=name,y='output',data = heart, estimator = np.mean)\n            plt.title('Barplot for '+name)\n            plt.xlabel(name)\n            plt.show()\n        print('Number of unique values:')\n        print(heart[i].value_counts())\n        print()\n        print('Fractions of unique values')\n        print( heart[i].value_counts()\/len(heart[i]))\n    print('--------'*18)\nprint('Cat_features: ',cat_features)","7778a7e8":"figure = plt.figure(figsize=(10,8))\nsns.heatmap(heart.corr(method='pearson'),annot = True,cmap= 'PiYG' )","daa9d6cb":"figure = plt.figure(figsize=(10,8))\nsns.heatmap(heart.corr(method='spearman'),annot = True,cmap= 'PiYG' )","02edef17":"features = heart.drop('output',axis = 1)\ntarget = heart['output']\n\nfeatures_train,features_valid,target_train,target_valid = train_test_split(features,target,test_size = 0.25, random_state = RANDOM_STATE)","e0fde3ad":"def add_to_model_types_compare(mtc,mod_name,best_params,best_scores,test_score):\n    mtc = mtc.append({'model_name':mod_name,'best_params':best_params,'best_scores':best_scores,'test_score':test_score},ignore_index = True)\n    display(mtc)\n    return mtc\nmodel_types_compare = pd.DataFrame()\n","1b1b9dfa":"def find_best_model(model,params,featuers_train,target_train,features_test,target_test,mtc,mod_name,cat_features, model_lib):\n    grd = GridSearchCV(estimator = model, param_grid = params, \n                               cv = 5, verbose= 5, n_jobs = -1)\n    if model_lib == 'LGBM':\n        grd.fit(features_train, target_train,categorical_feature = 'auto') \n    elif model_lib == 'CB' and len(cat_features)> 0:\n        grd.fit(features_train, target_train,cat_features = cat_features)   \n    else:\n        grd.fit(features_train, target_train)\n    bp = grd.best_params_\n    bs = grd.best_score_\n    est = grd.best_estimator_\n    test_sc = est.score(features_test,target_test)\n    mtc = add_to_model_types_compare(mtc,mod_name,bp,bs,test_sc)\n    return mtc,est","fc2cef0a":"dec_tree = DecisionTreeClassifier()\ndepth_list = [i for i in range(1,100)]\nparams = {'max_depth':depth_list,'class_weight':[None,'balanced'],'criterion':['gini','entropy'],'random_state':[RANDOM_STATE]}\nmodel_types_compare , best_DT= find_best_model( DecisionTreeClassifier(),params,features_train,target_train,features_valid,target_valid,model_types_compare,'DecisionTree',[],'SL')","b2c50e1c":"estim_list = [i for i in range(1,100,5)]\ndepth_list = [i for i in range(1,100)]\nparams = {'n_estimators':estim_list, 'max_depth':depth_list,'class_weight':[None,'balanced','balanced_subsample'],'criterion':['gini','entropy'],'random_state':[RANDOM_STATE]}\nrfc = RandomForestClassifier()\nmodel_types_compare, best_RF = find_best_model(rfc,params,features_train,target_train,features_valid,target_valid,model_types_compare,'RandomForest',[],'SL')","fb2927f8":"estim_list = [i for i in range(1,100,5)]\ndepth_list = [i for i in range(1,100)]\nparams = {'n_estimators':estim_list, 'max_depth':depth_list,'random_state':[RANDOM_STATE]}\ngbc = GradientBoostingClassifier()\nmodel_types_compare, best_GBC = find_best_model(gbc,params,features_train,target_train,features_valid,target_valid,model_types_compare,'GradientBoosting',[],'SL')","c1b78bd8":"params = {'class_weight':[None,'balanced'],'C':[0.1,0.2,0.3,0.5,0.7,1],'fit_intercept:'[True,False],'random_state':[RANDOM_STATE]}\nlr = LogisticRegression()\nmodel_types_compare, best_LR = find_best_mod(lr,params,features_train,target_train,features_valid,target_valid,model_types_compare,'Logistic Regression',[],'SL')","384f7027":"params = {'alpha':[0.0001,0.001,0.005,0.01,0.1,0.5],'class_weight':[None,'balanced'],'random_state':[RANDOM_STATE]}\nsgd = SGDClassifier()\nmodel_types_compare, best_SGD = find_best_mod(sgd,params,features_train,target_train,features_valid,target_valid,model_types_compare,'SGDClassifier',[],'SL') ","d229f888":"params = {'loss_function':['Logloss'],'learning_rate':[0.01,0.05,0.1,0.3,0.5,0.7,0.9], 'depth':[6],'random_seed':[RANDOM_STATE], 'verbose':[500]}\ncbc = CatBoostClassifier()\nmodel_types_compare, best_CBC = find_best_model(cbc,params,features_train,target_train,features_valid,target_valid,model_types_compare,'CatBoostClassifier',cat_features,'CB')","7d3f64c9":"params = {'loss_function':['Logloss'],'learning_rate':[0.01,0.05,0.1,0.3,0.5,0.7,0.9], 'depth':[6],'random_seed':[RANDOM_STATE],'verbose':[500]}\ncbc_wocf = CatBoostClassifier()\nmodel_types_compare, best_CBC_wocf = find_best_model(cbc,params,features_train,target_train,features_valid,target_valid,model_types_compare,'CatBoostClassifier WO CF',[],'CF')","c11c66bf":"params = {'class_weight':[None,'balanced'],'n_estimators':[10,20,50,100,300,500], 'max_depth':[5,10,15,30,50,70,100],'random_state':[RANDOM_STATE]}\nlgbm = LGBMClassifier()\nmodel_types_compare, best_lgbm = find_best_model(lgbm,params,features_train,target_train,features_valid,target_valid,model_types_compare,'LGBMClassifier WO CF',[],'LGBM')","13853e62":"params = {'class_weight':[None,'balanced'],'n_estimators':[10,20,50,100,300,500], 'max_depth':[5,10,15,30,50,70,100],'random_state':[RANDOM_STATE]}\nlgbm = LGBMClassifier()\nfeatures_train[cat_features] = features_train[cat_features].astype('category')\nfeatures_valid[cat_features] = features_valid[cat_features].astype('category')\nmodel_types_compare, best_lgbm = find_best_model(lgbm,params,features_train,target_train,features_valid,target_valid,model_types_compare,'LGBMClassifier',[],'LGBM')","b87115d7":"print('Params of best model:')\nprint(best_CBC.get_params())","eab71f67":"**MODELLING**","f06d5fc9":"**Research analysis**","bd9959b4":"**The best model => CatBoostClassifier**","92ccafcf":"**CORRELATION**"}}