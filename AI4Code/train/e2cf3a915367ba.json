{"cell_type":{"c326b6fe":"code","26c29572":"code","13c6fd81":"code","f9a16306":"code","0d73f604":"code","610480a6":"code","621ae214":"code","2ef1f7c8":"code","296ab5b1":"code","cc9689a6":"code","ef217490":"code","e79010d9":"code","e24e077e":"code","b4666733":"code","a49cbea9":"code","365aebe1":"code","a6505dba":"code","05a07e5c":"code","502d2ad8":"code","5f25185f":"code","9819b206":"code","377585de":"code","e810a699":"code","b49355d8":"code","dcf6a1c8":"code","c528b87b":"code","74c3d54d":"code","67459f11":"code","aa1e3456":"code","7609129c":"markdown","8f548cca":"markdown","a0041e37":"markdown","cdf316f1":"markdown","69137f5f":"markdown","0462bcb0":"markdown","e6b1b4b8":"markdown","899167a4":"markdown"},"source":{"c326b6fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#import zipfile\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","26c29572":"df = pd.read_csv(\"\/kaggle\/input\/qatartrade1518\/EVERPROD.PAN.csv\")\ndfcodes = pd.read_csv(\"\/kaggle\/input\/qatartrade15-18\/HS2code.csv\",delimiter='\\t')\n\ndfcodes.set_index('code', inplace=True)\n\ndf = df.join(dfcodes, on='hs2')\n#df1 = df\ndf = df.drop(['Unnamed: 0', 'hs8','hs6','hs4'], axis=1)\n\ndf = df.astype({\"hs2\": object, \"year\": int })","13c6fd81":"df['time'] = (((df['year']-2015) * 12) + df['month'])\n\ndf.loc[df['time'] < 30, 'emb'] = False\ndf.loc[df['time'] >= 30, 'emb'] = True\n\ndf = df.drop(['year','month'], axis = 1)","f9a16306":"df.sample(5)","0d73f604":"df.shape","610480a6":"df.head(10)","621ae214":"df.info()","2ef1f7c8":"df.describe().round()","296ab5b1":"df.isnull().sum()","cc9689a6":"ccol = ['iso3c','port','continent','region','hs2', 'emb','description','category']\nncol = ['time','weight','import_value']","ef217490":"for c in ccol:\n    print(df[c].value_counts())\n    print(\"-\")","e79010d9":"country_list = df.iso3c.unique()\ntime_list = df.time.unique()","e24e077e":"country_list_sh=['USA','CHN','DEU','JPN','ARE','GBR','IND','ITA','FRA','SAU','CHE','TUR','KOR','ESP','THA','NLD','OMN','AUS','MYS','VNM','EGY']","b4666733":"df1 = pd.DataFrame(df[df.iso3c == 'TLS'].groupby(['time'])['import_value'].sum())\ndf1.rename(columns={'import_value': 'TLS'}, inplace = True)","a49cbea9":"df1.drop(\"TLS\", axis='columns',inplace = True)","365aebe1":"for  c in country_list_sh:\n    df1 = df1.join(pd.DataFrame(df[df.iso3c == c].groupby(['time'])['import_value'].sum()))\n    df1.rename(columns={'import_value': c}, inplace = True)\n","a6505dba":"\ncorr = df1.corr().round(2)\ncorr.style.background_gradient(cmap='PiYG')\n#YlGn RdYlGn\n# 'RdBu_r' & 'BrBG' are other good diverging colormaps","05a07e5c":"import seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.arima_model import ARIMA","502d2ad8":"fig, axs = plt.subplots(21,figsize=(40,250), dpi = 50, sharex=True)\ni=0\nx = df1.index\nplt.style.use('fivethirtyeight')\n\nfor c in country_list_sh:\n    y = df1[c].values\n    axs[i].plot(x, y, label = c)\n    axs[i].tick_params(axis='both', which='major', labelsize=30)\n    axs[i].title.set_text(c)\n    #axs[i].title.set_size(40)\n    axs[i].axvline(x=29)\n    i=i+1","5f25185f":"plt.style.use('fivethirtyeight')\n\nfor c in country_list_sh:\n    autocorrelation_plot(df1[c][:29].values)\n    plt.title(c)\n    plt.show()\n    \n#     axs[i].plot(x, y, label = c)\n#     axs[i].tick_params(axis='both', which='major', labelsize=30)\n#     axs[i].title.set_text(c)\n    #axs[i].title.set_size(40)\n#     axs[i].axvline(x=29)\n#     i=i+1","9819b206":"model = ARIMA(df1['DEU'][:29].values, order=(0,1,1))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())\n","377585de":"model = ARIMA(df1['ITA'][:29].values, order=(0,1,1))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","e810a699":"residuals = pd.DataFrame(model_fit.resid)\nresiduals.plot()\nplt.show()\nresiduals.plot(kind='kde')\nplt.show()\nprint(residuals.describe())","b49355d8":"itaforcast = model_fit.forecast(steps=18)","dcf6a1c8":"forca = itaforcast[0]","c528b87b":"forcastgraph = np.append( [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],forca)","74c3d54d":"forcastgraph","67459f11":"(itaforcast[1])","aa1e3456":"plt.plot(df1[30:].index, df1['DEU'][30:].values)\nplt.plot(df1[30:].index, forcastgraph[30:])\n","7609129c":"Top 21 countries by import value are selected","8f548cca":"## Explore Data","a0041e37":"As all the series are (quite stationary) for the periods 0 - 29 (i.e. pre-embargo), we can apply ARIMA model to predict the expected values for each country that could have been expected if the embargo would have not occured. ","cdf316f1":"## **Load data**\nThe dataset has been converted in CSV (UTF-8) and compressed to zip to ease handling and loading.\nAdditionally an xlsx file with the HS2 classification has been loaded.\n\nThe two files are linked. Additional columns with further details on classifications are dropped.","69137f5f":"It's clear that the embargo imposed by SAU, ARE, EGY has quite clear inverse relationship with OMN (-.73, -.69, -.39), expecially the first two. When import decreases in the first 2, we can see a rise in OMN import. \n\nAlso top inverse relation for SAU are IND-.72, TUR -.79, OMN -.73. Indicating, possibly that whatever was not inported from SAU, probably was substituted by imports from these contruies (further research is needed)\n\nTop inverse for ARE are the same countries (similar values).\n\nTop inverse for EGY are is TUR (-.73) and to lesser extent IND and OMN (-.39)","0462bcb0":"A column with the month number starting from Jan 2015 is created, and the year and month columns are dropped.\nA column indicating the the month of the embargo is added. (1 = during embargo)","e6b1b4b8":"Autoregression does not seem to be significant the model will be be p = 0 hence MA","899167a4":"The dataset contains about about 20M records in 12 columns (7 numerical 5 categorical)\nNo null value recorded.\n\n**OPEN ISSUES**\n\n* calculate through linear reg in months above 30 \n* calculate diffence between expected and actual\n* see substitution\n\n**CLOSED ISSUES**\n* Monhs 1-11 seem to have all the exact same count (i.e. 1787064). Why is that?\n-the series is balanced (thanks Duc)\n* The 3 ports all seem to have the exact same count (i.e. 6999334). Why is that?\n-the series is balanced (thanks Duc)\n* What are HS2, HS4, HS6 and HS8 and what is their relation (HS4 is a sub group of HS2, HS6 is sub groups of HS4 etc). This hierarchy do not seem to be linked to country, weight value or anything else)\n-codes describing the type of item imported\n* 12267 descriptions are null (no match between code and hs2)\n- issue with HS2 77 not existing\n* time values seem not to be correct (max 12, min -35)\n- fixed formula"}}