{"cell_type":{"7f362e34":"code","9c02da23":"code","6d885e5c":"code","b2c9f6d3":"code","2f58e650":"code","e84ed4ae":"code","de6bb6c9":"code","c11611d9":"code","84a70531":"code","dfc6f69f":"code","c40ad675":"code","59fef320":"code","15951391":"code","441a5a0b":"code","c2e98eb2":"code","450b981d":"code","919e8eeb":"code","6658e9e8":"code","4ed20072":"markdown","ed3a731f":"markdown","0993f27d":"markdown","01b486c4":"markdown","333043a3":"markdown","7e76fc5a":"markdown","40de60ce":"markdown","2bf8b6e7":"markdown","8ae3d249":"markdown","e1472ca2":"markdown","b0386e8f":"markdown","632ea084":"markdown","1e4a544b":"markdown"},"source":{"7f362e34":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np","9c02da23":"x = tf.constant([4,2],dtype=tf.int32)  # can not take Tensor Type as input\nm = tf.convert_to_tensor([2,3]) # can take Tensor Type as input\nc = tf.constant(5) # A list with different dtypes or numpy array can be passed too.","6d885e5c":"y = (m*x)+c # try with tf.matmul if you want to perform matric multiplication\ny.numpy()","b2c9f6d3":"tf.concat([m,x],axis=0) # default axis is 0 but you can concat on other axes too","2f58e650":"t = [[1, 2, 3],[4, 5, 6]] # shape [2, 3]\nprint(\"axis=-1:\\n\",tf.expand_dims(t, -1),'\\n') # use last index dimension so axis=-1 works as axis=2\nprint(\"axis=0:\\n\",tf.expand_dims(t, 0),'\\n') # see the difference \nprint(\"axis=1:\\n\",tf.expand_dims(t, 1),'\\n') #  between 0 and 1\nprint(\"axis=2:\\n\",tf.expand_dims(t, 2),'\\n') # same as -1 or last index dimension","e84ed4ae":"cons = tf.constant([1.3,5.8,9]) #not good practice. Here data will be converted to same type internally \n# cons[0] = 5.0 # try it. I could be decieving you","de6bb6c9":"var = tf.Variable([1.3,5.8,9])\nvar[0].assign(3.1)\nvar","c11611d9":"ans = [2,2,2]*((var*cons)\/(var+cons))\n# try doing multiplying by 2 instead of [2,2,2]\n\nprint(type(ans))  # Look closely and see what is happening in the output\nans","84a70531":"weight = tf.Variable(3.2)\n\nlr = 0.01\n\ndef calculate_loss(w):\n    return w**1.3\n\n\nmanual_losses = []\nfor i in range(100):\n    weight = weight.assign(weight - lr*1.3*weight) \n    # this 1.3*weight makes the GD and comes due to the mighty Calculus\n    manual_losses.append(calculate_loss(weight)) # calculate the loss ar epoch i\n\n\nplt.plot(manual_losses)\nplt.show()","dfc6f69f":"def calculate_gradient(w):\n    '''\n    Method will take the weight vector w and calculate the gradients using chaining differential calculus\n    '''\n    with tf.GradientTape() as tape:\n        loss = calculate_loss(w) # calculate loss WITHIN tf.GradientTape() for a single or list of weights\n        \n    grad = tape.gradient(loss,w) # gradient of loss wrt. w the second argument w can be a list too\n    return grad\n\n\n\n# train and apply the things here\nweight = tf.Variable(3.2)\n\nopt = tf.keras.optimizers.SGD(lr=lr)\n\ntf_losses = []\n\nfor i in range(100):\n    grad = calculate_gradient(weight)\n    opt.apply_gradients(zip([grad],[weight]))  # zip makes a list of tuple of (grad_i,weight_i)\n    # map all the gradients to all the layers. There can be many weights and respective gradients\n    \n    tf_losses.append(calculate_loss(weight))\n    \n\nplt.plot(tf_losses)\nplt.show()","c40ad675":"class RegressionModel(tf.keras.Model): # every new model has to use Model\n    '''\n    A Model that performs Linear Regression \n    '''\n    def __init__(self,in_units,out_units):\n        '''\n        args:\n            in_units: number of input neurons\n            out_units: number of output units\n        '''\n        super(RegressionModel,self).__init__() # constructor of Parent class \n        \n        self.in_units = in_units\n        self.out_units = out_units\n        \n        self.w = tf.Variable(tf.initializers.GlorotNormal()((self.in_units,self.out_units))) \n        # make weight which has initial weights according to glorot_normal distribution\n        \n        self.b = tf.Variable(tf.zeros(self.out_units)) # bias is mostly zeros\n        \n        self.params = [self.w,self.b] # we can use the model.params directly inside the GradientTape()\n            \n    \n    def call(self,input_tensor):\n        '''\n        execurte forward pass\n        args:\n            input_tensor: input tensor which will be fed to the network\n        '''\n        return tf.matmul(input_tensor, self.w) + self.b","59fef320":"def generate_random_data(shape=(100,1)):\n    '''\n    Generate correlated X and y points which are correlated according to straight line  y=mx+c\n    args:\n        feat_shape: {tuple} shape of the X data\n    '''\n    X = np.random.random(shape)* np.random.randn() - np.random.randn() # complete randomness\n    m = np.random.random((shape[1],1))\n    c = np.random.randn()\n    y = X.dot(m) +  c + np.random.randn(shape[0],1)*0.13 # add some noise too\n    return X,y\n\n\ndef compute_loss(model,x_features,y_true):\n    '''\n    Calculate the loss. You can use RMSE or MAE \n    args:\n        model:  a model that'll give  predicted values\n        x_features: Array of data points\n        y_true: respective target values\n    '''\n    y_pred = model(x_features)\n    error = y_true  - y_pred\n    return tf.reduce_mean(tf.square(error)) # MSE: Mean Squred Error\n\n\n\ndef compute_grad(model,x_features,y_true):\n    '''\n    Compute the Gradient here\n    '''\n    with tf.GradientTape() as tape:\n        loss = compute_loss(model,x_features,y_true)\n        \n    return tape.gradient(loss,model.params) # you see model.params. It'll include all the params \n","15951391":"X,y = generate_random_data()  # try generating the data different times to see performance of model\n\n\nX = X.astype(np.float32) # default is double or float 64 in numpy\ny = y.astype(np.float32) # tf would have converted it to float32 automatically\n\n\nplt.scatter(X,y)\nplt.show()","441a5a0b":"losses = []\noptimizer = tf.keras.optimizers.SGD(lr=0.01)\nmodel = RegressionModel(1,1) # 1 feature columns and 1 output for regression easy for plotting\nprint(f\"Initial:\\n{model.w}\\n{model.b}\\n\\n\") # model's initial weights and biases\n\nfor epoch in range(500):\n    gradients = compute_grad(model,X,y)\n    optimizer.apply_gradients(zip(gradients,model.params)) # apply back prop to all the \"trainable\" params\n    \n    losses.append(compute_loss(model,X,y)) # make a list of loss per epoch\n\nprint(f\"Final:\\n{model.w}\\n{model.b}\")\n\nplt.plot(losses)\nplt.show()\n    \n    ","c2e98eb2":"reg_x_points = np.linspace(X.min(),X.max(),2) # get 100 equally spaced points between x_min and max\nreg_y_points = model.predict(reg_x_points.reshape(-1,1)).flatten() # get y predictions of those points\n\nplt.plot(reg_x_points,reg_y_points,color='m',label='Regression Line') \n# it'll draw a straight line as all the points are on the same line\n\nplt.scatter(X,y) # original data points\nplt.show()","450b981d":"@tf.function\ndef operation(x, y):\n    return x*y\n\noperation(tf.constant([9, 2]), tf.Variable([3,5]))","919e8eeb":"v = tf.Variable(4.07)\n\nwith tf.GradientTape() as tape:\n    result = operation(v, 2.45)\n    \ntape.gradient(result, v)","6658e9e8":"@tf.function\ndef common_function(inp):\n    print(\"Tracing with\", inp)\n    return inp + inp\n\nprint(common_function(tf.constant(1))) # int as input\nprint('*'*50,'\\n')\n\nprint(common_function(tf.constant(1.1))) # float as input\nprint('-'*50,'\\n')\n\nprint(common_function(tf.constant(\"inp is string\")))","4ed20072":"## GradientTape() and its need\nWhat we did was easy right...Righh Wrongggg!!! What we did was was just **A for Apple** in a world where `OpenGPT-2` is so tuned that it can be used maliciously to copy someone. (You should check that model).\nIf we have to calculate the chaining Gradients for all the layers, it would take months for a new user using the python that is why frameworks are here for the purpose. Now we'll see the working using tensorflow.","ed3a731f":"## Practical use of Variables\nSo what are `Neural Networks` again? Okay, yeah I forgot `a network of layers` and to reming layers have neurons. Have you wondered how tensorflow make this architecture possible? Well for starters, they assign neurons of weights to layers which change over time. Phew!! So complex. (Yeah but a collection of these are indeed complex).\n\nVoila!! You just learned something new. \n\nVariables act as the weights to the layers and the number of neurons are the shape of variable. Git it??\nWhen a `Dense` layer is having `10` neurons then it is transforming a coming input to a shape to an output shape equal to 10 so there is a weight **Variable** which has 10 units in it.\n\nWe will now try to calculate what Keras does under the hood. Train a dummy layer weight with dummy loss.","0993f27d":"# Changes from tf-1 to tf-2\n1. There is `tf.contrib` in 2.0\n2. Early Execution in 2.0 so there is no `tf.session`, `tf.placeholder` and `tf.global_variables_initializers` so there is no need to build the graph first. It would have made the framework a less efficient but then there is `@tf.function` decorator which does the same.\n\nHonestly, I used tensorflow less and Pytorch and Keras the most in place of older version so if you don't know these terms, you're lucky as a beginner I'd say.","01b486c4":"See!!! Everthing is handled by the `GradientTape()`. Try changing the `Optimizer` to know how they affect the results.","333043a3":"**`EagreTensor` represents a tensor who's value has been calculated in *eager* mode whereas `Tensor` represents a *tensor node in a graph* that may not yet have been calculated**","7e76fc5a":"### Manualy calculating Gradients\nWe know that weights ae updated during optimization as: \n`new_weight <- old_weight - learing_rate * (Gradient)`.\nLet us suppose:\n1. Hypothetical loss as `weight**1.3`\n2. lr = 0.01\n","40de60ce":"# Custom Layers and Models\nThere are times when we have to build something unique which is not used as commonly as the regular Neural Networks such as [Restricted Boltzman Machine or RBM](http:\/\/deeplearning.net\/tutorial\/rbm.html) or say a very unique network for the first time for research. What do we do now?? We have to make a custom Layer and define a Custom model here. There is a dedicted notebook on [Custom Models and Layers in tf 2.0](https:\/\/www.kaggle.com\/deshwalmahesh\/keras-tensorflow-2-0-custom-layers-models) so you can learn more about it there. Here, we are trying to take a dive towards the depth of tf 2.0 .\n\nWe'll make a simple Custom model from scratch and learn how to use `GradientTape()`  for the training and so forth.","2bf8b6e7":"## Training of Model using `GradientTape()`","8ae3d249":"## CHOO-CHOO..... OOPS Concept Coming Through\nPolymorphism\n\n**`trace` is useful when debugging, and it always executes during the tracing phase, that is, when the TF graph is constructed**","e1472ca2":"# Thank You\nPlease correct if something is wrong or suggest something new to add.","b0386e8f":"## Constants VS Variables\nConstants are the most accurate  `tuple` version of Tensors in tensorflow as they can store multiple elements. But why not `Lists`? Good question and and the answer is within the question if you know difference between list and tuple. **Tuples are immutable so are constants**, means they can not change the values what are stored inside them while we all use lists so much and know the working. So the list representation of tensorflow is **Variables** and most of the time we work with **variables** as we have to update the tensor values in terms of loss, gradients and so on. **You can perform operations on the mix**. `A human is still a human irrespective of the religion,race etc`- TF Developers\n\n**How to update**: Simply assign a value, is't that logical duh!!. Well not really but you do literally assign as `var.assign(value)`","632ea084":"## Basic Properties and Operations\n1. There are no `int`, `list` or any other data structure but just  **Tensors with data types**. \n2. You **Can NOT** performs operations on the tensors of different data types\n3. You can define the data type while initializing the tensor explicitly using `dtype=tf.data_type` or tensorflow can infer on it's own.\n4. With `tf 2.0`, you can directly see the result of `x+y` like in python while in `tf 1.x`, it was not possible.\n5. Result of any opertion will only be **TENSOR**\n6. Convert any tensor to numpy array using `tensor.numpy()`\n7. Change the data type of any tensor using `tf.cast(tensor)`\n8. Add extra dimension by using `tf.expand_dims()` and remove all shape=1 dimensions by `tf.squeeze()`\n9. Another method for reshaping is `tf.reshape`. It can do both of the operations stated above\n10. Roll or shift the rows or columns using `tf.roll`\n\n<font color='teal'>**Basically, most of the tensorflow basic functions work like numpy functions**<\/font>","1e4a544b":"# Use of `@tf.function`\nIt basically **compiles** a function into a callable TensorFlow graph (just like old times). In other words, it constructs a callable that executes a TensorFlow graph `(tf.Graph)` created by trace-compiling the TensorFlow operations in function, effectively executing function as a TensorFlow graph.\n\n**Properties**:\n1. Method using the decorator can have control flow statements like `if, for, while break, continue, return`.\n2. It can have `tf.Tensor` or `tf.Variable`\n3. To support arguments with different data types or shapes, it can build more than one graph.\n4. 3rd statement basically means **tf.function is polymorphic**\n5. AutoGraph will convert some for and while statements into the equivalent TensorFlow looping ops, like tf.while_loop. If not converted, the for or while loop is executed as a Python loop\n6. Use Tensorflow operations like `tf.Variable.assign`, `tf.print`, and `tf.summary` where ever necessary  in place of `list[n]='aa'` or `print()`. Use these Python's **SIDE EFFECTS**  only for debuggig.\n\n[Read More in Details](https:\/\/www.tensorflow.org\/guide\/function)"}}