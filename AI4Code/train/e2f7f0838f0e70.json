{"cell_type":{"fdecb424":"code","2d2b513d":"code","dc2b678b":"code","50d2b31c":"code","7647bb76":"code","c4489534":"code","399721f5":"code","3e99ea97":"code","628ccbc1":"code","90f21f20":"code","0eff050c":"code","135cbb38":"code","12e9a6ad":"code","14b57903":"code","15053427":"code","5ca25b1e":"code","69bbc957":"code","41a9dd60":"code","f1c388bc":"code","4b44e463":"code","85d198a6":"code","9b9a6d77":"code","24ad5d50":"code","8ca15f88":"code","8bf2aae7":"code","d8f41457":"code","3d408766":"code","4d39fbca":"code","7de6ba28":"code","2d275aa0":"code","32cacb00":"code","0d8d3a39":"code","36877a0c":"code","6cf1a1b4":"code","ce8eb65d":"code","ba04b7a7":"code","0d1252ed":"code","72262450":"markdown","a79861d4":"markdown","405dda28":"markdown","41921107":"markdown","d875f9d0":"markdown","2cb0de5c":"markdown","d1a4821c":"markdown","235dedf2":"markdown","9bb18223":"markdown","b4c73c4f":"markdown"},"source":{"fdecb424":"# Import Libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np","2d2b513d":"# Create HR file DataFrame, Look at Header Info:\ndf_hr = pd.read_csv('\/kaggle\/input\/hr-analytics\/HR_comma_sep.csv')\ndf_hr.head(5)","dc2b678b":"# Look at Features, Types, and N\/A Values if any:\ndf_hr.info()","50d2b31c":"# Time Spent With Company:\nprint(pd.pivot_table(df_hr, index = 'left', columns = 'time_spend_company', values = 'Department' ,aggfunc ='count'))","7647bb76":"# Turnover by Department:\nprint(pd.pivot_table(df_hr, index = 'left', columns = 'Department', values = 'salary' ,aggfunc ='count'))","c4489534":"# Turnover by Salary Level:\nprint(pd.pivot_table(df_hr, index = 'left', columns = 'salary', values = 'Department' ,aggfunc ='count'))","399721f5":"# Turnover by whether or not someone had an accident:\nprint(pd.pivot_table(df_hr, index = 'left', columns = 'Work_accident', values = 'Department' ,aggfunc ='count'))","3e99ea97":"# Turnover by Promotion in the last 5 years:\nprint(pd.pivot_table(df_hr, index = 'left', columns = 'promotion_last_5years', values = 'Department' ,aggfunc ='count'))","628ccbc1":"print(pd.pivot_table(df_hr, index = 'left', values = ['number_project','average_montly_hours','last_evaluation','satisfaction_level']))","90f21f20":"#Create seperate DataFrames for employees who \"left\" and those who \"stayed\"\ndf_left = df_hr[df_hr.left == 1]\ndf_stay = df_hr[df_hr.left == 0]","0eff050c":"df_left.info()","135cbb38":"df_stay.info()","12e9a6ad":"plt.xlabel('Job Satisfaction Value')\nplt.ylabel('Number of Employees')\nplt.title('REPORTED JOB SATISFACTION RANKINGS - EMPLOYEES WHO LEFT')\nplt.hist(df_left.satisfaction_level)","14b57903":"plt.xlabel('Job Satisfaction Value')\nplt.ylabel('Number of Employees')\nplt.title('REPORTED JOB SATISFACTION RANKINGS - EMPLOYEES WHO STAYED')\nplt.hist(df_stay.satisfaction_level,color='red')","15053427":"# Add a Numeric Field for Salary\ndf_hr['salary_num'] = 0","5ca25b1e":"# Assign Numeric Values for Salary Levels\ndf_hr.loc[df_hr['salary'] == 'low', 'salary_num'] = 1\ndf_hr.loc[df_hr['salary'] == 'medium', 'salary_num'] = 2\ndf_hr.loc[df_hr['salary'] == 'high', 'salary_num'] = 3","69bbc957":"df_hr.head(5)","41a9dd60":"# Confirm Turnover by Salary Number is the same as by Salary Level:\nprint(pd.pivot_table(df_hr, index = 'left', columns = 'salary_num', values = 'Department' ,aggfunc ='count'))","f1c388bc":"# Turnover by Salary Level - Same Values:\nprint(pd.pivot_table(df_hr, index = 'left', columns = 'salary', values = 'Department' ,aggfunc ='count'))","4b44e463":"#  Remove Salary Text Field\ndf_hr = df_hr.drop('salary', axis=1)\ndf_hr.head(10)","85d198a6":"df_dum = pd.get_dummies(df_hr.Department)","9b9a6d77":"df_dum","24ad5d50":"df_merged = pd.concat([df_hr,df_dum],axis='columns')","8ca15f88":"df_merged","8bf2aae7":"#Drop original 'Department' text field and one of new Dummies column fields as redundant - 'technical'\ndf_final = df_merged.drop(['Department','technical'],axis='columns')\ndf_final","d8f41457":"df_features = df_final.drop('left', axis=1)","3d408766":"df_features.head(5)","4d39fbca":"df_dependant = df_final.left","7de6ba28":"df_dependant.head(6000)","2d275aa0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_features,df_dependant,test_size=0.25)","32cacb00":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()","0d8d3a39":"model.fit(X_train,y_train)","36877a0c":"model.predict(X_test)","6cf1a1b4":"y_test","ce8eb65d":"model.score(X_test, y_test)","ba04b7a7":"from sklearn.svm import SVC\nsvm = SVC(gamma='auto')\nsvm.fit(X_train, y_train)\nsvm.score(X_test, y_test)","0d1252ed":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=40)\nrf.fit(X_train, y_train)\nrf.score(X_test, y_test)","72262450":"### Continious Variables:","a79861d4":"## Create Pivot Tables to Summarize Turnover (\"left\") Data by Variable:","405dda28":"## Convert Catagorical\/Text Field 'Department' into seperate fields using Get_Dummies Command","41921107":"## Create Seperate DataFrames for Dependant and Independant Variables","d875f9d0":"## Create Training and Testing Datasets - Run and Score ML Models: Logistic, SVC, and Random Forest","2cb0de5c":"### Catagorical Variables:","d1a4821c":"## Convert Text Salary Field to Numeric:  Field is Ordinal, so will convert salary \"levels\" to numeric values.","235dedf2":"### STEPS PERFORMED IN THIS ANALYSIS:\n \n 1.) Read in Data and initial review of fields and data.\n \n 2.) Use Pivot Tables to analyze key turnover variable, \"left\" against other variables in the data.\n\n 3.) Create different DataFrames for employees who stayed and who left for analysis.\n \n 4.) Create Histograms of values to visualize the differences in staying\/leaving in key variables.\n \n 5.) Convert salary text field with \"Low\"\/\"Medium\"\/\"High\" values to numeric for model analysis.\n \n 6.) Convert Catagorical\/Text Field 'Department' into seperate fields using Get_Dummies Command.\n \n 7.) Seperate the data variables from the prediction variable.\n \n 8.) Run train_test_split command to prepare data for training and testing.\n \n 9.) Run Logistic Regression, SVC, and Random Forest models for prediction.\n \n 10.) Evaluate Results - Random Forest is best Model for this data with score of 99.\n\n","9bb18223":"# Conclusion: Random Forest is the Best Model with a 99% Score. ","b4c73c4f":"## Create Histograms to See Value Ranges of Key Fields"}}