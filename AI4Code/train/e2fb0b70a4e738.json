{"cell_type":{"8145456d":"code","72aa0d5f":"code","a06348fc":"code","8e2e2589":"code","aa490075":"code","cd113b5e":"code","9b021f18":"code","dfa65aab":"code","8376354a":"code","00757993":"code","53da5f99":"code","951e1868":"code","d60763e4":"code","ac4d9e22":"code","b79e7c81":"code","ccd4d861":"code","7fe77681":"code","638fe723":"code","3e4a994c":"code","d899c035":"code","dceabfd2":"code","407a8453":"code","ee8e5134":"code","f06b071f":"code","6b16da0a":"code","93386c2a":"code","aa8db164":"code","df118ea0":"code","3c4087db":"code","b6db6412":"code","725f5d26":"code","996e6c41":"code","4dc711eb":"code","7a431df5":"code","4a0fc017":"code","59423e84":"code","b0041832":"code","1b668b6f":"code","5493ca08":"code","f099c903":"code","68deb053":"code","bfc81115":"code","366dd4f5":"code","78254905":"code","e18097ec":"code","faad90e7":"code","c946d457":"code","4b214aaa":"code","da7314c8":"code","6d5bc31d":"code","c88cfb1a":"code","cbf5e254":"code","a9249285":"code","e8a8c6b1":"code","4841e5d6":"code","0083d5b5":"code","c6107130":"code","f7b818fe":"code","19fabe34":"code","ecd4010c":"code","d9ceb51f":"code","e55debb9":"code","f8975ba3":"code","2c6c12ab":"code","0eec22d2":"code","dd4fb190":"code","7c4ea539":"code","4de2d56e":"code","51a816ed":"markdown","9274603c":"markdown","37df20b8":"markdown","04508a68":"markdown","9a1d4dcd":"markdown","bf6f661b":"markdown","1f7b79e4":"markdown","754f7a7d":"markdown","1801f528":"markdown","7918655d":"markdown","73fb814c":"markdown","65229573":"markdown","8c2d93db":"markdown","01bd9c81":"markdown","9eb42624":"markdown","819b34ff":"markdown","903fef71":"markdown","1def4a99":"markdown","8b31ff77":"markdown","6299cf61":"markdown","ecad7064":"markdown","fe6e76fe":"markdown","175f9f80":"markdown","39a5a64f":"markdown","f5339d1d":"markdown","2ccbf2c3":"markdown","b51bfa20":"markdown","2e7a4461":"markdown","befcae5a":"markdown","2890f656":"markdown","9212e1a1":"markdown","661f57d9":"markdown","e61c5284":"markdown","db779fd3":"markdown","a2a95b73":"markdown","c4b82c84":"markdown","f548e576":"markdown","555f3de9":"markdown","20ae6b74":"markdown","89d8775e":"markdown","2359521a":"markdown","d797c649":"markdown","f7ad1c13":"markdown","f908406a":"markdown","26212dba":"markdown","f7768986":"markdown","163c3c58":"markdown","2d7f4076":"markdown"},"source":{"8145456d":"#!pip uninstall statsmodels","72aa0d5f":" #!pip install statsmodels --upgraded","a06348fc":"#!pip install pyramid-arima","8e2e2589":"!pip install pmdarima # libreria con la funci\u00f3n auto_arima()","aa490075":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\nfrom scipy import stats\nfrom matplotlib import pyplot\nfrom pmdarima import auto_arima\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.preprocessing.sequence import TimeseriesGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom fbprophet import Prophet\n\n\n%matplotlib inline\nsns.set()","cd113b5e":"url = 'https:\/\/raw.githubusercontent.com\/sergiomora03\/AdvancedMethodsDataAnalysis\/master\/datasets_56102_107707_monthly-beer-production-in-austr.csv'\ndata = pd.read_csv(url)\ndata.head()","9b021f18":"#Descripci\u00f3n de la base de datos\ndata.info()","dfa65aab":"data.Month = pd.to_datetime(data.Month)\ndata.set_index('Month', inplace=True)\ndata.head()","8376354a":"#Producci\u00f3n en logaritmo\ndata['Log_Production']=np.log(data['Monthly beer production'])","00757993":"#Evoluci\u00f3n de producci\u00f3n de cerveza en Australia durante el periodo de an\u00e1lisis (niveles y logaritmo)\ndata[['Monthly beer production']].plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);\ndata[['Log_Production']].plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);","53da5f99":"res = seasonal_decompose(data['Monthly beer production'], model='additive',freq=12)\n\ndef plotseasonal(res, axes ):\n    res.observed.plot(ax=axes[0], legend=False)\n    axes[0].set_ylabel('Observed')\n    res.trend.plot(ax=axes[1], legend=False)\n    axes[1].set_ylabel('Trend')\n    res.seasonal.plot(ax=axes[2], legend=False)\n    axes[2].set_ylabel('Seasonal')\n    res.resid.plot(ax=axes[3], legend=False)\n    axes[3].set_ylabel('Residual')\n\nfig, axes = plt.subplots(ncols=1, nrows=4, sharex=True, figsize=(20,5))\n\nplotseasonal(res, axes)\n\nplt.tight_layout()\nplt.show()\n","951e1868":"res = seasonal_decompose(data['Log_Production'], model='additive',freq=12)\n\nfig, axes = plt.subplots(ncols=1, nrows=4, sharex=True, figsize=(20,5))\n\nplotseasonal(res, axes)\n\nplt.tight_layout()\nplt.show()","d60763e4":"beer=data['Monthly beer production']\nLog_beer=data['Log_Production']","ac4d9e22":"#Primera diferencia de la serie (niveles)\nbeer.diff().plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=10);","b79e7c81":"#Primera diferencia de la serie (logaritmo)\nLog_beer.diff().plot(figsize=(20,5), linewidth=2, fontsize=10)","ccd4d861":"#Prueba Dickey- Fuller\nresult = adfuller(data['Log_Production'])\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))","7fe77681":"#Prueba Dickey- Fuller - primera diferencia\nresult = adfuller(data['Log_Production'].diff().iloc[1:])\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))","638fe723":"#Autocorrelaci\u00f3n de la serie en an\u00e1lisis\nplt.figure(figsize=(20,5))\npd.plotting.autocorrelation_plot(data['Log_Production']);","3e4a994c":"#Autocorrelaci\u00f3n de la primera diferencia de la serie en an\u00e1lisis\nplt.figure(figsize=(20,5))\npd.plotting.autocorrelation_plot(data['Log_Production'].diff().iloc[1:]);","d899c035":"#Autocorrelaci\u00f3n simple y parcial serie producci\u00f3n cerveza\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nplot_acf(data['Log_Production'], ax=ax[0])\nplot_pacf(data['Log_Production'], ax=ax[1])\nplt.show()","dceabfd2":"#Autocorrelaci\u00f3n simple y parcial primera diferencia de serie producci\u00f3n cerveza\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nplot_acf(data['Log_Production'].diff().iloc[1:], ax=ax[0])\nplot_pacf(data['Log_Production'].diff().iloc[1:], ax=ax[1])\nplt.show()","407a8453":"X = data['Log_Production'].values\nsize = int(len(X) * 0.9)\ntrain, test = X[0:size], X[size:len(X)]\n\n\ndef ARIMA_FUNCTION(p,q):\n\tfor t in range(len(test)):\n\t\tmodel_1 = ARIMA(history, order=(p,1,q))\n\t\tmodel_fit_1 = model_1.fit(disp=0)\n\t\toutput = model_fit_1.forecast()\n\t\tyhat = output[0]\n\t\tpredictions.append(yhat)\n\t\tobs = test[t]\n\t\thistory.append(obs)\n\treturn mean_squared_error(test, predictions)**0.5","ee8e5134":"results=[]\nfor i in range(3):\n    for j in range(4):\n        if (i>j or i==0) and (i-j<3) :\n            predictions = list()\n            history = [x for x in train]\n            results.append([i,j,ARIMA_FUNCTION(i,j)])\n            print((i,j))","f06b071f":"results","6b16da0a":"model = ARIMA(train, order=(0,1,2))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","93386c2a":"residuals = pd.DataFrame(model_fit.resid)\nresiduals.plot(figsize=(20,5))\nplt.show()","aa8db164":"residuals.plot(kind='kde', figsize=(20,5))\nplt.show()\nprint(residuals.describe())","df118ea0":"print(\"KS P-value = \"+str(round(stats.kstest(residuals, 'norm')[1], 10)))","3c4087db":"history = [x for x in train]\npredictions = list()\n\nfor t in range(len(test)):\n    model_1 = ARIMA(history, order=(0,1,2))\n    model_fit_1 = model_1.fit(disp=0)\n    output = model_fit_1.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)\n    print('predicted=%f, expected=%f' % (yhat, obs))","b6db6412":"error_ARIMA = mean_squared_error(test, predictions)**0.5\nprint('Test RMSE: %.3f' % error_ARIMA)","725f5d26":"RollBack=pd.concat([pd.DataFrame({'TEST':test}),pd.DataFrame({'ARIMA':np.concatenate(predictions, axis=0)})],axis=1)\nRollBack.head()","996e6c41":"RollBack.plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);","4dc711eb":"stepwise_model = auto_arima(train, \n                            start_p=0,\n                            start_q=0, \n                            max_p=5, \n                            max_d=2, \n                            max_q=5, \n                            start_P=1,\n                            start_Q=1, \n                            max_P=2, \n                            max_D=2, \n                            max_Q=2, \n                            max_order=10,\n                            m=12,\n                            seasonal=True,\n                            trace=True,\n                            error_action='ignore',  \n                            suppress_warnings=True, \n                            stepwise=True)\nprint(stepwise_model.aic())","7a431df5":"mod = sm.tsa.statespace.sarimax.SARIMAX(train, trend='n', order=(1,1,1), seasonal_order=(2,0,2,12))\nresults = mod.fit()\nresults.summary()","4a0fc017":"#results.resid\nresiduals1 = pd.DataFrame(results.resid[1:])\nresiduals1.plot(figsize=(20,5))\nplt.show()","59423e84":"residuals1.plot(kind='kde', figsize=(20,5))\nplt.show()\nprint(residuals1.describe())","b0041832":"print(\"KS P-value = \"+str(round(stats.kstest(residuals1, 'norm')[1], 10)))\nprint(\"D\u2019Agostino and Pearson\u2019s P-value = \"+str(round(stats.normaltest(residuals1, axis=0)[1][0], 6)))","1b668b6f":"X = data['Log_Production'].values\nsize = int(len(X) * 0.9)\ntrain, test = X[0:size], X[size:len(X)]\nhistory = [x for x in train]\npredictions = list()\nfor t in range(len(test)):\n\tmodel = sm.tsa.statespace.sarimax.SARIMAX(history, trend='n', order=(1,1,1), seasonal_order=(2,0,2,12))\n\tmodel_fit = model.fit(disp=0)\n\toutput = model_fit.forecast()\n\tyhat = output[0]\n\tpredictions.append(yhat)\n\tobs = test[t]\n\thistory.append(obs)\n","5493ca08":"error_SARIMA = mean_squared_error(test, predictions)**0.5\nprint('Test RMSE: %.3f' % error_SARIMA)","f099c903":"RollBack=pd.concat([RollBack,pd.DataFrame({'SARIMA':predictions})],axis=1)\nRollBack.head()","68deb053":"RollBack.plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);","bfc81115":"data_pf = pd.DataFrame({'ds': data.Log_Production.index[:], 'y': data.Log_Production})\ndata_pf.head()","366dd4f5":"X = data_pf.y\nY = data_pf.ds\nsize = int(len(X) * 0.9)\ntrain_X, test_X = X[0:size], X[size:len(X)]\ntrain_Y, test_Y = Y[0:size], Y[size:len(Y)]\n    \nTrain = pd.concat([train_Y,train_X], axis=1)\nTest = pd.concat([test_Y,test_X], axis=1)","78254905":"predictions = list()\n    \ndef rolling_forecast():   \n    history = Train.copy()\n    \n    for t in range(len(test_X)):\n        m = Prophet()\n        m.fit(history);\n        future = m.make_future_dataframe(periods=1, freq='MS')\n        forecast = m.predict(future)\n        output=forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n        yhat = output[['yhat']][len(history):].values[0][0]\n        predictions.append(yhat)\n        obs = pd.DataFrame(Test[['ds','y']].iloc[t])\n        history = pd.concat([history, obs.transpose()],axis=0)\n        print('predicted=%f, expected=%f' % (yhat, obs.transpose()['y']))\n\n    \n    error_PROPHET = mean_squared_error(test_X, predictions)**0.5\n    print('Test RMSE: %.3f' % error_PROPHET)","e18097ec":"rolling_forecast()","faad90e7":"error_PROPHET = mean_squared_error(test_X, predictions) **0.5\nprint('Test RMSE: %.3f' % error_PROPHET)","c946d457":"RollBack=pd.concat([RollBack,pd.DataFrame({'Prophet':predictions})],axis=1)\nRollBack.head()","4b214aaa":"RollBack[['TEST', 'Prophet']].plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);","da7314c8":"RollBack.plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);","6d5bc31d":"data_LSTM = pd.DataFrame({'Log_Production': data.Log_Production})\ndata_LSTM.head()","c88cfb1a":"Y = data_LSTM\nsize = int(len(Y) * 0.9)\n\ntrain_Y, test_Y = Y[0:size], Y[size:len(Y)]","cbf5e254":"scaler = MinMaxScaler()\nscaler.fit(train_Y)\nscaled_train_data = scaler.transform(train_Y)\nscaled_test_data = scaler.transform(test_Y)","a9249285":"n_input = 12\nn_features= 1\ngenerator = TimeseriesGenerator(scaled_train_data, scaled_train_data, length=n_input, batch_size=1)","e8a8c6b1":"lstm_model = Sequential()\nlstm_model.add(LSTM(200, input_shape=(n_input, n_features)))\n#lstm_model.add(LSTM(units=50, return_sequences = True))\nlstm_model.add(Dense(1))\nlstm_model.compile(optimizer='adam', loss='mean_squared_error')\n\nlstm_model.summary()","4841e5d6":"lstm_model.fit_generator(generator,epochs=20)","0083d5b5":"losses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize=(20,5))\nplt.xticks(np.arange(0,21,1))\nplt.plot(range(len(losses_lstm)),losses_lstm);","c6107130":"lstm_predictions_scaled = list()\n\nbatch = scaled_train_data[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test)):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaled.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)","f7b818fe":"lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)","19fabe34":"error_LSTM = mean_squared_error(test, lstm_predictions) ** 0.5\nprint('Test RMSE: %.3f' % error_LSTM)","ecd4010c":"RollBack = pd.concat([RollBack,pd.DataFrame({'LSTM':np.concatenate(lstm_predictions, axis=0)})],axis=1)\nRollBack.head()","d9ceb51f":"RollBack[['TEST', 'LSTM']].plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);","e55debb9":"RollBack.plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);","f8975ba3":"RollBack = pd.concat([RollBack,pd.DataFrame({'Time':data.Log_Production.index[size:]})],axis=1)\nRollBack.head()","2c6c12ab":"RollBack.set_index('Time', inplace=True)\nRollBack.head()","0eec22d2":"RollBack.plot(figsize=(20,5), linewidth=2, fontsize=10)\nplt.xlabel('time', fontsize=15);","dd4fb190":"Error = pd.DataFrame({\"Models\":[\"ARIMA\", \"SARIMA\", \"Prophet\", \"LSTM\"],\n                      \"RMSE Log\" : [error_ARIMA, error_SARIMA, error_PROPHET, error_LSTM]})\nError","7c4ea539":"print('Test RMSE ARIMA: %.3f' % mean_squared_error(np.exp(RollBack.TEST), np.exp(RollBack.ARIMA)))\nprint('Test RMSE SARIMA: %.3f' % mean_squared_error(np.exp(RollBack.TEST), np.exp(RollBack.SARIMA)))\nprint('Test RMSE Prophet: %.3f' % mean_squared_error(np.exp(RollBack.TEST), np.exp(RollBack.Prophet)))\nprint('Test RMSE LSTM: %.3f' % mean_squared_error(np.exp(RollBack.TEST), np.exp(RollBack.LSTM)))","4de2d56e":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nnp.exp(RollBack[['SARIMA','TEST']]).plot(figsize=(20,5), linewidth=2, fontsize=10, ax = ax[0])\nnp.exp(RollBack[['Prophet','TEST']]).plot(figsize=(20,5), linewidth=2, fontsize=10, ax = ax[1])\nplt.xlabel('time', fontsize=15);\n#plt.show()","51a816ed":"Como se comprob\u00f3 en el test de ra\u00edz unitaria, esta ca\u00edda lenta en la funci\u00f3n de autocorrelaci\u00f3n simple, da indicios que la serie es no estacionaria.","9274603c":"# 3. Entendiendo los datos","37df20b8":"De acuerdo a los gr\u00e1ficos de los residuales podemos observar que el proceso tiene media constante, centrada alrededor de cero y varianza constante. Tambien, graficamente parece ajustarse a una distribuci\u00f3n Normal, sin embargo validamos esto con una prueba de normalidad ","04508a68":"## 4.4. LSTM Forecast","9a1d4dcd":"### 3.1 instalando librerias","bf6f661b":"Seg\u00fan los resultados del test de Kolmogorov Smirnoff con un nivel de significancia del 5% no podemos concluir que los residuales se ajustan a una distribuci\u00f3n normal.","1f7b79e4":"**Antecedentes:**\n\nEl sector Cervecero en Australia hace parte de la actividad econ\u00f3mica del Comercio, el cual aporta aproximadamente un 7% de la actividad econ\u00f3mica del pa\u00eds. Dentro del comercio, el Retail lidera el sector con un aporte del 52% donde se ubica el sector Cervecero. \n\nLa Industria Cevecera Australiana inicialmente fue dominada por los productores nacionales tradicionales Carlton & United Breweries (CUB) y Le\u00f3n  principalmente. A finales de la d\u00e9cada de los 70, empezaron una serie de fusiones de estas empresas regionales con trasnacionales, transformando el mercado a una gran participaci\u00f3n extranjera. Actualmente, el mercado lo dominan principalmente: La Cervera CUB que en 2011 se fusion\u00f3 con la multinacional Sabmiller y hoy en d\u00eda es 100% propiedad de AB InBev y,  por otra parte, la cervecera Le\u00f3n en 2009 pas\u00f3 a propiedad de la Cervecera Japonesa  Kirin Holdings Company Limited. Estas dos competidores hacen aproximadamente el 89% del mercado. El resto del mercado lo ocupa en mayor medida la Cervecera Nacional Coopers con un 4% de participaci\u00f3n.  \n\n**Relevancia e Accionabilidad:** \n\nEl an\u00e1lisis del mercado de Cervezas y espec\u00edficamente el de la producci\u00f3n es de vital importancia para las industrias cerveceras del Pa\u00eds. Es necesario hacer el tracking mensual del mercado y as\u00ed mismo prever la producci\u00f3n de Cerveza que cubra toda la demanda del mercado. El an\u00e1lisis de esta serie de tiempo de  la producci\u00f3n de Cerveza, le permite a los grandes fabricantes planear, organizar todo el proceso productivo de la manera m\u00e1s \u00f3ptima posible,  por medio de un anticipo o pron\u00f3stico del comportamiento del mercado. Como veremos m\u00e1s adelante en esta serie existen principalmente dos grandes picos de estacionalidad, marcados en primera medida por la temporada navide\u00f1a y verano (Dic-Ene) y en segunda medida por las vacaciones de mitad de a\u00f1o(Jun-Jul), en donde se observa un incremento muy marcado en la demanda y consumo de Cerveza y por lo tanto tambien en la producci\u00f3n. Por otra parte, les ayuda a entender a los fabricantes cual es el mejor momento o la fecha ideal para realizar lanzamientos de marcas\/submarcas en el mercado o para realizar alguna campa\u00f1a espec\u00edfica en alg\u00fan sector, de acuerdo a las capacidades de producci\u00f3n que tengan previstas.\n\n**Escalabilidad del Modelo:** \n\nActualmente, el mercado al ser dominado principalmente por inversi\u00f3n extranjera, a las multinacionales no les interesa \u00fanicamente hacer tracking sobre la producci\u00f3n de Australia, sino tambi\u00e9n aplicar estos modelos en los dem\u00e1s pa\u00edses  donde tienen participaci\u00f3n. La ventaja del sector cervecero es que en muchos pa\u00edses el comportamiento estacional de Diciembre y Junio se mantiene tanto en ventas como en producci\u00f3n, lo que hace que estos modelos y an\u00e1lisis de mercado tengan una f\u00e1cil escalabilidad en datos de la industria de otros pa\u00edses, adem\u00e1s que los modelos y algoritmos aqu\u00ed utilizados permiten una facil adaptaci\u00f3n.\n\n\n\n","754f7a7d":"#### 4.1.1 Selecci\u00f3n proceso ARIMA a estimar","1801f528":"## 4.1. Modelo ARIMA","7918655d":"Los resultados de la prueba de Dickey- Fuller confirman que, con un nivel de significancia del 5%, la serie de producci\u00f3n de cerveza diferenciada si es estacionaria.","73fb814c":"# Time Series Analysis - ARIMA, SARIMA, Prophet, LSTM.\n\nAuthor: *Sergio Alberto Mora Pardo*\n\n* email: [sergiomora823@gmail.com](mailto:sergiomora823@gmail.com)\n* LinkedIn: [\/sergiomorapado](https:\/\/www.linkedin.com\/in\/sergiomorapardo\/)\n* GitHub: [sergiomora03](https:\/\/github.com\/sergiomora03)\n\nEn el siguiente notebook se analiza la serie de tiempo de producci\u00f3n de cerveza de Australia. Se aplican los modelos ARIMA, SARIMA. Tambi\u00e9n, se prueba el ajuste con Prophet y finalmente, se crea una Red Neuronal Recurrente.","65229573":"De acuerdo a lo observado en la data original es necesario transformar la variable **Month** a formato fecha","8c2d93db":"Seg\u00fan los resultados del test de Kolmogorov Smirnoff con un nivel de significancia del 5% no podemos concluir que los residuales se ajustan a una distribuci\u00f3n normal.","01bd9c81":"#### 4.1.4. Rolling Forecast","9eb42624":"Una vez evaluadas las posibles combinaciones para el proceso SARIMA, el modelo con el mejor performance es el que tiene menor AIC, en este caso es el ARIMA(1,1,1)x(2,0,2,12) con un AIC=-1014.517","819b34ff":"# 5. Conclusiones","903fef71":"#### 4.2.4. Rolling Forecast","1def4a99":"#### 4.2.1. Selecci\u00f3n proceso SARIMA a estimar","8b31ff77":"### 3.5. An\u00e1lisis de estacionariedad","6299cf61":"## 4.2. Modelo SARIMA","ecad7064":"Evaluando el modelo con los par\u00e1metros \u00f3ptimos, se observa que todos los coeficientes del modelo son significativos a excepci\u00f3n de los primeros coeficientes de AR y MA de la parte estacional, sin embargo los mantenemos en el modelo ya que los segundos coeficientes de AR y MA del componente estacional si son significativos.","fe6e76fe":"Para el proceso del Rolling Forecast con Prophet separamos la base en train (90% de obs) para estimar el modelo y en test (10%) para calcular el error de la predicci\u00f3n. Dicho esto, escogemos el modelo con menor RMSE el cual es el que predice mejor, en este caso con un RMSE=0.078","175f9f80":"#### 4.1.2 Estimaci\u00f3n modelo","39a5a64f":"\n1. Choosing your time series (https:\/\/www.kaggle.com\/shenba\/time-series-datasets).\n\n2. Analysis of the context of the problem and relevance of the analysis: This should answer the question of why it is interesting or important to study the selected data.\n\n3. Understanding the data: Understand and analyze the main components of the time series, for example: seasonality, cyclicity, autocorrelation, behavior of the residuals, among others. Make use of graphs that allow you to understand each of the components clearly.\n\n4. Application of the model in predictions: Correct use of the models seen in class to make predictions related to the problem of interest.\n\n5. Conclusions: The conclusions must be relevant to the problem of interest. Conclusions on the procedures performed are also expected.","f5339d1d":"### 3.4. Transformaci\u00f3n y descompocisi\u00f3n","2ccbf2c3":"# 2. An\u00e1lisis y relevancia de la serie\n","b51bfa20":"De acuerdo a los RMSE obtenidos para cada modelo evaluado en los procesos ARIMA, el mejor modelo es el ARIMA (0,1,2) con un RMSE correspondiente a 0.12223215571124342","2e7a4461":"# 1. Serie seleccionada","befcae5a":"### 3.2 Importando Librerias","2890f656":"Seg\u00fan el an\u00e1lisis de la serie existe un fuerte componente estacional en la producci\u00f3n de cerveza que, como se observ\u00f3 anteriormente, no est\u00e1 siendo capturado por el proceso ARIMA seleccionado. Por consiguiente, se procede a estimar un modelo SARIMA, que es un modelo ARIMA que incluye el componente estacional de las series.","9212e1a1":"#### 4.3.1. Estimaci\u00f3n modelo","661f57d9":"## 4.3. Prophet Forecast","e61c5284":"Escenarios para evaluar los procesos *ARIMA*, en estos casos en todos los modelos utilizamos 1 Diferenciaci\u00f3n, el primer par\u00e1metro representa el proceso AR, el segundo corresponde al MA","db779fd3":"El mejor modelo SARIMA de los testeados presenta un RMSE sobre los datos de test de 0.062.","a2a95b73":"#### 4.2.3. An\u00e1lisis de residuales","c4b82c84":"A partir de los gr\u00e1ficos de la producci\u00f3n de cerveza (tanto en niveles como en logaritmo), se puede observar lo siguiente en relaci\u00f3n con el comportamiento de la serie y sus componentes:\n\n1) Hasta el a\u00f1o 1974 se registra un crecimiento importante de la producci\u00f3n de cerveza en el pa\u00eds, mostrando un tendencia positiva durante estos primeros a\u00f1os de an\u00e1lisis, para luego estabilizarse y tener una ligera disminuci\u00f3n a principios de la decada de los 80\u00b4s (tendencia negativa). La presencia de diferentes tendencias en el tiempo, indican inicialmente que la serie no es estacionaria.\n\n2) La serie tiene un marcado componente estacional, que consiste en un aumento de la producci\u00f3n de cerveza cada 12 meses, especificamente a finales del a\u00f1o (noviembre - diciembre) para luego disminuir a partir del mes de enero del siguiente a\u00f1o. Esta din\u00e1mica es consistente con la temporada de verano de Australia.\n\n3) El cambio en la amplitud del cada ciclo y la presencia de un componente aleatorio en el periodo de an\u00e1lisis, indican que la producci\u00f3n de cerveza ha recibido diferentes choques (oferta o demanda) que ha cambiado su din\u00e1mica en el tiempo y, adem\u00e1s, puede indicar problemas de heterocedasticidad en la serie.","f548e576":"### 3.3 Importando datos","555f3de9":"#### 4.2.2. Estimaci\u00f3n modelo","20ae6b74":"#### 4.1.5. Comparaci\u00f3n preliminar estimaciones\n\n","89d8775e":"Al comparar los RMSE obtenidos en las diferentes estimaciones, se obtiene que el Modelo SARIMA arroja el menor RSME (84.416), seguido del Modelo Prophet (RSME = 133.123). Por otra parte, cuando se grafican la series estimadas versus la observada, se encuentra que la serie resultado de los modelos Prophet y SARIMA son los de mejo ajuste a la serie de an\u00e1lisis. Sin embargo, los residuales del modelo SARIMA no se distribuyen normal. Por lo cual recomendamos el uso del modelo Prophet que no requiere de este supuesto para la realizaci\u00f3n de pron\u00f3sticos de la producci\u00f3n de cerveza.\n\nEn t\u00e9rminos de negocio, debido a la misma naturaleza del mercado de Cervezas, es importante  tener una buena predicci\u00f3n especialmente para los periodos estacionales, ya que son los de mayor foco para lanzamientos de nuevas marcas o campa\u00f1as espec\u00edficas. Dicho esto, el modelo SARIMA funciona mejor pero tendr\u00edamos que hacer alguna transformaci\u00f3n o correcci\u00f3n en los datos train para garantizar la normalidad en los residuales, debido a esto se recomienda utilizar el modelo Prophet.\n\nEn t\u00e9rminos de Escalabilidad tanto el modelo Prophet como el SARIMA funcionan muy bien, ya que el algoritmo en su proceso iterativo eval\u00faa m\u00faltiples modelos, eligiendo el de mejor performance. Podr\u00eda ser muy interesante para los Fabricantes aplicar estos modelos en Datos de m\u00e1s pa\u00edses donde tienen participaci\u00f3n, ya que en general la naturaleza de los datos se mantiene en los diferentes pa\u00edses.\n\nEn cuanto al procesamiento, consume menos hardware procesar el prophet que el modelo SARIMA, as\u00ed mismo, al medir sus tiempos de ejecuci\u00f3n el modelo SARIMA consume m\u00e1s tiempo de ejecuci\u00f3n que el Prophet","2359521a":"Despu\u00e9s de ejecutar el procedimiento de Rolling Forecast con el test el RMSE obtenido es de 0.122 con el ARIMA(0,1,2).","d797c649":"Los resultados de la prueba de Dickey- Fuller confirman que, con un nivel de significancia del 5%, la serie de producci\u00f3n de cerveza no es estacionaria.","f7ad1c13":"Una vez se diferencian las series se observa que la tendencia desaparece. Adicionalmente, con la transformaci\u00f3n de logaritmo parece mejorar el problema de varianza no constante. Por consiguiente, el ejercicio de an\u00e1lisis y estimaci\u00f3n se realizar\u00e1 con **la serie en logaritmo**.\n\nNo obstante, a continuaci\u00f3n, se procede a realizar la prueba de Dickey- Fuller para realizar una verificaci\u00f3n formal de la estacionariedad de la serie.","f908406a":"En la presente secci\u00f3n se procede a la estimaci\u00f3n de diferentes modelos de predicci\u00f3n: ARIMA, SARIMA, Prophet y una red reuronal recurente con una celda LSTM.","26212dba":"#### 4.1.3. An\u00e1lisis de residuales","f7768986":"Los anteriores gr\u00e1ficos permiten observar la evoluci\u00f3n de la producci\u00f3n de cerveza en Australia para el periodo de an\u00e1lisis.","163c3c58":"La serie seleccionada para la realizaci\u00f3n del presente proyecto corresponde a la producci\u00f3n mensual de cerveza en Australia en unidades de volumen para el periodo: enero de 1956 - agosto de 1995 (un total de 476 observaciones).","2d7f4076":"# 4. Aplicaci\u00f3n de modelos de predicci\u00f3n"}}