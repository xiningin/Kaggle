{"cell_type":{"6ce4ddcc":"code","e36eb692":"code","51f356d8":"code","3be0854a":"code","9fc64e1d":"code","b70da773":"code","1566cfd1":"code","5ce6a073":"code","dafeaeb2":"code","6fe6d66b":"code","9256dfdf":"code","701b709c":"code","ad2ef21c":"code","549e0625":"code","a3289738":"code","e0c4115d":"code","2cd15ae8":"code","020781a7":"code","7a264217":"code","0d5cc427":"code","32acd706":"code","d67b990b":"code","8a62d532":"code","2401688d":"code","38b20c29":"code","d65b688d":"code","c48a2720":"code","b9354a2a":"code","f4b967cb":"code","f584d38d":"code","bd070f71":"code","ce747c01":"code","30fa60b6":"code","068fe8f6":"markdown","840df2dc":"markdown","0228f661":"markdown","b75aa028":"markdown","86f540c0":"markdown","be69d877":"markdown","ecb90141":"markdown","e2eb9e41":"markdown","fb4f2d6d":"markdown","0ecb8d54":"markdown","391d63a2":"markdown"},"source":{"6ce4ddcc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e36eb692":"titanic_df = pd.read_csv(\"..\/input\/train.csv\")\ntitanic_df = titanic_df.drop([\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n# Remove Row which are having NAN values\ntitanic_df.dropna(axis = 1, how ='all', inplace = True)\n# To check which coulumn has NAN \ntitanic_df.isnull().any()\n#Replaced Nan values in Age column with it's Mean\ntitanic_df.ix[:,4]=(titanic_df.ix[:,4]).fillna(titanic_df.mean(axis=0)[3])","51f356d8":"def binarize(df):\n    for col in ['Sex']:\n        df[col] = df[col].map({'female':1, 'male':0})\n    return df\ndef binarize_Embark(df):\n    for col in ['Embarked']:\n        df[col] = df[col].map({'S':0, 'C':1,'Q':2})\n    return df\ndef label_Survived(df):\n    for col in ['Survived']:\n        df[col] = df[col].map({0:'NotSurvived', 1:'Survived'})\n    return df\ntitanic_df = binarize(titanic_df)\ntitanic_df = binarize_Embark(titanic_df)\ntitanic_df = label_Survived(titanic_df)","3be0854a":"x = titanic_df.ix[:,2:8].values\ny = titanic_df.ix[:,1].values","9fc64e1d":"# we are using function StandardScaler() function for standarizing the Matrix.\nfrom sklearn.preprocessing import StandardScaler\nstd = StandardScaler()\nstd","b70da773":"std.fit(x)","1566cfd1":"X_std = std.transform(x)","5ce6a073":"# Below is standard mean & variance featurewise\nstd.mean_, std.var_","dafeaeb2":"# we can directly use below funtion call in order to get our Matrix standarize\n#X_std = StandardScaler().fit_transform(x)\n#X_std","6fe6d66b":"mean_vec = np.mean(X_std, axis=0)\n#mean_vec = mean_vec[~pd.isnull(mean_vec)]\n#mean_vec\ncov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) \/ (X_std.shape[0]-1)\nprint('Covariance matrix \\n%s' %cov_mat)","9256dfdf":"#We can get Covarience matrix by direclty using below Method instead of doing like blove result will be same\nprint('NumPy covariance matrix: \\n%s' %np.cov(X_std.T))","701b709c":"cov_mat = np.cov(X_std.T)\ncov_mat\n\neig_vals, eig_vecs = np.linalg.eig(cov_mat)\nnp.linalg.eig\nprint('Eigenvectors \\n%s' %eig_vecs)\nprint('\\nEigenvalues \\n%s' %eig_vals)","ad2ef21c":"u,s,v = np.linalg.svd(X_std.T)\nu","549e0625":"s","a3289738":"v","e0c4115d":"for ev in eig_vecs:\n    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\nprint('Everything ok!')","2cd15ae8":"import plotly.plotly as py\nfrom plotly.graph_objs import *\nimport plotly.tools as tls\n\nfrom plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n%matplotlib inline\ninit_notebook_mode(connected=True)","020781a7":"# Make a list of (eigenvalue, eigenvector) tuples\neig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n#eig_pairs[1][1]\n# Sort the (eigenvalue, eigenvector) tuples from high to low\neig_pairs.sort()\neig_pairs.reverse()\n\n# Visually confirm that the list is correctly sorted by decreasing eigenvalues\nprint('Eigenvalues in descending order:')\nfor i in eig_pairs:\n    print(i[0])","7a264217":"tot = sum(eig_vals)\nvar_exp = [(i \/ tot)*100 for i in sorted(eig_vals, reverse=True)]\ncum_var_exp = np.cumsum(var_exp)\n\ntrace1 = Bar(\n        x=['PC %s' %i for i in range(1,7)],\n        y=var_exp,\n        showlegend=False)\n\ntrace2 = Scatter(\n        x=['PC %s' %i for i in range(1,7)], \n        y=cum_var_exp,\n        name='cumulative explained variance')\n\ndata = Data([trace1,trace2])\n\nlayout=Layout(\n        yaxis=YAxis(title='Explained variance in percent'),\n        title='Explained variance by different principal components')\n\nfig = Figure(data=data, layout=layout)\niplot(fig)","0d5cc427":"matrix_w = np.hstack((eig_pairs[0][1].reshape(6,1), \n                      eig_pairs[1][1].reshape(6,1)))\nprint('Matrix W:\\n', matrix_w)","32acd706":"Y = X_std.dot(matrix_w)","d67b990b":"Y.shape","8a62d532":"X_std.shape","2401688d":"traces = []\n\nfor name in ('NotSurvived','Survived'):\n\n    trace = Scatter(\n        x=Y[y==name,0],\n        y=Y[y==name,1],\n        mode='markers',\n        name=name,\n        marker=Marker(\n            size=10,\n            line=Line(\n                color='rgba(217, 217, 217, 0.14)',\n                width=0.5),\n            opacity=0.8))\n    traces.append(trace)\n\n\ndata = Data(traces)\nlayout = Layout(showlegend=True,\n                scene=Scene(xaxis=XAxis(title='PC1'),\n                yaxis=YAxis(title='PC2'),))\n\nfig = Figure(data=data, layout=layout)\niplot(fig)","38b20c29":"from sklearn.decomposition import PCA as sklearnPCA\nsklearn_pca = sklearnPCA(n_components=3)\nY_sklearn = sklearn_pca.fit_transform(X_std)","d65b688d":"sklearn_pca.explained_variance_ratio_","c48a2720":"Y_sklearn.shape","b9354a2a":"sklearn_pca.transform()","f4b967cb":"traces = []\n\nfor name in ('NotSurvived','Survived'):\n\n    trace = Scatter(\n        x=Y_sklearn[y==name,0],\n        y=Y_sklearn[y==name,1],\n        mode='markers',\n        name=name,\n        marker=Marker(\n            size=10,\n            line=Line(\n                color='rgba(217, 217, 217, 0.14)',\n                width=0.5),\n            opacity=0.8))\n    traces.append(trace)\n\n\ndata = Data(traces)\nlayout = Layout(showlegend=True,\n                scene=Scene(xaxis=XAxis(title='PC1'),\n                yaxis=YAxis(title='PC2'),))\n\nfig = Figure(data=data, layout=layout)\niplot(fig)","f584d38d":"%matplotlib inline\n\nfrom sklearn import datasets, cluster\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D","bd070f71":"np.random.seed(2)\nk_means = cluster.KMeans(n_clusters=2)\nk_means.fit(Y) \nlabels = k_means.labels_\nv\n# check how many of the samples were correctly labeled\ncorrect_labels = sum(y_var == labels)\n\nprint(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, y_var.size))","ce747c01":"# plot the clusters in color\nfig = plt.figure(1, figsize=(8, 8))\nplt.clf()\nax = Axes3D(fig, rect=[0, 0, 1, 1], elev=8, azim=200)\nplt.cla()\n\nax.scatter(Y[:, 0], Y[:, 1], c=labels.astype(np.float))\n\nax.w_xaxis.set_ticklabels([])\nax.w_yaxis.set_ticklabels([])\nax.set_xlabel('NotSurvived')\nax.set_ylabel('Survived')\n\n\nplt.show()\n","30fa60b6":"\ntraces = []\n\nfor tempvar in ('NotSurvived','Survived'):\n    trace = Scatter(\n        x=Y[y==tempvar,0],\n        y=Y[y==tempvar,1],\n        mode='markers',\n        name=name,\n        marker=Marker(\n            size=10,\n            line=Line(\n                color='rgba(217, 217, 217, 0.14)',\n                width=0.5),\n            opacity=0.8))\n    traces.append(trace)\ndata = Data(traces)\nlayout = Layout(showlegend=True,\n                scene=Scene(xaxis=XAxis(title='AxisX'),\n                yaxis=YAxis(title='AxisY'),))\n\nfig = Figure(data=data, layout=layout)\niplot(fig)","068fe8f6":"Creating two seprate variables x for features which contains all features which will undergo Matrix PCA methodlogy \nAnd y is the target variable wherein 0 for not survived and 1 for survived","840df2dc":"Below we have tried to plot in 2-D graph as well.","0228f661":"**Final Outcome Explanation by Graph**\nWith W Matrix now have tried to plot the graph on 2 Dimentional graph, wherein Not Survived And Survived people have mention.\nwe can not see clear segregation of survived & not survival here while applying PCA however it good for learning purpose.","b75aa028":"**PCA applied on Titanic Dataset using scikit learn Library**\nWith the help of scikit learn library we can direcly apply PCA by using sklearnPCA method\nall above steps we can avoid however it is good to know what it does in beckend.","86f540c0":"**K Mean clustering Algorithm**","be69d877":"**Calculate Eigen Vector & Eigen Values**","ecb90141":"**Graphical Representation**\nAbove Graph built by Numpy to give Graphical view on which features explain most variation in the dataset. As you can see PC1 & PC2 are both together Explain aroung 57% Variations.\n","e2eb9e41":"Categorical Features Sex , Embarked and Survived has been replaced by the numeric values by using map.","fb4f2d6d":"Now Prepare a W Matrix which Contains most relevant\/variation explanation feature column","0ecb8d54":"**Introduction**\nPCA Dimention reduction methodology, we are applying PCA on Titanic Dataset.\n\n","391d63a2":"**Steps Performed on Train data**\n1. Reading the Titanic Dataset from csv files.\n2. Removing Unwanted Colums from train Dataset.\n3. Droping Nan colums & replacing the same with mean of  respective column.\n"}}