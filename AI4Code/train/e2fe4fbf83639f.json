{"cell_type":{"99c28c8e":"code","fbc7cd6b":"code","8554d7ee":"code","238dddb3":"code","a1c28bf3":"code","36c10e07":"code","e8a8479f":"code","2702e3f2":"code","4a56695f":"code","db8e718b":"code","66c860b8":"code","b74fca57":"code","f3b1f7a6":"code","bc21d6ab":"code","349b7657":"code","c3c8b0fe":"markdown","1c4d0c12":"markdown","f44c2642":"markdown","4d30fa9e":"markdown","ac3acabc":"markdown","c20995ab":"markdown","8fd8a0ea":"markdown"},"source":{"99c28c8e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans","fbc7cd6b":"N = 100\nrandom_x0 = 1 + np.random.randn(N)\nrandom_x1 = 5 + np.random.randn(N)\nrandom_x2 = 10 + np.random.randn(N)\nrandom_x3 = 1 + np.random.randn(N)\nrandom_y0 = 2 + np.random.randn(N)\nrandom_y1 = 4 + np.random.randn(N)\nrandom_y2 = 4 + np.random.randn(N)\nrandom_y3 = 3 + 3 * np.random.randn(N)","8554d7ee":"cluster1=pd.DataFrame({'x':random_x0,'y':random_y0,'label':'culster1'})\ncluster2=pd.DataFrame({'x':random_x1,'y':random_y1,'label':'culster2'})\ncluster3=pd.DataFrame({'x':random_x2,'y':random_y2,'label':'culster3'})\ncluster4=pd.DataFrame({'x':random_x3,'y':random_y3,'label':'culster4'})","238dddb3":"plt.scatter(cluster1.iloc[:,0],cluster1.iloc[:,1],color=\"red\",alpha=0.3,label='cluster1')\nplt.scatter(cluster3.iloc[:,0],cluster3.iloc[:,1],color=\"green\",alpha=0.3,label='cluster3')\nplt.title(\"cluster k=2\")\nplt.legend(loc='best')\nplt.show()","a1c28bf3":"dataset1 = pd.concat([cluster1,cluster3],axis=0).drop(['label'],axis=1)\ndataset1.head()","36c10e07":"distortions = []\n\ndata=dataset1\n\nfor i  in range(1,15):                \n    km = KMeans(n_clusters=i, random_state=0)\n    km.fit(data)                     \n    distortions.append(km.inertia_)   \n\nplt.plot(range(1,15),distortions,marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.show()","e8a8479f":"plt.scatter(cluster1.iloc[:,0],cluster1.iloc[:,1],color=\"red\",alpha=0.3,label='cluster1')\nplt.scatter(cluster2.iloc[:,0],cluster2.iloc[:,1],color=\"blue\",alpha=0.3,label='cluster2')\nplt.scatter(cluster3.iloc[:,0],cluster3.iloc[:,1],color=\"green\",alpha=0.3,label='cluster3')\nplt.title(\"cluster k=3\")\nplt.legend(loc='best')\nplt.show()","2702e3f2":"dataset2 = pd.concat([cluster1,cluster2,cluster3],axis=0).drop(['label'],axis=1)\ndataset2.head()","4a56695f":"distortions = []\n\ndata=dataset2\n\nfor i  in range(1,15):                \n    km = KMeans(n_clusters=i, random_state=0)\n    km.fit(data)                     \n    distortions.append(km.inertia_)   \n\nplt.plot(range(1,15),distortions,marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.show()","db8e718b":"plt.scatter(cluster1.iloc[:,0],cluster1.iloc[:,1],color=\"red\",alpha=0.3,label='cluster1')\nplt.scatter(cluster2.iloc[:,0],cluster2.iloc[:,1],color=\"blue\",alpha=0.3,label='cluster2')\nplt.scatter(cluster4.iloc[:,0],cluster4.iloc[:,1],color=\"orange\",alpha=0.3,label='cluster4')\nplt.title(\"cluster k=3\")\nplt.legend(loc='best')\nplt.show()","66c860b8":"dataset3 = pd.concat([cluster1,cluster2,cluster4],axis=0).drop(['label'],axis=1)\ndataset3.head()","b74fca57":"distortions = []\n\ndata=dataset3\n\nfor i  in range(1,15):                \n    km = KMeans(n_clusters=i, random_state=0)\n    km.fit(data)                     \n    distortions.append(km.inertia_)   \n\nplt.plot(range(1,15),distortions,marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.show()","f3b1f7a6":"num_of_cluster=2\n\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=num_of_cluster, random_state=0).fit(dataset3)\nkmeans.labels_\n\nplt.scatter(dataset3.iloc[:,0],dataset3.iloc[:,1],c=kmeans.labels_,alpha=0.5)\nplt.show()","bc21d6ab":"num_of_cluster=3\n\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=num_of_cluster, random_state=0).fit(dataset3)\nkmeans.labels_\n\nplt.scatter(dataset3.iloc[:,0],dataset3.iloc[:,1],c=kmeans.labels_,alpha=0.5)\nplt.show()","349b7657":"num_of_cluster=4\n\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=num_of_cluster, random_state=0).fit(dataset3)\nkmeans.labels_\n\nplt.scatter(dataset3.iloc[:,0],dataset3.iloc[:,1],c=kmeans.labels_,alpha=0.5)\nplt.show()","c3c8b0fe":"# Cluster K=3\u3000almost neatly divided into three parts","1c4d0c12":"<font size=4, color='red'>You can clearly see 2 is proper number for K from Elbow method above<\/font>","f44c2642":"<font size=4, color='red'>\nSince clusters are not neatly separated, you can not see the clear proper number for K.<br>\nThis happens often because of charactor of dataset.<br>\n<\/font>\n<br>\n<font size=4>\nLet's try KMeans clustering to this dataset.\n<\/font>","4d30fa9e":"# Cluster K=3\u3000not neatly separated case","ac3acabc":"<font size=4, color='red'>You can see 3 would be proper number for K from Elbow method above<\/font>","c20995ab":"# Make Clusters","8fd8a0ea":"# Cluster K=2\u3000almost neatly divided into three parts"}}