{"cell_type":{"ecb15a02":"code","541a7fde":"code","52c44d43":"code","658eebc1":"code","f11454fc":"code","87f9d75e":"code","80b2c47c":"code","64d019fa":"code","b4d1c94f":"code","da4bd415":"code","96329c74":"markdown"},"source":{"ecb15a02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","541a7fde":"df = df = pd.read_csv(\"\/kaggle\/input\/nse-stocks-database\/banknifty.csv\", usecols=['date','open','high','low','close'])\ndf.columns","52c44d43":"import matplotlib.pyplot as plt\nimport pandas as pd\n\nimport datetime as dt\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler","658eebc1":"df = df.sort_values('date')\nprint(len(df))","f11454fc":"###### PLOTTING GRAPH ##############\n\nplt.figure(figsize = (18,9))\nplt.plot(range(df.shape[0]),(df['low']+df['high'])\/2.0)\n# plt.plot(range(df.shape[0]),(df['volume']))\nplt.xticks(range(0,df.shape[0],10000),df['date'].loc[::10000],rotation=45)\nplt.xlabel('Date',fontsize=18)\nplt.ylabel('Mid Price',fontsize=18)\nplt.show()","87f9d75e":"high_prices = df.loc[:,'high'].values\nlow_prices = df.loc[:,'low'].values\nmid_prices = (high_prices+low_prices)\/2.0\n\ntrain_data = mid_prices[:320000]\ntest_data = mid_prices[320000:]","80b2c47c":"scaler = MinMaxScaler()\ntrain_data = train_data.reshape(-1,1)\ntest_data = test_data.reshape(-1,1)","64d019fa":"smoothing_window_size = 10000\nfor di in range(0,300000,smoothing_window_size):\n    scaler.fit(train_data[di:di+smoothing_window_size,:])\n    train_data[di:di+smoothing_window_size,:] = scaler.transform(train_data[di:di+smoothing_window_size,:])\n\n# You normalize the last bit of remaining data\nscaler.fit(train_data[di+smoothing_window_size:,:])\ntrain_data[di+smoothing_window_size:,:] = scaler.transform(train_data[di+smoothing_window_size:,:])\n\n# Reshape both train and test data\ntrain_data = train_data.reshape(-1)\n\n# Normalize test data\ntest_data = scaler.transform(test_data).reshape(-1)\n\n# Now perform exponential moving average smoothing\n# So the data will have a smoother curve than the original ragged data\nEMA = 0.0\ngamma = 0.1\nfor ti in range(320000):\n  EMA = gamma*train_data[ti] + (1-gamma)*EMA\n  train_data[ti] = EMA\n\n# Used for visualization and test purposes\nall_mid_data = np.concatenate([train_data,test_data],axis=0)\n\n# MSE\n\nwindow_size = 500\nN = train_data.size\nstd_avg_predictions = []\nstd_avg_x = []\nmse_errors = []\n\nfor pred_idx in range(window_size,N):\n\n    if pred_idx >= N:\n        date = dt.datetime.strptime(k, '%Y-%m-%d').date() + dt.timedelta(days=1)\n    else:\n        date = df.loc[pred_idx,'date']\n\n    std_avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))\n    mse_errors.append((std_avg_predictions[-1]-train_data[pred_idx])**2)\n    std_avg_x.append(date)\n\nprint('MSE error for standard averaging: %.5f'%(0.5*np.mean(mse_errors)))\n","b4d1c94f":"plt.figure(figsize = (18,9))\nplt.plot(range(df.shape[0]),all_mid_data,color='b',label='True')\nplt.plot(range(window_size,N),std_avg_predictions,color='orange',label='Prediction')\n#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\nplt.xlabel('Date')\nplt.ylabel('Mid Price')\nplt.legend(fontsize=18)\nplt.show()\n","da4bd415":"# EXPONENTIAL MOVING AVERAGE\n\nwindow_size = 1000\nN = train_data.size\n\nrun_avg_predictions = []\nrun_avg_x = []\n\nmse_errors = []\n\nrunning_mean = 0.0\nrun_avg_predictions.append(running_mean)\n\ndecay = 0.5\n\nfor pred_idx in range(1,N):\n\n    running_mean = running_mean*decay + (1.0-decay)*train_data[pred_idx-1]\n    run_avg_predictions.append(running_mean)\n    mse_errors.append((run_avg_predictions[-1]-train_data[pred_idx])**2)\n    run_avg_x.append(date)\n\nprint('MSE error for EMA averaging: %.5f'%(0.5*np.mean(mse_errors)))\n\nplt.figure(figsize = (18,9))\nplt.plot(range(df.shape[0]),all_mid_data,color='b',label='True')\nplt.plot(range(0,N),run_avg_predictions,color='orange', label='Prediction')\n#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\nplt.xlabel('Date')\nplt.ylabel('Mid Price')\nplt.legend(fontsize=18)\nplt.show()","96329c74":"Please give an upvote if you like this :)"}}