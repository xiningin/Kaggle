{"cell_type":{"1edf1e01":"code","d62b60ef":"code","ad65b63a":"code","c27e86f3":"code","4f431bc3":"code","22a822d9":"code","d7397b5d":"code","59bf8a1e":"code","432fed25":"code","f305801e":"code","f38bb56a":"code","6179f268":"code","6bfd5e1d":"code","7928f271":"code","dc41e957":"code","25fd62ef":"code","dafa06bd":"code","08629a3d":"code","f3946027":"markdown","293def22":"markdown","6a2795a4":"markdown","38538a95":"markdown","8eb3532f":"markdown","f463c445":"markdown","723382b9":"markdown","60f227a2":"markdown","459449e9":"markdown","45b303bd":"markdown","dd87e121":"markdown","fc8d4b8b":"markdown","2c42c1eb":"markdown","c94d7a56":"markdown"},"source":{"1edf1e01":"import pandas as pd\nimport numpy as  np\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori,association_rules","d62b60ef":"data = pd.read_csv('..\/input\/apps-user-used-the-most\/apriori_data.csv')\ndata.head()\ndata['AppName'].dtypes","ad65b63a":"data.values","c27e86f3":"df = list(data[\"AppName\"].apply(lambda x:x.split(',')))","4f431bc3":"df","22a822d9":"te = TransactionEncoder()\nte_data = te.fit(df).transform(df)\ndata = pd.DataFrame(te_data,columns=te.columns_)\ndata\n","d7397b5d":"freq_items = apriori(data, min_support = 0.30, use_colnames = True, verbose = 1)\nfreq_items.sort_values(\"support\", ascending = False)","59bf8a1e":"freq_items['length'] = freq_items['itemsets'].apply(lambda x: len(x))\n","432fed25":"freq_items","f305801e":"freq_items.loc[((freq_items['length']>=2) \n                | (freq_items['support']>50)),:]","f38bb56a":"df_ar = association_rules(freq_items, metric = \"confidence\", min_threshold = 0.5)\ndf_ar","6179f268":"df_ar[(df_ar.support > 0.45) | (df_ar.confidence > 0.5)].sort_values(\"confidence\", ascending = False)","6bfd5e1d":"import seaborn as sns\nsns.scatterplot(data=df_ar,x=df_ar['support'],y=df_ar['confidence'])","7928f271":"import matplotlib.pyplot as plt\n%matplotlib inline","dc41e957":"X=df_ar['support']\ny=df_ar['confidence']\n\nfig,ax = plt.subplots()\ncmap = plt.cm.RdYlGn\nnorm = plt.Normalize(1,4)\n# c = np.random.randint(1,3,size=43)\n\nsc = plt.scatter(X,y, s=100, cmap=cmap, norm=norm)#c=c)\n\nannot = ax.annotate(\"\", xy=(0,0), xytext=(20,20),textcoords=\"offset points\",\n                    bbox=dict(boxstyle=\"round\", fc=\"w\"),\n                    arrowprops=dict(arrowstyle=\"->\"))\nannot.set_visible(True)\n\ndef update_annot(ind):\n\n    pos = sc.get_offsets()[ind[\"ind\"][0]]\n    annot.xy = pos\n    text = \"{}, {}\".format(\" \".join(list(map(str,ind[\"ind\"]))), \n                           \" \".join([names[n] for n in ind[\"ind\"]]))\n    annot.set_text(text)\n    annot.get_bbox_patch().set_facecolor(cmap(norm(c[ind[\"ind\"][0]])))\n    annot.get_bbox_patch().set_alpha(0.4)\n\n\ndef hover(event):\n    vis = annot.get_visible()\n    if event.inaxes == ax:\n        cont, ind = sc.contains(event)\n        if cont:\n            update_annot(ind)\n            annot.set_visible(True)\n            fig.canvas.draw_idle()\n        else:\n            if vis:\n                annot.set_visible(False)\n                fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect(\"motion_notify_event\", hover)","25fd62ef":"def onpick3(event):\n    ind = event.ind\n    print('onpick3 scatter:', ind, npy.take(X, ind), npy.take(y, ind))\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\ncol = ax1.scatter(X, y, picker=True)\n#fig.savefig('pscoll.eps')\nfig.canvas.mpl_connect('pick_event', onpick3)","dafa06bd":"pip install mplcursors","08629a3d":"import mplcursors\nfig, ax = plt.subplots()\nax.scatter(X,y)\nax.set_title(\"Mouse over a point\")\ncrs = mplcursors.cursor(ax,hover=True)\n\ncrs.connect(\"add\", lambda sel: sel.annotation.set_text(\n    'Point {},{}'.format(sel.target[0], sel.target[1])))\n","f3946027":"<p style=\"color:orange\"> \u27a1\u27a1 I Am Interested In Knowing What All Combinations Had a High Confidence n Support Values So Why Not Make a Scatter Plot<\/p>","293def22":"<h2 style=\"color:lightblue\" > so lets start !!  <\/h2>","6a2795a4":"<h1 style=\"color:purple\">Apriori algo applied on apps used most...<\/h1>\n\n<p style=\"text-align:center; border:1px solid black\"><img style=\"text-align:center\",src=\"https:\/\/www.google.com\/url?sa=i&url=https%3A%2F%2Fwww.macstories.net%2Fstories%2Fdevelopers-decade-long-rollercoaster-ride-the-business-of-selling-apps-on-the-app-store%2F&psig=AOvVaw10K7zSdrodFo3wCheb56AQ&ust=1608676511286000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCICX87aZ4O0CFQAAAAAdAAAAABAD\"><\/p>\n","38538a95":"<h3 style=\"color:orange\" > This is my first NB to kaggle , do SUPPORT it if you like <\/h3>  \nn feel free to give your suggestions for further improvements","8eb3532f":"<b style=\"color:black\">what are antecedants 'n' Consequents ???<\/b>\n\n<p style=\"color:orange\">\n\u27a1\u27a1  Antecedent support variable tells us probability of antecedent products alone\n\n<p style=\"color:orange\">\n\u27a1\u27a1  Consequents support variable tells us probability of consequents products alone(may cross check manually)\n\n<p style=\"color:orange\">    \n\u27a1\u27a1  The support value is the support value of the two products combined (Antecedents and Consequents)\n<\/p>\n<\/p>\n<\/p>\n","f463c445":"<html>\n\n<h3 style=\"color:orange\">\nwhat is association rule mining???? \n\nAssociation rule mining finds interesting associations and relationships among large sets of data items. This rule shows how frequently a itemset occurs in a transaction. \n<\/h3>\n\n<p style=\"color:orange\">\nBefore we start implementation of <b> # the apriori rule<\/b> \n    <\/p>\n    <h2 style=\"color:purple\">\n    <b>let us first see the basic definitions.\u2b07\u2b07\u2b07<\/b>\n    <\/h2>\n    \n<\/html>\n\n\n* Support Count(sigma) \u2013 Frequency of occurrence of a itemset.\n\n\n* Frequent Itemset \u2013 An itemset whose support is greater than or equal to minsup threshold.\n\n\n* Association Rule \u2013 An implication expression of the form X -> Y, where X and Y are any 2 itemsets.\n\n\n* Support(s) \u2013The number of transactions that include items in the {X} and {Y} parts of the rule as a percentage of the total number of transaction.It is a measure of how frequently the collection of items occur together as a percentage of all transactions.\n\n\n*    **FORMULA** support = sigma(X+Y)\/total items \u2013 It is interpreted as fraction of transactions that contain both X and Y.\n\n\n* Confidence(c) \u2013 It is the ratio of the no of transactions that includes all items in {B} as well as the no of transactions that includes all items in {A} to the no of transactions that includes all items in {A}.  \n\n* **FORMULA** Conf(X=>Y) = **Supp(XUY) \/ Supp(X)** \u2013 It measures how often each item in Y appears in transactions that contains items in X also.\n\n*    Lift(l) \u2013 he lift of the rule X=>Y is the confidence of the rule divided by the expected confidence, assuming that the itemsets X and Y are independent of each other.The  expected confidence is the confidence divided by the frequency of {Y}.\n\n\n* Lift(X=>Y) = Conf(X=>Y) \/ Supp(Y) \u2013 Lift value near 1 indicates X and Y almost often appear together as expected, greater than 1 means they appear together more than expected and less than 1  they appear less than expected.Greater lift values indicate stronger association.\n\n","723382b9":"so,\n\nto keep it simple we have used a very low support price for the analysis \n\nmin_support == .30  i.e (30%)","60f227a2":"### --as we see that the data is encoded as whole strings format \n### --so we convert and split the data into the lists format","459449e9":"<h3> <p style=\"color:lightblue\" > we can clearly see from the table which apps were installed and which ones were not by the 30 individuals <\/p> <\/h3>","45b303bd":"### thanks for reading ","dd87e121":"<h2 style='color:black'>Interpretation From Above :--<\/h2>\n\n<p style=\"color:violet\"> maximum support pair of apps was youtube n whatsapp(WA) - being used in tandom\n\n<p style=\"color:violet\"> instagram , youtube and WA had max support as triplet pair\n\n<p style=\"color:violet\"> and WA,insta,youtube,meet being the only 4 pair app with greater value of supporting threshold (30% in this case)\n\n\n<p style='color:orange'> the support values for the head n tail of the data \n\n<p style='color:orange'> youtube and whatsapp being highest in support pairs of 2 tells us that out of 100% there is 87.0968% chance of both being downloaded or Watched \n\n<h2 style='color:lightblue'>starting with some exploration of the table!!<\/h2>","fc8d4b8b":"## all about data:\n#### **the data has been collected through a survey of 30 students aged between 17-21 n asked to select the top apps they watch or stream or install?**\n#### **this data is cleaned and made into the format needed by the user to see the data**\n#### **there were 16 most famous app in choices among the data to choose from.**","2c42c1eb":"<p style='color:pink'> some failed approaches to make labels appear in NB while hovering over em<\/p>\n<p style='color:pink'> this didnt worked may be NB's doesnt provide this feature of hovering <\/p>","c94d7a56":"<html>\nwe now apply the association_rule onto the freq_items dataframe \n\nwhich will return all the possible combinations of apps with\n    \n    Support >= Min_Threshold_Support \nvalues \n    <\/html>\n    \nto find more on how this works you may check [this github link](http:\/\/rasbt.github.io\/mlxtend\/user_guide\/frequent_patterns\/apriori\/)\n\nOR\n\n[this youtube video](https:\/\/youtu.be\/guVvtZ7ZClw) for theory building and analysis interpretation "}}