{"cell_type":{"373d172e":"code","684ac1a6":"code","a8adbcaa":"code","540eca10":"code","3d83f262":"code","5080b477":"code","a49765e4":"code","7d1533f4":"code","c6d2d72d":"code","546388f0":"code","56f6125d":"markdown","abcc2b97":"markdown"},"source":{"373d172e":"import numpy as np\nimport pandas as pd\nimport math\n# from statistics import NormalDist","684ac1a6":"data_source = \"..\/input\/sentiment140\/training.1600000.processed.noemoticon.csv\"\ndf = pd.read_csv(data_source, encoding =\"ISO-8859-1\", header = None)[[5,0]]\ndf.rename({5:\"text\", 0:\"target\"}, axis=1, inplace = True)\ndf.head()","a8adbcaa":"def get_upper_pct(s: str) -> float:\n    \"\"\"Calculate the percentage of uppercase alpha characters to the total number of alpha characters.\n    \n    Non-alpha characters are ignored in the calculation    \n    \"\"\"\n    \n    letters_only = ''.join(filter(str.isalpha, s))\n    uppercase_freq = sum(1 for c in letters_only if c.isupper())\n    return (uppercase_freq\/len(letters_only))*100\n\nupper_pct_df = df[\"text\"].apply(get_upper_pct)\ndf[\"upper_pct\"] = upper_pct_df\ndf.head()","540eca10":"# sorting the calues according to upper_pct in descending order\ndf.sort_values(\"upper_pct\", ascending=False).head(50)","3d83f262":"# percentage of tweets which has all caps\nall_caps_len = len(df[df[\"upper_pct\"] == 100])\n\nprint(f\"Percentage of tweets with all caps: {(all_caps_len\/len(df))*100}\")","5080b477":"# split the df into 4 categories:\n# 1. all caps with negative sentiment\n# 2. all caps with positive sentiment\n# 3. not all caps with negative sentiment\n# 4. not all caps with positive sentiment\n\ndf_all_caps = df[(df[\"upper_pct\"] == 100)]\ndf_not_all_caps = df[(df[\"upper_pct\"] != 100)]\n\ndf_caps_neg = df_all_caps[df_all_caps[\"target\"] == 0]\ndf_caps_pos = df_all_caps[df_all_caps[\"target\"] == 4]\ndf_neg = df_not_all_caps[df_not_all_caps[\"target\"] == 0]\ndf_pos = df_not_all_caps[df_not_all_caps[\"target\"] == 4]","a49765e4":"# formatting \n\ncat_array = [\n    [len(df_caps_neg)\/len(df_all_caps), len(df_neg)\/len(df_not_all_caps)], \n    [len(df_caps_pos)\/len(df_all_caps), len(df_pos)\/len(df_not_all_caps)]\n]\n\ndf_cat = pd.DataFrame(cat_array, index=[\"negative_sentiment\", \"positive_sentiment\"], columns=[\"all_caps\", \"normal\"])\ndf_cat","7d1533f4":"p_c = (len(df_caps_neg) + len(df_neg))\/(len(df))\nsigma = math.sqrt(p_c*(1-p_c)*(1\/len(df_all_caps) + 1\/len(df_not_all_caps)))\nsigma","c6d2d72d":"p_cap_estimate = df_cat[\"all_caps\"][\"negative_sentiment\"]\np_norm_estimate = df_cat[\"normal\"][\"negative_sentiment\"]\n\ndiff = p_norm_estimate - p_cap_estimate\ndiff","546388f0":"# kaggle is stupid and only support python3.7 which does not have the NormalDist class \n# p_value = statistics.NormalDist(mu=0, sigma=sigma).cdf(diff)\n# p_value = 0.002","56f6125d":"# Hypothesis testing\nOur hypothesis is that tweets with all caps will have a higher proportion of negative sentiment than other (normal) tweets. Let p_caps and p_norm be the population proportions of negative sentiments. Hense this is a one-tailed test.\n\nH0: p_caps = p_norm  \nH1: p_caps > p_norm","abcc2b97":"# Hypothesis testing conclusion\np-value = 0.002\nalpha-value = 0.01 i.e. 99% confidence interval.\n\nSince p-value < alpha-value, we reject H0. Hence, there is statistical significance that tweets with all caps has a higher likelihood to be of negative sentiment. :("}}