{"cell_type":{"528d1d5d":"code","80d08d7a":"code","7a0b15c9":"code","d36d4d41":"code","f6ea497c":"code","59612f1e":"code","9a42e986":"code","5e7faf76":"code","a6a7e088":"code","c84713bf":"code","693cc6b8":"code","3a87d691":"code","df2e3362":"code","5c31d750":"code","4458dc03":"code","7f0f2611":"code","0f254eae":"code","48cd165b":"code","7e98308e":"code","28ac3792":"code","0b622256":"code","fc9e2672":"code","0f26d9a8":"code","9a5e839d":"code","34a678ba":"code","39752609":"code","fe3c12b0":"code","aa65a7b8":"code","a39d3d84":"markdown","ff6a98f2":"markdown","08c67d1d":"markdown","56603915":"markdown","b9f7a291":"markdown","d56854c2":"markdown","38b12f3d":"markdown","7915ea21":"markdown","dbe9dc7e":"markdown","16a0c539":"markdown","bf798445":"markdown","81be711e":"markdown","723e884e":"markdown","47a31d30":"markdown","f10223bc":"markdown"},"source":{"528d1d5d":"# import the required packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # visualization\nimport seaborn as sns # visualization\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, LinearRegression, Ridge\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import scale, LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","80d08d7a":"# read the train dataset\ndf1 = pd.read_csv(\"..\/input\/train.csv\")\nprint(df1.shape)\ndf1.head()\n","7a0b15c9":"# create a new dataset that we will use for further computations and recreate the same when required from df1.\ntitanic = df1.copy()","d36d4d41":"# check datatype of features\ntitanic.describe().T","f6ea497c":"# check the datatype of each feature\ntitanic.info()","59612f1e":"print(titanic.isna().sum())\nprint(f\"percentage of missing values:\\nAge: {titanic['Age'].isna().sum()\/len(titanic) :.2f}, \\nCabin: {titanic['Cabin'].isna().sum()\/len(titanic) :.2f}, \\nEmbarked: {titanic['Embarked'].isna().sum()\/len(titanic) :.2f}\")","9a42e986":"titanic.Embarked.fillna(titanic.Embarked.mode()[0], inplace=True)","5e7faf76":"# Convert all features into required datatype\n# titanic.Survived = titanic.Survived.astype('object')\n# titanic.Pclass = titanic.Pclass.astype('object')\n# titanic.SibSp = titanic.SibSp.astype('object')\n# titanic.Parch = titanic.Parch.astype('object')","a6a7e088":"titanic.drop('Cabin', axis=1, inplace=True)","c84713bf":"survived_count = round(titanic.Survived.value_counts(normalize=True)*100, 2)\nsurvived_count.plot.bar(title='Proportion of Survived and non-Survived passengers in dataset')\nplt.xticks(rotation=0, fontsize=12)\nplt.yticks(fontsize=12)\nfor x,y in zip([0,1],survived_count):\n    plt.text(x,y,y,fontsize=12)\nplt.show()","693cc6b8":"plt.subplots(figsize=(15,15))\n\n# We check the number of passengers survived in each class.\nind = sorted(titanic.Pclass.unique())\nsur_0 = titanic.Pclass[titanic['Survived'] == 0].value_counts().sort_index()\nsur_1 = titanic.Pclass[titanic['Survived'] == 1].value_counts().sort_index()\ntotal = sur_0.values+sur_1.values\nsur_0_prop = np.true_divide(sur_0, total)*100\nsur_1_prop = np.true_divide(sur_1, total)*100\nplt.subplot(321)\nplt.bar(ind, sur_1_prop.values, bottom=sur_0_prop.values, label='1')\nplt.bar(ind, sur_0_prop.values, label='0')\nplt.title(\"Number of Passengers survived in each class\", fontsize=15)\nfor x,y,z in zip(ind,[100]*3,sur_1):\n    plt.text(x,y,z,fontsize=12)\nfor x,y,z in zip(ind,sur_0_prop,sur_0):\n    plt.text(x,y,z,fontsize=12)\nplt.xticks(ind)\n\n\n# plot survival proportion in Age, for it we create age bins\nbins = [0,10,20,30,40,50,60,70,80]\nnames = ['0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80']\ndf_temp = titanic.dropna()\ndf_temp['Age_bins'] = pd.cut(x=titanic.Age, bins=bins, labels=names, right=False)\n\nind = sorted(df_temp.Age_bins.unique()[:8])\nage_0 = df_temp.Age_bins[df_temp['Survived'] == 0].value_counts().sort_index()\nage_1 = df_temp.Age_bins[df_temp['Survived'] == 1].value_counts().sort_index()\ntotal = age_0.values+age_1.values\nage_0_prop = np.true_divide(age_0, total)*100\nage_1_prop = np.true_divide(age_1, total)*100\nplt.subplot(322)\nplt.bar(ind, age_1_prop.values, bottom=age_0_prop.values, label='1')\nplt.bar(ind, age_0_prop.values, label='0')\nplt.title(\"Number of Passengers survived in each age group\", fontsize=15)\nfor x,y,z in zip(ind,[100]*8,age_1):\n    plt.text(x,y,z,fontsize=12)\nfor x,y,z in zip(ind,age_0_prop,age_0):\n    plt.text(x,y,z,fontsize=12)\n\nplt.legend(loc='upper right')\n    \n# check the proportion of passengers survived as per gender\nind = sorted(titanic.Sex.unique())\nsex_0 = titanic.Sex[titanic['Survived'] == 0].value_counts().sort_index()\nsex_1 = titanic.Sex[titanic['Survived'] == 1].value_counts().sort_index()\ntotal = sex_0.values+sex_1.values\nsex_0_prop = np.true_divide(sex_0, total)*100\nsex_1_prop = np.true_divide(sex_1, total)*100\nplt.subplot(323)\nplt.bar(ind, sex_1_prop.values, bottom=sex_0_prop.values, label='1')\nplt.bar(ind, sex_0_prop.values, label='0')\nplt.title(\"Number of Passengers survived genderwise\", fontsize=15)\nfor x,y,z in zip(ind,[100]*2,sex_1):\n    plt.text(x,y,z,fontsize=12)\nfor x,y,z in zip(ind,sex_0_prop,sex_0):\n    plt.text(x,y,z,fontsize=12)\n\n\n# check the proportion of passengers survived from port embarked\nind = sorted(titanic.Embarked.unique())\nemb_0 = titanic.Embarked[titanic['Survived'] == 0].value_counts().sort_index()\nemb_1 = titanic.Embarked[titanic['Survived'] == 1].value_counts().sort_index()\ntotal = emb_0.values+emb_1.values\nemb_0_prop = np.true_divide(emb_0, total)*100\nemb_1_prop = np.true_divide(emb_1, total)*100\nplt.subplot(324)\nplt.bar(ind, emb_1_prop.values, bottom=emb_0_prop.values, label='1')\nplt.bar(ind, emb_0_prop.values, label='0')\nplt.title(\"Number of Passengers survived from port embarked\", fontsize=15)\nfor x,y,z in zip(ind,[100]*3,emb_1):\n    plt.text(x,y,z,fontsize=12)\nfor x,y,z in zip(ind,emb_0_prop,emb_0):\n    plt.text(x,y,z,fontsize=12)\n\n\n# check the proportion of passengers survived with Siblings and Spouse\nind = sorted(titanic.SibSp.unique())\nsib_0 = titanic.SibSp[titanic['Survived'] == 0].value_counts().sort_index()\nsib_1 = titanic.SibSp[titanic['Survived'] == 1].value_counts().sort_index()\nsib_1 = titanic.SibSp[titanic['Survived'] == 1].value_counts().sort_index()\nfor i in sib_0.index:\n    if i not in sib_1.index:\n        sib_1[i]=0\ntotal = sib_0.values+sib_1.values\nsib_0_prop = np.true_divide(sib_0, total)*100\nsib_1_prop = np.true_divide(sib_1, total)*100\nplt.subplot(325)\nplt.bar(ind, sib_1_prop.values, bottom=sib_0_prop.values, label='1')\nplt.bar(ind, sib_0_prop.values, label='0')\nplt.title(\"Number of Passengers survived with Siblings and Spouse onboard\", fontsize=15, loc='center')\nfor x,y,z in zip(ind,[100]*9,sib_1):\n    plt.text(x,y,z,fontsize=12)\nfor x,y,z in zip(ind,sib_0_prop,sib_0):\n    plt.text(x,y,z,fontsize=12)\nplt.xticks(ind)\n\n\nind = sorted(titanic.Parch.unique())\npar_0 = titanic.Parch[titanic['Survived'] == 0].value_counts().sort_index()\npar_1 = titanic.Parch[titanic['Survived'] == 1].value_counts().sort_index()\nfor i in par_0.index:\n    if i not in par_1.index:\n        par_1[i]=0\ntotal = par_0.values+par_1.values\npar_0_prop = np.true_divide(par_0, total)*100\npar_1_prop = np.true_divide(par_1, total)*100\nplt.subplot(326)\nplt.bar(ind, par_1_prop.values, bottom=par_0_prop.values, label='1')\nplt.bar(ind, par_0_prop.values, label='0')\nplt.title(\"Number of Passengers survived with Parents and Children onboard\", fontsize=15, loc='left')\nfor x,y,z in zip(ind,[100]*7,par_1):\n    plt.text(x,y,z,fontsize=12)\nfor x,y,z in zip(ind,par_0_prop,par_0):\n    plt.text(x,y,z,fontsize=12)\nplt.xticks(ind)\n\nplt.show()","3a87d691":"# check the distribution of Fare in data. For better prediction results we need the continous data to be nearly closely normally distributed\nplt.subplots(figsize=(15,6))\nplt.subplot(121)\nsns.distplot(titanic.Fare)\n# We can see the data is positively skewed. We remove the skewness by taking natlog of the Fare column values\n# we have 0s in Fare column which we replace with 0.0001 so as to have the record in data but not change it's meaning\ntitanic.Fare[titanic['Fare'] == 0] = 0.0001\nFare_ln = np.log(titanic.Fare)\nplt.subplot(122)\nsns.distplot(Fare_ln)\nplt.show()","df2e3362":"# separate the missing value records from titanic data for imputation\nage_X = titanic[titanic['Age'].notna()].drop(['Age','PassengerId','Name','Ticket','Fare','Survived'], axis=1)\nage_y = titanic.Age[titanic['Age'].notna()]\nage_test = titanic[titanic['Age'].isna()].drop(['Age','PassengerId','Name','Ticket','Fare','Survived'], axis=1)","5c31d750":"age_X[['SibSp','Parch']] = MinMaxScaler().fit_transform(age_X[['SibSp','Parch']])\nage_test[['SibSp','Parch']] = MinMaxScaler().fit_transform(age_test[['SibSp','Parch']])\n\nage_X = pd.get_dummies(age_X)\nage_test = pd.get_dummies(age_test)","4458dc03":"linreg = LinearRegression()\nlinreg.fit(age_X, age_y)\nage_pred = linreg.predict(age_test)","7f0f2611":"titanic.Age[titanic['Age'].isna()] = age_pred","0f254eae":"titanic.isna().sum()","48cd165b":"X_train = titanic.drop(['Survived','PassengerId','Name','Ticket','Fare'], axis=1)\ncol = X_train.columns\ny_train = titanic.Survived\ny_train = y_train.astype('int')","7e98308e":"X_train[['SibSp','Parch','Age']] = MinMaxScaler().fit_transform(X_train[['SibSp','Parch','Age']])\nX_train = pd.get_dummies(X_train)","28ac3792":"logreg = LogisticRegression().fit(X_train,y_train)","0b622256":"# Read the test data\ntest = pd.read_csv('..\/input\/test.csv')\ntest = test[col]\ntest.isna().sum()","fc9e2672":"# separate the missing value records from test for imputation\nage_test = test[test['Age'].isna()].drop('Age', axis=1)\n\nage_test[['SibSp','Parch']] = MinMaxScaler().fit_transform(age_test[['SibSp','Parch']])\n\nage_test = pd.get_dummies(age_test)\n\ntest.Age[test['Age'].isna()] = linreg.predict(age_test)\ntest.isna().sum()","0f26d9a8":"test[['SibSp','Parch','Age']] = MinMaxScaler().fit_transform(test[['SibSp','Parch','Age']])\ntest = pd.get_dummies(test)\ny_pred = logreg.predict(test)","9a5e839d":"submit = pd.read_csv('..\/input\/gender_submission.csv')\nsubmit.head()","34a678ba":"submit['Survived'] = y_pred\n# submit.to_csv('gender_submission.csv', index=False)","39752609":"import keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nearl = EarlyStopping(patience=3) # early stopping\n","fe3c12b0":"#Setting up the model\nmodel1 = Sequential()\nmodel2 = Sequential()\n#Add first layer\nmodel1.add(Dense(50,activation='relu',input_shape=(titanic.shape[1],)))\nmodel2.add(Dense(100,activation='relu',input_shape=(titanic.shape[1],)))\n#Add second layer\nmodel1.add(Dense(32,activation='relu'))\nmodel2.add(Dense(50,activation='relu'))\n#Add output layer\nmodel1.add(Dense(2,activation='sigmoid'))\nmodel2.add(Dense(2,activation='sigmoid'))\n#Compile the model\nmodel1.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\nmodel2.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])","aa65a7b8":"X_train = titanic.drop(['Survived','PassengerId','Name','Ticket','Fare'], axis=1).values\ny_train = titanic.Survived.values\ny_train = y_train.astype('int')","a39d3d84":"    Analysis of our hypothesis:\n    1. Proportion of passengers survived is higher in 1st class and reducing in 2nd and 3rd. So our first hypothesis is true and this becomes an important variable for survival prediction.\n    2. Going by age wise, children have higher survival rate, whereas old ones above the age of 70 have not survived at all. We can use this feature to predict survival rate on test data.\n    3. Females have higher survival rate than males, even though there are more number of male passengers.\n    4. Passengers embarked at Cherbourg have higher survival chances than others. We don't know the reason behind this since the existing data does not reveal much about this.\n    5. As we said about siblings and spouse, these passengers have higher survival chances.\n    6. Also passengers with lesser dependents have higher survival chances.\n    \n    so our all the hypothesis are true.","ff6a98f2":"    We can impute the Embarked missing values with mode straight away since we have only 2 missing values. \n    Cabin has 77% missing values, hence it is logical to drop the column\n    Age has 20% missing values, we can neither drop these rows nor column. So we can impute the same at later stage before generating model.","08c67d1d":"    The data is not sparse in target variable","56603915":"### Univariate analysis","b9f7a291":"### Multivariate analysis\n\n    We can analyse multiple features at a time to understand interaction between the feature. I will skip this and move towards missing values imputation and model building.","d56854c2":"## Build model","38b12f3d":"This is python notebook code written in kernel directly. Objective of this problem is to identify the features that affect the survival of passengers.\nThis we will achieve through EDA and then applying models to verify our assumptions.\n","7915ea21":"### Create submission file","dbe9dc7e":"    We have 10 independent variables (excluding Passenger Id), and we have a task to identify on which features is our target variable dependent most.\n    we can see that data has minimum age of 0.42, which we can consider it to be a baby on onboard.\n    \n    We can generate a hypothesis before we move based on features we can see.\n    1. If the passenger is from 1st class he\/she would be given first preference to be saved on lifeboat, then second, then third.\n    2. Females will be given preference over males, so higher number of females will be saved.\n    3. Based on age, children and old age passengers will be saved before young and middle aged generation.\n    4. If a person has siblings his\/her chances are higher to survive, since we can assume that they can work together.\n    5. If a passenger is accompanied by parents or children then he\/she might try to save the dependents first.\n    We cannot say right now based on information provided, about the survival of passengers based on port from which passenger is embarked.","16a0c539":"    We can see that there are total 891 records, and Age, Cabin and Embarked features have missing values.\n    Check the count of missing values in each feature","bf798445":"## Impute missing value in Age column using Regression technique","81be711e":"## Read the data and understand the features first","723e884e":"## Exploratory Data Analysis\n    Now we test our hypothesis and try to get more information","47a31d30":"## Predict resutls on test data","f10223bc":"## Comparing with Neural Network"}}