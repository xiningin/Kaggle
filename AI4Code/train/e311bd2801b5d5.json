{"cell_type":{"d2972ca6":"code","930f8a0f":"code","29ec82ab":"code","05e0fe1d":"code","7c48a321":"code","a38dd8a5":"code","e87ea35f":"code","d34f13a1":"code","a98687c4":"code","873b2e01":"code","c8878445":"code","9daf05ce":"code","397d644d":"code","d25d949a":"code","36c611a7":"code","85b0c52c":"code","c9562aba":"code","11dbb0da":"code","99ed299e":"code","2b6f0571":"code","b41f282c":"code","da23fc36":"code","472d8bbf":"code","968ed533":"code","5aaa9921":"code","c26e9348":"code","b21d0ae5":"code","94b67480":"code","93d24381":"code","3f23d04c":"code","027cf4eb":"code","83df3867":"code","04f72a6a":"code","b9b847ea":"code","706a5a6b":"code","e0d567c9":"code","63db42a3":"code","5eabcae1":"code","fed5d1e0":"code","453db789":"code","28d13ae7":"code","5197d60c":"code","d2eb38cb":"code","4fd2295e":"code","cffd903a":"code","f0506119":"code","f4d03d1b":"code","3a3343db":"code","d0d6907a":"code","9e990e6c":"code","2e335bd9":"code","ef913ad6":"code","991c95d4":"code","92aabd70":"code","b2a2fede":"markdown","e49257b4":"markdown","d602d57e":"markdown","65265428":"markdown","8f995fd0":"markdown","a657df41":"markdown","e561f8f9":"markdown","45e34f8a":"markdown","23233dc1":"markdown","fbab6569":"markdown","d95336f2":"markdown","4b28f1c8":"markdown","7e206ae0":"markdown","8f69cdbe":"markdown","37f7d942":"markdown","a8a20e7b":"markdown","230b49cc":"markdown","929a7b58":"markdown","4d19686b":"markdown","49484dd2":"markdown","8c59f525":"markdown","65e0e20b":"markdown","a483d475":"markdown","f953b8c0":"markdown"},"source":{"d2972ca6":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.preprocessing import RobustScaler\nfrom fbprophet import Prophet\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport math\nfrom statsmodels.tsa.seasonal import seasonal_decompose","930f8a0f":"%matplotlib inline","29ec82ab":"df_train = pd.read_csv('..\/input\/into-the-future\/train.csv')\ndf_test = pd.read_csv('..\/input\/into-the-future\/test.csv')","05e0fe1d":"df_train.head()","7c48a321":"df_train.info()","a38dd8a5":"df_train.describe()","e87ea35f":"df_test.info()","d34f13a1":"df_test.describe()","a98687c4":"# Saving id of test\nid_test = df_test['id'].values\ndate_test = df_test['time'].values","873b2e01":"# Train time stamp\ndf_train['time'] = pd.to_datetime(df_train['time'])\ndf_train.info()","c8878445":"df_train.head()","9daf05ce":"# Test data timestamp\n# Train time stamp\ndf_test['time'] = pd.to_datetime(df_test['time'])\ndf_test.info()","397d644d":"feature_1_total = df_train['feature_1']","d25d949a":"feature_1_total = feature_1_total.append(pd.Series(df_test['feature_1'].values))","36c611a7":"print('Total entries in train and test data combined is :',len(feature_1_total.values))","85b0c52c":"feature_1_total.describe()","c9562aba":"# Plotting feature_1 of combined train and test data\nplt.plot(feature_1_total.values)","11dbb0da":"# Plotting feature_1 of train data.\nplt.plot(df_train['feature_1'])","99ed299e":"# Plotting feature_1 of test data\nplt.plot(df_test['feature_1'])","2b6f0571":"df_test_copy = df_test.copy()\ndf_test.index = df_test.time","b41f282c":"df_test['feature_1'].plot()","da23fc36":"# Plot for drop in data at around 100\nplt.plot(df_train.loc[50:200, 'feature_1'])","472d8bbf":"# Plotting feature_2\nplt.plot((df_train['feature_2']), 'r')","968ed533":"# Zoomed plot to check seasonality in data\nplt.plot((df_train.loc[100:200, 'feature_2']), 'r')","5aaa9921":"df_train_time_indexed = df_train['feature_2']\ndf_train_time_indexed.index = df_train['time']","c26e9348":"#deseasonalize = seasonal_decompose(df_train_time_indexed, model='additive', period='10S')","b21d0ae5":"# Correlation matrix\ndf_train.corr()","94b67480":"sns.heatmap(df_train.corr())","93d24381":"# Dropping ID\ndf_train = df_train.drop('id', axis=1)","3f23d04c":"# pair plot to understand kind of relationship between various features\nsns.pairplot(data=df_train)","027cf4eb":"# Checking distribution of the feature_1 and feature_2\nfig, ax1 = plt.subplots(ncols=2, figsize=(20,5))\nax1[0].hist(df_train['feature_1'])\nax1[0].set_title('Feature_1 distribution')\nax1[1].hist(df_train['feature_2'])\nax1[1].set_title('Feature_2 distribution')","83df3867":"# Creating dataframe for FBProphet\nX = pd.DataFrame(columns=['ds', 'y', 'add1'])\nX['ds'] = df_train['time']\nX['y'] = df_train['feature_2']\nX['add1'] = df_train['feature_1']","04f72a6a":"X.describe()","b9b847ea":"# Checking relationship between feature_1 and feature_2\nsns.relplot(x='add1', y='y', data=X)","706a5a6b":"# Splitting data to evaluate model\nsize = int(X.shape[0]*0.9)\nx_train = X[:size]\nx_valid = X[size:]","e0d567c9":"print('Train data size = {}, Valid data size ={}'.format(x_train.shape[0], x_valid.shape[0]))","63db42a3":"# y_true_valid\nfeature_2_valid = x_valid['y']","5eabcae1":"# Wanted to fit logistic trend, seasonality but we don't have enough data knowledge\nmodel = Prophet(growth='linear', n_changepoints=50, seasonality_mode='multiplicative')\nmodel.fit(x_train)","fed5d1e0":"#Forecasting based on x_valid\nforecast = model.predict(x_valid.drop('y', axis=1))","453db789":"model.plot_components(forecast)","28d13ae7":"# Saving Prediction in a variable\nprediction = forecast['yhat']","5197d60c":"plt.plot(prediction, 'r')\nplt.plot(feature_2_valid.reset_index(drop=True), 'b')","d2eb38cb":"print('RMSE :', math.sqrt(mean_squared_error(feature_2_valid, prediction)))","4fd2295e":"print('MAE :', mean_absolute_error(feature_2_valid, prediction))","cffd903a":"X_test = pd.DataFrame(data=date_test, columns=['ds'])\nX_test['add1'] = df_test['feature_1'].values","f0506119":"X_test.head()","f4d03d1b":"model_full = Prophet(growth='linear', n_changepoints=50, seasonality_mode='multiplicative')\nmodel_full.fit(X)","3a3343db":"forecast_test = model.predict(X_test)","d0d6907a":"model_full.plot_components(forecast_test)","9e990e6c":"prediction = forecast_test['yhat']","2e335bd9":"forecast_test.head()","ef913ad6":"submisson = pd.DataFrame({'id': id_test,\n                         'feature_2': prediction})","991c95d4":"submisson.head()","92aabd70":"submisson.to_csv(r'Final_Submit.csv', index=False)","b2a2fede":"# Feature 2","e49257b4":"# Train Valid Split","d602d57e":"# TimeStamp\nHere we will convert train and test data's time i, datetime format","65265428":"<h3> Training model on full dataset<\/h3>","8f995fd0":"# Importing Files","a657df41":"Scale of feature_1 and feature_2 are diffrent. Data is steadily increaing till around 300 then there is some variance  and change of trend can be observed. At around 450 trend is again increaing.","e561f8f9":"<b> Observation <\/b> : <br>\n1. By  observing data is quite clear that feature_1 is decreaing with time whereas feature_1 is increasing hence we may have some neagtive correlation between feature_1 and feature_2. <br>\n2. Data of feature_1 and feature_2 are on diffrent scale.<br>\n3. There is somewhat constant decrease in feature_1 with some noise and only one abrupt change in training data.<br>\n4. There are 3 change point for trend in feature_2 amd some kind of seasonality which might be visible by diffrencing.","45e34f8a":"# Understanding Data Visually","23233dc1":"We can see data is not noraml hence we need to normalize the data. Feature_1 is Right skewed wheareas feature_2 is right skewed.","fbab6569":"# Understanding Data\nHere we will try to understand the data and on basis of this understaning we will zoom in further in right direction.","d95336f2":"By observing graphs of feature_1 we can see that function of feature_1 is decreasing with time but after 750 it is increasing abruptly. Although ther is some ups and downs in data at 100 and 300 but at 750 spike is much higher. We need to further investigate to understand why this happens.","4b28f1c8":"Total standard deviation of data is bit higher than trainig data this indicates that test set have some what diffrent data then train set.","7e206ae0":"Heat map reveals some pretty interesting facts about data, id positively co-related to feature_2 and negatively co-related to feature_1 This can be an indication that feature_1 and feature_2 is really a function with domain of id.<br>\nCorrelation of id and feature_1 is way too high we can safely discard on of them to reduce the effect of collinearity in model.","8f69cdbe":"Time Indexing shows us that abrupt change is at 2 hr 15 mins. Now let's observe other fluctuation in train data, With no context and historical simillar patterns it is tough to sat why this change occur hence due to lack of our knowledge on this change point we will skip its further investigation and assume its happened due to some random event which we don't have knowledge about.","37f7d942":"# Feature 1\nZooming in into feature_1 to understand data and it's underlying pattern.","a8a20e7b":"# FB prophet Model","230b49cc":"Test data is less variant when compared to the train data also it have lower maximum entry when compared to train data, This implies that we have sufficient room to counter outliers and high levarage points.","929a7b58":"We can notice some outlier in data at around 750.<br>\nAs we can see it might seems like relationship is linear but it is not the case since upper part of relational plot shows non linear relationship, It is only the later less prominent part which shows linearity hence <b>linear regression models would not be sufficent<\/b> to represent data succesfully.<br>\nThis implies we need to fit more complex models.","4d19686b":"<h3> Making submisson.csv <\/h3>","49484dd2":"# Predictions","8c59f525":"Standard deviation of feature_1 and feature_2 both are on higher side this mean we have large variance in data, It is not suitable for our prediction model so we will scale the data before feeding it to our forecasting model if supervised learning is used.\n<br>\ntime column is not not in datetime format so we need to convert it. time is averaged for every 10 seconds which means frequency of data points are 10s","65e0e20b":"# Scaling Data","a483d475":"From zoomed in view of data it seems like this is just random noise in data and is not related to change points. We will simply skip obersvation of another drop as that is simmilar to this one.","f953b8c0":"There is visible seasonality but it's not clear and it is varying in nature. "}}