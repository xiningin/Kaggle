{"cell_type":{"1e15059b":"code","e52bbede":"code","6b7eaa91":"code","cc4dcd8a":"code","43481204":"code","de3c624b":"code","5471c29b":"code","f8ebbde4":"code","e758a4da":"code","a7fc427e":"code","ab67f78d":"code","7822f22d":"code","18877fa9":"code","1da1975d":"code","efe49f61":"code","a0a3de53":"code","ede5ec03":"code","32185dc9":"code","9834400b":"code","d22f5155":"code","1144d4b6":"code","6be4222e":"code","43572ca4":"code","488e2807":"code","e77a591e":"code","d6b6373d":"code","0f31a076":"code","da57d3c4":"code","477a96fb":"code","0fe07162":"code","a1ccdfbc":"code","d51f9d66":"code","83e2af8c":"markdown","c65ea3f3":"markdown","29a41133":"markdown","48119f9f":"markdown","01abb10b":"markdown","e83f6381":"markdown","6196c3c8":"markdown","b741c87c":"markdown","e45ec4cb":"markdown","0f674114":"markdown","c7d3b02f":"markdown","d44134e4":"markdown","947fcada":"markdown","518f5186":"markdown","9b5e2ac5":"markdown","137cfaaf":"markdown","c7c6979b":"markdown","8384cd7a":"markdown","850a2485":"markdown","d59eb9fe":"markdown","cd1a2ce3":"markdown","f4d5bd3b":"markdown","446e4ede":"markdown","c84776bd":"markdown","fb587407":"markdown","8814abe8":"markdown","1a59a0e0":"markdown","1dc1c1c6":"markdown","d8055fb7":"markdown","4cf85a86":"markdown","a7baeb36":"markdown","e4a45014":"markdown","4b15df49":"markdown","9c7a880f":"markdown","662ba860":"markdown","3639424f":"markdown","2e45781f":"markdown","528bb0c0":"markdown","c0cf647b":"markdown","693dd431":"markdown","6b086f8a":"markdown","e93e076e":"markdown","af1cabda":"markdown","a18e0343":"markdown","5648c08e":"markdown","1a67db9f":"markdown","162e7eae":"markdown","2cd1d49f":"markdown","3ac7059d":"markdown","45b0e661":"markdown"},"source":{"1e15059b":"import itertools\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score","e52bbede":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","6b7eaa91":"data = pd.read_csv(\"https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBM-DS0321EN-SkillsNetwork\/datasets\/dataset_part_2.csv\")\ndata.head()","cc4dcd8a":"X = pd.read_csv('https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBM-DS0321EN-SkillsNetwork\/datasets\/dataset_part_3.csv')\nX.head()","43481204":"Y = data['Class']\ntype(Y)","de3c624b":"df=Y.value_counts()\nplt.figure(figsize=(8,8))\nax=sns.barplot(x=df.index, y=df.values, palette='hls', alpha=0.9)\nsns.despine(top=True, right=True, left=False, bottom=False)\nfor p in ax.patches:\n    ax.annotate('n = {:.0f}'.format(p.get_height()), (p.get_x()+0.4, p.get_height()), \n                ha='center', va='bottom', color='black', fontsize=14)\nax.set_xticklabels(['Unsuccessful', 'Successful'], minor=False, fontsize=12)\nplt.yticks(fontsize=12)\nplt.xticks(fontsize=12)\nplt.title('Launch Outcome Success Counts', fontsize=24)\nplt.ylabel('Number of Launches',fontsize=18)\nplt.xlabel('Outcome',fontsize=18)\nplt.show()","5471c29b":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)","f8ebbde4":"X_train.shape","e758a4da":"X_test.shape","a7fc427e":"scaler = preprocessing.StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","ab67f78d":"parameters ={'C':[0.01,0.1,1],\n             'penalty':['l2'],\n             'solver':['lbfgs']}\nlr=LogisticRegression(random_state=1)\nlogreg_cv = GridSearchCV(lr, parameters, cv=10, refit=True)\nlogreg_cv.fit(X_train, Y_train)","7822f22d":"print(\"Tuned hyperparameters:\",logreg_cv.best_params_)\nprint(\"Cross-validation accuracy:\",logreg_cv.best_score_)","18877fa9":"glm_acc=logreg_cv.score(X_test, Y_test)\nprint(\"Test set accuracy: {:.1%}\".format(glm_acc))\nglm_probs = logreg_cv.predict_proba(X_test)[:,1]\nglm_auc=roc_auc_score(Y_test, glm_probs) \nprint(\"Test set AUC: {:.3}\".format(glm_auc))","1da1975d":"# Compute confusion matrix\nglm_yhat = logreg_cv.predict(X_test)\nglm_f1 = f1_score(Y_test, glm_yhat) \nglm_prec = precision_score(Y_test, glm_yhat)\nglm_rec = recall_score(Y_test, glm_yhat) \ncnf_matrix = confusion_matrix(Y_test, glm_yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\nprint(classification_report(Y_test, glm_yhat))\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(8,6))\nplot_confusion_matrix(cnf_matrix, classes=['Landed', 'Did not land'], normalize= False, title='GLM Confusion matrix')","efe49f61":"parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n              'C': np.logspace(-3, 3, 5),\n              'gamma':np.logspace(-3, 3, 5)}\nsvm = SVC(probability=True, random_state=1)","a0a3de53":"svm_cv = GridSearchCV(svm, parameters, cv=10)\nsvm_cv.fit(X_train, Y_train)","ede5ec03":"print(\"Tuned hyperparameters:\",svm_cv.best_params_)\nprint(\"Cross-validation accuracy:\",svm_cv.best_score_)","32185dc9":"svm_acc=svm_cv.score(X_test, Y_test)\nprint(\"Test set accuracy: {:.1%}\".format(svm_acc))\nsvm_probs = svm_cv.predict_proba(X_test)[:,1]\nsvm_auc=roc_auc_score(Y_test, svm_probs) \nprint(\"Test set AUC: {:.3}\".format(svm_auc))","9834400b":"# Compute confusion matrix\nsvm_yhat = svm_cv.predict(X_test)\nsvm_f1 = f1_score(Y_test, svm_yhat) \nsvm_prec = precision_score(Y_test, svm_yhat)\nsvm_rec = recall_score(Y_test, svm_yhat) \ncnf_matrix = confusion_matrix(Y_test, svm_yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\nprint(classification_report(Y_test, svm_yhat))\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(8,6))\nplot_confusion_matrix(cnf_matrix, classes=['Landed', 'Did not land'], normalize=False, title='SVM Confusion matrix')","d22f5155":"parameters = {'criterion': ['gini', 'entropy'],\n     'splitter': ['best', 'random'],\n     'max_depth': [2*n for n in range(1,10)],\n     'max_features': ['auto', 'sqrt'],\n     'min_samples_leaf': [1, 2, 4],\n     'min_samples_split': [2, 5, 10]}\n\ntree = DecisionTreeClassifier(random_state=1)","1144d4b6":"tree_cv = GridSearchCV(tree, parameters, cv=10)\ntree_cv.fit(X_train, Y_train)","6be4222e":"print(\"Tuned hyperparameters:\",tree_cv.best_params_)\nprint(\"Cross-validation Accuracy:\",tree_cv.best_score_)","43572ca4":"tree_acc=tree_cv.score(X_test, Y_test)\nprint(\"Test set accuracy: {:.1%}\".format(tree_acc))\ntree_probs = tree_cv.predict_proba(X_test)[:,1]\ntree_auc=roc_auc_score(Y_test, tree_probs) \nprint(\"Test set AUC: {:.3}\".format(tree_auc))","488e2807":"# Compute confusion matrix\ntree_yhat = tree_cv.predict(X_test)\ntree_f1 = f1_score(Y_test, tree_yhat) \ntree_prec = precision_score(Y_test, tree_yhat)\ntree_rec = recall_score(Y_test, tree_yhat) \ncnf_matrix = confusion_matrix(Y_test, tree_yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\nprint(classification_report(Y_test, tree_yhat))\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(8,6))\nplot_confusion_matrix(cnf_matrix, classes=['Landed', 'Did not land'], normalize=False, title='Decision Tree Confusion matrix')","e77a591e":"parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n              'p': [1,2]}\n\nKNN = KNeighborsClassifier()","d6b6373d":"knn_cv = GridSearchCV(KNN, parameters, cv=10)\nknn_cv.fit(X_train, Y_train)","0f31a076":"print(\"Tuned hyperparameters:\",knn_cv.best_params_)\nprint(\"Cross-validation accuracy:\",knn_cv.best_score_)","da57d3c4":"knn_acc = knn_cv.score(X_test, Y_test)\nprint(\"Test set accuracy: {:.1%}\".format(knn_acc))\nknn_probs = knn_cv.predict_proba(X_test)[:,1]\nknn_auc=roc_auc_score(Y_test, knn_probs) \nprint(\"Test set AUC: {:.3}\".format(knn_auc))","477a96fb":"# Compute confusion matrix\nknn_yhat = knn_cv.predict(X_test)\nknn_f1 = f1_score(Y_test, knn_yhat) \nknn_prec = precision_score(Y_test, knn_yhat)\nknn_rec = recall_score(Y_test, knn_yhat) \ncnf_matrix = confusion_matrix(Y_test, knn_yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\nprint(classification_report(Y_test, knn_yhat))\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(8,6))\nplot_confusion_matrix(cnf_matrix, classes=['Landed', 'Did not land'], normalize=False, title='KNN Confusion matrix')","0fe07162":"data = {'AUC': [glm_auc, svm_auc, tree_auc, knn_auc], 'F1-Score': [glm_f1, svm_f1, tree_f1, knn_f1], \n        'Precision': [glm_prec, svm_prec, tree_prec, knn_prec], 'Recall': [glm_rec, svm_rec, tree_rec, knn_rec],\n        'Accuracy': [glm_acc, svm_acc, tree_acc, knn_acc]}\nres = pd.DataFrame(data, index=['Logistic Regression', 'SVM', 'Decision Tree', 'KNN']).sort_values(by=['AUC'], ascending=False)\nres.round(3)","a1ccdfbc":"plt.figure(figsize=(12,8))\nax=sns.barplot(x=res.index, y='Accuracy', data=res, palette='Blues_d')\nsns.despine(top=True, right=True, left=False, bottom=False)\nplt.xlabel('Model', fontsize=20)\nplt.ylabel('Accuracy', fontsize=20)\nax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.0f}%'.format(x*100)))\nfor p in ax.patches:\n    ax.annotate('{:.1f}%'.format(p.get_height()*100), (p.get_x()+0.4, p.get_height()), \n                ha='center', va='bottom',color= 'black')\nplt.title('Model Accuracy on the Test Set', fontsize=20)\nplt.show()","d51f9d66":"plt.figure(figsize=(12,8))\nax=sns.barplot(x=res.index, y='AUC', data=res, palette='Blues_d')\nsns.despine(top=True, right=True, left=False, bottom=False)\nplt.xlabel('Model', fontsize=20)\nplt.ylabel('Area Under the Curve', fontsize=20)\nfor p in ax.patches:\n    ax.annotate('{:.3f}'.format(p.get_height()), (p.get_x()+0.4, p.get_height()), \n                ha='center', va='bottom',color='black')\nplt.title('Test Set Area Under the Curve', fontsize=20)\nplt.show()","83e2af8c":"After splitting the data, there are 72 records in our training set and 18 in our test set.","c65ea3f3":"We will import the following libraries for the lab\n","29a41133":"## Import Libraries and Define Auxiliary Functions\n","48119f9f":"## TASK  9\n","01abb10b":"Create a logistic regression object  then create a  GridSearchCV object  <code>logreg_cv<\/code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters<\/code>.\n","e83f6381":"# **Space X  Falcon 9 First Stage Landing Prediction**\n","6196c3c8":"This function is to plot the confusion matrix.\n","b741c87c":"Most unsuccessful landings are planned. Space X performs a controlled landing in the oceans.\n","e45ec4cb":"We can plot the confusion matrix\n","0f674114":"## Load the dataframe\n","c7d3b02f":"We output the <code>GridSearchCV<\/code> object for logistic regression. We display the best parameters using the data attribute <code>best_params\\_<\/code> and the accuracy on the validation data using the data attribute <code>best_score\\_<\/code>.\n","d44134e4":"## TASK  8\n","947fcada":"## TASK  5\n","518f5186":"<center>\n    <img src=\"https:\/\/gitlab.com\/ibm\/skills-network\/courses\/placeholder101\/-\/raw\/master\/labs\/module%201\/images\/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  \/>\n<\/center>\n","9b5e2ac5":"Load the data\n","137cfaaf":"## TASK  10\n","c7c6979b":"Space X advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars; other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. Therefore if we can determine if the first stage will land, we can determine the cost of a launch. This information can be used if an alternate company wants to bid against space X for a rocket launch.   In this lab, you will create a machine learning pipeline  to predict if the first stage will land given the data from the preceding labs.\n","8384cd7a":"Lets look at the confusion matrix:\n","850a2485":"* Perform exploratory  Data Analysis and determine Training Labels\n*   Create a column for the class\n*   Standardize the data\n*   Split into training data and test data\n* Find best Hyperparameter for SVM, Classification Trees and Logistic Regression\n*   Find the method performs best using test data\n","d59eb9fe":"## TASK  4\n","cd1a2ce3":"Calculate the accuracy on the test data using the method <code>score<\/code>:\n","f4d5bd3b":"Create the outcome variable from the column <code>Class<\/code> in <code>data<\/code>, then assign it to the variable <code>Y<\/code>, make sure the output is a Pandas series (only one bracket df\\['name of  column']).\n","446e4ede":"Calculate the accuracy of tree_cv on the test data using the method <code>score<\/code>:\n","c84776bd":"Several examples of an unsuccessful landing are shown here:\n","fb587407":"Create a k nearest neighbors object then  create a  <code>GridSearchCV<\/code> object  <code>knn_cv<\/code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters<\/code>.\n","8814abe8":"## TASK  2\n","1a59a0e0":"Find the method performs best:\n","1dc1c1c6":"Create a decision tree classifier object then  create a  <code>GridSearchCV<\/code> object  <code>tree_cv<\/code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters<\/code>.\n","d8055fb7":"## Assignment:  Machine Learning Prediction\n","4cf85a86":"Calculate the accuracy on the test data using the method <code>score<\/code>:\n","a7baeb36":"## Objectives\n","e4a45014":"The SVM, KNN, and Logistic Regression model achieved the highest accuracy at 83.3%, while the SVM performs the best in terms of Area Under the Curve at 0.958.","4b15df49":"Estimated time needed: **60** minutes\n","9c7a880f":"## TASK  6\n","662ba860":"## TASK  12\n","3639424f":"Use the function <code>train_test_split<\/code> to split the data sets `X` and `Y` into training and test data. Set the parameter <code>test_size<\/code> to 0.2 and random_state to 2.\n","2e45781f":"Examining the confusion matrix, we see that logistic regression can distinguish between the different classes.  We see that the major problem is false positives.\n","528bb0c0":"Use the function using <code>fit_transform()<\/code> to standardize the training data so that we can learn the scaling parameters of our training set. Then, use these learned parameters to scale our test data.","c0cf647b":"![](https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork\/api\/Images\/landing\\_1.gif)\n","693dd431":"Calculate the accuracy of tree_cv on the test data using the method <code>accuracy_score<\/code>:\n","6b086f8a":"## TASK  1\n","e93e076e":"## TASK  7\n","af1cabda":"We can plot the confusion matrix\n","a18e0343":"***\n","5648c08e":"Copyright \u00a9 2020 IBM Corporation. All rights reserved.\n","1a67db9f":"![](https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork\/api\/Images\/crash.gif)\n","162e7eae":"## TASK  3\n","2cd1d49f":"We can plot the confusion matrix\n","3ac7059d":"## TASK  11\n","45b0e661":"Create a support vector machine object then  create a  <code>GridSearchCV<\/code> object  <code>svm_cv<\/code> with cv - 10.  Fit the object to find the best parameters from the dictionary <code>parameters<\/code>.\n"}}