{"cell_type":{"4a1c4cfd":"code","6739ad7f":"code","9b296c3b":"code","c81e2f32":"code","471d3240":"code","e8d54277":"code","92d6d17e":"code","7c6427e3":"code","09d57f78":"code","1faf835f":"code","37b76fe5":"code","6db2d452":"code","1ac8e1d8":"code","4c931f4d":"code","945c0939":"code","d64133ca":"code","95815dc0":"code","c0586b80":"code","c26bb8eb":"code","c6f075af":"code","484ddfe7":"code","d3f2e680":"code","a6acfc9d":"code","11d33214":"code","481877ce":"code","75371224":"code","86998b77":"code","164882ca":"code","ecc24c07":"code","f29c1ae5":"code","4a647611":"code","4b68b4e2":"code","1bfdcb27":"code","7ea62e28":"code","a20dbf59":"code","fdaf4094":"code","32b7a71b":"code","d133c964":"code","56a70b05":"code","7297b612":"code","a2f2dcc0":"code","aab87b9f":"code","4d0a6e97":"code","423281ea":"code","76899074":"code","479e27b1":"code","82e5ca5a":"code","473873fc":"code","e1597337":"code","c642cc19":"code","d59631f3":"code","543c4c4f":"code","b17bc756":"code","8faea658":"code","4b4a6e71":"code","78e17041":"code","685d37ca":"code","4adf18ac":"code","38b2c7ee":"code","9ef9beeb":"code","48b1e834":"code","07786e57":"code","ee82dcf5":"code","6849d115":"code","52b96469":"code","30299b56":"code","62d90895":"code","e153c55c":"code","eadb061d":"code","a54d478f":"code","e522d452":"code","a343d250":"code","1aefb20d":"code","dbca9f95":"code","7ef6398c":"code","76c30fc3":"code","b4e0af84":"markdown","47891a54":"markdown","321c37fc":"markdown","ba2d7bca":"markdown","48c152dc":"markdown","4db96136":"markdown","b61e4a52":"markdown","359b80d5":"markdown","afd01699":"markdown","b090969d":"markdown","4d8cf2f6":"markdown","cc2307cb":"markdown","dbd41c06":"markdown","29c0e9bd":"markdown","91a323d2":"markdown","a3501c6b":"markdown","c947848e":"markdown","5a64825c":"markdown","089d52f5":"markdown","8f2a7512":"markdown","83b12d7c":"markdown","ffdd5288":"markdown","a8c23175":"markdown","c523761a":"markdown","d205841e":"markdown","42d74b4f":"markdown","9951a79b":"markdown","f562266b":"markdown","d21811ec":"markdown","be49ff9f":"markdown","fba9427b":"markdown","789d0dad":"markdown","d5c28cfa":"markdown","e4359641":"markdown","37b06a42":"markdown","ca8585f3":"markdown","19a26421":"markdown","a060a9aa":"markdown","3fc0e90b":"markdown","20425fce":"markdown","f17d0128":"markdown","ba140ff1":"markdown","3fa7942d":"markdown","ed8e2328":"markdown","39ce5112":"markdown"},"source":{"4a1c4cfd":"# Let's invite Our asssistant\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns","6739ad7f":"# invite the Data\nraw_data = pd.read_csv('..\/input\/titanic\/train.csv')","9b296c3b":"# let's see the data\nraw_data.head()","c81e2f32":"# describe numerical data\nraw_data.describe()","471d3240":"# describe categorical data\nraw_data.describe(include=['O'])","e8d54277":"# total missing value each variables\nraw_data.isna().sum()","92d6d17e":"# drop unimportant columns\nraw_data.drop(['PassengerId','Name','Ticket','Cabin'], axis=1, inplace=True)","7c6427e3":"# drop missing value\nraw_data.dropna(subset=['Age'], inplace=True)\n\n# because Embarked columns only has two missing value, I decided fill them with Mode\nraw_data['Embarked'].fillna(value='S', inplace=True)","09d57f78":"# total missing value each variables\nraw_data.isna().sum()","1faf835f":"# add family column\nraw_data['Family'] = raw_data['SibSp'] + raw_data['Parch']\n\n# drop Sibsp and Parch column\nraw_data.drop(['SibSp','Parch'], axis=1, inplace=True)","37b76fe5":"raw_data.head()","6db2d452":"# make a checkpoint\ndf = raw_data.copy()","1ac8e1d8":"df['Survived'].unique()","4c931f4d":"sns.distplot(df['Survived'])","945c0939":"df['Pclass'].unique()","d64133ca":"sns.distplot(df['Pclass'])","95815dc0":"# because it categorical data We need do One-hot encoding\ndf = pd.get_dummies(df, columns=['Pclass'])","c0586b80":"df.head()","c26bb8eb":"df['Sex'].unique()","c6f075af":"sex_dict = {'female':0, 'male':1}\ndf['Sex'] = df['Sex'].map(sex_dict)","484ddfe7":"sns.distplot(df['Age'])","d3f2e680":"sns.boxplot(df['Age'])","a6acfc9d":"# normal distribution check\nage_kurtosis = df['Age'].kurt()\nage_skewness = df['Age'].skew()\n\nprint ('Kurtosis and Skewness of Age \\n')\nprint ('Kurtosis: ' + str(age_kurtosis))\nprint ('Skewness: ' + str(age_skewness))","11d33214":"sns.distplot(df['Fare'])","481877ce":"sns.boxplot(df['Fare'])","75371224":"# normal distribution check\nfare_kurtosis = df['Fare'].kurt()\nfare_skewness = df['Fare'].skew()\n\nprint ('Kurtosis and Skewness of Fare \\n')\nprint ('Kurtosis: ' + str(fare_kurtosis))\nprint ('Skewness: ' + str(fare_skewness))","86998b77":"# drop the outlier\n# We should drop '0' too, because, it means you didn't pay for it\ndf.drop(df.loc[df['Fare']>= 500].index, inplace=True)\ndf.drop(df.loc[df['Fare']== 0].index, inplace=True)\n\n# recheck the Kurtosis and Skewness\nfare_kurtosis = df['Fare'].kurt()\nfare_skewness = df['Fare'].skew()\n\nprint ('Kurtosis and Skewness of Fare after remove the outlier\\n')\nprint ('Kurtosis: ' + str(fare_kurtosis))\nprint ('Skewness: ' + str(fare_skewness))","164882ca":"df['Fare'] = np.log(df['Fare'])","ecc24c07":"# recheck the Kurtosis and Skewness\nfare_kurtosis = df['Fare'].kurt()\nfare_skewness = df['Fare'].skew()\n\nprint ('Kurtosis and Skewness of log_Fare\\n')\nprint ('Kurtosis: ' + str(fare_kurtosis))\nprint ('Skewness: ' + str(fare_skewness))","f29c1ae5":"df['Embarked'].value_counts()","4a647611":"df = pd.get_dummies(df, columns=['Embarked'])","4b68b4e2":"df.head()","1bfdcb27":"sns.distplot(df['Family'])","7ea62e28":"sns.boxplot(df['Family'])","a20dbf59":"# normal distribution check\nfamily_kurtosis = df['Family'].kurt()\nfamily_skewness = df['Family'].skew()\n\nprint ('Kurtosis and Skewness of Family \\n')\nprint ('Kurtosis: ' + str(family_kurtosis))\nprint ('Skewness: ' + str(family_skewness))","fdaf4094":"df['Survived'].value_counts()","32b7a71b":"# Class count \ntotal_0, total_1 = df['Survived'].value_counts()\n\n# Divide by class\nsurvived_0 = df[df['Survived'] == 0]\nsurvived_1 = df[df['Survived'] == 1]","d133c964":"# do under_sampling\nsurvived_0_under = survived_0.sample(total_1)\nbalanced_data = pd.concat([survived_0_under, survived_1], axis=0)\n\nprint('Random under-sampling:')\nprint(balanced_data['Survived'].value_counts())","56a70b05":"# reset index data frame\nbalanced_data.reset_index(drop=True, inplace=True)","7297b612":"balanced_data.head()","a2f2dcc0":"# First, We must split the data which one has quantitative data and which one has qualitative data\n\nquantitative_data = balanced_data[['Age','Fare','Family']]\n\n\nqualitative_data = balanced_data[['Survived','Sex','Pclass_1','Pclass_2','Pclass_3','Embarked_C','Embarked_Q','Embarked_S']]","aab87b9f":"# Warmup the engine\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()","4d0a6e97":"# standardize the data\nscaled_quan = scaler.fit_transform(quantitative_data)","423281ea":"# turn into pandas\nscaled_quan = pd.DataFrame(scaled_quan, columns=quantitative_data.columns)","76899074":"# combine with categorical data\nscaled_data = pd.concat([scaled_quan,qualitative_data], axis=1)","479e27b1":"scaled_data.head()","82e5ca5a":"# First, We must declare which one is dependent variable, and which one is independet variables\ny = scaled_data['Survived']\nx = scaled_data.drop(['Survived'], axis=1)","473873fc":"# Import library for VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)","e1597337":"calc_vif(x)","c642cc19":"# drop Pclass_3 and Embarked_Q columns (Both of Them have small size)\nscaled_data.drop(['Pclass_3','Embarked_Q'],axis=1, inplace=True)","d59631f3":"import statsmodels.api as sm","543c4c4f":"# First, We must declare which one is dependent variable, and which one is independet variables\ny = scaled_data['Survived']\nx = scaled_data.drop('Survived',axis=1)","b17bc756":"X = sm.add_constant(x)\nlog_reg = sm.Logit(y,X)\nresult_log = log_reg.fit()","8faea658":"result_log.summary()","4b4a6e71":"# I decided to drop Fare first because It has largest p-value than others\nx = scaled_data.drop(['Survived','Fare'],axis=1)\n\nX = sm.add_constant(x)\nlog_reg = sm.Logit(y,X)\nresult_log = log_reg.fit()\n\nresult_log.summary()","78e17041":"# and I decided to drop both of Embarked because It doesn't have significant p-value\nx = scaled_data.drop(['Survived','Fare','Embarked_C','Embarked_S'],axis=1)\n\nX = sm.add_constant(x)\nlog_reg = sm.Logit(y,X)\nresult_log = log_reg.fit()\n\nresult_log.summary()","685d37ca":"from sklearn.metrics import accuracy_score","4adf18ac":"y_predict = result_log.predict()\ny_predict = np.around(y_predict)","38b2c7ee":"accuracy_score(y, y_predict)","9ef9beeb":"# save the model\nresult_log.save('train.pickle')","48b1e834":"# prepare the ingredients\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\nsurvived_data = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","07786e57":"# combine it\nraw_data2 = pd.merge(test_data, survived_data, on='PassengerId')","ee82dcf5":"raw_data2.isna().sum()","6849d115":"# drop unimportant columns base on Our analysis before\nraw_data2.drop(['PassengerId','Name','Ticket','Fare','Cabin'], axis=1, inplace=True)\nraw_data2.dropna(inplace=True)","52b96469":"# add Family column\nraw_data2['Family'] = raw_data2['SibSp'] + raw_data2['Parch']\n\n# drop Sibsp and Parch column\nraw_data2.drop(['SibSp','Parch'], axis=1, inplace=True)","30299b56":"# checkpoint\ndf2 = raw_data2.copy()\ndf2.reset_index(drop=True, inplace=True)","62d90895":"# because Pclass categorical data We need do One-hot encoding\ndf2 = pd.get_dummies(df2, columns=['Pclass'])","e153c55c":"# turn Sex data into binary\nsex_dict = {'female':0, 'male':1}\ndf2['Sex'] = df2['Sex'].map(sex_dict)","eadb061d":"# because Embarked categorical data We need do One-hot encoding\ndf2 = pd.get_dummies(df2, columns=['Embarked'])","a54d478f":"# a checkpoint\ndata2 = df2.copy()","e522d452":"# prevent multicollinearity\ndata2.drop(['Pclass_3','Embarked_Q'],axis=1, inplace=True)","a343d250":"# called the model\nnew_results = sm.load('train.pickle')","1aefb20d":"# define dependent and independent variables\ny = data2['Survived']\nx = data2.drop(['Survived','Embarked_C','Embarked_S'],axis=1)","dbca9f95":"# add constant (It is needed for Statsmodels)\nX = sm.add_constant(x)","7ef6398c":"# Predict Survived based on independent variables\ny_predict = new_results.predict(X)\ny_predict = np.around(y_predict)","76c30fc3":"# The accuracy\naccuracy_score(y, y_predict)","b4e0af84":"From distribution plot and boxplot, We know that this data is in normal distribution, so We don't have to take an action for it","47891a54":"Before We do regression, We should care about [multicollinearity](https:\/\/www.analyticsvidhya.com\/blog\/2020\/03\/what-is-multicollinearity\/). I try to used VIF (Variable Inflation Factors) to analyze multicollinearity.","321c37fc":"Our data is ready to be analyzed","ba2d7bca":"## Embarked\n\nEmbarked means Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n<br>I think We should see the distribution first.\n<br>Lets see, does it have three different values?","48c152dc":"It's true, It has two different values,\n<br>now we should turn this into a number\n<br>0=female and 1=male","4db96136":"There's no missing value here","b61e4a52":"# Summary","359b80d5":"* VIF starts at 1 and has no upper limit\n* VIF = 1, no correlation between the independent variable and the other variables\n* VIF exceeding 5 or 10 indicates high multicollinearity between this independent variable and the others\n\nSource: https:\/\/www.analyticsvidhya.com\/blog\/2020\/03\/what-is-multicollinearity\/","afd01699":"## Pclass\n\nPclass means Ticket Class (1=1st, 2=2nd, 3=3rd)\n<br>lets see, does it have three different values?","b090969d":"# Balancing Data","4d8cf2f6":"**We are ready to do *Logistic Regression***","cc2307cb":"* **LLR p-value**: 0.00 -> Which mean Our Regression is significantly can predict the survival chance\n* **Age** has significant role to survival chance (p-value = 0.000) <br>the coefficient is negative, It means the youngers have more chance to survive\n* **Family** has significant role to survival chance (p-value = 0.014) <br>the coefficient is negative, It means the lonely one has more chance to survive\n* **Sex** has significant role to survival chance (p-value = 0.000) <br>the coefficient is negative, It means the female has more chance to survive (remember in this case 1=male 0=female)\n* Both of **Pclass** has significant role to survival chance (p-value = 0.000\/0.001) <br>the coefficient is positive, It means higher class has more chance to survive","dbd41c06":"cool, It's normal now","29c0e9bd":"# Clean the Data","91a323d2":"Let's try to cut off unimportant variable one by one <br>note: sort by p-value","a3501c6b":"# Let's Playing God Here\n\nIn this data We're trying to predict someone survival chance<br>\n(I think that only God can predict when someone will be die. But here, We are trying to playing God role) <br>\nhahaha just kidding","c947848e":"**SibSp:** numbers of siblings \/ spouses aboard the Titanic\n\n**ParCh:** numbers of parents \/ children aboard the Titanic\n\nThey have similarity, I think We should combine these columns into one column called Family<br>\n**Family:** numbers of family aboard the Titanic","5a64825c":"## Family\n\nFamily means number of family abroad the Titanic\n<br>I think We should see the distribution first.","089d52f5":"## Age\n\nAge means Age in years\nBecause Data is a scale data, I think We should see the distribution first.","8f2a7512":"Based on Our VIF result, We should do something with Pclass and Embarked variable because Their VIF is in infinite number which is more than 5\n\nWe should drop one of Pclass variables and Embarked variables because [this reason](https:\/\/www.quora.com\/How-and-why-having-the-same-number-of-dummy-variables-as-categories-is-problematic-in-linear-regression-Dummy-variable-trap-Im-looking-for-a-purely-mathematical-not-intuitive-explanation-Also-please-avoid-using-the\/answer\/Iliya-Valchanov?share=9494e990&srid=uX7Kg)","83b12d7c":"It's true, It has three different values,\n<br>now we should turn this into dummies","ffdd5288":"There is no significant change, I think We should turn it into natural log","a8c23175":"Yes, It only has two value, let's move on","c523761a":"# Let's check the accuracy","d205841e":"It's true, It has three different values,\n<br>now we should turn this into dummies","42d74b4f":"## Fare\n\nFare means Passenger fare\n<br>I think We should see the distribution first.","9951a79b":"Because of these decription,I decided to drop: <br>\n1. PassengerId\n2. Name\n3. Ticket (too much unique data, It's look like PassengerId\/Name data, so I think It doesn't play a big role)\n4. Cabin (too much missing value)\n5. Some of missing value in Age and Fare column","f562266b":"Based on this [Scientific journal](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3591587\/), data can be assumed to be normally distributed if skewness < 2 and kurtosis < 7 (if it's negative skewness > -2 and kurtosis > - 7).\n\nAs You can see, Our data is \"not normal\".\n<br>I think We should remove the outlier","d21811ec":"## SibSp and ParCh","be49ff9f":"Based on this [Scientific journal](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3591587\/), data can be assumed to be normally distributed if skewness < 2 and kurtosis < 7 (if it's negative skewness > -2 and kurtosis > - 7).\n\nAs You can see, Our data is \"normal\".","fba9427b":"# Standardizing Data","789d0dad":"## Variables\n\n\n**PassengerId:** Passenger ID\n\n**Name:** Name\n\n**Survived:** Survived (0=No & 1=Yes) \n\n**pclass:** Ticket Class (1=1st, 2=2nd, 3=3rd)\n\n**sex:** Sex\n\n**Age:** Age in years\n\n**SibSp:** numbers of siblings \/ spouses aboard the Titanic\n\n**ParCh:** numbers of parents \/ children aboard the Titanic\n\n**Ticket:** Ticket number\n\n**Fare:** Passenger fare\n\n**Cabin:** Cabin number\n\n**Embarked:** Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)","d5c28cfa":"# Logistic Regression","e4359641":"## Sex\n\nSex means sex (female and male)\n<br>lets see, does it have two different values?","37b06a42":"Based on this [Scientific journal](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3591587\/), data can be assumed to be normally distributed if skewness < 2 and kurtosis < 7 (if it's negative skewness > -2 and kurtosis > - 7).\n\nAs You can see, Our data is \"normal\".","ca8585f3":"### Survived\nSurvived means Survived (0=No & 1=Yes) \n<br>lets see, does It have two value only?","19a26421":"**The accuracy is 80%** (on train dataset)","a060a9aa":"cool, let's move on","3fc0e90b":"## Accuracy on Test Dataset","20425fce":"# Look Closer to Each Variables","f17d0128":"Based on the distribution, I think We should make another column called Alone","ba140ff1":"at least Our prediction is better than flipping the coin :)","3fa7942d":"I think We have the chosen one. Because all variable in this equation has an important role","ed8e2328":"**Final accuracy is 62%**","39ce5112":"# Data Overview"}}