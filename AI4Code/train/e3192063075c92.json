{"cell_type":{"925682a5":"code","d364db63":"code","1b24551c":"code","9b6b5e01":"code","080991a7":"code","80b262db":"code","c14d53f4":"code","ff989390":"code","aa750186":"code","4916854f":"code","4b4ca3f2":"code","f36d0655":"code","70bea6e5":"code","a1d6b44d":"code","e8d66615":"code","0ac2d54a":"code","b057e51b":"code","4b58ed96":"code","7f4f6277":"markdown","b0f12a2f":"markdown","347ecdca":"markdown","53e2af63":"markdown","763829c7":"markdown","36aa0f93":"markdown","9685e493":"markdown","bc80d2f4":"markdown","300edd43":"markdown","16e46812":"markdown","4af023cf":"markdown","1afecd70":"markdown","ce2144bc":"markdown","8bc9d9cd":"markdown","d985183e":"markdown","1bc75310":"markdown","301c7597":"markdown","2da01b92":"markdown","265d849c":"markdown"},"source":{"925682a5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator","d364db63":"train_datagen = ImageDataGenerator(rescale=1.\/255,                 \n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\ntraining_set = train_datagen.flow_from_directory('..\/input\/cat-or-dog-dataset\/dataset\/training_set',\n                                                 target_size=(64,64),\n                                                 batch_size=32,\n                                                 class_mode='binary')","1b24551c":"test_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_set = test_datagen.flow_from_directory('..\/input\/cat-or-dog-dataset\/dataset\/test_set',\n                                            target_size=(64,64),\n                                            batch_size=32,\n                                            class_mode='binary')","9b6b5e01":"cnn = tf.keras.models.Sequential()","080991a7":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=[64,64,3]))","80b262db":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2))","c14d53f4":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2))","ff989390":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2))","aa750186":"cnn.add(tf.keras.layers.Flatten())","4916854f":"cnn.add(tf.keras.layers.Dense(units = 152, activation='relu'))","4b4ca3f2":"cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","f36d0655":"cnn.summary()","70bea6e5":"import pydot\nkeras.utils.plot_model(cnn)","a1d6b44d":"cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","e8d66615":"checkpoint_cb = keras.callbacks.ModelCheckpoint(\"Best_Model.h5\", save_best_only=True)","0ac2d54a":"model_history = cnn.fit(x= training_set,\n                validation_data=test_set, \n                epochs=30, \n                callbacks=[checkpoint_cb])","b057e51b":"pd.DataFrame(model_history.history).plot(figsize=(8,5))\nplt.xlabel('No of Epochs')\nplt.ylabel('Accuracy')","4b58ed96":"test_image = image.load_img('..\/input\/cat-or-dog-dataset\/dataset\/single_prediction\/cat_or_dog_2.jpg',target_size=(64,64))\ntest_image = image.img_to_array(test_image)\ntest_image = test_image\/255.\ntest_image = np.expand_dims(test_image, axis=0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\n\nif result[0][0] > 0.5:\n    prediction = 'dog'\n    x = round((result[0][0])*100)\n    print(\"dog :\",x, \"%\")\n    print(\"cat :\",100-x,\"%\")\nelse:\n    prediction = 'cat'\n    y = round((1 - result[0][0])*100)\n    print(\"cat\", y, \"%\")\n    print(\"dog\", 100-y, \"%\")","7f4f6277":"### we set throshold to 0.5, if model's predicted value is more than 0.5 than its dog otherwise it's cat\n###   result > 0.5, Dog\n###   result < 0.5, Cat\n* closer to 1 higher the chance of dog\n* closer to 0 higher the chance of cat\n* Example1 : if model predict 0.4 than its cat because we set threshold to 0.5 but we are not that much confident since 0.4 are not that much closer to 0\n* Example2 : if model predict 0.9 than its dog and we are very much confident about our result because we are much closer to 1.","b0f12a2f":"# **Cat or Dog classifier using CNN**","347ecdca":"### Step 5 : Output Layer\n* units : we need only 1 output neuron since we do binary classification(cat or dog)\n* activation : we use sigmoid function because we are doing binary classification","53e2af63":"# Part 3 - Training the CNN\n## Compiling the CNN\n* optimizer : **adam** optimizer which is use stochastic gradient descent to update the weights and reduce the loss(error between actual and predicted values)\n* loss : **binary_crossentropy** since we are doing binary classification\n* metrics : we choose **accuracy** which is most releavant way to measure the performance of classification model","763829c7":"### Adding a third convolutional layer","36aa0f93":"## Importing the Libraries","9685e493":"### CNN Model Architecture","bc80d2f4":"### Step 4 : Full Connection\n* that 1D vector will become the input of ann","300edd43":"## Training the CNN on the training set and evaluating it on the Test set\n* x : training_data\n* validation_data : we give test set to validation data\n* epochs : no of iteration on given data ","16e46812":"# Part 2 - Building the CNN\n## Initializing the CNN","4af023cf":"# Part 1 - Data Preprocessing","1afecd70":"### Step 2 : Pooling\n* pool_size - size of frame you want to apply pooling\n* strides : No of pixel you want to move","ce2144bc":"### Step 1- Convolutional layer\n* filters,kernels : No of feature detector you want to apply\n* kernel_size : An integer or tuple\/list of 2 integers, specifying the height and width of 2D convolutional window\n* activation : i choose **relu** because rectify the non-linearity of the model\n* input_shape : initializing the images 64 by 64 and 3 channels(rgb) which is we already initialized","8bc9d9cd":"## Creating a callback object of callbacks.ModelCheckpoint class to store best model out of all","d985183e":"## Preprocessing the Training set\n### we using ImageDataGenerator class to image augmentation, and we're doing this because get rid of overfitting.\n* rescale - we know that pixels lies between 0 to 255, by dividing 255 to each pixel we make sure that values interval should be 0 to 1(Data Normalizatiom)\n* shear_size - it will rotate the Images counter clock-wise\n* zoom-range - for zoom in\/out of images\n* horizontal_flip - values is boolean and randomly flips inputs horizontally\n\n### then we give some parameters to train_datagen object as below\n* path - path of training set folder\n* target_size - to convert differnt sizes of images to one standard size of image for reduce the computation\n* batch_size - how many images in each batch (classic default is 32)\n* class_mode - we have a binary outcome(cat or dog) that is why value is binary\n\n### for get more information about parameters [click_here](https:\/\/keras.io\/api\/preprocessing\/image\/)","1bc75310":"### Adding a second convolutional layer","301c7597":"### NOTE: history method will give you model details at each epoch.","2da01b92":"# Part 4 - Making a single prediction","265d849c":"### Step 3 : Flattening\n* Flattening is used to converts pooling layers to one dimensional(1D) vector.\n* NOTE : no need to specify any parameters\n"}}