{"cell_type":{"ce5c1574":"code","f4c0e260":"code","b155b1d8":"code","68d3dc43":"code","1dbf8f71":"code","c6f4984d":"code","feae2a32":"code","bcc97e05":"code","907ce2e0":"code","1ddddabc":"markdown","2d5a627b":"markdown","daacb8c3":"markdown","565a3989":"markdown","d2b4084c":"markdown","0d08814b":"markdown","811e0f5f":"markdown","010128f8":"markdown"},"source":{"ce5c1574":"from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\nfrom tensorflow.keras.activations import relu, sigmoid\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport tensorflow as tf\nimport os\nimport math\nimport numpy as np\nimport cv2 as cv\nimport random as rd\nimport matplotlib.pyplot as plt\n\n\nrd.seed(1)","f4c0e260":"def define_model():\n    model = tf.keras.models.Sequential()\n    model.add(Conv2D(32, (3, 3), padding=\"same\",\n        input_shape=(96, 96, 3)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=-1))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=-1))\n    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=-1))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=-1))\n    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=-1))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=-1))\n    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=-1))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(2048))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(17))\n    model.add(Activation('sigmoid'))\n    \n    return model","b155b1d8":"class Dataset(Sequence):\n    def __init__(self, paths: str, batch_size: int):\n        super(Dataset, self).__init__()\n        self.batch_size = batch_size\n        self.__data = paths\n        self.classes = []\n        self.__labels = self.__list_labels(self.__data)\n        \n        \n    def __len__(self):\n        return math.ceil(len(self.__data) \/ self.batch_size)\n    \n    def __getitem__(self, idx):\n        batch_x = self.__data[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.__labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n        return np.array([self.__load_image(i) for i in batch_x]), np.array(batch_y)\n    \n    def __list_labels(self, paths: list):\n        labels = []\n        for path in paths:\n            label = path.split(os.path.sep)[-2].split('_')\n            labels.append(label)\n            \n        mlb = MultiLabelBinarizer()\n        labels = mlb.fit_transform(labels)\n        self.classes = mlb.classes_\n            \n        return labels\n    \n    @staticmethod\n    def __load_image(path: str):\n        img = cv.imread(path)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        img = cv.resize(img, (96, 96))\n        return img \/ 255.0","68d3dc43":"train_size = 0.7\npaths = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        \npaths = sorted(paths)\npaths[0]\nrd.shuffle(paths)\nassert 0.0 < train_size <= 1.0\nthresh = round(len(paths) * train_size)\ntrain_paths = paths[:thresh]\ntest_paths = paths[thresh:]\nprint(train_paths[0], test_paths[1])","1dbf8f71":"train_ds = Dataset(train_paths, batch_size=32)\ntest_ds = Dataset(test_paths, batch_size=32)\n\nmodel = define_model()\nmodel.compile(loss=tf.keras.losses.MAE,\n             optimizer=tf.keras.optimizers.Adam(lr=1e-3, decay=0.00005),\n             metrics=['accuracy'])","c6f4984d":"for i in range(len(train_ds.classes)):\n    classes = '\\n'.join(train_ds.classes)\n\nwith open('classes.txt', 'w') as f:\n    f.write(classes)\n    \nto_json = model.to_json()\n\nwith open('model.json', 'w') as f:\n    f.write(to_json)","feae2a32":"best_weights = ModelCheckpoint('best.h5',\n                               monitor='val_loss',\n                               verbose=1,\n                               save_weights_only=True,\n                               save_best_only=True,\n                               mode='min',\n                               save_freq='epoch')\n\n\nlast_weights = ModelCheckpoint('last.h5',\n                               monitor='val_loss',\n                               verbose=1,\n                               save_weights_only=True,\n                               save_best_only=False,\n                               mode='auto',\n                               save_freq='epoch')","bcc97e05":"with tf.device('\/GPU:0'):\n    history = model.fit(x=train_ds,\n                        validation_data=test_ds,\n                        steps_per_epoch=len(train_ds),\n                        epochs=500,\n                        callbacks=[best_weights, last_weights])","907ce2e0":"plt.figure(figsize=(21, 8))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='train_accuracy')\nplt.plot(history.history['val_accuracy'], label='test_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.subplot(1, 2, 2)\nplt.plot(history.history[\"loss\"], label='train_loss')\nplt.plot(history.history[\"val_loss\"], label='test_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nplt.show()","1ddddabc":"# Read the paths and sepatate them to train and test samples","2d5a627b":"# Define model checkpoints to save best and last weights from each epoch","daacb8c3":"# Implement Sequential class for load data","565a3989":"# Define Dataset class instance and compile model","d2b4084c":"# Train the model","0d08814b":"# Define the smaller VGG net","811e0f5f":"# Save classes names and model arch","010128f8":"# Plot train metrics"}}