{"cell_type":{"48995b36":"code","02e54a96":"code","543985ee":"code","76c51de2":"code","4158611d":"code","a1ad80ea":"code","d0ab2515":"code","b1f0a5ba":"code","a13c5c22":"code","97845780":"code","5724622c":"code","9f30b253":"code","7cb31821":"code","2df90d72":"code","232eb36b":"code","281f35c0":"code","e050e086":"code","e6e5c7db":"code","b02773a5":"code","2e45f74e":"code","ebe24a23":"code","de7672cf":"code","2446e7c4":"code","8b2421c2":"code","776d8163":"markdown","509303e5":"markdown","ace892dd":"markdown","0e747c3d":"markdown","91160189":"markdown"},"source":{"48995b36":"# Octopus ML pakage - github.com\/gershonc\/octopus-ml\n!pip install octopus-ml","02e54a96":"import warnings\nwarnings.simplefilter(\"ignore\")\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport time\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport tracemalloc\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.metrics import classification_report\n%matplotlib inline\nsns.set_style(\"whitegrid\")\n\npd.set_option('display.max_columns', None)  # or 1000\npd.set_option('display.max_rows', None)  # or 1000\npd.set_option('display.max_colwidth', -1)  # or 199\n\n#check out https:\/\/github.com\/gershonc\/octopus-ml\nimport octopus_ml as oc\n\nimport optuna\nimport lightgbm as lgbm \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold , StratifiedKFold\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","543985ee":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-mar-2021\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-mar-2021\/test.csv\")","76c51de2":"train_df.head(2)","4158611d":"# Data shape \nprint (\"Train set: \",train_df.shape)\nprint (\"Test set: \",test_df.shape)","a1ad80ea":"# DataFrane Summary by pandas summary package (extension of pandas.describe method) \ndfs = DataFrameSummary(train_df)\ndfs.summary()","d0ab2515":"# Top 10 sparse features, mainly labs results \npd.Series(1 - train_df.count() \/ len(train_df)).sort_values(ascending=False).head(10)","b1f0a5ba":"# Categorical features\n\ncategorical_features=[]\nfor c in train_df.columns:\n    col_type = train_df[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        train_df[c] = train_df[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)","a13c5c22":"# Target distribution analysis\nfig, ax =plt.subplots(1,2)\n\n\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(3,4))\nsns.set_context(\"paper\", font_scale=1.2)                                                  \nsns.countplot('target',data=train_df, ax=ax[0])\ntrain_df['target'].value_counts().plot.pie(explode=[0,0.2],autopct='%1.2f%%',ax=ax[1])\nfig.show()","97845780":"sns.displot(data = train_df, kind = 'hist', x = 'cont1', hue = 'target', multiple = 'stack',bins=25,height = 4, aspect = 1.7)\n","5724622c":"sns.displot(data = train_df, kind = 'hist', x = 'cont2', hue = 'target', multiple = 'stack',bins=25,height = 4, aspect = 1.7)\n","9f30b253":"features=train_df.columns.to_list()\nprint ('Number of features ', len(features))\n\nfeatures_remove=['target']\nfor f in features_remove:\n    features.remove(f)\n    \nX=train_df[features]\ny=train_df['target']","7cb31821":"data = X\ntarget = y\n\ndef objective(trial , data = data , target = target):\n    train_x , test_x , train_y , test_y = train_test_split(data , target , \\\n            test_size = 0.10 , random_state = 42)\n    \n    params = {\n        #'power': trial.suggest_categorical(\"power\", [True, False]),\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 1e-5 , 10),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda' , 1e-5 , 10),\n        'num_leaves' : trial.suggest_int('num_leaves' , 11 , 300),\n        'learning_rate' : trial.suggest_uniform('learning_rate' , 0 , 0.1),\n        'max_depth' : trial.suggest_int('max_depth' , 5 , 20),\n        'n_estimators' : trial.suggest_int('n_estimators' , 1 , 9999),\n        'min_child_samples' : trial.suggest_int('min_child_samples' , 1 , 100),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-5 , 1),\n        'subsample' : trial.suggest_uniform('subsample' , 0 , 1.0),\n        'colsample_bytree' : trial.suggest_loguniform('colsample_bytree' , 1e-5 , 1),\n        'random_state' : trial.suggest_categorical('random_state' , [0,42,2021,555]),\n        'cat_smooth': trial.suggest_float('cat_smooth', 1.0, 50.0),\n        #'resample': trial.suggest_categorical(\"resample\", [None, 'random']),\n        'metric' : 'auc',\n        'device_type' : 'gpu',\n    }\n    model = lgbm.LGBMClassifier(**params)\n    model.fit(train_x , train_y , eval_set = [(test_x , test_y)] , early_stopping_rounds = 200 , \\\n             verbose = False)\n    preds = model.predict_proba(test_x)[:,1]\n    auc = roc_auc_score(test_y , preds)\n    return auc","2df90d72":"study = optuna.create_study(direction = 'maximize' , study_name = 'lgbm')\nstudy.optimize(objective , n_trials = 20)\nprint('numbers of the finished trials:' , len(study.trials))\nprint('the best params:' , study.best_trial.params)\nprint('the best value:' , study.best_value)","232eb36b":"\n\nparams = {'resample': None,\n         'learning_rate': 0.01,\n         'power': False,\n         'boosting_type': 'gbdt',\n         'num_leaves': 153,\n         'max_depth': 14,\n         'max_delta_step': 9,\n         'reg_alpha': 14.206069641010822,\n         'reg_lambda': 4.35151505977074,\n         'colsample_bytree': 0.23599717695150987,\n         'cat_smooth': 49.698724437071206,\n         'cat_l2': 19\n         }\nparams_additional={'verbose': -1}\nparams.update(params_additional)\n\n\nclf,arr_f1_weighted,arr_f1_macro,arr_f1_positive,prediction_folds,preds_folds,y_folds= oc.cv(X,y,0.5,1,shuffle=True,params=study.best_trial.params)\n","281f35c0":"oc.cv_plot(arr_f1_weighted,arr_f1_macro,arr_f1_positive,'TBS match 2021 - Kaggle compatition')\n","e050e086":"print(classification_report(y_folds, prediction_folds))\n","e6e5c7db":"oc.roc_curve_plot(y_folds,preds_folds)\n","b02773a5":"feature_imp_list=oc.plot_imp(clf,X,'LightGBM Mortality Kaggle',num=30)\n","2e45f74e":"top_features=feature_imp_list.sort_values(by='Value', ascending=False).head(32)\ntop_features\n","ebe24a23":"list_for_correlations=top_features['Feature'].to_list()\nlist_for_correlations.append('target')\noc.correlations(train_df,list_for_correlations)","de7672cf":"def Kaggle_submission(file_name,model,test_data,ids_list):\n    if TARGET in test_data.columns:\n        test_data.drop([TARGET],axis=1,inplace=True)\n    #test_pred=model.predict(test_data[features])[:,1]\n    test_pred=model.predict(test_data[features])\n    print (test_pred[1:2])\n\n    submit=pd.DataFrame()\n    submit['id'] = ids_list\n    submit['target'] = test_pred\n    submit.to_csv(file_name,index=False)\n    return submit","2446e7c4":"# Categorical features on testset\n\ncategorical_features=[]\nfor c in test_df.columns:\n    col_type = train_df[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        test_df[c] = test_df[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)\n\nTARGET=\"target\"\nsubmit=Kaggle_submission(\"LGBM_baseline_v15.csv\",clf,test_df,test_df['id'])","8b2421c2":"submit.head(10)","776d8163":"## Data pre-processing\n","509303e5":"## HPO - Hyper Paramaters Optimization  ","ace892dd":"## Introduction\n\nThis notebook is a very basic and simple example of LightGBM model and a showcase of a package octopus-ml:\n[https:\/\/github.com\/gershonc\/octopus-ml](https:\/\/github.com\/gershonc\/octopus-ml)","0e747c3d":"## ML modeling with Octopus-ml","91160189":"## EDA"}}