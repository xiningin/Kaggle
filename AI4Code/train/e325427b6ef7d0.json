{"cell_type":{"4e59606e":"code","60774834":"code","7d3b97c1":"code","3a256390":"code","95201abc":"code","f0be1378":"code","0a7d21c0":"code","ad5454f7":"code","7bc2e596":"code","39d3d0c3":"code","f46c8701":"code","93bdc0a0":"code","234ddae5":"code","4a0455cd":"code","50a0a5c6":"code","284b261c":"code","7d96dbec":"code","22570d6a":"code","6734c36b":"code","472aab7a":"code","6490d475":"code","7f57ae10":"code","517f21a3":"code","b041d6e3":"code","2fd9292b":"markdown","c6c0bbea":"markdown"},"source":{"4e59606e":"%%capture\n!git clone https:\/\/gist.github.com\/belkhir-nacim\/5230ccfcab05f30c35abb03444f6a216 dataset_util\n!pip install pytorch-lightning==0.7.6\n!pip install git+https:\/\/github.com\/belkhir-nacim\/generative_model_toolbox\n!pip install fastai2","60774834":"import functools\nfrom enum import IntEnum\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils as utils\nimport argparse\nfrom dataset_util.kaggle_textile_texuture_dataset import TextureDataset\nimport os\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid\nfrom torch import optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","7d3b97c1":"from generative_models_toolbox.utils.device import Cudafy","3a256390":"cudafy = Cudafy(0)","95201abc":"from fastai2.vision.all import *\n","f0be1378":"# Optional dependency to visualize image gradient\nimport kornia\nfrom typing import List\nimport math\nfrom torch.nn.init import _calculate_correct_fan\n\n\nlaplace_filter = partial(kornia.filters.laplacian, kernel_size=3)\ngradient_filter = kornia.filters.sobel\n\ndef visualize_filter(image, filter_func, ax=None,title=None):\n    filt = filter_func(image.unsqueeze(0))\n    # Normalizing to [0, 1] range\n    filt -= filt.min()\n    filt \/= filt.max()\n    img = kornia.tensor_to_image(filt[0])\n    if ax is None:\n        fig = plt.figure()\n        ax = fig.gca()\n    ax.imshow(img,cmap='gray')\n    if title is not None: ax.set_title(title)\n    return ax\n\n#Helper function\ndef decode_prediction(learner, inp):\n    y_hat = learn.model(cudafy(inp))\n    return TensorImage(y_hat.transpose(0, 1).reshape(1, 256, 256))\n","0a7d21c0":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom typing import List\nimport math\n\n\ndef siren_init(tensor, use_this_fan_in=None):\n    \"\"\"\n        Siren initalization of a tensor. To initialize a nn.Module use 'apply_siren_init'. \n        It's equivalent to torch.nn.init.kaiming_uniform_ with mode = 'fan_in'\n        and the same gain as the 'ReLU' nonlinearity\n    \"\"\"\n    if use_this_fan_in is not None:\n        fan_in = use_this_fan_in\n    else:\n        fan_in = nn.init._calculate_correct_fan(tensor, \"fan_in\")\n    bound = math.sqrt(6.0 \/ fan_in)\n    with torch.no_grad():\n        return tensor.uniform_(-bound, bound)\n\n\ndef apply_siren_init(layer: nn.Module):\n    \"\"\"\n        Applies siren initialization to a layer\n    \"\"\"\n    siren_init(layer.weight)\n    if layer.bias is not None:\n        fan_in = nn.init._calculate_correct_fan(layer.weight, \"fan_in\")\n        siren_init(layer.bias, use_this_fan_in=fan_in)\n\n\nclass Siren(nn.Module):\n    \"\"\"\n        Siren activation\n        https:\/\/arxiv.org\/abs\/2006.09661\n    \"\"\"\n\n    def __init__(self, w0=1):\n        \"\"\"\n            w0 comes from the end of section 3\n            it should be 30 for the first layer\n            and 1 for the rest\n        \"\"\"\n        super().__init__()\n        self.w0 = torch.tensor(w0)\n\n    def forward(self, x):\n        return torch.sin(self.w0 * x)\n\n    def extra_repr(self):\n        return \"w0={}\".format(self.w0)\n\n\ndef siren_layer(in_features, out_features, bias=True, w0=1):\n    \"\"\"\n        Siren Layer - it's a modified linear layer with sine activation\n    \"\"\"\n    layer = nn.Sequential(nn.Linear(in_features, out_features, bias), Siren(w0))\n    apply_siren_init(layer[0])\n    return layer\n\n\ndef siren_model(dimensions: List[int]):\n    \"\"\"\n        Siren model as presented in the paper. It's a sequence of linear layers followed by the Siren activation\n    \"\"\"\n    first_layer = siren_layer(dimensions[0], dimensions[1], w0=30)\n    other_layers = []\n    for dim0, dim1 in zip(dimensions[1:-1], dimensions[2:]):\n        other_layers.append(siren_layer(dim0, dim1))\n    return nn.Sequential(first_layer, *other_layers)","ad5454f7":"def run_xp_trial():\n\n    dl = DataLoader(TextureDataset('\/kaggle\/input\/textiledefectdetection',train=True, patch_size= 64, keep_angles=False,  keep_defects=False, sub_sample=2),shuffle=True, batch_size=1)\n    img_ground_truth,_,_ = next(iter(dl))\n    img_ground_original = img_ground_truth.squeeze(0)\n    img_ground_truth = img_ground_truth.squeeze(0).permute(1,2,0)\n    \n    pipe = Pipeline([transforms.ToPILImage(), transforms.Resize(256), transforms.ToTensor()])\n    image = pipe(img_ground_original)\n    print(image.shape)\n    fig, axes = plt.subplots(1,3,figsize=(15,8))\n    visualize_filter(image, lambda x:x,ax=axes[0],title='original' )\n    visualize_filter(image, gradient_filter,ax=axes[1],title='gradient')\n    visualize_filter(image, laplace_filter,ax=axes[2],title='laplacian')\n    \n    y = image.reshape(1, -1).transpose(0, 1)\n    g0, g1 = torch.meshgrid([torch.arange(-1, 1, step=2\/256), torch.arange(-1, 1, step=2\/256)])\n    x = torch.cat([g0.flatten().unsqueeze(1), g1.flatten().unsqueeze(1)], dim=1)\n    x = x.float()\n    for coord, pixel_value in zip(x, y):\n        c = ( 128 * (1 + coord)).long()\n        assert (image[:, c[0], c[1]] == pixel_value).all(), \"Pixel values do not match\"\n    from torch.utils.data import TensorDataset, random_split\n    dset = TensorDataset(cudafy(x), cudafy(y))\n    val_pct = 0.2\n    val_len = int(len(dset)*val_pct)\n    lengths = [len(dset)-val_len, val_len]\n    train_dset, val_dset = random_split(dset, lengths)\n    dls = DataLoaders(DataLoader(train_dset, bs=256), DataLoader(val_dset, bs=4096))\n    learn = Learner(dls,  cudafy(siren_model([2, 256, 128, 64, 32, 1])),  loss_func=MSELossFlat(),opt_func=ranger)\n    print(learn.model)\n    learn.fit_flat_cos(5, lr=1e-3)\n    \n    fig, axes = plt.subplots(1,2,figsize=(15,8))\n    visualize_filter(image, lambda x:x,ax=axes[0],title='original' )\n    visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\n    fig, axes = plt.subplots(1,3,figsize=(15,8))\n    visualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\n    visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\n    tmp = laplace_filter(image.unsqueeze(0))  - laplace_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n    visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\n    fig, axes = plt.subplots(1,3,figsize=(15,8))\n    visualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\n    visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\n    tmp = gradient_filter(image.unsqueeze(0))  - gradient_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n    visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')","7bc2e596":"dl = DataLoader(TextureDataset('\/kaggle\/input\/textiledefectdetection',train=False, patch_size= 64, keep_angles=False,  keep_defects=True, sub_sample=10),shuffle=True, batch_size=1)\n\nimg_ground_truth = None\nfor data,angle,label in dl:\n    if label[0].item()==3:\n        img_ground_truth = data\n    else:\n        pass\n# img_ground_truth,_,_ = next(iter(dl)) if train == True\nimg_ground_original = img_ground_truth.squeeze(0)\nimg_ground_truth = img_ground_truth.squeeze(0).permute(1,2,0)\npipe = Pipeline([transforms.ToPILImage(), transforms.Resize(256), transforms.ToTensor()])\nimage = pipe(img_ground_original)\nprint(image.shape)","39d3d0c3":"fig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, lambda x:x,ax=axes[0],title='original' )\nvisualize_filter(image, gradient_filter,ax=axes[1],title='gradient')\nvisualize_filter(image, laplace_filter,ax=axes[2],title='laplacian')","f46c8701":"y = image.reshape(1, -1).transpose(0, 1)\ny.shape","93bdc0a0":"g0, g1 = torch.meshgrid([torch.arange(-1, 1, step=2\/256), torch.arange(-1, 1, step=2\/256)])\nx = torch.cat([g0.flatten().unsqueeze(1), g1.flatten().unsqueeze(1)], dim=1)\nx = x.float()\nx.shape","234ddae5":"for coord, pixel_value in zip(x, y):\n    c = ( 128 * (1 + coord)).long()\n    assert (image[:, c[0], c[1]] == pixel_value).all(), \"Pixel values do not match\"","4a0455cd":"from torch.utils.data import TensorDataset, random_split\ndset = TensorDataset(cudafy(x), cudafy(y))\nval_pct = 0.005\nval_len = int(len(dset)*val_pct)\nlengths = [len(dset)-val_len, val_len]\ntrain_dset, val_dset = random_split(dset, lengths)\ndls = DataLoaders(DataLoader(train_dset, bs=256), DataLoader(val_dset, bs=4096))\nlearn = Learner(dls,  cudafy(siren_model([2, 256, 128, 64, 32, 1])),  loss_func=MSELossFlat(),opt_func=ranger)","50a0a5c6":"learn.model","284b261c":"learn.fit_flat_cos(150, lr=1e-3)","7d96dbec":"fig, axes = plt.subplots(1,2,figsize=(15,8))\nvisualize_filter(image, lambda x:x,ax=axes[0],title='original' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\nfig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\ntmp = cudafy(laplace_filter(image.unsqueeze(0)))  - laplace_filter(decode_prediction(learn, cudafy(x)).unsqueeze(0) )\nvisualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\nfig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\ntmp = cudafy(gradient_filter(image.unsqueeze(0)))  - gradient_filter(decode_prediction(learn, cudafy(x)).unsqueeze(0) )\nvisualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n# fig, axes = plt.subplots(1,2,figsize=(15,8))\n# visualize_filter(image, lambda x:x,ax=axes[0],title='original' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\n# fig, axes = plt.subplots(1,3,figsize=(15,8))\n# visualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\n# tmp = laplace_filter(image.unsqueeze(0))  - laplace_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n# visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\n# fig, axes = plt.subplots(1,3,figsize=(15,8))\n# visualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\n# tmp = gradient_filter(image.unsqueeze(0))  - gradient_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n# visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')","22570d6a":"# Number of pixels on the image\n256*256*3\n","6734c36b":"# Number of parameters on the model\nprint('Number of parameters of the model {}'.format(sum([p.numel() for p in learn.model.parameters()])))","472aab7a":"from typing import List\ndef relu_model(dimensions: List[int]):\n    \"\"\"\n        Sequence of linear layers followed by ReLU\n    \"\"\"\n    layers = []\n    for dim0, dim1 in zip(dimensions[:-1], dimensions[1:]):\n        layers.append(nn.Linear(dim0, dim1))\n        layers.append(nn.ReLU())\n    return nn.Sequential(*layers)","6490d475":"learn = Learner(dls,  cudafy(relu_model([2, 256, 128, 64, 32, 1])),  loss_func=MSELossFlat(), opt_func=ranger )","7f57ae10":"learn.model","517f21a3":"learn.fit_flat_cos(150, lr=1e-3)","b041d6e3":"fig, axes = plt.subplots(1,2,figsize=(15,8))\nvisualize_filter(image, lambda x:x,ax=axes[0],title='original' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\nfig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\ntmp = cudafy(laplace_filter(image.unsqueeze(0)))  - laplace_filter(decode_prediction(learn, cudafy(x)).unsqueeze(0) )\nvisualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\nfig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\ntmp = cudafy(gradient_filter(image.unsqueeze(0)))  - gradient_filter(decode_prediction(learn, cudafy(x)).unsqueeze(0) )\nvisualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n# fig, axes = plt.subplots(1,2,figsize=(15,8))\n# visualize_filter(image, lambda x:x,ax=axes[0],title='original' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\n# fig, axes = plt.subplots(1,3,figsize=(15,8))\n# visualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\n# tmp = laplace_filter(image.unsqueeze(0))  - laplace_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n# visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\n# fig, axes = plt.subplots(1,3,figsize=(15,8))\n# visualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\n# tmp = gradient_filter(image.unsqueeze(0))  - gradient_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n# visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')","2fd9292b":"# Implicit Neural Representations with Periodic Activation Functions\n[https:\/\/arxiv.org\/pdf\/2006.09661.pdf](https:\/\/arxiv.org\/pdf\/2006.09661.pdf)","c6c0bbea":"# Training with ReLU"}}