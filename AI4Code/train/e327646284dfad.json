{"cell_type":{"1c8abb14":"code","b8c7c751":"code","589c775f":"code","a3e98965":"code","b3dc7cb7":"code","3d7765ea":"code","9e65f159":"code","56e94958":"code","673cb1af":"code","77164700":"code","b871c20b":"code","7b33c117":"code","d8eae62d":"code","a9b5fc9d":"code","2ea4b8a7":"code","c2cb7ef5":"code","c2a52ca4":"code","9ab50dba":"code","57d51a44":"code","99c87da4":"code","6be184b9":"code","81f1803d":"code","3f01233e":"code","2400563a":"code","959065d7":"code","db463a47":"code","0b8da965":"code","78fc137f":"code","5e88b6bc":"code","1aaa87d5":"markdown","b157d78c":"markdown","19a193a2":"markdown","dc303eb0":"markdown","54e62d0d":"markdown","88dd285b":"markdown","7b127c71":"markdown"},"source":{"1c8abb14":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import   r2_score, accuracy_score\nfrom sklearn.model_selection import GridSearchCV , train_test_split","b8c7c751":"data = pd.read_csv('..\/input\/students-performance-in-exams\/StudentsPerformance.csv')\n","589c775f":"data.head()","a3e98965":"cat_cols = ['gender',\n            'race\/ethnicity',\n            'parental level of education',\n            'lunch'\n            ]\nnum_cols = [\n            'math score',\n            'reading score',\n            'writing score'\n]\ndata['Total Score'] = data['writing score'] + data['math score'] + data['reading score']\ndata['Mean Score'] = ((data['writing score'] + data['math score'] + data['reading score']) \/\/ 3)","b3dc7cb7":"print(data.shape)","3d7765ea":"data.head()","9e65f159":"print('Total' ,np.mean(data['Total Score'] \/ 3))\nprint('Reading' , np.mean(data['reading score']))\nprint('Math' , np.mean(data['math score']))\nprint('Writing' ,np.mean(data['writing score']))","56e94958":"plt.figure(figsize=(8, 30), dpi=100)\nn = len(num_cols)\nfor i, col in enumerate(num_cols):\n    plt.subplot(2*n, 2, 2*i+1)\n    plt.hist(data[col], bins=10)\n    plt.title(col)\n    plt.subplot(2*n, 2, 2*i+2)\n    plt.boxplot(data[col].values)","673cb1af":"plt.figure(figsize=(10, 100), dpi=100)\nn = len(cat_cols)\nfor i, col in enumerate(cat_cols):\n    value_counts = data[col].value_counts()\n    plt.subplot(2*n,2,2*i+1)\n    plt.pie(value_counts, labels=value_counts.index)\n    plt.subplot(2*n,2,2*i+2)\n    plt.bar(np.arange(len(value_counts)), value_counts, tick_label=value_counts.index)\n    plt.ylabel(col)","77164700":"f = sns.pairplot(data[num_cols]);\nf.fig.set_size_inches(10,10)","b871c20b":"n = len(cat_cols)\nfor i, col in enumerate(cat_cols):\n    value_counts = data[col].value_counts()\n    plt.subplot(n,1,i+1)\n    value_counts.plot(kind=\"barh\", figsize=(15, 60))\n    plt.ylabel(col)","7b33c117":"le = LabelEncoder()\nfor col in cat_cols:\n  data[col] = le.fit_transform(data[col])\n  data[col]  = data[col].astype('int')\ndata['test preparation course'] = le.fit_transform(data['test preparation course'])","d8eae62d":"data.head()","a9b5fc9d":"X = data.drop(['gender'], axis= 1)\ny = data['gender']\nX_train, X_test, y_train, y_test = train_test_split(X, y ,test_size = 0.2)","2ea4b8a7":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression();\nmodel.fit(X_train,y_train);\npred_model = model.predict(X_train)","c2cb7ef5":"print(\"Logistic Regression  Score : \",model.score(X_test,y_test))","c2a52ca4":"params = {'C' : [0.0001 , 0.001 , 0.01 , 0.1 , 1 , 10 , 100]}","9ab50dba":"model_cv = GridSearchCV(model , param_grid= params , cv = 5 , n_jobs= -1)\nmodel_cv.fit(X_train , y_train)\npred_model_cv = model_cv.predict(X_train)","57d51a44":"print(\"Logistic Regression(GridSearchCV) : \",model_cv.score(X_test,y_test))","99c87da4":"from sklearn.ensemble import RandomForestClassifier\nrandom_tree = RandomForestClassifier()\nrandom_tree.fit(X_train,y_train);\npred_model = random_tree.predict(X_train)","6be184b9":"print(\"RandomForestClassifier  Score : \",random_tree.score(X_test,y_test))","81f1803d":"params_tree = {'max_depth' : [4, 5 , 6 , 7 , 8 , 9 , 10 , 11],\n          'n_estimators' : [100,500]}","3f01233e":"random_tree_cv = GridSearchCV(random_tree , param_grid= params_tree , cv = 5 , n_jobs= -1)\nrandom_tree_cv.fit(X_train,y_train);\npred_model = random_tree_cv.predict(X_train)","2400563a":"print(\"RandomForestClassifier(GridSearchCV)  Score : \",random_tree_cv.score(X_test,y_test))","959065d7":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train,y_train)\nknn_pred = knn.predict(X_test)","db463a47":"print(\"KNeighborsClassifier  Score : \",knn.score(X_test,y_test))","0b8da965":"params_knn = {'n_neighbors' : [4, 5 , 6 , 7 , 8 , 9 , 10 , 11],\n          'weights' : ['distance']}","78fc137f":"knn_cv = GridSearchCV(knn , param_grid= params_knn , cv = 5 , n_jobs= -1)\nknn_cv.fit(X_train,y_train)\nknn_cv_pred = knn_cv.predict(X_test)","5e88b6bc":"print(\"KNeighborsClassifier(GridSearchCV)  Score : \",knn_cv.score(X_test,y_test))","1aaa87d5":"## Displaying data for categorical features","b157d78c":"## Processing of categorical features","19a193a2":"## RandomForestClassifier and GridSearchCV","dc303eb0":"## Displaying data for numerical features","54e62d0d":"## The average of the final result and for each of the subjects","88dd285b":"## KNeighborsClassifier and GridSearchCV","7b127c71":"## LogisticRegression and GridSearchCV\n"}}