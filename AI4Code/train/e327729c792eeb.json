{"cell_type":{"4f6cff53":"code","7655eca3":"code","e766c66e":"code","9432651e":"code","f3e5e1c7":"code","90af6127":"code","7d91c8a1":"code","556588a7":"code","77a6414c":"code","0e5fe2b8":"code","776a8f8e":"code","35fd2510":"code","7fb45368":"code","c6b04456":"code","28a5096e":"code","7b81be44":"code","ccd76824":"code","7f6d99a6":"code","76b430d7":"code","33ff789c":"code","3d4258d8":"markdown","6d349ebb":"markdown","ab350132":"markdown","8adf6819":"markdown","5b32eae8":"markdown","85f0d865":"markdown"},"source":{"4f6cff53":"DEBUG = False","7655eca3":"#before import process\nimport sys\nsys.path.append('..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master')\n\n#imports\nimport os, warnings, random, time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\n#\u8a55\u4fa1\u6307\u6a19(ROC\u30b9\u30b3\u30a2)\u3092\u7b97\u51fa\u3057\u3066\u304f\u308c\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\n#training\u30c7\u30fc\u30bf\u5206\u5272\u3092\u5de5\u592b\u3059\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom sklearn.model_selection import StratifiedKFold\n\n#\u30d7\u30ed\u30b0\u30ec\u30b9\u30d0\u30fc\u3092\u8868\u793a\u3057\u3066\u304f\u308c\u308b\nfrom tqdm import tqdm_notebook as tqdm\n\n#pytorch\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\nimport torch\nfrom torch import nn, optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.utils.data import Dataset, DataLoader\n\n#Pytorch\u7528EfficientNet\u3092\u8aad\u307f\u8fbc\u3080\u305f\u3081\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom efficientnet_pytorch import model as enet\n\n#Data Augmentation\u7528\u30e9\u30a4\u30d6\u30e9\u30ea\nimport albumentations as A\n\n#\u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\nimport pickle\n\n#\u63cf\u753b\u8a2d\u5b9a\n%matplotlib inline\n\n#\u8b66\u544a\u6587\u3092\u5168\u3066\u7121\u8996\nwarnings.filterwarnings('ignore')","e766c66e":"SEED = 32 #69\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)\n","9432651e":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","f3e5e1c7":"#params\nenet_type = 'efficientnet-b1' #b0~b8\u307e\u3067\u3042\u308a\u307e\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u6570\u304c\u5927\u304d\u304f\u306a\u308a\u307e\u3059\u3002\nmodel_name = 'v1'\nn_epochs = 2 if DEBUG else 15\ncosine_t = 15\nn_fold = 5\n\nbatch_size = 64\nimage_size = 224\n\nnum_workers = 2 #\u30b5\u30fc\u30d0\u7528gpu\u7279\u6709\u306e\u6982\u5ff5\u3067\u3059\u3002\u4e26\u884c\u51e6\u7406\u3092\u3044\u304f\u3064\u884c\u3046\u304b\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\n\ninit_lr = 1e-3\nTTA = 1\n\nProgress_Bar = False","90af6127":"train_df = pd.read_csv('..\/input\/melanoma-merged-external-data-512x512-jpeg\/folds_13062020.csv')\ntest_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\ntrain_images = '..\/input\/melanoma-merged-external-data-512x512-jpeg\/512x512-dataset-melanoma\/512x512-dataset-melanoma'\ntest_images = '..\/input\/melanoma-merged-external-data-512x512-jpeg\/512x512-test\/512x512-test'\n\nif DEBUG:\n    train_df = train_df[:100]\n    test_df = test_df[:50]\nelse:\n    train_df = train_df[:10000]\n    test_df = test_df[:]\n# One-hot encoding of anatom_site_general_challenge feature\nconcat = pd.concat([train_df['anatom_site_general_challenge'], test_df['anatom_site_general_challenge']], ignore_index=True)\ndummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\ntrain_df = pd.concat([train_df, dummies.iloc[:train_df.shape[0]]], axis=1)\ntest_df = pd.concat([test_df, dummies.iloc[train_df.shape[0]:].reset_index(drop=True)], axis=1)\n\n# Sex features\ntrain_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\ntest_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\ntrain_df['sex'] = train_df['sex'].fillna(-1)\ntest_df['sex'] = test_df['sex'].fillna(-1)\n\n# Age features\ntrain_df['age_approx'] \/= train_df['age_approx'].max()\ntest_df['age_approx'] \/= test_df['age_approx'].max()\ntrain_df['age_approx'] = train_df['age_approx'].fillna(0)\ntest_df['age_approx'] = test_df['age_approx'].fillna(0)\n\ntrain_df['patient_id'] = train_df['patient_id'].fillna(0)","7d91c8a1":"train_df.head()","556588a7":"pretrained_model = {\n        'efficientnet-b0': '..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth',\n        'efficientnet-b1': '..\/input\/efficientnet-pytorch\/efficientnet-b1-dbc7070a.pth',\n        'efficientnet-b2': '..\/input\/efficientnet-pytorch\/efficientnet-b2-27687264.pth',\n        'efficientnet-b3': '..\/input\/efficientnet-pytorch\/efficientnet-b3-c8376fa2.pth',\n        'efficientnet-b4': '..\/input\/efficientnet-pytorch\/efficientnet-b4-e116e8b3.pth',\n        'efficientnet-b5': '..\/input\/efficientnet-pytorch\/efficientnet-b5-586e6cc6.pth',\n        \n    }\nmodel_save_path = False\n\n\nclass enetv2(nn.Module):\n    def __init__(self, backbone, out_dim=1):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.sigmoid = nn.Sigmoid()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        #x = self.sigmoid(x)\n        return x","77a6414c":"transforms_train = A.Compose([\n    A.Transpose(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightness(limit=0.2, p=0.75),\n    A.RandomContrast(limit=0.2, p=0.75),\n    A.OneOf([\n        A.MotionBlur(blur_limit=5),\n        A.MedianBlur(blur_limit=5),\n        A.GaussianBlur(blur_limit=5),\n        A.GaussNoise(var_limit=(5.0, 30.0)),\n    ], p=0.7),\n    A.Resize(image_size, image_size),\n    A.Cutout(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.7),\n    #A.Normalize()\n])\n\ntransforms_val = A.Compose([\n    A.Resize(image_size, image_size),\n    #A.Normalize()\n])","0e5fe2b8":"class MelanomaDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True, transforms = None):\n\n        self.df = df\n        self.imfolder = imfolder\n        self.transforms = transforms\n        self.train = train\n        \n    def __getitem__(self, index):\n        if self.train:\n            im_path = os.path.join(self.imfolder, self.df.iloc[index]['image_id'] + '.jpg')\n        else:\n            im_path = os.path.join(self.imfolder, self.df.iloc[index]['image_name'] + '.jpg')\n\n        x = cv2.imread(im_path)\n\n        if self.transforms:\n            x = self.transforms(image = x) #albumentations\u306b\u753b\u50cf\u3092\u6295\u3052\u307e\u3059\n            x = x['image'].astype(np.float32) #\u5e30\u3063\u3066\u304d\u305f\u30c7\u30fc\u30bf\u304b\u3089\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u53d6\u308a\u51fa\u3057\u307e\u3059(SSD\u306e\u3088\u3046\u306a\u5834\u5408\u306b\u306f\u77e9\u5f62\u9818\u57df\u30c7\u30fc\u30bf\u3082\u5408\u308f\u305b\u3066\u5e30\u3063\u3066\u304d\u305f\u308a\u3059\u308b\u305f\u3081\u3001\u3053\u306e\u3088\u3046\u306a\u4ed5\u69d8\u306b\u306a\u3063\u3066\u3044\u307e\u3059)\n            \n        x = x.transpose(2, 0, 1) #channel first\n        \n        if self.train:\n            y = self.df.iloc[index]['target']\n            return x, y\n        else:\n            return x\n    \n    def __len__(self):\n        return len(self.df)","776a8f8e":"dataset_show = MelanomaDataset(train_df, train_images, train=True,transforms = transforms_train)\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20,10\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_show))\n        img, label = dataset_show[idx]\n        img = np.asarray(img)\n        img = img.transpose(1,2,0)\n        img = img.astype(np.uint8)\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #rgb\u2192bgr\n        axarr[p].imshow(img) \n        axarr[p].set_title(str(label))","35fd2510":"def train(model, iterator, optimizer, criterion, device):\n    \n    epoch_loss = 0\n    model.train()\n    \n    #\u30d7\u30ed\u30b0\u30ec\u30b9\u30d0\u30fc\u3092\u8868\u793a\u3059\u308b\u304b\u5426\u304b\n    bar = tqdm(iterator) if Progress_Bar else iterator\n    \n    for (x, y) in bar:\n        x = torch.tensor(x, device=device, dtype=torch.float32)\n        y = torch.tensor(y, device=device, dtype=torch.float32)\n        \n        optimizer.zero_grad()\n        y_pred = model(x)\n        loss = criterion(y_pred, y.unsqueeze(1)) #\u3053\u3053\u3067\u3001y\u306by.unsqueeze()\u6b21\u5143\u62e1\u5f35\u3092\u631f\u3080\u5fc5\u8981\u304c\u3042\u308b\uff1f(BCE\u3060\u3063\u305f\u3089\u3001\u3060\u3068\u601d\u308f\u308c\u308b)\n        loss.backward()\n        optimizer.step()\n        loss_np = loss.detach().cpu().numpy()\n        epoch_loss += loss_np\n        \n        if Progress_Bar:\n            bar.set_description('Training loss: %.5f' % (loss_np))\n        \n    return epoch_loss\/len(iterator)","7fb45368":"def evaluate(model, iterator, criterion, device):\n    \n    epoch_loss = 0\n    preds = np.array([])\n    targets = np.array([])\n    model.eval()\n    \n    bar = tqdm(iterator) if Progress_Bar else iterator\n    \n    with torch.no_grad(): #validation\u6642\u306b\u306f\u5b66\u7fd2\u3092\u884c\u3044\u307e\u305b\u3093\n        \n        for (x, y) in bar:\n        \n            x = torch.tensor(x, device=device, dtype=torch.float32)\n            y = torch.tensor(y, device=device, dtype=torch.float32)\n            \n            y_pred = model(x)\n            loss = criterion(y_pred, y.unsqueeze(1))\n            loss_np = loss.detach().cpu().numpy()\n            epoch_loss += loss_np\n            y_pred = torch.sigmoid(y_pred)\n            preds = np.append(preds, y_pred.detach().cpu().numpy())\n            targets = np.append(targets, y.detach().cpu().numpy())\n            \n            if Progress_Bar:\n                bar.set_description('Validation loss: %.5f' % (loss_np))\n    \n    val_acc = accuracy_score(targets, np.round(preds))\n    \n    try:\n       val_roc = roc_auc_score(targets, preds)\n    except ValueError:\n       val_roc = -1\n    \n            \n    return epoch_loss\/len(iterator), val_acc,val_roc","c6b04456":"def fit_model(model, model_name, train_iterator, valid_iterator, optimizer, loss_criterion, device, epochs):\n    \"\"\" Fits a dataset to model\"\"\"\n    best_valid_score = float('inf')\n    \n    train_losses = []\n    valid_losses = []\n    valid_roc_scores = []\n    \n    for epoch in range(epochs):\n        scheduler.step(epoch)\n        start_time = time.time()\n    \n        train_loss = train(model, train_iterator, optimizer, loss_criterion, device)\n        valid_loss, valid_acc_score, valid_roc_score = evaluate(model, valid_iterator, loss_criterion, device)\n        \n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        valid_roc_scores.append(valid_roc_score)\n\n        if valid_roc_score < best_valid_score:\n            best_valid_score = valid_roc_score\n            if model_save_path:\n                torch.save(model.state_dict(), os.path.join(model_save_path,f'{model_name}.pt'))\n            else:\n                torch.save(model.state_dict(), f'{model_name}_best.pt')\n        \n        #scheduler\u306e\u51e6\u7406 cosineannealing\u306f\u5225\n        #if scheduler != None:\n        #    scheduler.step(valid_loss)\n        end_time = time.time()\n\n        epoch_mins, epoch_secs = (end_time-start_time)\/\/60,round((end_time-start_time)%60)\n    \n        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n        print(f'Train Loss: {train_loss:.3f}')\n        print(f'Val. Loss: {valid_loss:.3f} | Val. ACC Score: {valid_acc_score:.3f} | Val. Metric Score: {valid_roc_score:.4f}')\n        print(f'lr:{optimizer.param_groups[0][\"lr\"]:.7f}')\n        \n        torch.save(model.state_dict(), f'{model_name}_final.pt')\n        #pickle\n        with open(f'{model_name}_final.pickle', mode = \"wb\") as fp:\n            pickle.dump(model,fp)\n        \n    return train_losses, valid_losses, valid_roc_scores","28a5096e":"tr_loss=[]\nval_loss=[]\nval_roc=[]\nmodels = []\nfor fold in range(1):\n    print(f\"Fitting on Fold {fold+1}\")\n    #Make Train and Valid DataFrame from fold\n    train_df_fold = train_df[train_df['fold'] != fold].reset_index(drop=True)\n    valid_df_fold = train_df[train_df['fold'] == fold].reset_index(drop=True)\n    \n    #Build and load Dataset\n    train_data = MelanomaDataset(train_df_fold, train_images, train=True, transforms = transforms_train) \n    valid_data = MelanomaDataset(valid_df_fold, train_images, train=True, transforms = transforms_val) \n    \n    train_iterator = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n    valid_iterator = DataLoader(valid_data, shuffle=False, batch_size=16, num_workers=num_workers)\n    \n    #\u30e2\u30c7\u30eb\u306e\u547c\u3073\u51fa\u3057(\u8a2d\u8a08\u56f3\u304b\u3089\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3078)\n    model = enetv2(enet_type, out_dim=1).to(device) #to(device)\uff1agpu\u3067\u8a08\u7b97\u3092\u884c\u3046\u3053\u3068\u3092\u5ba3\u8a00\n    \n    #\u640d\u5931\u95a2\u6570\u306e\u5b9a\u7fa9(BCE\u306fBinary Cross Entropy\u306e\u7565\u3067\u3001\u901a\u5e38\u306eCross Entropy Loss\u3092\u3061\u3087\u3063\u3068\u5de5\u592b\u3057\u305f\u3082\u306e\u3067\u3059)\n    loss_criterion = nn.BCEWithLogitsLoss()\n    \n    #\u6700\u9069\u5316\u624b\u6cd5\u306e\u5b9a\u7fa9(\u73fe\u5728\u3067\u306fAdam1\u5f37\u3067\u3059)\n    opt= optim.Adam(model.parameters(), lr=init_lr)\n    \n    #\u5b66\u7fd2\u7387\u3092\u5f90\u3005\u306b\u4e0b\u3052\u3066\u3044\u304f\u305f\u3081\u306e\u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u30fc\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002\n    scheduler = CosineAnnealingLR(opt, n_epochs)\n    \n    name = model_name + \"_\" + enet_type + \"_f\" + str(fold)\n    \n    #\u5168\u3066\u306e\u60c5\u5831\u3092fit_model\u306b\u5165\u308c\u3066\u3001\u5b66\u7fd2\u3092\u958b\u59cb\u3057\u307e\u3059\n    temp_tr_loss, temp_val_loss, temp_val_roc = fit_model(model, name, train_iterator, valid_iterator, opt, loss_criterion, device, epochs=n_epochs)\n    \n    #loss\u3068\u8a55\u4fa1\u6307\u6a19\u306b\u5bfe\u3059\u308b\u30b9\u30b3\u30a2\u3092\u8a18\u9332\u3057\u307e\u3059\n    tr_loss.append(temp_tr_loss)\n    val_loss.append(temp_val_loss)\n    val_roc.append(temp_val_roc)\n    \n    #fold\u3054\u3068\u306b\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3059\u308b\u70ba\u3001\u5b66\u7fd2\u3057\u7d42\u308f\u3063\u305f\u30e2\u30c7\u30eb\u306f\u30ea\u30b9\u30c8\u306b\u4fdd\u6301\u3057\u3066\u304a\u304d\u307e\u3059\n    models.append(model)","7b81be44":"for i in range(len(tr_loss)):\n    fig,ax = plt.subplots(nrows=1, ncols=2, figsize=(20,5))\n    ax[0].plot(tr_loss[i])\n    ax[0].set_title('Training and Validation Loss')\n    ax[0].plot(val_loss[i])\n    ax[0].set_xlabel('Epoch')\n\n    ax[1].plot(val_roc[i])\n    ax[1].set_title('Val ROC Score')\n    ax[1].set_xlabel('Epoch')\n\n\n    ax[0].legend();\n    ax[1].legend();","ccd76824":"test = MelanomaDataset(df=test_df,\n                       imfolder=test_images, \n                       train=False,\n                       transforms=transforms_train)","7f6d99a6":"#(model\u6570*TTA\u6570)\u56de\u3059\u306e\u3067\u6ce8\u610f\ndef get_predictions(model, iterator, device):\n    \n    preds = np.array([0.]*len(test_df))\n    model.eval()\n    bar = tqdm(iterator) if Progress_Bar else iterator\n    \n    with torch.no_grad():\n        for tta in range(TTA):\n            res = np.array([])\n            for x in bar:\n                x = torch.tensor(x, device=device, dtype=torch.float32)\n                y_pred = model(x)\n                y_pred = torch.sigmoid(y_pred)\n                res = np.append(res, y_pred.detach().cpu().numpy())\n            preds += res\n    preds \/= TTA\n    return preds","76b430d7":"prediction = np.array([0.]*len(test_df))\nfor i in range(len(models)):\n    test_iterator = DataLoader(dataset=test, batch_size=16, shuffle=False, num_workers=num_workers)\n    preds = get_predictions(models[i], test_iterator, device)\n    prediction += preds\nprediction \/= len(models)","33ff789c":"sub_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\nsub_df = sub_df[:50] if DEBUG else sub_df\nsub_df['target'] = prediction\n\nsub_df.to_csv('submission.csv', index=False) #index\u3092false\u306b\u3057\u306a\u3044\u3068\u3001\u5148\u982d\u5217\u306bindex\u60c5\u5831\u304c\u4ed8\u52a0\u3055\u308c\u305fcsv\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u306e\u3067\u6ce8\u610f\nsub_df.head()","3d4258d8":"# csv\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f  \n","6d349ebb":"# \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d","ab350132":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u3092\u884c\u3044\u3001\u63d0\u51fa\u3057\u307e\u3059  ","8adf6819":"# device\u306e\u6307\u5b9a  \npytorch\u3067\u306fgpu\u3092\u4f7f\u7528\u3057\u305f\u3044\u5834\u5408\u306b\u306fdevice\u3092\u6307\u5b9a\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002  \ngpu\u3067\u8a08\u7b97\u3092\u884c\u3046\u30d7\u30ed\u30bb\u30b9\u306b\u306f.to(device)\u95a2\u6570\u3092\u7528\u3044\u308b\u3053\u3068\u306b\u3088\u3063\u3066gpu\u306b\u8a08\u7b97\u3092\u56de\u3057\u307e\u3059\u3002  ","5b32eae8":"# \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8a2d\u5b9a  \n\u5909\u6570\u306b\u5fc5\u8981\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u683c\u7d0d\u3057\u3066\u304a\u304f\u3053\u3068\u306b\u3088\u308a\u3001\u3088\u308a\u52b9\u7387\u7684\u306b\u691c\u8a3c\u3092\u9032\u3081\u308b\u3053\u3068\u304c\u51fa\u6765\u307e\u3059\u3002  ","85f0d865":"# \u518d\u73fe\u6027\u306e\u62c5\u4fdd\n\u30e9\u30f3\u30c0\u30e0\u306a\u5024\u3092\u56fa\u5b9a\u3057\u3066\u304a\u304f\u3053\u3068\u3067\u30012\u56de\u540c\u3058\u30b3\u30fc\u30c9\u3092\u56de\u3057\u305f\u3068\u304d\u306b\u5168\u304f\u540c\u3058\u7d50\u679c\u304c\u5f97\u3089\u308c\u308b\u3088\u3046\u306b\u3057\u307e\u3059\u3002  \n\u3053\u308c\u3092\u30b7\u30fc\u30c9\u5024\u306e\u56fa\u5b9a\u3068\u3044\u3044\u307e\u3059  "}}