{"cell_type":{"64bcc291":"code","23588684":"code","2c46f24b":"code","88172e2f":"code","bf98c4f7":"code","cee79f03":"code","94bbecd5":"code","8931d2e5":"code","54aaa95f":"code","9568657a":"code","e365c2c1":"code","d9e6d846":"code","892bfce8":"code","e749bcdd":"code","d9b52841":"code","851d9aaa":"code","9ca29e0d":"code","e3956c1d":"code","c95ee185":"code","0c7794a4":"code","838d5b43":"code","25361b15":"code","c7eff429":"code","076c2350":"code","09c55552":"code","4dd0556b":"code","c4d6ca2f":"code","c0bdacac":"markdown","cd2014cc":"markdown","2ba47d48":"markdown","0ee854d5":"markdown","00a6f1f0":"markdown","2499319c":"markdown","ae76fb5a":"markdown","ba88d4bd":"markdown","59c7cb7d":"markdown","3493965b":"markdown","15a86918":"markdown","9f208052":"markdown","2923f2d1":"markdown","f3ffe9ba":"markdown","c01a9599":"markdown","e398201c":"markdown","559ff908":"markdown","ae3ed752":"markdown","067d34c0":"markdown","aeba04a0":"markdown","cb3b5423":"markdown","11d0c2e4":"markdown","6432d72c":"markdown","15ec524b":"markdown","719bb34e":"markdown","e9ba2cbc":"markdown","8bcd7319":"markdown","44f42b1f":"markdown","2f428a82":"markdown","5d9c3a4b":"markdown"},"source":{"64bcc291":"import pandas as pd\nimport numpy as np\nimport category_encoders as ce \nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline","23588684":"dftrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndftest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndftrain['Pclass'] = dftrain['Pclass'].replace({1:'Upper',2:'Middle',3:'Lower'})\ndftest['Pclass'] = dftest['Pclass'].replace({1:'Upper',2:'Middle',3:'Lower'})\ndftrain['Honorifics'] = dftrain['Name'].apply(lambda x: x.split(',')[1].split(' ')[1])\ndftest['Honorifics'] = dftest['Name'].apply(lambda x: x.split(',')[1].split(' ')[1])\ntrain = dftrain[['Sex','Pclass','Embarked','Honorifics']]\ntrain2 = dftrain[['Sex','Pclass','Embarked','Honorifics','Survived']]\ntest = dftest[['Sex','Pclass','Embarked','Honorifics']]\ntrain.head()","2c46f24b":"train.isnull().sum()","88172e2f":"print('Unique values for variable sex: ',train['Sex'].unique())\nprint('Unique values for variable Pclass: ',train['Pclass'].unique())\nprint('Unique values for variable Embarked: ',train['Embarked'].unique())\nprint('Unique values for variable Honorifics: ',train['Honorifics'].unique())","bf98c4f7":"ce_ord = ce.OrdinalEncoder(\n                           cols=['Pclass'],\n                           mapping=[{'col': 'Pclass', 'mapping': {'Lower': 1, 'Middle': 2,'Upper':3}}],\n                           handle_unknown='value',\n                           handle_missing='value'\n                           )","cee79f03":"ce_ord.fit_transform(train).head()","94bbecd5":"ce_ord.transform(test).head()","8931d2e5":"ce_nom = ce.OneHotEncoder(cols=['Sex'],handle_missing='value')","54aaa95f":"ce_nom.fit_transform(train).head()","9568657a":"ce_nom.fit_transform(test).head()","e365c2c1":"filter_nan = train['Embarked'].isnull()\ntrain_nan = train[filter_nan]\ntrain_nan = train_nan.append(train.iloc[3:5])\ntrain_nan","d9e6d846":"ce_nom2 = ce.OneHotEncoder(cols=['Embarked'],handle_missing='return_nan')\nce_nom2.fit_transform(train_nan).head()","892bfce8":"ce_nom2 = ce.OneHotEncoder(cols=['Embarked'],handle_missing='value')\nce_nom2.fit_transform(train_nan).head()","e749bcdd":"ce_nom2 = ce.OneHotEncoder(cols=['Embarked'],handle_missing='indicator')\nce_nom2.fit_transform(train_nan).head()","d9b52841":"train['Honorifics'].value_counts()","851d9aaa":"freq_map = (train['Honorifics'].value_counts()\/len(train)).to_dict()\nprint(freq_map)","9ca29e0d":"train_freq = train.copy()\ntrain_freq['Honorifics'] = train_freq['Honorifics'].map(freq_map)\ntrain_freq.head()","e3956c1d":"train['Honorifics'].value_counts() \/ len(train)","c95ee185":"train_honorifics = train.copy()\ntrain_honorifics['Honorifics'] = train_honorifics['Honorifics'].replace({'Dr.':'Rare','Rev.':'Rare',\n                             'Mlle.':'Rare','Col.':'Rare',\n                             'Major.': 'Rare','Don.':'Rare',\n                             'Ms.':'Rare','Jonkheer.':'Rare',\n                             'Capt.':'Rare','Sir.':'Rare',\n                             'Lady.':'Rare','the':'Rare','Mme.':'Rare'})\nprint(train_honorifics['Honorifics'].value_counts(dropna=False) \/ len(train_honorifics))","0c7794a4":"target_map = train2.groupby(['Honorifics'])['Survived'].mean().to_dict()\ntarget_map","838d5b43":"train2['Honorifics'].map(target_map)","25361b15":"print(train.columns)\nnominal_features = ['Sex','Embarked','Honorifics']\nordinal_features = ['Pclass']","c7eff429":"def get_ct(ordinal_features, nominal_features):\n\n    # Create ordinal encoder\n    ce_ord = ce.OrdinalEncoder(\n                               cols=ordinal_features,\n                               mapping=[{'col': 'Pclass', 'mapping': {'Lower': 1, 'Middle': 2,'Upper':3}}],\n                               handle_unknown='value',\n                               handle_missing='value'\n                               )\n    # Create nominal encoder\n    ce_nom = ce.OneHotEncoder(cols=nominal_features,handle_unknown='value',handle_missing='value')\n    \n    # Create a column transformer to combine both ordinal and nominal encoders \n    ct1 = ColumnTransformer(\n            transformers=[\n                ('cat_ordinal',ce_ord,ordinal_features),\n                ('cat_nominal',ce_nom,nominal_features),\n                ],remainder = 'drop')\n    clf = Pipeline(steps=[('preprocessor', ct1)])\n    return clf ","076c2350":"clf_cat = get_ct(ordinal_features, nominal_features)","09c55552":"clf_cat.fit(train)","4dd0556b":"train_data = clf_cat.transform(train)\nprint(train_data.shape)\nprint(train_data)","c4d6ca2f":"test_data = clf_cat.transform(test)\nprint(test_data.shape)\nprint(test_data)","c0bdacac":"<a id=\"section-four\"><\/a>\n# Target mean encoding (supervised)","cd2014cc":"Next we fit clf_cat to training dataset, and apply it to transform\nboth training and test dataset","2ba47d48":"<a id=\"subsection-four\"><\/a>\n## Rare Category","0ee854d5":"<a id=\"subsection-two\"><\/a>\n## One-hot Encoding\nOne hot encoding is applied when your categorical variable does not embed order information, e.g. sex \nor Embarked. Depending on the number unique values the feature has, same number of columns will be added.\nA sample will have 1 for the specific value it has for that feature, the rest values in that column will be 0.\nLet's first look at feature \"Sex\" since it does not have missing values. We construct \none hot encoder first using OneHotEncoder function.","00a6f1f0":"Let's separate our features into ordinal categorical features and nominal categorical features[](http:\/\/), then we\nbuild a pipeline using Scikit and category_encoders.","2499319c":"Thanks for going through this notebook. If you find it helpful, please upvote it and I really appreciate your support! Cheers!","ae76fb5a":"Let's check missing values. We see that we have 2 missing values for feature \"Embarked\".","ba88d4bd":"Similary, we fit it onto training dataset. You can see sex column is replaced by two columns \"Sex_1\" and \"Sex_2\".\nSex_1 is for \"male\" category and Sex_2 is for \"female\" category. When the data has male sex, Sex_1 will be 1 and\nSex_2 will be 0, as you can see row 0 as an example. ","59c7cb7d":"For target mean encoding, we are going to replace categories with their mean target\nvalues. Let's see an example, we use feature \"Honorifics\" for demonstration. We need\nto group data based on Honorifics, then calculate target mean within each group.","3493965b":"You can see that \"Rare\" category has a frequency of 3% after transformation.","15a86918":"Now we can fit and transform our data. You can see pclass has been mapped into numerical values based on\nthe mapping we defined in OrdinalEncoder.","9f208052":"Now, feature \"Embarked\" has two missing values, hanle_missing in OneHotEncoder can be\nset to \"error\", \"return_nan\", \"value\" and \"indicator\". When it is set to error, OneHotEncoder\nwill return error when it encounters missing values. Let's explore \"return_nan\", \"value\" and \"Indicator\". Let's first\nlocate rows with missing values for feature \"Embarked\". I am going to create\na small dataframe with two Null values, and two non-Null values.","2923f2d1":"When handle_missing = \"indicator\", an indicator column will be added. When the data has missing value, the indicator \nwill return true and assign value 1 to that indicator column. In this case, it gives\nthe same results as handle_missing=\"value\".","f3ffe9ba":"<a id=\"section-one\"><\/a>\n# Introduction\n\nIn this notebook, we are going to explore most commonly used categorical encoding strategies using\ntitanic dataset. I am going to demonstrate the use of category_encoders, which is a very useful library for catgorical\nencoding and can be directly used with Sklearn. So you can build your entire pipeline and have a consistent\nstrategy for categorical variable encoding. Handling of missing values will also be demonstrated.","c01a9599":"<a id=\"section-three\"><\/a>\n# Fundamental Encoding","e398201c":"When handle_missing = \"return_nan\", Embarked column is replaced by two columns Embarked_1 and Embarked_2.\nEmbarked_2 is for value S and Embarked_1 is for value NaN. In this case, for missing data row 61 and 829,\nboth Embarked_1 and Embarked_2 columns are being assigned to NaN.","559ff908":"<a id=\"subsection-one\"><\/a>\n## Ordianal Encoding\nOrdinal encoding is applied when categorical variable embeds ordering information. For example, in titanic\ndataset, pclass is a proxy for socio-economic status, i.e. lower, middle, upper class. We are going \nto map lower to 1, middel to 2 and upper to 3, and we will do this using category_encoders. Let's construct\nordinal encoder using function \"OrdinalEncoder\". We will be talking about how missing value is handled later on \nsince pclass feature does not have missing values. Note: we need to specify the columns to cols variable. Mapping\nwill be applied only to the columns specified in cols.","ae3ed752":"When handle_missing = \"value\", NaN is being treated as an unique category, as you can see\nfor missing row 61 and 829, Embarked_1 is being assigned to 1; whereas for row\n3 and 4, Embarked_2 is being assigned to 1.","067d34c0":"* [Introduction](#section-one)\n* [Examine Data](#section-two)\n* [Fundamental Encoding](#section-three)\n    - [Ordinal Encoding](#subsection-one)\n    - [One-hot encoding](#subsection-two)\n    - [Encoding with frequency](#subsection-three)\n    - [Rare Category](#subsection-four)\n* [Target Mean Encoding (Supervised)](#section-four)\n* [Scikit-learn Pipeline with category_encoders](#section-five)","aeba04a0":"<a id=\"subsection-three\"><\/a>\n## Encoding with frequency","cb3b5423":"Next, we apply ce_ord to our test dataset as well. **Note: ce_ord is fitted onto train dataset\nonly!**","11d0c2e4":"Similarly, one the encoder is fitted, we can transform test set as well","6432d72c":"Let's apply this map, you can see categories in \"Honorifics\" column are being replaced with their frequency\nvalues.","15ec524b":"Let's check unique categories for each feature.","719bb34e":"Now we apply target_map to \"Honorfics\" feature","e9ba2cbc":"We can see for \"Honorifics\" feature, lots of categories have frequencies below 1%, we can group \nthese categories into a single group and call it \"Rare\"","8bcd7319":"<a id=\"section-five\"><\/a>\n# Scikit-learn Pipeline with category_encoders","44f42b1f":"<a id=\"section-two\"><\/a>\n# Examine Data","2f428a82":"We can also encode categorical variables with their frequencies. I will demonstrate using \nfeature \"Honorifics\"","5d9c3a4b":"Now, let's create a map that maps each value to its frequency."}}