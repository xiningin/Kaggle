{"cell_type":{"a02f7cec":"code","c697e760":"code","6518d8ef":"code","756fd2c0":"code","9dc8fbe5":"code","68490955":"code","48465472":"code","49cd7b68":"code","b599b522":"code","9a257ed4":"code","5b21dd50":"code","71fd0079":"code","31021b65":"code","e96173f1":"code","9e07bbb9":"code","10d49726":"code","1a9e65da":"code","c2d63a82":"markdown","b3f6dc18":"markdown","09b56c52":"markdown","96dadd34":"markdown","655b6c48":"markdown","5c47ced2":"markdown","1fa80bd2":"markdown","a8ef090f":"markdown","db6bda9e":"markdown","90781a0b":"markdown","f8fa0e0d":"markdown","96c815ca":"markdown","92523805":"markdown","e1c98ab0":"markdown","7a5d237e":"markdown","2935c830":"markdown","7bbff4db":"markdown","cae0ae07":"markdown"},"source":{"a02f7cec":"import os\nimport pathlib\n\nif \"models\" in pathlib.Path.cwd().parts:\n    while \"models\" in pathlib.Path.cwd().parts:\n        os.chdir('..')\nelif not pathlib.Path('models').exists():\n    !git clone --depth 1 https:\/\/github.com\/tensorflow\/models","c697e760":"!pip install pycocotools","6518d8ef":"%%bash\n# Install the Object Detection API\ncd models\/research\/\nprotoc object_detection\/protos\/*.proto --python_out=.\ncp object_detection\/packages\/tf2\/setup.py .\npython -m pip install .","756fd2c0":"if \"tensorflow-object-detection\" in pathlib.Path.cwd().parts:\n    while \"tensorflow-object-detection\" in pathlib.Path.cwd().parts:\n        os.chdir('..')\nelif not pathlib.Path('tensorflow-object-detection').exists():\n    !git clone --depth 1 https:\/\/github.com\/tarun-bisht\/tensorflow-object-detection.git\npre_cwd=os.getcwd()\nos.chdir(\"tensorflow-object-detection\")","9dc8fbe5":"pretrained_model_url=\"http:\/\/download.tensorflow.org\/models\/object_detection\/tf2\/20200711\/efficientdet_d0_coco17_tpu-32.tar.gz\"\npretrained_model_name=\"efficientdet_d0_coco17_tpu-32\"","68490955":"# pretrained_model_file=f\"{pretrained_model_name}.tar.gz\"\nmodel_dir=f\"..\/{pretrained_model_name}-theft\"\npipeline_config_path=f\"..\/pipeline.config\"\noutput_directory= f\"..\/{pretrained_model_name}-theft-inf\"","48465472":"num_steps=1000\nnum_eval_steps=400\nnum_classes=3\nbatch_size=16","49cd7b68":"mode=\"detection\"\ntrain_path=\"..\/..\/input\/yolo-animal-detection-small\/train.record\"\ntest_path=\"..\/..\/input\/yolo-animal-detection-small\/test.record\"\ncheckpoint_path=f\"data\/models\/{pretrained_model_name}\/checkpoint\/ckpt-0\"\nlabel_path=\"data\/labels\/theft.pbtxt\"","b599b522":"# Download a pretrained model from tensorflow model zoo\n!wget {pretrained_model_url}\n!tar -xf {pretrained_model_name}.tar.gz\n!rm {pretrained_model_name}.tar.gz\n!mv {pretrained_model_name} data\/models","9a257ed4":"pipeline_file = '''# SSD with EfficientNet-b0 + BiFPN feature extractor,\n# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n# See EfficientDet, Tan et al, https:\/\/arxiv.org\/abs\/1911.09070\n# See Lin et al, https:\/\/arxiv.org\/abs\/1708.02002\n# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n#\n# Train on TPU-8\n\nmodel {\n  ssd {\n    inplace_batchnorm_update: true\n    freeze_batchnorm: false\n    num_classes: %d\n    add_background_class: false\n    box_coder {\n      faster_rcnn_box_coder {\n        y_scale: 10.0\n        x_scale: 10.0\n        height_scale: 5.0\n        width_scale: 5.0\n      }\n    }\n    matcher {\n      argmax_matcher {\n        matched_threshold: 0.5\n        unmatched_threshold: 0.5\n        ignore_thresholds: false\n        negatives_lower_than_unmatched: true\n        force_match_for_each_row: true\n        use_matmul_gather: true\n      }\n    }\n    similarity_calculator {\n      iou_similarity {\n      }\n    }\n    encode_background_as_zeros: true\n    anchor_generator {\n      multiscale_anchor_generator {\n        min_level: 3\n        max_level: 7\n        anchor_scale: 4.0\n        aspect_ratios: [1.0, 2.0, 0.5]\n        scales_per_octave: 3\n      }\n    }\n    image_resizer {\n      keep_aspect_ratio_resizer {\n        min_dimension: 512\n        max_dimension: 512\n        pad_to_max_dimension: true\n        }\n    }\n    box_predictor {\n      weight_shared_convolutional_box_predictor {\n        depth: 64\n        class_prediction_bias_init: -4.6\n        conv_hyperparams {\n          force_use_bias: true\n          activation: SWISH\n          regularizer {\n            l2_regularizer {\n              weight: 0.00004\n            }\n          }\n          initializer {\n            random_normal_initializer {\n              stddev: 0.01\n              mean: 0.0\n            }\n          }\n          batch_norm {\n            scale: true\n            decay: 0.99\n            epsilon: 0.001\n          }\n        }\n        num_layers_before_predictor: 3\n        kernel_size: 3\n        use_depthwise: true\n      }\n    }\n    feature_extractor {\n      type: 'ssd_efficientnet-b0_bifpn_keras'\n      bifpn {\n        min_level: 3\n        max_level: 7\n        num_iterations: 3\n        num_filters: 64\n      }\n      conv_hyperparams {\n        force_use_bias: true\n        activation: SWISH\n        regularizer {\n          l2_regularizer {\n            weight: 0.00004\n          }\n        }\n        initializer {\n          truncated_normal_initializer {\n            stddev: 0.03\n            mean: 0.0\n          }\n        }\n        batch_norm {\n          scale: true,\n          decay: 0.99,\n          epsilon: 0.001,\n        }\n      }\n    }\n    loss {\n      classification_loss {\n        weighted_sigmoid_focal {\n          alpha: 0.25\n          gamma: 1.5\n        }\n      }\n      localization_loss {\n        weighted_smooth_l1 {\n        }\n      }\n      classification_weight: 1.0\n      localization_weight: 1.0\n    }\n    normalize_loss_by_num_matches: true\n    normalize_loc_loss_by_codesize: true\n    post_processing {\n      batch_non_max_suppression {\n        score_threshold: 1e-8\n        iou_threshold: 0.5\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SIGMOID\n    }\n  }\n}\n\ntrain_config: {\n  fine_tune_checkpoint: \\\"%s\\\"\n  fine_tune_checkpoint_version: V2\n  fine_tune_checkpoint_type: \\\"%s\\\"\n  batch_size: %d\n  sync_replicas: true\n  startup_delay_steps: 0\n  replicas_to_aggregate: 8\n  use_bfloat16: true\n  num_steps: %d\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n  data_augmentation_options {\n    random_scale_crop_and_pad_to_square {\n      output_size: 512\n      scale_min: 0.1\n      scale_max: 2.0\n    }\n  }\n  optimizer {\n    momentum_optimizer: {\n      learning_rate: {\n        cosine_decay_learning_rate {\n          learning_rate_base: 8e-2\n          total_steps: 30000\n          warmup_learning_rate: .001\n          warmup_steps: 2500\n        }\n      }\n      momentum_optimizer_value: 0.9\n    }\n    use_moving_average: false\n  }\n  max_number_of_boxes: 100\n  unpad_groundtruth_tensors: false\n}\n\ntrain_input_reader: {\n  label_map_path: \\\"%s\\\"\n  tf_record_input_reader {\n    input_path: \\\"%s\\\"\n  }\n}\n\neval_config: {\n  metrics_set: \"coco_detection_metrics\"\n  use_moving_averages: false\n  batch_size: 1;\n}\n\neval_input_reader: {\n  label_map_path: \\\"%s\\\"\n  shuffle: false\n  num_epochs: 1\n  tf_record_input_reader {\n    input_path: \\\"%s\\\"\n  }\n}''' % (num_classes, checkpoint_path, mode, batch_size, num_steps, label_path, train_path,label_path,test_path)\n\nwith open(\"..\/pipeline.config\",'w') as pipe:\n    pipe.write(pipeline_file)","5b21dd50":"print(\"Size of train record file: \",str(os.path.getsize(train_path)\/1e+6)+\" MB\")\nprint(\"Size of test record file: \",str(os.path.getsize(test_path)\/1e+6)+\" MB\")","71fd0079":"!python train.py \\\n    --pipeline_config_path={pipeline_config_path} \\\n    --model_dir={model_dir} \\\n    --alsologtostderr \\\n    --num_train_steps={num_steps} \\\n    --sample_1_of_n_eval_examples=1 \\\n    --num_eval_steps={num_eval_steps}","31021b65":"!python train.py \\\n    --eval_timeout 10 \\\n    --pipeline_config_path={pipeline_config_path} \\\n    --model_dir={model_dir} \\\n    --checkpoint_dir={model_dir} \\","e96173f1":"!python export_model.py \\\n    --input_type image_tensor \\\n    --pipeline_config_path {pipeline_config_path} \\\n    --trained_checkpoint_dir {model_dir} \\\n    --output_directory {output_directory}\n!zip ..\/{pretrained_model_name}-theft-inf.zip -r {output_directory}\n!rm -rf {output_directory}","9e07bbb9":"!mv {pipeline_config_path} {model_dir}\n!zip ..\/{pretrained_model_name}-theft-ckpt.zip -r {model_dir}\n!rm -rf {model_dir}","10d49726":"os.chdir(pre_cwd)","1a9e65da":"%%bash\nrm -rf models\nrm -rf tensorflow-object-detection","c2d63a82":"### Model to Inference graph","b3f6dc18":"setting up model output directories and other paths which we will use later\n\n- model_dir: path to save model chekpoints while training\n- pipeline_config_path: path to config file of model it will be inside that model folder which we downloaded. we have to make changes to that file later before training.\n- output_directory: path where we will export out models inference graph\n","09b56c52":"## Cloning starter scripts for object detection api from my github\n","96dadd34":"### Lets Train !!! \n\n- model_dir : folder to place training checkpoints\n- pipeline_config_path : path to pipeline.config of model\n- num_train_steps : number of epochs to train","655b6c48":"### Zipping final models for output","5c47ced2":"## Edit the downloaded model pipeline.config file before starting forward.\n\nTo edit first visit [object detection api repo](https:\/\/github.com\/tensorflow\/models\/tree\/master\/research\/object_detection\/configs\/tf2) and paste contents from file of your desired model in the cell below. Instead of editing paste `\\\"%s\\\"` if desired parameter is string and `%d` if desired parameter is a number. We have defined the required parameter above we can use string formatting to do out task\n\n- `num_classes: 3` number of classes to train since we have 3 categories cat, dog and monkey.\n\n\n- under `train_config` edit\n\n    1. `fine_tune_checkpoint: \"data\/models\/efficientdet_d0_coco17_tpu-32\/checkpoint\/ckpt-0\"` path to pretrained checkpoint file\n    \n    2. `fine_tune_checkpoint_type: \"detection\"` \"detection\" mostly two options \"classification\" or \"detection\" but in some models like centernet there is \"fine_tune\" instead of detection. classification will train only classification layers while detection will train whole model.\n    \n    3. `batch_size: 16` batch size to train\n    \n    4. `num_steps: 1` number of steps to train (also known as train epochs)\n    \n    \n- under `train_input_reader` edit\n\n    1. `label_map_path: \"data\/labels\/theft.pbtxt\"` path to labels.pbtxt file\n    \n    2. `input_path: \"..\/..\/input\/yolo-animal-detection-small\/train.record\"` path to train tfrecords file\n    \n    \n- under `eval_input_reader` edit\n\n    1. `label_map_path: \"data\/labels\/theft.pbtxt\"` path to labels.pbtxt file\n    \n    2. `input_path: \"..\/..\/input\/yolo-animal-detection-small\/test.record\"` path to test tfrecords file","1fa80bd2":"## Check file size of our input dataset\n\nSometimes while creating tfrecords file if no image are encountered in specified location or location is wrong tfrecords files are still generated. We can double check the size that it is not 0MB","a8ef090f":"### Model Evaluation\n\nThe same train script is used to eval but checkpoints path where we save trained checkoints is required\n\n- model_dir : folder to place training checkpoints\n- pipeline_config_path : path to pipeline.config of model\n- checkpoint_dir: path to trained checkpoints\n- eval_timeout : minimum wait time to wait for evaluation of next keypoint if exists","db6bda9e":"Get a pretrained model from [tensorflow 2 model zoo](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/g3doc\/tf2_detection_zoo.md). I am using [efficientdet](http:\/\/download.tensorflow.org\/models\/object_detection\/tf2\/20200711\/efficientdet_d0_coco17_tpu-32.tar.gz)","90781a0b":"## Installing pycocotools for evaluation","f8fa0e0d":"## Cloning TensorFlow Object Detection API Repository","96c815ca":"## Setting up parameters","92523805":"# Getting Started with TensorFlow 2 Object Detection API\n\nThis notebook will help to get started with TensorFlow's Object Detection API whch was recently updated for supporting tensorflow 2.0. We can train an object detection classifier for multiple objects on Kaggle Kernels leveraging free GPU's.\n\nIn this notebook we will detect monkey, cat and dogs using this [dataset](https:\/\/www.kaggle.com\/tarunbisht11\/yolo-animal-detection-small)","e1c98ab0":"### Cleaning up output folder to not clutter with main output","7a5d237e":"setting up training hyperparameters make changes based on your need they are more self explanatory","2935c830":"setting up model training utilities these are needed to put in *pipeline.config* file of model\n\n- mode: there are two choices `detection` and `classification`. detection will train the full detection model while classification will train classification layers\n- train_path: path to train.record file\n- test_path: path to test.record file\n- checkpoint_path: path to pretrained checkpoints these are inside the model we downloaded\n- label_path: path to labels.pbtxt check the demo format of that file [here](https:\/\/github.com\/tarun-bisht\/tensorflow-object-detection\/blob\/master\/data\/labels\/theft.pbtxt) ","7bbff4db":"## Installing the Object Detection API","cae0ae07":"## Download a pretrained model to finetune.\n\nVisit [tensorflow 2 model zoo](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/g3doc\/tf2_detection_zoo.md) for other pretrained model. Mine is [efficientdet_d0](http:\/\/download.tensorflow.org\/models\/object_detection\/tf2\/20200711\/efficientdet_d0_coco17_tpu-32.tar.gz)"}}