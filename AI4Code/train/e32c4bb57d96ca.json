{"cell_type":{"fceed16a":"code","f5869806":"code","0167cbf7":"code","fd257b04":"code","1d636b4d":"code","6f45bf0d":"code","650ec1a0":"code","4b4ede9f":"code","86e6f180":"code","e23283de":"code","4566b9e6":"code","6e318893":"code","e0f354e4":"code","98b45473":"code","fbbfdee4":"code","7ee17e65":"code","ddf1f4e6":"code","0ba3897a":"code","f017c4ed":"code","8f2a530e":"code","82eb4dde":"code","98f51473":"code","43e80c70":"code","54e2b487":"code","6518df4b":"code","a8d052e5":"code","a3c93d60":"code","fcf8ffa4":"code","b2f8888b":"code","1592672c":"code","deccf987":"code","e065b066":"code","0c56f6d5":"code","9819dd5d":"code","d23c4ca5":"code","cd46e089":"markdown","b6483179":"markdown","f75e8faa":"markdown","bd271467":"markdown","88c455ff":"markdown","e5a8efb3":"markdown","e951f56e":"markdown","0b334d93":"markdown","25e0aa8b":"markdown","63e7050d":"markdown","71982e74":"markdown","0d06e263":"markdown","ce980dc1":"markdown","97bd74b7":"markdown","9a35ce7c":"markdown"},"source":{"fceed16a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5869806":"import numpy as np \nimport pandas as pd\nimport pandasql as psql\nfrom pandasql import sqldf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objs as go\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing","0167cbf7":"users = pd.read_csv(\"..\/input\/healthresponsescore-datasets\/users_data.csv\")\nsponsor = pd.read_csv(\"..\/input\/healthresponsescore-datasets\/sponsor_data.csv\")\nresponses = pd.read_csv(\"..\/input\/healthresponsescore-datasets\/hra_responses.csv\")\nscores = pd.read_csv(\"..\/input\/healthresponsescore-datasets\/hra_qna_scores.csv\")","fd257b04":"df =  psql.sqldf(\"select * from users\")\ndf.head()","1d636b4d":"spdf =  psql.sqldf(\"select * from sponsor\")\ndf.head()","6f45bf0d":"rsdf =  psql.sqldf(\"select * from responses\")\nresponses.head()","650ec1a0":"scores.head()","4b4ede9f":"responses = psql.sqldf(\"SELECT id, user_id, question_id, response,DATE(created_at) as date from responses;\")\nresponses\n\nusers = psql.sqldf(\"SELECT id,name, sponsor_id,DATE(created_at) as date from users;\")\nusers","86e6f180":"rudf = psql.sqldf(\"SELECT users.name, users.sponsor_id,users.date, responses.id as response_ID,responses.user_id,responses.question_id,responses.response from responses left join users on responses.user_id = users.id;\")\nrudf","e23283de":"rus_df = psql.sqldf(\"SELECT rudf.name, rudf.sponsor_id,rudf.date, rudf.response_ID,rudf.user_id,rudf.question_id,rudf.response,scores.type,scores.title,scores.text,scores.options,scores.score from rudf left join scores on rudf.question_id = scores.question_id;\")\nrus_df","4566b9e6":"sq = psql.sqldf(\"SELECT distinct user_id,question_id,score,response, response_id,name from rus_df;\")\nsq","6e318893":"Questiondf =  psql.sqldf(\"select distinct question_id, text from rus_df order by question_id; \")\nQuestiondf","e0f354e4":"age_height_weight_df = psql.sqldf(\"SELECT user_id,name,SUM(CASE WHEN question_id = 3 THEN response ELSE 0 END) AS Weight,SUM(CASE WHEN question_id = 4 THEN response ELSE 0 END) AS Height FROM rus_df GROUP BY user_id;\")\nage_height_weight_df","98b45473":"gender_df = psql.sqldf(\"SELECT user_id,(CASE WHEN question_id = 1 THEN response ELSE 0 END) AS Gender FROM rus_df WHERE question_id = 1 GROUP BY user_id;\")\ngender_df.info()","fbbfdee4":"ahwg_df = pd.merge(age_height_weight_df, gender_df, on = 'user_id')\nahwg_df.head(n=5)","7ee17e65":"fig = px.treemap(ahwg_df, path=['Gender'], color='Gender')\nfig.update_layout(margin = dict(t=60, l=15, r=15, b=15),\n                  title_text=\"<b>Gender Distribution<\/b>\",\n                  title_x=0.5,\n                  font=dict(family=\"serif\", size=20, color='rgb(5, 14, 48)'))\nfig.show()","ddf1f4e6":"smoke_df_k = psql.sqldf(\"SELECT user_id,(CASE WHEN question_id = 14 THEN response ELSE 0 END) AS 'No_of_Cigarette' FROM rus_df WHERE question_id = 14 GROUP BY user_id;\")\nsmoke_df_count = psql.sqldf(\"select No_of_cigarette, count(No_of_cigarette) as count from smoke_df_k group by No_of_cigarette\")\nsmoke_df_count","0ba3897a":"tmp_smoke = smoke_df_k.No_of_Cigarette.value_counts()\nsmoke_labels = (np.array(tmp_smoke.index))\nsmoke_sizes = (np.array((tmp_smoke \/ tmp_smoke.sum())*100))\n\n\nfig = go.Figure(data=[go.Pie(labels=smoke_labels, values=smoke_sizes, hole=.5)])\nfig.update_layout( title_text=\"Smoke Distribution\",\n    annotations=[dict(text='\ud83d\udeac', x=0.5, y=0.52, font_size=60, showarrow=False)])","f017c4ed":"score_df = psql.sqldf(\"select name, sum(score) as score from sq group by user_id;\")\nscore_df","8f2a530e":"fig = px.line(score_df, x=\"name\", y=\"score\", title='User Score')\nfig.show()","82eb4dde":"diabeties_df = psql.sqldf(\"SELECT user_id,name,(CASE WHEN question_id = 20 THEN response ELSE 0 END) AS fasting_sugar_levels_check FROM sq where question_id = 20 GROUP BY user_id;\")\ndiabeties_df[\"fasting_sugar_levels_check\"].value_counts()","98f51473":"diabeties_level_df = psql.sqldf(\"SELECT user_id,name,(CASE WHEN question_id = 21 THEN response ELSE 0 END) AS fasting_sugar_levels FROM rus_df where question_id = 21 GROUP BY user_id;\")\ndiabeties_level_df","43e80c70":"diabeties_merge_df = psql.sqldf(\"SELECT diabeties_level_df.user_id,diabeties_level_df.name,diabeties_level_df.fasting_sugar_levels,diabeties_df.fasting_sugar_levels_check from diabeties_level_df join diabeties_df on diabeties_level_df.user_id=diabeties_df.user_id;\")\ndiabeties_merge_df","54e2b487":"diabeties_yes_no = psql.sqldf(\"SELECT user_id,name,(CASE WHEN question_id = 22 THEN response ELSE 0 END) AS IsSugar FROM sq where question_id = 22 GROUP BY user_id;\")\ndiabeties_yes_no[\"IsSugar\"].value_counts()","6518df4b":"diabeties = psql.sqldf(\"SELECT diabeties_merge_df.user_id,diabeties_merge_df.name,diabeties_merge_df.fasting_sugar_levels,diabeties_merge_df.fasting_sugar_levels_check,diabeties_yes_no.IsSugar from diabeties_merge_df join diabeties_yes_no on diabeties_merge_df.user_id=diabeties_yes_no.user_id;\")\ndiabeties","a8d052e5":"smoke_yes_no = psql.sqldf(\"SELECT user_id,name,(CASE WHEN question_id = 13 THEN response ELSE 0 END) AS IsSmoke FROM sq where question_id = 13 GROUP BY user_id;\")\nsmoke_yes_no[\"IsSmoke\"].value_counts()","a3c93d60":"Alcohal_yes_no = psql.sqldf(\"SELECT user_id,name,(CASE WHEN question_id = 35 THEN response ELSE 0 END) AS IsAlcohal FROM sq where question_id = 35 GROUP BY user_id;\")\nAlcohal_yes_no[\"IsAlcohal\"].value_counts()","fcf8ffa4":"sugary_bev = psql.sqldf(\"SELECT user_id,name,(CASE WHEN question_id = 39 THEN response ELSE 0 END) AS Sugarybev FROM sq where question_id = 39 GROUP BY user_id;\")\nsugary_bev[\"Sugarybev\"].value_counts()","b2f8888b":"smoke = psql.sqldf(\"SELECT diabeties.user_id,diabeties.name,diabeties.fasting_sugar_levels,diabeties.fasting_sugar_levels_check,diabeties.IsSugar,smoke_yes_no.IsSmoke from diabeties left join smoke_yes_no on diabeties.user_id=smoke_yes_no.user_id;\")\nAlcohal = psql.sqldf(\"SELECT t1.user_id,t1.name,t1.fasting_sugar_levels,t1.fasting_sugar_levels_check,t1.IsSugar,t1.IsSmoke,t2.IsAlcohal from smoke as t1 left join Alcohal_yes_no as t2 on t1.user_id=t2.user_id;\")\nSugary_df = psql.sqldf(\"SELECT t1.user_id,t1.name,t1.fasting_sugar_levels,t1.fasting_sugar_levels_check,t1.IsSugar,t1.IsSmoke,t1.IsAlcohal,t2.Sugarybev from Alcohal as t1 left join sugary_bev as t2 on t1.user_id=t2.user_id;\")\nSugary_df","1592672c":"x = Sugary_df.drop(['IsSugar'],axis=1)\ny = Sugary_df['IsSugar']\n","deccf987":"le = preprocessing.LabelEncoder()\n#x = x.apply(le.fit_transform)\nx =  x.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\nx.head()","e065b066":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=0)","0c56f6d5":"cols = x_train.columns\n\nx_train = pd.DataFrame(x_train,columns = cols)\nx_test = pd.DataFrame(x_test,columns = cols)\nx_train","9819dd5d":"LR = LogisticRegression(solver='liblinear')\nLR.fit(x_train,y_train)\ny_pred = LR.predict(x_test)\ny_pred","d23c4ca5":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred)","cd46e089":"# Gender Distribution","b6483179":"Merging both DataFrames Height, Weight and Gender_DF together to get a combined DataFrame","f75e8faa":"There is Still much Duplicate Data. Suggestions are welcomed.\ud83d\ude05","bd271467":"# Distribution of Chain-smokers","88c455ff":"Creating Datasets for the ","e5a8efb3":"# Score User Line-Chart","e951f56e":"Sparating time from the DateTime column and putting it as only Date.","0b334d93":"**Removing the Duplicate Inputs given by the users**\n\nFew questions have multiple inputs by the same users and that is duplication of the Data\nSo we need to remove thos rows.","25e0aa8b":"# Creating Height and Weight Columns","63e7050d":"# Importing Important Library","71982e74":"# Smoking Category","0d06e263":"# Types of Questions","ce980dc1":" ***Response, Users and Scores Dataframe after the Left Join on the basis of Question_ID***","97bd74b7":"# Importing Datasets","9a35ce7c":"***Response and Users Dataset after a Left JOIN***"}}