{"cell_type":{"0969fe23":"code","112e6589":"code","e9d55a79":"code","3426ed12":"code","3041d9f6":"code","50133201":"code","3e5e2304":"code","675dbef0":"code","e520d30a":"code","07c33ccc":"code","88d47f91":"code","f9f17d9c":"code","f8f495c0":"code","81110851":"markdown","7c9f5d9f":"markdown","d11a6b35":"markdown","43d4f3bd":"markdown","b97b3fd2":"markdown","fccccaa4":"markdown","979c5564":"markdown","d51d98b6":"markdown","bcb9fbf3":"markdown","a0b50520":"markdown","996a4ee0":"markdown","9ca6bf8d":"markdown","6fa5c684":"markdown","3dcc90c5":"markdown"},"source":{"0969fe23":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt","112e6589":"dataset = pd.read_csv('..\/input\/restaurant-reviews\/Restaurant_Reviews.tsv' , delimiter= '\\t')\ndataset.head()","e9d55a79":"dataset.isnull().sum() # Checking for any null values in the dataset","3426ed12":"import re       # regular expression              \nimport nltk # natural language toolkit\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []                       \n\n# Iterating through all the reviews\nfor i in range(0,1000):\n    # Removing unnecessary punctuations and numbers except letters and replacing removed words with space.\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n    # converting review to lowercase\n    review = review.lower()\n    # Converting review to list(of Strings)\n    review  = review.split()\n    ps = PorterStemmer()\n    words = stopwords.words('english')\n    words.remove('not')\n    words.remove('but')\n    words.remove('is')\n    # Loop through all words and keep those which are not in stopwords list.\n    # set is much faster than a list and is considered when the review is very large eg. an article,a book\n    review = [ps.stem(word) for word in review if not word in set(words)]\n    # Joining back the review list to a string with each word seperated by a space.\n    review = ' '.join(review)\n    corpus.append(review)","3041d9f6":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\ncv = CountVectorizer(max_features= 1566)                \nX = cv.fit_transform(corpus).toarray()                 # toarray() is used to convert into matrix\ny = dataset.iloc[:,1].values","50133201":"X[0:5]","3e5e2304":"y[0:5]","675dbef0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state = 25)","e520d30a":"from sklearn.decomposition import PCA\npca = PCA(n_components=560)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_","07c33ccc":"from sklearn.svm import SVC\nclf = SVC(kernel = 'linear')\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","88d47f91":"results = pd.DataFrame({\n    'Actual': np.array(y_test).flatten(),\n    'Predicted': np.array(y_pred).flatten(),\n})\nresults[1:20]","f9f17d9c":"from sklearn.metrics import plot_confusion_matrix, accuracy_score\nplot_confusion_matrix(clf,X_test , y_test, cmap = plt.cm.Blues)\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy Score: ',accuracy)","f8f495c0":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","81110851":"# Classification report","7c9f5d9f":"# Actual and Predicted value comparision","d11a6b35":"# Importing Restaurnt_Reviews dataset","43d4f3bd":"## Support Vector Machine","b97b3fd2":"# Plotting confusion matrix","fccccaa4":"SVM with PCA gave an accuracy of 89%. However if you run the notebook several times you might get different accuracy between 86-90%. The answer to different accuracy is simple. But I'm leaving it for you to debugg why it's happening. Please give an upvote and comment if you liked the work :)","979c5564":"# Importing Libraries","d51d98b6":"# Preprocessing","bcb9fbf3":"# Applying PCA (Principal Component Analysis)","a0b50520":"## Conclusion","996a4ee0":"# Splitting training and test dataset","9ca6bf8d":"# Creating Bag Of Words","6fa5c684":"## Sentiment Analysis on restaurant reviews using SVM and PCA\n### Accuracy of 89% using SVM and PCA\nThe notebook is really simple for those who just started to work on NLP. And the accuracy is a lot more than other notebooks I find for restaurant reviews.","3dcc90c5":"Principal Component Analysis or PCA is a widely used technique for dimensionality reduction of the large data set. Reducing the number of components or features costs some accuracy and on the other hand, it makes the large data set simpler, easy to explore and visualize. Also, it reduces the computational complexity of the model which makes machine learning algorithms run faster."}}