{"cell_type":{"fb3f46da":"code","8b8fe618":"code","01b0f77e":"code","97e7c21b":"code","817de4b8":"code","3d924444":"code","170f07f7":"code","2ad2c1ea":"code","ca7afa04":"code","9af53125":"code","c8cc42d8":"code","4b36d8e3":"code","1ed66ba5":"code","20fef366":"code","00546957":"code","94a08f9c":"code","26bcfa69":"code","441e3cc8":"code","9a0ca138":"code","83c4d121":"code","f059acee":"code","d067ba79":"code","1f9e1b43":"code","d0a71d5c":"code","4cc5fd67":"code","e21d9615":"markdown","85dbf383":"markdown","c77ac2f9":"markdown","089e371c":"markdown","87cdfe9f":"markdown","380e7329":"markdown","f1682f2f":"markdown","503b0bcc":"markdown","e3cd45d1":"markdown","884687e7":"markdown","a046f6c6":"markdown","9fdd2151":"markdown","cc0e9572":"markdown","50639b7f":"markdown","d482d0bc":"markdown","b5db58b7":"markdown","e8b820b2":"markdown","5d8ab22b":"markdown","98bb43da":"markdown","606a9d7b":"markdown"},"source":{"fb3f46da":"import os\nimport gc\nprint(os.listdir(\"..\/input\"))\nimport numpy as np \nimport pandas as pd\nimport time","8b8fe618":"train = pd.read_csv('..\/input\/train_ship_segmentations_v2.csv')","01b0f77e":"train.head()","97e7c21b":"train['exist_ship'] = train['EncodedPixels'].fillna(0)\ntrain.loc[train['exist_ship']!=0,'exist_ship']=1\ndel train['EncodedPixels']","817de4b8":"print(len(train['ImageId']))\nprint(train['ImageId'].value_counts().shape[0])\ntrain_gp = train.groupby('ImageId').sum().reset_index()\ntrain_gp.loc[train_gp['exist_ship']>0,'exist_ship']=1","3d924444":"print(train_gp['exist_ship'].value_counts())\ntrain_gp= train_gp.sort_values(by='exist_ship')\ntrain_gp = train_gp.drop(train_gp.index[0:100000])","170f07f7":"print(train_gp['exist_ship'].value_counts())\ntrain_sample = train_gp.sample(5000)\nprint(train_sample['exist_ship'].value_counts())\nprint (train_sample.shape)","2ad2c1ea":"Train_path = '..\/input\/train_v2\/'\nTest_path = '..\/input\/test_v2\/'","ca7afa04":"%%time\ntraining_img_data = []\ntarget_data = []\nfrom PIL import Image\ndata = np.empty((len(train_sample['ImageId']),256, 256,3), dtype=np.uint8)\ndata_target = np.empty((len(train_sample['ImageId'])), dtype=np.uint8)\nimage_name_list = os.listdir(Train_path)\nindex = 0\nfor image_name in image_name_list:\n    if image_name in list(train_sample['ImageId']):\n        imageA = Image.open(Train_path+image_name).resize((256,256)).convert('RGB')\n        data[index]=imageA\n        data_target[index]=train_sample[train_gp['ImageId'].str.contains(image_name)]['exist_ship'].iloc[0]\n        index+=1\n        \nprint(data.shape)\nprint(data_target.shape)","9af53125":"from sklearn.preprocessing import OneHotEncoder\ntargets =data_target.reshape(len(data_target),-1)\nenc = OneHotEncoder()\nenc.fit(targets)\ntargets = enc.transform(targets).toarray()\nprint(targets.shape)","c8cc42d8":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(data,targets, test_size = 0.2)\nx_train.shape, x_val.shape, y_train.shape, y_val.shape","4b36d8e3":"from keras.preprocessing.image import ImageDataGenerator\nimg_gen = ImageDataGenerator(\n    rescale=1.\/255,\n    zca_whitening = False,\n    rotation_range = 90,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    brightness_range = [0.5, 1.5],\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    vertical_flip = True\n    \n)","1ed66ba5":"#from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n#from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\nfrom keras.applications.resnet50 import ResNet50 as ResModel\n#from keras.applications.vgg16 import VGG16 as VGG16Model\nimg_width, img_height = 256, 256\nmodel = ResModel(weights = 'imagenet', include_top=False, input_shape = (img_width, img_height, 3))","20fef366":"from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.models import Sequential, Model \nfor layer in model.layers:\n    layer.trainable = False\n\nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation=\"relu\")(x)\npredictions = Dense(2, activation=\"softmax\")(x)\n\n# creating the final model \nmodel_final = Model(input = model.input, output = predictions)","00546957":"from keras import optimizers\nepochs = 10\nlrate = 0.001\ndecay = lrate\/epochs\n#adam = optimizers.Adam(lr=lrate,beta_1=0.9, beta_2=0.999, decay=decay)\nsgd = optimizers.SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\nmodel_final.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\nmodel_final.summary()","94a08f9c":"model_final.fit_generator(img_gen.flow(x_train, y_train, batch_size = 16),steps_per_epoch = len(x_train)\/16, validation_data = (x_val,y_val), epochs = epochs )\nmodel_final.save('ResNet_transfer_ship.h5')","26bcfa69":"gc.collect()","441e3cc8":"train_predict_sample = train_gp.sample(2000)\nprint(train_predict_sample['exist_ship'].value_counts())","9a0ca138":"%%time\nfrom PIL import Image\ndata_predict = np.empty((len(train_predict_sample['ImageId']),256, 256,3), dtype=np.uint8)\ndata_target_predict = np.empty((len(train_predict_sample['ImageId'])), dtype=np.uint8)\nimage_name_list = os.listdir(Train_path)\nindex = 0\nfor image_name in image_name_list:\n    if image_name in list(train_predict_sample['ImageId']):\n        imageA = Image.open(Train_path+image_name).resize((256,256)).convert('RGB')\n        data_predict[index]=imageA\n        data_target_predict[index]=train_predict_sample[train_gp['ImageId'].str.contains(image_name)]['exist_ship'].iloc[0]\n        index+=1\n        \nprint(data_predict.shape)\nprint(data_target_predict.shape)","83c4d121":"from sklearn.preprocessing import OneHotEncoder\ntargets_predict =data_target_predict.reshape(len(data_target_predict),-1)\nenc = OneHotEncoder()\nenc.fit(targets_predict)\ntargets_predict = enc.transform(targets_predict).toarray()\nprint(targets_predict.shape)","f059acee":"predict_ship = model_final.evaluate(data_predict,targets_predict)","d067ba79":"print ('Accuracy of random data = '+ str(round(predict_ship[1]*100)) + \"%\")","1f9e1b43":"image_test_name_list = os.listdir(Test_path)\ndata_test = np.empty((len(image_test_name_list),256, 256,3), dtype=np.uint8)\ntest_name = []\nindex = 0\nfor image_name in image_test_name_list:\n    imageA = Image.open(Test_path+image_name).resize((256,256)).convert('RGB')\n    test_name.append(image_name)\n    data_test[index]=imageA\n    index+=1\nprint (data_test.shape)","d0a71d5c":"result = model_final.predict(data_test)","4cc5fd67":"result_list={\n    \"ImageId\": test_name,\n    \"Have_ship\":np.argmax(result,axis=1)\n}\nresult_pd = pd.DataFrame(result_list)\nresult_pd.to_csv('Have_ship_or_not.csv',index = False)","e21d9615":"## Load training data function\n* load training data to numpy array for training ","85dbf383":"## Balance have chip and no chip data\n* Remove 100000 data of no chip","c77ac2f9":"## Data augumatation\n* Using ImageDataGenerator","089e371c":"## Conclution\n*  We can use tranfer learning to detect ship or not , and get higher accuracy on it \n*  If we get 95% accuracy up, we can merge it with Unet model to produce a final submission\n*  Like Iafoss kernel: https:\/\/www.kaggle.com\/iafoss\/fine-tuning-resnet34-on-ship-detection\/notebook","87cdfe9f":"* Get random 2000 data from training set","380e7329":"# This kernel use simple transfer learning to detect ship exist or not\n*** For biginner, can get about 85% accuracy train on 10 epoch (~20min one epoch no GPU, ~100s one epoch have GPU)**\n* Use ResNet50 to do transfer learning \n* Load 5000 picture to be training data \n* Split 4000 training set , 1000 validate set  (0.2%)\n* Image size 256 x 256, RGB data\n* Using ImageGenerator to do data augumatation","f1682f2f":"* Load predict data ","503b0bcc":"## Add fully connect layer\n* Freeze convolution layer and add fully connect layer\n* On this case, we only need predict 2 category (1. have ship, 2. no ship)\n* For transfer learning, we only need to train parametric on fully connect layer","e3cd45d1":"## Load ResNet50 model with Keras\n* on Kaggle kernel, please turn on the internet setting to Internet connect  on right window","884687e7":"## Doing One hot on target\n* Set target to one hot target for classification problem","a046f6c6":"##  Set Hyperparameter and Start training \n* SGD optimizer\n* Using categorical_crossentropy to be loss function\n* lrate set to 0.001 (Maybe we have better value, In here, I have no experence on this)","9fdd2151":"## Split Training data to training data and validate data to detect overfit ","cc0e9572":"## Set Training set count\n* prevent large data cause much time ","50639b7f":"## Predict accuracy by random read training data","d482d0bc":"* Do one hot for predict target","b5db58b7":"## Tranfer EncodedPixels to target \n* have ship ==> 1\n* No ship ==> 0","e8b820b2":"## We found there are some duplicate image in training data\n* groupby duplicate image ","5d8ab22b":"* Evaluate predict","98bb43da":"* Result","606a9d7b":"## Load segmentation file"}}