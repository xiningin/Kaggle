{"cell_type":{"b3e10fe8":"code","d0f4a82e":"code","2ee277f1":"code","8db2aa3a":"code","84162690":"code","7de30461":"code","b8e6bf8b":"code","300704fe":"code","b0f835c6":"code","fb405210":"code","e4151217":"code","a495ad9e":"code","5a272650":"code","9de5da5d":"code","283abc04":"code","a2c99d7a":"code","0584cd37":"code","d0785e8e":"code","15bfa837":"code","d3f7254c":"code","ceed03c3":"code","ecb1595d":"code","7b68dd1f":"code","44f7d2ac":"code","26171ffc":"code","a9ade32c":"code","0e4da4c7":"code","cff292cb":"code","21af033f":"code","c6eef757":"code","4e931a12":"code","054c9b20":"code","3e763816":"code","0489ea58":"code","70ade148":"code","a462abda":"code","13ae9b82":"code","96e20663":"code","67e4a81a":"code","0444b0cc":"code","c7b301b0":"code","6d118705":"code","4e8e89bd":"code","440c969c":"markdown","e092762d":"markdown","2718a285":"markdown","6fd430bf":"markdown","a09f4ada":"markdown","a5493fd6":"markdown","c1d8bc45":"markdown","3ae5546d":"markdown","17446731":"markdown","1a38ea4c":"markdown","03048676":"markdown","fc03ea89":"markdown","a537e02e":"markdown","a6ce4b79":"markdown","1fe9ab96":"markdown","befe32a0":"markdown","310fc333":"markdown","7358a8b0":"markdown","5c96c532":"markdown","cae8d1bd":"markdown","0ae562fb":"markdown"},"source":{"b3e10fe8":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        \n        \n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit","d0f4a82e":"df = pd.read_csv('..\/input\/texas-wind-turbine-dataset-simulated\/TexasTurbine.csv')","2ee277f1":"df['Wind speed | (m\/s)'].hist()","8db2aa3a":"df['Wind speed | (m\/s)'].mean();","84162690":"df['Wind direction | (deg)'].hist();","7de30461":"\nfrom math import radians\n\nplt.figure(figsize=(8,8))\nax = plt.subplot(111, polar=True)\n# Inside circles are the wind speed and marker color and size represents the amount of power production\nsns.scatterplot(x=[radians(x) for x in df['Wind direction | (deg)']], \n                y=df['Wind speed | (m\/s)'],\n                size=df['System power generated | (kW)'],\n                hue=df['System power generated | (kW)'],\n                alpha=0.7, legend=None)\n# Setting the polar diagram's top represents the North \nax.set_theta_zero_location('N')\n# Setting -1 to start the wind direction clockwise\nax.set_theta_direction(-1)\n# Setting wind speed labels in a better position to see\nax.set_rlabel_position(110)\nplt.title('Wind Speed - Wind Direction - Power Production Diagram')\nplt.ylabel(None);","b8e6bf8b":"sns.heatmap(df.corr());\n\n","300704fe":"df.columns","b0f835c6":"plt.scatter(df[\"Wind speed | (m\/s)\"],df[\"System power generated | (kW)\"]);\n","fb405210":"df['System power generated | (kW)'].max() #3004.01","e4151217":"powercurve = pd.read_csv('..\/input\/texas-wind-turbine-dataset-simulated\/GE Turbine Power Curve.csv')\nplt.scatter(powercurve[\"Power curve wind speed array | (m\/s)\"],powercurve[\"Power curve turbine output array | (kW)\"]);","a495ad9e":"plt.scatter(df[\"Wind direction | (deg)\"],df[\"System power generated | (kW)\"]);","5a272650":"#from sklearn.preprocessing import StandardScaler\n#scaler = StandardScaler()\n#scaler.fit(df['System power generated | (kW)', 'Wind speed | (m\/s)',\n  #     'Wind direction | (deg)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","9de5da5d":"df['System power generated | (kW)'].max()","283abc04":"from sklearn.model_selection import train_test_split\n","a2c99d7a":"\n\nfrom sklearn.ensemble import  RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import r2_score, mean_absolute_error\n# metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","0584cd37":"from sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\n\ndef plot_learning_curve(\n    estimator,\n    title,\n    X,\n    y,\n    axes=None,\n    ylim=None,\n    cv=None,\n    n_jobs=None,\n    train_sizes=np.linspace(0.1, 1.0, 5),\n):\n    \"\"\"\n    Generate 3 plots: the test and training learning curve, the training\n    samples vs fit times curve, the fit times vs score curve.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        An estimator instance implementing `fit` and `predict` methods which\n        will be cloned for each validation.\n\n    title : str\n        Title for the chart.\n\n    X : array-like of shape (n_samples, n_features)\n        Training vector, where ``n_samples`` is the number of samples and\n        ``n_features`` is the number of features.\n\n    y : array-like of shape (n_samples) or (n_samples, n_features)\n        Target relative to ``X`` for classification or regression;\n        None for unsupervised learning.\n\n    axes : array-like of shape (3,), default=None\n        Axes to use for plotting the curves.\n\n    ylim : tuple of shape (2,), default=None\n        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n          - None, to use the default 5-fold cross-validation,\n          - integer, to specify the number of folds.\n          - :term:`CV splitter`,\n          - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer\/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : int or None, default=None\n        Number of jobs to run in parallel.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    train_sizes : array-like of shape (n_ticks,)\n        Relative or absolute numbers of training examples that will be used to\n        generate the learning curve. If the ``dtype`` is float, it is regarded\n        as a fraction of the maximum size of the training set (that is\n        determined by the selected validation method), i.e. it has to be within\n        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n        sets. Note that for classification the number of samples usually have\n        to be big enough to contain at least one sample from each class.\n        (default: np.linspace(0.1, 1.0, 5))\n    \"\"\"\n    if axes is None:\n        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n    axes[0].set_title(title)\n    if ylim is not None:\n        axes[0].set_ylim(*ylim)\n    axes[0].set_xlabel(\"Training examples\")\n    axes[0].set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n        estimator,\n        X,\n        y,\n        cv=cv,\n        n_jobs=n_jobs,\n        train_sizes=train_sizes,\n        return_times=True,\n    )\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    axes[0].grid()\n    axes[0].fill_between(\n        train_sizes,\n        train_scores_mean - train_scores_std,\n        train_scores_mean + train_scores_std,\n        alpha=0.1,\n        color=\"r\",\n    )\n    axes[0].fill_between(\n        train_sizes,\n        test_scores_mean - test_scores_std,\n        test_scores_mean + test_scores_std,\n        alpha=0.1,\n        color=\"g\",\n    )\n    axes[0].plot(\n        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n    )\n    axes[0].plot(\n        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n    )\n    axes[0].legend(loc=\"best\")\n\n    # Plot n_samples vs fit_times\n    axes[1].grid()\n    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n    axes[1].fill_between(\n        train_sizes,\n        fit_times_mean - fit_times_std,\n        fit_times_mean + fit_times_std,\n        alpha=0.1,\n    )\n    axes[1].set_xlabel(\"Training examples\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Scalability of the model\")\n\n    # Plot fit_time vs score\n    fit_time_argsort = fit_times_mean.argsort()\n    fit_time_sorted = fit_times_mean[fit_time_argsort]\n    test_scores_mean_sorted = test_scores_mean[fit_time_argsort]\n    test_scores_std_sorted = test_scores_std[fit_time_argsort]\n    axes[2].grid()\n    axes[2].plot(fit_time_sorted, test_scores_mean_sorted, \"o-\")\n    axes[2].fill_between(\n        fit_time_sorted,\n        test_scores_mean_sorted - test_scores_std_sorted,\n        test_scores_mean_sorted + test_scores_std_sorted,\n        alpha=0.1,\n    )\n    axes[2].set_xlabel(\"fit_times\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_title(\"Performance of the model\")\n\n    return plt\n","d0785e8e":"from xgboost import XGBRegressor\n\n\n    \n\n\n# fuction for performing and assessing XGBoosting algorithms on this dataset\n\ndef xgboosting(features_to_delate):\n    #features_to_delate is for assessing of importance of each features\n    train_X = df.drop(columns=features_to_delate)\n    #features_to_delate should be  a list \n    train_y = df['System power generated | (kW)']\n    train_x, test_x, train_y, test_y = train_test_split(train_X, train_y,test_size=0.3,random_state=17)\n    train_x.shape, test_x.shape, train_y.shape, test_y.shape\n    params = {'max_depth': range(2,5),'alpha': range(1,4),'learning_rate':[0.1,0.2,0.3],'n_estimators':range(50,100,20)}     \n    gradientboosting = XGBRegressor()\n    gcv = GridSearchCV(gradientboosting,params, n_jobs=-1, cv=5, verbose=1)\n    gcv.fit(train_x, train_y)\n\n    \n    \n    predict_train = gcv.predict(train_x)\n    predict_test  = gcv.predict(test_x)\n    test_x['predicted power'] = pd.Series(predict_test, index=test_x.index)\n    train_x['predicted power'] = pd.Series(predict_train, index=train_x.index)\n\n\n    #Root Mean Squared Error on train and test date\n    print('RMSE on train data: ', mean_squared_error(train_y, predict_train)**(0.5))\n    print('RMSE on test data: ',  mean_squared_error(test_y, predict_test)**(0.5))\n    print(\"MAE of train data: {}\".format(mean_absolute_error(test_y, predict_test)))\n    print(\"MAE of test data: {}\".format(mean_absolute_error(test_y, predict_test)))\n    print('Coefficient of determination on test data:', r2_score(test_y, predict_test))\n    print('Coefficient of determination on train data:', r2_score(train_y, predict_train))\n    plt.figure(figsize=(25,11))\n   \n    sns.scatterplot(x='Wind speed | (m\/s)', y='System power generated | (kW)',alpha=0.5, label= 'Real Power', data=df)\n    sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= test_x)\n    #sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= train_x_3)\n    plt.title('Wind Turbine Power Production Prediction')\n    plt.ylabel('Power Production (kw)')\n    plt.legend();\n    \n\n    return r2_score(test_y, predict_test), r2_score(train_y, predict_train)","15bfa837":"xgboosting(['Time stamp','System power generated | (kW)'])","d3f7254c":"xgboosting(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","ceed03c3":"xgboosting(['Time stamp', 'System power generated | (kW)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","ecb1595d":"xgboosting(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', 'Pressure | (atm)'])","7b68dd1f":"\n# function k-nn\ndef knn(features_to_delate):\n    train_X = df.drop(columns=features_to_delate)\n    #features_to_delate should be  a list \n    train_y = df['System power generated | (kW)']\n    train_x_3, test_x_3, train_y_3, test_y_3 = train_test_split(train_X, train_y,test_size=0.2,random_state=17)\n    train_x_3.shape, test_x_3.shape, train_y_3.shape, test_y_3.shape\n    # fit the model with the training data\n    knnmodel= KNeighborsRegressor(n_neighbors=10,n_jobs=-1)\n\n   \n    \n    # predict the target on train and test data \n    #predict_train = knnmodel.predict(train_x_3)\n    #predict_test  = knnmodel.predict(test_x_3)\n    \n    \n    # for kNN, we need to scale features\n    \n\n    knn_pipe = Pipeline(\n    [(\"scaler\", StandardScaler()), (\"knn\", KNeighborsRegressor(n_jobs=-1))]\n    )\n\n    knn_params = {\"knn__n_neighbors\": range(1, 10)}\n\n    knn_grid = GridSearchCV(knn_pipe, knn_params, cv=5, n_jobs=-1, verbose=True)\n\n    knn_grid.fit(train_x_3, train_y_3)\n    predict_train = knn_grid.predict(train_x_3)\n    predict_test  = knn_grid.predict(test_x_3)\n\n    knn_grid.best_params_, knn_grid.best_score_\n\n    \n    \n    test_x_3['predicted power'] = pd.Series(predict_test, index=test_x_3.index)\n    train_x_3['predicted power'] = pd.Series(predict_train, index=train_x_3.index)\n   \n    \n  \n   \n    \n   \n\n    #Root Mean Squared Error on train and test date r\n    print('RMSE on train data: ', mean_squared_error(train_y_3, predict_train)**(0.5))\n   \n    #print('MAPE on train data:',  mean_absolute_percentage_error(train_y_1,predict_train_2))\n    #print('MAPE on test data:',  mean_absolute_percentage_error(test_y_1,predict_test_2))\n    print('Coefficient of determination on test data:', r2_score(test_y_3, predict_test))\n   \n    \n     \n \n    print('RMSE on test data: ', mean_squared_error(test_y_3, predict_test)**(0.5))\n    \n    #print('MAPE on train data:',  mean_absolute_percentage_error(train_y_1,predict_train_2))\n    #print('MAPE on test data:',  mean_absolute_percentage_error(test_y_1,predict_test_2))\n    print('Coefficient of determination on test data:', r2_score(test_y_3, predict_test))\n    print('Coefficient of determination on train data:', r2_score(train_y_3, predict_train))\n    print(\"MAE of train data: {}\".format(mean_absolute_error(train_y_3, predict_train)))\n    print(\"MAE of test data: {}\".format(mean_absolute_error(test_y_3, predict_test)))\n    # Visualizing real, theoritical and predicted power production\n    plt.figure(figsize=(25,11))\n   \n    sns.scatterplot(x='Wind speed | (m\/s)', y='System power generated | (kW)',alpha=0.5, label= 'Real Power', data=df)\n    sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= test_x_3)\n    #sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= train_x_3)\n    plt.title('Wind Turbine Power Production Prediction')\n    plt.ylabel('Power Production (kw)')\n    plt.legend();\n        \n#Index(['Time stamp', 'System power generated | (kW)', 'Wind speed | (m\/s)',\n    #   'Wind direction | (deg)', 'Pressure | (atm)', 'Air temperature | ('C)'],\n    \n","44f7d2ac":"#knn(['Time stamp','System power generated | (kW)'])","26171ffc":"#knn(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","a9ade32c":"#knn(['Time stamp', 'System power generated | (kW)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","0e4da4c7":"#knn(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', 'Pressure | (atm)'])","cff292cb":"#knn(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', \"Air temperature | ('C)\"])","21af033f":"from sklearn.ensemble import RandomForestRegressor\ndef RF(features_to_delate):\n\n    train_X = df.drop(columns=features_to_delate)\n    #features_to_delate should be  a list \n    train_y = df['System power generated | (kW)']\n    train_x_3, test_x_3, train_y_3, test_y_3 = train_test_split(train_X, train_y,test_size=0.3,random_state=17)\n    train_x_3.shape, test_x_3.shape, train_y_3.shape, test_y_3.shape\n    parameters = {'bootstrap': [True, False],'min_samples_leaf': [1, 3, 5, 7,10], 'max_depth': [5,10,15,20,40],'n_estimators': [50, 100, 150, 200, 70]}\n    rfc = RandomForestRegressor(random_state=42, n_jobs=-1, oob_score=True)\n    gcv = GridSearchCV(rfc, parameters, n_jobs=-1, cv=5, verbose=1)\n    gcv.fit(train_x_3, train_y_3)\n    predict_train_3 = gcv.predict(train_x_3)\n    predict_test_3  = gcv.predict(test_x_3)\n    test_x_3['predicted power'] = pd.Series(predict_test_3, index=test_x_3.index)\n    train_x_3['predicted power'] = pd.Series(predict_train_3, index=train_x_3.index)\n\n\n    #Root Mean Squared Error on train and test date\n    print('RMSE on train data: ', mean_squared_error(train_y_3, predict_train_3)**(0.5))\n    print('RMSE on test data: ',  mean_squared_error(test_y_3, predict_test_3)**(0.5))\n    print(\"MAE of train data: {}\".format(mean_absolute_error(test_y_3, predict_test_3)))\n    print(\"MAE of test data: {}\".format(mean_absolute_error(test_y_3, predict_test_3)))\n    print('Coefficient of determination on test data:', r2_score(test_y_3, predict_test_3))\n    print('Coefficient of determination on train data:', r2_score(train_y_3, predict_train_3))\n    plt.figure(figsize=(25,11))\n   \n    sns.scatterplot(x='Wind speed | (m\/s)', y='System power generated | (kW)',alpha=0.5, label= 'Real Power', data=df)\n    sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= test_x_3)\n    #sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= train_x_3)\n    plt.title('Wind Turbine Power Production Prediction')\n    plt.ylabel('Power Production (kw)')\n    plt.legend();\n    \n\n    return r2_score(test_y_3, predict_test_3), r2_score(train_y_3, predict_train_3)\n\n\n\n    ","c6eef757":"#RF(['Time stamp','System power generated | (kW)'])","4e931a12":"#RF(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","054c9b20":"#RF(['Time stamp', 'System power generated | (kW)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","3e763816":"#RF(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', 'Pressure | (atm)'])","0489ea58":"#RF(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', \"Air temperature | ('C)\"])","70ade148":"# fuction for performing and assessing Boosting algorithms on this dataset\nfrom sklearn.ensemble import GradientBoostingRegressor\ndef boosting(features_to_delate):\n    #features_to_delate is for assessing of importance of each features\n    train_X = df.drop(columns=features_to_delate)\n    #features_to_delate should be  a list \n    train_y = df['System power generated | (kW)']\n    train_x, test_x, train_y, test_y = train_test_split(train_X, train_y,test_size=0.3,random_state=17)\n    train_x.shape, test_x.shape, train_y.shape, test_y.shape\n    parameters = {'learning_rate':[0.02,0.05, 0.1, 0.15,0.2],'n_estimators':range(50,200,30),'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n    gradientboosting = GradientBoostingRegressor(random_state=42)\n    gcv = GridSearchCV(gradientboosting,parameters, n_jobs=-1, cv=5, verbose=1)\n    gcv.fit(train_x, train_y)\n\n    \n    \n    predict_train = gcv.predict(train_x)\n    predict_test  = gcv.predict(test_x)\n    test_x['predicted power'] = pd.Series(predict_test, index=test_x.index)\n    train_x['predicted power'] = pd.Series(predict_train, index=train_x.index)\n\n\n    #Root Mean Squared Error on train and test date\n    print('RMSE on train data: ', mean_squared_error(train_y, predict_train)**(0.5))\n    print('RMSE on test data: ',  mean_squared_error(test_y, predict_test)**(0.5))\n    print(\"MAE of train data: {}\".format(mean_absolute_error(test_y, predict_test)))\n    print(\"MAE of test data: {}\".format(mean_absolute_error(test_y, predict_test)))\n    print('Coefficient of determination on test data:', r2_score(test_y, predict_test))\n    print('Coefficient of determination on train data:', r2_score(train_y, predict_train))\n    plt.figure(figsize=(25,11))\n   \n    sns.scatterplot(x='Wind speed | (m\/s)', y='System power generated | (kW)',alpha=0.5, label= 'Real Power', data=df)\n    sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= test_x)\n    #sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= train_x_3)\n    plt.title('Wind Turbine Power Production Prediction')\n    plt.ylabel('Power Production (kw)')\n    plt.legend();\n    \n\n    return r2_score(test_y, predict_test), r2_score(train_y, predict_train)\n","a462abda":"#boosting(['Time stamp','System power generated | (kW)'])","13ae9b82":"#boosting(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","96e20663":"#boosting(['Time stamp', 'System power generated | (kW)', 'Pressure | (atm)', \"Air temperature | ('C)\"])","67e4a81a":"#boosting(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', 'Pressure | (atm)'])","0444b0cc":"#boosting(['Time stamp', 'System power generated | (kW)','Wind direction | (deg)', \"Air temperature | ('C)\"])","c7b301b0":"from sklearn.svm import SVR\n\nfrom sklearn.metrics import make_scorer\n# fuction for performing and assessing support vector machine on this dataset\ndef svr(features_to_delate):\n    #features_to_delate is for assessing of importance of each features\n    train_X = df.drop(columns=features_to_delate)\n    #features_to_delate should be  a list \n    train_y = df['System power generated | (kW)']\n    train_x, test_x, train_y, test_y = train_test_split(train_X, train_y,test_size=0.3,random_state=17)\n    train_x.shape, test_x.shape, train_y.shape, test_y.shape\n    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n    parameters = {'kernel': ['rbf'], 'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],'C': [1, 10, 100, 1000, 10000]}\n    svr = SVR()\n    gcv = GridSearchCV(svr,parameters, n_jobs=-1, cv=5,scoring=scorer)\n    gcv.fit(train_x, train_y)\n\n    \n    \n    predict_train = gcv.predict(train_x)\n    predict_test  = gcv.predict(test_x)\n    test_x['predicted power'] = pd.Series(predict_test, index=test_x.index)\n    train_x['predicted power'] = pd.Series(predict_train, index=train_x.index)\n\n\n    #Root Mean Squared Error on train and test date\n    print('RMSE on train data: ', mean_squared_error(train_y, predict_train)**(0.5))\n    print('RMSE on test data: ',  mean_squared_error(test_y, predict_test)**(0.5))\n    print(\"MAE of train data: {}\".format(mean_absolute_error(test_y, predict_test)))\n    print(\"MAE of test data: {}\".format(mean_absolute_error(test_y, predict_test)))\n    print('Coefficient of determination on test data:', r2_score(test_y, predict_test))\n    print('Coefficient of determination on train data:', r2_score(train_y, predict_train))\n    plt.figure(figsize=(25,11))\n   \n    sns.scatterplot(x='Wind speed | (m\/s)', y='System power generated | (kW)',alpha=0.5, label= 'Real Power', data=df)\n    sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= test_x)\n    #sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= train_x_3)\n    plt.title('Wind Turbine Power Production Prediction')\n    plt.ylabel('Power Production (kw)')\n    plt.legend();\n    \n\n    return r2_score(test_y, predict_test), r2_score(train_y, predict_train)\n","6d118705":"# fuction for performing and assessing Boosting algorithms on this dataset\nfrom catboost import CatBoostRegressor\n\ndef catboost(features_to_delate):\n    cat = CatBoostRegressor()\n    #features_to_delate is for assessing of importance of each features\n    train_X = df.drop(columns=features_to_delate)\n    #features_to_delate should be  a list \n    train_y = df['System power generated | (kW)']\n    train_x, test_x, train_y, test_y = train_test_split(train_X, train_y,test_size=0.3,random_state=17)\n    train_x.shape, test_x.shape, train_y.shape, test_y.shape\n    parameters = {\"max_depth\": [16],\n              \"learning_rate\" : [0.3],\n              \"n_estimators\": [400,800,50]\n             }\n    #gradientboosting = GradientBoostingRegressor(random_state=42)\n    gcv= GridSearchCV(cat,param_grid=parameters,n_jobs=-1,  cv = 3, verbose=5)\n    #for key,value in cat.get_all_params().items():\n        #print(key,value)\n    gcv.fit(train_x, train_y)\n    print(gcv.best_estimator_)\n    predict_train = gcv.predict(train_x)\n    predict_test  = gcv.predict(test_x)\n    test_x['predicted power'] = pd.Series(predict_test, index=test_x.index)\n    train_x['predicted power'] = pd.Series(predict_train, index=train_x.index)\n\n\n    print(gcv.best_estimator_)\n    #Root Mean Squared Error on train and test date\n    print('RMSE on train data: ', mean_squared_error(train_y, predict_train)**(0.5))\n    print('RMSE on test data: ',  mean_squared_error(test_y, predict_test)**(0.5))\n    print(\"MAE of train data: {}\".format(mean_absolute_error(test_y, predict_test)))\n    print(\"MAE of test data: {}\".format(mean_absolute_error(test_y, predict_test)))\n    print('Coefficient of determination on test data:', r2_score(test_y, predict_test))\n    print('Coefficient of determination on train data:', r2_score(train_y, predict_train))\n    plt.figure(figsize=(25,11))\n    \n   \n    sns.scatterplot(x='Wind speed | (m\/s)', y='System power generated | (kW)',alpha=0.5, label= 'Real Power', data=df)\n    sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= test_x)\n    #sns.scatterplot(x='Wind speed | (m\/s)', y='predicted power', alpha=0.7, label='Predicted Power', marker='o', data= train_x_3)\n    plt.title('Wind Turbine Power Production Prediction')\n    plt.ylabel('Power Production (kw)')\n    plt.legend();\n    plot_learning_curve(gcv, 'learning curve', test_x, test_y, cv=3)\n    plot_learning_curve(gcv, 'learning curve', train_x, train_y, cv=3)\n\n    return r2_score(test_y, predict_test), r2_score(train_y, predict_train)\n","4e8e89bd":"#(['Time stamp','System power generated | (kW)']);","440c969c":"# ****XGBoosting****","e092762d":"     Operating data\n* Rated capacity: 3600kW\n* Cut-in wind speed: 3,5 m\/s\n* Cut-out wind speed: 27 m\/s\n* Rated wind speed: 14m\/s","2718a285":"*# Creating the polar diagram for wind direction*","6fd430bf":"scaling","a09f4ada":"**avarage wind speed is 7,376 m\/s**","a5493fd6":"let's draw real power curve","c1d8bc45":"the maximum power in 3004.01","3ae5546d":"** Here we can see real powee curve(link to GE brochure http:\/\/www2.elo.utfsm.cl\/~elo383\/tareas\/ge_36_brochure_new.pdf)**","17446731":"# **Random Forest**","1a38ea4c":"**Real Power Curve of this Turbine**","03048676":" # **k -nearest neighbors**","fc03ea89":"# **GRADIENT BOOSTING**","a537e02e":"**Support vector machines**","a6ce4b79":"*Wind speed and power production is highly correlated as one would expect.\n\nWe can see there are lower level power production for some wind directions.*","1fe9ab96":"NREL (National Renewable Energy Laboratory)\nCollection methodology\n\nNREL software-generated dataset using TMY weather with onshore turbine in Texas","befe32a0":"Now let's compare different forecast methods ","310fc333":"it's clear that this turbine produces maximum power when winds blows from 100 to 170 degrees","7358a8b0":" ![image.png](attachment:71908ce8-b292-4e79-ab1a-c953cbb6d012.png) ","5c96c532":"Wind Turbine details\nGeneral Electric Wind Turbine installed onshore:\n\nRotor diameter 111m\n\nRated output 3600kW\n\nHub height 80m\n\nSingle Wind Turbine","cae8d1bd":"The provided full-year hourly time-series are simulated using the National Renewable Energy Laboratory (NREL) software for a location in Texas, US. It has perfect data completeness, and no noisy data; challenges that hinder forecasting tasks with real datasets and distract from the goal.\nThe dataset contains various weather features which can be analyzed and used as predictors","0ae562fb":"task to assess the importance of each features "}}