{"cell_type":{"b5ce82cf":"code","caed78b7":"code","3d04ed4c":"code","3535adad":"code","2134d42d":"code","742c35ec":"code","b93017fc":"code","dcc341de":"code","3bc8dc6f":"code","329bfadf":"code","739ae5be":"code","849cf0a4":"code","1c373491":"code","cf639728":"code","b0ab5354":"code","bbe3a5bd":"code","cc39733e":"code","4ad3a4d9":"markdown","6cd2916a":"markdown"},"source":{"b5ce82cf":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F","caed78b7":"class Inception(nn.Module):\n    def __init__(self, in_channels, c1,c2,c3,c4,debug=False,**kwargs):\n        super(Inception, self).__init__(**kwargs)\n        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n        \n        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n        \n        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n        \n        self.debug = debug\n        \n    def forward(self, X):\n        if(self.debug):\n            p1 = self.p1_1(X)\n            print(\"p1_Conv: \", p1.shape)\n            p1 = F.relu(p1)\n            print(\"p1_relu:\", p1.shape)\n            \n            p2 = self.p2_1(X)\n            print(\"p2_Conv:\", p2.shape)\n            p2 = F.relu(p2)\n            print(\"p2_relu:\", p2.shape)\n            p2 = self.p2_2(p2)\n            print(\"p2_Conv2:\", p2.shape)\n            p2 = F.relu(p2)\n            print(\"p2_relu:\", p2.shape)\n            \n            p3 = self.p3_1(X)\n            print(\"p3_Conv:\", p3.shape)\n            p3 = F.relu(p3)\n            print(\"p3 relu:\", p3.shape)\n            p3 = self.p3_2(p3)\n            print(\"p3_Conv2:\", p3.shape)\n            p3 = F.relu(p3)\n            print(\"p3_relu:\", p3.shape)\n            \n            p4 = self.p4_1(X)\n            print(\"p4_Maxpool:\", p4.shape)\n            p4 = self.p4_2(p4)\n            print(\"p4_Conv:\", p4.shape)\n            p4 = F.relu(p4)\n            print(\"p4_relu:\", p4.shape)\n        \n        else:\n            p1 = F.relu(self.p1_1(X))\n            p2 = F.relu(self.p2_2(F.relu(self.p2_1(X))))\n            p3 = F.relu(self.p3_2(F.relu(self.p3_1(X))))\n            p4 = F.relu(self.p4_2(self.p4_1(X)))\n        \n        return torch.cat((p1,p2,p3,p4), dim=1)\n        ","3d04ed4c":"X = torch.randn(1,1,28,28)\n\ndef look_in_net(net, X):\n    out = X\n    \n    for layer in net:\n        out = layer(out)\n        print(f\"For output layer {out.__class__.__name__} : {out.shape}\")\n\n","3535adad":"net = Inception(1, 32, (32,64), (64,32),32,debug=True)","2134d42d":"net(X).shape","742c35ec":"p1 = torch.randn(1,2)\np2 = torch.randn(1,2)\np3 = torch.randn(1,2)\np4 = torch.randn(1,2)\n\ntorch.cat((p1,p2,p3,p4), dim=0)","b93017fc":"torch.cat((p1,p2,p3,p4), dim=1)","dcc341de":"b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n                   nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2,\n                                           padding=1))","3bc8dc6f":"b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1), nn.ReLU(),\n                   nn.Conv2d(64, 192, kernel_size=3, padding=1), nn.ReLU(),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))","329bfadf":"b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n                   Inception(256, 128, (128, 192), (32, 96), 64),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))","739ae5be":"b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n                   Inception(512, 160, (112, 224), (24, 64), 64),\n                   Inception(512, 128, (128, 256), (24, 64), 64),\n                   Inception(512, 112, (144, 288), (32, 64), 64),\n                   Inception(528, 256, (160, 320), (32, 128), 128),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))","849cf0a4":"b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n                   Inception(832, 384, (192, 384), (48, 128), 128),\n                   nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten())\n\nnet = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))","1c373491":"X = torch.rand(size=(1, 1, 96, 96))\nfor layer in net:\n    X = layer(X)\n    print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n\n","cf639728":"X = torch.randn(8,1,96,96)\nlook_in_net(net, X)","b0ab5354":"!pip install -U d2l\nimport d2l\nfrom d2l import torch\nfrom d2l.torch import *","bbe3a5bd":"lr, num_epochs, batch_size = 0.1, 10, 128\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)","cc39733e":"\nd2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())","4ad3a4d9":"The fact that it is training so successfully should mean something. I need to implement the d2l functions in my vanilla implementation.","6cd2916a":"# D2L\nD2l is an interactive online book, with lots of info on nitty gritty of pytorch , tensorflow etc. Find it here: http:\/\/d2l.ai\/"}}