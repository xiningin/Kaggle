{"cell_type":{"6a5488fa":"code","00d9f90c":"code","f1ca7ba3":"code","adbbba83":"code","660f7372":"code","8226425e":"code","77da0661":"code","2b5536c8":"code","59927b2f":"code","754f08fc":"code","972dd0ed":"code","dd50fc02":"code","42827679":"code","03be4f0d":"code","cf652f31":"code","e82028c7":"markdown","321518c7":"markdown","b4e06efe":"markdown","250aa284":"markdown","4ece6a7d":"markdown","113bb78d":"markdown","3b146aa6":"markdown","180e8cfa":"markdown","29355872":"markdown","ace0a274":"markdown","25ed17a8":"markdown","ab56e1bc":"markdown"},"source":{"6a5488fa":"# Mengimport library yang dibutuhkan program\nimport pandas as pd # Library untuk menangani data\nfrom pandas import DataFrame\nimport numpy as np # library numpy array\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import train_test_split # fungsi untuk membagi dataset menjadi data training dan data testing\nfrom sklearn.tree import DecisionTreeRegressor # fungsi untuk menggunakan model decision tree \nimport joblib # Library untuk mengeksport model yang sudah di training ke dalam bentuk file\n","00d9f90c":"# Path dataset yang ada (datapanas.csv) disimpan kedalam variabel skripsiku\n#ngeload data\nskripsiku = '..\/input\/datasettttt\/dataprocessku.csv'\n\n# Membaca dataset dengan dungsi read_csv pada library pandas (pd)\n# pada path yang tersimpan di variabel skripsiku\n# data csv yang ada disimpan di variabel hotSpotData\nhotSpotData = pd.read_csv(skripsiku)\n\n# hotSpotData2 = pd.read_csv(skripsiku)\n# frames = [hotSpotData, hotSpotData2]\n# seluruhData = pd.concat(frames)\n\n# Untuk melihat rangkuman dari dataset yang tersimpan pada variabel hotSpotData.\n# Rangkuman yang dimaksud itu sebenernya rangkuman secara statistik (kaya count atau jumlah data \n# pada kolom tsb, mean atau rata2 pada kolom tsb, std atau standar deviasi pada kolom tsb, \n# 25% itu kuartil bawah pada kolom tsb, 50% itu median pada kolom tsb, 75% kuartil atas pada kolom tsb, \n# max itu nilai maksimum pada kolom tsb, min itu nilai minimum pada kolom tsb)\nhotSpotData.describe()\n# seluruhData.describe()\n\n# Catatan: Rangkuman yang diliat dengan fungsi describe() itu cuman untuk kolom yang tipenya angka\n# makanya kolom2 kaya provinsi sama kota engga ada di rangkuman di bawah","f1ca7ba3":"# untuk ngeliat 5 data pertama dari hotSpotData (fungsi head() buat ngeliat 5 data pertama))\nhotSpotData.head()","adbbba83":"# Menentukan kolom mana aja yang dipake untuk fitur-fitur dalam prediksi.\n# Disini kolom CurahHujan engga dipake karena CurahHujan itu\n# kolom yang akan diprediksi.\n# Kolom-kolom yang dipake sebagai fitur untuk prediksi itu X\n# Kolom yang akan diprediksi itu Y\nfeatures = ['FFMC', 'DMC', 'DC',\n            'Temperatur', 'KecepatanAngin']\n\n# variabel x cuman nyimpen nilai kolom-kolom yang ditentuin \n# di variabel features dari hotSpotData\nx = hotSpotData[features]\n\n# ngeliat 5 data pertama dari variabel x (fungsi head() buat ngeliat 5 data pertama))\n# x ini belum di proses.\nx.head()","660f7372":"#Variabel y hanya menyimpan nilai-nilai kolom Luas Area dari hotSpotData\ny = hotSpotData['Luas Area']\n\n#meelihat 5 data pertama dari variabel y.\ny.head()","8226425e":"#mengatasi nilai non\\-angka pada kolom\\-kolom yang tersimpan di variabel x\n#preprocessing data non-numerik\nx = pd.get_dummies(x)\nx.head()","77da0661":"# Untuk membagi data menjadi data training dan testing\n# dipake fungsi train_test_split\n# train_test_split butuh 2 parameter utama yaitu\n# nilai kolom-kolom untuk melakukan prediksi (X) dan\n# nilai kolom yang diprediksi (Y)\n# parameter yang lain seperti shuffle dan test_size itu optional\n# shuffle dipake supaya pengambilan datanya engga random\n# test_size dipake untuk nentuin seberapa banyak data yang mau dipake untuk testing\n# test_size kalo ga ditentuin defaultnya 0.25 (jd nantinya data trainingnya 0.75,\n# data testingnya 0.25)\n# trainX sama trainY itu data training\n# valX sama valY itu data testing\n#trainX, valX, trainY, valY = train_test_split(\n#x,y, test_size=0.01, random_state=3)\ntrainX, valX, trainY, valY = train_test_split(\n    x,y, test_size=0.2, random_state=3)\n#print('Data Training')\n#print(trainX)\nprint('Data Test')\nprint(valX)\n\n#trainX, valX, trainY, valY = train_test_split(\n    #x,y, test_size=0.01, random_state=0)\n#print('Data Training')\n#print(trainX)\n#print('Data Test')\n#print(valX)\n#trainX, valX, trainY, valY = train_test_split(\n    #x,y)\n#print('Data Training')\n#print(trainX)\n#print('Data Test')\n#print(valX)\n\n# print('data')\n# print (valX)\n# print('datacoba')\nprint(valY)\n# Ini kalo bagi data manual\n# trainX = x[:299]\n# trainY = y[:299]\n# valX = x[299:]\n# valX = y[299:]\n\n# untuk ngeliat apakah benar data yang diambil 0.75 training dan 0.25 testing\n# dilakukan print pada variabel x (data utuh) dan data training beserta data testing\n\n# print data training\n# karena keseluruhan data ada 400 baris. berarti 0.75nya dipake training\n# perhitungannya 0.75 * 400 - 1 = 299 data yang dipakai untuk training\n# untuk memastikan kebenarannya diprint data di x dari index 0 sampai 300\n#print(\"Sumber data sebelum train_test_split (index 0-298)\")\n# python sistem indexing arraynya explisit artinya walau ditulis 299, \n# 299 itu tidak termasuk yang di print (cuman sampe 298)\n#print(x[:299])\n#print()\n#print(\"Data Training\")\n# ini print data yang ada di variabel trainX (hasil train_test_split)\n#print(trainX)","2b5536c8":"# Ini buat ngeliat data test\n# data test 0.25 berarti 0.25 * 400 + 1 = 101 data\n#print(\"Sumber data sebelum train_test_split (index 299-399)\")\n#print(x[299:])\n#print()\n#print(\"Data Testing\")\n#print(valX)","59927b2f":"# Model yang dipakai adalah Decision Tree untuk regresi jadi library yang dipake\n# itu DecisionTreeRegressor-nya sklearn\n# random_state itu parameter supaya Decision Tree nya ga berubah-berubah saat\n# programnya dijalanin ulang\n# max_leaf_nodes itu parameter untuk nentuin nilai maksimal leaf pada treenya berapa,\n# ditentuin karena kalau terlalu banyak leafnya biasanya malah makin tidak akurat modelnya\n#biar ngegeneratenya sama terus\n#membuat model\nhotspotPredictorModel = DecisionTreeRegressor(random_state=1, max_leaf_nodes=100)","754f08fc":"hotspotPredictorModel.fit(trainX, trainY)\nvalPredictions = hotspotPredictorModel.predict(valX)\nvalMae = metrics.mean_absolute_error(valPredictions, valY)\nprint(valMae)\nprint(valPredictions)\nprint(valX)\nprint(valY)","972dd0ed":"besar_kecil = np.where(valPredictions >= valY, 'MELUAS', 'TIDAK MELUAS')\nhitung_luas_kebakaran = (valPredictions \/ valY ) * 100\nresult = pd.DataFrame({'hasil_prediksi':valPredictions, 'nilai asli' \n                       : valY, 'keterangan':besar_kecil,\n                       'presentasi_kebakaran' :hitung_luas_kebakaran })\nprint(result)\n","dd50fc02":"data_test_satu_doang = valX.iloc[9,:]\nnilai_y_asli = [valY.iloc[9]]\npredict2 = hotspotPredictorModel.predict([data_test_satu_doang])\nhitung_persen = (predict2 \/ nilai_y_asli ) * 100\nprint('nilai hasil prediksi = ', predict2)\nprint('nilai asli = ', nilai_y_asli)\nprint(data_test_satu_doang)\nprint('hitung_persen =', hitung_persen)\n","42827679":"\n#joblib.dump(hotspotPredictorModel, 'my_model.pkl', compress=9)\n\n#prediction = pd.DataFrame(valPredictions, columns=['HASIL_PREDIKSI']).to_csv('prediction.csv')\nprediction = pd.DataFrame(result, columns= ['hasil_prediksi', 'keterangan', 'presentasi_kebakaran'])\nexport_csv = prediction.to_csv ('export_dataframe.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path\n#print (export_csv)\nprint(prediction)\n#result = result.to_csv('hasil.csv')\n#train = pd.DataFrame(trainX).to_csv('train.csv')\n#df.to_csv(index=False)","03be4f0d":"!dot -Tpng dot_data.dot -o tree.png -Gdpi=600 #export dot ke png di terminal linux dikaggle","cf652f31":"from IPython.display import Image \nImage(filename='tree.png')","e82028c7":"<h2>**Melatih Model (Training)**<\/h2>","321518c7":"sns.countplot(x=\"class\", data=data)\ndata.loc[:,'class'].value_counts()","b4e06efe":"Bisa diliat di tabel di atas ada kolom tambahan baru seperti kolom Provinsi_BALI, provinsi_BANGKA-BELITUNG, Hari_Kamis, dll. Nah kolom-kolom tambahan itu yang disebut sebagai kolom dummy.","250aa284":"from IPython.display import Image\nfrom sklearn.tree import export_graphviz \nexport_graphviz(hotspotPredictorModel, out_file='dot_data.dot',  \n                filled=False, rounded=True,\n                special_characters=True, feature_names=x.columns)\n","4ece6a7d":"color_list = ['red' if i=='Abnormal' else 'green' for i in data.loc[:,'class']]\npd.plotting.scatter_matrix(data.loc[:, data.columns != 'class'],\n                                       c=color_list,\n                                       figsize= [15,15],\n                                       diagonal='hist',\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = '*',\n                                       edgecolor= \"black\")\nplt.show()","113bb78d":"sns.countplot(x=\"class\", data=data)\ndata.loc[:,'class'].value_counts()\n# read csv (comma separated value) into data\n\n# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nx,y = data.loc[:,data.columns != 'class'], data.loc[:,'class']\nprint(type(x))\nprint(type(y))\nknn.fit(x,y)\nprediction = knn.predict(x)\nprint('Prediction: {}'.format(prediction))\n\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\nknn = KNeighborsClassifier(n_neighbors = 3)\nx,y = data.loc[:,data.columns != 'class'], data.loc[:,'class']\nknn.fit(x,y)\nprediction = knn.predict(x_test)\n#print('Prediction: {}'.format(prediction))\nprint('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test)) # accuracy","3b146aa6":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nx,y = data.loc[:,data.columns != 'class'], data.loc[:,'class']","180e8cfa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n# ignore warnings\nwarnings.filterwarnings(\"ignore\")\nfrom subprocess import check_output\ndata = pd.read_csv('..\/input\/dataqulagi\/dataprocessku1.csv')\nprint(plt.style.available) # look at available plot styles\nplt.style.use('ggplot')\ndata.head()\ndata.info()\ndata.describe()","29355872":"<h2>**Mengimport Library**<\/h2>","ace0a274":"..\/input\/datasetku<h2>**Membaca Data**<\/h2>","25ed17a8":"<h2>**Menangani Nilai Non-Angka dan Menangani Nilai Kosong**<\/h2>\nKalo seandainya didataset ada nilai yang non-angka dan nilai kosong, library sklearn enggak bisa memproses data tersebut dan akan memberikan error. Jadi sebelum diolah lebih lanjut data harus dilakukan praproses dulu, yaitu menangani nilai non-angka dan nilai kosong.\n\nUntuk menangani nilai non-angka, library pandas punya fungsi namanya get_dummies(). Untuk menangani nilai kosong, library sklearn punya fungsi namanya SimpleImputer().\n\n<h3>**Cara Kerja Pandas get_dummies()**<\/h3>\n![Table Full](http:\/\/miro.medium.com\/max\/700\/1*psCS6W7FNKJ_auc9fdnA1g.png)\n\nDi tabel atas, liat ada data non-angka di kolom sx. Nah pas fungsi get_dummies dipake, pandas bakal nambahin kolom baru (disebut kolom dummy, makanya nama fungsinya get_dummies) seperti tabel di bawah.\n\n![Tabel Dummy](https:\/\/miro.medium.com\/max\/700\/1*HfhgywtwXtxVcUmQuyu-_w.png)\n\nDia bakal buat kolom female sama male, kalo misalnya di kolom sx nilainya male maka di kolom male di kasih 1 dan kolom female 0 dan berlaku sebaliknya.","ab56e1bc":"<h2>**Membagi Data Menjadi Data Training dan Data Testing**<\/h2>"}}