{"cell_type":{"2c259c12":"code","e2ffd1f7":"code","bec1e97b":"code","068947da":"code","20af1503":"code","e3b412a4":"code","d78c2a75":"code","2e8e2dbc":"code","07af40a8":"code","dc7da477":"code","842ff042":"code","a33fbf4d":"code","fd656daa":"code","d60d8980":"code","74d86d26":"code","0bc5ddac":"code","040f281e":"code","40158c19":"code","219448f5":"code","ec13af7a":"code","8f3a7924":"code","fe4d944f":"code","372a1aab":"code","43cf3701":"code","60cb7cc8":"code","fd2f6677":"code","74a02bf4":"code","c24c11c9":"code","9fd3bcaf":"code","46f2cdd2":"code","c19eab7b":"code","834ac60d":"code","be57276c":"code","cc70976d":"code","951751b4":"code","a6b3dcf2":"code","3a814f6d":"code","3d50f501":"code","d6b82b3d":"code","dec98d3d":"code","0eefbeef":"code","18bfec73":"markdown","60bfc5ae":"markdown","50a0102e":"markdown","34c2f6d7":"markdown","51c7ee52":"markdown","7aa6b2b2":"markdown","203d8181":"markdown","18102600":"markdown","278d0377":"markdown","d2dfb846":"markdown","90214068":"markdown","4171903a":"markdown","b216cb30":"markdown","e65bdac5":"markdown","6e05466e":"markdown","cac9db12":"markdown","38e23fca":"markdown","d55a66b9":"markdown","d7c5a68d":"markdown","d6370304":"markdown","b85147a2":"markdown","985cda60":"markdown","fb125dea":"markdown","249c2606":"markdown"},"source":{"2c259c12":"import pandas as pd\nimport numpy as np\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom ipywidgets import interact\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\n","e2ffd1f7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bec1e97b":"def csv_to_df(filename):\n    df = pd.read_csv(filename,sep=','\n        , decimal='.'\n        )\n    return df\n    \n# Importing train and test\ntrain_df= csv_to_df(\"\/kaggle\/input\/song-popularity-prediction\/train.csv\")\ntest_df= csv_to_df(\"\/kaggle\/input\/song-popularity-prediction\/test.csv\")\ntrain_df.info()","068947da":"#Using Holoviews Package\n# To install use: conda install -c pyviz holoviews bokeh matplotlib\n# Steps here: https:\/\/holoviews.org\/user_guide\/Installing_and_Configuring.html\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport scipy.special\nimport holoviews as hv\nimport random\nfrom holoviews import opts\nfrom holoviews.operation import gridmatrix\nfrom sklearn.impute import SimpleImputer\n\nhv.extension('bokeh')\nhv.extension('matplotlib')\nhv.output(fig='png')","20af1503":"#Looking at the data\ntrain_df.head(2)","e3b412a4":"test_df.describe().T","d78c2a75":"# Amount of NaNs for the train dataset.\ntrain_df.isnull().sum()","2e8e2dbc":"#The plot below show the missing values accross all features.\n%matplotlib inline\n\nplt.figure(figsize=(10,6))\nsns.heatmap(train_df.isna(), cbar=False, cmap='viridis', yticklabels=False)\nplt.show()\n","07af40a8":"useful_cols = [col for col in train_df.columns if col not in ['id', 'song_popularity']]\ncols_dist = [col for col in useful_cols if col not in ['key', 'audio_mode', 'time_signature']]\n\n\nmygraph = []\nfor i,col in enumerate(train_df[useful_cols].columns):\n    if col in cols_dist:\n        plot = hv.Distribution(data=train_df,kdims=[col], vdims=['song_popularity'])\n        mygraph.append(plot)\n    else:\n        plot = hv.Bars(train_df.sort_values(by=col), kdims=[col], label=col).aggregate(function=np.count_nonzero)\n        mygraph.append(plot)\n             \nlayout = hv.Layout(mygraph).cols(4)\nlayout.opts(\n    opts.Distribution(alpha=1, bgcolor='lightgray'),\n    opts.Bars(axiswise=True, bgcolor='lightgray'),\n    opts.Layout(shared_axes=False))\n    ","dc7da477":"#Correlation\nplt.figure(figsize = (12,12))\ncorr_matrix=train_df.corr()\n \nmatrix = np.tril(corr_matrix) # take lower correlation matrix\n\n# Draw the heatmap with the mask\nsns.heatmap(corr_matrix.T, mask=matrix, square=True, cmap = 'magma')\nplt.xticks(size = 18,color = 'red')\nplt.yticks(size = 18,  color = 'red');","842ff042":"#Distribution of the features\nuseful_cols_y = ['loudness', 'energy', 'instrumentalness']\nuseful_cols_x = ['acousticness', 'energy']\n\nmygraph = []\nfor col_x in useful_cols_x:\n    for col_y in useful_cols_y:\n        plot = hv.Scatter(data = train_df, kdims=[col_x], \n                          vdims=[col_y, 'song_popularity'])\n        mygraph.append(plot)\n\nlayout = hv.Layout(mygraph).cols(len(useful_cols_y))\nlayout.opts(\n    #opts(color='song_popularity', cmap=['blue', 'orange'], xticks=10)\n    opts.Scatter(color='song_popularity', cmap=['blue', 'orange'], s=5),\n    opts.Curve(axiswise=True),\n    opts.Layout(shared_axes=False)\n    )\n\n    ","a33fbf4d":"y = train_df[\"song_popularity\"]\nX = train_df.drop(columns=['song_popularity'])\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=1, stratify=y)\n\nresults =[]\nstrategies = ['mean', 'median', 'most_frequent','constant']\nmodel_xgb = xgb.XGBClassifier(use_label_encoder=False, \n                            objective= 'binary:logistic',\n                            verbosity = 0)\n\nfor s in strategies:\n    pipeline = Pipeline([('impute', SimpleImputer(strategy=s)),('model', model_xgb)])\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n    \n    results.append(scores)\n    \nfor method, roc_auc in zip(strategies, results):\n    print('Method: {0}, mean roc_auc: = {1:.3f}, max roc_auc: {2:.3f}'.format(method, np.mean(roc_auc), np.max(roc_auc)))","fd656daa":"data = pd.DataFrame(results, index=strategies)","d60d8980":"# Based on the graph below there are very small difference among the imputations strategies choosen. \n# Therefore, we will select the mean for this work as it has the highest roc_auc.\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=data.T, showmeans=True,\n            meanprops={\"markerfacecolor\":\"white\", \"markeredgecolor\":\"blue\"})","74d86d26":"# Apply imputation - mean\ndef apply_inputer(df):\n    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n    imp_mean = imp_mean.fit(df)\n    df.iloc[:,:] = imp_mean.transform(df)\n    return df\n\ntrain_df = apply_inputer(train_df)\ntest_df = apply_inputer(test_df)","0bc5ddac":"%%time\n!rm -r kuma_utils\n!git clone https:\/\/github.com\/analokmaus\/kuma_utils.git\nimport sys\nsys.path.append(\"kuma_utils\/\")\nfrom kuma_utils.preprocessing.imputer import LGBMImputer\n\nlgbm_imtr = LGBMImputer(n_iter=100, verbose=True)\n\ntrain_lgbmimp = lgbm_imtr.fit_transform(train_df[useful_cols])\ntest_lgbmimp = lgbm_imtr.transform(test_df[useful_cols])\n\n#Adding id and song_popularity back\ntrain_lgbmimp = pd.concat([train_df[['id', 'song_popularity']], train_lgbmimp], axis=1)\ntest_lgbmimp = pd.concat([test_df[['id']], test_lgbmimp], axis=1)\n\n#print(train_lgbmimp.info())\n#print(test_lgbmimp.info())\n#train_df = train_lgbmimp\n#test_df = test_lgbmimp","040f281e":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nsns.set_style('whitegrid')\ntest_df[\"energy\"].plot(kind='hist')\nplt.show()","40158c19":"# The simplest use of qcut is to define the number of quantiles and let pandas figure out how to divide up the data. \n# In the example below, we tell pandas to create 10 equal sized groupings of the data.\n#test_df[\"energy_qualtile\"] = pd.qcut(test_df['energy'].dropna(), q=10, precision=0)\n#test_df[\"energy_qualtile\"].value_counts()\n\ndef get_quantile(df, column_name=\"energy\"):\n    bin_labels_10 = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H' ,'I', 'J']\n    df[column_name+'_qualtile'] = pd.qcut(\n                    df[column_name].dropna(),\n                    q=10,\n                    labels=bin_labels_10)\n    return df","219448f5":"train_df_live = train_df\ntest_df_live = test_df\ntrain_df_live = get_quantile(train_df_live, \"energy\")\ntest_df_live = get_quantile(test_df_live, \"energy\")","ec13af7a":"# Energy as quantile in both train and test datset.\ntrain = hv.Bars(train_df_live.sort_values(by='energy_qualtile'), kdims=['energy_qualtile']).aggregate(function=np.count_nonzero).relabel('Train dataset')\ntest = hv.Bars(test_df_live.sort_values(by='energy_qualtile'), kdims=['energy_qualtile']).aggregate(function=np.count_nonzero).relabel('Test dataset')\ntrain+test","8f3a7924":"# Seting a categorical liveness.\ndef label_liveness(row):\n    if row['liveness'] > 0.6:\n        return True\n    return False\nfeature_name = 'liveness_live'\ntrain_df_live = train_df\ntest_df_live = test_df\n\ntrain_df_live[feature_name] = train_df_live.apply(lambda row: label_liveness(row), axis=1)\ntest_df_live[feature_name] = test_df_live.apply(lambda row: label_liveness(row), axis=1)","fe4d944f":"train = hv.Bars(train_df_live.sort_values(by='liveness_live'), kdims=['liveness_live']).aggregate(function=np.count_nonzero).relabel('Train dataset')\ntest = hv.Bars(test_df_live.sort_values(by='liveness_live'), kdims=['liveness_live']).aggregate(function=np.count_nonzero).relabel('Test dataset')\ntrain+test","372a1aab":"def label_speechiness(row):\n    if row['speechiness'] >= 0.9:\n        return 'poetry'\n    if (row['speechiness'] > 0.5 and row['speechiness'] < 0.9):\n        return 'words'\n    if (row['speechiness'] > 0.3 and row['speechiness'] < 0.5):\n        return 'mix'\n    return 'music'\nfeature_name = 'speech_type'\n\ntrain_df_live[feature_name] = train_df_live.apply(lambda row: label_speechiness(row), axis=1)\ntest_df_live[feature_name] = test_df_live.apply(lambda row: label_speechiness(row), axis=1)","43cf3701":"train = hv.Bars(train_df_live.sort_values(by='speech_type'), kdims=['speech_type']).aggregate(function=np.count_nonzero).relabel('Train dataset')\ntest = hv.Bars(test_df_live.sort_values(by='speech_type'), kdims=['speech_type']).aggregate(function=np.count_nonzero).relabel('Test dataset')\ntrain+test","60cb7cc8":"def label_instrumentalness(row):\n    if row['instrumentalness'] > 0.5:\n        return False\n    return True\nfeature_name = 'instrumentalness_vocal'\n\ntrain_df_live[feature_name] = train_df_live.apply(lambda row: label_instrumentalness(row), axis=1)\ntest_df_live[feature_name] = test_df_live.apply(lambda row: label_instrumentalness(row), axis=1)\n","fd2f6677":"train = hv.Bars(train_df_live.sort_values(by='instrumentalness_vocal'), kdims=['instrumentalness_vocal']).aggregate(function=np.count_nonzero).relabel('Train dataset')\ntest = hv.Bars(test_df_live.sort_values(by='instrumentalness_vocal'), kdims=['instrumentalness_vocal']).aggregate(function=np.count_nonzero).relabel('Test dataset')\ntrain+test","74a02bf4":"#Keep track of results\nresults =[]\nfe_strategies = ['energy_qualtile' , 'liveness_live' , 'speech_type', 'instrumentalness_vocal']","c24c11c9":"# As we see below, all 4 new features are present in the dataset.\ntrain_df_live.info()","9fd3bcaf":"train_df_live.to_csv(\"train_df_live.csv\")\ntest_df_live.to_csv(\"test_df_live.csv\")","46f2cdd2":"train_df = train_df_live\ntest_df = test_df_live\n\ny = train_df[\"song_popularity\"]\nX = train_df.drop(columns=['song_popularity'])\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=1, stratify=y)","c19eab7b":"other_features = ['id', 'song_popularity']\ncategorical_features = ['energy_qualtile', 'liveness_live', 'speech_type', 'instrumentalness_vocal']\n#categorical_features = []\nnumeric_features = [col for col in train_df.columns if col not in other_features+categorical_features]\n","834ac60d":"# Pre processing\nnumeric_transformer = Pipeline(\n    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())]\n)\n\ncategorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_features),\n        (\"cat\", categorical_transformer, categorical_features),\n    ]\n)","be57276c":"# Append classifier to preprocessing pipeline.\n# Now we have a full prediction pipeline.\nmodel_xgb = xgb.XGBClassifier(use_label_encoder=False, \n                            objective= 'binary:logistic',\n                            verbosity = 0)\nclf = Pipeline(\n    steps=[(\"preprocessor\", preprocessor), \n           (\"model\", model_xgb)\n        #(\"classifier\", LogisticRegression())\n          ]\n)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)","cc70976d":"clf.fit(X_train, y_train)\nprint(\"model score: %.3f\" % clf.score(X_test, y_test))","951751b4":"# Plotting AUC\nimport sklearn.metrics as metrics\n# calculate the fpr and tpr for all thresholds of the classification\nprobs = clf.predict_proba(X_test)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","a6b3dcf2":"#Cross validation\nfinal_scores = cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\nprint(f\"Method: XGBClassifier, roc_auc mean: = {final_scores.mean()}, std: {final_scores.std()}\")","3a814f6d":"#clf.fit(X_train, y_train)\nprediction = clf.predict(test_df)","3d50f501":"submission = pd.DataFrame(prediction, index=test_df['id'], columns=[\"song_popularity\"])\nsubmission.index = submission.index.astype(int)\nsubmission.to_csv(\"submission.csv\")","d6b82b3d":"model_xgb = xgb.XGBClassifier(use_label_encoder=False, \n                            objective= 'binary:logistic',\n                            verbosity = 0)\nmodel_linear_svm = LinearSVC(C=10, loss=\"hinge\", max_iter=2000)\nmodel_poly_kernel = SVC(kernel=\"poly\", degree=3, coef0=1, C=5)","dec98d3d":"model_results =[]\nmodel_strategies = [model_xgb, model_linear_svm, model_poly_kernel]\n\nfor m in model_strategies:\n    pipeline = Pipeline([('impute', SimpleImputer(strategy='mean')),('model', m)])\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n    \n    model_results.append(scores)","0eefbeef":"for method, roc_auc in zip(model_strategies, model_results):\n    print('Method: {0}, mean roc_auc: = {1:.3f}, max roc_auc: {2:.3f}'.format(method, np.mean(roc_auc), np.max(roc_auc)))","18bfec73":"LightGBM compared to the SimplerImputer using mean did not provide a better prediction.\nThe following results from public lead board were:\n- SimplerImputer using mean + Feature Engineerings - AUC = 0.53874\n- LightGBM + Feature Engineerings - AUC = 0.52331\n- LightGBM - AUC = 0.53418\n\nThus this notebook will only use SImplerInput and proposed feature engineerings.","60bfc5ae":"## Binning Energy Feature\n\nAs per definition, energy feature is the perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. Thus, I decided to create a new feature containing 10 categories (from A to J).","50a0102e":"# Prediction using xgboost model\n\nIn this section I use xgboost to generate the predictions.\nIn some sections below, I show the comparison of some models, where xgboost has given the best output result.","34c2f6d7":"# Testing Different  Models","51c7ee52":"# Feature Descriptions\n\nThe dataset provided by the competion is a tabular form consisint of:\n- train.csv - the training set. it consists of an id column, the song features, and a target column: song_popularity.\n- test.csv - the test set. it consists of everything in train.csv except song_popularity.\n\nA high levekl overview of the features are:\n- 'id': unique id of the song\n- 'song_duration_ms': duration of song in milliseconds\n- 'acousticness',: a confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n- 'danceability': indicate how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.\n- 'energy': perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. \n- 'instrumentalness': \n- 'key': the estimated overall key of the track.\n- 'liveness': detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n- 'loudness': the overall loudness of a track in decibels (dB)\n- 'audio_mode': indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n- 'speechiness': detects the presence of spoken words in a track. \n- 'tempo': overall estimated tempo of a track in beats per minute (BPM).\n- 'time_signature': estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n- 'audio_valence': describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n- 'song_popularity': target column containing 0 or 1 indicating the popularity of the song.\n\nDetailed information of the features can be found in [Remek Kinas post](https:\/\/www.kaggle.com\/c\/song-popularity-prediction\/discussion\/301616) or in [this blog](https:\/\/www.software.com\/src\/explore-the-data-behind-your-most-productive-music-for-coding) by Software. \n","7aa6b2b2":"# Binning Instrummentalness Feature\n\nInstrumentalness predicts whether a track contains vocals. Instrumentalness is measured on a scale of 0 (likely contains vocal content) to 100 (likely contains no vocal content).\n\nSongs with higher instrumentalness are less likely to have vocals. \n","203d8181":"Now lets create the pipeline to evaluate the new addedd features.","18102600":"# Exploratory Data Analysis\n\nMy EDA is inspired by [Heads or Tails](https:\/\/www.kaggle.com\/headsortails) done in the following [notebook](https:\/\/www.kaggle.com\/headsortails\/song-popularity-eda-live-coding-fun). You can see also his live coding session on youtube [video 1](https:\/\/www.youtube.com\/watch?v=JXF-7rCcR1c&t=1619s) and [video 2](https:\/\/www.youtube.com\/watch?v=2aE6SvCVOis&list=WL&index=2&t=2026s).\n\nI am also using [Holoviews](https:\/\/holoviews.org\/) here for the first time. HoloViews is an open-source Python library.","278d0377":"### Inputation using LightGBM Imputer\nRef. Notebook: https:\/\/www.kaggle.com\/robikscube\/handling-with-missing-data-youtube-stream","d2dfb846":"### Inputation using SimplerInputer","90214068":"## Binning Speechiness Feauture\n\nspeechiness is defined as a feature which detect the presence of spoken words in a track. \nThus, the more exclusively speech-like the recording (e.g. talk show, audio book, poetry) the closer to 1.0 is the value. Values above 0.5 is used to describe tracks that are probably made entirely of spoken words. Values between 0.3 and 0.5 describes tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.3 most likely represent music and other non-speech-like tracks. Please note that those values were select by me.","4171903a":"### Feature Interaction\nBelow I plot the feature interaction between the following two subses ['loudness', 'energy', 'instrumentalness'] and ['acousticness', 'energy'].","b216cb30":"### Correlation Matrix\n\nThe picture below show the correlation matrix (dark color indicates anti-correlation while ligth color indicates strong correlation).\nAs you see in the matrix:\n-  strong anti-correlation between acousticness vs energy and loudness.\n- strong correlation between energy and loudness.\n- No meaningfull correlation between song popularity the rest of the features.\n","e65bdac5":"## What is the best imputation strategy\nLet\u00b4s check what is the best imputation strategy.","6e05466e":"## Binning Liveness Feature\n\nLiveness detects the presence of an audience in a song. Liveness is measured on a scale of 0 (no audience) to 100 (audible audience). To capture that, I created a feature liveness_line to indicate if it a live (liveness > 0.6) song.","cac9db12":"From the two plots above and correlation matrix we can state that:\n- Energy and loudness is positive correlated. You see this as the y variable tends to increase as the x variable increases. Ref. [correlation by khanacademy](https:\/\/www.khanacademy.org\/math\/statistics-probability\/describing-relationships-quantitative-data\/introduction-to-scatterplots\/a\/scatterplots-and-correlation-review).\n- Contrary you can see that acousticness versus energy and loundness: not correlated as there are not clear relationship between those two variables. ","38e23fca":"## Inspirational notebooks\n\n\ud83c\udfb6Song Prediction Kernel\ud83c\udfb6 : https:\/\/www.kaggle.com\/prikshitsingla\/song-prediction-kernel\n\n[Song Pop] Learn along: https:\/\/www.kaggle.com\/joatom\/song-pop-learn-along\n\nSong Popularity: Interactive EDA using plotly: https:\/\/www.kaggle.com\/desalegngeb\/song-popularity-interactive-eda-using-plotly","d55a66b9":"# Song Popularity Competition \n\nThis notebook summarizes my work on the Song Popularity Prediction Competition on Kaggle organized by [Abhishek Thakur].(https:\/\/www.kaggle.com\/abhishek)\n\nThe link to the Kaggle competion is here: https:\/\/www.kaggle.com\/c\/song-popularity-prediction\/submit\n\nThere is an excelent Exploratory Data Analysis (EDA) done by [Heads or Tails](https:\/\/www.kaggle.com\/headsortails) in the following [notebook](https:\/\/www.kaggle.com\/headsortails\/song-popularity-eda-live-coding-fun). \n","d7c5a68d":"# Let\u00b4s Submit Predictions to Kaggle","d6370304":"# Feature Engineering\nThis section I experiment with some simple feature engineering. \nFirst a simple mean inputation is used for the missing values.","b85147a2":"## Feature Interaction based on correlation","985cda60":"## What is the best model\nLet\u00b4s test a subset of models. For now, xgboost, svm annd svc.","fb125dea":"## Missing Values","249c2606":"## Visualization - Individual Feature Distributions\n\nLet\u00b4s use holoviews to show the distribution of each feature.  "}}