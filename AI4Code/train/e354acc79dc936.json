{"cell_type":{"1004a946":"code","a033966c":"code","6969ade2":"code","4651e494":"code","9b842752":"code","5e1ddd36":"code","058780af":"code","6abdf6f1":"code","e444c0d5":"code","ffe24aae":"code","367ccc7a":"markdown","1f10662e":"markdown","e05d9a34":"markdown"},"source":{"1004a946":"# kaggle \uc7ac\uc124\uce58\n\n! pip uninstall kaggle -y\n! pip install kaggle==1.5.6","a033966c":"! mkdir ~\/.kaggle\n! cp drive\/My\\ Drive\/Colab\\ Notebooks\/kaggle.json ~\/.kaggle\n\n! kaggle competitions download -c 2020-ai-air-pollution\n! unzip 2020-ai-air-pollution","6969ade2":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.optim as optim\n\nimport random\n\ntorch.manual_seed(777)","4651e494":"if torch.cuda.is_available():\n  device = torch.device(\"cuda\")\nelse:\n  device = torch.device(\"cpu\")","9b842752":"# \ud30c\uc77c \uc5f4\uae30\ndata = pd.read_csv('air_pollution_train.csv', header=None, skiprows=1)\n\n# \ubd80\uc801\ud569 \ub370\uc774\ud130 drop\ndata = data.dropna()\ndata = np.array(data)\ndata = pd.DataFrame(data)\n\n# \ud559\uc2b5 \ub370\uc774\ud130 \uad6c\uc131\n# \ucd1d 6\uac00\uc9c0\uc758 y\ub97c \uad6c\ud574\uc57c \ud558\ubbc0\ub85c y_train\uc744 \ub9ac\uc2a4\ud2b8\ub85c \uad6c\ud604\ud558\uc5ec \uac01\uac01 \uc800\uc7a5\nx_train = data.loc[:, 0:1]\nprint(x_train)\n\n# \uc2dc\uac04 \uceec\ub7fc\uc758 \ub370\uc774\ud130\ub97c \ubaa8\ub450 24\ub85c \ub098\ub214\n# \uadf8 \uac12\uc744 \uc77c\uc218\uc5d0 \ub123\uc5b4 x_train \uceec\ub7fc\uc744 \ud558\ub098\ub85c \uc904\uc774\uace0, x_train \ub370\uc774\ud130\ub97c \uc5f0\uc18d\uc801\uc73c\ub85c \ubc14\uafc8\nx_train.loc[:, 1] = x_train.loc[:, 0] + x_train.loc[:, 1] \/ 24\nx_train = x_train.loc[:, [1]]\nprint(x_train)\n\ny_train = [] # so2, co, o3, no2, pm10, pm2.5\nfor i in range(2, 8):\n  y_temp = data.loc[:, i]\n  y_temp = np.array(y_temp)\n  y_temp = torch.FloatTensor(y_temp).to(device)\n  y_train.append(y_temp)\n\nx_train = np.array(x_train)\nx_train = torch.FloatTensor(x_train).to(device)","5e1ddd36":"lr = [1e-2, 1e-2, 1e-2, 1e-2, 1, 1] # \uac01 \uc218\uce58\uc758 learning rate\ntotal_epochs = [1500, 1500, 1500, 1500, 1500, 1500] # \uac01 \uc218\uce58\uc758 epoch\nprint_per_epoch = [i \/ 10 for i in total_epochs] # \uac01 \uc218\uce58\uc758 \ud559\uc2b5 \uc9c4\ud589\ub3c4\ub97c \ub098\ud0c0\ub0b4\ub824 \ub530\ub85c \ub9cc\ub4e0 \ubcc0\uc218","058780af":"class NN(torch.nn.Module):\n  def __init__(self):\n    super(NN,self).__init__()\n    self.linear1 = torch.nn.Linear(1, 2, bias = True) # \ub808\uc774\uc5b4 \ucd94\uac00\n    self.linear2 = torch.nn.Linear(2,16, bias = True)\n    self.linear3 = torch.nn.Linear(16, 32, bias = True)\n    self.linear4 = torch.nn.Linear(32, 32, bias = True)\n    self.linear5 = torch.nn.Linear(32,1, bias = True)\n    self.relu = torch.nn.ReLU()\n    \n    torch.nn.init.xavier_uniform_(self.linear1.weight)\n    torch.nn.init.xavier_uniform_(self.linear2.weight)\n    torch.nn.init.xavier_uniform_(self.linear3.weight)\n    torch.nn.init.xavier_uniform_(self.linear4.weight)\n    torch.nn.init.xavier_uniform_(self.linear5.weight)\n  def forward(self,x):\n    out = self.linear1(x)\n    out = self.relu(out)\n    out = self.linear2(out)\n    out = self.relu(out)\n    out = self.linear3(out)\n    out = self.relu(out)\n    out = self.linear4(out)\n    out = self.relu(out)\n    out = self.linear5(out)\n    return out","6abdf6f1":"x_test = pd.read_csv('air_pollution_test.csv', header=None, skiprows=1)\n\nx_test.loc[:, 1] = x_test.loc[:, 0] + x_test.loc[:, 1] \/ 24\nx_test = x_test.loc[:, [1]]\n\nx_test = np.array(x_test)\nx_test = torch.FloatTensor(x_test).to(device)","e444c0d5":"# \uac74\ub108 \ub6f0\uc5b4\ub3c4 \ub418\ub294 \uc218\uce58\uc758 \uc778\ub371\uc2a4 \uc800\uc7a5\nskiptype = []\npredict = [0, 0, 0, 0, 0, 0]\n\nfor pollution_type in range(6):\n  # 0 ~ 5 : SO2, CO, O3, NO2, PM10, PM2.5\n\n  if pollution_type in skiptype:\n    continue\n\n  # \ubc30\uce58 \uc0ac\uc774\uc988 \uc124\uc815\n  batch_size = total_epochs[pollution_type] \/ 5\n  batch_size = int(batch_size)\n\n  train_set = torch.utils.data.TensorDataset(x_train, y_train[pollution_type])\n  data_loader = torch.utils.data.DataLoader(dataset=train_set,\n                                            batch_size=batch_size,\n                                            shuffle=True,\n                                            drop_last=True)\n\n  model = NN().to(device)\n  \n  loss = torch.nn.MSELoss().to(device)\n  optimizer = optim.Adam(model.parameters(), lr=lr[pollution_type])\n\n  mincost = 1e10 # cost \ucd5c\uc19f\uac12\n  minmodel = model\n\n    # \uc2dc\uc791 \ub85c\uadf8 \ucd9c\ub825\n  if pollution_type == 0:   print('Start training SO2')\n  elif pollution_type == 1: print('Start training CO')\n  elif pollution_type == 2: print('Start training O3')\n  elif pollution_type == 3: print('Start training NO2')\n  elif pollution_type == 4: print('Start training PM10')\n  elif pollution_type == 5: print('Start training PM2.5')\n\n  for epoch in range(total_epochs[pollution_type] + 1):\n\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n      X = X.to(device)\n      Y = Y.to(device)\n\n      optimizer.zero_grad()\n      hypothesis = model(X)\n\n      cost = loss(hypothesis, Y)\n      avg_cost += cost \/ len(data_loader)\n\n      cost.backward()\n      optimizer.step()\n    \n    \n    if avg_cost < mincost:\n      mincost = avg_cost\n      minmodel = model\n\n    if epoch % print_per_epoch[pollution_type] == 0:\n      print('Epoch {:6d}\/{} , cost = {}'.format(epoch, total_epochs[pollution_type], cost.item()))\n      \n  with torch.no_grad():\n    minmodel.eval()\n    predict[pollution_type] = minmodel(x_test)","ffe24aae":"sub = pd.read_csv('air_pollution_submission.csv', header=None, skiprows=1)\n\nsub[1] = sub[1].astype(float)\nsub[2] = sub[2].astype(float)\nsub[3] = sub[3].astype(float)\nsub[4] = sub[4].astype(float)\nsub[5] = sub[5].astype(float)\nsub[6] = sub[6].astype(float)\n\nsub = np.array(sub)\nfor i in range(len(sub)):\n  sub[i][1] = predict[0][i]\n  sub[i][2] = predict[1][i]\n  sub[i][3] = predict[2][i]\n  sub[i][4] = predict[3][i]\n  sub[i][5] = predict[4][i]\n  sub[i][6] = predict[5][i]\n\nfor i in range(6):\n  predict[i] = predict[i].detach().cpu().numpy().reshape(-1, 1)\n\nid = np.array([i for i in range(len(x_test))]).reshape(-1, 1)\nresult = np.hstack([id, predict[0], predict[1], predict[2], predict[3], predict[4], predict[5]])\n\nsub = pd.DataFrame(result, columns=[\"Id\", \"SO2\", \"CO\", \"O3\", \"NO2\", \"PM10\", \"PM2.5\"])\nsub['Id'] = sub['Id'].astype(int)\n\nsub\nsub.to_csv('baseline_defense_1_4.csv', index=False)","367ccc7a":"x_train \uceec\ub7fc \ucd95\uc18c, \ub370\uc774\ud130 \ubcc0\ud658","1f10662e":"train set, data loader \uc0ac\uc6a9\ud558\uc5ec \ucd5c\uc801\ud654 \ubc29\ubc95 \ubcc0\uacbd","e05d9a34":"\ub808\uc774\uc5b4 \ucd94\uac00"}}