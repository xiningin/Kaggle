{"cell_type":{"c0681c6e":"code","695ebce4":"code","e3fb1dfc":"code","4121e980":"code","767ded6a":"code","952fb755":"code","23734786":"code","56604910":"code","a9eb6e54":"code","84f64b29":"code","a94fcc5c":"code","9f1710d4":"code","c4be07bb":"code","ff13028a":"code","18630c7c":"code","796d4bf9":"code","ad3339b8":"code","8dccce34":"code","6d030176":"code","c0ea4836":"code","f636badc":"code","4a59414a":"code","6f440068":"code","8c2fe7a3":"code","43b76135":"code","c3199200":"code","ce55714c":"markdown","e6ca1712":"markdown","66d8aac9":"markdown","d2a5bfdf":"markdown","53619029":"markdown","dc63ef83":"markdown","484efcce":"markdown","a5e6fbda":"markdown","75cc5d19":"markdown","a880330a":"markdown","4656d958":"markdown","01efbce8":"markdown"},"source":{"c0681c6e":"#data manipulation\nimport numpy as np\nimport pandas as pd\nimport tqdm\n#file and system operations\nimport os\nimport sys\nassert sys.version_info >= (3,5)\n#visualization imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n#consistent sized plots\nfrom pylab import rcParams\nrcParams['figure.figsize']=12,5\nrcParams['axes.labelsize']=12\nrcParams['ytick.labelsize']=12\nrcParams['xtick.labelsize']=12\n#handle unwanted warnings \nimport warnings\nwarnings.filterwarnings(action='ignore',category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore',category=FutureWarning)\n#view all the columns\npd.options.display.max_columns = None\n#basic text manipulation libraries\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer","695ebce4":"reviews = pd.read_csv('\/kaggle\/input\/mobile-reviews\/K8 Reviews v0.2.csv',delimiter=',',engine='python')\nreviews.head(3)","e3fb1dfc":"#check the number of reviews \nlen(reviews)","4121e980":"#check the basic info\nreviews.info()","767ded6a":"#check the sentiment labels\nreviews['sentiment'].value_counts()","952fb755":"sns.countplot(reviews['sentiment'])\nplt.title('Count of the review sentiments')\nplt.show()","23734786":"#check randomly any of the reviews\nrandom = np.random.randint(1,len(reviews))\nprint(reviews['review'][random])","56604910":"#load the gensim library\nimport gensim","a9eb6e54":"'''\nWrite a function to proprocess the entire dataset \n'''\nstemmer = SnowballStemmer('english')\n\ndef lemmatize_stemming(text):\n    '''This function will lemmatize on Noun POS and stem the text'''\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text,pos='n'))\n    #return (WordNetLemmatizer().lemmatize(text,pos='n'))\n\n#tokenize and lemmatize\ndef preprocess(text):\n    '''Function to break into word tokens, remove stopwords, remove short words and finally to lemmatize and stem the individual tokens'''\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n            result.append(lemmatize_stemming(token))\n    return result","84f64b29":"#check for a sample review\nresult = preprocess('The worst camera I have ever seen. Even my very old configuration mobile phone had a better camera resolution. Battery draining faster.')\nprint(result)","a94fcc5c":"processed_docs = []\n\n#uncomment below line to find the topics for a particular sentiment\n#reviews = reviews[reviews['sentiment']==1]\n\nfor doc in reviews['review']:\n    processed_docs.append(preprocess(doc))","9f1710d4":"'''\nPreview the processed documents\n'''\nprint(processed_docs[:10])","c4be07bb":"'''\nCreate a dictionary of the words which appear in the entire corpus\n'''\ndictionary = gensim.corpora.Dictionary(processed_docs)","ff13028a":"dictionary.keys()[:10]","18630c7c":"#print a few words in the dictionary\ncount = 0\nfor k,v in dictionary.iteritems():\n    print(k,v)\n    count = count + 1\n    if count > 10:\n        break","796d4bf9":"dictionary.filter_extremes(no_below=5,no_above=0.1,keep_n=None)","ad3339b8":"bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]","8dccce34":"bow_corpus[10:20]","6d030176":"document_num = random\nbow_doc_x = bow_corpus[random]\n\nfor i in range(len(bow_doc_x)):\n    print(f'Word {bow_doc_x[i][0]} {dictionary[bow_doc_x[i][0]]} appears {bow_doc_x[i][1]} times')","c0ea4836":"#apply the gensim LDA model and generate 12 topics from the corpus\nseed = 41\nlda_model = gensim.models.LdaMulticore(corpus=bow_corpus,num_topics=12,id2word=dictionary,passes=10,workers=2,\n                                      random_state=seed,minimum_probability=0.05,alpha='symmetric')","f636badc":"'''\nFor each topic, explore each word and its relative weight in the topic\n'''\n\nfor idx,topic in lda_model.print_topics(-1,num_words=15):\n    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n    print(\"\\n\")\n    ","4a59414a":"#import Coherence model from gensim\nfrom gensim.models import CoherenceModel\n#compute coherence score\nlda_model_coherence = CoherenceModel(model=lda_model,texts=processed_docs,dictionary=dictionary,\n                                    coherence='c_v')\ncoherence_lda = lda_model_coherence.get_coherence()\nprint('\\nCoherence Score:',coherence_lda)","6f440068":"#define a helper function\ndef compute_coherence_score(corpus,dictionary,k,a):\n    #instantiate the model instance based on k,a and b\n    lda_model = gensim.models.LdaMulticore(corpus=corpus,id2word=dictionary,num_topics=k,alpha=a,\n                                           passes=10,\n                                           random_state=seed)\n    lda_model_coherence = CoherenceModel(model=lda_model,texts=processed_docs,dictionary=dictionary,coherence='c_v')\n    return lda_model_coherence.get_coherence()\n    ","8c2fe7a3":"#search for the best alpha and the number of topics --> one with the highest coherence score will be the best hyperparameter\nalpha =['symmetric','asymmetric']\n\nfor x in alpha:\n    print('Coherence Model with alpha = {}'.format(x))\n    print('-------------------------------------------')\n    print('\\n')\n    for i in range(5,10):\n        score = compute_coherence_score(corpus=bow_corpus,dictionary=dictionary,k=i,a=x)        \n        print(f'Coherence score with {i} topics is {score}')\n        print('\\n')","43b76135":"'''\nThough the model with alpha='asymmetric' and with 12 topics returned the highest coherence score. For the business use and simplicity, max topics of 7\nand alpha='asymmetric' as the final model. This also returned a comparable coherence score of 0.6262\n'''\nlda_model_final = gensim.models.LdaMulticore(corpus=bow_corpus,num_topics=7,id2word=dictionary,passes=10,workers=2,alpha='asymmetric')","c3199200":"from pprint import pprint\n# Print the Keyword in the 7 topics\npprint(lda_model_final.print_topics())\ndoc_lda = lda_model_final[bow_corpus]","ce55714c":"## _Running LDA using Bag of Words_","e6ca1712":"- _There are no null values or missing values in the dataset_","66d8aac9":"### _Load the Reviews Data_","d2a5bfdf":"### _Gensim doc2bow_\n- _Create a bag of words for each document ie for each document we create a dictionary reporting how many words and how many times those words appear_","53619029":"## _Topic Classification_\n\n- _Topic 1: Nice performance for the budget (all the good reviews)_\n- _Topic 2: Problems with battery charge and drain_\n- _Topic 3: Poor quality of sound and video_\n- _Topic 4: Reliiability issues very early since bought_\n- _Topic 5: Connectivity Issues_ \n- _Topic 6: Poor customer and replacement service_\n- _Topic 7: Quality and Reliability Issues like phone hangs_ ","dc63ef83":"## _Topic Modeling based on Reviews_\n***\n<b>DESCRIPTION<\/b>\n\nHelp a leading mobile brand understand the voice of the customer by analyzing the reviews of their product on Amazon and the topics that customers are talking about. You will perform topic modeling on specific parts of speech. You\u2019ll finally interpret the emerging topics.\n\n<b>Problem Statement: <\/b>\n\nA popular mobile phone brand, Lenovo has launched their budget smartphone in the Indian market. The client wants to understand the VOC (voice of the customer) on the product. This will be useful to not just evaluate the current product, but to also get some direction for developing the product pipeline. The client is particularly interested in the different aspects that customers care about. Product reviews by customers on a leading e-commerce site should provide a good view.\n\n<b>Domain: Amazon reviews for a leading phone brand<\/b>\n\n- Analysis to be done: POS tagging, topic modeling using LDA, and topic interpretation\n\n<b> Content: <\/b>\n\n- Dataset: \u2018K8 Reviews v0.2.csv\u2019\n\n<b>Columns:<\/b>\n- Sentiment: The sentiment against the review (4,5 star reviews are positive, 1,2 are negative)\n- Reviews: The main text of the review\n\n<b>Steps to perform:<\/b>\n\nDiscover the topics in the reviews and present it to business in a consumable format. Employ techniques in syntactic processing and topic modeling.\nPerform specific cleanup, POS tagging, and restricting to relevant POS tags, then, perform topic modeling using LDA. Finally, give business-friendly names to the topics and make a table for business.\n\n<b>Tasks: <\/b>\n- Read the .csv file using Pandas. Take a look at the top few records.\n- Normalize casings for the review text and extract the text into a list for easier manipulation.\n- Tokenize the reviews using NLTKs word_tokenize function.\n- Perform parts-of-speech tagging on each sentence using the NLTK POS tagger.\n- For the topic model, we should  want to include only nouns.\n- Find out all the POS tags that correspond to nouns.\n- Limit the data to only terms with these tags.\n- Lemmatize. \n- Different forms of the terms need to be treated as one.\n- No need to provide POS tag to lemmatizer for now.\n- Remove stopwords and punctuation (if there are any). \n- Create a topic model using LDA on the cleaned up data with 12 topics.\n- Print out the top terms for each topic.\n- What is the coherence of the model with the c_v metric?\n- Analyze the topics through the business lens.\n- Determine which of the topics can be combined.\n- Create topic model using LDA with what you think is the optimal number of topics\n- What is the coherence of the model?\n- The business should  be able to interpret the topics.\n- Name each of the identified topics.\n- Create a table with the topic name and the top 10 terms in each to present to the  business.\n\n","484efcce":"## _Hyperparameter Tuning_\n- _Number of topics K_\n- _Dirichlet hyperparamater alpha: Document Topic Density_\n- _Dirichlet hyperparameter beta: Word-Topic Density_","a5e6fbda":"## _Text Preprocessing_\n_Following steps will be performed_\n- _Tokenization - Split the text into sentences and sentences into words. Lowercase the words and remove any punctuation_\n- _Words that are fewer than 3 characters will be removed_\n- _All stopwords will be removed_\n- _Words are lemmatized - words in third person are changed to first person and words in future and past tense are changed to present tense_\n- _Words are stemmed - words are reduced to the root form_","75cc5d19":"## _Import Libraries and Load the Data_","a880330a":"### _Gensim filter extremes_\n- _Remove or filter the words that appear less than nobelow_\n- _Remove or filter the words that apepar more than noabove (fraction)_\n- _After the above two steps keep only the n most frequent tokens or keep all_","4656d958":"## _Bag of Words on the Dataset_","01efbce8":"- _The data seems to be fairly balanced. However, the objective of this project is to do topic modeling and not sentiment classification_"}}