{"cell_type":{"85f925ee":"code","1ae5a0f3":"code","cb4cc5e0":"code","556d2a7a":"code","d3d11f8c":"code","a79a0654":"code","509585e4":"code","9e8afd97":"code","4d7a4840":"code","f98b418a":"code","be055e38":"code","6bf05221":"code","9670a75a":"code","d0d636f7":"code","d9e1625a":"code","402321e7":"code","83858366":"code","ad4aeba2":"code","e8e00c83":"code","08d43024":"code","aecde0d7":"code","3a6d00d6":"code","8b363710":"markdown","1fa59d1f":"markdown","484dd43f":"markdown","c95310c3":"markdown","fe7b501e":"markdown","057b6050":"markdown","85e130db":"markdown","03a8bd55":"markdown","762f0fe2":"markdown","c3828ba1":"markdown","d4fd8069":"markdown","70c351df":"markdown","3f935f08":"markdown","d400bcca":"markdown"},"source":{"85f925ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ae5a0f3":"df_netflix = pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\")\nprint (df_netflix.shape)\ndf_netflix.head()","cb4cc5e0":"plt.figure(figsize=(10,7))\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"type\", data=df_netflix, palette=\"Set2\")","556d2a7a":"import itertools\nlist_country = [x.split(', ') for x in df_netflix.dropna(subset=['country'])['country'].tolist()]\nlist_country = list(itertools.chain(*list_country))\n\nfrom collections import Counter\ndf_netflix_country_count = pd.DataFrame(Counter(list_country).most_common()[:10], columns=['Country', 'Count'])","d3d11f8c":"plt.figure(figsize=(12,10))\nsns.set(style=\"darkgrid\")\nax = sns.barplot(y=\"Country\", x='Count', data=df_netflix_country_count, palette=\"Set2\", orient='h')","a79a0654":"plt.figure(figsize=(12,10))\nsns.set(style=\"darkgrid\")\nax = sns.countplot(y='release_year', data=df_netflix, palette=\"Set2\", order=df_netflix['release_year'].value_counts().index[0:15])","509585e4":"df_netflix.drop(columns=['director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'type'], inplace=True)\ndf_netflix.head()","9e8afd97":"from nltk.tokenize import word_tokenize\n\ndf_netflix['title_list'] = df_netflix['title'].str.lower()\ndf_netflix['listed_in'] = df_netflix['listed_in'].str.lower()\ndf_netflix['description'] = df_netflix['description'].str.lower()\n\ndf_netflix['title_list'] = df_netflix['title_list'].apply(word_tokenize)\ndf_netflix['listed_in'] = df_netflix['listed_in'].apply(word_tokenize)\ndf_netflix['description'] = df_netflix['description'].apply(word_tokenize)","4d7a4840":"from nltk.corpus import stopwords\nfrom string import punctuation\n\nlist_stopwords = set(stopwords.words('english') + list(punctuation))\ndf_netflix['title_list'] = df_netflix['title_list'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf_netflix['listed_in'] = df_netflix['listed_in'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf_netflix['description'] = df_netflix['description'].apply(lambda x: [word for word in x if word not in list_stopwords])","f98b418a":"import string\n\ndf_netflix['description'] = df_netflix['description'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf_netflix['description'] = df_netflix['description'].apply(lambda x : [word for word in x if len(word) > 0])","be055e38":"df_netflix['title_list'] = df_netflix['title_list'].apply(lambda x : list(set(x)))\ndf_netflix['listed_in'] = df_netflix['listed_in'].apply(lambda x : list(set(x)))\ndf_netflix['description'] = df_netflix['description'].apply(lambda x : list(set(x)))","6bf05221":"from wordcloud import WordCloud\n\nlist_genre = df_netflix['listed_in'].tolist()\nlist_genre = list(itertools.chain(*list_genre))\ngenre = ' '.join(list_genre)\n\nplt.figure(figsize=(16,12))\nwordcloud = WordCloud(max_font_size=50, max_words=100,background_color=\"white\").generate(genre)\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","9670a75a":"list_description = df_netflix['description'].tolist()\nlist_description = list(itertools.chain(*list_description))\ndescription = ' '.join(list_description)\n\nplt.figure(figsize=(16,12))\nwordcloud = WordCloud(max_font_size=50, max_words=100,background_color=\"white\").generate(description)\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","d0d636f7":"!wget -c \"https:\/\/s3.amazonaws.com\/dl4j-distribution\/GoogleNews-vectors-negative300.bin.gz\"\n!gunzip GoogleNews-vectors-negative300.bin.gz","d9e1625a":"import gensim\n\nwv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)","402321e7":"matrix_netflix_vocab = []\nfor list_ in df_netflix.to_numpy():\n    list_[2] = [word for word in list_[2] if word in wv.vocab]\n    list_[3] = [word for word in list_[3] if word in wv.vocab]\n    list_[4] = [word for word in list_[4] if word in wv.vocab]\n    matrix_netflix_vocab.append(list_)\ndf_netflix_vocab = pd.DataFrame(matrix_netflix_vocab, columns=df_netflix.columns)","83858366":"from tqdm import tqdm\n\ndef recommendation(title):\n    matrix_netflix_title_vocab = []\n    for list_ in df_netflix[df_netflix['title'] == title].to_numpy():\n        list_[2] = [word for word in list_[2] if word in wv.vocab]\n        list_[3] = [word for word in list_[3] if word in wv.vocab]\n        list_[4] = [word for word in list_[4] if word in wv.vocab]\n        matrix_netflix_title_vocab.append(list_)\n\n    matrix_similarity = []\n    pbar = tqdm(matrix_netflix_vocab)\n    for list1 in pbar:\n        for list2 in matrix_netflix_title_vocab:\n            score_catg = wv.n_similarity(list1[2], list2[2])\n            score_desc = wv.n_similarity(list1[3], list2[3])\n            try:\n                score_title = wv.n_similarity(list1[4], list2[4])\/2\n            except:\n                score_title = 0\n            if ((list1[1] != list2[1]) & (score_catg > 0.85)):\n                matrix_similarity.append([list1[1], list2[1], score_title, score_catg, score_desc])\n        pbar.update()\n    pbar.close()\n    df_netflix_similarity = pd.DataFrame(matrix_similarity, columns = ['recommendation','title','score_title', 'score_category', 'score_description'])\n    df_netflix_similarity['final_score'] = df_netflix_similarity['score_title'] + df_netflix_similarity['score_category'] + df_netflix_similarity['score_description']\n    return (df_netflix_similarity.sort_values(by=['final_score', 'score_category', 'score_description', 'score_title'], ascending=False).head(10))","ad4aeba2":"recommendation('Avengers: Infinity War')","e8e00c83":"recommendation('Black Panther')","08d43024":"recommendation('Friends')","aecde0d7":"recommendation(\"Article 15\")","3a6d00d6":"recommendation('Transformers: Robots in Disguise')","8b363710":"## **County wise analysis**","1fa59d1f":"## **Preprocessing of the data for RS**","484dd43f":"## **Analyses of TV Shows v\/s Movies**","c95310c3":"## **Download pretrained [word2vec](https:\/\/code.google.com\/archive\/p\/word2vec\/) model from Google**","fe7b501e":"## **WordCloud for Genres**","057b6050":"# **Content Based Recommendation Systems**\nThere are cases when the user is new on a platform and we end up having no prior information on the user. In such scenerios, we recommend similar items based on comments, feedbacks, reviews, description of the items with which the user interacts. \n\nModels\/ Algorithms like TF-IDF score, word2vec are used to capture the similarty in Content Based RS.","85e130db":"### Find Similarities Among Shows using ***Title, Genres, Description***","03a8bd55":"### **Retaining only Relevant Columns**","762f0fe2":"# **Recommendation System**\nRecommendation Systems are the systems that predict and filter the future preferences of user based based on their past experience. They are widely to recommend \n* similar products (Amazon, Flipkart)\n* relevant media, e.g. photos, videos and stories (Instagram)\n* relevant series and movies (Netflix, Amazon Prime Video, Hotstar)\n* relevant songs and podcasts (Spotify)\n* relevant videos (YouTube)\n* similar users, posts (LinkedIn, Twitter, Instagram)\n* relevant dishes and restaurants (Uber Eats, Zomato, Swiggy)\n\nThere are mainly 2 types of Recommendation System\n1. Content Based RS\n1. Collaborative Filtering\n![](https:\/\/user-images.githubusercontent.com\/43712046\/69491476-766eb100-0e5b-11ea-8fa7-6bfc781045a8.png)","c3828ba1":"### **Removing Punctuations and Stopwords**","d4fd8069":"## **Load the Dataset**","70c351df":"## **WordCloud for Description**","3f935f08":"## **RS in action on different shows**","d400bcca":"## **Year wise analysis**"}}