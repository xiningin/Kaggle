{"cell_type":{"139b9bce":"code","3a61b8ce":"code","f715854e":"code","340698fd":"code","09d67e1b":"code","db7c56a6":"code","eac44a0d":"code","84813495":"code","bfbce885":"code","f5646112":"code","b8ca1e35":"code","3206f0ca":"code","c263544a":"code","b64b457c":"code","64a8d671":"code","83b502e8":"code","556297d4":"code","8282b38c":"code","0dff3a52":"code","35cf51d3":"code","626e504d":"code","927cd18b":"code","38f41ece":"code","27709b84":"code","b6a336bc":"code","9b0684a0":"code","a43605cf":"code","734255dc":"code","013fee0c":"code","21639450":"code","af41d139":"code","60cc31f8":"code","67a0f712":"code","b4cac8f2":"code","d084a957":"code","32e66353":"code","38bd975e":"code","019b5eb0":"code","f7be1e11":"code","49b224d4":"code","b5165262":"code","136033a4":"code","48c51d76":"code","3e5a97f3":"code","30f91c8f":"code","d325c14e":"code","c35e9009":"code","a92c036a":"code","79613016":"code","cbd62c8f":"code","9e6a76d6":"code","8b8f8c39":"code","fcd642d1":"code","82b06c21":"code","9dde93c4":"code","067c9564":"code","06815594":"code","8ea8bc31":"code","941e2dcd":"code","5d7be131":"code","da510824":"markdown","706b71fc":"markdown","87bdd642":"markdown","f8af6041":"markdown","998208ee":"markdown","a74b4ded":"markdown","8aa7b094":"markdown","e85d164f":"markdown","08dcd1ee":"markdown","678c35be":"markdown","0747bdd1":"markdown","89ce8e88":"markdown"},"source":{"139b9bce":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","3a61b8ce":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ncombine = [train_df, test_df]","f715854e":"# show the columns of the data frame\nprint(train_df.columns.values) ","340698fd":"train_df.head()","09d67e1b":"# check null value\n# method2 \ntrain_df.isnull().sum()","db7c56a6":"# axis = 1 means column, axis = 0 means row\nnew_train_df = train_df.drop([\"Cabin\"], axis =1) # if no equal sign, then no change\nnew_train_df.isnull().sum()","eac44a0d":"new_train_df = new_train_df.dropna(axis = 0) # axis = 0 means the mean\nnew_train_df.isnull().sum()","84813495":"# get info of a dataset\n# method1 (use get info): we notice that Age and Cabin counts are not 891\nnew_train_df.info()","bfbce885":"# will come back with test data later\n#new_test_df.info()","f5646112":"# show the statistic of each numeric feature\nnew_train_df.describe()","b8ca1e35":"# this command helps find the info of categorical feature\nnew_train_df.describe(include=['O'])","3206f0ca":"# clearly, Name is not correalted with survive, so drop it\nnew_train_df = new_train_df.drop(['Name'], axis = 1)\nnew_train_df.head()","c263544a":"# Ticket has many duplicates, around 541 \/ 712 , so drop it \nnew_train_df = new_train_df.drop(['Ticket'], axis=1)\nnew_train_df.head()","b64b457c":"# no need passengerID \nnew_train_df = new_train_df.drop(['PassengerId'], axis=1)\nnew_train_df.head()","64a8d671":"# check realtionship with features and target value\n# groupby \nnew_train_df[['Pclass', 'Survived']].groupby(['Pclass']).mean().sort_values(by='Survived', ascending=False)","83b502e8":"new_train_df[['Sex', 'Survived']].groupby(['Sex']).mean().sort_values(by='Survived', ascending=False)","556297d4":"new_train_df[['SibSp', 'Survived']].groupby(['SibSp']).mean().sort_values(by='Survived', ascending=False)","8282b38c":"new_train_df[['Parch', 'Survived']].groupby(['Parch']).mean().sort_values(by='Survived', ascending=False)","0dff3a52":"new_train_df[['Embarked', 'Survived']].groupby(['Embarked']).mean().sort_values(by='Survived', ascending=False)","35cf51d3":"g = sns.FacetGrid(new_train_df, col='Survived') # FacetGrid is to set the format \ng.map(plt.hist, 'Age', bins=20)","626e504d":"#grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\ngrid = sns.FacetGrid(new_train_df, col='Survived', row='Pclass')\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","927cd18b":"# grid = sns.FacetGrid(train_df, col='Embarked')\ngrid = sns.FacetGrid(new_train_df, row='Embarked', aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","38f41ece":"grid = sns.FacetGrid(new_train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","27709b84":"new_test_df = test_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\nnew_test_df.head()","b6a336bc":"new_test_df.info()","9b0684a0":"# convert into binary data\nnew_train_df['Sex'] = new_train_df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\nnew_train_df.head()","a43605cf":"new_test_df['Sex'] = new_test_df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\nnew_test_df.head()","734255dc":"new_test_df.isnull().sum()","013fee0c":"new_test_df.describe()","21639450":"# fill the NA value for test dataset\nnew_test_df['Age'] = new_test_df['Age'].fillna(new_test_df['Age'].dropna().median())","af41d139":"new_test_df.isnull().sum()","60cc31f8":"new_test_df['Fare'] = new_test_df['Fare'].fillna(new_test_df['Fare'].dropna().median())\nnew_test_df.isnull().sum()","67a0f712":"# to divide age into different range \nnew_train_df['AgeBand'] = pd.cut(new_train_df['Age'], 5)\nnew_train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","b4cac8f2":"# split age variable\n\nfor dataset in [new_train_df, new_test_df]:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n    dataset['Age'] = dataset['Age'].astype(int)\n","d084a957":"new_train_df = new_train_df.drop(['AgeBand'], axis = 1)","32e66353":"new_train_df","38bd975e":"new_test_df.head()","019b5eb0":"for dataset in [new_train_df, new_test_df]:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1","f7be1e11":"new_train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","49b224d4":"# convert categorical variables into numeric\nfor dataset in [new_train_df, new_test_df]:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","b5165262":"new_train_df.head()","136033a4":"new_train_df.isnull().sum()","48c51d76":"# deal with Fare\nnew_train_df['FareBand'] = pd.cut(new_train_df['Fare'], 4)\nnew_train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","3e5a97f3":"\nfor dataset in [new_train_df, new_test_df]:\n    dataset.loc[ dataset['Fare'] <= 128, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 128) & (dataset['Fare'] <= 256), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 256) & (dataset['Fare'] <= 384), 'Fare'] = 2\n    dataset.loc[(dataset['Fare'] > 384), 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)","30f91c8f":"new_train_df = new_train_df.drop([\"FareBand\"], axis = 1)\nnew_train_df.head()","d325c14e":"new_train_df = new_train_df.drop([\"SibSp\", \"Parch\"], axis = 1)\n\nnew_train_df.head()","c35e9009":"new_test_df = new_test_df.drop([\"SibSp\", \"Parch\"], axis = 1)\nnew_test_df.head()","a92c036a":"Y_train = new_train_df[\"Survived\"]\nX_train = new_train_df.drop([\"Survived\"], axis=1)\nX_test = new_test_df.copy()\nX_train.shape, Y_train.shape, X_test.shape","79613016":"# Logistic is used when the dependent variable is categorical\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","cbd62c8f":"# Find the correaltions \ncoeff_df = pd.DataFrame(new_train_df.columns.delete(0)) # drop the survived column\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","9e6a76d6":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","8b8f8c39":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","fcd642d1":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","82b06c21":"# Perceptron\n# binary neural\n\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","9dde93c4":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","067c9564":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","06815594":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","8ea8bc31":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","941e2dcd":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","5d7be131":"# The best one is random forest\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n})\nsubmission.to_csv(\"Submission.csv\", index=False)","da510824":"# Features data type\nnumerical: Age, Fare, SibSp, Parch\ncategorical: Survivied Sex, Embarked\nOrinal: Pclass","706b71fc":"# clean test datset ","87bdd642":"# Model Evaluation","f8af6041":"# now the data is cleaned ","998208ee":"# Visualization","a74b4ded":"# Feature selection\ncheck the correaltion with them and the target value","8aa7b094":"# Now the data is preapared, we start to fit the model\n* Logistic Regression\n* KNN or k-Nearest Neighbors\n* Support Vector Machines\n* Naive Bayes classifier\n* Decision Tree\n* Random Forrest\n* Perceptron\n* Artificial neural network\n* RVM or Relevance Vector Machine","e85d164f":"# check null value\nmethod1 isnull().sum()\nmethod2 getinfo to find the count is the same or not\n\n# deal with null value\nmethod1: drop the columns with null value  - df.dropna(axis=1) \nmethod2: drop the rows with null value - df.dropna(axis=0)\nmethod3: fill the missing values 0 Imputation df[column].fillna(meanvalue)","08dcd1ee":"## Describe data","678c35be":"# check correaltion with categorical variables and target value","0747bdd1":"# Decide how to deal with null values\n(1) Since cabin has too many missing values, we may drop Cabin column\\\n(2) drop the rows with missing age data","89ce8e88":"# Access Data"}}