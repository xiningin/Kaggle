{"cell_type":{"540cd11f":"code","36c96050":"code","44eb5ba9":"code","312a7a63":"code","4d4bd4ea":"code","90d57df0":"code","34b17694":"code","020812da":"code","d6d233bc":"code","b8bbcea9":"code","6ac515c6":"code","36c53270":"code","7b5eafdb":"code","654d6563":"code","aa896aeb":"code","f2c46cf3":"code","0b416207":"code","e6e3e832":"code","56922ea3":"code","bb3469d8":"code","6fa748d1":"code","df016de1":"code","5e6164f8":"code","5e2664be":"code","cfd27f30":"code","eca887da":"code","c3ac5fcf":"code","bc4b4afc":"code","784a64b9":"code","860db66e":"code","b9f7ae3d":"code","3a04d886":"code","f2771fda":"code","21896748":"code","5ba0c732":"code","c06efbfb":"code","9336c420":"code","a4d62cbe":"markdown","c22b08d6":"markdown","752c2bd1":"markdown","e07fa1bb":"markdown","8cb45798":"markdown","bd7c9d2a":"markdown","7e97f26c":"markdown","a8f22bfb":"markdown","477ef2c9":"markdown","322bad09":"markdown","699800a2":"markdown","57a81e22":"markdown","99d27072":"markdown","0488b470":"markdown","ef9f5f08":"markdown","65d56798":"markdown","c56406e2":"markdown","fcde902e":"markdown","c8294a05":"markdown","bffbcf63":"markdown","24b539b4":"markdown","dd8c7a71":"markdown","977655e4":"markdown","360ecae6":"markdown","ab4afde9":"markdown","e533be7c":"markdown","ba937667":"markdown","bec4f642":"markdown","519b72ef":"markdown","68422ccf":"markdown","e7098c0d":"markdown","491def70":"markdown","643db5e6":"markdown","63563518":"markdown","7dec7870":"markdown","cdb004be":"markdown","64d0a840":"markdown","9a1f7ba8":"markdown","45812f52":"markdown","3e7a7721":"markdown","fccb69a1":"markdown","e68e5cc8":"markdown","ac2b7df4":"markdown","5e511805":"markdown","3bb5cd22":"markdown","99a77fb4":"markdown","42fcab2c":"markdown","bff931af":"markdown","669eb1e2":"markdown"},"source":{"540cd11f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (9,6)","36c96050":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf.head()","44eb5ba9":"df.shape","312a7a63":"sns.heatmap(df.isnull(),cbar = False)\nfor index,val in enumerate(df.isnull().sum()):\n    plt.text(index,val,str(val),bbox=dict(facecolor='w', alpha=1))\nplt.show()","4d4bd4ea":"df.info()","90d57df0":"df.drop([\"Cabin\",\"Name\",\"PassengerId\",\"Ticket\"],axis = 1,inplace = True)\ndf.head()","34b17694":"#Filling the missing value with mean in age column\nmean = df[\"Age\"].mean()\ndf[\"Age\"].fillna(mean, inplace = True)\n\n#Filling the missing value with most occured in embarked column\ndf[\"Embarked\"].fillna(\"S\", inplace = True)\ndf.isnull().sum()","020812da":"#Converting the Age dtype from float to int\ndf[\"Age\"] = np.round(df[\"Age\"])\ndf[\"Age\"] = df[\"Age\"].astype(int)\n\ndf[\"Fare\"] = np.round(df[\"Fare\"])\ndf[\"Fare\"] = df[\"Fare\"].astype(int)","d6d233bc":"df[\"Survived\"] = df[\"Survived\"].replace([0,1],[\"Not Survived\",\"Survived\"])","b8bbcea9":"sns.heatmap(df.corr(),annot=True)\nplt.show()","6ac515c6":"x= [0,1,2]\nsns.countplot(\"Pclass\", data = df, hue =\"Survived\")\nlabels = [\"1st Class\",\"2nd Class\",\"3rd Class\"]\nplt.title(\"Number of Survivors & Non-Survivors According to the Passenger Class \")\nplt.xlabel(\"Passenger Class\")\nplt.ylabel(\"Count\")\nplt.xticks(x, labels)\nplt.show()","36c53270":"sns.countplot(\"Sex\", data = df, hue =\"Survived\")\nplt.show()","7b5eafdb":"sns.countplot(\"Age\",data = df, hue = \"Survived\")\nplt.title(\"Number of Survivors & Non-Survivors According to the Age \")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.xticks(range(0,90,4))\nplt.show()","654d6563":"x = [0,1,2]\nsns.countplot(\"Embarked\", data = df, hue =\"Survived\")\nlabels = [\"Southampton\",\"Cherbourg\", \"Queenstown\"]\nplt.title(\"Number of Survivors & Non-Survivors According to the Embarked \")\nplt.xlabel(\"Embarked\")\nplt.ylabel(\"Count\")\nplt.xticks(x,labels)\nplt.show()","aa896aeb":"le = LabelEncoder()","f2c46cf3":"for val in df.columns:\n    if df[val].dtype == \"O\":\n        df[val] = le.fit_transform(df[val])\ndf.head()","0b416207":"df1 = pd.get_dummies(df[\"Pclass\"]).rename({1:\"1st Class\",2:\"2nd Class\",3:\"3rd Class\"},axis = 1)\n\ndf1[\"1st Class\"] = df1[\"1st Class\"].astype(int)\ndf1[\"2nd Class\"] = df1[\"2nd Class\"].astype(int)\ndf1[\"3rd Class\"] = df1[\"3rd Class\"].astype(int)","e6e3e832":"df['Small Family'] = np.where((df['SibSp'] <= 2) & (df['SibSp'] != 0), 1, 0)\ndf['Lonely Child'] = np.where(df['Parch'] == 1, 1, 0)\n\ndf['Family'] = df['SibSp'] + df['Parch']\ndf.head()","56922ea3":"df2 = pd.concat([df, df1], axis=1)","bb3469d8":"df2.drop([\"Pclass\",\"SibSp\",\"Parch\"],axis = 1, inplace = True)","6fa748d1":"sns.heatmap(df2.corr(),annot = True)","df016de1":"df2.head()","5e6164f8":"X = df2.drop(columns = \"Survived\",axis =1)\nY = df2[\"Survived\"]","5e2664be":"xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size = 0.2, random_state = 0)","cfd27f30":"lo = LogisticRegression(solver='liblinear')","eca887da":"xtrain_predict = lo.fit(xtrain,ytrain)\nxtrain_predict = lo.predict(xtrain)\nlo_train_predict = pd.DataFrame({\"Predicted Value\" : xtrain_predict,\n                              \"Actual Value\" : ytrain\n})\ntrain_lo_as = accuracy_score(xtrain_predict,ytrain)\nprint(\"LogisticRegression Train Data Accuracy Score: \",train_lo_as)\nprint()\nlo_train_predict.head()\n","c3ac5fcf":"xtest_predict = lo.fit(xtest,ytest)\nxtest_predict = lo.predict(xtest)\nlo_test_predict = pd.DataFrame({\"Predicted Value\" : xtest_predict,\n                              \"Actual Value\" : ytest\n})\ntest_lo_as = accuracy_score(xtest_predict,ytest)\nprint(\"LogisticRegression Test Data Accuracy Score: \",test_lo_as)\nprint()\nlo_train_predict.tail()\n","bc4b4afc":"rf = RandomForestClassifier()","784a64b9":"rf.fit(xtrain, ytrain)\nxtrain_predict = rf.predict(xtrain)\nrf_train_predict = pd.DataFrame({\"Predicted Value\" : xtrain_predict,\n                              \"Actual Value\" : ytrain\n})\ntrain_rf_as = accuracy_score(xtrain_predict,ytrain)\nprint(\"Random Forest Train Data Accuracy Score: \",train_rf_as)\nprint()\nrf_train_predict.head()","860db66e":"xtest_predict = rf.fit(xtest,ytest)\nxtest_predict = rf.predict(xtest)\nrf_test_predict = pd.DataFrame({\"Predicted Value\" : xtest_predict,\n                              \"Actual Value\" : ytest\n})\ntest_rf_as = accuracy_score(xtest_predict,ytest)\nprint(\"Random Forest Test Data Accuracy Score: \",test_rf_as)\nprint()\nrf_test_predict.head()\n","b9f7ae3d":"dt = DecisionTreeClassifier()","3a04d886":"dt.fit(xtrain, ytrain)\nxtrain_predict = dt.predict(xtrain)\ndt_train_predict = pd.DataFrame({\"Predicted Value\" : xtrain_predict,\n                              \"Actual Value\" : ytrain\n})\ntrain_dt_as = accuracy_score(xtrain_predict,ytrain)\nprint(\"Decision Tree Classifier Train Data Accuracy Score: \",train_dt_as)\nprint()\ndt_train_predict.head()","f2771fda":"xtest_predict = dt.fit(xtest,ytest)\nxtest_predict = dt.predict(xtest)\ndt_test_predict = pd.DataFrame({\"Predicted Value\" : xtest_predict,\n                              \"Actual Value\" : ytest\n})\ntest_dt_as = accuracy_score(xtest_predict,ytest)\nprint(\"Random Forest Test Data Accuracy Score: \",test_dt_as)\nprint()\ndt_test_predict.head()\n","21896748":"svm = SVC(kernel='rbf', C=100)","5ba0c732":"svm.fit(xtrain, ytrain)\nxtrain_predict = svm.predict(xtrain)\nsvm_train_predict = pd.DataFrame({\"Predicted Value\" : xtrain_predict,\n                              \"Actual Value\" : ytrain\n})\ntrain_svm_as = accuracy_score(xtrain_predict,ytrain)\nprint(\"Support Vector Machine Train Data Accuracy Score: \",train_svm_as)\nprint()\nsvm_train_predict.head()","c06efbfb":"xtest_predict = svm.fit(xtest,ytest)\nxtest_predict = svm.predict(xtest)\nsvm_test_predict = pd.DataFrame({\"Predicted Value\" : xtest_predict,\n                              \"Actual Value\" : ytest\n})\ntest_svm_as = accuracy_score(xtest_predict,ytest)\nprint(\"Random Forest Test Data Accuracy Score: \",test_svm_as)\nprint()\nsvm_test_predict.head()","9336c420":"Train = [train_lo_as,train_rf_as,train_dt_as,train_svm_as]\nTest = [test_lo_as,test_rf_as,test_dt_as,test_svm_as]\n\nAccuracy_Score = pd.DataFrame({\"Train Score\": Train,\"Test Score\":Test})\nAccuracy_Score.index = [\"LogisticRegression\", \"RandomForest\", \"DecisionTreeClassifier\", \"SupportVectorMachine\"]\nAccuracy_Score","a4d62cbe":"#### **Finding the correlation for visualization**","c22b08d6":"From the above plot we come to know that the people in **1st Class were mostly survived**","752c2bd1":"##### **Train Model**","e07fa1bb":"# **Data Visualization** ###","8cb45798":"#### **Finding the Shape of the Dataset**","bd7c9d2a":"##### **Train Model**","7e97f26c":"The dataset as 891 rows and 12 columns\n\nOur Target Variable is **Survived**","a8f22bfb":"#### **Reading the Dataset**","477ef2c9":"#### **Encoding the Dataset with LabelEncoder**","322bad09":"# **Thank You!!**","699800a2":"#### **Visualizing the Age Variable**","57a81e22":"#### **Dropping the Insignificant Variables**","99d27072":"### **Decision Tree**","0488b470":"#### **Visualizing the correlations in the dataset**","ef9f5f08":"#### **Spliting the dataset into two for training and testing purpose**","65d56798":"From the above chart we come to know that the people between the **28 to 32** were survived the most.\n","c56406e2":"#### **Visualizing the Pclass Variable**","fcde902e":"#### **Converting the Datatype**","c8294a05":"# **Training Models**","bffbcf63":"#### **Visualizing the Sex Variable**","24b539b4":"##### **Test Model**","dd8c7a71":"### **Random Forest**","977655e4":"\nFrom the above plot we come to know that **number of more female's were survived when compared to male**.","360ecae6":"# **Importing Libraries** ","ab4afde9":"#### **Concating the Datasets**","e533be7c":"The heatmap shows us wether the column as a null values or not.\n\nWith the help of heatmap we came to know that the column **Age has 177 null values and Cabin has 687 null values and Embarked has 2 null values**.","ba937667":"##### **Test Model**","bec4f642":"##### **Train Model**","519b72ef":"**RandomForest and DecisionTreeClassifier has the highest accuracy score.**","68422ccf":"##### **Test Model**","e7098c0d":"#### **Encoding the Dataset with Dummy Values**","491def70":"#### **Converting the data values for our need**","643db5e6":"# **Train Test and Split**","63563518":"# **Encoding the Data**","7dec7870":"## **Titanic Survivor Predicton**","cdb004be":"### **Support Vector Machines**","64d0a840":"##### **Test Model**","9a1f7ba8":"# **Exploratory Data Analysis** ","45812f52":"#### **Finding the null values that are present in the dataset**","3e7a7721":"### **Logistic Regression**","fccb69a1":"##### **Train Model**","e68e5cc8":"#### **Finding the Dataset info**","ac2b7df4":"\n#### **Filling the missing column values with mean and most occurred**","5e511805":"#### **Dropping the insignificant columns**","3bb5cd22":"#### **Visualizing the Embarked Variable**","99a77fb4":"* **Survived** variable is positively correlated with **Fare,Pcarch** \n* **Pclass** variable is positively correlated with **Embarked,Sex,Age**\n* **Sex** variable is positively correlated with **Embarked,Pclass,Age**\n* **Age** variable is positively correlated with **Fare,Sex**\n* **SibSp** variable is positively correlated with **Fare,Parch,Pclass**\n* **Parch** variable is positively correlated with **Embarked,Fare,SibSp,Pclass and Survived**\n* **Fare** variable is positively correlated with **Parch,SibSp,Age and Survived**\n* **Embarked** variable is positively correlated with **Parch,Pclass,Sex,Pclass**","42fcab2c":"# **Conclusion**","bff931af":"## **Finding the Best Model with the help of Accuracy Score**","669eb1e2":"Dropped the columns Cabin,Name,PassengerId,Ticket because the columns or insignificant for machine learning model"}}