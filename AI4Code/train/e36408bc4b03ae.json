{"cell_type":{"6edc9236":"code","acd6f7c4":"code","cbb02aba":"code","16b366e8":"code","da0fd8e2":"code","d681a98d":"code","a3aa8e1d":"code","cdb46bc1":"code","cb60c1fb":"code","9c80a6cd":"code","47cf785d":"code","d16bb367":"code","270444a2":"code","3d8b2e0a":"code","26f6367e":"code","ed339340":"code","ee24fa68":"code","4ad244fd":"code","560eb3cc":"code","2769f608":"code","9abedc90":"code","c5b462d2":"code","99c21de0":"code","29804498":"code","f4a13c56":"code","1deeaf42":"code","9f788697":"code","45f54494":"code","aa512631":"code","73a8bcc5":"markdown","b279b849":"markdown","f37a3e77":"markdown","d1209824":"markdown","190c4eb5":"markdown","980efc52":"markdown","c7fc7ac9":"markdown","f93f3d63":"markdown","ef03e181":"markdown","7ae568ae":"markdown","ec64dcfd":"markdown"},"source":{"6edc9236":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","acd6f7c4":"data=pd.read_csv(\"..\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","cbb02aba":"data.head(10)","16b366e8":"data.info()","da0fd8e2":"data.describe()","d681a98d":"f,ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","a3aa8e1d":"sns.countplot(data['OverTime'])\nfig = plt.gcf()\nfig.set_size_inches(10,10)\nplt.title('OverTime')","cdb46bc1":"sns.countplot(data['MaritalStatus'])\nfig = plt.gcf()\nfig.set_size_inches(10,10)\nplt.title('Marital Status')","cb60c1fb":"sns.countplot(data['JobRole'])\nfig = plt.gcf()\nfig.set_size_inches(20,14)\nplt.title('Job Role')","9c80a6cd":"sns.countplot(data['Gender'])\nfig = plt.gcf()\nfig.set_size_inches(10,10)\nplt.title('Gender')","47cf785d":"sns.countplot(data['EducationField'])\nfig = plt.gcf()\nfig.set_size_inches(10,10)\nplt.title('Education Field')","d16bb367":"sns.countplot(data['Department'])\nfig = plt.gcf()\nfig.set_size_inches(10,10)\nplt.title('eEpartment')","270444a2":"sns.countplot(data['BusinessTravel'])\nfig = plt.gcf()\nfig.set_size_inches(10,10)\nplt.title('Business travel')","3d8b2e0a":"sns.catplot(x=\"OverTime\", y=\"Age\", kind=\"swarm\", data=data);","26f6367e":"plt.subplots(figsize=(15,5))\nsns.countplot(data.TotalWorkingYears)","ed339340":"plt.subplots(figsize=(15,5))\nsns.countplot(data.Education)","ee24fa68":"sns.countplot(data.NumCompaniesWorked)","4ad244fd":"plt.subplots(figsize=(18,5))\nsns.countplot(data.DistanceFromHome)","560eb3cc":"import time\nimport math\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport scipy as sci\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom hyperopt import hp, tpe, Trials, STATUS_OK\nfrom hyperopt import fmin\n\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom matplotlib import pyplot as plt\nplt.style.use('fivethirtyeight') \n%matplotlib inline","2769f608":"ibm_df = data\ndescription = pd.DataFrame(index=['observations(rows)', 'percent missing', 'dtype', 'range'])\nnumerical = []\ncategorical = []\nfor col in ibm_df.columns:\n    obs = ibm_df[col].size\n    p_nan = round(ibm_df[col].isna().sum()\/obs, 2)\n    num_nan = f'{p_nan}% ({ibm_df[col].isna().sum()}\/{obs})'\n    dtype = 'categorical' if ibm_df[col].dtype == object else 'numerical'\n    numerical.append(col) if dtype == 'numerical' else categorical.append(col)\n    rng = f'{len(ibm_df[col].unique())} labels' if dtype == 'categorical' else f'{ibm_df[col].min()}-{ibm_df[col].max()}'\n    description[col] = [obs, num_nan, dtype, rng]\n\nnumerical.remove('EmployeeCount')\nnumerical.remove('StandardHours')\npd.set_option('display.max_columns', 100)\ndisplay(description)\ndisplay(ibm_df.head())","9abedc90":"def org_results(trials, hyperparams, model_name):\n    fit_idx = -1\n    for idx, fit  in enumerate(trials):\n        hyp = fit['misc']['vals']\n        xgb_hyp = {key:[val] for key, val in hyperparams.items()}\n        if hyp == xgb_hyp:\n            fit_idx = idx\n            break\n            \n    train_time = str(trials[-1]['refresh_time'] - trials[0]['book_time'])\n    acc = round(trials[fit_idx]['result']['accuracy'], 3)\n    train_auc = round(trials[fit_idx]['result']['train auc'], 3)\n    test_auc = round(trials[fit_idx]['result']['test auc'], 3)\n\n    results = {\n        'model': model_name,\n        'parameter search time': train_time,\n        'accuracy': acc,\n        'test auc score': test_auc,\n        'training auc score': train_auc,\n        'parameters': hyperparams\n    }\n    return results","c5b462d2":"lgb_data = ibm_df.copy()\nlgb_dummy = pd.get_dummies(lgb_data[categorical], drop_first=True)\nlgb_data = pd.concat([lgb_dummy, lgb_data], axis=1)\nlgb_data.drop(columns = categorical, inplace=True)\nlgb_data.rename(columns={'Attrition_Yes': 'Attrition'}, inplace=True)\n\ny_df = lgb_data['Attrition'].reset_index(drop=True)\nx_df = lgb_data.drop(columns='Attrition')\ntrain_x, test_x, train_y, test_y = train_test_split(x_df, y_df, test_size=0.20)\n\ndef lgb_objective(space, early_stopping_rounds=50):\n    \n    lgbm = LGBMClassifier(\n        learning_rate = space['learning_rate'],\n        n_estimators= int(space['n_estimators']), \n        max_depth = int(space['max_depth']),\n        num_leaves = int(space['num_leaves']),\n        colsample_bytree = space['colsample_bytree'],\n        feature_fraction = space['feature_fraction'],\n        reg_lambda = space['reg_lambda'],\n        reg_alpha = space['reg_alpha'],\n        min_split_gain = space['min_split_gain']\n    )\n    \n    lgbm.fit(train_x, train_y, \n            eval_set = [(train_x, train_y), (test_x, test_y)],\n            early_stopping_rounds = early_stopping_rounds,\n            eval_metric = 'auc',\n            verbose = False)\n    \n    predictions = lgbm.predict(test_x)\n    test_preds = lgbm.predict_proba(test_x)[:,1]\n    train_preds = lgbm.predict_proba(train_x)[:,1]\n    \n    train_auc = roc_auc_score(train_y, train_preds)\n    test_auc = roc_auc_score(test_y, test_preds)\n    accuracy = accuracy_score(test_y, predictions)  \n\n    return {'status': STATUS_OK, 'loss': 1-test_auc, 'accuracy': accuracy,\n            'test auc': test_auc, 'train auc': train_auc\n           }\n\ntrials = Trials()\nspace = {\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.3)),\n    'n_estimators': hp.quniform('n_estimators', 50, 1200, 25),\n    'max_depth': hp.quniform('max_depth', 1, 15, 1),\n    'num_leaves': hp.quniform('num_leaves', 10, 150, 1),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0), \n    'feature_fraction': hp.uniform('feature_fraction', .3, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'min_split_gain': hp.uniform('min_split_gain', 0.0001, 0.1)\n}\n\nlgb_hyperparams = fmin(fn = lgb_objective, \n                 max_evals = 150, \n                 trials = trials,\n                 algo = tpe.suggest,\n                 space = space\n                 )\n\nlgb_results = org_results(trials.trials, lgb_hyperparams, 'LightGBM')\ndisplay(lgb_results)","99c21de0":"age=pd.DataFrame(data.groupby(\"Age\")[[\"MonthlyIncome\",\"Education\",\"JobLevel\",\"JobInvolvement\",\"PerformanceRating\",\"JobSatisfaction\",\"EnvironmentSatisfaction\",\"RelationshipSatisfaction\",\"WorkLifeBalance\",\"DailyRate\",\"MonthlyRate\"]].mean())\nage[\"Count\"]=data.Age.value_counts(dropna=False)\nage.reset_index(level=0, inplace=True)\nage.head()","29804498":"plt.figure(figsize=(15,10))\nax=sns.barplot(x=age.Age,y=age.Count)\nplt.xticks(rotation=180)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Counts\")\nplt.title(\"Age Counts\")\nplt.show()","f4a13c56":"plt.figure(figsize=(15,10))\nax=sns.barplot(x=age.Age,y=age.MonthlyIncome,palette = sns.cubehelix_palette(len(age.index)))\nplt.xticks(rotation=180)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Monthly Income\")\nplt.title(\"Monthly Income According to Age\")\nplt.show()","1deeaf42":"income=pd.DataFrame(data.groupby(\"JobRole\").MonthlyIncome.mean().sort_values(ascending=False))","9f788697":"plt.figure(figsize=(15,10))\nax=sns.barplot(x=income.index,y=income.MonthlyIncome)\nplt.xticks(rotation=90)\nplt.xlabel(\"Job Roles\")\nplt.ylabel(\"Monthly Income\")\nplt.title(\"Job Roles with Monthly Income\")\nplt.show()","45f54494":"jobrole=pd.DataFrame(data.groupby(\"JobRole\")[\"PercentSalaryHike\",\"YearsAtCompany\",\"TotalWorkingYears\",\"YearsInCurrentRole\",\"WorkLifeBalance\"].mean())\njobrole","aa512631":"labels=data.EducationField.value_counts().index\ncolors=[\"cyan\",\"orange\",\"hotpink\",\"green\",\"navy\",\"#9b59b6\"]\n#explode=[0,0,0,0,0,0]\nsizes=data.EducationField.value_counts().values\nplt.figure(figsize=(7,7))\nplt.pie(sizes,labels=labels,colors=colors,autopct=\"%1.1f%%\")\nplt.title(\"Education Field Counts\",color=\"saddlebrown\",fontsize=15)","73a8bcc5":"### Getting information about the dataset","b279b849":"## Loading the Dataset","f37a3e77":"### Describe the dataset","d1209824":"### Print first 10 datapoints","190c4eb5":"## Importing Libraries","980efc52":"## Plot a correlation map for all numeric variables","c7fc7ac9":"# <font color='orange'> Please Upvote if you found these helpful :)<\/font>","f93f3d63":"<h1 align=\"center\"> HR Analysis, Prediction and Visualization <\/b> <\/h1><br>\n\n![](https:\/\/blueprintbusinesssolutionscorp.com\/wp-content\/uploads\/2017\/12\/attrition.png)\n","ef03e181":" HR Analytics helps us with interpreting organizational data. It finds out the people-related trends in the data and helps the HR Department take the appropriate steps to keep the organization running smoothly and profitably.Attrition is a corporate setup is one of the complex challenges that the people managers and the HRs personnel have to deal with the. \n \n Interestingly, machine learning models can be deployed to predict potential attrition cases, thereby helping the appropriate HR Personnel take the necessary steps to retain the employee.","7ae568ae":"# Breakdown of this notebook:\n1) **Importing the Libraries**\n\n2) **Loading the dataset**\n\n3) **Understanding the Attrition Problem and the Dataset**\n\n4) **Data Visualization:**   \n   - Plot a correlation map for all numeric variables\n   - Overtime\n   - Marital Status\n   - Job Role\n   - Gender\n   - Education Field\n   - Department\n   - Buisness Travel\n   - Relation between Overtime and Age\n   - Total Working Years\n   - Education Level\n   - Number of Companies Worked\n   - Distance from Home\n\n5) **Prediction of Attrition**: LGBM Classifier","ec64dcfd":"# Understanding the Attrition Problem and the Dataset"}}