{"cell_type":{"f3c0bcda":"code","8ff8b564":"code","11ca9e71":"code","9e873f63":"code","51ca2e7f":"code","14a54dfa":"code","1d4e445e":"code","38e31315":"code","2cd48d62":"code","a9133560":"code","409a3619":"code","db3bbc43":"code","eb2d4558":"code","19b65a3b":"code","a1532e8e":"code","0d44dcef":"code","abbb1928":"code","c59309d5":"code","540f9ef4":"code","1dd375fc":"code","617d6230":"code","824a5d37":"code","ac8dcdb4":"code","54a0796e":"code","85d44384":"code","38bb8f7e":"code","46d1f11c":"code","573e2345":"code","841595a9":"code","5ed9fca6":"code","b05acf2b":"code","4d1628c1":"code","fd05d23f":"code","4fdc6cd8":"code","69636355":"code","b4b71670":"code","e419edc8":"code","54fceb5e":"code","6c850481":"code","1e19d0a6":"code","9bceb274":"code","61223a45":"code","a4256226":"code","d9ca1bc9":"code","7472345a":"code","26153ec7":"code","40b42e55":"code","fa0c7962":"code","60ad0653":"code","886d2427":"code","40b98ced":"code","0272cccd":"code","092d7200":"code","c554e153":"code","1a0f5e18":"code","a9e349a5":"code","ae6869c1":"code","0ff75963":"code","59c55611":"code","6c27a32f":"code","7b83ca53":"code","ccc0e344":"code","4972af59":"code","b8a4f9dd":"code","5b7af836":"markdown","7c74cdda":"markdown","90639bdb":"markdown","e70c2202":"markdown","d4cf06a9":"markdown","adca5ce8":"markdown","2edafeb9":"markdown","3c275335":"markdown","668cfa78":"markdown","ad43e44c":"markdown","e9d7081e":"markdown","05094e81":"markdown","2b34fb4b":"markdown"},"source":{"f3c0bcda":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8ff8b564":"train_data= pd.read_csv(\"..\/input\/train_2v.csv\")\ntest_data=pd.read_csv(\"..\/input\/test_2v.csv\")","11ca9e71":"test_data=pd.read_csv(\"..\/input\/test_2v.csv\")","9e873f63":"train_data.head()","51ca2e7f":"train_data.info()","14a54dfa":"print(\"Train_Data Set Shape : {}\" .format(train_data.shape))\n\nprint(\"Test_Data Set Shape : {}\" .format(test_data.shape))","1d4e445e":"train_data.describe()","38e31315":"((train_data.isnull().sum()\/len(train_data))*100).sort_values(ascending=False)","2cd48d62":"((test_data.isnull().sum()\/len(test_data))*100).sort_values(ascending=False)","a9133560":"joined_data=pd.concat([train_data,test_data])","409a3619":"print(\"joined Data Shape : {}\" .format(joined_data.shape))","db3bbc43":"joined_data.iloc[-5:-1]","eb2d4558":"a=((joined_data.isnull().sum()\/len(joined_data))*100).sort_values(ascending=False)","19b65a3b":"a.plot.bar()\nplt.show()","a1532e8e":"train_data['bmi']=train_data.bmi.fillna(train_data.bmi.mean())","0d44dcef":"((train_data.isnull().sum()\/len(train_data))*100).sort_values(ascending=False)","abbb1928":"for i in train_data.select_dtypes(exclude=['int','float']).columns:\n    print('*******',i,'******') \n    print(train_data[i].value_counts())\n    print('*'*30)\n    print()","c59309d5":"from sklearn.preprocessing import LabelEncoder\nle= LabelEncoder()","540f9ef4":"train_data_orignal=train_data.copy()\ntrain_data_orignal.head()","1dd375fc":"train_data['gender']=le.fit_transform(train_data['gender'])\ntrain_data['ever_married'] = le.fit_transform(train_data['ever_married'])\ntrain_data['work_type']= le.fit_transform(train_data['work_type'])\ntrain_data['Residence_type']= le.fit_transform(train_data['Residence_type'])","617d6230":"train_data.info()","824a5d37":"train_data_without_smoke=train_data[train_data.smoking_status.isnull()]","ac8dcdb4":"train_data_with_smoke=train_data[train_data.smoking_status.notnull()]","54a0796e":"train_data_without_smoke.drop('smoking_status',axis=1,inplace=True)","85d44384":"print(\"Shape of Train Data With Smoked Data: {}\".format(train_data_with_smoke.shape))\nprint(\"Shape of Train Data Without Smoked Data: {}\".format(train_data_without_smoke.shape))","38bb8f7e":"train_data_without_smoke.head()","46d1f11c":"train_data_with_smoke.smoking_status=le.fit_transform(train_data_with_smoke.smoking_status)","573e2345":"f,ax=plt.subplots(figsize=(12,10))\n\ncorr=train_data_with_smoke.corr()\n\nsns.heatmap(train_data_with_smoke.corr(),mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(520,14,as_cmap=True),square=True, ax=ax)","841595a9":"train_data_orignal.head()","5ed9fca6":"sns.catplot(x='smoking_status',kind='count',col='stroke',hue='gender',data=train_data_orignal,palette=\"Blues_d\")","b05acf2b":"sns.catplot(x='hypertension',kind='count',col='stroke',hue='gender',data=train_data_orignal,palette=\"rainbow\")","4d1628c1":"sns.catplot(x='heart_disease',kind='count',col='stroke',hue='gender',data=train_data_orignal,palette=\"muted\")","fd05d23f":"sns.catplot(x='ever_married',kind='count',col='stroke',hue='gender',data=train_data_orignal,palette=\"BuGn_r\")","4fdc6cd8":"train_data_with_smoke['stroke'].value_counts()","69636355":"train_data_with_smoke['stroke'].value_counts().plot.bar()","b4b71670":"plt.figure(figsize=(12,5))\n\nplt.title(\"Distribution of age\")\n\nsns.distplot(train_data_with_smoke['age'],color='B')","e419edc8":"sns.catplot(x='smoking_status',kind='count',col='stroke',data=train_data_orignal[(train_data_orignal['age']>50) & (train_data_orignal['age']<70)],palette='rainbow',hue='gender')","54fceb5e":"from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN","6c850481":"ros=RandomOverSampler(random_state=0)\nsmote=SMOTE()","1e19d0a6":"x_resampled,y_resampled =ros.fit_resample(train_data_with_smoke.loc[:,train_data_with_smoke.columns!='stroke'],train_data_with_smoke['stroke'])","9bceb274":"print(\"ROS Shape Of Train Data With Smoke(Independent varriable) :   {}\".format(x_resampled.shape))\nprint(\"ROS Shape Of Train Data With Smoke(dependent varriable) :   {}\".format(y_resampled.shape))","61223a45":"x_resampled_1,y_resampled_1=ros.fit_resample(train_data_without_smoke.loc[:,train_data_without_smoke.columns!='stroke'],train_data_without_smoke['stroke'])","a4256226":"print(\"ROS Shape Of Train Data Without Smoke(Independent varriable) :   {}\".format(x_resampled_1.shape))\nprint(\"ROS Shape Of Train Data Without Smoke(dependent varriable) :   {}\".format(y_resampled_1.shape))","d9ca1bc9":"from sklearn.model_selection import train_test_split","7472345a":"X_train,X_test,y_train,y_test = train_test_split(x_resampled,y_resampled,test_size=0.2)\nprint(X_train.shape)\nprint(X_test.shape)","26153ec7":"X_train_1,X_test_1,y_train_1,y_test_1 = train_test_split(x_resampled_1,y_resampled_1,test_size=0.2)\nprint(X_train_1.shape)\nprint(X_test_1.shape)","40b42e55":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report,accuracy_score,confusion_matrix,auc,roc_auc_score,precision_score,recall_score,roc_curve","fa0c7962":"dtree=DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\npred=dtree.predict(X_test)","60ad0653":"print(classification_report(y_test,pred))\nprint('**'*40)\n\nprint(\"Accuracy Score : {} \".format(accuracy_score(y_test,pred)))\nprint('**'*40)\n\nprint(\"Confusion Matrix : {} \".format(confusion_matrix(y_test,pred)))\nprint('**'*40)\n\n\nprint(\"Precision Score : {} \".format(precision_score(y_test,pred)))\nprint('**'*40)\n\n\nprint(\"Recall Score : {} \".format(recall_score(y_test,pred)))\nprint('**'*40)\n","886d2427":"\ny_pred_prob=dtree.predict_proba(X_test)[::,1]\n\nfpr, tpr, _ = roc_curve(y_test,y_pred_prob)\nauc=roc_auc_score(y_test,y_pred_prob)\n\nplt.plot(fpr,tpr,label=\"AUC SCORE\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n","40b98ced":"#Lets Checkout The Importance Fetature \n\nImp_Feature=pd.DataFrame(dtree.feature_importances_ ,index=train_data_with_smoke.loc[:,train_data_with_smoke.columns!='stroke'].columns,columns=['Importance']).sort_values(by='Importance',ascending=False)\nprint(Imp_Feature)","0272cccd":"Imp_Feature.values","092d7200":"Imp_Feature.plot(kind='bar')","c554e153":"dtree1=DecisionTreeClassifier()\ndtree1.fit(X_train_1,y_train_1)\npred1=dtree1.predict(X_test_1)","1a0f5e18":"print(classification_report(y_test_1,pred1))\nprint('**'*40)\n\nprint(\"Accuracy Score : {} \".format(accuracy_score(y_test_1,pred1)))\nprint('**'*40)\n\nprint(\"Confusion Matrix : {} \".format(confusion_matrix(y_test_1,pred1)))\nprint('**'*40)\n\n\nprint(\"Precision Score : {} \".format(precision_score(y_test_1,pred1)))\nprint('**'*40)\n\n\nprint(\"Recall Score : {} \".format(recall_score(y_test_1,pred1)))\nprint('**'*40)\n","a9e349a5":"y_pred_prob_1=dtree1.predict_proba(X_test_1)[::,1]\n\nfpr, tpr, _ = roc_curve(y_test_1,y_pred_prob_1)\nauc=roc_auc_score(y_test_1,y_pred_prob_1)\n\nplt.plot(fpr,tpr,label=\"AUC SCORE=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","ae6869c1":"test_data.bmi=test_data.bmi.fillna(test_data.bmi.mean())","0ff75963":"((test_data.isnull().sum()\/len(test_data))*100).sort_values(ascending=False)","59c55611":"test_data['gender'] = le.fit_transform(test_data['gender'])\ntest_data['ever_married'] = le.fit_transform(test_data['ever_married'])\ntest_data['work_type']= le.fit_transform(test_data['work_type'])\ntest_data['Residence_type']= le.fit_transform(test_data['Residence_type'])","6c27a32f":"test_data.drop(axis=1,columns=['smoking_status'],inplace=True)","7b83ca53":"test_data.info()","ccc0e344":"final_data=dtree1.predict(test_data)","4972af59":"Result_df=pd.DataFrame(final_data,columns=['Pred'])","b8a4f9dd":"Result_df['Pred'].value_counts()","5b7af836":"Data Preprocessing","7c74cdda":"Cleary bioth the data set has missing value for smoking Status and Bmi. Lets join bith the data set ","90639bdb":"Lets Encode the Smoking status fro train data \n","e70c2202":"Lets Explore the age varriable","d4cf06a9":"lets impute BMI with its Mean as it has very less missing records","adca5ce8":" Dtree Without Smoking Status111","2edafeb9":"Now Lets Split our Resampled Data","3c275335":"# Transformation Of Test Data","668cfa78":"# Now Lets Predict on our Test Data","ad43e44c":"Lets get rid off these Catagorical varriables in a way so that our machine can understand these varriables","e9d7081e":"Handling missing Data","05094e81":"# Lets Create Our Model.{Decision Tree Classifier }","2b34fb4b":"**Handling Catagorical varriable**"}}