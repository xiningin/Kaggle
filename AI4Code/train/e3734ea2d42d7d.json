{"cell_type":{"2f36262c":"code","650e2485":"code","98f81ffd":"code","d7f1ac79":"code","f6ea7639":"code","f6597902":"code","2c1f83be":"code","ff3e3fea":"code","8e993b4f":"code","d1f48a62":"code","97b7a5bb":"code","95820691":"code","a45921aa":"code","3657ca9a":"code","a2a93ae3":"code","c1a25d7a":"code","e169c763":"code","35b5c8b4":"code","c08c27d6":"code","42dd8de4":"code","a2b885d3":"code","b848cbd0":"code","75bc8650":"code","1671c997":"code","e0ba55a1":"code","9b6b7a74":"code","d13725a7":"code","35a03816":"markdown","082c38f3":"markdown","f0aaba35":"markdown","9cd4aa57":"markdown","ebc713e7":"markdown","4a916cf9":"markdown","0556379c":"markdown","50e86ee7":"markdown","a5dda59b":"markdown","bf8c9bbc":"markdown","c962425a":"markdown","3d544500":"markdown","67bd9d1b":"markdown"},"source":{"2f36262c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport cv2\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.util import montage\nimport skimage.filters\nfrom skimage.feature import greycomatrix, greycoprops\nfrom skimage.morphology import label\nfrom scipy import ndimage\nfrom scipy.spatial import distance\nfrom sklearn.cluster import KMeans\nfrom tqdm import tqdm\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nprint(os.listdir(\"..\/input\/almaz-antey-hackathon-l0\"))\n\n# Any results you write to the current directory are saved as output.","650e2485":"train = os.listdir('..\/input\/almaz-antey-hackathon-l0\/train\/train')\nprint(len(train))\n\ntest = os.listdir('..\/input\/almaz-antey-hackathon-l0\/test\/test')\nprint(len(test))","98f81ffd":"ship_dir = '..\/input\/almaz-antey-hackathon-l0\/'\ntrain_image_dir = os.path.join(ship_dir, 'train\/train')\ntest_image_dir = os.path.join(ship_dir, 'test\/test')","d7f1ac79":"# load csv-data files\ntrain_df = pd.read_csv(os.path.join(ship_dir, 'train_classification.csv'))\nsample_sub = pd.read_csv(os.path.join(ship_dir, 'sample_submission.csv'))","f6ea7639":"train_df.head()","f6597902":"train_df.info()","2c1f83be":"train_df.ImageId.to_numpy()","ff3e3fea":"train_df.ImageId.nunique(), train_df.ImageId.shape","8e993b4f":"train_df.EncodedPixels.to_numpy()[5]","d1f48a62":"idx = 10\nfpath = os.path.join(train_image_dir, train_df.ImageId.iloc[idx])\nimage = skimage.io.imread(fpath)","97b7a5bb":"image.shape","95820691":"plt.imshow(image)\nplt.show()","a45921aa":"montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n\ndef multi_rle_encode(img, **kwargs):\n    '''\n    Encode connected regions as separated masks\n    '''\n    labels = label(img)\n    if img.ndim > 2:\n        return [rle_encode(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n    else:\n        return [rle_encode(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n\n# ref: https:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\ndef rle_encode(img, min_max_threshold=1e-4, max_mean_threshold=None):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    if np.max(img) < min_max_threshold:\n        return '' ## no need to encode if it's all zeros\n    if max_mean_threshold and np.mean(img) > max_mean_threshold:\n        return '' ## ignore overfilled mask\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list, **kwargs):\n    # Take the individual ship masks and create a single mask array for all ships\n    all_masks = np.zeros(kwargs['shape'], dtype = np.uint8)\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks |= rle_decode(mask, **kwargs)\n    return all_masks\n\ndef masks_as_color(in_mask_list, **kwargs):\n    # Take the individual ship masks and create a color mask array for each ships\n    all_masks = np.zeros(kwargs['shape'], dtype = np.float)\n    scale = lambda x: (len(in_mask_list) + x + 1) \/ (len(in_mask_list) * 2) ## scale the heatmap image to shift \n    for i,mask in enumerate(in_mask_list):\n        if isinstance(mask, str):\n            all_masks[:,:] += scale(i) * rle_decode(mask, **kwargs)\n    return all_masks","3657ca9a":"# simple data generator\ndef ship_generator(database, image_path, batch_size=9):\n    all_batches = list(database.groupby('ImageId'))\n    out_rgb = []\n    out_masks = []\n    while True:\n        np.random.shuffle(all_batches)  # shuffle\n        for c_img_id, c_masks in all_batches:\n            rgb_path = os.path.join(image_path, c_img_id)\n            c_img = skimage.io.imread(rgb_path)\n            c_mask = np.expand_dims(masks_as_color(c_masks['EncodedPixels'].values, shape=(768, 768)), -1)\n                \n            out_rgb += [c_img]\n            out_masks += [c_mask]\n            if len(out_rgb) >= batch_size:\n                yield np.stack(out_rgb, 0)\/255.0, np.stack(out_masks, 0)\n                out_rgb = []\n                out_masks = []","a2a93ae3":"def plot_one_example(gen):\n    \n    # init random generator\n    if gen is None:\n        raise ValueError('set data generator')\n        \n    train_x, train_y = next(gen)\n    print('x', train_x.shape, train_x.min(), train_x.max())\n    print('y', train_y.shape, train_y.min(), train_y.max())\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n    batch_rgb = montage_rgb(train_x)\n\n    batch_seg = montage(train_y[:, :, :, 0])\n    ax1.imshow(batch_rgb)\n    ax1.set_title('Images')\n    ax2.imshow(batch_seg)\n    ax2.set_title('Segmentations')\n    plt.show()","c1a25d7a":"generator = ship_generator(train_df, train_image_dir, batch_size=4)","e169c763":"plot_one_example(generator)","35b5c8b4":"# Detect the keypoints using SURF Detector\ndetector = cv2.SIFT_create(nfeatures=500, nOctaveLayers=3, contrastThreshold=0.07, \\\n                                       edgeThreshold=5, sigma=0.5)\n\nkeypoints = detector.detect(image, None)","c08c27d6":"# Draw keypoints\ndraw_image = image.copy()\nimg_keypoints = np.empty((image.shape[0], image.shape[1], 3), dtype=np.uint8)\ncv2.drawKeypoints(draw_image, keypoints, img_keypoints, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n\n# Show detected (drawn) keypoints\nplt.figure(figsize=(20, 10))\nplt.imshow(img_keypoints)\nplt.show()","42dd8de4":"train_images = {}\ntest_images = {}\n\ntmp_df = train_df.sample(100, replace=False).reset_index()\ntmp_df = tmp_df.drop_duplicates(subset=['ImageId'])\ntmp_test_df = tmp_df.sample(40, replace=False)\ntmp_df = tmp_df.drop(tmp_test_df.index)\n\nfor cls in tmp_df.IdCls.unique():\n    train_images[cls] = tmp_df[tmp_df.IdCls == cls].ImageId.to_numpy()\n    test_images[cls] = tmp_test_df[tmp_test_df.IdCls == cls].ImageId.to_numpy()","a2b885d3":"for key, value in test_images.items():\n    print(key, len(value))","b848cbd0":"hyp_params = dict(\n    nfeatures = 100,\n    nOctaveLayers = 3,\n    contrastThreshold = 0.03,\n    edgeThreshold = 10,\n    sigma = 1.6)\n\n\ndef sift_features(images):\n    sift_vectors = {}\n    descriptor_list = []\n    sift = cv2.SIFT_create(**hyp_params)\n    for key, value in images.items():\n        features = []\n        for img_name in tqdm(value):\n            img = skimage.io.imread(os.path.join(train_image_dir, img_name))\n            kp, des = sift.detectAndCompute(img, None)\n            if des is None:\n                continue\n           \n            descriptor_list.extend(des)\n            features.append(des)\n        sift_vectors[key] = features\n    return [descriptor_list, sift_vectors]","75bc8650":"sifts = sift_features(train_images) \n# Takes the descriptor list which is unordered one\ndescriptor_list = sifts[0] \n# Takes the sift features that is seperated class by class for train data\nall_bovw_feature = sifts[1] \n# Takes the sift features that is seperated class by class for test data\ntest_bovw_feature = sift_features(test_images)[1] ","1671c997":"def kmeans(k, descriptor_list):\n    kmeans = KMeans(n_clusters = k, n_init=10)\n    kmeans.fit(descriptor_list)\n    visual_words = kmeans.cluster_centers_ \n    return visual_words, kmeans\n    \n# Takes the central points which is visual words    \nvisual_words, knn_alg = kmeans(100, descriptor_list) ","e0ba55a1":"def image_class(all_bovw, centers):\n    dict_feature = {}\n    for key, value in all_bovw.items():\n        category = []\n        for img in tqdm(value):\n            histogram = np.zeros(len(centers))\n            for each_feature in img:\n                ind = np.argmax([distance.cosine(each_feature, center) for center in centers])\n                histogram[ind] += 1\n            category.append(histogram)\n        dict_feature[key] = category\n    return dict_feature\n    \n# Creates histograms for train data    \nbovw_train = image_class(all_bovw_feature, visual_words) \n# Creates histograms for test data\nbovw_test = image_class(test_bovw_feature, visual_words) ","9b6b7a74":"def knn(images, tests):\n    num_test = 0\n    correct_predict = 0\n    class_based = {}\n    \n    for test_key, test_val in tests.items():\n        class_based[test_key] = [0, 0] # [correct, all]\n        for tst in test_val:\n            predict_start = 0\n            minimum = 0\n            key = None\n            for train_key, train_val in images.items():\n                for train in train_val:\n                    if predict_start == 0:\n                        minimum = distance.euclidean(tst, train)\n                        key = train_key\n                        predict_start += 1\n                    else:\n                        dist = distance.cosine(tst, train)\n                        if(dist < minimum):\n                            minimum = dist\n                            key = train_key\n            \n            if(test_key == key):\n                correct_predict += 1\n                class_based[test_key][0] += 1\n            num_test += 1\n            class_based[test_key][1] += 1\n\n    return [num_test, correct_predict, class_based]\n    \n# Call the knn function    \nresults_bowl = knn(bovw_train, bovw_test) ","d13725a7":"def accuracy(results):\n    avg_accuracy = (results[1] \/ results[0]) * 100\n    print(\"Average accuracy: %\" + str(avg_accuracy))\n    print(\"\\nClass based accuracies: \\n\")\n    for key,value in results[2].items():\n        acc = (value[0] \/ value[1]) * 100\n        print(key, acc)\n        \n# Calculates the accuracies and write the results to the console.       \naccuracy(results_bowl)","35a03816":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","082c38f3":"# \u041b\u043e\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 ","f0aaba35":"### \u0412\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438","9cd4aa57":"## \u0414\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0438 \u043c\u0430\u0441\u043a\u0438 \u043a\u043e\u0440\u0430\u0431\u043b\u0435\u0439 \n\n\u041c\u0430\u0441\u043a\u0430 - \u044d\u0442\u043e \u0433\u0435\u043e\u043c\u0435\u0442\u0440\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u043c\u0435\u0441\u0442\u043e \u0442\u043e\u0447\u0435\u043a, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0430\u0435\u0442 \u043c\u0435\u0441\u0442\u043e\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u043d\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0438. \u041e\u0431\u044b\u0447\u043d\u043e \u043c\u0430\u0441\u043a\u0438 \u0437\u0430\u0434\u0430\u044e\u0442, \u043a\u0430\u043a \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0439 \u043c\u0430\u0441\u0441\u0438\u0432 \u0447\u0438\u0441\u0438\u0435\u043b, \u0433\u0434\u0435 1 - \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u0435\u0442 \u043d\u0430\u043b\u0438\u0447\u0438\u044e \u043e\u0431\u044a\u0435\u043a\u0442\u0430, 0 - \u0435\u0433\u043e \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0438\u0435. \u0412 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0435 \u0432\u0430\u043c \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b \u043c\u0430\u0441\u043a\u0438 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043a\u043e\u0440\u0430\u0431\u043b\u044f \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438.","ebc713e7":"# \u0420\u0430\u0431\u043e\u0442\u0430 \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438","4a916cf9":"### \u041e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043c\u0430\u0441\u043e\u043a","0556379c":"## \u0421\u043e\u0431\u0438\u0440\u0430\u0435\u043c \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0438","50e86ee7":"## \u041e\u0431\u0437\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445","a5dda59b":"# \u041c\u0435\u0448\u043e\u043a \u0441\u043b\u043e\u0432 ","bf8c9bbc":"## \u0421\u0442\u0440\u043e\u0438\u043c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0438","c962425a":"### \u0413\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439","3d544500":"## \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\n\n\u0422\u0443\u0442 \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043b\u044e\u0431\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f. \u0414\u043b\u044f \u043f\u0440\u043e\u0441\u0442\u043e\u0442\u044b \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c kNN.","67bd9d1b":"## \u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c"}}