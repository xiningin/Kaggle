{"cell_type":{"5e8796e0":"code","7c8bda97":"code","4c37263b":"code","d1e5760e":"code","73676d9f":"code","dc7f29bd":"code","57ba1c4e":"code","b696efd3":"code","c8572e9f":"code","f34508d0":"code","e45b2f6a":"code","d6a0e650":"code","2eaa1a66":"code","37979320":"code","e79135cc":"code","617c06a1":"code","9254975b":"code","c5bbd695":"code","cd04e6e8":"code","acb9e85d":"code","931dbed8":"code","3aa34978":"code","15de6ecb":"code","f5ec003f":"code","6c20dd0f":"code","4f11ea52":"code","c74738a6":"code","bf67dc0c":"code","729fcd5d":"code","cb5d361e":"code","e9bd79b7":"code","ca65924d":"code","b49f4c24":"code","83edcb18":"code","59324198":"code","aa911e4e":"code","52668581":"code","6483a6ec":"code","ac4598b3":"code","be20ac8e":"code","87f403b8":"code","a6593acc":"code","f47fa3e0":"code","0cff0d07":"code","08ec0aa7":"code","eab7e83e":"code","786b037d":"code","6a0b61e2":"code","f622d6dc":"code","5d318737":"code","0dc7ecb8":"code","f8fb77d8":"code","4156e50d":"code","e52aaa2c":"code","f1c7b047":"code","fc341c49":"markdown","0a9434a5":"markdown","5a8445dc":"markdown","494fafce":"markdown","40ea7aab":"markdown","9be50609":"markdown","77ae2261":"markdown","7e990d7a":"markdown","4af1e139":"markdown","50334f12":"markdown","34378191":"markdown","041cc034":"markdown","3e00a11a":"markdown","808b065f":"markdown","dbf5d6f2":"markdown","55834774":"markdown","76d39718":"markdown","be0ebd75":"markdown","5aef9bcf":"markdown","192209af":"markdown","56dad3f2":"markdown","9fcdc44d":"markdown"},"source":{"5e8796e0":"import cufflinks as cf\ncf.set_config_file(offline=True)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport os\n\nfrom pandas_summary import DataFrameSummary\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7c8bda97":"local_path = \".\/data\/\"\nkaggle_path = \"\/kaggle\/input\/killer-shrimp-invasion\/\"\nexample_submission_filename = \"temperature_submission.csv\"\ntrain_filename = \"train.csv\"\ntest_filename = \"test.csv\"\n\nbase_path = kaggle_path\n\ntemperature_submission = pd.read_csv(base_path + example_submission_filename)\ntest = pd.read_csv(base_path + test_filename)\ntrain = pd.read_csv(base_path + train_filename)","4c37263b":"train = train.drop(\"pointid\", axis=1)\ntest = test.drop(\"pointid\", axis=1)","d1e5760e":"train.head(5)","73676d9f":"len(train), len(test)","dc7f29bd":"train_summary = DataFrameSummary(train)\ntest_summary = DataFrameSummary(test)","57ba1c4e":"train_summary.columns_stats","b696efd3":"train_summary[\"Salinity_today\"]","c8572e9f":"train_summary[\"Temperature_today\"]","f34508d0":"train_summary[\"Substrate\"]","e45b2f6a":"train_summary[\"Depth\"]","d6a0e650":"train_summary[\"Exposure\"]","2eaa1a66":"train_summary[\"Presence\"]","37979320":"import missingno as msno\n%matplotlib inline","e79135cc":"msno.bar(train)","617c06a1":"msno.matrix(train)","9254975b":"msno.heatmap(train)","c5bbd695":"train_without_na = train.dropna()\nlen(train_without_na[train_without_na[\"Presence\"] == 1]), len(train[train[\"Presence\"] == 1])","cd04e6e8":"train[train[\"Presence\"] == 1]","acb9e85d":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimputer = IterativeImputer(max_iter=10)\nimputer.fit(train.drop(labels=[\"Presence\"], axis=1))\nnew_columns = train.drop(labels=[\"Presence\"], axis=1).columns.tolist()","931dbed8":"def impute_missing_data(df, target, imputer, new_columns):\n    df_without_target = df.drop(labels=[target], axis=1) if target in df.columns.tolist() else df\n    arr_imputed = imputer.transform(df_without_target)\n    df_imputed = pd.DataFrame.from_records(arr_imputed, columns=new_columns)\n    if target in df.columns.tolist():\n        df_imputed[\"Presence\"] = df[\"Presence\"]\n    return df_imputed","3aa34978":"target = \"Presence\"\ntrain_imputed = impute_missing_data(train, target, imputer, new_columns)\ntest_imputed = impute_missing_data(test, target, imputer, new_columns)","15de6ecb":"train_imputed[train_imputed[\"Presence\"] == 1]","f5ec003f":"corr = train_imputed.corr()\ncorr.style.background_gradient(cmap='coolwarm', axis=None)","6c20dd0f":"columns_to_bin = [\"Salinity_today\", 'Temperature_today', 'Depth', 'Exposure']\nfor col in columns_to_bin:\n    num_bins = 10\n    if col == \"Depth\":\n        num_bins = [-1.2**i + 0.5 for i in range(40)][::-1]\n    train_imputed[col + '_binned'] = pd.cut(train_imputed[col], num_bins)","4f11ea52":"pt = train_imputed.pivot_table(columns=\"Salinity_today_binned\", values=\"Presence\", aggfunc='count')\npt.iplot(kind='bar', title=\"Number of records per salinity bin\", xTitle=\"Salinity\", yTitle=\"Number of records\")","c74738a6":"pt = train_imputed.pivot_table(columns=\"Salinity_today_binned\", values=\"Presence\", aggfunc=np.count_nonzero)\npt.iplot(kind='bar', title=\"Number of positive presence per salinity bin\", xTitle=\"Salinity\", yTitle=\"Positive presence\")","bf67dc0c":"pt = train_imputed.pivot_table(columns=\"Salinity_today_binned\", values=\"Presence\", aggfunc=np.mean)\npt.iplot(kind='bar', title=\"Average presence per salinity bin\", xTitle=\"Salinity\", yTitle=\"Average presence\")","729fcd5d":"pt = train_imputed.pivot_table(columns=\"Temperature_today_binned\", values=\"Presence\", aggfunc='count')\npt.iplot(kind='bar', title=\"Number of records per temperature bin\", xTitle=\"Temperature\", yTitle=\"Number of records\")","cb5d361e":"pt = train_imputed.pivot_table(columns=\"Temperature_today_binned\", values=\"Presence\", aggfunc=np.count_nonzero)\npt.iplot(kind='bar', title=\"Number of positive presence per temperature bin\", xTitle=\"Temperature\", yTitle=\"Positive presence\")","e9bd79b7":"# average presence per temperature bin\npt = train_imputed.pivot_table(columns=\"Temperature_today_binned\", values=\"Presence\", aggfunc=np.mean)\npt.iplot(kind='bar', title=\"Average presence per temperature bin\", xTitle=\"Temperature\", yTitle=\"Average presence\")","ca65924d":"pt = train_imputed.pivot_table(columns=\"Depth_binned\", values=\"Presence\", aggfunc='count')\npt.iplot(kind='bar', title=\"Number of records per depth bin\", xTitle=\"Depth\", yTitle=\"Number of records\")","b49f4c24":"pt = train_imputed.pivot_table(columns=\"Depth_binned\", values=\"Presence\", aggfunc=np.count_nonzero)\npt.iplot(kind='bar', title=\"Number of positive presence per depth bin\", xTitle=\"Depth\", yTitle=\"Positive presence\")","83edcb18":"pt = train_imputed.pivot_table(columns=\"Depth_binned\", values=\"Presence\", aggfunc=np.mean)\npt.iplot(kind='bar', title=\"Number of positive presence per depth bin\", xTitle=\"Depth\", yTitle=\"Positive presence\")","59324198":"pt = train_imputed.pivot_table(columns=\"Exposure_binned\", values=\"Presence\", aggfunc='count')\npt.iplot(kind='bar', title=\"Number of records per exposure bin\", xTitle=\"Exposure\", yTitle=\"Number of records\")","aa911e4e":"pt = train_imputed.pivot_table(columns=\"Exposure_binned\", values=\"Presence\", aggfunc=np.count_nonzero)\npt.iplot(kind='bar', title=\"Number of positive presence per exposure bin\", xTitle=\"Exposure\", yTitle=\"Positive presence\")","52668581":"# average presence per temperature bin\npt = train_imputed.pivot_table(columns=\"Exposure_binned\", values=\"Presence\", aggfunc=np.mean)\npt.iplot(kind='bar', title=\"Average presence per exposure bin\", xTitle=\"Exposure\", yTitle=\"Average presence\")","6483a6ec":"pt = train_imputed.pivot_table(columns=\"Substrate\", values=\"Presence\", aggfunc='count')\npt.iplot(kind='bar', title=\"Number of records per substrate\", xTitle=\"Substrate\", yTitle=\"Number of records\")","ac4598b3":"pt = train_imputed.pivot_table(columns=\"Substrate\", values=\"Presence\", aggfunc=np.count_nonzero)\npt.iplot(kind='bar', title=\"Number of positive presence per substrate\", xTitle=\"Substrate\", yTitle=\"Positive presence\")","be20ac8e":"# average presence per temperature bin\npt = train_imputed.pivot_table(columns=\"Substrate\", values=\"Presence\", aggfunc=np.mean)\npt.iplot(kind='bar', title=\"Average presence per substrate\", xTitle=\"Substrate\", yTitle=\"Average presence\")","87f403b8":"target = \"Presence\"\nfeature_names_no_imputation = [\"Salinity_today\", \"Temperature_today\", \"Substrate\", \"Depth\", \"Exposure\"]\nfeature_names = new_columns","a6593acc":"# dataset without imputation\ntrain_fill_na = train.fillna(method='ffill')\nX_train_raw = train_fill_na[feature_names_no_imputation]\ny_train_raw = train_fill_na[target].astype('category')","f47fa3e0":"# dataset with imputation\nX_train_imputed = train_imputed[feature_names]\ny_train_imputed = train_imputed[target].astype('category')","0cff0d07":"# dataset z-scored\nimport copy\nfrom sklearn.preprocessing import StandardScaler\n\nX_train_imputed_std = copy.deepcopy(X_train_imputed)\ntest_imputed_std = copy.deepcopy(test_imputed)\ncolumns_to_standardise = ['Salinity_today', 'Temperature_today', 'Depth', 'Exposure']\nfor col in columns_to_standardise:\n    scaler = StandardScaler()\n    scaler.fit(train[[col]])\n    X_train_imputed_std[col] = scaler.transform(X_train_imputed[[col]])\n    test_imputed_std[col] = scaler.transform(test_imputed_std[[col]])\ny_train_imputed_std = y_train_imputed","08ec0aa7":"n_splits = 10","eab7e83e":"from sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import cross_val_score","786b037d":"classifier = DummyClassifier(strategy=\"constant\", constant=0)\n\nscores = cross_val_score(classifier, X_train_raw, y_train_raw,\n                         scoring='roc_auc', cv=n_splits)\n\nscores, scores.mean()","6a0b61e2":"from sklearn.ensemble import ExtraTreesClassifier","f622d6dc":"classifier = ExtraTreesClassifier(n_estimators=10, n_jobs=4)\n\nscores = cross_val_score(classifier, X_train_raw, y_train_raw,\n                         scoring='roc_auc', cv=n_splits)\n\nscores, scores.mean()","5d318737":"classifier = ExtraTreesClassifier(n_estimators=10, n_jobs=4)\n\nscores = cross_val_score(classifier, X_train_imputed, y_train_imputed,\n                         scoring='roc_auc', cv=n_splits)\n\nscores, scores.mean()","0dc7ecb8":"from sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression(solver=\"lbfgs\")\n\nscores = cross_val_score(classifier, X_train_imputed_std, y_train_imputed_std,\n                         scoring='roc_auc', cv=n_splits)\n\nscores, scores.mean()","f8fb77d8":"classifier = LogisticRegression().fit(X_train_imputed_std, y_train_imputed_std)","4156e50d":"predictions = classifier.predict_proba(test_imputed_std[feature_names])","e52aaa2c":"temperature_submission['Presence'] = 1 - predictions\ntemperature_submission.head(5)","f1c7b047":"temperature_submission.to_csv('my_sub.csv', index=False)","fc341c49":"### Substrate","0a9434a5":"Impute missing fields with sklearn IterativeImputer.","5a8445dc":"Create submission","494fafce":"# Dummy model: constant on raw dataset\nThat is, always predict 0","40ea7aab":"### Salinity","9be50609":"Z-scoring happens here.","77ae2261":"#### Salinity_today\nDef: water salinity at depth values between 0-2 metres<br>\nValues mostly in 0\u202610, few in 10\u202630\n\n#### Temperature today\nDef: water temperature at depth values between 0-2 metres<br>\nValues in 1\u20267\n\n#### Substrate\nDef: ocean substrate type, 1 = Sand, 0 = No Sand<br>\n95% is 1 (sand), 5% is 0 (no sand)\n\n#### Depth\nDef: depth of ocean<br>\nValues mostly in -0.5m\u2026-150m, few below -150m\n\n#### Exposure\nDef: wave exposure index at surface in the Baltic Sea<br>\nValues in 0\u202610^6\n\n#### Presence\nOnly 50 presence out of 2626044 records\n\n#### Columns with missing data\nSalinity_today (1.92%), Temperature_today (1.92%), Depth (0.13%), Exposure (0.02%).\n\n#### Conclusions\nVery imbalanced dataset, thus extra attention should be paid not to overfit. Should check if missing data are on records with positive presence.","7e990d7a":"### Temperature","4af1e139":"### Depth","50334f12":"# Model: extra tree on raw dataset","34378191":"# Main imports","041cc034":"# More EDA","3e00a11a":"### Exposure","808b065f":"# Model training preparation","dbf5d6f2":"# Missing data imputation","55834774":"# Model: logistic regression on dataset standardised","76d39718":"# Load data","be0ebd75":"### Feature correlation\nExposure and temperature: 0.63<br>\nSalinity and temperature: 0.53<br>\nSalinity and exposure: 0.18<br>\nDepth and substrate: -0.11<br>\nSalinity and depth: -0.21<br>\nDepth and temperature: -0.32<br>\nExposure and depth: -0.54\n\n### Where are the shrimps?\nSalinity in 0.5\u202610, mostly in 3\u202610<br>\nTemperature between 2 and 6<br>\nDepth between -12 and -0.5, mostly in -3\u20260.5<br>\nExposure between -1k and 600k, mostly in -1k\u2026100k<br>\nSubstrate mostly 0 (no sand)","5aef9bcf":"# Missing data\n\n#### Columns with missing data\nSalinity_today (1.92%), Temperature_today (1.92%), Depth (0.13%), Exposure (0.02%).\n\n#### Missing data correlation\nSalinity_today and Temperature_today missing data are perfectly correlated: if one of them is missing, also the other is missing.\n\n#### Missing data on records with positive presence\n18 (36%) of the 50 records with positive presence have missing data (always the pair Temperature_today and Salinity_today).\n\n#### Conclusions\nSince the dataset is highly imbalanced and 36% of the records with positive presence has missing data, imputation of missing data may play an important role.","192209af":"# Create submission","56dad3f2":"#\u00a0Basic EDA","9fcdc44d":"# Model: extra tree on dataset with imputation"}}