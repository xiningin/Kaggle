{"cell_type":{"397dd978":"code","2747c1f3":"code","c76952d2":"code","f9894c18":"code","e83f5065":"code","89a1a658":"code","af6a2116":"code","c350afaa":"code","46fb3296":"code","9526a90c":"code","9d48be7e":"code","531e5912":"code","8ca4f97f":"code","ddbed97e":"code","ebad5eb8":"code","938ceba1":"code","181c161a":"code","0139b211":"code","e582a6c8":"code","852a58eb":"code","e15749b9":"code","2668c698":"code","dd9f6937":"code","03de8734":"code","e3200572":"code","8c328fc6":"code","e4498f21":"code","3e2f93ad":"code","8ecfc64d":"markdown","b6a9e7a3":"markdown","b25835c9":"markdown","3ecaff07":"markdown","bb48b848":"markdown","2f12048c":"markdown","977ebb60":"markdown","4828ccc0":"markdown","787cab1e":"markdown"},"source":{"397dd978":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2747c1f3":"import tensorflow as tf\nfrom tensorflow import keras","c76952d2":"train = pd.read_csv('\/kaggle\/input\/grocery-sales-forecast-weekend-hackathon\/Grocery_Sales_ParticipantsData\/Train.csv')\ntest = pd.read_csv('\/kaggle\/input\/grocery-sales-forecast-weekend-hackathon\/Grocery_Sales_ParticipantsData\/Test.csv')","f9894c18":"train.head()","e83f5065":"train.shape, test.shape","89a1a658":"series = train.GrocerySales.values\ntime = np.arange(692, dtype=\"float32\")","af6a2116":"def plot_series(time, series, format=\"-\", start=0, end=None):\n    plt.plot(time[start:end], series[start:end], format)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    plt.grid(True)","c350afaa":"plt.figure(figsize=(10, 6))\nplot_series(time, series)\nplt.show()","46fb3296":"split_time = 600\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]\nplt.figure(figsize=(10, 6))\nplot_series(time_train, x_train)\nplt.show()\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplt.show()","9526a90c":"naive_forecast = series[split_time - 1:-1]\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, naive_forecast)","9d48be7e":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid, start=0, end=150)\nplot_series(time_valid, naive_forecast, start=1, end=151)","531e5912":"print(keras.metrics.mean_squared_error(x_valid, naive_forecast).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, naive_forecast).numpy())","8ca4f97f":"def moving_average_forecast(series, window_size):\n    forecast = []\n    for time in range(len(series) - window_size):\n        forecast.append(series[time:time + window_size].mean())\n    return np.array(forecast)\n\nmoving_avg = moving_average_forecast(series, 30)[split_time - 30:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, moving_avg)\n\nprint(keras.metrics.mean_squared_error(x_valid, moving_avg).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, moving_avg).numpy())","ddbed97e":"diff_series = (series[365:] - series[:-365])\ndiff_time = time[365:]\n\nplt.figure(figsize=(10, 6))\nplot_series(diff_time, diff_series)\nplt.show()","ebad5eb8":"diff_moving_avg = moving_average_forecast(diff_series, 50)[split_time - 365 - 50:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, diff_series[split_time - 365:])\nplot_series(time_valid, diff_moving_avg)\nplt.show()","938ceba1":"diff_moving_avg_plus_past = series[split_time - 365:-365] + diff_moving_avg\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, diff_moving_avg_plus_past)\nplt.show()","181c161a":"diff_moving_avg_plus_smooth_past = moving_average_forecast(series[split_time - 370:-360], 10) + diff_moving_avg\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, diff_moving_avg_plus_smooth_past)\nplt.show()","0139b211":"print(keras.metrics.mean_squared_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())","e582a6c8":"window_size = 20\nbatch_size = 32\nshuffle_buffer_size = 1000","852a58eb":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    dataset = tf.data.Dataset.from_tensor_slices(series)\n    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n    dataset = dataset.batch(batch_size).prefetch(1)\n    return dataset","e15749b9":"dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\nprint(dataset)\nl0 = tf.keras.layers.Dense(1, input_shape=[window_size])\nmodel = tf.keras.models.Sequential([l0])\n\nmodel.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\nmodel.fit(dataset,epochs=100,verbose=0)\n\nprint(\"Layer weights {}\".format(l0.get_weights()))","2668c698":"forecast = []\n\nfor time in range(len(series) - window_size):\n    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\n\n\nplt.figure(figsize=(10, 6))\n\nplot_series(time_valid, x_valid)\nplot_series(time_valid, results)","dd9f6937":"print(np.sqrt(keras.metrics.mean_squared_error(x_valid, results).numpy()))\nprint(keras.metrics.mean_absolute_error(x_valid, results).numpy())","03de8734":"tf.keras.backend.clear_session()\ndataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"), \n    tf.keras.layers.Dense(10, activation=\"relu\"), \n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\nhistory = model.fit(dataset,epochs=100,verbose=0)","e3200572":"loss = history.history['loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.show()","8c328fc6":"loss = history.history['loss']\nepochs = range(90, len(loss))\nplot_loss = loss[90:]\nprint(plot_loss)\nplt.plot(epochs, plot_loss, 'b', label='Training Loss')\nplt.show()","e4498f21":"forecast = []\nfor time in range(len(series) - window_size):\n    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\n\n\nplt.figure(figsize=(10, 6))\n\nplot_series(time_valid, x_valid)\nplot_series(time_valid, results)","3e2f93ad":"print(np.sqrt(keras.metrics.mean_squared_error(x_valid, results).numpy()))\nprint(keras.metrics.mean_absolute_error(x_valid, results).numpy())","8ecfc64d":"# Moving Average Approach","b6a9e7a3":"# Train-Validation Split","b25835c9":"# Time-Series Analysis in Python","3ecaff07":"# Deep Neural Network with Adam Optimizer","bb48b848":"# Moving Average with Smooting and Differentiation","2f12048c":"# Naive Forecasting","977ebb60":"Thus deep neural network thus provides the best RMSE compared to other approaches","4828ccc0":"# Neural Network with Multiple Linear Regression","787cab1e":"# Moving Average with differentiation"}}