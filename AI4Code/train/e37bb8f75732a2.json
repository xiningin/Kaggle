{"cell_type":{"e21a56eb":"code","f75dd676":"code","6ad40116":"code","6956d7ef":"code","3fc6788f":"code","396cd3a1":"code","cd16b20c":"code","e1902e64":"code","fa303ad2":"code","b17bf0d5":"code","a3a7fb7c":"code","aa7c36fd":"code","d2f68e4e":"code","318f4a7f":"code","6d6f542e":"code","ddbaa9f5":"code","2a76506e":"markdown","608d7cf6":"markdown","619a262e":"markdown","06b16d3c":"markdown","aaa5c7a6":"markdown","905d294c":"markdown"},"source":{"e21a56eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f75dd676":"X_train = pd.read_csv(\"..\/input\/X_train.csv\")\ny_train = pd.read_csv(\"..\/input\/y_train.csv\")\nX_test = pd.read_csv(\"..\/input\/X_test.csv\")\n\nX_train.head()","6ad40116":"X_test.head()","6956d7ef":"y_train.head()","3fc6788f":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(15, 5))\nsns.countplot(y_train['surface'])\nplt.title('Target distribution', size=20)\nplt.show()","396cd3a1":"missing_data = X_train.isnull().sum()\nprint (\"Missing Data in Training set\")\nmissing_data.tail()","cd16b20c":"missing_data = X_train.isnull().sum()\nprint (\"Missing Data in Test set\")\nmissing_data.tail()","e1902e64":"def feature_engineering(data):\n    \n    df = pd.DataFrame()\n    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 +\n                             data['angular_velocity_Z']**2)** 0.5\n    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 +\n                             data['linear_acceleration_Z'])**0.5\n    data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 +\n                             data['orientation_Z'])**0.5\n   \n    data['acc_vs_vel'] = data['totl_linr_acc'] \/ data['totl_anglr_vel']\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number']:\n            continue\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] \/ df[col + '_min']\n        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])\/2\n    return df","fa303ad2":"%%time\nX_train = feature_engineering(X_train)\nX_test = feature_engineering(X_test)\nprint(X_train.shape)\n","b17bf0d5":"y_train.head()","a3a7fb7c":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ny_train['surface']= le.fit_transform(y_train['surface'])\ny_train.head()","aa7c36fd":"X_train.fillna(0, inplace = True)\nX_test.fillna(0, inplace = True)\nX_train.replace(-np.inf,0,inplace=True)\nX_train.replace(np.inf,0,inplace=True)\nX_test.replace(-np.inf,0,inplace=True)\nX_test.replace(np.inf,0,inplace=True)","d2f68e4e":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\n\ndef k_folds(X, y, X_test, k):\n    folds = StratifiedKFold(n_splits = k, shuffle=True, random_state=20)\n    y_test = np.zeros((X_test.shape[0], 9))\n    y_oof = np.zeros((X.shape[0]))\n    score = 0\n    for i, (train_idx, val_idx) in  enumerate(folds.split(X, y)):\n        clf =  RandomForestClassifier(n_estimators = 100, n_jobs = -1)\n        clf.fit(X_train.iloc[train_idx], y[train_idx])\n        y_oof[val_idx] = clf.predict(X.iloc[val_idx])\n        y_test += clf.predict_proba(X_test) \/ folds.n_splits\n        score += clf.score(X.iloc[val_idx], y[val_idx])\n#         print('Fold: {} score: {}'.format(i,clf.score(X.iloc[val_idx], y[val_idx])))\n    print('Avg Accuracy', score \/ folds.n_splits) \n        \n    return y_oof, y_test ","318f4a7f":"y_oof, y_test = k_folds(X_train, y_train['surface'], X_test, k= 10)","6d6f542e":"confusion_matrix(y_oof,y_train['surface'])","ddbaa9f5":"y_test = np.argmax(y_test, axis=1)\nsubmission = pd.read_csv(os.path.join(\"..\/input\/\",'sample_submission.csv'))\nsubmission['surface'] = le.inverse_transform(y_test)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head(10)","2a76506e":"> **Data Preprocessing**","608d7cf6":"> **Labels Encoding**","619a262e":"> **Data Analysis**","06b16d3c":"> **Handling Missing Values**","aaa5c7a6":"> **Predictions Submission**","905d294c":"> **Model Building**"}}