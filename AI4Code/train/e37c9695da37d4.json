{"cell_type":{"4247ab4f":"code","8486822d":"code","63b97e2d":"code","aefdd656":"code","4b85777b":"code","df3e5206":"code","2ee39566":"code","d0808dba":"code","d100305d":"code","81080f9d":"code","b6b65fa7":"code","f692bd7d":"code","6fba5374":"code","953010a9":"code","14fe5438":"code","8d43d531":"code","008784ce":"code","84e80657":"code","33cccfd9":"code","4c281282":"code","b89f8a98":"code","f9ddb392":"code","fcb507e9":"code","e860cebf":"code","bb667a0e":"code","8560b31f":"code","7afac83b":"code","a799af67":"code","e9c9d53c":"code","3d445c24":"code","03e13679":"code","ce6ae064":"code","c3cf20b4":"code","8a803d96":"code","0acb55cb":"code","a03094e0":"code","d535a150":"code","c00d13ae":"code","3e1df2ec":"code","107f59da":"code","69f65f50":"code","ffcb62bb":"code","f188657d":"code","28c6a8c4":"code","6ee702ee":"code","a00e5e74":"code","0fc5c599":"code","1564125a":"code","e180a1c2":"code","679909b0":"code","410c3d14":"code","40bdb622":"code","505f65a8":"code","a1fdcef8":"code","5018c2d4":"code","26d34bfe":"code","0e84b927":"code","baf98e0a":"code","353e627e":"code","a9df759d":"code","14b85385":"code","c39faed1":"code","769daae4":"code","5d3d3ee9":"code","e2627617":"code","b1784f3b":"markdown","b0962aa6":"markdown","119c14a9":"markdown","b3a781e7":"markdown","d41556d1":"markdown","e02ce1f2":"markdown","b368ec0b":"markdown","5d21a50d":"markdown","8102e81a":"markdown","78f75a3c":"markdown"},"source":{"4247ab4f":"import pandas as pd\nimport csv\nimport numpy as np","8486822d":"train = pd.read_csv(\"..\/input\/amazon-ml-challenge-2021-hackerearth\/train.csv\",escapechar=\"\\\\\", quoting = csv.QUOTE_NONE)","63b97e2d":"train.head()","aefdd656":"train[\"BROWSE_NODE_ID\"].value_counts()","4b85777b":"train[\"BRAND\"].value_counts()","df3e5206":"train[\"TITLE\"].value_counts()","2ee39566":"train[\"DESCRIPTION\"].value_counts()","d0808dba":"train.loc[train['DESCRIPTION'] == \"NH10 DESIGNS Presents 3D HD Quality Hard Shell Back Covers provides protection to your phone from dust and unnecessary scratches. All designs come in HD and waterproof ink promising uncompromised quality. It has very Precise Cutting of Charging, Mic, Speaker & Headphone Jack etc. NH10 DESIGNS Covers are designer covers which comes in very little quantity almost 5-10 pcs so hurry up.The High Quality Back Cover Protects your phone from Scratches and Bumps. This back cover wraps around the back side of the mobile adding an extra layer of protection over your entire device.Our all covers comes with a 6 months printing warranty(Conditions apply).For any enquiry or customise orders.\"]","d100305d":"train.loc[train['TITLE'] == \"Allen Solly Men's Slim fit Casual Shirt\"]","81080f9d":"train[\"brand_in_title\"]=train.apply(lambda row : str(row.TITLE).startswith(str(row.BRAND)), axis=1)\ntrain[\"brand_in_title\"].value_counts()","b6b65fa7":"train[\"brand_in_description\"]=train.apply(lambda row : str(row.DESCRIPTION).startswith(str(row.BRAND)), axis=1)\ntrain[\"brand_in_description\"].value_counts()","f692bd7d":"train[\"brand_in_bullets\"]=train.apply(lambda row : str(row.BULLET_POINTS).startswith(str(row.BRAND)), axis=1)\ntrain[\"brand_in_bullets\"].value_counts()","6fba5374":"def get_near(s):\n  l=str(s).split()\n  k=\"\"\n  for i in l:\n    k=k+i\n  return k;","953010a9":"train[\"BRAND_NAME\"]=train.apply(lambda row: get_near(row.BRAND), axis=1)","14fe5438":"train[\"BRAND_NAME\"].value_counts()","8d43d531":"train[\"TITLE\"]=train.apply(lambda row: str(row.TITLE).replace(str(row.BRAND),str(row.BRAND_NAME)), axis =1)","008784ce":"train[\"DESCRIPTION\"]=train.apply(lambda row: str(row.DESCRIPTION).replace(str(row.BRAND),str(row.BRAND_NAME)), axis =1)","84e80657":"train[\"BULLET_POINTS\"]=train.apply(lambda row: str(row.BULLET_POINTS).replace(str(row.BRAND),str(row.BRAND_NAME)), axis =1)","33cccfd9":"train = train[[\"TITLE\",\"DESCRIPTION\",\"BULLET_POINTS\",\"BRAND_NAME\",\"BROWSE_NODE_ID\"]]","4c281282":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.stem import WordNetLemmatizer\nstop_words = stopwords.words(\"english\")\nlemmatizer = WordNetLemmatizer()","b89f8a98":"nltk.download(\"wordnet\")","f9ddb392":"def preprocess(s):\n  s=str(s).lower()\n  l=[]\n  for k in s.split():\n    if k not in stop_words:\n      l.append(lemmatizer.lemmatize(k))\n  return \" \".join(l)","fcb507e9":"train[\"TITLE\"]=train.apply(lambda x : preprocess(x.TITLE), axis=1)\ntrain[\"DESCRIPTION\"]=train.apply(lambda x : preprocess(x.DESCRIPTION), axis=1)\ntrain[\"BULLET_POINTS\"]=train.apply(lambda x : preprocess(x.BULLET_POINTS), axis=1)","e860cebf":"train.head()","bb667a0e":"train[\"INFO\"]=train.apply(lambda row: str(row.TITLE)+\" \"+str(row.DESCRIPTION)+\" \"+str(row.BULLET_POINTS), axis =1)\ntrain=train[[\"INFO\",\"BROWSE_NODE_ID\"]]","8560b31f":"train.head()","7afac83b":"documents=[text.split() for text in train.INFO]","a799af67":"import gensim","e9c9d53c":"w2v_model = gensim.models.word2vec.Word2Vec(window=4, \n                                            min_count=4, \n                                            workers=8)","3d445c24":"w2v_model.build_vocab(documents)","03e13679":"w2v_model.train(documents, total_examples=len(documents), epochs=50)","ce6ae064":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\nfrom keras import utils\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom sklearn.preprocessing import LabelEncoder","c3cf20b4":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(train.INFO)\n\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Total words\", vocab_size)","8a803d96":"train[\"INFO\"] = pad_sequences(tokenizer.texts_to_sequences(train[\"INFO\"]), maxlen=SEQUENCE_LENGTH)","0acb55cb":"encoder = LabelEncoder()\nencoder.fit(train.INFO.tolist())","a03094e0":"train[\"BROWSE_NODE_ID\"]=encoder.transform(train.BROWSE_NODE_ID.tolist())","d535a150":"embedding_matrix = np.zeros((vocab_size, 100))\nfor word, i in tokenizer.word_index.items():\n    if word in w2v_model.wv:\n        embedding_matrix[i] = w2v_model.wv[word]\nprint(embedding_matrix.shape)","c00d13ae":"del w2v_model","3e1df2ec":"embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=300, trainable=False)","107f59da":"model = Sequential()\nmodel.add(embedding_layer)\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='softmax'))\n\nmodel.summary()","69f65f50":"del embedding_layer","ffcb62bb":"del documents","f188657d":"model.compile(loss='binary_crossentropy',\n              optimizer=\"adam\",\n              metrics=['accuracy'])","28c6a8c4":"callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]","6ee702ee":"history = model.fit(train.INFO, train.BROWSE_NODE_ID,\n                    batch_size=1703,\n                    100,\n                    validation_split=0.1,\n                    verbose=1,\n                    callbacks=callbacks)","a00e5e74":"del train","0fc5c599":"test = pd.read_csv(\"..\/input\/amazon-ml-challenge-2021-hackerearth\/test.csv\",escapechar=\"\\\\\", quoting = csv.QUOTE_NONE)","1564125a":"test.head()","e180a1c2":"test[\"BRAND_NAME\"]=train.apply(lambda row: get_near(row.BRAND), axis=1)","679909b0":"test[\"TITLE\"]=test.apply(lambda row: str(row.TITLE).replace(str(row.BRAND),str(row.BRAND_NAME)), axis =1)","410c3d14":"test[\"DESCRIPTION\"]=test.apply(lambda row: str(row.DESCRIPTION).replace(str(row.BRAND),str(row.BRAND_NAME)), axis =1)","40bdb622":"test[\"BULLET_POINTS\"]=test.apply(lambda row: str(row.BULLET_POINTS).replace(str(row.BRAND),str(row.BRAND_NAME)), axis =1)","505f65a8":"test = test[[\"PRODUCT_ID\",\"TITLE\",\"DESCRIPTION\",\"BULLET_POINTS\",\"BRAND_NAME\"]]","a1fdcef8":"test[\"TITLE\"]=test.apply(lambda x : preprocess(x.TITLE), axis=1)\ntest[\"DESCRIPTION\"]=test.apply(lambda x : preprocess(x.DESCRIPTION), axis=1)\ntest[\"BULLET_POINTS\"]=test.apply(lambda x : preprocess(x.BULLET_POINTS), axis=1)","5018c2d4":"test.head()","26d34bfe":"test[\"INFO\"]=test.apply(lambda row: str(row.TITLE)+\" \"+str(row.DESCRIPTION)+\" \"+str(row.BULLET_POINTS), axis = 1)\ntest=test[[\"PRODUCT_ID\",\"INFO\"]]","0e84b927":"test.head()","baf98e0a":"test[\"INFO\"] = pad_sequences(tokenizer.texts_to_sequences(test[\"INFO\"]), maxlen=SEQUENCE_LENGTH)","353e627e":"test.BROWSE_NODE_ID = encoder.transform(test.BROWSE_NODE_ID.tolist())","a9df759d":"test.BROWSE_NODE_ID = test.BROWSE_NODE_ID.reshape(-1,1)","14b85385":"score = model.evaluate(test.INFO, test.BROWSE_NODE_ID, batch_size=BATCH_SIZE)\nprint()\nprint(\"ACCURACY:\",score[1])\nprint(\"LOSS:\",score[0])","c39faed1":"submission = pd.DataFrame(columns = [\"PRODUCT_ID\",\"BROWSE_NODE_ID\"])","769daae4":"def predictor(row):\n  ans = model.predict(row.INFO)\n  ans = np.argmax(ans, axis=1)\n  submission.append({\"PRODUCT_ID\":row.PRODUCT_ID, \"BROWSE_NODE_ID\": ans},ignore_index=False) ","5d3d3ee9":"test.apply(lambda row: predictor(row))","e2627617":"submission.to_csv(\".\/submission.csv\")","b1784f3b":"# Download all NLTK needed and stop words\nIf in stop words remove it If word not in brand name then lemmatize it or lemmatize all words","b0962aa6":"# Model Building and Label Encoder","119c14a9":"# Load Data","b3a781e7":"# Creating Input","d41556d1":"I could not complete training and testing due to lack of resourses. Let me know if anyone who has enough resources about the results.\nThank you","e02ce1f2":"# Check if all columns start with brand name","b368ec0b":"# Replace all Brand Names in all columns","5d21a50d":"# Get brand Name as a single word","8102e81a":"# Get all value counts","78f75a3c":"# Evaluate"}}