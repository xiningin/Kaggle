{"cell_type":{"66503dcd":"code","6c68a7d2":"code","b997b978":"code","c160127e":"code","95e7a0d8":"code","276f2b8f":"code","5b969a78":"code","1b14709a":"code","cd527d94":"code","d696c271":"code","e860aa6a":"code","da051c1d":"code","6f658fdf":"code","62936cfb":"code","afef719f":"code","8d53ab9a":"code","fe076b60":"code","a2d209dd":"code","b8533e95":"code","775b85b0":"code","895a2ebf":"code","b2f2e9c5":"code","b29a55fa":"code","00603697":"code","314208ae":"code","2be2b042":"code","57fcc73f":"code","01c19e4d":"code","d941e313":"code","8a743f91":"code","28862985":"code","b4efc006":"code","69bab5e0":"code","80bf54a1":"markdown","8a7587cf":"markdown","e89b35e0":"markdown","6fea19cb":"markdown"},"source":{"66503dcd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6c68a7d2":"import numpy as np\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score","b997b978":"import nltk\nnltk.download('stopwords')","c160127e":"print(stopwords.words('english'))","95e7a0d8":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv', encoding = \"ISO-8859-1\")","276f2b8f":"train.shape","5b969a78":"train.head()","1b14709a":"train.isnull().sum()","cd527d94":"train['target'].value_counts()","d696c271":"train['text'].duplicated().sum()","e860aa6a":"train['text']","da051c1d":"X = train['text']\nY = train['target']","6f658fdf":"print(X)\nprint(Y)","62936cfb":"test = pd.read_csv('..\/input\/nlp-getting-started\/test.csv', encoding = \"ISO-8859-1\")","afef719f":"test.shape","8d53ab9a":"test.head()","fe076b60":"test.isnull().sum()","a2d209dd":"port_stem = PorterStemmer()","b8533e95":"def stemming(content):   \n  stemmed_content = re.sub('[^a-zA-Z]',' ', content)  \n  stemmed_content = stemmed_content.lower() \n  stemmed_content = stemmed_content.split() \n  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] \n  stemmed_content = ' '.join(stemmed_content)\n  return stemmed_content","775b85b0":"train['text'] = train['text'].apply(stemming)","895a2ebf":"test['text'] = test['text'].apply(stemming)","b2f2e9c5":"print(train['text'])","b29a55fa":"print(test['text'])","00603697":"#Vectorizer\nvectorizer = TfidfVectorizer(max_features = 600)\nvectorizer.fit(X)","314208ae":"X = vectorizer.transform(X)","2be2b042":"text = vectorizer.transform(test['text'])","57fcc73f":"print(X)","01c19e4d":"print(text)","d941e313":"from sklearn.tree import DecisionTreeClassifier\nmodel1 = DecisionTreeClassifier(criterion='entropy', random_state=0)\nmodel1.fit(X,Y)","8a743f91":"DT_pred = model1.predict(text)","28862985":"sub = pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","b4efc006":"sub['target']=DT_pred\nsub.to_csv('DecisionTree.csv', index=False)","69bab5e0":"sub","80bf54a1":"**Decision Tree**","8a7587cf":"Test Data","e89b35e0":"Train Data","6fea19cb":"**Text Processing**"}}