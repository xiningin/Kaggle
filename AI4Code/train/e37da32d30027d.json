{"cell_type":{"0eba79dd":"code","641a6644":"code","595bbe6f":"code","1df7e52b":"code","211acf8b":"code","197aa365":"code","2fd62874":"code","ce414a33":"code","75bc68ab":"code","f189244e":"code","2ff40116":"code","3a44dd46":"code","58064fee":"code","36e2171a":"code","29938de9":"code","9d4ae65c":"code","21258808":"code","85a805d6":"code","e4c75dfb":"code","deda68cd":"code","b9913def":"code","5c0c4c10":"markdown","a0943b29":"markdown","ddabaded":"markdown","8a468b19":"markdown","b981787d":"markdown","cf41769e":"markdown","2c290e40":"markdown","cbc9d625":"markdown","446532fe":"markdown","2496b776":"markdown","aea39aa1":"markdown","ebccb98d":"markdown","74b7742c":"markdown","6e720bd4":"markdown","4febd4bb":"markdown","d6ea9266":"markdown","d6a0310d":"markdown","ee208717":"markdown","8bf1d1d3":"markdown","aea79f78":"markdown","ba63b42b":"markdown","10a087e7":"markdown","4cb2fb4f":"markdown","33a144ab":"markdown","c87ea122":"markdown","b931d0e6":"markdown","1bf4a89a":"markdown","6c73fbd1":"markdown","87cd7dd9":"markdown"},"source":{"0eba79dd":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","641a6644":"!wget https:\/\/raw.githubusercontent.com\/alexeygrigorev\/mlbookcamp-code\/master\/chapter-06-trees\/CreditScoring.csv","595bbe6f":"df = pd.read_csv('CreditScoring.csv')\ndf.columns = df.columns.str.lower()","1df7e52b":"status_values = {\n    1: 'ok',\n    2: 'default',\n    0: 'unk'\n}\n\ndf.status = df.status.map(status_values)\n\n\nhome_values = {\n    1: 'rent',\n    2: 'owner',\n    3: 'private',\n    4: 'ignore',\n    5: 'parents',\n    6: 'other',\n    0: 'unk'\n}\n\ndf.home = df.home.map(home_values)\n\nmarital_values = {\n    1: 'single',\n    2: 'married',\n    3: 'widow',\n    4: 'separated',\n    5: 'divorced',\n    0: 'unk'\n}\n\ndf.marital = df.marital.map(marital_values)\n\nrecords_values = {\n    1: 'no',\n    2: 'yes',\n    0: 'unk'\n}\n\ndf.records = df.records.map(records_values)\n\njob_values = {\n    1: 'fixed',\n    2: 'partime',\n    3: 'freelance',\n    4: 'others',\n    0: 'unk'\n}\n\ndf.job = df.job.map(job_values)","211acf8b":"for c in ['income', 'assets', 'debt']:\n    df[c] = df[c].replace(to_replace=99999999, value=0)","197aa365":"df = df[df.status != 'unk'].reset_index(drop=True)","2fd62874":"df['default'] = (df.status == 'default').astype(int)\ndel df['status']","ce414a33":"categorical = list(df.dtypes[df.dtypes == 'object'].index)\nnumerical = []\nfor column in df.columns:\n    if column not in categorical:\n        numerical.append(column)\n        \nnumerical","75bc68ab":"from sklearn.model_selection import train_test_split\ndf_full_train, df_test = train_test_split(df, test_size = 0.2, random_state = 1)\ndf_train, df_val = train_test_split(df_full_train, test_size = 0.25, random_state = 1)\n\ndf_full_train = df_full_train.reset_index()\ndf_train = df_train.reset_index()\ndf_val = df_val.reset_index()\ndf_test = df_test.reset_index()","f189244e":"from sklearn.metrics import roc_auc_score\n\nnumerical_features_auc = numerical.copy()\nnumerical_features_auc.remove('default')\n\nfor feature in numerical_features_auc:\n    if roc_auc_score(df['default'],df[feature]) < 0.5: \n        print ('%s %.3f' % (feature, roc_auc_score(df['default'],-df[feature])))\n    else:\n        print ('%s %.3f' % (feature, roc_auc_score(df['default'],df[feature])))","2ff40116":"columns = ['seniority', 'income', 'assets', 'records', 'job', 'home']\ndatasets = [df_full_train, df_train, df_test, df_val]\n\nfor dataset in datasets:\n    dataset = dataset[columns]\n\nfrom sklearn.feature_extraction import DictVectorizer\ndv = DictVectorizer(sparse = False)\n\ntrain_dict = df_train[columns].to_dict(orient = 'records')\ny_train = df_train.default.values\ndel df_train['default']\nX_train = dv.fit_transform(train_dict)\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(solver = 'liblinear', C = 1.0, max_iter = 1000)\nmodel.fit(X_train, y_train)\n","3a44dd46":"val_dict = df_val[columns].to_dict(orient = 'records')\ny_val = df_val.default.values\ndel df_val['default']\nX_val = dv.transform(val_dict)\n\ny_pred = model.predict_proba(X_val)[:, 1]\nroc_auc_score(y_val, y_pred).round(3)","58064fee":"scores = []\nthresholds = np.linspace(0,1,101)\n\nfor t in thresholds: \n    actual_positive = (y_val == 1)\n    actual_negative = (y_val == 0)\n\n    predict_positive = (y_pred >= t)\n    predict_negative = (y_pred <= t)\n    \n    tp = (predict_positive & actual_positive).sum()\n    tn = (predict_negative & actual_negative).sum()\n    \n    fp = (predict_positive & actual_negative).sum()\n    fn = (predict_negative & actual_positive).sum()\n    \n    p = tp \/ (tp + fp)\n    r = tp \/ (tp + fn)\n    \n    scores.append((t, p, r))\n    \ncolumns = ['threshold', 'precision', 'recall']\ndf_scores = pd.DataFrame(scores, columns = columns)\n\nplt.plot(df_scores.threshold,df_scores.precision, label = 'precision')\nplt.plot(df_scores.threshold,df_scores.recall, label = 'recall')\nplt.xlabel('threshold')\nplt.ylabel('metric')\nplt.legend()","36e2171a":"scores = []\nthresholds = np.linspace(0,1,101)\n\nfor t in thresholds: \n    actual_positive = (y_val == 1)\n    actual_negative = (y_val == 0)\n\n    predict_positive = (y_pred >= t)\n    predict_negative = (y_pred <= t)\n    \n    tp = (predict_positive & actual_positive).sum()\n    tn = (predict_negative & actual_negative).sum()\n    \n    fp = (predict_positive & actual_negative).sum()\n    fn = (predict_negative & actual_positive).sum()\n    \n    p = tp \/ (tp + fp)\n    r = tp \/ (tp + fn)\n    f1_score = 2 * ((p * r) \/ (p + r))\n    \n    scores.append((t, p, r, f1_score))\n\ncolumns = ['threshold', 'precision', 'recall', 'f1_score']\ndf_scores = pd.DataFrame(scores, columns = columns)\n\nmax_f1_score = df_scores['f1_score'].max()\nprint(max_f1_score)\ndf_scores[df_scores['f1_score'] == max_f1_score].threshold","29938de9":"columns = ['seniority', 'income', 'assets', 'records', 'job', 'home']","9d4ae65c":"\ndef train(df_train, y_train, C=1.0):\n    dicts = df_train[columns].to_dict(orient='records')\n\n    dv = DictVectorizer(sparse=False)\n    X_train = dv.fit_transform(dicts)\n\n    model = LogisticRegression(solver = 'liblinear', C=C, max_iter=1000)\n    model.fit(X_train, y_train)\n    \n    return dv, model","21258808":"def predict(df, dv, model):\n    dicts = df[columns].to_dict(orient='records')\n\n    X = dv.transform(dicts)\n    y_pred = model.predict_proba(X)[:, 1]\n\n    return y_pred","85a805d6":"from sklearn.model_selection import KFold \n\nkfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\nscores = []\n\nfor train_idx, val_idx in kfold.split(df_full_train):\n    df_train = df_full_train.iloc[train_idx]\n    df_val = df_full_train.iloc[val_idx]\n    \n    y_train = df_train.default.values\n    y_val = df_val.default.values\n    \n    dv, model = train(df_train, y_train, C = 1)\n    y_pred = predict(df_val, dv, model)\n    \n    auc = roc_auc_score(y_val, y_pred)\n    scores.append(auc)\n    \nstd = np.array(scores).std()\nstd","e4c75dfb":"def train(df_train, y_train, C=1.0):\n    dicts = df_train[columns].to_dict(orient='records')\n\n    dv = DictVectorizer(sparse=False)\n    X_train = dv.fit_transform(dicts)\n\n    model = LogisticRegression(solver = 'liblinear', C=C, max_iter=1000)\n    model.fit(X_train, y_train)\n    \n    return dv, model","deda68cd":"def predict(df, dv, model):\n    dicts = df[columns].to_dict(orient='records')\n\n    X = dv.transform(dicts)\n    y_pred = model.predict_proba(X)[:, 1]\n\n    return y_pred","b9913def":"n_splits = 5\n\nfor C in [0.01, 0.1, 1, 10]:\n    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n\n    scores = []\n\n    for train_idx, val_idx in kfold.split(df_full_train):\n        # the k-fold split uses index to shuffle the data\n        df_train = df_full_train.iloc[train_idx]\n        df_val = df_full_train.iloc[val_idx]\n        \n        # y values come from dataset\n        y_train = df_train.default.values\n        y_val = df_val.default.values\n        \n        # training and predicting\n        dv, model = train(df_train, y_train, C=C)\n        y_pred = predict(df_val, dv, model)\n        \n        # AUC\n        auc = roc_auc_score(y_val, y_pred)\n        scores.append(auc)\n    \n    print('C= %s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))","5c0c4c10":"## Your code","a0943b29":"Remove clients with unknown default status","ddabaded":"Some of the features are encoded as numbers. Use the following code to de-code them:","8a468b19":"What are the categorical variables? What are the numerical?","b981787d":"## Question 1\n\nROC AUC could also be used to evaluate feature importance of numerical variables. \n\nLet's do that\n\n* For each numerical variable, use it as score and compute AUC with the \"default\" variable\n* Use the training dataset for that\n\n\nIf your AUC is < 0.5, invert this variable by putting \"-\" in front\n\n(e.g. `-df_train['expenses']`)\n\nAUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.","cf41769e":"## Question 3\n\nNow let's compute precision and recall for our model.\n\n* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n* For each threshold, compute precision and recall\n* Plot them","2c290e40":"Data:\n\n- https:\/\/github.com\/gastonstat\/CreditScoring\n- Also available [here](https:\/\/raw.githubusercontent.com\/alexeygrigorev\/mlbookcamp-code\/master\/chapter-06-trees\/CreditScoring.csv)","cbc9d625":"## Question 5\n\n\nUse the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n\n```\nKFold(n_splits=5, shuffle=True, random_state=1)\n```\n\n* Iterate over different folds of `df_full_train`\n* Split the data into train and validation\n* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n* Use AUC to evaluate the model on validation\n","446532fe":"Answer to question 2: 0.812\n","2496b776":"Answer to question 3: 0.4","aea39aa1":"Answer for Question 6: 10 ","ebccb98d":"## Question 2\n\nWhat's the AUC of this model on the validation dataset? (round to 3 digits)\n\n- 0.512\n- 0.612\n- 0.712\n- 0.812","74b7742c":"Which C leads to the best mean score?\n\n- 0.01\n- 0.1\n- 1\n- 10\n\nIf you have ties, select the score with the lowest std. If you still have ties, select the smallest C","6e720bd4":"How large is standard devidation of the scores across different folds?\n\n- 0.001\n- 0.014\n- 0.09\n- 0.14","4febd4bb":"Answer to question 4: 0.3","d6ea9266":"At which threshold F1 is maximal?\n\n- 0.1\n- 0.3\n- 0.5\n- 0.7","d6a0310d":"Create the target variable","ee208717":"## Training the model\n\nFrom now on, use these columns only:\n\n```\n['seniority', 'income', 'assets', 'records', 'job', 'home']\n```\n\nApply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n\n```\nLogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n```","8bf1d1d3":"Split the data into 3 parts: train\/validation\/test with 60%\/20%\/20% distribution. Use `train_test_split` funciton for that with `random_state=1`","aea79f78":"Prepare the numerical variables:","ba63b42b":"Which numerical variable (among the following 4) has the highest AUC?\n\n- seniority\n- time\n- income\n- debt","10a087e7":"Closest answer to 0.013669 is 0.014 \nAnswer to Qn 5: 0.014","4cb2fb4f":"## Submit the results\n\nSubmit your results here: https:\/\/forms.gle\/e497sR5iB36mM9Cs5\n\nIt's possible that your answers won't match exactly. If it's the case, select the closest one.\n\n## Deadline\n\nThe deadline for submitting is 04 October 2021, 17:00 CET. After that, the form will be closed.","33a144ab":"At which threshold precision and recall curves intersect?\n\n* 0.2\n* 0.4\n* 0.6\n* 0.8","c87ea122":"## Preparation \n\nWe'll talk about this dataset in more details in week 6. But for now, use the following code to get started","b931d0e6":"## Question 4\n\nPrecision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n\nThis is the formula for computing F1:\n\n$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n\nWhere $P$ is precision and $R$ is recall.\n\nLet's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01","1bf4a89a":"## Homework 4\n\nUse this notebook as a starter","6c73fbd1":"Answer to Question 1: Seniority\n","87cd7dd9":"## Question 6\n\nNow let's use 5-Fold cross-validation to find the best parameter C\n\n* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n* Compute the mean score as well as the std"}}