{"cell_type":{"337faeee":"code","23e3d209":"code","939a2d77":"code","1e33e259":"code","3d697058":"code","0c75ed40":"code","d7e2461a":"code","07162290":"code","9aa5d85e":"code","f986cf2f":"code","e4c83c84":"code","87bc7c79":"code","ccfec031":"code","405d2810":"code","251dcaf8":"code","b38e6243":"code","7bcc9b33":"code","a2c91dc9":"code","c1da41f9":"code","e9550c72":"code","43094edc":"code","a04f8a1b":"code","5875fe5f":"code","6221db09":"code","cc03f685":"code","cc52730a":"code","1772535a":"code","8dd35eca":"code","bd4c71c7":"code","3d35a781":"code","e63142e2":"code","b3deba3a":"code","dfef52b2":"code","ba41c385":"code","38220939":"code","b2b95d2d":"code","f1835683":"code","e85a2668":"code","0544d743":"code","0fbc3f1a":"code","3e324297":"code","f47d0d55":"code","cf33dce0":"code","9af29dc7":"code","ef44a30e":"code","4e1a018e":"code","d4e9d0f2":"code","b25badab":"code","45015431":"code","65174246":"code","f6035f5f":"code","4f6a5362":"code","45a51389":"code","fa737418":"code","8e211599":"code","d15da362":"code","bf75ff09":"code","a8983302":"code","b9337219":"code","c3dc2929":"code","0c3da723":"code","e6e6755f":"code","1b53ed07":"code","6a41107f":"code","1cf442e9":"code","a383afbb":"code","800fb1af":"code","a79e457e":"code","6ae12726":"code","279174c1":"code","ec798ce6":"code","d0e6d81c":"code","7a5d3f9c":"code","aba84586":"code","5042fd08":"code","57851222":"code","6387d832":"code","c6e0c841":"code","81314378":"code","9482daeb":"code","9ca3d0b9":"code","1d087e8d":"code","6f87547e":"code","097e559f":"code","72224b10":"code","0b2793bf":"code","3a8db5b2":"code","f112975f":"markdown","9525609a":"markdown","c028ad70":"markdown","57580954":"markdown","811df5b7":"markdown","42454f9b":"markdown","32896915":"markdown","2c44bb2d":"markdown","ade9b253":"markdown","aab7402c":"markdown","eb9f1972":"markdown","16e12907":"markdown","596b76d5":"markdown","0c9bcb51":"markdown","fc9fdbf0":"markdown","c88d95b4":"markdown","4b125978":"markdown","a6f87d90":"markdown","1fd44454":"markdown","8a8f8651":"markdown","4385c96c":"markdown","f0cfdbb8":"markdown","ccff186e":"markdown","47ffc1aa":"markdown","a6dbc834":"markdown","7ffddf40":"markdown","a2d8c073":"markdown","e31950f0":"markdown","a06b06d1":"markdown","fea5d24e":"markdown","f3d3f8cb":"markdown","e5354240":"markdown","20f2d97a":"markdown","a39ab92d":"markdown","b2c3bd12":"markdown","2f8565b2":"markdown","f434b698":"markdown","52fbabd3":"markdown","73c02b1b":"markdown","26b01677":"markdown","ca7f1a1a":"markdown","24152b44":"markdown","e846eb69":"markdown","2c338f1f":"markdown","05b646e7":"markdown","5d87f5b4":"markdown","c303e7c0":"markdown","e7c0f7f5":"markdown","28d3c3e3":"markdown","22c88989":"markdown","60b0cf36":"markdown"},"source":{"337faeee":"# Importing Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom ast import literal_eval\nimport ast\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n# Importing Datasets\nimport os\nprint (os.listdir(\"..\/input\/movielens-latest-full\/\"))\n\n# Importing files\nratings=pd.read_csv('..\/input\/movielens-latest-full\/ratings.csv')\nlinks=pd.read_csv('..\/input\/movielens-latest-full\/links.csv')\nmovies=pd.read_csv('..\/input\/movielens-latest-full\/movies.csv')\ntags=pd.read_csv('..\/input\/movielens-latest-full\/tags.csv')\ngenome_scores=pd.read_csv('..\/input\/movielens-latest-full\/genome-scores.csv')\ngenome_tags=pd.read_csv('..\/input\/movielens-latest-full\/genome-tags.csv')\n\n\n# Styles to view dataframes side by side\nfrom IPython.core.display import HTML\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>'\n    )\n\n# Sample of our Dataset\ndisplay(multi_table([ratings.head(10),movies.head(10),tags.head(10),genome_tags.head(10),genome_scores.head(10),links.head(10)]))","23e3d209":"print (os.listdir(\"..\/input\/the-movies-dataset\/\"))\n\nmovies_meta=pd.read_csv('..\/input\/the-movies-dataset\/movies_metadata.csv')\ndisplay(movies_meta.head(3))","939a2d77":"movies_meta.info()\n\nmovies_meta[movies_meta['title'].isnull() ]\n# A quick glance tells us that columns with title as blank have inaccurate data in their fields","1e33e259":"# Remove null titles from original titles\nmovies_meta = movies_meta[pd.notnull(movies_meta['title'])]\n\nmovies_meta.info()","3d697058":"# Remove Un-necessary columns which I think are not needed\nmovies_meta = movies_meta.drop(['id','homepage', 'genres', 'imdb_id', 'original_title', 'overview', 'popularity', 'poster_path', 'status', 'tagline', 'video','vote_average','vote_count'],\n               axis = 1)","0c75ed40":"movies_meta['adult'].unique()","d7e2461a":"# We try to keep this as a boolean field\nmovies_meta.loc[(movies_meta['adult'] != 'True') & (movies_meta['adult'] != 'False'), 'adult'] = False\nmovies_meta['adult'] = movies_meta['adult'].map({'True': True, 'False': False})\nmovies_meta['adult'].value_counts()","07162290":"# We want to convert belongs to collection to boolean value\nmovies_meta['belongs_to_collection'] = movies_meta['belongs_to_collection'].notna()","9aa5d85e":"# I found this fucntion after googling to convert string objects into useable lists\n# Function to convert string objects using the library literaty_eval \n\ndef get_values(data_str):\n    if isinstance(data_str, float):\n        pass\n    else:\n        values = []\n        data_str = ast.literal_eval(data_str)\n        if isinstance(data_str, list):\n            for k_v in data_str:\n                values.append(k_v['name'])\n            return values\n        else:\n            return None","f986cf2f":"# Dictionary to lists\nmovies_meta[['production_companies', 'production_countries', 'spoken_languages']] = movies_meta[['production_companies', 'production_countries', 'spoken_languages']].applymap(get_values)","e4c83c84":"#release_date\nmovies_meta['release_date'] = pd.to_datetime(movies_meta['release_date'], format = '%Y-%m-%d', errors='coerce')","87bc7c79":"display(movies_meta[movies_meta['budget'] == '0']['budget'].count(),  # lots of null values\n        movies_meta[movies_meta['revenue'] == 0]['revenue'].count())","ccfec031":"# Converts budget to float datatype\nmovies_meta['budget'] = pd.to_numeric(movies_meta['budget'], errors = 'coerce')\n\n# replace 0 values with NaN\nmovies_meta.loc[(movies_meta['budget'] == 0) & (movies_meta['revenue'] == 0), 'revenue'] = np.nan\nmovies_meta.loc[movies_meta['budget'] == 0, 'budget'] = np.nan","405d2810":"def scale(num):\n    if num < 100:\n        return num * 1000000\n    elif num >= 100 and num < 1000:\n        return num * 1000\n    else:\n        return num","251dcaf8":"movies_meta[['budget', 'revenue']] = movies_meta[['budget', 'revenue']].applymap(scale)\nsns.distplot(movies_meta[movies_meta['budget'].notnull()]['budget'])\n\nmovies_meta['profit'] = movies_meta['revenue'] - movies_meta['budget']","b38e6243":"# Remove Un-necessary columns \nmovies_meta = movies_meta.drop(['budget','revenue'],\n               axis = 1)\n\nmovies_meta.head(5)","7bcc9b33":"movies=pd.read_csv('..\/input\/movielens-latest-full\/movies.csv')\ndisplay(multi_table([movies.head(), ratings.head()]))","a2c91dc9":"#To join movies with movies_meta by title\nmovies['title'] = movies['title'].map(lambda x: str(x)[:-7])","c1da41f9":"ratings_summary = ratings.groupby('movieId') \\\n       .agg({'rating':'mean', 'userId':'count'}) \\\n       .rename(columns={'rating':'rating_avg','userId':'rating_count'}) \\\n       .reset_index()\n\nmovie_ratings = pd.merge(ratings_summary, movies)\nmovie_ratings.head(3)","e9550c72":"movie_ratings.genres = movie_ratings.genres.str.split('|')\nmovie_ratings.head(3)","43094edc":"movies_full = pd.merge(movie_ratings, movies_meta , on = ['title'])\nmovies_full.head()","a04f8a1b":"tags=pd.read_csv('..\/input\/movielens-latest-full\/tags.csv')\ngenome_scores=pd.read_csv('..\/input\/movielens-latest-full\/genome-scores.csv')\ngenome_tags=pd.read_csv('..\/input\/movielens-latest-full\/genome-tags.csv')","5875fe5f":"display(multi_table([genome_scores.tail(3), tags.tail(3), genome_tags.tail(3)]))","6221db09":"# Capturing Tags only if its relevance is higher than 80% to a movie\ngs = genome_scores[genome_scores['relevance'] > 0.80]\ngs.head(5)","cc03f685":"tags_scores = pd.merge(genome_tags ,gs , on = ['tagId'])\ntags_scores.sort_values(['movieId'], ascending=True).head(10)","cc52730a":"ky = tags_scores[['tag','movieId']]\nky.drop_duplicates(keep=False,inplace=True) \n\nA_ky = ky.groupby('tag') \\\n       .agg({'movieId':'count'}) \\\n       .rename(columns={'movieId':'count'}) \\\n       .reset_index()\nA_ky.head(5)","1772535a":"# Keyword Analysis using Fuzzy Matching\nfrom fuzzywuzzy import process\nnames_array=[]\nratio_array=[]\n\ndef match_names(wrong_names,correct_names):\n    for row in wrong_names:\n        x=process.extractOne(row, correct_names)\n        names_array.append(x[0])\n        ratio_array.append(x[1])\n    return names_array,ratio_array\n \ndf= A_ky\nwrong_names=df['tag'].dropna().values\n \n#Correct tags dataset\nchoices_df=A_ky[A_ky['count'] > 100]\ncorrect_names=choices_df['tag'].values \n \nname_match,ratio_match=match_names(wrong_names,correct_names)\n \ndf['correct_tag_name']=pd.Series(name_match)\ndf['tag_names_ratio']=pd.Series(ratio_match)","8dd35eca":"output = df[['tag','correct_tag_name','tag_names_ratio' ]]\noutput.head()\nnew_tags = output[(output.tag_names_ratio >= 81) & (output.tag_names_ratio <= 100)]\ncorrect_tags = pd.merge(ky[['movieId','tag']],new_tags[['tag','correct_tag_name']], on = 'tag')\ntags_clean  = correct_tags.groupby(['correct_tag_name','movieId']) \\\n                           .agg({'tag':'count'}) \\\n                           .rename(columns={'tag':'count'}) \\\n                           .reset_index()\ntags_clean  = tags_clean.rename(columns={'correct_tag_name' : 'tag'})\ntags_clean.head()","bd4c71c7":"keywords = pd.merge(movies_full, tags_clean[['tag','movieId']] , on = ['movieId'])\nkeywords.head()","3d35a781":"# keywords.columns","e63142e2":"movies_all = keywords['genres'].apply(pd.Series)\\\n    .merge(keywords, right_index = True, left_index = True) \\\n    .drop(['genres'], axis = 1) \\\n    .melt(id_vars = ['movieId', 'rating_avg', 'rating_count', 'title', 'adult',\n       'belongs_to_collection', 'original_language', 'production_companies',\n       'production_countries', 'release_date', 'runtime', 'spoken_languages',\n       'profit','tag'], value_name = 'genre') \\\n    .drop(\"variable\", axis = 1) \\\n    .dropna()","b3deba3a":"movies_all = movies_all['production_companies'].apply(pd.Series)\\\n    .merge(movies_all, right_index = True, left_index = True) \\\n    .drop(['production_companies'], axis = 1) \\\n    .melt(id_vars = ['movieId', 'rating_avg', 'rating_count', 'title', 'adult',\n       'belongs_to_collection', 'original_language', 'production_countries',\n       'release_date', 'runtime', 'spoken_languages',\n       'profit','tag', 'genre'], value_name = 'produced_by') \\\n    .drop(\"variable\", axis = 1) \\\n    .dropna()","dfef52b2":"movies_all = movies_all['production_countries'].apply(pd.Series)\\\n    .merge(movies_all, right_index = True, left_index = True) \\\n    .drop(['production_countries'], axis = 1) \\\n    .melt(id_vars = ['movieId', 'rating_avg', 'rating_count', 'title', 'adult',\n       'belongs_to_collection', 'original_language', \n       'release_date', 'runtime', 'spoken_languages',\n       'profit','tag', 'genre','produced_by'], value_name = 'country') \\\n    .drop(\"variable\", axis = 1) \\\n    .dropna()","ba41c385":"movies_all = movies_all['spoken_languages'].apply(pd.Series)\\\n    .merge(movies_all, right_index = True, left_index = True) \\\n    .drop(['spoken_languages'], axis = 1) \\\n    .melt(id_vars = ['movieId', 'rating_avg', 'rating_count', 'title', 'adult',\n       'belongs_to_collection', 'original_language', \n       'release_date', 'runtime', \n       'profit','tag', 'genre','produced_by','country'], value_name = 'language') \\\n    .drop(\"variable\", axis = 1) \\\n    .dropna()","38220939":"\nmovies_clean.sort_values(['movieId'], ascending=True).head(5)","b2b95d2d":"movies_clean.info()","f1835683":"display(multi_table([ratings.head() , movies.head()]))","e85a2668":"import time\nratings['year'] = ratings['timestamp'].apply(lambda x: time.strftime('%Y', time.localtime(x)))\nratings = ratings.drop(['timestamp', 'userId'], axis=1)\n\nmovie_ratings = pd.merge(ratings, movies)\nmovie_ratings.head()\n\n# Compute the average rating for each movie\navg_ratings = movie_ratings.groupby(['movieId', 'title', 'genres', 'year'], as_index=False)['rating'].mean()\navg_ratings.head()","0544d743":"# Compute a list of distinct genres \nall_genres = []\nfor x in avg_ratings.genres:\n    all_genres.extend(x.split('|'))    \nall_genres = pd.unique(all_genres)\n\nprint(all_genres)","0fbc3f1a":"# Compute the average rating for each movie\navg_ratings = movie_ratings.groupby(['movieId', 'title', 'genres', 'year'], as_index=False)['rating'].mean()\navg_ratings.head()","3e324297":"# splits the genres column by taking the delimiter\nsplit_genres = avg_ratings['genres'].str.split('|')\nsplit_data = pd.DataFrame({'genres':split_genres.values}, index = split_genres.index)\n\nsplit_data['rating'] = avg_ratings['rating']\nsplit_data['title'] = avg_ratings['title']\nsplit_data['year'] = avg_ratings['year']\nsplit_data['movieId'] = avg_ratings['movieId']\n\nsplit_data.head()","f47d0d55":"objs = [split_data, pd.DataFrame(split_data['genres'].tolist())]\nnew_df = pd.concat(objs, axis=1).drop('genres', axis=1).sort_values('rating', ascending=False)\nfinal_ratings = pd.melt(new_df, var_name='genre', value_name=\"genres\", id_vars=['movieId','rating','title', 'year'], value_vars=[0,1,2,3,4,5,6,7,8]).sort_values('rating', ascending=False)\nfinal_ratings = final_ratings[final_ratings.genres.notnull()].drop(\"genre\", axis=1)\nfinal_ratings.sort_values(by=['movieId'], inplace=True)\nfinal_ratings.head()","cf33dce0":"# Total number of movies with a specific genre counted multiple times for multi genre movies\ngenre_count = final_ratings.groupby('genres').count()[['movieId']]\ngenre_count = genre_count.rename(columns = {'movieId': 'count'})\ngenre_count = genre_count.sort_values('count', ascending=False)\n\ncount = genre_count['count'].tolist()\ngenre = genre_count.index.tolist()\ngenre_count = pd.DataFrame({'genre': genre, 'count': count})\ngenre_count","9af29dc7":"# Plot total number of movies vs genre\ngenre_count.plot.barh(x = 'genre', y = 'count')\nplt.xlabel('Number of movies')\nplt.ylabel('Genre')\nplt.title('Number of Movies vs Genre')\n\nplt.show()","ef44a30e":"avg_genre_ratings = final_ratings.groupby(['genres'], as_index=False)['rating'].mean()\navg_genre_ratings = avg_genre_ratings.sort_values(by=['rating'], ascending=False)\navg_genre_ratings","4e1a018e":"avg_genre_ratings.plot.barh(x = 'genres', y='rating')\nplt.xlabel('Rating')\nplt.ylabel('Genres')\nplt.title('Comparing MovieLens Ratings by Genre')\n\nplt.show()","d4e9d0f2":"rating_acrossYears = final_ratings.groupby(['genres', 'year'], as_index=False)['rating'].mean()\n\nfig, ax = plt.subplots(figsize=(20, 10))\nfor genre, year in rating_acrossYears.groupby('genres'):\n    year.plot(x='year', y='rating', ax=ax, label=genre)\n    \nplt.xlabel('Year (1995 - 2018)')\nplt.xlim(0, 23) \nplt.ylabel('Rating')\nplt.title('Trends in Average Movie Ratings for Different Genres')\nplt.show()","b25badab":"movies_meta=pd.read_csv('..\/input\/the-movies-dataset\/movies_metadata.csv')\ndisplay(movies_meta.head(3))","45015431":"# Select relevent information\nwork1df = movies_meta[['title', 'belongs_to_collection', 'release_date', 'vote_average']]\n\n# Strip out all movies that do not belong to a collection or are missing relevent data.\nwork2df = work1df.dropna()\n\n# Sort the movies with sequels by collection and release date so that we can determine \n# with part (ie. 1,2,3, etc) the movie is in the series.\nmSeries=work2df.sort_values(by=['belongs_to_collection', 'release_date'])\n\nprint(mSeries.info())\nmSeries.isnull().sum()","65174246":"# Loop through the sequels to pull out the movie collection information \n# and since the data is sort by release date, we can determine with part\n# the movie is (ie. part 1, 2, 3, etc).  We can also use this process\n# to assign a decade to the sequel.  If it is the original movie, \n# the decade will be assign N\/A.\n\nimport re\n\nmSeries['Collection'] = ' '\nmSeries['Part'] = 0\n#mSeries['Decade'] = ''\n\nlastRec= mSeries.shape[0]\n\ni=0\npart = 1\nprevCollection = ''\n\nwhile i < lastRec :    \n    try:\n        s1 = re.search(\"'name': '(.*)', 'poster_path'\", mSeries.belongs_to_collection.values.item(i))\n        currCollection=s1.group(1)    \n    except AttributeError:        \n        currCollection = np.nan    \n    if currCollection == prevCollection :        \n        part += 1\n    else :       \n        prevCollection = currCollection\n        part = 1\n\n#    decade = mSeries.release_date.item(i)    \n    mSeries.set_value(mSeries.index[i],'Collection', currCollection)\n    mSeries.set_value(mSeries.index[i],'Part', part)\n#    mSeries.set_value(mSeries.index[i],'Decade', decade)    \n    i+=1","f6035f5f":"# Add a decade field based on release date.\n\nmSeries['Decade'] = mSeries.release_date.str[:3] + \"0\"\nmSeries.head(20)","4f6a5362":"# Select the date we need for analyzing ratings and clean up missing values or percentages\n# that are inf because of a divison by zero.\n\nmSeriesRating = mSeries[['Collection', 'title', 'release_date', 'vote_average']]\nmSeriesRating.dropna(subset=[\"Collection\"], how=\"all\")   \nmSeriesRating.drop(mSeries[mSeries.vote_average == 0].index)   \n#mSeriesRating.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"Rating_Compared_To_Orig\"], how=\"all\")\nmSeriesRating.head(20)","45a51389":"# Create a dataframe with each movie collection highest Part numbers.\n# Sort from highest to lowest and re-index the dataframe\n# Provide the top ten movie collections.\n\nworkdf = mSeries[['Collection', 'Part']]\nmostSequels = workdf.groupby(['Collection'], as_index=False)['Part'].max()\n\nprint(mostSequels.sort_values(by=['Part', 'Collection'], ascending=False).reset_index(drop=True).head(10))","fa737418":"# Create a dataframe for finding the highest rating.\n# Drop the original movie as we are looking for sequels only.\n\nworkdf = mSeries[['Collection', 'Part', 'vote_average']]\nworkdf2 = workdf.drop(workdf[workdf.Part == 1].index)\nbestSequels = workdf2.groupby(['Collection', 'Part'], as_index=False)['vote_average'].max()\n\nprint(bestSequels.sort_values(by=['vote_average', 'Collection', 'Part'], ascending=False).reset_index(drop=True).head(10))","8e211599":"# Create a dataframe for finding the most sequels.\n# First drop the original movie as we are looking for sequels only.\n\nworkdf = mSeries[['Decade', 'Part']]\nworkdf2 = workdf.drop(workdf[workdf.Part == 1].index)\nworkdf3 = workdf2[['Decade']]\n\nsequelDecades = workdf3.groupby(['Decade']).size().reset_index(name='Count')\n\nprint(sequelDecades.sort_values(by=['Count', 'Decade'], ascending=False))","d15da362":"# Temporarily break the ratings data out into movie series parts so that\n# we can merge them together by row based on movie collection.\n# We will analyze movies with three parts in the series.\n\n# Breaking a part the data based on part.\ntempdf=mSeries[['Collection', 'vote_average']]\nmSeriesRatingP1=tempdf.loc[mSeries['Part'] == 1]\nmSeriesRatingP1.rename(columns={'vote_average': 'Part_1'},inplace=True)\n\nmSeriesRatingP2=tempdf.loc[mSeries['Part'] == 2]\nmSeriesRatingP2.rename(columns={'vote_average': 'Part_2'},inplace=True)\n\n# Merging the data together again based in movie collection\nmSeriesCompare = pd.merge(mSeriesRatingP1, mSeriesRatingP2, on='Collection')\n\npart1Mean = mSeriesCompare[\"Part_1\"].mean()\npart2Mean = mSeriesCompare[\"Part_2\"].mean()\n\nmSeriesMeans = pd.DataFrame({'Original_Movie': [part1Mean], 'Part_2': [part2Mean]})\n\nmSeriesMeans.plot.bar()\n\nplt.show()","bf75ff09":"# Temporarily break the ratings data out into movie series parts so that\n# we can merge them together by row based on movie collection.\n# We will analyze movies with three parts in the series.\n\n# Breaking a part the data based on part.\ntempdf=mSeries[['Collection', 'vote_average']]\nmSeriesRatingP1=tempdf.loc[mSeries['Part'] == 1]\nmSeriesRatingP1.rename(columns={'vote_average': 'Part_1'},inplace=True)\n\nmSeriesRatingP2=tempdf.loc[mSeries['Part'] == 2]\nmSeriesRatingP2.rename(columns={'vote_average': 'Part_2'},inplace=True)\n\nmSeriesRatingP3=tempdf.loc[mSeries['Part'] == 3]\nmSeriesRatingP3.rename(columns={'vote_average': 'Part_3'},inplace=True)\n\n\n# Merging the data together again based in movie collection\ntempdf2 = pd.merge(mSeriesRatingP1, mSeriesRatingP2, on='Collection')\nmSeriesCompare = pd.merge(tempdf2, mSeriesRatingP3, on='Collection')\n\npart1Mean = mSeriesCompare[\"Part_1\"].mean()\npart2Mean = mSeriesCompare[\"Part_2\"].mean()\npart3Mean = mSeriesCompare[\"Part_3\"].mean()\n\nmSeriesMeans = pd.DataFrame({'Original_Movie': part1Mean, 'Part_2': [part2Mean], 'Part_3': [part3Mean]})\n\nmSeriesMeans.plot.bar()\n\nplt.show()","a8983302":"ToyStory = mSeriesCompare.loc[mSeriesCompare['Collection'] == 'Toy Story Collection']\nToyStory.rename(columns={'Part_1': 'Toy_Story', 'Part_2': 'Toy_Story_2', 'Part_3': 'Toy_Story_3'},inplace=True)\nToyStory.plot.bar()\nplt.show()","b9337219":"# Expand the analysis to movies with 4 sequels so that we can look at Indiana Jones\n\nmSeriesRatingP4=tempdf.loc[mSeries['Part'] == 4]\nmSeriesRatingP4.rename(columns={'vote_average': 'Part_4'},inplace=True)\n\ndf = mSeriesCompare\nmSeriesCompare = pd.merge(df, mSeriesRatingP4, on='Collection')\n","c3dc2929":"part4Mean = mSeriesCompare[\"Part_4\"].mean()\nmSeriesMeans = pd.DataFrame({'Original_Movie': part1Mean, 'Part_2': [part2Mean], 'Part_3': [part3Mean],\n                             'Part_4': [part4Mean]})\nmSeriesMeans.plot.bar()\nplt.show()","0c3da723":"IndianaJones = mSeriesCompare.loc[mSeriesCompare['Collection'] == 'Indiana Jones Collection']\nIndianaJones.rename(columns={'Part_1': 'Indiana_Jones', },inplace=True)\nIndianaJones.plot.bar()\nplt.show()","e6e6755f":"# Expand the analysis for movies with 8 sequels\n\ndf = mSeriesCompare\nmSeriesRatingP5=tempdf.loc[mSeries['Part'] == 5]\nmSeriesRatingP5.rename(columns={'vote_average': 'Part_5'},inplace=True)\nmSeriesCompare = pd.merge(df, mSeriesRatingP5, on='Collection')\n\ndf = mSeriesCompare\nmSeriesRatingP6=tempdf.loc[mSeries['Part'] == 6]\nmSeriesRatingP6.rename(columns={'vote_average': 'Part_6'},inplace=True)\nmSeriesCompare = pd.merge(df, mSeriesRatingP6, on='Collection')\n\ndf = mSeriesCompare\nmSeriesRatingP7=tempdf.loc[mSeries['Part'] == 7]\nmSeriesRatingP7.rename(columns={'vote_average': 'Part_7'},inplace=True)\nmSeriesCompare = pd.merge(df, mSeriesRatingP7, on='Collection')\n\ndf = mSeriesCompare\nmSeriesRatingP8=tempdf.loc[mSeries['Part'] == 8]\nmSeriesRatingP8.rename(columns={'vote_average': 'Part_8'},inplace=True)\nmSeriesCompare = pd.merge(df, mSeriesRatingP8, on='Collection')\n","1b53ed07":"part5Mean = mSeriesCompare[\"Part_5\"].mean()\npart6Mean = mSeriesCompare[\"Part_6\"].mean()\npart7Mean = mSeriesCompare[\"Part_7\"].mean()\npart8Mean = mSeriesCompare[\"Part_8\"].mean()\n\nmSeriesMeans = pd.DataFrame({'Original_Movie': part1Mean, 'Part_2': [part2Mean], 'Part_3': [part3Mean],\n                             'Part_4': [part4Mean], 'Part_5': [part5Mean], 'Part_6': [part6Mean],\n                             'Part_7': [part7Mean], 'Part_8': [part8Mean],})\n\n\nmSeriesMeans.plot.bar()\n\nplt.show()","6a41107f":"StarWars = mSeriesCompare.loc[mSeriesCompare['Collection'] == 'Star Wars Collection']\nStarWars.rename(columns={'Part_1': 'Star_Wars', },inplace=True)\nStarWars.plot.bar()\n\nplt.show()","1cf442e9":"ratings=pd.read_csv('..\/input\/movielens-latest-full\/ratings.csv')\nmovies=pd.read_csv('..\/input\/movielens-latest-full\/movies.csv')\nmovies_meta=pd.read_csv('..\/input\/the-movies-dataset\/movies_metadata.csv')","a383afbb":"# Drop timestamp field\nmovie_ratings = pd.merge(ratings, movies)\nmovie_ratings = movie_ratings.drop(['timestamp'], axis=1)\nmovie_ratings.head(5)","800fb1af":"# Join with \"links\" to retrieve imdb ID for joins later\nmovie_ratings = pd.merge(movie_ratings, links, on = ['movieId'])\nmovie_ratings = movie_ratings.drop(['tmdbId'], axis=1)\nmovie_ratings[\"imdbId\"] = movie_ratings[\"imdbId\"].apply(str)\nmovie_ratings[\"imdbId\"] = \"tt\"+ movie_ratings[\"imdbId\"].str.zfill(7)\nmovie_ratings.head(5)","a79e457e":"# with \"movies_metadata\", will extract budget, revenue and run time from this table after joining\nmovies_meta.rename(columns={'imdb_id':'imdbId'}, inplace = True)\nmovies_meta_mini= movies_meta[['imdbId','budget','popularity','revenue','runtime','release_date']]\nmovies_meta_mini.head(5)","6ae12726":"# Statistical details on titles\nmr_stats_2 = movie_ratings.groupby(['imdbId','title','genres']).agg({'rating': [min, max, 'mean', 'count', 'std','var']}).reset_index()\nmr_stats_2.head(5)","279174c1":"# Connect Runtime, Revenue and Budget, Release Date into Movie Dataset\nmovies_budget_runtime_revenue = pd.merge(mr_stats_2, movies_meta_mini , on=['imdbId'])\n\n#Rename Columns\nmovies_budget_runtime_revenue.columns = ['imdbId','imdbId2','title','genres','rating_min','rating_max','rating_mean','rating_count','rating_std','rating_var','budget','popularity','revenue','runtime','release_date']\nmovies_budget_runtime_revenue['decade'] = movies_budget_runtime_revenue['release_date'].str[:3]+\"0s\"\nmovies_budget_runtime_revenue.head(5)","ec798ce6":"# Using Scale Function : Refer to Data Cleaning (above) on movies_meta for details\ndef scale(num):\n    if num < 100:\n        return num * 1000000\n    elif num >= 100 and num < 1000:\n        return num * 1000\n    else:\n        return num","d0e6d81c":"movies_budget_runtime_revenue['budget'] = pd.to_numeric(movies_budget_runtime_revenue['budget'], errors = 'coerce')\nmovies_budget_runtime_revenue[['budget', 'revenue']] = movies_budget_runtime_revenue[['budget', 'revenue']].applymap(scale)","7a5d3f9c":"# Import libraries from sklearn\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing","aba84586":"#Use this array to store key genres\ngenre_list = []\ngenre_list.append(\"Action\")\ngenre_list.append(\"Adventure\")\ngenre_list.append(\"Animation\")\ngenre_list.append(\"Children\")\ngenre_list.append(\"Comedy\")\ngenre_list.append(\"Documentary\")\ngenre_list.append(\"Drama\")\ngenre_list.append(\"Fantasy\")\ngenre_list.append(\"Horror\")\ngenre_list.append(\"IMAX\")\ngenre_list.append(\"Musical\")\ngenre_list.append(\"Mystery\")\ngenre_list.append(\"Romance\")\ngenre_list.append(\"Sci-Fi\")\ngenre_list.append(\"Thriller\")\ngenre_list.append(\"War\")","5042fd08":"for z in genre_list:\n\n    #Limiting to Movies from at least the 1980s, less than 5 hours and having at least 100 ratings\n\n    lm = sns.lmplot(x='runtime', y='rating_mean', hue = 'decade', col='decade',\n           data = movies_budget_runtime_revenue[((movies_budget_runtime_revenue['decade'] == '2000s') | (movies_budget_runtime_revenue['decade'] == '1990s') | (movies_budget_runtime_revenue['decade'] == '1980s') | (movies_budget_runtime_revenue['decade'] == '2010s'))\n        & (movies_budget_runtime_revenue['runtime'] > 0) & (movies_budget_runtime_revenue['runtime'] < 301) & \n         (movies_budget_runtime_revenue['rating_count'] > 100) & (movies_budget_runtime_revenue['genres'].str.count(z) == 1)]).set(xlim = (0,300), ylim=(0,5))\n\n    # Access the figure\n    fig = lm.fig \n\n    # Add a title to the Figure\n    fig.suptitle(\"Genre: \" + z + \"- runtime vs. rating\", fontsize=12)\n","57851222":"## Find Slopes of Linear Regression - Runtime vs. Rating\n#print(\"Runtime vs. Rating - Slope of Regression Line by Genre\")\n\n## Store Regression Slopes in this Dataframe\nRuntime_Regression = pd.DataFrame(columns=['genres','slope'])\nRuntime_Regression[\"slope\"] = pd.to_numeric(Runtime_Regression[\"slope\"],downcast='float')\n\nfor z in genre_list:\n    Y = movies_budget_runtime_revenue[((movies_budget_runtime_revenue['decade'] == '2000s') | (movies_budget_runtime_revenue['decade'] == '1990s') | (movies_budget_runtime_revenue['decade'] == '1980s') | (movies_budget_runtime_revenue['decade'] == '2010s'))\n        & (movies_budget_runtime_revenue['runtime'] > 0)  & (movies_budget_runtime_revenue['runtime'] < 301) & \n         (movies_budget_runtime_revenue['rating_count'] > 100) & (movies_budget_runtime_revenue['genres'].str.count(z) == 1)]['rating_mean']\n\n    X = movies_budget_runtime_revenue[((movies_budget_runtime_revenue['decade'] == '2000s') | (movies_budget_runtime_revenue['decade'] == '1990s') | (movies_budget_runtime_revenue['decade'] == '1980s') | (movies_budget_runtime_revenue['decade'] == '2010s'))\n        & (movies_budget_runtime_revenue['runtime'] > 0)  & (movies_budget_runtime_revenue['runtime'] < 301) & \n         (movies_budget_runtime_revenue['rating_count'] > 100) & (movies_budget_runtime_revenue['genres'].str.count(z) == 1)]['runtime'].values.reshape(-1, 1)\n\n    model = sklearn.linear_model.LinearRegression().fit(X, Y)\n    \n   # print(z + \": Slope = \"+ str(model.coef_))\n    \n    Runtime_Regression = Runtime_Regression.append({'genres' : z,'slope' :  float(model.coef_)},ignore_index=True)","6387d832":"print(\"Slope of Regression Line by Genre ordered - Runtime vs. Rating\")\nRuntime_Regression.sort_values(by='slope', ascending=False) ","c6e0c841":"Runtime_Regression.sort_values(by='slope', ascending=False).plot.barh(x = 'genres', y='slope')\nplt.xlabel('Genre')\nplt.ylabel('Slope')\nplt.title('Comparing Runtime Regression to User Rating by Genre')\n\nplt.show()","81314378":"\n\nfor z in genre_list:\n\n    #Limiting to Movies from at least the 1980s, less than 5 hours and having at least 100 ratings\n\n    lm = sns.lmplot(x='budget', y='rating_mean', hue = 'decade', col='decade',\n           data = movies_budget_runtime_revenue[((movies_budget_runtime_revenue['decade'] == '2000s') | (movies_budget_runtime_revenue['decade'] == '1990s') | (movies_budget_runtime_revenue['decade'] == '1980s') | (movies_budget_runtime_revenue['decade'] == '2010s'))\n        & (movies_budget_runtime_revenue['runtime'] > 0)  & (movies_budget_runtime_revenue['runtime'] < 301) & (movies_budget_runtime_revenue['budget'] > 0) &\n         (movies_budget_runtime_revenue['rating_count'] > 100) & (movies_budget_runtime_revenue['genres'].str.count(z) == 1)]).set(xlim = (0,200000000), ylim=(0,5))\n\n    # Access the figure\n    fig = lm.fig \n\n    # Add a title to the Figure\n    fig.suptitle(\"Genre: \" + z + \"- budget vs. rating\", fontsize=12)","9482daeb":"## Find Slopes of Linear Regression - Budget vs. Rating\n#print(\"Budget vs. Rating - Slope of Regression Line by Genre\")\n## Store Regression Slopes in this Dataframe\nBudget_Regression = pd.DataFrame(columns=['genres','slope'])\nBudget_Regression[\"slope\"] = pd.to_numeric(Budget_Regression[\"slope\"],downcast='float')\n\nfor z in genre_list:\n\n    Y = movies_budget_runtime_revenue[((movies_budget_runtime_revenue['decade'] == '2000s') | (movies_budget_runtime_revenue['decade'] == '1990s') | (movies_budget_runtime_revenue['decade'] == '1980s') | (movies_budget_runtime_revenue['decade'] == '2010s'))\n        & (movies_budget_runtime_revenue['runtime'] > 0) & (movies_budget_runtime_revenue['budget'] > 0) & (movies_budget_runtime_revenue['runtime'] < 301) & \n         (movies_budget_runtime_revenue['rating_count'] > 100) & (movies_budget_runtime_revenue['genres'].str.count(z) == 1)]['rating_mean']\n\n    X = movies_budget_runtime_revenue[((movies_budget_runtime_revenue['decade'] == '2000s') | (movies_budget_runtime_revenue['decade'] == '1990s') | (movies_budget_runtime_revenue['decade'] == '1980s') | (movies_budget_runtime_revenue['decade'] == '2010s'))\n        & (movies_budget_runtime_revenue['runtime'] > 0) & (movies_budget_runtime_revenue['budget'] > 0) & (movies_budget_runtime_revenue['runtime'] < 301) & \n         (movies_budget_runtime_revenue['rating_count'] > 100) & (movies_budget_runtime_revenue['genres'].str.count(z) == 1)]['budget'].values.reshape(-1, 1)\n\n    model = sklearn.linear_model.LinearRegression().fit(X, Y)\n    \n    #print(z + \": Slope = \"+ str(model.coef_))\n    \n    Budget_Regression = Budget_Regression.append({'genres' : z,'slope' : float(model.coef_)},ignore_index=True)","9ca3d0b9":"print(\"Slope of Regression Line by Genre ordered - Budget vs. Rating\")\nBudget_Regression.sort_values(by='slope', ascending=False)   ","1d087e8d":"Budget_Regression.sort_values(by='slope', ascending=False).plot.barh(x = 'genres', y='slope')\nplt.xlabel('Genre')\nplt.ylabel('Slope')\nplt.title('Comparing Budget Regression to User Rating by Genre')\n\nplt.show()","6f87547e":"tag_unique = keywords.groupby(['movieId','title','tag','rating_avg','rating_count']) \\\n       .agg({'rating_avg':'count'}) \\\n       .rename(columns={'rating_avg':'count'}) \\\n       .reset_index()\ntag_unique = tag_unique[['movieId','title','tag','rating_avg','rating_count']]\ntag_unique.head(5)","097e559f":"tag_analysis = tag_unique.groupby(['tag']) \\\n        .agg({'rating_avg':'mean', 'rating_count':'sum'}) \\\n        .rename(columns={'rating_count':'Votes'}) \\\n        .reset_index()\n\ndisplay(tag_analysis.sort_values(['rating_avg'], ascending=True).head(10), tag_analysis.sort_values(['rating_avg'], ascending=False).head(10))","72224b10":"Recommendation = keywords[keywords['tag']=='masterpiece']\nR1 = Recommendation.groupby(['movieId', 'title', 'rating_avg']) \\\n        .agg({'rating_avg':'mean'}) \\\n        .rename(columns={'rating_avg':'rating_avg2'}) \\\n        .reset_index()\n\nR1 = R1[['movieId','title','rating_avg']]\nR1.sort_values(['rating_avg'], ascending=False).head(10)","0b2793bf":"Recommendation = keywords[keywords['tag']=='horrible']\nR1 = Recommendation.groupby(['movieId', 'title', 'rating_avg']) \\\n        .agg({'rating_avg':'mean'}) \\\n        .rename(columns={'rating_avg':'rating_avg2'}) \\\n        .reset_index()\n\nR1 = R1[['movieId','title','rating_avg']]\nR1.sort_values(['rating_avg'], ascending=True).head(10)","3a8db5b2":"Recommendation = keywords[keywords['tag']=='good acting']\nR1 = Recommendation.groupby(['movieId', 'title', 'rating_avg']) \\\n        .agg({'rating_avg':'mean'}) \\\n        .rename(columns={'rating_avg':'rating_avg2'}) \\\n        .reset_index()\n\nR1 = R1[['movieId','title','rating_avg']]\nR1.sort_values(['rating_avg'], ascending=False).head(10)","f112975f":"* movies_clean = movies_all[['title', 'movieId', 'rating_avg', 'rating_count',  'adult', 'belongs_to_collection', 'original_language', \n                'release_date', 'runtime', 'profit','tag', 'genre','produced_by','country','language']]\n* movies_clean = movies_clean.set_index('movieId', drop = True)","9525609a":"* # &#128203; Introduction of The Movies Dataset:\n\nThese files contain metadata for all 45,000 movies listed in the Full MovieLens Dataset. The dataset consists of movies released on or before July 2017. Data points include budget, revenue, release dates, languages, production companies, countries.","c028ad70":"* # &#128203; Calculating Avg and Volume of Ratings","57580954":"* # &#128203; Expanding on Genres","811df5b7":"* # &#128203; What were the top 10 movies with the most sequels in the series?","42454f9b":"# &#128202; 3. What about attributes such as length of movie\/show, budget of movie affect ratings?","32896915":"# &#128295; End of movies_meta","2c44bb2d":"* # &#128203; Features : production_companies, production_countries, spoken_languages : lists","ade9b253":"## &#128681; FINDINGS = Ratings compared to runtimeFINDINGS = Budget compared to rating\n\nNegative relationship of ratings vs. budgets for seemingly \"mainstream\" genres such as Romance, Comedy and Drama, show that over reliance on \"star\" salaries doesn't necessarily equate to user acceptance\n\nDocumentaries are all about content and storytelling - extra budgets don't seem to have much impact for viewer acceptance in this genre\n\nOn the converse end of the spectrum, the need for high budgets spent towards special effects, costumes, stunts, and computer graphics\/animation are key in viewer likelihood to rate Action, Sci-Fi, Animation and Children's movies.","aab7402c":"* # &#128203; Feature : belongs_to_collection : Boolean","eb9f1972":"* # &#128203; How did the Toy Story 3 compare to the original and Toy Story 2?","16e12907":"* The idea of using this is fo that we want to categorize similar keywords together to identify factors\/keywords that can influence a movie rating\n* The function tri[](http:\/\/)es to compare popular keywords identified by having counts > 100 and replacing the not so popular tags with the most relevant tags ","596b76d5":"# &#128202; 4. What are the most common keywords that are part of \u201cgood\u201d or bad ratings?\n\n* This component uses Df from Data Cleaning above. \n* Fuzzy Matching was used to match similar tags so we arrive at the most popular keywords associated with Good vs Bad Recommendation based on ratings","0c9bcb51":"* # &#128203; What are the highest rated sequels?","fc9fdbf0":"* # &#128203; A glimpse into Recommendation engines","c88d95b4":"* # &#128203; For movies with eight sequels, on average how did the sequels rate?","4b125978":"\n* # &#128203; PLOTS = Running Time vs. Rating","a6f87d90":"There are many movies with budgets smaller than \"100\" dollars(?), and it's hard to tell how we should scale the data: sometimes it should probably be a million times bigger and sometimes only a thousand.\n\nAfter scanning some of the data, checking Google, and using some common sense I decided:\n\nif budget < 100 : budget * 1000000\nif 100 =< budget < 1000: budget * 1000\nelse: budget\nsame thing goes to revenue","1fd44454":"* # &#128203; How did the Indiana Jones sequels rate compare to the original?","8a8f8651":"* # &#128221; Import Libraries, Styles and Datasets\nThe dataset is available in several snapshots. The ones that were used in this analysis were Latest Datasets - both full and small (for web scraping). They were last updated in October 2018.","4385c96c":"# &#128202; Exploratory Analysis & Data Visualization\n\nMain Objectives: \n1. Do certain genres lend themselves to a more \u201ccritical\u201d viewer-base (i.e. a distribution of lower ratings)\n2. Do movies as part of franchises have sequels that improve in viewer rating or made just for profitability?\n3. What about attributes such as length of movie\/show, budget of movie affect ratings?\n4. What are the most common keywords that are part of \u201cgood\u201d or bad ratings?","f0cfdbb8":"* # &#128203; Unstacking Lists into rows in Pandas in Preparation for Content Based Filtering (Used in Recommendation Engines)","ccff186e":"# &#128295; Data Cleaning: Merging metrics from (MovieLens)\n\n* We want to use the MovieLens Data to capture metrics related to UserRatings, Genres, keywords and consider bring all fields together for analysis","47ffc1aa":"* # &#128203; For movies with three sequels, on average how did the sequels rate?","a6dbc834":"# &#128295; Preparing the Data","7ffddf40":"* # &#128203; Expanding on Country produced","a2d8c073":"* # &#128203; Features : Release_date : Datetime","e31950f0":"# &#128295; Data Cleaning: Handling Missing Data - movies_meta\n\nIn the Data Cleaning, we explore the techniques to impute, merge, stack, aggregatre the different data from dasets:\nThe primary purpose of data cleaning is to apply ML to the feature set.\nBelow are the common techniques that can be applied to the dataset","a06b06d1":"* # &#128203; Features : Budget, Revenue and engineering a new field called *Profit*\n* Budget and Revenue have 0 values instead of NaN \n* Idea is to create a new metric called Profit to consider it as a factor to better understand its relation to movie ratings","fea5d24e":"* # &#128203; Which decade produced the most sequels?","f3d3f8cb":"What are the Top 10 and Bottom 10 tags by rating?","e5354240":"* # &#128203; Expanding on Languages","20f2d97a":"# &#128221; DataSet considerations and further additions:\n\nMovie lense contains important details based on User Ratings and will give us lots of insights related to Year, Tags, Genres etc.\nWe wanted to have more fun in exploring additional features such as budget, revenue, languages, international titles, sequels,  etc\nHence we included The Movies Dataset from : https:\/\/www.kaggle.com\/rounakbanik\/the-movies-dataset\n\nPlease find our Data Cleaning and EDA below:","a39ab92d":"# &#127909; Intro Of This NoteBook:\n This notebook uses a dataset from the [MovieLens 20M Dataset](https:\/\/www.kaggle.com\/grouplens\/movielens-latest-full). We will describe the dataset further as we explore with it using pandas.","b2c3bd12":"# &#128295; End of Data Cleaning","2f8565b2":"* # &#128203; Expanding on Produced_by","f434b698":"# &#128202; 2. Do movies as part of franchises have sequels that improve in viewer rating or made just for profitability?\nThe Analysis component can be executed as standalone pieces","52fbabd3":"* # &#128203; PLOTS = Budget vs. Rating","73c02b1b":"* # &#128203; Primary Key *Title* : to join with movies_meta above","26b01677":"## &#128223; Future Considerations\n\nWe have so far touched upon filtering for tags to search for top movie recommendations by ratings:\nFor future results, we would like to explore on Building Recommender Systems where we explore the 2 common approaches:\n* User Based Recommender Systems -- Using user statistic on user movie ratings\n* Item Based Recommender Systems -- what we did above","ca7f1a1a":"# &#128200; &#128201; Descriptive Statistics \n* Get the total Votes and total avg rating for each  movie","24152b44":"* # &#128203;How did the Star Wars sequels rate compare to the original?","e846eb69":"* # &#128203;Fuzzy String Matching With Pandas and FuzzyWuzzy\nFuzzy string matching or searching is a process of approximating strings that matches a particular pattern. Note that it gives an approximate and there is no guarantee that the string can be exact, however, sometimes the string accurately matches the pattern. How close the string is to a given match is measured by the edit distance. FuzzyWuzzy uses Levenshtein Distance to calculate the edit distance. [Link](http:\/\/https:\/\/www.geeksforgeeks.org\/fuzzywuzzy-python-library\/)\n\n","2c338f1f":"* # &#128203; On average how does the sequel rate compared to the original movie?","05b646e7":"* # &#128203; Features : genres to lists","5d87f5b4":"## &#128681; FINDINGS = Ratings compared to runtime\n\n* Probably of little surprise, negative relationship with ratings and increased runtime for those genres generally related to younger audiences (children, animation)\n* Probably unsurprising that documentary with rather \"flat\" relationship with ratings, as most in the genre tend to be contained in the 60-90 min range\n* Action and Thriller movies that are able to sustain their action over longer duration appear to result in higher average ratings","c303e7c0":"* # &#128203; Features : Bringing in Keywords and Tags","e7c0f7f5":"# &#128203; Introduction of MoveLens:\nThis is a report on the movieLens dataset available here. MovieLens itself is a research site run by GroupLens Research group at the University of Minnesota. The first automated recommender system was developed there in 1993.","28d3c3e3":"* # &#128203; Feature : Adult : Boolean","22c88989":"* # &#128203; For movies with four sequels, on average how did the sequels ratings?","60b0cf36":"# &#128202; 1. Do certain genres lend themselves to a more \u201ccritical\u201d viewer-base (i.e. a distribution of lower ratings)\nThis Analysis component can be executed as standalone pieces"}}