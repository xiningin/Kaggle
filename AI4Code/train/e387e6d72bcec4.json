{"cell_type":{"43afac2a":"code","16b55a67":"code","e6892dd7":"code","db6861cc":"code","d68214ee":"code","bc123523":"code","7b31fcd6":"code","b369d959":"code","b21eef96":"code","7a9da4e5":"code","4fd2b61e":"code","ee4d7819":"code","9079b46a":"code","00ed5b57":"code","376f6a26":"code","50135f67":"code","9bb89c6b":"code","57e29460":"markdown","dbc71728":"markdown"},"source":{"43afac2a":"import tensorflow as tf\nimport numpy as np\nimport glob\nimport os\nimport random\nfrom matplotlib import pyplot as plt\n%matplotlib inline","16b55a67":"keras = tf.keras\nlayers = tf.keras.layers","e6892dd7":"path = glob.glob('..\/input\/cat-and-dog\/training_set\/training_set\/*\/*.jpg')\npath = path[:1000] + path[-1000:]","db6861cc":"label = [int(p.split('\/')[5]=='cats') for p in path]","d68214ee":"def load_preprocess_image(path, label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [256, 256])\n    image = tf.cast(image, tf.float32)\n    image = image\/255\n    \n    return image, label","bc123523":"train_ds = tf.data.Dataset.from_tensor_slices((path, label))\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.map(load_preprocess_image, num_parallel_calls=AUTOTUNE)\n\ntrain_ds = train_ds.shuffle(2000).repeat().batch(32)","7b31fcd6":"test_path = glob.glob('..\/input\/cat-and-dog\/test_set\/test_set\/*\/*.jpg')\ntest_path = test_path[:500] + test_path[-500:]\nlen(test_path)","b369d959":"test_label = [int(p.split('\/')[5]=='cats') for p in test_path]\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test_path, test_label))\ntest_ds = test_ds.map(load_preprocess_image, num_parallel_calls=AUTOTUNE)\n    \ntest_ds = test_ds.batch(32).repeat()","b21eef96":"# weights \u4f7f\u7528\u9884\u5148\u8bad\u7ec3\u597d\u7684\u53c2\u6570 \/\u7b49\u4e8eNone\n# include_top \u662f\u5426\u5305\u542b\u8bad\u7ec3\u597d\u7684\u5206\u7c7b\u5668 i.e. \u5168\u8fde\u63a5\u5c42\uff0c\u5426\u5219\u53ea\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u5377\u79ef\u57fa\nconv_base = keras.applications.VGG16(weights='imagenet', include_top=False)","7a9da4e5":"conv_base.summary()","4fd2b61e":"model = keras.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","ee4d7819":"model.summary()","9079b46a":"conv_base.trainable = False\nmodel.summary()","00ed5b57":"model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\nhistory = model.fit(train_ds, steps_per_epoch=2000\/\/32, epochs=10, validation_data=test_ds, validation_steps=1000\/\/32)","376f6a26":"len(conv_base.layers)\n\nconv_base.trainable = True\n\nfine_tune_at = -3\nfor layer in conv_base.layers[:fine_tune_at]:\n    layer.trainable = False","50135f67":"model.compile(optimizer=keras.optimizers.Adam(lr=0.00005), loss='binary_crossentropy', metrics=['acc'])","9bb89c6b":"initial_epochs = 10\nfine_tune_epochs = 7\ntotal = initial_epochs + fine_tune_epochs\n\nhistory = model.fit(train_ds,\n                    steps_per_epoch=2000\/\/32,\n                    epochs=total,\n                    initial_epoch=initial_epochs,\n                    validation_data=test_ds,\n                    validation_steps=1000\/\/32)","57e29460":"**\u5fae\u8c03\uff1a** \u51bb\u7ed3\u6a21\u578b\u5e93\u5e95\u90e8\u7684\u5377\u79ef\u5c42\uff0c\u5171\u540c\u8bad\u7ec3\u65b0\u6dfb\u52a0\u7684\u5206\u7c7b\u5668\u5c42\u548c\u9876\u90e8\u90e8\u5206\u5377\u79ef\u5c42\n=> \u4f7f\u5f97\u9ad8\u9636\u7279\u5f81\u8868\u793a\u4e0e\u5b83\u4eec\u7684\u7279\u5b9a\u4efb\u52a1\u66f4\u76f8\u5173","dbc71728":"keras\u5185\u7f6e\u7ecf\u5178\u7f51\u7edc\u7684\u5b9e\u73b0\n\n\u8fc1\u79fb\u5b66\u4e60 => \u9002\u5408\u5c0f\u578b\u6570\u636e\u96c6\uff0cotherwise\u8fc7\u62df\u5408"}}