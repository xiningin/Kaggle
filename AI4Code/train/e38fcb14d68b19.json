{"cell_type":{"a4fc93d9":"code","80dbb87f":"code","f6b52d56":"code","504a24da":"code","7205836b":"code","7a5ceebb":"code","45431ea2":"code","c591a854":"code","270052b6":"code","4f06b99a":"code","db03909c":"code","f24aa6a2":"code","f3526c59":"code","9a60477d":"code","70c7f8b0":"code","c319e4a6":"code","f88526b6":"code","f51c23fe":"code","87aca27d":"code","9d009661":"code","6d016e4d":"code","55a1f447":"code","8afac228":"code","589e814f":"code","5c288db6":"code","dcc4255f":"code","91ec6afa":"code","7849a12e":"code","28321b24":"code","8cac61c8":"code","d9287bfb":"code","9def0785":"code","25629f82":"code","7c7190d4":"code","54c920c4":"code","2c2fe24f":"code","e1beaf00":"code","d3773487":"code","4a78cc6a":"code","8a53513c":"code","afc5cf6e":"code","e9131f5f":"code","c47722f1":"code","f4d07888":"code","4b81f6db":"code","dce3b1ef":"code","5f74be2e":"code","3e3bfefa":"code","dbf2b11e":"code","dda45e64":"code","47829da1":"code","74076ee3":"code","ad51b886":"code","3d1f6ce8":"code","c9714d14":"markdown","05182ea1":"markdown","580a0915":"markdown","66034b83":"markdown","2c507116":"markdown","282d6575":"markdown","287328e2":"markdown","9f120b7c":"markdown","7b9b44f2":"markdown","82d6384b":"markdown","0ad259b1":"markdown","60c77798":"markdown","7dac170e":"markdown","98edbead":"markdown","a8fdadac":"markdown"},"source":{"a4fc93d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","80dbb87f":"import numpy as np\nimport pandas as pd\n\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nimport time\nimport sys\nimport gc\nimport pickle\nsys.version_info","f6b52d56":"plt.style.use('ggplot')","504a24da":"items = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ncats = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ntrain = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\n# set index to ID to avoid droping it later\ntest  = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv').set_index('ID')","7205836b":"train.head()","7a5ceebb":"fig, ax = plt.subplots(nrows= 1, ncols= 2, figsize = (12,4))\n\nsns.distplot(train['item_price'], kde= False, ax= ax[0])\nsns.distplot(train['item_cnt_day'], kde= False, ax= ax[1])","45431ea2":"fig, ax = plt.subplots(nrows= 1, ncols= 2, figsize = (12,4))\n\nsns.boxplot(x = train['item_price'],ax= ax[0])\nsns.boxplot(x = train['item_cnt_day'],ax= ax[1])","c591a854":"train[['item_price', 'item_cnt_day']].describe().transpose()","270052b6":"train['item_price'].nlargest(5)","4f06b99a":"train['item_cnt_day'].nlargest(5)","db03909c":"train = train[train['item_price'] < 100000]\ntrain = train[train['item_cnt_day'] < 1001]","f24aa6a2":"train['item_price'].nsmallest(5)","f3526c59":"train[train['item_price'] <0]","9a60477d":"median_value = train[(train['shop_id'] == 32) & (train['item_id'] == 2973) & (train['item_price'] > 0)]['item_price'].median()\n\ntrain.loc[train.item_price<0, 'item_price'] = median_value","70c7f8b0":"shops.head()","c319e4a6":"shop_names = list(shops['shop_name'])","f88526b6":"print(f\"Unique Number of Shop Names : {shops['shop_name'].nunique()}\")\nprint(f\"Unique Number of Shop IDs : {shops['shop_id'].nunique()}\")","f51c23fe":"shops['city_name'] = shops['shop_name'].apply(lambda x : x.split()[0])\nshops.head()","87aca27d":"shops.drop('shop_name', axis= 1, inplace= True)\nshops.head()","9d009661":"label_encoder = LabelEncoder()\nshops['city_code'] = label_encoder.fit_transform(shops['city_name'])","6d016e4d":"shops.drop('city_name', axis= 1, inplace= True)\nshops.head()","55a1f447":"items.head()","8afac228":"#Creating Item type & subtype features\ncats['item_type'] = cats['item_category_name'].apply(lambda x : x.split('-')[0].strip())\ncats['item_subtype'] = cats['item_category_name'].apply(lambda x : x.split('-')[1].strip() if len(x.split('-')) > 1 else x.split('-')[0].strip())\n\n#Encoding them\ncats['item_type_code'] = LabelEncoder().fit_transform(cats['item_type'])\ncats['item_subtype_code'] = LabelEncoder().fit_transform(cats['item_subtype'])","589e814f":"cats.drop(['item_category_name', 'item_type', 'item_subtype'], axis= 1, inplace= True)\ncats.head()","5c288db6":"items = items.merge(cats, on= 'item_category_id', how= 'left')","dcc4255f":"items.drop('item_name', inplace= True, axis= 1)\nitems.head()","91ec6afa":"test.head()","7849a12e":"#Items which are present in Test but not in Train set\nlen(list(set(test.item_id) - set(test.item_id).intersection(set(train.item_id))))","28321b24":"print(f\"Unique Items in Test Set: {test['item_id'].nunique()}\")\nprint(f\"Unique Shops in Test Set: {test['shop_id'].nunique()}\")\nprint(f\"Total Shop Item pairs : {len(test)}\")","8cac61c8":"train['date_block_num'].unique()","d9287bfb":"matrix = []\n\ncols = ['date_block_num', 'shop_id', 'item_id']\n\nfor i in range(34) :\n    sales = train[train['date_block_num'] == i]\n    matrix.append(np.array(list(product([i], sales['shop_id'].unique(), sales['item_id'].unique() )), dtype='int16'))","9def0785":"matrix = pd.DataFrame(np.vstack(matrix), columns= cols)\n\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\n\nmatrix.head()","25629f82":"group = train.groupby(['date_block_num', 'shop_id', 'item_id']).agg({'item_cnt_day' : 'sum'})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace = True)\n\ngroup.head()","7c7190d4":"matrix = pd.merge(matrix, group, on= cols, how ='left')\n\nmatrix['item_cnt_month'] = matrix['item_cnt_month'].fillna(0).clip(0,20).astype(np.float16)\n\nmatrix.head()","54c920c4":"test['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)\n\ntest.head()","2c2fe24f":"matrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\nmatrix.fillna(0, inplace=True) \n\nmatrix.head()","e1beaf00":"#pulling shop features\nmatrix = pd.merge(matrix, shops, on= 'shop_id', how= 'left')\nmatrix = pd.merge(matrix, items, on= 'item_id', how= 'left')\n\nmatrix.head()","d3773487":"matrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['item_type_code'] = matrix['item_type_code'].astype(np.int8)\nmatrix['item_subtype_code'] = matrix['item_subtype_code'].astype(np.int8)\n\nmatrix.head()","4a78cc6a":"lags = [1,2,3,6,12]\n\nfor lag in lags :\n    matrix[f'Previous_{lag}_month_sales'] = matrix.groupby(['shop_id', 'item_id'])['item_cnt_month'].shift(lag)\n    \nmatrix.fillna(0, inplace= True)\nmatrix.head()","8a53513c":"def mean_encoded_features(matrix, columns, lags) :\n    \n    group = matrix.groupby(columns).agg({'item_cnt_month' : 'mean'})\n    new_column_name = '_'.join(columns) + '_item_cnt'\n    group.columns = [new_column_name] \n    group.reset_index(inplace = True)\n    \n    matrix = pd.merge(matrix, group, on= columns, how= 'left')\n    matrix[new_column_name] = matrix[new_column_name].astype(np.float16)\n    \n    for lag in lags :\n        matrix[f'lag_{lag + 1}_{new_column_name}'] = matrix.groupby(['shop_id', 'item_id'])[new_column_name].shift(lag)\n        \n    matrix.drop(new_column_name, axis=1, inplace=True)\n        \n    return matrix\n        ","afc5cf6e":"#Month Sales Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num'], lags= [1])\n\n#Month Item Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_id'], lags= [1,2,3,6,12])\n\n#Month Shop Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'shop_id'], lags= [1,2,3,6,12])\n\n#Month Item Category Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_category_id'], lags= [1,2,3,6,12])\n\n#Month Shop Category Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'shop_id', 'item_category_id'], lags= [1])\n\n#Month Shop Type Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'shop_id', 'item_type_code'], lags= [1])\n\n#Month Shop SubType Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'shop_id', 'item_subtype_code'], lags= [1])\n\n#Month City Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'city_code'], lags= [1])\n\n#Month Item City Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_id', 'city_code'], lags= [1])\n\n#Month Type Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_type_code'], lags= [1])\n\n#Month Sub-Type Level\nmatrix = mean_encoded_features(matrix, columns= ['date_block_num', 'item_subtype_code'], lags= [1])\n","e9131f5f":"#Adding avg price of each item\ngroup = train.groupby(['item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['item_avg_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['item_id'], how='left')\nmatrix['item_avg_price'] = matrix['item_avg_price'].astype(np.float16)","c47722f1":"#Adding Average Price every month of each item\ngroup = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['date_item_avg_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_price'] = matrix['date_item_avg_price'].astype(np.float16)","f4d07888":"matrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\nmatrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')","4b81f6db":"train['revenue'] = train['item_price'] *  train['item_cnt_day']\n\n#Month & Shop wise revenue\ngroup = train.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\ngroup.columns = ['date_shop_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\n#Shop wise Revenue\ngroup = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\ngroup.columns = ['shop_avg_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['shop_id'], how='left')\nmatrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n\nmatrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) \/ matrix['shop_avg_revenue']\nmatrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n\nmatrix = mean_encoded_features(matrix, columns= ['delta_revenue'], lags= [1])\n\nmatrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)","dce3b1ef":"#month as per calender\nmatrix['month'] = matrix['date_block_num'] % 12\n\n#number of days in the month \ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\nmatrix['days'] = matrix['month'].map(days).astype(np.int8)","5f74be2e":"#dropping intial 12 months data\nmatrix = matrix[matrix.date_block_num > 11]","3e3bfefa":"X_train = matrix[matrix['date_block_num'] < 34].drop('item_cnt_month', axis = 1)\ny_train = matrix[matrix['date_block_num'] < 34]['item_cnt_month']\n\nX_test = matrix[matrix['date_block_num'] == 34].drop('item_cnt_month', axis = 1)\ny_test = matrix[matrix['date_block_num'] == 34]['item_cnt_month']","dbf2b11e":"del matrix\ndel group\ndel items\ndel shops\ndel cats\ndel train\n# leave test for submission\ngc.collect();","dda45e64":"%%time\nmodel = XGBRegressor(max_depth=6, tree_method='gpu_hist', n_estimators=1000, colsample_bytree=0.8, subsample=0.8, eta=0.1,seed=42)\n\nmodel.fit(X_train, y_train)","47829da1":"submission = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')","74076ee3":"submission.head()","ad51b886":"submission['item_cnt_month'] = model.predict(X_test)","3d1f6ce8":"submission.to_csv('Xgboost.txt', index = False)","c9714d14":"Each Shop Name contains City name in the start. We will extract the city information from the shop name","05182ea1":"## Mean Encoded Features","580a0915":"## Item & Item Category Data","66034b83":"## Sales Train Data","2c507116":"## Trend Features\n","282d6575":"## Shop Data","287328e2":"## Revenue","9f120b7c":"## Creating Training & Test Sets","7b9b44f2":"## First Time Sale","82d6384b":"## Adding Target Lags","0ad259b1":"# Data Cleaning","60c77798":"# Creating Submission","7dac170e":"## Test Data","98edbead":"## Pulling Items & Shops Feature","a8fdadac":"## Time Features"}}