{"cell_type":{"88aa63a8":"code","e9c0766f":"code","ff588f87":"code","ec28a88d":"code","880e4ba7":"code","b50aa2e4":"code","c30c6ea7":"code","7db8fac8":"code","504adb07":"code","16bd68be":"code","013d105a":"code","c515bf08":"code","e2319f0f":"code","4bf2eb84":"code","d5b718cd":"code","01b041a2":"code","323cd7bc":"code","b45ff4fa":"code","62ce88fb":"code","c70dd5b8":"code","d00fddc2":"code","df152d47":"code","7b765954":"code","c6037868":"code","d8986f28":"code","51353b68":"code","1a2ffa96":"code","906c229b":"markdown","7ed011ad":"markdown","b9af90ac":"markdown","b7580cf2":"markdown","d08f54e3":"markdown","31c9f259":"markdown","dad2ec79":"markdown","a7d8cbe5":"markdown","8d7b3b31":"markdown","fadc43a6":"markdown"},"source":{"88aa63a8":"import numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D,Dropout, Flatten, Dense\nfrom keras import regularizers\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder # one-hot encoding for age\nfrom keras.utils.np_utils import to_categorical\n\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport os\n\nimage_path = '\/kaggle\/input\/facial-age\/face_age\/'\n","e9c0766f":"# Take a look at some images\n\ndef see_sample_images(age, number_of_images):\n    plt.figure(figsize=(10,10))\n    age_folder = image_path + age\n    images = os.listdir(age_folder)[:number_of_images]\n    for i in range(number_of_images):\n        file = mpimg.imread(age_folder +'\/'+ images[i])\n        plt.subplot(number_of_images\/2,2,i+1)\n        plt.imshow(file)\n\nsee_sample_images(\"033\",6)","ff588f87":"X = []\nY = []\nwidth = 100\nheight = 100 # resize to 100x100 to solve the RAM issue in Kaggle notebooks\n\nfor folder_name,_,filenames in os.walk(image_path):\n    if folder_name !=\"face_age\" and folder_name != 'Data':\n        for file in filenames:\n            file_path = folder_name +\"\/\"+ file\n            image = Image.open(file_path)\n            image = image.convert('RGB')\n            image = image.resize((width, height))\n            X.append(np.array(image))\n            Y.append(int(folder_name[-3:]))\n    else:\n        pass","ec28a88d":"# Normalise input data to range [0,1]\nX = np.array(X)\nX = X.astype('float32')\nX \/= 255.0\n# confirm the normalization\nprint('Min: %.3f, Max: %.3f' % (X.min(), X.max()))\n\nY = np.array(Y)\n","880e4ba7":"os.mkdir(\"Data\")\n\ntry:\n    os.remove(\"Data\/X.npy\")\n    os.remove(\"Data\/Y.npy\")\n    os.remove(\"Data\/X_train.npy\")\n    os.remove(\"Data\/Y_train.npy\")\n    os.remove(\"Data\/X_test.npy\")\n    os.remove(\"Data\/Y_test.npy\")\n    os.remove(\"Data\/X_val.npy\")\n    os.remove(\"Data\/Y_val.npy\")\nexcept OSError:\n    pass\n\n\n","b50aa2e4":"# np.save('Data\/X.npy', X)\n# np.save('Data\/Y.npy',Y)\n# X = np.load('Data\/X.npy')\n# Y = np.load('Daata\/Y.npy')","c30c6ea7":"# Train, validation and testing split (70\/15\/15)\ntest_size = 0.3\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, \n                                                    Y,\n                                                    test_size=test_size, \n                                                    random_state=seed,\n                                                    shuffle=True,\n                                                    stratify=Y)\n\nX_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5)","7db8fac8":"# save to files\nnp.save('Data\/X_train.npy', X_train)\nnp.save('Data\/Y_train.npy', Y_train)\nnp.save('Data\/X_val.npy', X_val)\nnp.save('Data\/Y_val.npy', Y_val)\nnp.save('Data\/X_test.npy', X_test)\nnp.save('Data\/Y_test.npy', Y_test)","504adb07":"# confirm the saved files\nos.listdir(\"Data\")","16bd68be":"# check out a random image and its corresponding age label\nplt.imshow(X_train[2])","013d105a":"Y_train[2]","c515bf08":"# Apply Image Augmentation\n\ntrain_datagen = ImageDataGenerator(\n    shear_range = 0.2, # random application of shearing\n    zoom_range = 0.2,\n    horizontal_flip = True) # randomly flipping half of the images horizontally\n\ntest_datagen = ImageDataGenerator(\n)","e2319f0f":"from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\nfrom timeit import default_timer as timer\n\nclass TimingCallback(Callback):\n    def __init__(self, logs={}):\n        self.logs=[]\n    def on_epoch_begin(self, epoch, logs={}):\n        self.starttime = timer()\n    def on_epoch_end(self, epoch, logs={}):\n        self.logs.append(timer()-self.starttime)\n\nearly_stopping = EarlyStopping(\n                                patience=5, # wait for 5 epochs\n                                min_delta = 0.01, # if in 5 epochs the loss function doesn't inrease (for accuracy) \n                                               # or decrease (for val_loss) by 1%, then stop\n                                verbose=1, # print the training epoch on which training was stopped\n                                mode = 'min',\n                                monitor='val_loss')\n\nreduce_learning_rate = ReduceLROnPlateau(\n                                    monitor=\"val_loss\",\n                                    patience=3, # if val_loss plateaus for 3 epochs such that it doesn't see \n                                                # an improvement of size = epsilon\n                                    episilon= 0.01,\n                                    factor=0.1,  # then we reduce the learning rate by a factor of 0.1\n                                    cooldown = 4, # and we wait for 4 epochs before we restart again\n                                    verbose=1)\n\ntime_callback = TimingCallback()\n\n        \n# hyperparameters\nlr = 0.01\nepochs = 30 # setting it to a low number since this is for Kaggle, ideally you should set this to a higher number ~ 100 so that the model overfits training data, and then apply the elbow methods to select the best params on validaion data\nbatch_size = 128\nresults = {}\ninput_shape =[width,height]\nnum_of_ages = 100","4bf2eb84":"def baseline_model():\n    model = Sequential()\n    model.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n                   padding=\"valid\",\n                   kernel_regularizer=regularizers.l2(0.00001),\n                   input_shape=(input_shape[0], input_shape[1], 3)))\n    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n    model.add(Dropout(0.5))\n    model.add(Flatten())\n    model.add(Dense(1,activation=\"linear\")) \n    return model","d5b718cd":"Adam= keras.optimizers.Adam(lr=0.1,beta_1=0.9, beta_2=0.999, decay=0.0)","01b041a2":"model = baseline_model()\n\nmodel.compile(optimizer=\"adam\",loss=\"mean_absolute_error\",metrics=['mean_absolute_error'])\n\nmodel_history = model.fit_generator(\n            train_datagen.flow(X_train,Y_train,\n                         batch_size = batch_size), # use augmented images\n            validation_data = (X_val,Y_val),\n            steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n            epochs = epochs,\n            callbacks = [\n                         reduce_learning_rate,\n                         early_stopping,\n                         time_callback\n                        ],\n            verbose=True)","323cd7bc":"baseline_adam_train_loss = model_history.history[\"loss\"]\nbaseline_adam_val_loss = model_history.history[\"val_loss\"]\nbaseline_adam_train_acc = model_history.history[\"mean_absolute_error\"]\nbaseline_adam_val_acc = model_history.history[\"val_mean_absolute_error\"]\n\n\nresults[\"baseline_adam\"] = {'train-loss': baseline_adam_train_loss,\n                             'val-loss': baseline_adam_val_loss,\n                             'train-mae': baseline_adam_train_acc,\n                             'val-mae': baseline_adam_val_acc}","b45ff4fa":"from keras.applications.mobilenet import MobileNet\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, BatchNormalization\nfrom keras.models import Sequential\nbase_mobilenet_model = MobileNet(input_shape =  (input_shape[0],input_shape[1], 3), \n                                 include_top = False, \n                                 weights = None)\nmobilenet_model = Sequential()\nmobilenet_model.add(BatchNormalization(input_shape = (input_shape[0],input_shape[1], 3)))\nmobilenet_model.add(base_mobilenet_model)\nmobilenet_model.add(BatchNormalization())\nmobilenet_model.add(GlobalAveragePooling2D())\nmobilenet_model.add(Dropout(0.5))\nmobilenet_model.add(Dense(1,activation='linear')) \n\n\n\nmobilenet_model.compile(optimizer = 'adam', loss = 'mean_absolute_error',\n                           metrics = [\"mean_absolute_error\"])\n\n# mobilenet_model.summary()\n\n# Fit model on training data\nmobilenet_model_history = mobilenet_model.fit_generator(\n            train_datagen.flow(X_train,Y_train,\n                         batch_size = batch_size), \n            validation_data = (X_val,Y_val),\n            epochs = epochs,\n            callbacks = [\n                         reduce_learning_rate,\n                         early_stopping,\n                         time_callback\n                        ],\n            verbose=True)","62ce88fb":"mobilenet_train_loss = mobilenet_model_history.history[\"loss\"]\nmobilenet_val_loss = mobilenet_model_history.history[\"val_loss\"]\nmobilenet_train_acc = mobilenet_model_history.history[\"mean_absolute_error\"]\nmobilenet_val_acc = mobilenet_model_history.history[\"val_mean_absolute_error\"]\n\n\nresults[\"mobilenet_adam\"] = {'train-loss': mobilenet_train_loss,\n                             'val-loss': mobilenet_val_loss,\n                             'train-mae': mobilenet_train_acc,\n                             'val-mae': mobilenet_val_acc}","c70dd5b8":"from keras.applications import VGG16\n\n\nconv_base = VGG16(weights='imagenet',                \n                  include_top=False,              \n                  input_shape=(input_shape[0],input_shape[1], 3))\n\nfor layer in conv_base.layers: # make VGG16 weights untrainable\n    layer.trainable = False","d00fddc2":"import keras\n\nvgg_adam = Sequential() \nvgg_adam.add(conv_base) \nvgg_adam.add(MaxPooling2D())\nvgg_adam.add(Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.00001)))\nvgg_adam.add(Dropout(0.5))\nvgg_adam.add(Flatten())\nvgg_adam.add(Dense(1,activation=\"linear\"))\n\nvgg_adam.compile(optimizer = \"adam\",loss=\"mean_absolute_error\", metrics=[\"mean_absolute_error\"])\n\n","df152d47":"vgg_adam_history = vgg_adam.fit_generator(\n            train_datagen.flow(X_train,Y_train,\n                         batch_size = batch_size), # use augmented images\n            validation_data = (X_val,Y_val),\n            steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n            epochs = epochs,\n            callbacks = [\n                         reduce_learning_rate,\n                         early_stopping,\n                         time_callback\n                        ],\n            verbose=True)","7b765954":"vgg_adam_train_loss = vgg_adam_history.history[\"loss\"]\nvgg_adam_val_loss = vgg_adam_history.history[\"val_loss\"]\nvgg_adam_train_acc = vgg_adam_history.history[\"mean_absolute_error\"]\nvgg_adam_val_acc = vgg_adam_history.history[\"val_mean_absolute_error\"]\n\n\nresults[\"vgg_adam\"] = {'train-loss': vgg_adam_train_loss,\n                             'val-loss': vgg_adam_val_loss,\n                             'train-mae': vgg_adam_train_acc,\n                             'val-mae': vgg_adam_val_acc}","c6037868":"color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n\nplt.figure(figsize=(8,6))\nfor i, cond in enumerate(results.keys()):\n    plt.plot(range(len(results[cond]['train-mae'])),results[cond]['train-mae'], '-', label=cond+\"_train\")\n    plt.plot(range(len(results[cond]['val-mae'])),results[cond]['val-mae'], '--', label=cond+\"_val\")\nplt.title(\"Mean Absolute Error\")\nplt.legend()\nplt.show()","d8986f28":"# Baseline model\n\nmodel_test_results = model.evaluate(X_test, Y_test, batch_size=128)\nprint(dict(zip(model.metrics_names, model_test_results)))\n","51353b68":"# MobileNet\n\nmobilenet_model_test_results = mobilenet_model.evaluate(X_test, Y_test, batch_size=128)\nprint(dict(zip(mobilenet_model.metrics_names, mobilenet_model_test_results)))\n","1a2ffa96":"# VGG16\nvgg_test_results = vgg_adam.evaluate(X_test, Y_test, batch_size=128)\nprint(dict(zip(vgg_adam.metrics_names, vgg_test_results)))","906c229b":"# 4.2 Model 2: MobileNet\n\nAdd 6 trainable layers, but freeze the MobileNet layers' weights","7ed011ad":"# 2. Preprocessing","b9af90ac":" <a><\/a>\n# Table of Contents\n1. Loading Data\n2. Preprocessing\n3. Building Models\n    * Simple NN Model with 6 layers\n    * MobileNet V2\n    * VGG16\n4. Tuning Hyperparameters \n4. Results\n\n","b7580cf2":"# 7. Evaluate performance on test set\n","d08f54e3":"# 5. Visualise Model Performances","31c9f259":"# 3. Callbacks and Default Hyperparameters","dad2ec79":"# 6. Results \n\n* MobileNet seems to have the best performance among the 3 models\n* Performance stagnated after 15th epoch","a7d8cbe5":"# 4.1 Model 1: Simple CNN Model\n\n* A simple CNN model with 6 layers:\nInput - Conv - MaxPool - Dropout - Flatten - Output","8d7b3b31":"<a><\/a>\n # 1. Loading Data","fadc43a6":"# 4.3 Model 3: VGG16\n\nAdd 5 trainable layers, but freeze the VGG16 layers' weights"}}