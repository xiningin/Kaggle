{"cell_type":{"5fed45c9":"code","d2523167":"code","c5f9d0fc":"code","ce82d502":"code","e1522ed8":"code","16ba9139":"code","a765dc2f":"code","a8d86b65":"code","6f2771f4":"code","b1d4dc30":"code","e5ba2882":"code","8f29ea35":"code","1d69dd33":"code","7ea89733":"code","98868af9":"code","443f15dc":"code","a55fada8":"code","90c69bb8":"code","78ca25af":"code","4d4ec7bd":"code","a60c6449":"code","78d5111e":"code","95ca8e9d":"code","3b1e50e7":"code","63f3aa07":"code","08e11c9a":"code","d98059cf":"markdown","226658fe":"markdown","e40cee35":"markdown","4a478d6f":"markdown","7fb9c0f0":"markdown","4129c96e":"markdown","7138d8c7":"markdown","c62ca6a7":"markdown","96cecdf3":"markdown","c307af72":"markdown","25446236":"markdown","a6881678":"markdown","5750c6c8":"markdown","e10ed577":"markdown","eacd1388":"markdown","f7bac2ec":"markdown","2ed71543":"markdown","e63ef92f":"markdown"},"source":{"5fed45c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nnp.random.seed(0)\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.image as mpimg\n\nimport tensorflow as tf\ntf.random.set_seed(1)\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d2523167":"# Define our example directories and files\nbase_dir = '..\/input\/chest-xray-pneumonia\/chest_xray'\n\ntrain_dir = os.path.join( base_dir, 'train')\nvalidation_dir = os.path.join( base_dir, 'val')\ntest_dir = os.path.join( base_dir,'test')\n\ntrain_NORMAL_dir = os.path.join(train_dir, 'NORMAL') \ntrain_PNEUMONIA_dir = os.path.join(train_dir, 'PNEUMONIA')\nvalidation_NORMALs_dir = os.path.join(validation_dir, 'NORMAL')\nvalidation_PNEUMONIA_dir = os.path.join(validation_dir, 'PNEUMONIA')\ntest_NORMAL_dir = os.path.join(test_dir, 'NORMAL')\ntest_PNEUMONIA_dir = os.path.join(test_dir, 'PNEUMONIA')\n\n\ntrain_NORMAL_fnames = os.listdir(train_NORMAL_dir)\ntrain_PNEUMONIA_fnames = os.listdir(train_PNEUMONIA_dir)\nvalidation_NORMAL_fnames = os.listdir(validation_NORMALs_dir)\nvalidation_PNEUMONIA_fnames = os.listdir(validation_PNEUMONIA_dir)\n\n#ratio of training set\ntrain_ratio = (len(train_PNEUMONIA_fnames) + len(train_NORMAL_fnames))\/(len(train_PNEUMONIA_fnames) + len(train_NORMAL_fnames)+len(validation_NORMAL_fnames) + len(validation_PNEUMONIA_fnames))\n\nprint(f'NORMAL class in Training set = {len(train_NORMAL_fnames)} : {round(len(train_NORMAL_fnames)\/(len(train_NORMAL_fnames)+len(train_PNEUMONIA_fnames)),3)*100}%')\nprint(f'PNEUMONIA class in Training set = {len(train_PNEUMONIA_fnames)} : {round(len(train_PNEUMONIA_fnames)\/(len(train_NORMAL_fnames)+len(train_PNEUMONIA_fnames)),3)*100}%')\nprint(f'Training set : Validation set ratio = {round(train_ratio*100,1)}% : {round((1-train_ratio)*100,1)}%')","c5f9d0fc":"old_train_set = []\nold_validation_set = []\n\nfor (dirpath, dirnames, filenames) in os.walk(train_dir):\n    old_train_set += [os.path.join(dirpath, file) for file in filenames]\nfor (dirpath, dirnames, filenames) in os.walk(validation_dir):\n    old_validation_set += [os.path.join(dirpath, file) for file in filenames]\n\nfull_train_set = old_train_set + old_validation_set #combine old training and validation set together for further splitting\nfull_train_set = pd.DataFrame({'abs_path' : full_train_set}) #put path into \nfull_train_set.loc[full_train_set['abs_path'].str.contains('NORMAL'), 'Class'] = 'NORMAL'\nfull_train_set.loc[full_train_set['abs_path'].str.contains('PNEUMONIA'), 'Class'] = 'PNEUMONIA'\nfull_train_set.sample(5)","ce82d502":"X = full_train_set['abs_path']\ny = full_train_set['Class']\n\n\nval_split = 0.2\n\nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size = val_split,stratify=y,random_state=42)\n\ntrain_set = pd.DataFrame({'abs_path':X_train,'Class':y_train})\nvalidation_set = pd.DataFrame({'abs_path':X_val,'Class':y_val})","e1522ed8":"datagen = ImageDataGenerator(rescale=1.\/255,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            shear_range=0.1,\n                            zoom_range=0.1,)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n#Train Image Generator\ntrain_generator=datagen.flow_from_dataframe(\ndataframe=train_set,\nx_col=\"abs_path\",\ny_col=\"Class\",\nbatch_size=32,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(150,150))\n\n#Validation Image Generator\nvalidation_generator=test_datagen.flow_from_dataframe(\ndataframe=validation_set,\nx_col=\"abs_path\",\ny_col=\"Class\",\nbatch_size=32,\nseed=42,\nshuffle=False,\nclass_mode=\"binary\",\ntarget_size=(150,150))\n\n#Test Image Generator\ntest_generator = test_datagen.flow_from_directory(\ntest_dir,\nbatch_size=32,\nshuffle=False,    \nclass_mode=\"binary\",\ntarget_size = (150,150))","16ba9139":"normal_count = 0\npneumonia_count = 0\nfor i in range(len(train_generator.labels)):\n    if train_generator.labels[i] == 0:\n        normal_count += 1\n    else:\n        pneumonia_count += 1\n        \nassert(normal_count+pneumonia_count==len(train_generator.labels))\n\n\nnormal_weight = pneumonia_count\/normal_count\npneumonia_weight = 1\n\nclass_weight = {0:normal_weight,1:pneumonia_weight}\nprint(class_weight)","a765dc2f":"val_normal_count = 0\nval_pneumonia_count = 0\nfor i in range(len(validation_generator.labels)):\n    if validation_generator.labels[i] == 0:\n        val_normal_count += 1\n    else:\n        val_pneumonia_count += 1\n        \nprint(f'normal in train set = {normal_count}')\nprint(f'pneumonia in train set = {pneumonia_count}')\nprint(f'normal in val set = {val_normal_count}')\nprint(f'pneumonia in val set = {val_pneumonia_count}')","a8d86b65":"x_batch, y_batch = next(train_generator)\nfig = plt.figure(figsize = (20,20))\n\nfor i in range(25):\n    ax = plt.subplot(5,5,i+1)\n    plt.imshow(x_batch[i])\n    if y_batch[i] == 1:\n        plt.title('PNEUMONIA')\n    else:\n        plt.title('NORMAL')\n","6f2771f4":"from tensorflow.keras.applications.vgg16 import VGG16\n\ndef create_model():\n    \n    pre_trained_model = VGG16(input_shape=(150,150,3),include_top=False)\n    \n    #freeze layers weight \n    for layer in pre_trained_model.layers:\n        layer.trainable = False\n    \n    \n    last_layer = pre_trained_model.get_layer('block5_pool')\n    print('last layer output shape: ', last_layer.output_shape)\n    last_output = last_layer.output\n    \n    \n    # Flatten the output layer to 1 dimension\n    x = layers.Flatten()(last_output)\n    # Add a fully connected layer with 128 hidden units and ReLU activation\n    x = layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n    # Add a dropout rate of 0.2\n    x = layers.Dropout(0.2)(x)\n    # Add a final sigmoid layer for classification\n    x = layers.Dense(1, activation='sigmoid')(x)           \n    \n    METRICS = [\n          tf.keras.metrics.TruePositives(name='tp'),\n          tf.keras.metrics.FalsePositives(name='fp'),\n          tf.keras.metrics.TrueNegatives(name='tn'),\n          tf.keras.metrics.FalseNegatives(name='fn'), \n          tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n          tf.keras.metrics.Precision(name='precision'),\n          tf.keras.metrics.Recall(name='recall'),\n          tf.keras.metrics.AUC(name='auc'),\n    ]\n    \n    \n    model = Model(pre_trained_model.input, x) \n    \n    model.compile(optimizer = tf.keras.optimizers.SGD(\n    learning_rate=0.001, momentum=0.9),\n                  loss = 'binary_crossentropy', \n                  metrics = METRICS)\n    \n    model.summary()\n\n    return model","b1d4dc30":"#Training hyperparameters\nbatch_size = 32\nsteps_per_epoch = len(train_generator.labels) \/\/ batch_size\nvalidation_step = len(validation_generator.labels) \/\/ batch_size\nepochs = 30\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_auc', \n    verbose=1,\n    patience=15,\n    mode='max',\n    restore_best_weights=True)\n\nbaseline_model = create_model()\nbaseline_history = baseline_model.fit(train_generator,\n        validation_data = validation_generator,\n        steps_per_epoch = steps_per_epoch,\n        epochs = epochs,\n        validation_steps = validation_step,\n        callbacks = [early_stopping]\n                            );\n\n","e5ba2882":"plt.style.use('ggplot')\nfrom sklearn.metrics import confusion_matrix, roc_curve\ndef plot_metrics(history):\n    metrics =  ['loss', 'auc', 'precision', 'recall']\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle('Preliminary performance of model', fontsize=16, y=1.05)\n    for n, metric in enumerate(metrics):\n        name = metric.replace(\"_\",\" \").capitalize()\n        plt.subplot(2,2,n+1)\n        sns.lineplot(history.epoch,  history.history[metric], label='Train')\n        sns.lineplot(history.epoch, history.history['val_'+metric] ,label='Val')\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        if metric == 'loss':\n          plt.ylim([0, plt.ylim()[1]])\n        elif metric == 'auc':\n          plt.ylim([0.8,1])\n        else:\n          plt.ylim([0,1])\n    \n        plt.legend()\n        \n    fig.tight_layout(pad=1.0)\n\ndef plot_cm(labels, predictions, p=0.5):\n    cm = confusion_matrix(labels, predictions > p)\n    plt.figure(figsize=(5,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\")\n    plt.title('Confusion matrix @{:.2f}'.format(p))\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n\n    print('Normal Chest X-rays Detected (True Negatives): ', cm[0][0])\n    print('Normal Chest X-rays Incorrectly Detected (False Positives): ', cm[0][1])\n    print('Pneumonia Chest X-rays Missed (False Negatives): ', cm[1][0])\n    print('Pneumonia Chest X-rays Detected (True Positives): ', cm[1][1])\n    print('Total Pneumonia Chest X-rays : ', np.sum(cm[1]))\n    \ndef plot_roc(name, labels, predictions,zoom=False, **kwargs):\n    fp, tp, _ = roc_curve(labels, predictions)\n    \n    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n    plt.xlabel('False positives [%]')\n    plt.ylabel('True positives [%]')\n    if zoom == True:\n        plt.xlim([-0.5,20])\n        plt.ylim([80,100.5])\n    else:\n        plt.xlim([-0.5,100])\n        plt.ylim([0,100.5])\n    plt.grid(True)\n    ax = plt.gca()\n    ax.set_aspect('equal')","8f29ea35":"plot_metrics(baseline_history)","1d69dd33":"train_prediction_baseline = baseline_model.predict(train_generator, batch_size = batch_size)\ntest_prediction_baseline = baseline_model.predict(test_generator, batch_size = batch_size)","7ea89733":"plot_cm(test_generator.labels,test_prediction_baseline)","98868af9":"plot_roc(\"Train Baseline\", train_generator.labels,train_prediction_baseline)\nplot_roc(\"Test Baseline\", test_generator.labels,test_prediction_baseline, linestyle='--')\nplt.legend(loc='lower right')","443f15dc":"plot_roc(\"Train Baseline\", train_generator.labels,train_prediction_baseline,zoom=True)\nplot_roc(\"Test Baseline\", test_generator.labels,test_prediction_baseline, linestyle='--',zoom=True)\nplt.legend(loc='lower right')","a55fada8":"#Checkpoint callback\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"xray_model.h5\",monitor='val_loss',save_best_only=True)\n\n#Reduce LR on Plateau\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=10,\n    verbose=0,\n    mode=\"auto\",\n    min_lr=0.0001)","90c69bb8":"finetuned_model = create_model()\n#load weight from baseline model\nfinetuned_model.set_weights(baseline_model.get_weights());","78ca25af":"#train some VGG16 layers\n# for count,layer in enumerate(finetuned_model.layers):\n#     if count in np.arange(15,23).tolist():\n#         layer.trainable = True\n        \nMETRICS = [\n          tf.keras.metrics.TruePositives(name='tp'),\n          tf.keras.metrics.FalsePositives(name='fp'),\n          tf.keras.metrics.TrueNegatives(name='tn'),\n          tf.keras.metrics.FalseNegatives(name='fn'), \n          tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n          tf.keras.metrics.Precision(name='precision'),\n          tf.keras.metrics.Recall(name='recall'),\n          tf.keras.metrics.AUC(name='auc'),\n    ]\n\n    \nfinetuned_model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n            loss = 'binary_crossentropy', \n            metrics = METRICS)\nfinetuned_model.summary()","4d4ec7bd":"epochs = 100\nfinetuned_history = finetuned_model.fit(train_generator,\n        validation_data = validation_generator,\n        steps_per_epoch = steps_per_epoch,\n        epochs = epochs,\n        validation_steps = validation_step,\n        class_weight=class_weight, #introduce class weight into model training\n        callbacks = [early_stopping,checkpoint,reduce_lr]\n                            ) ","a60c6449":"plot_metrics(finetuned_history)","78d5111e":"train_prediction_finetuned = finetuned_model.predict(train_generator, batch_size = batch_size)\ntest_prediction_finetuned = finetuned_model.predict(test_generator, batch_size = batch_size)","95ca8e9d":"plot_cm(test_generator.labels,test_prediction_finetuned)","3b1e50e7":"plot_roc(\"Train baseline\", train_generator.labels,train_prediction_baseline,color='r')\nplot_roc(\"Test baseline\", test_generator.labels,test_prediction_baseline, linestyle='--',color='r')\nplot_roc(\"Train finetuned\", train_generator.labels,train_prediction_finetuned,color='b')\nplot_roc(\"Test finetuned\", test_generator.labels,test_prediction_finetuned, linestyle='--',color='b')\nplt.legend(loc='lower right')","63f3aa07":"plot_roc(\"Train baseline\", train_generator.labels,train_prediction_baseline,color='r',zoom=True)\nplot_roc(\"Test baseline\", test_generator.labels,test_prediction_baseline, linestyle='--',color='r',zoom=True)\nplot_roc(\"Train finetuned\", train_generator.labels,train_prediction_finetuned,color='b',zoom=True)\nplot_roc(\"Test finetuned\", test_generator.labels,test_prediction_finetuned, linestyle='--',color='b',zoom=True)\nplt.legend(loc='lower right')","08e11c9a":"finetuned_results = finetuned_model.evaluate(test_generator,batch_size=batch_size, verbose=0)\nfor name, value in zip(finetuned_model.metrics_names, finetuned_results):\n    print(name, ': ', value)","d98059cf":"Let's have a look what our dataset look like ...","226658fe":"# Acknowledgement","e40cee35":"# Data preparation","4a478d6f":"This notebook is inspired by :\n\n[1] [Wikipedia : Pneumonia](https:\/\/en.wikipedia.org\/wiki\/Pneumonia#Respiratory_and_circulatory_failure)\n\n[2] [WHO : Pneumonia](https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/pneumonia)\n\n[3] [VGG16 : Pretrained model from Tensorflow](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications\/vgg16)\n\n[4] [Transfer Learning : from Tensorflow in pratice specialization](https:\/\/github.com\/lmoroney\/dlaicourse\/blob\/master\/Exercises\/Exercise%207%20-%20Transfer%20Learning\/Exercise%207%20-%20Answer.ipynb)\n\n[5] [TensorFlow Pneumonia Classification on X-rays by Amy Jang](https:\/\/www.kaggle.com\/amyjang\/tensorflow-pneumonia-classification-on-x-rays) where she point out interesting problem and solution for this dataset\n\n[6] [ImageGenerator flow from dataframe](https:\/\/medium.com\/@vijayabhaskar96\/tutorial-on-keras-flow-from-dataframe-1fd4493d237c)\n\n[7] [Precision recall curve for Keras model](https:\/\/www.dlology.com\/blog\/simple-guide-on-how-to-generate-roc-plot-for-keras-classifier\/)","7fb9c0f0":"# Dataset Visualization","4129c96e":"Looking good! We've managed to solve extreme training and validation set split from 99:1 ratio to 80:20 ratio with stratified class.","7138d8c7":"# Model Buidling","c62ca6a7":"# Fine tune the model","96cecdf3":"![Pneumonia](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/23\/Lobar_pneumonia_illustrated.jpg)\n\n> Pneumonia is an **inflammatory condition of the lung primarily affecting the small air sacs known as alveoli**. Symptoms typically include some combination of productive or **dry cough, chest pain, fever and difficulty breathing**. The severity of the condition is variable. Pneumonia is **usually caused by infection with viruses or bacteria**, and less commonly by other microorganisms. Identifying the responsible pathogen can be difficult. Diagnosis is often based on symptoms and physical examination. Chest X-rays, blood tests, and culture of the sputum may help confirm the diagnosis. The disease may be classified by where it was acquired, such as community- or hospital-acquired or healthcare-associated pneumonia.[1]\n\n> According to WHO, Pneumonia is the single **largest infectious cause of death in children worldwide**. Pneumonia killed 808 694 children under the age of 5 in 2017, accounting for 15% of all deaths of children under five years old. Pneumonia affects children and families everywhere, but is most prevalent in South Asia and sub-Saharan Africa. Children can be protected from pneumonia, it can be prevented with simple interventions, and treated with low-cost, low-tech medication and care.[2]\n\nTherefore, the earlier detection of Pneumania, the better chance of survival of children. In this study we'll focus on building a model to help doctor classifying chest x-rays images to identify which patiences has Pneumonia or not?","c307af72":"![VGG-16 architecture](https:\/\/neurohive.io\/wp-content\/uploads\/2018\/11\/vgg16.png)\n\nTo save time for model development, I decide to use pretrained VGG16 model from Tensorflow [3] you can try other model to see the different","25446236":"# Conclusion","a6881678":"# Data Explanation\n![Example](https:\/\/i.imgur.com\/jZqpV51.png)\n\nThe dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia\/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia\/Normal).\n\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\u2019s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients\u2019 routine clinical care.\n\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.","5750c6c8":"From sample of our dataset, \n\n* Chest x-rays for people who are healthy (NORMAL) are clearer, minimal white shaded in lung area\n* On the other hand, for people who have Pneumonia, their x-rays image seem more opaque. ","e10ed577":"# Pneumania Classification : Transfered CNN","eacd1388":"# What exactly is Pneumania : Why we should pay attention to it?","f7bac2ec":"**Cautions!**\n* We might experience class imbalanced problem. We should be awared that classification accuracy is not a good evaluating metrics in this case.\n* Training\/Validation set split is too extreme. With this size of validation set, our model may not generalized enough. To fix this I'll re-split train:val set to have more proper ratio","2ed71543":"Baseline performance are poor. The model wrongly classify normal chest x-rays into Pneumonia case which may result in too much workload for examiner. But the good things is there is minimal amount of Pneumonia chest x rays wrongly classified as normal chest x-rays.\n\nLet's see how can we improve the model by \n\n1. Introduce class weight into the model to overcome imbalanced class problem\n1. Use of ReduceLRonPlateau and Checkpoint callback\n1. Unfreeze some layer of VGG16 and train it","e63ef92f":"With limited time, we're able to build x-rays image classifier to classify to correctly predict Pneumonia chest x-rays with minimal Pneumonia cases wrongly classify as Normal (FN). Then we try to improve model performance by fine tuning with class weight and few techniques. We have acheive some improvement, but our model still have high amount of false positive (Normal case wrongly classify as Pneumonia)\n\nWe can see that our accuracy on test set is about 92% (relatively lower than accuracy in training and validation set). This indicate significant level of overfitting. Try reduce model complexity by cutting off some layers of VGG16 and adjust regularization parameters such as drop out rate and L2 regularization in Dense layers may help.\n\nOur recall is greater than our precision, which mean that almost all pneumonia x-ray images are correctly classified (which is our main objective) but there are some normal images wrongly identified. I will study further on how to solve this problem."}}