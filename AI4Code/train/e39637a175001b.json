{"cell_type":{"44a6fc73":"code","f5dc918d":"code","5e99f54c":"code","8ce0e813":"code","699ffb00":"code","e0be6224":"code","bb643b29":"code","f5bc3588":"code","c8a97dc8":"code","dbc662f5":"code","8143e52f":"code","27512bd0":"code","df876ed1":"code","823f8945":"code","c865be71":"code","92b9b0c2":"code","63da00a2":"code","c5d9aa34":"code","f980c392":"code","797a5a2f":"code","9447eba8":"code","4dfaa447":"code","516deaf9":"code","58fae249":"code","902bdc36":"code","1cd0885a":"code","899b7d9b":"code","8574d9fc":"code","74d672b5":"code","b994db37":"code","d801f57a":"code","e0606eeb":"code","5cfc1f83":"code","cf95c9a1":"code","529e7ddf":"markdown"},"source":{"44a6fc73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5dc918d":"df = pd.read_csv('\/kaggle\/input\/churn-modelling\/Churn_Modelling.csv')\n\ndf.head()","5e99f54c":"df = df.iloc[:,3:]\n\ndf.head()","8ce0e813":"df.describe()","699ffb00":"df.info()","e0be6224":"df['Geography'].value_counts()","bb643b29":"df['Gender'].value_counts()","f5bc3588":"df = pd.get_dummies(df, drop_first=True)\n\ndf.head()","c8a97dc8":"y = df['Exited']\nX = df.drop('Exited', 1)","dbc662f5":"X.shape","8143e52f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","27512bd0":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","df876ed1":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense\nfrom keras.layers import LeakyReLU, PReLU, ELU\nfrom keras.layers import Dropout","823f8945":"classifier = Sequential()","c865be71":"# adding the input layer and first hidden layer\nclassifier.add(Dense(units=10, kernel_initializer=\"he_normal\", activation=\"relu\", input_dim=11))\nclassifier.add(Dropout(0.2))\n# adding the second hidden layer\nclassifier.add(Dense(units=20, kernel_initializer=\"he_normal\", activation=\"relu\"))\nclassifier.add(Dropout(0.4))\n# adding the third hidden layer\nclassifier.add(Dense(units=15, kernel_initializer=\"he_normal\", activation=\"relu\"))\nclassifier.add(Dropout(0.3))\n# adding the output layer\nclassifier.add(Dense(units=1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))","92b9b0c2":"# compiling the ANN\nclassifier.compile(optimizer=\"Adamax\", loss=\"binary_crossentropy\", metrics=['accuracy'])","63da00a2":"# fitting the ANN\nmodel_history = classifier.fit(X_train, y_train, validation_split=0.33, batch_size=10, epochs=100)","c5d9aa34":"print(model_history.history.keys())","f980c392":"plt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','test'], loc='upper left')\nplt.show()","797a5a2f":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\nscore, acc = classifier.evaluate(X_test, y_test,\n                            batch_size=10)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","9447eba8":"p = sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","4dfaa447":"#import classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","516deaf9":"from sklearn.metrics import roc_curve\ny_pred_proba = classifier.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='ANN')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nplt.show()","58fae249":"#Area under ROC curve\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred_proba)","902bdc36":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ndef create_model(layers, activation, optimizer):\n    model = Sequential()\n    for i, nodes in enumerate(layers):\n        if i == 0:\n            model.add(Dense(nodes,input_dim=X.shape[1]))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n        else:\n            model.add(Dense(nodes))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n    \n    model.add(Dense(units=1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\n    model.compile(optimizer = optimizer, loss=\"binary_crossentropy\", metrics=['accuracy'])    \n    return model","1cd0885a":"model = KerasClassifier(build_fn=create_model)\n\nparameters = {'layers': [(40,30),(45,30,15)],\n              'activation': ['sigmoid', 'relu'],\n              'batch_size': [64, 128, 256],\n              'epochs': [50, 100],\n              'optimizer': ['adam', 'rmsprop']}\n\n\ngrid = GridSearchCV(estimator=model, param_grid=parameters, cv=3, verbose=10)","899b7d9b":"grid_search = grid.fit(X_train, y_train)","8574d9fc":"print('Best Parameters after tuning: {}'.format(grid_search.best_params_))\nprint('Best Accuracy after tuning: {}'.format(grid_search.best_score_))","74d672b5":"# Predicting the Test set results\ny_pred_grid = grid.predict(X_test)\ny_pred_grid = (y_pred_grid > 0.5)\n\nscore, acc = classifier.evaluate(X_test, y_test, batch_size=10)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred_grid)","b994db37":"p = sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","d801f57a":"print(classification_report(y_test,y_pred_grid))","e0606eeb":"y_pred_proba","5cfc1f83":"y_pred_proba = grid.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:][:,1])\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='ANN')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nplt.show()","cf95c9a1":"#Area under ROC curve\nroc_auc_score(y_test,y_pred_proba[:][:,1])","529e7ddf":"## Hyperparameter Optimization"}}