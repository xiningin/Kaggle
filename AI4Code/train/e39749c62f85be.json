{"cell_type":{"b9610449":"code","56df3f60":"code","04905fbf":"code","76240bd1":"code","145350a5":"code","795e834c":"code","20252886":"code","db4d1f4c":"code","db93ae89":"code","c6f2a70a":"code","15a72e43":"code","369ac50c":"code","698bfb9b":"code","50efbf9d":"code","f593bae9":"code","786da3e0":"code","d6b4d1d5":"code","40151809":"code","55d60ffd":"code","d02637a1":"code","75ca3d8e":"code","437fe42e":"markdown","c8879775":"markdown","b87d1653":"markdown","2b1b3896":"markdown","7f68d30b":"markdown","bdb65a9d":"markdown","fe764835":"markdown","1dc0964a":"markdown","d8c2184a":"markdown","047afd9c":"markdown","01b4bef9":"markdown","89be6826":"markdown","b66e0787":"markdown"},"source":{"b9610449":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm","56df3f60":"TRAIN_DIR = '..\/input\/sms-spam-collection-dataset\/spam.csv'","04905fbf":"df = pd.read_csv(TRAIN_DIR, encoding='latin-1') ","76240bd1":"df.head()","145350a5":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer","795e834c":"X_train, X_val, y_train, y_val = train_test_split(list(df['v2']), list(df['v1']), test_size=0.2, random_state=0) \nprint(f'Training Set: X_train Shape: {len(X_train)} | y_train Shape: {len(y_train)}')\nprint(f'Validation Set: X_val Shape: {len(X_val)} | y_val Shape: {len(y_val)}')","20252886":"X_train[0]","db4d1f4c":"class tokenizer:\n    def __init__(self, text_data):\n        self.vocab = {}\n        self.__get_vocab(text_data)\n        \n    def convert_text_dataset_to_matrix(self, X):\n        vocab = self.vocab\n        result = []       \n        for text in tqdm(X):\n            vector = self.__text_to_vector(text)\n            result.append(vector)\n        return result\n    \n    def __get_vocab(self, text_data):\n        word_id = 0\n        for text in text_data:\n            words = text.split()\n            for word in words:\n                word = word.lower()\n                if word not in self.vocab:\n                    self.vocab[word] = word_id\n                    word_id += 1\n        print(f'Length of Dictionary: {len(self.vocab)}')\n    \n    def __text_to_vector(self, text):\n        vocab = self.vocab\n        result = list(np.zeros(len(vocab)))\n        words = text.split()\n        for word in words:\n            word = word.lower()\n            if word in vocab:\n                result[vocab[word]] += 1\n        return result","db93ae89":"tz = tokenizer(X_train)","c6f2a70a":"X_train_matrix = tz.convert_text_dataset_to_matrix(X_train)\nX_val_matrix = tz.convert_text_dataset_to_matrix(X_val)","15a72e43":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","369ac50c":"def plot_confusion_matrix(conf_mtrx, classes, cmap=plt.cm.Blues):\n    num_class = conf_mtrx.shape[0]\n    \n    fig, ax = plt.subplots()\n    im = ax.imshow(conf_mtrx, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    ax.set(xticks=np.arange(num_class), yticks=np.arange(num_class),\n           xticklabels=classes, yticklabels=classes, \n           ylabel='True label', xlabel='Predicted label')\n\n    middle_threshold = conf_mtrx.max() \/ 2.\n    for row in range(num_class):\n        for col in range(num_class):\n            ax.text(col, row, format(conf_mtrx[row, col], '.0f'), ha=\"center\", va=\"center\",\n                    color=\"white\" if conf_mtrx[row, col] > middle_threshold else \"black\")\n    fig.tight_layout()\n    plt.show()","698bfb9b":"nb = MultinomialNB()\nnb.fit(X_train_matrix, y_train)","50efbf9d":"y_pred = nb.predict(X_val_matrix)","f593bae9":"print('Accuracy: ', accuracy_score(y_val, y_pred))\nprint('Confusion Matrix')\nprint(confusion_matrix(y_val, y_pred))\nprint('Classification Report')\nprint(classification_report(y_val, y_pred))","786da3e0":"plot_confusion_matrix(confusion_matrix(y_val, y_pred),classes=['ham', 'spam'])","d6b4d1d5":"class NaiveBayes_Spam:\n    def __init__(self):\n        self.log_p_spam_vector = None\n        self.log_p_ham_vector = None\n        self.log_p_spam = None\n        self.log_p_ham = None\n    \n    def fit(self, X_train, y_train):\n        num_text, num_words = len(X_train), len(X_train[0])\n        spam_word_counter, ham_word_counter = np.ones(num_words), np.ones(num_words) # Laplace Smoothing\n        spam_total_count, ham_total_count = 0, 0\n        spam_count, ham_count = 0, 0\n        \n        for i in tqdm(range(num_text)):\n            if y_train[i] == 'ham':\n                ham_word_counter += X_train[i]\n                ham_total_count += sum(X_train[i])\n                ham_count += 1\n            else:\n                spam_word_counter += X_train[i]\n                spam_total_count += sum(X_train[i])\n                spam_count += 1\n        \n        # log p(x|spam) (With Laplace Smoothing): For all the words in spam emails,\n        # the frequency of word x shows up.\n        self.log_p_spam_vector = np.log(spam_word_counter \\\n             \/ (spam_total_count + num_words))\n        # log p(x|ham)\n        self.log_p_ham_vector = np.log(ham_word_counter \\\n             \/ (ham_total_count + num_words))\n        # log p(spam)\n        self.log_p_spam = np.log(spam_count \/ num_text) \n        # log p(ham)\n        self.log_p_ham = np.log(ham_count \/ num_text) \n    \n    def predict(self, X):\n        num_text = len(X)\n        result = []\n        for i in tqdm(range(num_text)):\n            log_p_spam = sum(X[i] * self.log_p_spam_vector) + self.log_p_spam\n            log_p_ham = sum(X[i] * self.log_p_ham_vector) + self.log_p_ham\n            if log_p_spam > log_p_ham:\n                result.append('spam')\n            else:\n                result.append('ham')\n        return result","40151809":"nb = NaiveBayes_Spam()\nnb.fit(X_train_matrix, y_train)","55d60ffd":"y_pred = nb.predict(X_val_matrix)","d02637a1":"print('Accuracy: ', accuracy_score(y_val, y_pred))\nprint('Confusion Matrix')\nprint(confusion_matrix(y_val, y_pred))\nprint('Classification Report')\nprint(classification_report(y_val, y_pred))","75ca3d8e":"plot_confusion_matrix(confusion_matrix(y_val, y_pred),classes=['ham', 'spam'])","437fe42e":"# Model 1: Naive Bayes Model","c8879775":"3.Predict","b87d1653":"# Prepare Data","2b1b3896":"2.Build Vocab","7f68d30b":"Kaggle: https:\/\/www.kaggle.com\/uciml\/sms-spam-collection-dataset","bdb65a9d":"# Model 2: Naive Bayes Model (No Sklearn)","fe764835":"1.Split Training Set and Validation Set","1dc0964a":"2.Train","d8c2184a":"2.Predict","047afd9c":"1.Fit","01b4bef9":"# Explantory Data Analysis","89be6826":"1.Take a Glance at the Data","b66e0787":"1.Model Definition"}}