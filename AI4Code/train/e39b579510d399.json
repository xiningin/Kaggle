{"cell_type":{"e427e153":"code","b15fb163":"code","dc95e974":"code","a5a6d8a0":"code","8387380a":"code","54b7ca9e":"code","2e452a83":"code","c13d8e23":"code","5b9bcd52":"code","b74f989e":"code","98517702":"code","59d3f491":"code","5897f4e9":"code","7e2b3525":"code","b2afc658":"code","fbbe3b2b":"code","c5c1fe5c":"code","ae32954f":"code","4ed2d9d5":"code","3928a653":"code","ed73f7fc":"code","1db2f50d":"code","1a6d54fc":"code","e3f3054f":"code","7381b319":"code","74771561":"code","4876646a":"code","2f3aa0bb":"code","3decd49c":"code","c231860c":"code","79445790":"markdown","cdfa7650":"markdown","4160eae5":"markdown","ce021c73":"markdown","5f0bab0e":"markdown","941ac7ff":"markdown","3932eef4":"markdown","7b81fa83":"markdown"},"source":{"e427e153":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b15fb163":"\n# example of loading the keras facenet model\nfrom keras.models import load_model\n# load the model\nmodel = load_model('\/kaggle\/input\/facenet-keras\/facenet_keras.h5')\n# summarize input and output shape\nprint(model.inputs)\nprint(model.outputs)","dc95e974":"!pip install \/kaggle\/input\/mtcnn-package\/mtcnn-0.1.0-py3-none-any.whl","a5a6d8a0":"\n# confirm mtcnn was installed correctly\nimport mtcnn\n# print version\nprint(mtcnn.__version__)","8387380a":"# function for face detection with mtcnn\nfrom PIL import Image\nfrom numpy import asarray\nfrom mtcnn.mtcnn import MTCNN\n\n# extract a single face from a given photograph\ndef extract_face(filename, required_size=(160, 160)):\n\t# load image from file\n\timage = Image.open('\/kaggle\/input\/sample-face-images\/00000008.jpg')\n\t# convert to RGB, if needed\n\timage = image.convert('RGB')\n\t# convert to array\n\tpixels = asarray(image)\n\t# create the detector, using default weights\n\tdetector = MTCNN()\n\t# detect faces in the image\n\tresults = detector.detect_faces(pixels)\n\t# extract the bounding box from the first face\n\tx1, y1, width, height = results[0]['box']\n\t# bug fix\n\tx1, y1 = abs(x1), abs(y1)\n\tx2, y2 = x1 + width, y1 + height\n\t# extract the face\n\tface = pixels[y1:y2, x1:x2]\n\t# resize pixels to the model size\n\timage = Image.fromarray(face)\n\timage = image.resize(required_size)\n\tface_array = asarray(image)\n\treturn face_array\n\n# load the photo and extract the face\npixels = extract_face('...')\nprint(pixels)","54b7ca9e":"# demonstrate face detection on 5 Celebrity Faces Dataset\nfrom os import listdir\nfrom PIL import Image\nfrom numpy import asarray\nfrom matplotlib import pyplot\nfrom mtcnn.mtcnn import MTCNN\n\n# extract a single face from a given photograph\ndef extract_face(filename, required_size=(160, 160)):\n\t# load image from file\n\timage = Image.open(filename)\n\t# convert to RGB, if needed\n\timage = image.convert('RGB')\n\t# convert to array\n\tpixels = asarray(image)\n\t# create the detector, using default weights\n\tdetector = MTCNN()\n\t# detect faces in the image\n\tresults = detector.detect_faces(pixels)\n\t# extract the bounding box from the first face\n\tx1, y1, width, height = results[0]['box']\n\t# bug fix\n\tx1, y1 = abs(x1), abs(y1)\n\tx2, y2 = x1 + width, y1 + height\n\t# extract the face\n\tface = pixels[y1:y2, x1:x2]\n\t# resize pixels to the model size\n\timage = Image.fromarray(face)\n\timage = image.resize(required_size)\n\tface_array = asarray(image)\n\treturn face_array\n\n# specify folder to plot\nfolder = '\/kaggle\/input\/5-celebrity-faces-dataset\/train\/ben_afflek\/'\ni = 1\n# enumerate files\nfor filename in listdir(folder):\n\t# path\n\tpath = folder + filename\n\t# get face\n\tface = extract_face(path)\n\tprint(i, face.shape)\n\t# plot\n\tpyplot.subplot(2, 7, i)\n\tpyplot.axis('off')\n\tpyplot.imshow(face)\n\ti += 1\npyplot.show()","2e452a83":"# load images and extract faces for all images in a directory\ndef load_faces(directory):\n\tfaces = list()\n\t# enumerate files\n\tfor filename in listdir(directory):\n\t\t# path\n\t\tpath = directory + filename\n\t\t# get face\n\t\tface = extract_face(path)\n\t\t# store\n\t\tfaces.append(face)\n\treturn faces","c13d8e23":"# load a dataset that contains one subdir for each class that in turn contains images\ndef load_dataset(directory):\n\tX, y = list(), list()\n\t# enumerate folders, on per class\n\tfor subdir in listdir(directory):\n\t\t# path\n\t\tpath = directory + subdir + '\/'\n\t\t# skip any files that might be in the dir\n\t\t#\n\t\t# load all faces in the subdirectory\n\t\tfaces = load_faces(path)\n\t\t# create labels\n\t\tlabels = [subdir for _ in range(len(faces))]\n\t\t# summarize progress\n\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n\t\t# store\n\t\tX.extend(faces)\n\t\ty.extend(labels)\n\treturn asarray(X), asarray(y)","5b9bcd52":"# load train dataset\ntrainX, trainy = load_dataset('\/kaggle\/input\/5-celebrity-faces-dataset\/train\/')\nprint(trainX.shape, trainy.shape)\n# load test dataset\ntestX, testy = load_dataset('\/kaggle\/input\/5-celebrity-faces-dataset\/val\/')\nprint(testX.shape, testy.shape)\n# save arrays to one file in compressed format\n","b74f989e":"import numpy\nnumpy.savez_compressed('5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)","98517702":"# face detection for the 5 Celebrity Faces Dataset\nfrom os import listdir\nfrom os.path import isdir\nfrom PIL import Image\nfrom matplotlib import pyplot\nfrom numpy import savez_compressed\nfrom numpy import asarray\nimport numpy\nfrom mtcnn.mtcnn import MTCNN\n\n# extract a single face from a given photograph\ndef extract_face(filename, required_size=(160, 160)):\n\t# load image from file\n\timage = Image.open(filename)\n\t# convert to RGB, if needed\n\timage = image.convert('RGB')\n\t# convert to array\n\tpixels = asarray(image)\n\t# create the detector, using default weights\n\tdetector = MTCNN()\n\t# detect faces in the image\n\tresults = detector.detect_faces(pixels)\n\t# extract the bounding box from the first face\n\tx1, y1, width, height = results[0]['box']\n\t# bug fix\n\tx1, y1 = abs(x1), abs(y1)\n\tx2, y2 = x1 + width, y1 + height\n\t# extract the face\n\tface = pixels[y1:y2, x1:x2]\n\t# resize pixels to the model size\n\timage = Image.fromarray(face)\n\timage = image.resize(required_size)\n\tface_array = asarray(image)\n\treturn face_array\n\n# load images and extract faces for all images in a directory\ndef load_faces(directory):\n\tfaces = list()\n\t# enumerate files\n\tfor filename in listdir(directory):\n\t\t# path\n\t\tpath = directory + filename\n\t\t# get face\n\t\tface = extract_face(path)\n\t\t# store\n\t\tfaces.append(face)\n\treturn faces\n\n# load a dataset that contains one subdir for each class that in turn contains images\ndef load_dataset(directory):\n\tX, y = list(), list()\n\t# enumerate folders, on per class\n\tfor subdir in listdir(directory):\n\t\t# path\n\t\tpath = directory + subdir + '\/'\n\t\t# skip any files that might be in the dir\n\t\t#is dir removed here ######################\n\t\t# load all faces in the subdirectory\n\t\tfaces = load_faces(path)\n\t\t# create labels\n\t\tlabels = [subdir for _ in range(len(faces))]\n\t\t# summarize progress\n\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n\t\t# store\n\t\tX.extend(faces)\n\t\ty.extend(labels)\n\treturn asarray(X), asarray(y)\n\n# load train dataset\ntrainX, trainy = load_dataset('\/kaggle\/input\/5-celebrity-faces-dataset\/train\/')\nprint(trainX.shape, trainy.shape)\n# load test dataset\ntestX, testy = load_dataset('\/kaggle\/input\/5-celebrity-faces-dataset\/val\/')\n# save arrays to one file in compressed format\nnumpy.savez_compressed('5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)","59d3f491":"# load the face dataset\nimport numpy\ndata = numpy.load('5-celebrity-faces-dataset.npz')\ntrainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\nprint('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)","5897f4e9":"# load the facenet model\nimport keras.models\nmodel = keras.models.load_model('\/kaggle\/input\/facenet-keras\/facenet_keras.h5')\nprint('Loaded Model')","7e2b3525":"from numpy import load\nfrom numpy import expand_dims\nfrom numpy import asarray\nfrom numpy import savez_compressed\nfrom keras.models import load_model\ndef get_embedding(model, face_pixels):\n\t# scale pixel values\n\tface_pixels = face_pixels.astype('float32')\n\t# standardize pixel values across channels (global)\n\tmean, std = face_pixels.mean(), face_pixels.std()\n\tface_pixels = (face_pixels - mean) \/ std\n\t# transform face into one sample\n\tsamples = expand_dims(face_pixels, axis=0)\n\t# make prediction to get embedding\n\tyhat = model.predict(samples)\n\treturn yhat[0]\n","b2afc658":"newTrainX = list()\nfor face_pixels in trainX:\n\tembedding = get_embedding(model, face_pixels)\n\tnewTrainX.append(embedding)\nnewTrainX = asarray(newTrainX)\nprint(newTrainX.shape)\n# convert each face in the test set to an embedding\nnewTestX = list()\nfor face_pixels in testX:\n\tembedding = get_embedding(model, face_pixels)\n\tnewTestX.append(embedding)\nnewTestX = asarray(newTestX)\nprint(newTestX.shape)","fbbe3b2b":"numpy.savez_compressed('5-celebrity-faces-embeddings.npz', newTrainX, trainy, newTestX, testy)","c5c1fe5c":"# calculate a face embedding for each face in the dataset using facenet\nfrom numpy import load\nfrom numpy import expand_dims\nfrom numpy import asarray\nfrom numpy import savez_compressed\nfrom keras.models import load_model\n\n# get the face embedding for one face\ndef get_embedding(model, face_pixels):\n\t# scale pixel values\n\tface_pixels = face_pixels.astype('float32')\n\t# standardize pixel values across channels (global)\n\tmean, std = face_pixels.mean(), face_pixels.std()\n\tface_pixels = (face_pixels - mean) \/ std\n\t# transform face into one sample\n\tsamples = expand_dims(face_pixels, axis=0)\n\t# make prediction to get embedding\n\tyhat = model.predict(samples)\n\treturn yhat[0]\n\n# load the face dataset\ndata = load('5-celebrity-faces-dataset.npz')\ntrainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\nprint('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n# load the facenet model\nmodel = load_model('\/kaggle\/input\/facenet-keras\/facenet_keras.h5')\nprint('Loaded Model')\n# convert each face in the train set to an embedding\nnewTrainX = list()\nfor face_pixels in trainX:\n\tembedding = get_embedding(model, face_pixels)\n\tnewTrainX.append(embedding)\nnewTrainX = asarray(newTrainX)\nprint(newTrainX.shape)\n# convert each face in the test set to an embedding\nnewTestX = list()\nfor face_pixels in testX:\n\tembedding = get_embedding(model, face_pixels)\n\tnewTestX.append(embedding)\nnewTestX = asarray(newTestX)\nprint(newTestX.shape)\n# save arrays to one file in compressed format\nsavez_compressed('5-celebrity-faces-embeddings.npz', newTrainX, trainy, newTestX, testy)","ae32954f":"from numpy import load\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.svm import SVC\n# load dataset\ndata = load('5-celebrity-faces-embeddings.npz')\ntrainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\nprint('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))","4ed2d9d5":"# normalize input vectors\nin_encoder = Normalizer(norm='l2')\ntrainX = in_encoder.transform(trainX)\ntestX = in_encoder.transform(testX)","3928a653":"# label encode targets\nout_encoder = LabelEncoder()\nout_encoder.fit(trainy)\ntrainy = out_encoder.transform(trainy)\ntesty = out_encoder.transform(testy)\nprint(trainy,testy)","ed73f7fc":"# fit model\nmodel = SVC(kernel='linear')\nmodel.fit(trainX, trainy)","1db2f50d":"# predict\nyhat_train = model.predict(trainX)\nyhat_test = model.predict(testX)\n# score\nscore_train = accuracy_score(trainy, yhat_train)\nscore_test = accuracy_score(testy, yhat_test)\n# summarize\nprint('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))","1a6d54fc":"# develop a classifier for the 5 Celebrity Faces Dataset\nfrom numpy import load\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.svm import SVC\n# load dataset\ndata = load('5-celebrity-faces-embeddings.npz')\ntrainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\nprint('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n# normalize input vectors\nin_encoder = Normalizer(norm='l2')\ntrainX = in_encoder.transform(trainX)\ntestX = in_encoder.transform(testX)\n# label encode targets\nout_encoder = LabelEncoder()\nout_encoder.fit(trainy)\ntrainy = out_encoder.transform(trainy)\ntesty = out_encoder.transform(testy)\n# fit model\nmodel = SVC(kernel='linear', probability=True)\nmodel.fit(trainX, trainy)\n# predict\nyhat_train = model.predict(trainX)\nyhat_test = model.predict(testX)\n# score\nscore_train = accuracy_score(trainy, yhat_train)\nscore_test = accuracy_score(testy, yhat_test)\n# summarize\nprint('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))","e3f3054f":"# load faces\ndata = load('5-celebrity-faces-dataset.npz')\ntestX_faces = data['arr_2']","7381b319":"from random import choice\n# test model on a random example from the test dataset\nselection = choice([i for i in range(testX.shape[0])])\nrandom_face_pixels = testX_faces[selection]\nrandom_face_emb = testX[selection]\nrandom_face_class = testy[selection]\nrandom_face_name = out_encoder.inverse_transform([random_face_class])\nprint(random_face_name)","74771561":"# prediction for the face\nsamples = expand_dims(random_face_emb, axis=0)\nyhat_class = model.predict(samples)\nyhat_prob = model.predict_proba(samples)","4876646a":"# get name\nclass_index = yhat_class[0]\nclass_probability = yhat_prob[0,class_index] * 100\npredict_names = out_encoder.inverse_transform(yhat_class)","2f3aa0bb":"print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\nprint('Expected: %s' % random_face_name[0])","3decd49c":"# plot for fun\npyplot.imshow(random_face_pixels)\ntitle = '%s (%.3f)' % (predict_names[0], class_probability)\npyplot.title(title)\npyplot.show()","c231860c":"# develop a classifier for the 5 Celebrity Faces Dataset\nfrom random import choice\nfrom numpy import load\nfrom numpy import expand_dims\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.svm import SVC\nfrom matplotlib import pyplot\n# load faces\ndata = load('5-celebrity-faces-dataset.npz')\ntestX_faces = data['arr_2']\n# load face embeddings\ndata = load('5-celebrity-faces-embeddings.npz')\ntrainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n# normalize input vectors\nin_encoder = Normalizer(norm='l2')\ntrainX = in_encoder.transform(trainX)\ntestX = in_encoder.transform(testX)\n# label encode targets\nout_encoder = LabelEncoder()\nout_encoder.fit(trainy)\ntrainy = out_encoder.transform(trainy)\ntesty = out_encoder.transform(testy)\n# fit model\nmodel = SVC(kernel='linear', probability=True)\nmodel.fit(trainX, trainy)\n# test model on a random example from the test dataset\nselection = choice([i for i in range(testX.shape[0])])\nrandom_face_pixels = testX_faces[selection]\nrandom_face_emb = testX[selection]\nrandom_face_class = testy[selection]\nrandom_face_name = out_encoder.inverse_transform([random_face_class])\n# prediction for the face\nsamples = expand_dims(random_face_emb, axis=0)\nyhat_class = model.predict(samples)\nyhat_prob = model.predict_proba(samples)\n# get name\nclass_index = yhat_class[0]\nclass_probability = yhat_prob[0,class_index] * 100\npredict_names = out_encoder.inverse_transform(yhat_class)\nprint('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\nprint('Expected: %s' % random_face_name[0])\n# plot for fun\npyplot.imshow(random_face_pixels)\ntitle = '%s (%.3f)' % (predict_names[0], class_probability)\npyplot.title(title)\npyplot.show()","79445790":"Resoures Collected From\nhttps:\/\/machinelearningmastery.com\/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier\/\n\nAnother prominent project is called FaceNet by David Sandberg that provides FaceNet models built and trained using TensorFlow. The project looks mature, although at the time of writing does not provide a library-based installation nor clean API. Usefully, David\u2019s project provides a number of high-performing pre-trained FaceNet models and there are a number of projects that port or convert these models for use in Keras. https:\/\/github.com\/davidsandberg\/facenet\n\nA notable example is Keras FaceNet by Hiroki Taniai. His project provides a script for converting the Inception ResNet v1 model from TensorFlow to Keras. He also provides a pre-trained Keras model ready for use. https:\/\/github.com\/nyoki-mtl\/keras-facenet","cdfa7650":"# Plotting the Original Face Prediction For Example","4160eae5":"# The Complete code Can be seen here","ce021c73":"# Getting Embedding together","5f0bab0e":"# Facenet definition\nFaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity.\n\nOur method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches.\n\n","941ac7ff":"# Pullting it all together for classification","3932eef4":"# For Fun Getting it all Together","7b81fa83":"# Performing Face Classification"}}