{"cell_type":{"61a983a6":"code","94dbfadd":"code","ba247119":"code","6713ca20":"code","e0627156":"code","f117f8cb":"code","fa051e0f":"code","a79a9de0":"code","e0699e33":"code","4de946c2":"code","117a552a":"code","7c0803df":"code","82567586":"code","5e305c0d":"code","a8cc888f":"code","1967ba81":"code","8df7e573":"code","bba752cb":"code","d4b60706":"code","dace0ff7":"code","27dbe4de":"code","35b0149f":"code","3f3272cc":"code","9f2b1a13":"code","f50ea443":"code","3a5ea276":"code","b316d902":"code","fe81920c":"code","cd432cee":"code","67d637e2":"code","18aa9f37":"code","18519b19":"code","e02de59b":"code","5754ee0c":"code","fd6ad87e":"code","54dd486f":"code","0f512115":"code","93c191b9":"code","ef03de89":"code","2cba2a21":"code","c624dae4":"code","e38ff014":"code","3b6867cb":"code","3e1b47fd":"code","ad352c27":"code","4bd471a9":"code","e9e420da":"code","d29a3151":"code","b394c6b8":"code","e2f470a5":"code","9a4f6bdc":"markdown","94978417":"markdown","f1f8360b":"markdown","7b68575b":"markdown","22483e18":"markdown","73d5f4bd":"markdown","dea5c090":"markdown"},"source":{"61a983a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94dbfadd":"train = pd.read_csv('\/kaggle\/input\/janatahack-demand-forecasting-analytics-vidhya\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/janatahack-demand-forecasting-analytics-vidhya\/test.csv')","ba247119":"print(train.shape)\ntrain.head()","6713ca20":"train.info()","e0627156":"train.describe()","f117f8cb":"train.isnull().sum()","fa051e0f":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.distplot(train[\"units_sold\"])","a79a9de0":"print(\"skewness = \", train['units_sold'].skew())","e0699e33":"cor = train.corr()\nplt.figure(figsize= (15,12))\nsns.heatmap(cor, annot = True,)","4de946c2":"cont_feature = ['total_price','base_price']\ncat_feature = ['is_featured_sku','is_display_sku']\nfig,ax = plt.subplots(1,2,figsize = (18,5))\ni = 221\nfor f in cont_feature:\n    plt.subplot(i)\n    sns.distplot(train[f])\n    i += 1\n# #     plt.subplot(i)\n# #     train[f].plot.bar()\n#     i += 1\n\n#train['total_price'].plot.bar()\n    ","117a552a":"fig,ax = plt.subplots(1,2,figsize=(18,5))\ni = 121\nfor f in cat_feature:\n    plt.subplot(i)\n    train[f].value_counts().plot.bar(title = f)\n    #plt.hist(train[f])\n    i += 1","7c0803df":"fig,ax = plt.subplots(1,2,figsize=(18,5))\ni = 121\nfor f in cat_feature:\n    plt.subplot(i)\n    train.groupby(f)['units_sold'].mean().plot.bar()\n    i += 1","82567586":"\nfig,ax = plt.subplots(1,2,figsize=(18,5))\ni = 121\nfor f in cont_feature:\n    plt.subplot(i)\n    plt.scatter(train[f],train['units_sold'],label = f)\n    plt.xlabel(f)\n    plt.ylabel(\"units_sold\")\n    i += 1","5e305c0d":"#will see what is that highest outliered row\n\ntrain[train[\"units_sold\"] == train[\"units_sold\"].max()]\n#May be because of discount","a8cc888f":"train['week']= pd.to_datetime(train['week'])\ntrain.groupby('week').sum()['units_sold'].plot(figsize = (20,8))\nplt.xlabel(\"Week\")\nplt.ylabel(\"Units Sold\")","1967ba81":"train['year'] = pd.DatetimeIndex(train['week']).year\ntrain.groupby('year').sum()['units_sold'].plot(figsize = (20,8))\ntest['year'] = pd.DatetimeIndex(test['week']).year","8df7e573":"train['month'] = pd.DatetimeIndex(train['week']).month\ntest['month'] = pd.DatetimeIndex(test['week']).month\ntrain.groupby('month').sum()['units_sold'].plot(figsize = (20,8))","bba752cb":"train.groupby(['year','month']).sum()['units_sold'].plot(figsize = (20,8))","d4b60706":"train['discount'] = train['base_price'] - train['total_price']\ntest['discount'] = test['base_price'] - test['total_price']\nplt.scatter(train['discount'],train['units_sold'],label = 'discount')","dace0ff7":"train[train['total_price'].isnull() == True]","27dbe4de":"train[\"total_price\"].fillna(train[train['sku_id']== 245338]['total_price'].mean(),inplace = True)","35b0149f":"train.isnull().sum()","3f3272cc":"test.isnull().sum()","9f2b1a13":"train['units_sold_log'] = np.log(train['units_sold'])\ntrain['units_sold_log'].hist(bins=20) \n#test['units_sold_log'] = np.log(test['units_sold'])","f50ea443":"train['total_price_log'] = np.log(train['total_price'])\ntrain['total_price_log'].hist(bins=20) \ntest['total_price_log'] = np.log(test['total_price'])","3a5ea276":"train['base_price_log'] = np.log(train['base_price'])\ntrain['base_price_log'].hist(bins=20) \ntest['base_price_log'] = np.log(test['base_price'])","b316d902":"test.head()","fe81920c":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()","cd432cee":"from datetime import datetime    # To access datetime \nfrom pandas import Series\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd","67d637e2":"train = pd.read_csv('\/kaggle\/input\/janatahack-demand-forecasting-analytics-vidhya\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/janatahack-demand-forecasting-analytics-vidhya\/test.csv')\ntrain_original=train.copy() \ntest_original=test.copy()","18aa9f37":"train['week']= pd.to_datetime(train['week'])\ntest['week']= pd.to_datetime(test['week'])\ntrain_original['week']= pd.to_datetime(train_original['week'])\ntest_original['week']= pd.to_datetime(test_original['week'])","18519b19":"for i in (train, test, test_original, train_original):\n    i['year']=i['week'].dt.year \n    i['month']=i['week'].dt.month\n    i['week_number']=i['week'].dt.week\n    ","e02de59b":"train.index = train['week'] # indexing the Datetime to get the time period on the x-axis. \ndf=train.drop('record_ID',1)           # drop ID variable to get only the Datetime on x-axis. \nts = df['units_sold'] \nplt.figure(figsize=(16,8)) \nplt.plot(ts, label='Units Sold') \nplt.title('Time Series') \nplt.xlabel(\"Time(year-month)\") \nplt.ylabel(\"Units Sold\") \nplt.legend(loc='best')","5754ee0c":"train.groupby('year')['units_sold'].mean().plot.bar()","fd6ad87e":"train.groupby('month')['units_sold'].mean().plot.bar()","54dd486f":"temp=train.groupby(['year', 'month'])['units_sold'].mean() \ntemp.plot(figsize=(15,5), title= 'Units Sold (Monthwise)', fontsize=14)\n","0f512115":"train.Timestamp = pd.to_datetime(train[\"week\"]) \ntrain.index = train.Timestamp \n\nweekly = train.resample('W').mean() \n# # Converting to monthly mean \nmonthly = train.resample('M').mean()","93c191b9":"weekly[\"units_sold\"].plot(figsize=(15,8), title= 'Weekly', fontsize=14, ) \nmonthly[\"units_sold\"].plot(figsize=(15,8), title= 'Monthly', fontsize=14) ","ef03de89":"train[\"week\"].sort_values(ascending = False)","2cba2a21":"Train=train.loc['2011-01-08':'2013-09-03'] \nvalid=train.loc['2013-09-04':'2013-12-03']","c624dae4":"type(Train[\"units_sold\"])","e38ff014":"Train['units_sold'].plot(figsize=(15,8), title= 'units sold', fontsize=14, label='train') \nvalid['units_sold'].plot(figsize=(15,8), title= 'units sold', fontsize=14, label='valid') \nplt.xlabel(\"Datetime\") \nplt.ylabel(\"units sold\") \nplt.legend(loc='best') \nplt.show()","3b6867cb":"y_hat_avg = valid.copy() \ny_hat_avg['moving_avg_forecast'] = Train['units_sold'].rolling(10).mean().iloc[-1] # average of last 10 observations. \nplt.figure(figsize=(15,5)) \nplt.plot(Train['units_sold'], label='Train') \nplt.plot(valid['units_sold'], label='Valid') \nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 10 observations') \nplt.legend(loc='best') \nplt.show() \ny_hat_avg = valid.copy() \ny_hat_avg['moving_avg_forecast'] = Train['units_sold'].rolling(20).mean().iloc[-1] # average of last 20 observations. \nplt.figure(figsize=(15,5)) \nplt.plot(Train['units_sold'], label='Train') \nplt.plot(valid['units_sold'], label='Valid') \nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 20 observations') \nplt.legend(loc='best') \nplt.show() \ny_hat_avg = valid.copy() \ny_hat_avg['moving_avg_forecast'] = Train['units_sold'].rolling(50).mean().iloc[-1] # average of last 50 observations. \nplt.figure(figsize=(15,5)) \nplt.plot(Train['units_sold'], label='Train') \nplt.plot(valid['units_sold'], label='Valid') \nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 50 observations') \nplt.legend(loc='best') \nplt.show()\n","3e1b47fd":"from sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import mean_squared_log_error as msle\nfrom math import sqrt\n\nrms = sqrt(mean_squared_error(valid.units_sold, y_hat_avg.moving_avg_forecast)) \nprint(\"rms: \",rms)\nrmsle = sqrt(msle(valid.units_sold, y_hat_avg.moving_avg_forecast)) \nprint(\"rmsle: \",rmsle)","ad352c27":"import numpy as np\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt \ny_hat_avg = valid.copy() \nfit2 = SimpleExpSmoothing(np.asarray(Train['units_sold'])).fit(smoothing_level=0.6,optimized=False) \ny_hat_avg['SES'] = fit2.forecast(len(valid)) \nplt.figure(figsize=(16,8)) \nplt.plot(Train['units_sold'], label='Train') \nplt.plot(valid['units_sold'], label='Valid') \nplt.plot(y_hat_avg['SES'], label='SES') \nplt.legend(loc='best') \nplt.show()","4bd471a9":"rms = sqrt(mean_squared_error(valid.units_sold, y_hat_avg.SES)) \nprint(rms)\nrmsle = sqrt(msle(valid.units_sold, y_hat_avg.SES)) \nprint(rmsle)","e9e420da":"Train.index","d29a3151":"import statsmodels.api as sm \nplt.figure(figsize=(16,8)) \nsm.tsa.seasonal_decompose(Train[\"units_sold\"],period = 3).plot() \nresult = sm.tsa.stattools.adfuller(train.units_sold) \nplt.show()","b394c6b8":"y_hat_avg = valid.copy() \nfit1 = Holt(np.asarray(Train['units_sold'])).fit(smoothing_level = 0.3,smoothing_slope = 0.1) \ny_hat_avg['Holt_linear'] = fit1.forecast(len(valid)) \nplt.figure(figsize=(16,8)) \nplt.plot(Train['units_sold'], label='Train') \nplt.plot(valid['units_sold'], label='Valid') \nplt.plot(y_hat_avg['Holt_linear'], label='Holt_linear') \nplt.legend(loc='best') \nplt.show()","e2f470a5":"rms = sqrt(mean_squared_error(valid.units_sold, y_hat_avg.Holt_linear)) \nprint(rms)","9a4f6bdc":"***Moving Average***","94978417":"***# Holt\u2019s Linear Trend Model***","f1f8360b":"# **Feature engineering****","7b68575b":"Time Series","22483e18":"# ***OUTLIERS Treatment***","73d5f4bd":"# ***NULL values*****","dea5c090":"# * **Bivariant analysis*"}}