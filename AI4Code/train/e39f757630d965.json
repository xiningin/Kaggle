{"cell_type":{"d50d1be4":"code","696173fa":"code","087bf02e":"code","ed250954":"code","e30563b5":"code","44b2c780":"code","12fae077":"code","7f1ba8d3":"code","e32398d0":"code","a099aceb":"code","97b1b588":"code","fd93a1ca":"code","73a2480a":"code","3ffc9521":"code","bae24df4":"code","2c9496ed":"markdown","6a3debe7":"markdown","b11b2dce":"markdown","e3f5b7d5":"markdown","36b35b31":"markdown","4d9cb92c":"markdown","6e6ac310":"markdown","58abc354":"markdown","72f5580f":"markdown","97176c45":"markdown","70e197e8":"markdown","f24b000b":"markdown","c84502e6":"markdown","ed164085":"markdown","5556df68":"markdown","52b74347":"markdown","19b0868e":"markdown"},"source":{"d50d1be4":"# importing utility libraries\n\nimport requests\nimport bs4\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport time\nimport re","696173fa":"URL = \"https:\/\/internshala.com\/internships\/data%20science-internship\"\n#conducting a request of the stated URL above:\npage = requests.get(URL)\n#specifying a desired format of \u201cpage\u201d using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\nsoup = BeautifulSoup(page.text, \"html.parser\")\n#printing soup in a more structured tree format that makes for easier reading\nprint(soup.prettify())","087bf02e":"def extract_job_title_from_result(job_div, job_post):    \n    for a in job_div.find(name=\"div\", attrs={\"class\":\"company\"}).find(name=\"div\", attrs={\"class\":\"profile\"}).find(name=\"a\"):\n        job_post.append(a)","ed250954":"def extract_company_from_result(job_div, job_post): \n    for a in job_div.find(name=\"div\", attrs={\"class\":\"individual_internship_header\"}).find(name=\"div\", attrs={\"class\":\"company\"}).find(name=\"div\", attrs={\"class\":\"company_name\"}).find(name=\"a\"):\n        job_post.append(str(a).strip())","e30563b5":"def extract_location_from_result(job_div, job_post): \n    for a in job_div.find(name=\"div\", attrs={\"class\":\"individual_internship_details\"}).find(name=\"div\", attrs={\"id\":\"location_names\"}).find(name=\"a\", attrs={\"class\":\"location_link\"}):\n        job_post.append(str(a).strip())","44b2c780":"def extract_salary_from_result(job_div, job_post): \n    for stipend in job_div.find(name=\"div\", attrs={\"class\":\"individual_internship_details\"}).find(name=\"div\", attrs={\"class\":\"internship_other_details_container\"}).find(name=\"span\", attrs={\"class\":\"stipend\"}):        \n        if isinstance(stipend, bs4.element.NavigableString):\n            job_post.append(str(stipend).strip())","12fae077":"def extract_duration_from_result(job_div, job_post): \n    for stipend in job_div.find(name=\"div\", attrs={\"class\":\"individual_internship_details\"}).find(name=\"div\", attrs={\"class\":\"internship_other_details_container\"}).find(name=\"span\", attrs={\"class\":\"stipend\"}):        \n        if isinstance(stipend, bs4.element.NavigableString):\n            job_post.append(str(stipend).strip())","7f1ba8d3":"def Get_URL_Of_page(base_url, skill):\n    return base_url + \"\/internships\/\" + skill + \"-internship\"    ","e32398d0":"def Get_total_pages(url):\n    # get total number of pages\n    page = requests.get(url)\n    soup = BeautifulSoup(page.text, \"html.parser\", from_encoding=\"utf-8\")\n    total_pages = soup.find(name=\"span\", attrs={\"id\":\"total_pages\"})\n    return int(total_pages.text.strip())","a099aceb":"def Get_Internship_Description_Page_Url(job_div, base_url):\n    for a in job_div.find(name=\"div\", attrs={\"class\":\"button_container\"}).find_all(name=\"a\", attrs={\"class\":\"view_detail_button\"}, href=True):\n        return base_url + a['href']","97b1b588":"def extract_description_from_result(job_div, job_post):\n    page = requests.get(Get_Internship_Description_Page_Url(job_div, base_url))\n    soup_desc = BeautifulSoup(page.text, \"html.parser\", from_encoding=\"utf-8\")\n    \n    for div in soup_desc.find_all(name=\"div\", attrs={\"class\":\"section_heading heading_5_5\"}):\n        if any(word in div.text.strip() for word in [\"job\/internship\", \"internship\", \"work from home\", \"part time\", \"job\"]):\n            job_post.append(div.next_sibling.next_sibling.text.strip())","fd93a1ca":"#scraping code:\ncolumns = [\"job_title\", \"company_name\", \"location\", \"salary\", \"description\"]\nsample_df = pd.DataFrame(columns = columns)\nbase_url = \"https:\/\/internshala.com\"\nskill = \"data science\"\n\n\ndef Scrap_Internshala(base_url, skill):\n    url = Get_URL_Of_page(base_url, skill)\n    total_pages = Get_total_pages(url)\n    for page_number in range(total_pages):\n        page = requests.get(url + \"\/page-\" + str(page_number + 1))\n        time.sleep(1)  #ensuring at least 1 second between page grabs\n        soup = BeautifulSoup(page.text, \"html.parser\")\n\n        for div in soup.find_all(name=\"div\", attrs={\"class\":\"individual_internship\"}): \n            #specifying row num for index of job posting in dataframe\n            num = (len(sample_df) + 1)\n            #creating an empty list to hold the data for each posting\n            job_post = []\n            #grabbing job title\n            extract_job_title_from_result(div, job_post)\n            #grabbing company name\n            extract_company_from_result(div, job_post)\n            #grabbing location name\n            extract_location_from_result(div, job_post)\n            #grabbing salary\n            extract_salary_from_result(div, job_post)\n            #grabbing internship description\n            extract_description_from_result(div, job_post)\n            #appending list of job post info to dataframe at index num\n            sample_df.loc[num] = job_post\n            \n    return sample_df\n","73a2480a":"df_internships = Scrap_Internshala(base_url, skill)","3ffc9521":"df_internships.head()","bae24df4":"#saving df_internships as a local csv file \u2014 define your own local path to save contents \ndf_internships.to_csv(\"job_scrapping_internshala.csv\", encoding=\"utf-8\")","2c9496ed":"### Location","6a3debe7":"#  **Web Scrapping**","b11b2dce":"> Lets try scrapping internships from the website Internshala !","e3f5b7d5":"### Salaries","36b35b31":"### get HTML from the web page","4d9cb92c":"### Description","6e6ac310":"### Scrap data","58abc354":"### Company name","72f5580f":"> Web Scraping (also termed Screen Scraping, Web Data Extraction, Web Harvesting etc.) is a technique employed to extract large amounts of data from websites whereby the data is extracted and saved to a local file in your computer or to a database in table (spreadsheet) format.","97176c45":"### Extract Job title","70e197e8":"### Internship Description page URL","f24b000b":"### Duration","c84502e6":"### Total pages","ed164085":"### URL of Internships page","5556df68":"![web%20scrapping.png](attachment:web%20scrapping.png)","52b74347":"### Import utility libraries","19b0868e":"> Data displayed by most websites can only be viewed using a web browser. They do not offer the functionality to save a copy of this data for personal use. The only option then is to manually copy and paste the data - a very tedious job which can take many hours or sometimes days to complete. Web Scraping is the technique of automating this process, so that instead of manually copying the data from websites, the Web Scraping software will perform the same task within a fraction of the time."}}