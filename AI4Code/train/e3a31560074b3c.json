{"cell_type":{"8aa6d4a2":"code","af67cf74":"code","2a054a2d":"code","03d059ee":"code","d40a90d6":"code","59b6ed9b":"code","e3788379":"code","2a656fed":"code","75232ad4":"code","881d8a37":"code","9770eb51":"code","eac428d2":"code","a34bb83b":"code","b1b485da":"code","37db53ee":"code","afa617aa":"code","6ac7022e":"code","ced4d495":"code","0f2de41c":"code","11c55c92":"code","74c8ac11":"code","5b40aede":"code","532dfb45":"code","844335be":"code","f3bb2d10":"code","82246241":"code","3b2dc032":"code","bf76e545":"code","9f36cb5e":"code","0eafcafc":"code","bd54b1dd":"code","fbe5c49a":"code","5b81952e":"code","1973653f":"code","57641736":"code","79542cdb":"code","a638c438":"code","42c82354":"code","afec3080":"code","491e1dda":"code","5acbee2f":"code","281ad638":"code","77cb051f":"code","43de09d3":"code","b5f14bd4":"code","705ccdb4":"code","e4b27c57":"code","972b23ef":"code","e25dfc67":"code","51604649":"code","25a2e4ad":"code","b15d36d2":"code","4090f9e6":"code","4454400d":"code","f28b91ad":"code","8a4041d0":"code","a64435ab":"code","77c60d4c":"markdown","94565688":"markdown","020f3e58":"markdown","15a04db0":"markdown","66e9691d":"markdown","d3da15ec":"markdown","8f7fe055":"markdown","c18e5186":"markdown","2651ab42":"markdown","3d75d254":"markdown","c335931d":"markdown","0f241b95":"markdown","5365efde":"markdown","c637fab1":"markdown","f79ca562":"markdown","d3a2cb15":"markdown","45bf25e4":"markdown","525ede4f":"markdown","6943beea":"markdown","3652c746":"markdown","c8bf82d2":"markdown","a2858b2a":"markdown","eb5e0249":"markdown","995548d1":"markdown","b0e33a6a":"markdown","a9ce1952":"markdown","71bde6e8":"markdown","c00755c6":"markdown","130c5e2a":"markdown","b46681fc":"markdown","2f5ca5b2":"markdown","77906c7e":"markdown","70d94804":"markdown","a9f98ece":"markdown","992f8e18":"markdown","20f053a3":"markdown","1138bb9b":"markdown","da372b06":"markdown","cb026557":"markdown","b7570bee":"markdown","60d0e394":"markdown","19824a7b":"markdown","64680f4f":"markdown","4e362bf1":"markdown","bc4b4e6b":"markdown","53fad5a5":"markdown","d2b6896c":"markdown","82ea107c":"markdown","5151b450":"markdown","cfadd95e":"markdown","dd59c487":"markdown","01d37dd4":"markdown","71fbb762":"markdown","3401f080":"markdown","cb621489":"markdown","e27fc91e":"markdown","1f29d1d4":"markdown","5c1c71e7":"markdown","c7f992f6":"markdown","1afac60d":"markdown","635f3bd6":"markdown","f5ef629d":"markdown"},"source":{"8aa6d4a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport re\nimport string\nimport collections\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nfrom nltk import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import MiniBatchKMeans\n\nfrom time import time\n%matplotlib inline\nimport os\nimport pandas as pd\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\nimport spacy\nimport spacy.cli\nfrom spacy.matcher import Matcher \nfrom spacy.matcher import PhraseMatcher\n\nspacy.cli.download(\"en\")\nspacy.cli.download(\"en_core_web_lg\")\nnlp = spacy.load('en_core_web_lg')","af67cf74":"## set english loanguage\nstop_words = set(stopwords.words('english'))\n\n## declaration of Porter stemmer.\nporter=PorterStemmer()\n\n## Clean Null Record in dataframe\ndef cleanEmptyData(columnName,df):\n    return df[df[columnName].notnull()]\n\n## Remove Punctuation\ndef remove_punctuation(columnName,df):\n    return df.loc[:,columnName].apply(lambda x: re.sub('[^a-zA-z\\s]','',x))\n\n## Convert To Lower Case\ndef lower_case(input_str):\n    input_str = input_str.lower()\n    return input_str  \n\n## Remove duplicate item in the dataframe\ndef removeDuplicate(df,list):\n    df.drop_duplicates(list, inplace=True)    \n\n## Remove nlp stop words    \ndef remove_stop_words(columnName,df):\n  return df.loc[:,columnName].apply(lambda x: [word for word in x.split() if word not in stop_words])\n\n##Remove single character from the sentence\ndef remove_one_character_word(columnName,df):\n  return df.loc[:,columnName].apply(lambda x: [i for i in x if len(i) > 1])\n\n## Join as a single text with seperator\ndef join_seperator(columnName,df):\n  seperator = ', '\n  return df.loc[:,columnName].apply(lambda x: seperator.join(x))\n\n## apply stemmer to data frame fields\ndef apply_stemmer(columnName,df):\n  return df.loc[:,columnName].apply(lambda x: [porter.stem(word) for word in x])\n\n## Data Cleaning Process function\ndef dataCleaningProcess(dataFrame):\n    ## remove duplicate records\n    removeDuplicate(dataFrame,['abstract', 'text_body'])\n    \n    ## clean null value records\n    clean_data = cleanEmptyData('text_body',dataFrame)\n    clean_data.loc[:,'text_body_clean'] = clean_data.loc[:,'text_body'].apply(lambda x: lower_case(x))\n    \n    ## removing punctuation \n    clean_data.loc[:,'text_body_clean'] = remove_punctuation('text_body_clean',clean_data)\n    \n    ## apply stop words\n    clean_data.loc[:,'text_body_clean'] = remove_stop_words('text_body_clean',clean_data)\n    \n    ## apply stemmer for each tokens\n    clean_data.loc[:,'text_body_clean'] = apply_stemmer('text_body_clean',clean_data)\n    \n    ## removing single charter word in the sentence\n    clean_data.loc[:,'text_body_clean'] = remove_one_character_word('text_body_clean',clean_data)\n    \n    ## join as a single text from words token\n    clean_data.loc[:,'text_body_clean'] = join_seperator('text_body_clean',clean_data)\n    \n    ## remove coma after join\n    clean_data.loc[:,'text_body_clean'] = remove_punctuation('text_body_clean',clean_data)\n    \n    return clean_data","2a054a2d":"## get words token from text\ndef getWordsFromText(_text):\n    words = []\n    for i in range(0,len(_text)):\n        words.append(str(_text.iloc[i]['text_body']).split(\" \"))\n    return words\n\n# Read Excel data as Data Frame\ndef readExcelToDataFrame(path):\n    research_dataframe = pd.read_csv(path,index_col=False)\n    research_dataframe.drop(research_dataframe.columns[research_dataframe.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n    return research_dataframe\n\n## basic scatter plot\ndef showScatterPlot(_X,title):\n    # sns settings\n    sns.set(rc={'figure.figsize':(15,15)})\n    # colors\n    palette = sns.color_palette(\"bright\", 1)\n    # plot\n    sns.scatterplot(_X[:,0], _X[:,1], palette=palette)\n    plt.title(title)\n    # plt.savefig(\"plots\/t-sne_covid19.png\")\n    plt.show()\n\n## scatter plot with cluster\ndef showClusterScatterPlot(_X, _y_pred, title):\n    # sns settings\n    sns.set(rc={'figure.figsize':(10,10)})\n    # colors\n    palette = sns.color_palette(\"bright\", len(set(_y_pred)))\n    # plot\n    sns.scatterplot(_X[:,0], _X[:,1], hue=_y_pred, legend='full', palette=palette)\n    plt.title(title)\n    # plt.savefig(\"plots\/t-sne_covid19_label.png\")\n    plt.show()\n\n\n## drop clumns\ndef getTargetData(dataFrame):\n    text_body = dataFrame.drop([\"doc_id\", \"source\", \"title\", \"abstract\"], axis=1)\n    return getWordsFromText(text_body)\n\n## train model for tSNE clustering visualization\ndef trainEmbededData(_perplexity,dataFrame,total_cluster, _n_iter):\n    ## convert text to word frequency vectors\n    vectorizer = TfidfVectorizer(max_features=2**12)\n    \n    ## training the data and returning term-document matrix.\n    _X = vectorizer.fit_transform(dataFrame['text_body_clean'].values)\n    \n    ## tsne declartion\n    tsne = TSNE(verbose=1, perplexity=_perplexity,learning_rate=200, random_state=0, n_iter=_n_iter)\n    _X_embeded = tsne.fit_transform(_X.toarray())\n    \n    ## clusterring for tsne\n    _kmeans = MiniBatchKMeans(n_clusters=total_cluster)\n    return _X_embeded,_kmeans,_X\n\n## predicting cluster centers and predict cluster index for each sample\ndef predict(_kmeans,_X):\n    return _kmeans.fit_predict(_X)\n\n## reusable fucntion for TSNE K-Mean Clustering with TF-IDF\ndef analyse(pplexity,data_frame,cluster,iter):\n    ## train model for tSNE clustering visualization\n    embeded,kmeans,x = trainEmbededData(pplexity,data_frame,cluster,iter)\n    pred = predict(kmeans,x)\n    ## visualized the scatter plot\n    showClusterScatterPlot(embeded,pred,'t-SNE Covid-19 - Clustered(K-Means) - Tf-idf with Plain Text')\n    return embeded,kmeans,x","03d059ee":"research_dataframe = readExcelToDataFrame('\/kaggle\/input\/coviddata21\/data.csv')\nresearch_dataframe.head()","d40a90d6":"clean_data =dataCleaningProcess(research_dataframe)","59b6ed9b":"clean_data.head()\nclean_process_data = clean_data.drop([\"doc_id\", \"source\", \"title\", \"abstract\"], axis=1)\nclean_process_data.head(20)","e3788379":"meta_data = readExcelToDataFrame('\/kaggle\/input\/metadata\/meta.csv')\nmeta_data.head()\n","2a656fed":"def prepare_search_data(_meta_data_frame,research_dataframe):\n    ## add a field doc_id\n    _meta_data_frame[\"doc_id\"] = _meta_data_frame[\"sha\"]\n    \n    ## clean NUll record\n    _meta_data_frame = cleanEmptyData('doc_id', _meta_data_frame)\n    _meta_data_frame = cleanEmptyData('publish_time', _meta_data_frame)\n    \n    ## select only 2019 & 2020 published records\n    meta_data_filter = _meta_data_frame[_meta_data_frame['publish_time'].str.contains('2019') | _meta_data_frame['publish_time'].str.contains('2020')]  \n    \n     ## clean NUll record\n    research_dataframe_clean = cleanEmptyData('doc_id', research_dataframe)\n    research_dataframe_clean = cleanEmptyData('text_body', research_dataframe_clean)\n    \n    ## merging of Research data and meta data on doc_id\n    tmp_data_frame  = research_dataframe_clean.merge(meta_data_filter, on='doc_id', how='right')\n    \n    ## remove un used fields\n    clean_process_data = tmp_data_frame.drop([\"source\", \"abstract_x\",  \"abstract_x\",\"sha\",\"source_x\",\"title_y\",\"pmcid\",\"pubmed_id\",\"license\",\"abstract_y\",\"journal\",\"Microsoft Academic Paper ID\",\"WHO #Covidence\"], axis=1)\n    \n    ## clean NUll record\n    clean_process_data = cleanEmptyData('text_body', clean_process_data)\n    clean_process_data = clean_process_data.rename(columns={'title_x': 'title'}) \n    \n    # reordering the column index\n    columns = [\"doc_id\",\"doi\", \"publish_time\", \"authors\",\"url\",\"title\", \"text_body\"]\n    clean_process_data = clean_process_data.reindex(columns=columns)\n    \n    return clean_process_data","75232ad4":"def process_title(x):\n  if not str(x['title_x']).lower() =='nan':\n    return str(x['title_x']) + ' (' +  str(x['url']) + ')'\n  else:\n    return str(x['url'])","881d8a37":"filter_data = prepare_search_data(meta_data,research_dataframe)\nfilter_data.head()","9770eb51":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n\n","eac428d2":"def show_WordCloud(filter_data):\n    comment_words = ' '\n    stopwords = set(STOPWORDS) \n  \n# iterate through the csv file \n    for val in filter_data: \n\n        # typecaste each val to string \n        val = str(val) \n\n        # split the value \n        tokens = val.split() \n        #print(val) \n        # Converts each token into lowercase \n        for i in range(len(tokens)): \n            tokens[i] = tokens[i].lower() \n\n        for words in tokens: \n         comment_words = comment_words + words + ' '\n         #print(comment_words)\n\n    wordcloud = WordCloud(width = 800, height = 800, \n                    background_color ='white',\n                    max_words = 200, \n                    stopwords = stopwords, \n                    min_font_size = 10).generate(comment_words) \n\n    # plot the WordCloud image                        \n    plt.figure(figsize = (10, 10), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n\n    plt.show()\n\n","a34bb83b":"show_WordCloud(filter_data.title)","b1b485da":"embeded,kmeans,x = analyse(5000,clean_process_data,10,15000)","37db53ee":"papers = research_dataframe['text_body'].astype('str')\nlen(papers)\npapers.head()\n#meta_data_filter\u00a0=\u00a0_meta_data_frame[_meta_data_frame['publish_time'].str.contains('2019')\u00a0|\u00a0_meta_data_frame['publish_time'].str.contains('2020')]\u00a0\u00a0 ","afa617aa":"%%time\nimport nltk\nimport tqdm\nnltk.download('wordnet')\n\nstop_words = nltk.corpus.stopwords.words('english')\nwtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\nwnl = nltk.stem.wordnet.WordNetLemmatizer()\n\ndef normalize_corpus(papers):\n    norm_papers = []\n    for paper in tqdm.tqdm(papers):\n        paper = paper.lower()\n        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n        paper_tokens = list(filter(None, paper_tokens))\n        #if paper_tokens:\n        norm_papers.append(paper_tokens)\n            \n    return norm_papers\n    \nnorm_papers = normalize_corpus(papers)\nprint(len(norm_papers))","6ac7022e":"import gensim\n\nbigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_') # higher threshold fewer phrases.\nbigram_model = gensim.models.phrases.Phraser(bigram)\n\nprint(bigram_model[norm_papers[0]][:50])","ced4d495":"print(bigram_model[norm_papers[1]][:50])","0f2de41c":"norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n\n# Create a dictionary representation of the documents.\ndictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\nprint('Sample word to number mappings:', list(dictionary.items())[:15])\nprint('Total Vocabulary Size:', len(dictionary))","11c55c92":"# Filter out words that occur less than 20 documents, or more than 60% of the documents.\ndictionary.filter_extremes(no_below=20, no_above=0.6)\nprint('Total Vocabulary Size:', len(dictionary))","74c8ac11":"bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\nprint(bow_corpus[1][:50])","5b40aede":"print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])","532dfb45":"print('Total number of papers:', len(bow_corpus))","844335be":"import joblib\nlda_model = joblib.load('\/kaggle\/input\/coviddata21\/lda_model.jl')","f3bb2d10":"topics_assigned = lda_model[bow_corpus]","82246241":"len(topics_assigned)","3b2dc032":"b= pd.DataFrame(topics_assigned,columns = ['T0','T1','T2','T3','T4','T5','T6','T7','T8','T9'])","bf76e545":"d= pd.concat([research_dataframe['text_body'],b],axis=1)","9f36cb5e":"d.to_csv(\"Topic_paper_07042020_v4.csv\")","0eafcafc":"for topic_id, topic in lda_model.print_topics(num_topics=50, num_words=20):\n    print('Topic #'+str(topic_id+1)+':')\n    print(topic)\n    print()","bd54b1dd":"import numpy as np\ntopics_coherences = lda_model.top_topics(bow_corpus, topn=20)\navg_coherence_score = np.mean([item[1] for item in topics_coherences])\nprint('Avg. Coherence Score:', avg_coherence_score)","fbe5c49a":"topics_with_wts = [item[0] for item in topics_coherences]\nprint('LDA Topics with Weights')\nprint('='*50)\nfor idx, topic in enumerate(topics_with_wts):\n    print('Topic #'+str(idx+1)+':')\n    print([(term, round(wt, 3)) for wt, term in topic])\n    print()","5b81952e":"print('LDA Topics without Weights')\nprint('='*50)\nfor idx, topic in enumerate(topics_with_wts):\n    print('Topic #'+str(idx+1)+':')\n    print([term for wt, term in topic])\n    print()","1973653f":"cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n                                                      texts=norm_corpus_bigrams,\n                                                      dictionary=dictionary, \n                                                      coherence='c_v')\navg_coherence_cv = cv_coherence_model_lda.get_coherence()\n\numass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n                                                         texts=norm_corpus_bigrams,\n                                                         dictionary=dictionary, \n                                                         coherence='u_mass')\navg_coherence_umass = umass_coherence_model_lda.get_coherence()\n\nperplexity = lda_model.log_perplexity(bow_corpus)\n\nprint('Avg. Coherence Score (Cv):', avg_coherence_cv)\nprint('Avg. Coherence Score (UMass):', avg_coherence_umass)\nprint('Model Perplexity:', perplexity)","57641736":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nstopwords = set(STOPWORDS)\n\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=2000,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","79542cdb":"with open(\"\/kaggle\/input\/coviddata21\/Topic_paper_07042020_v4.csv\",encoding = 'utf8', errors='ignore') as f:\n    df_topic = pd.read_csv(f)\n    \n#df = df.replace(\"\\n\",\" \").dropna()","a638c438":"show_WordCloud(df_topic.loc[df_topic['Dominant_topic'] == 0]['text_body'])\n#show_WordCloud(filter_data.title)","42c82354":"show_WordCloud(df_topic.loc[df_topic['Dominant_topic'] == 1]['text_body'])","afec3080":"\nfrom __future__ import print_function\n\n__author__ = 'maxim'\n\nimport numpy as np\nimport gensim\nimport string\nfrom gensim.models import Word2Vec\nfrom keras.callbacks import LambdaCallback\nfrom keras.layers.recurrent import LSTM\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Dense, Activation\nfrom keras.models import Sequential\nfrom keras.utils.data_utils import get_file\nfrom gensim.models import Word2Vec\nimport pandas as pd\nimport numpy as np\nimport re\nimport json\nimport pandas as pd\nfrom gensim.models.fasttext import FastText\nfrom os import listdir\nfrom os.path import isfile, join\n\nfrom tqdm import tqdm\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nimport re\n\nimport gensim\nimport nltk","491e1dda":"print('loading model')\n\nword_model = Word2Vec.load(\"\/kaggle\/input\/coviddata21\/word2vec_1000ITR.model\")\n\nprint('model loaded')","5acbee2f":"\n#Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups\na=['severity','disease','fatality','patients','symptomatic']\nprint(word_model.most_similar(positive=a,topn=30)) \nprint(\"=================================================================\")\nprint(word_model.predict_output_word(a,topn=30)) \n#'populations','susceptibility','covid19'\n#Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups","281ad638":"#Data on potential risks factors\n#--Smoking, pre-existing pulmonary disease\na=['covid19','risk','smoking','existing', 'pulmonary' ,'disease','comorbidity']\n#comorbidities|mellitus|cardiovascular|vulnerability|hypertension|pneumonia|chronic|cvd\nprint(word_model.most_similar(positive=a,topn=30)) \nprint(\"=================================================================\")\nprint(word_model.predict_output_word(a,topn=30)) \n#'populations','susceptibility','covid19'\n#Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups","77cb051f":"#Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities\n\na=['infection','coexisting','virus','transmissible', 'virulent' ,'comorbidity']\n#severe|fatal|coinfection|contagious|susceptible|merscov|sftsv|highly|ibv|pedv|csfv|pathogenicity|eiav|prrsv|prv|h1n1pdm|hepatatis|lethalmhv|\nprint(word_model.most_similar(positive=a,topn=30)) \nprint(\"=================================================================\")\nprint(word_model.predict_output_word(a,topn=30)) ","43de09d3":"# Risk of COVID-19 in Neonates and pregnant women\n\na=['covid19','virus','risk','neonates','pregnant', 'women','postpartum','congenital']\n#stillbirth|miscarriage|congenital|malformations|microcephaly|abortion|obstetric|lbw|covid19\nprint(word_model.most_similar(positive=a,topn=40)) \nprint(\"=================================================================\")\nprint(word_model.predict_output_word(a,topn=40)) ","b5f14bd4":"#Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.\n\n\na=['covid19','virus','risk','economy','impact','behaviour','industry','global','socioeconomic','consequences']\n#lessen productivity|macroeconomic affecting|vulnerability|devastating|reducing|recession|unemployment\nprint(word_model.most_similar(positive=a,topn=40)) \nprint(\"=================================================================\")\nprint(word_model.predict_output_word(a,topn=40)) ","705ccdb4":"print(word_model.most_similar(positive=['treatment','options' ])) ","e4b27c57":"\narr_most_similar = [['severity','disease','fatality','patients','symptomatic'],\n['covid19','risk','smoking','existing', 'pulmonary' ,'disease','comorbidity'],\n['infection','coexisting','virus','transmissible', 'virulent' ,'comorbidity'],\n['covid19','virus','risk','neonates','pregnant', 'women','postpartum','congenital'],\n['covid19','virus','risk','economy','impact','behaviour','industry','global','socioeconomic','consequence']]\narr_predict=[['severity','disease','fatality','patients','symptomatic'],\n['covid19','risk','smoking','existing', 'pulmonary' ,'disease','comorbidity'],\n['infection','coexisting','virus','transmissible', 'virulent' ,'comorbidity'],\n['covid19','virus','risk','neonates','pregnant', 'women','postpartum','congenital'],\n['covid19','virus','risk','economy','impact','behaviour','industry','global','socioeconomic','consequence']]\n\n#EXAMPLE     \n#Public health mitigation measures that could be effective for control\n#Intial input fed to word2vec  model to extract related words that could lead to the answers of this question\n#['public','health','mitigation','measures',  'effective', 'control','covid19','disease']]\n#RESULT from first Query: [('interventions', 0.7447171807289124), ('prevention', 0.7438710927963257), ('preventive', 0.7241473197937012), ('policies', 0.7131460905075073), ('intervention', 0.7103219628334045), ('management', 0.7056314945220947), ('implementing', 0.6939526200294495), ('policy', 0.6897070407867432), ('quarantine', 0.6833001971244812), ('planning', 0.6516326069831848), ('implementation', 0.641217827796936), ('awareness', 0.6297034025192261), ('containment', 0.6278428435325623), ('preparedness', 0.622099757194519), ('epidemic', 0.6220937967300415), ('timely', 0.6204564571380615), ('community', 0.6184203624725342), ('government', 0.6134730577468872), ('outbreak', 0.6104072332382202), ('pandemic', 0.6079082489013672)]]\n#Updated input taken from first querying of word2vec model after choosing relevant keywords\n#['mitigation','measures','control','covid19','quarantine','containment','awareness','policies']]\n#RESULT from second Query: [[('interventions', 0.7805880308151245), ('intervention', 0.7159266471862793), ('policy', 0.690924346446991), ('preventive', 0.6865450143814087), ('implementing', 0.6757345795631409), ('implementation', 0.6531403064727783), ('planning', 0.6507831811904907), ('practices', 0.6400246620178223), ('prevention', 0.6383914947509766), ('management', 0.6378570199012756), ('government', 0.6369956731796265), ('preparedness', 0.6348874568939209), ('restrictions', 0.6139740943908691), ('campaigns', 0.6061151027679443), ('behaviors', 0.5989149808883667), ('plans', 0.5976110696792603), ('decisions', 0.5968020558357239), ('timely', 0.591980516910553), ('governmental', 0.5905696153640747), ('biosecurity', 0.5887465476989746)]]\n\n#Most Similar Keywrods Detection \n\nlen(arr_most_similar)\narrans=[]\nprint(len(arr_most_similar))\ncount=0\nfor i in arr_most_similar:\n    print('--------->',i)\n    answers=word_model.most_similar(positive=i,topn=30)\n    \n    arrans.append(answers)\n    count +=1\n    print('=========',count)\nprint(arrans)\nprint(len(arrans))\n\n\n#Predicted Keywords Detection\n\narr_predict\nlen(arr_predict)\narrans_arr_predict=[]\nprint(len(arr_predict))\ncount=0\nfor j in arr_predict:\n    print('--------->',j)\n    answers1=word_model.predict_output_word(j,topn=30)\n    \n    arrans_arr_predict.append(answers1)\n    count +=1\n    print('=========',count)\nprint(arrans_arr_predict)\nprint(len(arrans_arr_predict))\n\n","972b23ef":"for q in arrans:\n    print(q)","e25dfc67":"#arrans\nfor k in arrans_arr_predict:\n    print(k)","51604649":"## constant for spliting sentence\nalphabets= \"([A-Za-z])\"\nprefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\nsuffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\nstarters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\nacronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\nwebsites = \"[.](com|net|org|io|gov)\"","25a2e4ad":"\n \n## spliting to sentence from text\ndef split_into_sentences(text):\n    text = \" \" + text + \"  \"\n    text = text.replace(\"\\n\",\" \")\n    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n    text = re.sub(websites,\"<prd>\\\\1\",text)\n    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n    if \"\u201d\" in text: text = text.replace(\".\u201d\",\"\u201d.\")\n    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n    text = text.replace(\".\",\".<stop>\")\n    text = text.replace(\"?\",\"?<stop>\")\n    text = text.replace(\"!\",\"!<stop>\")\n    text = text.replace(\"<prd>\",\".\")\n    sentences = text.split(\"<stop>\")\n    sentences = sentences[:-1]\n    sentences = [s.strip() for s in sentences]\n    return sentences\n\n## search inference text by key words and return all the matches sentence\ndef search_inference_keys(text, keywords):\n    sentences = split_into_sentences(text)\n    txt = ''\n    for sent in sentences:\n        r = re.compile(keywords,flags=re.IGNORECASE)\n        if len(r.findall(sent))>0:         \n            txt = str(txt) + str(sent)\n    return txt\n\n\n## check key words exist or not in a sentence\ndef check_exist_multiple_keywords(text, keywords):\n    r = re.compile(keywords, flags=re.IGNORECASE)\n    if len(r.findall(text))>0:    \n        return True\n    else:\n        return False\n\n## Search Inference and download results as excel \ndef searc_by_keys_as_excel(keyword, src_data_frame):\n    data_frame = src_data_frame\n    ## check exist to slice down the related contents\n    data_frame['search_key_status'] =data_frame.loc[:,'text_body'].apply(lambda x: check_exist_multiple_keywords(x,keyword))\n    ## select only target data\n    process_data_frame = data_frame.query('search_key_status == True')\n  \n    ## filter on corona and covid 19 related data\n    process_data_frame['search_covid_content'] =process_data_frame.loc[:,'text_body'].apply(lambda x: check_exist_multiple_keywords(x,'covid-19|sars-cov-2|2019-ncov|ncov-19|coronavirus'))\n  \n    ## get only covid-19|sars-cov-2|2019-ncov|ncov-19|coronavirus data\n    process_data_frame = process_data_frame.query('search_covid_content == True')\n    process_data_frame.loc[:,'inference'] = process_data_frame.loc[:,'text_body'].apply( lambda x: search_inference_keys(x,keyword))\n    \n    ## remove unused fields\n    final_data = process_data_frame.drop([\"search_key_status\",\"text_body\"], axis=1)\n    ## download as excel\n    final_data.to_excel(str(keyword) + '_result.xlsx', sheet_name='keyword')\n  \n    return final_data","b15d36d2":"# Search Inference for \"incubation period\" and download results as excel \nsearch_data = prepare_search_data(meta_data,research_dataframe)","4090f9e6":"final_data =searc_by_keys_as_excel('interventions|policies|quarantine|awareness|preparedness|restrictions|campaigns|behaviors|biosecurity|governmental|search_data',search_data)\n#comorbidities|mellitus|cardiovascular|vulnerability|hypertension|pneumonia|chronic\n#'interventions','policies','quarantine','awareness''preparedness','restrictions','campaigns','behaviors',\n#'biosecurity','governmental'\nfinal_data.head()","4454400d":"final_data =searc_by_keys_as_excel('comorbidities|mellitus|cardiovascular|vulnerability|hypertension|pneumonia|chronic',search_data)\n","f28b91ad":"final_data =searc_by_keys_as_excel('severe|fatal|coinfection|contagious|susceptible|merscov|sftsv|highly|ibv|pedv|csfv|pathogenicity|eiav|prrsv|prv|h1n1pdm|hepatatis|lethalmhv|',search_data)","8a4041d0":"final_data =searc_by_keys_as_excel('stillbirth|miscarriage|congenital|malformations|microcephaly|abortion|obstetric|lbw|covid19',search_data)","a64435ab":"final_data =searc_by_keys_as_excel('lessen | productivity|macroeconomic | affecting|vulnerability|devastating|reducing|recession|unemployment',search_data)","77c60d4c":"Re usable Helper functions","94565688":"Build a Bi-gram Phrase Model","020f3e58":"Read the meta data from meta_data CSV","15a04db0":"**Inference of some topics **\n\n* Topic 1&5: mainly deals with the virus structure and genome \n* Topic 3: deals with the origin and history \n* Topic 4&10: For public health risk information \n* Topic 9: Has lab research on various subjects","66e9691d":"Question 2: * Smoking, pre-existing pulmonary disease\n**--> comorbidities|mellitus|cardiovascular|vulnerability|hypertension|pneumonia|chronic**","d3da15ec":"**Transforming corpus into bag of words vectors**\n\nWe can now perform feature engineering by leveraging a simple Bag of Words model.","8f7fe055":"Import libraries","c18e5186":"Question 3: Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities --> severe|fatal|coinfection|contagious|susceptible|merscov|sftsv|highly|ibv|pedv|csfv|pathogenicity|eiav|prrsv|prv|h1n1pdm|hepatatis|lethal|mhv","2651ab42":"LOAD the Research Dataset","3d75d254":"***Building model**\n\n> %%time\n> \n> > TOTAL_TOPICS = 10\n> \n> lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, \n>                                    alpha='auto', eta='auto', random_state=42,\n>                                    iterations=500, num_topics=TOTAL_TOPICS, \n>                                    passes=20, eval_every=None)*","c335931d":"Question 4: Neonates and pregnant women --> stillbirth|miscarriage|congenital|malformations|microcephaly|abortion|obstetric|lbw|covid19","0f241b95":"**Topic 2**","5365efde":"We tried understanding documents with different clusters with various perplexity and identified the optimal perplexity where the convergence of documents took place. ","c637fab1":"**Topic Models with Latent Dirichlet Allocation (LDA)**","f79ca562":"\n**Question 1: Public health mitigation measures that could be effective for control **\n\n492\tf24d3b4b4af138be06b7452b7acefc8948bc1056\t\ndoi.org\/10.1101\/2020.01.28.923169\t2020-01-28\t\nShao, P.; Shan, Y.\t\tBeware of asymptomatic transmission: \n\nStudy on 2019-nCoV prevention and control measures based on extended SEIR model\tTRUE\t\n\nThe purpose of this study is to reveal the role of the three most important current measures to control the spread of the epidemic, such as quarantine of infected persons, reduction of human mobility, and improvement of treatment.\n\n508\t754315299d847600d6c5d414665c728d40bf731d\t\ndoi.org\/10.1101\/2020.01.27.922443\t2020-01-30\t\nMing, W.-k.; Huang, J.; Zhang, C. J. P.\t\t\n\nBreaking down of healthcare system: Mathematical modelling for controlling the novel coronavirus (2019-nCoV) outbreak in Wuhan, China\tTRUE\t\n\nWith the increasing incidence of confirmed cases, corresponding spread control policies and emergency actions are taking place.[6] Earlier studies on the effectiveness of spread control measures during infectious disease pandemic showed large-scale strategies, such as closure of school closure, case isolation, household quarantine, internal travel restrictions and border control, were able to delay the spread and\/or reduce incidence rate at certain periods through the outbreak season.922443 doi: bioRxiv preprint As of 31 st January, it is estimated that there were 246,172 cases given a 10% diagnosis rate whilst being 88,075 and 52,094 cases given diagnosis rates of 50% and 90%, respectively, if no public health interventions were implemented ( Table 2) .If 70% efficacy rate could be achieved (Scenario 4), the forecasting number of cases would drop dramatically to 11,056 as of 10 th February compared to 115,355 without public health interventions (Scenario 2).922443 doi: bioRxiv preprint Therefore, the burdens on healthcare system would be substantial, particularly for the isolation wards and ICU, if no effective public health interventions were implemented.Second, classic SIR model assumes a constant infection rate, which is not likely to be true as interventions being implemented.Therefore, in this study, we constructed SIR models with multiple efficacy rates of public health interventions as proxy for the change of infection rate.To achieve higher efficacy of the public health interventions, efforts from individuals should not be neglected.All these are extremely important in raising awareness in the public as to personal preventive steps given the present situation (mild or subclinical symptoms observed in many cases and observed long incubation period).We believe that these volunteering activities can contribute to a successful delivery of public health principle and, in turn, efficacious interventions.To conclude, our estimates of the healthcare system burdens arising from the actual number of cases infected by the novel coronavirus appear to be considerable if no effective public health interventions were implemented.922443 doi: bioRxiv preprint -13 -public transport) and further effective large-scale interventions spanning all subgroups of populations (e.g., universal facemask wear) with an aim to obtain overall efficacy with at least 70%-90% to ensure the functioning of and avoid the breakdown of healthcare system.\n\nHighlight:\n\nMost important current measures to control the spread of the epidemic, such as quarantine of infected persons, reduction of human mobility, and improvement of treatment.\n\n===============================================================================================\n**Question 2: Data on potential risks factors: Smoking, pre-existing pulmonary disease**\n\nObservation made from research papers published on 2020: \n\n1572\tf294f0df7468a8ac9e27776cc15fa20297a9f040\t\n\n10.3390\/v12020244\t\n2020\t\nXu, Jiabao; Zhao, Shizhe; Teng, Tieshan; Abdalla, Abualgasim Elgaili; Zhu, Wan; Xie, Longxiang; Wang, Yunlong; Guo, Xiangqian\t\t\n\nSystematic Comparison of Two Animal-to-Human Transmitted Human Coronaviruses: SARS-CoV-2 and SARS-CoV\tTRUE\t\n\nThe source of unexplained pneumonia was first discovered in Wuhan in Dec, 2019, and SARS-CoV-2, a new coronavirus, was isolated from the respiratory epithelium of patients.The following month, there were clusters of atypical pneumonia reported in other parts of mainland China, Hong Kong [21] , Canada [22] , and Singapore [23] .29th, 2019, the health departments of Hubei Province received a report that four employees of the South China Seafood Wholesale Market were diagnosed with unknown-caused pneumonia in a local hospital, which was the first report of SARS-CoV-2 [27] .The following month, there were clusters of atypical pneumonia reported in other parts of mainland China, Hong Kong [21] , Canada [22] , and Singapore [23] .29th, 2019, the health departments of Hubei Province received a report that four employees of the South China Seafood Wholesale Market were diagnosed with unknown-caused pneumonia in a local hospital, which was the first report of SARS-CoV-2 [27] .COVID-19 can be classified into light, normal, severe, and critical types based on the severity of the disease [31] : (1) Mild cases-the clinical symptoms were mild, and no pneumonia was found on the chest computed tomography (CT); (2) normal cases-fever, respiratory symptoms, and patients found to have imaging manifestations of pneumonia; (3) severe cases-one of the following three conditions: Respiratory distress, respiratory rate \u2265 30 times\/min (in resting state, refers to oxygen saturation \u2264 93%), partial arterial oxygen pressure (PaO2)\/oxygen absorption concentration (FiO2) \u2264 300 mmHg (1 mmHg = 0.However, severe cases have been documented in young adults who have unique factors, particularly those with chronic diseases, such as diabetes or hepatitis B. Those with a long-term use of hormones or immunosuppressants, and decreased immune function, are likely to get severely infected.COVID-19 can be classified into light, normal, severe, and critical types based on the severity of the disease [31] : (1) Mild cases-the clinical symptoms were mild, and no pneumonia was found on the chest computed tomography (CT); (2) normal cases-fever, respiratory symptoms, and patients found to have imaging manifestations of pneumonia; (3) severe cases-one of the following three conditions: Respiratory distress, respiratory rate \u2265 30 times \/ min (in resting state, refers to oxygen saturation \u2264 93%), partial arterial oxygen pressure (PaO2)\/oxygen absorption concentration (FiO2) \u2264 300 mmHg (1 mmHg = 0.However, severe cases have been documented in young adults who have unique factors, particularly those with chronic diseases, such as diabetes or hepatitis B. Those with a long-term use of hormones or immunosuppressants, and decreased immune function, are likely to get severely infected.However, severe COVID-19 cases and deaths have mostly been in the middle-aged adults and the elderly with long smoking histories or other basic diseases, such as heart disease and hypertension [43, 44] .Viruses 2020, 12, x FOR PEER REVIEW 5 of 18 basic diseases, such as heart disease and hypertension [43, 44] .The early symptoms of SARS and COVID-19 are very similar to winter influenza, and the most important way to distinguish flu and pneumonia is to take throat swabs for viral testing [68] .\n\n\nHighlights:\n\nHowever, severe COVID-19 cases and deaths have mostly been in the middle-aged adults and the elderly with long smoking histories or other basic diseases, such as heart disease and hypertension \n\n=======================================================================================\n\n**Question 3: Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities**\n\n137\t39a7144b3eb9ddf5b9076163aa61099d8b58f977\thttp:\/\/dx.doi.org\/10.1093\/ofid\/ofz424\t2019 Oct 3\t['Noyola, Daniel E', 'Hunsberger, Sally', 'Vald\u00e9s Salgado, Raydel', 'Powers, John H', 'Galindo-Fraga, Arturo', 'Ortiz-Hern\u00e1ndez, Ana A', 'Ramirez-Venegas, Alejandra', 'Moreno-Espinosa, Sarbelio', 'Llamosas-Gallardo, Beatriz', 'Guerrero, M Lourdes', 'Beigel, John H', 'Ruiz-Palacios, Guillermo', 'Perez-Patrigeon, Santiago', None]\t\tOpen Forum Infectious Diseases Comparison of Rates of Hospitalization Between Single and Dual Virus Detection in a Mexican Cohort of Children and Adults With Influenza-Like Illness\tTRUE\tCurrent estimates indicate that lower respiratory tract infections (LRTIs) are the fifth leading cause of death in the world, accounting for 2.74 million deaths in 2015 [1] .The etiology of acute respiratory infections is diverse, and respiratory viruses are increasingly recognized as important causes of severe respiratory infections.Before the introduction of molecular detection methods, the etiology of a large proportion of acute respiratory infections could not be ascertained.The increasing use of reverse transcription polymerase chain reaction (RT-PCR) and other molecular methods has allowed for detection of respiratory viruses in a large proportion of cases.In addition, during the last 2 decades, previously unrecognized agents, such as human metapneumovirus (HMPV), human bocavirus (HBoV), rhinovirus C, and several coronaviruses, have been identified as new causes of respiratory infection [2] [3] [4] [5] .As such, the use of currently available diagnostic techniques allows detection of at least 1 pathogen in the majority of patients [6] .Additionally, the rates of hospitalization are significantly different based on the virus isolated.Mexican children 5 years of age and younger presenting with influenza-like illness (ILI) caused by human respiratory syncytial virus (RSV) and HMPV have been shown to be at greater risk of hospitalization compared with other viruses [7] .As a result of the increasing use of molecular detection of respiratory viruses and the frequent detection of some of these viruses in asymptomatic individuals, there is a need to clarify their role in the etiology of LRTI [8] .In addition, the availability of diagnostic platforms that allow for the simultaneous detection of many pathogens has resulted in the identification of \u22652 agents in a large number of patients with respiratory infections [9] [10] [11] .Before the use of molecular methods, detection of viral co-infections was relatively rare [12] .In contrast, most recent studies report detection of >1 virus in approximately one-fourth of patients (22.1%-22 .7%) [9] [10] [11] .This has created new opportunities for studying the contribution of each virus in the development, intensity, and duration of symptoms, as well as complications (eg, pneumonia) and death.To address this, many studies have sought to determine whether co-infection with \u22652 viruses contributes to the severity of an infection.Some of these studies have reported that the presence of >1 virus is associated with more severe infections, whereas others have not [9] [10] [11] [13] [14] [15] .In a systematic review and meta-analysis of studies carried out in children <5 years of age, no association between co-infection and increase in disease severity was found, but the need for further studies on this matter was identified [16] .Variability in the results of these studies might be a reflection of the populations included in each study, the definition of severity used, or the viruses that were compared.Of particular relevance is the definition of co-infection, as many studies compare those infected with a specific virus to infection with >1 virus [9] [10] [11] 15] .When assessing the effect of the presence of 2 viruses, various combinations may have differential effects on severity.In the present study, we investigated whether severity, defined as hospitalization with acute respiratory infections, increases with 2 viruses over that of each single virus.We analyzed data from a large prospective ILI cohort during 4 consecutive years in Mexico (ILI-002 study).This analysis is based on data from ILI-002, a hospital-based prospective observational cohort study of ILI [17] [18] [19] .The present analysis includes all participants enrolled in the ILI-002 study in whom 1 or 2 viruses were detected.The ILI-002 study was carried out at 6 public hospitals, 5 of them located in Mexico City and 1 in San Luis Potos\u00ed.Participating hospitals included 2 general hospitals (1 located in Mexico City and 1 in San Luis Potos\u00ed), 2 tertiary care pediatric hospitals, and 2 tertiary care hospitals (1 of them dedicated to the treatment of respiratory disorders, whereas the other provides medical care in a wide range of medical specialties).Adults and children seeking medical attention with ILI, defined as a respiratory symptom (eg, cough, dyspnea) plus a systemic symptom (eg, fever, malaise), were invited to participate in the ILI-002 protocol (ClinicalTrials.gov identifier: NCT01418287).For those enrolled, a follow-up telephone or face-to-face interview was performed at 14+\/-3 days, and a visit happened 28+\/-5 days after inclusion.The study protocol was approved by the ethics committee at all participating institutions, and all participants or guardians signed an informed consent or an assent form when pertinent.A nasopharyngeal swab for multiple PCR pathogen detection was obtained at enrollment.Samples were stored in transport media at 4\u00b0C at each site (for sites located in Mexico City) and sent daily to a central facility ( [HAdV] ) and 4 bacteria (Bordetella pertussis, Chlamydophila pneumoniae, Legionella pneumophila, and Mycoplasma pneumoniae).The 22-pathogen assay added CoV HKU1, HBoV, and influenza A (H1N1) pdm09 while removing influenza A H5N1.As reported by the manufacturer, the analytical limit of detection of the assay varies between 5 and 50 copies per reaction for most targets.Samples that were tested originally with the RespiFinder19 kit were subsequently tested for HBoV detection with the use of virus-specific primers.In addition, all samples were tested by real-time RT-PCR for influenza A following the Centers for Disease Control and Prevention (CDC) protocol [20] .Participants hospitalized during the 28 days of the study follow-up were considered to have severe disease.Hospitalization was defined as participants who were admitted to the hospital or remained in the emergency departments for at least 24 hours.Participants with a detected bacterial pathogen (Bordetella pertussis, Chlamydophila pneumoniae, Legionella pneumophila, and Mycoplasma pneumoniae), no virus, or >2 viruses were excluded.Comorbidities were defined as 1 of the following: chronic obstructive pulmonary disease, cardiovascular disease, diabetes mellitus, previous use of systemic steroids, obesity, overweight, and underweight.For this analysis, we grouped similar genera of viruses and examined the 8 most frequent groups of viruses isolated: influenza (A, A (H1N1)pdm09, and B grouped as influenza), HMPV, HPIV, RSV, RV, HAdV, CoV, and HBoV.Comparisons of baseline factors were made between hospitalization and nonhospitalization groups.All potential risk factors that were not categorical were grouped into categories.Chi-square statistics were used to make the univariate comparisons of the risk factors.Logistic regression models were used to compare hospitalization between all pairs of viruses and the combinations of the 2 viruses.Combinations with <10 participants were not analyzed.Each logistic regression model included sex, age (grouped into 3 categories), days since symptom onset (grouped into 3 categories), and comorbidity (yes\/no).Odds ratios and 95% confidence intervals were calculated.From 2010 to 2014, 5662 participants were included in the ILI-002 study.From these, 96.89% had a 28-day interview, 1619 had no virus isolated, and 32 had no sample; additionally, 85 were excluded for other reasons such as bacterial infections (18 subjects), missing covariate information (11 subjects), and >2 viruses (56 subjects).The final data set had 3926 participants.Of the 3926 participants, 1856 (47.3%) were hospitalized, 1411 (35.9%) were <11 years old, and 308 (7.8%) were >60 years old; 1673 (42.6%) were males (Table 1) .Of the 1856 hospitalized cases, 65 died with 1 virus and 12 died with 2 viruses detected.Table 2 shows the distribution of participants with a single virus diagnosis across the covariates used in the logistic regression models.Influenza, HPIV, CoV, and RV were detected more frequently in participants 11-60 years old, whereas RSV, HMPV, HAdV, and HBoV were more common in children <11 years old.One virus was detected in 3285 and 2 viruses were detected in 641 participants (Table 3) .RV (n = 1433), influenza (n = 888), and CoV (n = 703) were the most frequently detected viruses (either alone or in co-infection).The most frequent combination was influenza+CoV (116 of 641 dual infections; 18%).Influenza was found in combination with other agents in 237 participants (37% of 641 dual infections).There were 52 subjects with a combination of >3 viruses.The numbers were too small to perform any statistical analyses but were analyzed descriptively.In the subjects with 3 viruses detected, 56% had RV, 54% had influenza, and 48% had CoV.The combination of 3 viruses that occurred the most often (in 6 subjects) was influenza, HMPV, and HBoV.The adjusted odds ratios (ORs) for hospitalization rates between each of the viruses included in the study are shown in Figure 1 .Participants infected with HBoV were more likely to be hospitalized than those infected with influenza, CoV, HPIV, and RV ( Figure 1A) .Those with HAdV, HMPV, and RSV had similar but not statistically significant results.Participants infected with RSV were more likely to be hospitalized compared with cases of influenza, CoV, RV, HPIV, HAdV, and, to a lesser extent (not statistically significant), HMPV ( Figure 1B ).Participants with HMPV were more likely to be hospitalized compared with cases of influenza, CoV, and RV, but were not statistically significantly different compared with HPIV and HAdV ( Figure 1C ).HPIV cases were more likely to be hospitalized compared with cases of influenza, CoV, and, to lesser extent, HAdV (as assessed by point estimates) ( Figure 1D ), although none of these comparisons were statistically significant.Participants with HAdV were more likely to be hospitalized compared with cases of influenza and CoV (as assessed by point estimates), although neither of these comparisons reached statistical significance ( Figure 1E ).Participants with RV were more likely to be hospitalized as compared with CoV cases ( Figure 1F ).Although not statistically significant, CoV cases were less likely to be hospitalized as compared with those with influenza ( Figure 1G ).Figure 1H shows comparisons with influenza cases (already described).When 2 viruses were isolated, those with combinations of RSV+HPIV, CoV+HMPV, and CoV+RSV were less likely to be hospitalized than participants infected with individual viruses (Figure 2A-C) .The point estimates for individual viruses in HMPV and RV demonstrated a higher likelihood of these patients being hospitalized than those with combinations, but all confidence intervals included 1 ( Figure 2D ).Participants with HBoV+RV were more likely to be hospitalized than those with RV, but were hospitalized as frequently as those with HBoV alone ( Figure 2J ).The point estimate for severity in CoV+RV was greater than that for individuals for CoV or RV alone ( Figure 2K ), but the confidence interval included 1.The confidence intervals for all other combinations included 1, but the point estimates indicated that some of the combinations could be more severe than 1 of the single agents ( Figure 2L -R).Reports of the impact of multiple viral infections have been more frequent with the availability of PCR assays that detect multiple pathogens [9] [10] [11] [12] [13] [14] [15] .Most reports analyze data by grouping all combinations and compare this group with different single viruses.This has resulted in variable interpretations.ILI-002 is a large study of those with ILI in which a multipathogen PCR assay was performed on samples from all participants.The size of this cohort allowed there to be a sufficient number of participants with various virus combinations to perform separate analyses for some virus combinations and examine whether virus combinations increase severity over individual viruses.Our results highlight the importance of carrying out these separate analyses.Our data demonstrate that the severity of diseases was higher with specific viruses (eg, HBoV, RSV, and HMPV).However, in no combination was the dual infection significantly worse than in both of the individual viruses.Furthermore, as a class effect, it does not appear that infection with >1 virus increases severity of disease.Many of the confidence intervals for the combinations include no difference for each of the comparisons with the individual viruses.Based solely on point estimates, which may change with increasing numbers of participants, there appear to be some patterns that indicate a leading or governing effect of 1 virus in the combination.An example of this is the combination of CoV+RSV ( Figure 2C , panel C); CoV cases and CoV+RSV cases were less severe than cases of only RSV.Moreover, the severity of CoV+RSV cases was no different than that of CoV cases.This could indicate that CoV is the leading\/ governing agent in the combination.Similarly, HBoV may be governing RV in the combination of these 2 viruses (panel J), RV governing CoV (panel K), influenza governing HBoV (panel N), and RV governing RSV (panel P).The confidence intervals around the combinations are often large and include 1, so these interpretations are not conclusive and could differ if larger numbers of participants were studied.However, the pattern observed in the point estimates is suggestive of the governing effect described above and warrants further study.One explanation for the governing results is that virological testing was done only once in each participant, which does not distinguish sequential infections with 2 viruses from simultaneous infection with both viruses.It is possible that these results could reflect sequential infections rather than simultaneous infection and that symptoms (and hospitalization) could be the result of only 1 of the 2 viruses.The sample collection time with respect to the course of illness would then be an important factor.In a study carried out in participants with ILI, viral co-infections were detected more frequently in samples obtained during the first 2 days from symptom onset compared with those obtained after 3-7 days [21] .Thus, it is plausible that detection of co-infections might be the result of prolonged shedding of 1 virus with a subsequent infection with the second virus.Also, it could reflect a reduced ability of a second virus to replicate due to an already initiated host response and the production of interferon as a result of an initial viral infection.Interference of 1 virus with another virus has been shown to occur in vitro [22] , and epidemiological studies suggest that circulation of 1 virus might affect circulation of another virus in communities [23] .Overall, most previous studies have shown similar severity of single infections when compared with mixed infections [16] .However, some studies have shown significant differences between specific combinations of viruses and single viruses.For example, in cases of co-infection with RSV+RV and RSV+HBoV, the illness appeared to be more severe than in cases of RSV or HBoV infection alone [24] .Our results for RSV+RV follow the same pattern, but we did not have sufficient data to study the combination RSV+HBoV.Our analysis showed that participants with detection of only influenza virus were less likely to require hospitalization than participants in whom other viruses were detected.This was observed despite the fact that the study included the 2013-2014 winter season, when a severe wave of influenza A(H1N1) pdm09 was registered in Mexico [25] .This result could be derived from inclusion of all influenza subtypes in the analysis.The lower hospitalization rate in participants with influenza virus infection compared with those with other viruses may also be explained by influenza vaccination.Since 2009, influenza vaccination coverage in Mexico has been high [26] , and influenza vaccination has been reported to reduce influenza hospitalizations [27] .Unfortunately, it was not possible to obtain detailed data regarding influenza vaccination status for study participants to assess this.We also found that for single virus comparisons, HBoV, RSV, and HMPV were associated with severe infections.The RSV and HMPV finding is consistent with other reports that show these viruses to be leading causes of LRTI in children and adults [28] [29] [30] .In contrast, the role of HBoV as a cause of severe infections is less well established.Because HBoV infection is very common and frequently found in asymptomatic participants, the pathogenic role of this virus has been questioned [31, 32] .Children with higher viral loads tend to have more severe infections [33] , longer hospitalization duration [34, 35] , and are found to have co-infection by other viruses [36, 37] less frequently than those with lower viral loads.However, in children in daycare, viral load had no apparent association with severity of illness [31] , which also might reflect challenges in reproducibly measuring viral load in secretions.In all, these studies suggest that HBoV is frequently present in children as an asymptomatic or chronic infection with low viral loads, whereas some infections in which a high viral load is present may be associated with severe infections requiring hospitalization.Our study did not measure viral load, so it is unclear if our HBoV participants represented a sample of high-viral load participants, as we did not include asymptomatic participants with HBoV.The strengths of this study include the large numbers of participants and the consistent baseline testing and follow-up.Limitations include the definition of severity, as hospitalization was a surrogate for actual patient health status.Patients may be hospitalized for causes other than their respiratory illness, such as worsening of comorbidities, observation in high-risk participants, or social reasons.Further studies should be done using direct measures of patient health status such as intensity and duration of participants' symptoms or complications (eg, pneumonia).We have developed a symptom scale for influenza (FLU-PRO) as part of the study ILI-002 that could be used in future studies [38] .Adjusted odds ratio (on log scale) 20 The presence of chronic underlying conditions is an important factor that is associated with risk of developing severe respiratory infections.In addition, it is possible that chronic conditions may increase the risk of acquiring infections by multiple pathogens.A recent study reported that patients with coinfection caused by 2 or 3 different influenza virus strains were more likely to have underlying cardiovascular disorders than those with single influenza infections [39] ; however, no differences were observed in the prevalence of other underlying conditions.Although some other studies have found a higher prevalence of chronic disorders in patients with multiple viral pathogens, these appear to be limited to specific conditions, and no differences have been observed for other disorders [15, 40] .In addition, many studies have not found an association between the presence of chronic disorders and detection of multiple viruses [9, 14, 21, 24] .The main objective of our study was to determine if codetection of 2 viruses was associated with worse outcome, and we did not analyze which factors may have led to acquisition of \u22652 viruses; nevertheless, our analysis included the presence of chronic conditions as a covariate, in order to account for potential confounding.In a previous analysis of ILI-002 limited to children <5 years of age, the severity of single viruses was compared [7] , and the results were similar to our findings for single viruses in the present study.The majority of studies have focused on children, and the effect of mixed viral infections in adults is less clear [40] .One of the strengths of this analysis is that our study population included both pediatric and adult symptomatic participants.Although some comparisons resulted in estimates with wide confidence intervals, our interpretation based on point estimates revealed several patterns and could be hypothesis-generating for future studies.Our results suggest that, in general, having >1 virus detected by PCR on a respiratory sample does not increase the severity of disease from ILI.To assess the differences in hospitalization rates of mixed respiratory infections, it is necessary to carry out analyses between specific combinations of viruses.When 2 viruses are detected, it appears that the clinical severity of a respiratory infection, as defined by hospitalization, may be associated with 1 of these agents.Future studies with a larger number of participants designed to distinguish between sequential and simultaneous infection and using direct measures of patient health status should be of help in defining the role of each virus during the evolution of an acute respiratory episode.\n\n\nHighlight:\n\nIn addition, many studies have not found an association between the presence of chronic disorders and detection of multiple viruses [9, 14, 21, 24]\n\n========================================================================================\n\n\n**Question 4: Data on potential risks factors : Neonates and pregnant women -**\n\nObservation made from research papers published on 2020: \n\n1845\t\n779c1b5cb3afe3d50219aa2af791014a22eb355a\t\n10.3390\/v12020194\t\n2020\t\nSchwartz, David A.; Graham, Ashley L.\t\t\n\nviruses Perspective Potential Maternal and Infant Outcomes from Coronavirus 2019-nCoV (SARS-CoV-2) Infecting Pregnant Women: Lessons from SARS, MERS, and Other Human Coronavirus Infections\t\n\nTRUE\t\n\nIn order to address the potential obstetrical outcomes of infection to both mother and infant, the present communication describes the current state of knowledge regarding the effects of other coronavirus infections in pregnancy.It is the most prevalent non-obstetric infectious condition that occurs during pregnancy [14] [15] [16] .The most common adverse obstetrical outcomes associated with maternal pneumonias from all causes include This newly recognized coronavirus, producing a disease that has been termed COVID-19, is rapidly spreading throughout China, has crossed international borders to infect persons in neighboring countries, and humans infected by the virus are travelling via commercial airlines to other continents.In order to address the potential obstetrical outcomes of infection to both mother and infant, the present communication describes the current state of knowledge regarding the effects of other coronavirus infections in pregnancy.It is the most prevalent non-obstetric infectious condition that occurs during pregnancy [14] [15] [16] .The most common adverse obstetrical outcomes associated with maternal pneumonias from all causes include premature rupture of membranes (PROM) and preterm labor (PTL), intrauterine fetal demise (IUFD), intrauterine growth restriction (IUGR), and neonatal death [14] [15] [16] .However, even if this is the case, there is no doubt that SARS coronavirus infection was found to be associated with severe maternal illness, maternal death, and spontaneous abortion [19, [28] [29] [30] [31] .[29] evaluated the obstetrical outcomes from a cohort of pregnant women who developed SARS in Hong Kong during the period of 1 February to 31 July 2003.Four of the 7 women (57%) that presented during the 1st trimester sustained spontaneous miscarriages, likely a result of the hypoxia that was caused by SARS-related acute respiratory distress.Obstetrical ultrasounds revealed a low-lying placenta (placenta previa) but were otherwise normal.These 2 pregnancies also were complicated by oligohydramnios and had poor obstetrical outcomes-both infants had developed IUGR.In order to address the safety issues for the obstetrical management and delivery of pregnant women with SARS, guidelines were prepared by the Canadian Task Force on Preventive Health Care and the Society of Obstetricians and Gynaecologists of Canada [45] .A multidisciplinary team, consisting of obstetricians, nurses, pediatricians, infection control specialists, respiratory therapists, and anaesthesiologists, should be identified in each unit and be responsible for the unit organization and implementation of SARS management protocols.Two women died and there were 2 cases of perinatal death-1 stillbirth and 1 neonatal death shortly after emergency cesarean section.[62] , epidemiologic investigation of the 2012 MERS outbreak in Zarqa, Jordan, revealed that a 2nd trimester stillbirth (5 months gestational age) had occurred as a result of maternal exposure to MERS-CoV.This was the first documented occurrence of stillbirth during maternal infection with MERS-CoV.Today, pregnant women are usually excluded from experimental trial of drugs and vaccines that do not target obstetric conditions [69] .Coronaviruses can also result in adverse outcomes for the fetus and infant including intrauterine growth restriction, preterm delivery, admission to the ICU, spontaneous abortion and perinatal death.It remains to be seen during the current Wuhan 2019-nCoV epidemic how this newly-emergent coronavirus affects pregnant women and their infants, as well as which factors may modulate obstetrical disease and outcomes including the timing of maternal coronavirus exposure by gestational age, the effects of medications or other treatment regimens, differences in host immune responses, occurrence of coexisting medical and obstetrical conditions, and other covariables.\n\n\nHighlights:\n\nHowever, even if this is the case, there is no doubt that SARS coronavirus infection was found to be associated with severe maternal illness, maternal death, and spontaneous abortion [19, [28] [29] [30] [31]\n\n==================================================================================================\n\n**Question 5: Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences**\n\n\n402\tce6717ad3bb0da86077a5cbb8111576ea8230b2c\thttp:\/\/dx.doi.org\/10.15167\/2421-4248\/jpmh2019.60.3s1\t2019 Oct 15\t\t\tWHO's Global School Health Initiative. 1995. 4 WHO. Helsinki statement on health in all policies. 2013. 5 WHO. Health 2020. A European policy framework and stra-tegy for the 21 st century 2013\tTRUE\tThe contrast to the spread of chronic diseases, recently promoted by WHO with the 2020 Health Program, is also of particular relevance in terms of occupational health protection, since many of the chronic-degenerative age-related diseases, once they arise, can condition people's quality of life, progressively and permanently compromising their level of autonomy and work capacity, strongly affecting the system productivity.The repercussions observed in terms of employment can be different: reduced productivity, absence due to illness, demotion, interruption of the employment relationship which, depending on the case, can be an early retirement, a recognition of disability indemnified by the government, or even a dismissal.The term DM refers to a model theorized in the 1980s, initially developed in North America and Europe, which today is still poorly applied in Italy, aimed at reducing the impact of invalidity (deriving from disability, illness or accident) on the individuals' capability to effectively carry out their work activities.The establishment of such network has the objective of improving management, providing a centralized and homogeneous response throughout the entire region and reducing mobility to extra-regional providers.Therefore, only by increasing the vaccination level even further, the force of infection can be decreased due to the herd immunity and hence reducing the risk and size of sporadic measles outbreaks.The paper proposes a method for measuring the health benefits expected from reducing the contamination of drinking water and food matrices.These findings are important to understand the global shifting from the MD and to develop public health strategies for reducing health inequalities in the Mediterranean region and for health promotion.The high density of the discharge can create a briny layer on the seafloor affecting marine organisms and water quality.Migrant populations have specific health needs often due to social vulnerability.In line with our findings, further research is encouraged to develop an individualized approach and screening protocols -based on patient's characteristics -for reducing incidence of postoperative complications and improving long-term outcomes.\n\nHighlight:\n\nThe repercussions observed in terms of employment can be different: reduced productivity, absence due to illness, demotion, interruption of the employment relationship which, depending on the case, can be an early retirement, a recognition of disability indemnified by the government, or even a dismissal.\n\n\n","d3a2cb15":"**LDA TOPIC WITH WEIGHTS**","45bf25e4":"**TASK 1:**\n\nTask Details\nWhat do we know about COVID-19 risk factors? What have we learned from epidemiological studies?\n\nSpecifically, we want to know what the literature reports about:\n\n1. Data on potential risks factors\n    * Smoking, pre-existing pulmonary disease\n    * Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities\n    * Neonates and pregnant women\n    * Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.\n2. Transmission dynamics of the virus, including the basic reproductive number, incubation period, serial interval, modes of transmission and environmental factors\n3. Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups\n4. Susceptibility of populations\n5. Public health mitigation measures that could be effective for control","525ede4f":"The Visualization clearly talks about the : **coronavirus, transmission, infection, vaccine, ourbreak etc.. **\nGiving a clear picture of the terminalogies and informations that can be retrived from the research papers.","6943beea":"# PROS and CONS\n\nPROS:\n\n1. Good understanding and iference of the research papers through TSNE and LDA models\n2. Well Trained word embedding models\n3. Accurate keyword extraction with emamples demonstrated with results\n\nCONS:\n\n1. Manual intervention to establish the relationship of search algorithm to derive answers to the questions.","3652c746":"**Dimensionality Reduction with t-SNE**\n\nUsing t-SNE we can reduce our high dimensional features vector to 2 dimensions. By using the 2 dimensions as x,y coordinates, the text_body_clean can be plotted. t-SNE will attempt to preserve the relations of the higher dimensional data as closely as possible when shrunk to 2D\n\nAnalyse with perplexity of 5000, cluster 10, iteration : 15000\n\nThe optimal cluster parameter is decided after clustering the data from different preplexity and clusters and visualized.","c8bf82d2":"In the above word cloud for the topics were mostly about genome of the covid-19 and possibilties of other corona virus genomes and carriers.\n","a2858b2a":"# MODEL BUILDING AND INFERENCE","eb5e0249":"**Model Evaluation:**\n\nExample 1:\n\n**\" COVID-19 \"** keyword when tested against our word embedding model gave the following results.\n\n[('ncp', 0.7167163491249084), ('wuhan', 0.7067078351974487), ('2019ncov', 0.7065909504890442), ('sarscov2', 0.6876667737960815), ('mers', 0.6260266304016113), ('sars', 0.6118236780166626), ('2020', 0.6101416349411011), ('hubei', 0.5763685703277588), ('mainland', 0.5460340976715088), ('china', 0.531872034072876)]\n\nnotable keywords from the word2vec output are: 'wuhan','sars','china' relating to the orgin of the virus\n\n\nExample 2:\n\nFor Multiple keywords **'treatment','option'** keyword when tested against our word embedding model gave the following results.\n\n[('treatments', 0.88392174243927), ('therapies', 0.7969704866409302), ('therapy', 0.7752498984336853), ('drugs', 0.7263898253440857), ('medications', 0.7093261480331421), ('antivirals', 0.6795921325683594), ('regimens', 0.6594418287277222), ('prophylaxis', 0.653971254825592), ('medication', 0.6348516941070557), ('antibiotics', 0.6138178706169128)]\n\nnotable keywords from the word2vec outpur are : 'prophylaxis','therapies' relating to preventive medications . \n\nAs shown below:","995548d1":"**Topic 1**","b0e33a6a":"> TOPIC CSV CREATION","a9ce1952":"Data Cleaning","71bde6e8":"Question 1:* Public health mitigation measures that could be effective for control\n**--> 'interventions|policies|quarantine|awareness|preparedness|restrictions|campaigns|behaviors|biosecurity|governmental|search_data'**","c00755c6":"In the above Questions, Questions 1, 3 AND 5 are attempted using a combination of word2vec embedding to extract the keywords and search algorithm to extract the research articles related to it.\n\nWord2vec embedding provides the keywords that are closest to answer the questions","130c5e2a":"Cleaning of corpus helper functions ","b46681fc":"EXTRACT CSV","2f5ca5b2":"# VISUALIZATION","77906c7e":"**SEARCH ALGORITHM **\n\nTo extract the relevant research documents from the keywords extarcted ","70d94804":"As shown in the above steps, the context of the context words 'treatment','options' are well understood by the word2vec model in predicting the target words 'therapy','antivirals','regimens','prophylaxis' which are very relavant in finding the answers to the questions.","a9f98ece":"*The Keywords extracted through embedding are passed on to the below functions to extarct the list of research articles to further manually pick the articles relevant to the questions to answer the questions.*\n\n**Following are the keywords picked question wise:**\n\n* Public health mitigation measures that could be effective for control\n**--> 'interventions|policies|quarantine|awareness|preparedness|restrictions|campaigns|behaviors|biosecurity|governmental|search_data'**\n* Smoking, pre-existing pulmonary disease\n**--> comorbidities|mellitus|cardiovascular|vulnerability|hypertension|pneumonia|chronic**\n* Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities\n**--> severe|fatal|coinfection|contagious|susceptible|merscov|sftsv|highly|ibv|pedv|csfv|pathogenicity|eiav|prrsv|prv|h1n1pdm|hepatatis|lethal|mhv**\n* Neonates and pregnant women\n**--> stillbirth|miscarriage|congenital|malformations|microcephaly|abortion|obstetric|lbw|covid19**\n* Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.\n**--> lessen productivity|macroeconomic affecting|vulnerability|devastating|reducing|recession|unemployment**\n\n\nSeperate Excel is created in the Output section for each questions with its possible research articles that can prove the inference made using the word2vec answering approach.","992f8e18":"risk factor\n* Smoking, pre-existing pulmonary disease\n* Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities\n* Neonates and pregnant women\n* Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.","20f053a3":"**Answering Approach word embedding method**\n \nWord embedding for the following questions are extracted by passing a set of words from the question to the word embedding model and closest keywords are extracted to further find the closest keywords as shown in the example below:\n\n\n1. Data on potential risks factors\n    * Smoking, pre-existing pulmonary disease\n    * Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities\n    * Neonates and pregnant women\n    * Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.\n2. Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups\n\n3. Public health mitigation measures that could be effective for control\n\n\n**Example:**\n\n**Question 3 : Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).**\n\n***Embedding Step to extract keywords* **\n\n> print(word_model.predict_output_word(['covid19','surfaces'],topn=30))\n> print(word_model.predict_output_word(['covid19','surfaces','nonporous','handrails','desks','floor','fomite'],topn=30))\n> print(word_model.most_similar(['covid19','fomites','airborne','nonporous','handrails','desks','floor','fomite'],topn=30))\n\n***Search Algorithm to extracted related research articles:***\n\n> searc_by_keys_as_excel('fomites|airborne|nonporous|handrails|desks|floor|fomite|hands|toilets|door|bedrails',search_data)\n> \n","1138bb9b":"Filtered Data to be used to visualize the word cloud in the upcoming cells to understand the importance of topics and vocabs used.","da372b06":"Looks like we have a lot of unique phrases in our corpus of research papers, based on the preceding output. Several of these terms are not very useful since they are specific to a paper. Hence, we will prune our vocabulary and start removing terms.","cb026557":"**WORD CLOUD FOR THE DOMINANT TOPIC(S) **\n\nExample: Topic 1 can have 20 documents while Topic 2 may have 200 documents in it.Hence a word cloud is drawn to visualize the intersting vocabs involving each Topic","b7570bee":"**Load the LDA Model **","60d0e394":"# EDA\n\nWORD CLOUD FOR THE TITLE OF ARTICLES FROM 2019 - 2020 ","19824a7b":"# CONCLUSION","64680f4f":"Data Preparation included the below process:\n\n* Load Research & Meta Data\n* Meta Data filter for published time from 2019 to 2020 on doc_id\n* Remove unused fields for the search inference.","4e362bf1":"Import libraries","bc4b4e6b":"**Creation of Word Cloud Topic wise**","53fad5a5":"**Loading data(a)-Complete data by reading uploaded CSV** | CSV file is created by parsing the JSON data","d2b6896c":"Visualise Cleaned Data and removing columns","82ea107c":"**WORD2VEC MODEL **\n\nWORD2VEC EMBEDDING IS USED TO PREDICT THE TARGET WORD(S) FORM THE CONTEXT WORDS(Questions from task) USING CBOW \n\nIn this COVID-19 challenge the questions form the context words, we leverage the context words from the questions to predict the target words to form the keywords, which inturn will lead us to the answers for the respective context words(questions). we are using the CBOW approach in word2vec to acheive this.","5151b450":"We perform some basic text wrangling or preprocessing before diving into topic modeling. We keep things simple here","cfadd95e":"**LDA TOPICS WITH TOPIC ID** ","dd59c487":"Question 5: * Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.\n**--> lessen productivity|macroeconomic affecting|vulnerability|devastating|reducing|recession|unemployment**","01d37dd4":"word2vec model loading, we are using the training model by loading it.","71fbb762":"Import libraries ","3401f080":"# COVID-19 Open Research Dataset (CORD-19) Analysis\n\n![CORD-19.png](attachment:CORD-19.png)\n\n\n*An example of result snippet is shown below, For each tasks a sperate notebook is created with answers to each questions in a task added to a excel*\n\n\n","cb621489":"**LDA TOPIC WITHOUT WEIGHTS**","e27fc91e":"**KEYWORD EXTRACTION**\n\n* Public health mitigation measures that could be effective for control\n**--> 'interventions|policies|quarantine|awareness|preparedness|restrictions|campaigns|behaviors|biosecurity|governmental|search_data'**\n* Smoking, pre-existing pulmonary disease\n**--> comorbidities|mellitus|cardiovascular|vulnerability|hypertension|pneumonia|chronic**\n* Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities\n**--> severe|fatal|coinfection|contagious|susceptible|merscov|sftsv|highly|ibv|pedv|csfv|pathogenicity|eiav|prrsv|prv|h1n1pdm|hepatatis|lethal|mhv**\n* Neonates and pregnant women\n**--> stillbirth|miscarriage|congenital|malformations|microcephaly|abortion|obstetric|lbw|covid19**\n* Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.\n**--> lessen productivity|macroeconomic affecting|vulnerability|devastating|reducing|recession|unemployment**","1f29d1d4":"As shown in the above steps, the context of the context words 'covid19' are well understood by the word2vec model in predicting the target words 'wuhan','sars','china' relating to the orgin of the virus which are very relavant in approaching the answers to the questions. ","5c1c71e7":"**WORD CLOUD VISUALIZATION **\n\nWe have filtered 2019-2020 research papers to understand COVID-19 data through the word cloud visualization.","c7f992f6":"# SOLUTION APPROACH\n\n![covid.JPG](attachment:covid.JPG)","1afac60d":"**Robust Word2Vec Model with Gensim**\n\nThe __`gensim`__ framework, created by Radim \u0158eh\u016f\u0159ek consists of a robust, efficient and scalable implementation of the Word2Vec model. We will leverage the same on our covid-19 corpus. In our workflow, we will tokenize our normalized corpus and then focus on the following four parameters in the Word2Vec model to build it.\n\n- __`size`:__ The word embedding dimensionality : 100\n- __`window`:__ The context window size : 20\n- __`min_count`:__ The minimum word count : 1\n- __`iter`:__ Iteration : 1000 \n- __`sg`:__ Training model, 1 for skip-gram otherwise CBOW : CBOW\n\nWe have build a  Word2Vec model on the corpus. ","635f3bd6":"> In the above word cloud for the topics were mostly about infection samples and detection of virus in a patient","f5ef629d":"**Evaluating topic model:**\n\nQuality We can use perplexity and coherence scores as measures to evaluate the topic model. Typically, lower the perplexity, the better the model. Similarly, the lower the UMass score and the higher the Cv score in coherence, the better the model."}}