{"cell_type":{"5c527a80":"code","f52f1852":"code","60f71708":"code","97ef6158":"code","29092fd0":"code","be09b7d5":"code","41355274":"code","77eadc86":"code","8556bde5":"code","32eb6b29":"code","192f47b6":"code","b8d52e9c":"code","cb4e128a":"code","1d8fbd27":"code","09c5ead6":"code","f624d9d8":"code","bc81c36a":"code","15b6502e":"code","49422f08":"code","c9cdb41d":"code","d9b1c4c5":"code","d2930c75":"code","ef6ca569":"code","23a6e152":"code","9061df0e":"code","33f51f51":"code","4e649324":"code","bfc38d37":"code","79f42d5d":"code","a34f2ea4":"code","405d2cd9":"code","56b2e4da":"code","7a681e4f":"code","63d42f81":"code","81f0075a":"markdown","6be267a7":"markdown","c6e08304":"markdown","ce2af60d":"markdown","7d02e2ae":"markdown","0f595f60":"markdown","8562ab54":"markdown","c0ece978":"markdown","be183f19":"markdown"},"source":{"5c527a80":"import numpy as np \nimport pandas as pd \n\nfrom glob import glob\nimport os\nimport matplotlib.pyplot as plt\nimport shutil\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision import models\nimport torch\nfrom torch.autograd import Variable\nfrom torch.utils.data import random_split\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch import optim\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import datasets, transforms, models\nimport time\n%matplotlib inline","f52f1852":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","60f71708":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","97ef6158":"transform = transforms.Compose([\n                                transforms.ToTensor(),\n                                transforms.Resize((80,80))\n                               ])\ndataset = torchvision.datasets.ImageFolder('\/kaggle\/input\/flowers-recognition\/flowers\/flowers', transform=transform)","29092fd0":"print(dataset.classes)","be09b7d5":"print(dataset[0][0].shape)\nplt.imshow(dataset[0][0].permute(1, 2, 0))","41355274":"print(dataset[1][0].shape)\nplt.imshow(dataset[1][0].permute(1, 2, 0))","77eadc86":"print(len(dataset),\"\\n\")\nprint(\"75% samples   \",int(0.75*len(dataset)))\nprint(\"25% samples   \",int(0.25*len(dataset)))","8556bde5":"train_dataset, test_dataset = torch.utils.data.random_split(dataset,[3243, 1080])","32eb6b29":"# DataLoader to divide into batches\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,   \n                                           batch_size = 32,   \n                                           shuffle = True)   \n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                         batch_size = 32, \n                                         shuffle = True)","192f47b6":"class ConvNet(nn.Module):   \n    def __init__(self):   \n        super(ConvNet, self).__init__()\n\n        self.layer1 = nn.Sequential(   \n            nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1),   \n            nn.BatchNorm2d(64),   \n            nn.ReLU(),   \n            nn.MaxPool2d(kernel_size = 2, stride = 2))    \n        \n     \n        self.layer2 = nn.Sequential(   \n            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        \n        self.layer3 = nn.Sequential(  \n            nn.Conv2d(128, 256, kernel_size = 5, stride = 1, padding = 2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n           \n            \n        self.fc1 = nn.Linear(256*10*10, 128)   \n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 5)\n                \n    def forward(self, x):   \n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.reshape(out.size(0), -1)  \n        out = F.relu(self.fc1(out))  \n        out = F.dropout(out, training = self.training)\n        out = F.relu(self.fc2(out))\n        out = F.dropout(out, training = self.training)\n        out = F.relu(self.fc3(out))\n        return F.log_softmax(out,dim=1)","b8d52e9c":"model = ConvNet().to(device)","cb4e128a":"number_of_epochs = 10\nlearning_rate = 0.001","1d8fbd27":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()     \noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) ","09c5ead6":"total_step = len(train_loader)\nTraining_Loss = []   \nTraining_Accuracy = []   \nTest_Loss = []   \nTest_Accuracy = [] \n#training loop\n\nfor epoch in range(number_of_epochs):   \n    training_accuracy = 0\n    cum_tr_acc = 0\n    test_accuracy = 0\n    cum_ts_acc = 0\n    \n    for i, (images, labels) in enumerate(train_loader):  \n        model.train()\n        images = images.to(device)   \n        labels = labels.to(device)   \n\n        # Forward pass to get output\n        outputs = model(images)\n        # Calculate Loss: softmax --> cross entropy loss\n        loss = criterion(outputs, labels)   \n\n        # Clear optimizers\n        optimizer.zero_grad()   \n\n        # Getting gradients w.r.t. parameters\n        loss.backward()\n\n        # Updating parameters\n        optimizer.step()   \n\n        # Checking accuracy\n        preds = outputs.data.max(dim = 1, keepdim = True)[1]\n        cum_tr_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n\n        training_accuracy = cum_tr_acc\/len(train_loader.dataset) * 100\n\n    for i, (images, labels) in enumerate(test_loader):\n        model.eval()\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        test_loss = criterion(outputs, labels)\n\n        # Checking accuracy\n        preds = outputs.data.max(dim = 1, keepdim = True)[1]\n        cum_ts_acc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n\n        test_accuracy = cum_ts_acc\/len(test_loader.dataset) * 100\n\n    print(\"Epoch {}; Loss: {loss:.2f}; Accuracy: {training_accuracy:.2f}%; Test_Loss: {test_loss:.2f}; Test_Accuracy: {test_accuracy:.2f}%\".format(epoch+1, loss=loss.item(), training_accuracy = training_accuracy, test_loss = test_loss.item(), test_accuracy = test_accuracy))\n\n    Training_Loss.append(loss)   \n    Training_Accuracy.append(training_accuracy)   \n    Test_Loss.append(test_loss)   \n    Test_Accuracy.append(test_accuracy) ","f624d9d8":"model.eval()    \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:   \n        pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = model(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)   \n        pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n        \n    training_accuracy = 100 * correct \/ total\n    \n    print('Test Accuracy of the model on the test images: {} %'.format(training_accuracy))\n","bc81c36a":"plt.plot(range(10),Training_Loss)\nplt.plot(range(10),Test_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\")\nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","15b6502e":"transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                transforms.RandomRotation(0.2),\n                                transforms.ToTensor(),\n                                transforms.Resize((224,224))\n                               ])\n\ndataset = torchvision.datasets.ImageFolder('\/kaggle\/input\/flowers-recognition\/flowers\/flowers', transform=transform)\n\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [3000, 1323])\n\n#DataLoader to divide into batches\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,   \n                                           batch_size = 32,   \n                                           shuffle = True)   \n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                         batch_size = 32, \n                                         shuffle = True)","49422f08":"resnet = torchvision.models.resnet18(pretrained=True)","c9cdb41d":"resnet","d9b1c4c5":"Features = resnet.fc.in_features\nresnet.fc = nn.Linear(Features, 5)","d2930c75":"resnet = resnet.cuda()","ef6ca569":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet.parameters(), lr = learning_rate)","23a6e152":"total_step = len(train_loader)\nTraining_Loss = []\nTraining_Accuracy = []\nTest_Loss = []\nTest_Accuracy = []\n\nfor epoch in range(number_of_epochs):\n  training_accuracy = 0\n  test_accuracy = 0\n  for i, (images, labels) in enumerate(train_loader):\n    resnet.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = resnet(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim = 1, keepdim = True)[1]\n    training_accuracy += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  training_accuracy = training_accuracy\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(test_loader):\n    resnet.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = resnet(images)\n    test_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim = 1, keepdim = True)[1]\n    test_accuracy += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  test_accuracy = test_accuracy\/len(test_loader.dataset) * 100\n  \n  print(\"Epoch {}; Loss: {loss:.2f}; Accuracy: {training_accuracy:.2f}%; Test_Loss: {test_loss:.2f}; Test_Accuracy: {test_accuracy:.2f}%\".format(epoch+1, loss=loss.item(), training_accuracy = training_accuracy, test_loss = test_loss.item(), test_accuracy = test_accuracy))\n  \n  Training_Loss.append(loss)\n  Training_Accuracy.append(training_accuracy)\n\n  Test_Loss.append(test_loss)\n  Test_Accuracy.append(test_accuracy)","9061df0e":"model.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = resnet(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n        \n    training_accuracy = 100 * correct \/ total\n    \n    print('Test Accuracy of the model on the test images: {} %'.format(training_accuracy))\n","33f51f51":"plt.plot(range(5),Training_Loss)\nplt.plot(range(5),Test_Loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title(\"Loss\") \nplt.legend([\"Training Loss\", \"Validation Loss\"])\nplt.show()","4e649324":"vgg = torchvision.models.vgg16(pretrained = True)","bfc38d37":"vgg","79f42d5d":"vgg.classifier[6].out_features = 5\nfor param in vgg.features.parameters(): \n    param.requires_grad = False","a34f2ea4":"vgg = vgg.cuda()","405d2cd9":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vgg.parameters(), lr = learning_rate)","56b2e4da":"total_step = len(train_loader)\nTraining_Loss = []\nTraining_Accuracy = []\nTest_Loss = []\nTest_Accuracy = []","7a681e4f":"for epoch in range(number_of_epochs):\n  training_accuracy = 0\n  test_accuracy = 0\n  for i, (images, labels) in enumerate(train_loader):\n    vgg.train()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = vgg(images)\n    loss = criterion(outputs, labels)\n    \n    # Backward and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim = 1, keepdim = True)[1]\n    training_accuracy += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  training_accuracy = training_accuracy\/len(train_loader.dataset) * 100\n    \n  for i, (images, labels) in enumerate(test_loader):\n    vgg.eval()\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    # Forward pass\n    outputs = vgg(images)\n    test_loss = criterion(outputs, labels)\n    \n    # Checking accuracy\n    preds = outputs.data.max(dim = 1, keepdim = True)[1]\n    test_accuracy += preds.eq(labels.data.view_as(preds)).cpu().sum()\n    \n  test_accuracy = test_accuracy\/len(test_loader.dataset) * 100\n  \n  print(\"Epoch {}; Loss: {loss:.2f}; Accuracy: {training_accuracy:.2f}%; Test_Loss: {test_loss:.2f}; Test_Accuracy: {test_accuracy:.2f}%\".format(epoch+1, loss=loss.item(), training_accuracy = training_accuracy, test_loss = test_loss.item(), test_accuracy = test_accuracy))\n  Training_Loss.append(loss)\n  Training_Accuracy.append(training_accuracy)\n\n  Test_Loss.append(test_loss)\n  Test_Accuracy.append(test_accuracy)","63d42f81":"model.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        pred = []\n        Images = images.to(device)\n        Labels = labels.to(device)\n        outputs = vgg(Images)\n        prediction_array = outputs.data\n        \n        _, predicted = torch.max(prediction_array, 1)\n        pred += predicted\n        total += Labels.size(0)\n        correct += (predicted == Labels).sum().item()\n        \n    training_accuracy = 100 * correct \/ total\n    \n    print('Test Accuracy of the model on the test images: {} %'.format(training_accuracy))\n","81f0075a":"# Loading Dataset","6be267a7":"# Training Loop","c6e08304":"# Model Building","ce2af60d":"# Training Loop","7d02e2ae":"# Training Loop","0f595f60":"# (1)Transfer Learning Using Resnet 18","8562ab54":"# (2)Transfer Learning Using VGG 16","c0ece978":"# Importing Libraries","be183f19":"# Outputs\n\n#### Test Accuracy with Resnet18 :- 82.99 % \n\n#### Test Accuracy with VGG16 :- 80.80%"}}