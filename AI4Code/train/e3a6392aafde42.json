{"cell_type":{"d0f6f637":"code","11b823bf":"code","5e1efa0d":"code","f9c8e7eb":"code","f1b96b45":"code","d36015d3":"code","c79ad7c8":"code","acd21b74":"code","42b7cfe6":"code","4738573c":"code","99e46637":"code","207b02dc":"code","2920774d":"code","0c64c766":"code","d339d110":"code","999a2794":"code","ff10b341":"code","9e3a2228":"code","ab9e3565":"code","e58570aa":"code","abde8f7d":"code","638b4340":"code","c185ab60":"code","0f069cab":"code","7f0fc9ea":"code","c136594d":"code","bd67a0b8":"code","8d58cde7":"code","230a3f0a":"code","705e6c37":"code","c48f6a32":"code","3ecfb603":"code","298894b3":"code","8567a7e4":"code","c177e520":"code","f7afc409":"code","d31ec112":"code","eaf046c7":"code","46361140":"code","80de1975":"code","6d9f4a25":"code","afd238ce":"code","f428c815":"code","90600c83":"code","18d813c7":"code","e7360503":"code","0887f854":"code","0cef1c3f":"code","a571c767":"code","0bb1f7e9":"code","ca5b7a5f":"markdown","69c21442":"markdown","c4131377":"markdown","8419e522":"markdown","5e736af3":"markdown","f892c469":"markdown","efbc97fd":"markdown","ce104782":"markdown","b146596f":"markdown","e2373ef1":"markdown","ea32de70":"markdown","a881e9af":"markdown"},"source":{"d0f6f637":"import numpy as np # linear b\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)b\nimport seaborn as sns\nimport matplotlib.pyplot as plt","11b823bf":"train_path = '..\/input\/the-great-indian-hiring-hackathon\/Participants_Data_TGIH'\ntrain = pd.read_csv('..\/input\/the-great-indian-hiring-hackathon\/Participants_Data_TGIH\/Train.csv')\ntest =  pd.read_csv('..\/input\/the-great-indian-hiring-hackathon\/Participants_Data_TGIH\/Test.csv')\nsample_submission = pd.read_csv( '..\/input\/the-great-indian-hiring-hackathon\/Participants_Data_TGIH\/Sample Submission.csv')\n","5e1efa0d":"train.head()","f9c8e7eb":"test.head()","f1b96b45":"train.info()","d36015d3":"test.info()","c79ad7c8":"train.describe()","acd21b74":"test.describe()","42b7cfe6":"train.nunique()","4738573c":"# !pip install reg_resampler # will use if needed","99e46637":"Target_col = 'UnitPrice'","207b02dc":"categorical_vars = ['InvoiceNo', 'StockCode', 'Description', 'CustomerID', 'Country']\nconts = ['UnitPrice', 'Quantity']","2920774d":"train.Quantity.plot.hist()","0c64c766":"train.UnitPrice.plot.hist()","d339d110":"### By observing test dataset, Observed that test dont have quantity values higher than 4800 and lower than 9360\n### Also the UnitPrice column have 80000 which is an outlier i consider","999a2794":"# outliers\ntrain = train[train['Quantity']<=4800]\ntrain = train[train['Quantity']>-9360.000000]\n# Removed outliers\ntrain = train[train['UnitPrice']<30000]","ff10b341":"for i in categorical_vars:\n    print(train.groupby(i)['UnitPrice'].value_counts().nlargest(5))","9e3a2228":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train['Country'])\ntrain['Country_encode'] = le.transform(train['Country'])\ntest['Country_encode'] = le.transform(test['Country'])","ab9e3565":"# performing freq encoding\n\ndicto = train['Country'].value_counts(normalize=True).to_dict()\ntrain['Country'] = train['Country'].map(dicto)\ndicto = test['Country'].value_counts(normalize=True).to_dict()\ntest['Country'] = test['Country'].map(dicto)","e58570aa":"dicto = train['StockCode'].value_counts(normalize=True).to_dict()\ntrain['StockCode_freq'] = train['StockCode'].map(dicto)\ndicto = test['StockCode'].value_counts(normalize=True).to_dict()\ntest['StockCode_freq'] = test['StockCode'].map(dicto)","abde8f7d":"from scipy import stats","638b4340":"fitted_data, fitted_lambda = stats.boxcox(np.abs(train['Quantity']))\ntrain['Quantity_box'] = fitted_data\nfitted_data, fitted_lambda = stats.boxcox(np.abs(test['Quantity']))\ntest['Quantity_box'] = fitted_data","c185ab60":"sns.distplot(fitted_data)","0f069cab":"# date extractor info\ntrain['InvoiceDate'] = pd.to_datetime(train['InvoiceDate'])\ntest['InvoiceDate'] = pd.to_datetime(test['InvoiceDate'])","7f0fc9ea":"for df in [train, test]:\n    df['year'] = df['InvoiceDate'].dt.year\n    df['day'] = df['InvoiceDate'].dt.day\n    df['hour'] = df['InvoiceDate'].dt.hour\n    df['minutes'] = df['InvoiceDate'].dt.minute\n    df['day_of_year'] = df['InvoiceDate'].dt.dayofyear\n    df['day_of_year'] = df['InvoiceDate'].dt.dayofyear\n    df['day_of_week'] = df['InvoiceDate'].dt.dayofweek\n    df['ordinals'] = train['InvoiceDate'].apply(lambda x:x.toordinal()\/70000)","c136594d":"train.head()","bd67a0b8":"from sklearn.preprocessing import KBinsDiscretizer\nest = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\nest.fit(train['UnitPrice'].values.reshape(-1,1))\ntrain['formed'] = est.transform(train['UnitPrice'].values.reshape(-1,1)).astype(int)","8d58cde7":"from sklearn.preprocessing import KBinsDiscretizer\nest = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\nest.fit(train['Quantity'].values.reshape(-1,1))\ntrain['Quantity_quantiles'] = est.transform(train['Quantity'].values.reshape(-1,1)).astype(int)\ntest['Quantity_quantiles'] = est.transform(test['Quantity'].values.reshape(-1,1)).astype(int)","230a3f0a":"train['log_UnitPrice'] = np.log1p(train['UnitPrice'])","705e6c37":"train['CustomerID'] = train['CustomerID'].astype('int')\ntest['CustomerID'] = test['CustomerID'].astype('int')","c48f6a32":"train['InvoiceDate'].head()","3ecfb603":"## Modelling part","298894b3":"X = train.drop(['InvoiceNo', 'InvoiceDate','UnitPrice', 'StockCode_freq', 'log_UnitPrice', 'formed', 'year','minutes','hour', 'Quantity',\n               'Quantity_quantiles', 'Country_encode', 'StockCode_freq'], axis=1).values\ny = train['UnitPrice'].values\nstrat_y = train['formed']\nX_test = test.drop(['InvoiceNo', 'InvoiceDate', 'year','minutes','hour', 'Quantity',\n               'Quantity_quantiles',  'Country_encode','StockCode_freq'], axis=1).values","8567a7e4":"train.drop(['InvoiceNo', 'UnitPrice', 'InvoiceDate', 'log_UnitPrice', 'formed', 'year','minutes','hour','Quantity',\n               'Quantity_quantiles', 'Country_encode','StockCode_freq'], axis=1).columns","c177e520":"from sklearn.linear_model import Lasso, LinearRegression,Ridge\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import SVR","f7afc409":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt","d31ec112":"from sklearn.model_selection import StratifiedKFold,KFold","eaf046c7":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import ExtraTreeRegressor\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn import linear_model\nfrom catboost import CatBoostRegressor","46361140":"predictions = np.zeros(test.shape[0])\noobs = np.zeros(train.shape[0])\ny = train['UnitPrice'].values\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\nkf=KFold(n_splits=10, shuffle=True, random_state=42)\nparams = {'n_estimators':100000, 'n_jobs':-1, 'random_state':42}\nmodel = lgb.LGBMRegressor(**params)\n\nfor i, (train_id, valid_id) in enumerate(kf.split(X,y)):\n    print(\"fold \", i)  \n    X_train, y_train = X[train_id], y[train_id]\n    X_valid, y_valid = X[valid_id], y[valid_id]\n# # lambda y_true, y_pred:[rmse(y_true,y_pred)]\n    model.fit(X_train, y_train, eval_set =[(X_valid, y_valid)],  early_stopping_rounds=200, verbose=1000, eval_metric='rmse')\n\n    oobs[valid_id] = model.predict(X_valid)\n    predictions += model.predict(X_test)\nrmse = sqrt(mean_squared_error(y,oobs))\nfinals = predictions\/10\nfinals[finals<0] = 0\nlgb_predictions = finals\nsample_submission['UnitPrice'] = finals\nsample_submission.to_csv('lgb_final.csv', index=False)\nprint(\"RMSE\", rmse)\nlgb_oobs = oobs\nprint(\"best oob catboost\")\npd.DataFrame(data=oobs).to_csv('oob_lgb.csv')","80de1975":"predictions = np.zeros(test.shape[0])\noobs = np.zeros(train.shape[0])\ny = train['UnitPrice'].values\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\nkf=KFold(n_splits=10, shuffle=True, random_state=42)\nparams = {'n_estimators':50000, 'learning_rate': 0.1, 'eval_metric':'RMSE', 'loss_function':'RMSE', 'task_type':'GPU', 'devices':'0:1', 'random_state':42}\nmodel = CatBoostRegressor(**params)\n\nfor i, (train_id, valid_id) in enumerate(kf.split(X,y)):\n    print(\"fold \", i)\n\n    X_train, y_train = X[train_id], y[train_id]\n    X_valid, y_valid = X[valid_id], y[valid_id]\n\n    model.fit(X_train, y_train, eval_set =[(X_valid, y_valid)],  early_stopping_rounds=200, verbose=1000)\n\n    oobs[valid_id] = model.predict(X_valid)\n    predictions += model.predict(X_test)\n\nrmse = sqrt(mean_squared_error(y, oobs))\nfinals = predictions\/10\nfinals[finals<0] = 0\ncatboost_predictions = finals\nsample_submission['UnitPrice'] = finals\nsample_submission.to_csv('catboost_final.csv', index=False)\nprint(rmse)","6d9f4a25":"catboost_oobs = oobs\nprint(\"best oob catboost\")\npd.DataFrame(data=oobs).to_csv('oob_catboost.csv')","afd238ce":"CV = (lgb_predictions*0.7)+(catboost_predictions*0.3)","f428c815":"sample_submission['UnitPrice'] = CV\nsample_submission.to_csv('combined_2_weights_CV_2.csv', index=False)","90600c83":"params = {'n_estimators':10000, 'n_jobs':-1, 'random_state':42}\nmodel = lgb.LGBMRegressor(**params)\nmodel.fit(X,y)\npredictions_lgb = model.predict(X_test)","18d813c7":"sample_submission['UnitPrice'] = predictions_lgb\nsample_submission.to_csv('LGB_PLB.csv', index=False)\nsample_submission['UnitPrice'] = (predictions_lgb*0.3)+(lgb_predictions*0.7)\nsample_submission.to_csv('LGB_PLB_CV.csv', index=False)","e7360503":"params = {'n_estimators':10000, 'learning_rate': 0.1, 'eval_metric':'RMSE', 'loss_function':'RMSE', 'task_type':'GPU', 'devices':'0:1', 'random_state':42}\nmodel = CatBoostRegressor(**params)\nmodel.fit(X,y,verbose=1000)\npredictions_catboost = model.predict(X_test)","0887f854":"PLB = (predictions_lgb*0.7)+(predictions_catboost*0.3)","0cef1c3f":"sample_submission['UnitPrice'] = (CV*0.7) + (PLB*0.3)\nsample_submission.to_csv('combined_2_PLB_and_CV.csv', index=False)","a571c767":"train.sort_values(['StockCode', 'UnitPrice', 'InvoiceDate'])[['StockCode', 'UnitPrice', 'InvoiceDate']]","0bb1f7e9":"train = train.sort_values(['StockCode', 'UnitPrice', 'InvoiceDate'])\nanalysis = train.groupby(['StockCode', 'UnitPrice']).count().reset_index()\nana = analysis.loc[~analysis.StockCode.isin(analysis[analysis.duplicated(['StockCode'])].StockCode.unique().tolist()),['StockCode', 'UnitPrice']]\nana['StockCode'] = ana['StockCode'].astype('str')\nana.set_index('StockCode', inplace=True)","ca5b7a5f":"## Training model on all the training set at once for xgb and catboost","69c21442":"## get min max std deviation of the dataset \/check quantiles","c4131377":"### CatBoost","8419e522":"## Feature Engeneering","5e736af3":"# only LGB gave public lb of 23.37 and private lb 28.33564 (Machine Hack Considered this as final since it was best public lb)\n# catboost and lgb gave public lb of 23.84114 around 28.09341","f892c469":"### After analysis, I found that this weights are best for submission","efbc97fd":"### Features selected for training","ce104782":"## No Of Records in the dataset","b146596f":"- Invoice No - Invoice ID, encoded as Label\n- StockCode - Unique code per stock, encoded as Label\n- Description - The Description, encoded as Label\n- Quantity - Quantity purchased\n- InvoiceDate - Date of purchase\n- UnitPrice - The target value, price of every product\n- CustomerID - Unique Identifier for every Customer\n- Country - Country of sales, encoded as Label","e2373ef1":"## Description of Dataset","ea32de70":"### LGBM","a881e9af":"## some of stockcode had UnitPrice repating so used those value for mapping"}}