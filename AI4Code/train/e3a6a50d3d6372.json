{"cell_type":{"32f2927e":"code","0aba7d39":"code","4ffd4e1f":"code","361bce38":"code","bae57f6e":"code","f4d5e12f":"code","18735ac1":"code","6fba65a1":"code","63d3d991":"code","7bc347c7":"code","b6a1b2bf":"code","41e93c7b":"code","62190140":"code","c37ca5d4":"code","0e148390":"code","b7448b96":"code","4489a73b":"code","98fa7286":"markdown","6aaea866":"markdown","2f9308b3":"markdown","1fb08783":"markdown","f265d39d":"markdown","50a52329":"markdown","b219eec3":"markdown","06ea7012":"markdown","6958acd1":"markdown","9f7abb2d":"markdown","19e907cd":"markdown","4939e851":"markdown","e5d3c654":"markdown","ad676003":"markdown","1e479d8f":"markdown","84240864":"markdown"},"source":{"32f2927e":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n%matplotlib inline\n\nimport keras\nfrom keras.models import Sequential,Model\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D, MaxPool2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense, Input,SeparableConv2D\nfrom keras.layers import Dropout, BatchNormalization, ZeroPadding2D\nfrom keras.models import load_model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_curve,auc\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom keras.utils import to_categorical\nfrom glob import glob","0aba7d39":"# Importando os dados\ntrain =  '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train'\ntest  =  '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test'\nval   =  '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val'","4ffd4e1f":"imgNormal = glob(train+\"\/NORMAL\/*.jpeg\")\nimgNormal = np.asarray(plt.imread(imgNormal[1]))\nimgPneumonia = glob(train+\"\/PNEUMONIA\/*.jpeg\")\nimgPneumonia = np.asarray(plt.imread(imgPneumonia[5]))\n\nf = plt.figure(figsize= (10,6))\na1 = f.add_subplot(1,2,1)\nimg_plot = plt.imshow(imgNormal)\na1.set_title('Normal')\n\na2 = f.add_subplot(1, 2, 2)\nimg_plot = plt.imshow(imgPneumonia)\na2.set_title('Pneumonia')","361bce38":"#O batch_size define a quantidade de imagens que ser\u00e3o lidas por vez.\n\nbatch_size = 16\n\n#Aqui definimos as transforma\u00e7\u00f5es que ser\u00e3o aplicadas nas imagens.\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   width_shift_range=0.10,\n                                   height_shift_range=0.10,\n                                   rotation_range=20,\n                                   zoom_range = 0.1,\n                                   horizontal_flip = True,\n                                   vertical_flip=False,\n                                   fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255) \n\n\ntraining_set = train_datagen.flow_from_directory(train,\n                                                 target_size = (128, 128),                                                 \n                                                 color_mode='rgb',\n                                                 batch_size = batch_size,\n                                                 class_mode = 'binary')\n\nvalidation_generator = test_datagen.flow_from_directory(val,\n                                                        target_size=(128, 128),\n                                                        batch_size=batch_size,\n                                                        color_mode='rgb',\n                                                        shuffle=False,\n                                                        class_mode='binary')\n\ntest_set = test_datagen.flow_from_directory(test,\n                                            target_size = (128, 128),\n                                            color_mode='rgb',\n                                            shuffle=False,                                            \n                                            batch_size = batch_size,\n                                            class_mode = 'binary')\n\n","bae57f6e":"def construcao_modelo(shape=(128,128,3)):\n\n    modelo = Sequential()\n\n    #Primeira camanda\n    modelo.add(Conv2D(32, (4, 4), activation=\"relu\", input_shape=shape))\n\n    #Definindo o MaxPooling\n    modelo.add(MaxPooling2D(pool_size = (4, 4)))\n    \n    #Camada para tratar o overfitting,nesse caso em cada epochs zeraremos 30% dos neur\u00f4nios\n    modelo.add(Dropout(0.3))\n    \n    #Segunda camada\n    modelo.add(Conv2D(32, (4, 4), activation=\"relu\"))\n    modelo.add(MaxPooling2D(pool_size = (2, 2)))\n    \n    #Tradando overfitting na segunda camada\n    modelo.add(Dropout(0.3))\n    \n    # Da um reshape no output transformando em array\n    modelo.add(Flatten())\n\n    # Camada Dense\n    modelo.add(Dense(128, activation = 'relu'))\n    \n    #Camada para tratar o overfitting\n    modelo.add(Dropout(0.5))\n    \n    #Camada de saida\n    modelo.add(Dense(1, activation = 'sigmoid'))\n    \n    return modelo","f4d5e12f":"#resultado da arquitetura do modelo\nmodelo = construcao_modelo()\nmodelo.summary()","18735ac1":"modelo.compile(optimizer = 'adam',\n               loss = 'binary_crossentropy',\n               metrics = ['accuracy'])","6fba65a1":"filepath = 'melhor_modelo.hdf5'\n\ncheckpoint = ModelCheckpoint(filepath=filepath, \n                            monitor='val_loss', \n                            verbose=1, mode='min', \n                            save_best_only=True)\n\nearly_stop = EarlyStopping(monitor='val_loss',\n                            min_delta=0.001,\n                            patience=5,\n                            mode='min',\n                            verbose=1)\n\nlr_reduce = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.3,\n                              patience=2,\n                              verbose=2,\n                              mode='auto')\n","63d3d991":"r = modelo.fit_generator(training_set,\n                         epochs = 50,\n                         validation_data = validation_generator,\n                         callbacks=[checkpoint, early_stop,lr_reduce]\n                        )\n","7bc347c7":"#carregando o melhor modelo\nmelhorModelo = load_model('melhor_modelo.hdf5')","b6a1b2bf":"# Acur\u00e1cia e loss do modelo\nloss, acuracia = melhorModelo.evaluate_generator(test_set)\nprint(\"Loss: %.4f\" % (loss))\nprint(\"Acur\u00e1cia: %.2f%%\" % (acuracia*100))","41e93c7b":"fontsize = 15\nplt.style.use(\"_classic_test_patch\")\nplt.figure(figsize=(12,8))\nplt.plot(r.history[\"loss\"], label=\"train_loss\")\nplt.plot( r.history[\"val_loss\"], label=\"val_loss\")\nplt.plot( r.history[\"accuracy\"], label=\"train_acc\")\nplt.plot( r.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Compara\u00e7\u00e3o do desempenho do modelo em train e valida\u00e7\u00e3o \\n\",fontsize=fontsize)\nplt.xlabel(\"Epoch\",fontsize=fontsize)\nplt.ylabel(\"Loss \/ Acur\u00e1cia\",fontsize=fontsize)\nplt.legend(loc=\"best\")","62190140":"pred = modelo.predict_generator(test_set)\npred = pred > 0.5\ncm  = confusion_matrix(test_set.classes,pred)\n\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\nplt.title(\"Matriz de Confus\u00e3o - Teste\",fontsize=fontsize)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=fontsize)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=fontsize)\nplt.show()","c37ca5d4":"predValidacao = melhorModelo.predict_generator(validation_generator)\npredValidacao = predValidacao > 0.5\ncm  = confusion_matrix(validation_generator.classes,predValidacao)\n\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\nplt.title(\"Matriz de Confus\u00e3o - Valida\u00e7\u00e3o\",fontsize=fontsize)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=fontsize)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=fontsize)\nplt.show()","0e148390":"fpr, tpr, threshold = roc_curve(test_set.classes, pred)\nroc_auc = auc(fpr, tpr)\nX = [[0,1],[0,1]]\n\nplt.figure(figsize=(12,8))\nplt.title('Curva ROC',fontsize=fontsize)\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot(X[0],X[1],'r--')\nplt.xlim(X[0])\nplt.ylim(X[0])\nplt.ylabel('Verdadeiros Positivos',fontsize=fontsize)\nplt.xlabel('Falsos Positivos',fontsize=fontsize)\nplt.show()","b7448b96":"fpr, tpr, threshold = roc_curve(validation_generator.classes, predValidacao)\nroc_auc = auc(fpr, tpr)\nplt.figure(figsize=(12,8))\nX = [[0,1],[0,1]]\nplt.title('Curva ROC - Valida\u00e7\u00e3o',fontsize=fontsize)\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot(X[0],X[1],'r--')\nplt.xlim(X[0])\nplt.ylim(X[0])\nplt.ylabel('Verdadeiros Positivos',fontsize=fontsize)\nplt.xlabel('Falsos Positivos',fontsize=fontsize)\nplt.show()","4489a73b":"print(classification_report(test_set.classes,pred))","98fa7286":"# 4.2 Treinando o modelo","6aaea866":"# <center>Detec\u00e7\u00e3o de pneumonia usando Deep Learning<\/center>","2f9308b3":"Como podemos ver, apesar de termos colocado como m\u00e1ximo 50 \u00e9pocas, o modelo parou na d\u00e9cima quarta \u00e9poca devido ao **early_stop**. Conseguimos ver tamb\u00e9m que ele parou de aprender na \u00e9poca 14, onde atingiu 0.7500 de acur\u00e1cia na valida\u00e7\u00e3o.","1fb08783":"As imagens acima est\u00e3o sendo geradas a partir do conjunto de dados de train. Existem pequenas diferen\u00e7as nas imagens, mas vamos ver se podemos criar uma Rede Neural Convolucional que possa classificar essas diferen\u00e7as.","f265d39d":"# Importando as bibliotecas","50a52329":"# 5. Avalia\u00e7\u00e3o","b219eec3":"# 1.1 Visualiza\u00e7\u00e3o dos dados","06ea7012":"# Objetivo\n\n\u00a0Implementa\u00e7\u00e3o de um algoritmo de classifica\u00e7\u00e3o de imagens convolucionais - CNN, com o prop\u00f3sito de classificar paciente com e sem pneumonia.\n","6958acd1":"# 3. Compilando o modelo\n\nAntes de treinar o nosso modelo precisamos definir como a rede ir\u00e1 aprender, nesse caso iremos utilizar o otimizador adam e a loss para classifica\u00e7\u00e3o bin\u00e1rio e como metrica uma acur\u00e1cia simples ","9f7abb2d":"# 2. Constru\u00e7\u00e3o da arquitetura do Modelo","19e907cd":"Para o treinamento do modelo usaremos alguns callbacks:\n* ModelCheckPoint: Para salvar o modelo que tiver o menor loss durante o treinamento\n* EarlyStop: Para interromper o treinamento caso a rede pare de aprender\n* ReduceLROnPlateau: Reduz a taxa de aprendizado quando uma m\u00e9trica parar de melhorar.","4939e851":"A curva de roc mede a capacidade do modelo distinguir as classes. No nosso caso, quanto maior for o AUC melhor est\u00e1 o modelo para distinguir entre paciente com Pneumonia e sem Pneumonia. Para um modelo ideal o AUC \u00e9 proximo de 1.","e5d3c654":"# 1. Input dos Dados\nOs dados est\u00e3o dividido em tr\u00eas pasta:\n1. train - Imagens para treinamento do modelo\n\n2. test  - Imagens para testar o modelo\n\n3. val   - Imagens para validar o modelo\n","ad676003":"# 4.1 Definido os callbacks para o treinamendo do modelo.","1e479d8f":"# Integrantes\n* Adriana Maria Santos Viana\n* L\u00eddia Mara Aguiar Bezerra de Melo \n* Robson Batista da Silva\n* Viviane de Almeida Silvestre\n","84240864":"# 4. Treinando do modelo"}}