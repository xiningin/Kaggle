{"cell_type":{"973b1924":"code","08d2b27a":"code","309e9911":"code","c192aa84":"code","f57fa3ad":"code","ce88d96e":"code","ddb11ab2":"code","5f1a3c4a":"code","77bc3ae3":"code","176b3c06":"code","842b72dd":"code","3109db79":"code","b8a5853e":"code","2a7a60e2":"code","c346e7d7":"code","1291b613":"code","93354dd7":"code","d455a89c":"code","24afa4a9":"code","334f18e7":"code","e616ba6e":"code","951c5b34":"code","11e19d7e":"code","2395849d":"code","eab96409":"code","9fceaa84":"code","59cd9457":"code","738e3150":"code","4966c1bf":"code","e66ee0c1":"code","b9c1b6be":"code","dcc7d7a9":"code","4ab0743c":"code","6ed2e9f2":"code","1de637d9":"code","ad13750a":"code","4e4173b0":"code","9e382856":"code","d7be8d36":"code","d8f8d159":"code","8b2c55b8":"code","13f594d1":"code","5ebb5e11":"code","e8172452":"code","72d87534":"code","8643bfe4":"code","ed1e55e4":"code","e384d3f3":"code","625d26cd":"code","e4fe11e9":"code","957eca74":"code","ccba8f7f":"code","62f0ceeb":"code","9548d266":"code","517b25dd":"code","7f37c5cc":"code","671e95bf":"code","d4ae25df":"code","567477c4":"code","9ecc6a7e":"code","0b723e07":"code","cdba8ce0":"code","63772caa":"code","5c5b3978":"code","f4dd1eec":"code","004fd78c":"code","41df7f0c":"code","bfa340a9":"code","8c857785":"code","f09d4eb2":"code","c8e214ae":"code","d9eb3851":"code","8879e4b8":"code","4d6f9ab5":"code","d3ed90a2":"code","9b7aa4cd":"code","d5dbf40d":"code","2236a4ef":"code","ae50d5ce":"code","c22206b1":"code","d2d6abcb":"code","d1650779":"code","e14aa66c":"code","956c88fa":"code","d46969e7":"code","e0e0ac85":"code","d5518c4a":"code","b96b1569":"code","a863be89":"code","7fc85370":"code","4e1ee145":"code","13dd5aa3":"code","8a1e98ba":"code","cf5ac796":"code","e83d9233":"code","4c239657":"code","92d9bd96":"code","f28686bd":"code","874aea13":"code","30d0ad88":"code","9f72433c":"code","ea774863":"code","573f22cf":"code","b27a46aa":"code","90e948a3":"code","742fee33":"code","b123ecf0":"markdown","02d15265":"markdown","71505edc":"markdown","31a3eac9":"markdown","bd3f6725":"markdown","6273b17c":"markdown","2bbf550a":"markdown","1424fa4b":"markdown","3560f610":"markdown","105934a8":"markdown","1842d1ed":"markdown","88ed1c48":"markdown","148e7051":"markdown","42a33b8a":"markdown","66ed00a2":"markdown","f063917f":"markdown","802facb5":"markdown","33d0e2ed":"markdown","884d8e97":"markdown","f94a528e":"markdown","fae56a4a":"markdown","d04f65d1":"markdown","553458ec":"markdown","3f746242":"markdown","28ad7478":"markdown","56b45a0e":"markdown","4f21ef23":"markdown","5a0ee2fd":"markdown","4af5c8d9":"markdown","84146bb5":"markdown","7085a918":"markdown","4d54976b":"markdown","2b241d06":"markdown","b5fb231b":"markdown","fe396c50":"markdown","f3c17366":"markdown","ace34c6f":"markdown","c68e9718":"markdown","7261d224":"markdown","e9885e13":"markdown","9131de83":"markdown"},"source":{"973b1924":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","08d2b27a":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","309e9911":"# copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","c192aa84":"train.head()","f57fa3ad":"test.head()","ce88d96e":"train.info()","ddb11ab2":"train.describe().T","5f1a3c4a":"train['Pclass'].value_counts()","77bc3ae3":"train['Sex'].value_counts()","176b3c06":"train['SibSp'].value_counts()","842b72dd":"train['Parch'].value_counts()","3109db79":"train['Ticket'].value_counts()","b8a5853e":"train['Cabin'].value_counts()","2a7a60e2":"train['Embarked'].value_counts()","c346e7d7":"sns.barplot(x = 'Pclass', y = 'Survived', data = train);","1291b613":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","93354dd7":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","d455a89c":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","24afa4a9":"train.head()","334f18e7":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","e616ba6e":"train.describe().T","951c5b34":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","11e19d7e":"Q1 = train['Fare'].quantile(0.25)\nQ3 = train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","2395849d":"# observations with Fare data higher than the upper limit:\n\ntrain['Fare'] > (upper_limit)","eab96409":"train.sort_values(\"Fare\", ascending=False).head()","9fceaa84":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \ntrain['Fare'] = train['Fare'].replace(512.3292, 300)","59cd9457":"train.sort_values(\"Fare\", ascending=False).head()","738e3150":"test.sort_values(\"Fare\", ascending=False)","4966c1bf":"test['Fare'] = test['Fare'].replace(512.3292, 300)","e66ee0c1":"test.sort_values(\"Fare\", ascending=False)","b9c1b6be":"train.isnull().sum()","dcc7d7a9":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","4ab0743c":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","6ed2e9f2":"train.isnull().sum()","1de637d9":"test.isnull().sum()","ad13750a":"train.isnull().sum()","4e4173b0":"test.isnull().sum()","9e382856":"train[\"Embarked\"].value_counts()","d7be8d36":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","d8f8d159":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","8b2c55b8":"train.isnull().sum()","13f594d1":"test.isnull().sum()","5ebb5e11":"test[test[\"Fare\"].isnull()]","e8172452":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","72d87534":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","8643bfe4":"test[\"Fare\"].isnull().sum()","ed1e55e4":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ntrain[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\ntrain.head()","e384d3f3":"train.isnull().sum()","625d26cd":"test.isnull().sum()","e4fe11e9":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","957eca74":"train.head()","ccba8f7f":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","62f0ceeb":"train.head()","9548d266":"train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","517b25dd":"train.head()","7f37c5cc":"train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')","671e95bf":"test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","d4ae25df":"train.head()","567477c4":"test.head()","9ecc6a7e":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","0b723e07":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","cdba8ce0":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","63772caa":"train.isnull().sum()","5c5b3978":"test['Title'] = test['Title'].map(title_mapping)","f4dd1eec":"test.head()","004fd78c":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","41df7f0c":"train.head()","bfa340a9":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)","8c857785":"# Map each Age value to a numerical value:\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)","f09d4eb2":"train.head()","c8e214ae":"#dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","d9eb3851":"train.head()","8879e4b8":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])","4d6f9ab5":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","d3ed90a2":"train.head()","9b7aa4cd":"train.head()","d5dbf40d":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","2236a4ef":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","ae50d5ce":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","c22206b1":"train.head()","d2d6abcb":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","d1650779":"test.head()","e14aa66c":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")","956c88fa":"train.head()","d46969e7":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")","e0e0ac85":"test.head()","d5518c4a":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")","b96b1569":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","a863be89":"train.head()","7fc85370":"test.head()","4e1ee145":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","13dd5aa3":"x_train.shape","8a1e98ba":"x_test.shape","cf5ac796":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","e83d9233":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","4c239657":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","92d9bd96":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","f28686bd":"xgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","874aea13":"xgb_cv_model.fit(x_train, y_train)","30d0ad88":"xgb_cv_model.best_params_","9f72433c":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","ea774863":"xgb_tuned =  xgb.fit(x_train,y_train)","573f22cf":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","b27a46aa":"test","90e948a3":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = xgb_tuned.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","742fee33":"output.head()","b123ecf0":"## Missing Value Treatment","02d15265":"### Age","71505edc":"### Basic summary statistics about the numerical data","31a3eac9":"### Cabin","bd3f6725":"### Visualization","6273b17c":"#### Parch vs survived:","2bbf550a":"## Importing Librarires","1424fa4b":"### Embarked & Title","3560f610":"### Classes of some categorical variables","105934a8":"## Variable Transformation","1842d1ed":"## Loading Data","88ed1c48":"**Variables and Their Types:**\n\nSurvival: Survival -> 0 = No, 1 = Yes\n\nPclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n\nSex: Sex\n\nAge: Age in years\n\nSibSp: # of siblings \/ spouses aboard the Titanic\n\nParch: # of parents \/ children aboard the Titanic\n\nTicket: Ticket number\n\nFare: Passenger fare\n\nCabin: Cabin number\n\nEmbarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton","148e7051":"## Deleting Unnecessary Variables","42a33b8a":"### Name - Title","66ed00a2":"# Business Understanding \/ Problem Definition","f063917f":"### Family Size","802facb5":"#### SibSp vs survived:","33d0e2ed":"#### Pclass vs survived:","884d8e97":"## Analysis and Visualization of Numeric and Categorical Variables","f94a528e":"### Sex","fae56a4a":"# Data Understanding (Exploratory Data Analysis)","d04f65d1":"#### Sex vs survived:","553458ec":"## Spliting the train data","3f746242":"## Logistic Regression","28ad7478":"### Embarked","56b45a0e":"### Fare","4f21ef23":"**Variable Notes:**\n\nPclass: A proxy for socio-economic status (SES)\n- 1st = Upper\n- 2nd = Middle\n- 3rd = Lower\n\nAge: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nSibSp: The dataset defines family relations in this way...\n- Sibling = brother, sister, stepbrother, stepsister\n- Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nParch: The dataset defines family relations in this way...\n- Parent = mother, father\n- Child = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","5a0ee2fd":"## Random Forest","4af5c8d9":"# Modeling, Evaluation and Model Tuning","84146bb5":"### Pclass","7085a918":"## Gradient Boosting Classifier","4d54976b":"## Outlier Treatment","2b241d06":"# Data Preparation","b5fb231b":"### Fare","fe396c50":"# Deployment","f3c17366":"## Feature Engineering","ace34c6f":"### Embarked","c68e9718":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","7261d224":"### Ticket","e9885e13":"**Titanic Survival Prediction:**\n\nUse machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","9131de83":"### AgeGroup"}}