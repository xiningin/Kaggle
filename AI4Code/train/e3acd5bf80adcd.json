{"cell_type":{"b92e14fd":"code","c6da4365":"code","8b6849fc":"code","a4afebab":"code","068ac677":"code","69c469ea":"code","4ec662c0":"code","4cbf65e5":"code","54c9bb31":"code","43cefa50":"code","16e48717":"code","4d021698":"code","0c7e030a":"code","7eb3a060":"code","833f5bf1":"code","76d5dfbe":"code","eebafaa8":"code","805d1d69":"code","6eeac34b":"code","3ec14995":"code","0919c651":"code","29f318c0":"code","12f5cad1":"code","a2472f78":"code","8f210fb1":"code","24f500a9":"code","1d6d38c2":"code","b13cfbd3":"code","7b28a5ea":"code","ad7a403a":"code","b402b0b0":"code","05d83ebb":"code","4fe0bd16":"code","b1880815":"code","75b23b21":"code","09f2ceb7":"code","d7e817d5":"code","d7dc7211":"code","fce83a22":"code","c159d067":"code","d31f1b2f":"code","20d2c750":"code","3905d833":"code","8d846576":"code","5132cf95":"code","fd354571":"markdown","8369f346":"markdown"},"source":{"b92e14fd":"import numpy as np\nimport pandas as pd\nimport pydicom\nimport os\nimport random\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold","c6da4365":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M","8b6849fc":"def seed_everything(seed=2020):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    return seed","a4afebab":"ROOT = \"..\/input\/osic-pulmonary-fibrosis-progression\"\n\ntr = pd.read_csv(f\"{ROOT}\/train.csv\")\ntr.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\nchunk = pd.read_csv(f\"{ROOT}\/test.csv\")\n\nprint(\"add infos\")\nsub = pd.read_csv(f\"{ROOT}\/sample_submission.csv\")\nsub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\nsub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\nsub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\nsub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")","068ac677":"tr['WHERE'] = 'train'\nchunk['WHERE'] = 'val'\nsub['WHERE'] = 'test'\ndata = tr.append([chunk, sub])","69c469ea":"print(tr.shape, chunk.shape, sub.shape, data.shape)\nprint(tr.Patient.nunique(), chunk.Patient.nunique(), sub.Patient.nunique(), \n      data.Patient.nunique())\n#","4ec662c0":"data['min_week'] = data['Weeks']\ndata.loc[data.WHERE=='test','min_week'] = np.nan\ndata['min_week'] = data.groupby('Patient')['min_week'].transform('min')","4cbf65e5":"base = data.loc[data.Weeks == data.min_week]\nbase = base[['Patient','FVC']].copy()\nbase.columns = ['Patient','min_FVC']\nbase['nb'] = 1\nbase['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\nbase = base[base.nb==1]\nbase.drop('nb', axis=1, inplace=True)","54c9bb31":"data = data.merge(base, on='Patient', how='left')\ndata['base_week'] = data['Weeks'] - data['min_week']\ndel base","43cefa50":"COLS = ['Sex','SmokingStatus']\nFE = []\nfor col in COLS:\n    for mod in data[col].unique():\n        FE.append(mod)\n        data[mod] = (data[col] == mod).astype(int)\n#=================","16e48717":"\ndata['age'] = (data['Age'] - data['Age'].min() ) \/ ( data['Age'].max() - data['Age'].min() )\ndata['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) \/ ( data['min_FVC'].max() - data['min_FVC'].min() )\ndata['week'] = (data['base_week'] - data['base_week'].min() ) \/ ( data['base_week'].max() - data['base_week'].min() )\ndata['percent'] = (data['Percent'] - data['Percent'].min() ) \/ ( data['Percent'].max() - data['Percent'].min() )\nFE += ['age','percent','week','BASE']\n#FE += ['age','percent','BASE']","4d021698":"tr = data.loc[data.WHERE=='train']\nchunk = data.loc[data.WHERE=='val']\nsub = data.loc[data.WHERE=='test']\ndel data","0c7e030a":"SEED = seed_everything(42)\nNFOLD        = 5\nEPOCHS       = 800\nBATCH_SIZE   = 128\n\nM_LOSS       = 0.775\nLR           = 0.1\nDECAY        = 0.01     \n\nkf = KFold(n_splits=NFOLD)","7eb3a060":"C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n#=============================#\ndef score(y_true, y_pred):\n    tf.dtypes.cast(y_true, tf.float32)\n    tf.dtypes.cast(y_pred, tf.float32)\n    sigma = y_pred[:, 2] - y_pred[:, 0]\n    fvc_pred = y_pred[:, 1]\n    \n    #sigma_clip = sigma + C1\n    sigma_clip = tf.maximum(sigma, C1)\n    delta = tf.abs(y_true[:, 0] - fvc_pred)\n    delta = tf.minimum(delta, C2)\n    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n    metric = (delta \/ sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n    return K.mean(metric)\n#============================#\ndef qloss(y_true, y_pred):\n    # Pinball loss for multiple quantiles\n    qs = [0.2, 0.5, 0.8]\n    q = tf.constant(np.array([qs]), dtype=tf.float32)\n    e = y_true - y_pred\n    v = tf.maximum(q*e, (q-1)*e)\n    return K.mean(v)\n#=============================#\ndef mloss(_lambda):\n    def loss(y_true, y_pred):\n        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n    return loss\n#=================\ndef make_model():\n    z = L.Input((9,), name=\"Patient\")\n    x = L.Dense(100, activation=\"relu\", name=\"d1\")(z)\n    x = L.Dense(100, activation=\"relu\", name=\"d2\")(x)\n    #x = L.Dense(100, activation=\"relu\", name=\"d3\")(x)\n    p1 = L.Dense(3, activation=\"linear\", name=\"p1\")(x)\n    p2 = L.Dense(3, activation=\"relu\", name=\"p2\")(x)\n    preds = L.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n                     name=\"preds\")([p1, p2])\n    \n    \n    model = M.Model(z, preds, name=\"CNN\")\n    #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n    model.compile(loss=mloss(0.775), optimizer=tf.keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False), metrics=[score])\n    return model","833f5bf1":"net = make_model()\nprint(net.summary())\nprint(net.count_params())","76d5dfbe":"y = tr['FVC'].values\nz = tr[FE].values\nze = sub[FE].values\npe = np.zeros((ze.shape[0], 3))\npred = np.zeros((z.shape[0], 3))\ndelta = np.zeros((z.shape[0], 3))","eebafaa8":"%%time\ncnt = 0\ntrain = []\nval   = []\n\n\nfor tr_idx, val_idx in kf.split(z):\n    cnt += 1\n    print(f\"FOLD {cnt}\")\n    \n    \n    net = make_model()\n    \n    \n    net.fit(z[tr_idx], y[tr_idx], batch_size=BATCH_SIZE, epochs= EPOCHS, \n            validation_data=(z[val_idx], y[val_idx]), verbose=0) # \n    \n#     train.append(net.evaluate(z[tr_idx], y[tr_idx], batch_size=BATCH_SIZE))\n#     val.append(net.evaluate(z[val_idx], y[val_idx], batch_size=BATCH_SIZE)\n    print(\"train\", net.evaluate(z[tr_idx], y[tr_idx], verbose=0, batch_size=BATCH_SIZE))\n    print(\"val\", net.evaluate(z[val_idx], y[val_idx], verbose=0, batch_size=BATCH_SIZE))\n    #print(\"predict val...\")\n    pred[val_idx] = net.predict(z[val_idx], batch_size=BATCH_SIZE, verbose=0)\n    #print(\"predict test...\")\n    print()\n    pe += net.predict(ze, batch_size=BATCH_SIZE, verbose=0) \/ NFOLD\n    \n    delta += net.predict(z) \/ NFOLD\n    \n    \n#==============\n\n","805d1d69":"sigma_opt = mean_absolute_error(y, pred[:, 1])\nunc = pred[:,2] - pred[:, 0]\nsigma_mean = np.mean(unc)\nprint(sigma_opt, sigma_mean)\n#142.3356196400397 234.99396579009314","6eeac34b":"# Scoring\n\no_clipped = np.maximum(delta[:,2] - delta[:,0], 70)\ndelta = np.minimum(np.abs(delta[:, 1] - y), 1000)\nsqrt = (np.sqrt((2)))\nscore = (-(sqrt * (delta))\/(o_clipped)) - tf.math.log(sqrt * o_clipped)\n\nlogL_Score = np.mean(score)","3ec14995":"print('we are using fix seed value always to avoid RANDOMIZATION (NEED TO GET SAME RESULT)')\nprint('Seed value          =',SEED)\nprint('Number of folds     =',BATCH_SIZE)\nprint('Number of epochs    =',EPOCHS)\n\nprint('\\nmean_absolute_error =',sigma_opt)\n#print('unc_mean            =',unc_mean)\n\nprint('unc_mean            =',unc.mean())\nprint()\nprint('Log_laplace_Scores  =',logL_Score )\nprint()\nprint('unc_min             =',unc.min())\nprint('unc_max             =',unc.max())\nprint('unc_mean            =',(unc>=0).mean())","0919c651":"# # # # # ########### RUN FIRST TIME ONLY ################\n# stats = pd.DataFrame()\n# index = 0","29f318c0":"data = [[index, logL_Score, sigma_opt, unc.mean(), unc.min(),  unc.max(), (unc>=0).mean(),\n         BATCH_SIZE, EPOCHS,  NFOLD, M_LOSS, LR, DECAY ,SEED]]\ncolumns = ['S.No','Score', 'meanAbseErr', 'unc.mean', 'unc.min', 'unc.max',  '(unc>=0)',\n           'Bsize', 'epoch', 'NFOLD', 'M_LOSS', 'LR', 'DECAY', 'seed']\nkernal_stats = pd.DataFrame(data, columns=columns)\n# print(\"current kernal state\")\nkernal_stats","12f5cad1":"stats = pd.concat([stats, kernal_stats])\nstats.to_csv('kernal.csv', index = False)\nindex+=1\n# 154.68119019747556 213.12221373517662 0.0 213.12221373517662 384.3486328125 1.0\n# print('kernal stats of every version')\nstats\n\n#0 -6.490188 142.335620 234.993966 25.237061 485.192871 1.0 128 800 5 0.775 0.100 0.010 42\n#3 -6.488414\t141.404185\t234.008693\t20.999268\t495.660645\t1.0\t128\t850\t5\t0.775\t0.1\t0.01\t42","a2472f78":"plt.hist(unc)\nplt.title(\"uncertainty in prediction\")\n#plt.savefig('plt_unc_pred{}.png'.format(index))\nplt.show()","8f210fb1":"# plt.plot(arr)\n# plt.xlabel('epoch')\n# plt.ylabel('accuracy')\n# plt.title('Accuracy vs. No. of epochs');","24f500a9":"# idxs = np.random.randint(0, y.shape[0], 100)\n# plt.plot(y[idxs], label=\"ground truth\")\n# plt.plot(pred[idxs, 0], label=\"q25\")\n# plt.plot(pred[idxs, 1], label=\"q50\")\n# plt.plot(pred[idxs, 2], label=\"q75\")\n# plt.legend(loc=\"best\")\n# plt.show()","1d6d38c2":"import seaborn as sns\nsns.distplot(unc)\n#plt.(unc)\nplt.title(\"uncertainty in prediction\")\n# plt.savefig('sns_unc_pred{}.png'.format(index))\nplt.show()","b13cfbd3":"#sub.head()","7b28a5ea":"sub['FVC1'] = pe[:, 1]\nsub['Confidence1'] = pe[:, 2] - pe[:, 0]","ad7a403a":"subm = sub[['Patient_Week','FVC','Confidence','FVC1','Confidence1']].copy()","b402b0b0":"subm.loc[~subm.FVC1.isnull()].head(1)","05d83ebb":"subm.loc[~subm.FVC1.isnull(),'FVC'] = subm.loc[~subm.FVC1.isnull(),'FVC1']\nif sigma_mean<70:\n    subm['Confidence'] = sigma_opt\nelse:\n    subm.loc[~subm.FVC1.isnull(),'Confidence'] = subm.loc[~subm.FVC1.isnull(),'Confidence1']","4fe0bd16":"subm.head(1)","b1880815":"plt.hist(subm.FVC)\n# plt.title(\"uncertainty in prediction\")\n# plt.savefig('subm.FVC{}.png'.format(index))\nplt.show()\n\nplt.hist(subm.FVC1)\n# plt.title(\"uncertainty in prediction\")\n# plt.savefig('subm.FVC_1{}.png'.format(index))\nplt.show()","75b23b21":"plt.hist(subm.Confidence)\n# plt.title(\"uncertainty in prediction\")\n# plt.savefig('subm.Confidence{}.png'.format(index))\nplt.show()\n\nplt.hist(subm.Confidence1)\n# plt.title(\"uncertainty in prediction\")\n# plt.savefig('subm.Confidence_1{}.png'.format(index))\nplt.show()","09f2ceb7":"subm.describe().T","d7e817d5":"otest = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/test.csv')\nfor i in range(len(otest)):\n    subm.loc[subm['Patient_Week']==otest.Patient[i]+'_'+str(otest.Weeks[i]), 'FVC'] = otest.FVC[i]\n    subm.loc[subm['Patient_Week']==otest.Patient[i]+'_'+str(otest.Weeks[i]), 'Confidence'] = 0.1","d7dc7211":"subm[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)","fce83a22":"subm","c159d067":"# !pip install jovian --upgrade --quiet","d31f1b2f":"# import jovian","20d2c750":"# jovian.commit(project='osic-new-era')","3905d833":"submm = pd.read_csv('..\/input\/osic36175\/submission_6.175.csv')\nsubmm = submm.values\ncolnames = ['Patient','FVC_175', 'Confidence_175']\nsubmm = pd.DataFrame(submm, columns=colnames)","8d846576":"submm\n","5132cf95":"import seaborn as sns\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(14, 8))\n\nsns.kdeplot(subm['FVC'], ax=ax1)\nsns.kdeplot(subm['Confidence'], ax=ax2)\n\nsns.kdeplot(submm['FVC_175'], ax=ax1)\nsns.kdeplot(submm['Confidence_175'], ax=ax2)","fd354571":"### PREDICTION","8369f346":"### BASELINE NN "}}