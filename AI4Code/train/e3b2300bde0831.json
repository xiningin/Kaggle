{"cell_type":{"d153e7ee":"code","e607824b":"code","245febbb":"code","b9d6965d":"code","dac5b99f":"code","0c3794fa":"code","bb47f845":"code","74580dc3":"code","0ddf198d":"code","94b7b2b8":"code","babc0107":"markdown","41944b7d":"markdown","edfd90fd":"markdown","a4759491":"markdown","d815d507":"markdown","1ff7cce1":"markdown","e20e1126":"markdown","ad300fea":"markdown","d7e0e90b":"markdown","8e29b338":"markdown","0fff6f46":"markdown","3ec417b6":"markdown","777e33b4":"markdown","12d14d00":"markdown","d3589e73":"markdown"},"source":{"d153e7ee":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score","e607824b":"dataset = pd.read_csv('\/kaggle\/input\/housesalesprediction\/kc_house_data.csv')\ndataset.head()","245febbb":"dataset.isnull().sum()\nsns.heatmap(dataset.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')","b9d6965d":"dataset.info()","dac5b99f":"X = dataset.iloc[:, [3,4,5,6,7,8,9,10,11,12,13,17,18,19,20]].values\ny = dataset.iloc[:, 2].values","0c3794fa":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","bb47f845":"regressor = RandomForestRegressor(n_estimators = 30)\nregressor.fit(X_train, y_train)","74580dc3":"y_pred_train = regressor.predict(X_train)\nprint(r2_score(y_train,y_pred_train))","0ddf198d":"y_pred_test = regressor.predict(X_test)","94b7b2b8":"print(r2_score(y_test,y_pred_test))","babc0107":"# Splitting the dataset into the Training set and Test set","41944b7d":"# Calculating r2 Score for model trained on test dataset","edfd90fd":"# Making our dependent and independent features","a4759491":"# Importing the libraries","d815d507":"# Traing the train dataset on Random Forest Regression ","1ff7cce1":"# Importing the dataset","e20e1126":"**Here I had given a 20% of my whole dataset to the test data as we want to feed the maximum of our data to our training set so that our model can predict with a very high accuracy**","ad300fea":"**Oh Wow we achieved a great accuraccy of around 97% and I hope we achieve nearly the same accuracy for the test set**","d7e0e90b":"# Checking Null values in dataset\n**First of all we will check is there any null or nan value in our dataset.For This I will use two methods.\n1. By using inbuilt method of our data ,i.e., isnull() method\n2. By using heatmap function of seaborn library","8e29b338":"# Predicting the Test set results","0fff6f46":"**As we can see here that there is no null value.so there is no need to take care of missing values and we can safely move ahead.**","3ec417b6":"**Now making our dependent and independent features to test our model and predict for future values.In my independent values I have removed id and date as they merely do not affect the prices of house.Also I have decided to remove the yr_built , yr_renovated and zipcode as they will decrease the accurracy for the prediction of our model.I will show it to you later**","777e33b4":"**As there is no categorical data so we need not to take care of categorical or string data**","12d14d00":"**And we have achieved an accuracy of nearly 88% and I think its quit good for me as a beginner.\nPlease Do like and upvote my notebook if you liked it.**","d3589e73":"# Calculating the R^2 for our training set\n**I am calculating the R^2 for my training dataset to see how well my model is adapted to the train dataset to predict housing price. Lets hope good and now waiting....**"}}