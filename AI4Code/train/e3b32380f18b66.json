{"cell_type":{"0505b957":"code","e741f96c":"code","db6b653b":"code","e3cea732":"code","7235438e":"code","186eb5c9":"code","677b6c99":"code","92485473":"code","88f7ffe1":"code","6a4e60c3":"code","b6029a9c":"code","f3564e03":"code","e0cdb257":"code","d24607db":"markdown","1b88b5c5":"markdown","a0557678":"markdown","43f0ae5d":"markdown","36748e36":"markdown","9baecfb4":"markdown","88ab1b61":"markdown","97c06216":"markdown","7aca5eb1":"markdown","5846a755":"markdown","261a0cb5":"markdown","51b79a9a":"markdown"},"source":{"0505b957":"from keras.datasets import mnist\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.preprocessing.image import ImageDataGenerator","e741f96c":"(X_train, Y_train), (X_test, Y_test) = mnist.load_data()","db6b653b":"# Shape of Data in training and testing parts\nprint('Training data x_train shape: ', X_train.shape)\nprint('Test data x_test.shape:', X_test.shape)","e3cea732":"# Shape of Labels in training and testing parts\nprint('Training Labels y_train shape: ', Y_train.shape)\nprint('Testing Labels y_test.shape:', Y_test.shape)","7235438e":"# reshape dataset to have a single channel\nwidth, height, channels = X_train.shape[1], X_train.shape[2], 1\nX_train = X_train.reshape((X_train.shape[0], width, height, channels))\nX_test = X_test.reshape((X_test.shape[0], width, height, channels))\n# one hot encode target values\nY_train = to_categorical(Y_train)\nY_test = to_categorical(Y_test)","186eb5c9":"data_gen_object = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)","677b6c99":"data_gen_object.fit(X_train)","92485473":"train_iterator = data_gen_object.flow(X_train, Y_train, batch_size=64)\ntest_iterator = data_gen_object.flow(X_test, Y_test, batch_size=64)\nprint('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))","88f7ffe1":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n# compile model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","6a4e60c3":"training_history=model.fit(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)","b6029a9c":"_, acc = model.evaluate(test_iterator, steps=len(test_iterator), verbose=0)\nprint('Test Accuracy: %.3f' % (acc * 100))","f3564e03":"'''\n(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n# reshape dataset to have a single channel\nwidth, height, channels = X_train.shape[1], X_train.shape[2], 1\nX_train = X_train.reshape((X_train.shape[0], width, height, channels))\nX_test = X_test.reshape((X_test.shape[0], width, height, channels))\n# one hot encode target values\nY_train = to_categorical(Y_train)\nY_test = to_categorical(Y_test)\n# create generator to center images\ndata_gen_object = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)\n# calculate mean on training dataset\ndata_gen_object.fit(X_train)\n# prepare an iterators to scale images\ntrain_iterator = data_gen_object.flow(X_train, Y_train, batch_size=64)\ntest_iterator = data_gen_object.flow(X_test, Y_test, batch_size=64)\nprint('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n# define model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n# compile model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# fit model with generator\nmodel.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n# evaluate model\n_, acc = model.evaluate(test_iterator, steps=len(test_iterator), verbose=0)\nprint('Test Accuracy: %.3f' % (acc * 100)) '''","e0cdb257":"# load dataset\n(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n# reshape dataset to have a single channel\nwidth, height, channels = X_train.shape[1], X_train.shape[2], 1\nX_train = X_train.reshape((X_train.shape[0], width, height, channels))\nX_test = X_test.reshape((X_test.shape[0], width, height, channels))\n# one hot encode target values\nY_train = to_categorical(Y_train)\nY_test = to_categorical(Y_test)\n# confirm scale of pixels\nprint('Train min=%.3f, max=%.3f' % (X_train.min(), X_train.max()))\nprint('Test min=%.3f, max=%.3f' % (X_test.min(), X_test.max()))\n# create generator (1.0\/255.0 = 0.003921568627451)\ndatagen = ImageDataGenerator(rescale=1.0\/255.0)\n# prepare an iterators to scale images\ntrain_iterator = datagen.flow(X_train, Y_train, batch_size=64)\ntest_iterator = datagen.flow(X_test, Y_test, batch_size=64)\nprint('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n# confirm the scaling works\nbatchX, batchy = train_iterator.next()\nprint('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n# define model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n# compile model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n# fit model with generator\nmodel.fit(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n# evaluate model\n_, acc = model.evaluate(test_iterator, steps=len(test_iterator), verbose=0)\nprint('Test Accuracy: %.3f' % (acc * 100))","d24607db":"# Preprocessing images during training and evaluation in Keras\n\n```\nPixel values of images must be scaled before model training.\nBut in Keras it can be done just in time during Training by using ImageDataGenerater class\n```\n## Main Types of Scaling\n\n\n1.   Pixel Centering : scale pixels to have 0 mean\n2.   Pixel Standerdization : scale pixels to have 0 mean & unit standerdization\n3. ` Normalization of Pixels : scale pixels between 0 & 1 (just divide pixels my 255)\n\n#### Note : \n1. **The 3rd Type i.e \"Normalization\" doesnt need to fit data on Training as we dont need to find any statistics from training data.**\n2. **Also The 1st two methods can be combined together**\n","1b88b5c5":"# **Example 2**\n# In case for only rescaling i.e changeing pixels values between 0 and 1. All steps are same except,now we dont need the **Data Generator** object to fit on Train data.","a0557678":"\n# Five Steps of Scaling pixels\n\n\n1.   Making **Data generator** object using ImageDataGenerator\ne.g **datagen = ImageDataGenerator(featurewise_center=True)**\n\n2.   Use **.fit method** to calculate the scaling statisitcs on Training set (trainX).After this **Data generator** will gain the statistical information (mean and std) from the training model.\ne.g  **datagen.fit(trainX)**\n Note: This fitting is not required in case of simple Normalization\n\n3. Trained **Data generator** object is now used on bacthes of target or labels by creating an **iterator**   e.g\n \n **train_iterator = datagen.flow(trainX, trainY, batch_size=64)** \n Same for testign labels e.g\n\n **test_iterator = datagen.flow(testX, testY, batch_size=64)**\nNote: to use it on entire data set,make batch size=len(training data)\n\n4.  Make a model and compile it\n5.  Fit the model on the training set and at the same time during training, do the Scaling also e.g\n**model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)**\n\n6. Finally evaluate the model on the testing labels and at the same time do the scaling as well e.g \n\n**_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)**","43f0ae5d":"## **Step-5**\nModel Evaluation on Test data using Test Iterator","36748e36":"# **Scaling Example on mnist data**\n## Using only Pixel Centering and Pixel Standerdization","9baecfb4":"In CNN ,the Convolutions operate over 3D tensors, called feature maps, with two spatial axes (height\nand width) as well as a depth axis (also called the channels axis). For an RGB image, the\ndimension of the depth axis is 3, because the image has three color channels: red,\ngreen, and blue. For a black-and-white picture, like the MNIST digits, the **depth is 1**\n(levels of gray).\n **The training data has images of dimension 6000x28x28 where 6000 is number of images and 28x28 are the rows and columns. We need to add depth dimension (and remove the no of images dimension) ","88ab1b61":"## **Step-3**\nModel preparation and compilation","97c06216":"## **Step-4**\nModel fitting on Training data using Training Iterator","7aca5eb1":"## **Step-2**\nUse **.fit method** to calculate the Mean 7and std on Training set (trainX).After this **Data generator** will gain the statistical information (mean and std) from the training model.","5846a755":"## **Step-1**\nMaking **Data generator** object using ImageDataGenerator\ne.g **datagen = ImageDataGenerator(featurewise_center=True,....)**","261a0cb5":"# **Writing All Steps Together**","51b79a9a":"## **All Five Steps of Scaling shown below**"}}