{"cell_type":{"cdaf4d37":"code","a075421d":"code","5ad0eb54":"code","35e98d0e":"code","637d79ad":"code","edfc105c":"code","66f1246a":"code","f26b3963":"code","4bf1f205":"code","9b6208d0":"code","f8913a6a":"code","c2f54068":"code","6677eb9c":"code","86f19f5c":"code","92060b9a":"code","a54e397e":"code","4d2913f9":"code","6140d32a":"code","7ef39b48":"code","fcab6435":"code","6a5d2947":"code","654b2363":"code","329d4d26":"code","6b49edc5":"markdown","bafccc1c":"markdown","de75538b":"markdown","eef44f22":"markdown","d2128669":"markdown","20dde5bb":"markdown","213d8d5c":"markdown"},"source":{"cdaf4d37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pandas as pd\nimport pandas as pd\nimport numpy as np\nimport re \nimport nltk \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\n\n\nfrom io import StringIO\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import chi2\nfrom IPython.display import display\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\n\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.style.use('ggplot')\nimport matplotlib.patches as mpatches","a075421d":"!wget --no-check-certificate 'https:\/\/docs.google.com\/uc?export=download&id=1jPWsijAqzPoC5VDfZBjJBvm2BPJyMVdL' -O Data.zip","5ad0eb54":"import zipfile\n\n#Lokasi file zip\nfile_path = '\/kaggle\/working\/Data.zip'\n\n#Membaca file Zip\nunzip = zipfile.ZipFile(file_path, 'r')\nunzip.extractall('\/content')\nunzip.close()","35e98d0e":"df_train = pd.read_csv(\"\/content\/train.txt\", delimiter=';', header=None, names=['sentence','label'])\ndf_test = pd.read_csv(\"\/content\/test.txt\", delimiter=';', header=None, names=['sentence','label'])\ndf_val = pd.read_csv(\"\/content\/val.txt\", delimiter=';', header=None, names=['sentence','label'])","637d79ad":"#Menyatukan data validasi dengan data latih\nframes = [df_train, df_val]\ndf = pd.concat(frames)\ndf = df.reset_index()\ndf = df.drop(columns = \"index\")","edfc105c":"df","66f1246a":"#Melihat data yang hilang\ndef missing_percentage(df):\n    \"\"\"This function takes a DataFrame(df) as input and returns two columns, total missing values and total missing values percentage\"\"\"\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])\n\nmissing_percentage(df)","f26b3963":"#Melihat Sebaran Label\nimport seaborn as sns\nsns.countplot(x ='label', data = df,order = df[\"label\"].value_counts().index)\n \n# Show the plot\nplt.show()","4bf1f205":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndf['label_enc'] = labelencoder.fit_transform(df['label'])\ndf_test['label_enc'] = labelencoder.transform(df_test['label'])","9b6208d0":"map = df[['label','label_enc']].drop_duplicates(keep='first')\nmap","f8913a6a":"def relabel(a) :\n    if a == 4 :\n        o = \"sadness\"\n    elif a == 0 :\n        o = \"anger\"\n    elif a == 3 :\n        o = \"love\"\n    elif a == 5 :\n        o = \"surprise\"\n    elif a == 1 :\n        o = \"fear\"\n    else :\n        o = \"joy\"\n    return o","c2f54068":"df_test[['label','label_enc']].drop_duplicates(keep='first')","6677eb9c":"# import nltk\n# nltk.download('punkt')\n# from nltk.stem.porter import PorterStemmer\n# from nltk.tokenize.treebank import TreebankWordDetokenizer\n\n# porter_stemmer = PorterStemmer()    \n\n# sentence_stemm_train = []\n# for i in range(df.shape[0]):\n#     word_data = df.sentence[i]\n#     nltk_tokens = nltk.word_tokenize(word_data)\n#     word=[]\n#     for w in nltk_tokens:\n#         word.append(porter_stemmer.stem(w))\n#     sentence = TreebankWordDetokenizer().detokenize(word)\n#     sentence_stemm_train.append(sentence)\n\n# sentence_stemm_test = []\n# for i in range(df_test.shape[0]):\n#     word_data = df_test.sentence[i]\n#     nltk_tokens = nltk.word_tokenize(word_data)\n#     word=[]\n#     for w in nltk_tokens:\n#         word.append(porter_stemmer.stem(w))\n#     sentence = TreebankWordDetokenizer().detokenize(word)\n#     sentence_stemm_test.append(sentence)\n\n# df[\"sentence_stemm\"] = np.array(sentence_stemm_train)\n# df_test[\"sentence_stemm\"] = np.array(sentence_stemm_test)","86f19f5c":"tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, stop_words='english')\n\n# We transform each text into a vector\nfeatures_train = tfidf.fit_transform(df.sentence).toarray()\nfeatures_test = tfidf.transform(df_test.sentence).toarray()\n\nfeatures_train_name = tfidf.get_feature_names()\n\nlabels = df.label_enc\n\nprint(\"Jumlah Feature Setelah di Ekstrak : \"+str(features_train.shape[1]))","92060b9a":"feature_train_df = pd.DataFrame(data=features_train,    # values,    # 1st column as index\n                                columns=features_train_name)  # 1st row as the column names","a54e397e":"feature_train_df","4d2913f9":"from numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n#mencoba beberapa algoritma machine learning\n\n# models = [\n#     RandomForestClassifier,\n#     LinearSVC(),\n#     MultinomialNB(),XGBClassifier()\n# ]\n\nmodels = [LinearSVC()]\n\n# 5 Cross-validation\nCV = 10\ncv_df = pd.DataFrame(index=range(CV * len(models)))\n\nentries = []\nfor model in models:\n    model_name = model.__class__.__name__\n    accuracies = cross_val_score(model, features_train, labels, scoring='f1_macro', cv=CV)\n    for fold_idx, accuracy in enumerate(accuracies):\n        entries.append((model_name, fold_idx, accuracy))\n    \ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'f1_macro'])","6140d32a":"mean_f1 = cv_df.groupby('model_name').f1_macro.mean()\nstd_f1 = cv_df.groupby('model_name').f1_macro.std()\n\nf1 = pd.concat([mean_f1, std_f1], axis= 1, \n          ignore_index=True)\nf1.columns = ['Mean F1_Macro', 'Standard deviation']\nf1","7ef39b48":"model = LinearSVC()\nmodel.fit(features_train, labels)\ny_pred = model.predict(features_test)","fcab6435":"pred_cat = []\nfor i in y_pred:\n  cat = relabel(i)\n  pred_cat.append(cat)\npred_cat = np.array(pred_cat)","6a5d2947":"print(classification_report(df_test.label, pred_cat))","654b2363":"def predict_emotion(text):\n    x = tfidf.transform([text]).toarray()\n    pred = relabel(model.predict(x))\n    return pred","329d4d26":"text = \"i am very happy today\"\npredict_emotion(text)","6b49edc5":"# 1. Import Library","bafccc1c":"# 6. Mencoba untuk Memprediksi Data Testing dan Memprediksi Inputan Text","de75538b":"**Rizky Alif Ramadhan**\n\n**19\/446785\/TK\/49890**","eef44f22":"# 3. Melakukan Label Encoding","d2128669":"# 5. Modelling Menggunakan LinearSVC()","20dde5bb":"# 4. Melakukan Ekstraksi Fitur dengan Tfidf","213d8d5c":"# 2. Data Load and Data Understanding"}}