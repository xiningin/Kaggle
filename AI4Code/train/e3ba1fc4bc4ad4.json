{"cell_type":{"d94ca708":"code","468fe953":"code","7598bbf3":"code","246576de":"code","a717789d":"code","835dadef":"code","2b4a2908":"code","6bf9adfa":"code","d0589b72":"code","5efc8627":"code","b1499eaa":"code","eb03ca20":"code","2bca6355":"code","259f1543":"code","06ad28c8":"code","bd2dd156":"code","a9ce121a":"code","c8a426c7":"code","3c371be3":"code","51f3f96c":"markdown","06186bc9":"markdown","e11c02d9":"markdown","f52287ae":"markdown","3ec7f53f":"markdown","53ba6c53":"markdown","b15c7908":"markdown","6f9e5ca2":"markdown","f0dc237e":"markdown","01ddea13":"markdown","89c9659f":"markdown"},"source":{"d94ca708":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom IPython.display import clear_output\nfrom time import sleep\nimport os\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","468fe953":"!unzip -u ..\/input\/facial-keypoints-detection\/test.zip\n!unzip -u ..\/input\/facial-keypoints-detection\/training.zip","7598bbf3":"train_file = 'training.csv'\ntest_file = 'test.csv'\nlookup_file = '..\/input\/facial-keypoints-detection\/IdLookupTable.csv'\ntrain = pd.read_csv(train_file)\ntest = pd.read_csv(test_file)\nlookup = pd.read_csv(lookup_file)","246576de":"train.head()","a717789d":"lookup.head().T","835dadef":"train.isnull().any().value_counts()","2b4a2908":"train.fillna(method = 'ffill',inplace = True)\ntrain.isnull().any().value_counts()\ntrain.shape","6bf9adfa":"imag = []\nfor i in range(0,7049):\n    img = train['Image'][i].split(' ')\n    img = ['0' if x == '' else x for x in img]\n    imag.append(img)","d0589b72":"imag[0]","5efc8627":"image_list = np.array(imag,dtype = 'float')\nX_train = image_list.reshape(-1,96,96,1)","b1499eaa":"plt.imshow(train[10].reshape(96,96),cmap='gray')\nplt.show()","eb03ca20":"training = train.drop('Image',axis = 1)\n\ny_train = []\nfor i in range(0,7049):\n    y = training.iloc[i,:]\n\n    y_train.append(y)\ny_train = np.array(y_train,dtype = 'float')","2bca6355":"from keras.layers.advanced_activations import ReLU\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D","259f1543":"model = Sequential()\n\nmodel.add(Convolution2D(32, (3,3), activation = 'relu', padding='same', use_bias=False, input_shape=(96,96,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(32, (3,3), activation = 'relu', padding='same', use_bias=False))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, (3,3), activation = 'relu', padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(128, (3,3), activation = 'relu', padding='same', use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","06ad28c8":"model.compile(optimizer='adam', \n              loss='mean_squared_error',\n              metrics=['acc'])","bd2dd156":"model.fit(X_train,y_train,epochs = 10,batch_size = 32,validation_split = 0.2)","a9ce121a":"timag = []\nfor i in range(0,1783):\n    timg = test['Image'][i].split(' ')\n    timg = ['0' if x == '' else x for x in timg]    \n    timag.append(timg)\n    \n    \n# reshape and convert\n\ntimage_list = np.array(timag,dtype = 'float')\nX_test = timage_list.reshape(-1,96,96,1) \n\n","c8a426c7":"pred = model.predict(X_test)","3c371be3":"lookid_list = list(lookup['FeatureName'])\nimageID = list(lookup['ImageId']-1)\npre_list = list(pred)\n\nrowid = lookup['RowId']\nrowid=list(rowid)\n\nfeature = []\nfor f in list(lookup['FeatureName']):\n    feature.append(lookid_list.index(f))\n    \n\npreded = []\nfor x,y in zip(imageID,feature):\n    preded.append(pre_list[x][y])\nrowid = pd.Series(rowid,name = 'RowId')\nloc = pd.Series(preded,name = 'Location')\nsubmission = pd.concat([rowid,loc],axis = 1)\nsubmission.to_csv('face_key_submission.csv',index = False)","51f3f96c":"Handling Missing Values","06186bc9":"**Creating submission**\n\n","e11c02d9":"  1. Convolution Operation\n* The convulution operation is one of the fundemantal building a CNN.\n* We have a input matrix(the input picture) and a filter(feature detector).\n* Filter usally is a 3x3 matrix but it is not a rule.\n* Filter detects horizantal or vertical lines and convex shape on the picture. For example in a person picture, we can find ears or noise etc.\n\n\n\n**Padding:**\n\n After edge detection we need to use padding. In edge detection step, we saw that If we use 6x6 input and 3x3 filter then we end up with a 4x4 matrix. Everytime we apply convolution operation then out image shrinks. If a covolution operation as above is applied, we can repeat this operation two or three time because our image getting starts really small. So we ara throwing awat information near the edge of image. To solve this proble, we can pad the image. If we pad additional one border 6x6 image, we get 8x8 image instead of 6x6 image. After padding, we appyle 3x3 filter again we end up with 6x6 matrix. So, we preserve the original input size.\n\n\n\n2. Pooling Operation\n\n We apply pooling to reduce the size of network and speed the computation. We can apply avarage pooling or max pooling. Let's suppose we have 4x4 input matrix, If we apply max pooling then the output will be 2x2 matrix. The way you do that is really simple. It has two hyperparameters, filter size(f) and stride(s).\n \n\n3. Flattening\n\n Flattening is converting the output of convolutional layers into a 1 dimensional array for inputing it to next layer. It is connected to fully connected layer.","f52287ae":"## Implementation with Keras","3ec7f53f":"#### Prediction","53ba6c53":"**Let's seperate labels**","b15c7908":"#### Let's separate the labels and features. ","6f9e5ca2":"**Sample Image**","f0dc237e":"#### Preparing Test Data","01ddea13":"#### Missin Values","89c9659f":"**Let's reshape and convert it into float value.**"}}