{"cell_type":{"dff07ccc":"code","0d9ad0f9":"code","d4279b0b":"code","42ef6c79":"code","828b8060":"code","09e01075":"code","bdc6c4d0":"code","189680a2":"code","a237ac6b":"markdown"},"source":{"dff07ccc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\n\n\nprint(os.listdir(\"..\/input\"))","0d9ad0f9":"# Importing the dataset\nBATCH_SIZE = 64\n\n# list all transformations\ntransform = transforms.Compose([transforms.ToTensor()])\n\n# download and load training dataset\ntrainset = torchvision.datasets.MNIST(root='.\/data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\n# download and load testing dataset\ntestset = torchvision.datasets.MNIST(root='.\/data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","d4279b0b":"# Exploring the dataset\n\n# functions to show an image\ndef imshow(img):\n    #img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))","42ef6c79":"# parameters \nN_STEPS = 28\nN_INPUTS = 28\nN_NEURONS = 150\nN_OUTPUTS = 10\nN_EPHOCS = 10","828b8060":"# RNN Model\nclass ImageRNN(nn.Module):\n    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n        super(ImageRNN, self).__init__()\n        \n        self.n_neurons = n_neurons\n        self.batch_size = batch_size\n        self.n_steps = n_steps\n        self.n_inputs = n_inputs\n        self.n_outputs = n_outputs\n        \n        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n        \n        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n        \n    def init_hidden(self,):\n        # (num_layers, batch_size, n_neurons)\n        return (torch.zeros(1, self.batch_size, self.n_neurons))\n        \n    def forward(self, X):\n        # transforms X to dimensions: n_steps X batch_size X n_inputs\n        X = X.permute(1, 0, 2) \n        \n        self.batch_size = X.size(1)\n        self.hidden = self.init_hidden()\n        \n        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n        out = self.FC(self.hidden)\n        \n        return out.view(-1, self.n_outputs) # batch_size X n_output","09e01075":"# Instantiate model\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\nmodel = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\nlogits = model(images.view(-1, 28,28))\nprint(logits[0:10])","bdc6c4d0":"# Training\nimport torch.optim as optim\n\n# Device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Model instance\nmodel = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ndef get_accuracy(logit, target, batch_size):\n    ''' Obtain accuracy for training round '''\n    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n    accuracy = 100.0 * corrects\/batch_size\n    return accuracy.item()\n\nfor epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n    train_running_loss = 0.0\n    train_acc = 0.0\n    model.train()\n    \n    # TRAINING ROUND\n    for i, data in enumerate(trainloader):\n         # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # reset hidden states\n        model.hidden = model.init_hidden() \n        \n        # get the inputs\n        inputs, labels = data\n        inputs = inputs.view(-1, 28,28) \n\n        # forward + backward + optimize\n        outputs = model(inputs)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_running_loss += loss.detach().item()\n        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n         \n    model.eval()\n    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f' \n          %(epoch, train_running_loss \/ i, train_acc\/i))","189680a2":"# Calculate test accuracy\ntest_acc = 0.0\nfor i, data in enumerate(testloader, 0):\n    inputs, labels = data\n    inputs = inputs.view(-1, 28, 28)\n\n    outputs = model(inputs)\n\n    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n        \nprint('Test Accuracy: %.2f'%( test_acc\/i))","a237ac6b":"    ![](https:\/\/miro.medium.com\/max\/700\/1*vhAfRLlaeOXZ-bruv7Ostg.png)"}}