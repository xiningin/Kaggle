{"cell_type":{"4e054151":"code","0b228245":"code","a590f07a":"code","43ec01cf":"code","3efbaa2a":"code","40e82adb":"code","beb68be0":"code","2bc3d10a":"code","8cba0802":"code","5a9b3274":"code","fe440deb":"code","6e4b618d":"code","d7f96407":"code","be719eba":"code","d0bf8193":"code","ceecf1b1":"code","32abbc19":"code","dd8a2b73":"code","9186c949":"code","b3e587cc":"code","2f90f7d7":"code","a9035592":"code","79fbe0f5":"code","c92a1a18":"code","935ae424":"markdown","3259971b":"markdown","4c19f631":"markdown","1009f8c0":"markdown","1c455c61":"markdown","e0c8cb3c":"markdown","f37a80ae":"markdown","503ce371":"markdown","0bc9a98d":"markdown","52e33bff":"markdown","94f1fcd0":"markdown","3d3d1a41":"markdown","34d51335":"markdown","6e948262":"markdown","451c4e4b":"markdown","36c9ca70":"markdown","49cbe074":"markdown","cb397968":"markdown","64a2ce03":"markdown","b8a50c2b":"markdown","5e93cda5":"markdown"},"source":{"4e054151":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt  # for plotting\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b228245":"### SimpleImputer takes as an input 2d array, that's why if you want to give raw data you need to reshape first\n### this is a function to fill dataframe column missing values with given method\nfrom sklearn.impute import SimpleImputer\ndef fill_nan(dataframe_col, method_to_fill):\n    imputer = SimpleImputer(missing_values=np.nan, strategy=method_to_fill)\n    imputer.fit(dataframe_col.values.reshape(-1, 1))\n    return imputer.transform(dataframe_col.values.reshape(-1, 1))[:,0]\n\n\n### this function is to transform column to categorical column\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\ndef func_column_categorical(array_to_transform, column_number):\n    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [column_number])], remainder='passthrough')\n    return np.array(ct.fit_transform(array_to_transform))\n\n\n### this function is for encode the column of the array \"simply make it 0 and 1\"\nfrom sklearn.preprocessing import LabelEncoder\ndef func_label_encoding(column_to_encode):\n    le = LabelEncoder()\n    return le.fit_transform(column_to_encode)\n\n\n### this function is to print confusion matrix and accuracy score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ndef func_print_conf_mat_acc(classifier, x_test, y_test):\n    y_pred = classifier.predict(x_test)\n    cm = confusion_matrix(y_test, y_pred)\n    print(cm)\n    print(accuracy_score(y_test, y_pred))\n    \n    \n### this function is for feature scaling\nfrom sklearn.preprocessing import StandardScaler\ndef func_scale_train_test(x_train, x_test):\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n    return x_train, x_test\n","a590f07a":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n","43ec01cf":"column_sequence = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Survived']\n\ntrain_data = train_data[column_sequence]","3efbaa2a":"total_data = pd.concat([train_data.iloc[:,:-1], test_data], ignore_index=True, sort=False)","40e82adb":"total_data['Embarked'].fillna('X', inplace=True)","beb68be0":"total_data['Age'] = fill_nan(total_data['Age'], 'mean')\ntotal_data['Fare'] = fill_nan(total_data['Fare'], 'mean')","2bc3d10a":"columns_to_drop = ['Name', 'Ticket', 'Cabin']\ntotal_data.drop(columns_to_drop, inplace=True, axis=1)","8cba0802":"x_total = total_data.values\ny_train = train_data.iloc[:, -1].values\n\n### transforming embarked column\nx_total = func_column_categorical(x_total, 7)\n\n### transforming sex column, making it 0 or 1\nx_total[:,6] = func_label_encoding(x_total[:,6])\n","5a9b3274":"x_train = x_total[0:len(y_train), :]\nx_test = x_total[len(y_train):, :]","fe440deb":"from sklearn.model_selection import train_test_split\nxx_train, xx_test, yy_train, yy_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)","6e4b618d":"xx_train, xx_test = func_scale_train_test(xx_train, xx_test)","d7f96407":"dt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\ndt_classifier.fit(xx_train, yy_train)\nfunc_print_conf_mat_acc(dt_classifier, xx_test, yy_test)","be719eba":"knn_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn_classifier.fit(xx_train, yy_train)\nfunc_print_conf_mat_acc(knn_classifier, xx_test, yy_test)","d0bf8193":"kernel_svm_classifier = SVC(kernel = 'rbf', random_state = 0)\nkernel_svm_classifier.fit(xx_train, yy_train)\nfunc_print_conf_mat_acc(kernel_svm_classifier, xx_test, yy_test)","ceecf1b1":"log_reg_classifier = LogisticRegression(random_state = 0)\nlog_reg_classifier.fit(xx_train, yy_train)\nfunc_print_conf_mat_acc(log_reg_classifier, xx_test, yy_test)","32abbc19":"nb_classifier = GaussianNB()\nnb_classifier.fit(xx_train, yy_train)\nfunc_print_conf_mat_acc(nb_classifier, xx_test, yy_test)","dd8a2b73":"rf_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nrf_classifier.fit(xx_train, yy_train)\nfunc_print_conf_mat_acc(rf_classifier, xx_test, yy_test)","9186c949":"svm_classifier = SVC(kernel = 'linear', random_state = 0)\nsvm_classifier.fit(xx_train, yy_train)\nfunc_print_conf_mat_acc(svm_classifier, xx_test, yy_test)","b3e587cc":"xgb_classifier = XGBClassifier(learning_rate=0.1, max_depth=3, n_jobs=1)\nxgb_classifier.fit(xx_train, yy_train)","2f90f7d7":"xgb_classifier.predict(xx_test)","a9035592":"func_print_conf_mat_acc(xgb_classifier, xx_test, yy_test)","79fbe0f5":"x_train, x_test = func_scale_train_test(x_train, x_test)\nfinal_classifier = XGBClassifier(learning_rate=0.1, max_depth=3, n_jobs=1)\nfinal_classifier.fit(x_train, y_train)\nfinal_prediction = final_classifier.predict(x_test)","c92a1a18":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': final_prediction})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","935ae424":"### Training XGBoost on the Training set\n","3259971b":"### Final training and prediction\n","4c19f631":"### So, the best accuracy we could achive with XGBoost model","1009f8c0":"### Read the csv files","1c455c61":"### Training the Logistic Regression model on the Training set","e0c8cb3c":"### Training the Naive Bayes model on the Training set","f37a80ae":"### Training the Random Forest Classification model on the Training set","503ce371":"### Training the Decision Tree Classification model on the Training set\n","0bc9a98d":"### Training the K-NN model on the Training set\n","52e33bff":"## Functions","94f1fcd0":"### Differentiating train and test datas\n","3d3d1a41":"### Drop 'Name', 'Ticket', 'Cabin' columns from 'total_data'","34d51335":"### Training the Kernel SVM model on the Training set","6e948262":"### Dealing with categorical datas","451c4e4b":"### Concatenating train and test datas","36c9ca70":"### Training the SVM model on the Training set","49cbe074":"### Feature Scaling","cb397968":"### Changing 'Embarked' column missing values with 'X' in 'total_data'\n","64a2ce03":"### Splitting the dataset into the Training set and Test set","b8a50c2b":"### Changing 'Age' and 'Fare' columns missing values with 'mean' values in 'total_data'\n","5e93cda5":"### Move survived column to the end\n"}}