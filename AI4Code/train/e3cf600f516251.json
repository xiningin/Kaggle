{"cell_type":{"7870f121":"code","ce1a92d4":"code","a77a0bd2":"code","dff2b13b":"code","61bbcd1f":"code","ebe1d5c4":"code","847ba285":"code","f7b750bc":"code","270b5679":"code","fbce2424":"code","a1479bf5":"code","5e442ab4":"code","33edc032":"code","e11258ea":"code","04b2de4b":"code","5ce6be71":"code","e41cce91":"code","d5d36323":"code","4929451c":"code","03c8afbb":"code","039ca592":"code","e0d67486":"code","d133315f":"code","50c22287":"code","a2adcf54":"code","ada0b586":"code","574ada9c":"code","bb70bc59":"code","91c90cd6":"code","9773a303":"code","ec6710af":"code","a54e8c22":"code","a1b757f9":"code","9dba1d27":"code","b949cb06":"code","715cabe0":"code","3ac3a553":"code","5819b272":"code","160be7a1":"code","16915743":"code","33d31a5e":"code","eb612dcf":"markdown","c23fe072":"markdown","012514c4":"markdown","daf99391":"markdown","89b16a36":"markdown","a4f3adff":"markdown","f093891a":"markdown","c00c377e":"markdown","16f17342":"markdown","ff69cd64":"markdown","a9b4ff0e":"markdown","832505d4":"markdown","deb90b0b":"markdown","f887dcb6":"markdown","7a7c9d78":"markdown","336e0deb":"markdown","78dc52fe":"markdown","66177a81":"markdown","1186f4a5":"markdown","509eaa3a":"markdown","92827d80":"markdown","5f69ef76":"markdown","b4adc423":"markdown","f9bf883d":"markdown","d789dc4e":"markdown","55653a3b":"markdown","e60aa7be":"markdown","47097dfa":"markdown","1114d35c":"markdown","f6d09274":"markdown"},"source":{"7870f121":"# Import the necessary packages used in this notebook\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.decomposition import PCA, TruncatedSVD\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objects as go\nimport plotly\nimport plotly.express as px\ninit_notebook_mode(connected=True) #do not miss this line\n\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score,recall_score,precision_recall_curve,average_precision_score\nfrom sklearn.utils import resample\n\n# Make notebook full width\n#from IPython.core.display import display, HTML\n#display(HTML(\"<style>.container { width:85% !important; }<\/style>\"))","ce1a92d4":"print(os.listdir(\"..\/input\"))","a77a0bd2":"datafr = pd.read_csv(\"..\/input\/ethereum-frauddetection-dataset\/transaction_dataset.csv\", error_bad_lines=False)","dff2b13b":"display(datafr.head(10))","61bbcd1f":"display(datafr.tail(10))","ebe1d5c4":"datafr.dtypes","847ba285":"datafr.var().astype(int)","f7b750bc":"datafr.columns","270b5679":"datafr.drop(['Unnamed: 0','Index','Address','min value sent to contract', 'max val sent to contract', 'avg value sent to contract', 'total ether sent contracts', ' ERC20 uniq sent addr.1', ' ERC20 avg time between sent tnx', ' ERC20 avg time between rec tnx',\n       ' ERC20 avg time between rec 2 tnx', ' ERC20 avg time between contract tnx', ' ERC20 min val sent contract', ' ERC20 max val sent contract', ' ERC20 avg val sent contract'], axis=1, inplace=True)\ndatafr.shape","fbce2424":"# Check for Data Duplication\nduplicateRowsDF = datafr[datafr.duplicated()]\nprint(\"Duplicated Entries\")\ndisplay(duplicateRowsDF)\n\n# Remove Duplicated entries\ndatafr = datafr[~datafr.duplicated()]\n\n\n# Check the missing values in the column\nmissing_data = datafr.isnull().sum().sort_values(ascending=False)\n\nmissing_data = missing_data.reset_index(drop=False)\nmissing_data = missing_data.rename(columns={\"index\": \"Columns\", 0: \"Value\"})\nmissing_data['Proportion'] = (missing_data['Value']\/len(datafr))*100\n\nsample = missing_data[missing_data['Proportion']>1]\nfig = px.pie(sample, names='Columns', values='Proportion',\n             color_discrete_sequence=px.colors.sequential.Viridis_r,\n             title='Columns with a percentage of Missing values over 1%')\nfig.update_traces(textposition='inside', textinfo='label')\nfig.update_layout(paper_bgcolor='rgba(0,0,0,0)',\n                  plot_bgcolor='rgba(0,0,0,0)',\n                  font=dict(family='Cambria, monospace', size=12, color='#000000'))\nfig.show()","a1479bf5":"# Fill Missing Value\ndatafr = datafr.fillna(method='ffill')","5e442ab4":"fig = px.pie(datafr, names='FLAG',\n             color_discrete_sequence=px.colors.sequential.Viridis_r,\n             title='Proportion of data for FLAG column')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.update_layout(paper_bgcolor='rgba(0,0,0,0)',\n                  plot_bgcolor='rgba(0,0,0,0)',\n                  font=dict(family='Cambria, monospace', size=12, color='#000000'))\nfig.show()","33edc032":"# Fraudulant Correlation\nsample = datafr[datafr['FLAG']==1]\ncorr = sample.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, linewidths=0.1, square=True)\n\n# Non-Fraudulant Correlation\nsample = datafr[datafr['FLAG']==0]\ncorr = sample.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, linewidths=0.1, square=True)\n","e11258ea":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnewdf = datafr.select_dtypes(include=numerics)","04b2de4b":"newdf","5ce6be71":"Y = newdf['FLAG']\nX = newdf.iloc[:,1:]\ntrain_X, val_X, train_y, val_y = train_test_split(X, Y, random_state=1)\nmy_model = RandomForestClassifier(n_estimators=100,\n                                  random_state=0).fit(train_X, train_y)\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, feature_names = val_X.columns.tolist())","e41cce91":"target = newdf['FLAG']","d5d36323":"# Import library for VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)\nresult = calc_vif(newdf)","4929451c":"# Identify variables with high multi-collinearity\nresult[result['VIF']>10]","03c8afbb":"# newdf.columns","039ca592":"# Keep 1 column in a set and drop other columns with VIF inf. One variable in set\/group is able to better explain the variability\nnewdf.drop(['Received Tnx', 'Number of Created Contracts', 'total Ether sent', 'total ether received', 'total transactions (including tnx to create contract'], axis=1, inplace=True)","e0d67486":"newdf.shape","d133315f":"# newdf.columns","50c22287":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\ny = newdf['FLAG']\nX = newdf.drop(['FLAG'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Test Accuracy is {:.2f}%\".format(accuracy * 100.0))\n# f1 score\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 Score is {:.2f}%\".format(f1))\n# calculate prediction\nprecision = precision_score(y_test, y_pred, average='binary')\nprint('Precision is {:.2f}%'.format(precision))\nrecall = recall_score(y_test, y_pred, average='binary')\nprint('Recall is {:.2f}%'.format(recall))","a2adcf54":"import shap\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_test)\nshap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n","ada0b586":"model = XGBClassifier()\nmodel.fit(X_train[['Unique Received From Addresses', 'Time Diff between first and last (Mins)', 'avg val received']], y_train)\n\ny_pred = model.predict(X_test[['Unique Received From Addresses', 'Time Diff between first and last (Mins)', 'avg val received']])\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Test Accuracy is {:.2f}%\".format(accuracy * 100.0))","574ada9c":"# assign cnf_matrix with result of confusion_matrix array\ncnf_matrix = confusion_matrix(y_test,y_pred)\n#create a heat map\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","bb70bc59":"from xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.ensemble import BalancedBaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score,recall_score,precision_recall_curve,average_precision_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression","91c90cd6":"random_seed = 303","9773a303":"# define meta learner model\nlevel1 = LogisticRegression()\n# define the stacking ensemble\nestimates = list()\nestimates.append(('rf', RandomForestClassifier(n_estimators=1200,\n                                          max_depth = 8,\n                                          min_samples_leaf=10,\n                                          random_state=random_seed, \n                                          max_features = 0.4,\n                                          class_weight='balanced',\n                                          n_jobs=-1)))\nestimates.append(('brf', BalancedRandomForestClassifier(n_estimators=1200, \n                                                   max_depth = 8,\n                                                   random_state=random_seed, \n                                                   max_features = 0.4,\n                                                   class_weight='balanced',\n                                                   n_jobs=-1)))\nestimates.append(('xgb', XGBClassifier(max_depth=8,\n                                  learning_rate=0.7,\n                                  n_estimators=1200,\n                                  random_state=random_seed,\n                                  max_features = 0.4,\n                                  min_samples_leaf=10,\n                                  eval_metric=[\"error\", \"logloss\"],\n                                  n_jobs=-1)))\nestimates.append(('lgbm', LGBMClassifier(boosting_type='gbdt',\n                                    num_leaves=10,\n                                    max_depth=5,\n                                    learning_rate=0.7,\n                                    n_estimators=1200,\n                                    random_state=random_seed,\n                                    max_features = 0.4,\n                                    eval_metric=[\"error\", \"logloss\"],\n                                    class_weight='balanced',\n                                    n_jobs=-1)))\n# Stacking Classifier\nstack = StackingClassifier(estimators = estimates, final_estimator=level1)\n# Voting Classifier with hard voting\nvot_hard = VotingClassifier(estimators = estimates, voting ='hard')","ec6710af":"def get_models():\n    models = {}\n    models['stack'] = stack\n    # models['vot_hard'] = vot_hard\n    return models","a54e8c22":"newdf.shape","a1b757f9":"Y = newdf['FLAG'].values #Target\nX = newdf.drop('FLAG',axis=1) #Features","9dba1d27":"from imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTEENN\n# setting up testing and training sets\n# Random Split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=random_seed)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=random_seed) # 0.25 x 0.8 = 0.2\n\n# SMOTEENN\nsmenn = SMOTEENN(random_state=random_seed)\nX_train, Y_train = smenn.fit_resample(X_train, Y_train)","b949cb06":"unique, counts = np.unique(Y_train, return_counts=True)\n\nprint(np.asarray((unique, counts)).T)","715cabe0":"unique, counts = np.unique(Y_test, return_counts=True)\n\nprint(np.asarray((unique, counts)).T)","3ac3a553":"models = get_models()","5819b272":"import pickle\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nprint(\"Train Size\", X_train.shape)\nprint(\"Valid Size\", X_val.shape)\nprint(\"Test Size\", X_test.shape)\n\nscaler = RobustScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_train_scaled = pd.DataFrame(X_train_scaled)\n\nX_valid_scaled = scaler.transform(X_val)\nX_valid_scaled = pd.DataFrame(X_valid_scaled)\n\nfinal_test_scaled = scaler.transform(X_test)\nfinal_test_scaled = pd.DataFrame(final_test_scaled)\n\nprediction_smote = {}\nfor model in models.keys():\n    print(\"Model {0}\".format(model))\n    smote = models[model]\n    eval_set = [(X_train_scaled, Y_train), (X_valid_scaled, Y_val)]\n    smote.fit(X_train_scaled, Y_train)\n    # save the model to disk\n    filename = 'finalized_model.sav'\n    pickle.dump(smote, open(filename, 'wb'))\n\n# load model\nloaded_model = pickle.load(open(filename, 'rb'))\n    \n# predict probabilities\nprobs = loaded_model.predict_proba(final_test_scaled)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# Predict on test\nsmote_pred = loaded_model.predict(final_test_scaled)\nprediction_smote = smote_pred","160be7a1":"prediction_smote","16915743":"# Checking Balanced accuracy\nfrom sklearn.metrics import balanced_accuracy_score\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nimport seaborn as sns\n\ndef evaluate(Y_test, smote_pred):\n    b_a = balanced_accuracy_score(Y_test, smote_pred)\n    print(\"Balanced Test Accuracy is {:.2f}%\".format(b_a * 100.0))\n    f1_over = f1_score(Y_test, smote_pred)\n    print(\"F1 Score is {:.2f}%\".format(f1_over))\n    # assign cnf_matrix with result of confusion_matrix array\n    cnf_matrix = confusion_matrix(Y_test,smote_pred)\n    #create a heat map\n    sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\n    plt.xlabel('Predicted')\n    plt.ylabel('Expected')\n    plt.show()\n    precision_positive = metrics.precision_score(Y_test, smote_pred, pos_label=1)\n    precision_negative = metrics.precision_score(Y_test, smote_pred, pos_label=0)\n    \n    recall_sensitivity = metrics.recall_score(Y_test, smote_pred, pos_label=1)\n    recall_specificity = metrics.recall_score(Y_test, smote_pred, pos_label=0)\n    \n    #recall = np.diag(cnf_matrix) \/ np.sum(cnf_matrix, axis = 1)\n    #precision = np.diag(cnf_matrix) \/ np.sum(cnf_matrix, axis = 0)\n    print(\"Precision Positive-1:\", np.mean(precision_positive))\n    print(\"Precision Negative-0:\", np.mean(precision_negative))\n    print(\"Recall Sensitivity-1:\", np.mean(recall_sensitivity))\n    print(\"Recall Specificity-0:\", np.mean(recall_specificity))\n    return b_a, f1_over, precision_positive, precision_negative, recall_sensitivity, recall_specificity ","33d31a5e":"b_accuracy = []\nf1_scores = []\nprecisions_pos = []\nprecisions_neg = []\nrecall_sens = []\nrecall_spec = []\na,b,c,d,e,f = evaluate(np.array(Y_test.astype(int)), prediction_smote)\nb_accuracy.append(a)\nf1_scores.append(b)\nprecisions_pos.append(c)\nprecisions_neg.append(d)\nrecall_sens.append(e)\nrecall_spec.append(f)","eb612dcf":"## <a id='3'> Understanding Imbalance Data<\/a>","c23fe072":"**Comments:** If all the independent variables are orthogonal to each other, then VIF = 1.0. If there is perfect correlation, then VIF = infinity. A large value of VIF indicates that there is a correlation between the variables. If the VIF is 10, this means that the variance of the model coefficient is inflated by a factor of 10 due to the presence of multicollinearity.","012514c4":"<img src=\"https:\/\/feedzai.com\/aptopees\/2020\/12\/Header_Fraud_Detection_and_Prevention-.jpg\" alt=\"Drawing\" style=\"width: 700px; height: 450px;\"\/>","daf99391":"This dataset contains rows of known fraud and valid transactions made over Ethereum, a type of cryptocurrency.\n\nHere is a description of the rows of the dataset:\n\n1. Address: the address of the ethereum account\n2. Avg min between sent tnx: Average time between sent transactions for account in minutes\n3. Avg min between received tnx: Average time between received transactions for account in minutes\n4. Time Diff between first and_last (Mins): Time difference between the first and last transaction\n5. Sent_tnx: Total number of sent normal transactions\n6. Received_tnx: Total number of received normal transactions\n7. NumberofCreated_Contracts: Total Number of created contract transactions\n8. UniqueReceivedFrom_Addresses: Total Unique addresses from which account received transaction\n9. UniqueSentTo_Addresses20: Total Unique addresses from which account sent transactions\n10. MinValueReceived: Minimum value in Ether ever received\n11. MaxValueReceived: Maximum value in Ether ever received\n12. AvgValueReceived5Average value in Ether ever received\n13. MinValSent: Minimum value of Ether ever sent\n14. MaxValSent: Maximum value of Ether ever sent\n15. AvgValSent: Average value of Ether ever sent\n16. MinValueSentToContract: Minimum value of Ether sent to a contract\n17. MaxValueSentToContract: Maximum value of Ether sent to a contract\n18. AvgValueSentToContract: Average value of Ether sent to contracts\n19. TotalTransactions(IncludingTnxtoCreate_Contract): Total number of transactions\n20. TotalEtherSent:Total Ether sent for account address\n21. TotalEtherReceived: Total Ether received for account address\n22. TotalEtherSent_Contracts: Total Ether sent to Contract addresses\n23. TotalEtherBalance: Total Ether Balance following enacted transactions\n24. TotalERC20Tnxs: Total number of ERC20 token transfer transactions\n25. ERC20TotalEther_Received: Total ERC20 token received transactions in Ether\n26. ERC20TotalEther_Sent: Total ERC20token sent transactions in Ether\n27. ERC20TotalEtherSentContract: Total ERC20 token transfer to other contracts in Ether\n28. ERC20UniqSent_Addr: Number of ERC20 token transactions sent to Unique account addresses\n29. ERC20UniqRec_Addr: Number of ERC20 token transactions received from Unique addresses\n30. ERC20UniqRecContractAddr: Number of ERC20token transactions received from Unique contract addresses\n31. ERC20AvgTimeBetweenSent_Tnx: Average time between ERC20 token sent transactions in minutes\n32. ERC20AvgTimeBetweenRec_Tnx: Average time between ERC20 token received transactions in minutes\n33. ERC20AvgTimeBetweenContract_Tnx: Average time ERC20 token between sent token transactions\n34. ERC20MinVal_Rec: Minimum value in Ether received from ERC20 token transactions for account\n35. ERC20MaxVal_Rec: Maximum value in Ether received from ERC20 token transactions for account\n36. ERC20AvgVal_Rec: Average value in Ether received from ERC20 token transactions for account\n37. ERC20MinVal_Sent: Minimum value in Ether sent from ERC20 token transactions for account\n38. ERC20MaxVal_Sent: Maximum value in Ether sent from ERC20 token transactions for account\n39. ERC20AvgVal_Sent: Average value in Ether sent from ERC20 token transactions for account\n40. ERC20UniqSentTokenName: Number of Unique ERC20 tokens transferred\n41. RC20UniqRecTokenName: Number of Unique ERC20 tokens received\n42. ERC20MostSentTokenType: Most sent token for account via ERC20 transaction\n43. ERC20MostRecTokenType: Most received token for account via ERC20 transactions\n44. FLAG: whether the transaction is fraud or not\n","89b16a36":"**Comments:** The model accuracy hasn't differed by much suggesting that the achieved acccuracy is just an illusion which is caused due to imbalanced class dataset. Below we can actually see how the proportion of observations are actually predicted for each class using Confusion Matrix.","a4f3adff":"Accuracy can be a misleading metric for imbalanced data sets. Consider a sample with 95 negative and 5 positive values. Classifying all values as negative in this case gives 0.95 accuracy score. There are many metrics that don't suffer from this problem. For example, balanced accuracy[22] (bACC) normalizes true positive and true negative predictions by the number of positive and negative samples, respectively, and divides their sum by two: <br>\n\n\n![](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/f36a0a23620dcc20bb32cde7335179175f3cb63b)\n\nFor the previous example (95 negative and 5 positive samples), classifying all as negative gives 0.5 balanced accuracy score (the maximum bACC score is one), which is equivalent to the expected value of a random guess in a balanced data set. Balanced accuracy can serve as an overall performance metric for a model, whether or not the true labels are imbalanced in the data, assuming the cost of FN is the same as FP.","f093891a":"### The metric trap\nOne of the major issues that novice users fall into when dealing with unbalanced datasets relates to the metrics used to evaluate their model. Using simpler metrics like accuracy_score can be misleading. In a dataset with highly unbalanced classes, if the classifier always \"predicts\" the most common class without performing any analysis of the features, it will still have a high accuracy rate, obviously illusory.\n","c00c377e":"### Data Ingestion","16f17342":"**Future Observations:** Try to compare the volatility of Ethereum price against trnasaction dates to identify if major frauds happens during high volatility days.","ff69cd64":"## Introduction\nIn this notebook I will explore & implement the scope of credit card fraud detection using predictive models to identify the level of accuracy of labelling a transaction as regular or fraud.\n\n\n## Scope\n1. <a href='#1'> Problem Understanding <\/a>\n2. <a href='#2'> Preprocessing & Exploratory Data Analysis <\/a>\n3. <a href='#3'> Understanding Imbalance Data <\/a>\n4. <a href='#4'> Resampling Techniques <\/a>\n5. <a href='#5'> Model Prediction <\/a>\n6. <a href='#6'> Result Evaluation <\/a>\n\n\n## Focus Points\n* Never implement testing directly on oversampled and undersampled data.\n* Resampling (Oversampling or Undersampling) should be done during cross-validation only.\n* Always implement evaluation metrics like F1 score, Confusion Matrix, AUC score over Accuracy.\n","a9b4ff0e":"Some understanding of Blockchain methodology & how crypto-currency would work\n\n**Currency features:** total amount sent, total amount received, average amount sent, average amount received\nstandard deviation received, standard deviation sent\n\n**Network\/graph features:** in degree, out degree\nclustering coef\ufb01cient, number of triangles\n\n**Average neighbourhood (source target) whereby with reference to each query node:** source refers to origin\non incoming transaction and target is the destination The four features identi\ufb01ed: in-in, in-out, out-out, out\nin. Source-target in this regard represent node in degree and out-degree as re\ufb02ected by in and out.\n\n[Reference](https:\/\/www.researchgate.net\/publication\/313454425_A_Multifaceted_Approach_to_Bitcoin_Fraud_Detection_Global_and_Local_Outliers?enrichId=rgreq-5c6a9545f1143f5ff27a6462bce4bff7-XXX&enrichSource=Y292ZXJQYWdlOzMxMzQ1NDQyNTtBUzo2MzU5NzAzMjQwMTMwNTdAMTUyODYzODU0OTY0Nw%3D%3D&el=1_x_2&_esc=publicationCoverPdf)","832505d4":"### Conclusion\nSo far we tried using various performance metrics like Confusion matrix, F1-Score, Precision-Recall curve for different techniques like over-sampling of minority class, under-sampling of majority class and SMOTE (Synthetic Minority Over-Sampling Technique). Based on our evaluation metrics we found that undersampling of majority class resulted in poor poerformance when compared to Over-Sampling techniques and SMOTE coupled with undersampling ENN. It's still hard to pick a winner here. The algorithm we used in all the scenario was XGBoost.\n\nFurther Improvements: To further improve the model, below options can be considered:\n\n- Try using Deep Learning algorithms like MLP, or stacked or hybrid machine learning algorithms\n- Tuning of hyper-parameters(learning rate, max-depth, etc.) of the above models.","deb90b0b":"### Check for Multicollinearity","f887dcb6":"## <a id='5'> Model Prediction <\/a>","7a7c9d78":"### Confusion Matrix\n\nAn interesting way to evaluate the results is by means of a confusion matrix, which shows the correct and incorrect predictions for each class. In the first row, the first column indicates how many Flags 0 were predicted correctly, and the second column, how many Flags 0 were predicted as 1. In the second row, we note that all Flags 1 entries were erroneously predicted as Flags 0.\n\nTherefore, the higher the diagonal values of the confusion matrix the better, indicating many correct predictions.","336e0deb":"**Comments:** Much more balanced training data","78dc52fe":"## <a id='1'> Problem Understanding <\/a>","66177a81":"**Comments:** The SMOTE+ENN technique has improved the imbalance problem in our dataset and thus after modeling based on a Stacking classfier the results have fairly improved compared to the confusion matrix above <a href='#3'> Understanding Imbalance Data <\/a>.<br>\n**Layman Terms:** The model performance has improved with reduction in FN (missing the flag\/fraudulant transactions) with just 4% (11\/279) comapred to previously 31% (94\/295). Also, the FP (mis-identifying the usual transactions as flagged\/fraudulant) has reduced from 27% previously to just 15%. <br>\n**Note:** However,there's always a balance required between optimising FN against FP. Depending upon the business value we tune the model to get a our desired factor to an acceptable rate. In case of this kernel, I'm pretty happy with the results.","1186f4a5":"**The dataset is highly imbalanced which could lead us to create an algorithm resulting in predicting only 1 type of FLAG. Thus, we have to try different strategies as a solution to imbalance class problem.**\nHere are the few techniques that can be used for such a problem:\n1. Try Changing Performance Metric\n2. Try Resampling Dataset\n3. Try Generating Synthetic Samples\n4. Try Different Algorithms\n\n[Reference 1](https:\/\/machinelearningmastery.com\/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset\/)\n<br>\n[Reference 2](https:\/\/towardsdatascience.com\/methods-for-dealing-with-imbalanced-data-5b761be45a18)","509eaa3a":"### Change the Performance Metric\nAs we saw above, accuracy is not the best metric to use when evaluating imbalanced datasets as it can be very misleading. Metrics that can provide better insight include: <br>\n\n- Confusion Matrix: a table showing correct predictions and types of incorrect predictions.\n- Precision: the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifier\u2019s exactness. Low precision indicates a high number of false positives.\n- Recall: the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True -Positive Rate. It is a measure of a classifier\u2019s completeness. Low recall indicates a high number of false negatives.\n- F1: Score: the weighted average of precision and recall.","92827d80":"**Comments:** There seems to be a conflict between the feature importance in trying to estimate what factor influences the FLAG=1, fradualant transaction via Permutance Importance compared to Pearson Coefficient. <br>\n\nPermutation Importance shows that any major change in features like Time Diff b\/w First & last, Avg mins b\/w received tnx, avg val received have greater impact in predicting whether a transaction is Flagged as Fraud or Usual.","5f69ef76":"## <a id='4'> Resampling Technique<\/a>","b4adc423":"## <a id='2'> Preprocessing & Exploratory Data Analysis <\/a>","f9bf883d":"**Again trying to run a predictive model on first 3 features 'Unique Received From Addresses', 'Time Diff between first and last (Mins)', 'avg val received' we should notice a change in model's performance**","d789dc4e":"A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and \/ or adding more examples from the minority class (over-sampling).\n<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQB2zMaVjK63gF15QqCoMwzG3ewF5fD3NfKrA&usqp=CAU\" style=\"width: 300px; height: 300px;\"\/>","55653a3b":"### SMOTE-ENN Method\nDeveloped by Batista et al (2004), this method combines the SMOTE ability to generate synthetic examples for minority class and ENN ability to delete some observations from both classes that are identified as having different class between the observation\u2019s class and its K-nearest neighbor majority class. The process of SMOTE-ENN can be explained as follows. <br>\n- (Start of SMOTE) Choose random data from the minority class.\n- Calculate the distance between the random data and its k nearest neighbors.\n- Multiply the difference with a random number between 0 and 1, then add the result to the minority class as a synthetic sample.\n- Repeat step number 2\u20133 until the desired proportion of minority class is met. (End of SMOTE)\n- (Start of ENN) Determine K, as the number of nearest neighbors. If not determined, then K=3.\n- Find the K-nearest neighbor of the observation among the other observations in the dataset, then return the majority class from the K-nearest neighbor.\n- If the class of the observation and the majority class from the observation\u2019s K-nearest neighbor is different, then the observation and its K-nearest neighbor are deleted from the dataset.\n- Repeat step 2 and 3 until the desired proportion of each class is fulfilled. (End of ENN)\n","e60aa7be":"**Comments:** Drop independant features set with variance 0, the zero variance translates to constant or near constant behaviour in the features thus limiting any further explainatory power for analysis.","47097dfa":"**Comments:** This correlation plot shows that different features have different correlation when the dataset is subseted based on Fraudulant and Non-Fraudulant transactions","1114d35c":"## <a id='6'> Result Evaluation <\/a>","f6d09274":"**Comments:** Our test dataset which again is imbalanced as it's untouched"}}